Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 15?22,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsSeeing through deception: A computational approach to deceitdetection in written communication?ngela Almela Rafael Valencia-Garc?a Pascual CantosEnglish Department  Faculty of Computer Science English DepartmentUniversidad de Murcia Universidad de Murcia Universidad de Murcia30071 Murcia (Spain) 30071 Espinardo, Murcia (Spain) 30071 Murcia (Spain)angelalm@um.es valencia@um.es pcantos@um.esAbstractThe present paper addresses the questionof the nature of deception language.Specifically, the main aim of this piece ofresearch is the exploration of deceit inSpanish written communication.
We havedesigned an automatic classifier based onSupport Vector Machines (SVM) for theidentification of deception in an ad hocopinion corpus.
In order to test theeffectiveness of the LIWC2001categories in Spanish, we have drawn acomparison with a Bag-of-Words (BoW)model.
The results indicate that theclassification of the texts is moresuccessful by means of our initial set ofvariables than with the latter system.These findings are potentially applicableto areas such as forensic linguistics andopinion mining, where extensive researchon languages other than English isneeded.1 IntroductionDeception has been studied from the perspectiveof several disciplines, namely psychology,linguistics, psychiatry, and philosophy (Granhag& Str?mwall, 2004).
The active role played bydeception in the context of humancommunication stirs up researchers?
interest.Indeed, DePaulo et al (1996) report that peopletell an average of one to two lies a day, eitherthrough spoken or written language.
Morerecently, researchers in the field of opinionmining have become increasingly concerned withthe detection of the truth condition of theopinions passed on the Internet (Ott et al, 2011).This issue is particularly challenging, since theresearcher is provided with no information apartfrom the written language itself.Within this framework, the present studyattempts to explore deception cues in writtenlanguage in Spanish, which is something of anovelty.
The remainder of this paper is organizedas follows: in Section 2, related work on thetopic is summarized; in Section 3, we explain ourmethodology for analyzing data; in Section 4, theevaluation framework and experimental resultsare presented and discussed; Section 5 presentsthe results from a Bag-of-Words model as a basisfor comparison; finally, in Section 6 someconclusions and directions for further researchare advanced.2 Related WorkThere are verbal cues to deception which formpart of existing verbal lie detection tools used byprofessional lie catchers and scholars (Vrij,2010).
Automated linguistic techniques havebeen used to examine the linguistic profiles ofdeceptive language in English.
Most commonly,researchers have used the classes of wordsdefined in the Linguistic Inquiry and WordCount or LIWC (Pennebaker et al, 2001), whichis a text analysis program that counts words inpsychologically meaningful categories.
Itincludes about 2,200 words and word stemsgrouped into 72 categories relevant topsychological processes.
It has been used tostudy issues like personality (Mairesse et al,2007), psychological adjustment (Alpers et al,2005), social judgments (Leshed et al, 2007),tutoring dynamics (Cade et al, 2010), and mentalhealth (Rude et al, 2004).
The validation of thelexicon contained in its dictionary has beenperformed by means of a comparison of humanratings of a large number of written texts to therating obtained through their LIWC-basedanalyses.LIWC was firstly used by Pennebaker?sgroup for a number of studies on the language ofdeception, being the results published inNewman et al (2003).
For their purposes, they15collected a corpus with true and false statementsthrough five different studies.
In the first threetests, the participants expressed their trueopinions on abortion, as well as the opposite oftheir point of view.
The first study dealt with orallanguage, hence the videotaping of the opinions,whereas in the second and the third ones theparticipants were respectively asked to type andhandwrite their views.
In the fourth study, thesubjects orally expressed true and false feelingsabout friends, and the fifth one involved a mockcrime in which the participants had to deny anyresponsibility for a fictional theft.
The texts wereanalyzed using the 29 variables of LIWCselected by the authors.
Of the 72 categoriesconsidered by the program, they excluded thecategories reflecting essay content, any linguisticvariable used at low rates, and those unique toone form of communication (spoken vs. writtenlanguage).
The values for these 29 variables werestandardized by converting the percentages to zscores so as to enable comparisons across studieswith different subject matters and modes ofcommunication.
For predicting deception, alogistic regression was trained on four of the fivesubcorpora and tested on the fifth, which entailsa fivefold cross-validation.
The authors obtaineda correct classification of liars and truth-tellers ata rate of 67% when the topic was constant and arate of 61% overall.
However, in two of the fivestudies, the performances were not better thanchance.
Finally, the variables that weresignificant predictors in at least two studies wereused to evaluate simultaneously the five tests,namely self-reference terms, references to others,exclusive words, negative emotion elements andmotion words.
The reason for the poorperformance in some of the studies may lie withthe mixing of modes of communication, since, asstated by Picornell (2011), the verbal cues todeception in oral communication do not translateacross into written deception and vice versa.From this study, LIWC has been used in theforensic field mainly for the investigation ofdeception in spoken language.
There are someearly studies in this line which are concernedwith the usefulness of this software applicationas compared to Reality Monitoring technique(RM).
First, Bond and Lee (2005) applied LIWCto random samples from a corpus comprising lieand truth oral statements by sixty-four prisoners,only taking into consideration the variablesselected by Newman et al (2003) for the globalevaluation.
Overall, the results show thatdeceivers score significantly lower than truth-tellers as regards sensory details, butoutstandingly higher for spatial aspects.
Thelatter finding goes against previous research inRM theory; such is the case of Newman et al(2003), where these categories did not producesignificant results.
Apart from this difference,both studies share common ground: despiteconsidering RM theory, the authors did notperform manual RM coding on their data.
Thus,they do not draw a direct comparison betweenthe effectiveness of automatic RM codingthrough LIWC software and manual RM coding.This gap in research was plugged by Vrij etal.
(2007).
Their hypothesis predicts that LIWCcoding is less successful than manual RM codingin discriminating between deceivers and truth-tellers.
In order to test this theory, they collecteda corpus of oral interviews of 120 undergraduatestudents.
Half the participants were given therole of deceivers, having to lie about a stagedevent, whereas the remainder had to tell the truthabout the action.
The analysis revealed that RMdistinguished between truth-tellers and deceiversbetter than Criteria-Based Content Analysis.
Inaddition, manual RM coding offered more verbalcues to deception than automatic coding of theRM criteria.
There is a second experiment in thisstudy assessing the effects of three policeinterview styles on the ability to detectdeception, but the results will not be presentedhere because the subject lies outside the scope ofthis work.More recently, Fornaciari & Poesio (2011)conducted a study on a corpus of transcriptionsof oral court testimonies.
This work presents twomain novelties: first, the object of study is asample of spontaneously produced languageinstead of statements uttered ad hoc orlaboratory-controlled; moreover, it deals with alanguage other than English, namely Italian.
Theauthors continue Newman et al?s (2003) idea ofa method for classifying texts according to theirtruth condition instead of simply studying thelanguage in descriptive terms, their analysis unitbeing the utterance instead of the text.
Theirultimate aim is a comparison between theefficiency of the content-related features ofLIWC and surface-related features, including thefrequency and use of function words or of certainn-grams of words or parts-of-speech.
They usedfive kinds of vectors, taking the best featuresfrom their experiment, from Newman et al(2003), and all LIWC categories.
The latter16results in slightly better performance than theformer, but they do not obtain a statisticallysignificant difference.LIWC has been also used for theinvestigation of deception in written language.Curiously enough, research in this line has beenapproached by computational linguists and notfrom the perspective of the forensic science.First, Mihalcea & Strapparava (2009) usedLIWC for post hoc analysis, measuring severallanguage dimensions on a corpus of 100 falseand true opinions on three controversial topics ?the design of the questionnaire is indeed similarto Newman et al?s (2003).
As a preliminaryexperiment, they used two ML classifiers: Na?veBayes and Support Vector Machines, using wordfrequencies for the training of both algorithms,similar to a Bag-of-Words model.
They achievedan average classification performance of 70%,which is significantly higher than the 50%baseline.
On the basis of this information, theycalculate a dominance score associated with agiven word class inside the collection ofdeceptive texts as a measure of saliency.
Then,they compute word coverage, which is theweight of the linguistic item in the corpora.
Thus,they identify some distinctive characteristics ofdeceptive texts, but purely in descriptive terms.In this strand of research, Ott et al (2011)used the same two ML classifiers.
For theirtraining, apart from comparing lexically?baseddeception classifiers to a random guess baseline,the authors additionally evaluated and comparedtwo other computational approaches: genreidentification through the frequency distributionof part-of-speech (POS) tags, and a textcategorization approach which allows them tomodel both content and context with n-gramfeatures.
Their ultimate aim is deceptive opinionspam, which is qualitatively different fromdeceptive language itself.
Findings reveal that n-gram-based text categorization is the bestdetection approach; however, a combination ofLIWC features and n-gram features performmarginally better.These studies deal with written language asused in an asynchronous means ofcommunication.
In contrast, Hancock and hisgroup explore deceptive language in synchronouscomputer-mediated communication (CMC), inwhich all participants are online at the same time(Bishop, 2009).
Specifically, they use chatrooms.
In their first study using LIWC, Hancocket al (2004) explored differences between thesender?s and the receiver?s linguistic style acrosstruthful and deceptive communication.
For theanalysis, they selected the variables deemedrelevant to the hypotheses, namely word counts,pronouns, emotion words, sense terms, exclusivewords, negations, and question frequency.Results showed that, overall, when participantstold lies, they used more words, a larger amountof references to others, and more sense terms.Hancock et al (2008) reported rather similarresults from a comparable experiment.
Apartfrom this, they introduced the element ofmotivation, and observed that motivated liarstended to avoid causal terms, while unmotivatedliars increased their use of negations.All these studies coincide in theirexploration of a set of variables, but none ofthem take LIWC features as a whole for theautomatic classification of both sublanguages onwritten statements.
Furthermore, researchersusually take the language of deception as awhole, ignoring the particular features whichmay distinguish a speaker from the others,assuming that everybody lies similarly.
Insteadof comparing each individual sample ofdeceptive language to its corresponding controltext, the whole set of statements labelled as?false?
is contrasted with the set comprising?true?
statements.
This idiolectal comparisoncertainly permeates the practitioner lore withinthe forensic context, hence its interest forcomputational approaches to deception detection.It is worth noticing that the main disadvantage ofa corpus of ?authentic?
language is precisely thedifficulty to obtain a control sample of languagein which the same speaker tells the truth for thesake of comparison.3 MethodologyA framework based on a classifier using aSupport Vector Machine (SVM) has beendeveloped in order to detect deception in ouropinion corpus.
SVM have been appliedsuccessfully in many text classification tasks dueto their main advantages: first, they are robust inhigh dimensional spaces; second, any feature isrelevant; third, they are robust when there is asparse set of samples; finally, most textcategorization problems are linearly separable(Saleh et al, 2011).We have used LIWC to obtain the values forthe categories for the subsequent training of theabovementioned classifier.
This softwareapplication provides an efficient method for17studying the emotional, cognitive, and structuralcomponents contained in language on a word byword basis (Pennebaker et al, 2001).
The LIWCinternal dictionary comprises 2,300 words andword stems classified in four broad dimensions:standard linguistic processes, psychologicalprocesses, relativity, and personal concerns.
Eachword or word stem defines one or more of the 72default word categories.
The selection of wordsattached to language categories in LIWC hasbeen made after hundreds of studies onpsychological behaviour (Tausczik &Pennebaker, 2010).
Within the first dimension,linguistic processes, most categories involvefunction words and grammatical information.Thus, the selection of words is straightforward;such is the case of the category of articles, whichis made up of nine words in Spanish: el, la, los,las, un, uno, una, unos, and unas.
Similarly, thethird dimension, relativity, comprises a categoryconcerning time which is clear-cut: past, presentand future tense verbs.
Within the samedimension, that is also the case of the categoryspace, in which spatial prepositions and adverbshave been included.
On the other hand, theremaining two dimensions are more subjective,especially those denoting emotional processeswithin the second dimension.
These categoriesindeed demanded human judges to make thelexical selection.
For all subjective categories, aninitial list of word candidates was compiled fromdictionaries and thesauruses, being subsequentlyrated by groups of three judges workingindependently.
Finally, the fourth dimensioninvolves word categories related to personalconcerns intrinsic to the human condition.
Asmentioned above, this dimension has been oftenexcluded in deception detection studies, on thebasis that it is too content-dependent (Hancock etal., 2004, 2008; Newman et al, 2003).Table 1 provides an illustrative summary ofthe list of the dictionary categories ?acomprehensive account is included inPennebaker et al (2001:17-21), and theequivalences in Spanish can be found inRam?rez-Esparza et al (2007:37-39).We implemented our experiments using theWeka library (Bouckaert et al, 2010).
Weapplied a linear SVM with the defaultconfiguration set by the tool.
In order to train theclassifier, the corpus is divided into true and falsesamples.
For their analysis, we have consideredthe attributes of each dimension of LIWCpreviously described.I.StandardlinguisticdimensionII.Psycholog.processesIII.RelativityIV.PersonalconcernsTotalpronounsCausation SpaceJob orwork% wordscapturedby thedictionaryAffectiveoremotionalprocessesInclusivePhysicalstates andfunctions% wordslongerthan sixlettersNegativeemotionsExclusive ReligionWordCountCognitiveprocessesTimeMoney andfinancialissuesFirst-personsingularPositiveemotionsMotionverbsLeisureactivityTable 1: Summary of the variables used inLIWC2001Several classifiers have been obtained byusing the categories of each dimension.
For eachclassifier a tenfold cross-validation has beendone and all sets have an equal distributionbetween true and false statements.4 Evaluation framework and resultsTo study the distinction between true anddeceptive statements, a corpus with explicitlabelling of the truth condition associated witheach statement was required.
For this purpose,the design of the questionnaire for thecompilation of the corpus was similar to thatused by Mihalcea and Strapparava (2009).
Datawere produced by 100 participants, all of themnative speakers of Peninsular or EuropeanSpanish.
We focused on three different topics:opinions on homosexual adoption, opinions onbullfighting, and feelings about one?s best friend.A similar corpus was used in (Almela, 2011),where a pilot study on the discriminatory powerof lexical choice was conducted.
The corpus usedincluded a further data set, comprising opinionson a good teacher.
However, it was disregardedin the present paper, since the statements wereshorter and false and true opinions were not soeffectively differentiated.18As mentioned above, since it was notspontaneously produced language, it was deemednecessary to minimize the effect of theobserver?s paradox (Labov, 1972) by notexplaining the ultimate aim of the research to theparticipants.
Furthermore, they were told thatthey had to make sure that they were able toconvince their partners on the topics that theywere lying about, so as to have them highlymotivated, like in Hancock et al (2008).For the first two topics (homosexualadoption and bullfighting), we providedinstructions that asked the contributors toimagine that they were taking part in a debate,and had 10-15 minutes available to express theiropinion about the topic.
First, they were asked toprepare a brief speech expressing their trueopinion on the topic.
Next, they were asked toprepare a second brief speech expressing theopposite of their opinion, thus lying about theirtrue beliefs about the topic.
In both cases, theguidelines asked for at least 5 sentences and asmany details as possible.
For the other topic, thecontributors were asked to think about their bestfriend, including facts and anecdotes consideredrelevant for their relationship.
Thus, in this case,they were asked to tell the truth about how theyfelt.
Next, they were asked to think about aperson they could not stand, and describe it as ifs/he were their best friend.
In this second case,they had to lie about their feelings towards thesepeople.
As before, in both cases the instructionsasked for at least 5 detailed sentences.We collected 100 true and 100 falsestatements for each topic, with an average of 80words per statement.
We made a manualverification of the quality of the contributions.With three exceptions, all the other entries werefound to be of good quality.
Each sample wasentered into a separate text file, and misspellingswere corrected.
Each of the 600 text files wasanalyzed using LIWC to create the samples forthe classifier.
It is worth noting that the versionused was LIWC2001, since this is the one whichhas been fully validated for Spanish acrossseveral psycholinguistics studies (Ram?rez-Esparza et al, 2007).
The whole LIWC outputwas taken for the experiment, except for twocategories classified as experimental dimensions(Pennebaker et al, 2001): nonfluencies (e.g.
er,hm, umm) and fillers (e.g.
blah, Imean,youknow), since they are exclusive to spokenlanguage.
The remaining experimentaldimension, swear words, has been included forour purposes in the first dimension, linguisticprocesses, since this is the case for thesubsequent version of this software application.The results from the ML experiment areshown in Table 2.
In the first column, the numberof LIWC dimensions used for each classifier isindicated.
For example, 1_2_3_4 indicates thatall the dimensions have been used in theexperiment, and 1_2 indicates that only thecategories of dimensions 1 and 2 have been usedto train the classifier.
The scores shown in thetable stand for the F-measure, the weightedharmonic mean of precision and recall.Homos.adoptionBullfight.BestfriendTotal1 0.638 0.679 0.763 0.6831_2 0.709 0.655 0.83 0.7361_2_30.698 0.6690.835 0.7261_2_3_40.718 0.660.8450.7341_2_40.728 0.630.830.7281_3 0.64 0.68 0.82 0.7011_3_40.657 0.6430.8150.6981_4 0.631 0.651 0.738 0.6612 0.678 0.624 0.78 0.7022_3 0.724 0.619 0.81 0.7232_3_40.724 0.6090.810.7162_4 0.703 0.59 0.78 0.7063 0.62 0.62 0.695 0.6163_4 0.611 0.595 0.684 0.6544 0.506 0.525 0.639 0.561Table 2: Results from the experimentFindings reveal that the dimension whichperforms overall best irrespective of topic is thesecond one, psychological processes (70.2%).This is in line with Newman et al?s (2003)study, where belief-oriented vocabulary, such asthink, is more frequently encountered in truthfulstatements, since the presence of real facts doesnot require truth-related words for emphasis.
Asregards dominant words in deceptive texts,previous research highlights words related tocertainty, probably due to the speaker?s need toexplicitly use truth-related words as a means toconceal the lies (Bond & Lee, 2005; Mihalcea &Strapparava, 2009).
Furthermore, according toBurgoon et al (2003), other feature associatedwith deception is the high frequency of words19denoting negative emotions.
All these categoriesare included in the second dimension, and theirdiscriminant potential in deception detection isindeed confirmed in our classificationexperiment.The first dimension shows a relatively highperformance (68.3%).
It is natural that it shouldbe so, bearing in mind the considerable potentialof function words, which constitutes a substantialpart of standard linguistic dimensions.
The primeimportance of these grammatical elements hasbeen widely explored, not only in computationallinguistics, but also in psychology.
As Chungand Pennebaker (2007:344) have it, these words?can provide powerful insight into the humanpsyche?.
Variations in their usage has beenassociated to sex, age, mental disorders such asdepression, status, and deception.On the contrary, and as could be expectedfrom previous research (Newman et al, 2003;Fornaciari & Poesio, 2011), the fourth dimensionis the least discriminant on its own.
The reasonmay lie with the weak link of the topics involvedin the questionnaire with the content of thepersonal concerns categories.
However, there isnot much difference with the third one, relativity?just 0.055 points in the total score.As shown in Table 2, when the classifier istrained with certain combinations of dimensions,its performance improves noticeably.
Thisfinding is supported by Vrij?s words: ?a verbalcue uniquely related to deception, akin toPinocchio?s growing nose, does not exist.However, some verbal cues can be viewed asweak diagnostic indicators of deceit?
(2010:103).In this way, it seems clear that a combination oflexical features is more effective than isolatedcategories.
The grouping of the first twodimensions is remarkably successful (73.6%).Nevertheless, the addition of the other twodimensions to this blend is counterproductive,since it makes the score worse instead ofimproving it, probably due to their production ofnoise.
No doubt that the factor loadings of thefour dimensions play a considerable part in here.Overall, considering the total column, it seems asif the fourth LIWC dimension is the one cuttingoff the discrimination power.Furthermore, it is worth noting that theresults from the classification with thesedimensions are strongly dependent on the topicsof each subcorpus.
The topics dealt with in ourexperiment show that the interaction of LIWCdimensions 1_2_4 (72.8%) and 2_3 (72.4%)discriminates better true-false statements relatedto homosexuality adoption; similarly, thedimension selection of LIWC?s 1_2_3 (83.5%)and 1_2_3_4 (84.5%) perform very positivelyregarding the topics related to the best friend.
Onthe opposite scale, we get that true-falsestatements on bullfighting (1_3: 68%) are moredifficult to tell apart by means of LIWCdimensions.
A plausible explanation emergeshere: when speakers refer to their best friend,they are likelier to be emotionally involved in theexperiment; they are not just telling an opinionon a topic which is alien to them, but relatingtheir personal experience with a dear friend andlying about a person they really dislike.
Thispersonal involvement is probably reflected on thelinguistic expression of deception.5 Comparison with a Bag-of-Words modelIn this section we will present the results from aBag-of-Words (BoW) representation to provide abasis for comparison with our methodology.
Inthis model, a text is represented as an unorderedcollection of words, disregarding any linguisticfactor such as grammar, semantics or syntax(Lewis, 1998).
It has been successfully applied toa wide variety of NLP tasks such as documentclassification (Joachims, 1998), spam filtering(Provost, 1999), and opinion mining (Dave et al,2003).
However, its basis is not toosophisticated, hence the average scores obtainedthrough this method in terms of precision andrecall.
Table 3 shows the F-measure scoresobtained with this model.HomosexualadoptionBullfightingBestfriendTotal0.654 0.622 0.715 0.648Table 3: Results from the BoW modelCuriously enough, despite the simplicity ofthe method, in the first two topics the F-measurescores are better than the ones obtained from 6LIWC dimension combinations (see Table 2).When it comes to the third topic, the number isreduced to three combinations.
It is worth notingthat, although the scores in this topic are goodwith this simple model (71.5%), a difference of13 points is observed in the application of ourmethodology to this subcorpus.By means of the comparison, it is confirmedthat the third and the fourth dimensions, both on20their own and combined, perform worse than theBoW model, irrespective of the topic involved.However, as regards the total results, the onlytwo scores which are worse than BoW?s arederived from the application of these twodimensions on their own.
Specifically, there is adifference of 8.8 points between the best totalresult from our experiment (73.6%), obtained bymeans of the combination of the two firstdimensions, and the total result from BoW(64.8%).
This means that, in general terms, theclassification by means of our variables is moresuccessful than with the BoW model.6 Conclusions and further researchIn the present paper we have showed the highperformance of an automatic classifier fordeception detection in Spanish written texts,using LIWC psycholinguistic categories for itstraining.
Through an experiment conducted onthree data sets, we have checked thediscriminatory power of the variables as to theirtruth condition, being the two first dimensions,linguistic and psychological processes, the mostrelevant ones.For future research in this line, we willundertake a contrastive study of the presentresults and the application of the samemethodology to an English corpus, in order toidentify possible structural and lexicaldifferences between the linguistic expression ofdeceit in both languages.AcknowledgementsThis work has been supported by the SpanishGovernment through project SeCloud (TIN2010-18650).
?ngela Almela is supported by Fundaci?nS?neca scholarship 12406/FPI/09.References?ngela Almela.
2011.
Can lexical choice betray aliar?
Paper presented at the I Symposium on theSociology of Words, University of Murcia, Spain.Georg W. Alpers, Andrew Winzelberg, CatherineClassen, Heidi Roberts, Parvati Dev, CherylKoopman, and Barr Taylor.
2005.
Evaluation ofcomputerized text analysis in an Internet breastcancer support group.
Computers in HumanBehavior, 21, 361-376.Jonathan Bishop.
2009.
Enhancing the understandingof genres of web-based communities: The role ofthe ecological cognition framework.
InternationalJournal of Web-Based Communities, 5(1), 4-17.Gary D. Bond and Adrienne Y. Lee.
2005.
Languageof lies in prison: Linguistic classification ofprisoners?
truthful and deceptive natural language.Applied Cognitive Psychology, 19, 313-329.Remco R. Bouckaert, Eibe Frank, Mark A. Hall,Geoffrey Holmes, Bernhard Pfahringer, PeterReutemann, and Ian H. Witten.
2010.
WEKA-experiences with a java open-source project.Journal of Machine Learning Research, 11:2533-2541.Judee K. Burgoon, J. P. Blair, Tiantian Qin, and JayF.
Nunamaker.
2003.
Detecting deception throughlinguistic analysis.
Intelligence and SecurityInformatics, 2665, 91?101.Whitney L. Cade, Blair A. Lehman, and AndrewOlney.
2010.
An exploration of off topicconversation.
In Human Language Technologies:The 2010 Annual Conference of the NorthAmerican Chapter of the Association forComputational Linguistics, 669-672.
Associationfor Computational Linguistics.Cindy Chung and James W. Pennebaker.
2007.
Thepsychological functions of function words.
In K.Fiedler (Ed.
), Social Communication, 343?359.New York: Psychology Press.Malcolm Coulthard.
2004.
Author identification,idiolect, and linguistic uniqueness.
AppliedLinguistics, 25(4):431-447.Kushal Dave, Steve Lawrence, and David M.Pennock.
2003.
Mining the peanut gallery: opinionextraction and semantic classification of productreviews.
In Proceedings of the 12th internationalconference on World Wide Web (WWW '03).
ACM,New York, NY, USA, 519-528.Bella M. DePaulo, Deborah A. Kashy, Susan E.Kirkendol, Melissa M. Wyer, and Jennifer A.Epstein.
1996.
Lying in everyday life.
Journal ofPersonality and Social Psychology, 70: 979-995.Tommaso Fornaciari and Massimo Poesio.
2011.Lexical vs.
Surface Features in DeceptiveLanguage Analysis.
In Wyner, A. and Branting, K.Proceedings of the ICAIL 2011 Workshop ApplyingHuman Language Technology to the Law.P?r A. Granhag and Leif A. Str?mwall.
2004.
Thedetection of deception in forensic contexts.Cambridge, UK: Cambridge University Press.Jeffrey T. Hancock, Lauren E. Curry, SaurabhGoorha, and Michael T. Woodworth.
2004.
Lies inconversation: an examination of deception usingautomated linguistic analysis.
Annual Conference21of the Cognitive Science Society.
Taylor andFrancis Group, Psychology Press, Mahwah, NJ.Jeffrey T. Hancock, Lauren E. Curry, SaurabhGoorha, S. & Michael T. Woodworth.
2008.
Onlying and being lied to: A linguistic analysis ofdeception in computer-mediated communication.Discourse Processes, 45, 1-23.Thorsten Joachims.
1998.
Text categorization withsupport vector machines: learning with manyrelevant features.
ECML-98, 137-142.William Labov.
1972.
Sociolinguistic Patterns.Oxford, UK: Blackwell.Gilly Leshed, Jeffrey T. Hancock, Dan Cosley, PoppyL.
McLeod, and Geri Gay.
2007.
Feedback forguiding reflection on teamwork practices.
InProceedings of the GROUP?07 conference onsupporting group work, 217-220.
New York:Association for Computing Machinery Press.David D. Lewis.
1998.
Naive (Bayes) at Forty: TheIndependence Assumption in InformationRetrieval.
In Proceedings of ECML-98, 10thEuropean Conference on Machine Learning,Springer Verlag, Heidelberg, Germany.Fran?ois Mairesse, Marilyn A. Walker, MatthiasMehl, and Roger K. Moore.
2007.
Using linguisticcues for the automatic recognition of personality inconversation and text.
Journal of ArtificialIntelligence Research, 30(1), 457-500.Rada Mihalcea and Carlo Strapparava.
2009.
The LieDetector: Explorations in the AutomaticRecognition of Deceptive Language.
InProceedings of the Association for ComputationalLinguistics (ACL-IJCNLP 2009), Singapore, 309-312.Matthew L. Newman, James W. Pennebaker, Diane S.Berry, and Jane M. Richards.
2003.
Lying words:Predicting deception from linguistic styles.Personality and Social Psychology Bulletin, 29:665-675.Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T.Hancock.
2011.
Finding deceptive opinion spam byany stretch of the imagination.
In Proceedings ofACL, 309-319.James W. Pennebaker, Martha E. Francis, and RogerJ.
Booth.
2001.
Linguistic Inquiry and Word Count.Erlbaum Publishers, Mahwah, NJ.James W. Pennebaker, Cindy K. Chung, MollyIreland, Amy L. Gonzales, and Roger J. Booth, R.J. 2007.
The development and psychometricproperties of LIWC2007.
LIWC.net, Austin, TX.Isabel Picornell.
2011.
The Rake?s Progress: Mappingdeception in written witness statements.
Paperpresented at the International Association ofForensic Linguists Tenth Biennial Conference,Aston University, Birmingham, United Kingdom.Jefferson Provost.
1999.
Naive-bayes vs. rule-learningin classifcation of email.
Technical Report AI-TR-99-284, University of Texas at Austin, ArtificialIntelligence Lab.Nair?n Ram?rez-Esparza, James W. Pennebaker, andFlorencia A. Garc?a.
2007.
La psicolog?a del uso delas palabras: Un programa de computadora queanaliza textos en espa?ol [The psychology of worduse: A computer program that analyzes texts inSpanish].
Revista Mexicana de Psicolog?a, 24, 85-99.Stephanie S. Rude, Eva-Maria Gortner, and James W.Pennebaker.
2004.
Language use of depressed anddepression-vulnerable college students.
Cognitionand Emotion, 18, 1121-1133.Mohammed Rushdi-Saleh, Maria Teresa Mart?n-Valdivia, Arturo Montejo R?ez, and Luis AlfonsoUre?a L?pez.
2011.
Experiments with SVM toclassify opinions in different domains.
ExpertSystems with Applications, 38(12):14799-14804.Yla R. Tausczik and James W. Pennebaker.
2010.
Thepsychological meaning of words: LIWC andcomputerized text analysis methods.
Journal ofLanguage and Social Psychology, 29, 24-54.Aldert Vrij.
2010.
Detecting lies and deceit: Pitfallsand opportunities.
2nd edition.
John Wiley andSons, Chischester, UK.Aldert Vrij, Samantha Mann, Susanne Kristen, andRonald P. Fisher.
2007.
Cues to deception andability to detect lies as a function of policeinterview styles.
Law and human behavior, 31(5),499-518.22
