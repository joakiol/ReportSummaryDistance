Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 10?18,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsIBM?s Belief Tracker: Results On Dialog State Tracking ChallengeDatasetsRudolf Kadlec, Jind?rich Libovick?y, Jan Macek, and Jan KleindienstIBM Czech RepublicV Parku 4, Prague 4Czech Republic{rudolf kadlec, jindrich libovicky, jmacek2, jankle}@cz.ibm.comAbstractAccurate dialog state tracking is crucialfor the design of an efficient spoken dialogsystem.
Until recently, quantitative com-parison of different state tracking meth-ods was difficult.
However the 2013 Dia-log State Tracking Challenge (DSTC) in-troduced a common dataset and metricsthat allow to evaluate the performance oftrackers on a standardized task.
In this pa-per we present our belief tracker based onthe Hidden Information State (HIS) modelwith an adjusted user model component.Further, we report the results of our trackeron test3 dataset from DSTC.
Our trackeris competitive with trackers submitted toDSTC, even without training it achievesthe best results in L2 metrics and it per-forms between second and third place inaccuracy.
After adjusting the tracker usingthe provided data it outperformed the othersubmissions also in accuracy and yet im-proved in L2.
Additionally we present pre-liminary results on another two datasets,test1 and test2, used in the DSTC.
Strongperformance in L2 metric means that ourtracker produces well calibrated hypothe-ses probabilities.1 IntroductionSpoken dialog systems need to keep a represen-tation of the dialog state and the user goal tofollow an efficient interaction path.
The perfor-mance of state-of-the-art speech recognition sys-tems varies widely with domain and environmentwith word accuracy rates ranging from less than70% to 98%, which often leads to misinterpreta-tion of the user?s intention.
Dialog state trackingmethods need to cope with such error-prone auto-matic speech recognition (ASR) and spoken lan-guage understanding (SLU) outputs.
Traditionaldialog systems use hand-crafted rules to selectfrom the SLU outputs based on their confidencescores.
Recently, several data-driven approachesto dialog state tracking were developed as a partof end-to-end spoken dialog systems.
However,specifics of these systems render comparison ofdialog state tracking methods difficult.The Dialog State Tracking Challenge (DSTC)(Williams et al., 2013) provides a shared testbedwith datasets and tools for evaluation of dialogstate tracking methods.
It abstracts from subsys-tems of end-to-end spoken dialog systems focus-ing only on the dialog state estimation and track-ing.
It does so by providing datasets of ASR andSLU outputs with reference transcriptions togetherwith annotation on the level of dialog acts.In this paper we report initial encouraging re-sults of our generative belief state tracker.
We planto investigate discriminative approaches in the fu-ture.The rest of the paper continues as follows.
Inthe next section we formally introduce the dia-log tracking task together with datasets used inthe DSTC.
Then in Section 3 we discuss relatedwork.
Section 4 describes the belief update equa-tions of our tracker.
After that we introduce thedesign of our whole tracking system, especiallyhow we trained the system in a supervised settingon the train dataset and in an unsupervised settingon the test dataset.
In Section 6 we show resultsof our trackers, compare them to other DSTC par-ticipants, and discuss the results in the context ofdesign choices and task characteristics.2 DSTC Problem Definition, Datasetsand MetricsThe task of the DSTC can be formally definedas computing P(gt|u0:t, a0:t).
That is, for eachtime step t of the dialog compute the proba-bility distribution over the user?s hidden goal ggiven a sequence of SLU hypotheses from the10Dataset System # Annotatedtrain1a A 1013 yestrain1b A 1117 notrain1c A 9502 notrain2 A 643 yestrain3 B 688 yestest1 A 715 for eval.
onlytest2 A 750 for eval.
onlytest3 B 1020 for eval.
onlytest4 C 438 for eval.
onlyTable 1: Datasets description.
The System col-umn shows what dialog system was used to col-lect the dataset.
The # column shows the numberof dialogs in the dataset.
The last column informswhether the ground truth annotation was providedwith the dataset.System Dial.
model SLU scoresA open ??
inf, 0?B fixed ?0, 1?C open ?0, 1?Table 2: Main features of the dialog managersused to collect the datasets.
System A and C useopen dialog structure where the user can respondwith any combination of slots on any machinequestion.
System B uses a fixed dialog structurewhere the user can respond only with the conceptthe system expects.beginning of the dialog up to the time t de-noted as u0:tand a sequence of machine ac-tions a0:t. It is assumed that the goal is fixedthrough the dialog, unless the user is informedthat the requested goal does not exist.
In DSTCthe user?s goal consist of nine slots: route,from.desc, from.neighborhood, from.monument,to.desc, to.neighborhood, to.monument, date,time.The dialog datasets in the DSTC are partitionedinto five training sets and four test sets.
Detailsand differences of the datasets are summarized inTable 1 and 2.
The datasets come from dialog sys-tems deployed by three teams denoted as A, B andC.
All the training datasets were transcribed butonly three of them were annotated on the level ofdialog acts.
The SLU confidence scores from sys-tem B are relatively well calibrated, meaning thatconfidences can be directly interpreted as proba-bilities of observing the SLU hypothesis.
Confi-dence scores from the system A are not well cali-brated as noted by several DSTC participants (Leeand Eskenazi, 2013; Kim et al., 2013).The evaluation protocol is briefly described inSection 6.
Its detailed description can be found in(Williams et al., 2012), its evaluation in (Williamset al., 2013).In 2013, nine teams with 27 trackers partici-pated in the challenge.
The results of the besttrackers will be discussed together with the resultsof our tracker later in Section 6.3 Related WorkThis section shortly reviews current approaches todialog state tracking.
We divide the trackers intotwo broad families of generative and discrimina-tive methods.3.1 Generative MethodsThe HIS model (Young et al., 2010) introduces anapproximative method of solving the belief track-ing as an inference in a dynamic Bayesian networkwith SLU hypotheses and machine actions as ob-served variables and the estimate of the user?s goalas a hidden variable.
The HIS model was im-plemented several times (Williams, 2010; Ga?si?c,2011).
Recent criticism of generative methods forbelief tracking brought more attention to the dis-criminative methods (Williams, 2012b).In the DSTC only few generative system partic-ipated.
Kim et al.
(2013) implemented the HISmodel with additional discriminative rescoring,Wang and Lemon (2013) introduced a very simplemodel based on hand-crafted rules.
Both of themscored between the second and the fourth place inthe challenge.3.2 Discriminative MethodsAs was previously mentioned, the discriminativemethods received more attention recently.The overall winner of the DSTC (Lee and Es-kenazi, 2013) used a maximum entropy model,which they claim to be outperformed by bringingmore structure to the model by using the Condi-tional Random Fields (Lee, 2013).
The same typeof model is used also by Ren et al.
(2013).
Usageof Deep Neural Networks was tested by Hender-son et al.
(2013).
?Zilka et al.
(2013) compare a discriminativemaximum entropy model and a generative methodbased on approximate inference in a Bayesian net-11work, with the discriminative model preformingbetter.4 ModelOur model is an implementation of the HISmodel (Young et al., 2010).
In HIS the belief stateis viewed as a probability distribution over all pos-sible user?s goals.
The belief state is representedby a set of so-called partitions, which are sets ofuser?s goals that are indistinguishable based on ac-tions the system observes.
It means the probabilitymass assigned to a partition spreads to the user?sgoals in the partition proportionally to their?s priorprobabilities.
The belief update is performed intwo steps.Belief refinement ensures that for each user ac-tion on the SLU n-best list and each partition allgoals in the partition are either consistent with theuser action or not.
This step does not change thebelief state, it only enables the actual belief updateto be computed using the update equation (Eq.
1).The partitions are organized in a tree structurefor which it holds that a child and a parent partitionare identical in some slots and complementary inthe remaining ones.
This is ensured by the beliefrefinement procedure.
For each observed user ac-tion and each partition it first checks whether all ofthe hypotheses in the partition are either consistentwith the action or not.
If they are not, it splits thepartition into two partitions with the parent-childrelationship.
The inconsistent hypotheses remainin the parent partition and the consistent ones aremoved to the child.
The belief of the original par-tition is distributed between the new ones in theratio of their priors.To prevent an exponential increase in the num-ber of partitions during the dialog, a partition re-combination strategy can be used that removes theless probable partition and moves their hypothe-ses to different partitions.
We perform partitionrecombination at the end of each turn (Hendersonand Lemon, 2008), during the recombination lowprobability partitions are merged with their parentsexactly as suggested by Williams (2010).For the actual belief update the following stan-dard update equation is used:Pt+1(p) = k ?
Pt(p) ?
?u?uP(u|u) ?
P(u|p, a) (1)where k is a normalization constant, Pt(p) is beliefin partition p after turn t, a is the machine actiontaken in turn t, u is a set of observed user actions,P(u|u) is the score of action u in the SLU n-bestlist u.
In this definition P0(p) is a prior probabil-ity of partition p; the prior might be either uniformor estimated from the training data.
The list u isextended with an unobserved action u?
whose prob-ability is:P(u?|u) = 1??u?u\{u?}P(u|u).
(2)P(u|p, a) in the update equation is the usermodel, i.e.
how likely the user is to take an ac-tion u given that the last machine action was a anduser?s goal is represented by partition p.In our case:P(u|p, a) =?
(p, u, a)?p??
partitions?
(p?, u, a) ?
size(p?
)(3)where size(p) is the number of possible user?sgoals represented by p and ?
(p, u, a) is an indi-cator function that evaluates to 1 when user?s ac-tion u is compatible with the goal represented byp given the last machine?s action was a, otherwise?
evaluates to 0.?
is defined in the following way, for every ob-served action u ?
u \ {u?}:?
(p, u, a) = ??
(p, u, a) (4)where ?
?is a deterministic function that encodesthe meanings of user and machine actions for agiven partition.
The rules expressed by ?
?are forexample:?a : ??
(ps=w, inform(s = v), a) ={1 if v = w0 if v 6= wand??
(ps=w, yes(), conf (s = v)) ={1 if v = w0 if v 6= wwhere ps=wrepresents a partition where slot s hasvalue w, inform(s = v) is user?s action assigningvalue v to the slot s and conf (s = v) is machineaction requiring confirmation that slot s has valuev.For an unobserved action u?
we define ?
as:?
(p, u?, a) =?u?u\{u?}(1?
??
(p, u, a)).
(5)12This definition assumes that user?s unobservedaction u?
uniformly supports each partition not sup-ported by any of the observed user?s actions u.?
(p, u?, a) evaluates to 1 if none of user?s actionssupport given partition, otherwise it evaluates to0.
This can be viewed as an axiom of our system,alternatively we could assume that u?
supports allpartitions, not only those not supported by any ob-served action.The key property of the update equations for-mulated in this way is that the probability of a par-tition representing a hypothesis that a user?s goalwas not mentioned in any of the SLU lists up tothe time t does not outweigh probability of ob-served goals even though the prior probability ofunobserved hypothesis is usually orders of mag-nitude higher than the probability of all observedhypotheses.
However, when two goals are indis-tinguishable based on the SLU input then the ratioof their probabilities will be exactly the ratio oftheir priors.Belief update equations are generic and in-dependent of the internal structure of partitions.When the tracker has to be adapted to a new dia-log domain with the fixed goal the application de-veloper needs to supply only a new definition of?
?and partition splitting mechanism adjusted ac-cording to ?
?.4.1 Differences to the Original HISThe key difference between our HIS implementa-tion and previous HIS systems is in the formula-tion of the user model.
Previous HIS-based sys-tems (Young et al., 2010; Ga?si?c, 2011) factorizethe user model as:Porig(u|p, a) = k ?
P(T (u)|T (a)) ?
M(u, p, a)where P(T (u)|T (a)) is a dialog act type bigrammodel and M is a deterministic item matchingmodel that is similar to our ?.
Based on a descrip-tion of the item matching model given in (Keizeret al., 2008; Young et al., 2010; Ga?si?c, 2011) wededuce that it evaluates to a constant c+instead of1 when the user action is consistent with the parti-tion and to c?instead of 0 otherwise.
It holds that0 ?
c?c+?
1, e.g.
c?= 0.1 and c+= 0.9.In our tracker, we omit the dialog act type modelsince it is not a mandatory component of the usermodel and it can be added later.
However, themost important systematic difference between ourtracker and the original HIS formulation is that in-stead of using a reduced user model, which wouldPar.
PtPorigt+1Pourst+1pa1/31/31/4pb1/31/31/4pc1/31/31/2Table 3: Comparison of the effects of original HISuser model and our modified user model.
Initiallyall partitions are equally likely.
After performingbelief update using Eq.
1 the original model out-puts probabilities in the column Porigt+1, the columnPorigt+1shows results of our user model.be Porig(u|p, a) = ?
(p, u, a) in the original HIS,we use the formulation given in Eq.
3.
The origi-nal HIS does not use a concept of partition?s size(size(p?)
in Eq.
3) that we need for the definitionof our user model.We will illustrate the difference between thesetwo approaches on a minimalistic abstract exam-ple.
Suppose the belief space consists of three par-titions pa, pband pc, each of them having probabil-ity of1/3 and representing one possible user?s goal(i.e.
size(p?)
= 1).
There are two actions on theSLU list: ua,bthat is consistent only with paandpb(i.e.
??
(pa, ua,b, ?)
= 1), and ucthat is con-sistent only with pc.
Both ua,band ucare equallyprobable, P(ua,b|u) = P(uc|u) =1/2.
Accord-ing to one intuition paand pbshould share supportgiven to them by action ua,b, on the other hand pcdoes not share the action ucwith any other par-tition.
Thus after updating the probability usingEq.
1 one would expect Pt+1(pc) to be higher thanPt+1(pa).
Now we can compare the output of ourmodel and the original HIS side by side as shownin Table 3.
The user model as formulated in theoriginal HIS leads to a new belief state where allpartitions are equally probable.
However, accord-ing to our modified user model partition pcis twiceas probable than paor pb.
This is, we argue, closerto human intuition.The update equation for a partition p in this sim-plistic example is:Pt+1(p) = k ?
P(p) ?
(P(ua,b|u) ?
P(ua,b|p, ?
)+P(uc|u) ?
P(uc|p, ?
)).For every partition the original model wouldoutput the same probability:Porigt+1(p) = k113(12?
c++12?
c?
)=1313However our model gives the following equa-tion for both paand pb:Pourt+1(px) = k213(12?11 + 1+12?01)=14where x ?
{a, b}.
The impact of ua,bon pxis di-vided by a factor of 2 since it is shared by two par-titions each representing one possible user goal.For pcwe have:Pourt+1(pc) = k213(12?01 + 1+12?11)=12.This is how values in Table 3 were computed.Another extension of the original HIS is howwe handle the unobserved action.
To our knowl-edge, the original HIS systems (Young et al., 2010;Ga?si?c, 2011) do not deal with probability of unob-served action; Williams (2010) presents a differ-ent way of handling the unobserved action.
Weprovide unified way how to handle unrecognizedmass on the SLU list.
In the original HIS model,partition punobsnot supported by any of the ob-served actions obtains probability by M evalu-ating to c?on each observed action.
In ourmodel, punobsreceives non-zero probability due to?
(punobs, u?, ?)
evaluating to 1 (see Eq.
5).5 Tracker Design and its VariantsThe previous section gave detailed description ofthe update equations of our HIS based tracker.This section presents an overall design of differ-ent implemented tracker variants.
We will discusshow we use the bus route database and how weperform supervised and unsupervised prior adap-tation.5.1 Single Slot Tracking versus JointTracking of Multiple SlotsAn advantage of a HIS-based systems is that theymake it possible to track a joint probability distri-bution over a user?s goal.
This advantage is two-fold.
First, it enables usage of a joint prior, eitherlearned from training data or from the bus sched-ule database.
Second, tracking a joint distributionmakes it possible to use more information fromSLU hypotheses.
We will illustrate this on an ex-ample.
Suppose that SLU is able to extract multi-ple slots from one user?s utterance, in our exampleit might be interpreted as:inform(route=61,to.desc=cmu) 0.5inform(route=60,to.desc=zoo) 0.4And the machine explicitly confirms the route:expl-confirm(route=61)If the user?s response is interpreted as:negate() 0.8affirm() 0.1Then the system tracking only marginal proba-bilities over single slots will correctly considerroute 60 as being more probable but user?s nega-tion will have no effect on marginal distribution ofto.desc.
However, a system tracking the jointdistribution will now correctly rank zoo higherthan cmu.
The disadvantage of tracking joint hy-potheses is that it requires more computational re-sources.
A tracker tracking all slots independentlywith a uniform prior is denoted as IBMindepuniform, atracker tracking joint hypotheses with a uniformprior as IBMjointlyuniform.5.2 Bus Schedule DatabaseAlong with the dialog dataset DSTC organizersprovided a database with bus schedules for routesin Pittsburgh area.
We tested possibility to use re-lation between bus routes and bus stops that can beextracted from the database.
First, we normalizedbus stop names as found in the SLU hypotheses(e.g.
by removing prepositions), in this way wewere able to match 98 percent of bus stops foundin the SLU to stops in the database.An initial analysis of the data revealed thatonly around 55% of route , from.desc, to.deschypotheses annotated by human annotators as aground truth were also found in the database.This means that either callers were often askingfor non-existing combinations or the database wasmismatched.Our tracker utilizing the database tracked jointhypotheses for route , from.desc and to.desc slotsand hypotheses with combinations not found in thedatabase were penalized.
The prior of a joint par-tition pr,f,t, for a route r from destination f to des-tination t, was computed as:P(pr,f,t) = Puniform?DB(r, f, t)Where DB isDB(r , f , t) ={1 if ?r, f, t?
?
database1cotherwisewhere parameter c is a penalty constant for hy-potheses not in the database.
The value of c isestimated by parameter search on the train data.This tracker will be denoted as IBMjointlydb.14Test set 3Schedule 2 Schedule 3jointacc.avg.acc.jointL2avg.L2jointacc.avg.acc.jointL2avg.L2Team 6 (Lee and Eskenazi, 2013) .558 .680 .801 .597 .589 .823 .779 .367Team 8 (unknown authors) .424 .616 .845 .559 .408 .716 .878 .422Team 9 (Kim et al., 2013) .499 .657 .914 .710 .551 .828 .928 .461Team 3 (?Zilka et al., 2013) .464 .645 .831 .669 .528 .794 .734 .3901-best baseline .448 .620 .865 .611 .492 .703 .839 .514IBMjointlyuniform.521 .654 .785 .575 .557 .804 .746 .344IBMindepuniform.521 .654 .786 .576 .558 .806 .746 .343IBMjointlydb.523 .657 .774 .564 .559 .806 .738 .339IBMindeptrain-to-test.563 .680 .694 .513 .609 .828 .644 .285IBMindepunsup.573 .689 .685 .505 .611 .834 .634 .279Table 4: Results on the DSTC test set 3.
Higher accuracy is better, whereas lower L2 score is better.Numbers in bold highlight performance of the best tracker in the selected metric.
The first four rowsshow teams that performed the best in at least one of the selected metrics.
For each team in each metricwe show performance of the best submitted tracker.
This means that numbers in one row do not have to befrom a single tracker.
It is an upper bound of the team?s performance.
The fifth row shows performanceof a 1-best baseline tracker that always picks the SLU hypothesis with the top confidence.
The rest aredifferent variants of our tracker.
Here the bold numbers show where our tracker performed better than thebest tracker submitted to the DSTC.
A light gray highlight of a cell denotes the overall best performancein online setting, a dark gray highlight denotes the best performance while tracking offline.5.3 Priors AdaptationWe tested two variants of adjusting prior probabili-ties of user goals.
We estimated prior probabilitiesas a mixture of the uniform probability and empir-ical distribution estimated on the training data.In the first experiment the empirical probabili-ties were estimated using the annotation that wasavailable in the training data.
We tracked theslots independently because the empirical jointdistribution would be too sparse to generalize onthe test data.
We used one prior distribution toguide the selection of route hypotheses Prrouteand one shared distribution for possible destina-tion names Prdesc.
This distribution is trained ondata from both from and to destinations thus gain-ing a more robust estimate compared to using twoseparate distributions for from.desc and to.desc.This tracker will be denoted as IBMindeptrain-to-test.In the second experiment we used the test datawithout the ground truth labels to estimate the em-pirical prior.
We first ran the tracker with the uni-form prior on the testing set and we used the out-put hypotheses as a basis for the empirical distri-bution.
The prior of a hypothesis is proportionalto a sum of all tracker output scores for the hy-pothesis.
This scheme is called unsupervised prioradaptation by Lee and Eskenazi (2013).
Note thatthe prior was computed on the test dataset.
Thusthis technique is not directly applicable to a realis-tic setting where the belief tracker has to produce abelief for each dialog from the test set the first timeit sees it.
This tracker will be called IBMindepunsup.6 EvaluationWe evaluated all our tracker variants on the DSTCtest3 dataset using the protocol designed for thechallenge participants.
We also present initial re-sults of the basic IBMindepuniformand IBMjointlyuniformtrack-ers for test1 and test2 datasets.
Several quanti-ties were measured in three different schedules,which defines, which moments of the dialog theevaluation is performed.
Here we report resultsfor schedule 2 and 3.
Schedule 2 takes into ac-count all turns when the relevant concept appearedon user?s SLU list or was mentioned by the dialogsystem.
Schedule 3 evaluates belief at the end ofthe dialog, i.e.
at the moment when the queriedinformation is presented to the user.We report accuracy, which is the ratio of dialogswhere the user goal was correctly estimated, and15the L2 score, which is the Euclidean distance ofthe vector of the resulting belief from a vector hav-ing 1 for the correct hypothesis and 0s for the oth-ers.
For both of these the average values over alltracked slot is reported as well as the value for thejoint hypotheses.
The accuracy informs us how of-ten the correct query to the database will be made.The L2 score tells us how well-calibrated the re-sults are, which can be important for disambigua-tion and for statistical policy optimization.6.1 MethodWe used one thousand partitions as the limit forthe number of tracked hypotheses.
For eachtracker ran on the test set 3 we used only the topfive SLU hypotheses.All parameters for mixing the empirical priorprobability with uniform distribution in trackersIBMindeptrain-to-testand IBMindepunsupwere estimated us-ing 3-fold cross validation scheme on the trainingdata.
The best parameter setting on the trainingdata was then used in evaluation on the test set.Test set 1jointacc.avg.acc.jointL2avg.L2Team 6 .364 .862 .989 .278Team 9 .225 .789 1.154 .354Team 2 .206 .777 1.234 .4091-best baseline .138 .626 1.220 .530IBMjointlyuniform.332 .813 .992 .282IBMindepuniform.331 .804 1.010 .304Table 5: Preliminary results for schedule 3 on theDSTC test set 1 of our two trackers compared tothree overall well performing teams.
For teams 6and 9 see Table 4, team 2 is (Wang and Lemon,2013).
The legend of the table is the same as inTable 4.Even though we concentrated mainly on test-ing the tracker on dataset 3, we also ran it on thedatasets 1 and 2.
For the datasets 1 and 2 we usedthe single best SLU hypothesis from the live sys-tem.
Such hypothesis was assigned 99% probabil-ity and the remaining 1% was left for the unob-served action.
For the datasets 1 and 2 a post hoccomputed SLU hypotheses are available in addi-tion to the live data.
In our experiments, using thepost hoc computed SLU hypotheses with normal-ized confidence scores yielded worse results forour tracking systems.Test set 2jointacc.avg.acc.jointL2avg.L2Team 6 .526 .854 .885 .311Team 9 .268 .748 1.098 .450Team 2 .320 .764 1.148 .4701-best baseline .141 .487 1.185 .648IBMjointlyuniform.431 .789 .846 .316IBMindepuniform.413 .778 .875 .332Table 6: Preliminary results for schedule 3 on theDSTC test set 2.
For teams see Tables 4 and 5.The legend of the table is the same as in Table 4.6.2 ResultsResults of our trackers on the DSTC dataset 3 aresummarized in Table 4.
Preliminary results ofthe trackers on datasets 1 and 2 whose confidencescores are not that well calibrated are shown in Ta-bles 5 and 6.
The running time of the trackerswas on average below 0.05 seconds per turn1.
Theonly exception is IBMjointlydbthat executes plenty ofdatabase queries.
Although we did not focus onthe computational performance optimization mostof the trackers are suitable for on-line use.6.3 DiscussionQuantitative Comparison to DSTC Trackers.First let us discuss results of our trackers on test 3(Table 4).
Here both basic variants of the trackerIBMindepuniformand IBMjointlyuniformperform almost identi-cally.
This is because test 3 uses fixed dialog flowas discussed in Section 2, minor differences in per-formance between IBMindepuniformand IBMjointlyuniformarecaused only by numerical issues.
The trackers arearound the third place in accuracy.
In joint L2 met-rics they outperform the best tracker in DSTC sub-mitted by Team 6 (Lee and Eskenazi, 2013).Tracker utilizing database IBMjointlydbdoes notshow any significant improvement over the sametracker without database-based prior IBMjointlyuniform.We hypothesize that this is because of the fact thatpeople frequently asked for non-existing combina-tions of routes and stops, which were penalized fornot being in the database, as discussed in Sec.
5.2.Next follow the results of tracker IBMindeptrain-to-testthat learns priors for single slots on trainingdataset and uses them while inferring user?s goalon the test set.
In test set 3 priors enhanced1On one core of Intel Xeon CPU E3-1230 V2, 3.30GHz,with memory limitation of 1GB.16tracker?s performance in all metrics and the trackeroutperformed all DSTC trackers.Interesting results were achieved by IBMindepunsupthat performed even better than the IBMindeptrain-to-test.It uses a prior trained on the test set by running thetracker with a uniform prior.
The tracker was runfor three iterations each time using output of theprevious iteration as a new prior.After running the experiments with the top 5SLU hypotheses, we performed an experiment thatinvestigated influence of n-best list length on thetracker?s accuracy.
We evaluated five system vari-ants that received 1, 2, 3, 4 and 5 best SLU hy-potheses.
The overall trend was that initially per-formance increased as more SLU hypotheses wereprovided however then performance started de-creasing.
The 3-best variant achieved about 1.5%increase in joint accuracy compared to the 1-best.However, when using more than 3 best hypothe-ses, the performance slightly decreased.
For in-stance, IBMindepuniformusing 1-best hypothesis per-formed comparable to the 5-best configuration.Similar behavior of generative systems assumingobservation independence has already been ob-served in different domains (Vail et al., 2007).Based on these results we deduce two conclu-sions.
First, strong performance of IBMindepuniform1-best system compared to the 1-best baseline sys-tem suggests that the main added value of ourtracker in this domain is in the aggregation of ob-servations from multiple time steps, not in track-ing multiple hypotheses from one turn.
Sec-ond, we attribute the effect of decreasing accu-racy to the correlation of ASR errors from con-secutive dialog turns.
As noted by Williams(2012b), correlated ASR errors violate the as-sumption of observation independence that is as-sumed by HIS.
Extending the user model withan auto-regressive component, that is with depen-dence on observations from the previous time step(i.e.
P(ut|ut?1, p, a)), might help to tackle thisproblem in generative models (Wellekens, 1987).To summarize the results on test set 3, evenwithout any prior adaptation on the data ourtracker is competitive with the best submissionsto DSTC.
After incorporating prior knowledge itoutperforms all submitted trackers.On test set 1 and test set 2 (see Tables 5 and 6)the trackers perform second in accuracy.
In L2metrics the trackers are competitive with the besttracker in DSTC submitted by Team 6 and theyoutperform it in one out of four cases.
It is inter-esting that our basic strategy that ignores live SLUscores performed that strong.However, on test 1 and test 2, which make itpossible to input multiple slots in one user utter-ance, IBMjointlyuniformoutperforms IBMindepuniform, both inaccuracy and L2.
We hypothesize that this is be-cause of effect of tracking joint distributions de-scribed in Section 5.1.Qualitative Comparison to DSTC Trackers.Compared to another HIS-based system (Kim etal., 2013) participating in the DSTC, our imple-mentation does not suffer from the problem of as-signing high probability to the hypothesis that theuser goal was not observed so far.
This might bedue to our modified user model.
Therefore our im-plementation does not need a final transformationof belief scores as reported by Kim et al.
(2013).Additionally, our implementation does notexhibit the forgetting behavior as experiencedby?Zilka et al.
(2013).
Forgetting is undesirablegiven the validity of assumption that the user?sgoal remains fixed in the whole dialog, which isthe case of DSTC bus schedule domains.7 ConclusionAlthough the use of generative trackers was re-cently criticized by Williams (2012a), our re-sults show that at least in some metrics (e.g.
L2metrics on dataset 3) a generative tracker canoutperform the best state-of-the-art discriminativetracker (Lee and Eskenazi, 2013).
Even thoughwe agree that the discriminative approach might bemore promising, it seems that in general there areconditions where generative models learn fasterthan discriminative models (Ng and Jordan, 2001).Thus it might be beneficial to use a generativetracker for a newly deployed dialog system withonly a few training dialogs available and switch toa discriminative model once enough training datafrom an already running system is collected.
En-semble trackers incorporating both generative anddiscriminative models as used by Lee and Eske-nazi (2013) might also be an interesting directionfor future research.AcknowledgmentWe would like to thank Ji?r??
Havelka for his valu-able comments on a draft of this paper.
This workwas partially funded by the GetHomeSafe project(EU 7thFramework STREP project No.
288667).17ReferencesMilica Ga?si?c.
2011.
Statistical Dialogue Modelling.PhD thesis, University of Cambridge.James Henderson and Oliver Lemon.
2008.
MixtureModel POMDPs for Efficient Handling of Uncer-tainty in Dialogue Management.
In Proc ACL-HLT,pages 73?76.Matthew Henderson, Blaise Thomson, and SteveYoung.
2013.
Deep neural network approach forthe dialog state tracking challenge.
In Proceedingsof the SIGDIAL 2013 Conference, pages 467?471,Metz, France, August.
Association for Computa-tional Linguistics.Simon Keizer, Milica Ga?si?c, Franc?ois Mairesse, BlaiseThomson, Kai Yu, and Steve Young.
2008.
Mod-elling user behaviour in the his-pomdp dialoguemanager.
In Spoken Language Technology Work-shop, 2008.
SLT 2008.
IEEE, pages 121?124.
IEEE.Daejoong Kim, Jaedeug Choi Choi, Kee-Eung Kim,Jungsu Lee, and Jinho Sohn.
2013.
Engineering sta-tistical dialog state trackers: A case study on dstc.In Proceedings of the SIGDIAL 2013 Conference,pages 462?466, Metz, France, August.
Associationfor Computational Linguistics.Sungjin Lee and Maxine Eskenazi.
2013.
Recipe forbuilding robust spoken dialog state trackers: Dialogstate tracking challenge system description.
In Pro-ceedings of the SIGDIAL 2013 Conference, pages414?422, Metz, France, August.
Association forComputational Linguistics.Sungjin Lee.
2013.
Structured Discriminative ModelFor Dialog State Tracking.
In Proceedings of theSIGDIAL 2013 Conference, pages 442?451, Metz,France, August.
Association for Computational Lin-guistics.Andrew Ng and Michael Jordan.
2001.
On discrim-inative vs. generative classifiers: A comparison oflogistic regression and naive bayes.
Neural Infor-mation Processing Systems, pages 841?848.Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan.2013.
Dialog state tracking using conditional ran-dom fields.
In Proceedings of the SIGDIAL 2013Conference, pages 457?461, Metz, France, August.Association for Computational Linguistics.Douglas L Vail, Manuela M Veloso, and John D Laf-ferty.
2007.
Conditional Random Fields for Activ-ity Recognition Categories and Subject Descriptors.In Proceedings of the 6th International Joint Confer-ence on Autonomous Agents and Multiagent systems(AAMAS 2007).Zhuoran Wang and Oliver Lemon.
2013.
A sim-ple and generic belief tracking mechanism for thedialog state tracking challenge: On the believabil-ity of observed information.
In Proceedings of theSIGDIAL 2013 Conference, pages 423?432, Metz,France, August.
Association for Computational Lin-guistics.Christian Wellekens.
1987.
Explicit time correlationin hidden markov models for speech recognition.
InAcoustics, Speech, and Signal Processing, IEEE In-ternational Conference on ICASSP?87., volume 12,pages 384?386.
IEEE.Jason D Williams, Antoine Raux, Deepak Ramachan-dran, and Alan Black.
2012.
Dialog state trackingchallenge handbook.Jason Williams, Antoine Raux, Deepak Ramachan-dran, and Alan Black.
2013.
The Dialog StateTracking Challenge.
In Proceedings of the SIGDIAL2013 Conference, pages 404?413, Metz, France,August.
Association for Computational Linguistics.Jason D. Williams.
2010.
Incremental partition re-combination for efficient tracking of multiple dialogstates.
In ICASSP, pages 5382?5385.Jason D. Williams.
2012a.
Challenges and Opportuni-ties for State Tracking in Statistical Spoken DialogSystems: Results From Two Public Deployments.IEEE Journal of Selected Topics in Signal Process-ing, 6(8):959?970, December.Jason D Williams.
2012b.
A critical analysis oftwo statistical spoken dialog systems in public use.In Spoken Language Technology Workshop (SLT),2012 IEEE, pages 55?60.
IEEE.Steve Young, Milica Ga?si?c, Simon Keizer, Franc?oisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2010.
The Hidden Information State model:A practical framework for POMDP-based spokendialogue management.
Computer Speech & Lan-guage, 24(2):150?174, April.Luk?a?s?Zilka, David Marek, Mat?ej Korvas, and FilipJur?c???cek.
2013.
Comparison of bayesian discrim-inative and generative models for dialogue statetracking.
In Proceedings of the SIGDIAL 2013 Con-ference, pages 452?456, Metz, France, August.
As-sociation for Computational Linguistics.18
