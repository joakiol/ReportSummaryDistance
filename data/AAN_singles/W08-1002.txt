Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 9?15,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsParse selection with a German HPSG grammarBerthold Crysmann?Institut fu?r Kommunikationswissenschaften, Universita?t Bonn &Computerlinguistik, Universita?t des SaarlandesPoppelsdorfer Allee 47D-55113 Bonncrysmann@ifk.uni-bonn.deAbstractWe report on some recent parse selection ex-periments carried out with GG, a large-scaleHPSG grammar for German.
Using a manu-ally disambiguated treebank derived from theVerbmobil corpus, we achieve over 81% exactmatch accuracy compared to a 21.4% randombaseline, corresponding to an error reductionrate of 3.8.1 IntroductionThe literature on HPSG parsing of German has al-most exclusively been concerned with issues of the-oretical adequacy and parsing efficiency.
In contrastto LFG parsing of German, or even to HPSG workon English or Japanese, very little effort has beenspent on the question of how the intended, or, forthat matter a likely parse, can be extracted from theHPSG parse forest of some German sentence.
Thisissue becomes all the more pressing, as the gram-mars gain in coverage, inevitably increasing theirambiguity.
In this paper, I shall present preliminaryresults on probabilistic parse selection for a large-scale HPSG of German, building on technology de-veloped in the Lingo Redwoods project (Oepen etal., 2002).
?The research reported here has been carried out at the Ger-man Research Center for Artificial Intelligence (DFKI GmbH)as part of the projects COLLATE, QALL-ME, and Checkpoint,funded by the German Federal Ministery for education and Sci-ence (BMBF), the European Union, and the State of Berlin, re-spectively.
I am also greatly indepted to my colleagues BerndKiefer and Gu?nter Neumann, as well as to Stephan Oepen andDan Flickinger for support and comments relating to the workpresented here.The paper is organised as follows: in section 2, Ishall give a brief overview of the grammar.
Section 3discusses the treebanking effort we have undertaken(3.1), followed by a presentation of the parse selec-tion results we achieve using probabilistic modelstrained on different feature sets (3.2).2 The grammarThe grammar used in the experiments reported herehas originally been developed, at DFKI, in the con-text of the Verbmobil project (Mu?ller and Kasper,2000).
Developed initially for the PAGE devel-opment and processing platform (Uszkoreit et al,1994), the grammar has subsequently been ported toLKB (Copestake, 2001) and Pet (Callmeier, 2000)by Stefan Mu?ller.
Since 2002, the grammar hasbeen extended and modified by Berthold Crysmann(Crysmann, 2003; Crysmann, 2005; Crysmann,2007).The grammar, codename GG, is a large scaleHPSG grammar for German, freely available un-der an open-source license: it consists of roughly4000 types, out of which 290 are parametrised lexi-cal types, used in the definition of about 35,000 lex-ical entries.
The lexicon is further extended by 44lexical rules and about 300 inflectional rules.
Onthe syntactic side, the grammar has about 80 phrasestructure rules.The grammar covers all major aspects of Germanclausal and phrasal syntax, including free word or-der in the clausal domain, long-distance dependen-cies, complex predicates, passives, and extraposition(Crysmann, 2005).
Furthermore, the grammar cov-ers different coordination constructions, including9the so-called SGF coordination.
Furthermore, thegrammar is fully reversible, i.e.
it can be used forparsing, as well as generation.The phrase structure rules of the grammar areeither unary or binary branching phrase structureschemata, permitting free interspersal of modifiersbetween complements in the clausal domain.
Therelatively free order of complements is captured bymeans of lexical rules which permute the elementson the COMPS valence list.
As a result, the verb?scomplements can be saturated in any order.The treatment of verb placement is somewhat spe-cial: in sentences without a right sentence bracket, aleft branching structure is assumed, permitting effi-cient processing.
Whenever the right bracket is oc-cupied by a non-finite verb cluster, the finite verb inthe left bracket is related to the clause finla clusterby means of simulated head movement, followingthe proposal by (Kiss and Wesche, 1991), inter alia.As a consequence, the grammar provides both head-initial and head-final versions of the Head-Adjunct,Head-Complement and Head-Subject schemata.As output, the grammar delivers detailed seman-tic representations in the form of Minimal RecursionSemantics (Copestake et al, 2005).
These represen-tations have been successfully used in the contextof automated email response or question answering(Frank et al, 2006).
Most recently, the grammar hasbeen used for automatic correction of grammar andstyle errors, combining robust parsing with genera-tion.3 Parse Selection3.1 Treebank constructionThe treebank used in the experiments reported herehas been derived from the German subset of theVerbmobil (Wahlster, 2000) corpus.
In essence, weremoved any duplicates on the string level from thecorpus, in order to reduce the amount of subsequentmanual annotation.
Many of the duplicates thus re-moved were short interjection, such as ja ?yes?, nein?no?, or hm ?euhm?, which do not give rise to anyinteresting structural ambiguities.
As a side effect,removal of these duplicates also enhanced the qual-ity of the resulting treebank.The construction of the disambiguated treebankfor German followed the procedure suggested forEnglish by (Oepen et al, 2002): the corpus was firstanalysed with the German HPSG GG, storing thederivation trees of all successful parses.
In a sub-sequent annotation step, we manually selected thebest parse, if any, from the parse forest, using theRedwoods annotation tool cited above.After removal of duplicates, syntactic coverageof the corpus figured at 69.3 percent, giving a to-tal of 11894 out of 16905 sentences.
The vast ma-jority of sentences in the corpus are between 1 and15 words in length (14757): as a result, averagesentence length of parsed utterances figures at 7.64,compared to 8.72 for the entire corpus.
Although av-erage sentence length is comparatively low, the tree-bank still contains items up to sentence length 47.The 11894 successfully parsed sentences havesubsequently been disambiguated with the Red-woods treebanking tool, which is built on top ofLKB (Copestake, 2001) and [incr tsdb()] (Oepen,2002).
Figure 2 shows the annotation of an exam-ple sentence from the treebank.During annotation, 10356 sentences were suc-cessfully disambiguated to a single reading (87.1%).Another 276 sentences were also disambiguated, yetcontain some unresolved ambiguity (2.3%), while95 sentences were left unannotated (0.8%).
The re-maining 1167 items (=9.8%) were rejected, sincethe parse forest did not contain the desired reading.Since not all test items in the tree bank were am-biguous, we were left, after manual disambiguation,with 8230 suitable test items, i.e.
test items wherethe number of readings assigned by the parser ex-ceeds the number of readings judged as acceptable.Average ambiguity of fully disambiguated sen-tences in the tree bank is around 12.7 trees per sen-tence.
This corresponds to a baseline of 21.4% forrandom parse selection, owing to the unequal distri-bution of low and high ambiguity sentences.3.2 Parse selection3.2.1 Feature selectionThe parse selection experiments reported on herehave been performed using the LOGON branch ofthe LKB and [incr tsdb()] systems.
In particular, weused Rob Malouf?s tadm maximum entropy toolkitfor training and evaluation of our log-linear parseselection models.10212.5i?length in [30 .. 35| 020 0.0031.63 0.0211.1i?length in [10 .. 15|111i?length in [0 .. 5|210030.0032.0012.7266111.6333.0226.32833.1624.885.042.833330.5012.98311.83953.6340.29.803.8170665.449.0241811.43113.2117.27 63.5800.07016.710.0076.6i?length in [25 .. 30|0.056026.700.005.9377.50.08926Total7.0026.581189410.1508.39.07422717.27.05282.726.4111679.3311.4325.6755.598.01034907.320.00i?length in [45 .. 50|0.02 47.00 800.0i?length in [20 .. 25|01720.0021.321.540.024173.0211.336946.0028.521.721636.037203.4011.51990.0044.221.520.0 0 0.002.60.0154 1.44i?length in [35 .. 40|5.86636.783.67136.2545.21.7i?length in [15 .. 20|25i?length in [5 .. 10|65020.5037.60622716.5892.0327.06.8470.1216.318520.0036.0045516.591023.57.2481.310.2447564116.356.74trees?trees?trees?t?active = 0 unannotateditems#words?t?active > 1words?words?trees?t?active = 1items#Aggregate items#words?items#all resultsitems#trees?words?
(generated by [incr tsdb()] at 24?mar?08 (22:28))Figure 1: The GG Verbmobil treebankFigure 2: An example from the German treebank, featuring the Redwoods annotation tool11All experiments were carried out as a ten-foldcross-evaluation with 10 iterations, using 10 differ-ent sets of 7407 annotated sentences for training and10 disjoint sets of 823 test items for testing.The discriminative models we evaluate here weretrained on different subsets of features, all of whichwere extracted from the rule backbone of the deriva-tions stored in the treebank.
As node labels, we usedthe names of the HPSG rules licensing a phrasalnode, as well as the types of lexical entries (preter-minals).
On the basis of these derivation trees,we selected several features for training our disam-biguation models: local trees of depth 1, several lev-els of grandparenting, i.e.
inclusion of grandpar-ent node (GP 2), great-grandparent node (GP 3) andgreat-great-grandparent node (GP 4), partial trees ofdepth 1 (+AE).
Grandparenting features involve lo-cal trees of depth 1 plus a sequence of grandparentnodes, i.e.
the local tree is contextualised in relationto the dominating tree.
Information about a grand-parent?s other daughters, however, is not taken intoconsideration.
Partial trees, by contrast, are includedas a kind of back-off model.In addition to tree-configurational features, we ex-perimented with n-gram models, using n-gram sizesbetween 2 and 4.
These models were further varied,according to whether or not a back-off model wasincluded.Apart from these linguistic features, we also var-ied two parameters of the maximum entropy learner,viz.
variance and relative tolerance.
The relative tol-erance parameter restricts convergence of the model,whereas variance defines a prior in order to reduceover-fitting.
In the results reported here, we usedoptimal setting for each individual set of linguisticparameters, although, in most cases, these optimalvalues figured at 10?4 for variance and 10?6 for rel-ative tolerance.3.2.2 ResultsThe results of our parse selection experiments forGerman are summarised in tables 1 and 2, as well asfigures 3 and 4.As our major result, we can report an exact matchaccuracy for parse selection of 81.72%, using great-grandparenting (GP 3) and 4-grams.
This result cor-responds to an error reduction by a factor of 3.8, ascompared to the 21.4% random baseline.
?AE +AEGP 0 77.96 78.14GP 2 81.27 80.87GP 3 81.34 80.4GP 4 81.49 80.78Table 1: PCFG model with GrandparentingFigure 3: PCFG model with GrandparentingApart from the overall result in terms of achiev-able parse selection accuracy, a comparison of theindividual results is also highly informative.As illustrated by figure 3, models including anylevel of grandparenting clearly outperform the basicmodel without grandparenting (GP0).
Furthermore,relative gains with increasing levels of grandparent-ing are quite low, compared to the more than 3% in-crease in accuracy between the GP0 and GP2 mod-els.Another interesting observation regarding the datain table 1 and figure 3 is that the inclusion of par-tial constituents into the model (+AE) only benefitsthe most basic model.
Once the more sophisticatedgrandparenting models are used, partial constituentworsen rather than improve the overall performance.Another observation we made regarding the rela-tive usefulness of the features we have employed re-lates to n-gram models: again, we find that n-grammodels clearly improve on the basic model withoutgrandparenting (by about 1 percentage point), al-beit to a lesser degree than grandparenting itself (see12N0 N2 N3 N4GP 0 77.96 78.79 78.92 78.74GP 2 81.27 81.5 81.65 81.55GP 3 81.34 81.44 81.51 81.72GP 4 81.49 81.62 81.69 81.67Table 2: PCFG model with Grandparenting & N-gramsFigure 4: PCFG model with Grandparenting & N-Grams(-AE)above).
With grandparenting added, however, therelative gains of the n-gram models greatly dimin-ishes.
A possible explanation for this finding is thatreference to grandparenting indirectly makes avail-able information about the preceding and linear con-text, obviating the need for direct encoding in termsof n-grams.
Again, the best combined model (hier-archy + n-grams) outperforms the best purely hierar-chical model by a mere 0.23 percentage points.
Theresults obtained here for German thus replicate theresults established earlier for English, namely thatthe inclusion of n-gram information only improvesoverall parse selection to a less significant extent.A probably slightly unsurprising result relatesto the use of back-off models: we found that n-gram models with backing-off yielded better resultsthroughout our test field than the correspoding n-gram models that did not use this feature.
Differ-ences, however, were not dramatic, ranging roughlybetween 0.07 and 0.3 percentage points.The results obtained here for German comparequite well to the results previously achieved for theERG, a broad coverage HPSG for English: usinga similar treebank1 (Toutanova et al, 2002) report81.80 exact match accuracy for a log-linear modelwith local trees plus ancestor information, the modelwhich is closest to the models we have evaluatedhere.
The baseline in their experiments is 25.81.
Thebest model they obtain includes semantic dependen-cies, as well, yielding 82.65 exact match accuracy.Probably the most advanced approach to parse se-lection for German is (Forst, 2007): using a broadcoverage LFG grammar, he reports an f-score of83% of correctly assigned dependency triples for areference corpus of manually annotated newspapertext.
However, it is unclear how these figures relateto the exact match accuracy used here.Relevant, in principle, to our discussion here, arealso the results obtained with treebank grammars forGerman: (Dubey and Keller, 2003) have trained aPCFG on the Negra corpus (Skut et al, 1998), re-porting labelled precision and recall between 70 and75%.
(Ku?bler et al, 2006) essentially confirm theseresults for the Negra treebank, but argue instead thatprobabilistic parsing for German can reach far bet-ter results (around 89%), once a different treebankis chosen, e.g.
Tu?ba-D/Z.
However, it is quite dif-ficult to interpret the significance of these two tree-bank parsers for our purposes here: not only is theevaluation metric an entirely different one, but so arethe parsing task and the corpus.In an less recent paper, however, (Ruland, 2000)reports on probabilistic parsing of Verbmobil datausing a probabilistic LR-parser.
The parser has beentrained on a set of 19,750 manually annotated sen-tences.
Evaluation of the parser was then performedon a hold-out set of 1000 sentences.
In addition tolabelled precision and recall, (Ruland, 2000) alsoreport exact match, which figures at 46.3%.
Us-ing symbolic postprocessing, exact match improvesto as much as 53.8%.
Table 3.2.2 summarizes Ru-land?s results, permitting a comparison between ex-act match and PARSEVAL measures.
Although thetest sets are certainly not fully comparable,2 these1In fact, the Redwoods treebank used by (Toutanova et al,2002) was also derived from Verbmobil data.
The size of thetreebank, however, is somewhat smaller, containing a total of5312 sentences.2The overall size of the treebank suggests that we are ac-13GermanNot parsed 4.3%Exact match 53.8%LP 90.8%LR (all) 84.9%LR (in coverage) 91.6%Table 3: Performance of Ruland?s probabilistic parser(with postprocessing) on Verbmobil datafigures at least gives us an indication about how tojudge the the performance of the HPSG parse selec-tion models presented here: multiplying our 69.3%coverage with 81.72% exact match accuracy stillgives us an overall exact match accuracy of 56.6%for the entire corpus.However, comparing our German treebank toa structurally similar English treebank, we haveshown that highly comparable parse selection fig-ures can be obtained for the two languages with es-sentially the same type of probabilistic model.4 ConclusionWe have presented a treebanking effort for a large-scale German HPSG grammar, built with the Red-woods treebank technology (Oepen et al, 2002), anddiscussed some preliminary parse selection resultsthat are comparable in performance to the resultspreviously achieved for the English Resource Gram-mar (lingoredwoods:2002tlt).
Using a treebank of8230 disambiguated sentences, we trained discrim-inative log-linear models that achieved a maximalexact match accuracy of 81.69%, against a randombaseline of 21.4%.
We further investigated the im-pact of different levels of grandparenting and n-grams, and found that inclusion of the grandpar-ent node into the model improved the quality sig-nificantly, reference, however, to any higher nodesonly lead to very mild improvements.
For n-gramswe could only observe significant gains for modelswithout any grandparenting.
We therefore hope totest these findings against treebanks with a highersyntactic complexity, in the near future, in order totually dealing with the same set of primary data.
However, inour HPSG treebank string-identical test items had been removedprior to annotation and training.
As a result, our treebank con-tains less redundancy than the original Verbmobil test suites.establish whether these observations are indeed ro-bust.ReferencesUlrich Callmeier.
2000.
PET ?
a platform for experi-mentation with efficient HPSG processing techniques.Journal of Natural Language Engineering, 6(1):99?108.Ann Copestake, Dan Flickinger, Carl Pollard, and IvanSag.
2005.
Minimal recursion semantics: an intro-duction.
Research on Language and Computation,3(4):281?332.Ann Copestake.
2001.
Implementing Typed FeatureStructure Grammars.
CSLI Publications, Stanford.Berthold Crysmann.
2003.
On the efficient implemen-tation of German verb placement in HPSG.
In Pro-ceedings of RANLP 2003, pages 112?116, Borovets,Bulgaria.Berthold Crysmann.
2005.
Relative clause extrapositionin German: An efficient and portable implementation.Research on Language and Computation, 3(1):61?82.Berthold Crysmann.
2007.
Local ambiguity packingand discontinuity in german.
In T. Baldwin, M. Dras,J.
Hockenmaier, T. H. King, and G. van Noord, editors,Proceedings of the ACL 2007 Workshop on Deep Lin-guistic Processing, pages 144?151, Prague, Czech Re-public, June.
Association for Computational Linguis-tics.Amit Dubey and Frank Keller.
2003.
Probabilistic pars-ing for german using sister-head dependencies.
InACL, pages 96?103.Martin Forst.
2007.
Filling statistics with linguistics?
property design for the disambiguation of germanlfg parses.
In ACL 2007 Workshop on Deep Linguis-tic Processing, pages 17?24, Prague, Czech Republic,June.
Association for Computational Linguistics.Anette Frank, Hans-Ulrich Krieger, Feiyu Xu, HansUszkoreit, Berthold Crysmann, Brigitte Jo?rg, and Ul-rich Scha?fer.
2006.
Querying structured knowledgesources.
Journal of Applied Logic.Tibor Kiss and Birgit Wesche.
1991.
Verb orderand head movement.
In Otthein Herzog and Claus-Rolf Rollinger, editors, Text Understanding in LILOG,number 546 in Lecture Notes in Artificial Intelligence,pages 216?240.
Springer-Verlag, Berlin.Sandra Ku?bler, Erhard W. Hinrichs, and Wolfgang Maier.2006.
Is it really that difficult to parse german?
InProceedings of EMNLP 2006, Sydney, Australia.Stefan Mu?ller and Walter Kasper.
2000.
HPSG analy-sis of German.
In Wolfgang Wahlster, editor, Verb-mobil: Foundations of Speech-to-Speech Translation,pages 238?253.
Springer, Berlin.14Stephan Oepen, E. Callahan, Daniel Flickinger, Christo-pher Manning, and Kristina Toutanova.
2002.
LinGORedwoods: A rich and dynamic treebank for HPSG.In Beyond PARSEVAL.
Workshop at the Third Interna-tional Conference on Language Resources and Evalu-ation, LREC 2002, Las Palmas, Spain.Stephan Oepen.
2002.
Competence and PerformanceProfiling for Constraint-based Grammars: A NewMethodology, Toolkit, and Applications.
Ph.D. thesis,Saarland University.Tobias Ruland.
2000.
Probabilistic LR-parsing withsymbolic postprocessing.
In Wolfgang Wahlster, ed-itor, Verbmobil: Foundations of Speech-to-SpeechTranslation, pages 147?162.
Springer, Berlin.Wojciech Skut, Thorsten Brants, and Hans Uszkoreit.1998.
A linguistically interpreted corpus of Ger-man newspaper text.
In Proceedings of the ESSLLIWorkshop on Recent Advances in Corpus Annotation,Saarbru?cken, Germany.Kristina Toutanova, Christopher D. Manning, Stuart M.Shieber, Dan Flickinger, and Stephan Oepen.
2002.Parse disambiguation for a rich HPSG grammar.
InProceedings of the First Workshop on Treebanks andLinguistic Theories (TLT2002), pages 253?263, So-zopol, Bulgaria.Hans Uszkoreit, Rolf Backofen, Stephan Busemann,Abdel Kader Diagne, Elizabeth Hinkelman, Wal-ter Kasper, Bernd Kiefer, Hans-Ulrich Krieger,Klaus Netter, Gu?nter Neumann, Stephan Oepen, andStephen P. Spackman.
1994.
Disco - an hpsg-based nlp system and its application for appoint-ment scheduling.
In Proceedings of the 15th In-ternational Conference on Computational Linguistics(COLING?94), August 5-9, volume 1, pages 436?440,Kyoto, Japan.Wolfgang Wahlster, editor.
2000.
Verbmobil: Foun-dations of Speech-to-Speech Translation.
Springer,Berlin.15
