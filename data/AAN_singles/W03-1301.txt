Gene Name Extraction Using FlyBase ResourcesAlex Morganamorgan@mitre.orgLynette Hirschmanlynette@mitre.orgThe MITRE Corporation202 Burlington RoadBedford, MA 01730-1420Alexander Yehasy@mitre.orgMarc Colosimomcolosim@brandeis.eduAbstractMachine-learning based entity extraction re-quires a large corpus of annotated training toachieve acceptable results.
However, the costof expert annotation of relevant data, coupledwith issues of inter-annotator variability,makes it expensive and time-consuming tocreate the necessary corpora.
We report hereon a simple method for the automatic creationof large quantities of imperfect training datafor a biological entity (gene or protein) extrac-tion system.
We used resources available inthe FlyBase model organism database; theseresources include a curated lists of genes andthe articles from which the entries weredrawn, together a synonym lexicon.
We ap-plied simple pattern matching to identify genenames in the associated abstracts and filteredthese entities using the list of curated entriesfor the article.
This process created a data setthat could be used to train a simple HiddenMarkov Model (HMM) entity tagger.
The re-sults from the HMM tagger were comparableto those reported by other groups (F-measureof 0.75).
This method has the advantage of be-ing rapidly transferable to new domains thathave similar existing resources.1Introduction: Biological DatabasesThere is currently an information explosion inbiomedical research.
The growth of literature isroughly exponential, as can be seen in Figure 1which shows the number of literature references inFlyBase1 organized by date of publication over ahundred year span.2  This growth of literaturemakes it daunting for researchers to keep track ofthe information, even in very small subfields ofbiology.1 FlyBase is a database that focuses on research in the geneticsand molecular biology of the fruit fly (Drosophila melangas-Figure 1: FlyBase References, 1900-2000Increasingly, biological databases serve to collectand organize published experimental results.
Awide range of biological databases exist, includingmodel organism databases (e.g., for mouse3 andyeast4) as well as various protein databases (e.g.,Protein Information Resource5 (PIR) or SWISS-tor), a model organism for genetics research:http://www.flybase.org.PROT6 and   interaction databases such as theBiomolecular Interaction Network Database7(BIND).
These databases are created by a processof curation, which is done by Ph.D. biologists whoread the published literature to cull experimentalfindings and relations.
These facts are organizedinto a set of structured fields of a database and2 Of course most of these early references in FlyBase are notin electronic form.
The FlyBase database has been in existencesince 1993.3 http://www.informatics.jax.org/4 http://genome-www.stanford.edu/Saccharomyces/5 http://pir.georgetown.edu/pirwww/pirhome3.shtml6 http://us.expasy.org/sprot/7 http://www.bind.ca/linked to the source of information (the journalarticle).
As a result, curation is a time-consumingand expensive process; database curators are in-creasingly eager to adopt text mining and naturallanguage processing techniques to make curationfaster and more consistent.
As a result, there hasbeen growing interest in the application of entityextraction and text classification techniques to theproblem of biological database curation [Hirsch-man02].2Entity Extraction MethodsThere are two approaches to entity extraction.
Thefirst requires manual or heuristic creation of rulesto identify the names mentioned in text; the seconduses machine learning to create the rules that drivethe entity tagging.
Heuristic systems require expertdevelopers to create the rules, and these rules mustbe manually changed to handle new domains.
Ma-chine-learning based systems are dependent onlarge quantities of tagged data, consisting of bothpositive and negative examples.8  Figure 2 showsresults from the IdentiFinder system [Bikel99] il-lustrating that performance increases roughly withthe log of quantity of training data.
Given the ex-pense of manual annotation of large quantities ofdata, the challenge for the machine learning ap-proach is to find ways of creating sufficient quanti-ties of training data cheaply.Overall, hand-crafted systems seem to outper-form learning-based systems for biology.
How-ever, it is clear that the quantities of training havebeen small, relative to the results reported for en-tity extraction in e.g., newswire [Hirschman03].There are several published sets of performanceresults for automatic named biological entity ex-traction systems.
The system of Collier et al [Col-lier00] uses a hidden Markov model to achieve anF-measure9 of 0.73 when trained on a corpus of29,940 words of text from 100 MEDLINE ab-stracts.
Contrast this with Figure 2, which reportsresults using over 600,000 words of training data,and an F-measure of 0.95 for English newswireentity extraction (and 0.91 for Spanish).8 For negative examples, the "closed world" assumption gen-erally is taken to apply: if an entity is not tagged, it is assumedto be a negative example.Krauthammer et al [Krauthammer00] have taken asomewhat different approach which encodes char-acters as 4-tuples of  DNA bases; they then useBLAST together with a lexicon of gene names tosearch for 'gene name homologies'.
They report anF-measure of 0.75 without the use of a large set ofrules or annotated training data.The PASTA system [Gaizauskas03] uses a combi-nation of heuristic and machine-learned rules toachieve a higher F-measure over a larger numberof classes: F-measure of 0.83 for the task of identi-fying 12 classes of entities involved in the descrip-tion of roles of residues in protein molecules.Because they used heuristic rules, they were ableto get these results with a relatively small trainingcorpus of 52 MEDLINE abstracts (roughly 12,000words).Figure 2: Performance of BBN's IdentiFinder named entityrecognition system relative to the amount of training data, from[Bikel99]These results suggest that machine learning meth-ods will not be able to compete with heuristic rulesuntil there is a way to generate large quantities ofannotated training data.
Biology has the advantagethat there are rich resources available, such as lexi-cons, ontologies and hand-curated databases.What is missing is a way to convert these intotraining corpora for text mining and natural lan-guage processing.
Craven and Kumlien [Cra-ven99] developed an innovative approach that usedfields in a biological database to locate abstractswhich mention physiological localization of pro-teins.
Then via a simple pattern matching algo-9Recall) (PrecisionRecall)Precision2(+?
?=FManning D, Schutze H. Foundations of Statistical NaturalLanguage Processing, 2002: p 269.rithm, they identified those sentences where therelation was mentioned and matched these withentries in the Yeast Protein Database (YPD).
Inthis way, they were able to automatically create anannotated gold standard, consisting of sentencespaired with the curated relations derived fromthose sentences.
They then used these for trainingand testing a machine-learning based system.
Thisapproach inspired our interest in using existingresources to create an annotated corpus automati-cally.3r3.1FlyBase: Organization and ResourcesWe focused on FlyBase because we had access toFlyBase resources from our work in the creation ofthe KDD 2002 Cup Challenge Task 1 [Yeh03].Through this work, we had become familiar withthe multi-stage process of curation.
An early taskin the curation pipeline is to determine, for a givenarticle, whether there are experimental results thatneed to be added to the database.
This was the taskused as the basis for the KDD text data mining"challenge evaluation".
A later task in the pipelinecreates a list of the Drosophila genes discussed ineach curated article.
This is the task we focus on inthis paper.An example of a FlyBase entry can be seen in Fig-ure 3 which shows part of the record for the geneToll.
Under Molecular Function and BiologicalProcess we see that the gene is responsible for en-coding a transmembrane receptor protein involvedin antimicrobial humoral response (part of theinnate immune system of the fly).
We see furthethat  ?Tl?
and ?CG5490?
are synonymous for Toll(top of the entry next to Symbol), and the linkSynonyms leads to a long synonym list which in-cludes: ?Fs(1)Tl?, ?dToll?, ?CT17414?, ?Toll-1?,?Fs(3)Tl?, ?mat(3)9?, ?mel(3)10?, and ?mel(3)9?.Many of these facts about Toll are linked to a par-ticular literature reference in the database.
For ex-ample, following the link for Transcripts will leadto a page with links to the abstract of a paper byTauszig et al [Tauszig00] which reports on ex-periments which measured the lengths of RNAtranscribed from the Toll gene.For FlyBase, Drosophila genes are the key bio-logical entities; each entity (e.g., gene) is associ-ated with a unique identifier for the underlyingphysical entity.
If there were a one-to-one relation-ship between gene name and unique identifier, thegene identification task would be straightforward.However, both polysemy and synonymy occur fre-quently in the naming of biological entities, andthe gene names of Drosophila are considered to beparticularly problematic because of creative nam-ing conventions10.
For example, ?18 wheeler?,?batman?, and ?rutabaga?
are all Drosophila genenames.
A single entity (as represented by a uniqueidentifier) may have a number of names like Tollor even ATP?, which has 38 synonyms listed inFlyBase.Figure 3: FlyBase entry for TollResourcesWe obtained a copy of part the FlyBase database,11including the lists of genes discussed in each paperexamined by the curators.
Using the BioPython12modules, we were able to obtain MEDLINE ab-stracts for 15,144 for these papers.
We decided to10 At the other end of the spectrum is the yeast nomenclaturewhich is strictly controlled ?
see <http://genome-www.stanford.edu/Saccharomyces/gene_guidelines.shtml> fornomenclature conventions.11 Special thanks to William Gelbart, David Emmert, BeverlyMatthews, Leyla Bayraktaroglu, and Don Gilbert.12 http://www.biopython.org/set aside the same articles used in the KDD CupChallenge [Yeh03] for evaluation purposes.
Thisleft a training set of 14,033 abstracts, consisting ofa total of 2,664,324 lexemes identified by ourtokenizer.44.1It was only with some reluctance that we decidedto focus on journal abstracts.
From our earlierwork, we recognized that the majority of the in-formation entered into FlyBase is missing from theabstracts and can be found only in the full text ofthe article [Hirschman03].
However, due to copy-right restrictions, there is a paucity of freely avail-able full text for journal articles.
What articles areavailable in electronic form vary in their format-ting, which can cause considerable difficulty inautomatic processing.
MEDLINE abstracts have auniform format and are readily available.
Manyother experiments have been performed onMEDLINE abstracts for similar reasons.We also created a synonym lexicon from FlyBase.We found 35,971 genes with associated ?genesymbols?
(e.g.
Tl is the gene symbol for Toll) and48,434 synonyms; therefore, each gene has an av-erage of 2.3 alternate naming forms, including thegene symbol.
The lexicon also allowed us to asso-ciate each gene with one a unique FlyBase geneidentifier, providing "term normalization.
"ExperimentsFor purposes of evaluation, our task was the identi-fication of mentions of Drosophila genes in thetext of abstracts.
We also included mentions ofprotein or transcript where the associated geneshared the same name.
This occurs when, for ex-ample, the gene name appears as a pre-nominalmodifier, as in "the zygotic Toll protein".
We didnot include mentions of protein complexes becausethese are created out of multiple polypeptidechains with multiple genes (e.g., hemoglobin).
Wealso did not include families of proteins or genes(e.g.
lectin), particular alleles of a gene, geneswhich are not part of the natural Drosophila ge-nome such as reporter genes (e.g.
LacZ), and thenames of genes from other organisms (e.g.
sonichedgehog, the mammalian gene homologous to theDrosophila hedgehog gene).13BackgroundOur initial experiment [Hirschman03] had lookedat creating a gene name finder by simple patternmatching, using the extensive FlyBase list of genesand their synonyms and identifying each mentionwhich occurred in the lexicon with the appropriateunique identifier.
This yielded spectacularly poorresults: recall14 on the full papers was quite high(84%), but precision was 2%!
For abstracts, therecall was predictably lower (31%) and precisionremained low at 7%.
Our analysis showed thatpolysemy (described in Section 5) and the largeintersection of gene names with common Englishwords caused most of the performance problems.In the initial run, where a name was ambiguous,we recorded all gene identifiers; this raised recallbut lowered precision.
After removing all thenames which were ambiguous for a gene, precisionclimbed to 5% for full papers and 17% in abstracts,with a corresponding drop in recall (77% for fullpapers, 28% for abstracts).
We also tried a fewsimple filters, such as ignoring all terms threecharacters or less in length, but the best precisionwe could achieve was 29% in abstracts, certainlyunacceptable.We were, however, encouraged by the relativelyhigh recall in full papers.
Analysis showed thatmany of the missing names were contained only infigures or tables that had not been downloaded.While these were counted as recall errors whencompared to the FlyBase curation, there were, infact, no mentions of these genes in the text that hadbeen downloaded for this experiment.
Similarly,for abstracts, while the recall appeared low com-pared to the complete set of genes discussed in thefull paper, these genes were simply not mentionedin the abstract.
So from an information extraction13 There are no curated lists of complexes or families in Fly-Base, so we did not train a tagger for these tasks.
In our man-ual curation, we did create separate tags for complexes andfamilies, since we believe that these will be important for fu-ture tasks.14 Note that these measures of recall and precision are basedon the list of unique Drosophila genes curated in a paper.
Thisis quite different from recall and precision measuring the men-tions of gene names in a paper.
We used the measure ofunique genes in a paper because this allowed us to take advan-tage of the existing FlyBase expert curated resources.point of view, the simple pattern matchingachieved a very high recall for genes mentioned inthe text being processed.4.24.3Generating Noisy Training DataThe initial experiment demonstrated that exactmatch using rich lexical resources was not usefulon its own.
However, we realized that we coulduse the lists of curated genes from FlyBase to con-strain the possible matches within an abstract ?
thatis, to "license" the tagging of only those genesknown to occur in the curated full article.
Ourhope was that this filtered data would provide largequantities of cheap but imperfect or noisy trainingdata.Our next experiment focused on generating thislarge but noisy training corpus.
We used our inter-nal tokenizer, punctoker, originally designed foruse with newswire data.
There were some errors intokenization, since biological terms have a verydifferent morphology from newswire?
see[Cohen02] for an interesting discussion of tokeni-zation issues.
Among the problems in tokenizationwere uses of "-" instead of white space, or "/" toseparate recombinant genes.
However, an informalexamination of errors did not show tokenizationerrors to be a significant contributor to the overallperformance of the entity extraction system.To perform the pattern matching, we created a suf-fix tree of all the synonyms known to FlyBase forthose genes.
This was important, since many bio-logical entity names are multi-word terms.
Wethen used longest-extent pattern matching to findcandidate mentions in the abstract of the paper.The system tagged only terms licensed by the as-sociated list of genes for the abstract, assigning theappropriate unique gene identifier.
Even with theFlyBase filtering, this method resulted in someerrors.
For example, an examination of an abstractdescribing the gene to revealed the unsurprisingresult that all the uses of the word "to" did not referto the gene.
However, the aim was to create dataof sufficient quantity to lessen the effects of thisnoise.EvaluationIn order to measure performance, we created asmall doubly annotated test corpus.
We selected asample of 86 abstracts and had two annotatorsmark these abstracts for gene name mentions aspreviously described.
Mentions of families andforeign genes were also identified with differenttags during this process, but not evaluated.
Onecurator was a professional researcher in biologywith experience as a model organism genome da-tabase curator (Colosimo).
This set of annotationswas taken as the "gold-standard".
The second an-notator was the system developer with no particu-lar annotation experience (Morgan).
With twoannotators, we were able to measure inter-annotator agreement (F-measure of 0.87).
We alsomeasured the quality of the automatically created 4.4training data by using the lexical pattern matchingprocedure with filtering to generate annotations for86 abstracts in the test set.
The F-measure was0.83, when compared against the gold standard,shown in Table 1 below.F-measure Precision RecallTraining DataQuality0.83 0.78 0.88Inter-annotatorAgreement0.87 0.83 0.91TaWetha smethe[PatraiandwaFig15 Phttpble 1: Training data quality and inter-annotator agreementHMM Tagging With Noisy Training Datanow had a large quantity of noisy training datat we could use to train a statistical tagger.
Thithodology is illustrated in Figure 4.
We choseHMM-based trainable entity tagger phrag15lmer99] to extract the names in text.
Wened phrag on different amounts of training datameasured performance.
Our evaluation metrics the standard metric used in named entityAbstractsfromPubMedLexiconFlyBaseLarge Quantityof NoisyTraining DataPlain TextGenes TaggedGene1 Gene2Other1 Other2Start EndText automatically tagged usingFlyBase references and a lexicon isused to train up a tagger capable oftagging gene names in new text,including gene names never observedbefore.TrainableTaggerure 4: Schematic of  Methodologyhrag is available for download at://www.openchannelfoundation.org/projects/QandaTraining Data F-measure Precision Recall531522 0.62 0.73 0.54529760 0.64 0.75 0.561342039 0.72 0.80 0.652664324 0.73 0.79 0.67No Orthographic CorrectionTable 2: Performance as a function of training dataTraining Data F-measure Precision Recall531522 0.65 0.76 0.56529760 0.66 0.74 0.59522825 0.67 0.76 0.591322285 0.72 0.77 0.671342039 0.75 0.80 0.702664324 0.75 0.78 0.71Orthographic CorrectionTable 3: Improved performance with orthographical correctionfor Greek letters and case folding for term matching in trainingdata-f--",p-mn.6entity identification F-measure of 73%.
We thenmade a simple modification of the algorithm tocorrect for variations in orthography due to capi-talization and representation of Greek letters:  wesimply expanded the search for letters such as "?
"to include "Delta" and "delta".
By expanding thematching of terms using the orthographical andcase variants, performance of phrag improvedslightly, shown in Table 3, improving our bestperformance to an F-measure of 75%.5Figure 5 shows these results in a graphical form.Two things are apparent from this graph.
Based onthe results shown in Figure 2, we might expect theperformance to be linear with the logarithm of theamount of training data, and in this case there is arough fit with a correlation coefficient of .88.
Theother result which stands out is that there is con-siderable variation in the performance when train-ed on different training sets of the same size.
Webelieve that this is due to the very limited amountof testing data.Error AnalysisWe have identified three types of polysemy inDrosophila gene names in FlyBase.
In some cases,one name (e.g., ?Clock?)
can refer to two distinctgenes: period or Clock.
The term with the mostpolysemy is ?P450?
which is a family of genes andis listed as a synonym for 20 different genes inFlyBase.
In addition, the same term is often usedinterchangeably to refer to the gene, RNA tran-script, or the protein.
[Hazivassloglou01] presentsinteresting results that demonstrate that expertsonly agree 78% of the time on whether a particularmention refers to a gene or a protein.16  The mostproblematic type of polysemy occurs becausemany Drosophila gene names are also regular Eng-0.620.640.660.680.70.720.740.760.78100000 1000000 10000000Training Data (# of Lexemes)F-measureFigure 5: Performance as a function of the amount of train-ing data.
The line is a least-squares logarithmic fit with anR2 value of .8814.lish words such as "white", ?cycle?, and "bizarre".There are some particularly troublesome examplesthat occur because of frequent use of short forms(abbreviations) of gene names, e.g., "we", "a","not?, and even ?and?
each occur as gene names.These short forms are often abbreviations for thefull gene name.
For example, the gene symbol ofthe gene takeout is "to", and the symbol for the16 The entity tagging task for FlyBase was defined to extractgene-or-protein names; however, in cases where the articletalks only about the protein and not about the gene, the proteinname may not appear on the list of curated genes for the arti-cle, leading to apparent false positives in tagging.
evaluation, requiring the matching of a name's extent and tag (except that for our experiment, wewere only concerned with one tag, Drosophilagene).
Extent matching meant exact matching ogene name boundaries at the level of tokens:   Exactly matching boundaries were considered a hit.Inexact answers are considered a miss.
For example, a multiword gene name such as "fas receptorwhich has been tagged for "fas" but not for "recetor" would constitute a miss (recall error) and afalse alarm (precision error).Table 2 shows the performance of the basic systeas a function of the amount of training data.
Aswith Figure 2, we see there is a diminishing returas the amount of training data is increased.
At 2million words or training data, phrag achieved angene wee is "we".
It may be that more sophisti-cated handling of abbreviations can address someof these issues.An error analysis looking at the results of our sta-tistical tagger demonstrated some unusual behav-ior.
Because our gene name tagger phrag uses afirst order Markov model, it relies on local contextand occasionally makes errors such as not taggingall of the occurrences of the term "rutabaga" in anabstract about rutabaga as gene names.
This cer-tainly opens up the opportunity for some sort ofpost processing step to resolve these problems.The fact that phrag uses this local context cansometimes be a strength, enabling it to identifygene names it has never seen.
We estimated theability of the system to identify new terms as genenames by substituting strings unknown to phrag inplace of all the occurrences of gene names in theevaluation data.
The performance of the system atcorrectly identifying terms it had never observedgave a precision of 68%, a recall of 22% and an F-measure of 33%.
This result is relatively encour-aging, compared with the 3.3% precision and 4.4%recall for novel gene names reported by Krau-thammer.
Recognizing novel names is importantbecause the nomenclature of biological entities isconstantly changing and entity tagging systemsshould to be able to rapidly adapt and recognizenew terms.6 Conclusion and Future DirectionsWe have demonstrated that we can automaticallyproduce large quantities of relatively high qualitytraining data; these data were good enough to trainan HMM-based tagger to identify gene mentionswith an F-measure of 75% (precision of 78% andrecall of 71%), evaluated on our small develop-ment test set of 86 abstracts.
This compares fa-vorably with other reported results as described inSection 2, and as discussed below, we believe thatwe can improve upon these results in various ways.These results are still considerably below the re-sults from [Gaizauskas03] and may be too low tobe useful as a building block for further automatedprocessing, such as relation extraction.
However,in the absence of any shared benchmark evaluationsets, cross-system performance cannot be evalu-ated since the task definition and evaluation cor-pora differ from system to system.We plan to take this work in several directions.First, we believe that we can improve the quality ofthe underlying automatically generated data, andwith this, the quality of the entity tagging.
Thereare several things that could be improved.A morphological analyzer trained for biologicaltext would eliminate some of the tokenization er-rors and perhaps capture some of the underlyingregularities, such as addition of Greek letters ornumbers (with or without preceding hyphen) tospecify sub-types within a gene family.
There canalso be considerable semantic content in genenames and their formatting.
For example, manyDrosophila genes are differentiated from the genesof other organisms by prepending a "d" or "D",such as "dToll".
Gene names can also be explicitdescriptions of their chromosomal location or evenfunction (e.g.
Dopamine receptor).The problem of matching abbreviations has beentackled by a number of researchers [e.g.
Puste-jovsky02 and Liu03].
As was mentioned above, itseems that ambiguity for "short forms" of genenames could be partially resolved by detecting lo-cal definitions for abbreviations.
It should also bepossible to apply part of speech tagging and corpusstatistics to avoid mis-tagging of common words,such as ?to?
or ?and?.In the longer term, this methodology provides anopportunity to go beyond gene name tagging forDrosophila.
It can be extended to other domainsthat have comparable resources (e.g.
other modelorganism genome databases, other biological enti-ties), and entity tagging itself provides the founda-tion for more complex tasks, such as relationextraction (e.g.
using the BIND database) or attrib-ute extraction (e.g.
using FlyBase to identify at-tributes such as RNA transcript length, associatedwith protein coding genes).Second, the existence of a synonym lexicon withunique identifiers provides data for term normali-zation, a task of potentially greater utility to biolo-gists than the tagging of every mention in anarticle.
There are currently few corpora with anno-tated term normalization; using the methodologyoutlined here makes it possible to produce largequantities of normalized data.
The identificationand characterization of abbreviations and othertransformations would be particularly important innormalization.By exploiting the rich set of biological resourcesthat already exist, it should be possible to generatemany kinds of corpora useful for training high-quality information extraction and text miningcomponents.ReferencesBikel D, Schwartz R, Weischedel R. An Algorithm thatLearns What's in a Name.
Machine Learning, SpecialIssue on Natural Language Learning 34 (1999):211-31.Cohen KB, Dolbey A, Hunter L. ?Contrast and variabil-ity in gene names.?
Proceedings of the workshop onnatural language processing in the biomedical domain,Association for Computational Linguistics, 2002Collier N, Nobata C, Tsujii J.
?Extracting the Names ofGenes and Gene Products with a Hidden MarkovModel.?
Proceedings of COLING '2000 (2000): 201-07.Craven M, Kumlien J.
?Constructing Biological Knowl-edge Bases by Extracting Information from TextSources.?
Proceedings of the Seventh InternationalConference on Intelligent Systems for Molecular Biol-ogy 1999: 77-86.Gaizauskas R, Demetriou G, Artymiuk PJ, Willett P.?Protein Structures and Information Extraction fromBiological Texts: The PASTA System.?
Bioinformatics.19  (2003): 135-43.Hatzivassiloglou V, Duboue P, Rzhetsky A.
?Disam-biguating Proteins, Genes, and RNA in Text: A Ma-chine Learning Approach.?
Bioinformatics 2001: 97-106.Hirschman L, Park J, Tsujii J, Wong L, Wu C. "Accom-plishments and Challenges in Literature Data Miningfor Biology," Bioinformatics 17 (2002):1553-61.Hirschman L, Morgan A, Yeh A.
?Rutabaga by AnyOther Name: Extracting Biological Names."
Accepted,Journal of Biomedical Informatics, Spring 2003.Krauthammer M, Rzhetsky A, Morosov P, Friedman C.?Using BLAST for Identifying Gene and Protein Namesin Journal Articles.?
Gene 259 (2000): 245-52.Liu H, Friedman C.  ?Mining Terminological Knowl-edge in Large Biomedical Corpora.?
Proceedings of thePacific Symposium on Biocomputing.
2003.Palmer D, Burger J, and Ostendorf M. "InformationExtraction from Broadcast News Speech Data."
Pro-ceedings of the DARPA Broadcast News and Under-standing Workshop, 1999.Pustejovsky J, Casta?o J, Saur?
R, Rumshisky A, ZhangJ, Luo W. ?Medstract: Creating Large-scale InformationServers for Biomedical Libraries.?
Proceedings of theACL 2002 Workshop on Natural Language Processingin the Biomedical Domain.
2002.Tauszig et al ?Toll-related receptors and the control ofantimicrobial peptide expression in Drosophila.?
Pro-ceedings of the  National Academy of  Sciences 97(2000): 10520-5.Yeh A., Hirschman L,  Morgan A.
"Evaluation of TextData Mining for Database Curation: Lessons Learnedfrom the KDD Challenge Cup."
Accepted, IntelligentSystems in Molecular Biology, Brisbane, June 2003.
