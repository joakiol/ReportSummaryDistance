Combining Functionality and Ob\]ec~Orientednessfor Natural Language ProcessingToyoak l  N ish ida  I and  Shu j i  Dosh i taDepar tment  o f  In fo rmat ion  Sc ience ,  Kyoto  Un ivers i tySakyo-ku ,  Kyoto  606 ,  JAPANAbstractThis paper proposes a method for organizing linguisticknowledge in both systematic and flexible fashion.
Weintroduce a purely applicative language (PAL) as anintermediate representation and an object-orientedcomputation mechanism for its interpretation.
PAL enablesthe establishment of a principled and well-constrained methodof interaction among lexicon-oriented linguistic modules.
Theobject-oriented computation mechanism provides a flexiblemeans of abstracting modules and sharing common knowledge.1.
Introduct ionThe goal of this paper is to elaborate a domain-independentway of organizing linguistic knowledge, as a step forwards acognitive processor consisting of two components: a linguisticcomponent and a memory component.In this paper we assume the existence of the lattercomponent meeting the requirements described in \[Schank 82\].Thus the memory component attempts to understand theinput in terms of its empirical knowledge, predict whathappens next, and reorganize its knowledge based on newobservations.
Additionally, we assume that the memorycomponent can judge whether a given observation is plausibleor not, by consulting its empirical knowledge.The role of the linguistic component, on the other hand, isto supply "stimulus" to the memory component.
Morespecifically, the linguistic component attempts to determinethe propositional content, to supply missing constituents forelliptical expressions, to resolve references, to identify thefocus, to infer the intention of the speaker, etc.
In short, therole of the \[iguistic omponent is to "translate" the input intoan internal representation.For example, the output of the linguistic component for aninput:When did you go to New York?is something like the following2:There is an event e specified by a set of predicates:isa(e)=going A past(e) A agent(e)=the_hearer Adestination(e)=New_York.
The speaker is asking thehearer for the time when an event e took place.
The hearerpresupposes that the event e actually took place at sometime in the past.1Currently visiting Department of Computer Science, Yale University,New Haven, Connecticut 06520, USA.If the presupposition contradicts what the memory componentknows, then the memory component will recognize the input asa loaded question \[Kaplan 82\].
As a result, the memorycomponent may change its content or execute a plan toinforming the user that the input is inconsistent with what itknows.The primary concern of this paper is with the linguisticcomponent.
The approach we take in this paper is to combinethe notion of eompositionality a and an object-orientedcomputational mechanism to explore a principled and flexibleway of organizing linguistic knowledge.2 .
In termed ia te  Representat ion  andComputat iona l  Dev ice  fo rIn terpretat ion2.1 PAL  (Pure ly  Applicative Language)Effective use of intermediate r presentations is useful.
Wepropose the use of a language which we call PAL (PurelyApplicative Language).In PAL, new composite expressions are constructed onlywith a binary form of function application.
Thus, if z and I/are well-formed formulas of PAL, so is a form z(y).Expressions of PAL are related to expressions of naturallanguage as follows:Generally, when a phrase consists of its immediatedescendants, ay z and y, a PAL expression for the phrase isone of the following forms:<z>(  <V>)  or <p>(  <z>)where ~a> stands for a PAL expression for a phrase ~*.Which expression is the case depends on which phrase modifieswhich.
If a phrase z modifies V then the PAL expression for ztakes the functor position, i.e., the form is ~z~(~y~) .Simple examples are:big apple =* big~apple) ; adjectives modify .annevery big ~ very(big) ; adverbs modify adjectivesvery big apple ~ (very(big)Xapple) ; reeuesive composition2As illustrated in this example, we assume a predicate notation a~ anoutput of the linguistic omponent.
But this choice is only for descriptivepurposes and is not significant.awe prefer the term *functionality" to "eompositionality", reflecting aprocedural view rather than a purely mathematicaJ view.218How about other cases?
In principle, this work is based onMontague's observations \[Montague 74\].
Thus we take theposition that noun phrases modify (are functions of, to bemore precise) verb phrases.
But unlike Montague grammar wedo not use iambda expressions to bind case elements.
Insteadwe use special functors standing for case markers.
Forexample,he runs ~ (*subject(he)Xruns)he eats it ~ (*subject(he)X(*object(it)Xeats))Another example, involving a determiner, is illustrated below:a big apple ~ a(big(apple)) ; determiners modlf~l nounsSometimes we assume "null" words or items correspondingto morphemes, such as, role indicators, nominalizer, null NP,etc.apple which he eats~ (which((*subject(he))((*object(*null))(eats))))(apple); restrictive relative clauses modif~ nouns,; rdativizers modify sentences tomake adjectivesIn the discussion above, the notion of modify is crucial.What do we mean when we say z modifies y?
In the case ofMontague grammar, this question is answered based on apredetermined set theoretical model.
For example, a noun isinterpreted as a set of entities; the noun "penguin", forinstance, is interpreted as a set of all penguins.
An adjective,on the other hand, is interpreted as a function from sets ofentities to sets of entities; an adjective "small" is interpretedas a selector function which takes such a set of entities(interpretation of each noun) and picks up from it a set of"small" entities.
Note that this is a simplified discussion;intension is neglected.
Note also that different conception maylead to a different definition of the relation modifp, which willin turn lead to intermediate representations with differentfunction-argument relationships.After all, the choice of semantic representation is relative tothe underlying model and how it is interpreted.
A good choiceof a semantic representation - interpretation pair leads to aless complicated system and makes it easier to realize.The next section discusses a computational device forinterpreting PAL expressions.2 .2  Ob jec t -Or iented  DomainThe notion of object-orientedness is widely used in computerscience.
We employ the notion in LOOPS \[Bobrow 81\].
Thegeneral idea is as follows:We have a number of objects.
Objects can be viewed asboth data and procedures.
They are data in the sense thatthey have a place (called a local variable) to storeinformation.
At the same time, they are procedures in thatthey can manipulate data.
An object can only update localvariables belonging to itself.
When data belongs to anotherobject, a message must be sent to request he update.
Amessage consista of a label and its value.
In order to send amessage, the agent has to know the name of the receiver.There is no other means for manipulating data.
Objectscan be classified into classes and instances.
A class definesa procedure \[called a method) for handling incomingmessages of its instances.
A class inherits methods of itssuperclasses.Z.
Interpretat ion of  PAL Expressions inObject-Oriented DomainA class is defined for each constant of PAL.
A class objectfor a lexical item contains linguistic knowledge in a proceduralform.
In other words, a class contains information as to how acorresponding lexical item is mapped into memory structures.A PAL expression is interpreted by evaluating the formwhich results from replacing each constant of a given PALexpression by an instance of an object whose class name is thesame as the label of the constant.
The evaluation is done byrepeating the following cycle:?
an object in argument position sends to an objectin functor position a message whose label is"argument ~ and whose value is the object itself.?
a corresponding method is invoked and an object isreturned as a result of application; usually oneobject causes another object to modify its contentand the result is a modified version of either afunctor or an argument.Note that objects can interact only in a constrained way.
Thisis a stronger claim than that allowing arbitrarycommunication.
The more principled and constrained waymodules of the linguistic component interact, the lesscomplicated will be the system and therefore the betterperspective we can obtain for writing a large grammar.a .1  A S imple  ExampleLet's start by seeing how our simple example for a sentence"he runs" is interpreted in our framework.
A PAL expressionfor this sentence is:(*subject(he)Xruus)Class definitions for related objects are shown in figure 3.1.The interpretation process goes as follows:?
lnstantiating '*subject': let's call the new instance*subject 0.?
lnstantiating 'he': a referent is looked for from thememory.
The referent (let's call this i0) is set tothe local variable den, which stands for'denotation'.
Let the new instance be he 0.?
Evaluating '*subject0(he0)': a message whose labelis 'case' and whose value is 'subject' is sent to theobject he 0.
As a result, he0's variable case has avalue 'subject'.
The value of the evaluation is amodified version of he0, which we call he I toindicate a different version.?
Iustantiating 'runs': let's call the new instanceruns 0.
An event node (of the memory component)is created and its reference (let's call this e0) is setto the local variable den.
Then a new proposition'takes_place(e0)' is asserted to the memorycomponent.219class *subject:argument: scndImcssage , case:subject\];return\[sc/j~.
; i f  a message with label 'argument' comes, this method will send tothe object pointed to bll the variable rrtessage a message whoselabel is 'ease' and whose value is 'subject '.
; a variable rrteasage holds the value of an incoming message and avariable sel f  points to the oSjeet itself.class he:if instantiated then dcn*-'look for referent'.
; when a new instance is created, the referent is looked for and thevalue is set to the local variable den.ease: ease*-messagc; return\[selJ\].
; when a message comes whleh is labeled "ease', the local variable easewill be assigned the value the incoming message contains.
Thevalue of this method is the object itself.argument: return\[send\[message, c s :sol,l;; when this instance is applied to another object, this object will senda message whose label is the value of the local variable cone andwhose value field is the object itself.
The value of the messageprocessing is the value of this application.class runs:if instantiated then den.---ereate\['event:run'\];assert\[takes_ place(den)\].
; when a new instance of class '~ns" is instantiuted t a new ?oent willbe asserted to the memorf eornpanent.
The referenee to the newevent is set to the local variable den.subject: assert\['agent~den)~message.den'\]; return [sel~.
; when a message with label 'subject' comes, a new proposition isasserted to the mernor~ component.
7he value of this messagehandling is this obfeet itself.Figure 3.-1: Definitions of Sample Objects3.3 L ink ing  Case  ElementsOne of the basic tasks of the linguistic component is to findout which constituent is linked explicitly or implicitly to whichconstituent.
From the example shown in section 3.1, thereader can see at least three possibilities:Case l ink ing by sending messages.
Using conventionalterms of case grammar, we can say that "governer" receives amessage whose label is a surface ease and whose value is the"dependant' .
This implementation leads us to the notion ofabstraction to be discussed in section 3.4.Lex leon-dr lven methods  of determin ing  deep ease.Surface case is converted into deep case by a method definedfor each governer.
This makes it possible to handle this hardproblem without being concerned with how many differentmeanings each function word has.
Governers which have thesame characteristics in this respect can be grouped together asa superclass.
This enables to avoid duplication of knowledgeby means of hierarchy.
The latter issue is discussed in section3.2.The  use of impl ic i t  case markers .
We call items such as*subject or *object implicit, as they do not appear in thesurface form, as opposed to prepositions, which are explicit(surface} markers.
The introduction of implicit case markerseems to be reasonable if we see a language like Japanese inwhich surface case is explicitly indicated by postpositions.Thus we can assign to the translation of our sample sentence aPAL expression with the same structure as its English version:KARE GA HASHIRU ~ (GA(KARE)XHASHIRU)where, "KARE" means "he", "GA" postposition indicatingsurface subject, "HASHIRU" "run ~, respectively.?
Evaluating hel(runs0): a message whose label is'subject' and whose value is he !
is sent to runs0,which causes a new proposition 'agent(e0)--i 0, tobe asserted in the memory component.
The finalresult of the evaluation is a new version of theobject runs0, say runs 1.The above discussion is overly simplified for the purpose ofexplanation.
The following sections discuss a number of otherissues.3.2 Shar ing  Common KnowledgeObject-oriented systems use the notion of hierarchy to sharecommon procedures.
Lexical items with similar eharactericscan be grouped together as a class; we may, for example, havea class 'noun' as a superclass of lexicai items 'boy', 'girl','computer' and so forth.
~,Vhen a difference is recognizedamong objects of a class, the class may be subdivided; we maysubcategorize a verb into static verbs, action verbs,achievement verbs, etc.
Common properties can be shared atthe supercla~s.
This offers a flexible way for writing a largegrammar; one may start by defining both most general classesand least general classes.
The more observations are obtained,the richer will be the class-superclass network.
Additionally,mechanisms for supporting a multiple hierarchy and forborrowing a method are useful in coping with sophistication oflinguistic knowledge, e.g., introduction of more than onesubcategorization.3.4 Abst ract ionBy attaching a sort of a message controller in front of anobject, we can have a new version of the object whoselinguistic knowledge is essentially the same as the original onebut whose input/output specification is different.
As a typicalexample we can show how a passivizer *en is dealt with.
Anobject *en can have an embedded object as a value of its localvariable embedded.
If an instance of *en receives a messagewith label '*subject', then it will send to the object pointed byembedded the message with its label replaced by '*object'; if itreceives a message with label 'by', then it will transfer themessage to the "embedded" object by replacing the label fieldby '*subject'.Thus the object *en coupled with a transitive verb can beviewed as if they were a single intransitive verb.
This offersan abstracted way of handling linguistic objects.The effect can be seen by tracing how a PAL expression:( *subject(this(sentence)))((by(a~computer)))\[*en{understand)))"This sentence is understood by a computer.
"is interpreted 4.4Notice how the method for a transitive verb "understand" is defined, byextending the definition for an intransitive verb ~run ~.2203.5 Imp i ie i t  Case  L ink lngWe can use a very similar mechanism to deal with caselinking by causative verbs.
Consider the following sentence:z wants It to do z.This sentence implies that the subject of the infinitive is thegrammatical object of the main verb "wants ~.
Such aproperty can be shared by a number of other verbs such as"allow ~, "cause ~, "leC, "make", etc.
In the object-orientedimplementation, this can be handled by letting the objectdefined for this class transfer a message from its subject o theinfinitive.Note that the object for the these verbs must pass themessage from its subject o the infinitive when its grammaticalobject is missing.Another example of implicit case linking can be seen inrelative clauses.
In an object-oriented implementation, arelativizer transfers a message containing a pointer to the headnoun to a null NP occupying the gap in the relative clause.Intermediate objects serve as re-transmitting nodes as incomputer networks.3.6 Ob l igatory  Case  versus Non-Ob l igatory  CaseIn building a practical system, the problem of distinguishingobligatory case and non-obligatory case is always controversial.The notion of hierarchy is useful in dealing with this problemin a "lazy" fashion.
What we means by this is as follows:In procedural approach, the distinction we make betweenobligatory and non-obligatory cases seems to be based oneconomical reason.
To put this another way, we do notwant to let each lexical item have cases such as locative,instrumental, temporal, etc.
This would merely meanuseless duplication of knowledge.
We can use the notion ofhierarchy to share methods for these cases.
Any exceptionalmethod can be attached to lower level items.For example, we can define a class "action verb" which hasmethods for instrumental cases, while its superclass ~verb ~may not.This is useful for not only reflecting linguistic generalizationbut also offering a grammar designer a flexible means fordesigning a knowledge base.4 .
A Few RemarksAs is often pointed out, there are a lot of relationships whichcan be determined purely by examining linguistic structure.For example, presupposition, intra-sentential reference, focus,surface speech acts, etc.
This eventually means that thelinguistic component i self is domain independent.However, other issues such as, resolving ambiguity, resolvingtask-dependent reference, filling task-dependent ellipsis, orinferring the speaker's intention, cannot be solved solely by thelinguistic component \[Sehank 80\].
They require interactionwith the memory component.
Thus the domain dependentinformation must be stored in the memory component.To go beyond the semantics-on-top-of-syntax paradigm, wemust allow rich interaction between the memory and linguisticcomponents.
In particular, the memory component must beable to predict a structure, to guide the parsing process, or togive a low rating to a partial structure which is not plausiblebased on the experience, while the linguistic component mustbe able to explain what is going on and what it tries to see.To do this, the notion of object-orientedness provides a fairlyflexible method of interaction.Finally, we would like to mention how this frameworkdiffers from the authors' previous work on machinetranslation \[Nishida 83\], which could be viewed as aninstantiation of this framework.
The difference is that in theprevious work, the notion of lambda binding is used for linkingcases.
We directly used inteusional logic of Montaguegrammar as an intermediate language.
Though it broughtsome advantages, this scheme caused a number of technicalproblems.
First, using lambda forms causes difficulty inprocedural interpretation.
In the case of Montague grammarthis is not so, because the amount of computation doet notcause any theoretical problem in a mathematical theory.Second, though lambda expressions give an explicit form ofrepresenting some linguistic relations, other relations remainimplicit.
Some sort of additional mechanism should beintroduced to cope with those implicit relations.
Such amechanism, however, may spoil the clarity or explicitness oflambda forms.
This paper has proposed an alternative toaddress these problems.AcknowledgementsWe appreciate the useful comments made by MargotFlowers and Lawrence Birnbanm of Yale University,Department of Computer Science.References\[Bobrow 81\]\[Kaplan 82\]\[Montague 74\]\[Nishida 88\]\[Schank 80\]\[Schank 82\]Bobrow, D. G. and Stefik, M.The LOOPS Manual.Technical Report KB-VLS1-81-13, XeroxPARC, 1981.Kaplan, S. J.Cooperative Responses from a PortableNatural Language Query System.Artificial Intelligence 19(1982) :165-187,1982.Montague, R.Proper Treatment of Quantification iOrdinary English.In Thompson (editor), Formal Philosophy,pages 247-270.
Yale University, 1974.Nishida, T.Studies on the Application of FormalSemantics to English-Japanese MachineTran elation.Doctoral Thesis, Kyoto University, 1083.Schank, R. C. and Birnbaum.Memory, Meaning, and Syntax.Technical Report 189, Yale University,Department of Computer Science, 1980.Sehank, R. C.Dynamic Memory: A Theory of  Remindingand Learning in Computers and Peaple.Cambridge University Press, 1982.221
