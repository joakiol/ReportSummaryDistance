Proceedings of the 10th Conference on Parsing Technologies, pages 33?35,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsAdapting WSJ-Trained Parsers to the British National Corpus UsingIn-Domain Self-TrainingJennifer Foster, Joachim Wagner, Djame?
Seddah and Josef van GenabithNational Centre for Language TechnologySchool of Computing, Dublin City University, Dublin 9, Ireland{jfoster, jwagner, josef}@computing.dcu.ie, dseddah@paris4.sorbonne.fr?AbstractWe introduce a set of 1,000 gold standardparse trees for the British National Corpus(BNC) and perform a series of self-trainingexperiments with Charniak and Johnson?sreranking parser and BNC sentences.
Weshow that retraining this parser with a com-bination of one million BNC parse trees(produced by the same parser) and the orig-inal WSJ training data yields improvementsof 0.4% on WSJ Section 23 and 1.7% on thenew BNC gold standard set.1 IntroductionGiven the success of statistical parsing models onthe Wall Street Journal (WSJ) section of the PennTreebank (PTB) (Charniak, 2000; Collins, 2003, forexample), there has been a change in focus in recentyears towards the problem of replicating this successon genres other than American financial news sto-ries.
The main challenge in solving the parser adap-tation problem are the resources required to con-struct reliable annotated training examples.A breakthrough has come in the form of researchby McClosky et al (2006a; 2006b) who show thatself-training can be used to improve parser perfor-mance when combined with a two-stage rerankingparser model (Charniak and Johnson, 2005).
Self-training is the process of training a parser on its ownoutput, and earlier self-training experiments usinggenerative statistical parsers did not yield encour-aging results (Steedman et al, 2003).
McClosky etal.
(2006a; 2006b) proceed as follows: sentences?Now affiliated to Lalic, Universite?
Paris 4 La Sorbonne.from the LA Times newspaper are parsed by a first-stage generative statistical parser trained on someseed training data (WSJ Sections 2-21) and the n-best parse trees produced by this parser are rerankedby a discriminative reranker.
The highest rankedparse trees are added to the training set of the parserand the parser is retrained.
This self-training methodgives improved performance, not only on Section23 of the WSJ (an absolute f-score improvement of0.8%), but also on test sentences from the Browncorpus (Francis and Kuc?era, 1979) (an absolute f-score improvement of 2.6%).In the experiments of McClosky et al (2006a;2006b), the parse trees used for self-training comefrom the same domain (American newspaper text)as the parser?s original seed training material.
Bac-chiani et al (2006) find that self-training is ef-fective when the parse trees used for self-training(WSJ parse trees) come from a different domain tothe seed training data and from the same domain asthe test data (WSJ sentences).
They report a per-formance boost of 4.2% on WSJ Section 23 for agenerative statistical parser trained on Brown seeddata when it is self-trained using 200,000 WSJ parsetrees.
However, McCloskey et al (2006b) report adrop in performance for their reranking parser whenthe experiment is repeated in the opposite direction,i.e.
with Brown data for self-training and testing,and WSJ data for seed training.
In contrast, we re-port successful in-domain1 self-training experimentswith the BNC data as self-training and test material,and with the WSJ-trained reranking parser used byMcCloskey et al (2006a; 2006b).We parse the BNC (Burnard, 2000) in its entirety1We refer to data as being in-domain if it comes from thesame domain as the test data and out-of-domain if it does not.33using the reranking parser of Charniak and Johnson(2005).
1,000 BNC sentences are manually anno-tated for constituent structure, resulting in the firstgold standard set for this corpus.
The gold standardset is split into a development set of 500 parse treesand a test set of 500 parse trees and used in a seriesof self-training experiments: Charniak and John-son?s parser is retrained on combinations of WSJtreebank data and its own parses of BNC sentences.These combinations are tested on the BNC devel-opment set and Section 00 of the WSJ.
An optimalcombination is chosen which achieves a Parseval la-belled bracketing f-score of 91.7% on Section 23and 85.6% on the BNC gold standard test set.
ForSection 23 this is an absolute improvement of 0.4%on the baseline results of this parser, and for theBNC data this is a statistically significant improve-ment of 1.7%.2 The BNC DataThe BNC is a 100-million-word balanced part-of-speech-tagged corpus of written and transcribedspoken English.
Written text comprises 90% of theBNC: 75% non-fictional and 25% fictional.
To fa-cilitate parsing with a WSJ-trained parser, some re-versible transformations were applied to the BNCdata, e.g.
British English spellings were convertedto American English and neutral quotes disam-biguated.
The reranking parser of Charniak andJohnson (2005) was used to parse the BNC.
99.8%of the 6 million BNC sentences obtained a parse,with an average parsing speed of 1.4s per sentence.A gold standard set of 1,000 BNC sentences wasconstructed by one annotator by correcting the out-put of the first stage of Charniak and Johnson?sreranking parser.
The sentences included in the goldstandard were chosen at random from the BNC, sub-ject to the condition that they contain a verb whichdoes not occur in the training sections of the WSJsection of the PTB (Marcus et al, 1993).
A deci-sion was made to select sentences for the gold stan-dard set which differ from the sentences in the WSJtraining sections, and one way of finding differentsentences is to focus on verbs which are not attestedin the WSJ Sections 2-21.
It is expected that thesegold standard parse trees can be used as trainingdata although they are used only as test and develop-ment data in this work.
Because they contain verbswhich do not occur in the parser?s training set, theyare likely to represent a hard test for WSJ-trainedparsers.
The PTB bracketing guidelines (Bies et al,1995) and the PTB itself were used as references bythe BNC annotator.
Functional tags and traces werenot annotated.
The annotator noticed that the PTBparse trees sometimes violate the PTB bracketingguidelines, and in these cases, the annotator chosethe analysis set out in the guidelines.
It took approx-imately 60 hours to build the gold standard set.3 Self-Training ExperimentsCharniak and Johnson?s reranking parser (June 2006version) is evaluated against the BNC gold stan-dard development set.
Labelled precision (LP), re-call (LR) and f-score measures2 for this parser areshown in the first row of Table 1.
The f-score of83.7% is lower than the f-score of 85.2% reportedby McClosky et al (2006b) for the same parser onBrown corpus data.
This difference is reasonablesince there is greater domain variation between theWSJ and the BNC than between the WSJ and theBrown corpus, and all BNC gold standard sentencescontain verbs not attested in WSJ Sections 2-21.We retrain the first-stage generative statisticalparser of Charniak and Johnson using combinationsof BNC trees (parsed using the reranking parser)and WSJ treebank trees.
We test the combinationson the BNC gold standard development set and onWSJ Section 00.
Table 1 shows that parser accu-racy increases with the size of the in-domain self-training material.3 The figures confirm the claim ofMcClosky et al (2006a) that self-training with areranking parsing model is effective for improvingparser accuracy in general, and the claim of Gildea(2001) that training on in-domain data is effectivefor parser adaption.
They confirm that self-trainingon in-domain data is effective for parser adaptation.The WSJ Section 00 results suggest that, in orderto maintain performance on the seed training do-main, it is necessary to combine BNC parse trees2All scores are for the second stage of the parsing process,i.e.
the evaluation takes place after the reranking.
All evalua-tion is carried out using the Parseval labelled bracketing metrics,with evalb and parameter file new.prm.3The notation bnc500K+5wsj refers to a set of 500,000parser output parse trees of sentences taken randomly from theBNC concatenated with five copies of WSJ Sections 2-21.34BNC Development WSJ Section 00Self-Training LP LR LF LP LR LF- 83.6 83.7 83.7 91.6 90.5 91.0bnc50k 83.7 83.7 83.7 90.0 88.0 89.0bnc50k+1wsj 84.4 84.4 84.4 91.6 90.3 91.0bnc250k 84.7 84.5 84.6 91.1 89.3 90.2bnc250k+5wsj 85.0 84.9 85.0 91.8 90.5 91.2bnc500k+5wsj 85.2 85.1 85.2 91.9 90.4 91.2bnc500k+10wsj 85.1 85.1 85.1 91.9 90.6 91.2bnc1000k+5wsj 86.5 86.2 86.3 91.7 90.3 91.0bnc1000k+10wsj 86.1 85.9 86.0 92.0 90.5 91.3bnc1000k+40wsj 85.5 85.5 85.5 91.9 90.6 91.3BNC Test WSJ Section 23- 84.0 83.7 83.9 91.8 90.9 91.3bnc1000k+10wsj 85.7 85.4 85.6 92.3 91.1 91.7Table 1: In-domain Self-Training Resultswith the original seed training material during theself-training phase.Of the self-training combinations with above-baseline improvements for both development sets,the combination of 1,000K BNC parse trees andSection 2-21 of the WSJ (multiplied by ten) yieldsthe highest improvement for the BNC data, and wepresent final results with this combination for theBNC gold standard test set and WSJ Section 23.There is an absolute improvement on the originalreranking parser of 1.7% on the BNC gold standardtest set and 0.4% on WSJ Section 23.
The improve-ment on BNC data is statistically significant for bothprecision and recall (p < 0.0002, p < 0.0002).
Theimprovement on WSJ Section 23 is statistically sig-nificant for precision only (p < 0.003).4 Conclusion and Future WorkWe have introduced a set of 1,000 gold standardparse trees for the BNC.
We have performed self-training experiments with Charniak and Johnson?sreranking parser and sentences from the BNC.
Wehave shown that retraining this parser with a com-bination of one million BNC parse trees (producedby the same parser) and the original WSJ train-ing data yields improvements of 0.4% on WSJ Sec-tion 23 and 1.7% on the BNC gold standard sen-tences.
These results indicate that self-training onin-domain data can be used for parser adaptation.Our BNC gold standard set consists of sentencescontaining verbs which are not in the WSJ train-ing sections.
We suspect that this makes the goldstandard set a hard test for WSJ-trained parsers, andour results are likely to represent a lower bound forWSJ-trained parsers on BNC data.
When used astraining data, we predict that the novel verbs in theBNC gold standard set add to the variety of train-ing material, and will further help parser adaptationfrom the WSJ domain ?
a matter for further research.Acknowledgments We thank the IRCSET Em-bark Initiative (basic research grant SC/02/298and postdoctoral fellowship P/04/232), ScienceFoundation Ireland (Principal Investigator grant04/IN.3/I527) and the Irish Centre for High EndComputing for supporting this research.ReferencesMichiel Bacchiani, Michael Riley, Brian Roark, and RichardSproat.
2006.
Map adaptation of stochastic grammars.Computer Speech and Language, 20(1):41?68.Ann Bies, Mark Ferguson, Karen Katz, and Robert MacIntyre.1995.
Bracketing guidelines for treebank II style, Penn Tree-bank project.
Technical Report MS-CIS-95-06, Universityof Pennsylvania.Lou Burnard.
2000.
User reference guide for the British Na-tional Corpus.
Technical report, Oxford University.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best-parsing and maxent discriminative reranking.
In Pro-ceedings of ACL-05, pages 173?180, Barcelona.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.In Proceedings of NAACL-00, pages 132?139, Seattle.Michael Collins.
2003.
Head-driven statistical modelsfor natural language parsing.
Computational Linguistics,29(4):499?637.W.
Nelson Francis and Henry Kuc?era.
1979.
Brown CorpusManual.
Technical report, Brown University, Providence.Daniel Gildea.
2001.
Corpus variation and parser performance.In Proceedings of EMNLP-01, pages 167?202, Barcelona.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated corpusof English: the Penn Treebank.
Computational Linguistics,19(2):313?330.David McClosky, Eugene Charniak, and Mark Johnson.
2006a.Effective self-training for parsing.
In Proceedings of HLT-NAACL-06, pages 152?159, New York.David McClosky, Eugene Charniak, and Mark Johnson.
2006b.Reranking and self-training for parser adaptation.
In Pro-ceedings of COLING-ACL-06, pages 337?344, Sydney.Mark Steedman, Miles Osbourne, Anoop Sarkar, StephenClark, Rebecca Hwa, Julia Hockenmaier, Paul Ruhlen,Steven Baker, and Jeremiah Crim.
2003.
Boot-strappingstatistical parsers from small datasets.
In Proceedings ofEACL-03, Budapest.35
