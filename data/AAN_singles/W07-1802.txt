Proceedings of SPEECHGRAM 2007, pages 9?16,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsConverting Grammatical Framework to RegulusPeter Ljungl?fDepartment of LinguisticsG?teborg UniversityGothenburg, Swedenpeb@ling.gu.seAbstractWe present an algorithm for convertingGrammatical Framework grammars (Ranta,2004) into the Regulus unification-basedframework (Rayner et al, 2006).
The mainpurpose is to take advantage of the Regulus-to-Nuance compiler for generating opti-mized speech recognition grammars.
Butthere is also a theoretical interest in knowinghow similar the two grammar formalismsare.Since Grammatical Framework is more ex-pressive than Regulus, the resulting Regu-lus grammars can be overgenerating.
Wetherefore describe a subclass of Grammati-cal Framework for which the algorithm re-sults in an equivalent Regulus grammar.1 BackgroundIn this section we describe the grammar formalismGrammatical Framework (GF), and discuss its ex-pressive power and the present options for creat-ing speech recognition grammars (SRGs).
The mainproblem is that the size of the grammar can explodewhen inflectional parameters are expanded.
In thispaper we try to solve this problem by converting toa formalism for which there is an optimized SRGcompiler.
This formalism is Regulus, which is de-scribed together with its SRG compiler.The formal details are left out of the descriptionsin this section and can instead be found in section 2.In section 3 the conversion algorithm is presented indetail, and in section 4 there is a short discussion.1.1 Grammatical FrameworkGrammatical Framework (Ranta, 2004) is a gram-mar formalism based on type theory.
The main fea-ture is the separation of abstract and concrete syn-tax, which makes it very suitable for writing mul-tilingual grammars.
A rich module system also fa-cilitates grammar writing as an engineering task, byreusing common grammars.1.1.1 Separating abstract and concrete syntaxThe main idea of GF is the separation of ab-stract and concrete syntax, a distinction which isshared with several other grammar formalisms suchas Abstract Categorial Grammars (de Groote, 2001),Lambda Grammar (Muskens, 2003) and Higher Or-der Grammar (Pollard, 2004).
The abstract part ofa grammar defines a set of abstract syntactic struc-tures, called abstract terms or trees; and the concretepart defines a relation between abstract structuresand concrete structures.GF has a linearization perspective to grammarwriting, where the relation between abstract andconcrete is viewed as a mapping from abstract toconcrete structures, called linearization terms.
Insome cases the mapping can be partial or even many-valued.Although not exploited in many well-knowngrammar formalisms, a clear separation between ab-stract and concrete syntax gives some advantages.High-level language descriptions: When describ-ing the abstract syntax, the grammar writer canchoose not to care about language specific de-tails, such as inflection and word order.Multilingual grammars: It is possible to definedifferent concrete syntaxes for one particular9abstract syntax.
Multilingual grammars can beused as a model for interlingua translation, butalso to simplify localization of language tech-nology applications.Resource grammars: The abstract syntax of onegrammar can be used as a concrete syntax ofanother grammar.
This makes it possible to im-plement grammar resources to be used in sev-eral different application domains.These points are currently exploited in the GF Re-source Grammar Library (Ranta et al, 2006), whichis a multilingual GF grammar with a common ab-stract syntax for 13 languages.
The grammati-cal coverage is similar to the Core Language En-gine (Rayner et al, 2000).
The main purpose ofthe Grammar Library is as a resource for writingdomain-specific grammars.1.1.2 Abstract syntaxThe abstract theory of GF is a version of Martin-L?f?s (1984) dependent type theory.
A grammarconsists of declarations of categories and functions.Categories can depend on other categories.
Func-tion declarations can bind variables to be used in de-pendent types, and also take functions as arguments,thus giving rise to higher-order functions.
Since theabstract syntax also permits function definitions, theexpressive power of GF abstract syntax is Turing-complete.In this article we restrict ourselves to an impor-tant subclass of GF, where there are no dependenttypes and no higher-order functions.
This subclassis called context-free GF, and is an instance of Gen-eralized Context-Free Grammar (Pollard, 1984).The abstract syntax of a context-free GF grammarconsists of a set of function typings of the formf : A1 ?
?
?
?
?
A?
?
AThis typing says that f is a function taking ?
argu-ments with categories A1 .
.
.
A?
and returning a cat-egory A.
This is equivalent to a context-free gram-mar without terminal symbols.
Note however, thatthe function f would be written A ?
A1 .
.
.
A?
asan ordinary context-free rule.
I.e., the left-hand sideof a context-free rule corresponds to the result of thefunction, which is written to the right.
The restric-tion to a context-free backbone is not severe, sincethe concrete syntax is so expressive.1.1.3 Concrete syntaxLinearizations are written as terms in a typedfunctional programming language, which is limitedto ensure decidability in generation and in parsing.The language has records and finite-domain func-tions (called tables); and the basic types are termi-nal lists (called strings) and finite data types (calledparameter types).
There are also local definitions,lambda-abstractions and global function definitions.The parameters are declared by the grammar; theycan be hierarchical but not recursive, to ensure finite-ness.The language of linearization terms is quite com-plex, but it can be compiled to a normalized formwhich is called canonical GF.
In this paper we as-sume that all linearizations are in canonical form.A canonical concrete GF grammar contains declara-tions of all parameter types, and linearization defini-tions for all abstract functions.1.1.4 Expressive powerThe expressive power of context-free GF solelydepends on the possibility of discontinuous con-stituents.
This means that one grammatical phrasecan be split into several parts occurring in differentplaces in the sentence.
Discontinuous constituentspermit a simple and compositional way of treating,e.g., German compound verbs, where the particlecommonly is moved to the end of the sentence.Ljungl?f (2004) showed that context-free GF isequivalent to Multiple Context-Free Grammar (Sekiet al, 1991), which is known to be parseable in timepolynomial in the length of the input string.
From aconverted Multiple CFG, each constituent can be ex-tracted as a context-free rule, which will result in apossibly overgenerating context-free grammar.
Thiscontext-free grammar can be output from the GFsystem in several different speech recognition for-mats, as described by Bringert (2007).There is a severe problem with the conversionfrom GF to Multiple CFG however ?
the size ofthe resulting grammar tend to explode when the in-flectional parameters are expanded.
Large gram-mars such as many of the languages in the Resource10Grammar Library simply cannot be converted.
Onesolution would be to optimize the conversion algo-rithm, e.g., by interleaving parameter expansion andgrammar compaction.
Another solution would beto translate into a grammar formalism which doesnot have this size explosion.
This is where Reguluscomes in ?
if we could translate GF grammars intoRegulus grammars, we could make use of the re-search already put into the Regulus-to-Nuance com-piler, and would not have to reinvent the wheel.1.2 RegulusRegulus is an open-source toolkit for writinggrammar-based speech recognition systems (Rayneret al, 2006).1 The central part is the Regulus gram-mar formalism and a compiler for creating speechrecognition grammars.
The toolkit has been en-hanced with templates for developing e.g., speechtranslation systems and dialogue systems.
There isalso an English resource grammar, which can beused for grammar specialization using explanation-based learning (Rayner et al, 2006, chapters 9?10).1.2.1 Unification of finite parametersThe Regulus formalism is a context-free gram-mar, enhanced with unification of finite parameters.This means that the formalism is equivalent to acontext-free grammar.Each context-free category (e.g., Noun) has anumber of features (e.g., Number and Gender)with a finite domain of values (e.g., Sg/Pl andMasc/Fem/Neutr).
The feature values are specifiedusing a record paired with the grammatical category.Logical variables can be used for unifying featuresof different constituents in the rule.
It is possible todefine macros for simplifying common tasks, e.g.,when implementing a lexicon.Compared to Grammatical Framework, the Regu-lus formalism is quite restricted.
There is no cleardistinction between abstract and concrete syntax,and there is no advanced module system in which todefine grammatical resources.
Also, Regulus lacksdiscontinuous constituents, which reduces the ex-pressive power considerably.1More information about Regulus, including download in-formation, can be found on the project homepage: http://www.issco.unige.ch/projects/regulus/1.2.2 Compiling Regulus to Nuance GSLNuance Communications (2003) has developeda context-free grammar format for speech recogni-tion, which has become one of the de facto stan-dards for speech recognition.
The grammar formatis called Nuance Grammar Specification Language(GSL).
The format has some special features, suchas semantic tagging and probabilistic grammar rules.There are also restrictions in the format, most no-tably that the grammars must not be left-recursive.The Regulus formalism is designed to be able tomake use of the special features in Nuance GSL, andthe compiler can always create correct GSL gram-mars without left-recursion.2 Formal definitionsIn this section we give formal definitions of rules andlinearization terms in GF, grammar rules and termsin Regulus, and the intermediate structures we willbe using.2.1 GF grammar rulesSince we are only interested in GF grammars witha context-free backbone, the abstract syntax is acontext-free grammar where each rule has a uniquename.
The rules are written as typings in a func-tional language:f : A1 ?
?
?
?
?
A?
?
AAsmentioned earlier, this declaration corresponds tothe context-free rule A ?
A1 .
.
.
A?.Linearizations are written as function definitions,f x1 .
.
.
x?
= t, where x1 .
.
.
x?
are variables thatoccur in the linearization term t. An alternative wayof writing this is to name the variables consistentlyfor each rule, and then the linearization term t it-self is sufficient as a linearization definition.
Weadopt this idea and use the uniform variable names$1 .
.
.
$?
in each linearization.
With this approachwe also distinguish the argument variables from theparameter variables which get bound in tables.2.2 GF linearization terms and substructuresA parameter type P is just a set of parameter values{p1, .
.
.
, pn}.
Note that all parameter types mustbe disjoint, i.e., each parameter should belong to11exactly one parameter type.
Linearizations are de-fined by association linearization terms to the ab-stract functions.
Note that the definition of terms isslightly more general than the definition in GF, sincewe want to include reduced terms in the definition.The relation between the introduced classes are asfollows:P ?
VParVStr}?
V ?
TTerms (t ?
T) are defined inductively as follows:t ::= $n argument| ?s?
string| t ++ t?
concatenation| p pattern| {r1 = t1; .
.
.
; rn = tn} record| t.r projection| [p1 ?
t1; .
.
.
; pn ?
tn] table| t1!t2 selectionwhere n > 0 is a positive integer, p ?
P is a pattern,and r ?
R is a record label.
The class R of recordlabels is just a finite class of atomic values.
The ar-gument reference $n denotes the nth argument ofthe linearization function.Patterns (p ?
P) are pairs x@pi of variables, x,and sets of parameters, pi = {p1 .
.
.
pn}.
The pa-rameters p1 .
.
.
pn all must belong to the same pa-rameter type P, i.e., pi ?
P. The meaning of thepattern is that x is bound to one of the parameters inpi.
If pi = P we can skip that part and simply writex.
Conversely, if x is not used elsewhere in the term,we can skip it and simply write pi.Note that a pattern is a term in itself, but in GFit will always occur as a single variable x or as asingle parameter p. However, after the conversionalgorithm has transformed tables into records, pat-terns will become first class terms.Reduced terms (v ?
V) are subterms of ordinaryterms.
A reduced term is a term which does notcontain a table or a selection, and where projectionsonly occur in the form $n.
?, where ?
?
R?
is a se-quence of labels:v ::= $n.
?| ?s?| v ++ v?| p| {r1 = v1; .
.
.
; rn = vn}Reduced parameter terms (vp ?
VPar) are sub-terms of reduced terms, which correspond to param-eters:vp ::= $n.?
| pReduced string terms (vs ?
VStr) are subtermsof reduced terms, which correspond to strings:vs ::= $n.?
| ?s?
| vs ++ v?sNote that this is equivalent to a sequence of argu-ment projections and string constants, which in turnis equivalent to a right-hand side in a context-freerule.2.3 Regulus grammar rules and termsA Regulus grammar is a unification-based phrase-structure grammar.
It consists of grammar rules,which in turn is built up using Regulus terms.Regulus rules are regular context-free grammarrules, where each category is augmented with a Reg-ulus term:A:v ?
?0 A1:v1 ?1 .
.
.
A?:v?
?
?where each Ai is a context-free category, each vi isa Regulus term, and each ?i is a (possibly empty)sequence of terminal tokens.Regulus terms are flat records where all valuesare patterns (pi = xi@pii):2vr ::= {r1 = p1; .
.
.
; rn = pn}In this sense, Regulus terms are just subterms of re-duced terms.
However, a Regulus term can includeone of the two special labels sem and gsem, cor-responding to return values and global slot-fillingin Nuance GSL, respectively.
They can containcomplex structures, such as deeply nested lists andrecords.
Using these it is possible to define the syn-tactical structure of a phrase.2This is a slight abuse of syntax ?
in Regulus the record rowri = xi@pii is written as two separate rows ri = xi; ri = pii.123 Converting GF to RegulusIn this section we describe an algorithm for convert-ing any context-free GF rule into a set of Regulusrules.
This conversion is done in three steps:1.
Tables and table selections are removed fromthe GF term, resulting in several reduced termsand sets of constraints.2.
The results are massaged into Regulus termsfor the left-hand side and the right-hand side.3.
Finally, GF abstract syntax is used to create thefinal Regulus rules.In the final step, the abstract syntax is added as a se-mantic value in the Regulus rules.
This makes it pos-sible to get back the GF abstract syntax tree, whenusing Regulus (or Nuance) for parsing the grammar.Example As a running example we will use a stan-dard English GF rule for combining transitive verbswith noun phrases:vp : TV ?
NP ?
VP= {s = [n ?
$1.s!n ++ $2.s]}The idea is that a verb phrase has a parametricalnumber (n), which it inherits from the verb.
Whenthe verb phrase is used in a sentence, the numberwill depend on the inherent number of the subject.3.1 Converting tables to unification-basedrecordsThe main difference between GF and Regulus is thatthe former has tables and the latter has unification.The problem when converting from GF to Regulusis therefore how to get rid of the tables and selec-tions.
We present an algorithm for removing tablesand selections, by replacing them with logical vari-ables and equality constraints.The basic idea is to translate each row pi ?
tiin a table into a record {p = pi;v = ti}.
Thevariables in ti which are bound by pi become log-ical variables.
Thus the original table gives rise to ndifferent records (if n is the number of table rows),which in the end becomes n different Regulus terms.A table selection t!t?
then has to be translated intothe value t.v of the table, and a constraint is addedthat the selection term t?
and the pattern t.p of thetable should be unified.Step 1: Removing tables and selectionsWe define a nondeterministic reduction operation=?
.
The meaning of t =?
v/?
is that the term t ?T is converted to the reduced term v ?
V togetherwith the set of constraints ?
?
VPar ?
VPar.
Eachconstraint in ?
is of the form vp.= v?p, where vp andv?p are reduced parameter terms.?
Each row pi ?
ti in a table is reduced to arecord containing the pattern pi and the reducedvalue vi:ti =?
vi/?i[.
.
.
; pi ?
ti; .
.
.]
=?
{p = pi;v = vi}/?iNote that this rule is nondeterministic ?
the ta-ble is reduced to n different terms, where n isthe number of table rows.?
A table selection t!t?
is reduced to the value v.v,with the added constraint that the pattern v.pand the selection term v?
should unify:t =?
v0/?
t?
=?
v?p/??t!t?
=?
v / ???
(vp.= v?p)vp = prj(v0,p)v = prj(v0,v)Note that since t?
denotes a parameter, it will bereduced to a parameter term, v?p ?
VPar.?
A record projection t.r is reduced to a projec-tion v.r:t =?
v/?t.r =?
vr/?vr = prj(v, r)?
All other term constructors are reduced com-positionally, i.e., by reducing the internal termsrecursively.The function prj(v, r) calculates the projection ofr on the simple term v. Since there are only tworeduced term constructors that can correspond to arecord, there are only two cases in the definition:prj({.
.
.
; r = vr; .
.
.
}, r) = vrprj($n.?
, r) = $n.
?r13Example The original linearization term of the ex-ample contains one table and one selection.
Theselection $1.s!n is reduced to $1.sv with the addedconstraint $1.sp .= n. And since there is only onerow in the table, the example term is reduced to onesingle term vvp with the constraints ?vp:vvp = {s = {p = n;v = $1.sv ++ $2.s}}?vp = $1.sp.= n3.2 Building Regulus termsThe reduced term and the constraints from the firststep do not constitute a Regulus grammar rule, butthey have to be massaged into the correct form.
Thisis done in four small steps below.Step 2a: Flattening the reduced termAfter the conversion t =?
v/?, we have a re-duced term v ?
V and a set of constraints ?
?VPar ?
VPar.
Now we convert v into a set of con-straints and add to the constraint store ?:?
For each subterm v?
in v denoting a parameter,add $0.
?.= v?
to ?.
The path ?
is the sequenceof labels for getting from v to v?, i.e., v?
= v.?.We also create a set of ?proto rules?
?
?
R??VStr:?
For each subterm v?
in v denoting a string, add?
?
v?
to ?.
The path ?
is the same as above.Example There is one subterm in vvp denoting aparameter, so we add $0.sp .= n to ?vp.
There isone subterm in vvp that denotes a string, so we let?vp contain sv ?
$1.sv ++ $2.s.Step 2b: Simplifying the constraintsNow we have two constraint stores, ?
and ?, ofwhich the latter can be partially evaluated into a sim-pler form.1.
For each constraint of the form $n1.?1.=$n2.
?2, we replace it with two new constraints$ni.
?i.= x, where x is a fresh variable.32.
For each constraint of the form x1@pi1.=x2@pi2 , there are two possibilities:3Recall that x is just a shorthand for x@pi, where pi is the setof all parameters.?
If pi1 and pi2 are disjoint, then the con-straint is contradictive and we remove v,?
and ?
from the list of results.?
Otherwise, we replace each occurrence ofxi@pii in v and in ?, by x@pi, where x is afresh variable and pi = pi1 ?
pi2.Example We do not have to do anything to ?vp,since all constraints already are in simplified form.Step 2c: Building Regulus termsNow ?
only contains constraints of the form$n.
?.= p where p = x@pi.
We transform theseconstraints into the Regulus records T0, T1, .
.
.
, T?in the following way:?
For each constraint $n.
?.= p, add the recordrow {?
= p} to Tn.Note that the labels in the Regulus terms are se-quences of GF labels.Example The constraints in ?vp now give rise tothe Regulus terms:Tvp,0 = {sp = n}Tvp,1 = {sp = n}Tvp,2 = {}3.3 Building a Regulus grammarTo be able to create Regulus grammar rules from theRegulus terms T0 .
.
.
T?, we need to look at the ab-stract syntax in the GF grammar.
In this section wewill assume that the typing of the linearization inquestion is f : A1 ?
?
?
?
?
A?
?
A.Regulus (and Nuance GSL) permits the use of ar-bitrary nested lists in the special sem feature.
Wewill use the nested list for representing a GF abstractsyntax tree which then will be returned directly byNuance after the parsing has succeeded.
This is im-portant since the arguments to the function can bepermuted in the linearization, which then means thatthe arguments in the Regulus rule are permuted aswell.14Step 3a: Adding GF abstract syntax to theRegulus termsThe abstract syntax tree of the original rule is putas a sem value in the left-hand side term T0:?
Add the row {sem=[f x1 .
.
.
x?]}
to T0.?
For each 1 ?
i ?
?, add {sem=xi} to Ti.Note that the x1 .
.
.
x?
should be fresh variables, notused elsewhere in the terms.Example After adding semantics, the exampleterms become:Tvp,0 = {sp = n; sem = [vp x y]}Tvp,1 = {sp = n; sem = x}Tvp,2 = {sem = y}Step 3b: Building Regulus grammar rulesFinally, we can transform the proto rules in ?
intoRegulus grammar rules:?
For each proto rule ?0 ?
v1 ++ ?
?
?
++ vm in?, create a new Regulus rule:A?0 : T0 ?
v?1 .
.
.
v?mwhere the terms in the right-hand side are cal-culated as follows:(?s?)?
= ?s?($n.?)?
= An ?
: TnExample From the single proto rule in?vp we cre-ate the Regulus rule:VPsv : Tvp,0 ?
TVsv : Tvp,1 NPs : Tvp,2where the terms Tvp,i are described above.4 DiscussionWe have presented an algorithm for convertingGF grammars with a context-free backbone intounification-based Regulus grammars.
The algorithmis simple and straightforward, which is an indicationthat the formalisms are more similar than one mighthave guessed beforehand.4.1 Equivalence of the grammarsThe presented algorithm does not necessarily yieldan equivalent grammar.
This is a consequence of thefact that context-free GF is equivalent to MultipleCFG, and that Multiple CFG is much more expres-sive than context-free grammars.However, if the original grammar does not makeuse of multiple constituents, the conversion is equiv-alent.
Note that the grammar might very well con-tain multiple constituents, but if there is no right-hand side that refers to both constituents simultane-ously the equivalence is still preserved.4.2 Complexity issuesAs mentioned earlier, each GF function might giverise to several Regulus rules, so in one sense the re-sulting grammar is bigger than the original.
How-ever, the actual size in terms of memory usage doesnot differ (except maybe linear because of differ-ences in syntax).4.2.1 The number of rulesThe number of Regulus rules for one single GFlinearization term is equal to:|?|?
?|?|where |?| is the number of discontinuous con-stituents, and ?
ranges over all tables in the lin-earization term.
This is easy to see, since it isonly tables that are reduced nondeterministically,and each proto rule in ?
gives rise to one Regulusrule.4.2.2 The size of the grammarThe total size of the final grammar can be largerthan the original GF grammar.
This is because theRegulus grammar will contain lots of copies of thesame structures, e.g., everything outside of a tablehas to be duplicated in for each table row.
The the-oretical limit is the same as above ?
the number ofconstituents, times the the total product of all tablerows ?
but in practice the grammar explosion is notthat extreme.Since the increase in size is due to copying, theRegulus grammar can be compacted by the use ofmacros (Rayner et al, 2006, section 4.5).
This could15probably be implemented in the algorithm directly,but we have not yet investigated this idea.4.2.3 Time complexityThe time complexity of the algorithm is approxi-mately equivalent to the size of the resulting Regu-lus grammar.
The first step (in section 3.1), can beimplemented as a single pass through the term andis therefore linear in the size of the resulting terms.The post-processing steps (in section 3.2) are alsolinear in the size of the terms and constraints.
Fi-nally, the steps for building grammar rules does notdepend on the term size at all.
Thus, the time com-plexity is linear in the size of the final Regulus gram-mar.4.3 Using Regulus as a compiler for speechrecognition grammarsBy presenting an algorithm for converting GF gram-mars into Regulus, it is possible to further use theRegulus-to-Nuance compiler for getting an opti-mized speech recognition grammar.
The advantageto compiling Nuance grammars directly from GF isclear: the Regulus project has developed and imple-mented several optimizations (Rayner et al, 2006,chapter 8), which would have to be reimplementedin a direct GF-to-Nuance compiler.As previously mentioned in section 1.1.4, there isa speech recognition grammar compiler already im-plemented in GF (Bringert, 2007), which uses theequivalence of GF and Multiple CFG.
An interest-ing future investigation would be to compare the twoapproaches on realistic grammars.ReferencesBj?rn Bringert.
2007.
Speech recognition grammar com-pilation in Grammatical Framework.
Submitted toSpeechGram 2007.Philippe de Groote.
2001.
Towards abstract categorialgrammars.
In 39th Meeting of the Association forComputational Linguistics, Toulouse, France.Peter Ljungl?f.
2004.
Expressivity and Complexity ofthe Grammatical Framework.
Ph.D. thesis, G?teborgUniversity and Chalmers University of Technology,November.Per Martin-L?f.
1984.
Intuitionistic Type Theory.
Bib-liopolis, Napoli.ReinhardMuskens.
2003.
Language, lambdas, and logic.In Geert-Jan Kruijff and Richard Oehrle, editors, Reo-surce Sensitivity in Binding and Anaphora, pages 23?54.
Kluwer.Nuance Communications, Inc., 2003.
Nuance SpeechRecognition System 8.5: Grammar Developer?sGuide, December.Carl Pollard.
1984.
Generalised Phrase Structure Gram-mars, Head Grammars and Natural Language.
Ph.D.thesis, Stanford University.Carl Pollard.
2004.
Higher-order categorial grammar.
InMichel Moortgat, editor, International Conference onCategorial Grammars, Montpellier, France.Aarne Ranta, Ali El-Dada, and Janna Khegai,2006.
The GF Resource Grammar Library.Can be downloaded from the GF homepagehttp://www.cs.chalmers.se/~aarne/GFAarne Ranta.
2004.
Grammatical Framework, a type-theoretical grammar formalism.
Journal of FunctionalProgramming, 14(2):145?189.Manny Rayner, Dave Carter, Pierrette Bouillon, VassilisDigalakis, and Mats Wir?n.
2000.
The Spoken Lan-guage Translator.
Cambridge University Press.Manny Rayner, Beth Ann Hockey, and Pierrette Bouil-lon.
2006.
Putting Linguistics into Speech Recogni-tion: The Regulus Grammar Compiler.
CSLI Publica-tions.Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, andTadao Kasami.
1991.
On multiple context-free gram-mars.
Theoretical Computer Science, 88:191?229.16
