TOWARDS THE AUTOMATIC IDENTIFICATION OF ADJECTIVALSCALES: CLUSTERING ADJECTIVES ACCORDING TO MEANINGVasileios HatzivassiloglouKathleen R. McKeownDepartment of Computer Science450 Computer Science BuildingColumbia UniversityNew York, N.Y. 10027Internet: vh@cs.columbia.edukathy @ cs.columbia.eduABSTRACTIn this paper we present a method to group adjectivesaccording to their meaning, as a first step towards theautomatic dentification of adjectival scales.
We discuss theproperties of adjectival scales and of groups of semanticallyrelated adjectives and how they imply sources of linguisticknowledge in text corpora.
We describe how our systemexploits this linguistic knowledge to compute a measure ofsimilarity between two adjectives, using statistical tech-niques and without having access to any semantic infor-mation about he adjectives.
We also show how a clusteringalgorithm can use these similarities to produce the groupsof adjectives, and we present results produced by our sys-tem for a sample set of adjectives.
We conclude by present-ing evaluation methods for the task at hand, and analyzingthe significance of the results obtained.1.
INTRODUCTIONAs natural language processing systems becomemore oriented towards solving real-world problemslike machine translation or spoken language under-standing in a limited domain, their need for access tovast amounts of knowledge increases.
While a modelof the general rules of the language at various levels(morphological, syntactic, etc.)
can be hand-encoded,knowledge which pertains to each specific word isharder to encode manually, if only because of the sizeof the lexicon.
Most systems currently rely on humanlinguists or lexicographers who compile lexiconentries by hand.
This approach requires significantamounts of time and effort for expanding thesystem's lexicon.
Furthermore, if the compiled infor-mation depends in any way on the domain of theapplication, the acquisition of lexical knowledgemust be repeated whenever the system is transportedto another domain.
For systems which need access tolarge lexicons, some form of at least partial automa-tion of the lexical knowledge acquisition phase isneeded.One type of lexical knowledge which is useful formany natural anguage (NL) tasks is the semantic re-latedness between words of the same or different syn-tactic categories.
Semantic relatedness ubsumeshyponymy, synonymy, and antonymy-incompatibility.
Special forms of relatedness arerepresented in the lexical entries of the WordNet lex-ical database (Miller et al, 1990).
Paradigmaticsemantic relations in WordNet have been used fordiverse NL problems, including disambiguation ofsyntactic structure (Resnik, 1993) and semi-automatic onstruction of a large-scale ontology formachine translation (Knight, 1993).In this paper, we focus on a particular case ofsemantic relatedness: relatedness between adjectiveswhich describe the same property.
We describe atechnique for automatically grouping adjectives ac-cording to their meaning based on a given text cor-pus, so that all adjectives placed in one groupdescribe different values of the same property.
Ourmethod is based on statistical techniques, augmentedwith linguistic information derived from the corpus,and is completely domain independent.
Itdemonstrates how high-level semantic knowledgecan be computed from large amounts of low-levelknowledge (essentially plain text, part-of-speechrules, and optionally syntactic relations).The problem of identifying semantically relatedwords has received considerable attention, both incomputational linguistics (e.g.
in connection withthesaurus or dictionary construction (Sparck-Jones,1986)) and in psychology (Osgood et al, 1957).However, only recently has work been done on theautomatic computation of such relationships fromtext, quantifying similarity between words andclustering them ( (Brown et aL, 1992), (Pereira et al,1993)).
In comparison, our work emphasizes the useof shallow linguistic knowledge in addition to astatistical model and is original in the use of negativeknowledge to constrain the search space.
Further-more, we use a flexible architecture which will allowus to easily incorporate additional knowledge sourcesfor computing similarity.172While our current system does not distinguish be-tween scalar and non-scalar adjectives, it is a firststep in the automatic identification of adjectivalscales, since the scales can be subsequently orderedand the non-scalar adjectives filtered on the basis ofindependent tests, done in part automatically and inpart by hand in a post-editing phase.
The result is asemi-automated system for the compilation of adjec-tival scales.In the following sections, we first provide back-ground on scales, then describe our algorithm indetail, present the results obtained, and finallyprovide a formal evaluation of the results.2.
BACKGROUNDA linguistic scale is a set of words, of the samegrammatical category, which can be ordered by theirsemantic strength or degree of informativeness(Levinson, 1983).
For example, lukewarm, warm,and hot fall along a single adjectival scale since theyindicate a variation in the intensity of temperature ofthe modified noun (at least when used in their non-metaphorical senses; metaphorical usage of scalarwords normally also follows the order of the scale byanalogy).
Scales are not limited to adjectives; for ex-ample, {may, should, must} and {sometimes, often,always} (Horn, 1972) are linguistic scales consistingof auxiliary verbs expressing obligation and of ad-verbs expressing frequency respectively.In the case of adjectives, the above definition iscommonly relaxed to replace the total order amongthe elements of the scale by a partial one, so that theelements of the scale may be partitioned into twogroups (sub-scales), within each of which the order istotal.
The two sub-groups correspond to positive andnegative degrees of the common property that thescale describes.
For example, the set of adjectives{ cold, lukewarm, warm, hot} are normally consideredpart of one scale, even though no direct ordering ofsemantic strength exists between cold and hot.Linguistic scales are known to possess interestingproperties, derived from conventional logical entail-ment on the linear ordering of their elements andfrom Gricean scalar implicature (Levinson, 1983).Despite these properties and their potential usefulnessin both understanding and generating natural lan-guage text, dictionary entries are largely incompletefor adjectives in this regard.
Yet, if systems are to usethe information encoded in adjectival scales forgeneration or interpretation (e.g.
for selecting an ad-jective with a particular degree of semantic strength(Elhadad, 1991, Elhadad, 1993), or for handlingnegation), they must have access to the sets of wordscomprising a scale.Linguists have presented various tests for accept-ing or rejecting a particular scalar relationship be-tween any two adjectives.
For example, Horn (1969)proposed a test using the phrase "x even y"  for twoelements x and y of a totally ordered scale.
MoreI EXTRACT WORD JPATTERNSI .
.
.
MODULE 1 MODULE 2 MODULE nSIMILARITIESWORDSFigure 1: System architecture.refined tests locate the position of an adjective in ascale relative to the neutral element or to the ex-tremes of the scale (Bolinger, 1977).
The commonproblem with these methods is that they are designedto be applied by a human who incorporates the twoadjectives in specific sentential frames (e.g.
"X iswarm, even hot") and assesses the semantic validityof the resulting sentences.
Such tests cannot be usedcomputationally to identify scales in a domain, sincethe specific sentences do not occur frequently enoughin a corpus to produce an adequate description of theadjectival scales in the domain (Smadja, 1991).
Asscales vary across domains, the task of compilingsuch information is compounded.3.
ALGORITHMOur algorithm, whose overall architecture isdepicted in Figure 1, operates in four stages.
First, weextract linguistic data from the parsed corpus in theform of syntactically related word pairs, or, moregenerally, sequences of syntactically related words;this co-occurrence information is processed by a mor-phology component and tabulated.
In the secondstage, the various types of co-occurrence r lationswhich have been identified in the text are forwarded173to a set of independent similarity modules, whichoperate in parallel.
Each similarity module uses somelinguistic criterion to judge the similarity or dis-similarity between any two adjectives, producing areal number between 0 and l; a module may alsorefrain from making any judgement.
The third stagecombines the opinions of the various similaritymodules in a single dissimilarity measure for any pairof adjectives.
Finally, the fourth stage clusters theadjectives into groups according to the dissimilaritymeasure, so that adjectives with a high degree ofpairwise similarity fall in the same cluster (and, con-sequently, adjectives with a low degree of similarityfall in different clusters).The algorithm currently uses two similaritymodules based on two sources of linguistic data: datathat help establish that two adjectives are related, anddata that indicate that two adjectives are unrelated.First, we extract adjective-noun pairs that occur in amodification relation in order to identify the distribu-tion of nouns an adjective modifies and, ultimately,determine which adjectives it is related to.
This isbased on the expectation that adjectives describingthe same property tend to modify approximately thesame set of nouns.
For example, temperature is nor-mally defined for physical objects and we can expectto find that adjectives conveying different values oftemperature will all modify physical objects.
There-fore, our algorithm finds the distribution of nounsthat each adjective modifies and categorizes adjec-tives as similar if they have similar distributions.Second, we use adjective-adjective pairs occur-ring as pre-modifiers within the same NP as a strongindication that the two adjectives do not belong in thesame group.
There are three cases:1.
If both adjectives modify the head nounand the two adjectives are antithetical,the NP would be self-contradictory, asin the scalar sequence hot cold or thenon-scalar red black.2.
For non-antithetical scalar adjectiveswhich both modify the head noun, theNP would violate the Gricean maxim ofManner (Levinson, 1983) since thesame information is conveyed by thestrongest of the two adjectives (e.g.
hotwarm) .3.
Finally, if one adjective modifies theother, the modifying adjective has toqualify the modified one in a differentdimension.
For example, in light blueshirt, blue is a value of the propertycolor, while light indicates the shade 1.The use of multiple types of linguistic data, inINote that sequences such as blue-green are usually hyphenatedand thus better considered as a compound.addition to statistical measures, is a unique propertyof our work and significantly improves the accuracyof our results.
One other published model for group-ing semantically related words (Brown et al, 1992),is based on a statistical model of bigrams andtrigrams and produces word groups using no linguis-tic knowledge, but no evaluation of the results isreported.3.1.
Stage One: Extracting Word PairsDuring the first stage, the system extractsadjective-noun a d adjective-adjective pairs from thecorpus.
To determine the syntactic ategory of eachword, and identify the NP boundaries and the syntac-tic relations among the words, we used the Fidditchparser (Hindle, 1989).
For each NP, we then deter-mine its minimal NP, that part of an NP consisting ofthe head noun and its adjectival pre-modifiers 2.
Wematch a set of regular expressions, consisting of syn-tactic categories and representing the different formsa minimal NP can take, against he NPs.
From theminimal NP, we produce the different pairs of adjec-tives and nouns, assuming that all adjectives modifythe head noun 3.
This assumption is rarely invalid,because a minimal NP with multiple adjectives allmodifying the head noun is far more common than aminimal NP with multiple adjectives where one ofthem modifies another.
Furthermore, minimal NPswith multiple adjectives are relatively rare in the firstplace; most minimal NPs consist simply of a noun oran adjective and a noun.The resulting adjective-adjective and adjective-noun pairs are filtered by a morphology component,which removes pairs that contain erroneous infor-mation (such as mistyped words, proper names, andclosed-class words which may be mistakenly classi-fied as adjectives (e.g.
possessive pronouns)).
Thiscomponent also reduces the number of different pairswithout losing information by transforming words toan equivalent, base form (e.g.
plural nouns are con-verted to singular) so that the expected and actualfrequencies of each pair are higher.
Stage one thenproduces as output a simple list of adjective-adjectivepairs that occurred within the same minimal NP and atable with the observed frequencies of everyadjective-noun combination.
Each row in the tablecontains the frequencies of modified nouns for agiven adjective.2This part of an NP has been used by many researchers (e.g.
(Hobbs et aL, 1993) who call it a noun group), mostly because ofthe relative ase with which it can be identified.3We take into account possessives however and correct theresult, so that the minimal NP (the) tall man's wife will correctlyproduce the pair (tall, man) instead of (tall, wife).1743.2.
Stage Two: Computing SimilaritiesBetween AdjectivesThis stage currently employs two similaritymodules, each of which processes a part of the outputof stage one and produces a measure of similarity foreach possible pair of adjectives.The first module processes the adjective-nounfrequency table; for each possible pair in the table wecompare the two distributions of nouns.
We use arobust non-parametric method to compute thesimilarity between the modified noun distributionsfor any two adjectives, namely Kendall's x coef-ficient (Kendall, 1938) for two random variables withpaired observations.
In our case, the two randomvariables are the two adjectives we are comparing,and each paired observation is their frequency of co-occurrence with a given noun.
Kendall's x coef-ficient compares the two variables by repeatedlycomparing two pairs of their corresponding obser-vations.
Formally, if (Xi,Yi) and (Xj,Yj) are twopairs of observations for the adjectives X and Y onthe nouns i and j respectively, we call these pairsconcordant if Xi>Xj and Yi>Y.
or if Xi<X.
andYi<Yj; otherwise these pairs are ~iscordant.
W/e dis-card ties, that is pairs of observations where Xi=Xj.orYi=Yj.
For example, Table 1 shows the frequenciesobserved for the co-occurrences of the nounscoordination and market and the adjectives globaland international in the test corpus which isdescribed in Section 4.
From the table we observethat for i=coordination, j=market, X=global, andY=international, we have Xi=16 < 24=X: andYi=I9 < 33=Yj, so this particular pair of paired/obser -vations is concordant and contributes positively to thesimilarity between global and international.In general, if the distributions for the two adjec-tives are similar, we expect a large number of concor-dances, and a small number of discordances.Kendall's I: is defined as"c = Pc-Pdwhere Pc and Pd are the probabilities of observing aconcordance or discordance respectively.
~ rangesfrom -1 to +1, with +1 indicating complete concor-dance, -1 complete discordance, and 0 no correlationbetween X and Y.An unbiased estimator of x is the statisticC-QT=- -where n is the number of paired observations in thesample and C and Q are the numbers of observedconcordances and discordances respectively (Wayne,1990).
We compute T for each pair of adjectives, ad-justing for possible ties in the values of each variable,so that our statistic remains an unbiased estimator ofx.
We determine concordances and discordances byglobal internationalcoordination 16 19market 24 33Table 1: Example adjective-noun frequencies.sorting the pairs of observations (noun frequencies)on one of the variables (adjectives), and computinghow many of the (2) pairs of paired observationsagree or disagree with the expected order on the otheradjective.
We normalize the result to the range 0 to 1using a simple linear transformation.The second similarity module utilizes theknowledge offered by the observed adjective-adjective pairs.
We know that the adjectives whichappear in any such pair cannot be part of the samegroup, so the module produces zero similarity for allsuch pairs.
The module does not output any similarityvalue for pairs of adjectives which have not been ob-served together in the same minimal NP.The two modules produce results of a sig-nificantly different character.
The adjective-nounmodule always outputs a similarity value for any pairof adjectives, but these values tend to be around themiddle of the range of possible values; rarely will thepattern of similarity or dissimilarity be strong enoughto produce a value which has a large deviation from0.5.
This compression of the range of the similarityvalues can be attributed to the existence of many tiesand many adjective-noun pairs with low frequencies,as would be expected by Zipf's law (Zipf, 1949).However, the expected number of concordances anddiscordances which can be attributed to chance willbe the same (a random pair can produce a concor-dance or discordance with probability 0.5 for each),so the effect of chance fluctuations on T is not verysignificant.
Furthermore, the robustness of themethod guarantees that it will not be significantlyinfluenced by any outliers (this is true for all rankbased methods).
Therefore, although we cannot havecomplete confidence in a statistical estimate like T,we expect he module to produce useful estimates ofsimilarity.On the other hand, the adjective-adjective moduleproduces similarity values with absolute certainty,since once two adjectives have been seen in the sameNP even once, we can deduce that they do not belongin the same group.
However, this negative knowledgeis computed only for a few of the possible pairs ofadjectives, and it cannot be propagated to more pairsas dissimilarity is not a transitive relation.
As a resultwe can make some inferences with very high con-fidence, but we cannot make very many of them.1753.3.
Stage Three: Combining TheSimilarity EstimatesIn stage three we combine the values produced bythe various similarity modules in stage two using apre-specified algorithm.
The output of this stage is asingle table of dissimilarity values (as required by thenext stage) having one entry for each adjective pair.Currently we have only the two similarity modulesdescribed in the previous subsection, so we employthe following simple algorithm:for any pair of adjectives (x,y) doif the adjective-adjective module has no opinionon (x,y) thendissimilarity = 1 - (the similarity reported by theadjective-noun module)elsedissimilarity = some constant k> 1As can be easily seen, the algorithm has completeconfidence in the results of the adjective-adjectivemodule whenever that module has an opinion; whenit does not, the algorithm uses the similarity valueproduced by the adjective-noun module, after asimple linear transformation is applied to convert it toa dissimilarity.
The choice of the constant k reflectshow undesirable it is to place in the same group twoadjectives which have been observed in the sameminimal NP.
Since we consider the results of theadjective-adjective module more reliable than theadjective-noun module, we use a high value for k,k=10; this practically guarantees that a suggestion bythe adjective-adjective module will be respected bythe clustering algorithm unless the evidence for thecontrary is overwhelming.Note that by placing complete confidence in theoutput of the adjective-adjective module, the algo-rithm of stage three is sensitive to small errors thatthis module may perform.
An incorrect suggestionwould make possibly related adjectives be keptseparate.
However, this problem looks more severethan it really is.
An erroneous opinion produced bythat module must correspond to a violation of one ofthe three linguistic principles listed at the start of thissection; such violations do not occur in carefullywritten English (as is our test corpus of AssociatedPress news reports).
In fact, during the analysis of thecorpus for our test set of adjectives we found no er-roneously identified pairs of adjectives; however, ifthe system is used with a less well written, or evenspoken, corpus, the complete confidence in theadjective-adjective module may need to be reduced.This can be accomplished by taking into account hefrequency of an adjective-adjective pair, and makingour confidence an increasing function of this fre-quency.When new similarity modules, such as the onesdiscussed in Section 6, are added to the system, theabove algorithm will be inadequate for combiningtheir suggestions.
We plan to extend the algorithm tocompute an extended weighted average of thesimilarities and/or dissimilarities produced by thesemodules, and add a separate training componentwhich will determine the appropriate value for theweight of each module.3.4.
Stage Four: Clustering TheAdjectivesIn stage four we form groups of adjectives (a par-tition) according to the combined issimilarity valuescomputed in the previous stage.
We want to find apartition which is optimal, in the sense that adjectiveswith high dissimilarity are placed in different groups.We use a non-hierarchical clustering algorithm, sincesuch algorithms are in general stronger than hierar-chical methods (Kaufman and Rousseeuw, 1990).The number of clusters produced is an inputparameter.
The algorithm uses the exchange method(Spath, 1985) since the more commonly used K-means method (Kaufman and Rousseeuw, 1990) isnot applicable; the K-means method, like all centroidmethods, requires the measure d between the clus-tered objects to be a distance; this means, amongother conditions, that for any three objects x, y, and zthe triangle inequality applies.
However, this in-equality does not necessarily hold for our dis-similarity measure.
If the adjectives x and y were ob-served in the same minimal NP, their dissimilarity isquite large.
If  neither z and x nor z and y were foundin the same minimal NP, then it is quite possible thatthe sum of their dissimilarities could be less than thedissimilarity between x and y.The algorithm tries to produce a partition of theset of adjectives as close as possible to the optimalone.
This is accomplished by minimizing anobjective function ?
which scores a partition P. Theobjective function we use isdp(~ = E \[ 1__~ E d(x,y) \]c~ P I CIx,y~CThe algorithm starts by producing a random par-tition of the adjectives, computing its ?
value andthen for each adjective computing the improvementin ?
for every cluster where it can be moved; theadjective is moved to the cluster that yields the bestimprovement of ?
if there is such a cluster and thenext adjective is considered.
This procedure isrepeated until no more moves lead to an improve-ment of ~.This is a hill-climbing method and therefore isguaranteed to converge, but it may lead to a localminimum of ~, inferior to the global minimum thatcorresponds to the optimal solution.
To alleviate thisproblem, the partitioning algorithm is calledrepeatedly with different random starting partitionsand the best solution in these runs is kept.
As withmany practical optimization problems, computing theoptimal solution is NP-complete (Brucker, 1978).176antitrust newbig oldeconomic politicalfinancial potentialforeign realglobal seriousinternational severelegal staggeringlittle technicalmajor unexpectedmechanicalFigure 2: Adjectives to be grouped.Note that if the problem' s search space had been rela-tively small, then we could have computed the op-timal partition by enumerating all possible solutionsand keeping the best one.
However, again as withmany other practical optimization problems, thesearch space turns out to be intractably large.
Thenumber of possible partitions of n objects to m non-empty subsets with m<n is equal to the correspond-ing Stifling number of the second kind (Knuth,1973), and this number grows exponentially with nfor all but trivial values of m. For example, for ourtest set of adjectives presented in the next section, wehave n=21 and m=9; the corresponding number ofpossible partitions is roughly 1.23 ?
1014.4.
RESULTSWe tested our system on a 8.2 million word cor-pus of stock market reports from the Associated Pressnews wire.
A subset of 21 of the adjectives in thecorpus (Figure 2) was selected for practical reasons(mainly for keeping the evaluation task tractable).We selected adjectives that have one modified nounin common (problem) to ensure some semantic re-latedness, and we included only adjectives that oc-curred frequently so that our similarity measurewould be meaningful.The partition produced by the system for 9clusters appears in Figure 3.
Before presenting a for-mal evaluation of the results, we note that this par-tition contains interesting data.
First, the results con-tain two clusters of gradable adjectives which fall inthe same scale.
Groups 5 and 8 contain adjectivesthat indicate the size, or scope, of a problem; by aug-menting the system with tests to identify when anadjective is gradable, we could separate out these twogroups from other potential scales, and perhaps con-sider combining them.
Second, groups 1 and 6 clearlyidentify separate sets of non-gradable adjectives.
Thefirst contains adjectives that describe the geographi-cal scope of the problem.
Although at first sight wewould classify these adjectives as non-scalar, we ob-served that the phrase international even globalproblem is acceptable while the phrase *global eveninternational problem is not.
These patterns eem to1.
foreign global international2.
old3.
potential4.
new real unexpected5.
little staggering6.
economic financial mechanical politicaltechnical7.
antitrust8.
big major serious evere9.
legalFigure 3: Partition found for 9 clusters.suggest at least some degree of scalability.
On theother hand, group 6 contains non-scalar relational ad-jectives that specify the nature of the problem.
It isinteresting to note here that the clustering algorithmdiscourages long groups, with the expected numberadjectives per cluster being 9---2.33; nevertheless, ofthe evidence for the adjectives in group 6 is strongenough to allow the creation of a group with morethan twice the expected number of members.
Finally,note that even in group 4 which is the weakest groupproduced, there is a positive semantic orrelation be-tween the adjectives new and unexpected.
To sum-marize, the system seems to be able to identify manyof the existent semantic relationships among the ad-jectives, while its mistakes are limited to creatingsingleton groups containing adjectives that are relatedto other adjectives in the test set (e.g., missing thesemantic associations between new-old andpotential-real) and "recognizing" a non-significantrelationship between real and new-unexpected ingroup 4.We produced good results with a relatively smallcorpus of 8.2 million words 4, out of which only34,359 total / 3,073 distinct adjective-noun pairs in-volving 1,509 distinct nouns were relevant to our testset of 21 adjectives (Figure 2).
The accuracy of theresults can be improved if a larger, homogeneous cor-pus is used to provide the raw data.
Also, we canincrease the size of the adjective-noun and adjective-adjective data that we are using if we introduce moresyntactic patterns in stage one to extract more com-plex cases of pairs.
Furthermore, some of the associa-tions between adjectives that the system reports ap-pear to be more stable than others; these associationsremain in the same group when we vary the numberof clusters in the partition.
We have noticed that ad-jectives with a higher degree of semantic content(e.g.
international or severe) appear to form more4Corpora up to 366 million words have been used for similarclassification tasks.177Answer should be Yes Answer should be NoThe system says Yes a bThe system says No c dTable 2: Contingency table model for evaluation.stable associations than relatively semantically emptyadjectives (e.g.
little or real).
This observation can beused to filter out adjectives which are too general tobe meaningfully clustered in groups.5.
EVALUATIONTo evaluate the performance of our system wecompared its output to a model solution for theproblem designed by humans.
Nine human judgeswere presented with the set of adjectives to be par-titioned, a description of the domain, and a simpleexample.
They were told that clusters should notoverlap but they could select any number of clusters(the judges used from 6 to 11 clusters, with anaverage of 8.565 and a sample standard eviation of1.74).
Note that this evaluation method differs sig-nificantly from the alternative method of asking thehumans to directly estimate the goodness of thesystem's results (e.g.
(Matsukawa, 1993)).
It requiresan explicit construction of a model from the humanjudge and places the burden of the comparison be-tween the model and the system's output on the sys-tem instead of the judge.
It has been repeatedlydemonstrated that in complex evaluation taskshumans can easily find arguments to support ob-served data, leading to biased results and to an infla-tion of the evaluation scores.To score our results, we converted the com-parison of two partitions to a series of yes-no ques-tions, each of which has a correct answer (as dictatedby the model) and an answer assigned by the system.For each pair of adjectives, we asked if they fell inthe same cluster ( "yes")  or not ("no") .
Since humanjudges did not always agree, we used fractionalvalues for the correctness of each answer instead of 0("incorrect") and 1 ("correct").
We defined the cor-rectness of each answer as the relative frequency ofthe association between the two adjectives among thehuman models and the incorrectness of each answeras 1 - correctness; in this way, associations receive acorrectness value proportional to their popularityamong the human judges.
For example, in the sampleset of adjectives discussed in the previous ection, theassociation (foreign, international) received a cor-rectness value of 1, since all the humans placed thesetwo adjectives in the same group, while the associa-tion (legal, severe) received a correctness value of 0.The pair (economic, political) on the other handreceived a correctness value of 0.67, since two thirdsof the judges placed the two adjectives in the samegroup.
Once correctness and incorrectness valueshave been defined, we can generalize measures uchas "the number of correct associations retrieved bythe system" by using summation of those values in-stead of counting.
Then the contingency table model(Swets, 1969), widely used in Information Retrievaland Psychology, is applicable.
Referring to the clas-sification of the yes-no answers in Table 2, the fol-lowing measures are defined :a?
Recall = ?
100%a+ca?
Precision = ?
100%a+bb?
Fallout = b~--d" 100%In other words, recall is the percentage of correct"yes"  answers that the system found among themodel "yes"  answers, precision is the percentage ofcorrect "yes"  answers among the total of "yes"answers that the system reported, and fallout is thepercentage of incorrect "yes"  answers relative to thetotal number of "no"  answers 6.
Note that in ourgeneralized contingency table model, the symbols a,b, c, and d do not represent numbers of observedassociations but rather sums of correctness or incor-rectness values.
These sums use correctness valuesfor the quantities in the first column of Table 2 andincorrectness values for the quantities in the secondcolumn of Table 2.
Furthermore, the summation isperformed over all pairs reported or not reported bythe system for quantities in the first or second row ofTable 2 respectively.
Consequently, the informationtheoretic measures represent the generalized counter-parts of their original definitions.
In the case of per-fect agreement between the models, or of only onemodel, the generalized measures reduce to theiroriginal definitions.We also compute a combined measure for recalland precision, the F-measure (Van Rijsbergen, 1979),which always takes a value between the values ofrecall and precision, and is higher when recall andprecision are closer; it is defined asF - (132+1)x Precision x Recall132 x Precision + Recall5This is the reason that we presented the partition with 9clusters, as this is the closest integer to the average number ofclusters used by the humans.6Another measure used in information retrieval,overgeneration, is in our case always equal to (100 - precision)%.178Recall Precision Fallout F-measure (13=1)7 clusters 50.78% 43.56% 7.48% 46.89%8 clusters 37.31% 38.10% 6.89% 37.70%9 clusters 49.74% 46.38% 6.54% 48.00%10 clusters 35.23% 41.98% 5.54% 38.31%Table 3: Evaluation results.where 13 is the weight of recall relative to precision;we use 13=1.0, which corresponds to equal weightingof the two measures.The results of applying our evaluation method tothe system output (Figure 3) are shown in Table 3,which also includes the scores obtained for severalother sub-optimal choices of the number of clusters.We have made these observations related to theevaluation mechanism:1.
Recall is inversely related to fallout andprecision.
Decreasing the number ofclusters generally increases the recalland fallout and simultaneouslydecreases precision.2.
We have found fallout to be a bettermeasure overall than precision, since, inaddition to its decision-theoretic ad-vantages (Swets, 1969), it appears to bemore consistent across evaluations ofpartitions with different numbers ofclusters.
This has also been reported byother researchers in different evaluationproblems (Lewis and Tong, 1992).3.
The problem of assessing the meaningof the evaluation scores in an absolutesense is a non-trivial one.
For example,there has been increasing concern thatthe scoring methods used for evaluatingthe goodness of parsers are producingvalues which seem extremely good (inthe >90% range), while in fact the parsetrees produced are not so satisfactory;the blame for this inflation of the scorescan be assigned to an inadequate com-parison technique, which essentiallyconsiders a tree fragment correct whenit is a part of (although not exactlymatching) the corresponding fragmentin the model.
For other tasks, such aspart-of-speech assignment to free text,the comparison techniques are sound,but very high levels of performance(e.g, 90%) can be obtained by a zero-parameter model which operates at ran-dom; clearly this makes the assessmentof the significance of an improvementover the base line of the random algo-rithm much harder.As a consequence of point (3) made above, weneed to understand the significance of the scoresproduced by our evaluation methods (for example,the limits of their ranges) before trying to interpretthem.
There are theoretical principles which indicatethat the evaluation metrics will produce lower valuesmuch more easily than higher ones.
Because of themultiple models used, perfect scores are not attain-able.
Also, because ach pair of adjectives in a clusteris considered an observed association, the relation-ship between the number of associations produced bya cluster and the number of adjectives in the cluster isnot linear (a cluster with k adjectives will produce(k) =O (k 2) associations).
This leads to lower valuesof recall, since moving a single adjective out of acluster with k elements in the model will cause thesystem to miss k-1 associations.
As an example ofthis phenomenon, consider the hypothetical (single)model and partition of Figure 4; while the partitiondiffers from the model only in that the first clusterhas been split into two, the recall score abruptly fallsto 50%.In order to provide empirical evidence in additionto the theoretical discussion above, and be able toestimate an upper bound on the values of the evalua-tion metrics, we evaluated each human model againstall the other human models, using the same evalua-tion method which was used for the system; theresults ranged from 38 to 72% for recall, 1 to 12% forfallout, 38 to 81% for precision, and, covering aModel:1.
ABCDE2.
FG3.
H IPartition:1.
ABC2.
DE3.
FG4.
H IFigure 4: A hypothetical model where a smallperturbation leads to a recall scoreof 50%.179Recall Precision Fallout F-measure (13=1)Without negative knowledge 33.16% 32.32% 7.90% 32.74%With both modules 49.74% 46.38% 6.54% 48.00%Table 4: Comparison of the system's performance (9clusters) with and without he negative knowledge module.remarkably short range, 49 to 59% for F-measure 7,indicating that the performance of the system is notfar behind human performance.In order to provide a lower bound for the evalua-tion metrics and thus show that the system's coresare not close to the scores of the human judgessimply by chance, we performed a Monte Carloanalysis (Rubinstein, 1981) for the evaluationmetrics, by repeatedly creating random partitions ofthe sample adjectives and evaluating the results.
Thenwe estimated a smoothed probability density functionfor each metric from the resulting histograms; theresults obtained are shown in Figure 5 for F-measureand fallout using 9 clusters.
We observed that thesystem's performance (indicated by a square in thediagrams) was significantly better than what wewould expect under the null hypothesis of randomperformance; the probability of getting a better par-tition than the system's is extremely small for allmetrics (no occurrence in 20,000 trials) except forfallout, for which a random system may be better4.9% of the time.
The estimated ensity functionsalso show that the metrics are severely constrained bythe structure imposed by the clustering as they tend topeak at some point and then fall rapidly.Finally, we performed another study to quantifythe impact of using negative knowledge obtainedfrom adjective-adjective pairs.
We ran our system ina mode where the suggestions of the adjective-adjective module were ignored (i.e.
stage threesimply passed to the output he similarities computedby the adjective-noun module, after converting themto dissimilarities), and evaluated the results produced.The values of the metrics for the partition with 9clusters appear in Table 4, alongside the correspond-ing values produced when the system uses bothmodules.
When both modules are used, we can see asignificant improvement of about 15 points, which isa 43% to 50% improvement for all metrics (exceptfor fallout where the improvement is about 17%).This represents a definite improvement even thoughfor our test set of 21 adjectives (Figure 2) we ob-served in our corpus only 41 distinct adjective-adjective pairs, out of a possible (221)=210 pairs.
AI-7Thus indicating that human models which fared well on theprecision metric tended to perform badly on recall, and vice versa;remember that he values of the metrics are related to the numberof clusters used, and that he human judges were allowed to selectthe number of clusters they considered most appropriate; con-sequently, the models with high recall/low precision are the oneswith a small number of clusters, while the opposite pattern ofscores characterizes the models with a large number of clusters.though the observed pairs represent only 19.52% ofthe possible pairs, their importance is considerable.Note that the sparsity of the adjective-adjectivepairs does not allow us to perform a comparablestudy for the partition produced using the adjective-adjective module alone, since such a partition wouldbe largely determined by chance.6.
CONCLUSIONS ANDFUTURE WORKWe have described a system for extracting roupsof semantically related adjectives from large text cor-pora, with a flexible architecture which allows formultiple knowledge sources influencing similarity to0 10 20 ~tO 40 50F-me.urn (9 durum)0 S 10 15 20Falo~ {9 c tu~m)Figure 5: Estimated probability densities forF-measure and fallout with 9 clusters.180be easily incorporated into the system.
Our evalua-tion reveals that it has significantly high performancelevels, comparable to humans, using only a relativelysmall amount of input data; in addition, it shows theusefulness of negative knowledge, an original featureof our approach.
The system's results can be filteredto produce scalar adjectives that are applicable in anygiven domain.
Furthermore, while we havedemonstrated the algorithm on adjectives, it can bedirectly applied to other word classes once sources oflinguistic information for judging their similarityhave been identified.Our immediate plans are to incorporate moresimilarity modules into stage two of the system andadd a training component to stage three so that therelative weights of the various modules can be es-timated.
We have identified several additionalsources of linguistic knowledge which look promis-ing, namely pairs of adjectives eparated by connec-tives and adverb-adjective pairs.
We also plan to ex-tend the adjective-noun module to cover adjectives inpredicative positions, in addition to our current use ofattributive adjectives.
These extensions not only willprovide us with a better way of exploiting the infor-mation in the corpus but may also help us categorizethe adjectives as relational or attributive (Levi, 1978);such a categorization may be useful in classifyingthem as either scalar or non-scalar.
For determiningwhether a group of adjectives is scalar, we also planto use the gradability of the adjectives as observed inthe corpus.
In addition, we are exploring tests fordetermining whether two adjectives are antonymous,essentially in the opposite direction of the work byJusteson and Katz (1991) , and tests for comparingthe relative semantic strength of two adjectives.Furthermore, we plan to consider alternativeevaluation methods and test our system on a muchlarger set of adjectives.
That was not done for thecurrent evaluation because of the difficulty forhumans of constructing large models.
We are con-sidering an evaluation method which would use athesaurus to judge similarity, as well as a supplemen-tary method based on mathematical properties of theclustering.
Neither of these methods would accessany human models.
The mathematical method, whichuses cluster silhouettes and the silhouette coefficient(Kaufman and Rousseeuw, 1990), can also be used toautomatically determine the proper number ofclusters, one of the hardest problems in clusteranalysis.
We also plan a formal study to evaluate theappropriateness of the clustering method used, bycomputing and evaluating the results when a hierar-chical algorithm is employed instead in stage four.Eventually, we plan to evaluate the system's outputby using it to augment adjective ntries in a lexiconand test the augmented lexicon in an application suchas language generation.ACKNOWLEDGEMENTSThis work was supported jointly by DARPA andONR under contract N00014-89-J-1782, by NSFGER-90-24069, and by New York State Center forAdvanced Technology Contract NYSSTF-CAT(91)-053.
We wish to thank Diane Litman andDonald Hindle for providing us with access to theFidditch parser at AT&T Bell Labs, and KarenKukich and Frank Smadja for providing us with ac-cess to the Associated Press news wire corpus.Finally, we thank Rebecca Passonneau and theanonymous reviewers for providing us with usefulcomments on earlier versions of the paper.REFERENCESBolinger, D. (1977).
Neutrality, Norm, and Bias.Bloomington, IN: Indiana University LinguisticsClub.Brown P., Della Pietra V., deSouza P., Lai J., and MercerR.
(1992).
Class-based n-gram Models of NaturalLanguage.
Computational Linguistics, 18:4,467-479.Brucker, P. (1978).
On the complexity of clusteringproblems.
In Henn, R., Korte, B., and Oletti,W.
(Eds.
), Lecture Notes in Economics and Math-ematical Systems.
Optimierung und OperationsResearch.
Berlin: Springer.
Quoted in (Garey andJohnson, 1979).Elhadad, Michael.
(1991).
Generating Adjectives to Ex-press the Speaker' s Argumentative Intent.Proceedings of 9th National Conference on ArtificialIntelligence (AAA191).
Anaheim.Elhadad, Michael.
(1993).
Using Argumentation toControlLexical Choice: A Unification-BasedImplementation.
Doctoral dissertation, ComputerScience Department, Columbia University.Garey, M.R., and Johnson, D.S.
(1979).
Computers andIntractability: A Guide to the Theory ofNP-Completeness.
W.H.
Freeman.Hindle, D. M. (1989).
Acquiring Disambiguation Rulesfrom Text.
Proceedings of the 27th meeting of theAssociation for Computational Linguistics.
Van-couver, B.C..Hobbs J.R., Appelt D., Bear J., Israel D., Kameyama M.,and Tyson M. (1993).
FASTUS: A System for Extract-ing Information from Text.
Proceedings of theARPA Workshop on Human Language Technology.ARPA Information Science and Technology Office.Horn, L. (1969).
A Presuppositional Analysis of Only andEven.
Papers from the Fifth Regional Meeting.Chicago Linguistics Society.Hom, LR.
(1972).
On the Semantic Properties of theLogical Operators in English.
Bloomington, IN: In-diana University Linguistics Club.Justeson, J.S.
and Katz, S.M.
(1991).
Co-occurences of181Antonymous Adjectives and Their Contexts.Computational Linguistics, 17:1, 1-19.Kaufman, L. and Rousseeuw, P.J.
(1990).
Wiley Series inProbability and Mathematical Statistics.
FindingGroups in Data: An Introduction to Cluster Analysis.New York: Wiley.Kendall, M.G.
(1938).
A New Measure of Rank Correla-tion.
Biometrika, 30, 81-93.Knight, Kevin.
(1993).
Building a Large Ontology forMachine Translation.
Proceedings of the ARPAWorkshop on Human Language Technology.
ARPAInformation Science and Technology Office.Knuth, D.E.
(1973).
The Art of Computer Programming.Vol.
1: FundamentalAlgorithms (2nd ed.).
Reading,Mass.
: Addison-Wesley.Levi, Judith N. (1978).
The Syntax and Semantics of Com-plex Nominals.
New York: Academic Press.Levinson, S.C. (1983).
Pragmatics.
Cambridge, England:Cambridge University Press.Lewis, D. and Tong, R. (1992).
Text Filtering in MUC-3and MUC-4.
Proceedings of the Fourth MessageUnderstanding Conference (MUC-4).
DARPASoftware and Intelligent Systems Technology Office.Matsukawa, Tomoyoshi.
(1993).
Hypothesizing Word As-sociation From Untagged Text.
Proceedings of theARPA Workshop on Human Language Technology.ARPA Information Science and Technology Office.Miller, G.A.
(ed.).
(1990).
WordNet: An On-Line LexicalDatabase.
International Journal of Lexicography(special issue), 3:4, 235-312.Osgood, C.E., Suci, G.S.
and Tannenbaum, P.H.
(1957).The measurement of meaning.
Urbana, Illinois:University of Illinois Press.Pereira F., Tishby N., and Lee L. (1993).
DistributionalClustering of English Words.
Proceedings of the31st Conference of the ACL.
Columbus, Ohio: As-sociation for Computational Linguistics.Resnik, Philip.
(1993).
Semantic Classes and SyntacticAmbiguity.
Proceedings of the ARPA Workshop onHuman Language Technology.
ARPA InformationScience and Technology Office.Rubinstein, R.Y.
(1981).
Wiley Series in Probability andMathematical Statistics.
Simulation and the MonteCarlo method.
New York: Wiley.Smadja, F. (1991).
Retrieving Collocational Knowledgefrom Textual Corpora.
An Application: LanguageGeneration.
Doctoral dissertation, Department ofComputer Science, Columbia University.Sparck-Jones, Karen.
(1986).
Synonymy and SemanticClassification.
Edinburgh, Great Britain: EdinburghUniversity Press.
Based on the author's Ph.D. thesis,University of Cambridge, 1964.Spath, Helmuth.
(1985).
Ellis Horwood Series in Com-puters and their Applications.
Cluster Dissectionand Analysis: Theory, FORTRAN Programs,Examples.
Chichester, West Sussex, England: EllisHorwood.Swets, J.A.
(January 1969).
Effectiveness of InformationRetrieval Methods.
American Documentation, 20,72-89.Van Rijsbergen, C.J.
(1979).
Information Retrieval (2nded.).
London: Butterwoths.Wayne, D.W. (1990).
The Duxbury Advanced Series inStatistics and Decision Sciences.
Applied Non-parametric Statistics (2nd ed.).
Boston: PWS-KENT Publishing Company.Zipf, G.K. (1949).
Human Behavior and the Principle ofLeast Effort: An Introduction to Human Ecology.Reading, Mass.
: Addison-Wesley.182
