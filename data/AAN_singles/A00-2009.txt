A Simple Approach to Building Ensembles of Naive BayesianClassifiers for Word Sense DisambiguationTed PedersenDepar tment  of Computer  Sc ienceUn ivers i ty  of M innesota  Du luthDu luth ,  MN 55812 USAtpederse?d, umn.
eduAbst ractThis paper presents a corpus-based approach toword sense disambiguation that builds an ensembleof Naive Bayesian classifiers, each of which is basedon lexical features that represent co-occurring wordsin varying sized windows of context.
Despite thesimplicity of this approach, empirical results disam-biguating the widely studied nouns line and interestshow that such an ensemble achieves accuracy rival-ing the best previously published results.1 Int roduct ionWord sense disambiguation is often cast as a prob-lem in supervised learning, where a disambiguator isinduced from a corpus of manually sense-tagged textusing methods from statistics or machine learning.These approaches typically represent the context inwhich each sense-tagged instance of a word occurswith a set of linguistically motivated features.
Alearning algorithm induces a representative modelfrom these features which is employed as a classifierto perform disambiguation.This paper presents a corpus-based approach thatresults in high accuracy by combining a number ofvery simple classifiers into an ensemble that per-forms disambiguation via a majority vote.
This ismotivated by the observation that enhancing the fea-ture set or learning algorithm used in a corpus-basedapproach does not usually improve disambiguationaccuracy beyond what can be attained with shallowlexical features and a simple supervised learning al-gorithm.For example, a Naive Bayesian classifier (Dudaand Hart, 1973) is based on a blanket assumptionabout the interactions among features in a sense-tagged corpus and does not learn a representativemodel.
Despite making such an assumption, thisproves to be among the most accurate techniquesin comparative studies of corpus-based word sensedisambiguation methodologies (e.g., (Leacock et al,1993), (Mooney, 1996), (Ng and Lee, 1996), (Pealer-sen and Bruce, 1997)).
These studies represent thecontext in which an ambiguous word occurs with awide variety of features.
However, when the con-tribution of each type of feature to overall accuracyis analyzed (eg.
(Ng and Lee, 1996)), shallow lexi-cal features uch as co-occurrences and collocationsprove to be stronger contributors to accuracy thando deeper, linguistically motivated features uch aspart-of-speech and verb-object relationships.It has also been shown that the combined accuracyof an ensemble of multiple classifiers is often signifi-cantly greater than that of any of the individual clas-sifiers that make up the ensemble (e.g., (Dietterich,1997)).
In natural language processing, ensembletechniques have been successfully applied to part-of-speech tagging (e.g., (Brill and Wu, 1998)) andparsing (e.g., (Henderson and Brill, 1999)).
Whencombined with a history of disambiguation successusing shallow lexical features and Naive Bayesianclassifiers, these findings suggest hat word sense dis-ambiguation might best be improved by combiningthe output of a number of such classifiers into anensemble.This paper begins with an introduction to theNaive Bayesian classifier.
The features used to rep-resent the context in which ambiguous words occurare presented, followed by the method for selectingthe classifiers to include in the ensemble.
Then, theline and interest data is described.
Experimental re-sults disambiguating these words with an ensembleof Naive Bayesian classifiers are shown to rival pre-viously published results.
This paper closes with adiscussion of the choices made in formulating thismethodology and plans for future work.2 Na ive  Bayes ian  C lass i f ie rsA Naive Bayesian classifier assumes that all the fea-ture variables representing a problem are condition-ally independent given the value of a classificationvariable.
In word sense disambiguation, the contextin which an ambiguous word occurs is represented bythe feature variables (F1, F2, .
.
.
,  F~) and the senseof the ambiguous word is represented by the classi-fication variable (S).
In this paper, all feature vari-ables Fi are binary and represent whether or not aparticular word occurs within some number of wordsto the left or right of an ambiguous word, i.e., a win-63dow of context.
For a Naive Bayesian classifier, thejoint probability of observing a certain combinationof contextual features with a particular sense is ex-pressed as:np(F~, F~,..., Fn, S) = p(S) H p(FilS)i=1The parameters of this model are p(S) andp(Fi\]S).
The sufficient statistics, i.e., the summariesof the data needed for parameter estimation, are thefrequency counts of the events described by the in-terdependent variables (Fi, S).
In this paper, thesecounts are the number of sentences in the sense-tagged text where the word represented by Fi oc-curs within some specified window of context of theambiguous word when it is used in sense S.Any parameter that has a value of zero indicatesthat the associated word never occurs with the spec-ified sense value.
These zero values are smoothedby assigning them a very small default probability.Once all the parameters have been estimated, themodel has been trained and can be used as a clas-sifier to perform disambiguation by determining themost probable sense for an ambiguous word, giventhe context in which it occurs.2.1 Representation of ContextThe contextual features used in this paper are bi-nary and indicate if a given word occurs within somenumber of words to the left or right of the ambigu-ous word.
No additional positional information iscontained in these features; they simply indicate ifthe word occurs within some number of surroundingwords.Punctuation and capitalization are removed fromthe windows of context.
All other lexical items areincluded in their original form; no stemming is per-formed and non-content words remain.This representation of context is a variation onthe bag-of-words feature set, where a single windowof context includes words that occur to both the leftand right of the ambiguous word.
An early use ofthis representation is described in (Gale et al, 1992),where word sense disambiguation is performed witha Naive Bayesian classifier.
The work in this pa-per differs in that there are two windows of context,one representing words that occur to the left of theambiguous word and another for those to the right.2.2 Ensembles  of  Naive Bayes ian  Classif iersThe left and right windows of context have nine dif-ferent sizes; 0, 1, 2, 3, 4, 5, 10, 25, and 50 words.The first step in the ensemble approach is to train aseparate Naive Bayesian classifier for each of the 81possible combination of left and right window sizes.Naive_Bayes (1,r) represents a classifier where themodel parameters have been estimated based on Ire-quency counts of shallow lexical features from twowindows of context; one including I words to the leftof the ambiguous word and the other including rwords to the right.
Note that Naive_Bayes (0,0) in-cludes no words to the left or right; this classifier actsas a majority classifier that assigns every instance ofan ambiguous word to the most frequent sense inthe training data.
Once the individual classifiers aretrained they are evaluated using previously held-outtest data.The crucial step in building an ensemble is select-ing the classifiers to include as members.
The ap-proach here is to group the 81 Naive Bayesian clas-sifiers into general categories representing the sizesof the windows of context.
There are three suchranges; narrow corresponds to windows 0, 1 and 2words wide, medium to windows 3, 4, and 5 wordswide, and wide to windows 10, 25, and 50 wordswide.
There are nine possible range categories sincethere are separate left and right windows.
For exam-ple, Naive_Bayes(1,3) belongs to the range category(narrow, medium) since it is based on a one wordwindow to the left and a three word window to theright.
The most accurate classifier in each of thenine range categories i  selected for inclusion in theensemble.
Each of the nine member classifiers votesfor the most probable sense given the particular con-text represented by that classifier; the ensemble dis-ambiguates by assigning the sense that receives amajority of the votes.3 Exper imenta l  DataThe line data was created by (Leacock et al, 1993)by tagging every occurrence of line in the ACL/DCIWall Street Journal corpus and the American Print-ing House for the Blind corpus with one of six pos-sible WordNet senses.
These senses and their fre-quency distribution are shown in Table 1.
This datahas since been used in studies by (Mooney, 1996),(Towell and Voorhees, 1998), and (Leacock et al,1998).
In that work, as well as in this paper, a subsetof the corpus is utilized such that each sense is uni-formly distributed; this reduces the accuracy of themajority classifier to 17%.
The uniform distributionis created by randomly sampling 349 sense-taggedexamples from each sense, resulting in a training cor-pus of 2094 sense-tagged sentences.The interest data was created by (Bruce andWiebe, 1994) by tagging all occurrences of interestin the ACL/DCI Wall Street Journal corpus withsenses from the Longman Dictionary of Contempo-rary English.
This data set was subsequently usedfor word sense disambiguation experiments by (Ngand Lee, 1996), (Pedersen et al, 1997), and (Peder-sen and Bruce, 1997).
The previous tudies and thispaper use the entire 2,368 sense-tagged sentence cor-pus in their experiments.
The senses and their ire-64sense countproduct 2218written or spoken text 405telephone connection 429formation of people or things; queue 349an artificial division; boundary 376a thin, flexible object; cord 371total 4148Table 1: Distribution of senses for line - the exper-iments in this paper and previous work use a uni-formly distributed subset of this corpus, where eachsense occurs 349 times.sense countmoney paid for the use of money 1252a share in a company or business 500readiness to give attention 361advantage, advancement or favor 178activity that one gives attention to 66causing attention to be given to 11total 2368Table 2: Distribution of senses for interest - the ex-periments in this paper and previous work use theentire corpus, where each sense occurs the numberof times shown above.quency distribution are shown in Table 2.
Unlikeline, the sense distribution is skewed; the majoritysense occurs in 53% of the sentences, while the small-est minority sense occurs in less than 1%.4 Experimental  Resu l tsEighty-one Naive Bayesian classifiers were trainedand tested with the line and interest data.
Five-fold cross validation was employed; all of the sense-tagged examples for a word were randomly shuffledand divided into five equal folds.
Four folds wereused to train the Naive Bayesian classifier while theremaining fold was randomly divided into two equalsized test sets.
The first, devtes t ,  was used to eval-uate the individual classifiers for inclusion in the en-semble.
The second, tes t ,  was used to evaluate theaccuracy of the ensemble.
Thus the training datafor each word consists of 80% of the available sense-tagged text, while each of the test sets contains 10%.This process is repeated five times so that eachfold serves as the source of the test data once.
Theaverage accuracy of the individual Naive Bayesianclassifiers across the five folds is reported in Tables3 and 4.
The standard deviations were between .01and .025 and are not shown given their relative con-sistency.65Each classifier is based upon a distinct representa-tion of context since each employs a different com-bination of right and left window sizes.
The sizeand range of the left window of context is indicatedalong the horizontal margin in Tables 3 and 4 whilethe right window size and range is shown along thevertical margin.
Thus, the boxes that subdivide achtable correspond to a particular ange category.
Theclassifier that achieves the highest accuracy in eachrange category is included as a member of the ensem-ble.
In case of a tie, the classifier with the smallesttotal window of context is included in the ensemble.The most accurate single classifier for line isNaive_Bayes (4,25), which attains accuracy of 84%The accuracy of the ensemble created from the mostaccurate classifier in each of the range categories is88%.
The single most accurate classifier for interestis Naive._Bayes(4,1), which attains accuracy of 86%while the ensemble approach reaches 89%.
The in-crease in accuracy achieved by both ensembles overthe best individual classifier is statistically signifi-cant, as judged by McNemar's test with p = .01.4.1 Compar i son  to  P rev ious  Resu l tsThese experiments use the same sense-tagged cor-pora for interest and line as previous tudies.
Sum-maries of previous results in Tables 5 and 6 showthat the accuracy of the Naive Bayesian ensembleis comparable to that of any other approach.
How-ever, due to variations in experimental methodolo-gies, it can not be concluded that the differencesamong the most accurate methods are statisticallysignificant.
For example, in this work five-fold crossvalidation is employed to assess accuracy while (Ngand Lee, 1996) train and test using 100 randomlysampled sets of data.
Similar differences in train-ing and testing methodology exist among the otherstudies.
Still, the results in this paper are encourag-ing due to the simplicity of the approach.4.1.1 In teres tThe interest data was first studied by (Bruce andWiebe, 1994).
They employ a representation ofcontext that includes the part-of-speech of the twowords surrounding interest, a morphological featureindicating whether or not interest is singular or plu-ral, and the three most statistically significant co-occurring words in the sentence with interest, as de-termined by a test of independence.
These featuresare abbreviated as p-o-s, morph, and co-occur inTable 5.
A decomposable probabilistic model is in-duced from the sense-tagged corpora using a back-ward sequential search where candidate models areevaluated with the log-likelihood ratio test.
The se-lected model was used as a probabilistic lassifier ona held-out set of test data and achieved accuracy of78%.The interest data was included in a study by (Ngwidemediumnarrow50 .6325 .6310 .625 .614 .603 .582 .531 .420 .140.73 .80.74 .80.75 .81.75 .80.73 .80.73 .79.71 .79.68 .78.58 .73.82 .83.82 .s4.82 .83.81 .82.82 .82.82 .83.81 .82.79 .80.77 .79.83 .83.83 .83.83 .83.82 .82.82 .82.83 .82.82 .81.79 .80.79 .79.83 .83.83 .83.83 .84.82 .83.82 .82.81 .82.81 .81.81 .81.79 .801 2 3 4 5 10 25 50narrow medium wideTable 3: Accuracy of Naive Bayesian classifiers for line evaluated with the devtes t  data.
The italicizedaccuracies are associated with the classifiers included in the ensemble, which attained accuracy of 88% whenevaluated with the tes t  data.widemediumnarrow50 .7425 .7310 .755 .734 .723 .702 .661 .630 .530.80 .82.80 .82.82 .84.83 .85.83 .85.84 .86.83 .85.82 .85.72 .771 2nar row.83 .83 .83.83 .83 .83?
84 .84 .84.86 .85 .85.85 .84 .84.86 .86 .85.82 .80 .81.81 .80 .80.82 .81 .81.83 .81 .81.83 .81 .8O.83 .81 .80.86 .86 .84 .83 .80 .80.85 .86 .85 .82 .81 .80.78 .79 .77 .77 .76 .753 4 5 10 25 50medium wideTable 4: Accuracy of Naive Bayesian classifiers for interest evaluated with the devtes t  data.
The italicizedaccuracies are associated with the classifiers included in the ensemble, which attained accuracy of 89% whenevaluated with the tes t  data.and Lee, 1996), who represent he context of anambiguous word with the part-of-speech of threewords to the left and right of interest, a morpho-logical feature indicating if interest is singular orplural, an unordered set of frequently occurringkeywords that surround interest, local collocationsthat include interest, and verb-object syntactic re-lationships.
These features are abbreviated p-o-s,morph, co-occur, collocates, and verb-obj in Table5.
A nearest-neighbor classifier was employed andachieved an average accuracy of 87% over repeatedtrials using randomly drawn training and test sets.
(Pedersen et al, 1997) and (Pedersen and Bruce,1997) present studies that utilize the original Bruceand Wiebe feature set and include the interest data.The first compares a range of probabilistic modelselection methodologies and finds that none outper-form the Naive Bayesian classifier, which attains ac-curacy of 74%.
The second compares a range of ma-chine learning algorithms and finds that a decisiontree learner (78%) and a Naive Bayesian classifier(74%) are most accurate.664.1.2 LineThe line data was first studied by (Leacock et al,1993).
They evaluate the disambiguation accuracyof a Naive Bayesian classifier, a content vector, anda neural network.
The context of an ambiguousword is represented by a bag-of-words where thewindow of context is two sentences wide.
This fea-ture set is abbreviated as 2 sentence b-o-w in Table6.
When the Naive Bayesian classifier is evaluatedwords are not stemmed and capitalization remains.However, with the content vector and the neural net-work words are stemmed and words from a stop-listare removed.
They report no significant differencesin accuracy among the three approaches; the NaiveBayesian classifier achieved 71% accuracy, the con-tent vector 72%, and the neural network 76%.The line data was studied again by (Mooney,1996), where seven different machine learningmethodologies are compared.
All learning algo-rithms represent the context of an ambiguous wordusing the bag-of-words with a two sentence windowof context.
In these experiments words from a stop-Naive Bayesian EnsembleNg ~: Lee, 1996Bruce & Wiebe, 1994Pedersen & Bruce, 1997accuracy89%87%78%78%74%methodensemble of 9nearest neighbormodel selectiondecision treenaive bayesfeature setvarying left & right b-o-wp-o-s, morph, co-occurcollocates, verb-objp-o-s, morph, co-occurp-o-s, morph, co-occurTable 5: Comparison to previous results for interestNaive Bayesian EnsembleTowell & Voorhess, 1998Leacock, Chodor0w, & Miller, 1998Leacock, Towell, & Voorhees, 1993Mooney, 1996accuracy88%87%84%76%72%71%72%71%methodensemble oi ~ 9feature setvarying left & right bSo-wneural net local ~z topical b-o-w, p-o-snaive bayes local & topical b-o-w, p.-o-sneural net 2 sentence b-o-wcontent vectornaive bayesnaive bayes 2 sentence b-o-wperceptronTable 6: Comparison to previous results for linelist are removed, capitalization is ignored, and wordsare stemmed.
The two most accurate methods inthis study proved to be a Naive Bayesian classifier(72%) and a perceptron (71%).The line data was recently revisited by both (Tow-ell and Voorhees, 1998) and (Leacock et al, 1998).The former take an ensemble approach where theoutput from two neural networks is combined; onenetwork is based on a representation of local con-text while the other represents topical context.
Thelatter utilize a Naive Bayesian classifier.
In bothcases context is represented by a set of topical andlocal features.
The topical features correspond tothe open-class words that occur in a two sentencewindow of context.
The local features occur within awindow of context hree words to the left and rightof the ambiguous word and include co-occurrencefeatures as well as the part-of-speech of words inthis window.
These features are represented as lo-cal & topical b-o-w and p-o-s in Table 6.
(Towelland Voorhees, 1998) report accuracy of 87% while(Leacock et al, 1998) report accuracy of 84%.5 D iscuss ionThe word sense disambiguation e sembles in this pa-per have the following characteristics:?
The members of the ensemble are NaiveBayesian classifiers,?
the context in which an ambiguous word oc-curs is represented by co-occurrence f aturesA7extracted from varying sized windows of sur-rounding words,?
member classifiers are selected for the ensemblesbased on their performance relative to otherswith comparable window sizes, and?
a majority vote of the member classifiers deter-mines the outcome of the ensemble.Each point is discussed below.5.1 Naive Bayesian classifiersThe Naive Bayesian classifier has emerged as a con-sistently strong performer in a wide range of com-parative studies of machine learning methodologies.A recent survey of such results, as well as pos-sible explanations for its success, is presented in(Domingos and Pazzani, 1997).
A similar findinghas emerged in word sense disambiguation, wherea number of comparative studies have all reportedthat no method achieves ignificantly greater accu-racy than the Naive Bayesian classifier (e.g., (Lea-cock et al, 1993), (Mooney, 1996), (Ng and Lee,1996), (Pedersen and Bruce, 1997)).In many ensemble approaches the member classi-tiers are learned with different algorithms that aretrained with the same data.
For example, an en-semble could consist of a decision tree, a neural net-work, and a nearest neighbor classifier, all of whichare learned from exactly the same set of trainingdata.
This paper takes a different approach, wherethe learning algorithm is the same for all classifiers67but the training data is different.
This is motivatedby the belief that there is more to be gained by vary-ing the representation f context han there is fromusing many different learning algorithms on the samedata.
This is especially true in this domain since theNaive Bayesian classifier has a history of success andsince there is no generally agreed upon set of featuresthat have been shown to be optimal for word sensedisambiguation.5.2 Co-occur rence  featuresShallow lexical features uch as co-occurrences andcollocations are recognized as potent sources of dis-ambiguation information.
While many other con-textual features are often employed, it isn't clearthat they offer substantial advantages.
For exam-ple, (Ng and Lee, 1996) report that local collocationsalone achieve 80% accuracy disambiguating interest,while their full set of features result in 87%.
Prelim-inary experiments for this paper used feature setsthat included collocates, co-occurrences, part-of-speech and grammatical information for surroundingwords.
However, it was clear that no combination offeatures resulted in disambiguation accuracy signifi-cantly higher than that achieved with co-occurrencefeatures.5.3 Select ing ensemble  membersThe most accurate classifier from each of nine pos-sible category ranges is selected as a member ofthe ensemble.
This is based on preliminary experi-ments that showed that member classifiers with sim-ilar sized windows of context often result in little orno overall improvement in disambiguation accuracy.This was expected since slight differences in windowsizes lead to roughly equivalent representations ofcontext and classifiers that have little opportunityfor collective improvement.
For example, an ensem-ble was created for interest using the nine classifiersin the range category (medium, medium).
The ac-curacy of this ensemble was 84%, slightly less thanthe most accurate individual classifiers in that rangewhich achieved accuracy of 86%.Early experiments also revealed that an ensemblebased on a majority vote of all 81 classifiers per-formed rather poorly.
The accuracy for interest wasapproximately 81% and line was disambiguated withslightly less than 80% accuracy.
The lesson takenfrom these results was that an ensemble should con-sist of classifiers that represent as differently sizedwindows of context as possible; this reduces the im-pact of redundant errors made by classifiers thatrepresent very similarly sized windows of context.The ultimate success of an ensemble depends on theability to select classifiers that make complementaryerrors.
This is discussed in the context of combin-ing part-of-speech taggers in (Brill and Wu, 1998).They provide a measure for assessing the comple-mentarity of errors between two taggers that couldbe adapted for use with larger ensembles such as theone discussed here, which has nine members.5.4 D isambiguat ion  by major i ty  voteIn this paper ensemble disambiguation is based on asimple majority vote of the nine member classifiers.An alternative strategy is to weight each vote bythe estimated joint probability found by the NaiveBayesian classifier.
However, a preliminary studyfound that the accuracy of a Naive Bayesian ensem-ble using a weighted vote was poor.
For interest,it resulted in accuracy of 83% while for line it was82%.
The simple majority vote resulted in accuracyof 89% for interest and 88% for line.6 Future WorkA number of issues have arisen in the course of thiswork that merit further investigation.The simplicity of the contextual representationcan lead to large numbers of parameters in the NaiveBayesian model when using wide windows of con-text.
Some combination of stop-lists and stemmingcould reduce the numbers of parameters and thusimprove the overall quality of the parameter esti-mates made from the training data.In addition to simple co-occurrence f atures, theuse of collocation features eems promising.
Theseare distinct from co-occurrences in that they arewords that occur in close proximity to the ambiguousword and do so to a degree that is judged statisti-cally significant.One limitation of the majority vote in this paperis that there is no mechanism for dealing with out-comes where no sense gets a majority of the votes.This did not arise in this study but will certainlyoccur as Naive Bayesian ensembles are applied tolarger sets of data.Finally, further experimentation with the size ofthe windows of context seems warranted.
The cur-rent formulation is based on a combination of intu-ition and empirical study.
An algorithm to deter-mine optimal windows sizes is currently under de-velopment.7 Conc lus ionsThis paper shows that word sense disambiguationaccuracy can be improved by combining a numberof simple classifiers into an ensemble.
A methodol-ogy for formulating an ensemble of Naive Bayesianclassifiers is presented, where each member classifieris based on co-occurrence features extracted froma different sized window of context.
This approachwas evaluated using the widely studied nouns lineand interest, which are disambiguated with accuracyof 88% and 89%, which rivals the best previouslypublished results.688 AcknowledgmentsThis work extends ideas that began in collabora-tion with Rebecca Bruce and Janyce Wiebe.
Clau-dia Leacock and Raymond Mooney provided valu-able assistance with the line data.
I am indebted toan anonymous reviewer who pointed out the impor-tance of separate tes t  and devtest data sets.A preliminary version of this paper appears in(Pedersen, 2000).Re ferencesE.
Brill and J. Wu.
1998.
Classifier combination forimproved lexical disambiguation.
In Proceedingsof the 36th Annual Meeting of the Association forComputational Linguistics, Montreal.R.
Bruce and J. Wiebe.
1994.
Word-sense disam-biguation using decomposable models.
In Proceed-ings of the 32nd Annual Meeting of the Associ-ation for Computational Linguistics, pages 139-146.T.
Dietterich.
1997.
Machine--learning research:Four current directions.
AI magazine, 18(4):97-136.P.
Domingos and M. Pazzani.
1997.
On the optimal-ity of the simple Bayesian classifier under zero-oneloss.
Machine Learning, 29:103-130.R.
Duda and P. Hart.
1973.
Pattern Classificationand Scene Analysis.
Wiley, New York, NY.W.
Gale, K. Church, and D. Yarowsky.
1992.
Amethod for disambiguating word senses in a largecorpus.
Computers and the Humanities, 26:415-439.J.
Henderson and E. Brill.
1999.
Exploiting diver-sity in natural anguage processing: Combiningparsers.
In Proceedings of the Fourth Conferenceon Empirical Methods in Natural Language Pro-cessing, College Park, MD, June.C.
Leacock, G. Towell, and E. Voorhees.
1993.Corpus-based statistical sense resolution.
In Pro-ceedings of the ARPA Workshop on Human Lan-guage Technology, pages 260-265, March.C.
Leacock, M. Chodorow, and G. Miller.
1998.
Us-ing corpus statistics and WordNet relations forsense identification.
Computational Linguistics,24(1):147-165, March.R.
Mooney.
1996.
Comparative experiments on dis-ambiguating word senses: An illustration of therole of bias in machine learning.
In Proceedings ofthe Conference on Empirical Methods in NaturalLanguage Processing, pages 82-91, May.H.T.
Ng and H.B.
Lee.
1996.
Integrating multipleknowledge sources to disambiguate word sense:An exemplar-based approach.
In Proceedings ofthe 34th Annual Meeting of the Society for Com-putational Linguistics, pages 40-47.T.
Pedersen and R. Bruce.
1997.
A new supervised69learning algorithm for word sense disambiguation.In Proceedings of the Fourteenth National Con-ference on Artificial Intelligence, pages 604-609,Providence, RI, July.T.
Pedersen, R. Bruce, and J. Wiebe.
1997.
Sequen-tial model selection for word sense disambigua-tion.
In Proceedings of the Fifth Conference onApplied Natural Language Processing, pages 388-395, Washington, DC, April.T.
Pedersen.
2000.
An ensemble approach tocorpus-based word sense disambiguation.
I  Pro-ceedings of the Conference on Intelligent TextProcessing and Computational Linguistics, pages205-218, Mexico City, February.G.
Towell and E. Voorhees.
1998.
Disambiguatinghighly ambiguous words.
Computational Linguis-tics, 24(1):125-146, March.
