A COMPUTATIONAL FRAMEWORK FOR LEX ICAL  DESCRIPT IONGraeme D. RitchieDepartment of Artificial \]\[ntelligenceUniversity of Edinburgh80 South BridgeEdinburgh EH1 1HNStephen G. PulmanComputer LaboratoryUniversity of CambridgeCorn Exchange StreetCambridge CB2 3QGAlan W. BlackDepartment of Artificial IntelligenceUniversity of Edinburgh80 South BridgeEdinburgh EH1 1HNGraham J. RussellComputer LaboratoryUniversity of CambridgeCorn Exchange StreetCambridge CB2 3QGTo achieve generality, natural language parsers require dictionaries which handle lexical information ina linguistically motivated but computationally viable manner.
Various rule formalisms are presentedwhich process orthographic effects, word structure, and lexicai redundancy in a manner which allowsthe statement of linguistic generalisations with a clear computational interpretation.
A compactdescription of a medium-sized subset of the English lexicon can be stated using these formalisms.
Theproposed mechanisms have been implemented and tested, but require to be refined further if they areto be regarded as an interesting linguistic theory.1.
METHODOLOGYAs can be judged from the review in Ingria(1986), thereare a wide variety of techniques and sub-systems usedfor handling lexical information within natural anguageprocessing systems.
In many systems, particularly ex-perimental ones, the lexicon module is fairly small andrudimentary, as the vocabulary is limited and the re-search is not primarily concerned with lexical issues.On the other hand, theoretical inguists have oftendiscussed regularities that occur within the lexicon,primarily in the areas of morphology (word structure)and lexical redundancy (generalisations across lexicalentries).
We have designed a related set of rule-formal-isms and structures which embody a linguistically-motivated theory of lexical structure, and have imple-mented these techniques in software which can serve asa general lexical module within a natural languageparsing system.
This is of theoretical interest as itpresents a computer-tested set of mechanisms whichfulfil, in an integrated way, some of the roles thatCopyright 1987 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires afee and/or specific permission.0362-613X/87/030290-307503.00290 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexicai Descriptionlinguists have posited for morphological and lexicalrules.
From a practical point of view, it defines asoftware module which is largely rule-driven and so canbe tailored to different vocabularies, and perhaps evento various languages.
Although it has been designedwith syntactic parsing as the main intended application,most of the linguistic mechanisms and descriptions areindependent of their use within a parser.It is important to bear in mind the distinction be-tween a linguistic mechanism and a linguistic descrip-tion which uses that mechanism.
We have developednot only a related set of formalisms, all with a clearcomputational interpretation, we have devised a de-scription of a large subset of English morpho-syntacticphenomena using these formalisms.
Although the ade-quacy of the mechanism and of the description aremutually interdependent, it is important to maintain thisdistinction when appraising the work reported here,particularly when considering its possible extension toother vocabulary or other languages.
Another importantissue when considering a computationally feasible sys-tem is the question of how to interpret a rule-notationprocedurally.
Linguistic formalisms tend to be dis-cussed as declarative statements of regularities withinthe language, and it is not always clear what is theappropriate interpretation when the rules have to beused for processing data.
For example, the FeatureCo-occurrence Restrictions of Gazdar et al (1985) definearbitrary logical constraints to which feature-sets (cat-egories) must conform.
A computational implementa-tion has (at least) two ways in which these statementscould be interpreted - -  as recipes for filling in extrafeatures, or as filters for rejecting ill-formed categories(cf.
Stanley(1967)).
It is not at once apparent whether alinguist writing FCR statements would accept both ofthese as equally "natural" interpretations.
Whateveralgorithmic interpretation is chosen for a rule notation,it should be compu/ationally tractable and fairly obvi-ous to the reader.
This has led us, particularly in thearea of lexical redundancy rules, to opt for notationswhich have a very obvious and explicitly defined pro-cedural interpretation.A further methodological question which arises whengiving a computational interpretation to declarativestatements of lexical regularities is whether a rulenotation is best regarded as a notational device whichallows the linguist to write more succinct entries, butwhich is not used directly in the computation of theassociation between a character string and a lexicalentry.
In terms of the implementation, this is thequestion of whether a rule-system is an aid to the entryof data by the linguist (and can be used for some form ofpre-processing) or is a mechanism which is used in amore general or efficient look-up procedure.In designing linguistic rule-formalisms, there is tradi-tionally a trade-off between the power of the mechanismand the substance of the linguistic claims or theoriesembodied in the notation.
We have generally opted forfairly powerful techniques, in the interests of achievinggenerality and flexibility, for two reasons.
Firstly, wewere not sure initially what facilities would be neededfor an adequate description of lexical phenomena inEnglish, and so had to allow scope for experimentation.It would be possible, in the light of regularities withinour description, to devise a more restricted set of ruleformalisms if this was desired.
Secondly, we wished todesign and implement a set of tools which could be usedby computational linguists of a variety of theoreticalpersuasions and with varying needs, and hence we feltit would be too restrictive to tailor the rule systems tothe minimum that our description of English demanded.We shall start by giving an informal description of theoverall system, then we shall outline some of the rulesystems in more detail, and finally our description ofEnglish word-structure will be summarised.2.
OVERVIEWThe system can be thought of as a lexicon and varioussets of rules.
The lexicon contains entries for separatemorphemes, each entry containing four fields - -  acitation form (which is a canonical spelling for themorpheme), a phonological form, a syntactic category(an unordered set of features as in current unification-style grammars such as Gazdar et a1.
(1985), Kay(1985)),and a semantic structure, about which we shall saynothing here.
(In the implementation, a fifth field isincluded for miscellaneous purposes, but it has nolinguistic significance.
However, all examples hown inthis paper are taken from our implemented descriptionand hence will contain this fifth field, with a value ofNIL).There are two classes of rules.
Lexical rules (of whichthere are three types) express relationships betweenentries, or between fields within entries, and have aprocedural interpretation which maps a set of basicentries into a possibly larger set of entries with morespecified categories.
Morphological rules (of which thereare two types) express relationships between charactersand morphemes within a word, and have a proceduralinterpretation which allows a string of characters to bedecomposed into a structural analysis of a word.
Thereis also a very simple mechanism for defining defaultvalues for syntactic features, which does not properlyfall into either of these classes of rules.The lexical rules are of the following types:Completion Rules.
These state implications betweenparts of lexical entries - -  typically, that the presenceof certain syntactic feature-values (or combinationsof them) makes the presence of other particularvalues obligatory.
Their procedural interpretation isthat the predicted information should be added to theentries which match the antecedent of the implica-tion.Multiplication Rules.
These state implications concern-ing the existence of lexical entries.
Their proceduralComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 291Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical Descriptioninterpretation is to construct new lexical entries thatare predictable in form from existing ones.Consistency Checks.
These state implications betweencombinations of information within entries (again,typically syntactic features).
Their procedural inter-pretation is to reject any lexical entries which areinternally inconsistent.Notice that generalisations which might, in a whollydeclarative framework, be stated using a single type ofrule (e.g.
the Feature Co-occurrence Restrictions ofGazdar et al(1985)) are here dealt with by two separaterule-types, differing in their procedural interpretation.
Itwas found to be convenient for practical use to make thedistinction between asking the system to force entries tohave a particular form by adding information and stip-ulating that erroneously specified entries be rejected(however, see also the discussion on Lexical Rules inSection 8 below).The morphological rules are of two sorts:Spelling Rules.
These state relationships between sur-face forms of words (i.e.
ordinary orthography in-cluding inflections) and lexical forms (i.e.
canonicalforms in lexical entries, typically with stems andaffixes stored separately).
The rules are based on theformalism in Koskenniemi(1985), which is in turn ahigh-level notation related to Koskenniemi(1983a,b).Their procedural interpretation is that they can beused to segment character strings into individualmorphemes, taking account of orthographic effectswhich may occur at morpheme boundaries (or else-where).Word Grammar  Rules.
These rules describe the possi-ble internal structures of words, using a feature-grammar notation like that of Gazdar et a1.
(1985),with certain feature-passing conventions to supple-ment the use of variables and unification.
They havethe obvious procedural interpretation, i  that a fairlyconventional context-free parser can use these rulesto analyse a sequence of morphemes into a structuraltree.The remaining notational device is the Feature Defaultdefinition, which allows the statement ofa single defaultvalue for a feature.
That is, these are not as sophisti-cated as the Feature Specification Defaults of Gazdar eta1.
(1985), since they do not allow logical combinationsof features and values (but see further comments in thesection about Lexical Rules in Section 8 below).In addition to the above rule mechanisms, the imple-mented version contains various other notational con-veniences to support he definitions of rules or to reducethe work that the lexicon-writer must carry out.
Theseinclude the ability to define aliases for clusters ofsyntactic features, and to define names for feature-classes.As observed above, the need to use the lexiconwithin a natural language parsing system demands thatthere be a clearly defined computational process under-lying the definitions of the rule-types.
This also appliesto the', integrated functioning of the various mechanisms.The operation of the dictionary system can be viewed ashaving two stages - -  compilation and use.
The formerphase is a pre-processing in which lexical entries sup-plied in a linguistically appropriate form are manipu-lated by the lexical rules to produce a modified lexicalentry set, containing additional (predictable) informa-tion, and possibly more entries.
Of course, if the linguisthas chosen to state no lexical rules whatsoever, thisprocess is fairly simple and the set of entries is unaltered(in the implementation, the compilation process alsoinserts the entries in a tree-like index (cf.
Thorne,Bratley and Dewar(1968)), and hence even withoutlexical rules there is a need for compilation so thatsubsequent access works correctly).
The phase of dic-tionary use is essentially the process of looking uparbitrary character strings in the compiled dictionary,with the morphological rules being used to produce alistof all possible analyses of the string into words.
FeatureDefaults are inserted at appropriate junctures during thelook-up phase.3.
SPELLING RULESThese rules (called "morphographemic rules") are con-cerned with undoing spelling or phonological changes torecover the form of a word which corresponds to somemorpheme ntry in the lexicon.
For example, movedcan be viewed as move+ed, but with the deletion of theextra e; provability can be viewed as prove+able+ity,with adjustments occurring at both the internal bound-ary points.The formalism used within this system is based onthe work of Koskenniemi (1983a, 1983b, Karttunen1983).
In earlier versions of this formalism, the linguisthad to specify the spelling rules in a low-level notationsimilar to that for finite state automata, but Kosken-niemi (1985) outlined a more perspicuous high levelnotation, and we have adopted a variant of that, with acompilation technique inspired by the work ofBear(1986).The first point to understand about he rule formalismis that the rules describe relationships between thesurface form, that is the actual word as it appears in asentence, and the lexicai form, as it appears in thecitation forms of the lexical entries.
For example,moved is the surface form while move and +ed are thelexical forms.
What is required is a rule that allows thedeletion of an e from the lexical form.
Note that the ruleshould refer to the context where the e can be deletedand not just allow arbitrary deletions of es in the lexicalform as then the surface form reed would match red inthe lexicon uThe format for the Spelling Rules includes initialdeclarations and definitions of the associated entities(character sets, etc.)
needed to support the actualrule-definitions, asfollows.
The surface alphabet is the292 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexicai Descriptionset of acceptable symbols in a string being looked up,the lexieal alphabet is the set of acceptable symbolswithin citation forms in lexical entries, and namedsubsets of these alphabets can be declared.The spelling rules are specified as a pair (lexicalsymbol : surface symbol), and the context in which thatpair is acceptable.
A lexical symbol can be one of threetypes: a lexical character from the declared lexicalalphabet; a lexical set, declared over a range of lexicalcharacters; or the symbol 0 (zero) which represents thenull symbol.
Similarly there are three possibilities forthe surface symbol.Before a more detailed description of the formalismis given a simple example may help to explain thenotation.
The following example describes the phenom-enon of adding an e when pluralising some nouns (alsomaking some verbs into their third person singularform), e.g boys as boy+s while boxes as box+s.
Thisphenomena is known as "epenthesis"  :Epenthesis+:e <=> {<{s:sc :c}h:h> s :sx :xz :z  } - - -s :sThe left and right contexts are basically regular expres-sions, with angle brackets indicating sequences ofitems, curly braces indicating disjunctive choices, andordinary parentheses enclosing optional items.
This ruleassumes that the morpheme +s (see below for com-ments on the + character) is in the lexicon and repre-sents the plural morpheme.
(Let us exclude for the timebeing its use as the third person singular morpheme).Roughly speaking, the epenthesis rule states that e canbe added at a morpheme boundary when and only whenthe boundary has sh, ch, s, x, or z or on the left side ands on the right.
The " - - - "  can be thought of as markingthe position of the symbol pair + :e.Within our formalism there are no built-in conven-tions concerning morpheme boundaries.
However,  it isoften necessary to state a rule which stipulates thepresence of a morpheme boundary in the context.
Oneway to do this is to add a marker (some specialcharacter) to the lexical form of the morphemes in-volved.
Rules would then be able to refer indirectly tomorpheme boundaries by means of this special charac-ter in the context statement.
This means we havemorphemes of the lexical form +ed, move, +ing,+ation, etc.Another example in our English description is the"E-delet ion" rule:E-Deletion:e:0 <=> =:C2 --- < +:0 V :=>or <C:C V :V> --- <+:0  e:e>or {g:g c:c} --- < +:0 {e:e i:i}>or 1:0--- +:0or c:c --- < +:0 a:0 t:t b:b >where V, C and C2 represent particular subsets of thealphabets, and the = sign matches any symbol (roughlyspeaking).
Although alternatives can be specified withina left or right context using the disjunctive construct, wealso need the ability to allow alternatives for full con-texts.
I f  separate rules were given for each alternativeleft and right context there would be the undesirableeffect of each one blocking the other, since rules aretreated as conjoined; that is, all rules must match for asequence of symbol pairs to be acceptable.
Hence, toachieve a disjunctive choice for contexts there is the"or "  connective as used in "E-delet ion" above.
(Thisis not fully general as a rule pair can only have oneoperator type).
Each context in the above rule is forparticular cases: the first allows words like moved asmove+ed; the second allows argued as argue+ed; thethird allows encouraging as encourage+ing but alsocopes with courageous as courage+ous; the fourthcontext deals with e-deletion in words like readability asread+able+ity; and the last context allows e-deletion inreduction as reduce+ation.The three possible rule operators are: <- - ,  - -> or<=>,  which represent forms of implication, in thefollowing manner.Context Restriction:a:b - -> LC --- RCThis means the lexical character a can match thesurface character b only when it is in the context ofLC and RC, and hence a:b cannot appear in anyother context.Surface Coercion:a:b <--  LC --- RCThis means that in the context LC and RC a lexical acan only be matched with a surface b and nothingelse; for example a:c is disallowed in this context.Combined Rule:a:b <- -> LC --- RCThis is equivalent o the combination of the contextrestriction and surface coercion rules.
It means amatches b only in the context LC and RC, and a:b isthe only pair possible in that context.An addition to the formalism, which is formally notneeded, is the introduction of a "where"  clause.
Thissaves the user writing separate rules for similar phe-nomena.
A good example can be seen in the rule forconsonant doubling (gemination):Gemination:+:X <=> <C:C V:V =:X> --- V:Vwhere X in { b d fg  1 m n p r s t }The rule is effectively duplicated with the variable Xbound to each member of the set in turn.
If  a "where"clause were not used and X declared as a set rangingover { b d f g 1 m n p r s t }, the value found for X in therule pair + :X would not necessary be the same value forComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 293Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical DescriptionX in the left context.
There would be no point in givingsets this interpretation as we do not want the V:V in theleft context necessarily to be the same V:V in the right.The interpretation of pairs containing sets dependson the notion of feasible pairs.
A pair consisting of alexical symbol and a surface symbol is a feasible pair ifeither it is a concrete pair (see below) or consists of twoidentical symbols from the intersection of the lexicaland surface alphabets.
Concrete pairs are those pairsappearing in the rules (assuming any "where"  clausesare expanded into explicit enumeration) which are madeup of characters in the alphabets or null symbol only(i.e.
containing no sets).
Pairs containing sets, such asV:V where the lexical set V is { a e i o u y } and thesurface set V is { a e i o u y } are interpreted as allfeasible pairs that match.
If y:i is a feasible pair then itwill match V:V. Rules will typically be written only forpairs a:b where a and b are different characters.
It isbuilt into the formalism that unless otherwise restricted,all feasible pairs are accepted in any context.In addition to the definition above for feasible pairsthere is the facility to declare xplicitly that certain pairsare feasible.
This may be useful where some pair in arule contains a set and the user wishes it to stand forsome concrete pair that does not actually exist in any ofthe currently specified rules.
For example the pair +:=may be used, where = can be thought of as a setcontaining the whole surface alphabet.
The user mayintend this pair to stand for, among others, +:/, al-though + :l does not actually appear in any of the rules.In this case, + :l should be declared as a default pair.Any number of spelling rules can be specified (ourEnglish description has 15 - -  see appendix 2 for anannotated list).
These rules are applied in parallel to thematching of the surface form and the lexical forms.
Fora match to succeed, all rules must find it acceptable.
Allmembers of the set of feasible pairs not on the left-handside of some rule (i.e.
a:a, b:b, c:c, etc.)
are accepted inany context.There are some problems with this form of rule.When a rule pair a:b from some rule A with the operator<= > or = > also appears within a context of someother rule B, the user must take care to ensure that thecontext where a:b appears within rule B is catered for inrule A.
An example will help to illustrate this point.Consider the following two rules:E-Deletion:e:0 <=>=:C2 --- <+:0  V :=>or <C:C V:V> --- <+:0  e:e>or { g:g c:c }--- < +:0 { e:e i:i} >or h0---  +:0A-deletion:a:0 <=> < c:c e:0 +:0 > --- t:tThe e:O in the left context of the "A-delet ion" rule is ina context hat is not catered for within the "E-Delet ion"rule.
This means that "A-delet ion" will always fail.What is required is the addition of another context othe "E-Delet ion" rule:or c::c --- < +:0 a:0 t:t > ;; A-deletionThis rule-clashing is a significant factor that must betaken into consideration when specifying spelling rules(see Black ell a1.
(1987) for further discussion).
We havenot yet investigated formal criteria for detecting clasheswithin a rule-set, and it may in principle be undecidable(or at least highly intractable)Another decision the linguist has to make is when totreat a given alternation as morphographemic, and whento treat it by writing distinct morpheme ntries.
Forexample, it seems ridiculous to go as far as writing thefollowing rule:o:e <=> g:w --- <+:0  e:n d:t>which will match went to go+ed.
This rule is in factinsufficient as it introduces the pairs w:g, e:n and d:tinto the feasible pairs set and thus allows wear to matchgear etc.
If this rule were to be included then three morewould be needed to cope with these three extra pairs.But rules that match surface forms to such differentlexical forms are not recommended.
It seems wise tohave went as a morpheme ntry with the necessary pasttense marking.
Went is a clear example but some othersare not so clear.
Should written match write+en?
Thequestion of when a change is to be taken as a differentmorpheme or just as a spelling change is a question ofthe overall adequacy and elegance of the descriptionthere are no firm guidelines.4.
WORD GRAMMARThe morphological rules concerned with word-structurecan be viewed as a "Word Grammar" ,  characterisingderivationai and inflectional morphology in abstractionfrom the details of the actual character strings involved.These rules describe what constitutes an allowablesequence of morphemes, stating which concatenationsare valid, and the syntactic class of the overall wordformed by several morphemes.
For example,happy+ness is a valid noun, but arrive+ness is not avalid word.The word grammar is based on the concept of fea-tures and values.
Any constituent (morpheme, word,word-part, etc.)
can be represented by a set of featuresand values, called a category.
Our model of Englishmorphology is based heavily on the GPSG model ofsyntactic features (cf.
Gazdar et al (1985), chap.
2)(although it could be used simply as a very generalfeature-grammar by anyone who did not wish to adoptthe more esoteric aspects of GPSG theory).
For exam-ple the category of a plural noun can be represented as:((N +) (V -) (PLU +) (BAR 0))All features used in the word grammar (and lexicalentries) must be declared to the analyser system.
Thereare two types of features, atomic-valued and category-valued.
Atomic-valued features must be declared with294 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical Descriptionan enumerated set of atomic values.
Category-valuedfeatures can take any valid category as their value.These are declared using the keyword category, e.g.Feature N {+,-}Feature BAR {-1,0,1,2}Feature AGR categoryAlthough our sample English description uses particularfeature names, there is no need for the linguist o copysuch conventions.
There is only one restriction on thefeatures declared.
If a feature of the name STEM isdeclared, it must be a category-valued feature.
Thisfeature is used by the WSister Convention (see below)and should not be used in any other way.The word grammar is a feature unification grammarwith rules of the form:mother-> daughterl, daughter2 .
.
.
.
.
daughterNwhere mother, daughterl, daughter2, etc.
are catego-ries made up of features.
Rules may have one or moredaughters.
In addition to simple categories the grammarmay also contain variables and aliases (see below).Aliases are a short-hand for writing categories (andparts of categories).
They allow an atomic name to beassociated with a category, and hence then be used torepresent hat category in a rule.
For example thealiases Noun and Verb might be declared as:Alias Noun = ((BAR 0) (N +) (V -))Alias Verb = ((BAR 0) (N -) (V +))There are two types of variables allowed within thecategories in the grammar; "rule-category variables"and "feature value variables".
Rule-category variablesrange over specific categories, and are a short-hand forwriting similar grammar rules.
They are declared with arange of possible values that must be stated as a list ofaliases.
Rule-category variables can be used to capturegeneralisations in rules.
For example, in French bothnouns and adjectives can take a plural morpheme s(which can be represented by the category ((PLU +)) ).This phenomenon could be described using the follow-ing alias statements and rules:Alias Adj = ((BAR 0) (N +) (V +))Alias Noun = ((BAR 0) (N +) (V -))(AdjPlural( Adj (PLU +) ) -> ( Adj (PLU -) ), ( (PLU 4) ) )(NounPlural( Noun (PLU 4) ) -> ( Noun (PLU -) ), ( (PLU 4) ) )Alternatively, the two rules can be written as one bydeclaring a category variable:Alias Adj = ((BAR 0) (N +) (V +))Alias Noun = ((BAR 0) (N 4) (V -))Variable C = (Adj,Noun}(Plural(C (PLU ?)
) ->(C(PLU- ) ) , ( (PLU +) ) )Rule-category variables are "compiled out" duringgrammar compilation, and are thus actually used tocollapse a number of rules.Feature value variables, on the other hand, can bestbe thought of as "holes" that are filled in during parsing(although theoretically they have equivalent semanticsto rule-category variables, if we overlook the distinctionbetween abbreviations for finite sets and for infinitesets).
There are two types of feature value variables batomic-valued and category-valued (category-valued var-iables are not the same as rule-category variables).
Thedistinction is analogous to that between the atomic-valued features and category-valued features describedabove.
Atomic-valued variables are declared with anenumerated set of values, while category-valued varia-bles are declared with the keyword category:Variable ALPHA = {+,-}Variable ?AGR = categoryFeature value variables are not compiled out at gram-mar compile time but are instantiated during parsing.The ranges of feature value variables can be used torestrict he scope of rules.
They can also be used to"copy" values of features up (and down) the parse tree.For example, acompound noun can be said to inherit itsplural feature marking from the rightmost daughter.Using feature value variables we can write a rule thatensures that the compound noun will have the samePLU marking as its rightmost daughter:Variable ?X = {+,-}Alias N = ((BAR0)(N +)(V-))(NounCompound( N (PLU ?X) ) ->( N (PLU -) ), ;; ensure basic noun( N (PLU ?X) ))Note that although atomic-valued variables can bethought of as a short-hand for a number of rules, one foreach value in the range of the variable, category-valuedvariables cannot.
This is because there is potentially aninfinite number of categories that could be the value ofa category-valued feature.There are no typographical conventions built-in forspecifying variables; the rule-writer, however, maywish to adopt some convention such as starting allvariables with underscore or question mark.
This doesmake rules easier to read but is in no way mandatory.In addition to the use of variables for "passing"features around during parsing there are some built-infeature-passing conventions (see below for moredetails).Before a description of what constitutes a validanalysis can be given two definitions are required.Extension(a) A feature-value ( ither atomic or a category) is anextension of any variable of an appropriate type.Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 295Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical Description(b) An atomic feature-value is an extension of itself.
(c) Category A is an extension of category B iff for anyfeature f in category B , there is a value of f in Awhich is an extension of the value of f in categoryB.UnificationThe unification of two categories is the smallestcategory that is an extension of both of them if suchcategory exists.
It is possible that no such categoryexists, and in that case unification is undefined.Intuitively, extension and unification can be though ofas the set relation superset and the set operation union,respectively, with the extra refinement of allowing atmost one entry for each feature within a category.
Thecreation of the unification of two (or more) categories ireferred to as "unifying" the categories.The morphological analyser uses the rules in theWord Grammar to find all possible structures for a givenword.
Each structure is a tree in which each node isEITHER:the keyword ENTRY and a lexical entryOR: a local tree of the form N -> c l  c2  .
.
.
cn ,  whereN is a category and c i  is a constituent.
This tree mustmatch the following constraintsa.
there must be a rule in the word grammar of theform A -> d l  d2  .
.
.
dn ,  where category N isan extension of A and c i  is an extension ofd i  foreach i from 1 to n .b.
the local tree must be valid with respect o thefeature-passing conventions.The analyser returns all constituents hat span the givenstring and have a category that is an extension of thecategory which the linguist has defined to be the distin-guished category.
That is, in the same way that atraditional context-free grammar has a single distin-guished symbol which is used to define complete deri-vations, our morphological model has a distinguishedcategory .5.
FEATURE-PASSING CONVENTIONSFeature-passing conventions can be thought of as away of extracting various patterns which occur in theword-grammar rules and stating them separately.
Theeffect of this is to diminish the amount of explicitinformation that needs to be stated in the word-grammarrules, reducing both the size of the word-grammar (thenumber of rules) and the complexity of the individualrules.
These regularities can be expressed as feature-passing conventions which can be thought of as rules forpassing information UP the analysis tree (from terminalmorphemes to the final word), or for passing informa-tion DOWN the analysis tree (from word to constituentmorphemes).
The way of stating these conventions ibased on the mechanisms employed by GeneralisedPhrase Structure Grammar at the level of the sentence(Gazdar et al.
(1985)), but the morphological generali-sations embodied in them are essentially those ofSelkirk(1982).There are three conventions built into the system atpresent.
Notice that the definitions of the feature-passing conventions themselves are not under the con-trol of the lexicon-writer, although the features that areaffected by the conventions may be modified.
Theconventions act on certain specific features or feature-,classes, so the linguist can make use of these conven-tions by defining certain features to lie within thesenamed classes.
The system will then automaticallyapply the conventions to these features.All three feature conventions act on what is calledwithin GPSG terminology a "local tree" - -  a set of onemother node and its immediate daughters.
The conven-tions were originally designed for binary branching rules(introducing exactly two daughters), but they apply toall rules.
They are written in terms of "mother" , "leftdaughter" (i.e the leftmost daughter in a local tree) and"right daughter" (the rightmost daughter).
In unaryrules, those with just one category on the right-handside, the left and right daughters are the same category.THE WORD-HEAD CONVENTIONThe WHead feature-values in the mother should bethe same as the WHead feature-values of the rightdaughter.In the word parser, this is achieved, roughly speaking,by unifying the WHead features of the right daughterand those of the mother when the daughter is attached.From a linguistic point of view, the WHead featuresare typically those that will be relevant to sentence-levelsyntax, and hence those that will be of particular use toa sentence-parser which uses the dictionary.
This con-vention is a straightforward analogue of the simplestcase of the Head Feature Convention in (Gazdar et al(1985)).
Its effect is to enforce identity of the relevantfeature values between mother and the head daughter.Note that in the current system there is no formaldefinition of "head" to which the lexicon-writer hasaccess (despite the name given to this convention),since the right daughter always acts in this head-likefashion within our treatment of English morphology.Other analyses may deviate from this pattern, of course;different views of "head" may be implemented usingvariables and unification.Assuming the set of WHead features includes N, V,PLU, and VFORM, the Word-Head Convention wouldallow the following trees:((N +) (V -) (PLU +))0((BAR -I) (N +) (V -) (PLU +))and((N -) (V +) (VFORM ING))((N -) (V +))((BAR -1) (N -) (V +) (VFORM ING))296 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical Descriptionbut not (after all unification has occurred) trees of theform:((N +) (V +) (PLU +))0((BAR -1) (N +) (V -) (PLU +))and((N -) (V +))0((BAR -1) (N -) (V +) (VFORM EN))since one of the trees has a clash in the V value formother and right daughter, and the other lacks aVFORM marking on the mother to match that on theright daughter.THE WORD-DAUGHTER CONVENTION(a) If any WDaughter features exist on the right daugh-ter then the WDaughter features on the mothershould be the same as the WDaughter features onthe right daughter.
(b) If no WDaughter features exist on the right daughterthen the WDaughter features on the mother shouldbe the same as the WDaughter features on the leftdaughter.Again, this is ensured by carrying out unification of theappropriate feature markings during parsing.
This con-vention is designed to capture the fact that the subca-tegorization class of a word (in English) is not affectedby inflectional affixation, although it may be affected byderivation.Assuming the feature SUBCAT to be the onlyWDaughter feature, this convention allows trees suchas:((SUBCAT NP))((V +) (N -))((SUBCAT NP))((SUBCAT NP))((SUBCAT NP))((VFORM ING))but not((SUBCAT NP))((V +) (N -))((SUBCAT VP))((SUBCAT NP))((SUBCAT VP))((VFORM ING))In the first example the right daughter is specified for aSUBCAT value, and the mother has the same specifi-cation; in the second example, the right daughter has nospecification for SUBCAT and so the second clause ofthe WDaughter convention applies.
The third exampleis illegal because the values of SUBCAT on the rightdaughter and mother differ, and the fourth is illegalbecause, under clause (b) of the convention, the leftdaughter and mother WDaughter features must be iden-tical when there are no WDaughter features in the rightdaughter.THE WORD-SISTER CONVENTIONWhen one daughter (either left or right) has thefeature STEM, the category of the other daughtermust be an extension (superset) of the category valueof STEM.This third convention enables affixes to be subcatego-rized for the type of stem to which they attach.
Noticethat this convention is not defined in terms of anyfeature-classes, but is defined using just one "built-in"feature (STEM).
Hence, the way that the lexicon-writermakes use of this convention is not by declaring theextent of feature-classes (as for the other two conven-tions), but by adding STEM specifications to the fea-tures in morphemes in the lexicon, thereby indicatingthe combination possibilities for each affix.
The follow-ing examples follow the convention0((N -) (V +))((STEM ((N -) (V +))))0((V +) (N -) (INFL +))((STEM ((N -) (V +) (INFL +))))6.
FEATURE DEFAULTSFeature Defaults are similar in concept o the FeatureSpecification Defaults of Gazdar et al (1985).
They arestatements which define values for particular features incircumstances where no value has been entered byother mechanisms (i.e.
the original morpheme ntries,the action of the lexical rules, or the feature-passingconventions).
That is, they state what the value of afeature should be if there is no information to indicateany other value for it.
The defaults are applied to all newconstituents (words or parts of words) built duringmorphological analysis.
(In terms of the active chartimplementation of the parsing mechanism, the defaultchecking is done whenever a complete (inactive) edge isentered into the chart).At present, only very simple defaults are available,compared to the various kinds of defaults proposed (forsentence-level grammar) by Gazdar et al (1985).
All thelinguist can do is define the default value for a givenfeature (either a category-valued feature or an atomic-valued one).
For example, the statementDefaults BAR 0, AGR Infdeclares default values for two features (BAR andAGR), where "Inf" could be an alias for some category.However, Completion Rules have arbitrary descriptivepower, and can be used to achieve complex insertion ofComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 297Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexicai Descriptiondefault feature values, providing that the default-inser-tion can be performed adequately on individual mor-phemes (not categories formed by combining mor-phemes), since Completion Rules have their effect priorto morphological nalysis.
(See discussion in Section 8below)7.
LEXICAL RULESAll three types of rule (Completion Rules, Multiplica-tion Rules, and Consistency Checks) have the samebasic form:< pre-condition > < operator > < action >Although the < operator > and < action > are differentin each type of rule, the syntax of the < pre-condition >is the same.
Pre-conditions are specified as conjunctionsof (possibly negated) patterns, describing lexical en-tries.
Variables are denoted by atoms starting with anunderscore .g.
fred, fix etc.
and are bound duringmatching so that t--hey ca--ffbe used later in a match or ina rule action.
There is a special variable consisting ofonly an underscore ( .
.
.
.
), which never gets bound butcan be used to match--anything (cf.
Prolog).
All othervariables have a consistent interpretation throughout arule.
Matching is done from left to right (which issignificant in the matching of syntactic fields).
The entrybeing matched oes not have to have the features in thesame order as the pattern.The following examples of syntactic ategory match-ing illustrate some of the above points:((FIX f i x )  " (BAR ) res t )with tilde indicating negation, matches((FIX SUF) (N +) (V -))with __fix bound to SUF and res t  bound to ((N +)(V -))((FIX f i x )  "(BAR __ ) res t )does not match((FIX SUF) (BAR -1) (N +) (V -))since "(BAR _ ) fails to match any feature value forBAR((N -) (V +) rarest)matches((V +) (PLU -) (N -) (INFL +))with res t  bound to ((PLU -) (INFL +))((N +) (V-) res t )matches((V -) (N +))with res t  bound to an empty list of features.
Thepattern ((N +) junk (V -)) does not match any syntac-tic category because the variable junk will match allremaining features in the category being checked.When negation is used no bindings that are madewithin a negative pattern are passed on through thematch (agalin cf.
Prolog), although bindings can bepassed into negations.The above examples concern only the syntactic field,but pre-conditions match against entire entries.
Forexample:-(be ) and( ((N-) (V +) res t )  )would match all entries that do not have the citationform be and are marked with the features (N -) and(V +), and( ((N +) (V -) -(PLU ) ) )would match any entry with the features (N +) and(V -) but not the feature PLU (with any value).COMPLETION RULESCompletion Rules are designed to be used to addvalues to tile entries that are specified by the linguist,and are applied in order to the entries (after aliases havebeen expanded).
Accordingly, the order of the Comple-tion Rules is significant.
A Completion Rule is of theform< pre-condition > = > < entry skeleton >Ifa pre-condition matches an entry the entry is replacedwith the newly constructed one described by the entryskeleton.
A entry skeleton is of the same general formas a lexical entry, but various parts of it may contain theampersand symbol (&), to mean "the same as in theoriginal entry", or variables which have appeared in thepre-condition (and hence would have been bound in thematching process).For example the rules:( ((FIX f i x )  "(BAR ) res t )  ) =>(& & ((FIX fix) (BAR -I) res t )  & &)( ('(BAR ) res t )  ) =>(&&((BAR0)  res t )&&)( ((STEM ('(INFL ) s tem)  res t )  ) =>(& & ((STEM ((INFL +) s tem))  res t )  & &)have the action of adding (BAR -1) to entries containingthe feature FIX, adding (BAR 0) to all entries that donot have a BAR marking and lastly adding (INFL +) toall values of STEM that do not already have a markingfor INFL.
Note that the ordering of the first two rules issignificant.
If the first two rules were in the reverseorder, the FIX rule would not apply to any entries, as allentries would by that time have had (BAR 0) added.MULTIPLICATION RULESMultiplication Rules construct additional entries (asopposed to the replacement of entries performed by298 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical DescriptionCompletion Rules).
These are typically used to generatesimilar entries with slightly varying feature markings;for example, in English these rules can be used togenerate the first person, second person and plural ofverbs from the base form (as an alternative to designingthe morphological rules to handle the verb paradigm).The syntax of these rules is very similar to that of thecompletion rules:< pre-condition > =>> ( < list of entry skeletons > )The syntax of the entry skeletons i exactly the same asabove.
The ordering of the rules is not significant asnewly created entries are not re-tested against theMultiplication Rules.
This is to avoid possible infiniteapplication of rules.A Multiplication Rule to generate the first and secondperson singular and plural of a base verb could be:tion of a category that contains a V marking but no Nmarking, but the linguist may wish to specify that sucha category is invalid.
Consistency Checks are state-ments of the form:< pre-condition > demands < post-condition >The <post-condition> has the same syntax as thepre-conditions.
The interpretation is:If an entry_matches the pre-condition it must alsomatch the post-condition.For instance, if ali entries that are marked for V mustalso be marked for N and vice versa then this conditioncan be written as the following two ConsistencyChecks:( ( (V )  ) )demands( ( (N)  ) )( ( (N)  ) )demands( ((V ) ) )( ((V +) (N -) (BAR 0) (VFORM BSE) (INFL +) rest)) =>>((& & ((V +) (N -) (BAR 0) (PN PER1) (INFL -) rest) & &)(& & ((V +) (N -) (BAR 0) (PN PER2) (INFL -) rest)  & &)(& & ((V +) (N -) (BAR 0) (PN PLUR) (INFL -) rest) & &))The rules are applied in the following order: Multiplica-tion Rules (order is not significant), Completion Rules(in order of specification), and finally the ConsistencyChecks are applied to each entry created by the previ-ous rule applications.8.
DESCRIPTION OF ENGLISHNote that the entry being tested is not replaced butremains in the lexicon (assuming the ConsistencyChecks are passed - -  see below).
So, given the entry(like IAIk ((BAR 0) (V +) (VFORM BSE) (N -)(INFL +) (SUBCAT VP2a)) LIKE NIL)four entries would exist after the application of theMultiplication Rule, having the form:(like IAIk ((BAR 0) (V +) (VFORM BSE)(N -) (INFL +) (SUBCAT VP2a)) LIKE NIL)(like IAIk ((V +) (N -) (PN PER1)(BAR 0) (INFL -) (SUBCAT VP2a)) LIKE NIL)(like IAIk ((V +) (N -) (PN PER2)(BAR 0) (INFL -) (SUBCAT VP2a)) LIKE NIL)(like IAIk ((V +) (N -) (PN PLUR)(BAR 0) (INFL -) (SUBCAT VP2a)) LIKE NIL)CONSISTENCY CHECKSConsistency Checks are applied to every entry (in-cluding newly created ones) after the above two sets ofrules have applied.
Any entry that does not pass thesetests is not included in the lexicon.
The only formalrequirement on lexical entries is that entries are quin-tuples and that the syntactic field is a set of feature pairswith values as declared.
These Consistency Checksallow the linguist to check linguistic dependencieswithin entries; for example, there is no built-in prohibi-The mechanisms outlined in the preceding sectionscould be used to construct almost any description ofEnglish lexical facts.
Here we sketch one such descrip-tion, which we have developed using the mechanismsdescribed here.
It is worth observing in passing that thefeatures used in the description can be broadly groupedinto the following (overlapping) classes:Purely sentential.
These features are included as part ofthe grammatical description of sentence structure,and do not have any particular import within mor-phological rules.
For example, the feature SUBCATis used to indicate the subcategorisation f verbs,etc.
but does not affect spelling or word-structure.Features which do not affect morphology may still bemanipulated by the morphological rules, since thefeature-passing conventions will cause various fea-tures to be passed from morphemes to words.
Thuswhole words will inherit features from their compo-nent morphemes, without the rules mentioning thefeatures explicitly.Sentential with morphological effects.
The features Vand N (for classifying nouns, verbs, adjectives andprepositions, in the GPSG style), although obviouslymotivated by the syntactic form of sentences, alsoaffect various affixing processes.Purely morphological.
Certain features have been pos-tulated in our description solely to distinguish classesof morpheme that have different behaviour morpho-logically.
For example, the feature FIX (with possi-ble values PRE and SUF) indicates an affix, and theComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 299Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexicai Descriptionfeature INFL  (possible values + and -) indicateswhether a word or morpheme is capable of furtherinflection.Notice that this is not a formal distinction, and does notcorrespond to any sub-divisions in our mechanisms i itis merely an observation about our description of En-glish that certain features are not motivated by morpho-logical considerations.
In a sense, they could still besaid to "affect"  the morphological processing, since if afeature is mentioned in the STEM value of a morpheme,it will restrict possible morpheme combinations.
Thesentential features (i.e.
the first two classes above) havebeen devised in collaboration with the writers of amedium-sized grammar of English (Briscoe et al 1986),but we shall not discuss here the justifications for thedecisions regarding sentential grammar.
Appendix Ioutlines the usage of the more morphologically orlexically significant features.The Word Grammar describing inflectional and der-ivational morphology is not large; the complete set isgiven below.
Each rule is preceded by a mnemonicname, and VAL is a variable ranging over  + and - .Since the feature-marking (BAR 0) indicates a itemwhich constitutes a whole word, the PREFIXING rulecan be summarised as "Any word can be made up of aprefix followed by another valid word".
(Properties ofthe prefix and stem determine the full features of theword by the Feature-Passing Conventions - -  seebelow).
( PREFIXING((BAR 0)) ->((FIX PRE)), ((BAR 0)) )( SUFFIXING((BAR 0) (N +)) ->((BAR 0)), ((N +) (FIX SUF)) )( V-SUFFIXING((N -) (V +) (AUX VAL) (BAR 0)) ->((AUX VAL) (BAR 0)), ((FIX SUF) (N -) (V +)) )( NON-V-SUFFIXING((N -) (V +) (AUX VAL) (BAR 0)) ->((N +) (BAR 0)), ((N -) (V +) (FIX SUF) (AUX VAL)))The SUFFIXING rule can be phrased "Any noun oradjective can be made up of a noun or adjective stemfollowed by a suffix".
Notice that this rule does notstipulate that the stem must be of the same majorcategory (noun or adjective) as the overall word, andhence it covers derivational morphology (where thecategory is altered by affixation) as well as noun inflec-tions.
The restriction to nouns or adjectives (i.e.
entitiesmarked as (N +)) is necessary as verbs require theslightly more detailed rules V-SUFFIXING and NON-V-SUFFIXING (and prepositions - -  ((N -) (V -)) - -  donot take affixes at all).The V-SUFFIXING rule states "that a verb can bemade up of a verbal stem of the same auxiliary markingfollowed by a verbal suffix".
This is to cover generalverb inflection, for both auxiliaries (AUX +) and mainverbs (AUX -).The NON-V-SUFFIXING rule is to cover thosecases of derivational morphology where a noun oradjective (N +) stem becomes a verb through suffix-ation - -  "any noun or adjective which forms a wholeword can form a whole word verb by the addition of averbal suffix".In all these cases, the rules may seem to be rathersketchy and lacking in feature specifications.
For exam-ple, the PREFIXING rule does not stipulate muchabout the relationship between stem and compositeword, and therefore seems to omit the generalisationthat prefixation does not alter the grammatical featuresof the word (in particular, the major category is thesame).
However,  these highly economical grammarrules are made possible by the assumption that thevarious feature-passing conventions (and feature de-faults) will ensure that features are correct.
Hence it iscrucial that the word grammar be assessed in conjunc-tion with the feature-passing conventions defined inSection 5 above, and the following definitions of featureclasses:WHead Features:N V INFL PAST AFORM VFORM BARE-ADJADV AGR PLU POSS FINWDaughter Features:SUBCATThe features in the WHead list will be forced to have thesame values on the right-daughter and the mother;hence these feature-values when specified on a suffixwill percolate on to the main word, and will also remainon the main word when a prefix is added.
Similarly, theWDaughter feature will be inherited from the appropri-ate part of the word.There are also two feature-defaults:BAR 0LAT +These ensure that any morpheme, word, or part of aword which does not have a value for BAR will bemarked as a potential whole word, and that any item notmarked for being "Lat inate"  will be assumed to be so.There are two main types of lexical rules I Comple-tion Rules and Multiplication Rules.
The third type(Consistency Checks) are desirable for disciplined lex-icon-writing, but they do not insert any features orentries, and will not be discussed here.Although it is not obvious from the outline of theformalism given here, Completion Rules can be used inseveral ways to control the content of lexical entries.300 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical DescriptionThis is not to say that the notation has several interpre-tations, but rather that the lexicon writer can choose toemploy the facilities of these rules in different styles, inmuch the same way that a programmer can use aprogramming language in different manners.
We willterm the three main usages overwriting, obligatoryinsertion, and optional defaulting.
The overwriting useis fairly straightforward - -  in this, a rule is used to alterthe values of one or more specified features.
Forexample, a rule like the following would change alladjectives to nouns:( ((V +) (N +) res t )  ) =>(& & ((V -) (N +) res t )&&)This is achieved by mentioning the relevant featuresexplicitly in the pre-condition (pattern), and supplying anew form (right-hand side) which has an explicitlystated revised form of them; all other features arecarried over unchanged by the variable rest.
Leavingaside the rather absurd content of the ~-ove example,we have made no use of this effect in our description ofEnglish, as there seemed no point in putting in entrieswhich were to be systematically altered by rule (noticethat this is different from having the entries filtered outby some rule such as a Consistency Check).The notion of obligatory insertion is more subtle.This involves writing rules which will insert a featurevalue if it is not there already, but will result in thelexical entry being discarded if that feature is alreadyspecified in it.
For example, consider a rule which adds(INFL -) to all entries marked with an AFORM value:( ((AFORM _af) _rest) ) = >(& & ((INFL -) (AFORM _af) _rest) & &)The Completion Rule mechanism is not defined to checkfor the presence of features it is attempting to add, sothis rule will attempt o add (INFL -) even if the entryalready has a value for INFL (whether + or -).
If thereis no previous marking for INFL, this insertion will besuccessful, and the rule will have effectively added adefault marking.
If there is some previous marking, theinsertion will fail, since the mechanism is not defined tooverwrite entries, and the lexical entry will be dis-carded.Optional defaulting is a slightly more circumspectway of inserting default values.
Consider the followingrule, which also inserts (INFL -) as a default marking onentries specified for AFORM.
( ((AFORM _af) "(INFL ) _rest) ) = >>(& & ((INFL-) (AFORM a f )  res t )  & &)In this version, the pre-condition has an explicit checkfor the absence of an INFL marking (since the tilde signindicates negation of the immediately following condi-tion).
This rule will apply only to entries which areunspecified for INFL, and will have no effect (i.e.
leavein the lexicon unaltered) entries for which this pre-condition is not true.All the Completion Rules in our description of En-glish are written to act in a "default" manner; in fact, touse the terminology introduced immediately above,they are written in the "optional default" style, in thateach rule checks for the absence of a feature-valuebefore inserting the value.
The full set of CompletionRules is given in Appendix 3.There are two Multiplication Rules.
The first is toaccount for the fact that any noun or adjective which issubcategorised for a complement (e.g.
critic takes aprepositional phrase with 039 can also occur with nocomplement:( ((N +) (SUBCAT ) res t )  ) and-( ((SUBCAT NULL) ) )(& & ((N +) (SUBCAT NULL) res t )  & &) )The second clause of the pre-condition is necessarysimply because the pattern-matching mechanism doesnot permit the use of negated feature values (e.g.
(SUBCAT "NULL)) within a pattern.
The second Mul-tiplication Rule expands the present ense verb para-digm for all verbs apart from be, by adding three furtherlexical entries per verb:"(be ) and( (-(VFORM ) "(FIN ) -(AGR(V +) (N-) (INFL +) res t )())(& & ((V +) (N -) (FIN +) (INFL -) (PAST -)(AGR PLUR) res t )  & &)(& & ((V +) (N -) (FIN +) (INFL -) (PAST -)(AGR PER1) res t )  & &)(& & ((V +) (N -) (FIN +) (INFL -) (PAST -)(AGR PER2) res t )  & &)It might seem that this regularity would be more natu-rally handled in the morphological nalyser, rather thanas lexical redundancy.
However, that would necessitatethe introduction of a morpheme whose entire surfaceform was null (with suitable syntactic features).
Thecomplications this would introduce into the morphogra-phemic segmentation and word-grammar parsing areComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 301Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexicai Descriptionregarding as wholly unacceptable computationally, andso the Multiplication Rules have been used to capturethis generalisation.
(This is a very obvious example ofthe methodological issue mentioned in our openingsection, concerning the need for a viable proceduralinterpretation f the whole set of mechanisms).There are 15 spelling rules in our description.
Appen-dix 2 contains an annotated list of them.
In addition tothe actual rules the spelling rule mechanism requires thedefinition of the lexical and surface alphabets.
TheSurface Alphabet contains all normal alphabetic letters,space, hyphen and apostrophe (for simplicity, we shallignore the issue of upper and lower case here).
TheLexical Alphabet contains exactly the same symbolstogether with the plus sign (+) which we use to markmorpheme boundaries.
The null symbol (0) is a part ofthe formalism, and hence is not regarded as part ofeither alphabet (but may occur in rules anywhere that anormal alphabet symbol might occur).
In addition tostandard i entity pairs made from the intersection ofthelexical and surface alphabets, three default pairs aredeclared, so that these pairs are valid in any contextduring matching.+:0 a morpheme boundary symbol may be deleted onthe surface.-:0 hyphens in a citation form (e.g.
data-base) may beabsent from the surface string (e.g.
database).. .
.
.
:- where a lexical form has a space (e.g.
data base ),the surface strings may optionally contain a hypheninstead ( data-base ).9.
AN EXAMPLEThe above word grammar, and various other parts ofthe rules and definitions, can be illustrated with a simpleexample u the analysis of the word applications.
TheSpelling Rule interpreter will segment this (using theC-Insertion rule, and the Default Pair definition thatpairs morpheme boundaries with null) into three mor-phemes ---apply, +ation, and +s.
In the original exicalentries, these morphemes are listed thus, with +shaving two entries:(apply apply ((V +) (N -) (SUBCAT NP PPTO))APPLY NIL)(+ation +ation((FIX SUF) (V -) (N +) (INFL +)(STEM ((V +) (INFL +) (N -))))ATIONNIL)(+s +s((FIX SUF) (V +) (N -) (FIN +) (PAST -)(AGR SING3) (STEM ((V +) (N -) (INFL +))))SNIL)(+s +s((FIX SUF) (V -) (N +) (PLU +) (STEM ((N +) (V -) (INFL+))))SNIL)However, various Completion Rules will have actedupon these basic entries at the pre-compilation stage ofthe lexicon, resulting in the following more detailedentries for the three morphemes we are interested inhere (ignoring the other entry for +s):(apply apply ((INFL +) (V +) (N -) (BAR 0) (AT +) (LAT +)(SUBCAT NP PPTO) (AUX -)) APPLY NIL)(+ation +ation((FIX SUF) (V -) (N +) (BAR -1) (INFL +)(PLU -) (AT +) (LAT +)(STEM ((V +) (1NFL +) (N -))))ATIONNIL)(+s +s((FIX SUF) (V -) (N +) (BAR -!)
(PLU +)(INFL -) (AT +) (LAT +)(STEM ((N +) (V -) (INFL +))))SNIL)Seven rules achieve this - -  one adds the marking (BAR-1) to entries marked as affixes (i.e.
specified for FIX),another adds (BAR 0) to all entries which are specifiedfor V and N but lack a BAR value, the third adds (INFL-) to all morphemes marked with (PLU +), the fourthadds (INFL +) to all (BAR 0) entries which lack anINFL value, the fifth adds (AUX -) to all verbs (but notverbal affixes), the sixth adds (LAT +) to any entry witha V marking, and the seventh adds (AT +) to all entrieswith a (LAT +) marking.
Notice that the ordering of theCompletion Rules in the description is crucial, forexample the third of these rules affects the fourth.The SUFFIXING rule in the Word Grammar com-bines the first two morphemes into a subtree with thelexical entries for apply and +ation as daughter nodes.The left-hand side of this rule assigns the followingsyntactic ategory to the mother node:((BAR 0) (N +))Further feature markings are then computed, using theFeature Defaults and the Feature-Passing Conventions,giving((BAR 0) (N +) (V -) (INFL +) (PLU-)(LAT +) (SUBCAT NP-PPTO))The markings (V -) and (INFL +) result from theWHead Convention, since they must be equal to the302 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical Descriptionmarkings on the right daughter (+ation).
The marking(LAT +) follows directly from the Feature Default,since these are added to all constituents found by theword-parser, not just to individual morphemes.
The(SUBCAT NP__PPTO) is a result of the WDaughterConvention, because there is no SUBCAT feature onthe right daughter it must be the same as that on the left.The SUFFIXING rule operates again, to combine thisword (application) with the plural morpheme +s , toform a tree whose daughter categories are:Left: ((BAR 0) (N +) (V -)(INFL +) (LAT +) (PLU +) (SUBCATNP-PPTO))Right: ((FIX SUF) (V -) (N +) (BAR -1) (PLU +)(INFL -) (AT +) (LAT +) (STEM ((N +) (V -)(INFL +)))Notice that this combination will accord with theWSister convention, since the category of the left-daughter is an extension of the value of STEM on theright-daughter--((N +) (V -) (INFL +)).
The categoryof the mother node includes, from the SUFFIXINGrule, the following markings:((BAR 0) (N +))Again, further feature markings are then computed,giving:((BAR 0) (N +) (V -) (INFL -)(LAT +) (PLU +) (SUBCAT) np__.PPTO))The markings (V -), (PLU +) and (INFL -) result fromthe WHead Convention, since V, PLU and INFL areWHead features and so must have the same values as onthe right daughter (+s).
The marking (LAT +) followsdirectly from the Feature Default and the SUBCATfeature is a result of the WDaughter Convention.
Theoverall structure for the word can then be viewed as atree in which each node is annotated with either asyntactic category and a rule-name or the keywordENTRY and a morphemic lexical entry, as shownbelow.10.
CONCLUSIONSWe have presented an integrated set of formalisms fordescribing various aspects of the lexicon in a computa-tionally tractable manner, which have been used tocreate a non-trivial description of English lexical phe-nomena.
All these facilities have been implemented (inFranz Lisp on a Sun 2/120) and are being used as part ofcollaboration between Edinburgh, Cambridge and Lan-caster universities to develop a set of software tools fornatural language processing, under the Alvey Pro-gramme.
It should be borne in mind that all the rule-formalisms are highly experimental, and if they are toform a useful linguistic theory (as opposed a practicalsoftware package) a great deal of refinement is required.Not only are some of them perhaps too powerful (e.g.Completion Rules have arbitrary computational power),some of them may be too weak descriptively (e.g.
it isnot clear if the morphological mechanisms are adequatefor all languages).
The description is also still underdevelopment; the rules given here reflect he state of thesystem in summer 1986.APPENDIX 1--LEXICALLY SIGNIFICANT SYNTACTICFEATURESThe following are brief explanations of the featureswhich are involved in the Completion Rules in Appen-dix 3, the Word Grammar in Section 8, or which areparticularly pertinent o the Feature Passing Conven-tions.
Each feature name is followed by a list of itsallowable values.AT(- +)Stems to which the suffixes +ation and +ative mayattach are marked as (AT +), while those taking thecorresponding forms +ion and +ive are (AT -).
Thisspecification is referred to in the STEM feature of thesuffixes in question, resulting in action and presenta-tion, but not e.g.
presention.LAT (- +)((SUBCAT NP PPTO) (V -) (LAT +) (PLU +) (INFL -) (N +) (BAR 0))SUFFIXING((SUBCAT NP PPTO) (LAT +) (PLU -) (V -) (INFL +) (N +) (BAR 0))SUFFIXING(ENTRY (apply apply ((AUX -) (BAR 0) (V +) (N -) (INFL +) (AT +)(LAT +) (SUBCAT NP.PPTO)) APPLY NIL))(ENTRY (+ation +ation ((INFL +) (BAR -1) (N +) (V -) (PLU -)(AT +) (LAT +) (FIX SUF) (STEM ((LAT +) (INFL +)(N -) (V +) (BAR 0)))) ATION NIL))(ENTRY (+s +s ((INFL -) (PLU +) (AT +) (LAT +) (V -) (FIX SUF)(BAR -1) (STEM ((INFL +) (N +) (V -))) (N +)) S NIL))Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 303Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical DescriptionThe feature LAT distinguishes those stems tradition-ally analysed as latinate from others.
Certain affixesmay only attach to latinate stems; +an is one such,giving magician, but not artan.BARE-ADJ (- +)This is a feature allowing us to refer to two disjointcategory sets.
Certain suffixes (e.g.
+ly) may attacheither to the base form of regular, inflectable, adjec-tives (as in easily), or to non-inflectable adjectives (asin dangerously).
They may not, however, attach toinflected forms (easiestly); BARE-ADJ distinguishese.g.
easy and dangerous ((BARE-ADJ +)) fromeasiest, whereas INFL (see below) does not.FIX (PRE SUF)All affixes bear a specification for FIX; prefixes havethe value PRE, and suffixes have the value SUF.
Therules of the word grammar refer to the specifications,so that prefixes always precede their stems andsuffixes always follow.AGR (SING3 SING IT PER1 PLUR PER2 DEF SINGIN1SING N1PLUR THAT S)The feature AGR is responsible for enforcing thenecessary correspondence between categories insentence structure.
This is most common in the caseof subject and verb; is is specified as (AGR SING3),and am as (AGR SING1).POSS (+ -)Distinguishes possessive items from others.
His,whose, and the possessive's are specified as (POSS+).INFL (- +)INFL distinguishes those stems which may bear anadditional suffix (e.g.
walk) from those which cannot(e.g.
walking).STEM categoryThe STEM feature controls the attachment of affixesto stems.
The value of STEM in an affix categorymust (by the WSister feature passing convention) beincluded in the category of any stem that affix at-taches to.
In this way, +ing, for example, can berestricted to the base form of verbs.BAR(-10 1 2)The sentence grammar employs a three-level systemof categories, various phrases being specified as(BAR 1) or (BAR 2), and preterminals a (BAR 0).
Inour analysis of word-structure, we extend this con-cept below the level of the complete word; stems arespecified as (BAR 0), and affixes as (BAR -1).v( -+)N( -+)The major categories (nouns, verbs, adjectives, andprepositions) are classified by means of the featuresV and N. Verbs and adjectives, and their phrasalcounterparts, are specified as (V +), while nouns andprepositions are specified as (V -).
Nouns and adjec-tives, and their phrasal counterparts, are specified as(N +); verbs and prepositions are (N -).QUA (- +)Determiners (articles like the, a and adjectives likeall, three) are specified as (QUA +).
Other adjectivesare (QUA -).ADV (- +)Adverbs derived from adjectives (quickly, easily) areanalysed as adjectives bearing the specification(ADV +).AUX (- +)Verbs are specified as (AUX +) if they are auxiliaryverbs, and as (AUX -) otherwise.FIN (- +)Verbs are specified as (FIN +) if they are finite(tensed), and as (FIN -) otherwise.PAST (- +)Finite verbs are specified as (PAST +) if they are inthe past tense, and as (PAST -) otherwise.NEG (- +)NEG distinguishes negative words from others;aren't etc.
are specified as (NEG +).PLU (- +)PLU distinguishes plural nouns from others; men andcats both bear the specification (PLU +), and manand cat (PLU -).DEF (- +)Determiners are specified for DEF; the is (DEF +)and a is (DEF -).AFORM (ER EST NONE)AFORM encodes information concerning adjectivemorphology.
Comparatives and superlatives arespecified as (AFORM ER) and (AFORM EST) re-spectively, and non-inflectable adjectives are(AFORM NONE).NFORM (IT THERE NORM)NFORM encodes the type of a noun phrase.
The"dummy subjects" it and there are specified as(NFORM IT) and (NFORM THERE) respectively,while other NPs are (NFORM NORM).
Certainverbs can then be associated with one type of NP bymeans of their AGR feature.VFORM (BSE EN ING TO)VFORM encodes verb morphology.
"Bare infini-tives" are (VFORM BSE), passives and past partici-ples are (VFORM EN), gerunds and present partici-ples are (VFORM ING), and the infinitive to is(VFORM TO).SUBCAT (NP N 1 AP INF PRED PP PPFROMPPOF PPAT PPWITH PPTO PPON PPINNP PPOF NP PPTO NP INF ING THAT SFOR SBARE S BASE S FIN SBASE VP IT PPTO THAT S NP QNP LOC NP PPFOR PPABOUT NP PPFORNP PPFROM NP PPWITH304 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Puiman, Alan W. Black, and Graham J. Russell A Framework for Lexical DescriptionPPOF PPWITH OBJ GAP NP  PP INA1PPFORNP NPNP THAT SLOC NP  BASE VP NP  PPBYPPAGAINST PPBY NP  ING Q SNP  AS PRED PPTO THAT SNP  PP INTODEFNP INNP Q SN1PLUR S NPOF PLU--R NPTO N1S INGNP PPFROM PPOVER SING3NP  PREDNP OFF  NP  ONNP  UP ANY OBJ SUBJ - - -  NULL  )SUBCAT encodes the subcategorization class of  aword.
Elapse, like other purely intransitive verbs is(SUBCAT NULL) ,  and devour, like other transi-tives, is (SUBCAT NP).
Many minor category itemsare their own subcategory;  and has the specification(SUBCAT AND),  etc.APPENDIX 2-----SPELLING RULESThe first five rules are based on those described inKarttunen and Wittenburg (1983).
There are 15 rules intotal:Epenthesis+:e  <=> { < { s:s h:h > S:S y:i }--- s:sThis allows the insertion of  an e at a morphemeboundary,  before an s and preceded by either sh, ch,one of s, x or z, or a y/i pair as in fly~flies.Gemination+:X  <=> < C:C V:V =:X  --- V:Vwhere X in { b d f g 1 m n p r s t }This deals with doubling of  consonants in words likebigger, travelling, etc.Y-to-Iy:i <=> { C:C c:t } --- < +:= NA:NA >or =:  .
.
.
.
< +:c  a:a { t:t 1:1 b:b } >This rule deals with changing a lexical y to an i as inapplies (Note that this requires both this rule and theEpenthesis rule above as there is an e insertion too).The c:t change is to cope with words like democratic(from democracy+ic).
The second clause of  the Y-to-Irule deals with words like application.E-Deletione:0 <=> =:C2 --- < +:0 V := >or < C:C V:V --- <+:0  e:e >or { g:g c:c } --- < +:0 { e:e i:i } >or 1:0--- +:0or c:c --- < +:0 a:0 t:t > ;; A-deletionThis deals with e-deletion in words like moved(move+ed).
The second clause deals with words endingin two vowels like agreed.
The third clause deals withhard and soft g 's  and c 's  so that an e must be deleted infaced but not in advantageous (if it were the g wouldbecome hard).I-to-Yi:y <=> =:  .
.
.
.
<e :0  +:0  i:i >This handles words like dying and lying.C-insertion+:c  <=> y:i - - -  < a:a { t:t 1:1 b:b } >This is required for application.
Note that this rulerequires a clause in the Y-to- I  rule so that the the y:i inthis left context is al lowed by the Y-to-I  rule.K-insertion+:k <=> < V:V c:c > --- { < i:i n:n > e:e y:y }This caters for words ending in c that keep a hard cwhen a suffix is added e.g.
panicky and picnicking whileit does not require k insertion for words like criticise.A-deletiona:0 <=> < c:c e:0 +:0  > --- t:tA-deletion deals with examples like reduction(reduce + ation).E-to-Ie:i <=> c: .
.
.
.
< +:0  { a:a o:o } NB:NB>This covers words like pronounciation, gracious,spacious etc.
(The NB ( "not  b" )  set is to stop the ablesuffix from being affected.I- insertion+ :i < = > < C:C Vp:Vp NLR:NLR > --- <a:a  { n:n 1:1 } >Examples of  this are baronial, academician, civilian,dictatorial (This could be extended to cope with adver-bial, etc).C-to-Tc:t <=> n:n --- < =: i  +:0  a:a NB:NB >This should cope with evidential, influential.Y-deletiony:0 <=> g:g --- < +:0  i:i = :NG >Examples are allergic (from allergy+ic).L-deletion1:0 <=> b:b --- < e:0 +:0  1:1 >This rule deals with matching bly to ble+ly as inprobably.L-to- Il:i <=> b:b --- e:lE-to-LComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 305Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical Descriptione:l <=> l:i --- < +:0  i:i { t:t z:z s:s } >These above two rules deal with matching ability toable+ity as in probability, and similarly abilize toable+ize as in stabilize.
These rules are an interestingexample of how to deal with a change that happens overseveral characters.
They deal With matching bilO toble + where the il matches le.APPENDIX 3---COMPLETION RULESEach rule is preceded by a brief comment outlining itseffect.Add (BAR -1) as default to all entries with FIXspecifications.
( ((FIX fix)"(BAR ) rest) ) =>(& & ((FIX fix) (BAR -1) rest) & &)Add (LAT +) as default to all entries with Vspecifications.
( ((V v)"(LAT ) rest) ) =>(&&((V  v ) (LAT+)  rest )&&)Add (AT +) as default to all entries with (LAT +)specifications.
( ( (LAT+) ' (AT)  rest) ) =>(& & ((AT +) (LAT +) rest )&&)Add (INFL -) as default to all-entries with AFORMspecifications.
( ((AFORM af) ' ( INFL ) rest) ) =>(& & ((INFL -) (AFORM af) rest) & &)Add (INFL -) as default to all entries with VFORMspecifications.
( ((VFORM vf)"(INFL ) rest) ) =>(& & ((INFL -) (VFORM vf) rest) & &)Add (INFL -) as default to all entries with FINspecifications.
( ((FIN f in)'( INFL ) rest) ) =>(& & ((INFL -) (FIN fin) rest) & &)Add (INFL -) as default o all entries with (PLU +)specifications.
( ((PLU +)- ( INFL ) rest) ) =>(& & ((INFL -) (PLU +) rest) & &)Add (BAR 0) as default to all entries with V and Nspecifications.
( ((N n) (V v) "(BAR ) rest) ) =>(& & ((BAR 0) (N n)(V v) rest )&&)Add (PLU -) as default o all noun entries.
( ( (V - ) (N+) - (PLU)  rest) )=>(& & ((N + ) (V -) (PLU -) rest )&&)Add (INFL +) as default o all entries with (BAR -1)specifications.
( ( (BAR-1) ' ( INFL)  rest) ) =>(& & ((INFL +) (BAR -1) rest) & &)Add (INFL +) as default to all entries with (BAR 0)specifications.
( ((BAR 0) "(INFL ) rest) ) =>(& & ((INFL +) (BAR 0) rest) & &)Add (QUA -) as default o all adjective ntries.
( ((BAR 0) (V +) (N +) "(QUA ) rest) ) =>(& & ((BAR 0) (V +) (N +) (QUA -) rest) & &)Add (DEF -) as default to all entries with (QUA +)specifications.
( ( (QUA+) ' (DEF)  rest) ) =>(& & ((DEF -) (QUA +) rest) & &)Add (AUX -) as default o all verb entries.
( ((BAR 0) (V + ) (N -) "(AUX ) rest) ) =>(& & ((AUX -) (BAR 0) (V + ) (N -) rest) & &)Add (BARE-ADJ +) as default to all entries with(AFORM NONE) specifications.
( ((AFORMNONE)-(BARE-ADJ ) rest) ) =>(& & ((BARE-ADJ +) (AFORM NONE) rest) & &)Add (BARE-ADJ +) as default o all adjective ntrieswith (INFL +) specifications.
( ((V +) (N +) (INFL +) "(BARE-ADJ ) rest) ) =>(& & ((BARE-ADJ +) (V +) (N +) (INFL +) rest) & &)ACKNOWLEDGEMENTSThis work was supported by SERC/Alvey grantGR/C/79114.REFERENCESBear, John.
1986 A Morphological Recognizer with Syntactic andPhonological Rules.
In: Proceedings of the llth InternationalConference on Computational Linguistics.
Bonn, West Germany:272-276.Black, Alan W.; Ritchie, Graeme D.; Pulman, Stephen G.; andRussell, Graham J.
1987 Formalisms for Morphographemic De-scription.
In: Proceedings of 3rd Conference of the EuropeanChapter of the ACL.
Copenhagen, Denmark.Briscoe, Edward.J.
; Craig, I.; and Grover, Claire.
1986 The Use of theLOB Corpus in the Development of a Phrase Structure Grammarof English.
In: Proceedings of6th ICAME, Amsterdam.
(To bepublished eds.
Meijs, W., and van der Steen, G.J.
).Gazdar, Gerald; Klein Ewan; Pullum, Geoffrey K. and Sag, Ivan A.1985 Generalized Phrase Structure Grammar.
Blackwell, Oxford,England.306 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987Graeme D. Ritchie, Stephen G. Pulman, Alan W. Black, and Graham J. Russell A Framework for Lexical DescriptionIngria, Robert.
1986 Lexical Information for Parsing Systems: Pointsof Convergence and Divergence.
In: Proceedings of Workshop onAutomating the Lexicon, Grosseto, Italy.Karttunen, Laud and Wittenburg, Kent.
1983 A Two-level Morpho-logical Analysis of English.
Texas Linguistics Forum 22, Depart-ment of Linguistics, University of Texas, Austin, Texas: 217-228.Karttunen, L. 1983 KIMMO: A general morphological processor.Texas Linguistics Forum 22, Department of Linguistics, Univer-sity of Texas, Austin, Texas: 165-186.Kay, Martin.
1985 Parsing in Functional Unification Grammar.
In:Dowty, D.; Karttunen, L. and Zwicky, A.
(eds).
Natural Lan-guage Parsing.
Cambridge University Press, London: 251-278.Koskenniemi, Kimmo.
1983a Two-level model for morphologicalanalysis.
In: Proceedings of the Eighth International Joint Con-ference on Artificial Intelligence.
Karlsruhe, West Germany:683-685.Koskenniemi, Kimmo.
1983b Two-level Morphology: ageneral com-putational model for word-form recognition and production.
Pub-lication No.
11, University of Helsinki, Helsinki, Finland.Koskenniemi, Kimmo.
1985 Compilation of Automata from Two-Level Rules.
Talk given at Workshop on Finite-State Morphology,CSLI, Stanford, CA July 1985.Russell, Graham J.; Puiman, Stephen G.; Ritchie, Graeme D. andBlack, Alan W. 1986 A Dictionary and Morphological Analyser forEnglish.
In: Proceedings of the 1 lth International Conference onComputational Linguistics.
Bonn, West Germany: 277-279.Selkirk, Eiisabeth O.
1982 The Syntax of Words.
MIT Press, Cam-bridge, Mass.Stanley, Richard.
1967 Redundancy Rules in Phonology.
Language43, No.2: 393--436.Thorne, James P.; Bratley, Paul and Dewar, Hamish.
1968 TheSyntactic Analysis of English by Machine.
In: Michie, Donald,Ed., Machine Intelligence 3, Edinburgh University Press, Edin-burgh, Scotland: 281-309.Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 307
