Proceedings of the TextGraphs-6 Workshop, pages 1?9,Portland, Oregon, USA, 19-24 June 2011. c?2011 Association for Computational LinguisticsA Combination of Topic Models with Max-margin Learning for RelationDetectionDingcheng LiUniversity of MinnesotaTwin Cities, MN 55455lixxx345@umn.eduSwapna SomasundaranSiemens Corporate ResearchPrinceton, NJ 08540swapna.somasundaran@siemens.comAmit ChakrabortySiemens Corporate ResearchPrinceton, NJ 08540amit.chakraborty@siemens.comAbstractThis paper proposes a novel application ofa supervised topic model to do entity rela-tion detection (ERD).
We adapt Maximum En-tropy Discriminant Latent Dirichlet Alloca-tion (MEDLDA) with mixed membership forrelation detection.
The ERD task is refor-mulated to fit into the topic modeling frame-work.
Our approach combines the benefits ofboth, maximum-likelihood estimation (MLE)and max-margin estimation (MME), and themixed membership formulation enables thesystem to incorporate heterogeneous features.We incorporate different features into the sys-tem and perform experiments on the ACE2005 corpus.
Our approach achieves betteroverall performance for precision, recall andFmeasure metrics as compared to SVM-basedand LLDA-based models.1 IntroductionEntity relation detection (ERD) aims at finding rela-tions between pairs of Named Entities (NEs) in text.Availability of annotated corpora (NIST, 2003; Dod-dington et al, 2004) and introduction of shared tasks(e.g.
(Farkas et al, 2010; Carreras and Ma`rquez,2005)) has spurred a large amount of research in thisfield in recent times.
Researchers have used super-vised and semi-supervised approaches (Hasegawa etal., 2004; Mintz et al, 2009; Jiang, 2009), and ex-plored rich features (Kambhatla, 2004), kernel de-sign (Culotta and Sorensen, 2004; Zhou et al, 2005;Bunescu and Mooney, 2005; Qian et al, 2008) andinference algorithms (Chan and Roth, 2011), to de-tect predefined relations between NEs.In this work, we explore if and how the latent se-mantics of the text can help in detecting entity rela-tions.
For this, we adapt the Latent Dirichlet Alloca-tion (LDA) approach to solve the ERD task.
Specif-ically, we present a ERD system based on Maxi-mum Entropy Discriminant Latent Dirichlet Alloca-tion (MEDLDA).
MEDLDA (Zhu et al, 2009), isan extension of Latent Dirichlet Allocation (LDA)that combines capability of capturing latent seman-tics with the discriminative capabilities of SVM.There are a number of challenges in employingthe LDA framework for ERD.
Latent Dirichlet Allo-cation and its supervised extensions such as LabeledLDA (LLDA) (Ramage et al, 2009) and supervisedLDA (sLDA) (Blei and McAuliffe, 2008) are pow-erful generative models that capture the underlyingsemantics of texts.
However, they have trouble dis-covering marginal classes and easily employing richfeature sets, both of which are important for ERD.We overcome the first drawback by employing aMEDLDA framework, which integrates maximumlikelihood estimation (MLE) and maximum marginestimation (MME).
Specifically, it is a combinationof sLDA and support vector machines (SVMs).
Fur-ther, in order to employ rich and heterogeneous fea-tures we introduce a separate exponential family dis-tribution for each feature, similar to (Shan et al,2009), into our MEDLDA model.We formulate the relation detection task withinthe topic model framework as follows.
Pairs of NEmentions1 and the text between them is considered1Adopting the terminology used in the Automatic ContextExtraction (ACE) program (NIST, 2003), specific NE instancesare called mentions.1as mini-document.
Each mini-document has a re-lation type (analogous to the response variable inthe supervised topic model).
The topic model in-fers the topic (relation type) distribution of the mini-documents.
The supervised topic model discoversa latent topic representation of the mini-documentsand a response parameter distribution.
The topicrepresentation is discovered with observed responsevariables during training.
During testing, the topicdistribution of each mini-document can form a pre-diction of the relation types.We carry out experiments to measure the effec-tiveness of our approach and compare it to SVM-based and LLDA-based models, as well as to a pre-vious work using the same corpora.
We also mea-sure and analyze the effectiveness of incorporatingdifferent features in our model relative to other mod-els.
Our approach exhibits better overall precision,recall and Fmeasure than baseline systems.
We alsofind that the MEDLDA-based approach shows con-sistent capability for incorporation and improvementdue to a variety of heterogeneous features.The rest of the paper is organized as follows.
Wedescribe the proposed model in Section 2 and thefeatures that we explore in this work in Section 3.Section 4 describes the data, experiments, resultsand analyses.
We discuss the related work in Sec-tion 5 before concluding in Section 6.2 MEDLDA for Relation DetectionMEDLDA is an extension of LDA proposed by Zhu,Ahmed and Xing (2009).
LDA is itself unsuper-vised and the results are often hard to interpret.However, with the addition of supervised informa-tion (such as response variables), the resulting topicmodels have much better predictive power for classi-fication and regression.
In our work, we use relationannotations from the ACE (ACE, 2000 2005) corpusto provide the supervision.
NE pairs within a sen-tence, and the text between them are considered asa mini-document.
Each mini-document is assumedto be composed of a set of topics.
The topic modeltrained with these mini-documents given their rela-tion type label can generate topics biased toward re-lation types.
Thus, the trained topic model will havegood predictive power on relation types.We first describe the MEDLDA model from (Zhuet al, 2009) and then describe how we adapt it forrelation detection using mixed membership exten-sions.2.1 MEDLDAFigure 1: MEDLDAThe MEDLDA model described in (Zhu et al,2009) is illustrated in Figure 12.Here, ?
is a k-dimensional parameter of a Dirich-let distribution, ?1:k are the parameters for k compo-nent distribution over the words.
Each componentrefers to a topic.
In a collection of documents D,each document w1:N is generated from a sequenceof topics z1:N .
?
is a k-dimensional topic distribu-tion variable, which is sampled from a Dirichlet dis-tribution Dir(?).
Like common LDAs, MEDLDAuses independence assumption for a finite set of ran-dom variables z1, ..., zn which are independent andidentically distributed, conditioned on the parame-ter ?.
Like sLDA, MEDLDA is a supervised model.A response variable Y connected to each documentis added for incorporating supervised side informa-tion.
The supervised side information is expectedto make MEDLDA topic discoveries more inter-pretable.
Zhu, Ahmed and Xing?s (2009) MEDLDAmodel can be used in both regression and classifi-cation.
Concretely, Y is drawn from ?1:c, a c k-dimensional vector which can be derived from suit-able statistical model.
In our work, c is the num-ber of relation types.
Note that the plate diagramfor MEDLDA is quite similar to sLDA (Blei andMcAuliffe, 2008).
But there is a difference ?
sLDAfocuses on building regression models, and thus theresponse variable Y in sLDA is generated by a nor-mal distribution.Based on the plate diagram, the joint distributionof latent and observable variables for our MEDLDA-2(Zhu et al, 2009) do not have this plate digram in theirpaper; rather, we create this illustration from the description oftheir model.2based relation detection is given byp(?, z,w,y|?, ?1:k, ?1:c)=D?d=1p(?d|?)?
(N?n=1p(zdn|?d)p(wdn|zdn, ?1:k))?
p(yd|zd1:dN , ?1:c) (1)Another important difference from sLDA lies inthe fact that MEDLDA does joint learning with bothMME and MLE.
The joint learning is done in twostages, unsupervised topic discovery and multi-classclassification (we refer the reader to (Zhu et al,2009) for details).
During training, EM algorithmsare utilized to infer the posterior distribution of thehidden variables ?, z and ?.
In testing, the trainedmodels are used to predict relation types y.2.2 Mixed Membership MEDLDAAlthough the MEDLDA model described above canbe applied to the relation detection and classificationtask, a few modifications are necessary before it canbe effective in predicting relation types.
Mainly, aFigure 2: Mixed Membership MEDLDAlimitation of LDA or other existing topic models isthe difficulty in incorporating rich features.
This isbecause LDA is designed to handle data points withhomogeneous features such as words.
But for rela-tion detection, like many other NLP tasks, it is im-portant to have the flexibility of incorporating part-of-speech tags, named entities, grammatical depen-dencies and other linguistic features.
We overcomethis limitation by introducing a separate exponentialfamily distribution for each feature similar to (Shanet al, 2009).
Thus, our MEDLDA-based relationdetection model is really a mixed-member Bayesiannetwork.
Figure 2 illustrates our model with this ex-tension.Figure 2 is very similar to Figure 1; the only dif-ference is that the topic component number k is nowkN .
The generative process for each document thismodel is as follows:1.
Sample a component proportion ?d ?Dirichlet(?),2.
For each feature like word, part-of-speech,named entity in the document,(a) For n ?
{1, ..., N}, sample zdn = i ?Discrete(?d)(b) For n ?
{1,...,N}, sample wdn ?P (wdn|?dni)3.
Sample the relation type labelfrom a softmax(z?,?)
where yd ?softmax(exp(?Th z?
)?c?1h=1 exp(?Th z?
))In the sampling, index i is the number of the topiccomponent which ranges from 1 : k. P (wdn|?dni) in2(b) is an exponential family distribution where i isfrom 1...k. Note that now we have ?dni rather thanonly ?di since we have drawn separate distributionsfor each word (or feature) n.Now, our MEDLDA-based relation-detectionmodel can integrate diverse features of differenttypes or the same features with different parameters.Following the generative process, parameter es-timation and inferences can be made with eitherGibbs sampling or variational methods.
We use vari-ational methods since we adapt MEDLDA package3to mixed-membership MEDLDA and train relationdetection models.2.3 Relation DetectionWith the generative process, inference and parame-ter estimation in place, we are ready to perform rela-tion detection.
The first step is to perform variationalinference given the testing instances.In classification, we estimate the probability ofthe relation type given topics and the response pa-rameters, i.e.
p(yd|zd1:dN , ?1:c?1).
With variationalapproximation, we can derive the prediction rule asF (y, z1:N , ?)
= ?T f(y, z?)
where f(y, z?)
is a fea-ture vector.
Now, SVM can be used to derive the3this package is downloaded fromhttp://www.cs.cmu.edu/j?unzhu/medlda.htm3prediction rule.
The final prediction can be general-ized exactly the same as Zhu, Ahmed and Xing (Zhuet al, 2009):y?
= argmaxyE[?T f(y, Z?
)|?, ?]
(2)3 FeaturesWe explore the effectiveness of incorporating fea-tures into our systems as well as the baselines.
Forthis, we construct feature sets similar to Jiang andZhai (2007) and Zhou (2005).
Three kinds of fea-tures are employed:1.
BOW The Bag of Words (BOW) feature cap-tures all the words in our mini-document.
Itcomprises of the words of the two NE mentionsand the words between them.2.
SYN The SYN features are constructed to cap-ture syntactic, semantic and structural infor-mation of the mini-document.
They includefeatures such as HM1 (the head word of thefirst mention), HM2 (the head word of the sec-ond mention), ET1, ET2, M1 and M2 (Entitytypes and mention types of the two mentionsinvolved), #MB (number of other mentions inbetween the two mentions), #WB (number ofwords in between the two mentions).3.
COMP The COMP features are composite fea-tures that are similar to SYN, but they addition-ally capture language order and dependenciesbetween the features mentioned above.
Theseinclude features such as HM1HM2 (combininghead word of mention 1 and head word of men-tion 2) , ET12 (combinations of mention entitytype), ML12 (combination of mention levels),M1InM2 or M2InM1 (flag indicating whetherM2/M1 is included in M1/M2).The main intuitions behind employing compositefeatures, COMP, are as follows.
First, they capturethe ordering information.
The ordering of words arenot captured by BOW.
That is, BOW features as-sume exchangeability.
This works for models basedon random or seeded sampling (e.g.
LDA) ?
as longas words sampled are associated with a topic, thehidden topics of the documents can be discovered.In the case of ERD, this assumption might workwith symmetric relations.
However, when the rela-tions are asymmetric, ordering information is impor-tant.
Composite features such as HM1HM2 encodeswhat mention head word precedes the other.
Second,features such as M1InM2 or M2InM1 capture tokendependencies.
Besides exchangeability, LDA-basedmodels also assume that words are conditionally in-dependent.
Consequently, the system cannot capturethe knowledge that some mentions may be includedin other mentions.
By constructing features such asM1InM2 or M2InM1, we encode the dependency in-formation explicitly.4 ExperimentsAs MEDLDA is a combination of maximum mar-gin principle with maximum likelihood estimationfor topic modes, we compare it with two baselinesystems.
The first, SVM, uses only the maximummargin principle, while the second, LLDA, uses onlymaximum likelihood estimation for topic modeling.4.1 DataWe use the ACE corpus (Phase 2, 2005) for eval-uation.
The ACE corpus has annotations for bothentities and relations.
The corpus has six major re-lations types, 23 subtypes and 7 entity types.
In thiswork, we focus only on the six high-level relationtypes listed in Table 1.
In addition to the the 6 ma-jor types, we have an additional category, no relation(NO-REL), that exists between entities that are notrelated.The data for our experiments consists of pairs ofNEs from a sentence, and the gold standard annota-tion of their relation type (or NO-REL).
All relationsin the ACE corpus are intra-sentential and hence wedo not create NE pairs that cross sentence bound-aries.
Also, almost all positive instances are withintwo mentions of each other.
Hence, we create NEpairs for only those NEs that have at most 2 interven-ing NEs in between.
This gives us a total of 38,342relation instances of which 32,640 are negative in-stances (NO-REL) and 5702 are positive relation in-stances belonging to one of the 6 categories.4.2 Experimental SetupWe use 80% of the instances for training and 20%for testing.
The topic numbers and the penalty pa-rameter of the cost function C are first determined4Major Type Definition ExampleART artifactUser, owner, inventor or the makers of the KurskmanufacturerGEN-AFFcitizen, resident, religion, U.S. Companiesethnicity and organization-locationORG-AFFemployment, founder, ownership, The CEO of Siemens(Org-affiliation) sports-affiliation, investor-shareholderstudent-alumni and membershipPART-WHOLE geographical, subsidiary and so on a branch of U.S bankPER-SOCbusiness, family and a spokesman for the senator(person-social) lasting personal relationshipPHYS (physical) located or near a military base in GermanyTable 1: Relation types for ACE 05 corpusfor each of the models (wherever applicable) usingthe training data.
Best parameters are determinedfor the three conditions: 1) BOW features aloneBOW, 2) BOW plus SYN features (PlusSYN) and 3)BOW plus SYN and COMP features (PlusCOMP).All systems achieved their overall best performancewith PlusCOMP features (see Section 4.4 for a de-tailed analysis).4.2.1 MEDLDAThe number of topics are determined using theequation 2K0 + K1 following Zhu, Ahmed andXing (2009) and K1 = 2K0.
K0 is the numberof topics per class and K1 is the number of topicsshared by all relation types.
The choice of topics isbased on the intuition that the shared component K1should use all class labels to model common latentstructure while non-overlapping components shouldmodel specific characteristics data from each class.The ratio of topics is based on the understanding thatshared topics may be more than topics of each class.The specific numbers do not produce much variationin the final results.
We experimented with the fol-lowing number of topics: 20, 40, 70, 80, 90, 100,110.
BOW, PlusSYN, and PlusCOMP configura-tions obtain the best performance for 90 topics, 80topics, and 70 topics respectively.Since SVMs are employed in the MEDLDA im-plementation, we need to determine the penalty pa-rameter of the cost function, C. We used 5 fold cross-validation to locate the parameter C. The best valuesfor C are 25, 28, 30 respectively for BOW, PlusSYNand PlusCOMP configurations.
We used a linearkernel as it is the most commonly used kernel fortext classification tasks.
Since MEDLDA is run bysampling, the result may be different each time.
Weran it 5 times for each setting and took the averageas the final results.4.2.2 LLDA and SVMThe setting of topics for LLDA is similar toMEDLDA.
As LLDA is also run by sampling, weran it 5 times for each setting and took the averageas the final results.
In SVMlight, a grid search toolis provided to locate the the best value for parame-ter C. The best C for all three conditions was foundto be 1.
All other settings for the two models aresimilar to those of MEDLDA.4.3 ResultsPrec% Rec% F%SVM 53.2 35.2 40.3LLDA 28.3 51.6 36.6MEDLDA 57.8 53.2 55.4Table 2: Overall performance of the 3 systemsWe present the results of the three systems builtusing PlusCOMP, as all systems achieved their bestoverall performance using these features.
Table 2 re-ports the precision, recall and Fmeasure of the threesystems averaged across all 7 categories (the bestnumbers for each metric are highlighted in bold).Here we see that MEDLDA outperforms LLDA and5LabelsSVM LLDA MEDLDAPre% Rec% F% Pre% Rec% F% Pre% Rec% F%ART 30 8 14 1.5 33 3 49 36 41GEN-AFF 53 48 50 3 32 6 40 39 40ORG-AFF 55 35 43 59 58 59 53 59 56PART-WHOLE 39 08 14 31 82 45 44 52 48PER-SOC 50 17 25 7 92 13 73 76 75PHYS 55 35 43 26 47 33 56 19 29NO-REL 90 95 93 70 17 27 89 91 90Table 3: Multi-class Classification Results with PlusCOMP for SVM, LLDA and MEDLDA for the six ACE 05categories and NO-RELSVM across all metrics.
Specifically, there is a 15percentage point improvement in Fmeasure over thebest performing baseline.
This result indicates thatour approach of combining topic model with max-margin learning is effective for relation detection.Now, looking at the results for each individualrelationship category (see Table 3; the best num-bers for each category and metric are highlightedin bold) we see that the Fmeasure for MEDLDA isbetter than that for SVM for 4 out of the 6 ACE re-lation types; and better than the Fmeasure obtainedby LLDA for all relation types except ORG-AFF.Specifically, comparing with the best performingbaseline, MEDLDA produces a Fmeasure improve-ment 27 percentage points for ART, 3 percentagepoints for PART-WHOLE and 50 percentage pointsfor PER-SOC.
Also, for four of the six ACE rela-tion types, MEDLDA achieves the best precision.Even in the cases where MEDLDA is not the bestperformer for a relation category, its performance isnot very poor (unlike, for example, SVM for PART-WHOLE and LLDA for ART, respectively).Interestingly, the NO-REL category reveals asharp contrast in the performance of SVM andLLDA.
NO-REL is a difficult, catch-all categorythat is a mixture of data with diverse distributions.This is a category where maximum-margin learningis more effective than maximum-likelihood estima-tion.
Notice that MEDLDA achieves performanceclose to SVM for this category.
This is because,even though both LLDA and MEDLDA model hid-den topics and then employ discovered hidden topicsto predict relation types, MEDLDA does joint infer-ence of MLE and MME.
This joint inference helpsto improve the detection of NO-REL.Finally, we also compare our system?s results (us-ing PlusCOMP features) with the results of previ-ous research on the same corpus (Khayyamian et al,2009).
They use similar experimental settings: ev-ery pair of entities within a sentence is regarded toinvolve a negative relation instance unless it is anno-tated as positive in the corpus.
A similar filter (theyuse a distance filter) is used to sift out unrelated neg-ative instances.
Their train/test ratio of data split isalso the same as ours.Khayyamian, Mirroshandel and Abolhas-sani (2009) employ state-of-art kernel methodsdeveloped by Collins and Duffy (2002) and onlyreport Fmeasures over the six ACE relation types.For clarity, we reproduce their results in Table 4and repeat MEDLDA Fmeasures from Table 3 inthe last column.
The last row (Overall) reports themacro-averages computed over all relation types foreach system.
Here we see that overall, MEDLDAoutperforms all kernels.
MEDLDA also performsbetter than the best kernel for four of the six relationtypes.4.4 AnalysisAs mentioned previously, all three systems achievedtheir overall best performance with PlusCOMP fea-tures.
Here, we analyze if informative features areconsistently useful and if the systems can harnessthe informative features consistently across all re-lation types.
Figures 3, 4 and 5 illustrate the F-measures for SVM, LLDA and MEDLDA respec-tively for the three conditions: BOW, PlusSYN andPlusCOMP.6Labels CD?01 AAP AAPD TSAAPD-0 TSAAPD-01 MEDLDAART% 51 49 50 48 47 41GEN-AFF % 9 10 12 11 11 40ORG-AFF % 43 43 43 43 45 56PART-WHOLE % 30 28 29 30 28 48PER-SOC % 62 58 70 63 73 75PHYS % 32 36 29 33 33 29Overall (Avg) 38 37 39 38 40 48Table 4: F-measures for every kernel in (Khayyamian et al, 2009) and MEDLDAFigure 3: SVM Fmeausres for 3 feature conditionsFigure 4: LLDA Fmeausres for 3 feature conditionsFigure 5: MEDLDA Fmeausres for 3 feature conditionsLet us first look at the best systems (based onFmeasure) for each of the six ACE relation typesin Table 3, and look at what feature set pro-duces the best result for that system and relation.MEDLDA is the best performer for ART, PART-WHOLE and PER-SOC in Table 3.
Figure 5 re-veals that MEDLDA?s best performance for these re-lation types are obtained using PlusCOMP features.Similarly SVM obtains the best Fmeasure for GEN-AFF and PHYS relations and Figure 3 shows thatSVM achieves its best performance for these cate-gories using PlusCOMP.
We also see a similar trendwith LLDA and the ORG-AFF relation type.
Theseresults corroborate intuition from previous researchthat informative features are important for relationtype recognition.
The only exception to this is theperformance of SVM for NO-REL.
This is not sur-prising, as the features we use are focused on deter-mining true relation types and NO-REL is a mixtureof all cases (and features) where relations do not ex-ist.Further analysis of the figures reveal that eventhough there is a general trend towards better per-formance with addition of more informative fea-tures, not all systems show consistent improvementsacross all relation types with the addition of com-posite features.
That is, some systems get degradedperformance due to feature addition.
For example,in Figure 3, we see that the SVM with PlusCOMPfeatures is outperformed by SVM with PlusSYN forART and SVM with BOW for NO-REL.
The gainsfrom features are also inconsistent in the case ofLLDA (Figure 4).
While the LLDA system withPlusSYN features always improves over the one us-ing BOW, the performance drops considerably whenusing PlusCOMP features for ART and GEN-AFF.On the other hand, MEDLDA (see Figure 5) showsmore consistent improvement for all relation typeswith the addition of more complex features.
Also,7the gains are more substantial.
This is encouragingand opens up avenues for further exploration.5 Related WorkPrevious research has explored various methods andfeatures for relationship detection and mining.
Ker-nel methods have been popularly used for rela-tion detection.
Some examples are are dependencytree kernels (Culotta and Sorensen, 2004), short-est dependency path kernels (Bunescu and Mooney,2005), and more recently, convolution tree kernels(Zhao and Grishman, 2005; Zhang et al, 2006)context-sensitive convolution tree kernels (Zhou etal., 2007) and dynamic syntax tree kernels (Qian etal., 2008).
Kernel methods for relation extractionfocus on representing and capturing the structuredinformation of the text between the entities.
In ourMEDLDA model, instead of computing distancesbetween subtrees, we sample topics based on theirdistributions.
The sampling is not only on the (mini)document level, but also on the word level or on thesyntactic or semantic level.
Our model focuses onaddressing the underlying semantics more directlythan typical kernel-based methods.Chan and Roth (2011) employ constraints us-ing an integer linear programming (ILP) framework.Using this, they apply rich linguistic and knowledge-based constraints based on coreference annotations,a hierarchy of relations, syntacto-semantic structure,and knowledge from Wikipedia.
In our work, wefocus on capturing the latent semantics of the textbetween the NEs.A variety of features have been explored for ERDin previous research (Zhou et al, 2005; Zhou et al,2008; Jiang and Zhai, 2007; Miller et al, 2000).Syntactic features such as POS tags and dependencypath between entities; semantic features such asWord-Net relations, semantic parse trees and typesof NEs; and structural features such as which entitycame first in the sentence have been found useful forERD.
We too observe the utility of informative fea-tures for this task.
However, exploration of the fea-ture space is not the main focus of this work.
Rather,our focus is on whether the models are capable ofincorporating rich features.
A fuller exploration ofrich heterogeneous features is the focus of our fu-ture work.A closely related task is that of relation min-ing and discovery, where unsupervised, semi-supervised approaches have been effectively em-ployed (Hasegawa et al, 2004; Mintz et al, 2009;Jiang, 2009).
For example, Hasegawa et al (2004)use clustering and entity type information, whileMintz et al (2009) employ distant supervision.
OurERD task is different from these as we focus onclassifying the relation types into predefined relationtypes in the ACE05 corpus.Topic models have been applied previously for anumber of NLP tasks (e.g.
(Lin et al, 2006; Titovand McDonald, 2008).
LDAs have also been em-ployed to reduce feature dimensions in relation de-tection systems (Hachey, 2006).
However, to thebest of our knowledge, this is the first work to makeuse of topic models to perform relation detection.6 Conclusion and Future WorkIn this work, we presented a system for en-tity relation detection based on mixed-membershipMEDLDA.
Our approach was motivated by the ideathat combination of max margin and maximum like-lihood can help to improve relation detection task.For this, we adapted the existing work on MEDLDAand mixed membership models and formulated ERDas a topic detection task.
To the best of our knowl-edge, this is the first work to make full use of topicmodels for relation detection.Our experiments show that the proposed approachachieves better overall performance than SVM-based and LLDA-based approaches across all met-rics.
We also experimented with different featuresand the effectiveness of the different models for har-nessing these features.
Our analysis show that ourMEDLDA-based approach is able to effectively andconsistently incorporate informative features.As a model that incorporates maximum-likelihood, maximum-margin and mixed mem-bership learning, MEDLDA has the potential ofincorporating rich kernel functions or conditionaltopic random fields (CTRF) (Zhu and Xing, 2010).These are some of the promising directions for ourfuture exploration.8ReferencesACE.
2000-2005.
Automatic Content Extraction.http://www.ldc.upenn.edu/Projects/ACE/.D.M.
Blei and J. McAuliffe.
2008.
Supervised topicmodels.
Advances in Neural Information ProcessingSystems, 20:121?128.R.C.
Bunescu and R.J. Mooney.
2005.
A shortest pathdependency kernel for relation extraction.
In HLT &EMNLP.X.
Carreras and L. Ma`rquez.
2005.
Introduction to theCoNLL-2005 shared task: Semantic role labeling.
InCONLL, pages 152?164.
ACL.Y.
Chan and D. Roth.
2011.
Exploiting syntactico-semantic structures for relation extraction.
In ACL.M.
Collins and N. Duffy.
2002.
Convolution kernels fornatural language.
Advances in neural information pro-cessing systems, 1:625?632.A.
Culotta and J. Sorensen.
2004.
Dependency treekernels for relation extraction.
In Proceedings of the42nd Annual Meeting on Association for Computa-tional Linguistics, page 423.
ACL.G.
Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,S.
Strassel, and R. Weischedel.
2004.
The auto-matic content extraction (ACE) program?tasks, data,and evaluation.
In Proceedings of LREC, volume 4,pages 837?840.R.
Farkas, V. Vincze, G. Mo?ra, J. Csirik, and G. Szarvas.2010.
The CoNLL-2010 Shared Task: Learning to De-tect Hedges and their Scope in Natural Language Text.In CoNLL-2010, pages 1?12.B.
Hachey.
2006.
Comparison of similarity models forthe relation discovery task.
In COLING & ACL 2006,page 25.T Hasegawa, S Sekine, and Ralph Grishman.
2004.
Dis-covering relations among named entities from largecorpora.
In 42nd ACL.J.
Jiang and C.X.
Zhai.
2007.
A systematic explo-ration of the feature space for relation extraction.
InNAACL/HLT, pages 113?120.J.
Jiang.
2009.
Multi-task transfer learning for weakly-supervised relation extraction.
In 47th ACL & 4thAFNLP, pages 1012?1020.
ACL.N.
Kambhatla.
2004.
Combining lexical, syntactic, andsemantic features with maximum entropy models forextracting relations.
In ACL 2004 Interactive posterand demonstration sessions.M.
Khayyamian, S.A. Mirroshandel, and H. Abolhassani.2009.
Syntactic tree-based relation extraction using ageneralization of Collins and Duffy convolution treekernel.
In HLT/NAACL,: Student Research Workshop.Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side are you on?Identifying perspectives at the document and sentencelevels.
In CoNLL-2006.S.
Miller, H. Fox, L. Ramshaw, and R. Weischedel.
2000.A novel use of statistical parsing to extract informationfrom text.
In NAACL.M Mintz, S Bills, R Snow, and D Jurafsky.
2009.
Dis-tant supervision for relation extraction without labeleddata.
In 47th ACL & 4th AFNLP.US NIST.
2003.
The ACE 2003 Evaluation Plan.
US Na-tional Institute for Standards and Technology (NIST),pages 2003?08.L.
Qian, G. Zhou, F. Kong, Q. Zhu, and P. Qian.
2008.Exploiting constituent dependencies for tree kernel-based semantic relation extraction.
In 22nd ACL.D.
Ramage, D. Hall, R. Nallapati, and C.D.
Manning.2009.
Labeled LDA: A supervised topic model forcredit attribution in multi-labeled corpora.
In EMNLP.H.
Shan, A. Banerjee, and N.C. Oza.
2009.
Discrim-inative Mixed-membership Models.
In ICDM, pages466?475.
IEEE.Ivan Titov and Ryan McDonald.
2008.
A joint model oftext and aspect ratings for sentiment summarization.In ACL-08: HLT.M.
Zhang, J. Zhang, J. Su, and G. Zhou.
2006.
A com-posite kernel to extract relations between entities withboth flat and structured features.
In 21st ICCL & 44thACL.S.
Zhao and R. Grishman.
2005.
Extracting relationswith integrated information using kernel methods.
In43rd ACL.G Zhou, S. Jian, Z. Jie, and Z. Min.
2005.
Exploringvarious knowledge in relation extraction.
In In 43rdACL.G Zhou, M. Zhang, D.H. Ji, and Q Zhu.
2007.
Treekernel-based relation extraction with context-sensitivestructured parse tree information.
In EMNLP/CoNLL-2007, pages 728?736.G.D.
Zhou, M. Zhang, D.H. Ji, and Q.M.
Zhu.
2008.Hierarchical learning strategy in semantic relation ex-traction.
Information Processing & Management,44(3):1008?1021.J.
Zhu and E.P.
Xing.
2010.
Conditional Topic RandomFields.
In ICML.
ACM.J.
Zhu, A. Ahmed, and E.P.
Xing.
2009.
MedLDA: max-imum margin supervised topic models for regressionand classification.
In ICML, pages 1257?1264.
ACM.9
