Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 423?430,New York, June 2006. c?2006 Association for Computational LinguisticsA fast finite-state relaxation method for enforcingglobal constraints on sequence decodingRoy W. Tromble and Jason EisnerDepartment of Computer Science and Center for Language and Speech ProcessingJohns Hopkins UniversityBaltimore, MD 21218{royt,jason}@cs.jhu.eduAbstractWe describe finite-state constraint relaxation, a method for ap-plying global constraints, expressed as automata, to sequencemodel decoding.
We present algorithms for both hard con-straints and binary soft constraints.
On the CoNLL-2004 se-mantic role labeling task, we report a speedup of at least 16xover a previous method that used integer linear programming.1 IntroductionMany tasks in natural language processing involvesequence labeling.
If one models long-distance orglobal properties of labeled sequences, it can be-come intractable to find (?decode?)
the best labelingof an unlabeled sequence.Nonetheless, such global properties can improvethe accuracy of a model, so recent NLP papershave considered practical techniques for decod-ing with them.
Such techniques include Gibbssampling (Finkel et al, 2005), a general-purposeMonte Carlo method, and integer linear program-ming (ILP), (Roth and Yih, 2005), a general-purposeexact framework for NP-complete problems.Under generative models such as hidden Markovmodels, the probability of a labeled sequence de-pends only on its local properties.
The situationimproves with discriminatively trained models, suchas conditional random fields (Lafferty et al, 2001),which do efficiently allow features that are functionsof the entire observation sequence.
However, thesefeatures can still only look locally at the label se-quence.
That is a significant shortcoming, becausein many domains, hard or soft global constraints onthe label sequence are motivated by common sense:?
For named entity recognition, a phrase thatappears multiple times should tend to get thesame label each time (Finkel et al, 2005).?
In bibliography entries (Peng and McCallum,2004), a given field (author, title, etc.)
shouldbe filled by at most one substring of the in-put, and there are strong preferences on the co-occurrence and order of certain fields.?
In seminar announcements, a given field(speaker, start time, etc.)
should appear withat most one value in each announcement, al-though the field and value may be repeated(Finkel et al, 2005).?
For semantic role labeling, each argumentshould be instantiated only once for a givenverb.
There are several other constraints thatwe will describe later (Roth and Yih, 2005).A popular approximate technique is to hypothe-size a list of possible answers by decoding withoutany global constraints, and then rerank (or prune)this n-best list using the full model with all con-straints.
Reranking relies on the local model being?good enough?
that the globally best answer appearsin its n-best list.
Otherwise, reranking can?t find it.In this paper, we propose ?constraint relaxation,?a simple exact alternative to reranking.
As in rerank-ing, we start with a weighted lattice of hypothesesproposed by the local model.
But rather than restrictto the n best of these according to the local model,we aim to directly extract the one best according tothe global model.
As in reranking, we hope that thelocal constraints alone will work well, but if they donot, the penalty is not incorrect decoding, but longerruntime as we gradually fold the global constraintsinto the lattice.
Constraint relaxation can be usedwhenever the global constraints can be expressed asregular languages over the label sequence.In the worst case, our runtime may be exponentialin the number of constraints, since we are consider-ing an intractable class of problems.
However, weshow that in practice, the method is quite effectiveat rapid decoding under global hard constraints.4230O1?O?Figure 1: An automaton expressing the constraint that the labelsequence cannot be O?.
Here ?
matches any symbol except O.The remainder of the paper is organized as fol-lows: In ?2 we describe how finite-state automatacan be used to apply global constraints.
We thengive a brute-force decoding algorithm (?3).
In ?4,we present a more efficient algorithm for the case ofhard constraints.
We report results for the semanticrole labeling task in ?5.
?6 treats soft constraints.2 Finite-state constraintsPrevious approaches to global sequence labeling?Gibbs sampling, ILP, and reranking?seem moti-vated by the idea that standard sequence methods areincapable of considering global constraints at all.In fact, finite-state automata (FSAs) are powerfulenough to express many long-distance constraints.Since all finite languages are regular, any constraintover label sequences of bounded length is finite-state.
FSAs are more powerful than n-gram mod-els.
For example, the regular expression ??X??Y?
?matches only sequences of labels that contain an Xbefore a Y.
Similarly, the regular expression ?(O?
)requires at least one non-O label; it compiles into theFSA of Figure 1.Note that this FSA is in one or the other of its twostates according to whether it has encountered a non-O label yet.
In general, the current state of an FSArecords properties of the label sequence prefix readso far.
The FSA needs enough states to keep track ofwhether the label sequence as a whole satisfies theglobal constraint in question.FSAs are a flexible approach to constraints be-cause they are closed under logical operations suchas disjunction (union) and conjunction (intersec-tion).
They may be specified by regular expressions(Karttunen et al, 1996), in a logical language (Vail-lette, 2004), or directly as FSAs.
They may also beweighted to express soft constraints.Formally, we pose the decoding problem in termsof an observation sequence x ?
X ?
and possible la-bel sequences y ?
Y?.
In many NLP tasks, X is theset of words, and Y the tags.
A lattice L: Y?
7?
Rmaps label sequences to weights, and is encoded as aweighted FSA.
Constraints are formally the same?any function C: Y?
7?
R is a constraint, includ-ing weighted features from a classifier or probabilis-tic model.
In this paper we will consider only con-straints that are weighted in particular ways.Given a lattice L and constraints C, we seeky?def= argmaxy(L(y) +?C?CC(y)).
(1)We assume the lattice L is generated by a modelM : X ?
7?
(Y?
7?
R).
For a given observation se-quence x, we put L = M(x).
One possible modelis a finite-state transducer, where M(x) is an FSAfound by composing the transducer with x. Anotheris a CRF, where M(x) is a lattice with sums of log-potentials for arc weights.13 A brute-force finite-state decoderTo find the best constrained labeling in a lattice, y?,according to (1), we could simply intersect the lat-tice with all the constraints, then extract the bestpath.Weighted FSA intersection is a generalization ofordinary unweighted FSA intersection (Mohri et al,1996).
It is customary in NLP to use the so-calledtropical semiring, where weights are represented bytheir natural logarithms and summed rather thanmultiplied.
Then the intersected automaton L ?
Ccomputes(L ?
C)(y)def= L(y) + C(y) (2)To find y?, one would extract the best path inL ?
C1 ?
C2 ?
?
?
?
using the Viterbi algorithm, orDijkstra?s algorithm if the lattice is cyclic.
This stepis fast if the intersected automaton is small.The problem is that the multiple intersections inL ?
C1 ?
C2 ?
?
?
?
can quickly lead to an FSA withan intractable number of states.
The intersectionof two finite-state automata produces an automaton1For example, if M is a simple linear-chain CRF, L(y) =Pni=1 f(yi?1, yi) + g(xi, yi).
We build L = M(x) as anacyclic FSA whose state set is Y ?
{1, 2, .
.
.
n}, with transi-tions (y?, i?
1) ?
(y, i) of weight f(y?, y) + g(xi, y).424with the cross product state set.
That is, if F has mstates and G has n states, then F ?G has up to mnstates (fewer if some of the mn possible states donot lie on any accepting path).Intersection of many such constraints, even if theyhave only a few states each, quickly leads to a com-binatorial explosion.
In the worst case, the size, instates, of the resulting lattice is exponential in thenumber of constraints.
To deal with this, we presenta constraint relaxation algorithm.4 Hard constraintsThe simplest kind of constraint is the hard con-straint.
Hard constraints are necessarily binary?either the labeling satisfies the constraint, or it vi-olates it.
Violation is fatal?the labeling producedby decoding must satisfy each hard constraint.Formally, a hard constraint is a mappingC: Y?
7?{0,??
}, encoded as an unweighted FSA.
If a stringsatisfies the constraint, recognition of the string willlead to an accepting state.
If it violates the con-straint, recognition will end in a non-accepting state.Here we give an algorithm for decoding with a setof such constraints.
Later (?6), we discuss the caseof binary soft constraints.
In what follows, we willassume that there is always at least one path in thelattice that satisfies all of the constraints.4.1 Decoding by constraint relaxationOur decoding algorithm first relaxes the global con-straints and solves a simpler problem.
In particular,we find the best labeling according to the model,y?0def= argmaxyL(y) (3)ignoring all the constraints in C.Next, we check whether y?0 satisifies the con-straints.
If so, then we are done?y?0 is also y?.
Ifnot, then we reintroduce the constraints.
However,rather than include all at once, we introduce themonly as they are violated by successive solutions tothe relaxed problems: y?0, y?1, etc.
We definey?1def= argmaxy(L(y) + C(y)) (4)for some constraint C that y?0 violates.
Similarly,y?2 satisfies an additional constraint that y?1 violates,HARD-CONSTRAIN-LATTICE(L, C):1. y := Best-Path(L)2. while ?C ?
C such that C(y) = ??:3.
L := L ?
C4.
C := C ?
{C}5. y := Best-Path(L)6. return yFigure 2: Hard constraints decoding algorithm.and so on.
Eventually, we find some k for which y?ksatisfies all constraints, and this path is returned.To determine whether a labeling y satisfies a con-straint C, we represent y as a straight-line automa-ton and intersect with C, checking the result for non-emptiness.
This is equivalent to string recognition.Our hope is that, although intractable in the worstcase, the constraint relaxation algorithm will operateefficiently in practice.
The success of traditional se-quence models on NLP tasks suggests that, for nat-ural language, much of the correct analysis can berecovered from local features and constraints alone.We suspect that, as a result, global constraints willoften be easy to satisfy.Pseudocode for the algorithm appears in Figure 2.Note that line 2 does not specify how to chooseC from among multiple violated constraints.
Thisis discussed in ?7.
Our algorithm resembles themethod of Koskenniemi (1990) and later work.
Thedifference is that there lattices are unweighted andmay not contain a path that satisfies all constraints,so that the order of constraint intersection matters.5 Semantic role labelingThe semantic role labeling task (Carreras andMa`rques, 2004) involves choosing instantiations ofverb arguments from a sentence for a given verb.The verb and its arguments form a proposition.
Weuse data from the CoNLL-2004 shared task?thePropBank (Palmer et al, 2005) annotations of thePenn Treebank (Marcus et al, 1993), with sections15?18 as the training set and section 20 as the de-velopment set.
Unless otherwise specified, all mea-surements are made on the development set.We follow Roth and Yih (2005) exactly, in orderto compare system runtimes.
They, in turn, followHacioglu et al (2004) and others in labeling onlythe heads of syntactic chunks rather than all words.We label only the core arguments (A0?A5), treating425(a)0?1A0A02??
(b) 01O A0 A1 A2 A3 A4 A52O(verb position)A1A2A3A4A5 OA0(c)0OA0A1A2A3Figure 4: Automata expressing NO DUPLICATE A0 (?
matchesanything but A0), KNOWN VERB POSITION[2], and DISALLOWARGUMENTS[A4,A5].adjuncts and references as O.Figure 3 shows an example sentence from theshared task.
It is marked with an IOB phrase chunk-ing, the heads of the phrases, and the correct seman-tic role labeling.
Heads are taken to be the rightmostwords of chunks.
On average, there are 18.8 phrasesper proposition, vs. 23.5 words per sentence.
Sen-tences may contain multiple propositions.
There are4305 propositions in section 20.5.1 ConstraintsRoth and Yih use five global constraints on label se-quences for the semantic role labeling task.
We ex-press these constraints as FSAs.
The first two aregeneral, and the seven automata encoding them canbe constructed offline:?
NO DUPLICATE ARGUMENT LABELS(Fig.
4(a)) requires that each verb have atmost one argument of each type in a givensentence.
We separate this into six individualconstraints, one for each core argument type.Thus, we have constraints called NO DUPLI-CATE A0, NO DUPLICATE A1, etc.
Each ofthese is represented as a three-state FSA.?
AT LEAST ONE ARGUMENT (Fig.
1) simply re-quires that the label sequence is not O?.
This isa two-state automaton as described in ?2.The last three constraints require informationabout the example, and the automata must be con-structed on a per-example basis:?
ARGUMENT CANDIDATES (Fig.
5) encodes aset of position spans each of which must re-ceive only a single label type.
These spans wereproposed using a high-recall heuristic (Xue andPalmer, 2004).?
KNOWN VERB POSITION (Fig.
4(b)) simplyencodes the position of the verb in question,which must be labeled O.?
DISALLOW ARGUMENTS (Fig.
4(c)) specifiesargument types that are compatible with theverb in question, according to PropBank.5.2 ExperimentsWe implemented our hard constraint relaxation al-gorithm, using the FSA toolkit (Kanthak and Ney,2004) for finite-state operations.
FSA is an open-source C++ library providing a useful set of algo-rithms on weighted finite-state acceptors and trans-ducers.
For each example we decoded, we chose arandom order in which to apply the constraints.Lattices are generated from what amounts to aunigram model?the voted perceptron classifier ofRoth and Yih.
The features used are a subset of thosecommonly applied to the task.Our system produces output identical to that ofRoth and Yih.
Table 1 shows F-measure on the corearguments.
Table 2 shows a runtime comparison.The ILP runtime was provided by the authors (per-sonal communication).
Because the systems wererun under different conditions, the times are not di-rectly comparable.
However, constraint relaxation ismore than sixteen times faster than ILP despite run-ning on a slower platform.5.2.1 Comparison to an ILP solverRoth and Yih?s linear program has two kinds ofnumeric constraints.
Some encode the shortest pathproblem structure; the others encode the global con-straints of ?5.1.
The ILP solver works by relaxingto a (real-valued) linear program, which may obtaina fractional solution that represents a path mixtureinstead of a path.
It then uses branch-and-bound toseek the optimal rounding of this fractional solutionto an integer solution (Gue?ret et al, 2002) that repre-sents a single path satisfying the global constraints.Our method avoids fractional solutions: a relaxedsolution is always a true single path, which either426Mr.
Turner said the test will be shipped in 45 days to hospitals and clinical laboratories .B-NP I-NP B-VP B-NP I-NP B-VP I-VP I-VP B-PP B-NP I-NP B-PP B-NP O B-NP I-NP OTurner said test shipped in days to hospitals and laboratories .A0 O A1 A1 A1 A1 A1 A1 A1 A1 OFigure 3: Example sentence, with phrase tags and heads, and core argument labels.
The A1 argument of ?said?
is a long clause.01O A0 A1 A2 A3 A4 A52A2 A3 A4 A5 O A0 A14O10A016A122A228A334A440A55O11A017A123A229A335A441A542A543A544A545A53A546O A0 A1 A2 A3 A4 A5OA0A1A2A3A4A536A437A438A439A4A430A331A332A333A3A324A225A226A227A2A218A119A120A121A1A112A013A014A015A0A06O7O8O9OOFigure 5: An automaton expressing ARGUMENT CANDIDATES.Argument Count F-measureA0 2849 79.27A1 4029 75.59A2 943 55.68A3 149 46.41A4 147 81.82A5 4 25.00All 8121 74.51Table 1: F-measure on core arguments.satisfies or violates each global constraint.
In effect,we are using two kinds of domain knowledge.
First,we recognize that this is a graph problem, and insiston true paths so we can use Viterbi decoding.
Sec-ond, we choose to relax only domain-specific con-straints that are likely to be satisfied anyway (in ourdomain), in contrast to the meta-constraint of inte-grality relaxed by ILP.
Thus it is cheaper on aver-age for us to repair a relaxed solution.
(Our repairstrategy?finite-state intersection in place of branch-and-bound search?remains expensive in the worstcase, as the problem is NP-hard.
)5.2.2 Constraint violationsThe y?0s, generated with only local information,satisfy most of the global constraints most of thetime.
Table 3 shows the violations by type.The majority of best labelings according to thelocal model don?t violate any global constraints?a fact especially remarkable because there are nolabel sequence features in Roth and Yih?s unigramConstraint Violations FractionARGUMENT CANDIDATES 1619 0.376NO DUPLICATE A1 899 0.209NO DUPLICATE A0 348 0.081NO DUPLICATE A2 151 0.035AT LEAST ONE ARGUMENT 108 0.025DISALLOW ARGUMENTS 48 0.011NO DUPLICATE A3 13 0.003NO DUPLICATE A4 3 0.001NO DUPLICATE A5 1 0.000KNOWN VERB POSITION 0 0.000Table 3: Violations of constraints by y?0 .model.
This confirms our intuition that natural lan-guage structure is largely apparent locally.
Table 4shows the breakdown.
The majority of examples arevery efficient to decode, because they don?t requireintersection of the lattice with any constraints?y?0is extracted and is good enough.
Those exampleswhere constraints are violated are still relatively effi-cient because they only require a small number of in-tersections.
In total, the average number of intersec-tions needed, even with the naive randomized con-straint ordering, was only 0.65.
The order doesn?tmatter very much, since 75% of examples have oneviolation or fewer.5.2.3 Effects on lattice sizeFigure 6 shows the effect of intersection with vi-olated constraints on the average size of lattices,measured in arcs.
The vertical bars at k = 0,k = 1, .
.
.
show the number of examples where con-427Method Total Time Per Example PlatformBrute Force Finite-State 37m25.290s 0.522s Pentium III, 1.0 GHzILP 11m39.220s 0.162s Xeon, 3.x GHzConstraint Relaxation 39.700s 0.009s Pentium III, 1.0 GHzTable 2: A comparison of runtimes for constrained decoding with ILP and FSA.Violations Labelings Fraction Cumulative0 2368 0.550 0.5501 863 0.200 0.7502 907 0.211 0.9613 156 0.036 0.9974 10 0.002 0.9995 1 0.000 1.0006?10 0 0.000 1.000Table 4: Number of y?0 with each violation count.050010001500200025000  1  2  3  4  5VerbsMean Arcs with RelaxationMean Arcs with Brute ForceFigure 6: Mean lattice size (measured in arcs) throughout de-coding.
Vertical bars show the number of examples over whicheach mean is computed.straint relaxation had to intersect k contraints (i.e.,y?
?
y?k).
The trajectory ending at (for example)k = 3 shows how the average lattice size for thatsubset of examples evolved over the 3 intersections.The X at k = 3 shows the final size of the brute-forcelattice on the same subset of examples.For the most part, our lattices do stay muchsmaller than those produced by the brute-force algo-rithm.
(The uppermost curve, k = 5, is an obviousexception; however, that curve describes only theseven hardest examples.)
Note that plotting only thefinal size of the brute-force lattice obscures the longtrajectory of its construction, which involves 10 in-tersections and, like the trajectories shown, includeslarger intermediate automata.2 This explains the far2The final brute-force lattice is especially shrunk by its in-Constraint Violations FractionARGUMENT CANDIDATES 90 0.0209AT LEAST ONE ARGUMENT 27 0.0063NO DUPLICATE A2 3 0.0007NO DUPLICATE A0 2 0.0005NO DUPLICATE A1 2 0.0005NO DUPLICATE A3 1 0.0002NO DUPLICATE A4 1 0.0002Table 5: Violations of constraints by y?, measured over the de-velopment set.longer runtime of the brute-force method (Table 2).Harder examples (corresponding to longer trajec-tories) have larger lattices, on average.
This is partlyjust because it is disproportionately the longer sen-tences that are hard: they have more opportunitiesfor a relaxed decoding to violate global constraints.Hard examples are rare.
The left three columns,requiring only 0?2 intersections, constitute 96% ofexamples.
The vast majority can be decoded withoutmuch more than doubling the local-lattice size.6 Soft constraintsThe gold standard labels y?
occasionally violate thehard global constraints that we are using.
Countsfor the development set appear in Table 5.
Countsfor violations of NO DUPLICATE A?
do not includediscontinous arguments, of which there are 104 in-stances, since we ignore them.Because of the infrequency, the hard constraintsstill help most of the time.
However, on a small sub-set of the examples, they preclude us from inferringthe correct labeling.We can apply these constraints with weights,rather than making them inviolable.
This constitutesa transition from hard to soft constraints.
Formally,a soft constraint C: Y?
7?
R?
is a mapping from alabel sequence to a non-positive penalty.Soft constraints present new difficulty for decod-clusion of, for example, DISALLOW ARGUMENTS, which canonly remove arcs.
That constraint is rarely included in the re-laxation lattices because it is rarely violated (see Table 3).428SOFT-CONSTRAIN-LATTICE(L, C):1.
(y?, Score(y?))
:= (empty,??)2.
branches := [(L, C, 0)]3. while (L, C, penalty) := Dequeue(branches):4.
L := Prune(L, Score(y?)?
penalty)5. unless Empty(L):6. y := Best-Path(L)7. for C ?
C:8. if C(y) < 0: (* so C(y) = wC *)9.
C := C ?
{C}10.
Enqueue(branches, (L ?
C, C, penalty))11. penalty := penalty + C(y)12. if Score(y?)
< L(y) + penalty:13.
(y?, Score(y?))
:= (y, L(y) + penalty)14. return y?Figure 7: Soft constraints decoding algorithming, because instead of eliminating paths of L fromcontention, they just reweight them.In what follows, we consider only binary softconstraints?they are either satisfied or violated, andthe same penalty is assessed whenever a violationoccurs.
That is, ?C ?
C,?wC < 0 such that?y, C(y) ?
{0, wC}.6.1 Soft constraint relaxationThe decoding algorithm for soft constraints is a gen-eralization of that for hard constraints.
The differ-ence is that, whereas with hard constraints a vio-lation meant disqualification, here violation simplymeans a penalty.
We therefore must find and com-pare two labelings: the best that satisfies the con-straint, and the best that violates it.We present a branch-and-bound algorithm(Lawler and Wood, 1966), with pseudocode inFigure 7.
At line 9, we process and eliminate acurrently violated constraint C ?
C by consideringtwo cases.
On the first branch, we insist that C besatisfied, enqueuing L ?
C for later exploration.
Onthe second branch, we assume C is violated by allpaths, and so continue considering L unmodified,but accept a penalty for doing so; we immediatelyexplore the second branch by returning to the startof the for loop.3Not every branch needs to be completely ex-plored.
Bounding is handled by the PRUNE func-tion at line 4, which shrinks L by removing some3It is possible that a future best path on the second branchwill not actually violate C, in which case we have overpenalizedit, but in that case we will also find it with correct penalty on thefirst branch.or all paths that cannot score better than Score(y?
),the score of the best path found on any branch sofar.
Our experiments used almost the simplest possi-ble PRUNE: replace L by the empty lattice if the bestpath falls below the bound, else leave L unchanged.4A similar bounding would be possible in the im-plicit branches.
If, during the for loop, we find thatthe test at line 12 would fail, we can quit the forloop and immediately move to the next branch inthe queue at line 3.There are two factors in this algorithm that con-tribute to avoiding consideration of all of the expo-nential number of leaves corresponding to the powerset of constraints.
First, bounding stops evaluationof subtrees.
Second, only violated constraints re-quire branching.
If a lattice?s best path satisifies aconstraint, then the best path that violates it can beno better since, by assumption, ?y, C(y) ?
0.6.2 Runtime experimentsUsing the ten constraints from ?5.1, weightednaively by their log odds of violation, the soft con-straint relaxation algorithm runs in a time of 58.40seconds.
It is, as expected, slower than hard con-straint relaxation, but only by a factor of about two.As a side note, softening these particular con-straints in this particular way did not improve de-coding quality in this case.
It might help to jointlytrain the relative weights of these constraints andthe local model?e.g., using a perceptron algorithm(Freund and Schapire, 1998), which repeatedly ex-tracts the best global path (using our algorithm),compares it to the gold standard, and adjusts the con-straint weights.
An obvious alternative is maximum-entropy training, but the partition function wouldhave to be computed using the large brute-force lat-tices, or else approximated by a sampling method.7 Future workFor a given task, we may be able to obtain furtherspeedups by carefully choosing the order in whichto test and apply the constraints.
We might treat thisas a reinforcement learning problem (Sutton, 1988),4Partial pruning is also possible: by running the Viterbi ver-sion of the forward-backward algorithm, one can discover foreach edge the weight of the best path on which it appears.
Onecan then remove all edges that do not appear on any sufficientlygood path.429where an agent will obtain rewards by finding y?quickly.
In the hard-constraint algorithm, for ex-ample, the agent?s possible moves are to test someconstraint for violation by the current best path, orto intersect some constraint with the current lattice.Several features can help the agent choose the nextmove.
How large is the current lattice, which con-straints does it already incorporate, and which re-maining constraints are already known to be satis-fied or violated by its best path?
And what were theanswers to those questions at previous stages?Our constraint relaxation method should be testedon problems other than semantic role labeling.
Forexample, information extraction from bibliographyentries, as discussed in ?1, has about 13 fields to ex-tract, and interesting hard and soft global constraintson co-occurrence, order, and adjacency.
The methodshould also be evaluated on a task with longer se-quences: though the finite-state operations we usedo scale up linearly with the sequence length, longersequences have more chance of violating a globalconstraint somewhere in the sequence, requiring usto apply that constraint explicitly.8 ConclusionRoth and Yih (2005) showed that global constraintscan improve the output of sequence labeling modelsfor semantic role labeling.
In general, decoding un-der such constraints is NP-complete.
We exhibiteda practical approach, finite-state constraint relax-ation, that greatly sped up decoding on this NLP taskby using familiar finite-state operations?weightedFSA intersection and best-path extraction?ratherthan integer linear programming.We have also given a constraint relaxation algo-rithm for binary soft constraints.
This allows incor-poration of constraints akin to reranking features, inaddition to inviolable constraints.AcknowledgmentsThis material is based upon work supported bythe National Science Foundation under Grant No.0347822.
We thank Scott Yih for kindly providingboth the voted-perceptron classifier and runtime re-sults for decoding with ILP, and the reviewers forhelpful comments.ReferencesXavier Carreras and Llu?
?s Ma`rques.
2004.
Introduction to theCoNLL-2004 shared task: Semantic role labeling.
In Proc.of CoNLL, pp.
89?97.Jenny Rose Finkel, Trond Grenager, and Christopher Manning.2005.
Incorporating non-local information into informationextraction systems by Gibbs sampling.
In Proc.
of ACL, pp.363?370.Yoav Freund and Robert E. Schapire.
1998.
Large margin clas-sification using the perceptron algorithm.
In Proc.
of COLT,pp.
209?217, New York.
ACM Press.Christelle Gue?ret, Christian Prins, and Marc Sevaux.
2002.
Ap-plications of optimization with Xpress-MP.
Dash Optimiza-tion.
Translated and revised by Susanne Heipcke.Kadri Hacioglu, Sameer Pradhan, Wayne Ward, James H. Mar-tin, and Daniel Jurafsky.
2004.
Semantic role labeling bytagging syntactic chunks.
In Proc.
of CoNLL, pp.
110?113.Stephan Kanthak and Hermann Ney.
2004.
FSA: An efficientand flexible C++ toolkit for finite state automata using on-demand computation.
In Proc.
of ACL, pp.
510?517.Lauri Karttunen, Jean-Pierre Chanod, Gregory Grefenstette,and Anne Schiller.
1996.
Regular expressions for lan-guage engineering.
Journal of Natural Language Engineer-ing, 2(4):305?328.Kimmo Koskenniemi.
1990.
Finite-state parsing and disam-biguation.
In Proc.
of COLING, pp.
229?232.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.Conditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of ICML, pp.282?289.Eugene L. Lawler and David E. Wood.
1966.
Branch-and-bound methods: A survey.
Operations Research, 14(4):699?719.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated corpusof English: the Penn Treebank.
Computational Linguistics,19:313?330.Mehryar Mohri, Fernando Pereira, and Michael Riley.
1996.Weighted automata in text and speech processing.
In A. Ko-rnai, editor, Proc.
of the ECAI 96 Workshop, pp.
46?50.Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005.
TheProposition Bank: An annotated corpus of semantic roles.Computational Linguistics, 31(1):71?106.Fuchun Peng and Andrew McCallum.
2004.
Accurate informa-tion extraction from research papers using conditional ran-dom fields.
In Proc.
of HLT-NAACL, pp.
329?336.Dan Roth and Wen-tau Yih.
2005.
Integer linear programminginference for conditional random fields.
In Proc.
of ICML,pp.
737?744.Richard S. Sutton.
1988.
Learning to predict by the methods oftemporal differences.
Machine Learning, 3(1):9?44.Nathan Vaillette.
2004.
Logical Specification of Finite-StateTransductions for Natural Language Processing.
Ph.D. the-sis, Ohio State University.Nianwen Xue and Martha Palmer.
2004.
Calibrating featuresfor semantic role labeling.
In Proc.
of EMNLP, pp.
88?94.430
