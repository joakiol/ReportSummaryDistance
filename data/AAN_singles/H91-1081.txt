SPOKEN LANGUAGE SYSTEMSPI: John Makhoulmakhoul@bbn.comBBN Systems and Technologies, 10 Moulton St., Cambridge, MA 02138OBJECT IVESThe objective of this project is to develop a real-time spoken language system capable ofunderstanding and responding to spoken Englishcommands and queries for interactive human-machine applications, uch as battle management,command and control, and training of personnel oncomplex tasks.
The system will also include acapability to adapt o new speakers and a capabilityto detect when a user says a new word, and to allowthe user to add the word to the system.ACCOMPL ISHMENTSWork in this area requires the integration of threetechnologies: large-vocabulary continuous peechrecognition, natural anguage understanding, andsystem integration.
In our work at BBN, we haveintegrated our BYBLOS continuous speechrecognition technology with a new natural languageunderstanding component, DELPHI, resulting in acomplete spoken language system, called HARC(Hear And Respond to Continuous peech).
Amajor accomplishment of this project has been thedevelopment of a real-time version of HARC,implemented completely on commercially-availablehardware.
An N-best version of BYBLOS (seebelow) running in real-time has been implementedon a Sun 4 with a Sky Challenger signalprocessing board.
The DELPHI natural anguagecomponent also runs on a Sun 4.
The completesystem has been interfaced recently to a DARPA-sponsored military logistical planning system,called DART (Dynamic Analysis ReplanningTool).The DELPHI natural anguage component uses aUnification formalism for describing the syntax andsemantics of English and for enforcing syntacticand semantic onstraints.
It uses a higher-orderintensional logic for representing the meaning of asentence.
The system provides for the incrementalapplication of syntax and semantics; advantages ofthis approach are that unproductive s arch paths arecut off more quickly, and any improvements inunification parsing apply automatically tosemantics as well as syntax.
We have implementedunification semantics for our grammar rules in fourtask domains: battle management, personnelinformation retrieval, airline travel informationretrieval, and military logistical planning.
We haveinterfaced and extended the JANUS discoursemodule, developed under an earlier DARPA effort,to the HARC system.
We also developed a methodfor rapid porting of the natural anguage componentto new task domains using the Parlance Learner TMknowledge acquisition tool.
Recentaccomplishments in DELPHI include parsingspeedups, streamlining the unification grammar,and introducing mapping units into the semanticprocessing.
Syntactic and semantic parsing of asentence now takes less than one second on averageon a Sun 4.One important contribution has been thedevelopment of the N-best search strategy forintegrating speech and natural languagecomponents.
This method produces the N highestscoring sentences that match an input utterance,aided by a statistical language model.
The naturallanguage component hen searches these Nsentences for the highest scoring sentence for whichthe system can produce a semantic interpretation.The N-best paradigm, by providing a clean andsimple interface between speech and naturallanguage, has found immediate acceptance as themethod of choice in spoken language integration.An efficient two-pass (forward-backward) algorithmfor obtaining the N-best sentences has allowed theimplementation f the algorithm in real-time on aSun 4.In this project, we have been instrumental in thedesign of methodologies for the collection ofspoken language data and the objective valuationof spoken language systems.
We previously helpedspecify the DARPA Resource Management Corpusthat is now in common use for speech recognitionevaluation.
More recently, our proposals for theevaluation of spoken language systems have beenadopted by the DARPA community.We have developed what we believe to be the firstsuccessful method for the automatic detection ofout-of-vocabulary words.
This is an importantproblem for any realistic system with a largevocabulary.
Initial results show a 70% detectionrate with only 1% false alarm.
We have recentlydeveloped a capability for the addition of new wordsto a speech recognition system.407
