Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 203?212, Dublin, Ireland, August 23-29 2014.Time-aware Personalized Hashtag Recommendation on Social MediaQi Zhang, Yeyun Gong, Xuyang Sun, Xuanjing HuangShanghai Key Laboratory of Intelligent Information ProcessingSchool of Computer Science, Fudan University825 Zhangheng Road, Shanghai, P.R.China{qz, 12110240006, 13210240106, xjhuang}@fudan.edu.cnAbstractThe task of recommending hashtags for microblogs has been received considerable attention inrecent years, and many applications can reap enormous benefits from it.
Various approaches havebeen proposed to study the problem from different aspects.
However, the impacts of temporal andpersonal factors have rarely been considered in the existing methods.
In this paper, we propose anovel method that extends the translation based model and incorporates the temporal and personalfactors.
To overcome the limitation of only being able to recommend hashtags that exist in thetraining data of the existing methods, the proposed method also incorporates extraction strategiesinto it.
The results of experiments on the data collected from real world microblogging servicesby crawling demonstrate that the proposed method outperforms state-of-the-art methods that donot consider these aspects.
The relative improvement of the proposed method over the methodwithout considering these aspects is around 47.8% in F1-score.1 IntroductionOver the past few years, social media services have become one of the most important communicationchannels for people.
According to the statistic reported by the Pew Research Center?s Internet &American Life Project in Aug 5, 2013, about 72% of adult internet users are also members of at leastone social networking site.
Hence, microblogs have also been widely used as data sources for publicopinion analyses (Bermingham and Smeaton, 2010; Jiang et al., 2011), prediction (Asur and Huberman,2010; Bollen et al., 2011), reputation management (Pang and Lee, 2008; Otsuka et al., 2012), and manyother applications (Sakaki et al., 2010; Becker et al., 2010; Guy et al., 2010; Guy et al., 2013).
Inaddition to the limited number of characters in the content, microblogs also contain a form of metadatatag (hashtag), which is a string of characters preceded by the symbol (#).
Hashtags are used to mark thekeywords or topics of a microblog.
They can occur anywhere in a microblog, at the beginning, middle, orend.
Hashtags have been proven to be useful for many applications, including microblog retrieval (Efron,2010), query expansion (A.Bandyopadhyay et al., 2011), sentiment analysis (Davidov et al., 2010; Wanget al., 2011).
However, only a few microblogs contain hashtags provided by their authors.
Hence, thetask of recommending hashtags for microblogs has become an important research topic and has receivedconsiderable attention in recent years.Existing works have studied discriminative models (Ohkura et al., 2006; Heymann et al., 2008) andgenerative models (Krestel et al., 2009; Blei and Jordan, 2003; Ding et al., 2013) based on textualinformation from a single microblog.
However, from a dataset containing 282.2 million microblogscrawled from Sina Weibo1, we observe that different users may have different perspectives when pickinghashtags, and the perspectives of users are impacted by their own interests or the global topic trend.Meanwhile,the global topic distribution is likely to change over time.
To better understand how thetopics vary over time, we aggregate the microblog posts published in a month as a document.
Then, weuse a Latent Dirichlet Allocation (LDA) to estimate their topics.
Figure 1 illustrates an example, whereten active topics are selected.
We can observe that the topics distribution varies greatly over time.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1http://www.weibo.com.
It is one of the most popular microblog services in China.2032012-04 2012-06 2012-08 2012-10 2012-12 2013-02 2013-04020040060080010001200payofficialstaffsupportministrystatisticstomorrowreproduceresearchfinancialnetworkJapaneseculturetogetheryourself lifeincentive streetPisces AriesLeo HoroscopePlutoiphoneAppledesignfoodwaterTaurusVenuschargeslifeuniversitieseducationhusbandownwomenhomesuccessson likesaintsundayemployeesfilmloyalty husbandchildrenparenthappynesslikeegg  pumpkinFigure 1: An example of the topics of retweets in each month.
Each colored stripe represents a topic,whose height is the number of words assigned to the topic.
For each topic, the top words of this topic ineach month are placed on the stripe.Motivated by the methods proposed to handle the vocabulary gap problem for keyphrase extrac-tion (Liu et al., 2012) and hashtag suggestion (Ding et al., 2013), in this work, we also assume thatthe hashtags and textual content in a microblog are parallel descriptions of the same thing in differentlanguages.
To model the document themes, in this paper, we adopt the topical translation model tofacilitate the translation process.
Topic-specific word triggers are used to bridge the gap between thewords and hashtags.
Since existing topical translation models can only recommend hashtags learnedfrom the training data, we also incorporate an extraction process into the model.This work makes three main contributions.
First, we incorporate temporal and personal factors intoconsiderations.
Most of the existing works on hashtag recommendation tasks have focused on textualinformation.
Second, we adopt a topical translation model to combine extraction and translation methods.This makes it possible to suggest hashtags that are not included in the training data.
Third, to evaluatethe task, we construct a large collection of microblogs from a real microblogging service.
All of themicroblogs in the collection contain textual content and hashtags labeled by their authors.
This canbenefit other researchers investigating the same task or other topics using author-centered data.The remaining part of this paper is structured as follows: We briefly review existing methods inrelated domains in Section 2.
Section 3 gives an overview of the proposed generation model.
Section4 introduces the dataset construction, experimental results and analyses.
In Section 5, we will concludethe paper.2 Related WorksDue to the usefulness of tag recommendation, many methods have been proposed from differentperspectives (Heymann et al., 2008; Krestel et al., 2009; Rendle et al., 2009; Liu et al., 2012; Ding et al.,2013).
Heymann et al.
(Heymann et al., 2008) investigated the tag recommendation problem using thedata collected from social bookmarking system.
They introduced an entropy-based metric to capture thegenerality of a particular tag.
In (Song et al., 2008), a Poisson Mixture Model based method is introducedto achieve the tag recommendation task.
Krestel et al.
(Krestel et al., 2009) introduced a Latent DirichletAllocation to elicit a shared topical structure from the collaborative tagging effort of multiple users forrecommending tags.
Based on the the observation that similar webpages tend to have the same tags, Lu etal.
proposed a method taking both tag information and page content into account to achieve the task (Luet al., 2009).
Ding et al.
proposed to use translation process to model this task (Ding et al., 2013).
Theyextended the translation based method and introduced a topic-specific translation model to process thevarious meanings of words in different topics.
In (Tariq et al., 2013), discriminative-term-weights wereused to establish topic-term relationships, of which users?
perception were learned to suggest suitablehashtags for users.
To handle the vocabulary problem in keyphrase extraction task, Liu et al.
proposed a204topical word trigger model, which treated the keyphrase extraction problem as a translation process withlatent topics (Liu et al., 2012).Most of the works mentioned above are based on textual information.
Besides these methods,personalized methods for different recommendation tasks have also been paid lots of attentions (Lianget al., 2007; Shepitsen et al., 2008; Garg and Weber, 2008; Li et al., 2010; Liang et al., 2010; Rendle andSchmidt-Thieme, 2010).
Shepitsen et al.
(2008) proposed to use hierarchical agglomerative clusteringto take into account personalized navigation context in cluster selection.
In (Garg and Weber, 2008),the problem of personalized, interactive tag recommendation was also studied based on the statics of thetags co-occurrence.
Liang et al.
(2010) proposed to the multiple relationships among users, items andtags to find the semantic meaning of each tag for each user individually and used this information forpersonalized item recommendation.From the brief descriptions given above, we can observe that most of the previous works on hashtagsuggestion focused on textual information.
In this work, we propose to incorporate temporal and personalinformation into the generative methods.
Further more, to over the limitation that translation basedmethod can only recommend hashtags learned from the training data, we also propose to incorporate anextraction process into the model.3 The Proposed MethodsIn this section, we firstly introduce the notation and generation process of the proposed method.
Then,we describe the method used for learning parameters.
Finally, we present the methods of how do weapply the learned model to achieve the hashtag recommendation task.3.1 The Generation ProcessWe use D to represent the number of microblogs in the given corpus, and the microblogs have beendivided into T epoches.
Let t = 1, 2, ..., T be the index of an epoches, ?tis the topic distribution of theepoch t. Each microblog is generated by a user ui, where uiis an index between 1 and U , and U is thetotal number of users.
A microblog is a sequence of Ndwords denoted by wd= {wd1, wd2, ..., wdNd}.Each microblog contains a set of hashtags denoted by hd= {hd1, hd2, ..., hdMd}.
A word is defined asan item from a vocabulary with W distinct words indexed by w = {w1, w2, ..., wW}.
Each hashtag isfrom the vocabulary with V distinct hashtags indexed by h = {h1, h2, ..., hV}.
The notations in thispaper are summarized in Table 1.The original LDA assumes that a document is contains a mixture of topics, which is represented by atopic distribution, and each word has a hidden topic label.
Although, it is sensible for long document,due to the limitations of the length of characters in a single microblog, it tends to be about a single topic.Hence, we associate a single hidden variable with each microblog to indicate its topic.
Similar idea ofassigning a single topic to a short sequence of words has also been used for modeling Twitters (Zhao etal., 2011)The hashtag recommendation task is to discover a list of hashtags for each unlabeled microblog, Inour method, we first learn a topical translation model, and then we estimate the latent variables for eachmicroblog, finaly recommending hashtags accord to the learned model.Fig.
2 shows the graphical representation of the generation process.
The generative story for eachmicroblog is as follows:3.2 LearningTo learn the parameters of our model, we use collapsed Gibbs sampling (Griffiths and Steyvers, 2004) tosample the topics assignment z, latent variables assignment x and y.Given the current state of all but the variable xdand zdfor the dth microblog, we can jointly sample2051.
Draw pi ?
Beta(?
), ?
?
Beta(?)2.
Draw background word distribution ?B?
Dirichlet(?w)3.
Draw global trendy topic distribution ?t?
Dirichlet(?)
for each time epoch t = 1, 2, ..., T4.
Draw personal topic distribution ?u?
Dirichlet(?)
for each user u = 1, 2, ..., U5.
Draw word distribution ?z?
Dirichlet(?w) for each topic z = 1, 2, ...,K6.
Draw hashtag distribution ?z,w?
Dirichilet(?h) for each topic z = 1, 2, ...,K and each wordw = 1, 2, ...,W7.
For each microblog d = 1, 2, ..., Da.
Draw xd?
Bernoulli(?)b.
If xd= 0 thenDraw a topic zd?Multinomial(?u)End ifIf xd= 1 thenDraw a topic zd?Multinomial(?t)End ifc.
For each word n = 1, ..., Ndi.
Draw ydn?
Bernoulli(pi)ii.
If ydn= 0 thenDraw a word wdn?Multinomial(?B)End ifIf ydn= 1 thenDraw a word wdn?Multinomial(?zd)End ifd.
For each hashtag m = 1, ...,Mdi.
Draw hdm?
P (hdm|wd, zd, ?zd,wd)wdnzd?t?utdudxd???
?hdmydnpi?
?z?B?w?w?z,w?hTMdNdDKUWKFigure 2: The graphical representation of the proposed model.
Shaded circles are observations orconstants.
Unshaded ones are hidden variables.206Table 1: The notations used in this work.D The number of training data setW The number of unique word in the corpusV The number of unique hashtag in the corpusK The number of topicsT The total number of time epochesU The total number of usersNdThe number of words in the dth microblogMdThe number of hashtags in the dth microblogzdThe topic of the dth microblogxdThe latent variable decided the distribution category of zdydnThe latent variable decided the distribution category of wdnpi The distribution of latent variable ydn?
The distribution of latent variable xd?zThe distribution of topic words?BThe distribution of background words?tThe distribution of topics for time epoch t?uThe distribution of topics for user utdThe time epoch for microblog dudThe user of the microblog d?
The topic-specific word alignment table between word and hashtag or itselfxdand zd, the conditional probability of xd= p,zd= k is calculated as follows:Pr(xd= p, zd= k|z?d,x?d,y,w,h)?N?p+ ?N?(.
)+ 2?
?Nlk+ ?Nl(.)+K?
?Nd?n=1Nkwdn+ ?wNk(.
)+W?w?Md?m=1Nd?n=1Mwdn,hdm?d,k+ ?hMwdn,(.
)?d,k+ V ?h,(1)where l = udwhen p = 0 and l = tdwhen p = 1.
N?0is the number of microblog generated by personalinterests, while N?1is the number of microblog coming from global topical trends, N?(.
)= N?0+ N?1.Nudkis the number of microblogs generated by user udand under topic k.
Nud(.
)is the total number ofmicroblogs generated by user ud.
Ntdk=?tdt?=1e?t?
?N?t?t?k,N?t?t?kis the number of microblogs assignedto topic k at time epoch t ?
t?, e?t?
?is decay factory, and Ntd(.)=?Kk=1Ntdk.
Nkwdnis the times of wordwdnassigned to topic k, Nk(.
)is the times of all the word assigned to topic k, Mwdn,hdm?d,kis the number ofoccurrences that word wdnis translated to hashtag hdmgiven topic k. All the counters mentioned aboveare calculated with the dth microblog excluded.We sample ydnfor each word wdnin the dth microblog using the following equation:Pr(ydn= q|z,x,y?dn,w,h) ?Npiq+ ?Npi(.
)+ 2?
?Nlwdn+ ?wNl(.
)+W?w,(2)where l = B when q = 0 and l = zdwhen q = 1.
Npi0is the number of words assigned to backgroundwords and Npi1is the number of words under any topic respectively.
Npi(.
)= Npi0+Npi1, NBwdnis a countof word wdnoccurs as a background word.
Nzdwdnis the number of word wdnis assigned to topic zd, andNzd(.
)is the total number of words assigned to topic zd.
All counters are calculated with taking no accountof the current word wdn.In many cases, hashtag dose not appear in the training data, to solve this problem, we assume that eachword in the microblog can translate to a hashtag in the training data or itself.
We assume that each word207have aligned ?
(we set ?
= 1 in this paper after trying some number) times with itself under the specifictopic.
After all the hidden variables become stable, we can estimate the alignment probability as follows:?h,w,z=???Nhz,w+?hN(.
)z,w+?+(V+1)?hif h is a hashtag in the training data?+?hN(.
)z,w+?+(V+1)?hif h is the word itself(3)where Nhz,wis the number of the hashtag h co-occurs with the word w under topic z in the microblogs.For the probability alignment ?
between hashtag and word, the potential size is W ?
V ?
K. Thedata sparsity poses a more serious problem in estimating ?
than the topic-free word alignment case.To remedy the problem, we use interpolation smoothing technique for ?.
In this paper, we emplogysmoothing as follows:?
?h,w,z= ?
?h,w,z+ (1?
?
)P (h|w),(4)where ?
?h,w,zis the smoothed topical alignment probabilities, ?h,w,zis the original topical alignmentprobabilities.
P (h|w) is topic-free word alignment probability.
Here we obtain P (h|w) by exploringIBM model-1 (Brown et al., 1993).
?
is trade-off of two probabilities ranging from 0.0 to 1.0.
When?
= 0.0, ?
?h,w,zwill be reduce to topic-free word alignment probability; and when ?
= 1.0, there will beno smoothing in ??h,w,z.
For the word itself there are no smoothing, because it is a pseudo-count.3.3 Hashtag ExtractionWe perform hashtag extraction as follows.
Suppose given an unlabeled dataset, we perform GibbsSampling to iteratively estimate the topic and determine topic/background words for each microblog.The process is the same as described in Section 3.2.
After the hidden variables of topic/backgroundwords and the topic of each microblog become stable, we can estimate the distribution of topics for thedth microblog in unlabeled data by:?
?dk=p(k)p(wd1|k)...p(wdNd|k)Zwhere p(wdn|k) =Npi1+?Npi(.)+2??Nkwdn+?wNk(.
)+W?wand Nkwdnis the number of words wdnthat are assigned to topic k in the corpus, and p(k) =N?0+?N?(.)+2??Nuk+?Nu(.)+K?+N?1+?N?(.)+2??Ntk+?Nt(.
)+K?is regarded as a prior for topic distribution, Z is the normalizedfactor.
With topic distribution ?
?and topical alignment table ?
?, we can rank hashtags for the dthmicroblog in unlabeled data by computing the scores:P (hdm|wd, ?
?d, ??)
?K?zd=1Nd?n=1P (hdm|zd, wdn, ??)
?
P (zd|?
?d) ?
P (wdn|wd),(5)where hdmcan be a hashtag in the training data or a word in the dth microblog, p(wdn|wd) is the weightof the word wdnin the microblog, which can be estimated by the IDF score of the word.
According tothe ranking scores, we can suggest the top-ranked hashtags for each microblog to users.4 ExperimentsIn this section, we introduce the experimental results and the data collection we constructed for trainingand evaluation.
Firstly, we describe how do we construct the collection and statics of it.
Then weintroduce the experiment configurations and baseline methods.
Finally, the evaluation results andanalysis are given.4.1 Data CollectionWe use a dataset collected from Sina Weibo to evaluate the proposed approach and alternative methods.We random select 166,864 microblogs from Aug. 2012 to June 2013.
The unique number of hashtagsin the corpus is 17,516.
We use the microblogs posted from Aug. 2012 to May 2013 as the trainingdata.
The other microblogs are used for evaluation.
The hashtags marked in the original microblogs areconsidered as the golden standards.208Figure 3: Precision-recall curves of differentmethods on this task.0.000.050.100.150.200.250.300.350.400.450.500 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8PrecisionRecallTWTMTTMT-TTMU-TTMTU-TTMK-TTMTUK-TTMTable 2: Evaluation results of different methodson the evaluation collection.Methods Precision Recall F1TWTM 0.231 0.202 0.215SVM 0.418 0.366 0.390TTM 0.319 0.279 0.297T-TTM 0.338 0.301 0.319U-TTM 0.341 0.307 0.323K-TTM 0.386 0.337 0.360TU-TTM 0.355 0.310 0.331TUK-TTM 0.452 0.415 0.4334.2 Experiment ConfigurationsWe use precision (P ), recall (R), and F1-score (F1) to evaluate the performance.
Precision is calculatedbased on the percentage of ?hashtags truly assigned?
among ?hashtags assigned by system?.
Recallis calculated based on the ?hashtags truly assigned?
among ?hashtags manually assigned?.
F1-scoreis the harmonic mean of precision and recall.
We do 500 iterations of Gibbs sampling to train themodel.
For optimize the hyperparmeters of the proposed method and alternative methods, we use 5-foldcross-validation in the training data to do it.
The number of topics is set to 70.
The other settings ofhyperparameters are as follows: ?
= 50/K, ?w= 0.1, ?h= 0.1, ?
= 0.01, and ?
= 0.01.
Thesmoothing factor ?
in Eq.
(3) is set to 0.6.
For estimating the translation probability without topicalinformation, we use GIZA++ 1.07 to do it (Och and Ney, 2003).For baselines, we compare the proposed model with the following alternative models.?
TWTM: Topical word trigger model (TWTM) was proposed by Liu et al.
for keyphrase extractionusing only textual information (Liu et al., 2012).
We implemented the model and used it to achievethe task.?
TTM: Ding et al.
(2013) proposed the topical translation model (TTM) for hash tag extraction.
Weimplemented and extended their method for evaluating it on the corpus constructed in this work.4.3 Experimental ResultsTable 2 shows the comparisons of the proposed method with the state-of-the-art methods on theconstructed evaluation dataset.
?TUK-TTM?
denotes the method proposed in this paper.
?T-TTM?and ?U-TTM?
represent the methods incorporating temporal and personal information respectively.
?K-TTM?
represents the method incorporating the extraction factor.
From the results, we can observe thatthe proposed method is significantly better than other methods at 5% significance level (two-sided).Comparing to results of the TTM, we can observe that the temporal information, personal informationand extraction strategy can all benefit the task.
Among the three additional factors, the extraction strategyachieves the best result.
The limitation of only being able to recommend hashtags that exist in the trainingdata can be overcome in some degree by the proposed method.
The relative improvement of proposedTUK-TTM over TTM is around 47.8% in F1-score.Table 3 shows the comparisons of the proposed method with the method ?K-TTM?
in two corpus NE-Corpus and E-Corpus.
NE-Corpus include microblogs whose hashtags are not contained in the trainingdata.
E-Corpus include the microblogs whose hashtags appear in the training data.
We can observe thatthe proposed method significantly better than ?K-TTM?
in the E-Corpus.
Another observation is thatthe method incorporating the extraction factor achieves better performances on the NE-Corpus than E-Corpus.
We think that the reason is that the fewer times hashtag appear, the greater weight it has.
Hence,we can extract this kind of hashtags more easier.Figure 3 shows the precision-recall curves of TWTW, TTM, T-TTM, U-TTM, TU-TTM, K-TTM,and TUK-TTM on the evaluation dataset.
Each point of a precision-recall curve represents extracting209Table 3: Evaluation results of two different corpus.Corpus Methods P R FNE-CorpusK-TTM 0.631 0.553 0.589TUK-TTM 0.641 0.561 0.598E-CorpusK-TTM 0.172 0.162 0.167TUK-TTM 0.288 0.271 0.279Table 4: The influence of the number of topicsK of TUK-TTM.K Precision Recall F110 0.410 0.382 0.39630 0.435 0.380 0.40650 0.448 0.413 0.43070 0.452 0.415 0.433100 0.439 0.404 0.421Table 5: The influence of the smoothingparameter ?
of TUK-TTM.?
Precision Recall F10.0 0.379 0.354 0.3660.2 0.405 0.372 0.3880.4 0.433 0.398 0.4150.6 0.452 0.415 0.4330.8 0.426 0.386 0.4051.0 0.423 0.381 0.401different number of hashtags ranging from 1 to 5 respectively.
In the figure, curves which are closeto the upper right-hand corner of the graph indicate the better performance.
From the results, we canobserve that the performance of TUK-TTM is in the upper right-hand corner.
It also demonstrates thatthe proposed method achieves better performances than other methods.From the description of the proposed model, we can know that there are several hyperparameters inthe proposed TUK-TTM.
To evaluate the impacts of them, we evaluate two crucial ones, the number oftopics K and the smoothing factor ?.
Table 4 shows the influence of the number of topics.
From thetable, we can observe that the proposed model obtains the best performance when K is set to 70.
Andperformance decreases with more number of topics.
We think that data sparsity may be one of the mainreasons.
With much more topic number, the data sparsity problem will be more serious when estimatingtopic-specific translation probability.
Table 5 shows the influence of the translation probability smoothingparameter ?.
When ?
is set to 0.0, it means that the topical information is omitted.
Comparing the resultsof ?
= 0.0 and other values, we can observe that the topical information can benefit this task.
When ?
isset to 1.0, it represents the method without smoothing.
The results indicate that it is necessary to addressthe sparsity problem through smoothing.5 ConclusionsIn this paper, we propose a novel method which incorporates temporal and personal factors into thetopical translation model for hashtag recommendation task.
Since existing translation model basedmethods for this task can only recommend hashtags that exist in the training data of the topical translationmodel, we also incorporate extraction strategies into the model.
To evaluate the proposed method, wealso construct a dataset from real world microblogging services.
The results of experiments on the datasetdemonstrate that the proposed method outperforms state-of-the-art methods that do not consider theseaspects.6 AcknowledgementThe authors wish to thank the anonymous reviewers for their helpful comments.
This work waspartially funded by 973 Program (2010CB327900), National Natural Science Foundation of China(61003092,61073069), Shanghai Leading Academic Discipline Project (B114) and ?Chen Guang?project supported by Shanghai Municipal Education Commission and Shanghai Education DevelopmentFoundation(11CG05).210ReferencesA.Bandyopadhyay, M. Mitra, and P. Majumder.
2011.
Query expansion for microblog retrieval.
In Proceedingsof The Twentieth Text REtrieval Conference, TREC 2011.S.
Asur and B.A.
Huberman.
2010.
Predicting the future with social media.
In WI-IAT?10, volume 1, pages492?499.Hila Becker, Mor Naaman, and Luis Gravano.
2010.
Learning similarity metrics for event identification in socialmedia.
In Proceedings of WSDM ?10.Adam Bermingham and Alan F. Smeaton.
2010.
Classifying sentiment in microblogs: is brevity an advantage?
InProceedings of CIKM?10.D.M.
Blei and M.I.
Jordan.
2003.
Modeling annotated data.
In Proceedings of SIGIR, pages 127?134.Johan Bollen, Huina Mao, and Xiaojun Zeng.
2011.
Twitter mood predicts the stock market.
Journal ofComputational Science, 2(1):1 ?
8.Peter F Brown, Vincent J Della Pietra, Stephen A Della Pietra, and Robert L Mercer.
1993.
The mathematics ofstatistical machine translation: Parameter estimation.
Computational linguistics, 19(2):263?311.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.
Enhanced sentiment learning using twitter hashtags andsmileys.
In Proceedings of COLING ?10.Zhuoye Ding, Xipeng Qiu, Qi Zhang, and Xuanjing Huang.
2013.
Learning topical translation model formicroblog hashtag suggestion.
In Proceedings of IJCAI 2013.Miles Efron.
2010.
Hashtag retrieval in a microblogging environment.
In Proceedings of SIGIR ?10.Nikhil Garg and Ingmar Weber.
2008.
Personalized, interactive tag recommendation for flickr.
In Proceedings ofRecSys ?08.T.
L. Griffiths and M. Steyvers.
2004.
Finding scientific topics.
Proceedings of the National Academy of Sciences.Ido Guy, Naama Zwerdling, Inbal Ronen, David Carmel, and Erel Uziel.
2010.
Social media recommendationbased on people and tags.
In Proceedings of SIGIR ?10.Ido Guy, Uri Avraham, David Carmel, Sigalit Ur, Michal Jacovi, and Inbal Ronen.
2013.
Mining expertise andinterests from social media.
In Proceedings of WWW ?13.Paul Heymann, Daniel Ramage, and Hector Garcia-Molina.
2008.
Social tag prediction.
In Proceedings of SIGIR?08.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao.
2011.
Target-dependent twitter sentimentclassification.
In Proceedings of ACL 2011, Portland, Oregon, USA.Ralf Krestel, Peter Fankhauser, and Wolfgang Nejdl.
2009.
Latent dirichlet allocation for tag recommendation.
InProceedings of RecSys ?09.Lihong Li, Wei Chu, John Langford, and Robert E Schapire.
2010.
A contextual-bandit approach to personalizednews article recommendation.
In Proceedings of the 19th international conference on World wide web, pages661?670.
ACM.Ting-Peng Liang, Hung-Jen Lai, and Yi-Cheng Ku.
2007.
Personalized content recommendation and usersatisfaction: Theoretical synthesis and empirical findings.
Journal of Management Information Systems,23(3):45?70.Huizhi Liang, Yue Xu, Yuefeng Li, Richi Nayak, and Xiaohui Tao.
2010.
Connecting users and items withweighted tags for personalized item recommendations.
In Proceedings of the 21st ACM conference on Hypertextand hypermedia, pages 51?60.
ACM.Zhiyuan Liu, Chen Liang, and Maosong Sun.
2012.
Topical word trigger model for keyphrase extraction.
InProceedings of COLING.Yu-Ta Lu, Shoou-I Yu, Tsung-Chieh Chang, and Jane Yung-jen Hsu.
2009.
A content-based method to enhancetag recommendation.
In Proceedings of IJCAI?09.211Franz Josef Och and Hermann Ney.
2003.
A systematic comparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Tsutomu Ohkura, Yoji Kiyota, and Hiroshi Nakagawa.
2006.
Browsing system for weblog articles based onautomated folksonomy.
Workshop on the Weblogging Ecosystem Aggregation Analysis and Dynamics at WWW.Takanobu Otsuka, Takuya Yoshimura, and Takayuki Ito.
2012.
Evaluation of the reputation network using realisticdistance between facebook data.
In Proceedings of WI-IAT ?12.Bo Pang and Lillian Lee.
2008.
Opinion mining and sentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135,January.Steffen Rendle and Lars Schmidt-Thieme.
2010.
Pairwise interaction tensor factorization for personalized tagrecommendation.
In Proceedings of the third ACM international conference on Web search and data mining,pages 81?90.
ACM.Steffen Rendle, Leandro Balby Marinho, Alexandros Nanopoulos, and Lars Schmidt-Thieme.
2009.
Learningoptimal ranking with tensor factorization for tag recommendation.
In Proceedings of KDD ?09.Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010.
Earthquake shakes twitter users: real-time eventdetection by social sensors.
In Proceedings of WWW ?10.Andriy Shepitsen, Jonathan Gemmell, Bamshad Mobasher, and Robin Burke.
2008.
Personalizedrecommendation in social tagging systems using hierarchical clustering.
In Proceedings of the 2008 ACMConference on Recommender Systems, RecSys ?08, pages 259?266, New York, NY, USA.
ACM.Yang Song, Ziming Zhuang, Huajing Li, Qiankun Zhao, Jia Li, Wang-Chien Lee, and C. Lee Giles.
2008.
Real-time automatic tag recommendation.
In Proceedings of SIGIR ?08.Amara Tariq, Asim Karim, Fernando Gomez, and Hassan Foroosh.
2013.
Exploiting topical perceptions overmulti-lingual text for hashtag suggestion on twitter.
In FLAIRS Conference.Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou, and Ming Zhang.
2011.
Topic sentiment analysis in twitter:a graph-based hashtag sentiment classification approach.
In Proceedings of CIKM ?11.Wayne Xin Zhao, Jing Jiang, Jing He, Yang Song, Palakorn Achananuparp, Ee-Peng Lim, and Xiaoming Li.2011.
Topical keyphrase extraction from twitter.
In Proceedings of the 49th Annual Meeting of the Associationfor Computational Linguistics: Human Language Technologies-Volume 1, pages 379?388.
Association forComputational Linguistics.212
