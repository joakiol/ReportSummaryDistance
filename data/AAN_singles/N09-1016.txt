Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 137?145,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsWithout a ?doubt?
?Unsupervised discovery of downward-entailing operatorsCristian Danescu-Niculescu-Mizil, Lillian Lee, and Richard DucottDepartment of Computer ScienceCornell UniversityIthaca, NY 14853-7501cristian@cs.cornell.edu, llee@cs.cornell.edu, rad47@cornell.eduAbstractAn important part of textual inference is mak-ing deductions involving monotonicity, thatis, determining whether a given assertion en-tails restrictions or relaxations of that asser-tion.
For instance, the statement ?We know theepidemic spread quickly?
does not entail ?Weknow the epidemic spread quickly via fleas?,but ?We doubt the epidemic spread quickly?entails ?We doubt the epidemic spread quicklyvia fleas?.
Here, we present the first algorithmfor the challenging lexical-semantics prob-lem of learning linguistic constructions that,like ?doubt?, are downward entailing (DE).Our algorithm is unsupervised, resource-lean,and effective, accurately recovering many DEoperators that are missing from the hand-constructed lists that textual-inference sys-tems currently use.1 IntroductionMaking inferences based on natural-language state-ments is a crucial part of true natural-language un-derstanding, and thus has many important applica-tions.
As the field of NLP has matured, there hasbeen a resurgence of interest in creating systems ca-pable of making such inferences, as evidenced bythe activity surrounding the ongoing sequence of?Recognizing Textual Entailment?
(RTE) competi-tions (Dagan, Glickman, and Magnini, 2006; Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini,and Szpektor, 2006; Giampiccolo, Magnini, Dagan,and Dolan, 2007) and the AQUAINT knowledge-based evaluation project (Crouch, Saur?
?, and Fowler,2005).The following two examples help illustrate theparticular type of inference that is the focus of thispaper.1.
?We know the epidemic spread quickly?2.
?We doubt the epidemic spread quickly?A relaxation of ?spread quickly?
is ?spread?
; a re-striction of it is ?spread quickly via fleas?.
Fromstatement 1, we can infer the relaxed version, ?Weknow the epidemic spread?, whereas the restrictedversion, ?We know the epidemic spread quickly viafleas?, does not follow.
But the reverse holds forstatement 2: it entails the restricted version ?Wedoubt the epidemic spread quickly via fleas?, but notthe relaxed version.
The reason is that ?doubt?
is adownward-entailing operator;1 in other words, it al-lows one to, in a sense, ?reason from sets to subsets?
(van der Wouden, 1997, pg.
90).Downward-entailing operators are not restrictedto assertions about belief or to verbs.
For example,the preposition ?without?
is also downward entail-ing: from ?The applicants came without payment orwaivers?
we can infer that all the applicants camewithout payment.
(Contrast this with ?with?, which,like ?know?, is upward entailing.)
In fact, there aremany downward-entailing operators, encompassingmany syntactic types; these include explicit nega-tions like ?no?
and ?never?, but also many otherterms, such as ?refuse (to)?, ?preventing?, ?nothing?,?rarely?, and ?too [adjective] to?.1Synonyms for ?downward entailing?
include downward-monotonic and monotone decreasing.
Related concepts includeanti-additivity, veridicality, and one-way implicatives.137As the prevalence of these operators indicates andas van der Wouden (1997, pg.
92) states, downwardentailment ?plays an extremely important role innatural language?
(van Benthem, 1986; Hoeksema,1986; Sa?nchez Valencia, 1991; Dowty, 1994; Mac-Cartney and Manning, 2007).
Yet to date, only a fewsystems attempt to handle the phenomenon in a gen-eral way, i.e., to consider more than simple directnegation (Nairn, Condoravdi, and Karttunen, 2006;MacCartney and Manning, 2008; Christodoulopou-los, 2008; Bar-Haim, Berant, Dagan, Greental,Mirkin, Shnarch, and Szpektor, 2008).
These sys-tems rely on lists of items annotated with respect totheir behavior in ?polar?
(positive or negative) envi-ronments.
The lists contain a relatively small num-ber of downward-entailing operators, at least in partbecause they were constructed mainly by manualinspection of verb lists (although a few non-verbsare sometimes also included).
We therefore proposeto automatically learn downward-entailing opera-tors2 ?
henceforth DE operators for short ?
fromdata; deriving more comprehensive lists of DE op-erators in this manner promises to substantially en-hance the ability of textual-inference systems to han-dle monotonicity-related phenomena.Summary of our approach There are a num-ber of significant challenges to applying a learning-based approach.
First, to our knowledge there donot exist DE-operator-annotated corpora, and more-over, relevant types of semantic information are ?notavailable in or deducible from any public lexicaldatabase?
(Nairn et al, 2006).
Also, it seems thereis no simple test one can apply to all possible candi-dates; van der Wouden (1997, pg.
110) remarks, ?Asa rule of thumb, assume that everything that feelsnegative, and everything that [satisfies a conditiondescribed below], is monotone decreasing.
This ruleof thumb will be shown to be wrong as it stands; but2We include superlatives (?tallest?
), comparatives (?taller?
),and conditionals (?if?)
in this category because they have non-default (i.e., non-upward entailing) properties ?
for instance,?he is the tallest father?
does not entail ?he is the tallest man?.Thus, they also require special treatment when considering en-tailment relations.
In fact, there have been some attemptsto unify these various types of non-upward entailing opera-tors (von Fintel, 1999).
We use the term downward entailing(narrowly-defined) (DE(ND)) when we wish to specifically ex-clude superlatives, comparatives, and conditionals.it sort of works, like any rule of thumb.
?Our first insight into how to overcome these chal-lenges is to leverage a finding from the linguistics lit-erature, Ladusaw?s (1980) hypothesis, which can betreated as a cue regarding the distribution of DE op-erators: it asserts that a certain class of lexical con-structions known as negative polarity items (NPIs)can only appear in the scope of DE operators.
Notethat this hypothesis suggests that one can developan unsupervised algorithm based simply on check-ing for co-occurrence with known NPIs.But there are significant problems with apply-ing this idea in practice, including: (a) there is noagreed-upon list of NPIs; (b) terms can be ambigu-ous with respect to NPI-hood; and (c) many non-DEoperators tend to co-occur with NPIs as well.
Tocope with these issues, we develop a novel unsuper-vised distillation algorithm that helps filter out thenoise introduced by these problems.
This algorithmis very effective: it is accurate and derives many DEoperators that do not appear on pre-existing lists.Contributions Our project draws a connection be-tween the creation of textual entailment systems andlinguistic inquiry regarding DE operators and NPIs,and thus relates to both language-engineering andlinguistic concerns.To our knowledge, this work represents the firstattempt to aid in the process of discovering DE oper-ators, a task whose importance we have highlightedabove.
At the very least, our method can be usedto provide high-quality raw materials to help humanannotators create more extensive DE operator lists.In fact, while previous manual-classification effortshave mainly focused on verbs, we retrieve DE oper-ators across multiple parts of speech.
Also, althoughwe discover many items (including verbs) that arenot on pre-existing manually-constructed lists, theitems we find occur frequently ?
they are not some-how peculiar or rare.Our algorithm is surprisingly accurate given that itis quite resource- and knowledge-lean.
Specifically,it relies only on Ladusaw?s hypothesis as initial in-spiration, a relatively short and arguably noisy listof NPIs, and a large unannotated corpus.
It doesnot use other linguistic information ?
for exam-ple, we do not use parse information, even thoughc-command relations have been asserted to play a138key role in the licensing of NPIs (van der Wouden,1997).2 MethodWe mentioned in the introduction some significantchallenges to developing a machine-learning ap-proach to discovering DE operators.
The key insightwe apply to surmount these challenges is that in thelinguistics literature, it has been hypothesized thatthere is a strong connection between DE operatorsand negative polarity items (NPIs), which are termsthat tend to occur in ?negative environments?.
Anexample NPI is ?anymore?
: one can say ?We don?thave those anymore?
but not ?We have those any-more?.Specifically, we propose to take advantage of theseminal hypothesis of Ladusaw (1980, influenced byFauconnier (1975), inter alia):(Ladusaw) NPIs only appear within thescope of downward-entailing operators.This hypothesis has been actively discussed, up-dated, and contested by multiple parties (Linebarger,1987; von Fintel, 1999; Giannakidou, 2002, interalia).
It is not our intent to comment (directly) on itsoverall validity.
Rather, we simply view it as a veryuseful starting point for developing computationaltools to find DE operators?
indeed, even detractorsof the theory have called it ?impressively algorith-mic?
(Linebarger, 1987, pg.
361).First, a word about scope.
For Ladusaw?s hypoth-esis, scope should arguably be defined in terms of c-command, immediate scope, and so on (von Fintel,1999, pg.
100).
But for simplicity and to make ourapproach as resource-lean as possible, we simply as-sume that potential DE operators occur to the left ofNPIs,3 except that we ignore text to the left of anypreceding commas or semi-colons as a way to en-force a degree of locality.
For example, in both ?Bythe way, we don?t have plants anymoreNPI becausethey died?
and ?we don?t have plants anymoreNPI?,we look for DE operators within the sequence ofwords ?we don?t have plants?.
We refer to such se-quences in which we seek DE operators as NPI con-texts.3There are a few exceptions, such as with the NPI ?for thelife of me?
(Hoeksema, 1993).Now, Ladusaw?s hypothesis suggests that we canfind DE operators by looking for words that tend tooccur more often in NPI contexts than they occuroverall.
We formulate this as follows:Assumption: For any DE operator d,FbyNPIpdq ?
F pdq.Here, FbyNPIpdq is the number of occurrences of din NPI contexts4 divided by the number of wordsin NPI contexts, and F pxq refers to the number ofoccurrences of x relative to the number of words inthe corpus.An additional consideration is that we would liketo focus on the discovery of novel or non-obviousDE operators.
Therefore, for a given candidate DEoperator c, we compute pFbyNPIpcq: the value ofFbyNPIpcq that results if we discard all NPI con-texts containing a DE operator on a list of 10 well-known instances, namely, ?not?, ?n?t?, ?no?, ?none?,?neither?, ?nor?, ?few?, ?each?, ?every?, and ?without?.
(This list is based on the list of DE operators used bythe RTE system presented in MacCartney and Man-ning (2008).)
This yields the following scoring func-tion:Spcq : pFbyNPIpcqF pcq .
(1)Distillation There are certain terms that are notDE operators, but nonetheless co-occur with NPIs asa side-effect of co-occurring with true DE operatorsthemselves.
For instance, the proper noun ?Milken?
(referring to Michael Milken, the so-called ?junk-bond king?)
occurs relatively frequently with the DEoperator ?denies?, and ?vigorously?
occurs frequentlywith DE operators like ?deny?
and ?oppose?.
We re-fer to terms like ?milken?
and ?vigorously?
as ?pig-gybackers?, and address the piggybackers problemby leveraging the following intuition: in general, wedo not expect to have two DE operators in the sameNPI context.5 One way to implement this would beto re-score the candidates in a winner-takes-all fash-ion: for each NPI context, reward only the candidate4Even if d occurs multiple times in a single NPI context weonly count it once; this way we ?dampen the signal?
of func-tion words that can potentially occur multiple times in a singlesentence.5One reason is that if two DE operators are composed, theyordinarily create a positive context, which would not licenseNPIs (although this is not always the case (Dowty, 1994)).139with the highest score S. However, such a methodis too aggressive because it would force us to picka single candidate even when there are several withrelatively close scores?
and we know our score S isimperfect.
Instead, we propose the following ?soft?mechanism.
Each sentence distributes a ?budget?
oftotal score 1 among the candidates it contains ac-cording to the relative scores of those candidates;this works out to yield the following new distilledscoring functionSdpcq ?NPIcontexts pSpcqnppqNpcq , (2)where nppq  ?cP p Spcq is an NPI-context normal-izing factor and Npcq is the number of NPI con-texts containing the candidate c. This way, plausi-ble candidates that have high S scores relative to theother candidates in the sentence receive enhanced Sdscores.
To put it another way: apparently plausiblecandidates that often appear in sentences with mul-tiple good candidates (i.e., piggybackers) receive alow distilled score, despite a high initial score.Our general claim is that the higher the distilledscore of a candidate, the better its chances of beinga DE operator.Choice of NPIs Our proposed method requires ac-cess to a set of NPIs.
However, there does not ap-pear to be universal agreement on such a set.
Lichteand Soehn (2007) mention some doubts regardingapproximately 200 (!)
of the items on a roughly 350-item list of German NPIs (Ku?rschner, 1983).
ForEnglish, the ?moderately complete?6 Lawler (2005)list contains two to three dozen items; however,there is also a list of English NPIs that is severaltimes longer (von Bergen and von Bergen, 1993,written in German), and Hoeksema (1997) assertsthat English should have hundreds of NPIs, similarlyto French and Dutch.We choose to focus on the items on these liststhat seem most likely to be effective cues for ourtask.
Specifically, we select a subset of the LawlerNPIs, focusing mostly on those that do not havea relatively frequent non-NPI sense.
An examplediscard is ?much?, whose NPI-hood depends on6www-personal.umich.edu/jlawler/aue/npi.htmlwhat it modifies and perhaps on whether thereare degree adverbs pre-modifying it (Hoeksema,1997).
There are some ambiguous NPIs that wedo retain due to their frequency.
For example,?any?
occurs both in a non-NPI ?free choice?variant, as in ?any idiot can do that?, and in anNPI version.
Although it is ambiguous with re-spect to NPI-hood, ?any?
is also a very valuablecue due to its frequency.7 Here is our NPI list:any in weeks/ages/years budge yetat all drink a drop red cent evergive a damn last/be/take long but what bother todo a thing arrive/leave until give a shit lift a fingerbat an eye would care/mind eat a bite to speak of3 ExperimentsOur main set of evaluations focuses on the precisionof our method at discovering new DE operators.
Wethen briefly discuss evaluation of other dimensions.3.1 SetupWe applied our method to the entirety of the BLLIP(Brown Laboratory for Linguistic Information Pro-cessing) 1987?89 WSJ Corpus Release 1, availablefrom the LDC (LDC2000T43).
The 1,796,379 sen-tences in the corpus comprise 53,064 NPI contexts;after discarding the ones containing the 10 well-known DE operators, 30,889 NPI contexts were left.To avoid sparse data problems, we did not considercandidates with very low frequency in the corpus(?150 occurrences) or in the NPI contexts (?10 oc-currences).Methodology for eliciting judgments The obvi-ous way to evaluate the precision of our algorithm isto have human annotators judge each output item asto whether it is a DE operator or not.
However, thereare some methodological issues that arise.First, if the judges know that every term they arerating comes from our system and that we are hopingthat the algorithm extracts DE operators, they maybe biased towards calling every item ?DE?
regard-less of whether it actually is.
We deal with this prob-lem by introducing distractors ?
items that are notproduced by our algorithm, but are similar enoughto not be easily identifiable as ?fakes?.
Specifically,7It is by far the most frequent NPI, appearing in 36,554 ofthe sentences in the BLLIP corpus (see Section 3).140for each possible part of speech of each of our sys-tem?s outputs c that exists in WordNet, we choose adistractor that is either in a ?sibling?
synset (a hy-ponym of c?s hypernym) or an antonym.
Thus, thedistractors are highly related to the candidates.
Notethat they may in fact also be DE operators.The judges were made aware of the presence ofa substantial number of distractors (about 70 for theset of top 150 outputs).
This design choice did seemto help ensure that the judges carefully evaluatedeach item.The second issue is that, as mentioned in the in-troduction, there does not seem to be a uniform testthat judges can apply to all items to ascertain theirDE-ness; but we do not want the judges to impro-vise excessively, since that can introduce undesir-able randomness into their decisions.
We thereforeencouraged the judges to try to construct sentenceswherein the arguments for candidate DE operatorswere drawn from a set of phrases and restrictedreplacements we specified (example: ?singing?
vs?singing loudly?).
However, improvisation was stillrequired in a number of cases; for example, the can-didate ?act?, as either a noun or a verb, cannot take?singing?
as an argument.The labels that the judges could apply were?DE(ND)?
(downward entailing (narrowly-defined)), ?superlative?, ?comparative?, ?condi-tional?, ?hard to tell?, and ?not-DE?
(= none of theabove).
We chose this fine-grained sub-divisionbecause the second through fourth categories areall known to co-occur with NPIs.
There is somedebate in the linguistics literature as to whetherthey can be considered to be downward entailing,narrowly construed, or not (von Fintel, 1999,inter alia), but nonetheless, such operators call forspecial reasoning quite distinct from that requiredwhen dealing with upward entailing operators ?hence, we consider it a success when our algorithmidentifies them.Since monotonicity phenomena can be rather sub-tle, the judges engaged in a collaborative process.Judge A (the second author) annotated all items, butworked in batches of around 10 items.
At the end ofeach batch, Judge B (the first author) reviewed JudgeA?s decisions, and the two consulted to resolve dis-agreements as far as possible.One final remark regarding the annotation: somedecisions still seem uncertain, since various factorssuch as context, Gricean maxims, what should bepresupposed8 and so on come into play.
However,we take comfort in a comment by Eugene Charniak(personal communication) to the effect that if a wordcauses a native speaker to pause, that word is inter-esting enough to be included.
And indeed, it seemsreasonable that if a native speaker thinks there mightbe a sense in which a word can be considered down-ward entailing, then our system should flag it as aword that an RTE system should at least perhapspass to a different subsystem for further analysis.3.2 Precision ResultsWe now examine the 150 items that were mosthighly ranked by our system, which were sub-sequently annotated as just described.
(Forfull system output that includes the unannotateditems, see http://www.cs.cornell.edu/cristian.
We would welcome external anno-tation help.)
As shown in Figure 1a, which depictsprecision at k for various values of k, our systemperforms very well.
In fact, 100% of the first 60 out-puts are DE, broadly construed.
It is also interestingto note the increasing presence of instances that thejudges found hard to categorize as we move furtherdown the ranking.Of our 73 distractors, 46% were judged to bemembers of one of our goal categories.
The fact thatthis percentage is substantially lower than our algo-rithm?s precision at both 73 and 150 (the largest k weconsidered) confirms that our judges were not mak-ing random decisions.
(We expect the percentageof DE operators among the distractors to be muchhigher than 0 because they were chosen to be simi-lar to our system?s outputs, and so can be expectedto also be DE operators some fraction of the time.
)Table 1 shows the lemmas of just the DE(ND) op-erators that our algorithm placed in its top 150 out-puts.9 Most of these lemmas are new discoveries, inthe sense of not appearing in Ladusaw?s (1980) (im-plicit) enumeration of DE operators.
Moreover, the8For example, ?X doubts the epidemic spread quickly?
mightbe said to entail ?X would doubt the epidemic spreads via fleas,presupposing that X thinks about the flea issue?.9By listing lemmas, we omit variants of the same word, suchas ?doubting?
and ?doubted?, to enhance readability.
We omitsuperlatives, comparatives, and conditionals for brevity.14110 20 30 40 50 60 70 80 90 100 110 120 130 140 1500102030405060708090100kPrecisionat kDE(ND)S/C/CHard10 20 30 40 50 60 70 80 90 100 110 120 130 140 1500102030405060708090100kPrecisionat kDE(ND)S/C/CHard(a) (b)Figure 1: (a) Precision at k for k divisible by 10 up to k  150.
The bar divisions are, from the x-axis up,DE(ND) (blue, the largest); Superlatives/Conditionals/Comparatives (green, 2nd largest); and Hard (red, sometimesnon-existent).
For example, all of the first 10 outputs were judged to be either downward entailing (narrowly-defined)(8 of 10, or 80%) or in one of the related categories (20%).
(b) Precision at k when the distillation step is omitted.not-DE Hardalmost firmly one-day approveambitious fined signal cautionedconsiders liable remove dismisseddetect notify vowed fendTable 3: Examples of words judged to be either not inone of our monotonicity categories of interest (not-DE)or hard to evaluate (Hard).lists of DE(ND) operators that are used by textual-entailment systems are significantly smaller thanthat depicted in Table 1; for example, MacCartneyand Manning (2008) use only about a dozen (per-sonal communication).Table 3 shows examples of the words in our sys-tem?s top 150 outputs that are either clear mistakesor hard to evaluate.
Some of these are due to id-iosyncrasies of newswire text.
For instance, we of-ten see phrases like ?biggest one-day drop in ...?,where ?one-day?
piggybacks on superlatives, and?vowed?
piggybacks on the DE operator ?veto?, asin the phrase ?vowed to veto?.Effect of distillation In order to evaluate the im-portance of the distillation process, we study howthe results change when distillation is omitted (thususing as score function S from Equation 1 ratherthan Sd).
When comparing the results (summarizedin Figure 1b) with those of the complete system(Figure 1a) we observe that the distillation indeedhas the desired effect: the number of highly rankedwords that are annotated as not-DE decreases afterdistillation.
This results in an increase of the preci-sion at k ranging from 5% to 10% (depending on k),as can be observed by comparing the height of thecomposite bars in the two figures.10Importantly, this improvement does indeed seemto stem at least in part from the distillation processhandling the piggybacking problem.
To give just afew examples: ?vigorously?
is pushed down fromrank 48 (undistilled scoring) to rank 126 (distilledscoring), ?one-day?
from 25th to 65th, ?vowed?
from45th to 75th, and ?Milken?
from 121st to 350th.3.3 Other ResultsIt is natural to ask whether the (expected) decreasein precision at k is due to the algorithm assigningrelatively low scores to DE operators, so that theydo not appear in the top 150, or due to there be-ing no more more true DE operators to rank.
Wecannot directly evaluate our method?s recall becauseno comprehensive list of DE operators exists.
How-ever, to get a rough impression, we can check howour system ranks the items in the largest list we areaware of, namely, the Ladusaw (implicit) list men-tioned above.
Of the 31 DE operator lemmas on thislist (not including the 10 well-known DE operators),only 7 of those frequent enough to be considered byour algorithm are not in its top 150 outputs, and only10The words annotated ?hard?
do not affect this increase inprecision.142absence ofabsent fromanxious aboutto avoid (L)to barbarelyto blockcannot (L)compensate forto declineto deferto deny (L)to deterto discourageto dismissto doubt (L)to eliminateessential forto excludeto fail (L)hardly (L)to lackinnocent ofto minimizenever (L)nobodynothingto opposeto postponeto precludepremature toto preventto prohibitrarely (L)to refrain fromto refuse (L)regardlessto rejectreluctant to (L)to resistto rule outskepticalto suspendto thwartunable tounaware ofunclear onunlikeunlikely (L)unwilling toto vetowary ofwarned that (L)wheneverwithstandTable 1: The 55 lemmas for the 90 downward entailing (narrowly-defined) operators among our algorithm?s top 150outputs.
(L) marks instances from Ladusaw?s list.marks some of the more interesting cases.
We have addedfunction words (e.g., ?to?, ?for?)
to indicate parts of speech or subcategorization; our algorithm does not discovermulti-word phrases.Original ?
RestrictionDan is unlikely to sing.
????
{Dan is unlikely to sing loudly.Olivia compensates for eating by exercising.
????
{Olivia compensates for eating late by exercising.Ursula refused to sing or dance.
????
{Ursula refused to sing.Bob would postpone singing.
????
{Bob would postpone singing loudly.Talent is essential for singing.
????
{Talent is essential for singing a ballad.She will finish regardless of threats.
????
{She will finish regardless of threats to my career.Table 2: Example demonstrations that the underlined expressions (selected from Table 1) are DE operators: thesentences on the left entail those on the right.
We also have provided??
{ indicators because the reader might find ithelpful to reason in the opposite direction and see that these expressions are not upward entailing.5 are not in the top 300.
Remember that we only an-notated the top 150 outputs; so, there may be manyother DE operators between positions 150 and 300.Another way of evaluating our method would beto assess the effect of our newly discovered DE op-erators on downstream RTE system performance.There are two factors to take into account.
First, theDE operators we discovered are quite prevalent innaturally occurring text11 : the 90 DE(ND) operatorsappearing in our algorithm?s top 150 outputs occurin 111,456 sentences in the BLLIP corpus (i.e., in6% of its sentences).
Second, as previously men-tioned, systems do already account for monotonic-ity to some extent ?
but they are limited by the factthat their DE operator lexicons are restricted mostlyto well-known instances; to take a concrete examplewith a publicly available RTE system: Nutcracker(Bos and Markert, 2006) correctly infers that ?Wedid not know the disease spread?
entails ?We did notknow the disease spread quickly?
but it fails to in-11However, RTE competitions do not happen to currentlystress inferences involving monotonicity.
The reasons why arebeyond the scope of this paper.fer that ?We doubt the disease spread?
entails ?Wedoubt the disease spread quickly?.
So, systems canuse monotonicity information but currently do nothave enough of it; our method can provide themwiththis information, enabling them to handle a greaterfraction of the large number of naturally occurringinstances of this phenomenon than ever before.4 Related work not already discussedMagnini (2008), in describing modular approachesto textual entailment, hints that NPIs may be usedwithin a negation-detection sub-component.There is a substantial body of work in the linguis-tics literature regarding the definition and nature ofpolarity items (Polarity Items Bibliography).
How-ever, very little of this work is computational.
Therehas been passing speculation that one might wantto learn polarity-inverting verbs (Christodoulopou-los, 2008, pg.
47).
There have also been a fewprojects on the discovery of NPIs, which is the con-verse of the problem we consider.
Hoeksema (1997)discusses some of the difficulties with corpus-baseddetermination of NPIs, including ?rampant?
poly-143semy and the problem of ?how to determine inde-pendently which predicates should count as nega-tive??
a problemwhich our work addresses.
Lichteand Soehn (Lichte, 2005; Lichte and Soehn, 2007)consider finding German NPIs using a method con-ceptually similar in some respects to our own, al-though again, their objective is the reverse of ours.Their discovery statistic for single-word NPIs is theratio of within-licenser-clause occurrences to totaloccurrences, where, to enhance precision, the list oflicensers was filtered down to a set of fairly unam-biguous, easily-identified items.
They do not con-sider distillation, which we found to be an impor-tant component of our DE-operator-detection algo-rithm.
Their evaluation scheme, unlike ours, did notemploy a bias-compensation mechanism.
They didemploy a collocation-detection technique to extendtheir list to multi-word NPIs, but our independentexperiments with a similar technique (not reportedhere) did not yield good results.5 Conclusions and future workTo our knowledge, this work represents the first at-tempt to discover downward entailing operators.
Weintroduced a unsupervised algorithm that is moti-vated by research in linguistics but employs simpledistributional statistics in a novel fashion.
Our algo-rithm is highly accurate and discovers many reason-able DE operators that are missing from pre-existingmanually-built lists.Since the algorithm is resource-lean ?
requiringno parser or tagger but only a list of NPIs?
it can beimmediately applied to languages where such listsexist, such as German and Romanian (Trawin?ski andSoehn, 2008).
On the other hand, although the re-sults are already quite good for English, it wouldbe interesting to see what improvements could begained by using more sophisticated syntactic infor-mation.For languages where NPI lists are not extensive,one could envision applying an iterative co-learningapproach: use the newly-derived DE operators to in-fer new NPIs, and then discover even more new DEoperators given the new NPI list.
(For English, ourinitial attempts at bootstrapping from our initial NPIlist on the BLLIP corpus did not lead to substantiallyimproved results.
)In practice, subcategorization is an important fea-ture to capture.
In Table 1, we indicate which sub-categorizations are DE.
An interesting extension ofour work would be to try to automatically distin-guish particular DE subcategorizations that are lex-ically apparent, e.g., ?innocent?
(not DE) vs. ?inno-cent of?
(as in ?innocent of burglary?, DE).Our project provides a connection (among many)between the creation of textual entailment systems(the domain of language engineers) and the char-acterization of DE operators (the subject of studyand debate among linguists).
The prospect that ourmethod might potentially eventually be refined insuch a way so as to shed at least a little light on lin-guistic questions is a very appealing one, althoughwe cannot be certain that any progress will be madeon that front.Acknowledgments We thank Roy Bar-Haim, Cleo Con-doravdi, and Bill MacCartney for sharing their systems?
listsand information about their work with us; Mats Rooth forhelpful conversations; Alex Niculescu-Mizil for technical as-sistance; and Eugene Charniak for reassuring remarks.
We alsothank Marisa Ferrara Boston, Claire Cardie, Zhong Chen, YejinChoi, Effi Georgala, Myle Ott, Stephen Purpura, and AinurYessenalina at Cornell University, the UT-Austin NLP group,Roy Bar-Haim, Bill MacCartney, and the anonymous review-ers for for their comments on this paper.
This paper is basedupon work supported in part by DHS grant N0014-07-1-0152,National Science Foundation grant No.
BCS-0537606, a Ya-hoo!
Research Alliance gift, a CU Provost?s Award for Distin-guished Scholarship, and a CU Institute for the Social SciencesFaculty Fellowship.
Any opinions, findings, and conclusions orrecommendations expressed are those of the authors and do notnecessarily reflect the views or official policies, either expressedor implied, of any sponsoring institutions, the U.S. government,or any other entity.ReferencesRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, DaniloGiampiccolo, Bernardo Magnini, and Idan Szpektor.The second PASCAL Recognising Textual Entailmentchallenge.
In Proceedings of the Second PASCALChallenges Workshop on Recognising Textual Entail-ment, 2006.Roy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo Green-tal, Shachar Mirkin, Eyal Shnarch, and Idan Szpektor.Efficient semantic deduction and approximate match-ing over compact parse forests.
In Proceedings of TAC,2008.Johan Bos and Katja Markert.
Recognising textual en-tailment with robust logical inference.
In Quin?oneroCandela, Dagan, Magnini, and d?Alche?
Buc (2006),pages 404?426.Christos Christodoulopoulos.
Creating a natural logic in-ference system with combinatory categorial grammar.Master?s thesis, University of Edinburgh, 2008.144Dick Crouch, Roser Saur?
?, and Abraham Fowler.AQUAINT pilot knowledge-based evalua-tion: Annotation guidelines.
http://www2.parc.com/istl/groups/nltt/papers/aquaint kb pilot evaluation guide.pdf,2005.Ido Dagan, Oren Glickman, and Bernardo Magnini.
ThePASCAL Recognising Textual Entailment challenge.In Quin?onero Candela et al (2006), pages 177?190.David Dowty.
The role of negative polarity and con-cord marking in natural language reasoning.
In MandyHarvey and Lynn Santelmann, editors, Proceedings ofSALT IV, pages 114?144, Ithaca, New York, 1994.Cornell University.Gilles Fauconnier.
Polarity and the scale principle.
InProceedings of the Chicago Linguistic Society (CLS),pages 188?199, 1975.
Reprinted in Javier Gutierrez-Rexach (ed.
), Semantics: Critical Concepts in Linguis-tics, 2003.Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, andBill Dolan.
The third PASCAL Recognizing TextualEntailment challenge.
In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Para-phrasing, pages 1?9, 2007.
URL http://www.aclweb.org/anthology/W/W07/W07-1401.Anastasia Giannakidou.
Licensing and sensitivity in po-larity items: from downward entailment to nonveridi-cality.
In Proceedings of the Chicago Linguistic Soci-ety (CLS), 2002.Jack Hoeksema.
Monotonicity phenomena in natural lan-guage.
Linguistic Analysis, 16:25?40, 1986.Jack Hoeksema.
As (of) yet.
Appears in Language andCognition 3, the 1992 yearbook of the research groupfor theoretical and experimental linguistics of the Uni-versity of Groningen, 1993. http://www.let.rug.nl/hoeksema/asofyet.pdf.Jack Hoeksema.
Corpus study of negative polar-ity items.
IV-V Jornades de corpus linguistics1996-1997, 1997. http://odur.let.rug.nl/hoeksema/docs/barcelona.html.Wilfried Ku?rschner.
Studien zur Negation im Deutschen.Narr, 1983.William A. Ladusaw.
Polarity Sensitivity as InherentScope Relations.
Garland Press, New York, 1980.Ph.D.
thesis date 1979.John Lawler.
Negation and NPIs.
http://www.umich.edu/jlawler/NPIs.pdf, 2005.
Ver-sion of 10/29/2005.Timm Lichte.
Corpus-based acquisition of complex neg-ative polarity items.
In ESSLLI Student Session, 2005.Timm Lichte and Jan-Philipp Soehn.
The retrieval andclassification of Negative Polarity Items using statisti-cal profiles.
In Sam Featherston and Wolfgang Sterne-feld, editors, Roots: Linguistics in Search of its Ev-idential Base, pages 249?266.
Mouton de Gruyter,2007.Marcia Linebarger.
Negative polarity and grammaticalrepresentation.
Linguistics and philosophy, 10:325?387, 1987.Bill MacCartney and Christopher D. Manning.
Naturallogic for textual inference.
In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Para-phrasing, pages 193?200, 2007.Bill MacCartney and Christopher D. Manning.
Mod-eling semantic containment and exclusion in natu-ral language inference.
In Proceedings of the 22ndInternational Conference on Computational Linguis-tics (Coling 2008), pages 521?528, Manchester, UK,August 2008.
Coling 2008 Organizing Committee.URL http://www.aclweb.org/anthology/C08-1066.Bernardo Magnini.
Slides for a presentation entitled ?Se-mantic Knowledge for Textual Entailment?.
Sympo-sium on Semantic Knowledge Discovery, Organiza-tion and Use, New York University, November 14 and15, 2008.Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.Computing relative polarity for textual inference.
InProceedings of Inference in Computational Semantics(ICoS), 2006.Polarity Items Bibliography.
The polarity itemsbibliography.
http://www.sfb441.uni-tuebingen.de/a5/pib/XML2HTML/list.html, 2008.
Maintenance guaranteed onlythrough December 2008.Joaquin Quin?onero Candela, Ido Dagan, BernardoMagnini, and Florence d?Alche?
Buc, editors.
Ma-chine Learning Challenges, Evaluating Predictive Un-certainty, Visual Object Classification and Recogniz-ing Textual Entailment, First PASCAL Machine Learn-ing Challenges Workshop, MLCW 2005, Southamp-ton, UK, April 11-13, 2005, Revised Selected Papers,volume 3944 of Lecture Notes in Computer Science(LNCS), 2006.
Springer.V?
?ctor Sa?nchez Valencia.
Studies on natural logic andcategorial grammar.
PhD thesis, University of Ams-terdam, 1991.Beata Trawin?ski and Jan-Philipp Soehn.
A MultilingualDatabase of Polarity Items.
In Proceedings of LREC2008, May 28?30, Marrakech, Morocco, 2008.Johan van Benthem.
Essays in Logical Semantics.
Reidel,Dordrecht, 1986.Ton van der Wouden.
Negative contexts: Collocation,polarity and multiple negation.
Routledge, 1997.Anke von Bergen and Karl von Bergen.
NegativePolarita?t im Englischen.
Gunter Narr, 1993.
Listextracted and compiled by Manfred Sailer, 2008,http://www.sfs.uni-tuebingen.de/fr/esslli/08/byday/english-npi.pdf.Kai von Fintel.
NPI licensing, Strawson entailment, andcontext dependency.
Journal of Semantics, 16:97?148,1999.145
