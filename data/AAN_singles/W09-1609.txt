Proceedings of CLIAWS3, Third International Cross Lingual Information Access Workshop, pages 61?69,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsNE Tagging for Urdu based on Bootstrap POS LearningSmruthi Mukund Rohini K. SrihariDept.
of Computer Science and Engineering Dept.
of Computer Science and EngineeringUniversity at Buffalo, SUNY University at Buffalo, SUNYAmherst, NY, USA Amherst, NY, USAsmukund@buffalo.edu rohini@cedar.buffalo.eduAbstractPart of Speech (POS) tagging and Named Ent-ity (NE) tagging have become important com-ponents of effective text analysis.
In thispaper, we propose a bootstrapped model thatinvolves four levels of text processing for Ur-du.
We show that increasing the training datafor POS learning by applying bootstrappingtechniques improves NE tagging results.
Ourmodel overcomes the limitation imposed bythe availability of limited ground truth datarequired for training a learning model.
Bothour POS tagging and NE tagging models arebased on the Conditional Random Field(CRF) learning approach.
To further enhancethe performance, grammar rules and lexiconlookups are applied on the final output to cor-rect any spurious tag assignments.
We alsopropose a model for word boundary segmen-tation where a bigram HMM model is trainedfor character transitions among all positions ineach word.
The generated words are furtherprocessed using a probabilistic language mod-el.
All models use a hybrid approach thatcombines statistical models with hand craftedgrammar rules.1 IntroductionThe work here is motivated by a desire to under-stand human sentiment and social behavior throughanalysis of verbal communication.
Newspapersreflect the collective sentiments and emotions ofthe people and in turn the society to which theycater to.
Not only do they portray an event that hastaken place as is, but they also reveal details aboutthe intensity of fear, imagination, happiness andother emotions that people express in relation tothat event.
Newspaper write ups, when analyzedover these factors - emotions, reactions and beha-vior - can give a broader perspective on the culture,beliefs and the extent to which the people in theregion are tolerant towards other religions.
Ourfinal goal is to automate this kind of behavioralanalysis on newspaper articles for the Urdu lan-guage.
Annotated corpus that tag six basic humanemotions, ?happy?, ?fear?, ?sad?, ?surprise?, ?an-ger?
and ?disgust?, based on the code book devel-oped using the MPQA standards as guideline, iscurrently being developed.
Articles from two lead-ing Urdu newswires, BBC Urdu1 and Jung Daily2form our corpus.In order to achieve our goal, it was required togenerate the basic tools needed for efficient textanalysis.
This includes NE tagging and its precur-sor, POS tagging.
However, Urdu, despite beingspoken by over 100 million people, (Gordon,2005) is still a less privileged language when itcomes to the availability of resources on the inter-net.
Developing tools for a language with limitedresources is a challenge, but necessary, as the vo-lume of Urdu text on the internet is rising.
Huda(2001) shows that Urdu has now gained impor-tance on the web, making it the right time to tacklethese issues.It is useful to first examine some basic proper-ties of Urdu and how they affect the cascade ofNLP steps in text analysis.
Urdu has the nastaleeqand nasq style of writing that is similar to Arabic1 http://www.bbc.co.uk/urdu/2 http://www.jang.net/urdu/61and flows from right to left (Ahmad et al, 2001).
Italso adopts some of its vocabulary from Arabic.However, the grammar and semantics of the lan-guage is similar to Hindi and this makes it verydifferent from Arabic.
For effective text analysis, athorough syntactic and semantic understanding ofthe language is required.
Detailed grammaticalanalysis provided by Platts (1909) and Schmidt(1999) can be used for this purpose.
The first stepin the information retrieval pipeline is tokeniza-tion.
Unlike English, where the word delimiter ismostly a space, Urdu is more complex.
There arespace insertion as well as space deletion problems.This makes tokenization a difficult task.
The wordsegmentation model that we propose here com-bines the statistical approach that considers bigramtransition of characters based on their positions in aword and morphological rules with lexicon loo-kups.POS tagging comes next in the NLP text analy-sis pipeline.
The accuracy of the tagging modelvaries, depending on the tagsets used and the do-main of the ground truth data.
There are two maintagsets designed for Urdu, the CRULP tagset3 andthe U1-tagset (Hardie 2003).
The U1-tagset, re-leased as a part of EMILLE4 corpus, is based onthe EAGLES standards (Leech and Wilson 1999).We decided to use the standards proposed byCRULP for the following reasons.1.
The tagset, though not as detailed as theone proposed in U1-tagset, covers all thebasic requirements needed to achieve ourfinal goal.2.
The tagged corpus provided by CRULP isnewswire material, similar to our finalcorpus.A person, when asked to identify an NE taggedword in a sentence would typically try to first findthe word associated with a proper noun or a noun,and then assign a suitable NE tag based on the con-text.
A similar approach is used in our model,where the learning happens on the data that is POStagged as well as NE tagged.
Features are learntfrom the POS tags as well as the NE tags.
The finaloutput of our complete model returns the POS tags3http://www.crulp.org/Downloads/ling_resources/parallelcorpus/Urdu POS Tagset.pdf4 http://www.emille.lancs.ac.uk/and NE tags associated with each word.
Since wehave limited data for training both the POS as wellas the NE models, we propose a technique calledbootstrapping that helps in maximizing the learn-ing for efficient tagging.The remainder of the paper is organized as fol-lows.
Section 2 discusses the resources assimilatedfor the work followed by tokenization and wordsegmentation in Section 3.
Section 4 gives a de-tailed explanation of our model starting with abrief introduction of the learning approach used.Rules used for POS tagging and NE tagging arementioned in subsections of Section 4.
Section 5presents the results and Section 6 concludes thepaper.
In each section, wherever relevant, previouswork and drawbacks are presented.2 ResourcesBased on the style of writing for Urdu, differentencoding standards have been proposed.
UrduZabta Takthi - the national standard code page forUrdu and Unicode - international standard for mul-tilingual characters are the two proposed and wide-ly used encoding standards.
BBC Urdu and JungDaily are both encoded with Unicode standardsand are good sources of data.
The availability ofonline resources for Urdu is not as extensive asother Asian languages like Chinese and Hindi.However, Hussain (2008) has done a good job inassimilating most of the resources available on theinternet.
The lexicon provided as a part of theEMILLE (2003) data set for Urdu has about200,000 words.
CRL5 has released a lexicon of8000 words as a part of their Urdu data collection.They also provide an NE tagged data set mostlyused for morphological analysis.
The lexicon in-cludes POS information as well.
CRULP6 has alsoprovided a lexicon of 149,466 words that containsplaces, organizations and names of people.
As partof the Urdu morphological analyzer provided byHumayoun (2007), a lexicon of about 4,500 uniquewords is made available.
There are a few Urdu-English dictionaries available online and the firstonline dictionary, compiled by Siddiqi (2008),provides about 24,000 words with their meaningsin English.Getting all the resources into one single compi-lation is a challenge.
These resources were brought5 http://crl.nmsu.edu/Resources/lang_res/urdu.html6 http://www.crulp.org/software/ling_resources/wordlist.htm62together and suitably compiled into a format thatcan be easily processed by Semantex (Srihari,2008), a text extraction platform provided by JanyaInc7.
Lists of places, organizations and names offamous personalities in Pakistan were also com-piled using the Urdu-Wikipedia8 and NationalMas-ter9.
A list of most common names in Pakistan wascomposed by retrieving data from the variousname databases available on the internet.The word segmentation model uses the Urducorpus released by CRULP as the training data.This dataset is well segmented.
POS tagging modeluses data provided by CRULP and NE taggingmodel uses data provided by CRL.3 Word Segmentation and TokenizationUrdu is a language that has both the space inser-tion and space deletion problems.
The Urdu wordsegmentation problem as mentioned by Durrani(2007) is triggered by its orthographic rules andconfusions about the definition of a word.
Durranisummarizes effectively, all the problems associatedwith Urdu word segmentation.
Of all the differenttechniques explored to achieve this objective, tra-ditional techniques like longest and maximummatching depend mostly on the availability of alexicon that holds all the morphological forms of aword.
Such a lexicon is difficult to obtain.
It isshown by Theeramunkong et al, (2001), that for aThai segmentation system, the efficiency dropsconsiderably (from 97% to 82%) making this ap-proach highly lexicon dependent.Statistical based techniques have applied proba-bilistic models to solve the problem of word seg-mentation.
Bigram and trigram models are mostcommonly employed.
Using feature based tech-niques for POS tagging is also very common.These techniques overcome the limitations of sta-tistical models by considering the context aroundthe word for specific words and collocations.
Thereare other models that generate segments by consi-dering word level collation as well as syllable levelcollocation.However, for a language like Urdu, a model thatis purely statistical will fail to yield good segmen-tation results.
A mixed model that considers themorphological as well as semantic features of the7 http://www.janyainc.com/8 http://ur.wikipedia.com/wiki/9 http://www.nationmaster.com/index.phplanguage facilitates better performance as shownby Durrani (2007) where the word segmentationmodel uses a lexicon for proper nouns and a statis-tical model that trains over the n-gram probabilityof morphemes.
Maximum matching technique isused to generate word boundaries of the ortho-graphic words that are formed and these are laterverified using the POS information.
The segmentsthus generated are ranked and the best ones areaccepted.
Statistical models that consider characterbased, syllable based and word based probabilitieshave shown to perform reasonably well.
The Thaisegmentation problem was solved by Pornprasert-kul (1994) using the character based approach.
Inour model, we use a combination of characterbased statistical approach and grammar rules withlexicon lookups to generate word boundaries.Urdu segmentation problem can be looked at asan issue of inserting spaces between characters.
Allletters in Urdu, with a few exceptions, have threeforms - initial, medial and final.
(We do not con-sider the detached form for word formation).Words are written by joining the letters togetherand based on the position of the letter in the word,suitable forms are applied.
This property of wordformation is the crux of our model.
The bigramprobability of occurrences of each of these charac-ters, based on their positions, is obtained by train-ing over a properly segmented training set.
Forunknown characters, unknown character modelsfor all the three position of occurrences are alsotrained.
The probability of word occurrence isnoted.
Along with this, a lexicon rich enough tohold all possible common words is maintained.However, this lexicon does not contain propernouns.
A new incoming sentence that is not seg-mented correctly is taken and suitable word boun-daries are generated by using a combination ofmorphological rules, lexicon lookups, bigram wordprobabilities and bigram HMM character model.The following probabilities are estimated and max-imized at character level using the Viterbi algo-rithm.
The following are the calculatedprobabilities:(i) )|( )(1)( initialkmedialk chchP ?
- is the prob-bility of character k being in medialform given character k-1 is in initialform.63(ii) )|( )(1)( initialkfinalk chchP ?
- is the proba-bility of character k being in final formgiven character k-1 is in initial form.
(iii) )|( )(1)( medialkfinalk chchP ?
- is the proba-bility of character k being in final formgiven character k-1 is in medial form.
(iv) )|( )(1)( medialkmedialk chchP ?
- is the proba-bility of character k being in medialform given character k-1 is in medialform.
(v) )|( )(1)( finalkinitialk chchP ?
- is the proba-bility of character k being in initialform given character k-1 is in finalform.Each word thus formed successfully is then veri-fied for morphological correctness.
If the word isnot valid morphologically, then the window ismoved back over 3 characters and at every step thevalidity of occurrence of the word is noted.
Simi-larly, the window is moved 3 characters ahead andthe validity of the word is verified.
All wordsformed successfully are taken and furtherprocessed using a language model that considersthe bigram occurrence for each word.
The un-known word probability is considered here as well.The word with maximum probability is taken asvalid in the given context.Let >< 321 www  be the word formed by themoving window.
Then, the word selected, ws, isgiven by(vi)?????????
?=)(|)()(|)()(|)(max321prevprevprevswPwPwPwPwPwPwwhere wprev  is the previous word.It is also noted that the number of times a transi-tion happens from a syllable set with consonants toa syllable set with vowels, in a word, is no longerthan four in most cases as noted below.
This factoris also considered for terminating the Viterbi algo-rithm for each word.Ir | aad | ah - three transitionsSome of the morphological rules consideredwhile deciding the word boundaries are given be-low.
Word boundary is formed when1.
The word ends with ''??
- un Gunna2.
The character transitions over to digits3.
Punctuations marks are encountered ('-' isalso included)4.
No two 'ye' - choti ye come back to back5.
No characters occur in detached form un-less they are initials or abbreviations fol-lowed by a period6.
If current character is 'alif' and the pre-vious character is 'ee' - bari ye then theword boundary occurs after 'alif'Some of the drawbacks seen in this model aremainly on account of improper identification ofproper nouns.
If a proper noun is not well seg-mented, the error propagates through the sentenceand typically the next two or three words fail to getsegmented correctly.
Also, in Urdu, some wordscan be written in more than one ways.
This mostlydepends on the diacritics and ambiguity betweenbari and choti 'ye'.
The training data as well as thetest data were not normalized before training.
Themodel shows a precision of 83%.
We realized thatthe efficiency of this model can be improved ifphoneme level transitions were taken into consid-eration.
Training has to be increased over moreproper nouns and a lexicon for proper nouns loo-kup has to be maintained.
Diacritics that are typi-cally used for beautification should be removed.Words across the documents need to be normalizedto one accepted format to assure uniqueness.
Thisinvolves considerable amount of work and hence,in order to prevent the propagation of error into theNLP text analysis pipeline, we decided to test oursubsequent models using pre-segmented data, in-dependent of our word segmentation model.4 Learning ApproachesA Conditional Random Field (CRF), is an undi-rected graphical model used for sequential learn-ing.
The tasks of POS tagging and NE tagging areboth sequential learning tasks and hence this learn-ing approach is a reasonable choice.
What followsis a brief outline about CRF.
Interested readers arereferred to Lafferty et al, (2001), for more infor-mation on CRF.4.1 Conditional Random Fields (CRF)64A linear chain CRF defines a single log-linearprobabilistic distribution over the possible tag se-quences y for a sentence x?
?= =?=TtKktttkk xyytfxZxyp1 11 ),,,(exp)(1)|( ?where  fk(t, yt, yt-1, xt) is typically a binary functionindicating the presence of feature k, ?k is the weightof the feature, and Z(x) is a normalization function.?
?
?= =?=yTtKktttkk xyytfxZ1 11 ),,,(exp)( ?This modeling allows us to define features onstates (the POS/NE tags) and edges (pairs of adja-cent POS/NE tags) combined with observations(eg.
words and POS tags for NE estimation).
Theweights of the features are determined such thatthey maximize the conditional log-likelihood of thetraining data:( )?
== i ii xypL 1 )()( )|(log)( ??
.For the actual implementation, CRF++10, anopen source tool that uses the CRF learning algo-rithm is used.
The L-BFGS algorithm11 is used foroptimization.4.2 %E Tagging using POS informationPOS tagging is a precursor for all text analysistasks.
Assigning POS tags to words without anyambiguity depends on contextual information andextracting this information is a challenge.
For alanguage like English, several techniques havebeen proposed that can be broadly classified intostatistical, rule based and hybrid approaches (Ek-bal, 2007).
The general consensus is that ap-proaches like MEMM and HMM, that work wellfor Hindi, would work well for Urdu as well, sinceUrdu is grammatically similar to Hindi (Platts,1909).
However, the linguistic and morphologicalrules used in the post processing steps differ fromHindi because of Urdu?s borrowed vocabulary and10 http://crfpp.sourceforge.net/11 http://www.mcs.anl.gov/index.phpstyle of writing from Arabic.
Also, the requirementfor such models to work well is the availability oflarge training data.Building NE recognizers for languages like Ur-du is difficult as there are no concepts like capitali-zation of characters.
Also, most names of peoplehave specific meanings associated with them andcan easily be found in a dictionary with differentassociated meanings.
Various learning approacheshave been proposed for this task, HMM basedlearning approach (Bikel et al, 1999), MaximumEntropy Approach (Borthwick, 1999) and CRFapproach (McCallum, 2003) are the most popular.Ashish et al, (2009) show an SVM based approachalso works well for such tasks.
To overcome theproblem of limited data availability, we present amethod to increase the amount of training data thatis available, by using a technique called bootstrap-ping.We do not have a training corpus that is manual-ly tagged for both POS and NE.
Our training dataconsists of two different datasets.
The dataset usedfor POS tagging is provided by CRULP and istagged using their tagset.
The dataset used for NEtagging is provided by CRL as a part of their Urduresource package.
The CRL tagset consists ofLOCATION, PERSON, ORGANIZATION, DATEand TIME tags.
We use only the first three tags inthis work.Our aim is to achieve effective POS tagging andNE tagging by maximizing the use of the availabletraining data.
The CRULP dataset (which we calldatasetPOS) is a corpus of 150,000 words that areonly POS tagged and the CRL dataset (which wecall datasetNE) is a corpus of 50,000 words that areonly NE tagged.
First, we trained a CRF model ondatasetNE that uses only the NE information to per-form NE recognition.
This one stage model wasnot effective due to the sparseness of the NE tagsin the dataset.
The model requires more data whiletraining.
The obvious and frequently tried ap-proach (Thamar, 2004) is to use the POS informa-tion.Figure 1 shows a two stage model that uses POSinformation to perform NE tagging.
The first stagePOSA performs POS tagging by using a CRFtrained model to assign POS tags to each word in asentence of datasetNE.
The second stage NEA per-forms NE tagging by using another CRF trainedmodel that uses both the POS information as well65as the NE information, to perform effective NEtagging.Figure 1.
Two stage model for NE tagging using POSinformationHowever, although the accuracy of NE taggingimproved over the one stage model, there wasscope for further improvement.
It is obvious thatall the NE tagged words should have the propernoun (NNP) POS tag associated.
But, when POStags were generated for the NE tagged ground truthdata in datasetNE, most of the words were eithertagged as adjectives (JJ) or common nouns (NN).Most tags that come after case markers (CM) wereadjectives (JJ) in the training data.
Very few ac-counted for proper nouns after case markers.
Thisadversely affected the NE tagger output.
It wasalso noticed that the POS tagger tagged most of theproper nouns (NNP) as common nouns (NN) be-cause of the sparseness of the proper noun tag inthe POS ground truth data set datasetPOS.
This ob-servation made us look to bootstrapping techniquesfor effective learning.We propose a four stage model as shown in Fig-ure 2, for NE tagging.
Three of the stages aretrained using the CRF learning approach and onestage uses a rule based approach.
All four stagesare trained using unigram features on tags andwords and bigram features on tags.
The POStagged dataset, datasetPOS, consists of words andassociated POS tags and the NE tagged dataset,datasetNE, consists of words and associated NEtags.
We divide both datasets into training and test-ing partitions.
datasetPOS is divided into trainsetPOSand testsetPOS and datasetNE is divided into train-setNE and testsetNE.Figure 2.
Four stage model for NE tagging using POSinformation with bootstrappingIn the model shown in Figure 2, POSA stage is aCRF based stage that is trained using trainsetPOS.Once trained, the POSA stage takes as input a sen-tence and generates the associated POS tag foreach word in that sentence.In order to increase the NNP tag associations toimprove NE tagging, we generate POS tags for theNE training data in trainsetNE using the POSAstage.
The POS tags generated at the POSA stageare called POSint.
The POScorrection stage takes asinput trainsetNE along with its associated POS tags,POSint.
At this stage, correction rules - that changethe POS tags of NE associated words to propernoun (NNP), assign Case Markers (CM) beforeand after the NE tags and verify proper tagging ofCardinals (CD) - are applied.
The corrected POStags are called POScorrected.
A consolidated POStraining set consisting of entries from both train-setPOS and trainsetNE (with POScorrected generated asoutput from the POScorrection stage) is used to trainthe CRF based POSB stage.
This stage is the finalPOS tagging stage.
Test data consisting of sen-tences (words) from testsetNE is sent as input tostage POSB and the output generated at stage POSBis the POS tag associated with each input word of asentence.
The NEB stage is a CRF based NE taggerthat is trained on a dataset consisting of word andassociated NE tags from trainsetNE and associatedPOS tags from POScorrected.
This stage learns fromthe POS information and the NE information pro-vided in the training data.
Once trained, the NEBstage takes as input words from testsetNE and asso-ciated POS tags (obtained at stage POSB) and ge-nerates NE tags.The domain we are interested in is newswirematerial, and these articles are written in the ?jour-66nalistic?
or ?news writing?
style12.
The articles areobjective and follow a Subject-Object-Verb struc-ture.
Related information is usually presented with-in close sentence proximity.
This makes it possibleto hand-craft grammar rules for the discovery ofNE tags with fine granularity.
The final POStagged and NE tagged data generated as outputs atstage POSB and stage NEB respectively of the fourstage model, are processed using rules and lexiconlookups to further improve the overall tagging ac-curacy of the model.
Rules used are mostly domainspecific.
The rules were applied to the model usingSemantex.4.3 Rules for POS Tagging1.
Our model tags all the Question Words(QW) like ?????
- kya as pronoun (PR).
Allsuch occurrences are assigned QW tag.2.
If the word is ?????
?
kya and the previoustag is an adjective (JJ) and the next tag is aphrase marker (PM) then assign a lightverb tag (VBL) else assign a verb (VB) tagto the word.3.
It was observed that there were spuriousinstances of proper nouns getting tagged asnouns.
In order to correct this error, if aword ends with any of the charactersshown below, and the word was tagged asa noun, then the tag on the word waschanged to a proper noun.
?%?, ???
,??
?, ?
()?, ?
*+?,?,-?, ???
?, ?
0*- ?, ????4.
All valid cardinals were tagged as nouns orproper nouns by the model.
This was re-solved by looking for a digit in the string.4.4 Rules for %E Tagging1.
Words like ??????
(court), ???????
(bu-reau), ?????
(army) etc.
are looked up.
Ifthere are any nouns or proper nouns abovethese within a window of two, then the tagon this word is ORGANIZATION.2.
Words like ???????
(organization), ?????
?are marked ORGANIZATION if the pre-vious word is a proper noun.3.
Lexicon look up for names of places is per-formed and the POS tag of the next wordthat is found is checked.
If this tag is a12 http://en.wikipedia.org/wiki/News_writingCase Marker (CM) with a feminine gend-er, like ????
(main) or ????
?, then theword is marked with a LOCATION tag.4.
If a proper noun that is selected ends witha suffix ?pur?, ?bad, ?dad?
and has thesame constraint as mentioned in rule 3,then the LOCATION tag is assigned to itas well.5 ResultsThe NE tagging performance, for both the twostage model and the four stage model, are eva-luated using Precision (P), Recall (R) and F-Score(FS) metrics, the equations for which are givenbelow.
(vii) NEs  taggedof No.NEs taggedcorrectly  of No.
P =(viii) setin test  NEs of no.
TotalNEs  taggedof No.R =(ix)PRRPFS +=2We performed a 10 fold cross validation test todetermine the performance of the model.
The data-set is divided into 10 subsets of approximatelyequal size.
One subset is withheld for testing andthe remaining 9 subsets are used for training.
Thisprocess is repeated for all 10 subsets and an aver-age result is computed.
The 10 fold validation testfor NE tagging was performed for both the twostage as well as the four stage models.Set P R FS P R FS1 48.09 73.25 58.06 60.54 78.7 68.442 38.94 72.42 50.65 60.29 80.46 68.933 56.98 74.38 64.53 60.54 79.74 68.834 38.44 78.05 51.51 60.54 80.79 69.215 32.29 75.91 45.31 60.79 80.34 69.216 44.82 88.02 59.4 59.31 79.93 68.097 45.75 69.75 55.26 61.04 81.73 69.898 43.52 71.5 54.11 60.05 80.36 68.749 44.64 81.97 57.8 59.93 81.09 68.9210 44.17 78.18 56.45 60.67 79.22 68.72Avg 43.764 76.343 55.308 60.37 80.236 68.898Four Stage ModelTwo Stage ModelTable 1.
NE tagging results for the two stage and fourstage modelsIt can be seen from Table 1 that the four stagemodel outperforms the two stage model with the67average F-Score being 55.31% for the two stagemodel and 68.89% for the four stage model.Table 2 shows the POS tagging results for stagesPOSA and POSB.
The POSB stage performs margi-nally better than the POSA stage.Set P Set P1 84.38 1 83.972 89.32 2 89.843 88.09 3 88.484 89.45 4 89.665 89.66 5 89.766 90.57 6 90.637 81.1 7 89.248 89.47 8 89.59 89 9 89.1210 89.12 10 89.25Avg 88.016 Avg 88.945POSB ResultsPOSA ResultsTable 2.
POS tagging results for the two stage (POSA)and four stage (POSB) modelsAlthough for POS tagging, the improvement isnot very significant between the two models, tagslike light verbs (VBLI), auxiliary verbs (AUXAand AUXT), adjectives (JJ), demonstratives (DM)and nouns (NN, NNC, NNCM, NNCR) get taggedwith higher accuracy in the four stage model asshown in Table 3.
This improvement becomes evi-dent in the NE test set.
Unfortunately, since thisdata has no associated POS tagged ground truth,the results cannot be quantified.
The trainsetPOStraining data had very few instances of propernouns (NNP) occurring after case markers (CM)and so most of the proper nouns were gettingtagged as either adjectives (JJ) or common nouns(NN).
After providing more training data to stagePOSB, the model could effectively learn propernouns.
Spurious tagging of adjectives (JJ) andcommon nouns (NN) reduced while more propernouns (NNP, NNPC) were tagged accurately andthis allowed the NE stage to apply its learning effi-ciently to the NE test set thereby improving the NEtagging results.The two stage model tagged 238 NE taggedwords as proper nouns out of 403 NE words.
Thefour stage model tagged 340 NE tagged words asproper nouns out of 403 NE words.
The four stagemodel shows an improvement of 25.3% over thetwo stage model.
The results reported for NE andPOS tagging models are without considering rulesor lexicon lookups.Tag FS Tag FSAUXA 0.801 AUXA 0.816AUXT 0.872 AUXT 0.898DM 0.48 DM 0.521JJ 0.751 JJ 0.765NN 0.85 NN 0.858NNC 0.537 NNC 0.549NNCM 0.909 NNCM 0.923NNCR 0.496 NNCR 0.51RB 0.785 RB 0.834VBLI 0.67 VBLI 0.693VBT 0.553 VBT 0.586POSA Output POSB OutputTable 3.
POS tagging results for stages POSA and POSBIn order to further improve the POS tagged re-sults and NE tagged results, the rules mentioned insections 4.3 and 4.4 and lexicon lookups were ap-plied.
Table 4 shows the result for NE tagging withan overall F-Score of 74.67%Tag P R FSLOCATION 0.78 0.793 0.786ORGANIZATION 0.775 0.731 0.752PERSON 0.894 0.595 0.714NEA OutputTable 4.
NE tagging results after applying rules for testresults in Table 16.
Conclusion and Future WorkThis work was undertaken as a precursor toachieve our final objective as discussed in Section1.
The basic idea here is to increase the size of theavailable training data, by using bootstrapping, soas to maximize learning for NE tagging.
The pro-posed four stage model shows an F-Score of 68.9%for NE tagging which is much higher than that ob-tained by the simple two stage model.A lot of avenues remain to be explored to fur-ther improve the performance of the model.
Oneapproach would be to use the bootstrapping tech-nique for NE data as well.
However, the rules re-quired can be complicated.
More hand crafted rulesand detailed lexicon lookups can result in betterNE tagging.
We have also noticed certain ambigui-ties in tagging PERSON and LOCATION.
Rulesthat resolve this ambiguity can be explored.68ReferencesRaymond G. Gordon Jr.
(ed.).
2005.
Ethnologue: Lan-guages of the World, Fifteenth edition.
Dallas, TX.
:SIL InternationalKashif Huda.
2001.
An Overview of Urdu on the Web.Annual of Urdu Studies Vol 20.Zaheer Ahmad, Jehanzeb Khan Orakzai, Inam Shamsh-er, Awais Adnan.
2007.
Urdu astaleeq CharacterRecognition.
Proceedings of World Academy ofScience, Engineering and Technology.
Volume 26,ISSN 2070-3740.John T. Platts.
1967.
A grammar of the Hindustani orUrdu language.
Munshiram Manoharlal Delhi.R.
L. Schmidt.
1999.
Urdu: an essential grammar.London: Routledge.Sarmad Hussain.
2008.
Resources for Urdu LanguageProcessing.
The 6th Workshop on Asian LanguageResources.P.
Baker, A. Hardie, T. McEnery, B.D.
Jayaram.
2003.Corpus Data for South Asian Language Processing.Proceedings of the 10th Annual Workshop for SouthAsian Language Processing, EACL.M.
Humayoun, H. Hammarstrm, A. Ranta.
2007.
UrduMorphology, Orthography and Lexicon Extraction.CAASL-2: The Second Workshop on ComputationalApproaches to Arabic Script-based Languages, LSA2007 Linguistic Institute, Stanford University.Waseem Siddiqi, Shahab Alam.
2008.
Online Urdu-English and English-Urdu dictionary.N.
Durrani.
2007.
Typology of Word and AutomaticWord Segmentation in Urdu Text Corpus.
NationalUniversity of Computer and Emerging Sciences, La-hore, Pakistan.T.
Theeramunkong, S. Usanavasin.
2001. on-Dictionary Based Thai Word Segmentation Usingdecision trees.
In proceedings of the First Interna-tional Conference on Human Language TechnologyResearch, San Diego, California, USA.A.
Pornprasertkul.
1994.
Thai Syntactic Analysis.
Ph.DThesis, Asian Institute of Technology.Ismat Javed.
1981.
??
?????
????.
Taraqqi Urdu Bureau,New Delhi.Abdul M. Haq.
1987.
????
???
?
???.
Amjuman-e-Taraqqi Urdu (Hindi).Hassan Sajjad.
2007.
Statistical Part of Speech Taggerfor Urdu.
National University of Computer andEmerging Sciences, Lahore, Pakistan.John D. Lafferty, Andrew McCallum, Fernando C.N.Pereira.
2001.
Conditional Random Fields: Probabi-listicModels for Segmenting and Labeling SequenceData.
Proceedings of the Eighteenth InternationalConference on Machine Learning, pp.
282-289.John Chen.
2006.
How to use Sequence Tagger.
Seman-tex Documentation, Janya Inc.Bikel, D.M., Schwartz, R.L., Weischedel, R.M.1999.An Algorithm that Learns What?s in a ame.
Ma-chine Learning 34(1-3), pp.
211?231.Borthwick, A.
1999.
Maximum Entropy Approach toamed Entity Recognition.
PhD thesis, New YorkUniversity.McCallum, A., Li, W. 2003.
Early results for amedEntity Recognition with Conditional Random Fields,Feature Induction and Web-enhanced Lexicons.
InProceedings of CoNLL.A.
Hardie.
2003.
Developing a tagset for automatedpart-of-speech tagging in Urdu.
Department of Lin-guistics and Modern English Language, Universityof Lancaster.Leech, G and Wilson, A.
1999.
Standards for tagsets.Edited version of EAGLES Recommendations for theMorphosyntactic Annotation of Corpora.
In van Hal-teren, H (ed.)
Syntactic wordclass tagging.
Dor-drecht: Kluwer Academic Publishers.Awaghad Ashish Krishnarao, Himanshu Gahlot, AmitSrinet and D. S. Kushwaha.
2009.
A ComparativeStudy of amed Entity Recognition for Hindi UsingSequential Learning Algorithms.
In IEEE Interna-tional Advance Computing Conference (IACC '09),Thapar University, India.
March 6-7.Thamar Solario.
2004.
Improvement of amed EntityTagging by Machine Learning, Technical ReportCCC-04-004, Coordinacin de Ciencias Computatio-nales.Ekbal, A. and Bandyopadhyay, S. 2007.
A HiddenMarkov Model Based amed Entity Recognition Sys-tem: Bengali and Hindi as Case Studies.
SpringerLNCS, Vol.
4815, pp.
545.R.
K. Srihari, W. Li, C. Niu and T. Cornell,"InfoXtract:A Customizable Intermediate Level Information Ex-traction Engine," Journal of atural Language En-gineering, Cambridge U.
Press, 14(1), 2008, pp..33-69.69
