Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006, pages 86?93,Sydney, July 2006. c?2006 Association for Computational LinguisticsCorpus annotation by generationElke TeichTU DarmstadtDarmstadt, Germanyteich@linglit.tu-darmstadt.deJohn A. BatemanUniversita?t BremenBremen, Germanybateman@uni-bremen.deRichard EckartTU DarmstadtDarmstadt, Germanyeckart@linglit.tu-darmstadt.deAbstractAs the interest in annotated corpora isspreading, there is increasing concern withusing existing language technology forcorpus processing.
In this paper we ex-plore the idea of using natural languagegeneration systems for corpus annotation.Resources for generation systems often fo-cus on areas of linguistic variability thatare under-represented in analysis-directedapproaches.
Therefore, making use ofgeneration resources promises some sig-nificant extensions in the kinds of anno-tation information that can be captured.We focus here on exploring the use ofthe KPML (Komet-Penman MultiLingual)generation system for corpus annotation.We describe the kinds of linguistic infor-mation covered in KPML and show thesteps involved in creating a standard XMLcorpus representation from KPML?s gener-ation output.1 IntroductionMany high-quality, theory-rich language process-ing systems can potentially be applied to corpusprocessing.
However, the application of exist-ing language technology, such as lexical and/orgrammatical resources as well as parsers, turns outnot to be as straightforward as one might thinkit should be.
Using existing computational lexi-cons or thesauri, for instance, can be of limitedvalue because they do not contain the domain-specific vocabulary that is needed for a partic-ular corpus.
Similarly, most existing grammat-ical resources for parsing have restricted cover-age in precisely those areas of variation that arenow most in need of corpus-supported investiga-tion (e.g., predicate-argument structure, informa-tion structure, rhetorical structure).
Apart fromlimited coverage, further issues that may impedethe ready application of parsers in corpus process-ing include:?
Annotation relevance.
Specialized, theory-specific parsers (also called ?deep parsers?
;e.g., LFG or HPSG parsers) have been builtwith theoretical concerns in mind rather thanappliability to unrestricted text.
They maythus produce information that is not annota-tionally relevant (e.g., many logically equiv-alent readings of a single clause).?
Usability.
Deep parsers are highly complextools that require expert knowledge.
The ef-fort in acquiring this expert knowledge maybe too high relative to the corpus processingtask.?
Completeness.
Simple parsers (commonlycalled ?shallow parsers?
), on the otherhand, produce only one type of anno-tationally relevant information (e.g., PoS,phrase/dependency structure).
Other desir-able kinds of information are thus lack-ing (e.g., syntactic functions, semantic roles,theme-rheme).?
Output representation.
Typically, a parsingoutput is represented in a theory-specific way(e.g., in the case of LFG or HPSG parsers,a feature structure).
Such output does notconform to the common practices in corpusrepresentation.1 Thus, it has to be mappedonto one of the standardly used data mod-els for corpora (e.g., annotation graphs (Birdand Liberman, 2001) or multi-layer hier-archies (Sperberg-McQueen and Huitfeldt,2001; Teich et al, 2001)) and transformedto a commonly employed format, typicallyXML.1This is in contrast to the output representation of shal-low parsers which have often been developed with the goalof corpus processing.86In spite of these difficulties, there is a generalconsensus that the reward for exploring deep pro-cessing techniques to build up small to medium-scale corpus resources lies in going beyond thekinds of linguistic information typically coveredby treebanks (cf.
(Baldwin et al, 2004; Cahill etal., 2002; Frank et al, 2003)).In this paper, we would like to contribute to thisenterprise by adding a novel, yet complementaryperspective on theory-rich, high-quality corpus an-notation.
In a reappraisal of the potential contribu-tion of natural language generation technology forproviding richly annotated corpora, we explore theidea of annotation by generation.
Although thismay at first glance seem counter-intuitive, in fact agenerator, similar to a parser, creates rather com-plex linguistic descriptions (which are ultimatelyrealized as strings).
In our current investigations,we are exploring the use of these complex linguis-tic descriptions for creating annotations.
We be-lieve that this may offer a worthwhile alternativeor extension of corpus annotation methods whichmay alleviate some of the problems encounteredin parsing-based approaches.The generation system we are using is the KPML(Komet-Penman MultiLingual; (Bateman, 1997))system.
One potential advantage of KPML overother generation systems and over many parsingsystems is its multi-stratal design.
The kindsof linguistic information included in KPML rangefrom formal-syntactic (PoS, phrase structure) tofunctional-syntactic (syntactic functions), seman-tic (semantic roles/frames) and discoursal (e.g.,theme-rheme, given-new).
Also, since KPML hasbeen applied to generate texts from a broad spec-trum of domains, its lexicogrammatical resourcescover a wide variety of registers?another poten-tial advantage in the analysis of unrestricted text.As well as our general concern with investigat-ing the possible benefits of applying generationresources to the corpus annotation task, we arealso more specifically concerned with a series ofexperiments involving the KPML system as such.Here, for example, we are working towards theconstruction of ?treebanks?
based on the theory ofSystemic-Functional Linguistics (SFL; (Halliday,2004)), so as to be able to empirically test some ofSFL?s hypotheses concerning patterns of instantia-tion of the linguistic system in authentic texts.
An-notating the variety of linguistic categories givenin SFL manually is very labor-intensive and an au-tomated approach is clearly called for.
We are alsoworking towards a more detailed comparison ofthe coverage of the lexicogrammatical resourcesof KPML with those of parsing systems that aresimilarly theoretically-dedicated (e.g., the HPSG-based English Resource Grammar (ERG) (Copes-take and Flickinger, 2002) contained in LinGO(Oepen et al, 2002)).
Thus, the idea presentedhere is also motivated by the need to provide a ba-sis for comparing grammar coverage across pars-ing and generation systems more generally.The remainder of the paper is organized as fol-lows.
First, we present the main features of theKPML system (Section 2).
Second, we describe thesteps involved in annotation by generation, fromthe generation output (KPML internal generationrecord) to an XML representation and its refine-ment to an XML multi-layer representation (Sec-tion 3).
Section 4 concludes the paper with a criti-cal assessment of the proposed approach and a dis-cussion of the prospects for application in the con-struction of corpora comparable in size and qual-ity to existing treebanks (such as, for example, thePenn Treebank for English (Marcus et al, 1993)or the TIGER Treebank for German (Brants et al,2002)).
Since our description here has the statusof a progress report of work still in its beginningstages, we cannot yet provide the results of de-tailed evaluation.
In the final section, therefore, weemphasize the concrete steps that we are currentlytaking in order to be able carry out the detailedevaluations necessary.2 Natural language generation withKPMLThe KPML system is a mature grammar devel-opment environment for supporting large-scalegrammar engineering work for natural languagegeneration using multilingual systemic-functionalgrammars (Bateman et al, 2005).
Grammarswithin this framework consist of large lattices ofgrammatical features, each of which brings con-straints on syntactic structure.
The features arealso linked back to semantic configurations so thatthey can be selected appropriately when given asemantic specification as input.
The result of gen-erating with a systemic-functional grammar withKPML is then a rich feature-based representationdistributed across a relatively simple structuralbackbone.
Each node of the syntactic represen-tation corresponds to an element of structure and87typically receives on the order of 50-100 linguisticfeatures, called the feature selection.
Since withinsystemic-functional grammars, it is the featuresof the feature selection that carry most of the de-scriptive load, we can see each feature selection asan exhaustive description of its associated syntac-tic constituent.
Generation within KPML normallyproceeds on the basis of a semantic input specifi-cation which triggers particular feature selectionsfrom the grammar via a mediating linguistic ontol-ogy.The features captured in a systemic-functionalgeneration resource are drawn from the four com-ponents of functional meaning postulated withinsystemic-functional grammar: the ideational, ex-pressing content-related decisions, the logical, ex-pressing logical dependencies, the interpersonal,expressing interactional, evaluative and speech actinformation, and the textual, expressing how eachelement contributes to an unfolding text.
It is inthis extremely rich combination of features thatwe see significant value in exploring the re-use ofsuch grammars for annotation purposes and cor-pus enrichment.For annotation purposes, we employ someof the alternative modes of generation thatare provided by the full grammar developmentenvironment?it is precisely these that allow forready incorporation and application within the cor-pus annotation task.
One of the simplest ways inwhich generation can be achieved during grammardevelopment, for example, is by directly select-ing linguistic features from the grammar.
This cantherefore mimic directly the task of annotation: ifwe consider a target sentence (or other linguisticunit) to be annotated, then selecting the necessaryfeatures to generate that unit is equivalent to anno-tating that unit in a corpus with respect to a veryextensive set of corpus annotation features.Several additional benefits immediately acruefrom the use of a generator for this task.
First,the generator actually constructs the sentence (orother unit) as determined by the feature selection.This means that it is possible to obtain immedi-ate feedback concerning the correctness and com-pleteness of the annotation choices with respect tothe target.
A non-matching structure can be gener-ated if: (a) an inappropriate linguistic feature hasbeen selected, (b) the linguistic resources do notcover the target to be annotated, or (c) a combina-tion of these.
In order to minimise the influenceof (b), we only work with large-scale grammaticalresources whose coverage is potentially sufficientto cover most of the target corpus.
Further cor-pus instances that lie beyond the capabilities of thegeneration grammar used are an obvious source ofrequirements for extensions to that grammar.Second, the architecture of the KPML systemalso allows for other kinds of annotation support.During grammar development it is often requiredthat guidance is given directly to the semantics-grammar linking mappings: this is achieved byproviding particular ?answers?
to pre-defined ?in-quiries?.
This allows for a significantly moreabstract and ?intention?-near interaction with thegrammatical resource that can be more readilycomprehensible to a user than the details of thegrammatical features.
This option is therefore alsoavailable for annotation.Moreover, the semantic specifications used relyon a specified linguistic ontology that defines par-ticular semantic types.
These types can also beused directly in order to constrain whole collec-tions of grammatical features.
Providing this kindof guidance during annotation can also, on the onehand, simplify the process of annotation while, onthe other, produce a semantic level of annotationfor the corpus.In the following sections, we see a selection ofthese layers of information working in annotationin more detail, showing that the kinds of informa-tion produced during generation corresponds ex-tremely closely to the kinds of rich annotationscurrently being targetted for sophisticated corpuspresentation.3 Creating corpus annotations fromKPML output3.1 KPML outputThe output produced by KPML when being usedfor generation is a recursive structure with the cho-sen lexical items at the leaves.
Figure 1 shows theoutput tree for the sample sentence ?However theywill step up their presence in the next year?.The nodes of this structure may be freely an-notated by the user or application system to con-tain further information: e.g., for passing throughhyperlinks and URLs directly with the semanticswhen generating hypertext.
Most users simply seethe result of flattening this structure into a string:the generated sentence or utterance.This result retains only a fraction of the in-88Figure 1: Tree generated by KPMLformation that is employed by the generator dur-ing generation.
Therefore, since we are usingthe grammar development environment rather thansimply the generator component, we also have thepossibility of working directly with the internalstructures that KPML employs for display and de-bugging of resources during development.
Theseinternal structures contain a complete record ofthe information provided to the generation pro-cess and the generator decisions (including whichgrammatical features have been selected) that havebeen made during the construction of each unit.This internal record structure is again a recursivestructure corresponding directly to the syntacticstructure of the generated result and with eachnode having the information slots:constituent:{identifier, \\ unique id for the unitconcept, \\ link to the semantic concept expressedspelling, \\ the substring for this portion of structuregloss, \\ a label for use in inter-lineal glossesfeatures, \\ the set of grammatical features for this unitlexeme, \\ the lexeme chosen to cover this unit (if any)annotation, \\ user-specified informationfunctions \\ the grammatical functions the unit expresses}An extract from such an internal record structureencoded in XML is given in the Appendix (5.1).To support annotation, we make use of the XML-export capabilities of KPML (cf.
(Bateman andHartley, 2000)) in order to provide these com-pleted structures in a form suitable for passing onto the next stage of corpus annotation within anXML-based multi-layer framework.3.2 XML multi-layer representationSystemic-functional analysis is inherently multi-dimensional in that SFL adopts more than one viewon a linguistic unit.
Here, we focus on three anno-tationally relevant dimensions: axis (features andfunctions), unit (clause, group/phrase, word, mor-pheme) and metafunction (ideational, logical, in-terpersonal and textual).
Each metafunction maychunk up a given string (e.g., a clause unit) inFigure 2: Generation output viewed as multi-layerannotation<sfglayer metafunction="IDEATIONAL">However,<segment functions="AGENT">they</segment>will step up<segment functions="DIRECTCOMPLEMENT GOAL MEDIUM">their presence</segment><segment functions="TIMELOCATIVE">in the next year</segment>.</sfglayer>Figure 3: Metafunction+Function layersdifferent ways, thus potentially creating overlap-ping hierarchies.
This is depicted schematicallyfor the running example in Figure 2.
For instance,in this example, according to the textual meta-function, ?however they?
constitutes a segment(Theme) and according to the interpersonal meta-function, ?they will?
constitutes another segment(Mood).In order to be able to use the KPML output forannotation purposes, we adopt a multi-layer modelthat allows the representation of these different de-scriptional dimensions as separate layers superim-posed on a given string (cf.
(Teich et al, 2005)).The transformation from the KPML output to theconcrete multi-layer model adopted is defined inXSLT.From the KPML internal record structure weuse the information slots of identifier, spelling,features, and functions.
Each entry in the func-tion slot is associated with one metafunctional as-pect.
For each metafunctional aspect, an annota-tion layer is created for each constituent unit (e.g.,a clause) holding all associated functions togetherwith the substrings they describe (see Figure 3 forthe ideational functions contained in the clause inthe running example).An additional layer holds the complete con-stituent structure of the clause (cf.
Figure 4 for thecorresponding extract from the running example),89<constituent unit="-TOP-"selexp="LEXICAL-VERB-TERM-RESOLUTION..."><token features="HOWEVER">However,</token><constituent unit="TOPICAL"selexp="THEY-PRONOUN..."><token features="THEY PLURAL-FORM">they</token></constituent><token features="OUTCLASSIFY-REDUCED...">will</token><token features="DO-VERB...">step up</token><constituent unit="DIRECTCOMPLEMENT"selexp="NOMINAL-TERM-RESOLUTION OBLIQUE..."><constituent unit="DEICTIC"selexp="THEIR GENITIVE NONSUPERLATIVE..."><token features="THEIR PLURAL-FORM">their</token></constituent><token features="...COMMON-NOUN...">presence</token></constituent><constituent unit="TIMELOCATIVE"selexp="IN STRONG-INCLUSIVE UNORDERED..."><token features="IN">in</token><constituent unit="MINIRANGE"selexp="NOMINAL-TERM-RESOLUTION..."><token features="THE">the</token><constituent unit="STATUS"selexp="QUALITY-TERM-RESOLUTION..."><token features="...ADJECTIVE">next</token></constituent><token features="...COMMON-NOUN...">year .</token></constituent></constituent></constituent>Figure 4: Constituent+Feature layeri.e., the phrasal constituents and their features:<constituent unit="..." selexp="..."></constituent>and the tokens and their (lexical) features:<token features="..."> ... </token>Thus, the KPML generation output, which di-rectly reflects the trace of the generation process,is reorganized into a meaningful corpus represen-tation.
Information not relevant to annotation canbe ignored without loss of information concerningthe linguistic description.
The resulting represen-tation for the running example is shown in the Ap-pendix (5.2).24 DiscussionAlthough it is clear that the kind of informationalstructures produced during generation with moredeveloped KPML grammars align quite closelywith that targetted by sophisticated corpus anno-tation, there are several issues that need to be ad-dressed in order to turn this process into a prac-tical annotation alternative.
Those which we arecurrently investigating centre around usability andcoverage.2To improve readability, we provide the integrated repre-sentation rather than the stand-off representation which alignsthe different layers by using character offsets.Usability/effort.
Users need to be trained in pro-viding information to guide the generation pro-cess.
This guidance is either in the form of di-rect selections of grammatical features, in whichcase the user needs to know when the features ap-ply, or in the form of semantic specifications, inwhich case the user needs information concerningthe appropriate semantic classification accordingto the constructs of the linguistic ontology.
One ofthe methods by which the problem of knowing theimport of grammatical features may be alleviatedis to link each feature with sets of already anno-tated/generated corpus examples.
Thus, if a useris unsure concerning a feature, she can call forexamples to be displayed in which the particularlinguistic unit carrying the feature is highlighted.Even more useful is a further option which showsnot only examples containing the feature, but con-trasting examples showing where the feature hasapplied and where it has not.
This provides userswith online training during the use of the systemfor annotation.
The mechanisms for showing ex-amples and contrasting sets of generated sentencesfor each feature were originally provided as partof a teaching aid built on top of KPML: this allowsstudents to explore a grammar by means of the ef-fects that each set of contrasting features bringsfor generated structures.
For complex grammarsthis appears to offer a viable alternative to precisedocumentation?especially for less skilled users.Coverage.
When features have been selected, itmay still be the case that the correct target stringhas not been generated due to limited coverageof grammar and/or semantics.
This is indicativeof the need to extend the grammatical resourcesfurther.
A further alternative that we are explor-ing is to allow users to specify the correspondencebetween the units generated and the actual targetstring more flexibly.
This is covered by two cases:(i) that additional material is in the target stringthat was not generated, and (ii) that the surfaceorder of constituents is not exactly that producedby the generator.
In both cases we can refine thestand-off annotation so that the structural resultof generation can be linked to the actual string.Thus manual correction consists of minor align-ment statements between generated structure andstring.Certain other information that may not be avail-able to the generator, such as lexical entries, can beconstructed semi-automatically on-the-fly, again90using the information produced in the generationprocess (i.e., by collecting the lexical classifica-tion features and adding lexemes containing thosefeatures).
This method can be applied for all openword classes.Next steps.
In our future work, we will be car-rying out an extensive annotation experiment withthe prediction that annotation time is not higherthan for interactive annotation from a parsing per-spective.
TIGER, for example, reports 10 min-utes per sentence as an average annotation time.We expect an experienced KPML user to be sig-nificantly faster because the process of generationor feature selection explicitly leads the annotatorthrough precisely those features that are relevantand possible given the connectivity of the featurelattice defined by the grammar.
Annotation thenproceeds first by selecting the features that applyand then by aligning the generated structure withthe corpus instance: both potentially rather rapidstages.
Also, we would expect to achieve similarcoverage as reported by (Baldwin et al, 2004) forERG when applied to a random 20,000 string sam-ple of the BNC due to the coverage of the existinggrammars.The results of such investigations will be SFL-treebanks, analogous to such treebanks producedusing dependency approaches, LFG, HPSG, etc.These treebanks will then support the subsequentlearning of annotations for automatic processing.Acknowledgment.
This work was partially supportedby Hessischer Innovationsfond of TU Darmstadt and PACE(Partners for the Advancement of Collaborative EngineeringEducation: www.pacepartners.org).ReferencesT.
Baldwin, E. M. Bender, D. Flickinger, A. Kim, andS.
Oepen.
2004.
Road-testing the EnglishResourceGrammar over the British National Corpus.
InProceedings of the 4th International Conference onLanguage Resources and Evaluation (LREC) 2004,Lisbon, Portugal.J.
A. Bateman and A. F. Hartley.
2000.
Targetsuites for evaluating the coverage of text generators.In Proceedings of the 3rd International Conferenceon Language Resources and Evaluation (LREC),Athens, Greece.J.
A. Bateman, I.
Kruijff-Korbayova?, and G.-J.
Krui-jff.
2005.
Multilingual resource sharing acrossboth related and unrelated languages: An imple-mented, open-source framework for practical natu-ral language generation.
Research on Language andComputation, 3(2):191?219.J.
A. Bateman.
1997.
Enabling technology for multi-lingual natural language generation: the KPML de-velopment environment.
Journal of Natural Lan-guage Engineering, 3(1):15?55.S.
Bird and M. Liberman.
2001.
A formal frameworkfor linguistic annotation.
Speech Communication,33(1-2):23?60.S.
Brants, S. Dipper, S. Hansen, W. Lezius, andG.
Smith.
2002.
The TIGER treebank.
In Proceed-ings of the Workshop on Treebanks and LinguisticTheories, Sozopol.A.
Cahill, M. McCarthy, J. van Genabith, and A. Way.2002.
Automatic annotation of the Penn-Treebankwith LFG f-structure information.
In Proceedings ofthe 3rd International Conference on Language Re-sources and Evaluation (LREC) 2002, Las Palmas,Spain.A.
Copestake and D. Flickinger.
2002.
An open-sourcegrammar development environment and broad cov-erage English grammar using HPSG.
In Proceed-ings of the 2nd International Conference on Lan-guage Resources and Evaluation (LREC), Athens,Greece.A.
Frank, L. Sadler, J. van Genabith, and A. Way.2003.
From treebank resources to LFG f-structures.Automatic f-structure annotation of treebank treesand CFGs extracted from treebanks.
In A. Abeille,editor, Treebanks.
Building and using syntacticallyannotated corpora, pages 367?389.
Kluwer Aca-demic Publishers, Dordrecht, Boston, London.MAK Halliday.
2004.
Introduction to FunctionalGrammar.
Arnold, London.M.
P. Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: the Penn Treebank.
Computational Linguis-tics, 19(2):313?330.S.
Oepen, E. Callahan, D. Flickinger, C. D. Manning,and K. Toutanova.
2002.
LinGO Redwoods.
A richand dynamic treebank for HPSG.
In Workshop onParser Evaluation, 3rd International Conference onLanguage Resources and Evaluation (LREC), LasPalmas, Spain.C.M.
Sperberg-McQueen and C. Huitfeldt.
2001.GODDAG: A Data Structure for Overlapping Hi-erarchies.
In Proceedings of PODDP?00 andDDEP?00, New York.E.
Teich, S. Hansen, and P. Fankhauser.
2001.
Rep-resenting and querying multi-layer corpora.
InProceedings of the IRCS Workshop on LinguisticDatabases, University of Pennsylvania, Philadel-phia.E.
Teich, P. Fankhauser, R. Eckart, S. Bartsch, andM.
Holtz.
2005.
Representing SFL-annotated cor-pus resources.
In Proceedings of the 1st Computa-tional Systemic Functional Workshop, Sydney, Aus-tralia.915 Appendix5.1 Extract from generation record (clause level)<example><name>REUTERS29</name><generatedForm>However, they will step up their presence in the next year.</generatedForm><targetForm>But they will step up their presence in the next year.</targetForm><structures><constituent id="G3324" semantics="STEP-3278"><functions><function metafunction="UNKNOWN">SENTENCE</function></functions><features/><subconstituents><constituent id="G3308" semantics="RR62-3289"><functions><function metafunction="TEXTUAL">TEXTUAL</function><function metafunction="TEXTUAL">CONJUNCTIVE</function></functions><features><f>HOWEVER</f></features><subconstituents><string>However,</string></subconstituents></constituent><constituent id="G3310" semantics="PERSON-3291"><functions><function metafunction="TEXTUAL">TOPICAL</function><function metafunction="INTERPERSONAL">SUBJECT</function><function metafunction="UNIFYING">ACTOR</function><function metafunction="IDEATIONAL">AGENT</function></functions><features/><subconstituents><constituent id="G3309" semantics="PERSON-3291"><functions><function metafunction="LOGICAL">THING</function></functions><features><f>THEY</f><f>PLURAL-FORM</f></features><subconstituents><string>they </string></subconstituents></constituent></subconstituents></constituent><constituent id="G3311" semantics="ST59-3280-3297-3302"><functions><function metafunction="LOGICAL">TEMPO0</function><function metafunction="INTERPERSONAL">FINITE</function></functions><features><f>OUTCLASSIFY-REDUCED</f><f>OUTCLASSIFY-NEGATIVE-AUX</f><f>FUTURE-AUX</f><f>PLURAL-FORM</f><f>THIRDPERSON-FORM</f></features><subconstituents><string>will </string></subconstituents></constituent><constituent id="G3312" semantics="STEP-3278"><functions><function metafunction="UNIFYING">AUXSTEM</function><function metafunction="LOGICAL">VOICE</function><function metafunction="LOGICAL">LEXVERB</function><function metafunction="LOGICAL">PROCESS</function></functions><features><f>DO-VERB</f><f>EFFECTIVE-VERB</f><f>DISPOSAL-VERB</f><f>STEM</f></features><subconstituents><string>step up </string></subconstituents></constituent><constituent id="G3316" semantics="PRESENCE-3292-3306"><functions><function metafunction="IDEATIONAL">DIRECTCOMPLEMENT</function><function metafunction="IDEATIONAL">GOAL</function><function metafunction="IDEATIONAL">MEDIUM</function></functions></constituent></subconstituents></constituent></structures><selectionexpressions><selexp sem="STEP-3278"><unit>-TOP-</unit><f>LEXICAL-VERB-TERM-RESOLUTION</f><f>DO-NEEDING-VERBS</f><f>AUXSTEM-VOICE</f><f>REAL</f><f>NON-MOTION-CLAUSE</f><f>PLURAL-FINITE</f><f>PLURAL-SUBJECT</f><f>TOPICAL-INSERT</f> ...</selexp><selexp>...</selexp>...</selectionexpressions></example>5.2 Multi-layer representation of generation recordMetafunction+Function layers<sfglayer metafunction="UNKNOWN"><segment functions="SENTENCE">However, they will step up their presence in the next year .</segment></sfglayer><sfglayer metafunction="UNIFYING">However,<segment functions="ACTOR">they</segment>will<segment functions="AUXSTEM">step up</segment>their presence in the next year .</sfglayer><sfglayer metafunction="TEXTUAL"><segment functions="TEXTUAL CONJUNCTIVE">However,</segment><segment functions="TOPICAL">they</segment>will step up their presence in the next year .</sfglayer>92<sfglayer metafunction="LOGICAL">However,<segment functions="THING">they</segment><segment functions="TEMPO0">will</segment><segment functions="VOICE LEXVERB PROCESS">step up</segment><segment functions="THING">their</segment><segment functions="THING">presence</segment>in the<segment functions="QUALITY">next</segment><segment functions="THING">year .</segment></sfglayer><sfglayer metafunction="INTERPERSONAL">However,<segment functions="SUBJECT">they</segment><segment functions="FINITE">will</segment>step up<segment functions="DEICTIC">their</segment>presence in<segment functions="DEICTIC">the</segment>next year .</sfglayer><sfglayer metafunction="IDEATIONAL">However,<segment functions="AGENT">they</segment>will step up<segment functions="DIRECTCOMPLEMENT GOAL MEDIUM">their presence</segment><segment functions="TIMELOCATIVE"><segment functions="MINORPROCESS">in</segment><segment functions="MINIRANGE">the<segment functions="STATUS">next</segment>year .</segment></segment></sfglayer>Constituent+Feature layer<constituent id="G3324" unit="-TOP-"selexp="LEXICAL-VERB-TERM-RESOLUTION DO-NEEDING-VERBS AUXSTEM-VOICE REAL NON-MOTION-CLAUSE TOPICAL-INSERT ..."><token features="HOWEVER">However,</token><constituent id="G3310" unit="TOPICAL"selexp="THEY-PRONOUN NONDEMONSTRATIVE-SPECIFIC-PRONOUN NOMINATIVE NONSUPERLATIVE NONREPRESENTATION NONPARTITIVE ..."><constituent id="G3309" unit="TOPICAL"><token features="THEY PLURAL-FORM">they</token></constituent></constituent><tokenfeatures="OUTCLASSIFY-REDUCED OUTCLASSIFY-NEGATIVE-AUX FUTURE-AUX PLURAL-FORM THIRDPERSON-FORM">will</token><constituent id="G3312" unit="-TOP-"><token features="DO-VERB EFFECTIVE-VERB DISPOSAL-VERB STEM">step up</token></constituent><constituent id="G3316" unit="DIRECTCOMPLEMENT"selexp="NOMINAL-TERM-RESOLUTION OBLIQUE NONSUPERLATIVE NONREPRESENTATION NONPARTITIVE NONQUANTIFIED NOMINAL-GROUP ..."><constituent id="G3314" unit="DEICTIC"selexp="THEIR GENITIVE NONSUPERLATIVE NONREPRESENTATION NONPARTITIVE NONQUANTIFIED NOMINAL-GROUP ..."><constituent id="G3313" unit="DEICTIC"><token features="THEIR PLURAL-FORM">their</token></constituent></constituent><constituent id="G3315" unit="DIRECTCOMPLEMENT"><tokenfeatures="OUTCLASSIFY-PROPERNOUN NOUN COMMON-NOUN COUNTABLE SINGULAR-FORM NOUN">presence</token></constituent></constituent><constituent id="G3323" unit="TIMELOCATIVE"selexp="IN STRONG-INCLUSIVE UNORDERED TEMPORAL-PROCESS LOCATION-PROCESS SPATIO-TEMPORAL-PROCESS PREPOSITIONAL-PHRASE ..."><token features="IN">in</token><constituent id="G3322" unit="MINIRANGE"selexp="NOMINAL-TERM-RESOLUTION OBLIQUE NONSUPERLATIVE NONREPRESENTATION NONPARTITIVE NONQUANTIFIED NOMINAL-GROUP ..."><token features="THE">the</token><constituent id="G3320" unit="STATUS"selexp="QUALITY-TERM-RESOLUTION SIMPLEX-QUALITY NOTINTENSIFIED NONSCALABLE CONGRUENT-ADJECTIVAL-GROUP ..."><constituent id="G3319" unit="STATUS"><token features="OUTCLASSIFY-DEGREE-ADJ ADJ-NEUTRAL-FORM ADJECTIVE">next</token></constituent></constituent><constituent id="G3321" unit="MINIRANGE"><token features="OUTCLASSIFY-PROPERNOUN NOUN COMMON-NOUN COUNTABLE SINGULAR-FORM NOUN">year .</token></constituent></constituent></constituent></constituent>93
