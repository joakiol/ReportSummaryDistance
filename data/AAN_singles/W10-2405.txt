Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 39?47,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsTransliteration Generation and Mining with Limited Training ResourcesSittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma, Aditya Bhargava,Qing Dou, Mi-Young Kim, Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, AB, T6G 2E8, Canada{sj,dwyer,bergsma,abhargava,qdou,miyoung2,kondrak}@cs.ualberta.caAbstractWe present DIRECTL+: an online dis-criminative sequence prediction modelbased on many-to-many alignments,which is further augmented by the in-corporation of joint n-gram features.Experimental results show improvementover the results achieved by DIRECTL in2009.
We also explore a number of diverseresource-free and language-independentapproaches to transliteration mining,which range from simple to sophisticated.1 IntroductionMany out-of-vocabulary words in statistical ma-chine translation and cross-language informationretrieval are named entities.
If the languages inquestion use different writing scripts, such namesmust be transliterated.
Transliteration can be de-fined as the conversion of a word from one writ-ing script to another, which is usually based on thephonetics of the original word.DIRECTL+ is our current approach to nametransliteration which is an extension of the DI-RECTL system (Jiampojamarn et al, 2009).
Weaugmented the feature set with joint n-gram fea-tures which allow the discriminative model to uti-lize long dependencies of joint information ofsource and target substrings (Jiampojamarn et al,2010).
Experimental results suggest an improve-ment over the results achieved by DIRECTL in2009.Transliteration mining aims at automaticallyobtaining bilingual lists of names written in differ-ent scripts.
We explore a number of different ap-proaches to transliteration mining in the context ofthe NEWS 2010 Shared Task.1 The sole resourcethat is provided for each language pair is a ?seed?1http://translit.i2r.a-star.edu.sg/news2010dataset that contains 1K transliteration word pairs.The objective is then to mine transliteration pairsfrom a collection of Wikipedia titles/topics that aregiven in both languages.We explore a number of diverse resource-freeand language-independent approaches to translit-eration mining.
One approach is to bootstrap theseed data by generating pseudo-negative exam-ples, which are combined with the positives toform a dataset that can be used to train a clas-sifier.
We are particularly interested in achiev-ing good performance without utilizing language-specific resources, so that the same approach canbe applied with minimal or no modifications to anarray of diverse language pairs.This paper is divided in two main parts that cor-respond to the two tasks of transliteration genera-tion and transliteration mining.2 Transliteration generationThe structure of this section is as follows.
In Sec-tion 2.1, we describe the pre-processing steps thatwere applied to all datasets.
Section 2.2 reviewstwo methods for aligning the source and targetsymbols in the training data.
We provide detailson the DIRECTL+ systems in Section 2.3.
In Sec-tion 2.4, we discuss extensions of DIRECTL+ thatincorporate language-specific information.
Sec-tion 2.5 summarizes our results.2.1 Pre-processingFor all generation tasks, we pre-process the pro-vided data as follows.
First, we convert all char-acters in the source word to lower case.
Then,we remove non-alphabetic characters unless theyappear in both the source and target words.
Wenormalize whitespace that surrounds a comma, sothat there are no spaces before the comma and ex-actly one space following the comma.
Finally, weseparate multi-word titles into single words, usingwhitespace as the separator.
We assume a mono-39tonic matching and ignore the titles that have a dif-ferent number of words on both sides.We observed that in the ArAe task there arecases where an extra space is added to the targetwhen transliterating from Arabic names to theirEnglish equivalents; e.g., ?Al Riyad?, ?El Sayed?,etc.
In order to prevent the pre-processing fromremoving too many title pairs, we allow non-equalmatching if the source title is a single word.For the English-Chinese (EnCh) task, we con-vert the English letter ?x?
to ?ks?
to facilitate bet-ter matching with its Chinese targets.During testing, we pre-process test data in thesame manner, except that we do not remove non-alphabetic characters.
After the pre-processingsteps, our system proposes 10-best lists for singleword titles in the test data.
For multi-word titles,we construct 10-best lists by ranking the combina-tion scores of single words that make up the testtitles.2.2 AlignmentIn the transliteration tasks, training data consistof pairs of names written in source and targetscripts without explicit character-level alignment.In our experiments, we applied two different algo-rithms to automatically generate alignments in thetraining data.
The generated alignments providehypotheses of substring mappings in the trainingdata.
Given aligned training data, a transliterationmodel is trained to generate names in the targetlanguage given names in the source language.The M2M-aligner (Jiampojamarn et al, 2007)is based on the expectation maximization (EM)algorithm.
It allows us to create alignments be-tween substrings of various lengths.
We opti-mized the maximum substring sizes for the sourceand target based on the performance of the endtask on the development sets.
We allowed emptystrings (nulls) only on the target side.
We used theM2M-aligner for all alignment tasks, except forEnglish-Pinyin alignment.
The source code of theM2M-aligner is publicly available.2An alternative alignment algorithm is based onthe phonetic similarity of graphemes.
The key ideaof this approach is to represent each grapheme by aphoneme or a sequence of phonemes that is likelyto be represented by the grapheme.
The sequencesof phonemes on the source side and the targetside can then be aligned on the basis of phonetic2http://code.google.com/p/m2m-aligner/b a r c - l a y| | | | | | | |b a - k u r - iFigure 1: An alignment example.similarity between phonemes.
The main advan-tage of the phonetic alignment is that it requiresno training data.
We use the ALINE phoneticaligner (Kondrak, 2000), which aligns two stringsof phonemes.
The example in Figure 1 showsthe alignment of the word Barclay to its Katakanatransliteration ba-ku-ri.
The one-to-one alignmentcan then be converted to a many-to-many align-ment by grouping the Japanese phonemes that cor-respond to individual Katakana symbols.2.3 DIRECTL+We refer to our present approach to transliterationas DIRECTL+.
It is an extension of our DIRECTLsystem (Jiampojamarn et al, 2009).
It includes ad-ditional ?joint n-gram?
features that allow the dis-criminative model to correlate longer source andtarget substrings.
The additional features allowour discriminative model to train on informationthat is present in generative joint n-gram models,and additionally train on rich source-side context,transition, and linear-chain features that have beendemonstrated to be important in the transliterationtask (Jiampojamarn et al, 2010).Our model is based on an online discriminativeframework.
At each training iteration, the modelgenerates an m-best list for each given sourcename based on the current feature weights.
Thefeature weights are updated according to the gold-standard answers and the generated m-best an-swer lists using the Margin Infused Relaxed Algo-rithm (MIRA) (Crammer and Singer, 2003).
Thistraining process iterates over the training examplesuntil the model converges.
For m-best and n-gramparameters, we set m = 10 and n = 6 for all lan-guage pairs.
These parameters as well as otherswere optimized on the development sets.We trained our models directly on the datathat were provided by the organizers, with threeexceptions.
In order to improve performance,we gave special treatment to English-Korean(EnKo), English-Chinese (EnCh), and English-Hindi (EnHi).
These special cases are describedin the next section.402.4 Beyond DIRECTL+2.4.1 Korean JasoA Korean syllable can be decomposed into twoor three components called Jaso: an initial con-sonant, a middle vowel, and optionally a final con-sonant.
The Korean generation for EnKo involvesthe following three steps: (1) English-to-Jaso gen-eration, (2) correction of illegal Jaso sequences,and (3) Jaso-to-Korean conversion.In order to correct illegal Jaso sequences thatcannot be combined into Korean syllables in step2, we consider both vowel and consonant rules.A Korean vowel can be either a simple vowel ora complex vowel that combines two simple vow-els.
We can use this information in order to replacedouble vowels with one complex vowel.
We alsouse the silent consonant o (i-eung) when we needto insert a consonant between double vowels.
AKorean vowel - (eu) is most commonly insertedbetween two English consonants in transliteration.In order to resolve three consecutive consonants, itcan be placed into the most probable position ac-cording to the probability distribution of the train-ing data.2.4.2 Japanese KatakanaIn the Japanese Katakana generation task, we re-place each Katakana symbol with one or two let-ters using standard romanization tables.
This hasthe effect of expressing the target side in Latin let-ters, which facilitates the alignment.
DIRECTL+is trained on the converted data to generate the tar-get from the source.
A post-processing programthen attempts to convert the generated letters backinto Katakana symbols.
Sequences of letters thatcannot be converted into Katakana are removedfrom the output m-best lists and replaced by lowerscoring sequences that pass the back-conversionfilter.
Otherwise, there is usually a single validmapping because most Katakana symbols are rep-resented by single vowels or a consonant-vowelpair.
The only apparent ambiguity involves theletter n, which can either stand by itself or clus-ter with the following vowel letter.
We resolve theambiguity by always assuming the latter case un-less the letter n occurs at the end of the word.2.4.3 Chinese PinyinFollowing (Jiampojamarn et al, 2009), we experi-mented with converting the original Chinese char-acters to Pinyin as an intermediate representation.Pinyin is the most commonly known romanizationsystem for Standard Mandarin and many free toolsare available for converting Chinese characters toPinyin.
Its alphabet contains the same 26 lettersas English.
Each Chinese character can be tran-scribed phonetically into Pinyin.
A small percent-age of Chinese characters have multiple pronunci-ations, and are thus represented by different Pinyinsequences.
For those characters, we manually se-lected the pronunciations that are normally usedfor names.
This pre-processing step significantlyreduces the size of the target symbols: from 370distinct Chinese characters to 26 Pinyin symbols.This allows our system to produce better align-ments.We developed three models: (1) trained on theoriginal Chinese characters, (2) trained on Pinyin,and (3) the model that incorporates the phoneticalignment described in Section 2.2.
The combi-nation of the predictions of the different systemswas performed using the following simple algo-rithm (Jiampojamarn et al, 2009).
First, we rankthe individual systems according to their top-1 ac-curacy on the development set.
To obtain the top-1 prediction for each input word, we use simplevoting, with ties broken according to the rankingof the systems.
We generalize this approach tohandle n-best lists by first ordering the candidatetransliterations according to the rank assigned byeach individual system, and then similarly break-ing ties by voting and using the ranking of the sys-tems.2.4.4 Language identification for HindiBhargava and Kondrak (2010) apply support vec-tor machines (SVMs) to the task of identifyingthe language of names.
The intuition here is thatlanguage information can inform transliteration.Bhargava and Kondrak (2010) test this hypothe-sis on the NEWS 2009 English-Hindi transliter-ation data by training language identification ondata manually tagged as being of either Indian ornon-Indian origin.
It was found that splitting thedata disjointly into two sets and training separatetransliteration models yields no performance in-crease due to the decreased size of the data for themodels.We adopt this approach for the NEWS 2010task, but here we do not use disjoint splits.
In-stead, we use the SVMs to generate probabilities,and then we apply a threshold to these probabili-ties to generate two datasets.
For example, if weset the threshold to be 0.05, then we determine the41probabilities of a given name being of Indian ori-gin (phi) and of being of non-Indian origin (pen).If phi < 0.05 then the name is excluded from theIndian set, and if pen < 0.05 then the name isexcluded from the non-Indian set.
Using the twoobtained non-disjoint sets, we then train a translit-eration model for each set using DIRECTL+.Since the two sets are not disjoint, we must de-cide how to combine the two results.
Given that aname occurs in both sets, and both models providea ranked list of possible targets for that name, weobtain a combined ranking using a linear combi-nation over the mean reciprocal ranks (MRRs) ofthe two lists.
The weights used are phi and pen sothat the more likely a name is considered to be ofIndian origin, the more strongly the result from theIndian set is considered relative to the result fromthe non-Indian set.2.5 EvaluationIn the context of the NEWS 2010 MachineTransliteration Shared Task we tested our sys-tem on all twelve datasets: from English to Chi-nese (EnCh), Thai (EnTh), Hindi (EnHi), Tamil(EnTa), Bangla (EnBa), Kannada (EnKa), Ko-rean Hangul (EnKo), Japanese Katakana (EnJa),Japanese Kanji (JnJk); and, in the opposite di-rection, to English from Arabic (ArAe), Chi-nese (ChEn), and Thai (ThEn).
For all datasets,we trained transliteration models on the providedtraining and development sets without additionalresources.Table 1 shows our best results obtained on thedatasets in terms of top-1 accuracy and mean F-score.
We also include the rank in standard runsordered by top-1 word accuracy.
The EnCh re-sult presented in the table refers to the output ofthe three-system combination, using the combi-nation algorithm described in Section 2.4.3.
Therespective results for the three component EnChsystems were: 0.357, 0.360, and 0.363.
TheEnJa result in the table refers the system describedin Section 2.4.2 that applied specific treatmentto Japanese Katakana.
Based on our develop-ment results, this specific treatment improves asmuch as 2% top-1 accuracy over the language-independent model.
The EnHi system that in-corporates language identification obtained ex-actly the same top-1 accuracy as the language-independent model.
However, the EnKo systemwith Jaso correction produced the top-1 accu-Task top-1 F-score RankEnCh 0.363 0.707 2ChEn 0.137 0.740 1EnTh 0.378 0.866 2ThEn 0.352 0.861 2EnHi 0.456 0.884 1EnTa 0.390 0.891 2EnKa 0.341 0.867 2EnJa 0.398 0.791 1EnKo 0.554 0.770 1JnJk 0.126 0.426 1ArAe 0.464 0.924 1EnBa 0.395 0.877 2Table 1: Transliteration generation resultsracy of 0.554, which is a significant improvementover 0.387 achieved by the language-independentmodel.3 Transliteration miningThis section is structured as follows.
In Sec-tion 3.1, we describe the method of extractingtransliteration candidates that serves as the inputto the subsequently presented mining approaches.Two techniques for generating negative exam-ples are discussed in Section 3.2.
Our language-independent approaches to transliteration miningare described in Section 3.3, and a technique formining English-Chinese pairs is proposed in Sec-tion 3.4.
In Section 3.5, we address the issue ofoverlapping predictions.
Finally, Section 3.6 andSection 3.7 summarize our results.3.1 Extracting transliteration candidatesWe cast the transliteration mining task as a bi-nary classification problem.
That is, given a wordin the source language and a word in the targetlanguage, a classifier predicts whether or not thepair constitutes a valid transliteration.
As a pre-processing step, we extract candidate translitera-tions from the pairs of Wikipedia titles.
Word seg-mentation is performed based on sequences of oneor more spaces and/or punctuation symbols, whichinclude hyphens, underscores, brackets, and sev-eral other non-alphanumeric characters.
Apostro-phes and single quotes are not used for segmenta-tion (and therefore remain in a given word); how-ever, all single quote-like characters are convertedinto a generic apostrophe.
Once an English ti-tle and its target language counterpart have been42segmented into words, we form the candidate setfor this title as the cross product of the two setsof words after discarding any words that containfewer than two characters.After the candidates have been extracted, indi-vidual words are flagged for certain attributes thatmay be used by our supervised learner as addi-tional features.
Alternatively, the flags may serveas criteria for filtering the list of candidate pairsprior to classification.
We identify words that arecapitalized, consist of all lowercase (or all capital)letters, and/or contain one or more digits.
We alsoattempt to encode each word in the target languageas an ASCII string, and flag that word if the opera-tion succeeds.
This can be used to filter out wordsthat are written in English on both the source andtarget side, which are not transliterations by defi-nition.3.2 Generating negative training examplesThe main issue with applying a supervised learn-ing approach to the NEWS 2010 Shared Task isthat annotated task-specific data is not availableto train the system.
However, the seed pairs doprovide example transliterations, and these can beused as positive training examples.
The remainingissue is how to select the negative examples.We adopt two approaches for selecting nega-tives.
First, we generate all possible source-targetpairs in the seed data, and take as negatives thosepairs which are not transliterations but have alongest common subsequence ratio (LCSR) above0.58; this mirrors the approach used by Bergsmaand Kondrak (2007).
The method assumes thatthe source and target words are written in the samescript (e.g., the foreign word has been romanized).A second possibility is to generate all seed pair-ings as above, but then randomly select negativeexamples, thus mirroring the approach in Klemen-tiev and Roth (2006).
In this case, the source andtarget scripts do not need to be the same.
Com-pared with the LCSR technique, random samplingin this manner has the potential to produce nega-tive examples that are very ?easy?
(i.e., clearly nottransliterations), and which may be of limited util-ity when training a classifier.
On the other hand, attest time, the set of candidates extracted from theWikipedia data will include pairs that have verylow LCSR scores; hence, it can be argued that dis-similar pairs should also appear as negative exam-ples in the training set.3.3 Language-independent approachesIn this section, we describe methods for transliter-ation mining that can, in principle, be applied to awide variety of language pairs without additionalmodification.
For the purposes of the Shared Task,however, we convert all source (English) words toASCII by removing diacritics and making appro-priate substitutions for foreign letters.
This is doneto mitigate sparsity in the relatively small seed setswhen training our classifiers.3.3.1 Alignment-derived romanizationWe developed a simple method of performing ro-manization of foreign scripts.
Initially, the seed setof transliterations is aligned using the one-to-oneoption of the M2M-aligner approach (Jiampoja-marn et al, 2007).
We allow nulls on both thesource and target sides.
The resulting alignmentmodel contains pairs of Latin letters and foreignscript symbols (graphemes) sorted by their con-ditional probability.
Then, for each grapheme,we select a letter (or a null symbol) that has thehighest conditional probability.
The process pro-duces an approximate romanization table that canbe obtained without any knowledge of the targetscript.
This method of romanization was used byall methods described in the remainder of Sec-tion 3.3.3.3.2 Normalized edit distanceNormalized edit distance (NED) is a measure ofthe similarity of two strings.
We define a uniformedit cost for each of the three operations: substitu-tion, insertion, and deletion.
NED is computed bydividing the minimum edit distance by the lengthof the longer string, and subtracting the resultingfraction from 1.
Thus, the extreme values of NEDare 1 for identical strings, and 0 for strings thathave no characters in common.Our baseline method, NED+ is simply the NEDmeasure augmented with filtering of the candidatepairs described in Section 3.1.
In order to addressthe issue of morphological variants, we also fil-ter out the pairs in which the English word endsin a consonant and the foreign word ends with avowel.
With no development set provided, we setthe similarity thresholds for individual languageson the basis of the average word length in the seedsets.
The values were 0.38, 0.48, 0.52, and 0.58for Hindi, Arabic, Tamil, and Russian, respec-tively, with the last number taken from Bergsmaand Kondrak (2007).433.3.3 Alignment-based string similarityNED selects transliteration candidates when theromanized foreign strings have high characteroverlap with their English counterparts.
The mea-sure is independent of the language pair.
Thisis suboptimal for several reasons.
First of all,phonetically unrelated words can share many in-cidental character matches.
For example, theFrench word ?recettes?
and the English word?proceeds?
share the letters r,c,e,e,s as a com-mon subsequence, but the words are phoneticallyunrelated.
Secondly, many reliable, recurrent,language-specific substring matches are prevalentin true transliterations.
These pairings may or maynot involve matching characters.
NED can notlearn or adapt to these language-specific patterns.In light of these drawbacks, researchers haveproposed string similarity measures that can learnfrom provided example pairs and adapt the simi-larity function to a specific task (Ristad and Yiani-los, 1998; Bilenko and Mooney, 2003; McCallumet al, 2005; Klementiev and Roth, 2006).One particularly successful approach is byBergsma and Kondrak (2007), who use discrim-inative learning with an improved feature repre-sentation.
The features are substring pairs that areconsistent with a character-level alignment of thetwo strings.
This approach strongly improved per-formance on cognate identification, while varia-tions of it have also proven successful in transliter-ation discovery (Goldwasser and Roth, 2008).
Wetherefore adopted this approach for the translitera-tion mining task.We produce negative training examples usingthe LCSR threshold approach described in Sec-tion 3.2.
For features, we extract from the alignedword pairs all substring pairs up to a maximumlength of three.
We also append characters mark-ing the beginning and end of words, as describedin Bergsma and Kondrak (2007).
For our clas-sifier, we use a Support Vector Machine (SVM)training with the very efficient LIBLINEAR pack-age (Fan et al, 2008).
We optimize the SVM?sregularization parameter using 10-fold cross vali-dation on the generated training data.
At test time,we apply our classifier to all the transliterationcandidates extracted from the Wikipedia titles,generating transliteration pairs whenever there isa positive classification.3.3.4 String kernel classifierThe alignment-based classifier described in thepreceding section is limited to using substring fea-tures that are up to (roughly) three or four lettersin length, due to the combinatorial explosion in thenumber of unique features as the substring lengthincreases.
It is natural to ask whether longer sub-strings can be utilized to learn a more accurate pre-dictor.This question inspired the development of a sec-ond SVM-based learner that uses a string kernel,and therefore does not have to explicitly repre-sent feature vectors.
Our kernel is a standard n-gram (or spectrum) kernel that implicitly embedsa string in a feature space that has one co-ordinatefor each unique n-gram (see, e.g., (Shawe-Taylorand Cristianini, 2004)).
Let us denote the alphabetover input strings as A.
Given two input strings xand x?, this kernel function computes:k(x, x?)
=?s?An#(s, x)#(s, x?
)where s is an n-gram and #(a, b) counts the num-ber of times a appears as a substring of b.An extension of the n-gram kernel that we em-ploy here is to consider all n-grams of length1 ?
n ?
k, and weight each n-gram as a func-tion of its length.
In particular, we specify a value?
and weight each n-gram by a factor of ?n.
Weimplemented this kernel in the LIBSVM softwarepackage (Chang and Lin, 2001).
Optimal valuesfor k, ?, and the SVM?s regularization parame-ter were estimated for each dataset using 5-foldcross-validation.
The values of (k, ?)
that we ul-timately used were: EnAr (3, 0.8), EnHi (8, 0.8),EnRu (5, 1.2), and EnTa (5, 1.0).Our input string representation for a candidatepair is formed by first aligning the source and tar-get words using M2M-aligner (Jiampojamarn etal., 2007).
Specifically, an alignment model istrained on the seed examples, which are subse-quently aligned and used as positive training ex-amples.
We then generate 20K negative examplesby random sampling (cf.
Section 3.2) and applythe alignment model to this set.
Not all of these20K word pairs will necessarily be aligned; werandomly select 10K of the successfully alignedpairs to use as negative examples in the trainingset.Each aligned pair is converted into an ?align-ment string?
by placing the letters that appear in44Word pair zubtsov z u bovAligned pair z|u|b|t|s|o|v| z|u|b|| |o|v|Align?t string zz|uu|bb|t|s |oo|vvTable 2: An example showing how an alignmentstring (the input representation for the string ker-nel) is created from a word pair.the same position in the source and target next toone another, while retaining the separator charac-ters (see Table 2).
We also appended beginningand end of word markers.
Note that no romaniza-tion of the target words is necessary for this pro-cedure.At test time, we apply the alignment model tothe candidate word pairs that have been extractedfrom the train data, and retain all the successfullyaligned pairs.
Here, M2M-aligner also acts as afilter, since we cannot form alignment strings fromunaligned pairs ?
these yield negative predictionsby default.
We also filter out pairs that met any ofthe following conditions: 1) the English word con-sists of all all capital or lowercase letters, 2) thetarget word can be converted to ASCII (cf.
Sec-tion 3.1), or 3) either word contains a digit.3.3.5 Generation-based approachIn the mining tasks, we are interested in whether acandidate pair (x, y) is a transliteration pair.
Oneapproach is to determine if the generated translit-erations of a source word y?
= ?
(x) and a targetword x?
= ?
(y) are similar to the given candi-date pair.
We applied DIRECTL+ to the miningtasks by training transliteration generation modelson the provided seed data in forward and back-ward transliteration directions, creating ?
(x) and?
(y) models.
We now define a transliterationscore function in Eq.
1.
N(x?, x) is the normal-ized edit distance between string x?
and x, and w1and w2 are combination weights to favor forwardand backward transliteration models.S(x, y) = w1 ?
N(y?, y) + w2 ?
N(x?, x)w1 + w2(1)A candidate pair is considered a transliterationpair if its S(x, y) > ?
.
Ideally, we would liketo optimize these parameters, ?, w1, w2 based ona development set for each language pair.
Unfor-tunately, no development sets were provided forthe Shared Task.
Therefore, following Bergsmaand Kondrak (2007), we adopt the threshold of?
= 0.58.
We experimented with three sets of val-ues for w1 and w2: (1, 0), (0.5, 0.5), and (0, 1).Our final predictions were made using w0 = 0and w1 = 1, which appeared to produce the bestresults.
Thus, only the backward transliterationmodel was ultimately employed.3.4 English-Chinese string matchingDue to the fact that names transliterated into Chi-nese consist of multiple Chinese characters andthat the Chinese text provided in this shared taskis not segmented, we have to adopt a different ap-proach to the English-Chinese mining task (Unlikemany other languages, there are no clear bound-aries between Chinese words).
We first train ageneration model using the seed data and then ap-ply a greedy string matching algorithm to extracttransliteration pairs.The generation model is built using the discrim-inative training framework described in (Jiampoja-marn et al, 2008).
Two models are learned: oneis trained using English and Chinese characters,while the other is trained on English and Pinyin (astandard phonetic representation of Chinese char-acters).
In order to mine transliteration pairs fromWikipedia titles, we first use the generation modelto produce transliterations for each English tokenon the source side as both Chinese characters andPinyin.
The generated Chinese characters are ul-timately converted to Pinyin during string match-ing.
We also convert all the Chinese characters onthe target side to their Pinyin representations whenperforming string matching.The transliteration pairs are then mined by com-bining two different strategies.
First of all, we ob-serve that most of the titles that contain a separa-tion symbol ?
?
?
on the target side are translit-erations.
In this case, the number of tokens onboth sides is often equal.
Therefore, the miningtask can be formulated as a matching problem.We use a competitive linking approach (Melamed,2000) to find the best match.
First, we selectlinks between all possible pairs if similarity ofstrings on both sides is above a threshold (0.6 ?length(Pinyin)).
We then greedily extract thepairs with highest similarity until the number ofunextracted segments on either side becomes zero.The problem becomes harder when there is noindication of word segmentation for Chinese.
In-stead of trying to segment the Chinese charactersfirst, we use an incremental string matching strat-45egy.
For each token on the source side, the algo-rithm calculates its similarity with all possible n-grams (2 ?
n ?
L) on the target side, where Lis the length of the Chinese title (i.e., the numberof characters).
If the similarity score of n-gramwith the highest similarity surpasses a threshold(0.5 ?
length(Pinyin)), the n-gram sequence isproposed as a possible transliteration for the cur-rent source token.3.5 Resolving overlapping predictionsGiven a set of candidate word pairs that have beenextracted from a given Wikipedia title according tothe procedure described in Section 3.1, our clas-sifiers predict a class label for each pair inde-pendently of the others.
Pairs that receive neg-ative predictions are discarded immediately andare never reported as mined pairs.
However, itis sometimes necessary to arbitrate between pos-itive predictions, since it is possible for a classifierto mark as transliterations two or more pairs thatinvolve the same English word or the same targetword in the title.
Clearly, mining multiple overlap-ping pairs will lower the system?s precision, sincethere is (presumably) at most one correct translit-eration in the target language version of the titlefor each English word.3Our solution is to apply a greedy algorithm thatsorts the word pair predictions for a given titlein descending order according to the scores thatwere assigned by the classifier.
We make one passthrough the sorted list and report a pair of words asa mined pair unless the English word or the targetlanguage word has already been reported (for thisparticular title).43.6 ResultsIn the context of the NEWS 2010 Shared Taskon Transliteration Generation we tested our sys-tem on all five data sets: from English to Rus-sian (EnRu), Hindi (EnHi), Tamil (EnTa), Arabic(EnAr), and Chinese (EnCh).
The EnCh set dif-fers from the remaining sets in the lack of transpar-ent word segmentation on the Chinese side.
Therewere no development sets provided for any of thelanguage pairs.3On the other hand, mining all such pairs might improverecall.4A bug was later discovered in our implementation of thisalgorithm, which had failed to add the words in a title?s firstmined pair to the ?already reported?
list.
This sometimescaused up to two additional mined pairs per title to be re-ported in the prediction files that were submitted.Task System F P REnRu NED+ .875 .880 .869BK-2007 .778 .684 .902StringKernel* .811 .746 .889DIRECTL+ .786 .778 .795EnHi NED+ .907 .875 .941BK-2007 .882 .883 .880StringKernel .924 .954 .895DIRECTL+ .904 .945 .866EnTa NED+ .791 .916 .696BK-2007 .829 .808 .852StringKernel .914 .923 .906DIRECTL+ .801 .919 .710EnAr NED+ .800 .818 .783BK-2007 .816 .834 .798StringKernel* .827 .917 .753DIRECTL+ .742 .861 .652EnCh GreedyMatch .530 .698 .427DIRECTL+ .009 .045 .005Table 3: Transliteration mining results.
An aster-isk (*) indicates an unofficial result.Table 3 shows the results obtained by our var-ious systems on the final test sets, measured interms of F-score (F), precision (P), and recall(R).
The systems referred to as NED+, BK-2007,StringKernel, DIRECTL+, and GreedyMatch aredescribed in Section 3.3.2, Section 3.3.3, Sec-tion 3.3.4, Section 3.3.5, and Section 3.4 respec-tively.
The runs marked with an asterisk (*)were produced after the Shared Task deadline, andtherefore are not included in the official results.3.7 DiscussionNo fixed ranking of the four approaches emergesacross the four alphabetic language pairs (all ex-cept EnCh).
However, StringKernel appears to bethe most robust, achieving the highest F-score onthree language pairs.
This suggests that longersubstring features are indeed useful for classifyingcandidate transliteration pairs.
The simple NED+method is a clear winner on EnRu, and obtains de-cent scores on the remaining alphabetic languagepairs.
The generation-based DIRECTL+ approachranks no higher than third on any language pair,and it fails spectacularly on EnCh because of theword segmentation ambiguity.Finally, we observe that there are a number ofcases where the results for our discriminativelytrained classifiers, BK-2007 and StringKernel, are46not significantly better than those of the simpleNED+ approach.
We conjecture that automaticallygenerating training examples is suboptimal for thistask.
A more effective strategy may be to filter allpossible word pairs in the seed data to only thosewith NED above a fixed threshold.
We would thenapply the same threshold to the Wikipedia candi-dates, only passing to the classifier those pairs thatsurpass the threshold.
This would enable a bettermatch between the training and test operation ofthe system.4 ConclusionThe results obtained in the context of the NEWS2010 Machine Transliteration Shared Task con-firm the effectiveness of our discriminative ap-proaches to transliteration generation and mining.AcknowledgmentsThis research was supported by the Alberta Inge-nuity Fund, Informatics Circle of Research Excel-lence (iCORE), and the Natural Sciences and En-gineering Research Council of Canada (NSERC).ReferencesShane Bergsma and Grzegorz Kondrak.
2007.Alignment-based discriminative string similarity.
InProc.
ACL.Aditya Bhargava and Grzegorz Kondrak.
2010.
Lan-guage identification of names with SVMs.
In Proc.NAACL-HLT.Mikhail Bilenko and Raymond J. Mooney.
2003.Adaptive duplicate detection using learnable stringsimilarity measures.
In Proc.
KDD.Chih-Chung Chang and Chih-Jen Lin.
2001.
LIB-SVM: a library for support vector machines.Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Koby Crammer and Yoram Singer.
2003.
Ultracon-servative online algorithms for multiclass problems.Journal of Machine Learning Research, 3:951?991.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLIN-EAR: A library for large linear classification.
JMLR,9:1871?1874.Dan Goldwasser and Dan Roth.
2008.
Transliterationas constrained optimization.
In Proc.
EMNLP.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand Hidden Markov Models to letter-to-phonemeconversion.
In Proc.
HLT-NAACL.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint processing and discriminativetraining for letter-to-phoneme conversion.
In Proc.ACL.Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,Kenneth Dwyer, and Grzegorz Kondrak.
2009.
Di-recTL: a language-independent approach to translit-eration.
In NEWS ?09: Proceedings of the 2009Named Entities Workshop: Shared Task on Translit-eration, pages 28?31.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2010.
Integrating joint n-gram featuresinto a discriminative training framework.
In Proc.NAACL-HLT.Alexandre Klementiev and Dan Roth.
2006.
Namedentity transliteration and discovery from multilin-gual comparable corpora.
In Proc.
HLT-NAACL.Grzegorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In Proc.
NAACL,pages 288?295.Andrew McCallum, Kedar Bellare, and FernandoPereira.
2005.
A conditional random field fordiscriminatively-trained finite-state string edit dis-tance.
In Proc.
UAI.I.
Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learn-ing string-edit distance.
IEEE Trans.
Pattern Analy-sis and Machine Intelligence, 20(5).John Shawe-Taylor and Nello Cristianini.
2004.
Ker-nel Methods for Pattern Analysis.
Cambridge Uni-versity Press.47
