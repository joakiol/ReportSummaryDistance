Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 922?931,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsInflection Generation as Discriminative String TransductionGarrett Nicolai?Colin Cherry?Grzegorz Kondrak?
?Department of Computing Science?National Research Council CanadaUniversity of Alberta 1200 Montreal RoadEdmonton, AB, T6G 2E8, Canada Ottawa, ON, K1A 0R6, Canada{nicolai,gkondrak}@ualberta.ca Colin.Cherry@nrc-cnrc.gc.caAbstractWe approach the task of morphological inflec-tion generation as discriminative string trans-duction.
Our supervised system learns to gen-erate word-forms from lemmas accompaniedby morphological tags, and refines them by re-ferring to the other forms within a paradigm.Results of experiments on six diverse lan-guages with varying amounts of training datademonstrate that our approach improves thestate of the art in terms of predicting inflectedword-forms.1 IntroductionWord-forms that correspond to the same lemma canbe viewed as paradigmatically related instantiationsof the lemma.
For example, take, takes, taking,took, and taken are the word-forms of the lemmatake.
Many languages have complex morphologywith dozens of different word-forms for any givenlemma: verbs inflect for tense, mood, and person;nouns can vary depending on their role in a sen-tence, and adjectives agree with the nouns that theymodify.
For such languages, many forms will not beattested even in a large corpus.
However, differentlemmas often exhibit the same inflectional patterns,called paradigms, which are based on phonological,semantic, or morphological criteria.
The paradigmof a given lemma can be identified and used to gen-erate unseen forms.Inflection prediction has the potential to improveStatistical Machine Translation (SMT) into mor-phologically complex languages.
In order to ad-dress data sparsity in the training bitext, Clifton andSarkar (2011) and Fraser et al (2012) reduce diverseFigure 1: A partial inflection table for the German verbatmen ?to breathe?
in Wiktionary.inflected forms in the target language into the cor-responding base forms, or lemmas.
At test time,they predict an abstract inflection tag for each trans-lated lemma, which is then transformed into a properword-form.
Unfortunately, hand-crafted morpho-logical generators such as the ones that they use forthis purpose are available only for a small number oflanguages, and are expensive to create from scratch.The supervised inflection generation models that weinvestigate in this paper can instead be trained onpublicly available inflection tables.The task of an inflection generator is to producean inflected form given a base-form (e.g., an in-finitive) and desired inflection, which can be spec-ified as an abstract inflectional tag.
The generator istrained on a number of inflection tables, such as theone in Figure 1, which enumerate inflection formsfor a given lemma.
At test time, the generator pre-dicts inflections for previously unseen base-forms.For example, given the input atmen + 1SIA, wherethe tag stands for ?first person singular indicativepreterite,?
it should output atmete.Recently, Durrett and DeNero (2013) and Ahlberg922et al (2014) have proposed to model inflection gen-eration as a two-stage process: an input base-form isfirst matched with rules corresponding to a paradigmseen during training, which is then used to gen-erate all inflections for that base-form simultane-ously.
Although their methods are quite different,both systems account for paradigm-wide regulari-ties by creating rules that span all inflections withina paradigm.
We analyze both approaches in greaterdetail in Section 2.In this paper, we approach the task of supervisedinflection generation as discriminative string trans-duction, in which character-level operations are ap-plied to transform a lemma concatenated with an in-flection tag into the correct surface word-form.
Wecarefully model the transformations carried out for asingle inflection, taking into account source charac-ters surrounding a rule, rule sequence patterns, andthe shape of the resulting inflected word.
To takeadvantage of paradigmatic regularities, we performa subsequent reranking of the top n word-forms pro-duced by the transducer.
In the reranking model, softconstraints capture similarities between different in-flection slots within a table.
Where previous workleveraged large, rigid rules to span paradigms, ourwork is characterized by small, flexible rules thatcan be applied to any inflection, with features de-termining what rule sequence works best for eachpairing of a base-form with an inflection.Since our target application is machine transla-tion, we focus on maximizing inflection form ac-curacy, rather than complete table accuracy.
Unlikeprevious work, which aims at learning linguistically-correct paradigms from crowd-sourced data, our ap-proach is designed to be robust with respect to in-complete and noisy training data, which could be ex-tracted from digital lexicons and annotated corpora.We conduct a series of experiments which demon-strate that our method can accurately learn complexmorphological rules in languages with varying lev-els of morphological complexity.
In each experi-ment we either match or improve over the state ofthe art reported in previous work.
In addition to pro-viding a detailed comparison of the available inflec-tion prediction systems, we also contribute four newinflection datasets composed of Dutch and Frenchverbs, and Czech verbs and nouns, which are madeavailable for future research.2 Inflection generationDurrett and DeNero (2013) formulate the specifictask of supervised generation of inflected forms fora given base-form based on a large number of train-ing inflection tables, while Ahlberg et al (2014)test their alternative method on the same Wiktionarydataset.
In this section, we compare their work toour approach with respect to the following three sub-tasks:1. character-wise alignment of the word-forms inan inflection table (Section 2.1),2. extraction of rules from aligned forms (2.2),3. matching of rules to new base-forms (2.3).2.1 Table alignmentThe first step in supervised paradigm learning isthe alignment of related inflected forms in a ta-ble.
Though technically a multiple-alignment prob-lem, this can also be addressed by aligning eachinflected form to a base-form.
Durrett & DeNerodo exactly this, aligning each inflection to the basewith a paradigm-aware, position-dependent edit dis-tance.
Ahlberg et al use finite-state-automata toimplement a multiple longest-common-subsequence(LCS) alignment, avoiding the use of an explicitbase-form.
Both systems leverage the intuition thatcharacter alignment is mostly a problem of aligningthose characters that remain unchanged throughoutthe inflection table.Our alignment approach differs from previouswork in that we use an EM-driven, many-to-manyaligner.
Instead of focusing on unchanged charac-ters within a single paradigm, we look for smallmulti-character operations that have statistical sup-port across all paradigms.
This includes operationsthat simply copy their source into the target, leavingthe characters unchanged.2.2 Rule extractionThe second step involves transforming the characteralignments into inflection rules.
Both previous ef-forts begin addressing this problem in the same way:by finding maximal, contiguous spans of changedcharacters, in the base-form for Durrett & DeNero,and in the aligned word-forms for Ahlberg et alGiven those spans, the two methods diverge quitesubstantially.
Durrett & DeNero extract a rule for923a)?
s?
c?
h?
l?
i?
c?
h?
e?
n?e?s?
c?
h?
l?
i?
c?
h?
e?e?s?
c?
h?
l?
i?
c?
h?g?
e?
s?
c?
h?
l?
i?
c?
h?
e?
n?$?
x1?
x2?
en$?e?$?
x1?
x2?
e$?e?$?
x1?
x2?
$?$ge?
x1?
x2?
en$?$?$?$?$ge?en$?e$?$?en$?b)?
c)?d)?
e?e?e?
en$?e$?en$?$?s?s?c?c?h?h?l?l?$?$ge?e?e?en$?en$?i?i?Figure 2: Competing strategies for rule extraction: (a) analigned table; (b) a table-level rule; (c) vertical rules;(d) atomic rules.
$ is a word boundary marker.each changed span, with the rule specifying trans-formations to perform for each inflection.
Ahlberg etal.
instead replace each unchanged span with a vari-able, creating a single rule that specifies completeinflections for the entire table.
The latter approachcreates larger rules, which are easier to interpret fora linguist, but are less flexible, and restrict informa-tion sharing across paradigms.We move in the opposite direction by extractinga rule for each minimal, multi-character transforma-tion identified by our aligner, with no hard constrainton what rules travel together across different inflec-tions.
We attempt to learn atomic character transfor-mations, which extends the flexibility of our rules atthe cost of reduced interpretability.The differences in rule granularity are illustratedon the German verb schleichen ?to sneak?
in Fig-ure 2.
The single rule of Ahlberg et al comprisesthree vertical rules of Durrett & DeNero, which inturn correspond to eleven atomic rules in our system.Note that this is a simplification, as alignments andword boundary markers vary across the three sys-tems.2.3 Rule selectionThe final component of an inflection generation sys-tem is a mechanism to determine what rules to ap-ply to a new base-form, in order to generate theinflected forms.
The strongest signal for this taskcomes from learning how the training base-formsuse the rules.
With their highly restrictive rules,Ahlberg et al can afford a simple scheme, keepingan index that associates rules with base-forms, andemploying a longest suffix match against this indexto assign rules to new base-forms.
They also usethe corpus frequency of the inflections that wouldbe created by their rules as a rule-selection feature.Durrett & DeNero have much more freedom, bothin what rules can be used together and in whereeach rule can be applied.
Therefore, they employa more complex semi-Markov model to assign rulesto spans of the base-form, with features character-izing the n-gram character context surrounding thesource side of each rule.Since our rules provide even greater flexibility,we model rule application very carefully.
Like Dur-rett & DeNero, we employ a discriminative semi-Markov model that considers source character con-text, and like Ahlberg et al, we use a corpus to re-evaluate predictions.
In addition, we model rule se-quences, and the character-shape of the resulting in-flected form.
Note that our rules are much moregeneral than those of our predecessors, which makesit easy to get statistical support for these additionalfeatures.
Finally, since our rules are not bound byparadigm structure, we employ a reranking step toaccount for intra-paradigm regularities.3 Discriminative TransductionIn this section, we describe the details of ourapproach, including the affix representation, thestring alignment and transduction, and the paradigmreranking.3.1 Affix representationOur inflection generation engine is a discriminativesemi-Markov model, similar to a monotonic phrase-based decoder from machine translation (Zens andNey, 2004).
This system cannot insert characters,except as a part of a phrasal substitution, so wheninflecting a base form, we add an abstract affix rep-resentation to both provide an insertion site and toindicate the desired inflection.Abstract tags are separated from their lemmaswith a single ?+?
character.
Marking the morphemeboundary in such a way allows the transducer to gen-924eralize the context of a morpheme boundary.
Forexample, the third person singular indicative presentof the verb atmen is represented as atmen+3SIE.
Weuse readable tags throughout this paper, but they arepresented to the transducer as indivisible units; itcannot translate them character-by-character.German and Dutch past participles, as well as sev-eral Czech inflections, are formed by circumfixa-tion, a special process of simultaneous prefixationand suffixation.
We represent such inflections withseparate copies of the circumfix tag before and afterthe lemma.
For example, the past participle gebracht?brought?
is represented as PPL+bringen+PPL.
Inthe absence of language-specific information regard-ing the set of inflections that involve circumfixation,the system can learn to transduce particular affixesinto empty strings.During development, we experimented with an al-ternative method, in which affixes are represented bya default allomorph.
Allomorphic representationshave the potential advantage of reducing the com-plexity of transductions by the virtue of being sim-ilar to the correct form of the affix.
However, wefound that allomorphic affixes tend to obfuscate dif-ferences between distinct inflections, so we decidedto employ abstract tags instead.3.2 String transductionWe perform string transduction adapting the toolDIRECTL+, originally designed for grapheme-to-phoneme conversion (Jiampojamarn et al, 2010).DIRECTL+ is a feature-rich, discriminative charac-ter transducer, which searches for a model-optimalsequence of character transformation rules for its in-put.
The core of the engine is a dynamic program-ming algorithm capable of transducing many con-secutive characters in a single operation, also knownas a semi-Markov model.
Using a structured versionof the MIRA algorithm (McDonald et al, 2005),training attempts to assign weights to each featureso that its linear model separates the gold-standardderivation from all others in its search space.DIRECTL+ uses a number of feature templates toassess the quality of a rule: source context, targetn-gram, and joint n-gram features.
Context featuresconjoin the rule with indicators for all source char-acter n-grams within a fixed window of where therule is being applied.
Target n-grams provide indi-cators on target character sequences, describing theshape of the target as it is being produced, and mayalso be conjoined with our source context features.Joint n-grams build indicators on rule sequences,combining source and target context, and memoriz-ing frequently-used rule patterns.
Durrett & DeNeroalso use source context features, but we are the firstgroup to account for features that consider rule se-quences or target word shape.Following Toutanova and Cherry (2009), wemodify the out-of-the-box version of DIRECTL+ byimplementing an abstract copy feature that indicateswhen a rule simply copies its source characters intothe target, e.g.
p ?
p. The copy feature has the ef-fect of biasing the transducer towards preserving thebase-form within the inflected form.In addition to the general model that is trainedon all inflected word-forms, we derive tag-specificmodels for each type of inflection.
Development ex-periments showed the general model to be slightlymore accurate overall, but we use both types of mod-els in our reranker.3.3 String alignmentDIRECTL+ training requires a set of aligned pairsof source and target strings.
The alignments accountfor every input and output character without the useof insertion.
Derivations that transform the inputsubstrings into the desired output substrings are thenextracted from the alignments.We induce the alignments by adapting the M2Maligner of (Jiampojamarn et al, 2007), which usesExpectation-Maximization to maximize the jointlikelihood of its input under a pairwise alignmentscheme.
Previous work creates alignments basedupon entire inflection tables, while ours considerseach inflection paired with its base form indepen-dently.
M2M goes beyond linking single charactersby aligning entire substrings instead.
In practice, thebase-form serves as a pivot for the entire inflectiontable, leading to consistent multiple alignments.We modify the M2M aligner to differentiate be-tween stems and affixes.
The alignments betweenstem letters rarely require more than a 2-2 align-ment.
A single tag, however, must align to an en-tire affix, which may be composed of four or moreletters.
The distinction allows us to set different sub-string length limits for the two types.925In order to encourage alignments between iden-tical letters, we augment the training set by pair-ing each inflected form with itself.
In addition, wemodify the aligner to generalize the identity align-ments into a single operation, which corresponds tothe copy feature described in Section 3.2.3.4 RerankingMorphological processes such as stem changes tendto be similar across different word-forms of the samelemma.
In order to take advantage of such paradig-matic consistency, we perform a reranking of the n-best word-forms generated by DIRECTL+.
The cor-rect form is sometimes included in the n-best list,but with a lower score than an incorrect form.
Wepropose to rerank such lists on the basis of featuresextracted from the 1-best word-forms generated forother inflection slots, the majority of which are typ-ically correct.We perform reranking with the LiblinearSVM (Fan et al, 2008), using the method ofJoachims (2002).
An initial inflection table, createdto generate reranking features, is composed of1-best predictions from the general model.
For eachinflection, we then generate lists of candidate formsby taking the intersection of the n-best lists fromthe general and the tag-specific models.In order to generate features from our initial in-flection table, we make pairwise comparisons be-tween a prediction and each form in the initial ta-ble.
We separate stems from affixes using the align-ment.
Our three features indicate whether the com-pared forms share the same stem, the same affix, andthe same surface word-form, respectively.
We gen-erate a feature vector for each aligned pair of relatedword-forms, such as past participle vs. present par-ticiple.
In addition, we include as features the confi-dence scores generated by both models.Two extra features are designed to leverage a largecorpus of raw text.
A binary indicator feature firesif the generated form occurs in the corpus.
In orderto model the phonotactics of the language, we alsoderive a 4-gram character language model from thesame corpus, and include as a feature the normalizedlog-likelihood of the predicted form.Language / POS Set Base forms Infl.German Nouns DE-N 2764 8German Verbs DE-V 2027 27Spanish Verbs ES-V 4055 57Finnish Nouns FI-N 6400128Finnish Verbs FI-V 7249 53Dutch Verbs NL-V 11200 9French Verbs FR-V 6957 48Czech Nouns CZ-N 21830 17Czech Verbs CZ-V 4435 54Table 1: The number of base forms and inflections foreach dataset.4 ExperimentsWe perform five experiments that differ with respectto the amount and completeness of training data,and whether the training is performed on individualword-forms or entire inflection tables.
We follow theexperimental settings established by previous work,as much as possible.The parameters of our transducer and aligner wereestablished on a development set of German nounsand verbs, and kept fixed in all experiments.
Welimit stem alignments to 2-2, affix alignments to 2-4, source context to 8 characters, joint n-grams to 5characters, and target Markov features to 2 charac-ters.4.1 Inflection dataWe adopt the Wiktionary inflection data made avail-able by Durrett and DeNero (2013), with the sametraining, development, and test splits.
The develop-ment and test sets contain 200 inflection tables each.and the training sets consist of the remaining data.Table 1 shows the total number of tables in each lan-guage set.
We convert their inflectional informationto abstract tags for input to our transducer.We augment the original five datasets with fournew sets: Dutch verbs from the CELEX lexicaldatabase (Baayen et al, 1995), French verbs fromVerbiste, an online French conjugation dictionary2,and Czech nouns and verbs from the Prague Depen-dency Treebank (B?ohmov?a et al, 2003).
For each of1Durrett & DeNero report 40589 forms, but only use 6000for training, and 200 each for development and testing2http://perso.b2b2c.ca/sarrazip/dev/verbiste.html926Case Singular PluralNominative Buch B?ucherAccusative Buch B?ucherDative Buch B?uchernGenitive Buches B?ucherTable 2: All word-forms of the German noun Buch.these sets, the training data is restricted to 80% ofthe inflection tables listed in Table 1, with 10% eachfor development and testing.
Each lemma inflects toa finite number of forms that vary by part-of-speechand language (Table 1); German nouns inflect fornumber and case (Table 2), while French, Spanish,German, and Dutch verbs inflect for number, person,mood, and tense.We extract Czech data from the Prague Depen-dency Treebank, which is fully annotated for mor-phological information.
This dataset contains fewcomplete inflection tables, with many lemmas rep-resented by a small number of word-forms.
For thisreason, it is only suitable for one of our experiments,which we describe in Section 4.5.Finnish has a morphological system that is un-like any of the Indo-European languages.
Thereare 15 different grammatical cases for nouns andadjectives, while verbs make a number of distinc-tions, such as conditional vs. potential, and affir-mative vs. negative.
We derive separate models fortwo noun classes (singular and plural), and six verbclasses (infinitive, conditional, potential, participle,imperative, and indicative).
This is partly motivatedby the number of individual training instances forFinnish, which is much larger than the other lan-guages, but also to take advantage of the similaritieswithin classes.For the reranker experiments, we use the appro-priate Wikipedia language dump.
The number of to-kens in the corpora is approximately 77M for Czech,200M for Dutch, 6M for Finnish, 425M for French,550M for German, and 400M for Spanish.4.2 Individual inflectionsIn the first experiment, we test the accuracy of ourbasic model which excludes our reranker, and there-fore has no access to features based on inflection ta-bles or corpus counts.
Table 3 compares our resultsSet DDN Ours 10-bestDE-V 94.8 97.5 99.8DE-N 88.3 88.6 98.6ES-V 99.6 99.8 100FI-V 97.2 98.1 99.9FI-N 92.1 93.0 99.0NL-V 90.5* 96.1 99.4FR-V 98.8* 99.2 99.7Table 3: Prediction accuracy of models trained and testedon individual inflections.against the Factored model of Durrett & DeNero(DDN), which also makes an independent predictionfor each inflection.
The numbers marked with an as-terisk were not reported in the original paper, butwere generated by running their publicly-availablecode on our new Dutch and French datasets.
Forthe purpose of quantifying the effectiveness of ourreranker, we also include the percentage of correctanswers that appear in our 10-best lists.Our basic model achieves higher accuracy on alldatasets, which shows that our refined transduc-tion features are consistently more effective than thesource-context features employed by the other sys-tem.
Naturally, their system, as well as the system ofAhlberg et al, is intended for whole-table scenarios,which we test next.4.3 Complete paradigmsIn this experiment, we assume the access to com-plete inflection tables, as well as to raw corpora.
Wecompare our reranking system to the Joint modelof Durrett & DeNero (DDN), which is trained oncomplete tables, and the full model of Ahlberg etal.
(AFH), which is trained on complete tables, andmatches forms to rules with aid of corpus counts.Again, we calculated the numbers marked with anasterisk by running the respective implementationson our new datasets.The results of the experiment are shown in Ta-ble 4.
Our reranking model outperforms the Jointmodel of DDN on all sets, and the full model ofAFH on most verb sets.
Looking across tables to Ta-ble 3, we can see that reranking improves upon ourindependent model on 5 out of 7 sets, and is equiv-alent on the remaining two sets.
However, accord-927Set DDN AFH OursDE-V 96.2 97.9 97.9DE-N 88.9 91.8 89.9ES-V 99.7 99.6 99.9FI-V 96.4 96.6 98.1FI-N 93.4 93.8 93.6NL-V 94.4* 87.7* 96.6FR-V 96.8* 98.1* 99.2Table 4: Individual form accuracy of models trained oncomplete inflection tables.ing to single-form accuracy, neither our system norDDN benefits too much from joint predictions.
Ta-ble 5 shows the same results evaluated with respectto complete table accuracy.4.4 Incomplete paradigmsIn this experiment, we consider a scenario where,instead of complete tables, we have access to somebut not all of the possible word-forms.
This couldoccur for example if we extracted our training datafrom a morphologically annotated corpus.
We sim-ulate this by only including in our training tablesthe forms that are observed in the corresponding rawcorpus.
We then test our ability to predict the sametest forms as in the previous experiments, regardlessof whether or not they were observed in the corpus.We also allow a small held-out set of complete ta-bles, which corresponds to the development set.
ForDurrett & DeNero?s method, we include this held-out set in the training data, while for our system, weuse it to train the reranker.The Joint method of DDN and the methods ofAFH are incapable of training on incomplete tables,and thus, we can only compare our results againstthe Factored model of DDN.
However, unlike theirFactored model, we can then still take advantage ofparadigmatic and corpus information, by applyingour reranker to the predictions made by our simplemodel.The results are shown in Table 6, where we re-fer to our independent model as Basic, and to ourreranked system as Reranked.
The latter outper-forms DDN on all sets.
Furthermore, even withonly partial tables available during training, rerank-ing improves upon our independent model in everySet DDN AFH OursDE-V 85.0 76.5 90.5DE-N 79.5 82.0 76.5ES-V 95.0 98.0 99.0FI-V 87.5 92.5 94.5FI-N 83.5 88.0 82.0NL-V 79.5* 37.7* 82.1FR-V 92.1* 96.0* 97.1Table 5: Complete table accuracy of models trained oncomplete inflection tables.case.4.5 Partial paradigmsWe run a separate experiment for Czech, as the datais substantially less comprehensive than for the otherlanguages.
Although the number of 13.0% observednoun forms is comparable to the Finnish case, thepercentages in Table 6 refer only to the training set:the test and held-out sets are complete.
For Czech,the percentage includes the testing and held-out sets.Thus, the method of Durrett & DeNero and ourreranker have access to less training data than in theexperiment of Section 4.4.The results of this experiment are shown in Ta-ble 7.
Our Basic model outperforms DDN for bothnouns and verbs, despite training on less data.
How-ever, reranking actually decreases the accuracy ofour system on Czech nouns.
It appears that thereranker is adversely affected by the lack of com-plete target paradigms.
We leave the full investiga-tion into the effectiveness of the reranker on incom-plete data to future work.4.6 Seed paradigmsDreyer and Eisner (2011) are particularly concernedwith situations involving limited training data, andapproach inflection generation as a semi-supervisedtask.
In our last experiment we follow their exper-imental setup, which simulates the situation wherewe obtain a small number of complete tables froman expert.
We use the same training, development,and test splits to test our system.
Due to the natureof our model, we need to set aside a hold-out set forreranking.
Thus, rather than training on 50 and 100tables, we train on 40 and 80, but compare the results928Set % of Total DDN OursBasic RerankedDE-V 69.2 90.2 96.2 97.9DE-N 92.7 88.3 88.4 89.8ES-V 36.1 97.1 95.9 99.6FI-V 15.6 73.8 78.7 85.6FI-N 15.2 71.6 78.2 80.4DU-V 50.5 89.8 94.9 96.0FR-V 27.6 94.6 96.6 98.9Table 6: Prediction accuracy of models trained on ob-served forms.with the models trained on 50 and 100, respectively.For reranking, we use the same German corpus asin our previous experiments, but limited to the first10M words.The results are shown in Table 8.
When trainedon 50 seed tables, the accuracy of our models iscomparable to both the basic model of Dreyer andEisner (DE) and the Factored model of DDN, andmatches the best system when we add reranking.When trained on 100 seed tables, our full rerankingmodel outperforms the other models.5 Error analysisIn this section, we analyze several types of errorsmade by the various systems.
Non-word predictionsare marked with an asterisk.German and Dutch are closely-related languagesthat exhibit similar errors.
Many errors involve thepast participle, which is often created by circumfix-ation.
For the German verb verfilmen ?to film,?
wepredict the correct verfilmt, while the other systemshave verfilmen*, and geverfilmt*, respectively.
DDNsimply select an incorrect rule for the past partici-ple.
AFH choose paradigms through suffix analy-sis, which fails to account for the fact that verbs thatbegin with a small set of prefixes, such as ver-, donot take a ge- prefix.
This type of error particularlyaffects the accuracy of AFH on Dutch because of anumber of verbs in our test set that involve infixationfor the past participle.
Our system uses its sourceand target-side n-gram features to match these pre-fixes with their correct representation.The second type of error is an over-correction bythe corpus.
The past participle of the verb dimmen isSet % of Total DDN OursBasic RerankedCZ-N 13.0 91.1 97.7 93.5CZ-V 6.8 82.5 83.6 85.8Table 7: Prediction accuracy of models trained on ob-served Czech forms.gedimmt, but AFH predict dimmt*, and then changeit to dummen with the corpus.
Dummen is indeeda valid word in German, but unrelated to the verbdimmen.
It is also far more common, with 181 oc-currences in the corpus, compared with only 28 forgedimmt.
Since AFH use corpus frequencies, mis-takes like this can occur.
Our system is trained tobalance transducer confidence against a form?s ex-istence in a corpus (as opposed to log frequency),which helps it ignore the bias of common, but incor-rect, forms.The German verb brennen ?to burn?
has an irregu-lar past participle: gebrannt.
It involves both a stemvowel change and a circumfix, two processes thatonly rarely co-occur.
AFH predict the form brannt*,using the paradigm of the similar bekennen.
Theflexibility of DDN allows them to predict the correctform.
Our basic model predicts gebrennt*, whichfollows the regular pattern of applying a circumfix,while maintaining the stem vowel.
The reranker isable to correct this mistake by relating it to the formgebrannt in the corpus, whose stem is identical tothe stem of the preterite forms, which is a commonparadigmatic pattern.Our system can also over-correct, such as with thesecond person plural indicative preterite form for theverb reisen, which should be reistet, and which ourbasic model correctly predicts.
The reranker, how-ever, changes the prediction to rist.
This is a nominalform that is observed in the corpus, while the verbalform is not.An interesting example of a mistake made by theFactored model of DDN involves the Dutch verbaandragen.
Their model learns that stem vowel ashould be doubled, and that an a should be includedas part of the suffix -agt, which results in an incor-rect form aandraaagt*.
Thanks to the modelling ofphonotactics, our model is able to correctly rule outthe tripling of a vowel.929Seed Tables DE DDN OursBasic Full Factored Joint Basic Full50 89.9 90.9 89.6 90.5 89.7 90.9100 91.5 92.2 91.4 92.3 92.0 92.6Table 8: Prediction accuracy on German verb forms after training on a small number of seed inflection tables.Finnish errors tend to fall into one of three types.First, words that involve harmonically neutral vow-els, such as ?e?
and ?i?
occasionally cause errors invowel harmony.
Second, all three systems have diffi-culty identifying syllable and compound boundaries,and make errors predicting vowels near boundaries.Finally, consonant gradation, which alternates con-sonants in open and closed syllables, causes a rel-atively large number of errors; for example, oursystem predicts *heltempien, instead of the correcthellempien as the genitive singular of the compara-tive adjective hellempi ?more affectionate?.6 ConclusionWe have proposed an alternative method of generat-ing inflected word-forms which is based on discrim-inative string transduction and reranking.
We haveconducted a series of experiments on nine datasetsinvolving six languages, including four new datasetsthat we created.
The results demonstrate that ourmethod is not only highly accurate, but also robustagainst incomplete or limited inflection data.
In thefuture, we would like to apply our method to non-European languages, with different morphologicalsystems.
We also plan to investigate methods of ex-tracting morphological tags from a corpus, includingdifferentiating syncretic forms in context.AcknowledgmentsWe thank Mans Hulden and Aki-Juhani Kyr?ol?ainenfor their assistance in analyzing Finnish errors..This research was supported by the Natural Sci-ences and Engineering Research Council of Canada,and the Alberta Innovates Technology Futures.ReferencesMalin Ahlberg, Markus Forsberg, and Mans Hulden.2014.
Semi-supervised learning of morphologicalparadigms and lexicons.
In Proceedings of the 14thConference of the European Chapter of the Associ-ation for Computational Linguistics, pages 569?578,Gothenburg, Sweden, April.
Association for Compu-tational Linguistics.Harald R. Baayen, Richard Piepenbrock, and Leon Gu-likers.
1995.
The CELEX Lexical Database.
Release2 (CD-ROM).
Linguistic Data Consortium, Universityof Pennsylvania, Philadelphia, Pennsylvania.Alena B?ohmov?a, Jan Haji?c, Eva Haji?cov?a, and BarboraHladk?a.
2003.
The Prague dependency treebank.
InTreebanks, pages 103?127.
Springer.Ann Clifton and Anoop Sarkar.
2011.
Combin-ing morpheme-based machine translation with post-processing morpheme prediction.
In Proceedingsof the 49th Annual Meeting of the Associationfor Computational Linguistics: Human LanguageTechnologies-Volume 1, pages 32?42.
Association forComputational Linguistics.Markus Dreyer and Jason Eisner.
2011.
Discover-ing morphological paradigms from plain text usinga dirichlet process mixture model.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 616?627.
Association forComputational Linguistics.Greg Durrett and John DeNero.
2013.
Supervised learn-ing of complete morphological paradigms.
In Pro-ceedings of NAACL-HLT, pages 1185?1195.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A li-brary for large linear classification.
The Journal ofMachine Learning Research, 9:1871?1874.Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-bienne Cap.
2012.
Modeling inflection and word-formation in SMT.
In Proceedings of the 13th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 664?674.
Associa-tion for Computational Linguistics.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden markov models to letter-to-phoneme con-version.
In Human Language Technologies 2007: TheConference of the North American Chapter of the As-sociation for Computational Linguistics; Proceedingsof the Main Conference, pages 372?379, Rochester,New York, April.
Association for Computational Lin-guistics.930Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2010.
Integrating joint n-gram features intoa discriminative training framework.
In Proceedingsof NAACL-2010, Los Angeles, CA, June.
Associationfor Computational Linguistics.Thorsten Joachims.
2002.
Optimizing search enginesusing clickthrough data.
In Proceedings of the eighthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 133?142.ACM.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics.Kristina Toutanova and Colin Cherry.
2009.
A globalmodel for joint lemmatization and part-of-speech pre-diction.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 1-Volume 1, pages 486?494.
Association for Computational Linguistics.Richard Zens and Hermann Ney.
2004.
Improvements inphrase-based statistical machine translation.
In HLT-NAACL 2004: Main Proceedings, pages 257?264,Boston, USA, May.931
