A Head-Driven Approach toIncremental and Parallel Generation of Syntactic StructuresGiinter NeumannInstitute for Computational LinguisticsUniversity of SaarbrtickenIm Stadtwald 15, Bau 276600 Saarbrticken 11, FRGneumann@ sbuvax.campus.uni-sb.deWolfgang FinklerGerman Research Center forArtificial IntelligenceStuhlsatzenhausweg 36600 Saarbrticken 11, FRGfinkler@ dfki.uni- sb.deAbstract: This paper ~ describes theconstruction of syntactic structures within anincremental multi-level and parallel generationsystem.
Incremental and parallel generationimposes special requirements upon syntacticdescription and processing.
A head-drivengrammar epresented in a unification-basedformalism is introduced which satisfies thesedemands.
Furthermore the basic mechanismsfor the parallel processing of syntactic segmentsare presented.1.
IntroductionIncremental generation (i.e.
immediateverbalization of the parts of a stepwisecomputed conceptual structure - often called"message") is an important and efficientproperty of human language use(\[DeSmedt&Kempen~7\], \[Levelt89\]).
Thereare particular situations of conmmnication (e.g.simultaneous descriptions of ongoing events)where incremental generation is necessary inorder to ensure that new information can beverbalized in due time.
As \[DeSmedt&Kempen87\] mentioned, incremental generationcan be viewed as a parallel process: While thelinguistic module (or "how-to-say" component)of an incremental generator is processing partialconceptual structures which are previouslycomputed from the conceptual module (or"what-to-say" component) the latter can run1Major parts of the work presented in this paper weredeveloped during the master's thesis of the authors.
Thiswork was supported by the German Science Foundation(DFG) in its Special Collaborative Program on AI andKnowledge-Based Systems (SFB 314), project XTRA.Thanks to Gregor Erbach, Norbert Reithinger andHarald "Frost for their helpful comments on earlierversions of the paper.simultaneously and add more conceptualelements.
In \[Finkler&Neumann89\] we showthat it is possible to refine this parallelism:Every conceptual or linguistic segment can beviewed as an active unit which tries to verbalizeitself as fast and as independently aspossible.If the translation of a segment is not possiblebecause of unspecif ied but requiredinformation, it is necessary to request missinginformation in order not to jeopardize the fastmapping.
As a consequence, the linguisticmodule provides feedback for the selection ofwhat to say next by the conceptual module (cf.\[Hovy87\], [Reithinger88\]).Incremental generation imposes specialrequirements upon syntactic description andprocessing (cf.
\[Kempen87\]).
Until now only afew approaches to syntax have been developedwhich consider explicitly the requirements ofincremental construction of sentences, namelythat of \[Kempen87\] and \[DeSmedt&Kempen88\].
But those do not provide for abidirectional flow of control betweenconceptual nd linguistic module.In this paper we describe the principles ofrepresentation and processing of syntacticknowledge in the natural anguage generationsystem POPEL-HOW, which for the first timecombines explicitly incremental multi-levelgeneration with parallelism and feedback.
Thesyntactic knowledge is declaratively representedby a unification-based head-driven grammarthat is linguistically based on dependencygrammar.2.
Requirements upon the SyntacticLevelThe following aspects concerning therepresentation f syntactic knowledge and thebasic mechanism have to be regarded in anincremental multi-level and parallel model:1.
The grammar should be lexically based.
Thelexicon is assumed to be the "essentialmediator" between conceptualization andgrammatical encoding (cf.
\[Levelt89\]).
Duringincremental generation it is not plausible toassume that the syntactic structure is built up"from phrases to lexical elements" starting witha root node S.2.
The grammar should support vertical ratherthan horizontal orientation \[Kempen87\].
Therules should emphasize the growing ofsyntactic structures by individual branches(ideally, only by one branch, but see 4.1).
Oneshould avoid that, because of adding a newsegment, unnecessary constraints aresimultaneously added for sister segments.3.
Syntactic segments hould be expanded inthe following three ways \[Kempen87\]: upward(a new segment B becomes the root node of aprevious egment A), downward (B becomes adaughter node of A) and insertion (B becomesthe daughter node of A which already has adaughter and this daughter becomes thedaughter of B) 2.4.
During incremental generation one shouldnot assume that the chronological order inwhich syntactic segments are attachedcorresponds to the linear order of the resultingutterance.
Hence one should separateknowk:dge concerning immediate dominanceand linear precedence \[Kempen87\].
Especiallyduring the pm'allel processing of languages witha relatively free word order (cog., German),one should avoid building up unnecessarysyntactic paraphrases resulting tiom orderingvoxiations.5.
When the whole syntactic stn.,cture of anutterance is built up in a parallel fashion, itshould be possible to decide for every partialstructure whether it is locally complete.
In ahead-driven grammar this is possible ifsegments are based on head elements.
Thusonly the information that is necessary for theinflection and linearization of the head isconsidered (see 4.2).6.
During spontaneous speech it may happenthat already existing structures need to bemodified because of new information that canonly be considered by replacing old one (whichmeans "reformulation").
Because of thedynamic behaviour of an incremental multi-level and parallel system, syntactic structuresshould not only cooperate but also competeduring generation (see 4.3).The basic demands 2., 3., 4. are putforward by Kempen's framework for syntactictree formation \[Kempen87\].
They serve as atheoretical basis for the development of thesyntactic formalism proposed in this paper.
Theother aspects are explicitly mentioned becausethey are important for incremental multi-leveland parallel generation.
Before the formalismand the basic operations are described in moredetail we briefly introduce POPEL-HOW, thegenerator in which the fornaalisnl is embedded3.
Overview of POPEL-HOWPOPEL-HOW \[Fiekler&Neumann89\] is thehow-to-say component of the natural anguagegeneration system POPEL \[Reithinger88\].
Themain features of POPEL.-HOW are:Incremental generation: POPEL-WHAT(the what-to-say component) immediatelypasses egments of the conceptual structure asinput to POPEL-HOW when they areconsidered relevant for the contents to beproduced.
POPE1,-HOW tries to build up thecorresponding semantic and syntactic segmentsimmediately, too, in order to utter the inputsegments as fast as possible, i.e.
POPEL-HOWgenerates structures at each level in anincremental way.Feedback: It is possible that newconceptual segments cannot be uttered irectlybecause they lack necessary linguisticinformation.
In this case POPEL-HOW is ableto interact with POPEL-WHAT to demand themissing information.
The bidirectional f ow ofcontrol has two main advantages: Firstly, thedetermination of the contents can be done onthe basis of conceptual considerations only.Therefore, POPEL-HOW isflexible enough tohandle underspecified input 3.
Secondly,POPEL-WHAT has to regard feedback fromPOPEL-HOW during the computation of thefurther selection process.
This means, anincremental system like POPEL can model theinfluence of linguistical restrictions on theprocess that determines what to say next (cf.\[Hovy87\], [Reithinger88\]).Reformulations: The addition of newconceptual segments could result inconstructing semantic or syntactic segments hatstand in competition with previously computedsegments.
POPEL-HOW is able to handle suchreformulations.Unified parallel processing: Everysegment at each level is conceived as an activeand independent process.
This view is thefoundation of the parallel and incrementalgeneration with feedback at each level of2In our formalism we neexl only downwm'd and upwardexpansion because ofthe nature of the syntacticstructures.3\[V/ard88\] shows that most generation systems lackthis ability so that heir inputs have been tailored todetermine a good senmncc.2 289POPEL-HOW.
The processing approach isuniform since every process (either conceptual,semantic or syntactic) runs the same basicprogram and processes its segment in the sameway.4.
The Design of the Syntactic LevelThe syntactic level in POPEL-HOW is dividedinto two sublevels: the dependency-based l vel(DBS-!evel) and the level of inflected andlinearized structures (ILS-level).
At the DBS-level the syntactic structure is constructed in anincremental and parallel way.
At the ILS-levelthere exists one process which performsinflection and linearization for every incomingsegment of the DBS-level.4.1 RepresentationThe central knowledge source of bothsublevels is POPELGRAM, a unification-basedhead driven grammar.
The grammar isdeclaratively expressed in a modified version ofthe PATR formalism (cf.
\[Shieber85\]).
PATRis modified in the sense that the representationand derivation devices are separated.
To use itfor generation, the parser (i.e.
the derivationdevice) is replaced by operations uitable forincremental nd parallel generation 4.POPELGRAM is divided into immediatedominance (ID) and linear precedence (LP)structures .
In order to allow for verticalorientation, the D-structures are furthermoredivided into those that describe basic syntacticsegments and others that describe therelationship between complex structures.
Basicsegments are phrases that consist of a (non-empty) set of constituents.
At least oneconstituent must have a lexical category.
Thecentral point of view for the description of basicsegments is that the dependency relation isdefined for the constituents of a phrase: Oneconstituent that must have a lexical category isdenoted as the head of a phrase.
All otherconstituents are denoted as complements thatare immediately dependent on the head.
Thedependency relation of the constituents of aphrase is expressed as a feature descriptionnamed STRUCT which belongs to the phrasalcategory.
E. g., fig.
1 shows the feature set ofthe basic segment for constructing a sentence4This is in contrast to \[Shieber tal.89\] where the sameoperations are used for both analysis and generation.5In this paper we only consider the ID-structures inmore detail.phrase where the head governs twocomplements6:0:1: Ecat: SISTRUCT:fset: |Lsyn: ~cat: Vfset:-head: Fi\].
1comp,Ii lf t:s"bJl lsub, at" / :lvm: N J / ?
t2.
rfct: dirobj\] /\[ "\[va :N J\]syn: \[~Ilocal: \[agree: ~\]\]2: \[\]cat: NP1I 11 fset: syn: agree: FYJ-pers:\[\]\] te-J.num: \[ \]Jr~cat: NP23: te4fset: \[syn: \[case: Ace\ ]  \] \]Fig.
1The head element is the central element of thephrase and determines the characteristicproperties of the whole phrase that is defined asthe projection of its head 7.
The particular qualityof ID-structures of POPELGRAM makes itpossible to interpret such structures astheoretically based on dependency grammar (cf.\[Kunze75\], \[Hellwig861).
Basic segments canalso be defined as abstract descriptions ofcertain classes of lexical elements which havethe same category  and va lence (orsubcategorization) restrictions.
The abstractdescription of lexical information (in the senseof dependency grammar) is the foundation ofour lexically based grammar.
We assurne thatthis view supports incremental and parallelgeneration.Obviously, basic segments build up syntacticconstraints for their complements?
Althoughthis seems to emphasize horizontal orientation,these constraints are not redundant andtherefore do not violate the view of verticalorientation.
A basic segment must access theinformation that is necessary to build up a6The integer attributes correspond to the order of theelements inthe corresponding ID-ruleS ~ V, NP1, NP2.
Note: The order of constituents inot assumexl tobe the order of the corresponding surfacestring.7If complements of basic segments are defined asphrases, then the head elements of the complements areimmediately dependent on the head element of the basicsegment, because of the projection principle.
Hence,complex syntactic structures are compositionally viewedas hierarchical head and modifier su~actures.290minimal syntactically well-formed partialutterance.
If the dependencies between a headelement and its modifiers are strong as in thecase of complements, then this information hasto be formulated in an incremental grammar,\ [oo 8.Adjuncts are not necessary for buildingminimal well-formed structures.
Therefore theyare not part of basic segments.
The combinationof basic segments and adjuncts is expressed bymeans of complex segments.
Those ID-structures are applied only when thecorresponding basic segment already exists.4.2 Incremental and Parallel Processingl~D-structures are processed at the DBS-level.At this level basic segments are considered asindependent and active units.
In order to realizethis every basic segment is associated with itsown active process (or object) whereby the,;tructure of an object reflects the underlyingdependency relation of the segment.
For thefeature set of fig.
1 this can graphically berepresented asfollows:\[f,q s~mtcr:Fig.
2(v~ is denoted as the body and the directedNP1 NP2labeled slots 0 " 9 ~  and @ asthe context of the process.
The names of thebody and the slot correspond to the feature setsof the associated basic segment.
Every labeledslot serves as a communication li k to a processwhich represents the basic segment of thecorresponding slot's complement.
Thetopology of the network of active processesrepresents he corresponding dependency-based~ree structure.Objects at the DBS-level are created uringthe evaluation of local transition rules.
These8This point of view is in contrast o \[Kempen87\].
Inhis framework, all syntactic segments are defined asnode-arc-node structures because segments have tobranch only by one element at a time.rules describe the relation between semantic andsyntactic knowledge in a distributed way\[Finkler&Neumann89\].
They are local becauseevery rule describes tile mapping of semanticsegments (represented as concepts of anetwork-like formalism) to syntactic segmentsof the ID-part of POPELGRAM.
In principlethis local mapping is case-frame based: Asemantic head (e.g., a predicate) and its deepcases (e.g., agent or benefactive) am related toa corresponding syntactic head (e.g.
a verb)and its syntactic frame (e.g., subject or directobject constituents).
During the mapping lexicalmaterial which is deteIxnined through the choiceof words 9 directs and restricts the choice ofpossible syntactic structures.In order to construct syntactic structures inan incremental and parallel way, every DBS-object has to solve the following two centralsubtasks:a. building up connections to other objectsb.
mapping itself as fast as possible into thenext levelIn order to solve task a., every new createdDBS-object tries to integrate itself into thetopology of the already existing objects.Thereby the following cases have to bedistinguished:I.
The new object is taken up into the contextof an object.
Syntactically, this means that tilenew object represents an immediatelydependent constituent.
The existing structure isexpanded ownward (see fig.
3).G+ Mary Peter.v.-@-Q?
( ~  lovesPeter MaryFig.
3:The new active object is the left one.9The choice of words is performed in two steps inPOPEL-HOW.
While conceptual segments are translatedinto semantic segments, the content words  - e.g.
verbsand nouns - ,are selected.
Tile selection of  funct ion  words- e.g.
prepositions which depend on the meaning of tileverb - is performed uring the mapping between thesemantic level and the DBS-level.4 2912.
The new object takes up (or binds) analready existing object.
The existing structure isexpanded upward (see fig.
4).0 t toves "~0 Peter( ~  lovesPeter Mary?MaryFig.
4:In this example the new verbal object bindstwo existing nouns.3.
The new object describes a reformulation ofthe basic segment of an already existing object.This object must be replaced with the new one(see fig.
5).?
~ I|~ J lovesMary Peter SusanPeter MaryFig.
5:This is actually uttered as:"Peter loves Susan ... uh ...
Mary.
"While new communication li ks are built up,participating objects exchange their syntacticfeatures '?.
An adjunct is added to an object byaugmenting the object's context with a newlabeled slot.
When the slot is being filled withan object, its ass~iated feature set and the basicsegment are combined to yield a complexsegment that represents he new segment of theaugment~ object.Every DBS-object ries to map itself into thenext level as fast as possible (subtask b.)
in10 This is performed with the help of a search algorithmusing the ID-structures of POPELGRAM.
The ID-structures implicitly represent the search space.
Toconstraint the space, heuristic information in form ofpartial feature descriptions i used.
This search operationserves as the basis for other operations, to(), e.g.
forunifying lexical elements with basic segments.order to facilitate spontaneous speech.
Thefeature set of the head of the associated segmentis checked to see if it contains sufficientinformation for inflecting and linearizing it.
Forevery segment his information has to bespecified under the head's feature local.
Actualvalues come either from the lexicon, e.g.,gender for nouns, from dependent elements bymeans of structure sharing, e.g., person andnumber for a verb from the subject constituentor from a govering constituent, e.g., case fordependent ouns of a verb.When all subfeatures of the local feature havevalues, i.e.
a value other than the empty featureset, then the segment is said to be locallycomplete.
The reason for the segment of aDBSoobject not to be locally complete is thatDBS--objects that share values with the localfeature set are either not yet created or not yetlocally complete themselves (e.g., a verb islocally incomplete when a phrase that has to fillthe subject role is not yet created), in the firstcase, the missing objects are requested (usingthe object's context) from that object of thesemantic level above that has created therequesting object, in the second case, DBS-objects that are already connected to theunderspecified object are invited to determinethe missing values.4.3 Inf lection, L inearizat ionReformulationandSegments from the DBS-level that are locallycomplete ate inflected and linearized at the ILS-level in POPEL.-HOW.
The inflection isperformed by means of the package MORPHIX\[Finkler&Neumann88\], which handles most ofthe inflection phenomena of German.
The orderof segments in an utterance is syntacticallyconstrained by the LP-part of POPELGRAM.
Itis assumed that the order of activation ofconceptual segments (which is determinedusing pragmatical  knowledge  (of.\[Reithinger88\])) should be maintained if it issyntactically wellformed; otherwise thesegments are reordered by means of relevantLP-structures.
Therefore, the order of the inputsegments affects the variations of the linearorder in the resulting utterance, which makesPOPEL-HOW more flexible (e.g.
by decidingwhether to realize an active or passive form).But the order of the input segments can affectlexical choice, too.
For example, if the modifierdenoting the vehicle (e.g., "airplane") for aconceptual segment of type "comn-mte-by-public-transportation" is known in due time themore restricted verb "to fly" is chosen insteadof the more general verb "to go".
Otherwise, a292 5prepositional phrase realizing the modifier mustbe verbalized explicitly (e.g., "to go byairplane").It is possible that because of the incrementalcomposition of large structures across severallevels new conceptual segments lead to thereformulation f structures at successive l vels(cf.
\[DeSmedt&Kempen881) as indicated in thefollowing sample utterances:"Mary is going ... uh ... Mary and Peter aregoing to school.
""Eric goes ... uh ... flies to the USA.
"In POPEL-HOW the reformulation of asegment is represented by an object that is incompetition to the corresponding alreadyexisting object (e.g., the first utterance wherethe new conceptual segment "Peter" leads to asyntactic segment "Mary and Peter" which is incompetit ion with the noun phrase "Mary").
Inorder to integrate such new objects theconnections to an object which is to be replacedmust be broken up and reconnected to the newobject (see also fig.
5).
Of course, thereplacement must be performed for the relevantassociated segments, too.
For syntacticsegnaents we have developed an operationwhich allows the replacement of parts of agiven feature set.
In principle this is realized byresetting the corresponding partial feature set(i.e., relevant features get the empty value) andsubsequent ly  un i fy ing it with the newinformation.5.
Conc lus ionThis paper has demonstrated therepresentation and processing of syntacticknowle, dge within the generation systemPOPEL-HOW which for the first t imecombines  expl ic it ly incremental  sentenceproduction with parallelism and feedback.
Sucha generat ion  mode l  imposes  specia lrequirements on syntactic representation andprocessing.
A unification-based head-drivengrammar, linguistically based on dependencygrammar, is introduced that satisfies thesedemands.
Furthermore the basic mechanismsfor incremental and parallel generation havebeen presented.The whole generation system is implementedin Commonl isp  on a Symbolics 3640 lisp-machine by simulated parallelism using theprocess-facilities and the scheduler.
It also runsin Kyoto Commonl isp  and CLOS (using aselfwritten scheduler).
The system is fullyintegrated in the natural language access ystemXTRA (cf.
\[Allgayer et al89\]).References\[Allgayer et al89\] J. Al lgayer, R. Jansen-Winke ln ,  C~ Reddig and N. Reithinger.Bidirectional use of knowledge in the multi-modal NLaccess system XTRA: In: Proceedings of the llthIJCAI, pp.
1492 - 1497, Detroit, Michigan USA, 1989.\[DeSmedt&Kempen87\] K. DeSmedt and G.Kempen.
Incremental Sentence Production, Self-Correction and Coordination.
In: G. Kempen (ed.
),Natural Language Generation: New Results in ArtificialIntelligence, Psychology and Linguistics, pp.
365476,Dor&echt: Martinus Nijhoff, 1987.\[DeSmedt&Kempen88\] K. DeSmedt and G.Kempen.7"he Representation of GrammaticalKnowledge in a Model for Incremental SentenceGeneration.
Paper presented at the 4th IWG, SantaCat~dina Island, 7 1988.\[Finkler&Neumann88\] W. Finkler and G.Neumann.
MORPIIIX: A Fast Realization of aClassification-Based Approach to Morphology.
In:Proceedings of the WWWS, Springer, Berlin, 1988.\[Finkler&Neumann89\] W. Finkler and G.Neumann.
POPEL-HOW: A Distributed ParallelModel for Incremental Natural Language Productionwith Feedback.
In: Proceexlings of the 1 lth IJCAI, pp.1518 - 1523, Detroit, Michigan USA, 1989.\[Hellwig86\] P. ilellwig.
Dependency UnificationGrammar.
In: Proceexiings of the 1 lth COLING, Bonn,FRG, 1986.\[f{ovy87\] E. tlovy.
Generating Natural LanguageUnder Pragmatic Constraints.
Ph.D. thesis, YaleUniversity, 1987.\[Kempen87\] G. Kempen.
A Framework forIncremental Syntactic Tree Formation.
In: Proceedingsof the 10th IJCAI, Mailand, Italy, 1987.\[Kunze75\] J. Kunze.
Abhdngigkeitsgrammatik.Akademie-Verlag, Berlin, 1975.\[Levelt89\] W.J.M.
Levelt.
Speaking: FromIntention to Articulation.
Massachusetts Institute ofTechnology: The MIT Press, 1989.\[Reithinger88\] N. Reithinger.
POPEL: A Paralleland Incremental Natural Language Generation System.Paper presented atthe 4th IWG, Santa Catalina Island, 71988.\[Shieber85\] S.M.
Shieber.
An Introduction toUnification-Based Approaches to Grammar.
Volume 4of CSLI Lecture Notes, CLSI, Stanford, California,1985.lShieber et al89\] S.M.
Shieber, G. van Noord,R.M.
Moore and F.C.P.
Pereira.
A Semantic tlead-Driven Generation Algorithm for Unification-BasedFormalisms.
In: Proceedings of the 27th ACL,Vancouver, British Columbia, Canada, 1989.\[Ward88\] N. Ward.
Issues in Word Choice.
in:Proceedings of the 12th COL1NG, Budapest, Hungary,1988.6 293
