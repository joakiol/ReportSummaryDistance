Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 114?119,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsMultilingual Syntactic-Semantic Dependency Parsing with Three-StageApproximate Max-Margin Linear ModelsYotaro Watanabe, Masayuki Asahara and Yuji MatsumotoGraduate School of Information ScienceNara Institute of Science and Technology8916-5 Takayama, Ikoma, Nara, Japan, 630-0192{yotaro-w, masayu-a, matsu}@is.naist.jpAbstractThis paper describes a system for syntactic-semantic dependency parsing for multiple lan-guages.
The system consists of three parts: astate-of-the-art higher-order projective depen-dency parser for syntactic dependency pars-ing, a predicate classifier, and an argumentclassifier for semantic dependency parsing.For semantic dependency parsing, we ex-plore use of global features.
All componentsare trained with an approximate max-marginlearning algorithm.In the closed challenge of the CoNLL-2009Shared Task (Hajic?
et al, 2009), our systemachieved the 3rd best performances for En-glish and Czech, and the 4th best performancefor Japanese.1 IntroductionIn recent years, joint inference of syntactic and se-mantic dependencies has attracted attention in NLPcommunities.
Ideally, we would like to choose themost plausible syntactic-semantic structure amongall possible structures in that syntactic dependenciesand semantic dependencies are correlated.
How-ever, solving this problem is too difficult becausethe search space of the problem is extremely large.Therefore we focus on improving performance foreach subproblem: dependency parsing and semanticrole labeling.In the past few years, research investigatinghigher-order dependency parsing algorithms hasfound its superiority to first-order parsing algo-rithms.
To reap the benefits of these advances, weuse a higher-order projective dependency parsing al-gorithm (Carreras, 2007) which is an extension ofthe span-based parsing algorithm (Eisner, 1996), forsyntactic dependency parsing.In terms of semantic role labeling, we wouldlike to capture global information about predicate-argument structures in order to accurately predict thecorrect predicate-argument structure.
Previous re-search dealt with such information using re-ranking(Toutanova et al, 2005; Johansson and Nugues,2008).
We explore a different approach to dealwith such information using global features.
Useof global features for structured prediction problemhas been explored by several NLP applications suchas sequential labeling (Finkel et al, 2005; Krishnanand Manning, 2006; Kazama and Torisawa, 2007)and dependency parsing (Nakagawa, 2007) with agreat deal of success.
We attempt to use global fea-tures for argument classification in which the mostplausible semantic role assignment is selected usingboth local and global information.
We present anapproximate max-margin learning algorithm for ar-gument classifiers with global features.2 Dependency ParsingAs in previous work, we use a linear model for de-pendency parsing.
The score function used in ourdependency parser is defined as follows.s(y) = ?
(h,m)?yF (h,m,x) (1)where h and m denote the head and the dependentof the dependency edge in y, and F (h,m,x) is aFactor that specifies dependency edge scores.114We used a second-order factorization as in (Car-reras, 2007).
The second-order factor F is definedas follows.F (h,m,x) = w ??
(h,m,x)+w ??
(h,m, ch,x)+w ?
?
(h,m, cmi,x) +w ?
?
(h,m, cmo,x) (2)where w is a parameter vector, ?
is a feature vector,ch is the child of h in the span [h...m] that is closestto m, cmi is the child of m in the span [h...m] that isfarthest fromm and cmo is the child of m outside thespan [h...m] that is farthest fromm.
For more detailsof the second-order parsing algorithm, see (Carreras,2007).For parser training, we use the Passive Aggres-sive Algorithm (Crammer et al, 2006), which is anapproximate max-margin variant of the perceptronalgorithm.
Also, we apply an efficient parameter av-eraging technique (Daume?
III, 2006).
The resultinglearning algorithm is shown in Algorithm 1.Algorithm 1 A Passive Aggressive Algorithm withparameter averaginginput Training set T = {xt,yt}Tt=1, Number of iterationsN and Parameter Cw ?
0, v ?
0, c ?
1for i ?
0 to N dofor (xt,yt) ?
T doy?
= argmaxy w ?
?
(xt,y) + ?
(yt, y?
)?t = min?C, w??(xt,y?)?w??(xt,yt)+?(yt,y?)||?(xt,yt)??(xt,y?
)||2?w ?
w + ?t(?(xt,yt)?
?
(xt, y?
))v ?
v + c?t(?(xt,yt)?
?
(xt, y?
))c ?
c + 1end forend forreturn w ?
v/cWe set ?
(yt, y?)
as the number of incorrect headpredictions in the y?, and C as 1.0.Among the 7 languages of the task, 4 languages(Czech, English, German and Japanese) containnon-projective edges (13.94 %, 3.74 %, 25.79 %and 0.91 % respectively), therefore we need to dealwith non-projectivity.
In order to avoid losing thebenefits of higher-order parsing, we considered ap-plying pseudo-projective transformation (Nivre andNilsson, 2005).
However, growth of the number ofdependency labels by pseudo-projective transforma-tion increases the dependency parser training time,so we did not adopt transformations.
Therefore, theparser ignores the presence of non-projective edgesin the training and the testing phases.The features used for our dependency parser arebased on those listed in (Johansson, 2008).
In addi-tion, distance features are used.
We use shorthandnotations in order to simplify the feature represen-tations: ?h?, ?d?, ?c?, ?l?, ?p?, ??1?
and ?+1?
cor-respond to head, dependent, head?s or dependent?schild, lemma , POS, left position and right positionrespectively.First-order FeaturesToken features: hl, hp, hl+hp, dl, dp and dl+dp.Head-Dependent features: hp+dp, hl+dl, hl+dl,hl+hp+dl, hl+hp+dp, hl+dl+dp, hp+dl+dp andhl+hp+dl+dp.Context features: hp+hp+1+dp?1+dp,hp?1+hp+dp?1+dp, hp+hp+1+dp+dp+1 andhp?1+hp+dp+dp+1.Distance features: The number of tokens between thehead and the dependent.Second-order FeaturesHead-Dependent-Head?s or Dependent?s Child:hl+cl, hl+cl+cp, hp+cl, hp+cp, hp+dp+cp, dp+cp,dp+cl+cp, dl+cp, dl+cp+cl3 Semantic Role LabelingOur SRL module consists of two parts: a predicateclassifier and an argument classifier.
First, our sys-tem determines the word sense for each predicatewith the predicate classifier, and then it detects thehighest scored argument assignment using the argu-ment classifier with global features.3.1 Predicate ClassificationThe first phase of SRL in our system is to detectthe word sense for each predicate.
WSD can be for-malized as a multi-class classification problem givenlemmas.
We created a linear model for each lemmaand used the Passive Aggressive Algorithm with pa-rameter averaging to train the models.3.1.1 Features for Predicate ClassificationWord features: Predicted lemma and the predicted POSof the predicate, predicate?s head, and its conjunc-tions.Dependency label: The dependency label between thepredicate and the predicate?s head.115Dependency label sequence: The concatenation of thedependency labels of the predicate dependents.Since effective features for predicate classifica-tion are different for each language, we performedgreedy forward feature selection.3.2 Argument ClassificationIn order to capture global clues of predicate-argument structures, we consider introducing globalfeatures for linear models.
Let A(p) be a jointassignment of role labels for argument candidatesgiven the predicate p. Then we define a score func-tion s(A(p)) for argument label assignments A(p).s(A(p)) =?kFk(x,A(p)) (3)We introduce two factors: Local Factor FL andGlobal Factor FG defined as follows.FL(x, a(p)) = w ?
?L(x, a(p)) (4)FG(x,A(p)) = w ?
?G(x,A(p)) (5)where ?L, ?G denote feature vectors for the localfactor and the global factor respectively.
FL scores aparticular role assignment for each argument candi-date individually, and FG treats global features thatcapture what structure the assignment A has.
Re-sulting scoring function for the assignment A(p) isas follows.s(A(p)) = ?a(p)?A(p)w?
?L(x, a(p))+w?
?G(x,A(p))(6)Use of global features is problematic, because itbecomes difficult to find the highest assignment ef-ficiently.
In order to deal with the problem, we usea simple approach, n-best relaxation as in (Kazamaand Torisawa, 2007).
At first we generate n-best as-signments using only the local factor, and then addthe global factor score for each n-best assignment, fi-nally select the best scoring assignment from them.In order to generate n-best assignments, we used abeam-search algorithm.3.2.1 Learning the ModelAs in dependency parser and predicate classifier,we train the model using the PA algorithm with pa-rameter averaging.
The learning algorithm is shownin Algorithm 2.
In this algorithm, the weights cor-respond to local factor features ?L and global factorfeatures ?G are updated simultaneously.Algorithm 2 Learning with Global Features for Ar-gument Classificationinput Training set T = {xt,At}Tt=1, Number of iterationsN and Parameter Cw ?
0, v ?
0, c ?
1for i ?
0 to N dofor (xt,At) ?
T dolet ?
(xt,A) = Pa?A ?L(xt, a) + ?G(xt,A)generate n-best assignments {An} using FLA?
= argmaxA?
{An} w ?
?
(xt,A) + ?
(At,A)?t = min?C, w??(xt,A?)?w??(xt,At)+?(At,A?)||?(xt,At)??(xt,A?
)||2?w ?
w + ?t(?(xt,At)?
?
(xt, A?
))v ?
v + c?t(?(xt,At)?
?
(xt, A?
))c ?
c + 1end forend forreturn w ?
v/cWe set the margin value ?
(A, A?)
as the numberof incorrect assignments plus ?
(A, A?
), and C as 1.0.The delta function returns 1 if at least one assign-ment is different from the correct assignment and 0otherwise.The model is similar to re-ranking (Toutanova etal., 2005; Johansson and Nugues, 2008).
Howeverin contrast to re-ranking, we only have to prepareone model.
The re-ranking approach requires othertraining datasets that are different from the data usedin local model training.3.2.2 Features for Argument ClassificationThe local features used in our system are the sameas our previous work (Watanabe et al, 2008) exceptfor language dependent features.
The global featuresthat used in our system are based on (Johansson andNugues, 2008) that used for re-ranking.Local FeaturesWord features: Predicted lemma and predicted POS ofthe predicate, predicate?s head, argument candidate,argument candidate?s head, leftmost/rightmost de-pendent and leftmost/rightmost sibling.Dependency label: The dependency label of predicate,argument candidate and argument candidate?s de-pendent.Family: The position of the argument candicate with re-spect to the predicate position in the dependencytree (e.g.
child, sibling).116Average Catalan Chinese Czech English German Japanese SpanishMacro F1 Score 78.43 75.91 73.43 81.43 86.40 69.84 84.86 77.12(78.00*) (74.83*) (73.43*) (81.38*) (86.40*) (68.39*) (84.84*) (76.74*)Semantic Labeled F1 75.65 72.35 74.17 84.69 84.26 63.66 77.93 72.50(75.17*) (71.05*) (74.17*) (84.66*) (84.26*) (61.94*) (77.91*) (72.25*)Labeled Syntactic Accuracy 81.16 79.48 72.66 78.17 88.54 75.85 91.69 81.74(80.77*) (78.62*) (72.66*) (78.10*) (88.54*) (74.60*) (91.66*) (81.23*)Macro F1 Score 84.30 84.79 81.63 83.08 87.93 83.25 85.54 83.94Semantic Labeled F1 81.58 80.99 79.99 86.67 85.09 79.46 79.03 79.85Labeled Syntactic Accuracy 87.02 88.59 83.27 79.48 90.77 87.03 91.96 88.04Table 1: Scores of our system.Position: The position of the head of the dependency re-lation with respect to the predicate position in thesentence.Pattern: The left-to-right chain of the predictedPOS/dependency labels of the predicate?s children.Path features: Predicted lemma, predicted POS and de-pendency label paths between the predicate and theargument candidate.Distance: The number of dependency edges between thepredicate and the argument candidate.Global FeaturesPredicate-argument label sequence: The sequence ofthe predicate sense and argument labels in thepredicate-argument strucuture.Presence of labels defined in frame files: Whether thesemantic roles defined in the frame present in thepredicate-argument structure (e.g.
MISSING:A1 orCONTAINS:A1.
)3.2.3 Argument PruningWe observe that most arguments tend to be not farfrom its predicate, so we can prune argument candi-dates to reduce search space.
Since the characteris-tics of the languages are slightly different, we applytwo types of pruning algorithms.Pruning Algorithm 1: Let S be an argument candi-date set.
Initially set S ?
?
and start at predicate node.Add dependents of the node to S, and move current nodeto its parent.
Repeat until current node reaches to ROOT.Pruning Algorithm 2: Same as the Algorithm 1 ex-cept that added nodes are its grandchildren as well as itsdependents.The pruning results are shown in Table 2.
Sincewe could not prune arguments in Japanese accu-rately using the two algorithms, we pruned argumentcandidates simply by POS.algorithm coverage (%) reduction (%)Catalan 1 100 69.1Chinese 1 98.9 69.1Czech 2 98.5 49.1English 1 97.3 63.1German 1 98.3 64.3Japanese POS 99.9 41.0Spanish 1 100 69.7Table 2: Pruning results.4 ResultsThe submitted results on the test data are shown inthe upper part of Table 1.
Due to a bug, we mistak-enly used the gold lemmas in the dependency parser.Corrected results are shown in the part marked with*.
The lower part shows the post evaluation resultswith the gold lemmas and POSs.For some of the 7 languages, since the globalmodel described in Section 3.2 degraded perfor-mance compare to a model trained with only FL,we did NOT use the model for all languages.
Weused the global model for only three languages: Chi-nese, English and Japanese.
The remaining lan-guages (Catalan, Czech, German and Spanish) useda model trained with only FL.4.1 Dependency Parsing ResultsThe parser achieved relatively high accuracies forCzech, English and Japanese, and for each language,the difference between the performance with correctPOS and predicted POS is not so large.
However, inCatalan, Chinese German and Spanish, the parsingaccuracies was seriously degraded by replacing cor-rect POSs with predicted POSs (6.3 - 11.2 %).
Thisis likely because these languages have relatively lowpredicted POS accuracies (92.3 - 95.5 %) ; Chinese117FL FL+FG (?P, ?R)Catalan 85.80 85.68 (+0.01, -0.26)Chinese 86.58 87.39 (+0.24, +1.36)Czech 89.63 89.05 (-0.87, -0.28)English 85.66 85.74 (-0.87, +0.98)German 80.82 77.30 (-7.27, +0.40)Japanese 79.87 81.01 (+0.17, +1.88)Spanish 84.38 83.89 (-0.42, -0.57)Table 3: Effect of global features (semantic labeled F1).
?P and ?R denote the differentials of labeled precisionand labeled recall between FL and FL+FG respectively.has especially low accuracy (92.3%).
The POS ac-curacy may affect the parsing performances.4.2 SRL ResultsIn order to highlight the effect of the global fea-tures, we compared two models.
The first modelis trained with only the local factor FL.
The sec-ond model is trained with both the local factor FLand the global factor FG.
The results are shown inTable 3.
In the experiments, we used the develop-ment data with gold parse trees.
For Chinese andJapanese, significant improvements are obtained us-ing the global features (over +1.0% in labeled re-call and the slightly better labeled precision).
How-ever, for Catalan, Czech, German and Spanish, theglobal features degraded the performance in labeledF1.
Especially, in German, the precision is substan-tially degraded (-7.27% in labeled F1).
These resultsindicate that it is necessary to introduce language de-pendent features.4.3 Training, Evaluation Time and MemoryRequirementsTable 4 and 5 shows the training/evaluation timesand the memory consumption of the second-orderdependency parsers and the global argument classi-fiers respectively.
The training times of the predi-cate classifier were less than one day, and the testingtimes were mere seconds.As reported in (Carreras, 2007; Johansson andNugues, 2008), training and inference of the second-order parser are very expensive.
For Chinese, wecould only complete 2 iterations.In terms of the argument classifier, since N-bestgeneration time account for a substantial proportionof the training time (in this work N = 100), chang-iter hrs./iter sent./min.
mem.Catalan 9 14.6 9.0 9.6 GBChinese 2 56.5 3.7 16.2 GBCzech 8 14.6 20.5 12.6 GBEnglish 7 22.0 13.4 15.1 GBGerman 4 12.3 59.1 13.1 GBJapanese 7 11.2 21.8 13.0 GBSpanish 7 19.5 7.3 17.9 GBTable 4: Training, evaluation time and memory require-ments of the second-order dependency parsers.
The ?iter?column denote the number of iterations of the modelused for the evaluations.
Catalan, Czech and Englishare trained on Xeon 3.0GHz, Chinese and Japanese aretrained on Xeon 2.66GHz, German and Spanish aretrained on Opteron 2.3GHz machines.train (hrs.)
sent./min.
mem.Chinese 6.5 453.7 2.0 GBEnglish 13.5 449.8 3.2 GBJapanese 3.5 137.6 1.1 GBTable 5: Training, evaluation time and memory require-ments of the global argument classifiers.
The classifiersare all trained on Opteron 2.3GHz machines.ing N affects the training and evaluation times sig-nificantly.All modules of our system are implemented inJava.
The required memory spaces shown in Table4 and 5 are calculated by subtracting free memorysize from the total memory size of the Java VM.Note that we observed that the value fluctuated dras-tically while measuring memory usage, so the valuemay not indicate precise memory requirements ofour system.5 ConclusionIn this paper, we have described our system for syn-tactic and semantic dependency analysis in multilin-gual.
Although our system is not a joint approachbut a pipeline approach, the system is comparable tothe top system for some of the 7 languages.A further research direction we are investigatingis the application of various types of global features.We believe that there is still room for improvementssince we used only two types of global features forthe argument classifier.Another research direction is investigating jointapproaches.
To the best of our knowledge, three118types of joint approaches have been proposed:N-best based approach (Johansson and Nugues,2008), synchronous joint approach (Henderson etal., 2008), and a joint approach where parsingand SRL are performed simultaneously (Llu?
?s andMa`rquez, 2008).
We attempted to perform N-best based joint approach, however, the expen-sive computational cost of the 2nd-order projectiveparser discouraged it.
We would like to investigatesyntactic-semantic joint approaches with reasonabletime complexities.AcknowledgmentsWe would like to thank Richard Johansson for hisadvice on parser implementation, and the CoNLL-2009 organizers (Hajic?
et al, 2009; Taule?
et al,2008; Palmer and Xue, 2009; Hajic?
et al, 2006; Sur-deanu et al, 2008; Burchardt et al, 2006; Kawaharaet al, 2002; Taule?
et al, 2008).ReferencesAljoscha Burchardt, Katrin Erk, Anette Frank, AndreaKowalski, Sebastian Pado?, and Manfred Pinkal.
2006.The SALSA corpus: a German corpus resource forlexical semantics.
In Proc.
of LREC-2006, Genoa,Italy.Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proc.
of EMNLP-CoNLL 2007.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
JMLR, 7:551?585.Hal Daume?
III.
2006.
Practical Structured LearningTechniques for Natural Language Processing.
Ph.D.thesis, University of Southern California, Los Ange-les, CA, August.Jason Eisner.
1996.
Three new probabilistic models fordependency parsing.
In Proc.
of ICCL 1996.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In Proc.
of ACL 2005.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, PetrSgall, Petr Pajas, Jan S?te?pa?nek, Jir???
Havelka, MarieMikulova?, and Zdene?k Z?abokrtsky?.
2006.
Prague De-pendency Treebank 2.0.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic dependen-cies in multiple languages.
In Proc.
of CoNLL-2009,Boulder, Colorado, USA.James Henderson, Paola Merlo, Gabriele Musillo, andIvan Titov.
2008.
A latent variable model of syn-chronous parsing for syntactic and semantic dependen-cies.
In Proc.
of CoNLL 2008.Richard Johansson and Pierre Nugues.
2008.Dependency-based syntactic-semantic analysiswith propbank and nombank.
In Proc.
of CoNLL2008.Richard Johansson.
2008.
Dependency-based SemanticAnalysis of Natural-language Text.
Ph.D. thesis, LundUniversity.Daisuke Kawahara, Sadao Kurohashi, and Ko?iti Hasida.2002.
Construction of a Japanese relevance-taggedcorpus.
In Proc.
of LREC-2002, pages 2008?2013,Las Palmas, Canary Islands.Jun?Ichi Kazama and Kentaro Torisawa.
2007.
A newperceptron algorithm for sequence labeling with non-local features.
In Proc.
of EMNLP-CoNLL 2007.Vijay Krishnan and Christopher D. Manning.
2006.
Aneffective two-stage model for exploiting non-local de-pendencies in named entity recognition.
In Proc.
ofACL-COLING 2006.Xavier Llu?
?s and Llu?
?s Ma`rquez.
2008.
A joint model forparsing syntactic and semantic dependencies.
In Proc.of CoNLL 2008.Tetsuji Nakagawa.
2007.
Multilingual dependency pars-ing using global features.
In Proc.
of the CoNLLShared Task Session of EMNLP-CoNLL 2007.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-projectivedependency parsing.
In Proc.
of ACL 2005.Martha Palmer and Nianwen Xue.
2009.
Adding seman-tic roles to the Chinese Treebank.
Natural LanguageEngineering, 15(1):143?172.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s Ma`rquez, and Joakim Nivre.
2008.
The CoNLL-2008 shared task on joint parsing of syntactic and se-mantic dependencies.
In Proc.
of CoNLL-2008.Mariona Taule?, Maria Anto`nia Mart?
?, and Marta Re-casens.
2008.
AnCora: Multilevel Annotated Corporafor Catalan and Spanish.
In Proc.
of LREC-2008, Mar-rakesh, Morroco.Kristina Toutanova, Aria Haghighi, and Christopher D.Manning.
2005.
Joint learning improves semantic rolelabeling.
In Proc.
of ACL 2005.Yotaro Watanabe, Masakazu Iwatate, Masayuki Asahara,and Yuji Matsumoto.
2008.
A pipeline approach forsyntactic and semantic dependency parsing.
In Proc.of CoNLL 2008.119
