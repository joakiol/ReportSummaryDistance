Coling 2010: Poster Volume, pages 543?551,Beijing, August 2010Generative Alignment and Semantic Parsingfor Learning from Ambiguous SupervisionJoohyun KimDepartment of Computer ScienceThe University of Texas at Austinscimitar@cs.utexas.eduRaymond J. MooneyDepartment of Computer ScienceThe University of Texas at Austinmooney@cs.utexas.eduAbstractWe present a probabilistic generativemodel for learning semantic parsers fromambiguous supervision.
Our approachlearns from natural language sentencespaired with world states consisting ofmultiple potential logical meaning repre-sentations.
It disambiguates the mean-ing of each sentence while simultane-ously learning a semantic parser that mapssentences into logical form.
Comparedto a previous generative model for se-mantic alignment, it also supports fullsemantic parsing.
Experimental resultson the Robocup sportscasting corpora inboth English and Korean indicate thatour approach produces more accurate se-mantic alignments than existing methodsand also produces competitive semanticparsers and improved language genera-tors.1 IntroductionMost approaches to learning semantic parsers thatmap sentences into complete logical forms (Zelleand Mooney, 1996; Zettlemoyer and Collins,2005; Kate and Mooney, 2006; Wong andMooney, 2007b; Lu et al, 2008) require fully-supervised corpora that provide full formal logi-cal representations for each sentence.
Such cor-pora are expensive and difficult to construct.
Sev-eral recent projects on ?grounded?
language learn-ing (Kate and Mooney, 2007; Chen and Mooney,2008; Chen et al, 2010; Liang et al, 2009) exploitmore easily and naturally available training dataconsisting of sentences paired with world statesconsisting of multiple potential semantic repre-sentations.
This setting is partially motivated by adesire to model how children naturally learn lan-guage in the context of a rich, ambiguous percep-tual environment.In particular, Chen and Mooney (2008) in-troduced the problem of learning to sportscastby simply observing natural language commen-tary on simulated Robocup robot soccer games.The training data consists of natural language(NL) sentences ambiguously paired with logicalmeaning representations (MRs) describing recentevents in the game extracted from the simulator.Most sentences describe one of the extracted re-cent events; however, the specific event to whichit refers is unknown.
Therefore, the learner hasto figure out the correct matching (alignment) be-tween NL and MR before inducing a semanticparser or language generator.
Based on an ap-proach introduced by Kate and Mooney (2007),Chen and Mooney (2008) repeatedly retrain botha supervised semantic parser and language gener-ator using an iterative algorithm analogous to Ex-pectation Maximization (EM).
However, this ap-proach is somewhat ad hoc and does not exploita well-defined probabilistic generative model orreal EM training.On the other hand, Liang et al (2009) in-troduced a probabilistic generative model forlearning semantic correspondences in ambigu-ous training data consisting of sentences pairedwith observed world states.
Compared to Chenand Mooney (2008), they demonstrated improvedalignment results on Robocup sportscasting data.However, their model only produces an NL?MRalignment and does not learn either an effective543semantic parser or language generator.
In addi-tion, they use a combination of a simple Markovmodel and a bag-of-words model when generatingnatural language for MRs, therefore, they do notmodel context-free linguistic syntax.Motivated by the limitations of these previ-ous methods, we propose a new generative align-ment model that includes a full semantic pars-ing model proposed by Lu et al (2008).
Ourapproach is capable of disambiguating the map-ping between language and meanings while alsolearning a complete semantic parser for mappingsentences to logical form.
Experimental resultson Robocup sportscasting show that our approachoutperforms all previous results on the NL?MRmatching (alignment) task and also produces com-petitive performance on semantic parsing and im-proved language generation.2 Related WorkThe conventional approach to learning seman-tic parsers (Zelle and Mooney, 1996; Ge andMooney, 2005; Kate and Mooney, 2006; Zettle-moyer and Collins, 2007; Zettlemoyer andCollins, 2005; Wong and Mooney, 2007b; Lu etal., 2008) requires detailed supervision unambigu-ously pairing each sentence with its logical form.However, developing training corpora for thesemethods requires expensive expert human labor.Chen and Mooney (2008) presented methodsfor grounded language learning from ambigu-ous supervision that address three related tasks:NL?MR alignment, semantic parsing, and natu-ral language generation.
They solved the prob-lem of aligning sentences and meanings by iter-atively retraining an existing supervised seman-tic parser, WASP (Wong and Mooney, 2007b) orKRISP (Kate and Mooney, 2006), or an existingsupervised natural-language generator, WASP?1(Wong and Mooney, 2007a).
During each iter-ation, the currently trained parser (generator) isused to produce an improved NL?MR alignmentthat is used to retrain the parser (generator) in thenext iteration.
However, this approach does notuse the power of a probabilistic correspondencebetween an NL and MRs during training.On the other hand, Liang et al (2009) pro-posed a probabilistic generative approach to pro-duce a Viterbi alignment between NL and MRs.They use a hierarchical semi-Markov generativemodel that first determines which facts to dis-cuss and then generates words from the predi-cates and arguments of the chosen facts.
They re-port improved matching accuracy in the Robocupsportscasting domain.
However, they only ad-dressed the alignment problem and are unable toparse new sentences into meaning representationsor generate natural language from logical forms.In addition, the model uses a weak bag-of-wordsassumption when estimating links between NLsegments and MR facts.
Although it does use asimple Markov model to order the generation ofthe different fields of an MR record, it does notutilize the full syntax of the NL or MR or theirrelationship.Chen et al (2010) recently reported resultson utilizing the improved alignment produced byLiang et al (2009)?s model to initialize their owniterative retraining method.
By combining the ap-proaches, they produced more accurate NL?MRalignments and improved semantic parsers.Motivated by this prior research, our approachcombines the generative alignment model ofLiang et al (2009) with the generative semanticparsing model of Lu et al (2008) in order to fullyexploit the NL syntax and its relationship to theMR semantics.
Therefore, unlike Liang et al?ssimple Markov + bag-of-words model for gener-ating language, it uses a tree-based model to gen-erate grammatical NL from structured MR facts.3 BackgroundThis section describes existing models and algo-rithms employed in the current research.
Ourmodel is built on top of the generative semanticparsing model developed by Lu et al (2008).
Af-ter learning a probabilistic alignment and parsingmodel, we also used the WASP and WASP?1 sys-tems to produce additional parsing and generationresults.
In particular, since our current system isincapable of effectively generating NL sentencesfrom MR logical forms, in order to demonstratehow our matching results can aid NL generation,we use WASP?1 to learn a generator.
This followsthe experimental scheme of Chen et al (2010),which demonstrated that an improved NL?MR544SS : pass (PLAYER, PLAYER)PLAYERPLAYER : pink10pink10passes the ball to PLAYERPLAYER : pink11pink11Figure 1: Sample hybrid tree from Englishsportscasting dataset where (w,m) = (pink10passes the ball to pink11, pass(pink10, pink11))matching from Liang et al (2009) results in betteroverall parsing and generation.
Finally, our over-all generative model uses the IGSL (Iterative Gen-eration Strategy Learning) method of Chen andMooney (2008) to initially estimate the prior prob-ability of each event-type generating a natural-language comment.3.1 Generative Semantic ParsingLu et al (2008) introduced a generative seman-tic parsing model using a hybrid-tree framework.A hybrid tree is defined over a pair, (w,m), of anatural-language sentence and its logical meaningrepresentation.
The tree expresses a correspon-dence between word segments in the NL and thegrammatical structure of the MR.
In a hybrid tree,MR production rules constitute the internal nodes,while NL words (or phrases) constitute the leaves.A sample hybrid tree from the English Robocupdata is given in Figure 1.A generative model based on hybrid trees is de-fined as follows: starting from a root semanticcategory, the model generates a production of theMR grammar, and then subsequently generates amixed hybrid pattern of NL words and child se-mantic categories.
This process is repeated un-til all leaves in the hybrid tree are NL words (orphrases).
Each generation step is only dependenton the parent step, thus, generation is assumed tobe a Markov process.Lu et al (2008)?s generative parsing model es-timates the joint probability P (T ,w,m), whichrepresents the probability of generating a hybridtree T with NL w, and MR m. This probabilityis computed as the product of the probabilities ofthe steps in the generative process.
Since there aremultiple ways to construct a hybrid tree given apair of NL and MR, the data likelihood of the pair(w,m) given by the learned model is calculatedby summing P (T ,w,m) over all the possible hy-brid trees for NL w and MR m.The model is normally trained in a fully su-pervised setting using NL?MR pairs.
In order tolearn from ambiguous supervision, we extend thismodel to include an additional generative processfor selecting the subset of available MRs used togenerate NL sentences.3.2 WASP and WASP?1WASP (Word-Alignment-based Semantic Parsing)is a semantic parsing system that uses syntax-based statistical machine translation techniques.
Itinduces a probabilistic synchronous context-freegrammar (PSCFG) for generating correspondingNL?MR pairs.
Since a PSCFG is symmetricwith respect to the two languages it generates,the same learned model can be used for both se-mantic parsing (mapping NL to MR) and naturallanguage generation (mapping MR to NL), Sincethere is no prespecified formal grammar for theNL, the WASP?1 system learns an n-gram lan-guage model for the NL side and uses it to choosethe most probable NL translation for a given MRusing a noisy-channel model.3.3 IGSLChen and Mooney (2008) introduced the IGSLmethod for determining which event types a hu-man commentator is more likely to describe innatural language.
This is sometimes called strate-gic generation or content selection, the process ofchoosing what to say; as opposed to tactical gen-eration, which determines how to say it.
IGSLuses a method analogous to EM to train on am-biguously supervised data and iteratively improveprobability estimates for each event type, speci-fying how likely each MR predicate is to elicita comment.
The algorithm alternates betweentwo processes: calculating the expected proba-bility of an NL?MR matching based on the cur-rently learned estimates, and updating the prob-ability of each event type based on the expectedmatch counts.
IGSL was shown to be quite effec-tive at predicting which events in a Robocup game545English Korean# of NL comments 2036 1999# of extracted MR events 10452 10668# of NLs w/ matching MRs 1868 1913# of MRs w/ matching NLs 4670 4610Avg.
# of MRs per NL 2.50 2.41Table 1: Stats for Robocup sportscasting dataa human would comment upon.
In our proposedmodel, we use IGSL probability scores as initialpriors for our event selection model.4 Evaluation DatasetIn our experiments, we use the Robocupsportscasting data produced by Chen et al (2010),which includes both English and Korean com-mentaries.
The data was collected by having bothEnglish and Korean speakers commentate the fi-nal games from the RoboCup simulation soccerleague for each year from 2001 through 2004.
Ta-ble 1 presents some statistics on this sportscastingdata.
To construct the ambiguous training data,each NL commentary sentence is paired with MRsfor all extracted simulation events that occurred inthe previous 5 seconds (an average of 2.5 events).Figure 2 shows a sample trace from theRobocup English data.
Each NL commentary sen-tence normally has several possible MR matchesthat occurred within the 5-second window, in-dicated by edges between the NL and MR.Bold edges represent gold standard matches con-structed solely for evaluation purposes.
Note thatnot every NL has a gold matching MR.
This oc-curs because the sentence refers to unrecognizedor undetected events or situations or because thematching MR lies outside the 5-second window.5 Generative ModelLike Liang et al (2009)?s generative alignmentmodel, our model is designed to estimate P (w|s),where w is an NL sentence and s is a world statecontaining a set of possible MR logical forms thatcan be matched to w. However, our approachis intended to support both determining the mostlikely match between an NL and its MR in itsworld state, and semantic parsing, i.e.
finding theNatural LanguageMeaningRepresentationPurple9 prepares to attackpass( PurplePlayer9, PurplePlayer6)defense( PinkPlayer6, PinkPlayer6 )Purple9 passes toPurple6Purple6'spass was defended by Pink6turnover( purple6 , pink6)ballstoppeduple6spasswasdefendedbyink6Pink6 makes ashort pass toPink3kick( PinkPlayer6 )pass( PinkPlayer6 ,PinkPlayer3)Pinkgoalie now has the ballplaymode( free_kick_r)pass( PinkPlayer3 ,PinkPlayer1)Figure 2: Sample trace from Robocup Englishdata.most probable mapping from a given NL sentenceto an MR logical form.Our generative model consists of two stages:?
Event selection: P (e|s), chooses the event ein the world state s to be described.?
Natural language generation: P (w|e), mod-els the probability of generating natural-language sentence w from the MR specifiedby event e.5.1 Event selection modelThe event selection model specifies the probabil-ity distribution for picking an event that is likelyto be commented upon amongst the multiple MRlogical forms in the world state s. The probabil-ity of picking an event is assumed to depend onlyon its event type as given by the predicate of itsMR.
For example, the MR pass(pink10, pink11)has event type pass and arguments pink10 andpink11.Our model is similar to Liang et al (2009)?srecord choice model, but we only model their no-tion of salience, denoting that some event typesare more likely to be described than others.
We donot model their notion of coherence, which mod-els the order of event types in the commentary.
Wefound that for sportscasting the order of describedevents depends only on the sequence of events inthe game and does not exhibit any additional de-tectable pattern due to linguistic preferences.The probability of picking an event e of type teis denoted by p(te).
If there are multiple eventsof type t in a world state s, then an event of typet is selected uniformly from the set s(t) of events546of type t in state s. Therefore, the probability ofpicking an event is given by:P (e|s) = p(te)1|s(te)|(1)5.2 Natural language generation modelThe natural-language generation model definesthe probability distribution of NL sentences givenan MR specified by the previously selected event.We use Lu et al (2008)?s generative model for thisstep, in which:P (w|e) =?
?T over (w,m)P (T ,w|m) (2)where m is the MR logical form defined by evente and T is a hybrid tree defined over the NL?MRpair (w,m).The probability P (T ,w|m) is calculated usingthe generative semantic parsing model of Lu et al(2008) using the joint probability of the NL?MRpair (w,m), i.e.
the inside probability of gener-ating (w,m).
The likelihood of a sentence w isthen the sum over all possible hybrid trees definedby the NL?MR pair (w,m).
1The natural language generation model coversthe roles of both the field choice model and wordchoice models of Liang et al (2009).
Since ourevent selection model only chooses an event basedon its type, the order of its arguments still needsto be addressed.
However, Lu et al?s generativemodel includes ordering the MR arguments (asspecified by MR production rules) as well as thegeneration of NL words and phrases to expressthese arguments.
Thus, it is unnecessary to sepa-rately model argument ordering in our approach.21Lu et al (2008) propose 3 models for generative seman-tic parsing: unigram, bigram, and mixgram (interpolation be-tween the two).
We used the bigram model, where the gen-eration of a hybrid-tree component (NL word or semanticcategory) depends on the previously generated component aswell as the parent MR production.
The bigram model alwaysperformed the best on all tasks in our experimental evalua-tion.2We also tried using a Markov model to order argumentslike Liang et al (2009), but preliminary experimental resultsshowed that this additional component actually decreasedperformance rather than improving it.6 Learning and InferenceThis composite generative model is trained usingconventional EM methods.
The process is similarto Lu et al (2008)?s, an inside-outside style al-gorithm using dynamic programming to generatea hybrid tree from the NL?MR pair (w,m), ex-cept our model?s estimation process additionallydeals with calculating expected counts under theposterior P (e|w, s; ?)
in the E-step and normaliz-ing the counts to optimize parameters.
The wholeprocess is quite efficient; training time takes about30 minutes to run on sportscasts of three games ineither English or Korean.Unfortunately, we found that EM tended to getstuck at local maxima with respect to learning theevent-type selection probabilities, p(t).
There-fore, we also tried initializing these parameterswith the corresponding strategic generation valueslearned by the IGSL method of Chen and Mooney(2008).
Since IGSL was shown to be quite effec-tive at predicting which event types were likely tobe described, the use of IGSL priors provides agood starting point for our event selection model.Our model is built on top of Lu et al (2008)?sgenerative semantic parsing model, which is alsotrained in several steps in its best-performing ver-sion.3 Thus, the overall model is vulnerable togetting stuck in local optima when running EMacross these multiple steps.
We also tried usingrandom restarts with different initialization of pa-rameters, but initializing with IGSL priors per-formed the best in our experimental evaluation.7 Experimental EvaluationWe evaluated our proposed model on the Robocupsportscasting data described in Section 4.
Our ex-perimental results cover 3 tasks: NL?MR match-ing, semantic parsing, and tactical generation.Following Chen and Mooney (2008), the exper-iments were conducted using 4-fold (leave onegame out) cross validation.
Since the corpus con-tains data for four separate games, each fold uses3 games for training and the remaining game for3The bigram model of Lu et al (2008), which is the oneused in this paper, must be trained using parameters previ-ously learned for the IBM Model 1 and unigram model inorder to exhibit the best performance.
We followed the sametraining scheme in our version.547testing for semantic parsing and tactical genera-tion.
Matching performance is measured in train-ing data, since the goal is to disambiguate thisdata.
All results are averaged across these 4 folds.We also use the same performance metricsas Chen and Mooney (2008).
The accuracy ofmatching and semantic parsing are measured us-ing F-measure, the harmonic mean of precisionand recall, where precision is the fraction of thesystem?s annotations that are correct, and recallis the fraction of the annotations from the gold-standard that the system correctly produces.
Gen-eration is evaluated using BLEU score (Papineniet al, 2002) between generated sentences and ref-erence NL sentences in the test set.
We com-pare our results to previous results from Chen andMooney (2008) and Chen et al (2010) and tomatching results on Robocup data from Liang etal.
(2009).7.1 NL?MR MatchingThe goal of matching is to find the most probableNL?MR alignment for ambiguous examples con-sisting of an NL sentence and multiple potentialMR logical forms.
In Robocup sportscasting, theMRs for a given sentence correspond to all gameevents that occur within a 5-second window priorto the NL comment.
Not all NL sentences have amatching MR in this window, but most do.
Dur-ing testing, an NL w is matched to an MR m ifand only if the learned semantic parser producesm as the most probable parse of w. Thus, ourmodel does not force every NL to match an MR.If the most probable semantic parse of a sentencedoes not match any of the possible recent events,it is simply left unmatched.
Matching is evaluatedagainst the gold-standard matches supplied withthe data, which are used for evaluation purposesonly.
The gold matching data is never used duringtraining.Table 2 shows the detailed results for bothEnglish and Korean data.4 Our best approachoutperforms all previous methods for both En-glish and Korean by quite large margins.
Note4Since the Korean data was not yet available for use byeither Chen and Mooney (2008) or Liang et al (2009), wepresent the results reported by Chen et al (2010) for thesemethods.English KoreanChen and Mooney (2008) 0.681 0.753Liang et al (2009) 0.757 0.694Chen et al (2010) 0.793 0.841Our model 0.832 0.800Our model w/ IGSL init 0.885 0.895Table 2: NL?MR Matching Results (F-measure).Results are the highest reported in the cited work.English KoreanChen and Mooney (2008) 0.702 0.720Chen et al (2010) 0.803 0.812Our learned parser 0.742 0.764Lu et al + our matching 0.810 0.794WASP + our matching 0.786 0.808Lu et al + Liang et al 0.790 0.690WASP + Liang et al 0.803 0.740Table 3: Semantic Parsing Results (F-measure).Results are the highest reported in the cited work.that initializing our EM training with IGSL?s es-timates improves performance significantly, andthis approach outperforms Chen et al (2010)?sbest method, which also uses IGSL.In particular, our proposed model outperformsthe generative alignment model of Liang et al(2009), indicating that the extra linguistic infor-mation and MR grammatical structure used by Luet al (2008)?s generative language model makeour overall model more effective than a simpleMarkov + bag-of-words model for language gen-eration.7.2 Semantic ParsingSemantic parsing is evaluated by determining howaccurately NL sentences in the test set are cor-rectly mapped to their meaning representations.Results are presented in Table 3.5 6 For ourmodel, we report results using the parser learneddirectly from the ambiguous supervision, as well5The best result of Chen and Mooney (2008) is forWASPER-GEN, and that of Chen et al (2010) is for WASPERwith Liang et al?s matching initialization for English and forWASER-GEN-IGSL-METEOR with Liang et al?s initializationfor Korean.6Our semantic parsing results are based on our bestmatching results with IGSL initialization.548as results for training a supervised parser (bothWASP and Lu et al (2009)?s) on the NL?MRmatching produced by our model.
We also presentresults for training Lu et al?s parser and WASP onLiang et al?s NL?MR matchings.Our initial learned semantic parser does not per-form better than the best results reported by Chenet al (2010), but it is clearly better than the ini-tial results of Chen and Mooney (2008).
Train-ing WASP and Lu et al?s supervised parser onour method?s highly accurate set of disambiguatedNL?MR pairs improved the results.
Retraining Luet al?s parser gave the best overall results for En-glish, and retraining WASP gave the second high-est results for Korean, only failing to beat the verybest results of Chen et al (2010).
It is somewhatsurprising that simply retraining on the hardenedset of most probable NL?MR matches gives bet-ter results than the parser trained using EM, whichactually exploits the uncertainty in the underly-ing matches.
Further investigations of this phe-nomenon are indicated.Comparing with the corresponding results fortraining WASP and Lu et al?s supervised parseron the NL?MR matchings produced by Liang etal.
?s alignment method, it is clear that our match-ings produce more accurate semantic parsers ex-cept when training WASP on English.7.3 Tactical GenerationTactical generation is evaluated based on howwell the learned model generates accurate NL sen-tences from MR logical forms.
Without integrat-ing a language model for the NL, the existinggenerative model is not very effective for tacticalgeneration.
Lu et al (2009) introduced an effec-tive language generator for the hybrid tree frame-work using a Tree-CRF model; however, we didnot have access to this system.
Therefore, fortactical generation, we used the publicly avail-able WASP?1 system (Wong and Mooney, 2007a)trained on disambiguated NL?MR matches.
Thisapproach also allows direct comparison with theresults of Chen and Mooney (2008) and Chen etal.
(2010), who also used WASP?1 for tacticalgeneration.
Our objective is to show that the moreaccurate matchings produced by our generativemodel can improve tactical generation.English KoreanChen and Mooney (2008) 0.4560 0.5575Chen et al (2010) 0.4599 0.6796WASP?1 + Liang et al 0.4580 0.5828WASP?1 + our matching 0.4727 0.7148Table 4: Tactical Generation Results (BLEUscore).
Results are the highest reported in the citedwork.The results are shown in Table 4.7 8 Overall,WASP?1 trained on the NL?MR matching fromour alignment model performs better than all pre-vious methods.
In particular, using the matchingsfrom our method to train WASP?1 produces bet-ter tactical generators than using matchings fromLiang et al?s approach.7.4 DiscussionOverall, our model performs particularly well atmatching NL and MRs under ambiguous supervi-sion, and the difference is larger for English thanKorean.
However, improved matching results donot necessarily translate into significantly bettersemantic parsers.
For English, the improvementin matching is almost 10 percentage points in F-measure, but the semantic parsing result trainedwith this more accurate matching shows only 1point improvement.Compared to Liang et al (2009), our more ac-curate (i.e.
higher F-measure) matchings providea clear improvement in both semantic parsing andtactical generation.
The only exception is Englishparsing using WASP, which seems to be due tosome misleading noise in our alignments.
WASPseems to be affected more than Lu et al?s systemby such extraneous noise.
However, in tacticalgeneration, this extraneous noise does not seem tolead to worse performance, and our approach al-ways gives the best results.
As discussed by Chenand Mooney (2008) and Chen et al (2010), tac-tical generation is somewhat easier than seman-tic parsing in that semantic parsing needs to learn7The best result of Chen and Mooney (2008) is forWASPER-GEN, and that of Chen et al (2010) is for WASPERwith Liang et al?s matching initialization for English and forWASER-GEN with Liang et al initialization for Korean.8Our generation results are based on our best matchingresults with IGSL initialization.549to map a variety of synonymous natural-languageexpressions to the same meaning representation,while tactical generation only needs to learn oneway to produce a correct natural language descrip-tion of an event.
This difference in the nature ofsemantic parsing and tactical generation may bethe cause of the different trends in the results.8 Conclusions and Future WorkWe have presented a novel generative model capa-ble of probabilistically aligning natural-languagesentences to their correct meaning representa-tions given the ambiguous supervision providedby a grounded language acquisition scenario.
Ourmodel is also capable of simultaneously learningto semantically parse NL sentences into their cor-responding meaning representations.
Experimen-tal results in Robocup sportscasting show that theNL?MR matchings inferred by our model are sig-nificantly more accurate than those produced byall previous methods.
Our approach also learnscompetitive semantic parsers and improved lan-guage generators compared to previous methods.In particular, we showed that our alignments pro-vide a better foundation for learning accurate se-mantic parsers and tactical generators comparedto those of Liang et al (2009), whose genera-tive model is limited by a simple bag-of-words as-sumption.In the future, we plan to test our model onmore complicated data with higher degrees of am-biguity as well as more complex meaning repre-sentations.
One immediate direction is evaluat-ing our approach on the datasets of weather fore-casts and NFL football articles used by Liang et al(2009).
However, our current model does not sup-port matching multiple meaning representationsto the same natural-language sentence, and needsto be extended to allow multiple MRs to generatea single NL sentence.AcknowledgementsWe thank Wei Lu and Wee Sun Lee for sharingtheir software and giving helpful comments forthe paper.
We also thank Percy Liang for sharinghis code and experimental results with us.
Ad-ditionally, we thank David Chen in UTCS MLgroup for his comments and advice.
Finally, wethank the anonymous reviewers for their com-ments.
This work was funded by the NSF grantIIS.
0712907X.
The experiments were executedand run on the Mastodon Cluster, provided byNSF Grant EIA-0303609.ReferencesChen, David L. and Raymond J. Mooney.
2008.Learning to sportscast: a test of grounded languageacquisition.
In ICML ?08: Proceedings of the25th International Conference on Machine Learn-ing, pages 128?135, New York, NY, USA.
ACM.Chen, David L., Joohyun Kim, and Raymond J.Mooney.
2010.
Training a multilingualsportscaster: Using perceptual context to learn lan-guage.
Journal of Artificial Intelligence Research,37:397?435.Ge, Ruifang and Raymond J. Mooney.
2005.
A sta-tistical semantic parser that integrates syntax andsemantics.
In Proceedings of the Ninth Confer-ence on Computational Natural Language Learning(CoNLL-2005), pages 9?16, Ann Arbor, MI, July.Kate, Rohit J. and Raymond J. Mooney.
2006.
Us-ing string-kernels for learning semantic parsers.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguis-tics (COLING/ACL-06), pages 913?920, Morris-town, NJ, USA.
Association for Computational Lin-guistics.Kate, Rohit J. and Raymond J. Mooney.
2007.
Learn-ing language semantics from ambiguous supervi-sion.
In Proceedings of the Twenty-Second Con-ference on Artificial Intelligence (AAAI-07), pages895?900, Vancouver, Canada, July.Liang, Percy, Michael I. Jordan, and Dan Klein.
2009.Learning semantic correspondences with less super-vision.
In ACL-IJCNLP ?09: Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP: Vol-ume 1, pages 91?99, Morristown, NJ, USA.
Associ-ation for Computational Linguistics.Lu, Wei, Hwee Tou Ng, Wee Sun Lee, and Luke S.Zettlemoyer.
2008.
A generative model for pars-ing natural language to meaning representations.
InEMNLP ?08: Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,pages 783?792, Morristown, NJ, USA.
Associationfor Computational Linguistics.550Lu, Wei, Hwee Tou Ng, and Wee Sun Lee.
2009.
Nat-ural language generation with tree conditional ran-dom fields.
In EMNLP ?09: Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 400?409, Morristown,NJ, USA.
Association for Computational Linguis-tics.Papineni, Kishore, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: a method for auto-matic evaluation of machine translation.
In Pro-ceedings of the 40th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL-2002),pages 311?318, Philadelphia, PA, July.Wong, Yuk Wah and Raymond J. Mooney.
2007a.Generation by inverting a semantic parser that usesstatistical machine translation.
In Proceedings ofHuman Language Technologies: The Conference ofthe North American Chapter of the Association forComputational Linguistics (NAACL-HLT-07), pages172?179, Rochester, NY.Wong, Yuk Wah and Raymond J. Mooney.
2007b.Learning synchronous grammars for semantic pars-ing with lambda calculus.
In Proceedings of the45th Annual Meeting of the Association for Com-putational Linguistics (ACL-07), pages 960?967,Prague, Czech Republic, June.Zelle, John M. and Raymond J. Mooney.
1996.
Learn-ing to parse database queries using inductive logicprogramming.
In Proceedings of the Thirteenth Na-tional Conference on Artificial Intelligence (AAAI-96), pages 1050?1055, Portland, OR, August.Zettlemoyer, Luke S. and Michael Collins.
2005.Learning to map sentences to logical form: Struc-tured classification with probabilistic categorialgrammars.
In Proceedings of 21st Conference onUncertainty in Artificial Intelligence (UAI-2005),Edinburgh, Scotland, July.Zettlemoyer, Luke S. and Michael Collins.
2007.
On-line learning of relaxed CCG grammars for parsingto logical form.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL-07), pages 678?687, Prague, Czech Republic, June.551
