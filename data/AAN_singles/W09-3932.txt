Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 217?224,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsEffects of Conversational Agents on Human Communicationin Thought-Evoking Multi-Party DialoguesKohji DohsakaNTT Communication Science LaboratoriesNTT Corporation2-4, Hikaridai, Seika-cho,Kyoto 619-0237, JapanRyota AsaiGraduate School ofInformation Science and TechnologyOsaka University, 1-1 Yamadaoka,Suita, Osaka 565-0871, JapanRyuichiro Higashinaka and Yasuhiro Minami and Eisaku MaedaNTT Communication Science Laboratories, NTT Corporation2-4, Hikaridai, Seika-cho, Kyoto 619-0237, Japan{dohsaka,rh,minami,maeda}@cslab.kecl.ntt.co.jpAbstractThis paper presents an experimentalstudy that analyzes how conversationalagents activate human communication inthought-evoking multi-party dialogues be-tween multi-users and multi-agents.
Athought-evoking dialogue, which is a kindof interaction in which agents act on userwillingness to provoke user thinking, hasthe potential to stimulate multi-party in-teraction.
In this paper, we focus onquiz-style multi-party dialogues betweentwo users and two agents as an exampleof a thought-evoking multi-party dialogue.The experiment results showed that thepresence of a peer agent significantly im-proved user satisfaction and increased thenumber of user utterances.
We also foundthat agent empathic expressions signifi-cantly improved user satisfaction, raiseduser ratings of a peer agent, and increaseduser utterances.
Our findings will be use-ful for stimulating multi-party communi-cation in various applications such as ed-ucational agents and community facilita-tors.1 IntroductionConversational interfaces including dialogue sys-tems and conversational agents have been typi-cally used as a single interface to a single user (Zueet al, 1994; Allen et al, 2001; Cassell et al,2000).
On the other hand, a new area of re-search in conversational interfaces is dealing withmulti-party interaction (Traum and Rickel, 2002;Liu and Chee, 2004; Zheng et al, 2005).
Multi-party conversational interfaces have been appliedto such tasks as training decision-making in teamactivities (Traum and Rickel, 2002), collabora-tive learning (Liu and Chee, 2004), and coordinat-ing and facilitating interaction in a casual socialgroup (Zheng et al, 2005).The advantage of such multi-party dialoguesover two-party cases is that the multi-party caseencourages group interaction and collaborationamong human users.
This advantage can be ex-ploited to foster such human activities as studentlearning in more social settings and to build andmaintain social relationships among people.
How-ever, unless users actively engage in the interac-tion, these multi-party dialogue qualities cannotbe adequately exploited.
Our objective is to stim-ulate human communication in multi-party dia-logues between multi-users and multi-agents byraising user willingness to engage in the interac-tion and increasing the number of user utterances.As the first step toward this objective, we ex-ploit a new style of dialogue called thought-evoking dialogue and experimentally investigatethe impact of a peer agent?s presence and agentemotional expressions on communication activa-tion in thought-evoking multi-party dialogues.
Athought-evoking dialogue, an interaction in whichagents act on the willingness of users to provokeuser thinking and encourage involvement in thedialogue, has the potential to activate interactionamong participants in multi-party dialogues.Previous work proposed a quiz-style informa-tion presentation dialogue system (hereafter quiz-style dialogue system) (Higashinaka et al, 2007a)that is regarded as a kind of thought-evoking di-alogue system.
This system conveys contents asbiographical facts of famous people through quiz-style interaction with users by creating a ?Whois this??
quiz and individually presenting hints.217The hints are automatically created from the bi-ographical facts of people and ordered based onthe difficulty naming the people experienced bythe users (Higashinaka et al, 2007b).
Since theuser has to consider the hints to come up with rea-sonable answers, the system stimulates user think-ing.
This previous work reported that, for in-teraction between a single user and a computer,a quiz-style dialogue improved user understand-ing and willingness to engage in the interaction.In this paper, we focus on a quiz-style informa-tion presentation multi-party dialogue (hereafterquiz-style multi-party dialogue) as an example ofa thought-evoking multi-party dialogue.A peer agent acts as a peer of the users and par-ticipates in the interactions in the same way thatthe users do.
We are interested in the peer agent?srole in quiz-style multi-party dialogues since thepositive effects of a peer agent on users have beenshown in the educational domain (Chou et al,2003; Maldonado et al, 2005), which is a promis-ing application area for quiz-style dialogues.
Inthe educational domain, a user could benefit notonly from direct communication with a peer agentbut also from overhearing dialogues between apeer agent and a tutor.
Learning by observing oth-ers who are learning is called vicarious learningand positively affects user performance (Craig etal., 2000; Stenning et al, 1999).
To the best of ourknowledge, detailed experimental investigationson the effect of a peer agent on communicationactivation have not been reported in multi-partydialogues between multi-users and multi-agents,which are our main concern in this paper.The topic of emotion has gained widespreadattention in human-computer interaction (Bates,1994; Picard, 1997; Hudlicka, 2003; Prendingerand Ishizuka, 2004).
The impact of an agent?semotional behaviors on users has also recentlybeen studied (Brave et al, 2005; Maldonado etal., 2005; Prendinger et al, 2005).
However, theseprevious studies addressed scenario-based interac-tion in which a user and an agent acted with prede-termined timing.
In this paper, we investigate theimpact of agent emotional expressions on users inmulti-party dialogues in which multiple users andagents can make utterances with more flexible tim-ing.Resembling work by Brave et al (2005), weclassify agent emotional expressions into em-pathic and self-oriented ones and investigate theirimpact on users in a thought-evoking multi-partydialogue system.
As stated above, Brave etal.
(2005) addressed scenario-based Black-jack in-teraction, but we deal with multi-party dialoguesthat enable more flexible turn-taking.
Previousstudies (Bickmore and Picard, 2005; Higashinakaet al, 2008) showed that agent empathic expres-sions have a positive psychological impact uponusers, but they only examined two-party cases.Although Traum et al (2002) and Gebhard etal.
(2004) exploited the role of agent emotion inmulti-party dialogues, they did not adequately ex-amine the effects of agent emotion on communi-cation activation by experiment.In this work, we deal with disembodied agentsand focus on their linguistic behaviors.
We believethat our results are useful for designing embodiedconversational agents using other modalities.This paper presents an experimental study thatanalyzes how agents stimulate human communi-cation in quiz-style multi-party dialogues betweentwo users and two agents.
We are especially inter-ested in how the presence of a peer agent and agentemotional expressions improve user satisfaction,enhance user opinions about the peer agent, andincrease the number of user utterances.
Our find-ings will be useful for stimulating human com-munication in various applications such as educa-tional agents and community facilitators.In the following, Section 2 shows an overviewof our quiz-style multi-party dialogue system.Section 3 explains the experiment design, and Sec-tion 4 describes the results.
Section 5 concludesthe paper.2 Thought-Evoking Multi-PartyDialogue SystemWe implemented a quiz-style multi-party dialoguesystem between multi-users and multi-agents.
Thesystem is a Japanese keyboard-based dialogue sys-tem with a chat-like interface.
The users can makeutterances any time they want.
A user utteranceis completed and displayed on the chat windowwhen the Enter key is pressed.Our experiment dealt with cases where twousers and two agents engaged in a dialogue.
Thetwo agents are a quizmaster and a peer.
The quiz-master agent creates a ?Who is this??
quiz abouta famous person and presents hints one by one tothe users and the peer agent who guess the correctanswer.2181 Whowho Who is this?
First hint: Graduatedfrom the University of Tokyo.2 Mary I don?t know.3 Kinoko Yoshida Shigeru.4 Whowho No, not even close!5 Jane That?s very difficult.6 Kinoko Difficult for me, too.7 Whowho Second hint: Born in Ushigome,Edo....8 Whowho Third hint: Novelist and scholar ofBritish literature.9 Mary Murakami Haruki.10 Whowho Close!11 Kinoko You are close.
Excellent.12 Jane Well then, who is it?13 Whowho Fourth hint: Familiar with Haiku,Chinese poetry, and calligraphy.14 Mary Natsume Soseki.15 Whowho That?s right.
Wonderful.16 Kinoko Mary, excellent.
I?m happy foryou.17 Jane Mary, that?s the right answer.
Goodjob.Figure 1: Sample dialogueFigure 1 shows a sample dialogue.
Mary andJane are human users.
Whowho is the quizmasteragent, and Kinoko is the peer agent.
Quizmasteragent Whowho presents hints in lines 1, 7, 8, and13.
Users Mary and Jane and peer agent Kinokogive answers in lines 3, 9, and 14.The hints were automatically created usingbiographical facts (in Japanese) of people inWikipedia 1 based on a previously reportedmethod (Higashinaka et al, 2007b).2.1 Dialogue actsThe users and the two agents perform several dia-logue acts based on the dialogue context.Present-hint: The quizmaster agent presentshints one by one (lines 1, 7, 8, and 13) in thesample dialogue shown in Figure 1.Give-ans: Users and the peer agent give answers(lines 3, 9, and 14).Show-difficulty: Users and the peer agent offeropinions about the quiz difficulty (lines 2, 5,6, and 12).1http://ja.wikipedia.org/Evaluate-ans: When the answer is wrong, thequizmaster agent evaluates the answer basedon the person-name similarity score (Hi-gashinaka et al, 2007a) and utters ?veryclose!,?
?close!,?
?a little close!,?
?a little far,??far,?
or ?not even close!?
(lines 4 and 10).Complete-quiz-with-success: When the rightanswer is given, the quizmaster agent in-forms the dialogue participants that thecurrent quiz is completed (line 15).Complete-quiz-with-failure: If all hints havebeen generated and no right answer is given,the quizmaster agent gives the right answer,and the current quiz is completed.Feedback-on-wrong-ans: Users and the peeragent give feedback when their own or theother?s answers are wrong during the currentquiz (line 11).Feedback-on-success: Users and the peer agentgive feedback when their own or the other?sanswers are right and the current quiz sessionis completed (lines 16 and 17).Feedback-on-failure: Users and the peer agentgive feedback when the current quiz is com-pleted without the right answer.Address-hearer: Users and the two agents spec-ify an intended addressee by uttering theother?s name (lines 16 and 17).When a user utterance is input, the system sep-arates it into word tokens using a Japanese mor-phological analyzer and converts it into dialogueacts using hand-crafted grammar.
The system canrecognize 120,000 proper names of persons.2.2 Utterance generationSurface realization forms were prepared for eachdialogue act by the agents.
Agent utterances aregenerated by randomly selecting one of the forms.Some agent dialogue acts can be generatedwith emotional expressions.
Agent emotional ex-pressions are categorized into empathic and self-oriented ones (Brave et al, 2005).
The agentself-oriented emotional expressions (self-orientedexpressions) are oriented to their own state, andthe agent empathic expressions are oriented to theother?s state and are congruent with the other?s219Dialog act Emotion ExpressionsShow-difficultyEMP Difficult for me, too.Show-difficultySELF I don?t remember.That?s so frustrating.Show-difficultyNONE I don?t know.Feedback-on-successEMP You?re right.
I?mhappy for you.Feedback-on-successSELF I?m really glad I gotthe correct answer.Feedback-on-successNONE You?re right / I?mright.Feedback-on-failureEMP Too bad you didn?tknow the right an-swer.Feedback-on-failureSELF I?m disappointedthat I didn?t knowthe right answer.Feedback-on-failureNONE I/You didn?t knowthe right answer.Table 1: Examples of agent expressions.
EMPshows empathic expressions, SELF shows self-oriented expressions, and NONE shows neutralexpressions when neither emotion is present.welfare.
As explained in 3.1, we prepared differ-ent experimental conditions to determine the pres-ence/absence of agent empathic and self-orientedexpressions.
Based on the conditions, we con-trolled the agent emotional expressions.
Table 1shows examples of agent empathic, self-oriented,and neutral expressions.2.3 Dialogue managementThe system maintains a dialogue state in whichthe history of the participant?s dialogue acts isrecorded with the time of each act.
We preparedpreconditions of each dialogue act by the agents.For example, the quizmaster agent?s Evaluate-ans can be executed after the users or the peeragent provides a wrong answer.
The peer agent?sFeedback-on-success can be executed after thequizmaster agent performs Complete-quiz-with-success.
We also used the following turn-takingrules:1.
Either agent must talk when neither the usersnor the agents make utterances within a giventime (4 sec.
).Condition PeeragentEmpathic Self-oriented(0) Absent Absent Absent(1) Present Absent Absent(2) Present Present Absent(3) Present Absent Present(4) Present Present PresentTable 2: Experimental conditions based on pres-ence/absence of peer agent and agent empathicand self-oriented expressions2.
Agents must not talk for a given time (0.5sec.)
after the others talk.3.
The quizmaster agent must move to the nexthint when neither the users nor the peer agentgive a correct answer within a given time (30sec.
).Based on the dialogue state, the preconditionsof the dialogue acts and the turn-taking rules, thesystem chooses the next speaker and its dialogueact.3 Experiment3.1 Experimental conditionsTo evaluate the effects of the presence of the peeragent and the agent emotional expressions, weprepared five systems under different experimen-tal conditions, (0), (1), (2), (3), and (4), based onthe presence/absence of the peer agent and agentempathic and self-oriented expressions.
They areshown in Table 2.
In condition (0), the peer agentwas absent, and only the quizmaster agent waspresent.
In other conditions, both the quizmas-ter and peer agents were present.
In conditions(0) and (1), neither empathic nor self-oriented ex-pressions were exhibited.
In condition (2), onlyempathic expressions were exhibited.
In condition(3), only self-oriented expressions were exhibited.In condition (4), both empathic and self-orientedexpressions were exhibited.We evaluated the effects of the presence of thepeer agent by comparing conditions (0) and (1).We evaluated the effects of agent empathic andself-oriented expressions by comparing conditions(1), (2), (3), and (4).3.2 MeasuresWe used three measures: user satisfaction, useropinions about the peer agent, and the number of220Questionnaire itemsQ1 Did you want to converse with this sys-tem again?
(Willingness to engage in di-alogue)Q2 Was the dialogue enjoyable?
(Pleasant-ness of dialogue)Q3 Did you feel satisfied using the dialoguesystem?
(Satisfaction of system usage)Q4 Was the peer agent friendly?
(Agent?scloseness)Q5 Did you feel that the peer agent caredabout you?
(Agent?s caring)Q6 Was the peer agent likable?
(Agent?s lik-ability)Q7 Did the peer agent support you?
(Agent?s support)Table 3: Questionnaire items to evaluate user sat-isfaction (Q1, Q2, and Q3) and user opinionsabout the peer agent (Q4, Q5, Q6, and Q7)user utterances.
Among these measures, we re-garded the number of user utterances as an ob-jective measure to evaluate communication activa-tion.
User satisfaction and opinions about the peeragent are subjective measures based on the ques-tionnaires (ten-point Likert scale).
Table 3 showsthe questionnaires used in the experiment.
We ex-pected that a high level of user satisfaction andpositive opinions about the peer agent would leadto a high level of user engagement, which wouldpromote user utterances.User satisfaction was evaluated from differentperspectives with three questions: Q1, Q2, andQ3.
Q1 focused on user willingness to engage inthe dialogue; Q2 focused on the user experienceof the dialogue?s pleasantness; Q3 focused on usersatisfaction with the system.
We evaluated usersatisfaction with averages of the ratings of Q1, Q2,and Q3.
Using the averaged ratings of Likert ques-tions allows us to apply such parametric statisticaltests as a multi-factor ANOVA since the summedor averaged responses to Likert questions tend tofollow a normal distribution.User opinions about the peer agent were evalu-ated in terms of how the user perceived the peeragent?s closeness (Q4), its caring (Q5), its likabil-ity (Q6), and its support (Q7).
We evaluated useropinions about the peer agent with the averagedratings of these items.
Previous studies showedthat empathic behaviors exhibited by an agent im-proved user opinions about the agent in a Black-jack scenario (Brave et al, 2005) and in a socialdialogue between a single user and an agent (Hi-gashinaka et al, 2008).
We examined these itemsin multi-party dialogues with flexible turn-taking.3.3 ProcedureWe recruited and paid 64 Japanese adults (32males and 32 females) for their participation.
Themean ages of the male and female groups were32.0 and 36.2, respectively (male group: SD=9.2, min=22, max=59, female group: SD=9.6,min=20, max=50).
The participants were dividedinto 32 pairs of the same gender: 16 pairs of malesand 16 pairs of females.
The participants in eachpair were unacquainted.The experiment had a within-participants de-sign.
Each pair of participants successively en-gaged in dialogues using the five systems underdifferent experimental conditions.
The order ofusing the systems was counter-balanced to preventorder effect.Before starting the experiment, the participantswere informed that, after completing a dialoguewith each system, they would fill out question-naires.
The questionnaires on user opinions aboutthe peer agent were used only when it was present(conditions (1), (2), (3), and (4)).
The participantswere also told that the agents were computer pro-grams and not human participants.
During the ex-periment, each pair of participants was seated inseparate rooms in front of a computer display, akeyboard, and a mouse, and they could only com-municate with each other through the system.In the dialogue with each system, five ?Whois this??
quizzes about famous people were pre-sented.
The quiz subjects were chosen so thatthe difficulty level of the quizzes was approxi-mately the same in all the systems.
For this pur-pose, we first sorted people in Wikipedia in de-scending order by their PageRank TM score basedon Wikipedia?s hyper-link structure.
We then ex-tracted the top-50 people and divided them fromthe top into five groups of 10.
Next we randomlyselected five people from each group to makefive sets of five people of approximately identicalPageRank scores.
Each set of five people was usedfor quizzes in each system.On average, a pair of participants took 18 min-utes to complete a dialogue with each system.
Thenumber of hints that were actually presented in a221Figure 2: User satisfactionquiz averaged 7.5.4 Results4.1 User satisfactionFor questions Q1, Q2, and Q3, Cronbach?s alphawas 0.83, which justified combining these itemsinto a single index.
Therefore we evaluated usersatisfaction with averages of the ratings of theseitems.
Figure 2 shows user satisfaction under eachexperimental condition.To evaluate the effect of the peer agent?s pres-ence on user satisfaction, we compared conditions(0) and (1).
The F-test results showed that vari-ances were assumed to be equal across groups(p > 0.2), and the Kolmogorov-Smirnov test re-sults showed that the assumption of normality wassatisfied (p > 0.6).
By applying the paired t-testto both the male and female groups, we found thatthe peer agent?s presence significantly improveduser satisfaction (male group: t(31) = 4.2, p <0.001, female group: t(31) = 2.8, p < 0.008).To evaluate the effect of the empathic and self-oriented expressions exhibited by the agents onuser satisfaction, we compared conditions (1),(2), (3), and (4).
A three-factor ANOVA wasconducted with two within-participant factors ofempathic and self-oriented expressions and onebetween-participant factor of gender.
The F-testfor the homogeneity of variances (p > 0.1) andthe Kolmogorov-Smirnov normality test (p > 0.1)showed that the data met the ANOVA assump-tions.
As a result of the ANOVA, a signifi-cant main effect was found for empathic expres-sions with respect to user satisfaction, F (1, 62) =92.7, p < 0.001.
No significant main effects werefound for either self-oriented expressions or gen-der, and there were no significant interactions.Figure 3: User ratings of peer agentThese results showed that the peer agent?s pres-ence and the agent empathic expressions signif-icantly improved user satisfaction in quiz-stylemulti-party dialogues.4.2 User opinions about the peer agentFor questions Q4, Q5, Q6, and Q7, Cronbach?salpha was 0.92, which justified combining theseitems into a single index.
Therefore we evaluateduser opinions about the peer agent with the aver-aged ratings of these items under each experimen-tal condition.
Figure 3 shows the user ratings ofthe peer agent under each condition.To evaluate the effect of agent empathic andself-oriented expressions on the user ratings of thepeer agent, we compared conditions (1), (2), (3)and (4).
A three-factor ANOVA was conductedwith two within-participant factors of empathicand self-oriented expressions and one between-participant factor of gender.
The F-test for thehomogeneity of variances (p > 0.3) and theKolmogorov-Smirnov normality test (p > 0.2)showed that the data met the ANOVA assump-tions.
As a result of the ANOVA, a significantmain effect was found for empathic expressionswith respect to the user ratings of the peer agent,F (1, 62) = 77.4, p < 0.001.
There was amoderate main effect for self-oriented expressionswith respect to the user ratings of the peer agent,F (1, 62) = 4.38, p < 0.04.
There were no sig-nificant main effects for gender, and there were nosignificant interactions.These results showed that agent empathic ex-pressions significantly improved user ratings ofthe peer agent in quiz-style multi-party dialogues.222Figure 4: User utterances per quiz hint4.3 Number of user utterancesFigure 4 shows the number of user utterances perquiz hint under each condition.To evaluate the effect of the peer agent?s pres-ence on the number of user utterances per quizhint, we compared conditions (0) and (1).
Basedon the F-test and the Kolmogorov-Smirnov test,the assumptions of variance homogeneity (p >0.6) and normality (p > 0.5) were met.
By apply-ing the paired t-test to both the male and femalegroups, we found that the presence of the peeragent significantly increased the number of userutterances per hint (male group: t(31) = 3.1, p <0.004, female group: t(31) = 5.6, p < 0.001).To evaluate the effect of empathic and self-oriented expressions by agents on the numberof user utterances, we compared conditions (1),(2), (3), and (4).
A three-factor ANOVA wasconducted with two within-participant factors ofempathic and self-oriented expressions and onebetween-participant factor of gender.
The F-testfor the homogeneity of variances (p > 0.05) andthe Kolmogorov-Smirnov normality test (p > 0.6)showed that the data met the ANOVA assump-tions.
As a result of the ANOVA, a significantmain effect was found for empathic expressionswith respect to the number of user utterances,F (1, 62) = 18.9, p < 0.001.
No significant maineffects were found for either self-oriented expres-sions or gender, and there were no significant in-teractions.These results showed that the peer agent?s pres-ence and agent empathic expressions increasedthe number of user utterances and stimulated hu-man communication in quiz-style multi-party dia-logues.5 ConclusionThis paper experimentally analyzed how conver-sational agents stimulate human communicationin thought-evoking multi-party dialogues betweenmulti-users and multi-agents.
As an example ofsuch multi-party dialogue, we focused on quiz-style multi-party dialogues between two users andtwo agents.
We investigated how a peer agent?spresence and agent emotional expressions influ-enced user satisfaction, the user ratings of the peeragent, and the number of user utterances.
Theuser ratings of the peer agent included user?s per-ceived closeness, likability and caring from thepeer agent, and the user?s feeling of being sup-ported by the peer agent.The experiment results showed that the peeragent?s presence significantly improved user sat-isfaction and increased the number of user utter-ances.
We also found significant effects that agentempathic expressions improved user satisfactionand user positive ratings of the peer agent and thatthey further increased the number of user utter-ances.
These results indicate that employing a peeragent and agent empathic behaviors in thought-evoking multi-party dialogues will stimulate inter-action among people in computer-mediated com-munication.
Our findings will be useful for abroader class of applications such as educationalagents and community facilitators.Many directions for future work remain.
First,we plan to extend our work to deal with variousmodalities such as speech, gestures, body posture,facial expressions, and the direction of eye gazesto investigate the effects of agent representation(embodied or disembodied) and other modalitiesin thought-evoking multi-party dialogues.
Second,we will analyze how agent behaviors influenceusers and dialogues in more detail and develop amore sophisticated dialogue management methodbased on our detailed analysis.
Learning optimaldialogue management strategies in multi-party di-alogues is a challenging research topic.
Third, ex-amining the relationship between user personalitytraits and the impact of agents on users is valuable.Previous work reported that the effect of embodi-ment depended on user personalities (Lee et al,2006).
This direction is important to the stimula-tion of multi-party interaction for therapeutic andemotional support.223ReferencesJames Allen, Donna Byron, Myroslava Dzikovska,George Ferguson, Lucian Galescu, and AmandaStent.
2001.
Toward conversational human-computer interaction.
AI Magazine, 22(4):27?37.Joseph Bates.
1994.
The role of emotion in believableagents.
Communications of the ACM, 37(7):122?125.Timothy W. Bickmore and Rosalind W. Picard.
2005.Establishing and maintaining long-term human-computer relationships.
ACM Transactions onComputer-Human Interaction, 12(2):293?327.Scott Brave, Clifford Nass, and Kevin Hutchinson.2005.
Computers that care: investigating the effectsof orientation of emotion exhibited by an embodiedcomputer agent.
International Journal of Human-Computer Studies, 62(2):161?178.Justine Cassell, Joseph Sullivan, Scott Prevost, andElizabeth Churchill, editors.
2000.
Embodied Con-versational Agents.
MIT Press, Cambridge, MA.Chih-Yueh Chou, Tak-Wai Chan, and Chi-Jen Lin.2003.
Redefining the learning companion: the past,present, and future of educational agents.
Comput-ers & Education, 40(3):255?269.Scotty D. Craig, Barry Gholson, Matthew Ventura,Arthur C. Graesser, and the Tutoring ResearchGroup.
2000.
Overhearing dialogues and mono-logues in virtual tutoring sessions: Effects on ques-tioning and vicarious learning.
International Jour-nal of Artificial Intelligence in Education, 11:242?253.Patrick Gebhard, Martin Klesen, and Thomas Rist.2004.
Coloring multi-character conversationsthrough the expression of emotions.
In LectureNotes in Computer Science (Tutorial and ResearchWorkshop on Affective Dialogue Systems), volume3068, pages 128?141.Ryuichiro Higashinaka, Kohji Dohsaka, ShigeakiAmano, and Hideki Isozaki.
2007a.
Effects of quiz-style information presentation on user understand-ing.
In Proceedings of the 8th Annual Conferenceof the International Speech Communication Associ-ation, pages 2725?2728.Ryuichiro Higashinaka, Kohji Dohsaka, and HidekiIsozaki.
2007b.
Learning to rank definitions togenerate quizzes for interactive information presen-tation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguistics(Poster Presentation), pages 117?120.Ryuichiro Higashinaka, Kohji Dohsaka, and HidekiIsozaki.
2008.
Effects of self-disclosure and em-pathy in human-computer dialogue.
In Proceedingsof 2008 IEEE Workshop on Spoken Language Tech-nology, pages 109?112.Eva Hudlicka.
2003.
To feel or not to feel: The role ofaffect in human-computer interaction.
InternationalJournal of Human-Computer Studies, 59(1-2):1?32.Kwan Min Lee, Younbo Jung, Jaywoo Kim, andSang Ryong Kim.
2006.
Are physically em-bodied social agents better than disembodied socialagents?
: Effects of embodiment, tactile interaction,and people?s loneliness in human-robot interaction.International Journal of Human-Computer Studies,64(10):962?973.Yi Liu and Yam San Chee.
2004.
Intelligent pedagog-ical agents with multiparty interaction support.
InProceedings of International Conference on Intelli-gent Agent Technology, pages 134?140.Heidy Maldonado, Jong-Eun Roselyn Lee, ScottBrave, Cliff Nass, Hiroshi Nakajima, Ryota Ya-mada, Kimihiko Iwamura, and Yasunori Morishima.2005.
We learn better together: enhancing elearn-ing with emotional characters.
In Proceedings of the2005 Conference on Computer Support for Collab-orative Learning, pages 408?417.Rosalind W. Picard.
1997.
Affective Computing.
MITPress, Cambridge, MA.Helmut Prendinger and Mitsuru Ishizuka, editors.2004.
Life-Like Characters: Tools, Affective Func-tions, and Applications.
Springer, Berlin.Helmut Prendinger, Junichiro Mori, and MitsuruIshizuka.
2005.
Using human physiology to eval-uate subtle expressivity of a virtual quizmaster ina mathematical game.
International Journal ofHuman-Computer Studies, 62(2):231?245.Keith Stenning, Jean McKendree, John Lee, RichardCox, Finbar Dineen, and Terry Mayes.
1999.
Vi-carious learning from educational dialogue.
In Pro-ceedings of the 1999 Conference on Computer Sup-port for Collaborative Learning, pages 341?347.David Traum and Jeff Rickel.
2002.
Embodied agentsfor multi-party dialogue in immersive virtual worlds.In Proceedings of the 1st International Joint Confer-ence on.
Autonomous Agents and Multi-Agent Sys-tems, pages 766?773.Jun Zheng, Xiang Yuan, and Yam San Chee.
2005.Designing multiparty interaction support in Elva, anembodied tour guide.
In Proceedings of the 4th In-ternational Joint Conference on Autonomous Agentsand Multiagent Systems, pages 929?936.Victor Zue, Stephanie Seneff, Joseph Polifroni,Michael Phillips, Christine Pao, David Goodine,David Goddeau, and James Glass.
1994.
PEGA-SUS: a spoken dialogue interface for on-line airtravel planning.
Speech Communication, 15:331?340.224
