Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 2237?2248, Dublin, Ireland, August 23-29 2014.Using Spreading Activation to Evaluate and Improve OntologiesR?nan Mac an tSaoirWatson Group, IBM Irelandronanate@ie.ibm.comAbstractIn this paper, we explore the relationship between the human-encoded semantics of ontologiesand their application to natural language processing (NLP) tasks, such as word-sense disambig-uation (WSD), for which such ontologies may not have been originally designed.
We present amethod for assessing the semantic content of an ontology with respect to a target domain, byspreading activation over a graph that represents instances of ontology concepts and relation-ships, in domain text.
Our proposed method has several advantages beyond existing ontologymetrics.
By identifying bias or imbalance in the ontology, we can suggest target areas for im-provement, and simultaneously facilitate the automated optimisation of the graph for use in thechosen NLP task.
On applying this method to the Unified Medical Language System (UMLS)ontology, we significantly outperformed existing graph-based methods for WSD in biomedicalNLP (0.82 accuracy).
The subsequent introduction of a fall-back mechanism, using word-senseprobability, achieved state of the art for unsupervised biomedical WSD (0.89 accuracy).11 IntroductionAlthough ontologies do encode human knowledge, the degree to which these artefacts represent theentire scope of semantics in a target domain is difficult to quantify.
Since few ontologies offer largeenough scope to cater for an entire domain in natural language, merging of multiple ontologies is oftennecessary (Noy, 2004).
This further compounds the problem of assessing the semantic relevance of themerged resource.
The collective semantics in multiple source ontologies can often overlap inconsist-ently, and negotiation of meaning so that the associated set of concepts and relationships in the ontologyremains balanced, is critical.
The merging process is usually reserved for domain experts, who focus onontology portions in which they specialise.
It?s generally a case of painstakingly mapping individualconcepts between component data sets, to ensure semantic integrity (Jim?nez et al, 2012).
Coordinatingcollaborative ontology editing and merging is a related and well-known problem (Jim?nez et al, 2011).Existing ontology metrics generally focus on structural and logical semantics (Sicilia et al, 2012).Assessing how closely ontologies match the semantics of natural language text, or identifying specificportions of an ontology which require further development, are more difficult tasks.
We have identifieda robust method for this assessment.
This method involves static analysis of a graph representing ontol-ogy instances and inter-concept relationships, to address apparent imbalances that hinder spreading ac-tivation in the graph.
When accuracy and relevance for the task improves, the modified graph or activa-tion strategy identifies portions of interest for further development.
Many ontologies used in NLP todayare not designed for this (Guarino et al, 2009), and a flexible, automatic evaluation method is useful.We focused on the Unified Medical Language System (UMLS) as a typical ontology (NLM, 2013),displaying many of the problems associated with use of ontologies in NLP, including merged terminol-ogy, strongly overlapping semantic categories, inconsistent levels of structural depth, as well as incon-sistent coverage of associated instance data (Pisanelli et al, 1998).
We chose to assess this ontology withrespect to word sense disambiguation (WSD), which is commonly accepted to be one of the most diffi-cult tasks in NLP (Navigli, 2009).
We used the MSH-WSD corpus for testing purposes, which com-monly used in assessing methods for biomedical WSD (Jimeno Yepes and Aronson, 2012; McInnes etal, 2011; Gad el Rab et al, 2013).
Using node-centric graph metrics, we identified portions of the ontol-ogy which were not conducive to WSD via spreading activation.
After appropriately modifying theactivation strategy, we achieved state of the art performance in graph-based biomedical WSD (0.82).This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and pro-ceedings footer are added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/22372 Background2.1 OntologiesAn ontology, in computer science, is defined as an ?explicit specification of a shared conceptualization?
(Gruber, 1993), where a conceptualization may be some subset of real-world semantics, with respect tothe requirements for a given task.
It can contain concepts or classes of object, object properties, andinter-concept relationships, as well as instances of these in the target domain.
Such structured resourcesfacilitate the sharing and re-use of domain knowledge, and are invaluable for NLP applications.
A pri-mary example of such a resource is the UMLS, provided by the National Library of Medicine (NLM,2013).
The data set consists of a large lexicon, including millions of instance surface forms, in conjunc-tion with an ontology of concepts and inter-concept relationships in the medical domain.
It is composedof 139 different source ontologies or terminologies, each of which have their own labels, descriptionsand semantic perspective (e.g.
FMA2 for the body, and RXNORM3 for drugs, as well as more generalontologies like SNOMED4).
An example ontology is shown in Figure 1 below.Figure 1.
A simple (and incomplete) ontology describing ambiguous senses of the word ?cat?2.2 Ontology EvaluationEvaluating ontology semantics commonly focuses on the structural and logical nature of the resource.Related efforts may use logical reasoning to ensure that the semantics are internally consistent, or usethe structure and labels of another ontology as a baseline, assuming that textual labels for synonymousconcepts will be consistent between sources (Vrandecic and Sure, 2007; Ma, 2013).
A metric whichgoes beyond these and evaluates the semantic relevance to a given task is sorely needed (Vrandecicand Sure, 2007).
While metrics that examine the completeness of an ontology?s content are suggestedin the literature (Tartir et al, 2005), these metrics reflect a high-level summary of the content.
Theevaluation of this content, independent of the ontology itself, and at a sufficiently fine-grained level tosuggest areas for improvement, would be of significant additional benefit.Vrandecic and Sure (2007) recognise the paucity of metrics that take the ontology semantics intoaccount.
In terms of semantic quality, they propose leveraging a logical reasoner to evaluate that anontology is consistent within the context of its own assertions.
However, there is no objective analysisof the semantic content with respect to real world human knowledge.
Ma et al (2013) point out that prior2FMA: http://sig.biostr.washington.edu/projects/fm/AboutFM.html3RXNORM: http://bioportal.bioontology.org/ontologies/RXNORM4SNOMED: http://bioportal.bioontology.org/ontologies/SNOMEDCT2238ontology metrics neglect implicit semantic knowledge.
They acknowledge the utility of a graph structurein representing the content of an ontology, and assert that this structure preserves well the semantics ofthe ontology.
However, they do not proceed to examine the ontology in the context of a real-worldsemantic evaluation.
By limiting the scope of comparison to sets of related ontologies, they work on theassumption that similarly labelled concepts and structures are roughly equivalent.
Additionally, Siciliaet al (2012) suggest that there is no obvious metric to identify when an ontology needs to be improved.We propose that graphs composed of instances of ontology concepts and relationships, along withassociated unique identifiers, are a less na?ve approach to semantic matching than textual labels.
Wesuggest an objective analysis of how annotated instances of ontology concepts and relationships interact,by a process such as spreading activation in an associated graph, would be more reflective of the prox-imity of the evaluated ontology to the semantics of the target domain text.
We also suggest that analysisof particular characteristics of the graph, that amplify or hinder this activation process, are helpful inidentifying specific portions of the associated ontology that require further development.
Interestingly,the use of spreading activation as a method for ontology assessment has already been carried out previ-ously (Fang and Evermann, 2010).
In that case however, the spreading activation was in the context ofcognitive psychology, where test subjects manually assessed ontology content.
An automated approach,leveraging the same principles, without the requirement for human reviewers, would be of great value.2.3 Word Sense DisambiguationWSD is one of the most critical tasks in NLP (Navigli, 2009), and is often described as AI complete.Navigli (2009) identifies several main categories of approach to WSD, namely knowledge based, super-vised and unsupervised methods.
He proposes knowledge based methods as the most useful in the me-dium to long term, for several reasons.
He points to the availability of knowledge resources such asWordNet, Yago, and DBPedia, resources which are actively developed and enriched, as a starting pointof significant value.
He also suggests that supervised approaches are better for categorisation tasks likepart-of-speech (POS) tagging, rather than tasks that require more fine grained detail such as real-worldword-sense disambiguation.
As an example of this, consider that the process of disambiguating the cor-rect POS for a word may involve the selection of one from a set of possible POS tags.
One such tagset,widely used for English, is the Penn Treebank tagset consisting of 36 separate tags.
The UMLS data set,however, contains close to 3 million5 distinct senses.Though WSD is still widely regarded as an unsolved problem, supervised approaches to WSD gen-erally perform well.
Navigli (2009) suggests that this is due to the lack of real-world considerations indevelopment and testing of WSD methods.
We can consider the MSH-WSD corpus as an exampledemonstrating typical limitations when compared with the requirements for a real-world system.
MSH-WSD is a commonly used data set in biomedical WSD, using sense IDs from UMLS, and consisting ofapproximately 37,000 separate documents or abstracts, where a single ambiguous sense is annotatedwith the correct UMLS sense ID.
A WSD system need only identify this single sense correctly (regard-less of the other words in the document), in order to score highly.
Additionally, there are a total of 423distinct word-senses annotated in this test set, greatly reducing the scope of the task involved from ap-proximately 3 million possible senses in the full UMLS.
As a result, this data set is not a strong reflectionof what is required in real-world biomedical NLP applications, where a high percentage of the words ina given document or context must be assigned their correct senses.It is generally accepted that unsupervised methods for WSD minimise the cost of developing a suita-ble application, by relying on features that may be extracted directly from the target domain text, oralternatively using existing knowledge in some form.
The latter are often referred to as knowledge-based(KB) methods.
For supervised WSD a gold-standard is required input, where manually curated data setsfacilitate the training of robust machine learning algorithms.
Supervised methods generally outperformunsupervised (Agirre et al, 2010), but are limited by the cost of developing the required training data.However, as mentioned previously, these systems may not perform so well in real world WSD scenarios.In a biomedical context, there are several examples of both supervised and unsupervised (includingknowledge-based) approaches.
Most unsupervised approaches leverage the UMLS to some extent, andbuild on that knowledge using methods like Automated Corpus Extraction (Jimeno Yepes and Aronson,2012) and Information Content Similarity (McInnes et al, 2011).
The commonly cited example of a5UMLS stats: http://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/release/statistics.html2239supervised approach that consistently outperforms known unsupervised approaches is Na?ve Bayes(Jimeno Yepes and Aronson, 2012; McInnes et al, 2011), achieving 0.94 accuracy on the common dataset, although as we?ve outlined previously, the search space for a correct tag in the chosen data set (witha total number of 423 senses) is much smaller than would be the case in a real-world system.Several recent approaches to biomedical WSD leverage structured knowledge in the form of a graph.Examples range from the use of co-occurrence data from a domain-specific corpus (Agirre et al, 2006),to variations of PageRank (Agirre and Soroa, 2009; Agirre et al, 2010), to the representation of an on-tology, or portion of an ontology, as a graph (Gad El-Rab et al, 2013).
Ontologies are often used as asource from which to build the required graph, as they are readily available in many domains, and pro-vide a starting point of high-quality semantic knowledge.
As identified previously, the lexical ontologyWordnet is a commonly used resource in open domain WSD.
Similarly, in the biomedical domain, theUMLS is equally common.
Hybrid approaches leveraging both general lexical semantics like WordNetwith domain-specific semantics like UMLS are not as common however, but have been used with prom-ising results in other related NLP tasks such as anaphora resolution (Liang and Lin, 2005).Graph based methods have not performed as well as other unsupervised approaches, like MachineReadable Dictionaries: 0.8070 (Jimeno Yepes and Aronson, 2012), semi-supervised Automated CorpusExtraction methods: 0.8383 (Jimeno Yepes and Aronson, 2012), and co-occurrence metrics: 0.78 (McIn-nes and Pedersen, 2013).
A recent approach (El-Rab et al, 2013) achieved mixed results with respect toparticular terms in the MSH-WSD test corpus, achieving an overall accuracy of 0.603.
State of the artaccuracy for graph-based methods, in unsupervised biomedical WSD, was 0.72 (McInnes et al, 2011).State of the art in overall unsupervised biomedical WSD was 0.87 (Jimeno-Yepes and Aronson, 2012).2.4 Spreading ActivationThe theory of spreading activation was first proposed by Quillian (1966), in a model of human se-mantic memory.
Quillian proposed an abstract model of human memory, in order to artificially representthe means by which a human?s brain might process and understand the semantics of natural language.This model was enhanced by Collins and Quillian (1969) for retrieval tasks, and further modified byCollins and Loftus (1975).
The latter provided inspiration for research in many other related fields, fromcognitive psychology to neuroscience, to natural language processing, among others (Pace-Sigge, 2013).The basic premise of spreading activation is related to that of connectionism in artificial intelligence,which uses similar models for neural networks to reflect the fan-out effect of electrical signal in thehuman brain.
In the case of neural networks, a vertex in the graph could represent a single neuron, andedges could represent synapses.
In information retrieval (Crestani, 1997) and word-sense disambigua-tion (Tsatsaronis et al, 2007), generally vertices will represent word-senses and edges will representsome form of relationship, either lexical or semantic linkage, between these senses.An example implementation is ?Galaxy?, developed as part of the Nepomuk Social Semantic Desk-top6, which uses spreading activation to perform clustering on a graph.
Instead of traditional methods ofhard clustering, which partition a graph into different groups, Galaxy performs soft clustering, whichinvolves identifying a sub-graph located around a set of input nodes, and then finding the focus of thissub-graph.
The same implementation provides a configurable weighting model that allows modificationof starting weights associated with semantic types, edges and individual nodes in the graph.
This hasalready been used in various scenarios, such as social network analysis and dynamic semantic publica-tion of web content7, and may also be applied to any set of graph-structured data (Troussov et al, 2008).By discovering instances of ontology concepts in domain text, using the set of unique identifiers forinstances, we can activate corresponding nodes in the graph, from where a signal will traverse outwardacross adjacent nodes, activating these in turn.
As the signal spreads farther from a source node, it getsweaker by an amount specified in an associated weighting model for nodes and edges in the graph.
Ifthe signal spreads from multiple nearby source nodes, the signal will combine, and points of overlapwill be activated to a greater degree.
The nodes which accumulate the most activation are deemed to bethe focus nodes for the context.
The resulting activated portion of the graph will reflect the inherentmeaning of the document, in so far as the ontology?s defined semantics will allow.6http://dev.nepomuk.semanticdesktop.org/wiki/TextAnalytics#IBM7http://www.bbc.co.uk/blogs/bbcinternet/2010/07/bbc_world_cup_2010_dynamic_sem.html2240To demonstrate this process in action, we will draw examples from the ontology previously definedabove.
Figure 2 describes the resulting instance graph for the ontology described in Figure 1, on whichwe can perform spreading activation using instances in text.
Firstly, consider the set of surface formsassociated with concept instances in table 1.
If we annotate the set of contexts below with this lexicon,we can then use the annotations to activate the graph.
Nodes that are well connected may benefit fromthe potential overlap of signal coming from other adjacent nodes.
Instances are italicised below.?
The cats result for the patient's brain tumour was assessed by the Doctor.?
Tigers and lions are cats that live in the wild.
These cats are not afraid of dogs.?
The patient survived the brain tumour, but died of an allergic reaction to their neighbour's cats.In each example, the ambiguous term is the word ?cats?, which can variously refer to: cat_scan,wild_cat and domestic_cat.
The surrounding context of each instance contains other concept instancesthat may help to disambiguate the correct sense of ?cats?.
In the first example, the nodes representingwild_cat, domestic_cat, cat_scan and brain_cancer will be activated.
Since brain_cancer and cat_scanare relatively well connected in the graph, and are also adjacent to one another, the spreading activationwill return these nodes as the most likely interpretation of the content.In the second example, the correct instance is wild_cat.
However, this node is isolated in the graph,since there were no associated relationships in the ontology linking this particular instance to othernodes.
Since the instance of the class Dog is connected to domestic_cat, these nodes may amplify eachother?s signal to a greater degree than is possible at the isolated node wild_cat.
It is therefore likely thatunless the weighting model is reconfigured, we are unlikely to obtain the correct output.
The relevanceof isolated nodes may be boosted by increasing the rate of signal decay on other nodes in the graph.However, there is a risk in doing so, since the connectedness of instances in the ontology is likely abetter reflection of the semantic content.
It would be better to suggest that the ontology would benefitfrom further development, for example to introduce the ideas of habitat or fear.The final example demonstrates a more subtle bias in the ontology?s semantics, and the correspondinggraph.
The overlapping signal from cat_scan and brain_cancer suggests that cat_scan will be returnedinstead of domestic_cat.
Resolving this ambiguity in the graph may require modification of theweighting model, or further development.
An advantage in this case however, is the different semanticcategories involved: the classes of Cat and Scan.
Re-weighting the starting activation signal on the basisof a semantic category is less risky than re-weighting the entire set of nodes in the graph.
Even so, furtherdevelopment of the ontology, e.g.
to introduce the idea of animal allergies, would be beneficial.Figure 2.
Graph representation of the sample ontology.Instance ID Associated Surface Formswild_cat {lions, tigers, cat, cats, cub}domestic_cat {cat, cats, kitten }domestic_dog {dog, dogs, puppy}brain_cancer {brain carcinoma, brain tumour}cat_scan {cat, cats, cat scan}Table 1.
Example surface forms for instance data.22413 Method3.1 Ontology Instance GraphWe extracted data from the UMLS Metathesaurus (MT) and Semantic Network (SN) and built a triplestore in RDF/XML8 format, defining owl:Class and owl:ObjectProperty to reflect concepts and relation-ships.
Using the Galaxy API described in section 2.4, we built a spreading activation network, i.e.
adirected graph between instance IDs (vertices) and associated relationships (edges).
In order to narrowthe proximity between the semantics of domain text and the chosen ontology, we chose to build a graphof instance data.
The SN is a high level ontology, and therefore to assume that all relationships betweenClasses are applicable to all instances would have produced many incorrect assertions, such as ?AllDrugs have the set of All Drugs as ingredients?.
Therefore, only instances of relationships that explicitlylinked individual concept IDs (Concept Unique Identifiers, CUIs) were used.
Across the entire SN, asingle CUI may have various types of semantic interactions with other nodes, for example in the contextof Drugs and treated Diseases, or separately, in the context of Chemicals and associated Compounds.The UMLS CUIs were used as instance IDs to link surface forms in the text to nodes in the graph.It is important to point out that the UMLS ontology by no means uses the full expressivity of OWL.However, the general use of spreading activation over a graph derived from ontology content, is not solimited.
In other domains, and for ontologies that use the full range of OWL expression, as long as thegraph is built from a source that expresses other semantic qualities (e.g.
cardinality), the spreading acti-vation strategy will still apply.
For example, in the context of our sample ontology, consider activating?cat?, the signal spreading to an additional adjacent node for the concept of ?four legs?, and then otherconcepts with four legs, such as ?dog?, becoming activated.
The Galaxy API fully supports this.3.2 Test Corpus and Metric CalculationWe chose to use the MSH-WSD test corpus as our gold-standard.
This is a common test set usedacross the literature in biomedical WSD.
The metrics we used were Precision, Recall, FMeasure andAccuracy, whereas prior research mainly focuses on Accuracy.
In WSD, a true positive is a disambigu-ated output that matches a gold-standard, and a false positive is output that does not match.
As traditionalWSD algorithms are designed to generate output for every word in the text, recall and precision are thesame value.
However, our algorithm works on the principle of semantic relevance, and there is no guar-anteed output; senses with sufficient weight after spreading activation will be displayed.
Therefore, wehave chosen to take a closer look at precision and recall, which is discussed in more detail in section 4.Prior literature in biomedical WSD uses older versions of UMLS data, e.g.
2009AB (McInnes et al,2011).
We chose to focus on the 2013AA release of UMLS, in order to assess the most recent versionof the ontology?s semantic content, and in order to facilitate a useful modification of the current data,which could be leveraged by contemporary NLP systems.
This affected the comparison of test resultsusing the MSH-WSD data set.3.3 Lexical AnnotationIn conjunction with the graph described above, we constructed a set of lexical dictionaries that linkedUMLS CUIs or instance IDs, to portions of text in a document.
These portions of text, otherwise knownas surface forms, consisted of potentially many different strings associated with each ID.
An exampleof a data entry for a single UMLS CUI is in table 2 below.
Dictionaries were compiled for each semanticcategory in the UMLS SN, with overlapping associations between ID and textual surface form.CUI Semantic Type Surface Form (Text)C0018787 BodyPartOrRegion heartcardiac structureheart structurecoronaryfour chambered heartthe human heartTable 2.
Surface forms associated with the concept ?Heart?, UMLS CUI: C0018787.8http://www.w3.org/TR/rdf-syntax-grammar/2242In order to maximise the potential for spreading activation across the graph, we performed severalmodifications to the underlying lexical data in UMLS MT, to increase the variations of surface formassociated with instances of concepts.
Our reasoning for this is as follows: the more instances of con-cepts that occur in the text, the more nodes that get activated in the graph, and consequently the moreopportunities for the activation method to spread out and activate the set of concepts most relevant tothe semantics of the document text.
For a simple example of this process, please see section 2.4.
Exam-ples of transformations carried out in the data are presented in table 3, below.Pre-existing Term Transformation Type New Alternate Surface Formleg, right Alternating Comma right legbrain cancer Noun Phrase cancer of the brainCANCER Casing Variants CancerAnaemia Spelling Variants An?miaImmunoglobulin g Acronym IgImmunoglobulin g Term + Acronym Immunoglobulin g (Ig)Table 3.
Examples of UMLS data transformations applied.The use of a lexical part-of-speech tagger was particularly effective in filtering out instances of con-cepts that were obviously introducing unhelpful noise.
Some exemplary cases were the Amino Acids?on?, ?at?
and ?in?
(prepositions), and the GeneOrGenome ?was?
(verb).
UMLS concepts that directlyoverlapped with words that did not display an appropriate part-of-speech for a true concept (such asadjective or noun), were removed from the document metadata, and thereby not considered as input forspreading activation.
For this POS Filter, we chose to use the MaxEntropy model from OpenNLP9.3.4 Spreading Activation StrategyThe initial activation strategy was to set starting weights for all semantic categories to a value of 1.Decay factor of the spreading signal at each node in the graph was set to an initial value of 0.5, whenthe graph was built.
The initial threshold of semantic relevance was set to 0.1, and instances retaining asemantic value higher than this would be considered relevant.
The lexical annotations from the previousstep were used as input to the activation process, and nodes in the graph from instances in the text wereassigned their starting weight, according to the number of semantic categories, and their associatedweights.
As the signal is spread from these starting nodes, the decay factor is applied, reducing the signalstrength.
For each successive node, the signal is similarly reduced until it falls below the specifiedthreshold, and the activation process is completed.
It is important to note that the ambiguity in word-senses may not be entirely removed once the spreading activation has finished.
The consequences ofthis will depend on the particular end-goal.
In the case of WSD, we are only interested in obtaining asingle most appropriate CUI for a given surface form.
We therefore kept only the highest weighted CUIin our system output.
In the context of other NLP tasks, such as for named-entity inference or questionanswering and hypothesis generation (Ferucci et al, 2011), it can be useful to preserve multiple ambig-uous outputs for later processing.It was clear from the outset that simply building a graph of the ontology instance data and semanticrelationships was not sufficient to score highly in the WSD task.
El-Rab et al (2013), who used theUMLS SN structure for graph-based WSD, reported an overall accuracy of (0.603) on the MSH-WSDtest set, which roughly correlates with our baseline system (0.62).
Our added advantage is that modifi-cation of the weighting strategy allows us to iron out imbalance, or to reduce the influence of thoseportions of the graph that do not appear to encourage a spreading signal.
By focusing on signal amplifi-cation and decay, rather than modifying graph semantics, we can change the relevance of particularportions of the ontology without losing any of the original semantic detail.
Such modifications are sen-sitive to performance in the NLP task but, critically, do not require the assistance of domain experts.We initially pursued a cautious approach to modifying the activation strategy, by only decreasing thestarting weight of semantic categories associated with the affected nodes.
This weight was decreased bya factor equivalent to the number of overlapping semantic types on the same node.
Following this, wemeasured the accuracy of the approach against the MSH-WSD test corpus for WSD, testing blind, thatis by only considering the overall accuracy.
Upon close examination of the instance graph, for types of9http://opennlp.apache.org/2243structure or characteristics of nodes that may be hindering or over-amplifying the spreading signal (seesection 4.1), we further modified the activation strategy to negate the potential influence that certainobviously problematic nodes may have.
Modifying our spreading activation strategy in this way, afterstatic graph analysis alone, produced much more accurate output (see table 5, experiment 3).We then decided to split the test set in the ratio of 4:1, in order to more closely inspect the accuracyof particular cases of WSD, and attempt to correct this specific imbalance in the graph, while still per-forming some independent validation of the output.
The random nature of the split was to choose everyfifth example in the data, from the subset for each term.
After performing WSD using this 80%, or trainset, we discovered that it was possible to distinguish groups of high and low performing nodes in thegraph, with respect to the set of static graph metrics, described in the following section.3.5 Static Graph Analysis (SGA)As shown in the simple example in 2.4, assessment of ontology semantics can be done up front, beforethe graph is used.
Certain node characteristics may be examined in the graph using a set of graph theo-retical metrics, and portions of the graph that are not conducive to spreading activation may be identi-fied.
This analysis allows us to make educated modifications to the weighting strategy for spreadingactivation, as described previously.
The set of graph metrics we used is presented in table 4 below.Metric EvaluationIn Degree # of inward semantic linksOut Degree # of outward semantic linksTotal Degree (indegree + outdegree)Inward Edge Type Variation (ETV) # of inward edge typesOutward ETV # of outward edge typesTotal ETV (Inward ETV + Outward ETV)Table 4.
Static Graph Metrics derived from Diestel (2010).Following the use of these metrics, and the gathering of associated statistics, we categorised particulargroups of node in order to apply a common weighting strategy that should maximise performance of thespreading activation algorithm.
There were several common patterns that we identified, and chose totarget for re-weight.
Examples of those nodes that might negatively affect spreading activation are:?
Isolated Nodes, where Total Degree is 0?
Unbalanced Nodes, where inDegree and outDegree are significantly different?
Nodes with few variations in link type, or low Total ETV?
?Black Hole?
nodes, where there is a high Degree to ETV ratio (see section 4.1)For isolated nodes, we examined the set of associated semantic categories, and boosted their startingweight.
For unbalanced nodes, where the indegree was significantly higher or lower than the outdegree,we increased or decreased the decay factor accordingly, to reduce the imbalance of the spreading signal.For nodes with low ETV but high Degree, we increased the decay factor, in order to reduce the potentialinfluence of a single over-used semantic link.
For overly promiscuous (Norvig, 1986) or ?Black Hole?nodes, we reduced the starting weight applied by the associated semantic categories, and increased therate of decay.
In certain cases, the intended modifications were incompatible, and resulted in conflictingchanges to the graph and weighting strategy.
Where certain nodes might require a boost from one cate-gory, the starting weight for the same category may need to be reduced, due to an overly-connected nodeelsewhere.
We decided to inhibit the negatively connected nodes only, in light of the increase in systemaccuracy from reducing noise compared to the gain from improvement of individual nodes.4 Results and DiscussionThe baseline activation strategy was promising.
The introduction of a POS filter to ignore invalid in-stances (see section 3.3) had a strong effect on recall, due to reduced noise in the activation of the graph.Recall significantly improved upon the modification of starting weights after analysis of static graphmetrics, although precision fell slightly.
This result (0.82) constitutes state of the art in graph-basedWSD for biomedical text.
The fall in precision was not unexpected, since the graph was no longer so2244biased toward specific word senses.
We also present a further experiment that incorporates a fall-backmechanism for test cases where the spreading activation did not produce a disambiguated output.
Thisresult (0.89) constitutes state of the art in overall unsupervised biomedical WSD.
This allows our methodto assign a single word-sense for every ambiguous word or surface-form.
This fall-back alone achievesaccuracy of 59%, comparing favourably with a default-sense approach (54.5%: McInnes et al, 2011).Finally, by identifying bias in the graph toward specific senses in the test corpus, using an 80% subsetof the MSH-WSD data set for training, and then modifying the rate of decay for problematic nodes, weachieved a significant boost to recall, and consequently to overall accuracy.
We draw a distinction be-tween this and other results since the testing was not blind, but was using the gold-standard corpusdirectly, to examine the portions of the graph that did not perform well in testing.
We envisage that thismay still be of practical use in real-world applications, by firstly developing an appropriate gold-stand-ard, which in conjunction with analysis of the ontology instance graph, will result in optimal output.The current results reflect the scope of spreading activation being set to the whole document.
Onlyone sense of a word is recognised within that context, and documents containing multiple interpretationsof the same word will not be correctly disambiguated.
However, by configuring the scope to a sentenceor paragraph we may reduce the potential accuracy of the output by decreasing the available instancesfor activation.
Prior research into the ?One sense per discourse?
hypothesis suggests that the existingapproach should be appropriate in up to 98% of cases (Gale et al, 1992).Experiment Description Precision Recall FMeasure Accuracy1.
Baseline system 0.935 0.659 0.6639 0.622.
Baseline + POS Filter 0.901 0.721 0.7872 0.743.
As in 2, with SGA re-weight 0.841 0.822 0.8317 0.824.
As in 3, confidence fallback 0.912 0.887 0.8995 0.895.
SGA+WSD (20% test set) 0.986 0.942 0.9635 0.93McInnes et al, 2011  0.72J-Yepes & Aronson, 2012 0.87Table 5.
Comparison of WSD Results.4.1 Identifying and Resolving Graph Bias or ImbalanceIn experiment 5, having already identified specific cases that remained unbalanced, we attempted torectify this by examining the graph in parallel with the WSD metric data.
If a graph displays character-istics indicating imbalance or bias, for example where a node is unreachable (isolated in the graph), ornode degree and node edge-type variation are relatively low (see section 3.5), it is less likely that thespreading activation will reflect the meaning of the text.
We made discoveries similar to the following:?
80% of nodes with Total ETV >15 had WSD precision of over 90%?
60% of nodes with Total ETV <5 had precision of less than 10%We also discovered cases in the graph where a node had very high Degree (> 100), and relatively lowETV.
In terms of spreading activation, these nodes would be especially problematic.
We have coinedthe term ?Black Hole Node?
to describe this phenomenon.
In psycholinguistic terms, this may be com-parable to the notion of a Freudian slip, where a node in the graph which is not immediately relevant tothe context of the document, has become over-stimulated by its connectivity, or as Norvig (1986) wouldsuggest, its ?promiscuity?.
The signal will gravitate towards such an over-connected node during theprocess of spreading activation, affecting the relevance of other nodes in that context.
An example blackhole node is the UMLS CUI C0035298, representing a retina in a human eye, with 1636 edges and 19edge types.
The extra noise in activating such a node can skew the signal across the entire graph.
Wordsenses that compete for relevance with this or related nodes will have poorer accuracy.
We modified theactivation strategy to reflect this by increasing the rate of decay on such nodes from 0.5 to 0.99.By ensuring that only the graph weighting strategy is modified, we can keep all word-senses presentin the graph, resolving the issue identified by Norvig (1986) where such graph content had to be re-moved.
Using the WSD metric output, we also modified the activation strategy to cope with bias towardparticular senses in the test corpus.
We reduced the starting weight for semantic categories for the high-scoring sense, in order to potentially increase the relative semantic importance of the alternative senses.Table 6 demonstrates some of the improvements achieved with regard to specific ambiguous terms.2245Term F-Measure Before F-Measure AfterMurine Sarcoma Virus 0 0.47Gamma-Interferon 0.013 0.28RA 0.021 0.59CCD 0.033 1AA 0.899 0.99Table 6.
Examples of term-specific improvement using re-weighting strategy.4.2 MSH-WSD Data SetIn working with the MSH-WSD data set, we came across many issues that Navigli (2009) previouslyidentified.
The number of ambiguous senses (423) in the context of the full UMLS set of almost 3million, reduces the validity of this corpus for measuring real-world viability and accuracy.
Further tothis, our results with lexical analysis optimisation demonstrate that the test corpus ignored surroundingcontext for potentially overlapping terms, such as ?bat?
and ?fruit bat?.
In such cases, it would havebeen more accurate to use the CUI for ?fruit bat?
as the specific type of ?bat?, but the test corpus doesnot reflect this.
Our algorithm is sensitive to contextual semantics, so ensuring that all lexical matchesof any length remain present, potentially reduces the accuracy of the algorithm?s output, as well as thereal-world utility of the approach.
In spite of the various data transformation techniques applied, ourrecall maximised at 96.4%.
Critically, when we normalize our overall accuracy (0.89) to take this intoaccount, we reach accuracy of 0.92, a significant achievement in unsupervised WSD.
We are currentlyexamining what may be required to achieve maximum recall of 100%.
While such a result is not guar-anteed, without full coverage of the test set, we have not yet measured the full potential of this method.4.3 Identifying Focus Areas for Ontology ImprovementOne of the primary outcomes of this research is a method for the identification of specific ontologyportions that require further development.
As we have seen in section 4.1, there are several candidateswhich stand out.
Other issues pointing to required enhancements in the ontology were around the notionof isolated nodes in the graph.
An example of this is "ADA", the American Dental Association.
It issurprising to discover that although this term?s associated CUI (C0002456) is listed in 7 source ontolo-gies of the UMLS SN, there are no semantic relationships in the source between this CUI and any others.Of the 203 ambiguous terms in the MSH-WSD data set, 5 of those terms had associated nodes that weresimilarly isolated in the graph.
Without any semantic relationship to other concepts, it is reasonable tosuggest that the ontology would benefit from focused development of these nodes?
surrounding context.In terms of the variation of connectivity, we quickly discovered using our simple graph metrics thatthe ?SIB?
or sibling relationship was extremely common.
Consider the concept C0325089 representingthe felidae family or the animal cat, which has 8 connections, but for which SIB is the only availablelink type.
Hard-wiring siblings in this fashion, with no other link, is unhelpful since spreading activationcan already identify siblings from common parent nodes.
We contend that such concepts are not as wellconnected as they may first appear, and are therefore strong candidates for further development.
Thiswill not be apparent from the Degree metric alone, but by combining Degree and Edge Type Variationwith node-specific accuracy in an NLP task, it becomes a straightforward process.
Following this dis-covery, we also suggest that an empirical analysis of link quality would be beneficial, although thiswould not be a trivial task given the size of the data set (~3 million senses and ~700 link types).5 Summary and Future ResearchWe have presented a new method for evaluating ontology semantics which has several advantagesover existing approaches.
We have shown how the application of graph theoretical analysis to semanticstructures like ontologies is a valid means by which to assess their semantic quality, while enabling therecommendation of specific focus areas for further development.
We have additionally demonstratedthat a graph-metric based weighting strategy for spreading activation can overcome an ontology?s in-herent semantic inconsistencies, facilitating the optimisation of the ontology for a given NLP task.In the case of our UMLS prototype, we made significant improvements using this technique, achiev-ing state of the art in unsupervised knowledge based WSD (0.82), as well as achieving state of the art inoverall unsupervised WSD, with the use of a fall-back probability score (0.89).
An additional semi-2246supervised approach, leveraging gold-standard data from a training portion of the MSH-WSD data set,had very promising performance (0.93).
The amount of required input data to this method is relativelysmall when compared with fully supervised approaches, as a single gold-standard annotation in eachtarget context is sufficient to evaluate the graph using our spreading activation algorithm.In future we would like to apply this technique to other ontologies, and associated test sets, for otherdomains in NLP.
Merging of domain-specific ontologies with more general semantic resources likeYago or Wordnet may help to facilitate the activation of otherwise poorly connected or isolated nodesin the graph.
We would like to investigate the automatic learning of an optimal spreading activationweighting strategy.
An empirical study comparing data from human ontology reviewers with thisspreading activation technique, would also be helpful.We would like to expand the set of metrics used, by adapting other existing graph theoretical metricsto suit the requirements of NLP.
Some promising examples are ?Centrality?
and ?Betweenness?
outlinedby Brandes and Erlebach (2005), which determine the relative importance of a node within a graph.
Inthe case of UMLS, we can perform a comprehensive static analysis of all ambiguous CUIs within thedata set, identifying competing senses which do not have sufficient separation in the graph.
These sensescould then be targeted in the configuration of the spreading activation strategy.As interest grows in the use of graph theoretical methods for the analysis of cognitive processes (VanDijk et al, 2010; Bullmore and Sporns, 2009; Sporns, 2003), exploring the relationship between spread-ing activation in a graph representing ontology semantics, as performed in this research, and in neuralactivity during psycholinguistic experimentation (Fang and Evermann, 2010), becomes an exciting pro-spect that may lead to a better understanding of semantic processing in the human brain.AcknowledgementsSincere thanks to Mikhail Sogrin (IBM), the talented developer of both ?Galaxy?
and the lexicon expan-sion framework used here, without whom this research would not have been possible.ReferencesAgirre, E., Mart?nez, D., de Lacalle, O. L., & Soroa, A.
(2006, July).
Two graph-based algorithms for state-of-the-art WSD.
In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (pp.585-593).
Association for Computational Linguistics.Agirre, E., & Soroa, A.
(2009, March).
Personalizing PageRank for word sense disambiguation.
In Proceedingsof the 12th Conference of the European Chapter of the Association for Computational Linguistics.
ACLAgirre, E., Soroa, A., & Stevenson, M. (2010).
Graph-based Word Sense Disambiguation of biomedical docu-ments.
Bioinformatics, 26(22), 2889-2896.Brandes, U., & Erlebach, T.
(Eds.).
(2005).
Network analysis: methodological foundations (Vol.
3418).
Springer.Bullmore, E., & Sporns, O.
(2009).
Complex brain networks: graph theoretical analysis of structural and functionalsystems.
Nature Reviews Neuroscience, 10 (3), 186-198.Collins, A. M., & Quillian, M. R. (1969).
Retrieval time from semantic memory.
Journal of verbal learning andverbal behavior, 8(2), 240-247.Collins, A. M., & Loftus, E. F. (1975).
A spreading-activation theory of semantic processing.
Psychological re-view, 82(6), 407.Crestani, F. (1997).
Application of spreading activation techniques in information retrieval.
Artificial IntelligenceReview, 11(6), 453-482.Diestel, R. (2005), Graph Theory (3rd ed.
), Berlin, New York: Springer-Verlag, ISBN 978-3-540-26183-4.El-Rab, W. G., Za?ane, O. R., & El-Hajj, M. (2013, August).
Biomedical text disambiguation using UMLS.
In Pro-ceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Min-ing (pp.
943-947).
ACM.Evermann, J., & Fang, J.
(2010).
Evaluating ontologies: Towards a cognitive measure of quality.
Information Sys-tems, 35(4), 391-403.Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A.
A., & Welty, C. (2010).
BuildingWatson: An overview of the DeepQA project.
AI magazine, 31(3), 59-79.2247Gale, W. A., Church, K. W., & Yarowsky, D. (1992, February).
One sense per discourse.
In Proceedings of theworkshop on Speech and Natural Language (pp.
233-237).
Association for Computational Linguistics.Gruber, T. R. (1993).
A translation approach to portable ontology specifications.
Knowledge acquisition, 5(2)Guarino, N., Oberle, D., & Staab, S. (2009).
What is an Ontology?
In Handbook on ontologies (pp.
1-17).
SpringerJim?nez-Ruiz, E., Grau, B. C., & Horrocks, I.
(2012).
Exploiting the UMLS Metathesaurus in the Ontology Align-ment Evaluation Initiative.
In E-LKR Workshop (pp.
1-6).Jim?nez Ruiz, E., Grau, B. C., Horrocks, I., & Berlanga, R. (2011).
Supporting concurrent ontology development:Framework, algorithms and tool.
Data & Knowledge Engineering, 70(1), 146-164.Jimeno Yepes, A., & Aronson, A. R. (2012, January).
Knowledge-based and knowledge-lean methods combinedin unsupervised word sense disambiguation.
In Proceedings of the 2nd ACM SIGHIT International Health In-formatics Symposium (pp.
733-736).
ACM.Liang, T., & Lin, Y. H. (2005).
Anaphora resolution for biomedical literature by exploiting multiple resources.In Natural Language Processing?IJCNLP 2005(pp.
742-753).
Springer Berlin HeidelbergMa, Y., Jin, B., Liu, X., Liu, L., & Lu, K. (2013).
A Graph Derivation Based Approach for Measuring and Com-paring Structural Semantics of Ontologies.
IEEE Transactions on Knowledge and Data Engineering, 1.McInnes, B. T., Pedersen, T., Liu, Y., Melton, G. B., & Pakhomov, S. V. (2011).
Knowledge-based method fordetermining the meaning of ambiguous biomedical terms using information content measures of similarity.In AMIA Annual Symposium Proceedings (Vol.
2011, p. 895).
American Medical Informatics Association.McInnes, B. T., & Pedersen, T. (2013).
Evaluating measures of semantic similarity and relatedness to disambiguateterms in biomedical text.
Journal of biomedical informatics, 46(6), 1116-1124.National Library of Medicine.
2013.
Unified Medical Language System, version 2013AA.
NLMNavigli, R. (2009).
Word sense disambiguation: A survey.
ACM Computing Surveys (CSUR), 41(2), 10.Norvig, P. (1986).
Unified theory of inference for text understanding.
CALIFORNIA UNIV BERKELEY GRAD-UATE DIV.Noy, N. F. (2004).
Tools for mapping and merging ontologies.
In Handbook on ontologies (pp.
365-384).
SpringerPace-Sigge, M. (2013).
Lexical Priming in Spoken English Usage.
Palgrave Macmillan.Pisanelli, D. M., Gangemi, A., & Steve, G. (1998).
An ontological analysis of the UMLS Metathesaurus.
In Pro-ceedings of the AMIA symposium (p. 810).
American Medical Informatics Association.Plaza, L., Jimeno-Yepes, A. J., D?az, A., & Aronson, A. R. (2011).
Studying the correlation between differentword sense disambiguation methods and summarization effectiveness in biomedical texts.
BMC bioinformaticsQuillian, M.R.
(1966).
Semantic Memory.
Unpublished doctoral dissertation, Carnegie Institute of Technology(Re-printed in part in M. Minsky (1968).
Semantic Information Processing.
Cambridge, Mass.
MIT Press).Sicilia, M. A., Rodr?guez, D., Garc?a-Barriocanal, E., & S?nchez-Alonso, S. (2012).
Empirical findings on ontol-ogy metrics.
Expert Systems with Applications, 39(8), 6706-6711.Sporns, O.
(2003).
Graph theory methods for the analysis of neural connectivity patterns.
In Neuroscience Data-bases (pp.
171-185).
Springer US.Tartir, S., Arpinar, I.
B., Moore, M., Sheth, A. P., & Aleman-Meza, B.
(2005, November).
OntoQA: Metric-basedontology quality analysis.
In IEEE Workshop on Knowledge Acquisition from Distributed, Autonomous, Se-mantically Heterogeneous Data and Knowledge Sources (Vol.
9).Troussov, A., Sogrin, M., Judge, J., & Botvich, D. (2008).
Mining socio-semantic networks using spreading acti-vation technique.
In Proc.
International Workshop on Knowledge Acquisition from the Social WebTsatsaronis, G., Vazirgiannis, M., & Androutsopoulos, I.
(2007, January).
Word Sense Disambiguation withSpreading Activation Networks Generated from Thesauri.
In IJCAI (Vol.
7, pp.
1725-1730).Van Dijk, K. R., Hedden, T., Venkataraman, A., Evans, K. C., Lazar, S. W., & Buckner, R. L. (2010).
Intrinsicfunctional connectivity as a tool for human connectomics: theory, properties, and optimization.
Journal of neu-rophysiology, 103(1), 297.Vrande?i?, D., & Sure, Y.
(2007).
How to design better ontology metrics.
In The Semantic Web: Research andApplications (pp.
311-325).
Springer Berlin Heidelberg.2248
