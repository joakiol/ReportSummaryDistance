Proceedings of the BioNLP Shared Task 2013 Workshop, pages 26?34,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsEVEX in ST?13: Application of a large-scale text mining resourceto event extraction and network constructionKai Hakala1, Sofie Van Landeghem3,4, Tapio Salakoski1,2,Yves Van de Peer3,4 and Filip Ginter11.
Dept.
of Information Technology, University of Turku, Finland2.
Turku Centre for Computer Science (TUCS), Finland3.
Dept.
of Plant Systems Biology, VIB, Belgium4.
Dept.
of Plant Biotechnology and Bioinformatics, Ghent University, Belgiumkahaka@utu.fi, solan@psb.ugent.be, yvpee@psb.ugent.be,ginter@cs.utu.fi, tapio.salakoski@utu.fiAbstractDuring the past few years, several noveltext mining algorithms have been de-veloped in the context of the BioNLPShared Tasks on Event Extraction.
Thesealgorithms typically aim at extractingbiomolecular interactions from text by in-specting only the context of one sen-tence.
However, when humans inter-pret biomolecular research articles, theyusually build upon extensive backgroundknowledge of their favorite genes andpathways.
To make such world knowl-edge available to a text mining algorithm,it could first be applied to all available lit-erature to subsequently make a more in-formed decision on which predictions areconsistent with the current known data.
Inthis paper, we introduce our participationin the latest Shared Task using the large-scale text mining resource EVEX whichwe previously implemented using state-of-the-art algorithms, and which was appliedto the whole of PubMed and PubMed Cen-tral.
We participated in the Genia EventExtraction (GE) and Gene Regulation Net-work (GRN) tasks, ranking first in the for-mer and fifth in the latter.1 IntroductionThe main objective of our entry was to test theusability of the large-scale text mining resourceEVEX to provide supporting information to anexisting state-of-the-art event extraction system.In the GE task, EVEX is used to extract addi-tional features for event extraction, capturing theoccurrence of relevant events in other documentsacross PubMed and PubMed Central.
In the GRNtask, EVEX is the sole source of information, i.e.our entry consists of a modified subset of EVEX,rather than a new text mining system specificallytrained for the task.In the 2011 GE task, the majority of partici-pating systems used features solely extracted fromthe immediate textual context of the event candi-date, typically restricted to a single sentence (Kimet al 2012; McClosky et al 2012; Bjo?rne et al2012b; Vlachos and Craven, 2012).
Several stud-ies have subsequently incorporated coreference re-lations, capturing information also from surround-ing sentences (Yoshikawa et al 2011; Miwa et al2012).
However, no prior work exists on extend-ing the event context to the information extractedfrom other documents on a large scale.
The moti-vation for this entry is thus to test whether a gaincan be obtained by aggregating information acrossdocuments with mutually supporting evidence.In the following sections, we first introduceEVEX as the underlying text mining resource, andthen describe the methods developed specificallyfor the GRN and GE task entries.
Finally, a de-tailed error analysis of the results offers insightinto the performance of our systems and providespossible directions of future development.2 EVEXEVEX1 is a text mining resource built on topof events extracted from all PubMed abstractsand PubMed Central Open-Access full-text doc-uments (Van Landeghem et al 2013a).
The ex-traction was carried out using a combination ofthe BANNER named entity detector (Leaman andGonzalez, 2008) and the TEES event extractionsystem as made publicly available subsequent tothe last Shared Task (ST) of 2011 (Bjo?rne et al2012a).
Specifically, this version of TEES wastrained on the ST?11 GE data.1http://www.evexdb.org26On top of the individual event occurrences,EVEX provides event generalizations, allowingthe integration and summarization of knowledgeacross different articles (Van Landeghem et al2011).
For instance, the canonicalization algo-rithm deals with small lexical variations by re-moving non-alphanumerical characters (e.g.
?Esr-1?
to ?esr1?).
The canonical generalization thengroups those events together with the same eventtype and the same canonicalized arguments.
Addi-tionally, gene normalization data has recently beenintegrated within the EVEX resource, assigningtaxonomic classification and database identifiersto gene mentions in text using the GenNorm sys-tem (Wei and Kao, 2011).
Finally, the assignmentof genes to homologous families allows a morecoarse-grained generalization of the textual data.For each generalized event, a confidence score isautomatically calculated based upon the originalTEES classification procedure, with higher valuesrepresenting more confident predictions.Finally, the EVEX resource provides a networkinterpretation which transforms events into pair-wise gene/protein relations to represent a typed,directed network.
The primary advantage of sucha network, as compared to the complex, recursiveevent structures, is that a network is more eas-ily analysed and integrated with other external re-sources (Kaewphan et al 2012; Van Landeghemet al 2013b).3 GRN TaskThe Gene Regulatory Network subtask of theST?13 aims at evaluating the ability of text min-ing systems to automatically compile a gene regu-lation network from the literature.
The task is fo-cused specifically on sporulation in Bacillus sub-tilis, a thoroughly studied process.3.1 Challenge definitionThe primary goal of our participation in this taskwas assessing the ability to reconstruct regulatorynetworks directly from the EVEX resource.
Con-sequently, we have applied the EVEX data as itis publicly available.
This decision has two majorconsequences.
First, we have used the predictedBANNER entities rather than the gold-standardentity annotation, artificially rendering the chal-lenge more difficult.
Second, we did not adapt theEVEX events, which follow the ST?11 GE formal-ism, to the novel annotation scheme of the GRNEVEX type GRN typeBinding BindingRegulation* of Transcription TranscriptionRegulation* of Gene expression TranscriptionPositive regulation of Any* ActivationNegative regulation of Any* InhibitionRegulation of Any* RegulationTable 1: Conversion of EVEX event types to theGRN types.
The table is traversed from top tobottom, and the first rule that matches is applied.Regulation* refers to any type of regulatory event,and Any* refers to any other non-regulatory eventtype.challenge, but rather derived the network data di-rectly from the EVEX interactions.
For example,given these trigger annotationsT1 Protein 37 43 sigmaBT2 Gene 54 58 katXT3 Transcription 59 69 expressiona GE Transcription event looks likeE1 Transcription:T3 Theme:T2 Cause:T1while the GRN annotation is given byR1 Transcription Target:E1 Agent:T1E1 Action_Target:T3 Target:T2However, both formalisms can easily be trans-lated into the required GRN network format:sigB Interaction.Transcription katXwhere ?sigB?
is annotated as the Gene identifierof ?sigmaB?.
These gene identifiers are providedin the gold-standard entity annotations.
Note thatin this context, ?gene identifiers?
are standardizedgene symbols rather than numeric identifiers, andfull gene normalization is thus not required.3.2 From EVEX to GRN dataAs a first step towards creating a gene regula-tory network directly from EVEX, we have down-loaded all pairwise relations of the canonical gen-eralization (Section 2).
For each such relation,we also obtain important meta-data, including theconfidence value, the PubMed IDs in which a re-lation was found, whether or not those articlesdescribe Bacillus subtilis research, and whetheror not those articles are part of the GRN train-ing or test set.
In the most stringent setting, wecould then limit the EVEX results only to thoserelations found in the articles of the GRN dataset(72 in training, 45 in the development set, 55 inthe test set).
Additionally, we could test whetherperformance can be improved by also adding allBacillus subtilis articles (17,065 articles) or even27GRN event type Possible target types Possible agent typesInteraction.Binding Protein GeneInteraction.Transcription Protein, PolymeraseComplex Gene, OperonInteraction.RegulationProtein, PolymeraseComplex Gene, Operon, Protein, ProteinComplexInteraction.ActivationInteraction.InhibitionTable 2: Entity-type filtering of event predictions.
Only those events for which the arguments (the targetas well as the agent) have the correct entity types, are retained in the result set.all EVEX articles in which at least one event wasfound (4,107,953 articles).To match the canonicalized BANNER entitiesfrom EVEX to the standardized gene symbolsrequired for the GRN challenge, we have con-structed a mapping based on the GRN data.
First,we have scanned all gold-standard entities andremoved non-alphanumerical characters from thegene symbols as tagged in text.
Next, these canon-ical forms were linked to the corresponding stan-dardized gene symbols in the gold-standard anno-tations.
From the EVEX data, we then only re-tained those relations that could be linked to twogene symbols occurring together in a sentence.Finally, it was necessary to convert the origi-nal EVEX event types to the GRN relation types.This mapping is summarized in Table 1.
BecauseEVEX Binding events are symmetrical and GRNBindings are not, we add both possible directionsto the result set.
Note that some GRN types couldnot be mapped because they have no equivalentwithin the EVEX resource, such as the GRN type?Requirement?
or ?Promoter?.3.3 Filtering the dataAfter converting the EVEX pairwise relations tothe GRN network format, it is necessary to fur-ther process the set of predictions to obtain a co-herent network.
One additional filtering step con-cerns the entity types of the arguments of a specificevent type.
From the GRN data, we can retrievea symbol-to-type mapping, recording whether aspecific symbol referred to e.g.
a gene, proteinor operon in a certain article.
After careful in-spection of the GRN guidelines and the trainingdata, we enforced the filtering rules as listed inTable 2.
For example, this procedure success-fully removes protein-protein interactions fromthe dataset, which are excluded according to theGRN guidelines.
Even though these rules are oc-casionally more restrictive than the original GRNguidelines, their effectiveness to prune the datawas confirmed on the training set.Further, the GRN guidelines specify that a setof edges with the same Agent and Target shouldbe resolved into a single edge, giving preferenceto a more specialized type, such as Transcriptionin favour of Regulation.
Further, contradictorytypes between a specific entity pair (e.g.
Inhibitionand Activation) may occur simultaneously in theGRN data.
For the EVEX data however, it is morebeneficial to try and pick one single correct eventtype from the set of predictions, effectively reduc-ing the false positive rate.
To this end, the EVEXconfidence values are used to determine the singlemost plausible candidate.
Further analyses on thetraining data suggested that the best performancecould be achieved when only retaining the ?Mech-anism?
edges (Transcription and Binding) in caseswhen no regulatory edge was found.
Finally, wenoted that the EVEX Binding events more oftencorrespond to the GRN Transcription type, andthey were thus systematically refactored as such(after entity-type filtering).
We believe this shiftin semantics is caused by the fact that a promoterbinding is usually extracted as a binding event bythe TEES classifier, while it can semantically beseen as a Transcription event, especially in thosecases where the Theme is a protein name, and theCause a gene symbol (Table 2).3.4 ResultsTable 3 lists the results of our method on the GRNtraining data, which was primarily used for tun-ing the parameters described in Section 3.3.
Thehighest recall (42%) could be obtained when usingall EVEX data, without restrictions on entity typesand without restricting to Bacillus subtilis articles.As a result, this set of predictions may contain re-lations between homologs in related species whichhave the same name.
While the relaxed F-score(41%) is quite high, the Slot Error Rate (SER)score (1.56) is unsatisfying, as SER scores shouldbe below 1 for decent predictions.When applying entity type restrictions to theprediction set, relaxed precision rises from 39%28Dataset ETF SER F Rel.
P Rel.
R Rel.
F Rel.
SERAll EVEX data no 1.56 8.86 39.29% 41.98% 40.59% 1.23All EVEX data yes 1.15 11.53 59.74% 35.11% 44.23% 0.89B.
subtilis PMIDs yes 0.954 20.81 71.43% 22.90% 34.68% 0.86GRN PMIDs yes 0.939 17.39 80.00% 18.32% 29.81% 0.86Table 3: Performance measurement of a few different system settings, applied on the training data.
TheSER score is the main evaluation criterion of the GRN challenge.
The relaxed precision, recall, F andSER scores are produced by scoring the predictions regardless of the specific event types.
ETF refers toentity type filtering.to 60%, the relaxed F-score obtains a maximumscore of 44%, and the SER score improves to1.15.
The SER score can further be improvedwhen restricting the data to Bacillus subtilis arti-cles (0.954).
The optimal SER score is obtained byfurther limiting the prediction set to only those re-lations found in the articles from the GRN dataset(0.939), maximizing at the same time the relaxedprecision rate (80%).The final run which obtained the best SER scoreon the training data was subsequently applied onthe GRN test data.
It is important to note that theparameter selection of our system was not overfit-ted on the training data, as the SER score of ourfinal submission on the test data is 0.92, i.e.
higherthan the best run on the training data.Table 4 summarizes the official results of allparticipants to the GRN challenge.
Interestingly,the TEES classifier has been modified to retrainitself on the GRN data and to produce eventannotations in the GRN formalism (Bjo?rne andSalakoski, 2013), obtaining a final SER score of0.86.
It is remarkable that this score is only 0.06points better than our system which needed no re-training, and which was based upon the originalGE annotation format and predicted gene/proteinsymbols rather than gold-standard ones.
Addition-ally, the events in EVEX have been produced by aversion of TEES which was maximized on F-scorerather than SER score, and these measurementsare not mutually interchangeable (Table 3).
Weconclude that even though our GRN system ob-tained last place out of 5 participants, we believethat its relative close performance to the TEESsubmission demonstrates that large-scale text min-ing resources can be used for gene regulatory net-work construction without the need for retrainingthe text mining component.3.5 Error analysisTo determine the underlying reasons of our rela-tively low recall rate, we have analysed the 117SER Relaxed SERUniversity of Ljubljana 0.73 0.64K.U.Leuven 0.83 0.66TEES-2.1 0.86 0.76IRISA-TexMex 0.91 0.60EVEX 0.92 0.81Table 4: Official GRN performance rates.false negative predictions of our final run on thetraining dataset.
We found that 23% could be at-tributed to a missing or incompatible BANNERentity, 59% to a false negative TEES prediction,15% to a wrong GRN event type and 3% to incor-rectly mapping the gene symbol to the standard-ized GRN format.
Analysing the 16 false positivesin the same dataset, 25% could be attributed to anincorrectly predicted event structure, and 62.5% toa wrongly predicted event type.
One case was cor-rectly predicted but from a sentence outside theGRN data, and in one case a correctly predictednegation context was not taken into account.
Inconclusion, future work on the GRN conversion ofTEES output should mainly focus on refining theevent type prediction, while general performancecould be enhanced by further improving the TEESclassification system.4 GE TaskOur GE submission builds on top of the TEES 2.1system2 as available just prior to the ST?13 test pe-riod.
First applying the unmodified TEES system,we subsequently re-ranked its output and enforceda cut-off threshold with the objective of removingfalse positives from the TEES output (Section 4.1).In the official evaluation, this step results in a mi-nor 0.23pp increase of F-score compared to unpro-cessed TEES output (Table 5).
This yields the firstrank in the primary measure of the task with TEESranking second.The main motivation for the re-ranking ap-2https://github.com/jbjorne/TEES/wiki/TEES-2.129P R FEVEX 58.03 45.44 50.97TEES-2.1 56.32 46.17 50.74BioSEM 62.83 42.47 50.68NCBI 61.72 40.53 48.93DlutNLP 57.00 40.81 47.56Table 5: Official precision, recall and F-score ratesof the top-5 GE participants, in percentages.proach was the ability to incorporate external in-formation from EVEX to compare the TEES eventpredictions and identify the most reliable ones.Further, such a re-ranking approach leads to an in-dependent component which is in no way bound toTEES as the underlying event extraction system.The component can be combined with any systemwith sufficient recall to justify output re-ranking.4.1 Event re-rankingThe output of TEES is re-ranked using SVMrank,a formulation of Support Vector Machines whichis trained to optimize ranking, rather than classifi-cation (Joachims, 2006).
It differs from the basiclinear SVM classifier in the training phase, when aquery structure is defined as a subset of instanceswhich can be meaningfully compared among eachother ?
in our case all events from a single sen-tence.
During training, only instances within asingle query are compared and the SVM does notaim to learn a global ranking across sentences anddocuments.
We also experimented with polyno-mial and radial basis kernels, feature vector nor-malization and broadening the ranking query setsto whole sections or narrowing them to only eventswith shared triggers, but none of these settingswere found to further enhance the performance.The re-ranker assigns a numerical score to eachevent produced by TEES, and all events belowa certain threshold score are removed.
To setthis threshold, a linear SVM regressor is appliedwith the SVMlight package (Joachims, 1999) toeach sentence individually, i.e.
we do not apply adata-wide, pre-set threshold.
Unlike the re-rankerwhich receives features from a single event at atime, the regressor receives features describing theset of events in a single sentence.Re-ranker featuresEach event is described using a number of fea-tures, including the TEES prediction scores fortriggers and arguments, the event structure, andthe EVEX information about this as well as simi-lar events.
Events can be recursively nested, withthe root event containing other events as its ar-guments.
The root event is of particular impor-tance as the top-most event.
A number of fea-tures are thus dedicated specifically to this rootevent, while other features capture properties ofthe nested events.Features derived from TEES confidence scores:?
TEES trigger detector confidence of the rootevent and its difference from the confidenceof the negative class, i.e.
the margin by whichthe event was predicted by TEES.?
Minimum and maximum argument confi-dences of the root event.?
Minimum and maximum argument confi-dences, including recursively nested events(if any).?
Minimum and maximum trigger confidences,including recursively nested events (if any).?
Difference between the minimum and max-imum argument confidences compared toother events sharing the same trigger word.Features describing the structure of the event:?
Event type of the root trigger.?
For each path in the event from the root toa leaf argument, the concatenation of eventtypes along the path.?
For each path in the event from a leaf argu-ment to another leaf argument, the concate-nation of event types along the path.?
The event structure encoded in the bracketednotation with leaf (T)heme and (C)ause argu-ments replaced by a placeholder string, e.g.Regulation(C:_, T:Acetylation(T:_)).Features describing other events in the same sen-tence:?
Event counts for each event type.?
Event counts for each unique event structuregiven by the bracketed structure notation.All event counts extracted from EVEX are rep-resented as their base-10 logarithm to compressthe range and suppress differences in counts ofvery common events.The following features are generated in two ver-sions, one by grouping the events according to theEVEX canonical generalization and one for theEntrez Gene generalization (Section 2)3.3The generalizations based on gene families were evalu-ated as well, but did not result in a positive performance gain.30?
All occurrences of the given event in EVEX.?
For each path from root to a leaf gene/protein,all occurrences of that exact path in EVEX.?
For each pair of genes/proteins in the event,all occurrences of that pair in the network in-terpretation of EVEX.?
For each pair of genes/proteins in the event,all occurrences of that pair with a differentevent type in the network interpretation ofEVEX.For each event, path, or pair under considera-tion, features are created for the base-10 logarithmof the count in EVEX and of the number of uniquearticles in which it was identified, as well as forthe minimum, maximum, and average confidencevalues, discretized into six unique categories.Regressor featuresWhile the re-ranker features capture a single eventat a time, the threshold regressor features aggre-gate information about events extracted within onesentence.
The features include:?
For each event type, the average and mini-mum re-ranker confidence score, as well asthe count of events of that type.?
For each event type, the count of events shar-ing the same trigger.?
For each event type, the count of events shar-ing the same arguments.?
Minimum and maximum confidence valuesof triggers and arguments in the TEES out-put for the sentence.?
The section in the article in which the sen-tence appears, as given in the ST data.4.2 Training phaseTo train the re-ranker and the regressor, false pos-itive events are needed in addition to the true pos-itive events in the training data.
We thus applyTEES to the training data and train the re-rankerusing the correct ranking of the extracted events.A true positive event is given the rank 1 and a falsepositive event gets the rank -1.
A query structureis then defined, grouping all events from a sin-gle sentence to avoid mutual comparison of eventsacross sentences and documents during the train-ing phase.The trained re-ranker is then again applied tothe training data.
For every sentence, the optimalthreshold is set to be the re-ranker score of the lastevent which should be retained so as to maximize# P R FSimple events 833 -0.08 -0.36 -0.23Protein mod.
191 +0.09 -2.09 -1.12Binding 333 +0.43 -1.20 -0.44Regulation 1944 +2.38 -0.67 +0.36All 3301 +1.71 -0.73 +0.23Table 6: Performance difference in percentagepoints against the TEES system in the official testset results, shown for different event types.the F-score.
In case the sentence only containsfalse positives, the highest score is used, increasedby an empirically established value of 0.2.
A sim-ilar strategy is applied for sentences only contain-ing true positives by using the lowest score, de-creased by 0.2.In both steps, the SVM regularization parameterC is set by a grid search on the development set.Applying TEES and the re-ranker back to thetraining set results in a notably smaller propor-tion of false positives than would be expected ona novel input.
To obtain a fully realistic train-ing dataset for the re-ranker and threshold regres-sor would involve re-training TEES in a cross-validation setting, but this was not feasible due tothe tight schedule constraints of the shared task,and is thus left as future work.4.3 Error analysisAlthough the re-ranking approach resulted in aconsistent gain over the state-of-the-art TEES sys-tem on both the development and the test sets,the overall improvement is only modest.
As sum-marized in Table 6, the gain over the TEES sys-tem can be largely attributed to regulation eventswhich exhibit a 2.38pp gain in precision for a0.67pp loss in recall.
Regulation events are at thesame time by far the largest class of events, thusaffecting the overall score the most.In this section, we analyse the re-ranker andthreshold regressor in isolation to understand theirindividual contributions to the overall result and toidentify interesting directions for future research.To isolate the re-ranker from the threshold re-gressor and to identify the maximal attainable per-formance, we set an oracle threshold in every sen-tence so as to maximize the sentence F-score andinspect the performance at this threshold, effec-tively bypassing the threshold regressor.
This,however, provides a very optimistic estimate forsentences where all predicted events are false pos-itives, because the oracle then simply obtains the31All events P R FB-C oracle (re-ranked) 81.32 39.61 53.27W-C oracle (re-ranked) 54.92 39.61 46.02W-C oracle (random) 51.06 39.19 44.34Current system 47.15 39.61 43.05TEES 45.46 40.39 42.77Single-arg.
eventsB-C oracle (re-ranked) 81.37 50.58 62.38W-C oracle (re-ranked) 56.09 50.58 53.19W-C oracle (random) 52.73 50.00 51.33Current system 48.66 50.44 49.53TEES 47.16 51.09 49.04Multiple-arg.
eventsB-C oracle (re-ranked) 81.02 16.83 27.87W-C oracle (re-ranked) 48.61 16.83 25.00W-C oracle (random) 42.66 16.75 24.05Current system 39.64 17.12 23.91TEES 37.57 18.17 24.50Table 7: Performance comparison of the best case(B-C) and worst case (W-C) oracles, the currentsystem with the re-ranker and threshold regressor,and TEES.
As an additional baseline, the worstcase oracle is also calculated for randomly rankedoutput.
All results are reported also separately forsingle and multiple-argument events.decisions from the gold standard and the rank-ing itself is irrelevant.
This effect is particu-larly pronounced in sentences where only a sin-gle, false positive event is predicted (15.9% of allsentences with at least one event).
Therefore, inaddition to this best case oracle score, we also de-fine a worst case oracle score, where no eventsare removed from sentences containing only false-positives.
This error analysis is carried out on thedevelopment set using our own implementation ofthe performance measure to obtain per-event cor-rectness judgments.The results are shown in Table 7.
Even for theworst case oracle, the re-ranked output has the po-tential to provide a 9.5pp increase in precision fora 0.8pp loss in recall over the baseline TEES sys-tem.
How much of this potential gain is realizeddepends on the accuracy of the threshold regres-sor.
In the current system, only a 1.7pp precisionincrease for a 0.8pp recall loss is attained, demon-strating that the threshold regressor leaves muchroom for improvement.The best case oracle precision is 26.4pp higherthan the worst case oracle, indicating that substan-tial performance losses can be attributed to sen-tences with purely false positive events.
Indeed,sentences only containing one or two incorrectevents account for 26% of all sentences with atleast one predicted event.
Due to their large impactTEES 1-arg N-arg FullSimple events 64.43 +0.07 ?0.00 +0.07Protein mod.
40.47 +0.06 ?0.00 +0.06Binding 82.03 ?0.00 ?0.00 ?0.00Regulation 30.34 +0.70 -0.14 +0.53All events 45.04 +0.66 ?0.00 +0.64Table 8: Performance of the system on the de-velopment set when applied to single-argumentevents only (1-arg), to multiple-argument eventsonly (N-arg), and to all events (Full).on the overall system performance, these casesmay justify a focused effort in future research.To establish the relative merit of the re-ranker,we compare the worst-case oracle scores of the re-ranked output against random ranking, averagedover 10 randomization runs.
While the differencebetween TEES output and the random ranking re-flects the effect of using an oracle to optimize per-sentence score, the difference between the ran-dom ranking and the re-ranker output shows anactual added value of the re-ranker, not attainedfrom the use of oracle thresholds.
Here it is ofparticular interest to note that this difference ismore pronounced for events with multiple argu-ments (5.95pp of precision) as opposed to single-argument events (3.36pp of precision), possiblydue to the fact that such events have a much richerfeature representation and also employ the EVEXresource.
To assess the contribution of EVEXdata, a re-ranker was trained solely on features de-rived from EVEX.
This re-ranker achieved an F-score of 1.26pp higher than randomized ranking,thus suggesting that these features have a positiveinfluence on the overall score.To verify these results and measure their im-pact on the official evaluation, Table 8 summa-rizes the performance on the development set us-ing the official evaluation service.
To study theeffect on single-argument events (column 1-arg),the re-ranker score for multiple-argument eventsis artificially increased to always fall above thethreshold.
A similar strategy is used to studythe effect on multiple-argument events (columnN-arg).
These results confirm that the overallperformance gain of our system on top of TEESis obtained on single-argument events.
Further,multiple-argument events have only a negligibleeffect on the overall score, demonstrating that, dueto their low frequency, little can be gained or lostpurely on multiple-argument events.To summarize the error analysis, the results in32Table 7 suggest that the re-ranker is more effec-tive on multiple-argument events where it receivesmore features including external information fromEVEX.
On the other hand, the results in Table 8clearly demonstrate that the system is overall moreeffective on single-argument events.
This wouldsuggest a ?mismatch?
between the re-ranker andthe threshold regressor, each being more effectiveon a different class of events.
One possible expla-nation is the fact that the threshold regressor pre-dicts a single threshold for all events in a sentence,regardless of their type and number of arguments.If these cannot be distinguished by one threshold,it is clear that the threshold regressor will optimizefor the largest event type, i.e.
a single-theme regu-lation.
Studying ways to allow the regressor to actseparately on various event types will be importantfuture work.4.4 Discussion and future workOne of the main limitations of our approach isthat it can only increase precision, but not recall,since it removes events from the TEES output, butis not able to introduce new events.
As TEESutilizes separate processing stages for predictingevent triggers and argument edges, recall can beadjusted by altering either of these steps.
Wehave briefly experimented with modifying TEESto over-generate events by artificially lowering theprediction threshold for event triggers.
However,this simple strategy of over-generating triggersleads to a number of clearly incorrect events anddid not provide any performance gain.
As futurework, we thus hope to explore effective ways toover-generate events in a more controlled and ef-fective fashion.
In particular, a more detailed eval-uation is needed to assess whether the rate of trig-ger over-generation should be adjusted separatelyfor each event type.
Another direction to exploreis to over-generate argument edges.
This will en-tail a detailed analysis of partially correct eventswith a missing argument in TEES output.
As inthe case of triggers, it is likely that each event typewill need to be optimized separately.A notable amount of sentences include onlyfalse positive predictions, severely complicatingthe threshold regression.
In an attempt to over-come this issue, we trained a sentence classifierfor excluding sentences that should not containany events.
This classifier partially utilized thesame features as the threshold regressor, as wellas bag of words and bag of POS tags.
Thismethod showed some promise when used togetherwith trigger over-generation, but the gain was notenough to surpass the lost precision caused by theover-generation.
If the event over-generation canbe improved, the feasibility of this method shouldbe re-evaluated.5 ConclusionsWe have presented our participation in the latestBioNLP Shared Task by mainly relying on thelarge-scale text mining resource EVEX.
For theGRN task, we were able to produce a gene reg-ulatory network from the EVEX data without re-training specific text mining algorithms.
Usingpredicted gene/protein symbols and the GE for-malism, rather than gold standard entities and theGRN annotation scheme, our final result on thetest set only performed 0.06 SER points worseas compared to the corresponding TEES submis-sion.
This encouraging result warrants the use ofgeneric large-scale text mining data in network bi-ology settings.
As future work, we will extend theEVEX dataset with information on the entity typesto enable pruning of false-positive events andmore fine-grained classification of event types,such as the distinction between promoter binding(Protein-Gene Binding) and protein-protein inter-actions (Protein-Protein Binding).In the GE task, we explored a re-ranking ap-proach to improve the precision of the TEESevent extraction system, also incorporating fea-tures from the EVEX resource.
This approachled to a modest increase in the overall F-scoreof TEES and resulted in the first rank on the GEtask.
In the subsequent error analysis, we havedemonstrated that the re-ranker provides an oppor-tunity for a substantial increase of performance,only partially realized by the regressor which setsa per-sentence threshold.
The analysis has identi-fied numerous future research directions.AcknowledgmentsComputational resources were provided by CSCIT Center for Science Ltd., Espoo, Finland.
Thework of KH and FG was supported by theAcademy of Finland, and of SVL by the ResearchFoundation Flanders (FWO).
YVdP and SVL ac-knowledge the support from Ghent University(Multidisciplinary Research Partnership Bioinfor-matics: from nucleotides to networks).33ReferencesJari Bjo?rne and Tapio Salakoski.
2013.
TEES 2.1: Au-tomated annotation scheme learning in the BioNLP2013 Shared Task.
In Proceedings of BioNLPShared Task 2013 Workshop.
In press.Jari Bjo?rne, Filip Ginter, and Tapio Salakoski.
2012a.Generalizing biomedical event extraction.
BMCBioinformatics, 13(suppl.
8):S4.Jari Bjo?rne, Filip Ginter, and Tapio Salakoski.
2012b.University of Turku in the BioNLP?11 Shared Task.BMC Bioinformatics, 13(Suppl 11):S4.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Advances in Kernel Methods -Support Vector Learning.Thorsten Joachims.
2006.
Training linear SVMs inlinear time.
In Proceedings of the ACM Conferenceon Knowledge Discovery and Data Mining (KDD).Suwisa Kaewphan, Sanna Kreula, Sofie Van Lan-deghem, Yves Van de Peer, Patrik Jones, and FilipGinter.
2012.
Integrating large-scale text miningand co-expression networks: Targeting NADP(H)metabolism in E. coli with event extraction.
In Pro-ceedings of the Third Workshop on Building andEvaluating Resources for Biomedical Text Mining(BioTxtM 2012).Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsu-jii, Toshihisa Takagi, and Akinori Yonezawa.
2012.The Genia event and protein coreference tasks of theBioNLP Shared Task 2011.
BMC Bioinformatics,13(Suppl 11):S1.Robert Leaman and Graciela Gonzalez.
2008.
BAN-NER: an executable survey of advances in biomedi-cal named entity recognition.
Pacific Symposium onBiocomputing.
Pacific Symposium on Biocomputing,pages 652?663.David McClosky, Sebastian Riedel, Mihai Surdeanu,Andrew McCallum, and Christopher Manning.2012.
Combining joint models for biomedical eventextraction.
BMC Bioinformatics, 13(Suppl 11):S9.Makoto Miwa, Paul Thompson, and Sophia Ana-niadou.
2012.
Boosting automatic event ex-traction from the literature using domain adapta-tion and coreference resolution.
Bioinformatics,28(13):1759?1765.Sofie Van Landeghem, Filip Ginter, Yves Van de Peer,and Tapio Salakoski.
2011.
EVEX: a PubMed-scaleresource for homology-based generalization of textmining predictions.
In Proceedings of the BioNLP2011 Workshop, pages 28?37.Sofie Van Landeghem, Jari Bjo?rne, Chih-Hsuan Wei,Kai Hakala, Sampo Pyysalo, Sophia Ananiadou,Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, YvesVan de Peer, and Filip Ginter.
2013a.
Large-scale event extraction from literature with multi-level gene normalization.
PLoS ONE, 8(4):e55814.Sofie Van Landeghem, Stefanie De Bodt, Zuzanna J.Drebert, Dirk Inze?, and Yves Van de Peer.
2013b.The potential of text mining in data integration andnetwork biology for plant research: A case study onArabidopsis.
The Plant Cell, 25(3):794?807.Andreas Vlachos and Mark Craven.
2012.
Biomedicalevent extraction from abstracts and full papers usingsearch-based structured prediction.
BMC Bioinfor-matics, 13(Suppl 11):S5.Chih-Hsuan Wei and Hung-Yu Kao.
2011.
Cross-species gene normalization by species inference.BMC Bioinformatics, 12(Suppl 8):S5.Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hi-rao, Masayuki Asahara, and Yuji Matsumoto.
2011.Coreference based event-argument relation extrac-tion on biomedical text.
Journal of Biomedical Se-mantics, 2(Suppl 5):S6.34
