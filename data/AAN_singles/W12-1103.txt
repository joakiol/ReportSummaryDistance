JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 25?31,Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCPAcquisition terminologique pour identifier les mots cl?sd?articles scientifiquesThierry HamonLIM&BIO (EA3969)Universit?
Paris 1393017 Bobigny CedexFrancethierry.hamon@univ-paris13.frR?SUM?Le d?fi Fouille de texte 2012 (DEFT2012) a pour objectif d?identifier automatiquement des motscl?s choisis par les auteurs d?articles scientifiques dans les Sciences Humaines et Sociales.
Uneliste de termes constitu?e des mots cl?s est fournie dans la t?che 1.
Pour participer ?
ce d?fi,nous avons choisi d?exploiter des outils d?di?s ?
la constitution de terminologies structur?es.
Lestermes obtenus sont aussi ?t?
tri?s et filtr?s ?
l?aide de leur position, de m?thodes de pond?rationstatistiques et de crit?res linguistiques.
Plusieurs configurations de notre syst?me ont ?t?
d?finies.Nous avons obtenu une F-mesure de 0,3985 dans la t?che 1 et de 0,1921 dans la t?che 2.ABSTRACTTerminological acquisition for identifying keywords of scientific articlesThe challenge DEFT2012 aims at automatically identifying the keywords chosen by the authorsof scientific articles in the Humanities.
A keyword list is provided within the track 1.
We proposeto exploit terminological acquisition approaches.
The extracted terms are also sorted and filteredaccording to their position in the documents, weighting measures and linguistic criteria.
Wedefined several configurations of our system.
Our best F-measure for the track 1 is 0.3985 whilefor the track 2, the best F-measure is 0.1921.MOTS-CL?S : Mots cl?s, extraction de termes, mesure de pond?ration, filtrage de termes.KEYWORDS: Keywords, Term Recognition, Weighting Measure, Term Filtering.1 IntroductionL?association de mots cl?s ?
un document, notamment ?
un article scientifique, est un aspectimportant de l?indexation documentaire.
L?objectif du d?fi fouille de texte 2012 (DEFT2012)est d?identifier automatiquement les mots cl?s choisis par les auteurs d?articles scientifiques enSciences Humaines et Sociales.
Deux t?ches sont propos?es.
Dans la premi?re t?che, une listede mots cl?s est fournie.
Il s?agit donc de retrouver les mots cl?s les plus pertinents pour undocument donn?, parmi ceux fournis.
Dans la deuxi?me t?che, aucune liste de mots cl?s n?estfournie.
Il s?agit alors d?identifier les mots cl?s pouvant ?tre associ?s ?
chaque document.
Dans25les deux cas, le nombre de mots cl?s attendus est connu.Apr?s une description, ?
la section 2, du mat?riel utilis?, nous pr?sentons les diff?rentes approcheset param?tres utilis?s ?
la section 3.
Nous d?crivons ensuite, ?
la section 4, les diff?rentesexp?rimentations qui nous permis d?obtenir les r?sultats pr?sent?s ?
la section 5.2 Mat?rielNous avons ?
notre disposition un corpus pour les phases d?entra?nement et de test de chaquet?che.
De plus, pour la t?che 1, une liste des mots cl?s associ?s ?
l?ensemble des documents ducorpus est mise ?
disposition.Corpus Le corpus est compos?
d?articles scientifiques parus entre 2001 et 2008 dans des revuesde Sciences Humaines et Sociales :?
Revue des Sciences de l?
?ducation (RSE),?
Traduction, Terminologie, R?daction (TTR),?
Anthropologie et Soci?t?s (AS),?
Meta (journal des traducteurs ?
META).Le corpus est d?compos?
en quatre sous-corpus, constituant les ensembles d?entra?nement etde test pour les t?ches 1 et 2.
Pour chaque t?che, le corpus d?entra?nement comporte environ 1million de mots (environ 60% de la totalit?
du corpus pour une t?che donn?e), tandis que lescorpus de test sont constitu?s de 680 668 mots pour la t?che 1 et 639 267 mots pour la t?che 2(voir tableau 1).
Les corpus d?entra?nement ?taient disponibles pendant environ 2 mois, tandisque les corpus de test devaient ?tre trait?s en 3 jours.Entra?nement TestRevue T?che 1 T?che 2 T?che 1 T?che 2mots doc.
mots doc.
mots doc.
mots doc.RSE 143 314 19 160 387 20 112 203 13 91 371 13TTR 95 731 13 96 083 13 65 056 9 65 382 9AS 459 467 56 435 146 56 297 006 38 269 535 37META 334 238 52 339 051 52 206 412 34 212 979 34Total 1 032 750 140 1 030 667 94 680 677 141 639 267 93TABLE 1 ?
Description des corpus d?entra?nement et de test pour les t?ches 1 et 2 (nombre demots et de documents).Liste des mots cl?s Pour la t?che 1, nous disposons ?galement de la liste de mots cl?s ducorpus.
Ainsi, lors de l?entra?nement, nous disposons de 66 mots cl?s, et lors de la phase de test,de 478 mots cl?s.263 M?thodeAfin d?identifier les mots cl?s de chaque document, nous avons choisi d?utiliser dans un premiertemps des approches d?extraction et de reconnaissance terminologiques (section 3.1).
Les r?sul-tats de cette premi?re ?tape sont ensuite tri?s avec des m?thodes de pond?ration des termes(section 3.2).
Enfin, une ?tape de filtrage et de s?lection des termes tri?s permet d?identifier lesmots cl?s potentiellement les plus pertinents pour chaque document (section 3.3)3.1 Acquisition terminologiqueDans cette premi?re ?tape, nous avons exploit?
des m?thodes de reconnaissance ou d?extractionde termes pour identifier des mots cl?s.
Afin d?
?tendre la couverture de l?acquisition de termes etd?am?liorer l?
?tape de filtrage, nous avons ?galement acquis des variantes morpho-syntaxiquesdes termes extraits.Reconnaissance de termes (TermTagger).
Les mots cl?s fournis lors de la t?che 1 ont ?t?projet?s sur l?ensemble des documents du corpus de travail.
Cette projection a ?t?
?largie enprenant en compte les lemmes de mots du corpus.
Pour r?aliser la reconnaissance des mots cl?s,nous avons utilis?
le module Perl Alvis::TermTagger 1.Extraction des termes (YATEA).
Afin d?identifier les mots cl?s, nous avons choisi d?utiliser unem?thode d?extraction de termes.
Les mots cl?s pouvant ?tre des mots ou des groupes nominaux,nous conservons aussi bien les termes complexes que leurs composants simples.
Cette approche a?t?
utilis?e lors de la t?che 2 (o?
aucune liste de mots cl?s n?est fournie) mais aussi lors de lat?che 1 pour ?tendre l?identification des mots cl?s.Pour r?aliser l?extraction de termes sur les corpus, nous avons utilis?
YATEA 2 (Aubin et Hamon,2006).
Cet outil terminologique a pour objectif d?extraire d?un corpus des groupes nominauxqui peuvent ?tre consid?r?s comme de termes candidats.
Il fournit leur analyse syntaxique sousforme d?une d?composition en t?te et modifieur.
L?extraction des termes est r?alis?e sur descrit?res linguistiques (patrons d?analyse simples utilis?s de mani?re r?cursive et combin?s ?une d?sambiguisation endog?ne et la prise en compte de ph?nom?ne de variation morpho-syntaxique).
Des mesures de pond?ration statiques sont ?galement associ?es ?
chaque terme(fr?quence, TF-IDF, etc.
).Acquisition de variantes morpho-syntaxiques (Faster).
L?acquisition de variantes morpho-syntaxiques nous permet d?
?tendre la couverture des termes extraits par YATEA, mais aussid?am?liorer le tri et le filtrage des termes extraits.Nous avons utilis?
Faster (Jacquemin, 1997) en mode indexation libre.
Il nous est ainsi possiblede reconna?tre les variantes des termes extraits par YATEA ?
travers trois types de variationmorpho-syntaxique : la coordination de termes, l?insertion et la juxtaposition de modifieurs1.
http://search.cpan.org/~thhamon/Alvis-TermTagger/2.
http://search.cpan.org/~thhamon/Lingua-YaTeA/27et la permutation.
Comme nous ne disposons pas de ressources d?rivationnelles, les variantesd?rivationelles n?ont pas pu ?tre identifi?es.3.2 M?thodes de pond?rationAfin d?identifier les mots cl?s parmi les termes extraits du corpus, ceux-ci doivent ?tre tri?s parordre de pertinence.
Pour cela, nous avons utilis?
plusieurs m?thodes de pond?ration :?
la fr?quence du terme dans le document (tf)?
le TF-IDF associ?
au terme (Salton et McGill, 1986)?
la position de la premi?re occurrence du terme (position).
Nous consid?rons ici que les termessitu?s au d?but du document ont un poids plus ?lev?s que ceux situ?s ?
la fin.
La position estle nombre de caract?res depuis le d?but du document.
Les termes sont alors tri?s dans l?ordred?croissant.
Nous n?avons pas distingu?
le r?sum?
du reste du document afin d?avoir les termespr?sents dans le r?sum?
parmi les premi?res positions.?
le cosinus de la position de la premi?re occurrence du terme (positionCos).
Nous avonsfait l?hypoth?se que les termes pr?sents au d?but (notamment dans les sections r?sum?
etintroduction) ou ?
la fin (notamment conclusion) du document sont les plus pertinents.
Onplace ainsi la premi?re occurrence de chaque terme sur le cercle trigonom?trique en consid?rantque le d?but du document est l?angle 0 et la fin l?angle 2pi.
Nous avons calcul?
le cosinus del?angle form?
par la position.?
l?origine des termes (termOrigin).
Les termes issus de la liste de mots cl?s sont prioritaire surles termes extraits par YATEA ou les variantes morpho-syntaxiques.
Dans le cas des termes extraitsautomatiquement, la pond?ration peut tenir compte de l?application du filtre filtrTermino(voir section 3.3).3.3 Filtrage et s?lection des termesLes termes peuvent ?tre filtr?s ou regroup?s suivant diff?rents crit?res linguistiques :?
Suppression des termes situ?s dans des phrases r?dig?s dans une langue autre que le fran?ais(filtrLang).
Les revues ?tant issues des Sciences Humaines et Sociales, les articles contiennentdes phrases exemples pouvant ?tre ?crits dans diff?rentes langues.
L?extracteur de termes identi-fie alors des termes qu?il n?est pas n?cessaire de consid?rer comme des mots cl?s.
Pour identifierla langue des phrases des articles, nous avons utilis?
le module Perl Lingua::Identify 3 enutilisant les param?tres par d?faut et ne visant ?
identifier que le fran?ais, l?anglais, l?allemand,l?espagnol et l?italien.?
Suppression des termes (modifieurs de termes complexes) ?tiquet?s comme adjectifs.
Lesadjectifs correspondant ?
des mots cl?s sont conserv?s (filtrAdj) lors de la t?che 1.
Parexemple, espagnol est ?tiquet?
comme un adjectif mais peut correspondre ?
un nom et donc ?un mot cl?.
Il est alors conserv?.?
Prise en compte de l?inclusion lexicale : les termes en position t?te d?un terme et ayant derang plus ?lev?
dans la liste tri?e sont supprim?s (filtrInclLex).
Par exemple, dans la liste tri?e(Verbes supports, traduction, paraphrase, traduction automatique), le terme traduction serasupprim?
car celui-ci est inclus dans le terme traduction automatique.3.
http://search.cpan.org/~ambs/Lingua-Identify/28?
Regroupement des termes en fonction de leur forme canonique (concat?nation des lemmesdes composants) et filtrage par la forme fl?chie la plus fr?quente (filtrCan).?
S?lection des termes contenant au moins un mot plein issu de la liste des mots cl?s (filtrTermino).Nous faisons l?hypoth?se que si les mots cl?s sont compos?s de mots caract?ristiques du do-maine (en ?cartant les mots vides), il est possible de conserver les termes compos?s de cesmots.
Nous avons ?galement associ?
?
chaque terme, un poids correspondant ?
la proportionde mots caract?ristiques pr?sents parmi les mots composants le terme.Les filtres filtrAdj et filtrTermino sont appliqu?s avant le tri de la liste de termes par ordre depertinence, tandis que les autres sont utilis?s avec la liste des termes tri?s.
La liste r?sultante dece filtrage est ensuite r?duite au nombre de mots cl?s attendus pour chaque document.4 Exp?rimentationsNous avons r?alis?
plusieurs exp?riences afin d?identifier les combinaisons de param?tres lesplus adapt?s pour l?identification des mots cl?s.
L?ensemble des traitements a ?t?
r?alis?
dans laplate-forme Ogmios (Hamon et Nazarenko, 2008).
Chaque corpus a ?t?
segment?
en mots et enphrases.
Nous avons utilis?
le TreeTagger (Schmid, 1997) pour l?
?tiquetage morpho-syntaxiqueet la lemmatisation des mots.
En fonction des param?tres des exp?riences, nous avons utilis?
aumoins un des trois outils terminologiques (TermTagger, YATEA, Faster) d?crits ?
la section 3.1.
Leslistes de termes ont ensuite ?t?
tri?es et filtr?es en combinant plusieurs param?tres.A partir des r?sultats sur le corpus d?entra?nement, nous avons d?fini 3 runs pour les t?ches 1et 2.
Pour tous les runs, nous avons effectu?
un filtrage sur la langue (filtrLang) et les adjectifs(filtrAdj).T?che 1 (utilisation de la liste des mots cl?s)?
Run 1 : Les termes sont identifi?s ?
l?aide du TermTagger en exploitant la liste des mots cl?sfournie par le d?fi.
Suite aux r?sultats sur le corpus d?entra?nement, nous avons choisi dediff?rencier les m?thodes de filtrage en fonction des sous-corpus.
Ainsi, pour les sous-corpusRSE, TTR et META, nous avons exploit?
la position des termes pour trier la liste, alors quepour le sous-corpus AS, les termes sont tri?s en fonction du produit des poids positionCos ettf.
Le filtre filtrInclLex est ensuite appliqu?
pour r?duire la liste des termes et s?lectionner lesmots cl?s.?
Run 2 : Nous avons exploit?
TermTagger et YATEA pour extraire les termes du corpus.
Le filtrefiltrTermino a ?t?
appliqu?
pour d?une part s?lectionner les termes les plus pertinents, d?autrepart pour associer le poids termOrigin aux termes extraits par YATEA.
La liste des termes aensuite ?t?
tri?e en fonction de la m?thode de pond?ration termOrigin et, lorsque les valeurssont ?gales, en fonction du poids tf.?
Run 3 : dans ce run, nous avons ?galement exploit?
TermTagger et YATEA pour extraire lestermes du corpus et le filtre filtrTermino.
Nous avons choisi d?utiliser diff?rents poids pour letri de la liste des termes en fonction des sous-corpus.
Ainsi, pour les sous-corpus RSE et TTR,nous avons exploit?
le TF-IDF pour trier les termes.
Pour les sous-corpus META et AS, nousutilis?
le produit des poids positionCos et tf.29T?che 2?
Run 1 : L?extraction des termes a ?t?
r?alis?
?
l?aide de YATEA.
Nous avons ensuite exploit?
leTF-IDF pour trier la liste des termes.
Celle-ci a ensuite ?t?
r?duite ?
l?aide du filtre filtrCan(regroupement des termes poss?dant les m?mes formes canoniques).?
Run 2 : Nous avons utilis?
YATEA pour extraire les termes du corpus et Faster.
La liste destermes a ?t?
tri?e en fonction du produit des poids positionCos et TF-IDF, et r?duite ?
l?aidedu filtre filtrCan.?
Run 3 : Les termes ont ?t?
extraits ?
l?aide de YATEA.
Nous avons utilis?
le produit des poidspositionCos et tf pour trier les termes.
Les termes ont ensuite ?t?
s?lectionn?
?
l?aide du filtrefiltrCan.5 R?sultats et discussionLes r?sultats obtenus sur le corpus de test sont pr?sent?s dans le tableau 2.
Le meilleur runde la t?che 1 obtient une F-mesure de 0,39.
Il s?agit de projeter les mots cl?s et de les trier enfonction de leur position.
Les exp?rimentations sur les corpus d?entra?nement ont montr?
queles param?tres li?s ?
la position (position et positionCos) ont une influence sur les r?sultats.Les r?sultats obtenus sur les deux autres runs semblent montrer que la fr?quence des termesd?gradent l?identification des mots cl?s.
Enfin, sur le corpus d?entra?nement, nous avons observ?que seulement 72 % des mots cl?s projet?s avec TermTagger ?taient pr?sents dans le corpus 4,et que l?utilisation de YATEA permet d?augmenter l?g?rement les r?sultats (+0,5 %).
De m?me,YATEA permet d?identifier 55 % des mots cl?s.En ce qui concerne la t?che 2, nous obtenons une F-mesure de 0,19 pour le meilleur run.
Il s?agitde trier les termes extraits avec YATEA, en fonction du produit des poids positionCos et de lafr?quence dans le document, les termes ?tant ensuite regroup?s et filtr?s en fonction de leurforme canonique.Run t?che 1 T?che 2Pr?cision Rappel F-mesure Pr?cision Rappel F-mesure1 0,3985 0,3985 0,3985 0,1798 0,1798 0,17982 0,3333 0,3333 0,3333 0,1612 0,1612 0,16123 0,2253 0,2253 0,2253 0,1921 0,1921 0,1921TABLE 2 ?
R?sultats sur le corpus de testL?analyse des r?sultats montre que lorsque la liste des mots cl?s est fournie, la position de lapremi?re occurrence de termes est pr?pond?rante lors des phases de tri et de s?lection.
Parailleurs, l?utilisation d?un extracteur de termes permet de couvrir correctement les mots cl?s?
identifier.Enfin, les mesures de pond?ration globales telles que le TF-IDF ne permettent pasd?obtenir des r?sultats satisfaisants (le constat est le m?me avec la CValue (Maynard et Ananiadou,2000)).4.
Il s?agit d?un calcul du rappel l?g?rement diff?rent de celui utilis?
par les organisateurs du d?fi.306 ConclusionNous avons exploit?
des approches d?di?es ?
l?acquisition terminologique pour identifier desmots cl?s dans des corpus d?articles scientifiques des Sciences Humaines et Sociales.
Les listes determes extraites ont ?t?
tri?es et filtr?es ?
l?aide de m?thodes de pond?ration (position, fr?quenceau sein du document, TF-IDF, etc.)
et de crit?res linguistiques.
Les r?sultats obtenus montrentl?importance de la prise en compte de la position dans cette t?che quel que soit le cas de figure.En revanche, une m?thode de pond?ration globale comme le TF-IDF ne semble pas ?tre tr?s utiledans ce contexte applicatif.Les approches d?acquisition terminologique et notamment les extracteurs de termes, permettentd?obtenir une couverture relativement correcte, mais il est n?cessaire de poursuivre les inves-tigations sur les mesures statistiques permettant de trier au mieux les termes extraits.
Nousenvisageons par la suite d?utiliser l?algorithme de Page Rank (Page et al, 1998) pour trier etfiltrer les termes.
De m?me la structure des documents pourraient ?tre exploit?s beaucoup plus,notamment en prenant en compte la pr?sence des termes dans le r?sum?
ou les diff?rentes sec-tions du document (le titre des documents n?
?tait malheureusement pas disponible lors du d?fi,mais il nous semble qu?il pourrait ?tre important de le prendre en compte).
Enfin, l?identificationautomatique des mots cl?s pourrait ?tre con?ue comme une t?che d?assistance aux r?dacteurs desdocuments.
Dans ce cas de figure, il serait int?ressant de pouvoir ?valuer l?apport des diff?rentesapproches en calculant une pr?cision sur les n premiers termes ou un pourcentage de la liste.R?f?rencesAUBIN, S. et HAMON, T. (2006).
Improving term extraction with terminological resources.
InSALAKOSKI, T., GINTER, F., PYYSALO, S. et PAHIKKALA, T., ?diteurs : Advances in Natural LanguageProcessing (5th International Conference on NLP, FinTAL 2006), num?ro 4139 de LNAI, pages380?387.
Springer.HAMON, T. et NAZARENKO, A.
(2008).
Le d?veloppement d?une plate-forme pour l?annotationsp?cialis?e de documents web : retour d?exp?rience.
Traitement Automatique des Langues,49(2):127?154.JACQUEMIN, C. (1997).
Variation terminologique : Reconnaissance et acquisition automatiquesde termes et de leurs variantes en corpus.
M?moire d?habilitation ?
diriger des recherches eninformatique fondamentale, Universit?
de Nantes.MAYNARD, D. et ANANIADOU, S. (2000).
Identifying terms by their family and friends.
InProceedings of COLING 2000, pages 530?536, Saarbrucken, Germany.PAGE, L., BRIN, S., MOTWANI, R. et WINOGRAD, T. (1998).
The pagerank citation ranking : Bringingorder to the web.
Rapport technique, Stanford Digital Library Technologies Project.SALTON, G. et MCGILL, M. J.
(1986).
Introduction to Modern Information Retrieval.
McGraw-Hill,Inc., New York, NY, USA.SCHMID, H. (1997).
Probabilistic part-of-speech tagging using decision trees.
In JONES, D. etSOMERS, H., ?diteurs : New Methods in Language Processing Studies in Computational Linguistics.31
