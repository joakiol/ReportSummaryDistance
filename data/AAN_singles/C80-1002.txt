AUTOMATIC PROCESSING OF WRITTEN FRENCH LANGUAGEJ.L.Binot, M.Graitson, Ph.
Lemaire, D.RibbensComputer Sciences DepartmentUniversity of LiegeBelgiumAbstractAn automatic processor of written Frenchlanguage is described.
This processoruses syntactic and semantic informationsabout words in order to construct a se-mantic net representing the meaning ofthe sentences.
The structure of the net-work and the principles of the parserare explained.
An application to the pro-cessing of the medical records is thendiscussed.I.
IntroductionSABA ("Semantic Analyser , Backward Ap-proach") is an automatic parser of Frenchlanguage currently developped at LiegeUniversity, Belgium I.
It is now aimed atthe processing of medical records 2.
Howe-ver, the principles of this system wereconceived independently of any specificapplication.
SABA has been fundamentallyconceived as a general, flexible Frenchlanguage parser, which could be used asa component of a natural language inter-face between a human user and a givencomputer process 8.
This parser is not li-mited to the processing of correct, aca-demic French.
It is aimed also at pro-cessing the casual language of an ave-rage user.Though our system is uniquely concernedwith French, we have translated ourexamples in English everytime that itwas possible.
In this way, we hope thatthe non French-speaking reader might beable to get the flavour of our work.2.
General description of the s~stemSABA, as a parsing system, is essentiallysemantically oriented, Its goal is notto identify the complete syntactic struc-ture of the input sentences, but ratherto determine the possible semantic re-lationships between the terms of thesesentences.
More specifically, the systemtries to characterize the semantic depen-dencies that appear in a sentence bet-ween the complements and the terms whichare completed by them (from now on, aterm of this last kind will be called a"completee").
We will insist immediatelyupon the fact that both concepts of"com-plement" and of "completee" are to betaken in a general way.
The syntacticsubject of a verb is thus treated as acomplement of this verb.To characterize these semantic dependen-cies, the system uses a small set of re-lationships like AGENT, OBJECT, INSTRU-MENT, LOCUS, and so on.
In this way, oursystem is related to the family of "casesystems", using the now well known prin-ciples of case grammars 3 14 However, incontrast to some authors 3 15 17 18 , wedon~t try to find a complete and minimalset of universal relationships.
The onlycriterion for the choice of our relation-ships is their practical usefulness.
Forthe time being, about twenty differentrelationships are used by the system.All the relationships which are identifiedin an input sentence are summarized ina semantic network, which represents thesemantic structure of this sentence.
The(simplified) representation of a completesentence may be il lustrated by the figu-re I.
The fundamental principles of thenetwork will be described in the nextsection.The grammar used by the system has twocomponents, syntactic and semantic, whichare used interactively.
The syntacticcomponent has two main tasks.
First, itsegments the sentence into syntacticunits.
Second, it defines an order ofprocessing for all these units.
This syn-tactic component, which is implementedin a procedural way, will be describedin section 5.The semantic component defines which se-mantic relationships are acceptable bet-ween terms.
As we shall see later, itsscope is not only the relationships bet-ween verbs and nominal groups, but alsothe dependencies between nouns, betweennouns and adjectives, and, in fact, allpossible dependencies expressible inthe French language.
The semantic compo-nent will be described in section 4.3.
A semantic netSince a few years, semantic nets are wellknown as tools for expressing knowledgeand meaning 13 16 17.
Let us recall brief-ly the principle of such networks:a semantic net is a set of nodes, whichmay represent the different significantterms of a text or of a domain of know-ledge.
These nodes are interconnected bylabelled arcs, which represent the se-mantic relationships established betweenthem.A complete semantic network, which mustbe able to express a great variety of--9--semantic informations, is generally avery complex structure 7 9 17  The struc-ture that we use may be somewhat simpler,because it is aimed only at the repre-sentation of sentences, and not of gene-ral knowledge (at least at this state ofour work).
However it is still fairlycomplex, as it can be seen in figure I.
( today)(John).<MOMENT?N>OBJECTfindingAGENTN=N>I ?~ 2- (book)OBJECTDURATION N =2llearching I ~GENTN = \] (month)Figure I.
Representation of : "John hasfound today the books that he was sear-ching for since two months.We will not try here to discuss all thesubtleties of our net structure.
Rather,we will restrict ourselves to the state-ment of a few basic principles.
All theseprinciples can be explained with thehelp of the very simple example of thefigure 2.AGENT?
.
.
.
.
.
.
.
.
.
>0Peter eatingFigure 2.
Representation of : "Pete 7eats".First of all, in our terminology, verbsare not treated as predicates, (the ar-guments of which being the differentnouns of the sentence), but rather asarguments themselves.
We have abandonedthe dominant point of view that theverbs express mainly relationships, whi-le the others terms express objects orproperties.
Instead, we admit that asentence is composed of content words,which we call "semantic entities", rela-ted by semantic relationships.
The se-mantic entities include not only thenouns, but also the verbs, adjectives,adverbs, and some prepositions.Secondly, the semantic relationshipsare oriented (the positive orientationbeing denoted in the network by an ar-row).
By definition, the positive orien-tation is such that :- the origin of the arc is the node cor-responding to the term which appearsin the sentence as the complement, and- the extremity of the arc is the nodecorresponding to the term which appearsin the sentence as the completee.Third, a logical interpretation corres-ponds to the semantic net.
We will admitthat to the graphic configurationR 0< .
.
.
.
.
.
.
.
.
?x ycorresponds the logical proposit ion :R(x,y) = TrueWe will remark that the relation R isnot symmetrical with respect to its ar-guments : the first argument correspondsto the destination node of the networkrepresentation.4.
A_semantic grammarThe task of the semantic component ofthe grammar is to define which semanticrelationships are acceptable between thesemantic entities.
In order to do that,we shall use semantic knowledge aboutwords.
To each content word are assignedtwo different "property l i s t s " :  an"E-list" and a "T-list"E-lists.The E-list which is associated with oneterm lists all the relationships wherethis term may appear as a "completee".As an alternate definition, we may saythat an E-list lists all possible kindsof complements for the associated term.For example, the E-list of the verb "toeat"would be something like that :(eat(E-list(AGENT OBJECT INSTRUMENT LOCUSTIME) ) )E-lists appear to be very similar to thetraditional case frames used by thecase grammar theory.
There exists howe-ver a distinction : case frames weremeaned to indicate possible ARGUMENTSfor verbs, considered as predicates.E-lists are used to indicate possibleRELATIONSHIPS for the associated terms,which are considered as arguments.The  E-list associated to a term is a cha-racteristic of this term itself, andcannot be deduced from the context.
Itmust be given by a dictionary.T-lists.The T-list which is associated to a terml is~ the possible relationships wherethis term may appear as a complement.
Wemay also understand a T-list as the listof the possible kinds of "completee" ofa term.
In contrast to the E-list, theT-list of a term is, at least partially,bound by the context of this term in asentence.
The T-list of a noun, forexample, is provided by the prepositionwhich begins the nominal group.
Eachpreposition introduces thus a given,--10--fixed T-list.
And, to preserve the gene-rality of this rule, the lack of prepo-sition is assimilated to the presence ofan "empty" preposition, called PHI.For example, the T-list introduced by theFrench preposit ion "par" is somethinglike this :(par(T-i ist(AGENT,PATH,ORIGIN,DESTINA-ZION,QUANTITY)))Of course, we do not consider that thelists given as examples are complete.They are only an i l lustration of thereal configuration of the system.Some properties of T-lists and E-lists.a) From a logical point of view, the oc-currence of a relationship, say AGENT,in the E-list associated with a giventerm X is equivalent to the followingproposit ion :(~y)  AGENT (X ,y)The  occur rence  o f  the  same re la t ionsh ipin  the  T - l i s t  assoc ia ted  to  X is equ iva -lent  to  :(~y) AGENT (y ,X)Consequently, the only difference bet-ween T-lists and E-lists lies in theorientation given to the relationshipsdescribed by them.b) For any relationship, such as AGENT,we may define the "inverse relationship"AGENT -I, such that :AGENT(x,y) ~ AGENT-i(y,x)Given these inverse relationships, wehave the following property of E-listsand T-lists :"The occurrence of a given relationshipin the E-list associated with a term Xis equivalent to the occurrence of theinverse relationship in the T-list as-sociated to the same term, and recipro-cally"This property is used in some complexsituations where a term which appearsin the input sentence as a complementmust be represented in the network as acompletee.
This is the case, for exam-ple, of past and present participlesused as adjectives.c) The same relationship may not occurtwice in a given list of properties(E-list or T-list).
Concerning E-lists,this restriction may be translated as :"two different terms cannot play in thesame sentence the same role with respectto a given term",which is a typical restriction in somecase systems 3 is.d) Only one of the relationships listedin the T-list of a term may be used ina given sentence.
This means that eachterm in a sentence has a single role toplay.
This condition is not true for E-lists : all the relationships given bythe E-list of a term may be used in asentence where this term occurs.The properties c) and d) are called thetwo "exclusivity principles" of the sys-tem.Compatibi l i ty condition and selectionalrestrictionsWe will now show how we will use theseproperty lists in our system.
First wewill state a compatibi l i ty condition :"given two terms, one of which is a pos-sible complement of the second, a neces-sary condition to establish a given re-lationship between them is that this re-lationship be present both in the E-listof the possible completee and in the T-list of the possible complement".This condition is a necessary but nota sufficient one.
The reason of thiscan be shown in the following exampleLet us admit that we want to establishthe AGENT relationship between "eating"and "Peter" in "Peter eats".
We must ofcourse know that(Ny)AGENT(EATING,y) and(~x)AGENT (x ,PETER),i.e, that the act of eating takes anAGENT, and that Peter may be the AGENTof some activity.
But, in order to beallowed to stateAGENT (EAT ING, PETER),we must also know whether the two assig-nmentsx=EATINGy=PETERare correct.These assignments will be submitted toa set of restrictions.
These restric-tions are associated with the propertylists of the terms.
Restrictions concer-ning the complements of a term are as-sociated with the E-list of this term.Restrictions concerning the completee ofa term are associated with its T-list.The system uses different kinds of res-trictions, in order to solve differentkinds of ambiguities.
The main one ,which concerns nouns (and adjectives),uses a classif ication of these termsinto a hierarchized set of semantic clas-ses.
With the help of this classif ica-tion, we can for example express that"the AGENT of the action of eating mustbe an Animate being", which is denotedIIin the E-list of "eating" as :(eating(E-l ist(AGENT(Animate),.
.
.
)))Here is a more complete example.
Giventhe classif icationPeter ~ Human beingHaman being c Animate beingApple ~ FruitFruit c Comestible objectKnife ~ Instrumentand the property lists(PHI(T-i ist(AGENT,OBJECT,INSTRUMENT,.
)))(WITH(T-l ist(INSTRUMENT,...)))(EATING(E-i ist(AGENT(Animate),OBJECT(Comestible), INSrRUMENT(Instrument))))the system can easily parse the sentence"Peter eats an apple with a knife"and produce the three relationshipsAGENT(eating,Peter)OBJECT(eating,apple)INSTRUMENT(eating,knive)Other kinds of restrictions are based onsyntactic classes or on modal properties(of verbs).
We shall not discuss themfurther here.5.
The parserThe grammar, and thus the parser, arenot completely free of syntactic consi-derations.
The syntactic part of theparser has two main tasks :- the segmentation of the input textinto "syntactic units"- the determination of a parsing strate-gy.Syntactic units.Four kinds of syntactic units are defi-ned : words, groups, clauses and senten-ces.- Words, or atomic symbols are stringsof characters which match dictionaryentries (this definit ion takes into ac-count not only single words, but alsolocutions, as "at least", that will betreated by the system as atomic sym-bols).
To each Word are associated syn-tactic and semantic properties.
Wordsare divided into two main classes :?
the semantic entities, or contentwords, which can be arguments of se-mantic relationships : nouns, pro-nouns, verbs, adverbs, adjectives,and some prepositions.?
the function words, which cannot bearguments of semantic relationships :coordinate and subordinate conjunc-tions, articles, some prepositions,negation words, and so on.- Groups are sequences of Words.
EachGroup has a central term, which may bea noun (nominal Groups), a pronoun, anadjective or an adverb.- A Clause consists of one and only oneverb, and of a set of Groups.
A Clausehas also a central term, which is itsverb.- A Sentence is a sequence of Words de-limited by a "terminator" (punctuationmark like a period, a question-mark,...)A Sentence contains a set of Clauses.The parsing strategy.The parsing strategy is fundamentally abottom-up strategy, which may be definedrecursively as follows :For each syntactic unit (except Words),execute the following steps :- the segmentation of this unit into itsown internal syntactic units,- the parsing of these internal unitsaccording to a definite order,- the determination of the semantic rela-tionships between the internal units,- the substitution of the given unit, atthe next higher level, by a specialsymbol, which represents the analyzedunit.The semantic relationships are determinedaccording to the semantic grammar defi-ned above.
We want now to insist on thetwo other crucial points of this algo-rithm : the segmentation of a given unit,and the order for parsing the internalunits.The segmentation procedures has twotasks : breaking down sentences intoclauses, and clauses into groups.The segmentation of sentences into clau-ses is based on the following technics :starting at a verb, and moving one wordat a time to the left AND to the rightuntil a delimiter is recognized.
Forgroups, the same technics applies, ex-cept that a group is never extended tothe right of its main term.
Lists ofclause-delimiters and of group-delimi-ters are known by the system.
Coordinateconjunctions, which can or cannot be de-limiters depending on the context, doreceive a special treatment.An important point concerning the seg-mentation of the sentence into clausesmust be stressed.
It is performed eachtime that a clause must be selected tobe analyzed by the system.
This strategygives to the system the possibi l i ty touse informations collected in a priorstate of the analysis.
In this way, thestructure of very complex sentences canbe successfully analyzed.All segmentation procedures are already- 1 2 - -implemented and function satisfyingly.An example of segmentation of a Frenchsentence is shown in the figure 3.
Thesentence appears as a list of words, de-limited on the left and on the right bythe special symbol SB (Sentence Bounda-ry).
A syntactic category is assigned toeach word.
The results shown in the fi-gure are a simplif ication of the outputof the system.a) Les chiens auxquels vous vous atta-chez et qui vous rendent de l 'affectiondeviennent d'inestimables compagnons.b) The dogs that you love and who loveyou in return become precious comradesc) ((SB) (LES ART) (CHIENS NOM) (AUXQUELSPR-REL) (VOUS PR-PERS NIL(OD OI PR S))(VOUS PR-PERS NIL(OD OI S))(ATTACHEZVERBE IND)(ET CC)(QUI PR-REL)(VOUSPR-PERS NIL(OD OI PR S))(RENDENT VERBEIND)(DE PREP)( L ART)(AFFECTION NOM)(DEVIENNENT VERBE IND)(D ART)(INESTI-MABLES ADJ ) (COMPAGNONS NOM)(SB))d) ((SB) (LES ART) (CHIENS NOM) (PR) (ET CC)(QUI PR-REL)(VOUS PR-PERS NIL(OD OI PRS))(RENDENT VERBE IND)(DE PREP)( L ART)(AFFECTION NOM)(DEVIENNENT VERBE IN)(D ART) (INESTIMABLES ADJ) (COMPAGNONSNOM)(SB))e) ((SB) (LES ART) (CHIENS NOM) (PR) (ET CC)(P.R)(DEVIENNENT VERBE IND)(D PREP)(INESTIMABLES ADJ) (COMPAGNONS NOM) (SB))f) ((SB) (PP) (SB))Figure 3 : segmentat ion of a sentencea) the or ig ina l  French sentenceb) the English translationc) the input of the segmentation proce-dured) the state of the sentence after theanalysis of the relative clause "aux-quels vous vous attachez", which isreplaced by the special symbol PRe) the state of the sentence after theanalysis of the relative clause "quivous rendent de l 'affection", whichis replaced by PRf) final state of the sentence : themain clause was found and replaced byPPconcerning the order for parsing theinternal units at a given level, twostrategies are applied, one for clauses,and one for groups.For clauses, we simply follow the bot-tom-up strategy, with the followingrule : all subordinate clauses (relati-ve, conjunctive, infinitive,...) areprocessed before the clauses on whichthey depend.
If two clauses are on thesame level, a left to right priority isapplied.For groups, a backward strategy is ap-plied : the system always starts fromthe end of the clause, and moves to-wards the beginning.
At each step, theinternal structure of a group is parsed,AND THEN THE POSSIBLE RELATIONSHIPS BET-WEEN THIS GROUP AND THE FOLLOWING GROUPS(ALREADY PARSED) ARE INVESTIGATED.
Thisparticular order (after which the sys-tem is named) has a crucial importance.It is based on two facts :the first is related to the structureof the language.
In French, complementsare nearly always at the right of theterms on which they depend;the second is related to the system :we know that the T-lists of the seman-tic entities are, at least partially,deduced from the context.
Consequently,at the moment when the system investi-gates the potential relationships bet-ween a term and some possible comple-ment, the group in which this comple-ment appears must have already beenparsed !6.
ConclusionsWe have presented a parsing system forFrench language sentences.
This systemis characterized by- its generality,- a good amount of flexibil ity, due tothe fact that the system is semantical-ly oriented,- its capabil ity to cope with complexstructures, including subordinate clau-ses, conjunctions and references (theselast two features were not discussed inthe paper).The system was designed independently ofany specific application and was testedon a limited corpus (approximativelyone hundred) of common french sentences.We believe that this system is applica-ble in all domains, provided a structu-red semantic dictionary.
An applicationof our system to the medical domain iscurrently under development 2 6.
In thisdomain, existing automatic processingsystems do function successfully forE~glish and French pathology data 4 5 I012.
We took up the challenge to de-sign a system for processing patientdischarge summaries in internal medicine.It is quite true that the natural lan-guage of internal medicine data does notalways contain well formed sentences.This is not however a real problem.
Oneof the main advantages of the systemstems from the fact that it was designedto handle French free text, no matterhow academically correct or incorrect itmight be.
Consequently, we expect that thesystem can handle all kinds of medical13diagnoses.
Moreover, since it has beenconceived to process questions as wellas complete sentences, the system is notlimited to the processing of medicaldata.
Ultimately, it will be used toimplement a complete natural languageinterface for a data base management sys-tem.ReferencesI.
Binot,J.L.,Lemaire,Ph., & Ribbens,D.,Description d'un syst~me automatiqued'analyse du frangais.
Rapport interne,Universit@ de Liege, 1979.2.
Binot,J.L., Lemaire,Ph., & Ribbens,D.Analyse automatique de textes m~dicauxet codification des diagnostics.
Rap-port interne, Universit6 de Liege,1980.3.
Fillmore,C.J., The case for case,in Bach,E.
& Harms,R.
(Eds.
), Univer-sals in Linguistic Theory, Holt,Rinehart & Winston,lnc., N.Y., 1968.4.
Graitson,M., Identification et trans-formation automatique des morphemesterminaux dans le lexique m&dicalfrangais, Cahiers de Lexicologie,XXVI, 1975.5.
Graitson,M., Traitement automatiquedu frangais m~dical, Cahiers de Lexi-cologie, XXX, 1977.6.
Graitson,M., Syst~me d'indexationautomatique des dossiers m~dicauxde l'Universit~ de Liege, Rapportinterne, Universit~ de Liege, 1980.7.
Hendrix,G., Encoding knowledge inpartitioned networks, in N.V.Findler(Ed.
),Associative Networks - The re-presentation and use of knowledge incomputers, Academic Press, New-York.8.
Laubsch,J.H., Natural language inter-face engineering, S~minaire interna-tional sur les syst~mes intelligentsde questions-r~ponses et de grandesbanques de donn6es, Rapport de I'IRIA.9.
Martin,W.A., Roles, co-descriptors,and the representation of quantifiedEnglish expressions, Laboratory forComputer Sciences, M.I.T.
Press,1979.10.
Pratt,A.W., Automatic processing ofpathologic data, International Confe-rence on Computational Linguistics,Stockholm, 1969.11.
Pratt,A.W., Progress towards a medi-cal information system for the re-search environment, in Fuchs,G.
&Wagner,G.
(Eds), Krankenhaus-Infor-mationssysteme : Erstrebtes und er-reichtes, F.K.Schattauer Verlag,Stuttgart, 1972.12.
Dunham,G.S.,Pacak,H.G.,& Pratt,A.W.,Automatic indexing of pathologydata, Journal of the American Societyfor Information Sciences, March 1978.13.
Quillian,M.R., Semantic memory, inMinsky (Ed.
), Semantic InformationProcessing, M.I.T.
Press,Cambridge,Mass., 1968.14.
Samlowsky,W., Case grammar, inCharniak,E., & Wilks,Y.
(Eds), Compu-tational Semantics, North-Holland,1976.15.
Schank,R., Identification of concep-tualizations underlying natural lan-guage, in Schank & Colby (Eds), Com-puterModels of Thought and Language,Freeman, San-Francisco, 1973.16.
Scragg,G., Semantic nets as memorymodels, in Charniak,E., & Wilks,Y.
(Eds}, Computational Semantics, North-Holland, 1976.17.
Simmons,R.F., Semantic networks :computation and use for understandingEnglish sentences, in Schank,R.C.
&Colby,K.M., Computer Models of Thoughtand Language, Freeman and Company,1973.18.
Wilks,Y., Preference semantics, inKeenan,E.
(Ed.
), Formal Semantics ofNatural Language, Cambridge U.P.,1975.14
