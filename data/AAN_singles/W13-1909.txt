Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 72?79,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsRecognizing sublanguages in scientific journal articlesthrough closure propertiesIrina P. TemnikovaLinguistic Modelling LaboratoryBulgarian Academy of Sciencesirina.temnikova@gmail.comK.
Bretonnel CohenComputational Bioscience ProgramUniversity of Colorado School of MedicineDepartment of LinguisticsUniversity of Colorado at Boulderkevin.cohen@gmail.comAbstractIt has long been realized that sublanguagesare relevant to natural language process-ing and text mining.
However, practicalmethods for recognizing or characterizingthem have been lacking.
This paper de-scribes a publicly available set of tools forsublanguage recognition.
Closure proper-ties are used to assess the goodness of fitof two biomedical corpora to the sublan-guage model.
Scientific journal articlesare compared to general English text, andit is shown that the journal articles fit thesublanguage model, while the general En-glish text does not.
A number of examplesof implications of the sublanguage char-acteristics for natural language processingare pointed out.
The software is made pub-licly available at [edited for anonymiza-tion].1 Introduction1.1 Definitions of ?sublanguage?The notion of sublanguage has had varied defini-tions, depending on the aspects of sublanguageson which the authors focused.
(Grishman and Kit-tredge, 1986) focus on syntactic aspects of sub-languages: ?.
.
.
the term suggests a subsystem oflanguage.
.
.
limited in reference to a specific sub-ject domain.
In particular, each sublanguage hasa distinctive grammar, which can profitably bedescribed and used to solve specific language-processing problems?
(Grishman and Kittredge,1986).
(Kittredge, 2003) focuses on the spontaneousappearance of sublanguages in restricted domains,where the preconditions for a sublanguage to ap-pear are the sharing of specialized knowledgeabout a restricted semantic domain and recurrent?situations?
(e.g.
scientific journal articles, or dis-charge summaries) in which domain experts com-municate.
According to (Kittredge, 2003), charac-teristics of a sublanguage include a restricted lexi-con, relatively small number of lexical classes, re-stricted sentence syntax, deviant sentence syntax,restricted word co-occurrence patterns, and differ-ent frequencies of occurrence of words and syn-tactic patterns from the normal language.
(McDonald, 2000) focuses on the element of re-striction in sublanguages?the notion that they arerestricted to a specialized semantic domain, a very?focused?
audience, and ?stipulated content,?
withthe effect that both word choice and syntactic stylehave reduced options as compared to the normallanguage.The notions of restriction that recur in thesedefinitions of ?sublanguage?
lead directly to(McEnery and Wilson, 2001)?s notion of usingthe quantification of closure properties to assesswhether or not a given sample of a genre of lan-guage use fits the sublanguage model.
Closurerefers to the tendency of a genre of language to-wards finiteness at one or more linguistic levels.For example, a genre of language might or mightnot use a finite set of lexical items, or have a fi-nite set of sentence structures.
Notions of restric-tion suggest that a sublanguage should tend to-wards closure on at least some linguistic levels.To quantify closure, we can examine relationshipsbetween types and tokens in a corpus of the genre.In particular, we count the number of types thatare observed as an increasing number of tokensis examined.
If a genre does not exhibit closure,then the number of types will continue to rise con-tinually as the number of tokens increases.
Onthe other hand, closure is demonstrated when thenumber of types stops growing after some numberof tokens has been examined.721.2 Relevance of sublanguages to naturallanguage processingThe relevance of sublanguages to natural languageprocessing has long been recognized in a vari-ety of fields.
(Hirschman and Sager, 1982) and(Friedman, 1986) show how a sublanguage?basedapproach can be used for information extractionfrom clinical documents.
(Finin, 1986) shows thatsublanguage characterization can be used for thenotoriously difficult problem of interpretation ofnominal compounds.
(Sager, 1986) asserts a num-ber of uses for sublanguage?oriented natural lan-guage processing, including resolution of syntac-tic ambiguity, definition of frames for informa-tion extraction, and discourse analysis.
(Sekine,1994) describes a prototype application of sublan-guages to speech recognition.
(Friedman et al1994) uses a sublanguage grammar to extract a va-riety of types of structured data from clinical re-ports.
(McDonald, 2000) points out that modernlanguage generation systems are made effective inlarge part due to the fact that they are applied tospecific sublanguages.
(Somers, 2000) discussesthe relevance of sublanguages to machine trans-lation, pointing out that many sublanguages canmake machine translation easier and some of themcan make machine translation harder.
(Friedmanet al 2001) uses a sublanguage grammar to ex-tract structured data from scientific journal arti-cles.1.3 Previous work on sublanguagerecognitionVarious approaches have been taken to recog-nizing sublanguages.
We posit here two sepa-rate tasks?recognizing a sublanguage when oneis present, and determining the characteristics ofa sublanguage.
Information-theoretic approacheshave a long history.
(Sekine, 1994) clustered docu-ments and then calculated the ratio of the perplex-ity of the clustered documents to the perplexityof a random collection of words.
(Somers, 1998)showed that texts drawn from a sublanguage cor-pus have low weighted cumulative sums.
(Stetsonet al 2002) used relative entropy and squared chi-square distance to identify a sublanguage of cross-coverage notes.
(Mihaila et al 2012) looked atdistributions of named entities to identify and dif-ferentiate between a wide variety of scientific sub-languages.Non-information-theoretic, more heuristicmethods have been used to identify sublanguages,as well.
In addition to the information-theoreticmeasures described above, (Stetson et al 2002)also looked at such measures as length, incidenceof abbreviations, and ambiguity of abbreviations.
(Friedman et al 2002) use manual analysis todetect and characterize two biomedical sublan-guages.
(McEnery and Wilson, 2001) examineclosure properties; their approach is so central tothe topic of this paper that we will describe it insome length separately.
(McEnery and Wilson, 2001) examined the clo-sure properties of three linguistic aspects of theirmaterial under study.
As materials they used twocorpora that were assumed not to meet the sub-language model?the Canadian Hansard corpus,containing proceedings from the Canadian Parlia-ment, and the American Printing House for theBlind corpus, made up of works of fiction.
Asa corpus that was suspected to meet the sublan-guage model, they used a set of manuals fromIBM.
All three corpora differed in size, so theywere sampled to match the size of the smallestcorpus, meaning that all experiments were doneon collections 200,000 words in size.
The mate-rials under study were evaluated for their closureproperties at three linguistic levels.
At the mostbasic level, they looked at lexical items?simpleword forms.
The hypothesis here was that the non-sublanguage corpora would not tend toward finite-ness, i.e.
would not reach closure.
That is, if thenumber of word types found was graphed as anincreasing number of tokens was examined, theresulting line would grow continually and wouldshow no signs of asymptoting.
In contrast, thesublanguage corpus would eventually reach clo-sure, i.e.
would stop growing appreciably in sizeas more tokens were examined.The next level that they examined was the mor-phosyntactic level.
In particular, they looked atthe number of part-of-speech tags per lexical type.Here the intuition was that if the lexicon of thesublanguage is limited, then words might be co-erced into a greater number of parts of speech.This would be manifested by a smaller overallnumber of unique word/part-of-speech tag combi-nations.
Again, we would expect to see that thesublanguage corpus would have a smaller numberof word/part-of-speech tag combinations, as com-pared to the non-sublanguage corpus.
Graphingthe count of word type/POS tag sets on the y axis73and the cumulative number of tokens examined onthe x axis, we would see slower growth and lowernumbers overall.The final level that they examined was the syn-tactic level.
In this case, parse tree types weregraphed against the number of sentences exam-ined.
The intuition here is that if the sublanguageexhibits closure properties on the syntactic level,then the growth of the line will slow and we willsee lower numbers overall.
(McEnery and Wilson, 2001) found the hy-potheses regarding closure to be substantiated atall levels.
We will not reproduce their graphs,but will summarize their findings in terms of ra-tios.
On the lexical level, they found type/tokenratios of 1:140 for the IBM manuals (the assumedsublanguage), 1:53 for the Hansard corpus (as-sumed not to represent a sublanguage), and 1:17for the American Printing House for the Blind cor-pus (also assumed not to represent a sublanguage).The IBM manuals consist of a much smaller num-ber of words which are frequently repeated.At the morphosyntactic level, they found 7,594type/POS sets in the IBM manuals, 18,817 inthe Hansard corpus, and 11,638 in the Ameri-can Printing House for the Blind corpus?a muchsmaller number in the apparent sublanguage thanin the non-sublanguage corpora.
The word/part-of-speech tag averages coincided with the ex-pected findings given these number of types.
Theaverages were 3.19 for the IBM manuals, 2.45 forthe Hansard corpus, and 2.34 for the AmericanPrinting House for the Blind corpus.At the syntactic level, they found essentially lin-ear growth in the number of sentence types as thenumber of sentence tokens increased in the twonon-sublanguage corpora?the ratio of sentencetypes to sentences in these corpora were 1:1.07 forthe Hansard corpus and 1:1.02 for the AmericanPrinting House for the Blind corpus.
In contrast,the growth of sentence types in the IBM manu-als was not quite linear.
It grew linearly to about12,000 sentences, asymptoted between 12,000 and16,000, and then grew essentially linearly but at asomewhat slower rate from 16,000 to 30,000 sen-tences.
The ratio of sentence types to sentence to-kens in the IBM manuals was 1:1.66?markedlyhigher than in the other two corpora.1.4 Hypotheses tested in the paperThe null hypothesis is that there will be no differ-ence in closure properties between the general En-glish corpus and the two corpora of scientific jour-nal articles that we examine.
If the null hypothesisis not supported, then it might be deviated from inthree ways.
One is that the scientific corpora mightshow a greater tendency towards closure than thegeneral English corpus.
A second is that the gen-eral English corpus might show a greater tendencytowards closure than the scientific corpora.
A thirdis that there may be no relationship between theclosure properties of the two scientific corpora, re-gardless of the closure properties of the generalEnglish corpus?one might show a tendency to-wards closure, and the other not.2 Materials and Methods2.1 MaterialsThe data under examination was drawn from threesources: the CRAFT corpus (Bada et al 2012;Verspoor et al 2012), the GENIA corpus (Kimet al 2003), and a version of the British NationalCorpus (Leech et al 1994) re-tagged with Con-nexor?s Machinese parser (Ja?rvinen et al 2004).The CRAFT and GENIA corpora are composedof scientific journal articles, while the British Na-tional Corpus is a representative corpus compris-ing many different varieties of spoken and writtenEnglish.The CRAFT corpus is a collection of 97 full-text journal articles from the mouse genomics do-main.
It has been annotated for a variety of lin-guistic and semantic features; for the purposes ofthis study, the relevant ones were sentence bound-aries, tokenization, and part of speech.
We usedthe 70-document public release subset of the cor-pus, which comprises about 453,377 words.The GENIA corpus is a collection of 1,999 ab-stracts of journal articles about human blood celltranscription factors.
Like the CRAFT corpus,it has been annotated for a variety of linguisticand semantic features, again including sentenceboundaries, tokenization, and part of speech.
Inthe mid-2000?s, the GENIA corpus was shown tobe the most popular corpus for research in biomed-ical natural language processing (Cohen et al2005).
We used version 3.02 of the corpus, con-taining about 448,843 words.The experiment requires a corpus of generalEnglish for comparison.
For this purpose, we74used a subset of the British National Corpus.
Forpurposes of representativeness, we followed theBrown corpus strategy of extracting the first 2,000words from each article until a total of 453,377words were reached (to match the size of theCRAFT corpus).The size of the two data sets is far more than ad-equate for an experiment of this type?McEneryand Wilson were able to detect closure propertiesusing corpora of only 200,000 words in their ex-periments.2.2 Methods2.2.1 Implementation detailsTo determine the closure properties of arbitrarycorpora, we developed scripts that take a simpleinput format into which it should be possible toconvert any annotated corpus.
There are two inputfile types:?
A file containing one word and its corre-sponding part-of-speech tag per line.
Part ofspeech tags can consist of multiple tokens, asthey do in the BNC tag set, or of single to-kens, as they do in most corpora.
This fileformat is used as the input for the lexical clo-sure script and the word type/POS tag script.?
A file containing a sequence of part of speechtags per line, one line per sentence.
Thisfile format is used as input for the sentencetype closure script.
We note that this is anextremely rough representation of ?syntax,?and arguably is actually asyntactic in that itdoes not represent constituent or dependencystructure at all, but also point out that it hasthe advantage of being widely applicable andagnostic as to any particular theory of syntac-tic structure.
It also increases the sensitivityof the method to sentence type differences,providing a stronger test of fit to the sublan-guage model.Two separate scripts then process one of theseinput files to determine lexical, type/POS, and sen-tence type closure properties.
The output of ev-ery script is a comma-separated-value file suitablefor importing into Excel or other applications forproducing plots.
The two scripts and our scriptsfor converting the BNC, CRAFT, and GENIA cor-pora into the input file formats will be made pub-licly available at [redacted for anonymization pur-poses].
To apply the scripts to a new corpus, theFigure 1: Lexical closure properties.
Tick-markson x axis indicate increments of 50,000 tokens.only necessary step is to write a script to convertfrom the corpus?s original format to the simple for-mat of the two input file types described above.2.2.2 Investigating closure propertiesIn all three cases, the number of types, whether oflexical items, lexical type/part-of-speech pair, orsentence type was counted and graphed on the yaxis, versus the number of tokens that had beenobserved up to that point, which was graphed onthe x axis.
In the case of the lexical and type/POSgraphs, tokens were words, and in the case of thesentence graph, ?tokens?
were sentences.We then combined the lines for all three cor-pora and observed the total size of types, the rateof growth of the line, and whether or not there wasa tendency towards asymptoting of the growth ofthe line, i.e.
closure.Our major deviation from the approach of(McEnery and Wilson, 2001) was that rather thanparse trees, we used part-of-speech tag sequencesto represent sentence types.
This is suboptimal inthat it is essentially asyntactic, and in that it ob-scures the smoothing factor of abstracting awayfrom per-token parts of speech to larger syntacticunits.
However, as we point out above, it has theadvantages of being widely applicable and agnos-tic as to any particular theory of syntactic struc-ture, as well as more sensitive to sentence type dif-ferences.3 Results3.1 Lexical closure propertiesFigure 1 shows the growth in number of types oflexical items as the number of tokens of lexicalitems increases.
The British National Corpus datais in blue, the CRAFT data is in red, and the GE-NIA data is in green.75Figure 2: Type-part-of-speech tag closure proper-ties.
Tick-marks on x axis indicate increments of50,000 tokens.We note a drastic difference between the curvefor the BNC and the curves for CRAFT and GE-NIA.
The curves for CRAFT and GENIA are quitesimilar to each other.
Overall, the curve for theBNC climbs faster and much farther, and is stillclimbing at a fast rate after 453,377 tokens havebeen examined.
In contrast, the curves for CRAFTand GENIA climb more slowly, climb much less,and by the time about 50,000 tokens have been ex-amined the rate of increase is much smaller.
Theincrease in CRAFT and GENIA does not asymp-tote, as McEnery and Wilson observed for the IBMcorpus.
However, contrasted with the results forthe BNC, there is a clear difference.The type to token ratios for lexical items for thecorpora as a whole are shown in Table 1.
As thesublanguage model would predict, CRAFT andGENIA have much higher ratios than BNC.Corpus name RatioBNC 1: 12.650CRAFT 1: 23.080GENIA 1: 19.027Table 1: Lexical type-to-token ratios.3.2 Type/POS tag closure propertiesFigure 2 shows the growth in number of type-POS tag pairs as the number of tokens of lexicalitem/POS tag pairs increases.
The data from thedifferent corpora corresponds to the same colorsas in Figure 1.Once again, we note a drastic difference be-tween the curve for the BNC and the curves forCRAFT and GENIA.
If anything, the differencesare more pronounced here than in the case of thelexical closure graph.
Again, we do not see anasymptote in the increase of the curves for CRAFTand GENIA, but there is a clear difference whencontrasted with the results for the BNC.The type-to-token sets ratios for the corpora as awhole are shown in Table 2.
Again, as the sublan-guage model would predict, we see much higherratios in CRAFT and GENIA than in BNC.Corpus name RatioBNC 1: 10.80CRAFT 1: 19.96GENIA 1: 18.18Table 2: Type-to-token ratios for type/POS tags.Because the Machinese Syntax parser wasused to obtain the part-of-speech tagging forBNC and the Machinese Syntax parser?s tagset ismuch more granular and therefore larger than theCRAFT and GENIA tag sets, both of which areadaptations of the Penn treebank tag set, we con-sidered the hypothesis that the large size differ-ences of the tag sets were the cause of the differ-ences observed between BNC and the two corporaof scientific journal articles.
To test this hypothe-sis, we manually mapped the BNC tag set to thePenn treebank tag set.
The result was a new BNClist of tags, of the same number and granularityas the CRAFT/GENIA ones (35-36 tags).
Usingthis mapping, the BNC part-of-speech tags wereconverted to the Penn treebank tag set and the ex-periment was re-run.
The results show that thereis almost no difference between the results fromthe first and the second experiments.
The resultinggraph is omitted for space, but examining it onecan observe that the differences between the threecorpora in the graph are almost the same in bothgraphs.
The newly calculated type:tokens ratio forBNC are also illustrative.
They are highly similarto the type-token ratio for the original tag set?1:10.82 with the mapped data set vs. 1:10.80 withthe original, much larger tag set.
This supports theoriginal results and demonstrates that differencesin tag set sizes do not interfere with the identifica-tion of sublanguages.3.3 Sentence type closure propertiesFigure 3 shows the growth in number of sentencetypes as the number of sentences increases.
Thedata from the different corpora corresponds to thesame colors as in Figure 1.Here we see that all three corpora exhibit sim-76Figure 3: Sentence type closure properties.
Tick-marks on x axis indicate increments of 5,000 sen-tences.ilar curves?essentially linear, with nearly identi-cal growth rates.
This is a strong contrast with theresults seen in Figures 1 and 2.
We suggest somereasons for this in the Discussion section.The ratio of sentence types to sentence tokensfor the corpora as a whole are given in Table 3.As would be expected from the essentially lineargrowth observed with token growth for all threecorpora, all three ratios are nearly 1:1.Corpus name RatioBNC 1: 1.03CRAFT 1: 1.14GENIA 1: 1.11Table 3: Sentence type-to-token ratios.4 Discussion and ConclusionsThe most obvious conclusion of this study is thatthe null hypothesis can be rejected?the scien-tific corpora show a greater tendency towards clo-sure than the general English corpus.
Further-more, we observe that the two scientific corporabehave quite similarly to each other at all threelevels.
This second observation is not necessar-ily a given.
If we can consider for a moment thenotion that there might be degrees of fit to the sub-language model, it is clear that from a content per-spective the BNC is unlimited; the CRAFT cor-pus is limited to mouse genomics, but not to anyparticular area of mouse genomics (indeed, it con-tains articles about development, disease, physiol-ogy, and other topics); and GENIA is more lim-ited than CRAFT, being restricted to the topic ofhuman blood cell transcription factors.
If a tech-nique for sublanguage detection were sufficientlyprecise and granular, it might be possible to show astrict ranking from BNC to CRAFT to GENIA interms of fit to the sublanguage model (i.e., BNCshowing no fit, and GENIA showing a greater fitthan CRAFT since its subject matter is even morerestricted).
However, this does not occur?in ourdata, CRAFT showed a stronger tendency towardsclosure at the lexical level, while GENIA showsa stronger tendency towards closure at the mor-phosyntactic level.
It is possible that the small dif-ferences at those levels are not significant, and thatthe two corpora show the same tendencies towardsclosure overall.One reason that the IBM manuals in the(McEnery and Wilson, 2001) experiments showedsentence type closure but the CRAFT and GE-NIA corpora did not in our experiments is al-most certainly related to sentence length.
Theaverage length of a sentence in the IBM manu-als is 11 words, versus 24 in the Hansard corpusand 21 in the American Printing House for theBlind corpus.
In this respect, the scientific cor-pora are much more like the Hansard and Ameri-can Printing House for the Blind corpora than theyare like the IBM manuals?the average length ofa sentence in GENIA is 21.47 words, similar tothe Hansard and American Printing House for theBlind corpora and about twice the length of sen-tences in the IBM manuals.
Similarly, the aver-age sentence length of the CRAFT corpus is 22.27words (twice the average sentence length of theIBM manuals), and the average sentence length inthe BNC is 20.43 words.
Longer sentences implygreater chances for different sentence types.Another reason for the tendency towards sen-tence type closure in the IBM manuals, which wasnot observed in CRAFT and GENIA, is the strongpossibility that they were written in a controlledlanguage that specifies the types of syntactic con-structions that can be used in writing a manual,e.g.
limiting the use of passives, etc., as well aslexical choices and limits on other options (Kuhn,under review).
There is no such official controlledlanguage for writing journal articles.Finally, one reason that the CRAFT and GENIAcorpora did not show sentence type closure whilethe IBM manuals did is that while McEnery andWilson represented sentence types as parses, werepresented them as sequences of part-of-speechtags.
Representing sentence types as parse treeshas the effect of smoothing out some variabilityat the leaf node level.
For this reason, our repre-77sentation increases the sensitivity of the method tosentence type differences, providing a stronger testof fit to the sublanguage model.It has been suggested since Harris?s classicwork (Harris et al 1989) that scientific writingforms a sublanguage.
However, it is also clearfrom the work of (Stetson et al 2002) and (Mi-haila et al 2012) that some putative sublanguagesare a better fit to the model than others, and to datethere has been no publicly available, repeatablemethod for assessing the fit of a set of documentsto the sublanguage model.
This paper presentsthe first such package of software and uses it toevaluate two corpora of scientific journal articles.Future work will include evaluating the effects ofmapping all numbers to a fixed NUMBER token,which might affect the tendencies towards lexi-cal closure; evaluating the effect of the size oftag sets on type/part-of-speech ratios, which mightaffect tendencies towards type/part-of-speech clo-sure; and seeking a way to introduce more syntac-tic structure into the sentence type analysis with-out losing the generality of the current approach.We will also apply the technique to other biomed-ical genres, such as clinical documents.
Thereis also an important next step to take?this workprovides a means for recognizing sublanguages,but does not tackle the problem of determiningtheir characteristics.
However, despite these limi-tations, this paper presents a large step towards fa-cilitating the study of sublanguages by providinga quantitative means of assessing their presence.In analyzing the results of the study, some im-plications for natural language processing are ap-parent.
Some of these are in accord with the is-sues for sublanguage natural language processingpointed out in the introduction.
Another is that thiswork highlights the importance of both classic andmore recent work on concept recognition for sci-entific journal articles (and other classes of sublan-guages), such as MetaMap (Aronson, 2001; Aron-son and Lang, 2010), ConceptMapper (Tanenblattet al 2010), and the many extant gene mentionsystems.AcknowledgmentsIrina Temnikova?s work on the research re-ported in this paper was supported by the projectAComIn ?Advanced Computing for Innovation?,grant 316087, funded by the FP7 Capacity Pro-gramme (Research Potential of Convergence Re-gions).
Kevin Bretonnel Cohen?s work was sup-ported by grants NIH 5R01 LM009254-07 andNIH 5R01 LM008111-08 to Lawrence E. Hunter,NIH 1R01MH096906-01A1 to Tal Yarkoni, NIHR01 LM011124 to John Pestian, and NSF IIS-1207592 to Lawrence E. Hunter and BarbaraGrimpe.
The authors thank Tony McEnery andAndrew Wilson for advice on dealing with the tagsets.ReferencesAlan R. Aronson and Francois-Michel Lang.
2010.
Anoverview of MetaMap: historical perspective and re-cent advances.
Journal of the American Medical In-formatics Association, 17:229?236.A.
Aronson.
2001.
Effective mapping of biomedi-cal text to the UMLS Metathesaurus: The MetaMapprogram.
In Proc AMIA 2001, pages 17?21.Michael Bada, Miriam Eckert, Donald Evans, KristinGarcia, Krista Shipley, Dmitry Sitnikov, WilliamA.
Baumgartner Jr., Kevin Bretonnel Cohen, KarinVerspoor, Judith A. Blake, and Lawrence E. Hunter.2012.
Concept annotation in the craft corpus.
BMCBioinformatics, 13(161).K.
B. Cohen, Lynne Fox, Philip V. Ogren, andLawrence Hunter.
2005.
Corpus design for biomed-ical natural language processing.
In Proceedings ofthe ACL-ISMB workshop on linking biological liter-ature, ontologies and databases, pages 38?45.
As-sociation for Computational Linguistics.Timothy W. Finin.
1986.
Constraining the interpre-tation of nominal compounds in a limited context.In Ralph Grishman and Richard Kittredge, editors,Analyzing language in restricted domains: sublan-guage description and processing, pages 85?102.Lawrence Erlbaum Associates.Carol Friedman, Philip O. Anderson, John H.M.Austin, James J. Cimino, and Stephen B. Johnson.1994.
A general natural-language text processor forclinical radiology.
Journal of the American MedicalInformatics Association, 1:161?174.Carol Friedman, Pauline Kra, Hong Yu, MichaelKrauthammer, and Andrey Rzhetsky.
2001.
GE-NIES: a natural-language processing system for theextraction of molecular pathways from journal arti-cles.
Bioinformatics, 17(Suppl.
1):S74?S82.Carol Friedman, Pauline Kra, and Andrey Rzhetsky.2002.
Two biomedical sublanguages: a descriptionbased on the theories of Zellig Harris.
Journal ofBiomedical Informatics, 35:222?235.Carol Friedman.
1986.
Automatic structuring ofsublanguage information.
In Ralph Grishman andRichard Kittredge, editors, Analyzing language in78restricted domains: sublanguage description andprocessing, pages 85?102.
Lawrence Erlbaum As-sociates.Ralph Grishman and Richard Kittredge.
1986.
Ana-lyzing language in restricted domains: sublanguagedescription and processing.
Lawrence Erlbaum As-sociates.Zellig Harris, Michael Gottfried, Thomas Ryckman,Anne Daladier, Paul Mattick, T.N.
Harris, and Su-sanna Harris.
1989.
The form of information inscience: analysis of an immunology sublanguage.Kluwer Academic Publishers.Lynette Hirschman and Naomi Sager.
1982.
Auto-matic information formatting of a medical sublan-guage.
In Richard Kittredge and John Lehrberger,editors, Sublanguage: studies of language in re-stricted semantic domains, pages 27?80.
Walter deGruyter.Timo Ja?rvinen, Mikko Laari, Timo Lahtinen, SirkkuPaajanen, Pirkko Paljakka, Mirkka Soininen, andPasi Tapanainen.
2004.
Robust language analy-sis components for practical applications.
In Ro-bust and adaptive information processing for mobilespeech interfaces: DUMAS final workshop, pages53?56.Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, andJun?ichi Tsujii.
2003.
Genia corpus?a semanti-cally annotated corpus for bio-textmining.
Bioinfor-matics, 19(Suppl.
1):180?182.Richard I. Kittredge.
2003.
Sublanguages and con-trolled languages.
In Ruslan Mitkov, editor, The Ox-ford Handbook of Computational Linguistics, pages430?447.
Oxford University Press.Tobias Kuhn.
under review.
Survey and classificationof controlled natural languages.
Computational Lin-guistics.G.
Leech, R. Garside, and M. Bryant.
1994.
The large-scale grammatical tagging of text: experience withthe British National Corpus.
In N. Oostdijk andP.
de Haan, editors, Corpus based research into lan-guage.David D. McDonald.
2000.
Natural language genera-tion.
In Robert Dale, Hermann Moisl, and HaroldSomers, editors, Handbood of Natural LanguageProcessing, pages 147?179.
Marcel Dekker.Tony McEnery and Andrew Wilson.
2001.
CorpusLinguistics.
Edinburgh University Press, 2nd edi-tion.Claudiu Mihaila, Riza Theresa Batista-Navarro, andSophia Ananiadou.
2012.
Analysing entity typevariation across biomedical subdomains.
In Thirdworkshop on building and evaluating resources forbiomedical text mining, pages 1?7.Naomi Sager.
1986.
Sublanguage: linguistic phe-nomenon, computational tool.
In Ralph Grishmanand Richard Kittredge, editors, Analyzing languagein restricted domains: sublanguage description andprocessing, pages 1?17.
Lawrence Erlbaum Asso-ciates.Satoshi Sekine.
1994.
A new direction for sublan-guage nlp.
In Proceedings of the international con-ference on new methods in natural language pro-cessing, pages 123?129.Harold Somers.
1998.
An attempt to use weightedcusums to identify sublanguages.
In NeM-LaP3/CoNLL98: New methods in language process-ing and computational natural language learning,pages 131?139.Harold Somers.
2000.
Machine translation.
In RobertDale, Hermann Moisl, and Harold Somers, editors,Handbook of Natural Language Processing, pages329?346.
Marcel Dekker.Peter D. Stetson, Stephen B. Johnson, Matthew Scotch,and George Hripcsak.
2002.
The sublanguage ofcross-coverage.
In Proc.
AMIA 2002 Annual Sym-posium, pages 742?746.Michael Tanenblatt, Anni Coden, and Igor Sominsky.2010.
The ConceptMapper approach to named en-tity recognition.
In Language Resources and Evalu-ation Conference, pages 546?551.Karin Verspoor, Kevin Bretonnel Cohen, Arrick Lan-franchi, Colin Warner, Helen L. Johnson, ChristopheRoeder, Jinho D. Choi, Christopher Funk, YuriyMalenkiy, Miriam Eckert, Nianwen Xue, WilliamA.
Baumgartner Jr., Michael Bada, Martha Palmer,and Lawrence E. Hunter.
2012.
A corpus of full-textjournal articles is a robust evaluation tool for reveal-ing differences in performance of biomedical natu-ral language processing tools.
BMC Bioinformatics,13(207).79
