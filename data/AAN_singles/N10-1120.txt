Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 786?794,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsDependency Tree-based Sentiment Classification using CRFs with HiddenVariablesTetsuji Nakagawa?, Kentaro Inui??
and Sadao Kurohashi??
?National Institute of Information and Communications Technology?Tohoku University?Kyoto Universitytnaka@nict.go.jp, inui@ecei.tohoku.ac.jp, kuro@i.kyoto-u.ac.jpAbstractIn this paper, we present a dependency tree-based method for sentiment classification ofJapanese and English subjective sentences us-ing conditional random fields with hiddenvariables.
Subjective sentences often con-tain words which reverse the sentiment po-larities of other words.
Therefore, interac-tions between words need to be consideredin sentiment classification, which is difficultto be handled with simple bag-of-words ap-proaches, and the syntactic dependency struc-tures of subjective sentences are exploited inour method.
In the method, the sentiment po-larity of each dependency subtree in a sen-tence, which is not observable in training data,is represented by a hidden variable.
The po-larity of the whole sentence is calculated inconsideration of interactions between the hid-den variables.
Sum-product belief propaga-tion is used for inference.
Experimental re-sults of sentiment classification for Japaneseand English subjective sentences showed thatthe method performs better than other meth-ods based on bag-of-features.1 IntroductionSentiment classification is a useful technique for an-alyzing subjective information in a large number oftexts, and many studies have been conducted (Pangand Lee, 2008).
A typical approach for sentimentclassification is to use supervised machine learningalgorithms with bag-of-words as features (Pang etal., 2002), which is widely used in topic-based textclassification.
In the approach, a subjective sen-tence is represented as a set of words in the sen-tence, ignoring word order and head-modifier rela-tion between words.
However, sentiment classifi-cation is different from traditional topic-based textclassification.
Topic-based text classification is gen-erally a linearly separable problem ((Chakrabarti,2002), p.168).
For example, when a document con-tains some domain-specific words, the documentwill probably belong to the domain.
However, insentiment classification, sentiment polarities can bereversed.
For example, let us consider the sentence?The medicine kills cancer cells.?
While the phrasecancer cells has negative polarity, the word kills re-verses the polarity, and the whole sentence has pos-itive polarity.
Thus, in sentiment classification, asentence which contains positive (or negative) polar-ity words does not necessarily have the same polar-ity as a whole, and we need to consider interactionsbetween words instead of handling words indepen-dently.Recently, several methods have been proposed tocope with the problem (Zaenen, 2004; Ikeda et al,2008).
However, these methods are based on flatbag-of-features representation, and do not considersyntactic structures which seem essential to inferthe polarity of a whole sentence.
Other methodshave been proposed which utilize composition ofsentences (Moilanen and Pulman, 2007; Choi andCardie, 2008; Jia et al, 2009), but these methodsuse rules to handle polarity reversal, and whether po-larity reversal occurs or not cannot be learned fromlabeled data.
Statistical machine learning can learnuseful information from training data and generallyrobust for noisy data, and using it instead of rigidrules seems useful.
Wilson et al (2005) proposeda method for sentiment classification which utilizeshead-modifier relation and machine learning.
How-ever, the method is based on bag-of-features and po-larity reversal occurred by content words is not han-dled.
One issue of the approach to use sentencecomposition and machine learning is that only thewhole sentence is labeled with its polarity in gen-eral corpora for sentiment classification, and eachcomponent of the sentence is not labeled, thoughsuch information is necessary for supervised ma-786Whole Dependency TreePolarities of Dependency SubtreesIt cancer and heart disease.preventscancer and heart disease.preventscancer and heart disease.+?
?Figure 1: Polarities of Dependency Subtreeschine learning to infer the sentence polarity from itscomponents.In this paper, we propose a dependency tree-basedmethod for Japanese and English sentiment classifi-cation using conditional random fields (CRFs) withhidden variables.
In the method, the sentiment po-larity of each dependency subtree, which is not ob-servable in training data, is represented by a hiddenvariable.
The polarity of the whole sentence is cal-culated in consideration of interactions between thehidden variables.The rest of this paper is organized as follows: Sec-tion 2 describes a dependency tree-based methodfor sentiment classification using CRFs with hid-den variables, and Section 3 shows experimental re-sults on Japanese and English corpora.
Section 4discusses related work, and Section 5 gives conclu-sions.2 Dependency Tree-based SentimentClassification using CRFs with HiddenVariablesIn this study, we handle a task to classify the polar-ities (positive or negative) of given subjective sen-tences.
In the rest of this section, we describe a prob-abilistic model for sentiment classification based ondependency trees, methods for inference and param-eter estimation, and features we use.2.1 A Probabilistic Model based onDependency TreesLet us consider the subjective sentence ?It preventscancer and heart disease.?
In the sentence, cancerand heart disease have themselves negative polari-It cancer and heart disease.preventss0+<root>s10 s2+ s3?
s4?Figure 2: Probabilistic Model based on Dependency Trees0 s1 s2 s3 s4g1 g2 g3 g4g5g6 g7 g8Figure 3: Factor Graphties.
However, the polarities are reversed by modi-fying the word prevents, and the dependency subtree?prevents cancer and heart disease?
has positive po-larity.
As a result, the whole dependency tree ?Itprevents cancer and heart disease.?
has positive po-larity (Figure 1).
In such a way, we can considerthe sentiment polarity for each dependency subtreeof a subjective sentence.
Note that we use phrases asa basic unit instead of words in this study, becausephrases are useful as a meaningful unit for sentimentclassification1.
In this paper, a dependency subtreemeans the subtree of a dependency tree whose rootnode is one of the phrases in the sentence.We use a probabilistic model as shown in Fig-ure 2.
We consider that each phrase in the subjectivesentence has a random variable (indicated by a cir-cle in Figure 2).
The random variable represents thepolarity of the dependency subtree whose root nodeis the corresponding phrase.
Two random variablesare dependent (indicated by an edge in Figure 2) iftheir corresponding phrases have head-modifier re-lation in the dependency tree.
The node denoted as<root> in Figure 2 indicates a virtual phrase whichrepresents the root node of the sentence, and we re-gard that the random variable of the root node is thepolarity of the whole sentence.
In usual annotatedcorpora for sentiment classification, only each sen-tence is labeled with its polarity, and each phrase(dependency subtree) is not labeled, so all the ran-dom variables except the one for the root node are1From an empirical view, in our preliminary experimentswith the proposed method, phrase-based processing performedbetter than word-based processing in accuracy and in computa-tional efficiency.787hidden variables that cannot be observed in labeleddata (indicated by gray circles in Figure 2).
Withsuch a probabilistic model, it is possible to utilizeproperties such that phrases which contain positive(or negative) words tend to have positive (negative)polarities, and two phrases with head-modifier rela-tion tend to have opposite polarities if the head con-tains a word which reverses sentiment polarity.Next, we define the probabilistic model as shownin Figure 2 in detail.
Let n denote the number ofphrases in a subjective sentence, wi the i-th phrase,and hi the head index of the i-th phrase.
Let si de-note the random variable which represents the po-larity of the dependency subtree whose root is thei-th phrase (si ?
{+1,?1}), and let p denote thepolarity of the whole sentence (p ?
{+1,?1}).
Weregard the 0-th phrase as a virtual phrase which rep-resents the root of the sentence.
w,h, s respectivelydenote the sequence of wi, hi, si.w = w1 ?
?
?wn, h = h1 ?
?
?hn, s = s0 ?
?
?
sn,p = s0.For the example sentence in Figure 1, w1 =It,w2 =prevents, w3 =cancer, w4 =and heart dis-ease., h1 = 2, h2 = 0, h3 = 2, h4 = 2.
We definethe joint probability distribution of the sentiment po-larities of dependency subtrees s, given a subjectivesentence w and its dependency tree h, using log-linear models:P?(s|w,h)=1Z?
(w,h)exp{ K?k=1?kFk(w,h, s)},(1)Z?
(w,h)=?sexp{ K?k=1?kFk(w,h, s)}, (2)Fk(w,h, s)=n?i=1fk(i,w,h, s), (3)where ?
= {?1, ?
?
?
, ?K} is the set of parametersof the model.
fk(i,w,h, s) is the feature functionof the i-th phrase, and is classified to node featurewhich considers only the corresponding node, oredge feature which considers both the correspond-ing node and its head, as follows:fk(i,w,h, s)={ fnk (wi, si) (k ?
Kn),f ek(wi, si, whi , shi) (k ?
Ke),(4)where Kn and Ke respectively represent the sets ofindices of node features and edge features.2.2 Classification of Sentiment PolarityLet us consider how to infer the sentiment polarityp ?
{+1,?1}, given a subjective sentence w andits dependency tree h. The polarity of the root node(s0) is regarded as the polarity of the whole sentence,and p can be calculated as follows:p=argmaxp?P?
(p?|w,h), (5)P?(p|w,h)=?s:s0=pP?(s|w,h).
(6)That is, the polarity of the subjective sentence is ob-tained as the marginal probability of the root nodepolarity, by summing the probabilities for all thepossible configurations of hidden variables.
How-ever, enumerating all the possible configurations ofhidden variables is computationally hard, and we usesum-product belief propagation (MacKay, 2003) forthe calculation.Belief propagation enables us to efficiently calcu-late marginal probabilities.
In this study, the graph-ical model to be solved has a tree structure (identi-cal to the syntactic dependency tree) which has noloops, and an exact solution can be obtained us-ing belief propagation.
Dependencies among ran-dom variables in Figure 2 are represented by a factorgraph in Figure 3.
The factor graph consists of vari-able nodes si indicated by circles, and factor (fea-ture) nodes gi indicated by squares.
In the exam-ple in Figure 3, gi(1 ?
i ?
4) correspond to thenode features in Equation (4), and gi(5 ?
i ?
8)correspond to the edge features.
In belief propa-gation, marginal distribution is calculated by pass-ing messages (beliefs) among the variables and fac-tors connected by edges in the factor graph (Referto (MacKay, 2003) for detailed description of beliefpropagation).2.3 Parameter EstimationLet us consider how to estimate model parameters?,given L training examples D = {?wl,hl, pl?
}Ll=1.In this study, we use the maximum a posteriori es-timation with Gaussian priors for parameter estima-tion.
We define the following objective function L?,788and calculate the parameters ??
which maximize thevalue:L?=L?l=1logP?
(pl|wl,hl) ?12?2K?k=1?2k, (7)?
?=argmax?L?, (8)where ?
is a parameter of Gaussian priors and is setto 1.0 in later experiments.
The partial derivatives ofL?
are as follows:?L???k=L?l=1[?sP?
(s|wl,hl, pl)Fk(wl,hl, s)??sP?
(s|wl,hl)Fk(wl,hl, s)]?
1?2?k.
(9)The model parameters can be calculated with theL-BFGS quasi-Newton method (Liu and Nocedal,1989) using the objective function and its partialderivatives.
While the partial derivatives containsummation over all the possible configurations ofhidden variables, it can be calculated efficiently us-ing belief propagation as explained in Section 2.2.This parameter estimation method is same to oneused for Latent-Dynamic Conditional Random Field(Morency et al, 2007).
Note that the objective func-tion L?
is not convex, and there is no guarantee forglobal optimality.
The estimated model parametersdepend on the initial values of the parameters, andthe setting of the initial values of model parameterswill be explained in Section 2.4.2.4 FeaturesTable 1 shows the features used in this study.
Fea-tures (a)?
(h) in Table 1 are used as the node fea-tures (Equation (4)) for the i-th phrase, and fea-tures (A)?
(E) are used as the edge features for thei-th and j-th phrases (j=hi).
In Table 1, si denotesthe hidden variable which represents the polarity ofthe dependency subtree whose root node is the i-th phrase, qi denotes the prior polarity of the i-thphrase (explained later), ri denotes the polarity re-versal of the i-th phrase (explained later), mi de-notes the number of words in the i-th phrase, ui,k,bi,k, ci,k, fi,k respectively denote the surface form,base form, coarse-grained part-of-speech (POS) tag,Node Featuresa sib si&qic si&qi&rid si&ui,1, ?
?
?
, si&ui,mie si&ci,1, ?
?
?
, si&ci,mif si&fi,1, ?
?
?
, si&fi,mig si&ui,1&ui,2, ?
?
?
, si&ui,mi?1&ui,mih si&bi,1&bi,2, ?
?
?
, si&bi,mi?1&bi,miEdge FeaturesA si&sjB si&sj&rjC si&sj&rj&qjD si&sj&bi,1, ?
?
?
, si&sj&bi,miE si&sj&bj,1, ?
?
?
, si&sj&bj,mjTable 1: Features Used in This Studyfine-grained POS tag of the k-th word in the i-thphrase.We used the morphological analysis system JU-MAN and the dependency parser KNP2 for pro-cessing Japanese data, and the POS tagger MX-POST (Ratnaparkhi, 1996) and the dependencyparser MaltParser3 for English data.
KNP outputsphrase-based dependency trees, but MaltParser out-puts word-based dependency trees, and we con-verted the word-based ones to phrase-based ones us-ing simple heuristic rules explained in Appendix A.The prior polarity of a phrase qi ?
{+1, 0,?1} isthe innate sentiment polarity of a word contained inthe phrase, which can be obtained from sentimentpolarity dictionaries.
We used sentiment polaritydictionaries made by Kobayashi et al (2007) and Hi-gashiyama et al (2008)4 for Japanese experiments(The resulting dictionary contains 6,974 positive ex-pressions and 8,428 negative expressions), and a dic-tionary made by Wilson et al (2005)5 for Englishexperiments (The dictionary contains 2,289 positiveexpressions and 4,143 negative expressions).
Whena phrase contains the words registered in the dictio-naries, its prior polarity is set to the registered po-larity, otherwise the prior polarity is set to 0.
Whena phrase contains multiple words in the dictionaries,the registered polarity of the last (nearest to the end2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/3http://maltparser.org/4http://cl.naist.jp/?inui/research/EM/sentiment-lexicon.html5http://www.cs.pitt.edu/mpqa/789of the sentence) word is used.The polarity reversal of a phrase ri ?
{0, 1} rep-resents whether it reverses the polarities of otherphrases (1) of not (0).
We prepared polarity revers-ing word dictionaries, and the polarity reversal ofa phrase is set to 1 if the phrase contains a wordin the dictionaries, otherwise set to 0.
We con-structed polarity reversing word dictionaries whichcontain such words as decrease and vanish that re-verse sentiment polarity.
A Japanese polarity revers-ing word dictionary was constructed from an auto-matically constructed corpus, and the constructionprocedure is described in Appendix B (The dictio-nary contains 219 polarity reversing words).
AnEnglish polarity reversing word dictionary was con-structed from the General Inquirer dictionary6 in thesame way as Choi and Cardie (2008), by collectingwords which belong to either NOTLW or DECREAScategories (The dictionary contains 121 polarity re-versing words).Choi and Cardie (2008) categorized polarity re-versing words into two categories: function-wordnegators such as not and content-word negators suchas eliminate.
The polarity reversal of a phrase ri ex-plained above handles only the content-word nega-tors, and function-word negators are handled in an-other way, since the scope of a function-word nega-tor is generally limited to the phrase containing it inJapanese, and the number of function-word negatorsis small.
The prior polarity qi and the polarity rever-sal ri of a phrase are changed to the following q?i andr?i, if the phrase contains a function-word negator (inJapanese) or if the phrase is modified by a function-word negator (in English):q?i=?qi, (10)r?i=1 ?
ri.
(11)In this paper, unless otherwise noted, the word po-larity reversal is used to indicate polarity reversingcaused by content-word negators, and function-wordnegators are assumed to be applied to qi and ri in theabove way beforehand.As described in Section 2.3, there is no guaran-tee of global optimality for estimated parameters,since the objective function is not convex.
In our6http://www.wjh.harvard.edu/ inquirer/preliminary experiments, L-BFGS often did not con-verge and classification accuracy was unstable whenthe initial values of parameters were randomly set.Therefore, in later experiments, we set the initialvalues in the following way.
For the feature (A) inTable 1 in which si and sj are equal, we set the ini-tial parameter ?i of the feature to a random numberin [0.9, 1.1], otherwise we set to a random number in[?0.1, 0.1]7.
By setting such initial values, the initialmodel parameters have a property that two phraseswith head-modifier relation tend to have the samepolarity, which is intuitively reasonable.3 ExperimentsWe conducted experiments of sentiment classifica-tion on four Japanese corpora and four English cor-pora.3.1 DataWe used four corpora for experiments of Japanesesentiment classification: the Automatically Con-structed Polarity-tagged corpus (ACP) (Kaji andKitsuregawa, 2006), the Kyoto University and NTTBlog corpus (KNB) 8, the NTCIR Japanese opinioncorpus (NTC-J) (Seki et al, 2007; Seki et al, 2008),the 50 Topics Evaluative Information corpus (50Topics) (Nakagawa et al, 2008).
The ACP corpusis an automatically constructed corpus from HTMLdocuments on the Web using lexico-syntactic pat-terns and layout structures.
The size of the corpusis large (it consists of 650,951 instances), and weused 1/100 of the whole corpus.
The KNB corpusconsists of Japanese blogs, and is manually anno-tated.
The NTC-J corpus consists of Japanese news-paper articles.
There are two NTCIR Japanese opin-ion corpora available, the NTCIR-6 corpus and theNTCIR-7 corpus; and we combined the two cor-pora.
The 50 Topics corpus is collected from variouspages on the Web, and is manually annotated.We used four corpora for experiments of Englishsentiment classification: the Customer Review data7The values of most learned parameters distributed between-1.0 and 1.0 in our preliminary experiments.
Therefore, we de-cided to give values around the upper bound (1.0) and the mean(0.0) to the features in order to incorporate minimal prior knowl-edge into the model.8http://nlp.kuee.kyoto-u.ac.jp/kuntt/790(CR)9, the MPQA Opinion corpus (MPQA)10, theMovie Review Data (MR) 11, and the NTCIR En-glish opinion corpus (NTC-E) (Seki et al, 2007;Seki et al, 2008).
The CR corpus consists of re-view articles about products such as digital camerasand cellular phones.
There are two customer reviewdatasets, the 5 products dataset and the 9 productsdataset, and we combined the two datasets.
In theMPQA corpus, sentiment polarities are attached notto sentences but expressions (sub-sentences), and weregarded the expressions as sentences and classifiedthe polarities.
There are two NTCIR English cor-pora available, the NTCIR-6 corpus and the NTCIR-7 corpus, and we combined the two corpora.The statistical information of the corpora we usedis shown in Table 2.
We randomly split each corpusinto 10 portions, and conducted 10-fold cross valida-tion.
Accuracy of sentiment classification was cal-culated as the number of correctly predicted labels(polarities) divided by the number of test examples.3.2 Compared MethodsWe compared our method to 6 baseline methods,and this section describes them.
In the following,p0 ?
{+1,?1} denotes the major polarity in train-ing data, Hi denotes the set consisting of all the an-cestor nodes of the i-th phrase in the dependencytree, and sgn(x) is defined as below:sgn(x)=????
?+1 (x > 0),0 (x = 0),?1 (x < 0).Voting without Polarity Reversal The polarity ofa subjective sentence is decided by voting ofeach phrase?s prior polarity.
In the case of atie, the major polarity in the training data isadopted.p=sgn( n?i=1qi + 0.5p0).
(12)Voting with Polarity Reversal Same to Votingwithout Polarity Reversal, except that the po-larities of phrases which have odd numbers of9http://www.cs.uic.edu/ liub/FBS/sentiment-analysis.html10http://www.cs.pitt.edu/mpqa/11http://www.cs.cornell.edu/People/pabo/movie-review-data/reversal phrases in their ancestors are reversedbefore voting.p=sgn( n?i=1qi?j?Hi(?1)rj + 0.5p0).
(13)Rule The polarity of a subjective sentence is deter-ministically decided basing on rules, by con-sidering the sentiment polarities of dependencysubtrees.
The polarity of the dependency sub-tree whose root is the i-th phrase is decided byvoting the prior polarity of the i-th phrase andthe polarities of the dependency subtrees whoseroot nodes are the modifiers of the i-th phrase.The polarities of the modifiers are reversed iftheir head phrase has a reversal word.
The de-cision rule is applied from leaf nodes in the de-pendency tree, and the polarity of the root nodeis decided at the last.si=sgn(qi +?j:hj=isj(?1)ri), (14)p=sgn(s0 + 0.5p0).
(15)Bag-of-Features with No Dictionaries The polar-ity of a subjective sentence is classified us-ing Support Vector Machines.
Surface forms,base forms, coarse-grained POS tags and fine-grained POS tags of word unigrams and bi-grams in the subjective sentence are used asfeatures12.
The second order polynomial ker-nel is used and the cost parameter C is set to1.0.
No prior polarity information (dictionary)is used.Bag-of-Features without Polarity Reversal Sameto Bag-of-Features with No Dictionaries, ex-cept that the voting result of prior polarities(one of positive, negative or tie) is also usedas a feature.Bag-of-Features with Polarity Reversal Same toBag-of-Features without Polarity Reversal, ex-cept that the polarities of phrases which have12In experiments on English corpora, only the features of un-igrams are used and those of bigrams are not used, since thebigram features decreased accuracies in our preliminary experi-ments as reported in previous work (Andreevskaia and Bergler,2008).791Language Corpus Number of Instances (Positive / Negative)ACP 6,510 (2,738 / 3,772)Japanese KNB 2,288 (1,423 / 865)NTC-J 3,485 (1,083 / 2,402)50 Topics 5,366 (3,175 / 2,191)CR 3,772 (2,406 / 1,366)English MPQA 10,624 (3,316 / 7,308)MR 10,662 (5,331 / 5,331)NTC-E 3,812 (1,226 / 2,586)Table 2: Statistical Information of CorporaMethod Japanese EnglishACP KNB NTC-J 50 Topics CR MPQA MR NTC-EVoting-w/o Rev.
0.686 0.764 0.665 0.727 0.714 0.804 0.629 0.730Voting-w/ Rev.
0.732 0.792 0.714 0.765 0.742 0.817 0.631 0.740Rule 0.734 0.792 0.742 0.764 0.743 0.818 0.629 0.750BoF-no Dic.
0.798 0.758 0.754 0.761 0.793 0.818 0.757 0.768BoF-w/o Rev.
0.812 0.823 0.794 0.805 0.802 0.840 0.761 0.793BoF-w/ Rev.
0.822 0.830 0.804 0.819 0.814 0.841 0.764 0.797Tree-CRF 0.846* 0.847* 0.826* 0.841* 0.814 0.861* 0.773* 0.804(* indicates statistical significance at p < 0.05)Table 3: Accuracy of Sentiment Classificationodd numbers of reversal phrases in their ances-tors are reversed before voting.Tree-CRF The proposed method based on depen-dency trees using CRFs, described in Section 2.3.3 Experimental ResultsThe experimental results are shown in Table 3.
Theproposed method Tree-CRF obtained the best ac-curacies for all the four Japanese corpora and thefour English corpora, and the differences againstthe second best methods were statistically signifi-cant (p < 0.05) with the paired t-test for the sixof the eight corpora.
Tree-CRF performed betterfor the Japanese corpora than for the English cor-pora.
For both the Voting methods and the Bag-of-Features methods, the methods with polarity rever-sal performed better than those without it13.Both BoF-w/ Rev.
and Tree-CRF use supervisedmachine learning and the same dictionaries (the13The Japanese polarity reversing word dictionary was con-structed from the ACP corpus as described in Appendix B, andit is not reasonable to compare the methods with and withoutpolarity reversal on the ACP corpus.
However, the tendencycan be seen on the other 7 corpora.prior polarity dictionaries and the polarity revers-ing word dictionaries), but the latter performed bet-ter than the former.
Our error analysis showed thatBoF-w/ Rev.
was not robust for erroneous words inthe prior polarity dictionaries.
BoF-w/ Rev.
uses thevoting result of the prior polarities as a feature, andthe feature is sensitive to the errors in the dictionary,while Tree-CRF uses several information as well asthe prior polarities to decide the polarities of depen-dency subtrees, and was robust to the dictionary er-rors.
We investigated the trained model parametersof Tree-CRF, and found that the features (E) in Ta-ble 1, in which the head and the modifier have op-posite polarities and the head word is such as pro-tect and withdraw, have large positive weights.
Al-though these words were not included in the polar-ity reversing word dictionary, the property that thesewords reverse polarities of other words seems to belearned with the model.4 Related WorkVarious studies on sentiment classification havebeen conducted, and there are several methods pro-792posed for handling reversal of polarities.
In this pa-per, our method was not directly compared with theother methods, since it is difficult to completely im-plement them or conduct experiments with exactlythe same settings.Choi and Cardie (2008) proposed a method toclassify the sentiment polarity of a sentence bas-ing on compositional semantics.
In their method,the polarity of the whole sentence is determinedfrom the prior polarities of the composing words bypre-defined rules, and the method differs from ourswhich uses the probabilistic model to handle interac-tions between hidden variables.
Syntactic structureswere used in the studies of Moilanen and Pulman(2007) and, Jia et al (2009), but their methods arebased on rules and supervised learning was not usedto handle polarity reversal.
As discussed in Sec-tion 1, Wilson et al (2005) studied a bag-of-featuresbased statistical sentiment classification method in-corporating head-modifier relation.Ikeda et al (2008) proposed a machine learningapproach to handle sentiment polarity reversal.
Foreach word with prior polarity, whether the polarity isreversed or not is learned with a statistical learningalgorithm using its surrounding words as features.The method can handle only words with prior polar-ities, and does not use syntactic dependency struc-tures.Conditional random fields with hidden variableshave been studied so far for other tasks.
Latent-Dynamic Conditional Random Fields (LDCRF)(Morency et al, 2007; Sun et al, 2008) are prob-abilistic models with hidden variables for sequen-tial labeling, and belief propagation is used for in-ference.
Out method is similar to the models, butthere are several differences.
In our method, onlyone variable which represents the polarity of thewhole sentence is observable, and dependency re-lation among random variables is not a linear chainbut a tree structure which is identical to the syntacticdependency.5 ConclusionIn this paper, we presented a dependency tree-basedmethod for sentiment classification using condi-tional random fields with hidden variables.
In thismethod, the polarity of each dependency subtreeof a subjective sentence is represented by a hid-den variable.
The values of the hidden variablesare calculated in consideration of interactions be-tween variables whose nodes have head-modifier re-lation in the dependency tree.
The value of thehidden variable of the root node is identified withthe polarity of the whole sentence.
Experimentalresults showed that the proposed method performsbetter for Japanese and English data than the base-line methods which represents subjective sentencesas bag-of-features.AppendixA Rules for Converting Word Sequence toPhrase SequenceLet v1, ?
?
?
, vN denote an English word sequence, yithe part-of-speech of the i-th word, and zi the headindex of the i-th word.
The word sequence was con-verted to a phrase sequence as follows, by applyingrules which combine two adjacent words:LT ?
{?,(,-LRB-,-LSB-,-LCB-,CC}RT ?
{?,),,,--,.,:,POS,-RRB-,-RSB-,-RCB-}PP ?
{IN,RP,TO,DT,PDT,PRP,WDT,WP,WP$,WRB}NN ?
{CD,FW,NN,NNP,NNPS,NNS,SYM,JJ}dofor i := 1 to N ?
1if xi and xi+1 are not yet combined ?
(xi ?
LT ?xi+1 ?
RT ?
((yi = yi+1 ?
yi = i+ 1 ?
yi+1 = i) ?
(xi ?
PP ?
(xi ?
NN ?
xi+1 ?
NN )))) thenCombine the words vi and vi+1until No rules are appliedB Construction of Japanese PolarityReversing Word DictionaryWe constructed a Japanese polarity reversing worddictionary from the Automatically ConstructedPolarity-tagged corpus (Kaji and Kitsuregawa,2006).
First, we collected sentences, each of whichcontains just one phrase having prior polarity, andthe phrase modifies a phrase which modifies the rootnode.
Among them, we selected sentences in whichthe prior polarity is not equal to the polarity of thewhole sentence.
We extracted all the words in thehead phrase, and manually checked them whetherthey should be put into the dictionary or not.
The ra-tionale behind the procedure is that the prior polaritycan be considered to be reversed by a certain wordin the head phrase.793ReferencesAlina Andreevskaia and Sabine Bergler.
2008.
WhenSpecialists and Generalists Work Together: Overcom-ing Domain Dependence in Sentiment Tagging.
InProceedings of the 46th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies, pages 290?298.Soumen Chakrabarti.
2002.
Mining the Web: Dis-covering Knowledge from Hypertext Data.
Morgan-Kauffman.Yejin Choi and Claire Cardie.
2008.
Learning withCompositional Semantics as Structural Inference forSubsentential Sentiment Analysis.
In Proceedings ofthe 2008 Conference on Empirical Methods in NaturalLanguage Processing, pages 793?801.Masahiko Higashiyama, Kentaro Inui, and Yuji Mat-sumoto.
2008.
Acquiring Noun Polarity KnowledgeUsing Selectional Preferences.
In Proceedings of the14th Annual Meeting of the Association for NaturalLanguage Processing, pages 584?587.
(in Japanese).Daisuke Ikeda, Hiroya Takamura, Lev-Arie Ratinov, andManabu Okumura.
2008.
Learning to Shift the Po-larity of Words for Sentiment Classification.
In Pro-ceedings of the 3rd International Joint Conference onNatural Language Processing, pages 296?303.Lifeng Jia, Clement Yu, and Weiyi Meng.
2009.
The Ef-fect of Negation on Sentiment Analysis and RetrievalEffectiveness.
In Proceeding of the 18th ACM Con-ference on Information and Knowledge Management,pages 1827?1830.Nobuhiro Kaji and Masaru Kitsuregawa.
2006.
Auto-matic Construction of Polarity-Tagged Corpus fromHTML Documents.
In Proceedings of the COL-ING/ACL 2006 Main Conference Poster Sessions,pages 452?459.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Opinion Mining from Web Documents: Extrac-tion and Structurization.
Journal of the Japanese So-ciety for Artificial Intelligence, 22(2):227?238.Dong C. Liu and Jorge Nocedal.
1989.
On the limitedmemory BFGS method for large scale optimization.Mathematical Programming, 45(3):503?528.David J. C. MacKay.
2003.
Information Theory, Infer-ence, and Learning Algorithms.
Cambridge Univer-sity Press.Karo Moilanen and Stephen Pulman.
2007.
SentimentComposition.
In Proceedings of the Recent Advancesin Natural Language Processing International Confer-ence, pages 378?382.Louis-Philippe Morency, Ariadna Quattoni, and TrevorDarrell.
2007.
Latent-Dynamic Discriminative Mod-els for Continuous Gesture Recognition.
In Proceed-ings of the 2007 IEEE Conference on Computer Visionand Pattern Recognition, pages 1?8.Tetsuji Nakagawa, Takuya Kawada, Kentaro Inui, andSadao Kurohashi.
2008.
Extracting Subjective andObjective Evaluative Expressions from the Web.
InProceedings of the 2nd International Symposium onUniversal Communication.Bo Pang and Lillian Lee.
2008.
Opinion Mining andSentiment Analysis.
Foundations and Trends in Infor-mation Retrieval, 2(1-2):1?135.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
In Proceedings of the2002 Conference on Empirical Methods in NaturalLanguage Processing, pages 79?86.Adwait Ratnaparkhi.
1996.
A Maximum Entropy Modelfor Part-of-Speech Tagging.
In Proceedings of the1996 Conference on Empirical Methods in NaturalLanguage Processing Conference, pages 133?142.Yohei Seki, David Kirk Evans, Lun-Wei Ku, Hsin-HisChen, Noriko Kando, and Chin-Yew Lin.
2007.Overview of Opinion Analysis Pilot Task at NTCIR-6.
In Proceedings of the 6th NTCIR Workshop, pages265?278.Yohei Seki, David Kirk Evans, Lun-Wei Ku, Le Sun,Hsin-Hsi Chen, and Noriko Kando.
2008.
OverviewofMultilingual Opinion Analysis Task at NTCIR-7.
InProceedings of the 7th NTCIR Workshop.Xu Sun, Louis-Philippe Morency, Daisuke Okanohara,and Jun?ichi Tsujii.
2008.
Modeling Latent-Dynamicin Shallow Parsing: A Latent Conditional Model withImproved Inference.
In Proceedings of the 22nd In-ternational Conference on Computational Linguistics,pages 841?848.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis.
In Proceedings of the 2005Joint Conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 347?354.Livia Polanyi Annie Zaenen.
2004.
Contextual LexicalValence Shifters.
In Proceedings of the AAAI SpringSymposium on Exploring Attitude and Affect in Text.794
