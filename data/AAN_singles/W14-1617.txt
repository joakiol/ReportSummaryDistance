Proceedings of the Eighteenth Conference on Computational Language Learning, pages 160?170,Baltimore, Maryland USA, June 26-27 2014.c?2014 Association for Computational LinguisticsHallucinating Phrase Translations for Low Resource MTAnn IrvineCenter for Language and Speech ProcessingJohns Hopkins UniversityChris Callison-BurchComputer and Information Science Dept.University of PennsylvaniaAbstractWe demonstrate that ?hallucinating?phrasal translations can significantly im-prove the quality of machine translation inlow resource conditions.
Our hallucinatedphrase tables consist of entries composedfrom multiple unigram translations drawnfrom the baseline phrase table and fromtranslations that are induced from mono-lingual corpora.
The hallucinated phrasetable is very noisy.
Its translations are lowprecision but high recall.
We counter thisby introducing 30 new feature functions(including a variety of monolingually-estimated features) and by aggressivelypruning the phrase table.
Our analysisevaluates the intrinsic quality of ourhallucinated phrase pairs as well as theirimpact in end-to-end Spanish-English andHindi-English MT.1 IntroductionIn this work, we augment the translation model fora low-resource phrase-based SMT system by auto-matically expanding its phrase table.
We ?halluci-nate?
new phrase table entries by composing theunigram translations from the baseline system?sphrase table and translations learned from compa-rable monolingual corpora.
The composition pro-cess yields a very large number of new phrase pairtranslations, which are high recall but low preci-sion.
We filter the phrase table using a new set offeature functions estimated from monolingual cor-pora.
We evaluate the hallucinated phrase pairs in-trinsically as well as in end-to-end machine trans-lation.
The augmented phrase table provides morecoverage than the original phrase table, while be-ing high quality enough to improve translation per-formance.We propose a four-part approach to hallucinat-ing and using new phrase pair translations:1.
Learn potential translations for out-of-vocabulary (OOV) words from comparablemonolingual corpora2.
?Hallucinate?
a large, noisy set of phrasetranslations by composing unigram transla-tions from the baseline model and from themonolingually-induced bilingual dictionary3.
Use comparable monolingual corpora toscore, rank, and prune the huge number ofhallucinated translations4.
Augment the baseline phrase table with hal-lucinated translations and new feature func-tions estimated from monolingual corporaWe define an algorithm for generating looselycompositional phrase pairs, which we use to hal-lucinate new translations.
In oracle experiments,we show that such loosely compositional phrasepairs contribute substantially to the performanceof end-to-end SMT, beyond that of component un-igram translations.
In our non-oracle experiments,we show that adding a judiciously pruned set ofautomatically hallucinated phrase pairs to an end-to-end baseline SMT model results in a signifi-cant improvement in translation quality for bothSpanish-English and Hindi-English.2 MotivationTranslation models learned over small amountsof parallel data suffer from the problem of lowcoverage.
That is, they do not include trans-lations for many words and phrases.
Unknown160words, or out-of-vocabulary (OOV) words, havebeen the focus of previous work on integratingbilingual lexicon induction and machine transla-tion (Daum?e and Jagarlamudi, 2011; Irvine andCallison-Burch, 2013a; Razmara et al., 2013).Bilingual lexicon induction is the task of learningtranslations from monolingual texts, and typicalapproaches compare projected distributional sig-natures of words in the source language with dis-tributional signatures representing target languagewords (Rapp, 1995; Schafer and Yarowsky, 2002;Koehn and Knight, 2002; Haghighi et al., 2008).If the source and target language each contain, forexample, 100, 000 words, the number of pairwisecomparisons is about 10 billion, which is signifi-cant but computationally feasible.In contrast to unigrams, the difficulty in induc-ing a comprehensive set of phrase translations isthat the number of both source and target phrasesis immense.
For example, there are about 83 mil-lion unique phrases up to length three in the En-glish Wikipedia.
Pairwise comparisons of two setsof 100 million phrases corresponds to 1 x 1016.Thus, even if we limit the task to short phrases, thenumber of pairwise phrase comparisons necessaryto do an exhaustive search is infeasible.
However,multi-word translation units have been shown toimprove the quality of SMT dramatically (Koehnet al., 2003).
Phrase translations allow transla-tion models to memorize local context-dependenttranslations and reordering patterns.3 ApproachRather than compare all source language phraseswith all target language phrases, our approach effi-ciently proposes a smaller set of hypothesis phrasetranslations for each source language phrase.
Ourmethod builds upon the notion that many phrasetranslations can be composed from the translationsof its component words and subphrases.
For ex-ample Spanish la bruja verde translates into En-glish as the green witch.
Each Spanish word cor-responds to exactly one English word.
The phrasepair could be memorized and translated as a unit,or the English translation could be composed fromthe translations of each Spanish unigram.Zens et al.
(2012) found that only 2% of phrasepairs in German-English, Czech-English, Spanish-English, and French-English phrase tables consistof multi-word source and target phrases and arenon-compositional.
That is, for these languages,the vast majority of phrase pairs in a given phrasetable could be composed from smaller units.
Ourapproach takes advantage of the fact that manyphrases can be translated compositionally.We describe our approach in three parts.
In Sec-tion 3.1, we begin by inducing translations for un-known unigrams.
Then, in 3.2, we introduce ouralgorithm for composing phrase translations.
Inorder to achieve a high recall in our set of hypoth-esis translations, we define compositionality moreloosely than is typical.
Finally, in 3.3, we use com-parable corpora to prune the large set of hypothesistranslations for each source phrase.3.1 Unigram TranslationsIn any low resource setting, many word transla-tions are likely to be unknown.
Therefore, beforemoving to phrases, we use a bilingual lexicon in-duction technique to identify translations for un-igrams.
Specifically, because we assume a set-ting where we have some small amount of paral-lel data, we follow our prior work on supervisedbilingual lexicon induction (Irvine and Callison-Burch, 2013b).
We take examples of good transla-tion pairs from our word aligned training data (de-scribed in Section 4) and use random word pairsas negative supervision.
We use this supervisionto learn a log-linear classifier that predicts whethera given word pair is a translation or not.
We pairand score all source language unigrams in our tun-ing and test sets with target language unigrams thatappear in our comparable corpora.
Then, for eachsource language unigram, we use the log-linearmodel scores to rerank candidate target languageunigram translations.
As in our prior work, weinclude the following word pair features in ourlog-linear classifier: contextual similarity, tempo-ral similarity, topic similarity, frequency similar-ity, and orthographic similarity.3.2 Loosely Compositional TranslationsWe propose a novel technique for loosely compos-ing phrasal translations from an existing dictio-nary of unigram translations and stop word lists.Given a source language phrase, our approachconsiders all combinations and all permutationsof all unigram translations for each source phrasecontent word.
We ignore stop words in the in-put source phrase and allow any number of stopwords anywhere in the output target phrase.
Inorder to make the enumeration efficient, we pre-compute an inverted index that maps sorted target161casa houselinda prettylinda cutelinda handsomela casa lindastop words removedcasa lindaCartesian product?of unigram translationscute, house handsome, house house, prettyInverted Index lookupspretty house the pretty house a pretty house cute house house and handsomeBilingual Dictionary:Input Phrase:ABCDFigure 1: Example of loosely composed translations for theSpanish input in A, la casa linda.
In B, we remove the stopword la.
Then, in C, we enumerate the cartesian product of allunigram translations in the bilingual dictionary and sort thewords within each alphabetically.
Finally, we look up eachlist of words in C in the inverted index, and correspondingtarget phrases are enumerated in D. The inverted index con-tains all phrasal combinations and permutations of the wordlists in C which also appear monolingually with some fre-quency and with, optionally, any number of stop words.language content words to sets of phrases contain-ing those words in any order along with, option-ally, any number of stop words.
Our algorithm forcomposing candidate phrase translations is givenin Algorithm 1, and an example translation is com-posed in Figure 1.
Although in our experimentswe compose translations for source phrases up tolength three, the algorithm is generally applicableto any set of source phrases of interest.Algorithm 1 yields a set of target languagetranslations for any source language phrase forwhich all content unigrams have at least oneknown translation.
For most phrases, the result-ing set of hypothesis translations is very large andthe majority are incorrect.
In an initial pruningstep, we add a monolingual frequency cutoff to thecomposition algorithm and only add target phrasesthat have a frequency of at least ?FreqTto the in-verted index.
Doing so eliminates improbable tar-get language constructions early on, for examplehouse handsome her or cute a house.Input: A set of source language phrases of interest, S,each consisting of a sequence of wordssm1, sm2, ...smi; A list of all target languagephrases, targetPhrases; Source and target stopword lists, Stopsrcand Stoptrg; Set of unigramtranslations, tsmi, for all source language wordssmiR Stopsrc; monolingual target languagephrase frequencies, FreqT; Monolingualfrequency threshold ?FreqTOutput: @ Sm P S, a set of candidate phrasetranslations, Tm1, Tm2, ...TmkConstruct TargetInvertedIndex:for T P targetPhrases doif FreqTpT q ?
?FreqTthenT1 ?words tjP T if tjR StoptrgT1sorted?
sortedpT 1qappend T to TargetInvertedIndex[T1sorted]endendfor Sm P S doS1 ?words smiP Sm if smiR StopsrcCombsS1 ?
ts11?ts12?...
?ts1kT ?
r sfor cs1 P CombsS1docs1sorted?
sortedpcs1qT ?
T`TargetInvertedIndexpcs1sortedqendTm ?
TendAlgorithm 1: Computing a set of candidate composi-tional phrase translations for each source phrase in the setS.
An inverted index of target phrases is constructed thatmaps sorted lists of content words to phrases that containthose content words, as well as optionally any stop words,and have a frequency of at least ?FreqT.
Then, for a givensource phrase Sm, stop words are removed from the phrase.Next, the cartesian product of all unigram translations iscomputed.
Each element in the product is sorted and anycorresponding phrases in the inverted index are added to theoutput.3.3 Pruning Phrase Pairs Using ScoresDerived from Comparable CorporaWe further prune the large, noisy set of hypothe-sized phrase translations before augmenting a seedtranslation model.
To do so, we use a supervisedsetup very similar to that used for inducing uni-gram translations; we estimate a variety of sig-nals that indicate translation equivalence, includ-ing temporal, topical, contextual, and string simi-larity.
As we showed in Klementiev et al.
(2012),such signals are effective for identifying phrasetranslations as well as unigram translations.
Weadd ngram length, alignment, and unigram trans-lation features to the set, listed in Appendix A.We learn a log-linear model for combining thefeatures into a single score for predicting the qual-ity of a given phrase pair.
We extract training datafrom the seed translation model.
We rank hypoth-esis translations for each source phrase using clas-162sification scores and keep the top-k. We found thatusing a score threshold sometimes improves pre-cision.
However, as experiments below show, therecall of the set of phrase pairs is more important,and we did not observe improvements in transla-tion quality when we used a score threshold.4 Experimental SetupIn all of our experiments, we assume that we haveaccess to only a small parallel corpus.
For ourSpanish experiments, we randomly sample 2, 000sentence pairs (about 57, 000 Spanish words) fromthe Spanish-English Europarl v5 parallel corpus(Koehn, 2005).
For Hindi, we use the parallel cor-pora released by Post et al.
(2012).
Again, werandomly sample 2, 000 sentence pairs from thetraining corpus (about 39, 000 Hindi words).
Weexpect that this amount of parallel text could becompiled for a single text domain and any pair ofmodern languages.
Additionally, we use approxi-mately 2, 500 and 1, 000 single-reference parallelsentences each for tuning and testing our Span-ish and Hindi models, respectively.
Spanish tun-ing and test sets are newswire articles taken fromthe 2010 WMT shared task (Callison-Burch et al.,2010).1We use the Hindi development and testingsplits released by Post et al.
(2012).4.1 Unigram TranslationsOf the 16, 269 unique unigrams in the source sideof our Spanish MT tuning and test sets, 73% areOOV with respect to our training corpus.
21% ofunigram tokens are OOV.
For Hindi, 61% of the8, 137 unique unigrams in the tuning and test setsare OOV with respect to our training corpus, and18% of unigram tokens are OOV.
However, be-cause automatic word alignments estimated overthe small parallel training corpora are noisy, weuse bilingual lexicon induction to induce transla-tions for all unigrams.
We use the Wikipedia andonline news web crawls datasets that we releasedin Irvine and Callison-Burch (2013b) to estimatesimilarity scores.
Together, the two datasets con-tain about 900 million words of Spanish data andabout 50 million words of Hindi data.
For bothlanguages, we limit the set of hypothesis target un-igram translations to those that appear at least 10times in our comparable corpora.We use 3, 000 high probability word translation1news-test2008 plus news-syscomb2009 for tuning andnewstest2009 for testing.pairs extracted from each parallel corpus as posi-tive supervision and 9, 000 random word pairs asnegative supervision.
We use Vowpal Wabbit2forlearning.
The top-5 induced translations for eachsource language word are used as both a baselineset of new translations (Section 6.3) and for com-posing phrase translations.4.2 Composing and Pruning PhraseTranslationsThere are about 183 and 66 thousand unique bi-grams and trigrams in the Spanish and Hindi tun-ing and test sets, respectively.
However, manyof these phrases do not demand new hypothesistranslations.
We do not translate those which con-tain numbers or punctuation.
Additionally, forSpanish, we exclude names, which are typicallytranslated identically between Spanish and En-glish.3We exclude phrases which are sequences ofstop words only.
Additionally, we exclude phrasesthat appear more than 100 times in the small train-ing corpus because our seed phrase table likely al-ready contains high quality translations for them.Finally, we exclude phrases that appear fewer than20 times in our comparable corpora as our fea-tures are unreliable when estimated over so fewtokens.
We hypothesize translations for the ap-proximately 15 and 6 thousand Spanish and Hindiphrases, respectively, which meet these criteria.Our approach for inducing translations straightfor-wardly generalizes to any set of source phrases.In defining loosely compositional phrase trans-lations, we use both the induced unigram dictio-nary (Section 3.1) and the dictionary extractedfrom the word aligned parallel corpus.
We ex-pand these dictionaries further by mapping uni-grams to their five-character word prefixes.
Weuse monolingual corpora of Wikipedia articles4toconstruct stop word lists, containing the most fre-quent 300 words in each language, and indexes ofmonolingual phrase frequencies.
There are about83 million unique phrases up to length three inthe English Wikipedia.
However, we ignore tar-get phrases that appear fewer than three times, re-ducing this set to 10 million English phrases.
On2http://hunch.net/?vw/, version 6.1.4. withstandard learning parameters3Our names list comes from page titles of SpanishWikipedia pages about people.
We iterate through years, be-ginning with 1AD, and extract names from Wikipedia ?bornin?
category pages, e.g.
?2013 births,?
or ?Nacidos en 2013.?4All inter-lingually linked source language and Englisharticles.163average, our Spanish model yields 7, 986 Englishtranslations for each Spanish bigram, and 9, 231for each trigram, or less than 0.1% of all possi-ble candidate English phrases.
Our Hindi modelyields even fewer candidate English phrases, 826for each bigram and 1, 113 for each trigram, onaverage.We use the same comparable corpora used forbilingual lexicon induction to estimate featuresover hypothesis phrase translations.
The full fea-ture set is listed in Appendix A.
We extract su-pervision from the seed translation models by firstidentifying phrase pairs with multi-word sourcestrings, that appear at least three times in the train-ing corpus, and that are composeable using base-line model unigram translations and induced dic-tionaries.
Then, for each language pair, we usethe 3, 000 that have the highest ppf |eq scores aspositive supervision.
We randomly sample 9, 000compositional phrase pairs from those not in eachphrase table as negative supervision.
Again, weuse Vowpal Wabbit for learning a log linear modelto score any phrase pair.4.3 Machine TranslationWe use GIZA++ to word align each training cor-pus.
We use the Moses SMT framework (Koehn etal., 2007) and the standard phrase-based MT fea-ture set, including phrase and lexical translationprobabilities and a lexicalized reordering model.When we augment our models with new transla-tions, we use the average reordering scores overall bilingually estimated phrase pairs.
We tuneall models using batch MIRA (Cherry and Fos-ter, 2012).
We average results over three tuningruns and use approximate randomization to mea-sure statistical significance (Clark et al., 2011).For Spanish, we use a 5-gram language modeltrained on the English side of the complete Eu-roparl corpus and for Hindi a 5-gram languagemodel trained on the English side of the com-plete training corpus released by Post et al.
(2012).We train our language models using SRILM withKneser-Ney smoothing.
Our baseline models usea phrase limit of three, and we augment them withtranslations of phrases up to length three in our ex-periments.5 Oracle ExperimentBefore moving to the results of our proposedapproach for composing phrase translations, wepresent an oracle experiment to answer these re-search questions: Would a low resource transla-tion model benefit from composing its unigramtranslations into phrases?
Would this be fur-ther improved by adding unigram translations thatare learned from monolingual texts?
We an-swer these questions by starting with our low-resource Spanish-English and Hindi-English base-lines and augmenting each with (1) phrasal trans-lations composed from baseline model unigramtranslations, and (2) phrasal translations composedof a mix of baseline model unigram translationsand the monolingually-induced unigrams.Figure 2 illustrates how our hallucinated phrase-table entries can result in improved translationquality for Spanish to English translation.
Sincethe baseline model is trained from such a smallamount of data, it typically translates individualwords instead of phrases.
In our augmented sys-tem, we compose a translation of was no one fromhabia nadie, since habia translates as was in thebaseline model, nadie translates as one, and no isa stop word.
We are able to monolingually-inducetranslations for the OOVs centros and electoralesbefore composing the phrase translation pollingstations for centros electorales.In our oracle experiments, composed transla-tions are only added to the phrase table if theyare contained in the reference.
This eliminates thehuge number of noisy translations that our com-positional algorithm generates.
We augment base-line models with translations for the same sets ofsource language phrases described in Section 4.We use GIZA++ to word align our tuning andtest sets5and use a standard phrase pair extractionheuristic6to identify oracle phrase translations.We add oracle translations to each baseline modelwithout bilingually estimated translation scores7because such scores are not available for our auto-matically induced translations.
Instead, we scorethe oracle phrase pairs using the 30 new phrase ta-ble features described in Section 3.3.Table 1 shows the results of our oracle experi-ments.
Augmenting the baselines with the subsetof oracle translations which are composed giventhe unigram translations in the baseline modelsthemselves (i.e.
in the small training sets) yields5For both languages, we learn an alignment over our tun-ing and test sets and complete parallel training sets.6grow-diag-final7We use an indicator feature for distinguishing new com-posed translations from bilingually extracted phrase pairs.164not having dependent on the centros electorales .no was no one in the polling stations .no hab?a nadie en los centros electorales .original composeable?from original original composeable?from induced originalBaseline:Input:Hallucination Oracle:Figure 2: Example output from motivating experiment: a comparison of the baseline and full oracle translations of Spanishno hab?
?a nadie en los centros electorales, which translates correctly as there was nobody at the voting offices.
The full oracleis augmented with translations composed from the seed model as well as induced unigram translations.
The phrase was no oneis composeable from hab?
?a nadie given the seed model.
In contrast, the phrase polling stations is composeable from centroselectorales using induced translations.
For each translation, the phrase segmentations used by the decoder are highlighted.ExperimentBLEUBaseline MonolinguallyFeatures Estimated Feats.SpanishLow Resource Baseline 13.47 13.35+ Composeable Oracle14.90 15.18from Initial Model+ Composeable Oracle15.47 15.94w/ Induced Unigram Trans.HindiLow Resource Baseline 8.49 8.26+ Composeable Oracle9.12 9.54from Initial Model+ Composeable Oracle10.09 10.19w/ Induced Unigram Trans.Table 1: Motivating Experiment: BLEU results using thebaseline SMT model and composeable oracle translationswith and without induced unigram translations.a BLEU score improvement of about 1.4 pointsfor Spanish and about 0.6 for Hindi.
This find-ing itself is noteworthy, and we investigated thereason for it.
A representative example of a com-positional oracle translation that was added to theSpanish model is para evitarlos, which translatesas to prevent them.
In the training corpus, paratranslates far more frequently as for than to.
Thus,it is useful for the translation model to know that,in the context of evitarlos, para should translateas to and not for.
Additionally, evitarlos was ob-served only translating as the unigram prevent.The small model fails to align the adjoined cliticlos with its translation them.
However, our loosedefinition of compositionality allows the Englishstop word them to appear anywhere in the targettranslation.In the first result, composeable translations donot include those that contain new, induced wordtranslations.
Using the baseline model and in-duced unigram translations to compose phrasetranslations results in a 2 and 1.6 BLEU point gainfor Spanish and Hindi, respectively.The second column of Table 1 shows the resultsof augmenting the baseline models with the sameoracle phrase pairs as well as the new features esti-mated over all phrase pairs.
Although the featuresdo not improve the performance of the baselinemodels, this diverse set of scores improves perfor-mance dramatically when new, oracle phrase pairsare added.
Adding all oracle translations and thenew feature set results in a total gain of about 2.6BLEU points for Spanish and about 1.9 for Hindi.These gains are the maximum that we could hopeto achieve by augmenting models with our hallu-cinated translations and new feature set.6 Experimental Results6.1 Unigram TranslationsTable 2 shows examples of top ranked transla-tions for several Spanish words.
Although per-formance is generally quite good, we do observesome instances of false cognates, for example thetop ranked translation for aburridos, which trans-lates correctly as bored, is burritos.
Using au-tomatic word alignments as a reference, we findthat 44% of Spanish tuning set unigrams have acorrect translation in their top-10 ranked lists and62% in the top-100.
For Hindi, 31% of tuning setunigrams have a correct translation in their top-10ranked lists and 43% in the top-100.6.2 Hallucinated Phrase PairsBefore moving to end-to-end SMT experiments,we evaluate the goodness of the hallucinated andpruned phrase pairs themselves.
In order to do so,we use the same set of oracle phrase translationsdescribed in Section 5.Table 3 shows the top three English transla-tions for several Spanish phrases along with theirmodel scores.
Common, loose translations ofsome phrases are scored higher than less commonbut literal translations.
For example, very obvi-165Spanish abdominal abejorro abril aburridos accionista aceite actrizTop 5EnglishTranslationsabdominal bumblebees april burritos actionists adulterated actressabdomen bombus march boredom actionist iooc actorbowel xylocopa june agatean telmex olive awardappendicitis ilyitch july burrito shareholder milliliters americanacute bumble december poof antagonists canola singerTable 2: Top five induced translations for several source words.
Correct translations are bolded.
aceite translates as oil.Spanish English Scoreambos partidostwo parties 5.72both parties 5.31and parties 3.16hab?
?a apoyadowere supported 4.80were members 4.52had supported 4.39ministro neerland`esfinnish minister 4.76finnish ministry 2.77dutch minister 1.31unas cuantas semanasover a week 4.30a few weeks 3.72few weeks 3.22muy evidentesvery obvious 1.88very evident 1.87obviously very 1.84Table 3: Top three compositional translations for severalsource phrases and their model scores.
Correct translationsare bolded.ous scores higher than very evident as a translationof Spanish muy evidentes.
Similarly, dutch minis-ter is scored higher than netherlands minister as atranslation for ministro neerland`es.We use model scores to rerank candidate trans-lations for each source phrase and keep the top-k translations.
Figure 3 shows the precision andtype-based recall (the percent of source phrasesfor which at least one correct translation is gen-erated) as we vary k for each language pair.
Atk ?
1, precision and recall are about 27% forSpanish and about 25% for Hindi.8At k ?
200,recall increases to 57% for Spanish and precisiondrops to 2%.
For Hindi, recall increases to 40%and precision drops to 1%.Moving from k ?
1 to k ?
200, precisiondrops at about the same rate for the two source lan-guages.
However, recall increases less for Hindithan for Spanish.
We attribute this to two things.First, Hindi and English are less related than Span-ish and English, and fewer phrases are translatedcompositionally.
Our oracle experiments showedthat there is less to gain in composing phrase trans-lations for Hindi than for Spanish.
Second, theaccuracy of our induced unigram translations islower for Hindi than it is for Spanish.
Without ac-curate unigram translations, we are unable to com-pose high quality phrase translations.8Since we are computing type-based recall, and at k=1,we produce exactly one translation for each source phrase,precision and recall are the same.lllllllllll l0 10 20 30 40 50 60 70020406080RecallPrecision13.9014.0714.30 14.50 14.5713.47(a) Spanishlllllll0 10 20 30 40 50 60 7001020304050RecallPrecision 8.168.868.899.009.048.49(b) HindiFigure 3: Precision Recall curve with BLEU scores for thetop-k scored hallucinated translations.
k varies from 1 to 200.Baseline model performance is shown with a red triangle.Because we hallucinate translations for sourcephrases that appear in the training data up to 100times, our baseline models include some of theoracle phrase translations.
Not surprisingly, thebilingually extracted phrase pairs have relativelyhigh precision (81% and 40% for Spanish andHindi, respectively) and low recall (6% and 15%for Spanish and Hindi, respectively).6.3 End-to-End TranslationTable 4 shows end-to-end translation BLEU scoreresults (Papineni et al., 2002).
Our first baselineSMT models are trained using only 2, 000 paral-lel sentences and no new translation model fea-tures.
Our Spanish baseline achieves a BLEUscore of 13.47 and our Hindi baseline a BLEUscore of 8.49.
When we add the 30 new featurefunctions estimated over comparable monolingualcorpora, performance is slightly lower, 13.35 for166ExperimentBLEUSpanish HindiBaseline 13.47 8.49+ Mono.
Scores 13.35 8.26+ Mono.
Scores & OOV Trans 14.01 8.31+ Phrase Trans, k=1 13.90 8.16+ Phrase Trans, k=2 14.07 8.86*+ Phrase Trans, k=5 14.30* 8.89*+ Phrase Trans, k=25 14.50* 9.00*+ Phrase Trans, k=200 14.57* 9.04*Table 4: Experimental results.
First, the baseline modelsare augmented with monolingual phrase table features andthen also with the top-5 induced translations for all OOV un-igrams.
Then, we append the top-k hallucinated phrase trans-lations to the third baseline models.
BLEU scores are aver-aged over three tuning runs.
We measure the statistical sig-nificance of each +Phrase Trans model in comparison withthe highest performing (bolded) baseline for each language;* indicates statistical significance with p ?
0.01.Spanish and 8.26 for Hindi.
Our third baselinesaugment the second with unigram translations forall OOV tuning and test set source words using thebilingual lexicon induction techniques describedin Section 3.1.
We append the top-5 translationsfor each,9score both the original and the newphrase pairs with the new feature set, and retune.With these additional unigram translations, perfor-mance increases to 14.01 for Spanish and 8.31 forHindi.We append the top-k composed translations forthe source phrases described in Section 4 to thethird baseline models.
Both original and newphrase pairs are scored using the new feature set.BLEU score results are shown at different valuesof k along the precision-recall plots for each lan-guage pair in Figure 3 as well as in Table 4.
Wewould expect that higher precision and higher re-call would benefit end-to-end SMT.
As usual, atradeoff exists between precision and recall, how-ever, in this case, improvements in recall outweighthe risk of a lower precision.
As k increases, pre-cision decreases but both recall and BLEU scoresincrease.
For both Spanish and Hindi, BLEU scoregains start to taper off at k values over 25.In additional experiments, we found that with-out the new features the same sets of hallucinatedphrase pairs hurt performance slightly in compar-ison with the baseline augmented with unigramtranslations, and results don?t change as we varyk.10Thus, the translation models are able to ef-fectively use the higher recall sets of new phrase9The same set used for composing phrase translations.10For all values of k between 1 and 100, without the newfeatures, BLEU scores are about 13.70 for Spanishpairs because we also augmented the models with30 new feature functions, which help them distin-guish good from bad translations.7 DiscussionOur results showed that including a high recallset of ?hallucinated?
translations in our augmentedphrase table successfully improved the quality ofour machine translations.
The algorithm that weproposed for hypothesizing translations is flexible,and in future work we plan to modify it slightlyto output even more candidate translations.
Forexample, we could retrieve target phrases whichcontain at least one source word translation insteadof all.
Alternatively, we could identify candidatesusing entirely different information, for examplethe monolingual frequency of a source and targetword, instead of unigram translations.
This typeof inverted index may improve recall in the set ofhypothesis phrase translations at the cost of gener-ating a much bigger set for reranking.Our new phrase table features were informa-tive in distinguishing correct from incorrect phrasetranslations, and they allowed us to make use ofnoisy but high recall supplemental phrase pairs.This is a critical result for research on identify-ing phrase translations from non-parallel text.
Wealso believe that using fairly strong target (En-glish) language models contributed to our models?ability to discriminate between good and bad hal-lucinated phrase pairs.
We leave research on theinfluence of the language model in our setting tofuture work.In this work, we experimented with two lan-guage pairs, Spanish-English and Hindi-English.While Spanish and English are very closely re-lated, Hindi and English are less related.
Ouroracle experiments showed potential for compos-ing phrase translations for both language pairs,and, indeed, in our experiments using hallucinatedphrase translations we saw significant translationquality gains for both.
We expect that improvingthe quality of induced unigram translations willyield even more performance gains.The vast majority of prior work on low resourceMT has focused on Spanish-English (Haghighiet al., 2008; Klementiev et al., 2012; Ravi andKnight, 2011; Dou and Knight, 2012; Ravi, 2013;Dou and Knight, 2013).
Although such experi-ments serve as important proofs of concept, wefound it important to also experiment with a more167truly low resource language pair.
The success ofour approach that we have seen for Spanish andHindi suggests that it is worth pursuing such di-rections for other even less related and resourcedlanguage pairs.
In addition to language pair, textgenre and the degree of looseness or literalness ofgiven parallel corpora may also affect the amountof phrase translation compositionality.8 Related WorkPhrase-based SMT models estimated over verylarge parallel corpora are expensive to store andprocess.
Prior work has reduced the size of SMTphrase tables in order to improve efficiency with-out the loss of translation quality (He et al., 2009;Johnson et al., 2007; Zens et al., 2012).
Typi-cally, the goal of pruning is to identify and re-move phrase pairs which are likely to be inaccu-rate, using either the scores and counts of a givenpair itself or those relative to other phrase pairs.Our work, in contrast, focuses on low resource set-tings, where training data is limited and providesincomplete and unreliable scored phrase pairs.
Webegin by dramatically increasing the size of ourSMT phrase table in order to expand its coverageand then use non-parallel data to rescore and filterthe table.In the decipherment task, translation modelsare learned from comparable corpora without anyparallel text (Ravi and Knight, 2011; Dou andKnight, 2012; Ravi, 2013).
In contrast, we be-gin with a small amount of parallel data and takea very different approach to learning translationmodels.
In our prior work (Irvine and Callison-Burch, 2013b), we showed how effective evensmall amounts of bilingual data can be for learningtranslations from monolingual texts.Garera and Yarowsky (2008) pivot throughbilingual dictionaries in several language pairs tocompose translations for compound words.
Zhangand Zong (2013) construct a set of new, additionalphrase pairs for the task of domain adaptation formachine translation.
That work uses two dictio-naries to bootstrap a set of phrase pair transla-tions: one probabilistic dictionary extracted from2 million words of bitext and one manually creatednew-domain dictionary of 140, 000 word transla-tions.
Our approach to the construction of newphrase pairs is somewhat similar to Zhang andZong (2013), but we don?t rely on a very largemanually generated dictionary.
Additionally, wefocus on the low resource language pair setting,where a large training corpus is not available.Deng et al.
(2008) work in a standard SMT set-ting but use a discriminative framework for ex-tracting phrase pairs from parallel corpora.
Thatapproach yields a phrase table with higher preci-sion and recall than the table extracted by stan-dard world alignment based heuristics (Och andNey, 2003; Koehn et al., 2003).
The discrimi-native model combines features from word align-ments and bilingual training data as well as infor-mation theoretic features estimated over monolin-gual data into a single log-linear model and thenthe phrase pairs are filtered using a threshold onmodel scores.
The phrase pairs that it extracts arelimited to those that appear in pairs of sentences inthe parallel training data.
Our work takes a similarapproach to that of Deng et al.
(2008), however,unlike that work, we hallucinate phrase pairs thatdid not appear in training data in order to augmentthe original, bilingually extracted phrase table.Other prior work has used comparable cor-pora to extract parallel sentences and phrases(Munteanu and Marcu, 2006; Smith et al., 2010).Such efforts are orthogonal to our approach.
Weuse parallel corpora, when available, and hallu-cinates phrase translations without assuming anyparallel text in our comparable corpora.9 ConclusionsWe showed that ?hallucinating?
phrasal transla-tions can significantly improve machine transla-tion performance in low resource conditions.
Ourhallucinated translations are composed from uni-gram translations.
The translations are low preci-sion but high recall.
We countered this by intro-ducing new feature functions and pruning aggres-sively.10 AcknowledgementsThis material is based on research sponsored byDARPA under contract HR0011-09-1-0044 andby the Johns Hopkins University Human Lan-guage Technology Center of Excellence.
Theviews and conclusions contained in this publica-tion are those of the authors and should not beinterpreted as representing official policies or en-dorsements of DARPA or the U.S. Government.168ReferencesChris Callison-Burch, Philipp Koehn, Christof Monz,Kay Peterson, Mark Przybocki, and Omar Zaidan.2010.
Findings of the 2010 joint workshop on sta-tistical machine translation and metrics for machinetranslation.
In Proceedings of the Workshop on Sta-tistical Machine Translation (WMT).Colin Cherry and George Foster.
2012.
Batch tuningstrategies for statistical machine translation.
In Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Lin-guistics (NAACL).Jonathan H. Clark, Chris Dyer, Alon Lavie, andNoah A. Smith.
2011.
Better hypothesis testingfor statistical machine translation: controlling foroptimizer instability.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Hal Daum?e, III and Jagadeesh Jagarlamudi.
2011.Domain adaptation for machine translation by min-ing unseen words.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Yonggang Deng, Jia Xu, and Yuqing Gao.
2008.Phrase table training for precision and recall: Whatmakes a good phrase and a good phrase pair?
InProceedings of the Conference of the Association forComputational Linguistics (ACL).Qing Dou and Kevin Knight.
2012.
Large scaledecipherment for out-of-domain machine transla-tion.
In Proceedings of the Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP/CoNLL).Qing Dou and Kevin Knight.
2013.
Dependency-based decipherment for resource-limited machinetranslation.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).Nikesh Garera and David Yarowsky.
2008.
Translatingcompounds by learning component gloss translationmodels via multiple languages.
In Proceedings ofthe International Joint Conference on Natural Lan-guage Processing (IJCNLP).Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexi-cons from monolingual corpora.
In Proceedings ofthe Conference of the Association for ComputationalLinguistics (ACL).Zhongjun He, Yao Meng, and Hao Yu.
2009.
Dis-carding monotone composed rule for hierarchicalphrase-based statistical machine translation.
In Pro-ceedings of the 3rd International Universal Commu-nication Symposium.Ann Irvine and Chris Callison-Burch.
2013a.
Com-bining bilingual and comparable corpora for lowresource machine translation.
In Proceedings ofthe Workshop on Statistical Machine Translation(WMT).Ann Irvine and Chris Callison-Burch.
2013b.
Su-pervised bilingual lexicon induction with multiplemonolingual signals.
In Proceedings of the Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics (NAACL).Howard Johnson, Joel Martin, George Foster, andRoland Kuhn.
2007.
Improving translation qualityby discarding most of the phrasetable.
In Proceed-ings of the Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP/CoNLL).Alex Klementiev, Ann Irvine, Chris Callison-Burch,and David Yarowsky.
2012.
Toward statistical ma-chine translation without parallel corpora.
In Pro-ceedings of the Conference of the European Associ-ation for Computational Linguistics (EACL).Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
InACL Workshop on Unsupervised Lexical Acquisi-tion.Philipp Koehn, Franz Joseph Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Lin-guistics (NAACL).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the Conference of the Association forComputational Linguistics (ACL).Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of theMachine Translation Summit.Prasanth Kolachina, Nicola Cancedda, Marc Dymet-man, and Sriram Venkatapathy.
2012.
Prediction oflearning curves in machine translation.
In Proceed-ings of the Conference of the Association for Com-putational Linguistics (ACL).Dragos Munteanu and Daniel Marcu.
2006.
Extractingparallel sub-sentential fragments from non-parallelcorpora.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51,March.169Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automaticevaluation of machine translation.
In Proceedingsof the Conference of the Association for Computa-tional Linguistics (ACL).Matt Post, Chris Callison-Burch, and Miles Osborne.2012.
Constructing parallel corpora for six indianlanguages via crowdsourcing.
In Proceedings ofthe Workshop on Statistical Machine Translation(WMT).Reinhard Rapp.
1995.
Identifying word translationsin non-parallel texts.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Sujith Ravi and Kevin Knight.
2011.
Decipheringforeign language.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Sujith Ravi.
2013.
Scalable decipherment for machinetranslation via hash sampling.
In Proceedings ofthe Conference of the Association for ComputationalLinguistics (ACL).Majid Razmara, Maryam Siahbani, Reza Haffari, andAnoop Sarkar.
2013.
Graph propagation for para-phrasing out-of-vocabulary words in statistical ma-chine translation.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Charles Schafer and David Yarowsky.
2002.
Inducingtranslation lexicons via diverse similarity measuresand bridge languages.
In Proceedings of the Confer-ence on Natural Language Learning (CoNLL).Jason R. Smith, Chris Quirk, and Kristina Toutanova.2010.
Extracting parallel sentences from compara-ble corpora using document level alignment.
In Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Lin-guistics (NAACL).Richard Zens, Daisy Stanton, and Peng Xu.
2012.
Asystematic comparison of phrase table pruning tech-niques.
In Proceedings of the Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP/CoNLL).Jiajun Zhang and Chengqing Zong.
2013.
Learninga phrase-based translation model from monolingualdata with application to domain adaptation.
In Pro-ceedings of the Conference of the Association forComputational Linguistics (ACL).Appendix A: Phrase pair filtering featuresThe first ten features are similar to those describedby Irvine and Callison-Burch (2013b).
Stop wordsare defined as the most frequent 300 words in eachlanguage?s Wikipedia, and content words are allnon-stop words.?
Web crawl phrasal context similarity score?
Web crawl lexical context similarity score, averaged overaligned unigrams?
Web crawl phrasal temporal similarity score?
Web crawl lexical temporal similarity score, averagedover aligned unigrams?
Wikipedia phrasal context similarity score?
Wikipedia lexical context similarity score, averaged overaligned unigrams?
Wikipedia phrasal topic similarity score?
Wikipedia lexical topic similarity score, averaged overaligned unigrams?
Normalized edit distance, averaged over aligned unigrams?
Absolute value of difference between the logs of thesource and target phrase Wikipedia monolingual frequen-cies?
Log target phrase Wikipedia monolingual frequency?
Log source phrase Wikipedia monolingual frequency?
Indicator: source phrase is longer?
Indicator: target phrase is longer?
Indicator: source and target phrases same length?
Number of source content words higher than target?
Number of target content words higher than source?
Number of source and target content words same?
Number of source stop words higher than target?
Number of target stop words higher than source?
Number of source and target stop words same?
Percent of source words aligned to at least one target word?
Percent of target words aligned to at least one source word?
Percent of source content words aligned to at least onetarget word?
Percent of target content words aligned to at least onesource word?
Percent of aligned word pairs aligned in bilingual trainingdata?
Percent of aligned word pairs in induced dictionary?
Percent of aligned word pairs in stemmed induced dictio-nary170
