Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 158?161,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsSJTULTLAB: Chunk Based Method for Keyphrase ExtractionLetian WangDepartment ofComputer Science & EngineeringShanghai Jiao Tong UniversityShanghai, Chinakoh@sjtu.edu.cnFang LiDepartment ofComputer Science & EngineeringShanghai Jiao Tong UniversityShanghai, Chinafli@sjtu.edu.cnAbstractIn this paper we present a chunk basedkeyphrase extraction method for scientificarticles.
Different from most previous sys-tems, supervised machine learning algo-rithms are not used in our system.
Instead,document structure information is used toremove unimportant contents; Chunk ex-traction and filtering is used to reduce thequantity of candidates; Keywords are usedto filter the candidates before generatingfinal keyphrases.
Our experimental resultson test data show that the method worksbetter than the baseline systems and iscomparable with other known algorithms.1 IntroductionKeyphrases are sequences of words which cap-ture the main topics discussed in a document.Keyphrases are very useful in many natural lan-guage processing (NLP) applications such as doc-ument summarization, classification and cluster-ing.
But it is an expensive and time-consuming jobfor users to tag keyphrases of a document.
Theseneeds motivate methods for automatic keyphraseextraction.Most existing algorithms for keyphrase extrac-tion treat this task as a supervised classifica-tion task.
The KEA algorithm (Gordon et al,1999) identifies candidate keyphrases using lex-ical methods, calculates feature values for eachcandidate, and uses a machine-learning algorithmto predict which candidates are good keyphrases.A domain-specific method (Frank et al, 1999)was proposed based on the Naive Bayes learn-ing scheme.
Turney (Turney, 2000) treated adocument as a set of phrases, which the learn-ing algorithm must learn to classify as positive ornegative examples of keyphrases.
Turney (Tur-ney, 2003) also presented enhancements to theKEA keyphrase extraction algorithm that are de-signed to increase the coherence of the extractedkeyphrases.
Nguyen and yen Kan (Nguyen andyen Kan, 2007) presented a keyphrase extractionalgorithm for scientific publications.
They also in-troduced two features that capture the positionsof phrases and salient morphological phenom-ena.
Wu and Agogino (Wu and Agogino, 2004)proposed an automated keyphrase extraction al-gorithm using a nondominated sorting multi-objective genetic algorithm.
Kumar and Srinathan(Kumar and Srinathan, 2008) used n-gram filtra-tion technique and weight of words for keyphraseextraction from scientific articles.For this evaluation task, Kim and Kan (Kimand Kan, 2009) tackled two major issues in au-tomatic keyphrase extraction using scientific ar-ticles: candidate selection and feature engineer-ing.
They also re-examined the existing featuresbroadly used for the supervised approach.Different from previous systems, our systemuses a chunk based method to extract keyphrasesfrom scientific articles.
Domain-specific informa-tion is used to find out useful parts in a document.The chunk based method is used to extract candi-dates of keyphrases in a document.
Keywords of adocument are used to select keyphrases from can-didates.In the following, Section 2 will describe the ar-chitecture of the system.
Section 3 will introducefunctions and implementation of each part in thesystem.
Experiment results will be showed in Sec-tion 4.
The conclusion will be given in Section 5.2 System ArchitectureFigure 1 shows the architecture of our system.
Thesystem accepts a document as input (go througharrows with solid lines), then does the preprocess-ing job and identifies the structure of the docu-ment.
After these two steps, the formatted doc-ument is sent to the candidate selection module158PreprocessingDocumentStructureIdentificationChunk ExtractionChunk FilteringKeywordsExtractionChunk SelectionSystemKeyphrase SelectionOutput2Output1CandidateSelectionFormattedDocument(s)CandidatesInputDocumentTrainingDataFigure 1: System architecturewhich first extracts chunks from the document,then uses some rules to filter the extracted chunks.After candidate selection, the system will choosetop fifteen (ordered by the position of the first oc-currence in the original document) chunks fromthe candidates as the keyphrases and output theresult (?Output1?
in Figure 1) which is our sub-mitted result.
The candidates will also be sentto keyphrase selection module which first extractskeywords from the formatted document, then useskeywords to choose keyphrases from the candi-dates.
Keywords extraction needs some trainingdata (go through arrows with dotted lines) whichalso needs first two steps of our system.
The resultof keywords selection module will be sent to ?Out-put2?
as the final result after choosing top fifteenchunks.OpenNLP1and KEA2are used in chunk extrac-tion and keywords extraction respectively.3 System Description3.1 PreprocessingIn preprocessing, our system first deletes linebreaks between each broken lines to reconnect the1http://opennlp.sourceforge.net/2http://nzdl.org/Kea/broken sentences while line breaks after title andsection titles will be reserved.
Title and sectiontitles are recognized through some heuristic rulesthat title occupies first few lines of a documentand section titles are started with numbers exceptabstract and reference.
The system then deletesbrackets blocks in the documents to make sureno keyphrases will be splitted by brackets blocks(e.g., the brackets in ?natural language processing(NLP) applications?
could be an obstacle to ex-tracting phrase ?natural language processing ap-plications?
).3.2 Document Structure IdentificationScientific articles often have similar structureswhich start with title, abstract and end with con-clusion, reference.
The structure information isused in our system to remove unimportant con-tents in the input document.
Based on the anal-ysis of training documents, we assume that eacharticle can be divided into several parts: Title, Ab-stract, Introduction, Related Work, Content, Ex-periment, Conclusion, Acknowledgement and Ref-erence, where Content often contains the descrip-tion of theories, methods or algorithms.To implement the identification of documentstructure, our system first maps each section ti-tle (including document title) to one of the partsin the document structure with some rules derivedfrom the analysis of training documents.
For eachpart except Content, we have a pattern to map thesection titles.
For example, the section title of Ab-stract should be equal to ?abstract?, the section ti-tle of Introduction should contain ?introduction?,the section title of Related Work should contain?related work?
or ?background?, the section titleof Experiment should contain ?experiment?, ?re-sult?
or ?evaluation?, the section title of Conclu-sion should contain ?conclusion?
or ?discussion?.Section titles which do not match any of the pat-terns will be mapped to the Content part.
Aftermapping section titles, the content between twosection titles will be mapped to the same part asthe first section title (e.g., the content between thesection title ?1.
Introduction?
and ?2.
RelatedWork?
will be mapped to the Introduction part).In our keyphrase analysis, we observed thatmost keyphrases appear in the first few parts ofa document, such as Title, Abstract, and Introduc-tion.
We also found that parts like Experiment,Acknowledgement and Reference almost have no159keyphrases.
Thus, Experiment, Acknowledgementand Reference are removed by our system andother parts are sorted in their original order andoutputted as formatted document(s) (see in Fig-ure 1) for further process.3.3 Candidate SelectionThe purpose of candidate selection is to find outpotential keyphrases in a document.
Traditionalapproaches just choose all the possible words se-quences and filters them with part-of-speech tags.This approach may result in huge amount of candi-dates and lots of meaningless candidates for eachdocument.Our system uses chunk based method to solvethese problems.
?A chunk is a textual unit of adjacentword tokens which can be mutuallylinked through unambiguously identi-fied dependency chains with no recourseto idiosyncratic lexical information.
?3Our approach significantly reduces the quantityof candidates and keep the meanings of origi-nal documents.
For example, for an article ti-tle, ?Evaluating adaptive resource managementfor distributed real-time embedded systems?, thetraditional method will extract lots of meaning-less candidates like ?adaptive resource?
and ?dis-tributed real-time?, while our method just extract?adaptive resource management?
and ?distributedreal-time embedded systems?
as candidates.3.3.1 Chunk ExtractionThe first step of candidate selection is chunk ex-traction which extract chunks from a document.Four tools in OpenNLP, SentenceDetector, Tok-enizer, PosTagger and TreebankChunker, are uti-lized in our system.
The system first evokes Sen-tenceDetector to split the formatted document intosentences.
Then uses Tokenizer and PosTagger tolabel all the words with part-of-speech tag.
At last,TreebankChunker is used to extract chunks fromthe document.3.3.2 Chunk filteringNot all the extracted chunks can be the candidatesof keyphrases.
Our system uses some heuristicrules to select candidates from extracted chunks.3http://www.ilc.cnr.it/sparkle/wp1-prefinal/node24.htmlThe types of rules range from statistic informa-tion to syntactic structures.
The rules that our sys-tem uses are based on some traditional methodsfor candidate filtering.
They are:1.
Any chunks in candidates should have lessthan 5 words.2.
Any single word chunks in candidates shouldbe found at least twice in a document.3.
Any chunks in candidates should be nounphrases.4.
Any chunks in candidates must start with theword with the part-of-speech tag (defined inOpenNLP) NN, NNS, NNP, NNPS, JJ, JJRor JJS and end with the word with the part-of-speech tag NN, NNS, NNP or NNPS.
Chunksthat do not match these rules will be removed.Chunks that haven?t been removed will be thecandidate keyphrases of the document.3.4 Keyphrase SelectionOur analysis shows that keywords are helpful toextract keyphrases from a document.
Thus, key-words are used to select keyphrases from candi-date chunks.3.4.1 Keywords ExtractionKEA is a keyphrase extraction tool, it can also beused to extract keywords with some appropriateparameters.
We observed that most keyphrasesextracted by KEA only contain one word or twowords which describe the key meaning of the doc-ument, even when the max length is set to 5 ormore.
There are four parameters to be set, in or-der to get best results, we set maximum length ofa keyphrase to 2, minimum length of a keyphraseto 1, minimum occurrence of a phrase to 1 andnumber of keyphrases to extract to 30.
Then, theoutput of the KEA system contains thirty keywordsper document.As showed in Figure 1, KEA needs training data(provided by the task owner).
Our system uses for-matted documents (generated by the first two stepsof our system) of training data as the input trainingdata to KEA.3.4.2 Chunk SelectionAfter extracting thirty keywords from each docu-ment, our system uses these keywords to filter outnon-keyphrase chunks from the candidates.
The160system completes the task in two steps: 1) Re-move candidates of a document that do not haveany keywords of the document extracted by KEA;2) Choose the top fifteen (ordered by the positionof the first occurrence in the orginal document)keyphrases as the answer of a document (?Out-put2?
in Figure 1).4 Experiment ResultTable 1 shows the F-score of two outputs of oursystem and some baseline systems.
The first threemethods are the baselines provided by the taskowner.
TFIDF is an unsupervised method to rankthe candidates based on TFIDF scores.
NB andME are supervised methods using Navie Bayesand maximum entropy in WEKA4.
KEA refers tothe KEA system with the parameters that can out-put the best results.
OP1 is our system withthe ?Output1?
as result and OP2 is our systemwith the ?Output2?
as result (see Figure 1).
Insecond column, ?R?
means to use the reader-assigned keyphrases set as gold-standard data and?C?
means to use both author-assigned and reader-assigned keyphrases sets as answers.Method by Top05 Top10 Top15TFIDF R 10.44% 12.61% 12.87%C 11.19% 14.35% 15.10%NB R 9.86% 12.07% 12.65%C 10.89% 14.03% 14.70%ME R 9.86% 12.07% 12.65%C 10.89% 14.03% 14.70%KEA R 14.55% 17.24% 16.42%C 14.45% 17.68% 17.74%OP1 R 15.61% 17.60% 17.31%C 15.36% 18.41% 18.61%OP2 R 16.08% 18.42% 18.05%C 17.91% 20.52% 20.36%Table 1: The comparison of F-score of our systemwith other systems.From the table, we can see that, both two out-puts of our system made an improvement over thebaseline systems and got better results than thewell known KEA system.We submitted both results of OP1 and OP2 tothe evaluation task.
Because of some misunder-standing over the result upload system, only the4http://www.cs.waikato.ac.nz/ml/weka/result of OP1 (with bold style) was successfullysubmitted.5 ConclusionWe proposed a chunk based method for keyphraseextraction in this paper.
In our system, documentstructure information of scientific articles is usedto pick up significant contents, chunk based candi-date selection is used to reduce the quantity of can-didates and reserve their original meanings, key-words are used to select keyphrases from a docu-ment.
All these factors contribute to the result ofour system.ReferencesEibe Frank, Gordon W. Paynter, Ian H. Witten, CarlGutwin, and Craig G. Nevill-manning.
1999.Domain-specific keyphrase extraction.
pages 668?673.
Morgan Kaufmann Publishers.Ian Witten Gordon, Gordon W. Paynter, Eibe Frank,Carl Gutwin, and Craig G. Nevill-manning.
1999.Kea: Practical automatic keyphrase extraction.
InProceedings of Digital Libraries 99 (DL?99, pages254?255.
ACM Press.Su Nam Kim and Min-Yen Kan. 2009.
Re-examiningautomatic keyphrase extraction approaches in scien-tific articles.
In Proceedings of the Workshop onMultiword Expressions: Identification, Interpreta-tion, Disambiguation and Applications, pages 9?16,Singapore, August.
Association for ComputationalLinguistics.Niraj Kumar and Kannan Srinathan.
2008.
Automatickeyphrase extraction from scientific documents us-ing n-gram filtration technique.
In DocEng ?08:Proceeding of the eighth ACM symposium on Doc-ument engineering, pages 199?208, New York, NY,USA.
ACM.Thuy Dung Nguyen and Min yen Kan. 2007.Keyphrase extraction in scientific publications.
InIn Proc.
of International Conference on Asian Digi-tal Libraries (ICADL 07, pages 317?326.
Springer.Peter Turney.
2000.
Learning algorithms for keyphraseextraction.
Information Retrieval, 2:303?336.Peter Turney.
2003.
Coherent keyphrase extraction viaweb mining.
In In Proceedings of IJCAI, pages 434?439.Jia-Long Wu and Alice M. Agogino.
2004.
Au-tomating keyphrase extraction with multi-objectivegenetic algorithms.
In HICSS ?04: Proceedings ofthe Proceedings of the 37th Annual Hawaii Interna-tional Conference on System Sciences (HICSS?04) -Track 4, page 40104.3, Washington, DC, USA.
IEEEComputer Society.161
