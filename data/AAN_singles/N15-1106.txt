Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1018?1023,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsAPRO: All-Pairs Ranking Optimization for MT TuningMarkus Dreyer?SDL Research6060 Center Drive Suite 150Los Angeles, CA 90045markus.dreyer@gmail.comYuanzhe DongSDL Research6060 Center Drive Suite 150Los Angeles, CA 90045ydong@sdl.comAbstractWe present APRO, a new method for machinetranslation tuning that can handle large featuresets.
As opposed to other popular methods(e.g., MERT, MIRA, PRO), which involve ran-domness and require multiple runs to obtain areliable result, APRO gives the same result onany run, given initial feature weights.
APROfollows the pairwise ranking approach of PRO(Hopkins and May, 2011), but instead of rank-ing a small sampled subset of pairs from the k-best list, APRO efficiently ranks all pairs.
Byobviating the need for manually determinedsampling settings, we obtain more reliable re-sults.
APRO converges more quickly than PROand gives similar or better translation results.1 IntroductionMachine translation tuning seeks to find featureweights that maximize translation quality.
Recentefforts have focused on methods that scale to largenumbers of features (Cherry and Foster, 2012), andamong these, PRO has gained popularity (PairwiseRanking Optimization, Hopkins and May (2011)).PRO?s goal is to find feature weights such that theresulting k-best list entries are ranked in the sameway that an evaluation function (e.g., BLEU, Pap-ineni et al (2002)) ranks them.
To do this, it labelspairs of translations for each sentence as positive ornegative, depending on the gold ranking of the twopair elements given by BLEU.
A binary classifier istrained on these labeled examples, resulting in newfeature weights, and the procedure is iterated.
This?Markus Dreyer is now at Amazon, Inc., Seattle, WA.procedure would ordinarily be too expensive sincethere areO(k2) pairs per sentence, where both k andthe number of sentences can be in the thousands, sobillions of training examples would be produced periteration.
Therefore, Hopkins and May (2011) usesubsampling to consider a small percentage of allpairs per sentence.We present APRO (All-Pairs Ranking Optimiza-tion), a tuning approach that, like PRO, uses pair-wise ranking for tuning.
Unlike PRO, it is not lim-ited to optimizing a small percentage of pairs persentence.
Based on an efficient ranking SVM for-mulation (Airola et al (2011), Lee and Lin (2014)),we find, in each iteration, feature weights that min-imize ranking errors for all pairs of translations persentence.
This tuning method inherits all the ad-vantages of PRO?it is scalable, effective, easy toimplement?and removes its limitations.
It does notrequire meta-tuning of sampling parameters since nosampling is used; it does not need to be run multi-ple times to obtain reliable results, like MERT (Och,2003), PRO, MIRA (Chiang et al, 2008) and others,since it uses global optimization and is determin-istic given initial feature weights; and it convergesquickly.2 Notation and DefinitionsFor both PRO and APRO, we use the following def-initions: A tuning dataset contains S source sen-tences x1, .
.
.
, xS.
Let Ysbe the space of all transla-tions of xs.
It contains one or more known referencetranslations ys+.
Each translation ysi?
Yshas a fea-1018ture representation1f(xs, ysi), or for short, fsi, anda linear classification score hsi= wTfsi, where wis a feature weight vector.
Given a source sentencexs, a translation decoder can search (often a subsetof) Ysand return the k translations ys1, .
.
.
, yskwiththe highest classification scores.
A k-best list is thelist of ys1, .
.
.
, ysk,?s.
For each translation ysiwe canobtain an evaluation score b(ysi,ys+), or for short,bsi, which can be the BLEU+1 score (Lin and Och,2004).2For a given source sentence xs, let (i, j) de-note a pair of translations (ysi, ysj).3 PROWe now describe PRO, before constrasting it withour new approach, APRO.
For each iteration t fromt = 1 .
.
.
T , PRO performs the following steps:1.
Given current feature weights wt, obtain a k-best list, as defined above, from the translation de-coder.
For each xs, add to its k-best entries the k-best entries from previous iterations, so that xsnowhas kstranslations; the overall list is called an accu-mulated k-best list.2.
For each source sentence xs, first sample upto ?
candidate pairs from its translations in the k-best list.
Less similar pairs are more likely to be-come candidate pairs.
Similarity in a pair (i, j) heremeans a small absolute difference dsijbetween bsiand bsj.
The most similar pairs (dsij< ?)
are dis-carded.
Then select the ?
least similar pairs amongthe remaining candidate pairs.3.
For each pair (i, j) from the ?
selected pairs,add the difference vector (fsi?fsj) with class label1 if bsi> bsj, otherwise add it with class label ?1.Also add (fsj?fsi) with the opposite label.4.
Train any classifier on the labeled data, re-sulting in a new weights vector w?.
Set wt+1=??w?+(1??
)?wt.Dependencies between tuning iterations are intro-duced by the use of accumulated k-best lists andthe interpolation of weight vectors in step 4, usingan interpolation factor ?.
Translation quality varieswith different choices for ?, ?, ?, ?, see Figure 1.The quality varies even when PRO is run multipletimes with the same parameters, due to the sampling1For simplicity, we leave out nuisance variables like align-ments, segmentations, or parse trees, from this description,which may be part of the feature space.2But see Nakov et al (2013) for variants.20.5 21.0 21.5 22.0 22.5 23.0BLEU score on test data0.10.51.0?
(interpolation factor)fasterconvergenceslowerconvergencePRO APROFigure 1: PRO versus APRO (eng-swe) for 3 settings of ?.PRO: 8 sampling settings per ?
setting.4APRO: no sam-pling.
Vertical line indicates settings from H&M (2011).Not shown: PRO outlier with BLEU =7.9 at ?
= 0.5.step.
Practitioners would have to perform an expen-sive grid search multiple times to be sure to obtaingood results.
APRO seeks to remedy this problem.One could try to improve PRO by experimentingwith other pair selection heuristics; APRO circum-vents the problem by efficiently selecting all pairs.4 APROOur method APRO is, like PRO, a ranking method.We believe that learning to rank is a suitable methodfor MT tuning because it matches the test-time re-quirements of correctly predicting the best transla-tions or correctly ranked k-best lists of translations.Compared to PRO, we simplify the procedureby removing sampling and labeling steps 2 and 3,thereby removing some of PRO?s implementationcomplexity and manually set parameters.
We runonly two steps, corresponding to PRO?s steps 1 and4: In each tuning iteration, we obtain an accumu-lated k-best list, then directly find a neww?that min-imizes the loss on that k-best list, which correspondsto PRO?s running of a classifier.
APRO?s classifica-tion model is an efficient ranking SVM (Airola et al(2011), Lee and Lin (2014)), described as follows.4.1 ModelFor each sentence xs, we define the set of preferencepairs as the set of ordered translation pairs for whichthe evaluation score prefers the first element:Ps= {(i, j) : bsi> bsj} (1)4PRO settings: ?
= {5k, 8k} = {small, large}, ?
={50, 100} = {light, dark}, ?
= {.03, .05} = {no dot, dot}.1019Following Lee and Lin (2014), we define the loss(or, error) of any sentence s as the sum of its pair-wise squared hinge losses:Lsw=?
(i,j)?Psmax(0, 1?hsi+hsj)2(2)That is, no loss is contributed by preference pairsfor which the classification score correctly prefersthe first element by a large-enough margin, i.e.,hsi?
hsj+1; all other preference pairs contributesome loss.
We seek to find a weight vector that min-imizes the regularized overall loss:w?= argminwRw+ C ?1N?sLsw(3)where Rw=12wTw is a Gaussian regularizerto prevent overfitting and C a constant controllingthe relative regularization amount.
We divide byN =?sksto account for the increasing sizes ofaccumulated k-best lists between tuning iterations,which leads to increased sentence losses.
If thiswere not done, the relative amount of regularizationwould decrease in subsequent iterations of tuning.Any gradient-based optimization method can beused to findw?.
Since the loss is convex, the weightswe find given a particular k-best list are optimal.This is different from PRO and Bazrafshan et al(2012), where the resulting weights depend on thepairs sampled; MIRA, where they depend on the or-der of sentences processed; and MERT, where opti-mization is greedy and depends on initial weights.4.2 Efficient ComputationHow do we efficiently compute Lswper sentence?
Inthis and the following subsection, we leave out allsentence indices s for ease of notation; it is under-stood that we operate on a given sentence.A straightforward algorithm to compute Lwwould iterate over all preference pairs (i, j) ?
Pand add up their losses (Joachims, 2002).
However,since there are O(k2) pairs per sentence, with po-tentially thousands of sentences, this would be ex-tremely inefficient.
PRO?s solution to this problemis subsampling.
The alternative solution we apply isto make the sums over translation pairs efficient bycarefully rearranging the terms of the sentence loss,making use of quantities that can be precomputed ef-ficiently (Airola et al (2011), Lee and Lin (2014)).Definitions.
Let us define those quantities.
For agiven sentence s, let the set Q contain all membersof P that contribute a positive loss to the overall lossterm:Q = {(i, j) : (i, j) ?
P ?
(1?hi+hj> 0)} (4)We also define an index notation into Q:Qi?= {(i, j) ?
Q,?j} qi?= |Qi?| (5)Q?j= {(i, j) ?
Q, ?i} q?j= |Q?j| (6)ri?=?
(i,j)?Qi?hj(7)The bullet (?)
can be read as any.
Example: Q?3contains pairs ?
Q whose second element is transla-tion 3. qi?and q?jdenote corresponding set sizes.Rearrangement.
We use these definitions to ex-press the loss as a sum over only O(k) elements.First, we simplify the loss expression by summingonly over elements from Q, i.e., pairs from P thatcontribute a positive loss, so the max becomes un-necessary:Lw=?
(i,j)?Pmax(0, 1?hi+hj)2(8)=?(i,j)?Q(1?hi+hj)2(9)=?
(i,j)?Qh2i?2hi+1+h2j+2hj?2hihj(10)We then use the precomputed quantities definedabove to rewrite the sum over O(k2) pairs to a sumover just O(k) elements:Lw=k?i=1qi?
(h2i?2hi+1)+q?i(h2i+2hi)?2 ri?hi(11)This step is described in detail below.
Our newformulation is simpler but equivalent to Lee and Lin1020(2014).
Using order statistics trees (Cormen et al,2001), the quantities qi?, q?i, and ri?can be precom-puted in O(k log k) time (see details in Lee and Lin(2014)).
This precomputation, together with the re-arranged loss, allows APRO to make efficient weightupdates without having to subsample.Detailed derivation.
We explain how to deriveEquation 11 from Equation 10.First, let us define the following equalities:?
(1,j)?Qh1= q1??h1?
(2,j)?Qh2= q2??h2.
.
.If we do not fix the first pair element to a particu-lar value, we have:?(i,j)?Qhi=?iqi??hi(12)Similarly:?
(j,1)?Qh1= q?1?h1?
(j,2)?Qh2= q?2?h2.
.
.If we do not fix the second element of each pair toa particular value, we have:?
(j,i)?Qhi=?iq?i?hi(13)We split Equation 10 into separate sums and per-form a change of variables in the second sum:Lw=?(i,j)?Qh2i?2hi+1+?(j,i)?Qh2i+2hi?2?
(i,j)?Qhihj(14)We introduce one more equality, where (16) fol-lows from the definition of ri?in Equation 7:?(i,j)?Qhihj=?ihi???(i,j)?Qi?hj??(15)Lang.
Train Dev TestAra-Eng 14.4M 66K 37KChi-Eng 142.9M 61K 29KEng-Swe 100.1M 21K 22KEng-Fra 100.0M 63K 20KIta-Eng 102.8M 21K 20KPol-Eng 90.5M 21K 19KTable 1: Number of words in the used data sets.=?ihiri?
(16)We now use equalities 12, 13, and 16 to arrive atEquation 11:Lw=?iqi?(h2i?2hi+1)+?iq?i(h2i+2hi)?2?iri?hi=?iqi?
(h2i?2hi+1)+q?i(h2i+2hi)?2ri?hi5 Experiments5.1 Experimental SetupWe validate APRO on 6 diverse language pairs.
Foreach one, we perform HMM-based word alignment(Vogel et al, 1996) and phrase rule extraction on thetraining data.
We use 20 standard features, incl.
8 re-ordering features, plus the sparse features listed forPBTM systems in Hopkins and May (2011).5For Ara-Eng and Chi-Eng, we use BOLT Y2 datasets.6For all other languages, we sample train, dev,and test sets from in-house data.
Table 1 describesthe different data set sizes.
We use 5-gram LMstrained on the target side of the training data; forAra-Eng and Chi-Eng, we add 2 LMs trained on En-glish Gigaword and other sources.We tune on dev data.
In each tuning run, we usek = 500, except for Ara-Eng (k = 1500).
We usethe same weight initialization for every tuning run,where most features are initialized to 0 and somedense features are initialized to 1 or -1.
During tun-ing, we use case-insensitive BLEU+1.
We tune for5We use the 500 most frequent words for word pair features.6For ara-eng, a subset of the training data was chosen whosesource side has maximum similarity to the test source side.1021PRO APROBLEU LR BLEU LRAra-Eng (29.3) 30.7 (0.93) 0.97 (30.3) 30.8 (0.98) 0.99Chi-Eng (15.4) 20.8 (0.78) 0.98 (19.2) 20.8 (1.01) 0.98Eng-Fra (30.9) 33.0 (0.95) 0.97 (32.7) 33.3 (1.00) 0.99Eng-Swe (22.2) 22.4 (1.00) 1.01 (23.1) 23.0 (1.00) 1.00Ita-Eng (25.6) 25.3 (1.00) 1.00 (25.2) 25.6 (1.00) 1.00Pol-Eng (22.4) 23.0 (0.95) 0.99 (23.3) 23.3 (1.00) 0.99Table 2: PRO versus APRO after 10 iterations (small inparentheses) and at convergence (?
30 iterations).
Goodresults after 10 iterations indicate fast convergence.
PRO:mean over 2 runs (average BLEU standard deviation was0.1); APRO: single run.
LR: length ratio.up to 30 iterations,7where we reset the accumu-lated k-best list after 10 iterations.8For PRO, weuse ?=5000, ?=50, ?=0.05, ?=0.1, and (MegaM)regularization strength ?=1 as described in Hopkinsand May (2011).
For APRO, we use regulariza-tion strength C=0.01 and ?=1, which effectively re-moves the weight interpolation step.
We repeat eachPRO tuning twice and report the mean of length ra-tios and case-sensitive BLEU scores on test data.
ForAPRO, no repeated runs are necessary; it gives thesame result on any run given initial feature weights.For APRO, we optimize using the implementa-tion by Lee and Lin, which uses a truncated Newtonmethod.95.2 ResultsWe measure the runtime of PRO and APRO.
Foran accumulated k-best list containing s=2,748 sen-tences with an average ks=3,600 translation, PROand APRO take 13 and 8 minutes, respectively.
Ta-ble 2 shows translation quality after 10 iterationsand at convergence.
We observe that APRO con-verges quickly: After running for 10 iterations, itgives higher BLEU scores and better length ratiosthan PRO for five out of six language pairs.
At con-vergence, PRO has caught up, but for all language7Like Hopkins and May (2011), we stop earlier when theaccumulated k-best list does not change anymore.8This removes bad translations from early iterations and pro-vides good initial weights for the last 20 iterations.
This did notdecrease but sometimes increase final performance.9See http://goo.gl/CVmnoZ.
No change to the soft-ware is necessary; but in each iteration it must be called withC?=CN, see Equation 3.
We have also experimented with achange to the software that scales the loss of each sentence bythe number of translation pairs for that sentence; this did notgive reliable BLEU improvements over Equation 3.pairs APRO performs similar or better.One of APRO?s advantages are stable results: Fig-ure 1 compares PRO and APRO for 3 values of ?
:For each value, we run PRO eight times with dif-ferent sampling settings and APRO once.
We ob-serve that the different PRO settings result in differ-ent BLEU scores.
Cherry and Foster (2012) reportthat they could not find one PRO setting that workedacross all language pairs.
This suggests that practi-tioners may have to run expensive grid searches tofind optimal PRO performance; this is not necessarywith APRO.
While PRO performs best with ?
= 0.1,APRO gets good results for ?=1, which is the reasonfor its fast convergence (Table 2).6 ConclusionsWe have presented APRO, a new tuning method formachine translation.
Like PRO, APRO is a batchpairwise ranking method, and as such, it inheritsPRO?s advantages of being effective, scalable tolarge feature sets and easy to fit into the standardbatch MT tuning framework.
We remove PRO?ssampling step and learn a pairwise ranking over thewhole k-best list inO(k log k) time.
We have shownthat PRO?s different sampling settings result in dif-ferent final results; by removing these settings weget more reliable results.
We find that PRO?s weightinterpolation is not necessary for APRO, resulting infaster convergence.
At convergence, APRO?s trans-lation quality was found to be similar or better thanPRO?s.
APRO?s use of global optimization and thelack of randomness lead to more stable tuning withdeterministic results.AcknowledgmentsWe thank Jonathan May, Mark Hopkins, Bill Byrne,Adria Gispert, Gonzalo Iglesias, Steve DeNeefe andthe anonymous reviewers for their valuable com-ments and suggestions.ReferencesAntti Airola, Tapio Pahikkala, and Tapio Salakoski.2011.
Training linear ranking SVMs in linearithmictime using red-black trees.
Pattern Recognition Let-ters, 32(9):1328?1336.Marzieh Bazrafshan, Tagyoung Chung, and DanielGildea.
2012.
Tuning as linear regression.
In Pro-1022ceedings of the 2012 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics: Human Language Technologies, pages 543?547.
Association for Computational Linguistics.Colin Cherry and George Foster.
2012.
Batch tuningstrategies for statistical machine translation.
In Pro-ceedings of the 2012 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics: Human Language Technologies, pages 427?436.
Association for Computational Linguistics.David Chiang, Yuval Marton, and Philip Resnik.
2008.Online large-margin training of syntactic and struc-tural translation features.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 224?233.
Association for Compu-tational Linguistics.Thomas H Cormen, Charles E Leiserson, Ronald LRivest, Clifford Stein, et al 2001.
Introduction toalgorithms.
MIT press Cambridge, 2nd edition.Mark Hopkins and Jonathan May.
2011.
Tuning as rank-ing.
In Proceedings of the 2011 Conference on Empir-ical Methods in Natural Language Processing, pages1352?1362.
Association for Computational Linguis-tics.Thorsten Joachims.
2002.
Optimizing search enginesusing clickthrough data.
In Proceedings of the eighthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 133?142.ACM.Ching-Pei Lee and Chih-Jen Lin.
2014.
Large-scale lin-ear RankSVM.
Neural computation, 26(4):781?817.Chin-Yew Lin and Franz Josef Och.
2004.
ORANGE: amethod for evaluating automatic evaluation metrics formachine translation.
In Proceedings of Coling 2004,pages 501?507, Geneva, Switzerland, Aug 23?Aug27.
COLING.Preslav Nakov, Francisco Guzm?an, and Stephan Vogel.2013.
A tale about PRO and monsters.
In Proceed-ings of the 51st Annual Meeting of the Association forComputational Linguistics (Volume 2: Short Papers),pages 12?17, Sofia, Bulgaria, August.
Association forComputational Linguistics.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofthe 41st Annual Meeting on Association for Computa-tional Linguistics-Volume 1, pages 160?167.
Associa-tion for Computational Linguistics.K.
Papineni, S. Roukos, T. Ward, and W. J Zhu.
2002.BLEU: a method for automatic evaluation of machinetranslation.
In Proceedings of the 40th annual meet-ing on association for computational linguistics, pages311?318.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statistical trans-lation.
In Proceedings of the 16th conference on Com-putational linguistics-Volume 2, pages 836?841.
Asso-ciation for Computational Linguistics.1023
