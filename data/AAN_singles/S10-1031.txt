Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 150?153,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsDFKI KeyWE: Ranking keyphrases extracted from scientific articlesKathrin EichlerDFKI - Language TechnologyBerlin, Germanykathrin.eichler@dfki.deG?unter NeumannDFKI - Language TechnologySaarbr?ucken, Germanyneumann@dfki.deAbstractA central issue for making the contentof a scientific document quickly acces-sible to a potential reader is the extrac-tion of keyphrases, which capture the maintopic of the document.
Keyphrases canbe extracted automatically by generating alist of keyphrase candidates, ranking thesecandidates, and selecting the top-rankedcandidates as keyphrases.
We present theKeyWE system, which uses an adaptednominal group chunker for candidate ex-traction and a supervised ranking algo-rithm based on support vector machinesfor ranking the extracted candidates.
Thesystem was evaluated on data providedfor the SemEval 2010 Shared Task onKeyphrase Extraction.1 IntroductionKeyphrases capture the main topic of the docu-ment in which they appear and can be useful formaking the content of a document quickly ac-cessible to a potential reader.
They can be pre-sented to the reader directly, in order to providea short overview of the document, but can alsobe processed further, e.g.
for text summarization,document clustering, question-answering or rela-tion extraction.
The task of extracting keyphrasesautomatically can be performed by generating alist of keyphrase candidates, ranking these can-didates, and selecting the top-ranked candidatesas keyphrases.
In the KeyWE system, candidatesare generated based on an adapted nominal groupchunker described in section 3 and ranked usingthe SVMrankalgorithm (Joachims, 2006), as de-scribed in section 4.
The used features are spec-ified in section 5.
In section 6, we present theresults achieved on the test data provided for theSemEval 2010 Shared Task on Keyphrase Extrac-tion1by selecting as keyphrases the top 5, 10, and15 top-ranked candidates, respectively.2 Related workThe task of keyphrase extraction came up in the1990s and was first treated as a supervised learn-ing problem in the GenEx system (Turney, 1999).Since then, the task has evolved and various newapproaches have been proposed.
The task is usu-ally performed in two steps: 1. candidate ex-traction (or generation) and 2. keyphrase selec-tion.
The most common approach towards can-didate extraction is to generate all n-grams up toa particular length and filter them using stopwordlists.
Lately, more sophisticated candidate extrac-tion methods, usually based on additional linguis-tic information (e.g.
POS tags), have been pro-posed and shown to produce better results (e.g.Hulth (2004)).
Liu et al (2009) restrict their can-didate list to verb, noun and adjective words.
Kimand Kan (2009) generate regular expression rulesto extract simplex nouns and nominal phrases.
Asthe majority of technical terms is in nominal grouppositions2, we assume that the same holds true forkeyphrases and apply an adapted nominal groupchunker to extract keyphrase candidates.The selection process is usually based on somesupervised learning algorithm, e.g.
Naive Bayes(Frank et al, 1999), genetic algorithms (Turney,1999), neural networks (Wang et al, 2005) or de-cision trees (Medelyan et al, 2009).
Unsuper-vised approaches have also been proposed, e.g.
byMihalcea and Tarau (2004) and Liu et al (2009).However, as for the shared task, annotated train-ing data was available, we opted for an approachbased on supervised learning.1http://semeval2.fbk.eu/semeval2.php?location=tasks#T62Experiments on 100 manually annotated scientific ab-stracts from the biology domain showed that 94% of technicalterms are in nominal group position (Eichler et al, 2009).1503 Candidate extractionRather than extracting candidates from the full textof the article, we restrict our search for candidatesto the first 2000 characters starting with the ab-stract3.
We also extract title and general termsfor use in the feature construction process.
Fromthe reduced input text, we extract keyphrase candi-dates based on the output of a nominal group chun-ker.This approach is inspired by findings from cog-nitive linguistics.
Talmy (2000) divides the con-cepts expressed in language into two subsystems:the grammatical subsystem and the lexical sub-system.
Concepts associated with the grammati-cal subsystem provide a structuring function andare expressed using so-called closed-class forms(function words, such as conjunctions, determin-ers, pronouns, and prepositions, but also suf-fixes such as plural markers and tense markers).Closed-class elements (CCEs) provide a scaffold-ing, across which concepts associated with the lex-ical subsystem (i.e.
nouns, verbs, adjectives andadverbs) can be draped (Evans and Pourcel, 2009).Spurk (2006) developed a nominal group (NG)chunker that makes use of this grammatical sub-system.
Using a finite list of CCEs and learnedword class models for identifying verbs and ad-verbs, a small set of linguistically motivated ex-traction patterns is stated to extract NGs.
The rulesare based on the following four types of occur-rences of NGs in English: 1. at the sentence be-ginning, 2. within a determiner phrase, 3. follow-ing a preposition and 4. following a verb.
Notbeing trained on a particular corpus, the chunkerworks in a domain-independent way.
In addition,it scales well to large amounts of textual data.In order to use the chunker for keyphrase extrac-tion, we manually analysed annotated keyphrasesin scientific texts, and, based on the outcome of theevaluation, made some adaptations to the chun-ker, which take care of the fact that the boundariesof a keyphrase do not always coincide with theboundaries of a NG.
In particular, we remove de-terminers, split NGs on conjunctions, and processtext within parentheses separately from the maintext.
An evaluation on the provided training datashowed that the adapted chunker extracts 80% ofthe reader-annotated keyphrases found in the text.3This usually covers the introductory part of the articleand is assumed to contain most of the keyphrases.
Partialsentences at the end of this input are cut off.4 Candidate rankingThe problem of ranking keyphrase candidates canbe formalized as follows: For a document d anda collection of n keyword candidates C = c1...cn,the goal is to compute a ranking r that ordersthe candidates in C according to their degree ofkeyphraseness in d.The problem can be transformed into an ordinalregression problem.
In ordinal regression, the la-bel assigned to an example indicates a rank (ratherthan a nominal class, as in classification prob-lems).
The ranking algorithm we use is SVMrank,developed by Joachims (2006).
This algorithmlearns a linear ranking function and has shown tooutperform classification algorithms in keyphraseextraction (Jiang et al, 2009).The target (i.e.
rank) value defines the order ofthe examples (i.e.
keyphrase candidates).
Dur-ing training, the target values are used to gener-ate pairwise preference constraints.
A preferenceconstraint is included for all pairs of examples inthe training file, for which the target value differs.Two examples are considered for a pairwise pref-erence constraint only if they appear within thesame document.The model that is learned from the training datais then used to make predictions on the test ex-amples.
For each line in the test data, the modelpredicts a ranking score, from which the rankingof the test examples can be recovered via sorting.For ranking the candidates, they are transformedinto vectors based on the features described in sec-tion 5.During training, the set of candidates is made upof the annotated reader and author keywords aswell as all NG chunks extracted from the text.These candidates are mapped to three differentranking values: All annotated keywords are givena ranking value of 2; all extracted NG chunksthat were annotated somewhere else in the train-ing data are given a ranking value of 1; all otherNG chunks are assigned a ranking value of 0.Giving a special ranking value to chunks an-notated somewhere else in the corpus is a wayof exploiting domain-specific information aboutkeyphrases.
Even though not annotated in this par-ticular document, a candidate that has been anno-tated in some other document of the domain, ismore likely to be a keyphrase than a candidate thathas never been annotated before (cf.
Frank et al(1999)).1515 FeaturesWe used two types of features: term-specificfeatures and document-specific features.
Term-specific features cover properties of the candidateterm itself (e.g.
term length).
Document-specificfeatures relate properties of the candidate to thetext, in which it appears (e.g.
frequency of theterm in the document).
Our term-specific featuresconcern the following properties:?
Term length refers to the length of a can-didate in number of tokens.
We expressthis property in terms of five boolean fea-tures: has1token, has2tokens, has3tokens,has4tokens, has5orMoreTokens.
The advan-tage over expressing term length as a nu-meric value is that using binary features, weallow the algorithm to learn that candidatesof medium lengths are more likely to bekeyphrases than very short or very long can-didates.?
The MSN score of a candidate refers to thenumber of results retrieved when queryingthe candidate string using the MSN searchengine4.
The usefulness of MSN scores fortechnical term extraction has been shown byEichler et al (2009).
We normalize the MSNscores based on the number of digits of thescore and store the normalized value in thefeature normalizedMsn.
We also use a binaryfeature isZeroMsn expressing whether query-ing the candidate returns no results at all.?
Special characters can indicate whether acandidate is (un)likely to be a keyphrase.
Weuse two features concerning special charac-ters: containsDigit and containsHyphen.?
Wikipedia has shown to be a valuable sourcefor extracting keywords (Medelyan et al,2009).
We use a feature isWikipediaTerm,expressing whether the term candidate corre-sponds to an entry in Wikipedia.In addition, we use the following document-specific features:?
TFIDF, a commonly used feature introducedby Salton and McGill (1983), relates the fre-quency of a candidate in a document to itsfrequency in other documents of the corpus.4http://de.msn.com/?
Term position relates the position of the firstappearance of the candidate in the documentto the length of the document.
In addition,our feature appearsInTitle covers the fact thatcandidates appearing in the document titleare very likely to be keyphrases.?
Average token count measures the averageoccurrence of the individual (lemmatized) to-kens of the term in the document.
Ourassumption is that candidates with a highaverage token count are more likely to bekeyphrases.?
Point-wise mutual information (PMI,Church and Hanks (1989)) is used to capturethe semantic relatedness of the candidate tothe topic of the document.
A similar featureis introduced by Turney (2003), who, ina first pass, ranks the candidates based ona base feature set, and then reranks themby calculating the statistical associationbetween the given candidate and the top Kcandidates from the first pass.
To avoid thetwo-pass method, rather than calculatinginter-candidate association, we calculate theassociation of each candidate to the termsspecified in the General Terms section ofthe paper.
Like Turney, we calculate PMIbased on web search results (in our case,using MSN).
The feature maxPmi capturesthe maximum PMI score achieved with thelemmatized candidate and any of the generalterms.6 Results and critical evaluationTable 1 presents the results achieved by applyingthe KeyWE system on the data set of scientificarticles provided by the organizers of the sharedtask along with two sets of manually assignedkeyphrases for each article (reader-assigned andauthor-assigned keyphrases).
Our model wastrained on the trial and training data (144 articles)and evaluated on the test data set (100 articles).The evaluation is based on stemmed keyphrases,where stemming is performed using the Porterstemmer (Porter, 1980).Since SVMranklearns a linear function, one cananalyze the individual features by studying thelearned weights.
Roughly speaking, a high pos-itive (negative) weight indicates that candidateswith this feature should be higher (lower) in the152Top Set P R F5reader 24.40% 10.13% 14.32%combined 29.20% 9.96% 14.85%10reader 19.80% 16.45% 17.97%combined 23.30% 15.89% 18.89%15reader 17.40% 21.68% 19.31%combined 20.27% 20.74% 20.50%Table 1: Results on the two keyword sets:reader (reader-assigned keyphrases) and combined(reader- and author-assigned keyphrases)ranking.
In our learned model, the four most im-portant features (i.e.
those with the highest ab-solute weight) were containsDigit (-1.17), isZe-roMsn (-1.12), normalizedMsn (-1.00), and avgTo-kenCount (+0.97).
This result confirms that webfrequencies can be used as a valuable source forranking keyphrases.
It also validates our assump-tion that a high average token count indicates agood keyphrase candidate.
The maxPMI featureturned out to be of minor importance (-0.16).
Thismay be due to the fact that we used the terms fromthe General Terms section of the paper to calculatethe association scores, which may be too generalfor this purpose.AcknowledgmentsWe thank Angela Schneider for her adaptations tothe chunker and helpful evaluations.
The researchproject DiLiA is co-funded by the European Re-gional Development Fund (ERDF) in the contextof Investitionsbank Berlins ProFIT program undergrant number 10140159.
We gratefully acknowl-edge this support.ReferencesK.
W. Church and P. Hanks.
1989.
Word associa-tion norms, mutual information and lexicography.
InProceedings of the 27th Annual Conference of theAssociation of Computational Linguistics.K.
Eichler, H. Hemsen, and G. Neumann.
2009.
Un-supervised and domain-independent extraction oftechnical terms from scientifc articles in digital li-braries.
In Proceedings of the LWA Information Re-trieval Workshop, TU Darmstadt, Germany.V.
Evans and S. Pourcel.
2009.
New Directions in Cog-nitive Linguistics.
John Benjamins Publishing Com-pany.E.
Frank, G. W. Paynter, I. H. Witten, C. Gutwin,and C. G. Nevill-Manning.
1999.
Domain-specifickeyphrase extraction.
In Proceedings of the 16thInternational Joint Conference on Artificial Intelli-gence.A.
Hulth.
2004.
Combining Machine Learning andNatural Language Processing for Automatic Key-word Extraction.
Ph.D. thesis, Department of Com-puter and Systems Sciences, Stockholm University.X.
Jiang, Y. Hu, and H. Li.
2009.
A ranking ap-proach to keyphrase extraction.
In Proceedings ofthe 32nd Annual International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval.T.
Joachims.
2006.
Training linear svms in linear time.In Proceedings of the ACM Conference on Knowl-edge Discovery and Data Mining.S.
N. Kim and M. Y. Kan. 2009.
Re-examining auto-matic keyphrase extraction approaches in scientificarticles.
In Proceedings of the ACL/IJCNLP Multi-word Expressions Workshop.F.
Liu, D. Pennell, F. Liu, and Y. Liu.
2009.
Unsu-pervised approaches for automatic keyword extrac-tion using meeting transcripts.
In Proceedings of theConference of the NAACL, HLT.O.
Medelyan, E. Frank, and I.H.
Witten.
2009.Human-competitive tagging using automatickeyphrase extraction.
In Proceedings of the Interna-tional Conference of Empirical Methods in NaturalLanguage Processing (EMNLP).R.
Mihalcea and P. Tarau.
2004.
TextRank: Bringingorder into texts.
In Proceedings of the EMNLP.M.
F. Porter.
1980.
An algorithm for suffix stripping.Program, 14(3):130?137.G.
Salton and M. J. McGill.
1983.
Introduction tomodern information retrieval.
McGraw-Hill.C.
Spurk.
2006.
Ein minimal ?uberwachtes Verfahrenzur Erkennung generischer Eigennamen in freienTexten.
Diplomarbeit, Saarland University, Ger-many.L.
Talmy.
2000.
Towards a cognitive semantics.
MITPress, Cambridge, MA.P.
D. Turney.
1999.
Learning to extract keyphrasesfrom text.
Technical report, National ResearchCouncil, Institute for Information Technology.P.
D. Turney.
2003.
Coherent keyphrase extraction viaweb mining.
In Proceedings of the Eighteenth Inter-national Joint Conference on Artificial Intelligence.J.-B.
Wang, H. Peng, and J.-S. Hu.
2005.
Automatickeyphrases extraction from document using back-propagation.
In Proceedings of 2005 internationalconference on Machine Learning and Cybernetics.153
