MODELING EXTEMPORANEOUS ELABORATIONMarie A. BienkowskiBell Communications Research445 South Street, MRE 2P358Morristown, N J  07960-1961, USAABSTRACTIntelligent problem solving systems must be able to ex-press their results in a coherent and flexible manner.
Oneway this can be done is by eztemporaneous elaboration, themethod of language production that underlies more skilledtasks such as explanation.
This paper outlines a computa-tional model for extemporaneous elaboration that is imple-mented in a computer model called Extemper, shows ex-amples of its operation, and compares it with other models oflanguage production.
Extemper contains the four com-ponents minimally required for elaboration: 1) an efficientmethod for linearizing a knowledge structure, 2) atranslation/selection mechanism for producing a conceptualtextbase from the knowledge structure, 3) local coherenceoperators which provide local connections between textbaseelements, and 4) a conceptual generator to translate thecoherent textbase into English.IntroductionAn intelligent problem solving system may be required toparticipate in a purposive discourse with a user.
Purposivediscourse is dialogue where a welbdefined goal is pursued in astereotyped and efficient - but not inflexible - way.
Manycommon types of purposive discourse that could occur withan intelligent system, such as tutoring, explaining, and advis-ing, require lengthy elaborations.
Automated reasoners orproblem solvers, in particular, are often required to explain,describe, or justify, that is, to elaborate on, their solutions.The process of producing unrehearsed and unedited exposi-tions during purposive discourse is called ezternporaneous orspontaneous elaboration.This paper describes a computational model for extem-poraneous elaboration implemented in a computer modelcalled Extemper.
The model consists of four components.The first is a linearizer which provides the overall structureof the elaboration by either a) following a trace of theprocessing of a problem solver (rehashing) or, b) directing arehearsal of the knowledge used by the system (i.e., instan-tinting the knowledge structures normally used for problemsolving for use in language production).
The second com-ponent is a set of selectors which determine what will be ex-pressed based on considering the type of discourse, the dis-course goals of the listener, and the relevance of domain-specific items.The linearizer and selectors produce the overall concep-tual form of the elaboration.
It is given a coherent linguisticform by the combination of local coherence operators, whichexamine conceptual forms to track focus, add connectivewords, etc., and a sentence generator (Cullingford, 1986)which renders it in English.
Extemper's core model ofelaboration, then, consists of four components: a linearizer,selectors, local coherence operators, and a sentence gener-ator.
These constitute a minimal cognitive architecture forelaboration: minimal because more may be needed for otherelaboration types (e.g., a component to build and maintain alistener model for tutoring), and cognitive because com-ponents like these have been proposed by psychologists formodels of language production (e.g., vanDijk and Kintsch,1083).In the next section, I discuss how Extemper's componentscooperate to produce an elaboration.
In Section 3, I describethe type of domain that Extemper's minimal architecture issufficient for: descriptions of the operations of a problem sol-ver.
That section also distinguishes rehearsal from rehashing;these are different ways of obtaining the knowledge to beelaborated.
Before concluding, I compare Extemper withother systems designed for text and discourse production.Extemper:  A Computat ional  ModelExtemper implements a four component, minimal cog-nitive architecture for elaboration to produce descriptions ofthe behavior of problem solving systems.
The problem solv-ing systems it interacts with are a route'planner and anacademic counseling system.
1 Extemper's linearizer, incooperation with one of these problem solvers, provides asuccession of pieces of the knowledge source being elaboratedto translators.
These meaning-preserving translatorsproduce conceptual forms which are linked into a conceptualknowledge base and then processed by the selectors.
Theoutput of both the translators and selectors is representedusing a version of the Eclectic Representations forKnowledge Structures (ERKS) frame representation systemdeveloped by Cullingford (1986).The concept selection cycle builds a single ERKS meaningstructure until meaning structure (ms) functions determinethat a newly selected concept does not fit with the currentone.
The ms functions use a heuristic evaluation of the con-nectedness of propositions to determine when to generate asentence.
They rely on the semantic classes of concepts andthe goal structure represented in the conceptual knowledgebase.
For example, concepts representing simple actionstaken by the route planner are considered to be connected,and can be expressed in a single sentence if they occur con-secutively.
Actions that contribute directly to the same goalare also considered to be connected.
Note that there mayalso be syntactic constraints on what may fit into one sen-tence (e.g., Derr and McKeown, 1984, describe how con-siderations of focus may force complex sentences to begenerated) but those constraints would not apply at thislevel, since the syntactic form the meaning structure willtake is not yet known.After concept selection, the local coherence operatorsmediate between the conceptual form of the elaboration andits syntactic form by annotating meaning structures with in-structions for the sentence generator.
These instructions in-crease the connectedness or local coherence of the sentencesto be generated; given and new information, for example, iscomputed at this level.
The annotated meaning structuresare stored in a textbase whose elements are translated intoEnglish by the sentence generator.
The sentence generatoroperates by repeatedly looking up words to span conceptualforms and ordering the words and those concepts that werenot spanned according to predicates stored with the words.Additionally, there are conceptual "sketchifiers" that alter ordelete information to express a concept more succinctly.Two important contributions can be found in this com-putational model for language production (in addition to itsdescription of the minimal components needed for1Extemper and the problem solving systems are imple-mented in Frans Lisp on a Pyramid 90x.191elaboration).
One contribution is illustrated by Extemper'suse of the knowledge embodied in an intelligent system forguiding an elaboration.
Extemper follows the principle thatif a natural ordering exists for a body of knowledge, it shouldbe used to guide extemporaneous elaboration.
A natural or-dering is one that corresponds to some common sense use ofthe knowledge, such as a problem solver might exhibit.Another contribution of this elaboration model is that itdemonstrates that a language production mechanism can bedesigned to operate primarily on conceptual, language-freeforms.
Manipulations are performed on the conceptual formof an elaboration, not the linguistic form.
This is possible inExtemper because information from the problem solver isconverted into conceptual form by the meaning-preservingtranslators, and the selectors, local coherence operators, andsentence generator operate only on these forms.
Use of aconceptual representation throughout the elaboration processmakes possible a blurring of the distinction (traditionallymade in language production systems) between =what tosay = and "how to say it.=Linearizatlon and TranslationWhen a topic is chosen for elaboration, the concepts to becommunicated must be selected in an appropriate order.Extemper's linearizer is responsible for presenting pieces of aknowledge structure for selection in an order that is derivedin some fashion from information inherent in the structureitself.
To gain access to this ordering information, thelinearizer must cooperate closely with the intelligent systemthat is producing or manipulating the knowledge.
I discussthis further in Section 3 while describing the problem solvingsystems whose behavior Extemper describes.Orderings can be achieved in three general ways: exploit-ing a given ordering, imposing an ordering, or deriving an or-dering.
In exploiting a given ordering, the connections al-ready present in the knowledge structure are followed to findthe next piece of information to say.
An ordering must beimposed if the knowledge structure contains no ordering in-formation or if a different ordering is desired.
An imposedordering is usually something that is known to be an effectivemeans of ordering (e.g., describing visual scenes by salience).Deriving an ordering must be done in cases where the under-lying knowledge does not contain ordering information (andsuch information would be expensive to compute) and no im-posed ordering exists that can achieve the goals of theelaboration.The strategy Extemper uses is to exploit the commonsense ordering inherent in a knowledge structure.
The prin-ciple that knowledge should be elaborated in a mannersimilar to the way it is used is based on the observation thatcomplex transformations of knowledge are not found innaturally occuring elaborations, presumably because they aretoo time consuming to produce.
However, even though Ex-temper uses a common sense ordering as the primary order-ing method, it can be overcome by other factors such aspragmatic goals and listener input (although this has notbeen done for any of the implemented examples).
Also, thedesign of Extemper's lineariser does not preclude the use ofimposed structures for elaboration.
In such cases, thelinearizer follows an external structure instead of the one in-ternal to the knowledge structure used by the reasoner.
Thisflexibility is possible because Extemper's linearizer is imple-mented as a set of agenda-based tasks.
Because these tasksare preemptable, so is the operation of the linearizer, in keep-ing with Extemper's eventual use in a discourse processingsystem.Exploiting a given ordering does not guarantee a com-plete ordering.
A planner, for example, may arbitrarilychoose which parts of a plan should be pursued first if theparts independently achieve a goal.
The linearizer must, inthese cases, decide what parts to express first.
This is doneusing rules that choose among several possible next things tosay.
For example, in the route planning domain, a goal maybe shown to be true simply by reasoning about it, for ex-ample, =I am on Olden Street because I am in E-Quad andE-Quad is on Olden Street."
and "I assumed you were atGreen Hall because you wanted me to meet you there.
"These two reasoning chains may together contribute to thesatisfaction of a goal.
Neither one takes precedence overanother, so the linearizer uses a rule which prefers the shorterof the two (the second one).
Another rule, given several sub-goals for a goal, will choose the ones that are supported byreasoning chains over ones that are supported by furtherplanning.
Supplementing the ordering produced by theproblem solver with (common sense) rules like these gives acomplete ordering of concepts for the selectors.SelectionRelevance is an important constraint on discourse produc-tion.
Constraints on relevance may be imposed by the over-all type of discourse, pragmatic goals, and the characteristicsof the domain knowledge.
Determining if a given piece ofknowledge is relevant is considerably more difficult thanselecting a correct ordering for a knowledge structure.
Tech-niques that have been explored include annotations onperceptual-level representations of scenes to indicate visualsalience (Conklin, et.ai., 1983), and databases containingmultiple indexes keyed on user point of view (McKeown,et.ai., 1985).
However, these techniques involve supplement-ing stat ic  knowledge bases and do not readily apply to select-ing pertinent information from traces of a problem solver(which Extemper needs for both rehearsal and rehashing).Instead, Extemper uses selectors that rely on differentrelevance factors to assist in determining relevance Uon thefly.
"The selectors that Extemper uses are rules constrained bythe overall discourse goal of the listener.
This enables Ex-temper to produce elaborations that are tailored to a par-ticular goal (this is the only global relevance factor used inthe current implementation).
The operation of the selectorsis based on the ERKS method for representing meaning,namely that meaning representations consist of a kernel(main or core concept) and nuances (ancillary concepts thatdistinguish similar meaning structures).
For example, "Idrove to Green Hall."
is distinguished from =I traveled toGreen Hall."
by the nuance that, in the second case, thevehicle of transportation was a car.
Decomposing meaning inthis way allows meaning structures to be built piecewise bythe selectors.Selectors can only perform actions that influence the con-ceptual content of ERKS meaning structures.
They can bedivided into three categories: 1) those that select infor-mation for inclusion in a meaning structure, 2) those thatmodify the selected information, and 3) those that add ancil-lary information to meaning structures.
For example, aselector for the route planner might choose to include a con-cept representing a goal restatement, e.g., =I determined thatI could meet you at Green Hall if you and I were there.
"Another selector (depending upon the overall discourse goalthe listener is presumed to have) might choose to modify theconcept to omit mention of how this conclusion was arrivedat (i.e., omit =I determined that=.)
A selector that adds an-cillary information might produce introductory sentences likethe following from the academic counseling domain: "Thereare four major requirements you must meet for Liberal Artsand Sciences.
=The selectors add concepts to one meaning structure untilthe next concept to be added no longer fits with the ones al-ready selected.
In this way, complex sentences are built fromseparate concepts.
The separate concepts are connected ac-cording to the relationships found in the knowledge structure(e.g., consecutive actions are joined with a temporalconnective).
Prior to sentence generation, however, more in-192formation must be added to the ERKS meaning structure.Local Coherence OperatorsThe local coherence operators annotate ERKS meaningstructures to create ties between successive parts of theelaboration.
Based on examination of the conceptual formsin the current and previous meaning structures, they makedecisions that may influence the syntactic form of the sen-tence.
The most common one is the computation of givenand new information, which affects focus.
For example, inthe route planning domain, if a sentence mentions walking toa place, that (given) location may be the focus for the nextsentence.I walked to Green Ha l l .At Green Hall, I checked my mail.Another common operation is adding connective words, e.g.,using =Ok" to signal the end of a description of how a goalmay be achieved in the academic counseling domain.Local coherence operators are also used to provide certaindefault values for the meaning structure by fillingannotation nuances.
The most useful of these nuances areshorthand forms for full concepts that express specificationsthat are extrinsic to the meaning of the kernel concept: ab-solute time, relative time, and modals.
These nuances shouldbe filled by the problem solver, but are not because theproblem solvers used do not reason about time or modal in-formation.
The English sentence generator needs this infor-mation, so it has to be added in this ad hoc manner.The result of the first three parts, linearization, selection,and local coherence operations, is a set of generation instruc-tions represented as a conceptual form (consisting of a kerneland major nuance concepts) plus annotations on it.
ThisERKS meaning representation is entered into a teztbase, arepresentation of the contents of the discourse.
After beingadded to the textbase, the sentence generator producesEnglish text from it in the manner described in Section 1.Further details on the sentence generator can be found inCullingford (1986).The Prob lem Solving DomainThe emphasis in Extemper's design has been on modelingelaborations of the knowledge and behavior of goal-directedproblem solving systems.
These problem solvers are typifiedby systems uch as route planners or spatial reasoners.
Theyare of interest because they solve commonplace problems,and their solutions can be described by commonplace (henceextemporaneous) elaborations.Two basic categories of elaborations are needed forproblem solvers, and Extemper produces both kinds.
Oneprovides a reAasAing of something the problem solver hasdone from a trace of its execution.
Rehashed elaborationssay what was done to solve the problem, why it was done,and what the results were.
The other type of elaborationuses the problem solver's knowledge base directly toelaborate on reAear6ed knowledge.
The elaborator controls arehearsal (instead of following an execution trace) by alter-nately rehearsing knowledge and elaborating on it.
(Here,rehearsing means fleshing out knowledge structures, e.g., byfilling in the value of variables.)
Rehearsal is useful forproviding information without the overhead of running theproblem solver.Extemper serves as a first step for investigations intomethods for producing a variety of elaborations.
Theproblem solving elaborations it produces are descriptions ofprocesses or actions based on the domains of route planning(rehashed elaborations) and academic counseling (rehearsedelaborations).
These two domains use very different types ofknowledge, from rigid and script-like (the curriculumknowledge in the academic counseling domain) to a mixtureof goals, rules and plans (the route planning knowledge).Extemper's ability to interpret these different types ofdomain knowledge demonstrates it  flexibility.Table 1 shows a sample elaboration produced by Ex-temper.
This description of the route planner's behavior isintended for an operator or programmer of the route planner,and is highly detailed.
It gives the justifications underlyingthe route planner's actions and the "mental states" (e.g.,determined, a~6umed) of the planner.
Extemper alsoproduces two less verbose elaborations from the sameknowledge structure, based on different views of the dis-course goal of the listener.
One of them is shown in Table 2(the other is simply the last sentence in the elaborationshown in Table 2).
In the first, the listener is assumed to beunfamiliar with the area being described, in the second, ahigh degree of familiarity is assumed.
(The output lacksfluency because the focus of this work was not on sentencegeneration.
Some improvement in the output could begained from more work on sentence generation andpronominalization.
)I determined that I cou ld  meet you at GreenHal lif you and I were there.I assumed you were at GreenHal l  because youwanted me to meet you there.I knew I could be at .GreenHal l  if I was onthe street that it was on, faced it, andwalked to it.GreenHal l  was on Washington so I wanted tobe on Washington.I knew I could be on Washington if I was onthe street that intersects wlth Washingtonand was near the street that I was on,faced Washlngton?
and walked to theintersect ion of Washington and the streetthat intersects with Washington and wasnear the street that I was on.Wi l l iam was the street that intersectswith Washlngton so I wanted to be onWi l l iam and to walk to the intersect ion ofNashington and ?1111am.I assumed I was on Wi l l iam because I was atEQuad and EQuad was on Wil l iam.I assumed I faced WashlnEton because WashlnEtonwas or iented west of EQuad, I was at EQuad,and I faced west.I walked to the intersect lon of WashlnEton andWll l lam.I knew I could face GreenHal l  if I turned inthe direct ion that i turn in to be or ientedtowards GreenHa l l .I turned r ight and walked to GreenHall.Table 1: A Verbose Elaboration.. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.193I could meet you at Green Hall i f  you and Iwere there.Washington was the street that GreenHal l  was onso I wanted to be on Washington.Wi l l iam was the  s t reet  that i n te rsects  w i thWashington so I wanted to  be on Wi l l i am and towalk  to  the  in tersect ion  o f  Wash ington andWilliam.I walked to the intersection of Washington andWill iam.
turned right, and walked to GreenHall .Table 2: A Less  Verbose  E laborat lon .Re la ted  WorkThe focus of much current research on language produc-tion is on text and discourse planning.
Even though Ex-temper models an extemporaneous process, it must generatelengthy text like text production systems, and be as flexibleas discourse planning models in interacting with a user.HELPCON (a precursor of Extemper) used the conceptualgenerator CGEN to generate instructions for s computer-aided design system (Cullingford, 1982; Bienkowski, 1983).I- IELPCON extended CGEN's  notion of sketchification at theconcept level to the knowledge structure (KS) level by usingKS  sketchifiers corresponding to different links in "j'eaturescript8 ?
that described the CAD tool.
HELPCON wouldtraverse a feature script, apply the KS  sketchifiers to it, andsend the remaining concepts to CGEN.
Extemper's use ofexploited structure is similar to this.McKeown's TEXT  system (1985) uses =discoursestrategies = to link communicative purposes (e.g., derme,compare) with the appropriate set of rhetorical techniques(e.g., identify, contrast) for realizing them.
The strategiesare represented as recursive schemata which, along with theimmediate focus of the discourse, impose a partiM orderingon the techniques in a given strategy.
Schemata are hard tofind for some knowledge structures so a more knowledge-driven approach, such as Extemper uses, is needed in somecases.Mann and Moore's (1081) system, KDS, used a fragment(break input representation i to proposition-sised pieces) andcompose (combine the resulting propositions) method forgenerating text from a semantic net representation.
The ag-gregator that KDS uses for combining wastes effort tryinguseless combinations, a method which could cause problemsfor large texts.
In similar work, Vaughan (1986) hasproposed to use a plan and critique cycle to produce text.For modeling extemporaneous language production, however,critiquing is too time~consuming, and more reliable planningmechanisms are needed.Discourse planning systems treat language as the result ofexecution of speech acts that are designed to affect another'sbeliefs or knowledge.
These speech acts are planned bymodeling their effects on a model of the other's beliefs andknowledge.
Appelt (1082), for example, views languageproduction as one of several modaiities for a planner of ac-tions.
His planner, KAMP,  explicitly manipulates assertionsinvolving intensional concepts such as believe and know.
II-locutionary acts such as "inform = are axiom=tired to capturethe intentionality behind them; this enables KAMP to reasonabout how it can realize its intentions.Extemper, like discourse planners, integrates the generalknowledge an intelligent system has with its language be-havior.
Discourse planning methods, however, are not ap-plicable to this work because planning an entire elaborationby reasoning about how to affect another's knowledge wouldoverwhelm any planner.
Also, reasoning about speech actsdoes not solve basic problems in elaboration production, sincethe main relevant speech act for elaboration is only"inform.
= A planner, rather, would have to reason abouthow to achieve ordering, relevance and coherence goals in anelaboration.
Previous planning systems, then, have operatedon a different planning level than is needed for elaboratorslike Zxtemper.The alternative to "planning from scratch = methods is touse schemata or scripts for lengthy discourse production.While these certainly are part of an expert speaker's "bag oftricks, = there are several problems with relying on them ex-clusively for a process like elaboration.
One problem is thatsome elaborations, such as those involving close interactionwith a problem solver that is dynamically computing theknowledge structure to be elaborated, cannot be described byschemata.
Another is that schema may not be needed forsome tasks, if the knowledge structure is sufficiently well-structured.Extemper does not offer a complete solution to either theproblem of making elaboration as flexible as discourse or theproblem of finding efficient ways to generate long texts.However, by making use of the knowledge that a problemsolving system has, Extemper can guide an elaboration, andits reliance on a flexible task execution methodology(described in Bienkowski, 1986) to do this leaves open thepossibility that a method for reasoning about discourse goalscan be added in future revisions.Summary  and Conc lus ionsExtemper's reliance on a reasoning system to guide itsprocessing has been emphasized.
In promoting a tight in-tegration between language processing and reasoning com-ponents, this work is similar to the work on integrating pars-ing and memory described by Schank, 1980.
Interfacing to areasoning system requires a translation capability, however,so Extemper does not (in general) generate directly from thestructures that the reasoner uses.
But it cooperates closelyenough so that, if the actions of the reasoner are regarded asthe =thoughts= of the machine, Extemper serves as a windowon those thoughts.Extemper elies entirely on conceptual forms throughoutits processing cycle.
The exclusive use of conceptual formshas been pushed as far as possible to see if the =semantics"(or pragmatics) of a sentence could justify its =syntax.
=Sometimes this works; other times, nothing in a conceptualform suggests why a particular syntactic form should beneeded.
This results in non-fluent English.
This is not to saythat there is no reason for using the forms that could in-crease fluency, but that the reasons are to be found else-where.
The work of McKeown (1985) on how tracking focuscan affect syntactic structures, is an example of this.Extemper represents a minimal architecture for extem-poraneous elaboration as purposive discourse.
The four com-ponents it uses are necessary for any elaboration system.They are also sufficient for a certain class of knowledgesources.
This work contributes to research on languageproduction by both identifying extemporaneous elaborationas a naturalistic ability that is worthy of study, and byproposing a computational model for it.194REFERENCESD.
E. Appelt.
1985.
~Planning English ReferringExpressions."
Artif icial Intell igence 26: 1-34.M.
A. Bienkowski.
1983.
"Generating Natural LanguageExplanations."
The University of Connecticut, ComputerScience TR-CS83-1.
Storrs, Connecticut.M.
A. Bienkowski.
1986.
"Extemporaneous Elaborations:A Computational Model."
Princeton University CognitiveScience Laboratory CSL Report 1.
Princeton, New Jersey.P.
R. Cohen and R. C. Perrault.
1979.
Elements of aPlan- Based Theory of Speech Acts."
Cognitive Science 3:177-212.E.
J. Conklin, et.
al.
1983.
UAn Empirical Investigationof Visual Salience and its Role in Text Generation.
"Cognition and Brain Theory, 6.R.
E. Cullingford, et.
al.
lg82.
"Automated Explanationsas a Component of a CAD System.
u IEEE Transact ionson Systems, Man and Cybernetics,  SMC-12.R.
E. Cullingford.
1986.
Natural  Language Process-ing: A Knowledge Engineering Approach.
Rowman &Littlefield, Inc., Totowa, New Jersey.Derr, M. A. and McKeown, K. R. 1984. uUsing Focus toGenerate Complex and Simple Sentences."
Proceedings ofthe 22nd Annual  Meet ing of the ACL.
Stanford, Cali-fornia: 319-325.W.
C. Mann and J.
A. Moore.
1981. uComputer Genera-tion of Multiparagraph Efiglish Text."
Amer ican Journalof Computat ional  Linguistics, 7.K.
R. McKeown, et.
al.
1985.
"Tailoring Explanations forthe User."
Proceedings of the Ninth Internat ionalJoint Conference on Artif icial Intelligence: Los An-geles, California: 794-798.K.
R. McKeown.
1985.
Text  Generation.
CambridgeUniversity Press, Cambridge, United Kingdom.R.
C. Schank, M. Lebnwitg, and L. Birnbaum.
1980.
"AnIntegrated Understander," Amer ican Journal  of Com-putat ional  Linguistics, 6.T.
A. vanDijk and W. Klatsch.
1983.
Strategies of Dis-course Comprehension.
Academic Press, New York, NewYork.M.
M. Vaughan and D. D. McDonald.
1986.
"A Model ofRevision in Natural Language Generation," Proceedings ofthe 24th Meeting of the Association for Computa-t ional Linguistics: New York, New York: 90-95.195
