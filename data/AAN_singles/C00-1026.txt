Automat ic  Senmnt ic  Class i f icat ion for Ch inese Unknown Compound NounsKeh-Jiann Chert & Chao-jan ChenInstitute of Information Science, Acadeinia Sinica, TaipeiAbstractTim paper describes a similarity-based model topresent he morphological rules for Chinese com-pound nouns.
This representation model servesfunctions of 1) as the morphological rules of thecompounds, 2) as a mean to evaluate the proper-ness of a compound construction, and 3) as a meanto disambiguate the semantic ambiguity of thenlorphological head of a compound noun.
Anautomatic semantic lassil'ication system for Chine-se unknown compounds i thus implemented basedon the model.
Experiments and on'or analyses arcalso presented.1.
IntroductionThe occurrences of unknown words cause difficul-ties in natural language processing.
Tile word set ofa natural anguage is open-ended.
There is no wayof collecting every words of a language, since newwords will be created for expressing new concepts,new inventions.
Therefore how to identify newwords in a text will bc tile most challenging task fornatural language processing.
It is especially true forChinese.
Each Chinese morpheme (usually a singlecharacter) carries meanings and most are polysc-incus.
New words are easily constructed by com-bining lnorphelnes and their meanings are tile se-mantic composition of morpheme components.Of course there are exceptions of semantically non-compositional compounds.
In Chinese text, there isno blank to mark word boundaries and no inlqec-tional markers nor capitalization markers to denotethe syntactic or selnantic types of new words.Hence the unknown word identification for Chinesebecame one of the most difficult and demandingresearch topic.The syntactic and semantic categories ofunknown words in principle can be determined bytheir content and contextual information.
Howevermany difficult problems have to be solved.
First ofall it is not possible to find a uniforln representa-tional schema nd categorization algorithm to han-dle different ypes of unknown words, since eachtype of unknown words has very much differeutmorpho-syntactic structures.
Second, the clues foridentifying different ype of unknown words arealso different.
For instance, identification ofnames of Chinese is very much relied on thesurnames, which is a limited set of characters.The statistical methods are commonly used foridentifying proper names (Chang et al 1994,Sun et al 1994).
The identification of generalcompounds is more relied on the morphemesand tile semantic relations between morphemes.There are co-occurrence restrictions betweenmorphemes of compounds, but their relations areirregular and mostly due to common senseknowledge.
The third difficulty is the problemsof ambiguities, such as structure ambiguities,syntactic alnbiguitics and semantic ambiguities.For instances, usually a morpheme charac-tedword has multiple lneaning and syntacticcategories.
Therefore the ambiguity resolutionbecame one of the major tasks.Compound nouus are ttle most frequentlyoccurred unknown words in Chinese text.According to an inspection on tile Sinica corpus(Chen etc.
1996), 3.51% of lhe word tokens inthe corpus are unknown, i.e.
they are not listedin the CKIP lexicon, which contains about80,000 entries.
Alnong them, about 51% of theword types are compound nouns, 34% arecompound verbs and 15% are proper names.
Inthis paper we locus our attention on theidentification of the compound nouns.
Wepropose a representation model, which will befacilitated to identify, to disambiguate and toevaluate the structure of a compound noun.
Infact this model can be extended to handlecompound verbs also.1.1 General properties of compounds andtheir identification strategyThe semantic ategory and syntactic categoryare closely related.
For coarse-grained analysis,syntactic ategorization and semantic ategori-zation are close related.
For instances, nounsdenote entities; active verbs denote events andstative verbs denote states.
For fine-grainedanalysis, syntactic and semantic lassificationstake difl'erent classification criterion, in ourmodel the coarse-grained analysis is processedfirst.
The syntactic categories of an unknown173word are predicted first and the possible semanticcategories will be identified according to its topranked syntactic categories.
Different syntacticcategories require different representational modelsand different fine-grained semantic lassificationmethods.The presupposition of automatic se-mantic classification for compounds i that themeaning of a compound is the semantic om-position of its morphemic omponents and thehead morpheme determines the major semanticclass of this compound.
There are many poly-syllabic words of which the property of se-mantic composition does not hold, for in-stances the transliteration words, those wordsshould be listed in the lexicon.
Since for themajority of compounds the presupposition hold,the design of our semantic lassification algo-rithm will be based upon this presupposition.Therefore the process of identifying semanticclass of a compound boils down to find and todetermine the semantic lass of its head mor-phen-~e.
However ambiguous morphologicalstructures cause the difficulties in finding headmorpheme.
For instances, the compound in la)has two possible morphological structures, butonly lb) is the right interpretation.1 a) ~2\]..l..'American'b) ~ /~.
'Amcrica' 'people',c) ~ \["~l)\ 'beautiful' 'country-man'Once the morphological head is deterlnined, thesemantic resolution for the head morpheme is thenext difficulty to be solved.
About 51.5% of the200 most productive morphemes are polysemousand according to the Collocation Dictionary ofNoun and Measure Words (CDNM), in averageeach ambiguous morpheme carries 3.5 differentsenses (Huang et al 1997).2.
Representation ModelsCompounds are very productive types of unknownwords.
Nominal and verbal compounds are easilycoined by combiniug two/many words/characters.Since there are more than 5000 commonly usedChinese characters and each with idiosyncraticsyntactic behaviors, it is hm,t to derive a set ofmorphological rules to generate the set ofChinese colnpounds without over-generation runder-generation.
The set of general compoundsis an open-class.
The strategy for automaticidentification will be relied not only on themorpho-syntactic structures but also morpho-semantic relations.
In general, certaininterpretable semantic relationships betweenmorphemic must be held.
However there is noabsolute lneans to judge whether the semanticrelations between morphemic omponents areacceptable, i,e.
the acceptability of such type ofcompounds is not simply 'yes' or 'no'.
Thedegree of properness of a compound shoulddepend on the logical relation betweenmorphemic omponents and their logicalnessshould be judged by cominou sense knowledge.It is ahnost ilnpossible to in\]plement a systemwith common sense knowledge.
Chen & Chen(1998) proposed an example-based measurementto evaluate the properness of a newly coinedcompound instead.
They postulate that for anewly coined compound, if the semantic relationof its morphemic omponents i  similar to theexisting compounds, then it is inore likely thatthis newly coined compound is proper.2.1 Example-based similarity nleasureSupposed that a compound has the structure ofXY where X and Y are morphemes and sup-posed without loss of generality Y is the head.For instance, ~ i<~-  'learn-word-machine' is anoun compound and the head morphemeY is~'machine'  and the modifier X is ~ ' :  'learn-word'.
In fact the morpheme f~{~ has four differ-ent meanings.
They are 'machine', 'airplane','secret' and 'opportunity'.
How do computersjudge which one is the right meaning and how isthe compound construction well-formed or logi-cally lneaningful?
First of all, the exalnples withthe head morpheme ~ are extracted from cor-pora and dictionaries.
The examples are classi-fied according to their meaning as shown in theTable 1.Senses semantic category examples( l )  machine <~> Bo0ll(2) a i rp lane <~{~> Bo223(3) opportunity <{N~> Ca042(4) secret <~> Da011Table 1.
Four senses of tile morpheme ')~' and their respective samples174Tile meaning of ~l-\]i:i':I~,~- is then determined bycomparing the similarity between it and each classof exalllples.
Tile nleauing of the input ul\]kuownword will be assigned with the moaning of tile classwith the most simihu morpho-semantic structureswith this unknown word.
Tile similarity measure isbased on tile following formula.Supl)osed that each class of examples forlllS lhefollowing SOlUalltic relatioll rules.
The rules silowthe possible semantic relations between prel'ix andsuffix Y and their weight in term ol' ihe frequencydistribution of each semantic category of the pro-fixes in tile class.Rules: Semi +Y FreqlSere2 + Y Freq2:Semk + Y Freqk( freqi: tile number of the words of the l'orm Semi +Y)Take sulTix ~- with moaning of 'machine' asoxaulple.
Igor tile nlorphonle I{} 'ulachine', tileextracted COlllpotlllds of the fornl X+~j~-'machine'and tile semantic categories of the n3odifiors al'eshown il1 Table 2 and the n3orpl~ological rule de-rived froill them ix in Table 3.
The scnlai/tic typesalld their hierarchical structure are adopted fro111tile Chilin (Moi el al.
1984).
The similarity ismeasured between the semantic class of tile prefixX o1' tile unknown conlpound and tile prefix se-mantic types shown in the rule.
()no ot' the meas-uroulonts proposed is:SIMILAR (Sere ,Rule)  = {} ; i l , k  lnforl l lati()n-Load(Sem(hSemi) * lq-eqi } / Max-vahleWhere Sere is tile semantic class of X. Max-valueis tile maxinlal vahle o1' {~\] \[nfornlation Load(S~Selni)  * Freqi } for all semantic lasses S. Theiriax-wllue normalizes tile SIMILAR value to0-1.
S(hSemi denotes the least common ances-tor of S and Semi.
For instance, (Hh03(' lHb06)= H. Tile Information-Load(S) of a senmnticclass S ix defined as Entropy(sonlantic sys-tem) - Entropy(S).
Simply speaking it is theanlount of reduced entropy after S is seen.
En-tropy(S) =~\]i=l,k -p(SemilS) * Log P(SemiJs),where {Semi, Sem2 ..... Semk} is lhe set of thebottoln level selnantic lasses contained in S.J r ,  5 % t,n ~,~-(f~) AoI73 llh031 ,(7J~#~(t~) Bo171,~;'.te(7"(,l~) AoI73 I11~032 SII;~(}~)I f083 Ih063I~JTl{(\]~) 11c013 11e032 ll~(L, tt~(4~) Ili141 tlj345LI~7':~ @~) I 1c()32 (7 P J'-?!
('~{~)Fa221I~1 ~)j(4~) Eb342 4~Jl~(4~) Iic071'i:\[{'~)2@~) Eb342 /JJ(JC(lJ~) Ih031~1~ ,,,:(~) AoI62 117162 ?,3~(4,~) P>e(>51gg~'l.
;@}) I)k162 1fg191 ~J~!
',lZ({~J~) 1h0425',J{(,).
@{) Be041 ,~':~\[;41@~) 117192.
- -  I l l  I u ".
{ :  ILT-)I':(IN) Ca039 Ca041 ~.~pl) (4~) FhOI2Os~!l\]Ja(t~) 11c122 IJl:\];';::(45~) 1\[c231~t&i I(q~b \]~,12i 4,,i~1;~(.4',2~) Fa212 .hl102Table 2.
The senlanlic categories ol' modifiers oftile COlllpouuds el' X-"f~ ~ math inc"Take lhe word l~'~ i :J': I~ 'learning-word-inachine' as example.
In tile table 3, the resultsshow tile estiinated similarity between tileX-~J,~ Serui freqiHh031Ao 173He032Eb342Ae 162Hgl913I22I1Sem(~.~i!j ":)= Ilg111lnl'orrnation-Load( Hgl I 1 f-I Hh031 )=hlfornlation-Load(H)=2.231lnfornlation-Load( Hgl 11 N I1e032 )=hlformation-Load(Ii)=2.231Inforuultion-l~oad( Itg I 11 I'3 fig 191 )=lnformation-Load(Hg)=5.91?
i= l,k hfformation-Load(Hgl I 1 f-I Semi) * Freqi=2.231"3+2.231"2+5.912"  1 + ......= 104.632Max-Vahlel = Z i hffornlation-Load(Hg031 f-I Semi) * Freqi= 155.164S1MILAP,= (104.632 / 155.164) = 0.6743Table 3.
The derived morphological rule for tile ulorphenle 'machine' and tile simihu'ity measure of ,~.~l~j?
:t~"  aS ;_i I1OUn conlpound which denotes a kind of nlachille.175compound ~-~ and the extracted examples.
Thesimilarity value is also considered as the logicalproperness value of this compound.
In this case is0.67, which can be interpreted as that we have 67%of confidence to say that ~z~ 'learning-word-machine' is a well-formed compound.The above representation model serves many func-tions.
First of all it serves as the morl3hologicalrules of the colnpounds.
Second it serves as a meanto implement the evaluation function.
Third itserves as a mean to disambiguate he semantic am-biguity of the morphological head of a compoundnoun.
For instance, them are four different @.Each denotes 'machine', 'airplane', 'opportunity'and 'secret' and they are considered as four differ-ent morphemes.
The example shows that '~~}~'denotes a machine not other senses, since theevaluation score for matching the rules of '~-'ma-chine' has the highest evaluation score amongtheln.The above discussion shows the basic conceptand the base-line model of the example-basedmodel.
The above similarity measure is calledover-all-similarity measure, since it takes the equalweight on the similarity values of the input com-pound with every member in the class.
Anothersimilarity measum is called maximal-similarity,which is defined as follows.
It takes the maximalvalue of the similarity between input compoundand every member in the class as the output.SlM2(Word,Rule) = Maxi=l,k{ (InformationLoad(Sem~Semi)) / Max-value2 }Both similarity measures are reasonable and havetheir own advantages.
The experiment resultsshowed that the combination of these two measuresachieved the best performance on the weights ofw 1=0.3 and w2=0.7 (Chen & Chen 1998), i.e.
SIM= SIMI * wl + SIM2 * w2, where wl+w2 = 1.
Weadopt his measure in our experiments.It also showed a strong co-relation between thesimilarity scores and the human evaluation scoreson the properness of testing compounds.
The hu-man considemd bad compounds howed also lowsimilarity scores by computers.3.
System Implementation3.1 Knowledge sourcesTo categorize unknown words, the computer sys-tem has to equip with the linguistic and semanticknowledge about words, morphemes, and wordformation rules.
The knowledge is facilitated toidentify words, to categorize their semantic andsyntactic lasses, and to evaluate the properness ofword formation and the confidence level ofcategorization.
In our experiments, the availableknowledge sources include:1) CKIP lexicon: an 80,000 entry Chinese lexi-con with syntactic categories for each entry(CKIP 1993).2) Chilin: a thesaurus of synonym classes, whichcontains about 70,000 words distributed un-der 1428 semantic lasses (Mei 1984).3) Sinica Corpus: a 5 million word balancedChinese corpus with word segmented andpart-of-speech tagged (Chen 1996).4) the Collocation Dictionary of Noun andMeasure Words (CDNM) : The CDNM listscollocating measure words for nouns.
Thenouns in this dictionary are arranged by theirending morpheme, i.e.
head morpheme.
Thereare 1910 noun ending morphemes and 12,352example nouns grouped according to theirdifferent senses.Each knowledge source provides partial data forrepresenting morphological rules, which in-clndes lists of sample compounds, high frequen-cy morphemes and their syntactic and semanticinformation.
Unknown words and their frequen-cies can be extracted from the Sinica corpus.The extracted unknown words produce thetesting data and the morpheme-category asso-ciation-strength which are used in the algorithmfor the syntactic category prediction for un-known words (Chen et al 1997).
The CKIP dic-tionary provides the syntactic categories formorphemes and words.
The Chilin provides thesemantic categories for morpheme and words.The CDNM provides the set of high frequencynoun morphemes and the example compoundsgrouped according to each difference sense.
Thesemantic categories for each sense is extractedfrom the Chilin and disambiguated manually.The sample compounds for each sense-difl'emntiated morpheme xtracted from CDNMform the base samples for the morphologicalrules.
Additional samples are supplemented fromthe Chilin.3.2 Tile algorithm for morphologicalanalysisThe process of morphological analysis for com-pound words is very similar to Chinese wordsegmentation process.
It requires dictionarylook-up for matching nlorphemes and resolutionmethods for the inherent ambiguous egmenta-176tions, such as the exalnples in 1).
However con-ventional word segmentation algorithms cannotapply for the morphological analysis without modi-fication, since the nlorpho-syntactic behavior isdifferent froth syntactic behavior.
Since ihc struc-ture of the Chinese COlllpound nOtlllS is head finaland the most productive morphemes arc monosyl-labic, there is a simple and effective algorithm,which agrees with these facts.
This algorithm seg-ments input compounds flom left to right by thelongest matching criterion (Chcn& Liu 1992).
It isclear that the loft to right longest lllaiching algo-rithm prel'ers shorler head and longer modifierstructtlres.3.3 Senlant ic  categories of morphemesThe semantic categories of morphemes arc lot-lowed from the thesaurus Chilin.
This thesaurus isa lattice structure of concept taxonomy.
Mor-phemes/words may have multiple classification dueto either ambiguous classification or inherent so-illantic mnbiguitios.
For lhe ambiguous scn'lanticcategories o1' a morl)hcmo, lhc lower ranking se-nmntic categories will be eliminated and leave thehigher-ranking scnlantic categories to conlpotcduring the identification process.
For instances, inthe table 2 only the re;tier categories of each exam-ple are shown.
Since the majority of nlorphemcsare unanlbiguous, they will compensate the uncer-tainty caused by die semantically ambiguous roofphemes.
The rank of a semantic category of a mot'-phonic depends on the Occurrillg order o1: lhis lilO1-plionlo in ils synonyln group, since lhc arrangcincntof the Chilin cilirics is by this natural, hi addition,dtlo to limit coverage o1: Chilin, nlally of the ll\]Ol'-phemes arc not listed.
For the unlisted morphemes,we recursivcly apply the currellt algorithm to pre-dict their semantic categories.4.
Semantic Chlssification and AmbiguityResolut ion for  Compound NounsThe demand o1" a semantic hlssification system forCOlllpound nouns was first raised while the task ofselnantic tagging for Chinese corpus was lriod.
TheSin|ca corpus is a 5 in|Ilion-word Chinese corpuswith part-of speech lagging, lit lhis corpus there are47,777 word typos tagged with conllllOn nOl.lllS andOllly 12,536 Of tholll are listed ill the Chilin.
Theycount only 26.23%.
In oilier words the scmandccategories for most of the common nouns arc tin-known.
They will be the target for automatic se-mantic classification.4.1 Derivation of morphological rulesA list of' most productive lriorphoinos arc firstgenerated from the unknown words extractedfl'om the Sinica corpus.
The morphological ruleso1' the sot of the lllOSl productive head mor-phonies {llO derived flonl their examples.
Boththe CI)MN all(\] Chilin provide SOlilO oxanlplcs.So lhr there are 1910 head morphemes for com-pound nouns with examples in the system andincreasing.
They are all monosyllabic mor-phemes.
For the top 200 most productive mor-phenlcs, among them 51.5% are polysemous andin average each has 3.5 different meanings.
\]'tiecoverage of ihe ctlrrollt 1910 illorphonlos isaboul 71% of ihc uilkiiown noun conlpounds ofthe iesling dala.
The rosl 29% tincovorod nounnlorphonlos are cilher polysyllabic i-llorpholiiesor/lie low frequency nlorl~hemes.4.2 Semantic classification algorithmThe unknown compound nouns extracted fromthe Sinica corpus w'cre classified according toIhc morphological representation by the simihtr-ity-bascd algoriltnn.
The problcms of semanticambiguitics and out-of-coverage morphcmcswere two major dilTicultics to be solved duringthe classification stage.
The complete scmanlicclassification algorilhm is as follows:I) For each inpu!
noun compound, apply mor-phological analysis algorilhm lo derive diemorphemic components of the input com-pound.2) I)clcrminc the head nlorphenlc and modifiers.
'flit: dcfaull head illorphclllo is lhc last liior-phonic of a conlpound.3) Got die synlactic and semantic categories ofthe modifiers.
If a modil\]or is also an tin-known word, lhen apply this algorilhm rocur-sively to idendfy its son-ialltic category.4) For lhe head morpholne with the representa-tional rules, apply siinilarity illeastlro for eachpossible sornantic chtss and outptlt the so-manlic class with lhe highest siinilariiy wthic.5) If the head illorphonlo is not covered by tilenlorphological rules, search its semantic lassfrom the Chilin.
If its semantic lass is not listin the Chilin, then no ariswcr can be found, ifit is polysemous, then the top ranked classeswill be the output.In lhc step I, thc algorithm rcsolvcs the possibleambiguities o1' the morphological slrtlcttlrcs ofthe input COlllpound.
In the step 3, the selllanticcategories of the modil'ier arc determined.
Therearc some complications.
The firsl complicationis lhat lhe modifier has nmltiple semantic are-177gories.
In our current process, tile categories oflower ranking order will be eliminated.
The re-maining categories will be processed independently.One of the semantic categories of the modifierpairing with one of the rule of the head morphemewith the category will achieve the maximal simi-larity value.
The step 4 thus achieves the resolutionof both semantic ambiguities of the head and tilemodifier.
However only the category of the head isour target of resolution.
The second complication isthat the modifier is also unknown.
If it is a not list-ed in the Chilin, there is no way of knowing itssemantic categories by tile era'rent available re-sources.
At the step 4, the prediction of semanticcategory of the input compound will depend solelyon the information about its head morpheme.
If thehead morpheme is unambiguous then output thecategory of the head morpheme as the prediction.Otherwise, output he semantic ategory of the toprank sense of the head morpheme.
The step 5 han-dles the cases of exceptions, i.e.
no representationalrule for head morphemes.4.3 Experimental  resultsThe system classifes the set of unknown commonnouns extracted from tile Sinica corpus.
We ran-domly picked two hundred samples from tile outputfor the performance valuation by examining thesemantic classification manually.
The correctionrate for semantic lassil'ication is 84% and 81%for tile frst hundred samples and the secondhundred samples respectively.
We further classi-fy tim errors into different ypes.
The first type iscaused by the selection error while disam-biguating the polysemous head lnorphemes.
Thesecond type is caused by the fact that the mean-ings of some compounds are not semantic om-position of tile meanings of their morphologicalcomponents.
Tile third type errors are caused bythe fact that a few compounds are conjunctivestructures not assumed head-modifier structureby the system.
Tile forth type errors are causedby the head-initial constructions.
Other than tileclassification errors, there exist 10 unidentifiablecolnpounds, 4 and 6 in each set, for their headmorphemes are not listed in tile system nor inthe Chilin.
Among tile 190 identifiable headmorphemes, 142 of them are covered by themorphological rules encoded in the system and80 of theln have multiple semantic categories.Tile semantic categories of remaining 48 headmorphemes were found fiom the Chilin.
If thetype 1 selection errors are all caused by the 80morphemes with multiple semantic categories,then the correction rate of semantic disambigua-tion by our similarity-based measure is (80-15)/80 = 81%.Testing data 1 Testing data 2. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Total : 100error: 12type l(semantic selection error): 8type2(non-compositional): 2type3(conjunction): Itypre4(head-initial): 1unidentified: 4Total: 100error: 13type l(semantic selection error): 7type3(non-compositional): 5type3(con.junction): 0typre4(head-initial): 1unidentified: 6Table 5.
The performance valuations of5.
Further Remarks and ConclusionsIn general if an unknown word was extracted fromcorpora, both of its syntactic and semantic atego-ries are not known.
The syntactic ategories willbe predicted first according to its prefix-categoryand suffix-category associations as mentioned in(Chen et al 1997).
According to the top rankedsyntactic predictions, each respective semanticrepresentational rules or models will be applied toproduce the morpho-semantic plausibility of theunknown word of its respective syntactic atego-rization.
For instance if the predicted syntacticthe semantic lassification algorithmcategories are either a common noun or a verb, thealgorithm present in this paper will be carried outto classify its semantic ategory and produce itsplausibility value for the noun category.
Similarprocess should deal with tile case of verbs andproduce tile plausibility of being a verb.
The finalsyntactic and semantic prediction will be based oiltheir plausibility values and its contextual envi-ronments (Bai et al 1998, Ide 1998).The advantages of tile current representationalmodel are:1) it is declarative.
New examples and new mor-178phemes can be added into the system withoulchanging the processing algorilhm, but 111e per-formance o1' the system might be increased ueto the increlnent of the knowledge.2) The representational model not only providesthe semantic classification of the unknownwords but also gives the wdue of the phmsibil-ity o1' a compound construction.
This valuecould be utilized to resolve the alnbiguousmatching between compeling compound rules.3) The representational model can be extended forpresenting compound verbs.4) It acts as one of the major building block of aself-learning systeln for linguistic and worldknowledge acquisition on the lnternel environ-l l lel l t .Tile classification errors are caused by a) some ofthe testing examples have no semantic omposi-tion property, b) some semantic lassifications aretoo much fine-grained.
There is no clear cut dif-ference between some classes, even Imman judgecannot lnake a right classification, c) there are notenough samples that causes the simihuity-basedmodel does not work on the suffixes with few orno sample data.
The above classification errorscan be resolved by collecting the new words,which are Selnantically nol>compositional, intotile lexicon and by adding new examples for eachnaorphenle.Current Selnantic ategorization system onlyroughly classifies the unknown compound nounsaccording to their semantic heads.
In the futuredeeper analysis on the semantic relations betweenmodifier and head should also be carried otll.6.
Rel'erencesBai, M.H., C.J.
Chert & K..I.
Chert, 1998, "POS-lagging for Chinese Unknown Words byContextual P, ules" Proceedings ofROCLING, pp.47-62.Chang, .1.
S.,S.D.
Chert, S. J. Ker, Y. Chert, & J.Liu,1994 "A Multiple-Corpus Approach toRecognition of Proper Nmnes in ChineseTexts", Computer Processing o/" Chineseand Oriental Languages, Vo\[.
8, No.
1, pp.75-85.Chert, C. J., M. It.
Bai, K. J. Chert, 1997, "Catego-ry Guessing for Chinese Unknown Words.
"Proceedings of the Natural LangttageProcessing Pac(fi'c Rim Symposimn 1997,pp.
35-40.
NLPRS '97 Thailand.Chert, K. J., C.J.
Chert, 1998, "A Corpus-basedStudy on Computational Morphology forMandarin Chinese", in Qlmnlitative andComlmtationa\[ Studies on the Chineselxmgttage Eds by l?,cnjanfin K. Tsou, CityUniv.
of Hong Kong, pp283-306.Chert, l<eh-.liann, Ming-Hong Bai, 1997, "Un-known Wolzl l)etection for Chinese by aCorpus-based Learning Method."
Pro-ceedings of the lOth Research on Comlm-lalional Linguistics International Confer-ence, pp 159-174.Chert, K.J.
& S.II.
Liu, 1992,"Word ktentificationfor Mandarin Chinese Sentences," lbv-ceedings o.f 14th Colili,g, pp.
101 - 107.Chien, Lee-feng, 1999," lWF-tree-based AdaptiveKeyphrase Extraction for Intelligent Chine-se Information Retrieval," InformationProcessing and Management, Vol.
35, pp.501-521.l;ung P., 1998," Extracting Key Terms from Chi-nese and Japanese Texts," Computer Proc-essing of Oriental Languages, Vol.
12, #1,pp 99-122.Huang, C. R. E1 al.,1995,"The lnlroduction ofSinica Corpus," Proceedings of ROCIJNGVIII, pp.
81-89.lhtang, Chu-P, en, Keh-Jiann Chert, and Ching-hsiung Lai, 1997, Mandarin 1)allyClassification l)ictionary, Taipci: Mandarinl)aily Press.Ide, Nancy & Jean Veronis, 1998, " Special Issueon Word Sense l)isambiguation",Computational Linguistics, Vol.
24, # I.Lee, J.C. , Y.S.
Lee and H.H.
Chert, 1994,"Identification of Personal Names inChinese Texts."
Proceedings of 7th ROCComputational Linguistics Conference.Lin, M. Y., T. H. Chiang, & K.Y.
Su, t993," APreliminary Study on Unknown WordProblem in Chinese Word Segmentation"Proceedings of Reeling V1, pp 119-137.Mei, Gia-Chu etc., 1984Iq * - -  4~ ~q ~q g.(Chil in -thesaurus of Chinese words).
Hong Kong,McDonald 1)., 1996, " Internal and ExternalEvidence in the Identification and SemanticCategorization of Proper Names", inCorpus Processing Jot Lexical Acquisition,J.
Pustejovsky and B. Boguraev Eds, MITPress 1996.Sun, M. S., C.N.
Huang, H.Y.
Gao, & Jie Fang,1994, "Identifying Chinese Names in Unre-stricted Texts", Communication of COLIPS,Vol.4 No.
2.
113-122.179
