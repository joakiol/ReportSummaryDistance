Proceedings of the BioNLP Shared Task 2013 Workshop, pages 130?134,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsExploring a Probabilistic Earley Parser forEvent Composition in Biomedical TextsMai-Vu Tran1 Hoang-Quynh Le1  Van-Thuy Phi1  Thanh-Binh Pham1 Nigel Collier2,31University of Engineering and Technology, VNU, Hanoi, Vietnam2National Institute of Informatics, Tokyo, Japan3European Bioinformatics Institute, Cambridge, UK{vutm,lhquynh,thuypv,binhpt}@vnu.edu.vn, collier@ebi.ac.ukAbstractWe describe a high precision system for ex-tracting events of biomedical significance thatwas developed during the BioNLP shared task2013 and tested on the Cancer Genetics dataset.
The system achieved an F-score on the de-velopment data of 73.67 but was ranked 5th outof six with an F-score of 29.94 on the test data.However, precision was the second highestranked on the task at 62.73.
Analysis suggeststhe need to continue to improve our system forcomplex events particularly taking into ac-count cross-domain differences in argumentdistributions.1 IntroductionIn this paper we present our approach to the Bi-oNLP 2013 shared task on Cancer Genetics (CG)(Pyysalo et al 2013, Pyysalo et al 2012),aimed at identifying biomedical relations of sig-nificance in the development and progress ofcancer.
Our system explored a multi-stage ap-proach including trigger detection, edge detec-tion and event composition.
After trigger edgedetection is finished we are left with a semanticgraph from which we must select the optimalsubset that is consistent with the semantic framesfor each event type.
Previous approaches havederived sub-graph matching rules using heuris-tics (Jari Bj?rne et al2009) or machine learningusing graph kernels (Liu et al 2013).
Based onMcClosky et al(2011)?s observation that eventstructures have a strong similarity to dependencygraphs, we proposed a novel method for thecomposition of ambiguous events used a proba-bilistic variation of the Earley chart parsing algo-rithm (Stolcke 1995) for finding best derivedtrigger-argument candidates.
Our method usesthe event templates and named entity classes asgrammar rules.
As an additional novel step ourchart parsing approach incorporates a linear in-terpolation mechanism for cross-domain adaptiv-ity between the training and testing (develop-ment)  data.2 ApproachThe system consists of five main modules: pre-processing, trigger detection, edge detection,simple event extraction, complex event extrac-tion.
Each of these is described below with anemphasis on event composition where we ap-plied a probabilistic variation on the Earley par-ser.2.1 Experimental SettingAs our team?s first attempt at the BioNLP sharedtask we decided to focus our attention on theCancer Genetic Task.
The CG Task aims to ex-tract events related to the development and pro-gression of cancer.A characteristic feature of the CG Task is thatthere are a large number of entity and eventtypes: 18 entity classes, 40 types of event and 8types of arguments.
Among these events, thereare 7 that may have no arguments: Blood vesseldevelopment, Cell death, Carcinogenesis, Metas-tasis, Infection, Amino acid catabolism and Gly-colysis.
On the other hand, some events mayhave more than one argument: Binding and GeneExpression may have more than one Theme ar-gument, and Planned process may have morethan one Instrument argument.We divided events into two groups based ondefinitions of Miwa et al2010) : simple andcomplex events.
Simple events include 36 eventswhose arguments must be entities.
Complexevents include 4 event types whose argumentsmay be other events.2.2 Pre-processingPre-processing conventionally made use of theGeniaTagger (Tsuruoka and Tsujii, 2005) forsentence splitting and tokenizing, and the HPSG130parser Enju1 (Miyao and Tsujii, 2008).
Both ofthese were provided in the supporting resourcesby the task organisers.
Gold standard named enti-ty annotations were also provided.2.3 Trigger DetectionIn the CG Task dataset, 95% of the triggersthat indicate events are single token.
We there-fore treated trigger detection as a token labelingproblem in a similar way to Bj?rne et al(2009).Here the system has to classify whether a tokenacts as a trigger for one of the forty event typesor not.
We used the Liblinear-java library2 (Fanet al 2008) with the L2-regularized logistic re-gression method for both trigger detection andedge detection.
We performed a manual gridsearch to select a C-value parameter of 0.5.
Thisparameter value is same from that of the Turkusystem (Bj?rne et al(2009), in which the C-values were tuned for all of their detectors.The major features used are primarily basedon Miwa, et al(2012) and shown in Table 1.
Inour experiments this led to a relatively largenumber of features: about 500k features for thetrigger detection model, 900k features in the T-Emodel and 600k features in the EV-EV model.Our choice of the Liblinear library was partlymotivated by its efficient performance with largefeature sets.Feature TargetToken feature - Current tokenNeighbouring word feature - Current tokenWord n-gram feature - Current tokenTrigger dictionary feature - Current tokenPair n-gram feature - Between current token andnamed entitiesParse tree shortest pathfeature- Between current token andnamed entitiesTable 1: Features in the trigger detection module.2.4 Event edge detectionFor edge detection, we used Liblinear to con-struct two models: one model is designed primar-ily to extract trigger-entity edges (T-E model),while the other system is designed primarily toextract event-event edges (EV-EV model).The T-E model classifies edge candidates toone of the 8 argument roles (theme, cause, site,atloc, toloc, fromloc, instrument, participant)and a negative argument class.
Relation pairs areidentified through the simple event extractionmodule (cf Section 2.5).1 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/2 http://www.bwaldvogel.de/liblinear-java/The EV-EV model identifies relations in thesentences between 4 types of complex events(Regulation, Negative regulation, Positive Regu-lation and Planned process) and other events(including events belonging to the 4 complexevents).
The relations are classified into threeclasses: the two argument roles (theme or cause)or NOT.The features used in these two models aremostly the same as those used in the earlier trig-ger detection module.
Table 2 shows features andtheir applied target objects used in T-E model,Table 3 shows features and target objects foreach feature of EV-EV model.Feature TargetToken feature - Current trigger- Trigger argument entityClass feature - Current trigger- Trigger argument entityNeighbouring wordfeature- Current trigger- Trigger argument entityWord n-gram feature - Current trigger- Trigger argument entityPair n-gram feature - Between current trigger andargument entityParse tree shortestpath feature- Between current trigger andrigger argument entityTable 2: Features in the T-E model.Feature TargetToken feature Current trigger, target trigger, cur-rent arguments, target argumentsClass feature Current trigger, target trigger, cur-rent arguments, target argumentsNeighbouring wordfeatureCurrent trigger, target trigger, cur-rent arguments, target argumentsWord n-gram feature Current trigger, target trigger, cur-rent arguments, target argumentsPair n-gram feature Between current trigger and targettrigger, between current trigger andtarget arguments, between currentarguments and target trigger, be-tween current arguments and targetargumentsParse tree shortestpath featureBetween current trigger and targettrigger, between current trigger andtarget arguments, between currentarguments and target trigger, be-tween current arguments and targetargumentsTable 3: Features in the EV-EV model.2.5 Simple event extractionIn order to minimise the incorrect combinationof arguments and triggers it seemed natural to tryand solve the edge classification problem firstbetween triggers and entities (simple edge detec-tion) and then apply these as features in a stackedmodel to the complex event recogniser (cf Sec-tion 2.6).
In the simple event extraction module,131Figure 1: An example of representing two complex events as two event trees.we combined edge candidates identified in the T-E model into complete simple events.
After thisstep, we had the results which belong to the 36simple event types and relations between 4 com-plex events and entities.In order to select the edge candidates for eachtrigger, we used event-argument pattern basedprobabilities derived from the training set.
Anexample of a Development event-arguments pat-tern is:Development ?
Theme(Gene_expression) + At-Loc(Cancer)In practice there are several problems thatarose when opting for this simple strategy:- Firstly, there may be multiple candidateswith the same argument role label linking to atrigger (such triggers do not belong to Binding,Gene Expression and Planned process).
We usedthe output probability from the logistic regres-sion event edge classifiers to select the best can-didate in these cases.- Secondly, there are triggers whose candidateedge types link to entities that do not match pat-terns observed in the training set or do not haveany relation.
We introduced a rule-based seman-tic post-processing step: triggers are checked tosee if they belong to the 7 event types whichhave no argument; if they do not, we rejectedthese from the results.- Thirdly, there may be an imbalance betweenthe argument distribution in the training and test-ing data (development data).
In the developmentdata, we observed some event-argument patternswhich do not occur in training set, this problemmay lead to false negatives.
For example:Cell_transformation ?
Theme(Cell) + At-Loc(Cell) or Mutation ?Site(DNA_domain_or_region).
This was onecause of false negatives in our system?s perfor-mance (cf Section 3).2.6 Complex event extraction with proba-bilistic Earley ParserFor complex event extraction, based on theidea of McClosky et al(2011) that treats eventextraction as dependency parsing, we representcomplex events in the form of event trees whichare similar to dependency trees.
Our idea differsfrom McClosky et alin that they represented allevents in a sentences within a single tree, where-as we build a tree for each complex event.
Thissolution helps avoid the problem of directed cy-cles if there are two complex event that relate tothe same entity or event.Figure 1 shows an example of representingtwo complex events as two event trees.
To buildthe event tree, we create a virtual ROOT node;the complex event target will be linked directlyto this ROOT node, and triggers and entities thatdo not belong to sub-structure of the target eventwill also have links to ROOT node, too.
In theevent tree, labels of entity classes and eventtypes are retained while terms of triggers andentities are removed.For event tree parsing, we used the Earleyparsing algorithm proposed by Jay Earley (1970)to find alternative structures.
The event tree isstored in memory in the form of Earley rules.The inputs to the parser are the entities and trig-gers which have been identified in the triggerdetection module, and the outputs are the eventtree candidates.To choose the best event tree candidates, webuilt a probabilistic Earley parser which devel-oped from the idea of Hale (2001).
As a first at-tempt at introducing robustness for edge classifi-er error our parser used linear interpolation onthe probability from the edge detection moduleand the prior edge probabilities to calculate ascore for each event tree candidate.
The interpo-lation parameter ?
was set using a manual grid132search and reflects the confidence we have in thegeneralisability of the edge detection module onthe testing (development) data.The scoring function for each node is:Occurrence(edge | argrument)(node) (arguments | node)(edges)edges nodePScore Pnum??
??where,?
num(edge) is the number of edges thathave a link to the node?
POccurence(arguments|node) is a distribu-tion which represents the co-occurrence ofentity/trigger labels in the arguments of anevent type.?
(edge | argrument) (edge | argument)ClassifierP P?
??
?
(1 )* (edge | argument)PriorP???
?
is a linear interpolation parameter inthe range of [0,1]?
PClassifier(edge|argument) is the probabil-ity obtained from the edge classifier.?
PPrior(edge|argument) is the training set?sprior probability for the edge.Edges that linked directly to ROOT and didnot relate to the target complex event had a de-fault value of zero.
The final score of an eventtree candidate was calculated as ROOT?s value.We used a filter_threshold parameter to re-move event tree candidates which had an edgewith P(edge|argument) less than filter_threshold.On the other hand, we used a cut-off_thresholdparameter to choose event tree candidates whichhave highest value.
Event tree candidates whichare sub-structure of other event tree candidateswere removed from the final results.3 Results and DiscussionWe evaluated each component of the systemon the training and held out data sets.
The opti-mal configuration of parameters was then usedon the shared task test data.
We set these as fol-lows:?=0.5;filter_threshold=0.2;cutoff_threshold=0.45.Table 4 shows F-score performance for eventcomposition on the development data set.
Wefound that complex events such as regulation andplanned process performed at the lower end ofaccuracy due to their high complexity.
This re-sulted in relatively low recall compared to preci-sion (figures not shown).
The three Regulationevents in particular are very productive in termsof the variety of named entities and triggers theytake as arguments and their distribution in thedevelopment data was quite different to the train-ing data.Event F1 Event F1Development 86.67 Phosphorylation 68.45Blood vesseldevelopment84.15 Dephosphorylation 66.67Growth 76.77 DNA methylation 85.71Death 61.95 DNA demethyla-tion-Cell death 53.06 Pathway 61.81Breakdown 77.68 Localization 66.11Cell proliferation 59.82 Binding 70.68Cell division 100.00 Dissociation 100.00Remodeling 60.00 Regulation 69.55Reproduction - Positive regulation 68.13Mutation 78.74 Negative regula-tion68.57Carcinogenesis 60.67 Planned process 49.99Metastasis 74.39 Acetylation  100.00Metabolism 62.50 Glycolysis  69.89Synthesis 52.63 Glycosylation -Catabolism 59.27 Cell transformation  66.67Gene expression 79.18 Cell differentiation  71.18Transcription 75.00 Ubiquitination 75.00Translation 80.00 Amino acid ca-tabolism100.00Protein pro-cessing100.00 Infection  75.86Total  73.67Table 4: Baseline results for event composi-tion on the development data.From our analysis on the development set wefound that trigger detection was performing welloverall with F-scores in the range 78 to 80.
Wechoose 50 false negative events at random forerror analysis.
There are 29 triggers and 21events missing.
Table 5 shows a stratified analy-sis by major error type (we note that errors mayof course have multiple causes).Cause Trigger EventAmbiguity in event class 9Co-reference 6Do not match with any event argumentpatterns7No training instance 7 4Choose best argument entity in simpleevent extraction5No argument  4No Earley parser rule  8Total 29 21Table 5: Error classification of 50 missingfalse negatives.133Performance on the shared task testing set wasoverall disappointing with an F-score of 29.94(Recall = 19.66, Precision = 62.73, F-score ofsimple event extraction = 47.96 and F-score ofcomplex event extraction = 12.49) indicating lowcoverage caused by severe over-fitting issues.Analysis revealed that one cause of this was theimbalance in the distribution of arguments be-tween training and testing sets.4 ConclusionWe presented a system built on supervisedmachine learning with rich features, semanticpost-processing rules and the dynamic program-ming Earley parser.
The system achieved an F-score of 29.94 on the CG task with high preci-sion of 62.73.
Future work will focus on extend-ing recall for complex events and looking at howwe can avoid over-fitting to benefit cross-domainadaptivity.AcknowledgementsWe thank the shared task organisers for sup-porting this community evaluation and to thesupporting resource providers.
Nigel Collier alsogratefully acknowledges funding support fromthe European Commission through the MarieCurie International Incoming Fellowship (IIF)programme (Project: Phenominer, Ref: 301806).ReferencesDavid McClosky, Mihai Surdeanu, and Chris Man-ning.
2011.
Event extraction as dependency pars-ing.
In Proceedings of the BioNLP Shared Task2011 Workshop at the Association for Computa-tional Linguistics Conference, pp.
41-45.Jari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airo-la, Tapio Pahikkala, and Tapio Salakoski.
2009.Extracting complex biological events with richgraph-based feature sets.
In Proceedings of the Bi-oNLP 2009 Shared Task Workshop at the Associa-tion for Computational Linguistics Conference, pp.10?18.Jari Bj?rne, Filip Ginter, Tapio Salakoski: Universityof Turku in the BioNLP'11 Shared Task.
BMC Bi-oinformatics 13(S-11): S4 (2012)Fan R-E, Chang K-W, Hsieh C-J, Wang X-R, Lin C-J.
2008.
LIBLINEAR: A library for large linearclassification.
J Machine Learn Res 9:1871?1874.Miwa, M., Thompson, P., McNaught, J., Kell, D.,Ananiadou, S. 2012.
Extracting semantically en-riched events from biomedical literature.
BMC Bi-oinformatics 13, 108.Makoto Miwa, Rune S?tre, Jin-Dong Kim, andJun?ichi Tsujii.
2010.
Event extraction with com-plex event classification using rich features.
Jour-nal of Bioinformatics and Computational Biology(JBCB), 8(1):131?146.Earley, Jay (1970).
An efficient context-free parsingalgorithm.
Communications of the ACM 13 (2):94?102Andreas Stolcke (1995).
An efficient probabilisticcontext-free parsing algorithm that computes pre-fix probabilities.
Journal Computational Linguis-tics (1995) Volume 21 Issue 2: 165-201Sampo Pyysalo, Tomoko Ohta and Sophia Anani-adou.
(2013).
Overview of the Cancer Genetics(CG) task of BioNLP Shared Task 2013.
Proceed-ings of BioNLP Shared Task 2013 Workshop at theAssociation for Computational Linguistics Confer-ence, (in press).Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, Han-Cheol Cho, Jun'ichi Tsujii and Sophia Ananiadou.(2012).
Event extraction across multiple levels ofbiological organization.
Bioinformatics,28(18):i575-i581.Haibin Liu, Lawrence Hunter, Vlado Ke?elj, KarinVerspoor (2013).
Approximate Subgraph Match-ing-Based Literature Mining for Biomedical Eventsand Relations.
PLOS ONE, 2013.134
