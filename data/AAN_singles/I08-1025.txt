TSUBAKI: An Open Search Engine Infrastructure forDeveloping New Information Access MethodologyKeiji Shinzato?, Tomohide Shibata?, Daisuke Kawahara?,Chikara Hashimoto??
and Sadao Kurohashi?
?Graduate School of Informatics, Kyoto University?National Institute of Information and Communications Technology?
?Department of Informatics, Yamagata University{shinzato, shibata, kuro}@nlp.kuee.kyoto-u.ac.jpdk@nict.go.jp ch@yz.yamagata-u.ac.jpAbstractAs the amount of information created byhuman beings is explosively grown in thelast decade, it is getting extremely harderto obtain necessary information by conven-tional information access methods.
Hence,creation of drastically new technology isneeded.
For developing such new technol-ogy, search engine infrastructures are re-quired.
Although the existing search engineAPIs can be regarded as such infrastructures,these APIs have several restrictions such as alimit on the number of API calls.
To help thedevelopment of new technology, we are run-ning an open search engine infrastructure,TSUBAKI, on a high-performance comput-ing environment.
In this paper, we describeTSUBAKI infrastructure.1 IntroductionAs the amount of information created by human be-ings is explosively grown in the last decade (Uni-versity of California, 2003), it is getting extremelyharder to obtain necessary information by con-ventional information access methods, i.e., Websearch engines.
This is obvious from the fact thatknowledge workers now spend about 30% of theirday on only searching for information (The Del-phi Group White Paper, 2001).
Hence, creation ofdrastically new technology is needed by integratingseveral disciplines such as natural language process-ing (NLP), information retrieval (IR) and others.Conventional search engines such as Google andYahoo!
are insufficient to search necessary informa-tion from the current Web.
The problems of the con-ventional search engines are summarized as follows:Cannot accept queries by natural language sen-tences: Search engine users have to represent theirneeds by a list of words.
This means that searchengine users cannot obtain necessary information ifthey fail to represent their needs into a proper wordlist.
This is a serious problem for users who do notutilize a search engine frequently.Cannot provide organized search results: Asearch result is a simple list consisting of URLs,titles and snippets of web pages.
This type of re-sult presentation is obviously insufficient consider-ing explosive growth and diversity of web pages.Cannot handle synonymous expressions: Exist-ing search engines ignore a synonymous expressionproblem.
Especially, since Japanese uses three kindsof alphabets, Hiragana, Katakana and Kanji, thisproblem is more serious.
For instance, although bothJapanese words ?????
and ????
mean child,the search engines provide quite different search re-sults for each word.We believe that new IR systems that overcome theabove problems give us more flexible and com-fortable information access and that developmentof such systems is an important and interesting re-search topic.To develop such IR systems, a search engine in-frastructure that plays a low-level layer role (i.e., re-trieving web pages according to a user?s query froma huge web page collection) is required.
The Appli-cation Programming Interfaces (APIs) provided by189commercial search engines can be regarded as suchsearch engine infrastructures.
The APIs, however,have the following problems:1.
The number of API calls a day and the num-ber of web pages included in a search result arelimited.2.
The API users cannot know how the acquiredweb pages are ranked because the ranking mea-sure of web pages has not been made public.3.
It is difficult to reproduce previously-obtainedsearch results via the APIs because search en-gine?s indices are updated frequently.These problems are an obstacle to develop new IRsystems using existing search engine APIs.The research project ?Cyber Infrastructure for theInformation-explosion Era1?
gives researchers sev-eral kinds of shared platforms and sophisticatedtools, such as an open search engine infrastructure,considerable computational environment and a gridshell software (Kaneda et al, 2002), for creation ofdrastically new IR technology.
In this paper, we de-scribe an open search engine infrastructure TSUB-AKI, which is one of the shared platforms devel-oped in the Cyber Infrastructure for the Information-explosion Era project.
The overview of TSUBAKI isdepicted in Figure 1.
TSUBAKI is built on a high-performance computing environment consisting of128 CPU cores and 100 tera-byte storages, and itcan provide users with search results retrieved fromapproximately 100 million Japanese web pages.The mission of TSUBAKI is to help the develop-ment of new information access methodology whichsolves the problems of conventional information ac-cess methods.
This is achieved by the followingTSUBAKI?s characteristics:API without any restriction: TSUBAKI pro-vides its API without any restrictions such as thelimited number of API calls a day and the numberof results returned from an API per query, which arethe typical restrictions of the existing search engineAPIs.
Consequently, TSUBAKI API users can de-velop systems that handle a large number of webpages.
This feature is important for dealing with theWeb that has the long tail aspect.1http://i-explosion.ex.nii.ac.jp/i-explosion/ctr.php/m/Inde-xEng/a/Index/ 	Figure 1: An overview of TSUBAKI.Transparent and reproducible search results:TSUBAKI makes public not only its ranking mea-sure but also its source codes, and also provides re-producible search results by fixing a crawled webpage collection.
Because of this, TSUBAKI keepsits architecture transparency, and systems using theAPI can always obtain previously-produced searchresults.Web standard format for sharing pre-processedweb pages: TSUBAKI converts a crawled webpage into a web standard format data.
The web stan-dard format is a data format used in TSUBAKI forsharing pre-processed web pages.
Section 2 presentsthe web standard format in detail.Indices generated by deep NLP: TSUBAKI in-dexes all crawled web pages by not only words butalso dependency relations for retrieving web pagesaccording to the meaning of their contents.
The in-dex data in TSUBAKI are described in Section 3.This paper is organized as follows.
Section 2 de-scribes web standard format, and Section 3 showsTSUBAKI?s index data and its search algorithm.Section 4 presents TSUBAKI API and gives exam-ples of how to use the API.
Section 5 shows relatedwork.2 Sharing of Pre-processed Web Pages ona Large ScaleWeb page processing on a large scale is a dif-ficult task because the task generally requires a190high-performance computing environment (Kawa-hara and Kurohashi, 2006) and not everybody canuse such environment.
Sharing of large scale pre-processed web pages is necessary for eliminating thegap yielded by large data processing capabilities.TSUBAKI makes it possible to share pre-processed large scale web pages through the API.TSUBAKI API provides not only cached originalweb pages (i.e., 100 million pages) but also pre-processed web pages.
As pre-processed data ofweb pages, the results of commonly performed pro-cessing for web pages, including sentence bound-ary detection, morphological analysis and parsing,are provided.
This allows API users to begin theirown processing immediately without extracting sen-tences from web pages and analyzing them by them-selves.In the remainder of this section, we describe aweb standard format used in TSUBAKI for sharingpre-processed web pages and construction of a largescale web standard format data collection.2.1 Web Standard FormatThe web standard format is a simple XML-styleddata format in which meta-information and text-information of a web page can be annotated.
Themeta-information consists of a title, in-links and out-links of a web page and the text-information consistsof sentences extracted from the web page and theiranalyzed results by existing NLP tools.An example of a web standard format data isshown in Figure 2.
Extracted sentences are enclosedby <RawString> tags, and the analyzed resultsof the sentences are enclosed by <Annotation>tags.
Sentences in a web page and their analyzed re-sults can be obtained by looking at these tags in thestandard format data corresponding to the page.2.2 Construction of Web Standard FormatData CollectionWe have crawled 218 million web pages over threemonths, May - July in 2007, by using the Shim-Crawler,2 and then converted these pages into webstandard format data with results of a Japaneseparser, KNP (Kurohashi and Nagao, 1994), throughour conversion tools.
Note that this web page collec-2http://www.logos.t.u-tokyo.ac.jp/crawler/<?xml version="1.0" encoding="UTF-8"?><StandardFormatUrl="http://www.kantei.go.jp/jp/koizumiprofile/1_sinnen.html" OriginalEncoding="Shift_JIS" Time="2006-08-14 19:48:51"><Text Type="default"><S Id="1" Length="70" Offset="525"><RawString>????????????????????
(???????)??????
?</RawString><Annotation Scheme="KNP"><!
[CDATA[* 1D <??><??><??><??><????><??><?:??><??:0-4><RID:1056>??
????
??
??
6 ??
5 * 0 * 0 NIL <??><??><????><?????><??><?????><???><????>...??
??
??
???
14 ??????
7 ?????????
31 ???
2 NIL <????><????><????><???><??><?????????>?
?
?
??
1 ??
1 * 0 * 0 NIL <??><??><?
?>EOS]]></Annotation></S>...</Text></StandardFormat>Figure 2: An example of web standard format datawith results of the Japanese parser KNP.tion consists of pages written not only in Japanesebut also in other languages.The web pages in the collection are converted intothe standard format data according to the followingfour steps:Step 1: Extract Japanese web pages from a givenpage collection.Step 2: Detect Japanese sentence boundaries in theextracted web pages.Step 3: Analyze the Japanese sentences by the NLPtools.Step 4: Generate standard format data from the ex-tracted sentences and their analyzed results.We followed the procedure proposed in Kawaharaand Kurohashi (2006) for Steps 1 and 2.The web pages were processed by a grid comput-ing environment that consists of 640 CPU cores and640 GB main memory in total.
It took two weeks tofinish the conversion.
As a result, 100 million webstandard format data were obtained.
In other words,the remaining 118 million web pages were regardedas non-Japanese pages by our tools.The comparison between original web pages andthe standard format data corresponding to thesepages in terms of file size are shown in Table 1.
We191Table 1: File size comparison between original webpages and standard format data (The number of webpages is 100 millions, and both the page sets arecompressed by gzip.
)Document set File size [TB]Original web pages 0.6Standard format styled data 3.1can see that the file size of the web standard formatdata is over five times bigger than that of the originalweb pages.3 Search Engine TSUBAKIIn this section, we describe the indices and searchalgorithm used in TSUBAKI.3.1 Indices in TSUBAKITSUBAKI has indexed 100 million Japanese webpages described in Section 2.2.
Inverted index datawere created by both words and dependency rela-tions.
Note that the index data are constructed fromparsing results in the standard format data.3.1.1 Word IndexHandling of synonymous expressions is a cru-cial problem in IR.
Especially, since Japanese usesthree kinds of alphabets, Hiragana, Katakana andKanji, spelling variation is a big obstacle.
For exam-ple, the word ?child?
can be represented by at leastthree spellings ????
?, ?????
and ????
inJapanese.
Although these spellings mean child, ex-isting search engines handle them in totally differentmanner.
Handling of spelling variations is importantfor improving search engine performance.To handle spelling variations properly, TSUBAKIexploits results of JUMAN (Kurohashi et al, 1994),a Japanese morphological analyzer.
JUMAN seg-ments a sentence into words, and gives represen-tative forms of the words simultaneously.
For ex-ample, JUMAN gives us ????
as a representativeform of the words ????
?, ?????
and ???.
?TSUBAKI indexes web pages by word representa-tive forms.
This allows us to retrieve web pages thatinclude different spellings of the queries.TSUBAKI also indexes word positions for pro-viding search methods such as an exact phrasesearch.
A word position reflects the number ofwords appearing before the word in a web page.
Forexample, if a page contains N words, the word ap-pearing in the beginning of the page and the lastword are assigned 0 and N ?
1 as their positionsrespectively.3.1.2 Dependency Relation IndexThe understanding of web page contents is crucialfor obtaining necessary information from the Web.The word frequency and link structure have beenused as clues for conventional web page retrieval.These clues, however, are not sufficient to under-stand web page?s contents.
We believe that otherclues such as parsing results of web page contentsare needed for the understanding.Let us consider the following two sentences:S1: Japan exports automobiles to Germany.S2: Germany exports automobiles to Japan.Although the above sentences have different mean-ings, they consist of the same words.
This meansthat a word index alone can never distinguish the se-mantic difference between these sentences.On the other hand, syntactic parsers can producedifferent dependency relations for each sentence.Thus, the difference between these sentences canbe grasped by looking at their dependency relations.We expect that dependency relations work as effi-cient clues for understanding web page contents.As a first step toward web page retrieval consid-ering the meaning of web page contents, TSUBAKIindexes web pages by not only words but also de-pendency relations.
An index of the dependency re-lation between A and B is represented by the notationA?
B, which means A modifies B.
For instance, thedependency relation indices Japan?
export, auto-mobile ?
export, to ?
export, and Germany ?
toare generated from the sentence S1.3.1.3 Construction of Index dataWe have constructed word and dependency rela-tion indices from a web standard format data collec-tion described in Section 2.2.
The file size of theconstructed indices are shown in Table 2.
We cansee that the file size of the word index is larger thanthat of dependency relation.
This is because that theword index includes all position for all word indexexpression.192Table 2: File sizes of the word and dependencyrelation indices constructed from 100 million webpages.Index type File size [TB]Word 1.17Dependency relation 0.89Table 3: Comparison with index data of TSUBAKIand the Apache Lucene in terms of index data size(The number of web pages is a million.
)Search engine File size [GB]TSUBAKI (words) 12.0TSUBAKI (dependency relations) 9.1Apache Lucene 4.7Moreover, we have compared index data con-structed by TSUBAKI and the Apache Lucene,3 anopen source information retrieval library, in termsof the file size.
We first selected a million webpages from among 100 million pages, and then in-dexed them by using the indexer of TSUBAKI andthat of the Lucene.4 While TSUBAKI?s indexerindexed web pages by the both words and depen-dency relations, the Lucene?s indexer indexed pagesby only words.
The comparison result is listed inTable 3.
We can see that the word index data con-structed by TSUBAKI indexer is larger than that ofthe Lucene.
But, the file size of the TSUBAKI?s in-dex data can be made smaller because the TSUB-AKI indexer does not optimize the constructed indexdata.3.2 Search AlgorithmTSUBAKI is run on a load balance server, four mas-ter servers and 27 search servers.
Word and depen-dency relation indices generated from 100 millionweb pages are divided into 100 pieces respectively,and each piece is allocated to the search servers.
Inshort, each search server has the word and depen-dency relation indices generated from at most fourmillion pages.The procedure for retrieving web pages is shownin Figure 3.
Each search server calculates rele-vance scores between a user?s query and each doc-3http://lucene.apache.org/java/docs/index.html4We used the Lucene 2.0 for Japanese which is availablefrom https://sen.dev.java.net/servlets/ProjectDocumentList?folderID=755&ex pandFolder=755&folderID=0Step 1: The load balance server forwards user?s queryQto the most unoccupied master server.Step 2: The master server extracts the set of index ex-pressions q from the given query Q, and transmitsthe set of q and search conditions such as a logicaloperator (i.e., AND/OR) between words inQ to 27search servers.Step 3: The search server retrieves web pages accordingto the set of q and search conditions by using wordand dependency relation indices.Step 4: The search server calculates a relevance scorefor each retrieved document, and then returns thedocuments with their scores to the master server.Step 5: The master server sorts the returned documentsaccording to their calculated scores.Step 6: The top M documents are presented to the useras a search result.Figure 3: The search procedure of TSUBAKI.
(Steps 3 and 4 are performed in parallel.
)ument that matches the query.
We used the sumof OKAPI BM25 (Robertson et al, 1992) scoresover index expressions in the query as the relevancescore.
The relevance score scorerel is defined as:scorerel (Q, d) =?q?QBM25 (q, d)BM25 (q, d) = w ?
(k1 + 1)fqK + fq?
(k3 + 1)qfqk3 + qfqw = log N ?
n + 0.5n + 0.5,K = k1((1?
b) + bllave)where q is an index expression extracted from thequery Q, fq is the frequency of the expression q in adocument d, qfq is the frequency of q in Q, and N isthe total number of crawled web pages.
TSUBAKIused 1.0 ?
108 as N .
n is the document frequencyof q in 100 million pages, l is the document lengthof d (we used the number of words in the documentd), and lave is the average document length over allthe pages.
In addition to them, the parameters ofOKAPI BM25, k1,k3 and bwere set to 2, 0 and 0.75,respectively.Consider the expression ?global warming?s ef-fect?
as a user?s query Q.
The extracted index ex-pressions fromQ are shown in Figure 4.
Each searchserver calculates a BM25 score for each index ex-pression (i.e., effect, global, .
.
.
, global?
warm),and sums up the calculated scores.Note that BM25 scores of dependency relationsare larger than those of single words because the193Word index: effect, global, warm,Dependency relation index: global ?
warm, warm ?effectFigure 4: The index expressions extracted from thequery ?global warming?s effect.
?document frequencies of dependency relations arerelatively smaller than those of single words.
Con-sequently, TSUBAKI naturally gives high score val-ues to web pages that include the same dependencyrelations as the one included in the given query.4 TSUBAKI APIAs mentioned before, TSUBAKI provides the APIwithout any restriction.
The API can be queried by?REST (Fielding, 2000)-Like?
operators in the sameway of Yahoo!
API.
TSUBAKI API users can obtainsearch results through HTTP requests with URL-encoded parameters.
Examples of the available re-quest parameters are listed in Table 4.
The samplerequest using the parameters is below:Case 1: Get the search result ranked at top 20 withsnippets for the search query ???
(Kyoto)?.http://tsubaki.ixnlp.nii.ac.jp/api.cgi?query=%E4%BA%AC%E9%83%BD&starts=1&results=20TSUBAKI API returns an XML document in Fig-ure 5 for the above request.
The result includes agiven query, a hitcount, the IDs of web pages thatmatch the given query, the calculated scores and oth-ers.
The page IDs in the result enable API usersto obtain cached web pages and web standard for-mat data.
An example request for obtaining the webstandard format data with document ID 01234567 isbelow.Case 2: Get web standard format data with the doc-ument ID 01234567.http://tsubaki.ixnlp.nii.ac.jp/api.cgi?id=01234-567&format=xmlThe hitcounts of words are frequently exploitedin NLP tasks.
For example, Turney (Turney, 2001)proposed a method that calculates semantic similar-ities between two words according to their hitcountsobtained from an existing search engine.
AlthoughTSUBAKI API users can obtain a query?s hitcountTable 4: The request parameters of TSUBAKI API.Parameter Value Descriptionquery string The query to search for (UTF-8 encoded).
The query param-eter is required for obtainingsearch results?start integer:default 1The starting result position toreturn.results integer:default 20The number of results to re-turn.logical operator AND/OR:default ANDThe logical operation tosearch for.dpnd 0/1: default 1 Specifies whether to use de-pendency relations as clues fordocument retrieving.
Set to 1to use dependency relations.only hitcounts 0/1: default 0 Set to 1 to obtain a query?s hit-count only.snippets 0/1: default 0 Set to 1 to obtain snippets.id string The document ID to obtaina cached web page or stan-dard format data correspond-ing to the ID.
This parameteris required for obtaining webpages or standard format data.format html/xml The document type to return.This parameter is required ifthe parameter id is set.from a search result shown in Figure 5, TSUBAKIAPI provides an access method for directly obtain-ing query?s hitcount.
The API users can obtain onlya hitcount according to the following HTTP request.Case 3: Get the hitcount of the query ???
(Ky-oto)?http://tsubaki.ixnlp.nii.ac.jp/api.cgi?query=%E4%BA%AC%E9%83%BD&only hitcounts=1In this case, the response of the API is a plain-textdata indicating the query?s hitcount.5 Related WorkAs mentioned before, existing search engine APIssuch as Google API are insufficient for infrastruc-tures to help the development of new IR method-ology, since they have some restrictions such as alimited number of API calls a day.
The differencesbetween TSUBAKI API and existing search engineAPIs are summarized in Table 5.
Other than accessrestrictions, the serious problem of these APIs is thatthey cannot always reproduce previously-provided194<ResultSet time="2007-10-15 14:27:01" query="??"
totalResultsAvailable="4721570" totalResultsReturned="20"firstResultPosition="1" logicalOperator="AND" forceDpnd="0" dpnd="1" filterSimpages="1"><Result Rank="1" Id="017307147" Score="8.87700"><Title>???????????????????????
?</Title><Url>http://www.docch.net/blog/jtb-e/kyouto.shtml</Url><Snippet/><Cache><Url>http://tsubaki.ixnlp.nii.ac.jp/index.cgi?URL=INDEX_DIR/h017/h01730/017307147.html&KEYS=%E4%BA%AC%E9%83%BD</Url><Size>2900</Size></Cache></Result>...</ResultSet>Figure 5: An example of a search result returned from TSUBAKI API.search results because their indices are updated fre-quently.
Because of this, it is difficult to preciselycompare between systems using search results ob-tained on different days.
Moreover, private searchalgorithms are also the problem since API users can-not know what goes on in searching web pages.Therefore, it is difficult to precisely assess the con-tribution of the user?s proposed method as long asthe method uses the existing APIs.Open source projects with respect to search en-gines such as the Apache Lucene and the Rast5 canbe also regarded as related work.
Although theseprojects develop an open search engine module, theydo not operate web search engines.
This is differentfrom our study.
The comparison between TSUBAKIand open source projects with respect to indexingand ranking measure are listed in Table 6.The Search Wikia project6 has the similar goal toone of our goals.
The goal of this project is to cre-ate an open search engine enabling us to know howthe system and the algorithm operate.
However, thealgorithm of the search engine in this project is notmade public at this time.The Web Laboratory project (Arms et al, 2006)also has the similar goal to ours.
This project aims atdeveloping an infrastructure to access the snapshotsof the Web taken by the Internet Archive.7 Currentlythe pilot version of the infrastructure is released.The released infrastructure, however, allows users toaccess only the web pages in the Amazon.com Website.
Therefore, TSUBAKI is different from the in-frastructure of the Web Laboratory project in terms5http://projects.netlab.jp/rast/6http://search.wikia.com/wiki/Search Wikia7http://www.archive.org/index.phpTable 5: The differences between TSUBAKI APIand existing search engine APIs.Features Google Yahoo!
TSUBAKI# of API calls a day 1,000 50,000 unlimited# of URLs in a search result 1,000 1,000 unlimitedProviding cached pages Yes Yes YesProviding processed pages No No YesUpdating indices Yes Yes NoTable 6: Comparison with indexing and rankingmeasure.Search Engine Indexing Ranking MeasureTSUBAKI word, dependencyrelationOKAPI BM25Apache Lucene character bi-gram,wordTF?IDFRAST character bi-gram,wordTF?IDFof the scale of a used web page collection.6 ConclusionWe have described TSUBAKI, an open search en-gine infrastructure for developing new informationaccess methodology.
Its major characteristics are:?
the API without any restriction,?
transparent and reproducible search results,?
Web standard format for sharing pre-processedweb pages and?
indices generated by deep NLP.TSUBAKI provides not only web pages retrievedfrom 100 million Japanese pages according to auser?s query but also pre-processed large scale web195pages produced by using a high-performance com-puting environment.On the TSUBAKI infrastructure, we are develop-ing a new information access method that organizesretrieved web pages in a search result into clusters ofpages that have relevance to each other.
We believethat this method gives us more flexible informationaccess than existing search methods.Furthermore, we are building on the TSUBAKIinfrastructure a common evaluation environment toevolve IR methodology.
Such an environment isnecessary to easily evaluate novel IR methodology,such as a new ranking measure, on a huge-scale webcollection.Our future work is to handle synonymous expres-sions such as ?car?
and ?automobile.?
Handlingsynonymous expressions is important for improvingthe performance of search engines.
The evaluationof TSUBAKI?s performance is necessary, which isalso our future work.ReferencesWiiliam Y.
Arms, Selcuk Aya, Pavel Dmitriev, Blazej J.Kot, Ruth Mitchell, and Lucia Walle.
2006.
Buildinga research library for the history of the web.
In Pro-ceedings of the Joint Conference on Digital Libraries,June 2006, pages 95?102.Roy Thomas Fielding.
2000.
Architectural Styles andthe Design of Network-based Software Architectures.Ph.D.
thesis, University of California, Irvine.Kenji Kaneda, Kenjiro Taura, and Akinori Yonezawa.2002.
Virtual private grid: A command shell for uti-lizing hundreds of machines efficiently.
In In 2ndIEEE/ACM International Symposium on Cluster Com-puting and the Grid (CCGrid 2002).Daisuke Kawahara and Sadao Kurohashi.
2006.Case frame compilation from the web using high-performance computing.
In Proceedings of the 5thInternational Conference on Language Resources andEvaluation (LREC2006), pages 1344?1347.Sadao Kurohashi and Makoto Nagao.
1994.
A syntacticanalysis method of long japanese sentences based onthe detection of conjunctive structures.
ComputationalLinguistics, (4):507?534.Sadao Kurohashi, Toshihisa Nakamura, Yuji Matsumoto,and Makoto Nagao.
1994.
Improvements of japanesemorphological analyzer juman.
In The InternationalWorkshop on Sharable Natural Language, pages 22 ?28.Stephen E. Robertson, Steve Walker, MichelineHancock-Beaulieu, Aarron Gull, and Marianna Lau.1992.
Okapi at TREC.
In Text REtrieval Conference,pages 21?30.The Delphi Group White Paper.
2001.Connecting to your knowledge nuggets.http://www.delphiweb.com/knowle-dgebase/documents/upload/pdf/1802.pdf.Peter Turney.
2001.
Mining the web for synonyms: Pmi-ir versus lsa on toefl.
In Proceedings of the TwelfthEuropean Conference on Machine Learning (ECML-2001), pages 491?502.University of California.
2003.How much information?
2003.http://www2.sims.berkeley.edu/research/projects/how-much-info-2003/.196
