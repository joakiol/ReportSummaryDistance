A Tractable Extension of Linear Indexed GrammarsBill Keller and David WeirSchool of Cognitive and Computing SciencesUniversity of SussexFalmer, Brighton BN1 9QHUKb?11.
ke l le r /dav id ,  we?r~lcogs, us sex .
ac.
ukAbst rac tVijay-Shanker and Weir (1993) showthat Linear Indexed Grammars (I_IG) canbe processed in polynomial time by ex-ploiting constraints which make possiblethe extensive use of structure-sharing.This paper describes a formalism thatis more powerful than I_IG, but whichcan also be processed in polynomial timeusing similar techniques.
The formal-ism, which we refer to as Partially Lin-ear PATR (PI_PATR) manipulates featurestructures rather than stacks.1 In t roduct ionUnification-based grammar formalisms can beviewed as generalizations of Context-Free Gram-mars (CFG) where the nonterminal symbols arereplaced by an infinite domain of feature struc-tures.
Much of their popularity stems from theway in which syntactic generalization may be el-egantly stated by means of constraints amongstfeatures and their values.
Unfortunately, the ex-pressivity of these formalisms can have undesir-able consequences for their processing.
In naiveimplementations of unification grammar parsers,feature structures play the same role as nonter-minals in standard context-free grammar parsers.Potentially large feature structures are stored atintermediate steps in the computation, so thatthe space requirements of the algorithm are ex-pensive.
Furthermore, the need to perform non-destructive unification means that a large propor-tion of the processing time is spent copying featurestructures.One approach to this problem is to refine pars-ing algorithms by developing techniques uch asrestrictions, structure-sharing, and lazy unifica-tion that reduce the amount of structure that isstored and hence the need for copying of featuresstructures (Shieber, 1985; Pereira, 1985; Kart-tunen and Kay, 1985; Wroblewski, 1987; Gerde-mann, 1989; Godden, 1990; Kogure, 1990; Emele,1991; Tomabechi, 1991; Harrison and Ellison,1992)).
While these techniques can yield signifi-cant improvements in performance, the generalityof unification-based grammar formalisms meansthat there are still cases where expensive process-ing is unavoidable.
This approach does not ad-dress the fundamental issue of the tradeoff be-tween the descriptive capacity of a formalism andits computational power.In this paper we identify a set of constraintsthat can be placed on unification-based grammarformalisms in order to guarantee the existence ofpolynomial time parsing algorithms.
Our choiceof constraints is motivated by showing how theygeneralize constraints inherent in Linear IndexedGrammar (l_lG).
We begin by describing how con-straints inherent in I.IG admit tractable process-ing algorithms and then consider how these con-straints can be generalized to a formalism thatmanipulates trees rather than stacks.
The con-straints that we identify for the tree-based sys-tem can be regarded equally well as constraintson unification-based grammar formalisms uch asPArR (Shieber, 1984).2 From Stacks  to TreesAn Indexed Grammar (IG) can be viewed as a CFGin which each nonterminal is associated with astack of indices.
Productions pecify not only hownonterminals can be rewritten but also how theirassociated stacks are modified.
1_16, which werefirst described by Gazdar (1988), are constrainedsuch that stacks are passed from the mother to atmost a single daughter.For I_IG, the size of the domain of nontermi-nals and associated stacks (the analogue of thenonterminals in CFG) is not bound by the gram-mar.
However, Vijay-Shanker and Weir (1993)demonstrate that polynomial time performance75can be achieved through the use of structure-sharing made possible by constraints in the waythat LI6 use stacks.
Although stacks of un-bounded size can arise during a derivation, it isnot possible for a LIG to specify that two depen-dent, unbounded stacks must appear at distinctplaces in the derivation tree.
Structure-sharingcan therefore be used effectively because check-ing the applicability of rules at each step in thederivation involves the comparison of structuresof limited size.Our goal is to generalize the constraints inher-ent in LIG to a formalism that manipulates fea-ture structures rather than stacks.
As a guidling heuristic we will avoid formalisms that gen-erate tree sets with an unbounded number of un-bounded, dependent branches.
It appears that thestructure-sharing techniques used with LIG cannotbe generalized in a straightforward way to suchformalisms.Suppose that we generalize LIG to allow thestack to be passed from the mother to two daugh-ters.
If this is done recursion can be used to pro-duce an unbounded number of unbounded, depen-dent branches.
An alternative is to allow an un-bounded stack to be shared between two (or more)daughters but not with the mother.
Thus, rulesmay mention more than one unbounded stack, butthe stack associated with the mother is still asso-ciated with at most one daughter.
We refer tothis extension as Partially Linear Indexed Gram-mars (PLIG).Example  1 The PLIG with the following produc-tions generates the language{ anbmcnd m In, m > 1 }and the tree set shown in Figure 1.
Because a sin-gle PUG production may mention more than oneunbounded stack, variables (x, y) are introduced todistinguish between them.
The notation A\[xa\] isused to denote the nonterminal A associated withany stack whose top symbol is ~r.A\[x\]  --+ aA\[?a\],B\[x~\] -~ bBb\],C \ [~\]  -~ cCb\],D\[xa \ ]  --* dD\[x\],A\[x\] ~ B\[y\]C\[x\]D\[y\],B\[~\] -~ b,C\[~\] -~ c,D\[a\] ---* d.Example  2 A PLIG with the following produc-tions generates the k-copy language over { a,b }*,i.e., the language{w' Iwe {o,b}" }Ana A\[~\]a A\[cr n\]B\[,~ m\]b B\[~\]bC\[c~ n\] D\[~ m\]c C\[o-"-'\] d v\[o-"- ' \ ]c c\[~\] d D\[o-\]e dFigure 1: Tree set for {a"bmc'd "~ In,m >_ 1 }where k > 1.sDk copiesA\[xch\] --~ a A\[x\], A\[z~J ~ b A\[x\].Example  3 PLIG can "count" to any fixed k, i.e.,a PLIG with the following productions generates thelanguage{a?
.
.
.a  n In>O}where k > 1.S~ --* Al\[z\].
.
.Ak\[z\],Al\[xa\] ~ al Al\[x\], AI~ --~ A,Ak \[x~r\] --+ ak Ak \[x\], Ak ~ --* A.In PLIG, stacks shared amongst siblings cannotbe passed to the mother.
As a consequence, thereis no possibility that recursion can be used to in-crease the number of dependent branches.
In fact,the number of dependent branches is bounded bythe length of the right-hand-side of productions.By the same token, however, PUG may only gen-erate structural descriptions in which dependent76rll rl2A\[r, d S2\[c~( r,,, r~)\]a A\[rn-1\]a A\[n\]/b B\[rn-1\] C\[rn\]b BIll\]Jb c C\[rl\]/where rl = ~1 and ri+l = ~2(ri)Figure 2: Tree set for { anbncn In > 1 }branches begin at nodes that are siblings of oneanother.
Note that the tree shown in Figure 2is unobtainable because the branch rooted at 7/1is dependent on more than one of the branchesoriginating at its sibling r/2.This l imitation can be overcome by moving toa formalism that manipulates trees rather thanstacks.
We consider an extension of CFG in whicheach nonterminal A is associated with a tree r.Productions now specify how the tree associatedwith the mother is related to the trees associ-ated with the daughters.
We denote trees withfirst order terms.
For example, the following pro-duction requires that the x and y subtrees of themother's tree are shared with the B and C daugh-ters, respectively.
In addition, the daughters havein common the subtree z.A\[ao(x,y)\] --* B\[ch(z, z)\]z)\]There is a need to incorporate some kind ofgeneralized notion of linearity into such a system.Corresponding to the linearity restriction in \[16we require that any part of the mother's tree ispassed to at most one daughter.
Correspondingto the partial linearity of PIAG, we permit subtreesthat are not shared with the mother to be sharedamongst he daughters.
Under these conditions,the tree set shown in Figure 2 can be generated.current q ?statea i -1  ai ai + lI II A tf irst ' T ' lastnonblank ~ aj \[ an " nonblanksymbol current symbolsymbolFigure 3: Encoding a Turing MachineThe nodes 71 and r/2 share the tree rn, which oc-curs twice at the node r/2.
At r12 the two copies ofrn are distributed across the daughters.The formalism as currently described can beused to simulate arbitrary Turing Machine com-putations.
To see this, note that an instanta-neous description of a Turing Machine can be en-coded with a tree as shown in Figure 3.
Movesof the Turing Machine can be simulated by unaryproductions.
The following production may beglossed: "if in state q and scanning the symbol X,then change state to q~, write the symbol Y andmove left" 1A\[q(W(x), X, y)\] --* A\[q'(x, W, r(y)) \ ]One solution to this problem is to prevent a sin-gle daughter sharing more than one of its subtreeswith the mother.
However, we do not impose thisrestriction because it still leaves open the possi-bility of generating trees in which every branchhas the same length, thus violating the conditionthat trees have at most a bounded number of un-bounded, dependent branches.
Figure 4 showshow a set of such trees can be generated by il-lustrating the effect of the following production.A\[c~(cr(x, y), a(x' ,  y'))\] ---* A\[a(z, x)\]A\[cr(z, y)\]d\[~(z, z')\]u')\]To see this, assume (by induction) that all fourof the daughter nonterminals are associated withthe full binary tree of height i (v 0.
All four ofthese trees are constrained to be equal by theproduction given above, which requires that theyhave identical eft (i.e.
z) subtrees (these subtreesmust be the full binary tree vi-1).
Passing theright subtrees (x, y, z' and //I) to the mother asshown allows the construction of a full binary treewith height i + 1 (ri+l).
This can be repeated an1There will be a set of such productions for eachtape symbol W.77A f~ T i+ l0.
0.A 0.
A .0 .V~V~ V~V~A 0.
IA  0.II /' D\[B  \[\]77/%.
A%.ri- l = \[7\]Figure 4: Building full binary treesunbounded number of times so that all full binarytrees are produced.To overcome both of these problems we imposethe following additional constraint on the produc-tions of a grammar.
We require that subtrees ofthe mother that are passed to daughters that sharesubtrees with one another must appear as siblingsin the mother's tree.
Note that this condition rulesout the production responsible for building full bi-nary trees since the x, y, x' and y' subtrees are notsiblings in the mother's tree despite the fact thatall of the daughters hare a common subtree z.Moreover, since a daughter shares subtrees withitself, a special case of the condition is that sub-trees occurring within some daughter can only ap-pear as siblings in the mother.
This condition alsorules out the Turing Machine simulation.
We referto this formalism as Partially Linear Tree Gram-mars (PLTG).
As a further illustration of the con-straints places on shared subtrees, Figure 5 showsa local tree that could appear in a derivation tree.This local tree is licensed by the following produc-tion which respects all of the constraints on PLT6productions.A\[0.1(f2(xl, x2, x3), f3(x4, 0.4))1 --*B\[0.~(~, ,  x l) \]c\[0.~(0.~, ~)1D\[0.8(~=, ~, ~)\]Note that in Figure 5 the daughter nodes labelledB and D share a common subtree and the sub-trees shared between the mother and the B and Ddaughters appear as siblings in the tree associatedi f l0"2 0.3\[\] \[\] \[\] \[\] f~\[\] \[\] D I \[\] \[\] \[\]Figure 5: A PLTG local treewith the mother.Example  4 The PLTG with the following produc-tions generates the language{a"b"c  ~ In >_ 1 }and the tree set shown in Figure 2.Sl \[frO\] ""+ A\[x\] $2 If(x, x)\],&\[ f (~,  y)\] --+ B id  &\[y\],&Ix\] -~  c\[d,A\[a2(x)\] --* aA\[x\],B\[0.~(~)\] -~ b~\[~\],C\[0.2(x)\] -~ cC\[~\],A\[fl\] - -  a,B\[0.1\] --~ b,C\[0.d -~ c.Example  5 The PLTG with the following produc-tions generates the language of strings consistingof k copies of strings of matching parenthesis, i.e.,the languagewhere k k 1 and D is the set of strings in { (,) }*that have balanced brackets, i. e, the Dyck languageover { (,) }.s\[\] -~,A\[x\] .
A\[x\]: AB -~ ~,Yk copiesA\[fl(x)\] --* ( A\[z\] ), A\[a2(x, y)\] --~ A\[z\] A\[y\].3 Trees  to Feature  S t ruc turesFinally, we note that acyclic feature structureswithout re-entrancy can be viewed as trees withbranches labelled by feature names and atomicvalues only found at leaf nodes (interior nodes78being unlabelled).
Based on this observation,we can consider the constraints we have formu-lated for the tree system PI_TG as constraints ona unification-based grammar formalism such asPARR.
We will call this system Partially LinearPATR (PI_PATR).
Having made the move from treesto feature structures, we consider the possibilityof re-entrancy in PI_PATR.Note that the feature structure at the rootof a PI_PATR derivation tree will not involve re-entrancy.
However, for the following reasons webelieve that this does not constitute as great alimitation as it might appear.
In unification-basedgrammar, the feature structure associated withthe root of the tree is often regarded as the struc-ture that has been derived from the input (i.e.,the output of a parser).
As a consequence thereis a tendency to use the grammar ules to  accu-mulate a single, large feature structure giving acomplete ncoding of the analysis.
To do this, un-bounded feature information is passed up the treein a way that violates the constraints developed inthis paper.
Rather than giving such prominenc.eto the root feature structure, we suggest hat theentire derivation tree should be seen as the objectthat is derived from the input, i.e., this is whatthe parser returns.
Because feature structures as-sociated with all nodes in the tree are available,feature information eed only be passed up thetree when it is required in order to establish de-pendencies within the derivation tree.
When thisapproach is taken, there may be less need for re-entrancy in the root feature structure.
Further-more, re-entrancy in the form of shared featurestructures within and across nodes will be foundin PI_PATR (see for example Figure 5).4 Generat ive  Capac i tyHG are more powerful than CI=G and are known tobe weakly equivalent to Tree Adjoining Grammar,Combinatory Categorial Grammar,  and HeadGrammar  (Vijay-Shanker and Weir, 1994).
PI_IGare more powerful than I_IG since they can gener-ate the k-copy language for any fixed k (see Exam-ple 2).
Slightly more generally, PI_IG can generatethe language{w~\]weR}for any k > 1 and regular language R. We be-lieve that the language involving copies of stringsof matching brackets described in Example 5 can-not be generated by PI_IG but, as shown in Exam-pie 5, it can be generated by P/T(:; and thereforePLPATR.
Slightly more generally, PLTG can gener-ate the language{w k Iw~L }for any k > 1 and context-free language L. Itappears that the class of languages generated byPI_TG is included in those languages generated byLinear Context-Free Rewriting Systems (Vijay-Shanker et al, 1987) since the construction in-volved in a proof of this underlies the recognitionalgorithm discussed in the next section.As is the case for the tree sets of 16, 1_16 andTree Adjoining Grammar, the tree sets generatedby PI_TG have path sets that.
are context-free lan-guages.
In other words, the set of all strings la-belling root to frontier paths of derivation treesis a context-free language.
While the tree setsof lAG and Tree Adjoining Grammars have inde-pendent branches, PI_T6 tree sets exhibit depen-dent branches, where the number of dependentbranches in any tree is bounded by the grammar.Note that the number of dependent branches inthe tree sets of 16 is not bounded by the grammar(e.g., they generate sets of all full binary trees).5 T ractab le  Recogn i t ionIn this section we outline the main ideas un-derlying a polynomial time recognition algorithmfor PlPATR that generalizes the CKY algorithm(Kasami, 1965; Younger, 1967).
The key to thisalgorithm is the use of structure sharing tech-niques similar to those used to process I_lG effi-ciently (Vijay-Shanker and Weir, 1993).
To un-derstand how these techniques are applied in thecase of PLPATR, it is therefore helpful to considerfirst the somewhat simpler case of I_lG.The CKY algorithm is a bottom-up recognitionalgorithm for CI=G.
For a given grammar G andinput string al .
.
.
a,~ the algorithm constructs anarray P, having n 2 elements, where element P\[i, j\]stores all and only those nonterminals of G thatderive the substring ai...aj.
A naive adapta-tion of this algorithm for I_lG recognition wouldinvolve storing a set of nonterminals and their as-sociated stacks.
But since stack length is at leastproportional to the length of the input string,the resultant algorithm would exhibit exponen-tial space and time complexity in the worst case.Vijay-Shanker and Weir (1993) showed that thebehaviour of the naive algorithm can be improvedupon.
In I_lG derivations the application of a rulecannot depend on more than a bounded portionof the top of the stack.
Thus, rather than storingthe whole of the.
potentially unbounded stack ina particular array entry, it suffices to store just79A\[~acr'\](a) / / /~yai B\[a~\]ap aqB\[a'~r\](b)a T aq A\[~'~ro"\]ai Bloc'or\] aja T aqFigure 6: "Context-Freeness' in I_IG derivationsa bounded portion together with a pointer to theresidue.Consider Figure 6.
Tree (a) shows a LIG deriva-tion of the substring hi .
.
.a j  from the objectA\[aaa'\].
In this derivation tree, the node labelledB\[aa\] is a distinguished escendant of the root sand is the first point below A\[c~rcr ~\] at which thetop symbol (or) of the (unbounded) stack aa  is ex-posed.
This node is called the terminator of thenode labelled A\[acr\].
It is not difficult to show thatonly that portion of the derivation below the ter-minator node is dependent on more than the topof the stack ha.
It follows that for any stack a'a,if there is a derivation of the substring %.. .hefrom B\[c~'c~\] (see tree (b)), then there is a cor-responding derivation of a i .
.
.a j  from A\[al~rcr '\](see tree (c)).
This captures the sense in whichI_IG derivations exhibit "context-freeness".
Effi-cient storage of stacks can therefore be achievedby storing in Pit, j\] just that bounded amount ofinformation (nonterminal plus top of stack) rele-vant to rule application, together with a pointer toany entry in Pip, q\] representing a subderivationfrom an object B\[c~'a\].2The stack aa associated with B is "inherited"from the stack associated with A at the root of thetree.Before describing how we adapt this techniqueto the case of PLPATR we discuss the sense inwhich PLPATR derivations exhibit a "context-freeness" property.
The constraints on PLPATRwhich we have identified in this paper ensure thatthese feature values can be manipulated indepen-dently of one another and that they behave ina stack-like way.
As a consequence, the storagetechnique used effectively for LIG recognition maybe generalized to the case of PLPATR.Suppose that we have the derived tree shownin Figure 7 where the nodes at the root of thesubtrees T1 and 7"2 are the so-called f-terminatorand g-terminator of the tree's root, respectively.Roughly speaking, the f-terminator of a node isthe node from which it gets the value for the fea-ture f ,  Because of the constraints on the formof PLPATR productions, the derivations betweenthe root of 7- and these terminators cannot in gen-eral depend on more than a bounded part of thefeature structures \ [ \ ]  and \[-~.
At the root of thefigure the feature structures \[-i-\] and \ [ \ ]  have beenexpanded to show the extent of the dependency inthis example.
In this case, the value of the featurein \[-~ must be a, whereas, the feature g is Y notfixed.
Furthermore, the value of the feature g inmust be b, whereas, the feature f is not fixed.This means, for example, that the applicability ofthe productions used on the path from the rootof rl to the root of r depends on the feature f in\ [ \ ]  having the value a but does not depend on thevalue of the feature g in \[~\].
Note that in this treethe value of the feature g in \[-~ is\[,:c\]F I= 9 Faand the value of the feature f in \ [~  isF~= g :dSuppose that, in addition to the tree shown inFigure 7 the grammar generates the pair of treesshown in Figure 8.
Notice that while the featurestructures at the root of r~ and r4 are not compat-ible with ~ and \[~\], they do agree with respectto those parts that are fully expanded at v's rootnode.
The "context-freeness" of PI_PATR meansthat given the three trees shown in Figures 7 and 8the tree shown in Figure 9 will also be generatedby the grammar.This gives us a means of efficiently storing thepotentially unbounded feature structures associ-ated with nodes in a derivation tree (derived fea-ture structures).
By analogy with the situation for80g:  F19 :bap aq ar asFigure 7: Terminators in PLPATR\['i \]\] \[!,F\]\] f : c j f : g : d j4 g: g F~ g:ap aq ar asFigure 8: Compatible subderivations9 F~ \]\[7\]g g :ap aq ar asFigure 9: Alternative derivationLIG, derived feature structures can be viewed asconsisting of a bounded part (relevant o rule ap-plication) plus unbounded information about thevalues of features.
For each feature, we store inthe recognition array a bounded amount of in-formation about its value locally, together with apointer to a further array element.
Entries in thiselement of the recognition array that are compat-ible (i.e.
unifiable) with the bounded, local infor-mation correspond to different possible values forthe feature.
For example, we can use a single en-try in the recognition array to store the fact thatall of the feature structures that can appear at theroot of the trees in Figure 9 derive the substringa i .
.
.a j .
This entry would be underspecified, forexample, the value of feature \[-~ would be spec-ified to be any feature stored in the array entryfor the substring ap... aq whose feature f had thevalue a.However, this is not the end of the story.
In con-trast to LIG, PLPATR licenses tructure sharing onthe right hand side of productions.
That is, par-tial linearity permits feature values to be sharedbetween daughters where they are not also sharedwith the mother.
But in that case, it appearsthat checking the applicability of a production atsome point in a derivation must entail the com-parison of structures of unbounded size.
In fact,this is not so.
The PLPATR recognition algorithmemploys a second array (called the compatibilityarray), which encodes information about the com-patibility of derived feature structures.
Tuples ofcompatible derived feature structures are storedin the compatibility array using exactly the sameapproach used to store feature structures in themain recognition array.
The presence of a tuplein the compatibility array (the indices of whichencode which input substrings are spanned) in-dicates the existence of derivations of compatiblefeature structures.
Due to the "context-freeness"of PLPATR, new entries can be added to the com-patibility array in a bottom-up manner based onexisting entries without the need to reconstructcomplete feature structures.6 Conc lus ionsIn considering ways of extending LIG, this paperhas introduced the notion of partial linearity andshown how it can be manifested in the form ofa constrained unification-based grammar formal-ism.
We have explored examples of the kinds oftree sets and string languages that this system cangenerate.
We have also briefly outlined the sensein which partial linearity gives rise to "context-freeness" in derivations and sketched how this can81be exploited in order to obtain a tractable recog-nition algorithm.7 AcknowledgementsWe thank Roger Evans, Gerald Gazdar~ AravindJoshi, Bernard Lang, Fernando Pereira, MarkSteedman and K. Vijay-Shanker for their help.ReferencesMartin Emele.
1991.
Unification with lazy non-redundant copying.
In 29 th meeting Assoc.Comput.
Ling., pages 323--330, Berkeley, CA.G.
Gazdar.
1988.
Applicability of indexed gram-mars to natural languages.
In U. Reyle andC.
Rohrer, editors, Natural Language Parsingand Linguistic Theories, pages 69--94.
D. Rei-del, Dordrecht, Holland.Dale Gerdemann.
1989.
Using restrictions tooptimize unification parsing.
In InternationalWorkshop of Parsing Technologies, pages 8--17, Pittsburgh, PA.Kurt Godden.
1990.
Lazy unification.
In 28 thmeeting Assoc.
Comput.
Ling., pages 180--187,Pittsburgh, PA.S.
P. Harrison and T. M. Ellison.
1992.
Restric-tion and termination i  parsing with feature-theoretic grammars.
Computational Linguis-tics, 18(4):519--531.L.
Karttunen and M. Kay.
1985.
Structure shar-ing with binary trees.
In 23 th meeting Assoc.Comput.
Ling., pages 133--136.T.
Kasami.
1965.
An efficient recognition andsyntax algorithm for context-free languages.Technical Report AF-CRL-65-758, Air ForceCambridge Research Laboratory, Bedford, MA.Kiyoshi Kogure.
1990.
Strategic lazy incrementalcopy graph unification.
In 13 ?` InternationalConference on Comput.
Ling., pages 223--228,Helsinki.P.
C. N. Pereira.
1985.
A structure-sharingrepresentation for unification-based grammarformalisms.
In 23 ~h meeting Assoc.
Comput.Ling., pages 137--144.S.
M. Shieber.
1984.
The design of a computerlanguage for linguistic information.
In 10 thInternational Conference on Comput.
Ling.,pages 363-366.S.
M. Shieber.
1985.
Using restriction to ex-tend parsing algorithms for complex-feature-based formalisms.
In 23 rd meeting Assoc.
Corn-put.
Ling., pages 82-93.Hideto Tomabechi.
1991.
Quasi-destructivegraph unification.
In 29 th meeting Assoc.
Corn-put.
Ling., pages 315--322, Berkeley, CA.K.
Vijay-Shanker and D. J. Weir.
1993.
Parsingsome constrained grammar formalisms.
Com-putational Linguistics, 19(4):591--636.K.
Vijay-Shanker and D. a. Weir.
1994.
Theequivalence of four extensions of context-freegrammars.
Math.
Syst.
Theory, 27:511-546.K.
Vijay-Shanker, D. J. Weir, and A. K. Joshi.1987.
Characterizing structural descriptionsproduced by various grammatical formalisms.In 25 th meeting Assoc.
Comput.
Ling., pages104-111.David Wroblewski.
1987.
Nondestructive graphunification.
In 6 th National Conference on Arti-ficial Intelligence, pages 582--587, Seattle, WA.D.
H. Younger.
1967.
Recognition and parsing ofcontext-free languages in time n 3.
Informationand Control, 10(2):189-208.82
