Temporal Discourse Models for Narrative StructureInderjeet MANIDepartment of LinguisticsGeorgetown UniversityICC 452Washington, DC 20057im5@georgetown.eduJames PUSTEJOVSKYDepartment of Computer ScienceBrandeis UniversityVolen 258Waltham, Massachusetts 02254jamesp@cs.brandeis.eduAbstractGetting a machine to understand humannarratives has been a classic challenge forNLP and AI.
This paper proposes a newrepresentation for the temporal structure ofnarratives.
The representation is parsimonious,using temporal relations as surrogates fordiscourse relations.
The narrative models,called Temporal Discourse Models, are tree-structured, where nodes include abstractevents interpreted as pairs of time points andwhere the dominance relation is expressed bytemporal inclusion.
Annotation examples andchallenges are discussed, along with a reporton progress to date in creating annotatedcorpora.1 IntroductionGetting a machine to understand human narrativeshas been a classic challenge for NLP and AI.Central to all narratives is the notion of time andthe unfolding of events.
When we understand astory, in addition to understanding other aspectssuch as plot, characters, goals, etc., we are able tounderstand the order of happening of events.
Agiven text may have multiple stories; when weunderstand such a text, we are able to tease apartthese distinct stories.
Thus, understanding the storyfrom a text involves building a global model of thesequences of events in the text, as well as thestructure of nested stories.
We refer to such modelsas Temporal Discourse Models (TDMs).Currently, while we have informaldescriptions of the structure of narratives, e.g.,(Bell 1999), we lack a precise understanding ofthis aspect of discourse.
What sorts of structuralconfigurations are observed?
What formalcharacteristics do they have?
For syntacticprocessing of natural languages, we have,arguably, answers to similar questions.
However,for discourse, we have hardly begun to ask thequestions.One of the problems here is that most ofthe information about narrative structure is implicitin the text.
Thus, while linguistic information inthe form of tense, aspect, temporal adverbials anddiscourse markers is often present, people usecommonsense knowledge to fill in information.Consider a simple discourse: Yesterday Holly wasrunning a marathon when she twisted her ankle.David had pushed her.
Here, aspectual informationindicates that the twisting occurred during therunning, while tense suggests that the pushingoccurs before the twisting.
Commonsenseknowledge also suggests that the pushing causedthe twisting.We can see that even for interpreting suchrelatively simple discourses, a system mightrequire a variety of sources of linguisticknowledge, including knowledge of tense, aspect,temporal adverbials, discourse relations, as well asbackground knowledge.
Of course, otherinferences are clearly possible, e.g., that therunning stopped after the twisting, but whenviewed as defaults, these latter inferences seem tobe more easily violated.
The need forcommonsense inferences has motivatedcomputational approaches that are domain-specific, using hand-coded knowledge (e.g., Asherand Lascarides 2003, Hitzeman et al 1995).A number of theories have postulated theexistence of various discourse relations that relateelements in the text to produce a global model ofdiscourse, e.g., (Mann and Thompson 1988),(Hobbs 1985), (Hovy 1990) and others.
In RST(Mann and Thompson 1988), (Marcu 2000), theserelations are ultimately between semantic elementscorresponding to discourse units that can be simplesentences or clauses as well as entire discourses.
InSDRT (Asher and Lascarides 2003), these relationsare between representations of propositionalcontent, called Discourse RepresentationStructures (Kamp and Reyle, 1993).Despite a considerable amount of veryproductive research, annotating such discourserelations has proved problematic.
This is due to thefact that discourse markers may be absent (i.e.,implicit) or ambiguous; but more importantly,because in many cases the precise nature of thesediscourse relations is unclear.
Although (Marcu etIn addition to T1, we also have thetemporal ordering constraints C1:  {Eb < Ec, Ec <Ea, Ea < Ed}.
These are represented separatelyfrom the tree.
A TDM is thus a pairing of treestructures and temporal constraints.
Moreprecisely, a Temporal Discourse Model for a text isa pair <T, C>, where T is a rooted, unordered,directed tree with nodes N = ?E ?
A?, where E isthe set of events mentioned in the text and A is aset of abstract events, and a parent-child orderingrelation, ?
(temporal inclusion).
A non-leaf nodecan be textually mentioned or abstract.
Nodes alsohave a set of atomic-valued features.
Note that thetree is temporally unordered left to right.
C is a setof temporal ordering constraints using the orderingrelation, < (temporal precedence) as well as (forstates, clarified below) ?minimal restrictions?
onthe above temporal inclusion relation (expressed asa ?min).al.
1999) (Carlson et al 2001) reported relativelyhigh levels of inter-annotator agreement, this wasbased on an annotation procedure where theannotators were allowed to iteratively revise theinstructions based on joint discussion.While we appreciate the importance ofrepresenting rhetorical relations in order to carryout temporal inferences about event ordering, webelieve that there are substantial advantages inisolating the temporal aspects and modeling themseparately as TDMs.
This greatly simplifies therepresentation, which we discuss next.2 Temporal Discourse ModelsA TDM is a tree-structured syntactic model ofglobal discourse structure, where temporalrelations are used as surrogates for discourserelations, and where abstract events correspondingto entire discourses are introduced as nodes in thetree.
In (1) the embedding nodes E0 and E1 were abstract, but textually mentioned events canalso create embeddings, as in (2) (example from(Spejewski 1988)):We begin by illustrating the basicintuition.
Consider discourse (1), from (Webber1988): (2) a. Edmond made his own Christmaspresents this year.
b.
First he dried a bunchof tomatoes in his oven.
c. Then he made abooklet of recipes that use dried tomatoes.
d.He scanned in the recipes from his gourmetmagazines.
e. He gave these gifts to hisfamily.
(1) a. John went into the florist shop.b.
He had promised Mary some flowers.c.
She said she wouldn?t forgive him if heforgot.
d. So he picked out three red roses.The discourse structure of (1) can berepresented by the tree, T1, shown below.T2 =                 E0               E0                    Ea                Ee               Ea         E1                      Ed                  Eb    Ec                                          Ed                        Eb       Ec               Here E0 has children Ea, E1, and Ed, andE1 has children Eb and Ec.
The nodes withalphabetic subscripts are events mentioned in thetext, whereas nodes with numeric subscripts areabstract events, i.e., events that represent abstractdiscourse objects.
A node X is a child of node Y iffX is temporally included in Y.
In our scheme,events are represented as pairs of time points.
So,E0 is an abstract node representing a top-levelstory, and E1 is an abstract node representing anembedded story.
Note that the mentioned eventsare ordered left to right in text order for notationalconvenience, but no temporal ordering is directlyrepresented in the tree.
Since the nodes in thisrepresentation are at a semantic level, the treestructure is not necessarily isomorphic to arepresentation at the text level, although T1happens to be isomorphic.C2 = {Ea < Ee, Eb < Ec}Note that the partial ordering C can beextended using T and temporal closure axioms(Setzer and Gaizauskas 2001), (Verhagen 2004), sothat in the case of <T2, C2>, we can infer, forexample, that Eb < Ed, Ed < Ee, and so forth.In representing states, we take aconservative approach to the problems oframification and change (McCarthy and Hayes1969).
This is the classic problem of recognizingwhen states (the effects of actions) change as aresult of actions.
Any tensed stative predicate willbe represented as a node in the tree (progressivesare here treated as stative).
Consider an examplelike John walked home.
He was feeling great.Here we represent the state of feeling great asbeing minimally a part of the event of walking,without committing to whether it extends before orafter the event.
While this is interpreted as anoverloaded temporal inclusion in the TDM tree, aconstraint is added to C indicating that thisinclusion is minimal.This conservative approach results inlogical incompleteness, however.
For example,given the discourse Max entered the room.
He waswearing a black shirt, the system will not knowwhether the shirt was worn after he entered theroom.
States are represented as bounded intervals,and participate in ordering relations with events inthe tree.
It is clear that in many cases, a stateshould persist throughout the interval spanningsubsequent events.
This is not captured by thecurrent tree representation.
Opposition structuresof predicates and gating operations over propertiescan be expressed as constraints introduced byevents, however, but at this stage of development,we have been interested in capturing a coarsertemporal ordering representation, very robustly.We believe, however, that annotation using theminimal inclusion relation will allow us to reasonabout persistence heuristically in the future.3 PrerequisitesPrior work on temporal information extraction hasbeen fairly extensive and is covered in (Mani et al2004).
Recent research has developed the TimeMLannotation scheme (Pustejovsky et al 2002)(Pustejovsky et al 2004), as well as a corpus ofTimeML-annotated news stories (TimeBank 2004)and annotation tools that go along with it, such asthe TANGO tool (Pustejovsky et al 2003).TimeML flags tensed verbs, adjectives, andnominals that correspond to events and states,tagging instances of them with standard TimeMLattributes, including the class of event (perception,reporting, aspectual, state, etc.
), tense (past,present, future), grammatical aspect (perfective,progressive, or both), whether it is negated, anymodal operators which govern it, and itscardinality if the event occurs more than once.Likewise, time expressions are flagged, and theirvalues normalized, so that Thursday in He left onThursday would get a resolved ISO time valuedepending on context  (TIMEX2 2004).
Finally,temporal relations between events and timeexpressions (e.g., that the leaving occurs duringThursday) are recorded by means of temporal links(TLINKs) that express Allen-style intervalrelations (Allen 1984).Several automatic tools have beendeveloped in conjunction with TimeML, includingevent taggers (Pustejovsky et al 2003), timeexpression taggers (Mani and Wilson 2000), andan exploratory link extractor (Mani et al 2003).Temporal reasoning algorithms have also beendeveloped, that apply transitivity axioms to expandthe links using temporal closure algorithms (Setzerand Gaizauskas 2001), (Pustejovsky et al 2003).However, TimeML is inadequate as atemporal model of discourse: it constructs noglobal representation of the narrative structure,instead annotating a complex graph that linksprimitive events and times.4 Related FrameworksSince the relations in TDMs involve temporalinclusion and temporal ordering, the mentionedevents can naturally be mapped to other discourserepresentations used in computational linguistics.A TDM tree can be converted to a first-ordertemporal logic representation (where temporalordering and inclusion operators are added) byexpanding the properties of the nodes.
Theseproperties include any additional predicationsmade explicitly about the event, e.g., informationfrom thematic arguments and adjuncts.
In otherwords, a full predicate argument representation,e.g., as might be found in the PropBank(Kingsbury and Palmer 2002), can be associatedwith each node.TDMs can also be mapped to DiscourseRepresentation Structures (DRS) (which in turncan be mapped to a logical form).
Since TDMsrepresent events as pairs of time points (which canbe viewed as intervals), and DRT represents eventsas primitives, we can reintroduce time intervalsbased on the standard DRT approach (e ?
t forevents,  e O t for states, except for present tensestates, where t ?
e).Consider an example from the DiscourseRepresentation Theory (DRT) literature (fromKamp and Reyle 1993):(3) a.
A man entered the White Hart.
b. Hewas wearing a black jacket.
c. Bill servedhim a beer.The TDM is <T3, C3> below, withinternal properties of the nodes as shown:T3 =      E0Ea          EcEbC3 = {Ea < Ec}node.properties(Ea): enter(Ea, x, y),man(x), y= theWhiteHart, Ea < nnode.properties(Eb): PROG(wear(Eb, x1,y1)), black-jacket(y1), x1=x, Eb < n,node.properties(Ec): serve(Ec, x2, y2, z),beer(z), x2=Bill, y2=x, Ec < nFrom T3: Eb ?
EaFrom C3: Ea < EcThe DRT representation is shown below(here we have created variables for thereference times):Note that we are by no means claimingthat DRSs and TDMs are equivalent.
TDMs aretree-structured and DRSs are not, and the inclusionrelations involving our abstract events, i.e., Ea ?E0 and Ec ?
E0, are not usually represented inDRT.
Nevertheless, there are many similaritiesbetween TDMs and DRT which are worthexamining for semantic and computationalproperties.
Furthermore, SDRT (Asher andLascarides 2003) extends DRT to includediscourse relations.
SDRT and RST both differfundamentally from TDMs, since we dispense withrhetorical relations.It should be pointed out, nevertheless, thatTDMs, as modeled so far, do not representmodality and intensional contexts in the treestructure.
(However, information about modalityand negation is stored in the nodes based onTimeML preprocessing).
One way of addressingthis issue is to handle lexically derived modalsubordination (such as believe and want) byintroducing embedded events, linked to the modalpredicate by subordinating relations.
For example,in the sentence John believed that Mary graduatedfrom Harvard, the complement event isrepresented as a subtree linked by a lexicalrelation.DLTAG (Webber et al 2004) is a modelof discourse structure where explicit or implicitdiscourse markers relating only primitive discourseunits.
Unlike TDMs, where the nodes in the treecan contain embedded structures, DLTAG is alocal model of discourse structure; it thus providesa set of binary relations, rather than a tree LikeTDMs, however, DLTAG models discoursestructure without postulating the existence ofrhetorical relations in the discourse tree.
Instead,the rhetorical relations appear as predicates in thesemantic forms for discourse markers.
In thisrespect, they differ from TDMs, which do notcommit to specific rhetorical relations.Spejewski (1994) developed a tree-basedmodel of the temporal structure of a sequence ofsentences.
Her approach is based on relations oftemporal coordination and subordination, and isthus a major motivation for our own approach.However, her approach mixes both reference timesand events in the same representation, so that theparent-child relation sometimes representstemporal anchoring, and at other timescoordination.
In the above example of John walkedhome.
He was feeling great, her approach wouldrepresent the ?reference time?
of the state (offeeling great) as being part of the event of walkingas well as part of the state, resulting in a graphrather than a strict tree.
Note that our approachuses minimality.Ea, x, y , Eb, x1, y1, Ec, x2, y2, z,t1, t2, t3enter(Ea, x, y), man(x), y=theWhiteHartPROG(wear(Eb, x1, y1)), black-jacket(y1), x1=xserve(Ec, x2, y2, z), beer(z),x2=Bill, y2=xt1 < n, Ea ?
t1, t2 < n, Eb ?
t2, Eb?
Ea, t3 < n, Ec ?
t3, Ea < Ec(Hitzeman et al 1995) developed acomputational approach to distinguish varioustemporal threads in discourse.
The idea here, basedon the notion of temporal centering, is that there isone ?thread?
that the discourse is currentlyfollowing.
Thus, in (1) above, each utterance isassociated with exactly one of two threads: (i)going into the florist?s shop and (ii) interactingwith Mary.
Hitzeman et al prefer an utterance tocontinue a current thread which has the same tenseor is semantically related to it, so that in (1) above,utterance d would continue the thread (i) abovebased on tense.
In place of world knowledge,however, semantic distance between utterances isused, presumably based on lexical relationships.Whether such semantic similarity is effective is amatter for evaluation, which is not discussed intheir paper.
For example, it isn?t clear what wouldrule out (1c) as continuing thread (i).While TDMs do not commit to rhetoricalrelations, our expectation is that they can be usedas an intermediate representation for rhetoricalparsing.
Thus, when event A in a TDM temporallyprecedes its right sibling B, the rhetorical relationof Narration will typically be inferred.
When Bprecedes is left sibling A, then Explanation willtypically be inferred.
When A temporally includesa child node B, then Elaboration is typicallyinferred, etc.
TDMs are thus a useful shallowrepresentation that can be a useful first step inderiving rhetorical relations; indeed, rhetoricalrelations may be implicit in the human annotationof such relations, e.g., when explicit discoursemarkers like ?because?
indicate a particulartemporal order.5 Annotation SchemeThe annotation scheme involves taking eachdocument that has been preprocessed with timeexpressions and event tags (complying withTimeML) and then representing TDM parse treesand temporal ordering constraints (the latter alsocompliant with TimeML TLINKS).Each discourse begins with a root abstractnode.
As an annotation convention, (A1) in theabsence of any overt or covert discourse markersor temporal adverbials, a tense shift will license thecreation of an abstract node, with the event withthe shifted tense being the leftmost daughter of theabstract node.
The abstract node will then beinserted as the child of the immediately precedingtext node.
In addition, convention (A2) states thatin the absence of temporal adverbials and overt orcovert discourse markers, a stative event willalways be placed as a child of the immediatelypreceding text event when the latter is non-stative.Further, convention (A3) states that when theprevious event is stative, in the absence oftemporal adverbials and explicit or implicitdiscourse markers, the stative event is a sibling ofthe previous stative (as in a scene-setting fragmentof discourse).We expect that inter-annotator reliabilityon TDM trees will be quite high, given thetransparent nature of the tree structure along withclear annotation conventions.
The Appendicesprovide examples of annotation, to illustrate thesimplicity of the scheme as well as potentialproblems.6  CorporaWe have begun annotating three corpora withTemporal Discourse Model information.
The firstis the Remedia corpus (remedia.com).
There are115 documents in total, grouped into four readinglevels, all of which have been tagged by a humanfor time expressions in a separate project by LisaFerro at MITRE.
Each document is short, about237 words on average, and has a small number ofquestions after it for reading comprehension.The Brandeis Reading Corpus is acollection of 100 K-8 Reading Comprehensionarticles, mined from the web and categorized bylevel of comprehension difficulty.
Articles rangefrom 50-350 words in length.
Complexity of thereading task is defined in terms of five basicclasses of reading difficulty.The last is the Canadian BroadcastingCorporation (cbc4kids.ca).
The materials arecurrent-event stories aimed at an audience of 8-year-old to 13-year-old students.
The stories areshort (average length around 450 words).
Morethan a thousand articles are available.
TheCBC4Kids corpus is already annotated with POSand parse tree markup.7 ConclusionOur assumption so far has been that the temporalstructure of narratives is tree-structured andcontext-free.
Whether the context-free property isviolated or not remains to be seen.Once the annotation effort is completed,we plan to use the annotated corpora in statisticalparsing algorithms to construct TDMs.
This shouldallow features from the corpus to be leveragedtogether to make inferences about narrativestructure.
While such knowledge sourcecombination is not by any means guaranteed tosubstitute for commonsense knowledge, it at leastallows for the introduction of generic, machinelearning methods for extracting narrative structurefrom stories in any domain.
Earlier work in a non-corpus based (Hitzeman et al 1995) as well ascorpus-based setting (Mani et al 2003) attests tothe usefulness of combining knowledge sources forinferring temporal relations.
We expect to leveragesimilar methods in TDM parsing.We believe that the temporal aspect ofdiscourse provides a handle for investigatingdiscourse structure, thereby simplifying theproblem of discourse structure annotation.
It istherefore of considerable theoretical interest.Further, being able to understand the structure ofnarratives will in turn allow us to summarize themand answer temporal questions about narrativestructure.ReferencesJ.
F. Allen.
1984.
Towards a General Theory ofAction and Time.
Artificial Intelligence 23:123-154.N.
Asher and A. Lascarides.
2003.
Logics ofConversation.
Cambridge University Press.A.
Bell.
1999.
News Stories as Narratives.
In A.Jaworski and N. Coupland, The DiscourseReader, Routledge, London and New York, 236-251.L.
Carlson, D. Marcu and M. E. Okurowski.
2001.Building a discourse-tagged corpus in theframework of rhetorical structure theory.
InProceedings of the 2nd SIGDIAL Workshop onDiscourse and Dialogue, Eurospeech 2001,Aalborg, Denmark.B.
Grosz, A. Joshi and S. Weinstein.
1995.Centering: A Framework for Modeling theLocal Coherence of Discourse.
ComputationalLinguistics 2(21), pp.
203-225J.
Hitzeman, M. Moens and C. Grover.
1995.Algorithms for Analyzing the TemporalStructure of Discourse.
In Proceedings of theAnnual Meeting of the European Chapter of theAssociation for Computational Linguistics,Utrecht, Netherlands, 1995, 253-260.J.
Hobbs.
1985.
On the Coherence and Structure ofDiscourse.
Report No.
CSLI-85-37.
Stanford,California: Center for the Study of Languageand Information, Stanford University.E.
Hovy.
1990.
Parsimonious and ProfligateApproaches to the Question of DiscourseStructure Relations.
In Proceedings of the FifthInternational Workshop on Natural LanguageGeneration.H.
Kamp and U. Reyle.
1993.
Tense and Aspect.Part 2, Chapter 5 of From Discourse to Logic,483-546.P.
Kingsbury and M. Palmer.
2002.
FromTreebank to PropBank.
In Proceedings of the3rd International Conference on LanguageResources and Evaluation (LREC-2002), LasPalmas, Spain.I.. Mani, B. Schiffman and J. Zhang.
2003.Inferring Temporal Ordering of Events in News.Proceedings of the Human LanguageTechnology Conference, HLT?03.I.
Mani and G. Wilson.
2000.
Processing of News.Proceedings of the 38th Annual Meeting of theAssociation for Computational Linguistics(ACL'2000), 69-76.I.
Mani, J. Pustejovsky and R. Gaizauskas.
2004.The Language of Time: A Reader.
OxfordUniversity Press, to appear.W.
Mann and S. Thompson.
1988.
Rhetoricalstructure theory: Toward a functional theory oftext organization.
Text, 8(3): 243-281.D.
Marcu.
2000.
The Theory and Practice ofDiscourse Parsing and Summarization.
TheMIT Press.D.
Marcu, E. Amorrortu and M. Romera.
1999.Experiments in constructing a corpus ofdiscourse trees.
In Proceedings of the ACLWorkshop on Standards and Tools for DiscourseTagging, College Park, MD, 48-57.J.
McCarthy and P. Hayes.
1969.
Somephilosophical problems from the standpoint ofartificial intelligence.
In B.Meltzer and D.Michie, Eds.
Machine Intelligence 4.J.
Pustejovsky, B. Ingria, R. Sauri, J. Castano, J.Littman, R. Gaizauskas, A. Setzer, G. Katz andI.
Mani.
2004.
The Specification LanguageTimeML.
In I. Mani, J. Pustejovsky and R.Gaizauskas.
The Language of Time: A Reader.Oxford University Press, to appear.A.
Setzer and R. Gaizauskas.
2001.
A Pilot Studyon Annotating Temporal Relations in Text.
ACL2001, Workshop on Temporal and SpatialInformation ProcessingB.
Spejewski.
1994.
Temporal Subordination inDiscourse.
.Ph.D.
Thesis, University ofRochester.J.
Pustejovsky, I. Mani, L. Belanger, B. Boguraev,B.
Knippen, J. Littman, A. Rumshisky, A. See,S.
Symonenko, J.
Van Guilder, L. Van Guilder,M.
Verhagen, R. Ingria.
2003.
TANGO FinalReport.
timeml.org.J.
Pustejovsky, L. Belanger, J. Castano, R.Gaizauskas, P. Hanks, R. Ingria, G. Katz, D.Radev, A. Rumshisky, A. Sanfilippo, R. Sauri,B.
Sundheim, M. Verhagen.
2002.
TERQASFinal Report.
timeml.org.TIMEBANK.
2004. timeml.org.TIMEX2.
2004. timex2.mitre.org.B.
Webber.
1998.
Tense as Discourse Anaphor.Computational Linguistics 14(2): 61-73.B.
Webber, M. Stone, A. Joshi and A. Knott.
2003.Computational Linguistics, 29:4, 545-588.Appendix A: Examples from (Hitzeman et al1995)1.
(a) John entered the room.
(b) Mary stoodup.Ea is inserted as left daughter of root.
Eb isattached as sister (an analogue of a Narrationdefault rhetorical relation).E0Ea   EbC: Ea<Eb2.
(a) John entered the room.
(b) Mary wasseated behind the desk.Ea is anchored as left daughter of root.
Eb is atensed stative, and is embedded below Ea.E0EaEa E1 E2   EbC: Eb ?min EaEb         Ec 3.
(a) John fell.
(b) Mary pushed him.C: Eb<Ea, Ec<Eb7.
(a) John got to work late.
(b) He had leftthe house at 8.
(c) He had eaten a bigbreakfast.E0Ea  EbE0  C: Eb<Ea4.
(a) John entered the room because (b) Marystood up.
Ea E1 E2E0Eb         EcC: Eb<Ea, Ec<Eb  Ea  EbC: Eb<EaThis is due to the ?because?-inversion rule.Appendix B: Level 200 Story from the BrandeisReading Corpus 5.
(a) Mary was tired.
(b) She was exhausted.a.
David wants to buy a Christmas present for avery special person, his mother.E0b.
David's father gives him $5.00 a week pocketmoney andEac.
David puts $2.00 a week into his bankaccount.d.
After three months David takes $20.00 out ofhis bank account andEbC: Eb ?min Eae.
goes to the shopping mall.f.
He looks and looks for a perfect gift.
This case, unlike (2), would be an analogue of anElaboration relation.
Here, other knowledgesources, such as a centering (Grosz et al 1995)could play a role in inferring such a discourserelation.g.
Suddenly he sees a beautiful brooch in theshape of his favorite pet.h.
He says to himselfi.
"Mother loves jewelry, andj.
the brooch costs only $l7.00."k.
He buys the brooch and  6.
(a) Sam rang the bell.
(b) He had lost the key.
(c) It had fallen through a hole in his pocket.
l. takes it home.m.
He wraps the present in Christmas paper andn.
places it under the tree.
Ea is attached as right branching event.
Eb isattached as sister with precedence constraintrelative to Ea coming from the past perfectmarking.
Ec is attached as sister with precedenceconstraint relative to Eb coming from past perfect.Losing the key is explained by (or elaborated by)the description of the key falling through the hole.Hence, it should be an embedding relation on thisreading.
Nevertheless, the current parse is arguablycorrect since the falling caused the loss of the key.o.
He is very excited andp.
he is looking forward to Christmas morning tosee the joy on his mother's face.q.
But when his mother opens the presentr.
she screams with fright becauses.
she sees a spider.Ea, Eb, and Ec are all statively interpreted due tothe presence of modification by frequencyadverbial TIMEX3 expressions (from TimeML),giving rise to habitual event interpretations.
Theyare embedded inside an abstract E0 node.E0E3E0Eq Er EsEa Eb EcC: Eq<Er, Es<Er, Eq<Es  C: Ea ?min E0, Eb ?min E0, Ec ?min E0E1 is created with the recognition of the timeexpression ?after three months?.
Ed is attached asthe left daughter node in E1.
Ee is attached assister (default Narrative).
Similarly for Ef, Eg, andEh.The TDM for the  entire article isrepresented below:E1Ed Ee Ef Eg EhC: Ed<Ee, Ee<Ef, Ef<Eg, Eg<EhThe syntactically embedded sentences in (i) and(j) are recognized as states and are embeddedwithin Eh.E1Ed Ee  Ef  Eg  EhEi                EjC: Ed<Ee, Ee<Ef, Ef<Eg, Eg<Eh, Ei in Eh, Ej inEhAttachment and narrative order holds for Ek,El, Em, and En.
The states in Eo and Ep willbe embedded under En:E1Ed  Ee  Ef  Eg  Eh  Ek    El   Em     EnEi     Ej          Eo      EpThe presence of ?when?
as a TimeML signalcreates a new abstract event, E3, and thesubsequent ordering relation E3>E2.Finally, narration continues under E3 with Eq,Er, and Es, as daughters to E3, with the additionalconstraint of ?because-inversion?, Es<Er.
