LANGUAGE RESEARCH SPONSORED BY ONRSusan ChipmanProgram Manager, Cognitive ScienceOffice of Naval ResearchArlington, VA 22217-5660In contrast o DARPA, ONR has not had a definedprogram that is focused exclusively on languageresearch.
However, there have been someclusters of projects concerned with language thathave been supported within the Cognitive ScienceProgram and its prior incarnation, the Personneland Training Research Program.
The ONRprogram is a basic research program, but amission-oriented one which seeks to generateresults that will prove applicable to significantNavy applications.
Traditionally, as the earliername indicates, those applications were soughtprimarily in training; more recently, the targetshave been broadened to include human factorsapplications, especially in human-systeminteraction.
Originally, the program was apsychological research program, but it evolvedinto a cognitive science program, the firstgovernment research program to be so labeled.The ONR Cognitive Science Program emphasizesthe use of AI techniques to model humancognitive performance, and it has alsoemphasized the special sub-field of AI concernedwith artificially intelligent computerized instructionor tutoring systems (ICAI or ITS).
Thus, the ONRCognitive Science Program also contrasts withthe DARPA Human Language TechnologyProgram in being concerned with understandinghow human language actually is produced andprocessed by humans.
(There is also an AIprogram within the Computer Science Division ofONR.)
The management style of the programmight be best described as dvnamic coherence.That is, a degree of coherence or focus isnecessary in order to enhance the likeliho(x:l ofidentifiable impact on application areas, but thefocal clusters do evolve over time, partially inresponse to promising proposals that arereceived.
New proposals are judged partially bythe extent o which they cohere with and enhancethe current portfolio of projects, not merely onisolated merit and inclusion in the broad area ofcognitive science.
Two salient clusters oflanguage-related research that emerged havebeen the currently active emphasis on tutorialdiscourse and an eadier interest in improvingthe readability of instructional texts anddocumentation.
Both have had significantnatural language AI aspects, but not allprojects have involved computation.TUTORIAL DISCOURSEThis cluster of projects follows earlier majorinvestments in artificially intelligent utoringsystems.
The striking effectiveness of one-on-one tutorial instruction by human tutors(estimated to be a 2 standard deviationimprovement over conventional classroominstruction) has sparked great interest inefforts to emulate that effectiveness withartificially intelligent computerizedinstructional systems.
Despite enoughsuccess in that endeavor to make theproduction of intelligent tutoring systems amore applied research or developmentactivity, present intelligent utoring systemscircumvent, evade, and finesse the problemof natural language interaction in variousways because the demands of tutorialinteraction are really beyond the state of theart in computerized natural anguage.
In theONR Cognitive Science Program, humantutorial interaction is being studied from theperspectives of linguists, psychologists, andcomputational linguists who aim to emulate itin artificial systems.
Among the issues thatarise in these studies are the size or scope ofthe discourse organization imparted by thetutor, the balance between the tutor's agendaand immediate responsiveness to the student,the extent to which tutors revise their plansdynamically, the nature and breadth ofknowledge required to support theseinteractions, the relationship between tutorialinteraction and normal conversationalpatterns, and the nature of repair andcorrection processes, including the use of290positive, neutral and negative feedback.
The easeor feasibility of emulating these features of humantutorial discourse certainly varies, but it is alsotrue that the introduction of a computer as aconversational participant is a significant change:what is the perceived social status or role of acomputer?
Similarly, it is possible that idealcomputerized tutorial discourse might differ fromwhat is observed among humans.
The diverseresearch perspectives required to address theseissues typify the interdisciplinary character ofcognitive science.Apart from some Informal studies conductedwithin larger projects concerned with buildingearly intelligent utodng systems, the first of theserecent studies of tutorial discourse was conductedby Barbara Fox, a linguist at the University ofColorado.
Her primary data were four hour-longsessions of math/science tutoring which werevideo-taped and transcribed in a very detailedway that records pauses and non-verbal behavior(according to the methods of Sacks, Schegloffand Jefferson).
She focused on correction andrepair processes in tutorial discourse.
Sheconcluded that tutors structure correction activityso as to enable students to correct their ownerrors, whenever possible.
Tutoring, in spite of itsemphasis on learning, and therefore on makingand correcting mistakes, is organized by thesame principle of correction that organizeseveryday conversation -- the preference for selfcorrection.
She found that tutors make heavy useof pre-correction strategies and of silence, inorder to accomplish this preference for selfcorrection (on the part of the students).
Pre-correction strategies signal an upcomingcorrection from the tutor; they serve to alert thestudent o the possibility of that she has made anerror.
The student can then engage in trying tofigure out what the error might be, and then cantry to correct it him/herself.
Throughout thisprocess, the tutor provides further feedback to thestudent to indicate whether or not the student ison the right track.
Tutors also give students aconsiderable amount of time in answeringquestions before they step in to redirect orcorrect (depending on the context, the silencecan be from 1 to 5 seconds or so).
That is, tutorsoften wait to see if the student will serf correct.And tutors do not force an immediate answer;they give the student time to address thequestion.
If the student is displaying obvioussigns of being lost or stuck, however, the tutorprovides immediate guidance.
Fox alsostudied some tutorial sessions conducted byteletype in which the tutees were led tobelieve that the tutor was a computer.
Thesesessions revealed some interestingdifferences in interaction.
Students expecttutoring computers to be capable of complexnumerical computations, and they feel free toleave dead time and to make off-the-wallremarks.
These students appeared to believethat they actually were interacting with acomputer.A project by Arthur Greesser at MemphisState that is still on-going includes muchlarger samples of interacting students andtutors.
One sample was of school childrenbeing tutored in arithmetic.
Another analyzedinteraction patterns in 44 one-hour tutoringsessions involving college students.Undergraduate students were tutored bygraduate students on troublesome topics in aresearch methods course in psychology (e.g.,variables, statistics, factorial designs,hypothesis testing).
Similar to Fox, theprimary focus was on collaborativeexchanges and feedback mechanisms duringquestion asking and question answering.Graesser has identified substantial problemsin knowledge tracking and feedbackmechanisms between student and tutor; thepragmatic principles of politeness andcooperativity during conversation oftenseemed to present a barrier to effectivepedagogy during tutoring.
The relationshipbetween student question asking and level ofachievement has been analyzed, as well asthe way tutors handled student errors.
Amodel of tutorial interaction is beingdeveloped which specifies dialogue patterns,pragmatic assumptions, goal structures, andpedagogical strategies during question askingand answering.
Although the present projectdoes not include artificial production oftutoring dialogue, Graesser, a psychologistwith a joint appointment in computer science,has previously done computer simulations ofquestion asking and answering.
He regardsthese studies of naturalistic tutoring as anecessary preliminary to the design ofeffective dialogue facilities in intelligenttutoring systems, although he believes thatthere might be ways in which artificial tutorialdialogue could improve upon the natural.291Two other current projects do involve artificialproduction of tutorial dialogue.
Martha Evens, acomputational linguist at liT, has been working todevelop an intelligent tutoring system withgenuine natural language interaction capacity.She and her collaborators are building anintelligent tutoring system that can carry out atutorial dialogue with first year medical students,helping them to understand the negative feedbacksystem that controls blood pressure, guiding themin building a qualitative, causal mental model ofthe system.
With the goal of understanding howhuman tutors generate tutorial dialogues in thissituation, they have captured seven face-to-faceand thirty-seven keyboard-to-keyboard tutoringsessions, each lasting an hour or more.
Thetutors are professors of physiology at RushMedical College; the students are first yearmedical students from their classes.
The study ofhuman tutoring sessions reveals many exampleswhere the expert tutors produce large-scalediscourse structures: multi-turn discoursestructures, multi-stage hints, series of Socraticquestions, directed chains of reasoning.Investigating tutors' responses to studentinitiatives, Evens and her associates found thattutors always respond to student initiatives tosome extent.
Revelations of seriousmisconceptions change the tutor's agenda toelimination of the misconception.
An initiativefrom the student that is relevant to the tutor'scurrent agenda results in a modification of theplan to Incorporate the issue raised by thestudents.
Other student initiatives evoke a briefresponse, followed by a return to the tutor'sagenda.
Unlike Fox, they found direct negativefeedback in their tutorial dialogs 25% of the timeas well as direct contradictions of what thestudent has just said 10% of the time.
Keyboard-to-keyboard communication resulted in moreelaborate positive and negative feedbackresponses from the tutors, fewer turns, and slowerinitiation of student responses.
The currentversion of the tutor, Circsim-Tutor Version 2,generates lesson plans and tactics on both largeand small scales, but in the process of executinga given plan, it generates the actual dialogue aturn at a time.
The next version will attempt toemulate the larger structures of the human tutors.Evens judges that the tutorial repair processesdescribed by Fox seem extremely difficult toemulate.
Therefore, she is attempting to avoidrepair by studying the source of repair situationsand avoiding them: the most common source ofconversational misunderstanding is vague"how" questions from the tutor.
Evens andher collaborators are trying to generate morespecific questions.
Another source ofmisunderstanding is the tutor 'smisinterpretation of very terse and ill-formedinput from the student; Evens' tutor ischecking those interpretations with thestudent.
Although Evens studied tutorialinteraction over a computer link (as well asface-to-face tutoring) in order to approximatethe conditions of computer tutoring, althoughshe has devoted considerable effort todealing with the error-ridden, abbreviated, andelliptical input from the students, this tutormay interest DARPA grantees as a potentialtestbed for the integration of speechrecognition with natural language.
Speechinteraction would be a highly desirable featurefor computerized training systems.
Given thelimited resources of the ONR program,however, we are relying upon DARPA to solvethe speech recognition problem.The project in this cluster that has begunmost recently is that of Johanna Moore, acomputer scientist at Pittsburgh.
Althoughthe aim of her project is the artificialgeneration of tutorial explanations, she alsohas begun by studying human tutors in orderto identify the properties that make themeffective.
She replaced the natural languagecomponent of an existing ITS with a humantutor, and gathered protocols of studentsinteracting with the human tutor.
(The existingtutor is the Shedock tutor of skill indiagnosing problems with an avionics teststation, an Air Force project.
The existingtutor has been evaluated in workplace trainingand found highly effective; it is the first of alarge number of maintenance training tutorswhich the Air Force plans to develop foractual, practical training use.)
She thensystematically compared the human'sresponses to those that would have beenproduced by the ITS, identifying two criticalfeatures that distinguish human tutorialexplanations from those of theircomputational counterparts.
First, humanexplainers freely exploit the previousdiscourse in their subsequent explanations.This facilitates understanding and learning byrelating new information effectively to recentlyconveyed material, and avoiding repetition of292old material that could distract the student fromwhat is new.
Second, human tutors makeextensive use of discourse markers to expressrelationships among individual units ofinformation.
These markers provide cues to thestructure of the explanation and the informationbeing conveyed, and thus make the explanationseasier to understand.
Moore is now constructinga computational explanation planner capable ofassigning appropriate discourse markers and ofgenerating explanations that make use of priordiscourse in ways done by human tutors.TEXT READABIL ITYA second cluster of language research projectshas focused on improving text readability.
Themilitary services and their contractors produceenormous amounts of text, system documentationand training materials for the personnel who willoperate and maintain those systems.Consequently, there has been interest in researchaiming to make these materials readable andcomprehensible for their users.
A few years ago,the ONR program supported a cluster of projectsconcerned with the design of readable andcomprehensible procedural instructions, a specialgenre that has been neglected in generaleducational research on reading and text design.Among these projects was an effort by DavidKieras, now at the University of Michigan.
In abasic research project, Kieras demonstrated anautomated system that could provide rathersophisticated comments on text structure andquality, such as, "This paragraph does not seemto have a main idea."
This was done without anytrue comprehension of the text.
The text wasparsed and a propositional representation of thetext was constructed.
Propositions were linkedby repeated mentions of the same term.Comments on text coherence could then bederived.In conjunction with a project to develop a systemto aid the authors of Navy training materials(AIM), the Navy Personnel Research andDevelopment Center provided somewhat moreapplied funding (6.2) for further work by Kieras onthe development of a text critiquing system thatmight enhance the capabilities of AIM.
Kierasreviewed the psycholinguistic research literatureon the determinants of text readability andcomprehensibility.
(Current standards forreadability are based on crude formulas thatmeasure sentence length and thefrequency/familiarity of words used in thetext.
Yet, it is known that conversions toshorter sentences can sometimes make textsless comprehensible by obscuring theconnections among ideas in the text.)
As afirst step, Kieras put considerable effort intobuilding a parser that could handle actualNavy training documents in production.These do have some unusual structuralformat features that are not found in the textsfor which most existing parsers weredesigned.
In addition, many of these textsare written by senior enlisted personnel withsubject matter expertise, personnel who arenot trained or talented as writers.
They canpresent severe parsing challenges even tohighly skilled human readers.
Experts incomputational linguistics will not be surprisedto hear that the "finished" version of Kieras'parser cannot parse many of the sentencesor so-called sentences in these trainingdocuments, although failure to parse mightsometimes be appropriate grounds forcriticizing the writing.
(Kieras's parser iswritten in Common Lisp and is available forthose who might want to use it, along with adocumenting manual that explains how toadd additional capabilities to it.)
Kieras didgo on to build a text critiquing system basedon his earlier work and the broaderpsycholinguistic research literature.Experimentation with this system revealedsome interesting problem areas: for example,the system makes too many spuriouscomplaints about the introduction of "newreferents'.
This happens because it does notknow about semantic relations among thewords in the text, such as synonymy andpart-whole relations.
If the F-14 has beendiscussed, it will respond to "the wing" as anew referent.
In its present state, thecritiquing system does not have a practical,reasonably friendly user interface.
In additionto making errors, it does not prune orprioritize comments but outputs anoverwhelming barrage.
Design of an effectiveuser interface has not yet been supported.
(NPRDC has also been interested in relatedwork by Bruce Britton, a psychologist at theUniversity of Georgia, who was initiallysupported by the Air Force.
Britton has293shown that revisions guided by the sameprinciples implemented in Kieras' system doimprove text comprehension.
Britton hasdeveloped some simple computer programs thataid human users in doing the same kinds ofanalyses done by the Kieras program, relyingupon the human users to do parsing and supplysemantic knowledge.
)In addition to the Kieras project, several othershave been supported with a view to potentialapplications in a system like AIM.
Navy supportof George Miller's WordNet project began withthis rationale, although it was obvious thatWordNet would be a very general lexical resourcewith diverse potential applications in naturallanguage computing.
WordNet might be used toaid authors in finding more frequent and familiarwords to substitute for rare words in their initialdrafts.
Specialists in natural language computingmight note an interesting irony here: veryfrequent words tend to be very ambiguoussemantically.
Thus, to make a text readable tohuman readers of limited ability, one is advised tosubstitute very ambiguous words for lessambiguous ones.
Semantic ambiguity does notseem to be problematic for human readers.
Inaddition, of course, WordNet seemed to havepromise as a way of eliminating some of theerroneous comments generated by the textcritiquing system.Another project has been a system of automatedtext formatting developed by Thomas Bever, apsycholinguist at Rutgers.
Bever's system insertsslightly larger spaces at phrase boundaries(roughly speaking) in the text.
Perhapssurprisingly, this has significant effects on readingspeed and comprehension performance,especially for less skilled readers, although thetext retains a normal appearance.
(All of theservices have many personnel with rather poorreading skills.
Remedial reading instruction is amajor training expense.)
Formatted texts haveeven been shown to improve performance in anentire training course.
Preliminary results suggestthat the effects of text formatting are much largerfor texts presented on computer screens -- theexpected future format of military documentation.Bever's system does not parse the text in order toinsert these spaces; he has developed a set ofsurface rules for doing it.
However, he has alsoshown that a neural net can be trained to dospace insertion very quickly when trained by afew texts that have been marked by a human.In this way, formatting could be applied tolanguages other than English with a verysmall expenditure of effort.
It might be a veryuseful feature for the translators' work stationsthat have been a target application for DARPAwork in machine translation and machine-added translation.
At this time, thepsychological mechanism by which thisforrnatting aids readers is unknown;presumably it relieves some of the processingburden of parsing the text.
Because of itsdemonst ra ted  e f fect iveness  andunobtrusiveness, Bever's text formatting islikely to move into practical application inmajor Navy training manuals soon.At one time, we had hoped that the AIMsystem would remain an on-going appliedproject with periodic upgrades that wouldprovide a conduit for the ready application ofresearch advances.
However, a managerialdecision was made that all such projectswould be limited to a 3-year span.
The AIMsystem, which is implemented on Suncomputers, was declared finished and fieldedas little more than a fancy word processingsystem that helps to meet the specialformatting requirements of Navy trainingdocuments, supplemented by a MacDraw-likecapability for scanning in and manipulatingillustrative diagrams.
It is very popular withits users.
Obviously, efforts may be made toinitiate a new project that would incorporatemore sophisticated language processingcapabilities.Although psychological research on textdesign has a long history, advances inlinguistic understanding change the nature ofthe questions that can be asked in suchresearch and the nature of the phenomenathat are noticed.
In particular, as in theresearch on tutorial discourse, much is beingdiscovered about larger-scale discoursestructures.
Related issues, such as theeffective design and use of diagrams, aremuch less well understood.
At present, theseare not high priority topics in the basicresearch Cognitive Science Program at ONR,but they may receive attention in the future,and some projects may receive supportthrough the 6.2 Manpower, Personnel andTraining R&D Committee at ONR.294
