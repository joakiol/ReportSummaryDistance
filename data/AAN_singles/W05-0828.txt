Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 155?158,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005First Steps towards Multi-Engine Machine TranslationAndreas EiseleComputational LinguisticsSaarland University P.O.Box 151150D-66041 Saarbru?cken, Germanyeisele@coli.uni-saarland.deAbstractWe motivate our contribution to the sharedMT task as a first step towards an inte-grated architecture that combines advan-tages of statistical and knowledge-basedapproaches.
Translations were generatedusing the Pharaoh decoder with tables de-rived from the provided alignments for allfour languages, and for three of them us-ing web-based and locally installed com-mercial systems.
We then applied statis-tical and heuristic algorithms to select themost promising translation out of each setof candidates obtained from a source sen-tence.
Results and possible refinementsare discussed.1 Motivation and Long-term Perspective?The problem of robust, efficient and reliablespeech-to-speech translation can only be crackedby the combined muscle of deep and shallow pro-cessing approaches.?
(Wahlster, 2001) Although thisstatement has been coined in the context of VerbMo-bil, aiming at translation for direct communication,it appears also realistic for many other translationscenarios, where demands on robustness, coverage,or adaptability on the input side and quality on theoutput side go beyond today?s technological possi-bilities.
The increasing availability of MT enginesand the need for better quality has motivated con-siderable efforts to combine multiple engines intoone ?super-engine?
that is hopefully better than anyof its ingredients, an idea pionieered in (Frederkingand Nirenburg, 1994).
So far, the larger group ofrelated publications has focused on the task of se-lecting, from a set of translation candidates obtainedfrom different engines, one translation that looksmost promising (Tidhar and Ku?ssner, 2000; Akiba etal., 2001; Callison-Burch and Flournoy, 2001; Ak-iba et al, 2002; Nomoto, 2004).
But also the morechallenging problem of decomposing the candidatesand re-assembling from the pieces a new sentence,hopefully better than any of the given inputs, hasrecently gained considerable attention (Rayner andCarter, 1997; Hogan and Frederking, 1998; Banga-lore et al, 2001; Jayaraman and Lavie, 2005).Although statistical MT approaches currentlycome out as winners in most comparative evalua-tions, it is clear that the achievable quality of meth-ods relying purely on lookup of fixed phrases will belimited by the simple fact that for any given combi-nation of topic, application scenario, language pair,and text style there will never be sufficient amountsof pre-existing translations to satisfy the needs ofpurely data-driven approaches.Rule-based approaches can exploit the effort thatgoes into single entries in their knowledge reposi-tories in a broader way, as these entries can be un-folded, via rule applications, into large numbers ofpossible usages.
However, this increased generalitycomes at significant costs for the acquisition of therequired knowledge, which needs to be encoded byspecialists in formalisms requiring extensive train-ing to be used.
In order to push the limits of today?sMT technology, integrative approaches will have tobe developed that combine the relative advantages of155both paradigms and use them to compensate for theirdisadvantages.
In particular, it should be possibleto turn single instances of words and constructionsfound in training data into internal representationsthat allow them to be used in more general ways.In a first step towards the development of inte-grated solutions, we need to investigate the relativestrengths and weaknesses of competing systems onthe level of the target text, i.e.
find out which sen-tences and which constructions are rendered wellby which type of engine.
In a second step, suchan analysis will then make it possible to take theoutcomes of various engines apart and re-assemblefrom the building blocks new translations that avoiderrors made by the individual engines, i.e.
to find in-tegrated solutions that improve over the best of thecandidates they have been built from.
Once this canbe done, the third and final step will involve feedback of corrections into the individual systems, suchthat differences between system behaviour can trig-ger (potentially after manual resolution of unclearcases) system updates and mutual learning.In the long term, one would hope to achieve asetup where a group of MT engines can convergeto a committee that typically disagrees only in trulydifficult cases.
In such a committee, remaining dis-sent between the members would be a symptom ofunresolved ambiguity, that would warrant the costof manual intervention by the fact that the system asa whole can actually learn from the additional ev-idence.
We expect this setup to be particularly ef-fective when existing MT engines have to be portedto new application domains.
Here, a rule-based en-gine would be able to profit from its more genericknowledge during the early stages of the transitionand could teach unseen correspondences of knownwords and phrases to the SMT engine, whereas theSMT system would bring in its abilities to applyknown phrase pairs in novel contexts and quicklylearn new vocabulary from examples.2 Collecting Translation Candidates2.1 Setting up Statistical MTIn the general picture laid out in the preceding sec-tion, statistical MT plays an important role for sev-eral reasons.
On one hand, the construction of a rel-atively well-performing phrase-based SMT systemfrom a given set of parallel corpora is no more overlydifficult, especially if ?
as in the case in this sharedtask ?
word alignments and a decoder are provided.Furthermore, once the second task in our chain willhave been surmounted, it will be relatively easy tofeed back building blocks of improved translationsinto the phrase table, which constitutes the centralresource of the SMT system Therefore, SMT facili-tates experiments aiming at dynamic and interactiveadaptation, the results of which should then also beapplicable to MT engines that represent knowledgein a more condensed form.In order to collect material for testing these ideas,we constructed phrase tables for all four languages,following roughly the procedure given in (Koehn,2004) but deviating in one detail related to the treat-ment of unaligned words at the beginning or end ofthe phrases1.
We used the Pharaoh decoder as de-scribed on http://www.statmt.org/wpt05/mt-shared-task/ after normalization of all tables to lower case.2.2 Using Commercial EnginesAs our main interest is in the integration of statis-tical and rule-based MT, we tried to collect resultsfrom ?conventional?
MT systems that had more orless uniform characteristics across the languages in-volved.
We could not find MT engines supporting allfour source languages, and therefore decided to dropFinnish for this part of the experiment.
We sent thetexts of the other three languages through several in-carnations of Systran-based MT Web-services2 andthrough an installation of Lernout & Hauspie PowerTranslator Pro, Version 6.43.31We used slightly more restrictive conditions that resulted ina 5.76% reduction of phrase table size2The results were incomplete and different, but sufficientlyclose to each other so that it did not seem worthwhile to explorethe differences systematically.
Instead we ranked the servicesaccording to errors in an informal comparison and took for eachsentence the first available translation in this order.3After having collected or computed all translations, we ob-served that in the case of French, both systems were quite sen-sitive to the fact that the apostrophes were formatted as separatetokens in the source texts (l ?
homme instead of l?homme).
Wetherefore modified and retranslated the French texts, but did notexplore possible effects of similar transformations in the otherlanguages.1563 Heuristic Selection3.1 ApproachWe implemented two different ways to select, outof a set of alternative translations of a given sen-tence, one that looks most promising.
The first ap-proach is purely heuristic and is limited to the casewhere more than two candidates are given.
For eachcandidate, we collect a set of features, consisting ofwords and word n-grams (n ?
{2, 3, 4}).
Each ofthese features is weighted by the number of can-didates it appears in, and the candidate with thelargest feature weight per word is taken.
This canbe seen as the similarity of each of the candidateto a prototypical version composed as a weightedmixture of the collection, or as being remotely re-lated to a sentence-specific language model derivedfrom the candidates.
The heuristic measure was usedto select ?favorite?
from each group of competingtranslations obtained from the same source sentence,yielding a fourth set of translations for the sentencesgiven in DE, FR, and ES.A particularity of the shared task is the fact thatthe source sentences of the development and test setsform a parallel corpus.
Therefore, we can not onlyintegrate multiple translations of the same sourcesentence into a hopefully better version, but we canmerge the translations of corresponding parts fromdifferent source languages into a target form thatcombines their advantages.
This approach, calledtriangulation in (Kay, 1997), can be motivated bythe fact that most cases of translation for dissemi-nation involve multiple target languages; hence onecan assume that, except for the very first of them,renderings in multiple languages exist and can beused as input to the next step4.
See also (Och andNey, 2001) for some related empirical evidence.
Inorder to obtain a first impression of the potential oftriangulation in the domain of parliament debates,we applied the selection heuristics to a set of fourtranslations, one from Finnish, the other three theresult of the selections mentioned above.3.2 Results and DiscussionThe BLEU scores (Papineni et al, 2002) for 10 di-rect translations and 4 sets of heuristic selections4Admittedly, in typical instances of such chains, Englishwould appear earlier.Source MT BLEULanguage Engine scoreDE Pharaoh 20.48L & H 13.97Systran 14.92heuristic selection 16.01statistical selection 20.55FR Pharaoh 26.29L & H 17.82Systran 20.29heuristic selection 21.44statistical selection 26.49ES Pharaoh 26.69L & H 17.28Systran 17.38heuristic selection 19.16statistical selection 26.74FI Pharaoh 16.76all heuristic selection 22.83statistical selection 25.80Table 1: BLEU scores of various MT engines andcombinationsthereof are given in Table 1.
These results showthat in each group of translations for a given sourcelanguage, the statistical engine came out best.
Fur-thermore, our heuristic approach for the selectionof the best among a small set of candidate transla-tions did not result in an increase of the measuredBLEU score, but typically gave a score that wasonly slightly better than the second best of the in-gredients.
This somewhat disappointing result canbe explained in two ways.
Apparently, the selectionheuristic does not give effective estimates of trans-lation quality for the candidates.
Furthermore, thegranularity on which the choices have to bee madeis too coarse, i.e.
the pieces for which the symbolicengines do produce better translations than the SMTengine are accompanied by too many bad choices sothat the net effect is negative.4 Statistical SelectionThe other score we used was based on probabilitiesas computed by the trigram language model for En-glish provided by the organizers of the task, in arepresentation compatible with the SRI LM toolkit157(Stolcke, 2002).
However, a correct implementa-tion for obtaining these estimates was not availablein time, so the selections generated from the statis-tical language model could not be used for officialsubmissions, but were generated and evaluated af-ter the closing date.
The results, also displayed inTable 1, show that this approach can lead to slightimprovements of the BLEU score, which howeverturn out not to be statistically sigificant in then senseof (Zhang et al, 2004).5 Next StepsWhen we started the experiments reported here, thehope was to find relatively simple methods to selectthe best among a small set of candidate translationsand to achieve significant improvements of a hybridarchitecture over a purely statistical approach.
Al-though we could indeed measure certain improve-ments, these are not yet big enough for a conclu-sive ?proof of concept?.
We have started a refine-ment of our approach that can not only pick the bestamong translations of complete sentences, but alsojudge the quality of the building blocks from whichthe translations are composed.
First informal resultslook very promising.
Once we can replace singlephrases that appear in one translation by better alter-natives taken from a competing candidate, chancesare good that a significant increase of the overalltranslation quality can be achieved.6 AcknowledgementsThis work has been funded by the DeutscheForschungsgemeinschaft.
We want to thank twoanonymous reviewers for numerous pointers to rel-evant literature, Bogdan Sacaleanu for his help withthe collection of translations from on-line MT en-gines, as well as the organizers of the shared task formaking these interesting experiments possible.ReferencesYasuhiro Akiba, Kenji Imamura, and Eiichiro Sumita.2001.
Using multiple edit distances to automaticallyrank machine translation output.
In Proceedings of MTSummit VIII, Santiago de Compostela, Spain.Yasuhiro Akiba, Taro Watanabe, and Eiichiro Sumita.2002.
Using language and translation models to se-lect the best among outputs from multiple mt systems.In COLING.Srinivas Bangalore, German Bordel, and Giuseppe Ric-cardi.
2001.
Computing consensus translation frommultiple machine translation systems.
In ASRU, Italy.Chris Callison-Burch and Raymond S. Flournoy.
2001.A program for automatically selecting the best outputfrom multiple machine translation engines.
In Proc.
ofMT Summit VIII, Santiago de Compostela, Spain.Robert E. Frederking and Sergei Nirenburg.
1994.
Threeheads are better than one.
In ANLP, pages 95?100.Christopher Hogan and Robert E. Frederking.
1998.
Anevaluation of the multi-engine mt architecture.
In Pro-ceedings of AMTA, pages 113?123.Shyamsundar Jayaraman and Alon Lavie.
2005.
Multi-engine machine translation guided by explicit wordmatching.
In Proc.
of EAMT, Budapest, Hungary.Martin Kay.
1997.
The proper place of men and ma-chines in language translation.
Machine Translation,12:3?23.
First appeared as a Xerox PARC workingpaper in 1980.Philipp Koehn.
2004.
Pharaoh: A beam search decoderfor phrase-based statistical machine translation mod-els.
In AMTA, pages 115?124.Tadashi Nomoto.
2004.
Multi-engine machine transla-tion with voted language model.
In Proc.
of ACL.Franz-Josef Och and Hermann Ney.
2001.
Statisticalmulti-source translation.
In Proceedings of MT Sum-mit VIII, Santiago de Compostela, Spain, September.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of ACL,pages 311?318.Manny Rayner and David M. Carter.
1997.
Hybrid lan-guage processing in the spoken language translator.
InProc.
ICASSP ?97, pages 107?110, Munich, Germany.Andreas Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In Proc.
Intl.
Conf.
on Spoken Lan-guage Processing.Dan Tidhar and Uwe Ku?ssner.
2000.
Learning to selecta good translation.
In COLING, pages 843?849.Wolfgang Wahlster.
2001.
Robust translation of spon-taneous speech: A multi-engine approach.
In IJCAI,pages 1484?1493.
Invited Talk.Ying Zhang, Stephan Vogel, and Alex Waibel.
2004.
In-terpreting BLEU/NIST scores: How much improve-ment do we need to have a better system?
In Proceed-ings of LREC, Lisbon, Portugal.158
