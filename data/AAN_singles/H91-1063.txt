SESS ION 11 - NATURAL LANGUAGE I I IMitch MarcusDepartment CISUniversity of PennsylvaniaPhiladelphia, PA 19104INTRODUCTIONThe five papers in this session, as well as the ten papers inthe other two natural language sessions, can be classified intothree broad categories: (1) statistical approaches to naturallanguage processing and the automatic acquisition of linguisticstructure (2 out of 5 papers in this session; 8 out of 15 overall);(2) robust processing of texts by combining multiple partialanalyses (2 out of 5; 5 out of 15); and (3) fundamental issues inlinguistic analysis which will become bottlenecks toprocessing of more complex texts and interactive dialogues (1out of 5; 2 out of 15).
It is quite remarkable that the largest woof these categories, (1) and (2), would probably not beenrepresented in an NLP session at such a meeting just three orfour years ago.
From the papers ampled here, it is clear that arevolution in natural language processing is occurring and thatthe strong surge of work in these two areas is closely linked:both of the text analysis systems discussed in this sessionbring together statistical and non-statistical techniques.
Boththe rapid change in research direction and the results achievedare surprising and worthy of special note.The overview that follows draws out some more detailedcornrnonalities of the papers in this session, and then presentsa brief tutorial introduction to two of the problems whichseveral of these papers address.COMMONALIT IESTwo of the papers in this session focus on the automaticextraction from large annotated corpora of rules which can beused to accurately determine two different aspects of linguisticstructure.
The issue that these two papers address is to whatextent can the set of linguistic facts which any natural languageprocessor needs to encode be discovered automatically throughthe examination of a large corpus of text rather than requiringcareful hand programming.
A paper by Brent and Berwick ofM1T demonstrates a technique which automates a crucial aspectof building the lexicon which lies at the heart of any NLPsystem.
The technique they describe automatically determineswhich suboategorization frames a particular verb takes, i.e.
that"hit" takes a direct object (as in "he hit it") but "die" does it (asin "he died it").
A paper by Meteer, Schwartz and Weichedel ofBBN reports on experiments with a stochastic part of speechtagger.
Such a system automatically determines for every wordof an input text stream what part of speech (noun, verb,adjective, etc) that word is in that particular context.
Thispaper demonstrates (among other results) techniques by whichthe part of speech of words completely unknown to the systemcan be estimated with 85% accuracy.
This paper alsodemonstrates that the overall error rate of the system (for bothknown and unknown words) drops only marginally if thetraining corpus is reduced from a million words to only 64,000words.
The tagger described here has an overall error rate of3.3% when trained on the larger corpus, rising only to 3.9%when the corpus size was reduced to 64,000 words.
This meansthat a sufficient corpus to bootstrap a stochastic tagger for anew domain can be annotated in less than the equivalent of oneweek of full time work for a good annotator, given that theaverage production rate for part of speech tagging for a singlePenn Treebank annotator is 3,500 words per hour.Papers by Jacobs, Krupka and Rau of GE and byStrzalkowski and Vauthey of NYU demonstrate wo differentapplications for systems which can partially analyze text.
TheGE paper demonstrates that a partial analysis of unconstrainedtext, carefully targetted, suffices to extract the informationnecessary to fill in predetermined frames about particular kindsof events, while the NYU paper shows that the partial analysisof document abstracts can be used to advantage to drive asystem which uses classical information retrieval frameworktechniques.
While the GE system uses a fairly superficialsyntactic analysis phase to feed fragments to a fairly powerfulset of lexico-semantic patterns, the NYU system uses a fairlypowerful parser capable of producing fragments if under severetime pressure.
A fairly superficial statistical clustering routineis then used to extract information from the resulting perhapspartial analysis.Finally, a paper by Allen presents a framework foranalyzing the discourse structure of a newly collected corpus oftask-oriented dialogues in which pairs of participants cooperateto solve simple transportation problems in a simulated world.Alien finds that a fairly small taxonomy of types ofinteractions based entirely on the intentions of the speakersuffices to categorize all the interactions in the collectedcorpus.While these papers are on three different topics, theyactually all share a common approach.
The research underlyingall five of these papers relied on a corpus-based methodology;the research that each of these papers presents i  bulk on fairlylarge corpora in different domains, some annotated and somenot.
Furthermore, all but the last of these papers presentedsystems which have at least one statistical subcomponent.Both the GE and the NYU text analysis systems utilizestochastic part of speech taggers as front ends; indeed the NYUsystem uses the BBN tagger discussed in this session.
The NYUsystem, as discussed above, also drives a statistical clusteringalgorithm.
It appears that our new statistical tools are akeadybeing successfully incorporated in larger systems.D ISCOURSE STRUCTURETo understand the importance of the paper by Allen (at theUniversity of Rochester) and other work in discourse structure,one needs to understand that every dialogue has an implicitstructure which must be recovered to extract he informationbeing conveyed by the dialogue.
While this structure is simpleand minimal in discourses of two or three exchanges, the323discourse structure of a dialogue involving multiple exchangescan be quite complex.
Greatly oversimplfying the problem, onecan view this problem as a parsing problem, requiring acharacterization of the set of nonterminals, i.e.
a set ofdifferent kinds of entities which discourses are made of, andsome characterization f the form of the grammar itself.Allen's characterization f discourse structure is based upon theview that the basic units reflect the intentions of theparticipants in the discourse, with larger units reflecting suchchunks as a simple Request, a simple Inform, or a Clarificationof art earlier point.
The "grammar" of discourse is known toinvolve nested recursive structures, much like context free andmore complex forms of grammar.
Thus, a Clarification mightbe decomposed into a Request-for-Clarification, f llowed by anInform, followed by an Accept of the Clarification.
Castingthis into a context free rule, one might have:Clarification --> Request-for-Clarification Inform AcceptIt must be stressed that this oversimplification distortswhat we know about he structure of discourses.
Allen's paperdescribes the process of "parsing" the discourse as a what iscalled a plan recognition process in the artificial intelligenceliterature.
The grammar metaphor used here is oversimplifiedbut makes clear the main point: that a discourse has anelaborate structure, and that any model which will successfullyextract hat structure must do much more than simply look backat the last sentence or two in Markovian fashion.D ISCOVERING VERB FRAMESThe work presented in the paper by Brent and Berwick ofMIT is unlike any presented at previous Speech and NaturalLanguage Workshops.
To correctly analyze the full range ofsentences which use any particular verb, an NLP system musthave some knowledge about the range of verb frames thatcooccur with that verb.
To be able to analyze the full range ofsentences that might occur with the verb "know", for example,a system must know that this verb can occur with a simpledirect object ("He knows her.
"), or a single clause ("He knowsshe left") or a noun phrase followed by an infinitival verbphrase ("He knows her to be honest").
In systems to date, thisinformation has been laboriously and carefully hand coded forevery verb that the system might encounter.
The MIT paperpresents a new technique which opens up the possibility that akey aspect of the lexical entry for a given verb can beautomatically determined given an appropriate corpus.
Theresearch reported here demonstrates a new technique whichsuccessfully determined sets of verbs which are used with fivedifferent subeategorization frames with a false positive rate ofno more than 3% per frame.
While there are far more than fivesubeategorization frames, and while the paper does not analyzethe percentage of verbs which occur in a given frame that thetechnique does not detect, the approach presented here appearsto be extremely promising.
Note also that the sets of verbswhich take similar sets of verbs frames are often closely relatedsemantically.
The set of verbs which take the three verb framesfor "know" presented above also includes "believe","understand", and "suspect", all closely related in meaning.Thus, if a system can automatically determine the set of verbframes that cooccur with a particular verb, it may well be able toapproximate its semantics as well.A TECHNIQUE FOR IDENTIFY INGPROPER NOUNSOne simple new technique for identifying proper nouns waspresented by Ken Church of AT&T Bell Labs during thediscussion period which should prove of value to othersbuilding stochastic taggers.
Church's tagger augments thecapitalization heuristic used within the BBN tagger andpresented in their paper with one other simple check: wordswhich are capitalized and which occur only capitalized morethan once within a fixed size text window are taken to be propernames .324
