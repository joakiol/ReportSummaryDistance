Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 239?245,Baltimore, Maryland USA, June 26?27, 2014.c?2014 Association for Computational LinguisticsThe DCU Terminology Translation System for the Medical Query Subtaskat WMT14Tsuyoshi Okita, Ali Hosseinzadeh Vahid, Andy Way, Qun LiuDublin City University, School of ComputingGlasnevin, Dublin 9Ireland{tokita,avahid,away,qliu}@computing.dcu.ieAbstractThis paper describes the Dublin CityUniversity terminology translation systemused for our participation in the querytranslation subtask in the medical trans-lation task in the Workshop on Statisti-cal Machine Translation (WMT14).
Wedeployed six different kinds of terminol-ogy extraction methods, and participatedin three different tasks: FR?EN and EN?FR query tasks, and the CLIR task.
Weobtained 36.2 BLEU points absolute forFR?EN and 28.8 BLEU points absolutefor EN?FR tasks where we obtained thefirst place in both tasks.
We obtained 51.8BLEU points absolute for the CLIR task.1 IntroductionThis paper describes the terminology translationsystem developed at Dublin City University forour participation in the query translation subtask atthe Workshop on Statistical Machine Translation(WMT14).
We developed six kinds of terminol-ogy extraction methods for the problem of medi-cal terminology translation, especially where rareand new words are considered.
We have severalmotivations which we address before providing adescription of the actual algorithms undeprinningour work.First, terminology translation cannot be seenjust as a simple extension of the translation processif we use an analogy from human translation.
Ter-minology translation can be considered as moreimportant and a quite different task than transla-tion per se, so we need a considerably differentway of solving this particular problem.
Bilingualterminology selection has been claimed to be thetouchstone in human translation, especially wherescientific and legal translation are concerned.
Ter-minology selection is often the hardest and mosttime-consuming process in the translation work-flow.
Depending on the particular requirements ofthe use-case (Way, 2013), users may not object todisfluent translations, but will invariably be verysensitive to the wrong selection of terminology,even if the meaning of the chosen terms is correct.This is especially true if this selected terminologydoes not match with that preferred by the usersthemselves, in which case users are likely to ex-press some kind of complaint; it may even be thatthe entire translation is rejected as sub-standard orinappropriate on such grounds.Second, we look at how to handle new and rarewords.
If we inspect the process of human trans-lation more closely, it is easy to identify severaldifferences compared to the methods used in sta-tistical MT (SMT).
Unless stipulated by the client,the selection of bilingual terminology can be ahighly subjective process.
Accordingly, it is notnecessarily the bilingual term-pair with the highestprobability that is chosen by the human translator.It is often the case that statistical methods oftenforget about or delete less frequent n-grams, butrely on more frequent n-grams using maximumlikelihood or Maximum A Priori (MAP) meth-ods.
If some terminology is highly suitable, ahuman translator can use it quite freely.
Further-more, there are a lot of new words in reality forwhich new target equivalents have to be created bythe translators themselves, so the question arisesas to how human translators actually select ap-propriate new terminology.
Transliteration, whichis often supported by many Asian languages in-cluding Hindi, Japanese, and Chinese, is perhapsthe easiest things to do under such circumstances.Slight modifications of alphabets/accented charac-ters can sometimes successfully create a valid newterm, even for European languages.The remainder of this paper is organized as fol-lows.
Section 2 describes our algorithms.
Ourdecoding strategy in Section 3.
Our experimen-239tal settings and results are presented in Section 4,and we conclude in Section 5.2 Our MethodsApart from the conventional statistical approach toextract bilingual terminology, this medical querytask reminds us of two frequently occurring prob-lems which are often ignored: (i) ?Can we forgetabout terminology which occurs only once in acorpus?
?, and (ii) ?What can we do if the termi-nology does not occur in a corpus??
These twoproblems require computationally quite differentapproaches than what is usually done in the stan-dard statistical approach.
Furthermore, the medi-cal query task in WMT14 provides a wide range ofcorpora: parallel and monolingual corpora, as wellas dictionaries.
These two interesting aspects mo-tivate our extraction methods which we present inthis section, including one relatively new MachineLearning algorithm of zero-shot learning arisingfrom recent developments in the neural networkcommunity (Bengio et al., 2000; Mikolov et al.,2013b).2.1 Translation ModelWord alignment (Brown et al., 1993) and phraseextraction (Koehn et al., 2003) can capture bilin-gual word- and phrase-pairs with a good deal ofaccuracy.
We omit further details of these stan-dard methods which are freely available elsewherein the SMT literature (e.g.
(Koehn, 2010)).2.2 Extraction from Parallel Corpora(Okita et al., 2010) addressed the problem ofcapturing bilingual term-pairs from parallel datawhich might otherwise not be detected by thetranslation model.
Hence, the requirement inOkita et al.
is not to use SMT/GIZA++ (Och andNey, 2003) to extract term-pairs, which are thecommon focus in this medical query translationtask.The classical algorithm of (Kupiec, 1993) usedin (Okita et al., 2010) counts the statistics of ter-minology c(etermi, ftermj|st) on the source andthe target sides which jointly occur in a sentencestafter detecting candidate terms via POS tag-ging, which are then summed up over the entirecorpus?Nt=1c(etermi, ftermj|st).
Then, the al-gorithm adjusts the length of etermiand ftermj.It can be said that this algorithm captures term-pairs which occur rather frequently.
However, thisapparent strength can also be seen in disadvanta-geous terms since the search for terminology oc-curs densely in each of the sentences which in-creases the computational complexity of this algo-rithm, and causes the method to take a consider-able time to run.
Furthermore, if we suppose thatmost frequent term-pairs are to be extracted via astandard translation model (as described briefly inthe previous section), our efforts to search amongfrequent pairs is not likely to bring about furthergain.It is possible to approach this in a reverse man-ner: ?less frequent pairs can be outstanding termcandidates?.
Accordingly, if our aim changes tocapture only those less frequent pairs, the situationchanges dramatically.
The number of terms weneed to capture is considerably decreased.
Manysentences do not include any terminology at all,and only a relatively small subset of sentences in-cludes a few terms, such that term-pairs becomesparse with regard to sentences.
Term-pairs canbe found rather easily if a candidate term-pair co-occurs on the source and the target sides and onthe condition that the items in the term-pair actu-ally correspond with one another.This condition can be easily checked in variousways.
One way is to translate the source side ofthe targeted pairs with the alignment option in theMoses decoder (Koehn et al., 2007), which we didin this evaluation campaign.
Another way is to useasupervised aligner, such as the Berkeley aligner(Haghighi et al., 2009), to align the targeted pairsand check whether they are actually aligned or not.We assume two predefined sets of terms atthe outset, Eterm= {eterm1, .
.
.
, etermn} andFterm= {fterm1, .
.
.
, ftermn}.
We search forpossible alignment links between the term-paironly when they co-occur in the same sentence.One obvious advantage of this approach is thecomputational complexity which is fairly low.Note that the result of (Okita et al., 2010)shows that the frequency-based approach of (Ku-piec, 1993) worked well for NTCIR patent termi-nology (Fujii et al., 2010), which otherwise wouldhave been difficult to capture via the traditionalSMT/GIZA++ method.
In contrast, however, thisdid not work well on the Europarl corpus (Koehn,2005).2402.3 Terminology DictionariesTerminology dictionaries themselves are obvi-ously among the most important resources forbilingual term-pairs.
In this medical query transla-tion subtask, two corpora are provided for this pur-pose: (i) Unified Medical Language System cor-pus (UMLS corpus),1and (ii) Wiki entries.22.4 Extraction from TerminologyDictionaries: lower-order n-gramsTerminology dictionaries provide reliable higher-order n-gram pairs.
However, they do not oftenprovide the correspondences between the lower-order n-grams contained therein.
For example, theUMLS corpus provides a term-pair of ?abdominalcompartment syndrome ||| syndrome du compar-timent abdominal?
(EN|||FR).
However, such ter-minology dictionaries often do not explicitly pro-vide the correspondent pairs ?abdominal ||| ab-dominal?
(EN|||FR) or ?syndrome ||| syndrome?(EN|||FR).
Clearly, these terminology dictionariesimplicitly provide the correspondent pairs.
Notethat UMLS and Wiki entries provide terminol-ogy dictionaries.
Hence, it is possible to obtainsome suggestion by higher order n-gram models ifwe know their alignments between words on thesource and target sides.
Algorithm 1 shows theoverall procedure.Algorithm 1 Lower-order n-gram extraction algo-rithm1: Perform monolingual word alignment forhigher-order n-gram pairs.2: Collect only the reliable alignment pairs (i.e.discard unreliable alignment pairs).3: Extract the lower-order word pairs of our in-terest.2.5 Extraction from Monolingual Corpora:Transliteration and AbbreviationMonolingual corpora can be used in various ways,including:1.
Transliteration: Many languages support thefundamental mechanism of between Euro-pean and Asian languages.
Japanese evensupports a special alphabet ?
katakana ?
forthis purpose.
Chinese and Hindi also per-mit transliteration using their own alphabets.1http://www.nlm.nih.gov/research/umls/.2http://www.wikipedia.org.However, even among European languages,this mechanism makes it possible to findpossible translation counterparts for a giventerm.
In this query task, we did this onlyfor the French-to-English direction and onlyfor words containing accented characters (byrule-based conversion).2.
Abbreviation: It is often the case that abbre-viations should be resolved in the same lan-guage.
If the translation includes some ab-breviation, such as ?C.
difficile?, this needsto be investigated exhaustively in the samelanguage.
However, in the specific domainof medical terminology, it is quite likely thatpossible phrase matches will be successfullyidentified.2.6 Extraction from Monolingual Corpora:Zero-Shot LearningAlgorithm 2 Algorithm to connect two word em-bedding space1: Prepare the monolingual source and targetsentences.2: Prepare the dictionary which consists of Uentries of source and target sentences amongnon-stop-words.3: Train the neural network language model onthe source side and obtain the continuousspace real vectors of X dimensions for eachword.4: Train the neural network language model onthe target side and obtain the continuous spacereal vectors of X dimensions for each word.5: Using the real vectors obtained in the abovesteps, obtain the linear mapping between thedictionary in two continuous spaces usingcanonical component analysis (CCA).Another interesting terminology extractionmethod requires neither parallel nor comparablecorpora, but rather just monolingual corpora onboth sides (possibly unrelated to each other) to-gether with a small amount of dictionary entrieswhich provide already known correspondencesbetween words on the source and target sides(henceforth, we refer to this as the ?dictionary?
).This method uses the recently developed zero-shotlearning (Palatucci et al., 2009) using neural net-work language modelling (Bengio et al., 2000;Mikolov et al., 2013b).
Then, we train both sides241with the neural network language model, and usea continuous space representation to project wordsto each other on the basis of a small amount ofcorrespondences in the dictionary.
If we assumethat each continuous space is linear (Mikolov etal., 2013c), we can connect them via linear projec-tion (Mikolov et al., 2013b).
Algorithm 2 showsthis situation.In our experiments we use U the same as theentries of Wiki and X as 50.
Algorithm 3 showsthe algorithm to extract the counterpart of OOVwords.Algorithm 3 Algorithm to extract the counterpartof OOV words.1: Prepare the projection by Algorithm 2.2: Detect unknown words in the translation out-puts.3: Do the projection of it (the source word) intothe target word using the trained linear map-pings in the training step.3 Decoding StrategyWe deploy six kinds of extraction methods: (1)translation model, (2) extraction from parallel cor-pora, (3) terminology dictionaries, (4) lower-ordern-grams, (5) transliteration and abbreviation, and(6) zero-shot learning.
Among these we deployfour of them ?
(2), (4), (5) and (6) ?
in a limitedcontext, while the remaining two are used with-out any context, mainly owing to time constraints;only when we did not find the correspondent pairsvia (1) and (3), did we complement this by theother methods.The detected bilingual term-pairs using (1) and(3) can be combined using various methods.
Oneway is to employ a method similar to (confu-sion network-based) system combination (Okitaand van Genabith, 2011; Okita and van Genabith,2012).
First we make a lattice: if we regard onecandidate of (1) and two candidates in (3) as trans-lation outputs where the words of two candidatesin (3) are connected using an underscore (i.e.
oneword), we can make a lattice.
Then, we can deploymonotonic decoding over them.
If we do this forthe devset and then apply it to the test set, we canincorporate a possible preference learnt from thedevelopment set, i.e.
whether the query transla-tor prefers method (1) or UMLS/Wiki translation.MERT process and language model are applied ina similar manner with (confusion network-based)system combination (cf.
(Okita and van Genabith,2011)).We note also that a lattice structure is useful forhandling grammatical coordination.
Since queriesare formed by real users, reserved words fordatabase query such as ?AND?
(or ?ET?
(FR)) and?OR?
(or ?OU?
(FR)) are frequently observed inthe test set.
Furthermore, there is repeated use of?and?
more than twice, for example ?douleur ab-nominal et Helicobacter pylori et cancer?, whichmakes it very difficult to detect the correct coor-dination boundaries.
The lattice on the input sidecan express such ambiguity at the cost of splittingthe source-side sentence in a different manner.4 Experimental ResultsThe baseline is obtained in the following way.
TheGIZA++ implementation (Och and Ney, 2003) ofIBM Model 4 is used as the baseline for wordalignment: Model 4 is incrementally trained byperforming 5 iterations of Model 1, 5 iterations ofHMM, 3 iterations of Model 3, and 3 iterationsof Model 4.
For phrase extraction the grow-diag-final heuristics described in (Koehn et al., 2003) isused to derive the refined alignment from bidirec-tional alignments.
We then perform MERT (Och,2003) which optimizes parameter settings usingthe BLEUmetric (Papineni et al., 2002), while a 5-gram language model is derived with Kneser-Neysmoothing (Kneser and Ney, 1995) trained usingSRILM (Stolcke, 2002).
We use the whole train-ing corpora including the WMT14 translation taskcorpora as well as medical domain data.
UMLSand Wikipedia are used just as training corpora forthe baseline.For the extraction from parallel corpora (cf.Section 2.2), we used Genia tagger (Tsuruoka andTsujii, 2005) and the Berkeley parser (Petrov andKlein, 2007).
For the zero-shot learning (cf.
Sec-tion 2.6) we used scikit learn (Pedregosa et al.,2011), word2vec (Mikolov et al., 2013a), and arecurrent neural network (Mikolov, 2012).
Othertools used are in-house software.Table 2 shows the results for the FR?EN querytask.
We obtained 36.2 BLEU points absolute,which is an improvement of 6.3 BLEU point ab-solute (21.1% relative) over the baseline.
Table3 shows the results for the EN?FR query task.We obtained 28.8 BLEU points absolute, whichis an improvement of 8.7 BLEU points abso-242lute (43% relative) over the baseline.
Our sys-tem was the best system for both of these tasks.These improvements over the baseline were sta-tistically significant by a paired bootstrap test(Koehn, 2004).Query task FR?ENOur method baselineBLEU 36.2 29.9BLEU cased 30.9 26.5TER 0.340 0.443Table 1: Results for FR?EN query task.extraction LM MERT BLEU (cased)(1) - (6) all Y 30.9(1), (2), (3) all Y 30.3(1), (3), (6) all Y 30.1(1), (3), (4) all Y 29.1(1), (3), (5) all Y 29.0(1) and (3) all Y 29.0(1) and (3) medical Y 27.5(1) and (3) WMT Y 27.0(1) and (3) medical N 25.1(1) and (3) WMT N 24.3(1) medical Y 25.9(1) WMT Y 25.0Table 2: Table shows the effects of extractionmethods, language model and MERT process.
Allthe measurements are by BLEU (cased).
In thistable, ?medical?
indicates a language model builton all the medical corpora while ?WMT?
indicatesa language model built on all the non-medical cor-pora.
Note that some sentence in testset can beconsidered as non-medical domain.
Extractionmethods (1) - (6) correspond to those described inSection 2.1 - 2.6.Table 4 shows the results for CLIR task.
Weobtained 51.8 BLEU points absolute, which is animprovement of 9.4 BLEU point absolute (22.2%relative) over the baseline.
Although CLIR task al-lowed 10-best lists, our submission included only1-best list.
This resulted in the score of P@5 of0.348 and P@10 of 0.346 which correspond tothe second place, despite a good result in termsof BLEU.
This is since unlike BLEU score P@5and P@10 measure whether the whole elementsin reference and hypothesis are matched or not.We noticed that our submission included a lot ofQuery task EN?FROur method baselineBLEU 28.8 20.1BLEU cased 27.7 18.7TER 0.483 0.582Table 3: Results for EN?FR query task.near miss sentences only in terms of capitaliza-tion: ?abnominal pain and Helicobacter pylori andcancer?
(reference) and ?abnominal pain and heli-cobacter pylori and cancer?
(submission).
Theseare counted as incorrect in terms of P@5 andP@10.3Noted that after submission we obtainedthe revised score of P@5 of 0.560 and P@10 of0.560 with the same method but with 2-best listswhich handles the capitalization varieties.CLIR task FR?ENOur method baselineBLEU 51.8 42.2BLEU cased 46.0 38.3TER 0.364 0.398P@5 0.348 (0.560?)
?P@10 0.346 (0.560?)
?NDCG@5 0.306 ?NDCG@10 0.307 ?MAP 0.2252 ?Rprec 0.2358 ?bpref 0.3659 ?relRet 1524 ?Table 4: Results for CLIR task.5 ConclusionThis paper provides a description of the DublinCity University terminology translation system forour participation in the query translation subtaskin the medical translation task in the Workshop onStatistical Machine Translation (WMT14).
We de-ployed six different kinds of terminology extrac-tion methods.
We obtained 36.2 BLEU points ab-solute for FR?EN, and 28.8 BLEU points abso-lute for EN?FR tasks, obtaining first place on bothtasks.
We obtained 51.8 BLEU points absolute forthe CLIR task.3The method which incorporates variation in capitaliza-tion in its n-best lists outperforms the best result in terms ofP@5 and P@10.243AcknowledgmentsThis research is supported by the Science Founda-tion Ireland (Grant 07/CE/I1142) as part of CNGLat Dublin City University.ReferencesYoshua Bengio, Rejean Ducharme, and Pascal Vincent.2000.
A neural probabilistic language model.
InProceedings of Neural Information Systems, pages1137?1155.Peter F. Brown, Vincent J.D Pietra, Stephen A.D.Pietra,and Robert L. Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational Linguistics, Vol.19, Issue 2,pages 263?311.Atsushi Fujii, Masao Utiyama, Mikio Yamamoto,Takehito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and Sayori Shimohata.
2010.
Overview of thepatent translation task at the NTCIR-8 workshop.In Proceedings of the 8th NTCIR Workshop Meet-ing on Evaluation of Information Access Technolo-gies: Information Retrieval, Question Answeringand Cross-lingual Information Access, pages 293?302.Aria Haghighi, John Blitzer, John DeNero, and DanKlein.
2009.
Better word alignments with super-vised itg models.
In In Proceedings of the Confer-ence of Association for Computational Linguistics,pages 923?931.Reinhard Kneser and Hermann Ney.
1995.
Im-proved backing-off for n-gram language modeling.In Proceedings of the IEEE International Confer-ence on Acoustics, Speech and Signal Processing,pages 181?184.Philipp Koehn, Franz Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceed-ings of the Human Language Technology Confer-ence of the North American Chapter of the Associ-ation for Computationa Linguistics (HLT / NAACL2003), pages 115?124.Philipp Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor Statistical Machine Translation.
In Proceedingsof the 45th Annual Meeting of the Association forComputational Linguistics Companion Volume Pro-ceedings of the Demo and Poster Sessions, pages177?180.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofConference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2004), pages 388?395.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of theMachine Translation Summit, pages 79?86.Philipp Koehn.
2010.
Statistical machine translation.Cambridge University Press.Julian.
Kupiec.
1993.
An algorithm for finding Nounphrase correspondences in bilingual corpora.
InProceedings of the 31st Annual Meeting of the Asso-ciation for Computational Linguistics, pages 17?22.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013a.
Efficient estimation of word represen-tations in vector space.
In Proceedings of Workshopat International Conference on Learning Represen-tations.Tomas Mikolov, Quoc V. Le, and Ilya Sutskever.2013b.
Exploiting similarities among languages formachine translation.
ArXiv:1309.4168.Tomas Mikolov, Wen tau Yih, and Geoffrey Zweig.2013c.
Linguistic regularities in continuous spaceword representations.
In Proceedings of the Confer-ence of the North American Chapter of the Associ-ation for Computational Linguistics / Human Lan-guage Technology (NAACL/HLT 2005), pages 746?751.Tomas Mikolov.
2012.
Statistical language modelsbased on neural networks.
PhD thesis at Brno Uni-versity of Technology.Franz Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Franz Och.
2003.
Minimum Error Rate Training inStatistical Machine Translation.
In Proceedings ofthe 41st Annual Meeting of the Association for Com-putational Linguistics, pages 160?167.Tsuyoshi Okita and Josef van Genabith.
2011.
DCUConfusion Network-based System Combination forML4HMT.
Shared Task on Applying MachineLearning techniques to optimising the division oflabour in Hybrid MT (ML4HMT-2011, collocatedwith LIHMT-2011), pages 93?98.Tsuyoshi Okita and Josef van Genabith.
2012.
Mini-mum Bayes Risk Decoding with Enlarged Hypoth-esis Space in System Combination.
In Proceed-ings of 13th International Conference on IntelligentText Processing and Computational Linguistics (CI-CLING 2012), pages 40?51.Tsuyoshi Okita, Alfredo Maldonado Guerra, YvetteGraham, and Andy Way.
2010.
Multi-wordexpression-sensitive word alignment.
In Proceed-ings of the Fourth International Workshop On CrossLing ual Information Access (CLIA2010, collocatedwith COLING2010), pages 26?34.244Mark Palatucci, Dean Pomerleau, Geoffrey Hinton,and Tom Mitchell.
2009.
Zero-shot learning withsemantic output codes.
In Neural Information Pro-cessing Systems (NIPS), pages 1410?1418.K.
Papineni, S. Roukos, T. Ward, and W.J.
Zhu.
2002.BLEU: A Method For Automatic Evaluation of Ma-chine Translation.
In Proceedings of the 40th An-nual Meeting of the Association for ComputationalLinguistics (ACL-02).F.
Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B.
Thirion, O. Grisel, M. Blondel, P. Pretten-hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-sos, D. Cournapeau, M. Brucher, M. Perrot, andE.
Duchesnay.
2011.
Scikit-learn: Machine learn-ing in Python.
Journal of Machine Learning Re-search, 12:2825?2830.Slav Petrov and Dan Klein.
2007.
Learning and infer-ence for hierarchically split PCFGs.
In Proceedingsof AAAI (Nectar Track), pages 1663?1666.Andreas Stolcke.
2002.
SRILM ?
An extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Process-ing, pages 901?904.Yoshimasa Tsuruoka and Jun?ichi Tsujii.
2005.
Bidi-rectional inference with the easiest-first strategyfor tagging sequence data.
In Proceedings of theConference on Human Language Technology / Em-pirical Methods on Natural Language Processing(HLT/EMNLP 2005), pages 467?474.Andy Way.
2013.
Traditional and emerging use-casesfor machine translation.
In Proceedings of Translat-ing and the Computer 35.245
