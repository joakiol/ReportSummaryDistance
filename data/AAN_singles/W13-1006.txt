Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 42?50,Atlanta, Georgia, 13-14 June 2013. c?2013 Association for Computational LinguisticsDetermining Compositionality of Word ExpressionsUsing Word Space ModelsLubom?
?r Krc?ma?r?, Karel Jez?ekUniversity of West BohemiaFaculty of Applied SciencesDepartment of Computer Science and EngineeringPilsen, Czech Republic{lkrcmar,jezek ka}@kiv.zcu.czPavel PecinaCharles University in PragueFaculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsPrague, Czech Republicpecina@ufal.mff.cuni.czAbstractThis research focuses on determining seman-tic compositionality of word expressions us-ing word space models (WSMs).
We discussprevious works employing WSMs and presentdifferences in the proposed approaches whichinclude types of WSMs, corpora, preprocess-ing techniques, methods for determining com-positionality, and evaluation testbeds.We also present results of our own approachfor determining the semantic compositionalitybased on comparing distributional vectors ofexpressions and their components.
The vec-tors were obtained by Latent Semantic Analy-sis (LSA) applied to the ukWaC corpus.
Ourresults outperform those of all the participantsin the Distributional Semantics and Composi-tionality (DISCO) 2011 shared task.1 IntroductionA word expression is semantically compositionalif its meaning can be understood from the literalmeaning of its components.
Therefore, semanti-cally compositional expressions involve e.g.
?smallisland?
or ?hot water?
; on the other hand, seman-tically non-compositional expressions are e.g.
?redtape?
or ?kick the bucket?.The notion of compositionality is closely relatedto idiomacy ?
the higher the compositionality thelower the idiomacy and vice versa (Sag et al 2002;Baldwin and Kim, 2010).Non-compositional expressions are often referredto as Multiword Expressions (MWEs).
Baldwin andKim (2010) differentiate the following sub-types ofcompositionality: lexical, syntactic, semantic, prag-matic, and statistical.
This paper is concerned withsemantic compositionality.Compositionality as a feature of word expressionsis not discrete.
Instead, expressions populate a con-tinuum between two extremes: idioms and free wordcombinations (McCarthy et al 2003; Bannard et al2003; Katz, 2006; Fazly, 2007; Baldwin and Kim,2010; Biemann and Giesbrecht, 2011).
Typical ex-amples of expressions between the two extremes are?zebra crossing?
or ?blind alley?.Our research in compositionality is motivatedby the hypothesis that a special treatment of se-mantically non-compositional expressions can im-prove results in various Natural Language Process-ing (NPL) tasks, as shown for example by Acosta etal.
(2011), who utilized MWEs in Information Re-trieval (IR).
Besides that, there are other NLP ap-plications that can benefit from knowing the degreeof compositionality of expressions such as machinetranslation (Carpuat and Diab, 2010), lexicography(Church and Hanks, 1990), word sense disambigua-tion (Finlayson and Kulkarni, 2011), part-of-speech(POS) tagging and parsing (Seretan, 2008) as listedin Ramisch (2012).The main goal of this paper is to present an anal-ysis of previous approaches using WSMs for de-termining the semantic compositionality of expres-sions.
The analysis can be found in Section 2.
Aspecial attention is paid to the evaluation of the pro-posed models that is described in Section 3.
Section4 presents our first intuitive experimental setup andresults of LSA applied to the DISCO 2011 task.
Sec-tion 5 concludes the paper.422 Semantic Compositionality of WordExpressions Determined by WSMsSeveral recent works, including Lin (1999), Schoneand Jurafsky (2001), Baldwin et al(2003), Mc-Carthy et al(2003), Katz (2006), Johannsen et al(2011), Reddy et al(2011a), and Krc?ma?r?
et al(2012), show the ability of methods based on WSMsto capture the degree of semantic compositionalityof word expressions.
We analyse the proposed meth-ods and discuss their differences.
As further de-scribed in detail and summarized in Table 1, the ap-proaches differ in the type of WSMs, corpora, pre-processing techniques, methods for determining thecompositionality, datasets for evaluation, and meth-ods of evaluation itself.Our understanding of WSM is in agreement withSahlgren (2006): ?The word space model is a com-putational model of word meaning that utilizes thedistributional patterns of words collected over largetext data to represent semantic similarity betweenwords in terms of spatial proximity?.
For moreinformation on WSMs, see e.g.
Turney and Pan-tel (2010), Jurgens and Stevens (2010), or Sahlgren(2006).WSMs and their parameters WSMs can be builtby different algorithms including LSA (Landauerand Dumais, 1997), Hyperspace Analogue to Lan-guage (HAL) (Lund and Burgess, 1996), RandomIndexing (RI) (Sahlgren, 2005), and Correlated Oc-currence Analogue to Lexical Semantics (COALS)(Rohde et al 2005).
Every algorithm has its ownspecifics and can be configured in different ways.The configuration usually involves e.g.
the choiceof context size, weighting functions, or normaliz-ing functions.
While Schone and Jurafsky (2001),Baldwin et al(2003), and Katz (2006) addoptedLSA-based approaches, Johannsen et al(2011) andKrc?ma?r?
et al(2012) employ COALS; the others usetheir own specific WSMs.Corpora and text preprocessing Using differ-ent corpora and their preprocessing naturally leadsto different WSMs.
The preprocessing can differe.g.
in the choice of used word forms or in re-moval/retaining of low-frequency words.
For exam-ple, while Lin (1999) employs a 125-million-wordnewspaper corpus, Schone and Jurafsky (2001) usea 6.7-million-word subset of the TREC databases,Baldwin et al(2003) base their experiments on90 million words from the British National Corpus(Burnard, 2000).
Krc?ma?r?
et al(2012), Johannsen etal.
(2011), and Reddy et al(2011a) use the ukWaCcorpus, consisting of 1.9 billion words from webtexts (Baroni et al 2009).
As for preprocessing,Lin (1999) extracts triples with dependency relation-ships, Baldwin et al(2003), Reddy et al(2011a),and Krc?ma?r?
et al(2012) concatenate word lemmaswith their POS categories.
Johannsen et al(2011)use word lemmas and remove low-frequency wordswhile Reddy et al(2011a), for example, keep onlyfrequent content words.Methods We have identified three basic methodsfor determining semantic compositionality:1) The substitutability-based methods exploitthe fact that replacing components of non-compositional expressions by words which aresimilar leads to anti-collocations (Pearce, 2002).Then, frequency or mutual information of suchexpressions (anti-collocations) is compared withthe frequency or mutual information of the originalexpressions.
For example, consider expected occur-rence counts of ?hot dog?
and its anti-collocationssuch as ?warm dog?
or ?hot terrier?.2) The component-based methods, utilized for ex-ample by Baldwin et al(2003) or Johannsen et al(2011), compare the distributional characteristics ofexpressions and their components.
The context vec-tors expected to be different from each other aree.g.
the vector representing the expression ?hot dog?and the vector representing the word ?dog?.3) The compositionality-based methods comparetwo vectors of each analysed expression: the trueco-occurrence vector of an expression and the vec-tor obtained from vectors corresponding to the com-ponents of the expression using a compositional-ity function (Reddy et al 2011a).
The most com-mon compositionality functions are vector additionor pointwise vector multiplication (Mitchell and La-pata, 2008).
For example, the vectors for ?hot dog?and ?hot???dog?
are supposed to be different.Evaluation datasets There is still no consensuson how to evaluate models determining semanticcompositionality.
However, by examining the dis-cussed papers, we have observed an increasing ten-43Paper Corpora WSMs Methods Data (types) EvaluationLin (1999) 125m, triples own SY NVAA c.
dicts., P/RSchone+Jurafsky(2001) 6.7m TREC LSA SY, CY all types WN, P/RcBaldwin et al(2003) BNC+POS LSA CT NN, VP WN, PCMcCarthy et al(2003) BNC+GR own CTn PV MA, WN, dicts., SKatz (2006) GNC LSA CY PNV MA, P/R, FmKrc?ma?r?
et al(2012) ukWaC+POS COALS SY AN, VO, SV MA, CR, APD, CLJohannsen et al(2011) ukWaC COALS SY, CT AN, VO, SV MA, CR, APD, CLReddy et al(2011a) ukWaC+POS own CT, CY NN MA, S, R2Table 1: Overview of experiments applying WSMs to determine semantic compositionality of word expressions.
BNC- British National Corpus, GR - grammatical relations, GNC - German newspaper corpus, TREC - TREC corpus;SY - substitutability-based methods, CT - component-based methods, CTn - component-based methods comparingWSM neighbors of expressions and their components, CY - compositionality-based methods; NVAP c. - noun, verb,adjective, adverb combinations, NN - noun-noun, VP - verb-particles, AN - adjective-noun, VO - verb-object, SV -subject-verb, PV - phrasal-verb, PNV - preposition-noun-verb; dicts.
- dictionaries of idioms, WN - Wordnet, MA- use of manually annotated data, S - Spearman correlation, PC - Pearson correlation, CR - Spearman and Kendallcorrelations, APD - average point difference, CL - classification, P/R - Precision/Recall, P/Rc - Precision/Recallcurves, Fm - F measure, R2 - goodness.dency to exploit manually annotated data from aspecific corpus, ranging from semantically composi-tional to non-compositional expressions (McCarthyet al 2003; Katz, 2006; Johannsen et al 2011;Reddy et al 2011a; Krc?ma?r?
et al 2012).This approach, as opposed to the methodsbased on dictionaries of MWEs (idioms) or Word-net (Miller, 1995), has the following advantages:Firstly, the classification of a manually annotateddata is not binary but finer-grained, enabling theevaluation to be more detailed.
Secondly, the low-coverage problem of dictionaries, which originatesfor example due to the facts that new MWEs stillarise or are domain specific, is avoided.1 For exam-ple, Lin (1999), Schone and Jurafsky (2001), Bald-win et al(2003) used Wordnet or other dictionary-type resources.3 Evaluation MethodsThis section discusses evaluation methods includ-ing average point difference (APD), Spearman andKendall correlations, and precision of classifica-tion (PoC) suggested by Biemann and Giesbrecht(2011); Precision/nBest, Recall/nBest and Preci-sion/Recall curves proposed by Evert (2005); and1The consequence of using a low-coverage dictionary cancause underestimation of the used method since the dictionarydoes not have to contain MWEs correctly found by that method.Average Precision used by Pecina (2009).
Our eval-uation is based on the English part of the manu-ally annotated datasets DISCO 2011 (Biemann andGiesbrecht, 2011), further referred to as DISCO-En-Gold.Disco-En-Gold consists of 349 expressions di-vided into training (TrainD), validation (ValD), andtest data (TestD) manually assigned scores from 0to 100, indicating the level of compositionality (thelower the score the lower the compositionality andvice versa).
The expressions are of the followingtypes: adjective-noun (AN), verb-object (VO), andsubject-verb (SV).
Based on the numerical scores,the expressions are also classified into three disjointclasses (coarse scores): low, medium, and high com-positional.2 A sample of the Disco-En-Gold data ispresented in Table 2.Comparison of evaluation methods The purposeof the DISCO workshop was to find the best meth-ods for determining semantic compositionality.
Theparticipants were asked to create systems capable ofassigning the numerical values closest to the onesassigned by the annotators (Gold values).
The pro-posed APD evaluation measure is calculated as themean difference between the particular systems?
val-2Several expressions with the numerical scores close to thespecified thresholds were not classified into any class.44Type Expression Ns CsEN ADJ NN blue chip 11 lowEN V OBJ buck trend 14 lowEN ADJ NN open source 49 mediumEN V OBJ take advantage 57 mediumEN ADJ NN red squirrel 90 highEN V SUBJ student learn 98 highTable 2: A sample of manually annotated expressionsfrom Disco-En-Gold with their numerical scores (Ns) andcoarse scores (Cs).ues and the Gold values assigned to the same expres-sions.
PoC is defined as the ratio of correct coarsepredictions to the number of all the predictions.Following Krc?ma?r?
et al(2012), we argue thatfor the purpose of comparison of the methods, thevalues assigned to a set of expressions by a certainmodel are not as important as is the ranking of theexpressions (which is not sensitive to the originaldistribution of compositionality values).
Similarlyas Evert (2005), Pecina (2009), and Krc?ma?r?
et al(2012) we adopt evaluation based on ranking (al-though the measures such as PoC or APD might pro-vide useful information too).Evaluation based on ranking can be realizedby measuring ranked correlations (Spearman andKendall) or Precision/Recall scores and curves com-monly used e.g.
in IR (Manning et al 2008).
InIR, Precision is defined as the ratio of found rele-vant documents to all the retrieved documents withregards to a user?s query.
Recall is defined as the ra-tio of found relevant documents to all the relevantdocuments in a test set to the user?s query.
ThePrecision/Recall curve is a curve depicting the de-pendency of Precision upon Recall.
Analogously,the scheme can be used for evaluation of the meth-ods finding semantically non-compositional expres-sions.
However, estimation of Recall is not possiblewithout knowledge of the correct class3 for every ex-pression in a corpus.
To bypass this, Evert (2005)calculates Recall with respect to the set of annotateddata divided into non-compositional and composi-tional classes.
The Precision/nBest, Recall/nBest,and Precision/Recall curves for the LSA experiment3A semantically non-compositional expression or a seman-tically compositional expressionsdescribed in the following section are depicted inFigures 1 and 2.Evert?s (2005) curves allow us to visually com-pare the results of the methods in more detail.
Tofacilitate comparison of several methods, we alsosuggest using average precision (AP) adopted fromPecina (2009), which reduces information providedby a single Precision/Recall curve to one value.
APis defined as a mean Precision at all the values ofRecall different from zero.4 LSA experimentLSA is WSM based on the Singular Value De-composition (SVD) factorization (Deerwester et al1990) applied to the co-occurrence matrix.
In thematrix, the numbers of word occurrences in speci-fied contexts4 are stored.
The row vectors of the ma-trix capture the word meanings.5 The idea of usingSVD is to project vectors corresponding to the wordsinto a lower-dimensional space and thus bring thevectors of words with similar meaning near to eachother.We built LSA WSM and applied the component-based method to Disco-En-Gold.
We used ourown modification of the LSA algorithm originallyimplemented in the S-Space package (Jurgens andStevens, 2010).
The modification lies in treating ex-pressions and handling stopwords.
Specifically, weadded vectors for the examined expressions to WSMin such a way that the original vectors for wordswere preserved.
This differentiates our approache.g.
from Baldwin et al(2003) or Johannsen et al(2011) who label the expressions ahead of time andbuild WSMs treating them as single words.
Treat-ing the expressions as the single words affects theWSM vectors of their constituents.
As an example,consider the replacement of occurrences of ?shortdistance?
by e.g.
the EXP#123 label.
This affectsthe WSM vectors of ?short?
and ?distance?
sincethe numbers of their occurrences and the numbersof contexts they occur in drops.
Consequently, thisalso affects the methods for determining the compo-sitionality which are based upon using the vectors of4The commonly used contexts for words are documents orthe preceding and following words in a specified window.5WSMs exploit Harris?
distributional hypothesis (Harris,1954), which states that semantically similar words tend to ap-pear in similar contexts.45expressions?
constituents.As for treating stopwords, we mapped the trigramexpressions containing the determiners ?the?, ?a?,or ?an?
as the middle word to the corresponding bi-gram expressions without the determiners.
The intu-ition is to extract more precise co-occurrence vectorsfor the VO expressions often containing some inter-vening determiner.
As an example, compare the oc-currences of ?reinvent wheel?
and ?reinvent (deter-miner) wheel?
in the ukWaC corpus which are 27and 623, respectively, or the occurrences of ?crossbridge?
and ?cross (determiner) bridge?
being 50and 1050, respectively.6We built LSA WSM from the whole ukWaCPOS-tagged corpus for all the word lemmas con-catenated with their POS tags excluding stopwords.We treated the following strings as stopwords: thelemmas with frequency below 50 (omitting low-frequency words), the strings containing two adja-cent non-letter characters (omitting strings such asweb addresses and sequences of e.g.
star symbols),and lemmas with a different POS tag from noun,proper noun, adjective, verb, and adverb (omittingclosed-class words).
As contexts, the entire docu-ments were used.The co-occurrence matrix for words was normal-ized by applying the log-entropy transformation andreduced to 300 dimensions.
Using these settings,Landauer and Dumais (1997) obtained the best re-sults.
Finally, the co-occurrence vectors of expres-sions were expressed in the lower-dimensional spaceof words in a manner analogous to how a user?squery is being expressed in lower-dimensional spaceof documents in IR (Berry et al 1995).
The Disco-En-Gold expressions were sorted in ascending orderby the average cosine similarity between the vec-tors corresponding to the expressions and the vectorscorresponding to their components.Evaluation We have not tried to find the optimalparameter settings for the LSA-based model yet.Therefore, we present the results on the concate-nation of TrainD with ValD giving us TrainValDand on TestD.
The expressions ?leading edge?
and?broken link?
were removed from TestD becausethey occur in the ukWaC corpus assigned with the6More precisely, the occurrences were calculated from thePOS-tagged parallels of the expressions.required POS tags less than 50 times.
APs withthe Spearman and Kendall correlations between thecompositionality values assigned by the LSA-basedmodel and the Gold values are depicted in Table 3.The Spearman correlations of the LSA model ap-plied to the whole TrainValD and TestD are highlysignificant with p-values < 0.001.
For the AP evalu-ation, the expressions with numerical values less orequal to 50 were classified as non-compositional7,giving us the ratio of non-compositional expressionsin TrainValD and TestD equal to 0.26 and 0.20, re-spectively.
The Precision/nBest and Recall/nBestgraphs corresponding to the LSA-based model ap-plied to TestD are depicted in Figure 1.
The Preci-sion/Recall graphs corresponding to the LSA-basedmodel applied to TrainD and TestD are depicted inFigure 2.For comparison, the graphs in Figures 1 and 2also show the curves corresponding to the evaluationof Pointwise Mutual Information (PMI).8 The co-occurrence statistics of the expressions in Disco-En-Gold was extracted from the window of size three,sliding through the whole lemmatized ukWaC cor-pus.Discussion As suggested in Section 3, we com-pare the results of the methods using Spearman andKendall correlations, AP, and Everts?
curves.
Wepresent the results of the LSA and PMI modelsalongside the results of the best performing modelsparticipating in the DISCO task.
Namely, Table 3presents the correlation values of our models, thebest performing WSM-based model (Reddy et al2011b), the best performing model based upon as-sociation measures (Chakraborty et al 2011), andrandom baseline models.The poor results achieved by employing PMI aresimilar to the results of random baselines and in ac-cordance with those of participants of the DISCOworkshop (Chakraborty et al 2011).
We hypoth-esize that the PMI-based model incorrectly assignslow values of semantic compositionality (high val-7Choice of this value can affect the results.
The value of 50was chosen since it is the middle value between the manuallyassigned scores ranging from 0 to 100.8PMI is an association measure used to determine thestrength of association between two or more words basedon their occurrences and co-occurrences in a corpus (Pecina,2009).46Model Dataset ?-All ?-AN ?-VO ?-SV ?
-All ?
-AN ?
-VO ?
-SV AP-AllLSA TrainValD 0.47 0.54 0.36 0.57 0.32 0.38 0.24 0.44 0.61PMI TrainValD 0.02 -0.25 0.29 0.14 0.01 -0.18 0.20 0.10 0.28baseline TrainValD 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.26LSA TestD 0.50 0.50 0.56 0.41 0.35 0.36 0.39 0.30 0.53Reddy-WSM TestD 0.35 - - - 0.24 - - - -StatMix TestD 0.33 - - - 0.23 - - - -PMI TestD -0.08 -0.07 0.13 -0.08 -0.06 -0.04 0.08 -0.07 0.21baseline TestD 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.20Table 3: The values of AP, Spearman (?)
and Kendall (? )
correlations between the LSA-based and PMI-based modelrespectively and the Gold data with regards to the expression type.
Every zero value in the table corresponds to thetheoretically achieved mean value of correlation calculated from the infinite number of correlation values between theranking of scores assigned by the annotators and the rankings of scores being obtained by a random number genarator.Reddy-WSM stands for the best performing WSM in the DISCO task (Reddy et al 2011b).
StatMix stands for the bestperforming system based upon association measures (Chakraborty et al 2011).
Only ?-All and ?
-All are available forthe models explored by Reddy et al(2011b) and Chakraborty et al(2011).ues of PMI) to frequently occurring fixed expres-sions.
For example, we observed that the calculatedvalues of PMI for ?international airport?
and ?reli-gious belief?
were high.To the contrary, our results achieved by employ-ing the LSA model are statistically significant andbetter than those of all the participants of the DISCOworkshop.
However, the data set is probably notlarge enough to provide statistically reliable com-parison of the methods and it is not clear how re-liable the dataset itself is (the interannotator agree-ment was not analyzed) and therefore we can notmake any hard conclusions.5 ConclusionWe analysed the previous works applying WSMsfor determining the semantic compositionality of ex-pressions.
We discussed and summarized the major-ity of techniques presented in the papers.
Our anal-ysis reveals a large diversity of approaches whichleads to incomparable results (Table 1).
Since it hasbeen shown that WSMs can serve as good predic-tors of semantic compositionality, we aim to createa comparative study of the approaches.Our analysis implies to evaluate the proposed ap-proaches using human annotated data and evalua-tion techniques based on ranking.
Namely, we sug-gest using Spearman and Kendall correlations, Pre-cision/nBest, Recall/nBest, Precision/Recall curves,and AP.Using the suggested evaluation techniques, wepresent the results of our first experiments exploit-ing LSA (Figures 1, 2 and Table 3).
The results ofthe LSA-based model, compared with random base-lines, PMI-based model, and all the WSM-based andstatistical-based models proposed by the participantsof the DISCO task, are very promising.AcknowledgmentsWe thank to V?
?t Suchomel for providing theukWaC corpus and the anonymous reviewers fortheir helpful comments and suggestions.
The re-search is supported by Advanced Computing andInformation Systems (grant no.
SGS-2013-029)and by the Czech Science Foundation (grant no.P103/12/G084).
Also, the access to the CERIT-SCcomputing facilities provided under the programmeCenter CERIT Scientific Cloud, part of the Opera-tional Program Research and Development for Inno-vations, reg.
no.
CZ.
1.05/3.2.00/08.0144 is highlyappreciated.ReferencesOtavio Costa Acosta, Aline Villavicencio, and Viviane P.Moreira.
2011.
Identification and treatment of multi-word expressions applied to information retrieval.
InProceedings of the Workshop on Multiword Expres-sions: from Parsing and Generation to the Real World,MWE ?11, pages 101?109, Stroudsburg, PA, USA.47Timothy Baldwin and Su Nam Kim.
2010.
Multiwordexpressions.
In Nitin Indurkhya and Fred J. Damerau,editors, Handbook of Natural Language Processing,Second Edition.
CRC Press, Taylor and Francis Group,Boca Raton, FL.
ISBN 978-1420085921.Timothy Baldwin, Colin Bannard, Takaaki Tanaka, andDominic Widdows.
2003.
An empirical model ofmultiword expression decomposability.
Proceedingsof the ACL 2003 workshop on Multiword expressionsanalysis acquisition and treatment, pages 89?96.Colin Bannard, Timothy Baldwin, and Alex Lascarides.2003.
A statistical approach to the semantics of verb-particles.
In Proceedings of the ACL 2003 work-shop on Multiword expressions: analysis, acquisitionand treatment, volume 18 of MWE ?03, pages 65?72,Stroudsburg, PA, USA.Marco Baroni, Silvia Bernardini, Adriano Ferraresi, andEros Zanchetta.
2009.
The WaCky wide web: acollection of very large linguistically processed web-crawled corpora.
Journal of Language Resources AndEvaluation, 43(3):209?226.Michael W. Berry, Susan T. Dumais, and Gavin W.O?Brien.
1995.
Using linear algebra for intelligentinformation retrieval.
SIAM Rev., 37(4):573?595.Chris Biemann and Eugenie Giesbrecht.
2011.
Distri-butional semantics and compositionality 2011: sharedtask description and results.
In Proceedings of theWorkshop on Distributional Semantics and Composi-tionality, DiSCo ?11, pages 21?28.Lou Burnard.
2000.
User reference guide for the BritishNational Corpus.
Technical report, Oxford UniversityComputing Services.Marine Carpuat and Mona Diab.
2010.
Task-based eval-uation of multiword expressions: a pilot study in statis-tical machine translation.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, HLT ?10, pages 242?245, Strouds-burg, PA, USA.Tanmoy Chakraborty, Santanu Pal, Tapabrata Mondal,Tanik Saikh, and Sivaju Bandyopadhyay.
2011.Shared task system description: Measuring the com-positionality of bigrams using statistical methodolo-gies.
In Proceedings of the Workshop on Distribu-tional Semantics and Compositionality, pages 38?42,Portland, Oregon, USA.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lexicogra-phy.
Comput.
Linguist., 16(1):22?29.Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-dauer, George W. Furnas, and Richard A. Harshman.1990.
Indexing by latent semantic analysis.
Jour-nal of the American Society of Information Science,41(6):391?407.Stefan Evert.
2005.
The statistics of word cooccur-rences: word pairs and collocations.
Ph.D. the-sis, Universita?t Stuttgart, Holzgartenstr.
16, 70174Stuttgart.Afsaneh Fazly.
2007.
Automatic Acquisition of LexicalKnowledge about Multiword Predicates.
Ph.D. thesis,University of Toronto.Mark Alan Finlayson and Nidhi Kulkarni.
2011.
De-tecting multi-word expressions improves word sensedisambiguation.
In Proceedings of the Workshop onMultiword Expressions: from Parsing and Generationto the Real World, MWE ?11, pages 20?24, Strouds-burg, PA, USA.Zellig Harris.
1954.
Distributional structure.
Word,10(23):146?162.Anders Johannsen, Hector Martinez Alonso, ChristianRish?j, and Anders S?gaard.
2011.
Shared task sys-tem description: frustratingly hard compositionalityprediction.
In Proceedings of the Workshop on Distri-butional Semantics and Compositionality, DiSCo ?11,pages 29?32, Stroudsburg, PA, USA.David Jurgens and Keith Stevens.
2010.
The s-spacepackage: an open source package for word space mod-els.
In Proceedings of the ACL 2010 System Demon-strations, ACLDemos ?10, pages 30?35, Stroudsburg,PA, USA.Graham Katz.
2006.
Automatic identification ofnon-compositional multi-word expressions using la-tent semantic analysis.
In In Proceedings of theACL/COLING-06 Workshop on Multiword Expres-sions: Identifying and Exploiting Underlying Proper-ties, pages 12?19.Lubom?
?r Krc?ma?r?, Karel Jez?ek, and Massimo Poesio.2012.
Detection of semantic compositionality usingsemantic spaces.
Lecture Notes in Computer Science,7499 LNAI:353?361.Thomas K. Landauer and Susan T. Dumais.
1997.
A so-lution to Plato?s problem: The latent semantic analysistheory of acquisition, induction, and representation ofknowledge.
Psychological Review, 104(2):211?240.Dekang Lin.
1999.
Automatic identification of non-compositional phrases.
In Proceedings of the 37thannual meeting of the Association for ComputationalLinguistics on Computational Linguistics, ACL ?99,pages 317?324, Stroudsburg, PA, USA.Kevin Lund and Curt Burgess.
1996.
Producinghigh-dimensional semantic spaces from lexical co-occurrence.
Behavior Research Methods, 28(2):203?208.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schu?tze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press, New York, NY,USA.48Diana McCarthy, Bill Keller, and John Carroll.
2003.Detecting a continuum of compositionality in phrasalverbs.
In Proceedings of the ACL 2003 workshop onMultiword expressions analysis acquisition and treat-ment, volume 18 of MWE ?03, pages 73?80.George A. Miller.
1995.
WordNet: A lexical databasefor English.
Communications of the ACM, 38:39?41.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
In Proceedings ofACL-08: HLT, pages 236?244, Columbus, Ohio.Darren Pearce.
2002.
A Comparative Evaluation ofCollocation Extraction Techniques.
In Proceedings ofthe Third International Conference on Language Re-sources and Evaluation, LREC.Pavel Pecina.
2009.
Lexical Association Measures: Col-location Extraction, volume 4 of Studies in Compu-tational and Theoretical Linguistics.
U?FAL, Praha,Czechia.Carlos Ramisch.
2012.
A generic framework for multi-word expressions treatment: from acquisition to appli-cations.
In Proceedings of ACL 2012 Student ResearchWorkshop, ACL ?12, pages 61?66, Stroudsburg, PA,USA.Siva Reddy, Diana McCarthy, and Suresh Manandhar.2011a.
An empirical study on compositionality incompound nouns.
In Proceedings of 5th InternationalJoint Conference on Natural Language Processing,pages 210?218, Chiang Mai, Thailand.Siva Reddy, Diana McCarthy, Suresh Manandhar, andSpandana Gella.
2011b.
Exemplar-based word-spacemodel for compositionality detection: Shared task sys-tem description.
In Proceedings of the Workshop onDistributional Semantics and Compositionality, pages54?60, Portland, Oregon, USA.Douglas L. Rohde, Laura M. Gonnerman, and David C.Plaut.
2005.
An improved model of semantic sim-ilarity based on lexical co-occurrence.
Unpublishedmanuscript.Ivan A.
Sag, Timothy Baldwin, Francis Bond, Ann A.Copestake, and Dan Flickinger.
2002.
Multiword ex-pressions: A pain in the neck for nlp.
In Proceedingsof the Third International Conference on Computa-tional Linguistics and Intelligent Text Processing, CI-CLing ?02, pages 1?15, London, UK.
Springer-Verlag.Magnus Sahlgren.
2005.
An introduction to random in-dexing.
In Methods and Applications of Semantic In-dexing Workshop at the 7th International Conferenceon Terminology and Knowledge Engineering, Leipzig,Germany.Magnus Sahlgren.
2006.
The Word-Space Model: Us-ing distributional analysis to represent syntagmaticand paradigmatic relations between words in high-dimensional vector spaces.
Ph.D. thesis, StockholmUniversity.Patrick Schone and Daniel Jurafsky.
2001.
Isknowledge-free induction of multiword unit dictionaryheadwords a solved problem?
In Proceedings of the2001 Conference on Empirical Methods in NaturalLanguage Processing, pages 100?108.Violeta Seretan.
2008.
Collocation extraction based onsyntactic parsing.
Ph.D. thesis, University of Geneva.Peter D. Turney and Patrick Pantel.
2010.
From fre-quency to meaning: vector space models of semantics.J.
Artif.
Int.
Res., 37(1):141?188.49baseline PMI LSA0 2 5 5 0 7 5 100 125 150 175nBest0.000.050.100.150.200.250.300.350.400.450.500.550.600.650.700.750.800.850.900.951.001.05Precisionbaseline PMI LSA0 2 5 5 0 7 5 100 125 150 175nBest0.000.050.100.150.200.250.300.350.400.450.500.550.600.650.700.750.800.850.900.951.001.05RecallFigure 1: Smoothed graphs depicting the dependency of Precision (left) and Recall (right) upon the nBest selectednon-compositional candidates from the ordered list of expressions in TestD created by the LSA and PMI-based models.baseline PMI LSA0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0Recall0.000.050.100.150.200.250.300.350.400.450.500.550.600.650.700.750.800.850.900.951.001.05Precisionbaseline PMI LSA0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0Recall0.000.050.100.150.200.250.300.350.400.450.500.550.600.650.700.750.800.850.900.951.001.05PrecisionFigure 2: Smoothed graphs depicting the dependency of Precision upon Recall using the LSA and PMI-based modelsordering the expressions in TrainValD (left) and TestD (right) according to their non-compositionality.50
