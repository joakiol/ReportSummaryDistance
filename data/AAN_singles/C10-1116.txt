Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1029?1037,Beijing, August 2010EMMA: A Novel Evaluation Metric for Morphological AnalysisSebastian SpieglerIntelligent Systems GroupUniversity of Bristolspiegler@cs.bris.ac.ukChristian MonsonCenter for Spoken Language UnderstandingOregon Health & Science Universitymonsonc@csee.ogi.eduAbstractWe present a novel Evaluation Metricfor Morphological Analysis (EMMA)that is both linguistically appealing andempirically sound.
EMMA uses a graph-based assignment algorithm, optimizedvia integer linear programming, to matchmorphemes of predicted word analysesto the analyses of a morphologically richanswer key.
This is necessary especiallyfor unsupervised morphology analysissystems which do not have access tolinguistically motivated morpheme labels.Across 3 languages, EMMA scores of14 systems have a substantially greaterpositive correlation with mean averageprecision in an information retrieval(IR) task than do scores from the metriccurrently used by the Morpho Challenge(MC) competition series.
We computeEMMA and MC metric scores for 93separate system-language pairs fromthe 2007, 2008, and 2009 MC compe-titions, demonstrating that EMMA isnot susceptible to two types of gamingthat have plagued recent MC competi-tions: Ambiguity Hijacking and SharedMorpheme Padding.
The EMMA eval-uation script is publicly available fromhttp://www.cs.bris.ac.uk/Research/MachineLearning/Morphology/Resources/.1 IntroductionWords in natural language are constructed fromsmaller building blocks called morphemes.
Forexample, the word wives breaks down into an un-derlying stem, wife, together with a plural suffix.Analyzing the morphological structure of wordsis known to benefit a variety of downstream nat-ural language (NL) tasks such as speech recogni-tion (Creutz, 2006; Ar?soy et al, 2009), machinetranslation (Oflazer et al, 2007), and informationretrieval (McNamee et al, 2008).A variety of automatic systems can morpholog-ically analyze words that have been removed fromtheir surrounding context.
These systems rangefrom hand-built finite state approaches (Beesleyand Karttunen, 2003) to recently proposed algo-rithms which learn morphological structure in anunsupervised fashion (Kurimo et al, 2007).
Sinceunsupervised systems do not have access to lin-guistically motivated morpheme labels, they typ-ically produce morphological analyses that areclosely related to the written form.
Such a systemmight decompose wives as wiv -es.
Meanwhile,a hand-built system might propose wife_N +Plu-ral, or even parse wives as a hierarchical featurestructure.
As morphological analysis systems pro-duce such varied outputs, comparing decomposi-tions from disparate systems is a challenge.This paper describes EMMA, an EvaluationMetric for Morphological Analysis that quantita-tively measures the quality of a set of morpholog-ical analyses in a linguistically adequate, empir-ically useful, and novel fashion.
EMMA evalu-ates analyses that can be represented as a flat setof symbolic features, including hierarchical repre-sentations, which can be projected down to a lin-earized form (Roark and Sproat, 2007).An automatic metric that discriminates be-tween proposed morphological analyses should1029fulfill certain computational and linguistic crite-ria.
Computationally, the metric should:1.
Correlate with the performance of real-worldNL processing tasks which embed the morpho-logical analyses.2.
Be Readily Computable: The metric will onlybe useful if it is less time consuming and easierto compute than the larger NL task.3.
Be Robust: The metric should be difficult togame and should accurately reflect the distri-bution of predicted and true morphemes.4.
Be Readily Interpretable: When possible, thefinal numeric score should directly identify thestrengths and weaknesses of the underlyingmorphological analysis system.While accounting for these computational re-quirements, a morphology metric should still re-ward accurate models of linguistic structure.
Inparticular, the metric should account for:1.
Morphophonology: Applying a morphologicalrule may alter the surface form of stem or af-fix.
In the word wives, /waivz/, a rule of mor-phophonology voices the stem-final /f/ of wife,/waif/, when the plural suffix is added.
A met-ric should penalize for not placing wives andwife as forms of the same lexeme.2.
Allomorphy: A metric should capture the suc-cessful grouping of allomorphs.
The Germanplural has several surface allomorphs includ-ing -en in Zeiten (times), -e in Hunde (dogs),and -s in Autos (cars).
A metric should rewarda morphological analysis system that analyzesthe different surface forms of the German plu-ral as underlyingly identical.3.
Syncretism: In mirror fashion, a metricshould reward analyses that distinguish be-tween surface-identical syncretic morphemes:although derives and derivations both containan -s morpheme, one marks 3rd person singularand the other plural.4.
Ambiguity: Finally, a metric should accountfor legitimate morphological ambiguity.
In He-brew, the written word MHGR has three vi-able morphological segmentations: M- H- GR,?from the foreigner?, M- HGR, ?from Hagar?,and the unsegmented form MHGR, meaning?immigrant?
(Lavie et al, 2004).
Absent dis-ambiguating context, a morphological systemshould be rewarded for calling out all threeanalyses for MHGR.Morphophonology, allomorphy, syncretism,and ambiguity are all common phenomena in theworld?s languages.
The first three have all re-ceived much discussion in theoretical linguistics(Spencer and Zwicky, 2001), while morpholog-ical ambiguity has significant practical implica-tions in NL processing, e.g.
in machine translationof morphologically complex languages (Lavie etal., 2004; Oflazer et al, 2007).In Section 2 we propose the metric EMMA,which has been specifically designed to evalu-ate morphological analyses according to our com-putational and linguistic criteria.
Section 3 thendescribes and qualitatively critiques several well-used alternative metrics.
Section 4 empiricallycompares EMMA against the qualitatively-strongmetric used in the Morpho Challenge competitionseries (Kurimo et al, 2009).
And we conclude inSection 5.2 EMMA: An Evaluation Metric forMorphological AnalysisEMMA, the metric we propose for the evalua-tion of morphological analyses, like all the met-rics that we consider in this paper, compares pro-posed morphological analyses against an answerkey of definitively-analyzed words from a vocab-ulary.
Since a set of proposed analyses is likelyto use a different labeling scheme than the answerkey, especially true of the output from unsuper-vised systems, EMMA does not perform a directcomparison among proposed and answer analy-ses.
Instead, EMMA seeks a one-to-one relabel-ing of the proposed morphemes that renders themas similar as possible to the answer key.
EMMA,then, measures the degree to which proposed anal-yses approximate an isomorphism of the answerkey analyses.
For exposition, we initially assumethat, for each word, a single proposed analysisis scored against a single unambiguous answeranalysis.
We relax this restriction in Section 2.3,where EMMA scores multiple proposed analyses1030against a set of legitimately ambiguous morpho-logical analyses.To find the most appropriate one-to-one mor-pheme relabeling, EMMA turns to a standard al-gorithm from graph theory: optimal maximummatching in a bipartite graph.
A bipartite graph,G = {X,Y ;E}, consists of two disjoint setsof vertices, X = {x1, x2, .
.
.
, xn} and Y = {y1,y2, .
.
.
, ym}, and a set of edges e(xi, yj) ?
Esuch that each edge has one end in X and the otherend in Y .
In EMMA, the set, A, of all unique mor-phemes in the answer key and the set, P , of allunique morphemes in the proposed analyses serveas the disjoint vertex sets of a bipartite graph.A matching M ?
E in a bipartite graph is de-fined as a set of edges e(xi, yj) such that no xior yj is repeated.
A maximum matching is amatching where no M ?
with |M ?| > |M | exists.Furthermore, a weight w(xi, yj) ?
< may be as-signed to each edge e(xi, yj) of a bipartite graph.An optimal assignment is a maximum matchingwhich also maximizes the sum of the weights ofthe edges of the matching?e(xi,yj)?Mw(xi, yj) .EMMA weights the edge between a particularanswer morpheme a ?
A and a proposed mor-pheme p ?
P as the number of words, w, in thevocabulary, V , where the answer analysis of w in-cludes morpheme a while the proposed analysisincludes p. EMMA constructs an optimal assign-ment maximum matching in this weighted bipar-tite morpheme graph.
The edge weights ensurethat the optimal matching will link the answer andproposed morphemes which globally occur in theanalyses of the same words most often ?
restrict-ing each answer morpheme to be represented by atmost one proposed morpheme, and each proposedmorpheme to represent at most one morpheme inthe answer key.
On the one hand, the restrictionsthus imposed by bipartite matching penalize setsof proposed analyses that do not differentiate be-tween surface-identical syncretic morphemes.
Onthe other hand, the same one-to-one matching re-strictions penalize proposed analyses that do notconflate allomorphs of the same underlying mor-pheme, whether those allomorphs are phonologi-cally induced or not.
Thus, EMMA meets our lin-guistic criteria from Section 1 of modeling syn-cretism, allomorphy, and morphophonology.2.1 Maximum Matching by Integer LinearProgrammingTo construct the maximum matching optimal as-signment of answer and proposed morphemes,EMMA uses standard integer linear programmingtechniques as implemented in lpsolve (Berkelaaret al, 2004).
For the purpose of our integer pro-gram, we represent the weight of each potentialedge of the optimal bipartite morpheme assign-ment in a count matrix C = {cij} where cij is as-signed the number of words w ?
V which sharemorpheme ai in the answer key and pj in the pre-diction.
We then define a binary matrix B = {bij}of the same dimensions as C. Each bij will be setto 1 if an edge exists from ai to pj in the optimalmaximum matching, with bij = 0 otherwise.
Theinteger linear program can then be defined as fol-lows:argmaxB?i,j(C ?B)ij (1)s.t.
?ibij ?
1 ,?jbij ?
1 , bij ?
0 ,where (C ?
B)ij = cij ?
bij is the element-wiseHadamard product.2.2 Performance MeasuresHaving settled on a maximum matching optimalassignment of proposed and answer morphemes,EMMA derives a final numeric score.
Let wkbe the kth word of V ; and let Ak and Pk de-note, respectively, the sets of morphemes in theanswer key analysis of wk and predicted analysisof wk.
Furthermore, let P ?k denote the predictedmorphemes for wk where a morpheme pj is re-placed by ai if bij = 1.
Now that Ak and P ?kcontain morpheme labels that are directly compa-rable, we can define precision and recall scoresfor the proposed analysis of the word wk.
Preci-sion is the fraction of correctly relabeled proposedmorphemes from among all proposed morphemesof wk; while recall is the number of correctly rela-beled morphemes as a fraction of the answer key1031analysis of wk.
Precision and recall of the full vo-cabulary are the average word-level precision andrecall:precision = 1|V ||V |?k|Ak?P ?k ||P ?k |, (2)recall = 1|V ||V |?k|Ak?P ?k ||Ak|.
(3)Finally, f-measure is the harmonic mean of pre-cision and recall:f -measure = 2 ?
precision ?
recallprecision+ recall .
(4)2.3 Morphological Ambiguity in EMMAThus far we have presented EMMA for the sce-nario where each word has a single morphologicalanalysis.
But, as we saw in Section 1 with the He-brew word MHGR, natural language permits sur-face forms to have multiple legitimate morpho-logical analyses.
When a word is truly ambigu-ous, EMMA expects an answer key to contain aset of analyses for that word.
Similarly, we per-mit sets of proposed alternative analyses.
To ex-tend EMMA with the ability to evaluate alterna-tive analyses we first generalize the optimal max-imum matching of morphemes from Section 2.1.We then define a new integer linear program tomatch answer and proposed alternative analyses.Finally, we adjust the performance measures ofSection 2.2 to account for alternatives.2.3.1 Ambiguity and Morpheme MatchingLet Ak,r denote the rth alternative answer anal-ysis of the kth word with 1 ?
r ?
mk, and letPk,s denote the sth alternative prediction with1 ?
s ?
nk, where mk is the number of alterna-tive analyses in the answer key and nk the num-ber of alternative predictions for wk.
We redefineAk =?mkr Ak,r and Pk =?nks Pk,s as the set ofall answer or, respectively, predicted morphemesof wk across all analysis alternatives.
Instead ofincrementing each cij entry in the count matrixC by a full count, we now add 1mk?nk to cij forall pairs (ai, pj) ?
Ak ?
Pk.
This corresponds tocounting each combination of an answer key andpredicted morpheme normalized by the number ofpossible pairings between proposed and answeranalysis alternatives.
When both the answer andproposed analyses consist of just a single alter-native, cij remains unchanged.
Generalized mor-pheme matching still employs the linear programdefined in Equation 1.2.3.2 Matching of Alternative AnalysesAfter performing a one-to-one morpheme rela-belling that accounts for ambiguity, we need toextend EMMA with the ability to evaluate alterna-tive analyses.
We again turn to optimal maximummatching in a bipartite graph: Where earlier wematched proposed and answer morphemes, nowwe match full proposed and answer analysis alter-natives, maximizing the total number of correctlypredicted morphemes across all alternatives.
Gen-eralizing on the notation of the unambiguous case,let P ?k,s denote the sth alternative predicted analy-sis of the kth word where predicted morphemeshave been replaced by their assigned answer keymorphemes.
We introduce a new count matrixC ?
= {c?r,s}, where c?r,s is the count of commonmorphemes of the rth answer key alternative andsth predicted alternative.
Based on Equation 1,we calculate the binary matrix B?
= {b?r,s} whichcontains the optimal assignment of the alternativeanswer key and predicted analyses for wk.2.3.3 Ambiguity and Performance ScoresWe now adjust EMMA?s numeric performancemeasures to account for sets of ambiguous anal-ysis alternatives.
Precision becomes1|V ||V |?k1nkmk?rnk?sb?r,s|Ak,r?P ?k,s||P ?k,s|, (5)the ratio of correctly predicted morphemes acrossall predicted alternatives normalised by the num-ber of predicted alternatives, nk, and the vocab-ulary size, |V |.
The factor b?r,s guarantees thatscores are only averaged over pairs of proposedand answer analysis alternatives that have been as-signed, that is, where b?r,s = 1.
Recall is measuredsimilarly with1|V ||V |?k1mkmk?rnk?sb?r,s|Ak,r?P ?k,s||Ak,r|.
(6)1032Here, we normalize by mk, the number of alterna-tive analyses for the kth word that are listed in theanswer key.
The normalisation factors 1mk and 1nkensure that predicting too few or many alternativeanalyses is penalised.3 Other Morphology MetricsHaving presented the EMMA metric for evaluat-ing the quality of a set of morphological analyses,we take a step back and examine other metrics thathave been proposed.
Morphology analysis metricscan be categorized as either: 1.
Directly compar-ing proposed analyses against an answer key, or 2.Indirectly comparing proposed and answer analy-ses by measuring the strength of an isomorphic-like relationship between the proposed and answermorphemes.
The proposed EMMA metric belongsto the second category of isomorphism-based met-rics.3.1 Metrics of Direct InspectionBy Segmentation Point.
Perhaps the most read-ily accessible automatic evaluation metric is a di-rect comparison of the morpheme boundary posi-tions in proposed and answer analyses.
As earlyas 1974, Hafer and Weiss used the direct boundarymetric.
Although intuitively simple, the segmen-tation point method implicitly assumes that it ispossible to arrive at a valid morphological anal-ysis by merely dividing the characters of a wordinto letter sequences that can be reconcatenated toform the original word.
But, by definition, con-catenation cannot describe non-contanative pro-cesses like morphophonology and allomorphy.Nor does simple segmentation adequately differ-entiate between surface-identical syncretic mor-phemes.
Despite these drawbacks, precision andrecall of segmentation points is still used in cur-rent morphological analysis research (Poon et al(2009), Snyder and Barzilay (2008), Kurimo et al(2006)).Against Full Analyses.
To confront the realityof non-concatenative morphological processes, ananswer key can hold full morphological analyses(as opposed to merely segmented surface forms).But while a hand-built (Beesley and Karttunen,2003) or supervised (Wicentowski , 2002) mor-phology analysis system can directly model theannotation standards of a particular morphologi-cal answer key, the label given to specific mor-phemes is ultimately an arbitrary choice that anunsupervised morphology induction system hasno way to discover.By Hand.
On the surface, scoring proposedanalyses by hand appears to provide a way to eval-uate the output of an unsupervised morphologyanalysis system.
Hand evaluation, however, doesnot meet our criteria from Section 1 for a robustand readily computable metric.
It is time consum-ing and, as Goldsmith (2001) explains, leaves dif-ficult decisions of what constitutes a morpheme toon-the-fly subjective opinion.3.2 Metrics of Isomorphic AnalysisRecognizing the drawbacks of direct evaluation,Schone and Jurafsky (2001), Snover et al (2002),and Kurimo et al (2007) propose related measuresof morphological analysis quality that are basedon the idea of an isomorphism.
For reasons thatwill be clear momentarily, we refer to the Schoneand Jurafsky, Snover et al, and Kurimo et al met-rics as soft isomorphic measures.
As discussedin Section 2, metrics of isomorphism measuresimilarities between the distribution of proposedmorphemes and the distribution of answer mor-phemes, where proposed and answer morphemesmay be disjoint symbol sets.Unlike the EMMA metric proposed in Section2, the soft metrics of isomorphism do not seekto explicitly link proposed morphemes to answermorphemes.
Instead, their metrics group sets orpairs of words which share, in either the pro-posed analyses or in the answer analyses, a stem(Schone and Jurafsky, 2001; Snover, 2002), a suf-fix (Snover et al, 2002), or any arbitrary mor-pheme (Kurimo et al, 2007).
The soft met-rics subsequently note whether these same sets orpairs of words share any morpheme in the answerkey or, respectively, in the proposed analyses.
Byforegoing a hard morpheme assignment, the softmetrics do not adequately punish sets of proposedand answer morphemes which fail to model syn-cretism and/or allomorphy.
For example, pro-posed analyses that annotate 3rd person singularand plural with a single undifferentiated +s mor-pheme will receive recall credit for both nouns and1033verbs.3.3 The Morpho Challenge MetricThe Morpho Challenge (MC) competition seriesfor unsupervised morphology analysis algorithms(Kurimo et al, 2009) has used a soft metric of iso-morphism in its most recent three years of compe-tition: 2007, 2008, and 2009.
According to Ku-rimo et al (2009) the Morpho Challenge (MC)measure samples random word pairs which shareat least one common morpheme.
Precision is cal-culated by generating random word pairs fromthe set of proposed analyses and then compar-ing the analyses of the word pairs in the answerkey.
The fraction of found and expected commonmorphemes is normalised by the number of wordswhich are evaluated.
Recall is defined in mirrorfashion.
The MC metric also normalizes preci-sion and recall scores across sets of alternativeanalyses for each word in the proposal and answerkey.
To our knowledge the MC metric is the firstisomorphism-based metric to attempt to accountfor morphological ambiguity.
As we show in Sec-tion 4, however, MC?s handling of ambiguity iseasily gamed.The MC metric does meet our criterion of beingreadily computable and, as we will show in the ex-perimental section, the metric also correlates to acertain extent with performance on a higher-levelnatural language processing task.
The downsideof the MC metric, however, is robustness.
In addi-tion to MC?s crude handling of ambiguity and itsover-counting of allomorphs and syncretic mor-phemes, the random pair sampling method thatMC uses is not independent of the set of analysesbeing evaluated.
If two algorithms predict differ-ent morpheme distributions, the sampling methodwill find different numbers of word pairs.
We sub-stantiate our claim that the MC metric lacks ro-bustness in Section 4 where we empirically com-pare it to the EMMA metric.4 Experimental EvaluationTo experimentally evaluate our newly proposedEMMA metric, and to quantitatively compare theEMMA and MC metrics, we have evaluated re-sults of 93 system-language pairs from MorphoChallenge 2007, 2008, and 2009.1 The evaluationcomprised three algorithms by Bernhard (2007)and Bernhard (2009), one algorithm by Can andManandhar (2009), the MC baseline algorithmMorfessor by Creutz (2006), UNGRADE by Gole-nia et al (2009), two algorithms by Lavallee andLanglais (2009), one algorithm by Lignos et al(2009), five ParaMor versions by Monson et al(2008) and Monson et al (2009), three Promodesversions by Spiegler et al (2009) and one al-gorithm by Tchoukalov et al (2009).
We ranthese algorithms over six data sets available fromthe MC competition: Arabic (vowelized and non-vowelized), English, Finnish, German, and Turk-ish.
We then scored the system outputs using bothEMMA and the MC metric against an answer keyprovided by MC.
In Sections 2 and 3.3 we have al-ready commented on the linguistic characteristicsof both metrics.
In this section, we concentrate ontheir computational performance.Both the EMMA and MC metrics are readilycomputable: Both are freely available2 and theyeach take less than two minutes to run on the av-erage desktop machines we have used.
In termsof interpretability, EMMA not only returns theperformance as precision, recall and f-measureas MC does, but also provides predicted analy-ses where mapped morphemes are replaced by an-swer key morphemes.
This information is help-ful when judging results qualitatively since it ex-poses tangible algorithmic characteristics.
In Ta-ble 1 we present the algorithms with the highestMC and EMMA scores for each language.
Forall languages, the EMMA and MC metrics placedifferent algorithms highest.
One reason for thesignificantly different rankings that the two met-rics provide may be the sampling of random pairsthat MC uses.
Depending on the distribution ofpredicted morphemes across words, the numberof random pairs, which is used for calculating theprecision, may vary.
For instance, on vowelizedArabic, Promodes 1 is evaluated over a sampleof 100 pairs where MC selected just 47 pairs forParaMor Mimic.1Detailed results can be found in Spiegler (2010).2EMMA may be downloaded from http://www.cs.bris.ac.uk/Research/MachineLearning/Morphology/Resources/1034Language Algorithm and year of MC evaluation metric EMMA evaluation metricparticipation in MC Pr.
Re.
F1 Pr.
Re.
F1Arabic (nv) Promodes 2 2009 0.7789 0.3980 0.5268 0.5356 0.2444 0.3356Ungrade 2009 0.7971 0.1603 0.2670 0.7017 0.2490 0.3675Arabic (vw) Promodes 2 2009 0.5946 0.6017 0.5982 0.4051 0.3199 0.3575Promodes 1 2009 0.7381 0.3477 0.4727 0.5588 0.3281 0.4135English Bernhard 1 2007 0.7850 0.5763 0.6647 0.8029 0.7460 0.7734Lignos 2009 0.7446 0.4716 0.5775 0.9146 0.6747 0.7766Finnish ParaMorPlusMorfessor 2008 0.5928 0.5675 0.5798 0.2271 0.3428 0.2732Lavallee rali-cof 2009 0.6731 0.3563 0.4659 0.5061 0.4065 0.4509German ParaMorPlusMorfessor 2008 0.5562 0.6077 0.5808 0.3633 0.4948 0.4190Morfessor 2009 0.6528 0.3818 0.4818 0.7311 0.5556 0.6314Turkish ParaMorPlusMorfessor 2008 0.6779 0.5732 0.6212 0.3476 0.4315 0.3851Morfessor 2009 0.7894 0.3330 0.4684 0.5901 0.3703 0.4550Table 1: Best performing algorithms with MC and EMMA evaluation metric.Algorithm and year of MC evaluation metric EMMA evaluation metricparticipation in MC Pr.
Re.
F1 Pr.
Re.
F1Morfessor 2009 0.8143 0.2788 0.4154 0.4751 0.3472 0.4012ParaMor 2008 0.4111 0.4337 0.4221 0.4322 0.3770 0.4027ParaMorPlusMorfessor 2008 0.5928 0.5675 0.5798 0.2271 0.3428 0.2732Paramor Morfessor Union 2009 0.4374 0.5676 0.4941 0.3878 0.4530 0.4178Table 3: Gaming MC with ambiguity hijacking on Finnish.Looking at any particular algorithm-languagepair, the EMMA and MC scores differ consider-ably and respective raw scores are not directlycomparable.
More interesting is the extent towhich both metrics correlate with real NL tasks.Table 2 lists the Spearman rank correlation co-efficient for algorithms from MC 2009 on En-glish, Finnish and German comparing rankings off-measure results returned by either MC or EMMAagainst rankings using the mean average preci-sion (MAP) of an information retrieval (IR) task.3All MAP scores are taken from Kurimo et al(2009).
Although both metrics positively correlatewith the IR results; EMMA?s correlation is clearlystronger across all three languages.To test the robustness of the EMMA and MCmetrics, we performed two experiments where weintentionally attempt to game the metrics ?
ambi-guity hijacking and shared morpheme padding.
Inboth experiments, the MC metric showed vulnera-bility.
Ambiguity hijacking results for Finnish ap-3Detailed results can be found in Spiegler (2010).pear in Table 3, other languages perform similarly.Using both metrics, we scored the Finnish analy-ses that were proposed by a) the Morfessor algo-rithm alone, b) ParaMor alone, and c) two waysof combining ParaMor and Morfessor: ParaMor-PlusMorfessor simply lists the ParaMor and Mor-fessor analyses as alternatives ?
as if each wordwere ambiguous between a ParaMor and a Mor-fessor analysis; ParaMorMorfessorUnion, on theother hand, combines the morpheme boundarypredictions of ParaMor and Morfessor into a sin-gle analysis.
The ParaMorPlusMorfessor systemgames the ambiguity mechanism of the MC met-ric, achieving an f-measure higher than that of anyof the three other algorithms.
EMMA, however,correctly discovers that the analyses proposed byParaMorPlusMorfessor lie farther from an iso-morphism to the the answer key than do the uni-fied analyses of ParaMorMorfessorUnion.In Table 4 we show a second way of gamingthe MC metric ?
shared morpheme padding.
Weadd the same unique bogus morpheme to eachproposed analysis of every word for all systems.1035Language MC evaluation EMMA evaluationPrecision Recall F-measure Precision Recall F-measureArabic (nv) 0.91?0.02 10.83?
8.33 7.20?5.10 0.91?0.05 1.30?0.07 1.20?0.05Arabic (vw) 0.85?0.04 11.17?8.81 7.13?5.23 0.89?0.07 1.21?0.06 1.12?0.05English 0.36?0.08 2.02?0.66 0.63?0.10 0.73?0.15 1.05?0.08 0.86?0.12Finnish 0.57?0.08 3.07?2.47 1.19?0.68 0.87?0.19 1.12?0.10 0.99?0.14German 0.43?0.08 2.90?1.45 0.84?0.16 0.80?0.17 1.09?0.08 0.94?0.11Turkish 0.58?0.09 2.95?1.65 1.19?0.37 0.85?0.08 1.07?0.04 0.97?0.05Table 4: Gaming MC with shared morpheme padding: Average and standard deviations of the ratio ofpadded to original scores.Padding analyses with a shared morpheme signif-icantly increases the recall scores of the MC met-ric.
We summarize our experimental results bycalculating, for each language-algorithm pair, theratio of the score for the padded analyses as com-pared to that of the original, unpadded analyses.Table 4 reports average and standard deviation ofthe ratios across all systems for each language.
InArabic (nv.
and vw.
), the recall increases by 10.83and 11.17 times, which leads to an inflation of f-measure by 7.20 and 7.13 times ?
this is a directresult of the soft nature of the MC isomorphism.In contrast, EMMA?s recall scores increase muchless than MC?s do, and EMMA?s precision scoresdecrease proportionately.
A small change to theset of proposed analyses does not lead to a hugedifference in f-measure ?
characteristic of a morerobust metric.5 ConclusionThis paper has proposed, EMMA, a novel evalua-tion metric for the assessment of the quality of aset of morphological analyses.
EMMA?s:1.
Coverage of the major morphological phenom-ena,Correlation with IRIR vs. MC IR vs. EMMAEnglish 0.466 0.608Finnish 0.681 0.759German 0.379 0.637Table 2: Spearman rank correlation coefficient ofmetrics vs. Information Retrieval (IR).2.
Correlation with performance on natural lan-guage processing tasks, and3.
Computational robustnessall recommend the the metric as a strong and use-ful measure ?
particularly when evaluating un-supervised morphology analysis systems which,lacking access to labeled training data, are unin-formed of the labeling standard used in the answerkey.AcknowledgementsWe would like to acknowledge various fruitfuldiscussions with Aram Harrow, Alex Popa, TiloBurghardt and Peter Flach.
The work was par-tially sponsored by EPSRC grant EP/E010857/1Learning the morphology of complex syntheticlanguages, as well as by NSF Grant #IIS-0811745and DOD/NGIA grant #HM1582-08-1-0038.ReferencesAr?soy, Ebru, Dog?an Can, S?dd?ka Parlak, Has?im Sak,and Murat Sara?lar.
2009.
Turkish Broadcast NewsTranscription and Retrieval.
IEEE Trans.
on Audio,Speech and Lang.
Proc.Beesley, Kenneth R. and Lauri Karttunen.
2003.Finite State Morphology.
University of ChicagoPress.Berkelaar, Michel, Kjell Eikland, and Peter Note-baert.
2004.
Open source (mixed-integer) lin-ear programming system, version 5.1.0.0. http://lpsolve.
sourceforge.net/.Bernhard, Delphine.
2007.
Simple morpheme la-belling in unsupervised morpheme analysis.
Work-ing Notes, CLEF 2007 Workshop.1036Bernhard, Delphine.
2009.
Morphonet: Exploring theuse of community structure for unsupervised mor-pheme analysis.
Working Notes, CLEF 2009 Work-shop.Can, Burcu and Suresh Manandhar.
2009.
Unsuper-vised learning of morphology by using syntactic cat-egories.
Working Notes, CLEF 2009 Workshop.Creutz, Mathias.
2006.
Induction of the Morphol-ogy of Natural Language: Unsupervised MorphemeSegmentation with Application to Automatic SpeechRecognition.
Ph.D. thesis, Helsinki University ofTechnology, Espoo, Finland.Goldsmith, John.
2001.
Unsupervised learning of themorphology of a natural language.
Comp.
Ling., 27.Gol?nia, Bruno, Sebastian Spiegler, and Peter Flach.2009.
Ungrade: unsupervised graph decomposi-tion.
Working Notes, CLEF 2009 Workshop.Hafer, M. A. and S. F. Weiss.
1974.
Word segmenta-tion by letter successor varieties.
Inf.
Storage andRetrieval, 10.Kurimo, Mikko, Mathias Creutz, Matti Varjokallio,Ebru Arisoy, Murat Saraclar.
2006.
Unsupervisedsegmentation of words into morphemes - MorphoChallenge 2005.
Interspeech.Kurimo, Mikko, Mathias Creutz, and Ville Turunen.2007.
Overview of morpho challenge in CLEF2007.
Working Notes, CLEF 2007 Workshop.Kurimo, Mikko and Ville Turunen.
2008.
Unsuper-vised Morpheme Analysis Evaluation by IR exper-iments ?
Morpho Challenge 2008.
Working Notes,CLEF 2008 Workshop.Kurimo, Mikko, Sami Virpioja, and Ville T. Turunen.2009.
Overview and results of morpho challenge2009.
Working Notes, CLEF 2009 Workshop.Lavallee, Jean-Francois and Philippe Langlais.
2009.Morphological Acquisition by Formal Analogy.Working Notes, CLEF 2009 Workshop.Lavie, Alon, Erik Peterson, Katharina Probst, ShulyWintner, Yaniv Eytani.
2004.
Rapid Prototyp-ing of a Transfer-based Hebrew-to-English MachineTranslation System.
Proc.
of TMI-2004.Lignos, Constantine, Erwin Chan, Mitchell P. Mar-cus, and Charles Yang.
2009.
A rule-based unsu-pervised morphology learning framework.
WorkingNotes, CLEF 2009 Workshop.McNamee, Paul, Charles Nicholas, and James May-field.
2008.
Don?t Have a Stemmer?
Be Un+con-cern+ed Proc.
of the 31st Anual International ACMSIGIR Conference 20-24 July 2008.Monson, Christian, Jaime Carbonell, Alon Lavie, andLori Levin.
2008.
Paramor and morpho challenge2008.
Working Notes, CLEF 2008 Workshop.Monson, Christian, Kristy Hollingshead, and BrianRoark.
2009.
Probabilistic paramor.
WorkingNotes, CLEF 2009 Workshop.Oflazer, Kemal, and I?lknur Durgar El-Kahlout.
2007.Different Representational Units in English-to-Turkish Statistical Machine Translation.
Proc.
ofStatistical Machine Translation Workshop at ACL2007.Poon, Hoifung, Colin Cherry and Kristina Toutanova2009.
Unsupervised Morphological Segmentationwith Log-Linear Models.
Proc.
of ACL.Roark, Brian and Richard Sproat.
2007.
Computa-tional Approaches to Morphology and Syntax.
Ox-ford Univ.
Press.Schone, Patrick and Daniel Jurafsky.
2001.
Know-lege-free induction of inflectional morphologies.Proc.
of NAACL-2001.Snover, Matthew G., Gaja E. Jarosz and Michael R.Brent.
2002.
Unsupervised Learning of Morphol-ogy Using a Novel Directed Search Algorithm: Tak-ing the First Step.
Proc.
of the ACL-02 SIGPHONWorkshop.Snyder, Benjamin and Regina Barzilay.
2008.
Unsu-pervised Multilingual Learning for MorphologicalSegmentation.
Proc.
of ACL-08: HLT.Spencer, Andrew and Arnold M. Zwicky, editors.2001.
The Handbook of Morphology.
Wiley-Black-well.Spiegler, Sebastian, Bruno Gol?nia, and Peter A.Flach.
2009.
Promodes: A probabilistic genera-tive model for word decomposition.
Working Notes,CLEF 2009 Workshop.Spiegler, Sebastian.
2010.
EMMA: A Novel Metric forMorphological Analysis - Experimental Results inDetail.
Computer Science Department, Universityof Bristol, U.K.Tchoukalov, Tzvetan, Christian Monson, and BrianRoark.
2009.
Multiple sequence alignment formorphology induction.
Working Notes, CLEF 2009Workshop.Wicentowski, Richard 2002.
Modeling and Learn-ing Multilingual Inflectional Morphology in a Min-imally Supervised Framework.
Ph.D. thesis, TheJohns Hopkins University, Baltimore, Maryland,U.S.A.1037
