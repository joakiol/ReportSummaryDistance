Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 249?256,Sydney, July 2006. c?2006 Association for Computational LinguisticsCorrecting ESL Errors Using Phrasal SMT TechniquesChris Brockett, William B. Dolan, and Michael GamonNatural Language Processing GroupMicrosoft ResearchOne Microsoft Way, Redmond, WA 98005, USA{chrisbkt,billdol,mgamon}@microsoft.comAbstractThis paper presents a pilot study of theuse of phrasal Statistical Machine Trans-lation (SMT) techniques to identify andcorrect writing errors made by learners ofEnglish as a Second Language (ESL).Using examples of mass noun errorsfound in the Chinese Learner Error Cor-pus (CLEC) to guide creation of an engi-neered training set, we show that applica-tion of the SMT paradigm can capture er-rors not well addressed by widely-usedproofing tools designed for native speak-ers.
Our system was able to correct61.81% of mistakes in a set of naturally-occurring examples of mass noun errorsfound on the World Wide Web, suggest-ing that efforts to collect alignable cor-pora of pre- and post-editing ESL writingsamples offer can enable the develop-ment of SMT-based writing assistancetools capable of repairing many of thecomplex syntactic and lexical problemsfound in the writing of ESL learners.1 IntroductionEvery day, in schools, universities and busi-nesses around the world, in email and on blogsand websites, people create texts in languagesthat are not their own, most notably English.
Yet,for writers of English as a Second Language(ESL), useful editorial assistance geared to theirneeds is surprisingly hard to come by.
Grammarcheckers such as that provided in MicrosoftWord have been designed primarily with nativespeakers in mind.
Moreover, despite growingdemand for ESL proofing tools, there has beenremarkably little progress in this area over thelast decade.
Research into computer feedback forESL writers remains largely focused on small-scale pedagogical systems implemented withinthe framework of CALL (Computer Aided Lan-guage Learning) (Reuer 2003; VanderventerFaltin, 2003), while commercial ESL grammarcheckers remain brittle and difficult to customizeto meet the needs of ESL writers of differentfirst-language (L1) backgrounds and skill levels.Some researchers have begun to apply statis-tical techniques to identify learner errors in thecontext of essay evaluation (Chodorow & Lea-cock, 2000; Lonsdale & Strong-Krause, 2003), todetect non-native text (Tomokiyo & Jones, 2001),and to support lexical selection by ESL learnersthrough first-language translation (Liu et al,2000).
However, none of this work appears todirectly address the more general problem ofhow to robustly provide feedback to ESL writ-ers?and for that matter non-native writers inany second language?in a way that is easily tai-lored to different L1 backgrounds and second-language (L2) skill levels.In this paper, we show that a noisy channelmodel instantiated within the paradigm of Statis-tical Machine Translation (SMT) (Brown et al,1993) can successfully provide editorial assis-tance for non-native writers.
In particular, theSMT approach provides a natural mechanism forsuggesting a correction, rather than simplystranding the user with a flag indicating that thetext contains an error.
Section 2 further motivatesthe approach and briefly describes our SMT sys-tem.
Section 3 discusses the data used in our ex-periment, which is aimed at repairing a commontype of ESL error that is not well-handled by cur-rent grammar checking technology: mass/countnoun confusions.
Section 4 presents experimentalresults, along with an analysis of errors producedby the system.
Finally we present discussion andsome future directions for investigation.2492 Error Correction as SMT2.1 Beyond Grammar CheckingA major difficulty for ESL proofing is that errorsof grammar, lexical choice, idiomaticity, andstyle rarely occur in isolation.
Instead, any givensentence produced by an ESL learner may in-volve a complex combination of all these errortypes.
It is difficult enough to design a proofingtool that can reliably correct individual errors;the simultaneous combination of multiple errorsis beyond the capabilities of current proofingtools designed for native speakers.
Consider thefollowing example, written by a Korean speakerand found on the World Wide Web, which in-volves the misapplication of countability to amass noun:And I knew many informationsabout Christmas while I waspreparing this article.The grammar and spelling checkers in MicrosoftWord 2003 correctly suggest many ?
muchand informations ?
information.Accepting these proposed changes, however,does not render the sentence entirely native-like.Substituting the word much for many leavesthe sentence stilted in a way that is probably un-detectable to an inexperienced non-nativespeaker, while the use of the word knew repre-sents a lexical selection error that falls well out-side the scope of conventional proofing tools.
Abetter rewrite might be:And I learned a lot of in-formation about Christmaswhile I was preparing thisarticle.or, even more colloquially:And I learned a lot aboutChristmas while I was pre-paring this articleRepairing the error in the original sentence,then, is not a simple matter of fixing an agree-ment marker or substituting one determiner foranother.
Instead, wholesale replacement of thephrase knew many informations withthe phrase learned a lot is needed to pro-duce idiomatic-sounding output.
Seen in theseterms, the process of mapping from a raw, ESL-authored string to its colloquial equivalent looksremarkably like translation.
Our goal is to showthat providing editorial assistance for writersshould be viewed as a special case of translation.Rather than learning how strings in one languagemap to strings in another, however, ?translation?now involves learning how systematic patterns oferrors in ESL learners?
English map to corre-sponding patterns in native English2.2 A Noisy Channel Model of ESL ErrorsIf ESL error correction is seen as a translationtask, the task can be treated as an SMT problemusing the noisy channel model of (Brown et al,1993): here the L2 sentence produced by thelearner can be regarded as having been corruptedby noise in the form of interference from his orher L1 model and incomplete language modelsinternalized during language learning.
The task,then, is to reconstruct a corresponding valid sen-tence of L2 (target).
Accordingly, we can seek toprobabilistically identify the optimal correct tar-get sentence(s) T* of an ESL input sentence S byapplying the familiar SMT formula:( ){ }{ })P()|P(maxarg|Pmaxarg*TTSSTTTT==In the context of this model, editorial assis-tance becomes a matter of identifying those seg-ments of the optimal target sentence or sentencesthat differ from the writer?s original input anddisplaying them to the user.
In practice, the pat-terns of errors produced by ESL writers of spe-cific L1 backgrounds can be captured in thechannel model as an emergent property of train-ing data consisting ESL sentences aligned withtheir corrected edited counterparts.
The highestfrequency errors and infelicities should emergeas targets for replacement, while lesser frequencyor idiosyncratic problems will in general not sur-face as false flags.2.3 ImplementationIn this paper, we explore the use of a large-scaleproduction statistical machine translation systemto correct a class of ESL errors.
A detailed de-scription of the system can be found in (Menezes& Quirk 2005) and (Quirk et al, 2005).
In keep-ing with current best practices in SMT, our sys-tem is a phrasal machine translation system thatattempts to learn mappings between ?phrases?
(which may not correspond to linguistic units)rather than individual words.
What distinguishes250this system from other phrasal SMT systems isthat rather than aligning simple sequences ofwords, it maps small phrasal ?treelets?
generatedby a dependency parse to corresponding stringsin the target.
This ?Tree-To-String?
model holdspromise in that it allows us to potentially benefitfrom being able to access a certain amount ofstructural information during translation, withoutnecessarily being completely tied to the need fora fully-well-formed linguistic analysis of the in-put?an important consideration when it issought to handle ungrammatical or otherwise ill-formed ESL input, but also simultaneously tocapture relationships not involving contiguousstrings, for example determiner-noun relations.In our pilot study, this system was em-ployed without modification to the system archi-tecture.
The sole adjustment made was to haveboth Source (erroneous) and Target (correct) sen-tences tokenized using an English language to-kenizer.
N-best results for phrasal alignment andordering models in the decoder were optimizedby lambda training via Maximum Bleu, along thelines described in (Och, 2003).3 Data Development3.1 Identifying Mass NounsIn this paper, we focus on countability errors as-sociated with mass nouns.
This class of errors(involving nouns that cannot be counted, such asinformation, pollution, and home-work) is characteristically encountered in ESLwriting by native speakers of several East Asianlanguages (Dalgish, 1983; Hua & Lee, 2004).1We began by identifying a list of English nounsthat are frequently involved in mass/count errorsin by writing by Chinese ESL learners, by takingthe intersection of words which:?
occurred in either the Longman Dictionaryof Contemporary English or the AmericanHeritage Dictionary with a mass sense?
were involved in n ?
2 mass/count errors inthe Chinese Learner English CorpusCLEC (Gui and Yang, 2003), either taggedas a mass noun error or else with an adja-cent tag indicating an article error.21These constructions are also problematic for hand-crafted MT systems (Bond et al, 1994).2CLEC tagging is not comprehensive; some commonmass noun errors (e.g., make a good progress)are not tagged in this corpus.This procedure yielded a list of 14 words:knowledge, food, homework, fruit,news, color, nutrition, equipment,paper, advice, haste, information,lunch, and tea.
3   Countability errors in-volving these words are scattered across 46 sen-tences in the CLEC corpus.For a baseline representing the level of writingassistance currently available to the average ESLwriter, we submitted these sentences to theproofing tools in Microsoft Word 2003.
Thespelling and grammar checkers correctly identi-fied 21 of the 46 relevant errors, proposed oneincorrect substitution (a few advice ?
a fewadvices), and failed to flag the remaining 25errors.
With one exception, the proofing toolssuccessfully detected as spelling errors incorrectplurals on lexical items that permit only massnoun interpretations (e.g., informations),but ignored plural forms like fruits and pa-pers even when contextually inappropriate.
Theproofing tools in Word 2003 also detected singu-lar determiner mismatches with obligatory pluralforms (e.g.
a news).3.2 Training DataThe errors identified in these sentences providedan informal template for engineering the data inour training set, which was created by manipulat-ing well-formed, edited English sentences.
Rawdata came from a corpus of ~484.6 million wordsof Reuters Limited newswire articles, releasedbetween 1995 and 1998, combined with a~7,175,000-word collection of articles from mul-tiple news sources from 2004-2005.
The result-ing dataset was large enough to ensure that alltargeted forms occurred with some frequency.From this dataset we culled about 346,000sentences containing examples of the 14 targetedwords.
We then used hand-constructed regularexpressions to convert these sentences intomostly-ungrammatical strings that exhibitedcharacteristics of the CLEC data, for example:?
much ?
many: much advice ?many advice?
some ?
a/an: some advice ?an advice?
conversions to plurals: much goodadvice ?
many good advices3Terms that also had a function word sense, such aswill, were eliminated for this experiment.251?
deletion of counters: piece(s)/item(s)/sheet(s) of)?
insertion of determinersThese were produced in multiple combinationsfor broad coverage, for example:I'm not trying to give youlegal advice.
??
I'm not trying to give you alegal advice.?
I'm not trying to give youthe legal advice.?
I'm not trying to give youthe legal advices.A total of 24128 sentences from the news datawere ?lesioned?
in this manner to create a set of65826 sentence pairs.
To create a balanced train-ing set that would not introduce too many arti-facts of the substitution (e.g., many should notalways be recast as much just because that is theonly mapping observed in the training data), werandomly created an equivalent number of iden-tity-mapped pairs from the 346,000 examples,with each sentence mapping to itself.Training sets of various sizes up to 45,000pairs were then randomly extracted from the le-sioned and non-lesioned pairs so that data fromboth sets occurred in roughly equal proportions.Thus the 45K data set contains approximately22,500 lesioned examples.
An additional 1,000randomly selected lesioned sentences were setaside for lambda training the SMT system?s or-dering and replacement models.4  Evaluation4.1 Test DataThe amount of tagged data in CLEC is too smallto yield both development and test sets from thesame data.
In order to create a test set, we had athird party collect 150 examples of the 14 wordsfrom English websites in China.
After minorcleanup to eliminate sentences irrelevant to thetask,4 we ended up with 123 example sentencesto use as test set.
The test examples vary widelyin style, from the highly casual to more formalpublic announcements.
Thirteen examples weredetermined to contain no errors relevant to ourexperiment, but were retained in the data.54.2 ResultsTable 1 shows per-sentence results of translatingthe test set on systems built with training datasets of various sizes (given in thousands of sen-tence pairs).
Numbers for the proofing tools inWord 2003 are presented by way of comparison,with the caveat that these tools have been inten-tionally implemented conservatively so as not topotentially irritate native users with false flags.For our purposes, a replacement string is viewedas correct if, in the view of a native speaker whomight be helping an ESL writer, the replacementwould appear more natural and hence potentiallyuseful as a suggestion in the context of that sen-tence taken in isolation.
Number disagreementon subject and verb were ignored for the pur-poses of this evaluation, since these errors werenot modeled when we introduced lesions into thedata.
A correction counted as Whole if the sys-tem produced a contextually plausible substitu-tion meeting two criteria: 1) number and 2) de-terminer/quantifier selection (e.g., many in-formations ?
much information).Transformations involving bare singular targets(e.g., the fruits ?
fruit) also countedas Whole.
Partial corrections are those whereonly one of the two criteria was met and part ofthe desired correction was missing (e.g., an4In addition to eliminating cases that only involvedsubject-verb number agreement, we excluded a smallamount of spam-like word salad, several instances ofthe word homework being misused to mean ?workdone out of the home?, and one misidentified quota-tion from Scott?s Ivanhoe.5This test set may be downloaded athttp://research.microsoft.com/research/downloadsData Size Whole Partial Correctly Left New Error Missed Word Order  Error45K 55.28  0.81  8.13  12.20  21.14  1.6330K 36.59  4.07  7.32  16.26  32.52  3.2515K 47.15  2.44  5.69  11.38  29.27  4.07cf.
Word 29.27  0.81  10.57  1.63  57.72  N/ATable 1.
Replacement percentages (per sentence basis) using different training data sets252equipments ?
an equipment versus thetargeted bare noun equipment).
Incorrect sub-stitutions and newly injected erroneous materialanywhere in the sentence counted as New Errors,even if the proposed replacement were otherwisecorrect.
However, changes in upper and lowercase and punctuation were ignored.The 55.28% per-sentence score for Wholematches in the system trained on the 45K data setmeans that it correctly proposed full correctionsin 61.8% of locations where corrections neededto be made.
The percentage of Missed errors, i.e.,targeted errors that were ignored by the system,is correspondingly low.
On the 45K training dataset, the system performs nearly on a par withWord in terms of not inducing corrections onforms that did not require replacement, as shownin the Correctly Left column.
The dip in accu-racy in the 30K sentence pair training set is anartifact of our extraction methodology: the rela-tively small lexical set that we are addressinghere appears to be oversensitive to random varia-tion in the engineered training data.
This makesit difficult to set a meaningful lower bound onthe amount of training data that might be neededfor adequate coverage.
Nonetheless, it is evidentfrom the table, that given sufficient data, SMTtechniques can successfully offer corrections fora significant percentage of cases of the phenom-ena in question.Table 2 shows some sample inputs togetherwith successful corrections made by the system.Table 3 illustrates a case where two valid correc-tions are found in the 5-best ranked translations;intervening candidates were identical with thetop-ranked candidate.4.3 Error AnalysisTable 1 also indicates that errors associated withthe SMT system itself are encouragingly few.
Asmall number of errors in word order were found,one of which resulted in a severely garbled sen-tence in the 45K data set.
In general, the percent-age of this type of error declines consistentlywith growth of the training data size.
Linearity ofthe training data may play a role, since the sen-tence pairs differ by only a few words.
On thewhole, however, we expect the system?s ordermodel to benefit from more training data.The most frequent single class of newly intro-duced error relates to sporadic substitution of theword their for determiners a/the.
This isassociated with three words, lunch, tea, andhaste, and is the principal contributor to thelower percentages in the Correctly Left bin, ascompared with Word.
This overgeneralizationerror reflects our attempt to engineer the discon-tinuous mapping the X of them ?
theirX, motivated by examples like the following,encountered in the CLEC dataset:Input Shanghai residents can buy the fruits for a cheaper price than before.Replacement Shanghai residents can buy fruit for a cheaper price than before .Input Thank u for giving me so many advice.Replacement thank u for giving me so much advice .Input Acquiring the knowledge of information warfare is key towinning warsReplacement acquiring knowledge of information warfare is key to win-ning warsInput Many knowledge about Li Bai can be gain through it.Replacement much knowledge about Li Bai can be gain through it .Input I especially like drinking the tea.Replacement i especially like drinking tea .Input Icons printed on a paper have been brought from Europe,and were pasted on boards on Taiwan.Replacement icons printed on paper have been brought from Europe , andwere pasted on boards on Taiwan .Table 2.
Sample corrections, using 45K engineered training data253In this equal world, lots ofpeople are still concernedon the colors of them ?The inability of our translation system to handlesuch discontinuities in a unitary manner reflectsthe limited ability of current SMT modelingtechniques to capture long-distance effects.
Simi-lar alternations are rife in bilingual data, e.g.,ne?pas in French (Fox, 2002) and separableprefixes in German (Collins et al 2005).
AsSMT models become more adept at modelinglong-distance effects in a principled manner,monolingual proofing will benefit as well.The Missed category is heterogeneous.
TheSMT system has an inherent bias against deletion,with the result that unwanted determiners tendednot to be deleted, especially in the smaller train-ing sets.Other errors related to coverage in the devel-opment data set.
Several occurrences of green-grocer?s apostrophes (tea?s, equipment?s)caused correction failures: these were not antici-pated when engineering the training data.
Like-wise, the test data presented several malformedquantifiers and quantifier-like phrases (plentytea ?
plenty of tea, a lot infor-mation ?
a lot of information,few information ?
too little in-formation) that had been unattested in thedevelopment set.
Examples such as these high-light the difficulty in obtaining complete cover-age when using handcrafted techniques, whetherto engineer errors, as in our case, or to handcrafttargeted correction solutions.The system performed poorly on words thatcommonly present both mass and count nounsenses in ways that are apt to confuse L2 writers.One problematic case was paper.
The follow-ing sentences, for example, remained uncor-rected:He published many paper inprovincial and national pub-lication.He has published thirty-twopieces of papers.Large amounts of additional training datawould doubtless be helpful in providing contex-tual resolutions to the problems.
Improvedalignment models may also play a role here incapturing complex structures of the kind repre-sented by constructions involving counters.5 DiscussionThe artificially-engineered training data that werelied on for our experiments proved surprisinglyuseful in modeling real errors made by non-native speakers.
However, this is obviously a lessthan ideal data source, since the errors introducedby regular expressions are homogenously dis-tributed in a way that naturally-occurring errorsare not, creating artifacts that undoubtedly impairour SMT models.Artificial data of this sort may be useful asproof of concept, but hand engineering such dataplainly does not present a viable path to develop-ing real world applications.
In order to be able tohandle the rich panoply of errors and error inter-actions encountered in the text of second lan-guage learners large quantities of naturally-occurring ?before?
and ?after?
texts will need tobe collected.
By way of illustration, Table 4shows the output of results of ?translating?
ourtest data into more natural English by hand anddumping the pre- and post-editing pairs to the45K training set.6 Although we were unable toexactly recover the target sentences, inspectionshowed that 25 sentences had improved, somesignificantly, as Table 4 shows.
Under the rightconditions, the SMT system can capture contex-tual morphological alternations (nutri-tion/nutritious), together with complexmappings represented by the dependencieslearn ?
knowledge ?
many (ESL) and6Since a single example of each pair was insufficientto override the system?s inherent bias towards uni-gram mappings, 5 copies of each pair were appendedto the training data.Input: And we can learn many knowledge or new information from TVCandidate 1: And we can learn much knowledge or new information from TVCandidate 5: And we can learn a lot of knowledge or new information from TVTable 3.
Multiple replacement candidates generated by 45K training set254gain ?
knowledge ?
a lot of (Eng-lish).
In a rule-based correction system, an im-mense amount of hand-coding would be requiredto handle even a small subset of the potentialrange of such mismatches between learner andnative-like English.
This knowledge, we believe,is best acquired from data.5.1 The Need for Data CollectionGiven a sufficiently large corpus of aligned sen-tences containing error patterns produced by ESLwriters of the same L1 background and their cor-rected counterparts we expect eventually to beable to capture the rich complexity of non-nativeerror within a noisy-channel based SMT model.As a practical matter, however, parallel data ofthe kind needed is far from easy to come by.
Thisdoes not mean, however, that such data does notexist.
The void left by commercial grammarcheckers is filled, largely unobserved, by a num-ber of services that provide editorial assistance,ranging from foreign language teachers, to lan-guage helpdesks in multinational corporations, tomentoring services for conferences.
Translationbureaus frequently offer editing services for non-native speakers.
Yet, unlike translation, the ?be-fore?
and ?after?
texts are rarely recycled in aform that can be used to build translation models.Although collecting this data will involve a largeinvestment in time, effort, and infrastructure, aserious effort along these lines is likely to provefruitful in terms of making it possible to applythe SMT paradigm to ESL error correction.5.2 Feedback to SMTOne challenge faced by the SMT model is theextremely high quality that will need to be at-tained before a system might be usable.
Since itis highly undesirable that learners should be pre-sented with inaccurate feedback that they maynot have the experience or knowledge to assess,the quality bar imposed on error correction is farhigher than is that tolerated in machine transla-tion.
Exploration of error correction and writingassistance using SMT models may thus prove animportant venue for testing new SMT models.5.3 Advantages of the SMT ApproachStatistical Machine Translation has provided ahugely successful research paradigm within thefield of natural language processing over the lastdecade.
One of the major advantages of usingSMT in ESL writing assistance is that it can beexpected to benefit automatically from any pro-gress made in SMT itself.
In fact, the approachpresented here benefits from all the advantagesof statistical machine translation.
Since the archi-tecture is not dependent on hard-to-maintainrules or regular expressions, little or no linguisticexpertise will be required in developing andmaintain applications.
As with SMT, this exper-tise is pushed into the data component, to behandled by instructors and editors, who do notneed programming or scripting skills.We expect it to be possible, moreover, onceparallel data becomes available, to quickly rampup new systems to accommodate the needs ofInput sentence And we can learn many knowledge or new information fromTV.45K system output and we can learn much knowledge or new information fromTV .45K + translation sys-tem outputwe can gain a lot of knowledge or new information fromTV .Input sentence The following is one of the homework for last week.45K system output the following is one of their homework for last week .45K + translation sys-tem outputthe following is one of the homework assignments forlast week .Input sentence i like mushroom,its very nutrition45K system output i like mushroom , its very nutrition45K + translation sys-tem output i like mushroom , its very nutritiousTable 4.
Contextual corrections before and after adding ?translations?
to 45K training data255learners with different first-language back-grounds and different skill levels and to writingassistance for learners of L2s other than English.It is also likely that this architecture may haveapplications in pedagogical environments and asa tool to assist editors and instructors who dealregularly with ESL texts, much in the manner ofeither Human Assisted Machine Translation orMachine Assisted Human Translation.
We alsobelieve that this same architecture could be ex-tended naturally to provide grammar and styletools for native writers.6 Conclusion and Future DirectionsIn this pilot study we have shown that SMT tech-niques have potential to provide error correctionand stylistic writing assistance to L2 learners.The next step will be to obtain a large dataset ofpre- and post-editing ESL text with which totrain a model that does not rely on engineereddata.
A major purpose of the present study hasbeen to determine whether our hypothesis is ro-bust enough to warrant the cost and effort of acollection or data creation effort.Although we anticipate that it will take a sig-nificant lead time to assemble the necessaryaligned data, once a sufficiently large corpus isin hand, we expect to begin exploring ways toimprove our SMT system by tailoring it morespecifically to the demands of editorial assistance.In particular, we expect to be looking into alter-native word alignment models and possibly en-hancing our system?s decoder using some of thericher, more structured language models that arebeginning to emerge.AcknowledgementsThe authors have benefited extensively from dis-cussions with Casey Whitelaw when he internedat Microsoft Research during the summer of2005.
We also thank the Butler Hill Group forcollecting the examples in our test set.ReferencesBond, Francis, Kentaro Ogura and Satoru Ikehara.1994.
Countability and Number in Japanese-to-English Machine Translation.
COLING-94.Peter E Brown, Stephen A. Della Pietra, Robert L.Mercer, and Vincent J. Della Pietra.
1993.
TheMathematics of Statistical Machine Translation.Computational Linguistics, Vol.
19(2): 263-311.Martin Chodorow and Claudia Leacock.
2000.
AnUnsupervised Method for Detecting GrammaticalErrors.
NAACL 2000.Michael Collins, Philipp Koehn and Ivona Ku?erov?.2005.
Clause Restructuring for Statistical machineTranslation.
ACL 2005, 531-540.Gerard M. Dalgish.
1984.
Computer-Assisted ESLResearch.
CALICO Journal.
2(2): 32-33Heidi J.
Fox.
2002.
Phrasal Cohesion and StatisticalMachine Translation.
EMNLP 2002.Shicun Gui and Huizhong Yang (eds).
2003 Zhong-guo Xuexizhe Yingyu Yuliaohu.
(Chinese LearnerEnglish Corpus).
Shanghai: Shanghai WaiyuJiaoyu Chubanshe.
(In Chinese).Hua Dongfan and Thomas Hun-Tak Lee.
2004.
Chi-nese ESL Learners' Understanding of the EnglishCount-Mass Distinction.
In Proceedings of the 7thGenerative Approaches to Second Language Ac-quisition Conference (GASLA 2004).Ting Liu, Ming Zhou, Jianfeng Gao, Endong Xun,and Changning Huang.
2000.
PENS: A Machine-aided English Writing System for Chinese Users.ACL 2000.Deryle Lonsdale and Diane Strong-Krause.
2003.Automated Rating of ESL Essays.
In Proceedingsof the HLT/NAACL Workshop: Building Educa-tional Applications Using Natural Language Proc-essing.Arul Menezes, and Chris Quirk.
2005.
Microsoft Re-search Treelet Translation System: IWSLT Evalua-tion.
Proceedings of the International Workshop onSpoken Language Translation.Franz Josef Och, 2003.
Minimum error rate trainingin statistical machine translation.
ACL 2003.Franz Josef Och and Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
ACL 2000.Chris Quirk, Arul Menezes, and Colin Cherry.
2005.Dependency Tree Translation: Syntactically In-formed Phrasal SMT.
ACL 2005.Veit Reuer.
2003.
Error Recognition and Feedbackwith Lexical Functional Grammar.
CALICO Jour-nal, 20(3): 497-512.Laura Mayfield Tomokiyo and Rosie Jones.
2001.You?re not from round here, are you?
Naive BayesDetection of Non-Native Utterance Text.
NAACL2001.Anne Vandeventer Faltin.
2003.
Natural languageprocessing tools for computer assisted languagelearning.
Linguistik online 17, 5/03 (http://www.linguistik-online.de/17_03/vandeventer.html)256
