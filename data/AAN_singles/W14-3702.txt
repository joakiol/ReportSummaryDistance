Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 6?14,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsExploiting Timegraphs in Temporal Relation ClassificationNatsuda Laokulrat?, Makoto Miwa?, and Yoshimasa Tsuruoka?
?The University of Tokyo, 3-7-1 Hongo, Bunkyo-ku, Tokyo, Japan{natsuda,tsuruoka}@logos.t.u-tokyo.ac.jp?Toyota Technological Institute, 2-12-1 Hisakata, Tempaku-ku, Nagoya, Japanmiwa@toyota-ti.ac.jpAbstractMost of the recent work on machinelearning-based temporal relation classifi-cation has been done by considering onlya given pair of temporal entities (events ortemporal expressions) at a time.
Entitiesthat have temporal connections to the pairof temporal entities under inspection arenot considered even though they providevaluable clues to the prediction.
In thispaper, we present a new approach for ex-ploiting knowledge obtained from nearbyentities by making use of timegraphs andapplying the stacked learning method tothe temporal relation classification task.By performing 10-fold cross validationon the Timebank corpus, we achieved anF1 score of 59.61% based on the graph-based evaluation, which is 0.16 percent-age points higher than that of the localapproach.
Our system outperformed thestate-of-the-art system that utilizes globalinformation and achieved about 1.4 per-centage points higher accuracy.1 IntroductionTemporal relationships between entities, namelytemporal expressions and events, are regarded asimportant information for deep understanding ofdocuments.
Being able to predict temporal re-lations between events and temporal expressionswithin a piece of text can support various NLP ap-plications such as textual entailment (Bos et al.,2005), multi-document summarization (Bollegalaet al., 2010), and question answering (Ravichan-dran and Hovy, 2002).Temporal relation classification, which is one ofthe subtasks TempEval-3 (UzZaman et al., 2013),aims to classify temporal relationships betweenpairs of temporal entities into one of the 14 re-lation types according to the TimeML specifica-tion (Pustejovsky et al., 2005), e.g., BEFORE, AF-TER, DURING, and BEGINS.The Timebank corpus introduced by Puste-jovsky et al.
(2003) has enabled the machinelearning-based classification of temporal relation-ship.
By learning from the annotated relationtypes in the documents, it is possible to predictthe temporal relation of a given pair of temporalentities (Mani et al., 2006).However, most of the existing machinelearning-based systems use local informationalone, i.e., they consider only a given pair of tem-poral entities at a time.
Entities that have tem-poral connections to the entities in the given pairare not considered at all even though they providevaluable clues to the prediction.
Hence, the lo-cal approach often produces contradictions.
Forinstance, the system may predict that A happensbefore B, that B happens before C, and that A hap-pens after C, which are mutually contradictory.In order to tackle the contradiction problem,global approaches have been proposed by Cham-bers and Jurafsky (2008) and Yoshikawa et al.(2009).
Chamber and Jurafsky proposed a globalmodel based on Integer Linear Programming thatcombines the output of local classifiers and max-imizes the global confidence scores.
While theyfocused only on the temporal relations betweenevents, Yoshikawa et al.
proposed a Markov Logicmodel to jointly predict the temporal relations be-tween events and time expressions.In this paper, we propose an approach thatutilizes timegraphs (Miller and Schubert, 1999),which represent temporal connectivity of all tem-poral entities in each document, for the relationclassification.
Our method differs from the pre-vious work in that their methods used transitionrules to enforce consistency within each triplet ofrelations, but our method can also work with a setconsisting of more than three relations.
Moreover,6Figure 1: An example from the Timebank corpusin our work, the full set of temporal relations spec-ified in TimeML are used, rather than the reducedset used in the previous work.We evaluate our method on the TempEval-3?sTask C-relation-only data, which provides a sys-tem with all the appropriate temporal links andonly needs the system to classify the relationtypes.
The result shows that by exploiting thetimegraph features in the stacked learning ap-proach, the classification performance improvessignificantly.
By performing 10-fold cross valida-tion on the Timebank corpus, we can achieve an F1score of 59.61% based on the graph-based evalu-ation, which is 0.16 percentage points (pp) higherthan that of the local approach.
We compared theresults of our system to those of Yoshikawa et al.
(2009) and achieved about 1.4 pp higher accuracy.The remainder of the paper is organized as fol-lows.
Section 2 explains the temporal relationclassification task and the pairwise classifier.
Sec-tion 3 and Section 4 describe our proposed time-graph features and the application to the stackedlearning approach.
Section 5 shows the experi-ment setup and presents the results.
Finally, wediscuss the results in 6 and conclude with direc-tions for future work in Section 7.2 Temporal Relation ClassificationAccording to TempEval-3, a temporal annotationtask consists of several subtasks, including tempo-ral expression extraction (Task A), event extrac-tion (Task B), and temporal link identification andrelation classification (Task C).
Our work, as withthe previous work mentioned in Section 1, onlyfocuses on the relation classification task (Task C-relation only).
The system does not extract eventsand temporal expressions automatically.A pair of temporal entities, including events andtemporal expressions, that is annotated as a tem-poral relation is called a TLINK.
Temporal rela-tion classification is a task to classify TLINKs intotemporal relation types.Following TempEval-3, all possible TLINKsare between:?
Event and Document Creation Time (DCT)?
Events in the same sentence?
Event and temporal expression in the samesentence?
Events in consecutive sentences2.1 The Timebank corpusThe Timebank corpus is a human-annotated cor-pus commonly used in training and evaluating atemporal relation classifier.
It is annotated follow-ing the TimeML specification to indicate events,temporal expressions, and temporal relations.
Italso provides five attributes, namely, class, tense,aspect, modality, and polarity, associated witheach event (EVENT), and four attributes, namely,type, value, functionInDocument, and temporal-Function, associated with each temporal expres-sion (TIMEX3).
An example of the annotated eventand temporal expression is shown in Figure 1.The sentence is brought from wsj 0292.tml in theTimebank corpus.There is no modal word in the sentence, so theattribute modality does not appear.We use the complete set of the TimeML rela-tions, which has 14 types of temporal relations in-cluding BEFORE, AFTER, IMMEDIATELY BEFORE, IM-MEDIATELY AFTER, INCLUDES, IS INCLUDED, DUR-ING, DURING INVERSE, SIMULTANEOUS, IDENTITY,BEGINS, BEGUN BY, END, and ENDED BY.
However,in TempEval-3, SIMULTANEOUS and IDENTITY areregarded as the same relation type, so we changeall IDENTITY relations into SIMULTANEOUS.Given the example mentioned above, the tem-poral relation is annotated as shown in the last lineof Figure 1.
From the annotated relation, the eventrose (e30) happens DURING the temporal expres-sion the first nine months (t88).7Feature E-E E-T DescriptionEvent attributesClass X XAll attributes associated with events.
The ex-planation of each attribute can be found in(Pustejovsky et al., 2005).Tense X XAspect X XModality X XPolarity X XTimex attributesType XAll attributes associated with temporal ex-pressions.
The explanation of each attributecan be found in (Pustejovsky et al., 2005).Value XFunctionInDocument XTemporalFunction XMorphosyntactic informationWords X XWords, POS, lemmas within a window be-fore/after event words extracted using Stan-ford coreNLP (Stanford NLP Group, 2012)Part of speech tags X XLemmas X XLexical semantic informationSynonyms of event word tokens X XWordNet lexical database (Fellbaum, 1998)Synonyms of temporal expressions XEvent-Event informationClass match XDetails are described in (Chambers et al.,2007)Tense match XAspect match XClass bigram XTense bigram XAspect bigram XSame sentence X X True if both temporal entities are in the samesentenceDeep syntactic informationPhrase structure X X Deep syntactic information extracted fromEnju Parser (Miyao and Tsujii, 2008).
Thedetails are described in (Laokulrat et al.,2013)Predicate-argument structure X XTable 1: Local featuresFeature E-E E-T DescriptionAdjacent nodes and links X XThe details are described in Subsection 3.2Other paths X XGeneralized paths X X(E,V,E) tuples X X(V,E,V) tuples X XTable 2: Timegraph features8Figure 2: path length ?
2Figure 3: path length ?
33 Proposed methodRather than using only local information ontwo entities in a TLINK, our goal is to exploitmore global information which can be extractedfrom a document?s timegraph.
Our motivationis that temporal relations of nearby TLINKs ina timegraph provide very useful information forpredicting the relation type of a given TLINK.
Forinstance, consider the following sentence and thetemporal connectivity shown in Figure 2.About 500 people attended (e1) a Sundaynight memorial for the Buffalo-area physicianwho performed abortions, one year (t1) after hewas killed (e2) by a sniper?s bullet.It can be seen that the relation between e1 andt1 and the relation between t1 and e2 are usefulfor predicting the relation between e1 and e2.Another more-complicated example is shownbelow with temporal connectivity in Figure 3.?The Congress of the United States is af-fording(e1) Elian Gonzalez what INS and thisadministration has not, which is his legal rightand his right to due process,?
said(e2) JorgeMas Santos, chairman of the Cuban AmericanNational Foundation.
?This gives(e3) him theprotection that he will not be repatriated(e4) toCuba between now and Feb.
10.?Figure 5: Local pairwise classification.
EachTLINK is classified separately.Figure 6: Timegraph constructed from a docu-ment?s TLINKsAgain, the relation between e4 and e3can be inferred from the nearby relations,i.e., (1) e4 AFTER e2 and e2 AFTER e1imply e4 AFTER e1, (2) e4 AFTER e1 ande1 SIMULTANEOUS e3 imply e4 AFTER e3.3.1 Overview of our frameworkOur framework is based on the stacked learn-ing method (Wolpert, 1992), which employs twostages of classification as illustrated in Figure 4.3.1.1 Local pairwise modelIn a local pairwise model, temporal relation clas-sification is done by considering only a given pairof temporal entities at a time as illustrated in Fig-ure 5.
We use a supervised machine learning ap-proach and employ the basic feature set that canbe easily extracted from the document?s text andthe set of features proposed in our previous work(Laokulrat et al., 2013), which utilizes deep syn-tactic information, as baselines.
The local featuresat different linguistic levels are listed in Table 1.Two classifiers are used: one for Event-EventTLINKs (E-E), and the other for Event-TimeTLINKs (E-T).3.1.2 Stacked learningStacked learning is a machine learning methodthat enables the learner to be aware of the labelsof nearby examples.9Figure 4: Stacked learning.
The output from the first stage is treated as features for the second stage.The final output is predicted using label information of nearby TLINKs.The first stage, as shown in Figure 5, uses thelocal classifiers and predicts the relation types ofall TLINKs.
In the second stage, the document?stimegraph is constructed and the output from thefirst stage is associated with TLINKs in the graph.The classifiers in the second stage use the infor-mation from the nearby TLINKs and predict thefinal output.
We exploit features extracted fromthe documents?
timegraphs, as listed in Section 3.2in the second stage of the stacked learning.An example of a document?s timegraph isshown in Figure 6.3.2 Timegraph featuresWe treat timegraphs as directed graphs and doublethe number of edges by adding new edges withopposite relation types/directions to every existingedge.
For example, if the graph contains an edgee1 BEFORE e2, we add a new edge e2 AFTER e1.Our proposed timegraph features are describedbelow.?
Adjacent nodes and linksThe features are the concatenation of the di-rections to the adjacent links to the pair of en-tities, the relation types of the links, and theinformation on the adjacent nodes, i.e., wordtokens, part of speech tags, lemmas.
For ex-ample, the features for predicting the relationbetween e1 and e2 in Figure 6 are SRC OUT-IS INCLUDED-(Type of t0), DEST IN-BEFORE-(Type of t0), and so on.In this work, only Type of temporal expres-sion (an attribute given in the Timebank cor-pus), Tense and Part-of-speech tag are ap-plied but other attributes could also be used.?
Other pathsPaths with certain path lengths (in this work,2 ?
path length ?
4) between the temporalentities are used as features.
The paths mustnot contain cycles.
For example, the pathfeatures of the relation between e1 and e2are IS INCLUDED-BEFORE and SIMULTANEOUS-BEFORE-BEFORE.?
Generalized pathsA generalized version of the path features,e.g., the IS INCLUDED-BEFORE path is gener-alized to *-BEFORE and IS INCLUDED-*.?
(E,V,E) tuplesThe (E,V,E) tuples of the edges and ver-tices on the path are used as features, e.g.,IS INCLUDED (Type of t0) BEFORE.?
(V,E,V) tuplesThe (V,E,V) tuples of the edges and verticeson the path are used as features, e.g., (Tenseof e1) IS INCLUDED (Type of t0) and (Type oft0) BEFORE (Tense of e2).The summary of the timegraph features isshown in Table 2.4 Relation inference and time-timeconnectionWe call TLINKs that have more than one path be-tween the temporal entities ?multi-path TLINKs?.The coverage of the multi-path TLINKs is pre-sented in Table 3.
The annotated entities in10the Timebank corpus create loosely connectedtimegraphs as we can see from the table that only5.65% of all the annotated TLINKs have multiplepaths between given pairs of temporal entities.Since most of the timegraph features are onlyapplicable for multi-path TLINKs, it is importantto have dense timegraphs.
In order to increasethe numbers of connections, we employ two ap-proaches: relation inference and time-time con-nection.4.1 Relation inferenceWe create new E-E and E-T connections betweenentities in a timegraph by following a set of infer-ence rules.
For example, if e1 happens AFTER e2and e2 happens IMMEDIATELY AFTER e3, then weinfer a new temporal relation ?e1 happens AFTERe3?.
In this paper, we add a new connection onlywhen the inference gives only one type of tem-poral relation as a result from the relation infer-ence.
Figure 7b shows the timegraph after addingnew inference relations to the original timegraphin Figure 7a.4.2 Time-time connectionAs with Chambers et al.
(2007) and Tatu andSrikanth (2008), we also create new connectionsbetween time entities in a timegraph by applyingsome rules to normalized values of time entitiesprovided in the corpus.Figure 7c shows the timegraph after adding atime-time link and new inference relations to theoriginal timegraph in Figure 7a.
When the nor-malized value of t2 is more than the value of t1,a TLINK with the relation type AFTER is addedbetween them.
After that, as introduced in Sub-section 4.2, new inference relations (e1-e2, e1-e3,e2-e3) are added.As the number of relations grows too large af-ter performing time-time connection and infer-ence relation recursively, we limited the number ofTLINKs for each document?s timegraph to 10,000relations.
The total number of TLINKs for all doc-uments in the corpus is presented in Table 4.
Thefirst row is the number of the human-annotated re-lations.
The second and third rows show the to-tal number after performing relation inference andtime-time connection.
(a) Original timegraph(b) After relation inference.
Two relations (e1-e2, e1-e3)are added.afterafter(c) After time-time connection (t1-t2) and relation inference.Three relations (e1-e2, e1-e3, e2-e3) are added.Figure 7: Increasing number of TLINKsNo.
of TLINKs E-E E-T TotalAll TLINKs 2,520 2,463 4,983Multi-path TLINKs 119 163 282Percentage 4.72 6.62 5.65Table 3: Coverage of multi-path TLINKs11ApproachGraph-based evaluationF1(%) P(%) R(%)Local - baseline features 58.15 58.17 58.13Local - baseline + deep features 59.45 59.48 59.42Stacked - baseline features 58.33 58.37 58.29Stacked (inference) - baseline features 58.30 58.32 58.27Stacked (inference, time-time) - baseline features 58.29 58.31 58.27Stacked - baseline + deep features 59.55 59.51 59.58Stacked (inference) - baseline + deep features 59.55 59.57 59.52Stacked (inference, time-time) - baseline + deep features 59.61 59.63 59.58Table 5: Ten-fold cross validation results on the training setNo.
of TLINKs TotalAnnotated 4,983+Inference 24,788+Inference + time-time connection 87,992Table 4: Number of TLINKs in the Timebank cor-pus5 EvaluationFor the baselines and both stages of the stackedlearning, we have used the LIBLINEAR (Fanet al., 2008) and configured it to work as L2-regularized logistic regression classifiers.We trained our models on the Timebank corpus,introduced in Subsection 2.1, which was providedby the TempEval-3 organiser.
The corpus contains183 newswire articles in total.5.1 Results on the training dataThe performance analysis is performed based on10-fold cross validation over the training data.
Theclassification F1 score improves by 0.18 pp and0.16 pp compared to the local pairwise modelswith/without deep syntactic features.We evaluated the system using a graph-basedevaluation metric proposed by UzZaman andAllen (2011).
Table 5 shows the classificationaccuracy over the training set using graph-basedevaluation.The stacked model affected the relation classi-fication output of the local model, changing therelation types of 390 (out of 2520) E-E TLINKsand 169 (out of 2463) E-T TLINKs.5.2 Comparison with the state of the artWe compared our system to that of Yoshikawaet al.
(2009) which uses global information toimprove the accuracy of temporal relation clas-sification.
Their system was evaluated based onTempEval-2?s rules and data set (Verhagen et al.,2007), in which the relation types were reduced tosix relations: BEFORE, OVERLAP, AFTER, BEFORE-OR-OVERLAP, OVERLAP-OR-AFTER, and VAGUE.
Theevaluation was done using 10-fold cross validationover the same data set as that of their reported re-sults.According to TempEval-2?s rules, there arethree tasks as follows:?
Task A: Temporal relations between eventsand all time expressions appearing in thesame sentence.?
Task B: Temporal relations between eventsand the DCT.?
Task C: Temporal relations betweeen mainverbs of adjacent sentences.The number of TLINKs annotated by the orga-nizer, after relation inference, and after time-timeconnection for each task is summarized in Table7.
Table 8 shows the number of TLINKs after per-forming relation inference and time-time connec-tion.As shown in Table 6, our system can achievebetter results in task B and C even without deepsyntactic features but performs worse than theirsystem in task A.
Compared to the baselines, theoverall improvement is statistically significant* (p< 10?4, McNemar?s test, two-tailed) without deepsyntactic features and gets more statistically sig-nificant** (p< 10?5, McNemar?s test, two-tailed)when applying deep syntactic information to thesystem.
The overall result has about 1.4 pp higheraccuracy than the result from their global model.Note that Yoshikawa et al.
(2009) did not applydeep syntactic features in their system.12Approach Task A Task B Task C OverallYoshikawa et al.
(2009) (local) 61.3 78.9 53.3 66.7Yoshikawa et al.
(2009) (global) 66.2 79.9 55.2 68.9Our system (local) - baseline features 59.9 80.3 58.5 68.5Our system (local) - baseline + deep features 62.1 80.3 58.4 69.0Our system (stacked) - baseline features 59.5 79.9 58.5 68.2Our system (stacked, inference) - baseline features 59.9 80.0 59.7 68.7Our system (stacked, inference, time-time) - baseline fea-tures63.8 80.0 58.9 69.5*Our system (stacked) - baseline + deep features 63.5 79.4 58.0 68.9Our system (stacked, inference) - baseline + deep features 63.7 80.3 59.2 69.7Our system (stacked, inference, time-time) - baseline +deep features65.9 80.5 58.9 70.3**Table 6: Comparison of the stacked model to the state of the art and to our local model (F1 score(%))No.
of TLINKs Task A Task B Task CAnnotated 1,490 2,556 1,744Table 7: TempEval-2 data setNo.
of TLINKs TotalAnnotated 5,970+Inference 156,654+Inference + time-time connection 167,875Table 8: Number of relations in TempEval-2 datasetThe stacked model enhances the classificationaccuracy of task A when timegraphs are denseenough.
Deep syntactic features can be extractedonly when temporal entities are in the same sen-tences so they improve the model for task A(event-time pairs in the same sentences) but thesefeatures clearly lower the accuracy of task C, sincethere are very few event-event pairs that appearin the same sentences (and break the definitionof task C).
This is probably because the sparse-ness of the deep features degrades the performancein task C. Moreover, these features do not helptask B in the local model because we cannot ex-tract any deep syntactic features from TLINKs be-tween events and DCT.
However, they contributeslightly to the improvement in the stacked modelsince deep syntactic features increase the accuracyof the prediction of task A in the first stage of thestacked model.
As a result, timegraph features ex-tracted from the output of the first stage are betterthan those extracted from the local model trainedon only baseline features.6 DiscussionAs we can see from Table 5 and 6, althoughdeep syntactic features can improve the classifi-cation accuracy significantly, some additional pre-processing is required.
Moreover, deep parsersare not able to parse sentences in some specificdomains.
Thus, sometimes it is not practical touse this kind of features in real-world temporalrelation classification problems.
By applying thestacked learning approach to the temporal relationclassification task, the system with only baselinefeatures is able to achieve good classification re-sults compared to the system with deep syntacticfeatures.Again, from Table 5 and 6, the inference andtime-time connection, described in Section 4,sometimes degrade the performance.
This is pre-sumably because the number of features increasesseverely as the number of TLINKs increased.The stacked model also has another advantagethat it is easy to build and does not consume toomuch training time compared to MLNs used byYoshikawa et al.
(2009), which are, in general,computationally expensive and infeasible for largetraining sets.7 ConclusionIn this paper, we present an approach for exploit-ing timegraph features in the temporal relationclassification task.
We employ the stacked learn-ing approach to make use of information obtainedfrom nearby entities in timegraphs.
The results13show that our system can outperform the state-of-the-art system and achieve good accuracy by us-ing only baseline features.
We also apply the rela-tion inference rules and the time-time connectionto tackle the timegraphs?
sparseness problem.In future work, we hope to improve the classi-fication performance by making use of probabilityvalues of prediction results obtained from the firststage of the stacked learning and applying the fullset of inference relations to the system.AcknowledgementThe authors would like to thank the anonymous re-viewers for their insightful comments and sugges-tions, which were helpful in improving the qualityof the paper.ReferencesDanushka Bollegala, Naoaki Okazaki, and MitsuruIshizuka.
2010.
A bottom-up approach to sentenceordering for multi-document summarization.
In In-formation Processing & Management, Volume 46,Issue 1, January 2010, pages 89?109.Johan Bos and Katja Markert.
2005.
Recognis-ing textual entailment with logical inference.
InHLT/EMNLP 2005, pages 628?635.Nathanael Chambers, Shan Wang and Dan Juraf-sky.
2007.
Classifying temporal relations betweenevents.
In ACL 2007, pages 173?176.Nathanael Chambers and Dan Jurafsky.
2008.
Jointlycombining implicit constraints improves temporalordering.
In EMNLP 2008, pages 698?706.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Cambridge, MA: MIT Press.Natsuda Laokulrat, Makoto Miwa, Yoshimasa Tsu-ruoka and Takashi Chikayama.
2013.
UTTime:Temporal relation classification using deep syntac-tic features.
In SemEval 2013, pages 89?92.Inderjeet Mani, Marc Verhagen, Ben Wellner, ChongMin Lee and James Pustejovsky.
2006.
MachineLearning of Temporal Relations.
In ACL 2006,pages 753?760.Stephanie A. Miller and Lenhart K. Schubert.
1999.Time revisited.
In Computational Intelligence 6,pages 108?118.Yusuke Miyao and Jun?ichi Tsujii.
2008.
Feature for-est models for probabilistic HPSG parsing.
In Com-putational Linguistics.
34(1).
pages 35?80, MITPress.James Pustejovsky, Patrick Hanks, Roser Saur?
?, An-dew See, Rob Gaizauskas, Andrea Setzer, DragomirRadev, Beth Sundheim, David Day, Lisa Ferro andMarcia Lazo.
2003.
The TIMEBANK Corpus.In Proceedings of Corpus Linguistics 2003 (March2003), pages 545?557.James Pustejovsky, Robert Ingria, Roser Saur?
?, Jos?eCasta?no, Jessica Littman, Rob Gaizauskas, AndreaSetzer, Graham Katz and Inderjeet Mani.
2005.
Thespecification language TimeML.
In The Languageof Time: A reader, pages 545?557.Deepak Ravichandran and Eduard Hovy.
2002.
Learn-ing surface text patterns for a question answeringsystem.
In ACL 2002, pages 41?47.Stanford Natural Language Processing Group.
2012.Stanford CoreNLP.Marta Tatu and Munirathnam Srikanth.
2008.
Experi-ments with reasoning for temporal relations betweenevents.
In COLING 2008, pages 857?864.Naushad UzZaman and James F. Allen.
2011.
Tempo-ral evaluation.
In ACL 2011, pages 351?356.Naushad UzZaman, Hector Llorens, Leon Derczyn-ski, Marc Verhagen, James Allen and James Puste-jovsky.
2013.
SemEval-2013 Task 1: TempEval-3:Evaluating time expressions, events, and temporalrelations.
In SemEval 2013, pages 2?9.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Graham Katz and James Pustejovsky.2007.
SemEval-2007 task 15: TempEval temporalrelation identification.
In SemEval 2007, pages 75?80.David H. Wolpert.
1992.
Stacked generalization.
InNeural Networks, volume 5, pages 241?259.Katsumasa Yoshikawa, Sebastian Riedel ,MasayukiAsahara and Yuji Matsumoto.
2009.
Jointly iden-tifying temporal relations with Markov Logic.
InACL 2009, pages 405?413.14
