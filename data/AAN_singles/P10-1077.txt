Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 749?759,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsFine-grained Genre Classification using Structural Learning AlgorithmsZhili WuCentre for Translation StudiesUniversity of Leeds, UKz.wu@leeds.ac.ukKatja MarkertSchool of ComputingUniversity of Leeds, UKscskm@leeds.ac.ukSerge SharoffCentre for Translation StudiesUniversity of Leeds, UKs.sharoff@leeds.ac.ukAbstractPrior use of machine learning in genreclassification used a list of labels as clas-sification categories.
However, genreclasses are often organised into hierar-chies, e.g., covering the subgenres of fic-tion.
In this paper we present a methodof using the hierarchy of labels to improvethe classification accuracy.
As a testbedfor this approach we use the Brown Cor-pus as well as a range of other corpora, in-cluding the BNC, HGC and Syracuse.
Theresults are not encouraging: apart from theBrown corpus, the improvements of ourstructural classifier over the flat one arenot statistically significant.
We discuss therelation between structural learning per-formance and the visual and distributionalbalance of the label hierarchy, suggestingthat only balanced hierarchies might profitfrom structural learning.1 IntroductionAutomatic genre identification (AGI) can betraced to the mid-1990s (Karlgren and Cutting,1994; Kessler et al, 1997), but this research be-came much more active in recent years, partly be-cause of the explosive growth of the Web, andpartly because of the importance of making genredistinctions in NLP applications.
In InformationRetrieval, given the large number of web pages onany given topic, it is often difficult for the usersto find relevant pages that are in the right genre(Vidulin et al, 2007).
As for other applications,the accuracy of many tasks, such as machine trans-lation, POS tagging (Giesbrecht and Evert, 2009)or identification of discourse relations (Webber,2009) relies of defining the language model suit-able for the genre of a given text.
For example,the accuracy of POS tagging reaching 96.9% onnewspaper texts drops down to 85.7% on forums(Giesbrecht and Evert, 2009), i.e., every seventhword in forums is tagged incorrectly.This interest in genres resulted in a prolifer-ation of studies on corpus development of webgenres and comparison of methods for AGI.
Thetwo corpora commonly used for this task are KI-04 (Meyer zu Eissen and Stein, 2004) and San-tinis (Santini, 2007).
The best results reported forthese corpora (with 10-fold cross-validation) reach84.1% on KI-04 and 96.5% accuracy on Santinis(Kanaris and Stamatatos, 2009).
In our research(Sharoff et al, 2010) we produced even better re-sults on these two benchmarks (85.8% and 97.1%,respectively).
However, this impressive accuracyis not realistic in vivo, i.e., in classifying webpages retrieved as a result of actual queries.
Onereason comes from the limited number of genrespresent in these two collections (eight genres inKI-04 and seven in Santinis).
As an example, onlyfront pages of online newspapers are listed in San-tinis, but not actual newspaper articles, so once anarticle is retrieved, it cannot be assigned to anyclass at all.
Another reason why the high accu-racy is not useful concerns the limited number ofsources in each collection, e.g., all FAQs in Santi-nis come from either a website with FAQs on hur-ricanes or another one with tax advice.
In the end,a classifier built for FAQs on this training data re-lies on a high topic-genre correlation in this par-ticular collection and fails to spot any other FAQs.There are other corpora, which are more diversein the range of their genres, such as the fifteengenres of the Brown Corpus (Kuc?era and Fran-cis, 1967) or the seventy genres of the BNC (Lee,2001), but because of the number of genres inthem and the diversity of documents within eachgenre, the accuracy of prior work on these collec-tions is much less impressive.
For example, Karl-gren and Cutting (1994) using linear discriminantanalysis achieve an accuracy of 52% without us-749ing cross-validation (the entire Brown Corpus wasused as both the test set and training set), with theaccuracy improving to 65% when the 15 genresare collapsed into 10, and to 73% with only 4 gen-res (Figure 1).
This result suggests the importanceof the hierarchy of genres.
Firstly, making a deci-sion on higher levels might be easier than on lowerlevels (fiction or non-fiction rather than sciencefiction or mystery).
Secondly, we might be ableto improve the accuracy on lower levels, by takinginto account the relevant position of each node inthe hierarchy (distinguishing between reportageor editorial becomes easier when we know theyare safely under the category of press).Figure 1: Hierarchy of Brown corpus.This paper explores a way of using information onthe hierarchy of labels for improving fine-grainedgenre classification.
To the best of our knowl-edge, this is the first work presenting structuralgenre classification and distance measures for gen-res.
In Section 2 we present a structural reformula-tion of Support Vector Machines (SVMs) that cantake similarities between different genres into ac-count.
This formulation necessitates the develop-ment of distance measures between different gen-res in a hierarchy, of which we present three dif-ferent types in Section 3, along with possible esti-mation procedures for these distances.
We presentexperiments with these novel structural SVMs anddistance measures on three different corpora inSection 4.
Our experiments show that structuralSVMs can outperform the non-structural standard.However, the improvement is only statistically sig-nificant on the Brown corpus.
In Section 5 weinvestigate potential reasons for this, includingthe (im)balance of different genre hierarchies andproblems with our distance measures.2 Structural SVMsDiscriminative methods are often used for clas-sification, with SVMs being a well-performingmethod in many tasks (Boser et al, 1992;Joachims, 1999).
Linear SVMs on a flat list oflabels achieve high efficiency and accuracy in textclassification when compared to nonlinear SVMsor other state-of-the-art methods.
As for structuraloutput learning, a few SVM-based objective func-tions have been proposed, including margin for-mulation for hierarchical learning (Dekel et al,2004) or general structural learning (Joachimset al, 2009; Tsochantaridis et al, 2005).
But manyimplementations are not publicly available, andtheir scalability to real-life text classification tasksis unknown.
Also they have not been applied togenre classification.Our formulation can be taken as a special in-stance of the structural learning framework in(Tsochantaridis et al, 2005).
However, they con-centrate on more complicated label structures asfor sequence alignment or parsing.
They proposedtwo formulations, slack-rescaling and margin-rescaling, claiming that margin-rescaling has twodisadvantages.
First, it potentially gives signifi-cant weight to output values that might not be eas-ily confused with the target values, because everyincrease in the loss increases the required margin.However, they did not provide empirical evidencefor this claim.
Second, margin rescaling is notnecessarily invariant to the scaling of the distancematrix.
We still used margin-rescaling because itallows us to use the sequential dual method forlarge-scale implementation (Keerthi et al, 2008),which is not applicable to the slack-rescaling for-mulation.
For web page classification we willneed fast processing.
In addition, we performedmodel calibration to address the second disadvan-tage (distance matrix invariance).Let x be a document and wm a weight vectorassociated with the genre class m in a corpus withk genres at the most fine-grained level.
The pre-dicted class is the class achieving the maximuminner product between x and the weight vector forthe class, denoted as,argmaxmwTmx,?m.
(1)750Accurate prediction requires that when a docu-ment vector is multiplied with the weight vectorassociated with its own class, the resulting innerproduct should be larger than its inner productswith a weight vector for any other genre class m.This helps us to define criteria for weight vectors.Let xi be the i?th training document, and yi itsgenre label.
For its weight vector wyi , the innerproductwTyixi should be larger than all other prod-ucts wTmxi, that is,wTyixi ?wTmxi ?
0,?m.
(2)To strengthen the constraints, the zero value on theright hand side of the inequality for the flat SVMcan be replaced by a positive value, correspondingto a distance measure h(yi,m) between two genreclasses, leading to the following constraint:wTyixi ?wTmxi ?
h(yi,m),?m.
(3)To allow feasible models, in real scenarios suchconstraints can be violated, but the degree of vio-lation is expected to be small.
For each document,the maximum violation in the k constraints is ofinterest, as given by the following loss term:Lossi = maxm{h(yi,m)?wTyixi +wTmxi}.
(4)Adding up all loss terms over all training docu-ments, and further introducing a term to penalizelarge values in the weight vectors, we have thefollowing objective function (C is a user-specifiednonnegative parameter).minm,i:12k?m=1wTmwm + Cp?i=1Lossi.
(5)Efficient methods can be derived by borrowing thesequential dual methods in (Keerthi et al, 2008)or other optimization techniques (Crammer andSinger, 2002).3 Genre Distance MeasuresThe structural SVM (Section 2) requires a dis-tance measure h between two genres.
We canderive such distance measures from the genrehierarchy in a way similar to word similaritymeasures that were invented for lexical hierar-chies such as WordNet (see (Pedersen et al,2007) for an overview).
In the following,we will first shortly summarise path-based andinformation-based measures for similarity.
How-ever, information-based measures are based onthe information content of a node in a hierarchy.Whereas the information content of a word or con-cept in a lexical hierarchy has been well-defined(Resnik, 1995), it is less clear how to estimatethe information content of a genre label.
We willtherefore discuss several different ways of estimat-ing information content of nodes in a genre hierar-chy.3.1 Distance Measures based on Path LengthIf genre labels are organised into a tree (Figure 1),one of the simplest ways to measure distance be-tween two genre labels (= tree nodes) is pathlength (h(a, b)plen):f(a, LCS(a, b)) + f(b, LCS(a, b)), (6)where a and b are two nodes in the tree,LCS(a, b) is their Least Common Subsumer, andf(a, LCS(a, b)) is the number of levels passedthrough when traversing from a to the ancestralnode LCS(a, b).
In other words, the distancecounts the number of edges traversed from nodes ato b in the tree.
For example, the distance betweenLearned and Misc in Figure 1 would be 3.As an alternative, the maximum path lengthh(a, b)pmax to their least common subsumer canbe used to reduce the range of possible values:max{f(a, LCS(a, b)), f(b, LCS(a, b))}.
(7)The Leacock & Chodorow similarity measure(Leacock and Chodorow, 1998) normalizes thepath length measure (6) by the maximum numberof nodes D when traversing down from the root.s(a, b)plsk = ?log((h(a, b)plen + 1)/2D).
(8)To convert it into a distance measure, we caninvert it h(a, b)plsk = 1/s(a, b)plsk.Other path-length based measures include theWu & Palmer Similarity (Wu and Palmer, 1994).s(a, b)pwupal =2f(R,LCS(a, b))(f(R, a) + f(R, b)), (9)where R describes the hierarchy?s root node.
Heresimilarity is proportional to the shared path fromthe root to the least common subsumer of twonodes.
Since the Wu & Palmer similarity is alwaysbetween [0 1), we can convert it into a distancemeasure by h(a, b)pwupal = 1?
s(a, b)pwupal.7513.2 Distance Measures based on InformationContentPath-based distance measures work relatively wellon balanced hierarchies such as the one in Figure 1but fail to treat hierarchies with different levelsof granularity well.
For lexical hierarchies, as aresult, several distance measures based on infor-mation content have been suggested where the in-formation content of a concept c in a hierarchy ismeasured by (Resnik, 1995)IC(c) = ?log(freq(c)freq(root)).
(10)The frequency freq of a concept c is the sum ofthe frequency of the node c itself and the frequen-cies of all its subnodes.
Since the root may be adummy concept, its frequency is simply the sumof the frequencies of all its subnodes.
The simi-larity between two nodes can then be defined asthe information content of their least common sub-sumer:s(a, b)resk = IC(LCS(a, b)).
(11)If two nodes just share the root as their subsumer,their similarity will be zero.
To convert 11 into adistance measure, it is possible to add a constant 1to it before inverting it, as given byh(a, b)resk = 1/(s(a, b)resk + 1).
(12)Several other similarity measures have been pro-posed based on the Resnik similarity such as theone by (Lin, 1998):s(a, b)lin =2IC(LCS(a, b))IC(a) + IC(b).
(13)Again to avoid the effect of zero similarity whendefining the Lin?s distance we use:h(a, b)lin = 1/(s(a, b)lin + 1).
(14)(Jiang and Conrath, 1997) directly define Jiang?sdistance (h(a, b)jng):IC(a) + IC(b)?
2IC(LCS(a, b)).
(15)3.2.1 Information Content of Genre LabelsThe notion of information content of a genre is notstraightforward.
We use two ways of measuringthe frequency freq of a genre, depending on itsinterpretation.Genre Frequency based on Document Occur-rence.
We can interpret the ?frequency?
of agenre node simply as the number of all documentsbelonging to that genre (including any of its sub-genres).
Unfortunately, there are no estimates forgenre frequencies on, for example, a representa-tive sample of web documents.
Therefore, we ap-proximate genre frequencies from the documentfrequencies (dfs) in the training sets used in clas-sification.
Note that (i) for balanced class distribu-tions this information will not be helpful and (ii)that this is a relatively poor substitute for an esti-mation on an independent, representative corpus.Genre Frequency based on Genre Labels.
Wecan also use the labels/names of the genre nodesas the unit of frequency estimation.
Then, thefrequency of a genre node is the occurrence fre-quency of its label in a corpus plus the occurrencefrequencies of the labels of all its subnodes.
Notethat there is no direct correspondence between thismeasure and the document frequency of a genre:measuring the number of times the potential genrelabel poem occurs in a corpus is not in any wayequivalent to the number of poems in that corpus.However, the measure is still structurally awareas frequencies of labels of subnodes are included,i.e.
a higher level genre label will have higherfrequency (and lower information content) than alower level genre label.1For label frequency estimation, we manuallyexpand any label abbreviations (such as "newsp"for BNC genre labels), delete stop words and func-tion words and then use two search methods.
Forthe search method word we simply search the fre-quency of the genre label in a corpus, using threedifferent corpora (the BNC, Brown and Googleweb search).
As for the BNC and Brown cor-pus some labels are very rarely mentioned, we forthese two corpora use also a search method gramwhere all character 5-grams within the genre labelare searched for and their frequencies aggregated.3.3 TerminologyAlgorithms are prefixed by the kind of distancemeasure they employ ?
IC for Information con-tent and p for path-based).
If the measure is infor-1Obviously when using this measure we rely on genre la-bels which are meaningful in the sense that lower level labelswere chosen to be more specific and therefore probably rarerterms in a corpus.
The measure could not possibly be use-ful on a genre hierarchy that would give random names to itsgenres such as genre 1.752mation content based the specific measure is men-tioned next, such as lin.
The way for measuringgenre frequency is indicated last with df for mea-suring via document frequency and word/gramwhen measured via frequency of genre labels.
Iffrequencies of genre labels are used, the corpusfor counting the occurrence of genre labels is alsoindicated via brown, bnc or the Web as estimatedby Google hit counts gg.
Standard non-structuralSVMs are indicated by flat.4 Experiments4.1 DatasetsWe use four genre-annotated corpora for genreclassification: the Brown Corpus (Kuc?era andFrancis, 1967), BNC (Lee, 2001), HGC (Stubbeand Ringlstetter, 2007) and Syracuse (Crowstonet al, 2009).
They have a wide variety of genrelabels (from 15 in the Brown corpus to 32 genresin HGC to 70 in the BNC to 292 in Syracuse), anddifferent types of hierarchies.4.2 Evaluation MeasuresWe use standard classification accuracy (Acc) onthe most fine-grained level of target categories inthe genre hierarchy.In addition, given a structural distance H , mis-classifications can be weighted based on the dis-tance measure.
This allows us to penalize incor-rect predictions which are further away in the hi-erarchy (such as between government documentsand westerns) more than "close" mismatches (suchas between science fiction and westerns).
For-mally, given the classification confusion matrix Mthen each Mab for a 6= b contains the numberof class a documents that are misclassified intoclass b.
To achieve proper normalization in giv-ing weights to misclassified entries, we can redis-tribute a total weight k ?
1 to each row of H pro-portionally to its values, where k is the numberof genres.
That is, given g the row summationof H , we define a weight matrix Q by normal-izing the rows of H in a way given by Qab =(k ?
1)hab/ga, a 6= b.
We further assign a unitvalue to the diagonal of Q.
Then it is possible toconstruct a structurally-aware measure (S-Acc):S-Acc =?aMaa/?a,bMabQab.
(16)4.3 Experimental SetupWe compare structural SVMs using all path-basedand information-content based measures (see alsoSection 3.3).
As a baseline we use the accuracyachieved by a standard "flat" SVM.We use 10-fold (randomised) cross validationthroughout.
In each fold, for each genre class 10%of documents are used for testing.
For the re-maining 90%, a portion of 10% are sampled forparameter tuning, leaving 80% for training.
Ineach round the validation set is used to help de-termine the best C associated with Equation (5)based on the validation accuracy from the candi-date list 0.0001, 0.0005, 0.001, 0.005, 0.01,0.05, 0.1, 0.5, 1.
Note via this experiment setup,all methods are tuned to their best performance.For any algorithm comparison, we use a McNe-mar test with the significance level of 5% as rec-ommended by (Dietterich, 1998).4.4 FeaturesThe features used for genre classification are char-acter 4-grams for all algorithms, i.e.
each docu-ment is represented by a binary vector indicatingthe existence of each character 4-gram.
We usedcharacter n-grams because they are very easy toextract, language-independent (no need to rely onparsing or even stemming), and they are knownto have the best performance in genre classifica-tion tasks (Kanaris and Stamatatos, 2009; Sharoffet al, 2010).4.5 Brown Corpus ResultsThe Brown Corpus has 500 documents and is or-ganized in a hierarchy with a depth of 3.
Itcontains 15 end-level genres.
In one experimentin (Karlgren and Cutting, 1994) the subgenres un-der fiction are grouped together, leading to 10 gen-res to classify.Results on 10-genre Brown Corpus.
A stan-dard flat SVM achieves an accuracy of 64.4%whereas the best structural SVM based on Lin?sinformation content distance measure (IC-lin-word-bnc) achieves 68.8% accuracy, significantlybetter at the 1% level.
The result is also signif-icantly better than prior work on the Brown cor-pus in (Karlgren and Cutting, 1994) (who use thewhole corpus as test as well as training data).
Ta-ble 1 summarizes the best performing measuresthat all outperform the flat SVM at the 1% level.753Table 1: Brown 10-genre Classification Results.Method AccuracyKarlgren and Cutting, 1994 65 (Training)Flat SVM 64.40SSVM(IC-lin-word-bnc) 68.80SSVM(IC-lin-word-br) 68.60SSVM(IC-lin-gram-br) 67.80Figure 2 provides the box plots of accuracy scores.The dashed boxes indicate that the distance mea-sures perform significantly worse than the bestperforming IC-lin-word-bnc at the bottom.
Thesolid boxes indicate the corresponding measuresare statistically comparable to the IC-lin-word-bncin terms of the mean accuracy they can achieve.50 55 60 65 70 75 80IC?lin?word?bncIC?lin?word?brIC?jng?dfpwupalIC?lin?gram?brIC?resk?word?bncIC?resk?word?ggplenIC?resk?dfIC?lin?gram?bncIC?resk?gram?brIC?lin?dfIC?resk?gram?bncIC?resk?word?brIC?lin?word?ggplskpmaxIC?jng?word?brIC?jng?word?bncflatIC?jng?gram?bncIC?jng?gram?brIC?jng?word?ggAccuracyFigure 2: Accuracy on Brown Corpus (10 genres).Results on 15-genre Brown Corpus.
We per-form experiments on all 15 genres on the end levelof the Brown corpus.
The increase of genre classesleads to reduced classification performance.
In ourexperiment, the flat SVM achieves an accuracy of52.40%, and the structural SVM using path lengthmeasure achieves 55.40%, a difference significantat the 5% level.
The structural SVMs using infor-mation content measures IC-lin-gram-bnc and IC-resk-word-br also perform equally well.
In addi-tion, we improve on the training accuracy of 52%reported in (Karlgren and Cutting, 1994).We are also interested in structural accuracy (S-Acc) to see whether the structural SVMs makefewer "big" mistakes.
Table 2 shows a cross com-parison of structural accuracy.
Each row showshow accurate the corresponding method is un-der the structural accuracy criteria given in thecolumn.
The ?no-struct?
column corresponds tovanilla accuracy.
It is natural to expect each di-agonal entry of the numeric table to be the high-est, since the respective method is optimised forits own structural distance.
However, in our case,Lin?s information content measure and the plenmeasure perform well under any structural ac-curacy evaluation measure and outperform flatSVMs.4.6 Other CorporaIn spite of the promising results on the BrownCorpus, structural SVMs on other corpora (BNC,HGC, Syracuse) did not show considerable im-provement.HGC contains 1330 documents divided into 32approximately equally frequent classes.
Its hierar-chy has just two levels.
Standard accuracy for thebest performing structural methods on HGC is justthe same as for flat SVM (69.1%), with marginallybetter structural accuracy (for example, 71.39 vs.71.04%, using a path-length based structural ac-curacy).
The BNC corpus contains 70 genres and4053 documents.
The number of documents perclass ranges from 2 to 501.
The accuracy of SSVMis also just comparable to flat SVM (73.6%).
TheSyracuse corpus is a recently developed large col-lection of 3027 annotated webpages divided into292 genres (Crowston et al, 2009).
Focusing onlyon genres containing 15 or more examples, we ar-rived at a corpus of 2293 samples and 52 genres.Accuracy for flat (53.3%) and structural SVMs(53.7%) are again comparable.5 DiscussionGiven that structural learning can help in topicalclassification tasks (Tsochantaridis et al, 2005;Dekel et al, 2004), the lack of success on genresis surprising.
We now discuss potential reasons forthis lack of success.5.1 Tree Depth and BalanceOur best results were achieved on the Brown cor-pus, whose genre tree has at least three attractiveproperties.
Firstly, it has a depth greater than 2,i.e.
several levels are distinguished.
Secondly,it seems visually balanced: branches from rootto leaves (or terminals) are of pretty much equallength; branching factors are similar, for exam-ple ranging between 2 and 6 for the last level ofbranching.
Thirdly, the number of examples at754Table 2: Structural Accuracy on Brown 15-genre Classification.Method no-struct (=typical accuracy) IC-lin-gram-bnc plen IC-resk-word-br IC-jng-word-ggflat 52.40 55.34 60.60 58.91 52.19IC-lin-gram-bnc 55.00 58.15 63.59 61.83 53.85plen 55.40 58.74 64.51 62.61 54.27IC-resk-word-br 55.00 58.24 63.96 62.08 54.08IC-jng-word-gg 46.00 49.00 54.89 53.01 52.58each leaf node is roughly comparable (distribu-tional balance).The other hierarchies violate these properties toa large extent.
Thus, the genres in HGC are al-most represented by a flat list with just one extralevel over 32 categories.
Similarly, the vast ma-jority of genres in the Syracuse corpus are alsoorganised in two levels only.
Such flat hierar-chies do not offer much scope to improve over acompletely flat list.
There are considerably morelevels in the BNC for some branches, e.g., writ-ten/national/broadsheet/arts, but many other gen-res are still only specified to the second level ofits hierarchy, e.g., written/adverts.
In addition, theBNC is also distributionally imbalanced, i.e.
thenumber of documents per class varies from 2 to501 documents.To test our hypothesis, we tried to skew theBrown genre tree in two ways.
First, we kept thetree relatively balanced visually and distribution-ally but flattened it by removing the second layerPress, Misc, Non-Fiction, Fiction from the hierar-chy, leaving a tree with only two layers.
Second,we skewed the visual and distributional balance ofthe tree by collapsing its three leaf-level genres un-der Press, and the two under non-fiction, leading to12 genres to classify (cf.
Figure 1).30 35 40 45 50 55 60 65 70IC?resk?word?bncIC?resk?gram?bncIC?resk?word?brIC?lin?gram?bncplenpwupalIC?lin?word?brIC?resk?word?ggIC?lin?dfIC?lin?word?bncIC?lin?gram?brIC?jng?dfflatIC?resk?dfplskIC?resk?gram?brpmaxIC?lin?word?ggIC?jng?gram?bncIC?jng?gram?brIC?jng?word?brIC?jng?word?bncIC?jng?word?ggAccuracyFigure 3: Accuracy on flattened Brown Corpus (15genres).35 40 45 50 55 60 65 70 75IC?resk?word?brIC?resk?gram?bncpmaxIC?resk?gram?brIC?resk?dfIC?lin?word?bncpwupalplenIC?resk?word?bncplskIC?lin?gram?brflatIC?lin?word?brIC?lin?dfIC?lin?gram?bncIC?jng?gram?brIC?jng?dfIC?resk?word?ggIC?lin?word?ggIC?jng?gram?bncIC?jng?word?brIC?jng?word?bncIC?jng?word?ggAccuracyFigure 4: Accuracy on skewed Brown Corpus (12genres).As expected, the structural methods on eitherskewed or flattened hierarchies are not signifi-cantly better than the flat SVM.
For the flattenedhierarchy of 15 leaf genres the maximal accuracyis 54.2% vs. 52.4% for the flat SVM (Figure 3), anon-significant improvement.
Similarly, the max-imal accuracy on the skewed 12-genre hierarchyis 58.2% vs. 56% (see also Figure 4), again a notsignificant improvement.To measure the degree of balance of a tree,we introduce two tree balance scores based onentropy.
First, for both measures we extend allbranches to the maximum depth of the tree.
Thenlevel by level we calculate an entropy score, ei-ther according to how many tree nodes at the nextlevel belong to a node at this level (denoted asvb: visual balance), or according to how manyend level documents belong to a node at this level(denoted as db: distribution balance).
To maketrees with different numbers of internal nodesand leaves more comparable, the entropy scoreat each level is normalized by the maximal en-tropy achieved by a tree with uniform distributionof nodes/documents, which is simply?log(1/N),where N denotes the number of nodes at the corre-755sponding level.
Finally, the entropy scores for alllevels are averaged.
It can be shown that any per-fect N-ary tree will have the largest visual balancescore of 1.
If in addition its nodes at each levelcontain the same number of documents, the distri-bution balance score will reach the maximum, too.Table 3 shows the balance scores for all the cor-pora we use.
The first two rows for the Brown cor-pus have both large visual balance and distributionbalance scores.
As shown earlier, for those two se-tups the structural SVMs perform better than theflat approach.
In contrast, for the tree hierarchiesof Brown that we deformed or flattened, and alsoBNC and Syracuse, either or both of the two bal-ance scores tend to be lower, and no improvementhas been obtained over the flat approach.
Thismay indicate that a further exploration of the rela-tion between tree balance and the performance ofstructural SVMs is warranted.
However, high vi-sual balance and distribution scores do not neces-sarily imply high performance of structural SVMs,as very flat trees are also visually very balanced.As an example, HGC has a high visual balancescore due to a shallow hierarchy and a high distri-butional balance score due to a roughly equal num-ber of documents contained in each genre.
How-ever, HGC did not benefit from structural learningas it is also a very shallow hierarchy; therefore wethink that a third variable depth also needs to betaken into account.A similar observation on the importance ofwell-balanced hierarchies comes from a recentPascal challenge on large scale hierarchical textclassification,2 which shows that some flat ap-proaches perform competitively in topic classifi-cation with imbalanced hierarchies.
However, theparticipants do not explore explicitly the relationbetween tree balance and performance.Other methods for measuring tree balance(some of which are related to ours) are used inthe field of phylogenetic research (Shao and Sokal,1990) but they are only applicable to visual bal-ance.
In addition, the methods they used oftenprovide conflicting results on which trees are con-sidered as balanced (Shao and Sokal, 1990).5.2 Distance MeasuresWe also scrutinise our distance measures as theseare crucial for the structural approach.
We no-tice that simple path length based measures per-2http://lshtc.iit.demokritos.gr/Table 3: Tree Balance ScoresCorpus depth vb dbBrown (10 genres) 3 0.9115 0.9024Brown (15 genres) 3 0.9186 0.9083Brown (15, flattened) 2 0.9855 0.8742Brown (12, skewed) 3 0.8747 0.8947HGC (32) 2 0.9562 0.9570BNC (70) 4 0.9536 0.8039Syracuse (52) 3 0.9404 0.8634form well overall; again for the Brown corpusthis is probably due to its balanced hierarchywhich makes path length appropriate.
There areother probable reasons why information contentbased measures do not perform better than path-length based ones.
When measured via docu-ment frequency in a corpus we do not have suffi-ciently large, representative genre-annotated cor-pora to hand.
When measured via genre labelfrequency, we run into at least two problems.Firstly, as mentioned in Section 3.2.1 genre la-bel frequency does not have to correspond to classfrequency of documents.
Secondly, the labelsused are often abbreviations (e.g.
W_institut_doc,W_newsp_brdsht_nat_social in BNC Corpus),underspecified (other, misc, unclassified) or a col-lection of phrases (e.g.
belles letters, etc.
inBrown).
This made search for frequency very ap-proximate and also loosens the link between labeland content.We investigated in more depth how well the dif-ferent distance measures are aligned.
We adaptthe alignment measure between kernels (Cristian-ini et al, 2002), to investigate how close the dis-tance matrices are.
For two distance matrices H1and H2, their alignment A(H1, H2) is defined as:< H1, H2 >F?< H1, H1 >F , < H2, H2 >F, (17)where < H1, H2 >F=?ki,j H1(gi, gj)H2(gi, gj)which is the total sum of the entry-wise productsbetween the two distance matrices.
Figure 5 showsseveral distance matrices on the (original) 15 genreBrown corpus.
The plen matrix has clear blocksfor the super genres press, informative, imagina-tive, etc.
The IC-lin-gram-bnc matrix refines dis-tances in the blocks, due to the introduction of in-formation content.
It keeps an alignment score thatis over 0.99 (the maximum is 1.00) toward the plenmatrix, and still has visible block patterns.
How-ever, the IC-jng-word-bnc significantly adjusts the756distance entries, has a much lower alignment scorewith the plen matrix, and doesn?t reveal appar-ent blocks.
This partially explains the bad perfor-mance of the Jiang distance measure on the Browncorpus (see Section 4).
The diagrams also showthe high closeness between the best performing ICmeasure and the simple path length based mea-sure.plenInformative ImaginativePressMiscnonfictionIC?lin?gram?bnc (0.98376)Informative ImaginativePressMiscnonfictionplsk (0.96061)Informative ImaginativePressMiscnonfictionIC?jng?word?bnc (0.92993)Informative ImaginativePressMiscnonfictionFigure 5: Distance Matrices on Brown.
Values inbracket is the alignment with the plen matrixAn alternative to structural distance measureswould be distance measures between the gen-res based on pairwise cosine similarities betweenthem.
To assess this, we aggregated all character4-gram training vectors of each genre and calcu-lated standard cosine similarities.
Note that thesesimilarities are based on the documents only anddo not make use of the Brown hierarchy at all.
Af-ter converting the similarities to distance, we plugthe distance matrix into our structural SVM.
How-ever, accuracy on the Brown corpus (15 genres)was almost the same as for a flat SVM.
Inspectingthe distance matrix visually, we determined thatthe cosine similarity could clearly distinguish be-tween Fiction and Non-Fiction texts but not be-tween any other genres.
This also indicates thatthe genre structural hierarchy clearly gives infor-mation not present in the simple character 4-gramfeatures we use.
For a more detailed discussionof the problems of the currently prevalently usedcharacter n-grams as features for genre classifica-tion, we refer the reader to (Sharoff et al, 2010).6 ConclusionsIn this paper, we have evaluated structural learn-ing approaches to genre classification using sev-eral different genre distance measures.
Althoughwe were able to improve on non-structural ap-proaches for the Brown corpus, we found it hard toimprove over flat SVMs on other corpora.
As po-tential reasons for this negative result, we suggestthat current genre hierarchies are either not of suf-ficient depth or are visually or distributionally im-balanced.
We think further investigation into therelationship between hierarchy balance and struc-tural learning is warranted.
Further investigationis also needed into the appropriateness of n-gramfeatures for genre identification as well as goodmeasures of genre distance.In the future, an important task would be the re-finement or unsupervised generation of new hier-archies, using information theoretic or data-drivenapproaches.
For a full assessment of hierarchicallearning for genre classification, the field of genrestudies needs a testbed similar to the Reuters or 20Newsgroups datasets used in topic-based IR with abalanced genre hierarchy and a representative cor-pus of reliably annotated webpages.With regard to algorithms, we are also inter-ested in other formulations for structural SVMsand their large-scale implementation as well as thecombination of different distance measures, forexample in ensemble learning.AcknowledgementsWe would like to thank the authors of each corpuscollection, who invested a lot of effort into produc-ing them.
We are also grateful to Google Inc. forsupporting this research via their Google ResearchAwards programme.ReferencesBoser, B. E., Guyon, I. M., and Vapnik, V. N.(1992).
A training algorithm for optimal mar-gin classifiers.
In COLT ?92: Proceedings ofthe fifth annual workshop on Computationallearning theory, pages 144?152, New York,NY, USA.
ACM.Crammer, K. and Singer, Y.
(2002).
On the algo-rithmic implementation of multiclass kernel-based vector machines.
J. Mach.
Learn.
Res.,2:265?292.Cristianini, N., Shawe-Taylor, J., and Kandola, J.(2002).
On kernel target algnment.
In Pro-ceedings of the Neural Information Process-757ing Systems, NIPS?01, pages 367?373.
MITPress.Crowston, K., Kwasnik, B., and Rubleske, J.(2009).
Problems in the use-centered de-velopment of a taxonomy of web genres.In Mehler, A., Sharoff, S., and Santini,M., editors, Genres on the Web: Com-putational Models and Empirical Studies.Springer, Berlin/New York.Dekel, O., Keshet, J., and Singer, Y.
(2004).Large margin hierarchical classification.
InICML ?04: Proceedings of the twenty-first in-ternational conference on Machine learning,page 27, New York, NY, USA.
ACM.Dietterich, T. G. (1998).
Approximate statisticaltests for comparing supervised classificationlearning algorithms.
Neural Computation,10:1895?1923.Giesbrecht, E. and Evert, S. (2009).
Part-of-Speech (POS) Tagging - a solved task?
Anevaluation of POS taggers for the Web ascorpus.
In Proceedings of the Fifth Webas Corpus Workshop (WAC5), pages 27?35,Donostia-San Sebasti?n.Jiang, J. J. and Conrath, D. W. (1997).
Semanticsimilarity based on corpus statistics and lexi-cal taxonomy.
CoRR, cmp-lg/9709008.Joachims, T. (1999).
Making large-scale SVMlearning practical.
In Sch?lkopf, B., Burges,C., and Smola, A., editors, Advances inKernel Methods ?
Support Vector Learning,pages 41?56.
MIT Press.Joachims, T., Finley, T., and Yu, C.-N. (2009).Cutting-plane training of structural svms.Machine Learning, 77(1):27?59.Kanaris, I. and Stamatatos, E. (2009).
Learning torecognize webpage genres.
Information Pro-cessing and Management, 45:499?512.Karlgren, J. and Cutting, D. (1994).
Recogniz-ing text genres with simple metrics using dis-criminant analysis.
In Proc.
of the 15th.
Inter-national Conference on Computational Lin-guistics (COLING 94), pages 1071 ?
1075,Kyoto, Japan.Keerthi, S. S., Sundararajan, S., Chang, K.-W.,Hsieh, C.-J., and Lin, C.-J.
(2008).
A se-quential dual method for large scale multi-class linear svms.
In KDD ?08: Proceeding ofthe 14th ACM SIGKDD international confer-ence on Knowledge discovery and data min-ing, pages 408?416, New York, NY, USA.ACM.Kessler, B., Nunberg, G., and Sch?tze, H. (1997).Automatic detection of text genre.
In Pro-ceedings of the 35th ACL/8th EACL, pages32?38.Kuc?era, H. and Francis, W. N. (1967).
Computa-tional analysis of present-day American En-glish.
Brown University Press, Providence.Leacock, C. and Chodorow, M. (1998).
Combin-ing local context and WordNet similarity forword sense identification, pages 305?332.
InC. Fellbaum (Ed.
), MIT Press.Lee, D. (2001).
Genres, registers, text types, do-mains, and styles: clarifying the conceptsand navigating a path through the BNC jun-gle.
Language Learning and Technology,5(3):37?72.Lin, D. (1998).
An information-theoretic defini-tion of similarity.
In ICML ?98: Proceed-ings of the Fifteenth International Confer-ence on Machine Learning, pages 296?304,San Francisco, CA, USA.
Morgan KaufmannPublishers Inc.Meyer zu Eissen, S. and Stein, B.
(2004).
Genreclassification of web pages.
In Proceedingsof the 27th German Conference on ArtificialIntelligence, Ulm, Germany.Pedersen, T., Pakhomov, S. V. S., Patwardhan, S.,and Chute, C. G. (2007).
Measures of seman-tic similarity and relatedness in the biomed-ical domain.
J. of Biomedical Informatics,40(3):288?299.Resnik, P. (1995).
Using information content toevaluate semantic similarity in a taxonomy.In IJCAI?95: Proceedings of the 14th inter-national joint conference on Artificial intel-ligence, pages 448?453, San Francisco, CA,USA.
Morgan Kaufmann Publishers Inc.758Santini, M. (2007).
Automatic Identification ofGenre in Web Pages.
PhD thesis, Universityof Brighton.Shao, K.-T. and Sokal, R. R. (1990).
Tree balance.Systematic Zoology, 39(3):266?276.Sharoff, S., Wu, Z., and Markert, K. (2010).
TheWeb library of Babel: evaluating genre col-lections.
In Proc.
of the Seventh LanguageResources and Evaluation Conference, LREC2010, Malta.Stubbe, A. and Ringlstetter, C. (2007).
Recogniz-ing genres.
In Santini, M. and Sharoff, S.,editors, Proc.
Towards a Reference Corpus ofWeb Genres.Tsochantaridis, I., Joachims, T., Hofmann, T., andAltun, Y.
(2005).
Large margin methodsfor structured and interdependent output vari-ables.
J. Mach.
Learn.
Res., 6:1453?1484.Vidulin, V., Lu?trek, M., and Gams, M. (2007).Using genres to improve search engines.
InProc.
Towards Genre-Enabled Search En-gines: The Impact of NLP.
RANLP-07.Webber, B.
(2009).
Genre distinctions for dis-course in the Penn TreeBank.
In Proc the47th Annual Meeting of the ACL, pages 674?682.Wu, Z. and Palmer, M. (1994).
Verbs seman-tics and lexical selection.
In Proceedings ofthe 32nd annual meeting on Association forComputational Linguistics, pages 133?138,Morristown, NJ, USA.
Association for Com-putational Linguistics.759
