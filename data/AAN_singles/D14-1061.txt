Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 557?565,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsBeyond Parallel Data: Joint Word Alignment and DeciphermentImproves Machine TranslationQing Dou , Ashish Vaswani, and Kevin KnightInformation Sciences InstituteDepartment of Computer ScienceUniversity of Southern California{qdou,avaswani,knight}@isi.eduAbstractInspired by previous work, where decipher-ment is used to improve machine translation,we propose a new idea to combine word align-ment and decipherment into a single learningprocess.
We use EM to estimate the model pa-rameters, not only to maximize the probabil-ity of parallel corpus, but also the monolingualcorpus.
We apply our approach to improveMalagasy-English machine translation, whereonly a small amount of parallel data is avail-able.
In our experiments, we observe gains of0.9 to 2.1 Bleu over a strong baseline.1 IntroductionState-of-the-art machine translation (MT) systems ap-ply statistical techniques to learn translation rules au-tomatically from parallel data.
However, this relianceon parallel data seriously limits the scope of MT ap-plication in the real world, as for many languages anddomains, there is not enough parallel data to train a de-cent quality MT system.However, compared with parallel data, there aremuch larger amounts of non parallel data.
The abil-ity to learn a translation lexicon or even build a ma-chine translation system using monolingual data helpsaddress the problems of insufficient parallel data.
Raviand Knight (2011) are among the first to learn a fullMT system using only non parallel data through deci-pherment.
However, the performance of such systemsis much lower compared with those trained with par-allel data.
In another work, Klementiev et al.
(2012)show that, given a phrase table, it is possible to esti-mate parameters for a phrase-based MT system fromnon parallel data.Given that we often have some parallel data, it ismore practical to improve a translation system trainedon parallel data by using additional non parallel data.Rapp (1995) shows that with a seed lexicon, it is possi-ble to induce new word level translations from non par-allel data.
Motivated by the idea that a translation lexi-con induced from non parallel data can be used to trans-late out of vocabulary words (OOV), a variety of priorresearch has tried to build a translation lexicon fromnon parallel or comparable data (Fung and Yee, 1998;Koehn and Knight, 2002; Haghighi et al., 2008; GareraFigure 1: Combine word alignment and deciphermentinto a single learning process.et al., 2009; Bergsma and Van Durme, 2011; Daum?eand Jagarlamudi, 2011; Irvine and Callison-Burch,2013b; Irvine and Callison-Burch, 2013a; Irvine et al.,2013).Lately, there has been increasing interest in learn-ing translation lexicons from non parallel data with de-cipherment techniques (Ravi and Knight, 2011; Douand Knight, 2012; Nuhn et al., 2012; Dou and Knight,2013).
Decipherment views one language as a cipherfor another and learns a translation lexicon that pro-duces fluent text in the target (plaintext) language.
Pre-vious work has shown that decipherment not only helpsfind translations for OOVs (Dou and Knight, 2012), butalso improves translations of observed words (Dou andKnight, 2013).We find that previous work using monolingual orcomparable data to improve quality of machine transla-tion separates two learning tasks: first, translation rulesare learned from parallel data, and then the informationlearned from parallel data is used to bootstrap learningwith non parallel data.
Inspired by approaches wherejoint inference reduces the problems of error propaga-tion and improves system performance, we combinethe two separate learning processes into a single one,as shown in Figure 1.
The contributions of this workare:557?
We propose a new objective function for wordalignment that combines the process of wordalignment and decipherment into a single learningtask.?
In experiments, we find that the joint process out-performs the previous pipeline approach, and ob-serve Bleu gains of 0.9 and 2.1 on two differenttest sets.?
We release 15.3 million tokens of monolingualMalagasy data from the web, as well as a smallMalagasy dependency tree bank containing 20ktokens.2 Joint Word Alignment andDecipherment2.1 A New Objective FunctionIn previous work that uses monolingual data to im-prove machine translation, a seed translation lexiconlearned from parallel data is used to find new transla-tions through either word vector based approaches ordecipherment.
In return, selection of a seed lexiconneeds to be careful as using a poor quality seed lexi-con could hurt the downstream process.
Evidence froma number of previous work shows that a joint inferenceprocess leads to better performance in both tasks (Jianget al., 2008; Zhang and Clark, 2008).In the presence of parallel and monolingual data, wewould like the alignment and decipherment models tobenefit from each other.
Since the decipherment andword alignment models contain word-to-word transla-tion probabilities t( f | e), having them share these pa-rameters during learning will allow us to pool infor-mation from both data types.
This leads us to de-velop a new objective function that takes both learn-ing processes into account.
Given our parallel data,(E1,F1), .
.
.
, (Em,Fm), .
.
.
, (EM,FM), and monolingualdata F1mono, .
.
.
,Fnmono, .
.
.
,FNmono, we seek to maximizethe likelihood of both.
Our new objective function isdefined as:Fjoint=M?m=1log P(Fm| Em) + ?N?n=1log P(Fnmono) (1)The goal of training is to learn the parameters thatmaximize this objective, that is?
?= arg max?Fjoint(2)In the next two sections, we describe the word align-ment and decipherment models, and present how theyare combined to perform joint optimization.2.2 Word AlignmentGiven a source sentence F = f1, .
.
.
, fj, .
.
.
, fJand atarget sentence E = e1, .
.
.
, ei, .
.
.
, eI, word alignmentmodels describe the generative process employed toproduce the French sentence from the English sentencethrough alignments a = a1, .
.
.
, aj, .
.
.
, aJ.The IBM models 1-2 (Brown et al., 1993) and theHMM word alignment model (Vogel et al., 1996) usetwo sets of parameters, distortion probabilities andtranslation probabilities, to define the joint probabil-ity of a target sentence and alignment given a sourcesentence.P(F, a | E) =J?j=1d(aj| aj?1, j)t( fj| eaj).
(3)These alignment models share the same translationprobabilities t( fj| eaj), but differ in their treatment ofthe distortion probabilities d(aj| aj?1, j).
Brown etal.
(1993) introduce more advanced models for wordalignment, such as Model 3 and Model 4, which usemore parameters to describe the generative process.
Wedo not go into details of those models here and thereader is referred to the paper describing them.Under the Model 1-2 and HMM alignment models,the probability of target sentence given source sentenceis:P(F | E) =?aJ?j=1d(aj| aj?1, j)t( fj| eaj).Let ?
denote all the parameters of the word align-ment model.
Given a corpus of sentence pairs(E1,F1), .
.
.
, (Em,Fm), .
.
.
, (EM,FM), the standard ap-proach for training is to learn the maximum likelihoodestimate of the parameters, that is,?
?= arg max?M?m=1log P(Fm| Em)= arg max?log???????
?aP(Fm, a | Em)??????
?.We typically use the EM algorithm (Dempster et al.,1977), to carry out this optimization.2.3 DeciphermentGiven a corpus of N foreign text sequences (cipher-text), F1mono, .
.
.
,Fnmono, .
.
.
,FNmono, decipherment findsword-to-word translations that best describe the cipher-text.Knight et al.
(2006) are the first to study several natu-ral language decipherment problems with unsupervisedlearning.
Since then, there has been increasing interestin improving decipherment techniques and its applica-tion to machine translation (Ravi and Knight, 2011;558Dou and Knight, 2012; Nuhn et al., 2012; Dou andKnight, 2013; Nuhn et al., 2013).In order to speed up decipherment, Dou and Knight(2012) suggest that a frequency list of bigrams mightcontain enough information for decipherment.
Accord-ing to them, a monolingual ciphertext bigram Fmonoisgenerated through the following generative story:?
Generate a sequence of two plaintext tokens e1e2with probability P(e1e2) given by a languagemodel built from large numbers of plaintext bi-grams.?
Substitute e1with f1and e2with f2with probabil-ity t( f1|e1) ?
t( f2|e2).The probability of any cipher bigram F is:P(Fmono) =?e1e2P(e1e2) ?
t( f1|e1) ?
t( f2|e2) (4)And the probability of the corpus is:P(corpus) =N?n=1P(Fnmono) (5)Given a plaintext bigram language model, the goal isto manipulate t( f |e) to maximize P(corpus).
Theoret-ically, one can directly apply EM to solve the problem(Knight et al., 2006).
However, EM has time complex-ity O(N ?V2e) and space complexity O(Vf?Ve), where Vf,Veare the sizes of ciphertext and plaintext vocabulariesrespectively, and N is the number of cipher bigrams.There have been previous attempts to make decipher-ment faster.
Ravi and Knight (2011) apply Bayesianlearning to reduce the space complexity.
However,Bayesian decipherment is still very slow with Gibbssampling (Geman and Geman, 1987).
Dou and Knight(2012) make sampling faster by introducing slice sam-pling (Neal, 2000) to Bayesian decipherment.
BesidesBayesian decipherment, Nuhn et al.
(2013) show thatbeam search can be used to solve a very large 1:1 wordsubstitution cipher.
In subsection 2.4.1, we describeour approach that uses slice sampling to compute ex-pected counts for decipherment in the EM algorithm.2.4 Joint OptimizationWe now describe our EM approach to learn the param-eters that maximize Fjoint(equation 2), where the dis-tortion probabilities, d(aj| aj?1, j) in the word align-ment model are only learned from parallel data, andthe translation probabilities, t( f | e) are learned usingboth parallel and non parallel data.
The E step and Mstep are illustrated in Figure 2.Our algorithm starts with EM learning only on par-allel data for a few iterations.
When the joint inferencestarts, we first compute expected counts from paralleldata and non parallel data using parameter values fromthe last M step separately.
Then, we add the expectedcounts from both parallel data and non parallel data to-gether with different weights for the two.
Finally weFigure 2: Joint Word Alignment and Deciphermentwith EMrenormalize the translation table and distortion table toupdate parameters in the new M step.The E step for parallel part can be computed effi-ciently using the forward-backward algorithm (Vogel etal., 1996).
However, as we pointed out in Section 2.3,the E step for the non parallel part has a time com-plexity of O(V2) with the forward-backward algorithm,where V is the size of English vocabulary, and is usu-ally very large.
Previous work has tried to make de-cipherment scalable (Ravi and Knight, 2011; Dou andKnight, 2012; Nuhn et al., 2013; Ravi, 2013).
How-ever, all of them are designed for decipherment with ei-ther Bayesian inference or beam search.
In contrast, weneed an algorithm to make EM decipherment scalable.To overcome this problem, we modify the slice sam-pling (Neal, 2000) approach used by Dou and Knight(2012) to compute expected counts from non paralleldata needed for the EM algorithm.2.4.1 Draw Samples with Slice SamplingTo start the sampling process, we initialize the firstsample by performing approximate Viterbi decodingusing results from the last EM iteration.
For each for-eign dependency bigram f1, f2, we find the top 50 can-didates for f1and f2ranked by t(e| f ), and find the En-glish sequence e1, e2that maximizes t(e1| f1) ?
t(e2| f2) ?P(e1, e2).Suppose the derivation probability for current sam-ple e current is P(e current), we use slice sampling todraw a new sample in two steps:?
Select a threshold T uniformly between 0 andP(e current).?
Draw a new sample e new uniformly from a pool559of candidates: {e new|P(e new) > T }.The first step is straightforward to implement.
How-ever, it is not trivial to implement the second step.
Weadapt the idea from Dou and Knight (2012) for EMlearning.Suppose our current sample e current contains En-glish tokens ei?1, ei, and ei+1at position i ?
1, i, andi+1 respectively, and fibe the foreign token at positioni.
Using point-wise sampling, we draw a new sampleby changing token eito a new token e?.
Since the restof the sample remains the same, only the probability ofthe trigram P(ei?1e?ei+1) (The probability is given by abigram language model.
), and the channel model prob-ability t( fi|e?)
change.
Therefore, the probability of asample is simplified as shown Equation 6.P(ei?1e?ei+1) ?
t( fi|e?)
(6)Remember that in slice sampling, a new sample isdrawn in two steps.
For the first step, we choose athreshold T uniformly between 0 and P(ei?1eiei+1) ?t( fi|ei).
We divide the second step into two cases basedon the observation that two types of samples are morelikely to have a probability higher than T (Dou andKnight, 2012): (1) those whose trigram probability ishigh, and (2) those whose channel model probability ishigh.
To find candidates that have high trigram proba-bility, Dou and Knight (2012) build a top k sorted listsranked by P(ei?1e?ei+1), which can be pre-computedoff-line.
Then, they test if the last item ekin the listsatisfies the following inequality:P(ei?1ekei+1) ?
c < T (7)where c is a small constant and is set to prior in theirwork.
In contrast, we choose c empirically as we donot have a prior in our model.
When the inequality inEquation 7 is satisfied, a sample is drawn in the fol-lowing way: Let set A = {e?|ei?1e?ei+1?
c > T } andset B = {e?|t( fi|e?)
> c}.
Then we only need to samplee?uniformly from A ?
B until P(ei?1e?ei+1) ?
t( fi|e?)
isgreater than T .
It is easy to prove that all other candi-dates that are not in the sorted list and with t( fi|e?)
?
chave a upper bound probability: P(ei?1ekei+1)?c.
There-fore, they do not need to be considered.Second, when the last item ekin the list does notmeet the condition in Equation 7, we keep drawingsamples e?randomly until its probability is greater thanthe threshold T .As we mentioned before, the choice of the small con-stant c is empirical.
A large c reduces the number ofitems in set B, but makes the condition P(ei?1ekei+1) ?c < T less likely to satisfy, which slows down the sam-pling.
On the contrary, a small c increases the numberof items in set B significantly as EM does not encour-age a sparse distribution, which also slows down thesampling.
In our experiments, we set c to 0.001 basedon the speed of decipherment.
Furthermore, to reducethe size of set B, we rank all the candidate translationsSpanish EnglishParallel 10.3k 9.9kNon Parallel 80 million 400 millionTable 1: Size of parallel and non parallel data for wordalignment experiments (Measured in number of tokens)of fiby t(e?| fi), then we add maximum the first 1000candidates whose t( fi|e?)
>= c into set B.
For the restof the candidates, we set t( fi|e?)
to a value smaller thanc (0.00001 in experiments).2.4.2 Compute Expected Counts from SamplesWith the ability to draw samples efficiently for deci-pherment using EM, we now describe how to computeexpected counts from those samples.
Let f1, f2be aspecific ciphertext bigram, N be the number of sam-ples we want to use to compute expected counts, ande1, e2be one of the N samples.
The expected countsfor pairs ( f1, e1) and ( f2, e2) are computed as:?
?count( f1, f2)Nwhere count( f1, f2) is count of the bigram, and ?
is theweight for non parallel data as shown in Equation 1.Expected counts collected for f1, f2are accumulatedfrom each of its N samples.
Finally, we collect ex-pected counts using the same approach from each for-eign bigram.3 Word Alignment ExperimentsIn this section, we show that joint word alignment anddecipherment improves the quality of word alignment.We choose to evaluate word alignment performancefor Spanish and English as manual gold alignmentsare available.
In experiments, our approach improvesalignment F score by as much as 8 points.3.1 Experiment SetupAs shown in Table 1, we work with a small amount ofparallel, manually aligned Spanish-English data (Lam-bert et al., 2005), and a much larger amount of mono-lingual data.The parallel data is extracted from Europarl, whichconsists of articles from European parliament plenarysessions.
The monolingual data comes from Englishand Spanish versions of Gigaword corpra containingnews articles from different news agencies.We view Spanish as a cipher of English, and followthe approach proposed by Dou and Knight (2013) toextract dependency bigrams from parsed Spanish andEnglish monolingual data for decipherment.
We onlykeep bigrams where both tokens appear in the paral-lel data.
Then, we perform Spanish to English (En-glish generating Spanish) word alignment and Span-ish to English decipherment simultaneously with themethod discussed in section 2.5603.1.1 ResultsWe align all 500 sentences in the parallel corpus, andtune the decipherment weight (?)
for Model 1 andHMM using the last 100 sentences.
The best weightsare 0.1 for Model 1, and 0.005 for HMM.
We start withModel 1 with only parallel data for 5 iterations, andswitch to the joint process for another 5 iterations withModel 1 and 5 more iterations of HMM.
In the end, weuse the first 100 sentence pairs of the corpus for evalu-ation.Figure 3 compares the learning curve of alignmentF-score between EM without decipherment (baseline)and our joint word alignment and decipherment.
Fromthe learning curve, we find that at the 6th iteration, 2iterations after we start the joint process, alignment F-score is improved from 34 to 43, and this improvementis held through the rest of the Model 1 iterations.
Thealignment model switches to HMM from the 11th iter-ation, and at the 12th iteration, we see a sudden jumpin F-score for both the baseline and the joint approach.We see consistent improvement of F-score till the endof HMM iterations.4 Improving Low Density LanguagesMachine Translation with Joint WordAlignment and DeciphermentIn the previous section, we show that the joint wordalignment and decipherment process improves qualityof word alignment significantly for Spanish and En-glish.
In this section, we test our approach in a morechallenging setting: improving the quality of machinetranslation in a real low density language setting.In this task, our goal is to build a system to trans-late Malagasy news into English.
We have a smallamount of parallel data, and larger amounts of mono-lingual data collected from online websites.
We build adependency parser for Malagasy to parse the monolin-gual data to perform dependency based decipherment(Dou and Knight, 2013).
In the end, we perform jointword alignment and decipherment, and show that thejoint learning process improves Bleu scores by up to2.1 points over a phrase-based MT baseline.4.1 The Malagasy LanguageMalagasy is the official language of Madagascar.
It hasaround 18 million native speakers.
Although Mada-gascar is an African country, Malagasy belongs to theMalayo-Polynesian branch of the Austronesian lan-guage family.
Malagasy and English have very dif-ferent word orders.
First of all, in contrast to En-glish, which has a subject-verb-object (SVO) word or-der, Malagasy has a verb-object-subject (VOS) wordorder.
Besides that, Malagasy is a typical head ini-tial language: Determiners precede nouns, while othermodifiers and relative clauses follow nouns (e.g.
ny?the?
boky ?book?
mena ?red?).
The significant dif-ferences in word order pose great challenges for bothSource Malagasy EnglishParallelGlobal Voices 2.0 million 1.8 millionWeb News 2.2k 2.1kNon ParallelGigaword N/A 2.4 billionallAfrica N/A 396 millionLocal News 15.3 million N/ATable 2: Size of Malagasy and English data used in ourexperiments (Measured in number of tokens)machine translation and decipherment.4.2 DataTable 2 shows the data available to us in our experi-ments.
The majority of parallel text comes from GlobalVoices1(GV).
The website contains international newstranslated into different foreign languages.
Besidesthat, we also have a very small amount of parallel textcontaining local web news, with English translationsprovided by native speakers at the University of Texas,Austin.
The Malagasy side of this small parallel corpusalso has syntactical annotation, which is used to train avery basic Malagasy part of speech tagger and depen-dency parser.We also have much larger amounts of non paral-lel data for both languages.
For Malagasy, we spenttwo months manually collecting 15.3 million tokens ofnews text from local news websites in Madagascar.2We have released this data for future research use.
ForEnglish, we have 2.4 billion tokens from the Gigawordcorpus.
Since the Malagasy monolingual data is col-lected from local websites, it is reasonable to argue thatthose data contain significant amount of information re-lated to Africa.
Therefore, we also collect 396 milliontokens of African news in English from allAfrica.com.4.3 Building A Dependency Parser for MalagasySince Malagasy and English have very different wordorders, we decide to apply dependency based decipher-ment for the two languages as suggested by Dou andKnight (2013).
To extract dependency relations, weneed to parse monolingual data in Malagasy and En-glish.
For English, there are already many good parsersavailable.
In our experiments, we use Turbo parser(Martins et al., 2013) trained on the English Penn Tree-bank (Marcus et al., 1993) to parse all our Englishmonolingual data.
However, there is no existing goodparser for Malagasy.The quality of a dependency parser depends on theamount of training data available.
State-of-the-art En-glish parsers are built from Penn Treebank, which con-tains over 1 million tokens of annotated syntactical1globalvoicesonline.org2aoraha.com, gazetiko.com, inovaovao.com,expressmada.com, lakroa.com561Figure 3: Learning curve showing our joint word alignment and decipherment approach improves word alignmentquality over the traditional EM without decipherment (Model 1: Iteration 1 to 10, HMM: Iteration 11 to 15)trees.
In contrast, the available data for training a Mala-gasy parser is rather limited, with only 168 sentences,and 2.8k tokens, as shown in Table 2.
At the very be-ginning, we use the last 120 sentences as training datato train a part of speech (POS) tagger using a toolkitprovided by Garrette et al.
(2013) and a dependencyparser with the Turbo parser.
We test the performanceof the parser on the first 48 sentences and obtain 72.4%accuracy.One obvious way to improve tagging and parsing ac-curacy is to get more annotated data.
We find more datawith only part of speech tags containing 465 sentencesand 10k tokens released by (Garrette et al., 2013), andadd this data as extra training data for POS tagger.Also, we download an online dictionary that containsPOS tags for over 60k Malagasy word types from mala-gasyword.org.
The dictionary is very helpful for tag-ging words never seen in the training data.It is natural to think that creation of annotated datafor training a POS tagger and a parser requires largeamounts of efforts from annotators who understand thelanguage well.
However, we find that through the helpof parallel data and dictionaries, we are able to createmore annotated data by ourselves to improve taggingand parsing accuracy.
This idea is inspired by previ-ous work that tries to learn a semi-supervised parserby projecting dependency relations from one language(with good dependency parsers) to another (Yarowskyand Ngai, 2001; Ganchev et al., 2009).
However, wefind those automatic approaches do not work well forMalagasy.To further expand our Malagasy training data, wefirst use a POS tagger and parser with poor perfor-mance to parse 788 sentences (20k tokens) on theMalagasy side of the parallel corpus from GlobalVoices.
Then, we correct both the dependency linksand POS tags based on information from dictionaries3and the English translation of the parsed sentence.
Wespent 3 months to manually project English dependen-cies to Malagasy and eventually improve test set pars-ing accuracy from 72.4% to 80.0%.
We also make thisdata available for future research use.4.4 Machine Translation ExperimentsIn this section, we present the data used for our MTexperiments, and compare three different systems tojustify our joint word alignment and decipherment ap-proach.4.4.1 Baseline Machine Translation SystemWe build a state-of-the-art phrase-based MT system,PBMT, using Moses (Koehn et al., 2007).
PBMT has 3models: a translation model, a distortion model, anda language model.
We train the other models usinghalf of the Global Voices parallel data (the rest is re-served for development and testing), and build a 5-gram language model using 834 million tokens fromAFP section of English Gigaword, 396 million tokensfrom allAfrica, and the English part of the parallel cor-pus for training.
For alignment, we run 10 iterationsof Model 1, and 5 iterations of HMM.
We did not runModel 3 and Model 4 as we see no improvements inBleu scores from running those models.
We do word3an online dictionary from malagasyword.org, as well asa lexicon learned from the parallel data562alignment in two directions and use grow-diag-final-and heuristic to obtain final alignment.
During decod-ing, we use 8 standard features in Moses to score a can-didate translation: direct and inverse translation proba-bilities, direct and inverse lexical weighting, a languagemodel score, a distortion score, phrase penalty, andword penalty.
The weights for the features are learnedon the tuning data using minimum error rate training(MERT) (Och, 2003).To compare with previous decipherment approach toimprove machine translation, we build a second base-line system.
We follow the work by Dou and Knight(2013) to decipher Malagasy into English, and build atranslation lexicon Tdecipherfrom decipherment.
To im-prove machine translation, we simply use Tdecipherasan additional parallel corpus.
First, we filter Tdecipherby keeping only translation pairs ( f , e), where f is ob-served in the Spanish part and e is observed in the En-glish part of the parallel corpus.
Then we append allthe Spanish and English words in the filtered Tdecipherto the end of Spanish part and English part of the paral-lel corpus respectively.
The training and tuning processis the same as the baseline machine translation systemPBMT.
We call this system Decipher-Pipeline.4.4.2 Joint Word Alignment and Deciphermentfor Machine TranslationWhen deciphering Malagasy to English, we extractMalagasy dependency bigrams using all availableMalagasy monolingual data plus the Malagasy part ofthe Global Voices parallel data, and extract Englishdependency bigrams using 834 million tokens fromEnglish Gigaword, and 396 million tokens from al-lAfrica news to build an English dependency languagemodel.
In the other direction, we extract English de-pendency bigrams from English part of the entire paral-lel corpus plus 9.7 million tokens from allAfrica news4, and use 17.3 million tokens Malagasy monolingualdata (15.3 million from the web and 2.0 million fromGlobal Voices) to build a Malagasy dependency lan-guage model.
We require that all dependency bigramsonly contain words observed in the parallel data usedto train the baseline MT system.During learning, we run Model 1 without decipher-ment for 5 iterations.
Then we perform joint wordalignment and decipherment for another 5 iterationswith Model 1 and 5 iterations with HMM.
We tunedecipherment weights (?)
for Model 1 and HMM us-ing grid search against Bleu score on a developmentset.
In the end, we only extract rules from one di-rection P(English|Malagasy), where the deciphermentweights for Model 1 and HMM are 0.5 and 0.005 re-spectively.
We chose this because we did not find anybenefits to tune the weights on each direction, and thenuse grow-diag-final-end heuristic to form final align-ments.
We call this system Decipher-Joint.4We do not find further Bleu gains by using more Englishmonolingual data.ParallelMalagasy EnglishTrain (GV) 0.9 million 0.8 millionTune (GV) 22.2k 20.2kTest (GV) 23k 21kTest (Web) 2.2k 2.1kNon ParallelMalagasy EnglishGigaword N/A 834 millionWeb 15.3 million 396 millionTable 3: Size of training, tuning, and testing data innumber of tokens (GV: Global Voices)4.5 ResultsWe tune each system three times with MERT andchoose the best weights based on Bleu scores on tuningset.Table 4 shows that while using a translation lexiconlearnt from decipherment does not improve the qualityof machine translation significantly, the joint approachimproves Bleu score by 0.9 and 2.1 on Global Voicestest set and web news test set respectively.
The resultsshow that the parsing quality correlates with gains inBleu scores.
Scores in the brackets in the last row ofthe table are achieved using a dependency parser with72.4% attachment accuracy, while scores outside thebrackets are obtained using a dependency parser with80.0% attachment accuracy.We analyze the results and find the gain mainlycomes from two parts.
First, adding expected countsfrom non parallel data makes the distribution of trans-lation probabilities sparser in word alignment models.The probabilities of translation pairs favored by bothparallel data and decipherment becomes higher.
Thisgain is consistent with previous observation where asparse prior is applied to EM to help improve wordalignment and machine translation (Vaswani et al.,2012).
Second, expected counts from deciphermentalso help discover new translation pairs in the paral-lel data for low frequency words, where those wordsare either aligned to NULL or wrong translations in thebaseline.5 Conclusion and Future WorkWe propose a new objective function for word align-ment to combine the process of word alignment anddecipherment into a single task.
In, experiments, wefind that the joint process performs better than previouspipeline approach, and observe Bleu gains of 0.9 and2.1 point on Global Voices and local web news test sets,respectively.
Finally, our research leads to the releaseof 15.3 million tokens of monolingual Malagasy datafrom the web as well as a small Malagasy dependencytree bank containing 20k tokens.Given the positive results we obtain by using thejoint approach to improve word alignment, we are in-563Decipherment System Tune (GV) Test (GV) Test (Web)None PBMT (Baseline) 18.5 17.1 7.7Separate Decipher-Pipeline 18.5 17.4 7.7Joint Decipher-Joint 18.9 (18.7) 18.0 (17.7) 9.8 (8.5)Table 4: Decipher-Pipeline does not show significant improvement over the baseline system.
In contrast, Decipher-Joint using joint word alignment and decipherment approach achieves a Bleu gain of 0.9 and 2.1 on the GlobalVoices test set and the web news test set, respectively.
The results in brackets are obtained using a parser trainedwith only 120 sentences.
(GV: Global Voices)spired to apply this approach to help find translationsfor out of vocabulary words, and to explore other pos-sible ways to improve machine translation with deci-pherment.AcknowledgmentsThis work was supported by NSF Grant 0904684 andARO grant W911NF-10-1-0533.
The authors wouldlike to thank David Chiang, Malte Nuhn, Victoria Fos-sum, Ashish Vaswani, Ulf Hermjakob, Yang Gao, andHui Zhang (in no particular order) for their commentsand suggestions.ReferencesShane Bergsma and Benjamin Van Durme.
2011.Learning bilingual lexicons using the visual similar-ity of labeled web images.
In Proceedings of theTwenty-Second International Joint Conference onArtificial Intelligence - Volume Three.
AAAI Press.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
The math-ematics of statistical machine translation: Parameterestimation.
Computational Linguistics, 19:263?311.Hal Daum?e, III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by miningunseen words.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies.
Associa-tion for Computational Linguistics.Arthur Dempster, Nan Laird, and Donald Rubin.
1977.Maximum likelihood from incomplete data via theEM algorithm.
Computational Linguistics, 39(4):1?38.Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning.
Asso-ciation for Computational Linguistics.Qing Dou and Kevin Knight.
2013.
Dependency-based decipherment for resource-limited machinetranslation.
In Proceedings of the 2013 Conferenceon Empirical Methods in Natural Language Process-ing.
Association for Computational Linguistics.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compa-rable texts.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Computa-tional Linguistics - Volume 1.
Association for Com-putational Linguistics.Kuzman Ganchev, Jennifer Gillenwater, and BenTaskar.
2009.
Dependency grammar induction viabitext projection constraints.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP: Vol-ume 1 - Volume 1.
Association for ComputationalLinguistics.Nikesh Garera, Chris Callison-Burch, and DavidYarowsky.
2009.
Improving translation lexicon in-duction from monolingual corpora via dependencycontexts and part-of-speech equivalences.
In Pro-ceedings of the Thirteenth Conference on Computa-tional Natural Language Learning.
Association forComputational Linguistics.Dan Garrette, Jason Mielens, and Jason Baldridge.2013.
Real-world semi-supervised learning of pos-taggers for low-resource languages.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Pa-pers).
Association for Computational Linguistics.Stuart Geman and Donald Geman.
1987.
Stochas-tic relaxation, Gibbs distributions, and the Bayesianrestoration of images.
In Readings in computer vi-sion: issues, problems, principles, and paradigms.Morgan Kaufmann Publishers Inc.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of ACL-08: HLT.
Association for Computational Linguis-tics.Ann Irvine and Chris Callison-Burch.
2013a.
Com-bining bilingual and comparable corpora for low re-source machine translation.
In Proceedings of theEighth Workshop on Statistical Machine Transla-tion.
Association for Computational Linguistics, Au-gust.Ann Irvine and Chris Callison-Burch.
2013b.
Su-pervised bilingual lexicon induction with multiplemonolingual signals.
In Proceedings of the 2013564Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies.
Association for Computa-tional Linguistics.Ann Irvine, Chris Quirk, and Hal Daume III.
2013.Monolingual marginal matching for translationmodel adaptation.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing.
Association for Computational Linguistics.Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?u.2008.
A cascaded linear model for joint Chineseword segmentation and part-of-speech tagging.
InProceedings of ACL-08: HLT.
Association for Com-putational Linguistics.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky.
2012.
Toward statisti-cal machine translation without parallel corpora.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Lin-guistics.
Association for Computational Linguistics.Kevin Knight, Anish Nair, Nishit Rathod, and KenjiYamada.
2006.
Unsupervised analysis for decipher-ment problems.
In Proceedings of the COLING/ACL2006 Main Conference Poster Sessions.
Associationfor Computational Linguistics.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
InProceedings of the ACL-02 Workshop on Unsuper-vised Lexical Acquisition.
Association for Computa-tional Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ond?rej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions.Association for Computational Linguistics.Patrik Lambert, Adri?a De Gispert, Rafael Banchs, andJos?e B. Mari?no.
2005.
Guidelines for word align-ment evaluation and manual alignment.
LanguageResources and Evaluation, 39(4):267?285.Mitchell Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2).Andre Martins, Miguel Almeida, and Noah A. Smith.2013.
Turning on the Turbo: Fast third-order non-projective Turbo parsers.
In Proceedings of the 51stAnnual Meeting of the Association for Computa-tional Linguistics (Volume 2: Short Papers).
Asso-ciation for Computational Linguistics.Radford Neal.
2000.
Slice sampling.
Annals of Statis-tics, 31.Malte Nuhn, Arne Mauser, and Hermann Ney.
2012.Deciphering foreign language by combining lan-guage models and context vectors.
In Proceedingsof the 50th Annual Meeting of the Association forComputational Linguistics: Long Papers - Volume1.
Association for Computational Linguistics.Malte Nuhn, Julian Schamper, and Hermann Ney.2013.
Beam search for solving substitution ciphers.In Proceedings of the 51st Annual Meeting of theAssociation for Computational Linguistics.
Associ-ation for Computational Linguistics.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofthe 41st Annual Meeting of Association for Compu-tational Linguistics.
Association for ComputationalLinguistics.Reinhard Rapp.
1995.
Identifying word translationsin non-parallel texts.
In Proceedings of the 33rd an-nual meeting of Association for Computational Lin-guistics.
Association for Computational Linguistics.Sujith Ravi and Kevin Knight.
2011.
Deciphering for-eign language.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies.
Associa-tion for Computational Linguistics.Sujith Ravi.
2013.
Scalable decipherment for machinetranslation via hash sampling.
In Proceedings of the51th Annual Meeting of the Association for Compu-tational Linguistics.
Association for ComputationalLinguistics.Ashish Vaswani, Liang Huang, and David Chiang.2012.
Smaller alignment models for better trans-lations: Unsupervised word alignment with the l0-norm.
In Proceedings of the 50th Annual Meeting ofthe Association for Computational Linguistics: LongPapers - Volume 1.
Association for ComputationalLinguistics.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statisticaltranslation.
In Proceedings of the 16th Conferenceon Computational Linguistics - Volume 2.
Associa-tion for Computational Linguistics.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual POS taggers and NP bracketers via robustprojection across aligned corpora.
In Proceedingsof the Second Meeting of the North American Chap-ter of the Association for Computational Linguisticson Language Technologies.
Association for Compu-tational Linguistics.Yue Zhang and Stephen Clark.
2008.
Joint word seg-mentation and POS tagging using a single percep-tron.
In Proceedings of ACL-08: HLT, Columbus,Ohio.
Association for Computational Linguistics.565
