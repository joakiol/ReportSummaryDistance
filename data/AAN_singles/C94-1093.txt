Restructuring Tagged Corpora with Morpheme Adjustment RulesAbstractToshihisa Tashiro Noriyoshi Uratani Tsuyoshi MorimotoATR In terpret ing  Te lecommunicat ions  Research Labor~tor ies2-2 t I ikar idai ,  Seika-cho, Soraku-gun,  Kyoto  619-02, JAPAN{tash i ro ,ura tan i ,mor imoto}  ~ i t l .a t  r.co.jpA part-of-speech tagged corpus is a very hnportant knowledge source for natural language processing researchers.
'Poday, several part-of-speech tagged corpora re readily available for research use.
\[Iowever, because there is widediversity of morphological information systems (word-segmentation~ part-of-speech system, etc.
), it is ditficult touse tagged corpora with an incompatible morphological infm'mation system.
This paper proposes a me,hod ofconverting tagged corpora frOlll olte l l lorphellle system to allother,1 In t roduct ionRecently, mm,y natural language processing re-searchers have concentrated on corpus-based ap-proaches.
Linguistic corpora can be classified asword-segmented corpora, part-of-speech tagged cor-pora, and parsed corpora, tlecause a part-of-speechtagged corpus is the most important corpus, muchcorpus-based natural language processing researchhas been performed using part-of-speech tagged cor-pora.Ilowever, building a large part-of-speech taggedcorpus is very dillicult.
It is even more difficult tobuild a corpus for languages without explicit wordboundary characters, such as Japanese.
q'herefore,researchers always complain of the scarcity of data inthe corpus.To solve this data scarcity problem, previous worksproposed methods of increasing the productivityof the labor required for building a part-of-speechtagged corpus.
\[1\].
'.l'his paper proposes another method of acquir-ing large part-of-speech tagged corpora: restructur-ing tagged corpora by using morpheme adjustmentrules.
This method assures good use of the sharablepart-of-speech tagged corpora that are already awdl-able such as the ATR Dialog Database (ADD) \[2;3\].Ideally, these corpora could be used by all re-searchers and research groups without any modifica-tions, llowever, actual part-of-speech tagged corporahave the following problems:?
Diversity of orthography:A word can be spelled in various ways.
InJapanese, there are three types of character sets:kanji (i~.~"-), hiragana (~ to ~ ~), and katakana(:~J # :~J ?).
Also, people can use these charactersets at their discretion.?
Diversity of word segmentation:Because the Japanese language has no wordboundary characters(i.e, blank spaces), thereare no standards of word segmentation.
A sin-gle word in a certain corpus may be considerednmltiple words in other corpora, and vice versa.?
Diw;rsity of part-of speech systems:There are no standards for part-of-speech sys-tems.
It is true that a detailed part-of-speechsystem can help the application of part-of-speechinformation, lint the labor required \['or lmildingcorpora will continue to increase.
This problemis language-independent.Diversities of word-segmentation and part-of-speech systems are fatal problems.
The simplest wayto solve these problems is to perform a morphologicalanalysis on the raw text in the corpus, with no regardto the word-segmentation a d part-of-speech infermation.
Uowever, making a high-quality morphologi-cal analyzer demands much time and care.
Addition-ally, it is wasteful to ignore the word-segmentationand part-of-speech i,fformation that h~s been ac-quired with much effort.In restructuring tagged corpora with nmrpheme ad-justmel,t rules, tim word-segrnentation and part-of-speech inlbrmation of the original corpus is rewrittm,,making good use of the original corpus information.
"riffs method is characterized by reduced manual ef-fort.In the next section, the method of rest, rueturingtagged corpora is described in detail.
Section 3 re-ports the result of an experiment in rewriting thecorpus using this method.2 Restructuring Tagged Co lporaRestructuring tagged corpora involves the followingthree steps:?
preparation of training set?
extraction of morpheme adjustment rules?
rewrith~g of corpora5692.1 Preparat ion of Training SetFirst, sentences for the training set are chosen fromthe corpus to be rewritten.
New word-segmentationand part-of-speech information (morphological infor-mation) is given to the sentences by a morphologi-cal analyzer or by hand.
Consequently, the trainingset has two sets of morphological information for thesame raw text.
Figure I shows an example of thetraining set.A large number of training sentences i desirable,but preparing many sentences requires much time andeffort.
A vmst nmnber of sentences would be requiredto extend coverage to content words (such as nouns,w'A)s, ete), but flmctionaI words (such as particles,auxiliary verbs, ere) can be covered with a smallernumber of sentences.ntw text '~!,'q\]O I f I~& .5/~'(" L ~ 5 Z}~morphological ('/~qJg \[N~- n-com)(tJ: postp-topic)information A (aS vste,n)(~ vinlt)(,G f,,)(-OL~ 5 auxv-Imlt-aux-nom)(Z~ auxv-sfp-1)information B (t-?
NItJJ~J) (~7o 2b:N~,i\])(,t, ~,:i?l~JJ~l)(et.
x ~JJ~OJa,~l)(5 I~NjDJ)(fi, $gtl)377~\])Figure 1: An Example of the 'Fraining Set2.2 Extract ion of Morpheme Adjust-ment RulesThe method of extracting morpheme ad.iustmentrules from the training set involves finding correspon-dence between rewriting units and extracting rules forunknown words:2.2.1.
CorrespoiMenees of Rewr i t ing  Uni tsIn languages without explicit word boundary char-acters, such as Japanese, a single word in a certainmorphological information system may be dividedinto multiple words (one-to-many correspondence)in other morphological information systems, multi-pie words may be unified (many-to-one correspon-dence), or the segmentation of multiple words maybe changed (many-to-many correspondence).
Figure2 shows these correspondences.We developed an algorithm to find these correspon-dences (Appendix A).
By using this algorithm, mor-pheme rewriting rules (Figure 3) can be extracted.2.2.2 Rules lot" Unknown WordsRewriting rules such as those shown in Figure 3 canrewrite only the words that appeared in the train-ing set,.
If the training set is small, the coverageof the rules will be limited.
Ilowever, because thisn~orpheme adjnstment is a method of rewriting part-of-speech tagged corpora, the treatment of unknownone- to -one \ ]"I\[l~ (NOUN)" o "JIl~sl~ (NOUN)"|one-to-many\]"~ (V|,qRB)" ~ "~ (V-ST~M) .... ~ (~Nt~L)"\[many-to-oriel"~.,~ (NOUN)" "~115~ (NOUN)" <~ "~/ \ ] \ ]~  (NOUN)"\[hi ~tny-to- lna l ly \ ]"m (PAR'FICIA,~)" v, ;5 (VERB)"~# "-Cv, (AUXV-STEM) .... -5 (\[NFL)"Figure 2: Various correspondences~* x:~', (auxvstem-aspc) ~ (vinfl)(t.~tl)Ji~\]) +~ ~_" (postp-oblg)Z.-\[ ~-  (~i~i\]) ?>_-_:: (n-digit) -I" (digit-sul/ix-zyuu) --(n-digit)l?ignre 3: An Example of Extracted Ruleswords is easier than with an ordinary morphologicalanaIyzer, because that our method can make gooduse of the part-of-speech information of the origi-nal corpus.
Rules for unknown words without word-segmentation changes between two morphological in-formation systems can be extracted automaticallyfrom one-to-one correspondence rules in the rewrit-ing rules.Rules tbr unknown words with word-segmentationchanges can also be extracted automatically by us-ing information concerning the length of the word'scharacters.
For examph'., when a single verb with twocharacters in a certaiu morphological information sys-tem corresponds to two words (verb-stem with onecharacter and verb-inflection with one character) inanother morphological information system, the fol-lowing rewriting rule is extracted.2(verb)--~ l(verb-stem) l(verb-inflection)Figure 4 shows sample rules for unknown words.The heuristic knowledge of character sets that anordinary Japanese morphological nalyzer uses (suchas "katakana words are usually proper nom,s", "verbiMleetion words are spelled using hiragana", etc.
)are also available in this nlorpheme adjustment ted>nique.?
r 2.3 Rewrit ing of Tagged Corpora2.3.1 Appl icat ion of Rewr i t ing IhnnsBy applyi,~g the rewriting rules described in the lastsubsection to the tagged corpus, a lattice structure~ll)j~/il <* FADN+ftll)j;~ ,~> POSTP-OBLG2(~j~,~) l(:/~l~)JffO}il,q) o a(VSTEM) I(VINFL)"2(tdIJlgl~,il) ?> I(POSTP-OPTN) I(POSTP-CONTR)Figure 4: An Exarnple of gules for Unknown Words570I>OSTP-oP'rN AOXV-ST?Mr---  f iADV-REItNEL\] VSTEM AUXV\]  AUXV-STEbl I AUXVI I~V-KE.
.
, : * ,  wN~.,~ l~Dv.
l~j._l.Figure 5: An Exanlple of the Lattice Formed by theMorpheme Adjuster~IJXV- STEI~I\[ AUXVI~UX'!
V~.~ c- -I POSTP-OPTN I AU)fV VINFLi ' - -  I} PO$~'P"OBLG I AUXV- STIc:l i V (NFI,I~  f C------ADV-KERNZI, \[ VSTEM AUXV i ADV-COR3 I AU X"r- -  1 I' F - --_x,-,~ ,~ f ~ 2 9 - _l"igure 6: An Example of the l,attice Formed by anOrdinary Morphological Analyzer(Figure 5) is formed because of I, he ainlliguity inrewriting rules.
1l{owew;r, this ambiguity is not as great as the aml>i-guity that occurs in ordinary morphological analysisbecause our method makes good use of the inform;v-tion of the original corpus.
Figure 6 shows the latticestructure formed when using the ordinary morpholog-ical analysis on the same raw text.
Note that the sizeof this lattice is greater i.hail the size oF the latticemade by our method.2.3 .2  Latt iee SearchThe last step in restructuring tagged corpora can beconsidered a lattice search l)rol)lenl.
\[U this step, allof the following knowledge sources for anlhiguil, y reso-lution used in ordinary morphological nalysis is alsoavailable in our method:?
connection matr ix?
heuristic preferences (longest word preference,minimum phrase preference, etc.)?
stochastic preferences (word n-gram, IIMM, etc.
)By using these knowledge sources, the most plausi-ble candidate is chosen.
In effect, the original corpusis converted to a new eorptls that uses a differentmorphological information system.3 Exper iment3.1 Experimental ConditionThe targets in our experiment are a morl~hologicalinformation system for the A'I?II, l)ialog Database\[2;l'\])hls ambiguity mainly conies from l.he difl;Jrence iii part-oLspeech granularity between the two morphological infornla-\[,ion systenls,3\] and a morphological infornlation system lbr theunification-based Japanese grammar used in A'I'R'sspoken language parser\[4\].
'l.
'hese two morphologicalinformation systenls haw; the following characteris-tics.?
The ATR Dialog 13at.abase was developed as ma-terial for analyzing the characteristics of spoken-style Japanese.
'\['herefore, the part-of-speechgranularity is coarse.
Additionally, because theword-.segmentation is based on a morphologicaland etymological criterion, compound nouns ~mdcompound words that fluiction as a single aux-iliary w~rb (e.g.
"-C ~ zj ") are divided into sev-eral shorter word units.
Ou the other hand, be-cause this database giw;s little consideration tomechanical processing, stems and inflections oFinflectional words are not segmented.?
The nnification-based Japanese gramnmr hasa medium-grained part-.of-speech (pre-ternlinal)system to make it both c\[tleient and easy tomaintain\[5\].
Because the objective of the gram-Ynar is to ext rac t  the syntact i c  s t ruc tures  e lJapanese  sentences automatically and elIiciently,COml~OUnd words that funel.iml as a single wordare usually recognized as a single word.
On theother hand, steins amt ilHlectious of inllectionalwords  are seg l \ [ le l l ted  for eol lve l l ience ()l' nlechall.-ieal processiug.The above descriptions how that these nl?~rl~hologi-cal infl)rulation syst.ems differ.
The objectiw~ of thisexperiment is to examine whether our method canadjust the differences between the two niorphologicalinformation systems to ~i considerable xtent.Firsl;, we chose 1,000 sentences fronl the A;I'li,Dialog Database as the training set and providedthe morphological information (word-segmentationand lmrl.-of'-speech) of the unification-based Japanesegra l l i lnar .
\%Te prepared  350 sei itel iCes as the  Lest selb,separate from the training set.
'Phe t,'st sentenceswere also giw~n the lnorphological infornlal, ion.We extracted 1,5;18 r.orrespondeiiees el' rewrithlgunil.s (i.e.
rewi'il.hlg rilies) alid <128 rules For Uliknownwords.
'\]'\]lc.se rllles can l)e used for the \]Ji direetioila\]rewril.ing experiuienl..As the kliowh~dge sOtll'<:e in searching lattices, wordbigrauis and part-ol-sl)eech I)igralns were trained wil;hthe training set.
To perform the hi-directional rewrit-ing experinlent, these bigralns were trained in bothi norpho log iea l  in fo rn ia l ; ion  sys ten ls .
'\['O eOl'ilpare o/lr niethod with ordinary niorpholog-ical analysis, we dew, loped a sinlple stocha.<~tic iior-phological analyzer that uses the santo bigrams as theknowledge sourc~,s 2.
Ilecause this morphological na-lyzer has been developed for the comparative xper-iment, it.
catlnot inanage unknown words.
'Fherelbre,the rewriting test was performed by using not only the"2 Of Cotlrse, the ordinary nlorphologlcal nalyzer can rewritethe corpus Iilllch nitre accurately by tlshlg richer knowledgegOllr('t~s, llowevei', it onlst he llo{ed tilat on l '  n le l ,  i l od  it lvlo c ; l l ltlSf~ 51 lch  knowl.dgc S(-ItlI'CI~S,571Morphological Unification-Based ATR DialogInformation Japanese Gralnlnar Datal)euseTraining Setsentences 1,000 1,000(words) (I0,510) (10,723)Test Set (Full)sentences(words)Test Set (Sub)sentences(words)Vocabulary350(3,804)148(904)350(4,060) ....148(949)1,284 1,168POS System 75Word Bigram ' 41325POS Bigram 503264,292262Table 1: Experimental Conditiontest sentences, but also the training sentences (closeexperiment) and the sentences having no imknownwords (a subset of the test set).Table 1 shows the experinlental conditions ill de-tail.3.2 Rewriting of Morphological Infor-mationThe experiment was performed bi-directionally be-tween the morphological information system of theATt~ Dialog Database (ADD) and the morphologi-cal information system of unification-based Japanesegrammar.3.2.1 From Uni f icat ion-Based Granmxar toADDThis experiment rewrites from a medimn-graiuedmorphological information system to a coarse-grainedmorphological information system.
Table :1.2.1 showsthe result of this rewriting.
The segmentation er-ror rate and part-of-speech error rate were calculatedusing the same definition in \[1\].
Table 2 shows theresult.The error rates seem to be rather large, but itshould be noted that only simple knowledge sourcesare used both ill our method (the morpheme adjuster)and by the morphological nalyzer.
Also, it is signif-icant that our targets are spoken-style Japanese sen-tences.
Ordinary morphological analyzers can ana-lyze written-style Japanese sentences with a less than50_/o error rate, by using richer knowledge sources\[I\].However, previous work reported that the error ratefor automatic morphological nalysis of the ADD textis more than 15%\[6\].hi comparing the two methods, the part-of-speecherror rates of our method are clearly better than thoseof the morphological nalyzer.
This shows that ourmethod can make good use of tile original part-of-speech information.3.2.2 From ADD to Unl f icat lon-BasedJapanese GrammarThis experiment is more difficult because this rewrit-ing is from the coarse-grained morphological infor-nlation system to the medium-grained morphologicalinformation systeln.
Table 3 shows the result.The part-of-speech error rates of our method arebetter in this rewriting experiment, oo.4 ConclusionThis paper proposed restructuring of tagged corporaby using morpheme adjustment rifles.
The even-tuaI goal of this work is to make precious knowledgesources truly sharable among many researchers.
Tileresults of tile experiment seem promising.Our rnorpbenle adjustment method has some re-semblaace to Brill's part-of-speech tagging method\[7\].Brill's simple part-of-speech tagger call be considereda morpheme adjnster that adjusts differences betweeninitial (default) tags and correct ta~s.As Brill applied his part-of-speech tagging tech-nique to tbe syntactic bracketing technique\[8\], webelieve that our method can be applied to the ad-justment of parsed corpora.
In the work of Grish-man et al\[9\], tree rewriting rules to adjust differencesbetween Tree Bank and their grammar were proba-bly prepared manually.
By applying our method toparsed corpora, such rewriting rules call be extractedautomatically.AcknowledgmentsThe attthors would llke t.o thank Dr. Yasnhlro Yamazaki, Pres-ident of ATI/ interpreting Telecommunications Lalmrat.orles,for his collstant supl)ot't and encouragement..References\[1\] Maruyama, ll., Oglno, S., l\[idano, M., "The Mega-WordTagged-Corpus Project," TMI-93, pp.15-23, 1990\[2\] Ehara, T., Ogtlra, a.  and Morimoto, T, "ATR, DialogueDatabase," ICSLP-90, pp.1093-1096, 1990.\[3\] Sagisaka, Y., Uratani, N., "ATI~ Spoken LanguageDatahase," The Journal ,ff Ihe Acoustical Society of Japan,Vol.
,18, 12, l)p. ggs-S82, 1992.
(in a*qmnese)\[,1\] Nagata, M. and Morimoto, T.: "A Unification-Based.\]apanese Pm'ser for Speech-to-Speech "\['ranslatlon," IEICETrans.
Inf.
,?.~ Syst., VoI.F76-D, No.l, pp.51-61, 1993.\[5\] Nagata, M. "An Empirical Study on lq.ule Granularity andUnification Interleaving.
- Toward an Etlleient Unification-Based Parsing System," in Proe.
of COLING-92, 1992.\[6\] Kita, K., Ogura, K., Morlmoto, T., Yano, Y., "Autotnatl-tally Extract.tug Frozen Patterns fronl Corpora Using CostCh'iterla.
", IPSJ "\['rans.
Vol.34, No.9,pp.1937-19,13, 1993.
(inJapanese)\[7\] Brill, E.,: "A Simple I/.ule-Based Part of Speech Tagger,"Proceedings of the Third Conference on Applied Nal.m'alLanguage Processing, 1992.\[8\] Brill, E., "Aut.omatic Grammar Induction and ParsingFree Text: Transformation-Based Error-l)riven Parsing,"ACt93, 1993.\[9\] Ralph Grishman, Catherine Maeleod and Jolm Sterling"Evaluating Parsing Strategies Using Standardized ParseFiles," Proceedings of the Ttfird Conference on Applied Nat-m'al Language Processing, pp.156-161,1992.572Method segmentation error rate'rest Set (Full) 7.8% 2.8%Test Set (Sub)Morpheme Adjuster 5,1% 1.5%(Morphological Analyzer) (<3%) (3.4%)Training Set(close test)Morpheme Adjuster 0,2% 1.5%(1Viorphologieal Analyzer) (1.3%) (3.7%)Table 2: From Unification-B~sed Cranmmr to ADDMethod segmentatioli error rate l)art-of-speeeh error i:ateTest Set (l?ull) 8,2% 6.9%Test Set, (Sub)Morpheme Adjuster 4.2% 3.1%(Morl)hologieal Analyzer) (8,5%) (6.8%)Training Set (close test)Morpheme Adjuster 0.5% 3.3%(Morphological Analyzer) (0.5%) (6.3%)Imrt-ol'speech error rate '\]?~al10.
(3%6,6%(9.7%)1.7%(5.0%)Totalt5.t%7.3%(lr,.3%)3.8%0~.~_ ,)_Tabh.'
3: l;'rom ADD to Unification-I\]ased (\]ramruarAppend ixA .The  Ru le  Ext rac t ion  A lgor i thmtype~ord = recordsymbol :string; {ex.
"~"}part-of-speech :string; {ex.
"NOUN"}endwordlist = recordelem : array\[I..MAXLENGTI\[\] of wordlast : integerendprocedure FIND_CDRRESPONDENCES (h ,B : uordlist) ;{The arguments of this procedure aretwo kinds of morphological informationof the same sentence .For example :h : (~,  vstem)(~ vinfl)(~ auxv-stem) ( I~ auxv-infl)(7"< auxv-t ense)( / c  li)lg#Jil"\] )The OUTptrr subroutine outputs the correspon-dences such as:Because the total "LENGTHs" of two argumentsare the same, this algorit}bm is guaranteed tohe completed normally.
}vatlhs,rhs : wor(11ist ;cur a, cur_}): integer; {cursors}begincur_a := l; cur_b := J;\]hs.last := I; rhs.last := 1; {Initialize}lhs.
elem \[lhs.
hast\] : = A. s\]em \[cur a\] ;lhs.last := lhs.last+l;rhs.elem\[rhs.last\] :: B.elem\[cur b\];rhs.last := rhs.last+l;while ( A.last > ctrr a ) do beginif LENGTII(Ihs) = LEN(;TH(rhs) then beginOUTPUT(Ihs, rhs);cur_a := cm' a+i; cur b := cur b+t;Initialize (lhs, rhs) ;lhs.elemElhs.last\] := A.elem\[cur_a\];lhs.last := lhs.last+1;rhs.elem\[rhs.last\] := B.elem\[cur_b\];rhs.\].ast := rhs.last4.1;endelse if LENGTH(Ihs) > LENGTH(rhs) then beg:cur b := cur b+l;rhs.elem\[rhs.last\] := B.elem\[cur_b\];rhs.last := rhs.last+l;endelse beginc%hr a : = cur a+l ;lhs.elem\[lhs.last\] := A.elem\[cur a\];\],hs,last := lhs.last+l;endend ;function LENGTH(A: uordlJst);{This function returns the total length ofword\]ist.
When dm arg is "((~)g~ vstem)(O vinfl))",this function returns 3.
}v~rlength, count : integer;beginlength = O;:\[or count := 1 to h.last dolength := length+lA.elem\[count\].symboll;re turn  length;end573
