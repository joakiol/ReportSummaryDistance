Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1255?1263,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsAn Unsupervised Probability Model for Speech-to-Translation Alignment ofLow-Resource LanguagesAntonios Anastasopoulos and David ChiangUniversity of Notre Dame{aanastas, dchiang}@nd.eduLong DuongUniversity of Melbournelduong@student.unimelb.edu.auAbstractFor many low-resource languages, spoken lan-guage resources are more likely to be an-notated with translations than with transcrip-tions.
Translated speech data is potentiallyvaluable for documenting endangered lan-guages or for training speech translation sys-tems.
A first step towards making use of suchdata would be to automatically align spokenwords with their translations.
We present amodel that combines Dyer et al?s reparam-eterization of IBM Model 2 (fast_align)and k-means clustering using Dynamic TimeWarping as a distance measure.
The two com-ponents are trained jointly using expectation-maximization.
In an extremely low-resourcescenario, our model performs significantlybetter than both a neural model and a strongbaseline.1 IntroductionFor many low-resource languages, speech data iseasier to obtain than textual data.
And becausespeech transcription is a costly and slow process,speech is more likely to be annotated with transla-tions than with transcriptions.
This translated speechis a potentially valuable source of information ?
forexample, for documenting endangered languages orfor training speech translation systems.In language documentation, data is usable only ifit is interpretable.
To make a collection of speechdata usable for future studies of the language, some-thing resembling interlinear glossed text (transcrip-tion, morphological analysis, word glosses, freetranslation) would be needed at minimum.
Newtechnologies are being developed to facilitate col-lection of translations (Bird et al, 2014), and therealready exist recent examples of parallel speechcollection efforts focused on endangered languages(Blachon et al, 2016; Adda et al, 2016).
As for theother annotation layers, one might hope that a firstpass could be done automatically.
A first step to-wards this goal would be to automatically align spo-ken words with their translations, capturing informa-tion similar to that captured by word glosses.In machine translation, statistical models have tra-ditionally required alignments between the sourceand target languages as the first step of training.Therefore, producing alignments between speechand text would be a natural first step towards MTsystems operating directly on speech.We present a model that, in order to learn suchalignments, adapts and combines two components:Dyer et al?s reparameterization of IBM Model 2(Dyer et al, 2013), more commonly known asfast_align, and k-means clustering using Dy-namic Time Warping (Berndt and Clifford, 1994) asa distance measure.
The two components are trainedjointly using expectation-maximization.We experiment on two language pairs.
One isSpanish-English, using the CALLHOME and Fishercorpora.
The other is Griko-Italian; Griko is anendangered language for which we created (andmake freely available)1 gold-standard translationsand word alignments (Lekakou et al, 2013).
In allcases, our model outperforms both a naive but strongbaseline and a neural model (Duong et al, 2016).1https://www3.nd.edu/?aanastas/griko/griko-data.tar.gz12552 BackgroundIn this section, we briefly describe the existing mod-els that the two components of our model are basedon.
In the next section, we will describe how weadapt and combine them to the present task.2.1 IBM Model 2 and fast_alignThe IBM translation models (Brown et al, 1993)aim to model the distribution p(e | f) for an En-glish sentence e = e1 ?
?
?
el, given a French sentencef = f1 ?
?
?
em.
They all introduce a hidden variablea = a1 ?
?
?
al that gives the position of the Frenchword to which each English word is aligned.The general form of IBM Models 1, 2 andfast_align isp(e, a | f) = p(l)l?i=1t(ei | fai) ?
(ai | i, l,m)where t(e | f ) is the probability of translating Frenchword f to English word e, and ?
(ai = j | i, l,m) isthe probability of aligning the i-th English word withthe j-th French word.In Model 1, ?
is uniform; in Model 2, it isa categorical distribution.
Dyer et al (2013) pro-pose a reparameterization of Model 2, known asfast_align:h(i, j, l,m) = ?????
?il ?jm??????
(ai | i, l,m) =??????
?p0 ai = 0(1 ?
p0) exp ?h(i,ai,l,m)Z?
(i,l,m) ai > 0where the null alignment probability p0 and preci-sion ?
?
0 are hyperparameters optimized by gridsearch.
As ?
?
0, the distribution gets closer to thedistribution of IBM Model 1, and as ?
gets larger,the model prefers monotone word alignments morestrongly.2.2 DTW and DBADynamic Time Warping (DTW) (Berndt and Clif-ford, 1994) is a dynamic programming methodfor measuring distance between two temporal se-quences of variable length, as well as computingan alignment based on this distance.
Given two se-quences ?, ??
of length m and m?
respectively, DTWconstructs an m?m?
matrix w. The warping path canbe found by evaluating the following recurrence:wi, j = d(?i, ?
?j) + min{wi?1, j,wi?1, j?1,wi, j?1}where d is a distance measure.
In this paper, we nor-malize the cost of the warping path:DTW(?, ??)
= wm,m?m + m?which lies between zero and one.DTW Barycenter Averaging (DBA) (Petitjean etal., 2011) is an iterative approximate method that at-tempts to find a centroid of a set of sequences, min-imizing the sum of squared DTW distances.In the original definition, given a set of sequences,DBA chooses one sequence randomly to be a ?skele-ton.?
Then, at each iteration, DBA computes theDTW between the skeleton and every sequence inthe set, aligning each of the skeleton?s points withpoints in all the sequences.
The skeleton is then re-fined using the found alignments, by updating eachframe in the skeleton to the mean of all the framesaligned to it.
In our implementation, in order to avoidpicking a skeleton that is too short or too long, werandomly choose one of the sequences with medianlength.3 ModelWe use a generative model from a source-languagespeech segment consisting of feature frames ?
=?1 ?
?
?
?m to a target-language segment consisting ofwords e = e1 .
.
.
el.
We chose to model p(e | ?
)rather than p(?
| e) because it makes it easier to in-corporate DTW.
The other direction is also possible,and we plan to explore it in future work.In addition to the target-language sentence e,our model hypothesizes a sequence f = f1 ?
?
?
flof source-language clusters (intuitively, source-language words), and spans (ai, bi) of the source sig-nal that each target word ei is aligned to.
Thus, theclusters f = f1 ?
?
?
fl and the spans a = a1, .
.
.
, al andb = b1, .
.
.
, bl are the hidden variables of the model:p(e | ?)
=?a,b,fp(e, a,b, f | ?
).The model generates e, a,b, and f from ?
as fol-lows.12561.
Choose l, the number of target words, with uni-form probability.
(Technically, this assumes amaximum target sentence length, which we canjust set to be very high.)2.
For each target word position i = 1, .
.
.
, l:(a) Choose a cluster fi.
(b) Choose a span of source frames (ai, bi) forei to be aligned to.
(c) Generate a target word ei from fi.Accordingly, we decompose p(e, a,b, f | ?)
into sev-eral submodels:p(e, a,b, f | ?)
= p(l)l?i=1u( fi) ?s(ai, bi | fi,?)
??
(ai, bi | i, l, |?|) ?t(ei | fi).Note that submodels ?
and s both generate spans(corresponding to step 2b), making the model de-ficient.
We could make the model sum to one byreplacing u( fi)s(ai, bi | fi,?)
with s( fi | ai, bi,?
),and this was in fact our original idea, but the modelas defined above works much better, as discussed inSection 7.4.
We describe both ?
and s in detail be-low.Clustering model The probability over clusters,u( f ), is just a categorical distribution.
The submodels assumes that, for each cluster f , there is a ?pro-totype?
signal ?
f (cf.
Ristad and Yianilos, 1998).Technically, the ?
f are parameters of the model, andwill be recomputed during the M step.
Then we candefine:s(a, b | f ,?)
= exp(?DTW(?f , ?a ?
?
?
?b)2)?ma,b=1 exp(?DTW(?
f , ?a ?
?
?
?b)2)where DTW is the distance between the prototypeand the segment computed using Dynamic TimeWarping.
Thus s assigns highest probability to spansof ?
that are most similar to the prototype ?
f .Distortion model The submodel ?
controls the re-ordering of the target words relative to the sourceframes.
It is an adaptation of fast_align to ourFigure 1: Sample distributions for the alignment variables aand b for m = 100, l = 5, p0 = 0, ?
= 0.5, and ?
= 20.setting, where there is not a single source word po-sition ai, but a span (ai, bi).
We want the model toprefer the middle of the word to be close to the di-agonal, so we need the variable a to be somewhat tothe left and b to be somewhat to the right.
Therefore,we introduce an additional hyperparameter ?
whichis intuitively the number of frames in a word.
Thenwe defineha(i, j, l,m, ?)
= ?????
?il ?jm ?
?????
?hb(i, j, l,m, ?)
= ?????
?il ?j ?
?m ?
??????
?a(ai | i, l,m) =??????
?p0 ai = 0(1 ?
p0) exp ?ha(i,ai,l,m)Z?
(i,l,m) ai > 0?b(bi | i, l,m) =??????
?p0 bi = 0(1 ?
p0) exp ?hb(i,bi,l,m)Z?
(i,l,m) bi > 0?
(ai, bi | i, l,m) = ?a(ai | i, l,m) ?b(bi | i, l,m)where the Z?
(i, l,m) are set so that all distributionssum to one.
Figure 1 shows an example visualisationof the the resulting distributions for the two variablesof our model.We set ?
differently for each word.
For each i, weset ?i to be proportional to the number of charactersin ei, such that ?i ?i = m.Translation model The translation model t(e | f )is just a categorical distribution, in principle allow-ing a many-to-many relation between source clustersand target words.
To speed up training (with nearlyno change in accuracy, in our experiments), we re-strict this relation so that there are k source clustersfor each target word, and a source cluster uniquelydetermines its target word.
Thus, t(e | f ) is fixed to1257either zero or one, and does not need to be reesti-mated.
In our experiments, we set k = 2, allowingeach target word to have up to two source-languagetranslations/pronunciations.
(If a source word hasmore than one target translation, they are treated asdistinct clusters with distinct prototypes.
)4 TrainingWe use the hard (Viterbi) version of the Expectation-Maximization (EM) algorithm to estimate the pa-rameters of our model, because calculating expectedcounts in full EM would be prohibitively expensive,requiring summations over all possible alignments.Recall that the hidden variables of the model arethe alignments (ai, bi) and the source words ( fi).
Theparameters are the translation probabilities t(ei | f )and the prototypes (?
f ).
The (hard) E step uses thecurrent model and prototypes to find, for each targetword, the best source segment to align it to and thebest source word.
The M step reestimates the prob-abilities t(e | f ) and the prototypes ?
f .
We describeeach of these steps in more detail below.Initialization Initialization is especially importantsince we are using hard EM.To initialize the parameters, we initialize the hid-den variables and then perform an M step.
We as-sociate each target word type e with k = 2 sourceclusters, and for each occurrence of e, we randomlyassign it one of the k source clusters.The alignment variables ai, bi are initialized toai, bi = arg maxa,b?
(a, b | i, l,m).M step The M step reestimates the probabilitiest(e | f ) using relative-frequency estimation.The prototypes ?
f are more complicated.
Theo-retically, the M step should recompute each ?
f soas to maximize that part of the log-likelihood thatdepends on ?
f :L?
f =??
?i| fi= flog s(ai, bi | f ,?)=??
?i| fi= flog exp(?DTW(?f , ?ai ?
?
?
?bi)2)Z( f ,?)=??
?i| fi= f?DTW(?
f , ?ai ?
?
?
?bi)2 ?
log Z( f ,?
)where the summation over ?
is over all source sig-nals in the training data.
This is a hard problem, butnote that the first term is just the sum-of-squares ofthe DTW distance between ?
f and all source seg-ments that are classified as f .
This is what DBA issupposed to approximately minimize, so we simplyset ?
f using DBA, ignoring the denominator.E step The (hard) E step uses the current modeland prototypes to find, for each target word, the bestsource segment to align it to and the best source clus-ter.In order to reduce the search space for a and b,we use the unsupervised phonetic boundary detec-tion method of Khanagha et al (2014).
This methodoperates directly on the speech signal and providesus with candidate phone boundaries, on which werestrict the possible values for a and b, creating alist of candidate utterance spans.Furthermore, we use a simple silence detectionmethod.
We pass the envelope of the signal througha low-pass filter, and then mark as ?silence?
timespans of 50ms or longer in which the magnitude isbelow a threshold of 5% relative to the maximumof the whole signal.
This method is able to detectabout 80% of the total pauses, with a 90% precisionin a 50ms window around the correct silence bound-ary.
We can then remove from the candidate list theutterance spans that include silence, on the assump-tion that a word should not include silences.
Finally,in case one of the span?s boundaries happens to bewithin a silence span, we also move it so as to notinclude the silence.Hyperparameter tuning The hyperparametersp0, ?, and ?
are not learned.
We simply set p0 tozero (disallowing unaligned target words) and set ?as described above.For ?we perform a grid search over candidate val-ues to maximize the alignment F-score on the devel-opment set.
We obtain the best scores with ?
= 0.5.5 Related WorkA first step towards modelling parallel speech can beperformed by modelling phone-to-word alignment,instead of directly working on continuous speech.For example, Stahlberg et al (2012) extend IBMModel 3 to align phones to words in order to build1258cross-lingual pronunciation lexicons.
Pialign (Neu-big et al, 2012) aligns characters and can be ap-plied equally well to phones.
Duong et al (2016)use an extension of the neural attentional model ofBahdanau et al (2015) for aligning phones to wordsand speech to words; we discuss this model below inSection 6.2.There exist several supervised approaches that at-tempt to integrate speech recognition and machinetranslation.
However, they rely heavily on the abun-dance of training data, pronunciation lexicons, orlanguage models, and therefore cannot be applied ina low- or zero-resource setting.A task somewhat similar to ours, which operatesat a monolingual level, is the task of zero-resourcespoken term discovery, which aims to discover re-peated words or phrases in continuous speech.
Vari-ous approaches (Ten Bosch and Cranen, 2007; Parkand Glass, 2008; Muscariello et al, 2009; Zhang andGlass, 2010; Jansen et al, 2010) have been tried,in order to spot keywords, using segmental DTW toidentify repeated trajectories in the speech signal.Kamper et al (2016) try to discover word segmen-tation and a pronunciation lexicon in a zero-resourcesetting, combining DTW with acoustic embeddings;their methods operate in a very low-vocabulary set-ting.
Bansal (2015) attempts to build a speech trans-lation system in a low-resource setting, by using assource input the simulated output of an unsupervisedterm discovery system.6 ExperimentsWe evaluate our method on two language pairs,Spanish-English and Griko-Italian, against twobaseline methods, a naive baseline, and the modelof Duong et al (2016).6.1 DataFor each language pair, we require a sentence-aligned parallel corpus of source-language speechand target-language text.
A subset of these sentencesshould be annotated with span-to-word alignmentsfor use as a gold standard.6.1.1 Spanish-EnglishFor Spanish-English, we use the Spanish CALL-HOME corpus (LDC96S35) and the Fisher corpus(LDC2010T04), which consist of telephone conver-sations between Spanish native speakers based in theUS and their relatives abroad, together with Englishtranslations produced by Post et al (2013).
Span-ish is obviously not a low-resource language, but wepretend that it is low-resource by not making useof any Spanish ASR or resources like transcribedspeech or pronunciation lexicons.Since there do not exist gold standard alignmentsbetween the Spanish speech and English words, weuse the ?silver?
standard alignments produced byDuong et al (2016) for the CALLHOME corpus,and followed the same procedure for the Fisher cor-pus as well.
In order to obtain them, they first used aforced aligner to align the speech to its transcription,and GIZA++ with the gdfa symmetrization heuris-tic to align the Spanish transcription to the Englishtranslation.
They then combined the two alignmentsto produce ?silver?
standard alignments between theSpanish speech and the English words.The CALLHOME dataset consists of 17532Spanish utterances, based on the dialogue turns.
Wefirst use a sample of 2000 sentences, out of whichwe use 200 as a development set and the rest as atest set.
We also run our experiments on the wholedataset, selecting 500 utterances for a developmentset, using the rest as a test set.
The Fisher datasetconsists of 143355 Spanish utterances.
We use 1000of them as a development set and the rest as a testset.6.1.2 Griko-ItalianWe also run our model on a corpus that consists ofabout 20 minutes of speech in Griko, an endangeredminority dialect of Greek spoken in south Italy,along with text translations into Italian (Lekakouet al, 2013).2 The corpus consists of 330 mostlyprompted utterances by nine native speakers.
Al-though the corpus is very small, we use it to show-case the effectiveness of our method in a hard settingwith extremely low resources.All utterances were manually annotated and tran-scribed by a trained linguist and bilingual speakerof both languages, who produced the Griko tran-scriptions and Italian glosses.
We created full trans-lations into Italian and manually aligned the transla-tions with the Griko transcriptions.
We then com-2http://griko.project.uoi.gr1259bined the two alignments (speech-to-transcriptionand transcription-to-translation) to produce speech-to-translation alignments.
Therefore, our compar-ison is done against an accurate ?gold?
standardalignment.
We split the data into a development setof just 30 instances, and a test set of the remain-ing 300 instances.6.1.3 PreprocessingIn both data settings, we treat the speech data as asequence of 39-dimensional Perceptual Linear Pre-diction (PLP) vectors encoding the power spectrumof the speech signal (Hermansky, 1990), computedat 10ms intervals.
We also normalize the features atthe utterance level, shifting and scaling them to havezero mean and unit variance.6.2 BaselinesOur naive baseline assumes that there is no reorder-ing between the source and target language, andaligns each target word ei to a source span whoselength in frames is proportional to the length of ei incharacters.
This actually performs very well on lan-guage pairs that show minimal or no reordering, andlanguage pairs that have shared or related vocabular-ies.The other baseline that we compare against isthe neural network attentional model of Duong etal.
(2016), which extends the attentional model ofBahdanau et al (2015) to be used for aligning andtranslating speech, and, along with several modifi-cations, achieve good results on the phone-to-wordalignment task, and almost match the baseline per-formance on the speech-to-word alignment task.7 ResultsTo evaluate an automatic alignment between thespeech and its translation against the gold/silverstandard alignment, we compute alignment preci-sion, recall, and F-score as usual, but on links be-tween source-language frames and target-languagewords.7.1 OverviewTable 1 shows the precision, recall, and balanced F-score of the three models on the Spanish-EnglishCALLHOME corpus (both the 2000-sentence subsetmethod precision recall F-scoreCALLHOMEspa-eng2ksentsours 38.8 38.9 38.8naive 31.9 40.8 35.8neural 23.8 29.8 26.417ksentsours 38.4 38.8 38.6naive 31.8 40.7 35.7neural 26.1 32.9 29.1Fisherspa-eng 143ksentsours 33.3 28.7 30.8naive 24.0 33.2 27.8gri-ita 300sentsours 56.6 51.2 53.8naive 42.2 52.2 46.7neural 24.6 30.0 27.0Table 1: Our model achieves higher precision and F-score thanboth the naive baseline and the neural model on all datasets.and the full set), the Spanish-English Fisher corpus,and the Griko-Italian corpus.In all cases, our model outperforms both thenaive baseline and the neural attentional model.
Ourmodel, when compared to the baselines, improvesgreatly on precision, while slightly underperformingthe naive baseline on recall.
In certain applications,higher precision may be desirable: for example, inlanguage documentation, it?s probably better to erron the side of precision; in phrase-based translation,higher-precision alignments lead to more extractedphrases.The rest of the section provides a further anal-ysis of the results, focusing on the extremely low-resource Griko-Italian dataset.7.2 Speaker robustnessFigure 2 shows the alignments produced by ourmodel for three utterances of the same sentence fromthe Griko-Italian dataset by three different speak-ers.
Our model?s performance is roughly consistentacross these utterances.
In general, the model doesnot seem significantly affected by speaker-specificvariations, as shown in Table 2.We do find, however, that the performance onmale speakers is slightly higher compared to thefemale speakers.
This might be because the fe-male speakers?
utterances are, on average, longer byabout 2 words than the ones uttered by males.1260Male 1: F-scoredevo comprare il pane ogni giornoModel: 54.3devo comprareil pane ogni giornoWoman 2: F-scoredevo comprare il pane ogni giornoModel: 62.1devocomprareil pane ogni giornoMale 4: F-scoredevo comprare il pane ogni ogni giornoModel: 70.9devo comprareil pane ogni ogni giornoFigure 2: Alignments produced for the Italian sentence devo comprare il pane ogni giorno as uttered by three differentGriko speakers.speaker utt len F-scorefemale 1 55 9.0 49.4female 2 61 8.1 55.0female 3 41 9.6 51.0female 4 23 7.3 54.4female 5 21 6.1 56.6male 1 35 5.9 59.5male 2 32 6.0 61.9male 3 34 6.7 60.2male 4 23 6.4 64.0Table 2: Model performance (F-score) is generally consistentacross speakers.
The second column (utt) shows the number ofutterances per speaker; the third (len), their average length inwords.7.3 Word level analysisWe also compute F-scores for each Italian wordtype.
As shown in Figure 3, the longer the word?sutterance, the easier it is for our model to correctlyalign it.
Longer utterances seem to carry enough in-formation for our DTW-based measure to functionproperly.
On the other hand, shorter utterances areharder to align.
The vast majority of Griko utter-ances that have less than 20 frames and are less ac-curately aligned correspond to monosyllabic deter-miners (o, i,a, to, ta) or conjunctions and preposi-tions (ka, ce, en, na, an).
For such short utterances,there could be several parts of the signal that possi-bly match the prototype, leading the clustering com-ponent to prefer to align to wrong spans.Furthermore, we note that rare word types tend tobe correctly aligned.
The average F-score for hapaxlegomena (on the Italian side) is 63.2, with 53% ofthem being aligned with an F-score higher than 70.0.7.4 Comparison with proper modelAs mentioned in Section 3, our model is deficient,but it performs much better than the model thatsums to one (henceforth, the ?proper?
model): Inthe Spanish-English dataset (2000 sentences sam-ple) the proper model yields an F-score of 32.1, per-forming worse than the naive baseline; in the Griko-1261Griko: ?`cha na afora`so to tsom?`Gold: F-scoredovevo comprare il paneOurs: 82.3dovevo comprare il paneProper: 61.7dovevo comprare il paneAttention: 38.3dovevo comprareil paneFigure 4: The deficient model performs very well, whereasthe proper and the attentional model prefer extreme alignmentspans.
For example, the proper model?s alignment for the wordsdovevo and pane are much too short.Griko: e` Vale`ria meleta` o` giorna`liGold: F-scoreValeria legge il giornaleOurs: 67.8Valeria legge il giornaleProper: 75.2Valeria legge ilgiornaleAttention: 6.0il legge il giornale Valeria giornaleFigure 5: One of the rare examples where the proper modelperforms better than the deficient one.
The hapax legomenaValeria and giornali are not properly handled by the at-tentional model.0 20 40 60 80 100 1200.20.40.60.8word length (frames)averageF-scoreFigure 3: There is a positive correlation between average word-level F-score and average word utterance length (in frames).Italian dataset, it achieves an F-score of 44.3, whichis better than the baselines, but still worse than ourmodel.In order to further examine why this happens, weperformed three EM iterations on the Griko-Italiandataset with our model (in our experience, three it-erations are usually enough for convergence), andthen computed one more E step with both our modeland the proper model, so as to ensure that the twomodels would align the dataset using the exact sameprototypes and that their outputs will be comparable.In this case, the proper model achieved an over-all F-score of 44.0, whereas our model achieved anF-score of 53.6.
Figures 4 and 5 show the resultingalignments for two sentences.
In both of these exam-ples, it is clear that the proper model prefers extremespans: the selected spans are either much too short or(less frequently) much too long.
This is further ver-ified by examining the statistics of the alignments:the average span selected by the proper model hasa length of about 30 ?
39 frames whereas the aver-age span of the alignments produced by our deficientmodel is 37 ?
24 frames.
This means that the align-ments of the deficient model are much closer to thegold ones, whose average span is 42 ?
26 frames.We think that this is analogous to the ?garbagecollection?
problem in word alignment.
In the IBMword alignment models, if a source word f occursin only one sentence, then EM can align many tar-get words to f and learn a very peaked distributiont(e | f ).
This can happen in our model and the propermodel as well, of course, since IBM Model 2 isembedded in them.
But in the proper model, some-thing similar can also happen with s( f | a, b): EMcan make the span (a, b) large or small, and evi-dently making the span small allows it to learn avery peaked distribution s( f | a, b).
By contrast, ourmodel has s(a, b | f ), which seems less susceptibleto this kind of effect.8 ConclusionAlignment of speech to text translations is a rela-tively new task, one with particular relevance forlow-resource or endangered languages.
The modelwe propose here, which combines fast_align andk-means clustering using DTW and DBA, outper-forms both a very strong naive baseline and a neuralattentional model, on three tasks of various sizes.The language pairs used here do not have verymuch word reordering, and more divergent language1262pairs should prove more challenging.
In that case,the naive baseline should be much less competitive.Similarly, the fast_align-based distortion modelmay become less appopriate; we plan to try incorpo-rating IBM Model 3 or the HMM alignment model(Vogel et al, 1996) instead.
Finally, we will in-vestigate downstream applications of our alignmentmethods, in the areas of both language documenta-tion and speech translation.AcknowledgementsWe would like to thank Steven Bird, Eamonn Keogh,and the anonymous reviewers for their helpful feed-back.
This research was supported in part by NSFAward 1464553.ReferencesGilles Adda, Sebastian Stu?ker, Martine Adda-Decker,Odette Ambouroue, Laurent Besacier, David Bla-chon, He?le`ne Bonneau-Maynard, Pierre Godard, Fa-tima Hamlaoui, Dmitry Idiatov, et al 2016.
Break-ing the unwritten language barrier: The BULB project.Procedia Computer Science, 81:8?14.Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-gio.
2015.
Neural machine translation by jointlylearning to align and translate.
In Proc.
ICLR.Sameer Bansal.
2015.
Speech translation without speechrecognition.
Master?s thesis, University of Edinburgh.Donald J. Berndt and James Clifford.
1994.
Using dy-namic time warping to find patterns in time series.
InProc.
KDD, pages 359?370.Steven Bird, Lauren Gawne, Katie Gelbart, and IsaacMcAlister.
2014.
Collecting bilingual audio in remoteindigenous communities.
In Proc.
COLING.David Blachon, Elodie Gauthier, Laurent Besacier, Guy-Noe?l Kouarata, Martine Adda-Decker, and Annie Ri-alland.
2016.
Parallel speech collection for under-resourced language studies using the Lig-Aikuma mo-bile device app.
Procedia Computer Science, 81:61?66.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: Parameter esti-mation.
Computational Linguistics, 19(2):263?311.Long Duong, Antonios Anastasopoulos, David Chiang,Steven Bird, and Trevor Cohn.
2016.
An attentionalmodel for speech translation without transcription.
InProc.
NAACL HLT, pages 949?959, June.Chris Dyer, Victor Chahuneau, and Noah A. Smith.2013.
A simple, fast, and effective reparameterizationof IBM Model 2.
In Proc.
NAACL HLT.Hynek Hermansky.
1990.
Perceptual linear predictive(PLP) analysis of speech.
J. Acoustical Society ofAmerica, 87(4):1738?1752.Aren Jansen, Kenneth Church, and Hynek Hermansky.2010.
Towards spoken term discovery at scale withzero resources.
In Proc.
INTERSPEECH, pages 1676?1679.Herman Kamper, Aren Jansen, and Sharon Goldwater.2016.
Unsupervised word segmentation and lexicondiscovery using acoustic word embeddings.
IEEETrans.
Audio, Speech, and Language Processing.Vahid Khanagha, Khalid Daoudi, Oriol Pont, and Hus-sein Yahia.
2014.
Phonetic segmentation of speechsignal using local singularity analysis.
Digital SignalProcessing.Marika Lekakou, Valeria Baldiserra, and Antonis Anasta-sopoulos.
2013.
Documentation and analysis of an en-dangered language: aspects of the grammar of Griko.Armando Muscariello, Guillaume Gravier, and Fre?de?ricBimbot.
2009.
Audio keyword extraction by unsuper-vised word discovery.
In Proc.
INTERSPEECH.Graham Neubig, Taro Watanabe, Shinsuke Mori, and Tat-suya Kawahara.
2012.
Machine translation withoutwords through substring alignment.
In Proc.
ACL.Alex S. Park and James R. Glass.
2008.
Unsuper-vised pattern discovery in speech.
IEEE Trans.
Audio,Speech, and Language Processing, 16(1):186?197.Franc?ois Petitjean, Alain Ketterlin, and Pierre Ganc?arski.2011.
A global averaging method for dynamic timewarping, with applications to clustering.
PatternRecognition, 44(3):678?693.Matt Post, Gaurav Kumar, Adam Lopez, DamianosKarakos, Chris Callison-Burch, and Sanjeev Khu-danpur.
2013.
Improved speech-to-text translationwith the Fisher and Callhome Spanish?English speechtranslation corpus.
In Proc.
IWSLT.Eric Sven Ristad and Peter N Yianilos.
1998.
Learn-ing string-edit distance.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 20(5):522?532.Felix Stahlberg, Tim Schlippe, Sue Vogel, and TanjaSchultz.
2012.
Word segmentation through cross-lingual word-to-phoneme alignment.
In Proc.
IEEESpoken Language Technology Workshop (SLT).Louis Ten Bosch and Bert Cranen.
2007.
A compu-tational model for unsupervised word discovery.
InProc.
INTERSPEECH, pages 1481?1484.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statistical trans-lation.
In Proc.
COLING, pages 836?841.Yaodong Zhang and James R Glass.
2010.
Towardsmulti-speaker unsupervised speech pattern discovery.In Proc.
ICASSP, pages 4366?4369.1263
