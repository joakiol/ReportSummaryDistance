Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 977?984,Sydney, July 2006. c?2006 Association for Computational LinguisticsEmpirical Lower Bounds on the Complexity of Translational Equivalence ?Benjamin WellingtonComputer Science Dept.New York UniversityNew York, NY 10003{lastname}@cs.nyu.eduSonjia WaxmonskyComputer Science Dept.University of Chicago?Chicago, IL, 60637wax@cs.uchicago.eduI.
Dan MelamedComputer Science Dept.New York UniversityNew York, NY, 10003{lastname}@cs.nyu.eduAbstractThis paper describes a study of the pat-terns of translational equivalence exhib-ited by a variety of bitexts.
The studyfound that the complexity of these pat-terns in every bitext was higher than sug-gested in the literature.
These findingsshed new light on why ?syntactic?
con-straints have not helped to improve statis-tical translation models, including finite-state phrase-based models, tree-to-stringmodels, and tree-to-tree models.
Thepaper also presents evidence that inver-sion transduction grammars cannot gen-erate some translational equivalence rela-tions, even in relatively simple real bi-texts in syntactically similar languageswith rigid word order.
Instructionsfor replicating our experiments are athttp://nlp.cs.nyu.edu/GenPar/ACL061 IntroductionTranslational equivalence is a mathematical rela-tion that holds between linguistic expressions withthe same meaning.
The most common explicit rep-resentations of this relation are word alignmentsbetween sentences that are translations of eachother.
The complexity of a given word alignmentcan be measured by the difficulty of decomposingit into its atomic units under certain constraints de-tailed in Section 2.
This paper describes a studyof the distribution of alignment complexity in avariety of bitexts.
The study considered wordalignments both in isolation and in combinationwith independently generated parse trees for oneor both sentences in each pair.
Thus, the study?
Thanks to David Chiang, Liang Huang, the anonymousreviewers, and members of the NYU Proteus Project for help-ful feedback.
This research was supported by NSF grant #?s0238406 and 0415933.?
SW made most of her contribution while at NYU.is relevant to finite-state phrase-based models thatuse no parse trees (Koehn et al, 2003), tree-to-string models that rely on one parse tree (Yamadaand Knight, 2001), and tree-to-tree models thatrely on two parse trees (Groves et al, 2004, e.g.
).The word alignments that are the least complexon our measure coincide with those that can begenerated by an inversion transduction grammar(ITG).
Following Wu (1997), the prevailing opin-ion in the research community has been that morecomplex patterns of word alignment in real bitextsare mostly attributable to alignment errors.
How-ever, the experiments in Section 3 show that morecomplex patterns occur surprisingly often even inhighly reliable alignments in relatively simple bi-texts.
As discussed in Section 4, these findingsshed new light on why ?syntactic?
constraints havenot yet helped to improve the accuracy of statisti-cal machine translation.Our study used two kinds of data, each con-trolling a different confounding variable.
First,we wanted to study alignments that contained asfew errors as possible.
So unlike some other stud-ies (Zens and Ney, 2003; Zhang et al, 2006), weused manually annotated alignments instead of au-tomatically generated ones.
The results of our ex-periments on these data will remain relevant re-gardless of improvements in technology for auto-matic word alignment.Second, we wanted to measure how much ofthe complexity is not attributable to systematictranslation divergences, both in the languages asa whole (SVO vs. SOV), and in specific construc-tions (English not vs. French ne.
.
.
pas).
To elim-inate this source of complexity of translationalequivalence, we used English/English bitexts.
Weare not aware of any previous studies of wordalignments in monolingual bitexts.Even manually annotated word alignments varyin their reliability.
For example, annotators some-times link many words in one sentence to many977(a) that,Ibelieveweallfindunacceptable,regardlessofpoliticalparty,jepenseque,independammentdenotreparti,noustrouvonstouscelainacceptable(b)(Y / Y,Y) ?
?> (D C / D,C)*(S / S) ?
?> (X A  / X A X) (X / X,X) ?
?> (Y B / B Y,Y)X A Y B A D C B ABDACYAYBXAXSSbelievepartypenseunaccthatcelaparti inaccFigure 1: (a) Part of a word alignment.
(b) Derivation of this word alignment using only binary and nullary productionsrequires one gap per nonterminal, indicated by commas in the production rules.words in the other, instead of making the effort totease apart more fine-grained distinctions.
A studyof such word alignments might say more aboutthe annotation process than about the translationalequivalence relation in the data.
The inevitablenoise in the data motivated us to focus on lowerbounds, complementary to Fox (2002), who wrotethat her results ?should be looked on as more of anupper bound.?
(p. 307) As explained in Section 3,we modified all unreliable alignments so that theycannot increase the complexity measure.
Thus, wearrived at complexity measurements that were un-derestimates, but reliably so.
It is almost certainthat the true complexity of translational equiva-lence is higher than what we report.2 A Measure of Alignment ComplexityAny translation model can memorize a trainingsentence pair as a unit.
For example, given a sen-tence pair like (he left slowly / slowly he left) withthe correct word alignment, a phrase-based trans-lation model can add a single 3-word biphrase toits phrase table.
However, this biphrase would nothelp the model predict translations of the individ-ual words in it.
That?s why phrase-based modelstypically decompose such training examples intotheir sub-biphrases and remember them too.
De-composing the translational equivalence relationsin the training data into smaller units of knowledgecan improve a model?s ability to generalize (Zhanget al, 2006).
In the limit, to maximize the chancesof covering arbitrary new data, a model should de-compose the training data into the smallest pos-sible units, and learn from them.1 For phrase-based models, this stipulation implies phrases oflength one.
If the model is a synchronous rewrit-ing system, then it should be able to generate ev-ery training sentence pair as the yield of a binary-1Many popular models learn from larger units at the sametime, but the size of the smallest learnable unit is what?s im-portant for our purposes.branching synchronous derivation tree, where ev-ery word-to-word link is generated by a differentderivation step.
For example, a model that usesproduction rules could generate the previous ex-ample using the synchronous productions(S, S) ?
(X Y / Y X); (X, X) ?
(U V / U V);(Y, Y) ?
(slowly, slowly); (U, U) ?
(he, he);and (V, V) ?
(left, left).A problem arises when this kind of decomposi-tion is attempted for the alignment in Figure 1(a).If each link is represented by its own nonterminal,and production rules must be binary-branching,then some of the nonterminals involved in gener-ating this alignment need discontinuities, or gaps.Figure 1(b) illustrates how to generate the sen-tence pair and its word alignment in this manner.The nonterminals X and Y have one discontinuityeach.More generally, for any positive integer k, it ispossible to construct a word alignment that cannotbe generated using binary production rules whosenonterminals all have fewer than k gaps (Satta andPeserico, 2005).
Our study measured the com-plexity of a word alignment as the minimum num-ber of gaps needed to generate it under the follow-ing constraints:1.
Each step of the derivation generates no morethan two different nonterminals.2.
Each word-to-word link is generated from aseparate nonterminal.2Our measure of alignment complexity is analo-gous to what Melamed et al (2004) call ?fan-out.
?3 The least complex alignments on this mea-sure ?
those that can be generated with zero gaps?
are precisely those that can be generated by an2If we imagine that each word is generated from a sep-arate nonterminal as in GCNF (Melamed et al, 2004), thenconstraint 2 becomes a special case of constraint 1.3For grammars that generate bitexts, fan-out is equal tothe maximum number of allowed gaps plus two.978bitext # SPs min median max 95% C.I.Chinese/English 491 4 24 52 .02Romanian/English 200 2 19 76 .03Hindi/English 90 1 10 40 .04Spanish/English 199 4 23 49 .03French/English 447 2 15 29 .01Eng/Eng MTEval 5253 2 26 92 .01Eng/Eng fiction 6263 2 15 97 .01Table 1: Number of sentence pairs and mini-mum/median/maximum sentence lengths in each bitext.All failure rates reported later have a 95% confidenceinterval that is no wider than the value shown for each bitext.ITG.
For the rest of the paper, we restrict our atten-tion to binary derivations, except where explicitlynoted otherwise.To measure the number of gaps needed to gener-ate a given word alignment, we used a bottom-uphierarchical alignment algorithm to infer a binarysynchronous parse tree that was consistent withthe alignment, using as few gaps as possible.
Ahierarchical alignment algorithm is a type of syn-chronous parser where, instead of constraining in-ferences by the production rules of a grammar, theconstraints come from word alignments and possi-bly other sources (Wu, 1997; Melamed and Wang,2005).
A bottom-up hierarchical aligner beginswith word-to-word links as constituents, wheresome of the links might be to nothing (?NULL?).
Itthen repeatedly composes constituents with otherconstituents to make larger ones, trying to find aconstituent that covers the entire input.One of the important design choices in this kindof study is how to treat multiple links attached tothe same word token.
Word aligners, both hu-man and automatic, are often inconsistent aboutwhether they intend such sets of links to be dis-junctive or conjunctive.
In accordance with itsfocus on lower bounds, the present study treatedthem as disjunctive, to give the hierarchical align-ment algorithm more opportunities to use fewergaps.
This design decision is one of the main dif-ferences between our study and that of Fox (2002),who treated links to the same word conjunctively.By treating many-to-one links disjunctively, ourmeasure of complexity ignored a large class of dis-continuities.
Many types of discontinuous con-stituents exist in text independently of any trans-lation.
Simard et al (2005) give examples suchas English verb-particle constructions, and theFrench negation ne.
.
.
pas.
The disparate elementsof such constituents would usually be aligned tothe same word in a translation.
However, whenPP NPb)VS leftGeorgeFridayGeorge left on FridayVPSNPV PPleftGeorgeFridayGeorge left on Fridayonona)Figure 2: a) With a parse tree constraining the top sentence,a hierarchical alignment is possible without gaps.
b) With aparse tree constraining the bottom sentence, no such align-ment exists.our hierarchical aligner saw two words linked toone word, it ignored one of the two links.
Ourlower bounds would be higher if they accountedfor this kind of discontinuity.3 Experiments3.1 DataWe used two monolingual bitexts and fivebilingual bitexts.
The Romanian/English andHindi/English data came from Martin et al (2005).For Chinese/English and Spanish/English, weused the data from Ayan et al (2005).
TheFrench/English data were those used by Mihalceaand Pedersen (2003).
The monolingual bitext la-beled ?MTEval?
in the tables consists of multipleindependent translations from Chinese to English(LDC, 2002).
The other monolingual bitext, la-beled ?fiction,?
consists of two independent trans-lations from French to English of Jules Verne?snovel 20,000 Leagues Under the Sea, sentence-aligned by Barzilay and McKeown (2001).From the monolingual bitexts, we removed allsentence pairs where either sentence was longerthan 100 words.
Table 1 gives descriptive statis-tics for the remaining data.
The table also showsthe upper bound of the 95% confidence intervalsfor the coverage rates reported later.
The resultsof experiments on different bitexts are not directlycomparable, due to the varying genres and sen-tence lengths.3.2 Constraining Parse TreesOne of the main independent variables in our ex-periments was the number of monolingual parsetrees used to constrain the hierarchical alignments.To induce models of translational equivalence,some researchers have tried to use such trees toconstrain bilingual constituents: The span of ev-ery node in the constraining parse tree must coin-cide with the relevant monolingual span of some979crew astronautsincludedSNP VPNPVPVPSNPPPtheinare crewincludedastronautstheFigure 3: A word alignment that cannot be generated with-out gaps in a manner consistent with both parse trees.node in the bilingual derivation tree.
These ad-ditional constraints can thwart attempts at hierar-chical alignment that might have succeeded oth-erwise.
Figure 2a shows a word alignment and aparse tree that can be hierarchically aligned with-out gaps.
George and left can be composed in bothsentences into a constituent without crossing anyphrase boundaries in the tree, as can on and Fri-day.
These two constituents can then be composedto cover the entire sentence pair.
On the otherhand, if a constraining tree is applied to the othersentence as shown in Figure 2b, then the wordalignment and tree constraint conflict.
The projec-tion of the VP is discontinuous in the top sentence,so the links that it covers cannot be composed intoa constituent without gaps.
On the other hand, if agap is allowed, then the VP can compose as on Fri-day .
.
.
left in the top sentence, where the ellipsisrepresents a gap.
This VP can then compose withthe NP complete a synchronous parse tree.
Someauthors have applied constraining parse trees toboth sides of the bitext.
The example in Figure 3can be hierarchically aligned using either one ofthe two constraining trees, but gaps are necessaryto align it with both trees.3.3 MethodsWe parsed the English side of each bilingual bitextand both sides of each English/English bitext us-ing an off-the-shelf syntactic parser (Bikel, 2004),which was trained on sections 02-21 of the PennEnglish Treebank (Marcus et al, 1993).Our bilingual bitexts came with manually anno-tated word alignments.
For the monolingual bi-texts, we used an automatic word aligner basedon a cognate heuristic and a list of 282 functionwords compiled by hand.
The aligner linked twowords to each other only if neither of them was onthe function word list and their longest commonsubsequence ratio (Melamed, 1995) was at least0.75.
Words that were not linked to another wordin this manner were linked to NULL.
For the pur-poses of this study, a word aligned to NULL isa non-constraint, because it can always be com-posed without a gap with some constituent that isadjacent to it on just one side of the bitext.
Thenumber of automatically induced non-NULL linkswas lower than what would be drawn by hand.We modified the word alignments in all bi-texts to minimize the chances that alignment errorswould lead to an over-estimate of alignment com-plexity.
All of the modifications involved addinglinks to NULL.
Due to our disjunctive treatmentof conflicting links, the addition of a link to NULLcan decrease but cannot increase the complexity ofan alignment.
For example, if we added the links(cela, NULL) and (NULL, that) to the alignmentin Figure 1, the hierarchical alignment algorithmcould use them instead of the link between celaand that.
It could thus generate the modified align-ment without using a gap.
We added NULL linksin two situations.
First, if a subset of the linksin an alignment formed a many-to-many mappingbut did not form a bipartite clique (i.e.
every wordon one side linked to every word on the other side),then we added links from each of these words toNULL.
Second, if n words on one side of the bi-text aligned to m words on the other side withm > n then we added NULL links for each ofthe words on the side with m words.After modifying the alignments and obtainingmonolingual parse trees, we measured the align-ment complexity of each bitext using a hierarchi-cal alignment algorithm, as described in Section 2.Separate measurements were taken with zero, one,and two constraining parse trees.
The synchronousparser in the GenPar toolkit4 can be configured forall of these cases (Burbank et al, 2005).Unlike Fox (2002) and Galley et al (2004), wemeasured failure rates per corpus rather than persentence pair or per node in a constraining tree.This design was motivated by the observation thatif a translation model cannot correctly model a cer-tain word alignment, then it is liable to make incor-rect inferences about arbitrary parts of that align-ment, not just the particular word links involved ina complex pattern.
The failure rates we report rep-resent lower bounds on the fraction of training data4http://nlp.cs.nyu.edu/GenPar980# of gaps allowed ?
0/0 0/1 or 1/0Chinese/English 26 = 5% 0 = 0%Romanian/English 1 = 0% 0 = 0%Hindi/English 2 = 2% 0 = 0%Spanish/English 3 = 2% 0 = 0%French/English 3 = 1% 0 = 0%Table 2: Failure rates for hierarchical alignment of bilingualbitexts under word alignment constraints only.# of gaps allowed onnon-English side ?
0 1 2Chinese/English 298 = 61% 28 = 6% 0 = 0%Romanian/English 82 = 41% 6 = 3% 1 = 0%Hindi/English 33 = 37% 1 = 1% 0 = 0%Spanish/English 75 = 38% 4 = 2% 0 = 0%French/English 67 = 15% 2 = 0% 0 = 0%Table 3: Failure rates for hierarchical alignment of bilin-gual bitexts under the constraints of a word alignment and amonolingual parse tree on the English side.that is susceptible to misinterpretation by overcon-strained translation models.3.4 Summary ResultsTable 2 shows the lower bound on alignment fail-ure rates with and without gaps for five languagespaired with English.
This table represents thecase where the only constraints are from wordalignments.
Wu (1997) has ?been unable to findreal examples?
of cases where hierarchical align-ment would fail under these conditions, at leastin ?fixed-word-order languages that are lightly in-flected, such as English and Chinese.?
(p. 385).In contrast, we found examples in all bitexts thatcould not be hierarchically aligned without gaps,including at least 5% of the Chinese/English sen-tence pairs.
Allowing constituents with a singlegap on one side of the bitext decreased the ob-served failure rate to zero for all five bitexts.Table 3 shows what happened when we usedmonolingual parse trees to restrict the composi-tions on the English side.
The failure rates wereabove 35% for four of the five language pairs, and61% for Chinese/English!
Again, the failure ratefell dramatically when one gap was allowed on theunconstrained (non-English) side of the bitext.
Al-lowing two gaps on the non-English side led to al-most complete coverage of these word alignments.Table 3 does not specify the number of gaps al-lowed on the English side, because varying this pa-rameter never changed the outcome.
The only waythat a gap on that side could increase coverage is ifthere was a node in the constraining parse tree that# of gaps ?
0/0 0/1 0/20 CTs 171 = 3% 0 = 0% 0 = 0%1 CTs 1792 = 34% 143 = 3% 7 = 0%2 CTs 3227 = 61% 3227 = 61% 3227 = 61%Table 4: Failure rates for hierarchical alignment of theMTEval bitext, over varying numbers of gaps and constrain-ing trees (CTs).# of gaps ?
0/0 0/1 0/20 CTs 23 = 0% 0 = 0% 0 = 0%1 CTs 655 = 10% 22 = 0% 1 = 0%2 CTs 1559 = 25% 1559 = 25% 1559 = 25%Table 5: Failure rates for hierarchical alignment of the fic-tion bitext, over varying numbers of gaps and constrainingtrees (CTs).had at least four children whose translations werein one of the complex permutations.
The absenceof such cases in the data implies that the failurerates under the constraints of one parse tree wouldbe identical even if we allowed production rules ofrank higher than two.Table 4 shows the alignment failure rates for theMTEval bitext.
With word alignment constraintsonly, 3% of the sentence pairs could not be hierar-chically aligned without gaps.
Allowing a singlegap on one side decreased this failure rate to zero.With a parse tree constraining constituents on oneside of the bitext and with no gaps, alignment fail-ure rates rose from 3% to 34%, but allowing asingle gap on the side of the bitext that was notconstrained by a parse tree brought the failure rateback down to 3%.
With two constraining trees thefailure rate was 61%, and allowing gaps did notlower it, for the same reasons that allowing gapson the tree-constrained side made no difference inTable 3.The trends in the fiction bitext (Table 5) weresimilar to those in the MTEval bitext, but the cov-erage was always higher, for two reasons.
First,the median sentence size was lower in the fictionbitext.
Second, the MTEval translators were in-structed to translate as literally as possible, but thefiction translators paraphrased to make the fictionmore interesting.
This freedom in word choice re-duced the frequency of cognates and thus imposedfewer constraints on the hierarchical alignment,which resulted in looser estimates of the lowerbounds.
We would expect the opposite effect withhand-aligned data (Galley et al, 2004).To study how sentence length correlates withthe complexity of translational equivalence, wetook subsets of each bitext while varying the max-98100.010.020.030.040.050.060.070.0810  20  30  40  50  60  70  80  90  100failureratemaximum length of shortest sentence0 constraining treesChinese/EngMTevalfiction00.10.20.30.40.50.60.710  20  30  40  50  60  70  80  90  100failureratemaximum length of shorter sentence1 constraining treeChinese/EngRomanian/EngHindi/EngSpanish/EngMTevalFrench/Engfiction00.10.20.30.40.50.60.710  20  30  40  50  60  70  80  90  100failureratemaximum length of shorter sentence2 constraining treesMTevalfictionFigure 4: Failure rates for hierarchical alignment without gaps vs. maximum length of shorter sentence.category ?
1 2 3valid reordering 12 10 5parser error n/a 16 25same word used differently 15 4 0erroneous cognates 3 0 0total sample size 30 30 30initial failure rate (%) 3.25 31.9 38.4% false negatives 60?7 66?7 84?3adjusted failure rate (%) 1.3?.22 11?2.2 6?1.1Table 6: Detailed analysis of hierarchical alignment failuresin MTEval bitext.imum length of the shorter sentence in each pair.5Figure 4 plots the resulting alignment failure rateswith and without constraining parse trees.
Thelines in these graphs are not comparable to eachother because of the variety of genres involved.3.5 Detailed Failure AnalysisWe examined by hand 30 random sentence pairsfrom the MTEval bitext in each of three differentcategories: (1) the set of sentence pairs that couldnot be hierarchically aligned without gaps, evenwithout constraining parse trees; (2) the set of sen-tence pairs that could not be hierarchically alignedwithout gaps with one constraining parse tree, butthat did not fall into category 1; and (3) the setof sentence pairs that could not be hierarchicallyaligned without gaps with two constraining parsetrees, but that did not fall into category 1 or 2.
Ta-ble 6 shows the results of this analysis.In category 1, 60% of the word alignments thatcould not be hierarchically aligned without gapswere caused by word alignment errors.
E.g.
:1a GlaxoSmithKline?s second-best selling drug may haveto face competition.1b Drug maker GlaxoSmithKline may have to face com-petition on its second best selling product.The word drug appears in both sentences, but fordifferent purposes, so drug and drug should not5The length of the shorter sentence is the upper bound onthe number of non-NULL word alignments.have been linked.6 Three errors were caused bywords like targeted and started, which our wordalignment algorithm deemed cognates.
12 of thehierarchical alignment failures in this categorywere true failures.
For example:2a Cheney denied yesterday that the mission of his tripwas to organize an assault on Iraq, while in Manama.2b Yesterday in Manama, Cheney denied that the mis-sion of his trip was to organize an assault on Iraq.The alignment pattern of the words in bold isthe familiar (3,1,4,2) permutation, as in Figure 1.Most of the 12 true failures were due to movementof prepositional phrases.
The freedom of move-ment for such modifiers would be greater in bitextsthat involve languages with less rigid word orderthan English.Of the 30 sentence pairs in category 2, 16 couldnot be hierarchically aligned due to parser errorsand 4 due to faulty word alignments.
10 were dueto valid word reordering.
In the following exam-ple, a co-referring pronoun causes the word align-ment to fail with a constraining tree on the secondsentence:3a But Chretien appears to have changed his stance aftermeeting with Bush in Washington last Thursday.3b But after Chretien talked to Bush last Thursday inWashington, he seemed to change his original stance.25 of the 30 sentence pairs in category 3 failedto align due to parser error.
5 examples failed be-cause of valid word reordering.
1 of the 5 reorder-ings was due to a difference between active voiceand passive voice, as in Figure 3.The last row of Table 6 takes the various rea-sons for alignment failure into account.
It esti-mates what the failure rates would be if the mono-lingual parses and word alignments were perfect,with 95% confidence intervals.
These revised ratesemphasize the importance of reliable word align-ments for this kind of study.6This sort of error is likely to happen with other wordalignment algorithms too, because words and their commontranslations are likely to be linked even if they?re not transla-tionally equivalent in the given sentence.9824 DiscussionFigure 1 came from a real bilingual bitext,and Example 2 in Section 3.5 came from areal monolingual bitext.7 Neither of these ex-amples can be hierarchically aligned correctlywithout gaps, even without constraining parsetrees.
The received wisdom in the literatureled us to expect no such examples in bilin-gual bitexts, let alne in monolingual bitexts.See http://nlp.cs.nyu.edu/GenPar/ACL06 formore examples.
The English/English lowerbounds are very loose, because the automatic wordaligner would not link words that were not cog-nates.
Alignment failure rates on a hand alignedbitext would be higher.
We conclude that the ITGformalism cannot account for the ?natural?
com-plexity of translational equivalence, even whentranslation divergences are factored out.Perhaps our most surprising results were thoseinvolving one constraining parse tree.
These re-sults explain why constraints from independentlygenerated monolingual parse trees have not im-proved statistical translation models.
For exam-ple, Koehn et al (2003) reported that ?requiringconstituents to be syntactically motivated does notlead to better constituent pairs, but only fewer con-stituent pairs, with loss of a good amount of valu-able knowledge.?
This statement is consistent withour findings.
However, most of the knowledgeloss could be prevented by allowing a gap.
Witha parse tree constraining constituents on the En-glish side, the coverage failure rate was 61% forthe Chinese/English bitext (top row of Table 3),but allowing a gap decreased it to 6%.
Zhang andGildea (2004) found that their alignment method,which did not use external syntactic constraints,outperformed the model of Yamada and Knight(2001).
However, Yamada and Knight?s modelcould explain only the data that would pass the no-gap test in our experiments with one constrainingtree (first column of Table 3).
Zhang and Gildea?sconclusions might have been different if Yamadaand Knight?s model were allowed to use discon-tinuous constituents.
The second row of Ta-ble 4 suggests that when constraining parse treesare used without gaps, at least 34% of training sen-tence pairs are likely to introduce noise into themodel, even if systematic syntactic differences be-tween languages are factored out.
We should not7The examples were shortened for the sake of space andclarity.01020304050607080901000  10  20  30  40  50  60  70cumulative%ageofsentencesspan lengthFigure 5: Lengths of spans covering words in (3,1,4,2) per-mutations.be surprised when such constraints do more harmthan good.To increase the chances that a translation modelcan explain complex word alignments, some au-thors have proposed various ways of extendinga model?s domain of locality.
For example,Callison-Burch et al (2005) have advocated forlonger phrases in finite-state phrase-based transla-tion models.
We computed the phrase length thatwould be necessary to cover the words involvedin each (3,1,4,2) permutation in the MTEval bi-text.
Figure 5 shows the cumulative percentage ofthese cases that would be covered by phrases up toa certain length.
Only 9 of the 171 cases (5.2%)could be covered by phrases of length 10 or less.Analogous techniques for tree-structured transla-tion models involve either allowing each nonter-minal to generate both terminals and other non-terminals (Groves et al, 2004; Chiang, 2005), or,given a constraining parse tree, to ?flatten?
it (Fox,2002; Zens and Ney, 2003; Galley et al, 2004).Both of these approaches can increase coverage ofthe training data, but, as explained in Section 2,they risk losing generalization ability.Our study suggests that there might be somebenefits to an alternative approach using discontin-uous constituents, as proposed, e.g., by Melamedet al (2004) and Simard et al (2005).
The largedifferences in failure rates between the first andsecond columns of Table 3 are largely indepen-dent of the tightness of our lower bounds.
Syn-chronous parsing with discontinuities is computa-tionally expensive in the worst case, but recentlyinvented data structures make it feasible for typi-cal inputs, as long as the number of gaps allowedper constituent is fixed at a small maximum (Wax-monsky and Melamed, 2006).
More research isneeded to investigate the trade-off between thesecosts and benefits.9835 ConclusionsThis paper presented evidence of phenomena thatcan lead to complex patterns of translationalequivalence in bitexts of any language pair.
Therewere surprisingly many examples of such patternsthat could not be analyzed using binary-branchingstructures without discontinuities.
Regardless ofthe languages involved, the translational equiva-lence relations in most real bitexts of non-trivialsize cannot be generated by an inversion trans-duction grammar.
The low coverage rates withoutgaps under the constraints of independently gen-erated monolingual parse trees might be the mainreason why ?syntactic?
constraints have not yet in-creased the accuracy of SMT systems.
Allowing asingle gap in bilingual phrases or other types ofconstituent can improve coverage dramatically.ReferencesNecip Ayan, Bonnie J. Dorr, and Christof Monz.
2005.Alignment link projection using transformation-based learning.
In EMNLP.Regina Barzilay and Kathleen McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In ACL.Andrea Burbank, Marine Carpuat, Stephen Clark,Markus Dreyer and Pamela Fox, Declan Groves,Keith Hall, Mary Hearne, I. Dan Melamed,Yihai Shen, Andy Way, Ben Wellington, andDekai Wu.
2005.
Final Report on StatisticalMachine Translation by Parsing.
JHU CLSP.http://www.clsp.jhu.edu/ws2005/groups/statistical/report.htmlDan Bikel.
2004.
A distributional analysis of a lexical-ized statistical parsing model.
In EMNLP.Chris Callison-Burch, Colin Bannard, and JoshScroeder.
2005.
Scaling phrase-based statisticalmachine translation to larger corpora and longerphrases.
In ACL.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In ACL.Bonnie Dorr.
1994.
Machine translation divergences:A formal description and proposed solution.
Com-putational Linguistics 20(4):597?633.Heidi Fox.
2002.
Phrasal cohesion and statistical ma-chine translation.
In EMNLP.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translation rule?In HLT-NAACL.Declan Groves, Mary Hearne, and Andy Way.
2004.Robust sub-sentential alignment of phrase-structuretrees.
In COLING.Philipp Koehn, Franz Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In NAACL.Mitchell Marcus, Beatrice Santorini, and Mary-AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Joel Martin, Rada Mihalcea, and Ted Pedersen.
2005.Word alignments for languages with scarce re-sources.
In ACL Workshop on Building and UsingParallel Texts.I.
Dan Melamed.
1995.
Automatic evaluation and uni-form filter cascades for inducing N -best translationlexicons.
In ACL Workshop on Very Large Corpora.I.
Dan Melamed, Giorgio Satta, and Benjamin Welling-ton.
2004.
Generalized multitext grammars.
InACL.I.
Dan Melamed and Wei Wang.
2005.
Gen-eralized Parsers for Machine Translation.NYU Proteus Project Technical Report 05-001http://nlp.cs.nyu.edu/pubs/.Rada Mihalcea and Ted Pedersen.
2003.
An evalua-tion exercise for word alignment.
In HLT-NAACLWorkshop on Building and Using Parallel Texts.LDC.
2002.
NIST MT evaluation data, LinguisticData Consortium catalogue # LDC2002E53.http://projects.ldc.upenn.edu/TIDES/mt2003.html.Giorgio Satta and Enoch Peserico.
2005.
Somecomputational complexity results for synchronouscontext-free grammars.
In EMNLP.Michel Simard, Nicola Cancedda, Bruno Cavestro,Marc Dymetman, Eric Guassier, Cyril Goutte, andKenji Yamada.
2005.
Translating with non-contiguous phrases.
In EMNLP.Sonjia Waxmonsky and I. Dan Melamed.
2006.
A dy-namic data structure for parsing with discontinuousconstituents.
NYU Proteus Project Technical Report06-001 http://nlp.cs.nyu.edu/pubs/.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?404.Kenji Yamada and Kevin Knight.
2001.
A syntax-based statistical translation model.
In ACL.Richard Zens and Hermann Ney.
2003.
A comparativestudy on reordering constraints in statistical machinetranslation.
In ACL.Hao Zhang and Daniel Gildea.
2004.
Syntax-basedalignment: Supervised or unsupervised?
In COL-ING.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous binarization for ma-chine translation.
In HLT-NAACL.984
