Proceedings of the SIGDIAL 2014 Conference, pages 292?299,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsWord-Based Dialog State Trackingwith Recurrent Neural NetworksMatthew Henderson, Blaise Thomson and Steve YoungDepartment of Engineering,University of Cambridge, U.K.{mh521, brmt2, sjy}@eng.cam.ac.ukAbstractRecently discriminative methods for track-ing the state of a spoken dialog have beenshown to outperform traditional generativemodels.
This paper presents a new word-based tracking method which maps di-rectly from the speech recognition resultsto the dialog state without using an explicitsemantic decoder.
The method is based ona recurrent neural network structure whichis capable of generalising to unseen dialogstate hypotheses, and which requires verylittle feature engineering.
The methodis evaluated on the second Dialog StateTracking Challenge (DSTC2) corpus andthe results demonstrate consistently highperformance across all of the metrics.1 IntroductionWhile communicating with a user, statistical spo-ken dialog systems must maintain a distributionover possible dialog states in a process called di-alog state tracking.
This distribution, also calledthe belief state, directly determines the system?sdecisions.
In MDP-based systems, only the mostlikely dialog state is considered and in this casethe primary metric is dialog state accuracy (Bo-hus and Rudnicky, 2006).
In POMDP-based sys-tems, the full distribution is considered and thenthe shape of the distribution as measured by an L2norm is equally important (Young et al., 2009).
Inboth cases, good quality state tracking is essentialto maintaining good overall system performance.Typically, state tracking has assumed the outputof a Spoken Language Understanding (SLU) com-ponent in the form of a semantic decoder, whichmaps the hypotheses from Automatic SpeechRecognition (ASR) to a list of semantic hypothe-ses.
This paper considers mapping directly fromASR hypotheses to an updated belief state at eachturn in the dialog, omitting the intermediate SLUprocessing step.
This word-based state trackingavoids the need for an explicit semantic represen-tation and also avoids the possibility of informa-tion loss at the SLU stage.Recurrent neural networks (RNNs) provide anatural model for state tracking in dialog, asthey are able to model and classify dynamic se-quences with complex behaviours from step tostep.
Whereas, most previous approaches to dis-criminative state tracking have adapted station-ary classifiers to the temporal process of dialog(Bohus and Rudnicky, 2006; Lee and Eskenazi,2013; Lee, 2013; Williams, 2013; Henderson etal., 2013b).
One notable exception is Ren et al.
(2013), which used conditional random fields tomodel the sequence temporally.Currently proposed methods of discriminativestate tracking require engineering of feature func-tions to represent the turn in the dialog (Ren etal., 2013; Lee and Eskenazi, 2013; Lee, 2013;Williams, 2013; Henderson et al., 2013b).
It is un-clear whether differences in performance are dueto feature engineering or the underlying models.This paper proposes a method of using simple n-gram type features which avoid the need for fea-ture engineering.
Instead of using inputs with a se-lect few very informative features, the approach isto use high-dimensional inputs with all the infor-mation to potentially reconstruct any such hand-crafted feature.
The impact of significantly in-creasing the dimensionality of the inputs is man-aged by careful initialisation of model parameters.Accuracy on unseen or infrequent slot valuesis an important concern, particularly for discrim-inative classifiers which are prone to overfittingtraining data.
This is addressed by structuringthe recurrent neural network to include a compo-nent which is independent of the actual slot valuein question.
It thus learns general behaviours forspecifying slots enabling it to successfully decode292ASR output which includes previously unseen slotvalues.In summary, this paper presents a word-basedapproach to dialog state tracking using recurrentneural networks.
The model is capable of gen-eralising to unseen dialog state hypotheses, andrequires very little feature engineering.
The ap-proach is evaluated in the second Dialog StateTracking Challenge (DSTC2) (Henderson et al.,2014) where it is shown to be extremely competi-tive, particularly in terms of the quality of its con-fidence scores.Following a brief outline of DSTC2 in section2, the definition of the model is given in section3.
Section 4 then gives details on the initialisationmethods used for training.
Finally results on theDSTC2 evaluation are given in 5.2 The Second Dialog State TrackingChallengeThis section describes the domain and method-ology of the second Dialog State Tracking Chal-lenge (DSTC2).
The challenge is based on alarge corpus collected using a variety of telephone-based dialog systems in the domain of finding arestaurant in Cambridge.
In all cases, the subjectswere recruited using Amazon Mechanical Turk.The data is split into a train, dev and test set.The train and dev sets were supplied with labels,and the test set was released unlabelled for a oneweek period.
At the end of the week, all partici-pants were required to submit their trackers?
out-put on the test set, and the labels were revealed.
Amis-match was ensured between training and test-ing conditions by choosing dialogs for the eval-uation collected using a separate dialog manager.This emulates the mis-match a new tracker wouldencounter if it were actually deployed in an end-to-end system.In summary, the datasets used are:?
dstc2 train - Labelled training consisting of1612 dialogs with two dialog managers andtwo acoustic conditions.?
dstc2 dev - Labelled dataset consistingof 506 calls in the same conditions asdstc2 train, but with no caller in common.?
dstc2 test - Evaluation dataset consisting of1117 dialogs collected using a dialog man-ager not seen in the labelled data.In contrast with DSTC1, DSTC2 introduces dy-namic user goals, tracking of requested slots andtracking the restaurant search method.
A DSTC2tracker must therefore report:?
Goals: A distribution over the user?s goal foreach slot.
This is a distribution over the possi-ble values for that slot, plus the special valueNone, which means no valid value has beenmentioned yet.?
Requested slots: A reported probability foreach requestable slot that has been requestedby the user, and should be informed by thesystem.?
Method: A distribution over methods, whichencodes how the user is trying to use the di-alog system.
E.g.
?by constraints?, when theuser is trying to constrain the search, and ?fin-ished?, when the user wants to end the dialog.A tracker may report the goals as a joint overall slots, but in this paper the joint is reported as aproduct of the marginal distributions per slot.Full details of the challenge are given in Hen-derson et al.
(2013a), Henderson et al.
(2014).
Thetrackers presented in this paper are identified un-der ?team4?
in the reported results.3 Recurrent Neural Network ModelThis section defines the RNN structure used fordialog state tracking.
One such RNN is used perslot, taking the most recent dialog turn (user inputplus last machine dialog act) as input, updating itsinternal memory and calculating an updated beliefover the values for the slot.
In what follows, thenotation a?b is used to denote the concatenationof two vectors, a and b.
The ithcomponent of thevector a is written a|i.3.1 Feature RepresentationExtracting n-grams from utterances and dialogacts provides the feature representations neededfor input into the RNN.
This process is very sim-ilar to the feature extraction described in Hender-son et al.
(2012), and is outlined in figure 1.For n-gram features extracted from the ASRN -best list, unigram, bigram and trigram featuresare calculated for each hypothesis.
These arethen weighted by the N -best list probabilities andsummed to give a single vector.Dialog acts in this domain consist ofa list of component acts of the formacttype(slot=value) where the slot=valuepair is optional.
The n-gram type features293extracted from each such component act are?acttype?, ?slot?, ?value?, ?acttypeslot?, ?slot value?
and ?acttype slotvalue?, or just ?acttype?
for the act acttype().Each feature is given weight 1, and the featuresfrom individual component acts are summed.To provide a contrast, trackers have also beenimplemented using the user dialog acts output byan SLU rather than directly from the ASR output.In this case, the SLU N -best dialog act list is en-coded in the same way except that the n-gramsfrom each hypothesis are weighted by the corre-sponding probabilities, and summed to give a sin-gle feature vector.Consider a word-based tracker which takes anASR N -best list and the last machine act as inputfor each turn, as shown in figure 1.
A combinedfeature representation of both the ASR N -best listand the last machine act is obtained by concate-nating the vectors.
This means that in figure 1 thefood feature from the ASR and the food featurefrom the machine act contribute to separate com-ponents of the final vector f .fvASRfoodjamaicanindian food1.00.90.1<value> food<value> 0.90.9Machine Actconfirm foodconfirm food jamaicanfood jamaican1.01.01.0e.g.
v = jamaicanconfirm food <value>food <value>1.01.0for each value, vjamaican food 0.9<slot><value>1.01.0<value> <slot> 1.0confirm 1.0<value> 1.0confirm <slot> <value><slot> <value>1.01.0<value> 1.0indian 0.1<value> food 1.0jamaican <slot> 0.9indian <slot> 0.1confirm food <value> 1.0food <value> 1.0confirm <slot> jamaican 1.0<slot> jamaican 1.00.9jamaican food 0.1indian food confirm(food=jamaican)food 1.0<slot> 1.0fsf5 non-zero elements6 non-zero elements2 non-zero elements6 non-zero elements8 non-zero elements3 non-zero elements11 non-zero elements14 non-zero elements5 non-zero elementsjamaican 1.0Figure 1: Example of feature extraction for oneturn, giving f , fsand fv.
Here s = food.
For allv /?
{indian, jamaican}, fv= 0.Note that all the methods for tracking reportedin DSTC1 required designing feature functions.For example, suggested feature functions includedthe SLU score in the current turn, the probabil-ity of an ?affirm?
act when the value has beenconfirmed by the system, the output from base-line trackers etc.
(e.g.
Lee and Eskenazi (2013),Williams (2013), Henderson et al.
(2013b)).
Incontrast, the approach described here is to presentthe model with all the information it would needto reconstruct any feature function that might beuseful.3.2 Generalisation to Unseen StatesOne key issue in applying machine learning to thetask of dialog state tracking is being able to dealwith states which have not been seen in training.For example, the system should be able to recog-nise any obscure food type which appears in theset of possible food types.
A na?
?ve neural net-work structure mapping n-gram features to an up-dated distribution for the food slot, with no tyingof weights, would require separate examples ofeach of the food types to learn what n-grams areassociated with each.
In reality however n-gramslike ?<value> food?
and ?serving <value>?
are likelyto correspond to the hypothesis food=?<value>?
forany food-type replacing ?<value>?.The approach taken here is to embed a networkwhich learns a generic model of the updated beliefof a slot-value assignment as a function of ?tagged?features, i.e.
features which ignore the specificidentity of a value.
This can be considered as re-placing all occurrences of a particular value witha tag like ?<value>?.
Figure 1 shows the process ofcreating the tagged feature vectors, fsand fvfromthe untagged vector f .3.3 Model DefinitionIn this section an RNN is described for trackingthe goal for a given slot, s, throughout the se-quence of a dialog.
The RNN holds an internalmemory, m ?
RNmemwhich is updated at eachstep.
If there are N possible values for slot s, thenthe probability distribution output p is in RN+1,with the last component p|Ngiving the probabil-ity of the None hypothesis.
Figure 2 provides anoverview of how p and m are updated in one turnto give the new belief and memory, p?and m?.One part of the neural network is used to learna mapping from the untagged inputs, full memoryand previous beliefs to a vector h ?
RNwhichgoes directly into the calculation of p?
:h = NNet (f ?
p?m) ?
RN294p mhN.
Net.g vp vN.
Net.for each value, vh+gp?softmax m?logisticfor each slot,  sffsfvpNFigure 2: Calculation of p?and m?for one turnwhere NNet(?)
denotes a neural network functionof the input.
In this paper all such networks haveone hidden layer with a sigmoidal activation func-tion.The sub-network for h requires examples of ev-ery value in training, and is prone to poor general-isation as explained in section 3.2.
By including asecond sub-network for g which takes tagged fea-tures as input, it is possible to exploit the obser-vation that the string corresponding to a value invarious contexts is likely to be good evidence foror against that value.
For each value v, a compo-nent of g is calculated using the neural network:g|v= NNet(f?
fs?
fv?
{p|v, p|N} ?m)?
RBy using regularisation, the learning will pre-fer where possible to use the sub-network for grather than learning the individual weights foreach value required in the sub-network for h. Thissub-network is able to deal with unseen or infre-quently seen dialog states, so long as the state canbe tagged in the feature extraction.
This model canalso be shared across slots since fsis included asan input, see section 4.2.The sub-networks applied to tagged and un-tagged inputs are combined to give the new belief:p?= softmax ([h + g]?
{B}) ?
RN+1where B is a parameter of the RNN, contributingto the None hypothesis.
The contribution from gmay be seen as accounting for general behaviourof tagged hypotheses, while h makes correctionsdue to correlations with untagged features andvalue specific behaviour e.g.
special ways of ex-pressing specific goals and fitting to specific ASRconfusions.Finally, the memory is updated according to thelogistic regression:m?= ?
(Wm0f +Wm1m) ?
RNmemwhere the Wmiare parameters of the RNN.3.4 Requested Slots and MethodA similar RNN is used to track the requested slots.Here the v runs over all the requestable slots, andrequestable slot names are tagged in the featurevectors fv.
This allows the neural network calcu-lating g to learn general patterns across slots justas in the case of goals.
The equation for p?ischanged to:p?= ?
(h + g)so each component of p?represents the probability(between 0 and 1) of a slot being requested.For method classification, the same RNN struc-ture as for a goal is used.
No tagging of the featurevectors is used in the case of methods.4 TrainingThe RNNs are trained using Stochastic GradientDescent (SGD), maximizing the log probability ofthe sequences of observed beliefs in the trainingdata (Bottou, 1991).
Gradient clipping is used toavoid the problem of exploding gradients (Pascanuet al., 2012).
A regularisation term is included,which penalises the l2 norm of all the parameters.It is found empirically to be beneficial to give moreweight in the regularisation to the parameters usedin the network calculating h.When using the ASR N -best list, f is typi-cally of dimensionality around 3500.
With somany weights to learn, it is important to initialisethe parameters well before starting the SGD algo-rithm.
Two initialisation techniques have been in-vestigated, the denoising autoencoder and sharedinitialisation.
These were evaluated by trainingtrackers on the dstc2 train set, and evaluating ondstc2 dev (see table 1).4.1 Denoising AutoencoderThe denoising autoencoder (dA), which providesan unsupervised method for learning meaningful295Joint Goals Method RequestedSharedinit.dAinit.Acc L2 Acc L2 Acc L20.686 0.477 0.913 0.147 0.963 0.059X 0.688 0.466 0.915 0.144 0.962 0.059X 0.680 0.479 0.910 0.152 0.962 0.059X X 0.696 0.463 0.915 0.144 0.965 0.057Baseline: 0.612 0.632 0.830 0.266 0.894 0.174Table 1: Performance on the dev set when varying initialisation techniques for word-based tracking.
Accdenotes the accuracy of the most likely belief at each turn, and L2 denotes the squared l2 norm betweenthe estimated belief distribution and correct (delta) distribution.
For each row, 5 trackers are trainedand then combined using score averaging.
The final row shows the results for the focus-based baselinetracker (Henderson et al., 2014).underlying representations of the input, has beenfound effective as an initialisation technique indeep learning (Vincent et al., 2008).A dA is used to initialise the parameters of theRNN which multiply the high-dimensional inputvector f .
The dA learns a matrix WdAwhich re-duces f to a lower dimensional vector such thatthe original vector may be recovered with minimalloss in the presence of noise.For learning the dA, f is first mapped such thatfeature values lie between 0 and 1.
The dA takes asinput fnoisy, a noisy copy of f where each compo-nent is set to 0 with probability p. This is mappedto a lower dimensional hidden representation h:h = ?
(WdAfnoisy+ b0)A reconstructed vector, frec, is then calculatedas:frec= ?
(WTdAh+ b1)The cross-entropy between f and frecis used asthe objective function in gradient descent, with anadded l1 regularisation term to ensure the learningof sparse weights.
As the ASR features are likelyto be very noisy, dense weights would be prone tooverfitting the examples.1When using WdAto initialise weights in theRNN, training is observed to converge faster.
Ta-ble 1 shows that dA initialisation leads to bettersolutions, particularly for tracking the goals.4.2 Shared InitialisationIt is possible to train a slot-independent RNN, us-ing training data from all slots, by not including hin the model (the dimensionality of h is dependent1The state-of-the-art in dialog act classification with verysimilar data also uses sparse weights Chen et al.
(2013).on the slot).
In shared initialisation, such an RNNis trained for a few epochs, then the learnt param-eters are used to initialise slot-dependent RNNsfor each slot.
This follows the shared initialisationprocedure presented in Henderson et al.
(2013b).Table 1 suggests that shared initialisation whencombined with dA initialisation gives the best per-formance.4.3 Model CombinationIn DSTC1, the most competitive results wereachieved with model combination whereby theoutput of multiple trackers were combined to givemore accurate classifications (Lee and Eskenazi,2013).
The technique for model combination usedhere is score averaging, where the final score foreach component of the dialog state is computed asthe mean of the scores output by all the trackersbeing combined.
This is one of the simplest meth-ods for model combination, and requires no extratraining data.
It is guaranteed to improve the accu-racy if the outputs from the individual trackers arenot correlated, and the individual trackers operateat an accuracy > 0.5.Multiple runs of training the RNNs were foundto give results with high variability and modelcombination provides a method to exploit thisvariability.
In order to demonstrate the effect,10 trackers with varying regularisation parame-ters were trained on dstc2 train and used to trackdstc2 dev.
Figure 3 shows the effects of combin-ing these trackers in larger groups.
The mean ac-curacy in the joint goals from combining m track-ers is found to increase with m. The single outputfrom combining all 10 trackers outperforms anysingle tracker in the group.The approach taken for the DSTC2 challengewas therefore to train multiple trackers with vary-296Accuracy# trackers combined, m1 2 3 4 5 6 7 8 9 100.640.650.660.670.680.690.700.710.72Figure 3: Joint goal accuracy on dstc2 dev from systemcombination.
Ten total trackers are trained with varying reg-ularisation parameters.
For each m = 1 .
.
.
10, all subsetsof size m of the 10 trackers are used to generate10Cmcom-bined results, which are plotted as a boxplot.
Boxplots showminimum, maximum, the interquartile range and the median.The mean values are plotted as connected points.ing model hyper-parameters (e.g.
regularisationparameters, memory size) and combine their out-put using score averaging.
Note that maintainingaround 10 RNNs for each dialog state componentsis entirely feasible for a realtime system, as theRNN operations are quick to compute.
An un-optimised Python implementation of the trackerincluding an RNN for each dialog state compo-nent is able to do state tracking at a rate of around50 turns per second on an Intel?
Core?
i7-9703.2GHz processor.5 ResultsThe strict blind evaluation procedure defined forthe DSTC2 challenge was used to investigate theeffect on performance of two contrasts.
The firstcontrast compares word-based tracking and con-ventional tracking based on SLU output.
The sec-ond contrast investigates the effect of includingand omitting the sub-network for h in the RNN.Recall h is the part of the model that allows learn-ing special behaviours for particular dialog statehypotheses, and correlations with untagged fea-tures.
These two binary contrasts resulted in a to-tal of 4 system variants being entered in the chal-lenge.Each system is the score-averaged combinedoutput of 12 trackers trained with varying hyper-parameters (see section 4.3).
The performance ofthe 4 entries on the featured metrics of the chal-lenge are shown in table 2.It should be noted that the live SLU used theword confusion network, not made available in thechallenge.
The word confusion network is knownto provide stronger features than theN -best list forlanguage understanding (Henderson et al., 2012;T?ur et al., 2013), so the word-based trackers us-ing N -best ASR features were at a disadvantagein that regard.
Nevertheless, despite this hand-icap, the best results were obtained from word-based tracking directly on the ASR output, ratherthan using the confusion network generated SLUoutput.
Including h always helps, though this isfar more pronounced for the word-based track-ers.
Note that trackers which do not include h arevalue-independent and so are capable of handlingnew values at runtime.The RNN trackers performed very competi-tively in the context of the challenge.
Figure 4 vi-sualises the performance of the four trackers rela-tive to all the entries submitted to the challenge forthe featured metrics.
For full details of the evalua-tion metrics see Henderson et al.
(2014).
The boxin this figure gives the entry IDs under which theresults are reported in the DSTC (under the teamID ?team4?).
The word-based tracker includingh (h-ASR), was top for joint goals L2 as well asrequested slots accuracy and L2.
It was close tothe top for the other featured metrics, followingclosely entries from team 2.
The RNN trackersperformed particularly well on measures assessingthe quality of the scores such as L2.There are hundreds of numbers reported in theDSTC2 evaluation, and it was found that the h-ASR tracker ranked top on many of them.
Consid-ering L2, accuracy, average probability, equal er-ror rate, log probability and mean reciprocal rankacross all components of the the dialog state, thesegive a total of 318 metrics.
The h-ASR trackerranked top of all trackers in the challenge in 89 ofthese metrics, more than any other tracker.
TheASR tracker omitting h came second, ranking topin 33 of these metrics.The trackers using SLU features ranked topin all of the featured metrics among the trackerswhich used only the SLU output.6 ConclusionsThe RNN framework presented in this paper pro-vides very good performance in terms of both ac-curacy and the quality of reported probability dis-tributions.
Word-based tracking is shown to be oneof the most competitive approaches submitted toDSTC2.
By mapping straight from the ASR out-put to a belief update, it avoids any information297TrackerInputsJoint Goals Method RequestedentryIncludehLiveASRLiveSLUAcc L2 ROC Acc L2 ROC Acc L2 ROC0 X X 0.768 0.346 0.365 0.940 0.095 0.452 0.978 0.035 0.5251 X 0.746 0.381 0.383 0.939 0.097 0.423 0.977 0.038 0.4902 X X 0.742 0.387 0.345 0.922 0.124 0.447 0.957 0.069 0.3403 X 0.737 0.406 0.321 0.922 0.125 0.406 0.957 0.073 0.385Table 2: Featured metrics on the test set for the 4 RNN trackers entered to the challenge.0.41.00.60.80.00.8AccuracyJoint Goals Method Requested All0.20.40.6L2entry0entry2entry1entry3word-basedSLU inputfull model no hbaselineFigure 4: Relative performance of RNN trackers for fea-tured metrics in DSTC2.
Each dash is one of the 34 trackersevaluated in the challenge.
Note a lower L2 is better.
ROCmetric is only comparable for systems of similar accuracies,so is not plotted.
The focus baseline system is shown as acircle.lost in the omitted SLU step.In general, the RNN appears to be a promisingmodel, which deals naturally with sequential inputand outputs.
High dimensional inputs are handledwell, with little feature engineering, particularlywhen carefully initialised (e.g.
as here using de-noising autoencoders and shared initialisation).Future work should include making joint pre-dictions on components of the dialog state.
In thispaper each component was tracked using its ownRNN.
Though not presented in this paper, no im-provement could be found by joining the RNNs.However, this may not be the case for other do-mains in which slot values are more highly cor-related.
The concept of tagging the feature func-tions allows for generalisation to unseen valuesand slots.
This generalisation will be explored infuture work, particularly for dialogs in more open-domains.AcknowledgementsMatthew Henderson is a Google Doctoral Fellow.ReferencesDan Bohus and Alex Rudnicky.
2006.
A K-hypotheses+ Other Belief Updating Model.
Proc.of the AAAI Workshop on Statistical and EmpiricalMethods in Spoken Dialogue Systems.L?eon Bottou.
1991.
Stochastic gradient learning inneural networks.
In Proceedings of Neuro-N?
?mes91, N?
?mes, France.
EC2.Yun-Nung Chen, William Yang Wang, and Alexan-der I Rudnicky.
2013.
An empirical investigation ofsparse log-linear models for improved dialogue actclassification.
In Acoustics, Speech and Signal Pro-cessing (ICASSP), 2013 IEEE International Confer-ence on.Matthew Henderson, Milica Ga?si?c, Blaise Thom-son, Pirros Tsiakoulis, Kai Yu, and Steve Young.2012.
Discriminative Spoken Language Under-standing Using Word Confusion Networks.
In Spo-ken Language Technology Workshop, 2012.
IEEE.298Matthew Henderson, Blaise Thomson, and JasonWilliams.
2013a.
Dialog State Tracking Challenge2 & 3 Handbook.
camdial.org/?mh521/dstc/.Matthew Henderson, Blaise Thomson, and SteveYoung.
2013b.
Deep Neural Network Approach forthe Dialog State Tracking Challenge.
In Proceed-ings of SIGdial, Metz, France, August.Matthew Henderson, Blaise Thomson, and JasonWilliams.
2014.
The second dialog state trackingchallenge.
In Proceedings of the SIGdial 2014 Con-ference, Baltimore, U.S.A., June.Sungjin Lee and Maxine Eskenazi.
2013.
Recipe forbuilding robust spoken dialog state trackers: Dialogstate tracking challenge system description.
In Pro-ceedings of the SIGDIAL 2013 Conference, Metz,France, August.Sungjin Lee.
2013.
Structured discriminative modelfor dialog state tracking.
In Proceedings of the SIG-DIAL 2013 Conference, Metz, France, August.Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.2012.
Understanding the exploding gradient prob-lem.
CoRR.Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan.2013.
Dialog state tracking using conditional ran-dom fields.
In Proceedings of the SIGDIAL 2013Conference, Metz, France, August.G?okhan T?ur, Anoop Deoras, and Dilek Hakkani-T?ur.2013.
Semantic parsing using word confusion net-works with conditional random fields.
In INTER-SPEECH.Pascal Vincent, Hugo Larochelle, Yoshua Bengio, andPierre-Antoine Manzagol.
2008.
Extracting andcomposing robust features with denoising autoen-coders.
In Proceedings of the 25th InternationalConference on Machine Learning, Helsinki, Fin-land.Jason Williams.
2013.
Multi-domain learning and gen-eralization in dialog state tracking.
In Proceedingsof the SIGDIAL 2013 Conference, Metz, France, Au-gust.Steve Young, Milica Ga?si?c, Simon Keizer, Franc?oisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2009.
The Hidden Information State model:A practical framework for POMDP-based spokendialogue management.
Computer Speech & Lan-guage.299
