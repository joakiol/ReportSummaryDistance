Bm|mm|mmmmmShallow Post Morphological Processing with KURDMichael Carl and Antic Schmidt-Wiggeremail: cad,antje@iai.uni-sb.deInstitut fiir Angewandte Informstionsforschung,Martin-Luther-StraJ~e 14, 66111 SaarbrtickenGermanyAbst rac tIn this paper we describe a constraintbased formalism that manipulates se-quences of morphological analyses in or-der to Kill, Unify, Replace or Deleteparts of the structure.
We compare theformalism to a similar approach (CGP)and describe two applications.1 IntroductionIn NLP applications an input text undergoes anumber of transformations until the desired in-formation can be extracted from it.
Typically,such transformations involve part of speech tag-ging, morphological nalyses uch as lemmatiza-tion or full derivational and compositional naly-ses, context-dependent disambiguation of taggingresults, multi-word recognition, shallow, partial orfull syntactic parsing, semantic analyses and soOU.It is not always evident what level of analysisshould be involved.
For instance, whether a cer-tain task reqnizes a full parse or whether some'shallow' operations may be sufficient is often dif-ficult to determine.
The choice of tools can beguided by the data or the requirements and theprerequisites of the goal to be reached.
Theseconsiderations may depend on the availability of agrammatical model, the required standard of theresults, and processing time constraints.
However,the optimization of this task remains an unre-solved area until now.The interest of the NLP community for 'shal-low' processing has grown recently (cf.
(Karls-son, 1990),(Abney, 1996), (Deelerek and Klein,1997)).
In this paper, we describe a simple formal-ism (KURD x) that is designed to perform someX KURD is an  acronym representing the ftrst lettersof the implemented actions: K(ill)-U(nify)-R(?place)-D(elete)Carl and Schmidt-Wigger 257'shallow' operations on morphologically analyzedtexts.
The output can be used directly, or be redi-rected to further processing.Typical tasks for such shallow processing include?
Tagging (disarnbiguation of multiple mor-phological analyses)Often a set of simple rules that runs in a setorder over the results of the morphologicalanalyses i sufficient o disambiguate multipleanalysis of a word due to its morphosyntacticcontext.?
Syntax check ingGrammatically erroneous entences are de-tected by a set of rules describing commonweak points such as missing punctuationmarks or ill-formed agreement.?
Style check ingHighly complex constructions or heavyphrases can disturb the reading and under-standing process.
To avoid this, style check-ers can recognize such patterns o that theauthor can readjust his text for better com-munication.?
Shallow pars ingShallow parsing can help to simplify the databefore full parsing is undertaken.
It recog-nizes syntactic phrases, mostly on the nomi-nal level.?
Segmentat ionThe morphological analysis deals with wordswhich are presented in texts.
High levelprocessing deals with units between the wordlevel and the text level, mostly with sen-tences.
Thus, sentence segmentation is a typ-ical shallow process, but other subunits couldbe equally interesting.KURDMichael Carl and Antje Schmidt-Wigger (1998) Shallow Post Morphological Processing with KURD.
In D.M.W.
Powers (ed.
)NeMLaP3/CoNLL98: New Methods in Language Processing and Computational Natural Language Learning.
ACL, pp 257-265.The basic idea of the presented formalism is thefollowing: in a set of rules, patterns are definedwhich are mapped onto the morphologically ana-lyzed input strings.
If the mapping is successful,modifications of the analysis are undertaken ac-cording to the specifications in the rule.
To ensureexpressiveness and ease of formulation of the rules,we have introduced some elements of unificationbased systems into the formalism.2 Morphological AnalysisMorphological analysis 2 is the process of separat-ing grammatical information and (a) stem(s) fromthe surface form of an input word.
Lemmatizationgenerates from an input string a basic word formthat does not contain inflectional information.
Alemma together with the grammatical informationis thus equivalent to the surface form of the word.In addition, lemma decomposition can be carriedout by the morphological processor.
Recognitionof composition and derivation yields knowledgeabout the internal structure of the word.Morphological information and the value of thelemma are represented in the form of sets of at-tribute/operator/values (/I op V) which we willrefer to as feature bundles (FBs).
Beside mor-phological analysis and lemmatization, sentencesegmentation is performed by the morphologicalprocessor.
The output is thus a sentence descrip-tor SD that  contains multiple Word DescriptorsWDs.
The distinction between WDs and deeperembedded FBs  is useful later in this paper due tothe important  functional difference.
The formaldefinition of a SD is as follows:Sentence Descriptor SD:SD : := WD , . "
, WD .WD : := FBFB ::= {AVS} ; .
.
.
; { Avs  }AVS : := A opV, .
.
- ,A  op VV : := ATM I FB  I VARATM : := atom ; - - .
; a tomVAR : := '_' followed by any stringA : := any alpha-numeric stringop : : :  = I *=A WD may consist of two types of disjunctiverepresentation (local or complex disjunction) in2In this section and in the paper we refer to MPRO asthe analysis tool (Maas, 1996).
MPRO is very powerful: ityields more than 95% correct morphological nalysis andlemmas of arbitrary German and English text.a number of different levels.
Local disjunction isan alternation of atomic values, complex disjunc-tion is an alternation of complex features (FB) .Which of the disjunctive representations is cho-sen depends on the one hand on the expressiverequirements (i.e.
no feature dependencies canbe expressed with local disjunctions) and on theother hand on the linguistic assumptions of themorphological nalysis.Word descriptor WD "der ' :' l u=d_ar t ,  c=w, sc=ar t ,  fu=def \]I'gen= , \] fgsn= ,\] f 1(- case=d;g)  tcase-- 'n)  ( case=g j j~ case--n, ' case=g;djagr= ~g=m, ; nb=sg,(nb=sg I ,g=fBoth types of disjunction are shown in the rep-resentation of the German article "der ' .
A firstlevel of disjunction occurs on the level of the worddescriptors.
Different analyses (as a determiner( lu=d_e.rt) and as a relative pronoun ( lu=d_re l ) )are separated by a semicolon ';'.
The second levelof disjunction occurs in the feature "agr ' ,  whichhas a complex disjunction as its value.
The feature"case"  in the first complex disjunctor has a localdisjunction (g ;d)as  its value.
The word "der"  hasseven different interpretations which axe meltedtogether here by means of the two different typesof disjunction.Note that we do not need variable binding betweendifferent attributes of the same FB 3. because wepresume that each attribute in a (morphological)FB  expresses a different piece of information (itthus has a different ype).3 The FormalismThe formalism we shall describe in this section ap-plies a set of rules in a predefmed order to sentencedescriptors SD thereby modifying selected worddescriptors WD.
The modified SDs are returnedas a result.
For each SD, each rule is repeatedlySin many theories and formalisms (e.g.
HPSG, CAT2(Sharp and Streiter, 1995)) different attributes in a FB canbe forced to always have the same values by assigning thesame variable as their values (they share the same struc-ture).
However, these approaches allow structure sharingand vl~able binding only among equal types.Carl and Schmidt- Wigger 258 KURDmIImmmmm|||mII1IIIIapplied, starting from the first WD.A rule essentially consists of a description partand an action part.
The description consists of anumber of conditions that must match successiveWDs.
While matching the description part ofa rule onto a SD, WDs are marked in order tobe modified in the action part.
A rule fails if acondition does not match.
In this case the actionpart of the rule is not activated.
The action partis activated if all conditions are satisfied.
Actionsmay modify (Kill, Unify, Replace or Delete) a WDor single features of it.A condition of a rule can either match an intervalor it can match a count of the WD.
In the for-mer case, one set of tests must be true.
In thelatter case two sets of tests must be true, one foran external interval and one for a count of aninternal interval.3.1 Some examplesGerman verbs have detachable prefixes that canbe homonyms to prepositions.
Morphologicalanalysis thus generates two interpretations forsuch a string.
However, the syntactic positionof prefixes and prepositions within a sentence isdifferent.
While prepositions occur as the headin prepositional phrases and thus ate always fol-lowed by a nominal phrase or a pronoun, detachedprefixes occur at the end of the matrix sentence,thus fonowed by a punctuation mark or a coordi-nator.
The following rule disambiguates a prefixat the end of a sentence, i.e the interpretation asa preposition ({c=w,sc=p}) shMi be deleted fromthe WD.
(1) Disambiguate_Prefix =The rule 1 consists of two conditions (separatedby a comma) in the description part and oneact in the action part.
It illustrates the capac-ity of the formalism to express disjunction andconjunction at the same time.
The first conditionmatches a preposition (~c=w, so=p}) and a pre-fix (~c=vpref}).
That is, the matched WD isexpected to be ambiguous with respect to itscategory.
Feature cooccurrences are requited inthe first test, where both features c=w and sc=pmust occur in conjunction in (at least) one in-terpretation of the matched WD.
The existencequantifier e preceding the FB means that thereis an appropriate interpretation i the WD, i.e.there is a non-empty intersection of FB andWD.
The second condition consists of one testonly.
The FB matches an end-of-sentence it m(~sc--punct;corma}).
Here, the all quantifier arequites the WD to be a subset of the FB  i.e.there is no interpretation i the WD which is notan end-of-sentence it m.A WD for which the first condition is true ismarked by the marker ~A'.
The rule applies if thesecond condition is true for the following WD.The act/on part has one consequence that con-sists of one act.
The WD which has been markedin the description part is unified with the FB(~c=vpref}) of the act.
This results in the un-ambiguous identification of the prefix because theprepositional nalysis is ruled out.An example of a rule that disambiguates theagreement of a (German) noun phrase is givenbelow (2).
The rule can be paraphrased as fol-lows: for all sequences of WD that have a uni-fyable agreement feature ({affr= lGlt~) and thatconsist of an article (~c=w, sc=ar~}) followed byzero or more adjectives (*~c=adj}) followed byone noun (~c--noun~): unify the intersection ofthe agreement ({agr=_AGlt}) into the respectivefeatures of the marked word descriptors.
(2) Disambiguate_Noun_Phrase =Ae { c=, .
so=ar t ,  ag-z=_A,It}.
*Aa {c=adj .
agr=_lGE}.Ae { c='noun, agr---_A,It} :Au {agr=_AGP,.
}The description part of rule (2) has threeconditions.
Each condition matches an intervalof the WDs.
The second condition can possiblybe empty since it has the irleene star scope ('*').All WDs for which the test is true are marked bythe maxker "A" and thus undergo the same act inthe action part.The formalism allows the use of variables (e.g._AGR) for the purpose of unification.
WDs canonly be modified by instantiatious of variables i.e.variable bindings may not be transferred into theWD.
Each time a rule is activated, the variablesare reinitialized.Carl and Schmidt-Wigger 259 KURDThe rule (2) matches a noun phrase, thereby dis-ambiguating the agreement.
With slight changes,the output  of the rule can be turned into a shallowparse:(3) Reduce_Noun-Phrase :Ae {c=w, sc=ar t ,  agr=_AGR},*Aa {c=ad j ,  agr=_tGR},?Be :BrThe operator "r" in the second conseqence ofthe rule (3) replaces the category value in thenoun node by a new one (~c=np}) .
The de-terminer node ({?=w,sc=art})  and all adjectivenodes ({c=adj})  are removed ('killed') by meansof the kill operator ILk{} from the sentence de-scriptor such that only the NP node is printed asa result.Style checking has often to deal with thecomplexity 4 of a phrase.
Therefore, it makes useof another type of rules where the presence of anumber of word interpretations in a certain countis checked.
For instance in technical texts, it maybe advisable not to have more than eight wordsbefore the finite verb.
The rule (4) unifies anappropriate warning number into the fixst finiteverb analysis if more than eight words have oc-curred before it.
(4) Verb_Position =e {mlr r= 1, v t  yp ' - - f iv},8e {sc '=comma; c i t  ; s lash}  \]& {vtyp?
=f iVe{  ?
?=verb} ,The first condit ion matches the first WD in a sen-tence ({imrr=1}) if it has an interpretation differ-ent f rom a finite verb ({vtyp '=f iv}) .
The secondcondit ion is a count that matches a sequence of4 The complexity of a phrase is a ~net lon  of di~erent pa-rameters  uch as its length, the number of lexic-1 elements,the complexity of its structure.
The definitions differ fromone author  to the next.
In our calculation of complexity,only length and number  of lexical elements Lre taken into8,ccoux l t .WDs other than finite verbs.
This is expressedby the external test ({vtyp '=f iv} ;{c '=verb})following the vertical bar.
The internal test({sc '=comma;c i t  ;sZash}), e.g.
the part beforethe vertical bat counts the number of words inthe count different from punctuation marks andslashes.
The count is true if eight or more suchinternal  teas  are true.
The motivation for thethird condit ion is to put the marker "A" on thefinite verb such that it can be unified with thewarning in the action part.
The warning can beused by further tools to select an appropriate mes-sage for the user.3.~ Formal  Def in i t ionThe formal definition of rule syntax is given be-low:Definition of rule:?
/'u~e ::~-descr ::=condition ::=interval ::=Coun.,~ ::~__te$~ : :=nazr~e'=' descr ' : '  actioncondition1 ',' condition~ .
.
.interval \] count\[~o~\]\[~arker\] te~t ,  te~t  .
.
.
.nu~r~ in~ervallnt ' \[ '  intervale=tquantif ier FBact ion  : := conseq;  ',' conseq=conseq : := Tr~zrker act;  act= .
.
.act ::= operator FBsco~ ::= ^ I + \[ * I -marker ::= t \ [ .
.
.
I Zhum ::= 0 \ [ ' .
- I  99operetor ::= k I u \[ r \[quantif ier ::= e \[ aWhether or not a rule applies (i.e.
its actionpart is executed or not) depends on whetherits conditions match.
Each condition matchesthe longest possible sequence of WDs and, oncematched, other segmentations axe not considered.We do not foresee backtracking or multiple so-lution generation.
The length of an intervaldepends on the scope of the interval  and theoutcome of the tests.
In accordance with manylinguistic formalisms we distinguish between fourscopes.A The interval  matches one optional word.
* The interval  matches zero or more words.+ The interval  matches at least one word.- The interval  matches one and only one word.This is the default value for the scope.Carl and Schmidt- Wigger 260 KURDIIlIIllIIlIIIIIIIIsIsIsIs!1IIIIi lIIA test maps a FB onto a WD.
Whether a testis true or false depends on the quantif ier of thetest.
The ezistence quantif ier "e" and theall quanti f ier  "a" are implemented as follows:e The test is true if there is a non-empty subsetbetween the FB and the current WD.
TheFB describes a possible interpretation of thecurrent WD.
The test is true if there is atleast one interpretation i  the current WDthat is unifyable with FB.a The test is true if the current WD is a subsetof the FB.
The FB describes the necessaryinterpretation of the current WD.
The testis true if the FB subsumes all interpretationsof the current WD.All consequences of the action part are executedif the description part matches.
The acts of aconsequence apply to the marked WD.
The fol-lowing operators are currently implemented:k kills the marked WD.u unifies FB into the marked WD.r replaces the values of the features in themarked WDs by those of FB.d deletes the specified features in FB  f.tom themarked WD.Apart from an interval, a condition can consistof a count.
The length of a count is controlledby a set of ezternal tests (intervalezt), i.e.
theright border of the count is either the end of theSD or a WD where one of the ezternal tests isfalse.
The outcome of a count (whether it is trueor false) is controlled by a set of internal tests(intervali,~t).
For a count to be true, at least thespecified number of internal tests must be true.4 Re la ted  WorkIn order to compare KURD with other postmor-phological processing systems, one can distinguishbetween the formali.~ms' design, the implementa-tion of a grammar and the tasks for which thesystem is designed.
Most such comparisons (e.g.
(Abney, 1996)) are based on processing time, ac-curacy and recall, which in fact do not differenti-ate between the strength of the form~l/~m and thestrength of the grammar actually implemented.In this section we want to compare the capaxitiesof KURD to another formalisms by describing itsformal characteristics for each possible step in thechain of NLP application.
Two concrete applica-tions will be presented in the following section.Similar to KURD, CGP of the 'Helsinki' project(el.
(Karlsson, 1990)) is a system working onmorphologically analysed text that contains lex-ical ambiguities.
KURD and CGP are somewhatalike with respect to the basic assumptions onsteps one would need to disambiguate morpho-logical descriptions: an ambiguous word (WD) isobserved in its context.
If necessary it has tobe acertained that the context itself is not am-biguous.
In a fitting context the disambiguationoperation is triggered.
The realization of theseassumptions in the two formalisms differs in thefollowing features:In KURD ...?
a rule definition is based on pattern matchingof a specific context, in which the action'sfocus is than selected.?
the scope of disambiguation is fixed by meansof markers.
This allows more than one opera-tion to be defined in the marked scope (WDs)at a time, and the same operation to be ap-plied to more than one word (WD).?
the context of an operation and the opera-tion itself are defined in separate parts of therule.
Each part may contain a distinct set offeatures while in CGP, all features pecifiedfor the focused word are subject to the samedisambiguation.?
variable binding is supported.
Multiple in-terpretations of several words can be disam-biguated by unification as exemplified in rule(2).
In CGP, rule batteries are necessary forthis task, and disambiguation of the combi-nation of features of more than two WD isnot possible.?
unbounded ependencies can be modeled bymeans of intervals.
We are not sure whetherthese can be modeled in CGP by means ofrelative positions.In CGP ...?
the focus of the rule is positioned before theleft- and rightward context is described.Carl and Schmidt-Wigger 261 KURD?
one can look backwards in a context.
This isnot always possible in KURD due to undei-specification in the morphological input.?
one can define sets of features.
In KURD,this can be modeled by means of feature dis-junction; thus more freedom in KURD, butless consistency.?
one can discard a reading when the contextis NOT re~li~ed.
In KURD, these possibilitycan only be modeled using two rules and ameta-feature.?
there is a specific clause boundary mode.
InKURD, clause boundaries have to be enumer-ated as simple features.To summarize the comparison, backward look-ing seems basically the only difference with whichCGP has an advantage over KURD in terms of ex-pressiveness, while variable binding gives KURDadvantage over CGP.
In terms of user-friendliness,the systems choose two different directions.
InKURD the use of markers and rule separationinto a description part and an action part mayreduce the number of rules, while CGP allows forthe simplification of rules by means of sets or theclause boundary mode.The next step in processing moves from the treat-ment of words towards the treatment of wordgroups i.e.
to parsing.
Traditional parsers arefull parsers building all possible deep parse treesover the fiat input structure.
Weaker models, usu-ally referred to as 'shallowparsers' (cf.
(Karlssonand Karttunen, 1997)), allow for partial parses,for trees of depth of one or for one result only.The output data structure of a parser is generallya bracketed structure which preserves the origi-nal morphological fiat structure inside the outputstructure.
Some shallow parsers, however such asCGP, assign syntactic functions to the words of asentence and renounce the representation of thedependency structure.Parsing with KURD results in a one level repre-sentation where the nodes (WD) can be enrichedwith information concerning their syntactic func-tions.
The insertion of brackets is not supportedin KURD but recognized phrases can be reducedto one node if they are part of higher level phrases.Also recursivity of language has to be approx-imated by means of iterative, multiple applica-tion of (not necessarily the same) rule set.
ThusKURD has to be classified as a typical shallowparsing system, also Mlowing for partial parsing.The last step in the NLP processing chain is apractical application of the linguistic knowledgefor a specific task.
The next section describessuch an application of KURD for style checking.It does not rely on a full disambiguation a d syn-tactic tagging of the morphological nalysis.
Dis-ambiguation is undertaken only when necessary.We believe that 100% disambiguation is too ex-pensive for a rule based system 5 especially whenit has to be adapted to each new text type.
In thenext section, we show that good results can alsobe obtained on ambiguous input.5 Style checkingIn this section we want to describe an appli-cation of KURD for style checking of technicaldocuments.
The application has been developedand tested for a car manufacturing environment(Hailer, 1996).In technical documentation, the quality of the textin terms of completeness, correctness, consistency,readability and user-frlend\]hess i  a central goal(Fottner-Top, 1996).
Therefore completed ocu-ments undergo a cycle of correction and re-editing.As our experiments in this production processhave shown, 40% of re-editions in technical doc-uments are motivated by stylistic considerations(compared to corrections of orthographies, yn-tax, content or layout).On the basis of the observed re-editions, stylisticguidelines have been formulated, such as:1.
Do not use compounds made up of three ormore elements.2.
Do not use the passive voice if there is aJaexplicit agent.3.
Long coordinations hould be represented inlists.The compilation of these guidelines has influencedthe architecture of KURD to a certain extent.Most scientists correlate the readability of a sen-tence with its complexity, defined often by length,5 CGP contained 400 rules for 90~ disamhiguation qual-ity (c~.
(Karlsson, 1990)).
In order to reach nearly 100%,this number increased up to 1109 rules.., cf.
(Karlsson andKarttunen, 1997)Carl and Schmidt-Wigger 262 KURDmmmmssssmmmmssmmIimIIIIII!1IIIInumber of content words and/or structural em-bedding.
Whereas such information is not com-mon in NLP applications, its calculation can bemodeled in KURD through the coun?
mechanism.The basic idea of Using the formalism for stylechecking is exemplified by rule (4): a morphosyn-tactic pattern is recognized by a specific rule uni-fying a warning number into the marked WD.This number triggers an appropriate message infurther processing steps that signals the use of anundesirable formulation.
As a result, the user canameliorate that part of the text.For better results, the style checking applicationmakes use of the disambiguating power of KURD;i.e.
some tagging rules (e.g.
rule (1)) precede theapplication of the style rules.The system cont~in~ at its present stage 36 stylewarnings which axe expressed by 124 KURD rules:an average of 3 to 4 rules for each style problem.The warnings can be classified as follows (for ex-amples, see above):1.
One word warnings (10 types of warning):These warnings can either recognize the com-plex internal structure of compound words, orforbid the use of a certain word.
For the lattertask, style checking moves towards checkingagainst he lexicon of a Controlled Language.This task should not be over-used, a lexicallydriven control mechanism seems to be moreadequate.2.
S t ructure - l inked  warnings (19 types ofwarning):These warnings react to complex syntacticstructures and trigger the proposition of a re-formulation to the writer.
They are thereforethe most interesting for the user and for therule writer.3.
Count ing  warnings (7 types of warning):These warnings measure the complexity of asentence or of a sub-phrase by counting itsdements.
Complexity is a central topic in thereadability literature (see footnote 5), but itdoes not allow the triggering of a concretereformulation proposition to the user.Most structure-linked warnings require more thanone KURD rule.
This is due to the fact that thepattern to be recognized can occur in differentforms in the text.
As shown by the following ex-ample (5), two rules would be necessary to detectCarl and Schmidt-Wigger 263the 'Future II' in German, because word order ofverbal phrases in main sentences differs from thatin subordinate clauses.
(5) Der Mann wird schnell gekommenTl~e man will quickly comesein.be.Er weifl, daft der Mann schnenHe knows, ~h~zt $he man quicklygekommen sein wird.come be will.For recursive phenomena KURD's fiat matchingapproach is somewhat inconvenient.
In example6, rule 2 applies to die Werkzeuge, although thearticle die should in fact be \]inked to Arbeiter,while Werkzeuge stands in a bare plural.
(6) die Werkzeuge herstelhnden Arbeiterthe tools building workersTo handle such problems, one can try to enumer-ate the dements which can be contained betweenthe two borders of a pattern to be recognized.
Butthis approach mostly yields only approximate r -sults because it does not respect he generativecapacity of language.However, most of the style warnings have beeneasily implemented in KURD, as the appropriatepattern can still often be recognized by one or twoelements at its borders.The system has been tested against an analyzedcorpus of approx.
76,000 sentences.
More than5,000 sentences to be ameliorated were detectedby KURD.
757 of them were selected manuallyto control the validity of the rules of warningclass 2 and 3: In 8% (64), the warnings hadbeen applied incorrectly.
In these cases, syntac-tic structure could not adequately be described inthe KURD formalism.
These 8%, however, onlyreflects the erroneous results of warning classes 2and 3.
They do not cover sentences selected bysimple rules such as those of class 1.
Rules ofwarning class 1 are responsible for 20% of the au-tomatically detected sentences to be ameliorated.These rules do never apply incorrectly.In another test, a text of 30 pages was anno-tated by a human corrector and the KURD stylechecker.
The results were compared.
ABout 50%KURDof the human annotations were also annotatedby the computer with a comparable ameliorationproposition.
35% resisted an automatic diagno-sis, either because the recursive structure couldnot adequately be modeled by the style checkingrules, or because the information calculated by themorphological nalysis was not sufficient (i.e.
nosemantic information was available).
By writingnew style rules, a 65% recall could be achieved.The precision of the style checker, on the otherhand, seems to be a critical point.
The checkerproduces three times more automatic warningsthan the human corrector.
This is mainly dueto the 'counting rules', because the count limitswere often too low.
The choice of acceptable lim-its is still under discussion.It has been shown that pattern recognition couldbe a valuable means for applications needing atleast basic information on syntactic structures andthat KURD could be a tool for realizing these ap-plications.6 Chunk  Reduct ion  andRef inementIn the framework of the CBAG s module (el.
(Carl, 1998) in this volume) KURD is used inseveral components.
CBAG is an example basedtranslation engine whose aim it is to be used as astand-alone Example Based Machine T~anslationsystem (EBMT) or to be dynamically integratedas a f~ont-end into a Rule Based Machine T~aus-lation system.The CBAG module is divided into three sub-modules:?
The Case Base Compilation module (CBC)compiles a set of bilingual SD equivalencesinto a case base thereby inducing case ab-stractions from the concrete SD.
Case ab-stractions ensure a greater ecall and are thusneeded for a better coverage of the system.?
The Case Based Analysis module (CBA) de-composes and reduces an input SD into a setof chunks according to the cases in the casebase.
Reduced sequences are more likely tomatch a case in the case base because theyare shorter abstractions from the original se-quence of WDs.6 CBAG stands for Case Based Analysis and Generation?
The Case Based Generation module (CBG)re-generates equences of taxget languageWDs from the reduced chunks.
In the re-finement process \]exical and grammatical in-formation axe merged together into WDs.KURD is used for two different asks in these mod-ules.
In the CBC module and in the CBA module,KURD performs chunk reduction and in the CBGmodule, KURD performs chunk refinement.In order to do chunk reduction, the input SD isfirst decomposed into a sequence of chunks accord-ing to the entries in the case base.
KURD reducesthose chunks which match a case in the case baseinto one chunk descriptor according to the schemaof rule 3.In the refinement phase, KURD merges lexicaland grammatical information which is extractedfrom two different sets of cases.
These rules useall types of operators that axe available in KURD.7 Imp lementat ionThe KURD formalism is implemented in C andcompilable under gcc.
It runs on spazc worksta-tions and is currently ported to PC (with gcc).8 Conc lus ionIn this paper we have presented a constraint-basedformalism (KURD) that manipulates morphologi-cal analysis in order to kill, unify, replace or deleteparts of the structure.
The formalism reafizesa pattern matching approach that is suitable forshallow and/or partial NLP.First, we give a formal definition of the data struc-ture and of the formalism and discuss a few exam-ple rules in order to present he capacities of theformalism.KURD is then compared to another slmilaxformalism (CGP) and it is found that bothformalisms have a comparable expressiveness.Whereas in KURD the use of variables and mark-ers makes the rule writing easier, CGP allows forthe simplification of rules by means of sets or theclause boundary mode.Two applications of KURD axe presented.
In twolaxge-scale xperiments it could be shown thatstyle-checking can be realized by KURD with areasonable result.
In a small experiment it isshown that KURD can be used for shallow parsingand refinement in a MT application.Carl and Schmidt- Wigger 264 KURDIIIIIIIIIIIIIIIIi lIIIIIIIIIIIII!II9 AcknowledgementWe would like to thank Munpyo Hong and CathPease for valuable comments.Re ferencesSteven Abney.
1996.
Partial Parsing via Finite-State Cascades.
In Proceedings of the E$SLLI '96Robnst Parsing Workshop~.Michad Carl.
1998.
A constructivist approach toMT.
In Proceedings of NeMLaP, Sydney.Thierry Declerek and Judith Klein.
1997.
EinEmail-Korpus zur Entwicldung und Evaluierungder Analysekomponente eines Termin-vereinbaxungssystems.
In Konferenzbeitr~ge d r6.Fachtagung der DGfS-CL.Claudia Fottner-Top.
1996.
Workshop: Erstel-lung yon verstgndlicher nnd benutzerfreundlichertechnischer Dokumentation.
Working paper, In-stitut ffir Technische Literatur, M~nchen.Johann Hailer.
1996.
MULTILINT, A Techni-cal Documentation System with Mttltilingual In-telligence.
In Translating and the Computer 18,London.
Aslib, The Association for InformationManagement, Information House.Fred Kaxlsson and Lauri Karttunen.
1997.
Sub-sentential processing.
In G.B.
Varile and A. Zam-polll, editors, Survey of the State of the A~t in Hu-man Language Technology, volume Vol.
XII+XIIIof Linguistiea Computazionale.
Giaxdinl Editori eStampatori, Pisa.Fred Kax\]sson.
1990.
Constraint grammax as aframework for parsing running text.
In COLING-90, volume 3, pages 168-173.Heinz-Dieter Maas.
1996.
MPRO - Ein Systemzur Analyse und Synthese deutscher WSrter.
InRoland Hausser, editor, Linguistische Verifika-~ion, Spraehe und Information.
Max NiemeyerVerlag, Tfibingen.Randall Sharp and Oliver Streiter.
1995.
Ap-plications in Multilingual Machine Translation.In Proceedings of The Third International Con-ference and Ezhibi~ion on Practical Applica-tions of Prolog, Paris, 4th-Tth April.
URL:http://www.iai.uni-sb.de/cat2/docs.html.Carl and Schmidt-Wigger 265 KURDmmmmmmmmmm
