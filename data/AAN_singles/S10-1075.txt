Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 337?340,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsUSFD2: Annotating Temporal Expresions and TLINKs for TempEval-2Leon DerczynskiDept of Computer ScienceUniversity of SheffieldRegent Court211 PortobelloSheffield S1 4DP, UKleon@dcs.shef.ac.ukRobert GaizauskasDept of Computer ScienceUniversity of SheffieldRegent Court211 PortobelloSheffield S1 4DP, UKrobertg@dcs.shef.ac.ukAbstractWe describe the University of Sheffieldsystem used in the TempEval-2 challenge,USFD2.
The challenge requires the au-tomatic identification of temporal entitiesand relations in text.USFD2 identifies and anchors temporalexpressions, and also attempts two of thefour temporal relation assignment tasks.A rule-based system picks out and an-chors temporal expressions, and a max-imum entropy classifier assigns temporallink labels, based on features that includedescriptions of associated temporal signalwords.
USFD2 identified temporal expres-sions successfully, and correctly classifiedtheir type in 90% of cases.
Determin-ing the relation between an event and timeexpression in the same sentence was per-formed at 63% accuracy, the second high-est score in this part of the challenge.1 IntroductionThe TempEval-2 (Pustejovsky and Verhagen,2009) challenge proposes six tasks.
Our systemtackles three of these: task A ?
identifying time ex-pressions, assigning TIMEX3 attribute values, andanchoring them; task C ?
determining the tempo-ral relation between an event and time in the samesentence; and task E ?
determining the temporalrelation between two main events in consecutivesentences.
For our participation in the task, wedecided to employ both rule- and ML-classifier-based approaches.
Temporal expressions are dealtwith by sets of rules and regular expressions, andrelation labelling performed by NLTK?s1 maxi-mum entropy classifier with rule-based processingapplied during feature generation.
The features(described in full in Section 2) included attributes1See http://www.nltk.org/ .from the TempEval-2 training data annotation,augmented by features that can be directly derivedfrom the annotated texts.
There are two main aimsof this work: (1) to create a rule-based tempo-ral expression annotator that includes knowledgefrom work published since GUTime (Mani andWilson, 2000) and measure its performance, and(2) to measure the performance of a classifier thatincludes features based on temporal signals.Our entry to the challenge, USFD2, is a succes-sor to USFD (Hepple et al, 2007).
In the rest ofthis paper, we will describe how USFD2 is con-structed (Section 2), and then go on to discussits overall performance and the impact of someinternal parameters on specific TempEval tasks.Regarding classifiers, we found that despite us-ing identical feature sets across relation classifi-cation tasks, performance varied significantly.
Wealso found that USFD2 performance trends withTempEval-2 did not match those seen when clas-sifiers were trained on other data while perform-ing similar tasks.
The paper closes with commentsabout future work.2 System DescriptionThe TempEval-2 training and test sets are parti-tioned into data for entity recognition and descrip-tion, and data for temporal relation classification.We will first discuss our approach for temporal ex-pression recognition, description and anchoring,and then discuss our approach to two of the re-lation labelling tasks.2.1 Identifying, describing and anchoringtemporal expressionsTask A of TempEval-2 requires the identificationof temporal expressions (or timexes) by defininga start and end boundary for each expression, andassigning an ID to it.
After this, systems shouldattempt to describe the temporal expression, de-termining its type and value (described below).337Our timex recogniser works by building a set ofn-grams from the data to be annotated (1 ?
n ?5), and comparing each n-gram against a hand-crafted set of regular expressions.
This approachhas been shown to achieve high precision, with re-call increasing in proportion to ruleset size (Hanet al, 2006; Mani and Wilson, 2000; Ahn et al,2005).
The recogniser chooses the largest possiblesequence of words that could be a single temporalexpression, discarding any sub-parts that indepen-dently match any of our set of regular expressions.The result is a set of boundary-pairs that describetemporal expression locations within documents.This part of the system achieved 0.84 precisionand 0.79 recall, for a balanced f1-measure of 0.82.The next part of the task is to assign a typeto each temporal expression.
These can be oneof TIME, DATE, DURATION, or SET.
USFD2only distinguishes between DATE and DURATIONtimexes.
If the words for or during occur in thethree words before the timex, the timex ends withan s (such as in seven years), or the timex is a bi-gram whose first token is a (e.g.
in a month), thenthe timex is deemed to be of type DURATION; oth-erwise it is a DATE.
These three rules for deter-mining type were created based on observation ofoutput over the test data, and are correct 90% ofthe time with the evaluation data.The final part of task A is to provide a valuefor the timex.
As we only annotate DATEsand DURATIONs, these will be either a fixedcalendrical reference in the format YYYY-MM-DD, or a duration in according to the TIMEX2standard (Ferro et al, 2005).
Timex strings oftoday or now were assigned the special valuePRESENT REF, which assumes that today is be-ing used in a literal and not figurative manner, anassumption which holds around 90% of the timein newswire text (Ahn et al, 2005) such as thatprovided for TempEval-2.
In an effort to calcu-late a temporal distance from the document cre-ation time (DCT), USFD2 then checks to see ifnumeric words (e.g.
one, seven hundred) are inthe timex, as well as words like last or next whichdetermine temporal offset direction.
This distancefigure supplies either the second parameter to aDURATION value, or helps calculate DCT offset.Strings that describe an imprecise amount, such asfew, are represented in duration values with an X,as per the TIMEX2 standard.
We next search thetimex for temporal unit strings (e.g.
quarter, day).Table 1: Features used by USFD2 to train a tem-poral relation classifier.Feature TypeFor eventsTense StringAspect StringPolarity pos or negModality StringFor timexesType Timex typeValue StringDescribing signalsSignal text StringSignal hint Relation typeArg 1 before signal?
BooleanSignal before Arg 2?
BooleanFor every relationArguments are same tense BooleanArguments are same aspect BooleanArg 1 before Arg 2?
BooleanFor every intervalToken number in sentence / 5 IntegerText annotated StringInterval type event or timexThis helps build either a duration length or an off-set.
If we are anchoring a date, the offset is appliedto DCT, and date granularity adjusted according tothe coarsest temporal primitive present ?
for ex-ample, if DCT is 1997-06-12 and our timex is sixmonths ago, a value of 1997-01 is assigned, as it isunlikely that the temporal expression refers to theday precisely six months ago, unless followed bythe word today.Where weekday names are found, we usedBaldwin?s 7-day window (Baldwin, 2002) to an-chor these to a calendrical timeline.
This tech-nique has been found to be accurate over 94%of the time with newswire text (Mazur and Dale,2008).
Where dates are found that do not specifya year or a clear temporal direction marker (e.g.,April 17 vs. last July), our algorithm counts thenumber of days between DCT and the next oc-currence of that date.
If this is over a limit f ,then the date is assumed to be last year.
This isa very general rule and does not take into accountthe tendency of very-precisely-described dates tobe closer to DCT, and far off dates to be looselyspecified.
An f of 14 days gives the highest per-formance based on the TempEval-2 training data.Anchoring dates / specifying duration lengthswas the most complex part of task A and our na?
?verule set was correct only 17% of the time.338Table 2: A sample of signals and the TempEval-2temporal relation they suggest.Signal phrase Suggested relationprevious AFTERahead of BEFOREso far OVERLAPthereafter BEFOREin anticipation of BEFOREfollows AFTERsince then BEFOREsoon after AFTERas of OVERLAP-OR-AFTERthroughout OVERLAP2.2 Labelling temporal relationsOur approach for labelling temporal relations (orTLINKs) is based on NLTK?s maximum en-tropy classifier, using the feature sets initially pro-posed in Mani et al (2006).
Features that de-scribe temporal signals have been shown to givea 30% performance boost in TLINKs that em-ploy a signal (Derczynski and Gaizauskas, 2010).Thus, the features in Mani et al (2006) are aug-mented with those used to describe signals de-tailed in Derczynski and Gaizauskas (2010), withsome slight changes.
Firstly, as there are no spe-cific TLINK/signal associations in the TempEval-2 data (unlike TimeBank (Pustejovsky et al,2003)), USFD2 needs to perform signal identifi-cation and then associate signals with a temporalrelation between two events or timexes.
Secondly,a look-up list is used to provide TLINK label hintsbased on a signal word.
A list of features em-ployed by USFD2 is in Table 1.We used a simplified version of the approachin Cheng et al (2007) to identify signal words.This involved the creation of a list of signalphrases that occur in TimeBank with a frequencyof 2 or more, and associating a signal from this listwith a temporal entity if it is in the same sentenceand clause.
The textually nearest signal is chosenin the case of conflict.As this list of signal phrases only contained 42entries, we also decided to define a ?most-likely?temporal relation for each signal.
This was doneby imagining a short sentence of the form event1?
signal ?
event2, and describing the type of re-lation between event 1 and event 2.
An excerptfrom these entries is shown in Table 2.
The hintfrom this table was included as a feature.
Deter-mining whether or not to invert the suggested rela-tion type based on word order was left to the clas-sifier, which is already provided with word orderfeatures.
It would be possible to build these sug-gestions from data such as TimeBank, but a num-ber of problems stand in the way; the TimeML andTempEval-2 relation types are not identical, wordorder often affects the actual relationship type sug-gested by a signal (e.g.
compare He ran homebefore he showered and Before he ran home, heshowered), and noise in mined data is a problemwith the low corpus occurrence frequency of mostsignals.This approach was used for both the intra-sentence timex/event TLINK labelling task andalso the task of labelling relations between mainevents in adjacent sentences.3 DiscussionUSFD2?s rule-based element for timex identifica-tion and description performs well, even achievingabove-average recall despite a much smaller ruleset than comparable and more complex systems.However, the temporal anchoring component per-forms less strongly.
The ?all-or-nothing?
metricemployed for evaluating the annotation of timexvalues gives non-strict matches a zero score (e.g.if the expected answer is 1990-05-14, no reward isgiven for 1990-05) even if values are close, whichmany were.In previous approaches that used a maxi-mum entropy classifier and comparable featureset (Mani et al, 2006; Derczynski and Gaizauskas,2010), the accuracy of event-event relation classi-fication was higher than that of event-timex clas-sification.
Contrary to this, USFD2?s event-eventclassification of relations between main eventsof successive sentences (Task E) was less accu-rate than the classification of event-timex rela-tions between events and timexes in the same sen-tence (Task C).
Accuracy in Task C was good(63%), despite the lack of explicit signal/TLINKassociations and the absence of a sophisticatedsignal recognition and association mechanism.This is higher than USFD2?s accuracy in TaskE (45%) though the latter is a harder task, asmost TempEval-2 systems performed significantlyworse at this task than event/timex relation classi-fication.Signal information was not relied on by manyTempEval 2007 systems (Min et al (2007) dis-339cusses signals to some extent but the system de-scribed only includes a single feature ?
the sig-nal text), and certainly no processing of this datawas performed for that challenge.
USFD2 beginsto leverage this information, and gives very com-petitive performance at event/timex classification.In this case, the signals provided an increase from61.5% to 63.1% predictive accuracy in task C. Thesmall size of the improvement might be due to thecrude and unevaluated signal identification and as-sociation system that we implemented.The performance of classifier based approachesto temporal link labelling seems to be levellingoff ?
the 60%-70% relation labelling accuracy ofwork such as Mani et al (2006) has not beengreatly exceeded.
This performance level is stillthe peak of the current generation of systems.
Re-cent improvements, while employing novel ap-proaches to the task that rely on constraints be-tween temporal link types or on complex linguisticinformation beyond that describable by TimeMLattributes, still yield marginal improvements (e.g.Yoshikawa et al (2009)).
It seems that to breakthrough this performance ?wall?, we need to con-tinue to innovate with and discuss temporal re-lation labelling, using information and knowl-edge from many sources to build practical high-performance systems.4 ConclusionIn this paper, we have presented USFD2, a novelsystem that annotates temporal expressions andtemporal links in text.
The system relies onnew hand-crafted rules, existing rule sets, machinelearning and temporal signal information to makeits decisions.
Although some of the TempEval-2tasks are difficult, USFD2 manages to create goodand useful annotations of temporal information.USFD2 is available via Google Code2.AcknowledgmentsBoth authors are grateful for the efforts of theTempEval-2 team and appreciate their hard work.The first author would like to acknowledge theUK Engineering and Physical Science ResearchCouncil for support in the form of a doctoral stu-dentship.2See http://code.google.com/p/usfd2/ .ReferencesD.
Ahn, S.F.
Adafre, and MD Rijke.
2005.
Towardstask-based temporal extraction and recognition.
InDagstuhl Seminar Proceedings, volume 5151.J.A.
Baldwin.
2002.
Learning temporal annotation ofFrench news.
Ph.D. thesis, Georgetown University.Y.
Cheng, M. Asahara, and Y. Matsumoto.
2007.Temporal relation identification using dependencyparsed tree.
In Proceedings of the 4th InternationalWorkshop on Semantic Evaluations, pages 245?248.L.
Derczynski and R. Gaizauskas.
2010.
Using sig-nals to improve automatic classification of temporalrelations.
In Proceedings of the ESSLLI StuS.
Sub-mitted.L.
Ferro, L. Gerber, I. Mani, B. Sundheim, and G. Wil-son.
2005.
TIDES 2005 standard for the annotationof temporal expressions.
Technical report, MITRE.B.
Han, D. Gates, and L. Levin.
2006.
From languageto time: A temporal expression anchorer.
In Tem-poral Representation and Reasoning (TIME), pages196?203.M.
Hepple, A. Setzer, and R. Gaizauskas.
2007.USFD: preliminary exploration of features and clas-sifiers for the TempEval-2007 tasks.
In Proceedingsof SemEval-2007, pages 438?441.I.
Mani and G. Wilson.
2000.
Robust temporal pro-cessing of news.
In Proceedings of the 38th AnnualMeeting on ACL, pages 69?76.
ACL.I.
Mani, M. Verhagen, B. Wellner, C.M.
Lee, andJ.
Pustejovsky.
2006.
Machine learning of tem-poral relations.
In Proceedings of the 21st Inter-national Conference on Computational Linguistics,page 760.
ACL.P.
Mazur and R. Dale.
2008.
Whats the date?
Highaccuracy interpretation of weekday.
In 22nd Inter-national Conference on Computational Linguistics(Coling 2008), Manchester, UK, pages 553?560.C.
Min, M. Srikanth, and A. Fowler.
2007.
LCC-TE:a hybrid approach to temporal relation identificationin news text.
In Proceedings of the 4th InternationalWorkshop on Semantic Evaluations, pages 219?222.J.
Pustejovsky and M. Verhagen.
2009.
SemEval-2010task 13: evaluating events, time expressions, andtemporal relations (TempEval-2).
In Proceedings ofthe Workshop on Semantic Evaluations, pages 112?116.
ACL.J.
Pustejovsky, P. Hanks, R. Sauri, A. See,R.
Gaizauskas, A. Setzer, D. Radev, D. Day,L.
Ferro, et al 2003.
The Timebank Corpus.
InCorpus Linguistics, volume 2003, page 40.K.
Yoshikawa, S. Riedel, M. Asahara, and Y. Mat-sumoto.
2009.
Jointly identifying temporal rela-tions with markov logic.
In IJCNLP: Proceedingsof 47th Annual Meeting of the ACL, pages 405?413.340
