Preliminary Chinese Term Classificationfor Ontology ConstructionGaoying Cui, Qin Lu, Wenjie LiDepartment of Computing,Hong Kong Polytechnic University{csgycui, csluqin, cswjli}@comp.polyu.edu.hkAbstractAn ontology can be seen as a representa-tion of concepts in a specific domain.
Ac-cordingly, ontology construction can be re-garded as the process of organizing theseconcepts.
If the terms which are used to la-bel the concepts are classified before build-ing an ontology, the work of ontology con-struction can proceed much more easily.Part-of-speech (PoS) tags usually carrysome linguistic information of terms, soPoS tagging can be seen as a kind of pre-liminary classification to help constructingconcept nodes in ontology because featuresor attributes related to concepts of differentPoS types may be different.
This paper pre-sents a simple approach to tag domainterms for the convenience of ontology con-struction, referred to as Term PoS (TPoS)Tagging.
The proposed approach makesuse of segmentation and tagging resultsfrom a general PoS tagging software to pre-dict tags for extracted domain specificterms.
This approach needs no training andno context information.
The experimentalresults show that the proposed approachachieves a precision of 95.41% for ex-tracted terms and can be easily applied todifferent domains.
Comparing with someexisting approaches, our approach showsthat for some specific tasks, simple methodcan obtain very good performance and isthus a better choice.Keywords: ontology construction, part-of-speech (PoS) tagging, Term PoS (TPoS)tagging.1 IntroductionOntology construction has two main issuesincluding the acquisition of domain concepts andthe acquisition of appropriate taxonomies of theseconcepts.
These concepts are labeled by the termsused in the domain which are described bydifferent attributes.
Since domain specific terms(terminology) are labels of concepts among otherthings, terminology extraction is the first and theforemost important step of domain conceptacquisition.
Most of the existing algorithms inChinese terminology extraction only produce a listof terms without much linguistic information orclassification information (Yun Li and QiangjunWang, 2001; Yan He et al, 2006; Feng Zhang etal., 2006).
This fact makes it difficult in ontologyconstruction as the fundamental features of theseterms are missing.
The acquisition of taxonomies isin fact the process of organizing domain specificconcepts.
These concepts in an ontology should bedefined using a subclass hierarchy by assigningand defining properties and by definingrelationship between concepts etc.
(Van Rees, R.,2003).
These methods are all concept descriptions.The linguistic information associated with domainterms such as PoS tags and semantic classificationinformation of terms can also make up for theconcept related features which are associated withconcept labels.
Terms with different PoS tagsusually carry different semantic information.
Forexample, a noun is usually a word naming a thingor an object.
A verb is usually a word denoting anaction, occurrence or state of existence, which areall associated with a time and a place.
Thus inontology construction, noun nodes and verb nodesshould be described using different attributes withdifferent discriminating characters.
With thisinformation, extracted terms can then be classifiedThe 6th Workshop on Asian Languae Resources, 200817accordingly to help in ontology construction andretrieval work.
Thus PoS tags can help identify thedifferent features needed for concept representationin domain ontology construction.It should be pointed out that Term PoS (TPoS)tagging is different from the general PoS taggingtasks.
It is designed to do PoS tagging for a givenlist of terms extracted from some terminology ex-traction algorithms such as those presented in(Luning Ji et al, 2007).
The granularity of generalPoS tagging is smaller than what is targeted in thispaper because terms representing domain specificconcepts are more likely to be compound wordsand sometimes even phrases, such as ??????
?
(file manager),  ?????
?
(description ofconcurrency), etc..
Even though current generalword segmentation and PoS tagging can achieveprecision of 99.6% and 97.58%, respectively(Huaping Zhang et al, 2003),   its performance fordomain specific corpus is much less satisfactory(Luning Ji et al, 2007), which is why terminologyextraction algorithms need to be developed.In this paper, a very simple but effective methodis proposed for TPoS tagging which needs no train-ing process or even context information.
Thismethod is based on the assumption that every termhas a headword.
For a given list of domain specificterms which are segmented and each word in theterm already has a PoS tag, the TPoS tagging algo-rithm then identifies the position of the headwordand take the tag of the headword as the tag of theterm.
Experiments show that this method is quiteeffective in giving good precision and minimalcomputing time.The remaining of this paper is organized as fol-lows.
Section 2 reviews the related work.
Section 3gives the observations to the task and correspond-ing corpus, then presents our method for TPOStagging.
Section 4 gives the evaluation details anddiscussions on the proposed method and referencemethods.
Section 5 concludes this paper.2 Related WorkAlthough TPoS tagging is different from generalPoS tagging, the general POS tagging methods areworthy of referencing.
There are a lot of existingPOS tagging researches which can be classifiedinto following categories in general.
Natural ideasof solving this problem were to make use of theinformation from the words themselves.
A numberof features based on prefixes and suffixes andspelling cues like capitalization were adopted inthese researches (Mikheev, A, 1997; Brants, Thor-sten, 2000; Mikheev, A, 1996).
Mikheev presenteda technique for automatically acquiring rules toguess possible POS tags for unknown words usingtheir starting and ending segments (Mikheev, A,1997).
Through an unsupervised process of ruleacquisition, three complementary sets of word-guessing rules would be induced from a generalpurpose lexicon and a raw corpus: prefix morpho-logical rules, suffix morphological rules and end-ing-guessing rules (Mikheev, A, 1996).
Brantsused the linear interpolation of fixed length suffixmodel for word handling in his POS tagger, namedTnT.
For example, an English word ending in thesuffix ?able was very likely to be an adjective(Brants, Thorsten, 2000).Some existing methods are based on the analysisof word morphology.
They exploited more featuresbesides morphology or took morphology as sup-plementary means (Toutanova et al, 2003; HuihsinTseng et al, 2005; Samuelsson, Christer, 1993).Toutanova et al demonstrated the use of both pre-ceding and following tag contexts via a depend-ency network representation and made use of someadditional features such as lexical features includ-ing jointly conditioning on multiple consecutivewords and other fine-grained modeling of wordfeatures (Toutanova et al, 2003).
Huihisin et alproposed a variety of morphological word features,such as the tag sequence features from both leftand right side of the current word for POS taggingand implemented them in a Maximum EntropyMarkov model (Huihsin Tseng et al, 2005).Samuelsson used n-grams of letter sequences end-ing and starting each word as word features.
Themain goal of using Bayesian inference was to in-vestigate the influence of various informationsources, and ways of combining them, on the abil-ity to assign lexical categories to words.
TheBayesian inference was used to find the tag as-signment T with highest probability P(T|M, S)given morphology M (word form) and syntacticcontext S (neighboring tags) (Samuelsson, Christer,1993).Other researchers inclined to regard this POStagging work as a multi-class classification prob-lem.
Many methods used in machine learning, suchThe 6th Workshop on Asian Languae Resources, 200818as Decision Tree, Support Vector Machines (SVM)and k-Nearest-Neighbors (k-NN), were used forguessing possible POS tags of words (G. Orphanosand D. Christodoulakis, 1999; Nakagawa T, 2001;Maosong Sun et al, 2000).
Orphanos and Christo-doulakis presented a POS tagger for Modern Greekand focused on a data-driven approach for the in-duction of decision trees used as disambiguation orguessing devices (G. Orphanos and D. Christodou-lakis, 1999).
The system was based on a high-coverage lexicon and a tagged corpus capable ofshowing off the behavior of all POS ambiguityschemes and characteristics of words.
SupportVector Machine is a widely used (or effective)classification approach for solving two-class pat-tern recognition problems.
Selecting appropriatefeatures and training effective classifiers are themain points of SVM method.
Nakagawa et al usedsubstrings and surrounding context as features andachieve high accuracy in POS tag prediction (Na-kagawa T, 2001).
Furthermore, Sun et alpresenteda POS identification algorithm based on k-nearest-neighbors (k-NN) strategy for Chinese word POStagging.
With the auxiliary information such asexisting tagged lexicon, the algorithm can find outk nearest words which were mostly similar with theword need tagging (Maosong Sun et al, 2000).3 Algorithm DesignAs pointed out earlier, TPoS tagging is differentfrom the general PoS tagging tasks.
In this paper, itis assumed that a terminology extraction algorithmhas already obtained the PoS tags of individualwords.
For example, in the segmented and taggedsentence ???
?/n ?
?/n ?/v ?/f ?/w ??/n?
?/d ?/v ??
?/a ?
?/n ?/f ?
?/v ?/w?
(Incomputer graphics, objects are usually representedas polygonal meshes.
), the term ???????
(polygonal meshes) has been segmented into twoindividual words and tagged as ????
/a?
(polygonal /a) and ???
/n?
(meshes /n).
Theterminology extraction algorithm would identifythese two words  ????/a?
and ???/n?
as asingle term in a specific domain.
The proposedalgorithm is to determine the PoS of this singleterm ???????
(polygonal meshes), thus thealgorithm is referred to as TPoS tagging.
It can beseen that the general purpose PoS tagging and termPoS tagging assign tags at different granularity.
Inprinciple, the context information of terms can helpTPoS tagging and the individual PoS tags may begood choices as classification features.The proposed TPoS tagging algorithm consistsof two modules.
The first module is a terminologyextraction preprocessing module.
The secondmodule carries out the TPoS tag assignment.
In theterminology extraction module, if the result of ter-minology extraction algorithm is a list of termswithout PoS tags, a general purpose segmentercalled ICTCLAS1 will be used to give PoS tags toall individual words.
ICTCLAS is developed byChinese Academy of Science, the precision ofwhich is 97.58% on tagging general words(Huaping Zhang et al, 2003).
Then the output ofthis module is a list of terms, referred to as Term-List, using algorithms such as the method de-scribed in (Luning Ji et al, 2007).In this paper, two simple schemes for the termPoS tag assignment module are proposed.
The firstscheme is called the blind assignment scheme.
Itsimply assigns the noun tag to every term in theTermList.
This is based on the assumption thatmost of the terms in a specific domain representcertain concepts that are most likely to be nouns.Result from this blind assignment scheme can beconsidered as the baseline or the worse case sce-nario.
Even in general domain, it is observed thatnouns are in the majority of Chinese words withmore than 50% among all different PoS tags (HuiWang, 2006).The second scheme is called head-word-drivenassignment scheme.
Theoretically, it will take thetag of the head word of one term as the tag of thewhole term.
But here it simply takes the tag of thelast word in a term.
This is based on the assump-tion that each term has a headword which in mostcases is the last word in a term (Hui Wang, 2006).One additional experiment has been done to verifythis assumption.
A manually annotated Chineseshallow Treebank in general domain is used for thestatistic work (Ruifeng Xu et al, 2005).
There are9 different structures of Chinese phrases, (YunfangWu et al, 2003), but only 3 of them do not havetheir head words in the tail, which are about 6.56%from all phrases.
Following the examples earlier,1 Copyright ?
Institute of Computing Technology, ChineseAcademy of SciencesThe 6th Workshop on Asian Languae Resources, 200819the term ???
?/a ??/n?
(polygonal /a meshes/n) will be assigned the tag ?/n?
because the lastword is labeled ?/n?.There are a lot of semanteme tags at the end of aterm.
For example, ?/ng?
presents single characterpostfix of a noun.
But it would be improper if aterm is tagged as ?/ng?.
For example, the term ????
?
(decision-making machine) contains twosegments as  listed with two components ??
?/n?and ??/ng?.
It is obvious that ????/ng?
is in-appropriate.
Thus the head-word-driven assign-ment scheme also includes some rules to correctthis kind of problems.
As will be discussed in theexperiment, the current result of TPoS tagging isbased on 2 simple induction rules applied in thisalgorithm.4 Experiments and DiscussionsThe domain corpus used in this work contains16 papers selected from different Chinese IT jour-nals between 1998 and 2000 with over 1,500,000numbers of characters.
They cover topics in IT,such as electronics, software engineering, telecom,and wireless communication.
The same corpus isused by the terminology extraction algorithm de-veloped in (Luning Ji et al, 2007).
In the domainof IT, two TermLists are used for the experiment.TermList1 is a manually collected and verifiedterm list from the selected corpus containing a totalof 3,343 terms.
TermList1 is also referred to as thestandard answer set to the corpus for evaluationpurposes.
TermList2 is produced by running theterminology extraction algorithm in (Van Rees, R,2003).
TermList2 contains 2,660 items out ofwhich 929 of them are verified as terminology and1,731 items are not considered terminology ac-cording to the standard answer above.To verify the validity of the proposed method todifferent domains, a term list containing 366 legalterms obtained from Google searching results for???????
?
(complete dictionary of legalterms) is selected for comparison, which is namedTermList3.4.1 Experiment on the Blind AssignmentSchemeThe first experiment is designed to examine theproportion of nouns in TermList1 and TermList3,to validate of the assumption of the blind assign-ment scheme.
In first part of this experiment, allthe 3,343 terms in TermList1 are tagged as nouns.The result shows that the precision of the blindassignment scheme is between 78.79% and 84.77%.The reason for the range is that there are about 200terms in TermList1 which can be considered eitheras nouns, gerunds, or even verbs without referenceto context.
For example, the term ?????????
(?remote access of local area network?
or ?re-mote access to local area network?)
and the term????
(polarization or polarize), can be consid-ered either as nouns if they are regarded as coursesof events or as verbs if they refer to the actions forcompleting certain work.
The specific type is de-pendent on the context which is not provided with-out the use of a corpus.
However, the experimentresult does show that in a specific domain, there isa much higher percentage of terms that are nounsthan other tags in general (Hui Wang, 2006).
As toTermList3, the precision of blind assignment isbetween 65.57% and 70.77% (19 mixed ones).TermList2 is the result of a terminology extractionalgorithm and there are non-term items in the ex-traction result, so the blind assignment scheme isnot applied on TermList2.
The blue colored bars(lighter color) in Figure 1 shows the result ofTermList1 and TermList3 using the blind assign-ment scheme which gives the two worst resultcompared to our proposed approach to be dis-cussed in Section 4.24.2 Experiments on the Head-Word-DrivenAssignment SchemeThe experiment in this section was designed tovalidate the proposed head-word-driven assign-ment scheme.
The same experiment is conductedon the three term lists respectively, as shown inFigure 1 in purple color (darker color).
The preci-sion for assigning TPoS tags to TermList1 is93.45%.
By taking the result from a terminologyextraction algorithm without regards to its potentialerror propagations, the precision of the head-word-driven assignment scheme for TermList2 is94.32%.
For TermList3, the precision of PoS tagassignment is 90.71%.
By comparing to the blindassignment scheme, this algorithm has reasonablygood performance for all three term list withprecision of over 90%.
It also gives 8.7% and19.9% improvement for TermList1 and TermList3,respectively, as compared to the blind assignmentThe 6th Workshop on Asian Languae Resources, 200820scheme, a reasonably good improvement without aheavy cost.
However, there are some abnormali-ties in these results.
Supposedly, TermList1 is ahand verified term list in the IT domain and thus itsresult should have less noise and thus should per-form better than TermList2, which is not the caseas shown in Figure 1.Figure 1 Performance of the Two AssignmentSchemes on the Three Term Lists0.00%20.00%40.00%60.00%80.00%100.00%T1 T2 T3Term ListsPrecisionblind assignmenthead-drivenassignmentBy further analyzing the error result, for exam-ple for TermList1, among these 3,343 terms, about219 were given improper tags, such as the term ?????
(Graphics).
In this example, two individualwords, ???/n?
and ?
?/v?, form a term.
So theoutput was ????/v?
for taking the tag of the lastsegment.
It was a wrong tag because the wholeterm was a noun.
In fact, the error is caused by thegeneral word PoS tagging algorithm because with-out context, the most likely tagging of ??
?, a se-manteme, is a verb.
This kind of errors in se-manteme tagging appeared in the results of allthree term lists with 169 from TermList1, 29 fromTermList2 and 12 from TermList3, respectively.This was a kind of errors which can be correctedby applying some simple induction rules.
For ex-ample, for all semantemes with multiple tags (in-cluding noun as in the example), the rule can be?tagging terms with noun suffixes as nouns?.
Forexample, terms ??
?/n ?/q?
(reform-through-labor camp) and ???
?/n ?
?/n ?/v?
(com-puter graphics) were given different tags using thehead-word-driven assignment scheme.
They wereassigned as: ????/q?
and ??????
?/v?which can be corrected by this rule.
Another kindof mistake is related to the suffix tags such as ?/ng?
(noun suffix) and ?/vg?
(verb suffix).
For examples,??
?/n ?
?/n ?/ng?
(intellectual property tri-bunal) and ??
?/n ?/vg?
(data set) will be taggedas ??????
/ng?
and ????
/vg?, respec-tively, which are obviously wrong.
So, the simplerule of ?tagging terms with ?/ng?
and ?/vg?
to ?/n?is applied.
The performance of TPoS tag assign-ment after applying these two fine tuning inductionrules are shown in Table 1 below.Table 1 Influence of Induction Rules on DifferentTerm ListsTermListsPrecisionof taggingPrecisionafter add-ing induc-tion ruleImprove-mentPercentageTermList1 93.45% 97.03% 3.83%TermList2 94.32% 95.41% 1.16%TermList3 90.71% 93.99% 3.62%It is obvious that with the use of fine tuning us-ing induction rules, the results are much better.
Infact the result for TermList1 reached 97.03%which is quite close to PoS tagging of general do-main data.
The abnormality also disappeared as theperformance of TermList1 has the best result.
Theimprovement to TermList2 (1.16%) is not as obvi-ous as that for TermList1 and TermList3, whichare 3.83% and 3.62%, respectively.
This, however,is reasonable as TermList2 is produced directlyfrom a terminology extraction algorithm using acorpus, thus, the results are noisier.Further analysis is then conducted on the resultof TermList2 to examine the influence of non-termitems to this term list.
The non-term items areitems that are general words or items cannot beconsidered as terminology according to the stan-dard answer sheet.
For example, neither of theterms ????
(problem) and ???????
(pat-tern training is) were considered as terms becausethe former was a general word, and the lattershould be considered as a fragment rather than aword.
In fact, in 2,660 items extracted by the algo-rithm as terminology, only 929 of them are indeedterminology (34.92%), and rest of them do notqualify as domain specific terms.
The result of thisanalysis is listed in Table 2.The 6th Workshop on Asian Languae Resources, 200821Table 2 Data Distribution Analysis on TermList2Without InductionRulesInduction RulesAppliedcorrectterms precisioncorrectterms precisionTerms(929)  879 94.62%  898 96.66%Non-terms(1,731) 1,630 94.17% 1,640 94.74%Total(2,660) 2,509 94.32% 2,538 95.41%Results show that 31 and 50 from the 929 cor-rect terms were assigned improper PoS tags usingthe proposed algorithm with and without the induc-tions rules, respectively.
That is, the precisions forcorrect data are comparable to that of TermList1(93.45% and 97.03%, respectively).
For the non-terms, 91 items and 101 items from 1,731 itemswere assigned improper tags with and without theinduction rules, respectively.
Even though the pre-cisions for terms and non-terms without using theinduction rules are quite the same (94.62% vs.94.17%), the improvement for the non-terms usingthe induction rules are much less impressive thanthat for the terms.
This is the reason for the rela-tively less impressed performance of inductionrules for TermList2.
It is interesting to know that,even though the performance of the terminologyextraction algorithm is quite poor with precision ofonly around 35% (929 out of 2,666 terms), it doesnot affect too much on the performance of theTPoS proposed in this paper.
This is mainly be-cause the items extracted are still legitimate words,compounds, or phrases which are not necessarilydomain specific.The proposed algorithm in this paper use mini-mum resources.
They need no training process andeven no context information.
But the performanceof the proposed algorithm is still quite good andcan be directly used as a preparation work for do-main ontology construction because of its presionof over 95%.
Other PoS tagging algorithms reachgood performance in processing general words.For example, a k-nearest-neighbors strategy toidentify possible PoS tags for Chinese words canreach 90.25% for general word PoS tagging(Maosong Sun et al, 2000).
Another method basedon SVM method on English corpus can reach96.9% in PoS tagging known and unknown words(Nakagawa T, 2001).
These results show that pro-posed method in this paper is comparable to thesegeneral PoS tagging algorithms in magnitude.
Ofcourse, one main reason of this fact is the differ-ence in its objectives.
The proposed method is forthe PoS tagging of domain specific terms whichhave much less ambiguity than tagging of generaltext.
Domain specific terms are more likely to benouns and there are some rules in the word-formation patterns while general PoS tagging algo-rithms usually need training process in which largemanually labeled corpora would be involved.
Ex-periment results also show that this simple methodcan be applied to data in different domains.5 Conclusion and Future WorkIn this paper, a simple but effective method forassigning PoS tags to domain specific terms waspresented.
This is a preliminary classification workon terms.
It needs no training process and not evencontext information.
Yet it obtains a relativelygood result.
The method itself is not domain de-pendent, thus it is applicable to different domains.Results show that in certain applications, a simplemethod may be more effective under similar cir-cumstances.
The algorithm can still be investigatedover the use of more induction rules.
Some contextinformation, statistics of word/tag usage can alsobe explored.AcknowledgmentsThis project is partially supported by CERGgrants (PolyU 5190/04E and PolyU 5225/05E) andB-Q941 (Acquisition of New Domain SpecificConcepts and Ontology Update).ReferencesYun Li, Qiangjun Wang.
2001.
Automatic Term Extrac-tion in the Field of Information Technology.
In theproceedings of The Conference of 20th Anniversaryfor Chinese Information Processing Society of China.Yan He, Zhifang Sui, Huiming Duan, and Shiwen Yu.2006.
Term Mining Combining Term ComponentBank.
In Computer Engineering and Applications.Vol.42 No.33,4--7.Feng Zhang, Xiaozhong Fan, and Yun Xu.
2006.
Chi-nese Term Extraction Based on PAT Tree.
Journal ofBeijing Institute of Technology.
Vol.
15, No.
2.Van Rees, R. 2003.
Clarity in the Usage of the TermsOntology, Taxonomy and Classification.
CIB73.The 6th Workshop on Asian Languae Resources, 200822Mikheev, A.
1997.
Automatic Rule Induction.
for Un-known Word Guessing.
In Computational LingusiticsVol.
23(3), ACL.Toutanova, Kristina, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.In proceedings of HLT-NAACL.Huihsin Tseng, Daniel Jurafsky, and Christopher Man-ning.
2005.Morphological Features Help POS Tag-ging of Unknown Words across Language Varieties.In proceedings of the Fourth SIGHAN Workshop onChinese Language Processing.Samuelsson, Christer.
1993.
Morphological TaggingBased Entirely on Bayesian Inference.
In proceedingsof NCCL 9.Brants, Thorsten.
2000.
TnT: A Statistical Part-of-Speech Tagger.
In proceedings of ANLP 6.G.
Orphanos, and D. Christodoulakis.
1999.
POS Dis-ambiguation and Unknown Word Guessing with De-cision Trees.
In proceedings of EACL?99, 134--141.H Schmid.
1994.
Probabilistic Part-of-Speech TaggingUsing Decision Trees.
In proceedings of InternationalConference on New Methods in Language Processing.Maosong Sun, Dayang Shen, and Changning Huang.1997.
CSeg& Tag1.0: a practical word segmenterand POS tagger for Chinese texts.
In proceedings ofthe fifth conference on applied natural languageprocessing.Ying Liu.
2002.
Analysing Chinese with Rule-basedMethod Combined with Statistic-based Method.
InComputer Engineering and Applications, Vol.7.Mikheev, A.
1996.
Unsupervised Learning of Word-Category Guessing Rules.
In proceedings of ACL-96.Nakagawa T, Kudoh T, and Matsumoto Y.
2001.
Un-known Word Guessing and Part-of-Speech TaggingUsing Support Vector Machines.
In proceedings ofNLPPRS 6, 325--331.Maosong Sun, Zhengping Zuo, and B K, TSOU.
2000.Part-of-Speech Identification for Unknown ChineseWords Based on K-Nearest-Neighbors Strategy.
InChinese Journal of Computers.
Vol.23 No.2: 166--170.Luning Ji, Mantai Sum, Qin Lu, Wenjie Li, YirongChen.
2007.
Chinese Terminology Extraction usingWindow-based Contextual Information.
In proceed-ings of CICLING.Huaping Zhang et al 2003.
HHMM-based ChineseLexical Analyzer ICTCLAS.
Second SIGHAN work-shop affiliated with 41th ACL, 184--187.
SapporoJapan.Hui Wang.
Last checked: 2007-08-04.
Statistical studieson Chinese vocabulary (????????
).http://www.huayuqiao.org/articles/wanghui/wanghui06.doc.
The date of publication is unknown from theonline source.Ruifeng Xu, Qin Lu, Yin Li and Wanyin Li.
2005.
TheDesign and Construction of the PolyU Shallow Tree-bank.
International Journal of Computational Lin-guistics and Chinese Language Processing, V.10 N.3.Yunfang Wu, Baobao Chang and Weidong Zhan.
2003.Building Chinese-English Bilingual Phrase Database.Page 41-45, Vol.
4.The 6th Workshop on Asian Languae Resources, 200823The 6th Workshop on Asian Languae Resources, 200824
