Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 814?820,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsCascading Collective Classification for Bridging Anaphora RecognitionUsing a Rich Linguistic Feature SetYufang Hou1, Katja Markert2, Michael Strube11 Heidelberg Institute for Theoretical Studies gGmbH, Heidelberg, Germany(yufang.hou|michael.strube)@h-its.org2School of Computing, University of Leeds, UKscskm@leeds.ac.ukAbstractRecognizing bridging anaphora is difficult dueto the wide variation within the phenomenon,the resulting lack of easily identifiable surfacemarkers and their relative rarity.
We developlinguistically motivated discourse structure,lexico-semantic and genericity detection fea-tures and integrate these into a cascaded mi-nority preference algorithm that models bridg-ing recognition as a subtask of learning fine-grained information status (IS).
We substan-tially improve bridging recognition withoutimpairing performance on other IS classes.1 IntroductionIn bridging or associative anaphora (Clark, 1975;Prince, 1981; Gundel et al 1993), the antecedentand anaphor are not coreferent but are linked via avariety of contiguity relations.1 In Example 1, thephrases a resident, the stairs and the lobby are bridg-ing anaphors with the antecedent One building.2(1) One building was upgraded to red status while peo-ple were taking things out, and a resident called up thestairs to his girlfriend, telling her to keep sending thingsdown to the lobby.Bridging is an important problem as it affects lin-guistic theory and applications alike.
For exam-ple, without bridging resolution, entity coherencebetween the first and second coordinated clause in1We exclude comparative anaphora where anaphor and an-tecedent are in a similarity/exclusion relation, indicated by ana-phor modifiers such as other or similar (Modjeska et al 2003).2Examples are from OntoNotes (Weischedel et al 2011).Bridging anaphora are set in boldface; antecedents in italics.Example 1 cannot be established.
This is a prob-lem both for coherence theories such as Centering(Grosz et al 1995) (where bridging is therefore in-corporated as an indirect realization of previous en-tities) as well as applications relying on entity co-herence modelling, such as readability assessmentor sentence ordering (Barzilay and Lapata, 2008).Full bridging resolution needs (i) recognition thata bridging anaphor is present and (ii) identificationof the antecedent and contiguity relation.
In re-cent work, these two tasks have been tackled sep-arately, with bridging recognition handled as part ofinformation status (IS) classification (Markert et al2012; Cahill and Riester, 2012; Rahman and Ng,2012).
Each mention in a text gets assigned one ISclass that describes its accessibility to the reader ata given point in a text, bridging being one possibleclass.
We stay within this framework.Bridging recognition is a difficult task, so that wehad to report very low results on this IS class in pre-vious work (Markert et al 2012).
This is due to thephenomenon?s variety, leading to a lack of clear sur-face features for recognition.
Instead, we formulatein this paper novel discourse structure and lexico-semantic features as well as features that distinguishbridging from generics (see Section 3).
In addition,making up between 5% and 20% of definite descrip-tions (Gardent and Manue?lian, 2005; Caselli andProdanof, 2006) and around 6% of all NPs (Mark-ert et al 2012), bridging is still less frequent thanmany other IS classes and recognition of minorityclasses is well known to be more difficult.
We there-fore use a cascaded classification algorithm to ad-dress this problem (Omuya et al 2013).8142 Related WorkMost bridging research concentrates on antecedentselection only (Poesio and Vieira, 1998; Poesio etal., 2004a; Markert et al 2003; Lassalle and De-nis, 2011; Hou et al 2013), assuming that bridg-ing recognition has already been performed.
Previ-ous work on recognition is either limited to definiteNPs based on heuristics evaluated on small datasets(Hahn et al 1996; Vieira and Poesio, 2000), ormodels it as a subtask of learning fine-grained IS(Rahman and Ng, 2012; Markert et al 2012; Cahilland Riester, 2012).
Results within this latter frame-work for bridging have been mixed: We reported inMarkert et al(2012) low results for bridging in writ-ten news text whereas Rahman and Ng (2012) re-port high results for the four subcategories of bridg-ing annotated in the Switchboard dialogue corpus byNissim et al(2004).
We believe this discrepancy tobe due to differences in corpus size and genre as wellas in bridging definition.
Bridging in Switchboardincludes non-anaphoric, syntactically linked part-ofand set-member relationships (such as the building?slobby), as well as comparative anaphora, the latterbeing marked by surface indicators such as other,another etc.
Both types are much easier to identifythan anaphoric bridging cases.3 In addition, manynon-anaphoric lexical cohesion cases have been an-notated as bridging in Switchbard as well.We also separate bridging recognition and ante-cedent selection.
One could argue that a joint modelis more attractive as potential antecedents such asbuilding ?trigger?
subsequent bridging cases such asstairs (Example 1).
However, bridging can be indi-cated by referential patterns without world knowl-edge about the anaphor/antecedent NPs, as the non-sense example 2 shows: the wug is clearly a bridginganaphor although we do not know the antecedent.4(2) The blicket couldn?t be connected to the dax.
Thewug failed.Similarly, Clark (1975) distinguishes betweenbridging via necessary, probable and inducibleparts/roles and argues that only in the first andmaybe the second case the antecedent triggers the3See also the high results for our specific category for com-parative anaphora (Markert et al 2012).4We thank an anonymous reviewer for pointing this out.bridging anaphor in the sense that we already spon-taneously think of the anaphor when we read the an-tecedent.
Also, bridging recognition on its own canbe valuable for applications: for example, prosody isinfluenced by IS status without needing antecedentknowledge (Baumann and Riester, 2013).3 Characterizing Bridging Anaphora forAutomatic Recognition3.1 Properties of bridging anaphoraBridging anaphors are rarely marked by surface fea-tures.
Indeed, even the common practice (Vieira andPoesio, 2000; Lassalle and Denis, 2011; Cahill andRiester, 2012) to limit bridging to definite NPs doesnot seem to be correct: We report in previous work(Hou et al 2013) that less than 40% of the bridg-ing anaphora in our corpus are definites.
Instead,bridging is diverse with regard to syntactic formand function: bridging anaphora can be definite NPs(Examples 4 and 6), indefinite NPs (Example 5) orbare NPs (Examples 3, 8 and 9).
The only frequentsyntactic property shared is that bridging NPs tendto have a simple internal structure with regards tomodification.
Bridging is also easily confused withgenerics: friends is used as bridging anaphor in Ex-ample 9 but generically in Example 10.
(3) .
.
.
meat .
.
.
The Communists froze prices instead.
(4) .
.
.
the fund?s building .
.
.
The budget was only$400,000.
(5) .
.
.
employees .
.
.
A food caterer stashed stones in thefalse bottom of a milk pail.
(6) .
.
.
his truck .
.
.
The farmer at the next truck shouts,?Wheat!?
(7) .
.
.
the firms .
.
.
Crime was the reason that 26% re-ported difficulty recruiting personnel and that 19% saidthey were considering moving.
(8) .
.
.
the company .
.
.
His father was chairman andchief executive until his death in an accident five yearsago.
(9) .
.
.
Josephine Baker .
.
.
Friends pitched in.
(10) Friends are part of the glue that holds life and faithtogether.Bridging anaphora can have almost limitless varia-tion.
However, we observe that bridging anaphorsare often licensed because of discourse structure815Markert et al(2012) local feature setf1 FullPrevMention (b) f2 FullPreMentionTime (n)f3 PartialPreMention (b) f4 ContentWordPreMention (b)f5 Determiner (n) f6 NPtype (n)f7 NPlength (int) f8 GrammaticalRole (n)f9 NPNumber (n) f10 PreModByCompMarker (b)f11 SemanticClass (n)Markert et al(2012) relational feature setf12 HasChild (r) f13 Precedes (r)Table 1: Markert et als (2012) feature set, b indi-cates binary, n nominal, r relational features.and/or lexical or world knowledge.
With regard todiscourse structure, Grosz et al(1995) observe thatbridging is often needed to establish entity coher-ence between two adjacent sentences (Examples 1,2, 4, 5, 6, 7 and 9).
With regard to lexical and worldknowledge, relational noun phrases (Examples 3, 4,8 and 9), building parts (Example 1), set member-ship elements (Example 7), or, more rarely, tem-poral/spatial modification (Example 6) may favor abridging reading.
Motivated by these observations,we develop discourse structure and lexico-semanticfeatures indicating bridging anaphora as well as fea-tures designed to separate genericity from bridging.3.2 FeaturesIn Markert et al(2012) we classify eight fine-grained IS categories for NPs in written text: old,new and 6 mediated categories (syntactic, world-Knowledge, bridging, comparative, aggregate andfunction).
This feature set (Table 1, f1-f13) workswell to identify old, new and several mediated cate-gories.
However, it fails to recognize most bridginganaphora which we try to remedy in this work byincluding more diverse features.Discourse structure features (Table 2, f1-f3).Bridging occurs frequently in sentences where oth-erwise there would no entity coherence to previoussentences/clauses (see Grosz et al(1995) and Poe-sio et al(2004b) for discussions about bridging, en-tity coherence and centering transitions in the Cen-tering framework).
This is especially true for topicNPs (Halliday and Hasan, 1976) in such sentences.We follow these insights by identifying coherencegap sentences (see Examples 1, 4, 5, 6, 7, 9 and also2): a sentence has a coherence gap (f1) if it has nonenew local features for bridgingdiscourse f1 IsCoherenceGap (b)structure f2 IsSentFirstMention (b)f3 IsDocFirstMention (b)semantics f4 IsWordNetRelationalNoun (b)f5 IsInquirerRoleNoun (b)f6 IsBuildingPart (b)f7 IsSetElement (b)f8 PreModSpatialTemporal (b)f9 IsYear (b)f10 PreModifiedByCountry (b)generic f11 AppearInIfClause (b)NP f12 VerbPosTag (l)features f13 IsFrequentGenericNP (b)f14 WorldKnowledgeNP (l)f15 PreModByGeneralQuantifier (b)other features f16 Unigrams (l)f17 BridgingHeadNP (l)f18 HasChildNP (b)new features for other mediated categoriesaggregate f19 HasChildCoordination (r)function f20 DependOnChangeVerb (b)worldKnowledge f21 IsFrequentProperName (b)Table 2: New feature set, l indicates lexical features.of the following three coherence elements: (1) entitycoreference to previous sentences, as approximatedvia string match or presence of pronouns, (2) com-parative anaphora approximated by mentions modi-fied via a small set of comparative markers (see alsoTable 1, f10 PreModByCompMarker), or (3) propernames.
We approximate the topic of a sentence viathe first mention (f2).f3 models that bridging anaphors do not appearat the beginning of a text.Semantic features (Table 2, f4-f10).
In contrastto generic patterns, our semantic features capturelexical properties of nouns that make them morelikely to be the head of a bridging NP.
We createf4-f8 to capture four kinds of bridging anaphora.Lo?bner (1985) distinguishes between relationalnouns that take on at least one obligatory semanticrole (such as friend) and sortal nouns.
It is likely thatrelational nouns are more frequently used as bridg-ing than sortal nouns (see Examples 3, 4, 8 and 9).We extract a list containing around 4,000 relationalnouns from WordNet and a list containing around500 nouns that specify professional roles from theGeneral Inquirer lexicon (Stone et al 1966), thendetermine whether the NP head appears in these lists816or not (f4 and f5).
The obligatory semantic role fora relational noun can of course also be filled NP in-ternally instead of anaphorically and we use the fea-tures f10 (for instances such as the Egyptian presi-dent) and f18 (for complex NPs that are likely to fillneeded roles NP internally) to address this.Because part-of relations are typical bridging re-lations (see Example 1 and Clark (1975)), we use f6to determine whether the NP is a part of the buildingor not, using again a list extracted from Inquirer.f7 is used to identify set membership bridgingcases (see Example 7), by checking whether theNP head is a number or indefinite pronoun (such asnone, one, some) or modified by each, one.
How-ever, not all numbers are bridging cases (such as1976) and we use f9 to exclude such cases.Lassalle and Denis (2011) note that some bridginganaphors are indicated by spatial or temporal modi-fications (see Example 6).
We use f8 to detect thisby compiling 20 such adjectives from Inquirer.Features to detect generic nouns (Table 2, f11-f15).
Generic NPs (Example 10) are easily con-fused with bridging anaphora.
Inspired by Reiterand Frank (2010) who build on linguistic research,we develop features (f11-f15) to exclude generics.First, hypothetical entities are likely to refer togeneric entities (Mitchell et al 2002), We approx-imate this by determining whether the NP appearsin an if-clause (f11).
Also the clause tense andmood may play a role to decide genericity (Reiterand Frank, 2010).
This is often reflected by the mainverb of a clause, so we extract its POS tag (f12).Some NPs are commonly used generically, suchas children, men, or the dollar.
The ACE-2 corpus(distinct from our corpus) contains generic annota-tion .
We collect all NPs from ACE-2 that are alwaysused generically (f13).
We also try to learn NPs thatare uniquely identifiable without further descriptionor anaphoric links such as the sun or the pope.
Wedo this by extracting common nouns which are an-notated as worldKnowledge from the training part ofour corpus5 and use these as lexical features (f14).Finally, motivated by the ACE-2 annotationguidelines, we identify six quantifiers that may in-dicate genericity, such as all, no, neither (f15).5This list varies for each run of our algorithm in 10-foldcross validation.Other features for bridging (Table 2, f16-f18).Following Rahman and Ng (2012), we use unigrams(f16).
We also extract heads of bridging anaphorsfrom the training data as lexical features (f17) tolearn typical nouns used for bridging that we did notcover in lexicon extraction (f4 to f6).Feature f18 models that bridging anaphora mostoften have a simple internal structure and usually donot contain any other NPs.Features for other IS categories (Table 2, f19-f21).
We propose three features to improve otherIS categories.
In the relational feature f19, we sep-arate coordination parent-child from other parent-child relations to help with the class aggregate.
f20determines whether a number is the object of an in-crease/decrease verb (using a list extracted from In-quirer) and therefore likely to be the IS class func-tion.
Frequent proper names are more likely to behearer old and hence of the class worldKnowledge.f21 extracts proper names that occur in at least 100documents in the Tipster corpus to approximate this.4 Experiments and ResultsExperimental setup.
We perform experiments onthe corpus provided in Markert et al(2012)6.
It con-sists of 50 texts taken from the WSJ portion of theOntoNotes corpus (Weischedel et al 2011) with al-most 11,000 NPs annotated for information statusincluding 663 bridging NPs and their antecedents.All experiments are performed via 10-fold cross-validation on documents.
We use gold standardmentions and the OntoNotes named entity and syn-tactic annotation layers for feature extraction.Reimplemented baseline system (rbls).
rbls usesthe same features as Markert et al(2012) (Table 1)but replaces the local decision tree classifier withLibSVM as we will need to include lexical features.rbls + Table 2 feature set (rbls+newfeat).
Basedon rbls, all the new features from Table 2 are added.Cascading minority preference system (cmps).Minority classes such as bridging suffer during stan-dard multi-class classification.
Inspired by Omuya6http://www.h-its.org/nlp/download/isnotes.php817collective cascade + collectivemarkert 12 rbls rbls+newfeat cmps cmps?newfeatR P F R P F R P F R P F R P Fold 84.1 85.2 84.6 84.6 85.5 85.1 84.4 86.0 85.2 82.2 87.2 84.7 78.9 89.5 83.8med/worldKnowledge 60.6 70.0 65.0 65.9 69.6 67.7 67.4 77.3 72.0 67.2 77.2 71.9 67.5 66.7 67.1med/syntactic 75.7 80.1 77.9 77.8 81.2 79.4 82.2 81.9 82.0 81.6 82.5 82.0 73.9 81.7 77.6med/aggregate 43.1 55.8 48.7 47.9 58.0 52.5 64.5 79.5 71.2 63.5 77.9 70.0 46.9 60.0 52.7med/function 35.4 53.5 48.7 33.8 56.4 42.3 67.7 72.1 69.8 67.7 72.1 69.8 41.5 50.0 45.4med/comparative 81.4 82.0 81.7 81.8 82.5 82.1 81.8 82.1 82.0 86.6 78.2 82.2 86.2 78.7 82.3med/bridging 12.2 41.7 18.9 10.7 36.6 16.6 19.3 39.0 25.8 44.9 39.8 42.2 31.8 23.9 27.3new 87.7 73.3 79.8 87.5 74.8 80.7 86.5 76.1 81.0 83.0 78.1 80.5 82.4 76.1 79.1acc 76.8 77.6 78.9 78.6 75.0Table 3: Experimental resultset al(2013), we develop a cascading minority pref-erence system for fine-grained IS classification.
Forthe five minority classes (function, aggregate, com-parative, bridging and worldKnowledge) that eachmake up less than the expected 18 of the data set, wedevelop five binary classifiers with LibSVM7 usingall features from Tables 1 and 2 and apply them inorder from rarest to more frequent category.
When-ever a minority classifier predicts true, this class isassigned.
When all minority classifiers say false, weback off to the multiclass rbls+newfeat system.cmps ?
Table 2 feature set (cmps?newfeat).
Totest the effect of using the minority preference sys-tem without additional features, we employ a cmpssystem with baseline features from Table 1 only.Results and Discussion (Table 3).
Our novelfeatures in rbls+newfeat show improvements forworldKnowledge, aggregate and function as well asbridging categories compared to both baseline sys-tems, although the performance for bridging is stilllow.
In addition, the overall accuracy is significantlybetter than the two baseline systems (at the level of1% using McNemar?s test).
Using the cascaded mi-nority preference system cmps in addition improvesbridging results substantially while the performanceon other categories does not worsen.
The algorithmneeds both our novel feature classes as well as cas-caded modelling to achieve this improvement as thecomparison to cmps?newfeat shows: the latter low-ers overall accuracy as it tends to overgenerate rare7Parameter against data imbalance is set according to theratio between positive and negative instances in the training set.classes (including bridging) with low precision if thefeatures are not strong enough.
Our novel features(addressing linguistic properties of bridging) and thecascaded algorithm (addressing data sparseness) ap-pear to be complementary.To look at the impact of features in our best sys-tem, we performed an ablation study.
Lexical fea-tures as well as semantic ones have the most impact.Discourse structure and genericity information fea-tures have less of an impact.
We believe the latter tobe due to noise involved in extracting these features(such as approximating coreference for the coher-ence gap feature) as well as genericity recognitionstill being in its infancy (Reiter and Frank, 2010).5 ConclusionsThis paper aims to recognize bridging anaphora inwritten text.
We develop discourse structure, lexico-semantic and genericity features based on linguis-tic intuition and corpus research.
By using a cas-cading minority preference system, we show thatour approach outperforms the bridging recognitionin Markert et al(2012) by a large margin withoutimpairing the performance on other IS classes.Acknowledgements.
Yufang Hou is funded by a PhDscholarship from the Research Training Group Coher-ence in Language Processing at Heidelberg University.Katja Markert receives a Fellowship for Experienced Re-searchers by the Alexander-von-Humboldt Foundation.We thank HITS gGmbH for hosting Katja Markert andfunding the annotation.818ReferencesRegina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Computa-tional Linguistics, 34(1):1?34.Stefan Baumann and Arndt Riester.
2013.
Coreference,lexical givenness and prosody in German.
Lingua.Accepted.Aoife Cahill and Arndt Riester.
2012.
Automatically ac-quiring fine-grained information status distinctions inGerman.
In Proceedings of the SIGdial 2012 Confer-ence: The 13th Annual Meeting of the Special InterestGroup on Discourse and Dialogue, Seoul, Korea, 5?6July 2012, pages 232?236.Tommaso Caselli and Irina Prodanof.
2006.
Annotat-ing bridging anaphors in Italian: In search of reliabil-ity.
In Proceedings of the 5th International Conferenceon Language Resources and Evaluation, Genoa, Italy,22?28 May 2006.Herbert H. Clark.
1975.
Bridging.
In Proceedings of theConference on Theoretical Issues in Natural LanguageProcessing, Cambridge, Mass., June 1975, pages 169?174.Claire Gardent and He?le`ne Manue?lian.
2005.
Cre?ationd?un corpus annote?
pour le traitement des descrip-tions de?finies.
Traitement Automatique des Langues,46(1):115?140.Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.1995.
Centering: A framework for modeling the lo-cal coherence of discourse.
Computational Linguis-tics, 21(2):203?225.Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski.1993.
Cognitive status and the form of referring ex-pressions in discourse.
Language, 69:274?307.Udo Hahn, Michael Strube, and Katja Markert.
1996.Bridging textual ellipses.
In Proceedings of the 16thInternational Conference on Computational Linguis-tics, Copenhagen, Denmark, 5?9 August 1996, vol-ume 1, pages 496?501.M.
A. K. Halliday and Ruqaiya Hasan.
1976.
Cohesionin English.
London, U.K.: Longman.Yufang Hou, Katja Markert, and Michael Strube.
2013.Global inference for bridging anaphora resolution.
InProceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Atlanta, Georgia, 9?14 June 2013, pages 907?917.Emmanuel Lassalle and Pascal Denis.
2011.
Leverag-ing different meronym discovery methods for bridgingresolution in French.
In Proceedings of the 8th Dis-course Anaphora and Anaphor Resolution Colloquium(DAARC 2011), Faro, Algarve, Portugal, 6?7 October2011, pages 35?46.Sebastian Lo?bner.
1985.
Definites.
Journal of Seman-tics, 4:279?326.Katja Markert, Malvina Nissim, and Natalia N. Mod-jeska.
2003.
Using the web for nominal anaphoraresolution.
In Proceedings of the EACL Workshop onthe Computational Treatment of Anaphora.
Budapest,Hungary, 14 April 2003, pages 39?46.Katja Markert, Yufang Hou, and Michael Strube.
2012.Collective classification for fine-grained informationstatus.
In Proceedings of the 50th Annual Meeting ofthe Association for Computational Linguistics, Jeju Is-land, Korea, 8?14 July 2012, pages 795?804.Alexis Mitchell, Stephanie Strassel, Mark Przybocki,JK Davis, George Doddington, Ralph Grishman,Adam Meyers, Ada Brunstain, Lisa Ferro, and BethSundheim.
2002.
ACE-2 Version 1.0.
LDC2003T11,Philadelphia, Penn.
: Linguistic Data Consortium.Natalia M. Modjeska, Katja Markert, and Malvina Nis-sim.
2003.
Using the web in machine learning forother-anaphora resolution.
In Proceedings of the 2003Conference on Empirical Methods in Natural Lan-guage Processing, Sapporo, Japan, 11?12 July 2003,pages 176?183.Malvina Nissim, Shipara Dingare, Jean Carletta, andMark Steedman.
2004.
An annotation scheme for in-formation status in dialogue.
In Proceedings of the 4thInternational Conference on Language Resources andEvaluation, Lisbon, Portugal, 26?28 May 2004, pages1023?1026.Malvina Nissim.
2006.
Learning information status ofdiscourse entities.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural LanguageProcessing, Sydney, Australia, 22?23 July 2006, pages94?012.Adinoyi Omuya, Vinodkumar Prabhakaran, and OwenRambow.
2013.
Improving the quality of minorityclass identification in dialog act tagging.
In Proceed-ings of the 2013 Conference of the North AmericanChapter of the Association for Computational Linguis-tics: Human Language Technologies, Atlanta, Geor-gia, 9?14 June 2013, pages 802?807.Massimo Poesio and Renata Vieira.
1998.
A corpus-based investigation of definite description use.
Com-putational Linguistics, 24(2):183?216.Massimo Poesio, Rahul Mehta, Axel Maroudas, andJanet Hitzeman.
2004a.
Learning to resolve bridgingreferences.
In Proceedings of the 42nd Annual Meet-ing of the Association for Computational Linguistics,Barcelona, Spain, 21?26 July 2004, pages 143?150.Massimo Poesio, Rosemary Stevenson, Barbara Di Euge-nio, and Janet Hitzeman.
2004b.
Centering: A para-metric theory and its instantiations.
ComputationalLinguistics, 30(3).
309-363.819Ellen F. Prince.
1981.
Towards a taxonomy of given-newinformation.
In P. Cole, editor, Radical Pragmatics,pages 223?255.
Academic Press, New York, N.Y.Altaf Rahman and Vincent Ng.
2012.
Learning the fine-grained information status of discourse entities.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, Avignon, France, 23?27 April 2012, pages 798?807.Nils Reiter and Anette Frank.
2010.
Identifying genericnoun phrases.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, Uppsala, Sweden, 11?16 July 2010, pages 40?49.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,Daniel M. Ogilvie, and Cambridge Computer Asso-ciates.
1966.
General Inquirer: A Computer Ap-proach to Content Analysis.
MIT Press, Cambridge,Mass.Renata Vieira and Massimo Poesio.
2000.
Anempirically-based system for processing definite de-scriptions.
Computational Linguistics, 26(4):539?593.Ralph Weischedel, Martha Palmer, Mitchell Marcus, Ed-uard Hovy, Sameer Pradhan, Lance Ramshaw, Ni-anwen Xue, Ann Taylor, Jeff Kaufman, MichelleFranchini, Mohammed El-Bachouti, Robert Belvin,and Ann Houston.
2011.
OntoNotes release 4.0.LDC2011T03, Philadelphia, Penn.
: Linguistic DataConsortium.820
