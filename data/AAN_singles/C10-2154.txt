Coling 2010: Poster Volume, pages 1345?1353,Beijing, August 2010An Empirical Study of Translation Rule Extraction with MultipleParsersTong Xiao?
?, Jingbo Zhu?
?, Hao Zhang?, Muhua Zhu??
?Natural Language Processing Lab., Northeastern University?Key Laboratory of Medical Image Computing, Ministry of Education{xiaotong,zhujingbo}@mail.neu.edu.cnzhanghao@ics.neu.edu.cn, zhumuhua@gmail.comAbstractTranslation rule extraction is an impor-tant issue in syntax-based Statistical Ma-chine Translation (SMT).
Recent studiesshow that rule coverage is one of the keyfactors affecting the success of syntax-based systems.
In this paper, we firstpresent a simple and effective method toimprove rule coverage by using multipleparsers in translation rule extraction, andthen empirically investigate the effec-tiveness of our method on Chinese-English translation tasks.
Experimentalresults show that extracting translationrules using multiple parsers improves astring-to-tree system by over 0.9 BLEUpoints on both NIST 2004 and 2005 testcorpora.1 IntroductionRecently various syntax-based models have beenextensively investigated in Statistical MachineTranslation (SMT), including models betweensource trees and target strings (Quirk et al, 2005;Liu et al, 2006; Huang et al, 2006), sourcestrings and target trees (Yamada and Knight,2001; Galley et al, 2006; Shen et al, 2008), orsource trees and target trees (Eisner, 2003; Dingand Palmer, 2005; Cowan et al, 2006; Zhang etal., 2008; Liu et al, 2009).
In these models, au-tomatic extraction of translation rules is an im-portant issue, in which translation rules are typi-cally extracted using parse trees onsource/target-language side or both sides of thebilingual text.
Exploiting the syntactic informa-tion encoded in translation rules, syntax-basedsystems have shown to achieve comparable per-formance with phrase-based systems, even out-perform them in some cases (Marcu et al, 2006).Among all the factors contributing to the suc-cess of syntax-based systems, rule coverage hasbeen proved to be an important one that affectsthe translation accuracy of syntax-based systems(DeNeefe et al, 2007; Shen et al, 2008).
How-ever, these systems suffer from a problem thattranslation rules are extracted using only 1-bestparse tree generated by a single parser, whichgenerally results in relatively low rule coveragedue to the limited scope in rule extraction (Miand Huang, 2008).
To alleviate this problem, astraightforward solution is to enlarge the scopeof rule extraction, and obtain translation rules byusing a group of diversified parse trees insteadof a single parse tree.
For example, Mi andHuang (2008) used k-best parses and forest toextract translation rules for improving the rulecoverage in their forest-based SMT system, andachieved promising results.
However, most pre-vious work used the parse trees generated byonly one parser, which still suffered somewhatfrom the relatively low diversity in the outputsof a single parser.Addressing this issue, we investigate how toextract diversified translation rules using multi-ple parsers.
As different parsers (or parsingmodels) can provide us with parse trees havingrelatively large diversity, we believe that it isbeneficial to employ multiple different parsers toobtain diversified translation rules and thus en-large the rule coverage.
Motivated by this idea,we propose a simple and effective method toimprove rule coverage by using multiple parsers1345in rule extraction.
Furthermore, we conduct anempirical study to investigate the effectivenessof our method on Chinese-English translation ina string-to-tree system.
Experimental resultsshow that our method improves the baseline sys-tem by over 0.9 BLEU points on both NIST2004 and 2005 test corpora, even achieves a +1BLEU improvement when working with the k-best extraction method.
More interestingly, weobserve that the MT performance is not verysensitive to the parsing performance of the pars-ers used in rule extraction.
Actually, the MT sys-tem does not show different preferences for dif-ferent parsers.2 Related WorkIn machine translation, some efforts have beenmade to improve rule coverage and advance theperformance of syntax-based systems.
For ex-ample, Galley et al (2006) proposed the idea ofrule composing which composes two or morerules with shared states to form a larger, com-posed rule.
Their experimental results showedthat the rule composing method could signifi-cantly improve the translation accuracy of theirsyntax-based system.
Following Galley et al(2006)?s work, Marcu et al (2006) proposedSPMT models to improve the coverage of phras-al rules, and demonstrated that the system per-formance could be further improved by usingtheir proposed models.
Wang et al (2007) de-scribed a binarization method that binarizedparse trees to improve the rule coverage on non-syntactic mappings.
DeNeefe et al (2007) analy-ized the phrasal coverage problem, and com-pared the phrasal coverage as well as translationaccuracy for various rule extraction methods(Galley et al, 2006; Marcu et al, 2006; Wang etal., 2007).As another research direction, some work isfocused on enlarging the scope of rule extractionto improve rule coverage.
For example, (Venu-gopal et al, 2008) and (Mi and Huang, 2008)extracted rules from the k-best parses and forestgenerated by a single parser to alleviate theproblem of the limited scope of 1-best parse, andachieved promising results.Our work differs from previous work in thatwe are concerned with obtaining diversifiedtranslation rules using multiple different parsers(or parsing models) instead of a single parser (orparsing model).
It can be regarded as an en-hancement of previous studies.
As shown in thefollowing parts of this paper, it works very wellwith the existing techniques, such as rule com-posing (Galley et al, 2006), SPMT models(Marcu et al, 2006) and rule extraction with k-best parses (Venugopal et al, 2008).3 Translation Rule ExtractionIn this work, the issue of translation rule extrac-tion is studied in the string-to-tree model pro-posed by Galley et al (2006).
We choose thismodel because it has been shown to be one ofthe state-of-the-art syntax-based models, and hasbeen adopted in the most successful systems inNIST 2009 MT evaluation.Typically, (string-to-tree) translation rules arelearned from the word-aligned bilingual textwhose target-side has been parsed using a syn-tactic parser.
As the basic unit of translation, atranslation rule consists of sequence words orvariables in the source language, and a syntaxtree in the target language having words (termi-nals) and variables (non-terminals) at leaves.Figure 1 shows the translation rules extractedfrom a word-aligned sentence pair with a target-side parse tree.Figure 1: Translation rules extracted from astring-tree pair.1346Figure 2: Rule extraction using two different parsers (Berkeley Parser and Collins Parser).
Theshaded rectangles denote the translation rules that can be extracted from the parse tree generated byone parser but cannot be extracted from the parse tree generated by the other parser.To obtain basic translation rules, the (minimal)GHKM extraction method proposed in (Galleyet al 2004) is utilized.
The basic idea of GHKMextraction is to compute the set of the mini-mally-sized translation rules that can explain themappings between source-language string andtarget-language tree while respecting the align-ment and reordering between the two languages.For example, from the string-tree pair shown atthe top of Figure 1, we extract the minimalGHKM translation rules r1-6.
In addition toGHKM extraction, the SPMT models (Marcu etal., 2006) are employed to obtain phrasal rulesthat are not covered by GHKM extraction.
Forexample, rule r8  in Figure 1 is a SPMT rule thatis not obtained in GHKM extraction.
Finally, therule composing method (Galley et al, 2006) isused to compose two or more minimal GHKMor SPMT rules having shared states to form lar-ger rules.
For example, rule r7 in Figure 1 is gen-erated by composing rules r2 and r6.4 Differences in Coverage between RuleExtractions with Different ParsersAs described above, translation rule extractionrelies on the outputs (parse trees) of parsers.
Asdifferent parsers generally have large diversitybetween their outputs, rule extractions with dif-ferent parsers generally result in very differentsets of rules.
For example, Figure 2 shows therule extractions on a word-aligned sentence pairhaving two target-trees generated by BerkeleyParser and Collins Parser, respectively.
It is ob-served that Figure 2 (a) and (b) cover differentsets of rule due to the different target-trees usedin rule extraction.
Particularly, well-formed rulesra7-a9 are extracted in Figure 2 (a), while they donot appear in Figure 2 (b).
Also, rules rb7-b9 inFigure 2 (b) have the similar situation.
This ob-servation gives us an intuition that there is a?complementarity?
between the rules extractedusing different parsers.1347We also conduct a quantitative study to inves-tigate the impact of using different parsers(Berkeley Parser and Collins Parser) on rulecoverage.
Tables 1 shows the statistics of therules extracted from 370K Chinese-English par-allel sentence pairs1 using the method describedin Section 3.
In addition to the total number ofrules extracted, the numbers of phrasal rules anduseful rules are also reported to indicate the rulecoverage of a rule set.
Here phrasal rule refersto the rule whose source-side and the yield of itstarget-side contains only one phrase each, withoptional surrounding variables.
According to(DeNeefe et al, 2007), the number of phrasalrules is a good indicator of the coverage of a ruleset.
useful rule refers to the rule that can be ap-plied when decoding the test sentences 2 .
Asshown in Table 1, the two resulting rule sets on-ly have about 70% overlaps (Column 4), and therule coverage increases by about 20% when wecombine them together (Column 5).
This findingconfirms that the rule coverage can be improvedby using multiple different parsers in rule extrac-tion.# of rules # of phrasalrules# ofuseful rulesBerkeley 3,538,332 2,515,243 549,783Collins 3,526,166 2,481,195 553,893Overlap 2,542,380 1,907,521 386,983Union 4,522,118 3,088,920 716,693Table 1: Comparison of rule coverage betweendifferent rule sets.5 Translation Rule Extraction withMultiple Parsers5.1 Rule Extraction AlgorithmMotivated by the above observations, we pro-pose a rule extraction method to improve therule coverage by using multiple parsers.Let <f, e, a> be a tuple of <source sentence,target sentence, bi-directional word alignments>,1 LDC2005T10, LDC2003E07, LDC2003E14 andLDC2005T062 In this experiment, the test sentences come fromNIST 2004 and 2005 MT evaluation sets.
It should benoted that due to the pruning in decoding we cannotcount the exact number of rules that can be used dur-ing decoding.
In this work, we use an alternative ?the number of rules matched with test sentences ?
toestimate an upper-bound approximately.and {P1, ..., PN} be N syntactic parsers in target-language.
The following pseudocode formulizesthe algorithm for extracting translation rulesfrom <f, e, a> using parsers {P1, ..., PN}, wherePi(e) returns the parse tree generated by the i-thparser Pi.
Function GENERATERULES() com-putes the set of rules for <f, ti, a> by using vari-ous rule extraction methods, such as  the methoddescribed in Section 3.Multi-Parser based Rule ExtractionInput: <f, e, a> and P = {P1, ..., PN}Output: rule set R1 Function MULTIPAREREXTRACTOIN(<f, e, a>, P )2     for i = 1 to N do                           <  for each parser3        ti = Pi(e)                                      <  target-tree4       Ri = GENERATERULES (f, ti, a) <  rule extraction5       R.append(Ri)6     return R7 Function GENERATERULES ( f, ti, a )8     return rules extracted from <f, ti, a>5.2 Learning Rule ProbabilitiesIn multi-parser based rule extraction, more thanone parse trees are used, and each of them is as-sociated with a parsing confidence (e.g.
genera-tive probability of the tree).
Ideally, if the parsetrees used in rule extraction can be accuratelyweighted, the rule probabilities will be betterestimated according to the parse weights, forexample, the rules extracted from a parse treehaving a low weight should be penalized accord-ingly in the estimation of rule probabilities.
Un-fortunately, the tree probabilities are generallyincomparable between different parsers due tothe different parsing models used and ways ofimplementation.
Thus we cannot use the poste-rior probability of a rule?s target-side to estimatethe fractional count (Mi and Huang, 2008; Liu etal., 2009), which is used in maximum-likelihoodestimation of rule probabilities.
In this work, tosimplify the problem, we assume that all theparsers have the same and maximum degrees ofconfidence on their outputs.
For a rule r ex-tracted from a string-tree pair, the count of r isdefined to be:1( , )( )Nir ic rN?== ?
(1)where ( , )r i?
is 1 if r is extracted by using the i-th parser, otherwise 0.1348Following Mi and Huang (2008)?s work, threeconditional rule probabilities are employed forexperimenting with our method.
': ( ') ( )( )Pr( | ( ))( )r root r root rc rr root rc r== ?
(2)': ( ') ( )( )Pr( | ( ))( )r lhs r lhs rc rr lhs rc r== ?
(3)': ( ') ( )( )Pr( | ( ))( )r rhs r rhs rc rr rhs rc r== ?
(4)where lhs(r) and rhs(r) are the source-hand andtarget-hand sides of r respectively, and root(r) isthe root of r?s target-tree.5.3 Parser Indicator FeaturesFor each rule, we define N indicator features (i.e.
( , )r i? )
to indicate a rule is extracted by usingwhich parsers, and add them into the translationmodel.
By training the feature weights with Min-imum Error Rate Training (MERT), the systemcan learn preferences for different parsers auto-matically.6 ExperimentsThe experiments are conducted on Chinese-English translation in a state-of-the-art string-to-tree SMT system.6.1 Experimental SetupOur bilingual data consists of 370K sentencepairs (9M Chinese words + 10M English words)which have been used in the experiment in Sec-tion 4.
GIZA++ is employed to perform the bidi-rectional word alignment between the source andtarget sentences, and the final word alignment isgenerated using the inter-sect-diag-grow method.A 5-gram language model is trained on the tar-get-side of the bilingual data and the Xinhuaportion of English Gigaword corpus.
The devel-opment data set comes from NIST MT 2003evaluation set.
To speed up MERT, sentenceswith more than 20 Chinese words are removed.The test sets are the NIST MT evaluation sets of2004 and 2005.Our baseline MT system is built based on thestring-to-tree model proposed in (Galley et al,2006).
In this system, both of minimal GHKM(Galley et al, 2004) and SPMT rules (Marcu etal., 2006) are extracted from the bilingual corpus,and the composed rules are generated by com-posing two or three minimal GHKM and SPMTrules3.
We use a CKY-style decoder with cubepruning (Huang and Chiang, 2007) and beamsearch to decode new Chinese sentences.
By de-fault, the beam size is set to 30.
For integratingn-gram language model into decoding efficiently,rules containing more than two variables orsource word sequences are binarized using thesynchronous binarization method (Zhang et al,2006; Xiao et al, 2009).The system is evaluated in terms of the case-insensitive NIST version BLEU (using theshortest reference length), and statistical signifi-cant test is conducted using the re-sampling me-thod proposed by Koehn (2004).6.2 The ParsersFour syntactic parsers are chosen for the ex-periments.
They are Stanford Parser4, BerkeleyParser 5 , Collins Parser (Dan Bikel?s reimple-mentation of Collins Model 2) 6  and CharniakParser7.
The former two are state-of-the-art non-lexicalized parsers, while the latter two are state-of-the-art lexicalized parsers.
All the parsers aretrained on sections 02-21 of the Wall StreetJournal (WSJ) Treebank, and tuned on section22.
Table 2 summarizes the performance of theparsers.Parser Recall Precision F1Stanford 86.29% 87.21% 86.75%Berkeley 90.18% 90.45% 90.32%Collins 89.14% 88.85% 88.99%Charniak 89.99% 90.28% 90.13%Table 2: Performance of the four parsers on sec-tion 23 of the WSJ Treebank.We parse the target-side of the bilingual datausing the four parsers individually.
From the 1-best parses generated by these parsers, we obtainfour baseline rule sets using the method de-scribed in Section 3, as well as the rule sets usi-3 Generally a higher baseline can be obtained bycombining more (unit) rules.
However, we find thatusing more composed rules does not affect the impactof using multiple parsers.
Thus, we choose this set-ting in order to finish all experiments in time.4 http://nlp.stanford.edu/software/lex-parser.shtml5 http://code.google.com/p/berkeleyparser/6 http://www.cis.upenn.edu/~dbikel/download.html7 http://www.cs.brown.edu/people/ec/#software1349Rule Coverage BLEU4 (%)  Rule set# of rules # ofphrasal rules# ofuseful rulesDev.
MT04 MT05Stanford (S) 3,679 K 2,581 K 573 K 39.36 36.02 36.98Berkeley (B) 3,538 K 2,515 K 549 K 39.32 36.05 36.98Collins (Co) 3,526 K 2,481 K 553 K 39.16 36.07 36.91BaselineCharniak (Ch) 3,450 K 2,435 K 540 K 39.24 35.90 36.89S + B 4,567 K 3,105 K 726 K 39.87+ 36.57+ 37.47+S + Co 4,734 K 3,202 K 752 K 39.94+ 36.57+ 37.52+S + Ch 4,764 K 3,258 K 751 K 40.01+ 36.51 37.59+B + Co 4,522 K 3,088 K 716 K 39.84+ 36.60+ 37.46+B +  Ch 4,562 K 3,129 K 717 K 39.81+ 36.49 37.412parsersCo + Ch 4,592 K 3,125 K 727 K 39.75 36.55+ 37.43+S + B + Co 5,331 K 3,543 K 852 K 40.14++ 36.83++ 37.78++S + B + Ch 5,380 K 3,590 K 854 K 40.05+ 36.82++ 37.70+S + Co + Ch 5,551 K 3,663 K 877 K 40.35++ 36.70+ 37.70+ 3 parsersB + Co + Ch 5,294 K 3,544 K 840 K 40.04+ 36.76+ 37.65+4 S + B + Co + Ch 6,005 K 3,940 K 958 K 40.28++ 36.99++ 37.89++Table 5: Evaluation results.
+ or ++ = significantly better than all the baseline systems (using singleparser) at the 95% or 99% confidence level.Stanford Berkeley Collins CharniakStanford 100% 76.72% 73.32% 74.89%Berkeley 76.72% 100% 75.69% 76.76%Collins 73.32% 75.69% 100% 74.84%Charniak 74.89% 76.76% 74.84% 100%Table 3: Agreement between different parsers.ng the multi-parser based rule extraction method.Before conducting primary experiments, we firstinvestigate the differences between the 1-bestoutputs of the parsers.
Table 3 shows the agree-ment between each pair of parsers.
Here the de-gree of agreement shown in each cell is com-puted by using one parser?s output as a goodstandard to evaluate the other parser?s output interms of F1 score, and a higher agreement score(i.e.
F1 score) means that the 1-best outputs ofthe two parsers are more similar to each other.We see that the agreement scores between dif-ferent parsers are always below 80%.
This resultreflects a large diversity in parse trees generatedby different parsers, and thus confirms our ob-servations in Section 4.We also examine the ?complementarity?
be-tween the baseline rule sets generated by usingdifferent parsers individually.
Table 4 shows theresults, where the degree of ?complementarity?between two rule sets is defined as the percent-age of the rules in one rule set that are not cov-ered by the other rule set.
It can be regarded as ameasure of the disagreement between two rulesets, and a higher number indicates large ?com-plementarity?.
For example, in Row 2, Column 3(Table 4), ?25.09%?
means that 25.09% rules inthe first rule set (using Stanford Parser) are notcovered by the second rule set (using BerkeleyParser).
Table 4 shows that there is always a dis-agreement of over 25% between different rulesets.
These results indicate that using differentparsers can lead to a relatively large ?comple-mentarity?
between the rule sets.Stanford Berkeley Collins CharniakStanford 0% 25.09% 29.91% 31.43%Berkeley 27.98% 0% 27.90% 29.68%Collins 32.84% 28.15% 0% 30.89%Charniak 35.70% 31.43% 32.37% 0%Table 4: Disagreement between the rule sets ob-tained using different parsers individually.6.3 Evaluation of TranslationsWe then study the impact of multi-parser basedrule extraction on translation accuracy.
Table 5shows the BLEU scores as well as the rule cov-erage for various rule extraction methods.
Wesee, first of all, that the rule coverage is im-proved significantly by multi-parser based ruleextraction.
Compared to the baseline method (i.e.single-parser based rule extraction), the multi-parser based rule extraction achieves over 20%coverage improvements when only two parsersare used, even yields gains of over 50 percentage1350points when all the four parsers are used together.Also, BLEU score is improved by multi-parserbased rule extraction.
When two parsers are em-ployed in rule extraction, there is generally again of over 0.4 BLEU points on both MT04 andMT05 test sets.
Further improvements areachieved when more parsers are involved.
Onboth test sets, using three parsers in rule extrac-tion generally yields a +0.7 BLEU improvement,and using all the parsers together yields a +0.9BLEU improvement which is the biggest im-provement achieved in this set of experiment.All these results show that multi-parser basedrule extraction is an effective way to improve therule coverage as well as the BLEU score of thesyntax-based MT system.An interesting finding is that there seems nosignificant differences in BLEU scores betweenthe baseline systems (using single parsers),though the parsing performance of the corre-sponding parsers is very different from eachother.
For example, the MT performance corre-sponding to Berkeley Parser is very similar tothat corresponding to Stanford Parser despite a4-point difference in F1 score between the twoparsers.
Another example is that Charniak parserperforms slightly worse than the other three onMT task, though it achieves the 2nd best parsingperformance in all the parsers.
This interestingfinding shows that the performance of syntax-based MT systems is not very sensitive to theparsing performance of the parsers used in ruleextraction.6.4 Preferences for ParsersWe also investigate the preferences for differentparsers in our system.
Table 6 shows the weightsof the parser indicator features learned byMERT, as well as the number of edges gener-ated by applying the rules corresponding to dif-ferent parsers during decoding.
Both of the met-rics are used to evaluate the contributions of theparsers to MT decoding.
We see that thoughStanford Parser and Berkeley Parser are shownto be relatively more preferred by the decoder,there are actually no significant differences inthe degrees of the contributions of differentparsers.
This result also confirms the fact ob-served in Table 5 that the MT system does nothave special preferences for different parsers.Indicator Weight # of edges(Dev.
)# of edges(MT04)# of edges(MT05)Stanford 0.1990 7.7 M 169.2 M 101.7 MBerkeley 0.1982 7.7 M 166.3 M 100.2 MCollins 0.1690 6.9 M 149.9 M   93.1 MCharniak 0.1729 7.1 M 156.5 M   97.2 MTable 6: Preferences for different parsers.Though Table 6 provides some informationabout the contributions of different parsers, itstill does not answer how often these rules arereally used to generate final (1-best) translation.Table 7 gives an answer to this question.
We seethat, following the similar trend in Table 5, dif-ferent parsers have nearly equal contributions ingenerating final translation.Indicator # of rulesused in 1-best(Dev.
)# of rulesused in 1-best(MT04)# of rulesused in 1-best(MT05)Stanford     2,410 23,513 14,357Berkeley     2,455 23,878 14,670Collins     2,309 22,654 13,815Charniak     2,269 22,406 13,731Table 7: Numbers of rules used in generatingfinal (1-best) translation.6.5 Rule Extraction with k-best ParsesWe also conduct experiments to compare theeffectiveness of multi-parser based rule extrac-tion and rule extraction with k-best parses gener-ated by a single parser.
As Berkeley parser isone of the best-performing parsers in previousexperiments, we employ it to generate k-bestparses in this set of experiment.
As shown inFigure 3, both of the methods improve theBLEU scores by enlarging the set of parse treesused in rule extraction.
Compared to k-best ex-traction, multi-parser extraction shows consiste-36.83737.237.437.637.83838.23.5 5.0 6.5BLEU4(%)# of rules (million)1-best4-best10-best20-best30-best 50-best2 parsers3 parsers4 parsersmulti-parser extractionk-best extractionFigure 3: Multi-parser based rule extraction vs.rule extraction with k-best parses (MT05).1351ntly better BLEU scores.
Using 4 different pars-ers, it achieves an improvement of 0.6 BLEUpoints over k-best extraction where even 50-bestparses are used.Finally, we extend multi-parser based rule ex-traction to extracting rules from the k-best parsesgenerated by multiple parsers.
Figure 4 showsthe results on ?S + B + Co + Ch?
system.
We seethat multi-parser based rule extraction can bene-fit from k-best parses, and yields a modest (+0.2BLEU points) improvement when extractingfrom 10-best parses.
However, since k-best ex-traction generally results in much slower extrac-tion speed, it might not be a good choice to usek-best parses to improve our method in practice.37.737.837.93838.138.238.338.438.55.5 6.5 7.5 8.5BLEU4(%)# of rules (million)1-best2-best5-best10-bestmulti-parser + k-best extractionFigure 4: Multi-parser based rule extraction &rule extraction with k-best parses (MT05).7 Discussion and Future WorkIn this work, all the parsers are trained using thesame treebank.
To obtain diversified parse treesfor multi-parser based rule extraction, an alterna-tive way is to learn parsers on treebanks anno-tated by different organizations (e.g.
Penn Tree-bank and ICE-GB corpus).
Since different tree-banks can provide us with more diversity inparsing, we believe that our system can benefit alot from the parsers that are learned on multipledifferent treebanks individually.
But here is aproblem that due to the different annotationstandards used, there is generally an incompati-bility between treebanks annotated by differentorganizations.
It will result in that we cannotstraightforwardly mix the resulting rule sets (orheterogeneous grammars for short) for probabil-ity estimation as well as the use for decoding.
Tosolve this problem, a simple solution might bethat we transform the incompatible rules into aunified form.
Alternatively, we can use hetero-geneous decoding (or parsing) techniques (Zhuet al, 2010) to make use of heterogeneousgrammars in the stage of decoding.
Both topicsare very interesting and worth studying in ourfuture work.Besides k-best extraction, our method can alsobe applied to other rule extraction schemes, suchas forest-based rule extraction.
As (Mi andHuang, 2008) has shown that forest-based ex-traction is more effective than k-best extractionin improving translation accuracy, it is expectedto achieve further improvements by using multi-parser based rule extraction and forest-based ruleextraction together.8 ConclusionsIn this paper, we present a simple and effectivemethod to improve rule coverage by using mul-tiple parsers in translation rule extraction.
Ex-perimental results show thatz Using multiple parsers in rule extractionachieves large improvements of rule cover-age over the baseline method where only asingle parser is used, as well as a +0.9BLEU improvement on both NIST 2004and 2005 test corpora.z The MT system can be further improved byusing multiple parsers and k-best parses to-gether.
However, with the consideration ofextraction speed, it might not be a goodchoice to use k-best parses to improve mul-ti-parser based rule extraction in practice.z The MT performance is not influenced bythe parsing performance of the parsers usedin rule extraction very much.
Actually, theMT system does not show different prefer-ences for different parsers.AcknowledgementsThis work was supported in part by the NationalScience Foundation of China (60873091) andthe Fundamental Research Funds for the CentralUniversities (N090604008).
The authors wouldlike to thank the anonymous reviewers and Ton-gran Liu for their pertinent comments for im-proving the early version of this paper, and Ru-shan Chen for building parts of the baseline sys-tem.1352ReferencesBrooke Cowan, Ivona Ku?erov?
and Michael Collins.2006.
A discriminative model for tree-to-treetranslation.
In Proc.
of EMNLP 2006, pages 232-241.Steve DeNeefe, Kevin Knight, Wei Wang and DanielMarcu.
2007.
What Can Syntax-based MT Learnfrom Phrase-based MT?
In Proc.
of EMNLP 2007,pages 755-763.Yuan Ding and Martha Palmer.
2005.
Machine trans-lation using probabilistic synchronous dependencyinsertion grammars.
In Proc.
of ACL 2005, AnnArbor, Michigan, pages 541-548.Jason Eisner.
2003.
Learning non-isomorphic treemappings for machine translation.
In Proc.
of ACL2003, pages 205-208.Michel Galley, Mark Hopkins, Kevin Knight andDaniel Marcu.
2004.
What's in a translation rule?In Proc.
of HLT-NAACL 2004, Boston, USA,pages 273-280.Michel Galley, Jonathan Graehl, Kevin Knight, Da-niel Marcu, Steve DeNeefe, Wei Wang and Igna-cio Thayer.
2006.
Scalable inferences and trainingof context-rich syntax translation models.
In Proc.of COLING/ACL 2006, Sydney, Australia, pages961-968.Liang Huang and David Chiang.
2007.
Forest rescor-ing: Faster decoding with integrated languagemodels.
In Proc.
of ACL 2007, Prague, Czech Re-public, pages 144-151.Liang Huang, Kevin Knight and Aravind Joshi.
2006.Statistical syntax-directed translation with ex-tended domain of locality.
In Proc.
of AMTA 2006,pages 66-73.Philipp Koehn.
2004.
Statistical Significance Testsfor Machine Translation Evaluation.
In Proc.
ofEMNLP 2004, Barcelona, Spain, pages 388-395.Yang Liu, Qun Liu and Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machinetranslation.
In Proc.
of COLING/ACL 2006, Syd-ney, Australia, pages 609-616.Yang Liu, Yajuan L?
and Qun Liu.
2009.
ImprovingTree-to-Tree Translation with Packed Forest.
InProc.
of ACL 2009, pages 558-566.Daniel Marcu, Wei Wang, Abdessamad Echihabi andKevin Knight.
2006.
SPMT: Statistical machinetranslation with syntactified target language phras-es.
In Proc.
of EMNLP 2006, Sydney, Australia,pages 44-52.Haitao Mi and Liang Huang.
2008.
Forest-basedTranslation Rule Extraction.
In Proc.
of EMNLP2008, pages 206-214.Chris Quirk, Arul Menezes and Colin Cherry.
2005.Dependency treelet translation: Syntactically in-formed phrasal SMT.
In Proc.
of ACL 2005, pages271-279.Libin Shen, Jinxi Xu and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation al-gorithm with a target dependency language model.In Proc.
of ACL/HLT 2008, pages 577-585.Ashish Venugopal, Andreas Zollmann, Noah A.Smith and Stephan Vogel.
2008.
Wider Pipelines:K-best Alignments and Parses in MT Training.
InProc.
of AMTA 2008, pages 192-201.Wei Wang, Kevin Knight and Daniel Marcu.
2007.Binarizing Syntax Trees to Improve Syntax-BasedMachine Translation Accuracy.
In Proc.
ofEMNLP-CoNLL 2007, Prague, Czech Republic,pages 746-754.Tong Xiao, Mu Li, Dongdong Zhang, Jingbo Zhu andMing Zhou.
2009.
Better Synchronous Binariza-tion for Machine Translation.
In Proc.
of EMNLP2009, Singapore, pages 362-370.Kenji Yamada and Kevin Knight.
2001.
A syntax-based statistical machine translation model.
InProc.
of ACL 2001, pages 132-139.Hao Zhang, Liang Huang, Daniel Gildea and KevinKnight.
2006.
Synchronous Binarization for Ma-chine Translation.
In Proc.
of HLT-NAACL 2006,New York, USA, pages 256- 263.Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li,Chew Lim Tan and Sheng Li.
2008.
A Tree Se-quence Alignment-based Tree-to-Tree TranslationModel.
In Proc.
of ACL/HLT 2008, pages 559-567.Muhua Zhu, Jingbo Zhu and Tong Xiao.
2010.
Het-erogeneous Parsing via Collaborative Decoding.
InProc.
of COLING 2010.1353
