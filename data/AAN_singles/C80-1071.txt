SPEECH RECOGNITION SYSTEM FOR SPOKEN JAPANESE SENTENCESMinoru Shigenaga, Yoshihiro Sekiguchi and Chia-horng LaiFaculty of Engineering, Yamanashi UniversityTakeda-4, Kofu 400, JapanSummary: A speech recognition system for continu-ously spoken Japanese simple sentences is de-scribed.
The acoustic analyser based on a psy-chological assumption for phoneme identif icationcan represent the speech sound by a phonemestring in an expanded sense which contains acous-tic features such as buzz and silence as well asordinary phonemes.
Each item of the word diction-ary is written in Roman letters of Hepburn sys-tem, and the reference phoneme string and thereference characteristic phoneme string necessa-ry for matching procedure of input phoneme se-quences are obtained from the word dictionaryusing a translating routine.
In syntax analysis,inflexion of verbs and adjectives and those ofsome main auxil iary verbs are taken into account.The syntax analyser uses a network dealing withstate transition among Parts of speech, predictsfollowing words and outputs their syntactic in-terpretation of the input phoneme string.
Thesemantic knowledge system deals with semanticdefinition of each verb, semantic nature of eachword and the schema of the sentence, and con-constructs a semantic network.
The semantic anal-yser examines semantic validity of the recogniz-ed sentence as to whether each word in the sen-tence meets the definition of the recognizedverb or others.
The present object of recogni-tion is a Japanese fairy tale composed of simplesentences alone.
The syntactic and semantic anal-ysers work well and can recognize simple sen-tences provided that the acoustic analyser out-puts correct phoneme strings.
For real speech,though the level of semantic processing is yetlow, it can recognize 25 blocks out of 33 blocks(A block means a part of speech sound uttered ina breath.
), and 9 sentences out of 16 sentencesuttered by an adult male.1.
IntroductionIntensive studies of speech recognition orspeech understanding are being carried out \[1-3\],but there are some fundamental problems to besolved both in acoustic analysis and linguisticprocessing.
The authors think there must existsome fundamental procedures to be applicable toany task in speech recognition, and are tryingto solve the problems through the behavior oftwo recognition systems which deal with Japanesesentences \[4\] and FORTRAN programs \[5\] spokenwithout interruption.Both the recognition systems consist of twoparts: an acoustic analyser and a linguistic pro-cessor.
In the acoustic analysis, recognitionmodel based on a psychological assumption is in-troduced for phoneme identification.
As a result,speech sound has come to easily be expressed ina phoneme string in an expanded sense that con-tains some acoustic features such as buzz andsilence as well as ordinary phonemes.
The sys-tems require a process of learning a small num-ber of training samples \[6\] for identif icationof the speaker's vowels, nasals and buzz.
In thelinguistic processor, using major acoustic fea-tures as well as linguistic information haSmadeitpossible to effectively reduce the number ofcandidate words.
For sequences of phonemes witherroneous ones has also been devised a graphicmatching method \[7\] more suitable for matchingthan the one using dynamic programming.In the previous system for Japanese sen-tences, sentences were narrowly limited in apre-decided style.
In the new system, as shownin Fig.
i.i, the knowledge system is much rein-forced.
That is, in the syntax analysis, inflex-ion of verbs and adjectives and those of somemain auxiliary verbs can be referred;.thus thesyntax analyser may be able to deal with variouskinds of simple sentences.
A simulation has con-firmed the ability of syntax analyser for simplesentences which have been offered in terms ofRoman letters without any partit ion betweenwords.
In the semantic knowledge source, seman-tic definition of verbs, natures of nouns, asimple schema for a topic are stored, and seman-tic network will be constructed as a recognitionprocessgoes  on.
This semantic knowledge is usedto yield, at the end of spoken sentence, themost semantically probable sentence as an outputand occasionally to reduce the number of candi-date words in co-operation with the syntax ana-lyser.2.
Acoustic Analyser and Matching MethodA psychology based model is used to obtainneat phoneme string from speech wave using thefollowing feature parameters determined everyten mil l i -seconds \[5\].
(i) Maximum value of amplitudes,(ii) Number of zero-crossing,(iii) Normalized prediction error,(iv) Pareor-coefficients,(v) Variation of Parcor-coefficients betweensuccessive frames,(vi) Frequency spectrum,(vii) Formant frequencies.The output phonemes and their decision methodsare given in Table 2.1.
The obtained output pho-neme strings contain 5 Japanese vowels, a nasalgroup, an unvoiced stop consonant group, /s/,/h/, /r/, buzz parts and silence.
D iscr iminat ionof each stop consonant \[8\] and that of each na-sal consonant are not yet embodied in this sys-tem.Vowels and /s/ having long duration and si-lent parts are used as characteristic phonemes.-- 472Knowledge sourceSemantic knowledge~ ~  {Defin~tion~\]ema  i/erb /<structure) (network b~Semant icinformation II) Semantic analyser ISyntactic knowledgeSyntactlc State k__/ L__dsyntactictransition~----~Inflexion) I ~information/ networkS__ |Knowledge about vocabulary, \] , Li_~v?cabulary ~_~fCharacteristic~ /Word i hl "\information/analyser \[ IMatching unit III~-~\ ]  {Candidate ~ I \word s t r ings /Selector of ~Match ing  ~ I\]candidate words unitI (Phoneme ~string)I Acoustic ~ analyser\]Fig.
1.1 Speech recognition system.Besides an ordinary word dictionary, a character-istic phoneme dictionary (This dictionary existsonly implicitly and is automatically composedfrom the word dictionary which is written in Ro-man letters.)
is prepared and presents major a-coustic features of each word.
These major fea-tures are used for reduction of the number ofcandidate words.For matching between a phoneme string witherroneous phonemes and items of the word or char-acteristic phoneme dictionaries, a new matchingmethod using graph theory is devised \[7\].These acoustic and matching processings arethe same as the ones in the previous systems.3.
Knowledge Representation3.1.
Syntactic Knowledge3.1.1.
Classification of Japanese wordsfor machine reco@nitionIn order to automatically recognizecontinuously spoken natural languages, itis necessary to use syntactic rules.
How-ever using the original form of Japanesegrammar written by grammarians is not nec-essarily suitable for mechanical recogni-tion.
Moreover it is very difficult to re-duce the number of predicted words only bysyntactic information because of the natureof Japanese language which does not requireto keep the word order so rigorously.
Tak-ing account of these conditions, Japanesewords are classified as described in thefollowing article and the syntax may pref-erably be represented by state transitionnetworks as shown in section 3.1.3.3.1.1.1.
Classification of words by parts ofspeechEach word is classified grammatically asgiven in Table 3.1.
In Japanese nouns, pronouns,numerals and quasi-nouns (KEISHIKI-MEISHI in Jap-anese) are called substantives (inflexionlessparts of speech in Japanese grammar, TAIGEN inJapanese), and verbs, auxiliary verbs and adjec-tives are called inflexional words (inflexionalparts of speech!
YOGEN in Japanese).
Meanwhilethe words No.
1 - No.
ii in Table 3.1 are inflex-ionless words and the words No.
12 - No.
15 are'able 2.1 Output phonemes and their decision methods.Class Output Phoneme Decision MethodVowel i,e,a,o,uParcor-coefficients k,Nasal m'n'9'N using Bayes decision theoryBuzz denoted by Bs Number of zero-crossingsFricative Variations of amplitude andh spectrum, Number of zero-crossings, and Unsimilarityto vowels and nasalsr LiquidUnvoicedstopSilencep,t,kVariations of amplitude andfirst formant frequency,Number of zero-crossingsFollowing after silence andHaving high frequencycomponentsSmall amplitude--473--inf lexional  words.
In No.
16 the inf lexion rulesnecessary for each inf lexional  word are wr i t tenin appropr iate forms.
The addit ional  word "car-r iage return" in No.
17 is a special symbol.
Weask each spejker to utter the word "carr iage re-turn" at the  end of each sentence in order to in-form the recognizer of the end of a sentence.Japanese verbs, adject ives and auxi l iaryverbs are inf lexional.
The verb's inf lexion hasbeen c lass i f ied t radi t ional ly  into 5 kinds of in-f lexion types: GODAN-KATSUYO (inflexion), KAMI-ITCHIDAN-KATSUYO, SHIMO-ICHIDAN-KATSUYO, SAGYO-HENKAKU-KATSUYO and KAGYO-HENKAKU-KATSUYO.
Butwe c lass i fy  them into 14 types as given in Table3.2 taking into account the combinat ion of thestem, a consonant fol lowing the stem and the in-f lexional ending of each word.
Examples areshown in Fig.
3.1.
By so doing the number of in-f lexion tables becomes smaller.The adject ives and verbal -ad ject ives(KEIYO-DOSHI in Japanese) have we c lass i f ied into 3types according to their  inf lexion.
Two types ofthem are shown in Fig.
3.2.The inf lexion of auxi l iary verbs is thesame as the tradit ional  one.
Some examples areTable 3.1 Class i f icat ion of words by partsof speech.
No.16 and 17 are exceptional.No.
part of speech123456789l0ii1213141516"17"nounpronounnmneralquasi -nounpref ixsuff ixpart  modi fy ing substant ivesadverbconjunct ionexc lamat ionpart ic leverbadject iveauxi l iary verbsubsidiary verbinf lexioncarr iage returnTable 3.2 Class i f icat ion of verbs.No Inf lexion Example123456789i0ii121314GODAN-KATS UYO 1,, 2,, 3" 4,, 5" 6,, 7" 8,, 9,, i0KAMI - I CH I DAN- KATS UYO,SHI MO- I CHI DAN-KATSUYOSAGYO-HENKAKU- KATSUYOKAGY O- HENKAKU -KATS UYOVerb: ARU (be)IKUKATS UNORUKAUSHINUYOMUYOBUSAKUOSUOYOGUOKI RUNAGE RUSURUKURUARUshown in Fig.
3.3.YOMUWord StemIKU I ~(go)Inf lexion Fol lowing vowelF irst  I Endingconsonant vowel Consonant & vowel(a)- -  K ~ A (i. negative)I (2.
RENYO)U (3. conclusive)U (4 RENTAI)E (5. conditional)E (6. imperative)OU(7; volit ional)(b) T ~ TA (3) (auxiliary)TA (4) verbTE (particle)(read)Fig.
3.\]Inf lexionAdject ive IAdject ive II (Verbal-adject ive )YO ~ M - -  the same as (a)\ N (c) ~ DA (3) (auxiliary)DA (4) verbDE (particle)Inf lexion of verbs: IKU (go) (No.l in Ta-ble 3.2) and YOMU (read) (No.6 in Table3.2).
RENYO or RENTAI means that thefol lowing word must be inf lexional  orsubstantive respectively.
The fol lowingwords TA and DA are auxi l iary verbs andTE and DE are part ic les.Word I Stem I Inf lexionUTSUKUSHII  UTSUKUSHI(beutiful)SHIZUKADA(beingquiet )Fig.
3.2SHIZUKA~!
I  (3)(4)u (2)EREBA (5)AROU ( 7 )T - -  TA (3)T - -  TA (4)DA (3)NA (4)ARA ' 5\~DA~ou (7)~ D A T  - -  TA (3)- -DAT  - -  TA (4)Examples of inf lexion of an adject ive and averbal -adject ive.
The numbers in parenthesesare ident i f ied with the ones in Fig.
3.1.Word Stem Inf lexion(2)(3)(4)(5)(7)Fig.
3.3Word Stem Inf lexionNAI NA~iU  (4) 32\k'KERE--BA c5)~KAT- - -TA  (3)'KAT---TA (4)Examples of inf lexion of auxi l iary verbs.
Thenumbers in parentheses are ident i f ied withthe ones in Fig.
3.1.-4743.1.1.2.
Classification of words by syntacticfunctionsIn a Japanese sentence some words expressmaterial (no~ma) such as substantives and verbs,and the others express syntactic function (no~-sis) such as particles and auxiliary verbs \[9\].The latter controls the syntactic function ofthe former, or; in other words, gives a materialword or phrase a modifying function and thesetwo words usually appear in a pair in sentences.The pair is called a phrase, and some modifyingrelation is established between phrases.
Andthose modifying relations between phrases com-pose a sentence.
In some cases a phrase consistsof only a word such as an adjective, an adverband some inflexional word, without being accom-panied by any word that expresses a syntacticfunction, and itself carries a syntactic func-tion.
Some examples are shown here.
(i)WATASHI (pronoun) NO (particle) HON ~noun" I " "book"..................... phrasel lmodifying relation(my books)adjective) H~A (noun )SHIROI ...... ( white flowerphrase \[modifying relation(white flowers)ISHI noun ) NO (particle) IE (noun)(stone l housephrasemodifying relation(stone houses)HON.noun.
KONO(7 in Table 3.1) GA(particle)..ph}ase this ~ (book)Imodifying relation.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.phrase (This book ...)(ii) TOKYO (TOKYO)n?un .
E (particle,to I~U (verbgo)I phrase Imodifying relation(go to TOKYO)HON (noun.
UO (partlcle) KAU (verb)book) l buyphraseImodifying relation(buy a book)The syntactic relation is classified intothree categories:(a) Modification of a substantive word orphraseSome examples are shown in above (i).
(b) Modification of an inflexional word orphraseSome examples are shown in above (ii).
(c) Termination (the end of a sentence).3.1.3.
Szntactic state transition networkA syntactic state transition network is anetwork which represents the Japanese syntax\[10\].The standard form is shown in Fig.
3.4, whereeach S represents a syntactic state, an arrowa transition path to the next state, C a part ofspeech, and I syntactic information.
Therefore,if a state S O is followed by the part of speechC O then the state transits context-freely to S 1outputting syntactic information I 0.To an inflexional word a transition networkis also applied and represents the inflexion.
Inspeech recognition it is necessary to pursue thewhole transition from the stem of an inflexionalword to the end of inflexion, in other words, topredict the stem of an inflexional word with itsinflexional ending and to output the syntacticinformation comprehensively for the whole wordsincluding their inflexions.
In Fig.
3.5 is shownan example of transition network and accompany-ing syntactic information for two verbs "IKU(go)"Fig.
3.4c0/I ?Standard form of syntactic statetransition network.
SO, Sl: states,CO: part of speech or inflection,I0: syntactic information.rerereFig.
3.5 Transition network for verbs: "IKU (go)and YOMU (read)" with their inflexionand  syntactic information.
X/Z meansthat X is output letters and Z is thesyntactic information.
~: empty, CR:carriage return, P: particle, and thenumbers are identified with the onesin Fig.
3.1.--475--and "YOMU (read)".
This procedure corresponds topredicting all possible combinations of a verbwith auxiliary verbs.
For example, for a word"go", it may be better to predict probable com-binations: go, goes, will go, will have gone,went and so on, though the number of probablecombinations will be restricted.The syntactic state transition network cannot only predicts combinable words but also out-puts syntactic information about modifying rela-tion between phrases.3.2.
Knowledge about Vocabulary3.2.1.
Word dictionaryEach word is entered in a word dictionaryin group according to part of speech as shown inFig.
3.6.
Each entry and its inflexion table arerepresented in Roman letters together with seman-tic information.
If a part of speech is predict-ed using the syntactic state transition network,a word group of the predicted part of speech ispicked out from the dictionary.3.2.2.
Automatic translating routine for Romanletter strings and inflexion tablesThis routine translates a word written inRoman letters into a phoneme string using atable \[ii\].
A translated phoneme string of a pre-dicted word is used as a reference for matchingan input phoneme string.
This routine can alsoextract the characteristic phoneme string of aword.
A characteristic phoneme string of a wordcontains only phonemes to be surely extractedfrom the speech wave.
It is composed of vowels,/s/ and silence, and represents major acousticinformation of a word.
Some examples of the pho-neme strings are shown in Table 3.3.For matching procedure between an input pho-neme string and a predicted word are used bothphoneme and characteristic phoneme strings ofthe word.
Here, these phoneme strings are notstored in the word dictionary.
The system hasonly one word dictionary written in Roman let-ters and phoneme stringsnecessary for matchingare produced each time from the word dictionaryusing the translating routine.
This fact makesit very easy to enrich the entry of vocabulary.part of WordspeechC 0 ~  WOO 1W002CI------~ WI01WI02C2-----~ W201W202Fig.
3.6 Word dictionary.Table 3.3 Examples of phoneme and characteris-tic phoneme strings of words.
P: un-voiced stop, N: nasal, B: buzz, .
:silence.Word Phoneme Characteristic(Pronunciation) string phoneme stringOZIISAN OBSIISAN OISAYAMA IEAMA AASENTAKU SEN.PA.PU SE.A.UOOKII OO.PSI O.SI3.3.
Semantic KnowledgeSemantic information is used for the follow-ing purposes.
(i) Elimination of semantically inconsistentsentences which have been recognized using onlyacoustic and syntactic information.
(ii) Future development to semantic understand-ing of natural language by forming semantic net-works.
(iii) Control of transition on the syntacticstate transition network through the syntax ana-lyser.3.3.1.
Semantic informationOne of the semantic information dealt withis "knowledge about meaning".
This knowledge in-volves (i) what each word means, (ii) verb-cen-tered semantic structure, and (iii) schema of astory \[i0\].
The other information is, so called,"remembrance of episode" which means the remem-brance of a topic of conversation.
In the pre-sent system, meaning of a word is represented bya list structure, and the others are representedby networks.In the system the knowledge about meaningmust be given from outside and can not yet be in-creased or updated by itself, but remembrance ofepisode can be increased or updated whenever newinformation comes in.
While, if a schema hasbeen already formed for a topic to be talkedfrom now on, the knowledge of the topic willhelp recognition of the spoken topic.
In the fol-lowing sections how semantic information worksin the recognition system will be explained.3.3.1.1.
Meaning of a wordDenote a word by n, its characteristic fea-tures by fi(i=l,...,m; m is the number of fea-tures).
Then, the meaning of a word may be ex-pressed as follows:n(fl' f2' "''' fm )'wheref.
= 1 when the word has the characteristic1 feature f ,  lf = 0 when the word has not the feature f .
1 1For example, if fl = concrete, f2 = creature, f3 =animal, .... thenhill (1, 0, 0, ..... ), dog (i, i, i, ..... ).476 .
.
.
.3.3.1.2.
Def in i t ion of a verbA verb plays very important semantic rolein a s imple sentence.
A semantic representat ionof meaning of a verb is shown in Fig.
3.7, wheren O , n I , ..., n. are nodes, and Ar I, Ar 2, .., Ar.
l 1attatched to each arc are the natures of eacharc.
The nature of a node n is determined by aPnature Ar at tatched to the arc d i rect ing to thePnode n .
Thus,PStructure = (V, Arl, Ar 2, ..., Ari),in  I = a word or node qual i f ied  bya nature Arl,Restr ict ion "n. a word  or node qual i f ied  byl a nature Ar.
1.For example, a verb "IKU (go)" is def ined byFig.
3.8.3.3.1.3.
SchemaThe form of a schema can not be determineduniquely.
Deal ing with a story, we may be ableto represent the schema, for example, as shownin Table 3.4 and Table 3.5.3.3.1.4.
Remembrance of an episode --- Forma-t ion of a semant ic  networkRefer ing to the results of syntact ic  analy-sis and the re lat ion between the nature of anarc and a case part ic le  (partly involv ing anoth-er part ic le) ,  the system forms a semantic net-work for a simple sentence center ing a recog-nized verb.
For instance, if a word sequenceOZI ISAN WA YAMA E SHIBAKARI NI IKIMASHITA.
(An old man went to a h i l l  for gathering)f irewoods.with syntact ic  informat ion is given, a networkshown in Fig.
3.9 wi l l  be formed.
In Fig.
3.9 aprocess construct ing a sentence is also shown.3.3.2.
L ink ing a semantic network for a sen-tence with a semantic network for anepisodeAfter  a network for a sentence has beenformed, the network must be l inked Up with thealready constructed network for the current epi-sode.
For  this purpose a new node must  be identi-f ied with the same node in the episode network.< nl>Fig.
3.7verb\] isa ,Ar I< no> ,< n 2 > < n 3 >Def in i t ion of a verb.n: node, Ar: nature of an arc,isa: is an instance of.IKU (go)isa ~.~ <n5>< n l > ~ < n 0 ~ - ~  at T~ n2) ~'~r?m L lto L~~.
-~< n4 ><n3>Fig.
3.8 Def in i t ion of a verb "IKU (go)"sub: subject, L: location, T:time, isa: is an instance of,ino: in order  to.Table 3.4 A schema of a story.Story Tit leScenes OpeningsceneEpisodem, n, o j k, i, mevent i event 2Characters  A, B, C, D A, B, E, F A, COther key words m, nevent nX, Y, Za, b, cTable 3.5 A schema for a tale "MOMOTARO (a brave boy born out of a peach)".Story MOMOTAROScenes Openingscene event 1an old manCharacters an old man an old womanOther key wordsonce upon atime, l ivehil l ,  f ire-woods, goEpisodeevent 5Momotaro, dog,monkey, pheasanttreasure, br ing--477--Word sequence recognized using acoustic and syn-tactic information:OZIISAN WA YAMA E SHIBAKARI NI IKIMASHITA.
(an old) to a for gathering) (went)man (hill) (firewoodsForming phrases and giving syntactic informa-tion:OZIISAN WA YAMA E SHIBAKARI NI IKIMASHITA.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.\[phrase having\]\[RENYO\] \[RENYO\] \[RENYO\] verb, endConstructing a sentence by showing modifying re-lation:OZIISAN WA YAMA E SHIBAKARI NI IKIMASHITA.
(modi f icat ion)(a) Process of constructing a sentence.an old man go~isa ~:sa <i05> i-~ gathering~ ino  firewoods<lh> ~-~- <ioo> ...__._t~from / Ito L "~<i04><102> <103> isa ~ hill(b) Semantic network.Fig.
3.9 Process of constructing a sentence (a)and its semantic network (b) for "Anold man went to a hill for gatheringfirewoods.".
--- shows a phrase,shows modification and RENYO in \[ \]means this phrase modifies an inflex-ional word or phrase, ino: in order to.In the present system all relations explicitlyappearing in sentences and nodes expressing lo-cation are examined whether they have already ap-peared or not.
Time relation is not handled un-less it appears explicitly in sentences.
Deeperstructures of meaning such as causality or rea-soning are not yet able to be dealt with.
Fig.
3.i0 illustrates a network for the episode, whichhas been constructed after the system has proces-sed several sentences at the beginning of thetale of "MOMOTARO" shown below.There lived an old man and an old woman.The old man went to a hill for gathering fire-woods .The old woman went to a brook for washing.She was washing on a brookside.3.3.3.
Word prediction by a conjunction "TO(and)"When the syntax analyser has found a con-junction "TO (and)" which is used to enumeratesome nouns, the system can predict a followingnoun group.
For instance, for the input "MOMOTA-RO WA INU TO ... (MOMOTARO was accompanied by adog and ... ", the system picks up as a follow-ing noun a noun group having similar natures tothose a dog has.3.3.4.
Application of semantic knowledge tospeech recognitionUsing semantic knowledge the system ad-vances recognition process as follows:(i) Using acoustic and syntactic information,and sometimes semantic information, the systemprocesses an input sentence and outputs severalword sequences.
The syntax analyser gives toeach word sequence necessary syntactic informa-tion such as part of speech of each componentword, phrase and modifying relation betweenan old man< > l '  ~ s u b~ and Tisa/ and from / ~ f~ ~ f rom } T / \tot / IL / .<i007 >~ ~ ~ / 1 / ino / i015" isaisa ub L rOm <lO10< at T ><1014 >/an  o~ld w o m a n ~  ~ L i sa / / /  \]to L .
.
.
.
.| at T /<1020> isa > go <" <i~13\ isa ?
hill<1024>~ 1~10#25>~ ~'~<1023> isa > brookwashing ~ <1030> i sa  > do/ f r o m ~ ~  Tsub ~T "~<I034>1033Fig.
3.10 A network for the episode constructed after processing the severalsentences at the beginning of the tale of "MOMOTARO".gatheringfirewoods- -478  -phrases.
(ii) The semantic processor, using this syntac-tic information, forms a semantic network foreach word sequence.
(iii) A word sequence for which a semantic net-work failed to be formed satisfactorily is re-jected because of semantic inconsistency.
For in-stance, for an input sentence: "OZIISAN WA YAMAE SHIBAKARI NI IKIMASHITA.
(An old man went to ahill for gathering firewo6ds.
)", an output wordsequence: "OZIISAN WA HANA (flower) E SHIBAKARINI IKIMASHITA."
is rejected, because the verb"IKU (go)" has an arc "to Location" but the out-put word sequence has no word meaning locationand also the word "HANA (flower)" has no appro-priate arc in the network.
(iv) Taking into account the result of syntaxanalysis and reliability of acoustic matching,the most reliable word sequence is output.
(v) Finally, the semantic network of the out-put sentence is linked with the semantic networkof the episode formed by this process stage.4.
ResultsWe have been dealing with a Japanese fairytale, "MOMOTARO" consisting of simple sentencesand are now improving the system performance.The system's vocabulary is 99 words in total ex-cepting inflexion of verbs, auxiliary verbs andadjectives.
For simple sentences, the syntacticand semantic analysers work well.
Furthermorethe syntactic analyser alone can exactly recog-nize simple sentences with correct phonemestrings which would be provided from an ideal a-coustic analyser.
Though the level of semanticanalysis is in its first stage, for simple sen-tences the semantic analyser can reject semanti-cally inconsistent word sequences.Therefore the acoustic analyser must be im-proved first of all.
Its performance is as fol-lows: The total number of output phonemes expect-ed for an ideal acoustic analyser is 826 for thewhole 16 test sentences from the tale, while thenumber of correct phonemes obtained from the an-alyser is 741 (89.7 %), and that of erroneousphonemes is 125 (15.1%),  in which the numbersof mis-identif ied phonemes, missing phonemes andsuperfluous phonemes are 25, 60 and 40 respec-tively.The system can successfully recognize 25blocks (a part of a sentence uttered in a breath)out of 33 blocks, and 9 sentences out of 16 sen-tences.5.
ConclusionWe have just started to construct a speechrecognition system which can deal with semanticinformation and inflexion of words and have manyproblems to be solved.
IIowever, from this experi-ment it may be able to say as follows:(i) The acoustic analyser gives Pretty neat pho-neme strings, if only a learning process usingBayes decision theory for a group of vowels, na-sals and buzz is executed for each speaker.ii) Use of global acoustic features is effec-tive to reduce the number of predicted candidatewords, though its effectiveness is not so muchas in case of our isolatedly spoken word recogni-tion system \[12\].
(iii) In Japanese, inflexion of inflexionalwords are complicated, and the number of Romanletters involved in the stem and inflexional end-ing of each verb or each auxiliary verb is usual-ly very small.
Especially the number of letterswhich very important particles have is muchsmaller.
These aspects are very unfavorable forspeech recognition in which ideal acoustic pro-cessing can not be expected.
But the syntacticand matching processors can, to some extent, pro-cess input phoneme strings with erroneous pho-nemes satisfactorily.
(iv) Developing the vocabulary is very easy.Of course we must improve the capability ofthe syntactic and semantic analysers and also de-velop the vocabulary.Referencesi.
Reddy, D.R.
: "Speech recognition", Invitedpapers presented at the 1974 IEEE symposium,Academic Press (1975).2.
Sakai, T. and Nakagawa, S.: "A speech under-standing system of simple Japanese sentencesin a task domain", Trans.
IECE Japan, Vol.E60, No.
i, p.13 (1977).3.
Koda, M., Nakatsu, R., Shikano, K. and Itoh,K.
: "On line question answering system by con-versational speech", J. Acoust.
Soc.
Japan,Vol.
34, No.
3, p.194 (1978).4.
Sekiguchi, Y. and Shigenaga, M.: "Speech re-cognition system for Japanese Sentences", J.Acoust.
Soc.
Japan, Vol.
34, No.
3, p.204(1978).5.
Shigenaga, M. and Sekiguchi, Y.: "Speech re-cognition of connectedly spoken FORTRAN pro-grams", Trans.
IECE Japan, Vol.
E62, No.
7,p.466 (1979).6.
Sekiguchi, Y. and Shigenaga, M.: "A method ofphoneme identification among vowels and na-sals using small training samples", Acous.Soc.
Japan Tech.
Rep., $78-17 (1978).7.
Sekiguchi, Y. and Shigenaga, M.: "A method ofclassification of symbol strings with someerrors by using graph theory and its applica-tion to speech recognition", Information pro-cessing, Vol.
19, No.
9, p.831 (1978).8.
Shigenaga, M. and Sekiguchi, Y.: "Recognitionof stop consonants", 10th ICA, (1980).9.
Suzuki, K.:"NIPPON BUNPO HONSHITSURON"(Funda-mental study on Japanese grammar), Meiji-sho-in (1976).I0.
Norman, D.A.
and Rumelhart, D.E.
: "Explora-tions in cognition", W.H.
Freeman and Company.(1975).ii.
Sekiguchi, Y. and Shigenaga, M.: "On theword dictionary in speech recognition system",Reports of Faculty of Eng., Yamanashi Univ.,No.
28, p.122 (1977).12.
Sekiguchi, Y., Oowa, H., Aoki, K. and Shige-naga, M.: "Speech recognition system for FORT-RAN programs", Information Processing, Vol.18No.
5, p.445 (1977).--479--
