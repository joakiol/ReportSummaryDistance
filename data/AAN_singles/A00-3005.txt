Corpus-Based Syntactic Error Detection Using Syntactic PatternsKoldo Gojenola, Maite OronozInformatika Fakultatea, 649 P. K., Euskal Herriko Unibertsitatea,20080 Donostia (Euskal Herria)jipgogak@si.ehu.es, jiboranm@si.ehu.esAbstractThis paper presents a parsing system for thedetection of syntactic errors.
It combines arobust partial parser which obtains the mainsentence components and a finite-stateparser used for the description of syntacticerror patterns.
The system has been tested ona corpus of real texts, containing bothcorrect and incorrect sentences, withpromising results.IntroductionThe problem of syntactic error detection andcorrection has been addressed since the earlyyears of natural language processing.
Differenttechniques have been proposed for the treatmentof the significant portion of errors (typographic,phonetic, cognitive and grammatical) that resultm valid words (Weischedel and Sondheimer1983; Heidorn et al 1982).
However, althoughmost currently used word-processors actuallyprovide a grammar checking module, little workhas been done on the evaluation of results.There are several reasons for this:?
Incomplete coverage.
Some of the bestparsers at the moment can analyze only asubset of the sentences in real texts.Compared to syntactic valid structures, the setof syntactically incorrect sentences can beconsidered almost infinite.
When a sentencecannot be parsed it is difficult to determinewhether it corresponds to a syntactic error orto an uncovered syntactic onstruction.
In theliterature, syntactic errors have been definedmostly with respect to their correspondingcorrect constructions.
The use of unrestrictedcorpora confronts us with the problem offlagging a correct structure as erroneous(false alarms).
These facts widen the scope ofthe problem, as not only incorrect structuresbut also correct ones must be taken intoaccount.On the other hand, robust parsing systems(e.g., statistical ones) are often unable todistinguish ungrammatical structures fromcorrect ones.24?
The need for big corpora.
Each kind ofsyntactic error occurs with very lowfrequency and, therefore, big corpora areneeded for testing.
Even if such corpora wereavailable, the task of recognizing errorinstances for evaluation is a hard task, as thereare no syntactically annotated treebanks witherror marks for the purposes of evaluationand testing.
Thus, to obtain naturallyoccurring test data, hundreds of texts must beautomatically and manually examined andmarked.The aim of the present work is to examine thefeasibility of corpus-based syntactic errordetection, with methods that are sensitive enoughto obtain high correction rates anddiscriminating enough to maintain low falsealarm rates.
The system will be applied toBasque, an agglutinative language with relativefree order among sentence components.
Itsrecent standardization makes it necessary todevelop a syntactic hecking tool.The remainder of this paper is organized asfollows.
After commenting on the literature onsyntactic error detection in section 2, section 3presents a description of the linguistic resourceswe have used.
Section 4 describes the error typeswe have treated, while section 5 gives theevaluation results.1 BackgroundKukich (1992) surveys the state of the art insyntactic error detection.
She estimates that aproportion of all the errors varying between25% and over 50%, depending on theapplication, are valid words.
Atwell and Elliott(1987) made a manual study concluding that55% of them are local syntactic errors(detectable by an examination of the localsyntactic context), 18% are due to globalsyntactic errors (involving long-distancesyntactic dependencies, which need a full parseof the sentence), and 27% are semantic errors.Regarding their treatment, different approacheshave been proposed:?
The relaxation of syntactic constraints(Douglas and Dale 1992).
This grammar-based method allows the analysis of sentences\[ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
., Sentence II II Morphologicalanalysis and disambiguationIIiChart-parser, chart (automaton) IJ IFinite-state parser, No Error / Error Type(s) ,JI .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
|Figure 1.
Overview of the system.that do not fulfill some of the constraints ofthe language by identifying a rule that mighthave been violated, determining whether itsrelaxation might lead to a successful parse.
Itsmain disadvantage is the need of a full-coverage grammar, a problem not solved atthe moment, except for restrictedenvironments (Menzel and SchrOder 1999).?
Error patterns (Kukich 1992; Golding andSchabes 1996; Mangu and Brill 1997), in theform of statistical information, hand-codedrules or automatically earned ones.?
Charts have been used in grammar-basedsystems as a source of information; they canbe resorted to if no complete analysis isfound, so as to detect a syntactic error(Mellish 1989; Min-Wilson 1998).2 L ingu is t i c  resourcesWe have used a parsing system (Aldezabal et al1999, 2000) divided in three main modules (seefigure 1):?
Morphological analysis and disambiguation.A robust morphological analyzer (Alegria etal.
1996) obtains for each word itssegmentation(s) into component morphemes.After that, morphological disambiguation(Ezeiza et al 1998) is applied, reducing thehigh word-level ambiguity from 2.65 to 1.19interpretations.?
Unification-based chart-parsing.
Aftermorphological nalysis and disambiguation, aPATR-II unification grammar is appliedbottom-up to each sentence, giving a chart asa result.
The grammar is partial but it gives acomplete coverage of the main sentenceelements, uch as noun phrases, prepositionalphrases, sentential complements and simplesentences.
The result is a shallow parser(Abney 1997) that can be used forsubsequent processing (see figure 2).
In thisfigure, dashed lines are used to indicatelexical elements (lemmas and morphemes),while plain lines define syntactic onstituents.Bold circles represent word-boundaries, andplain ones delimit morpheme-boundaries.The figure has been simplified, as each arc isactually represented by its morphological ndsyntactic information, in the form of asequence of feature-value pairs.?
Finite-state parsing.
A tool is needed that willallow the definition of complex linguisticerror patterns over the chart.
For that reason,we view the chart as an automaton to whichfinite-state constraints can be appliedencoded in the form of automata andtransducers (we use the Xerox Finite StateTool, XFST, (Karttunen et al 1997)).
Finite-state rules provide a modular, declarative andflexible workbench to deal with the resultingchart.
Among the finite-state operators used,we apply composition, intersection and unionof regular expressions and relations.PP (in the nice house at the mountain)~modi f ie r  (at the mountain)~ -  .
_ - -  ~ S (I have seen (it))~ PP (in the nice house) kk ~ e s e e n ~mend i~o-~'O- -k~O " 0 et ~e"~)~ ~" 0 "Figure 2.
State of the chart after the analysis ofMendiko etxepolitean ikusi dut nik ('I have seen (it)in the nice house at the mountain').25Durangon, 1999ko martxoaren 7anIn Durango, 1999, March the 7th(Durango, (1999 (March, (7,inessive, genitive) genitive, inessivesing) sing) sing)Example 1.
Format of a valid date expression.The full system provides a robust basis,necessary for any treatment based on corpora.In the case of error detection, a solid base isindispensable.3 Er ror  detect ionAs a test, we chose the case of date expressionsdue to several reasons:?
It was relatively easy to obtain test datacompared to other kinds of errors.
Althoughthe data must be obtained mostly manually,date expressions contain several cues (monthnames, year numbers) that help in the processof finding semiautomatically test sentences.In any case, manual marking is needed for allthe retrieved sentences.?
The context of application is wide, that is,date expressions contain morphologicallyand syntactically rich enough phenomenawhere several types of errors can be found.These can be viewed as representative of theset of local syntactic errors so that the sameprocedure can be used when dealing withother kinds of errors.
Example 1 shows oneof the formats of a date expression.Basque being an agglutinative language, most ofthe elements appearing in date expressions (yearnumbers, months and days) must be inflected,attaching to them the corresponding numberand case morphemes.
Moreover, each differentdate format requires that the elements involvedappear in fixed combinations.
This is a commonsource of errors, not detectable by a spelling-checker, as each isolated word-form is correct.For evaluation, we collected 267 essays writtenby students (with a high proportion of errors)and texts from newspapers and magazines,totaling more than 500,000 words.
From themwe chose 658 sentences, including correct dates,incorrect dates, and also structures 'similar' todates (those sentences containing months andyears, which could be mistaken for a date), inorder to test false positives (see table 1).
As aresult of the selection procedure, the proportionof errors is higher than in normal texts.
Wedivided our data into two groups.
One of themwas used for development, leaving the secondone for the final test.
The proportion of correctdates is higher in the case of test data withrespect o those in the development corpus, sothat the effect of false positives will be evaluatedwith more accuracy.Number of sentencesCorrect datesi\[Structures 'similar' to datesIncorrect datesIncorrect dates with 1 errorDeve lopment411corpus24765 39255 17191 37Test  corpus43 % 47 6 % 16Incorrect dates with 2 errors 42 % 46 27 % 73Incorrect dates with 3 errors 6 % 7 4 % 11Table 1.
Test data.iError t~,pe1.
The year number cannot be inflected using a hyphen2.
The month lmartxoak) must appear in lowercase3.
The optional locative preceding dates (Frantzia)must be followed by a comma4.
The day number after a month in genitive case(martxoaren) must have a case mark5.
The day number after a month in absolutive case(ekainak) cannot have a case mark6.
The month (martxoan) must be inflected in genitiveor absolutive caseExampleIDonostian, 1995-eko martxoaren 14an1997ko martxoak 14Frantzia 1997ko irailaren 8anDonostian, 19995eko martxoaren 221998.eko ekainak 14ean argitaratuaDonostian, 1995.eko martxoan 28anCombination of errors I2, 3 and 4) karrera bukatu nuenean 1997ko Ekainaren 30anTable 2.
Most frequent error types in dates.26define NP_Mon th_Absolu t ive or_Ergat ivedefine PP Year_Genitivedefine Error_Type 5define Mark_Error Type__5NP_Month_Abs olut ive_or_Ergat ive Inflected_Number;\[ Error__Type_5 \] @-> BEGINERRORTYPE5 "... " ENDERRORTYPE5I I Optional_place_Name Optional_Cor~na PP_Year_Genit ive _Example 2.
Regular expressions for an error pattern.After examining different instances of errors, wechose the six most frequent error types (see table2).
In a first phase, one or more patterns weredefined for each error type.
However, we soonrealized that this approach failed because quiteoften two or three errors might appear in thesame expression.
This phenomenon asked for akind of 'gradual relaxation' approach, whichhad to consider that several mistakes could co-occur.
Instead of treating each errorindependently, we had to design error patternsbearing in mind not only the correct expression,but its erroneous versions as well.
For example,the last sentence in table 2 contains threedifferent errors, so that the error pattern for thesecond error should consider the possibility ofalso containing errors 3 and 4.
This relaxationon what could be considered a correct date hadthe risk of increasing the number of falsepositives.
As the number of interactions amongerrors grows exponentially with the number oferrors (there are potentially 2 6 combinations ofthe six error types), we based our error patternson the combinations actually found in thecorpus, so that in practice that number can beconsiderably reduced (we did not find anyexpression containing more than three errors inthe corpus).The error pattern for the fifth kind of error (seeexample 21 ) is defined in two steps.
First, thesyntactic pattern of the error is defined (an NPconsisting of a month in ergative or absolutivecase followed by an inflected number), andnamed Error_Type5.
Second, a transducer(Mark_Error_Type_5) is defined whichsurrounds the incorrect pattem (represented byNumber of sentencesUndetected date errorsDetected date errorsFalse alarms"... ") by two error tags (BEGINERRORTYPE5and ENDERRORTYPE5).
To further restrict theapplication of the rule, left and right contexts forthe error can be defined (in a notationreminiscent of two-level morphology), mostly toassure that the rule is only applied to dates, thuspreventing the possibility of obtaining falsepositives.Concerning the definition of error patterns,equal care must be taken for correct andincorrect dates.
In a first phase, we devised rulesfor the errors but, after testing them on correctdates from the development corpus, we had toextend the rules so as to eliminate false positives.As a result, more than 60 morphosyntacticpatterns (each corresponding to a finite-stateautomata or transducer) were needed for thedefinition of the six basic error patterns.
Theyrange from small local constraints (45 automatawith less than 100 states) to the most complexpatterns (a transducer with 10,000 states and475,000 arcs).4 Eva luat ionTable 3 shows the results?
As the developmentcorpus could be inspected uring the refinementof the parser, the results in the second and thirdcolumns can be understood as an upper limit ofthe parser in its current state, with 100%precision (no false alarms) and 91% recall.The system obtains 84% recall over the corpusof previously unseen 247 sentences?
31 errorsout of 37 are detected giving the exact cause ofthe error (in cases with multiple errors almost allof them were found)?Development corpus4117 9%84 91%0Table 3.
Evaluation results.Test corpus'2476 16%31 84%5i For more information on XFST regular expressions,see (Karttunen et al 1997)?27Exampleatxiloketa 1998ko urtarriletik irailaren 16ra ...the imprisonment from January 1998 till the 16th ofSeptemberDonostian 1960ko Urtarrilaren jaioaborn in Donostia in the January of 1960etorriko da 1997ko irailaren 26ko 1 : 15etanit will come the 26 of Septernber 1997 at 1:15atzotik 1999ko abenduaren 31arte,from ~esterday until the 31st of DecemberPrimakovek 1998ko irailaren 1 in hartu zuen ...Primakov took it on the 11th o\[ September 1998Cause of the errorStructure similar to a date incorrectly interpreted as adate and flagged as erroneous.Incorrect Basque construction that is interpreted asadate.The system takes the hour number (1:15) as the day ofthe month.The grammar does not cover the arte (until) particle, soa correct date is flagged as ungrammatical.The unknown word Primakov is interpreted as alocative.Table 4.
False alarms.Regarding precision, there are 5 false alarms,that is, correct dates or sentences similar to datesflagged as erroneous.
If these false positives aredivided by the number of sentences (247) of thetest corpus, we can estimate the false alarm rateto be 2.02% over the number of dates in realtexts.
Table 4 examines ome of the false alarms,two of them due to expressions imilar to datesthat are mistaken for dates, other two relate toconstructions not taken into account in thedesign of the partial grammar, and the last one isdue to insufficient lexical coverage.Although the results are promising, more corpusdata will be needed in order to maximizeprecision.Conc lus ionsThis work presents the application of a parsingsystem to syntactic error detection.
The reportedexperiment has as its main features:?
It is corpus-based.
If a system is to be useful,it must be tested on real examples of bothcorrect and incorrect sentences.
Although thismay seem evident, it has not been the case formost of the previous work on syntactic errors.This implies the existence of big corpora and,for most of the errors, manual annotation.?
The most successful methods for errordetection, i.e., relaxation of syntacticconstraints and error patterns over a chart,have been combined with good results.
Onthe other hand, the relaxation is not applieddynamically at parsing time, but it has beenmanually coded.
This implies a considerableamount of work, as we had to consider theformats for valid sentences as well as for alltheir incorrect variants.?
A partial robust parsing architecture providesa powerful way to consider simultaneouslyinformation at the morphemic and syntacticlevels.
The unification grammar is necessaryto treat aspects like complex agreement andword order variations, currently unsolvableusing finite-state networks.
It constructs allthe possible syntactic components.
On theother hand, regular expressions in the formof automata nd transducers are suitable forthe definition of complex error patternsbased on linguistic units.We are currently exploring new extensions to thesystem:?
Adding new kinds of errors.
Our system, aswell as any system dealing with syntacticerrors, suffers the problem of scaling up, asthe addition of new types of errors willsuppose an increment in the number of errorpatterns that involves a considerable amountof work in the process of  hand-coding therules.
The possible interaction among rulesfor different error types must be studied,although we expect that the rule sets will bemostly independent.
Another interestingaspect is the reusability of the linguisticpatterns: in the process of treating errors indates some patterns describe generallinguistic facts that can be reused, whileothers pertain to idiosyncratic facts of dates.We plan to extend the system to otherqualitatively different ypes of errors, such asthose involving agreement between the maincomponents of the sentence, which is veryrich in Basque, errors due to incorrect use ofsubcategorization and errors in post-positions.
Although the number of potentialsyntactic errors is huge, we think that thetreatment of the most frequent kinds of errorwith high recall and precision can result inuseful grammar-checking tools.?
Automatic acquisition of error detectingpatterns.
Although manual examinationseems unavoidable we think that, with acorpus of errors big enough, machinelearning techniques could be applied to the28problem of writing error patterns (Goldingand Roth 1996; Mangu and Brill 1997).
Thissolution would be even more useful in thecase of combinations of different errors.
Inany case, it must be examined whetherautomatic methods reach the high precisionand reliability obtained by hand-coded rules.?
Using either hand-coded rules orautomatically learned ones, both methodshave still the problem .of obtaining andmarking big test corpora, a process that willhave to be made mostly manually (except forsome limited cases like word confusion(Golding and Roth 1996)).
This is one of themajor bottlenecks.AcknowledgementsThis research is supported by the BasqueGovernment, the University of the BasqueCountry and the Interministerial Commission forScience and Technology (CICYT).
Thanks toGorka Elordieta for his help writing the finalversion of the paper.ReferencesAgirre E., Gojenola K., Sarasola K., Voutilainen A.
(1998) Towards a Single Proposal in SpellingCorrection.
COLING-ACL'98, Montreal.Abney S. (1997) Part-of-Speech Tagging and PartialParsing.
In Corpus-Based Methods in Language andSpeech Processing, Kluwer, Dordrecht, 1997.Aldezabal I., Gojenola K., Oronoz M. (1999)Combining Chart-Parsing and Finite State Parsing.Proceedings of the Student Session of the EuropeanSummer School in Logic, Language andComputation (ESSLLI'99), Utrecht.Aldezabal I., Gojenola K., Sarasola K. (2000) ABootstrapping Approach to Parser Development.Sixth International Workshop on ParsingTechnologies, Trento.Alegria I., Artola X., Sarasola K., Urkia.
M. (1996)Automatic morphological nalysis of Basque.
Literary& Linguistic Computing, Vol.
11.Atwell E., Elliott S. (1987) Dealing with Ill-FormedEnglish Text.
In The Computational Analysis ofEnglish: a Corpus-Based Approach, De.
Longman.Douglas, S., Dale R. 1992.
Towards Robust PATR.COL1NG'92, Nantes.Ezeiza N., Alegria I., Arriola J.M., Urizar R., Aduriz I.
(1998) Combining Stochastic and Rule-BasedMethods for Disambiguation in AgglutinativeLanguages.
COLING-ACL-98, Montreal.Golding A. and Schabes.
Y.
(1996) Combining trigram-based and feature-based methods for context-sensitivespelling correction.
In Proc.
of the 34th ACLMeeting, Santa Cruz, CA.Golding A., Roth.
D. (1996) A Winnow-basedApproach to Spelling Correction.
Proceedings of the13th International Conference on Machine Learning,ICML'96.Heidom G. E., Jensen K., Miller L. A., Byrd R. J.,Chodorow M. S. (1982) The EPISTLE text-critiquingsystem.
IBM Systems Journal, Vol.
21, No.
3.Karttunen L., Chanod J-P., Grefenstette G., Schiller A.
(1997) Regular Expressions For LanguageEngineering.
Journal of Natural LanguageEngineering.Kukich K. (1992) Techniques for automaticallycorrecting words in text.
In ACM ComputingSurveys, Vol.
24, N. 4, December, pp.
377-439.Mangu L., Brill E. (1997) Automatic Rule Acquisitionfor Spelling Correction.
Proceedings of the 14thInternational Conference on Machine Learning,ICML'97.Mellish C. (1989) Some Chart-Based Techniques forParsing Ill-Formed Input.
EACL' 89.Menzel W., Schr6der I.
(1999) Error Diagnosis forLanguage Learning Systems.
RECALL, specialedition, May 1999.Min K., Wilson W. (1998) Integrated Control of ChartItems for Error Repair.
COLING-ACL'98, Montreal.Roche E., Schabes Y.
(1997) Finite-State LanguageProcessing.
MIT Press.Weischedel R.M., Sondheimer N.K.
(1983) Meta-rulesas a Basis for Processing Ill-Formed Input.
AmericanJournal of Computational Linguistics, 9.29
