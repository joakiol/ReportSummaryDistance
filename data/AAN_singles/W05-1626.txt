Chart generation using production systemsSebastian VargesInformation Technology Research InstituteUniversity of BrightonSebastian.Varges@itri.brighton.ac.ukAbstractProductions systems, traditionally mainly usedfor developing expert systems, can also be em-ployed for implementing chart generators.
Fo-cusing on bottom-up chart generation, we de-scribe how the notions of chart algorithms re-late to the knowledge base and Rete networkof production systems.
We draw on experiencegained in two research projects on natural lan-guage generation (NLG), one involving surfacerealization, the other involving both a contentdetermination task (referring expression gener-ation) and surface realization.
The projectscentered around the idea of ?overgeneration?,i.e.
of generating large numbers of output can-didates which served as input to a ranking com-ponent.
The purpose of this paper is to extendthe range of implementation options availableto the NLG practitioner by detailing the spe-cific advantages and disadvantages of using pro-duction systems for NLG.1 IntroductionA general question faced by the NLG practitioner iswhether to use an off-the-shelf generator or develop one?from scratch.?
Often, understanding the workings ofthe off-the-shelf generator and providing the requiredinput structures requires substantial work.
Further-more, the off-the-shelf generator may not provide therequired functionality without additional programming,the project may dictate the use of a particular program-ming language or frequent interaction with componentswritten in that language.In this paper, we describe how to implement chartgenerators in production systems, i.e.
from scratch.Production systems have traditionally mainly been usedfor developing expert systems [Giarratano and Riley,1993].
The particular production system we use, JESS[Friedman-Hill, 2003] is implemented in Java, making iteasy to interact with other Java components.
The ruleencodings described in this paper should also work forother production systems such as CLIPS (?C LanguageIntegrated Production System?, [Riley, 1999]).We used JESS in two projects centering around theconcept of overgeneration-and-ranking.
Both involvedthe generation of a large number of alternative outputswhich served as input to a ranker written in Java.
Searchwas directed by influencing the agenda ordering of thechart generator.
At the syntactic level, realization inboth projects was ?shallow.?
However, since we were us-ing expert system technology, we were able to use moresophisticated domain reasoning for content planning ?more specifically, referring expression generation ?
todrive the realizer in one of the projects.The two characteristics just described, the ability todeal with issues of search and the integration with rea-soning capabilities, make generation using productionsystems quite different from other methods of shallowgeneration.
For example, pipelines of XSLT stylesheetscan be used to transform XML trees encoding linguisticstructures [Wilcock, 2001; Moore et al, 2004].
However,the focus in using XSLT for generation is more on pur-suing a single alternative than on searching for the bestone.
Furthermore, rewriting XML trees with XSLT lendsitself toward top-down generation, whereas the use ofproduction systems naturally results in bottom-up gen-eration.In the following section, we relate chart algorithms toproduction systems at a more abstract level.
We thendiscuss two generators implemented in the productionsystem JESS.2 Chart algorithms and productionsystemsKnowledge-based expert systems consist of rules (or?productions?)
and a knowledge base of facts (KB).
Rulesexpress logical implications and facts contingent truths.Facts match (possibly partially defined) fact descrip-tions, or ?conditions?, in the antecedent of rules, andif all conditions required in a rule antecedent are sat-isfied, the consequent follows.
In a production system,this means the production is ?activated.?
All activatedrules are collected in a ?conflict set.?
After this, a de-cision is made about what rule to fire according to thesearch strategy (breadth-first and depth-first are usuallybuilt-in strategies).
Processing can be thought of as asequence of cycles where each cycle is defined as addingone fact to the KB, matching it against the rules, andcomputing what rules to fire next.
This may result innew facts, and a new cycle begins.The basic outline of knowledge-based expert systemsis similar in spirit to declarative rule systems based onthe logic programming paradigm in NLP in which theorder of rule execution does not affect the result.
Theknowledge base serves as a store for proven facts and ishence comparable to the chart data structures in NLP.More precisely, the knowledge base corresponds to a pas-sive chart since it only contains completed chart edges.Executing a rule consequent can involve the assertionor retraction of facts to/from the KB.
Since a chart ismonotonically accumulating, grammar rules only assertnew edges in our implementations.Another way of thinking about production systems isin terms of a blackboard architecture: the KB serves as ablackboard and rules/productions are triggered by newfacts that are added to it.Probably the most distinctive property of productionsystems is the compilation of the productions into a net-work.
The Rete networks of production systems (?rete?is Latin for ?net?)
exploit structural similarities betweenrule antecedents by creating a network that allows factsto match antecedents in several rules at once.
The ideais to create tests for conditions in rule antecedents and toshare the results between rules [Forgy, 1982].
Matchinga fact against the Rete network can partially ?activate?a whole set of rules that share that node.
This avoidscycling over possibly large numbers of rules in turn andrepeatedly matching the same elements.Standardly, a forward chaining interpreter is used toexecute productions.
This corresponds to bottom-uptree traversal algorithms in computational linguisticsterminology.
The ?conflict resolution strategy?
addressesthe above mentioned question which of the activatedrules should fire.
It corresponds to the agenda strategyin chart parsing/generation.
The following table relatesthe terminologies:Production Systems NLPproductions in grammar rulesRete networkworking memory/ passive chartknowledge basefacts in knowledge base passive edgespartially activated active edgesproductions (insideRete network)conflict resolution agenda withstrategy ordering functionSince the partially activated productions are part ofthe Rete network, they are more difficult to observe inpractice than the active edges of a chart.
However, pro-duction systems such as JESS provide means to inspectthe network.3 Case study 1: realization withautomatically derived rulesThe first project involves overgeneration (and ranking)with rules that were extracted from a semantically an-notated subset of the Penn Treebank II.
The input tothe realizer consists of a bag of semantic tags with asso-ciated values in the management succession domain, forexample PERSON=Piere Vinken, AGE=61 or POST=chairman.1We use structured (or ?unordered?)
facts of attribute-value pairs to define chart edges.
Figure 1 shows aslightly simplified production that, given two facts withheads NP-POST DESCR ADJ and PP-POST NODET generates anew fact with head VP-POST DESCR ADJ:(defrule phrasal-rule-83(NP-POST_DESCR_ADJ (idx ?i0) (coidx ?cx0) (syn ?s0)(consumes $?c0) (terms ?t0)(instances ?table0) (deriv $?d0))(PP-POST_NODET (idx ?i1) (coidx ?cx1) (syn ?s1)(consumes $?c1&:(set(create$ $?c0 $?c1)))(terms ?t1) (instances ?table1)(deriv $?d1))(phrasal-rule-83)=>(assert(VP-POST_DESCR_ADJ(idx (bind ?idx (npt))) (coidx ?cxc)(syn VP) (consumes (create$ $?c0 $?c1))(terms was named to ?t0 ?t1)(instances (combine-tables ?table0 ?table1))(deriv [VP p83-0366 ?idx was named to $?d0 $?d1])(fired-by phrasal-rule-83))))Figure 1: Grammar rule encoded as productionThis production effectively results in the bottom-uptraversal of a local tree.
The names of the fact headscombine syntactic and semantic information.
The factshave slots such as idx, a unique edge identifier, andderiv, which represents the derivation tree.
Slot valuesare mainly only picked up by variables (prefixed by ?and $?)
and passed on to the rule consequent.
However,there is an exception: the condition matching the secondedge with head PP-POST NODET performs a test in order toprevent combinations of edges that express overlappingsemantics, based on semantic indices associated with theattribute-value pairs of the input.
These are stored inthe consumes slot.Typically, the facts matched on the left-hand side ofthe production shown above provide realizations such as?the additional post?
and ?of chief executive officer.?
Thenewly generated edge combines this into ?was named tothe additional post of chief executive officer.?
Phono-logical forms are handled in the terms slot where theyare represented in combination with semantic tags, forexample ?the [POST DESCR ADJ additional] post.?
These1These semantic labels are slightly simplified.
For reasonsof space we cannot discuss the semantic annotation and ruleconstruction here.
See [Varges, 2003] for more details.rules/productions encode a phrasal generator with shal-low syntax: they only use syntactic categories.
However,other simple syntactic features, for example for model-ing number/gender/person agreement, could be incorpo-rated by adding the appropriate slots and values.The instances slot provides an example of the tight in-tegration of the production system JESS with Java.
Theslot contains references to Java objects that are relevantto the ranker.
Furthermore, combine-instance-tables onthe right-hand side of the production is a function callthat is simply passed on to the ranker written in Java.The left-hand side of the example production also con-tains a condition that matches a simple unique fact forthe name of the rule (phrasal-rule-83).
In this way,rules can be dynamically blocked and unblocked.
Onlythose rules are able to fire whose name has been assertedinto the KB.
Matching the name fact last in the rule an-tecedent allows the Rete compiler to identify possiblecommon prefixes of match patterns across rules.
Thiswould not be possible if a unique match condition wasplaced first.The realizer uses 476 automatically constructed pro-ductions.
Sharing in the Rete network is mostly limitedto the ?pattern network.?
In contrast, the ?join network?is not able to reduce the number of match computa-tions substantially because most grammar rules are bi-nary (see [Varges, 2003] for more details).
The realizer iscapable of generating several hundred sentences within afew seconds.
Averaged over 40 inputs taken from a testset, it produced 350 sentences within 5 seconds.4 Case study 2: referring expressiongenerationThe second use of a production system for NLG is fora manually written referring expression generator devel-oped in the TUNA2 project [Varges, 2004].
Conceptu-ally, it consists of two modules: a reasoner that pro-duces logical forms (descriptions of domain objects) froma domain representation and a realizer for those logicalforms.
Both modules are interleaved in the sense thatthe reasoner ?marks?
logical forms that it is able to real-ize, and the domain reasoner is only allowed to combinesimpler logical forms into more complex ones if they havebeen realized successfully.
One way to describe this pro-cessing architecture is in terms of two interleaved chartalgorithms that exchange chart items.
The other is interms of a blackboard architecture ?
in fact, the KB al-most acts as whiteboard [Cahill et al, 1999].
This isparticularly intuitive here, and also closer to the imple-mentation: the reasoner automatically responds to themarking of a logical form fact as being realized since pro-ductions are activated whenever a matching fact is addedto the KB (or changed).
In other words, the productionsof the modules communicate via the KB.The modules of the referring expression generator,i.e.
reasoner and realizer, are implemented by means ofnamespaces for the facts and productions they contain.2EPSRC grant GR/S13330/01In addition, we define namespaces for facts representingthe domain model and for the lexicon.
We show somefacts of the domain model since this is the starting pointof the computation:(DOMAIN::vertex (index v1))(DOMAIN::type (name musician) (index v1))(DOMAIN::attribute (name hair-colour) (value black)(index v1))(DOMAIN::vertex (index v2))(DOMAIN::type (name instrument) (index v2))(DOMAIN::relation (name hold) (rel-index r1))(DOMAIN::out-relation (out v1) (rel-index r1))(DOMAIN::in-relation (in v2) (rel-index r1))Facts define object types, attribute-values pairs andrelations between the objects.
In the example above,they describe a musician with black hair holding an in-strument.
The facts are defined in namespace DOMAINand are related by means of the indices held in the indexand other slots.
The use of vertex facts indicates thatthe representation is inspired by the Graph approach toreferring expression generation [Krahmer et al, 2003].At the first stage of processing, content determinationrules produce logical forms paired with a list containingthe vertices of the domain objects they describe:(LF::type-extension (extension v1) (id 3)(lf "(" type "=" musician ")")(depth 1) (type musician))(LF::neq-type-extension (extension v1) (id 17)(lf "(" NOT "(" type "=" instrument ")" ")")(depth 2) (negated 3))The first fact lists, in slot extension, all domain ob-jects of type ?musician?, which is only v1 in our exam-ple.
The second fact contains the vertices of all objectsthat are not of type instrument, which again is v1.
Thefacts contain the logical form as a sequence of atoms andstrings.
However, the fact heads are more importantfor matching since the logical forms (and many otherslot values) are just passed on to the right-hand side.Facts can contain slots that are only relevant to theirparticular type, for example negated for facts with headneq-type-extension.The namespace of the realization module is populatedwith facts that contain syntactic information and surfaceforms:(REALIZER::np (phon not an instrument)(id 35) (dtr-left 5) (dtr-right 11)(num sing) (pers 3) (form neq-indefinite))(REALIZER::syntax-semantics-mapping(sem-id 17) (syn-id 35))The REALIZER::np fact above is the realization ofa corresponding description fact in the LF namespace.The separate REALIZER::syntax-semantics-mappingfact records which description fact in the LF namespace isrealized by which fact in the REALIZER namespace, againby means of indices.
An alternative to using a mappingfact is to modify the REALIZER::np fact directly.The implementation currently consists of 95 produc-tions and 71 additional functions that are invoked on theright-hand sides of the productions.
These functions per-form tasks such as counting domain objects and relationsbetween objects, and computing the agenda ordering ofthe chart generator.5 Discussion and conclusionsWe consider the use of a production system in these twoprojects successful.
Production systems are suitable forthe efficient exploration of alternatives and for robust,?data-driven?
bottom-up processing.
Such processing isparticularly robust if ?flat?
input structures are used, andthis in turn is encouraged by the unnested structure ofthe facts in the knowledge base.
This points to a char-acteristic of production languages that at the same timeis a source of their efficiency (by allowing the construc-tion of the Rete networks) and a limitation: since theslot values of facts cannot contain recursive data struc-tures, we need to resort to the use of indices to expressthat certain facts ?belong together.?
This is evident inthe index slots of the domain model in the second casestudy, for example.
The same technique is used in theNL-SOAR project [Rubinoff and Lehman, 1994], to ourknowledge the most extensive use of production systemsfor NLP.
However, if indices are used extensively, morework needs to be done in the join network part of theRete network, partially offsetting its benefits.
In sum,we see the following advantages of using production sys-tems for NLG:?
they are able to deal with large numbers of (pos-sibly machine-learned) rules (case study 1, see also[Doorenbos, 1993]),?
they are suitable for integrating NLG with moregeneral inferencing/reasoning (case study 2),?
general advantages: (largely) declarative behaviour;seamless integration with Java if JESS is used; de-velopment: rapid prototyping, read-eval-print loop.On the other hand, we see the following disadvantages:?
facts of limited structure and unavailability of uni-fication: production systems are not well-suited fordeveloping generators based on unification-basedgrammar formalisms such as HPSG;?
general disadvantages: alternative tree-traversalstrategies such as head-driven approaches notstraightforward to implement; development: limitedcompile-time checks.One possibility of addressing the lack of nested datastructures might be to compile complex feature for-malisms into a more shallow cfg-like format, i.e.
againto automatically generate productions (as we did in thefirst project).
A further avenue of future work is thepre-compilation of descriptions for the referring expres-sion generator.
This is motivated by the fact that in ourapproach a large part of the computation of descriptionsis independent of the specific generation input.
Such pre-compilation should result in significant efficiency gains.In this paper we have not been able to explore pro-duction systems and, in particular, their Rete networksin full detail.
However, we hope to have convinced thereader that the use of production systems for NLG canbe advantageous when relatively shallow but rule-basedgeneration capabilities are required.References[Cahill et al, 1999] Lynne Cahill, Christy Doran, RogerEvans, Chris Mellish, Daniel Paiva, Mike Reape, Do-nia Scott, and Neil Tipper.
In Search of a ReferenceArchitecture for NLG Systems.
In Proc.
of EWNLG-99, 1999.
[Doorenbos, 1993] Robert B. Doorenbos.
Matching100,000 learned rules.
In Proc.
of AAAI-93, 1993.
[Forgy, 1982] Charles L. Forgy.
Rete: A Fast Algorithmfor the Many Pattern/ Many Object Pattern MatchProblem.
Artificial Intelligence, 19:17?37, 1982.
[Friedman-Hill, 2003] Ernest Friedman-Hill.
JESS -the Java Expert System Shell, Version 6.x.
San-dia National Laboratories, Software available athttp://herzberg.ca.sandia.gov/jess/, 2003.
[Giarratano and Riley, 1993] Joseph Giarratano andGary Riley.
Expert Systems: Principles and Practice.PWS Publishing, Boston, 2nd edition, 1993.
[Krahmer et al, 2003] Emiel Krahmer, Andre Verleg,and Sebastiaan van Erk.
Graph-based Generationof Referring Expressions.
Computational Linguistics,29(1):53?72, 2003.
[Moore et al, 2004] Johanna Moore, Kaska Porayska-Pomsta, Sebastian Varges, and Claus Zinn.
Generat-ing tutorial feedback with affect.
In Proc.
of FLAIRS,2004.
[Riley, 1999] Gary Riley.
CLIPS: A Tool for Build-ing Expert Systems.
http://www.ghg.net/clips/CLIPS.html, 1999.
[Rubinoff and Lehman, 1994] R. Rubinoff and J. F.Lehman.
Real-time Natural Language Generation inNL-Soar.
In Proc.
of IWNLG, 1994.
[Varges, 2003] Sebastian Varges.
Instance-based NaturalLanguage Generation.
PhD thesis, ICCS, School ofInformatics, University of Edinburgh, 2003.
[Varges, 2004] Sebastian Varges.
Overgenerating refer-ring expressions involving relations.
In Proc.
of INLG-04, 2004.
[Wilcock, 2001] Graham Wilcock.
Pipelines, Templatesand Transformations: XML for Natural LanguageGeneration.
In Proc.
of First NLP and XML Work-shop (NLPRS-2001), 2001.
