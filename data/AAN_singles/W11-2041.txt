Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 338?340,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsBEETLE II: an adaptable tutorial dialogue systemMyroslava O. Dzikovska and Amy Isard and Peter Bell and Johanna D. MooreSchool of Informatics, University of Edinburgh, Edinburgh, United Kingdom{m.dzikovska,j.moore,amy.isard,peter.bell}@ed.ac.ukNatalie Steinhauser and Gwendolyn CampbellNaval Air Warfare Center Training Systems Division, Orlando, FL, USA{gwendolyn.campbell,natalie.steihauser}@navy.milAbstractWe present BEETLE II, a tutorial dialogue sys-tem which accepts unrestricted language in-put and supports experimentation with differ-ent dialogue strategies.
Our first system eval-uation compared two dialogue policies.
Theresulting corpus was used to study the impactof different tutoring and error recovery strate-gies on user satisfaction and student interac-tion style.
It can also be used in the future tostudy a wide range of research issues in dia-logue systems.1 IntroductionThere has recently been much interest in develop-ing tutorial dialogue systems that understand studentexplanations (Graesser et al, 1999; Aleven et al,2001; Nielsen et al, 2008; VanLehn et al, 2007),because it has been shown that high percentages ofself-explanation and student contentful talk are cor-related with better learning in human-human tutor-ing (Chi et al, 1994; Litman et al, 2009).
How-ever, most existing systems use pre-authored tutorresponses for addressing student errors.
The advan-tage of this approach is that tutors can devise reme-diation dialogues that are highly tailored to specificmisconceptions, providing step-by-step scaffoldingand potentially suggesting additional exercises.
Thedisadvantage is a lack of adaptivity and generality:students often get the same remediation for the sameerror regardless of their past performance or dia-logue context.
It also becomes more difficult to ex-periment with different dialogue policies (includingerror recovery and tutorial policies determining themost appropriate feedback), due to the complexitiesin applying tutoring strategies consistently in a largenumber of hand-authored remediations.The BEETLE II system architecture is designed toovercome these limitations (Callaway et al, 2007).It uses a deep parser and generator, together witha domain reasoner and a diagnoser, to produce de-tailed analyses of student utterances and to generatefeedback automatically.
This allows the system toconsistently apply the same tutorial policy across arange of questions.
The system?s modular setup andextensibility also make it a suitable testbed for bothcomputational linguistics algorithms and more gen-eral questions about theories of learning.The system is based on an introductory electric-ity and electronics course developed by experiencedinstructional designers, originally created for use ina human-human tutoring study.
The exercises werethen transferred into a computer system with onlyminor adjustments (e.g., breaking down compoundquestions into individual questions).
This resultedin a realistic tutoring setup, which presents interest-ing challenges to language processing components,involving a wide variety of language phenomena.We demonstrate a version of the system that un-derwent a user evaluation in 2009, which found sig-nificant learning gains for students interacting withthe system.
The experimental data collection com-pared two different dialogue policies implementedin the system, and resulted in a corpus supportingresearch into a variety of questions about human-computer dialogue interaction (Dzikovska et al,2010a).338Figure 1: Screenshot of the BEETLE II system2 Example InteractionThe BEETLE II system delivers basic electricity andelectronics tutoring to students with no prior knowl-edge of the subject.
A screenshot is shown in Figure1.
The student interface includes an area to displayreading material, a circuit simulator, and a dialoguehistory window.
Currently all interactions with thesystem are typed.
Students read pre-authored cur-riculum slides and carry out exercises which in-volve experimenting with the circuit simulator andexplaining the observed behaviour.
The system alsoasks some high-level questions, such as ?What isvoltage?
?.An example dialogue with the system, taken fromthe evaluation corpus, is shown in Figure 2.
It showsthree key system properties: after the student?s firstturn, which was correct but incomplete, the systemrephrases the correct part of the student answer andprompts for the missing information.
In the secondturn, the system cannot interpret the student utter-ance, so it responds with a targeted help messageand a hint about the object that needs to be men-tioned.
Finally, in the last turn the system com-bines the information from the tutor?s hint and thestudent?s answers and restates the complete answersince the current answer was completed over multi-ple turns.3 Data Analysis and Future WorkThe data collected with the BEETLE II system hasbeen used to investigate several research questionsregarding discourse and dialogue: the effectivenessof different error recovery strategies (Dzikovska etal., 2010b); the underlying dimensions of user sat-isfaction and their relationship with learning gain(Dzikovska et al, 2011); the relationship between(student) alignment in dialogue and learning gain(Steinhauser et al, 2011); and the differences be-tween students?
social and metacognitive statementsdepending on the interaction style (Dzikovska et al,2010a).
We are currently annotating the data withadditional interaction parameters, including correct-ness of student answers and appropriateness of sys-tem hints.
This will allow us to apply PARADISE339Tutor: Why was bulb A on when switch Ywas open and switch Z was closed?Student: because it had a closed pathTutor: Right.
There is a closed path.
Keepgoing.Student: there was a closed path not effected bythe switchTutor: I?m sorry, I?m having a problem un-derstanding.
I don?t understand theword ?effect?
here.
Here?s a hint.
Youranswer should mention a battery.Student: it has a closed path with the batteryTutor: You?re on the right track.
Here?s theanswer.
Bulb A is still contained in aclosed path with the battery.Figure 2: Example interaction with the system from ourcorpusmethodology to get additional insight into which pa-rameters of tutorial dialogue affect learning gain anduser satisfaction.We are also adding a speech interface to the sys-tem, which will open new and interesting researchquestions.
Students often fail to use domain termi-nology correctly, and in the tutoring domain it isimportant to teach students to use proper terminol-ogy, so incorrect usage must be detected and cor-rected.
This means that grammar-based languagemodels are not appropriate for the language mod-elling, and opens new questions about robust ASRand language interpretation in such domains.AcknowledgementsThis work has been supported in part by US Of-fice of Naval Research grants N000141010085 andN0001410WX20278.
We thank Katherine Harrison,Leanne Taylor, Charles Scott, Simon Caine, CharlesCallaway and Elaine Farrow for their contributionsto this effort.ReferencesV.
Aleven, O. Popescu, and K. R. Koedinger.
2001.Towards tutorial dialog to support self-explanation:Adding natural language understanding to a cogni-tive tutor.
In Proceedings of the 10th InternationalConference on Artificial Intelligence in Education(AIED ?01)?.Charles B. Callaway, Myroslava Dzikovska, Elaine Far-row, Manuel Marques-Pita, Colin Matheson, and Jo-hanna D. Moore.
2007.
The Beetle and BeeDiff tutor-ing systems.
In Proceedings of SLaTE?07 (Speech andLanguage Technology in Education).Michelene T. H. Chi, Nicholas de Leeuw, Mei-HungChiu, and Christian LaVancher.
1994.
Eliciting self-explanations improves understanding.
Cognitive Sci-ence, 18(3):439?477.Myroslava Dzikovska, Natalie B. Steinhauser, Jo-hanna D. Moore, Gwendolyn E. Campbell, Kather-ine M. Harrison, and Leanne S. Taylor.
2010a.
Con-tent, social, and metacognitive statements: An em-pirical study comparing human-human and human-computer tutorial dialogue.
In Proceedings of ECTEL-2010, pages 93?108.Myroslava O. Dzikovska, Johanna D. Moore, NatalieSteinhauser, and Gwendolyn Campbell.
2010b.
Theimpact of interpretation problems on tutorial dialogue.In Proceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics(ACL-2010).Myroslava O. Dzikovska, Johanna D. Moore, NatalieSteinhauser, and Gwendolyn Campbell.
2011.
Ex-ploring user satisfaction in a tutorial dialogue system.In Proceedings of the 12th annual SIGdial Meeting onDiscourse and Dialogue.A.
C. Graesser, K. Wiemer-Hastings, P. Wiemer-Hastings, and R. Kreuz.
1999.
Autotutor: A simu-lation of a human tutor.
Cognitive Systems Research,1:35?51.Diane Litman, Johanna Moore, Myroslava Dzikovska,and Elaine Farrow.
2009.
Using natural language pro-cessing to analyze tutorial dialogue corpora across do-mains and modalities.
In Proc.
of 14th InternationalConference on Artificial Intelligence in Education.Rodney D. Nielsen, Wayne Ward, and James H. Martin.2008.
Learning to assess low-level conceptual under-standing.
In Proceedings 21st International FLAIRSConference, Coconut Grove, Florida, May.Natalie B. Steinhauser, Gwendolyn E. Campbell,Leanne S. Taylor, Simon Caine, Charlie Scott, My-roslava O. Dzikovska, and Johanna D. Moore.
2011.Talk like an electrician: Student dialogue mimickingbehavior in an intelligent tutoring system.
In Proceed-ings of the 15th International Conference on ArtificialIntelligence in Education (AIED-2011).Kurt VanLehn, Pamela Jordan, and Diane Litman.
2007.Developing pedagogically effective tutorial dialoguetactics: Experiments and a testbed.
In Proceedings ofSLaTE Workshop on Speech and Language Technol-ogy in Education, Farmington, PA, October.340
