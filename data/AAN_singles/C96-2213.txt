Using a Hybrid System of Corpus- and Knowledge-Based Techniquesto Automate the Induction of a Lexical Sublanguage GrammarGeert Jan WilmsUnion University2447 Hwy 45 Bypass Box 1857.
Jackson, TN 38305.
USAjwilms @buster.uu.eduAbstractPorting a Natural Language Processing(NLP) system to a new donmin renmins one of thebottlenecks in syntactic parsing, because of theamount of effort required to fix gaps in the lexicon,and to attune the existing grammar to the idiosyncra-cics of the new sublanguage.
This paper shows howthc process of fitting a lexicalizcd grammar to adomain can be automated to a great extent by using ahybrid system that combines traditimml knowledge-based techniques with a corpus-based approach.1.
Porting BottleneckThe trMitional gramnmr knowledgebase isthe product of a never-ending attempt by linguists toimpose order on something that refuses to be pinneddown because it is a living thing.
To a great extent,of course, these linguists are able to point toregularities, because language is first of all a practicalthing, a means to communicate, and there must be acolnmon base for such transfer to take phtce.
But allrules have exceptions, and often it turns out theseexception s are not isolated or random, so tile rule isfinetuned.
The problem is that what is "grannnatical"depends on the tmwritten rules of a certain domain.When the core grammar is augmented toacconnnodateall these idiosyncracies, the danger is not that anungrammatical sentence might slip through, but thatperfectly legitimate input receives an incorrectanalysis that is sanctioned by some peripheralgrammar rule that doesn't apply to the domain underinvestigation.
The semantic mnponent which getsthis false positive may reject it and request a secondreading, and the correct parse will most probablycome down the pipeline eventually if the grammar istruly broad-coverage, but a semantic module is notalways well equipped to detect such errors and mayhave a difficult time enough trying to resolveattachment problems, anaphoric references, etc., evenwhen presented with the "right" parse.In systems that use a lexical grammar, i.e.,whore part of the grammatical "knowledge" is storedoutside the non-terminals of the grammar proper,using subcategorization frames associated withterminals (words in Ihe lexicon), the peril likewise {sthat this resource becomes bhmted over time withoptions exercised only in certain settings or when theword is used in a marginal sense.Clearly something must be done to separatethe wheat from the chaff; the problem is twofold:getting the grammar and lcxicon to a ccrtain level ofcompetence was a laborious and timc-consmningprocess, and undoing this (i.e., eliminating unwantedoptions) is ahnost as difficult and painfifl as theconstant augmenting in the first place.
And secondly,what constitutes wheat and chaff is different for eachdomain, so this "dieting" must bc repeated lot everyport.Corpus-based techniques can help automatethis filtering, i.e., the source text should be viewednot only as an "obstacle" to be tamed (parsed), but asa resource that is best authority on what isgrammatical for the domain.2.
Data-Driven AttuningSince the carly 90s, there has been a surge ofintcrest in corpus-based NLP rescarch; someresearchers have tackled the grammar proper, makingit a probabilistic system,'or doing away with a rule-based system altogethcr and inducing a customizcdgrammar from scratch using stochastic methods.Dcspite the shortcomings of knowlcdgc-basedsystems, it seems wrong to throw away all that hasbeen gained, imperfect as it is.
Rather, a hybridsystem shoukl be developed where the strengths ofboth paradigms arc combined.
A good example l thatis a probabilistic Contcxt Free Grammar.Both Brcnt (1993) and Manning (1993), whoattempt o induce a lexicon of subcategorizationfeatures do so by completely discarding all pre-existing knowledge; both systems are stand-ahmc,without a parsing engine to test or use the "learned"information.
Brcnt in fact takes the "fronl scratch" toan extreme, and models his system aftcr the way achild learns to understand hmguage.
The algorithm ofboth authors basically inw)lves a pattern matcher thatscans the input for a verb, and once an anchor isfound, its right context is searched for cues lotsubcategorization fi'ames.
Brent's cues are veryprimitive, but because hc only picks up frmnes whenthe indicators are mmmbiguous, his results are veryreliable, albeit sparse (unless a very large trainingcorpus is used).
Manning's triggers on the other handare more sophisticated, but because they are lessdependable he must rely on heavy statistical filteringto reduce the "noise."
Although Manning's work ininducing features certainly accomplishes the goal ofcustomizing the lexicon to a particulm" domain, the1163porting process is still very much a manual enterprisein that he must write a mini-parser, a finite statemachine that includes an NP recognizer "and variousother rules to recognize certain cases that appearfrequently" (1993, 237).The dilemma of any pattern matchingapproach is in essence abootstrapping problem; if thegoal is to induce syntactic information (in the form oflexical features), then paradoxically some heavysyntactic processing power is needed to "parse" thetraining data to mine for evidence that a particularverb subcategorizes for an object option, whileavoiding false triggers (imposter patterns).
Manninghas built into his finite state device a panic mode toskip over ambiguous elements, but the trick is torecognize when things get hairy; that is where a lot ofprogramming el'tort akes place, and this finetuning isnever over (and must be repeated for every port to anew domain) as Manning himself admits (1993, 238).3.
Category Space of Context DigestsThe category space described in this paperuses a very different approach to inducesubcategorization frames; instead of starting fi'omscratch, the existing rich lexicon is exploited andfeatures are assigned to new words based on theirparadigmatic relatedness to known words.
Thusinstead of having to "hunt" for evidence, this approachis able to exploit the expertise of seasoned linguistswho constructed the initial lexicon, which wasintentionally designed to be broad-coverage.
Such astrategy not only avoids having to distinguish goodcues from irrelevant triggers, but is capable ofinducing some features like ASSERTION for whichthere is no marker that would indicate its presence.A category space is a multi-dimensionalspace in which the syntactic category of words isrepresented by a vector of co-occurrence counts(Schiitze 1993).
Proximity between two such vectors,or context digests, can be used to measure theparadigmatic relatedness of the words they represent(Schtitze and Pedersen 1993).
Paradigmatic relatednessindicates how well two words can be substituted lbreach other, i.e., how similar their syntactic behavioris.
This is not the same as the synonym relationship,which is based on semantic similarity.There are two general approaches in theliterature to collecting distributional information:window-based and syntactically-based (Charniak1993).
In the latter scheme the text is scanned until asection is found that is deemed to be relevant.
The"rough" structure of the sentence is computed, aprocess known as partial parsing.
This produces a flattree with phrase boundaries marked and identified bytype, but without much internal detail.A second approach to collecting relevantdistributional information is to keep co-occurrencecounts of the nearest lexical neighbors of a word,usually within a fixed distance or "window."
Markovmodels, for example, predict he POS of a word basedon the tags of the two or three words preceding it(bigrams and trigrams respectively).
Schatze hasexperimented with window lengths of four words, twohundred letter lburgrams and two thousand characters(Schtitze 1993).In the research presented here, a window oftour was adopted, i.e., for words of interest in thedomain of physical chemistry, co-occurrence countswere kept between those words and their immediateleft neighbors (Wi_l wi), immediate right neighbors(wi Wi+l), and left and right neighbors that are twowords away (wi-2 wi and wi wi+2 respectively).One importance difference between thecategory space reported here fi'om the one in Schiitzeand Pedersen (1993) is that words were disambiguatedby part of speech so as not to mix up contextinformation of unrelated tokens, a problem Sch/itzeacknowledges plagues his system (1993, 254).
Thecorpus was tagged using Brill's tagger (Brill 1993),which is based on what he calls transformatiombasederror-driven learning.
1430 word types tagged as verbsoccurred frequently enough (>10x) in the trainingcorpus to warrant constructing a vector or contextdigest.
As Zipf's law would predict, there is a longtail of word types which occur too infrequently topermit gathering useful statistics.Each window of the context digests tracksco-occurrence counts with word types of ~ POS,provided these types have a minimum frequency of100 in the training corpus.
For "rare" neighbors, thealgorithm simply records the neighbor's POS, acompromise to keep the size of the arrays manage-able, while providing some information on thesyntactic ontext.Context digests are formed by combining the4 fixed windows, each consisting of co-occurrencecounts with 5,509 possible neighbors.
In addition,some limited long(er)-distance information isappended to the vector: the training corpus has beenaugmented with bracketing information, that is, withimplicit trees that exhibit binary branching, butwhose nonterminals are unlabelled.
This is anotherapplication of Brill's transformation-based error-drivenlearner (Brill 1993), which was trained on 32,000bracketed sentences from the Penn Treebank.
Thesephrasal boundaries are of variable length, and can infact span the whole sentence.
Ideally, the name of thetype phrase that the verb occurred in should be used asa clustering feature, but since this information isunavailable (the non-terminals in the trees implicit inthe bracketing are unlabelled) the next best thing isused, and each boundary is marked by a pair of tagsoccurring on either side of the bracket.Each context digest for verbs, then, contains116427,654 possible entries.
The resulting matrix is verysparse, however; the density for the verb categoryspace is only 1.5 percent.
Hence the distributionalinformation is generalized by means of a matrixmanipulation method called Singular ValueDecomposition (SVD).
This technique is el'ten usedin factor analysis, because reducing the representationto a low dimensionality allows one to better visualizethe space, lit is exactly this compactness ofrepresentation that has led Schtitze to apply SVD tothe field of NLP, to reduce the number of inputparameters to a neural net, without sacrificing toomany of the fine distinctions in the original text(Schiitze 1993).
Deerweester tal.
(1990) introducedSVD to the field of inlk)rmation retrieval lor improveddocmnent representations; the original term-documentmatrix is decomposed into linearly independentfactors, many (5t' which are very small.
Anapproximate model with fewer dimensions can beconstructed by ignoring these small components.
Bycombining only the first k linearly independentcomponents, a reduced model is built which disregardslesser terminology variations, because k is smallerthan the number of rows (terms).To generalize the associational patterns inthe category space that was bootstrapped from thephysical chcmistry corpus, SVD was applied with itconservative value for k of 350.
The tool used for thispurpose was a slightly modified version of the las2module from the SVDPACKC package (Berry et al1993).
Tim generalizing effect of SVD causes thecategory space for verbs to become much less sparse:35.4 percent of the entries now have non-zero%ounts."
Most of these are new counts, i.e.
SVDinfers context similarities between words that may notbe apparent in the original co-occurrence matrix due tothe natural randomness in any corpus sample.
Theaverage number (51' context digests that are verysimilar (greater than 97 percent confidence) remainsfairly constant alter SVD, but the dimension reductionprovides a lot more information about syntacticbehavior when a less strict cutoff value is adopted (say90 percent).4.
Induction based on NeighborhoodsProximity in this reduced space is then usedto find for all the context digests a neighborhood ofwords that are paradigmatically related.
Proximity canbe computed by using the cosine similarity measure,which was a major feature of the SMARTinformation retrieval system (Salton 1983).
Thismeasures the cosine of the angle between two contextdigests, which can be viewed as vectors in a s-dimensional space.The category space can be clustered bycomparing pairs of context digests using the cosinesimilarity measure; such clusters contain words whosesyntactic behavior is substantially similar.
The degreeof similarity depends on the adopted threshold value.However, these neighborhoods are nottraditional clnsters; each verb has its own individualrepresentation in a multi-dimensional space, i.e.
is thecenter of its own neighborhood.
Typically any givenverb is a vector which silnultaneously belongs inseveral neighborhoods.Verbal subcatcgorization frames liketransitivity, or the ability to take a that-complementor to-infinitive can be induced for new words based ona "composite" of features associated with "similar"verbs that are.
defined in the lexicon.
Theknowledgebase used in this research is the domain-independent lexicon of PUNDIT, a broad-coveragesymbolic NLP system, which contains 164 verbswith detailed subcategorization inl'ormation(Hirsehman et al 1989).
PUNDIT's features are asubset (51" Sager's Linguistic String Project (Sager1981), which include sebctional restrictions, featuresthat license constructs, and object options that affectthe interpretation f a sentence.The induction works as follows: each verblms its own neighborhood, formed by computing thecosine similarity weight between it and all other verbsin the category space, and by retaining those whoscweight excecds a certain threshold.
If there are nonearby verbs with known teatures, more remote wordscan be used for deciding on whether acertain featureshould apply to the verb being examined, especially ifa substantial majority of these "distant relatives" arein agreement.
If the features are treated as booleanvalues (present/not present), it will most certainlyhappen in neighborhoods with liberal cutoff pointsthat there will be some disagreement for individualoptions, so a heuristic must negotiate these"eonllicts" and settle for the best abstraction.
Such aheuristic should have the following three characteris-tics:1) verbs that are close to the word being examinedshould carry more weight in the decision processthan verbs that are closer to the perimeter.2) both positive and negative vidence (the absenceof a feature for a particular verb) should beconsidered.3) given the fact that the presence of a feature is theresult of a positive decision/action (by alinguist), whereas the absence may be anoversight, there should be it (slight) bias in favorof the former; the sensitivity threshold can bcadjusted by shifting the point at which the weightof evidence is considered sufficient o decide infavor of adopting the feature.The existing verbs in the lexicon themselvesundergo a similar process whereby they are fitted tothe domain: some of their "generic" features which menot appropriate m'e dropped, whereas "gaps" in objectoptions are filled.
The net result is that the grammar1165becomes attuned to the sublanguage: parses becomepossible because the enabling features are present,while the search space is pruned of many falsepositives because unnecessary features are omitted.5.
EvaluationManning evaluates his system by computingprecision and recall scores with the OALD dictionaryas golden standard.
However, precision is no__!t a goodyardstick for evaluating the performance of theinduction process, because it measures the outcomeagainst a "flawed" lexicon; the induced features,because of the data-driven ature of the process, aremore "precise" when measured against the "real world"of the sublanguage domain than the hand-built entriesthat are the product mostly of introspection andanecdotal evidence.
The system described in this paperwas tested instead by comparing the number ofsuccessful parses of a held-out est corpus before andafter customizing the lexicon.
Out-of-the-boxPUNDIT returned 42 parses for the 170 sentences inthe training corpus (some of which were falsepositives), versus 94 successful parses using theattuned lexicon.
It should be pointed out that these 94sentences contain an average of 2.14 verbs.6.
ConclusionThe category space is the arbiter ofparadigmatic relatedness, and since it is bootstrappedfrom a training corpus that is.representative for thedomain sublanguage, the resulting lexical entries willbe customized for that domain.
Porting the lexicon toa new domain is as simple as bootstrapping anothercategory space.
Experiments with PUNDIT, a broad-coverage symbolic NLP system, have shown that thecategory space can successfully bc used to inducefeatures like transitivity and subcategorization forclauses and infinitival complements.The advantage of combining data-drivenmining with the existing lexical knowledgebase overother bootstrapping methods is that this approachdoes not require the manual identification ofappropriate cues for subcategorization features, or theinvolved construction of a pattern matcher that issophisticated nough to ignore false triggers.7.
ReferencesBerry, Michael, Theresa Do, Gavin O'Brien, VijayKrishna, and Sowmini Varadhan.
1993.
SVDPACKC(version 1.0) user's guide.
Knoxville, TN: Departmentof Computer Science, University of Tennessee.Technical Report, CS-93~ 194.Brent, Michael.
1993.
From grammar to lexicon.Unsupervised learning of lexical syntax.
Computa-tional Linguistics: Special Report on Using ~ LargeCorpora: II 19 (June): 243-62.Brill, Eric.
1993.
A corpus-based approach tolanguage learning.
Ph.D.
diss., University ofPennsylvania.Charniak, Eugene.
1993.
Statistical languagelearning.
Cambridge, MA: MIT Press.Deerweester, Scott, Susan Dumais, George Furnas,Thomas Landauer, and Richard Harshman.
1990.Indexing by latent semantic analysis.
Journal of theAmerican Society for Information Science 41(September): 391-407.Hirschman, Lynette, Martha Palmer, John Dowding,Deborah Dahl, Marcia Linebarger, RebeccaPassonneau, Francois Lang, Catherine Ball, and CarlWeir.
1989.
The PUNDIT natural languageprocessing system.
In Proceedings of the annualartificial intelligence systems in governmentconference held in Washington, D.C., March, 1989.Manning, Christopher.
1993.
Automatic acquisitionof a large subcategorization dictionary from corpora.In Proceedings of the thirty-first annual meeting ofthe ACL _held in Columbus, OH, June, 1993, by theAssociation for Computational Linguistics.
235-42.Sager, Naomi, ed.
1981.
Natural languageinformation processing: A computer grammar of..English and its applications.
Reading, MA: Addison-Wesley.Salton, Gerald.
1983. introduction to moderninformation retrieval.
New York, N.Y.: McGraw-Hill.Schfitze, Hinrich.
1993.
Part-of-speech induction fromscratch.
In Proceedings of the thirtv-first annualmeeting of the ACL held in Columbus, OH, June,1993, by the Association for ComputationalLinguistics.
251-58.Schiitze, Hinrich, and Jan Pedersen.
1993.
A vectormodel for syntagmatic and paradigmatic relatedness.
InProceedings of the ninth annual conference of theCentre of the new OED and Text Research eld inOxford, England, 1993, by the University ofWaterloo.Wilms, G. Jan. 1995.
Automated induction of alexical sublanguage grammar using a hybrid systemof corpus- and knowledge-based techniques.
Ph.D.diss., Mississippi State University.1166
