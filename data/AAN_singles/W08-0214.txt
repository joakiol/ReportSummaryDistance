Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 114?119,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsTeaching NLP to Computer Science Majors via Applications andExperimentsReva FreedmanDepartment of Computer ScienceNorthern Illinois UniversityDeKalb, IL 60115rfreedman@niu.eduAbstractMost computer science majors at NorthernIllinois University, whether at the B.S.
or M.S.level, are professionally oriented.
However,some of the best students are willing to trysomething completely different.
NLP is achallenge for them because most have nobackground in linguistics or artificialintelligence, have little experience in readingtraditional academic prose, and are unused toopen-ended assignments with gray areas.
Inthis paper I describe a syllabus for Introductionto NLP that concentrates on applications andmotivates concepts through studentexperiments.
Core materials include anintroductory linguistics textbook, the Jurafskyand Martin textbook, the NLTK book, and aPython textbook.1 IntroductionNorthern Illinois University is a large publicuniversity (25,000 students) located about 60 mileswest of Chicago.
Most computer science majorscome from the suburbs and exurbs of Chicago orsmall towns near the university.
Their preferredcareer path is generally to obtain a programmingjob in local industry, preferably in a hi-tech area.Most students take the Introduction to NLP courseout of a desire to do something different from theirrequired courses.In this paper I describe the issues I have found inteaching NLP to this population, and the syllabus Ihave developed as a result.
Since the studentsenjoy programming and see system developmentas the core issue of computer science, I concentrateon applications and their structure.
I motivatemany of the issues involved using data and systemsfrom the web and in-class experiments.
I explicitlyteach the linguistics background that they need.2 Student backgroundI started from the following assumptions derivedfrom several years of teaching Introduction toArtificial Intelligence and Introduction to NLP atNIU.Linguistic background:1.
Students have never studied linguistics.2.
Students are not familiar with the commonsyntactic constructions of English taught intraditional English grammar, and are often unsureabout parts of speech.3.
Students have little experience with languagesother than English.Programming:4.
Students are not familiar with programminglanguages other than conventional imperativelanguages such as C++, Java, and .NET.5.
Students like to program and to build workingsystems.6.
Students expect to have programminglanguages explicitly taught in class.Academic approach:7.
Students live on the web and areuncomfortable having to use offline referencematerials.8.
Students are not comfortable with orinterested in traditional academic prose or researchpapers.9.
Students are taking the course for fun and todo something different.
They are unlikely to needspecific NLP content in their future careers.11410.
Students taking NLP are unlikely to havetime in their program to take another artificialintelligence course (although there are exceptions).3 Course goalsFrom these presuppositions I have developed thefollowing general principles to provide a positiveexperience for both students and teacher:1.
Teach the linguistic content explicitly, at alevel suitable for beginners.2.
Concentrate on applications, using them tomotivate algorithms.3.
Concentrate on student involvement at alllevels: in-class experiments, take-homeexperiments to be discussed in class, and practicalprogramming projects.4.
Concentrate on a few basic principles that arerepeated in many contexts, such as rule-based vs.Bayesian approaches and the role of worldknowledge in working systems.From these presuppositions I have developed asyllabus that maintains student interest, providesstudents a basic background in NLP, and alsoprovides them with useful skills and knowledgethat they may not otherwise encounter in theirprogram of study.The course has three goals:1.
Give students a general background in theissues involved in handling both speech andwritten text, some of the most commonapplications, and some of the most widely usedalgorithms.2.
Provide students with a productive experiencein a modern programming language.3.
Teach students a number of useful conceptsthat they might not otherwise come across in theircourse of study.
These topics include:?
Bayes?
Law?
Dynamic programming?
Hidden Markov models?
Regular expressions and finite-state machines?
Context-free grammarsThe following sections of the paper describe themost important units of the course, showing howthey use the principles stated above to contribute tothese goals.4 Introducing NLPThe first goal of the course is to define the NLPtask and explain why it is harder and lessdeterminate than many of the problems they havestudied in their other courses.I start by encouraging students to list all themeanings they can for ?I made her duck?, based onthe five meanings given by Jurafsky and Martin(2000, section 1.2).
For a view of a system that candeal with such issues, I then introduce Figure 1.1of Bird, Klein, and Loper (2008, henceforcereferred to as the NLTK textbook), which shows apipeline architecture for a spoken dialogue system.I use this opportunity to discuss each componentand possible data representations.5 Providing linguistic backgroundI introduce three kinds of background knowledge,related to speech, words and sentences, and humanfactors issues.5.1 Background for speech processingTo provide essential background for discussingspeech processing, I introduce the concepts ofphone and phoneme.
I also teach give a briefintroduction to the IPA so that I can use it inexamples.
I use the following sections fromStewart and Vaillette (2001), a textbook forintroductory linguistics classes:File 3.1: International Phonetic Alphabet (IPA)File 3.2: English consonantsFile 3.3: English vowelsFile 3.5: English transcription exercisesFile 4.1: Phones vs. phonemesThese sections were chosen to provide thebackground students need while providingmaximum opportunities for interaction.
Studentshave found this approach more accessible than therather terse treatment in Jurafsky and Martin(2000, ch.
4).
I do the following activities, familiarto teachers of introductory linguistics classes, inclass:?
Putting one?s fingers on the glottis to experiencethe difference between voiced and unvoiced115consonants?
Putting one?s hand in front of one?s mouth toexperience the difference between aspirated andunaspirated consonants?
Reading IPA transcription in pairsI also introduce students to the idea that bothpronunciation and other areas of human languagegeneration are affected by context.
For example,using Figure 5.7 of Jurafsky and Martin (2000) asa guide, I try to generate as many as possible of thesixteen most common pronunciations of becauseshown in that figure.5.2 Background for text processingAs background for the text processing section, Ilecture on a few core aspects of syntax and relatedtopics that will be needed during the semester.These topics include the following:?
What is a word??
How many parts of speech are there??
Lexical ambiguity?
Syntactic ambiguity, including PP attachment,attachment of gerunds, and coordinationambiguity?
Difference between syntactic structure andintention5.3 Background in human factors issuesThis section includes several topics that experiencehas shown will be needed during the semester.The first is the difference between descriptiveand prescriptive linguistics.
I take class polls onvarious sociolinguistic issues, includingpronunciation, word choice and sentence structure,using File 10.10: Language variation from Stewartand Vaillette (2001) as a basis.I take a poll on the pronunciation of the wordoffice, choosing that word since the distribution ofits first vowel is sensitive both to geography andspeaker age.
The poll gives me an opportunity tointroduce some of the human factors issues relatedto corpus collection and the issue of statisticalsignificance.
We also examine some datacollection tasks found on the Internet, using themto discuss experimental design and how it relates tothe data collected.Finally, I begin a discussion on the differencebetween rule-based and statistical systems that willrecur frequently during the semester.
This is agood place to discuss the importance of separatingtraining data and test data.6 Python6.1 Basic PythonThe next step is to teach basic Python so that therewill be time for some practice programs before thefirst major programming project.
As computerscience majors, the students tend to find that thetreatment in the NLTK textbook does not answerenough of their technical questions, such as issueson argument handling and copying of objectsvs.
references to them.I give several lectures on Python, including thefollowing topics:?
Basic data structures?
Basic control structures?
Functions and modules?
Objects?
File handlingI have found Lutz (2008) to be the most readableintroductory textbook.
I use Chun (2007) as areference for topics not covered by Lutz, such asregular expressions and some of the I/O options.6.2 Using Python for basic languagehandlingThis unit basically covers the material in chapters2, 3, and 6 of the NLTK textbook.
The goal is toshow students how easily some of these problemscan be handled with an appropriate programminglanguage.
Many of them are quite uncomfortablewith the idea of a list not implemented withpointers, but in the end they cope well with alanguage that does not have all the baggage ofC++.I give a simple assignment that involves findingthe most common words in a corpus.
A secondarypurpose of this assignment is to reinforce theearlier lecture on the difficulty of defining a word.I lard the input text for the assignment withproblematic cases such as hyphenated multiwordexpressions, e.g., ?the orange-juice basedconfection.
?1167 Rule-based dialogue systems usingregular expressionsSince later in the course we will be comparingrule-based systems to statistics-based systems, thisis an appropriate time to introduce rule basedsystems.
We experiment in class with Eliza, tryingboth to make it work and make it fail.
I give out alist of versions available on the web, and studentscan easily find more.
In class I often use the emacsbuilt-in version.I then give out copies of the original Eliza paper(Weizenbaum, 1966), which contains the originalscript in an appendix.
If time permits, I alsodiscuss PARRY (Parkison, Colby and Faught,1977), which has a much more linguisticallysophisticated design but there is no simulatoravailable for it.I introduce regular expressions at this point fortwo reasons.
In addition to being required forcontinued use of the NLTK textbook, regularexpressions are an important idea that is nototherwise included in our curriculum.
Weexperiment with Rocky Ross?
interactive web site(Pascoe, 2005) and occasionally with othersimulators.
I also assign a simple homework usingregular expressions in Python.The first major project in the course is to writean shallow interactive written dialogue system, i.e.,an Eliza-type program.
Students have the choice ofchoosing a more realistic, limited domain, such asa database front-end, or of picking a specific case(e.g., a linguistic issue) that they would like Elizato handle.
This project is implemented in Python asa rule-based system with heavy use of regularexpressions.
Before they write their code, studentsdo a five-minute presentation of their domain,including a sample conversation.
After the projectsare due, they present their results to the class.8 Spelling correction and Bayes?
LawBayes?
Law is another core topic that students aregenerally unfamiliar with, even though statistics isrequired in our program.
To provide a contrast torule-based systems, and to introduce this coretopic, I present Kernighan, Church and Gale?s(1990) Bayesian approach to spelling correction, asexplained by Jurafsky and Martin  (2000, section5.5).Kernighan et al choose as the preferredcorrection the one that maximizes P(t|c)P(c), wheret is the typo and c is a candidate correction.
In aprevious paper (Freedman, 2005), I discuss indetail an assignment where students choose acorpus and replicate Kernighan?s calculations.They then compare their results to results fromtheir favorite word processor.Students are generally surprised at how similarthe results are from what they originally see as anunmotivated calculation.
They are always surprisedto learn that spelling correction is generally notdone by a lookup process.
They are also surprisedto learn that learn that results were largelyindependent of the corpus chosen.I also demonstrate approximating wordfrequencies by page counts in Google, along with adiscussion of the advantages and disadvantages ofdoing so.
In general, students prefer to use one ofthe NLTK corpora or a corpus obtained from theweb.9 Machine translation: rule-based andstatistical modelsThis unit has several purposes.
In addition toshowing students how the same problem can beattacked in remarkably different ways, includingmultiple levels of rule-based and statistically-basedsystems, machine translation gives students a lookat a fielded application that is good enough to beviable but sill obviously needs improvement.To the extent that information is publiclyavailable, I discuss the architecture of one of theoldest machine translation systems, Systran(Babelfish), and one of the newest, Microsoft LiveTranslator.
The latter uses components fromMindNet, Microsoft?s knowledge representationproject, which provides another opportunity toreinforce the importance of world knowledge inartificial intelligence and NLP in particular.
It alsoprovides an initial opportunity to discuss theconcept of machine learning as opposed to hand-crafting rules or databases.As the assignment for this unit, students choosea short text in a foreign language.
They usemultiple web-based translation systems to translateit into English, and analyze the results.
In additionto the systems mentioned above, the Reversosystem has done well in these experiments.Popular inputs include administrative text (e.g.,citizenship rules) from a bilingual country and117chapter 1 of Genesis.
One student started with aFrench version of the Tolkien poem ?...
one ring torule them all...?
Although translation of poetryobviously poses different issues than technical text,a fruitful discussion emerged from the fact that twoof the systems misparsed one or more of the linesof the poem.10 POS identification, parsing andauthor identificationThis unit of the course covers key sections ofchapters 4, 7, 8 and 9 of the NLTK textbook.Although one student originally stated that ?Ireally don?t care about parts of speech,?
studentsfind this material more interesting after seeing howmany of the machine translation errors are causedby parsing errors.
Still, I only cover POSassignment enough to use it for chunking andparsing.The application chosen for this unit involvesauthor identification.
I introduce students to thebasics of the Federalist Papers controversy.
Then Idiscuss the approach of Mosteller and Wallace(1984), which depends largely on words usedmuch more frequently by one author than theother, such as while and whilst.I suggest to students that more interesting resultscould perhaps be obtained if data about items suchas part of speech use and use of specificconstructions of English were added to the input.As an alternative assignment, I give studentstranscripts of tutoring by two different professorsand invite them to identify the authors ofadditional transcripts from a test set.
A secondarygoal of this assignment is for students to see thelevel of cleanup that live data can require.This assignment also shows students the relativedifficulty level of chunking vs. parsing better thanany lecture could.
This is useful because studentsotherwise tend to find chunking too ad hoc fortheir taste.I do teach several approaches to parsing sincemany students will not otherwise see context-freegrammars in their studies.
Having had theexperiences with machine translation systems helpsprevent the reaction of a previous class to Earley?salgorithm: ?we understand it; it?s just notinteresting.?
I also frame Earley?s algorithm asanother example of dynamic programming.11 Speech understandingStudents generally find speech a much morecompelling application than written text.
In thisunit I discuss how basic speech processing works.This unit provides a nice review of the basics ofphonology taught at the beginning of the semester.It also provides a nice review of Bayes?
Lawbecause the approach used, based on Jurafsky andMartin (2000, ch.
5.7?5.9) uses Bayes?
Law in afashion similar to spelling correction.The assignment for this unit involvesexperimenting with publicly available speechunderstanding systems to see how well they work.The assignment involves comparing two automated411 systems, Google?s new system(1-800-GOOG411), which was built specificallyfor data collection, and Jingle (1-800-FREE411),which is advertising-supported.
I also encouragestudents to report on their own experiments withbank, airline, and other systems.I give at least one anonymous questionnaireevery semester.
Students generally report that thelevel of detail is appropriate.
They generally votefor more topics as opposed to more depth, and theyalways vote for more programming assignmentsand real systems rather than theory.12 Future workI am considering replacing author identification byquestion answering, both because it is an importantand practical topic and because I think it wouldprovide better motivation for teaching chunking.
Iam also considering keeping author identificationand adding the use of a machine learning packageto that unit, since I believe that machine learning israpidly becoming a concept that all students shouldbe exposed to before they graduate.My long-term goal is to have students build anend-to-end system.
A short-term goal in service ofthis objective would be to add a unit on text-to-speech systems.13 ConclusionsThis paper described a syllabus for teaching NLPto computer science majors with no background inthe topic.
Students enjoyed the course more andwere more apt to participate when the course wasoriented toward applications such as dialogue118systems, machine translation, spelling correctionand author identification.
Students also learnedabout the architecture of these systems and thealgorithms underlying them.
Students implementedversions of some of the smaller applications andexperimented with web versions of large fieldedsystems such as machine translation systems.AcknowledgmentsI thank the authors of Jurafsky and Martin (2000)and Bird, Klein and Loper (2008), whose extensivelabor has made it possible to teach this course.
Iwould also like to thank the anonymous reviewersfor their suggestions.ReferencesSteven Bird, Ewan Klein, and Edward Loper.
(2008).Natural Language Processing in Python.
Availableon the web at http://nltk.org/index.php/Book.Wesley J. Chun.
(2007).
Core Python Programming,2/e.
Upper Saddle River, NJ: Prentice-Hall.Reva Freedman.
(2005).
Concrete Assignments forTeaching NLP in an M.S.
Program.
In SecondWorkshop on Effective Tools and Methodologies forTeaching NLP and CL, 43rd Annual Meeting of theACL.Daniel Jurafsky and James H. Martin.
(2000).
Speechand Language Processing.
Upper Saddle River, NJ:Prentice-Hall.Mark Lutz.
(2008).
Learning Python, 3/e.
Sebastopol,CA: O?Reilly.Mark D. Kernighan, Kenneth W. Church, and WilliamA.
Gale.
(1990).
A spelling correction program basedon a noisy channel model.
In COLING ?90(Helsinki), v. 2, pp.
205?211.Frederick and Mosteller and David L. Wallace.
(1984).Applied Bayesian and Classical Inference: The Caseof The Federalist Papers.
New York: Springer.Originally published in 1964 as Inference andDisputed Authorship: The Federalist.Brad Pascoe (2005).
Webworks FSA applet.
Availableat http://www.cs.montana.edu/webworks/projects/theoryportal/models/fsa-exercise/appletCode/fsa_applet.html.Roger C. Parkison, Kenneth Mark Colby, and WilliamS.
Faught.
(1977).
Conversational LanguageComprehension Using Integrated Pattern-Matchingand Parsing.
Artificial Intelligence 9: 111?134.Thomas W. Stewart, Jr. and Nathan Vaillette.
(2001).Language Files: Materials for an Introduction toLanguage and Linguistics, 8/e.
Columbus: OhioState University Press.Joseph Weizenbaum.
(1966).
Eliza?A ComputerProgram for the Study of Natural LanguageComputation between Man and Machine.Communications of the ACM 9(1): 36?45.119
