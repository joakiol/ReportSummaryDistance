Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications , pages 174?184,Baltimore, Maryland USA, June 26, 2014.c?2014 Association for Computational LinguisticsRule-based and machine learning approaches for second languagesentence-level readabilityIldik?o Pil?an, Elena Volodina and Richard JohanssonSpr?akbanken, University of GothenburgBox 200, Gothenburg, Sweden{ildiko.pilan, elena.volodina, richard.johansson}@svenska.gu.seAbstractWe present approaches for the identifica-tion of sentences understandable by sec-ond language learners of Swedish, whichcan be used in automatically generated ex-ercises based on corpora.
In this work wemerged methods and knowledge from ma-chine learning-based readability research,from rule-based studies of Good Dictio-nary Examples and from second languagelearning syllabuses.
The proposed selec-tion methods have also been implementedas a module in a free web-based lan-guage learning platform.
Users can usedifferent parameters and linguistic filtersto personalize their sentence search withor without a machine learning componentassessing readability.
The sentences se-lected have already found practical use asmultiple-choice exercise items within thesame platform.
Out of a number of deeplinguistic indicators explored, we foundmainly lexical-morphological and seman-tic features informative for second lan-guage sentence-level readability.
We ob-tained a readability classification accuracyresult of 71%, which approaches the per-formance of other models used in simi-lar tasks.
Furthermore, during an empir-ical evaluation with teachers and students,about seven out of ten sentences selectedwere considered understandable, the rule-based approach slightly outperforming themethod incorporating the machine learn-ing model.1 Introduction and motivationDespite the fact that there is a vast selection of ex-isting materials, many language teachers opt forcompleting course syllabuses with either inventedexamples or authentic resources, customized tothe need of specific learners (Howard and Major,2004).
Collections with millions of tokens of dig-ital text are available for several languages today,part of which would offer adequate practice mate-rial for learners of a second or foreign language(L2) to develop their skills further.
However, anecessary first step representing a major challengewhen reusing copora for automatic exercise gen-eration is how to assess the suitability of the avail-able material.
In this study, we explored how wecould exploit existing Natural Language Process-ing (NLP) tools and resources for this purpose.To overcome copyright issues often limitingfull-text access to certain corpora, we decided towork with sentences as linguistic unit when as-sessing the characteristics of suitability and whengenerating exercise items.
Although a large num-ber of studies exist investigating readability, i.e.understandability, at the text level, the sentencelevel remains little explored.
Similarly, the focusof previous investigations has mainly been read-ability from native language (L1) readers?
per-spective, but aspects of L2 readability have beenless widely studied.
To our knowledge no previ-ous research have explored this latter dimensionfor Swedish before, hence we aim at filling thisgap, which can be useful, besides the purposesmentioned above, also in future sentence and textsimplification and adaptation tasks.We propose a rule-based as well as a combi-nation of rule-based and machine learning meth-ods for the identification of sentences understand-able by L2 learners and suitable as exercise items.During the selection of linguistic indicators, wehave taken into consideration previously studiedfeatures of readability (Franc?ois and Fairon, 2012;Heimann M?uhlenbock, 2013; Vajjala and Meur-ers, 2012), L2 Swedish curricula (Levy Scherrerand Lindemalm, 2009; Folkuniversitet, 2013) andaspects of Good Dictionary Examples (GDEX)174(Hus?ak, 2010; Kilgarriff et al., 2008), being thatwe believe they have some properties in commonwith exercise items.
The current version of themachine learning model distinguishes sentencesreadable by students at an intermediate level ofproficiency from sentences of a higher readabil-ity level.
The approaches have been implementedand integrated into an online Intelligent Computer-Assisted Language Learning (ICALL) platform,L?arka (Volodina et al., 2013).
Besides a modulewhere users can experiment with the filtering ofcorpus hits, a module with inflectional and vocab-ulary exercises (making use of the selected sen-tences with our method) is also available.
An ini-tial evaluation with students, teachers and linguistsindicated that more than 70% of the sentencesselected were understandable, and about 60% ofthem would be suitable as exercise items accord-ing to the two latter respondent groups.2 Background2.1 Text-level readabilityReadability of texts in different languages hasbeen the subject of several studies and theyrange from simpler formulas, taking into ac-count superficial text properties, to more sophis-ticated NLP methods.
Traditional readabilitymeasures for L1 Swedish at the text level in-clude LIX (L?asbarthetsindex, ?Readability index?
)(Bj?ornsson, 1968) and the Nominal Ratio (Hult-man and Westman, 1977).
In recent years a num-ber of studies, mostly focusing on the L1 con-text, appeared which take into consideration lin-guistic features based on a deeper text processing.Morphosyntactic aspects informative for L1 read-ability include, among others, parse tree depth,subordination features and dependency link depth(length) (Dell?Orletta et al., 2011).
Languagemodels have also been commonly used for read-ability predictions (Collins-Thompson and Callan,2004; Schwarm and Ostendorf, 2005).
A recentlyproposed measure, the Coh-Metrix (Graesser etal., 2011), aims at a multilevel analysis of texts, in-spired by psycholinguistic principles.
It measuresnot only linguistic difficulty, but also cohesion intexts.Research on L1 readability for Swedish,using machine learning, is described inHeimann M?uhlenbock (2013) and Falkenjacket al.
(2013).
Heimann M?uhlenbock (2013)examined readability along five dimensions:surface features, word usage, sentence structure,idea density and human interest.
Mean depen-dency distance, subordinate clauses and modifiersproved good predictors for L1 Swedish.Although a number of readability formulas ex-ist for native language users, these might not besuitable predictors of L2 difficulty being that theacquisition processes of L1 and L2 present a num-ber of differences (Beinborn et al., 2012).
Studiesfocusing on L2 readability are considerably fewerin the literature.
The linguistic features in this con-text include, among others, relative clauses, pas-sive voice (Heilman et al., 2007) and the num-ber of coordinate phrases per clause (Vajjala andMeurers, 2012).
Crossley et al.
(2008) appliedsome Coh-Metrix indicators to English L2 read-ability.
The authors found that lexical corefer-entiality, syntactic similarity and word frequencymeasures outperformed traditional L1 readabilityformulas.
A language-independent approach toL2 readability assessment, using an online ma-chine learning algorithm, is presented by Shen etal.
(2013) which, however, employed only the sur-face features of average sentence and word length,and word frequencies as lexical feature.
The au-thors found that none of the features in isolationwas able to clearly distinguish between the levels.In the second language teaching scenario, awidely used scale is the Common EuropeanFramework of Reference for Languages (CEFR)(Council of Europe, 2001), which, however, hasbeen less frequently adopted so far in readabilitystudies.
The CEFR guidelines for L2 teaching andassessment define six different proficiency levels:A1 (beginner), A2 (elementary), B1 (intermedi-ate), B2 (upper intermediate), C1 (advanced) andC2 (proficiency).
Franc?ois and Fairon (2012) pro-posed a CEFR-based readability formula for L2French.
Some of the predictive features proved tobe structural properties, including shallow lengthfeatures as well as different morpho-syntactic cat-egories (e.g.
present participles) and the presenceof words in a list of easy words.2.2 Sentence-level readabilityMany of the text readability measures mentionedabove have shortcomings when used on very shortpassages containing 100 words or less (Kilgarriffet al., 2008).
The concept of readability at the sen-tence level can be related to the selection of ap-propriate vocabulary example sentences.
GDEX175(Hus?ak, 2010; Kilgarriff et al., 2008) is a sentenceevaluation algorithm, which, on the basis of lex-ical and syntactical criteria, automatically ranksexample candidates from corpora.
Some of theinfluential linguistic aspects of appropriate exam-ple sentences are: their length and structure, thepresence of short and common vocabulary itemswhich do not need disambiguation and the ab-sence of anaphoric pronouns.
Segler (2007) fo-cuses on the L2 rather than on the lexicographiccontext.
He explores the characteristics of helpfulvocabulary examples to be used via an ICALL sys-tem for L2 German and underlines the importanceof syntactic complexity.
Research about rankingSwedish corpus examples is presented in Volodinaet al.
(2012b).
Their first algorithm includes fourheuristic rules concerning sentence length, infre-quent lexical items, keyword position and the pres-ence of finite verbs, complemented by a sentencesimilarity measure in the second algorithm.
Read-ability experiments focusing at the sentence levelhave started to appear recently both for languagelearning purposes (Pil?an et al., 2013) and for de-tecting differences between simplified and unsim-plified sentence pairs (Vajjala and Meurers, 2014).3 ResourcesOur sentence selection module utilizes a numberof tools, resources and web services available forSwedish.
Korp1, an infrastructure for accessingand maintaining corpora (Borin et al., 2012), con-tains a large number of Swedish texts which areequipped with automatic annotations (with someexceptions) for part-of-speech (POS), syntactic(dependency) relations, lemma forms and senseids.
Korp offers, among others, a web servicefor concordances, which makes a search in cor-pora based on a query (e.g.
a keyword and itsPOS) and returns hits with a sentence-long con-text.
Moreover, with the corpus pipeline of Korp,tools for automatically annotating corpora are alsoavailable.
A variety of different modern Swedishcorpora from Korp have been used throughout thisstudy including novel, newspaper and blog texts.Another source for sentences was the CEFRcorpus (Volodina and Johansson Kokkinakis,2013), a collection of CEFR-related L2 Swedishcourse book texts.
The corpus contains: (a) man-ual annotations indicating the structure of each les-son in the book (exercises, instructions, texts etc.
);1http://spraakbanken.gu.se/korp/(b) automatic linguistic annotations obtained withthe annotation tools available through Korp.
TheCEFR corpus at the time of writing included B1texts from three course books and B2 texts fromone course book.
The annotation of additional ma-terial covering other CEFR levels was ongoing.Not only corpora, but also information from fre-quency word lists has been used for determiningthe appropriateness of a sentence.
The Kelly list(Volodina and Kokkinakis, 2012) is a frequency-based vocabulary list mostly built on a corpus ofweb texts from 2010.
Besides frequency infor-mation, an associated CEFR level is available foreach item.
Another frequency-based word list em-ployed for the machine learning experiments is theWikipedia list (Volodina et al., 2012b).
It containsthe POS and the number of occurrences for eachword form in a corpus of Swedish Wikipedia texts.A central resource of the present study is L?arka2(Volodina et al., 2013), a freely available onlineICALL platform.
Currently its exercise generatormodule offers tasks both for students of linguisticsand learners of L2 Swedish (Figure 1).
Additionalparts include a corpus editor used for the annota-tion of the CEFR corpus and the sentence selectionmodule presented in this paper, Hit-Ex3(Hitta Ex-empel, ?Find Examples?
or Hit Examples).
Theversion under development contains also dictationand spelling exercises (Volodina et al., 2013).4 Machine learning experiments forreadability4.1 DatasetWe distinguished two different classes in thedataset for the machine learning experiments: (a)sentences understandable at (within) B1 level and(b) sentences above B1 level.
For the formergroup, sentences were collected from B1-leveltexts from the CEFR corpus.
Sentences above B1level consisted partly of B2-level sentences fromthe CEFR corpus, and partly of native languagesentences from Korp retrieved on the basis of key-words between B2 and C2 levels according to theKelly list.
Only sentences between the length of5 and 30 tokens were collected from all resourcesto decrease the influence of sentence length on thedecisions made by the classifiers and to increasethe importance of other linguistic features.
The2http://spraakbanken.gu.se/larka/3http://spraakbanken.gu.se/larka/larka hitex index.html176Figure 1: Inflectional exercise.size of the dataset and the number of sentences perlevel are illustrated in Table 1.Level Source Nr.
sentencesWithin B1 B1 (CEFR) texts 2358Above B1B2 (CEFR) texts 795Korp corpora 1528Total size of dataset 4681Table 1: The source and the number of sentencesin the dataset.4.2 MethodWe performed supervised classification using astraining and test data the set of sentences describedin section 4.1.
Thus, we aimed at a two-way clas-sification distinguishing sentences within B1 levelfrom those above.
This level, besides being ap-proximately a middle point of the CEFR scale,is typically divided into sub-levels in languagecourses (Folkuniversitet, 2013) which indicates amore substantial linguistic content.
Consequently,additional practice for learners can be beneficial atthis stage.
Self-study activities may also be morecommon in this phase since students have suffi-cient L2 autonomy.
We experimented with dif-ferent classification algorithms4available throughthe Scikit-learn Python package (Pedregosa et al.,2011), out of which we present the results onlyof the best performing one here, a linear SupportVector Machine (SVM) classifier.
The SVM clas-sifier aims at separating instances into classes witha hyperplane (Tanwani et al., 2009), equivalent toa line in a two-dimensional space.
This hyperplaneis defined based on the feature values of instancesand weights associated with them.
Once extracted,the values for each feature were scaled and cen-tered.Evaluation was carried out with stratified 10-fold cross-validation, i.e.
the proportion of labelsin each fold was kept the same as that in the wholetraining set during the ten iterations of trainingand testing.
The evaluation measures taken intoconsideration were accuracy, precision, recall andthe F1 score, a combination of precision and re-call, the two of them being equally important (Pe-dregosa et al., 2011).4The other classification methods used were a Na?
?veBayes classifier, a decision tree and two linear algorithms:perceptron and logistic regression.1774.3 FeaturesAfter a thorough overview of the machine learn-ing approaches for readability in the literature, anumber of features were chosen to be tested inour experiments.
The features selected aimed ata deep analysis of the sentences at different lin-guistic levels.
Besides traditional readability indi-cators, a number of syntactic, morphological, lexi-cal and semantic aspects have been taken into con-sideration.
Our initial set contained altogether 28features, as presented in Table 2 on the next page.A number of popular traditional (shallow) fea-tures were included in the feature set (features1-4).
These required less sophisticated text pro-cessing and had previously been used in sev-eral studies with success (Beinborn et al., 2012;Dell?Orletta et al., 2011; Franc?ois and Fairon,2012; Heimann M?uhlenbock, 2013; Vajjala andMeurers, 2012).
We computed sentence length asthe number of tokens including punctuation, andtoken length as the number of characters per to-ken.Part of the syntactic features was based on thedepth (length) and direction of dependency arcs(features 5-8).
Another group of these featuresrelied on the type of dependency relations.
Infeature 9 (Mod) nominal pre-modifiers (e.g.
ad-jectives) and post-modifiers (e.g.
relative clauses,prepositional phrases) were counted, similarly toHeimann M?uhlenbock (2013).
Variation fea-tures (ModVar, AdvVar) measured the ratio of amorphosyntactic category to the number of lex-ical (content) words in the sentence, as in Va-jjala and Meurers (2012).
These lexical cate-gories comprised nouns, verbs, adverbs and ad-jectives.
Subordinates (11) were detected onthe basis of the ?UA?
(subordinate clause minussubordinating conjunction) dependency relationtag (Heimann M?uhlenbock, 2013).
Features De-pDepth, Mod, Sub and RightDep, PrepComp havepreviously been empoyed for Swedish L1 read-ability at the text level in Heimann M?uhlenbock(2013) and Falkenjack et al.
(2013) respectively.The lexical-morphological features (features13-25) constituted the largest group.
Difficultyat the lexical level was determined based on boththe TTR feature mentioned above, expressing vo-cabulary diversity, and on the basis of the rar-ity of words (features 13-17) according to theKelly list and the Wikipedia word list.
An anal-ogous approach was adopted also by Franc?ois andFairon (2012), Vajjala and Meurers (2012) andHeimann M?uhlenbock (2013) with positive re-sults.
The LexD feature considers the ratio oflexical words (nouns, verbs, adjectives and ad-verbs) to the sum of tokens in the sentence (Vajjalaand Meurers, 2012).
The NN/VB ratio feature,which has a higher value in written text, can alsoindicate a more complex sentence (Biber et al.,2004; Heimann M?uhlenbock, 2013).
Features 21-25 are based on evidence from the content of L2Swedish course syllabuses (Folkuniversitet, 2013)and course books (Levy Scherrer and Lindemalm,2009), part of them being language-dependent,namely S-VB/VB and S-VB%.
These two featurescover different types of Swedish verbs ending in-s which can indicate either a reciprocal verb, apassive construction or a deponent verb, active inmeaning but passive in form (Fasth and Kanner-mark, 1989).Our feature set included three semantic fea-tures (26-28).
The intuition behind 28 is thatwords with multiple senses (polysemous words),increase reading complexity as, in order to under-stand the sentence, word senses need to be dis-ambiguated (Graesser et al., 2011).
This featurewas computed by counting the number of senseIDs per token according to a lexical-semantic re-source for Swedish, SALDO (Borin et al., 2013),and dividing this value by the number of tokensin the sentence.
As pronouns indicate a poten-tially more difficult text (Graesser et al., 2011),we included PN/NN in our set.
Both NomRand PN/NN capture idea density, i.e.
how com-plex the relation between the ideas expressed are(Heimann M?uhlenbock, 2013).4.4 Classification resultsThe results obtained using the complete set of 28features is shown in Table 3.
The results of theSVM are presented in comparison to a baselineclassifier assigning the most frequent output labelin the dataset to each instance.Classifier Acc F1 B1 Prec B1 RecallBaseline 0.50 0.66 0.50 1.00SVM 0.71 0.70 0.73 0.68Table 3: Classification results with the completefeature set.The baseline classifier tagged sentences with50% accuracy being that the split between the two178Nr.
Feature Name FeatureIDNr.
Feature Name FeatureIDTraditional Lexical-morphological1 Sentence length SentLen 13 Average word frequency(Wikipedia list)WikiFr2 Average token length TokLen 14 Average word frequency (Kellylist)KellyFr3 Percentage of words longerthan 6 charactersLongW% 15 Percentage of words above B1levelDiffW%4 Type-token ratio TTR 16 Number of words above B1levelDiffWsSyntactic 17 Percentage of words at B1 level B1W%5 Average dependency depth DepDepth 18 Lexical density LexD6 Dependency arcs deeper than 4 DeepDep 19 Nouns/verbs NN/VB7 Deepest dependency / sentencelengthDDep /SentLen20 Adverb variation AdvVar8 Ratio of right dependency arcs RightDep 21 Modal verbs / verbs MVB/VB9 Modifiers Mod 22 Participles / verbs PCVB/VB10 Modifier variation ModVar 23 S-verbs / verbs S-VB/VB11 Subordinates Sub 24 Percentage of S-verbs S-VB%12 Prepositional complements PrepComp 25 Relative pronouns RelPNSemantic26 Nominal ratio NomR27 Pronoun/noun PN/NN28 Average number of senses perwordSense/WTable 2: The complete feature set.classes was about 50-50%.
The SVM classified 7out of 10 sentences accurately.
The precision andrecall values for the identification of B1 sentenceswas 73% and 68%.
Previous classification resultsfor a similar task obtained an average of 77.25%of precision for the classification of easy-to-readtexts within an L1 Swedish text-level readabil-ity study (Heimann M?uhlenbock, 2013).
Anotherclassification at the sentence level, but for Italianand from an L1 perspective achieved an accuracyof 78.2%, thus 7% higher compared to our results(Dell?Orletta et al., 2011).
The 73% precisionof our SVM model for classifying B1 sentenceswas close to the precision of 75.1% obtained forthe easy-to-read sentences from Dell?Orletta et al.(2011).
Franc?ois and Fairon (2012) in a classi-fication study from the L2 perspective, aiming atdistinguishing all 6 CEFR levels for French at thetext level, concluded that intermediate levels areharder to distinguish than the levels at the edgesof the CEFR scale.
The authors reported an adja-cent accuracy of 67% for B1 level, i.e.
the levelof almost 7 out of 10 texts was predicted eithercorrectly or with only one level of difference com-pared to the original level.
Precise comparisonwith previous results is, however, difficult since,to our knowledge, there are no results reported forL2 readability at the sentence level.
Thus, the val-ues mentioned above serve more as a side-by-sideillustration.Besides experimenting with the complete fea-ture set, groups of features were also separatelytested.
The results are presented in Table 4.Feature group(Nr of features)Acc F1Traditional (4) 0.59 0.55Syntactic (8) 0.59 0.54Lexical (13) 0.70 0.70Semantic (3) 0.61 0.55Table 4: SVM results per feature group.The group of traditional and syntactic featuresperformed similarly, with an accuracy of 59%.
In-179Rank Feature ID Weight1 DiffW% 0.5762 Sense/W 0.4383 DiffWs 0.4224 SentLen 0.2585 Mod 0.2236 KellyFr 0.2157 NomR 0.1328 AdvVar 0.1149 Ddep/SentLen 0.0810 DeepDep 0.08Table 5: The 10 most informative featuresaccording to the SVM weights.terestingly, although semantic features representedthe smallest group, they performed 2% better thantraditional or syntactic features.
The largest groupof features including lexical-morphological indi-cators performed around 10% more accuratelythan other feature groups.Among the 10 features that influenced most thedecisions of our SVM classifier, we can find at-tributes from different feature groups.
The ID ofthese features together with the SVM weights arereported in Table 5.
An informative traditionalmeasure was sentence length, similarly to the re-sults of previous studies (Beinborn et al., 2012;Dell?Orletta et al., 2011; Franc?ois and Fairon,2012; Heimann M?uhlenbock, 2013; Vajjala andMeurers, 2012).
Lexical-morphological featuresbased on information about the frequency and theCEFR level of items in the Kelly list (DiffW%,DiffWs and KellyFr) also proved to be influentialfor the classification, as well as AdvVar.
Two outof our three semantic features, namely NomR and,in particular, Sense/W, were also highly predictive.Syntactic features Ddep/SentLen and DeepDep,based on information about dependency arcs, werealso among the ten features with highest weights,but they were somewhat less useful, as the weightsin Table 5 show.Contrary to our results, Franc?ois and Fairon(2012) found syntactic features more informativethan semantic ones for L2 French.
This may de-pend either on the difference between the featuresused or the target languages.
Moreover, in the caseof Swedish L1 text readability the noun/pronounratio and modifiers proved to be indicative of text-level difficulty (Heimann M?uhlenbock, 2013), butat the sentence level from the L2 perspective onlythe latter seemed influential in our experiments.The data used for the experiments was labeledfor CEFR levels at the text level, not at the sen-tence level.
This introduced some noise in the dataand made the classification task somewhat harder.In the future, the availability of data labeled atthe sentence level could contribute to more ac-curate results.
Excluding potentially lower levelsentences from those appearing in higher leveltexts based on the distance between feature vec-tors could also be explored, in a similar fashion toDell?Orletta et al.
(2011).5 Heuristics: GDEX parameters forsentence filtering and rankingBesides SVM classification, our sentence selec-tion module, Hit-Ex, offers also a number ofheuristic parameter options5, usable either in com-bination or as an alternative to the machine learn-ing model (for further details see section 6).
Partof these search parameters are generic preferencesincluding the keyword to search for, its POS, thecorpora from Korp to be used during selection andthe desired CEFR level of the sentences.
Further-more, it is possible to avoid sentences containing:abbreviations, proper names, keyword repetition,negative formulations (inte ?not?
or utom ?except?in the sentence), modal verbs, participles, s-verbsand sentences lacking finite verbs.
Users can alsoallow these categories and choose a penalty pointbetween 0 and -50 for them.
The penalty scorefor each filtering criteria is summed for obtain-ing a final score per sentence, based on whicha final ranking is produced for all sentences re-trieved from Korp, the ranking reflecting the ex-tent to which they satisfy the search criteria.
Someadditional parameters, partly overlapping with themachine learning model?s features, are also avail-able for users to experiment with, being that themachine learning model does not cover all CEFRlevels.
Based on statistical evidence from corpora,we suggested default values for all parameters forretrieving sentences of B1, B2, C1 level with rule-based parameters only.
However, additional dataand further testing is required to verify the appro-priateness of the proposed values.5See Pil?an (2013) or the Hit-Ex webpage,http://spraakbanken.gu.se/larka/larka hitex index.html,for a complete list of parameters.1806 Combined approachAs mentioned in the previous subsection, theheuristic parameters and the machine learning ap-proach have been implemented and tested alsoin combination.
Parameters are kept to performa GDEX-like filtering, whilst the SVM model isemployed to ensure that hits were of a suitablelevel for learners.
During this combined filtering,first a ranking for each unfiltered sentence comingfrom the web service of Korp is computed withheuristics.
During these calculations, the parame-ters partly or fully overlapping with certain fea-tures of the machine learning model are deacti-vated, i.e.
receive penalty points set to 0, thus,they do not influence the ranking.
Instead, thoseaspects are taken care of by the machine learningmodel, in a subsequent step.
Only the 100 sen-tences ranked highest are given for classificationto the machine learning model for efficiency rea-sons.
Finally, once the classification has been per-formed, sentences classified as understandable atB1 level are returned in the order of their heuris-tic ranking.
Figure 2 shows part of the interfaceof Hit-Ex, as well as the highest ranked three sen-tences6of an example search for the noun hund?dog?
at B1 level.
Besides the Hit-Ex page, boththe heuristics-only and the combined approachesare available also as web services.7 EvaluationThe purpose of the evaluation was to explore howmany sentences, collected from native languagecorpora in Korp with our algorithms, were under-standable at B1 level (at B1 or below) and thus, ap-propriate to be presented to learners of L2 Swedishof that CEFR level.
Participants included three L2Swedish teachers, twenty-six L2 Swedish studentsat B1 level, according to their current or most re-cent language course, and five linguists familiarwith the CEFR scale.
Besides the criteria of un-derstandability (readability), the aspect of beingan appropriate exercise item was also explored.We selected altogether 196 sentences using bothour approaches, with two different parameter set-tings for the rule-based method (See Pil?an et al.
(2013) and Pil?an (2013) for further details aboutthe evaluation).
Evaluators were asked to indicatewhether they found the sentences understandable6English translations of the selected sentences: (1)?Itwould be enough for a normal dog.?
; (2)?They left the bodyin the form of a dog.?
; (3)?There was a person with a dog.
?at B1 level or not.
Teachers and linguists (TL)rated the sentences also as potential exercise items.The results of the evaluation are presented in Table6.Understandability Exercise itemTL Students TL76% 69% 59%73%Table 6: Evaluation results.Respondents found overall 73% percent of thesentences selected by both our methods under-standable at B1 level, whilst somewhat less, aboutsix out of ten items, proved to be suitable for beingincluded in exercises for L2 Swedish learning.According to our evaluators, the two settingsof the rule-based approach (Alg1-s1 and Alg1-s2)satisfied the two criteria observed between 1-5%more of the cases.
On average, teachers, linguistsand students considered 75% of the sentences se-lected with Alg1-s1 understandable, but only 70%of those identified with the combined approach(Alg2).
The detailed results per algorithm, crite-ria and user group are shown in Figure 3.Figure 3: Comparison of algorithms.According to our evaluators?
comments, someof the selected sentences contained difficult as-pects at the syntactic level, among others, diffi-cult word order, subordinates and relative clauses.Moreover, at the lexical level, a stricter lexical fil-tering, and checking for a sufficient amount of lex-ical words in the sentence would be required.
Re-spondents?
comments revealed also the potentialfuture improvement of filtering for context depen-dency which would make sentences more suitableas exercise items.181Figure 2: Part of the user interface and example search results.8 ConclusionIn this study we investigated linguistic fac-tors influencing the sentence-level readability ofSwedish from a L2 learning point of view.
Themain contribution of our work consists of twosentence selection methods and their implemen-tation for identifying sentences from a varietyof Swedish corpora which are not only readable,but potentially suitable also as automatically gen-erated exercise items for learners at intermedi-ate (CEFR B1) level and above.
We proposeda heuristics-only and a combined selection ap-proach, the latter merging rule-based parameters(targeting mainly the filtering of ?undesired?
lin-guistic elements), and machine learning methodsfor classifying the readability of sentences fromL2 learners?
perspective.
We obtained a classi-fication accuracy of 71% with an SVM classifierwhich compares well to previously reported re-sults for similar tasks.
Our results indicate the suc-cess of lexical-morphological and semantic fac-tors over syntactic ones in the L2 context.
Themost predictive indicators include, besides sen-tence length, the amount of difficult words in thesentence, adverb variation, nominal pre- and post-modifiers and two semantic criteria, the averagenumber of senses per word and nominal ratio (Ta-ble 5).
Within a smaller-scale evaluation, about73% of the sentences selected by our methodswere understandable at B1 level, whilst about 60%of the sentences proved to be suitable as exerciseitems, the heuristics-only approach being slightlypreferred by evaluators.
Further investigation ofthe salient properties of exercise items may con-tribute to the improvement of the current selectionapproach.
The method, as well as most of the pa-rameters and features used, are language indepen-dent and could, thus, be applied also to languagesother than Swedish, provided that NLP tools per-forming similarly deep linguistic processing areavailable.
Future additions to the filtering param-eters may include aspects of word order, indepen-dence from a wider context, valency informationand collocations.
The optimization of the classifiercould also be studied further; different algorithmsand additional features could be tested to improvethe classification results.
The machine learningapproach might show improvements in the futurewith training instances tagged at the sentence leveland it can be easily extended, once additional datafor other CEFR levels becomes available.
Finally,additional evaluations could be carried out to con-firm the appropriateness of the sentences rankedby the extended and improved selection method.To indicate the extent to which a sentence is un-derstandable, 4- or 5-point scales may be used,and the employment of exercises instead of a listof sentences to read could also be investigated forverifying the suitability of the examples.182ReferencesLisa Beinborn, Torsten Zesch, and Iryna Gurevych.2012.
Towards fine-grained readability measures forself-directed language learning.
In Electronic Con-ference Proceedings, volume 80, pages 11?19.Douglas Biber, Susan Conrad, Randi Reppen, PatByrd, Marie Helt, Victoria Clark, Viviana Cortes,Eniko Csomay, and Alfredo Urzua.
2004.
Repre-senting language use in the university: Analysis ofthe TOEFL 2000 spoken and written academic lan-guage corpus.
Test of English as a Foreign Lan-guage.Carl Hugo Bj?ornsson.
1968.
L?asbarhet.
Liber.Lars Borin, Markus Forsberg, and Johan Roxen-dal.
2012.
Korp - the corpus infrastructure ofSpr?akbanken.
In Proceedings of LREC, pages 474?478.Lars Borin, Markus Forsberg, and Lennart L?onngren.2013.
SALDO: a touch of yin to WordNet?s yang.Language Resources and Evaluation, 47(4):1191?1211.Kevyn Collins-Thompson and James P Callan.
2004.A language modeling approach to predicting readingdifficulty.
In HLT-NAACL, pages 193?200.Council of Europe.
2001.
Common European Frame-work of Reference for Languages: Learning, Teach-ing, Assessment.
Cambridge University Press.Scott A Crossley, Jerry Greenfield, and Danielle SMcNamara.
2008.
Assessing text readability us-ing cognitively based indices.
Tesol Quarterly,42(3):475?493.Felice Dell?Orletta, Simonetta Montemagni, and Giu-lia Venturi.
2011.
Read-it: Assessing readabilityof Italian texts with a view to text simplification.In Proceedings of the Second Workshop on Speechand Language Processing for Assistive Technolo-gies, pages 73?83.
Association for ComputationalLinguistics.Johan Falkenjack, Katarina Heimann M?uhlenbock, andArne J?onsson.
2013.
Features indicating readabilityin Swedish text.
In Proceedings of the 19th NordicConference of Computational Linguistics (NODAL-IDA 2013), pages 27?40.Cecilia Fasth and Anita Kannermark.
1989.
Godagrunder.
Folkuniversitetets F?orlag.Folkuniversitet.
2013.
Kurser i svenska.
SvenskaB1.
http://www.folkuniversitetet.se/Kurser--Utbildningar/Sprakkurser/Svenska_Swedish/Svenska-B1--Swedish-B1/.Thomas Franc?ois and C?edrick Fairon.
2012.
An AIreadability formula for French as a foreign language.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning,pages 466?477.
Association for Computational Lin-guistics.Arthur C Graesser, Danielle S McNamara, andJonna M Kulikowich.
2011.
Coh-Metrix providingmultilevel analyses of text characteristics.
Educa-tional Researcher, 40(5):223?234.Michal J. Heilman, Kevyn Collins-Thompson, JamieCallan, and Maxine Eskenazi.
2007.
Combininglexical and grammatical features to improve read-ability measures for first and second language texts.In Proceedings of NAACL HLT, pages 460?467.Katarina Heimann M?uhlenbock.
2013.
I see what youmean.
Ph.D. thesis, University of Gothenburg.Jocelyn Howard and Jae Major.
2004.
Guidelines fordesigning effective English language teaching mate-rials.
In 9th Conference of Pan Pacific Associationof Applied Linguistics.Tor G Hultman and Margareta Westman.
1977.
Gym-nasistsvenska.
Liber.Milos Hus?ak.
2010.
Automatic retrieval of good dic-tionary examples.
Bachelor Thesis, Brno.Adam Kilgarriff, Milos Hus?ak, Katy McAdam,Michael Rundell, and Pavel Rychl`y.
2008.
GDEX:Automatically finding good dictionary examples ina corpus.
In Proceedings of Euralex.Paula Levy Scherrer and Karl Lindemalm.
2009.
Rivs-tart B1 + B2.
Textbok.
Natur och Kultur, Stockholm.Fabian Pedregosa, Ga?el Varoquaux, Alexandre Gram-fort, Vincent Michel, Bertrand Thirion, OlivierGrisel, Mathieu Blondel, Peter Prettenhofer, RonWeiss, Vincent Dubourg, et al.
2011.
Scikit-learn:Machine learning in Python.
The Journal of Ma-chine Learning Research, 12:2825?2830.Ildik?o Pil?an, Elena Volodina, and Richard Johans-son.
2013.
Automatic selection of suitable sen-tences for language learning exercises.
In 20 Yearsof EUROCALL: Learning from the Past, Lookingto the Future.
2013 EUROCALL Conference, 11thto 14th September 2013?Evora, Portugal, Proceed-ings., pages 218?225.Ildik?o Pil?an.
2013.
NLP-based Approaches toSentence Readability for Second Language Learn-ing Purposes.
Master?s Thesis, University ofGothenburg.
https://www.academia.edu/6845845/NLP-based_Approaches_to_Sentence_Readability_for_Second_Language_Learning_Purposes.Sarah E Schwarm and Mari Ostendorf.
2005.
Read-ing level assessment using support vector machinesand statistical language models.
In Proceedings ofthe 43rd Annual Meeting on Association for Com-putational Linguistics, pages 523?530.
Associationfor Computational Linguistics.183Thomas M Segler.
2007.
Investigating the selectionof example sentences for unknown target words inICALL reading texts for L2 German.
PhD Thesis.University of Edinburgh.Wade Shen, Jennifer Williams, Tamas Marius, andElizabeth Salesky.
2013.
A language-independentapproach to automatic text difficulty assessment forsecond-language learners.
In Proceedings of the 2ndWorkshop on Predicting and Improving Text Read-ability for Target Reader Populations, pages 30?38.Association for Computational Linguistics.Ajay Kumar Tanwani, Jamal Afridi, M Zubair Shafiq,and Muddassar Farooq.
2009.
Guidelines to se-lect machine learning scheme for classification ofbiomedical datasets.
In Evolutionary Computation,Machine Learning and Data Mining in Bioinformat-ics, pages 128?139.
Springer.Sowmya Vajjala and Detmar Meurers.
2012.
On im-proving the accuracy of readability classification us-ing insights from second language acquisition.
InProceedings of the Seventh Workshop on InnovativeUse of NLP for Building Educational Applications,pages 163?173.
Association for Computational Lin-guistics.Sowmya Vajjala and Detmar Meurers.
2014.
Assess-ing the relative reading level of sentence pairs fortext simplification.
In Proceedings of the 14th Con-ference of the European Chapter of the Associationfor Computational Linguistics (EACL-14), Gothen-burg, Sweden.
Association for Computational Lin-guistics.Elena Volodina and Sofie Johansson Kokkinakis.
2013.Compiling a corpus of CEFR-related texts.
In Pro-ceedings of the Language Testing and CEFR confer-ence, Antwerpen, Belgium, May 27-29, 2013.Elena Volodina and Sofie Johansson Kokkinakis.
2012.Introducing the Swedish Kelly-list, a new lexicale-resource for Swedish.
In Proceedings of LREC,pages 1040?1046.Elena Volodina, Richard Johansson, and Sofie Johans-son Kokkinakis.
2012b.
Semi-automatic selec-tion of best corpus examples for Swedish: Ini-tial algorithm evaluation.
In Workshop on NLPin Computer-Assisted Language Learning.
Proceed-ings of the SLTC 2012 workshop on NLP for CALL.Link?oping Electronic Conference Proceedings, vol-ume 80, pages 59?70.Elena Volodina, Dijana Pijetlovic, Ildik?o Pil?an, andSofie Johansson Kokkinakis.
2013.
Towards agold standard for Swedish CEFR-based ICALL.In Proceedings of the Second Workshop on NLPfor Computer-Assisted Language Learning.
NEALTProceedings Series 17.
Nodalida 2013, Oslo, Nor-way.184
