Semantic Representations ofSyntactically Marked DiscourseStatus in CrosslinguisticPerspectiveEmily M. BenderDavid Goss-GrubbsUniversity of Washington (USA)email: ebender@u.washington.eduAbstractThis paper presents suggested semantic representations for different typesof referring expressions in the format of Minimal Recursion Semanticsand sketches syntactic analyses which can create them compositionally.We explore cross-linguistic harmonization of these representations, topromote interoperability and reusability of linguistic analyses.
We followBorthen and Haugereid (2005) in positing COG-ST (?cognitive status?
)as a feature on the syntax-semantics interface to handle phenomena as-sociated with definiteness.
Our proposal helps to unify the treatments ofdefiniteness markers, demonstratives, overt pronouns and null anaphoraacross languages.
In languages with articles, they contribute an existen-tial quantifier and the appropriate value for COG-ST.
In other languages,the COG-ST value is determined by an affix.
The contribution of demon-strative determiners is decomposed into a COG-ST value, a quantifier,and proximity information, each of which can be contributed by a dif-ferent kind of grammatical construction in a given language.
Along withCOG-ST, we posit a feature that distinguishes between pronouns (andnull anaphora) that are sensitive to the identity of the referent of theirantecedent and those that are sensitive to its type.1718 Bender and Goss-Grubbs1 IntroductionIn this paper, we discuss the compositional construction of semantic representationsreflecting discourse status across a range of phenomena.
Borthen and Haugereid(2005) propose COG-ST (?cognitive-status?
)1 as a feature on the syntax-semanticsinterface to handle phenomena associated with definiteness.
We explore how theirapproach leads to cross-linguistically unified treatments of demonstratives, overt pro-nouns and null anaphora as well.
We find that cross-linguistic studies motivate differ-ent representations than we might have arrived at from just one language.Our work grows out of the Grammar Matrix, a multilingual grammar engineeringproject (Bender et al, 2002; Bender and Flickinger, 2005) which strives to harmonizesemantic representations across diverse languages.
The Grammar Matrix is couchedwithin the Head-driven Phrase Structure Grammar (HPSG) framework (Pollard andSag, 1994).
We use Minimal Recursion Semantics (Copestake et al, 2001, 2005) asour semantic representation system.2 Background2.1 Minimal Recursion SemanticsGrammar Matrix-derived grammars associate surface strings with MRS representa-tions (or MRSs), in a bidirectional mapping that allows both parsing and generation.An MRS consists of a multiset of elementary predications (eps), each of which is asingle relation with its associated arguments, labeled by a handle; a set of handle con-straints relating the labels of eps to argument positions within other eps; and a tophandle indicating which of the labels has outermost scope (Copestake et al, 2001,2005).
The MRSs produced by these grammars are underspecified for scope, allowingmultiple different fully-scoped variants, according to the handle constraints.Each ep has a predicate (PRED) value and one or more argument positions, usu-ally labeled ARG0 through ARGn.
By convention, we refer to elementary predicationsby their PRED values.
For scope-taking eps (including quantifiers as well as clause-embedding predicates such as _believe_v_rel and scopal modifiers such as negation),at least one argument position is handle-valued, and related (in a well-formed struc-ture) to the label of another ep.
For non-scopal predications, the values of the argumentpositions are variables (also called indices) which may themselves be associated with?variable properties?, such as person, number and gender on individual variables, ortense, aspect, sentential force and mood on event variables.One benefit of MRS is that it is designed to be compatible with feature-structuregrammars.
We build up MRSs through an HPSG implementation of the MRS algebrain Copestake et al (2001), in which each constituent bears features recording the epsand handle constraints contributed within the constituent, as well as a set of propertiesexposed through the feature HOOK to facilitate further composition.
These proper-ties include pointers to the local top handle (LTOP), the constituent?s primary index(INDEX), and the external argument, if any (XARG).Eps are canonically contributed by lexical entries, with one ep per lexical entry.Lexical entries can, however, contribute more than one ep or no eps at all.
In addition,syntactic constructions can also contribute eps of their own.1Original feature name: COGN-ST.Semantic Representations of Syntactically Marked Discourse Status 19cog-stactiv-or-less uniq-or-moreuniq+fam+activfam-or-less fam-or-moreuniq+fam activ+famuniq-or-less activ-or-moretype-id uniq-id familiar activated in-focFigure 1: Cognitive status hierarchy2.2 Harmonization of RepresentationsThe semantic representations used in the Grammar Matrix were originally derivedfrom those used in the English Resource Grammar (Flickinger, 2000), a wide-coveragegrammar of English.
In this paper, we propose to refine the semantic representationsfor phenomena connected to discourse status in light of the constraints on the syntax-semantics interface we find in a range of languages.
This is not to say that we arepromoting working towards an interlingua: indeed, even if it were possible to define asuitable interlingual set of representations, we believe it wouldn?t be possible to mapfrom surface strings to such representations in one compositional step.Nonetheless, it is useful to harmonize representations across languages while stillallowing for necessary differences, for at least two reasons.
First, when semanticrepresentations are as similar as they practically can be, this simplifies both the transfercomponent in transfer-basedmachine translation systems (e.g., Oepen et al, 2007) andthe design of downstream components that make use of semantic representations inmultilingual NLP systems in general.
Second, harmonized semantic representationsfacilitate the creation of libraries in a resource like the GrammarMatrix, which in turnpromotes both the reuse of analyses within implemented grammars and the explorationof computational linguistic typology.2.3 Discourse/Cognitive StatusThis paper builds on a tradition of work investigating the way the discourse statusof referents influences the form of the referring expressions used to refer to them, oralternatively, the way that speakers use contrasts in form to signal to their interlocu-tors the discourse (or cognitive) status of their intended referents (Chafe, 1976, 1994;Prince, 1981; Gundel et al, 1993; Borthen and Haugereid, 2005; Arnold, 2008).Borthen and Haugereid (2005) (henceforth B&H) present arguments from a rangeof languages that the discourse status associated with referring expressions can beconstrained by multiple intersecting syntactic factors.
They use this to motivate em-bedding the discourse status information within the semantic features of a sign, rather20 Bender and Goss-Grubbsthan on the contextual features.
They adapt the implicational scale proposed by Gun-del et al (1993) and Prince (1981), representing discourse referents as having a rangeof values from ?type identifiable?
through ?in focus?.
In Gundel et al and Prince?swork, this is an implicational scale, where a discourse status of ?in focus?, for example,also entails a discourse status of ?activated?.
B&H argue that it needs to be representedwithin the syntax by a type hierarchy that makes each discourse status type incompat-ible with the others, while also creating supertypes that represent ranges of discoursestatus values.
Their intuition is that the syntactic constraints restrict the distributionof certain forms based on the highest discourse status they are compatible with, ratherthan on the actual discourse status of the referent they are used to evoke in a givencontext.
The cognitive status hierarchy, as we adopt it from Borthen and Haugereid(2005) is shown in Fig 1.3 Markers of DefinitenessThe first phenomenon we consider is markers of definiteness.
In English, these aresyntactically identified with determiners, and thus the English Resource Grammarrepresents the semantic contrast between the and a with the PRED value of the epcontributed by the determiner: _the_q_rel vs. _a_q_rel (where ?q?
stands for ?quan-tifier?).
Crosslinguistically, however, definiteness is not always marked in lexical de-terminers which might plausibly contribute quantifier relations.
For example, in Nor-wegian, definiteness is signaled in part by an affix on the noun:(1) JegIs?sawbilen.car.DEF?I saw the car.?
[nob]This does not lend itself to the analysis of definiteness in English provided by theERG: First, the definite suffix can co-occur with something else in the determinerrole, as in (2).2 Second, even if the affix did contribute a _def_q_rel, this would leadto ill-formed MRSs as soon as there were any intersective modifiers: Eps introducedby intersective modifiers (such as nye in (2)) should be labeled with the same handleas the ep introduced by the noun.
But according to the MRS model of semantic com-positionality, the label of the noun?s relation is not available for further compositiononce the quantifier has attached.
(2) JegIs?sawdenthenyenew.DEFbilencar.DEF?I saw the new car.?
[nob]Third, adjectives can also take definite forms.
We would like to enforce the com-patibility of this information, rather than having each instance of the definite suffixcontribute an additional ep.
Per B&H, this supports treating definiteness in terms of afeature rather than through eps.2Note that the determiner is required when there is an adjective in a definite NP, and pragmatically veryrestricted when there is not.Semantic Representations of Syntactically Marked Discourse Status 21Following B&H, we note that the apparently binary distinction between definitesand indefinites is better assimilated to the cognitive status hierarchy.
There are mor-phosyntactic phenomena in various languages which divide the cognitive status hier-archy into two separate ranges, though the division point may vary across languagesand within languages across phenomena.
Using a single feature for cognitive statusthat takes its values from the type hierarchy in Fig 1 allows these various distinctionsto be modeled elegantly.B&H propose wrapping semantic indices in a new structure ref-prop, which con-tains COG-ST as well as other features related to the referential properties of a nounphrase.
In this paper, we focus on COG-ST and leave the other dimensions to futurework.
However, we differ from B&H in proposing that COG-ST, at least, should be afeature of semantic indices, rather than inside a parallel structure (i.e., their ref-prop).This has the benefit of causing the COG-ST information from particular words or af-fixes to be included in the compositionally created semantic representations of phrasesand sentences without any further effort: wherever the index so marked appears, it willcarry its COG-ST value with it.
It also makes the (correct, we believe) prediction thatwhenever an index appears in multiple places in the semantic representation, it shouldbear the same cognitive status information in all of them.
For example, the MRS for(3) is as in (4), where the variable ?x5?
represents the cat, and appears as a value in fourseparate elementary predications: ARG0 of _cat_n_rel, ARG0 of _exist_q_rel, ARG1of _want_v_rel, and ARG1 of _go+out_v_rel.
We claim that in all of these guises,the cognitive status of the referent is the same; there is only one mental representationof the referent involved.
(3) The cat wanted to go out.
(4) ???????????????
?LTOP h0INDEX e1RELS???????
?_exist_q_relLBL h3ARG0 x5[uniq-id]RSTR h6BODY h4???????,??
?_cat_n_relLBL h7ARG0 x5???,??????
?_want_v_relLBL h8ARG0 e2ARG1 x5ARG2 h9???????,????
?_go+out_v_relLBL h10ARG0 e11ARG1 x5?????
?HCONS?h6 =q h7, h9 =q h10????????????????
?B&H consider this possibility and dismiss it on the grounds that coreferential nounphrases don?t necessarily share the same cognitive status.
However, placing the COG-ST value on the index does not necessarily entail that the expressions The cat, herself,and her impute the same cognitive status to their discourse referent in (5).
As far asthe syntactic processing is concerned, these expressions introduce distinct indices.
It isup to a separate reference resolution component to identify them, and that componentcould merge their COG-ST values or not, as appropriate.
(5) The cat opened the door herself with her paw.Thus rather than having English the and similar elements introduce a specializedquantifier relation, we instead do a small amount of semantic decomposition: theintroduces just an existential quantifier (_exist_q_rel), but constrains the variable it22 Bender and Goss-Grubbsa.
def-noun-lex-rule := inflecting-lexeme-to-word-rule &%prefix (ha- *)[ SYNSEM.LOCAL.CONT.HOOK.INDEX.COG-ST uniq-id,DTR noun-lex ].b.
def-adj-lex-rule := inflecting-lexeme-to-word-rule &%prefix (ha- *)[ SYNSEM.LOCAL.CAT.HEAD.MOD.LOCAL.CONT.HOOK.INDEX.COG-STuniq-or-more, DTR adj-lex ].c.
indef-noun-lex-rule := constant-lexeme-to-word-rule &[ SYNSEM.LOCAL.CAT.HEAD.MOD.LOCAL.CONT.HOOK.INDEX.COG-STtype-id, DTR adj-lex ].Figure 2: Sample lexical rules for definiteness affixesbinds to be [COG-ST uniq-id].
This signals to the hearer that s/he should be able toassign a unique representation to the referent (but not that the referent itself is uniquein the world or in the previous discourse, cf.
Gundel et al, 2001).In other languages affixes can also constrain COG-ST to uniq-or-more or uniq-id.We illustrate here with the Hebrew definite prefix ha-, shown in (6) (from Wintner,2000:322).
(6) kollall?e?
?sixha-smalotDEF-dressesha-yapotDEF-niceha-?elleDEF-these?elliminemi-?rhbfrom-US?all these six nice dresses of mine from the US?
[heb]ha- is added by a lexical rule (sketched in Fig 2a) which adds information aboutthe COG-ST to the noun?s own INDEX value.3 When ha- attaches to an adjectivein Hebrew, it instead adds the information that the noun the adjective is modifyingmust have the COG-ST value uniq-or-more, as sketched in Fig 2b.
This rule is pairedwith a non-inflecting lexical rule Fig 2c which produces adjectives which can onlymodify nouns that are [COG-ST type-id], i.e., indefinite.
This will enforce definitenessagreement across the noun phrase.4This section has briefly outlined an adaptation of B&H?s proposal for definitenessmarking.
The main difference to their proposal is in the location of COG-ST in thefeature geometry.
In the following two sections, we extend the approach to demon-stratives and a variety of null anaphora.4 DemonstrativesDemonstratives can stand alone as noun phrases (demonstrative pronouns) or func-tion as nominal dependents.
Starting again with English, we find that demonstra-tives in their nominal-dependent guise, like the markers of definiteness, fill the spec-3The lexical rules in Fig 2 are non-branching productions that apply at the bottom of the parse tree,before any syntactic rules can apply.
The SYNSEM value represents the mother and the DTR value thedaughter.
The types they inherit from (e.g., inflecting-lexeme-to-word-rule) enforce identity of most ofthe information between mother and daughter.
The rules add information about COG-ST, which must becompatible with what?s provided by the lexical entries for the rules to apply.4For the rule for unmarked nouns, see ?4 below.Semantic Representations of Syntactically Marked Discourse Status 23ifier slot of the noun phrase and function as determiners.
Accordingly, the ERGrepresents their semantic contribution through the PRED value of the quantifier rela-tion: _this_q_dem_rel and _that_q_dem_rel.
Crosslinguistically, however, demon-stratives functioning as nominal dependents can also appear as adjectives or affixes(Dryer, 2008).
In such languages, within the general constraints of composition ofMRS, it is not elegant or natural-seeming to have an adjective contribute a quantifierrelation or constrain the PRED value of a relation contributed by a separate determineror non-branching NP construction.Instead, it seems more appropriate to decompose the semantic representation of de-terminers into a quantifier relation (_exist_q_rel) and a separate one-place modifierrelation (e.g., _distal+dem_a_rel, for ?that?).
In languages with demonstrative adjec-tives, the demonstrative form contributes only the modifier relation.
In languages withdemonstrative determiners, the demonstrative forms contribute both.Demonstratives also constrain the COG-ST value of the nouns the modify, typicallyto activ-or-fam.
In some languages, (e.g., Irish Gaelic), the demonstratives require ad-ditional marking of discourse status.
Typically this takes the form of a definite article(see (7) from McCloskey (2004)), but demonstratives can also attach to pronouns andproper nouns (McCloskey, 2004).
(7) anthefearmanm?rbigt?agarthastockygro?cheerfulseoDEM?this big stocky cheerful man?
[gle](8) *fear m?r t?agartha gro?
seoSuch languages are straightforwardly countenanced within this system: the definitearticle and article-less NPs have incompatible COG-ST values, and only the former iscompatible with the COG-ST constraints contributed by the demonstrative adjective.5The situation in Hebrew is slightly more complex: Demonstratives can occur withor without the ha- prefix, so long as they agree with the noun they modify.
Conversely,nouns without the ha- prefix are interpreted as indefinite, unless they are modified bya demonstrative adjective.
It is unclear at this point whether there is a differencein interpretation between (9) and (10) (from Wintner, 2000:334), but it seems likelythat type-id is not the correct cognitive status for (9); that is, it is most likely not anindefinite.
(9) seprbookzethisnimkaris.soldheitebwell?This book sells well.?
[heb](10) ha-seprDEF-bookha-zeDEF-thisnimkaris.soldheitebwell?This book sells well.?
[heb]5McCloskey points out that the demonstratives can attach to coordinated NPs, each with their ownarticle.
This raises difficulties for treating the demonstratives as adjectives, as it would require the demon-strative adjectives to attach outside the determiner (cf.
Bender et al, 2005).
We leave this issue to futurework.24 Bender and Goss-GrubbsHere, we postpone the assignment of a COG-ST value to an unmarked noun until theNP level, filling in type-id in case no demonstrative has attached.
This requires anadditional syntactic feature to control the application of the NPs rules, but this seemsmotivated: As Wintner notes, ha- is functioning as an agreement marker; its distri-bution has become grammaticized and drifted somewhat from what purely semanticconstraints would predict.To provide complete representations for demonstratives, we also need to address theadditional information they carry in many languages, such as the relative proximityof the referent to the speaker and/or the hearer, its visibility or elevation (Diessel,1999).
These distinctions appear to be at least partially independent of the COG-ST dimension.
In addition, in the absence of any evidence for syntactically-mediatedagreement between elements of a sentence along this dimension, for now we representthis part of the meaning of demonstratives as an elementary predication rather than asa feature.Some languages (e.g., Lithuanian) have a demonstrative element which does notexpress any distance contrast, in addition to ones that do (Diessel, 2008).
In thiscase, it might make sense to reduce the contribution of the former sort of element tothe constraints it places on the noun?s COG-ST value.
However, in the interests ofuniformity within the system, we continue to assign it an elementary predication.Other languages (e.g., French and German) don?t mark any distance contrast onthe primary demonstrative element.
In all such languages, there are optional, deicticadverbials which can be added to mark the contrast (Diessel, 2008).
(11) DasDEMBildpicturehierheregef?lltlikemirmebesserbetteralsthandasDEMda.there.
?I like this picture better than that one (over there).?
[deu]In light of such data, we could decompose demonstratives with distance contrasts inall languages into separate demonstrative and deictic/distance relations.
Alternatively,we could do that decomposition only in languages like German and French.
To theextent that the deictic elements (e.g., German hier and da) have other uses as ordinaryadverbs which can be syntactically assimilated to the same lexical entry, we wouldwant to at least make sure that the ep they contribute is the same in both cases.5 Overt pronouns and zero anaphoraPronouns in the ERG are currently represented by an index which is bound by thequantifier _pronoun_q_rel andmodified by _pronoun_n_rel.
The quantifier ep marksthe pronoun as definite, and the modifier ep serves as the restriction for the quantifieras well as identifying the index as a pronoun.Following the treatment of other nominals presented here, however, we do awaywith the quantifier ep in favor of the COG-ST feature.
Similarly, we replace the mod-ifier ep with a feature PRON-TYPE, which indicates whether an index is to be inter-preted as pronominal, and if so, the type of the pronoun (as discussed below).
Notonly is this representation simpler, there is no prediction that pronouns participate inquantifier scope relations, as there is when using _pronoun_q_rel.Semantic Representations of Syntactically Marked Discourse Status 25Overt pronouns, clitics and zero pronominals are generally assumed to take a COG-ST value of in-focus (Gundel et al, 1993; Borthen and Haugereid, 2005).
In general,we agree.
We assume that most overt pronouns and many forms of zero anaphora dotake that value.
However, there are forms which require us to make exceptions to this.First let us consider the English indefinite pronoun one, as in (12).
Clearly in thiscase the referent of one is not in focus.
Rather, such a pronoun should bear the COG-STvalue type-id.
(12) Kim bought a computer and Sandy borrowed one.B&H make a distinction between what they call token pronouns and type pronouns,where the former are the standard pronouns, which corefer with their antecedents, andthe latter are like English one, which refer to a new token whose type is taken fromits antecedent.
We propose that the PRON-TYPE feature take a value of type pron-type, with subtypes not-pron for non-pronouns and type-or-token for pronouns.
Thelatter will have two further subtypes, token-pron and type-pron.
English one will belexically specified as [PRON-TYPE type-pron].Certain cases of zero anaphora similarly get their type information from their an-tecedents.
A couple of instances of the Italian null subject construction appear in (13)and (14).
(13) JohnJohnhahasfattomake.PPRTlathetorta.cake.La-hait-hasmangiataeat.PPRT?John baked the cake.
(He) ate it.?
[ita](14) Seifunoabambinochildvuolewantsunabiscotto,cookiegli-arrivato.him-arrives?If a child wants a cookie, he gets one.?
[ita]In (13), the referent of the null subject is indeed an entity which is in focus, namelyJohn.
On the other hand, in (14) the referent of the null subject is a new token of atype which is in focus, namely the type ?cookie?.To handle this situation, we propose that Italian null subjects are associated withCOG-ST in-focus, and with PRON-TYPE type-or-token.
The grammar for Italian con-tains a ?subject drop?
construction which discharges the subject requirement of theverb without realizing any overt dependent.
Because the verb will have linked the ap-propriate argument position of its own ep to the HOOK.INDEX value inside the featurerecording its subject requirement, the subject drop construction can constrain the prop-erties of this index.
In particular, it will specify that its PRON-TYPE is type-or-token(i.e., it is a pronominal), and that its COG-ST is in-focus.
The subject-drop constructionis sketched in Fig 3.
When further processing determines the nature of the antecedent,the PRON-TYPE value will get further specified.
If it is a non-specific indefinite, e.g.
itis an indefinite in an intensional context, the pronominal will be specified type-pron,otherwise it will be specified token-pron.The next type of zero pronominal we consider are Japanese dropped arguments,which present a counterexample to Gundel et al (1993)?s claim that all zero pronom-inals are COG-ST in-focus.
To be sure, Japanese zero anaphora can be understood26 Bender and Goss-Grubbshead-opt-subj-phrase := head-valence-phrase & head-only &[ SYNSEM.LOCAL.CAT.VAL.SUBJ < >,HEAD-DTR.SYNSEM.LOCAL.CAT [ HEAD verb & [ FORM fin ],VAL.SUBJ < [ LOCAL.CONT.HOOK.INDEX[ COG-ST in-focus,PRON-TYPE type-or-token ]] > ]].Figure 3: Subject drop construction for Italiansimilarly to overt token pronouns, as in (15).
However, there are also examples whereit can be understood like an overt type pronoun, like English one, as in (16).
Notethat (16) is different from (14) in that the antecedent of the null anaphor is not in anintensional context.
(15) Mi-ta.see.PAST?
(He/she) saw (it).?
[jpn](16) Zyon-waJohn.TOPkonpyuutaa-ocomputer.ACCkat-ta.buy.PASTMearii-waMary.TOPkari-ta.borrow.PAST?John bought a computer.
Mary borrowed one.?
[jpn]We propose that Japanese dropped arguments are underspecified with respect tocognitive status and pronoun type.
They are associated with indices specified as COG-ST cog-st and PRON-TYPE type-or-token.Finally, we turn to lexically licensed null instantiation in English, beginning withdefinite null instantiation.
Fillmore et al (2003) define definite null instantiation asa phenomenon whereby some conceptually necessary participant in a situation is leftunexpressed, but its identity is derivable from context.
In lexically licensed null instan-tiation, the possibility of argument drop and the interpretation of the dropped argumentare dependent on the selecting head.
In English, lexically licensed DNI is typically akind of token pronominal, as in (17).
But some items can also license type-pronominalDNI, as in (18).
In (17), the thing that was won is the previously mentioned game.In (18), there is no particular job that is being sought, although we do know from thecontext that it is a job.
(17) Kim played a game with Sandy, and Sandy won.
(18) I can?t find a job, but I?m still looking.We model lexical licensing of null instantiation through a feature called OPT whichallows selecting heads to record whether or not their arguments are ?optional?.
Sincethe interpretation of dropped arguments is also constrained by the lexical heads, wepropose two additional features OPT-CS and OPT-PT which encode the cognitive statusand pronoun type to assign to that argument in case it is dropped.
The complement-drop construction and the lexical constraints on look are sketched in Fig 4a-b.In this figure, strings prefixed with # indicate reentrancy in the feature structure.The feature KEYREL in lexical entries is a pointer to the main ep they contribute.
TheSemantic Representations of Syntactically Marked Discourse Status 27a.
head-opt-comp-phrase := head-valence-phrase & head-only &[ SYNSEM.LOCAL.CAT.VAL.COMPS #comps, HEAD-DTR.SYNSEM.LOCAL.CAT[ VAL.COMPS [ FIRST [ OPT +,OPT-CS #cog-st,OPT-PT #pron-type,LOCAL.CONT.HOOK.INDEX [ COG-ST #cog-st,PRON-TYPE #pron-type ]],REST #comps ]]].b.
look := pp-transitive-verb-lex &[ STEM < "look" >,SYNSEM [ LOCAL.CAT.VAL.COMPS < [ OPT-CS in-focus,OPT-PT type-or-token ] >,LKEYS.KEYREL.PRED "_look_v_rel" ]].c.
read := transitive-verb-lex &[ STEM < "read" >,SYNSEM [ LOCAL.CAT.VAL.COMPS < [ OPT-CS type-id,OPT-PT non-pron ] >,LKEYS.KEYREL.PRED "_read_v_rel" ]].d.
devour := transitive-verb-lex &[ STEM < "devour" >,SYNSEM [ LOCAL.CAT.VAL.COMPS < [ OPT - ] >,LKEYS.KEYREL.PRED "_devour_v_rel" ]].Figure 4: Lexically licensed complement drop for Englishtype transitive-verb-lex inherits from its supertypes the linking constraints which iden-tify the HOOK.INDEX values of the syntactic arguments with the appropriate ARGnvalues in the ep contributed by the verb.6Indefinite null instantiation is similar, except that the identity of the missing elementis either unknown or immaterial.
An example of this is (19).
INI differs from othernull nominals in that it is not a kind of anaphor.
There is nothing in the context thathelps to identify its referent.
(19) Kim is reading.We propose that indices in INI constructions are specified as COG-ST type-id andPRON-TYPE non-pron.
In English, these constructions are also lexically licensed, andcan be handled with the same features described for DNI.
The lexical constraints onread are illustrated in Fig 4c.
For completeness, we also include in Fig 4d an exampleof a lexical item which does not license missing complements.6 Summary and Future WorkIn this paper we have explored the construction of semantic representations for a va-riety of forms of referring expressions.
Building on Borthen and Haugereid (2005)?sproposal to treat cognitive status as a semantic feature within HPSG, we have devel-oped representations for definite, demonstrative and null NPs, and sketched means ofarriving at them compositionally.6The constraints shown on the COMPS value of lexical entries would actually be implemented as con-straints on types that the lexical entries inherit from, allowing the grammar to capture generalizations acrosslexical entries.
They are shown as constraints on the lexical entries here for ease of exposition only.28 Bender and Goss-GrubbsIn future work, we plan to expand the range of these analyses to cover phenomenasuch as Irish demonstratives taking scope over coordinated noun phrases and cross-linguistic variation in the marking of generics as definite or indefinite.On the basis of these analyses, we plan to develop libraries for the Grammar Ma-trix customization system covering the topics discussed here.
The Grammar Matrixcustomization system (Bender and Flickinger, 2005; Drellishak and Bender, 2005)presents the linguist-user with a typological questionnaire which elicits informationabout the language to be described.
On the basis of the user?s responses to the ques-tionnaire, the customization system compiles a working starter grammar out of theMatrix core grammar and analyses stored in libraries.
The new libraries will cover ar-gument optionality (both general pro-drop and lexically-licensed), as well as demon-stratives of different syntactic types (pronouns, determiners, adjectives and affixes),the marking of definiteness, and definiteness agreement.AcknowledgmentsWe would like to thank Toshiyuki Ogihara, Laurie Poulson, Jeanette Gundel, JenniferArnold, Francesca Gola, and the reviewers for STEP 2008 for helpful comments anddiscussion.
Any remaining errors are our own.
This material is based upon worksupported by the National Science Foundation under Grant No.
BCS-0644097.ReferencesArnold, J. E. (2008).
Reference production: Production-internal and addressee-oriented processes.
Language and Cognitive Processes 23(4), 495?527.Bender, E. M., M. Egg, and M. Tepper (2005).
Semantic construction for nominalexpressions in cross-linguistic perspective.
In IWCS-6.Bender, E. M. and D. Flickinger (2005).
Rapid prototyping of scalable grammars:Towards modularity in extensions to a language-independent core.
In Proceed-ings of the 2nd International Joint Conference on Natural Language ProcessingIJCNLP-05 (Posters/Demos), Jeju Island, Korea.Bender, E. M., D. Flickinger, and S. Oepen (2002).
The Grammar Matrix: Anopen-source starter-kit for the rapid development of cross-linguistically consistentbroad-coverage precision grammars.
In J. Carroll, N. Oostdijk, and R.
Sutcliffe(Eds.
), Proceedings of the Workshop on Grammar Engineering and Evaluation atthe COLING19, Taipei, Taiwan, pp.
8?14.Borthen, K. and P. Haugereid (2005).
Representing referential properties of nominals.Research on Language and Computation 3(2), 221?246.Chafe, W. (1976).
Givenness, contrastiveness, definiteness, subjects, topics, and pointof view.
In C. Li (Ed.
), Subject and Topic, pp.
25?56.
New York: Academic Press.Chafe, W. (1994).
Discourse, Consciousness, and Time.
Chicago: Chicago UniversityPress.Semantic Representations of Syntactically Marked Discourse Status 29Copestake, A., D. Flickinger, C. Pollard, and I.
A.
Sag (2005).
Minimal recursionsemantics: An introduction.
Research on Language and Computation 3(4), 281?332.Copestake, A., A. Lascarides, and D. Flickinger (2001).
An algebra for semanticconstruction in constraint-based grammars.
In Proc.
ACL.Diessel, H. (1999).
Demonstratives: Form, Function, and Grammaticalization.
Am-sterdam: John Benjamins.Diessel, H. (2008).
Distance contrasts in demonstratives.
In M. Haspelmath,M.
Dryer, D. Gil, and B. Comrie (Eds.
), The World Atlas of Linguistic StructuresOnline, Chapter 41.
Munich: Max Planck Digital Library.Drellishak, S. and E. M. Bender (2005).
A coordination module for a crosslinguisticgrammar resource.
In S. M?ller (Ed.
), Proc.
HPSG, Stanford, pp.
108?128.
CSLIPublications.Dryer, M. S. (2008).
Order of demonstrative and noun.
In M. Haspelmath, M. Dryer,D.
Gil, and B. Comrie (Eds.
), The World Atlas of Linguistic Structures Online,Chapter 88.
Munich: Max Planck Digital Library.Fillmore, C., C. Johnson, and M. Petruck (2003).
Background to FrameNet.
Interna-tional Journal of Lexicography 16, 235?250.Flickinger, D. (2000).
On building a more efficient grammar by exploiting types.Natural Language Engineering 6 (1) (Special Issue on Efficient Processing withHPSG), 15?28.Gundel, J., N. Hedberg, and R. Zacharski (1993).
Cognitive status and the from ofreferring expressions in discourse.
Language 69, 274?307.Gundel, J., N. Hedberg, and R. Zacharski (2001).
Definite descriptions and cognitivestatus in English: Why accommodation is unnecessary.
English Language andLinguistics 5, 273?295.McCloskey, J.
(2004).
Irish nominal syntax I: Demonstratives.
UC Santa Cruz.Oepen, S., E. Velldal, J. T. L?nning, P. Meurer, V. Ros?n, and D. Flickinger (2007).Towards hybrid quality-oriented machine translation.
On linguistics and probabili-ties in MT.
In TMI 2007, Sk?vde, Sweden.Pollard, C. and I.
A.
Sag (1994).
Head-Driven Phrase Structure Grammar.
Studiesin Contemporary Linguistics.
Chicago: University of Chicago Press.Prince, E. (1981).
Toward a taxonomy of given-new information.
In P. Cole (Ed.
),Radical Pragmatics, pp.
223?255.
New York: Academic Press.Wintner, S. (2000).
Definiteness in the Hebrew noun phrase.
Journal of Linguis-tics 36, 319?363.
