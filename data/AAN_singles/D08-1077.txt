Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 735?744,Honolulu, October 2008. c?2008 Association for Computational LinguisticsSyntactic Models for Structural Word Insertion and DeletionArul Menezes and Chris QuirkMicrosoft ResearchOne Microsoft Way, Redmond, WA 98052, USA{arulm, chrisq}@microsoft.comAbstractAn important problem in translation neglectedby most recent statistical machine translationsystems is insertion and deletion of words,such as function words, motivated by linguisticstructure rather than adjacent lexical context.Phrasal and hierarchical systems can onlyinsert or delete words in the context of a largerphrase or rule.
While this may suffice whentranslating in-domain, it performs poorly whentrying to translate broad domains such as webtext.
Various syntactic approaches have beenproposed that begin to address this problem bylearning lexicalized and unlexicalized rules.Among these, the treelet approach usesunlexicalized order templates to modelordering separately from lexical choice.
Weintroduce an extension to the latter that allowsfor structural word insertion and deletion,without requiring a lexical anchor, and showthat it produces gains of more than 1.0% BLEUover both phrasal and baseline treelet systemson broad domain text.1 IntroductionAmong the phenomena that are modeled poorly bymodern SMT systems is the insertion and deletionof words, such as function words, that aremotivated by the divergent linguistic structurebetween source and target language.
To take thesimplest of examples, the English noun compound?file name?
would typically be translated intoSpanish as ?nombre de archivo?, which requiresthe insertion of the preposition ?de?.
Conversely,when translating from Spanish to English, the ?de?must be deleted.
At first glance, the problem mayseem trivial, yet the presence and position of thesefunction words can have crucial impact on theadequacy and fluency of translation.In particular, function words are often used todenote key semantic information.
They may beused to denote case information, in languages suchas Japanese.
Failing to insert the proper casemarker may render a sentence unreadable orsignificantly change its meaning.
Learning theseoperations can be tricky for MT models best suitedto contiguous word sequences.
From a fluencystandpoint, proper insertion of determiners andprepositions can often make the difference betweenlaughably awkward output and natural soundingtranslations; consider the output ?it?s a cake piece?as opposed to ?it?s a piece of cake?.Furthermore, since missing or spurious functionwords can confuse the target language model,handling these words properly can have an impactbeyond the words themselves.This paper focuses on methods of inserting anddeleting words based on syntactic cues, to be usedin the context of a syntax-informed translationsystem.
While the models we build are relativelysimple and the underlying templates are easy toextract, they add significant generalization abilityto the base translation system, and result insignificant gains.2 BackgroundAs a motivating example, let us return to theEnglish/Spanish pair ?file name?
and ?nombre dearchivo?.
In principle, we would want a machinetranslation system to be capable of learning thefollowing general transformation:?
NOUN1 NOUN2?
 ?
NOUN2 de NOUN1?
(1)Yet even this simple example is beyond thecapabilities of many common approaches.The heavily lexicalized approaches of phrasalsystems (Koehn et al, 2003), are inherentlyincapable of this generalization.
As a proxy, they735acquire phrase pairs such as ?nombre de archivo? ?file name?, ?nombre de?
 ?name?
and ?dearchivo?
 ?file?.
Note that the inserted word isattached to adjacent context word(s).
When the testset vocabulary has significant overlap with thetraining vocabulary, the correct translation canoften be assembled based on the head or themodifying noun.
However, as we show in thispaper, this is woefully inadequate when translatingtruly out-of-domain input.In principle, phrase-based translation systemsmay employ insertion phrase pairs such as?[NULL]?
 ?de?
(2)but the ungrounded nature of this transformationmakes its use during decoding difficult.
Since thereare no constraints on where such a rule may applyand the rule does not consume any input words, thedecoder must attempt these rules at every point inthe search.The reverse operation?de?
 ?[NULL]?
(3)is more feasible to implement, though again, thereis great ambiguity ?
a source word may be deletedat any point during the search, with identical targetresults.
Few systems allow this operation inpractice.
Estimating the likelihood of this operationand correctly identifying the contexts in which itshould occur remain challenging problems.Hierarchical systems, such as (Chiang, 2005) inprinciple have the capacity to learn insertions anddeletions grounded by minimal lexical cues.However, the extracted rules use a single non-terminal.
Hence, to avoid explosive ambiguity,they are constrained to contain at least one alignedpair of words.
This restriction successfully limitscomputational complexity at a cost ofgeneralization power.Syntax-based approaches provide fertile contextfor grounding insertions and deletions.
Often wemay draw a strong correspondence betweenfunction words in one language and syntacticconstructions in another.
For instance, the syntacticapproach of Marcu et al (2006) can learnunlexicalized rules that insert function words inisolation, such as:NP(NN:x0 NN:x1)  x1 de  x0 (4)However, as discussed in (Wang, Knight &Marcu, 2007), joint modeling of structure andlexical choice can exacerbate data sparsity, aproblem that they attempt to address by treebinarization.
Nevertheless, as we show below,unlexicalized structural transformation rules suchas (1) and (4) that allow for insertion of isolatedfunction words, are essential for good qualitytranslation of truly out-of-domain test data.In the treelet translation approach (Menezes &Quirk, 2007), lexical choice and syntactic re-ordering are modeled separately using lexicalizedtreelets and unlexicalized order templates.
Wediscuss this approach in more detail in Section 4.In Section 5, we describe how we extend thisapproach to allow for structural insertion anddeletion, without the need for content wordanchors.3 Related WorkThere is surprisingly little prior work in this area.We previously (Menezes & Quirk, 2005) exploredthe use of deletion operations such as (3) above,but these were not grounded in any syntacticcontext, and the estimation was somewhatheuristic1.The tuple translation model of Crego et al(2005), a joint model over source and targettranslations, also provides a means of deletingwords.
In training, sentence pairs such as ?nombrede archivo?
/ ?file name?
are first word aligned,then minimal bilingual tuples are identified, suchas ?nombre / name?, ?de / NULL?
and ?archivo /file?.
The tuples may involve deletion of words byallowing an empty target side, but do not allowinsertion tuples with an empty source side.
Theseinserted words are bound to an adjacent neighbor.An n-gram model is trained over the tuplesequences.
As a result, deletion probabilities havethe desirable property of being conditioned onadjacent context, yet this context is heavilylexicalized, therefore unlikely to generalize well.More recently, Li et.
al.
(2008) describe threemodels for handling ?single word deletion?
(theydiscuss, but do not address, word insertion).
Thefirst model uses a fixed probability of deletion1We assigned channel probabilities based on the sum of theModel1 probability of the source word being aligned to NULLor one of a list of "garbage collector" words.
This exploits theproperty of Model1 that certain high-frequency words tend toact as "garbage collectors" for words that should remainunaligned.736P(NULL), independent of the source word,estimated by counting null alignments in thetraining corpus.
The second model estimates adeletion probability per-word, P(NULL|w), alsodirectly from the aligned corpus, and the thirdmodel trains an SVM to predict the probability ofdeletion given source language context(neighboring and dependency tree-adjacent wordsand parts-of-speech).
All three models give largegains of 1.5% BLEU or more on Chinese-Englishtranslation.
It is interesting to note that the moresophisticated models provide a relatively smallimprovement over the simplest model in-domain,and no benefit out-of-domain.4  Dependency treelet translationAs a baseline, we use the treelet translationapproach (which we previously described inMenezes & Quirk, 2007), a linguistically syntax-based system leveraging a source parser.
It firstunifies lexicalized treelets and unlexicalizedtemplates to construct a sentence-specific set ofsynchronous rewrite rules.
It then finds the highestscoring derivation according to a linearcombination of models.
We briefly review thissystem before describing our current extension.4.1 The treelet translation modelSentence-specific rewrite rules are constructed byunifying information from three sources: adependency parse of the input sentence, a set oftreelet translation pairs, and a set of unlexicalizedorder templates.
Dependency parses arerepresented as trees: each node has a lexical labeland a part of speech, as well as ordered lists of pre-and post-modifiers.A treelet represents a connected subgraph of adependency tree; treelet translation pairs consistof source and target treelets and a node alignment.This alignment is represented by indices: eachnode is annotated with an integer alignment index.A source node and a target node are aligned iff theyhave the same alignment index.
For instance:((old1/JJ) man2/NN)  (hombre2 (viejo1)) (5)(man1/NN)  (hombre1) (6)Order templates are unlexicalized transductionrules that describe the reorderings, insertions anddeletions associated with a single group of nodesthat are aligned together.
For instance:((x0:/DT) (x1:/JJ) 1/NN)  ((x0) 1 (x1)) (7)((x0:/DT) (x1:/JJ) 1/NN)  ((x0) (x1) 1) (8)((x0:/DT) 1/NN)  ((x0) 1) (9)((x0:/RB) 1/JJ)  ((x0) 1) (10)Each node is either a placeholder or a variable.Placeholders, such as 1/NN on the source side or1 on the target side, have alignment indices andconstraints on their parts-of-speech on the sourceside, but are unconstrained lexically (representedby the ).
These unify at translation time withlexicalized treelet nodes with matching parts-of-speech and alignment.Variables, such as x0:/DT on the source sideand x0: on the target side, also have parts-of-speech constraints on the source side.
Variables areused to indicate where rewrite rules are recursivelyapplied to translate subtrees.
Thus each variablelabel such as x0, must occur exactly once on eachside.In effect, a template specifies how all thechildren of a given source node are reorderedduring translation.
If translation were a word-replacement task, then templates would be justsimple, single-level tree transducers.
However, inthe presence of one-to-many and many-to-onetranslations and unaligned words,  templates mayspan multiple levels in the tree.As an example, order template (7) indicates thatan NN with two pre-modifying subtrees headed byDT and JJ may be translated by using a singleword translation of the NN, placing the translationof the DT subtree as a pre-modifier, and placingthe translation of the JJ subtree as a post-modifier.As discussed below, this template can unify withthe treelet (6) to produce the following rewriterule:((x0:DT) (x1:JJ) man/NN) ((x0) hombre (x1)) (11)Matching: A treelet translation pair matches aninput parse iff there is a unique correspondencebetween the source side of the treelet pair and aconnected subgraph of the input parse.An order template matches an input parse iffthere is a unique correspondence between thesource side of the template and the input parse,with the additional restriction that all children ofinput nodes that correspond to placeholder737template nodes must be included in thecorrespondence.
For instance, order template (7)matches the parse((the/DT) (young/JJ) colt/NN) (12)but not the parse((the/DT) (old/JJ) (grey/JJ) mare/NN) (13)Finally, an order template matches a treelettranslation pair at a given node iff, on both sourceand target sides, there is a correspondence betweenthe treelet translation nodes and template nodesthat is consistent with their tree structure andalignments.
Furthermore, all placeholder nodes inthe template must correspond to some treelet node.Constructing a sentence-specific rewrite rule isthen a process of unifying each treelet with amatching combination of order templates withrespect to an input parse.
Each treelet node mustbe unified with one and only one order templateplaceholder node.
Unifying under these constraintsproduces a rewrite rule that has a one-to-onecorrespondence between variables in source andtarget.
For instance, given the input parse:((the/DT) ((very/RB) old/JJ) man/NN)  (14)we can create a rewrite rule from the treelettranslation pair (5) by unifying it with the ordertemplate (7), which matches at the node man andits descendents, and template (10), which matchesat the node old, to produce the following sentence-specific rewrite rule:((the/DT) ((x1: /RB) old/JJ) man/NN) ((el) hombre ((x1) viejo)) (15)Note that by using different combinations oforder templates, a single treelet can producemultiple rewrite rules.
Also, note how treelettranslation pairs capture contextual lexicaltranslations but are underspecified with respect toordering, while order templates separately capturearbitrary reordering phenomena yet areunderspecified lexically.
Keeping lexical andordering information orthogonal until runtimeallows for the production of novel transductionrules never actually seen in the training corpus,leading to improved generalization power.Decoding: Given a set of sentence-specificrewrite rules, a standard beam search algorithm isused to find the highest scoring derivation.Derivations are scored according to a linearcombination of models.4.2 TrainingThe process of extracting treelet translation pairsand order templates begins with parallel sentences.First, the sentence pairs are word segmented onboth sides, and the source language sentences areparsed.
Next, the sentence pairs are word alignedand the alignments are used to project a targetlanguage dependency tree.Treelet extraction: From each sentence pair ,with the alignment relation ~, a treelet translationpair consisting of the source treelet  	  and thetarget treelet is extracted iff:(1) There exist    andsuch that  ~.
(2) For all   , and such that ~,    iff.Order template extraction is attempted startingfrom each node Sroot in the source whose parent isnot also aligned to the same target word(s).
Weidentify Troot, the highest target node aligned toSroot.
We initialize the sets S0 as {Sroot} and T0 as{Troot}.
We expand S0 to include all nodesadjacent to some element of S0 that are (a)unaligned, or (b) aligned to some node in T0.
Theconverse is applied to T0.
This expansion isrepeated until we reach a fixed point.
Together, S0and T0 make up the placeholder nodes in theextracted order template.
We then create onevariable in the order template for each direct childof nodes in S0 and T0 that is not already included inthe order template.
Iff there is a one-to-one wordalignment correspondence between source andtarget variables, then a template is extracted.
Thisrestriction leads to clean templates, at the cost ofexcluding all templates involving extraposition.5 Insertion/deletion order templatesIn this paper, we extend our previous work toallow for insertion and deletion of words, byallowing unaligned lexical items as part of theotherwise unlexicalized order templates.Grounding insertions and deletions in templatesrather than treelets has two major benefits.
First,insertion and deletion can be performed even in theabsence of specific lexical context, leading togreater generalization power.
Secondly, thisincreased power is tempered by linguistically738informative unlexicalized context.
Rather thanproposing insertions and deletions in any arbitrarysetting, we are guided by specific syntacticphenomena.
For instance, when translating Englishnoun compounds into Spanish, we often mustinclude a preposition; this generalization isnaturally captured using just parts-of-speech.The inclusion of lexical items in order templatesaffects the translation system in only a few places:dependency tree projection, order templateextraction, and rewrite rule construction at runtime.Dependency tree projection: During this step ofthe baseline treelet system, unaligned words are bydefault attached low, to the lowest alignedneighbor.
Although this worked well inconjunction with the discriminative order model, itprevents unaligned nodes from conditioning onrelevant context in order templates.
Therefore, wechange the default attachment of unaligned nodesto be to the highest aligned neighbor; informalexperiments showed that this did not noticeablyimpact translation quality in the baseline system.For example, consider the source parse and alignedtarget sentence:((calibrated1/JJ) (camera2/NN) file3/NN)archivo3 de4 c?mara2 calibrado1 (16)Using the baseline projection algorithm wouldproduce this target dependency tree:(archivo3 ((de4) c?mara2) (calibrado1)) (17)Instead, we attach unaligned words high:(archivo3 (de4) (c?mara2) (calibrado1)) (18)Order template extraction: In addition to thepurely unlexicalized templates extracted from eachtraining sentence, we also allow templates thatinclude lexical items for each unaligned token.
Foreach point in the original extraction procedure,where S0 or T0 contain unaligned nodes, we nowextract two templates: The original unlexicalizedtemplate, and a new template in which only theunaligned node(s) contain the specific lexicalitem(s).
From the example sentence pair (16),using the projected parse (18) we would extract thefollowing two templates:((x0:/JJ) (x1:/NN) 1/NN) (1 (2) (x1) (x0)) (19)((x0:/JJ) (x1:/NN) 1/NN) (1 (de2) (x1) (x0)) (20)Template matching and unification: We extendthe template matching against the input parse torequire that any lexicalized source template nodesmatch the input exactly.
When matching templatesto treelet translation pairs, any unaligned treeletnodes must be consistent with the correspondingtemplate node (i.e.
the template node must beunlexicalized, or the lexical items must match).
Onthe other hand, lexicalized template nodes do notneed to match any treelet nodes -- insertions ordeletions may now come from the template alone.Consider the following example input parse:((digital/JJ) (camera/NN)(file/NN) extension/NN) (21)The following treelet translation pair provides acontextual translation for some of the children,including the insertion of one necessarypreposition:((file1/NN) extension2/NN) (extension2 (de3) (archivo1)) (22)The following order template can provide relativeordering information between nodes as well asinsert the remaining prepositions:((x0:/JJ) (x1:/NN) (x2:/NN) 1/NN) (1 (de2) (x2) (de3) (x0) (x1)) (23)The unification of this template and treelet issomewhat complex: the first inserted de is agreedupon by both template and treelet, whereas thesecond is inserted by the template alone.
Thisresults in the following novel rewrite rule:((x0:/JJ) (x1: /NN) (file) extension) (extension (de) (archivo) (de) (x0) (x1))   (24)These relatively minimal changes produce apowerful contextualized model of insertion anddeletion.Parameter estimation: The underlying treeletsystem includes a template probability estimatedby relative frequency.
We estimate our lexicalizedtemplates in the same way.
However earlyexperiments showed that this feature alone was notenough to allow even common insertions, since theprobability of even the most common insertiontemplates is much lower than that of unlexicalizedtemplates.
To improve the modeling capability, weincluded two additional feature functions: a countof structurally inserted words, and a count ofstructurally deleted words.7396 ExampleConsider the following English test sentence andcorresponding Spanish human translation:September is National Cholesterol EducationMonthSeptiembre es el Mes Nacional para laEducaci?n sobre el ColesterolThe baseline treelet system without structuralinsertions translates this sentence as:Septiembre es Nacional Colesterol Educaci?nMesNot only is the translation missing the appropriatearticles and prepositions, but also in their absence,it fails to reorder the content words correctly.Without the missing prepositions, the languagemodel does not show a strong preference amongvarious orderings of "nacional" "colesterol""educaci?n" and "mes".Using structural insertion templates, the highestscoring translation of the sentence is now:Septiembre es el Mes Nacional de Educaci?n decolesterolAlthough the choice of prepositions is not the sameas the reference, the fluency is much improved andthe translation is quite understandable.
Figure 6.1,lists the structural insertion templates that are usedto produce this translation, and shows how they areunified with treelet translation pairs to producesentence-specific rewrite rules, which are in turncomposed during decoding to produce thistranslation.7 ExperimentsWe evaluated the translation quality of the systemusing the BLEU metric (Papineni et al, 2002).
Wecompared three systems: (a) a standard phrasalsystem using a decoder based on Pharaoh, (Koehnet al, 2003), (b) A baseline treelet system usingunlexicalized order templates and (c) The presentwork, which adds structural insertion and deletiontemplates.7.1 DataWe report results for two language pairs, English-Spanish and English- Japanese.
For English-Spanish we use two training sets: (a) the Europarlcorpus provided by the NAACL 2006 StatisticalMachine Translation workshop (b) a ?general-domain?
data set that includes a broad spectrum ofdata such as governmental data, general web dataand technical corpora.SeptemberNNisVBNationalJJCholesterolNNEducationNNMonthNNInput dependency treex2x0 de2 de3 x1x0:*JJx1:*NNx2:*NN*1NNx2mes x0 de de x1x0:*JJx1:*NNx2:*NNmonthNNseptiembre es x1x1:*NNisVBseptemberNNx0 *1 x1x0:*NN*1VBx1:*NNseptiembre esseptemberNNisVBmesmonthNNTreelets Templates Rewrite Rulesel2 elFigure 6.1: Example sentence, matching treelets, structural insertion templates and unified rewrite rules740For English-Japanese we use only the ?general-domain?
data set.SentencepairsTokens PhrsizeMERTdataEuroparl E-S 730K 15M 7 EuroparlGeneral E-S 3.7M 41M 4 WebGeneral E-J 2.6M 16M 4 WebTable 7.1 Training dataFor English-Spanish we report results using thefour test sets listed in Table 7.2.
For English-Japanese we use only the web test set.
The firsttwo tests are from the 2006 SMT workshop and thenewswire test is from the 2008 workshop.
The webtest sets were selected from a random sampling ofEnglish web sites, with target language translationsprovided by professional translation vendors.
Alltest sets have one reference translation.Domain Sentence pairseu-test Europarl  2000nc-test News commentary 1064News News wire 2051Web General web text 5000Table 7.2 Test data7.2 ModelsThe baseline treelet translation system uses all themodels described in Menezes & Quirk (2007),namely:?
Treelet log probabilities, maximum likelihoodestimates with absolute discounting.?
Forward and backward lexical weighting,using Model-1 translation log probabilities.?
Trigram language model using modifiedKneser-Ney smoothing.?
Word and phrase count feature functions.?
Order template log probabilities, maximumlikelihood estimates, absolute discounting.?
Count of artificial source order templates.2?
Discriminative tree-based order model.The present work does not use the discriminativetree-based order model3 but adds:2When no template is compatible with a treelet, the decodercreates an artificial template that preserves source order.
Thiscount feature allows MERT to deprecate the use of suchtemplates.
This is analogous to the glue rules of Chiang(2005).?
Count of structural insertions: This counts onlywords inserted via templates, not lexicalinsertions via treelets.?
Count of structural deletions: This counts onlywords deleted via templates, not lexicaldeletions via treelets.The comparison phrasal system was constructedusing the same alignments and the heuristiccombination described in (Koehn et al, 2003).This system used a standard set of models:?
Direct and inverse log probabilities, bothrelative frequency and lexical weighting.?
Word count, phrase count.?
Trigram language model log probability.?
Length based distortion model.?
Lexicalized reordering model.7.3 TrainingWe parsed the source (English) side of the corpususing NLPWIN, a broad-coverage rule-basedparser able to produce syntactic analyses at varyinglevels of depth (Heidorn, 2000).
For the purposesof these experiments, we used a dependency treeoutput with part-of-speech tags and unstemmed,case-normalized surface words.
For wordalignment we used a training regimen of fiveiterations of Model 1, followed by five iterations ofa word-dependent HMM model (He, 2007) in bothdirections.
The forward and backward alignmentswere combined using a dependency tree-basedheuristic combination.
The word alignments andEnglish dependency tree were used to project atarget tree.
From the aligned tree pairs weextracted treelet and order template tables.For the Europarl systems, we use aphrase/treelet size of 7 and train model weightsusing 2000 sentences of Europarl data.
For the?general-domain?
systems, we use a phrase/treeletsize of 4, and train model weights using 2000sentences of web data.For any given corpus, all systems used the sametreelet or phrase size (see Table 7.1) and the sametrigram language model.
Model weights weretrained separately for each system, data set andexperimental condition, using minimum error ratetraining to maximize BLEU (Och, 2003).3In our experiments, we find that the impact of this model issmall in the presence of order templates; also, it degrades theoverall speed of the decoder.7418 Results and DiscussionTables 8.1 and 8.4 compare baseline phrasal andtreelet systems with systems that use various typesof insertion and deletion templates.English-Japanese: As one might expect, the useof structural insertion and deletion has the greatestimpact when translating between languages such asEnglish and Japanese that show significantstructural divergence.
In this language pair, bothinsertions and deletions have an impact, for a totalgain of 1.1% BLEU over the baseline treeletsystem, and 3.6% over the phrasal system.
To aidour understanding of the system, we tabulated themost commonly inserted and deleted words whentranslating from English into Japanese in Tables8.2 and 8.3 respectively.
Satisfyingly, most of theinsertions and deletions correspond to well-knownstructural differences between the languages.
Forinstance, in English the thematic role of a nounphrase, such as subject or object, is typicallyindicated by word order, whereas Japanese usescase markers to express this information.
Hence,case markers such as ???
and ???
need to beinserted.
Also, when noun compounds aretranslated, an intervening postposition such as ??
?is usually needed.
Among the most commondeletions are ?the?
and ?a?.
This is becauseJapanese does not have a notion of definiteness.Similarly, pronouns are often dropped in Japanese.English-Spanish: We note, in Table 8.4 thateven between such closely related languages,structural insertions give us noticeableimprovements over the baseline treelet system.
Onthe smaller Europarl training corpus theimprovements range from 0.5% to 1.1% BLEU.On the larger training corpus we find that for themore in-domain governmental4 and news test sets,the effect is smaller or even slightly negative, but4The "general domain" training corpus is a superset of theEuroparl training set, therefore, the Europarl tests sets are "in-domain" in both cases.on the very broad web test set we still see animprovement of about 0.7% BLEU.As one might expect, as the training data sizeincreases, the generalization power of structuralinsertion and deletions becomes less importantwhen translating in-domain text, as more insertionsand deletions can be handled lexically.Nevertheless, the web test results indicate that ifone hopes to handle truly general input the needfor structural generalizations remains.Unlike in English-Japanese, when translatingfrom English to Spanish, structural deletions areless helpful.
Used in isolation or in combinationwith insertion templates they have a slightlynegative and/or insignificant impact in all cases.We hypothesize that when translating from Englishinto Spanish, more words need to be inserted thandeleted.
Conversely, when translating in thereverse direction, deletion templates may play abigger role.
We were unable to test the reversedirection because our syntax-based systems dependon a source language parser.
In future work wehope to address this.% BLEUPhrasal 13.41Baseline treelet 15.89+Deletion only 16.00+Insertion only 16.16+Deletion and Insertion 17.01Table 8.1: English-Japanese system comparisonsWord Count %age Type?2844 42% Postposition?1637 24% Postposition/case marker?630 9.3% Postposition/case marker?517 7.6% Punctuation?476 7.0% Postposition?
?266 3.9% Light verb?101 1.5% Postposition?68 1.0% Postposition?
?27 0.40% Light verb?26 0.38% Punctuation?19 0.28% Question markerTable 8.2: E-J: Most commonly inserted wordsWord Count %age Typethe 875 59% Definite article- 159 11% Punctuationa 113 7.7% Indefinite articleyou 53 3.6% Pronounit 53 3.6% Pronounthat 26 1.8% Conjunction, Pronoun" 23 1.6% Punctuationin 16 1.1% Preposition.
10 0.68% Punctuation's 10 0.68% PossessiveI 9 0.61% PronounTable 8.3: E-J: Most commonly deleted words742In table 8.5 and 8.6, we list the words mostcommonly inserted and deleted when translatingthe web test using the general English-Spanishsystem.
As in English-Japanese, we find that theinsertions are what one would expect on linguisticgrounds.
However, deletions are used much lessfrequently than insertions and also much lessfrequently than they are in English-Japanese.
Only53 words are structurally deleted in the 5000sentence test set, as opposed to 4728 structuralinsertions.
Furthermore, the most common deletionis of quotation marks, which is incorrect in mostcases, even though such deletion is evidenced inthe training corpus5.On the other hand, the next most commondeletions ?I?
and ?it?
are linguistically wellgrounded, since Spanish often drops pronouns.9 Conclusions and Future WorkWe have presented an extension of the treelettranslation method to include order templates withstructural insertion and deletion, which improvestranslation quality under a variety of scenarios,particularly between structurally divergentlanguages.
Even between closely relatedlanguages, these operations significantly improvethe generalizability of the system, providingbenefit when handling out-of-domain test data.Our experiments shed light on a little-studiedarea of MT, but one that is nonetheless crucial forhigh quality broad domain translation.
Our resultsaffirm the importance of structural insertions, inparticular, when translating from English into other5In many parallel corpora, quotes are not consistentlypreserved between source and target languages.languages, and the importance of both insertionsand deletions when translating between divergentlanguages.
In future, we hope to study translationsfrom other languages into English to study the roleof deletions in such cases.ReferencesChiang, David.
A hierarchical phrase-based model forstatistical machine translation.
ACL 2005.Crego, Josep, Jos?
Mari?o and Adri?
de Gispert.Reordered search and tuple unfolding for Ngram-based SMT.
MT Summit 2005.He, Xiaodong.
Using Word Dependent TransitionModels in HMM based Word Alignment forStatistical Machine Translation.
Workshop onStatistical Machine Translation, 2007de 3509 74% Prepositionla 555 12% Determinerel 250 5.3% Determinerse 77 1.6% Reflexive pronounque 63 1.3% Relative pronounlos 63 1.3% Determinerdel 57 1.2% Preposition+Determiner, 42 0.89% Punctuationa 30 0.63% Prepositionen 21 0.44% Prepositionlo 9 0.19% Pronounlas 6 0.13% DeterminerTable 8.5: E-S: Most commonly inserted words" 38 72% PunctuationI 5 9.4% Pronounit 2 3.8% Pronoun, 2 3.8% Punctuation- 2 3.8% PunctuationTable 8.6: E-S: Most commonly deleted wordsEU-devtest EU-test NC-test Newswire Web testEUROPARL E-SPhrasal 27.9 28.5 24.7 17.7 17.0Baseline treelet 27.65 28.38 27.00 18.46 18.71+Deletion only 27.66 28.39 26.97 18.46 18.64+Insertion only 28.23 28.93 28.10 19.08 19.43+Deletion and Insertion 28.27 29.08 27.82 18.98 19.19GENERAL E-SPhrasal 28.79 29.19 29.45 21.12 27.91Baseline treelet 28.67 29.33 32.49 21.90 27.42+Deletion only 28.67 29.27 32.25 21.69 27.47+Insertion only 28.90 29.70 32.53 21.84 28.30+Deletion and Insertion 28.34 29.41 32.66 21.70 27.95Table 8.4: English-Spanish system comparisons, %BLEU743Heidorn, George.
?Intelligent writing assistance?.
InDale et al Handbook of Natural LanguageProcessing, Marcel Dekker.
2000Koehn, Philipp, Franz Josef Och, and Daniel Marcu.Statistical phrase based translation.
NAACL 2003.Chi-Ho Li, Dongdong Zhang, Mu Li, Ming Zhou, HaileiZhang.
An Empirical Study in SourceWord Deletionfor Phrase-based Statistical Machine Translation.Workshop on Statistical Machine Translation, 2008Marcu, Daniel, Wei Wang, Abdessamad Echihabi, andKevin Knight.
SPMT: Statistical MachineTranslation with Syntactified Target LanguagePhrases.
EMNLP-2006.Menezes, Arul, and Chris Quirk.
Microsoft ResearchTreelet translation system: IWSLT evaluation.International Workshop on Spoken LanguageTranslation, 2005Menezes, Arul, and Chris Quirk.
Using DependencyOrder Templates to Improve Generality inTranslation.
Workshop on Statistical MachineTranslation, 2007Och, Franz Josef.
Minimum error rate training instatistical machine translation.
ACL 2003.Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
BLEU: a method for automatic evaluationof machine translation.
ACL 2002.Wang, Wei, Kevin Knight and Daniel Marcu.Binarizing Syntax Trees to Improve Syntax-BasedMachine Translation Accuracy.
EMNLP-CoNLL,2007744
