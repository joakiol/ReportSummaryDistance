Proceedings of NAACL-HLT 2013, pages 721?726,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsUsing Document Summarization Techniques for Speech Data SubsetSelectionKai Wei?, Yuzong Liu?, Katrin Kirchhoff , Jeff BilmesDepartment of Eletrical EngineeringUniversity of WashingtonSeattle, WA 98195, USA{kaiwei,yzliu,katrin,bilmes}@ee.washington.eduAbstractIn this paper we leverage methods from sub-modular function optimization developed fordocument summarization and apply them tothe problem of subselecting acoustic data.
Weevaluate our results on data subset selectionfor a phone recognition task.
Our frameworkshows significant improvements over randomselection and previously proposed methods us-ing a similar amount of resources.1 IntroductionPresent-day applications in spoken language technol-ogy (speech recognizers, keyword spotters, etc.)
candraw on an unprecedented amount of training data.However, larger data sets come with increased de-mands on computational resources; moreover, theytend to include redundant information as their sizeincreases.
Therefore, the performance gain curvesof large-scale systems with respect to the amount oftraining data often show ?diminishing returns?
: newdata is often less valuable (in terms of performancegain) when added to a larger pre-existing data set thanwhen added to a smaller pre-existing set (e.g.,(Moore,2003)).
Therefore it is of prime importance to de-velop methods for data subset selection.
We distin-guish two data subselection scenarios: (a) a prioriselection of a data set before (re-)training a system;in this case the goal is to subselect the existing dataset as well as possible, eliminating redundant infor-mation; (b) selection for adaptation, where the goal?These authors are joint first authors with equal contribu-tions.is to tune a system to a known development or testset.
While many studies have addressed the secondscenario, this paper investigates the first: our goal isto select a smaller subset of the data that fits a given?budget?
(e.g.
maximum number of hours of data) butprovides, to the extent possible, as much informationas the complete data set.
Additionally, our selectionmethod should be a low-resource method that doesnot require an already-trained complex system suchas an existing word recognizer.This problem is akin to unsupervised data ?sum-marization?.
In (Lin and Bilmes, 2009) a novel classof summarization techniques based on submodularfunction optimization were proposed for extractivedocument summarization.
Interestingly, these meth-ods can also be applied to speech data ?summariza-tion?
with only small modifications.
In the followingsections we develop a submodular framework forspeech data summarization and evaluate it on a proof-of-concept phone recognition task.2 Related WorkMost approaches to data subset selection in speechhave relied on ?rank-and-select?
approaches that de-termine the utility of each sample in the data set,rank all samples according to their utility scores, andthen select the top N samples.
In weakly supervisedapproaches (e.g.,(Kemp and Waibel, 1998; Lamelet al 2002; Hakkani-Tur et al 2002), utility is re-lated to the confidence of an existing word recognizeron new data samples: untranscribed training data isautomatically transcribed using an existing baselinespeech recognizer, and individual utterances are se-lected as additional training data if they have low721confidence.
These are active learning approachessuitable for a scenario where a well-trained speechrecognizer is already available and additional datafor retraining needs to be selected.
However, wewould like to reduce available training data ahead oftime with a low-resource approach.
In (Chen et al2009) individual samples are selected for the purposeof discriminative training by considering phone ac-curacy and the frame-level entropy of the Gaussianposteriors.
(Itoh et al 2012) use a utility functionconsisting of the entropy of word hypothesis N-bestlists and the representativeness of the sample using aphone-based TF-IDF measure.
The latter is compa-rable to methods used in this paper, though the firstterm in their objective function still requires a wordrecognizer.
In (Wu et al 2007) acoustic training dataassociated with transcriptions is subselected to max-imize the entropy of the distribution over linguisticunits (phones or words).
Most importantly, all thesemethods select samples in a greedy fashion withoutoptimality guarantees.
As we will explain in the nextsection, greedy selection is near-optimal only whenapplied to monotone submodular functions.3 Submodular FunctionsSubmodular functions (Edmonds, 1970) have beenwidely studied in mathematics, economics, and op-erations research and have recently attracted interestin machine learning (Krause and Guestrin, 2011).
Asubmodular function is defined as follows: Given a fi-nite ground set of objects (samples) V = {v1, ..., vn}and a function f : 2V ?
R+ that returns a real valuefor any subset S ?
V , f is submodular if ?A ?
B,and v /?
B, f(A+ v)?
f(A) ?
f(B + v)?
f(B).That is, the incremental ?value?
of v decreases whenthe set in which v is considered grows from A to B.Powerful optimization guarantees exist for certainsubtypes of submodular functions.
If, for example,the function is monotone submodular, i.e.
?A ?B, f(A) ?
f(B), then it can be maximized, undera cardinality constraint, by a greedy algorithm thatscales to extremely large data sets, and finds a solu-tion guaranteed to approximate the optimal solutionto within a constant factor 1?
1/e (Nemhauser et al1978).
Submodular functions can be considered thediscrete analog of convexity.3.1 Submodular Document SummarizationIn (Lin and Bilmes, 2011) submodular functions wererecently applied to extractive document summariza-tion.
The problem was formulated as a monotonesubmodular function that had to be maximized sub-ject to cardinality or knapsack constraints:argmaxS?V {f(S) : c(S) ?
K} (1)where V is the set of sentences to be summarized, Kis the maximum number of sentences to be selected,and c(?)
?
0 is sentence cost.
f(S) was instantiatedby a form of saturated coverage:fSC(S) =?i?Vmin{Ci(S), ?Ci(V )} (2)where Ci(S) =?j?S wij , and where wij ?
0 in-dicates the similarity between sentences i and j ?Ci : 2V ?
R is itself monotone submodular (modu-lar in fact) and 0 ?
?
?
1 is a saturation coefficient.fSC(S) is monotone submodular and therefore hasthe previously mentioned performance guarantees.The weighting function w was implemented as thecosine similarity between TF-IDF weighted n-gramcount vectors for the sentences in the dataset.3.2 Submodular Speech SummarizationSimilar to the procedure described above we can treatthe task of subselecting an acoustic data set as anextractive summarization problem.
For our a prioridata selection scenario we would like to extract thosetraining samples that jointly are representative ofthe total data set.
Initial explorations of submodularfunctions for speech data can be found in (Lin andBilmes, 2009), where submodular functions wereused in combination with a purely acoustic similaritymeasure (Fisher kernel).
In addition Equation 2 thefacility location function was used:ffac(S) =?i?Vmaxj?Swij (3)Here our focus is on utilizing methods that movebeyond purely acoustic similarity measures and con-sider kernels derived from discrete representationsof the acoustic signal.
To this end we first run a to-kenizer over the acoustic signal that converts it intoa sequence of discrete labels.
In our case we use a722simple bottom-up monophone recognizer (withouthigher-level constraints such as a phone languagemodel) that produces phone labels.
We then use thehypothesized sequence of phonetic labels to computetwo different sentence similarity measures: (a) co-sine similarity using TF-IDF weighted phone n-gramcounts, and (b) string kernels.
We compare theirperformance to that of the Fisher kernel as a purelyacoustic similarity measure.TF-IDF weighted cosine similarityThe cosine similarity between phone sequences siand sj is computed assimij =?w?si tfw,si ?
tfw,sj ?
idf2w?
?w?si tf2w,si idf2w?
?w?sj tf2w,sj idf2w(4)where tfw,si is the count of n-gram w in si and idfwis the inverse document count of w (each sentence isa ?document?).
We use n = 1, 2, 3.String kernelThe particular string kernel we use is a gapped,weighted subsequence kernel of the type described in(Rousu and Shawe-Taylor, 2005).
Formally, we de-fine a sentence s as a concatenation of symbols froma finite alphabet ?
(here the inventory of phones) andan embedding function from strings to feature vec-tors, ?
: ??
?
H. The string kernel function K(s, t)computes the distance between the resulting vectorsfor two sentences si and sj .
The embedding functionis defined as?ku(s) :=?i:u=s(i)?|i| u ?
?k (5)where k is the maximum length of subsequences,|i| is the length of i, and ?
is a penalty parameterfor each gap encountered in the subsequence.
K isdefined asK(si, sj) =?u?
?u(si), ?u(sj)?wu (6)where w is a weight dependent on the length ofu, l(u).
Finally, the kernel score is normalized by?K(si, si) ?
K(sj , sj) to discourage long sentencesfrom being favored.Fisher kernelThe Fisher kernel is based on the vector of derivativesUX of the log-likelihood of the acoustic data (X)with respect to the parameters in the phone HMMs?1, ..., ?m for m models, having similarity score:simij = (maxi?,j?di?j?)?
dij , where dij = ||U ?i ?
U?j ||1,U ?X = 5?
logP (X|?
), and U?X = U?1X ?
U?2x , ..., ?U?mX .4 Data and SystemsWe evaluate our approach on subselecting trainingdata from the TIMIT corpus for training a phone rec-ognizer.
Although this not a large-scale data task, itis an appropriate proof-of-concept task for rapidlytesting different combinations of submodular func-tions and similarity measures.
Our goal is to focuson acoustic modeling only; we thus look at phonerecognition performance and do not have to take intoaccount potential interactions with a language model.We also chose a simple acoustic model, a monophoneHMM recognizer, rather than a more powerful butcomputationally complex model in order to ensurequick experimental turnaround time.
Note that thegoal of this study is not to obtain the highest phoneaccuracy possible; what is important is the relativeperformance of the different subset selection meth-ods, especially on small data subsets.The sizes of the training, development and test dataare 4620, 200 and 192 utterances, respectively.
Pre-processing was done by extracting 39-dimensionalMFCC feature vectors every 10 ms, with a windowof 25.6ms.
Speaker mean and variance normaliza-tion was applied.
A 16-component Gaussian mixturemonophone HMM system was trained on the full dataset to generate parameters for the Fisher kernel andphone sequences for the string kernel and TF-IDFbased similarity measures.Following the selection of subsets (2.5%, 5%, 10%,20%, 30%, 40%, 50%, 60%, 70% and 80% of thedata, measured as percentage of non-silence speechframes), we train a 3-state HMM monophone recog-nizer for all 48 TIMIT phone classes on the result-ing sets and evaluate the performance on the coretest set of 192 utterances, collapsing the 48 classesinto 39 in line with standard practice (Lee and Hon,1989).
The HMM state output distributions are mod-eled by diagonal-covariance Gaussian mixtures withthe number of Gaussians ranging between 4 and 64,depending on the data size.As a baseline we perform 100 random draws ofthe specified subset sizes and average the results.723The second baseline consists of the method in (Wu etal., 2007), where utterances are selected to maximizethe entropy of the distribution over phones in theselected subset.5 ExperimentsWe tested the three different similarity measures de-scribed above in combination with the submodularfunctions in Equations 2 and 3.
The parameters ofthe gapped string kernel (i.e.
the kernel order (k), thegap penalty (?
), and the contiguous substring lengthl) were optimized on the development set.
The bestvalues were ?
= 0.1, k = 4, l = 3.
We found thatfacility location was superior to saturated cover func-tion across the board.Comparison of different data subset selection methodsPhone Accuracy (%)PercentageofSpeechinSelectedSubset40# 45# 50# 55# 60# 65#80#70#60#50#40#30#20#10#5#2.5# string#kernel#TF7IDF#trigram#TF7IDF#bigram#TF7IDF#unigram#Fisher#kernel#entropy#random#Figure 1: Phone accuracy for different subset sizes; eachblock of bars lists, from bottom to top: random baseline,entropy baseline, Fisher kernel, TF-IDF (unigram), TF-IDF (bigram), TF-IDF (trigram), string kernel.Figure 1 shows the performance of the random andentropy-based baselines as well as the performanceof the facility location function with different sim-ilarity measures.
The entropy-based baseline beatsthe random baseline for most percentage cases butis otherwise the lowest-performing method overall.Note that this baseline uses the true transcriptions inline with (Wu et al 2007) rather than the hypothe-sized phone labels output by our recognizer.
The lowperformance and the fact that it is even outperformedby the random baseline in the 2.5% and 70% casesPercentageofSpeechinSelectedSubsetPhone Accuracy (%)Comparison of different submodular functions45505560652.5 5 10 20 30 40 60 60 70 80Figure 2: Phone accuracy obtained by random selection,facility location function, and saturated coverage function(string kernel similarity measure).may be because the selection method encourageshighly diverse but not very representative subsets.Furthermore, the entropy-based baseline utilizes anon-submodular objective function with a heuristicgreedy search method.
No theoretical guarantee ofoptimality can be made for the subset found by thismethod.Among the different similarity measures the Fisherkernel outperforms the baseline methods but haslower performance than the TF-IDF kernel and thestring kernel.
The best performance is obtained withthe string kernel, especially when using small train-ing data sets (2.5%-10%).
The submodular selectionmethods yield significant improvements (p < 0.05)over both the random baseline and over the entropy-based method.We also investigated using different submodularfunctions, i.e.
the facility location function and thesaturated coverage function.
Figure 2 shows the per-formance of the facility location (ffac) and saturatedcoverage (fSC) functions in combination with thestring kernel similarity measure.
The reason ffacoutperforms fSC is that fSC primarily controls forover-coverage of any element not in the subset via the?
saturation hyper-parameter.
However, it does notensure that every non-selected element has good rep-resentation in the subset.
fSC measures the quality ofthe subset by how well each individual element out-side the subset has a surrogate within the subset (via7244045505560652.5p 5p 10p 20p 30p4045505560652.5p 5p 10p 20p 30p4045505560652.5p 5p 10p 20p 30p4045505560652.5p 5p 10p 20p 30pTF-IDF bigramTF-IDF unigramstring kernelTF-IDF trigramFigure 3: Phone accuracy for true vs. hypothesized phonelabels, for string-based similarity measures.the max function) and hence tends to model completecoverage better, leading to better results.Finally we examined whether using hypothesizedphone sequences vs. the true transcriptions has nega-tive effects.
Figure 3 shows that this is not the case:interestingly, the hypothesized labels even result inslightly better results.
This may be because the rec-ognized phone sequences are a function of both theunderlying phonetic sequences that were spoken andthe acoustic signal characteristics, such as the speakerand channel.
The true transcriptions, on the otherhand, are able to provide information only about pho-netic as opposed to acoustic characteristics.6 DiscussionWe have presented a low-resource framework foracoustic data subset selection based on submodularfunction optimization, which was previously devel-oped for document summarization.
Evaluation on aproof-of-concept task has shown that the method issuccessful at selecting data subsets that outperformsubsets selected randomly or by a previously pro-posed low-resource method.
We note that the bestselection strategies for the experimental conditionstested here involve similarity measures based on adiscrete tokenization of the speech signal rather thandirect acoustic similarity measures.AcknowledgmentsThis material is based on research sponsored byIntelligence Advanced Research Projects Activity(IARPA) under agreement number FA8650-12-2-7263.
The U.S. Government is authorized to re-produce and distribute reprints for Governmentalpurposes notwithstanding any copyright notationthereon.
The views and conclusions contained hereinare those of the authors and should not be interpretedas necessarily representing the official policies orendorsements, either expressed or implied, of Intelli-gence Advanced Research Projects Activity (IARPA)or the U.S. Government.ReferencesB.
Chen, S.H Liu, and F.H.
Chu.
2009.
Training data se-lection for improving discriminative training of acousticmodels.
Pattern Recognition Letters, 30:1228?1235.J.
Edmonds, 1970.
Combinatorial Structures and their Ap-plications, chapter Submodular functions, matroids andcertain polyhedra, pages 69?87.
Gordon and Breach.G.
Hakkani-Tur, G. Riccardi, and A. Gorin.
2002.
Activelearning for automatic speech recognition.
In Proc.
ofICASSP, pages 3904?3907.N.
Itoh, T.N.
Sainath, D.N.
Jiang, J. Zhou, and B. Ramab-hadran.
2012.
N-best entropy based data selection foracoustic modeling.
In Proceedings of ICASSP.Thomas Kemp and Alex Waibel.
1998.
Unsupervisedtraining of a speech recognizer using TV broadcasts.In in Proceedings of the International Conference onSpoken Language Processing (ICSLP-98), pages 2207?2210.A.
Krause and C. Guestrin.
2011.
Submodularity and itsapplications in optimized information gathering.
ACMTransactions on Intelligent Systems and Technology,2(4).L.
Lamel, J.L.
Gauvain, and G. Adda.
2002.
Lightlysupervised and unsupervised acoustic model training.Computer, Speech and Language, 16:116 ?
125.K.F.
Lee and H.W.
Hon.
1989.
Speaker-independentphone recognition using Hidden Markov Models.
IEEETrans.
ASSP, 37:1641?1648.Hui Lin and Jeff A. Bilmes.
2009.
How to select a goodtraining-data subset for transcription: Submodular ac-tive selection for sequences.
In Proc.
Annual Confer-ence of the International Speech Communication Asso-ciation (INTERSPEECH), Brighton, UK, September.H.
Lin and J. Bilmes.
2011.
A class of submodularfunctions for document summarization.
In Proceedingsof ACL.R.K.
Moore.
2003.
A comparison of the data require-ments of automatic speech recognition systems andhuman listeners.
In Proceedings of Eurospeech, pages2581?2584.G.
L. Nemhauser, L. A. Wolsey, and M. L. Fisher.
1978.An analysis of approximations for maximizing submod-ular functions-I.
Math.
Program., 14:265?294.725J.
Rousu and J. Shawe-Taylor.
2005.
Efficien computa-tion of of gapped substring kernels for large alphabets.Journal of Machine Leaning Research, 6:13231344.Y.
Wu, R. Zhang, and A. Rudnicky.
2007.
Data selectionfor speech recognition.
In Proceedings of ASRU.726
