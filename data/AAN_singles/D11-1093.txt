Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1003?1011,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsRefining the Notions of Depth and Density in WordNet-basedSemantic Similarity MeasuresTong WangDepartment of Computer ScienceUniversity of Torontotong@cs.toronto.eduGraeme HirstDepartment of Computer ScienceUniversity of Torontogh@cs.toronto.eduAbstractWe re-investigate the rationale for and the ef-fectiveness of adopting the notions of depthand density in WordNet-based semantic sim-ilarity measures.
We show that the intuitionfor including these notions in WordNet-basedsimilarity measures does not always stand upto empirical examination.
In particular, thetraditional definitions of depth and densityas ordinal integer values in the hierarchicalstructure of WordNet does not always corre-late with human judgment of lexical semanticsimilarity, which imposes strong limitationson their contribution to an accurate similaritymeasure.
We thus propose several novel defi-nitions of depth and density, which yield sig-nificant improvement in degree of correlationwith similarity.
When used in WordNet-basedsemantic similarity measures, the new defini-tions consistently improve performance on atask of correlating with human judgment.1 IntroductionSemantic similarity measures are widely used innatural language processing for measuring distancebetween meanings of words.
There are currentlytwo mainstream approaches to deriving such mea-sures, i.e., distributional and lexical resource-basedapproaches.
The former usually explores the co-occurrence patterns of words in large collectionsof texts such as text corpora (Lin, 1998) or theWeb (Turney, 2001).
The latter takes advantage ofmostly handcrafted information, such as dictionar-ies (Chodorow et al, 1985; Kozima and Ito, 1997)or thesauri (Jarmasz and Szpakowicz, 2003).Another important resource in the latter stream issemantic taxonomies such as WordNet (Fellbaum,1998).
Despite their high cost of compilation andlimited availability across languages, semantic tax-onomies have been widely used in similarity mea-sures, and one of the main reasons behind this is thatthe often complex notion of lexical semantic simi-larity can be approximated with ease by the distancebetween words (represented as nodes) in their hier-archical structures, and this approximation appealsmuch to our intuition.
Even methods as simple as?hop counts?
between nodes (e.g., that of Rada et al1989 on the English WordNet) can take us a longway.
Meanwhile, taxonomy-based methods havebeen constantly refined by incorporating variousstructural features such as depth (Sussna, 1993; Wuand Palmer, 1994), density (Sussna, 1993), type ofconnection (Hirst and St-Onge, 1998; Sussna, 1993),word class (sense) frequency estimates (Resnik,1999), or a combination these features (Jiang andConrath, 1997).
Most of these algorithms are fairlyself-contained and easy to implement, with off-the-shelf toolkits such as that of Pedersen et al (2004).With the existing literature focusing on carefullyweighting these features to construct a better seman-tic similarity measure, however, the rationale foradopting these features in calculating semantic sim-ilarity remains largely intuitive.
To the best of ourknowledge, there is no empirical study directly in-vestigating the effectiveness of adopting structuralfeatures such as depth and density.
This serves asthe major motivation for this study.The paper is organized as follows.
In Section2 we review the basic rationale for adopting depth1003and density in WordNet-based similarity measuresas well as existing literature on constructing suchmeasures.
In Section 3, we show the limitations ofthe current definitions of depth and density as well aspossible explanations for these limitations.1 We thenpropose new definitions to avoid such limitations inSection 4.
The effectiveness of the new definitionsis evaluated by applying them in semantic similar-ity measures in Section 5 and conclusions made inSection 6.2 Related WorkThe following are the current definitions of depthand density which we aim at improving.
Given anode/concept c in WordNet, depth refers to the num-ber of nodes between c and the root of WordNet,(i.e., the root has depth zero, its hyponyms depthone, and so on).
There are more variations in thedefinition of density, but it is usually defined as thenumber of edges leaving c (i.e., its number of childnodes) or leaving its parent node(s) (i.e., its numberof sibling nodes).
We choose to use the latter sinceit is used by most of the existing literature.2.1 The Rationale for Depth and DensityThe rationale for using the notions of depth and den-sity in WordNet-based semantic similarity measuresis based on the following assumption:Assumption 1 Everything else being equal, twonodes are semantically closer if (a) they residedeeper in the WordNet hierarchy, or (b) they aremore densely connected locally.This is the working assumption for virtually allWordNet-based semantic similarity studies usingdepth and/or density.
For depth, the intuition isthat adjacent nodes deep down the hierarchy arelikely to be conceptually close, since the differen-tiation is based on finer details (Jiang and Conrath,1997).
Sussna (1993) termed the use of depth asdepth-relative scaling, claiming that ?only-siblingsdeep in a tree are more closely related than only-siblings higher in the tree?.
Richardson and Smeaton(1995) gave an hypothetical example illustratingthis ?only-siblings?
situation, where plant?animal1Since the works we review in this section have differentdefinitions of depth and density, we defer our formal definitionsto Section 3.are the only two nodes under living things, andwolfhound?foxhound under hound.
They claimedthe reason that the former pair can be regarded asconceptually farther apart compared to the latter isrelated to the difference in depth.As for the relation between density and similar-ity, the intuition is that if the overall semantic massfor a given node is constant (Jiang and Conrath,1997), then the more neighboring nodes there are ina locally connected subnetwork, the closer its mem-bers are to each other.
For example, animal, per-son, and plant are more strongly connected with lifeform than aerobe and plankton because the first threewords all have high density in their local networkstructures (Richardson and Smeaton, 1995).
Notethat the notion of density here is not to be con-fused with the conceptual density used by Agirreand Rigau (1996), which is essentially a semanticsimilarity measure by itself.In general, both observations on depth and densityconform to intuition and are supported qualitativelyby several existing studies.
The main objective ofthis study is to empirically examine the validity ofthis assumption.2.2 Semantic Similarity Measures Using Depthand/or DensityOne of the first examples of using depth and den-sity in WordNet-based similarity measures is that ofSussna (1993).
The weight on an edge between twonodes c1 and c2 with relation r in WordNet is givenas:w(c1,c2) = w(c1?r c2)+w(c2?r c1)2dwhere d is the depth of the deeper of the two nodes.As depth increases, weight decreases and similarityin turn increases, conforming to Assumption 1.
Theedge weight was further defined asw(c1?r c2) = maxr?
maxr?minrnr(c1)where nr(X) is ?the number of relations of type rleaving node X?, which is essentially an implicitform of density, and maxr and minr are the maxi-mum and minimum of nr, respectively.
Note thatthis formulation of density contradicts Assumption10041 since it is proportional to edge weight (left-hand-side) and thus negatively correlated to similarity.Wu and Palmer (1994) proposed a concept simi-larity measure between two concepts c1 and c2 as:sim(c1,c2) = 2 ?dep(c)len(c1,c)+ len(c2,c)+2 ?dep(c)(1)where c is the lowest common subsumer (LCS) of c1and c2, and len(?, ?)
is the number of edges betweentwo nodes.
The rationale is to adjust ?hop count?
(the first two terms in the denominator) with thedepth of LCS: similarity between nodes with same-level LCS is in negative proportion to hop counts,while given the same hop count, a ?deeper?
LCSpulls the similarity score closer to 1.Jiang and Conrath (1997) proposed a hybridmethod incorporating depth and density informationinto an information-content-based model (Resnik,1999):w(c, p) =(dep(p)+1dep(p) )??
[?+(1??)
E?den(p) ]?
[IC(c)?
IC(p)]T (c, p) (2)Here, p and c are parent and child nodes in Word-Net, dep(?)
and den(?)
denote the depth and den-sity of a node, respectively, E?
is the average densityover the entire network of WordNet, and ?
and ?
aretwo parameters controlling the contribution of depthand density values to the similarity score.
IC(?)
isthe information content of a node based on proba-bility estimates of word classes from a small sense-tagged corpus (Resnik, 1999), and T (c, p) is a link-type factor differentiating different types of relationsbetween c and p.3 Limitations on the Current Definitions ofDepth and DensityTo what extent do the notions of depth and densityhelp towards an accurate semantic similarity mea-sure?
Our empirical investigation below suggeststhat more often than not, they fail our intuition.A direct assessment of the effectiveness of us-ing depth and density is to examine their correla-tion with similarity.
Empirical results in this sectionFigure 1: Correlation between depth and similarity.are achieved by the following experimental setting.Depth is defined as the number of edges between theroot of the hierarchy and the lowest common sub-sumer (LCS) of two nodes under comparison, anddensity as the number of siblings of the LCS.2 Sim-ilarity is measured by human judgment on similar-ity between word pairs.
Commonly used data setsfor such judgments include that of Rubenstein andGoodenough (1965), Miller and Charles (1991), andFinkelstein et al (2001) (denoted RG, MC, and FG,respectively).
RG is a collection of similarity ratingsof 65 word pairs averaged over judgments from 51human subjects on a scale of 0 to 4 (from least tomost similar).
MC is a subset of 30 pairs out of theRG data set.
These pairs were chosen to have evenlydistributed similarity ratings in the original data set,and similarity judgment was elicited from 38 humanjudges with the same instruction as used for RG.
FGis a much larger set consisting of 353 word pairs,and the rating scale is from 0 to 10.
We combine theRG and FG data sets in order to maximize data size.Human ratings r on individual sets are normalized torn on 0 to 1 scale by the following formula:rn = r?
rminrmax?
rminwhere rmax and rmin are the maximum and minimumof the original ratings, respectively.
Correlation isevaluated using Spearman?s ?.2We also tried several other variants of these definitions,e.g., using the maximum or minimum depth of the two nodesinstead of the LCS.
With respect to statistical significance tests,these variants all gave the same results as our primary definition.1005Figure 2: Histogram of depth of WordNet noun synsets.3.1 DepthThe distribution of similarity of the combined dataset over depth is plotted in Figure 1.
For depth val-ues under 5, similarity scores are fairly evenly dis-tributed over depth, showing no statistical signifi-cance in correlation.
For depth 5 and above, theshape of distribution resembles an upper-triangle,suggesting that (1) correlation with similarity be-comes stronger in this range of depth value, and (2)data points with higher depth values tend to havehigher similarity scores, but the reverse of the claimdoes not hold, i.e., word pairs with ?shallower?
LCScan also be judged quite similar by humans.There are many more data points with lower depthvalues than with higher depth values in the com-bined data set.
In order to have a fair comparison ofstatistical significance tests on the two value rangesfor depth, we randomly sample an equal number(100) of data points from each value range, and thecorrelation coefficient between depth and similarityis averaged over 100 of such samplings.
Correla-tion coefficients for depth value under 5 versus 5 andabove are ?
= 0.0881, p ?
0.1 and ?
= 0.3779, p <0.0001, respectively, showing an apparent differencein degree of correlation.Two interesting observations can be made fromthese results.
Firstly, the notion of depth is relativeto the distribution of number of nodes over depthvalue.
For example, depth 20 by itself is virtuallymeaningless since it might be quite high if the ma-jority of nodes in WordNet are of depth 10 or less,or quite low if the majority depth value are 50 ormore.
According to the histogram of depth valuesin WordNet (Figure 2), the distribution of number ofnodes over depth value approximately conforms to anormal distribution N (8,2).
It is visually quite no-ticeable that the actual quantity denoting how deep anode resides in WordNet is conflated at depth valuesbelow 5 or above 14.
In other words, the distributionmakes it rather inaccurate to say, for instance, that anode of depth 4 is twice as deep as a node of depth 2.This might explain the low degree of correlation be-tween similarity and depth under 5 in Figure 1 (man-ifested by the long, vertical stripes across the entirerange of similarity scores (0 to 1) for depth 4 andunder), and also how the correlation increases withdepth value.
Unfortunately, we do not have enoughdata for depth above 14 to draw any conclusion onthis higher end of the depth spectrum.Secondly, even on the range of depth values withhigher correlation with similarity, there is no defini-tive sufficient and necessary relation between depthand similarity (hence the upper triangle instead ofa sloped line or band).
Particularly, semanticallymore similar words are not necessarily deeper in theWordNet hierarchy.
Data analysis reveals that theLCS of highly similar words can be quite close tothe hierarchical root.
Examples include coast?shore,which is judged to be very similar by humans (9 ona scale of 0?10 in both data sets).
The latter is a hy-pernym of the former and thus the LCS of the pair,yet it is only four levels below the root node entity(via geological formation, object, and physical en-tity).
Another situation is when the human judgesconfused relatedness with similarity, and WordNetfails to capture the relatedness with its hierarchicalstructure of lexical semantics: the pair software?computer can only be related by the root node en-tity as their LCS, although the pair is judged quite?similar?
by humans (8.5 on 0 to 10 scale).The only conclusive claim that can be made hereis that word pairs with deeper LCS?s tend to be moresimilar.
However, since only word forms (ratherthan senses) are available in these psycho-linguisticexperiments, the one similarity rating given by hu-man judges sometimes fails to cover multiple sensesfor polysemous words.
In the pair stock?jaguar ofthe FG set, for example, one sense of stock (live-stock, stock, farm animal: any animals kept for useor profit) is closely connected to jaguar through adepth-10 LCS (placental, placental mammal, eu-therian, eutherian mammal).
However, the pair re-ceived a low similarity rating (0.92 on 0?10), prob-1006Figure 3: Correlation between density and similarity.MC RG FGdep 0.7056*** 0.6909*** 0.3701***den 0.2268 0.2660* 0.1023Table 1: Correlation between depth/density and similar-ity on individual data sets.
Number of asterisks indicatesdifferent confidence intervals (?*?
for p < 0.05, ?***?
forp < 0.0001).ably because judges associated the word form stockwith its financial sense, especially when there wasan abundant presence of pairs indicating this particu-lar sense of the word (e.g., stock?market, company?stock).3.2 DensityComparing to depth, density exhibits much lowercorrelation with similarity (Figure 3-a and 3-b).
Weconducted correlation experiments between densityand similarity with the same setting as for depth andsimilarity above.
Data points with extremely highdensity values (up to over 400) are mostly idiosyn-cratic to the densely connected regions in WordNetand are numerically quite harmful.
We thus ex-cluded outliers with density values above 100 in theexperiment.Evaluation on the combined data set shows nocorrelation between density and similarity.
To con-firm the result, we break the experiments down to thethree individual data sets, and the results are listed inTable 1.
The correlation coefficient between densityand similarity ranges from 0.10 to 0.27 There is nostatistical significance of correlation on two of thethree data sets (MC and FG), and the significanceon RG is close to marginal with p = 0.0366.Data analysis suggests that density values are of-ten biased by particular fine-grainedness of localstructures in WordNet.
Qualitatively, Richardsonand Smeaton (1995) previously observed that ?theirregular densities of links between concepts resultsin unexpected conceptual distance measures?.
Em-pirically, on the one hand, more than 90% of Word-Net nodes have density values less than or equal to3.
This means that for 90% of the LCS?s, there areonly three integer values for density to distinguishthe varying degrees of similarity.
In other words,such a range might be too narrow to have any realdistinguishing power over similarity.
On the otherhand, there are outliers with extreme density valuesparticular to the perhaps overly fine-grained subcat-egorization of some WordNet concepts, and thesenodes can be LCS?s of word pairs of drastically dif-ferent similarity.
The node person, individual, forexample, can be the LCS of similar pairs such asman?woman, as well as quite dissimilar ones suchas boy?sage, where the large density value does notnecessarily indicate high degree of similarity.Another crucial limitation of the definition of den-sity is the information loss on specificity.
In the ex-isting literature, density is often adopted as a proxyfor the degree of specificity of a concept, i.e., nodesin densely connected regions in WordNet are takento be more specific and thus closer to each other.This information of a given node should be inher-ited by its hierarchical descendants, since specificityshould monotonically increase as one descends thehierarchy.
For example, the node piano has a den-sity value of 15 under the node percussion instru-ment.
However, the density value of its hyponymsGrand piano, upright piano, and mechanical piano,is only 3.
Due to the particular structure of this sub-network in WordNet, the grand?upright pair mightbe incorrectly regarded as less specific (and thus lesssimilar) than, say, between piano?gong, both as per-cussion instruments.4 New Definitions of Depth and DensityIn this section, we formalize new definitions ofdepth and density to correct for their current limi-1007MC RG FGdepu 0.7201*** 0.6798*** 0.3751***denu 0.2268 0.2660* 0.1019deni 0.7338*** 0.6751*** 0.3445***Table 2: Correlation between new definitions ofdepth/density and similarity.tations discussed in Section 3.4.1 DepthThe major problem with the current definition ofdepth is its failure to take into account the unevendistribution of number of nodes over the depth value.As seen in previous examples, the distribution israther ?flat?
on both ends of depth value, which doesnot preserve the linearity of using the ordinal valuesof depth and thus introduces much inaccuracy.To avoid this problem, we ?re-curve?
depth valueto the cumulative distribution.
Specifically, if wetake the histogram distribution of depth value in Fig-ure 2 as a probability density function, our approachis to project cardinal depth values onto its cumula-tive distribution function.
The new depth is denoteddepu and is defined as:depu(c) = ?c?
?WN |{c?
: dep(c?)?
dep(c)}||WN|Here, dep(?)
is the original depth value, and WN isthe set of all nodes in WordNet.
The resulting depthvalues not only reflect the flat ends, but also preservelinearity for the depth value range in the middle.
Incomparison with Table 1), correlation between depuand similarity increases over the original depth val-ues on two of the three data sets (first row in Table2 and decreases on the RG set.
Later, in Section 5,we show how these marginal improvements translateinto better similarity measures with statistical signif-icance.4.2 DensityIn theory, a procedure analogous to the above cumu-lative definition can also be applied to density, i.e.,by projecting the original values onto the cumula-tive distribution function.
However, due to the Zip-fian nature of density?s histogram distribution (Fig-ure 4, in contrast to Gaussian for depth in Figure2), this is essentially to collapse most density valuesFigure 4: Histogram of density in WordNet.into a very small number of discrete values (whichcorrespond to the original density of 1 to 3).
Ex-periments show that it does not help in improvingcorrelation with similarity scores (second row in Ta-ble 2 for denu): correlation remains the same on MCand RG, and decreases slightly on FG.We therefore resort to addressing the issue of in-formation loss on specificity by inheritance.
Intu-itively, the idea is to ensure that a node be assignedno less density mass than its parent node(s).
In the?piano?
example (Section 3.2), the concept piano ishighly specific due to its large number of siblingsunder the parent node percussion instruments.
Con-sequently, the density of its child nodes upright pi-ano and grand piano should inherit its specificity ontop of their own.Formally, we redefine density recursively as fol-lows:deni(r) = 0deni(c) = ?h?hyper(c) deni(h)|hyper(c)| +den(c)where r is the root of WordNet hierarchy (with nohypernym), and hyper(?)
is the set of hypernyms of agiven concept.
The first term is the inheritance part,normalized over all hypernyms of c in case of mul-tiple inheritance, and the second term is the originalvalue of density.The resulting density values correlate signifi-cantly better with similarity.
As shown in row 3in Table 2, the correlation coefficients are abouttripled on all three data sets with the new densitydefinition deni, and the significance of correlationis greatly improved as well (from non-correlating or1008marginally correlating to strongly significantly cor-relating on all three data sets).5 Using the New Definitions in SemanticSimilarity MeasuresIn this section, we test the effectiveness of the newdefinitions of depth and density by using them inWordNet-based semantic similarity measures.
Thetwo similarity measures we experiment with are thatof Wu and Palmer (1994) and Jiang and Conrath(1997).
The first one used depth only, and the secondone used both depth and density.The task is to correlate the similarity measureswith human judgment on similarity between wordpairs.
We use the same three data sets as in Section3.
despite the fact that MC is a subset of RG dataset, we include both in order to compare with exist-ing studies.Correlation coefficient is calculated using Spear-man?s ?, although results reported by some earlierstudies used parametric tests such as the PearsonCorrelation Coefficient.
The reason for our choiceis that the similarity scores of the word pairs inthese data sets do not necessarily conform to nor-mal distributions.
Rather, we are interested in testingwhether the artificial algorithms would give higherscores to pairs that are regarded closer in meaningby human judges.
A non-parametric test suits betterfor this scenario.
And this partly explains why ourre-implementations of the models have lower corre-lation coefficients than in the original studies.Note that there are other WordNet-based similar-ity measures using depth and/or density that we optto omit for various reasons.
Some of them were notdesigned for the particular task at hand (e.g., that ofSussna, 1993, which gives very poor correlation inthis task).
Others use depth of the entire WordNethierarchy instead of individual nodes as a scalingfactor (e.g., that of Leacock and Chodorow, 1998),which is unsuitable for illustrating the improvementbrought about by the new depth and density defini-tions.Parameterization of the weighting of depth anddensity is a common practice to control their indi-vidual contribution to the final similarity score (e.g.,?
and ?
in Equation (2)).
Jiang and Conrath alreadyhad separate weights in their original study.
In or-Best AverageMC RB GR MC RB GRdep 0.7671 0.7824 0.3773 0.7612 0.7686 0.3660depu 0.7824 0.7912 0.3946 0.7798 0.7810 0.3787Table 3: Correlation between human judgment and simi-larity score by Wu and Palmer (1994) using two versionsof depth.Best AverageMC RB GR MC RB GRdep,den 0.7875 0.8111 0.3720 0.7689 0.7990 0.3583depu, den 0.8009 0.8181 0.3804 0.7885 0.8032 0.3669dep,deni 0.7882 0.8199 0.3803 0.7863 0.8102 0.3689depu,deni 0.8065 0.8202 0.3818 0.8189 0.8194 0.3715Table 4: Correlation between human judgment and sim-ilarity score by Jiang and Conrath (1997) using differentdefinitions of depth and density.der to parameterize depth used by Wu and Palmer intheir similarity measure, we also modify Equation(1) as follows:sim(c1,c2) = 2 ?dep?
(c)len(c1,c)+ len(c2,c)+2 ?dep?
(c)where depth is raised to the power of ?
to vary itscontribution to the similarity score.For a number of combinations of the weightingparameters, we report both the best performanceand the averaged performance over all the param-eter combinations.
The latter number is meaningfulin that it is a good indication of numerical stability ofthe parameterization.
In addition, parameterizationis able to generate multiple correlation coefficients,on which statistical tests can be run in order to showthe significance of improvement.
We use the rangefrom 0 to 5 with step 1 for ?
and from 0 to 1 withstep 0.1 for ?.Table 3 and 4 list the experiment results.
In bothmodels, the cumulative definition of depth depu con-sistently improve the performance of the similaritymeasures.
In the Jiang and Conrath (1997) model,where density is applicable, the inheritance-baseddefinition of density deni also results in better cor-relation with human judgments.
The optimal resultis achieved when combining the new definitions ofdepth and density (row 4 in Table 4).
For averageperformance, the improvement of all the new def-initions over the original definitions is statistically1009significant on all three data sets according to pairedt-test.6 ConclusionsThis study explored effective uses of depth and/ordensity in WordNet-based similarity measures.
Westarted by examining how well these two structuralfeatures correlate with human judgment on wordpair similarities.
This direct comparison showed thatdepth correlates with similarity only on certain valueranges, while density does not correlate with humanjudgment at all.Further investigation revealed that the problem fordepth lies in the simplistic representation as its ordi-nal integer values.
The linearity in this representa-tion fails to take into account the conflated quantityof depth in the two extreme ends of the depth spec-trum.
For density, a prominent issue is the informa-tion loss on specificity of WordNet concepts, whichgives an inaccurate density value that is biased bythe idiosyncratic constructions in densely connectedregions in the hierarchy.We then proposed new definitions of depth anddensity to address these issues.
For depth, linear-ity in different value ranges is realistically reflectedby projecting the depth value to its cumulative dis-tribution function.
The loss of specificity informa-tion in density, on the other hand, is corrected byallowing concepts to inherit specificity informationfrom their parent nodes.
The new definitions showsignificant improvement in correlation of semanticsimilarity given by human judges.
In addition, whenused in existing WordNet-based similarity measures,they consistently improve performance and numeri-cal stability of the parameterization of the two fea-tures.The notions of depth and density pertain to anyhierarchical structure like WordNet, which suggestsvarious extensions of this work.
A natural next stepof the current work is to apply the same idea to se-mantic taxonomies in languages other than Englishwith available similarity judgments are also avail-able.
Extrinsic tasks using WordNet-based semanticsimilarity can potentially benefit from these refinednotions of depth and density as well.AcknowledgmentsThis study was inspired by lectures given by Profes-sor Gerald Penn of the University of Toronto, andwas financially supported by the Natural Sciencesand Engineering Research Council of Canada.ReferencesEneko Agirre and German Rigau.
Word sense dis-ambiguation using conceptual density.
In Pro-ceedings of the 16th Conference on Computa-tional Linguistics, pages 16?22.
Association forComputational Linguistics, 1996.Martin Chodorow, Roy Byrd, and George Heidorn.Extracting semantic hierarchies from a large on-line dictionary.
In Proceedings of the 23rd An-nual Meeting of the Association for Computa-tional Linguistics, pages 299?304, Chicago, Illi-nois, USA, 1985.Christiane Fellbaum.
WordNet: An Electronic Lexi-cal Database.
MIT Press, Cambridge, MA, 1998.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-tan Ruppin.
Placing search in context: The con-cept revisited.
In Proceedings of the 10th Inter-national Conference on World Wide Web, pages406?414.
ACM, 2001.Graeme Hirst and David St-Onge.
Lexical chainsas representations of context for the detection andcorrection of malapropisms.
In Christiane Fell-baum, editor, WordNet: An Electronic LexicalDatabase, pages 305?332.
1998.Mario Jarmasz and Stan Szpakowicz.
Roget?s the-saurus and semantic similarity.
In Proceedingsof International Conference on Recent Advancesin Natural Language Processing, pages 212?219,Borovets, Bulgaria, 2003.Jay Jiang and David Conrath.
Semantic similaritybased on corpus statistics and lexical taxonomy.Proceedings of International Conference on Re-search in Computational Linguistics, 33, 1997.Hideki Kozima and Akira Ito.
Context-sensitivemeasurement of word distance by adaptive scal-ing of a semantic space.
Recent Advances in Nat-ural Language Processing: Selected Papers fromRANLP, 95:111?124, 1997.1010Claudia Leacock and Martin Chodorow.
Combin-ing local context and WordNet similarity for wordsense identification.
WordNet: An electronic lexi-cal database, 49(2):265?283, 1998.Dekang Lin.
Automatic retrieval and clustering ofsimilar words.
In Proceedings of the 17th Interna-tional Conference on Computational Linguistics,pages 768?774, Montreal, Canada, 1998.Goerge Miller and Walter Charles.
Contextual cor-relates of semantic similarity.
Language and Cog-nitive Processes, 6(1):1?28, 1991.Ted Pedersen, Siddharth Patwardhan, and JasonMichelizzi.
WordNet::Similarity: measuring therelatedness of concepts.
In Demonstration Papersat Human Language Technologies - North Ameri-can Chapter of the Association for ComputationalLinguistics, pages 38?41.
Association for Com-putational Linguistics, 2004.Roy Rada, Hafedh Mili, Ellen Bicknell, and MariaBlettner.
Development and application of a metricon semantic nets.
IEEE Transactions on Systems,Man and Cybernetics, 19(1):17?30, 1989.Philip Resnik.
Semantic similarity in a taxon-omy: an information-based measure and its ap-plication to problems of ambiguity in natural lan-guage.
Journal of Artificial Intelligence Research,11(11):95?130, 1999.R.
Richardson and A.F.
Smeaton.
Using WordNetin a knowledge-based approach to information re-trieval.
In Proceedings of the BCS-IRSG Collo-quium, Crewe.
Citeseer, 1995.Herbert Rubenstein and John Goodenough.
Contex-tual correlates of synonymy.
Communications ofthe ACM, 8(10):627?633, 1965.Michael Sussna.
Word sense disambiguation forfree-text indexing using a massive semantic net-work.
In Proceedings of the second internationalconference on Information and knowledge man-agement, pages 67?74.
ACM, 1993.Peter Turney.
Mining the web for synonyms: PMI-IR versus LSA on TOEFL.
Proceedings of theTwelfth European Conference on Machine Learn-ing, pages 491?502, 2001.Zhibiao Wu and Martha Palmer.
Verb semanticsand lexical selection.
In Proceedings of the 32ndAnnual Meeting of the Association for Compu-tational Linguistics, pages 133?138.
Associationfor Computational Linguistics, 1994.1011
