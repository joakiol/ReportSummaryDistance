Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 185?193,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsWhen Did that Happen?
?
Linking Events and Relations to TimestampsDirk Hovy*, James Fan, Alfio Gliozzo, Siddharth Patwardhan and Chris WeltyIBM T. J. Watson Research Center19 Skyline DriveHawthorne, NY 10532dirkh@isi.edu, {fanj,gliozzo,siddharth,welty}@us.ibm.comAbstractWe present work on linking events and flu-ents (i.e., relations that hold for certainperiods of time) to temporal informationin text, which is an important enabler formany applications such as timelines andreasoning.
Previous research has mainlyfocused on temporal links for events, andwe extend that work to include fluentsas well, presenting a common methodol-ogy for linking both events and relationsto timestamps within the same sentence.Our approach combines tree kernels withclassical feature-based learning to exploitcontext and achieves competitive F1-scoreson event-time linking, and comparable F1-scores for fluents.
Our best systems achieveF1-scores of 0.76 on events and 0.72 on flu-ents.1 IntroductionIt is a long-standing goal of NLP to process natu-ral language content in such a way that machinescan effectively reason over the entities, relations,and events discussed within that content.
The ap-plications of such technology are numerous, in-cluding intelligence gathering, business analytics,healthcare, education, etc.
Indeed, the promiseof machine reading is actively driving research inthis area (Etzioni et al 2007; Barker et al 2007;Clark and Harrison, 2010; Strassel et al 2010).Temporal information is a crucial aspect of thistask.
For a machine to successfully understandnatural language text, it must be able to associatetime points and temporal durations with relationsand events it discovers in text.
?The first author conducted this research during an in-ternship at IBM Research.In this paper we present methods to estab-lish links between events (e.g.
?bombing?
or?election?)
or fluents (e.g.
?spouseOf?
or ?em-ployedBy?)
and temporal expressions (e.g.
?lastTuesday?
and ?November 2008?).
While previ-ous research has mainly focused on temporal linksfor events only, we deal with both events and flu-ents with the same method.
For example, considerthe sentence belowBefore his death in October, Steve Jobsled Apple for 15 years.For a machine reading system processing thissentence, we would expect it to link the fluentCEO of (Steve Jobs, Apple) to time duration ?15years?.
Similarly we expect it to link the event?death?
to the time expression ?October?.We do not take a strong ?ontological?
positionon what events and fluents are, as part of ourtask these distinctions are made a priori.
In otherwords, events and fluents are input to our tempo-ral linking framework.
In the remainder of this pa-per, we also do not make a strong distinction be-tween relations in general and fluents in particu-lar, and use them interchangeably, since our focusis only on the specific types of relations that rep-resent fluents.
While we only use binary relationsin this work, there is nothing in the frameworkthat would prevent the use of n-ary relations.
Ourwork focuses on accurately identifying temporallinks for eventual use in a machine reading con-text.In this paper, we describe a single approach thatapplies to both fluents and events, using featureengineering as well as tree kernels.
We show thatwe can achieve good results for both events andfluents using the same feature space, and advocate185the versatility of our approach by achieving com-petitive results on yet another similar task with adifferent data set.Our approach requires us to capture contextualproperties of text surrounding events, fluents andtime expressions that enable an automatic systemto detect temporal linking within our framework.A common strategy for this is to follow standardfeature engineering methodology and manuallydevelop features for a machine learning modelfrom the lexical, syntactic and semantic analysisof the text.
A key contribution of our work in thispaper is to demonstrate a shallow tree-like repre-sentation of the text that enables us to employ treekernel models, and more accurately detect tempo-ral linking.
The feature space represented by suchtree kernels is far larger than a manually engi-neered feature space, and is capable of capturingthe contextual information required for temporallinking.The remainder of this paper goes into the de-tails of our approach for temporal linking, andpresents empirical evidence for the effectivenessof our approach.
The contributions of this papercan be summarized as follows:1.
We define a common methodology to linkevents and fluents to timestamps.2.
We use tree kernels in combination with clas-sical feature-based approaches to obtain sig-nificant gains by exploiting context.3.
Empirical evidence illustrates that ourframework for temporal linking is very ef-fective for the task, achieving an F1-score of0.76 on events and 0.72 on fluents/relations,as well as 0.65 for TempEval2, approachingstate-of-the-art.2 Related WorkMost of the previous work on relation extractionfocuses on entity-entity relations, such as in theACE (Doddington et al 2004) tasks.
Temporalrelations are part of this, but to a lesser extent.The primary research effort in event temporalityhas gone into ordering events with respect to oneanother (e.g., Chambers and Jurafsky (2008)), anddetecting their typical durations (e.g., Pan et al(2006)).Recently, TempEval workshops have focusedon the temporal related issues in NLP.
Some ofthe TempEval tasks overlap with ours in manyways.
Our task is similar to task A and C ofTempEval-1 (Verhagen et al 2007) in the sensethat we attempt to identify temporal relation be-tween events and time expressions or documentdates.
However, we do not use a restricted set ofevents, but focus primarily on a single temporalrelation tlink instead of named relations like BE-FORE, AFTER or OVERLAP (although we showthat we can incorporate these as well).
Part of ourtask is similar to task C of TempEval-2 (Verha-gen et al 2010), determining the temporal rela-tion between an event and a time expression inthe same sentence.
In this paper, we do apply oursystem to TempEval-2 data and compare our per-formance to the participating systems.Our work is similar to that of Boguraev andAndo (2005), whose research only deals withtemporal links between events and time expres-sions (and does not consider relations at all).
Theyemploy a sequence tagging model with manualfeature engineering for the task and achievedstate-of-the-art results on Timebank (Pustejovskyet al 2003) data.
Our task is slightly different be-cause we include relations in the temporal linking,and our use of tree kernels enables us to explore awider feature space very quickly.Filatova and Hovy (2001) also explore tempo-ral linking with events, but do not assume thatevents and time stamps have been provided by anexternal process.
They used a heuristics-based ap-proach to assign temporal expressions to events(also relying on the proximity as a base case).They report accuracy of the assignment for thecorrectly classified events, the best being 82.29%.Our best event system achieves an accuracy of84.83%.
These numbers are difficult to compare,however, since accuracy does not efficiently cap-ture the performance of a system on a task with somany negative examples.Mirroshandel et al(2011) describe the use ofsyntactic tree kernels for event-time links.
Theirresults on TempEval are comparable to ours.
Incontrast to them, we found, though, that syntactictree kernels alone do not perform as well as usingseveral flat tree representations.3 Problem DefinitionThe task of linking events and relations to timestamps can be defined as the following: given a setof expressions denoting events or relation men-186tions in a document, and a set of time expressionsin the same document, find all instances of thetlink relation between elements of the two inputsets.
The existence of a tlink(e, t) means that e,which is an event or a relation mention, occurswithin the temporal context specified by the timeexpression t.Thus, our task can be cast as a binary rela-tion classification task: for each possible pairof (event/relation, time) in a document, decidewhether there exists a link between the two, andif so, express it in the data.In addition, we make these assumptions aboutthe data:1.
There does not exist a timestamp for ev-ery event/relation in a document.
Althoughevents and relations typically have temporalcontext, it may not be explicitly stated in adocument.2.
Every event/relation has at most one time ex-pression associated with it.
This is a simpli-fying assumption, which in the case of rela-tions we explore as future work.3.
Each temporal expression can be linked toone or more events or relations.
Since mul-tiple events or relations may happen for agiven time, it is safe to assume that each tem-poral expression can be linked to more thanone event/relation.In general, the events/relations and their associ-ated timestamps may occur within the same sen-tence or may occur across different sentences.
Inthis paper, we focus on our effort and our evalua-tion on the same sentence linking task.In order to solve the problem of temporal link-ing completely, however, it will be important toalso address the links that hold between entitiesacross sentences.
We estimate, based on our dataset, that across sentence links account for 41% ofall correct event-time pairs in a document.
For flu-ents, the ratio is much higher, more than 80% ofthe correct fluent-time links are across sentences.One of the main obstacles for our approach in thecross-sentence case is the very low ratio of posi-tive to negative instances (3 : 100) in the set of allpairs in a document.
Most pairs are not linked toone another.4 Temporal Linking FrameworkAs previously mentioned, we approach the tem-poral linking problem as a classification task.
Inthe framework of classification, we refer to eachpair of (event/relation, temporal expression) oc-curring within a sentence as an instance.
The goalis to devise a classifier that separates positive (i.e.,linked) instances from negative ones, i.e., pairswhere there is no link between the event/relationand the temporal expression in question.
The lat-ter case is far more frequent, so we have an inher-ent bias toward negative examples in our data.1Note that the basis of the positive and nega-tive links is the context around the target terms.It is impossible even for humans to determine theexistence of a link based only on the two termswithout their context.
For instance, given just twowords (e.g., ?said?
and ?yesterday?)
there is noway to tell if it is a positive or a negative example.We need the context to decide.Therefore, we base our classification models oncontextual features drawn from lexical and syn-tactic analyses of the text surrounding the targetterms.
For this, we first define a feature-basedapproach, then we improve it by using tree ker-nels.
These two subsections, plus the treatmentof fluent relations, are the main contributions ofthis paper.
In all of this work, we employ SVMclassifiers (Vapnik, 1995) for machine learning.4.1 Feature EngineeringA manual analysis of development data providedseveral intuitions about the kinds of features thatwould be useful in this task.
Based on this anal-ysis and with inspiration from previous work (cf.Boguraev and Ando (2005)) we established threecategories of features whose description follows.Features describing events or relations.
Wecheck whether the event or relation is phrasal, averb, or noun, whether it is present tense, pasttense, or progressive, the type assigned to theevent/relation by the UIMA type system used forprocessing, and whether it includes certain trig-ger words, such as reporting verbs (?said?, ?re-ported?, etc.
).1Initially, we employed an instance filtering method toaddress this, which proved to be ineffective and was subse-quently left out.187Features describing temporal expressions.We check for the presence of certain trigger words(last, next, old, numbers, etc.)
and the type ofthe expression (DURATION, TIME, or DATE) asspecified by the UIMA type system.Features describing context.
We also in-clude syntactic/structural features, such as testingwhether the relation/event dominates the temporalexpression, which one comes first in the sentenceorder, and whether either of them is dominatedby a separate verb, preposition, ?that?
(which of-ten indicates a subordinate sentence) or counter-factual nouns or verbs (which would negate thetemporal link).It is not surprising that some of the most in-formative features (event comes before tempo-ral expression, time is syntactic child of event)are strongly correlated with the baselines.
Lesssalient features include the test for certain wordsindicating the event is a noun, a verb, and if sowhich tense it has and whether it is a reportingverb.4.2 Tree Kernel EngineeringWe expect that there exist certain patterns be-tween the entities of a temporal link, which mani-fest on several levels: some on the lexical level,others expressed by certain sequences of POStags, NE labels, or other representations.
Kernelsprovide a principled way of expanding the numberof dimensions in which we search for a decisionboundary, and allow us to easily model local se-quences and patterns in a natural way (Giuliano etal., 2009).
While it is possible to define a spacein which we find a decision boundary that sepa-rates positive and negative instances with manu-ally engineered features, these features can hardlycapture the notion of context as well as those ex-plored by a tree kernel.Tree Kernels are a family of kernel functionsdeveloped to compute the similarity between treestructures by counting the number of subtreesthey have in common.
This generates a high-dimensional feature space that can be handled ef-ficiently using dynamic programming techniques(Shawe-Taylor and Christianini, 2004).
For ourpurposes we used an implementation of the Sub-tree and Subset Tree (SST) (Moschitti, 2006).The advantages of using tree kernels aretwo-fold: thanks to an existing implementation(SVMlight with tree kernels, Moschitti (2004)), itis faster and easier than traditional feature engi-neering.
The tree structure also allows us to usedifferent levels of representations (POS, lemma,etc.)
and combine their contributions, while at thesame time taking into account the ordering of la-bels.
We use POS, lemma, semantic type, and arepresentation that replaces each word with a con-catenation of its features (capitalization, count-able, abstract/concrete noun, etc.
).We developed a shallow tree representation thatcaptures the context of the target terms, withoutencoding too much structure (which may preventgeneralization).
In essence, our tree structure in-duces behavior somewhat similar to a string ker-nel.
In addition, we can model the tasks by pro-viding specific markup on the generated tree.
Forexample, in our experiment we used the labelsEVENT (or equivalently RELATION) and TIME-STAMP to mark our target terms.
In order to re-duce the complexity of this comparison, we focuson the substring between event/relation and timestamp and the rest of the tree structure is trun-cated.Figure 1 illustrates an example of the structuredescribed so far for both lemmas and POS tags(note that the lowest level of the tree contains tok-enized items, so their number can differ form theactual words, as in ?attorney general?).
Similartrees are produced for each level of representa-tions used, and for each instance (i.e., pair of timeexpressions and event/relation).
If a sentence con-tains more than one event/relation, we create sep-arate trees for each of them, which differ in the po-sition of the EVENT/RELATION marks (at level1 of the tree).The tree kernel implicitly expands this struc-ture into a number of substructures allowing usto capture sequential patterns in the data.
As wewill see, this step provides significant boosts tothe task performance.Curiously, using a full-parse syntactic tree asinput representation did not help performance.This is in line with our finding that syntactic re-lations are less important than sequential patterns(see also Section 5.2).
Therefore we adopted the?string kernel like?
representation illustrated inFigure 1.188Scores of supporters of detained Egyptian opposition leader Nur demonstrated outside the attorney general?soffice in Cairo last Saturday, demanding he be freed immediately.BOWTIMETOKsaturdayTOKlastTERMTOKcairoTERMTOKinTERMTOKofficeTERMTOKattorney generalTERMTOKoutsideEVENTTOKdemonstrateBOPTIMETOKNNPTOKJJTERMTOKNNPTERMTOKINTERMTOKNNTERMTOKNNPTERMTOKADVEVENTTOKVBDFigure 1: Input Sentence and Tree Kernel Representations for Bag of Words (BOW) and POS tags (BOP)5 EvaluationWe now apply our models to real world data, andempirically demonstrate their effectiveness at thetask of temporal linking.
In this section, we de-scribe the data sets that were used for evaluation,the baselines for comparison, parameter settings,and the results of the experiments.5.1 BenchmarkWe evaluated our approach in 3 different tasks:1.
Linking Timestamps and Events in the ICdomain2.
Linking Timestamps and Relations in the ICdomain3.
Linking Events to Temporal Expressions(TempEval-2, task C)The first two data sets contained annotationsin the intelligence community (IC) domain, i.e.,mainly news reports about terrorism.
It com-prised 169 documents.
This dataset has been de-veloped in the context of the machine reading pro-gram (MRP) (Strassel et al 2010).
In both casesour goal is to develop a binary classifier to judgewhether the event (or relation) overlaps with thetime interval denoted by the timestamp.
Successof this classification can be measured by precisionand recall on annotated data.We originally considered using accuracy as ameasure of performance, but this does not cor-rectly reflect the true performance of the system:given the skewed nature of the data (much smallernumber of positive examples), we could achieve ahigh accuracy simply by classifying all instancesas negative, i.e., not assigning a time stamp at all.We thus decided to report precision, recall and F1.Unless stated otherwise, results were achieved via10-fold cross-validation (10-CV).The number of instances (i.e., pairs of eventand temporal expression) for each of the differ-ent cases listed above was (in brackets the ratio ofpositive to negative instances).?
events: 2046 (505 positive, 1541 negative)?
relations: 6526 (1847 positive, 4679 nega-tive)The size of the relation data set after filtering is5511 (1847 positive, 3395 negative).In order to increase the originally lower numberof event instances, we made use of the annotatedevent-coreference as a sort of closure to add moreinstances: if events A and B corefer, and thereis a link between A and time expression t, thenthere is also a link between B and t. This was notexplicitly expressed in the data.For the task at hand, we used gold standardannotations for timestamps, events and relations.The task was thus not the identification of theseobjects (a necessary precursor and a difficult taskin itself), but the decision as to which events andtime expressions could and should be linked.We also evaluated our system on TempEval-2 (Verhagen et al 2010) for better comparison189to the state-of-the-art.
TempEval-2 data includedthe task of linking events to temporal expressions(there called ?task C?
), using several link types(OVERLAP, BEFORE, AFTER, BEFORE-OR-OVERLAP, OVERLAP-OR-AFTER).
This is abit different from our settings as it required theimplementation of a multi-class classifier.
There-fore we trained three different binary classifiers(using the same feature set) for the first three ofthose types (for which there was sufficient train-ing data) and we used a one-versus-all strategy todistinguish positive from negative examples.
Theoutput of the system is the category with the high-est SVM decision score.
Since we only use threelabels, we incur an error every time the gold la-bel is something else.
Note that this is stricterthan the evaluation in the actual task, which leftcontestants with the option of skipping examplestheir systems could not classify.5.2 BaselinesIntuitively, one would expect temporal expres-sions to be close to the event they denote, or evensyntactically related.
In order to test this, we ap-plied two baselines.
In the first, each temporal ex-pression was linked to the closest event (as mea-sured in token distance).
In the second, we at-tached each temporal expression to its syntactichead, if the head was an event.
Results are re-ported in Figure 2.While these results are encouraging for ourtask, it seems at first counter-intuitive that thesyntactic baseline does worse than the proximity-based one.
It does, however, reveal two facts:events are not always synonymous with syntacticunits, and they are not always bound to tempo-ral expressions through direct syntactic links.
Thelatter makes even more sense given that the linkscan even occur across sentence boundaries.
Pars-ing quality could play a role, yet seems far fetchedto account for the difference.More important than syntactic relations seemto be sequential patterns on different levels, a factwe exploit with the different tree representationsused (POS tags, NE types, etc.
).For relations, we only applied the closest-relation baseline.
Since relations consist of two ormore arguments that occur in different, often sep-arated syntactic constituents, a syntactic approachseems futile, especially given our experience withevents.
Results are reported in Figure 3.baseline comparisonPage 1Precision Recall F102040608010035.063.045.048.088.062.063.075.4 68.376.6 76.5 76.2Evaluation Measures EventsBL-parent BL-closest features +tree kernelmetric%Figure 2: Performance on eventsSystem AccuracyTRIOS 65%this work 64.5%JU-CSE, NCSU-indiTRIPS, USFD2all 63%Table 1: Comparison to Best Systems in TempEval-25.3 EventsFigure 2 shows the improvements of the feature-based approach over the two baseline, and the ad-ditional gain obtained by using the tree kernel.Both the features and tree kernels mainly improveprecision, while the tree kernel adds a small boostin recall.
It is remarkable, though, that the closest-event baseline has a very high recall value.
Thissuggests that most of the links actually do occurbetween items that are close to one another.
For apossible explanation for the low precision value,see the error analysis (Section 5.5).Using a two-tailed t-test, we compute the sig-nificance in the difference between the F1-scores.Both the feature-based and the tree kernel ap-proach improvements are statistically significantat p < 0.001 over the baseline scores.Table 1 compares the performances of our sys-tem to the state-of-the-art systems on TempEval-2Data, task C, showing that our approach is verycompetitive.
The best systems there used sequen-tial models.
We attribute the competitive natureof our results to the use of tree kernels, which en-ables us to make use of contextual information.5.4 RelationsIn general, performance for relations is not as highas for events (see Figure 3).
The reason here istwo-fold: relations consist of two (or more) ele-ments, which can be in various positions with re-spect to one another and the temporal expression,and each relation can be expressed in a number of190baseline comparisonPage 1Precision Recall F1010203040506070809010035.024.0 29.063.180.670.470.8 74.0 72.2Evaluation Metric RelationsBL-closest features +tree kernelmetric%Figure 3: Performance on relations/fluentslearning curvesPage 10 10 20 30 40 50 60 70 80 90 100404550556065707580Learning Curves Relationsfeatures w/ treekernel% of dataF1scoreFigure 4: Learning curves for relation modelsdifferent ways.Again, we perform significance tests on the dif-ference in F1 scores and find that our improve-ments over the baseline are statistically significantat p < 0.001.
The improvement of the tree kernelover the feature-based approach, however, are notstatistically significant at the same value.The learning curve over parts of the trainingdata (exemplary shown here for relations, Figure4)2 indicates that there is another advantage to us-ing tree kernels: the approach can benefit frommore data.
This is conceivably because it allowsthe kernel to find more common subtrees in thevarious representations the more examples it gets,while the feature space rather finds more instancesthat invalidate the expressiveness of features (i.e.,it encounters positive and negative instances thathave very similar feature vectors).
The curve sug-gests that tree kernels could yield even better re-sults with more data, while there is little to no ex-pected gain using only features.5.5 Error AnalysisExamining the misclassified examples in our data,we find that both feature-based and tree-kernelapproaches struggle to correctly classify exam-2The learning curve for events looks similar and is omit-ted due to space constraints.ples where time expression and event/relation areimmediately adjacent, but unrelated, as in ?theman arrested last Tuesday told the police ...?,where last Tuesday modifies arrested.
It limitsthe amount of context that is available to the treekernels, since we truncate the tree representationsto the words between those two elements.
Thiscase closely resembles the problem we see in theclosest-event/relation baseline, which, as we haveseen, does not perform too well.
In this case, theincorrect event (?told?)
is as close to the time ex-pression as the correct one (?arrested?
), resultingin a false positive that affects precision.
Featurescapturing the order of the elements do not seemhelp here, since the elements can be arranged inany order (i.e., temporal expression before or af-ter the event/relation).
The only way to solve thisproblem would be to include additional informa-tion about whether a time expression is alreadyattached to another event/relation.5.6 AblationsTo quantify the utility of each tree representation,we also performed all-but-one ablation tests, i.e.,left out each of the tree representations in turn, ran10-fold cross-validation on the data and observedthe effect on F1.
The larger the loss in F1, themore informative the left-out-representation.
Weperformed ablations for both events and relations,and found that the ranking of the representationsis the same for both.In events and relations alike, leaving out POStrees has the greatest effect on F1, followed bythe feature-bundle representation.
Lemma and se-mantic type representation have less of an impact.We hypothesize that the former two capture un-derlying regularities better by representing differ-ent words with the same label.
Lemmas in turnare too numerous to form many recurring pat-terns, and semantic type, while having a smallerlabel alphabet, does not assign a label to everyword, thus creating a very sparse representationthat picks up more noise than signal.In preliminary tests, we also used annotateddependency trees as input to the tree kernel, butfound that performance improved when they wereleft out.
This is at odds with work that clearlyshowed the value of syntactic tree kernels (Mir-roshandel et al 2011).
We identify two poten-tial causes?either our setup was not capable ofcorrectly capturing and exploiting the information191from the dependency trees, or our formulation ofthe task was not amenable to it.
We did not inves-tigate this further, but leave it to future work.6 Conclusion and Future WorkWe cast the problem of linking events and rela-tions to temporal expressions as a classificationtask using a combination of features and tree ker-nels, with probabilistic type filtering.
Our maincontributions are:?
We showed that within-sentence temporallinks for both events and relations can be ap-proached with a common strategy.?
We developed flat tree representations andshowed that these produce considerablegains, with significant improvements overdifferent baselines.?
We applied our technique without great ad-justments to an existing data set and achievedcompetitive results.?
Our best systems achieve F1 score of 0.76on events and 0.72 on relations, and are ef-fective at the task of temporal linking.We developed the models as part of a machinereading system and are currently evaluating it inan end-to-end task.Following tasks proposed in TempEval-2, weplan to use our approach for across-sentence clas-sification, as well as a similar model for linkingentities to the document creation date.AcknowledgementsWe would like to thank Alessandro Moschitti forhis help with the tree kernel setup, and the review-ers who supplied us with very constructive feed-back.
Research supported in part by Air ForceContract FA8750-09-C-0172 under the DARPAMachine Reading Program.ReferencesKen Barker, Bhalchandra Agashe, Shaw-Yi Chaw,James Fan, Noah Friedland, Michael Glass, JerryHobbs, Eduard Hovy, David Israel, Doo Soon Kim,Rutu Mulkar-Mehta, Sourabh Patwardhan, BrucePorter, Dan Tecuci, and Peter Yeh.
2007.
Learn-ing by reading: A prototype system, performancebaseline and lessons learned.
In Proceedings ofthe 22nd National Conference for Artificial Intelli-gence, Vancouver, Canada, July.Branimir Boguraev and Rie Kubota Ando.
2005.Timeml-compliant text analysis for temporal rea-soning.
In Proceedings of IJCAI, volume 5, pages997?1003.
IJCAI.Nathanael Chambers and Dan Jurafsky.
2008.
Unsu-pervised learning of narrative event chains.
pages789?797.
Association for Computational Linguis-tics.Peter Clark and Phil Harrison.
2010.
Machine read-ing as a process of partial question-answering.
InProceedings of the NAACL HLT Workshop on For-malisms and Methodology for Learning by Reading,Los Angeles, CA, June.George Doddington, Alexis Mitchell, Mark Przybocki,Lance Ramshaw, Stephanie Strassel, and RalphWeischedel.
2004.
The automatic content extrac-tion program ?
tasks, data and evaluation.
In Pro-ceedings of the LREC Conference, Canary Islands,Spain, July.Oren Etzioni, Michele Banko, and Michael Cafarella.2007.
Machine reading.
In Proceedings of theAAAI Spring Symposium Series, Stanford, CA,March.Elena Filatova and Eduard Hovy.
2001.
Assigningtime-stamps to event-clauses.
In Proceedings ofthe workshop on Temporal and spatial informationprocessing, volume 13, pages 1?8.
Association forComputational Linguistics.Claudio Giuliano, Alfio Massimiliano Gliozzo, andCarlo Strapparava.
2009.
Kernel methods for min-imally supervised wsd.
Computational Linguistics,35(4).Seyed A. Mirroshandel, Mahdy Khayyamian, andGholamreza Ghassem-Sani.
2011.
Syntactic treekernels for event-time temporal relation learning.Human Language Technology.
Challenges for Com-puter Science and Linguistics, pages 213?223.Alessandro Moschitti.
2004.
A study on convolutionkernels for shallow semantic parsing.
In Proceed-ings of the 42nd Annual Meeting on Association forComputational Linguistics, pages 335?es.
Associa-tion for Computational Linguistics.Alessandro Moschitti.
2006.
Making tree kernelspractical for natural language learning.
In Proceed-ings of EACL, volume 6.Feng Pan, Rutu Mulkar, and Jerry R. Hobbs.
2006.Learning event durations from event descriptions.In Proceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, pages 393?400.
Association for Computa-tional Linguistics.James Pustejovsky, Patrick Hanks, Roser Saur?, An-drew See, Robert Gaizauskas, Andrea Setzer,Dragomir Radev, Beth Sundheim, David Day, Lisa192Ferro, and Marcia Lazo.
2003.
The TIMEBANKCorpus.
In Proceedings of Corpus Linguistics2003, pages 647?656.John Shawe-Taylor and Nello Christianini.
2004.
Ker-nel Methods for Pattern Analysis.
Cambridge Uni-versity Press.Stephanie Strassel, Dan Adams, Henry Goldberg,Jonathan Herr, Ron Keesing, Daniel Oblinger,Heather Simpson, Robert Schrag, and JonathanWright.
2010.
The DARPA Machine Read-ing Program-Encouraging Linguistic and Reason-ing Research with a Series of Reading Tasks.
InProceedings of LREC 2010.Vladimir Vapnik.
1995.
The Nature of StatisticalLearning Theory.
Springer, New York, NY.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Graham Katz, and James Puste-jovsky.
2007.
Semeval-2007 task 15: Tempevaltemporal relation identification.
In Proceedings ofthe 4th International Workshop on Semantic Evalu-ations, pages 75?80.
Association for ComputationalLinguistics.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 task 13:Tempeval-2.
In Proceedings of the 5th Interna-tional Workshop on Semantic Evaluation, pages 57?62.
Association for Computational Linguistics.193
