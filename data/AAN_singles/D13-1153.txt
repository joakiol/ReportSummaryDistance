Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1465?1475,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsSemi-Supervised Representation Learning forCross-Lingual Text ClassificationMin Xiao and Yuhong GuoDepartment of Computer and Information SciencesTemple UniversityPhiladelphia, PA 19122, USA{minxiao,yuhong}@temple.eduAbstractCross-lingual adaptation aims to learn a pre-diction model in a label-scarce target lan-guage by exploiting labeled data from a label-rich source language.
An effective cross-lingual adaptation system can substantially re-duce the manual annotation effort required inmany natural language processing tasks.
Inthis paper, we propose a new cross-lingualadaptation approach for document classifica-tion based on learning cross-lingual discrim-inative distributed representations of words.Specifically, we propose to maximize the log-likelihood of the documents from both lan-guage domains under a cross-lingual log-bilinear document model, while minimizingthe prediction log-losses of labeled docu-ments.
We conduct extensive experiments oncross-lingual sentiment classification tasks ofAmazon product reviews.
Our experimentalresults demonstrate the efficacy of the pro-posed cross-lingual adaptation approach.1 IntroductionWith the rapid development of linguistic resourcesin different languages, developing cross-lingual nat-ural language processing (NLP) systems becomesincreasingly important (Bel et al 2003; Shanahanet al 2004).
Recently, cross-lingual adaptationmethods have been studied to exploit labeled infor-mation from an existing source language domainwhere labeled training data is abundant for use ina target language domain where annotated trainingdata is scarce (Prettenhofer and Stein, 2010).
Pre-vious work has shown that cross-lingual adaptationcan greatly reduce labeling effort for a variety ofcross language NLP tasks such as document catego-rization (Bel et al 2003; Amini et al 2009), genreclassification (Petrenz and Webber, 2012), and sen-timent classification (Shanahan et al 2004; Wei andPal, 2010; Prettenhofer and Stein, 2010).The fundamental challenge of cross-lingual adap-tation stems from a lack of overlap between the fea-ture space of the source language data and that ofthe target language data.
To address this challenge,previous work in the literature mainly relies on au-tomatic machine translation tools.
They first trans-late all the text data from one language domain intothe other and then apply techniques such as domainadaptation (Wan et al 2011; Rigutini and Maggini,2005; Ling et al 2008) and multi-view learning(Amini et al 2009; Guo and Xiao, 2012b; Wan,2009) to achieve cross-lingual adaptation.
However,machine translation tools may not be freely availablefor all languages.
Moreover, translating all the textdata in one language into the other language is tootime-consuming in reality.
As an economic alter-native solution, cross-lingual representation learn-ing has recently been used in the literature to learnlanguage-independent representations of the data forcross language text classification (Prettenhofer andStein, 2010; Petrenz and Webber, 2012).In this paper, we propose to tackle cross languagetext classification by inducing cross-lingual predic-tive data representations with both labeled and un-labeled documents from the two language domains.Specifically, we propose a cross-lingual log-bilineardocument model to learn distributed representationsof words, which can capture both the semantic sim-1465ilarities of words across languages and the predic-tive information with respect to the target classifi-cation task.
We conduct the representation learn-ing by maximizing the log-likelihood of all docu-ments from both language domains under the cross-lingual log-bilinear document model and minimiz-ing the prediction log-losses of labeled documents.We formulate the learning problem as a joint non-convex minimization problem and solve it using alocal optimization algorithm.
To evaluate the effec-tiveness of the proposed approach, we conduct ex-periments on the task of cross language sentimentclassification of Amazon product reviews.
The em-pirical results show the proposed approach is veryeffective for cross-lingual document classification,and outperforms other comparison methods.2 Related WorkMuch work in the literature proposes to constructcross-lingual representations by using aligned paral-lel data.
Basically, they first employ machine trans-lation tools to translate documents from one lan-guage domain to the other one and then induce lowdimensional latent representations as interlingualrepresentations (Littman et al 1998; Vinokourovet al 2002; Platt et al 2010; Pan et al 2011; Guoand Xiao, 2012a).
Littman et al(1998) proposeda cross-language latent semantic indexing methodto induce interlingual representations by perform-ing latent semantic indexing over a dual-languagedocument-term matrix, where each dual-languagedocument contains its original words and the corre-sponding translation text.
Vinokourov et al(2002)proposed a cross-lingual kernel canonical corre-lation analysis method, which learns two projec-tions (one for each language) by conducting kernelcanonical correlation analysis over a paired bilin-gual corpus and then uses the two projections toproject documents from language-specific featurespaces to the shared multilingual semantic featurespace.
Platt et al(2010) employed oriented prin-cipal component analysis (Diamantaras and Kung,1996) over concatenated parallel documents, whichlearns a multilingual projection by simultaneouslyminimizing the projected distance between paral-lel documents and maximizing the projected covari-ance of documents across different languages.
Panet al(2011) proposed a bi-view non-negative matrixtri-factorization method for cross-lingual sentimentclassification on the parallel training and test data.Guo and Xiao (2012a) developed a transductivesubspace representation learning method for cross-lingual text classification based on non-negative ma-trix factorization.
Some other works exploited par-allel data by using multilingual topic models to ex-tract cross-language latent topics as interlingual rep-resentations (Mimno et al 2009; Ni et al 2011;Platt et al 2010; Smet et al 2011) and using neu-ral probabilistic language modes to learn word em-beddings as cross-lingual distributed representations(Klementiev et al 2012).
Most of them were de-veloped by applying the latent Dirichlet alcation(LDA) model (Blei et al 2003) in a multilingual set-ting, including the polylingual topic model (Mimnoet al 2009), the bilingual LDA model (Smet et al2011), and the multilingual LDA model (Ni et al2011).
Platt et al(2010) extended the probabilis-tic latent semantic analysis (PLSA) model (Hof-mann, 1999) and presented two variants of multilin-gual topic models: the joint PLSA model and thecoupled PLSA model.
Recently, Klementiev et al(2012) extended the neural probabilistic languagemodel (Bengio et al 2000) to induce cross-lingualword distributed representations on a set of word-level aligned parallel sentences.
The applicabilityof these approaches however is limited by the avail-ability of parallel corpus.
Translating the whole setof documents to produce parallel corpus is too time-consuming, expensive and even practically impossi-ble for some language pairs.
We thus do not evaluatethose approaches in our empirical study.Another group of works propose to use bilin-gual dictionaries to learn interlingual representa-tions (Gliozzo, 2006; Prettenhofer and Stein, 2010).Gliozzo (2006) first translated each term from onelanguage to the other using a bilingual dictionaryand used the translated terms to augment origi-nal documents.
Then they conducted latent se-mantic analysis (LSA) over the document-term ma-trix with concatenated vocabularies to obtain in-terlingual representations.
Prettenhofer and Stein(2010) proposed a cross-language structural cor-respondence learning (CL-SCL) method to inducelanguage-independent features by using word trans-lation oracles.
They first selected a subset of source1466language features, which have the highest mutual in-formation with respect to the class labels in the la-beled documents from the source language domain,to translate them into the target language domain,and then used these pivot pairs to induce cross-lingual representations by modeling the correlationsbetween pivot features and non-pivot features.
Ourproposed approach shares a similarity with the CL-SCL method in (Prettenhofer and Stein, 2010) ononly requiring a small amount of word translations.But our approach performs representation learningin a semi-supervised manner by directly incorporat-ing discriminative information with respect to thetarget prediction task, while CL-SCL only exploitslabels when selecting pivot features and the struc-tural correspondence learning process is conductedin a fully unsupervised fashion.Some other bilingual resources, such as multilin-gual WordNet (Fellbaum, 1998) and universal part-of-speech (POS) tags (Petrov et al 2012), have alsobeen exploited in the literature for interlingual learn-ing.
Gliozzo (2006) proposed to use MultiWordNetto map words from different languages to a commonsynset-id as language-sharing terms.
A similar workwas proposed in A.R.
et al(2012), which trans-formed words from different languages to WordNetsynset identifiers as interlingual sense-based rep-resentations.
However, multilingual WordNet re-sources are not always available for different lan-guage pairs.
Recently, Petrenz and Webber (2012)used language-specific POS taggers to tag each wordand then mapped those language-specific POS tagsto twelve universal POS tags as interlingual featuresfor cross language fine-grained genre classification.This approach requires a POS tagger for each lan-guage and it may be adversely affected by the POStagging accuracy.3 Semi-Supervised RepresentationLearning for Cross-Lingual TextClassificationIn this section, we introduce a semi-supervisedcross-lingual representation learning method andthen use it for cross language text classification.Assume we have ?s labeled and us unlabeled doc-uments in the source language domain S and ?t la-beled and ut unlabeled documents in the target lan-guage domain T .
We assume all the documents areindependent and identically distributed in each lan-guage domain, and each document xi is representedas a bag of words, xi = {wi1, wi2, .
.
.
, wiNi}.
Weuse (x?i , yi) to denote the i-th labeled document andits label, and consider exploiting the labeled docu-ments in the source domain S for learning classifiersin the target domain T .To build connections between the two languagedomains, we first construct a set of critical bilingualword pairs M = {(wsi , wtj)}mi=1, where wsi is a crit-ical word in the source language domain, wtj is itstranslation in the target language domain, and m isthe number of word pairs.
Here being critical meansthe word should be discriminative for the predictiontask and occur frequently in both language domains.Following the work (Prettenhofer and Stein, 2010),we select bilingual word pairs in a heuristic way.First we select a subset of words from the source lan-guage domain, which have the highest mutual infor-mation with the class labels in labeled source docu-ments.
The mutual information is computed basedon the empirical distributions of words and labelsin the labeled source documents.
Then we translatethe selected words into the target language using atranslation tool to produce word pairs.
Finally weproduce the M set by eliminating any candidate pair(ws, wt), if either ws occurs less than a predefinedthreshold value ?
in all source language documentsor wt occurs less than ?
in all target language docu-ments.
Given the constructed bilingual word pair setM , the words appearing in the source language doc-uments but not in M can be put together to form asource specific vocabulary set Vs = {ws1, .
.
.
, wsvs}.Similarly, the words appearing in the target languagedocuments but not in M can be put together to forma target specific vocabulary set Vt = {wt1, .
.
.
, wtvt}.An overall cross-lingual vocabulary set can then beconstructed as V = Vs ?
Vt ?
M , which has a totalof v = vs + vt + m entries.
This cross-lingual vo-cabulary set covers all words appearing in both do-mains, while mapping each bilingual pair in M intothe same entry.To tackle cross language text classification, wethen propose a cross-lingual log-bilinear documentmodel to learn a predictive cross-lingual represen-tation of words, which maps each entry in the vo-cabulary set V to one row vector in a word embed-1467ding matrix R ?
Rv?k.
Similar to the log-bilinearlanguage model (Mnih and Hinton, 2007) and thelog-bilinear document model (Maas et al 2011),our proposed model learns a dense feature vector foreach word to capture semantic similarities betweenthe vocabulary entries.
But unlike the previous twomodels which only work with a monolingual lan-guage, our model also captures semantic similaritiesacross different languages.
Moreover, we explicitlyincorporate the label information into our proposedapproach, rendering the induced word embeddingsmore discriminative to the target prediction task.3.1 Cross-Lingual Word EmbeddingsAs mentioned above, we assume a unified embed-ding matrix R which contains the distributed vec-tor representations of words in the two languagedomains.
However, even in a unified representa-tion space, the distribution of words in the two do-mains will be different.
To capture the distributiondivergence of the two domains and facilitate cross-lingual learning, we split the word embedding ma-trix into three parts: source language specific partRs ?
Rv?ks , common part Rc ?
Rv?kc and tar-get language specific part Rt ?
Rv?kt , such thatk = ks + kc + kt.
Intuitively, we assume that sourcelanguage words contain no target language specificrepresentations and target language words containno source language specific representations.
Thusfor words in the two language domains, we retrievetheir distributed vector representations from the em-bedding matrix R using two mapping functions, ?Sand ?T , one for each language domain.
The twomapping functions are defined as?S(w) =[Rs(w), Rc(w),0t]T (1)?T (w) =[0s, Rc(w), Rt(w)]T (2)where 0t is a kt-dimensional row vector of zeros,0s is a ks-dimensional row vector of zeros, Rs(w)denotes the row vector of Rs matrix correspondingto the word w, Rc(w) denotes the row vector of Rcmatrix corresponding to the word w, and Rt(w) de-notes the row vector of Rt matrix corresponding tothe word w. It is easy to see that each pair of wordsin M will share the same vector from Rc.
To encodemore information into the common part of represen-tation for better knowledge transfer from the sourcelanguage domain to the target language domain, weassume kc ?
ks and kc ?
kt.
The form of three partfeature representations has been exploited in previ-ous work of domain adaptation with heterogeneousfeature spaces (Duan et al 2012).
However, theirapproach simply duplicates the original features aslanguage-specific representations, while we will au-tomatically learn those three part latent representa-tions in our approach.3.2 Semi-Supervised Cross-LingualRepresentation LearningGiven the word representation scheme above, weconduct cross-lingual representation learning by si-multaneously maximizing the log-likelihood of alldocuments and the conditional likelihood of labeleddocuments from the two language domainsmax??L?
{S,T }?xi?LNi?j=1logPL(wij |?)+??L?
{S,T }?x?i?LlogPL(yi|x?i , ?)
(3)where ?
denotes the model parameters and ?
is atrade-off parameter.
The first part of the objectivefunction captures the likelihood of the documentsbeing generated with the learned representation R.PL(wij |?)
is the probability of word wij appearingin the document xi from the language domain L, andis defined asPL(wij |?)
=exp (?EL(wij , ?))?w?
?V exp (?EL(w?, ?
))(4)The term EL(wij , ?)
is a log-bilinear energy func-tion, defined asEL(wij , ?)
= ?dTi ?L(wij) ?
bwij (5)where di is a k-dimensional weight vector for docu-ment xi and bwij is the bias for word wij .
Below wewill use b to denote a v-dimensional vector contain-ing all words?
biases.The second part of the objective function in (3)takes the label information into account and aimsto render the latent word representations more task-predictive.
We use a logistic regression model to1468compute the conditional probability of the class la-bel given the document with the induced word rep-resentations, such thatPL(yi|x?i , ?)
=11 + exp(?yi(wT?L(x?i) + q))(6)where w, q are model parameters of the logistic re-gression model, ?L(xi) is the k-dimensional vectorrepresentation of the document xi in the languagedomain L. We compute ?L(xi) by taking averageover all words in the document xi such as?L(xi) =1NiNi?j=1?L(wij) (7)By summing over all descriptions above, we cansee that the proposed semi-supervised representa-tion learning has a set of model parameters, ?
={R, {di},b,w, q}.
In order to avoid overfitting, weadd regularization terms for the parameters R, {di}and w, which leads to the final optimization problembelowmax??L?
{S,T }?xi?L(Ni?j=1logPL(wij |?)
?
?
?di?22)+ ??L?
{S,T }?x?i?LlogPL(yi|x?i , ?)?
?
?R?2F ?
?
?w?22 (8)where ?, ?, ?
are trade-off parameters, ?
?
?F denotethe Frobenius norm and ?
?
?2 denote the Euclidean-norm.
This objective function is not jointly convexin all model parameters.
We develop a gradient-based iterative optimization procedure to seek a lo-cal optimal solution.
We first randomly initialize themodel parameters {di}, R,w and set b and q to ze-ros.
Then we iteratively make gradient-based up-dates over the model parameters until reach a localoptimal solution.3.3 Cross-Lingual Document ClassificationAfter solving (8), we obtain a word embedding ma-trix R. The distributed vector representation of anygiven document can then be computed using Eq.
(7)based on Eq.
(1) or Eq.
(2).
Under the distributedvector representations of the documents in both lan-guage domains, we perform cross-lingual documentclassification by training a supervised classificationmodel using labeled data from both language do-mains and then applying it to classify test documentsin the target language domain .4 ExperimentsWe empirically evaluate the proposed approach us-ing the cross language sentiment classification tasksof Amazon product reviews in four languages.
Inthis section, we report our experimental results.4.1 DatasetWe used the multilingual sentiment classificationdataset1 provided by Prettenhofer and Stein (2010),which contains Amazon product reviews in four dif-ferent languages, English (E), French (F), German(G) and Japanese (J).
The English product reviewswere sampled from previous cross-domain senti-ment classification datasets (Blitzer et al 2007),while the other three language product reviews werecrawled from Amazon by the authors in November2009.
In the dataset, each language contains threecategories of product reviews, Books (B), DVD (D)and Music (M).
Each language-category pair con-tains a balanced training set and test set, each ofwhich consists of 1000 positive reviews and 1000negative reviews.
Each review is represented asa unigram bag-of-word feature vector with term-frequency values.
Following the work (Prettenhoferand Stein, 2010), we used the original English re-views as the source language while treating the otherthree languages as target languages.
Thus, we con-struct nine cross language sentiment classificationtasks (GB, GD, GM, FB, FD, FM, JB, JD, JM), onefor each target language-category pair.
For example,the task GB means that the target language is Ger-man and the training and test data are samples fromBooks reviews.4.2 ApproachesWe compare our proposed semi-supervised cross-lingual representation learning (CL-RL) approachto the following approaches for cross-lingual doc-ument classification.1http://www.webis.de/research/corpora/1469Table 1: Average classification accuracies and standard deviations for the 9 cross-lingual sentiment classification tasks.The bold format indicates that the difference between the results of CL-RL and MT is significant with p < 0.05 undera McNemar paired test for labeling disagreements.Task TB CL-Dict CLD-LSA CL-SCL MT CL-RLGB 66.25?0.64 69.40?0.61 70.30?0.44 73.78?0.32 78.05?0.64 79.89?0.30GD 63.16?0.66 66.37?0.63 66.85?0.46 71.99?0.25 75.75?0.58 77.14?0.16GM 65.42?0.77 68.81?0.51 68.93?0.58 71.58?0.35 74.85?0.62 77.27?0.16FB 65.98?0.51 69.35?0.48 69.98?0.51 73.89?0.16 78.00?0.49 78.25?0.32FD 63.76?0.37 67.96?0.60 68.88?0.43 73.79?0.28 75.75?0.71 74.83?0.30FM 65.94?0.56 67.98?0.69 68.42?0.60 71.20?0.28 74.85?0.49 78.71?0.32JB 63.86?0.80 59.40?0.29 62.62?0.62 62.49?0.23 67.20?0.80 71.11?0.21JD 63.59?0.74 62.13?0.26 63.87?0.72 65.54?0.29 67.70?0.57 73.12?0.23JM 65.84?0.90 63.01?0.46 65.67?0.72 65.49?0.36 68.30?0.61 74.38?0.40?
TB: This is a target baseline method, whichtrains a supervised monolingual classifier onthe labeled training data from the target lan-guage domain without representation learning.?
CL-Dict: This is a simple baseline compar-ison method, which uses the bilingual wordpairs directly to align features from differentlanguage domains into a unified feature dictio-nary and then trains a supervised classifier onthis aligned feature space with labeled trainingdata from both language domains.?
CLD-LSA: This is the cross-lingual represen-tation learning method developed in (Gliozzo,2006), which first translates each documentfrom one language into the other language viaa bilingual dictionary to produce augmentingfeatures, and then performs latent semanticanalysis (LSA) over the augmented bilingualdocument-term matrix.?
CL-SCL: This is the cross language structuralcorrespondence learning method developed in(Prettenhofer and Stein, 2010).?
MT: This is a machine translation based com-parison method, which first uses an existingmachine translation tool (google translation) totranslate the target language documents into thesource language and then trains a monolingualclassifier with labeled training data from bothdomains in the source language.In all experiments, we used a linear support vec-tor machine (SVM) for sentiment classification.
Forimplementation, we used the liblinear package (Fanet al 2008) with all of its default parameters.
Forthe CL-SCL method, we used the same parame-ter setting as suggested in the paper (Prettenhoferand Stein, 2010): the number of pivot features isset as 450, the threshold value for selecting pivotfeatures is 30, and the reduced dimensionality af-ter singular value decomposition is 100.
For theCLD-LSA method, we set the dimensionality of la-tent representation as 1000.
Similarly, for our pro-posed approach, we built the cross-lingual vocabu-lary M by setting m = 450 and ?
= 30.
Forour representation learning, we set ?
= 1, ?
=?
= ?
= 1e?4, and set ks, kc, kt to be 25, 50,25, respectively.
The values of ?, ?, ?
and ?
areselected using the first cross language classifica-tion task GB.
We selected the ?
value from theset {0.01, 0.1, 1, 10, 100} and selected ?, ?, ?
valuesfrom the set {1e?5, 1e?4, 1e?3, 1e?2, 1e?5} by re-peating the experiment three times with random datapartitions and choosing the parameter values that ledto the best average classification accuracy.4.3 Classification AccuracyFor each of the nine cross language sentiment classi-fication tasks with different target language-categorypairs, we used the training set in the source languagedomain (English) as labeled data while treating thetest set in the source language domain as unlabeled.1470100 200 300 400 50065707580GB#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 50060657075GD#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 500657075GM#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 50065707580FB#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 5006065707580FD#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 50065707580FM#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 5005560657075JB#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 50060657075JD#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RL100 200 300 400 50060657075JM#Labeled target instancesAccuracyTBCL?DictCLD?LSACL?SCLMTCL?RLFigure 1: Average classification accuracies and standard deviations for 10 runs with respect to different numbers oflabeled training documents in the target language domain.For target language domain, we used the test set astest data while randomly selecting 100 documentsfrom the training set as labeled data and treating therest as unlabeled data.
Thus, for each task, we have2000 labeled documents and 2000 unlabeled docu-ments from the source language domain, and 100labeled and 1900 unlabeled documents from the tar-get language domain for training.
We have 2000 testdocuments from the target language domain as test-ing data.
In each experiment, a classifier is producedby each approach with the training data and testedon the testing data.
We repeated each experiment10 times with different random selections of 100 la-beled training documents from the target languagedomain.
The average classification accuracies andstandard deviations are reported in Table 1.From Table 1, we can see that the proposed semi-supervised cross-lingual representation learning ap-proach, CL-RL, clearly outperforms all other com-parison methods on eight out of the nine tasks.
Thetarget baseline TB performs poorly on all the ninetasks, which suggests that 100 labeled instancesfrom the target language is far from enough to ob-tain an accurate sentiment classifier in the target lan-1471100 200 300 40065707580German#DimensionAccuracyBooksDVDMusic100 200 300 40065707580French#DimensionAccuracyBooksDVDMusic100 200 300 4006065707580Japanese#DimensionAccuracyBooksDVDMusicFigure 2: Average classification accuracy and standard deviation results for the proposed approach over 10 runs withrespect to different dimensionality for the induced cross-lingual representations.guage domain.
By exploiting the large amount oflabeled training data from the source language do-main, even the simple cross-lingual adaptation ap-proach, CL-Dict, produces effective improvementsover TB.
However, its performance is not consis-tent across the nine tasks.
It has inferior perfor-mance than TB on the three tasks of adapting En-glish to the Japanese language domain.
This sug-gests the simple bilingual word-pair based featurespace unification method is far from ideal for pro-viding effective cross-lingual representations, espe-cially when two languages (English, Japanese) arevery different.
With a better designed representa-tion learning, CLD-LSA outperforms CL-Dict on allthe nine tasks, but the improvements are very smallon some tasks (e.g., GM).
CL-SCL not only out-performs CL-Dict on all tasks, but also performsmuch better than CLD-LSA on most tasks.
Its per-formance nevertheless is inferior to the method ofMT.
Though MT can greatly increase the test accu-racies comparing to the other four methods, TB, CL-Dict, CLD-LSA, and CL-SCL, the benefit is obtainedat the cost of whole document translations.
In con-trast, our proposed approach does not require wholedocument translations, but relies on the same sim-ple word-pair translations used in CL-Dict.
It how-ever consistently and significantly outperforms TB,CL-Dict, CLD-LSA, and CL-SCL on all tasks, andoutperforms MT on eight out of the nine tasks.We also conduct significance tests for our pro-posed approach and MT using a McNemar pairedtest for labeling disagreements (Gillick and Cox,1989).
The results in bold format indicate that theyare significant with p < 0.05.
All these resultsdemonstrate the efficacy of our cross-lingual repre-sentation learning method.4.4 Classification Accuracy vs the Number ofLabeled Target DocumentsNext, we investigated the performance of the six ap-proaches by varying the number of labeled train-ing documents from the target language domain.We maintained the same experimental setting as be-fore, but investigated a range of different values,?t = {100, 200, 300, 400, 500}, as the number of la-beled training documents from the target languagedomain.
In each experiment, for a given value ?t,we randomly selected ?t documents from the train-ing set of the target language domain as labeled dataand used the rest as unlabeled data.
We still per-formed prediction on the same 2000 test documentsin the target language domain.
We repeated eachexperiment 10 times based on different random se-lections of the labeled training data from the targetlanguage domain.
The average classification accura-cies and standard deviations across different ?t val-ues for all comparison methods on all the nine tasksare plotted in Figure 1.We can see when the number of labeled targetdocuments is small, TB performs poorly, especiallyfor the first six tasks (GB, GD, GM, FB, FD, FM).By increasing the size of labeled target training data,TB can greatly increase its prediction accuracies andeven outperform the CL-Dict method.
The sim-ple CL-Dict method has inconsistent performanceacross the nine tasks.
Its performance is better than1472TB when the labeled training data in the target lan-guage domain is very limited and is poor than TBwhen the labeled target data reaches 300 for the sixtasks using German and French as target languages.Moreover, when adapting a system from English toa much more different target language (Japanese),CL-Dict produces much lower accuracies for all thethree tasks comparing with TB.
These results showthat CL-Dict has very limited capacity on transfer-ring labeled information from a related source lan-guage domain.
Similar performance is observed forCLD-LSA.
With a more sophisticated representationlearning, the CL-SCL method consistently outper-forms CL-Dict.
However, it produces inferior per-formance than CLD-LSA on the tasks of JB and JM.By using more translation resources, the MT methodoutperforms TB, CL-Dict, CLD-LSA, CL-SCL in allthe nine tasks across almost all scenarios.
Our pro-posed method CL-RL significantly outperforms allthe other five comparison methods across all experi-ments except on the task of FD, where MT producessimilar performance.
Moreover, it is especially im-portant to notice that CL-RL achieves high test ac-curacies even when the number of labeled target in-stances is small.
This is important for transferringknowledge from a source language to reduce the la-beling effort in the target language.4.5 Sensitivity AnalysisWe also investigated the sensitivity of the proposedapproach over the dimensionality of the inducedcross-lingual representations.
We used the same ex-perimental setting as before, and conducted experi-ments with a set of different dimensionality values,k = {100, 200, 300, 400}.
For each value k, weset ks = 0.25k, kc = 0.5k, kt = 0.25k.
We re-peated each experiment for 10 times based on dif-ferent random selections of labeled target trainingdata and plotted the average prediction accuraciesand standard deviations in Figure 2 for all the ninecross-lingual sentiment classification tasks.
We cansee the proposed approach produces stable accuracyresults across the range of different k values.
Thissuggests the proposed approach is not very sensitiveto the dimensionality of the cross-lingual embeddingfeatures within the considered range of values, andwith a small dimensionality of 100, the induced rep-resentation can already perform very well.4.6 Cross-Lingual Word RepresentationsFinally, we used the first task GB, which adapts theBooks reviews from English to German, to gain in-tuitive understandings over the learned cross-lingualword representations.
Given an English word asseed word, we find its five closest neighboring En-glish words and German words according to the Eu-clidean distances calculated in the induced cross-lingual representation space.
We present a few re-sults in Table 2.
From Table 2, we can see that the re-trieved words in both language domains are seman-tically close to the seed words, which indicates thatour proposed method can capture semantic similar-ities of words not only in a monolingual setting butalso in a multilingual setting.5 ConclusionIn this paper, we proposed a semi-supervised cross-lingual representation learning approach to addresscross-lingual text classification.
The distributedword representation induced by the proposed ap-proach can capture semantic similarities of wordsacross languages while maintaining predictive infor-mation with respect to the target classification tasks.To evaluate the proposed approach, we conductedexperiments on nine cross language sentiment clas-sification tasks constructed from the Amazon prod-uct reviews in four languages, comparing to a num-ber of comparison methods.
The empirical resultsshowed that the proposed approach can produceeffective cross-lingual adaptation performance andsignificantly outperform other comparison methods.ReferencesM.
Amini, N. Usunier, and C. Goutte.
Learning frommultiple partially observed views - an applicationto multilingual text categorization.
In Advances inNeural Information Processing Systems (NIPS),2009.B.
A.R., A. Joshi, and P. Bhattacharyya.
Cross-lingual sentiment analysis for indian languagesusing linked wordnets.
In Proceedings of theInternational Conference on Computational Lin-guistics (COLING), 2012.N.
Bel, C. Koster, and M. Villegas.
Cross-lingual1473Table 2: Examples of source seed words together with five closest English words and five closest German wordsestimated using the Euclidean distance in the cross-lingual representation space on the task GB.books absolutely loveEnglish German English German English Germanbooks buch absolutely absolut love liebebook bu?cher definitely absolute loved liebentext text completely definitiv like wiepage blatt certainly komplett fond wiederwords wo?rter totally sicher feel fu?hlenexpensive good notEnglish German English German English Germanexpensive teuer good gut not nichtexpense ho?her better besser no nieoverpriced ho?chsten well nett cannot neincostly hoch nice gro?artig non keineprice preis great gro?
?ten never keinestext categorization.
In Proceedings of EuropeanConference on Digital Libraries (ECDL), 2003.Y.
Bengio, R. Ducharme, and P. Vincent.
A neu-ral probabilistic language model.
In Advances inNeural Information Processing Systems (NIPS),2000.D.
Blei, A. Ng, and M. Jordan.
Latent dirichlet allocation.
Journal of Machine Learning Research(JMLR), 3:993?1022, 2003.J.
Blitzer, M. Dredze, and F. Pereira.
Biographies,bollywood, boomboxes and blenders: Domainadaptation for sentiment classification.
In Pro-ceedings of the Annual Meeting of the Asso.
forComputational Linguistics (ACL), 2007.K.
Diamantaras and S. Kung.
Principal componentneural networks: theory and applications.
Wiley-Interscience, 1996.L.
Duan, D. Xu, and I. Tsang.
Learning with aug-mented features for heterogeneous domain adap-tation.
In Proceedings of the International Con-ference on Machine Learning (ICML), 2012.R.
Fan, K. Chang, C. Hsieh, X. Wang, and C. Lin.LIBLINEAR: A library for large linear classifi-cation.
Journal of Machine Learning Research(JMLR), 9:1871?1874, 2008.C.
Fellbaum, editor.
WordNet: an electronic lexicaldatabase.
MIT Press, 1998.L.
Gillick and S. Cox.
Some statistical issuesin the comparison of speech recognition algo-rithms.
In Proceedings of the International Con-ference on Acoustics, Speech, and Signal Process-ing (ICASSP), 1989.A.
Gliozzo.
Exploiting comparable corpora andbilingual dictionaries for cross-language text cat-egorization.
In Proceedings of the InternationalConference on Computational Linguistics and theAnnual Meeting of the Association for Computa-tional Linguistics (ICCL-ACL), 2006.Y.
Guo and M. Xiao.
Transductive representationlearning for cross-lingual text classification.
InProceedings of the IEEE International Confer-ence on Data Mining (ICDM), 2012a.Y.
Guo and M. Xiao.
Cross language text clas-sification via subspace co-regularized multi-viewlearning.
In Proceedings of the International Con-ference on Machine Learning (ICML), 2012b.T.
Hofmann.
Probabilistic latent semantic analysis.In Proceedings of Uncertainty in Artificial Intelli-gence (UAI), 1999.A.
Klementiev, I. Titov, and B. Bhattarai.
Inducingcrosslingual distributed representations of words.1474In Proceedings of the International Conference onComputational Linguistics (COLING), 2012.X.
Ling, G. Xue, W. Dai, Y. Jiang, Q. Yang, andY.
Yu.
Can chinese web pages be classified withenglish data source?
In Proceedings of the Inter-national Conference on World Wide Web (WWW),2008.M.
Littman, S. Dumais, and T. Landauer.
AutomaticCross-Language Information Retrieval using La-tent Semantic Indexing, chapter 5, pages 51?62.Kluwer Academic Publishers, 1998.A.
Maas, R. Daly, P. Pham, D. Huang, A. Ng, andC.
Potts.
Learning word vectors for sentimentanalysis.
In Proceedings of the Annual Meetingof the Association for Computational Linguistics:Human Language Technologies (ACL), 2011.D.
Mimno, H. Wallach, J. Naradowsky, D. Smith,and A. McCallum.
Polylingual topic models.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Vol-ume 2 - Volume 2, 2009.A.
Mnih and G. Hinton.
Three new graphical mod-els for statistical language modelling.
In Proceed-ings of the International Conference on MachineLearning (ICML), 2007.X.
Ni, J.
Sun, J. Hu, and Z. Chen.
Cross lingualtext classification by mining multilingual topicsfrom wikipedia.
In Proceedings of the ACM In-ternational Conference on Web Search and DataMining (WSDM), 2011.J.
Pan, G. Xue, Y. Yu, and Y. Wang.
Cross-lingualsentiment classification via bi-view non-negativematrix tri-factorization.
In Proceedings of thePacific-Asia conference on Advances in knowl-edge discovery and data mining (PAKDD), 2011.P.
Petrenz and B. Webber.
Label propagation forfine-grained cross-lingual genre classification.
InProceedings of the NIPS xLiTe workshop, 2012.S.
Petrov, D. Das, and R. McDonald.
A universalpart-of-speech tagset.
In Proceedings of the Inter-national Conference on Language Resources andEvaluation (LREC), 2012.J.
Platt, K. Toutanova, and W. Yih.
Translingual doc-ument representations from discriminative projec-tions.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP), 2010.P.
Prettenhofer and B. Stein.
Cross-languagetext classification using structural correspondencelearning.
In Proceedings of the Annual Meetingof the Association for Computational Linguistics(ACL), 2010.L.
Rigutini and M. Maggini.
An em based train-ing algorithm for cross-language text categoriza-tion.
In Proceedings of the Web Intelligence Con-ference, 2005.J.
Shanahan, G. Grefenstette, Y. Qu, and D. Evans.Mining multilingual opinions through classifica-tion and translation.
In Proceedings of AAAISpring Symposium on Exploring Attitude and Af-fect in Text, 2004.W.
Smet, J. Tang, and M. Moens.
Knowledge trans-fer across multilingual corpora via latent topics.In Proceedings of the Pacific-Asia conference onAdvances in knowledge discovery and data min-ing (PAKDD), 2011.A.
Vinokourov, J. Shawe-taylor, and N. Cristian-ini.
Inferring a semantic representation of textvia cross-language correlation analysis.
In Ad-vances in Neural Information Processing Systems(NIPS), 2002.C.
Wan, R. Pan, and J. Li.
Bi-weighting domainadaptation for cross-language text classification.In Proceedings of the International Joint Confer-ence on Artificial Intelligence (IJCAI), 2011.X.
Wan.
Co-training for cross-lingual sentimentclassification.
In Proceedings of the Annual Meet-ing of the Association for Computational Linguis-tics (ACL), 2009.B.
Wei and C. Pal.
Cross lingual adaptation: Anexperiment on sentiment classifications.
In Pro-ceedings of the Annual Meeting of the Asso.
forComputational Linguistics (ACL), 2010.1475
