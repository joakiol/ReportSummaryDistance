KIND TYPES IN KNOWLEDGE REPRESENTATIONK.
DahlgrenIBH Los Ange les  Sc ient i f i c  Center11601Wi l sh i ro  B1.Los Ange les ,  Ca l i fo rn ia  90025J.
McDowellDepartment of LinguisticsUniversity of Southern CaliforniaLos Angeles, California 90089Abstract Tiffs paper describes Kind Types (KT), a system which usescommonsense knowledge to reason about natural anguage text.
KT en-codes some of the knowledge underlying natural anguage understanding,including category distinctions and descriptions dlffercntiating real-worldobjects, states and events.
It embeds an ontology reflecting the ordinaryperson's top-level cognitive model of real-world distinctions and a data-base of prototype descriptions of real-world entities.
KT is transportable,empirlcally-based and constrained for efficient reasoning in ways similarto human reasoning processes.I.
The problem A model of the semantic knowledge of conceptsunderlying natural anguage is definitional rather than assertlonal in thatit contains general descriptions of objects and their relations, as opposedto facts about specific objects (Levesque 84)i Part of competence inEnglish is the knowledge that an elephant is an animal, and therefore itmoves on its own.
Competence also involves knowing particular thingsabout elephants, uch as that they have trunks.
This general descriptionof the elej~hant concept is part of commonsense knowledge and belief.We will call this the cognitive model.
In order to implement it, a com-puter system must represent what speakers of a language believe aboutthe world and their named concepts, rather than represent he actualworld.
A complete computer model of the cognitive model would repre-sent the commonsense conceptual scheme presupposed by a particularculture and language, in tbis case, urban American English,Knowledge of a natural anguage implies knowledge of a kind of theoryof the environment used by a culture.
In learning a language a childlearns the category cuts recognized in that theory fBerlin 72l IDou?herty7g).
Assuming that knowledge of word meaning is not differently re-presented than other kinds of knowledge (Tarnawsky 82), KT is designedto encode the world view embodied in natural language as ordinaryknowledge, while retaining the autonomy of combinatorial semantics andof syntax.
KT does not provide all the meaning, but it yields an interest~ing and transportable portion of it.The work reported here addresses two major problems.
First, theknowledge associated with a concept does not always give necessary andsufficient conditions for deciding whether an object falls under the con-cept name.
The problem is to find a systematic way of predicting whichconcepts can be reasoned about using first order logic directly and simply(as a conjunction of predicates) and which ones require default logic.Second, the cognitive model models the actual world, which is open andcontinuous (Hayes 85).
The potential concepts and relations betweenthem are infinite.
Nevertheless, humans manage to reason without cog-nitive overload.
Can the computer model be systematically constrainedusing predictions paralleling those employed by humans in reasoningabout the actual world7Consider the following database of facts (assertions) and axioms (defi-nitions).
The language used is irrelevant; any system isomorphic to firstorder logic will have the same deficiency.l) FACTSHuman(mary).Teacher(mary).Student of (mary,john).Teacherof(john, mary).AXIOMSV x Teacher(x) ~ Human(x).V x ~t y Teacher(x) ~ Teacherof(y,x).A question-answering system with the above database of facts and216axioms can respond easily to questions uch as (2) but would be unableto answer (3).2) Does Mary have a student?Who is Mary's student7Is Mary human?3) Is Mary touchable?Can Mary move himseIf about7What does Mary do?Are John and Mary part of an institution?The questions in (3) can be answered by a system which has a taxonomichierarchy with features at the nodes, such as KL-ONE (Brachman andSchmolze 1985).
If Mary is human, Mary is physical object, which hasthe feature "touchable".
Similarly, since Mary is an animal, she canmove herself about.
KT employs such a taxonomy, and it is called anontology to reflect the fact that KT reasons with such information asthough it were true and complete, in contrast to generic informationwhicl{ is probabilistle.
The ontology is is unique to KT and is based uponresults in cognitive psychology, linguistics and philosophy.Another deficiency of tile database in ( l )  is that it knows nothing aboutJohn, Mary and their relationship, even though English speakers haredescriptions of the typical objects in the sets defined by the predicatesHuman, Teacher and Student.
For example, it would be desireablo if thesystem could respond as follows:4) Is Mary intelligent?
--Probably so.Is Mary articulate7 --Probably so.Does John listen to Mary7 --Probably so.ls Mary educated?
--Inherently so.What does Mary do?
--Inherently, teaches.The questions in (4) reflect he kind of things that average people thinkof when confronted with the predicates (1) (Dah gren 85).
Why not havethe AI system infer similarly?
In order for such information to be useful,the system needs to know that "intelligent" is a probabilistic feature as-sociated with the predicate Teacher.
Therefore, if told~lntell igent(mary) it should be able to reason that (5) while reasoningthat (6) is definitely inconsistent.5) ~ lntell lgent(mary) A Teacher(mary)6) (Remainder (X/2)  = 0) A Oddnumber(X)A system needs the capacity to reason with prototype information assn-elated with concepts.
But the vastness of such information is an obstacleto its use in commonsense r asoning systems.
The strategy employed inthe KT system is to take advantage of the high degree of structure inprototype information in order to constrain it.
Different types of kinds,such as artifacts, natural kinds and persons, are associated with predict-ably different ypes of information, and KT exploits these constraints.II.
Diversity in the Lezicpt/The task of representing meaning for sorts(common nouns) attd predicates (verbs and adjectives) themselves, hasbeen impeded by several philosophical problems which are yet to be re-solved.
The traditional approach, decomposition i to conjunctions ofother predicates, is notoriously defective.
There is no principled way toselect or limit the number of other predicates.
Suppose the meaning ofa~n~N_le is represented as (7).7) Apple -~.
Fruit (P, ed V Green) A l',otmd A Sizel0Why not addGrowsontrces?
The proposal to justify the addition of fur-thor predicates by the contrast with the moaning of other words has beenrejected on a number of grounds (Dowty 79).Predicate meaning representation is difficult because the domain of thecognitive model is the actual World, which is both open and unknown toa large extent.
I-h,mans can never be totally expert about the actualworld.
And, the knowledge o1 predicates used by speakers of a naturallanguage varies with expertise, how precise the predicate itself is, andcontext.
Some psychologists maintain that the the inherent openness ofthe actual world is dealt with cognitively by making clear (though possi-bly inaccurate) category cuts, and then reasoning about categories of ob-jects, including the unclear cases, using prototypes.
(P, osch, el al 76)(Smith and Medin 80).
This view implies diversity of representations ofpredicate meanings across the lexicon.
Some types of predicates will havecriterial features, ODD NUMBEI'~, others, such as names and naturalkinds, LEMON, will not.Because it represents sort and predicate meaning with prototypes, andbecause it uses first order logic, KT differs in theory and results fromsystems uch as KL-ONE.
In KL-ONE, concepts are defined by thelrroles (descriptive lements) and their subsuming concepts (those con-cepts superordinate o them in the taxonomy).
The concept ELEPHANTis defined by rolesets describing facts such as "has 4 legs", and by its at-tachment o MAMMAL.
The claim is that all and any instantiation ofthe ELEPHANT concept has 4 legs.
In contrast, descriptions in KT areprobabilistic.
The system accepts elephants with 3 legs, though it knowsthat elephants inherentfy have 4 legs.
It accepts eggs which are brown,even though it knows that eggs are prototypically white.
Further, inKL-ONE, since the descriptions arc meant to be defining, non-definingassociated information is not encoded.
By contrast,  KT encodes a greatdeal of information usually associated with a concept, without the hn-plicit claim that it applies to all instantiations of the concept.
ELE-PHANT can have features "forgetful",  " lmnbering" and so forth,without claiming that all elephants have those features.Another implication of the prototype model is that the content of fea-tures is seen as essentially limitless.
In contrast, the semantic net modelassumes that there is a manageable set of primitive concepts whose sizeis much smallcr that that of the English lexicon, that these are explicitlyconnected.
In KT, only ontological relationships are stated as rulcs.
Therelationships between specific descriptions can bc derived throughproblem-solving, but is not encoded.
For example, in KL-ONE,  the factthat both clouds and eggs are white is directly stated by a link from bothCLOUD and EGG to WHITE.
In KT, that both have a color is stated inthe kind type PHYSICAL OBJECT, but that they both have the samecolor is reasoned at run time.The diversity of information KT accepts is constrained by kind types,which predict that associated with ELEPHANT are leatures describingparts, because ELEPHANT is in the kind type PHYSICAL OBJECT.
Onthe other band, ELEPHANT does not have features describing its modeof construction because it is not in tile kind type AI~.'I'IFAC'F.
Thus, theKT system predicts limitless numbers of possible descriptions which areconstrained by types deriving from correlational constraints of the actualworld.The KT system differs from most other representations of thecommonsense knowledge underlying natural angtmge in taking the con-tent of descriptions from psycholinguistic studies.
Because of its empir-ical basis, KT responds to queries in a natural and human-l ike way.Though other formalisms could be used to represent empirically-derivedmodels of human commonsense knowledge, KT lends itself to represent-ins the diversity of information found in the data because it allows a vlr-tually unlimited number of features, while organizing them with the kindtypes.III.
The K i n d ~ ~  KT reads geography text, and shows itsunderstanding of the textby  answering questions.
Text understandingdemonstrates the usefulness of the system, but many interesting problemsin that area of resemch are not addressed by this work.
KT is written inVM/PROLOG.
It uses a parser, a f irst-order logic translator and ametainterpreter dew:loped by Stabler and Tarnawsky (19851.
It employsa set of databases which represent he commonsense ontology, tim ge-neric features for sorts, type information for the generic features, andkind types for the ontology.
Below is a sample text representative of theEnglish KT understands.Sam ling_ Text John is a miner  who lives in a mountain town.
His wiferaises a chicken who lays brown eggs.
The company-owned clinic is nearthe mine.
The nurse monitors the health of the miners.
She approves ofJohn's diet.111.1 Tim Ontological Schema To capture ontological constraints, KTemploys a top-level conceptual schema, some of which appears in Figure1.
It is intended to mirror tile average English-speaker's beliefs aboutwhat  tile major category cuts of the environment arc, that is, aeomlnooscnge ontology.F igure  1 The Onto log ica l  SchemaENTITY ~ (ABSTRACT v ILEAL) & (INDIVIDUAL v COLLECTIVE)ABSTRACT ~ IDEAL V PROPOSITIONAL v qUANTITY v \]RREALREAL ~ (PHYSICAL v TEMPORAL v SENTIENT)& (NATURAL v SOCIAL)PHYSICAL ~ (STATIONARY v NONSTATIONARY)& (ANIMATE v INANIMATE)NONSTATIONARY -- SELFMOVING V NONSELFMOVINGCOLLECT\]VE ~ MASS v SET v STRUCTURESTATIONARY ~ ~ MOVEABLETEMPORAL ~ STATIVE v NONSTATiVENONSTATIVE ~ (GOAL v NONGOAL)& (PROCESS v ACTIVITY v MOTION)PROCESS ~ POSITIVE v NEGATIVEACTIVITY ~ OCCUPATIONAL v INTERACTIONALOCCUPATIONAL ~ AGRICULTURAL v MININGMANUv IRADE v SERVICE v EDUCATIONINTERACTIONAL ~ POSSESSIVE v ASSISTIVE v CONIACTt}A4.V CONFRONTATIONALMOTION ~ (FAST v SLOW) & (TOWARD v AWAY)Tim goal is to encode all ontology which is consistent with an ernpiricallyverifiable cognitive model.
As much evklence as possible was derivedf rom psychologicalrcscarch.
The schema was developed to handle thepredicates found in 4100 wolds o\[ geography text drawn from textbooks.Despite the complexity of constructing a computer model of theontology, two commonly-used sinrplifieations, binary trees and planarbranching in trees, wcre rejected.
First, though binary trees have simpIi-lying mathematical  properties, they arc not likely to be psychologicallyreal.
People easily think in terms of more than two branches, such asFISH vs BIRD vs MAMMAL,  and so on, off of the VEWI'EBI~.A'I'E node.Secondly, most representations a sume that each node has a uniqueparent.
But cross-classification is necdcd shlce colnn\]oosensc rt2}lso?lingUSeS it.
People understand, for example, that entities cress-classify as in-dividuals or sets and real or abstract.
Tiffs means that at each node, morethan one plane might be needed for branching.
Cross-classiflcation ishandled as in (McCord 85).
A type hierarchy is generated which pernfitseach node to be cross-classified in !!
ways.
In the top level rule of Figure1 each entity must be classified both ways, as either ABS'I 'RACT orILEAL, and as either INDIVIDUAL or COLLECTIVE.  '
lhis correspondsto the claim that cngnilively there is essentially a palallel ontologicalschema for collectives.
For example, people know that herds consist ofanimals, so that herds are real and concrete.
Thus we have the parallelontology Iragments in (8).
(8)INDIVIDUAL COLLECTIVEENTITY ENTIIYABSTRACT REAl_ ABSTRACT REAL/ JCONCRETE CONCRETE/ /ANIMAL ANIMAL / /CO,_~W HERDInheritance of properties works differently for tile collectivcs than itdoes for individuals.
Because cow is under ANIMAL,  "cow is a kind ofanimal" is true.
In contrast, !toLd attaches to ANIMAL,  but "a herd is akind of animal" is not true.
A herd consists of animals.
We have foundthat though there arc gaps among the collectives, a surprising mnnber oftypes of entities lmve collective names in English.
For example, plop-217ositions come in collectives (d i scourse~th~.
Another importantcross-classification involves SOCIAL vs NATURAL.
Entities (or events)which come into being (or take place) naturally must be distinguishedfrom those which arise through some sort of social intervention.ART IFACT is one of the SOCIAL nodes.
The distinction needs to bemade high up in the ontology because it affects most kind types.
For ex-ample, events may either be SOCIAL (p_arty_) or NATURAL _(earth-guake).
(Section IV expands upon the justifications for the ontology).The ontology also assumes the possibility of multiple attachments ofinstantiations to nodes.
Thus the representation is actually a latticerather than a tree.
For example, an entity, John, is both a HUMAN withthe physical properties of a mammal,  and is also a PERSON who thinks.The latter makes John very similar to other sentients uch at institutionsand social roles.
Instead of loading all of that complexity into a singleHUMAN node, we make the SENTIENT~NON-SENTIENT distinctionhigh tip in the hierarchy.
There is ample philosophical (Strawson 53) andpsychological (Gehnan and Spelke 81) support Ior this decision.
Any ac-tual person is attached to both the HUMAN and PERSON nodes in theontology.1II.2 Generic Information In the generic features database, each sortis represented as a predicate with two arguments.
The first is a list ofprototype features and tile second is a list of inherent features.
A prote-type feature it typically associated with a sort or tuedicate.
Most entities'have more prototypical features than inherent features.
From our sam-ple, a miner is typically "male";  a norse is typically "female"; a towntypically has "houses",  Ua square II, Ila fountain", and so on, h lherentfeatures are are rationally unrevisable properties of a sort or predicate.Thus, a man is inherently "male",  a wife is inherently "marr ied" ,  a houseis inherently "house-slzed".
From our sample, a miner inherently "worksin a mine", a nurse inherently is "educated",  a town inherently contains"buildings", and so on.IlI.3 Feature ~I~y~ The lu'ototype features are represented by the sameset of predicates osed to represent the inherent 1eatures, thus achievingSOOle econollly bl the rules.
Nevertheless, the nmnber of predicatesneeded to encode the inherent and prototype features is theoreticallylimitless.
Fortunately, a small and manageable set of 33 feature typesencodes a great deal of inforlnation, although not exhaustively.
The fea-tures themselves were chosen empirically to correspond withpsycholingulstic data gathered by l;'.esch et al(1976), Asheraft (1976)and Dahigren (1985a) When asked to list prototypieal Ieatures of variousconcrete objects, subjects tend to name features which fall into a smallnunrber of types such as SIZE, COLOR, SHAPE, and FUNCTION.Similarly, a few types of features uch as STATUS, SEX, INTERNALTI~.AIT AND I~.ELAT1ON are named for social roles.Notice that a feature type such as SIZE or COLOR may be inherentfor one sort but only prototypleal for another.
For instance, while bloodinherently has COLOP, " red" ,  a brick is only prototypically " red" .
Whilea brick inherently has SHAPE "rectangular parallehJpitmd" , bread is onlyprototypically " loaf-shaped".
In some cases, a sort has a feature typeboth inherently and prototypically.
For example, a doctor has the inher-ent FUNCTION "treats sick peot~le" and the prototypical FUNCTION"consoles ick people".I11.4 Kind q'ypcs as Metasorts Most knowledge representation systemspermit any combination of the features in descriptions.
KT limits thesecombinations by taking advantage of several important ontological con-straints affecting the possible real-world objects and therefore possiblecombinations of features in commonsense knowledge.
Objects 1all intokinds.
In particular, natural  kinds exist because their members haresome underlying trait, while artifacts and social kinds exist because lsocial convention Schwartz(1979) Dahlgren (1985b).
We call classifica-tions of kinds KIND TYPES, so that NATUP, AL KIND constitutes onekiud type, ARTIFACT another, and so on.
Kind types constrain theeomnlonsense knowledge base in several ways?
First, each kind type isunderstood in terms of certain predictable feature types.
NATURALKIND is conceived primarily in terms of perceptual features, whileARTIFACT adds functional features.
Second, there is a correlationalstructure to the features of reai-world objects.
Given that an object is a218mammal,  certain features will be found (eg. "
fur" )  and others will beabsent (eg. "
feathers") .Associated with each node in the ontology is kind type informationencoding feature types entities attached at that node may have.
Entitiesmay be described by features falling into a some or all of these featuretypes, and no others.
Inheritance up the tree ensures that any lower nodehas all the feature types of higher nodes on any path to ENTITY.
Forinstance, any node under P I tYSICAL may have certain feature types,and any node under AP, T IFACT may have those inherited I tem PlIYS-1CAL, as well as fu,'ther feature types, as below:PI IYSICAL - Shape.
Size, Color, Materialrl'exture, Odor,  ltasparts, PartofAF.TIFACT - {PHYSICAL\] ,  Function, Operation,Construction, OwnerAt each node, only certain feature types are applicable.
Conversely, eachfeature known to KT is classified by type as a COLOR,  SIZE, FUNC-TION, INTERNAL TRAIT or other.
Cohn (19851 describes the econ-onry of the use of sorts in logic programming.
In the KT system, sorts andpredicates appear at the terminal nodes of the ontology.
In addition, thekind types employed by the system represent metasorts, in that theyconstrain the possible ty_~es of sorts recognized by the system.I11.5 Encoding the Common Sense Knowlcdgt~ The representationsdescribed above will be illustrated with the sort nurse.
Nurse is attachedto the ohtology in axiom9) nurse(X) -+ role(X).From this axiom nurse inherits SENTIENT, SOCIAL, PHYSICAL,REAL,  INDIVIDUAL and ENTITY tronl the ontology, In the generic?
database, the axiom (101 lists the prototype and inherent Ieatures ofnurse.10) marse ({caring,female}, {educated,asslstant,help(X,Y) & person(Y) & sick(Y)}).Notice that the last inherent feature is in the form of a PP.OLOG clause.This makes it possible to use the whole complex feature as input to theEnglish grammar  in order to \[ormnlate an English response to a questionsuch as "What  does the nurse do?
", or "Does the uursc help peopleT".The feature typing database classifies the features as follows:relalion(assistant).interonltrait (caring).internzltrait(educated).sex(female).function(help(*,*)).The kind types predict that as a I~.OLE, nmse will have certain typesof features.
Inherited from the SENTIENT kind type are feature typesINTERNAL TP, AIT ("car ing")  and GOAL ("tries to help").
Inheritedfrom the SOCIAL kind type are feature types FUNCTION ("takes careof patients") and REQUIREMENT ("license").
In addition, RE-LAT ION type features ("assistant") are predicted with a ROLE,IV.
The Inference Mecharfism Built into the natural anguage compo-nent by Stabler and Tarnawsky is a mctainterpreter which solves queriesof all axioms active in the system.
This permits us to query ontologicaland generic information as welt as textual information.
The translationof tile first sentence of Sample Text is as in (11).11) miner(john} & town( town220)The problem solver derives t11o answers to qneries as in (12}.
matchinglogic translations of tile queries, which are in ttm form of Prelog goals, tothe database.12) Is John a miner7 -- YesDoes John live in a town7 -- YesIn addition, KT is able to nlake a number of inferences from the textwhich are not directly stated there.
The inferences are drawn from vari-ous aspects of the common-sense knowledge built into KT.IV.I Inheritance Using the ontological database anti tile same problemsolver, the KT system deduces taxonomical ly inherited informationabout the entities mentioned in tile text, as in (13\]-(14).13) What is a miner7--A miner is a role, sentient, concrete,social, individual and an entity.14) What does a miner do?--A miner digs for minerals.What is digging7--a goal-oriented, natural, nonmcutal,real, tem.tmt'al ctivityIf an entity has dual attachment,  for example as a human and as a role,or as a place anti as an institution, then KT explains inheritance relationsalong both paths of the ontology.
A clinic is both a social place and aninstitution, and so when asked (15),15) What is the clinic?KT replies both that "A clinic is an institution, sentient, physical, real,collective, structure."
and that "A  clinic is a social place, place, inani-nmte, physical, stationary, social, real, individual."
Direct ontologicalquestions uch as (16) are also answered:16) ls tile clinic a social place?
--YesIs the clinic collective?
--YesThe inheritance path is followed in answering such questions, so that thesystem call answer not only queries of node attachments at to the termi-nal nodes of the ontology, but at all higher levels.IV.2 Coln1~letq.
a.D~l - hmon)plc_'tc.l(nowlcd~gc_" In reasoning with thisschema, the system knows which valid inferences it can deriveontologically, and thcrefcre definitively, and which knowledge is incom-plete.
For example, KT knows that it knows the following for certain:V x Human(x)  ~ Thinks(x)VxTeacher (x ) - -  l luman(x)It also knows that if something is HUMAN,  it is not AIISTRACT.
Whenasked "Is the teai:her abstract?"
it answers "No" .
Thus it handles theexclusivity of sets called for by Hcndrix (1979) and Teoenbaum(1985).On the other hand, it knows which information is incomplete.
With ge-neric descriptions, KT knows that it only knows at the la'obabilistie l vel.It asked, "Is Mary  intelligent?"
it rcspouds "Probably so."
' lhis reflectsthe fact that most English speakers hare a prototype of teachers as intel-ligent.
The logic works this way.
If a question is ontological, KT givesdclinitive (yes/no)  answers.
If the question is generic, the answer isqualified as either prototype or inherent.
If no attswcr can be derived toa non-ontological question; KT responds "1 don't  kttow."
Thus KT makesthe open world assumption except with regard to ontological classifica.tions.
Tills ability to reason about incomplete definitions is shnilar toLevesque's proposal for incomplete databases (Levesque 84).IV.3 Prototy_p_c_'_ag~tlnhgj2Efit Fea!31res KT answers queries concerningfeatures of the entities in the text, both directly and by types of features.Direct feature queries are of the form (17).
The form of the answer de-pends upon whether the feature is prototypical or inherent.17) Is the miner rugged?
--Probably so.Is the clinic a place?
--Inherently so.Does the chicken lay eggs7 -- Inherently so.Are tile eggs white7 --Probably so.t Iow is digging done7 --Probably with a shovel.Where is digging done7 --Probably in the earth.IV.4 Overriding Features Genmqe information is handled differentlyfrom ontological information.
First, it is tentatively inferred, andchecked against ile current knowledge base of information built up fromthe reading tile text.
If anything ill the tcxtnal database conflicts with ageneric inference, the latter is overridden.
K'F takes the text as the au-thority, and if the text says that an entity has a feature contradict ingthose in its oommonsense knowledge of the entity, the text's claim comesfirst.
For example, Salnplc Text says that the eggs are "brown" ,  whichoverrides the prototypical generic lcaturo "white" which is listed for c~g,as in (18).18) Are the eggs brown?
--The text says so.The cancellation takes place simply by matching to the textual dalabasefirst.
Sbnilarly, if a text said that an elephant had three legs.
the KT sys-tem would reason that it had three legs, and not the inherent four thatelephants have.
By overriding inherent features, KT gets aronnll  thecancellation problem which arises when features are viewed as logicallynecessary.
If "has four legs" is taken to be a logically necessary feature,aug  three-legged elephant forces a contradiction, or special processing forexceptions (Brachman and Schmolze 1985).
The KT system accepts bothfacts as true, with no contradiction.
This particular elephant has threelegs, and elephants inherently have four legs.In attempting to match to both the textual and generic databases, tilepossibility of infinite recursion arises.
This is true in principle for the hu-man reasoner, as well.
KT prevents infinite recursion by limiting infer-enccs to a depth of 5.Because of the feature typing, KT can answer queries as in (19).19) What color are tile eggs?What function does tile clinic have?Feature typing classifies "brown"  as of type COLOR.
When KT looksfirst at the translation of the text to see whether it contains an assertionwhich states a color for tile eggs, it must distinguish tile facts in the textwhich arc relevant o the feature type queried.
With respect o SampleText, in order for KT to answer "What  color are tile eggs?
", KT mustknow that "brown"  is a COl .OR.
Without feature types, KT would notcontrast "white" with "brown" .KrI ' deduces ets of lacts, as well as individual facts.
When qnmied for atype of feature, sucll as FUNCTION, KT responds with all functionslisted for a sort.
For example, clinics protolypical ly have both outpatientand emergency' functions, and Krl ' lists both when queried for funclion.For sorts which are structural,  that is, concrete objects and institutions,KT is able to describe tile structure.
If asked "What  structure does theclinic have?
",  KT answels that typically it has a hierarchy of head-asslstant-clientele and has roles of doctor for head, nurse for assislant nndpatient for clientele.
Similarly, if asked "What  structure does the lishhave?
",  KT answers, inherently it has these parts: fins, 1 tail, 1 head, 2eyes, scales.
When KT lists parts, bare plurals mean an unspecified numober greater than one.IV.5 Kind "l~'t~es The kind types are useful in both parsing and infercnc-lug for text understanding.
In the parsing phase, kind types can be usedfour ways.
First, verb sense ambiguity can be resolve d by' the kind typesof subject and object head nouns.
In a sentence with the verb take,knowing that the subject is a vehicle forces the choice of the one sense ofthe verb, and knowing that it is a human forces another.
Secoudly, KTcan reason the other way around, and use selection restrictions on verbsto infer the kind types entities referred to in the sentence.
Consider sen-tence (20).20) ABC sued tile man.Using kind types for selection restrictions, KT infers that the entitynamed ABC is a SENTIENT.
Given the further information in (21), KTinfers that ABC is an INSTrI 'UTION and not a PEP, SON, because theverb ~ requires an INSTITUTION as object.21921) The man had joined ABC illegally.Thirdly, certain anaphoric references can be resolved using kind types.When verb selection restrictions classify the entity referred to by a pro-noun as in a certain kind type, then possible antecedents are correspond-ingly constrained.
Consider the relationships in (22).
~ corefers withmilk because, when intransitive, s~ requires a LIQUID as subject.22) The cat drank the milk.
It spilled.Fourthly, attachment ambiguities for prepositional phrases can be re-solved using kind types.
Consider sentence (23).23) John bought he lock in the afternoon.It is syntactically possible for the prepositional phrase in the aIternoon tomodify the lock, the verb phrase or the whole sentence.
Since afternoonis in the kind type TEMPORAL,  KT can resolve this syntactic ambiguity,and attach the prepositional phrase so that it modifies the whole sentence(Dahlgren and McDowell, 1986).IV.6 Summary of Inference Mechanism In summary,  predications usedto derive inferences in the text are found in five aspects of common-senseknowledge:a) Ontological Schemab) Verb and adjective selection restrictionsc) Generic Informationd) Typing Informatione) Kind typesIn using KT, queries drive these inferences.
After a text such as theSample Text has been read, KT can respond to queries and seem to un-derstand the text in a more human-l ike way using the various aspects ofknowledge indicated above.
Below are listed some queries and responses.Q: Who is John?A: The man who lives in the town.---Prototypical town has people living in it.---Prototypieal male person is a man (not a boy).Q: Was the town built?A: Yes.---By ontology of artifactsQ: Who built the town.A: People.---By ontology of artifactsQ: Does John wear pants7A: Probably so.---By prototype database.Q: Does John eat eggs.A: Yes.---Because ggs are food.Q: What does health think7A: Health doesn't hink.---By kind types.Q: Does John look like a clinic7A: No.---By ontology database.Q: Does John live in a'tent7A: Probably not.---By prototype of townQ: Does John have a function2A: Yes,---By kind typesIV.
Basis for the Commonsense Knowledge_ Results in linguistlc re-search underline the importance of category distinctions, such as thosebetween abstract and concrete objects, and persons as opposed to otherobjects.
These actively affect sentence interpretation and generation.The sentence "The rock read the book" must either be interpreted asanomalous or metaphorical bceause only persons read.
These constraintsprovide an empirical basis for the ontology.
Cognitive psychological re-220search provides a further basis for the ontology.
Keil's work cnontological categorization in cognitive development was consulted inconstructing the schema (Kei179).
Gehnan and Spelke's results suggestedplacing SENTIENT higher in the schema (Gehnan and Spelke 81).Graesser and Clark's studies were the basis of the verb ontology(Graesser & Clark, 1985).
Psycholingulstie research in the prototypetheory provided descriptions of the actual prototypes hared by English-speakers for a number of these categories (Rosch, ct a176) (Dahlgren 85).The ontological schema was developed in two steps.
First, the verbsf rom the corpus o\[ geography texts were classified accotdlng toselectional restrictions (SRs) oo subjects and objects.
Second, the mini-real categories needed to aceomodate these Sl~.s were arranged in a hi-erarchical schema.
Certain SRs, such as HUMAN,  ANIMA'I f f ,CONCRETE,  were expected.
Others were surprises.
Some verbs re-quired complements hat were marked for PLACE,  and others requiredeither subjects or objects to have certain mnveabil ity Ieatures.
q'hese aresummarized below.STATIONARY:  normally immobile, attached to the earth, movedonly at great effort.SELFMOVING: normally in motion or designed for motion, in someeases with no apparent initial source.NONSELFMOVING:  normally immobile but can be moved withslight effort.
A source for the motion is expected, usually somethingSELFMOV1NG.One other interesting result from this stage of tire project is that a nmnberof vc rbs takee l thera  PROPOSIT IONAL or a SENTIENT subject.
Botha book and a person can say something.Once the set of categories had been established, the next stage was \[it-ting tllem into a hierarchy from which inheritance of features c(mM becomputed by KT.
There were several constraints guiding this process.First, we wanted the ontology to be as compact as possible.
Second, wewished to minimize nonexistent leaf nodes.
Third, we preferred ttmt thesystem infer too little than too much.
Daring this process it was alsonecessary to decide which of the Sl~.s represented true category cuts in anontological schema and which were merely features on individual exiealitems.
The guiding principle here was that if the distinction under exam-ination (i.e.
ANIMATE/ INANIMATE)  pervaded some subtrce, then itwas assigned to a branching point.
But if some distinction was needed inisolated parts of the tree, then it was represented as a feature.
For in-stance, we found that the INDIVIDUAL~COLLECTIVE distinctionpervades the lexicon and must be a pr imary cut in the ontology.
Manyverbs select only INDIVIDUAL (rnin21~clc) or only COLLEC'I IVt~(stamj~ede) subjects or" objects.
Properties which were assigned 1eaturestatus were items like EDIBLE and SIZE.The NATURAL/SOCIAL  distinction was placed high on tile tree be-cause human intervention pervades the world.
All abstract entities ateproducts oI tile human mind, but every category of real entities, includingevents and states, contains dozens of examples of the products of society.We therefore reserved the term ARTIFACT for irranimatc man-madeobjects to distinguish them from natural inanimate objccts. '
IheSENTIENT~PHYSICAL distinction is also fairly high.
SENTIENF isoften placed as a subordinate nf ANIMATE,  but in commonsense rea-soning, the properties of people and things are very difIerent.
TheNATURAL/SOCIAL  distinction applies to SENTIENT just as it does toPHYSICAL.
A NATURAL,  SENTIENT entity is a PERSON, that is aman,  w o m a ~  whereas a SOCIAL, SI~NTI\]JNT entity is aROLE,  seoretary~ miner, president.
A collection of PERSON is a BODY,crowd I ,  Agsnob _.
A collection of ROLE is an INSTITUTION, hos imp~l~school.
The INDIV IDUAL/COLLECT IVE  cut had to be made at thelevel of ENTITY (the highest level) at the same place as theA I JSTRACT/REAL  cut.
This was not the only place where multipledistinctions applied (see Figure I).Our  term COLLECTIVE applies to all collections of entities, classifiedinto three subgroups.
True collectives are sets in which each member oftile set is identical to all tile others (l_lcrd~ t_nob, m~p_w~lL IIgR\[).
Masses arecollections whose members are referred to only in terms of measurableunits (saskd~__water), Finally, there are structures where the membershave specified relations, such as in institutions (school, cotnpanz~It was consideration of both the constraints listed above, and the as-slgnments of SRs to feature or node status that led us to abandon bothb inary  branching and  planar trees as useful representational devices.While it was possible to model some distinctions as binary, others re-quired more than two branches.
For example, ABSTRACT entitieswhich divided into IDEAL, PP, OPOSH' IONAL,  QUANTH'Y ,  andIRREAL,  all of which have equivalent status as SRs.Figure ill Terminal Nodes in the ~c\]lenlaExample Rulebush PLANT ~ REAL & INI)IVIDUAL & I'IIYSICAL& NATURAl.. & ANIMATE & STATIONARYbear ANIMAL * REAL & INDIVIDUAL & PtlYSICAL& NATURAL & ANIMAqE & NONSTATIONAR%& SELFMOVINGmountain PLACE ~- REAL & INDIVIDUAL & PIIYSICAL& STATIONARY & INANIMATEmountain NATURAL PLACE ~ NATURAL & PLACEvillage SOCIAL PI~\[ACE ~- PLACE & SOCIALstone MINERA~ ,- REAL & INDIVIDtJAt & PIIYSICAL& NA'IUI~AI.
& INANIMATE& NONSTATIONARY & N{}NSEI.FMOVINGSantos PERSON ,- REAL & INDIVIDUAL & NAqURAL& SENTII'N 1'car VEIIICLI:.
-- AIVHFACT & SEI.FMOVING& PIIYSICAL & SEt.FMOVINGradio AICIIFACT -~ ARTIFACT & NONSELFMOVINGsecretary ROLE * REAl., & INDIVIDUAL & SENTIENT& SOCIALbook DISCOURSE * ABSH~.ACT & COLLECTIVE& PILOPOSITIONALWe were still faced with the fact that many entities still seemed tostraddle the hierarchy.
Is an individual human a PRIMATE or a PER-SON, or both7 Is a hospital an INSTITUTION or a PLACE, or both?
Ifwe were to establish a hierarchy which would reflect these differences,we would end up with a very large and unwieldy schema with huge gaps.Therefore, we deekted on multiple attachment for those entities whichre(mlred it.
This decision was justified as well by examioation of the textswhich revealed that a human teeing was generally dealt w i th in  a contextas either a person or a physiological being, but rarely as both at tim sametime.
Figure IIl giw:s examples of some nouns, their assignment to cate-gories and rules by which terminal nodes in the schema are generatedfrom higher..level nodes.
Figure lII shows only a few examples of termi-nal nodes irt the schema, However,  every path through the ontology re-suits in a terminal node which is named and which represents a uniqueclass defined by inheritance of features up the tree.
Tetmina\[ node namesdistinguish the individuals from the collectives, For instance, the collec-tive node corresponding to I 'LANI '  is FLOP, A.
The individual node cor-responding to DISCOURSE is PROPOSH' ION.
Similarly, STUFF is thecollective nf MINERAl_, INSTH'UTION is the collective of ROLl?, andBODY is the collective of PERSON, etc.The types of features which occurred in the data at each node in theontology were the basis of the kind types.
It is an empMeal fact that fea-ture types are correlated in relation to ontological classifications.
At eachnode in the ontology is a kind type encoding certain sets of properties thatany entity classified at that node may have.
Inheritance up the tree en-sures that any lower node has all the properties of higher nodes on a sin-gle path to ENTITY.
For each property at a node, a set of values applies.While the values for items such as COLOR are fairly obvious, we havehad to construct value ranges elsewhere.
For SIZE, we ltave started withthe set {microscopic, l~iny, small, handleable, medium, large, huge,building-sized, skyscraper- sized, mountainous, region-sized!, which is areality-oriented scale to be applied loosely.
The kind types were ex-tracted empirically from the generic data after all the features weretyped, by inspection of types of features associa\[ed with sorts and predi-cates at each node of the ontology.The texts in the corpus describe lifestyle and industry in wlrious coun-tries.
Generic descriptions of the nouns in the text were drawn frotn thepsycholinguistic literature, to the extent possible.
((Rosch 76); (Ashcraft76); (Dahlgren 85)).
For P, OLE, we used generic descriptions of socialroles collected by Dahlgren and partially published in (Dahlgren 85).
ForPHYSICAL we used generic descriptions from (Ashcraft 76).
For thosenouns where no data existed, generic descriptions were created cen-forming to the types of information generated by subjects for similarnouns.
We do not consider this a defect of our system, since we are nottrying to argue for the psychological reality of any particular generic de-scription, but merely for the efficacy of a reasoning system which usesthem.
The decision to place features in the prototype list or the inherentlist for a sort or predicate was decided by two judges.
It is a research goalto verify judgments experimental ly.Co eclusjot~ hi conclusion, KT encodes an ontology which omdels thetop level of typical t~'nglish speaker's cognitive model ef the actual wolld.It employs everal different ypes of information to reason in human-l ikeways about text that it reads.
In addition to the onlolngy, iI uses velbselection restrictions and generic in\[ormatlon associated with COIleel)ls.By enlploying systematic constraints in the form of kind types assoeialedwith nodes in the ontology, KT reasons efficiently.
All of lhe informationKT uses is d rawn from empirical studies of human cognitive psychology,linguistics or the corpus of text which KT reads.
Because of this empiricalbasis, and the breadth of the ontology, KT is a transportable syslcmwhich is potentially useful for understanding any text of a general, literalnat'tn'e,REF\]7 RENCESAshcralt ,  M.II.
Property norms for typical and atypical items lrom 17categories.
Mere9% Z 9qd Cogttition, 6: 227-32, 19"18.Brachman, P-_l.
and J.G.
Schmolze.
1985.
An overview of the KL-ONEknowledge representation system.
C ogt\]iLive Science 9 : 171-210.Berlin, B.
1972, Speculations on the growth of ethnobotanicalnomenclature.
\[ 5938uagc:3nd So?i~t Z 1:41-86.Dahlgren, K. 1985a, The Structnl e of Social Categories,C ogniLivq_Science 9:379-398.Dahlgren, K. 1985b.
Kind types in lexieal representation.
To appear.Dahlgren, K. and J, McDowell.
1986.
Using eotnmonsense knowlcdgeto disatnbiguale, To appear.Dougherty, J.W.D.
1978.
Salience and relativity in classificationAxeer icaR E t\[)~mlo~is b 5:66~80.Dowty, David R. 1979.
W tA?1 M~!an!#g ~!B!
Monta ugpe G\ [a!nAw i.Durdrecht, l lolland: D. Reidel Publishing CompanyGehnan, R. andE,  Spelke.
1981, Thoughts About Animate andInanimate Objects, in S'ecia) CDg!
!i).i'ce D~wel~ac j  ~,cds.
J.II.
Flavell and L. P, oss, p. 43-81.Graesser, A. and L. Clark.
1985.
Strtt?1urps anc t I'recettures i~\[_In3plieit fZnowle_d~g ?.
.
Norwood,New Jersey: Ablex.Hayes, P.J.
1985.
The second naive physics manifesto.In For_u)al\[l'heur_i?s o/tlaq.Co3nmonsetlye World,eds.
J,P,.
Hobbs and R.C.
Moore.
Norwood,  N.J.; Ablex.Hendrix,  G.G.
1979, Encoding Knowledge in Partitioned Networks,in Asspciative Net~'ork_s, ed.
N.J. Findler, p.51-92.Keil, F. C. 1979.
Se!
!mjltic and (.~onceptual Develo3Eneot.t larwu'd U Press.Levesque, 11.
1984, The logic of imcotnplete knowledge bases,in _QvLCot~cEph,al M?~!eling.
eels.
M. L. Broclie,J.
Mylopeulos and J,W.
Sehmidt.
New York: Sptiogcr-Verlag.McCord,  M. 1985.
The Icxical base for setnantic intcrpretatital in aprolog parser.
Wet kshop on the Lexicon, Parsing and SeuaantieInterpretation.
CI JNY Graduate Center.Rosch, I3., Mervis, C.B., Gray.
W.D., Johnson.
D.M.
&Boyes-Braem, I', 19/6.
Basic objects in naturalcategories.
_C__ogeilivc_l\[sychqlqgy 8:382-439.Smith, Edward E. and Medin, Douglas L. 1985.
Catcgoriesand Concepts.
t larvard U.Stabler, E.P,, Jr., and G.O.
Tarnawsky.
1985, NLProlcg---A prolog-based natural  anguage facility, To appear.Strawson, P.C, 1953.
Indivkluals.
London: Methuen.t Tarnawsky,  G.O.
1)82.
Knowled&e Semantics.
UnpublishedNYU Dissertation.Tenenbautn, J.D.
1985.
Taxonomic reasoning.
Prec, IJCAI.221
