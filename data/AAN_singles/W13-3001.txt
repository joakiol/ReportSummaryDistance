Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 1?11,Sofia, Bulgaria, August 9, 2013. c?2013 Association for Computational LinguisticsDistributions on Minimalist Grammar DerivationsTim HunterDepartment of LinguisticsCornell University159 Central Ave., Ithaca, NY, 14853tim.hunter@cornell.eduChris DyerSchool of Computer ScienceCarnegie Mellon University5000 Forbes Ave., Pittsburgh, PA, 15213cdyer@cs.cmu.eduAbstractWe present three ways of inducing proba-bility distributions on derivation trees pro-duced by Minimalist Grammars, and givetheir maximum likelihood estimators.
Weargue that a parameterization based on lo-cally normalized log-linear models bal-ances competing requirements for mod-eling expressiveness and computationaltractability.1 IntroductionGrammars that define not just sets of trees orstrings but probability distributions over these ob-jects have many uses both in natural language pro-cessing and in psycholinguistic models of suchtasks as sentence processing and grammar ac-quisition.
Minimalist Grammars (MGs) (Stabler,1997) provide a computationally explicit formal-ism that incorporates the basic elements of oneof the most common modern frameworks adoptedby theoretical syntacticians, but these grammarshave not often been put to use in probabilistic set-tings.
In the few cases where they have (e.g.
Hale(2006)), distributions over MG derivations havebeen over-parametrized in a manner that followsstraightforwardly from a conceptualization of thederivation trees as those generated by a particu-lar context-free grammar, but which does not re-spect the characteristic perspective of the under-lying MG derivation.
We propose an alternativeapproach with a smaller number of parameters thatare straightforwardly interpretable in terms that re-late to the theoretical primitives of the MG formal-ism.
This improved parametrization opens up newpossibilities for probabilistically-based empiricalevaluation of MGs as a cognitive hypothesis aboutthe discrete primitives of natural language gram-mars, and for the use of MGs in applied naturallanguage processing.In Section 2 we present MGs and their equiv-alence to MCFGs, which provides a context-free characterization of MG derivation trees.
Wedemonstrate the problems with the straightforwardmethod of supplementing a MG with probabili-ties that this equivalence permits in Section 3, andthen introduce our proposed reparametrization thatsolves these problems in Section 4.
Section 5 con-cludes and outlines some suggestions for future re-lated work.2 Minimalist Grammars and MultipleContext-Free Grammars2.1 Minimalist GrammarsA Minimalist Grammar (MG) (Sta-bler and Keenan, 2003)1 is a five-tupleG = ?
?,Sel ,Lic,Lex ,c?
where:?
?
is a finite alphabet?
Sel (?selecting types?)
and Lic (?licensingtypes?)
are disjoint finite sets which togetherdetermine the set Syn (?syntactic features?
),which is the union of the following four sets:selectors = {=f | f ?
Sel}selectees = { f | f ?
Sel}licensors = {+f | f ?
Lic}licensees = {-f | f ?
Lic}?
Lex (?the lexicon?)
is a finite subset of??
?
(selectors ?
licensors)?
?
selectees ?licensees??
c ?
Sel is a designated type of completed ex-pressions(A sample lexicon is shown in Fig.
3 below.
)1We restrict attention here to MGs without head move-ment as presented by Stabler and Keenan (2003).
Weak gen-erative capacity is unaffected by this choice (Stabler, 2001).1Given an MG G, an expression is an orderedbinary tree with non-leaf nodes labeled by an ele-ment of {<,>}, and with leaf nodes labeled by anelement of ??
?
Syn?.
We take elements of Lexto be one-node trees, hence expressions.
We oftenwrite elements of ??
?
Syn?
with the two com-ponents separated by a colon (e.g.
arrive : +d v).Each application of one of the derivational opera-tions MERGE and MOVE, defined below, ?checks?or deletes syntactic features on the expression(s)to which it applies.The head of a one-node expression is the ex-pression?s single node; the head of an expression[< e1 e2] is the head of e1; the head of an expres-sion [> e1 e2] is the head of e2.
An expression iscomplete iff the only syntactic feature on its headis a selectee feature c and there are no syntacticfeatures on any of its other nodes.
Given an ex-pression e, yield(e) ?
??
is result of concatenat-ing the leaves of e in order, discarding all syntacticfeatures.CL(G) is the set of expressions generatedby taking the closure of Lex under the func-tions MERGE and MOVE, defined in Fig.
1;intuitive graphical illustrations are given inFig 2.
The language generated by G is {s | ?e ?CL(G) such that e is complete and yield(e) = s}.An example derivation, using the grammar inFig.
3, is shown in Fig.
4.
This shows both the?history?
of derivational operations ?
althoughoperations are not shown explicitly, all binary-branching nodes correspond to applications ofMERGE and all unary-branching nodes to MOVE?
and the expression that results from each op-eration.
Writing instead only MERGE or MOVEat each internal node would suffice to determinethe eventual derived expression, since these op-erations are functions.
A derivation tree is atree that uses this less redundant labeling: moreprecisely, a derivation tree is either (i) a lexi-cal item, or (ii) a tree [MERGE ?1 ?2] such thatMERGE(eval(?1), eval(?2)) is defined, or (iii) atree [MOVE ? ]
such that MOVE(eval(?))
is defined;where eval is the ?interpretation?
function thatmaps a derivation tree to an expression in the ob-vious way.
We define ?
(G) to be the set of allderivation trees using the MG G.An important property of the definition ofMOVE is that it is only defined on ?
[+f?]
if thereis a unique subtree of this tree whose (head?s) firstfeature is -f .
From this it follows that in anypierre : d who : d -whmarie : d will : =v =d tpraise : =d v  : =t coften : =v v  : =t +wh cFigure 3: A Minimalist Grammar lexicon.
Thetype of completed expressions is c.>who : < : c >marie : <will : <praise :  :< : +wh c >marie : <will : <praise : who : -wh : =t +wh c>marie : <will : t <praise : who : -wh<will : =d t <praise : who : -whwill : =v =d t<praise : v who : -whpraise : =d v who : d -whmarie : dFigure 4: An MG derivation of an embedded ques-tion2MERGE(e1[=f ?
], e2[f ?
])={[< e1[?]
e2[?]]
if e1[=f ?]
?
Lex[> e2[?]
e1[?]]
otherwiseMOVE(e1[+f ?
])= [> e2[?]
e?1[?
]]where e2[-f ?]
is a unique subtree of e1[+f ?
]and e?1 is like e1 but with e2[-f ?]
replaced by an empty leaf node  : Figure 1: Definitions of MG operations MERGE and MOVE.
The first case of MERGE creates comple-ments, the second specifiers.
f ranges over Sel ?
Lic; ?
and ?
range over Syn?
; and e[?]
is an MGexpression whose head bears the feature-sequence ?.=f ?f ?MERGE?
?<=f ?
f ?MERGE?
?>+f ?-f ?MOVE ?
?>Figure 2: Graphical illustrations of definitions of MERGE and MOVE.
Rectangles represent single-nodetrees.
Triangles represent either single-node trees or complex trees, but the second case of MERGE appliesonly when the first case does not (i.e.
when the =f ?
tree is complex).3derivation of a complete expression, every inter-mediate derived expression will have at most |Lic|subtrees whose (head?s) first feature is of the form-g for any g ?
Lic.2.2 Multiple Context-Free GrammarsMultiple Context-Free Grammars (MCFGs) (Sekiet al 1991; Kallmeyer, 2010) are a mildlycontext-sensitive grammar formalism in the senseof Joshi (1985).2 They bring additional expressivecapacity over context-free grammars (CFGs) bygeneralizing to allow nonterminals to categorizenot just single strings, but tuples of strings.
Forexample, while a CFG might categorize eats cakeas a VP and the boy as an NP, an MCFG couldcategorize the tuple ?says is tall,which girl?
as aVPWH (intuitively, a VP containing a WH whichwill move out of it).
Correspondingly, MCFGproduction rules (construed as recipes for build-ing expressions bottom-up) can specify not only,for example, how to combine a string which is anNP and a string which is a VP, but also how tocombine a string which is an NP with a tuple ofstrings which is a VPWH.
The CFG rule whichwould usually be written ?S ?
NP VP?
is shownin (1) in a format that makes explicit the string-concatenation operation; (2) uses this notation toexpress an MCFG rule that combines an NP witha VPWH to form a string of category Q, an em-bedded question.
(We often omit angle bracketsaround one-tuples.)
An example application ofthis rule is shown in (3).st :: S ?
s :: NP t :: VP (1)t2st1 :: Q ?
s :: NP ?t1, t2?
:: VPWH (2)which girl the boy says is tall :: Q ?the boy :: NP ?says is tall,which girl?
:: VPWH(3)Every nonterminal in an MCFG derives (only) n-tuples of strings, for some n known as the non-terminal?s rank.
In the examples above NP, VP,S and Q are of rank 1, and VPWH is of rank 2.A CFG is an MCFG where every nonterminal hasrank 1.Michaelis (2001) showed that it is possible toreformulate MGs in a way that uses categorized2MCFGs are almost identical to Linear Context-FreeRewrite Systems (Vijay-Shanker et al 1987).
Seki et al(1991) show that the two formalisms are weakly equivalent.string-tuples, of the sort that MCFGs manipulate,as derived structures (or expressions) instead oftrees.
The ?purpose?
of the internal tree structurethat we assign to derived objects is, in effect, toallow a future application of MOVE to break themapart and rearrange their pieces, as illustrated inFig.
2.
But since the placement of the syntacticfeatures on a tree determines the parts that will berearranged by a future application of MOVE (in anyderivation of a complete expression), we lose norelevant information by splitting up a tree?s yieldinto the components that will be rearranged andthen ignoring all other internal structure.
Thus thefollowing tree:+f ?-f ?
-g ?
(4)becomes a tuple of categorized strings (we will ex-plain the 0 subscript shortly):?s : +f ?
, t : -f ?
, u : -g ?
?0or, equivalently, a tuple of strings, categorized bya tuple-of-categories:?s, t, u?
:: ?+f ?,-f ?,-g ?
?0 (5)The order of the components is irrelevant exceptfor the first component, which contains the entirestructure?s head node; intuitively, this is the com-ponent out of which the others move.Based on this idea, Michaelis (2001) showshow to construct, for any MG, a correspond-ing MCFG whose nonterminals are tuples like?+f ?,-f ?,-g ?
?0 from above.
The uniquenessrequirement in the definition of MOVE ensures thatwe need only a finite number of such nontermi-nals.
The feature sequences that comprise theMCFG nonterminals, in combination with the MGoperations, determine the MCFG production rulesin which each MCFG nonterminal appears.
Forexample, the arrangement of features on the treein (4) dictates that MOVE is the only MG opera-tion that can apply to it; thus the internals of thecomplex category in (5) correspondingly dictatethat the only MCFG production that takes (5) as?input?
(again, thinking right-to-left or bottom-upas in (1) and (2)) is one that transforms it in ac-cord with the effects of MOVE.
If ?
= , then this4effect will be to transform the three-tuple into atwo-tuple as shown in (6), since the t-componentnow has no remaining features and has thereforereached its final position:?ts, u?
:: ?
?,-g ?
?0 ?
?s, t, u?
:: ?+f ?,-f,-g ?
?0 (6)This is analogous ?
modulo the presence of theadditional u : -g ?
component ?
to the rule thatis used in the final step of the derivation in Fig.
5,which is the MCFG equivalent of Fig.
4.If, on the other hand, ?
6= , then the t-component will need to move again later in thederivation, and so we keep it as a separated com-ponent:?s, t, u?
:: ?
?, ?,-g ??0?
?s, t, u?
:: ?+f ?,-f ?,-g ?
?0 (7)The subscript 0 on the tuples above indi-cates that the corresponding expressions are non-lexical; for lexical expressions, the subscript is 1.This information is not relevant to MOVE oper-ations, but is crucial for distinguishing betweenthe complement and specifier cases of MERGE.For example, in the simplest cases where no to-be-moved subconstituents are present, the con-structed MCFG must contain two rules corre-sponding to MERGE as follows.
(n matches either1 or 0.
)st :: ??
?0 ?
s :: ?=f ?
?1 t :: ?f?n (8)ts :: ??
?0 ?
s :: ?=f ?
?0 t :: ?f?n (9)By similar logic, it is possible to constructall the necessary MCFG rules corresponding toMERGE and MOVE; see, for example, Stabler andKeenan (2003, p.347) for (a presentation of theMG operations that can also be straightforwardlybe read as) the general schemas that generate theserules.
One straightforward lexical/preterminal ruleis added for each lexical item in the MG, andthe MCFG?s start symbol is ?c?0.3 The resultingMCFG is weakly equivalent to the original MG,and strongly equivalent in the sense that one canstraightforwardly convert back and forth betweenthe two grammars?
derivation trees.
The MCFGequivalent of the MG in Fig.
3 is shown in Fig.
6(ignoring the weights for now, which we come tobelow).43We exclude ?c?1 on the simplifying assumption that thewho marie will praise :: ?c?0?marie will praise,who?
:: ?+wh c,-wh?0 :: ?=t +wh c?1 ?marie will praise,who?
:: ?t,-wh?0?will praise,who?
:: ?=d t,-wh?0will :: ?=v =d t?1 ?praise,who?
:: ?v,-wh?0praise :: ?=d v?1 who :: ?d -wh?1marie :: ?d?1Figure 5: The MG derivation from Fig.
4 illus-trated with tuples of strings instead of trees as thederived structures.Notation.
We define the above conversion pro-cess to be an (invertible) function pi from MGs toMCFGs.
That is, for an valid MG, G it holds thatpi(G) is an equivalent MCFG and pi?1(pi(G)) =G.
By abuse of notation, we will use pi as the func-tion for converting from MG derivation trees toequivalent MCFG derivation trees.
By an MCFGderivation tree we mean a tree like Fig.
5 but withnon-leaf nodes labelled only by nonterminals (nottuples of strings).
The derivation tree language ofan MCFG is thus a local tree language, just as fora CFG; that of an MG is non-local but regular (Ko-bele et al 2007).3 Distributions on DerivationsAssume a Minimalist Grammar, G. In this sec-tion and the next, we will consider various ways ofdefining probability distributions on the derivationtrees in ?
(G).5 The first approach, introduced inSection 3.2, is conceptually straightforward but isproblematic in certain respects that we discuss inSection 3.3.
We present a different approach thatresolves these problems in Section 4.We also consider the problem of estimating theparameters of these distributions from a finite sam-ple of training data, specified by a function f?
:?
(G) ?
N, where f?(?)
is the number of timesderivation ?
occurs in the sample.
To this end, itMG has no lexical item whose only feature is the selectee c.4This MCFG includes only the rules that are ?reachable?from the lexical items.
For example, we leave aside rulesinvolving the nonterminal ?=c v -wh?0, even though theschemas in Stabler and Keenan (2003) generate them.5We use the terms derivation tree and derivation inter-changeably.5?ERF2/2  :: ?=t +wh c?195/95  :: ?=t c?197/97 will :: ?=v =d t?16/6 often :: ?=v v?197/97 praise :: ?=d v?195/192 marie :: ?d?197/192 pierre :: ?d?12/2 who :: ?d -wh?1?ERF2/2 ?st, u?
:: ?+wh c,-wh?0 ?
s :: ?=t +wh c?1 ?t, u?
:: ?t,-wh?095/95 st :: ?=d t?0 ?
s :: ?=v =d t?1 t :: ?v?02/2 ?st, u?
:: ?=d t,-wh?0 ?
s :: ?=v =d t?1 ?t, u?
:: ?v,-wh?02/97 ts :: ?c?0 ?
?s, t?
:: ?+wh c,-wh?095/97 st :: ?c?0 ?
s :: ?=t c?1 t :: ?t?095/95 ts :: ?t?0 ?
s :: ?=d t?0 t :: ?d?12/2 ?ts, u?
:: ?t,-wh?0 ?
?s, u?
:: ?=d t,-wh?0 t :: ?d?195/100 st :: ?v?0 ?
s :: ?=d v?1 t :: ?d?15/100 st :: ?v?0 ?
s :: ?=v v?1 t :: ?v?02/3 ?s, t?
:: ?v,-wh?0 ?
s :: ?=d v?1 t :: ?d -wh?11/3 ?st, u?
:: ?v,-wh?0 ?
s :: ?=v v?1 ?t, u?
:: ?v,-wh?0Figure 6: The MCFG produced from the MG in Fig.
3, as described in Section 2.2; with weights com-puted by relative frequency estimation based on the naive parametrization, as described in Section 3.will be useful to define the empirical distributionon derivations to be p?(?)
= f?(?)/??
?
f?(??
).3.1 Stochastic MCFGsAs with CFGs, it is straightforward to imbuean MCFG, H , with production probabilities andthereby create a stochastic MCFG.6 In stochas-tic MCFGs (as in CFGs) the probability of a non-terminal rewrite in a derivation is conditionally in-dependent of all other rewrite decisions, given thenon-terminal type.
This formulation defines a dis-tribution over MCFG derivations in terms of a ran-dom branching process that begins with probabil-ity 1 at the start symbol and recursively expandsfrontier nodes N , drawing branching decisionsfrom the the conditional distribution p(?
| N); theprocess terminates when lexical items have beenproduced on all frontiers.If p(?
| N) is the probability that N rewrites as?
and f?
(N ?
?)
is the number of times N ?
?occurs in derivation tree ?
, thenp(?)
=?(N??)?Hp(?
| N)f?
(N??).
(10)With mild assumptions to ensure consistency (Chi,1999), the p(?
)?s form a proper probability distri-bution over all derivations in H .7Because the derivation trees of the MG G standin a bijection with the derivation trees of theMCFG pi(G), stochastic MCFGs can be used todefine a distribution on MG derivations.6Although MCFGs have a greater generative capacitythan CFGs, the statistical properties do not change at all, un-less otherwise noted.7The estimators that are based on empirical frequenciesin a derivation bank which we use in this paper will alwaysyield consistent estimates.
Refer Chi (1999) for more detail.3.2 The naive parametrizationThe most straightforward way to parameterize astochastic MCFG uses individual parameters ?
?|Nto represent each production probability, i.e., p(?
|N).= ?
?|N .
When applied to an MCFG that isderived from an MG, we will refer to this as thenaive parametrization.This is the parametrization used by Hale (2006)to define a probability distribution over the deriva-tions of MGs in order to explore the predictionsof an information-theoretic hypothesis concerningsentence comprehension difficulty.MLE.
The arguably most standard technique forsetting the parameters of a probability distributionis so that they maximize the likelihood of a sam-ple of training data.
In the naive parameterization,the maximum likelihood estimate (MLE) for eachparameter ?
?ERF?|N is the empirical relative frequencyof the rewrite N ?
?
in the training data (Abney,1997):?
?ERF?|N =??
f?(?)fpi(?
)(N ?
?)??
f?(?)?(N???
)?pi(G) fpi(?
)(N ?
??
).3.3 Unfaithfulness to MGsWhile the naive parameterization with MLE esti-mation is simple, it is arguably a poor choice forparameterizing distributions on MGs.
The prob-lem is that, relative to the independence assump-tions encoded in the MG formalism, each step ofthe MCFG derivation both conditions on and pre-dicts ?too much?
structure.
As a result, common-alities across different applications of the sameMG operation are modeled independently and donot share statistical strength.
This arises because690 pierre will praise marie5 pierre will often praise marie1 who pierre will praise1 who pierre will often praiseFigure 7: An artificial corpus of sentences deriv-able from the grammars in Figures 3 and 6.of the way the MCFG?s nonterminals multiply outall relevant arrangements of features.8 We illus-trate the problem with an example.Consider the corpus in Fig.
7, where each sen-tence is preceded by its frequency.
Since each sen-tence is assigned a unique derivation by our exam-ple MG, this is equivalent to a treebank.One reasonable statistical interpretation of thefirst two lines is that a verb phrase comprises averb and an object 95% of the time, and comprisesthe adverb often and another verb phrase 5% ofthe time (since pierre will often praise marie hastwo nested verb phrase constituents).
The last twolines provide an analogous pair of sentences in-volving wh-movement of the object.
A priori, onewould expect that the 95:5 relative frequency thatdescribes the presence of the adverb also applieshere; however, the ERF estimator will use 2:1 in-stead.
Why is this?
The VP category in the MCFGis ?split?
into two to indicate whether it has a wh-feature inside it, and each has its own parameters.We criticize this on the grounds that it is not in linewith our main goal of defining a distribution overthe derivations of the MG: from the perspective ofthe MG, there is a sense in which it is ?the sameinstance?
of MERGE that combines often with averb phrase, whether or not the verb phrase?s ob-ject bears a -wh feature.
In other words, the differ-ences between the following two trees seem unre-lated to the way in which they are both candidatesto be merged with often : =v v.<praise : v who : -wh<praise : v marie :From the perspective of the MCFG, however, theintroduction of the adverb is mediated by expan-sions of the nonterminal ?v?0 in cases withoutobject wh-movement, but by expansions of thedistinct nonterminal ?v,-wh?0 in cases with it.Therefore the information about adverb inclusionthat is conveyed by the movement-free entries in8Stabler (forthcoming) also discusses the sense in whichMCFG rules ?miss generalizations?
found in MGs.the corpus is interpreted as only relevant to simi-larly movement-free derivations.
This can be seenin the weights of the last four rules in Fig.
6, whichwere computed by relative frequency estimationon the basis of the corpus.Relative to the underlying MG, the naiveparametrization has too many degrees of freedom:the model is overparameterized and is capable ofcapturing statistical distinctions that we have the-oretical reasons to dislike.
Of course, it is possi-ble that VPs have meaningfully different distribu-tions depending on whether or not they contain awh-feature; however, we would like a parameter-ization that provides the flexibility to treat thesetwo different contexts as identical, as different, orto share statistical strength between them in someother way.
In the next section we propose twoalternative parametrizations that provide this con-trol.4 Log-linear MCFGs4.1 Globally normalized log-linear modelsAn alternative mechanism for inducing a distribu-tion on ?
(G) that provides more control over in-dependence assumptions is the globally normal-ized log-linear model (also called a Markov ran-dom field, undirected model, or Gibbs distribu-tion).
Unlike the model in the previous section,log-linear models are not stochastic in nature?they assign probabilities to structured objects, butthey do not rely on a random branching processto do so.
Rather, they use a d-dimensional vectorof feature functions?
= ?
?1,?2, .
.
.
,?d?, where?i : ?
(G) ?
R, to extract features of the deriva-tion, and a real-valued weight vector ?
?
Rd.9Together, ?
and ?
define the score of a derivation?
as a monotonic function of the weighted sum ofthe feature values ?1(?
), .
.
.
,?d(?):s?(?)
= exp(?
??(?
)).Using this function, a Gibbs distribution on thederivations in ?
(G) isp?(?)
=s?(?)??
???
(G) s?(??
), (11)9The term feature here refers to functions of a derivation;it should not be confused with the syntactic features dis-cussed immediately above.
However, in as much as syntacticfeatures characterize the steps in a derivation, it is natural thatthey would play a central role in defining distributions overderivations, and indeed, our proposed feature functions ex-amine syntactic features almost exclusively.7provided that the sum in the denominator is fi-nite.10Notice that (11) is similar to the formula fora relative frequency, the difference being that weuse a derivation?s score s?(?)
rather than its em-pirical count.
This use of scores provides a wayto express the kind of ?missed similarities?
wediscussed in Section 3.3 via the choice of featurefunctions.
Returning to the example from above,in order to express the similarity between the twoadverb-introducing rules ?
one involving the non-terminal ?v?0, the other involving ?v,-wh?0 ?we could define a particular feature function ?ithat maps a derivation to 1 if it contains either oneof these rules and 0 otherwise.
Then, all else be-ing equal, setting the corresponding parameter ?ito a higher value will increase the score s?(?
),and hence the probability p?(?
), of any derivation?
that introduces an adverb, with or without wh-movement of the object.MLE.
As with the naive parameterization, thethe parameters ?may be set to maximize the (log)likelihood of the training data, i.e.,??
= arg max?n?i=1p?(?i)f?
(?i)= arg max?n?i=1f?
(?i) log p?(?i)?
??
?=L [log likelihood].
(12)We remark that maximizing the log likelihoodof data in this parameterization is equivalent tofinding the distribution p?(?)
in which the ex-pected value of ?(?)
is equal to the expectedvalue of the same under the empirical distribution(i.e., under p?(?))
and whose entropy is maximized(Della Pietra et al 1997).
This equivalence is par-ticularly clear when the gradient of L (see (12))with respect to ?
is examined:?
?L = Ep?(?)[?(?)]?
Ep?(?)[?(?)].
(13)This form makes clear thatL achieves an optimumwhen the expectations of ?
match under the twodistributions.1110There are several conditions under which this is true.
Itis trivially true if |?
(G)| < ?.
When ?
is infinite, the de-nominator may still be finite if features functions grow (su-per) linearly with the derivation size in the limiting case asthe size tends to infinity.
Then, if feature weights are nega-tive, the denominator will either be equal to or bounded fromabove by an infinite geometric series with a finite sum.
Referto Goodman (1999) and references therein.11While the maximizing point cannot generally be solved4.2 Feature localityNotice that the approach just outlined is extremelygeneral: the feature functions ?
can examine thederivation trees as a whole.
It is possible to definefeatures that pay attention to arbitrary or globalproperties of a derivation.
While such featuresmight in fact generalize well to new data ?
for ex-ample, one could mimic a bigram language modelby including features counting bigrams in thestring that is generated by the derivation ?
theseare intuitively ?bad?
since they ignore the deriva-tion?s structure.
Furthermore, there is a substantialpractical downside to allowing unrestricted featuredefinitions: features that do not ?agree?
with thederivation structure make inference computation-ally intractable.
Specifically, finding the best mostprobable derivation of a sentence with ?global?features is NP-hard (Koller and Friedman, 2009).For these reasons, it is advantageous to requirethat ?
decompose additively in terms of local fea-ture functions, ?
over the steps that make up aderivation.
For defining distributions under an MGG, we will assume that feature functions decom-pose over the productions in a derivation under theMCFG projection pi(G), i.e.,?(?)
=?(N??)?pi(?)?
(N ?
?)
.Under the locality assumption, we may rewrite thescore s?(?)
as?(N??)?pi(G)(exp(?
??
(N ?
?)))fpi(?)(N??)
.This (partially) addresses the issue of computa-tional tractability, enforces our intuition that thescore of a derivation tree should be a function ofscores of its component steps, and still gives us theability to avoid the overconditioning that we iden-tified in Section 3.3.124.3 Locally normalized log-linear modelsEven with our assumption of feature locality, find-ing ??
remains challenging since the second termfor analytically, gradient based optimization techniques maybe effectively used to find it (and it is both guaranteed to existand guaranteed to be unique).12We say that the issue of computational tractability is onlypartially resolved because only certain operations ?
identi-fying the most probable derivation of a string ?
are truly ef-ficient.
Computing the model?s normalization function, whileno longer NP-hard, still not practical.8in (13) is difficult to compute.13 In this section wesuggest a parameterization that admits both effi-cient ML estimation and retains the ability to usefeature functions to control the distribution.To do so, we revisit the approach of definingdistributions on derivations in terms of a stochas-tic process from Section 3.1, but rather than defin-ing the branching distributions with independentparameters for each MCFG nonterminal rewritetype, we parameterize it in terms of locally nor-malized log-linear models, also called a condi-tional logit model (Murphy, 2012).
Given an MGG, a weight vector w ?
Rd, and rule-local featurefunctions ?
as defined above,14 let the branchingprobabilitypw(?
| N).=exp(w ??
(N ?
?))?(N???
)?pi(G) exp(w ??
(N ?
??
)).Like the parametrization in Section 4.1, thisnew parametrization is based on log-linear mod-els and therefore allows us to express similaritiesamong derivational operations via choices of fea-ture functions.
However, rather than defining fea-ture functions ?i on entire derivations, these fea-tures can only ?see?
individual MCFG rules.
Putdifferently, the same technique we used in Sec-tion 4.1 to define a probability distribution over theentire set of derivations, is used here to define eachof the local conditional probability distributionsover the expansions of a single MCFG nontermi-nal.
Via the perspective familiar from stochasticMCFGs, these individual conditional probabilitydistributions together define a distribution on theentire set of derivations.MLE.
As with the previous two models, we canset parametersw to maximize the likelihood of thetraining data.
Here, the global likelihood is ex-pressed in terms of the probabilities of condition-ally independent rewrite events, each defined in alog-linear model:Lc =??f?(?)?(N??)?pi(?)fpi(?
)(N ?
?)
log pw(?
| N).13Specifically, it requires computing expectations under allpossible derivations in ?
(pi(G)) during each step of gradientascent, which requires polynomial space/time in the size ofthe lexicon to compute exactly.14The notational shift from?
tow to emphasizes that thesetwo parameter vectors have very different semantics.
Theformer parameterizes potential functions in a globally nor-malized random field while the later is used to determine afamily of conditional probability distributions used to definea stochastic process.Its gradient with respect to w is therefore?wLc =??f?(?)?(N??)?pi(?)fpi(?
)(N ?
?)[?
(N ?
?)?
Epw(??|N)?
(N ?
??
)].As with the globally normalized model, ?wLc =0 has no closed form solution; however, gradient-based optimization is likewise effective.
How-ever, unlike (13), this gradient is straightforward tocompute since it requires summing only over thedifferent rewrites of each non-terminal categoryduring each iteration of gradient ascent, ratherthan over all possible derivations in ?
(G)!4.4 Example parameter estimationIn this section we compare the probability esti-mates for productions in a stochastic MCFGs ob-tained using the naive parameterization discussedin Section 3.2 that conditions on ?too much?
infor-mation and those obtained using locally normal-ized log-linear models with grammar-appropriatefeature functions.
Our very simple feature set con-sists just of binary-valued feature functions that in-dicate:?
whether a MERGE step, MOVE step, or a termi-nating lexical-insertion step is being generated;?
what selector feature (in the case of MERGEsteps) or licensor feature (in the case of MOVEsteps) is being checked (e.g., +wh or =d or =v);and?
what lexical item is used (e.g., marie : d or : =t c), in the case of terminating lexical-insertion steps.Table 1 shows the values of some of these featuresfor a sample of the MCFG rules in Fig.
6.Table 2 compares the production probabilitiesestimated for last four rules in Fig.
6 using thenaive empirical frequency method and our recom-mended log-linear approach with the features de-fined as above.15 The presence or absence of a-wh feature does not affect the log-linear model?sprobability of adding an adverb to a verb phrase,in keeping with the perspective suggested by thederivational operations of MGs.15The log-linear parameters were optimized using a stan-dard quasi-Newtonian method (Liu and Nocedal, 1989).9Table 1: Selected feature values for a sample of MCFG rules.
The first four rules are the ones thatillustrated the problems with the naive parametrization in Section 3.3.MCFG Rule ?MERGE ?=d ?=v ?=t ?MOVE ?+whst :: ?v?0 ?
s :: ?=d v?1 t :: ?d?1 1 1 0 0 0 0st :: ?v?0 ?
s :: ?=v v?1 t :: ?v?0 1 0 1 0 0 0?s, t?
:: ?v,-wh?0 ?
s :: ?=d v?1 t :: ?d -wh?1 1 1 0 0 0 0?st, u?
:: ?v,-wh?0 ?
s :: ?=v v?1 ?t, u?
:: ?v,-wh?0 1 0 1 0 0 0st :: ?c?0 ?
s :: ?=t c?1 t :: ?t?0 1 0 0 1 0 0ts :: ?c?0 ?
?s, t?
:: ?+wh c,-wh?0 0 0 0 0 1 1Table 2: Comparison of probability estimators.MCFG Rule Naive p?
Log-linear p?st :: ?v?0 ?
s :: ?=d v?1 t :: ?d?1 0.95 0.94st :: ?v?0 ?
s :: ?=v v?1 t :: ?v?0 0.05 0.06?s, t?
:: ?v,-wh?0 ?
s :: ?=d v?1 t :: ?d -wh?1 0.67 0.94?st, u?
:: ?v,-wh?0 ?
s :: ?=v v?1 ?t, u?
:: ?v,-wh?0 0.33 0.065 Conclusion and Future WorkWe have presented a method for inducing a prob-ability distribution on the derivations of a Min-imalist Grammar in a way that remains faithfulto the way the derivations are conceived of inthis formalism, and for obtaining the maximumlikelihood estimate of its parameters.
Our pro-posal takes advantage of the MG-MCFG equiva-lence in the sense that it uses the underlying prob-abilistic branching process of a stochastic MCFG,but avoids the problems of overparametrizationthat come with the naive approach that reifies theMCFG itself.Our parameterization has several applicationsworth noting.
It provides a new way to comparevariants of the MG formalism that propose slightlydifferent sets of primitives (operations, types offeatures, etc.)
but are equivalent once transformedinto MCFGs.
Examples of such variants includethe addition of an ADJOIN operation (Frey andGa?rtner, 2002), or replacing MERGE and MOVEwith a single feature-checking operation (Stabler,2006; Hunter, 2011).
Derivations using these dif-ferent versions of the formalism often boil downto the same string-concatenation operations andwill therefore be expressible using equivalent setsof MCFG rules.
The naive parametrization willtherefore not distinguish them, but in the sameway that our proposal above ?respects?
standardMGs?
classification of MCFG rules according toone set of derivational primitives, one could de-fine feature vectors that respect different classifi-cations.Outside of MGs, the strategy is applicable toany other formalisms whose derivations can be re-cast as those of MCFGs, such as TAGs and CCGs.More generally still, it could be applied to anyformalism whose derivation tree languages can becharacterized by a local tree grammar; in our case,the relevant local tree language is obtained via aprojection from the regular tree language of MGderivation trees.AcknowledgmentsThanks to John Hale for helpful discussion and tothe anonymous reviewers for their insightful com-ments.
This work was sponsored by NSF awardnumber 0741666, and by the U. S. Army ResearchLaboratory and the U. S. Army Research Officeunder contract/grant number W911NF-10-1-0533.ReferencesSteven P. Abney.
1997.
Stochastic attribute-valuegrammars.
Computational Linguistics.Zhiyi Chi.
1999.
Statistical properties of probabilisticcontext-free grammars.
Computational Linguistics.Stephen Della Pietra, Vincent Della Pietra, and JohnLafferty.
1997.
Inducing features of random fields.IEEE Transactions on Pattern Analysis and MachineIntelligence, 19(4).10Werner Frey and Hans-Martin Ga?rtner.
2002.
On thetreatment of scrambling and adjunction in minimal-ist grammars.
In Gerhard Ja?ger, Paola Monachesi,Gerald Penn, and Shuly Wintner, editors, Proceed-ings of Formal Grammar 2002, pages 41?52.Joshua Goodman.
1999.
Semiring parsing.
Computa-tional Linguistics, 25(4).John Hale.
2006.
Uncertainty about the rest of thesentence.
Cognitive Science, 30:643?672.Tim Hunter.
2011.
Insertion Minimalist Gram-mars: Eliminating redundancies between merge andmove.
In Makoto Kanazawa, Andra?s Kornai, Mar-cus Kracht, and Hiroyuki Seki, editors, The Mathe-matics of Language (MOL 12 Proceedings), volume6878 of LNCS, pages 90?107.
Springer, Berlin Hei-delberg.Aravind Joshi.
1985.
How much context-sensitivityis necessary for characterizing structural descrip-tions?
In David Dowty, Lauri Karttunen, andArnold Zwicky, editors, Natural Language Process-ing: Theoretical, Computational and PsychologicalPerspectives, pages 206?250.
Cambridge UniversityPress, New York.Laura Kallmeyer.
2010.
Parsing Beyond Context-FreeGrammars.
Springer-Verlag, Berlin Heidelberg.Gregory M. Kobele, Christian Retore?, and Sylvain Sal-vati.
2007.
An automata theoretic approach tominimalism.
In James Rogers and Stephan Kepser,editors, Proceedings of the Workshop on Model-Theoretic Syntax at 10; ESSLLI ?07.Daphne Koller and Nir Friedman.
2009.
ProbabilisticGraphical Models: Principles and Techniques.
MITPress.Dong C. Liu and Jorge Nocedal.
1989.
On the limitedmemory BFGS method for large scale optimization.Mathematical Programming B, 45(3):503?528.Jens Michaelis.
2001.
Derivational minimalism ismildly context-sensitive.
In Michael Moortgat, ed-itor, Logical Aspects of Computational Linguistics,LACL 1998, volume 2014 of LNCS, pages 179?198.Springer, Berlin Heidelberg.Kevin P. Murphy.
2012.
Machine Learning: A Proba-bilistic Perspective.
MIT Press.Hiroyuki Seki, Takashi Matsumara, Mamoru Fujii, andTadao Kasami.
1991.
On multiple context-freegrammars.
Theoretical Computer Science, 88:191?229.Edward P. Stabler and Edward L. Keenan.
2003.
Struc-tural similarity within and among languages.
Theo-retical Computer Science, 293:345?363.Edward P. Stabler.
1997.
Derivational minimalism.
InChristian Retore?, editor, Logical Aspects of Compu-tational Linguistics, volume 1328 of LNCS, pages68?95.
Springer, Berlin Heidelberg.Edward P. Stabler.
2001.
Recognizing head move-ment.
In Philippe de Groote, Glyn Morrill, andChristian Retore?, editors, Logical Aspects of Com-putational Linguistics, volume 2099 of LNCS, pages254?260.
Springer, Berlin Heidelberg.Edward P. Stabler.
2006.
Sidewards without copying.In Shuly Wintner, editor, Proceedings of The 11thConference on Formal Grammar, pages 157?170.CSLI Publications, Stanford, CA.Edward Stabler.
forthcoming.
Two models of min-imalist, incremental syntactic analysis.
Topics inCognitive Science.K.
Vijay-Shanker, David J. Weir, and Aravind K.Joshi.
1987.
Characterizing structural descriptionsproduced by various grammatical formalisms.
InProc.
25th Meeting of Assoc.
Computational Lin-guistics, pages 104?111.11
