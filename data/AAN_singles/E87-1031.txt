PLANNING FOR PROBLEM FORMULATIONIN ADVICE-G IV ING D IALOGUEPaul Decitre, Thomas  Grossi, C14o Jullien, Jean-Philippe SolvayCap Sogeti InnovationCentre de Recherche de GrenobleChemin  du Vieux Ch ine38240 Meylan,  FranceAbst rac tWe dist inguish three main,  overlapping activities in anadvice-giving dialogue: problem formulat ion,  resolution,and explanat ion.
This  paper focuses on a problem for-mulat ion activity in a dialogue module  which interactson one side with an expert  problem solver for financialinvesting and on the other side with a natura l  languagefront-end.
Several strategies which reflect specific aspectsof person-machine advice-giving dialogues are realized byincorporating planning at a high-level of dialogue.In t roduct ionAs performances and scope of intelligent systems in-crease and the interaction of a system with a user gains incomplexity, it becomes desirable to provide an easy initialaccess to a system for the novice user.
Natural languageis a med ium presumably known by most users.
For thesystem however, it not only requires understanding nat-ural language "utterances" (on a keyboard) but also rec-ogni~.ing the intentions behind these utterances.
It leadsto a full-fledged dialogue involving much reasoning at thepragmatic level of the communication process.
The com-petence of most intelligent systems is usually bound toa restricted application domain and we can imagine thatpart of a dialogue is domain-dependent while another isdomain-independent.
Our  efforts aim at designing a dia-logue module making these different aspects explicit andinteracting with other knowledge-based agents.
This workcontributes to Esprit Project 816 EsteamX:  An architec-ture for distributed problem solving by cooperating dataand knowledge bases.
Advice-giving systems for financialinvestment have been chosen as a first testbed application.This paper describes preliminary research on the dialoguemodule of such a system and the resulting prototype.An  advice-giving dialogue comprises three main activ-ities, which may overlap:- l~wblsm form,dug/on, where the various needs and ca-pabilities of the user are elicited;- reso/uh'on, in which a possible solution to the problemis determined;- ezpla~;tion, which aims at convincing the user thatIThe project is supported in part by the Commission ofthe European Communitiesthe solution is in fact what she/he needs.Our work concentrates on a problem formulation activityin a dialogue module which cooperates with a problemsolver and a natural language front-end.
The problemsolver selects adequate securities for basic investment sit-uations of a private investor and is being developed aspart of the same Esprit project \[Bruffaerts 1986\].
Thenatural language front-end based on functional grammarsis the result of separate research at Cap Sogeti Innovation\[Fimbel 1985, Lancel 1986\].Computat iona l  AspectsDialogue and communicat ion  theory are a broad fieldof studies drawing on several disciplines, among them phi-losophy, cognitive science, and artificial intelligence.
Theflurry of research devoted to these topics in recent yearsis largely enough to convince us we could not seriouslyhope to tackle the "general" problem.
We have thereforelimited our interest to person-machine advice-giving dia-logue and we focus on two essential characteristics of thiskind of dialogue:- the system has intentions and extensive knowledgeabout the domain which are a pr/or/unknown to theuser;- the user 's  intent ions must  be interpreted in terms ofthe sys tem's  abilities or inabilities.We can see the first point as a manifestation of the "ex-pertness" of the system, and the second as a manifestationof the Unoviceness~ of the user.We briefly recall some other research issues connectedto our work and then elaborate on the specific aspects ofperson-machine advice-giving dialogue.Many  efforts have been devoted to developing a generaltheory for speech act understanding \[Searle 1969, Allen1980, Cohen 1979\].
Recognizing the illocutionary forceof a speech act allows the system to reason about theintentions of the user and to behave accordingly.
Mostwork in this field addresses only isolated speech acts orsometimes single utterances and is not concerned with apossible dialogue setting.
Recent attempts, however, forreformulating speech act analysis inside a general theoryof action {Cohen 1986\] or for applying default reasoningto speech act understanding \[Perrault 1986\] may yet facil-itate an extension to a whole dialogue.
Another line of re-search has taken into account the dialogue dimension \[Lit-man 1984, Wilensky 1984, Carberry 1986\] and shown thestrong interrelation between dialogue and plans but has186been mostly concerned with information-seeking dialoguesin which the user seems to have an implicit knowledge ofwhat the system can or cannot do.
These dialogues of-ten produce patterns of the type "question from the userrequiring adequate answer from the system" and seldomconsider a possible initiative on the system's behalf.
Dia-logue parsing is yet another approach which attempts toformalize the surface structure of a dialogue \[Reichman1984, Wachtel 1986 I.
It could however lead to some rigid-ity in the interaction between the user and the system;for instance, it may  not provide the adequate primitiveelements to detect and repair communicative failures inthe dialogue.
A possible way out would be to accountfor this surface structure of dialogue within a theory ofpragrnatics \[Airenti 1986\].In person-machine advice-giving dialogue the challengewe face is how to make the expert ise of the system acces-sible to the user in order to satisfy her /h is  needs: the "ex-pertness" of the system and the "novicenees" of the userforce a compromise between the system control l ing thedialogue and the user expressing her /h imse l f  freely.
Wechose to rely on the system for conduct ing the dialoguewithout however ignoring the initiative of the user, whichis to be examined within the intentional framework of thesystem.
In the course of our research, we have derived afew general strategies which typify our approach.?
Whenever  possible, the system should set a clear back-ground to the conversation.
This  is part icularly true ofthe beginning of a session, where the system should notleave the user in the dark but  should at once define itsown competence and suggest possible options to the user.This initial sett ing will reflect the global- purpose of thedialogue and its expected unfolding.?
Each step of a dialogue takes place in a certain context.We must  ensure a common perception of this context bythe user and the system if we want a meaningful  exchangebetween them.s It is worth tak ing advantage of what the system canexpect from the user when the latter "takes the floor" toguide the search of a correct interpretat ion and quicklydecide the best-suited reaction.
We should make theseexpectat ions of the system apparent in our model of di-alogue.
Nevertheless, we want the system to allow foruser digressions, such as the introduct ion of a new topicor the correction of a previous s tatement .
It is impor-tant to note that  a sophist icated ialogue managementwhich would allow the system to react adequately to thisunexpected behavior  of the user should not impair  thestraightforward and most  probable reaction described justbefore.
It should rather  be called upon as a second bestchoice when the first one has failed, thus defining a pref-erence hierarchy among possible reactions of the system.
(In other words, first the c lear-minded and obedient user,then the muddle-minded onel)?
The form of the interaction between a user and anadvice-giver evolves with the experience they have of eachother and the increase of their mutua l  knowledge, either inthe course of a same session or through several sessions.The dialogue system should gradual ly lead the user to-ward a s impler and more e/~lcient interface by suggest ingthe adequate jargon and steps which would allow the userto quicker and better  formulate her /h is  problem \[Slator19861 .Descr ip t ion  o f  the  P ro to type?
Wor ldThe  World of our dialogue module consists of a setof objects among which several relations and inheritancemechanisms are defined.
For instance, there are classicalis-a links, part-of links (a cash-need is part of the invest-ment plan) and specification links (an amount is "specified"by a number and a currency).Parts of this semantic network are shared with otheragents than the dialogue agent, or at least have the samerepresentation in other agents.
This is the case betweenthe dialogue module and the problem solver for the prob-lem formulation phase: a model of the expected problemis represented in the World.For our application', the expected problem consists ofan investment plan expressed in terms of the basic invest-ment situations for which the problem solver is able to se-lect the adequate securities.
It may  include an emergency-fund, i.e., an amount of money  which should be availableat random time within a given delay, or a cash-need, i.e.,an amount of money which should be available at a givendate.
These financial objects in the problem model arerelated to objects describing goals and situations of theuser's everyday world through rsqu/rvrn~nat links.
For in-stance, buying a car in five years may necessitate a cash-need, while covering unexpected expenses may ask for anemergency-fund.
These reqm'mment links will guide therecognition of the user plan when resolving references.Other  domain knowledge for the problem formulat ion di-alogue is encoded in terms of the problem model objectsand includes preferred sequences for the interaction withthe user and constraints on these objects.For the dialogue module,  the user is considered as an-other agent and her /h is  intentions and mental  states arerepresented in terms of posit ions toward objects of the di-alogue.
Examples of such posit ions are 'user understandsX' ,  ' system wants to know the value of X', or 'user wantsX to take a certain value'.
We can view the objects andposit ions as represent ing respectively static and dynamicinformation in the  system and allowing the exchange ofinformation between agents.?
Focus -Stack  and  AgendaWe can characterize each step of the dialogue by a givenattent ional  focus and a given task for the system.
In ourdialogue module these correspond respectively to a par-t i tu lar  object - -  or set of objects - -  under  discussion andto an action of the system.Dur ing the dialogue, the focus of attent ion obviouslyevolves along a chronological dimension: one subject ata t ime.
But  a deeper analysis (el., for example,  \[Grosz1985\]) reveals a layered structure .
In the current pro-totype, these layers of foci come into play in refinementand digression.
Ref inement occurs when the t reatmentof a complex object is split into sub-dialogues about itsparts: dur ing such a sub-dialogue, the "parent" and "sib-ling" objects const i tute background context layers.
Atypical digression takes place when the system suspendsinformat ion-gather ing to give an explanat ion and comesback to the suspended step of the dialogue.
The systemkeeps track of the active layers of foci in the Focus-Stack.The sequence of actions the system has currentlyplanned to perform are stored in the Agenda.187?
A rch i tec tureThe dialogue module contains four sub-modules: theINTERPRETER and the GENERATOR are in charge of relat-ing logical form expressions of the natural language front-end to meanings about the World, the EXECUTOR carriesout communicative-games for interacting with the user,and the REACTOR activates metaplans for updating theAgenda and the Focus-Stack.The next sections of this paper investigates in greaterdetail how the metaplans and communicative-gamesmodel the possible actions and strategies of the systemand enter into the dialogue planning process.
An  accounton other aspects of this prototype may be found in a pre-vious technical report \[Decitre 1986\].H igh-Leve l  P lann ing  in  the  REACTORFrom the dialogue module's point of view, the entireconversation results from the goal, "Obtain an investmentplan problem specification from the user".
The goal is ex-panded according to the problem model into appropriatesubgoMs, which are pushed onto the Agenda for sequen-tial execution.
As each subgoal is considered, it may befurther expanded as necessary.
In other words, the de-composition of the communicative intentions (obtainingspecifications) reflects the decomposition of the task in-tentions (investing).
There exist two types of metaplans:the metaplans for expanding the Agenda and the meta,plans for revising it according to some initiative from theuser.?
Expans ionAs an illustration of the first type of metaplans, letus consider what happens at the beginning of an advice-giving session.
When the dialogue starts, the Agenda con-sists solely of a single action t~atCinsest-plaa ).
A treat actionbasically corresponds to a sequence of three steps: presen-tation of the object to the user, asking for values whichspecify this object, and finally asking for confirmation.But the expansion of treat actions can vary according tothe type of their argument.
For instance, an object may beeither simple or complex, it may also be visible or trans-parent.
A transparent object is part of the structure of theproblem model but remains invisible to the user.
This isthe case for p~b~insest -p /an)  which consists of the setof the parts of an investment plan, /.e., {emews~U-yum/,cadL-need*,/o~-term}.
These transparent objects attemptto model the differences which may exist between howthe problem model is organised and how it may be per-ceived by the user.
For a complex object, the expansionintroduces treatment~ for the parts of the complex object,whereas imple objects have only specifications.Let us just show how these expansion metaplans ac-count for the first two of our general strategies.The expansion of the initial goal tvest(inee#t-plan~ postsa prcsent(ineest-plan) onto the Agenda.
The presentationof a complex object such as in,eat-p/an reflects how it willbe expanded, since the same source of information, i.e.,the problem model, is used for presentation and expan-sion, and thus provides a background setting for the di-alogue.
The order - -  in this case obligatory - -  in whichthe sub-objects of in~eJt-plan are considered is: first, thetota/-amount for the plan; second, the pa~tion(in~est-plan).The latter is a transparent object for which adequate pre-sentation rules are defined: the presentation of a partitionsimply entails a presentation of all parts.
The natural lan-guage front-end actually generates the following descrip-tion:system-"investment-plan: An investment plan ischaracterized by a total amount and is usually com-posed of an emergency-fund, one or several cash-needsand a long-term investment.
"Update of the Focus-Stack is also governed by the expan-sion, and a layer containing all the objects introduced inthis presentation is pushed onto the stack.
The presentexample gives \[toto3-amount, emergen~p-fun~l, co.h-need, Ion4-term\].
We see again the effect of transparency: the partsthemselves are directly pushed onto the stack and not thepartition.
This layer will constitute the backup layer ofthe Focus-Stack associated to the overall dialogue setting.At this stage, the next action on the Agenda ist~at(totoi-~mount) which may be further expanded in pu~h-focua, o,~k-i~Jo-game, ckeek-com~ete, pop-focus.
The ask-info-game is a communicative game which asks a questionabout the total-amount object:system - 'What  is the total amount of your plan ofinvestment?
"and waits for the response of the user.
The communica-tive game is designed to induce the user to specializeher/his focus of attention toward the refined context otal-~mount, and pud~-Jocu~(total-~nount) places this object onthe Focus-Stack, updating it correspondingly.?
Rev is ionOur plan generation is simplified because the executionof one subgoal cannot invalidate another, so a constantmonitoring of preconditions is obviated; but this is morethan made up by the difficulW in accommodating possiblechanges to the plan necessitated ble the user's input.
Thechoice of a planning process which either expands or re-pairs an existing plan reflects our third strategy.
Indeed,the natural expansion of a plan can be seen as correspond-ing to the expected behavior of the user and the revisionsonly happen when the user takes the initiative.
In thisapproach, the reasoning which takes place when the userfollows the expected course is reduced to its minimum andonly digressions require extra efforts.Interactions with the user are handled through com-municative games and a special metaplan reacts when acommunicative game appears on top of the Agenda.
Thismetaplan triggers the execution of the game and ann-lyres the outcome of the execution to decide consequentlythe updates to the Agenda.
If the game has completelysucceeded, /.e.
all responses of the user fit the expecta-tions, the communicative game is simply removed fromthe Agenda and replaced by ok-~e~'t actions for each newposition expressed by the user.
Otherwise there exist un-expected responses and different actions are pushed ontothe Agenda in such a way that the expected positions willbe analysed first by means of ok-react actions, then un-expected positions concerning the current focus and un-expected positions outside the current focus by means ofnot-ok-react actions.
For all these not-ok-re~ct actions, thereare metaplans to consider the precise situation and todecide an appropriate reaction, with rearrangement andother modifications made as necessary to the Agenda ofpending actions.
Delaying the expansion of plans until it188becomes necessary to execute them facilitates taking intoaccount the effect of the user's responses on goals notyet addressed, as in, for example, the verification of con-straints which the various parts of the problem definitionimpose on one another, or in noticing that the value of amissing variable can be computed from the combinationof other values the user has already given.What  sorts of snags can occur in a dialogue that mightforce the system to revise its plans?
Our problem modelprovides certain relations which must hold between val-ues provided by the user.
The user might, however,give a value which is in conflict either with one of theseconstraints or with values previously given.
We mustpoint out the sticking-point and help the user resolvethe conflict.
The serify-cor~straird metaplan pushes a me~-con~trsint-game onto the Agenda.
This game will presentthe local constraint which led to refusing the new posi-tion expressed by the user and the justifications whichrelate this local constraint to the global constraints of theproblem model.
Consider, for instance, a simple equalityconstraint between the total amount and the sum of theamounts  of the parts.
Wi th  a $20,000 total-amount anda $5,000 amount for the eme~encp/um/, a $16,000 assign-value position for the amount of the ca.sh-~cd would bringsystem -"The amount of your cash-need should beless than or equal to $15.000 for consistency with thetotal amount.
"We also have preferences (and somet imes obligations)in the ordering of the various points to be addressed ur-ing the conversation, but  the user  might  not respect hem.For instance, the user might  at any moment  decide tochange subject,  in which case we must  consider the effectsof the switch: if, for example,  she /he  asks to back up inthe conversation to change someth ing  which was of neces-sity addressed before the current subject,  this could forcerevision of all the values given since that  point up to thepresent.
Based on the following situations, we identifythree classes of change-~b'ject metaplans,  which can trig-ger when the new posit ion expressed by the user bearson a context which is not the current  focus and modifyaccordingly the Agenda:- the  current focus must  be treated before the newsubject introduced by the user (according to se-quencing policies in the problem model),- the  subject the user would like to examine has al-ready been treated and a modif ication would haveconsequences on what has been discussed since,- there is no sequencing difficulty.If the user asks for explanation of some point whichshe/he doesn't understand, the system enters a digressionin the dialogue, after which the original topic is resumed.Low-Leve l  P lann ing  and  the  EXECUTORAs discussed above, the decomposit ion of a plan oftenengenders the need for interaction with the user.
Thisis done through the communicat ive games.
Basically acommunicat ive game aims at representing a pair of turnsbetween the user  and the system,  e.g., quest ion/answer.
(In fact, we also need to model one-turn games for thetransit ions between phaees, e.g., in t roduct ion / resumpt ionof a new/old subject).
A l though we can never be surethe second turn  will take place as desired, the interestof representing games is to provide local expectat ions forthe interpretation of the response of the user.
It shouldbe noted that our intention in using these communicativegames is not to impose a structure on the dialogue be-tween the user and the system: these games correspondto an ideal dialogue in which the user would always re-spond as expected.
The actual dialogue is a successionof communicative games which may fail, thereby reacti-vating the high-level planning process described in theprevious section.With each communicative game is associated an out-meaning which indicates the semantic content to be con-veyed to the user when the game is executed.
This oral-meaning is expressed in the internal language of the dia-logue module in which mostly appear objects of the prob-lem model.
Adequate references in logical form to theseobjects are provided by the GENERATOR of the dialoguemodule.
The referring process utilizes:- the semantic representation of the World;- the Focus-Stack, especially the current focus whichmay be elliptically referred to;- the conceptual state of the user.This conceptual state is based on initial assumptions, e.g.,whether a concept is a prior/familiar to the user, andon what has already transpired during the dialogue, e.g.whether a concept has already been explained, or howthe user has previously referred to an object of the prob-lem model.
The GENERATOR takes this information toadapt its description and link unknown concepts to fa-miliar ones.
Thus the user progressively learns what theproblem model consists of and how it relates to her/hisfamiliar concepts: a simple but efficient approach to theevolving interaction between the user and the system heldabove as our fourth desirable strategy for person-machineadvice-giving dialogues.Symmetrically a communicative game is also charac-terized by an ia-ezpeeted meaning which stands for the ex-pected response of the user, usually in terms of positionson the current focus or on parts of the current focus.
Theuser's sentence is put into logical form by the natural lan-guage front-end and poseible meanings are proposed bythe INTERPRETER.
The latter has to determine whichobject of the problem model the description of the usercould refer to.
Each interpretation attempt is done withina context, that is a particular object which is the root ofthe search process.
Interpretation is based on two searchstrategies: the first uses specificat/on links, while the sec-ond uses d~cr/m,'~nt properties and re~'rement links.
Twotypes of reference can be recognized.
Direct reference usesonly the first strategy following the R~','fwah'on links start-ing from the context object and allows for elliptical an-swers to questions.
Indirect reference uses successivelyboth strategies: a search based on the dimerirnlnant prop-erties determines candidate objects with a ~q~'rement linkto the context object, then these candidates constitute thestarting points for searching along apecificat/on links.
Theuser does not have the same structured view of the finan-cial world as the system do, and hence will not necessarilyrefer to things as we would like.
The user will talk aboutUthe car I want to buy in five years" which requires acash-need.
Interpretation attempts are ordered accordingto the stack of loci: the most salient focus (or layer of loci)is selected as context (or set of contexts), then the deeperfoci are successively tried.
The INTERPRETER only tries189a deeper focus if no interpretation has been found at ahigher layer.
Moreover, for each layer, the INTERPRETERtries to solve the direct reference before the indirect oneand returns all possible interpretations within the firstlayer and type of reference which permitted to solve thereference.
The structure of past loci partly reflects theevolution of our task structure \[Grosz 1985\] and allowsthe user to refer back to past segments of the dialogue.This structure is more supple than a mechanism whichrelies solely on unachieved goals because not only is thefocus of a completed task not lost, but its location withinthis structure is influenced by the problem model in orderto optimize subsequent recovery.Additional knowledge is contained in game descrip-tions: a feature in-react complements in-ezpreted in provid-ing a set of game-specific rules for interpreting the literalmeaning of the user's response returned by the INTER-PRETER into its intended meaning within the particulargame considered.
A simple example consists of trans-formation rules for yes-ok/no answers depending on thegame.Conc lus ionThis work incorporates planning by the system at ahigh level of dialogue, and nevertheless leaves a great dealof initiative to the user.
This flexibility is enhanced bythe wide range of input styles which are allowed by theinterpretation f input according to focus and indirect ref-erence.
At the moment we have a prototype of a dia-logue module written in Prolog which implements generalstrategies for person-machine advice-giving dialogue.
ThenaturM-language front-end, written in C, has been inter-faced with the prototype, but the generation side wouldrequire further investigation.
Generalizing the planningcomponent and integrating more sophisticated plan recog-nition techniques are some of the other issues addressedin a next prototype.
Work is also under way to extendthe concept base in our knowledge world to enrich theconversation with the user.Re ferencesAirenti G., Bara B.G., and Colombetti M., uCogni-tire Pragmatic.s," Research Report URIA 86-1, Unit~.
diRicerca di Intelligen-.a Artiflciale, Universit~ di Milano,1986.Allen J., ~A Plan-Based Analysis of Indirect SpeechActs," JournoJ olthe Assoeiah'on ol Computation~ Lin~ietics,vol.
15, 1980.Bruffeerts A., Henin E., and Marlair V., ~An Expert Sys-tem Prototype for Financial Counseling," Research Re-port 507, Philips Research Laboratory Brussels, 1986.Carberry S., "User Models: the Problem of Disparity,"Procredinos of the Xlth International Cortlcr~nce on Computa-t/ona/L/ngu/~ics, pp.
29-34, Bonn (FR Germany), 1986.Cohen P.R.
and Perrault C.R., "Elements of a Plan-BasedTheory of Speech Acts," Cognitive 8cicnre, no.
3, pp.
177-212, 1979.Cohen P.R., "The Role of Speech Acts in Natural Lan-guage Understanding," Tutorials of the XIth InternationalConference on Computational Linguistics, Bonn (FR Ger-many), 1986.Decitre P., Grossi T., Juilien C., and Solvay J.P., "A Sum-mary Description of a Dialoguer Prototype," TechnicalReport CRG 86-1, Cap Sogeti Innovation, 1986.Fimbel E., Groscot H., Lancel J.M., and Simonin N., "Us-ing a Text Model for Analysis and Generation," Proce~/in?8of the S~o~ Conference of the European CTmpter of the AsJo-ciah'on /or Computational La'nguiatics, Geneva (Switzerland),1985.Gross B.J., "Discourse Structure and the Proper Treat-ment of Interruptions," Proceeding~ of the IXth IJCAI, LosAngeles (USA), 1985.Lancel J.M., Rousselot F., and Simonin N., "A Gram-mar  Used for Parsing and Generation," Procredings of theXlth International Conference on Computational Linguiatic,,pp.
536-539, Bonn (FR Germany), 1986.Litman D.J.
and Allen J.F., "A Plan Recognition Modelfor Subdialogues in Conversations," Technical Report 141,University of Rochester, 1984.Perrault C.R., "An Application of Default Logic to SpeechAct Theory," Proceedings ol the NATO Workshop on ~ruc-ture o/Mulh'mod~ DioJoguee Includ.in~ Voice, Venaco (France),1986.Reichman R., "Extended Person-Machine Interface," At-tibia\] Intelligence, vol.
22, pp.
157-218, 1984.Searle J., Speech Acts: An Eama# in the Ph~osoph# olLar~uaoe,Cambridge University Press, 1969.Slator B.M., Anderson M.P., and Conley W., "Pygmalionat the Interface," Communications of the ACM, vol.
29 ,no.
?, pp.
599-604, 1986.Wachtel T., ~Pragmatic Sensitivity in NL Interfaces andthe Structure of Conversation," Proeee&'ngs o/the Xlth Inter-nohion~d Conleren~ on Computational Lingui~ics, pp.
35-41,Bonn (FR Germany), 1986.Wileusky R., Arens Y., and Chin D., "Talking to UNIXin English: An Overview of UC, ~ C'ommun/cat/o~ /theACM, vol.
27 , no.
6, pp.
574-593, 1984.190
