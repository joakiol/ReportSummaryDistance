Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 779?786, Vancouver, October 2005. c?2005 Association for Computational LinguisticsThe Hiero Machine Translation System:Extensions, Evaluation, and AnalysisDavid Chiang, Adam Lopez, Nitin Madnani, Christof Monz, Philip Resnik, Michael SubotinInstitute for Advanced Computer Studies (UMIACS)University of Maryland, College Park, MD 20742, USA{dchiang,alopez,nmadnani,christof,resnik,msubotin}@umiacs.umd.eduAbstractHierarchical organization is a well known prop-erty of language, and yet the notion of hierarchi-cal structure has been largely absent from the bestperforming machine translation systems in recentcommunity-wide evaluations.
In this paper, we dis-cuss a new hierarchical phrase-based statistical ma-chine translation system (Chiang, 2005), present-ing recent extensions to the original proposal, newevaluation results in a community-wide evaluation,and a novel technique for fine-grained comparativeanalysis of MT systems.1 IntroductionHierarchical organization is a well known prop-erty of language, and yet the notion of hierarchi-cal structure has, for the last several years, beenabsent from the best performing machine transla-tion systems in community-wide evaluations.
Statis-tical phrase-based models (e.g.
(Och and Ney, 2004;Koehn et al, 2003; Marcu andWong, 2002)) charac-terize a source sentence f as a flat partition of non-overlapping subsequences, or ?phrases?, f?1 ?
?
?
f?J ,and the process of translation involves selecting tar-get phrases e?i corresponding to the f?
j and modify-ing their sequential order.
The need for some wayto model aspects of syntactic behavior, such as thetendency of constituents to move together as a unit,is widely recognized?the role of syntactic units iswell attested in recent systematic studies of trans-lation (Fox, 2002; Hwa et al, 2002; Koehn andKnight, 2003), and their absence in phrase-basedmodels is quite evident when looking at MT systemoutput.
Nonetheless, attempts to incorporate richerlinguistic features have generally met with little suc-cess (Och et al, 2004a).Chiang (2005) introduces Hiero, a hierarchicalphrase-based model for statistical machine transla-tion.
Hiero extends the standard, non-hierarchicalnotion of ?phrases?
to include nonterminal sym-bols, which permits it to capture both word-level andphrase-level reorderings within the same framework.The model has the formal structure of a synchronousCFG, but it does not make any commitment to alinguistically relevant analysis, and it does not re-quire syntactically annotated training data.
Chiang(2005) reported significant performance improve-ments in Chinese-English translation as comparedwith Pharaoh, a state-of-the-art phrase-based system(Koehn, 2004).In Section 2, we review the essential elementsof Hiero.
In Section 3 we describe extensions tothis system, including new features involving namedentities and numbers and support for a fourfoldscale-up in training set size.
Section 4 presents newevaluation results for Chinese-English as well asArabic-English translation, obtained in the contextof the 2005 NISTMT Eval exercise.
In Section 5, weintroduce a novel technique for fine-grained com-parative analysis of MT systems, which we em-ploy in analyzing differences between Hiero?s andPharaoh?s translations.2 HieroHiero is a stochastic synchronous CFG, whose pro-ductions are extracted automatically from unanno-tated parallel texts, and whose rule probabilitiesform a log-linear model learned by minimum-error-rate training; together with a modified CKY beam-search decoder (similar to that of Wu (1996)).
Wedescribe these components in brief below.779S ?
?S 1 X 2 ,S 1 X 2 ?S ?
?X 1 ,X 1 ?X ?
?yu X 1 you X 2 , have X 2 with X 1 ?X ?
?X 1 de X 2 , the X 2 that X 1 ?X ?
?X 1 zhiyi, one of X 1 ?X ?
?Aozhou,Australia?X ?
?shi, is?X ?
?shaoshu guojia, few countries?X ?
?bangjiao, diplomatic relations?X ?
?Bei Han,North Korea?Figure 1: Example synchronous CFG2.1 GrammarA synchronous CFG or syntax-directed transductiongrammar (Lewis and Stearns, 1968) consists of pairsof CFG rules with aligned nonterminal symbols.
Wedenote this alignment by coindexation with boxednumbers (Figure 1).
A derivation starts with a pairof aligned start symbols, and proceeds by rewrit-ing pairs of aligned nonterminal symbols using thepaired rules (Figure 2).Training begins with phrase pairs, obtained as byOch, Koehn, and others: GIZA++ (Och and Ney,2000) is used to obtain one-to-many word align-ments in both directions, which are combined into asingle set of refined alignments using the ?final-and?method of Koehn et al (2003); then those pairs ofsubstrings that are exclusively aligned to each otherare extracted as phrase pairs.Then, synchronous CFG rules are constructedout of the initial phrase pairs by subtraction: ev-ery phrase pair ?
f?
, e??
becomes a rule X ?
?
f?
, e?
?,and a phrase pair ?
f?
, e??
can be subtracted from arule X ?
?
?1 f?
?2, ?1e??2?
to form a new rule X ??
?1X i ?2, ?1X i ?2?, where i is an index not alreadyused.
Various filters are also applied to reduce thenumber of extracted rules.
Since one of these filtersrestricts the number of nonterminal symbols to two,our extracted grammar is equivalent to an inversiontransduction grammar (Wu, 1997).2.2 ModelThe model is a log-linear model (Och and Ney,2002) over synchronous CFG derivations.
Theweight of a derivation is PLM(e)?LM , the weightedlanguage model probability, multiplied by the prod-uct of the weights of the rules used in the derivation.The weight of each rule is, in turn:(1) w(X ?
?
?, ??)
=?i?i(X ?
?
?, ??
)?iwhere the ?i are features defined on rules.
The ba-sic model uses the following features, analogous toPharaoh?s default feature set:?
P(?
| ?)
and P(?
| ?)?
the lexical weights Pw(?
| ?)
and Pw(?
| ?
)(Koehn et al, 2003);1?
a phrase penalty exp(1);?
a word penalty exp(l), where l is the number ofterminals in ?.The exceptions to the above are the two ?glue?rules, which are the rules with left-hand side S inFigure 1.
The second has weight one, and the firsthas weight w(S ?
?S 1 X 2 ,S 1 X 2 ?)
= exp(?
?g),the idea being that parameter ?g controls the model?spreference for hierarchical phrases over serial com-bination of phrases.Phrase translation probabilities are estimated byrelative-frequency estimation.
Since the extractionprocess does not generate a unique derivation foreach training sentence pair, a distribution over pos-sible derivations is hypothesized, which gives uni-form weight to all initial phrases extracted from asentence pair and uniform weight to all rules formedout of an initial phrase.
This distribution is then usedto estimate the phrase translation probabilities.The lexical-weighting features are estimated us-ing a method similar to that of Koehn et al (2003).The language model is a trigram model with mod-ified Kneser-Ney smoothing (Chen and Goodman,1998), trained using the SRI-LM toolkit (Stolcke,2002).1This feature uses word alignment information, which is dis-carded in the final grammar.
If a rule occurs in training withmore than one possible word alignment, Koehn et al take themaximum lexical weight; Hiero uses a weighted average.780?S 1 ,S 1 ?
?
?S 2 X 3 ,S 2 X 3 ??
?S 4 X 5 X 3 ,S 4 X 5 X 3 ??
?X 6 X 5 X 3 ,X 6 X 5 X 3 ??
?Aozhou X 5 X 3 ,Australia X 5 X 3 ??
?Aozhou shi X 3 ,Australia is X 3 ??
?Aozhou shi X 7 zhiyi,Australia is one of X 7 ??
?Aozhou shi X 8 de X 9 zhiyi,Australia is one of the X 9 that X 8 ??
?Aozhou shi yu X 1 you X 2 de X 9 zhiyi,Australia is one of the X 9 that have X 2 with X 1 ?Figure 2: Example partial derivation of a synchronous CFG.The feature weights are learned by maximizingthe BLEU score (Papineni et al, 2002) on held-outdata, using minimum-error-rate training (Och, 2003)as implemented by Koehn.
The implementation wasslightly modified to ensure that the BLEU scoringmatches NIST?s definition and that hypotheses inthe n-best lists are merged when they have the sametranslation and the same feature vector.3 ExtensionsIn this section we describe our extensions to the baseHiero system that improve its performance signif-icantly.
First, we describe the addition of two newfeatures to the Chinese model, in a manner similarto that of Och et al (2004b); then we describe howwe scaled the system up to a much larger trainingset.3.1 New featuresThe LDC Chinese-English named entity lists (900kentries) are a potentially valuable resource, butprevious experiments have suggested that simplyadding them to the training data does not help(Vogel et al, 2003).
Instead, we placed them ina supplementary phrase-translation table, givinggreater weight to phrases that occurred less fre-quently in the primary training data.
For each en-try ?
f , {e1, .
.
.
, en}?, we counted the number of timesc( f ) that f appeared in the primary training data,and assigned the entry the weight 1c( f )+1 , whichwas then distributed evenly among the supplemen-tary phrase pairs {?
f , ei?}.
We then created a newmodel feature for named entities.
When one of thesesupplementary phrase pairs was used in transla-tion, its feature value for the named-entity featurewas the weight defined above, and its value in theother phrase-translation and lexical-weighting fea-tures was zero.
Since these scores belonged to a sep-arate feature from the primary translation probabili-ties, they could be reweighted independently duringminimum-error-rate training.Similarly, to process Chinese numbers and dates,we wrote a rule-based Chinese number/date transla-tor, and created a new model feature for it.
Again,the weight given to this module was optimizedduring minimum-error-rate training.
In some caseswe wrote the rules to provide multiple uniformly-weighted English translations for a Chinese phrase(for example,k?
(bari) could become ?the 8th?
or?on the 8th?
), allowing the language model to decidebetween the options.3.2 Scaling up trainingChiang (2005) reports on experiments in Chinese-English translation using a model trained on7.2M+9.2M words of parallel data.2 For the NISTMT Eval 2005 large training condition, consider-ably more data than this is allowable.
We choseto use only newswire data, plus data from Sino-rama, a Taiwanese news magazine.3 This amountsto almost 30M+30M words.
Scaling to this set re-quired reducing the initial limit on phrase lengths,previously fixed at 10, to avoid explosive growth of2Here and below, the notation ?X + Y words?
denotes Xwords of foreign text and Y words of English text.3From Sinorama, only data from 1991 and later were used,as articles prior to that were translated quite loosely.781the extracted grammar.
However, since longer initialphrases can be beneficial for translation accuracy,we adopted a variable length limit: 10 for the FBIScorpus and other mainland newswire sources, and 7for the HK News corpus and Sinorama.
(During de-coding, limits of up to 15 were sometimes used; inprinciple these limits should all be the same, but inpractice it is preferable to tune them separately.
)For Arabic-English translation, we used the ba-sic Hiero model, without special features for namedentities or numbers/dates.
We again used only thenewswire portions of the allowable training data; wealso excluded the Ummah data, as the translationswere found to be quite loose.
Since this amountedto only about 1.5M+1.5M words, we used a higherinitial phrase limit of 15 during both training and de-coding.4 EvaluationFigure 1 shows the performance of several systemson NIST MT Eval 2003 Chinese test data: Pharaoh(2004 version), trained only on the FBIS data; Hi-ero, with various combinations of the new featuresand the larger training data.4 This table also showsHiero?s performance on the NIST 2005 MT evalua-tion task.5 The metric here is case-sensitive BLEU.6Figure 2 shows the performance of two systemson Arabic in the NIST 2005 MT Evaluation task:DC, a phrase-based decoder for a model trained byPharaoh, and Hiero.5 AnalysisOver the last few years, several automatic metricsfor machine translation evaluation have been intro-duced, largely to reduce the human cost of itera-tive system evaluation during the development cy-cle (Lin and Och, 2004; Melamed et al, 2003; Pap-ineni et al, 2002).
All are predicated on the concept4The third line, corresponding to the model without new fea-tures trained on the larger data, may be slightly depressed be-cause the feature weights from the fourth line were used insteadof doing minimum-error-rate training specially for this model.5Full results are available at http://www.nist.gov/speech/tests/summaries/2005/mt05.htm.
For this test, aphrase length limit of 15 was used during decoding.6For this task, the translation output was uppercased usingthe SRI-LM toolkit: essentially, it was decoded again usingan HMM whose states and transitions are a trigram languagemodel of cased English, and whose emission probabilities arereversed, i.e., probability of cased word given lowercased word.System Features Train MT03 MT05Pharaoh standard FBIS 0.268Hiero standard FBIS 0.288Hiero standard full 0.329Hiero +nums, names full 0.339 0.300Table 1: Chinese results.
(BLEU-4; MT03 case-insensitive, MT05 case-sensitive)System Train MT05DC full 0.399Hiero full 0.450Table 2: Arabic results.
(BLEU-4; MT03 case-insensitive, MT05 scores case-sensitive.of n-gram matching between the sentence hypothe-sized by the translation system and one or more ref-erence translations?that is, human translations forthe test sentence.
Although the motivations and for-mulae underlying these metrics are all different, ul-timately they all produce a single number represent-ing the ?goodness?
of the MT system output over aset of reference documents.
This facility is valuablein determining whether a given system modificationhas a positive impact on overall translation perfor-mance.
However, the metrics are all holistic.
Theyprovide no insight into the specific competencies orweaknesses of one system relative to another.Ideally, we would like to use automatic methodsto provide immediate diagnostic information aboutthe translation output?what the system does well,and what it does poorly.
At the most general level,we want to know how our system performs on thetwo most basic problems in translation?word trans-lation and reordering.
Unigram precision and recallstatistics tell us something about the performance ofan MT system?s internal translation dictionaries, butnothing about reordering.
It is thought that higher or-der n-grams correlate with the reordering accuracyof MT systems, but this is again a holistic metric.What we would really like to know is howwell thesystem is able to capture systematic reordering pat-terns in the input, which ones it is successful with,and which ones it has difficulty with.
Word n-gramsare little help here: they are too many, too sparse, andit is difficult to discern general patterns from them.7825.1 A New Analysis MethodIn developing a new analysis method, we are moti-vated in part by recent studies suggesting that wordreorderings follow general patterns with respect tosyntax, although there remains a high degree of flex-ibility (Fox, 2002; Hwa et al, 2002).
This suggeststhat in a comparative analysis of two MT systems, itmay be useful to look for syntactic patterns that onesystem captures well in the target language and theother does not, using a syntax based metric.We propose to summarize reordering patterns us-ing part-of-speech sequences.
Unfortunately, recentwork has shown that applying statistical parsers toungrammatical MT output is unreliable at best, withthe parser often assigning unreasonable probabili-ties and incongruent structure (Yamada and Knight,2002; Och et al, 2004a).
Anticipating that thiswould be equally problematic for part-of-speechtagging, we make the conservative choice to applyannotation only to the reference corpus.
Word n-gram correspondences with a reference translationare used to infer the part-of-speech tags for words inthe system output.First, we tagged the reference corpus with partsof speech.
We used MXPOST (Ratnaparkhi, 1996),and in order to discover more general patterns, wemap the tag set down after tagging, e.g.
NN, NNP,NNPS and NNS all map to NN.
Second, we com-puted the frequency freq(ti .
.
.
t j) of every possibletag sequence ti .
.
.
t j in the reference corpus.
Third,we computed the correspondence between each hy-pothesis sentence and each of its corresponding ref-erence sentences using an approximation to max-imum matching (Melamed et al, 2003).
This al-gorithm provides a list of runs or contiguous se-quences of words ei .
.
.
e j in the reference that arealso present in the hypothesis.
(Note that runs areorder-sensitive.)
Fourth, for each recalled n-gramei .
.
.
e j, we looked up the associated tag sequenceti .
.
.
t j and incremented a counter recalled(ti .
.
.
t j).Finally, we computed the recall of tag patterns,R(ti .
.
.
t j) = recalled(ti .
.
.
t j)/freq(ti .
.
.
t j), for allpatterns in the corpus.By examining examples of these tag sequences inthe reference corpus and their hypothesized trans-lations, we expect to gain some insight into thecomparative strengths and weaknesses of the MTsystems?
reordering models.
(An interactive plat-form for this analysis is demonstrated by Lopez andResnik (2005).
)5.2 ChineseWe performed tag sequence analysis on the Hieroand Pharaoh systems trained on the FBIS data only.Table 3 shows those n-grams for which Hiero andPharaoh?s recall differed significantly (p < 0.01).The numbers shown are the ratio of Hiero?s recallto Pharaoh?s.
Note that the n-grams on which Hi-ero had better recall are dominated by fragments ofprepositional phrases (in the Penn Treebank tagset,prepositions are tagged IN or TO).Our hypothesis is that Hiero produces English PPsbetter because many of them are translated fromChinese phrases which have an NP modifying an NPto its right, often connected with the particle?
(de).These are often translated into English as PPs, whichmodify the NP to the left.
A correct translation, then,would have to reorder the two NPs.
Notice in the ta-ble that Hiero recalls proportionally more n-gramsas n increases, corroborating the intuition that Hieroshould be better at longer-distance reorderings.Investigating this hypothesis qualitatively, we in-spected the first five occurrences of the n-grams ofthe first type on the list (JJ NN IN DT NN).
Ofthese, we omit one example because both systemsrecalled the n-gram correctly, and one because theydiffered only in lexical choice (Hiero matched the5-gram with one reference sentence, Pharaoh withzero).
The other three examples are shown below (H= Hiero, P = Pharaoh):(2) T?UN?hsecurity?council?of?*five8?permanent?member??countries-allR1.
five permanent members of the UN Secu-rity CouncilH.
the five permanent members of the un se-curity councilP.
the united nations security council perma-nent members of the five countries78310.00 JJ NN IN DT NN7.00 IN NN TO5.50 IN DT NN NN PU NN5.50 IN DT NN NN PU NN NN4.50 NN JJ NN PU4.50 NN IN DT JJ4.00 VB CD IN DT3.67 IN DT NN NN PU3.50 NN IN DT NN NN3.30 NN IN DT NN3.14 DT NN IN DT NN3.00 IN DT NN PU2.50 NN TO NN2.03 DT JJ NN IN1.95 IN NN PU1.77 IN NN CD1.74 DT NN IN NN1.70 JJ NN IN1.55 VB IN DT1.46 NN IN NN1.46 DT NN PU1.44 IN DT JJ1.42 NN IN DT1.41 IN DT NN1.37 PU CC1.34 IN CD1.32 JJ NN PU1.30 IN NN1.29 NN IN1.18 NN PU1.09 CD1.07 VB1.06 NN NN1.06 IN1.05 NN0.61 RB CD0.21 TO VB PR0.18 PU RB CD0.12 NN CD TO NN0.12 CD TO NNTable 3: Chinese-English POS n-grams on which Hiero and Pharaoh had significantly different recall, ar-ranged by recall ratio.
Ratio > 1 indicates tag sequences that Hiero matched more frequently.(3)?KIraqq:crisis?of most?new?UdevelopmentR1.
the latest development on the Iraqi crisisH.
the latest development on the Iraqi crisisP.
on the iraqi crisis, the latest development(4) ?tthis-yearupperJthalf-yearR1.
the first half of this yearH.
the first half of this yearP.
the first half ofAll three of these examples involve an NP modify-ing an NP to its right; two with the particle?
(de)and one without.
In all three cases Hiero reorders theNPs correctly; Pharaoh preserves the Chinese wordorder in two cases, but in the third, for reasons notunderstood, drops the modifying NP.The n-grams on which Hiero did worse thanPharaoh mostly involved numbers; here a pattern isnot as easily discernible, but there are several caseswhere Hiero makes errors in translating numbers(neither system in this comparison used the dedi-cated number translator).
For the n-gram TOVB PR,it seems Hiero has a tendency to delete possessivepronouns (PR, abbreviated from PRP$).5.3 ArabicInitial inspection of the n-grams on which Hieroshowed significantly higher recall in the Arabic-English task suggested that here, too, better trans-lation of nominal phrases may be at play.
We in-vestigated this conjecture further by examining sev-eral n-gram sets with the highest recall ratios.
Someof them on closer inspection turned out to conflatedifferent structural patterns, and provided little in-terpretable information.
However, the 8 sentencesin the n-gram list IN DT JJ JJ showed a degree ofstructural consistency.
The list contained 6 instanceswhere Hiero performed better in translating a com-plex NP or PP, one instance in which DC performedbetter in translating a complex PP, and one case inwhich they both performed equally poorly.
Belowwe show two examples of phrases on which Hieroperformed better, and the one example on which itshierarchical approach produced undesirable results(H = Hiero, D = DC).
(5) AlthewjwdpresenceAltheEskrYmilitaryAltheAmYrkYAmericanfYinAlthemnTqpregionR1.
the American military presence in the re-gionH.
the american military presence in the re-gionD.
the military presence in the region(6) AltYwhichtSnEhAmanufactures-themAlthe$rkpcompanyAlthekwrYpKoreanAlthejnwbYpSouthernR1.
which are manufactured by the South Ko-rean companyH.
which are manufactured by the south ko-rean companyD.
which are manufactured by the company ,the south korean7848.00 WR DT NN8.00 PR NN IN DT7.00 DT PU6.00 DT NN NN PO5.00 IN DT JJ JJ4.67 DT NN IN VB2.89 NN NN NN VB2.73 PR VB IN2.56 NN PU WD VB2.45 JJ CC JJ NN2.38 DT JJ JJ NN2.08 CC JJ NN2.01 PR VB2.00 TO DT NN NN1.80 NN PU WD1.80 NN IN DT JJ NN1.77 NN IN DT JJ1.76 JJ JJ NN1.74 VB CD1.68 NN NN VB1.46 JJ NN NN1.43 JJ JJ1.35 IN DT JJ1.24 VB IN1.21 NN VB1.20 NN IN DT1.17 PR1.10 JJ NN1.08 NN NN1.07 IN DT1.02 NN0.47 NN CD PU CD NN NN0.47 NN CD PU CD NN NN NN0.47 NN CD PU CD NN NN NN PU0.45 NN CD PU CD NN0.29 NN CD NN0.27 NN CD NN CD0.09 NN CD NN PUTable 4: Arabic-English POS n-grams on which Hiero and DC had significantly different recall, arranged byrecall ratio.
Ratio > 1 indicates tag sequences that Hiero matched more frequently.
(7) swqmarketAltheEqArAtreal-estatefYinAkbrlargestmdYnpcitySnAEYpindustrialSYnYpChinese$AnghAYShanghaiR2.
The real estate market in the largest Chi-nese industrial city , ShanghaiH.
chinese real estate market in the largest in-dustrial city shanghaiD.
real estate market in the largest chinese in-dustrial city shanghaiIn the last example we see that Hiero mistakenlyidentified the adjective ?Chinese?
as modifying thehighest head of the first NP in the apposition.The style of Arabic newswire tends strongly to-wards the verb-initial word order in the main clause.Based on our inspection of the n-gram collection NNVB, we were also able to note that Hiero performednoticeably better in reordering the subject and mainverb to produce idiomatic English translations.
Al-though in this set the differences in the recall for theNN VB bigram were influenced by many differenttranslation issues, reordering the subject and mainverbs was the only structural pattern that recurredconsistently throughout the set, appearing in 8 of the29 relevant sentences.
(8) wqAland-saidAlthebYAnstatementAnthatR1.
The statement saidH.
the statement said thatD.
said a statement that(9) AElnannouncedms&wlofficialfYinAltheAmmnationsAlthemtHdpunitedAnthatR1.
A United Nations official announced thatH.
the united nations official announced thatD.
an official in the united nations thatLooking at the bottom of the list, we find moreexamples of how Hiero?s reordering behavior some-times backfires.
These n-grams seem primarily to beparts of bylines, where Hiero has a tendency to refor-mat the date, whereas DC keeps the original format,matching more often.
(10) mAnYlAManila2626YnAYrJanuaryR3.
Manila 26 JanuaryH.
manila , january 26P.
manila 26 january6 ConclusionsThe work reported in this paper extends the origi-nal treatment of Hiero (Chiang, 2005) by evaluat-ing an improved version in a community-wide exer-cise for Chinese-English and Arabic-English trans-lation, and by introducing a novel analysis tech-nique for comparing MT systems?
output.
The eval-uation results provide strong evidence that the ap-proach gains performance from its hierarchical ex-tensions to phrase-based translation.
The analysisof part-of-speech tag sequences provides a way toperform finer-grained comparison of system output,pinpointing phenomena for which the systems differsignificantly.785AcknowledgementsWe would like to thank Philipp Koehn for the use ofthe Pharaoh system.
This research was supported inpart by ONR MURI Contract FCPO.810548265 andDepartment of Defense contract RD-02-5700.ReferencesStanley F. Chen and Joshua Goodman.
1998.
An empir-ical study of smoothing techniques for language mod-eling.
Technical Report TR-10-98, Harvard UniversityCenter for Research in Computing Technology.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofthe 43rd Annual Meeting of the ACL, pages 263?270.Heidi J.
Fox.
2002.
Phrasal cohesion and statistical ma-chine translation.
In Proceedings of EMNLP 2002,pages 304?311.Rebecca Hwa, Philip Resnik, Amy Weinberg, and OkanKolak.
2002.
Evaluating translational correspondenceusing annotation projection.
In Proceedings of the40th Annual Meeting of the ACL, pages 392?399.Philipp Koehn and Kevin Knight.
2003.
Feature-richstatistical translation of noun phrases.
In Proceedingsof the 41st Annual Meeting of the ACL, pages 311?318.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT-NAACL 2003, pages 127?133.Philipp Koehn.
2004.
Pharaoh: a beam search decoderfor phrase-based statistical machine translation mod-els.
In Proceedings of AMTA 2004, pages 115?124.P.
M. Lewis II and R. E. Stearns.
1968.
Syntax-directedtransduction.
Journal of the ACM, 15:465?488.Chin-Yew Lin and Franz Josef Och.
2004.
Automaticevaluation of machine translation quality using longestcommon subsequence and skip-bigram statistics.
InProceedings of the 42nd Annual Meeting of the ACL,pages 606?613.Adam Lopez and Philip Resnik.
2005.
Pattern visualiza-tion for machine translation output.
In Proceedings ofHLT/EMNLP 2005.
Demonstration session.Daniel Marcu andWilliamWong.
2002.
A phrase-based,joint probability model for statistical machine transla-tion.
In Proceedings of EMNLP 2002, pages 133?139.I.
Dan Melamed, Ryan Green, and Joseph P. Turian.2003.
Precision and recall of machine translation.
InProceedings of HLT-NAACL 2003, pages 61?63.Franz Josef Och and Hermann Ney.
2000.
Improved sta-tistical alignment models.
In Proceedings of the 38thAnnual Meeting of the ACL, pages 440?447.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statis-tical machine translation.
In Proceedings of the 40thAnnual Meeting of the ACL, pages 295?302.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Computational Linguistics, 30:417?449.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,Anoop Sarkar, Kenji Yamada, Alex Fraser, ShankarKumar, Libin Shen, David Smith, Katherine Eng,Viren Jain, Zhen Jin, and Dragomir Radev.
2004a.
Asmorgasbord of features for statistical machine trans-lation.
In Proceedings of HLT-NAACL 2004.Franz Josef Och, Ignacio Thayer, Daniel Marcu, KevinKnight, Dragos Stefan Munteanu, Quamrul Tipu,Michel Galley, and Mark Hopkins.
2004b.
Arabic andChinese MT at USC/ISI.
Presentation given at NISTMachine Translation Evaluation Workshop.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of the ACL, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
B???
: a method for automatic evalua-tion of machine translation.
In Proceedings of the 40thAnnual Meeting of the ACL, pages 311?318.Adwait Ratnaparkhi.
1996.
A maximum-entropy modelfor part-of-speech tagging.
In Proceedings of EMNLP,pages 133?142.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Processing,volume 2, pages 901?904.Stephan Vogel, Ying Zhang, Fei Huang, Alicia Trib-ble, Ashish Venugopal, Bing Zhao, and Alex Waibel.2003.
The CMU statistical machine translation sys-tem.
In Proceedings of MT-Summit IX, pages 402?409.Dekai Wu.
1996.
A polynomial-time algorithm for sta-tistical machine translation.
In Proceedings of the 34thAnnual Meeting of the ACL, pages 152?158.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23:377?404.Kenji Yamada and Kevin Knight.
2002.
A decoder forsyntax-based statistical MT.
In Proceedings of the40th Annual Meeting of the ACL, pages 303?310.786
