Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 123?130,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsLanguage-independent hybrid MT with PRESEMTGeorge Tambouratzis Sokratis Sofianopoulos Marina VassiliouILSP, Athena R.C ILSP, Athena R.C ILSP, Athena R.Cgiorg_t@ilsp.gr s_sofian@ilsp.gr mvas@ilsp.grAbstractThe present article provides a compre-hensive review of the work carried outon developing PRESEMT, a hybrid lan-guage-independent machine translation(MT) methodology.
This methodologyhas been designed to facilitate rapidcreation of MT systems for uncon-strained language pairs, setting the low-est possible requirements on specialisedresources and tools.
Given the limitedavailability of resources for many lan-guages, only a very small bilingual cor-pus is required, while language model-ling is performed by sampling a largetarget language (TL) monolingual cor-pus.
The article summarises implementa-tion decisions, using the Greek-Englishlanguage pair as a test case.
Evaluationresults are reported, for both objectiveand subjective metrics.
Finally, main er-ror sources are identified and directionsare described to improve this hybrid MTmethodology.1 Introduction and backgroundCurrently a large proportion of language-independent MT approaches are based on thestatistical machine translation (SMT) paradigm(Koehn, 2010).
A main benefit of SMT is that itis directly amenable to new language pairs, pro-vided appropriate training data are available forextracting translation and language models.
Themain obstacle to the creation of an SMT systemis the requirement for SL-TL parallel corpora ofa sufficient size to allow the extraction of mean-ingful translation models.
Such corpora (of theorder of million sentences) are hard to obtain,particularly for less resourced languages.
On theother hand, the translation accuracy of such sys-tems largely depends on the quality and size ofthe bilingual corpora, as well as their relevanceto the domain of text being translated.
Even ifsuch parallel corpora exist for a language pair,they are frequently restricted to a specific do-main (or a narrow range of domains).
As a con-sequence, these corpora are not suitable for cre-ating MT systems that focus on other domains.For this reason, in SMT, researchers are investi-gating the extraction of information from mono-lingual corpora, including lexical translationprobabilities (Klementiev et al 2012) and topic-specific information (Su et al 2011).Alternative techniques for creating MT sys-tems using less informative but readily availableresources have been proposed.
Even if thesemethods do not provide a translation quality ashigh as SMT, their ability to develop hybrid MTsystems with very limited specialised resourcesrepresents an important advantage.
Such meth-ods include automatic inference of templates forstructural transfer from SL to TL (Caseli et al2008 and Sanchez-Martinez et al 2009).
Simi-larly, Carbonell et al(2006) propose an MTmethod that needs no parallel text, but relies on alightweight translation model utilising a full-form bilingual dictionary and a decoder for long-range context.
Other systems using low-cost re-sources include METIS (Dologlou et al 2003)and METIS-II (Markantonatou et al 2009; Carlet al 2008), which utilise a bilingual lexicon123and monolingual corpora to translate SL texts.METIS/METIS II, which have studied transla-tion only towards English, employ pattern rec-ognition algorithms to retrieve the most appro-priate translation from a monolingual corpus.2 The MT methodology in briefThe MT methodology has been developedwithin the PRESEMT (Pattern REcognition-based Statistically Enhanced MT) project,funded by the European Commission (cf.www.presemt.eu).
It comprises three stages:(i) pre-processing, where the input sentence istagged and lemmatised(ii) main translation, where the actual transla-tion output is generated and(iii) post-processing, where the correspondingtokens are generated from lemmas.The main translation process is split in twophases, namely (a) the establishment of thetranslation structure in terms of phrase order and(b) the definition of word order and resolution oflexical ambiguities at an intra-phrase level.In terms of resources, PRESEMT utilises a bi-lingual lemma dictionary providing SL ?
TLlexical correspondences.
It also employs an ex-tensive TL monolingual corpus, compiled auto-matically via web crawling (Pomikalek et al2008) to generate a comprehensive phrase-basedlanguage model.
The provision of the monolin-gual corpus allows PRESEMT to use only a verysmall bilingual corpus for mapping the transferfrom SL to TL sentence structures.
This bilin-gual corpus only numbers a few hundred sen-tences, reducing reliance on costly linguistic re-sources.
The corpus is assembled from availableparallel corpora, only replacing free translationswith more literal ones, to allow the accurate ex-traction of structural modifications.
The parallelcorpus coverage is not studied prior to integra-tion in PRESEMT, which would have allowedan optimisation of translation performance.3 Extracting information from corpora3.1 Parallel corpusInitially, both the bilingual and the monolingualcorpora are annotated 1  so as to incorporatelemma and Part-of-Speech (PoS) informationand other salient language-specific morphologi-cal features (e.g.
case, number, tense etc.).
Fur-thermore, for the TL side, a shallow parser orchunker (hereafter referred to as parser) is usedto split the sentences into syntactic phrases.
Asthe proposed methodology has been developedto maximise the use of publicly-available soft-ware, the user is free to select any desired parserfor the TL language.To avoid either an additional SL side parser orpotential incompatibilities between the two pars-ers, the Phrase Aligner module (PAM, Tam-bouratzis et al 2011) is implemented.
PAMtransfers the TL side parsing scheme, which en-compasses lemma, tag and parsing information,to the SL side, based on lexical information cou-pled with statistical data on PoS tag correspon-dences extracted from the lexicon.
The parsingscheme includes phrase boundaries and phraselabels.
PAM follows a 3-step process, involving(a) lexicon-based alignment, (b) alignment basedon similarity of grammatical features and PoStag correspondence and (c) alignment on theevidence of already aligned neighbouring words.The SL side of the aligned corpus is subse-quently processed by the Phrasing model genera-tor (PMG), to create an SL phrasing modelwhich will then parse sentences input for transla-tion.
The original PMG implementation (Tam-bouratzis et al 2011) has utilised ConditionalRandom Fields (CRF), due to the considerablerepresentation capabilities of this model(Lafferty et al 2001).
CRF is a statistical mod-elling method that takes context into account topredict labels for sequences of input samples.The implementation of an alternative PMGmethodology (termed PMG-simple) based ontemplate-matching principles has also been pur-sued.
PMG-simple locates phrases that match1For the annotation task readily available tools are em-ployed.
For the experiments reported here, TreeTagger(Schmid, 1994) has been used for the TL text processingand the FBT PoS tagger (Prokopidis et al 2011) has beenemployed for the processing of the SL text..124exactly what it has seen before, based on a sim-ple template-matching algorithm (Duda et al2001).
The templates used are the phrases towhich the SL side sentences of the bilingual cor-pus have been segmented.
In contrast to CRF,PMG-simple implements a greedy search (Black,2005) without backtracking.
Initially all phrasesare positioned in an ordered list according totheir likelihood of being accurately detected.Starting from the phrase with the highest likeli-hood, PMG-simple examines if each phrase oc-curs in the input sentence.
If it does and the con-stituent words are not part of an already estab-lished phrase, the constituent words are markedas parts of this phrase and are no longer consid-ered in the phrase-matching process.
If thephrase pattern does not occur, the next in-linephrase is considered, until the table is exhausted.Comparative results between CRF and PMG-simple are reported in the results section.3.2 Monolingual corpusThe TL monolingual corpus is processed to ex-tract two complementary types of information.The first type supports disambiguation betweenmultiple possible translations, while the seconddetermines the order of words in the final trans-lation and the addition or removal of functionalwords, using a TL phrase model derived from anindexing based on (i) phrase type, (ii) phrasehead lemma and (iii) phrase head PoS tag.The TL phrases are then organised in a hashmap that allows the storage of multiple valuesfor each key, using as a key the three aforemen-tioned criteria.
For each phrase the number ofoccurrences within the corpus is retained.
Eachhash map is stored in a separate file to minimiseaccess time during translation.4 Translation phase 1: Structure selec-tionThe Structure selection phase determines thetype and relative position of TL phrases to whichthe SL ones are translated.
To achieve this,PRESEMT consults the SL-to-TL structuralmodifications as contained in the PAM-processed parallel corpus.
In that respect, itresembles EBMT (Hutchins, 2005).Translation phase 1 receives as input an SLsentence, annotated with tag & lemma informa-tion and segmented into phrases by the PMG.
Adynamic programming algorithm then deter-mines for each SL side the most similar (interms of phrase structure) SL sentence from thebilingual corpus.
Similarity is calculated by tak-ing into account structural information such asthe phrase type, the PoS tag and case (if applica-ble) of the phrase head and phrase functionalhead info.
The phrases of the input sentence arethen reordered to generate the translation struc-ture by combining the phrase alignments estab-lished by the algorithm and the SL-TL phrasealignment information stored in the pair of paral-lel sentences.The dynamic programming algorithm com-pares structures from the same language.
Themost similar SL structure from the bilingual cor-pus, that will determine the TL translation struc-ture, is thus selected purely on SL properties.The similarity of two sentences is calculated as aweighted internal product between the two sen-tences, traversing both sentences in parallel fromtheir start towards their end.
The implementedmethod utilises the Smith-Waterman variant(Smith and Waterman, 1981).The last step of this phase is the translation ofwords using the bilingual lexicon.2 All transla-tion alternatives are disambiguated during thesubsequent translation phase.5 Translation Phase 2: Translationequivalent selectionIssues resolved in the second phase are phrase-internal and include (i) word order within eachphrase, (ii) introduction or deletion of functionalwords and (iii) selection of the best candidate inthe case of translation ambiguities.
These areresolved using the phrase-based indexing of theTL monolingual corpus.For each phrase of the sentence being trans-lated, the algorithm searches the TL phrasemodel for similar phrases.
If the search is suc-cessful, all retrieved TL phrases are compared tothe phrase to be translated.
The comparison isbased on the words included, their tags and lem-mas and the morphological features.2If an SL word is not included in the lexicon, it is retainedin the translation in its original SL form.1251.
Retrieve the relevant phrases from the TLcorpus based on the head word2.
Compare the phrase with all the TL relevantphrases and store the one that scores thehighest similarity score3.
For any words that the TL model cannotdisambiguate, use the lemma frequencymodel for selecting the best translation4.
Return the new translated Phrase instance.Figure 1.
Pseudocode for Translation equivalentselectionFor the purposes of the proposed methodol-ogy, the stable-marriage algorithm (Gale &Shapley, 1962) is applied for calculating thesimilarity and aligning the words of a phrasepair.
In comparison to other relevant algorithms,the Gale-Shapley algorithm, results in poten-tially non-optimal solutions, but possesses theadvantage of a substantially lower complexityand thus a reduced processing time.Using the most similar TL phrase and theword alignments generated by the stable-marriage algorithm, word reordering, translationdisambiguation and addition or removal of func-tional words is performed for each phrase of theinput sentence.
The final translation is producedby combining all of its translated phrases.6 Developing new Language PairsThe porting of the proposed methodology to newlanguage pairs is straightforward.
The summarypresented herewith is based on the creation of anew Greek-to-Italian language pair, and is typi-cal of porting to new TLs.
Initially, the NLPtools need to be selected for the new language(tagger & lemmatiser, shallow parser).
In addi-tion, a TL monolingual corpus and a bilinguallexicon need to be provided.
The following stepsare then taken:A.
Create a java wrapper class for the Italianannotation tools, and provide rules for iden-tifying heads of phrases.B.
Tag/lemmatise and chunk the TL corpus,which takes less than a day.C.
Process the chunked Italian corpus to gener-ate the phrase model.
This operation is fullyautomated and performed off-line (e.g.
for acorpus of 100 million words, approx.
1.5days are needed).D.
For the parallel corpus, train the PAM/PMGsuite for the relevant language pair (less than2 hours needed).7 Objective Evaluation ExperimentsThe evaluation results reported in this articlefocus on the Greek ?
English language pair.
Twodatasets have been used (a development set anda test set), each of which comprises 200 sen-tences, with a length of between 7 and 40 words.For every sentence, exactly one reference trans-lation has been created, by SL-language nativespeakers and then the translation correctness wascross-checked by TL-language native speakers.Number of sentences 200 Source webReference translations 1 Language pair EL?ENMetrics MT systemBLEU NIST Meteor TERPRESEMT  0.3254 6.9793 0.3880 51.5330METIS-2 0.1222 3.1655 0.2698 82.878Systran 0.2930 6.4664 0.3830 49.721Bing 0.4600 7.9409 0.4281 37.631Google 0.5544 8.8051 0.4665 29.791WorldLingo 0.2659 5.9978 0.3666 50.627Table 1.
Objective metrics results for PRESEMT& other MT systems (development set)To objectively evaluate the translation accu-racy, four automatic evaluation metrics havebeen chosen, namely BLEU (Papineni et al2002), NIST (NIST 2002), Meteor (Denkowskiand Lavie, 2011) and TER (Snover et al 2006).When developing the MT methodology, exten-sive evaluation was carried out at regular inter-vals (Sofianopoulos et al 2012).
The evolutionof translation accuracy is depicted within Figure2.
The falling trend for TER, signifies a continu-ously improving translation performance.
Thecurrent results for a number of MT systems forthe development set are reported in Table 1.These results show that at the current stage ofdevelopment the proposed approach has a qual-ity exceeding that of WorldLingo and Systran,but is still inferior to Google and Bing.
The re-sults are particularly promising, taking into ac-count that the proposed methodology has beendeveloped for a substantially shorter period thanthe other systems, and has no language-specificinformation injected into it.
According to an er-126ror analysis carried out, most of the errors aredue to the lack of syntactic information (e.g.
theinability to distinguish between object/subject).Also a point which can be improved concernsthe mapping of sentence structures from SL toTL.
To address this, additional experiments arecurrently under way involving larger monolin-gual corpora.Even without this type of knowledge, the pro-posed methodology has shown substantial scopefor improvement, as evidenced by the evolutionof the objective translation metrics (cf.
Figure2).
It is expected that this trend will be continuedin future versions of the MT system.40.000045.000050.000055.000060.000065.0000May-12 Jun-12 Jul-12 Aug-12 Sep-12 Oct-12 Nov-12 Dec-12Figure 2.
Evolution of translation accuracy re-flected by TER scores for the PRESEMT systemtogether with the associated trend lineNumber of sentences 200 Source webReference translations 1 Language pair EL?ENMetrics PMG typeBLEU NIST Meteor TERCRF-based 0.3167 6.9127 0.3817 52.509PMG-simple 0.3254 6.9793 0.3880 51.533Table 2.
Effect on PRESEMT translation accu-racy of using the two distinct PMG variantsRecent activity towards improving translationaccuracy has focussed on the effect of using dif-ferent PMG approaches, as summarised in sec-tion 3.
According to Table 2, an improvement inall four metrics is achieved using PMG-simpleinstead of CRF.
For the limited training set de-fined by the parallel corpus, PMG-simple ex-tracts more effectively the phrasing model.
Animprovement of approx.
3% in the BLEU scoreis achieved over the CRF-based system.
Thereduction in TER is almost 2% indicating a siz-able improvement in translation quality, whileNIST and METEOR scores are improved by 1%and 1.9% respectively.8 Subjective Evaluation ResultsTo fully evaluate translation quality, both objec-tive and subjective evaluation have been imple-mented.
The latter type is carried out by humanswho assess translation quality.Human evaluation is considered to be morerepresentative of the actual MT quality (Calli-son-Burch, et al 2008 & 2011), though on theother hand it is time-consuming and laborious.Furthermore, it lacks objectivity (single evalua-tors may not be consistent in assessing a giventranslation through time while two evaluatorsmay yield completely different judgements onthe same text) and must be repeated for everynew test result.For the human evaluation, for each languagepair, a total of 15 language professionals wererecruited, who were either language profession-als, closely associated with MT tasks, or post-graduate university students in the area of lin-guistics.
Two types of subjective evaluationwere carried out.
The first one involves the ex-perts grading translations generated by the PRE-SEMT system regarding their adequacy and flu-ency.
Adequacy refers to the amount of informa-tion from the SL text that is retained in the trans-lation, based on a 1-5 scale of scores (with ascore of 1 corresponding to the worst transla-tion).
Fluency measures whether the translationis well-formed, also on a 1-5 scale, with empha-sis being placed on grammaticality.The second type of subjective evaluation in-volves direct comparison between the transla-tions generated by PRESEMT and by other es-tablished MT systems over the same dataset.
Inthis case, each evaluator ranks the translations ofthe different systems, these systems being pre-sented in randomised order to ensure the de-pendability of the feedback received.Subjective evaluation activities were carriedout during two distinct periods (namely Octoberand December 2012), separated by two months.The purpose of implementing two sessions hasbeen to judge the improvement in the systemwithin the intervening period.
Thus, two distinctversions of the EL-EN MT system correspond-ing to these two time points were used.
For ref-127erence, the objective evaluation results obtainedfor the test sentences are listed in Table 3.
Inboth cases, the CRF-based PMG was used sinceit was more mature at the time of evaluation.A specifically-designed platform has been de-veloped to support subjective evaluation activi-ties3.
This platform has been used to (a) collectthe human evaluators?
feedback for the differentlanguage pairs and (b) support the subsequentassessment of the results via statistical methods.Number of sentences 200 Source webReference translations 1 Language pair EL?ENMetrics MT systemBLEU NIST Meteor TERPRESEMT(phase 1) 0.2627 6.2001 0.3329 60.0420PRESEMT(phase 2) 0.2666 6.2061 0.3335 59.3360Bing 0.4793 8.1357 0.4486 35.7220Google 0.5116 8.4549 0.4580 32.6860WorldLingo 0.3019 6.3799 0.3814 46.7350Table 3.
Objective metrics results for PRESEMT& other MT systems (test set)020406080100number of cases1 2 3 4 5Score scaleadequacyfluencyFigure 3.
Histogram of adequacy and fluencyover all sentences (1st human evaluation phase)020406080100number of cases1 2 3 4 5Score scaleadequacyfluencyFigure 4.
Histogram of adequacy and fluencyover all sentences (2nd human evaluation phase)For the proposed methodology, in phase 1 rel-atively low values of both adequacy and fluency3www.presemt.eu/presemt_eval/measurements were recorded.
By comparing thescores in the first and second evaluation phases(Figures 3 and 4, respectively), it can be seenthat both adequacy and fluency histograms movetowards higher values (notably fluency ratingswith a score of 3 and adequacy ratings withscores of 3 and 4 have substantially higher fre-quencies).
This reflects improved translationquality in the later version of the proposed MTsystem in comparison to the earlier one.Number of sentences 200 Source webReference translations 1 Language pair EL?ENAdequacy Fluency MT systemaverage stdev.
average stdev.PRESEMT(phase 1)  3.08 0.27 2.17 0.27PRESEMT(phase 2) 3.14 0.24 2.16 0.25Google 4.17 0.39 3.51 0.50Bing 3.75 0.77 3.02 0.61WorldLingo 3.77 0.45 3.11 0.51Table 4.
Summary of measurements (in terms ofaverage and standard deviation) for fluency andadequacy for various MT systems (test set)In addition, in phase 2 of subjective evalua-tion, adequacy and fluency measurements werecollected for the three operational systems usedas reference systems (namely Google Translate,Bing and WorldLingo).
These operational sys-tems have higher adequacy and fluency valuesthan PRESEMT, as indicated in Table 4.
Fur-thermore, paired t-tests have confirmed that at a0.99 level of significance, these three systemshave statistically superior subjective measure-ments to the proposed methodology.
To providea reference, for the same set of 200 sentences,objective metrics are shown in Table 3 for eachsystem.
As can be seen the relative order of thesystems in the subjective evaluations (in termsof adequacy and fluency) is confirmed by theobjective measurements.A second subjective evaluation focused onranking comparatively the translations of thefour studied MT systems.
Evaluators were pre-sented with the outputs of the four systems inrandomized order, to conceal the identity of eachsystem.
The evaluators were requested to orderthe four translations from higher to lower quality(with 1 denoting the more accurate translation.128To transform this ranking into a single score, theindividual rankings per evaluator have been ac-cumulated and normalized over the number ofevaluators.
Then the representative scoring hasbeen defined as a weighted sum of frequency ofa system being ranked as first, second, third andfourth best over all evaluators, by multiplyingwith weights of 40, 30, 20 and 10 respectively.The average scores of the proposed methodologywere the lowest, followed by the ranking resultsfor WorldLingo.
The results of Bing and Googleare comparable with the Google results givingthe best results.
A statistical analysis was carriedout using paired t-tests for all six pairings of thefour systems being studied.
This has confirmedthat the differences in subjective scores are sta-tistically significant at a level of 0.95.To summarise, subjective evaluation hasshown that the PRESEMT methodology has aninferior translation performance in terms of sub-jective measurements to the three operationalsystems.
This can be justified as the proposedmethodology refrains from utilising language-specific information as a priori grammaticalknowledge.
Inferior translations also reflect themuch shorter development time available as wellas the very limited amount of expensive re-sources provided.
The effect on translation qual-ity of using pre-existing tools (to ease portabilityto new language pairs) needs to be stressed, asno modification of these tools was performed toremedy systematic shortcomings identified.
Forthe newer MT versions now available, a newround of subjective evaluations is planned.
It hasbeen observed that improvements in objectivemetrics are followed by improved subjectiveevaluation performance.
Thus, for these newversions, an improved accuracy is expected.9 DiscussionIn the present article the principles and imple-mentation of a novel language-independent MTmethodology have been presented.
This meth-odology draws on information from a large TLmonolingual corpus and a very small bilingualone.
The overwhelming majority of linguisticinformation is extracted in an automated mannerusing pattern recognition techniques.Two types of evaluation have been reported,these concerning objective and subjectiveevaluations.
Experimental results using objectivemetrics through a period of time have indicated arising trend in terms of translation quality.
Also,it has been shown that by introducing a newphrasing model for the sentences to be translateda substantial improvement is achieved.
Subjec-tive evaluation activities have indicated a highertranslation accuracy achieved by other MT sys-tems.
A limiting factor for the PRESEMT meth-odology is admittedly the requirement for port-ability to new language pairs.
This leads to theextraction of knowledge from texts via algo-rithmic means and the adoption of already exist-ing linguistic tools, without modifications.On the other hand, subsequent versions of theproposed MT system have shown a trend of im-proving translation accuracy.
In this respect, ob-jective evaluation results are promising, espe-cially taking into account the fact that for severalaspects, scope for improvement has been identi-fied.
This includes the revision of the structureselection phase, where smaller sub-sententialstructures need to be combined to improve gen-eralisation.
In addition, improvements in the bi-lingual corpus compilation procedure need to bestudied.
The results of these ongoing experi-ments will be reported in the future.ReferencesPaul E. Black.
2005.
Dictionary of Algorithms andData Structures.
U.S. National Institute of Stan-dards and Technology (NIST).Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz and Josh Schroeder.
2009.Further Meta-Evaluation of Machine Translation.Proceedings of the WMT-08 Workshop, Colom-bus, Ohio.Chris Callison-Burch, Philip Koehn, Christof Monz,Omar F. Zaidan.
2011.
Findings of the2011Workshop on Statistical Machine Translation.Proceedings of the 6th Workshop on StatisticalMachine Translation, Edinburgh, UK, pp.
22?64.Jaime Carbonell, Steve Klein, David Miller, MichaelSteinbaum, Tomer Grassiany and Jochen Frey.2006.
Context-Based Machine Translation.
Pro-ceedings of the 7th AMTA Conference, Cam-bridge, MA, USA, pp.
19-28.Michael Carl, Maite Melero, Toni Badia, VincentVandeghinste, Peter Dirix, Ineke Schuurman,Stella Markantonatou, Sokratis Sofianopoulos,129Marina Vassiliou and Olga Yannoutsou.
2008.METIS-II: Low Resources Machine Translation:Background, Implementation, Results and Poten-tials.
Machine Translation, 22 (1-2):pp.
67-99.Helena M. Caseli, Maria das Gra?as V. Nunes andMikel L. Forcada.
2008.
Automatic Induction ofBilingual resources from aligned parallel corpora:Application to shallow-transfer machine transla-tion.
Machine Translation, 20:pp.
227-245.Michael Denkowski and Alon Lavie.
2011.
Meteor1.3: Automatic Metric for Reliable Optimizationand Evaluation of Machine Translation Systems.EMNLP 2011 Workshop on Statistical MachineTranslation, Edinburgh, UK, pp.
85-91.Ioannis Dologlou, Stella Markantonatou, GeorgeTambouratzis, Olga Yannoutsou, Athanasia Fourlaand Nikos Ioannou.
2003.
Using MonolingualCorpora for Statistical Machine Translation: TheMETIS System.
Proceedings of the EAMT- CLAW2003 Workshop, Dublin, Ireland, pp.
61-68.Richard O. Duda, Peter E. Hart and David G. Scott.2001.
Pattern Classification (2nd edition).
WileyInterscience, New York, U.S.A.David Gale and Lloyd S. Shapley.
1962.
CollegeAdmissions and the Stability of Marriage.
Ameri-can Mathematical Monthly, 69:pp.
9-14.John Hutchins.
2005.
Example-Based MachineTranslation: a Review and Commentary.
MachineTranslation, 19:pp.
197-211.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch and David Yarowsky.
2012.
Toward Statis-tical Machine Translation without Parallel Cor-pora.
Proceedings of EACL2012, Avignon,France, 23-25 April, pp.
130-140.Philip Koehn.
2010.
Statistical Machine Translation.Cambridge University Press, Cambridge.John Lafferty, Andrew McCallum and FernandoPereira.
2001.
Conditional Random Fields: Prob-abilistic Models for Segmenting and Labelling Se-quence Data.
Proceedings of ICML 2011, Belle-vue, Washington, USA, pp.
282-289.Harry Mairson.
1992.
The Stable Marriage Problem.The Brandeis Review, 12:1.Stella Markantonatou, Sokratis Sofianopoulos, OlgaGiannoutsou and Marina Vassiliou.
2009.
HybridMachine Translation for Low- and Middle- Den-sity Languages.
Language Engineering for Lesser-Studied Languages, S. Nirenburg (ed.
), IOS Press,pp.
243-274.NIST 2002.
Automatic Evaluation of Machine Trans-lation Quality Using n-gram Co-occurrences Sta-tistics.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: A Method for Auto-matic Evaluation of Machine Translation.
Pro-ceedings of the 40th ACL Meeting, Philadelphia,USA, pp.
311-318.Jan Pomik?lek and Pavel Rychl?.
2008.
Detecting co-derivative documents in large text collections.Proceedings of LREC2008, Marrakech, Morrocco,pp.1884-1887.Prokopis Prokopidis, Byron Georgantopoulos andHarris Papageorgiou.
2011.
A suite of NLP toolsfor Greek.
Proceedings of the 10th ICGL Confer-ence, Komotini, Greece, pp.
373-383.Felipe Sanchez-Martinez and Mikel L. Forcada.2009.
Inferring Shallow-transfer Machine transla-tion Rules from Small Parallel Corpora.
Journal ofArtificial Intelligence Research, 34:pp.
605-635.Helmut Schmid.
1994.
Probabilistic Part-of-SpeechTagging Using Decision Trees.
Proceedings of In-ternational Conference on New Methods in Lan-guage Processing, Manchester, UK, pp.
44-49.Temple F. Smith and Michael S. Waterman.
1981.Identification of Common Molecular Subse-quences.
Journal of Molecular Biology, 147:195-197.Matthew Snover, Bonnie Dorr, Richard Schwartz,Linnea Micciulla and John Makhoul.
2006.
AStudy of Translation Edit Rate with Targeted Hu-man Annotation.
Proceedings of the 7th AMTAConference, Cambridge, MA, USA, pp.
223-231.Sokratis Sofianopoulos, Marina Vassiliou and GeorgeTambouratzis.
2012.
Implementing a language-independent MT methodology.
Proceedings of the1st Workshop on Multilingual Modeling (heldwithin the ACL-2012 Conference), Jeju, Republicof Korea, pp.1-10.Jinsong Su, Hua Wu, Haifeng Wang, Yidong Chen,Xiaodong Shi, Huailin Dong and Qun Liu.
2011.Translation Model Adaptation for Statistical Ma-chine Translation with Monolingual Topic Infor-mation.
Proceedings of the 50th ACL Meeting,Jeju, Republic of Korea, pp.
459?468.George Tambouratzis, Fotini Simistira, Sokratis Sofi-anopoulos, Nikos Tsimboukakis and Marina Vas-siliou.
2011.
A resource-light phrase scheme forlanguage-portable MT.
Proceedings of the 15thEAMT Conference, Leuven, Belgium, pp.
185-192.130
