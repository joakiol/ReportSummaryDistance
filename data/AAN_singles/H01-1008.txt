Assigning Belief Scores to Names in QueriesChristopher DozierResearch and DevelopmentThomson Legal and Regulatory610 Opperman DriveEagan, MN 55123,USAchris.dozier@westgroup.comABSTRACTAssuming that the goal of a person name query is to findreferences to a particular person, we argue that one can derivebetter relevance scores using probabilities derived from alanguage model of personal names than one can using corpusbased occurrence frequencies such as inverse document frequency(idf).
We present here a method of calculating person namematch probability using a language model derived from adirectory of legal professionals.
We compare how well namematch probability and idf predict search precision of wordproximity queries derived from names of  legal professionals andmajor league baseball players.
Our results show that name matchprobability is a better predictor of relevance than idf.
We alsoindicate how rare names with high match probability can be usedas virtual  tags within a corpus to identify effective collocationfeatures for person names within a professional class.1.
INTRODUCTIONSome of the most common types of queries submitted to searchengines both on the internet and on proprietary text searchsystems consist simply of a person?s name.
To improve the waysuch queries are handled, it would be useful if search enginescould estimate the likelihood or belief that a name contained in adocument pertains to the name in the query.
Traditionally,relevance likelihood for name phrases has been based on inversedocument frequency or idf, [3][4].
The idea behind this relevanceestimate is that names which rarely occur in the corpus arethought to be more indicative of relevance than names thatcommonly occur.Assuming that the goal of a person name query is to findreferences to a particular person, we argue that one can derivebetter relevance scores using probabilities derived from alanguage model of personal names than one can using corpusbased occurrence frequencies.
The reason for this is that findingreferences to a particular person in text is more dependent uponthe relative rarity of the name with respect to the humanpopulation than it is on the rarity of the name within a corpus.To get an intuitive idea of this point, consider that, within acorpus of 27,000 Wall Street Journal articles published betweenJanuary and August of the year 2000, the name ?Trent Lott?occurred in 80 documents while the name ?John Smith?
occurredin 24.
All 80 references to ?Trent Lott?
referred to the majorityleader of the U.S. Senate, while ?John Smith?
references mappedto 5 different people.
This is not surprising.
From ourexperience, we know that ?Trent Lott?
is an uncommon name and?John Smith?
is a common one.We present here evidence that name match probability based on alanguage model predicts relevance for name queries far better thanidf.
It may be argued that idf was never intended to be used tomeasure the relative ambiguity of a name query.
However, idf isthe standard measure used in probabilistic search engines tomeasure the degree of relevance terms and phrases within acollection have to the terms and phrases in queries, [1] [5].
Forthis reason, we take idf to be the standard against which tocompare name match probability.Being able to predict relevance through name match probabilitiesenables us to do three things.
First, it tells us when we need toadd information to the query to improve precision either byprompting the user for it or automatically expanding the query.Second, and perhaps more importantly, it enables us to use nameswith high match probabilities as virtual tags that can help us finduseful collocation features to disambiguate names within a givenclass of names, such as the names of attorneys and judges.
Forpurposes of this paper, we define an ambiguous name as onelikely to be shared by many people and an unambiguous name asone likely to apply to a single person or to only a few people.And third, match probability can be used as a feature within aname search operator to improve search precision.2.
DESCRIPTION OF MATCHPROBABILITY CALCULATION FORPERSON NAMESThe motivation for our work is an effort to develop a name searchoperator to find attorneys and judges in the news.
In ourparticular application, we wish to allow users to search fornewspaper references to attorneys and judges listed in a directoryof U.S. legal professionals.
This directory contains thecurriculum vitae of approximately one million people.
In thissection, we show how we calculate person name matchprobability.To compute the probability of relevance or match probability for aname, we perform three steps.
First, we compute a probabilitydistribution for the first and last names in our name directory.This is our language model.
Second, we compute a name?sprobability by multiplying its first name probability with its lastname probability.
Third, we compute its match probability bytaking the reciprocal of the product of the name probability andthe size of the human population likely to be referenced in thecorpus.
For our Wall Street Journal test corpus, we estimated thissize to be approximately the size of the U.S. population or 300million.
Formulas for the three steps are shown below.where F =  number of occurrences of first name, L = number ofoccurrences of last name, and N = number of names in thedirectory.
(2) )_()_()( namelastPnamefirstPnameP ?=(3)   ( ) 1)(1)_(+?= namePHmatchnamePwhere H = size of human population likely to be referenced by thecollection.Example calculations for Trent Lott and John Smith are shownbelow in Table 1.In this example, the match probability for Trent Lott isapproximately four orders of magnitude higher than the matchprobability for John Smith, while idf or document frequencysuggests the likelihood of relevance for documents retrieved forJohn Smith is higher than for documents retrieved for Trent Lott.Both empirically and intuitively, match probability is a betterpredictor of relevance here than idf.3.
EVALUATION OF NAME MATCHPROBABILITY VERSUS IDFTo test our hypothesis that name match probability predictsrelevance better than idf, we compared how well name querieswith high match probabilities performed against name querieswith high idf.
We performed two experiments.
In the first, weselected names of individuals in our legal directory.
In thesecond, we used the names of currently active major leaguebaseball players.To conduct the first experiment, we labeled person names in acollection of 27,000 WSJ documents with a commerciallyavailable name tagging program.
We then extracted these namesand created a merged list of names specified by first and last nameand pulled from this list names that occurred within our legaldirectory.
We then sorted this list by name match probability andby document occurrence frequency (which is equivalent to idf) tocreate two lists.
We then binned the names in the name matchprobability list into sets that fell between the following probabilityranges: 1.0-0.9, 0.9-0.8 ,0.8-0.7, 0.7-0.6, 0.6-0.5, 0.5-0.4, 0.4-0.3,0.3-0.2, 0.2-0.1, and 0.1-0.0.
We binned the names in thedocument frequency list into sets that fell into the followingdocument occurrence frequencies: 1, 2, 3, 4, 5, 6, 7, 8, 9, and>=10.We then selected 50 names at random from each of these bins(except for bins associated with 0.8-0.7 and 0.7-0.6 probabilitieswhich contained 42 and 31 names  respectively).
For each nameselected, we identified the legal directory entry that wascompatible with the name.
In most cases, only one legal directoryentry was compatible with the name.
In some cases, multipleentries were compatible.
For example, the name ?Paul Brown?
iscompatible with 71 legal directory entries since there are 71people in the directory with the first name ?Paul?
and the lastname ?Brown?.
In these cases, we selected one of the entries atrandom.For each name in each bin, we found the set of documents in theWSJ collection that would be returned by the word proximityquery ?First_name +2 Last_name?.
That is, the documents thatcontained the first name followed within two words by the lastname.The search precision results for match probability and documentfrequency bins are shown in tables 2 and 3 below.
The searchprecision of each bin was the number of relevant documentsreturned by the names in the bin divided by the total number ofdocuments returned.
The row labeled  ?Number Unique Names inEach Category?
is a count of the number of unique first and lastname pairs found within the WSJ collection for the probabilityand document frequency ranges indicated.
It was from these setsof names that we selected our queries.The results in tables 2 and 3 show that match probability does abetter job of estimating relevance than idf.
Table 2 shows thatsearch precision goes up as match probability rises.
Table 3shows no apparent correspondence between document frequencyand search precision.Table 1: Example Calculation of Match ProbabilityName P(first name) P(last name) P(name) P(name match) Doc FreqTrent Lott 0.000084 0.000048 0.00000000408 0.449371705 80John Smith 0.036409 0.006552 0.00023857 0.00001397 24(1) NFnamefirstP =)_(NLnamelastP =)_(In the second experiment, we performed basically the same stepsdescribed above on the names of the 286 baseball playerscurrently playing in the major leagues.
We assigned name matchprobabilities to these names using the language model we derivedfrom the legal directory.
Of the 286 names, we found 82 thatwere compatible with one or more name instances in the WSJcollection.
For all 82, we found the set of documents in the WSJcollection that would be returned by the word proximity query?First_name +2 Last_name?.
We then measured how frequentlythe documents returned for a particular word proximity queryactually referenced the player with which the name query waspaired.
As in the attorney and judge name experiment, namematch probability predicted relevance more accurately than idf.The results for baseball player names are shown in tables 4 and 5above.Note that on average the search precision for baseball players washigher than for attorneys and judges.
This is due to the combinedTable 2:  Search Precision At Different Match Probabilities for Names Compatiblewith Judge and Attorney Names for WSJ CollectionMatch ProbRange1.0 -0.90.9 ?0.80.8 ?0.70.7 ?0.60.6 ?0.50.5 ?0.40.4 ?0.30.3 ?0.20.2 ?0.10.1 ?0.0SearchPrecision0.835 0.754 0.595 0.677 0.596 0.708 0.628 0.544 0.520 0.12Number UniqueNames in EachCategory80 61 42 31 57 72 113 135 292 10758Table 3:  Search Precision At Different Document Occurrence Frequencies for Names Compatiblewith Judge and Attorney Names for WSJ CollectionDoc Freq1 2 3 4 5 6 7 8 9 >=10SearchPrecision0.18 0.10 0.10 0.20 0.06 0.10 0.08 0.18 0.14 0.24Number UniqueNames in EachCategory7702 1946 703 374 224 145 95 75 55 322Table 4:  Search Precision At Different Match Probabilities for Names Compatiblewith Names of Major League Baseball Players for WSJ CollectionMatch ProbRange1.0 -0.90.9 ?0.80.8 ?0.70.7 ?0.60.6 ?0.50.5 ?0.40.4 ?0.30.3 ?0.20.2 ?0.10.1 ?0.0Search Precision  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.939 0.633Number UniqueNames in EachCategory15 5 2 2 2 3 2 7 7 48Table 5:  Search Precision At Different Document Occurrence Frequencies for Names Compatiblewith Names of Major League Baseball Players for WSJ CollectionDoc Freq1 2 3 4 5 6 7 8 9 >=10SearchPrecision0.888 0.882 0.952 1.0 0.75 0.666 1.0 NA 1.0 0.74Number UniqueNames in EachCategory45 17 7 3 4 6 2 0 1 8effects of there being far fewer baseball player names thanattorney and judge names and the fact that the average probabilityof a baseball player being mentioned in the news is higher thanthe average probability for a judge or attorney being mentioned.4.
USING RARE NAMES TO IDENTIFYSEARCH FEATURESAn important use of name match probabilities is the identificationof co-occurrence features in text that can serve to disambiguatename references.
If we know certain names in the corpora veryprobably refer to certain individuals listed in a professionaldirectory, we can look for words that co-occur frequently withthese names but infrequently with names in general.
These wordsare likely to work well at disambiguating references to names oflow match probability.As an example of feature identification, consider the figures 1 and2 above.
In these figures, the word ?rare?
stands for the 20% ofnames in the legal directory that have the highest matchprobability.
The phrase ?medium rare?
stands for the next 20%and so on.
The word ?common?
then stands for the 20% ofnames with the lowest match probability.
For each of the fivecategories of name rarity, the graphs in the figures show theprobability of an appositive term occurring at a given wordposition relative to the position of a name.Figure 1 shows the probability of attorney appositive nouns suchas ?attorney?, ?lawyer?, ?counsel?, or ?partner?
occurring at 12different word positions around attorney names of varying degreesof rarity.
Position ?1 stands for the word position directly beforethe name.
Position +1 stands for the position directly after.Position ?2 stands for the word position two words in front of thename and so on.
Figure 2 shows the probability of judgeappositive nouns such as ?judge?
or ?justice?
occurring aroundjudge names.The graphs in figures 1 and 2 show that the probability ofappositive terms occurring at particular word positions growssteadily as the name rarity increases.
This demonstrates thatappositive terms are good indicators for judge and attorney nameswithin the WSJ collection.
The figures also shows the wordpositions in which we should look for appositive terms.Figure 1 shows that we should look for attorney appositives inword positions ?2, -1, +2, +4, and +5.
This makes intuitive sensebecause it accounts for sentence constructs such as those shown intable 6.The sudden drop off in appositive term probability at wordposition +1 also makes sense since an article, adjective, or otherpart of speech often occurs between a trailing appositive headnoun and the proper noun it modifies.
The drop off at wordposition +3 is still something of a mystery and is not somethingwe can explain at this time.
Since +3 behavior seems to have nolinguistic basis that we can perceive, we do not rely on it inconstructing our search operator.Figure 2 shows that we should look for judge appositives in wordposition -1.
This makes perfect sense since it accounts forconstructs such as ?
Judge William Rehnquist?
and ?JusticeAntonin Scalia?.
Figure 2 also suggests that using the -1appositive test should yield good search recall since theconditional probability for rare names is about 0.9.00.050.10.150.20.250.30.35-6 -5 -4 -3 -2 -1 1 2 3 4 5 6raremedium raremediummedium commoncommon00.20.40.60.81-6 -5 -4 -3 -2 -1 1 2 3 4 5 6raremedium raremediummediumcommoncommonFigure1: Conditional probability ofattorney terms by word positionrelative to nameFigure2: Conditional probability ofjudge terms by word position relativeto nameTable 6: Examples of Use of Attorney Term Near Attorney NameRelativeWordPositionExample sentence-2 Attorney General Janet Reno said today ?..-1 Attorney Jack Smith defended his client vigorously.+2 said Vicki Patton, senior attorney for EnvironmentalDefense+4 said Jim Hahn, Los Angeles City Attorney+5 says Buck Chapoton, a prominent Washington taxattorney5.
PRELIMINARY SEARCH OPERATOREXPERIMENTSWe are currently investigating what levels of  search precision andrecall we can achieve with special attorney and judge name searchoperators using name rarity together with  co-occurrence featuressuch as appositive, city, state, firm, and court terms.
Ourpreliminary results are encouraging.
Initial experiments with theattorney search operator indicate we can achieve a nine foldimprovement in search precision over simple word proximitysearches over the WSJ collection while sacrificing 18% recall.Preliminary results are shown in table 7 below.
We producedthese results by selecting 677 attorney names at random from thelegal directory that existed within the WSJ collection.
For eachname, we ran word proximity searches using the first and lastname of the lawyers and scored the results.
Using the scoredresults from 377 of the names, we then trained a special Bayesianbased name operator that used first name, last name, city, state,firm, and name rarity information as sources of name matchevidence.
Finally we tested the word proximity operatorperformance against the special name operator using theremaining 300 names.Note that we have assumed above that word proximity searchesyield 100% recall.
This is not wholly accurate since it does notaccount for nicknames, use of first name initials, and so on.
Weplan to revise this recall estimate in the future, but for now weassume that a word proximity search on first and last nameprovides close to 100% recall in a collection such as the WSJ.6.
FUTURE WORKWe plan to complete development of search operators for attorneyand judges that make use of the combined features of name rarity,appositives, city, state, firm, and court terms.
We plan to comparethe performance of these operators against searches based onname indexes derived from combining MUC style extractiontechniques and record linking techniques.
[2] Our hope is that thesearch operators will perform at levels close to the indexed basedsearches so that we can avoid the operational costs of creatingspecial name indexes.We plan to mine names from text using name rarity and seedappositive phrases.
For example, using a seed appositive phrasefor a profession such as ?expert witness?, we plan to identify andextract a set of expert witness names.
From this initial set ofnames, we will identify rare names and use these to identify moreappositive phrases.
Once the appositive phrases are identified, weplan to extract more names, then more appositive phrases, and soon until a stopping condition is reached.
In this manner, we hopeto develop a technique to automatically extract name lists fromtext collections.Finally we plan to assess whether it is possible to develop similarname match probability calculations for other types of names suchas company names, organization names, and product names.7.
CONCLUSIONAssuming that the goal of a person name query is to findreferences to a particular person, we have shown  that one canderive better relevance scores using probabilities derived from alanguage model of personal names than one can using corpusbased occurrence frequencies.
We presented here a method ofcalculating person name match probability using a languagemodel derived from a directory of legal professionals.
Wecompared how well name match probability and idf predict searchprecision of word proximity queries derived from names of legalprofessionals and major league baseball players.
Our resultsshowed that name match probability is a better predictor ofrelevance than idf.
We also indicated how rare names with highmatch probability can be used as virtual tags within a corpus toidentify effective collocation features for person names within aprofessional class.8.
REFERENCES[1] Baeza-Yates, R. and Ribeiro-Neto, B., Modern InformationRetrieval.
ACM Press,  New York, 1999.
[2] Dozier, C. and Haschart, R., "Automatic Extraction andLinking of Person Names in Legal Text" in Proceedings of RIAO'2000;  Content Based Multimedia Information Access.
Paris,France.
pp.1305-1321.
2000[3] de Lima, F. and Pedersen, J., Phrase Recognition andExpansion for Short, Precision-biased Queries based on a QueryLog.
In  Proc.of the 22nd Annual Int.
ACM SIGIR Conference onResearch and Development in Information Retrieval, pp.
145 ?152, Berkeley, California, USA, 1999.
[4] Thompson, P. and Dozier, C., Name Searching andInformation Retrieval.
In Proc.of the 2nd Conference onEmpirical Methods in NLP,  pp.
134 ?140, Providence, RhodeIsland, 1997.
[5] Turtle, H. and Croft, W.,  Inference Networks for DocumentRetrieval.
In Proc.of the 13th Annual Int.
ACM SIGIR Conferenceon Research and Development in Information Retrieval, pp.
1 ?24, Brussels, Belgium, 1990.Table 7: Comparison of Performance of Word ProximitySearch and Special Name Operator Searches for AttorneyNamesSearch Method Precision Recall F-measureWord proximity 0.09 1.00 0.17Attorney Name SearchOperator0.85 0.82 0.83
