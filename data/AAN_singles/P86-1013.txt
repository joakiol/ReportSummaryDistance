PARSING CONJUNCTIONS DETERMINISTICALLYDonald W. KosyThe Robotics InstituteCarnegie-Mellon UniversityPittsburgh, Pennsylvania 15213ABSTRACTConjunctions have always been a source of problems for naturallanguage parsers.
This paper shows how these problems may becircumvented using a rule.based, walt-and-see parsing strategy.A parser is presented which analyzes conjunction structuresdeterministically, and the specific rules it uses are described andillustrated.
This parser appears to be faster for conjunctions thanother parsers in the literature and some comparative timings aregiven.INTRODUCTIONIn recent years, there has been an upsurge of interest in tech-niques for parsing sentences containing coordinate conjunctions(and, or and but) \[1,2,3,4,5,8,9\].
These techniques are intendedto deal with three computational problems inherent in conjunc-tion parsing:1.
Since virtually any pair of constituents of the samesyntactic type may be conjoined, a grammar that ex-plicitly enumerates all the possibilities eems need-lessly cluttered with a large number of conjunctionrules.2.
If a parser uses a top-down analysis strategy (as iscommon with ATN and logic grammars), it musthypothesize a structure for the second conjunct with-out knowledge of its actual structure.
Since thisstructure could be any that parallels some con-stituent hat ends at the conjunction, the parser mustgenerate and test all such possibilities in order to findthe ones that match.
In practice, the combinatorialexplosion of possibilities makes this slow.3.
It is possible for a conjunct to have "gaps" (ellipsedelements) which are not allowed in an unconjoinedconstituent of the same type.
These gaps must befilled with elements from the other conjunct for aproper interpretation, as in: I gave Mary a nickel andHarry a dime.The paper by Lesmo and Torasso \[9\] briefly reviews which tech.niques apply to which problems before presenting their own ap-proach.Two papers in the list above \[1,3\] present deterministic, "wait.and-see" methods for conjunction parsing.
In both, however, thediscussion centers around the theory and feasibility of parsersthat obey the Marcus determinism hypothesis \[10\] and operatewith a limited-length Iookahead buffer.
This paper examines theother side of the coin, namely, the practical power of the wait-and.see approach compared to strictly top-down or bottom-upmethods.
A parser is described that analyzes conjunction struc.tures deterministically and produces parse trees similar to thoseproduced by Dahl & McCord's MSG system \[4\].
It is much fasterthan either MSG or Fong & Berwick's RPM device \[5\], and com-parative timings are given.
We conclude with some descriptivecomparisons to other systems and a discussion of the reasonsbehind the performance observed.OVERVIEW OF THE PARSERFor the sake of a name, we will call the parser NEXUS since itis the syntactic component of a larger system called NEXUS.
Thissystem is being developed to study the problem of learning tech.nical concepts from expository text.
The acronym stands forNon.Expert Understanding System.NEXUS is a direct descendent of READER, a parser written byGinsparg at Stanford in the late 1970's \[6\].
Like all wait-and-seeparsers, it incorporates a stack to hold constituent structuresbeing built, some variables that record the state of the parse, anda set of transition rules that control the parsing process.
Thestack structures and state variables in NEXUS are almost thesame as in READER, but the rules have been rewritten to makethem cleaner, more transparent, and more complete.There are two categories of rules.
Segmentation rules areresponsible for finding the boundaries of constituents and creat-ing stack structures to store these results.
Recombination rulesare responsible for attaching one structure to another in syntac-tically valid ways.
Segmentation operations are separate from,and always precede, recombination operations.
All the rules areencoded in Lisp; there is no separate rule interpreter.Segmentation rules take as input a word from the input sen.tence and a partial-parse of the sentence up to that word.
Therules are organized into procedures such that each procedureimplements those rules that apply to one syntactic word class.When a rule's conditions are met, it adds the input word to thepartial-parse, in a way specified in the rule, and returns the newpartial-parse as output.A partial-parse has three parts:1.
The stack: A stack (not a tree) of the data structureswhich encode constituents.
There are two types ofstructures in the stack, one type representing clausenuclei (the verb group, noun phrase arguments, andadverbs of a clause), and the other representingprepositional phrases.
Each structure consists of acollection of slots to be filled with constituents as theparse proceeds.2.
The message (MSG): A symbol specifying the lastaction performed on the stack.
In general, this sym-bol will indicate the type of slot the last input word78was inserted in.3.
The stack-message (MSGI): A list of properties ofthe stack as a whole (e.g.
the sentence is imperative).The various types of slots comprising stack structures are definedin Figure 1.
VERB, PREP, ADV, NOTE, and FUNCTION slots areifilled during segmentation, while CASES and MEASURE slots areadded during recombination.
NP slots are filled with nounphrases during segmentation but may subsequently be aug-mented by post-modifiers during recombination.CLAUSES PREPOSITION STRUCTURESVERB: verb phraseADV: adverbsNP1,NP2,NP3: noun phrasesNOTE: notesFUNCTION: clause functionMEASURE: ratingCASES: adjunctsPREP: prepositionADV: adverbsNP: noun phraseNOTE: notesMEASURE: ratingDEFINITIONSClause functionHypothesized role of the clause in the sentence, e.g.
main,relative clause, infinitive adjunct, etc.NotesSegmentation rules can leave notes about a structure that will beused in ,later processing.RatingA numerical measure of the syntactic and semantic acceptabilityof the structure to be used in choosing between competingpossible parses.AdjunctsThe prepositional phrases and subordinate clauses that turn outto be adjuncts to this clause.Figu re 1 : Stack StructuresAn English rendering of some segmentation rules for variousword classes is given in the Appendix.
The tests in a rule dependon the current word, the messages, and various properties ofstructures in the/stack at the time the tests are made.
As eachword is taken fi'om the input stream, all rules in its syntacticclass(es) are tried, in order, using the current partial parse.
Allrules that succeed are executed.
However, if the execution ofsome rule stipulates a return, subsequent rules for that class areignored.The actions a rule can take are of five main types.
For a giveninput word W, a rule can:?
continue filling a slot in the top stack structure byinserting W?
begin filling a new slot in the top structure?
push a new structure onto the stack and begin fillingone of its slots?
collapse the stack so that a structure below the topbecomes the new top?
modify a slot in the top structure based on the infor-mation provided by WIn addition, a rule will generally change the MSG variable, andmay insert or delete items in the list of stack messages.The way the rules work is best shown by example.
Supposethe input is:The children wore the socks on their hands.The segmentation NEXUS performs appears in Fig.
2a.
On theleft are the words of the sentence and their possible syntacticclasses.
The contribution each word makes to the developmentof the parse is shown to the right of the production symbol "= ~>".We will draw the stack upside down so that successive parsingstates are reached as one reads down the page.
The contents ofa stack structure are indicated by the accumulation of slot valuesbetween the dashed-line delimiters ("--.-.").
Empty slots are notshown.Input WordWord Class MSG1 MSG Stack-- - nil BEGIN FUNCTION: MAINthe A => nil NOUN NPI: thechildren N = > nil NOUN NPI': the childrenwore V = > nil VERB VERB: worethe A = > nil NOUN NP2: thesocks N,V => nil NOUN NP2': thesockson P = ;> nil PREP PREP: ontheir N = > nil NOUN NP: theirhands N,V => nil NOUN NP': theirhandsa.
Segmentation{wear PN\[SUB the children\]the socks\]their hands\] }b. RecombinationFigure 2: Parse of The children wore the socks on their handsBefore parsing begins, the three parts of a partial-parse areinitialized as shown on the first line.
One structure is prestored inthe stack (it will come to hold the main clause of the inputsentence), the message is BEGIN, and MSG1 is empty.
The pars-ing itself is performed by applying the word class rules for eachinput word to the partial-parse left after processing the previousword.
For example, before the word wore is processed,MSG = NOUN, MSG1 is empty, and the stack contains one clausewith FUNCTION = MAIN and NP1 = the children.
Wore is a verband so the Verb rules are tried.
The third rule is found to applysince there is a clause in the stack meeting the conditions.
Thisclause is the top one so there is no collapse.
(Collapse performsrecombination and is described below.)
The word wore is in.serted in the VERB slot, MSG is set, and the rule returns the newpartial.parse.It is possible for the segmentation process to yield more thanone new partial-parse for a given input word.
This can occur intwo ways.
First, a word may belong to several syntactic classes"79and when this is so, NEXUS tries the rules for each class.
If rulesin more than one class succeed, more than one new partial-parseis produced.
As it happens, the two words in the example that areboth nouns and verbs do not produce more than one partial-parse because the Verb rules don't apply when they areprocessed.
Second, a word in a given class can often be addedto a partial.parse in more than one way.
The third and fifth Verbrules, for example, may both be applicable and hence canproduce two new partial.parses.
In order to keep track of thepossibilities, all active partial.parses are kept in a list and NEXUSadds new words to each in parallel.
The main segmentation con-trol loop therefore has the following form:For each word w in the input  sentence doFor" each wor"d c lass  C that  w belongs to  doFor" each par t ia l  parse P in the l i s t  doTry the C ru les  g iven w and PLoopLoopStore a l l  new par t ia l -parses  in the l i s tLoopIn contrast to segmentation rules, which add structures to apartial.parse stack, recombination rules reduce a stack by joiningstructures together.
These rules specify the types of attachmentthat are possible, such as the attachment of a post-modifier to anoun phrase or the attachment of an adjunct to a clause.
Thesuccessful execution of a rule produces a new structure, with theattachment made, and a rating of the semantic acceptability ofthe attachment.
The ratings are used to choose among differentattachments if more than one is syntactically possible.There are three rating values -- perfect, acceptable, and un-acceptable .- and these are encoded as numbers so that therecan be degrees of acceptability.
When one structure is attachedto another, its rating is added to the rating of the attachment andthe sum becomes the rating of the new (recombined) structure.
Astructure's rating thus reflects the ratings of all its componentconstituents.
Although NEXUS is designed to call upon an inter.preter module to supply the ratings, currently they must be sup-plied by interaction with a human interpreter.
Eventually, we ex-pect to use the procedures developed by Hirst \[7\].
There is also a'no-interpreter' switch which can be set to give perfect ratings toclause attachment of right-neighbor prepositional phrases, andnoun phrase ("low") attachment of all other post-modifiers.The order in which attachments are attempted is controlled bythe co l \ ]apse  procedure.
Co l lapse  is responsible for assem-bling an actual parse tree from the structures in a stack.
Afterinitializing the root of the tree to be the bottom stack structure,the remaining structures are considered in reverse stack order sothat the constituents will be added to the tree in the order theyappeared (left to right).
For each structure, an attempt is made toattach it to some structure on the right frontier of the tree, startingat the lowest point and proceeding to the highest.
(Looking onlyat the right frontier enforces the no-crossing condition of Englishgrammar.
1 ) If a perfect attachment is found, no further pos-sibilities are considered.
Otherwise, the highest-rated attachmentis selected and co11 apse goes on to attach the next structure.
Ifno attachment is found, the input is ungrammatical with respectto the specifications in the recombination rules.1The no-crossing condition says that one constituent cannot be attached to anon-neighboring constituent without attaching the neighbor first.
For instance, ifconstituents are ordered A, B, and C, then C cannot be attached to A unless B isattached to A first.
Furthermore, this implies that if B and C are both attached toA, B is closed to further attachments.After a stack has been collapsed, a formatting procedure iscalled to produce the final output.
This procedure is primarilyresponsible for labeling the grammatical roles played by NPs andfor computing the tense of VERBs.
It is also responsible for in-serting dummy nouns in NP slots to mark the position of "wh.gaps" in questions and relative clauses.Figure 2b shows the tree NEXUS would derive for the ex-ample.
The code PN indicates past tense, and the role namesshould be self-explanatory.
During collapse, the interpreterwould be asked to rate the acceptability of each noun phrase byitself, the acceptability of the clause with the noun phrases in it,and the acceptability of the attachment.
The former ratings arenecessary to detect mis.segmented constituents, e.g., todowngrade "time flies" as a plausible subject for the sentenceTime flies like an arrow.
By Hirst's procedure, the last ratingshould be perfect for the attachment of the on.phrase to theclause as an adjunct since, without a discourse context, there isno referent for the socks on their hands and the verb wear ex-pects a case marked by on.CONJUNCTION PARSINGTo process and and or, we need to add a coordinate conjunc-tion word class (C) and three segmentation rules for it.
21.
If MSG = BEGIN,Push a clause with FUNCTION = w onto stack.Set MSG = CONJ and return.2.
If the topmost nonconjunct clause in the stack has VERB filled,Push a clause with FUNCTION = w onto stack.Set MSG = CONJ and return.3.
Otherwise,Push a preposition structure with PREP = w onto stack.Set MSG = PREP and return.The first rule is for sentence-initial conjunctions, the second forpotential clausal conjuncts and the third is for cases where theconjunction cannot join clauses.
This last case arises when nounphrases are conjoined in the subject of a sentence: John andMary wore socks.
Note that the stack structure for a noun phraseconjunct is identical to that for a prepositional phrase.To handle gaps, we also need to add one rule each to theNoun and Verb procedures.
For Verb, the rule is:4.
If MSG = CON J,Set NP1 = !sub, VERB = w in top structure,Set MSG = VERB and return.For Noun:5.
If the top structure S is a clause conjunct with NP1 filled butno VERB and there is another clause C in the stack with VERBfilled and more than one NG filled,Copy VERB filler from C to S's VERB slotIf C has NP3 filled,Transfer S's NP1 to NP2 and set S's NP1 =/sub.Insert w as new NG in S.Set MSG = NOUN and return.In both rules, !sub is a dummy placeholder for the subject of the2The conjunction but is not syntactically interchangeable with and and or sincebut cannot freely conjoin noun phrases: =John but Mary wore aock$.
The rulesfor but have not yet been developed.80clause.
Rule 4 is for verbs that appear directly after a conjunctionand rule 5 is for transitive or ditransitive conjuncts with gappedverb.To specify attachments for conjuncts, we need some recom-bination rules.
In general, elements to be conjoined must havevery similar syntactic structure.
They must be of the same type(noun phrase, clause, prepositional phrase, etc.).
If clauses, theymust serve the same function (top level assertion, infinitive, rela-tive clause, etc.
), and if non-finite clauses, any ellipsed elements(wh-gaps) must be the same.
If these conditions are met, anattachment is proposed.Additionally, in three situations, a recombination rule may alsomodify the right conjunct:1.
A clause conjunct without a verb can be proposed asa noun phrase conjunct.2.
A clause conjunct without a verb may also beproposed as a gapped verb, as in: Bob saw Sue inParis and \[Bob saw\] Linda in London.3.
When constituents from the left conjunct are ellipsed,they may have to be taken from the right conjunct, asin the famous sentence: John drove through andcompletely demolished a plate glass window.
Thistransformation is actually implemented in the finalformatting procedure since all of the trailing cases inthe right conjunct must be moved over to the left con-junct if any such movement is warranted.Since all these situations are structurally ambiguous, the inter-preter is always called to rate the modifications.
In situation 2, forinstance, it may be that there is no gap: Bob saw Sue in \[Parisand London\] in the spring of last year.
In situation 3, the gappedelement might come from context, rather than the right conjunct:Ignoring the stop sign at the intersection, John drove through andcompletely demolished his reputation as a safe driver.
Hence,only interpretation can determine which choice is most ap-propriate.Let us now examine how these rules operate by tracingthrough a few examples.
First, suppose the sentence from theprevious section were to continue with the words "and their feet".Rule 2 would respond to the conjunction, and the rest of thesegmentation would be:Input WordWord Class MSG1 MSG Stackand C = > nil CONJ FUNCTION: ANDtheir N = > nil NOUN NP1 : theirfeet N = > nil NOUN NP1 ': their feetThus, the noun rules would do what they normally do in filling thefirst NP slot in a clause structure.
If the sentence ended here,recombination would conjoin the last two noun phrases, "theirhands" end "their feet", as the complement of on, producing:{wear PNf SUB the children\] OBJ the socks\] ON their hands (AND their feet)\] }If, instead, the sentence did not end but continued with a verb-- "froze", say .- the segmentation would continue by adding thisword to the VERB slot in the top structure, which is open.
Asbefore, the rules would do what they normally do to fill a slot.Recombination would yield conjoined clauses:{wear PNrUB the children\]OBJ the socks\] _ON their hands\]AND (V freeze PN\[SUB their feet\]) }Notice that the second clause is inserted as just another caseadjunct of the first clause.
There is really no need to construct acoordinate structure (wherein both clauses would be dominatedby the conjunction) since it adds nothing to the interpretation.Moreover, as Dahl & McCord point out \[4\], it is actually better topreserve the subordination structure because it provides essen-tial information for scoping decisions.Now we move on to gaps.
Consider a new right conjunct forour original example sentence in which the subject is ellipsed:The children wore the socks on their hands ~nd froze their feet.Rule 4 would detect the gap and the resulting segmentationwould be:Input WordWord Class MSG1 MSG Stackand C = > nil CONJ FUNCTION: ANDfroze V = > nil VERB NPI: /subVERB: frozetheir N = > nil NOUN NP2: theirfeet N = ) nil NOUN NP2': their feetRecombination would yield conjoined clauses with shared sub-ject:{wear PNISUB the children\]OBJ the socks\]ON their hands\]AND (V freeze PNSUB/sub\] _OBJ their feet\]) }The appearance of /sub in the second SUB slot tells the inter-preter that the subject of the right conjunct is ?creferential withthe subject of the left conjunct.Finally, to illustrate rule 5, consider the sentence:The children wore the socks on their hands andJohn a lampshade on his head.When the parser comes to "a", rule 5 applies, the verb wore iscopied over to the second conjunct, and "a" is inserted into NP2.Thus, the segmentation of the conjunct clause looks like this:Input WordWord Class MSG1 MSG Stackand C = > nil CONJ FUNCTION: ANDJohn N = ;> nil NOUN NPI: Johna A = > nil VERB: woreNOUN NP2: slampshade N = > nil NOUN NP2': a lampshadeon P => nil PREP PREP: onhis N = > nil NOUN NP: hishead N,V => nil NOUN NP': hisheadRecombination would produce the conjunction of two completeclauses with no shared material.8 \ ]RESULTSUsing the rules described above, NEXUS can successfullyparse all the conjunction examples given in all the papers, withtwo exceptions.
It cannot parse:?
conjoined adverbs, e.g., Slowly and stealthily, hecrept toward his victim.?
embedded clausal complement gaps, e.g., Max wantsto try to begin to write a novel and Alex a play.The problem with these forms lies not so much in the conjunctionrules as in the rules for adverbs and clausal complements ingeneral.
These latter rules simply aren't very well developed yet.It is instructive to compare the NEXUS parser to that of Lesmo& Toraseo.
Like theirs, NEXUS solves the first problem men-tioned in the introduction by using transition rules rather than amore conventional declarative grammar.
Also like theirs, NEXUSsolves the third problem by means of special rules which detectgaps in conjuncts and which fill those gaps by copying con-stituents from the other conjunct.
Unlike theirs, however, NEXUSdelays recombination decisions as long as it can and so does nothave to search for possible attachments in some situations wheretheirs does.
For instance, in processingHenry repeated the story John told Mary and Bobtold Ann his opinion.their parser would first mis.attach \[and Bob\] to \[Mary\], then mis-attach \[and Bob told Ann\] to \[John told Mary\].
Each time, asearch would be made to find a new attachment when the nextword of the input was read.
NEXUS can parse this sentencesuccessfully without any mis-attachments at all.It is also instructive to compare NEXUS to the work of Church.His thesis \[3\] gives a detailed specification of a some fairlyelegant rules for conjunction (and several other constructions)along with their linguistic and psycholinguistic justification.
Whilemost of the rules are not actually exhibited, their specificationsuggests that they are similar in many ways to those in NEXUS.However, Church was primarily concerned with the implicationsof determinism and limited memory, and so his parser, YAP, doesnot defer decisions as long as NEXUS does.
Hence, YAP couldnot find, or ask for resolution of, the ambiguity in a sentence like:I know Bob and Bill left.
YAP parses this as \[I know Bob\] and \[Billleft\].
NEXUS would find both parses because the third and fifthverb rules both apply when the verb left is processed.
Note thatthese two parses are required not because of the conjunction,but because of the verb know, which can take either a nounphrase or a clause as its object.
Only one parse would be neededfor unambiguous variations uch as I know that Bob and Bill leftand I know Bob and Bill knows me.
In general, the conjunctionrules do not introduce any additional nondeterminism into thegrammar beyond that which was there already.With respect to efficiency, the table below gives the executiontimes in milliseconds for NEXUS's parsing of the sample sen-tences tabulated in \[5\].
For comparison, the times from \[5\] forMSG and RPM are also shown.
All three systems were executedon a Dec.20 and the times shown for each are just the time takento build parse trees: time spent on morphological analysis andpost-parse transformations i  not included.
MSG and RPM arewritten in Prolog and NEXUS is written in Maclisp (compiled).NEXUS was run with the 'no-interpreter' switch turned on.Sample Sentences MSG RPM NEXUSEach man ate an apple and a pear.
662 292 112John ate an apple and a pear.
613 233 95A man and a woman saw each train.
319 506 150Each man and each woman ate an apple.
320 503 129John saw and the woman heard a manthat laughed.
788 834 275John drove the car through andcompletely demolished a window.
275 1032 166The woman who gave a book to Johnand drove a car through a windowlaughed.
1007 3375 283John saw the man that Mary saw and Billgave a book to laughed.
439 311 205John saw the man that heard the womanthat laughed and saw Bill.
636 323 289The man that Mary saw and heard gavean apple to each woman.
501 982 237John saw a and Mary saw the red pear.
726 770 190In all cases, NEXUS is faster, and in the majority, it is morethat twice as fast as either other system.
Averaging over all thesentences, NEXUS is about 4 times faster than RPM and 3 timesfaster than MSG.CONCLUSIONSThe most innovative feature in NEXUS is its use of only twokinds of stack structures, one for clauses and one for everythingelse.
When a structure is at the top of the stack, it represents atop.down prediction of constituents yet to come, and words fromthe input simply drop into the slots that are open to that class ofword.
When a word is encountered that cannot be inserted intothe top structure nor into any structure lower in the stack, a newstructure is built bottom-up, the new word inserted in it, and theparse goes on.
When a word can both be inserted somewhere inthe stack and also in a new structure, all possible parses arepursued in parallel.
Thus, NEXUS seems to be a unique memberof the wait-and-see family since it is not always deterministic andhence need not disembiguate until all information it could getfrom the sentence is available.The general efficiency of the parser is due primarily to itsseparation of segmentation from recombination.
This is a divideand conquer strategy which reduces a large search space-- grammatical patterns for words in sentences -- into two smallerones: (1) the set of grammatical patterns for simple phrases andclause nuclei, and (2) the set of allowable combinations of stackstructures.
Of course, search is still required to resolve structuralambiguity, but the total number of combinations is much less.It is not clear whether the parser's speed in the particularcases above comes from divide and conquer or from the dif-ferences between Prolog and Maclisp.
Nevertheless, as systemsare built that require larger, more comprehensive grammars, andthat must deal with longer, more complicated sentences, the ef-ficiency of wait-and-see methods like those presented hereshould become increasingly important.82REFERENCES\[1\] Berwick, R.C.
(1983), "A Deterministic Parser With BroadCoverage," Proceedings of/JCA/8, Karlsruhe, W. Germany,pp.
710-712.\[2\] Boguraev, B.K.
(1983), "Recognising Conjunctions Withinthe ATN Framework," in K. Sparck-Jones and Y.
Wilks(eds.
), Automatic Natural Language Parsing, Ellis Horwood.\[3\] Church, K.W.
(1980), "On Memory Limitations in NaturalLanguage Processing," LCS TR.245, Laboratory for Com-puter Science, MIT, Cambridge, MA.Dahl, V., and McCord, M.C.
(1983), "Treating Coordination inLogic Grammars," American Journal of ComputationalLinguistics, V. 9, No.
2, pp.
69-91.\[5\] Fong, S, and Berwick, R.C.
(1985), "New Approaches toParsing Conjunctions Using Prolog," Proceedings of the23rd ACL Conference, Chicago, pp.
118-126.\[6\] Ginsparg, J.
(1978), Natural Language Processing in anAutomatic Programming Framework, AIM-316, PhD.
Thesis,Computer Science Dept., Stanford University, Stanford, CA.\[7\] Hirst, G. (in press), Semantic Interpretation and the Resolu-tion of Ambiguity, New York: Cambridge University Press.\[8\] Huang, X.
(1984), "Dealing with Conjunctions in a MachineTranslation Environment," Proceedings of COLING 84, Stan-ford, pp.
243-246.\[9\] Lesmo, L., and Torasso, P. (1985), "Analysis of Conjunctionsin a Rule.Based Parser", Proceedings of the 23rd ACLConference, Chicago, pp.
180-187.\[10\] Marcus, M. (1980), A Theory of Syntactic Recognition forNatural Language, Cambridge, MA.
: The MIT Press.83APPENDIX: SAMPLE SEGMENTATION RULESWORD CLASSA: ArticleGo begin new np with current word w.M: ModifierIf MSG = NOUN and LEGALNP(lastNP + w),Continue lestNP with w and return.Else,Go begin new np with w.N: NounIf MSG = NOUN & w = that and lastNP can take a relative clause,Push a clause with FUNCTION = THAT, NP1 = that onto stack.Set MSG = THAT and return.If MSG = NOUN or THAT & LEGALNP(laetNP + w),Continue lastNP with w.If MSG = THAT, set MSG = NOUN and return.If w is the only noun in lastNP, return.If the top clause in the stack haS no empty NP, retum.Beoin new no:if MSG = THAT,Replace NPt with w.Set MSG = NOUN and return.If there a clause C in the stack with NP empty& C is below a relative clause with VERB filled,Collapse stack down to C end insert w as now NP.Set MSG = NOUN.If the top structure in the stack has NP empty,Insert w as new NP.Set MSG = NOUN and return.If MSG = NOUN & lastNP can take a relative clause starting with w,Push a clause with FUNCTION = RC, NP1 = w onto stack.Set MSG = NOUN and return.If the topmost clause C in the stack has VERB filled,& C's VERB can take a clausal complement,Push a clause with FUNCTION = WHAT, NP1 = w onto stack.Set MSG = NOUN and return.WORD CLASSP: Prepositionit w = to & next word is infinitive verb,Push a clause with FUNCTION = INF, NP1 =/sub onto stack.Set MSG = INF and return.Else,Push a preposition structure with PREP = w onto stack.Set MSG = PREP and return.V: VerbIf MSG = BEGIN & w not inflected,Set NP1 = YOU' ,  VERB = w, NOTE = IMP.Set MSG = VERB, insert IMP in MSG1, and retum.If MSG = VERB & LEGALVP(VERB + w),Continue VERB with w and return.If there is a clause C in the stack with NP1 filled & VERB empty& AGREES(w,NP1),if C not top structure in stack, collapse stack down to C.Set C's VERB = w and set MSG = VERB.If C is a subclause, return.If the top clause C in the stack has NP3 filled,If C not top structure in stack, collapse stack down to C.Push a clause with FUNCTION = THAT, VERB = w onto stack.Transfer C's NP3 to NP1 of new clause.Set MSG = VERB and return.if the topmost clause C with VERB filled can take a clause as NP2,If C not top structure in stack, collapse stack down to C.Push a clause with FUNCTION = WHAT, VERB = w onto stack.If C's NP2 is filled, transfer C's NP2 to NP1 of now clause.Set MSG = VERB and return.DEFINITIONS1.
The current input word is w.2.
The variable lastNP refers to the contents of the last NP ~Jot filled inthe top structure,3.
The predicate LEGALVP tests whether ~s argument is s syntac-tically well.formed (partial) verb phrase (auxiliaries + verb).4.
The predicate LEGALNP tests whether its argument is a syntac-tically well-formed noun phrase (article + "modifiers + nouns).5.
The predicate AGREES tests whether an NP and a verb agree innumber.6.
A structure S "has NP empty" if S is either:?
a preposition structure with NP empty;?
a clause with no NP filled;?
a clause with NP1 filled & VERB filled & either the verb isITansitive or it is ditransitive, passive form;?
a clause with .NP1 filled & NP2 filled and ~ is ditraneitive,not pasei.ve form.7.
A relative clause is a clause with FUNCTION = RC or THAT.8.
A sol)clause is  relative clause or a clause with FUNCTION = INF orWHAT.NOTES1.
Of course, this is just a subset of the miss NEXUS actually uses.
Notshown, for example, are rules for questions, adverbs, participles,many other important coostruction?2.
Even in the full parser, there are no rules for determining theinternal structure of noun phrases.
11hat ask is handled by theintemretar.3.
The noun rules will always insert a new NP constituent into anempty NP slot if such a slot is available.
Hence, they will always fillNP3 in a clause with ?
ditrartsitive verb, end NP2 in clause whichcan take a clausal complement, even if these noun phrases turn outto be the initial NPs of relative or complement clauses.
Suchmisettachments are detected by the fourth and fifth verb rules,which respond by generating the proper structures.4.
A clause with FUNCTION = THAT represents either a complement ora relative clause.
The choice is made when the stack is collapsed.5.
The word that as sole NP constituent is either the demonstrativepronoun or a placeholder for a subsequent WHAT compiemenLThe choice is made when the stack is collapsed.84
