Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 349?362,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsProbabilistic Models of Cross-Lingual Semantic Similarity in ContextBased on Latent Cross-Lingual Concepts Induced from Comparable DataIvan Vuli?c and Marie-Francine MoensDepartment of Computer ScienceKU Leuven, Belgium{ivan.vulic|marie-francine.moens}@cs.kuleuven.beAbstractWe propose the first probabilistic approachto modeling cross-lingual semantic sim-ilarity (CLSS) in context which requiresonly comparable data.
The approach re-lies on an idea of projecting words andsets of words into a shared latent semanticspace spanned by language-pair indepen-dent latent semantic concepts (e.g., cross-lingual topics obtained by a multilingualtopic model).
These latent cross-lingualconcepts are induced from a comparablecorpus without any additional lexical re-sources.
Word meaning is represented asa probability distribution over the latentconcepts, and a change in meaning is rep-resented as a change in the distributionover these latent concepts.
We present newmodels that modulate the isolated out-of-context word representations with contex-tual knowledge.
Results on the task ofsuggesting word translations in context for3 language pairs reveal the utility of theproposed contextualized models of cross-lingual semantic similarity.1 IntroductionCross-lingual semantic similarity (CLSS) is a met-ric that measures to which extent words (or moregenerally, text units) describe similar semanticconcepts and convey similar meanings across lan-guages.
Models of cross-lingual similarity are typ-ically used to automatically induce bilingual lexi-cons and have found numerous applications in in-formation retrieval (IR), statistical machine trans-lation (SMT) and other natural language process-ing (NLP) tasks.
Within the IR framework, theoutput of the CLSS models is a key resource inthe models of dictionary-based cross-lingual in-formation retrieval (Ballesteros and Croft, 1997;Lavrenko et al., 2002; Levow et al., 2005; Wangand Oard, 2006) or may be utilized in query ex-pansion in cross-lingual IR models (Adriani andvan Rijsbergen, 1999; Vuli?c et al., 2013).
TheseCLSS models may also be utilized as an addi-tional source of knowledge in SMT systems (Ochand Ney, 2003; Wu et al., 2008).
Additionally,the models are a crucial component in the cross-lingual tasks involving a sort of cross-lingualknowledge transfer, where the knowledge aboututterances in one language may be transferred toanother.
The utility of the transfer or annotationprojection by means of bilingual lexicons obtainedfrom the CLSS models has already been provenin various tasks such as semantic role labeling(Pad?o and Lapata, 2009; van der Plas et al., 2011),parsing (Zhao et al., 2009; Durrett et al., 2012;T?ackstr?om et al., 2013b), POS tagging (Yarowskyand Ngai, 2001; Das and Petrov, 2011; T?ackstr?omet al., 2013a; Ganchev and Das, 2013), verb clas-sification (Merlo et al., 2002), inducing selectionalpreferences (Peirsman and Pad?o, 2010), namedentity recognition (Kim et al., 2012), named en-tity segmentation (Ganchev and Das, 2013), etc.The models of cross-lingual semantic similar-ity from parallel corpora rely on word alignmentmodels (Brown et al., 1993; Och and Ney, 2003),but due to a relative scarceness of parallel texts formany language pairs and domains, the models ofcross-lingual similarity from comparable corporahave gained much attention recently.All these models from parallel and compara-ble corpora provide ranked lists of semanticallysimilar words in the target language in isolationor invariably, that is, they do not explicitly iden-349tify and encode different senses of words.
Inpractice, it means that, given the sentence ?Thecoach of his team was not satisfied with the gameyesterday.
?, these context-insensitive models ofsimilarity are not able to detect that the Spanishword entrenador is more similar to the polyse-mous word coach in the context of this sentencethan the Spanish word autocar, although auto-car is listed as the most semantically similar wordto coach globally/invariably without any observedcontext.
In another example, while Spanish wordspartido, encuentro, cerilla or correspondencia areall highly similar to the ambiguous English wordmatch when observed in isolation, given the Span-ish sentence ?She was unable to find a match inher pocket to light up a cigarette.
?, it is clear thatthe strength of semantic similarity should changein context as only cerilla exhibits a strong seman-tic similarity to match within this particular sen-tential context.Following this intuition, in this paper we inves-tigate models of cross-lingual semantic similarityin context.
The context-sensitive models of sim-ilarity target to re-rank the lists of semanticallysimilar words based on the co-occurring contextsof words.
Unlike prior work (e.g., (Ng et al., 2003;Prior et al., 2011; Apidianaki, 2011)), we explorethese models in a particularly difficult and min-imalist setting that builds only on co-occurrencecounts and latent cross-lingual semantic conceptsinduced directly from comparable corpora, andwhich does not rely on any other resource (e.g.,machine-readable dictionaries, parallel corpora,explicit ontology and category knowledge).
Inthat respect, the work reported in this paper ex-tends the current research on purely statisticaldata-driven distributional models of cross-lingualsemantic similarity that are built upon the ideaof latent cross-lingual concepts (Haghighi et al.,2008; Daum?e III and Jagarlamudi, 2011; Vuli?c etal., 2011; Vuli?c and Moens, 2013) induced fromnon-parallel data.
While all the previous mod-els in this framework are context-insensitive mod-els of semantic similarity, we demonstrate how tobuild context-aware models of semantic similaritywithin the same probabilistic framework which re-lies on the same shared set of latent concepts.The main contributions of this paper are:?
We present a new probabilistic approach tomodeling cross-lingual semantic similarity incontext based on latent cross-lingual seman-tic concepts induced from non-parallel data.?
We show how to use the models of cross-lingual semantic similarity in the task of sug-gesting word translations in context.?
We provide results for three languagepairs which demonstrate that contextualizedmodels of similarity significantly outscorecontext-insensitive models.2 Towards Cross-Lingual SemanticSimilarity in ContextLatent Cross-Lingual Concepts.
Latent cross-lingual concepts/senses may be interpreted aslanguage-independent semantic concepts presentin a multilingual corpus (e.g., document-alignedWikipedia articles in English, Spanish and Dutch)that have their language-specific representations indifferent languages.
For instance, having a multi-lingual collection in English, Spanish and Dutch,and then discovering a latent semantic concepton Soccer, that concept would be represented bywords (actually probabilities over words P (w|zk),where w denotes a word, and zkdenotes k-thlatent concept): {player, goal, coach, .
.
.}
inEnglish, bal?on (ball), futbolista (soccer player),equipo (team), .
.
. }
in Spanish, and {wedstrijd(match), elftal (soccer team), doelpunt (goal), .
.
.
}in Dutch.
Given a multilingual corpus C, the goalis to learn and extract a set Z of K latent cross-lingual concepts {z1, .
.
.
, zK} that optimally de-scribe the observed data, that is, the multilingualcorpus C. Extracting cross-lingual concepts ac-tually implies learning per-document concept dis-tributions for each document in the corpus, anddiscovering language-specific representations ofthese concepts given by per-concept word distri-butions in each language.Z = {z1, .
.
.
, zK} represents the set of K la-tent cross-lingual concepts present in the multilin-gual corpus.
These K semantic concepts actuallyspan a latent cross-lingual semantic space.
Eachword w, irrespective of its actual language, maybe represented in that latent semantic space as aK-dimensional vector, where each vector compo-nent is a conditional concept score P (zk|w).A number of models may be employed to in-duce the latent concepts.
For instance, one coulduse cross-lingual Latent Semantic Indexing (Du-mais et al., 1996), probabilistic Principal Compo-nent Analysis (Tipping and Bishop, 1999), or aprobabilistic interpretation of non-negative matrix350factorization (Lee and Seung, 1999; Gaussier andGoutte, 2005; Ding et al., 2008) on concatenateddocuments in aligned document pairs.
Other morerecent models include matching canonical correla-tion analysis (Haghighi et al., 2008; Daum?e III andJagarlamudi, 2011) and multilingual probabilistictopic models (Ni et al., 2009; De Smet and Moens,2009; Mimno et al., 2009; Boyd-Graber and Blei,2009; Zhang et al., 2010; Fukumasu et al., 2012).Due to its inherent language pair indepen-dent nature and state-of-the-art performance in thetasks such as bilingual lexicon extraction (Vuli?c etal., 2011) and cross-lingual information retrieval(Vuli?c et al., 2013), the description in this pa-per relies on the multilingual probabilistic topicmodeling (MuPTM) framework.
We draw a di-rect parallel between latent cross-lingual conceptsand latent cross-lingual topics, and we presentthe framework from the MuPTM perspective, butthe proposed framework is generic and allows theusage of all other models that are able to com-pute probability scores P (zk|w).
These scores inMuPTM are induced from their output language-specific per-topic word distributions.
The mul-tilingual probabilistic topic models output prob-ability scores P (wSi|zk) and P (wTj|zk) for eachwSi?
VSand wTj?
VTand each zk?Z , and it holds?wSi?VSP (wSi|zk) = 1 and?wTj?VTP (wTj|zk) = 1.
The scores are thenused to compute scores P (zk|wSi) and P (zk|wTj)in order to represent words from the two differentlanguages in the same latent semantic space in auniform way.Context-Insensitive Models of Similarity.
With-out observing any context, the standard models ofsemantic word similarity that rely on the seman-tic space spanned by latent cross-lingual conceptsin both monolingual (Dinu and Lapata, 2010a;Dinu and Lapata, 2010b) and multilingual set-tings (Vuli?c et al., 2011) typically proceed in thefollowing manner.
Latent language-independentconcepts (e.g., cross-lingual topics or latent wordsenses) are estimated on a large corpus.
TheK-dimensional vector representation of the wordwS1?
VSis:vec(wS1) = [P (z1|wS1), .
.
.
, P (zK|wS1)] (1)Similarly, we are able to represent any target lan-guage word wT2in the same latent semantic spaceby aK-dimensional vector with scores P (zk|wT2).Each word regardless of its language is repre-sented as a distribution over K latent concepts.The similarity between wS1and some word wT2?VTis then computed as the similarity betweentheir K-dimensional vector representations usingsome of the standard similarity measures (e.g.,the Kullback-Leibler or the Jensen-Shannon diver-gence, the cosine measure).
These methods useonly global co-occurrence statistics from the train-ing set and do not take into account any contex-tual information.
They provide only out-of-contextword representations and are therefore able to de-liver only context-insensitive models of similarity.Defining Context.
Given an occurrence of aword wS1, we build its context set Con(wS1) ={cwS1, .
.
.
, cwSr} that comprises r words from VSthat co-occur with wS1in a defined contextualscope or granularity.
In this work we do not in-vestigate the influence of the context scope (e.g.,document-based, paragraph-based, window-basedcontexts).
Following the recent work from Huanget al.
(2012) in the monolingual setting, welimit the contextual scope to the sentential context.However, we emphasize that the proposed modelsare designed to be fully functional regardless ofthe actual chosen context granularity.
e.g., whenoperating in the sentential context, Con(wS1) con-sists of words occurring in the same sentence withthe particular instance of wS1.
Following Mitchelland Lapata (2008), for the sake of simplicity, weimpose the bag-of-words assumption, and do nottake into account the order of words in the contextset as well as context words?
dependency relationsto wS1.
Investigating different context types (e.g.,dependency-based) is a subject of future work.By using all words occurring with wS1in a con-text set (e.g., a sentence) to build the setCon(wS1),we do not make any distinction between ?infor-mative and ?uninformative?
context words.
How-ever, some context words bear more contextual in-formation about the observed word wS1and arestronger indicators of the correct word meaning inthat particular context.
For instance, in the sen-tence ?The coach of his team was not satisfiedwith the game yesterday?, words game and teamare strong clues that coach should be translatedas entrenador while the context word yesterdaydoes not bring any extra contextual informationthat could resolve the ambiguity.Therefore, in the final context set Con(wS1) itis useful to retain only the context words that re-351ally bring extra semantic information.
We achievethat by exploiting the same latent semantic spaceto provide the similarity score between the ob-served word wS1and each word cwSi, i = 1, .
.
.
, rfrom its context set Con(wS1).
Each word cwSimay be represented by its vector vec(cwSi) (see eq.
(1)) in the same latent semantic space, and therewe can compute the similarity between its vec-tor and vec(wS1).
We can then sort the similarityscores for each cwSiand retain only the top scoringM context words in the final set Con(wS1).
Theprocedure of context sorting and pruning shouldimprove the semantic cohesion between wS1andits context since only informative context featuresare now present in Con(wS1), and we reduce thenoise coming from uninformative contextual fea-tures that are not semantically related towS1.
Otheroptions for the context sorting and pruning arepossible, but the main goal in this paper is to il-lustrate the core utility of the procedure.3 Cross-Lingual Semantic Similarity inContext via Latent ConceptsRepresenting Context.
The probabilistic frame-work that is supported by latent cross-lingual con-cepts allows for having the K-dimensional vectorrepresentations in the same latent semantic spacespanned by cross-lingual topics for: (1) Singlewords regardless of their actual language, and (2)Sets that comprise multiple words.
Therefore, weare able to project the observed source word, alltarget words, and the context set of the observedsource word to the same latent semantic spacespanned by latent cross-lingual concepts.Eq.
(1) shows how to represent single words inthe latent semantic space.
Now, we present a wayto address compositionality, that is, we show howto build the same representations in the same latentsemantic space beyond the word level.
We need tocompute a conditional concept distribution for thecontext set Con(wS1), that is, we have to computethe probability scores P (zk|Con(wS1)) for eachzk?
Z .
Remember that the context Con(wS1)is actually a set of r (or M after pruning) wordsCon(wS1) = {cwS1, .
.
.
, cwSr}.
Under the single-topic assumption (Griffiths et al., 2007) and fol-lowing Bayes?
rule, it holds:P (zk|Con(wS1)) =P (Con(wS1)|zk)P (zk)P (Con(wS1))=P (cwS1, .
.
.
, cwSr|zk)P (zk)?Kl=1P (cwS1, .
.
.
, cwSr|zl)P (zl)(2)=?rj=1P (cwSj|zk)P (zk)?Kl=1?rj=1P (cwSj|zl)P (zl)(3)Note that here we use a simplification where weassume that all cwSj?
Con(wS1) are condition-ally independent given zk.
The assumption of theconditional independence of unigrams is a stan-dard heuristic applied in bag-of-words model inNLP and IR (e.g., one may observe a direct anal-ogy to probabilistic language models for IR wherethe assumption of independence of query wordsis imposed (Ponte and Croft, 1998; Hiemstra,1998; Lavrenko and Croft, 2001)), but we haveto forewarn the reader that in general the equa-tion P (cwS1, .
.
.
, cwSr|zk) =?rj=1P (cwSj|zk) isnot exact.
However, by adopting the conditionalindependence assumption, in case of the uniformtopic prior P (zk) (i.e., we assume that we do notposses any prior knowledge about the importanceof latent cross-lingual concepts in a multilingualcorpus), eq.
(3) may be further simplified:P (zk|Con(wS1)) ?
?rj=1P (cwSj|zk)?Kl=1?rj=1P (cwSj|zl)(4)The representation of the context set in the latentsemantic space is then:vec(Con(wS1)) = [P (z1|Con(wS1)), .
.
.
, P (zK|Con(wS1))]We can then compute the similarity betweenwords and sets of words given in the same latentsemantic space in a uniform way, irrespective oftheir actual language.
We use all these propertieswhen building our context-sensitive CLSS mod-els.One remark: As a by-product of our modelingapproach, by this procedure for computing repre-sentations for sets of words, we have in fact pavedthe way towards compositional cross-lingual mod-els of similarity which rely on latent cross-lingualconcepts.
Similar to compositional models inmonolingual settings (Mitchell and Lapata, 2010;Rudolph and Giesbrecht, 2010; Baroni and Zam-parelli, 2010; Socher et al., 2011; Grefenstetteand Sadrzadeh, 2011; Blacoe and Lapata, 2012;Clarke, 2012; Socher et al., 2012) and multilingualsettings (Hermann and Blunsom, 2014; Ko?cisk?yet al., 2014), the representation of a set of words(e.g., a phrase or a sentence) is exactly the sameas the representation of a single word; it is simplya K-dimensional real-valued vector.
Our work oninducing structured representations of words and352text units beyond words is similar to (Klemen-tiev et al., 2012; Hermann and Blunsom, 2014;Ko?cisk?y et al., 2014), but unlike them, we do notneed high-quality sentence-aligned parallel data toinduce bilingual text representations.
Moreover,this work on compositionality in multilingual set-tings is only preliminary (e.g., we treat phrases andsentences as bags-of-words), and in future workwe will aim to include syntactic information in thecomposition models as already done in monolin-gual settings (Socher et al., 2012; Hermann andBlunsom, 2013).Intuition behind the Approach.
Going back toour novel CLSS models in context, these modelsrely on the representations of words and their con-texts in the same latent semantic space spanned bylatent cross-lingual concepts/topics.
The modelsdiffer in the way the contextual knowledge is fusedwith the out-of-context word representations.The key idea behind these models is to repre-sent a word wS1in the latent semantic space as adistribution over the latent cross-lingual concepts,but now with an additional modulation of the rep-resentation after taking its local context into ac-count.
The modulated word representation in thesemantic space spanned by K latent cross-lingualconcepts is then:vec(wS1, Con(wS1)) = [P?
(z1|wS1), .
.
.
, P?
(zK|wS1)] (5)where P?
(zK|wS1) denotes the recalculated (ormodulated) probability score for the conditionalconcept/topic distribution ofwS1after observing itscontext Con(wS1).
For an illustration of the keyidea, see fig.
1.
The intuition is that the contexthelps to disambiguate the true meaning of the oc-currence of the word wS1.
In other words, afterobserving the context of the word wS1, fewer latentcross-lingual concepts will share most of the prob-ability mass in the modulated context-aware wordrepresentation.Model I: Direct-Fusion.
The first approachmakes the conditional distribution over latent se-mantic concepts directly dependent on both wordwS1and its context Con(wS1).
The probabilityscore P?
(zk|wS1) from eq.
(5) for each zk?
Z isthen given as P?
(zk|wS1) = P (zk|wS1, Con(wS1)).We have to estimate the probabilityP (zk|wS1, Con(wS1)), that is, the probability thatword wS1is assigned to the latent concept/topic zkgiven its context Con(wS1):P (zk|wS1, Con(wS1)) =P (zk, wS1)P (Con(wS1)|zk)?Kl=1P (zl, wS1)P (Con(wS1)|zl)(6)Since P (zk, wS1) = P (wS1|zk)P (zk), if we closelyfollow the derivation from eq.
(3) which showshow to project context into the latent semanticspace (and again assume the uniform topic priorP (zk)), we finally obtain the following formula:P?
(zk|wS1) ?P (wS1|zk)?rj=1P (cwSj|zk)?Kl=1P (wS1|zl)?rj=1P (cwSj|zl)(7)The ranking of all words wT2?
VTaccording totheir similarity to wS1may be computed by detect-ing the similarity score between their representa-tion in the K-dimensional latent semantic spaceand the modulated source word representation asgiven by eq.
(5) and eq.
(7) using any of the ex-isting similarity functions (Lee, 1999; Cha, 2007).The similarity score Sim(wS1, wT2, Con(wS1)) be-tween some wT2?
VTrepresented by its vectorvec(wT2) and the observed word wS1given its con-text Con(wS1) is computed as:sim(wS1, wT2, Con(wS1))= SF(vec(wS1, Con(wS1)), vec(wT2))(8)where SF denotes a similarity function.
Wordsare then ranked according to their respective sim-ilarity scores and the best scoring candidate maybe selected as the best translation of an oc-currence of the word wS1given its local con-text.
Since the contextual knowledge is inte-grated directly into the estimation of probabilityP (zk|wS1, Con(wS1)), we name this context-awareCLSS model the Direct-Fusion model.Model II: Smoothed-Fusion.
The next modelfollows the modeling paradigm established withinthe framework of language modeling (LM), wherethe idea is to ?back off?
to a lower order N-gram in case we do not possess any evidenceabout a higher-order N-gram (Jurafsky and Mar-tin, 2000).
The idea now is to smooth the repre-sentation of a word in the latent semantic spaceinduced only by the words in its local contextwith the out-of-context type-based representationof that word induced directly from a large trainingcorpus.
In other words, the modulated probabilityscore P?
(zk|wS1) from eq.
(5) is calculated as:P?
(zk|wS1) = ?1P (zk|Con(wS1)) + (1?
?1)P (zk|wS1) (9)where ?1is the interpolation parameter, P (zk|wS1)is the out-of-context conditional concept probabil-ity score as in eq.
(1), and P (zk|Con(wS1)) isgiven by eq.
(3).
This model compromises be-tween the pure contextual word representation and353z3z2z1coach(in isolation)entrenadorautocarz3z2z1coach(contextualized)entrenadorautocarThe coach of his team was notsatisfied with the game yesterday.KcoachKcoachCONTEXT-INSENSITIVE CONTEXT-SENSITIVEFigure 1: An illustrative toy example of the main intuitions in our probabilistic framework for buildingcontext sensitive models with only three latent cross-lingual concepts (axes z1, z2and z3): A changein meaning is reflected as a change in a probability distribution over latent cross-lingual concepts thatspan a shared latent semantic space.
A change in the probability distribution may then actually steer anEnglish word coach towards its correct (Spanish) meaning in context.the out-of-context word representation.
In caseswhen the local context of word wS1is informa-tive enough, the factor P (zk|Con(wS1)) is suffi-cient to provide the ranking of terms in VT, thatis, to detect words that are semantically similar towS1based on its context.
However, if the context isnot reliable, we have to smooth the pure context-based representation with the out-of-context wordrepresentation (the factor P (zk|wS1)).
We call thismodel the Smoothed-Fusion model.The ranking of words wT2?
VTthen finallyproceeds in the same manner as in Direct-Fusionfollowing eq.
(8), but now using eq.
(9) for themodulated probability scores P?
(zk|wS1).Model III: Late-Fusion.
The last model is con-ceptually similar to Smoothed-Fusion, but it per-forms smoothing at a later stage.
It proceeds intwo steps: (1) Given a target word wT2?
VT, themodel computes similarity scores separately be-tween (i) the context set Con(wS1) and wT2, and(ii) the word wS1in isolation and wT2(again, on thetype level); (2) It linearly combines the obtainedsimilarity scores.
More formally, we may write:Sim(wS1, wT2, Con(wS1))= ?2SF(vec(Con(wS1)), vec(wT2))+ (1?
?2)SF(vec(wS1), vec(wT2))(10)where ?2is the interpolation parameter.
Sincethis model computes the similarity with each tar-get word separately for the source word in isola-tion and its local context, and combines the ob-tained similarity scores after the computations,this model is called Late-Fusion.4 Experimental SetupEvaluation Task: Suggesting Word Transla-tions in Context.
Given an occurrence of a pol-ysemous word wS1?
VSin the source languageLSwith vocabulary VS, the task is to choose thecorrect translation in the target language LTofthat particular occurrence of wS1from the givenset T = {tT1, .
.
.
, tTq}, T ?
VT, of its q possibletranslations/meanings (i.e., its translation or senseinventory).
The task of suggesting a word trans-lation in context may be interpreted as ranking theq translations with respect to the observed localcontext Con(wS1) of the occurrence of the wordwS1.
The best scoring translation candidate in theranked list is then the suggested correct translationfor that particular occurrence of wS1after observ-ing its local context Con(wS1).Training Data.
We use the following corpora forinducing latent cross-lingual concepts/topics, i.e.,for training our multilingual topic model: (i) a col-lection of 13, 696 Spanish-English Wikipedia arti-cle pairs (Wiki-ES-EN), (ii) a collection of 18, 898Italian-English Wikipedia article pairs, (iii) a col-lection of 7, 612 Dutch-English Wikipedia arti-cle pairs (Wiki-NL-EN), and (iv) the Wiki-NL-EN corpus augmented with 6,206 Dutch-Englishdocument pairs from Europarl (Koehn, 2005)(Wiki+EP-NL-EN).
The corpora were previouslyused in (Vuli?c and Moens, 2013).
No explicit useis made of sentence-level alignments in Europarl.354Sentence in Italian Correct Translation (EN)1.
I primi calci furono prodotti in legno ma recentemente... stock2.
In caso di osteoporosi si verifica un eccesso di rilascio di calcio dallo scheletro... calcium3.
La crescita del calcio femminile professionistico ha visto il lancio di competizioni... football4.
Il calcio di questa pistola (Beretta Modello 21a, calibro .25) ha le guancette in materiale... stockTable 1: Example sentences from our IT evaluation dataset with corresponding correct translations.Spanish Italian DutchAmbiguous word Ambiguous word Ambiguous word(Possible senses/translations) (Possible senses/translations) (Possible senses/translations)1. estaci?on 1. raggio 1. toren(station; season) (ray; radius; spoke) (rook; tower)2. ensayo 2. accordo 2. beeld(essay; rehearsal; trial) (chord; agreement) (image; statue)3. n?ucleo 3. moto 3. blade(core; kernel; nucleus) (motion; motorcycle) (blade; leaf; magazine)4. vela 4. calcio 4.fusie(sail; candle) (calcium; football; stock) (fusion; merger)5. escudo 5. terra 5. stam(escudo; escutcheon; shield) (earth; land) (stem; trunk; tribe)6. papa 6. tavola 6. koper(Pope; potato) (board; panel; table) (copper; buyer)7. cola 7. campione 7. bloem(glue; coke; tail; queue) (champion; sample) (flower; flour)8. cometa 8. carta 8. spanning(comet; kite) (card; paper; map) (voltage; tension; stress)9. disco 9. piano 9. noot(disco; discus; disk) (floor; plane; plan; piano) (note; nut)10. banda 10. disco 10. akkoord(band; gang; strip) (disco; discus; disk) (chord; agreement)11. cinta 11. istruzione 11. munt(ribbon; tape) (education; instruction) (coin; currency; mint)12. banco 12. gabinetto 12. pool(bank; bench; shoal) (cabinet; office; toilet) (pole; pool)13. frente 13. torre 13. band(forehead; front) (rook; tower) (band; tyre; tape)14. fuga 14. campo 14. kern(escape; fugue; leak) (camp; field) (core; kernel; nucleus)15. gota 15. gomma 15. kop(gout; drop) (rubber; gum; tyre) (cup; head)Table 2: Sets of 15 ambiguous words in Spanish, Italian and Dutch from our test set accompanied by thesets of their respective possible senses/translations in English.All corpora are theme-aligned comparable cor-pora, i.e, the aligned document pairs discuss sim-ilar themes, but are in general not direct trans-lations (except for Europarl).
By training onWiki+EP-NL-EN we want to test how the trainingcorpus of higher quality affects the estimation oflatent cross-lingual concepts that span the sharedlatent semantic space and, consequently, the over-all results in the task of suggesting word transla-tions in context.
Following prior work (Koehn andKnight, 2002; Haghighi et al., 2008; Prochassonand Fung, 2011; Vuli?c and Moens, 2013), we re-tain only nouns that occur at least 5 times in thecorpus.
We record lemmatized word forms whenavailable, and original forms otherwise.
We useTreeTagger (Schmid, 1994) for POS tagging andlemmatization.Test Data.
We have constructed test datasets inSpanish (ES), Italian (IT) and Dutch (NL), wherethe aim is to find their correct translation in En-glish (EN) given the sentential context.
We haveselected 15 polysemous nouns (see tab.
2 forthe list of nouns along with their possible transla-tions) in each of the 3 languages, and have man-ually extracted 24 sentences (not present in thetraining data) for each noun that capture differentmeanings of the noun from Wikipedia.
In orderto construct datasets that are balanced across dif-ferent possible translations of a noun, in case ofq different translation candidates in T for someword wS1, the dataset contains exactly 24/q sen-tences for each translation from T .
In total, wehave designed 360 sentences for each language355pair (ES/IT/NL-EN), 1080 sentences in total.1.
Wehave used 5 extra nouns with 20 sentences each asa development set to tune the parameters of ourmodels.
As a by-product, we have built an initialrepository of ES/IT/NL ambiguous words.
Tab.1 presents a small sample from the IT evaluationdataset, and illustrates the task of suggesting wordtranslations in context.Evaluation Procedure.
Our task is to presentthe system a list of possible translations and letthe system decide a single most likely translationgiven the word and its sentential context.
Groundtruth thus contains one word, that is, one correcttranslation for each sentence from the evaluationdataset.
We have manually annotated the correcttranslation for the ground truth1by inspecting thediscourse in Wikipedia articles and the interlingualWikipedia links.
We measure the performance ofall models as Top 1 accuracy (Acc1) (Gaussier etal., 2004; Tamura et al., 2012).
It denotes the num-ber of word instances from the evaluation datasetwhose top proposed candidate in the ranked list oftranslation candidates from T is exactly the cor-rect translation for that word instance as given byground truth over the total number of test word in-stances (360 in each test dataset).Parameters.
We have tuned ?1and ?2on the de-velopment sets.
We set ?1= ?2= 0.9 for alllanguage pairs.
We use sorted context sets (seesect.
2) and perform a cut-off at M = 3 most de-scriptive context words in the sorted context setsfor all models.
In the following section we discussthe utility of this context sorting and pruning, aswell as its influence on the overall results.Inducing Latent Cross-Lingual Concepts.
Ourcontext-aware models are generic and allow ex-perimentations with different models that inducelatent cross-lingual semantic concepts.
However,in this particular work we present results obtainedby a multilingual probabilistic topic model calledbilingual LDA (Mimno et al., 2009; Ni et al.,2009; De Smet and Moens, 2009).
The BiLDAmodel is a straightforward multilingual extensionof the standard LDA model (Blei et al., 2003).For the details regarding the modeling, generativestory and training of the bilingual LDA model, werefer the interested reader to the aforementionedrelevant literature.We have used the Gibbs sampling procedure1Available at http://people.cs.kuleuven.be/?ivan.vulic/software/(Geman and Geman, 1984) tailored for BiLDAin particular for training and have experimentedwith different number of topics K in the interval300?
2500.
Here, we present only the results ob-tained withK = 2000 for all language pairs whichalso yielded the best or near-optimal performancein (Dinu and Lapata, 2010b; Vuli?c et al., 2011).Other parameters of the model are set to the typicalvalues according to Steyvers and Griffiths (2007):?
= 50/K and ?
= 0.01.2Models in Comparison.
We test the performanceof our Direct-Fusion, Smoothed-Fusion and Late-Fusion models, and compare their results withthe context-insensitive CLSS models described insect.
2 (No-Context).
We provide results withtwo different similarity functions: (1) We havetested different SF-s (e.g., the Kullback-Leiblerand the Jensen-Shannon divergence, the cosinemeasure) on the K-dimensional vector represen-tations, and have detected that in general the bestscores are obtained with the Bhattacharyya coef-ficient (BC) (Cha, 2007; Kazama et al., 2010),(2) Another similarity method we use is the so-called Cue method (Griffiths et al., 2007; Vuli?cet al., 2011), which models the probability thata target word tTiwill be generated as an as-sociation response given some cue source wordwS1.
In short, the method computes the scoreP (tTi|wS1) = P (tTi|zk)P (zk|wS1).
We can usethe scores P (tTi|wS1) obtained by inputting out-of-context probability scores P (zk|wS1) or modulatedprobability scores P?
(zk|wS1) to produce the rank-ing of translation candidates.5 Results and DiscussionThe performance of all the models in comparisonis displayed in tab.
3.
These results lead us toseveral conclusions:(i) All proposed context-sensitive CLSS modelssuggesting word translations in context signifi-cantly outperform context-insensitive CLSS mod-els, which are able to produce only word trans-lations in isolation.
The improvements in re-sults when taking context into account are ob-2We are well aware that different hyper-parameter set-tings (Asuncion et al., 2009; Lu et al., 2011), might haveinfluence on the quality of learned latent cross-lingual con-cepts/topics and, consequently, the quality of latent semanticspace, but that analysis is not the focus of this work.
Addi-tionally, we perform semantic space pruning (Reisinger andMooney, 2010; Vuli?c and Moens, 2013).
All computationsare performed over the best scoring 100 cross-lingual topicsaccording to their respective scores P (zk|wSi) similarly to(Vuli?c and Moens, 2013).356Direction: ES?EN IT?EN NL?EN (Wiki) NL?EN (Wiki+EP)ModelAcc1Acc1Acc1Acc1Acc1Acc1Acc1Acc1(SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=BC) (SF=Cue) (SF=BC) (SF=Cue)No-Context .406 .406 .408 .408 .433 .433 .433 .433Direct-Fusion .617 .575 .714 .697 .603 .592 .606 .636Smoothed-Fusion .664 .703* .731 .789* .669 .712* .692 .761*Late-Fusion .675 .667 .742 .728 .667 .644 .683 .722Table 3: Results on the 3 evaluation datasets.
Translation direction is ES/IT/NL?EN.
The improvementsof all contextualized models over non-contextualized models are statistically significant according to achi-square statistical significance test (p<0.05).
The asterisk (*) denotes significant improvements ofSmoothed-Fusion over Late-Fusion using the same significance test.served for all 3 language pairs.
The large im-provements in the results (i.e., we observe an aver-age relative increase of 51.6% for the BC+Direct-Fusion combination, 64.3% for BC+Smoothed-Fusion, 64.9% for BC+Late-Fusion, 49.1% forCue+Direct-Fusion, 76.7% for Cue+Smoothed-Fusion, and 64.5% for Cue+Late-Fusion) confirmthat the local context of a word is essential in ac-quiring correct word translations for polysemouswords, as isolated non-contextualized word repre-sentations are not sufficient.
(ii) The choice of a similarity function influencesthe results.
On average, the Cue method as SF out-performs other standard similarity functions (e.g.,Kullback-Leibler, Jensen-Shannon, cosine, BC) inthis evaluation task.
However, it is again impor-tant to state that regardless of the actual choiceof SF, context-aware models that modulate out-of-context word representations using the knowledgeof local context outscore context-insensitive mod-els that utilize non-modulated out-of-context rep-resentations (with all other parameters equal).
(iii) The Direct-Fusion model, conceptually sim-ilar to a model of word similarity in context inmonolingual settings (Dinu and Lapata, 2010a),is outperformed by the other two context-sensitivemodels.
In Direct-Fusion, the observed word andits context are modeled in the same fashion, that is,the model does not distinguish between the wordand its surrounding context when it computes themodulated probability scores P?
(zk|wS1) (see eq.(7)).
Unlike Direct-Fusion, the modeling assump-tions of Smoothed-Fusion and Late-Fusion pro-vide a clear distinction between the observed wordwS1and its context Con(wS1) and combine the out-of-context representation of wS1and its contextualknowledge into a smoothed LM-inspired proba-bilistic model.
As the results reveal, that strategyleads to better overall scores.
The best scores ingeneral are obtained by Smoothed-Fusion, but itis also outperformed by Late-Fusion in several ex-perimental runs where BC was used as SF.
How-ever, the difference in results between Smoothed-Fusion and Late-Fusion in these experimental runsis not statistically significant according to a chi-squared significance test (p < 0.05).
(iv) The results for Dutch-English are influencedby the quality of training data.
The performanceof our models of similarity is higher for modelsthat rely on latent-cross lingual topics estimatedfrom the data of higher quality (i.e., compare theresults when trained on Wiki and Wiki+EP in tab.3).
The overall quality of our models of similarityis of course dependent on the quality of the latentcross-lingual topics estimated from training data,and the quality of these latent cross-lingual con-cepts is further dependent on the quality of multi-lingual training data.
This finding is in line witha similar finding reported for the task of bilinguallexicon extraction (Vuli?c and Moens, 2013).
(v) Although Dutch is regarded as more similarto English than Italian or Spanish, we do not ob-serve any major increase in the results on bothtest datasets for the English-Dutch language paircompared to English-Spanish/Italian.
That phe-nomenon may be attributed to the difference insize and quality of our training Wikipedia datasets.Moreover, while the probabilistic framework pro-posed in this chapter is completely language pairagnostic as it does not make any language pairdependent modeling assumptions, we acknowl-edge the fact that all three language pairs com-prise languages coming from the same phylum,that is, the Indo-European language family.
Futureextensions of our probabilistic modeling frame-work also include porting the framework to othermore distant language pairs that do not share thesame roots nor the same alphabet (e.g., English-Chinese/Hindi).Analysis of Context Sorting and Pruning.
We3570.550.60.650.70.750.8Acc11 2 3 4 5 6 7 8 9 10 11 AllSize of the ranked contextES-ENIT-ENNL-EN (Wiki)NL-EN (Wiki+EP)Figure 2: The influence of the size of sorted con-text on the accuracy of word translation in context.The model is Cue+Smoothed-Fusion.also investigate the utility of context sorting andpruning, and its influence on the overall resultsin our evaluation task.
Therefore, we have con-ducted experiments with sorted context sets thatwere pruned at different positions, ranging from 1(only the most similar word to wS1in a sentence isincluded in the context set Con(wS1)) to All (allwords occurring in a same sentence with wS1areincluded in Con(wS1)).
The monolingual similar-ity between wS1and each potential context word ina sentence has been computed using BC on theirout-of-context representations in the latent seman-tic space spanned by cross-lingual topics.
Fig.
2shows how the size of the sorted context influencesthe overall results.
The presented results have beenobtained by the Cue+Smoothed-Fusion combina-tion, but a similar behavior is observed when em-ploying other combinations.Fig.
2 clearly indicates the importance of con-text sorting and pruning.
The procedure ensuresthat only the most semantically similar words in agiven scope (e.g., a sentence) influence the choiceof a correct meaning.
In other words, closelysemantically similar words in the same sentenceare more reliable indicators for the most probableword meaning.
They are more informative in mod-ulating the out-of-context word representations incontext-sensitive similarity models.
We observelarge improvements in scores when we retain onlythe top M semantically similar words in the con-text set (e.g., when M=5, the scores are 0.694,0.758, 0.717, and 0.767 for ES-EN, IT-EN, NL-EN (Wiki) and NL-EN (Wiki+EP), respectively;while the same scores are 0.572, 0.703, 0.639 and0.672 when M=All).6 Conclusions and Future WorkWe have proposed a new probabilistic approach tomodeling cross-lingual semantic similarity in con-text, which relies only on co-occurrence countsand latent cross-lingual concepts which can be es-timated using only comparable data.
The approachis purely statistical and it does not make any ad-ditional language-pair dependent assumptions; itdoes not rely on a bilingual lexicon, orthographicclues or predefined ontology/category knowledge,and it does not require parallel data.The key idea in the approach is to representwords, regardless of their actual language, as dis-tributions over the latent concepts, and both out-of-context and contextualized word representa-tions are then presented in the same latent spacespanned by the latent semantic concepts.
Achange in word meaning after observing its con-text is reflected in a change of its distributionover the latent concepts.
Results for three lan-guage pairs have clearly shown the importanceof the newly developed modulated or ?contextual-ized?
word representations in the task of suggest-ing word translations in context.We believe that the proposed framework is onlya start, as it ignites a series of new research ques-tions and perspectives.
One may further exam-ine the influence of context scope (e.g., document-based vs. sentence-based vs. window-based con-texts), as well as context selection and aggregation(see sect.
2) on the contextualized models.
Forinstance, similar to the model from?O S?eaghdhaand Korhonen (2011) in the monolingual setting,one may try to introduce dependency-based con-texts (Pad?o and Lapata, 2007) and incorporatethe syntax-based knowledge in the context-awareCLSS modeling.
It is also worth studying othermodels that induce latent semantic concepts frommultilingual data (see sect.
2) within this frame-work of context-sensitive CLSS modeling.
Onemay also investigate a similar approach to context-sensitive CLSS modeling that could operate withexplicitly defined concept categories (Gabrilovichand Markovitch, 2007; Cimiano et al., 2009; Has-san and Mihalcea, 2009; Hassan and Mihalcea,2011; McCrae et al., 2013).AcknowledgmentsWe would like to thank the anonymous review-ers for their comments and suggestions.
This re-search has been carried out in the framework of theSmart Computer-Aided Translation Environment(SCATE) project (IWT-SBO 130041).358ReferencesMirna Adriani and C. J. van Rijsbergen.
1999.
Termsimilarity-based query expansion for cross-languageinformation retrieval.
In Proceedings of the 3rd Eu-ropean Conference on Research and Advanced Tech-nology for Digital Libraries (ECDL), pages 311?322.Marianna Apidianaki.
2011.
Unsupervised cross-lingual lexical substitution.
In Proceedings of the 1stWorkshop on Unsupervised Learning in NLP, pages13?23.Arthur Asuncion, Max Welling, Padhraic Smyth, andYee Whye Teh.
2009.
On smoothing and inferencefor topic models.
In Proceedings of the 25th Confer-ence on Uncertainty in Artificial Intelligence (UAI),pages 27?34.Lisa Ballesteros and W. Bruce Croft.
1997.
Phrasaltranslation and query expansion techniques forcross-language information retrieval.
In Proceed-ings of the 20th Annual International ACM SIGIRConference on Research and Development in Infor-mation Retrieval (SIGIR), pages 84?91.Marco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Represent-ing adjective-noun constructions in semantic space.In Proceedings of the 2010 Conference on Em-pirical Methods in Natural Language Processing(EMNLP), pages 1183?1193.William Blacoe and Mirella Lapata.
2012.
A com-parison of vector-based representations for seman-tic composition.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 546?556.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet Allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Jordan Boyd-Graber and David M. Blei.
2009.
Mul-tilingual topic models for unaligned text.
In Pro-ceedings of the 25th Conference on Uncertainty inArtificial Intelligence (UAI), pages 75?82.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics,19(2):263?311.Sung-Hyuk Cha.
2007.
Comprehensive survey on dis-tance/similarity measures between probability den-sity functions.
International Journal of Mathe-matical Models and Methods in Applied Sciences,1(4):300?307.Philipp Cimiano, Antje Schultz, Sergej Sizov, PhilippSorg, and Steffen Staab.
2009.
Explicit versus la-tent concept models for cross-language informationretrieval.
In Proceedings of the 21st InternationalJoint Conference on Artifical Intelligence (IJCAI),pages 1513?1518.Daoud Clarke.
2012.
A context-theoretic frame-work for compositionality in distributional seman-tics.
Computational Linguistics, 38(1):41?71.Dipanjan Das and Slav Petrov.
2011.
Unsuper-vised part-of-speech tagging with bilingual graph-based projections.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies (ACL-HLT), pages 600?609.Hal Daum?e III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by min-ing unseen words.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies (ACL-HLT), pages 407?412.Wim De Smet and Marie-Francine Moens.
2009.Cross-language linking of news stories on the Webusing interlingual topic modeling.
In Proceedings ofthe CIKM 2009 Workshop on Social Web Search andMining (SWSM@CIKM), pages 57?64.Chris H. Q. Ding, Tao Li, and Wei Peng.
2008.
Onthe equivalence between non-negative matrix fac-torization and probabilistic latent semantic index-ing.
Computational Statistics & Data Analysis,52(8):3913?3927.Georgiana Dinu and Mirella Lapata.
2010a.
Measur-ing distributional similarity in context.
In Proceed-ings of the 2010 Conference on Empirical Methodsin Natural Language Processing (EMNLP), pages1162?1172.Georgiana Dinu and Mirella Lapata.
2010b.
Topicmodels for meaning similarity in context.
In Pro-ceedings of the 23rd International Conference onComputational Linguistics (COLING), pages 250?258.Susan T. Dumais, Thomas K. Landauer, and MichaelLittman.
1996.
Automatic cross-linguistic infor-mation retrieval using Latent Semantic Indexing.In Proceedings of the SIGIR Workshop on Cross-Linguistic Information Retrieval, pages 16?23.Greg Durrett, Adam Pauls, and Dan Klein.
2012.
Syn-tactic transfer using a bilingual lexicon.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 1?11.Kosuke Fukumasu, Koji Eguchi, and Eric P. Xing.2012.
Symmetric correspondence topic models formultilingual text analysis.
In Procedings of the 25thAnnual Conference on Advances in Neural Informa-tion Processing Systems (NIPS), pages 1295?1303.359Evgeniy Gabrilovich and Shaul Markovitch.
2007.Computing semantic relatedness using Wikipedia-based explicit semantic analysis.
In Proceedings ofthe 20th International Joint Conference on ArtificialIntelligence (IJCAI), pages 1606?1611.Kuzman Ganchev and Dipanjan Das.
2013.
Cross-lingual discriminative learning of sequence modelswith posterior regularization.
In Proceedings of the2013 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 1996?2006.
?Eric Gaussier and Cyril Goutte.
2005.
Relation be-tween PLSA and NMF and implications.
In Pro-ceedings of the 28th Annual International ACM SI-GIR Conference on Research and Development inInformation Retrieval (SIGIR), pages 601?602.
?Eric Gaussier, Jean-Michel Renders, Irina Matveeva,Cyril Goutte, and Herv?e D?ejean.
2004.
A geomet-ric view on bilingual lexicon extraction from com-parable corpora.
In Proceedings of the 42nd AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 526?533.Stuart Geman and Donald Geman.
1984.
Stochas-tic relaxation, Gibbs distributions, and the Bayesianrestoration of images.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 6(6):721?741.Edward Grefenstette and Mehrnoosh Sadrzadeh.
2011.Experimental support for a categorical composi-tional distributional model of meaning.
In Proceed-ings of the 2011 Conference on Empirical Methodsin Natural Language Processing (EMNLP), pages1394?1404.Thomas L. Griffiths, Mark Steyvers, and Joshua B.Tenenbaum.
2007.
Topics in semantic representa-tion.
Psychological Review, 114(2):211?244.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of the46th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies (ACL-HLT), pages 771?779.Samer Hassan and Rada Mihalcea.
2009.
Cross-lingual semantic relatedness using encyclopedicknowledge.
In Proceedings of the 2009 Conferenceon Empirical Methods in Natural Language Pro-cessing (EMNLP), pages 1192?1201.Samer Hassan and Rada Mihalcea.
2011.
Semanticrelatedness using salient semantic analysis.
In Pro-ceedings of the 25th AAAI Conference on ArtificialIntelligence (AAAI), pages 884?889.Karl Moritz Hermann and Phil Blunsom.
2013.
Therole of syntax in vector space models of composi-tional semantics.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 894?904.Karl Moritz Hermann and Phil Blunsom.
2014.
Mul-tilingual models for compositional distributed se-mantics.
In Proceedings of the 52nd Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 58?68.Djoerd Hiemstra.
1998.
A linguistically motivatedprobabilistic model of information retrieval.
In Pro-ceedings of the 2nd European Conference on Re-search and Advanced Technology for Digital Li-braries (ECDL), pages 569?584.Eric H. Huang, Richard Socher, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Improving wordrepresentations via global context and multiple wordprototypes.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 873?882.Daniel Jurafsky and James H. Martin.
2000.
Speechand Language Processing: An Introduction to Nat-ural Language Processing, Computational Linguis-tics, and Speech Recognition.
Prentice Hall PTR.Jun?ichi Kazama, Stijn De Saeger, Kow Kuroda,Masaki Murata, and Kentaro Torisawa.
2010.
ABayesian method for robust estimation of distribu-tional similarities.
In Proceedings of the 48th An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 247?256.Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.2012.
Multilingual named entity recognition usingparallel data and metadata from Wikipedia.
In Pro-ceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages694?702.Alexandre Klementiev, Ivan Titov, and Binod Bhat-tarai.
2012.
Inducing crosslingual distributed repre-sentations of words.
In Proceedings of the 24th In-ternational Conference on Computational Linguis-tics (COLING), pages 1459?1474.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
InProceedings of the ACL Workshop on UnsupervisedLexical Acquisition (ULA), pages 9?16.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of the10th Machine Translation Summit (MT SUMMIT),pages 79?86.Tom?a?s Ko?cisk?y, Karl Moritz Hermann, and Phil Blun-som.
2014.
Learning bilingual word representationsby marginalizing alignments.
In Proceedings of the52nd Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 224?229.Victor Lavrenko and W. Bruce Croft.
2001.Relevance-based language models.
In Proceedingsof the 24th Annual International ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval (SIGIR), pages 120?127.360Victor Lavrenko, Martin Choquette, and W. BruceCroft.
2002.
Cross-lingual relevance models.
InProceedings of the 25th Annual International ACMSIGIR Conference on Research and Development inInformation Retrieval (SIGIR), pages 175?182.Daniel D. Lee and H. Sebastian Seung.
1999.
Al-gorithms for non-negative matrix factorization.
InProceedings of the 12th Conference on Advancesin Neural Information Processing Systems (NIPS),pages 556?562.Lillian Lee.
1999.
Measures of distributional sim-ilarity.
In Proceedings of the 37th Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 25?32.Gina-Anne Levow, Douglas W. Oard, and PhilipResnik.
2005.
Dictionary-based techniques forcross-language information retrieval.
InformationProcessing and Management, 41(3):523?547.Yue Lu, Qiaozhu Mei, and Chengxiang Zhai.
2011.Investigating task performance of probabilistic topicmodels: An empirical study of PLSA and LDA.
In-formation Retrieval, 14(2):178?203.John Philip McCrae, Philipp Cimiano, and RomanKlinger.
2013.
Orthonormal explicit topic analysisfor cross-lingual document matching.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing (EMNLP), pages1732?1740.Paola Merlo, Suzanne Stevenson, Vivian Tsang, andGianluca Allaria.
2002.
A multilingual paradigmfor automatic verb classification.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 207?214.David Mimno, Hanna Wallach, Jason Naradowsky,David A. Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 880?889.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
In Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 236?244.Jeff Mitchell and Mirella Lapata.
2010.
Compositionin distributional models of semantics.
Cognitive Sci-ence, 34(8):1388?1429.Hwee Tou Ng, Bin Wang, and Yee Seng Chan.
2003.Exploiting parallel texts for word sense disambigua-tion: An empirical study.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 455?462.Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.2009.
Mining multilingual topics from Wikipedia.In Proceedings of the 18th International World WideWeb Conference (WWW), pages 1155?1156.Diarmuid?O S?eaghdha and Anna Korhonen.
2011.Probabilistic models of similarity in syntactic con-text.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 1047?1057.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Sebastian Pad?o and Mirella Lapata.
2007.Dependency-based construction of semantic spacemodels.
Computational Linguistics, 33(2):161?199.Sebastian Pad?o and Mirella Lapata.
2009.
Cross-lingual annotation projection for semantic roles.Journal of Artificial Intelligence Research, 36:307?340.Yves Peirsman and Sebastian Pad?o.
2010.
Cross-lingual induction of selectional preferences withbilingual vector spaces.
In Proceedings of the 11thMeeting of the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies (NAACL-HLT), pages 921?929.Jay M. Ponte and W. Bruce Croft.
1998.
A languagemodeling approach to information retrieval.
In Pro-ceedings of the 21st Annual International ACM SI-GIR Conference on Research and Development inInformation Retrieval (SIGIR), pages 275?281.Anat Prior, Shuly Wintner, Brian MacWhinney, andAlon Lavie.
2011.
Translation ambiguity in andout of context.
Applied Psycholinguistics, 32(1):93?111.Emmanuel Prochasson and Pascale Fung.
2011.
Rareword translation extraction from aligned compara-ble documents.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies (ACL-HLT), pages 1327?1335.Joseph Reisinger and Raymond J. Mooney.
2010.A mixture model with sharing for lexical seman-tics.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 1173?1182.Sebastian Rudolph and Eugenie Giesbrecht.
2010.Compositional matrix-space models of language.
InProceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages907?916.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of theInternational Conference on New Methods in Lan-guage Processing.Richard Socher, Eric H. Huang, Jeffrey Pennington,Andrew Y. Ng, and Christopher D. Manning.
2011.Dynamic pooling and unfolding recursive autoen-coders for paraphrase detection.
In Proceedings ofthe 24th Annual Conference on Advances in Neural361Information Processing Systems (NIPS), pages 801?809.Richard Socher, Brody Huval, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Semantic com-positionality through recursive matrix-vector spaces.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 1201?1211.Mark Steyvers and Tom Griffiths.
2007.
Probabilistictopic models.
Handbook of Latent Semantic Analy-sis, 427(7):424?440.Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, RyanMcDonald, and Joakim Nivre.
2013a.
Token andtype constraints for cross-lingual part-of-speech tag-ging.
Transactions of ACL, 1:1?12.Oscar T?ackstr?om, Ryan McDonald, and Joakim Nivre.2013b.
Target language adaptation of discriminativetransfer parsers.
In Proceedings of the 14th Meetingof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies (NAACL-HLT), pages 1061?1071.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from compara-ble corpora using label propagation.
In Proceed-ings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 24?36.Michael E. Tipping and Christopher M. Bishop.
1999.Mixtures of probabilistic principal component anal-ysers.
Neural Computation, 11(2):443?482.Lonneke van der Plas, Paola Merlo, and James Hen-derson.
2011.
Scaling up automatic cross-lingualsemantic role annotation.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies(ACL-HLT), pages 299?304.Ivan Vuli?c and Marie-Francine Moens.
2013.
Cross-lingual semantic similarity of words as the similarityof their semantic word responses.
In Proceedings ofthe 14th Meeting of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies (NAACL-HLT), pages106?116.Ivan Vuli?c, Wim De Smet, and Marie-Francine Moens.2011.
Identifying word translations from compara-ble corpora using latent topic models.
In Proceed-ings of the 49th Annual Meeting of the Associationfor Computational Linguistics: Human LanguageTechnologies (ACL-HLT), pages 479?484.Ivan Vuli?c, Wim De Smet, and Marie-Francine Moens.2013.
Cross-language information retrieval modelsbased on latent topic models trained with document-aligned comparable corpora.
Information Retrieval,16(3):331?368.Jianqiang Wang and Douglas W. Oard.
2006.
Com-bining bidirectional translation and synonymy forcross-language information retrieval.
In Proceed-ings of the 29th Annual International ACM SIGIRConference on Research and Development in Infor-mation Retrieval (SIGIR), pages 202?209.Hua Wu, Haifeng Wang, and Chengqing Zong.
2008.Domain adaptation for statistical machine transla-tion with domain dictionary and monolingual cor-pora.
In Proceedings of the 22nd International Con-ference on Computational Linguistics (COLING),pages 993?1000.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual POS taggers and NP bracketers via robustprojection across aligned corpora.
In Proceedingsof the 2nd Meeting of the North American Chap-ter of the Association for Computational Linguistics(NAACL), pages 200?207.Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai.2010.
Cross-lingual latent topic extraction.
In Pro-ceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages1128?1137.Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.2009.
Cross language dependency parsing using abilingual lexicon.
In Proceedings of the 47th An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 55?63.362
