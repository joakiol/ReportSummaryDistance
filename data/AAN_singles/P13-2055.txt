Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 306?311,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsEnhanced and Portable Dependency Projection AlgorithmsUsing Interlinear Glossed TextRyan GeorgiUniversity of WashingtonSeattle, WA 98195, USArgeorgi@uw.eduFei XiaUniversity of WashingtonSeattle, WA 98195, USAfxia@uw.eduWilliam D. LewisMicrosoft ResearchRedmond, WA 98052, USAwilewis@microsoft.comAbstractAs most of the world?s languages areunder-resourced, projection algorithmsoffer an enticing way to bootstrap theresources available for one resource-poor language from a resource-rich lan-guage by means of parallel text andword alignment.
These algorithms,however, make the strong assumptionthat the language pairs share commonstructures and that the parse trees willresemble one another.
This assump-tion is useful but often leads to errorsin projection.
In this paper, we willaddress this weakness by using treescreated from instances of InterlinearGlossed Text (IGT) to discover pat-terns of divergence between the lan-guages.
We will show that this methodimproves the performance of projectionalgorithms significantly in some lan-guages by accounting for divergence be-tween languages using only the partialsupervision of a few corrected trees.1 IntroductionWhile thousands of languages are spokenin the world, most of them are consideredresource-poor in the sense that they do nothave a large number of electronic resourcesthat can be used to build NLP systems.
Forinstance, some languages may lack treebanks,thus making it difficult to build a high-qualitystatistical parser.One common approach to address this prob-lem is to take advantage of bitext between aresource-rich language (e.g., English) and aresource-poor language by projecting informa-tion from the former to the latter (Yarowskyand Ngai, 2001; Hwa et al, 2004).
While pro-jection methods can provide a great deal of in-formation at minimal cost to the researchers,they do suffer from structural divergence be-tween the language-poor language (aka targetlanguage) and the resource-rich language (akasource language).In this paper, we propose a middle groundbetween manually creating a large-scale tree-bank (which is expensive and time-consuming)and relying on the syntactic structures pro-duced by a projection algorithm alone (whichare error-prone).Our approach has several steps.
First, weutilize instances of Interlinear Glossed Text(IGT) following Xia and Lewis (2007) as seenin Figure 1(a) to create a small set of paralleldependency trees through projection and thenmanually correct the dependency trees.
Sec-ond, we automatically analyze this small setof parallel trees to find patterns where the cor-rected data differs from the projection.
Third,those patterns are incorporated to the projec-tion algorithm to improve the quality of pro-jection.
Finally, the features extracted fromthe projected trees are added to a statisti-cal parser to improve parsing quality.
Theoutcome of this work are both an enhancedprojection algorithm and a better parser forresource-poor languages that require a mini-mal amount of manual effort.2 Previous WorkFor this paper, we will be building uponthe standard projection algorithm for depen-dency structures as outlined in Quirk et al(2005) and illustrated in Figure 1.
First, asentence pair between resource-rich (source)and resource-poor (target) languages is wordaligned [Fig 1(a)].
Second, the source sen-tence is parsed by a dependency parser forthe source language [Fig 1(b)].
Third, sponta-306siwA ne pAnI se GadZe ko BarASita filled the clay-pot with waterSita erg water with clay-pot acc filled(a) An Interlinear Glossed Text (IGT) instance in Hindiand word alignment between the gloss line and theEnglish translation.Sitafilledtheclay-pot withwater(b) Dependency parse of English translation.siwABarAtheGadZe sepAnI(c) English words are replaced with Hindi words andspontaneous word ?the?
are removed from the tree.siwABarAGadZesepAnIne ko(d) Siblings in the tree are reordered based on the wordorder of the Hindi sentence and spontaneous Hindiwords are attached as indicated by dotted lines.
Thewords pAnI and se are incorrectly inverted, as indi-cated by the curved arrow.Figure 1: An example of projecting a depen-dency tree from English to Hindi.neous (unaligned) source words are removed,and the remaining words are replaced withcorresponding words in the target side [Fig1(c)].
Finally, spontaneous target words arere-attached heuristically and the children of ahead are ordered based on the word order inthe target sentence [Fig 1(d)].
The resultingtree may have errors (e.g., pAni should dependon se in Figure 1(d)), and the goal of this studyis to reduce common types of projection errors.In Georgi et al (2012a), we proposed amethod for analyzing parallel dependency cor-pora in which word alignment between treeswas used to determine three types of edge con-figurations: merged, swapped, and spon-taneous.
Merged alignments were those inwhich multiple words in the target tree alignedto a single word in the source tree, as in Figure2.
Swapped alignments were those in whicha parent node in the source tree aligned to achild in the target tree and vice-versa.
Finally,spontaneous alignments were those for whicha word did not align to any word on the otherside.
These edge configurations could be de-tected from simple parent?child edges and thealignment (or lack of) between words in thelanguage pairs.
Using these simple, language-agnostic measures allows one to look for diver-gence types such as those described by Dorr(1994).Georgi et al (2012b) described a methodin which new features were extracted fromthe projected trees and added to the featurevectors for a statistical dependency parser.The rationale was that, although the projectedtrees were error-prone, the parsing modelshould be able to set appropriate weights ofthese features based on how reliable these fea-tures were in indicating the dependency struc-ture.
We started with the MSTParser (Mc-Donald et al, 2005) and modified it so that theedges from the projected trees could be usedas features at parse time.
Experiments showedthat adding new features improved parsingperformance.In this paper, we use the small training cor-pus built in Georgi et al (2012b) to improvethe projection algorithm itself.
The improvedprojected trees are in turn fed to the statisticalparser to further improve parsing results.3 Enhancements to the projectionalgorithmWe propose to enhance the projection algo-rithm by addressing the three alignment typesdiscussed earlier:1.
Merge: better informed choice for headfor multiply-aligned words.2.
Swap: post-projection correction of fre-quently swapped word pairs.3.
Spontaneous: better informed attach-ment of target spontaneous words.The detail of the enhancements are ex-plained below.3.1 Merge Correction?Merged?
words, or multiple words on the tar-get side that align to a single source word, areproblematic for the projection algorithm be-cause it is not clear which target word shouldbe the head and which word should be the307rAma buxXimAna lagawA hERam intelligent seem be-Pres?Ram seems intelligent?seemsVBZRamNNPintelligentJJlagawAseemsramRambuxXimAnaintelligenthEbe-PresFigure 2: An example of merged alignment,where the English word seems align to twoHindi words hE and lagawA.
Below the IGTare the dependency trees for English andHindi.
Dotted arrows indicate word align-ment, and the solid arrow indicates that hEshould depend on lagawA.dependent.
An example is given in Figure 2,where the English word seems align to twoHindi words hE and lagawA.On the other hand, from the small amountof labeled training data (i.e., a set of hand-corrected tree pairs), we can learn what kindof source words are likely to align to multipletarget words, and which target word is likely tothe head.
The process is illustrated in Figure3.
In this example, the target words tm andtn are both aligned with the source word siwhose POS tag is POSi, and tm appears beforetn in the target sentence.
Going through theexamples of merged alignments in the trainingdata, we keep a count for the POS tag of thesource word and the position of the head onthe target side.1 Based on these counts, oursystem will generate rules such as the ones inFigure 3(c) which says if a source word whosePOS is POSi aligns to two target words, theprobability of the right target word dependingon the left one is 75%, and the probability ofthe left target word depending on the right oneis 25%.
We use maximum likelihood estimate(MLE) to calculate the probability.The projection algorithm will use those rulesto handle merged alignment; that is, when asource word aligns to multiple target words,the algorithm determines the direction of de-pendency edge based on the direction prefer-ence stored in the rules.
In addition to rules for1We use the position of the head, not the POS tag ofthe head, because the POS tags of the target words arenot available when running the projection algorithm onthe test data.siPOSitmtn(a) Alignment between a source word and two targetwords, and one target word tm is the parent of theother word tn.tmtnto... tp(b) Target sentence showing the ?left?
dependency be-tween tm and tn.POSi ?
left 0.75POSi ?
right 0.25(c) Rules for handling merged alignmentFigure 3: Example of merged alignment andrules derived from such an examplean individual source POS tag, our method alsokeeps track of the overall direction preferencefor all the merged examples in that language.For merges in which the source POS tag is un-seen or there are no rules for that tag, thislanguage-wide preference is used as a backoff.3.2 Swap CorrectionAn example of swapped alignment is in Figure4(a), where (sj , si) is an edge in the sourcetree, (tm, tn) is an edge in the target tree, andsj aligns to tn and si aligns to tm.
Figure1(d) shows an error made by the projectionalgorithm due to swapped alignment.
In orderto correct such errors, we count the numberof (POSchild, POSparent) dependency edges inthe source trees, and the number of times thatthe directions of the edges are reversed on thetarget side.
Figure 4(b) shows a possible set ofcounts resulting from this approach.
Based onthe counts, we keep only the POS pairs thatappear in at least 10% of training sentencesand the percentage of swap for the pairs areno less than 70%.2 We say that those pairstrigger a swap operation.At the test time, swap rules are applied as apost-processing step to the projected tree.
Af-ter the projected tree is completed, our swaphandling step checks each edge in the sourcetree.
If the POS tag pair for the edge triggers2These thresholds are set empirically.308siPOSitmtnsjPOSj(a) A swapped alignment between source words sj andsi and target words tm and tn.POS Pair Swaps Total %(POSi, POSj) ?
16 21 76(POSk, POSl) ?
1 1 100(POSn, POSo) ?
1 10 10(b) Example set of learned swap rules.
Swaps counts thenumber of times the given (child, parent) pair is seenin a swap configuration in the source side, and totalis the number of times said pair occurs overall.Figure 4: Example swap configuration and col-lected statistics.jl m no phi k lm no phi kjFigure 5: Swap operation: on the left is theoriginal tree; on the right is the tree afterswapping node l with its parent j.a swap operation, the corresponding nodes inthe projected tree will be swapped, as illus-trated in Figure 5.3.3 Spontaneous ReattachmentTarget spontaneous words are difficult to han-dle because they do not align to any sourceword and thus there is nothing to project tothem.
To address this problem, we collect twotypes of information from the training data.First, we keep track of all the lexical itemsthat appear in the training trees, and the rel-ative position of their head.
This lexical ap-proach may be useful in handling closed-classwords which account for a large percentage ofspontaneous words.
Second, we use the train-ing trees to determine the favored attachmentdirection for the language as a whole.At the test time, for each spontaneous wordin the target sentence, if it is one of the wordsfor which we have gathered statistics from thetraining data, we attach it to the next wordin the preferred direction for that word.
If theword is unseen, we attach it using the overalllanguage preference as a backoff.3.4 Parser EnhancementsIn addition to above enhancements to the pro-jection algorithm itself, we train a dependencyparser on the training data, with new featuresfrom the projected trees following Georgi et al(2012b).
Furthermore, we add features thatindicate whether the current word appears ina merge or swap configuration.
The resultsof this combination of additional features andimproved projection is shown in Table 1(b).4 ResultsFor evaluation, we use the same data sets asin Georgi et al (2012b), where there is a smallnumber (ranging from 46 to 147) of tree pairsfor each of the eight languages.
The IGTinstances for those tree pairs come from theHindi Treebank (Bhatt et al, 2009) and theOnline Database of Interlinear Text (ODIN)(Lewis and Xia, 2010).We ran 10-fold cross validation and reportedthe average of 10 runs in Table 1.
The top ta-ble shows the accuracy of the projection algo-rithm, and the bottom table shows parsing ac-curacy of MSTParser with or without addingfeatures from the projected trees.
In both ta-bles, the Best row uses the enhanced projec-tion algorithm.
The Baseline rows use theoriginal projection algorithm in Quirk et al(2005) where the word in the parentheses in-dicates the direction of merge.
The Error Re-duction row shows the error reduction of theBest system over the best performing baselinefor each language.
The No Projection row inthe second table shows parsing results whenno features from the projected trees are addedto the parser, and the last row in that tableshows the error reduction of the Best row overthe No Projection row.Table 1 shows that using features from theprojected trees provides a big boost to thequality of the statistical parser.
Furthermore,the enhancements laid out in Section 3 im-prove the performance of both the projectionalgorithm and the parser that uses featuresfrom projected trees.
The degree of improve-ment may depend on the properties of a par-ticular language pair and the labeled data we309(a) The accuracies of the original projection algorithm (the Baselin rows) and the enhanced algorithm (the Bestrow) on eight language pairs.
For each language, the best performing baseline is in italic.
The last row showsthe error reduction of the Best row over the best performing baseline, which is calculated by the formulaErrorRate = Best?BestBaseline100?BestBaseline ?
100YAQ WLS HIN KKN GLI HUA GER MEXBest 88.03 94.90 77.44 91.75 87.70 90.11 88.71 93.05Baseline (Right) 87.28 89.80 57.48 90.34 86.90 79.31 88.03 89.57Baseline (Left) 84.29 89.80 68.11 88.93 76.98 79.54 88.03 89.57Error Reduction 5.90 50.00 29.26 14.60 6.11 51.66 5.68 33.37(b) The parsing accuracies of the MSTParser with or without new features extracted from projected trees.
Thereare two error reduction rows: one is with respect to the best performing baseline for each language, the otheris with respect to No Projection where the parser does not use features from projected trees.YAQ WLS HIN KKN GLI HUA GER MEXBest 89.28 94.90 81.35 92.96 81.35 88.74 92.93 93.05Baseline (Right) 88.28 94.22 78.03 92.35 80.95 87.59 90.48 92.43Baseline (Left) 87.88 94.22 79.64 90.95 80.95 89.20 90.48 92.43No Projection 66.08 91.32 65.16 80.75 55.16 72.22 62.72 73.03Error Reduction (BestBaseline) 8.53 11.76 8.40 7.97 2.10 -4.26 25.74 8.19Error Reduction (No Projection) 68.39 41.24 46.47 63.43 58.41 59.47 81.04 74.23Table 1: System performance on eight languages: Yaqui (YAQ), Welsh (WLS), Hindi (HIN),Korean (KKN), Gaelic (GLI), Hausa (HUA), German (GER), and Malagasy (MEX).have for that language pair.
For instance,swap is quite common for the Hindi-Englishpair because postpositions depend on nounsin Hindi whereas nouns depend on preposi-tions in English.
As a result, the enhancementfor the swapped alignment alone results in alarge error reduction, as in Table 2.
This ta-ble shows the projection accuracy on the Hindidata when each of the three enhancements isturned on or off.
The rows are sorted by de-scending overall accuracy, and the row thatcorresponds to the system labeled ?Best?
inTable 1 is in bold.5 ConclusionExisting projection algorithms suffer from theeffects of structural divergence between lan-guage pairs.
We propose to learn common di-vergence types from a small number of treepairs and use the learned rules to improve pro-jection accuracy.
Our experiments show no-table gains for both projection and parsingwhen tested on eight language pairs.
As IGTdata is available for hundreds of languagesthrough the ODIN database and other sources,one could produce a small parallel treebankfor a language pair after spending a few hoursmanually correcting the output of a projec-tion algorithm.
From the treebank, a bet-ter projection algorithm and a better parsercan be built automatically using our approach.Spont Swap Merge Direction AccuracyX X Left 78.07X X Informed 77.44X Left 76.69X Informed 76.06X Left 69.49X Informed 68.96Left 68.11Informed 67.58X X Right 66.32X Right 64.97X Right 58.84Right 57.48Table 2: Projection accuracy on the Hindidata, with the three enhancements turningon or off.
The ?spont?
and ?swap?
columnsshow a checkmark when the enhancementsare turned on.
The merge direction indicateswhether a left or right choice was made as abaseline, or whether the choice was informedby the rules learned from the training data.While the improvements for some languagesare incremental, the scope of coverage for thismethod is potentially enormous, enabling therapid creation of tools for under-resourced lan-guages of all kinds at a minimal cost.AcknowledgmentThis work is supported by the National Sci-ence Foundation Grant BCS-0748919.
Wewould also like to thank the reviewers for help-ful comments.310ReferencesRajesh Bhatt, Bhuvana Narasimhan, MarthaPalmer, Owen Rambow, Dipti MisraSharma, and Fei Xia.
A multi-representational and multi-layered treebankfor Hindi/Urdu.
In ACL-IJCNLP ?09: Pro-ceedings of the Third Linguistic AnnotationWorkshop.
Association for ComputationalLinguistics, August 2009.Bonnie Jean Dorr.
Machine translation di-vergences: a formal description and pro-posed solution.
Computational Linguistics,20:597?633, December 1994.R Georgi, F Xia, and W D Lewis.
Measur-ing the Divergence of Dependency Struc-tures Cross-Linguistically to Improve Syn-tactic Projection Algorithms.
In Proceedingsof the Sixth International Conference onLanguage Resources and Evaluation (LREC2012), Istanbul, Turkey, May 2012a.Ryan Georgi, Fei Xia, and William D Lewis.Improving Dependency Parsing with Inter-linear Glossed Text and Syntactic Projec-tion.
In Proceedings of the 24th Interna-tional Conference on Computational Lin-guistics (COLING 2012), Mumbai, India,December 2012b.Rebecca Hwa, Philip Resnik, Amy Weinberg,Clara Cabezas, and Okan Kolak.
Bootstrap-ping parsers via syntactic projection acrossparallel texts.
Natural Language Engineer-ing, 1(1):1?15, 2004.William D Lewis and Fei Xia.
DevelopingODIN: A Multilingual Repository of Anno-tated Language Data for Hundreds of theWorld?s Languages.
2010.R.
McDonald, F. Pereira, K. Ribarov, andJ.
Haji?.
Non-projective dependency parsingusing spanning tree algorithms.
Proceedingsof the conference on Human Language Tech-nology and Empirical Methods in NaturalLanguage Processing, pages 523?530, 2005.Chris Quirk, Arul Menezes, and Colin Cherry.Dependency treelet translation: Syntacti-cally informed phrasal SMT.
In Proceed-ings of the 43rd Annual Meeting of the Asso-ciation for Computational Linguistics.
Mi-crosoft Research, 2005.Fei Xia and William D Lewis.
Multilin-gual Structural Projection across Interlin-ear Text.
In Human Language Technologies:The Annual Conference of the North Amer-ican Chapter of the Association for Compu-tational Linguistics (NAACL), 2007.David Yarowsky and Grace Ngai.
Inducingmultilingual POS taggers and NP bracketersvia robust projection across aligned corpora.In Second meeting of the North AmericanAssociation for Computational Linguistics(NAACL), Stroudsburg, PA, 2001.
JohnsHopkins University.311
