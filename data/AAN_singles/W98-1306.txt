Treatment of ~-Moves in Subset ConstructionGertjan van NoordAlfa-informatica & BCNUniversity of Groningen, NetherlandsvannoordOlet, rug.
nlAbstract.
The paper discusses the problem of determinising finite-state automata contain-ing large numbers of e-moves.
Experiments with finite-state approximations of natural lan-guage grammars often give rise to very large automata with a very large number of e-moves.
The paper identifies three subset construction algorithms which treat e-moves.
Anumber of experiments has been performed which indicate that he algorithms diff~ con-siderably in practice.
Furthermore, the experiments suggest that he average number of e-moves per state can be used to predict which algorithm islikely to perform best for a giveninput automatorL1 IntroductionIn experimenting with finite-state approximation techniques for context-free and more pow-erful grammatical formalisms (such as the techniques presented in Pereira nd Wright (1997),Nederhof (1997), Evans (1997)) we have found that the resulting automata often are extremelylarge.
Moreover, the automata contain many e-moves (jumps).
And finally, if such automata aredeterminised then the resulting automata are often smaller.
It turns out that a straightforwardimplementation f the subset construction determinisation algorithm performs badly for suchinputs.As a motivating example, consider the definite-clause grammar that has been developedfor the OVIS2 Spoken Dialogue System.
This grammar is described in detail in van Noord etal.
(1997).
After removing the feature constraints ofthis grammar, and after the removal of thesub-grammar for temporal expressions, this context-free skeleton grammar was input o an im-plementation f the technique described inNederhof (1997).
1 The resulting non-deterministicautomaton (labelled zov/s2 below) contains 89832 states, 80935 e-moves, and 80400 transitions.The determinised automaton contains only 6541 states, and 60781 transitions.
Finally, the mini-mal automaton contains only 78 states and 526 transitions!
Other grammars give rise to similarnumbers.
Thus, the approximation techniques yield particularly 'verbose' automata for rela-tively simple languages.The experiments were performed using the FSA Utilities toolkit (van Noord, 1997).
At thetime, an old version of the toolkit was used, which ran into memory problems for some of theseautomata.
For this reason,, the subset construction algorithm has been re-implemented, payingspecial attention to the treatment of e-moves.
Three variants of the subset construction algo-rithm are identified which differ in the way e-moves are treated:per graph The most obvious and straightforward approach is sequential in the followingsense.
Firstly, an equivalent automaton without e-moves i constructed for the input.
In or-A later implementation by Nederhof (p.c.)
avoids construction f the complete non-determistic automa-ton by determinis'mg and minimising subautomata before they are embedded into larger subautomata.57mmBDder to do this, the transitive closure of the graph consisting of all e-moves i computed.
Sec-ondly, the resulting automato n is then treated by a subset construction algorithm for e-freeautomata.per state For each state which occurs in a subset produced uring subset construction, com-pute the states which are reachable using e-moves.
The results of this computation can bememorised, orcomputed for each state in a preprocessing step.
This is the approach men-tioned briefly in Johson and Wood (1997).
2per subset For each subset Q of states which arises during subset construction, compute Q' DQ which extends Q with all states which are reachable from any member of Q using e-moves.
Such an algorithm is described in Aho, Sethi, and Ullman (1986).
We extend thisalgorithm by memorising the e-closure computation.?
The motivation for this paper is the experience that he first approach turns out to be imprac-tical for automata with very large numbers of e-moves.
An integration of the subset construc-tion algorithm with the computation ofe-reachable states performs much better in practice.
Theper subset alorithm almost always performs better than the per state approach.
However, forautomata with a low number of jumps, the per graph algorithm outperforms the others.In constructing an e-free automaton the number of transitions increases.
Given the fact thatthe input automaton already is extremely arge (compared to the simplicity of the language itdefines), this is an undesirable situation.
An equivalent e-freeautomaton f r the example givenabove results in an automaton with 2353781 transitions.
The implementation fper subset is theonly variant which succeeds in determinising the input automaton ofthis example.In the following section some background information concerning the FSA Utilities tool-box is provided.
Section 3 then presents a short statement ofthe problem (determinise a givenfinite-state automaton), and a subset construction algorithm which solves this problem in theabsence of e-moves.
Section 4 identifies three variants of the subset construction algorithmwhich take e-moves into account.
Finally, section 5discusses some experiments in order to com-pare the three variants both on randomly generated automata and on automata generated byapproximation algorithms.2 FSA Ut i l i t iesThe FSA Utilities tool-box is a collection of tools to manipulate r gular expressions, finite-stateautomata and finite-state ransducers (both string-to-string and string-to-weight transducers).Manipulations include determirtisation (both for finite-state acceptors and finite-state trans-ducers), minimisation, composition, complementation, intersection, Kleene closure, etc.
Var-ious visualisation tools are available to browse finite-state automata.
The tool-box is imple-mented in SICStus Prolog.The motivation for the FSA Utilities tool-box has been the rapidly growing interest for finite-state techniques in computational linguistics.
The FSA Utilities tool-box has been developed toexperiment with these techniques.
The tool-box is available free of charge under Gnu GeneralPublic License.
z The following provides an overview of the functionality of the tool-box.2 According to Derick Wood (p.c.
), this approach as been implemented in several systems, includingHoward Johnson's INR System.3 See http: //www.
let.
rug.
nl /%7Evannoord/Fsa./.
The automata used in the experiments areavailable from the same site.
,58mUmmmmmmnmummmm\[\]mnmnmUmmmm- Construction offinite automata on the basis of regular expressions.
Regular expressiorl op-erators include concatenation, Kleene closure, union and option (the standard regular ex-pression operators).
Furthermore the extended regular expression operators are provided:complement, difference and ".intersection.
Symbols can be intervals of symbols, or the 'Any'-variable which matches any symbol.
Regular expression operators are provided for oper-ations on the underlying automaton, including minimisation and determinisation.
FinaUy,we support user-defined regular expression operators.- We also provide operators for transductions such as composition, cross-product, same-length-cross-product, domain, range, identity and in~cersion.- Determinisation and Minimisation.
Three different minimisation algorithms are sup-ported: Hopcroft's algorithm (Hopcroft, 1971), Hopcroft and Ullmart's algorithm (Hopcroftand Ullman, 1979), and Brzozowski's algorithm (Brzozowski, 1962).- Determinisation a d minimisation of string-to-string and string-to-weight transducers(Mohri, 1996; Mohri, 1997).- Visuuli~tion.
Support includes built-in visualisation (TCl/Tk, TeX+PicTeX, TeX+PsTricks,Postscript) and interfaces tothird party graph visualisation software (Graphviz (dot), VCG,daWmci).- Random generation offinite automata ( n extension of the algorithm in Leslie (1995) to al-low the generation offinite automata containing e-moves).3 Subset Construction3.1 Problem statementLet a finite-state machine M be specified by a tuple (Q, 22, 6, S, F) where Q is a finite set of states,is a finite alphabet, 6 is a function from Q x (27 u {e} ) --* 2 Q.
Furthermore, S c Q is a set ofstart states 4 and F C Q is a set of final states.Let e-move be the relation {(qi, qJ)lqj E $(qi, e)}.
e-reachable is the reflexive and transitiveclosure of e-move.
Let e-CLOSURE: 2 Q --, 2 Q be a function which is defined as:e-CLOSURE(Q') = {qlq' fi Q', (q', q) e e-reachable)For any given finite-state automaton M = (Q, ~, 6, S, F) there is an equivalent deterministicautomaton M' = (2 Q, 27, 6', {Q0}, F').
F' is the set of all states in 2 Q containing a final state ofM, i.e., the set of subsets {Q~ e 2Ctlq E Qi, q E F}.
M' has a single start state Q0 which is theepsilon closure of the start states of M, i.e., Q0 = e-CLOSURE(S).
Finally,?
({q~, q2,..., qd, a) = ~'LOSUREC6(q~, ) U ~(q2, a) U... U ~(q~, a))An algorithm which computes M' for a given M will only need to take into account states in20 which are reachable from the start state Q0.
This is the reason that for many input automatathe algorithm does not need to treat all subsets of states (but note that there are automata forwhich all subsets are relevant, and hence xponential behaviour cannot be avoided in general).Consider the subset construction algorithm in figure 1.
The algorithm maintains a set ofsubsets States.
Each subset can be either marked or unmarked (to indicate whether the sub-set has been treated by the algorithm); the set of unmarked subsets is sometimes referred to4 Note that a set of start states is required, rather than a single start state.
Many operations onautomatacan be defined somewhat more elegantly in this way.
Obviously, for deterministic automata this setshould be a singleton set.59111fund subset_construction ( ( Q, 27, 6, S, F) )index_transitionsO; Trans := 0; F/ns/s := 0; States := O;Start =: epsilon.dosure( S)add(Start)while there is an unmarked subset T E States dom~rk(T)foreach (a, U) ~ insm~ctions(T) doU := epsilon_dosure(U)TransiT, a\] := {U}add(U)odedmtum (States, E, rrans, {Start}, P#~)endproc add (U) Reachable-state-set Maintenancei fU~ Statesthenadd U unmarked to Statesif U N F then F/na/s := F/na/s U U fifiendtunct/mtrucaons (P)return merge(Upe P transfl/ons(p))endInstruction Computationfunct eps//on_dosure(U)return Uendvariant 1: No e-movesFigure 1.
Subset-construction algorithm.as the agenda.
The algorithm takes such an unmarked subset T and computes all transitionsleaving T. This computation is performed by the function instructions and is called instructioncomputation by Johson and Wood (1997).The function index_transitions constructs he function transitions : Q -~ 2~ x 2Q.
This func-tion returns for a given state p the set of pairs (s, T) representing the transitions leaving p. Fur-thermore, the function merge takes such a set of pairs and merges all pairs with the same firstelement (by taking the union of the corresponding second elements).
For example:mee({(a{24})(b{24})(a{34})(b{56})})={(a{23;4})(b{2456)}The procedure add is responsible for "reachable-state-set maintenance', by ensuring thattarget subsets are added to the set of subsets if these subsets were not encountered before.
More-over, if such a new subset contains afinal state, then this subset is added to the set of final states.60i\[\]iIIIIiiiiiiiiIiIIiImII4 Three  Var iants  for  e -MovesThe algorithm presented in the previous ection does not treat e-moves.
In this section threepossible xtensions of the algorithm are identified to treat e-moves.4.1 Per graphThis variant can be seen as a straightforward implementation f the constructive proof that forany given automaton with e-moves there is an equivalent one without e-moves (Hopcroft andUllman, 1979)\[page 26-27\].For a given M = (Q,2~,6,S,F) t l~  variant first computes M' = (Q,2~,6',S',F), whereS' = e-CLOSURE(S), and ~'(q, a) = e-CLOSURE(5(q, a)).
The function e-CLOSURE is com-puted by using a standard transitive closure algorithm for directed graphs: this algorithm isapplied to the directed graph consisting of all e-moves of M. Such an algorithm can be foundin several textbooks (see, for instance, Cormen, Leiserson, and Rivest (1990)).The advantage of this approach is that the subset construction algorithm does not need tobe modified at all.
Moreover, the transitive closure algorithm is fired only once (for the fullgraph), whereas the following two variants call a spedalised transitive closure algorithm pos-sibly many times.4.2 Per subset and per stateThe pet subset and the per state algorithm use a variant of the transitive closure algorithm forgraphs.
Instead of computing the transitive closure of a given graph, this algorithm only com-putes the closure for a given set of states.
Such an algorithm is given in figure2.funct c/osure(T)D=: 0foreach t E T do add t unmarked to D odwhile there is an unmarked state t E D domark(t)foreach qE ~(t, e) doif q ~ D then add q unmarked to D fiododreturn DendFigure 2.
Epsilon-closure AlgorithmIn either of the two integrated approaches, the subset construction algorithm is initialisedwith an agenda containing a single subset which is the e-CLOSDRE of the set of start-states ofthe input; furthermore, the way in which new transitions are computed also takes the effectof ~-moves into account.
Both differences are accounted for by an alternative definition of theepsilon_closure function.61IRThe approach in which the transitive closure is computed for one state at a time is definedby the following definition of the epsilon_closure function.
Note that we make sure that thetransitive closure computation is only performed once for each input state, by memorising theclosure/unctior~-funct epsilon_dosure(U)ret.m U~u me~o( dos~e( {,,} ))endvariant 2: per stateIn the case of the per subset approach the closure algorithm isapplied to each subset.
We alsomemorise the closure function, in order to ensure that the closure computation is performedonly once for each subset.
This can be useful since the same subset can be generated many timesduring subset construction.
The definition simply is:funct epsilon_dosure(U)return memo ( d osure (U ) )endvariant 3: per subsetThe motivation for per state approach may be the insight hat in this case the closure algo-rithm is called at most IQ\] times.
In contrast, in the per subset approach the transitive closurealgorithm ay need to be called 2 IQI times.
On the other hand, in the per state approach someoverhead must be accepted for computing the union of the results for each state.
Moreover, inpractice the number of subsets is often much smaller than 21QI.
In some cases, the number ofreachable subsets i  smaller than the number of states encountered in those subsets.IIIIII5 ExperimentsTwo sets of experiments have been performed.
In the first set of experiments a number of ran-dom automata is generated according to a number of criteria (based on Leslie (1995)).
In thesecond set of experiments, results are provided for a number of (much larger) automata thatsurfaced uring actual development work on finite-state approximation techniques.Random automata.
Firstly, consider a number of experiments for randomly generated automata.Following Leslie (1995), the absolute transition density of an automaton is defined as the numberof transitions divided by the square of the number of states times the number of symbols (i.e.the number of transitions divided by the number of possible transitions).
Deterministic transi-tion density is the number of transitions divided by the number of states times the number ofsymbols (i.e.
the ratio of the number of transitions and the number of possible trans~'ons in adeterministic machine).
Leslie (1995) shows that deterministic transition density is a reliable mea-sure for the difficulty of subset construction.
Exponential blow-up can be expected for inputautomata with deterministic transition density of around 2.
5A number of automata were generated randomly, according to the number of states, sym-bols, and transition density.
The random generator makes ure that all states are reachable fromthe start state.
For the first experiment, a number of automata was randomly generated, consist-ing of 15 symbols, and 15, 20, 25, 100 or 1000 states, using various densities (and no e-moves).5 Leslie uses the terms absolute density and deterministic density.62mmmmmmmmummmnmmmThe results are summarised in figure 3.
Only a single result is given since each of the imple-mentations works equally well in the absence of e-moves.
8A new concept called absolute jump density is introduced to specify the number of c-moves.
Itis defined as the number of e-moves divided by the square of the number of states (i.e., the prob-ability that an e-move exists for a given pair of states).
Furthermore, deterministic jump densityis the number of e-moves divided by the number of states (i.e., the average number of ~-moveswhich leave a given state).
In order to measure the differences between the three implemen-tations, a number of automata has been generated consisting of 15 states and 15 symbols, us-ing various transition densities between 0.01 and 0.3 (for larger densities the automata tend tocollapse to an automaton for 27*).
For each of these transition densities, jump densities werechosen in the range 0.01 to 0.24 (again, for larger values the automaton collapses).
In figure 4the outcomes of this experiment are summarised by listing the average amount of CPU-time re-quired per deterministic jump density (for each of the three algorithms).
Thus, every dot repre-sents the average for determinising a number of different input automata with various absolutetransition densities and the same deterministic jump densi~.
The figures 5, 6 and 7 summarisesimilar experiments using input automata with 20, 25 and 100 states, zThe striking aspect of these xperiments i  that the per graph algorithm is more efficient forlower deterministic jump densities, whereas, if the deterministic jump density gets larger, theper subset alorithm is more efficient.
The turning point is around a deterministic jump den-sity between I and 1.5~ where it seems that for larger automata the turning point occurs at a'lower determinisic jump density.
Interestingly, this generalisation is supported by the experi-ments on automata which were generated by approximation techniques (although the resultsfor randomly generated automata re more consistent than the results for "real' examples).Experiment: Automata generated by approximation algorithms The automata used in the previousexperiments were randomly generated, according to a number of criteria.
However, itmay wellbe that in practice the automata that are to be treated by the algorithm have typical propertieswhich were not reflected in this test data.
For this reason results are presented for a numberof automata that were generated using approximation techniques for context-free grammars(Pereira nd Wright, 1997; Nederhof, 1997; Evans, 1997).
In particular, anumber of automatahas been used generated by Mark-Jan Nederhof using the technique described in Nederhof(1997).
In addition, a small number of automata have been used which were generated usingthe technique of Pereira and Wright (1997) (as implemented by Nederhof).The automata typically contain lots of jumps.
Moreover, the number of states of the resultingautomaton isoften smaller than the number of states in the input automaton, Results are givenin table 1.
One of the most striking examples i  the ygrim automaton consisting of 3382 statesCPU-time was measured on a HP 9000/780 machine running HP-UX 10.20, 240Mb, with SICStus Prolog3 #3.
For comparison with an "industrial strength" implementation, we have applied the determiniserof AT&T's FSM utilities for the same examples.
The results how that for automata with very smalltransition densities FSM is faster (up to 2 Or 3 times as fast), but for automata with larger densities theresults are very similar, in some cases our Prolog implementation is even faster.
Note finally that ourtimings do include IO, but not the start-up of the Prolog engine.We also provide the results for FSM again; we used the pipe fsmrmepsilon I fsmdeterminize?
According to Fernando Pereira (pc) the comparison is less meaningful in this case because the fsm-rmepsilon program treats weighted automata.
This generalisation requires some overhead also in caseno weights are used (for the determiniser this generalisation does not lead to any significant overhead).Pereira mentions furthermore that FSM used to include a determiniser with integrated treatment ofjumps.
Because this version could not (easily) be generalised for weighted automata it was droppedfrom the tool-set.68=O v,ww,wOle+06100000100001000100100.01~m +states \[\]+\ [ \ ]  \ [ \ ]Input automata with 25 states.
.
.
.
.
i .
.
.
.
.
.
.
.
i~em +?\[\]+E I~++o\[\]?
+nl ++.
* i .
.
.
.
.
.
I0.1 1Determirdstic Density| m0B\[\]\[\]\[\].
.
.
.
.
I00, , .
.
.
.
!10le+06=o 1000000 100001000100~ a  o~m +states o0 0 0+Input automata with 100 states.
.
.
.
.
!
.
.
.
.
, .
.
.
.
i??
?,O ~+~rn+o oo#.++.
.
.
.
.
.
!rnOO\[\]10 .
.
.
.
.
.
.
I , * * * , * .1  * * , .
.
.
.
.
\[0.01 0.1 1 10Deterministic DensityFigure 3.
Deterministic transition density versus CPU-time in msec.
The input automata have no E-moves.64!u10000Q Qx + ~0tOO0I000 0.5r~x+oX+0X~+15 statesi i ixx\[ \]I I .
.
.
.pergraph ~per subset +per state \[\]fsm xXX x X X x x13 13 V'l + + ~I+ r:l+ + + +I I I I | I1 1.5 2 2.5 3 3.5 4Deterministic Jump DensityFigure4.
Average amount of CPU-time versus jump density for each of the three algorithms, and FSM.Input automata have 15 states.
Absolute transition densities: 0.01-0.3.u20 states100000 .
.
.
.
.
!
i i !
iQ100001000100~a?i "  iper graph oper ~hbset +per state mfsm ?X XxX x X x0 x x?
0 Q+ + ,,I, + ,,k10 I I I I | I ,I0 0.5 1 1.5 2 2.5 3 3.5 4Deterministic Jump DensityFigureS.
Average mount  of C.PU-time versus jump density for each of the three algorithms, and FSM.Input automata have 20 states.
Absolute transition densities: 0.01-0.3.65BBOJt u100000100001000100\[\]O ?10025 statesi ' i !
!
i i uper graphper Subset +per state ofsm xX\[\] X X0 0?.
,o+ +4-X X x X X X X X X X0 e0 0 0O 0 0 0 0 0 +?
+ ++ + + + ?
+!
!
!
I I I I0.5 1 1.5 2 2.5 3 3.5 4Deterministic Jump DensityFigure 6.
Average amount of CPU-time versus deterministic jump density for each of the three algorithms,and FSM.
Input automata have 25 states.
Absolute transition densities: 0.01-0.3.vu100000100001000100 states' O O ' ' ' I+ o o per  subset  + + B+ o per  state o'> ~" n O f'slTt X?
X +x @ x ox X +x ?
x +R4" + X X Xq' o. ;5 o ~ ~.x ~ 0 x+ + G 0 O+ +@+.4-+100 i , I ~ .
,0 0.5 1 1.5 2 2.5 3Determ/nistic Jump DensityFigure 7.
Average amount of CPU-time versus deterministic jump density for each of the three algorithmsand FSM.
Input automata have 100 states.
Absolute transition densities: 0.001-0.0035.66and 10571 jumps.
For this example, the per graph implementation ran out of memory (after along time), whereas the per subset alorithm produced the determinised automaton relativelyquickly.
The FSM implementation took much longer for this example (whereas for many of theother examples itperforms better than our implementations).
Note that this example has thehighest number of jumps per number of states ratio.input automatonId #states # transitions #jumps!
griml.n 238 43 485g9a 342 58 478g7 362 424 277g15 409 90 627ovis5.n 417 702 130g9 438 313 472gll 822 78 1578g8 956 2415 330g14 1048 403 1404ovis4.n~ 1424 2210 660g13 1441 1006 1404rene2 1800 2597 96ovis9.p 1868 2791 3120ygrim 3382 5422 10571ygrim.pi 48062 63704 122095java19 54369 28333 59394java16 64210 43935 43505zovis3 88156 78895 79437zovis2 89832 80400 80935CPU-ti~e (msec)~'aph subset state FS~2060 100 140 4(260 70 70 3(180 240 200 6(280 130 180 4(290 320 380 19C560 850 640 11C1280 160 160 6(500 500 610 14(1080 1240 730 12Cl2260 222O 2870 1311 I 2400 3780 2550 44~ 440 530 600 20~ 8334O 8O4O0 8704O 5256C2710 70140 78491( \[F - 1438960 - 857585G 130130 55290 64420 847( 67180 24200 31770 637G 968160 768440- 1176650 - 938040Tab le  1.
Results for automata generated by approximation algorithms.
The dashes in the table indicatethat he corresponding al orithm ran out of memory (after a long period of time) for that particular ex-ample.6 ConclusionWe have discussed three variants of the subset-construction algorithm for determinising finiteautomata.
The experiments support he following conclusions:- the per graph variant works best for automata with a limited number of jumps- the per subset variant works best for automata with a large number of jumps- the per state variant almost never outperforms both of the two other variants- typically, if the deterministic jump density of the input is less than 1, then the pergraph vari-ant outperforms the per subset variant.
If this value is larger than 1.5, then per subset outper-forms per graph.- the per subset approach isespecially useful for automata generated by finite-state approxi-mation techniques, because those techniques often yield automata with very large numberof ~-moves.67AcknowledgementsI am grateful to Mark-Jan Nederhof or support, and for providing me with lots of (often dread-ful) automata generated by his finite-state approximation tools.ReferencesAho, Alfred V., Ravi Sethi, and Jeffrey D. Ullman.
1986.
Comp//ers.
Principles, Techniques and Tools.
Addi-son Wesley.Brzozowskl, J.A.
1962.
Canonical regular expressions and minimal state graphs for definite events.
InMathematical theory of Automata.
Polytechnic Press, Polytechnic Institute of Brooklyn, N.Y., pages 529-561.
Volume 12 of MRI Symposia Series.Cormen, Leisersorb and Rivest.
1990.
Introduction to Algorithms.
Cambridge Mass.
: MIT Press.Evans, Edmund Grimley.
1997.
Approximating context-free grammars with a finite-state calculus.
In35th Annual Meeting of the Association for Computational Linguistics and 8th Conference ofthe EuropeanChapter of the Association for Computational Linguistics, pages 452--459, Madrid.Hopcroft, John E. 1971.
An n log n algorithm for minimizing the states in a finite automaton.
InZ.
Kohavi, editor, The Theory of Machines and Computations.
Academic Press, pages 189--196.Hopcroft, John E. and Jeffrey D. Ullman.
1979.
Introduction to Automata Theory, Languages and Computa-t/on.
Addison Wesley.Johson, J. Howard and Derick Wood.
1997.
Instruction computation i subset construction.
In DarrellRaymond, Derick Wood, and Sheng Yu, editors, Automata Implementation.
Springer Verlag, pages 64-71.
Lecture Notes in Computer Science 1260.Leslie, Ted.
1995.
Efficient approaches tosubset construction.
Master's thesis, Computer Science, Uni-versity of Waterloo.Mohri, Mehryar.
1996.
On some applications of finite-state automata theory to natural language process-ing.
Natural Language Engineering, 2:61--80.
Originally appeared in 1994 as Technical Report, institutGaspard Monge, Paris.Mohri, Mehryar.
1997.
Finite-state transducers in language and speech processing.
Computational Lin-gu/stics, 23(2):269--311.Nederhof, M.J. 1997.
Regular approximations of CFLs.
A grammatical view.
In International Workshop onParsing Technologies, Massachusetts Institute of Technology, September.van Noord, Gertjan.
1997.
FSA Utilities: A toolbox to manipulate finite-state automata.
In Darrell Ray-mond, Derick Wood, and Sheng Yu, editors, Automata Implementation.
Springer Verlag.
Lecture Notesin Computer Science 1260.van Noord, Gertjan, Gosse Bouma, Rob Koeling, and Mark-Jan NederhoL 1997.
Robust grammaticalanalysis for spoken dialogue systems.
Article submitted to Journal of Natural Language Engineering.Draft availabel from http: //www.
let.
rug.
nl / ~vannoord/.Pereira, Femando C.N.
and Rebecca N. Wright.
1997.
Finite-state approximation of phrase-structuregrammars.
In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing.
MIT Press,Cambridge, pages 149-173.68
