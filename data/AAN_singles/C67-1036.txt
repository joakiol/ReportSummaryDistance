Research  Group forQuant i ta t ive  L ingu is t i c  sFackS tockho lm 40SWEDENKVAL  PM 339June 191 1967The Ent ropy  of Recurs ive  Markov  ProcessesByBENNY BRODDAThe work  repor ted  in th is  paper  has been sponsored  by Humanis t i skafo rskn ingsr~det ,  Tekn iska  fo rskn ingsr~det  and  R iksbankens  Jub i leums-fond, S tockho lm,  Sweden.
'.\THE~ENTROPY OF  RECURSIVE  MARKOV PROCESSESByBENNY BRODDAKVAL ,  Fack ,  S tockho lm 40, SwedenSummaryThe a im of th is  communicat ion  is  to obta in  an exp l i c i t  fo rmula  fo r  ca lcu la t -ing the ent ropy  of a source  wh ich  behaves  in accordance  wi th  the ru les  of anarb i t ra ry  Phrase  S t ruc ture  Grammar ,  in wh ich  re la t ive  probab i l i t i es  a rea t tached  to the ru les  in the grammar .
With th is  a im in mind  we in t roduce  ana l te~rnat ive de f in i t ion  of the concept  of a PSG as a se t  of  se l f -embedded ( re -Curs ive)  F in i te  S ta te  Grammars ;  when the probab i l i t i es  a re  taken  into accountin such  a grammar  we ca l l  i t  a Recurs ive  Markov  Process .1.
In the f i r s t  sec t ion  we g ive  a more  deta i led  de f in i t ion  of  what  k ind  of Mar -kov  P rocesses  we are  go ing to genera l i ze  la ter  on (in sec .
3), and we a l soout l ine  the concept  of ent ropy  in an ord inary  Markov  source .
More  deta i l s  "ofin fo rmat ion  may be foupd~ e .g .
,  in Kh inch ins  "Mathemat ica l  Foundat ions  ofIn fo rmat ion  Theory" ,  N .Y .
~ 1957~ or  " In fo rmat ion  Theory"  by  R.  Ash ,  N. Y. ,1965.A Markov  Grammar  is  de f ined  as a Markov  Source  w i th  the fo l low ing  proper -t ie  s :Assume that  there  a re  n+ 1 s ta tes ,  say  S O , S1, .
.
.
,  Sn, in the source .
S O isde f ined  as  the in i t ia l  s ta te  and S is  de f ined  as  the f ina l  s ta te  and the o therns ta tes  a re  ca l led  in termed ia te  s ta tes .
We sha l l ,  of course ,  a l so  have  a t rans i -t ion mat r ix ,  M = (Pi j) ,  conta in ing  the, t rans i t ion  probab i l i t i es  of  the source .a) A t rans i t ion  f rom s ta te  S i to s ta te  S k is  a lways  accompan ied  by a produc-t ion  of a (non-zero)  le t te r  a ik  f rom a g iven  f in i te  a lphabet .
T rans i t ion  tod i f fe rent  s ta tes  f rom one g iven  s ta te  a lway  s p roduce  d i f fe rent  le t te rs .b) F rom the" in i t ia l  s ta te ,  S0~ d i rec t  or  ind i rec t  t rans i t ions  shou ld  be poss ib leto any o ther  s ta te  in the source .
F rom no s ta te  is  a t rans i t ion  to S O a l lowed.c) F rom any s ta te ,  d i rec t  or  ind i rec t  t rans i t ions  to the f ina l  s ta te  S shou ldnbe poss ib le .
F rom S n no t rans i t ion  is  a l lowed to any o ther  s ta te  (S n is  an"absorb ing  s ta te" ) .The work  repor ted  in th is  paper  has been  sponsored  by Humanis t i ska  fo rsk -n ingsr~det ,  Tekn iska  fo rskn ingsr~det  and R iksbankens  Jub i leumsfond ,  S tock -ho lm,  Sweder i .A (grammat ica l )  sente 'nce  shou ld  now be de f ined  as the ( le f t - to - r ight )  conca-tenat ion  of the le t te rs  p roduced  by the source ,  when pass ing  f rom the in i t ia ls ta te  to the f ina l  s ta te .The length  of a sentence  is  de f ined  as the number  of  le t te rs  in the sentence .To s imp l i fy  mat ters  w i thout  d ropp ing  much of genera l i ty  we a l so  requ i re  thatd) The greates t  common d iv i sor  fo r  a l l  the poss ib le  lengths  of sentences  is  = l( i .
e .
,  the source  becomes  an aper iod ic  source ,  i f  i t  is  shor t -c i rcu i ted  byident i fy ing  the f ina l  and in i t ia l  s ta tes ) .
~-With the proper t ies  a - d above ,  the source  obta ined  by  ident i fy ing  the f ina land in i t ia l  s ta tes  is  an indecomposab le ,  e rgod ic  Markov  process  (cf.
Fe l le r ,"P robab i l i ty  Theory  and Its App l i ca t ions" ,  ch.
15, N. Y. s 1950).In the t rans i t ion  matr ix  M fo r  a Markov  grammar  of our  type  a l l  e lementsin the f i r s t  co lumn are  zero ,  and in the las t  row a l l  e lements  a re  zero  ex -cept  the las t  one wh ich  is  = 1.
For  a g iven  Markov  grammar  we de f ine  theuncer ta in ty  or  ent ropy ,  Hi ,  fo r  each  s ta te  S i, i = 0, 1 .
.
.
.
, n, as :nHi=~l  Pij l ?g  P i j ;  i=  1, Z .
.
.
.
.
n.j=OWe a lso  de f ine  the ent ropy ,  H or  H(M),  fo r  the grammar  asn= 1(1).
= x.H.1 1i= 0where  x = (x0, x z, .
.
.
,  Xn_l)  is  de f ined  as the s ta t ionary  d i s t r ibut ion -~ thesource  obta ined  when S O and S n a re  ident i f ied ;  thus  x is  de f ined  as the  (un ique)so lu t ion  to the set  of  s imu l taneous  equat ions(z)xM 1 = xx0 + X l + ' ' "  + Xn-1 = 1where  M 1 is  fo rmed by  sh i f t ing  the las t  and f i r s t  co lumns  and then  omi t t ingthe las t  row and co lumn.
The mean sentence  length .
~, of  the set  of g rammat -i ca l  sentences  can now be eas i ly  ca lcu la ted  as(3) = 1/x 0(cf.
Feller, op.
tit.)2.
Embedded GrammarsWe now assume that  we have two Markov  grammars ,  M and M1, w i th  s ta tesS O , S 1 .
.
.
.
, S n,  and  T o , T I, .
.
.
,  T m,  respect ive ly ,  where  S O ands  n, T Oand T m are  the cor respond ing  in i t ia l  and  f ina l  s ta tes .
Now cons ider  twos ta tes  S i and S k in the grammar  M; assume that  the cor respond ing  t rans i t ionprobab i l i ty  is = Pik" We now t rans form the grammar ,  M1, into a new one ,M\ ] ,  by  embedd ing  the grammar  M 2 in  M 1 between the s ta tes  S i and Sk, anoperat ion  which  is per fo rmed by ident i fy ing  the s ta tes  T O and T wi th  the ms ta tes  S i and S k respect ive ly .
Or ,  to be more  prec ise ,  assume that  in thegrammar  M 1 the t rans i t ions  to the s ta tes  Tj ,  j~ l ,  has  the probab i l i t i es  q0j"Then,  in  the grammar  M ' ,  t rans i t ions  to a s ta te  T. f rom the s ta te  S. w i l l3 1take p lace  wi th  the probab i l i ty  =.Pikq0 j .
A re turn  to the s ta te  S k in  the "main"grammar  f rom an in termed ia te  s ta te  Tj in  M 1 takes  p lace  wi th  the probab i l i tyqjm"With the cond i t ions  above  fu l f i l l ed ,  we propose  that  the ent ropy  for  the.
com-posed  grammar  be ca lcu la ted  accord ing  to the fo rmula :(4) H(M' )  = H(M)  + x ip ik  " ~I  " H(M| )1 + x iP ik  (~1 - 1)where  H(M) is  the ent ropy  of the grammar  M when there  is an ord inary  con-nect ion  (with probab i l i ty  Pik) between the s ta tes  S i and Sk, and  where  x. is1the inherent  p robab i l i ty  of be ing  in the state  S. under  the same cond i t ions .1~1 is the mean sentence  length  of the sentences  produced by the grammarM 1 a lone .
(It is  qu i te  natura l  that  th is  number  appears  as a we ight  in thefo rmula ,  s ince  if one is p roduc ing  a sentence  accord ing  to the grammar  Mand ar r ives  at the s tate  S i and f rom there  "d ives"  into the grammar  M1,then ~1 is the expected  wa i t ing  t ime for  emerg ing  aga in  in the main  grammarM. )
The fac tor  x iP ik  may be in terpreted  as the combined  probab i l i ty  of evera r r iv ing  at.S i and  there  choos ing  the path  over  to M 1 (you may,  of course ,choose qui te  another  path  f rom Si).The proo f  of fo rmula  (4) is  very ' s t ra ight fo rward ,  once  the premises  accord -ing to the above have  been g iven,  and  we omi t  i t  here ,  as it does not  g ivemuch ext ra  ins ight  to the theory .
THe fo rmula  may be extended to the casewhen there  are :more  than  one sub-grammar  embedded in the grammar  M ' ,by add ing s imi la r  te rms as the one standing,  to the r ight  in the numeratorand  the denominator .
The impor tant  th ing here  is that  the fac tors  of the typex .p .~ depend on ly  on the probab i l i ty  mat r ix  for  the grammar  M and are  de-  1 1 pendent  of the sub-grammars  invo lved .3.
Recur  s ive  or  Se l f -embedded Sources  ~-.
....It  is  now qui te  natura l  to a l low a grammar  to have  i t se l f  as a sub-grammaror  to a l low a grammar  M 1" to conta in  a grammar  M~.
wh ich ,  in  i ts  tu rn ,  con-ta ins  M 1, and so on.
The grammars  thus  obta ined  cannot ,  howeverB be re -wr i t ten  as an ord inary  Markov  grammar .
The re la t ion  between an ord inaryMarkov  grammar  and a recurs ive  one i s~exact ly  s imi la r  to the re la t ion  be-tween F in i te  s ta te  Languages  and Phrase  S t ructure  Languages .To be more  precise, assume that we have a set of Markov  grammars  M~M l .
.
.
.
.
M~ where MI 0 is called the main  grammar  and in the sense thatthe process always starts at the initial state in M ~ and ceases when itreaches the final state in M 0.
Each  of the grammars  may contain any numberof the others (and itself) as sub-grammars .
The only restriction is that f romany state in any one of the grammars  there should exist a path which ends upat  the f ina l  s ta te  of M O.RemarkIf we in terpret  a source  of our  k ind  as a Phrase  S t ructure  Language,  the re -wr i t ing  ru les  a re  a l l  of the fo l low ing  k ind :(5) S i -* Aik + Sk o.r_r S n -, #;where the S' s are all non-terminal symbols.
(They stand for the names  ofthe states in the sources - M~,  l~i I .
.
.
.
.
M~and where  S O is assumed to bethe initial symbol  /the Chomskyan S/ and S n is the terminating state whichproduces the sentence delimiter #.
The symbols Aik ar e either terminal sym-bols / l e t te rs  f rom a f in i te  a lphabet /  o r  non- termina l  symbo ls  equa l  to thename of the in i t ia l  s ta te  in  one of the grammars  M~, Ni~ .
.
.
.
.
M~ /one  may4a lso  say  that  A ikgrammar/.
): i:s tands  as  an abbrev ia t ion  fo r  an arb i t ra ry  sentence  of  thatWe assoc ia te  each  grammar  M!
w i th  the grammar  M. ,  j = 0, 12 .
.
.
.
, N, by3 3jus t  cons ider ing  i t  as  a non- recurs ive  one,  thaf  i s ,  we cons ider  a l l  the sym-bo ls  A ik  as  te rmina l  symbo ls  (even  i f  they  are : 'not ) .
The grammars  thus  ob-ta ined  are  ord inar i l y  Markov  grammars  accord ing  to our  de f in i t ion ,  and  theent rop ies  Hj = H(Mj)  a re  eas i ly  computed  accord ing  to fo rmula  (1), as  a rethe s ta t ionary  d i s t r ibut ions  / fo rmula  (2 ) / .
The fo l lwo ing  theorem shows howthe ent rop ies  H!
fo r  the  fu l l y  recurs ive  grammars  M!
a re  connected  w i th  theJ 3numbers  H. .JTheoremThe  ent ropy  H!
fo r  a set  of recurs ive  Markov  grammar  Mj ,  j = 0, 1,Jcan  be ca lcu la ted  accord ing  to the fo rmula.
.
.
,  N,(6)k kj=0,  1 .
.
.
.
,N .Here  the  fac tors  Yjk a re  dependent  on ly  of the  probab i l i ty  matr ix  of the?
g rammar  and  the numbers  ~k def ined  as  the mean sentence  length  of  thesentences  of the  grammar  M~,  k = 0, 1, .
.
.
.
N, and  computab le  accord -ing to lemma be low.H~ is  the ent ropy  fo r  the grammar .The theorem above  i s  a d i rec t  app l i ca t ion  fo r  the grammar  of fo rmula  (4),sec .
2.The coef f i c ients  Yjk in fo rmula  (6) can ,  more  prec ise ly ,  be ca lcu la ted  asa sum of te rms of the type  x iP im wi th  the ind ices  (i ,  m) a re  where  the  gram-!"
x i and are  the components  the  s ta -  mar  M~ appears  in the grammar  M3~ P imt ionary  d i s t r ibut ion  and  probab i l i ty  matr ix  fo r  the grammar  M.o, JAssume now that  we have  a Markov  grammar  of our  type ,  but  fo r  wh icheach  t rans i t ion  w i l l  take  a cer ta in  amount  of t ime.
A very  natura l  quest ioni s  then:  "What  i s  the expected  t ime to produce  a sentence  in that  language ?
"The answer  is  in the fo l low ing  lemma.LemmaLet  M be a_MMarkov grammar  w i th  s ta tes  S i ,  i=  O,S a re  the in i t ia l  and  f ina l  s ta tes  respect ive ly ,n1 .
.
.
.
, n, where  S O andAssume that  each  t rans i t ion  S i -.
S k w i l l  take  Ylk t ime un i ts .Denote the expected t ime for arrival at S given that the grammar  is in statenS i by ti, i = 0, I, ...~ n~ (thus t o is the expected t ime for producing asen-tence).
The  t imes t I will then fulfill the following set of simultaneously linearequations :(7) t i  = ~ P ik  ( t ik  + tk)kFormula  (7) i s  i t se l f  a p roo f  of the lemrna .Wi th  more  conven ient  notat ions  we can  wr i te  (7) as(E - P)  t = Ptwhere  E is  the un i t  mat r ix ,  P is  the probab i l i ty  matr ix  (w i th  P = 0) andnnPt is  the vector  w i th  componentsPi (t) =~ P im t im'  i = 0, 1 .
.
.
.
, n.mThe app l i ca t ion  of  ~he lemma for  comput ing  the numbers  ~k in fo rmula  (6) i snow the fo l low ing .The transition t imes of the lemma are, of course, the expected t ime (or"lengths" as we have called it earlier) for passing via a sub-grammar  of thegrammar  under consideration.
Thus the number  tik i-~\]itself the unknown en-title s ~k"6For  each  of  the sub-grammars  M~, j : 0, I ,  .
.
.
,  N, we geta  set  of l inearJequat ions  of type  (7) for  determin ing  the vectors  t of 1emma.
The f i r s t  com-ponent  of th i s  vector ,  i .e .
j  the number  t O , i s  then  equa l  to the expectedlength ,  ~, of the sentences  of that  g~ammar .
(Unfor tunate ly ,  we have  tocompute  ext ra  the expected  t ime fo r  go ing  f rom any  s ta te  of the  sub-gram-mars  to the  cor respond ing  f ina l  s ta te .
)The to ta l  number  of unknowns  invo lved  when comput ing  the ent ropy  of  ourg rammar  (i .
e .
, the ent ropy  H~) i s  equa l  to(the to ta l  number  of s ta tes  in a l l  our  sub-grammars)  p lus(the number  of sub-grammars) .Th is  i s  a l so  the number  of equat io r~,_ for  we haven + 1 e~uat ions  f rom formula(6) and then  (n + 1) se ts  of equat ions  of  the type  (7).
We asser t  that  a l l  theses imul taneous  equat ions  a~e so lvab le ,  i f  the grammar  fu l f i l l s  the cond i t ionswe ear l ie r  s ta ted  fo r  the grammar ,  i .e .
,  that  f rom 'each  s ta te  in any  sub-g rammar  ex is ts  a t  leas t  one path  to the f ina l  s ta te  of  that  g rammar .
