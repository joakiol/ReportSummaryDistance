An Empirical Study on the Generationof Anaphora in ChineseChing-Long Yeh*Tatung Institute of TechnologyChr is  Mel l i sh  tUniversity of EdinburghThe goal of this work is to study how to generate various kinds of anaphora in Chinese, includingzero, pronominal, and nominal anaphora, from the syntactic and semantic representation ofmultisentential text.
In this research we confi'ne ourselves to descriptive texts.
We examine theoccurrence of anaphora in human-generated xt and those generated by a hypothetical computerequipped with anaphor generation rules, assuming that the computer can generate the sametexts as the human except hat anaphora re generated by the rules.
A sequence of rules usingindependently motivated linguistic onstraints i developed until the results obtained are closeto those in the real texts.
The best rule obtained for the choice of anaphor type makes use ofthe following conditions: locality between anaphor and antecedent, syntactic onstraints on zeroanaphora, discourse segment structures, alience of objects and animacy of objects.
We furtherestablish arule for choosing descriptions ira nominal anaphor is decided on.
We have implementedthe above rules in a Chinese natural language generation system that is able to generate descriptivetexts.
We sent some generated texts to a number of native speakers of Chinese and comparedhuman-created results and computer-generated xt to investigate the quality of the generatedanaphora.
The results of the comparison show that the rules are fairly effective in dealing withthe generation of anaphora in Chinese.1.
IntroductionThe field of natural anguage generation has made a great deal of progress in the gen-eration of multisentential text in recent years (McKeown 1985; Maybury 1990; Dale1992; Hovy 1993).
Most of the well-known systems first select and organize the mes-sage contents to be generated and then map the organized results into a sequenceof surface sentences.
When mapping into the surface form, the selection of appropri-ate forms for anaphora is very important o make the generated text a cohesive unit(McDonald 1980; Dale 1992).
In this paper, our goal is the computer generation ofanaphora in Chinese.In Chinese, anaphora can be classified as zero, pronominal, and nominal forms,as exemplified in (1) by ~,  ta i 'he' and nage ren i 'that person', respectively (Chen1987).
1Zero anaphora re generally noun phrases that are understood from the contextand do not need to be specified.
In contrast, in this paper, we use the term nonzero?
Department of Computer Science and Engineering, 40 Chungshan North Road, Section 3, Taipei, 104,Taiwan.
Email: chingyeh@cse.ttit.edu.twf Department of Artificial Intelligence, 80 South Bridge, Edinburgh EH1 1HN, Scotland.
Email:c.mellish@ed.ac.uk1 We use a ?~a b to denote a zero anaphor, where the subscript a is the index of the zero anaphor itself andthe superscript b is the index of the referent.
A single ~ without any script represents an intrasententialzero anaphor.
Also note that a superscript attached to an NP is used to represent the index of thereferent.C) 1997 Association for Computational LinguisticsComputational Linguistics Volume 23, Number 1anaphora to denote those that are specified in discourse, namely, pronominal andnominal anaphora.
(1) a. Zhangsan i jinghuang de wang wai pao,Zhangsan frightened NOM towards outside run'Zhangsan was frightened and ran outside.'b.
~ zhuangdao yige renJ,(he) bump-to a person'(He) bumped into a person.'c.
ta i kanqing lena ren J de zhangxiang,he see-clear ASPECT that person GEN appearance'He saw clearly that person's appearance.'d.
oi 2 renchu na renJ shi shui.
(he) recognize that person is who'(He) recognized who that person is.
'This research starts with establishing possible rules for the generation of anaphorain Chinese.
Previous work suggests obtaining these rules from consulting the results oflinguistic study, including general principles, such as the Gricean maxims (Grice 1975)used in (Dale and Haddock 1991; Reiter and Dale 1992; Dale 1992) and focus theory,as used in (Dale 1992).
A shortcoming of previous work is that it is unclear to whatextent he resulting rules are effective in dealing with the generation of anaphora.
Inan attempt to overcome this, we adopt an empirical approach to obtaining rules basedon observations of real texts.The basic methodology used is to start with a set of human-generated Chinesetexts and the simplest possible anaphor generation rule (a rule that only considersthe locality of anaphora).
We then progressively add extra tests to the rule, based onindependently motivated but simple linguistic principles.
At each stage, we conductexperiments that compare the anaphora occurring in the human-generated text withthose in the texts that would be generated by a computer taking the same syntacticand semantic ontent as the human texts and generating Chinese anaphora ccordingto the rule being tested (this has to be simulated by hand).
This process continuesuntil a rule with promising performance on the data is obtained.
The objective is thusto answer the question of how complex a rule must be to account for the complexityof anaphor generation exhibited by the test data.This paper presents one sequence of rules developed using the above methodologyand evaluates the effectiveness of the new linguistic principles taken into account ateach point.
At present, we have chosen only one intuitively plausible way to generateincreasingly complex rules, with refinements introduced as they occurred to us (thoughnot motivated by the data).
Clearly the work could and should be extended to considerall possible combinations of the principles in all possible orders.Except where noted below, the preselected Chinese data serves as an independenttest of the effectiveness of the different rules, which are based on principles that havebeen independently suggested in the literature.
However, the fact that the chosen datadetermine the termination condition for the development means that the rules could beoverfitting the chosen data.
Therefore a selection of the rules have been implementedin a Chinese natural anguage generation system and their results are further evaluatedby means of an experiment using native speakers.This paper concentrates on the use of zero, pronominal, and nominal anaphorain Chinese generated text.
We are not concerned with lexical anaphora (Tutin andKittredge 1992) where the anaphor and its antecedent share meaning components,170Yeh and Mellish An Empirical Study on Anaphoraimmedia~/ ~ngZ NZZ=490P=I 16N=703locality?i m m ~Z--~74 Z= 16P=I03 P=I3N=329 N=374Z NZMatched Overgenerated Undergenerated Total861 (66%) 432 (33%) 16 (1%) 1,309Figure 1Decision tree, classification tree, and result for Rule 1.while the anaphor belongs to an open lexical class.
For example, flower can be used asa lexical anaphor for rose (Tutin and Kittredge 1992).In Sections 2 to 3.3, we establish the rules for the generation of anaphora in Chi-nese.
We consider the case of zero anaphora (Section 2) first, followed by nonzeroanaphora (Section 3), which divides into pronouns (Section 3.1) and nominal anaphora(Sections 3.2 and 3.3).
Next, in Section 4, we describe the implementation f the gen-eration rules in our Chinese generation system and show the result of evaluating theanaphora in the text generated by systems employing different rules.
Finally, Section 5presents the conclusions.2.
Zero AnaphoraInitially we consider simply the decision of whether a generated anaphor should be azero pronoun (Z) or some nonzero phrase (NZ).2.1 Rule 1- LocalityAlthough there are no clear rules delineated in previous linguistic work, we, neverthe-less, can summarize a very simple rule, Rule 1 as shown below and in an associateddecision tree in Figure 1, for the generation of zero anaphora.Rule 1If an entity, e, in the current clause was referred to in the immediately preceding clause,then a zero anaphor is used for e; otherwise, a nonzero anaphor is used.This is clearly a very simple rule, but it is interesting to see how well it performs.We now describe an experiment comparing the anaphora generated by a hypotheticalcomputer employing this rule and those occurring in real text to see how well it works.The same basic format is used for subsequent experiments on more refined rules.In this paper, the selected texts are restricted to the exposition type, which explainan idea or discuss a problem.
Three sets of articles consisting of scientific questionsand answers written by multiple authors, and an introduction to Chinese grammar,are selected as the test data (more details can be found in Yeh \[1995\]).
In this data,there are 490 zero pronouns, 116 pronouns, and 703 nominal anaphora, making a total171Computational Linguistics Volume 23, Number 1of 1,309 anaphora.
The experiment is executed in three steps:.2..Zero and nonzero anaphora within the selected texts are identified.
2Each anaphor is given values according to the conditions in the currentrule.
For example, for Rule 1, an anaphor is determined tobe immediateif its antecedent occurs in the immediately preceding clause; otherwise itis long-distance.
We can then classify the anaphora corresponding to thedecision tree of the rule, as in Figure 1.
In the figure, Z and NZ denotezero and nonzero anaphora, respectively.
Later we will use P and N todistinguish between pronouns and nominal anaphora.
3We assume that a hypothetical computer employing the current rule cangenerate the same text as the test data except for the anaphora, whichare determined by the rule to be tested.
We simulate this computer byhand and note down the difference between the anaphora generated bythe computer and those in the test data.In step 3, we categorize the differences between the results as: matched, over-generated and under-generated types.
If a reference created by the simulated com-puter is the same as the one in the real text, then it belongs to the matched type.If a zero anaphor is created by the hypothetical computer, while the correspondingposition in the real text is a nonzero anaphor, then it belongs to the overgeneratedtype.
Conversely, if a zero anaphor is found in some position in the real text, whilea nonzero anaphor is created by the computer, then it belongs to the undergeneratedtype.From the classification tree, the number of the matched type is the total numberof zero and nonzero anaphora ssociated with zero and nonzero leaf nodes in theclassification tree.
The over- and under-generated types are counted as the numbersof nonzero and zero anaphora ssociated with zero and nonzero leaf nodes in thetree.
The result of using Rule 1 on the test data is shown in Figure 1.
In the table,the matched rate of the test data is 66%, which obviously shows an unpromisingperformance of the computer employing Rule 1.
Apparently, what we need to do isto find more constraints o enhance Rule 1.
As shown in the classification trees of thetest data, the numbers of nonzeros are far greater than their counterparts, zeros, inthe long-distance cases of anaphora.
Thus, in the following, we will not make anyrefinement to the long-distance cases because little progress would be obtained.2.2 Rule 2: Adding Syntactic ConstraintsLi and Thompson (1979, 1981) formulated a negative rule stating that zero anaphoraare not allowed in certain syntactic positions regardless of discourse factors: the NPright after a coverb, and the pivotal NP in a serial verb construction.
Therefore, weenhanced Rule 1 by adding the above syntactic onstraints on zero anaphora, whichbecomes Rule 2, as shown in Figure 2.2 This is not necessarily a trivial task, as of course there is no physical evidence for zero anaphora intext.
Indeed, there is some question as to whether the notion of zero pronoun is the best way ofaccounting for the syntactic facts about languages uch as Chinese.
Since we are looking at things froma generation perspective, we have considered a zero pronoun to occur when an important semanticelement is not overtly specified in the text.
In practice, this criterion probably produces imilar resultsto approaches considering verb subcategorization (Walker, Iida, and Cote 1994).3 Note that we only deal with third person pronouns in Chinese; thus, in the table, and the following,pronominal anaphora, or pronouns, refer to third person cases.
In this paper, we treat the first andsecond person pronouns as nominal anaphora.172Yeh and Mellish An Empirical Study on AnaphoraZ=490P=116N=703locality?i~ .
.
.~~ "~"~g 16P=I03 P=I3lo/cal~ty?
N=329 N=374immedia~/ X~ng violatingconstr~aints?Syntactic NZviolatin svnt..~tic NZ ~ constraints.
~ Z-474y P=37 P=66N=154 N--175NZ Z NZ ZMatched Overgenerated Undergenerated Total1,052 (80%) 241 (18%) 16 (1%) 1,309Figure 2Decision tree, classification tree, and result for Rule 2.Rule 2If an entity, e, in the current clause was referred to in the immediately preceding clauseand does not violate any syntactic onstraint on zero anaphora, then a zero anaphoris used for e; otherwise, a nonzero anaphor is used.We then established for each anaphor in the test data whether a zero anaphorin this position would violate these syntactic onstraints or not and obtained a newclassification tree, as shown in Figure 2.
The matched rate of Rule 2 is 80%, as shown inthe same figure.
Though Rule 2 improves its predecessor's performance, the result stilldiscourages us from using it for the generation of zero anaphora in Chinese.
As shownin Li and Thompson (1979) and Frosz and Sidner (1986), the structure of discourse is asignificant factor affecting the use of anaphoric forms.
Thus, we employed the notionof discourse structure as the basis for enhancing the rule.2.3 Rule 3: Adding Discourse StructureGrosz and Sidner (1986) suggest hat three structures can be identified within a dis-course: linguistic structure, intentional structure, and attentional state.
The first struc-ture is the sequence of utterances that comprise the discourse.
Underlying this is theintentional structure, which shows the relationship between the respective purposes ofdiscourse segments.
An important idea in the theory is the effect of the linguistic ex-pressions in utterances constituting the discourse and the discourse segment structureon each other.
On the one hand, linguistic expressions can be used to convey informa-tion about the discourse segment structure.
On the other hand, the discourse segmentstructure constrains the interpretation of linguistic expressions.
What concerns us hereis the interrelationship between the forms of referring expressions and the discoursesegment structures.Li and Thompson (1979) propose the idea that the use of nonzero anaphora hasto do with the segment boundaries in a discourse.
A zero anaphor used to refer tosome entity in the previous clause might be expected to indicate the continuationof a discourse segment, while a nonzero anaphor occurring in the same situation173Computational Linguistics Volume 23, Number 1Z=490P=116N=703locality?i rnm~Z=474 Z=l 6P=I03 P=I3N=329 N=374'--a'"- ?
violating syntactic NZ |~ ~ty constraints?immedia /  ~ngZ = ( )  Z=474violatin~ svnt~tic NZ P=66 cons'tramts.
P=37es~ XN~ N=154 N=175 at segment Y NZ beginning?at segment ~NZ beg/inning?
Z=7yy  X~ P=41N=126NZ Z NZZ=467P=25N=49ZMatched Overgenerated Undergenerated Total1,212 (93%) 74 (6%) 23 (2%) 1,309Figure 3Decision tree, classification tree, and result for Rule 3.signals a boundary of a discourse segment.
From the generator's perspective, whenthe decision about the anaphoric form for a phrase referring to some entity in theprevious utterance is to be made, the factor of discourse segment boundaries must betaken into consideration.
Therefore, based on this idea, we improve the previous rulesfor generation of zero anaphora, to make Rule 3, as shown in Figure 3.Rule 3If an entity, e, in the current clause was referred to in the immediately precedingclause, does not violate any syntactic onstraint on zero anaphora, and is not at thebeginning of a discourse segment, then a zero anaphor is used for e; otherwise, anonzero anaphor is used.To determine the applicability of the new constraint to each anaphor, we had toaccess the discourse segment structures of the test data.
Therefore, we annotated theboundaries between discourse segments in the test data and the hierarchical discoursestructures, by hand, according to perceived iscourse segment intentions.
Since ourannotations were based on intuition, we tested them by comparing them with thoseof other native speakers of Chinese to see whether our intuitions about the discoursestructures of the test data were reliable for the purpose of the experiments.
In the test,four native speakers of Chinese were asked to annotate discourse segment boundariesfor five articles elected from the test data.
Each speaker was given a short descriptionin Chinese (see the Appendix) about he idea of discourse structure and the task to bedone, namely, annotate the discourse segment boundaries according to the intentionsof the discourse segments.
The speakers reached a good level of agreement amongthemselves (obtaining a value of 0.76 for the kappa statistic \[Siegel and Castellan 1988\])174Yeh and Mellish An Empirical Study on Anaphoraand adding our own annotations to the pool resulted in a similar level of agreement(kappa = 0.764).
On average, 89% of our annotation markers match those of the speak-ers.
From the above comparison, we judged that the annotations we made were highlyreliable for the purpose of the experiment.
The result also shows that the sententialmarks in the test data closely correlate to the boundaries between discourse segments.In Chinese written text, a sentential mark, ".
", is normally inserted at the end of a "sen-tence," which is a meaning-complete unit in a discourse; on the other hand, commasare inserted between clauses within a "sentence" as separators (Liu 1984).
4A Chinesediscourse, say a paragraph of written text, therefore consists of a sequence of "sen-tences" and the corresponding intentions altogether form the intention of the discourse.The classification trees and results of the experiment are shown in Figure 3.
Bytaking into account the effect of discourse segment structure, we obtained 93% matchesin the test data.
The result shows that Rule 3 is helpful for the decision as to whetherto use a zero anaphor.2.4 Rule 4: Adding Topic ContinuityAlthough the zero anaphora generated using Rule 3 look considerably similar to thosein the test data, there are, nevertheless, still a number of overgenerations for the testdata.
Tai (1978), Li and Thompson (1979), and Chen (1984, 1986), have noticed thatzero anaphora frequently occur in topic chains where a referent is referred to in thefirst clause, and then several more clauses follow talking about the same referent (thetopic), but with it omitted; (lb) in Section 1 is an example.
Here, we use the featureof topic-prominence in Chinese (Li and Thompson 1981) to further efine the previousrule.In Chinese, the topic of a sentence is what the sentence is about and alwayscomes first in the sentence; the rest of the sentence is comment upon the topic (Liand Thompson 1981).
The topic is always either definite (refers to something that thereader already knows about), or generic (refers to a class of entities).
The subject of asentence, on the other hand, is the NP that has a "doing" or "being" relationship withthe verb in the sentence.
By distinguishing between topics and subjects in sentences, wehave the following types of sentences: entences with both subject and topic, sentencesin which the subject and topic are identical, sentences with no subjects, and sentenceswith no topic (Li and Thompson 1981).
A sentence without a topic is used to introducea new entity into the discourse.
In the remaining types of sentences, the topic can befound at the beginning of the sentence.The basic idea here is to investigate he positions of the antecedent and the anaphorin their respective clauses.
Then we observe the occurrence of both the antecedentand anaphor in the topic position to see the effect of topic on zero anaphora.
In thefollowing, we divided the position of anaphora in their respective utterances into topicand nontopic ases.For each anaphor, its antecedent's position is classified as either topic or directobject.
Thus we have the types of antecedent-anaphor pai s shown in Figure 4.
Sincein the new rule the condition of topic continuity in clause will be considered to refinethe zero leaf node in the decision tree of Rule 3, we focus on investigating the cor-responding anaphora in the classification trees.
The numbers of the various types of4 The sentential mark also has two auxiliaries, question and exclamation marks, which are used toexpress "sentences" with certain tones.175Computational Linguistics Volume 23, Number 1Types of antecedent-anaphor pairPosition of antecedent Position of anaphorType A: topic topicType B: object-1 topicType C: topic nontopicType D: object-1 nontopicType E: others topicType F: others nontopicOccurrence of antecedent-anaphor pairsAnaphor A B C D E F TotalZ 403 47 5 3 0 9 467P 10 3 11 0 1 0 25N 10 11 2 1 25 0 49Figure 4Types and occurrence of antecedent-anaphor pai s in the subset of test data corresponding tozero leaf of Rule 3.antecedent-anaphor pairs in the test data, according to this classification, are shownin Figure 4.Obviously, for columns A and B in the table, nonzero cases, namely the sums ofpronouns and nominals, are in the minority of the test data.
Chen (1987) found a higherpercentage of zero anaphora occurring in the topic position with their antecedent mostfrequently in the topic or object positions of the immediately previous clause, whichstrongly supports the idea of letting anaphora of Types A and B be zero.
Zero anaphoraof Types A and B are generally understood because they are salient (Li and Thompson1981).
Anaphora of Types C to F are not as salient as Types A and B; thus we groupTypes C to F as nonsalient.
The total number of zero cases for the nonsalient ype is17(4%) in the test data; the total number of nonzeros for the same type is 40(63%).Thus we let anaphora of the nonsalient type be nonzero.
By letting Types A and B bezero, and others be nonzero, we obtained a new rule, Rule 4.Rule 4If an entity, e, in the current clause was referred to in the immediately preceding clause,does not violate any syntactic onstraint on zero anaphora, is not at the beginning ofa discourse segment, and is salient, then a zero anaphor is used for e; otherwise, anonzero anaphor is used.The decision tree and classification tree are shown in Figure 5.The result in the same figure shows that the matched rate increased from 93% to94%.
Note that, although the new material in Rule 4 was motivated by the prior work ofChen and others, the exact form of the new constraint was formulated after consideringthe distribution of anaphora in the data, which means that an improvement (on thisdata) was almost inevitable.3.
Overt Noun PhrasesWe now consider how to distinguish between pronouns and nominal anaphora.176Yeh and Mellish An Empirical Study on AnaphoraZ=490P=116N=703locality?immediatj e ' '~Z=~-74 Z----I 6P=103 P=I3N=329 N=374violating syntactic NZconstraints?iw ty?immedia~/ ~ng Z- - -O  7__~474P=37 P=66violatin~ svmactic NZ N=154 N=175 at segment constraints: NZ beginning?Y?
~ Y " ' ~  Z=467NZ at segment Z=7 P=25beg)nn~ng?
P---41 N=49Y NZZ~50 17 NZ s/~ie~t?
yes/"~y~, /  "X~ P=13 P=12NZ N=21 N=28Z Z NZMatched Overgenerated Undergenerated Total1,235 (94%) 34 (3%) 40 (3%) 1,309Figure 5Decision tree, classification tree, and result for Rule 4.3.1 An imacy  and Overt PronominalsAs shown in the classification trees of Rule 4 in Figure 5, pronouns are in the minorityof the nonzeros in the test data, and indeed this is clearly the case in the languagein general.
A simple way to refine the previous anaphor generation rule is to let thenonzero parts in the rule be nominal.
The decision tree and classification tree can thenbe obtained from Figure 5 by changing all nonzeroes (NZs) into nominals (Ns).To demonstrate he result of using the new decision tree, we extended the deft-nition of matched, overgenerated and undergenerated types used previously for zeroand nonzero anaphora to zero, pronominal, and nominal anaphora.
The number ofmatched cases for zero, pronoun, and nominal in the test data can be obtained by sum-ming up anaphora of the correct ype associated with the leaf nodes labeled Z, P, andN in the classification trees, respectively.
The overgenerated cases of zero anaphora,for instance, are the sum of nonzero anaphora ssociated with the leaf nodes labeledZ in the classification trees.
Conversely, the undergenerated cases of zero anaphora,for instance, are the sum of zero anaphora ssociated with the leaf nodes labeled withnonzeros.
The overgenerated and undergenerated cases of pronouns and nominals canbe obtained in a similar way.
The result from using full NPs for nominal anaphorais shown in Table 1.
Hereafter, we use overall  matched to refer to the total numberof matched anaphora, across all the classes.
The number of overall matched cases isthus 1,132 (450 + 682), out of 1,309 anaphora in total.
In general, we can convert histo a percentage by dividing by the total number of anaphora.
Thus the percentage of177Computational Linguistics Volume 23, Number 1Table 1Result of choosing full NP NZ in Rule 4.Matched Overgeneration UndergenerationZ P N Z P N Z P N450 (34%) 0(0%) 682 (52%) 34 (3%) 0(0%) 143 (11%) 40 (3%) 116 (9%) 21 (2%)overall matched cases is 86%.
This rate looks quite promising; however, it does nottruly reflect he use of different nominal forms.Li and Thompson (1979), and Chen (1986) showed that pronouns are frequentlyused when the anaphora occur at places marked as minor discontinuities and whenreferring to things that are highly noteworthy.
The conditions of minor discontinuitywere not clearly stated, and individual judgements on this are likely to vary.
Thus wewill not take it as a constraint to further refine our rule.
As for the other discoursefactor, high noteworthiness, the condition of animacy noticed by Chen can be deter-mined according to the features of the referent and hence is easily implementable.In an examination of inanimate anaphora, Chen (1986) found that there were only afew instances of pronouns; in other words, most pronominal anaphora re animate.On the other hand, the percentage of inanimate anaphora being encoded in nominalforms is higher than that of pronouns.
Thus we employ the animacy of the referentas a constraint to refine Rule 4 and obtain a new rule, Rule 5, as shown in Figure 6.Rule 5If an entity, e, in the current clause was referred to in the immediately preceding clause,does not violate any syntactic onstraint on zero anaphora, is not at the beginning ofa discourse segment, and is salient, then a zero anaphor is used for e; otherwise, anonzero anaphor is used.
If a nonzero anaphor is animate, then it is pronominalized;otherwise, it is nominalized.In general, animate objects characterize living things, especially animal life.
We adoptedthis concept to determine the animacy of anaphora.
The result of using Rule 5 is shownin the table of Figure 6.
Although the increase in the overall matched rate was notsignificant, 39% (45/116) of the pronouns in the test data, however, were matched byusing the new rule.3.2 Full NP DescriptionsThe surface structure of a Chinese nominal anaphor is a noun phrase that consistsof a head noun optionally preceded by associative phrase, articles, relative clauses,and adjectives (Li and Thompson 1981).
In Chinese, whether one chooses articles fornominal descriptions depends on complicated factors (Teng 1975; Li and Thompson1981).
Observing the test data, we found that nominal anaphora re not commonlymarked with articles.
5 Thus, we chose not to use articles for descriptions of nominalanaphora in our system.
The nominal descriptions investigated in the remainder of thissection are thought of as noun phrases of the above scheme without articles.
Nominalanaphora do not have unique forms as their zero and pronominal counterparts do.The description can be the same as the initial reference, parts of the information i  the5 See Yeh (1995) for detailed descriptions.178Yeh and Mellish An Empirical Study on Anaphorai,n media~/e,/ "x~ngviolatinR svata~ctic NZ consxralnts.a~inlat6?
at segmentyes// "xno beg)n~ng?/ XNyy  "x~yes~im~ s~ie~xt ?ye J  ~P N Z animate?P NZ=0P=37N=154 /,;mi~,ate?Y7Z=0 Z=9"P=I7 P=20N=8PZ=490P=116N=703immediat/e/ _~n gz=474 z= 16P=lO3 P=13N=329 N=374 violating syntactic con/~rai,ms?
NY7 "K ?Z=474P=66N=175 gt segmentZ=7 Z-4467N= 146 P=41 P=25N N= 129 N=49 ammate, salient?zY~ ~N~_~ Y_~450 ~Z?=I7P=23 P=I8 P=I3 P=I2N=I6 N=II0 N=21 N=28p N Z animate?Z=0 Z~I7P=5 P=7N=2 N=26p NMatched Overgeneration UndergenerationZ P N Z P N Z P N Total anaphora450 45 656 34 26 98 40 71 47 1,30934% 3% 50% 3% 2% 7% 3% 5% 4%Figure 6Decision tree, classification tree, and result for Rule 5.Table 2Occurrence of various types of nominal anaphora in the test data.Bare Full Reduced New Other Total471 (69%) 85 (12%) 72 (11%) 31 (5%) 23 (3%) 682initial reference can be removed, new information can be added to the initial reference,or even a different lexical item can be used for a nominal anaphor.
In this paper, wefocus on the first two cases.
A nominal anaphor is referred to as a reduced form, or areduction, of the initial reference if its head noun is the same as the initial reference,and its modification part is a strict subset of the optional part in the initial reference;otherwise, if it is identical to the initial reference, th6n it is a full description.We can classify nominal descriptions into the types shown in Figure 7.
The break-down of the matched nominal anaphora in the test data, in terms of the above clas 2sification, is shown in Table 2.
Note that first and second person pronotms in the testdata are classified as Type Bare in the table.179Computational Linguistics Volume 23, Number 1BareFullReducedNewOtherTypes of nominal anaphora.The initial reference isa bare noun, and the subsequent reference is the sameas the initial reference.The initial reference is reducible, and the subsequent reference is the same asthe initial reference.The initial reference is reducible and the subsequent reference is a reducedform of the initial reference without new information.The subsequent reference has new information in addition to the initialreference.Otherwise.Examples of nominal anaphora.Initial references Nominal anaphoraBare zuqiu 'football' zuqiu 'football'Full tie-tong 'iron barrel' tie-tong 'iron barrel'Reduced tie-tong 'iron barrel' tong 'barrel'New shui 'water' yuan-wan-zhong deshui'water in the round bowl'Other qian 'money' neixie chaopiao 'those notes'Figure 7Types and examples of nominal anaphora.The figures in Table 2 show that full descriptions, namely, Types Bare and Full,are frequently used for nominal anaphora.
Thus we first choose full descriptions forall N's.
As shown in Table 2, there are 556 (471 + 85) full descriptions used among682 matched nominal anaphora.
Thus the overall matched rate becomes 77%, if wetake different descriptions of nominal anaphora into account.
Obviously this showsthat the choice of full NP for nonzeros is not promising.
In the next subsection, weimprove this by considering the use of reduced and full descriptions.3.3 Reduced Descriptions within SegmentsPrevious work on the generation of referring expressions focused on producing mini-mal distinguishing descriptions (Dale and Haddock 1991; Dale 1992; Reiter and Dale1992) or descriptions customized for different levels of hearers (Reiter 1990).
Sincewe are not concerned with the generation of descriptions for different levels of users,we look only at the former group of work, which aims at generating descriptions fora subsequent reference to distinguish it from the set of entities with which it mightbe confused.
The main data structure in these algorithms is a context set, which isthe set of entities the hearer is currently assumed to be attending to, except he in-tended referent.
Minimal distinguishing descriptions pursue efficiency in producingan adequate description that can identity the intended referent unambiguously witha given context set.
Dale (1992) used the global focus space (Grosz and Sidner 1986),as the context set in his domain of small discourse.
Following this idea, the contextset grows as the discourse proceeds.
Consider, for example, two nominal anaphorareferring to the same entity occurring at different places in a discourse.
According tothe above algorithms, a single description would be produced for both anaphora if thecontext sets at both places contain the same elements.
On the other hand, in general,a description with more distinguishing information is used for the second anaphor ifdistractors have entered into the context set.
Two entities are said to be distractors to180Yeh and Mellish An Empirical Study on Anaphoraeach other if they are of the same category.
For example, the black dog and the brown dogare distractors to each other because they are of the same category, dog.
The entity, thebig cat, is not a distractor to the black dog because it is of different category, cat.Grosz and Sidner (1986) claim that discourse segmentation is an important factor,though obviously not the only one, governing the use of referring expressions.
If theidea of context set were restricted to local focus space (Grosz and Sidner 1986), then theresulting descriptions would be to some extent sensitive to local aspects of discoursestructure.
Although the algorithms would be refined due to the introduction of morediscourse structure, they would essentially still serve the purpose of distinguishingpotential referents.The beginnings of discourse segments, in a sense, indicate shifts of intention in adiscourse (Grosz and Sidner 1986).
In this situation, it may be preferred that subsequentreferences be full descriptions rather than reduced ones or pronouns, to emphasize thebeginning of discourse segments, even if the referents have just been mentioned inthe immediately previous utterance.
See Grosz and Sidner (1986) and Dale (1992) forsome examples that illustrate this idea.
Figure 8 indicates that a similar situation mayhappen in Chinese discourse.Among the groups of initial and subsequent references, we focus on the one in-dexed j, lafengzheng de xian 'the string pulling the kite'.
After it is initially introducedin (b), it then appears in zero and nominal forms alternatively in the rest of the dis-course, as shown schematically in Figure 9.
At the beginning of the second "sentence,"it appears in a full description and then in four reduced descriptions in the rest of the"sentence.
"6 It is not mentioned in the third "sentence."
When it is reintroduced intothe fourth "sentence," it appears in another full noun phrase, piao zai kongzhong de xian'the string fluttering in the sky,' which is not reduced.
Then, in the last "sentence," itrepeats the same patterns as in the second "sentence."
Since there are no distractingelements for the string in the discourse, the use of full descriptions at the beginningof "sentences," (e) and (g), can be interpreted as emphasizing that a new discoursesegment, "sentence," has begun.
The accompanying reduced descriptions can then beexplained as being intended to contrast with the emphasis at the beginning of "sen-tences."
Note that a full description is used for the subsequent reference in (p) that isnot at the beginning of a "sentence" because it is the first mention in the "sentence.
"Thus, we would generalize the above interpretation to be that a full description ispreferred for a subsequent reference if it is at the beginning of a "sentence" or the firstmention in the "sentence"; otherwise, a reduced description is preferred.Should distracting elements occur in a "sentence," a sufficiently distinguishabledescription is required for a subsequent reference within the "sentence" instead of areduced one, even if it has been mentioned previously in the "sentence," for example,yuanwan 'the round bowl' in (2d) and fangwan 'the square bowl' in (2e).
7(2) a. zhaolai tongyang daxiao de liangkuai tiepi,get same big-small NOM two iron-piece'Get two pieces of iron of the same size.'b.
zuocheng yige yuanwan i he yige fangwanJ.make one round-bowl and one square-bowl'Make a round and a square bowl.'c.
ba yuanwanili zhuangman leshui,6 See Section 2.3 for an explanation f "sentence.
"7 This is also obtained from the test data.181Computational Linguistics Volume 23, Number 1a.
fengzheng i ~b fangdao gaokong shangqu yihou,b.
la fengzheng i de xian j zhenme ye la bu zhi,c.
(d zongshi xiang xia wan,d.
zhe shi weishenme ne?e.
yuanlai, buguan fang fengzheng i de xian j you duome xi,f.
~J dou shi you zhongliang de,g.
xianJ de zhongliang shi youyu diqiu dui xian j you xiyin de liliang ter chansheng de,h.
zhege liliang I haoxiang wuxing de shou,i.
q5 k ba xian j xiangxi zhuai,j.
xianJ ~ jiu la bu zhi le.k.
qishi, fengzheng iye you zhongliang,1.
yinwei feng m chui zhe fengzheng i,m.
~b" shi fengzheng i xiang shang sheng,n.
suoyi fengzheng' bingbu xiang xia chen.o.
zheyang, ~ zai fangfengzheng i shi,p.
piao zai kongzhong de xian j xingcheng yige wanqu de huxing.q.
piao zai kongzhong de xian j yue chang,r.
xian j wanqu de yue lihai,s.
~J yue la bu zhi.Translation:a.
When flying a kite / in the sky,b.
the string pulling the kite ij can't be pulled straight.c.
It / is always bent downwards.d.
Why is that?e.
However thin the string pulling the kite q is,f.
(it)J all has weight.g.
The weight of the string j is due to the attracting power of the earth on the string jr.h.
This power I is like a invisible hand.i.
(It) 1 pulls the string j down.j.
The string j then cannot be pulled straight.k.
However, the kitC also has weight.1.
Since the wind m blows the kitC,m.
(it)" makes the kite / rise.n.
Therefore, the kite / does not fall down.o.
So when flying a kite/,p.
the string fluttering in the sky j forms a curved arc.q.
The longer the string fluttering in the sky j,r.
the more curved the string I is,s.
and the more difficult (it) j is to pull straight.Figure 8A sample Chinese written text.BA round-bowl - in  fill-full ASPECT water'Fill the round bowl  full of water.'d.
ranhou ba yuanwanizhong de shui manman daojin fangwanJli,then BA round-bowl - in  GEN water s lowly fill-in square-bowl- in'Then slowly pour  the water  in the round bowl  into the square bowl.182Yeh and Mellish An Empirical Study on Anaphoraa.Ib.I  j lttllC.I j zd.te.
I  j hrl lf.
I j .zg.I j reduced j reducedh.Ii.
I i rechmerti .
\[ j reducedk.I1.\[m\[n.\[O\[  1p.lj.f.u Iq.Ij_0,u Ir.
I j .
reduced IS.I j z  I, .
?
"sentence" l:.
"sentence" 2".
'2i "sentence" 3i"sentence" 4:"sentence" 5Key: j.z: referentj in zero form.j.full: referent j in full noun phrase.j.reduced: referent j in reduced noun phrase:"sentence" boundary.Figure 9Occurrence of referent j in the discourse in Figure 8.e.
ni hui faxian fangwanJ zhuangbuxia zhexie shui,you will find square-bowl fill-not-in these water'You will find that the square bowl can't hold this water.'f.
youxie shui hui liu chulai.have-some water will flow out-come'Some water will overflow.
'On the basis of the above observations, we propose the following preference rulefor the generation of descriptions for nominal anaphora in Chinese.Preference RuleIf a nominal anaphor, n, is the first mention in a "sentence," then a full description ispreferred; otherwise, if n is within a "sentence" and has been mentioned previouslyin the same "sentence" without distracting elements, then a reduced description ispreferred; otherwise a full description is preferred.We examined the nominal anaphora matched by using Rule 5 with the ones gen-erated by the preference rule.
The result is shown in Table 3.
As shown in the table,by using the preference rule, in addition to the fact that the majority of the nominalanaphora using full descriptions are matched, a considerable number of reduced de-scriptions are matched as well, giving an overall match of 88%.
If we only consider183Computational Linguistics Volume 23, Number 1Table 3Result of using the preference rule on the test data.Matched Bare Full Reduced New Other Total %yes 459 67 53 0 0 579 88%no 0 13 13 31 20 77 12%Types Bare, Full, and Reduced, namely, full and reduced escriptions in the test data,the match rates become 96% (579/605).
Both figures show that the preference rule ispromising in the choice of full or reduced descriptions for nominal anaphora.4.
Implementation and Evaluation ResultIn this section, we briefly describe the implementation of the rules in our Chinesenatural anguage generation system.
We then present an evaluation of the anaphorain some texts generated by our system.4.1 ImplementationThe rules obtained in the previous sections have been implemented in the referringexpression component of our Chinese natural anguage generation system (Yeh 1995)that generates paragraph-sized texts for describing the plants, animals, etc., in a na-tional park.
Basically, the main goal of our work is to generate coherent texts by takingadvantage of various forms of anaphora in Chinese.
The system, like conventional ones(McKeown 1985; Maybury 1990; Dale 1992; Hovy 1993), is divided into strategic andtactical components.
Since we do not aim at inventing new concepts in content plan-ning, we borrow the idea of text planning in Maybury's TEXPLAN system (Maybury1990) as the basis of the strategic omponent.
As for the tactical component, we haveconstructed a simple Chinese grammar in the PATR formalism (Shieber 1986), whichis sufficient for our purpose at the current stage.On accepting an input goal from the user, the system invokes the text planneraccording to the operators in the plan library to build a hierarchical discourse struc-ture that satisfies the input goal.
After the text planning is finished, the decision ofanaphoric forms and descriptions i then carried out by traversing the plan tree.
Withinthe traversal, when a reference is met, if it is a subsequent one, then the program con-sults Rule 5 to obtain a form: zero, pronominal, or nominal.
If the nominal form ischosen, then the preference rule is consulted to get a description.In the domain knowledge base, each entity, in addition to the information for thehead noun in the surface form, is accompanied by a property list that will be realized inthe modification part of the surface noun phrase for the initial reference.
We build upthe semantic structure of an initial reference by taking all the elements in the propertylist, along with the substance of the entity, corresponding to the head noun in thesurface noun phrase.
To simplify the work, for the moment, only one element is storedin the property list.
When a full description is chosen for a subsequent reference, itssemantic structure contains the same property and substance information as the initialreference.
On the other hand, if a reduced escription is decided on, only the substanceis taken into the semantic structure.
In the future, we will extend the property list byallowing multiple elements in the list.The tests of locality, syntactic onstraints, and salience are straightforward to im-plement because the system has complete knowledge of the discourse to be generated184Yeh and Mellish An Empirical Study on Anaphoraand its syntactic structure.
Only the tests of discourse structure and animacy are dif-ficult, and for these we have had to approximate what a more sophisticated systemmight be able to do.
Currently, we examine the decomposition field of a planningoperator by hand to determine "sentence" boundaries and fix this for all applicationsof the operator.
Thus we assume that there is a distinguished level of structure ina discourse plan that is relevant for this purpose (this may be expressible in termsof Maybury's distinction between rhetorical acts and speech acts).
For the animacyconstraint, we have had to determine by hand whether each individual object in ourdomain is likely to be treated as animate or not.4.2 EvaluationThe linguistic principles embodied in our rules were all independently proposed, soin some respects the previous data served as both training and test data in the devel-opment of the rules.
Furthermore, the assumed contextual information, for example,discourse structures, may be difficult to access in a real implementation.
Thus, theperformance ofa real anaphor generation algorithm based on the rules proposed heremay be different from the experimental results we obtained.
In this section, we attempta post-evaluation by asking some native speakers of Chinese to judge the quality ofthe anaphora generated by a real system based on the rules.Evaluation is becoming an increasingly important issue for natural language gen-eration systems (Meteer and McDonald 1991), though, unfortunately, there are still nogenerally accepted methods.
In this work, we were particularly concerned to find amethod of evaluation that reflected irectly on the anaphor generation of the system(unlike "black box" evaluation of the kind we had done before \[Levine and Mellish1995\]).
We were also wary of asking human subjects to estimate the "readability" or"coherence" of texts (though this seemed to work well for Acker and Porter \[1994\]).
Inthis evaluation, we chose three Chinese natural language generation systems to com-pare.
Each system is assumed to have the same system components, as described inSection 4.1, except hat the referring expression component ofeach system is equippedwith a different anaphor generation rule.
Given an input to a test system, anaphorain the resulting texts will be determined by the rule used in the referring expressioncomponent of the system.
The rules, TRi, i = 1 .
.
.
.
.
3, used in the test systems areshown in Figure 10.
TR1 corresponds to our Rule 2, together with an animacy testto distinguish between pronouns and nominal anaphora.
TR2 adds the constraint ondiscourse structure and TR3 adds to this the salience constraint (and is the same asRule 5).
The intention was to test a range of rules and hence get an indication of howmuch better (if at all) the more sophisticated rules are than the simpler ones.The evaluation task can be divided into an annotation stage and a comparisonstage.
In the annotation stage, each of 12 native speakers of Chinese is given five testsheets corresponding to five texts generated by our generation system.
The numbersof clauses in the texts are 5, 12, 12, 21, and 34; the numbers of anaphora in the textsare 4, 11, 11, 20, and 34.Each anaphor position in a generated text was left empty and all candidate formsof the anaphor, including zero, pronominal, and full and reduced escriptions wereput under the empty space.
The speaker was asked to annotate which form he orshe preferred for each anaphor position on the test sheets.
After the annotations werecollected, we compared the speakers' results with the generated texts to investigatethe performance of the test rules.
In each comparison, we noted down the number ofmatches between the computer-generated t xt and the human result.
This approachis the same as that used in Knight and Chander (1994) for the problem of articlegeneration, except hat in our case we had to use generated, rather than naturally185Computational Linguistics Volume 23, Number 1immedia?a~ngviolating syntactic N constraints?
ye/\osatisfying '~ Z an)/n~ criterion.Y7  "gX ?P NTR1immedia~/ X~ngviolating syntactic N constraints?Y /  X~ ?anTa~y criterion, at segmentY7 ,~o y},~ ,~,oP N .
satisfying '~ Z ammacy riterion.
y/ oP NTR2~a~?immedia~/ N~ngviolating syntactic N constraints?
,e/\o?
satisfying .
'~ and/navy criterion, b~,~ir~ng?at segme tY~/,??
xOX?
y~ x~x?N satisfying sal~eqce?animacy,-criteriOl~es / N,,n 0re /  "\x~o 7 xO~ / \ Z satisfying P N animacy riterion?Y /  NX~ ?P NTR3Figure 10Rules used in the compared systems.Table 4Average match rates between the results of test systems and native speakers.System Text 1 Text 2 Text 3 Text 4 Text 5TR1 3.6 7.8 6.8 14 23.890% 70% 62% 70% 70%TR2 3.6 7.8 7.3 14.9 24.390% 70% 66% 75% 71%TR3 3.6 8.7 7.1 14.6 2490% 79% 65% 73% 71%occurring, texts, because otherwise our system would not have had access to theappropriate syntactic and semantic information.
The average matching rates of thetexts generated by the test systems with native speakers' results are shown in Table 4.On average, the matching rate of TR3 is 76%, compared with the other systems, thematching rate of TR1 is 72% and of TR2 is 74%.186Yeh and Mellish An Empirical Study on AnaphoraTable $Agreement of annotations among speakers.Speaker Text 1 Text 2 Text 3 Text 4 Text 51 3.9 8 7.5 14.3 242 3.9 9.5 7.8 16.1 26.53 3.9 9.1 7.8 15.8 26.34 3.9 8.9 6.6 15.4 23.95 3.3 8.5 8.3 15.2 25.46 3.9 9.5 8.3 14.1 26.57 3.9 8.3 7.1 15 26.28 3.9 8.1 7.9 15.8 26.49 2.4 6.8 7 12.1 20.510 3.9 8.6 8.1 14.5 2511 2.3 5.7 7 12.7 21.212 3.9 9.4 7.8 15.3 26.3Average 3.6 8.4 7.6 14.7 24.990% 76% 69% 73% 73%This average matching rate, however, is lower than the matching rates we obtainedin the empirical studies described previously.
The problem is partly because the testtexts used in the former comparison are human-created, while the test texts used hereare computer-generated.
The grammatical structures of the computer-generated textsare simplified; they are not as sophisticated as human texts.
When asked to decidetheir preferences for anaphora in the computer-generated xts, speakers may findthe information shown in the test texts less complete than what they are used to increating their own texts and hence it may be difficult for them to make decisions.
Inthe empirical study, the human-created texts perhaps provided enough informationfor the hypothetical computer to decide on an appropriate anaphoric form.A more important reason why the matching rates are lower with speakers thanwith the hypothetical computer may be that in some circumstances, more than onesolution may be acceptable and the speakers may not always choose the same one asthe computer.
This hypothesis can be investigated by looking at the extent o whichthe speakers agree among themselves.To see how the speakers agree among themselves, we compared speakers' anno-tations.
The comparison result is shown in Table 5.
For each speaker, the number foreach test text is the average of matches with the other eleven speakers.
At the end ofthe table are the average numbers for the speakers' agreement among themselves.
Thefigures in the table show that the speakers do not achieve agreement among them-selves for the use of anaphora in this test.
These figures are further supported by theuse of the kappa statistic.
The overall kappa value for all speakers i about 0.41, whichrepresents only "moderate" agreement.
The measure of agreement gets worse if onlythe zero/pronoun/nominal  distinction is considered or if zero and nonzero pronounsare lumped together.
Only two speakers agree with one another with a kappa valueof more than 0.7 (none with a value of greater than 0.8).
The speakers as a wholeagreed with kappa greater than 0.7 on only 30 out of the 80 anaphora, with completeagreement only 14 times.
To get an overall agreement ofgreater than 0.8 would requirereducing the set of speakers from 12 to a carefully selected 3.Since all systems produce the same result on Text 1, unsurprisingly they all havethe same matching rate, as shown in Table 4.
Text 2 contains three topic shifts thatwould make the rule containing the salience constraint, TR3, obtain different output187Computational Linguistics Volume 23, Number 1from those without this constraint.
TR1 and TR2 produce the same output and hencethey obtain the same matching rate, 70%.
TR3 obtains higher matching rates than theother two, 79%, which shows the effectiveness of the salience constraint in it.Another middle-sized test text, Text 3, is broken into three "sentences" and con-tains three topic shifts.
The constraints on discourse segment beginnings in TR2 andTR3 and the salience constraint in TR3 would therefore have some effects on the out-put texts.
The matching rate, as shown in Table 4, increases from 62% to 66% for TR2,which shows that the constraint on discourse segment beginnings in TR2 is effective.TR3 obtains a 65% matching rate, on average, which is 1% lower than its predecessorTR2.
However, this decrease in average matching rate does not negate the effectivenessof the salience constraint in TR3.
TR2's text differs from TR3's in the three topic shifts:TR2 generates zero anaphora for these shifts, while TR3 generates full descriptions.The speakers varied greatly in choosing anaphoric forms for these topic shifts: among12 speakers, 4 chose all full descriptions, 3 used all zero anaphora, and the other 5chose zero, pronominal, and nominal anaphora.
Thus, 4 of the 12 speakers completelyagree with TR3, while 3 agree with TR2.
This shows that the salience constraint inTR3 is still effective.Next, we examine the more complicated texts, Texts 4 and 5.
As shown in Table 4,the increases in matching rates show the effectiveness of the constraint on discoursesegments beginning in TR2.
Again, the average matching rates of TR3 are sightly lowerthan TR2 for these two texts.
However, similar to the situation in Text 3, the speakershave varied agreement on the choice of anaphora for the topic shiftings in these twotexts.
For Text 4, 3 speakers completely agree with TR2 and 1 speaker agrees with TR3.As for Text 5, 2 speakers completely agree with TR2, while the others partly agree withTR2 and TR3.The discussions above show that the salience constraint in TR3 is sometimes effec-tive in getting small improvements in the output exts.
In brief, the more sophisticatedconstraints a rule contains, the better it performs.
Both TR2 and TR3 perform betterthan TR1.
TR3 performs better than TR2 for texts with simple discourse segment struc-ture.
For the texts having complicated iscourse segment structures, TR2 is slightlybetter than TR3 on average matching rates.
Adding the results of the rules to thoseof the speakers leads to a slight decrease in kappa for TR1 but progressively better(though only from 0.41 to 0.43) values for kappa for TR2 and TR3.
This indicates thatthe better ules seem to disagree with the speakers no more than the speakers disagreeamong themselves.
There are nine anaphora where the kappa score including TR3 isless than that for the speakers alone (in many other cases, the results are better).
Theseseem to involve places where the speakers were more willing to use a zero pronoun(where the system used a reduced nominal anaphor) and where the speakers reducednominal anaphora less than the system did.5.
ConclusionIn this paper, we present empirical work on the generation of anaphora in Chinese.The initial set of results suggests that most anaphora, including zero anaphora, andfull and reduced escriptions for nominal anaphora, can be effectively generated by arule using simple syntactic, semantic, and discourse constraints.
The results obtainedfrom an implementation of this rule, however, correlated less well with human per-formance.
It is hard to determine the reason for this, though the problems of reliablyimplementing all the constraints, presenting the anaphora within naturalqooking textsand, above all, coping with the disagreements between ative speakers, all probablymake a contribution.188Yeh and Mellish An Empirical Study on AnaphoraThe factors affecting the use of pronouns are very complicated; thus it is difficultto get computable rules.
Introducing the constraint of animacy of objects in the rulecan resolve part of the problem.
We do not handle the generation of long-distancepronouns, which were rare in our texts.
A possible solution would be to employ theconcept of stacked focus space in Grosz and Sidner's discourse structure theory (Groszand Sidner 1986; Dale 1992).In the final rule, the implementation f the test of the beginning of a discoursesegment is not quite as straightforward asthe other constraints.
In our current imple-mentation, we rely on the hierarchical structure of the message content to be generatedas the basis for dividing the message into segments, which is effective in improvingthe texts generated by our Chinese natural anguage generation system.
The evalua-tion result also shows that the rule using all constraints collected from the empiricalstudy performs better than one with simpler constraints.In the future, this work needs to be further developed to deal with anaphora inother types of texts and the use of connectives in generated text to create cohesivediscourse.
In addition the constraints for pronominal anaphora could be improved,and the implementation extended to satisfy other types of applications.6.
AcknowledgementsWe would like to thank the three anonymous reviewers of this paper, whose detailedcomments have been extremely valuable.Appendix: Instructions for Discourse SegmentationThe instructions for discourse segmentation, given in Chinese, are as follows:Description: There are five articles to be examined in this investiga-tion.
Each article is accompanied by a question-style topic.
The contentof an article is to answer the question accompanying it.
Therefore thepurpose (or intention) of the whole article is obviously to answer itsown question.
Reading carefully, you will find that an article can be di-vided into a string of segments according to their respective purposes(or intentions).
Let's call each of them a subpurpose (or subintention).Therefore the purpose (or intention) of an article is obviously com-posed of a string of subpurposes (or subintentions).
In other words,every subpurpose (subintention) serves as a part of the whole inten-tion of an article.
Furthermore, in an article, a subpurpose (or subin-tention) can be a subsidiary of other subpurposes (or subintentions),just like subpurposes ( ubintentions) are subsidiaries of the whole in-tention.
That is, a subpurpose can subsume others.
Therefore, we havea hierarchical intentional structure for an article,Task: After thoroughly understanding the above description, for eacharticle, complete the following tasks:.2.Mark the boundaries of segments; andDraw the hierarchical intentional structure.189Computational Linguistics Volume 23, Number 1ReferencesAcker, Liane and Bruce Porter.
1994.Extracting viewpoints from knowledgebases.
In Proceedings ofthe Twelfth NationalConference on Arti~cial Intelligence, pages547-552.
AAAI Press/MIT Press.Chen, Ping.
1984.
A discourse analysis ofthird person zero anaphora in Chinese.Technical Report, Indiana UniversityLinguistics Club, Bloomington, IN.Chen, Ping.
1986.
Referent Introducing andTracking in Chinese Narratives.
Ph.D. thesis,University of California, Los Angeles, CA.Chen, Ping.
1987.
Hanyu lingxin huizhi dehuayu fenxi \[A discourse approach tozero anaphora in Chinese\].
ZhongguoYuwen \[Chinese Linguistics\], pages 363-378.Dale, Robert.
1992.
Generating ReferringExpressions: Constructing Descriptions in aDomain of Objects and Processes.
The MITPress, Cambridge, MA.Dale, Robert and Nicholas Haddock.
1991.Content determination i  the generationof referring expressions.
ComputationalIntelligence, pages 252-265.Grice, Herbert P. 1975.
Logic andconversation.
In P. Cole and J. L. Morgan,editors, Syntax and Semantics 3: Speech Acts.Academic Press, New York.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions, and thestructure of discourse.
ComputationalLinguistics, 12(3):175-204.Hovy, Eduard.
1993.
Automated iscoursegeneration using discourse structurerelations.
Artificial Intelligence,63(1-2):341-385.Knight, Kevin and Ishwar Chander.
1994.Automated postediting of documents.
InProceedings ofthe Twelfth National Conferenceon Art~'cial Intelligence, pages 779-784.AAAI Press/MIT Press.Levine, John and Chris Mellish.
1995.
Theidas user trials: Quantitative valuation ofan applied natural anguage generationsystem.
In Proceedings ofthe Fifth EuropeanWorkshop on Natural Language Generation,pages 75-94, Leiden, The Netherlands.Li, Charles N. and Sandra A. Thompson.1979.
Third-person pronouns andzero-anaphora in Chinese discourse.
InT.
Giv6n, editor, Syntax and Semantics:Discourse and Syntax, volume 12.Academic Press, pages 311-335.Li, Charles N. and Sandra A. Thompson.1981.
Mandarin Chinese: A FunctionalReference Grammar.
University ofCalifornia Press, Berkeley, CA.Liu, Y. C. 1984.
Zuowen defangfa \[Approachesto Composition\].
Xuesheng Chubanshe,Taipei, Taiwan.Maybury, Mark T. 1990.
PlanningMultisentential English Text UsingCommunicative Acts.
Ph.D. thesis,Cambridge University.McDonald, David D. 1980.
Natural LanguageGeneration as a Process of Decision Makingunder Constraints.
Ph.D. thesis, MIT.McKeown, Kathleen R. 1985.
Text Generation.Cambridge University Press.Meteer, Marie and David McDonald.
1991.Evaluation for generation.
In J. G. Nealand S. M. Walter, editors, Natural LanguageProcessing Systems Evaluation Workshop,pages 127-131, NY.
Rome Laboratory.Reiter, Ehud.
1990.
Generating descriptionsthat exploit a user's domain knowledge.In R. Dale, C. Mellish, and M. Zock,editors, Current Research in NaturalLanguage Generation.
Academic Press.Reiter, Ehud and Robert Dale.
1992.
A fastalgorithm for the generation of referringexpressions.
In Proceedings ofthe 14thInternational Conference on ComputationalLinguistics, pages 232-238.Shieber, Stuart M. 1986.
An introduction tounification-based approach to grammar.Technical Report Lecture Notes, No.
4,CSLI, Stanford University.Siegel, Sidney and N. J. Castellan.
1988.Nonparametric Statistics for the BehavioralSciences.
McGraw-Hill.Tai, James H. Y.
1978.
Anaphoric constraintsin Mandarin Chinese narrative discourse.In J. Hinds, editor, Anaphora in Discourse.Linguistic Research, Edmonton, Alberta.Teng, Shou-Hsin.
1975.
A Semantic Study ofthe Transitivity Relations in Chinese.University of California Press, Berkeley,CA.Tutin, Agn~s and Richard Kittredge.
1992.Lexical choice in context: Generatingprocedural texts.
In Proceedings ofthe 14thInternational Conference on ComputationalLinguistics (COLING-92), pages 763-769,Nantes, France.Walker, Marilyn, Masayo Iida, and SharonCote.
1994.
Japanese discourse and theprocess of centering.
ComputationalLinguistics, 20(2):193-232.Yeh, Ching-Long.
1995.
Generation ofAnaphors in Chinese.
Ph.D. thesis,University of Edinburgh, Edinburgh,Scotland.190
