Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 55?60,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsDOMCAT: A Bilingual Concordancer for Domain-Specific ComputerAssisted TranslationMing-Hong Bai1,2 Yu-Ming Hsieh1,2 Keh-Jiann Chen1 Jason S. Chang21 Institute of Information Science, Academia Sinica, Taiwan2 Department of Computer Science, National Tsing-Hua University, Taiwanmhbai@sinica.edu.tw, morris@iis.sinica.edu.tw,kchen@iis.sinica.edu.tw, jason.jschang@gmail.comAbstractIn this paper, we propose a web-basedbilingual concordancer, DOMCAT 1 , fordomain-specific computer assistedtranslation.
Given a multi-word expressionas a query, the system involves retrievingsentence pairs from a bilingual corpus,identifying translation equivalents of thequery in the sentence pairs (translationspotting) and ranking the retrieved sentencepairs according to the relevance betweenthe query and the translation equivalents.To provide high-precision translationspotting for domain-specific translationtasks, we exploited a normalizedcorrelation method to spot the translationequivalents.
To ranking the retrievedsentence pairs, we propose a correlationfunction modified from the Dice coefficientfor assessing the correlation between thequery and the translation equivalents.
Theperformances of the translation spottingmodule and the ranking module areevaluated in terms of precision-recallmeasures and coverage rate respectively.1 IntroductionA bilingual concordancer is a tool that can retrievealigned sentence pairs in a parallel corpus whosesource sentences contain the query and thetranslation equivalents of the query are identifiedin the target sentences.
It helps not only on findingtranslation equivalents of the query but alsopresenting various contexts of occurrence.
As aresult, it is extremely useful for bilingual1 http://ckip.iis.sinica.edu.tw/DOMCAT/lexicographers, human translators and secondlanguage learners (Bowker and Barlow 2004;Bourdaillet et al, 2010; Gao 2011).Identifying the translation equivalents,translation spotting, is the most challenging part ofa bilingual concordancer.
Recently, most of theexisting bilingual concordancers spot translationequivalents in terms of word alignment-basedmethod.
(Jian et al, 2004; Callison-Burch et al,2005; Bourdaillet et al, 2010).
However, wordalignment-based translation spotting has somedrawbacks.
First, aligning a rare (low frequency)term may encounter the garbage collection effect(Moore, 2004; Liang et al, 2006) that cause theterm to align to many unrelated words.
Second, thestatistical word alignment model is not good atmany-to-many alignment due to the fact thattranslation equivalents are not always correlated inlexical level.
Unfortunately, the above effects willbe intensified in a domain-specific concordancerbecause the queries are usually domain-specificterms, which are mostly multi-word low-frequencyterms and semantically non-compositional terms.Wu et al (2003) employed a statisticalassociation criterion to spot translation equivalentsin their bilingual concordancer.
The association-based criterion can avoid the above mentionedeffects.
However, it has other drawbacks intranslation spotting task.
First, it will encounter thecontextual effect that causes the system incorrectlyspot the translations of the strongly collocatedcontext.
Second, the association-based translationspotting tends to spot the common subsequence ofa set of similar translations instead of the fulltranslations.
Figure 1 illustrates an example ofcontextual effect, in which ?Fan K'uan?
isincorrectly spotted as part of the translation of thequery term ??????
?
(Travelers AmongMountains and Streams), which is the name of the55painting painted by ?Fan K'uan/??
?
since thepainter?s name is strongly collocated with thename of the painting.Sung , Travelers Among Mountains and Streams , FanK'uan???????
?Figure 1.
?Fan K'uan?
may be incorrectly spotted aspart of the translation of ??????
?, if pureassociation method is applied.Figure 2 illustrates an example of commonsubsequence effect, in which ???????
(theRiver During the Qingming Festival/ Up the RiverDuring Qingming) has two similar translations asquoted, but the Dice coefficient tends to spot thecommon subsequences of the translations.
(Function words are ignored in our translationspotting.
)Expo 2010 Shanghai-Treasures of Chinese Art Alongthe River During the Qingming Festival2010?????????????????
?Oversized Hanging Scrolls and Handscrolls Up theRiver During Qingming???????????
?Figure 2.
The Dice coefficient tends to spot the commonsubsequences ?River During Qingming?.Bai et al (2009) proposed a normalizedfrequency criterion to extract translationequivalents form sentence aligned parallel corpus.This criterion takes lexical-level contexture effectinto account, so it can effectively resolve the abovementioned effect.
But the goal of their method is tofind most common translations instead of spottingtranslations, so the normalized frequency criteriontends to ignore rare translations.In this paper, we propose a bilingualconcordancer, DOMCAT, for computer assisteddomain-specific term translation.
To remedy theabove mentioned effects, we extended thenormalized frequency of Bai et al (2009) to anormalized correlation criterion to spot translationequivalents.
The normalized correlation inheritsthe characteristics of normalized frequency and isadjusted for spotting rare translations.
Thesecharacteristics are especially important for adomain-specific bilingual concordancer to spottranslation pairs of low-frequency and semanticallynon-compositional terms.The remainder of this paper is organized asfollows.
Section 2 describes the DOMCAT system.In Section 3, we describe the evaluation of theDOMCAT system.
Section 4 contains someconcluding remarks.2 The DOMCAT SystemGiven a query, the DOMCAT bilingualconcordancer retrieves sentence pairs and spotstranslation equivalents by the following steps:1.
Retrieve the sentence pairs whose sourcesentences contain the query term.2.
Extract translation candidate words from theretrieved sentence pairs by the normalizedcorrelation criterion.3.
Spot the candidate words for each targetsentence and rank the sentences bynormalized the Dice coefficient criterion.In step 1, the query term can be a single word, aphrase, a gapped sequence and even a regularexpression.
The parallel corpus is indexed by thesuffix array to efficiently retrieve the sentences.The step 2 and step 3 are more complicated andwill be described from Section 2.1 to Section 2.3.2.1 Extract Translation Candidate WordsAfter the queried sentence pairs retrieved from theparallel corpus, we can extract translationcandidate words from the sentence pairs.
Wecompute the local normalized correlation withrespect to the query term for each word e in eachtarget sentence.
The local normalized correlationis defined as follows:??????????
?fqfqfeqjif jf ifepfepelnc ||)|(||)|(),,;(      (1)where q denotes the query term, f denotes thesource sentence and e denotes the target sentence,?
is a small smoothing factor.
The probability p(e|f)is the word translation probability derived from theentire parallel corpus by IBM Model 1 (Brown etal., 1993).
The sense of local normalizedcorrelation of e can be interpreted as theprobability of word e being part of translation ofthe query term q under the condition of sentencepair (e, f).56Once the local normalized correlation iscomputed for each word in retrieved sentences, wecompute the normalized correlation on theretrieved sentences.
The normalized correlation isthe average of all lnc values and defined as follows:??
?niiielncnenc 1)()( ),,;(1);( feqq            (2)where n is the number of retrieved sentence pairs.After the nc values for the words of the retrievedtarget sentences are computed, we can obtain atranslation candidate list by filtering out the wordswith lower nc values.To compare with the association-based method,we also sorted the word list by the Dice coefficientdefined as follows:)()(),(2),( qqq freqefreqefreqedice ??
(3)where freq is frequency function which  computesfrequencies from the parallel corpus.Candidate words NCmountain 0.676stream 0.442traveler 0.374among 0.363sung 0.095k'uan 0.090Figure 3(a).
Candidate words sorted by nc values.Candidate words Dicetraveler 0.385reduced 0.176stream 0.128k'uan 0.121fan 0.082among 0.049mountain 0.035Figure 3(b).
Candidate words sorted by Dice coefficientvalues.Figure 3(a) and (b) illustrate examples oftranslation candidate words of the query term ??????
?
(Travelers Among Mountains andStreams) sorted by the nc values, NC, and the Dicecoefficients respectively.
The result shows that thenormalized correlation separated the related wordsfrom unrelated words much better than the Dicecoefficient.The rationale behind the normalized correlationis that the nc value is the strength of word egenerated by the query compared to that ofgenerated by the whole sentence.
As a result, thenormalized correlation can easily separate thewords generated by the query term from the wordsgenerated by the context.
On the contrary, the Dicecoefficient counts the frequency of a co-occurredword without considering the fact that it could begenerated by the strongly collocated context.2.2 Translation SpottingOnce we have a translation candidate list andrespective nc values, we can spot the translationequivalents by the following spotting algorithm.For each target sentence, first, spot the word withhighest nc value.
Then extend the spotted sequenceto the neighbors of the word by checking their ncvalues of neighbor words but skipping functionwords.
If the nc value is greater than a threshold ?,add the word into spotted sequence.
Repeat theextending process until no word can be added tothe spotted sequence.The following is the pseudo-code for thealgorithm:S is the target sentenceH is the spotted word sequence?is the threshold of translation candidate wordsInitialize:H? ?emax?S[0] Foreach ei in S: If nc(ei) > nc(emax):emax ?
?eiIf nc(emax )??
:?add?emax?to?HRepeat until no word add to Hej?left?neighbor?of?H?If?nc(ej?)??:??
??
?add?ej?to?H?ek?right?neighbor?of?H?If nc(?ek?)???:??
??
?add?ek?to?H?Figure 4: Pseudo-code of translation spotting process.572.3 RankingThe ranking mechanism of a bilingualconcordancer is used to provide the most relatedtranslation of the query on the top of the outputsfor the user.
So, an association metric is needed toevaluate the relations between the query and thespotted translations.
The Dice coefficient is awidely used measure for assessing the associationstrength between a multi-word expression and itstranslation candidates.
(Kupiec, 1993; Smadja etal., 1996; Kitamura and Matsumoto, 1996;Yamamoto and Matsumoto, 2000; Melamed, 2001)The following is the definition of the Dicecoefficient:)()(),(2),( qtqtqt freqfreqfreqdice ??
(4)where q denotes a multi-word expression to betranslated, t denotes a translation candidate of q.However, the Dice coefficient has the commonsubsequence effect (as mentioned in Section 1) dueto the fact that the co-occurrence frequency of thecommon subsequence is usually larger than that ofthe full translation; hence, the Dice coefficienttends to choose the common subsequence.To remedy the common subsequence effect, weintroduce a normalized frequency for a spottedsequence defined as follows:??
?niiilnfnf1)()( ),,;(),( feqtqt            (5)where lnf is a function which compute normalizedfrequency locally in each sentence.
The followingis the definition of lnf:?????
?tHfeqfeqteelnclnf )),,;(1(),,;(      (6)where H is the spotted sequence of the sentencepair (e,f), H-t are the words in H but not in t. Therationale behind lnf function is that: when countingthe local frequency of t in a sentence pair, if t is asubsequence of H, then the count of t should bereasonably reduced by considering the strength ofthe correlation between the words in H-t and thequery.Then, we modify the Dice coefficient byreplacing the co-occurrence frequency withnormalized frequency as follows:)()(),(2),( qtqtqt freqfreqnfnf_dice ??
(7)The new scoring function, nf_dice(t,q), isexploited as our criterion for assessing theassociation strength between the query and thespotted sequences.3 Experimental Results3.1 Experimental SettingWe use the Chinese/English web pages of theNational Palace Museum 2  as our underlyingparallel corpus.
It contains about 30,000 sentencesin each language.
We exploited the ChampollionToolkit (Ma et al, 2006) to align the sentence pairs.The English sentences are tokenized andlemmatized by using the NLTK (Bird and Loper,2004) and the Chinese sentences are segmented bythe CKIP Chinese segmenter (Ma and Chen, 2003).To evaluate the performance of the translationspotting, we selected 12 domain-specific terms toquery the concordancer.
Then, the returned spottedtranslation equivalents are evaluated against amanually annotated gold standard in terms of recalland precision metrics.
We also build two differenttranslation spotting modules by using the GIZA++toolkit (Och and Ney, 2000) with theintersection/union of the bidirectional wordalignment as baseline systems.To evaluate the performance of the rankingcriterion, we compiled a reference translation setfor each query by collecting the manuallyannotated translation spotting set and selecting 1 to3 frequently used translations.
Then, the outputs ofeach query are ranked by the nf_dice function andevaluated against the reference translation set.
Wealso compared the ranking performance with theDice coefficient.3.2 Evaluation of Translation SpottingWe evaluate the translation spotting in terms of theRecall and Precision metrics defined as follows:2 http://www.npm.gov.tw58||||1)(1)()(????
??
niigniiigHHHRecall                     (8)||||1)(1)()(????
??
niiniiigHHHPrecision                     (9)where i denotes the index of the retrievedsentence, )(iH  is the spotted sequences of the ithsentence returned by the concordancer,  and )(igH isthe gold standard spotted sequences of the ithsentence.
Table 1 shows the evaluation oftranslation spotting for normalized correlation, NC,compared with the intersection and union ofGIZA++ word alignment.
The F-score of thenormalized correlation is much higher than that ofthe word alignment methods.
It is noteworthy thatthe normalized correlation increased the recall ratewithout losing the precision rate.
This may indicatethat the normalized correlation can effectivelyconquer the drawbacks of the word alignment-based translation spotting and the association-based translation spotting mentioned in Section 1.Recall Precision F-scoreIntersection 0.4026 0.9498 0.5656Union 0.7061 0.9217 0.7996NC 0.8579 0.9318 0.8933Table 1.
Evaluation of the translation spottingqueried by 12 domain-specific terms.We also evaluate the queried results of eachterm individually (as shown in Table 2).
As itshows, the normalized correlation is quite stablefor translation spotting.Query terms GIZA Intersection GIZA Union NC R P F R P F R P F???
(Maogong cauldron) 0.27 0.86 0.41 0.87 0.74 0.80  0.92 0.97 0.94????
(Jadeite cabbage) 0.48 1.00 0.65 1.00 0.88 0.94  0.98 0.98 0.98?????
(Travelers Among Mountains and Streams) 0.28 0.75 0.41 1.00 0.68 0.81 0.94 0.91 0.92?????
(Up the River During Qingming) 0.22 0.93 0.35 0.97 0.83 0.89  0.99 0.91 0.95???
(Ching-te-chen) 0.50 0.87 0.63 0.73 0.31 0.44 1.00 0.69 0.82??
(porcelain) 0.53 0.99 0.69 0.93 0.64 0.76 0.78 0.96 0.86??
(cobalt blue glaze) 0.12 1.00 0.21 0.85 0.58 0.69 0.94 0.86 0.90??
(inscription) 0.20 0.89 0.32 0.71 0.34 0.46  0.88 0.95 0.91????
(Three Friends and a Hundred Birds) 0.58 0.99 0.73 1.00 0.97 0.99 1.00 0.72 0.84??
(wild cursive script) 0.42 1.00 0.59 0.63 0.80 0.71 0.84 1.00 0.91???
(Preface to the Orchid Pavilion Gathering) 0.33 0.75 0.46 0.56 0.50 0.53 0.78 1.00 0.88????
(Latter Odes to the Red Cliff) 0.19 0.50 0.27 0.75 0.46 0.57 0.94 0.88 0.91Table 2.
Evaluation of the translation spotting for each term3.3 Evaluation of RankingTo evaluate the performance of a ranking function,we ranked the retrieved sentences of the queries bythe function.
Then, the top-n sentences of theoutput are evaluated in terms of the coverage ratedefined as follows:?coveragequeries of #top-nin on  translatia findcan  queries of #   (10)The meaning of the coverage rate can beinterpreted as: how many percent of the query canfind an acceptable translation in the top-n results.We use the reference translations, as described inSection 3.1, as acceptable translation set for eachquery of our experiment.
Table 3 shows thecoverage rate of the nf_dice function comparedwith the Dice coefficient.
As it shows, in theoutputs ranked by the Dice coefficient, usesusually have to look up more than 3 sentences tofind an acceptable translation; while in the outputsranked by the nf_dice function, users can find anacceptable translation in top-2 sentences.59dice nf_dicetop-1 0.42  0.92top-2 0.75  1.00top-3 0.92  1.00Table 3.
Evaluation of the ranking criteria.4 Conclusion and Future WorksIn this paper, we proposed a bilingualconcordancer, DOMCAT, designed as a domain-specific computer assisted translation tool.
Weexploited a normalized correlation whichincorporate lexical level information intoassociation-based method that effectively avoid thedrawbacks of the word alignment-based translationspotting as well as the association-based translationspotting.In the future, it would be interesting to extendthe parallel corpus to the internet to retrieve morerich data for the computer assisted translation.ReferencesBai, Ming-Hong, Jia-Ming You, Keh-Jiann Chen, JasonS.
Chang.
2009.
Acquiring Translation Equivalencesof Multiword Expressions by Normalized CorrelationFrequencies.
In Proceedings of EMNLP, pages 478-486.Bird, Steven and Edward Loper.
2004.
NLTK: TheNatural Language Toolkit.
In Proceedings of ACL,pages 214-217.Bourdaillet, Julien, St?phane Huet, Philippe Langlaisand Guy Lapalme.
2010.
TRANSSEARCH: from abilingual concordancer to a translation finder.Machine Translation, 24(3-4): 241?271.Bowker, Lynne, Michael Barlow.
2004.
Bilingualconcordancers and translation memories: Acomparative evaluation.
In Proceedings of theSecond International Workshop on LanguageResources for Translation Work, Research andTraining , pages.
52-61.Brown, Peter F., Stephen A. Della Pietra, Vincent J.Della Pietra, Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation:Parameter Estimation.
Computational Linguistics,19(2):263-311.Callison-Burch, Chris, Colin Bannard and JoshSchroeder.
2005.
A Compact Data Structure forSearchable Translation Memories.
In Proceedings ofEAMT.Gao, Zhao-Ming.
2011.
Exploring the effects and use ofa Chinese?English parallel concordancer.
Computer-Assisted Language Learning 24.3 (July 2011): 255-275.Jian, Jia-Yan, Yu-Chia Chang and Jason S. Chang.
2004.TANGO: Bilingual Collocational Concordancer.
InProceedings of ACL, pages 166-169.Kitamura, Mihoko and Yuji Matsumoto.
1996.Automatic Extraction of Word SequenceCorrespondences in Parallel Corpora.
In Proceedingsof WVLC-4 pages 79-87.Kupiec, Julian.
1993.
An Algorithm for Finding NounPhrase Correspondences in Bilingual Corpora.
InProceedings of ACL, pages 17-22.Liang, Percy, Ben Taskar, Dan Klein.
2006.
Alignmentby Agreement.
In Proceedings of HLT-NAACL 2006,pages 104-111, New York, USA.Ma, Wei-Yun and Keh-Jiann Chen.
2003.
Introductionto CKIP Chinese word segmentation system for thefirst international Chinese word segmentationbakeoff.
In Proceedings of the second SIGHANworkshop on Chinese language processing, pages168-171.Ma, Xiaoyi.
2006.
Champollion: A Robust Parallel TextSentence Aligner.
In Proceedings of the FifthInternational Conference on Language Resourcesand Evaluation.Melamed, Ilya Dan.
2001.
Empirical Methods forExploiting parallel Texts.
MIT press.Moore, Robert C. 2004.
Improving IBM Word-Alignment Model 1.
In Proceedings of ACL, pages519-526, Barcelona, Spain.Och, Franz J., Hermann Ney., 2000, ImprovedStatistical Alignment Models, In Proceedings of ACL,pages 440-447.
Hong Kong.Smadja, Frank, Kathleen R. McKeown, and VasileiosHatzivassiloglou.
1996.
Translating Collocations forBilingual Lexicons: A Statistical Approach.Computational Linguistics, 22(1):1-38.Wu, Jian-Cheng, Kevin C. Yeh, Thomas C. Chuang,Wen-Chi Shei, Jason S. Chang.
2003.
TotalRecall: ABilingual Concordance for Computer AssistedTranslation and Language Learning.
In Proceedingsof ACL, pages 201-204.Yamamoto, Kaoru, Yuji Matsumoto.
2000.
Acquisitionof Phrase-level Bilingual Correspondence usingDependency Structure.
In Proceedings of COLING,pages 933-939.60
