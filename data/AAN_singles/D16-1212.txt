Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2011?2016,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsCapturing Argument Relationships for Chinese Semantic Role LabelingLei Sha, Tingsong Jiang, Sujian Li, Baobao Chang, Zhifang SuiKey Laboratory of Computational Linguistics, Ministry of EducationSchool of Electronics Engineering and Computer Science, Peking UniversityCollaborative Innovation Center for Language Ability, Xuzhou 221009 Chinashalei, tingsong, lisujian, chbb, szf@pku.edu.cnAbstractIn this paper, we capture the argument rela-tionships for Chinese semantic role labelingtask, and improve the task?s performance withthe help of argument relationships.
We splitthe relationship between two candidate argu-ments into two categories: (1) Compatible ar-guments: if one candidate argument belongsto a given predicate, then the other is morelikely to belong to the same predicate; (2) In-compatible arguments: if one candidate argu-ment belongs to a given predicate, then theother is less likely to belong to the same predi-cate.
However, previous works did not explic-itly model argument relationships.
We use asimple maximum entropy classifier to capturethe two categories of argument relationshipsand test its performance on the Chinese Propo-sition Bank (CPB).
The experiments show thatargument relationships is effective in Chinesesemantic role labeling task.1 IntroductionSemantic Role Labeling (SRL) is defined as the taskto recognize arguments for a given predicate and as-sign semantic role labels to them.
Because of it-s ability to encode semantic information, there hasbeen an increasing interest in SRL on many lan-guages (Gildea and Jurafsky, 2002; Sun and Juraf-sky, 2004).
Figure 1 shows an example in ChineseProposition Bank (CPB) (Xue and Palmer, 2003),which is a Chinese corpus annotated with semanticrole labels.Previous works of Chinese SRL include feature-based approaches and neural network based ap-proaches.
Feature-based approaches often extract alarge number of handcrafted features from the sen-tence, and feed these features to statistical classifierssuch as CRF, MaxEnt and SVM (Sun and Jurafsky,2004; Xue, 2008; Ding and Chang, 2008; Ding andChang, 2009; Sun, 2010).
Neural network basedapproaches usually take Chinese SRL as sequencelabeling task and use bidirectional recurrent neuralnetwork (RNN) with long-short-term memory (LST-M) to solve the problem (Wang et al, 2015).However, both of the above two kinds of ap-proaches identify each candidate argument separate-ly without considering the relationship between ar-guments.
We define two categories of argument re-lationships here: (1) Compatible arguments: if onecandidate argument belongs to a given predicate,then the other is more likely to belong to the samepredicate; (2) Incompatible arguments: if one can-didate argument belongs to a given predicate, thenthe other is less likely to belong to the same pred-icate.
For example, in Figure 1, the word ???
(foreign businessman) and ????
(entrepreneur)tend to be compatible arguments when the predi-cate word is ??]?(invest).
On the other hand, ????
(entrepreneur) and ?5??
(rule) are not likely tobelong to the same predicate ??]?
(invest).In this paper, we propose to use a quadratic opti-mization method to explicitly model the relationshipbetween candidate arguments to improve the perfor-mance of Chinese SRL.
We train a maximum en-tropy classifier, and then use the classifier to predictargument relationships between any two candidatearguments in a sentence.
Experiments show that ar-gument relationships can greatly improve the perfor-mance of Chinese SRL.2011???????????????
?protectforeignbusinessmaninvestentrepreneurlegalprofitsixitemrulePOS:VVNNVVNNJJNNCDMNNSRL:OS-ARG0relS-arg1OOOOOWord:Figure 1: A sentence with semantic roles labeled from CPB.
?rel?
represents the predicate, English translation: ?Six rules to protectforeign businessman?s legal profits when investing entrepreneurs?2 Related WorkSemantic Role Labeling (SRL) task was first pro-posed by Gildea and Jurafsky (2002).
Previous ap-proaches on Chinese SRL can be classified into twocategories: (1) feature-based approaches (2) neuralnetwork based approaches.Among feature-based approaches, Sun and Juraf-sky (2004) did the preliminary work on Chinese SR-L without any large semantically annotated corpusand produced promising results.
Xue and Palmer(2003) proposed Chinese Proposition Bank (CPB),which leads to more complete and systematic re-search on Chinese SRL (Xue and Palmer, 2005;Xue, 2008; Ding and Chang, 2009).
Sun et al(2009) extended the work of Chen et al (2006), per-formed Chinese SRL with shallow parsing, whichtook partial parses as inputs.
Yang and Zong (2014)proposed multi-predicate SRL, which showed im-provements both on English and Chinese Proposi-tion Bank.Neural network based approaches are free ofhandcrafted features, Collobert and Weston (2008)proposed a convolutional neural network for SRL.Their approach achieved competitive performanceon English SRL without requiring task specific fea-ture.
Wang et al (2015) proposed a bidirectionalLSTM-RNN for Chinese SRL.However, most of the aforementioned approachesdid not take the compatible arguments and incom-patible arguments into account.
Inspired by Sha etal.
(2016), our approach model the two argumen-t relationships explicitly to achieve a better perfor-mance on Chinese SRL.3 Capturing the Relationship BetweenArgumentsWe found that there are two typical relationships be-tween candidate arguments: (1) Compatible argu-ments: if one candidate argument belongs to oneevent, then the other is more likely to belong to thesame event; (2) incompatible arguments: if one can-didate argument belongs to one event, then the otheris less likely to belong to the same event.We trained a maximum entropy classifier to pre-dict the relationship between two candidate argu-ments.
We choose the following features:1.
PREDICATE: the predicate in the current sen-tence2.
ARGUMENT DISTANCE: the distance betweenthe two candidate arguments in the sentence3.
Whether the two candidate arguments occur onthe same side of the predicate4.
PARENT DEPENDENCY DISTANCE: the dis-tance between the two candidate arguments?parents in the dependency parse tree5.
PARENT POS: if the two candidate argumentsshare the same parent, take the common paren-t?s POS tag as a feature6.
Whether the two candidate arguments occur onthe same side of the common parent if the twocandidate arguments share the same parentAll the words in one sentence except for the predi-cate are candidate arguments.
The word pairs in theground truth Chinese SRL annotation (training data)are extracted as training data.
The training examplesare generated as follows: For an candidate argumentpair, if both of them are labeled as semantic roles,we take it as positive example.
For each positive ex-ample, we randomly exchange one of the argumentswith an irrelevant argument1 to get a negative exam-ple.1an irrelevant argument is in the same sentence with thepredicate, but it is not labeled as semantic role2012Sentence:     ??
??
??
??
??
...Protect Foreignbusinessman invest Entrepreneur legalPredicate givenBidirectional LSTM-RNNOutput: 1L 2L 3L 4LFigure 2: The bidirectional LSTM-RNN architecture.The chinese sentences should be segmented tochinese words first.
For a sentence with n+1 word-s, we denote C ?
Rn?n as the argument relation-ship matrix.
In the testing procedure, the maximumentropy classifier is used to predict the relationshipbetween argument i and argument j as Cij .When the output of the maximum entropy clas-sifier is around 0.5, it is not easy to figure outwhether it is the first relationship or the second,we call this kind of information ?uncertain infor-mation?
(unclear relationship).
For a better perfor-mance, we strengthen the certain information andweaken the uncertain information.
We transform theresult of maximum entropy classifier as follows:C(i, j) =??
?1 0.8 < MaxEnt(i, j) ?
1.00 0.2 ?MaxEnt(i, j) ?
0.8?1 0.0 ?MaxEnt(i, j) < 0.2(1)We set two thresholds, if the output of the maximumentropy classifier is larger than 0.8, we set Ci,j = 1(compatible arguments), if the output is lower than0.2, we set Ci,j = ?1 (incompatible arguments),otherwise, we set Ci,j = 0 (unclear relationship).The threshold 0.8 and 0.2 are tuned by developmentset.4 Quadratic Optimization Method (QOM)4.1 Post-processing Module of BidirectionalLSTM-RNNOur quadratic optimization method is a post-processing module of bidirectional LSTM-RNN(Wang et al, 2015).
The simplified ar-chitecture of bidirectional LSTM-RNN is shown asFigure 2.Each dimension of the output vector Li ?RnL , i = 1 ?
?
?n corresponds to the score of a cer-tain semantic role label.
nL represents the numberof semantic role labels.
Then we normalize Li oversemantic roles as Eq 2 shows.L?i = Normalize(Li) (2)Each dimension of L?i represents the probability of acertain semantic role label.Let PArg ?
Rn be a probability vector, each di-mension of which represents the probability that thecurrent word has a semantic role as is shown in Eq 3.PRole ?
Rn is another probability vector, each di-mension represents the probability of the most likelysemantic role the current word may be labeled as isshown in Eq 4.PArg(i) =?jL?i(j)[label(j) 6= ?0?]
(3)PRole(i) = maxj L?i(j) (4)where [?]
equals to 1 if the inner statement is true and0 otherwise.
label(j) 6= ?0?
means the j-th word isnot labeled with semantic role.4.2 Quadratic OptimizationWe use a n-dim vector X to represent the identifica-tion result of candidate arguments.
Each entry of Xis 0 or 1, 0 represents ?noArg?, 1 represents ?arg?.X can be assigned by maximizing E(X) as definedby Eq 5.X = argmaxXE(X)E(X) = ?1XTCX + ?2XTParg+ (1?
?1 ?
?2)XTProle(5)Here, XTCX means to add up all the relationshipvalue if the two arguments are identified.
Hence, themore the identified arguments are related, the largerthe value XTCX is.
XTParg is the sum of all cho-sen arguments probability.
XTProle is the sum of allthe classified roles?
probability.Eq 5 means that, while we should select the se-mantic role with a larger probability, the argumentrelationship evaluation should also as large as possi-ble.2013We use Beam Search method (Algorithm 1) tosearch for the optimal assignment X .
The hyper-parameters ?1 and ?2 can be chosen according todevelopment set.Input: Argument relationship matrix: Cthe argument probabilities required by P argsumthe role probabilities required by P rolesumData: K: Beam sizen: Number of candidate argumentsOutput: The best assignment XSet beam B ?
[] ;for i?
1 ?
?
?n dobuf?
{z?
?
l|z?
?
B, l ?
{0, 1}};B ?
[] ;while j ?
1 ?
?
?K doxbest = argmaxx?buf E(x);B ?
B ?
{xbest};buf?buf?
{xbest};endendSort B descendingly according to E(X);return B[0];Algorithm 1: Beam Search decoding algorithmfor SRL.
?
means to concatenate an element tothe end of a vector.5 ExperimentWe conduct experiments to compare our modelwith previous landmark methods on the benchmarkdataset CPB for Chinese SRL.
We use Wang et al(2015)?s model as baseline.
The result reveals thatour quadratic optimization method can further im-prove the result of bidirectional LSTM-RNN.5.1 Experiment SettingsWe conduct experiments on the standard benchmarkdataset CPB 1.02.
We follow the same data set-ting as previous work (Xue, 2008; Sun et al, 2009),which divided the dataset into three parts: 648files (from chtb 081.fid to chtb 899.fid)are used as the training set.
The developmen-t set includes 40 files, from chtb 041.fid tochtb 080.fid.
The test set includes 72 files,2https://catalog.ldc.upenn.edu/LDC2005T23Method F1(%)Xue (2008) 71.90Collobert and Weston (2008) 74.05Sun et al (2009) 74.12Yang and Zong (2014) 75.31Wang et al (2015) 77.21QOM - stengthen 76.24QOM - feature 4,5,6 77.52QOM 77.69Table 1: Results comparison on CPB dataset.which are chtb 001.fid to chtb 040.fid,and chtb 900.fid to chtb 931.fid.The training dataset of the argument relation-ship matrix contains 1.6M cases (736K positive and864K negative) which are randomly generated ac-cording to the ground truth in the training docu-ments.
We use Stanford Parser3 for dependencyparsing.We tuned the coefficients ?1 and ?2 of Eq 5 on thedevelopment set, and finally we set ?1 = 0.10 and?2 = 0.45.5.2 Chinese SRL PerformanceTable 1 shows our SRL performance comparedto previous landmark results.
We can see thatwith quadratic optimization method as the post-processing module, our approach (QOM) outper-forms Wang et al (2015) by a large margin (Wilcox-on Signed Rank Test, p < 0.05).
We also did someablation test, in Table 1, ?QOM - stengthen?
is theresult when we do not strengthen the argument re-lationship matrix.
We can see that the uncertain in-formation is very harmful to the performance, whichworsen the accuracy for about 1%.
?QOM - feature4,5,6?
is the performance when we do not use thedependency features when capturing the argumentrelationships since Wang et al (2015) didn?t use anydependency feature.
We can see that event withoutdependency feature, our method still can outperformWang et al (2015)?s result.Figure 3 visualizes the candidate argument re-lationship matrix.
From this graph, we capturedthe compatible arguments (?
?foreign businessman?and ??
?entrepreneur?
), incompatible arguments(??item?
and ?
?foreign businessman?
), (?5?rule?3http://nlp.stanford.edu/software/lex-parser.shtml2014Chinese o 	?
??
?
{ ?
8 ?
5?English translation protect foreign businessman entrepreneur legal profit six item ruleFigure 3: The Visualization of argument relationship Matrix, Left is the origin matrix.
Right is the strengthened matrix.
In theorigin matrix, we can directly see the argument relationship we captured (the darker green means stronger relationship, lightergreen means weaker relationship).
After strengthening, on the right, the words with strong relationship are classified as compatiblearguments (the black squares), weak relationship are classified as incompatible arguments (the white squares).
Others (the greysquares) are unclear relationship.and ?
?foreign businessman?).
Therefore, ?
?foreign businessman?
and ???entrepreneur?
should bethe roles of ??]invest?
simultaneously , (??item?,?
?foreign businessman?)
and (?5 ?rule?, ?
?foreign businessman?)
should not be the roles of ??]invest?
simultaneously.6 ConclusionIn this paper, we propose to use a quadratic opti-mization method based on two kinds of argumen-t relationships to improve the performance of Chi-nese SRL.
We first train a maximum entropy clas-sifier to capture the compatible arguments and in-compatible arguments.
Then we use quadratic op-timization to improve the result of bidirectionalLSTM-RNN(Wang et al, 2015).
The experimen-t has proved the effectiveness of our approach.
Thismethod can also be used in other probabilistic meth-ods.AcknowledgementsWe would like to thank our three anonymous re-viewers for their helpful advice on various as-pects of this work.
This research was sup-ported by the National Key Basic ResearchProgram of China (No.2014CB340504) and theNational Natural Science Foundation of China(No.61375074,61273318).
The contact author forthis paper is Baobao Chang and Zhifang Sui.ReferencesWenliang Chen, Yujie Zhang, and Hitoshi Isahara.
2006.An empirical study of chinese chunking.
In Proceed-ings of the COLING/ACL on Main conference postersessions, pages 97?104.
Association for Computation-al Linguistics.Ronan Collobert and Jason Weston.
2008.
A unified ar-chitecture for natural language processing: Deep neu-ral networks with multitask learning.
In Proceedingsof the 25th international conference onMachine learn-ing, pages 160?167.
ACM.Weiwei Ding and Baobao Chang.
2008.
Improving chi-nese semantic role classification with hierarchical fea-ture selection strategy.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 324?333.
Association for Computation-al Linguistics.Weiwei Ding and Baobao Chang.
2009.
Word basedchinese semantic role labeling with semantic chunk-ing.
International Journal of Computer Processing OfLanguages, 22(02n03):133?154.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic la-beling of semantic roles.
Computational linguistics,28(3):245?288.Lei Sha, Jing Liu, Chin-Yew Lin, Sujian Li, BaobaoChang, and Zhifang Sui.
2016.
Rbpb: Regularization-based pattern balancing method for event extraction.2015In Proceedings of the 54th Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 1224?1234, Berlin, Germany,August.
Association for Computational Linguistics.Honglin Sun and Daniel Jurafsky.
2004.
Shallow seman-tic parsing of chinese.
In Proceedings of NAACL-HLT,volume 2004.Weiwei Sun, Zhifang Sui, Meng Wang, and Xin Wang.2009.
Chinese semantic role labeling with shallowparsing.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing:Volume 3-Volume 3, pages 1475?1483.
Association forComputational Linguistics.Weiwei Sun.
2010.
Improving chinese semantic role la-beling with rich syntactic features.
In Proceedings ofthe ACL 2010 Conference Short Papers, pages 168?172.
Association for Computational Linguistics.Zhen Wang, Tingsong Jiang, Baobao Chang, and Zhi-fang Sui.
2015.
Chinese semantic role labeling withbidirectional recurrent neural networks.
In Proc.
ofthe 2015 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 1626?1631.Nianwen Xue and Martha Palmer.
2003.
Annotating thepropositions in the penn chinese treebank.
In Proceed-ings of the second SIGHAN workshop on Chinese lan-guage processing-Volume 17, pages 47?54.
Associa-tion for Computational Linguistics.Nianwen Xue and Martha Palmer.
2005.
Automatic se-mantic role labeling for chinese verbs.
In IJCAI, vol-ume 5, pages 1160?1165.
Citeseer.Nianwen Xue.
2008.
Labeling chinese predicates withsemantic roles.
Computational linguistics, 34(2):225?255.Haitong Yang and Chengqing Zong.
2014.
Multi-predicate semantic role labeling.
In EMNLP, pages363?373.2016
