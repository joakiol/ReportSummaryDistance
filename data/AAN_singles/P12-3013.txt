Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 73?78,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsBIUTEE: A Modular Open-Source System for Recognizing TextualEntailmentAsher SternComputer Science DepartmentBar-Ilan UniversityRamat-Gan 52900, Israelastern7@gmail.comIdo DaganComputer Science DepartmentBar-Ilan UniversityRamat-Gan 52900, Israeldagan@cs.biu.ac.ilAbstractThis paper introduces BIUTEE1, an open-source system for recognizing textual entail-ment.
Its main advantages are its ability to uti-lize various types of knowledge resources, andits extensibility by which new knowledge re-sources and inference components can be eas-ily integrated.
These abilities make BIUTEEan appealing RTE system for two researchcommunities: (1) researchers of end applica-tions, that can benefit from generic textual in-ference, and (2) RTE researchers, who can in-tegrate their novel algorithms and knowledgeresources into our system, saving the time andeffort of developing a complete RTE systemfrom scratch.
Notable assistance for these re-searchers is provided by a visual tracing tool,by which researchers can refine and ?debug?their knowledge resources and inference com-ponents.1 IntroductionRecognizing Textual Entailment (RTE) is the task ofidentifying, given two text fragments, whether oneof them can be inferred from the other (Dagan et al,2006).
This task generalizes a common problem thatarises in many tasks at the semantic level of NLP.For example, in Information Extraction (IE), a sys-tem may be given a template with variables (e.g., ?Xis employed by Y?)
and has to find text fragmentsfrom which this template, with variables replacedby proper entities, can be inferred.
In Summariza-tion, a good summary should be inferred from the1www.cs.biu.ac.il/?nlp/downloads/biuteegiven text, and, in addition, should not contain du-plicated information, i.e., sentences which can be in-ferred from other sentences in the summary.
Detect-ing these inferences can be performed by an RTEsystem.Since first introduced, several approaches havebeen proposed for this task, ranging from shallowlexical similarity methods (e.g., (Clark and Har-rison, 2010; MacKinlay and Baldwin, 2009)), tocomplex linguistically-motivated methods, whichincorporate extensive linguistic analysis (syntacticparsing, coreference resolution, semantic role la-belling, etc.)
and a rich inventory of linguistic andworld-knowledge resources (e.g., (Iftene, 2008; deSalvo Braz et al, 2005; Bar-Haim et al, 2007)).Building such complex systems requires substantialdevelopment efforts, which might become a barrierfor new-comers to RTE research.
Thus, flexible andextensible publicly available RTE systems are ex-pected to significantly facilitate research in this field.More concretely, two major research communitieswould benefit from a publicly available RTE system:1.
Higher-level application developers, whowould use an RTE system to solve inferencetasks in their application.
RTE systems forthis type of researchers should be adaptablefor the application specific data: they shouldbe configurable, trainable, and extensiblewith inference knowledge that capturesapplication-specific phenomena.2.
Researchers in the RTE community, that wouldnot need to build a complete RTE system fortheir research.
Rather, they may integrate73their novel research components into an ex-isting open-source system.
Such research ef-forts might include developing knowledge re-sources, developing inference components forspecific phenomena such as temporal infer-ence, or extending RTE to different languages.A flexible and extensible RTE system is ex-pected to encourage researchers to create andshare their textual-inference components.
Agood example from another research area is theMoses system for Statistical Machine Transla-tion (SMT) (Koehn et al, 2007), which pro-vides the core SMT components while beingextended with new research components by alarge scientific community.Yet, until now rather few and quite limited RTEsystems were made publicly available.
Moreover,these systems are restricted in the types of knowl-edge resources which they can utilize, and in thescope of their inference algorithms.
For example,EDITS2 (Kouylekov and Negri, 2010) is a distance-based RTE system, which can exploit only lexicalknowledge resources.
NutCracker3 (Bos and Mark-ert, 2005) is a system based on logical represen-tation and automatic theorem proving, but utilizesonly WordNet (Fellbaum, 1998) as a lexical knowl-edge resource.Therefore, we provide our open-source textual-entailment system, BIUTEE.
Our system providesstate-of-the-art linguistic analysis tools and exploitsvarious types of manually built and automaticallyacquired knowledge resources, including lexical,lexical-syntactic and syntactic rewrite rules.
Fur-thermore, the system components, including pre-processing utilities, knowledge resources, and eventhe steps of the inference algorithm, are modu-lar, and can be replaced or extended easily withnew components.
Extensibility and flexibility arealso supported by a plug-in mechanism, by whichnew inference components can be integrated with-out changing existing code.Notable support for researchers is provided by avisual tracing tool, Tracer, which visualizes everystep of the inference process as shown in Figures 22http://edits.fbk.eu/3http://svn.ask.it.usyd.edu.au/trac/candc/wiki/nutcrackerand 3.
We will use this tool to illustrate various in-ference components in the demonstration session.2 System Description2.1 Inference algorithmIn this section we provide a high level description ofthe inference components.
Further details of the al-gorithmic components appear in references providedthroughout this section.BIUTEE follows the transformation basedparadigm, which recognizes textual entailmentby converting the text into the hypothesis via asequence of transformations.
Such a sequence isoften referred to as a proof, and is performed, in oursystem, over the syntactic representation of the text- the text?s parse tree(s).
A transformation modifiesa given parse tree, resulting in a generation of anew parse tree, which can be further modified bysubsequent transformations.Consider, for example, the following text-hypothesis pair:Text: ... Obasanjo invited him to step down as president... and accept political asylum in Nigeria.Hypothesis: Charles G. Taylor was offered asylum inNigeria.This text-hypothesis pair requires two majortransformations: (1) substituting ?him?
by ?CharlesG.
Taylor?
via a coreference substitution to an ear-lier mention in the text, and (2) inferring that if ?Xaccept Y?
then ?X was offered Y?.BIUTEE allows many types of transformations,by which any hypothesis can be proven from anytext.
Given a T-H pair, the system finds a proofwhich generates H from T, and estimates the proofvalidity.
The system returns a score which indicateshow likely it is that the obtained proof is valid, i.e.,the transformations along the proof preserve entail-ment from the meaning of T.The main type of transformations is application ofentailment-rules (Bar-Haim et al, 2007).
An entail-ment rule is composed of two sub-trees, termed left-hand-side and right-hand-side, and is applied on aparse-tree fragment that matches its left-hand-side,by substituting the left-hand-side with the right-hand-side.
This formalism is simple yet power-ful, and captures many types of knowledge.
Thesimplest type of rules is lexical rules, like car ?74vehicle.
More complicated rules capture the en-tailment relation between predicate-argument struc-tures, like X accept Y ?
X was offeredY.
Entailment rules can also encode syntacticphenomena like the semantic equivalence of ac-tive and passive structures (X Verb[active]Y ?
Y is Verb[passive] by X).
Variousknowledge resources, represented as entailmentrules, are freely available in BIUTEE?s web-site.
Thecomplete formalism of entailment rules, adopted byour system, is described in (Bar-Haim et al, 2007).Coreference relations are utilized via coreference-substitution transformations: one mention of an en-tity is replaced by another mention of the same en-tity, based on coreference relations.
In the above ex-ample the system could apply such a transformationto substitute ?him?
with ?Charles G. Taylor?.Since applications of entailment rules and coref-erence substitutions are yet, in most cases, insuffi-cient in transforming T into H, our system allowson-the-fly transformations.
These transformationsinclude insertions of missing nodes, flipping parts-of-speech, moving sub-trees, etc.
(see (Stern andDagan, 2011) for a complete list of these transforma-tions).
Since these transformations are not justifiedby given knowledge resources, we use linguistically-motivated features to estimate their validity.
For ex-ample, for on-the-fly lexical insertions we consideras features the named-entity annotation of the in-serted word, and its probability estimation accordingto a unigram language model, which yields lowercosts for more frequent words.Given a (T,H) pair, the system applies a searchalgorithm (Stern et al, 2012) to find a proof O =(o1, o2, .
.
.
on) that transforms T into H. For eachproof step oi the system calculates a cost c(oi).
Thiscost is defined as follows: the system uses a weight-vector w, which is learned in the training phase.
Inaddition, each transformation oi is represented by afeature vector f(oi) which characterizes the trans-formation.
The cost c(oi) is defined as w ?
f(oi).The proof cost is defined as the sum of the costs ofthe transformations from which it is composed, i.e.
:c(O) ,n?i=1c(oi) =n?i=1w ?
f(oi) = w ?n?i=1f(oi)(1)If the proof cost is below a threshold b, then the sys-tem concludes that T entails H. The complete de-scription of the cost model, as well as the methodfor learning the parameters w and b is described in(Stern and Dagan, 2011).2.2 System flowThe BIUTEE system flow (Figure 1) starts with pre-processing of the text and the hypothesis.
BIUTEEprovides state-of-the-art pre-processing utilities:Easy-First parser (Goldberg and Elhadad, 2010),Stanford named-entity-recognizer (Finkel et al,2005) and ArkRef coreference resolver (Haghighiand Klein, 2009), as well as utilities for sentence-splitting and numerical-normalizations.
In addition,BIUTEE supports integration of users?
own utilitiesby simply implementing the appropriate interfaces.Entailment recognition begins with a global pro-cessing phase in which inference related computa-tions that are not part of the proof are performed.Annotating the negation indicators and their scopein the text and hypothesis is an example of such cal-culation.
Next, the system constructs a proof whichis a sequence of transformations that transform thetext into the hypothesis.
Finding such a proof is asequential process, conducted by the search algo-rithm.
In each step of the proof construction the sys-tem examines all possible transformations that canbe applied, generates new trees by applying selectedtransformations, and calculates their costs by con-structing appropriate feature-vectors for them.New types of transformations can be added toBIUTEE by a plug-in mechanism, without the needto change the code.
For example, imagine that aresearcher applies BIUTEE on the medical domain.There might be some well-known domain knowl-edge and rules that every medical person knows.Integrating them is directly supported by the plug-inmechanism.
A plug-in is a piece of code which im-plements a few interfaces that detect which transfor-mations can be applied, apply them, and constructappropriate feature-vectors for each applied trans-formation.
In addition, a plug-in can perform com-putations for the global processing phase.Eventually, the search algorithm finds a (approx-imately) lowest cost proof.
This cost is normalizedas a score between 0 and 1, and returned as output.Training the cost model parameters w and b(see subsection 2.1) is performed by a linear learn-75Figure 1: System architectureRTEchallengeMedian Best BIUTEERTE-6 33.72 48.01 49.09RTE-7 39.89 48.00 42.93Table 1: Performance (F1) of BIUTEE on RTE chal-lenges, compared to other systems participated in thesechallenges.
Median and Best indicate the median scoreand the highest score of all submissions, respectively.ing algorithm, as described in (Stern and Dagan,2011).
We use a Logistic-Regression learning algo-rithm, but, similar to other components, alternativelearning-algorithms can be integrated easily by im-plementing an appropriate interface.2.3 Experimental resultsBIUTEE?s performance on the last two RTE chal-lenges (Bentivogli et al, 2011; Bentivogli et al,2010) is presented in Table 1: BIUTEE is better thanthe median of all submitted results, and in RTE-6 itoutperforms all other systems.3 Visual Tracing ToolAs a complex system, the final score provided asoutput, as well as the system?s detailed logging in-formation, do not expose all the decisions and cal-culations performed by the system.
In particular,they do not show all the potential transformationsthat could have been applied, but were rejected bythe search algorithm.
However, such information iscrucial for researchers, who need to observe the us-age and the potential impact of each component ofthe system.We address this need by providing an interactivevisual tracing tool, Tracer, which presents detailedinformation on each proof step, including potentialsteps that were not included in the final proof.
In thedemo session, we will use the visual tracing tool toillustrate all of BIUTEE?s components4.3.1 ModesTracer provides two modes for tracing proof con-struction: automatic mode and manual mode.
In au-tomatic mode, shown in Figure 2, the tool presentsthe complete process of inference, as conducted bythe system?s search: the parse trees, the proof steps,the cost of each step and the final score.
For eachtransformation the tool presents the parse tree beforeand after applying the transformation, highlightingthe impact of this transformation.
In manual mode,the user can invoke specific transformations pro-actively, including transformations rejected by thesearch algorithm for the eventual proof.
As shown inFigure 3, the tool provides a list of transformationsthat match the given parse-tree, from which the userchooses and applies a single transformation at eachstep.
Similar to automatic mode, their impact on theparse tree is shown visually.3.2 Use casesDevelopers of knowledge resources, as well as othertypes of transformations, can be aided by Tracer asfollows.
Applying an entailment rule is a processof first matching the rule?s left-hand-side to the textparse-tree (or to any tree along the proof), and thensubstituting it by the rule?s right-hand-side.
To test a4Our demonstration requirements are a large screen and In-ternet connection.76Figure 2: Entailment Rule application visualized in tracing tool.
The upper pane displays the parse-tree generated byapplying the rule.
The rule description is the first transformation (printed in bold) of the proof, shown in the lowerpane.
It is followed by transformations 2 and 3, which are syntactic rewrite rules.rule, the user can provide a text for which it is sup-posed to match, examine the list of potential trans-formations that can be performed on the text?s parsetree, as in Figure 3, and verify that the examinedrule has been matched as expected.
Next, the usercan apply the rule, visually examine its impact onthe parse-tree, as in Figure 2, and validate that it op-erates as intended with no side-effects.The complete inference process depends on theparameters learned in the training phase, as well ason the search algorithm which looks for lowest-costproof from T to H. Researchers investigating thesealgorithmic components can be assisted by the trac-ing tool as well.
For a given (T,H) pair, the auto-matic mode provides the complete proof found bythe system.
Then, in the manual mode the researchercan try to construct alternative proofs.
If a proofwith lower cost can be constructed manually it im-plies a limitation of the search algorithm.
On theother hand, if the user can manually construct a bet-ter linguistically motivated proof, but it turns out thatthis proof has higher cost than the one found by thesystem, it implies a limitation of the learning phasewhich may be caused either by a limitation of thelearning method, or due to insufficient training data.4 ConclusionsIn this paper we described BIUTEE, an open-sourcetextual-inference system, and suggested it as a re-search platform in this field.
We highlighted keyadvantages of BIUTEE, which directly support re-searchers?
work: (a) modularity and extensibility,(b) a plug-in mechanism, (c) utilization of entail-ment rules, which can capture diverse types ofknowledge, and (d) a visual tracing tool, which vi-sualizes all the details of the inference process.AcknowledgmentsThis work was partially supported by the IsraelScience Foundation grant 1112/08, the PASCAL-77Figure 3: List of available transformations, provided by Tracer in the manual mode.
The user can manually chooseand apply each of these transformations, and observe their impact on the parse-tree.2 Network of Excellence of the European Com-munity FP7-ICT-2007-1-216886, and the Euro-pean Community?s Seventh Framework Programme(FP7/2007-2013) under grant agreement no.
287923(EXCITEMENT).ReferencesRoy Bar-Haim, Ido Dagan, Iddo Greental, and EyalShnarch.
2007.
Semantic inference at the lexical-syntactic level.
In Proceedings of AAAI.Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, andDanilo Giampiccolo.
2010.
The sixth pascal recog-nizing textual entailment challenge.
In Proceedings ofTAC.Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, andDanilo Giampiccolo.
2011.
The seventh pascal recog-nizing textual entailment challenge.
In Proceedings ofTAC.Johan Bos and Katja Markert.
2005.
Recognising textualentailment with logical inference.
In Proceedings ofEMNLP.Peter Clark and Phil Harrison.
2010.
Blue-lite: aknowledge-based lexical entailment system for rte6.In Proceedings of TAC.Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.
The pascal recognising textual entailment chal-lenge.
In Quionero-Candela, J.; Dagan, I.; Magnini,B.
; d?Alch-Buc, F.
(Eds.)
Machine Learning Chal-lenges.
Lecture Notes in Computer Science.Rodrigo de Salvo Braz, Roxana Girju, Vasin Pun-yakanok, Dan Roth, and Mark Sammons.
2005.
Aninference model for semantic entailment in natural lan-guage.
In Proceedings of AAAI.Christiane Fellbaum, editor.
1998.
WordNet An Elec-tronic Lexical Database.
The MIT Press, May.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In Proceedings of ACL.Yoav Goldberg and Michael Elhadad.
2010.
An effi-cient algorithm for easy-first non-directional depen-dency parsing.
In Proceedings of NAACL.Aria Haghighi and Dan Klein.
2009.
Simple coreferenceresolution with rich syntactic and semantic features.
InProceedings of EMNLP.Adrian Iftene.
2008.
Uaic participation at rte4.
In Pro-ceedings of TAC.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL.Milen Kouylekov and Matteo Negri.
2010.
An open-source package for recognizing textual entailment.
InProceedings of ACL Demo.Andrew MacKinlay and Timothy Baldwin.
2009.
Abaseline approach to the rte5 search pilot.
In Proceed-ings of TAC.Asher Stern and Ido Dagan.
2011.
A confidence modelfor syntactically-motivated entailment proofs.
In Pro-ceedings of RANLP.Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner.2012.
Efficient search for transformation-based infer-ence.
In Proceedings of ACL.78
