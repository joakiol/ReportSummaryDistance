An Empirical Investigation of Proposals in CollaborativeDialoguesBarbara  D i  Eugen io  Pamela  W.  Jo rdanJohanna D.  Moore  R ichmond H.  ThomasonLearn ing  Research  & Deve lopment  Center ,  and  Intel l igent Sys tems ProgramUnivers i ty  of  P i t t sburghP i t t sburgh ,  PA 15260, USA{dieugeni, jordan, jmoore, thomason}@isp, pitt.
eduAbst ractWe describe a corpus-based investigation of propos-als in dialogue.
First, we describe our DR/compliantcoding scheme and report our inter-coder reliabilityresults.
Next, we test several hypotheses about whatconstitutes a well-formed proposal.1 In t roduct ionOur project's long-range goal (see http://www.isp.pitt .edu/' intgen/) is to create a unified architecturefor collaborative discourse, accommodating both in-terpretation and generation.
Our computational p-proach (Thomason and Hobbs, 1997) uses a formof weighted abduction as the reasoning mechanism(Hobbs et al, 1993) and modal operators to modelcontext.
In this paper, we describe the corpus studyportion of our project, which is an integral partof our investigation i to recognizing how conversa-tional participants coordinate agreement.
From ourfirst annotation trials, we found that the recogni-tion of "classical" speech acts (Austin, 1962; Searle,1975) by coders is fairly reliable, while recognizingcontextual relationships (e.g., whether an utteranceaccepts a proposal) is not as reliable.
Thus, we ex-plore other features that can help us recognize howparticipants coordinate agreement.Our corpus study also provides a preliminary as-sessment of the Discourse Resource Initiative (DR/)tagging scheme.
The DRI is an international "grass-roots" effort that seeks to share corpora that havebeen tagged with the core features of interest tothe discourse community.
In order to use the corescheme, it is anticipated that each group will need torefine it for their particular purposes.
A usable draftcore scheme is now available for experimentation (seehttp://www.georgetown.edu/luperfoy/Discourse-Treebank/dri-home.html).
Whereas several groupsare working with the unadapted core DR/ scheme(Core and Allen, 1997; Poesio and Traum, 1997),we have attempted to adapt it to our corpus andparticular esearch questions.First we describe our corpus, and the issue oftracking agreement.
Next we describe our codingscheme and our intercoder reliability outcomes.
Lastwe report our findings .on tracking agreement.2 T rack ing  AgreementOur corpus consists of 24 computer-mediateddialogues 1 in which two participants collaborate ona simple task of buying furniture for the living anddining rooms of a house (a variant of the task in(Walker, 1993)).
The participants' main goal is tonegotiate purchases; the items of highest priority area sofa for the living room and a table and four chairsfor the dining room.
The problem solving task iscomplicated by several secondary goals: 1) Matchcolors within a room, 2) Buy as much furniture asyou can, 3) Spend all your money.
A point systemis used to motivate participants to try to achieve asmany goals as possible.
Each subject has a bud-get and inventory of furniture that lists the quanti-ties, colors, and prices for each available item.
Bysharing this initially private information, the partici-pants can combine budgets and select furniture fromeither's inventory.
The problem is collaborative inthat all decisions have to be consensual; funds areshared and purchasing decisions are joint.In this context, we characterize an agreement asaccepting a partner's uggestion to include a specificfurniture item in the solution.
In this paper we willfocus on the issue of recognizing that a suggestionhas been made (i.e.
a proposal).
The problem is noteasy, since, as speech act theory points out (Austin,1962; Searle, 1975), surface form is not a clear indi-cator of speaker intentions.
Consider excerpt (1): 2(1) A: \[35\]: i have a blue sofa for 300.\[36\]: it's my cheapest one.B: \[37\]: I have 1 sofa for 350\[38\]: that is yellow\[39\]: which is my cheapest,\[40\]: yours sounds good.\[35\] is the first mention of a sofa in the conversa-x Participants work in separate rooms and communicate viathe computer interface.
The interface prevents interruptions.2We broke the dialogues into utterances, partly followingthe algorithm in (Passonneau, 1994).325tion and thus cannot count as a proposal to includeit in the solution.
The sofa A offers for considera-tion, is effectively proposed only after the exchangeof information in \[37\]--\[39\].However, if the dialogue had proceeded as below,\[35'\] would count as a proposal:(2) B: \ [32 ' \ ] :  I have 1 sofa fo r  350\[33'\]: that  is yellow\[34'\]: which is my cheapest.A: \[35'\]: i have a blue sofa for 300.Since context changes the interpretation of \[35\], ourgoal is to adequately characterize the context.
Forthis, we look for guidance from corpus and domainfeatures.
Our working hypothesis is that for bothparticipants context is partly determined by the do-main reasoning situation.
Specifically, if the suitablecourses of action are highly limited, this will makean utterance more likely to be treated as a proposal;this correlation is supported by our corpus analysis,as we will discuss in Section 5.3 Cod ing  SchemeWe will present our coding scheme by first describingthe core DR/ scheme, followed by the adaptationsfor our corpus and research issues.
For details aboutour scheme, see (Di Eugenio et al, 1997); for detailsabout features we added to DR/, but that are notrelevant for this paper, see (Di Eugenio et al, 1998).3.1 The  DRI  Cod ing  SchemeThe aspects of the core DR/scheme that apply toour corpus are a subset of the dimensions underForward- and Backward-Looking Functions.3.1.1 Forward-Look ing  FunctionsThis dimension characterizes the potential effectthat an utterance Ui has on the subsequent dialogue,and roughly corresponds to the classical notion ofan illocutionary act (Austin, 1962; Searle, 1975).
Aseach Ui may simultaneously achieve multiple effects,it can be coded for three different aspects: State-ment, Influence-on-Hearer, Influence-on-Speaker.Statement.
The primary purpose of Statements isto make claims about the world.
Statements are sub-categorized as an Assert when Speaker S is trying tochange Hearer H's beliefs, and as a Reassert if theclaim has already been made in the dialogue.In f luence-on-Hearer  ( I -on-H).
A Ui tagged withthis dimension influences H's future action.
DR/dis-tinguishes between S merely laying out options forH's future action (Open-Option), and S trying to getH to perform a certain action (see Figure 1).
Infe-R?quest includes all actions that request informa-tion, in both explicit and implicit forms.
All otheractions 3are Action-Directives.3Although this may cause future problems (Tuomela,.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i' I s  S discussing potential act ions of  H?
',--Is S ~'-th-g-to get H to d .
.
.
.
.
thing?
: Open-Op.on....... ;;-/ ....... -%.o..o.Is 14 supposed to provide information'?\[ .
.
.
.
3 ( ^otio..Diroo.voFigure 1: Decision Tree for Influence-on-HearerInfluence-on-Speaker ( I -on-S).
A Ui tagged withthis dimension potentially commits S (in varying de-grees of strength) to some future course of action.The only distinction is whether the commitment isconditional on H's agreement (Offer) or not (Com-mit).
With an Offer, S indicates willingness to com-mit to an action if H accepts it.
Commits includepromises and other weaker forms.3.1.2 Backward FunctionsThis dimension indicates whether Ui is unsolicited,or responds to a previous Uj or segment.
4 The tagsof interest for our corpus are:?
Answer:  Ui answers a question.?
Agreement:1.
Ui Accept/Rejects if it indicates S's attitude to-wards a belief or proposal embodied in its an-tecedent.2.
Ui Holds if it leaves the decision about the pro-posal embodied in its antecedent open pendingfurther discussion.3.2 Refinements to Core FeaturesThe core DRI manual often does not operationalizethe tests associated with the different dimensions,such as the two dashed nodes in Figure 1 (the shadednode is an addition that we discuss below).
Thisresulted in strong disagreements regarding ForwardFunctions (but not Backward Functions) during ourinitial trials involving three coders.Statement,  In the current DR/manual ,  the testfor Statement is whether Ui can  be followed by"That's not true.".
For our corpus, only syntacticimperatives or interrogatives were consistently fil-tered out by this purely semantic test.
Thus, werefined it by appealing to syntax, semantics, and do-main knowledge: Ui is a Statement if it is declarative1995), DR I  considers joint actions as decomposable into in-dependent Influence-on-Speaker / Hearer dimensions.4Space constraints prevent discussion of segments.326and it is 1) past; or 2) non past, and contains a sta-tive verb; or 3) non past, and contains a non-stativeverb in which the implied action:?
does not require agreement in the domain;?
or is supplying agreement.For example, We could start in the living room isnot tagged as a statement if meant as a suggestion,i.e.
if it requires agreement.I -on -H  and  I -on-S.
These two dimensions de-pend on the potential action underlying U~ (see theroot node in Figure 1 for I-on-H).
The initial dis-agreements with respect o these functions were dueto the coders not being able to consistently identifysuch actions; thus, we provide a definition for ac-tions in our domain, s and heuristics that correlatetypes of actions with I-on-H/I-on-S.We have two types of potential actions: put fur-niture item X in room Y and remove furniture itemX from room Y.
We subcategorize them as specificand general.
A specific action has all necessary pa-rameters pecified (type, price and color of item, androom).
General actions arise because all necessaryparameters are not set, as in I have a blue sofa ut-tered in a null context.Heur i s t i c  for I -on -H  (the shaded node in Fig-ure 1).
If H's potential action described by Ui isspecific, Ui is tagged as Action-Directive, otherwiseas Open-Option.Heur i s t i c  for I -on-S.  Only a Ui that describes S'sspecific actions is tagged with an 1-on-S tag.Finally, it is hard to offer comprehensive guidancefor the test is S trying to get H to do something?
inFigure 1, but some special cases can be isolated.
Forinstance, when S refers to one action that the partic-ipants could undertake, but in the same turn makesit clear the action is not to be performed, then S isnot trying to get H to do something.
This happens inexcerpt (1) in Section 2.
A specific action (get B's$350 yellow sofa) underlies \[38\], which qualifies asan Action-Directive just like \[35\].
However, becauseof \[40\], it is clear that B is not trying to get A to useB's sofa.
Thus, \[38\] is tagged as an Open-Option.3.3 Cod ing  for p rob lem solv ing featuresIn order to investigate our working hypothesis aboutthe relationship between context and limits on thecourses of action, we coded each utterance for fea-tures of the problem space.
Since we view the prob-lem space as a set of constraint equations, we decidedto code for the variables in these equations and thenumber of possible solutions given all the possibleassignments of values to these variables.The variables of interest for our corpus are the ob-jects of type t in the goal to put an object in a room(e.g.
varsola, vartabte or  varchairs).
For a solution to5Our definition of actions does not apply to Into-Requests,as the latter are easy to recognize.327\[\[ Stat.
\[I-on-H II-on-S H Answer \[Agr.
IIII "831 .72 I .72 II .79 I .54 IITable 1: Kappas for Forward and Backward Func-tionsexist to the set of constraint equations, each varl inthe set of equations must have a solution.
For exam-ple, if 5 instances of sofas are known for varsola, butevery assignment of a value to varsoIa violates thebudget constraint, then varsola and the constraintequations are unsolvable.We characterize the solution size for the problemas determinate if there is one or more solutions andindeterminate otherwise.
It is important o notethat the set of possible values for each vari is notknown at the outset since this information must beexchanged uring the interaction.
If S supplies ap-propriate values for vari but does not know what Hhas available for it then we say that no solution ispossible at this time.
It is also important o pointout that during a dialogue, the solution size for a setof constraint equations may revert from determinateto indeterminate ( .g.
when S asks what else H hasavailable for a vari).4 Analysis of the Coding ResultsTwo coders each coded 482 utterances with theadapted DRI features (44% of our corpus).
Table 1reports values for the Kappa (K) coefficient of agree-ment (Carletta, 1996) for Forward and BackwardFunctions .6The columns in the tables read as follows: if utter-ance Ui has tag X, do coders agree on the subtag?For example, the possible set of values for I-on-Hare: NIL (Ui is not tagged with this dimension),Action-Directive, Open-Option, and Info-Request.The last two columns probe the subtypes of Back-ward Functions: was Ui tagged as an answer to thesame antecedent?
was Ui tagged as accepting, re.jecting, or holding the same antecedent?
TK factors out chance agreement between coders;K=0 means agreement is not different from chance,and K=I  means perfect agreement.
To assess theimport of the values 0 <: K < 1 beyond K's sta-tistical significance (all of our K values are signifi-cant at p=0.000005), the discourse processing com-munity uses Krippendorf's cale (1980) 8, which dis-eFor problem solving features, K for two doubly codeddialogues was > .8.
Since reliability was good and time wasshort, we used one coder for the remaining dialogues.7In general, we consider 2 non-identical antecedents asequivalent if one is a subset of the other, e.g.
if one is anutterance Uj and the other a segment containing Uj.SMore forgiving scales exist but have not yet been dis-cussed by the discourse processing community, e.g.
the onein (Rietveld and van Hour, 1993).II Stat.
I I-on-H I I-on-S II Answer I Agr.
III\] "681 .
71 I N/Sa II .81 I .43 IIaN/S means  not  s igni f icantTable 2: Kappas from (Core and Allen 97)counts any variable with K < .67, and allows tenta-tive conclusions when .67 < K < .8 K, and definiteconclusions when K>.8.
Using this scale, Table 1suggests that Forward Functions and Answer can berecognized far more reliably than Agreement.To assess the DRI effort, clearly more experimentsare needed.
However, we believe our results showthat the goal of an adaptable core coding scheme isreasonable.
We think we achieved good results onForward Functions because, as the DRI enterpriseintended, we adapted the high level definitions toour domain.
However, we have not yet done so forAgreement since our initial trial codings did not re-veal strong disagreements; now given our K results,refinement is clearly needed.
Another possible con-tributing factor for the low K on Agreement is thatthese tags are much rarer than the Forward Func-tion tags.
The highest possible value for K may besmaller for low frequency tags (Grove et al, 1981).Our assessment is supported by comparing our re-sults to those of Core and Allen (1997) who used theunadapted DRI manual - -  see Table 2.
Overall, ourForward Function results are better than theirs (thenon significant K for I-on-S in Table 2 reveals prob-lems with coding for that tag), while the BackwardFunction results are compatible.
Finally, our assess-ment may only hold for task-oriented collaborativedialogues.
One research group tried to use the DRIcore scheme on free-flow conversations, and had toradically modify it in order to achieve reliable coding(Stolcke et al, 1998).5 T rack ing  Propose  and  CommitIt appears we have reached an impasse; if humancoders cannot reliably recognize when two partici-pants achieve agreement, he prospect of automat-ing this process is grim.
Note that this calls intoquestion analyses of agreements based on a singlecoder's tagging effort, e.g.
(Walker, 1996).
We thinkwe can overcome this impasse by exploiting the relia-bility of Forward Functions.
Intuitively, a U~ taggedas Action-Directive + Offer should correlate witha proposal - -  given that all actions in our domainare joint, an Action-Directive tag always co-occurswith either Offer (AD+O) or Commit (AD?C).
Fur-ther, analyzing the antecedents of Commits houldshed light on what was treated as a proposal in thedialogue.
Clearly, we cannot just analyze the an-tecedents of Commit to characterize proposals, as aDet Indet UnknownAD+O 25 7 0Open-Option 2 2 0AD+C 10 2 0Other 4 2 4Table 3: Antecedents of Commitproposal may be discarded for an alternative.To complete our intuitive characterization of aproposal, we will assume that for a Ui to count asa well-formed proposal (WFP), the context must besuch that enough information has already been ex-changed for a decision to be made.
The feature so-lution size represents such a context.
Thus our firsttestable characterization f a WFP is:1.1 Ui counts as a WFP if it is tagged as Action-Directive + Offer and if the associated solutionsize is determinate.To gain some evidence in support of 1.1, wechecked whether the hypothesized WFPs appear asantecedents of Commits?
Of the 32 AD?Os in Ta-ble 3, 25 have determinate solution size; thus, WFPsare the largest class among the antecedents of Com-mit, even if they only account for 43% of such an-tecedents.
Another indirect source of evidence forhypothesis 1.1 arises by exploring the following ques-tions: are there any WFPs that are not committedto?
if yes, how are they dealt with in the dialogue?If hypothesis 1.1 is correct, then we expect hat eachsuch Ui should be responded to in some fashion.
Ina collaborative setting such as ours, a partner can-not just ignore a WFP as if it had not occurred.We found that there are 15 AD+Os with determi-nate solution size in our data that are not commit-ted to.
On closer inspection, it turns out that 9out of these 15 are actually indirectly committed to.Of the remaining 6, four are responded to with acounterproposal (another AD+O with determinatesolution size).
Thus only two are not responded toin any fashion.
Given that these 2 occur in a di-alogue where the participants have a distinctivelynon-collaborative style, it appears hypothesis 1.1 issupported.Going back to the antecedents of Commit (Ta-ble 3), let's now consider the 7 indeterminateAD?Os.
They can be considered as tentative pro-posals that need to be negotiated.
1?
To further re-fine our characterization f proposals, we explore thehypothesis:9Antecedents of Commits are not tagged.
We recon-structed them from either variable tags or when Ui has bothCommit  and Accept tags, the antecedent of the Accept.1?Becanse of our heuristics of tagging specific actions asActionDirectives, these utterances are not Open-Options.3281.2 When the antecedent of a Commit is an AD+Oand indeterminate, the intervening dialoguerenders the solution size determinate.In 6 out of the 7 indeterminate antecedentAD+Os, our hypothesis verified (see excerpt (1),where \[35\] is an AD+ 0 with indeterminate solutionsize, and the antecedent to the Commit in \[40\]).As for the other antecedents of Commit in Table 3,it is not surprising that only 4 Open-Options occurgiven the circumstances in which this tag is used (seeFigure 1).
These Open-Options appear to functionas tentative proposals like indeterminate AD+ Os, asthe dialogue between the Open-Option and the Com-mit develops according to hypothesis 1.2.
We wereinstead surprised that AD+Cs are a very commoncategory among the antecedents of Commit (20%);the second commit appears to simply reconfirm thecommitment expressed by the first (Walker, 1993;Walker, 1996), and does not appear to count as aproposal.
Finally, the Other column is a collectionof miscellaneous antecedents, such as Info-Requestsand cases where the antecedent is unclear, that needfurther analysis.
For further details, see (Di Eugenioet al, 1998).6 Future  WorkFuture work includes, first, further exploring the fac-tors and hypotheses discussed inSection 5.
We char-acterized WFPs as AD+Os with determinate solu-tion size: a study of the features of the dialogue pre-ceding the WFP will highlight how different optionsare introduced and negotiated.
Second, whereas ourcoders were able to reliably identify Forward Func-tions, we do not expect computers to be able to do soas reliably, mainly because humans are able to takeinto account the full previous context.
Thus, we areinterested in finding correlations between ForwardFunctions and "simpler" tags.AcknowledgementsThis material is based on work supported by the Na-tional Science Foundation under Grant No.
IRI-9314961.We wish to thank Liina Pyllk~inen for her contributionsto the coding effort, and past and present project mem-bers Megan Moser and Jerry Hobbs.Re ferencesJohn L. Austin.
1962.
How to Do Things WithWords.
Oxford University Press, Oxford.Jean Carletta.
1996.
Assessing agreement on classi-fication tasks: the kappa statistic.
ComputationalLinguistics, 22(2).Mark G. Core and James Allen.
1997.
Codingdialogues with the DAMSL annotation scheme.AAAI Fall Symposium on Communicative Actionsin Human and Machines, Cambridge MA.Barbara Di Eugenio, Pamela W. Jordan, and Li-ina PylkkLrmn.
1997.
The COCONUT project:Dialogue annotation manual, http://www.isp.pitt.edu/'intgen/research-papers.Barbara Di Eugenio, Pamela W. Jordan, Rich-mond H. Thomason, and Johanna D. Moore.1998.
The Acceptance cycle: An empirical inves-tigation of human-human collaborative dialogues.Submitted for publication.William M. Grove, Nancy C. Andreasen, Pa-tricia McDonald-Scott, Martin B. Keller, andRobert W. Shapiro.
1981.
Reliability studiesof psychiatric diagnosis, theory and practice.Archives General Psychiatry, 38:408-413.Jerry Hobbs, Mark Stickel, Douglas Appelt, andPaul Martin.
1993.
Interpretation asabduction.Artificial Intelligence, 63(1-2):69-142.Klaus Krippendorff.
1980.
Content Analysis: an In-troduction to its Methodology.
Beverly Hills: SagePublications.Rebecca J. Passonneau.
1994.
Protocol for codingdiscourse referential noun phrases and their an-tecedents.
Technical report, Columbia University.Massimo Poesio and David Traum.
1997.
Rep-resenting conversation acts in a unified seman-tic/pragmatic framework.
AAAI Fall Symposiumon Communicative Actions in Human and Ma-chines, Cambridge MA.T.
Rietveld and R. van Hout.
1993.
Statistical Tech-niques .for the Study of Language and LanguageBehaviour.
Mouton de Gruyter.John R. Searle.
1975.
Indirect Speech Acts.
InP.
Cole and J.L.
Morgan, editors, Syntax and Se-mantics 3.
Speech Acts.
Academic Press.A.
Stolcke, E. Shriberg, R. Bates, N. Coccaro, D. Ju-rafsky, R. Martin, M. Meteer, K. Ries, P. Taylor,and C. Van Ess-Dykema.
1998.
Dialog act model-ing for conversational speech.
AAAI Spring Sym-posium on Applying Machine Learning to Dis-course Processing.Richmond H. Thomason and Jerry R. Hobbs.
1997.Interrelating interpretation a d generation i anabductive framework.
AAAI Fall Symposium onCommunicative Actions in Human and Machines,Cambridge MA.Raimo Tuomela.
1995.
The Importance of Us.
Stan-ford University Press.Marilyn A. Walker.
1993.
Informational Redun-dancy and Resource Bounds in Dialogue.
Ph.D.thesis, University of Pennsylvania, December.Marilyn A. Walker.
1996.
Inferring acceptance andrejection in dialogue by default rules of inference.Language and Speech, 39(2).329
