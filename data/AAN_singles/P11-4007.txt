Proceedings of the ACL-HLT 2011 System Demonstrations, pages 38?43,Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational LinguisticsAn ERP-based Brain-Computer Interface for text entryusing Rapid Serial Visual Presentation and Language ModelingK.E.
Hild?, U.
Orhan?, D.
Erdogmus?, B.
Roark?, B.
Oken?, S.
Purwar?, H.
Nezamfar?, M.
Fried-Oken?
?Oregon Health and Science University ?Cognitive Systems Lab, Northeastern University{hildk,roarkb,oken,friedm}@ohsu.edu {orhan,erdogmus,purwar,nezamfar}@ece.neu.eduAbstractEvent related potentials (ERP) correspondingto stimuli in electroencephalography (EEG)can be used to detect the intent of a per-son for brain computer interfaces (BCI).
Thisparadigm is widely used to build letter-by-letter text input systems using BCI.
Neverthe-less using a BCI-typewriter depending only onEEG responses will not be sufficiently accu-rate for single-trial operation in general, andexisting systems utilize many-trial schemes toachieve accuracy at the cost of speed.
Henceincorporation of a language model based prioror additional evidence is vital to improve accu-racy and speed.
In this demonstration we willpresent a BCI system for typing that integratesa stochastic language model with ERP classifi-cation to achieve speedups, via the rapid serialvisual presentation (RSVP) paradigm.1 IntroductionThere exist a considerable number of people with se-vere motor and speech disabilities.
Brain computerinterfaces (BCI) are a potential technology to createa novel communication environment for this popula-tion, especially persons with completely paralyzedvoluntary muscles (Wolpaw, 2007; Pfurtscheller etal., 2000).
One possible application of BCI is typ-ing systems; specifically, those BCI systems thatuse electroencephalography (EEG) have been in-creasingly studied in the recent decades to enablethe selection of letters for expressive language gen-eration (Wolpaw, 2007; Pfurtscheller et al, 2000;Treder and Blankertz, 2010).
However, the use ofnoninvasive techniques for letter-by-letter systemslacks efficiency due to low signal to noise ratio andvariability of background brain activity.
Thereforecurrent BCI-spellers suffer from low symbol ratesand researchers have turned to various hierarchi-cal symbol trees to achieve system speedups (Serbyet al, 2005; Wolpaw et al, 2002; Treder andBlankertz, 2010).
Slow throughput greatly dimin-ishes the practical usability of such systems.
In-corporation of a language model, which predictsthe next letter using the previous letters, into thedecision-making process can greatly affect the per-formance of these systems by improving the accu-racy and speed.As opposed to the matrix layout of the popu-lar P300-Speller (Wolpaw, 2007), shown in Fig-ure 1, or the hexagonal two-level hierarchy of theBerlin BCI (Treder and Blankertz, 2010), we uti-lize another well-established paradigm: rapid se-rial visual presentation (RSVP), shown in Figure2.
This paradigm relies on presenting one stimu-lus at a time at the focal point of the screen.
Thesequence of stimuli are presented at relatively highspeeds, each subsequent stimulus replacing the pre-vious one, while the subject tries to perform men-tal target matching between the intended symbol andthe presented stimuli.
EEG responses correspondingto the visual stimuli are classified using regularizeddiscriminant analysis (RDA) applied to stimulus-locked temporal features from multiple channels.The RSVP interface is of particular utility for themost impaired users, including those suffering fromlocked-in syndrome (LIS).
Locked-in syndrome canresult from traumatic brain injury, such as a brain-stem stroke1, or from neurodegenerative diseasessuch as amyotrophic lateral sclerosis (ALS or LouGehrig?s disease).
The condition is characterized bynear total paralysis, though the individuals are cog-nitively intact.
While vision is retained, the motorcontrol impairments extend to eye movements.
Of-ten the only reliable movement that can be made by1Brain stem stroke was the cause of LIS for Jean-DominiqueBauby, who dictated his memoir The Diving Bell and the But-terfly via eyeblinks (Bauby, 1997).MGA FEC_97653 4Y 1ZXWUTSRQONHBLKIV8PJ2DFigure 1: Spelling grid such as that used for the P300speller (Farwell and Donchin, 1988).
?
?
denotes space.38Figure 2: RSVP scanning interface.an individual is a particular muscle twitch or singleeye blink, if that.
Such users have lost the voluntarymotor control sufficient for such an interface.
Rely-ing on extensive visual scanning or complex gestu-ral feedback from the user renders a typing interfacedifficult or impossible to use for the most impairedusers.
Simpler interactions via brain-computer in-terfaces (BCI) hold much promise for effective textcommunication for these most impaired users.
Yetthese simple interfaces have yet to take full advan-tage of language models to ease or speed typing.In this demonstration, we will present a language-model enabled interface that is appropriate for themost impaired users.In addition, the RSVP paradigm provides someuseful interface flexibility relative to the grid-basedparadigm.
First, it allows for auditory rather thanvisual scanning, for use by the visually impairedor when visual access is inconvenient, such as inface-to-face communication.
Auditory scanning isless straightforward when using a grid.
Second,multi-character substrings can be scanned in RSVP,whereas the kind of dynamic re-organization of agrid that would be required to support this can bevery confusing.
Finally, language model integrationwith RSVP is relatively straightforward, as we shalldemonstrate.
See Roark et al (2010) for methodsintegrating language modeling into grid scanning.2 RSVP based BCI and ERP ClassificationRSVP is an experimental psychophysics techniquein which visual stimulus sequences are displayedon a screen over time on a fixed focal area andin rapid succession.
The Matrix-P300-Speller usedby Wadsworth and Graz groups (especially g.tec,Austria) opts for a spatially distributed presentationof possible symbols, highlighting them in differentorders and combinations to elicit P300 responses.Berlin BCI?s recent variation utilizes a 2-layer treestructure where the subject chooses among six units(symbols or sets of these) where the options are laidout on the screen while the subject focuses on a cen-tral focal area that uses an RSVP-like paradigm toelicit P300 responses.
Full screen awareness is re-quired.
In contrast, our approach is to distributethe stimuli temporally and present one symbol at atime using RSVP and seek a binary response to findthe desired letter, as shown in Figure 2.
The lattermethod has the advantage of not requiring the userto look at different areas of the screen, which can bean important factor for those with LIS.Our RSVP paradigm utilizes stimulus sequencesconsisting of the 26 letters in the English alphabetplus symbols for space and backspace, presented ina randomly ordered sequence.
When the user seesthe target symbol, the brain generates an evoked re-sponse potential (ERP) in the EEG; the most promi-nent component of this ERP is the P300 wave, whichis a positive deflection in the scalp voltage primar-ily in frontal areas and that generally occurs with alatency of approximately 300 ms.
This natural nov-elty response of the brain, occurring when the userdetects a rare, sought-after target, allows us to makebinary decisions about the user?s intent.The intent detection problem becomes a signalclassification problem when the EEG signals arewindowed in a stimulus-time-locked manner start-ing at stimulus onset and extending for a sufficientduration ?
in this case 500ms.
Consider Figure3, which shows the trial-averaged temporal signalsfrom various EEG channels corresponding to tar-get and non-target (distractor) symbols.
This graphshows a clear effect between 300 and 500 ms for thetarget symbols that is not present for the distractorsymbols (the latter of which clearly shows a com-ponent having a periodicity of 400 ms, which is ex-pected in this case since a new image was presentedevery 400 ms).
Figure 4, on the other hand, showsthe magnitude of the trial and distractor responses atchannel Cz on a single-trial basis, rather than aver-aged over all trials.
The signals acquired from eachEEG channel are incorporated and classified to de-termine the class label: ERP or non-ERP.Our system functions as follows.
First, each chan-nel is band-pass filtered.
Second, each channel istemporally-windowed.
Third, a linear dimensionreduction (using principal components analysis) islearned using training data and is subsequently ap-plied to the EEG data when the system is beingused.
Fourth, the data vectors obtained for eachchannel and a given stimulus are concatenated tocreate the data matrix corresponding to the speci-fied stimulus.
Fifth, Regularized Discriminant Anal-ysis (RDA) (Friedman, 1989), which estimates con-ditional probability densities for each class using39Figure 3: Trial-averaged EEG data corresponding to the targetresponse (top) and distractor response (bottom) for a 1 secondwindow.Kernel Density Estimation (KDE), is used to deter-mine a purely EEG-based classification discriminantscore for each stimulus.
Sixth, the conditional prob-ability of each letter given the typed history is ob-tained from the language model.
Seventh, Bayesianfusion (which assumes the EEG-based informationand the language model information are statisticallyindependent given the class label) is used to combinethe RDA discriminant score and the language modelscore to generate an overall score, from which weinfer whether or not a given stimulus represents anintended (target) letter.RDA is a modified quadratic discriminant anal-ysis (QDA) model.
Assuming each class has amultivariate normal distribution and assuming clas-sification is made according to the comparison ofposterior distributions of the classes, the optimalBayes classifier resides within the QDA model fam-ily.
QDA depends on the inverse of the class co-variance matrices, which are to be estimated fromtraining data.
Hence, for small sample sizes andhigh-dimensional data, singularities of these matri-ces are problematic.
RDA applies regularization andshrinkage procedures to the class covariance matrixFigure 4: Single-trial EEG data at channel Cz correspondingto the target response (top) and distractor response (bottom) fora 1 second window.estimates in an attempt to minimize problems asso-ciated with singularities.
The shrinkage proceduremakes the class covariances closer to the overall datacovariance, and therefore to each other, thus mak-ing the quadratic boundary more similar to a linearboundary.
Shrinkage is applied as??c(?)
= (1?
?)?
?c + ??
?, (1)where ?
is the shrinkage parameter, ?
?c is the classcovariance matrix estimated for class c ?
{0, 1},c = 0 corresponds to the non-target class, c = 1 cor-responds to the target class, and ??
is the weightedaverage of class covariance matrices.
Regularizationis administered as?
?c(?, ?)
= (1?
?)??c(?)
+?dtr[??c(?
)]I, (2)where ?
is the regularization parameter, tr[?]
is thetrace function, and d is the dimension of the datavector.After carrying out the regularization and shrink-age on the estimated covariance matrices, theBayesian classification rule (Duda et al, 2001) isapplied by comparing the log-likelihood ratio (using40Figure 5: Timing of stimulus sequence presentationthe posterior probability distributions) with a confi-dence threshold.
The confidence threshold can bechosen so that the system incorporates the relativerisks or costs of making an error for each class.
Thecorresponding log-likelihood ratio is given by?RDA(x) = logfN (x; ?
?1, ?
?1(?, ?
))p?i1fN (x; ?
?0, ?
?0(?, ?
))p?i0, (3)where ?c and p?ic are the estimates of the class meansand priors, respectively, x is the data vector to beclassified, and fN (x;?,?)
is the pdf of a multivari-ate normal distribution.The set of visual stimuli (letters plus two ex-tra symbols, in our case) can be shown multipletimes to achieve a higher classification accuracy forthe EEG-based classifier.
The information obtainedfrom showing the visual stimuli multiple times caneasily be combined by assuming the trials are sta-tistically independent, as is commonly assumed inEEG-based spellers2.
Figure 5 presents a diagram ofthe timing of the presentation of stimuli.
We definea sequence to be a randomly-ordered set of all theletters (and the space and backspace symbols).
Theletters are randomly ordered for each sequence be-cause the magnitude of the ERP, hence the quality ofthe EEG-based classification, is commonly thoughtto depend on how surprised the user is to find theintended letter.
Our system also has a user-definedparameter by which we are able to limit the max-imum number of sequences shown to the user be-fore our system makes a decision on the (single) in-tended letter.
Thus we are able to operate in single-trial or multi-trial mode.
We use the term epoch todenote all the sequences that are used by our sys-tem to make a decision on a single, intended let-2The typical number of repetitions of visual stimuli is on theorder of 8 or 16, although g.tec claims one subject is able toachieve reliable operation with 2 trials (verbal communication).ter.
As can be seen in the timing diagram shownin Figure 5, epoch k contains between 1 and Mksequences.
This figure shows the onset of each se-quence, each fixation image (which is shown at thebeginning of each sequence), and each letter usingnarrow pulses.
After each sequence is shown, thecumulative (overall) score for all letters is computed.The cumulative scores are non-negative and sum toone (summing over the 28 symbols).
If the num-ber of sequences shown is less than the user-definedlimit and if the maximum cumulative score is lessthan 0.9, then another randomly-ordered sequence isshown to the user.
Likewise, if either the maximumnumber of sequences has already been shown or ifthe maximum cumulative score equals or exceeds0.9, then the associated symbol (for all symbols ex-cept the backspace) is added to the end of the listof previously-detected symbols, the user is able totake a break of indefinite length, and then the systemcontinues with the next epoch.
If the symbol hav-ing the maximum cumulative score is the backspacesymbol, then the last item in the list of previously-detected symbols is removed and, like before, theuser can take a break and then the system continueswith the next epoch.3 Language ModelingLanguage modeling is important for many text pro-cessing applications, e.g., speech recognition or ma-chine translation, as well as for the kind of typ-ing application being investigated here (Roark et al,2010).
Typically, the prefix string (what has al-ready been typed) is used to predict the next sym-bol(s) to be typed.
The next letters to be typed be-come highly predictable in certain contexts, partic-ularly word-internally.
In applications where textgeneration/typing speed is very slow, the impactof language modeling can become much more sig-nificant.
BCI-spellers, including the RSVP Key-board paradigm presented here, can be extremelylow-speed, letter-by-letter writing systems, and thuscan greatly benefit from the incorporation of proba-bilistic letter predictions from an accurate languagemodel.For the current study, all language models wereestimated from a one million sentence (210M char-acter) sample of the NY Times portion of the EnglishGigaword corpus.
Models were character n-grams,estimated via relative frequency estimation.
Corpusnormalization and smoothing methods were as de-scribed in Roark et al (2010).
Most importantly for41Figure 6: Block diagram of system architecture.this work, the corpus was case normalized, and weused Witten-Bell smoothing for regularization.4 System ArchitectureFigure 6 shows a block diagram of our system.
Weuse a Quad-core, 2.53 GHz laptop, with system codewritten in Labview, Matlab, and C. We also usethe Psychophysics Toolbox3 to preload the imagesinto the video card and to display the images atprecisely-defined temporal intervals.
The type UBg.USBamp EEG-signal amplifier, which is manufac-tured by g.tec (Austria), has 24 bits of precision andhas 16 channels.
We use a Butterworth bandpass fil-ter of 0.5 to 60 Hz, a 60 Hz notch filter, a samplingrate of 256 Hz, and we buffer the EEG data until wehave 8 samples of 16-channel EEG data, at whichpoint the data are transmitted to the laptop.
Weuse either g.BUTTERfly or g.LADYbird active elec-trodes, a g.GAMMA cap, and the g.GAMMAsys ac-tive electrode system.The output of the amplifier is fed to the laptop viaa USB connection with a delay that is both highlyvariable and unknown a priori.
Consequently, weare unable to rely on the laptop system clock in or-der to synchronize the EEG data and the onset ofthe visual stimuli.
Instead, synchronization betweenthe EEG data and the visual stimuli is provided bysending a parallel port trigger, via an express card-to-parallel port adaptor, to one of the digital inputsof the amplifier, which is then digitized along withthe EEG data.
The parallel port to g.tec cable wascustom-built by Cortech Solutions, Inc. (Wilming-ton, North Carolina, USA).
The parallel port triggeris sent immediately after the laptop monitor sendsthe vertical retrace signal.
The mean and the stan-3http://psychtoolbox.org/wikka.php?wakka=HomePagedard deviation of the delay needed to trigger the par-allel port has been measured to be on the order oftens of microseconds, which should be sufficientlysmall for our purposes.5 ResultsHere we report data collected from 2 subjects, oneof whom is a LIS subject with very limited experi-ence using our BCI system, and the other a healthysubject with extensive experience using our BCI sys-tem.
The symbol duration was set to 400 ms, theduty cycle was set to 50%, and the maximum num-ber of sequences per trial was set to 6.
Before test-ing, the classifier of our system was trained on dataobtained as each subject viewed 50 symbols with 3sequences per epoch (the classifier was trained oncefor the LIS subject and once for the healthy sub-ject).
The healthy subject was specifically instructedto neither move nor blink their eyes, to the extentpossible, while the symbols are being flashed on thescreen in front of them.
Instead, they were to waituntil the rest period, which occurs after each epoch,to move or to blink.
The subjects were free to pro-duce whatever text they wished.
The only require-ment given to them concerning the chosen text wasthat they must not, at any point in the experiment,change what they are planning to type and they mustcorrect all mistakes using the backspace symbol.Figure 7 shows the results for the non-expert,LIS subject.
A total of 10 symbols were correctlytyped by this subject, who had chosen to spell,?THE STEELERS ARE GOING TO ...?.
Noticethat the number of sequences shown exceeds themaximum value of 6 for 3 of the symbols.
Thisoccurs when the specified letter is mistyped one ormore times.
For example, for each mistyped non-backspace symbol, a backspace is required to delete42T H E _ S T E E L E051015202530354045No.of sequencesto reachconfidence thresholdMean = 144/10 = 14.4 (seq/desired symbol)Mean = 5.1 (seq/symbol)Figure 7: Number of sequences to reach the confidence thresh-old for the non-expert, LIS subject.T H E _ L A K E R S _ A R E _ I N _ F I051015202530354045No.of sequencesto reachconfidence thresholdMean = 28/20 = 1.4 (seq/desired symbol)Mean = 1.4 (seq/symbol)Figure 8: Number of sequences to reach the confidence thresh-old for the expert, healthy subject.the incorrect symbol.
Likewise, if a backspace sym-bol is detected although it was not the symbol thatthe subject wished to type, then the correct symbolmust be retyped.
As shown in the figure, the meannumber of sequences for each correctly-typed sym-bol is 14.4 and the mean number of sequences persymbol is 5.1 (the latter of which has a maximumvalue of 6 in this case).Figure 8 shows the result for the expert, healthysubject.
A total of 20 symbols were cor-rectly typed by this subject, who had chosen tospell, ?THE LAKERS ARE IN FIRST PLACE?.The mean number of sequences for each correctly-typed symbol for this subject is 1.4 and the meannumber of sequences per symbol is also 1.4.
Noticethat in 15 out of 20 epochs the classifier was able todetect the intended symbol on the first epoch, whichcorresponds to a single-trial presentation of the sym-bols, and no mistakes were made for any of the 20symbols.There are two obvious explanations as to why thehealthy subject performed better than the LIS sub-ject.
First, it is possible that the healthy subject wasusing a non-neural signal, perhaps an electromyo-graphic (EMG) signal stemming from an unintendedmuscle movement occurring synchronously with thetarget onset.
Second, it is also possible that the LISsubject needs more training in order to learn howto control the system.
We believe the second ex-planation is correct and are currently taking stepsto make sure the LIS subject has additional time totrain on our system in hopes of resolving this ques-tion quickly.AcknowledgmentsThis work is supported by NSF under grantsECCS0929576, ECCS0934506, IIS0934509,IIS0914808, BCS1027724 and by NIH under grant1R01DC009834-01.
The opinions presented hereare those of the authors and do not necessarilyreflect the opinions of the funding agencies.ReferencesJ.-D. Bauby.
1997.
The Diving Bell and the Butterfly.Knopf, New York.R.O.
Duda, P.E.
Hart, and D.G.
Stork.
2001.
Patternclassification.
Citeseer.L.A.
Farwell and E. Donchin.
1988.
Talking off thetop of your head: toward a mental prosthesis utiliz-ing event-related brain potentials.
Electroenceph Clin.Neurophysiol., 70:510?523.J.H.
Friedman.
1989.
Regularized discriminant analy-sis.
Journal of the American statistical association,84(405):165?175.G.
Pfurtscheller, C. Neuper, C. Guger, W. Harkam,H.
Ramoser, A. Schlogl, B. Obermaier, and M. Pre-genzer.
2000.
Current trends in Graz brain-computerinterface (BCI) research.
IEEE Transactions on Reha-bilitation Engineering, 8(2):216?219.B.
Roark, J. de Villiers, C. Gibbons, and M. Fried-Oken.2010.
Scanning methods and language modeling forbinary switch typing.
In Proceedings of the NAACLHLT 2010 Workshop on Speech and Language Pro-cessing for Assistive Technologies, pages 28?36.H.
Serby, E. Yom-Tov, and G.F. Inbar.
2005.
An im-proved P300-based brain-computer interface.
NeuralSystems and Rehabilitation Engineering, IEEE Trans-actions on, 13(1):89?98.M.S.
Treder and B. Blankertz.
2010.
(C) overt atten-tion and visual speller design in an ERP-based brain-computer interface.
Behavioral and Brain Functions,6(1):28.J.R.
Wolpaw, N. Birbaumer, D.J.
McFarland,G.
Pfurtscheller, and T.M.
Vaughan.
2002.
Brain-computer interfaces for communication and control.Clinical neurophysiology, 113(6):767?791.J.R.
Wolpaw.
2007.
Brain?computer interfaces as newbrain output pathways.
The Journal of Physiology,579(3):613.43
