Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 22?28,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsUsing Domain Knowledge about Medications to Correct Recognition Errorsin Medical Report CreationStephanie SchreitterAlexandra KleinJohannes MatiasekAustrian Research Institutefor Artificial Intelligence (OFAI)Freyung 6/61010 Vienna, Austriafirstname.lastname@ofai.atHarald TrostSection for Artificial IntelligenceCenter for Med.
Statistics, Informatics,and Intelligent SystemsMedical University of ViennaFreyung 6/21010 Vienna, Austriaharald.trost@meduniwien.ac.atAbstractWe present an approach to analysing auto-matic speech recognition (ASR) hypothesesfor dictated medical reports based on back-ground knowledge.
Our application area isprescriptions of medications, which are a fre-quent source of misrecognitions: In a sam-ple report corpus, we found that about 40%of the active substances or trade names anddosages were recognized incorrectly.
In about25% of these errors, the correct string of wordswas contained in the word graph.
We havebuilt a knowledge base of medications basedon information contained in the Unified Med-ical Language System (UMLS), consistingof trade names, active substances, strengthsand dosages.
From this, we generate a va-riety of linguistic realizations for prescrip-tions.
Whenever an inconsistency in a pre-scription is encountered on the best path ofthe word graph, the system searches for alter-native paths which contain valid linguistic re-alizations of prescriptions consistent with theknowledge base.
If such a path exists, a newconcept edge with a better score is added tothe word graph, resulting in a higher plausi-bility for this reading.
The concept edge canbe used for rescoring the word graph to obtaina new best path.
A preliminary evaluation ledto encouraging results: in nearly half of thecases where the word graph contained the cor-rect variant, the correction was successful.1 IntroductionAutomatic speech recognition (ASR) is widely usedin the domain of medical reporting.
Users appreciatethe fact that the records can be accessed immediatelyafter their creation and that speech recognition pro-vides a hands-free input mode, which is important asphysicians often simultaneously handle documentssuch as notes and X-rays (Alapetite et al, 2009).A drawback of using ASR is the fact that speech-recognition errors have to be corrected manually bymedical experts before the resulting texts can beused for electronic patient records, quality controland billing purposes.
This manual post-processing istime-consuming, which slows down hospital work-flows.A number of recognition errors could be avoidedby incorporating explicit domain knowledge.
Weconsider prescriptions of medications a good start-ing point as they are common and frequent in thevarious medical fields.
Furthermore, they containtrade names and dosages, i.e.
proper names and dig-its, which are frequently misrecognized by ASR inall domains.For our approach, we have extracted and adaptedinformation about medications from the UnifiedMedical Language System (UMLS) (Lindberg et al,1993).
This data contains information about tradenames, active substances, strengths and dosages andcan easily be modified, e.g.
when new medicationsare released.In the first step, we assessed the potential for im-provement by analyzing a sample corpus of medicalreports.
It turned out that in 4383 dictated reportswhich were processed by a speech-recognition sys-tem, the word-error rate for medications was about40%, which is slightly higher than the the averageword-error rate of the reports.
Examining a sample22of word graphs for the reports, we realized that inabout 30% of these errors, the correct string of wordswas contained in the word graph, but not ranked asthe best path.In the following sections, we will first givean overview of previous approaches to detectingspeech-recognition errors and semantic rescoring ofword-graph hypotheses.
Then, we will describehow we have adapted information about medicationsfrom the UMLS to enhance the word graph withconcept nodes representing domain-specific infor-mation.
Finally, we will illustrate the potential forimproving the speech-recognition result by meansof an evaluation of word graphs for medical reportswhich were processed by our system.2 Extraction of Medication Information,Error Handling and Semantic Rescoring(Gold et al, 2008) gives an overview on extract-ing structured medication information from clinicalnarratives.
Extracted medication information mayserve as a base for quality control, pharmaceuticalresearch and the automatic creation of ElectronicHealth Records (EHR) from clinical narratives.
Thei2b2 Shared Task 2009 focussed on medication ex-traction, e.g.
(Patrick and Li, 2009; Halgrim et al,2010).
These approaches work on written narrativetexts from clinical settings, which may have beentyped by physicians, transcribed by medical tran-scriptionists or recognized by ASR and corrected bymedical transcriptionists.In contrast, our approach takes as input wordgraphs produced by an ASR system from dictatedtexts and aims at minimizing the post-processing re-quired by human experts.Speech-recognition systems turn acoustic inputinto word graphs, which are directed acyclic graphsrepresenting the recognized spoken forms and theirconfidence scores (Oerder and Ney, 1993).
In mostspeech-recognition systems, meaning is implicitlyrepresented in the language model (LM), indicat-ing the plausibility of sequences of words in termsof n-grams.
It has often been stated that the intro-duction of an explicit representation of the utterancemeaning will improve recognition results.
Naturally,this works best in limited domains: the larger anapplication domain, the more difficult it is to buildan optimal knowledge representation for all possi-ble user utterances.
Limited domains seem to bemore rewarding with regard to coverage and perfor-mance.
Consequently, combining speech recogni-tion and speech understanding has so far mostly re-sulted in applications in the field of dialogue systemswhere knowledge about the domain is represented interms of the underlying database, e.g.
(Seneff andPolifroni, 2000).Several approaches have investigated the poten-tial of improving the mapping between the user ut-terance and the underlying database by constructinga representation of the utterance meaning.
Mean-ing analysis is either a separate post-processing stepor an integral part of the recognition process.
Insome approaches, the recognition result is analyzedwith regards to content to support the dialogue man-ager in dealing with inconsistencies (Macherey etal., 2003).
As far as dictated input is concerned,which is not controlled by a dialogue manager, (Voll,2006) developed a post-ASR error-detection mech-anism for radiology reports.
The hybrid approachuses statistical as well as rule-based methods.
Theknowledge source UMLS is employed for measur-ing the semantic distance between concepts and forassessing the coherence of the recognition result.In other approaches, the analysis of meaningis integrated into the recognition process.
Se-mantic confidence measurement annotates recogni-tion hypotheses with additional information abouttheir assumed plausibility based on semantic scores(Zhang and Rudnicky, 2001; Sarikaya et al, 2003).
(Gurevych and Porzel, 2003; Gurevych et al, 2003)present a rescoring approach where the hypothe-ses in the word graph are reordered according tosemantic information.
Usually, conceptual parsersare employed which construct a parse tree of con-cepts representing the input text for mapping be-tween the recognition result and the underlying rep-resentation.
Semantic language modeling (Wangetal., 2004; Buehler et al, 2005) enhances the lan-guage model to incorporate sequences of conceptswhich are considered coherent and typical for a spe-cific context.
In these approaches, the representa-tions of the underlying knowledge are created spe-cially for the applications or are derived from a textcorpus.In our approach, we aim at developing a prototype23for integrating available knowledge sources into theanalysis of the word graph during the recognitionprocess.
We have decided not to integrate the com-ponent directly into the ASR system but to introducea separate post-processing step for the recognition ofinformation about medications with the word graphsas interface.
This makes it easier to update the med-ication knowledge base, e.g.
if new medications arereleased.
Furthermore, it is not necessary to retrainthe ASR system language model for each new ver-sion of the medication knowledge base.3 Knowledge Base and Text CorpusFor our approach, we prepared a knowledge baseconcerning medications and dosages, and we useda corpus of medical reports, dictated by physiciansin hospitals.
The ASR result and a manual transcrip-tion is available for each report.
For a subset of thecorpus, word graphs could be obtained.
By aligningthe recognition result with the manual transcriptions,error regions can be extracted.3.1 Knowledge BaseAs it is our aim to find correct dosages of med-ications in the word graph, we built a domain-specific knowledge base which contains medica-tions and strengths as they occur in prescriptions.In our sample of medical reports, about 1/3 of themedications occurred as active ingredients while therest were trade names.
Therefore, both had to becovered in our knowledge base which is based onRxNorm (Liu et al, 2005).
RxNorm is a standard-ized nomenclature for clinical drugs and drug de-livery devices and part of UMLS, ensuring a broadcoverage of trade names and active ingredients.
Ofseveral available versions of RxNorm, the semanticbranded drug form is the most suitable one for ourpurposes as it contains pharmaceutical ingredients,strengths, and trade names.
For example, the tradename Synthroid R?
is listed as follows:Thyroxine 0.025 MG Oral Tablet [Synthroid R?
]Thyroxine is the active ingredient with the dosagevalue 0.025 and the dosage unit milligrams.
Thedosage unit form is oral tablet.We used a RxNorm version with 1,508 active sub-stances and 7,688 trade names (11,263 trade namescounting the different dosages).
The active ingre-dients in RxNorm are associated with AnatomicalTherapeutic Chemical (ATC) Codes.3.2 Sample CorpusThe corpus is a random sample of 924 clinical re-ports which were dictated by physicians from var-ious specialties and hospitals.
The dications wereprocessed by an ASR system and transcribed by hu-man experts.
Word graphs marked with the best path(indicating the highest acoustic and language-modelscores) represent the recognition result.
Tradenamesare part of the recognition lexicon, but they are fre-quently misrecognized.Of the 9196 medications (i.e.
trade names andactive substances) in RxNorm, only 330 (3.6%) ap-peared in the sample corpus.We searched the corpus for recognition errorsconcerning trade names, active ingredients and theirdosages by comparing the manual transcriptions tothe best paths in the word graphs, and a list of themismatches (i.e.
recognition errors) and their fre-quencies was compiled.
It turned out that 39.3% ofall trade names and active ingredients were recog-nized incorrectly.
The average ASR word-error rateof the reports was 38.1%.
Aproximately 1-2% of thetrade names were not covered by RxNorm.4 ApproachOur approach consists of a generation mechanismwhich anticipates possible spoken forms for thecontent of the knowledge base.
The word graphsare searched for trade names or active substancesand, subsequently, matching dosages.
New conceptedges are inserted if valid prescriptions are found inthe word graph.4.1 Detecting Medications in the Word GraphThe (multi-edge) word graphs are scanned, and thewords associated with each edge are compared to themedications in the knowledge base.
Figure 1 showsa word graph consisting of hypotheses generated byASR, which is the input to our system.
The dashededges indicate the best path, while dotted lines arehypotheses which are not on the best path.24Figure 1: Sample word graph fragmentIn case a match, i.e.
a trade name or an active sub-stance, is found, all edges succeeding the medica-tion edge are searched for dosage values and dosageunits.
So far, we only examine the context to theright-hand side; in the data, we did not encounterany medications where the dosage occurred beforethe trade name or active substance.
The followingkinds of fillers between the trade name or active sub-stance and the dosage are allowed: ?to?
and ?of?as well as non-utterances such as hesitation, noiseand silence; in the corpus, we did not encounter anyother fillers.4.2 Generation of Spoken Forms and MappingThe medication found in the word graph is looked upin RxNorm, and all possible spoken forms of validdosage values and dosage units for this medicationare generated.
Spoken forms for the medicationnames consist of the trade names and the active sub-stances.
Variation in the pronunciation of the tradenames or active substances is handled by the ASRrecognition lexicon.
For generating spoken forms ofthe dosage values, finite-state tools were used.
Fordosage units, we wrote a small grammar.
Lookingat two examples, the medication Synthroid R?
andColace R?
(the latter appears in the word graphs inFigure 2 and Figure 1), the spoken forms shown inTable 1 are generated.
Each box contains the al-ternative spoken variants.
Synthroid R?
contains theactive substance Thyroxine and Colace R?
containsthe active substance Docusate; users may either re-fer to the trade name or the active substance, so bothpossibilities are generated for each medication anddosage.
RxNorm does not contain the dosage unit?mcg?
(micrograms), which occurred in the reports.Therefore, microgram dosage values were convertedto milligrams.
Since both ?miligram(s)?
and ?mi-crogram(s)?
may occur for Synthroid R?, dosage val-ues for both dosage units are generated.
Althoughstrictly, ?twenty five?
and ?twenty-five?
are identicalspoken forms, both versions may appear in the wordgraph and thus are provided by our system.Sometimes, a medication may contain several ac-tive substances, e.g.
Hyzaar R?, a medication againsthigh blood pressure:Hydrochlorothiazide 12.5 MG / Losartan 50 MGOral Tablet [Hyzaar]25trade name/ dosage value dosage unitactivesubstance?Synthroid?
?zero point zero two five?
?milligram??Thyroxine?
?zero point O two five?
?milligrams?
?O point zero two five?
?O point O two five?
?point zero two five?
?point O two five?
?twenty five?
?microgram??twenty-five?
?micrograms?
?two five??Colace?
?one hundred?
?miligram??Docusate?
?a hundred?
?miligrams?
?hundred?Table 1: Generated spoken forms found in the word graphIn these cases, the generation of possible spokenforms also includes different permutations of sub-stances, as well as a spoken forms containing thedosage unit either only at the end or after each valueif the dosage unit is identical.4.3 Inserting Concept EdgesThe sequences of words which constitute the wordgraph are compared to the spoken forms generatedfor the RxNorm knowledge base.
The active sub-stances or trade names serve as a starting point: incase a trade name is found in the word graph, thespoken forms for dosages of all active substances aregenerated in all permutations.
If an active substanceis found in the word graph, only the spoken formsfor the substance dosage are searched in the wordgraph.A new concept edge is inserted into the wordgraph for each path matching one of the generatedspoken forms of the medications data base.
The in-serted concept edges span from the first matchingnode to the last matching node on the path.
Fig-ure 2 shows the word graph from Figure 1 with an in-serted concept edge (in bold).
For each inserted con-cept edge, new concept-edge attributes are assignedcontaining the IDs of the original edges as children,their added scores plus an additional concept scoreand the sequence of words.
Since no large-scale ex-periments have yet been carried out, so far the con-cept score which is added to the individual scores ofthe children is an arbitrary number which improvesthe score of the medication subpath in constrast topaths which do not contain valid medication infor-mation.
If several competing medication paths arefound, a concept edge is inserted for each path, andthe concept edges can be ranked according to theiracoustic and language-model scores.5 EvaluationIn the first step, we examined a report sample in or-der to determine if there are cases where a valid pre-scription is recognised although the physician didnot mention a prescription.
We did not encounterthis phenomenon in our report corpus.We then applied our method to a sample of 924word graphs.
In this sample,?
481 valid dosages could be found, although?
only 325 of these were on the best path.With our approach, for the 156 prescriptions(32%) which were not on the best path, alternativescould be reconstructed from the word graph.
Basedon the inserted concept edges, the best path can berescored.In order to measure recall, i.e.
how many of allexisting prescriptions in the reports can be detectedwith our knowledge base, we manually checkeda sample of 132 reports (containing manual tran-scriptions and ASR results).
In this sample, 85 er-rors concerning medications and/or prescriptions oc-curred.
For 19 of the 85 errors, the correct result wascontained in the word graph.
For 8 errors, it couldbe reconstructed.
So about 9% of the errors concern-ing medications can be corrected in our sample.
Forthe cases where the prescription could not be recon-structed although it was contained in the word graph,an analysis of the errors is shown in Table 2.Since new medications are constantly being re-leased, and trade names change frequently, mis-matches may be due to the fact that our version ofRxNorm was from a more recent point in time thanthe report corpus.
We assume that under real-worldconditions, both RxNorm and the medications pre-scribed by physicians reflect the current situation.Some problems concerning medication namesand dosage units were caused by missing spokenforms containing abbreviations, e.g.
of dosage units(mg vs. mg/ml) or names (Lantus vs. Lantus in-sulin).
Here, the coverage needs to be improved.26Figure 2: Sample word graph fragment with inserted concept node (left)Table 2: Error types found in manual evaluationtype of error # exampleWord Graph RxNormdifferences in medication names 3 Cardizem CD 120 mg Cardizem 120 mgbetween the knowledge base and the word graphdifferences in dosage values 4 Tapazole 60 mg Tapazole 10 mgbetween the knowledge base and the word graphdifferences in dosage units 4 Epogen 20000 units Epogen 20000 mlbetween the knowledge base and the word graphThere are also cases where two medications appearin the word graph, and both had the valid prescrip-tion strength, therefore the system was not able todetermine the correct medication.6 ConclusionIn this paper, we present an attempt to reducethe number of speech-recognition errors concern-ing prescriptions of medications based on a domain-specific knowledge base.
Our approach uses wordgraphs as input and creates new versions of the wordgraph with inserted concept edges if more plausi-ble prescriptions are found.
The concept edges canbe used for rescoring the best path.
An evaluationshowed that 32% of prescriptions found in the wordgraphs were not on the best path but could be re-constructed.
The manual evaluation of 132 reportsshows that our method covers 42% of the prescrip-tions which are actually spoken during the dictation.At present, we have only investigated the reduc-tion of medication misrecognitions in our evalua-tion.
In a larger evaluation, we will determine the ac-tual impact of our method on the word-error rate ofmedical reports.
Furthermore, we are working on in-tegrating additional available knowledge sources sothat the plausibility of prescriptions can also be as-27sessed from a broader medical point of view, e.g.
incase two subsequent prescriptions are encounteredin the word graph which are incompatible due todrug interactions.
As a next step, the system canbe extended to compare the prescriptions with thepatient record, e.g.
if a patient has medication al-lergies.
So far, our simple solution integrating onlyavailable, constantly updated knowledge about med-ications has already turned out to be a good startingpoint for rescoring word graphs based on domainknowledge.AcknowledgmentsThe work presented here has been carried out inthe context of the Austrian KNet competence net-work COAST.
We gratefully acknowledge fundingby the Austrian Federal Ministry of Economics andLabour, and ZIT Zentrum fuer Innovation und Tech-nologie, Vienna.
The Austrian Research Institutefor Artificial Intelligence is supported by the Aus-trian Federal Ministry for Transport, Innovation, andTechnology and by the Austrian Federal Ministryfor Science and Research.
The authors would liketo thank the anonymous reviewers for their helpfulcomments.ReferencesA.
Alapetite, A., H.B.
Andersen, H.B.
and M. Hertzumb.Acceptance of speech recognition by physicians: Asurvey of expectations, experiences, and social in-fluence.
International Journal of Human-ComputerStudies 67(1) (2009) 36?49D.
Bu?hler, W. Minker and A. Elciyanti.
Us-ing language modelling to integrate speechrecognition with a flat semantic analysis.
In:6th SIGdial Workshop on Discourse and Di-alogue, Lisbon, Portugal (September 2005)http://www.sigdial.org/workshops/workshop6/proceed-ings/pdf/86-paper.pdf.S.
Gold, N. Elhadad, X. Zhu, J.J. Cimino, G. Hripcsak.Extracting Structured Medication Event Informationfrom Discharge Summaries.
In: Proceedings of theAMIA 2008 Symposium.I.
Gurevych and R. Porzel.
Using knowledge-basedscores for identifying best speech recognition hy-pothesis.
In: Proceedings of ISCA Tutorial andResearch Workshop on Error Handling in SpokenDialogue Systems, Chateau-d?Oex-Vaud, Switzer-land (2003) 77?81 http://proffs.tk.informatik.tu-darmstadt.de/TK/abstracts.php3?lang=en&bibtex=1&-paperID=431.R.
Porzel, I. Gurevych and C. Mu?ller.
Ontology-basedcontextual coherence scoring.
Technical report, Euro-pean Media Laboratory, Heidelberg, Germany (2003)http://citeseer.ist.psu.edu/649012.html.S.R.
Halgrim, F. Xia, I. Solti, E. Cadag and O. Uzuner.Statistical Extraction of Medication Information fromClinical Records.
In: Proc.
of AMIA Summit on Trans-lational Bioinformatics, San Francisco, CA, March10-12, 2010.D.A.
Lindberg, B.L.
Humphreys and A.T. McCray.
Theunified medical language system.
Methods of In-formation in Medicine 32(4) (August 1993) 281?291http://www.nlm.nih.gov/research/umls/.S.
Liu, W. Ma, R. Moore, V. Ganesan and S. Nelson.Rxnorm: Prescription for electronic drug informationexchange.
IT Professional 7(5) (September/October2005) 17?23K.
Macherey, O. Bender and H. Ney.
Multi-level er-ror handling for tree based dialogue course man-agement.
In: Proceedings of ISCA Tutorial andResearch Workshop on Error Handling in Spo-ken Dialogue Systems, Chateau-d?Oex-Vaud, Switzer-land (2003) 123?128, http://www-i6.informatik.rwth-aachen.de/?bender/papers/isca tutorial 2003.pdf.M.
Oerder and H. Ney.
Word graphs: An efficient inter-face between continuous speech recognition and lan-guage understanding.
In: Proc.
IEEE ICASSP?93.
Vol-ume 2.
119?122.J.
Patrick and M. Li.
A Cascade Approach to ExtractingMedication Events.
In: Proc.
Australasian LanguageTechnology Workshop (ALTA) 2009.R.
Sarikaya, Y. Gao and M. Picheny.
Word level confi-dence measurement using semantic features.
In: Proc.of IEEE ICASSP2003.
Volume 1.
(April 2003) 604?607.S.
Seneff and J. Polifroni.
Dialogue Management in theMERCURY Flight Reservation System.
In: Satel-lite Dialogue Workshop, ANLP-NAACL, Seattle (April2000).K.D.
Voll.
A Methodology of Error Detection:Improving Speech Recognition in Radiology.PhD thesis, Simon Fraser University (2006)http://ir.lib.sfu.ca/handle/1892/2734.K.
Wang, Y.Y.
Wang and A. Acero.
Use and acquisitionof semantic language model.
In: HLT-NAACL.
(2004)http://www.aclweb.org/anthology-new/N/N04/N04-3011.pdf.R.
Zhang and A.I.
Rudnicky.
Word level confi-dence annotation using combinations of fea-tures.
In: Proceedings of Eurospeech.
(2001)http://www.speech.cs.cmu.edu/Communicator/papers/-RecoConf2001.pdf.28
