Proceedings of NAACL-HLT 2015, pages 51?55,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsSETS: Scalable and Efficient Tree Search in Dependency GraphsJuhani Luotolahti1, Jenna Kanerva1,2, Sampo Pyysalo1and Filip Ginter11Department of Information Technology2University of Turku Graduate School (UTUGS)University of Turku, Finlandfirst.last@utu.fiAbstractWe present a syntactic analysis query toolkitgeared specifically towards massive depen-dency parsebanks and morphologically richlanguages.
The query language allows arbi-trary tree queries, including negated branches,and is suitable for querying analyses with richmorphological annotation.
Treebanks of overa million words can be comfortably queriedon a low-end netbook, and a parsebank withover 100M words on a single consumer-gradeserver.
We also introduce a web-based inter-face for interactive querying.
All contribu-tions are available under open licenses.1 IntroductionSyntactic search is one of the basic tools necessaryto work with syntactically annotated corpora, bothmanually annotated treebanks of modest size andmassive automatically analyzed parsebanks, whichmay go into hundreds of millions of sentences andbillions of words.
Traditionally, tools such asTGrep2 (Rohde, 2004) and TRegex (Levy and An-drew, 2006) have been used for tree search.
How-ever, these tools are focused on constituency treesannotated with simple part-of-speech tags, and havenot been designed to deal with dependency graphsand rich morphologies.
Existing search systems aretraditionally designed for searching from treebanksrarely going beyond million tokens.
However, tree-bank sized corpora may not be sufficient enough forsearching rare linguistic phenomena, and thereforeability to cover billion-word parsebanks is essen-tial.
Addressing these limitations in existing tools,we present SETS, a toolkit for search in dependencytreebanks and parsebanks that specifically empha-sizes expressive search of dependency graphs in-cluding detailed morphological analyses, simplicityof querying, speed, and scalability.Operator Meaning< governed by> governs<@L governed by on the left<@R governed by on the right>@L has dependent on the left>@R has dependent on the right!
negation& | and / or+ match if both sets not empty-> universal quantificationTable 1: Query language operators.2 Demonstration outlineWe demonstrate the query system on the set of allavailable Universal Dependencies1treebanks, cur-rently covering 10 languages with the largest tree-bank (Czech) consisting of nearly 90K trees with1.5M words.
We demonstrate both the commandline functionality as well as an openly accessibleweb-based interface for the graph search and visual-ization on multiple languages.
We also demonstratehow new treebanks in the CoNLL formats are addedto the system.3 Query languageThe query language is loosely inspired by TRegex,modified extensively for dependency structures.Each query specifies the words together with anyrestrictions on their tags or lemmas, and then con-nects them with operators that specify the depen-dency structure.
Table 1 shows the operators definedin the query language, and Table 2 illustrates a rangeof queries from the basic to the moderately complex.1universaldependencies.github.io/docs.Note that while the SETS system is completely generic, wehere use UD tagsets and dependency relations in examplesthroughout.51Target QueryThe word dog as subject dog <nsubjA verb with dog as the object VERB >dobj dogA word with two nominal modifiers >nmod >nmodA word with a nominal modifier that has a nominal modifier >nmod ( >nmod )An active verb without a subject VERB&Voice=Act !>nsubjA word which is a nominal modifier but has no adposition <nmod !>caseA word governed by case whose POS tag is not an adposition !ADP <caseTable 2: Example queries.The query language is explained in detail in the fol-lowing.3.1 WordsWord positions in queries can be either unspeci-fied, matching any token, or restricted for one ormore properties.
Unspecified words are markedwith the underscore character.
Lexical token restric-tions include wordform and lemma.
Wordforms canappear either as-is (word) or in quotation marks("word").
Quotation marks are required to dis-ambiguate queries where the wordform matches afeature name, such as a query for the literal wordNOUN instead of tokens with the NOUN POS tag.Words can be searched by lemma using the L= pre-fix: for example, the query L=be matches all tokenswith the lemma (to) be.Words can also be restricted based on anytags, including POS and detailed morphologi-cal features.
These tags can be included in thequery as-is: for example, the query for search-ing all pronouns is simply PRON.
All wordrestrictions can also be negated, combined ar-bitrarily using the and and or logic operators,and grouped using parentheses.
For example,(L=climb|L=scale)&VERB&!Tense=Pastsearches for tokens with either climb or scale aslemma whose POS is verb and that are not in thepast tense.3.2 Dependency relationsDependency relations between words are queriedwith the dependency operators (< and >), option-ally combined with the dependency relation name.For example, the query to find tokens governedby an nsubj relation is <nsubj , and tokensgoverning an nsubj relation can be searched with>nsubj .
The left-most word in the searchexpression is always the target, and is identified inthe results.
While the two preceding nsubj queriesmatch the same graphs, they thus differ in the tar-get token.
To constrain the linear direction of thedependency relation, the operators @R and @L canbe used, where e.g.
>nsubj@R means that thetoken must have a nsubj dependent to the right.Negations and logical operators can be appliedto the dependency relations in the same manner asto words.
There are two different ways to negaterelations; the whole relation can be negated, as in!>nsubj , which means that the tokens maynot have an nsubj dependent (not having any depen-dent is allowed), or only the type can be negated,as in >!nsubj , where the token must havea dependent but it cannot be nsubj.
Tokens whichhave either a nominal or clausal subject dependentcan be queried for with the logical or operator:>nsubj|>csubj .Subtrees can be identified in the search expres-sion by delimiting them with parentheses.
For ex-ample, in >nmod ( >nmod ), the target to-ken must have a nominal modifier which also hasa nominal modifier (i.e a chain of two modifiers),whereas in >nmod >nmod the token musthave two (different) nominal modifiers.
Note thatqueries such as >nmod >nmod are inter-preted so that all sibling nodes in the query must beunique in the match to guarantee that the restrictionis not satisfied twice by the same token in the targettree.There is no restriction on the complexity of sub-trees, which may also include any number of nega-tions and logical operators.
It is also possible tonegate entire subtrees by placing the negation op-erator !
before the opening parenthesis.523.3 SentenceThe more general properties of the sentence insteadof just the properties of certain token, can bequeried using the operators +, match a sentenceif both sets are not empty and ->, universalquantification ?
operators.
For example, if wewanted to find a sentence where all subject de-pendents are in the third person, we could query( <nsubj ) -> (Person=3 <nsubj ).And to find sentences where we have a tokenwith two nmod dependents and a word dogsomewhere in the sentence we could query( >nmod >nmod ) + "dog".4 Design and implementationThe scalability and speed of the system stem fromseveral key design features, the most important ofwhich is the that every query is used to generatean algorithmic implementation that is then compiledinto native binary code, a process which takes typi-cally less than a second.
Search involves the follow-ing steps:1) The user query is translated into a sequence ofset operations (intersection, complement, etc.)
overtokens.
For example, a query for tokens that are inthe partitive case and dependents of a subject rela-tion is translated into an intersection of the set ofpartitive case tokens and the set of subject depen-dents.
Similarly, negation can in most cases be im-plemented as the set complement.
The code im-plementing these operations is generated separatelyfor each query, making it possible to only includethe exact operations needed to execute each specificquery.2) The code implementing this sequence of op-erations is translated into C by the Cython compiler.The set operations are implemented as bit operationson integers (bitwise and, or, etc.)
and can thus be ex-ecuted extremely fast.3) An SQL statement is generated and used tofetch from a database the token sets that are neededto evaluate the query.
The query retrieves the to-ken sets only for those trees containing at least onetoken meeting each of the restrictions (dependencyrelations, morphological tags, etc.
).4) The sequence of set operations implementingthe query is used to check whether their configura-tion matches the query.
For each match, the wholetree is retrieved from the database, reformatted andoutput in the CoNLL-U format.The data is stored in an embedded database as pre-computed token sets, with separate sets for all dif-ferent lemmas, wordforms, and morphological fea-tures.
These sets are stored as native integers witheach bit corresponding to a single token position ina sentence.
Since the vast majority of sentences areshorter than 64 words, these sets typically fit intoa single integer.
However, the system imposes noupper limit on the sentence length, using several in-tegers when necessary.The system uses SQLite as its database back-end and the software is written as a combination ofPython, Cython and C++.
Cython enables easy inte-gration of Python code with fast C-extensions, vitalto assure the efficiency of the system.
As it uses theembedded SQLite database, the system is fully self-contained and requires no server applications.In addition to the primary search system, we cre-ated a simple browser-based frontend to the querysystem that provides a dynamic visualization of theretrieved trees and the matched sections (Figure 1).This interface was implemented using the PythonFlask2framework and the BRAT annotation tool(Stenetorp et al, 2012).5 BenchmarksOur graph-search tool is tested and timed on threedifferent machines and two datasets.
Evaluationplatforms include a server-grade machine with goodresources, a standard laptop computer and a smallnetbook with limited performance.
To comparethe efficiency of our system to the state-of-the-arttreebank searching solutions, we employ ICARUS(G?artner et al, 2013) search and visualization toolwhich also focuses on querying dependency trees.ICARUS system loads the data into the computer?smain memory, while our system uses a database,which is optimized by caching.
The comparison ofour graph-search tool and the ICARUS baseline isrun on server machine with a dataset of roughly 90Ktrees.Three test queries are chosen so that bothsystems support the functionality needed in or-2http://flask.pocoo.org/53Figure 1: Web interface showing trees in Finnish.der to run the tests.
The first query is astraightforward search for all subject dependents( <nsubj ) and the second query adds a lex-ical restraint to it and requires the lemma to beI (L=I <nsubj ).
The third query is muchmore complex and is inspired by an actual linguis-tic use case to find examples of an exceptionallyrare transitive verb usage in Finnish.
The queryincludes chaining of dependencies and a negation( >nsubj (Case=Gen > ) >dobj ...!
<xcomp ).Query 1 Query 2 Query 3ICARUS 2m30s 2m30s 2m30sSETS 1.61s 1.2s 2.18sTable 3: The speed of our system compared to the base-line on the three different test queries when a treebank ofabout 90K sentences is used.As can be seen from Table 3, when our system andthe baseline system are tested on the server machineusing the three example queries our system clearlyoutperforms the baseline.
The speed of the baselineseems to be relatively unaffected by the complexityof the query, suggesting a bottle-neck somewhereelse than tree-verification.
It should be noted thatthese measurements are only to illustrate the relativespeed and performance differences, and are subjectto change depending on system cache.
Due to theirarchitecture, neither system has a major advantage inthe use of memory and the results are broadly com-parable.Our system is also tested on a standard laptop, anda netbook using the same three queries and the sameinput corpus.
The first test query was finished by anetbook in 37 seconds, the third query, most com-plex of them, was finished in 13.5 seconds.
The lap-top finished the first query in 16 seconds, the secondin 7 seconds and the third in 16 seconds.As our system is meant for searching from verylarge corpora, we test it with a parsebank of 10 mil-lion trees and over 120 million tokens.
A variant ofthe test query number 3, the most complex of thequeries, was executed in time between 1m52s and48s (depending the system cache).
The test query 1took from 5m10s to 4m30s and the lexicalized ver-sion (query 2) from 12s to 9s.
The test queries wereperformed on the same server-machine as the runsshown in Table 3.54Since our system uses pre-indexed databases thedisk space needed for holding the data slightly in-creases.
Indexing the 90K sentence treebank usedin our tests requires about 550M of free disk space,whereas indexing the 10 million sentence parsebankuses 35G of space.6 ConclusionWe have presented a syntax query system especiallygeared towards very large treebanks and parsebanks.In the future, we will implement support for graphqueries, e.g.
coindexing of the tokens, since manytreebanks have multiple layers of dependency struc-tures.
Related to this goal, we aim to include sup-port for properties of the tokens and dependencies,for example the annotation layer of the dependency,word sense labels, etc.The full source code of the system is available un-der an open license at https://github.com/fginter/dep_search.
Additionally, we main-tain a server for public online search in all avail-able Universal Dependencies treebanks (Nivre etal., 2015) at http://bionlp-www.utu.fi/dep_search.AcknowledgmentsThis work was supported by the Kone Foundationand the Emil Aaltonen Foundation.
Computationalresources were provided by CSC ?
IT Center for Sci-ence.References[G?artner et al2013] Markus G?artner, Gregor Thiele,Wolfgang Seeker, Anders Bj?orkelund, and JonasKuhn.
2013.
Icarus ?
an extensible graphical searchtool for dependency treebanks.
In Proceedings ofDemonstrations at ACL?13, pages 55?60.
[Levy and Andrew2006] Roger Levy and Galen Andrew.2006.
Tregex and Tsurgeon: tools for querying andmanipulating tree data structures.
In Proceedings ofLREC?06).
[Nivre et al2015] Joakim Nivre, Cristina Bosco, JinhoChoi, Marie-Catherine de Marneffe, Timothy Dozat,Rich?ard Farkas, Jennifer Foster, Filip Ginter, YoavGoldberg, Jan Haji?c, Jenna Kanerva, Veronika Laip-pala, Alessandro Lenci, Teresa Lynn, ChristopherManning, Ryan McDonald, Anna Missil?a, Simon-etta Montemagni, Slav Petrov, Sampo Pyysalo, Na-talia Silveira, Maria Simi, Aaron Smith, Reut Tsarfaty,Veronika Vincze, and Daniel Zeman.
2015.
Universaldependencies 1.0.
[Rohde2004] Douglas L. T. Rohde, 2004.
TGrep2 UserManual.
Available at http://tedlab.mit.edu/?dr/Tgrep2.
[Stenetorp et al2012] Pontus Stenetorp, Sampo Pyysalo,Goran Topi?c, Tomoko Ohta, Sophia Ananiadou, andJun?ichi Tsujii.
2012.
Brat: a web-based tool for nlp-assisted text annotation.
In Proceedings of Demon-strations at EACL?12, pages 102?107.55
