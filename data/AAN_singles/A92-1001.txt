Deriving Database Queries from Logical Formsby Abductive Definition ExpansionManny Rayner  and  H iyan  A lshawi  *SR I  In ternat iona lCambr idge  Computer  Sc ience Research  Cent re23 Mil lers Yard ,  Cambr idge  CB2 1RQ,  U.K.manny?cam, sri.
com hiyan~cam, sri.
tomAbst ractThe paper describes a principled approach tothe problem of deriving database queries fromlogical forms produced by a general NL in-terface.
Our method attempts to construct adatabase query and a set of plausible assump-tions, such that the logical form is equivalentto the query given the assumptions.
The do-main information eeded is provided as declar-ative meaning postulates, including "defini-tional equivalences".
The technical basis forthe approach is that a "definition" of the formHead A Conditions ~ Body can be read pro-cedurally as "Expand Head to Body if it oc-curs in an environment where Conditions canbe inferred".
The "environment" is providedby the other conjuncts occurring together withHead in the original ogical form, together withother meaning postulates and the contents ofthe database.
The method has been imple-mented in CLARE, a language and reasoningsystem whose linguistic component is the SRICore Language Engine.1 In t roduct ionThe basic question addressed in this paper is that ofhow to connect a general NL interface and a back-endapplication in a principled way.
We will assume herethat the interface takes input in a natural anguage andproduces a representation in some kind of enriched first-order logic, and that the application is some kind of rela-tional database; this is a common and important situa-tion, and it is well-known that the problems involved arenon-trivial.
The techniques used apply equally well toother NLP applications which involve mapping linguisticconcepts to knowledge base predicates.
Concrete xam-ples in the paper will be taken from the SRI CLAREsystem, working in the domain of project resource man-agement.
CLARE is a combined natural language and*CLARE is being developed as part of a collaborativeproject involving BP Research, British Aerospace, BritishTelecom, Cambridge University, SRI International nd theUK Defence Research Agency.
The project is funded in partby the UK Department of Trade and Industry.reasoning system which includes the Core Language En-gine (or CLE, Alshawi 1992) as its language component.The CLE produces emantic interpretations of sentencesin a notation called Quasi Logical Form.
For databaseinterface applications, the semantic interpretations areconverted into fairly conventional logical forms beforequery derivation takes place.A NL interface like CLARE which is general (ratherthan being tailored to the application) will produce log-ical forms that essentially mirror the linguistic contentof the input.
It will thus normally contain what mightbe called "linguistic" predicates (i.e.
word senses): forexample, the logical form for a query like($1) List all payments made to BT during 1990.would be expected to contain predicates correspondingdirectly to payment, make and during.
An appropriatedatabase query, on the other hand, might be a commandto search for "transaction" tuples where the "payee" fieldwas filled by "BT", and the "date" field by a date con-strained to be between 1st January and 31st December,1990.
The differing nature of the two representations canlead to several possible kinds of difficulties, depending onhow the "linguistic" and "database" representations areconnected.
There are three in particular that we willdevote most of our attention to in what follows:1.
A query can be conceptually outside the database'sdomain.
For example, if "payments" in (S1) is re-placed by "phone-calls", the interface should be ableto indicate to the user that it is unable to relate thequery to the information contained in the database.2.
A query can be contingently outside the database'sdomain.
Thus if "1990" is replaced by "1985", itmay be possible to derive a query; however, if thedatabase only contains records going back to 1989,the result will be an empty list.
Presenting this tothe user without explanation is seriously misleading.3.
A query may need additional implicit assumptionsto be translatable into database form.
Asking (S1)in the context of our example Project ResourceManagement domain, it is implicitly understoodthat all payments referred to have been made bySRI.
If the user receives no feedback describing theassumptions that have been made to perform thetranslation, it is again possible for misunderstand-ings to arise.1One attractive way to attempt o effect the connec-tion between LF and database query is to encode thedatabase as a set of unit clauses, and to build an inter-preter for the logical forms, which encodes the relationsbetween linguistic and database predicates as "rules" or"meaning postulates" written in Horn-clause form (cf.e.g.
McCord 1987).
Anyone who has experimented withthis scheme will, however, know that it tends to suf-fer from all three of the types of problem listed above.This is hardly surprising, when one considers that Horn-clauses are "if" rules; they give conditions for the LF'sbeing true, but (as pointed out in Konolige 1981), theylack the "only if" half that says when they are false.It is of course possible to invoke the Closed World As-sumption (CWA); in this interpretation, finite failure isregarded as equivalent o negation.
Unfortunately, ex-perience also shows that it is extremely difficult to writemeaning postulates for non-trivial domains that are validunder this strict interpretation.For these reasons, Scha (1983) argues that approacheswhich express the connection between LF and databasequery in terms of first-order logic formulas are unpromis-ing.
Instead, previous approaches to query derivationwhich attempt to justify equivalence between queriesand semantic represenations have been limited (at leastin implemented systems) to employing restricted formsof inference.
Examples are the type inference used inPHLIQA (Bronnenberg et al1980) and Stallard's 're-cursive terminological simplification' (Stallard 1986).In this paper we will show how a more general de-ductive approach can be taken.
This depends on codingthe relationship between LF and database forms not asHorn-clauses but as "definitional equivalences", explicitif-and-only-if rules of a particular form.
Our approachretains computational tractabil ity by limiting the wayin which the equivalences can take part in deductions,roughly speaking by only using them to perform directedexpansions of definitions.
However we still permit non-trivial goal-directed domain reasoning in justifying queryderivation, allowing, for example, the translation of anLF conjuct to be influenced by any other LF conjuncts,in contrast o the basically local translation in PHLIQA.This approach deals with the first two points above with-out recourse to the CWA and simultaneously allows aclean integration of the "abductive" reasoning needed totake care of point 3.
The main technical problems to besolved are caused by the fact that the left-hand sides ofthe equivalences are generally not atomic.The rest of the paper is organized as follows.
The mainconcepts are introduced in sections 2 and 3, followed bya simple example in section 4.
Section 5 discusses therole of existential quantification in equivalences.
In sec-tion 6 we introduce abductive reasoning, and relate thisto the problems discussed above.
Section 8 then brieflydescribes issues related to implementing efficient searchstrategies to support the various kinds of inference used,and in section 9 we present an extended example showinghow an LF can be successively reduced by equivalencesinto DB query form.2 Query  Trans la t ion  as  Def in i t ionExpans ionThe task which the CLARE database interface carriesout is essentially that of translating a logical formula inwhich all predicates are taken from one set of symbols(word sense predicates) into a formula in which all pred-icates are taken from another set (database relations)and determining the assumptions under which the twoformulae are equivalent.
Since database relations aregenerally more specific than word senses, it will oftenbe the case that the set of assumptions i non-empty.The same mechanism is used for translating both queriesand assertions into database form; moreover, the declar-ative knowledge used is also compiled, using a differ-ent method, so as to permit generation of English fromdatabase assertions, though further description of this isbeyond the scope of the paper.The main body of the declarative knowledge used iscoded in a set of equivalential meaning postulates inwhich word sense predicates appear on one side anddatabase relations appear on the other.
(In fact, inter-mediate predicates, on the way to translating from lin-guistic predicates to database predicates may appear oneither side.)
The translation process then corresponds toabductive reasoning that views the meaning postulatesas conditional definitions of the linguistic predicates interms of database (or intermediate) predicates, the con-ditions being either discharged or taken as assumptionsfor a particular derivation.
We will therefore refer to th~translation process as 'definition expansion'.If the left-hand sides of equivalences needed to be arbi.trary formulas, the whole scheme would probably be im-practical.
However, experimentation with CLARE ha~lead us to believe that this is not the case; sufficient ex-pressive power is obtained by restricting them to be ncmore complex than existentially quantified conjunction,of atomic formulas.
Thus we will assume that equivalen.tim meaning postulates have the general form 1(3yl, Y2,..--P1 A P2 A P3...) *--* P '  (1'In the implementation these rules are written in a notation illustrated by the following example,ex is ts  ( \ [Event \ ]  ,and(work_onl (Event, Person, Project),pro jec t  l (P ro j  ec t ) ) )  <->DB_PRO JECT_MEMBER(Proj ec t ,  Person)in which work_onl and pro jec t l  are linguistic predi.cates and DB_PROJECT_MEMBER is a database relation (w(will adhere to the convention of capitalizing names oldatabase relations).The attractive aspect of this type of equivalence stem:from the fact that it can be given a sensible interpre.tation in terms of the procedural notion of "definition-expansion".
Neglecting for the moment the existentiaquantification, the intuitive idea is that is that (1) carbe read as "P1 can be expanded to P '  if it occurs ira Quantification over the yl on the left-hand side will offerin practice be vacuous.
In this and other formulas, we assum(implicit universal quantification over free variables.2an environment where /)2 ^  P3... can be inferred".
The"environment" is provided by the other conjuncts occur-ring together with P1 in the original logical form, to-gether with other meaning postulates and the contentsof the database.
This provides a framework in whicharbitrary domain inference can play a direct role in jus-tifying the validity of the translation of an LF into aparticular database query.3 T rans la t ion  SchemasThe ideas sketched out above can be formalised as theinference rules (2), (3) and (4):(3yl, Y2, ....P1 A P2 ^  P3...) ~ P '  AConds ~ O(P2 h Pa...)Conds --+ (O(P1) +-+ P') (2)where 0 is a substitution that replaces each Yi with adifferent unique constant.Conds A Q ---, (P *--, P')Conds --+ (P A Q +-+ P' A Q) (3)Co.ds (O( P) O( P') ) )Conds --+ (3x.P +-+ 3x.P'))  (4)where 0 substitutes a unique constant for x.In each of these, the formulas before the :=> are thepremises, and the formula after the conclusion.
The in-ference rules can be justified within the framework ofthe sequent calculus (Robinson 1979), though space lim-itations prevent us from doing so here.
(2) is the basecase: it gives sufficient conditions for using (1) to ex-pand P1 (the head of the definition) to P '  (its body).The other formulas, (3) and (4), are the main recursivecases.
(3) expresses expansion of a conjunction in termsof expansion of one of its conjuncts, adding the otherconjunct to the environment of assumptions as it doesso; (4) expresses expansion of an existentially quantifiedform in terms of expansion of its body, replacing thebound variables with unique constants.
We will refer toinference rules like (3) and (4) as expansion-schemas orjust schemas.
One or more such schema must be givenfor each of the logical operators of the representation lan-guage, defining the expansion of a construct built withthat operator in terms of the expansion of one of its con-stituents.The central use of the equivalences i  thus as truth-preserving conditional rewriting rules, which licencetranslation of the head into the body in environmentswhere the conditions hold.
There is a second use of theequivalences as normal Horn-clauses, which as we soonshall see is also essential to the translation process.
Anequivalence of the form/'1 ^ P2  ^ .
.
.
~ 01^02 A .
.
.implies the validity, for any i, of all Horn-clauses eitherof the formPi ~- Q1 ^ Q2 A. .
.orQi ' , - -P IAP2A.
.
.We will refer to these, respectively, as normal and back-ward Horn-clause readings of the equivalence.
For exam-ple, the ruleand(manl(X) ,employeel(X)) <->exists ( \[HasCar\], employee (X ,m, HasCar) )produces two normal Horn-clause readings,manl(X) <- employee(X,m,HasCar).employeel(X) <- employee(X,m,HasCar).and one backward Horn-clause reading,employee(X,m,skl(X))  <- manl(X),employeel(X).where ski is a Skolem function.
Note that in the equiv-alential reading, as well as in the backward one, it isessential to distinguish between existential and univer-sal quantification of variables on the left-hand side.
Theequivalential reading of a rule of typep(X,Y) <-> q(Y)licences, for example, expansion of p(a,b) to q(b); thejustification for this is that q(b) implies p(X,b) for anyvalue of X.
However, if the rule is changed toexisgs(\[X\],p(X,Y)) <-> q(Y)the expansion is no longer valid, since q(b) only impliesthat p(X,b) is valid for some value of X, and not nec-essarily for a.
This pair of examples should clarify whythe constants involved in schema (2) must be unique.We are now in a position to explain the basic expan-sion process; in the interests of expositional clarity, wewill postpone mention of the abductive proof mecha-nism until section 6.
Our strategy is to use (2) andthe expansion-schemas as the kernel of a system that al-lows expansion of logical forms, using the equivalencesas expandable complex definitions.The actual process of expansion of a complex formulaF is a series of single expansion steps, each of whichconsists of the expansion of an atomic constituent of F.An  expansion step contains the following sub-steps:Recurse: descend through F using the expansion-schemas, until an atomic sub-formula A is reached.During this process, an environment E has been ac-cumulated in which conditions will be proved, andsome bound variables will have been replaced byunique constants.Trans late:  find a rule Byi.
(H A C) ~ B such that (i)H (the 'head') unifies with A with m.g.u.
0, and(ii) 0 pairs the ~Yi only with unique constants in Aderiving from existentially bound variables.
If it isthen possible to prove 0(C) in E, replace A withO(B).Simpli fy:  if possible, apply simplifications to the result-ing formula.4 A S imple  ExampleWe now present a simple example to illustrate how theprocess works.In CLARE, the sentence ($2)(S2) Do any women work on CLARE?3receives the LFexists( \[C,E\] ,and (woman I (C), work onl (E, C, clare) ) )This has to be mapped to a query which accesses twodatabase relations, DB_EMPLOYEE(Emp1,Sex,HasCar)and DB_PROJECT_MEMBER(Emp1,Project); the desiredresult is thus:exists(\[C,H\],and (DB_ EMP LOYEE ( C, w, H ),DB_PRO JECT_MEMBER (clare, C) ) )(Sex can be w or m).
The most clearly non-triviMpart is justifying the conversion between the lin-guistic relation womanl(X) and the database relationDB_EMPLOYEE(X,w,_).
Even in the limited PRM do-main, it is incorrect o state that "woman" is equivMentto "employee classed as being of female sex"; there arefor example large numbers of women who are listed inthe DB_PAYEE relation as having been the recipients ofpayments.
It is more correct to say that a tuple of typeDB EMPLOYEE (X, w, _) is equivalent to the conjunction oftwo pieces of information: firstly that X is a woman, andsecondly that she is an employee.
This can be capturedin the ruleand (womanl (Person),employeel (Person)) <->exists ( \[HasCar\] ,and (DB_EMPLOYEE (Person, w, HasCar) ) ) (EQI)In the left-to-right direction, the rule can be read as"womanl (X) translates to DB_EMPLOYEE(X, w,_), in con-texts where it is possible to prove employeel(X).
"For the rule to be of use in the present example, wemust therefore provide a justification for employeel (X) 'sholding in the context of the query.
The simplest way toensure that this is so is to provide a Horn-clause meaningpostulate,employeel (X) <-DB_PROJECT_MEMBER(Proj ect, X).
(HCI)which encodes the fact that project members are em-ployees.Similarly, we will need an equivalence rule to convertbetween work_onl and DB_PROJECT_MEMBER.
Here thefact we want to state is that project-members are pre-cisely people who work on projects, which we write asfollows:exists ( \[Event\],and(work_onl (Event, Person, Project ),pro jec t  l (P ro jec t ) ) )  <->DB_PRO JECT_MEMBER(Pro j ect, Person) (EQ2)We will also make indirect use of the rule that statesthat projects are objects that can be found in the firstfield of a DB_PROJECT tuple,project l(Proj) <->exists ( \[ProjNum, Start ,End\] ,DB_PROJECT(Pro3, ProjNum, Start, End) ) (EQ3)since this will allow us to infer (by looking in thedatabase) that the predicate pro jec t  1 holds of c la re .Two expansions now produce the desired transforma-tion; in each, the schemas (4) and (3) are used in turnto reduce to the base case of expanding an atom.
Re-member that schema (4) replaces variables with uniqueconstants; when displaying the results of such a trans-formation, we will consistently write X* to symbolize thenew constant associated with the variable X.The first atom to be expanded is womanl(C*),and the corresponding environment of assumptionsis {work_onl(E*,C*,clare)}.
womanl(C*) unifieswith the head of the rule (EQ1), making its con-ditions employeel(C*) .
Using the Horn-clausemeaning postulate (HCl), this can be reduced tcDB_PROJECT_MEMBER(Proj ec t ,  C*).
Note that C* in thi,formula is a constant, while P ro jec t  is a variable.
Thi,,new goal can now be reduced again, by applying the rul~(EQ2) as a backwards Horn-clause, toand(work_onl (Event, C*, Project) ,project I (Project ) ) ),The first conjunct can be proved from the assumptionsinstantiating Pro jec t  to c la re ;  the second conjunct ca*now be derived from the normal Horn-clause reading orule (EQ3), together with the fact that c la re  is listed aa project in the database.
This completes the reasoninlthat justifies expanding womanl (C) in the context of thiquery, toexists ( \[HasCar\],and(DB_EMPLOYEE ( C, w, HasCar) ) )The second expansion is similar; the atom to be e~panded here is work_onl(E*,C*,clare), and the environment of assumptions is {womanl(C*)}.
Now thrule (EQ2) can be used; its conditions after unifcation with the head are pro jec t l ( c la re ) ,  the wlidity of which follows from another application c(EQ3).
So work onl(E,C,clare) can be expanded tDB_PROJECT_MEMBEK(clare,C), giving the desired r~sult.5 Ex is tent ia l  Quant i f i ca t ionWe have so far given little justification for the complic~tions introduced by existential quantification on the lefthand sides of equivalences.
These become important iconnection with the so-called "Doctor on Board" pro\[lem (Perrault and Grosz, 1988), which in our domaican be illustrated by a query like ($3),(S3) Does Mary have a car?This receives the LFexists(\[C,E\] ,and(carl  (C) , havel (E ,mary, C) ) ) )for which the intended database query will beexists ( IS\],DB_EMPLOYEE (mary, S, y) )if Mary is listed as an employee.
However, we also d,mand that a query like ($4)(S4) Which car does Mary have?should be untranslatable, since there is clearly no wayextract the required information from the DB_EMPLOYErelationship.The key equivalence is (EQ4)4exists(\[E,C\] ,and( carl (C) ,and(havel (E,P, C),employeel (P))) <->exist s ( IS\], DB_EMPLOYEE(P, S, y) ) (EQ4)which defines the linguistic predicate car l .
When usedin the context of ($3), (EQ4) can be applied in exactlythe same way as (EQ2) and (E{~3) were in the previ-ous example; the condition have l (E, P, C) will be provedby looking at the other conjunct, and employeel (mary)by referring to the database.
The substitution used tomatch the car l  predication from the LF with the head of(EQ4) fulfills the conditions on the t ranslate step of theexpansion procedure: the argument of car l  is bound byan existential quantifier both in the LF and in (EQ4).
In($4), on the other hand, car l  occurs in the LF in a con-text where its argument is bound by a f ind  quantifier,which is regarded as a type of universal.
The matchingsubstitution will thus be illegal, and translation will failas required.6 Abduct ive  Expans ionWe now turn to the topic of abductive expansion.
Aspointed out in section 1, it is normally impossible to jus-tify an equivalence between an LF and a database querywithout making use of a number of implicit assumptions,most commonly ones stemming from the hypothesis thatthe LF should be interpretable within the given domain.The approach we take here is closely related to that pio-neered by Hobbs and his colleagues (Hobbs et a188).
Weinclu~le declarations asserting that certain goals may beassumed without proof during the process of justifyingconditions; each such declaration associates an assump-tion cost with a goal of this kind, and proofs with lowassumption cost are preferred.
So for example the mean-ing postulate relating the linguistic predicate paymentland the intermediate predicate t ransact ion  isand (payment I (Trans),payment f rom_SRI(Trans))  <->exist s ( \[Cheque, Dat e, Payee\],transaction(Trans, Cheque ,Date, Payee) )) (EQS)"transactions are payments from SRI"and there is also a Horn-clause meaning postulatepayment_from_SRI (X) <-payment s_ re f  e r red_ t  o_are_f  rom_SRI.and an assumptiondeclarationas sume (payment s_re f  e r red_ t  o_are_f  rom_SRI,cost (0))The advantage of this mechanism (which may at firstsight seem rather indirect) is that it makes it possi-ble explicitly to keep track of when the assumptionpayments._veferred_to_are_from_SRI has been used inthe course of deriving a database query from the originalLF.
Applied systematically, it allows a set of assumptionsto be collected in the course of performing the transla-tion; if required, CLARE can then inform the user as totheir nature.
In the current version of the PRM applica-tion, there are about a dozen types of assumption thatcan be made.
Most of these are similar to the one shownabove: that is to say, they are low-cost assumptions thatcheques, payments, projects and so on are SRI-related.One type of assumption, however, is sufficiently dif-ferent as to deserve xplicit mention.
These are relatedto the problem, mentioned in Section 1, of queries "con-tingently" outside the database's domain.
The PRMdatabase, for instance, is limited in time, only con-taining records of transactions carried out over a spec-ified eighteen-month period.
Reflecting this, mean-ing postulates distinguish between the two predicatestransaction and DB_TRANSACTION, which respectivelyare intended to mean "A transaction of this type tookplace" and "A transaction of this type is recorded in thedatabase".
The meaning postulate linking them isand(transaction(Id, CNum, Date, Payee),transaction_data_available(Date)) <->DB_TRANSACTION (Id~ CNum, Dat e, Payee) (EQ6)transaction_data_available is defined by the furtherpostulatetransaction_data_available (Date) <-and(c_before (date(17,8,89) ,Date),c_before(Dat e, date (31,3,91))) (HC2)The interesting thing about (HC2) is that the infor-mation needed to prove the condition transaction-_data_available(Date) is sometimes, though not al-ways, present in the LF.
It will be present in a querylike ($I), which explicitly mentions a period; there arefurther axioms that allow the system to infer in these cir-cumstances that the conditions are fulfilled.
However, aquery like ($5),($5) Show the largest payment to Cow's Milk.contains no explicit mention of time.
To deal with sen-tences like ($5), there is a meaning postulatetransaction_data_available(X) <-payments_referred_to made_between( 17/8/89,31/3/91) .with an associated assumption declarationas sume (payments_referred_to_made_between( 17/8/89,31/3/91) ,cost (15)).The effect of charging the substantial cost of 15 unitsfor the assumption (the max imum permitted cost for anexpansion step being 20) is in practice strongly to pre-fer proofs where it is not used; the net result from theuser's perspective is that s/he is informed of the contin-gent temporal limitation of the database only when itis actually relevant to answering a query.
This has ob-vious utility in terms of increasing the interface's user-friendliness.7 S impl i f i ca t ion  Us ing  Funct iona lIn fo rmat ionA problem arising from the definition-expansion pro-cess which we have so far not mentioned is that the5database queries it produces tend to contain a consid-erable amount of redundancy.
For example, we shallsee below in section 9 that the database query derivedfrom sentence (S1) originally contains three separateinstances of the transaction relation, one from eachof the original linguistic predicates paymentl ,  make2and dur ing l .
Roughly speaking, payraentl(Ev) ex-pands to t ransact ion(Ev  .
.
.
.
.
.
), make2(Ev,Ag,P,To)to t ransact ion(Ev ,  _, To,_) and during_Temporal (Ev,Date) to t ransact ion(Ev  .
.
.
.
.
Date); the databasequery will conjoin all three of these together.
It is clearlypreferable, if possible, to merge them instead, yielding acomposite predication t ransact  ion (Ev,_, To,Dat e).Our framework allows an elegant solution to this prob-lem if a little extra declarative information is provided,specifically information concerning functional relation-ships in predicates.
The key fact is that t ransact ion  isa function from its first argument (the transaction iden-tifier) to the remaining ones (the cheque number, thepayee and the date).
The system allows this informa-tion to be entered as a "function" meaning postulate inthe formfunct ion (transact ion ( Id, ChequeNo, Payee, Date ),\[Id\] -> \[ChequeNo,Payee,Date\])This is treated as a concise notation for the meaningpostulatet ransact ion( i ,  cl, Pl, dl )( transact ion( i ,  c2, P2, d2 ) ~-~Cl -- c2 A Pl = P2 A dl = d2)which is just a conditional form of the equivalentialmeaning postulates already described.
It is thus pos-sible to handle "merging" simplification of this kind, aswell as definition expansion, with a uniform mechanism.In the current version of the system, the transformationprocess operates in a cycle, alternating expansions fol-lowed by simplifications using the same basic interpreter;simplification consists of functional "merging" followedby reduction of equalities where this is applicable.The simplification process is even more importantwhen processing assertions.
Consider, for example, whatwould happen to the pair of sentences ($6) - ($7) withoutsimplification:(S6) Clara is an employee who has a car.
($7) Clara is a woman.
($6) translates into the database formexists(\[A,B\] ,DB_EMPLOYEE ( clara, A, y) )(The second field in DB_EMPLOYEE indicates sex, and thethird whether or not the employee has a company car).This can then be put into Horn-clause form asDB_EMPLOYEE (c la ra ,  skl ,y)and asserted into the Prolog database.
Since Clara isnow known to be an employee, ($7) will produce theunit clauseDB_EMPLOYEE ( clara, w, sk2)The two clauses produced would contain all the infor-mation entered, but they could not be entered into a re-lational database as they stand; a normal database hasno interpretation for the Skolem constants kl  and sk2.However, it is possible to use function information tomerge them into a single record.
The trick is to arrangethings so that the system can when necessary recoverthe existentially quantified form from the Skolemizedone; all assertions which contain Skolem constants arekept together in a "local cache".
Simplification of asser-tions then proceeds according to the following sequenceof steps:1.
Retrieve all assertions from the local cache.2.
Construct a formula A, which is their logical con-junction.3.
Let A0 be A, and let {sk l .
.
.
skn)  be the Skolemconstants in A.
For i = 1 ... n, let xi be a new vari-able, and let Ai be the formula 3xi .A i_ l  \[ski/xi\], i.e.the result of replacing ski with xi and quantifyingexistentially over it.4.
Perform normal function merging on Am, and callthe result A'.5.
Convert A' into Horn-clause form, and replace theresult in the local cache.In the example above, this works as follows.
After ($6)and ($7) have been processed, the local cache containsthe clausesDB_EMPLOYEE ( c la ra ,  sk 1, y)DB_EMPLOYEE ( clara, w, sk2)A = A0 is then the formulaand (DB EMPLOYEE (c la ra ,  sk 1, y)DB_EMPLOYEE (c la ra ,  w, sk2) )and A2 isexists(\[Xl,X2\]and (DB EMPLOYEE ( c la ra ,  X 1, y)DB_EMPLOYEE (c la ra ,  w, X2) )Since DB_EMPLOYEE is declared functional on its first ar-gument, the second conjunct is reduced to two equalities:giving the formulaexists ( \[Xl, X2\]and (DB_EMPLOYEE ( clara, X I, y)and(Xl = w,y = x2))which finally simplifies to A ',DB_EMPLOYEE (clara, w, y)a record without Skolem constants, which can be addedto a normal relational database.8 Search  Strategies for DefinitionExpansionThis section describes the problems that must be solvedat the implementation level if the definition-expansionscheme is to work with acceptable fficiency.
The struc-ture of the top loop in the definition-expansion process is6 6roughly that of a Prolog meta-interpreter, whose clausescorrespond to the "expansion-schemas" described in sec-tion 2.The main predicate in the expansion interpreter con-tains an argument used to pass the environment ofassumptions, which corresponds to the Conds in theschemas above.
The interpreter successively reducesthe formula to be expanded to a sub-formula, possiblyadding new hypotheses to the environment of assump-tions.
When an atomic formula is reached, the inter-preter attempts to find an equivalence with a match-ing head (where "matching" includes the restrictions onquantification described at the end of section 2), and ifit does so then attempts to prove the conditions.
If aproof is found, the atom is replaced by the body of theselected equivalence.The computationally expensive operation is that ofproving the conditions; since inference uses the equiva-lences in both directions, it can easily become very inef-ficient.
The development of search techniques for mak-ing this type of inference tractable required a significanteffort, though their detailed description is beyond thescope of this paper.
Very briefly, two main strategies areemployed.
Most importantly, the application of "back-ward" Horn clause readings of equivalences i restrictedto cases similar to that illustrated in section 4, wherethere are dependencies between the expansion of two ormore conjuncts.
In addition to this, there are a num-ber of heuristics for penalizing expenditure of effort onbranches judged likely to lead to infinite recursion or re-dundant computation.For the project resource management domain, whichcurrently has 165 equivalence rules, the time taken forquery derivation from LF is typically between 1 and 10seconds under Quintus Prolog on a Sun Sparcstation 2.9 A Full ExampleIn this section, we will present a more elaborate illustra-tion of CLARE's current capabilities in this area, show-ing how the process of definition expansion works for thesentence (S1).
This initially receives an LF which aftersome simplification has the formfind( \[PayEv\] ,exist s ( \[Payer, MakeEv\] ,and (payment I (PayEr),and (make2 (MakeEv, Payer, PayEr, bt ),duringl (PayEr,interval(date(1990, I, 1)) ,date(1990,12,31))) ) )As already indicated, the resulting database querywill have as its main predicate the relation DB_TRAN-SACTION ( Id ,  ChequeNo, Dat e, Payee).
We will also needan evaluable binary predicate cbefore ,  which takes tworepresentations of calendar dates and succeeds if the firstis temporally before the second.
The final query will beexpressed entirely in terms of these two predicates.The first step is to apply meaning postulates which re-late the linguistic predicates paymentl ,  make2 to the in-termediate predicate t ransact ion .
Recall, as explainedin section 6 above, that transaction is distinct fromDB_TRANSACTION.
The relevant postulates areand (payment 1( Id ) ,payment_from_SRI( Id))  <->exists(\[C,D,Payee\] ,transaction( Id, C, D, Payee) ) (EQT)'CA payment from SRI is something that enters into atransaction relation as its first argument".and(make2 (Event, As sumed_SRl, Payment, Payee),and (payment_from_SRl (Event),transactionl (Payment)) ) <->ex is ts  ( \[C ,D\],and(transact ion (Event, C, D, Paye e),Event = Payment)) (EQ8)"A payment is made by SRI to a payee if it and the payeeenter into a transaction relation as first and fourtharguments.
"Note that the atom payment_from_SRl(PayEv), oc-curring in the first two rules, will have to be proved usingan abductive assumption, as explained in section 6.
Af-ter (EQ7) and (EQ8) have been applied and the equalityintroduced by (EQ8) removed, the form of the query isfind( \[PayEv\],exists ( \[A ,B, C,D, El,and(transact ion (PayEv ,A, B, C),and (transact ion (PayEv ,D, E, bt) ),duringl (PayEr,interval(date(1990,1,1)) ,date(1990,12 ,31) ) ) ) )under the abductive assumption payments_re fer red-_to_are_from_SRI.The next rules to be applied are those that expandduringl.
The intended semantics of duringl (EI,E2)are "El and E2 are events, and the time associated withE1 is inside that associated with E2".
The relevant equiv-alences are nowduringl(EI,E2) <->exists(\[Ti,T2\] ,and(associated_time(El ,TI),and(associat ed_t ime (E2, T2),c_during (TI, T2) ) ) ) ) (EQ9)"The dur ing l  relation holds between E1 and E2 if andonly if the calendar event associated with E1 is insidethat associated with E2.
"and(associat ed_t ime (Id, Dat e),transactionl (Id)) <->exists(\[C,Payee,Y,M,D\],transaction (Id, C ,Date ,P) ) (EQ I0)"Date is the event associated with a transaction event ifand only if they enter into the t ransact ion  relation asthird and first arguments respectively.
"Applying (EQ9) and (EQ10) in succession, the queryis translated tofind( \[PayEr\],exists( \[Date,A,B,C,D,E,F,G\],and(transact ion (PayEv, A, B, C),and(transact ion (PayEv ,D, E ,bt ) ) ,and(transact ion (PayEv ,F,Date, G),7and(c_dur ing (Dat e,in terva l (date(1990,1 ,1 )  ) ,daze (1990,12,31) ) ) ) )The query is now simplified by exploiting the fact thatt ransact ion  is functional on its first argument: it ispossible to merge all three occurrences, as described insection 7, to produce the formfind( \[PayEr\] ,exists( \[ChequeId,Dat e\],and (trans act ion (PayEr, Cheque Id, Dat e, bt ),c_during(Date,interval (date( 1990, I, I) ),da te (1990,12 ,31) ) ) ) )Equivalences for temporal predicates then expand thesecond conjunct, producing the formf ind(  \[PayEr\] ,exists ( \[ChequeId,Date\] ,and (transact ion (PayEr, ChequeId, Date, bt),and(c_before (date (1990, I, I) ,Date),c_before(Date,date(1990,12,31))))))Finally, (EQ6) above is applied, to expand the interme-diate predicate t ransact ion  into the database relationDB_TKANSACTION.When the transaction predication is expanded,PayEv and Date are replaced by corresponding constantsPayEr* and Date*, as explained in section 2; the envi-ronment of assumptions i the set{c_before(date(1990,1 ,1 )  ,DaZe*),c_before(Date* ,date  (1990,12,31) }The relevant clauses are now (tiC2) and a meaning pos-tulate that encodes the fact that c_before is transitive,namelyc_before(Datel,Date3) <-c_before(Datel,Date2),c_before(Date2, Date3) (HC3)By chaining backwards through these to the assump-tions, it is then possible to prove that t ransact ion -_date_avai lab le(Date*)  holds, and expand to the finalformf ind(  \[PayEr\] ,exists ( \[ChequeId ,Date\] ,and (DB_TRANSACTI ON (PayEr, ChequeId, Date, bt ),and(c_before (dat e(1990, I, I) ,Date),c_before(Date,date(1990,12,31)))))This can be evaluated directly against the database;moreover, the system has managed to prove, underthe abductive assumption payments_referred_to_are_-from_SKI, that it is equivalent to the original query.10 Conc lus ions  and  Fur ther  D i rec t ionsWe believe that the definition-expansion mechanism pro-vides a powerful basic functionality that CLARE will beable to exploit in many ways, some of which we expectto begin investigating in the near future.
Several inter-esting extensions of the framework presented here arepossible, of which we mention two.Firstly, it can be the case that an expansion can onlybe carried out if a certain set of assumptions A is made,but that it is also possible to deduce the negation ofone of the assumptions in A from the original LF.
(Forexample, the query may refer to a time-period that isexplicitly outside the one covered by the database).
Ina situation of this kind it is likely that the user has amisconception concerning the contents of the database,and will appreciate being informed of the reason for thesystem's inability to answer.It is also fairly straight-forward to use the methodto answer "meta~level" questions about the database'sknowledge (cf.
Rayner and Jansen, 1987).
For exam-ple, Does the database know how many transactions weremade in July?
can be answered affirmatively (relativeto assumptions) if the embedded question How manytransactions were made in July?
can be expanded toan equivalent database query.
We expect to be able toreport more fully on these ideas at a later date.Re ferencesAlshawi, H., ed.
1992.
The Core Language Engine.Cambridge, Massachusetts: The MIT Press.Bronneberg, W.J.H.J., H.C. Bunt, S.P.J.
Landsbergen,R.J.H.
Scha, W.J.
Schoenmakers and E.P.C.
vanUtteren.
1980.
"The Question Answering SystemPHLIQAI".
In L. Bole (ed.
), Natural LanguageQuestion Answering Systems.
Macmillan.Hobbs, J.R., M. Stickel, P. Martin and D. Edwards.1988.
"Interpretation as Abduction".
Proceedingsof the 26th Annual Meeting of the Association forComputational Linguistics, 95-103Konolige, K. 1981.
The Database as Model: A Metathe-oretic Approch, SRI technical note 255.McCord, M.C.
1987.
"Natural Language Processing inProlog".
In A. Walker (ed.)
Knowledge Systemsand Prolog.
Addison-Wesley, Reading, MA.Perrault, C.R.
and B.J.
Grosz.
1988.
"Natural Lan-guage Interfaces".
In Exploring Artificial Intelli-gence: Survey Talks from the National Conferenceson Artificial Intelligence, Morgan Kaufmann, SanMateo.Rayner, M. and S. Janson.
1987.
"Epistemic Reason-ing, Logic Programming, and the Interpretation ofQuestions".
Proceedings of the 2nd InternationalWorkshop on Natural Language Understanding andLogic Programming, North-Holland.Robinson, J.A.
1979.
Logic: Form and Function.
Edin-burgh University Press.Scha, R.J.H.
1983.
Logical Foundations for Question An-swering, Ph.D. Thesis, University of Groningen, theNetherlands.Stallard, D.G.
1986.
A Terminological SimplificationTransformation for Natural Language Question-Answering Systems.
Proceedings of the 24th An-nual Meeting of the Association for ComputationalLinguistics, 241-246.8
