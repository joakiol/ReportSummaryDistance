Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 227?230,New York, June 2006. c?2006 Association for Computational LinguisticsIdentifying Perspectives at the Document and Sentence Levels UsingStatistical ModelsWei-Hao Lin?Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213 U.S.A.whlin@cs.cmu.eduAbstractIn this paper we investigate the problem ofidentifying the perspective from which adocument was written.
By perspective wemean a point of view, for example, fromthe perspective of Democrats or Repub-licans.
Can computers learn to identifythe perspective of a document?
Further-more, can computers identify which sen-tences in a document strongly convey aparticular perspective?
We develop sta-tistical models to capture how perspec-tives are expressed at the document andsentence levels, and evaluate the proposedmodels on a collection of articles on theIsraeli-Palestinian conflict.
The resultsshow that the statistical models can suc-cessfully learn how perspectives are re-flected in word usage and identify the per-spective of a document with very high ac-curacy.1 IntroductionIn this paper we investigate the problem of auto-matically identifying the perspective from which adocument was written.
By perspective, we mean?subjective evaluation of relative significance, apoint-of-view.?
For example, documents about thePalestinian-Israeli conflict may appear to be aboutthe same topic, but reveal different perspectives:?This is joint work with Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann, and supported by the Advanced Re-search and Development Activity (ARDA) under contract num-ber NBCHC040037.
(1) The inadvertent killing by Israeli forces ofPalestinian civilians ?
usually in the course ofshooting at Palestinian terrorists ?
isconsidered no different at the moral and ethicallevel than the deliberate targeting of Israelicivilians by Palestinian suicide bombers.
(2) In the first weeks of the Intifada, for example,Palestinian public protests and civiliandemonstrations were answered brutally byIsrael, which killed tens of unarmed protesters.Example 1 is written from a Israeli perspective; Ex-ample 2 is written from a Palestinian perspective .We aim to address a research question: can comput-ers learn to identify the perspective of a documentgiven a training corpus of documents that are writ-ten from different perspectives?When an issue is discussed from different per-spectives, not every sentence in a document stronglyreflects the perspective the author possesses.
For ex-ample, the following sentences are written by onePalestinian and one Israeli:(3) The Rhodes agreements of 1949 set them asthe ceasefire lines between Israel and the Arabstates.
(4) The green line was drawn up at the RhodesArmistice talks in 1948-49.Example 3 and 4 both factually introduce the back-ground of the issue of the ?green line?
withoutexpressing explicit perspectives.
Can computersautomatically discriminate between sentences thatstrongly express a perspective and sentences thatonly reflect shared background information?227A system that can automatically identify the per-spective from which a document written will be ahighly desirable tool for people analyzing huge col-lections of documents from different perspectives.An intelligence analyst regularly monitors the po-sitions that foreign countries take on political anddiplomatic issues.
A media analyst frequently sur-veys broadcast news, newspapers, and web blogs fordifferent viewpoints.
What these analysts need incommon is that they would like to find evidence ofstrong statements of differing perspectives, while ig-noring statements without strong perspectives as lessinteresting.In this paper we approach the problem of learningperspectives in a statistical learning framework.
Wedevelop statistical models to learn how perspectivesare reflected in word usage, and evaluate the modelsby measuring how accurately they can predict theperspectives of unseen documents.
Lacking anno-tation on how strongly individual sentences conveya particular perspective in our corpus poses a chal-lenge on learning sentence-level perspectives.
Wepropose a novel statistical model, Latent SentencePerspective Model, to address the problem.2 Related WorkIdentifying the perspective from which a documentis written is a subtask in the growing area of auto-matic opinion recognition and extraction.
Subjec-tive language is used to express opinions, emotions,and sentiments.
So far research in automatic opinionrecognition has primarily addressed learning sub-jective language (Wiebe et al, 2004; Riloff et al,2003; Riloff and Wiebe, 2003), identifying opinion-ated documents (Yu and Hatzivassiloglou, 2003) andsentences (Yu and Hatzivassiloglou, 2003; Riloff etal., 2003; Riloff and Wiebe, 2003), and discriminat-ing between positive and negative language (Yu andHatzivassiloglou, 2003; Turney and Littman, 2003;Pang et al, 2002; Dave et al, 2003; Nasukawa andYi, 2003; Morinaga et al, 2002).Although by its very nature we expect much ofthe language of presenting a perspective or point-of-view to be subjective, labeling a document or asentence as subjective is not enough to identify theperspective from which it is written.
Moreover, theideology and beliefs authors possess are often ex-pressed in ways more than conspicuous positive ornegative language toward specific targets.3 CorpusOur corpus consists of articles published on thebitterlemons website1.
The website is set upto ?contribute to mutual understanding [betweenPalestinians and Israels] through the open exchangeof ideas?.
Every week an issue about Israeli-Palestinian conflict is selected for discussion, forexample, ?Disengagement: unilateral or coordi-nated?
?, and a Palestinian editor and an Israeli edi-tor contribute a article addressing the issue.
In ad-dition, the Israeli and Palestinian editors invite orinterview one Israeli and one Palestinian to expresstheir views, resulting in a total of four articles in aweekly edition.We evaluate the subjectivity of each sentence us-ing the patterns automatically extracted from foreignnews documents (Riloff and Wiebe, 2003), and findthat 65.6% of Palestinian sentences and 66.2% of Is-raeli sentences are classified as subjective.
The highbut almost equivalent percentages of subjective sen-tences from two perspectives supports our observa-tion in Section 2 that perspective is largely expressedin subjective language but subjectivity ratio is notnecessarily indicative of the perspective of a docu-ment.4 Statistical Modeling of PerspectivesWe approach the problem of learning perspectives ina statistical learning framework.
Denote a trainingcorpus as pairs of documents Wn and their perspec-tives labels Dn, n = 1, .
.
.
,N , N is the total numberof documents in the corpus.
Given a new documentW?
with a unknown document perspective D?, iden-tifying its perspective is to calculate the followingconditional probability,P (D?|W?
, {Dn,Wn}Nn=1) (5)We are interested in how strongly each sentence inthe document convey perspective.
Denote the inten-sity of the m-th sentence of the n-th document as abinary random variable Sm,n, m = 1, .
.
.
,Mn, Mnis the total number of sentences of the n-th docu-ment.
Evaluating how strongly a sentence conveys1http://www.bitterlemons.org228a particular perspective is to calculate the followingconditional probability,P (Sm,n|{Dn,Wn}Nn=1) (6)4.1 Document Perspective ModelsThe process of generating documents from a partic-ular perspective is modeled as follows,pi ?
Beta(?pi, ?pi)?
?
Dirichlet(??
)Dn ?
Binomial(1, pi)Wn ?
Multinomial(Ln, ?d)The model is known as na?
?ve Bayes models (NB),which has been widely used for NLP tasks such astext categorization (Lewis, 1998).
To calculate (5)under NB in a full Bayesian manner is, however,complicated, and alternatively we employ MarkovChain Monte Carlo (MCMC) methods to simulatesamples from the posterior distributions.4.2 Latent Sentence Perspective ModelsWe introduce a new binary random variables, S, tomodel how strongly a perspective is expressed atthe sentence level.
The value of S is either s1 ors0, where s1 means the sentence is written stronglyfrom a perspective, and s0 is not.
The whole gener-ative process is modeled as follows,pi ?
Beta(?pi, ?pi)?
?
Beta(??
, ??
)?
?
Dirichlet(??
)Dn ?
Binomial(1, pi)Sm,n ?
Binomial(1, ?
)Wm,n ?
Multinomial(Lm,n, ?
)pi and ?
carry the same semantics as those in NB.S is naturally modeled as a binary variable, where?
is the parameter of S and represents how likelya perspective is strongly expressed at the sentencegiven on the overall document perspective.
We callthis model Latent Sentence Perspective Models(LSPM), because S is never directly observed in ei-ther training or testing documents and need to be in-ferred.
To calculate (6) under LSPM is difficult.
Weagain resort to MCMC methods to simulate samplesfrom the posterior distributions.5 Experiments5.1 Identifying Perspectives at the DocumentLevelTo objectively evaluate how well na?
?ve Bayes mod-els (NB) learn to identify perspectives expressedat the document level, we train NB against on thebitterlemons corpus, and evaluate how accu-rately NB predicts the perspective of a unseen doc-ument as either Palestinian or Israeli in ten-foldcross-validation manner.
The average classificationaccuracy over 10 folds is reported.
We comparethree different models, including NB with two dif-ferent inference methods and Support Vector Ma-chines (SVM) (Cristianini and Shawe-Taylor, 2000).NB-B uses full Bayesian inference and NB-M usesMaximum a posteriori (MAP).Model Data Set Accuracy ReductionBaseline 0.5SVM Editors 0.9724NB-M Editors 0.9895 61%NB-B Editors 0.9909 67%SVM Guests 0.8621NB-M Guests 0.8789 12%NB-B Guests 0.8859 17%Table 1: Results of Identifying Perspectives at theDocument LevelThe results in Table 1 show that both NB andSVM perform surprisingly well on both Editors andGuests subsets of the bitterlemons corpus.
Wealso see that NBs further reduce classification er-rors even though SVM already achieves high accu-racy.
By considering the full posterior distributionNB-B further improves on NB-M, which performsonly point estimation.
The results strongly suggestthat the word choices made by authors, either con-sciously or subconsciously, reflect much of their po-litical perspectives.5.2 Identifying Perspectives at the SentenceLevelIn addition to identify the perspectives of a doc-ument, we are interested in which sentences inthe document strongly convey perspectives.
Al-though the posterior probability that a sentence229covey strongly perspectives in (6) is of our inter-est, we can not directly evaluate their quality due tothe lack of golden truth at the sentence level.
Alter-natively we evaluate how accurately LSPM predictsthe perspective of a document, in the same way ofevaluating SVM and NB in the previous section.
IfLSPM does not achieve similar identification accu-racy after modeling sentence-level information, wewill doubt the quality of predictions on how stronglya sentence convey perspective made by LSPM.Model Training Testing AccuracyBaseline 0.5NB-M Guest Editor 0.9327NB-B Guest Editor 0.9346LSPM Guest Editor 0.9493NB-M Editors Guests 0.8485NB-B Editors Guests 0.8585LSPM Guest Editor 0.8699Table 2: Results of Perspective Identification at theSentence LevelThe experimental results in Table 2 show that theLSPM achieves similarly or even slightly better ac-curacy than those of NBs, which is very encourag-ing and suggests that the proposed LSPM closelymatch how perspectives are expressed at the docu-ment and sentence levels.
If one does not explic-itly model the uncertainty at the sentence level, onecan train NB directly against the sentences to clas-sify a sentence into Palestinian or Israeli perspec-tive.
We obtain the accuracy of 0.7529, which ismuch lower than the accuracy previously achievedat the document level.
Therefore identifying per-spective at the sentence level is much harder thanat that the document level, and the high accuracyof identifying document-level perspectives suggeststhat LPSM closely captures the perspectives ex-pressed at the document and sentence levels, givenindividual sentences are very short and much less in-formative about overall perspective.6 Summary of ContributionsIn this paper we study the problem of learningto identify the perspective from which a text waswritten at the document and sentence levels.
Weshow that perspectives are expressed in word us-age, and statistical learning algorithms such as SVMand na?
?ve Bayes models can successfully uncoverthe word patterns chosen by authors from differ-ent perspectives.
Furthermore, we develop a novelstatistical model to infer how strongly a sentenceconvey perspective without any labels.
By intro-ducing latent variables, Latent Sentence PerspectiveModels are shown to capture well how perspectivesare reflected at the document and sentence levels.The proposed statistical models can help analystssift through a large collection of documents writtenfrom different perspectives.
The unique sentence-level perspective modeling can automatically iden-tify sentences that are strongly representative of theperspective of interest, and we plan to manuallyevaluate their quality in the future work.ReferencesNello Cristianini and John Shawe-Taylor.
2000.
An Introduction to Support Vec-tor Machines and Other Kernel-based Learning Methods.
Cambridge Univer-sity Press.Kushal Dave, Steve Lawrence, and David M. Pennock.
2003.
Mining thepeanut gallery: Opinion extraction and semantic classification of product re-views.
In Proceedings of the 12th International World Wide Web Conference(WWW2003).David D. Lewis.
1998.
Naive (Bayes) at forty: The independence assumption ininformation retrieval.
In Proceedings of the European Conference on MachineLearning (ECML).S.
Morinaga, K. Yamanishi, K. Tateishi, and T. Fukushima.
2002.
Mining productreputations on the web.
In Proceedings of the 2002 ACM SIGKDD Interna-tional Conference on Knowledge Discovery and Data Mining.T.
Nasukawa and J. Yi.
2003.
Sentiment analysis: Capturing favorability usingnatural language processing.
In Proceedings of the 2nd International Confer-ence on Knowledge Capture (K-CAP 2003).Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002.
Thumbs up?
Senti-ment classification using machine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Language Processing (EMNLP-2002).Ellen Riloff and Janyce Wiebe.
2003.
Learning extraction patterns for subjec-tive expressions.
In Proceedings of the Conference on Empirical Methods inNatural Language Processing (EMNLP-2003).Ellen Riloff, Janyce Wiebe, and Theresa Wilson.
2003.
Learning subjective nounsusing extraction pattern bootstrapping.
In Proceedings of the 7th Conferenceon Natural Language Learning (CoNLL-2003).Peter Turney and Michael L. Littman.
2003.
Measuring praise and criticism:Inference of semantic orientation from association.
ACM Transactions onInformation Systems (TOIS), 21(4):315?346.Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell, and Melanie Mar-tin.
2004.
Learning subjective language.
Computational Linguistics, 30(3).Hong Yu and Vasileios Hatzivassiloglou.
2003.
Towards answering opinion ques-tions: Separating facts from opinions and identifying the polarity of opinionsentences.
In Proceedings of the Conference on Empirical Methods in NaturalLanguage Processing (EMNLP-2003).230
