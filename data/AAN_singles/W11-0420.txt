Proceedings of the Fifth Law Workshop (LAW V), pages 161?169,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational LinguisticsDiscourse-constrained Temporal AnnotationYuping ZhouBrandeis UniversityWaltham, MA 02452yzhou@brandeis.eduNianwen XueBrandeis UniversityWaltham, MA 02452xuen@brandeis.eduAbstractWe describe an experiment on a temporal or-dering task in this paper.
We show that by se-lecting event pairs based on discourse struc-ture and by modifying the pre-existent tem-poral classification scheme to fit the data bet-ter, we significantly improve inter-annotatoragreement, as well as broaden the coverage ofthe task.
We also present analysis of the cur-rent temporal classification scheme and pro-pose ways to improve it in future work.1 IntroductionEvent-based temporal inference is a fundamentalnatural language technology aimed at determiningthe temporal anchoring and relative temporal or-dering between events in text.
It supports a widerange of natural language applications such as In-formation Extraction (Ji, 2010), Question Answer-ing (Harabagiu and Bejan, 2005; Harabagiu andBejan, 2006) and Text Summarization (Lin andHovy, 2001; Barzilay et al, 2002).
Creating con-sistently annotated domain-independent data suffi-cient to train automatic systems has been the bot-tleneck.
While low-level temporal annotation taskssuch as identifying events and time expressions arerelatively straightforward and can be done with highconsistency, high-level tasks necessary to eventuallyarrange events in a document in a temporal orderhave proved to be much more challenging.Among these high-level tasks, the task of annotat-ing the temporal relation between main events standsout as probably the most challenging.
This task wasthe only task in the TempEval campaigns (Verha-gen et al, 2009; Verhagen et al, 2010) to deal withinter-sentential temporal relations, and also the onlyone to directly tackle event ordering.
The idea isthat events covered in an article are scattered in dif-ferent sentences, with some, presumably importantones, expressed as predicates in prominent positionsof a sentence (i.e.
the ?main event?
of the sentence).By relating main events from different sentences ofan article temporally, one could get something of achain of important events from the article.This task, in both previously reported attempts,one for English (Verhagen et al, 2009) and the otherfor Chinese (Xue and Zhou, 2010), has the lowestinter-annotator agreement (at 65%) among all tasksfocusing on annotating temporal relations.
Verha-gen et al (2009) attribute the difficulty, shared by alltasks annotating temporal relations, mainly to twofactors: rampant temporal vagueness in natural lan-guage and the fact that annotators are not allowed toskip hard-to-classify cases.Xue and Zhou (2010) take a closer look at thistask specifically.
They report that part of the diffi-culty comes from ?wrong?
main events (in the sensethat they are not main events in the intended sense)being selected in the preparation step.
This step is aseparate task upstream of the temporal relation task.The ?wrong?
main events produced in this step be-come part of event pairs whose temporal relation itmakes no sense to annotate, and often is hard-to-classify.
The reason ?wrong?
main events get se-lected is because the selection is based on syntacticcriteria.
In fact, these syntactic criteria produce re-sults so counter-intuitive that this seemingly simple161preparation task only achieves 74% inter-annotatoragreement.Another part of the difficulty comes from me-chanical pairing of main events for temporal relationannotation.
Simply pairing up main events from ad-jacent sentences oversimplifies the structure withinan article and is prone to produce hard-to-classifycases for temporal relation annotation.
Both causespoint to the need for a deeper level of text analysis toinform temporal annotation.
For this, Xue and Zhou(2010) suggest introduction of discourse structure asannotated in the Penn Discourse Treebank (PDTB)into temporal relation annotation.So the previous two reports, taken together, seemto suggest that the reason this task is especially chal-lenging is because the difficulty associated with tem-poral vagueness in natural language, which is sharedby all tasks dealing with temporal relation, is com-pounded by the problem of having to annotate far-fetched pairs that should not be annotated, which isunique for the only task dealing with inter-sententialtemporal relations.
These two problems are the fociof our experiment done on Chinese data.The paper is organized as follows: In Section 2,we describe the annotation scheme; in Section 3, wedescribe the annotation procedure; in Section 4 wereport and discuss the experiment results.
And fi-nally we conclude the paper.2 Annotation SchemeAs stated in the introduction, there are two prob-lems to be addressed in our experiment.
The firstproblem is that ?wrong?
main events get identifiedand main events that do not bear any relation arepaired up for temporal annotation.
To address thisproblem, we follow the suggestion by Xue and Zhou(2010), namely using a PDTB-style discourse struc-ture to pick out and pair up main events.
We be-lieve that adopting a discourse-constrained approachto temporal annotation will not only improve anno-tation consistency but also increase the Informative-ness Value of the annotated data, under the assump-tion that temporal relations that accord with the dis-course structure are more valuable in conveying theoverall information of a document.
Since there is noChinese data annotated with PDTB-style discoursestructure available, we have to develop our own.
Thescheme for this step is described in Section 2.1.The second problem is that there is too much tem-poral vagueness in natural language with respect tothe temporal classification scheme.
Since we can-not change the way natural language works, we tryto model the classification scheme after the data it issupposed to classify.
The scheme for the temporalannotation is covered in Sections 2.2 and 2.3.2.1 Discourse-constrained selection of mainevents and their pairs2.1.1 Discourse annotation schemeThe PDTB adopts a lexically grounded approachto discourse relation annotation (Prasad et al, 2008).Based on discourse connectives like ?since?, ?and?,and ?however?, discourse relation is treated as apredicate taking two abstract objects (AO?s) (suchas events, states, and propositions) as arguments.For example, in the sentence below, ?since?
is thelexical anchor of the relation between Arg1 andArg2 (example from Prasad et al (2007)).
(1) Since [Arg2 McDonald?s menu prices rosethis year], [Arg1 the actual decline may havebeen more].This notion is generalized to cover discourse rela-tions that do not have a lexical anchor, i.e.
im-plicit discourse relations.
For example, in the two-sentence sequence below, although no discourseconnective is present, a discourse relation similar tothe one in (1) is present between Arg1 and Arg2 (ex-ample from Prasad et al (2007)).
(2) [Arg1 Some have raised their cash positions torecord levels].
[Arg2 High cash positions helpbuffer a fund when the market falls].Based on this insight, we have fashioned a schemetailored to linguistic characteristics of Chinese text.The linguistic characteristics of Chinese text rele-vant to discussion here can be illustrated with thefollowing sentence.
(3) ?
?according to reports?,[AO1 ??Dongguan?
?Customs?in total??e1accept??company??contract??record????
?8400 plus?
]CL?[AO2,?compare??pilot?before162?slight?e2EXIST??
]increase?,[AO3??company??e3respond/response??
]well/good?,[AO4??generally??e4acknowledge??
]accept/acceptance?
?According to reports, [AO1 Dongguan DistrictCustoms acceptede1 more than 8400 recordsof company contracts], [AO2 (showinge2) aslight increase from before the pilot].
[AO3Companies respondede3 well], [AO4 generallyacknowledginge4 acceptance].
?One feature is that it is customary to have complexideas packed into one sentence in Chinese.
The sen-tence above reports on how a pilot program workedin Dongguan City.
Because all that is said is aboutthe pilot program, it is perfectly natural to includeit all in a single sentence in Chinese.
Intuitivelythough, there are two different aspects of how thepilot program worked: the number of records andthe response from the affected companies.
To reportthe same facts in English, it is probably more naturalto break them down into two sentences, but in Chi-nese, not only are they merely separated by comma,but also there is no connective relating them.Another feature is that grammatical relation be-tween comma-separated chunks within a sentenceis not always clear.
In the above sentence, for in-stance, although the grammatical relations betweenAO1 and AO2, and between AO3 and AO4 are clearin the English translation (i.e.
the first in each pair isthe main clause and the second an adjunct), it is notat all clear in the original.
This is the result of sev-eral characteristics of Chinese, for example, there isno inflectional clues on the verb to indicate its gram-matical function in the sentence.Based on these features of Chinese text1, we havedecided to use punctuation as the main potentialindicator for discourse relations: the annotator isasked to judge, at every instance of comma, pe-riod, colon and semi-colon, if it is an indicator fordiscourse relation; if both chunks separated by thepunctuation are projections of a predicate, then thereis a discourse relation between them.
Applying thisscheme to the sentence in (3), we have four abstractobjects as marked up in the example.1A more detailed justification for this scheme is presented inZhou and Xue (2011).To determine the exact text span of each argu-ment of a relation, we adopt the Minimality Princi-ple formulated in Prasad et al (2007): only as manyclauses and/or sentences should be included in an ar-gument selection as are minimally required and suf-ficient for the interpretation of the relation.
Apply-ing this principle to the sentence in (3), we can de-limit the three sets of discourse relations as follows:AO1?AO2, (AO1,AO2)?
(AO3,AO4), and AO3?AO4.2.1.2 Selection and pairing-up of main eventsSelection of main events is done on the level of thesimplex abstract object, with one main event per sim-plex AO.
The main event corresponds to the predi-cate heading the simplex AO.
In (3), there are foursimplex AO?s, AO1-4 ( which further form two com-plex AO?s, (AO1,AO2) and (AO3,AO4)).
The an-chors for the four main events are the underlinedverbs labeled as ?e1-4?.Pairing up the main events is done on the levelof discourse relation.
In the case of a relationonly involving simplex AO?s, the main events ofthe two AO?s pair up; in the case of a relationinvolving complex AO?s, the discourse relation isdistributed among the simplex AO?s to form mainevent pairs.
For example, with the discourse relation(AO1,AO2)?
(AO3,AO4), four pairs of main eventsare formed: e1?e3, e1?e4, e2?e3, and e2?e4.
Thisgets tedious fast as the number of simplex AO?s ina complex AO increases; in this experiment, the an-notator relies on her discretion in such cases.
Thisproblem should be addressed in a more elegant wayin the future.It is worth noting that in addition to picking outright main events and event pairs for temporal anno-tation, this scheme also broadens the coverage of thetask.
In the old scheme based on syntactic criteria,there is a stipulation: one main event per sentence.Because the new discourse-constrained scheme istailored to the characteristics of Chinese text, it isable to expose more main events (in the intendedsense) to temporal annotation.2.2 Classification scheme for temporal relationannotationBy modifying the six-value scheme used in Tem-pEval (containing before, overlap, after, before-or-overlap, overlap-or-after and vague), our classifica-163tion scheme has seven values in it: before, overlap,after, not-before, not-after, groupie, and irrelevant.2.2.1 The values ?not-before?
and ?not-after?The values ?not-before?
and ?not-after?
areequivalent to ?overlap-or-after?
and ?before-or-overlap?
in the TempEval scheme.
The reason wemade this seemingly vacuous change is because wefound that the old values were used for two differentpurposes by annotators.
In addition to their intendeduse, i.e.
to capture indeterminacy between the twosimplex values, they were also used to label a spe-cific case of ?overlap?.
An example of such misuseof the value ?before-or-overlap?
is presented below:(4) ???
?1996?year?,[e1 ??]generate?ASP??first?CL??local??Chinese??judge?,?until?
?at present?,?already?EXIST?close??20?CL??local??Chinese[e2??
]hold the post??judicial??official?.
?The first local ethnic Chinese judge [e1 assumed]the office in 1996; up until now, there have beenclose to 20 ethnic Chinese locals [e2 holding] theposts of judicial officials.
?The reason for such use is probably because it repre-sents two alternative ways of looking at the temporalrelation between the two events : either e1 is beforethe later bulk of e2 or e1 overlaps the beginning tipof e2.
To avoid such mis-uses, we made the abovechange.2.2.2 The value ?groupie?This value is set up for two events whose tempo-ral relation to each other is unclear, but are known tohappen within the same temporal range.
For exam-ple, the temporal relation between the events repre-sented by the underlined verbs should be classifiedas ?groupie?.
(5) ?today?yesterday?two?day?,?
?Hong Kong??SAR????CPPCC?
?member?also[e1 ??]inspect?ASP??Ningbo??
?development district?,??Ningbo???Xitianxin??Textile????Ltd.
?,[e2 ??]tour?ASP??
?Tianyi Pavilion?,??Chiang?
?ancestral home?.
?Yesterday and today, CPPCC members from HongKong SAR also [e1 visited] Ningbo DevelopmentDistrict and Ningbo Xitianxin Textile Ltd., and [e2toured] Tianyi Pavilion and the ancestral home ofChiang Kai-shek.
?In this example, the common range shared by thetwo events is expressed in the form of a time ex-pression, ??????
(?yesterday and today?
), butit does not have to be the case.
It can be in the formof another event (e.g., ?????????
(?duringthe process of project construction?
)), or another en-tity with a time stamp (e.g., ??????
(?in theEighth Five-year Plan period?
)).It should be noted that the linguistic phenomenoncaptured by this value can occur in a situation wherethe internal temporal relation between two eventscan be classified with another value.
So ideally, thisvalue should be set up as a feature parallel to theexistent classification scheme.
But due to technicalrestrictions imposed on our experiment, we groupedit with all the others and instructed the annotatorsto use it only when none of the five more specificvalues applies.2.2.3 The value ?irrelevant?We substituted this value for the old one ?vague?because it is too vague.
Anything that cannot fit intothe classification scheme would be labeled ?vague?,but in fact, some cases are temporally relevant andprobably should be characterized in the classifica-tion scheme.
Case in point are those we now label?groupie?.This change reflects our guiding principle for de-signing the classification scheme.
If the relation be-tween two events is temporally relevant, we shouldtry to characterize it in some way; if too many rela-tions are temporally relevant but too vague to fit intothe classification scheme (comfortably), then the ad-equacy of the scheme is questionable.2.3 An additional specification: which event?In addition to the classification scheme, it is alsonecessary to specify which event should be con-sidered for temporal annotation.
This question has164never been clearly addressed, probably because itseems self-evident: the event in question is the oneexpressed by the event anchor (usually a verb).
Thisintuitive answer actually accounts for some too-vague-to-classify cases.
In some cases, the eventthat is easily annotated (and should be the one beingannotated in our opinion) is not the event expressedby the verb, as is the case in (6).
(6) ?PREP??absorb?
?foreign business??invest??aspect?,??China?now?already??become??world?POSTP??utilize?
?foreign fund??most?DE???developing???country.
?With regard to attracting foreign business invest-ments, China has now become the developing coun-try that utilizes the most foreign funds in the world.
?This sentence is taken from an article summarizingChina?s economic progress during the ?Eighth Five-Year Plan?
period (from 1991 to 1995).
The an-chor for the main event of the sentence is clearly????
(?become?
), but should the event it repre-sents, the process of China becoming the develop-ing country that utilizes the most foreign funds, beconsidered for the temporal relation annotation?
Itis both counter-intuitive and impractical.Intuitively, the sentence is a statement of the cur-rent state with regard to attracting foreign businessinvestments, not of the process leading up to thatstate.
If we were to consider the process of ?be-coming?
in relation to other events temporally, wewould have to ask, when are the starting and endingpoints of this process?
How does one decide when itis not made clear in the article?
One could conceiv-ably go as far back as to when China did not use onecent of foreign funds.
Should it be restricted to the?Eighth Five-Year Plan?
period since it is the targetperiod of the whole article?
But why use the five-year period, when there are more specific, syntac-tically explicit aspectual/temporal modifiers in thesentence, i.e.
????
(?now already?
), to restrict it?To make use of these in-sentence aspectual/temporalmodifiers, we have to go with our intuition that theevent is the current state of China with regard to uti-lizing foreign investments, i.e.
the temporal locationof the event is at present.So the event that should be considered for tem-poral annotation is not the one represented by theevent anchor itself, but rather the one described bythe whole clause/sentence headed by the event an-chor.
This allows all sorts of temporal clues in thesame clause/sentence to help decide the temporal lo-cation of the event, hence makes the annotation taskeasier in many cases.3 Annotation procedureThe annotation process consists of two separatestages, with a different annotation procedure in placefor each.
The first stage involves only one annotator,and it deals with picking out pairs of event anchorsbased on the discourse relation as described in Sec-tion 2.1.
The output of this stage defines the targetsfor the next stage of annotation: temporal relationannotation.
Temporal relation annotation is a two-phase process, including double-blind annotation bytwo annotators and then adjudication by a judge.With this procedure in place, the results we re-port in Section 4 are all from the second stage.
Twoannotators go through ten weeks of training, whichincludes annotating 10 files each week, submittingthem to adjudication, and then attending a trainingsession at the end of each week.
In the training ses-sion, the judge discusses with the annotators her ad-judication notes from the previous week, as well asspecific questions the annotators raise.The data set consists of 100 files taken from theChinese Treebank (Xue et al, 2005).
The source ofthese files is Xinhua newswire.
The annotation iscarried out within the confines of the Brandeis An-notation Tool (BAT)2 (Verhagen, 2010).4 Evaluation and discussionTable 1 reports the inter-annotator agreement of tem-poral annotation, both between the two annotators(A and B) and between each annotator and the judge(J), over a training period of ten weeks.
Each week,10 files are assigned, averaging about 315 eventpairs for annotation.Table 1 shows that annotators have taken up thetemporal annotation scheme fairly quickly, reaching75% agreement within three weeks.
After several2http://timeml.org/site/bat-versions/bat-redesign165Week No.
of tokens f(A, B) f(A, J) f(B, J)1 310 0.48062 352 0.62783 308 0.75324 243 0.77375 286 0.8007 0.8601 0.85666 299 0.7659 0.8662 0.88967 296 0.7973 0.8784 0.87848 323 0.7988 0.8978 0.87939 358 0.8212 0.9106 0.896610 378 0.8439 0.9365 0.8995Table 1: Inter-annotator agreement over 10 weeks oftraining.weeks of consolidation and fine-tuning, the agree-ment slowly reaches the lower 80% towards the endof the 10-week training period.
This level of agree-ment is a substantial improvement over the previ-ously reported results, at 65%, for both English andChinese data (Verhagen et al, 2009; Xue and Zhou,2010).
This indicates that the general direction ofour experiment is on the right track.Table 2 below is the confusion matrix based onthe annotation data from the final 4 weeks:a b o na nb g ia 148 3 19 0 1 0 1b 0 344 29 1 0 0 7o 14 10 1354 3 3 2 82na 0 0 3 3 0 0 0nb 0 0 1 0 1 0 0g 2 1 9 0 0 13 1i 3 7 67 0 0 1 572Table 2: Confusion matrix on annotation from Weeks7-10: a=after; b=before; o=overlap; na=not-after;nb=not-before; g=groupie; i=irrelevant.The matrix is fairly clean except when the value?overlap?
is concerned.
This value really stands outin more than one way.
It is the most nebulous one inthe whole scheme, prone to be confused with all sixother values.
In particular, it is most likely to be con-fused with the value ?irrelevant?.
It is also the mostused value among all seven values, covering roughlyhalf of the tokens.
We will discuss this value in moredetail in Section 4.2 below.The value ?groupie?
may also seem troublesomeif we look at mis-classification as a percentage of itstotal occurrences, however, it may not be as bad as itseems.
As pointed out in Section 2.2.2, despite thefact that the linguistic phenomenon this value cap-tures can, and does, co-occur with temporal relationsrepresented by other values, we had to set it up as anopposing value to the rest due to technical restric-tions.
If/when this value is set up as a stand-alonefeature to capture the linguistic phenomenon fully,the percentage of mis-classification should drop sig-nificantly because the number of total occurrenceswill increase dramatically.The overall distribution of values shown in Table2 is very skewed.
At one end of the distributionspectrum is the value ?overlap?, covering half ofthe data; at the other end are the values ?not-before?and ?not-after?, covering less than 0.3% of the tokencombined.
It raises the question if such a classifica-tion scheme is well-designed to produce data usefulfor machine learning.To shed light on what is behind the numbers andto uncover trends that numbers do not show, we alsotake a closer look at the annotation data.
Three is-sues stand out.4.1 Event anchorIn our current scheme, effort is made to pick out thepredicate from a clause as the event anchor for tem-poral annotation.
Our experiment suggests maybethis step should be skipped since it, in practice, un-dermines a specification of the scheme.
The specifi-cation is that the event to be considered for temporalannotation is the one being described by the wholeclause, but the practice of displaying a mere word tothe annotator in effect instructs the annotator to con-centrate on the word itself, rather than the clause.Despite repeated reminder during training sessions,the suggestive power of the display still sometimesgets the upper hand.
(7) presents such an exampleconcerning e1 and e2.
(7) ?PREP?this??period?,?
?West Africa??peacekeeping?
?force?once[e1 ??]dispatch??
?fighter jet??bomb??rebel?
?position?,[e2 ??]bomb-dead??rebel?about??
?50 plus166?
?CL?During this period, West African PeacekeepingForce [e1 dispatched] fighter jets and bombed rebelpositions, [e2 killing] about 50 rebel troops.
?One annotator classified the relation as ?before?, ob-viously thinking of the event of dispatching fighterjets as e1; had he considered the event of dispatch-ing fighter jets and bombing the rebel positions, theevent being described by the clause, the value wouldhave easily been ?overlap?.Since displaying the single-word event anchorsometimes leads annotators astray, this step proba-bly should be skipped.
Doing so also simplifies theannotation process.4.2 The value ?overlap?As pointed out above, the value ?overlap?
is quitea troubling character in the classification scheme: itis both the most-used and probably the least well-defined.
Annotation data show that when it is con-fused with ?after?, ?before?, ?not-after?, and ?not-before?, it usually involves a perceptually punc-tual event (?pp-event?
henceforth) and a perceptu-ally lasting event (?pl-event?
henceforth), and the is-sue is whether the pp-event coincides with one of thetemporal edges of the pl-event.
If it does, then thevalue is ?overlap?
; otherwise, it is ?after?/?before?.And on top of it is the factor of how sure one isof the issue: if one is sure, either way, the valueis ?overlap?/?after?/?before?
; otherwise, it is ?not-after?/?not-before?.
Below is an example on whichthe two annotators disagree as to whether the rela-tion between e1 and e2 should be classified as ?be-fore?
or ?overlap?.
(8) ?
?in addition?,??Brazil??woman??
?national team?PREP??S.
America??
?soccer match?POSTP?,[e1 ??]sweep?
?thousand-troop?like?roll?mat?,[e2 ??]ascend?ASP??champion??throne?.
?In addition, in the South America Cup, Brazil-ian Women?s national team totally [e1 annihilated]all their opponents and [e2 ascended] the throne ofchampion.
?In this example, e2 is the pp-event and e1 is the pl-event.
Depending on when one thinks e2 happened,either as soon as the last match ended or at the latermedal ceremony, (and if the former, whether there istemporal overlap between e1 and e2), it is classifiedas either ?before?
or ?overlap; and if one is unsure,it can be classified as ?not-after?.Such cases again raise the same question as thedrastically uneven distribution of values shown inTable 2: Does the current classification scheme slicethe temporal pie the right way?
Let us make a posterchild out of ?overlap?
: it seems to both impose toostringent a condition and not make enough distinc-tion.
It imposes too stringent a condition on thosecases like (8) to which whether there is temporaloverlap seems beside the point.
At the same time,it does not make enough distinction for cases like(4), in which an event does share one edge of an-other event temporally: once such cases are classi-fied as ?overlap?, the specific information regard-ing the edge is lost.
Such information could be veryuseful in temporal inference.
Since it is infeasibleto annotate the temporal relation between all eventsin an article, temporal inference is needed to expandthe scope of temporal annotation.
For example, if itis known from annotation that e1 is before e2 ande2 is before e3, then it can be inferred e1 is beforee3.
In the case of ?overlap?, whenever it is one ofthe premises, no inference can be made, but if the?edge?
information is supplied, some inferences arepossible.To make finer-grained distinctions in the classifi-cation scheme runs counter to the conventional wis-dom that a coarser-grained scheme would do a bet-ter job handling vagueness.
But our experiment hasproven the conventional wisdom wrong: our seven-value system achieved much higher agreement thanthe old six-value system.
So the key is not fewer, butbetter, distinctions, ?better?
in the sense that theycharacterize the data in a more intuitive and insight-ful way.
Temporal relation in natural language is?too?
vague only when we judge it against a sys-tem of temporal logic, in fact, we think the rightword to describe temporal relation in natural lan-guage is ?flexible?
: it is as precise as the situationcalls for.
To characterize the flexibility better, forstarters, ?overlap?
needs to be restructured for rea-sons put forth above, and ?not-before?
and ?not-167after?
should be discarded since they obviously donot carry weight.4.3 Objective vs. subjective temporal referenceA major contributor to uncertainty and disagreementin annotation is subjective temporal reference.
Sub-jective temporal reference is made based on the au-thor?s perspective of the temporal axis, for example,????
(?today?
), ????
(?at present), and ????(?past?).
In this group, references with a fixed spando not constitute a problem once the point of utter-ance is determined (e.g.
literal use of ?today?, ?thismonth?
); it is those with an elastic temporal span thatcause disagreement.
For example, ?at present?
canhave a span of a second, or several minutes, or a cou-ple of hours, or even years depending on the context.When an event modified with this type of tempo-ral expression is paired with another event modifiedwith direct reference to a point/span on the tempo-ral axis (i.e.
with an objective reference), annotationbecomes tricky.
The event pair e1-e2 in the two-sentence sequence below is such an example.
(9) ??past?,?PREP?
?Yangtze River?POSTP?build??bridge?be?CL???
?national affair?,??nowadays??almost[e1??]become???
?common scene.??????1992-year,??Jiangsu??
?Yangzhong County?
?farmer[e2 ??
]raise funds??build-finish?ASP??Yangzhong??Yangtze??Bridge?,?and??Hubei?DE??Chibi??Yangtze??Bridge?total??invest??
?300 million plus?Yuan?,??all?depend??private?
?raise funds??build-finish?.
?In the past, building a bridge on Yangtze River wasa national affair, nowadays it almost [e1becomes]a common scene.
In 1992, farmers in YangzhongCounty, Jiangsu Province [e2raised] funds and com-pleted Yangzhong Yangtze Bridge, while ChibiYangtze Bridge in Hubei Province cost more than300 million Yuan, all from private fund-raising.
?This is taken from a piece written in 1997.
In thecontext, it is clear that the contrast is between thesituation before the opening-up of China and the sit-uation about 20 years later.
So it is reasonable to as-sume that the year 1992 falls inside the span of whatthe author considered nowadays; at the same time, itseems also reasonable to assume a narrow interpre-tation of ????
(?nowadays?)
that does not includethe year 1992 in the span.
These two interpretationswould result in ?overlap?
and ?after?
respectively,and actually did so in our experiment.There are also extreme cases in which objectiveand subjective temporal references come in directconflict.
For example,(10) ?while?
?reporter[e1 ??
]ask about?China?Russia??relationship?DE??status?and??cooperation??prospect?when?,??
?Jiang Zemin?
?President[e2 ?
]say?..., ...?When a reporter [e1 asked] about the status ofChina-Russia relationship and the prospects for co-operation, President Jiang Zemin [e2 said], ...?The relation between e1 and e2 is before basedon objective reference, but overlap according tothe subjective reference, indicated by ??..??(?when?).
This problem should be factored in whena new classification scheme is designed.5 ConclusionsIn this paper, we have described an experiment thatfocuses on two aspects of the task of annotatingtemporal relation of main events: annotation tar-get selection and a better-fitting temporal classifica-tion scheme.
Experiment results show that selectingmain event pairs based on discourse structure andmodeling the classification scheme after the data im-proves inter-annotator agreement dramatically.
Re-sults also show weakness of the current temporalclassification scheme.
For that, we propose a re-structuring along the lines of what this experimenthas proven working: making more intuitive and in-sightful distinctions that characterize the data bet-ter.
This direction can be taken to improve otherhigh-level temporal annotation tasks that have beenplagued by the same ?vagueness?
problem.AcknowledgmentsThis work is supported by the National ScienceFoundation via Grant No.
0855184 entitled ?Build-ing a community resource for temporal inference168in Chinese?.
All views expressed in this paper arethose of the authors and do not necessarily representthe view of the National Science Foundation.ReferencesRegina Barzilay, Noemie Elhadad, and Kathleen McKe-own.
2002.
Inferring strategies for sentence orderingin multidocument news summarization.
Journal of Ar-tificial Intelligence Research, 17:35?55.Sanda Harabagiu and Cosmin Adrian Bejan.
2005.Question Answering Based on Temporal Inference.
InProceedings of the AAAI-2005 Workshop on Inferencefor Textual Question Answering, Pittsburgh, Pennsyl-vania.Sanda Harabagiu and Cosmin Adrian Bejan.
2006.
AnAnswer Bank for Temporal Inference.
In Proceedingsof LREC 2006, Genoa, Italy.Heng Ji.
2010.
Challenges from information extrac-tion to information fusion.
In Proceedings of COLING2010, pages 507?515, Beijing, China, August.Chin-Yew Lin and Eduard Hovy.
2001.
Neats: A mul-tidocument summarizer.
In Proceedings of the Docu-ment Understanding Workshop.Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, AlanLee, Aravind Joshi, Livio Robaldo, and Bonnie Web-ber, 2007.
The Penn Discourse Treebank 2.0 Annota-tion Manual.
The PDTB Research Group, December.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The Penn Discourse Treebank 2.0.In Proceedings of the 6th International Conference onLanguage Resources and Evaluation (LREC 2008).Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Jessica Moszkowicz, and James Puste-jovsky.
2009.
The TempEval Challenge: IdentifyingTemporal Relation in Text.
Language Resources andEvaluation, 43(1):161?179.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 task 13:Tempeval-2.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 57?62, Up-psala, Sweden, July.
Association for ComputationalLinguistics.Marc Verhagen.
2010.
The Brandeis Annotation Tool.In Language Resources and Evaluation Conference,LREC 2010, pages 3638?3643, Malta.Nianwen Xue and Yuping Zhou.
2010.
Applying Syn-tactic, Semantic and Discourse Constraints to ChineseTemporal Annotation.
In Proceedings of COLING2010, pages 1363?1372, Beijing, China, August.Nianwen Xue, Fei Xia, Fu dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese TreeBank: PhraseStructure Annotation of a Large Corpus.
Natural Lan-guage Engineering, 11(2):207?238.Yuping Zhou and Nianwen Xue.
2011.
A PDTB-inspiredDiscourse Annotation Scheme for Chinese.
Submittedto EMNLP 2011.169
