Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 562?571,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsGenerating Code-switched Text for Lexical LearningIgor LabutovCornell Universityiil4@cornell.eduHod LipsonCornell Universityhod.lipson@cornell.eduAbstractA vast majority of L1 vocabulary acqui-sition occurs through incidental learningduring reading (Nation, 2001; Schmitt etal., 2001).
We propose a probabilistic ap-proach to generating code-mixed text asan L2 technique for increasing retentionin adult lexical learning through reading.Our model that takes as input a bilingualdictionary and an English text, and gener-ates a code-switched text that optimizes adefined ?learnability?
metric by construct-ing a factor graph over lexical mentions.Using an artificial language vocabulary,we evaluate a set of algorithms for gener-ating code-switched text automatically bypresenting it to Mechanical Turk subjectsand measuring recall in a sentence com-pletion task.1 IntroductionToday, an adult trying to learn a new language islikely to embrace an age-old and widely acceptedpractice of learning vocabulary through curatedword lists and rote memorization.
Yet, it is notuncommon to find yourself surrounded by speak-ers of a foreign language and instinctively pick upwords and phrases without ever seeing the defini-tion in your native tongue.
Hearing ?pass le saleplease?
at the dinner table from your in-laws vis-iting from abroad, is unlikely to make you thinktwice about passing the salt.
Humans are extraor-dinarily good at inferring meaning from context,whether this context is your physical surround-ing, or the surrounding text in the paragraph of theword that you don?t yet understand.Recently, a novel method of L2 language teach-ing had been shown effective in improving adultlexical acquisition rate and retention1.
This tech-1authors?
unpublished worknique relies on a phenomenon that elicits a nat-ural simulation of L1-like vocabulary learning inadults ?
significantly closer to L1 learning for L2learners than any model studied previously.
By in-fusing foreign words into text in the learner?s na-tive tongue into low-surprisal contexts, the lexi-cal acquisition process is facilitated naturally andnon-obtrusively.
Incidentally, this phenomenonoccurs ?in the wild?
and is termed code-switchingor code-mixing, and refers to the linguistic patternof bilingual speakers swapping words and phrasesbetween two languages during speech.
While thisphenomenon had received significant attentionfrom both a socio-linguistic (Milroy and Muysken,1995) and theoretical linguistic perspectives (Be-lazi et al, 1994; Bhatt, 1997) (including somecomputational studies), only recently has it beenhypothesizes that ?code-switching?
is a markingof bilingual proficiency, rather than deficiency(Genesee, 2001).Until recently it was widely believed that inci-dental lexical acquisition through reading can onlyoccur for words that occur at sufficient densityin a single text, so as to elicit the ?noticing?
ef-fect needed for lexical acquisition to occur (Cobb,2007).
Recent neurophysiological findings, how-ever, indicate that even a single incidental expo-sure to a novel word in a sufficiently constrainedcontext is sufficient to trigger an early integra-tion of the word in the brain?s semantic network(Borovsky et al, 2012).An approach explored in this paper, and moti-vated by the above findings, exploits ?constrain-ing?
contexts in text to introduce novel words.
Astate-of-the-art approach for generating such textis based on an expert annotator whose job is todecide which words to ?switch out?
with novelforeign words (from hereon we will refer to the?switched out?
word as the source word and to the?switched in?
word as the target word).
Conse-quently the process is labor-intensive and leads to562a ?one size fits all solution?
that is insensitive tothe learner?s skill level or vocabulary proficiency.This limitation is also cited in literature as a sig-nificant roadblock to the widespread adaptationof graded reading series (Hill, 2008).
A reading-based tool that follows the same principle, i.e.
bysystematic exposure of a learner to an incremen-tally more challenging text, will result in more ef-fective learning (Lantolf and Appel, 1994).To address the above limitation, we develop anapproach for automatically generating such ?code-switched?
text with an explicit goal of maximizingthe lexical acquisition rate in adults.
Our methodis based on a global optimization approach thatincorporates a ?knowledge model?
of a user withthe content of the text, to generate a sequence oflexical ?switches?.
To facilitate the selection of?switch points?, we learn a discriminative modelfor predicting switch point locations on a corpusthat we collect for this purpose (and release to thecommunity).
Below is a high-level outline of thispaper.?
We formalize our approach within a prob-abilistic graphical model framework, infer-ence in which yields ?code-switched?
textthat maximizes a surrogate to the acquisitionrate objective.?
We compare this global method to sev-eral baseline techniques, including the strong?high-frequency?
baseline.?
We analyze the operating range in whichour model is effective and motivate the near-future extension of this approach with theproposed improvements.2 Related WorkOur proposed approach to the computational gen-eration of code-switched text, for the purpose ofL2 pedagogy, is influenced by a number of fieldsthat studied aspects of this phenomenon from dis-tinct perspectives.
In this section, we briefly de-scribe a motivation from the areas of socio- andpsycho- linguistics and language pedagogy re-search that indicate the promise of this approach.2.1 Code-switching as a natural phenomenonCode-switching (or code-mixing) is a widely stud-ied phenomenon that received significant attentionover the course of the last three decades, acrossthe disciplines of sociolinguistics, theoretical andpsycholinguistics and even literary and culturalstudies (predominantly in the domain of Spanish-English code-switching) (Lipski, 2005).Code-switching that occurs naturally in bilin-gual populations, and especially in children, hasfor a long time been considered a marking ofincompetency in the second language.
A morerecent view on this phenomenon, however, sug-gests that due to the underlying syntactic com-plexity of code-switching, code-switching is ac-tually a marking of bilingual fluency (Genesee,2001).
More recently, the idea of employingcode-switching in the classroom, in a form ofconversation-based exercises, has attracted theattention of multiple researchers and educators(Moodley, 2010; Macaro, 2005), yielding promis-ing results in an elementary school study in South-Africa.2.2 Computational Approaches toCode-switchingAdditionally, there has been a limited numberof studies of the computational approaches tocode-switching, and in particular code-switchedtext generation.
Solorio and Liu (2008), recordand transcribe a corpus of Spanish-English code-mixed conversation to train a generative model(Naive Bayes) for the task of predicting code-switch points in conversation.
Additionally theytest their trained model in its ability to generatecode-switched text with convincing results.
Build-ing on their work, (Adel et al, 2012) employ ad-ditional features and a recurrent network languagemodel for modeling code-switching in conversa-tional speech.
Adel and collegues (2011) proposea statistical machine translation-based approachfor generating code-switched text.
We note, how-ever, that the primary goal of these methods is inthe faithful modeling of the natural phenomenonof code-switching in bilingual populations, andnot as a tool for language teaching.
While usefulin generating coherent, syntactically constrainedcode-switched texts in its own right, none of thesemethods explicitly consider code-switching as avehicle for teaching language, and thus do nottake on an optimization-based view with an ob-jective of improving lexical acquisition throughthe reading of the generated text.
More recently,and concurrently with our work, Google?s Lan-guage Immersion app employs the principle of563code-switching for language pedagogy, by gener-ating code-switched web content, and allowing itsusers to tune it to their skill level.
It does not, how-ever, seem to model the user explicitly, nor is itclear if it performs any optimization in generatingthe text, as no studies have been published to date.2.3 Computational Approaches to SentenceSimplificationAlthough not explicitly for teaching language,computational approaches that facilitate accessi-bility to texts that might otherwise be too difficultfor its readers, either due to physical or learningdisabilities, or language barriers, are relevant.
Inthe recent work of (Kauchak, 2013), for exampledemonstrates an approach to increasing readabilityof texts by learning from unsimplified texts.
Ap-proaches in this area span methods for simplify-ing lexis (Yatskar et al, 2010; Biran et al, 2011),syntax (Siddharthan, 2006; Siddharthan et al,2004), discourse properties (Hutchinson, 2005),and making technical terminology more accessibleto non-experts (Elhadad and Sutaria, 2007).
Whilethe resulting texts are of great potential aid to lan-guage learners and may implicitly improve upon areader?s language proficiency, they do not explic-itly attempt to promote learning as an objective ingenerating the simplified text.2.4 Recent Neurophysiological findingsEvidence for the potential effectiveness of code-switching for language acquisition, stem from therecent findings of (Borovsky et al, 2012), whohave shown that even a single exposure to a novelword in a constrained context, results in the inte-gration of the word within your existing semanticbase, as indicated by a change in the N400 elec-trophysiological response recorded from the sub-jects?
scalps.
N400 ERP marker has been foundto correlate with the semantic ?expectedness?
of aword (Kutas and Hillyard, 1984), and is believedto be an early indicator of word learning.
Further-more, recent work of (Frank et al, 2013), showthat word surprisal predicts N400, providing con-crete motivation for artificial manipulation of textto explicitly elicit word learning through naturalreading, directly motivating our approach.
Prior tothe above findings, it was widely believed that forevoking ?incidental?
word learning through read-ing alone, the word must appear with sufficientlyhigh frequency within the text, such as to elicit the?noticing?
effect ?
a prerequisite to lexical acqui-sition (Schmidt and Schmidt, 1995; Cobb, 2007).3 Model3.1 OverviewThe formulation of our model is primarily moti-vated by two hypotheses that have been validatedexperimentally in the cognitive science literature.We re-state these hypotheses in the language of?surprisal?:1.
Inserting a target word into a low surprisalcontext increases the rate of that word?s inte-gration into a learner?s lexicon.2.
Multiple exposures to the word in low sur-prisal contexts increases rate of that word?sintegration.Hypothesis 1 is supported by evidence from(Borovsky et al, 2012; Frank et al, 2013), and hy-pothesis 2 is supported by evidence from (Schmidtand Schmidt, 1995).
We adopt the term ?low-surprisal?
context to identify contexts (e.g.
n-grams) that are highly predictive of the target word(e.g.
trailing word in the n-gram).
The motiva-tion stems from the recent evidence (Frank et al,2013) that low-surprisal contexts affect the N400response and thus correlate with word acquisi-tion.
To realize a ?code-switched?
mixture thatadheres maximally to the above postulates, it isself-evident that a non-trivial optimization prob-lem must be solved.
For example, naively select-ing a few words that appear in low-surprisal con-texts may facilitate their acquisition, but at the ex-pense of other words within the same context thatmay appear in a larger number of low-surprisalcontexts further in the text.To address this problem, we approach it witha formulation of a factor graph that takes globalstructure of the text into account.
Factor graph for-malism allows us to capture local features of indi-vidual contexts, such as lexical and syntactic sur-prisal, while inducing dependencies between con-sequent ?switching decisions?
in the text.
Max-imizing likelihood of the joint probability underthe factorization of this graph yields an optimalsequence of these ?switching decisions?
in the en-tirety of the text.
Maximizing joint likelihood, aswe will show in the next section, is a surrogate tomaximizing the probability of the learner acquir-ing novel words through the process of reading thegenerated text.564wi Known     + Constrained Unknown + Constrained Unknown + Unconstrained Known     + Unconstrained.
.
.w1 w2 w3 w4 w5 w|V |KNOW DON?T KNOW ?ikMeaning of  malhela?Existingknowledgeof wordUser?s lexical knowledge modelzikThe door   malhela   to the beachwiinfused wordKNOW DON?T KNOW ContextualInterpretationof wordUpdatedknowledgebeliefUpdatedKnowldgeModelLEGENDMixed-Language ContentFigure 1: Overview of the approach.
Probabilistic learner model (PLM) provides the current value of thebelief in the learner?s knowledge of any given word.
Local contextual model provides the value of thebelief in learning the word from the context alone.
Upon exposure of the learner to the word in the givencontext, PLM is updated with the posterior belief in the user?s knowledge of the word.3.2 Language Learner ModelA simplified model of the learner, that we shallterm a Probabilistic Learner Model (PLM) servesas a basis for our approach.
PLM is a model ofa learner?s lexical knowledge at any given time.PLM models the learner as a vector of indepen-dent Bernoulli distributions, where each compo-nent represents a probability of the learner know-ing the corresponding word.
We motivate a proba-bilistic approach by taking the perspective of mea-suring our belief in the learner?s knowledge of anygiven word, rather than the learner?s uncertainty inown knowledge.
Formally, we can fully specifythis model for learner i as follows:Ui= (pii0, pii1, .
.
.
, pii|V |) (1)where V is the vocabulary set ?
identicalacross all users, and piijis our degree of belief inthe learner i?s knowledge of a target wordwj?
V .Statistical estimation techniques exist for estimat-ing an individual?s vocabulary size, such as (Bhatand Sproat, 2009; Beglar, 2010), and can be di-565rectly employed for estimating the parameters ofthis model as our prior belief about user i?s knowl-edge.The primary motivation behind a probabilisticuser model, is to provide a mechanism for up-dating these probabilities as the user progressesthrough her reading.
Maximizing the parametersof the PLM under a given finite span of code-switched text, thus, provides a handle for generat-ing optimal code-switched content.
Additionally,a probabilistic approach allows for a natural inte-gration of the user model with the uncertainty inother components of the system, such as uncer-tainty in determining the degree of constraint im-posed by the context, and in bitext alignment.3.3 Model overviewAt the high level, as illustrated in Figure 1, our ap-proach integrates the model of the learner (PLM)with the local contextual features to update thePLM parameters incrementally as the learner pro-gresses through the text.
The fundamental as-sumption behind our approach is that the learner?sknowledge of a given word after observing it ina sentence is a function of 1) the learner?s previ-ous knowledge of the word, prior to observing itin a given sentence and 2) a degree of constraintthat a given context imposes on the meaning of thenovel word, and is directly related to the surprisalof novel word in that context.
Broadly, as thelearner progresses from one sentence to the next,exposing herself to more novel words, the updatedparameters of the language model in turn guidethe selection of new ?switch-points?
for replac-ing source words with the target foreign words.
Inpractice, however, this process is carried out im-plicitly and off-line by optimizing the estimatedprogress of the learner?s PLM, without dynamicfeedback.
Next, we describe the model in detail.3.4 Switching Factor Graph ModelTo aid in the specification of the factor graph struc-ture, we introduce new terminology.
Because thePLM is updated progressively, we will refer to theparameters of the PLM for a given word wiafterobserving its kthappearance (instance) in the text,as the learner?s state of knowledge of that word,and denote it as a binary random variable zik.P (zik= 1) =??
?Probability thatword wi?
Vis understood on kthexposureWithout explicit testing of the user, this variableis hidden.
We can view the prior learning modelas the parameters of the vector of random variables(z00, z10, .
.
.
z|V |0).The key to our approach is in how the param-eters of these hidden variables are updated fromrepeated exposures to words in various contexts.Intuitively, an update to the parameter of zikfromzik?1occurs after the learner observes word wiina context (this may be an n-gram, an entire sen-tence or paragraph containing wi, but we will re-strict our attention to fixed-length n-grams).
In-tuitively an update to the parameter of zik?1willdepend on how ?constrained?
the meaning of wiis in the given context.
We will refer to it as the?learnability?, denoted by Lki, of word wion itskthappearance, given its context.
Formally, wewill define ?learnability?
as follows:P (Lik= 1|wi,w\i, z\ik) =P (constrained(wi) = 1|w)?i 6=jP (zjk= 1)(2)where w\irepresents the set of words that com-prise the context window of wi, not including wi,and z\ikare the states corresponding to each of thewords in w\i.
P (constrained(wi) = 1|w) is a realvalue (scaled between 0 and 1) that represents thedegree of constraint imposed on the meaning ofword wiby its context.
This value comes froma binary prediction model trained to predict the?predictability?
of a word in its context, and isbased on the dataset that we collected (describedlater in the paper).
Generally, this value maycome directly from the surprisal quantity given bya language model, or may incorporate additionalfeatures that are found informative in predictingthe constraint on the word.
Finally, the quantityis weighted by the parameters of the state vari-ables corresponding to the words other than wicontained in the context.
This encodes an intu-ition that a degree of predictability of a given wordgiven its context is related to the learner?s knowl-edge of the other words in that context.
If, for ex-ample, in the sentence ?pass me the salt and pep-per, please?, both ?salt?
and ?pepper?
are substi-tuted with their foreign translations that the learneris unlikely to know, it?s equally unlikely that shewill learn them after being exposed to this con-text, as the context itself will not offer sufficient566information for both words to be inferred simulta-neously.
On the other hand, substituting ?salt?
and?pepper?
individually, is likely to make it mucheasier to infer the meaning of the other.zik 1zikLikFigure 2: A noisy-OR combination of the learner?sprevious state of knowledge of the word zik?1andthe word?s ?learnability?
in the observed contextLikThe updated parameter of zikis obtained from anoisy-OR combination of the parameters of zik?1and Lik:P (zik= 1|zik?1, Lik) =1?
[1?
P (Lik= 1)][1?
P (zk?1= 1)]A noisy-OR-based CPD provides a convenientand tractable approximation in capturing the in-tended intuition: updated state of knowledge of agiven word will increase if the word is observed ina ?good?
context, or if the learner already knowsthe word.Combining Equation 2 for each word in the con-text using the noisy-OR, the updated state for wordwiwill now be conditioned on zik?1, z\ik,wk.
Be-cause of the dependence of each z in the contexton all other hidden variables in that context, wecan capture the dependence using a single factorper context, with all of the z variables taking partin a clique, whose dimension is the size of the con-text.We will now introduce a dual interpretation ofthe z variables: as ?switching?
variables that de-cide whether a given word will be replaced with itstranslation in the foreign language.
If, for exam-ple, all of the words have high probability of be-ing known by a learner, than maximizing the jointlikelihood of the model will result in most of thewords ?switched-out?
?
a desired result.
For anarbitrary prior PLM and the input text, maximiz-ing joint likelihood will result in the selection of?switched-out?
words that have the highest finalprobability of being ?known?
by the learner.3.5 InferenceThe problem of selecting ?switch-points?
reducesto the problem of inference in the resulting factorgraph.
Unfortunately, without a fairly strong con-straint on the collocation of switched words, theresulting graph will contain loops, requiring tech-niques of approximate inference.
To find the opti-mal settings of the z variables, we apply the loopymax-sum algorithm.
While variants of loopy be-lief propagation, in general, are not guaranteed toconverge, we found that the convergence does in-deed occur in our experiments.3.6 Predicting ?predictable?
wordsWe carried out experiments to determine whichwords are likely to be inferred from their context.The collected data-set is then used to train a logis-tic regression classifier to predict which words arelikely to be easily inferred from their context.
Webelieve that this dataset may also be useful to re-searchers in studying related phenomena, and thusmake it publicly available.For this task, we focus only on the followingcontext features for predicting the ?predictability?of words: n-gram probability, vector-space simi-larity score, coreferring mentions.
N-gram prob-ability and vector-space similarity2score are allcomputed within a fixed-size window of the word(trigrams using Microsoft N-gram service).
Coref-erence feature is a binary feature which indicateswhether the word has a co-referring mention in a3-sentence window preceding a given context (ob-tained using Stanford?s CoreNLP package).
Wetrain L2-regularized logistic regression to predicta binary label L ?
{Constrained,Unconstrained}using a crowd-sourced corpus described below.3.7 Corpus ConstructionFor collecting data about which words are likelyto be ?predicted?
given their content, we devel-oped an Amazon Mechanical Turk task that pre-sented turkers with excerpts of a short story (En-glish translation of ?The Man who Repented?
by2we employ C&W word embeddings from http://metaoptimize.com/projects/wordreprs/567wiwjwiwiwjwjwkwiS 1S 2S 3S 4S 5S 6Original Text Factor GraphMapping f 1f 2f 3f 4f 5zi0zi1zi2zi3z j0zj1zj2 zk0Figure 3: Sequence of sentences in the text (left) is mapped into a factor graph, whose nodes correspondto specific occurences of individual words, connected in a clique corresponding to a context in which theword occurs.Ana Maria Matute), with some sentences contain-ing a blank in place of a word.
Only content wordswere considered for the task.
Turkers were re-quired to type in their best guess, and the num-ber of semantically similar guesses were countedby an average number of 6 other turkers.
A ra-tio of the median of semantically similar guessesto the total number of guesses was then taken asthe score representing ?predictability?
of the wordbeing guessed in the given context.
All words cor-responding to blanks whose scores were equal toand above 0.6 were than taken as a positive la-bel (Constrained) and scores below 0.6 were takenas a negative label (Unconstrained).
Turkers thatjudged the semantic similarity of the guesses ofother turkers achieved an average Cohen?s kappaagreement of 0.44, indicating fair to poor agree-ment.4 ExperimentsWe carried out experiments on the effectivenessof our approach using the Amazon MechanicalTurk platform.
Our experimental procedure wasas follows: 162 turkers were partitioned into fourgroups, each corresponding to a treatment con-dition: OPT (N=34), HF (N=41), RANDOM(N=43), MAN (N=44).
Each condition corre-Figure 4: Visualization of the most ?predictable?words in an excerpt from the ?The Man who Re-pented?
by Ana Maria Matute (English transla-tion).
Font-size correlates with the score given byjudge turkers in evaluating guesses of other turk-ers that were presented with the same text, but theword replaced with a blank.
Snippet of the datasetthat we release publicly.sponded to a model used to generate the presentedcode-switched text.
For all experiments, the textused was a short story ?Lottery?
by Shirley Jack-son, and a total number of replaced words wascontrolled (34).
Target vocabulary consisted ofwords from an artificial language, generated stat-ically by a mix of words from several languages.Below we describe the individual treatment condi-tions:RANDOM (Baseline): words for switching are568selected at random from content only words.HF (High Frequency) Baseline: words forswitching are selected at random from a rankedlist of words that occur most frequently in the pre-sented text.MAN (Manual) Baseline: words for switch-ing are selected manually by the author, based onthe intuition of which words are most likely to beguessed in context.OPT (Optimization-based): factor graph-basedmodel proposed in this paper is used for generat-ing code-switched content.
The total number ofswitched words generated by this method is usedas a constant for all baselines.Turkers were solicited to participate in a studythat involved ?reading a short story with a twist?
(title of HIT).
Not the title, nor the descriptiongave away the purpose of the study, nor that itwould be followed by a quiz.
Time was not con-trolled for this study, but on average turkers took27 minutes to complete the reading.
Upon com-pleting the reading portion of the task, turkerswere presented with novel sentences that featuredthe words observed during reading, where onlyone of the sentences used the word in a semanti-cally correct way.
Turkers were asked to select thesentence that ?made the most sense?.
An exampleof the sentences presented during the test:Example 1XMy edzino loves to go shopping everyweekend.The edzino was too big to explore on ourown, so went with a group.English word: wifeExample 2X His unpreadvers were utterly confus-ing and useless.The unpreadvers was so strong, that hehad to go to a hospital.English word: directionsA ?recall?
metric was computed for each turker,defined as the ratio of correctly selected sentencesto the total number of sentences presented.
The?grand-average recall?
across all turkers was thencomputed and reported here.5 ResultsWe perform a one-way ANOVA across the fourgroups listed above, with the resulting F = 11.38and p = 9.7e?7.
Consequently, multiple pairwisecomparison of the models was performed with theBonferroni-corrected pairwise t-test, yielding theonly significantly different recall means betweenHF ?
MAN (p = 0.00018), RANDOM ?MAN (p = 2.8e ?
6), RANDOM ?
OPT(p = 0.00587).
The results indicate that, whilenone of the automated methods (RANDOM ,HF , OPT ) outperform manually generated code-switched text, OPT outperforms the RANDOMbaseline (no decisive conclusion can be drawnwith respect to the HF ?
RANDOM pair).Additionally, we note, that for words with fre-quency less than 4, OPT produces recall that ison average higher than theHF baseline (p=0.043,Welch?s t-test), but at the expense of higher fre-quency words.llllll0.000.250.500.75HF MAN OPT RANDOMConditionRecallConditionHFMANOPTRANDOMFigure 5: Results presented for 4 groups, sub-jected to 4 treatment conditions: RANDOM ,HF , MAN , OPT .
Recall performance foreach group corresponds to the average ratio ofselected sentences that correctly utilize code-switched words in novel contexts, across all turk-ers.6 DiscussionWe observe from our experiments that theoptimization-based approach does not in generaloutperform the HF baseline.
The strength of the569lll0.00.20.40.60.8HF OPTConditionRecall ConditionHFOPTFigure 6: Subset of the results for 2 of the 4 treat-ment conditions: HF and OPT that correspondto recall only for words with item frequency in thepresented text below 4.frequency-based baseline is attributed to a well-known phenomenon that item frequency promotesthe ?noticing?
effect during reading, critical fortriggering incidental lexical acquisition.
Gener-ating code-switched text by replacing high fre-quency content words, thus, in general is a sim-ple and viable approach for generating effectivereading-based L2 curriculum aids.
However, thismethod is fundamentally less flexible than theoptimization-based method proposed in this paper,for several reasons:?
The optimization-based method explicitlymodels the learner and thus generates code-switched text progressively more fit for agiven individual, even across a sequence ofmultiple texts.
A frequency-based baselinealone would generate content at approxi-mately the same level of difficulty consis-tently, with the pattern that words that tend tohave high frequency in the natural languagein general to be the ones that are ?switched-out?
most often.?
An optimization-based approach is able toelicit higher recall in low frequency words,as the mechanism for their selection is drivenby the context in which these words appear,rather than frequency alone, favoring thosethat are learned more readily through context.Moreover, the proposed method in this pa-per is extensible to more sophisticated learnermodels, with a potential to surpass the resultspresented here.
Another worthwhile applica-tion of this method is as a nested componentwithin a larger optimization-based tool, thatin addition to generating code-switched textas demonstrated here, aids in selecting con-tent (such as popular books) as units in thecode-switched curriculum.7 Future WorkIn this work we demonstrated a pilot implemen-tation of a model-based, optimization-based ap-proach to content generation for assisting in thereading-based L2 language acquisition.
Our ap-proach is based on static optimization, and whileit would, in theory progress in difficulty with morereading, its open-loop nature precludes it frommaintaining an accurate model of the learner inthe long-term.
For generating effecting L2 con-tent, it is important that the user be kept in a ?zoneof proximal development?
?
a tight region wherethe level of the taught content is at just the rightdifficulty.
Maintaining an accurate internal modelof the learner is the single most important require-ment for achieving this functionality.
Closed-looplearning, with active user feedback is, thus, goingto be functionally critical component of any sys-tem of this type that is designed to function in thelong-term.Additionally, our approach is currently a proof-of-concept of an automated method for generat-ing content for assisted L2 acquisition, and is lim-ited to artificial language and only isolated lexi-cal items.
The next step would be to integratebitext alignment across texts in two natural lan-guages, inevitably introducing another stochas-tic component into the pipeline.
Extending thismethod to larger units, like chunks and simplegrammar is another important avenue along whichwe are taking this work.
Early results from concur-rent research indicate that ?code-switched based?method proposed here is also effective in elicitingacquisition of multi-word chunks.ReferencesHeike Adel, Ngoc Thang Vu, Franziska Kraus, TimSchlippe, Haizhou Li, and Tanja Schultz.
2012.
Re-570current neural network language modeling for codeswitching conversational speech.
ICASSP.David Beglar.
2010.
A rasch-based validation of thevocabulary size test.
Language Testing, 27(1):101?118.Hedi M Belazi, Edward J Rubin, and Almeida Jacque-line Toribio.
1994.
Code switching and x-bar the-ory: The functional head constraint.
Linguistic in-quiry, pages 221?237.Suma Bhat and Richard Sproat.
2009.
Knowingthe unseen: estimating vocabulary size over unseensamples.
In Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 1-Volume1, pages 109?117.
Association for ComputationalLinguistics.Rakesh Mohan Bhatt.
1997.
Code-switching,constraints, and optimal grammars.
Lingua,102(4):223?251.Or Biran, Samuel Brody, and Noemie Elhadad.
2011.Putting it simply: a context-aware approach to lexi-cal simplification.Fabian Blaicher.
2011.
SMT-based Text Generationfor Code-Switching Language Models.
Ph.D. thesis,Nanyang Technological University, Singapore.Arielle Borovsky, Jeffrey L Elman, and Marta Kutas.2012.
Once is enough: N400 indexes semantic inte-gration of novel word meanings from a single expo-sure in context.
Language Learning and Develop-ment, 8(3):278?302.Tom Cobb.
2007.
Computing the vocabulary demandsof l2 reading.
Language Learning & Technology,11(3):38?63.Noemie Elhadad and Komal Sutaria.
2007.
Min-ing a lexicon of technical terms and lay equivalents.In Proceedings of the Workshop on BioNLP 2007:Biological, Translational, and Clinical LanguageProcessing, pages 49?56.
Association for Compu-tational Linguistics.Stefan L Frank, Leun J Otten, Giulia Galli, andGabriella Vigliocco.
2013.
Word surprisal predictsn400 amplitude during reading.
In Proceedings ofthe 51st annual meeting of the Association for Com-putational Linguistics, pages 878?883.Fred Genesee.
2001.
Bilingual first language acqui-sition: Exploring the limits of the language faculty.Annual Review of Applied Linguistics, 21:153?168.David R Hill.
2008.
Graded readers in english.
ELTjournal, 62(2):184?204.Ben Hutchinson.
2005.
Modelling the substitutabil-ity of discourse connectives.
In Proceedings of the43rd Annual Meeting on Association for Computa-tional Linguistics, pages 149?156.
Association forComputational Linguistics.David Kauchak.
2013.
Improving text simplificationlanguage modeling using unsimplified text data.
InProceedings of ACL.Marta Kutas and Steven A Hillyard.
1984.
Brain po-tentials during reading reflect word expectancy andsemantic association.
Nature.James P Lantolf and Gabriela Appel.
1994.
Vy-gotskian approaches to second language research.Greenwood Publishing Group.John M Lipski.
2005.
Code-switching or borrowing?no s?e so no puedo decir, you know.
In Selected Pro-ceedings of the Second Workshop on Spanish Soci-olinguistics, pages 1?15.Ernesto Macaro.
2005.
Codeswitching in the l2classroom: A communication and learning strat-egy.
In Non-native language teachers, pages 63?84.Springer.Lesley Milroy and Pieter Muysken.
1995.
Onespeaker, two languages: Cross-disciplinary per-spectives on code-switching.
Cambridge UniversityPress.Visvaganthie Moodley.
2010.
Code-switching andcommunicative competence in the language class-room.
Journal for Language Teaching, 44(1):7?22.Ian SP Nation.
2001.
Learning vocabulary in anotherlanguage.
Ernst Klett Sprachen.Richard C Schmidt and Richard W Schmidt.
1995.
At-tention and awareness in foreign language learning,volume 9.
Natl Foreign Lg Resource Ctr.Norbert Schmitt, Diane Schmitt, and CarolineClapham.
2001.
Developing and exploring the be-haviour of two new versions of the vocabulary levelstest.
Language testing, 18(1):55?88.Advaith Siddharthan, Ani Nenkova, and KathleenMcKeown.
2004.
Syntactic simplification for im-proving content selection in multi-document sum-marization.
In Proceedings of the 20th internationalconference on Computational Linguistics, page 896.Association for Computational Linguistics.Advaith Siddharthan.
2006.
Syntactic simplificationand text cohesion.
Research on Language and Com-putation, 4(1):77?109.Thamar Solorio and Yang Liu.
2008.
Learning to pre-dict code-switching points.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 973?981.
Association forComputational Linguistics.Mark Yatskar, Bo Pang, Cristian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
For the sake of sim-plicity: Unsupervised extraction of lexical simplifi-cations from wikipedia.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 365?368.
Association forComputational Linguistics.571
