Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 902?912,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsUsing Unknown Word Techniques To Learn Known WordsKostadin CholakovUniversity of GroningenThe Netherlandsk.cholakov@rug.nlGertjan van NoordUniversity of GroningenThe Netherlandsg.j.m.van.noord@rug.nlAbstractUnknown words are a hindrance to the perfor-mance of hand-crafted computational gram-mars of natural language.
However, wordswith incomplete and incorrect lexical entriespose an even bigger problem because they canbe the cause of a parsing failure despite beinglisted in the lexicon of the grammar.
Such lex-ical entries are hard to detect and even harderto correct.We employ an error miner to pinpoint wordswith problematic lexical entries.
An auto-mated lexical acquisition technique is thenused to learn new entries for those wordswhich allows the grammar to parse previouslyuncovered sentences successfully.We test our method on a large-scale grammarof Dutch and a set of sentences for which thisgrammar fails to produce a parse.
The appli-cation of the method enables the grammar tocover 83.76% of those sentences with an ac-curacy of 86.15%.1 IntroductionIn this paper, we present an automated two-phasemethod for treating incomplete or incorrect lexicalentries in the lexicons of large-scale computationalgrammars.
The performance of our approach istested in a case study with the wide-coverage Alpinogrammar (van Noord, 2006) of Dutch.
When ap-plied to real test sentences previously not coveredby Alpino, the method causes a parsing coverage of83.76% and the accuracy of the delivered analysesis 86.15%.The main advantage of our approach is the suc-cessful combination of efficient error mining andlexical acquisition techniques.
In the first phase, er-ror mining pinpoints words which are listed in thelexicon of a given grammar but which neverthelessoften lead to a parsing failure.
This indicates that thecurrent lexical entry for such a word is either wrongor incomplete and that one or more correct entriesfor this word are missing from the lexicon.
Our ideais to treat the word as if it was unknown and, in thesecond phase, to employ lexical acquisition (LA) tolearn the missing correct entries.In the case study presented here, we employ theiterative error miner of de Kok et al (2009).
Sinceit has to be run on a large parsed corpus, we haveparsed the Flemish Mediargus corpus (?1.5 billionwords) with Alpino.
The reason for this choice isthe relatively large lexical difference between stan-dard Dutch and Flemish.
This increases the chanceto encounter words which are used in Flemish in away not handled by Alpino yet.For example, the word afwater (to drain) is listedas a first person singular present verb in the Alpinolexicon.
However, the error miner identifies thisword as the reason for the parsing failure of 9 sen-tences.
A manual examination reveals that the wordis used as a neuter noun in these cases?
het afwater(the drainage).
Since there is no noun entry in thelexicon, Alpino was not able to produce full-spananalyses.After the error miner identifies afwater as a prob-lematic word, we employ our machine learningbased LA method presented in Cholakov and vanNoord (2010) to learn new entries for this word.This method has already been successfully appliedto the task of learning lexical entries for unknownwords and, as the error miner, it can be used ?out ofthe box?.
LA correctly predicts a neuter noun en-902try for afwater and the addition of this entry to thelexicon enables Alpino to cover the 9 problematicsentences from the Mediargus corpus.It should be noted that since our approach cannotdifferentiate between incomplete and incorrect en-tries, no entry in the lexicon is modified.
We simplyadd the lexical entries which, according to the LAmethod, are most suitable for a given problematicword and assume that, if these entries are correct,the grammar should be able to cover previously un-parsable sentences in which the word occurs.The remainder of the paper is organised as fol-lows.
Section 2 describes the error miner.
Section3 presents the Alpino grammar and parser and theLA technique we employ.
Section 4 describes anexperiment where error mining is performed on theMediargus corpus and then, LA is applied to learnnew lexical entries for problematic words.
Section5 discusses the effect which the addition of the newentries to the lexicon has on the parsing coverageand accuracy.
Section 6 provides a comparison be-tween our approach and previous work similar in na-ture.
This section also discusses the application ofour method to other systems and languages as wellas some ideas for future research.2 Error MiningThe error miner of de Kok et al (2009) combines thestrengths of the error mining methods of van Noord(2004) and Sagot and de la Clergerie (2006).
Theidea behind these methods is that grammar errorslead to the parsing failure of some grammatical sen-tences.
By running the grammar over a large corpus,the corpus can be split into two subsets?
the set ofsentences which received a full-span parse and theset of sentences failed to parse.
Words or n-gramswhich occur in the latter set have a suspicion of be-ing the cause of parsing failures.van Noord (2004) defines the suspicion of a wordsequence as:(1) S(wi...wj) =C(wi...wj |error)C(wi...wj)where C(wi...wj) is the number of sentenceswhich the sequence wi...wj occurs in andC(wi...wj |error) is the number of occurrences ofthe sequence in unparsable sentences.While this method performs well in identifyingwords and n-grams that are unambiguously suspi-cious, it also assigns incorrectly a high suspicionto forms which happen to occur often in unparsablesentences by ?bad luck?.
The iterative error miningalgorithm of Sagot and de la Clergerie (2006) tacklesthis problem by taking the following into account:?
If a form occurs within parsable sentences, itbecomes less likely for it to be the cause of aparsing failure.?
The suspicion of a form depends on the suspi-cions of the other forms in the unparsable sen-tences it occurs in.?
A form observed in a shorter sentence is ini-tially more suspicious than a form observed ina longer one.However, because of data sparseness problems, thismethod is only able to handle unigrams and bigrams.Another potential problem is the absence of criteriato determine when to use unigrams and when bi-grams to represent forms within a given sentence.Consider the trigram w1, w2, w3 where w2 is thecause of a parsing failure.
In this case, the wholetrigram as well as the bigrams w1, w2 and w2, w3will become suspicious which would prevent the un-igram w2 from ?manifesting?
itself.To avoid this problem, de Kok et al (2009) usesa preprocessor to the iterative miner of Sagot andde la Clergerie (2006) which iterates through a sen-tence of unigrams and expands unigrams to longern-grams when there is evidence that this is useful.
Aunigram w1 is expanded to a bigram w1, w2 if thisbigram is more suspicious than both of its unigrams.The general algorithm is that the expansion to an n-gram i...j is allowed when the following two condi-tions are fulfilled:(2) S(i...j) > S(i...j ?
1) ?
expFactorS(i...j) > S(i + 1...j) ?
expFactorWithin the preprocessor, suspicion is defined asshown in (1) and the expFactor is a parameter spe-cially designed to deal with data sparseness.As the error mining technique of de Kok et al(2009) successfully overcomes the problems which903the other error mining methods we discussed en-counter, we have chosen to employ this techniquein our experiment.3 Automated Lexical Acquisition3.1 The Alpino Grammar and ParserSince we employ Alpino for the purposes of our casestudy, it is convenient to explain the LA method wehave chosen to use in the context of this system.The Alpino wide-coverage parser is based on alarge stochastic attribute value grammar.
The gram-mar takes a ?constructional?
approach, with richlexical representations stored in the lexicon and alarge number of detailed, construction specific rules(about 800).Currently, the lexicon contains over 100K lexicalentries and a list of about 200K named entities.
Eachword is assigned one or more lexical types.
Forexample, the verb amuseert (to amuse) is assignedtwo lexical types?
verb(hebben,sg3,intransitive) andverb(hebben,sg3,transitive)?
because it can be usedeither transitively or intransitively.
The other typefeatures indicate that it is a present third person sin-gular verb and it forms perfect tense with the auxil-iary verb hebben.3.2 Learning AlgorithmThe goal of the LA method we describe Cholakovand van Noord (2010) is to assign correct lexicaltype(s) to a given unknown word.It takes into account only open-class lexical types:nouns, adjectives and verbs.
The types considered inthe learning process are called universal types1.For a given word, a maximum entropy (ME)based classifier takes various morphological andsyntactic features as input and outputs a ranked listof lexical types.
The probability of a lexical type t,given an unknown word and its context c is:(3) p(t|c) =exp(?i?ifi(t,c))?t?
?Texp(?i?ifi(t?,c))where fi(t, c) may encode arbitrary characteristicsof the context and < ?1,?2, ... > is a weightingparameter which maximises the entropy and can be1The adjectives can be used as adverbs in Dutch and thus,the latter are not considered to be an open class.Featuresi) a, af, afw, afwaii) r, er, ter, ateriii) particle yes #in this case afiv) hyphen nov) noun?het,sg?, verb?sg1?vi) noun(het,count,sg), noun(de,count,pl)vii) noun(het), noun(count), noun(sg), noun(de)noun(pl)Table 1: Features for afwaterevaluated by maximising the pseudo-likelihood on atraining corpus (Malouf, 2002).Table 1 shows the features for afwater, the wordwe discussed in Section 1.
Row (i) contains 4 sepa-rate features derived from the prefix of the word and4 other suffix features are given in row (ii).
The twofeatures in rows (iii) and (iv) indicate whether theword starts with a particle and if it contains a hy-phen, respectively.Further, the method we describe in Cholakovand van Noord (2009) is applied to generate theparadigm(s) of each word in question.
This methoduses a finite state morphology to generate possibleparadigm(s) for a given word.
The morphology doesnot have access to any additional linguistic infor-mation and thus, it generates all possible paradigmsallowed by the word orthography.
Then, the num-ber of search hits Yahoo returns for each form ina given paradigm is combined with some simpleheuristics to determine the correct paradigm(s).
Theweb search heuristics are also able to determine thecorrect definite article (de or het) for words withnoun paradigms.One verb and one noun paradigm are generatedfor afwater.
In these paradigms, afwater is listed asa first person singular present verb form and a sin-gular het noun form, respectively.
This informationis explicitly used as features in the classifier whichis shown in row (v) of Table 1.Next, syntactic features for afwater are obtainedby extracting a number of sentences which it oc-curs in from large corpora or Internet.
These sen-tences are parsed with a different ?mode?
of Alpinowhere this word is assigned all universal types, i.e.
itis treated as being maximally ambiguous.
For eachsentence only the parse which is considered to be thebest by the Alpino statistical disambiguation model904is preserved.
Then, the lexical type that has beenassigned to afwater in this parse is stored.
Duringparsing, Alpino?s POS tagger (Prins and van Noord,2001) keeps filtering implausible type combinations.For example, if a determiner occurs before the un-known word, all verb types are typically not takeninto consideration.
This heavily reduces the compu-tational overload and makes parsing with universaltypes computationally feasible.When all sentences have been parsed, a list canbe drawn up with the types that have been used andtheir frequency:(4) noun(het,count,sg) 54noun(de,count,pl) 7tmp noun(het,count,sg) 4adjective(no e(adv)) 4proper name(sg,?ORG?)
1The lexical types assigned to afwater in at least 80%of the parses are used as features in the classifier.These are the two features in row (vi) of Table 1.Further, as illustrated in row (vii), each attribute ofthe considered types is also taken as a separate fea-ture.After the classifier predicts lexical types for eachword, these predictions are subject to two additionalsteps of processing.
In the first one, the generatedword paradigms are explicitly used as a filteringmechanism.
When a word is assigned a verb or anadjective type by the classifier but there is no verb oradjective paradigm generated for it, all verb or ad-jective predictions for this word are discarded.The output of this ?filtering?
is further processedin the second step which deals with the correctprediction of subcategorization frames for verbs.Following the observations made in Korhonen etal.
(2000), Lapata (1999) and Messiant (2008),Cholakov and van Noord (2010) employ a maximumlikelihood estimate (MLE) from observed relativefrequencies with an empirical threshold to filter outlow probability frames.Since some frames could be very infrequent andthe MLE method may not capture them, the gener-ated word paradigms are used to increase the num-ber of contexts observed for a given verb.
Addi-tional sentences are extracted for each form in theparadigm of a given word predicted to be a verb.These sentences are again parsed with the universaltypes.
Then we look up the assigned universal verbtypes, calculate the MLE for each subcategorizationframe and filter out frames with MLE below someempirical threshold.4 Learning New Lexical EntriesBefore we start with the description of the exper-iment, it is important to note that Alpino is veryrobust?
essentially, it always produces a parse.
Ifthere is no analysis spanning the whole sentence,the parser finds all parses for each substring and re-turns what it considers to be the best sequence ofnon-overlapping parses.
However, in the context ofthis experiment, a sentence will be considered suc-cessfully parsed only if it receives a full-span anal-ysis.
For the sake of clarity, from now on we shalluse the terms coverage and cover only with regardto such sentences.
The term parsing failure shall re-fer to a sentence for which Alpino fails to produce afull-span analysis.4.1 Error Mining on MediargusThe first step in our experiment is to perform er-ror mining on the Mediargus corpus.
The corpusconsists of texts from Flemish newspapers from theperiod between 1998 and 2007.
It contains about1.5 billion words (?78M sentences).
The corpushas been parsed with Alpino and the parsing resultsare fed into the error miner of de Kok et al (2009).The parser has not produced a full-span analysis for7.28% of the sentences (?5.7M sentences).When finished, the error miner stores the resultsin a data base containing potentially problematic n-grams.
Each n-gram is linked to its suspicion scoreand the sentences which it occurs in and which werenot covered by Alpino.Before proceeding with LA, however, we shouldidentify the n-grams which are indicative for a prob-lem in the lexicon.
The first step in this directionis to extract all unigrams from the data base whichhave a suspicion equal to or greater than 0.7 togetherwith the uncovered sentences they occur in.
Thisresulted in a list containing 4179 unique unigrams.Further, we select from this list only those unigramswhich have lexical entries in the Alpino lexicon andoccur in more than 5 sentences with no full-span905parse.
Sometimes, the error miner might be wrongabout the exact word which causes the parsing fail-ure for a given sentence.
The 5 sentences empiri-cal threshold is meant to guarantee that the selectedwords are systematically causing problems for theparser.The result of this selection is 36 unigrams (words)which occur in a total of 388 uncovered sentences?an average of 10.78 sentences per word.
The smallnumber of selected words is due to the fact thatmost of the problematic 4179 unigrams represent to-kenization errors (two or more words written as one)and spelling mistakes which, naturally, are not listedin the Alpino lexicon.
Very few of the 4179 uni-grams are actual unknown words.
Table 2 showssome of the problematic unigrams and their suspi-cions.opVorig 0.898989GentHoewel 0.89759Nieuwpoortl 0.897414SportTijdens 0.897016DirvenDe 0.896428mistrap 0.896038Dwoeurp 0.896013passerde 0.89568doorHugo 0.893901goedkmaken 0.892407ManneN 0.891539toegnag 0.891523Table 2: Problematic unigrams and their suspicionsIt can be seen immediately that most of the uni-grams presented in the table are tokenization errors.There are also some typos.
The unigram passerdeshould be written as passeerde, the past singularverb form of the verb ?to pass?
and toegnag is themisspelled noun toegang (access).
The only prob-lematic unigram with a lexical entry in the Alpinolexicon is mistrap (misstep, to misstep).Although the experiment setup yields a small testset, we employ it because the words in this set repre-sent ?clear-cut?
cases.
This allows us to demonstratebetter the effect of our technique.4.2 Applying Lexical AcquisitionOur assumption is that incomplete or incorrect lex-ical entries prevented the production of full-spanparses for the 388 sentences in which the 36 prob-lematic words pinpointed by the error miner oc-cur.
That is why, in the second step of the exper-iment, these words are temporarily removed fromthe Alpino lexicon, i.e.
they are treated as unknownwords, and we employ the LA method presented inthe previous section to learn offline new lexical en-tries for them.The setup for the learning process is exactly thesame as in Cholakov and van Noord (2010).
The setof universal types consists of 611 types and the ME-based classifier has been trained on the same set of2000 words as in Cholakov and van Noord (2010).Those types predicted by the classifier which ac-count together for less than 5% of probability massare discarded.In order to increase the number of observed con-texts for a given word when parsing with the univer-sal types, up to 100 additional sentences in which theword occurs are extracted from Internet.
However,when predicting new lexical entries for this word,we want to take into account only sentences whereit causes a parsing failure.
It is in such sentenceswhere a new lexical entry can be learnt through LA.For example, the LA method would be able to pre-dict a noun entry for afwater if it focuses only oncontexts where it has a noun reading, i.e.
on sen-tences not covered by Alpino.That is why, the sentences we extracted from In-ternet are first parsed with the standard Alpino con-figuration.
When averaging over the 36 sentencesets, it turns out that Alpino has been able to cover10.05% of the sentences.
Although we cannot besure that the 36 words are the cause of a parsingfailure in each of the uncovered sentences, this lowcoverage indicates once more that Alpino has sys-tematic problems with sentences containing thesewords.Then, the uncovered sentences from Internet to-gether with the 388 problematic sentences from theMediargus corpus are parsed with Alpino and theuniversal types.
For example, the list of univer-sal types assigned to afwater in (4) contains mostlynoun types, i.e.
the kind of types which are currentlynot in the lexicon for this word and which we wantto learn.The result of the LA process is the prediction ofa total of 102 lexical types, or 2.83 types per word.This high number is due to the fact that 25 wordsreceive verb predictions.
Since a verb can have vari-906ous subcategorization frames, there is one type as-signed for each frame.
For example, inscheppen(to spoon in(to)) receives 3 types which differ onlyin the subcategorization frame?
verb(hebben,inf,tr.),verb(hebben,inf,intr.)
and verb(hebben,inf,np np).However, the infinitive in Dutch is also theform for plural present and inscheppen correctlyreceives 3 more predictions?
verb(hebben,pl,tr.),verb(hebben,pl,intr.)
and verb(hebben,pl,np np).Let us examine the most frequent types of lexiconerrors for the 36 problematic words by looking atthe current Alpino lexical entries for some of thesewords and the predictions they receive from the LAmethod.
The original Alpino entries for 19 of the25 words predicted to be verbs are a product of aspecific lexical rule in the grammar.
Consider thefollowing sentences:(5) a. IkIschepspoondethesoepsoupinindethekom.bowl?I spoon the soup into the bowl.?b.
datthatikIdethesoepsoupdethekombowlininschepspoon?that I spoon the soup into the bowl?c.
datthatikIdethesoepsoupdethekombowlinschepin spoon?that I spoon the soup into the bowl?We see in (5-b) that the preposition in is used as apostposition in the relative clause.
However, in suchcases, there is linguistic evidence that in behaves asa separate verb particle.
That is why, as shown in(5-c), people sometimes write in and the verb to-gether when they occur next to each other in the sen-tence.
To account for this, Alpino employs a speciallexical rule.
This rule assigns a certain type of sub-categorization frame to verbs like inscheppen wherea postposition can be interpreted as a separable par-ticle.
That subcategorization frame requires a nounphrase (?the soup?
in (5-c)) and a locative NP (?thebowl?
in (5-c)).However, in some cases, the entries generated bythis lexical rule cannot account for other possible us-ages of the verbs in question.
For example,(6) Uyoumoetmustdezethiszelfyourselfinscheppen.spoon in.INF?You have to spoon this in yourself.
?Alpino fails to parse this sentence because inschep-pen is used without a locative NP.
Now, when theLA method has predicted a transitive verb type forinscheppen, the parser should be able to cover thesentence.
Other such examples from our data in-clude wegwist (to erase.3PER.SG), onderligt (to lieunder.3PER.SG), etc.Further, there are 10 words, including afwater,which represent cases of nominalisation currentlynot accounted for in the Alpino lexicon.
TheLA process correctly predicts noun types for thesewords.
This should enable the parser to cover sen-tences like:(7) Diethismoetmusteenadeelpartvanfromhettheafwaterdrainagevervoeren.transport/move?This has to move a part of the drainage.
?where afwater is used as a noun.There are also 3 words which correctly receiveadjective predictions.
Currently, their lexical en-tries are incomplete because they are assigned onlypast participle types in the lexicon.
However, pastparticiples in Dutch can also act as adjectives.
Forhistorical reasons, this systematic ambiguity is nottreated as such in Alpino.
Each participle shouldalso have a separate adjective lexical entry but, aswe see, this is not always the case.5 ResultsAfter LA is finished, we restore the original lexicalentries for the 36 words but, additionally, each wordis also assigned the types which have been predictedfor it by the LA method.
The 388 problematic sen-tences from the Mediargus corpus are then re-parsedwith Alpino.
We are interested in observing:1. how many sentences receive a full-span analy-sis2.
how the parsing accuracy of Alpino changesTable 3 shows that when the Alpino lexicon is ex-tended with the lexical entries we learnt through LA,the parser is able to cover nearly 84% of the sen-tences, including the ones given in (6) and (7).
Sincethere is no suitable baseline which this result canbe compared to, we developed an additional modelwhich indicates what is likely to be the maximumcoverage that Alpino can achieve for those sentencesby adding new lexical entries only.907In this second model, for each of the 36 words, weadd to the lexicon all types which were successfullyused for the respective word during the parsing withuniversal types.
In this way, Alpino is free to choosefrom all types it has considered suitable for a givenword, i.e.
the parser is not limited by the outcomeof the LA process but rather by the overall quality ofthe grammar.The ?universal types?
model performs better thanours?
it achieves 87.9% coverage.
Still, the perfor-mance of our model is close to this result, i.e.
closeto what we consider to be the maximal possible cov-erage of Alpino for these 388 sentences when onlyLA is used.Model Coverage (%)Our model (Alpino + LA) 83.76Universal types 87.89Table 3: Coverage results for the re-parsed 388 problem-atic sentencesSome of the sentences which cannot be coveredby both models are actually not proper sentencesbut fragments which were wrongly identified as sen-tences during tokenization.
Many other cases in-clude sentences like:(8) Eenageleyellowfrommelcreasepapier,paperArabischeArabiclettertekens.characters?A yellow paper crease, Arabic characters.
?which is probably the caption of a photo or an illus-tration.
However, because of the absence of a verb,Alpino splits the analysis into two parts?
the part be-fore the comma and the part after the comma.Here is a more interesting case:(9) Alswhenweweonsusnaartodethebuffettafelbuffetbegeven,proceedmistrapmisstepikIme.myself?When we proceed to the buffet I misstep.
?The LA method does not predict a reflexive verbtype for mistrap which prevents the production ofa full-span analysis because Alpino cannot connectthe reflexive pronoun me to mistrap.
In this case,however, the universal type model outperforms ours.A reflexive verb type is among the universal typesand thus, Alpino is able to use that type to deliver afull-span parse.
We should note though, that LA cor-rectly predicts a noun type for mistrap which enablesAlpino to parse successfully the other 14 sentenceswhich this word occurs in.Let us now look at the correctness of the deliv-ered parses.
To estimate the accuracy of the parser,we have randomly selected 100 sentences out of the388 sentences in the test set and we have manuallyannotated them in order to create a gold standard forevaluation.Accuracy in Alpino is measured in terms of de-pendency relations.
The accuracy for sentenceswhich are not assigned a full-span analysis but a se-quence of non-overlapping parses can still be largerthan zero because, within these parses, some cor-rect dependency relations could have been produced.That is why, though the coverage of Alpino for theselected 100 sentences is zero, we can still obtaina number for accuracy and use it as a baseline forcomparison.
Clearly, this baseline is expected to per-form worse than both our model and the universaltypes one since those are able to cover most of thesentences and thus, they are likely to produce morecorrect dependency relations.
However, it gives usan idea how much extra quality is gained when cov-erage improves.The accuracy results for the 100 annotated sen-tences are given in Table 4.
The average sentencelength is 18.9 tokens.Model Accuracy (%) msec/sentenceAlpino 63.35 803Our model 86.15 718Universal types 85.12 721Table 4: Accuracy results for the 100 annotated sentencesOur model achieves the highest accuracy withoutincreasing the parse times.
Further, the baseline hasa much lower result which shows that coverage isnot gained on the expense of accuracy.Our model and the universal types one achieve thesame accuracy for most of the sentences.
However,the universal types model has an important disad-vantage which, in some cases, leads to the produc-tion of wrong dependency relations.
The model pre-dicts a large number of lexical types which, in turn,leads to large lexical ambiguity.
This lexical am-biguity increases the number of possible analysesAlpino chooses from, thus making it harder for the908parser to produce the correct analysis.
Let us con-sider the following example where a sentence is cov-ered by both models but the universal types modelhas lower accuracy:(10) Datthatwijwehetitrechttrokken,straighten.PAST.PL.pleitpleadvoorforonzeourhuidigecurrentconditie.condition?It pleads for our condition that we straightened it.
?Here, het is the object of the verb rechttrokken.However, although there are transitive verb typesamong the universal types assigned to rechttrokken,Alpino chooses to use a verb type which subcate-gorizes for a measure NP.
This causes for het to beanalysed not as an object but as a measure comple-ment, i.e.
the produced dependency relation is incor-rect.The LA method, on the other hand, is much morerestrictive but its predictions are also much more ac-curate.
Since it considers sentences containing otherforms of the paradigm of rechttrokken when predict-ing subcategorization frames, the LA method cor-rectly assigns only one transitive and one intransitiveverb type to this word.
This allows Alpino to recog-nize het as the object of the verb and to produce thecorrect dependency relation.The few cases where the universal types modeloutperforms ours include sentences like the onegiven in (9) where the application of our modelcould not enable Alpino to assign a full-span analy-sis.
Sometimes, the LA method is too restrictive anddoes not output some of the correct types.
Thesetypes, on the other hand, could be provided by theuniversal types model and could enable Alpino tocover a given sentence and thus, to produce morecorrect dependency relations.
Allowing for the LAmethod to predict more types, however, has provento be a bad solution because, due to the increasedlexical ambiguity, this leads to lower parsing accu-racy.6 Discussion6.1 Comparison to Previous WorkThe performance of the technique we presented inthis paper can be compared to the performance of anumber of other approaches applied to similar tasks.Zhang et al (2006) and Villavicencio et al (2007)use error mining to semi-automatically detect En-glish multiword expressions (MWEs).
Then, theyemploy LA to learn proper lexical entries for theseMWEs and add them to the lexicon of a large-scaleHPSG grammar of English (ERG; (Copestake andFlickinger, 2000)).
This increases parsing coverageby 15% to 22.7% for a test set of 674 sentencescontaining MWEs and parsed with the PET parser(Callmeier, 2000).
In both studies, however, thecombination of error mining and LA is applied toa very specific task whereas our method is a generalone.Nicolas et al (2008) employ a semi-automaticmethod to improve a large-scale morphosyntacticlexicon of French (Lefff ; (Sagot et al, 2006)).The lexicon is used in two grammars?
the FRMG(Thomasset and de la Clergerie, 2005), a hybrid TreeAdjoining/Tree Insertion Grammar, and the SxLFG-FR LFG grammar (Boullier and Sagot, 2006).
Thefirst step in this approach is also the application of anerror miner (Sagot and de la Clergerie, 2006) whichuses a parsed newspaper corpus (about 4.3M words)to pinpoint problematic unigrams.The crucial difference with our method is in thesecond step.
Nicolas et al (2008) assign underspec-ified lexical entries to a given problematic unigramto allow the grammar to parse the uncovered sen-tences associated with this unigram.
Then, these en-tries are ranked based on the number of successfulparses they have been used in.The use of underspecification, however, causeslarge ambiguity and severe parse overgeneration(observed also in Fouvry (2003)).
As a consequenceof that, the ranked list of lexical entries for each un-igram is manually validated to filter out the wrongentries.
The employment of LA in our approach, onthe other hand, makes it fully automatic.
The rank-ing of the predictions is done by the classifier andthe predicted entries are good enough to improve theparsing coverage and accuracy without any manualwork involved.
Generally, recent studies (Baldwin,2005; Zhang and Kordoni, 2006; Cholakov et al,2008; Cholakov and van Noord, 2010) have clearlyshown that when it comes to learning new lexicalentries, elaborate LA techniques perform better andare more suitable for large-scale grammars than un-909derspecification2.Further, the naive ranking system used in Nicolaset al (2008) puts a correctly generated entry for aninfrequent usage of a given word (e.g., a verb witha rare subcat frame) in the bottom of the ranked listbecause of the low number of sentences in whichthis entry is used.
The LA method we employ ismore sensitive to rare usages of words because itconsiders occurrences of the word in question out-side the parsed corpus (very important if the corpusis domain-specific) and it also takes into account allforms in the paradigm(s) of the word.
This increasesthe chances of a rare usage of this word to ?manifest?itself.Nicolas et al (2008) uses the lexical entries whichremain after the manual validation to re-parse thenewspaper corpus.
254 words (mostly verbs) arecorrected and the parse coverage increases by 3.4%and 1.7% for the FRMG and the SxLFG, respec-tively.
However, the authors do not mention howmany of the original uncovered sentences they areable to cover and therefore, we cannot compare ourcoverage result.
Nothing is said about the parsingaccuracy.
Even with manually validated lexical en-tries, it is still possible for the grammar to producefull-span but wrong analyses.6.2 Application to Other Systems andLanguagesIt is important to note that this paper should beviewed as a case study where we illustrate the re-sults of the application of what we believe to be agood algorithm for dealing with incomplete or in-correct lexical entries?
namely, the combination oferror mining and LA.
However, our method is gen-eral enough to be applied to other large-scale gram-mars and languages.The error mining is directly usable as soon asthere is a large parsed corpus available.
The LAtechnique we employed is also quite general pro-vided that certain requirements are fulfilled.
First,words have to be mapped onto some finite set of la-bels of which a subset of open-class (universal) la-bels has to be selected.
This subset represents thelabels which can be predicted for unknown words.2In Nicolas et al (2008) the authors also admit that an elab-orate LA technique will produce better results.Second, we need a parser to analyse sentencesin which a given unknown word occurs.
Finally,the ME-based classifier allows for arbitrary com-binations of features and therefore, any (language-specific) features considered useful can be included.As for the paradigm generation method, the idea ofcombining a finite state morphology and web heuris-tics is general enough to be implemented for differ-ent languages.We have already started investigating the applica-bility of our method to the FRMG and a large-scalegrammar of German and the initial experiment andresults we have obtained are promising.6.3 Future ResearchCurrently, our algorithm handles only unigrams(words).
However, it would be useful to extend it,so it can work with longer n-grams.
For example,a given word could have some reading which is notyet handled in the lexicon only within a particularbi- or trigram.Consider the bigram ?schampte af ?
which hasbeen identified as problematic by the error miner.It represents the particle verb ?afschampte?
(toglance.PAST.SG).
Although the lexicon contains averb entry for ?schampte?, there is no entry handlingthe case when this verb combines with the particle?af ?.
Another example is the bigram ?de slachtoffer?
(the victim).
In standard Dutch, the noun ?slachtof-fer?
goes with the ?het?
definite article which ismarked in its lexical entry.
However, in Flemish it isused with the ?de?
article.Our method is currently not able to capture thesetwo cases since they can be identified as problem-atic on bigram level and not when only unigrams areconsidered.Further, the definition of what the error minerconsiders to be a successful parse is a rather crudeone.
As we saw, even if the grammar is able to pro-duce a full-span analysis for a given sentence, thisanalysis could still not be the correct one.
There-fore, it is possible that a word could have a prob-lematic lexical entry even if it only occurs in sen-tences which are assigned a full-span parse.
Cur-rently, such a word will not be identified as prob-lematic by the error miner.
That is why, some (sta-tistical) model which is capable of judging the plau-sibility of a parse should be developed and incorpo-910rated in the calculation of the suspicions during errormining.ReferencesTim Baldwin.
2005.
Bootstrapping deep lexical re-sources: Resources for courses.
In Proceedings of theACL-SIGLEX 2005 Workshop on Deep Lexical Acqui-sition, Ann Arbor, USA.Pierre Boullier and Beno?
?t Sagot.
2006.
Efficient parsingof large corpora with a deep LFG parser.
In Proceed-ings of LREC?06, Genoa, Italy.Ulrich Callmeier.
2000.
PET?
a platform for experimen-tation with efficient HPSG processing techniques.
InJournal of Natural Language Engineering, volume 6,pages 99?107.
Cambridge University Press.Kostadin Cholakov and Gertjan van Noord.
2009.
Com-bining finite state and corpus-based techniques forunknown word prediction.
In Proceedings of the7th Recent Advances in Natural Language Processing(RANLP) conference, Borovets, Bulgaria.Kostadin Cholakov and Gertjan van Noord.
2010.
Ac-quisition of unknown word paradigms for large-scalegrammars.
In Proceedings of the 23rd InternationalConference on Computational Linguistics (COLING-2010), Beijing, China.Kostadin Cholakov, Valia Kordoni, and Yi Zhang.
2008.Towards domain-independent deep linguistic process-ing: Ensuring portability and re-usability of lexicalisedgrammars.
In Proceedings of COLING 2008 Work-shop on Grammar Engineering Across Frameworks(GEAF08), Manchester, UK.Ann Copestake and Dan Flickinger.
2000.
An open-source grammar development environment and broad-coverage English grammar using HPSG.
In Pro-ceedings of the 2nd International Conference on Lan-guage Resource and Evaluation (LREC 2000), Athens,Greece.Danie?l de Kok, Jianqiang Ma, and Gertjan van Noord.2009.
A generalized method for iterative error miningin parsing results.
In Proceedigns of the 2009 Work-shop on Grammar Engineering Across Frameworks,ACL-IJCNLP 2009, pages 71?79, Singapore.Frederik Fouvry.
2003.
Lexicon acquisition with a large-coverage unification-based grammar.
In Companionto the 10th Conference of EACL, pages 87?90, Bu-dapest, Hungary.Anna Korhonen, Genevieve Gorell, and Diana McCarthy.2000.
Statistical filtering and subcategorization frameacquisition.
In Proceedings of the Joint SIGDAT Con-ference on Empirical Methods in Natural LanguageProcessing and Very Large Corpora, Hong Kong,China.Mirella Lapata.
1999.
Acquiring lexical generalizationsfrom corpora.
A case study for diathesis alternations.In Proceedings of the 37th Annual Meeting of ACL,Maryland, USA.Robert Malouf.
2002.
A comparison of algorithms formaximum entropy parameter estimation.
In Proceed-ings of the 6th conference on Natural Language Learn-ing (CoNLL-2002), pages 49?55, Taipei, Taiwan.Cedric Messiant.
2008.
A subcategorization acquisitionsystem for French verbs.
In Proceedings of the ACL2008 Student Research Workshop, Columbus, OH.Lionel Nicolas, Beno?
?t Sagot, Miguel Molinero, JacquesFarre?, and Eric de la Clergerie.
2008.
Computer aidedcorrection and extension of a syntactic wide-coveragelexicon.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (COLING-2008), pages 633?640, Manchester, UK.Robbert Prins and Gertjan van Noord.
2001.
Unsu-pervised POS-tagging improves parcing accuracy andparsing efficiency.
In Proceedings of IWPT, Beijing,China.Beno?
?t Sagot and Eric de la Clergerie.
2006.
Error min-ing in parsing results.
In Proceedings of the 44th Meet-ing of the Association for Computational Linguistics(ACL?06), pages 329?336, Morristown, NJ, USA.Beno?
?t Sagot, Lionel Cle?ment, Eric de la Clergerie, andPierre Boullier.
2006.
The Lefff 2 syntactic lexiconfor French.
In Proceedings of LREC?06, Genoa, Italy.Franc?ois Thomasset and Eric de la Clergerie.
2005.Comment obtenir plus des me?etagrammaires.
In Pro-ceedings of TALN?05, Dourdan, France.Gertjan van Noord.
2004.
Error mining for wide-coverage grammar engineering.
In Proceedings of the42nd Meeting of the Association for ComputationalLinguistics (ACL?04), pages 446?453, Barcelona,Spain.Gertjan van Noord.
2006.
At last parsing is now opera-tional.
In Proceedings of TALN, Leuven, Belgium.Aline Villavicencio, Valia Kordoni, Yi Zhang, MarcoIdiart, and Carlos Ramisch.
2007.
Validation andevaluation of automatically acquired multiword ex-pressions for grammar engineering.
In Proceedingsof the 2007 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, pages 1034?1043,Prague, Czech Republic.Yi Zhang and Valia Kordoni.
2006.
Automated deeplexical acquisition for robust open text processing.
InProceedings of the Fifth International Conference onLanguage Resourses and Evaluation (LREC 2006),Genoa, Italy.Yi Zhang, Valia Kordoni, Aline Villavicencio, and MarcoIdiart.
2006.
Automated multiword expression pre-diction for grammar engineering.
In Proceedings of911the ACL Workshop on Multiword Expressions: Identi-fying and Exploiting Underlying Properties, pages 36?44, Sydney, Australia.912
