Proceedings of NAACL-HLT 2013, pages 117?126,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsCombining multiple information types in Bayesian word segmentationGabriel Doyle and Roger LevyDepartment of LinguisticsUniversity of California, San DiegoLa Jolla, CA 92093, USA{gdoyle,rlevy}@ucsd.eduAbstractHumans identify word boundaries in continu-ous speech by combining multiple cues; exist-ing state-of-the-art models, though, look at asingle cue.
We extend the generative model ofGoldwater et al2006) to segment using sylla-ble stress as well as phonemic form.
Our newmodel treats identification of word boundariesand prevalent stress patterns in the language asa joint inference task.
We show that this modelimproves segmentation accuracy over purelysegmental input representations, and recov-ers the dominant stress pattern of the data.Additionally, our model retains high perfor-mance even without single-word utterances.We also demonstrate a discrepancy in the per-formance of our model and human infants onan artificial-language task in which stress cuesand transition-probability information are pit-ted against one another.
We argue that this dis-crepancy indicates a bound on rationality inthe mechanisms of human segmentation.1 IntroductionFor an adult speaker of a language, word segmen-tation from fluid speech may seem so easy thatit barely needed to be learned.
However, pausesin speech and word boundaries are not well cor-related (Cole & Jakimik, 1980), word boundariesare marked by a conspiracy of partially-informativecues (Johnson & Jusczyk, 2001), and different lan-guages mark their boundaries differently (Cutler &Carter, 1987).
This makes the problem of unsuper-vised word segmentation acquisition, whether by acomputational model or an infant, a daunting task.Effective segmentation relies on the flexible in-tegration of multiple types of segmentation cues,among them statistical regularities in phonemes andprosody, coarticulation, and allophonic variation.
In-fants begin using multiple segmentation cues withintheir first year of life (Johnson & Jusczyk, 2001).Despite this, many state-of-the-art models look atonly one type of information: phonemes.In this study, we expand an existing model toincorporate multiple cues, leading to an improve-ment in segmentation performance and opening newways of investigating human segmentation acquisi-tion.
On the latter point, we show that rational learn-ers can learn to segment without encountering wordsin isolation, and that human learners deviate from ra-tionality in certain segmentation tasks.2 Previous workThe prevailing unsupervised word segmentation sys-tems (e.g., Brent, 1999; Goldwater, Griffiths, &Johnson, 2006; Blanchard & Heinz, 2008) use onlyphonemic information to segment speech.
However,human segmenters use additional information types,notably stress information, in their segmentation.We present an overview of these phonemic mod-els here before discussing the prosodic model ex-pansion.
A more complete review is available inGoldwater (2007).2.1 Goldwater et al2006)The Goldwater et alodel is related to Brent(1999)?s model, both of which use strictly phone-mic information to segment.
The model assumes thatthe corpus is generated by a Dirichlet process over117word bigrams.1 We present a basic overview here,based on Sect.
5.5 of Goldwater, 2007.
To generatethe word wi given the preceding word wi?1:1.
Decide if bigram bi = ?wi?1, wi?
is novel2.
If bi non-novel, draw bi from bigram lexicon3.
If bi novel, decide whether wi is novela.
If wi non-novel, draw wi from word lexiconb.
If wi novel, draw wi from word-generatingdistribution P0.The Dirichlet process first decides whether todraw a non-novel (?nn?)
bigram, with probabilityproportional to the number of times the previousword has appeared in the corpus:p(?wi?1, wi?
nn|wi?1) =n?wi?1,??n?wi?1,??
+ ?1, (1)where n?x,y?
is the token count for bigram ?x, y?.If the bigram is non-novel, word wi is drawn inproportion to the number of times it has appearedafter wi?1 in the corpus:p(wi = x|?wi?1, wi?
nn) =n?wi?1,x?n?wi?1,??
(2)If the bigram is novel, this could either be due towi being a novel word or due to wi being an existingword that had not appeared with wi?1 before.
Theprobability of wi being a non-novel word x isp(wi = x,wi nn|?wi?1, wi?novel) =b??,wi?(b??,??
+ ?0),(3)where b?.,.?
is the count of word bigram types.Finally, if wi is a new word, its phonemic form isgenerated from a distribution P0.
In the Goldwateret alodel, this distribution is simply the product ofthe unigram probabilities of the phonemes, P (?j),times the probability of a word boundary, p#, to endthe word:p(wi = ?1 ?
?
?
?M |winovel) = p#(1?
p#)M?1?P (?j)(4)1We will only discuss the bigram model here because it ismore appropriate from both a cognitive perspective (it posits la-tent hierarchical structure) and engineering perspective (it seg-ments more accurately) than the unigram model.To segment an observed corpus, the model Gibbssamples over the possible word boundaries (utter-ance boundaries are assumed to be word bound-aries).2 The exchangability of draws from a Dirichletprocess allows for Gibbs sampling of each possibleboundary given all the others.2.2 A cognitively-plausible variantPhillips and Pearl (2012) make these Bayesian seg-mentation models more cognitively plausible in twoways.
The first is to move from phonemes to syl-lables as the base representational unit from whichwords are constructed, as infants learn to categorizesyllables before phonemes (Eimas, 1999).
The sec-ond is to add memory and processing constraints onthe learner.
They find that syllable-based segmen-tation is better than phoneme-based segmentationin the bigram model (though worse in the unigrammodel), and that, counter-intuitively, the constrainedlearner outperforms the unconstrained learner.
Thisimprovement appears to be driven by better perfor-mance in segmenting more common words.
In thiswork, we adopt the syllabified representation but re-tain the unconstrained rational learner assumption.2.3 Other multiple-cue modelsSome previous models have incorporated multiplecues, specifically the phonemic and stress infor-mation that our model will use.
Two prominentexamples are Christiansen, Allen, and Seidenberg(1998)?s connectionist model and Gambell and Yang(2006)?s algebraic model.
The connectionist modelplaces word boundaries where the combination ofphonemic and stress information predict likely ut-terance boundaries, but does not include an explicitsense of ?word?, and performs only modestly onthe segmentation task (boundary F-scores of .40-.45).
The algebraic model also underperforms theBayesian model (Phillips & Pearl, 2012) unless itincludes the heuristic that there is a word bound-ary between any two stressed syllables.
Our modelpresents a more general and completely unsuper-vised approach to segmentation with multiple cue-types.2The model assumes that utterance boundaries are generatedjust like other words, and includes an adjustable parameter p$to account for their frequency.118In general, joint inference is becoming more com-mon in language acquisition problems and has beenshown to improve performance over single-featureinference.
Examples include joint inference of alexicon and phonetic categories (Feldman, Grif-fiths, & Morgan, 2009), joint inference of syntacticword order and word reference (Maurits, Perfors, &Navarro, 2009), and joint inference of word mean-ings and speaker intentions in child-directed speech(Frank, Goodman, & Tenenbaum, 2009).3 Model designOur model changes P0 from a single-cue distribu-tion, generating only phonemes, to a multiple-cuedistribution that generates a stress form as well.
Thiscan improve segmentation performance and allowsthe investigation of rational segmentation behaviorin a multiple-cue world.In the original model, P0(wi = ?1 ?
?
?
?M ) ?
?j P (?j), where P (?j) is the frequency of thephoneme ?j .
In the multiple-cue model, we firstgenerate a phonemic form wi, then assign a stresspattern si to it.P0(wi, si) = PW (wi)PS(si|M)= p#(1?
p#)M?1M?jP (?j)PS(si|M) (5)The phonemic form wi has the same product-of-segments probability as the Goldwater et alodel,but ?j are now syllables instead of phonemes.
Wediscuss the rationale behind this change in the nextsection.The phonemic form is generated first, and thestress form is then drawn as a multinomial over allpossible stress patterns with the same number of syl-lables as wi.
The stress distribution PS is a multino-mial distribution over word-length stress templates.PS can be learned by the model based on a Dirich-let prior, but for simplicity in the present implemen-tation, we estimate PS as the plus-one-smoothedfrequency of the stress patterns in the current seg-mentation.
There are two stress levels (stressed orunstressed), and 2M possible stress templates for aword of length M .33We do not assume that each word has one and only oneUnlike phonemic forms, stress patterns are drawnas a whole word.
This allows the model to capturea wide range of stress biases, although it preventsthe model from generalizing biases across differentword lengths.
A potential future change to PS thatwould allow for better generalization is discussed inSection 6.3.1 On syllabification and stressWe change from segmenting on phonemes to seg-menting on syllables in order to more easily imple-ment stress information, which is a supersegmentalfeature most appropriately located on syllables.
Syl-labified data has been used in some previous mod-els of segmentation, especially those using stressinformation or syllable-level transition probabilities(Christiansen et al 1998; Swingley, 2005; Gambell& Yang, 2006; Phillips & Pearl, 2012).For studying human word segmentation, Phillipsand Pearl argue syllabified speech may be amore cognitively plausible testing ground.
3-month-old infants appear to have categorical representa-tions of syllables (Eimas, 1999), three months be-fore word segmentation appears (Borfeld, Morgan,Golinkoff, & Rathbun, 2005), and seven monthsbefore phoneme categorization (Werker & Tees,1984).
In addition, syllabification is assumed inmuch work on human word segmentation, especiallyin artificial-language studies (e.g., Thiessen & Saf-fran, 2003), which calculate statistical cues at thesyllable level.The assumption that syllable boundaries areknown affects the baseline performance of themodel, as it reduces the number of possible wordboundary locations (since a word boundary is nec-essarily a syllable boundary).
As such performanceover syllabified data cannot be directly compared toperformance on non-syllabified data.It may seem that syllabification is so closely tiedto word segmentation that including the former in amodel of the latter leaves little to the model.
How-ever, the determinants of syllable boundaries are notthe same as those for word boundaries.
The prob-stressed syllable, which would reduce the number of possiblestress templates to M , for two reasons.
First, in the current cor-pus, some words have citation forms with multiple stressed syl-lables.
Second, in actual speech this assumption will not hold(e.g., many function words go unstressed).119lem of assigning syllable boundaries is a question ofdeciding where a boundary goes between two syl-lable nuclei, with the assumption that there must bea boundary there.
The problem of assigning wordboundaries is a question of deciding whether thereis a boundary between two syllable nuclei, and if so,where it is.
Knowing the syllable boundaries reducesthe set of possible word boundaries, but does not di-rectly address the question of how likely a boundaryis.
The difference in these tasks is supported by thethree-month gap between syllable and word identifi-cation in infants.4 DataWe use the Korman (1984) training corpus, as com-piled by Christiansen et al(1998), in this study.
Thisis a 24493-word corpus of English spoken by adultsto infants aged 6?16 weeks.4 Phonemes, stresses,and syllable boundaries are the same as those usedby Christiansen et alwhich were based on citationforms in the MRC Psycholinguistic Database.
Allmonosyllabic words were coded as stressed.
Onlyutterances for which all words had citation formswere included.This corpus is largely monosyllabic (87.3% of allword tokens), and heavily biased toward initial stress(89.2% of all multisyllable word tokens).
No wordis longer than three syllables, and most words haveonly one stressed syllable.
A breakdown of the cor-pus by stress pattern is given in Table 1.
This mono-syllabic bias is an inherent property of English, notidiosyncratic to this corpus.
The Bernstein-Ratnerchild-directed corpus is also over 80% monosyl-labic.
We expect that the results of segmentation onchild-directed data will extend to adult speech, asthe adult-directed corpus used by Gambell and Yang(2006) has an average word length of 1.17 syllables.5 ExperimentsWe test the model on three problems.
First, we showthat the addition of stress information improves seg-mentation performance compared to a stress-lessmodel.
Next, we apply the model to a question inhuman segmentation acquisition.
Finally, we look at4Approximately 150 word tokens from the original corpuswere omitted in our version of the corpus due to a disparitybetween recorded number of syllables and number of stresses.Types TokensStress pattern Count Stress pattern CountS 21402 S 523SW 2231 SW 208SS 389 WS 40WS 284 SWW 24SWW 182 SS 7WSW 33 WSW 7Other 5 Other 2Table 1: Corpus stress patterns by types and tokens,showing an initial-stress bias in all lengths.a task where the rational model deviates from humanperformance.5.1 Parameter settingThe model has four free parameters: ?0 and ?1,which affect the likelihood of new words and bi-grams, respectively, and p# and p$, which affect theexpected likelihood of word and utterance bound-aries.
Following Goldwater, Griffiths, and Johnson(2009), we set ?0 = 20, ?1 = 100, p# = 0.8 andp$ = 0.5 in all experiments.5In all cases, the model performed five indepen-dent runs of 20000 iterations of Gibbs sampling theboundaries for the full corpus.
Simulated annealingwas performed during the burn-in period to improveconvergence.
All performance measures are reportedas the mean of these five runs.Performance is measured as word, boundary, andlexicon precision, recall, and F-scores.
A word ismatched iff both of its true boundaries are markedas boundaries and no internal boundaries are markedas word boundaries.
Boundary counts omit utteranceboundaries, which are assumed to be word bound-aries.
Lexical counts are based on word type counts.5.2 Stress improves performanceWe begin by showing that including a secondcue type improves segmentation performance.
Wecompare segmentation on a corpus with the at-tested stress patterns to that of a corpus with-out stress.
With stress information included inthe model, word/boundary/lexicon F-scores are5Performance was similar for a range of settings between 1and 100 for ?0 and between 10 and 200 for ?1.120With stress Without stressWord Bnd Lex Word Bnd LexPrec .76 .99 .75 .76 .99 .72Rec .61 .70 .87 .60 .69 .84F .68 .82 .80 .67 .82 .77Table 2: Precision, recall, and F-score over corpora withand without stress information available.
Stress informa-tion especially improves lexical performance..68/.82/.80.
Without stress, performance drops to.67/.82/.77.6 Full results are given in Table 2.Stress information primarily improves lexiconperformance, along with a small improvement intoken segmentation.
Accounting for stress reducesboth false positives and negatives in the lexicon; thefact that the lexical improvement is greater than thatfor words or boundaries suggests that much of theimprovement rests is on rare words.These effects are small but significant.
For wordtoken performance, we performed a paired t-teston utterance token F-scores between the with- andwithout-stress models.
This difference was signif-icant (t = 11.28, df = 8125, p < .001).
Weperformed a similar utterance-by-utterance test onboundaries; again a small singificant improvementwas found (t = 8.92, df = 6084, p < .001).
Toassess lexicon performance, we calculated for eachword type in the gold-standard lexicon the propor-tion of the five trials in which that word appearedin the learned lexicon for the two models.
We thenexamined the words where the proportions differedbetween the models.
89 true words appeared moreoften in the with-stress lexicons; 40 appeared moreoften in the without-stress lexicons.
(683 appearedequally often in both.)
By a sign test, this is signif-icant at p < .001.
We also tested lexicon perfor-mance with a binomial test on the two models?
lexi-con accuracy; this result was marginal (p = .06).The explicit tracking of stress information alsoimproves the model?s acquisition of the stress bias ofthe language.
Acquisition of the stress bias is poten-tially useful for generalization; stress patterns can beused for an initial segmentation if few or none of thewords are familiar.
In practice, we see children use6Recall that due to the syllabified data, these results are notdirectly comparable to unsyllabified results in previous work.their stress biases to segment new words from En-glish speech (Jusczyk, Houston, & Newsome, 1999)as well as artificial languages (Thiessen & Saffran,2003).We assess the learned stress bias by dividing upthe corpus as the model has segmented it, and countthe number of tokens with SW versus WS stress pat-terns.7 With stress representation, the learned stressbias is 6.77:1, and without stress representation, thestress bias is lower, at 6.33:1.
Although these areboth underestimates of the corpus?s true stress bias(7.86:1), the stressed model is stronger and a betterestimate of the true value.The model?s performance can be compared tovarious baselines, but perhaps the strongest is onewith every syllable boundary being a word bound-ary.
This baseline represents a shift from boundaryprecision being at ceiling (as in the model) to bound-ary recall being at ceiling.
In fact, due to the pre-ponderance of monosyllabic words in English child-directed speech, this baseline outperforms the modelon word and boundary F-scores (.68 and .82 in themodel, .82 and .91 in the baseline).
However, thebaseline?s lexicon is much worse than the model?s(F=.80 in the with-stress model, F=.64 in the base-line), and the baseline fails to learn anything aboutthe language?s stress biases.
In addition, the base-line oversegments, whereas both the model and in-fant segmenters undersegment (Peters, 1983).
Thisraises an important question about what the modelshould seek to optimize: though the baseline is moreaccurate by token, no structure is learned; type per-formance is more important if we want to learn theunderlying structure.5.3 Are isolated words necessary?We next use this model to test the necessity of iso-lated words in rational word segmentation.
It is notimmediately obvious how human learners begin tosegment words from fluid speech.
Stress biases andother phonological cues are dominant in all but theearliest of infant word segmentation (Johnson &Jusczyk, 2001).
This raises a chicken-and-egg prob-lem; if the cues infants favor to segment words, suchas stress biases, are dependent on the words of the7Note this defines a stress bias for the stressless model aswell.121language, how do they learn enough words to deter-mine the cues?
biases?One existing proposal is that human learners de-velop their stress biases based on words frequentlyheard in isolation (Jusczyk et al 1999).
In En-glish, these include names and common diminutives(e.g., mommy, kitty) that generally have initial stress.These single-word utterances could offer the seg-menter an initial guess of the stress bias, by suppos-ing that short utterances are single words and record-ing their stress patterns.
The most common stresspatterns in short utterances could then be used asan initial guess at the stress bias to bootstrap otherwords and thereby improve the learned stress bias.We test the rational learner?s need for such ex-plicit bootstrapping by learning to segment a corpuswith all single-word utterances removed.
The corpusis produced by excising all single-word utterancesfrom the Korman corpus.
This results in a 22081-word corpus, 10% fewer tokens than in the original.However, it does not substantially change the lexi-con; the number of distinct word types only dropsfrom 811 to 806.We compare performance only on ambiguousboundaries and lexicon, as these are comparablebetween the corpora, and find that the model per-forms almost equally well.
Without single-word ut-terances, boundary and lexical F-scores are .81 and.80, compared to .82 and .80 with single-word utter-ances.
This shows that rational learners are able tosegment even without the possibility of bootstrap-ping stress patterns from single-word utterances.5.4 Bounded rationality in humansegmentationLastly, we use this model to examine rational per-formance in a multiple-cue segmentation task.
Weshow that humans?
segmentation does not adhere tothese predictions, suggesting a bound on human ra-tionality in word segmentation.We consider an artificial language study byThiessen and Saffran (2003).
In this study, infantsare exposed to an artificial language consisting offour bisyllabic word types uttered repeatedly with-out pauses.
Each syllable appears in only one wordtype, so within-word transition probabilities are al-ways 1, while across-word transition probabilitiesare less than 0.5.
Segmentation strategies that hy-Against bias, with TPAB CD CD ABWS WS WS WSWith bias, against TPA BC DC DA BW SW SW SW STable 3: Examples of segmenting an artificial languageaccording to transition probabilities (top) or stress bias(bottom), when the true words have weak-strong stress.Vertical lines represent word boundaries.
The top seg-mentation produces a smaller lexicon, but the bottom seg-mentation produces primarily words with the preferredstress pattern.pothesize word boundaries at low transition proba-bilities or that seek to minimize the lexicon size willsegment out the four word types as expected.Segmentation in the experiment is complicated bythe presence of stress in the artificial language.
De-pending on the condition, the words are either allstrong-weak or all weak-strong.
In the first condi-tion, segmenting according to transition probabili-ties, lexicon size, or English stress bias favors thesame segmentation.
In the second condition, though,segmenting by the English stress bias to yield a lex-icon of strong-weak words requires boundaries inthe middle of the words.
The segmenter must decidewhether transition probabilities or preferred stresspatterns are more important in segmentation.
Thissituation is illustrated in Table 3, with a corpus con-sisting of two word types, AB and CD, each withweak-strong stress.Thiessen and Saffran found that seven-month-old English-learning infants consistently segmentedaccording to the transition probabilities, regardlessof stress.
However, nine-month-olds segmented ac-cording to the English stress bias, even if this meantgoing against the transition probabilities.Intuitively, this could be rational behavior accord-ing to our model.
A child?s increasing age meansmore exposure to data, potentially leading the childto develop more confidence in the stress bias.
Asconfidence in the stress bias increases, the cost ofsegmenting against it increases as well.
A suffi-ciently strong stress preference could lead the seg-menter to accept a large lexicon, all of whose wordshave the preferred stress pattern, over a small lexi-122con, all of whose words have the dispreferred stresspattern.To judge by the Korman corpus, English has astress bias of approximately 7:1 in favor of SW bi-syllabic stress over WS.8 If human segmentation be-havior follows the rational model, the model shouldpredict segmentation to favor strong-weak wordsover the transition probabilities when the stress biasis approximately this strong.We test this rationality hypothesis with a smallerversion of the Thiessen and Saffran artificial lan-guage, consisting of 48 tokens.9 In one version,all tokens have the preferred SW pattern, and inthe other all tokens have the dispreferred WS pat-tern.
We then adjust the PS distribution such thatPS(SW |M = 2) = b ?
PS(WS|M = 2), whereb is the bias ratio.
We run the model otherwise thesame as in the previous experiments, except with 10runs instead of 5.Contrary to this hypothesis, the model?s segmen-tation with b = 7 was the same whether the truewords were strong-weak or weak-strong.
In all tenruns, transition probabilities dictated the segmenta-tion.
To switch to stress-based segmentation, the biasmust be orders of magnitude greater than the Englishbias.
Figure 1 shows the proportions of runs in theweak-strong condition that show segmentation ac-cording to the stress bias, as the bias increases byfactors of 10.
When b = 10000, three of the ten runssegmented according to the stress bias; below that,the stress bias did not affect the rational model?s seg-mentation.Why is this?
In the Bayesian model, the stress biasof a language affects only the PS(si|M) term in theP0 distribution, so non-novel words are not penal-ized for their stress pattern.
The model pays onlyonce to create a word; once the word is generated,no matter how a priori implausible the word was,it may be cheaply drawn again as a non-novel word.This effect can be illustrated with a brief calculation.Consider a corpus built from four bisyllabic wordtypes (AB, CD, EF, GH), each appearingN times.
If8The specific bias varies from corpus to corpus, but this ap-pears to be a representative value.9The 48 tokens come from four word types, with two typesappearing 16 times and the other two appearing 8 times, mim-icking the relative frequencies of Thiessen and Saffran?s lan-guages.
Their test language had 270 tokens.biasPercent SWsegmention020406080100100 101 102 103 104 105 106Figure 1: Percentage of runs segmented with the stressbias, against transition probabilities, as bias varies.
AtEnglish-level biases, the rational model still overrules thestress bias when segmenting.the corpus is segmented against the transition proba-bilities, the resulting lexicon will have 16 bisyllabicword types (BA, BC, BE, BG, DA, etc.
), each occur-ring approximately N4 times.The probability of the against-bias corpus (CWS)is proportional to the probability of generating thefour word types, and then drawing them non-novellyfrom the lexicon.10 (To simplify the calculations,we use the unigram version of the Goldwater et almodel.
)p(CWS) ?
P4WPS(WS)4(N !
)414N !
(6)The first two terms are the probability of gen-erating the four word types (Eqn.
5);11 the secondtwo terms are the Dirichlet process draws fromthe existing lexicon N times each (Eqn.
2).
Bycomparison, the probability of the with-bias corpusCSW depends on generating the 16 word types, anddrawing each non-novelly N4 times.p(CSW ) ?
P16W PS(SW )16(N4!
)16 14N !
(7)Given an SW bias b and a uniform distributionover syllables (so PW = 164 ), we find:p(CWS)p(CSW )= 6412(b+ 1)12b16(N !
)4(N4 !
)16(8)10It is also possible to generate this corpus by re-drawing thewords novelly, but this is much less likely than non-novel draws.11Because all syllables have equal unigram probabilities, theprobability of all words?
phonemic forms are equal, and will bewritten as PW .123This equation shows that the rational model isheavily biased toward the segmentation that fits thetransition probabilities.
Increasing the stress bias bor decreasing the number of observed word tokensmakes the rational model more likely to segmentwith the stress bias (against transition probabilities),but as we see in the experimental results, the stressbias must be very strong to overcome the efficientlexicon that the transition probability segmentationprovides.Since humans do not show this same inherentbias (or quickly lose it as they acquire the stressbias), we can ask how humans deviate from ratio-nality.
One possibility is that humans simply do notsegment in this Bayesian manner.
However, previ-ous work (Frank, Goldwater, Griffiths, & Tenen-baum, 2010) has shown that human word segmen-tation shows similar behavior to a resource-limitedBayesian model.
Equation 8 suggests that humansegmentation could deviate from rationality by hav-ing an effectively stronger bias than English wouldsuggest (reducing the first fraction)12 or, as withPhillips and Pearl?s constrained learners, by havingeffectively less input than the model assumes (reduc-ing the second fraction).6 Future workIntroducing stress into the Bayesian segmentationmodel suggests a few additional expansions.
Onepossibility is to add other cues into the genera-tive model via P0.
Any cue that is based on theword itself can be added in this way, with littlechange to the general model structure.
Phonotacticscan be added using an n-gram distribution for P0(Blanchard & Heinz, 2008).
Coarticulation betweenadjacent phonemes is also used in human segmen-tation (Johnson & Jusczyk, 2001), so the P0 distri-bution could predict higher within-word coarticula-tion.
Integrating additional cues used by human seg-menters extends the investigation of the bounds onrationality in human segmentation and in balancingmultiple conflicting cues.12A potential source of an inflated bias is infants?
preferencefor strong-weak patterns.
Jusczyk, Cutler, and Redanz (1993)found English-hearing infants listened longer to strong-weakpatterns than weak-strong.
This could lead to overestimation ofthe stress bias by making possible strong-weak segmentationsmore prominent in the segmenter?s mind.A more complex view of the stress system of alanguage may also be useful.
One possibility is toplace a Dirichlet prior over the stress templates andallow PS to be learned as a latent variable in themodel.
Another possibility is to treat the stress tem-plates more generally; in the present implementa-tion, knowledge of the preferred stress patterns forword of one length tells the segmenter nothing aboutpreferred stress patterns in another length.
Cross-linguistically common stress rules (e.g., those thatplace stress a certain number of syllables from theleft or right edge of a word) can be coded into PS toimprove generalization.
Each rule dictates a specificstress pattern for each word length.
When a wordis generated in the Dirichlet process, the generativemodel would decide whether to assign stress accord-ing to one of these rules or to assign lexical stressfrom a default multinomial distribution.
(This ?de-fault?
distribution would handle idiosyncratic stressassignments, as one might see with names or mor-phologically complex words, like Spanish reflexiveverbs.)
A sparse prior over these rules, asymmetri-cally weighted against the default category, will en-courage the model to explain as much of the ob-served stress patterns as possible with a few domi-nant rules, improving the phonological structure thatthe segmenter learns.Improving the realism of the data is also impor-tant.
The corpora used in much of segmentation re-search are idealized representations of the true data,and the dictionary-based phoneme and stress pat-terns used in this study are no exception.
This idealsetting may paint a skewed picture of the segmen-tation problem, by providing a more consistent andlearnable data source than humans actually receive.Elsner, Goldwater, and Eisenstein (2012)?s modelunifying lexical and phonetic acquisition takes a sig-nificant step in showing that a rational segmentercan handle noisy input by recognizing phonetic vari-ants of a base form.
In terms of stress representa-tions, dictionary-based stress has been standard inprevious work (Christiansen et al 1998; Gambell &Yang, 2006; Rytting, Brew, & Fosler-Lussier, 2010),but it is important to confirm such results against a(currently nonexistent) corpus with stresses based onthe actual utterances.
Effective use of stress in a lessidealized setting may require a more complex repre-sentation of stress in the model.1247 ConclusionEffective word segmentation combines multiple fac-tors to make predictions about word boundaries.
Weextended an existing Bayesian segmentation modelto account for two factors, phonemes and stress,when segmenting.
This improves segmentation per-formance and opens up new possibilities for compar-ing rational segmentation and human segmentation.AcknowledgmentsThis research was partially supported by an Alfred P.Sloan Fellowship to RL and by NSF award 0830535.We also appreciate the feedback of the reviewersand the members of the UCSD Computational Psy-cholinguistics Lab.ReferencesBlanchard, D., & Heinz, J.
(2008).
Improvingword segmentation by simultaneously learn-ing phonotactics.
In Proceedings of CoNLL(pp.
65?72).Borfeld, H., Morgan, J., Golinkoff, R., & Rath-bun, K. (2005).
Mommy and me: familiarnames help launch babies into speech-streamsegmentation.
Psychological Science, 16(4),298?304.Brent, M. R. (1999).
An efficient, probabilisticallysound algorithm for segmentation and worddiscovery.
Machine Learning, 34, 71?105.Christiansen, M. H., Allen, J., & Seidenberg, M. S.(1998).
Learning to segment speech usingmultiple cues: A connectionist model.
Lan-guage and Cognitive Processes, 13, 221?268.Cole, R., & Jakimik, J.
(1980).
A model of speechperception.
In Perception and production offluent speech (pp.
136?163).
Hillsdale, NJ:Erlbaum.Cutler, A., & Carter, D. (1987).
The predominanceof strong initial syllables in the English vocab-ulary.
Comp.
Speech Lang., 2, 133?142.Eimas, P. (1999).
Segmental and syllabic representa-tions in the perception of speech by young in-fants.
Journal of the Acoustic Society of Amer-ica, 105, 1901?1911.Elsner, M., Goldwater, S., & Eisenstein, J.
(2012).Bootstrapping a unified model of lexical andphonetic acquisition.
In Proceedings of the50th annual meeting of the ACL.Feldman, N., Griffiths, T., & Morgan, J.
(2009).Learning phonetic categories by learning alexicon.
In Proceedings of the 31st annualconference on cognitive science.Frank, M., Goldwater, S., Griffiths, T., & Tenen-baum, J.
(2010).
Modeling human perfor-mance in statistical word segmentation.
Cog-nition.Frank, M., Goodman, N., & Tenenbaum, J.
(2009).Using speakers?
referential intentions tomodel early cross-situational word learning.Psychological Science, 20, 579?585.Gambell, T., & Yang, C. (2006).
Word segmen-tation: Quick but not dirty.
(Unpublishedmanuscript)Goldwater, S. (2007).
Nonparametric Bayesianmodels of lexical acquisition.
Unpublisheddoctoral dissertation, Brown Univ.Goldwater, S., Griffiths, T., & Johnson, M. (2006).Contextual dependencies in unsupervisedword segmentation.
In Proceedings of Col-ing/ACL.Goldwater, S., Griffiths, T. L., & Johnson, M.(2009).
A Bayesian framework for word seg-mentation: Exploring the effects of context.Cognition, 112, 21?54.Johnson, E., & Jusczyk, P. (2001).
Word segmen-tation by 8-month-olds: When speech cuescount more than statistics.
J. of Memory andLanguage, 44, 548?567.Jusczyk, P., Cutler, A., & Redanz, N. (1993).
Pref-erence for predominant stress patterns of En-glish words.
Child Development, 64, 675?687.Jusczyk, P., Houston, D., & Newsome, M. (1999).The beginnings of word segmentation inEnglish-learning infants.
Cognitive Psychol-ogy, 39, 159?207.Korman, M. (1984).
Adaptive aspects of mater-nal vocalizations in differing contexts at tenweeks.
First language, 5, 44?45.Maurits, L., Perfors, A., & Navarro, D. (2009).
Jointacquisition of word order and word reference.In Proceedings of 31st annual conference ofthe Cognitive Science Society.Peters, A.
(1983).
The units of language acqui-125sition: Monographs in applied psycholinguis-tics.
Cambridge Univ.
Press.Phillips, L., & Pearl, L. (2012).
?less is more?in Bayesian word segmentation: When cogni-tively plausible learners outperform the ideal.In Proceedings of the 34th annual conferenceof the cognitive science society.Rytting, C. A., Brew, C., & Fosler-Lussier, E.(2010).
Segmenting words from naturalspeech: subsegmental variation in segmentalcues.
Journal of Child Language, 37, 513?543.Swingley, D. (2005).
Statistical clustering and thecontents of the infant vocabulary.
CognitivePsychology, 50, 86?132.Thiessen, E. D., & Saffran, J. R. (2003).
When cuescollide: Use of stress and statistical cues toword boundaries by 7- to 9-month-old infants.Developmental Psychology, 39(4), 706?716.Werker, J., & Tees, R. (1984).
Cross-languagespeech perception: Evidence for perceptualreorganization during the first year of life.
In-fant Behavior and Development, 7, 49?63.126
