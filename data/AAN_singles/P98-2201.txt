A Connectionist  Approach to Preposit ional Phrase Attachmentfor Real World TextsJ osep  M.  Sopena and Agust i  LLoberas  and Joan  L.  Mo l inerLaboratory  of Neurocomput ingUn ivers i ty  of Barce lonaPg.
Vall d 'Hebron ,  17108035 Barce lona  (Spain)e-mai l :  {pep ,  agust  i ,  j oan)?axon, ps i .
ub.
esAbst ractIll this paper we describe a neural network-basedapproach to prepositional phrase attachment disam-biguation for real world texts.
Although the use ofsemantic lasses in this task seems intuitively to beadequate, methods employed to date have not usedthem very effectively.
Causes of their poor resultsare discussed.
Our model, which uses only classes,scores appreciably better than the other class-basedmethods which have been tested on the Wall StreetJournal corpus.
To date, the best result obtainedusing only classes was a score of 79.1%; we obtainedan accuracy score of 86.8%.
This score is among thebest reported in the literature using this corpus.1 In t roduct ionStructural ambiguity is one of the most serious prob-lems faced by Natural Language Processing (NLP)systems.
It occurs when the syntactic informationdoes not suffice to make an assignment decision.Prepositional phrase (PP) attachment is, perhaps,the canonical case of structural ambiguity.
Whatkind of information should we use in order to solvethis ambiguity?
In most cases, the informationneeded comes from a local context, and the attach-lnent decision is based essentially on the relation-ships existing between predicates and arguments,what Katz y Fodor (1963) called selectional restric-tions.
For example, in the expression: (V accommo-date) (gP Johnson's election) (PP as a director),the PP is attached to the NP.
However, in the ex-pression: (V taking) (NP that news) (PP as a signto be cautions), the PP is attached to the verb.
Inboth expressions, the attachment site is decided ontile basis of verb and noun seleetional restrictions.In other eases, the information determining the PPattachment comes from a global context.
In this pa-per we will focus on the disambiguation mechanismbased on selectional restrictions.Previous work has shown that it is extremely diffi-cult to build hand-made rule-based systems able todeal with this kind of problem.
Since such hand-made systems proved unsuccessful, in recent yearstwo main methods have appeared capable of auto-1233matic learning from tagged corpora: automatic rulebased methods and statistical methods.
In this pa-per we will show that, providing that the problem iscorrectly approached, an NN can obtain better re-sults than any of the methods used to date for PPattachment disambiguation.Statistical methods consider how a local contextcan disambiguate PP attachment estimating theprobability from a corpus:p(verb attachlv NP1 prep NP2)Since an NP can be arbitrarily complex, the prob-lem can be simplified by considering that only theheads of the respective phrases are relevant when de-ciding PP attachment.
Therefore, ambiguity is re-solved by means of a model that takes into accountonly phrasal heads: p(verb attachlverb nl prep n2).There are two distinct methods for establishing therelationships between the verb and its arguments:methods using words (lexical preferences) and meth-ods using semantic lasses (selectional restrictions).2 Us ing  WordsThe attachment probabilityp(verb attach\]verb nl prep n2)should be computed.
Due to the use of word co-occurrence, this approach comes up against the se-rious problem of data sparseness: the same 4-tuple(v nl prep n2) is hardly ever repeated across thecorpus even when the corpus is very large.
Collinsand Brooks (1995) showed how serious this problemcan be: almost 95% of the 3097 4-tuples of theirtest set do not appear in their 20801 training set 4-tuples.
In order to reduce data sparseness, Hindleand Rooth (1993) simplified the context, by consid-ering only verb-preposition (p(prep\]verb)), and nl-preposition (p(prep\]nl)) co- occurrences, n2 was ig-nored in spite of the fact that it may play an im-portant role.
In the test, attachment to verb wasdecided if p(preplverb ) > p(prep\]noun); otherwiseattachment to nl is decided.
Despite these limita-tions, 80% of PP were correctly assigned.Another method for reducing data sparseness hasbeen introduced recently by Collins and Brooks(1995).
These authors showed that the problem ofPP attachment ambiguity is analogous to n-gramlanguage models used in speech recognition, andthat one of the most common methods for languagemodelling, the backed-off estimate, is also applica-ble here.
Using this method they obtained 84.5%accuracy on WSJ data.3 Us ing  C lassesWorking with words implies generating huge param-eter spaces for which a vast amount of memory spaceis required.
NNs (probably like people) cannot dealwith such spaces.
NNs are able to approximatevery complex functions, but they cannot memorizehuge probability look-up tables.
The use of seman-tic classes has been suggested as an alternative toword co-occurrence.
If we accept the idea that allthe words included in a given class mu'st have simi-lar (attachment) behaviour, and that there are fewersemantic lasses than there are words, the problemof data sparseness and memory space can be consid-erably reduced.Some of the class-based methods have used Word-Net (Miller et al, 1993) to extract word classes.WordNet is a semantic net in which each nodestands for a set of synonyms (synset), and domi-nation stands for set inclusion (IS-A links).
Eachsynset represents an underlying concept.
Table 1shows three of the senses for the noun bank.
Ta-ble 2 shows the accuracy of the results reportedin previous work.
The worst results were obtainedwhen only classes were used.
It is reasonable toassume a major source of knowledge humans useto make attachment decisions is the semantic lassfor the words involved and consequently there mustbe a class-based method that provides better re-sults.
One possible reason for low performance usingclasses is that WordNet is not an adequate hierarchysince it is hand-crafted.
Ratnaparkhi et al (1994),instead of using hand-crafted semantic lasses, usesword classes obtained via Mutual Information Clus-tering (MIC) in a training corpus.
Table 2 showsthat, again, worse results are obtained with classes.A complementary explanation for the poor resultsusing classes would be that current methods do notuse class in fo rmat ion  very  ef fect ively for sev-eral reasons: 1.-In WordNet, a particular sense be-longs to several classes (a word belongs to a class ifit falls within the IS-A tree below that class), and sodetermining an adequate level of abstraction is diffi-cult.
2.- Most words have more than one sense.
Asa result, before deciding attachment, it is first nec-essary to determine the correct sense for each word.3.- None of the preceding methods used classes forverbs.
4.- For reasons of complexity, the complete4-tuple has not been considered simultaneously ex-cept in Ratnaparkhi et a1.(1994).
5.- Classes of a1234given sense and classes of different senses of differentwords can have complex interactions and the pre-ceding methods cannot take such interactions intoaccount.4 Encod ing  and  NetworkArch i tec ture .Semantic lasses were extracted from Wordnet 1.5.In order to encode each word we did not use Word-Net directly, but constructed a new hierarchy (a sub-set of WordNet) including only the classes that cor-responded to the words that belonged to the trainingand test sets.
We counted the number of times thedifferent semantic lasses appear in the training andtest sets.
The hierarchy was pruned taking thesestatistics into account.
Given a threshold h, classeswhich appear less than h% were not included.
Inthis way we avoided having an excessive number ofclasses in the definition of each word which may havebeen insufficiently trained due to a lack of examplesin the training set.
We call the new hierarchy ob-tained after the cut WordNei'.
Due to the largenumber of verb hierarchies, we made each verb lex-icographical file into a tree by adding a root nodecorresponding to the file name.
According to Milleret al (1993), verb synsets are divided into 15 lex-icographical files on the basis of semantic criteria.Each root node of a verb hierarchy belongs to onlyone lexicographical fi e. We made each old root nodehang from a new root node, the label of which wasthe name of its lexicographical fi e. In addition, wecodified the name of the lexicographical file of theverb itself.There are essentially two alternative proceduresfor using class information.
The first one consists ofthe simultaneous presentation of all the classes of allthe senses of all the words in the 4-tuple.
The in-put was divided into four slots representing the verb,nl, prep, and n2 respectively.
In slots nl and n2,each sense of the corresponding noun was encodedusing all the classes within the IS-A branch of theWordNet'hierarchy, from the corresponding hierar-chy root node to its bottom-most node.
In the verbslot, the verb was encoded using the IS_A_WAY_OFbranches.
There was a unit in the input for eachnode of the WordNet subset.
This unit was on ifit represented a semantic lass to which one of thesenses of the word to be encoded belonged.
As forthe output ,  there were only two units representingwhether the PP attached to the verb or not.The second procedure consists of presenting all theclasses of each sense of each word serially.
However,the parallel procedure have the advantage that thenetwork can detect which classes are related withwhich ones in the same slot and between slots.
Weobserved this advantage in preliminary studies.Feedforward networks with one hidden layer andTable 1: WordNet information for the noun 'bank'.Sense 1Sense 2Sense 3group --~ people --* organ izat ion  --* ins t i tu t ion  --~ f inanc ia l _ ins t i tu t .ent i ty  ~ object ---* a r t i fac t  ---* fac i l i ty  ---* depositoryent i ty  ---* object ---* natural_object ---* geo log ica l_ format ion  ---* slopeTable 2: Test size and accuracy results reported in previous works.
'W' denotes words only, 'C' class only and'W+C' words+classes.Author \[ W \[ C \[ W+C \[ Classes Test sizeHindle and Rooth (93) 80Resnik and Hearst(93) 81.6 79.3 83.9Resnik and Hearst (93) 75 aRatnaparkhi et al (94) 81.2 79.1 81.6Brill and Resnik (94) 80.8 81.8Collins and Brooks (95) 84.5Li and Abe (95) 85.8 ?
84.9- 88OWordNet 172WordNet 500MIC 3O97WordNet 500- 3097WordNet 172aAccuracy obtained by Brill and Resnik (94) using Resnik's method on a larger test.bThis accuracy is based on 66% coverage.a full interconnectivity between layers were used inall the experiments.
The networks were trained withbackpropagation learning algorithm.
The activationfunction was the logistic function.
The number ofhidden units ranged from 70 to 150.
This networkwas used for solving our classification problem: at-tached to noun or attached to verb.
The outputactivation of this network represented the bayesianposterior probability that the PP of the encoded sen-tence attaches to the verb or not (Richard and Lipp-mann (1991)).5 T ra in ing  and  Exper imenta lResu l t s .21418 examples of structures of the kind 'VB N1PREP N2' were extracted from the Penn-TreeBankWall Street Journal (Marcus et al 1993).
Word-Net did not cover 100% of this material.
Propernames of people were substituted by the WordNetclass someone, company names by the class busi-ness_organization, and prefixed nouns for their stem(co-chairman ---* chairman).
788 4-tuples were dis-carded because of some of their words were not inWordNet and could not be substituted.
20630 codi-fied patterns were finally obtained: 12016 (58.25%)with the PP attached to N1, and 8614 (41.75%) toVB.We used the cross-validation method as a mea-sure of a correct generalization.
After encoding,the 20630 patterns were divided into three subsets:training set (18630 patterns), set A (1000 patterns),and set B (1000 patterns).
This method evaluatedperformance (the number of attachment errors) on a1235pattern set (validation set) after each complete passthrough the training data (epoch).
Series of threeruns were performed that systematically varied therandom starting weights.
In each run the networkswere trained for 40 epochs.
In each run the weightsof the epoch having the smallest error with respectto the validation set were stored.
The weights corre-sponding to the best result obtained on the valida-tion test in the three runs were selected and used toevaluate the performance in the test set.
First, weused set A as validation set and set B as test, andafterwards we used set B as validation and set A astest.
This experiment was replicated with two newpartitions of the pattern set: two new training sets(18630 patterns) and 4 new validation/test ets of1000 patterns each.Results showed in table 3 are the average accu-racy over the six test sets (1000 patterns each) used.We performed three series of runs that varied the in-put encoding.
In all these encodings, three tree cutthresholds were used: 10~o, 6~ and 2~o.
The num-ber of semantic lasses in the input encoding rangedfrom 139 (10% cut) to 475 (2%) In the first encod-ing, the 4-tuple without extra information was used.The results for this case are shown in the 4-tuplecolumn entry of table 3.
In the second encoding,we added the prepositions the verbs select for theirinternal arguments, ince English verbs with seman-tic similarity could select different prepositions (forexample, accuse and blame).
Verbs can be classi-fied on the basis of the kind of prepositions theyselect.
Adding this classification to the WordNet  Iclasses in the input encoding improved the results(4-tuple + column entry of table 3).The 2% cut results were significantly better (p <0.02) than those of the 6% cut for 4-tuple and 4-tuple + encodings.
Also, the results for the 4-tuple +condition were significanly better (p < 0.01).For all simulations the momentum was 0.8, initialweight range 0.1.
No exhaustive parameter explo-ration was carried out, so the results can still beimproved.Some of the errors committed by the network canbe attributed to an inadequate class assignment byWordNet.
For instance, names of countries haveonly one sense, that of location.
This sense is not ap-propriate in sentences like: Italy increased its salesto Spain; locations do not sell or buy anything, andthe correct sense is social_group.
Other mistakescome from what are known as reporting and aspec-tual verbs.
For example in expressions like reportedinjuries to employees or iniliated lalks with the Sovi-ets the nl has an argumental structure, and it is theelement hat imposes electional restrictions on thePP.
There is no good classification for these kindsof verbs in WordNet.
Finally, collocations or id-ioms, which are very frequent, (e.g.
lake a look, payatlention), are not considered lexical units in theWSJ corpus.
Their idiosyncratic behaviour intro-duces noise in the selectional restrictions acquisitionprocess.
Word-based models offer a clear advantageover class-based methods in these cases.6 D iscuss ionWhen sentences with PP attachment ambiguitieswere presented to two human expert judges the meanaccuracy obtained was 93.2% using the whole sen-tence and 88.2% using only the 4-tuple (Ratnaparkhiet al, 1994).
Our best result is 86.8%.
This accu-racy is close to human performance using the 4-tuplealone.
Collins and Brooks (1995) reported an accu-racy of 84.5% using words alone, a better score thanthose obtained with other methods tested on theWSJ corpus.
We used the same corpus as Collinsand Brooks (WSJ) and a similar sized training set.They used a test set size of 3097 patterns, whereaswe used 6000.
Due to this size, the differences be-tween both results (84.5% and 86.81%) were proba-bly significant.
Note that our results were obtainedusing only class information.
Ratnaparkhi et al(1994)'s results are the best reported so far usingonly classes (for 100% coverage): 79.1%.
From theseresults we can conclude that improvements in thesyntactic disambiguation problem will come not onlyfrom the availability of better hierarchies of classesbut also from methods that use them better.
NNsseem especially well designed to use them effectively.How do we account for the improved results?First, we used verb class information.
Given theset of words in the 4-tuple and a way to repre-1236sent senses and semantic lass information, a syn-tactic disambiguation system (SDS) must find someregularities between the co-occurrence of classesand the attachment point.
Presenting all of theclasses of all the senses of the complete 4-tuplesimultaneously, assuming that the training set isadequate, the network can detect which classes(and consequently which senses) are related withwhich others.
As we have said, due to its com-plexity, current methods do not consider the com-plete 4-tuple simultaneously.
For example, Liand Abe (1995) use p(verb altachlv prep n2) orp(verb attachlv nl prep)).
The task of selectingwhich of the senses contributes to making the cor-rect attachment could be difficult if the whole 4-tuple is not simultaneously present.
A verb hasmany senses, and each one could have a differentargumental structure.
In the selection of the cor-rect sense of the verb, the role of the object (nl)is very important.
Deciding the attachment site bycomputing p(verb attachlv prep n2) would be inad-equate.
It is also inadequate to omit n2.
Rule basedapproaches also come up against this problem.
InBrill and Resnik (1994), for instance, for reasons ofrun-time efficiency and complexity, rules regardingthe classes of both nl  and n2 were not permitted.Using a parallel presentation it is also possible todetect complex interactions between the classes ofa particular sense (for example, exceptions) or theclasses of different senses that cannot be detectedin the case of current statistical methods.
We havedetected these interactions in studies on word sensedisambiguation we are currently carrying out.
Forexample, the behavior of verbs which have the sensesof process and state differs from that of verbs whichhave the sense of process but not of state, and vicev-ersa.A parallel presentation (of classes as well of senses)gives rise to a highly complex input.
A very impor-tant characteristic of neural networks is their capa-bility of dealing with multidimensional inputs (Bar-ton, 1993).
They can compute very complex statis-tical functions and they are model free.
Comparedto the current methods used by the statistical orrule-based approaches to natural language process-ing, NNs offer the possibility of dealing with a muchmore complex approach (non-linear and high dimen-sional).References .Barron, A.
(1993).
Universal Approximation Bounds forSuperposition of a Sigmoidal Function.
IEEE Transac-tions on Information Theory, 39:930-945.Brill, E. & Resnik, P. (1994).
A Rule-Based Approachto Prepositional Phrase Attachment Disambiguation.
InProceedings of the Fifteenth International Conferenceson Computational Linguistics (COLING-9J).Collins, M. & Brooks, J.
(1995).
Prepositional PhraseTable 3: Accuracy results for different input encoding and tree cuts.Cut 4-tuple 4-tuple +10% 83.17 4-0.9 85.15 4-0.86% 84.07 4-0.7 85.32 4-0.92% 85.12 +1.0 86.81 4-0.9attachment.
In Proceedings of the 3rd Workshop on VeryLarge Corpora.Hindle, D. & Rooth, M. (1993).
Structural Ambigu-ity and Lexical Relations.
Computational Linguistics,19:103-120.Katz, J.
& Fodor, J.
(1963).
The Structure of Seman-tic Theory.
Language, 39: 170-210.Li, H. & Abe, N. (1995).
Generalizing Case Frames us-ing a Thesaurus and the MDL Principle.
In Proceedingsof the International Workshop on Parsing Technology.Marcus, M., Santorini, B.
& Marcinkiewicz, M.(1993).
Building a Large Annotated Corpus of English:The Penn Treebank.
Computational Linguistics, 19:313-330.Miller, G., Beckwith, R., Felbaum, C., Gross, D. &Miller, K. (1993).
Introduction to WordNet: An On-line Lexical Database.
Anonymous FTP, internet: clar-ity.princeton.edu.Ratnaparkhi, A., Reynar, J.
& Roukos, S. (1994).
AMaximum Entropy Model for Prepositional Phrase At-tachment.
In Proceedings of the ABPA Workshop onHuman Language Technology.Resnik, P. & Hearst, M. (1993).
Syntactic Ambiguityand Conceptual Relations.
In Proceedings of the ACLWorkshop on Very Large Corpora.1237
