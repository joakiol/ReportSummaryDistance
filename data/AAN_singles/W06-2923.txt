Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 171?175, New York City, June 2006. c?2006 Association for Computational LinguisticsLingPars, a Linguistically Inspired, Language-Independent MachineLearner for Dependency TreebanksEckhard BickInstitute of Language and CommunicationUniversity of Southern Denmark5230 Odense  M, Denmarkeckhard.bick@mail.dkAbstractThis paper presents a Constraint Grammar-inspired machine learner and parser,  Ling?Pars, that assigns dependencies to morpho?logically annotated treebanks in a function-centred way.
The system not only bases at?tachment probabilities for PoS, case, mood,lemma on those features' function probabili?ties, but also uses topological features likefunction/PoS  n-grams,  barrier  tags  anddaughter-sequences.
In  the  CoNLL sharedtask, performance was below average on at?tachment  scores,  but  a  relatively  higherscore for  function tags/deprels  in  isolationsuggests that the system's strengths were notfully exploited in the current architecture.1 IntroductionThis paper describes LingPars, a Constraint Gram?mar-inspired language-independent treebank-learn?er developed from scratch between January 9th andMarch  9th 2006  in  the  context  of  the  CoNLL-X2006 shared task (http://nextens.uvt.nl/~conll/), or?ganized by Sabine Buchholz,  Erwin Marsi,  YvalKrymolowski and Amit Dubey.
Training treebanksand test data were provided for  13 different  lan?guages: Arabic (Smr?
et al 2002), Chinese (Chenet  al.
2003),  Czech  (Haji?
et  al.
2001), Danish(Kromann 2003), Dutch (van der Beek et al 2002),German (Brants et.al 2002), Japanese (Kawata andBartels), Portuguese (Afonso et al 2002), Slovene(D?erosky  et  al.
2006),  Spanish  (Palomar  et  al.2004),  Swedish  (Nilsson  et  al.
2005),  Turkish(Oflazer et al 2003 and Nart et.al 2003), Bulgarian(Simov et al 2005).
A number of these treebankswere not originally annotated in dependency style,but transformed from constituent tree style for thetask, and all differ widely in terms of tag granulari?ty (21-302  part-of-speech tags, 7-82 function la?bels).
Also, not all treebanks included morphologi?cal  information,  and  only  half  offered  a  lemmafield.
Such  descriptive  variation  proved  to  be  aconsiderable  constraint  for  our  parser  design,  aswill  be  explained  in  chapter  2.
No  external  re?sources and no structural preprocessing were used1.2 Language  independence  versus  theoryindependenceWhile  manual  annotation  and/or  linguistic,  rule-based parsers are necessary for the creation of itstraining data, only a machine learning based parser(as targeted in the CoNNL shared task) can hope tobe  truly language independent  in  its  design.
Thequestion is, however, if this necessarily implies in?dependence of linguistic/descriptive theory.In our own approach, LingPars, we thus depart?ed from the Constraint Grammar descriptive model(Karlsson  et  al.
2005),  where  syntactic  functiontags (called DEPREL or dependency relations  inthe shared task) rank higher than dependency/con?stituency and are  established  before head attach?ments, rather than vice versa (as would be the casefor many probabilistic, chunker based systems, or1The only exception is what we consider a problem in the dependency-versionof the German TIGER treebank, where postnominal attributes of nouns appearas dependents of that noun's head if the latter is a preposition, but not otherwise(e.g.
if the head's head is a preposition).
LingPars  failed to learn this somewhatidiosyncratic distinction, but performance improved when  the analysis was pre?processed with an additional np-layer (to be re-flattened after parsing.
).171the classical PENN treebank descriptive model).
Inour hand-written,  rule based parsers,  dependencytreebanks are  constructed by using sequential  at?tachment rules, generally attaching functions (e.g.subject, object, postnominal) to forms (finite verb,noun) or lexical tags (tense, auxiliary, transitive),with  a  direction  condition  and  the  possibility  ofadded target,  context  or  barrier  conditions  (Bick2005).In LingPars, we tried to mimic this methodologyby trying to learn probabilities for both CG stylesyntactic-function  contexts  and  function-to-formattachment rules.
We could not,  however, imple?ment the straightforward idea of learning probabili?ties and optimal ordering for an existing body of(manual) seeding rules,  because the 13 treebankswere not harmonized in their tag sets and descrip?tive conventions2.As  an  example,  imagine  a  linguistic  rule  thattriggers  "subclause-hood"  for  a  verb-headed  de?pendency-node as soon as a subordinator attachesto  it,  and  then,  implementing  "subclause-hood",tries to attach the verb not to the root, but to anoth?er verb left of the subordinator, or right to a root-attaching verb.
For the given set of treebanks prob?abilities and ordering priorities for this rule cannotbe learned by one and the same parser, simply be?cause some treebanks attach the verb to the subor?dinator rather than vice versa, and for verb chains,there is no descriptive consensus as to whether theauxiliary/construction  verb  (e.g.
Spanish)  or  themain verb (e.g.
Swedish) is regarded as head.3 System architectureThe point of departure for pattern learning in Ling?Pars  were  the  fine-grained  part  of  speech  (PoS)tags (POSTAG) and the LEMMA tag.
For  thoselanguages that did not provide a lemma tag, lower-cased  word  form was  used  instead.
Also,  whereavailable from the FEATS field and not already in?tegrated into the PoS tag, the following informa?tion was integrated into the PoS tag:a) case, which was regarded as a good predictorfor function, as well as a good dependency-indica?tor for e.g.
preposition- and adnominal attachmentb) mood/finiteness, in order to predict subordina?tion and verb chaining, especially in the absence of2 Neither was there time (and for some languages: reading knowledge) to writethe necessary converters to and from a normalized standard formalism for eachtreebank.auxiliary class information in the FEATS fieldc) pronoun subclass, in order to predict adnomi?nal vs. independent function as well as subordinat?ing function (relatives and interrogatives)A few treebanks did not classify subordinatingwords  as  conjunctions,  relatives,  interrogativesetc., but lumped them into the general adverb andpronoun classes.
Danish is a case in point - here,the treebank classified all non-inflecting words asPoS 'U'3.
Our solution, implemented only for Dan?ish and Swedish, was to introduce a list of struc?ture-words, that would get their PoS appended withan '-S', enabling the  learner to distinguish betweene.g.
"ordinary" ADV, and "structural" ADV-S.3.1 The parserIn a first round, our parser calculates a preferencelist of functions and dependencies for each word,examining all possible mother-daughter pairs andn-grams in the sentence (or paragraph).
Next, de?pendencies  are  adjusted  for  function,  basicallysumming up the  frequency-,  distance- and direc?tion-calibrated function?PoS attachment probabil?ities  for  all  contextually  allowed  functions  for  agiven word.
Finally, dependency probabilities areweighted  using  linked  probabilities  for  possiblemother-, daughter- and sister-tags in a second pass.The result are 2 arrays, one for possible daugh?ter?mother  pairs,  one  for  word:function  pairs.Values in both arrays are normalized to the 0..1 in?terval, meaning that for instance even an originallylow probability, long distance attachment will gethigh values after normalization if there are few orno competing alternatives for the word in question.LingPars  then  attempts  to  "effectuate"  the  de?pendency (daughter?mother) array, starting withthe - in normalized terms - highest value4.
If  thedaughter candidate is as yet unattached, and the de?pendency does not produce circularities or crossingbranches, the corresponding part of the (ordered)word:function array is calibrated for the suggesteddependency, and the top-ranking function chosen.In principle,  one pass through the  dependencyarray would suffice to parse a sentence.
However,3For the treebank as such, no information is lost, since it will be recoverablefrom the function tag.
In a training situation, however, there is much less to trainon than in a treebank with a more syntactic definition of PoS.4 Though we prefer to think of attachments as bottom-up choices, the value-or?dered approach is essentially neither bottom-up nor top-down, depending on thelanguage and the  salience of relations in a sentence, all runs had a great varia?tion in the order of attachments.
A middle-level attachment like case-basedpreposition-attachment, for instance, can easily outperform (low) article- or(high) top-node-attachment.172due to linguistic constraints like uniqueness princi?ple, barrier tags and "full" heads5, some words maybe  left  unattached  or  create  conflicts  for  theirheads.
In these cases, weights are reduced for theconflicting functions, and increased for all daugh?ter?mother  values  of  the  unattached  word.
Thevalue arrays are then recomputed and rerun.
In thecase of unattached words, a complete rerun is per?formed, allowing problematic words to attach be?fore  those  words  that  would  otherwise  haveblocked them.
In the case of a function (e.g subjectuniqueness)  conflict,  only  the  words  involved  inthe conflict are rerun.
If no conflict-free solution isfound after 19 runs, barrier-, uniqueness- and pro?jectivity-constraints are relaxed for a last run6.Finally,  the  daughter-sequence  for  each  head(with the head itself  inserted) is  checked againstthe  probability  of  its  function  sequence  (learnednot  from n-grams  proper,  but  from  daughter-se?quences in the training corpus).
For instance, theconstituents of a clause would make up such a se?quence and allow to correct a sequence like SUBJVFIN  ARG2  ARG1  into  SUBJ  VFIN  ARG1ARG2, where ARG1 and ARG2 are object func?tions  with  a  preferred  order  (for  the  languagelearned) of ARG1 ARG2.3.2 Learning functions (deprels)LingPars  computes  function  probabilities  (Vf,function value) at three levels: First, each lemmaand PoS is assigned local (context-free) probabili?ties for all possible functions.
Second, the proba?bility of  a  given function occurring at  a  specificplace  in  a  function  n-gram (func-gram,  example(a))  is  calculated (with n between 2 and 6).
Thelearner only used endocentric func-grams, markingwhich  of  the  function  positions  had  their  headwithin the func-gram.
If no funcgram supported agiven function, its probability for the word in ques?tion was set to zero.
At the third level, for each en?docentric n-gram of word classes (PoS), the proba?bility for a given function occurring at a given po?sition  in  the  n-gram (position  2  in  example  (b))was computed.
Here, only the longest possible n-grams were used by the parser, and first and lastpositions of the n-gram were used only to providecontext, not to assign function probabilities.5Head types with a limited maximum number of dependents (usually, one)6In the rare case of still missing heads or functions, these are computed usingprobabilities for a simplified set of word classes (mostly the CPOSTAG), or - asa last resort - set to ROOT-attachment.
(a)>N?2 SUBJ?4 <N?2 AUX MV?4 ACC?5(b) art?2 n:SUBJ?4 adj?2 v-fin v-inf?4 n?53.3 Learning dependenciesIn a rule based Constraint Grammar system, depen?dency would be expressed as attachment of func?tions to forms (i.e.
subject to verb, or modifier toadjective).
However,  with  empty  deprel  fields,LingPars cannot use functions directly, only theirprobabilities.
Therefore, in a first pass, it computesthe probability for the whole possible attachmentmatrix for a sentence, using learned mother- anddaughter-normalized  frequencies  for  attachmentsof  type  (a)  PoS?PoS,  (b)  PoS?Lex,  (c)Lex?PoS and (d) Lex?Lex, taking into accountalso  the  learned  directional  and  distance  prefer?ences.
Each matrix cell is then filled with a valueVfa ("function attachment value") - the sum of theindividual normalized probabilities of all possiblefunctions  for  that  particular  daughter  given  thatparticular  mother  multiplied  with  the  preestab?lished,  attachment-independent  Vf  value  for  thattoken-function combination.Inspired by the BARRIER conditions in CG rulecontexts, our learner also records the frequency ofthose PoS and those functions (deprels) that mayappear between a dependent of PoS A and a headof PoS B.
The parser then regards all  other,  non-registered interfering PoS or functions as blockingtokens for a given attachment pair, reducing its at?tachment value by a factor of 1/100.In a second pass, the attachment matrix is cali?brated  using  the  relative  probabilities  for  depen?dent daughters, dependent sisters and head mothergiven.
This way, probabilities of object and objectcomplement  sisters  will  enhance  each  other,  andgiven the fact that treebanks differ as to which ele?ment of a verb chain arguments attach to, a verbalhead  can  be  treated  differently  depending  onwhether it has a high probability for another verb(with auxiliary,  modal  or  main verb function) asmother or daughter or not.Finally, like for functions, n-grams are used tocalculate attachment probabilities.
For each endo?centric PoS n-gram (of length 6 or less), the proba?bilities  of  all  treebank-supported  PoS:functionchains and their dependency arcs are learned, andthe value for an attachment word pair occurring inthe chain will be corrected using both the chain/n-gram probability and the Vf value for the function173associated  with  the  dependent  in  that  particularchain.
For contextual reasons, arcs central to the n-gram are weighted higher than peripheral arcs.73.4 Non-projectivity and other language-spe?cific problemsAs a general rule, non-projective arcs were only al?lowed if no other, projective head could be foundfor a given word.
However, linguistic knowledgesuggests that non-projective arcs should be particu?larly likely in  connection with verb-chain-depen?dencies,  where subjects  attach to  the  finite  verb,but objects to the non-finite verb, which can createcrossing arcs in the case of object fronting, chaininversion  etc.
Since  we  also  noted  an  error-riskfrom arguments getting attached to the closest verbin  a  chain  rather  than  the  linguistically  correctone8, we chose to introduce systematic, after-parseraising of certain pre-defined arguments from theauxiliary to the main verb.
This feature needs lan?guage-dependent parameters, and time constraintsonly allowed the implementation for Danish, Span?ish, Portuguese and Czech.
For Dutch, we also dis?covered word-class-related projectivity-errors, thatcould be  remedied by exempting certain  FEATSclasses from the parser's general projectivity con?straint altogether (prep-voor and V-hulp)9.In  order  to  improve  root  accuracy,  topnodeprobability was set to zero for verbs with a safesubordinator dependent.
However, even those tree?banks descriptively supporting this did not all PoS-mark  subordinators.
Therefore,  FEATS-informa?tion was used, or as a last resort - for Danish andSwedish  - word forms.A  third  language-specific  error-source  waspunctuation, because some treebanks (cz, sl, es) al?lowed punctuation as heads.
Also, experiments forthe Germanic and Romance languages showed thatperformance decreased when punctuation was al?lowed as BARRIER, but increased, when a fine-grained punctuation PoS10 was included in functionand dependency n-grams.7Due to BARRIER constraints, or simply because of insufficient training data inthe face of a very detailed tag set, it may be impossible to assign all words n-gram supported functions or dependencies.
In the former case, local functionprobabilities are used, in the latter attachment is computed as function ?
PoSprobability only, using the most likely function.8 Single verbs being more frequent than verb chains, the learner tended to gener?alize close attachment, and even (grand)daughter and (grand)mother conditionscould not entirely remedy this problem.9Though desirable, there was no time to implement this for other languages.10 Only for Spanish and Swedish was there a subdivision of punctuation PoS, sowe had to supply  this information in all other cases by adding token-informa?tion to the POSTAG field.4 EvaluationBecause of LingPars' strong focus on function tags,a separate analysis of attachment versus label per?formance was thought to be of interest.
Ill. 1 plotsthe latter (Y-axis) against the former (X-axis), withdot size symbolizing treebank size.
In this evalua?tion, a fixed training chunk size of 50,000 tokens11was used, and tested on a different sample of 5,000tokens (see also 5/50 evaluation in ill. 2).
For mostlanguages,  function  performance  was  better  thanattachment performance (3.2 percentage points onaverage,  as opposed to 0.44 for  the CoNLL sys?tems overall), with dots above the hyphenated "di?agonal of balance".
Interestingly, the graphics alsomakes  it  clear  that  performance  was  lower  forsmall treebanks, despite the fact that training cor?pus size had been limited in the experiment, possi?bly indicating correlated differences in the balancebetween tag set size and treebank size.Illustration 1: Attachment accuracy(x-axis) vs. label accuracy (y-axis)Ill.  2 keeps the information from ill. 1 (5/50-depand 5/50-func), represented in the two lower lines,but adds performance for maximal training corpussize12 with  (a)  a  randomly  chosen  test  chunk  of5,000 tokens  not included in  the  training corpus(5/all-5)  and (b)  a  20,000 token chunk  from thetraining corpus (20/all).
Languages were sorted ac?11Smaller for Slovene and Arabic (for these languages: largest possible)12Due to deadline time constraints, an upper limit of 400,000 lines was forced onthe biggest treebanks, when training for unknown test data,  meaning that only ?of the German data and 1/3 of the Czech data could be used.174cording  to  20/all-func  accuracy.
As  can  be  seenfrom  the  dips  in  the  remaining  (lower)  curves,small training corpora (asterisk-marked languages)made it difficult for the parser (1) to match 20/allattachment performance on unknown data, and (2)to  learn  labels/functions  in  general  (dips  in  allfunction curves, even 20/all).
For the larger tree?banks, the parser performed better (1-3 percentagepoints) for the full training set than for the 50,000token training set.Illustration 2: Performance with different training cor?pus sizes (upper 2 curves: Test data included)5 OutlookWe have  shown that  a  probabilistic  dependencyparser can be built on CG-inspired linguistic prin?ciples with a strong focus on function and tag se?quences.
Given the time constraint and the fact thatthe learner had to be built from scratch, its perfor?mance would encourage further research.
In partic?ular, a systematic parameter/performance analysis13should be performed for the individual languages.In the long term, a notational harmonization of thetreebanks  should  allow  the  learner  to  be  seededwith existing hand-written dependency rules.ReferencesAfonso, S., E. Bick, R. Haber and D. Santos.
Floresta Sint?
(c)tica: A treebank of Portuguese.
In   Proceed?ings of LREC'02.
pp.
1698-1703 .
Paris: ELRAvan der Beek, L. G. Bouma, R. Malouf, G. van Noord.
2002.
The Alpino Dependency Treebank.
In: Compu?tational  Linguistics  in  the  Netherlands  CLIN 2001.13Parameters like uniqueness and directedness are already learned by the system(through  probability thresholds), while others, like function weights, structuralword classes and frequency thresholds for barriers and lexeme n-grams are usednow, but with a fixed value for all languages.pp.
8-22.
RodopiBick, Eckhard.
2005.
Turning Constraint Grammar Data into  Running  Dependency  Treebanks.
In:  Civit, Montserrat & K?bler, Sandra & Mart?, Ma.
Ant?nia (ed.
), Proceedings of TLT 2005, Barcelona.
pp.19-2Brants, S., S. Dipper, S. Hansen, W. Lezius, G. Smith.
2002.
The TIGER Treebank.
Proc.
of TLT1, SozopolD?erosky,  S.,  T.  Erjavec,  N.  Ledinek,  P.  Pajas,  Z.
?abokrtsky, A.
?ele.
2006.
Towards a Slovene De?pendency Treebank.
In Proc.
of LREC'06, GenoaHaji?, J., B.
Hladk?, and P. Pajas.
2001.
The Prague De?pendency Treebank:  Annotation Structure  and Sup?port.
In  Proc.
of  the IRCS Workshop on Linguistic  Databases, pp.
105-114.
University of Pennsylvania.Karlsson,  Fred, Atro Vouitilainen, Jukka Heikkil?
and A. Anttila.
1995.
Constraint Grammar - A Language-Independent  System  for  Parsing  Unrestricted  Text.
Mouton de Gruyter: Berlin.Kawata,  Y.  and  J.  Bartels.
2000.
Stylebook  for  the Japanese  Treebank  in  VERBMOBIL.
Universit?t T?bingen: Verbmobil-Report 240.Chen, Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, Chi-Ching Luo, Ming-Chung Chang, Chao-Jan Chen, and Zhao-Ming Gao.
2003.
Sinica Treebank: Design Cri?teria, Representational Issues and Implementation.
In A.  Abeille  (ed.)
Treebanks  Building  and  Using Parsed Corpora.
Dordrecht:Kluwer, pp231-248.Kromann, M. T. 2003.
The Danish Dependency Tree?bank.
In J. Nivre and E. Hinrichs (ed.)
Proceedings of  TLT2003.
V?xj?
University Press, SwedenNart,  B.  Atalay,  Kemal  Oflazr,  Bilge  Say.
2003.
The Annotation Process in the Turkish Treebank.
In Pro?ceedings of the EACL Workshop on Linguistically In?terpreted Corpora - LINC 2003.
BudapestNilsson, J, J.
Hall and J. Nivre.
2005.
MAMBA Meets TIGER:  Reconstructing  a  Swedish  Treebank  from Antiquity.
In Proceedings NODALIDA 2005.
JoenssuOflazer,  K.,  B.
Say, D.Z.
Hakkani-T?r,  G. T?r.
2003.
Building  a  Turkish  Treebank.
In  A.  Abeill?
(ed.)
Building and Exploiting Syntactically-annotated Cor?pora.
KluwerPalomar, M. et.
al.
2004.
Construcci?n de una base de datos de ?rboles sint?ctico-sem?nticos para el catal?n, euskera y castellano.
In:  Proceedings of SEPLN XX, pp 81-88.
Barcelona: ISSN 1135-5948Simov, K., P. Osenova, A. Simov, M. Kouylekov.
2004.
Design and Implementation of the Bulgarian HPSG-based Treebank.
In E. Hinrichs and K. Simov (ed.
), Journal of Research on Language and Computation,  Vol.
2, No.
4 , pp.
495-522.
KluwerSmr?, Otakar,  Jan ?naidauf,  and Petr  Zem?nek.
2002.
Prague Dependency Treebank for Arabic: Multi-Lev?el Annotation of Arabic corpus.
In Proceedings of the  International  Symposium  on  Processing  of  Arabic, pages 147-155, Manouba, Tunisia, April 2002.cz de pt bu se nl tu*ar*sl*da ja es*zh6567,57072,57577,58082,58587,59092,59597,55/50 dep5/50 func20/all dep20/all func5/all-5 dep5/all-5 func175
