Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 183?188,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsVs and OOVs: Two Problems for Translation between German andEnglishSara Stymne, Maria Holmqvist, Lars AhrenbergLinko?ping UniversitySweden{sarst,marho,lah}@ida.liu.seAbstractIn this paper we report on experimentswith three preprocessing strategies for im-proving translation output in a statisticalMT system.
In training, two reorderingstrategies were studied: (i) reorder on thebasis of the alignments from Giza++, and(ii) reorder by moving all verbs to theend of segments.
In translation, out-of-vocabulary words were preprocessed in aknowledge-lite fashion to identify a likelyequivalent.
All three strategies were im-plemented for our English?German sys-tem submitted to the WMT10 shared task.Combining them lead to improvements inboth language directions.1 IntroductionWe present the Liu translation system for the con-strained condition of the WMT10 shared transla-tion task, between German and English in both di-rections.
The system is based on the 2009 Liu sub-mission (Holmqvist et al, 2009), that used com-pound processing, morphological sequence mod-els, and improved alignment by reordering.This year we have focused on two issues: trans-lation of verbs, which is problematic for transla-tion between English and German since the verbplacement is different with German verbs often be-ing placed at the end of sentences; and OOVs, out-of-vocabulary words, which are problematic formachine translation in general.
Verb translationis targeted by trying to improve alignment, whichwe believe is a crucial step for verb translationsince verbs that are far apart are often not alignedat all.
We do this mainly by moving verbs to theend of sentences previous to alignment, which wealso combine with other alignments.
We trans-form OOVs into known words in a post-processingstep, based on casing, stemming, and splitting ofhyphenated compounds.
In addition, we performgeneral compound splitting for German both be-fore training and translation, which also reducesthe OOV rate.All results in this article are for the develop-ment test set newstest2009, on truecased output.We report Bleu scores (Papineni et al, 2002) andMeteor ranking (without WordNet) scores (Agar-wal and Lavie, 2008), using percent notation.
Wealso used other metrics, but as they gave similarresults they are not reported.
For significance test-ing we used approximate randomization (Riezlerand Maxwell, 2005), with p < 0.05.2 Baseline SystemThe 2010 Liu system is based on the PBSMT base-line system for the WMT shared translation task1.We use the Moses toolkit (Koehn et al, 2007) fordecoding and to train translation models, Giza++(Och and Ney, 2003) for word alignment, and theSRILM toolkit (Stolcke, 2002) to train languagemodels.
The main difference to the WMT base-line is that the Liu system is trained on truecaseddata, as in Koehn et al (2008), instead of lower-cased data.
This means that there is no need for afull recasing step after translation, instead we onlyneed to uppercase the first word in each sentence.2.1 CorpusWe participated in the constrained task, where weonly trained the Liu system on the news and Eu-roparl corpora provided for the workshop.
Thetranslation and reordering models were trained us-ing the bilingual Europarl and news commentarycorpora, which we concatenated.We used two sets of language models, onewhere we first trained two models on Europarland news commentary, which we then interpolated1http://www.statmt.org/wmt10/baseline.html183with more weight given to the news commentary,using weights from Koehn and Schroeder (2007).The second set of language models were trainedon monolingual news data.
For tuning we usedevery second sentence, in total 1025 sentences, ofnews-test2008.2.2 Training with Limited ComputationalResourcesOne challenge for us was to train the transla-tion sytem with limited computational resources.We trained all systems on one Intel Core 2 CPU,3.0Ghz, 16 Gb of RAM, 64 bit Linux (RedHat)machine.
This constrained the possibilities of us-ing the data provided by the workshop to the full.The main problem was training the language mod-els, since the monolingual data was very largecompared to the bilingual data.In order to train language models that were bothfast at runtime, and possible to train with the avail-able memory, we chose to use the SRILM toolkit(Stolcke, 2002), with entropy-based pruning, with10?8 as a threshold.
To reduce the model size wealso used lower order models for the large corpus;4-grams instead of 5-grams for words and 6-gramsinstead of 7-grams for the morphological models.It was still impossible to train on the monolingualEnglish news corpus, with nearly 50 million sen-tences, so we split that corpus into three equal sizeparts, and trained three models, that were interpo-lated with equal weights.3 Morphological ProcessingWe added morphological processing to the base-line system, by training additional sequence mod-els on morphologically enriched part-of-speechtags, and by compound processing for German.We utilized the factored translation frameworkin Moses, to enrich the baseline system with anadditional target sequence model.
For Englishwe used part-of-speech tags obtained using Tree-Tagger (Schmid, 1994), enriched with more fine-grained tags for the number of determiners, in or-der to target more agreement issues, since nounsalready have number in the tagset.
For Germanwe used morphologically rich tags from RFTag-ger (Schmid and Laws, 2008), that contains mor-phological information such as case, number, andgender for nouns and tense for verbs.
We usedthe extra factor in an additional sequence modelon the target side, which can improve word orderSystem Bleu MeteorBaseline 13.42 48.83+ morph 13.85 49.69+ comp 14.24 49.41Table 1: Results for morphological processing,English?GermanSystem Bleu MeteorBaseline 18.34 38.13+ morph 18.39 37.86+ comp 18.50 38.47Table 2: Results for morphological processing,German?Englishand agreement between words.
For German thefactor was also used for compound merging.Prior to training and translation, compound pro-cessing was performed, using an empirical method(Koehn and Knight, 2003; Stymne, 2008) thatsplits words if they can be split into parts that oc-cur in a monolingual corpus, choosing the split-ting option with the highest arithmetic mean of itspart frequencies in the corpus.
We split nouns,adjectives and verbs, into parts that are contentwords or particles.
We imposed a length limit onparts of 3 characters for translation from Germanand of 6 characters for translation from English,and we had a stop list of parts that often led toerrors, such as arische (Aryan) in konsularische(consular).
We allowed 10 common letter changes(Langer, 1998) and hyphens at split points.
Com-pound parts were given a special part-of-speechtag that matches the head word.For translation into German, compound partswere merged into full compounds using a methoddescribed in Stymne and Holmqvist (2008), whichis based on matching of the special part-of-speechtag for compound parts.
A word with a compoundPOS-tag were merged with the next word, if theirPOS-tags were matching.Tables 1 and 2 show the results of the addi-tional morphological processing.
Adding the se-quence models on morphologically enriched part-of-speech tags gave a significant improvement fortranslation into German, but similar or worse re-sults as the baseline for translation into English.This is not surprising, since German morphologyis more complex than English morphology.
Theaddition of compound processing significantly im-proved the results on Meteor for translation into184English, and it also reduced the number of OOVsin the translation output by 20.8%.
For translationinto German, compound processing gave a signif-icant improvement on both metrics compared tothe baseline, and on Bleu compared to the systemwith morphological sequence models.
Overall, webelieve that both compound splitting and morphol-ogy are useful; thus all experiments reported in thesequel are based on the baseline system with mor-phology models and compound splitting, whichwe will call base.4 Improved Alignment by ReorderingPrevious work has shown that translation qualitycan be improved by making the source languagemore similar to the target language, for instancein terms of word order (Wang et al, 2007; Xiaand McCord, 2004).
In order to harmonize theword order of the source and target sentence, theyapplied hand-crafted or automatically induced re-ordering rules to the source sentences of the train-ing corpus.
At decoding time, reordering ruleswere again applied to input sentences before trans-lation.
The positive effects of such methods seemto come from a combination of improved align-ment and improved reordering during translation.In contrast, we focus on improving the wordalignment by reordering the training corpus.
Thetraining corpus is reordered prior to word align-ment with Giza++ (Och and Ney, 2003) and thenthe word links are re-adjusted back to the originalword positions.
From the re-adjusted corpus, wecreate phrase tables that allow translation of non-reordered input text.
Consequently, our reorderingonly affects the word alignment and the phrase ta-bles extracted from it.We investigated two ways of reordering.
Thefirst method is based on word alignments and theother method is based on moving verbs to sim-ilar positions in the source and target sentences.We also investigated different combinations of re-orderings and alignments.
All results for the sys-tems with improved reordering are shown in Ta-bles 3 and 4.4.1 Reordering Based on AlignmentsThe first reordering method does not require anysyntactic information or rules for reordering.
Wesimply used symmetrized Giza++ word align-ments to reorder the words in the source sentencesto reflect the target word order and applied Giza++System Bleu Meteorbase 14.24 49.41reorder 14.32 49.58verb 13.93 49.22base+verb 14.38 49.72base+verb+reorder 14.39 49.39Table 3: Results for improved alignment,English?GermanSystem Bleu Meteorbase 18.50 38.47reorder 18.77 38.53verb 18.61 38.53base+verb 18.66 38.61base+verb+reorder 18.73 38.59Table 4: Results for improved alignment,German?Englishagain to the reordered training corpus.
The follow-ing steps were performed to produce the final wordalignment:1.
Word align the training corpus with Giza++.2.
Reorder the source words according to the or-der of the target words they are aligned to(store the original source word positions forlater).3.
Word align the reordered source and originaltarget corpus with Giza++.4.
Re-adjust the new word alignments so thatthey align source and target words in the orig-inal corpus.The system built on this word alignment (re-order) had a significant improvement in Bleu scoreover the unreordered baseline (base) for transla-tion into English, and small improvements other-wise.4.2 Verb movementThe positions of finite verbs are often very differ-ent in English and German, where they are oftenplaced at the end of sentences.
In several cases wenoted that finite verbs were misaligned by Giza++.To improve the alignment of verbs, we moved allverbs in both English and German to the end of thesentences prior to word alignment.
The reorderedsentences were word aligned with Giza++ and the185resulting word links were then re-adjusted to alignwords in the original corpus.The system created from this alignment (verb)resulted in significantly lower scores than base fortranslation into German, and similar scores as basefor translation into English.4.3 Combination SystemsThe alignment based on reordered verbs did notproduce a better alignment in terms of Bleu scoresof the resulting translations, which led us to theconclusion that the alignment was noisy.
How-ever, it is possible that we did correctly align somewords that were misaligned in the baseline align-ment.
To investigate this issue we concatenatedfirst the baseline and verb alignments, and then allthree alignments, and extracted phrase tables fromthe concatenated training sets.All scores for both combined systems signifi-cantly outperformed the unfactored baseline, andwere slightly better than base.
For translation intoGerman it was best to use the combination of onlyverb and base, which was significantly better thanbase on Meteor.
This shows that even though theverb alignments were not good when used in a sin-gle system, they still could contribute in a combi-nation system.5 Preprocessing of OOVsOut-of-vocabulary words, words that have notbeen seen in the training data, are a problem instatistical machine translation, since no transla-tions have been observed for them.
The standardstrategy is to transfer them as is to the translationoutput, which, naive as it sounds, actually workswell in some cases, since many OOVs are numbersor proper names (Stymne and Holmqvist, 2008).However, it still results in incomprehensible wordsin the output in many cases.
We have investi-gated several ways of changing unknown wordsinto similar words that have been seen in the train-ing data, in a preprocessing step.We also considered another OOV problem,number formatting, since it differs between En-glish and German.
To address this, we swappeddecimal points/commas, and other delimeters forunknown numbers in a post-processing step.In the preprocessing step, we applied a num-ber of transformations to each OOV word, accept-ing the first applicable transformation that led to aknown word:Type German Englishtotal OOVs 1833 1489casing 124 26stemming 270 72hyphenated words 230 124end hyphens 24 ?Table 5: Number of affected words by OOV-preprocessing1.
Change the word into a known cased ver-sion (since we trained a truecased system,this handles cased variations of words)2.
Stem the word, and if we know the stem,choose the most common realisation of thatstem (using a Porter stemmer)3.
For hyphenated words, split at the hyphen (ifany of the resulting parts are OOVs, they arerecursively treated as well)4.
Remove hyphens at the end of German words(that could result from compound splitting)The first two steps were based on frequency listsof truecased and stemmed words that we compiledfrom the monolingual training corpora.Inspection of the initial results showed thatproper names were often changed into other wordsin English, so we excluded them from the prepro-cessing by not applying it to words with an initialcapital letter.
This happened to a lesser extent forGerman, but here it was impossible to use the samesimple heuristic for proper names, since Germannouns also have an initial capital letter.The number of affected words for the baselineusing the final transformations are shown in Table5.
Even though we managed to transform somewords, we still lack a transformation for the ma-jority of OOVs.
Despite this, there is a tendency ofsmall improvements on both metrics in the major-ity of cases in both translation directions, as shownin Tables 6 and 7.Figure 1 shows an example of how OOV pro-cessing affects one sentence for translation fromGerman to English.
In this case splitting a hy-phenated compound gives a better translation,even though the word opening is chosen ratherthan jack.
There is also a stemming change,where the adjective ausgereiftesten (the most well-engineered), is changed form superlative to posi-tive.
This results in a more understandable trans-186DE original Die besten und technisch ausgereiftesten Telefone mit einer 3,5-mm-O?ffnungfu?r normale Kopfho?rer kosten bis zu fu?nfzehntausend Kronen.DE preprocessed die besten und technisch ausgereifte Telefone mit einer 3,5 mm O?ffnung fu?rnormale Kopf Ho?rer kosten bis zu fu?nfzehntausend Kronen .base+verb+reorder The best and technically ausgereiftesten phones with a 3,5-mm-O?ffnung fornormal earphones cost up to fifteen thousand kronor.base+verb+reorder+OOVThe best and technologically advanced phones with a 3.5 mm opening for nor-mal earphones cost up to fifteen thousand kronor.EN reference The best and most technically well-equipped telephones, with a 3.5 mm jackfor ordinary headphones, cost up to fifteen thousand crowns.Figure 1: Example of the effects of OOV processing for German?EnglishSystem Bleu Meteorbase 14.24 49.41+ OOV 14.26 49.43base+verb 14.38 49.72+ OOV 14.42 49.75+ MBR 14.41 49.77Table 6: Results for OOV-processing and MBR,English?German.System Bleu Meteorbase 18.50 38.47+ OOV 18.48 38.59base+verb+reorder 18.73 38.59+ OOV 18.81 38.70+ MBR 18.84 38.75Table 7: Results for OOV-processing and MBR,German?English.lation, which, however, is harmful to automaticscores, since the preceding word, technically,which is identical to the reference, is changed intotechnologically.This work is related to work by Arora et al(2008), who transformed Hindi OOVs by us-ing morphological analysers, before translation toJapanese.
Our work has the advantage that it ismore knowledge-lite, as it only needs a Porterstemmer and a monolingual corpus.
Mirkin et al(2009) used WordNet to replace OOVs by syn-onyms or hypernyms, and chose the best overalltranslation partly based on scoring of the sourcetransformations.
Our OOV handling could po-tentially be used in combination with both thesestrategies.6 Final SubmissionFor the final Liu shared task submission weused the base+verb+reorder+OOV system forGerman?English and the base+verb+OOV sys-tem for English?German, which had the bestoverall scores considering all metrics.
To thesesystems we added minimum Bayes risk (MBR)decoding (Kumar and Byrne, 2004).
In standarddecoding, the top suggestion of the translation sys-tem is chosen as the system output.
In MBR de-coding the risk is spread by choosing the trans-lation that is most similar to the N highest scor-ing translation suggestions from the system, withN = 100, as suggested in Koehn et al (2008).MBR decoding gave hardly any changes in auto-matic scores, as shown in Tables 6 and 7.
The finalsystem was significantly better than the baseline inall cases, and significantly better than base on Me-teor in both translation directions, and on Bleu fortranslation into English.7 ConclusionsAs in Holmqvist et al (2009) reordering by us-ing Giza++ in two phases had a small, but consis-tent positive effect.
Aligning verbs by co-locatingthem at the end of sentences had a largely negativeeffect.
However, when output from this methodwas concatenated with the baseline alignment be-fore extracting the phrase table, there were con-sistent improvements.
Combining all three align-ments, however, had mixed effects.
Combining re-ordering in training with a knowledge-lite methodfor handling out-of-vocabulary words led to sig-nificant improvements on Meteor scores for trans-lation between German and English in both direc-tions.187ReferencesAbhaya Agarwal and Alon Lavie.
2008.
METEOR,M-BLEU and M-TER: Evaluation metrics for high-correlation with human rankings of machine transla-tion output.
In Proceedings of the Third Workshopon Statistical Machine Translation, pages 115?118,Columbus, Ohio, USA.Karunesh Arora, Michael Paul, and Eiichiro Sumita.2008.
Translation of unknown words in phrase-based statistical machine translation for languagesof rich morphology.
In Proceedings of the 1st Inter-national Workshop on Spoken Languages Technolo-gies for Under-Resourced Languages, pages 70?75,Hanoi, Vietnam.Maria Holmqvist, Sara Stymne, Jody Foo, and LarsAhrenberg.
2009.
Improving alignment for SMTby reordering and augmenting the training corpus.In Proceedings of the Fourth Workshop on Statis-tical Machine Translation, pages 120?124, Athens,Greece.Philipp Koehn and Kevin Knight.
2003.
Empiricalmethods for compound splitting.
In Proceedings ofthe 10th Conference of the EACL, pages 187?193,Budapest, Hungary.Philipp Koehn and Josh Schroeder.
2007.
Experi-ments in domain adaptation for statistical machinetranslation.
In Proceedings of the Second Workshopon Statistical Machine Translation, pages 224?227,Prague, Czech Republic.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbst.
2007.
Moses:Open source toolkit for statistical machine transla-tion.
In Proceedings of the 45th Annual Meetingof the ACL, demonstration session, pages 177?180,Prague, Czech Republic.Philipp Koehn, Abhishek Arun, and Hieu Hoang.2008.
Towards better machine translation quality forthe German-English language pairs.
In Proceedingsof the Third Workshop on Statistical Machine Trans-lation, pages 139?142, Columbus, Ohio, USA.Shankar Kumar and William Byrne.
2004.
MinimumBayes-risk decoding for statistical machine transla-tion.
In Proceedings of the 2004 Human LanguageTechnology Conference of the NAACL, pages 169?176, Boston, Massachusetts, USA.Stefan Langer.
1998.
Zur Morphologie und Seman-tik von Nominalkomposita.
In Tagungsband der4.
Konferenz zur Verarbeitung natu?rlicher Sprache(KONVENS), pages 83?97, Bonn, Germany.Shachar Mirkin, Lucia Specia, Nicola Cancedda, IdoDagan, Marc Dymetman, and Idan Szpektor.
2009.Source-language entailment modeling for translat-ing unknown terms.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP, pages 791?799, Suntec, Singapore.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of the ACL, pages 311?318, Philadelphia, Pennsylvania, USA.Stefan Riezler and John T. Maxwell.
2005.
On somepitfalls in automatic evaluation and significance test-ing for MT.
In Proceedings of the Workshop on In-trinsic and Extrinsic Evaluation Measures for MTand/or Summarization at the 43th Annual Meeting ofthe ACL, pages 57?64, Ann Arbor, Michigan, USA.Helmut Schmid and Florian Laws.
2008.
Estimation ofconditional probabilities with decision trees and anapplication to fine-grained pos tagging.
In Proceed-ings of the 22th International Conference on Com-putational Linguistics, pages 777?784, Manchester,UK.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of theInternational Conference on New Methods in Lan-guage Processing, pages 44?49, Manchester, UK.Andreas Stolcke.
2002.
SRILM ?
an extensiblelanguage modeling toolkit.
In Proceedings of theSeventh International Conference on Spoken Lan-guage Processing, pages 901?904, Denver, Col-orado, USA.Sara Stymne and Maria Holmqvist.
2008.
Process-ing of Swedish compounds for phrase-based statis-tical machine translation.
In Proceedings of the12th Annual Conference of the European Associa-tion for Machine Translation, pages 180?189, Ham-burg, Germany.Sara Stymne.
2008.
German compounds in factoredstatistical machine translation.
In Proceedings ofGoTAL ?
6th International Conference on NaturalLanguage Processing, pages 464?475, Gothenburg,Sweden.Chao Wang, Michael Collins, and Philipp Koehn.2007.
Chinese syntactic reordering for statisticalmachine translation.
In Proc.
of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, pages 737?745, Prague, Czech Republic.Fei Xia and Michael McCord.
2004.
Improvinga statistical MT system with automatically learnedrewrite patterns.
In Proceedings of the 20th Inter-national Conference on Computational Linguistics,pages 508?514, Geneva, Switzerland.188
