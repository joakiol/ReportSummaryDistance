Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 42?47,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsMachine Learning of Syntactic Attachmentfrom Morphosyntactic and Semantic Co-occurrence StatisticsAdam Slaski and Szymon Acedan?ski and Adam Przepi?rkowskiUniversity of WarsawandInstitute of Computer SciencePolish Academy of SciencesAbstractThe paper presents a novel approach to ex-tracting dependency information in morpho-logically rich languages using co-occurrencestatistics based not only on lexical forms(as in previously described collocation-basedmethods), but also on morphosyntactic andwordnet-derived semantic properties of words.Statistics generated from a corpus annotatedonly at the morphosyntactic level are usedas features in a Machine Learning classifierwhich is able to detect which heads of groupsfound by a shallow parser are likely to be con-nected by an edge in the complete parse tree.The approach reaches the precision of 89%and the recall of 65%, with an extra 6% re-call, if only words present in the wordnet areconsidered.1 IntroductionThe practical issue handled in this paper is how toconnect syntactic groups found by a shallow parserinto a possibly complete syntactic tree, i.e., how tosolve the attachment problem.
To give a well-knownexample from English, the task is to decide whetherin I shot an elephant in my pajamas1, the group inmy pajamas should be attached to an elephant or toshot (or perhaps to I).The standard approach to this problem relies onfinding collocation strengths between syntactic ob-jects, usually between lexical items which are headsof these objects, and resolve attachment ambigui-ties on the basis of such collocation information.1http://www.youtube.com/watch?v=NfN_gcjGoJoThe current work extends this approach in two mainways.
First, we consider a very broad range offeatures: not only lexical, but also lexico-semantic,lexico-grammatical, and grammatical.
Second, andmore importantly, we train classifiers based not onthese features directly, but rather on various associ-ation measures calculated for each of the consideredfeatures.
This way the classifier selects which typesof features are important and which association mea-sures are most informative for any feature type.The proposed method is evaluated on Polish,a language with rich inflection (and relatively freeword order), which exacerbates the usual datasparseness problem in NLP.In this work we assume that input texts are al-ready part-of-speech tagged and chunked, the lat-ter process resulting in the recognition of basic syn-tactic groups.
A syntactic group may, e.g., con-sist of a verb with surrounding adverbs and particlesor a noun with its premodifiers.
We assume that allgroups have a syntactic head and a semantic head.
Inverbal and nominal groups both heads are the sameword, but in prepositional and numeral groups theyusually differ: the preposition and the numeral aresyntactic heads of the respective constituents, whilethe semantic head is the head noun within the nomi-nal group contained in these constituents.To simplify some of the descriptions below, bysyntactic object we will understand either a shallowgroup or a word.
We will also uniformly talk aboutsyntactic and semantic heads of all syntactic objects;in case of words, the word itself is its own syntac-tic and semantic head.
In effect, any syntactic ob-ject may be represented by a pair of words (the two42heads), and each word is characterised by its baseform and its morphosyntactic tag.2 AlgorithmThe standard method of solving the PP-attachmentproblem is based on collocation extraction (cf., e.g.,(Hindle and Rooth, 1993)) and consists of threemain steps: first a training corpus is scanned andfrequencies of co-occurrences of pairs of words(or more general: syntactic objects) are gathered;then the collected data are normalised to obtain, foreach pair, the strength of their connection; finally,information about such collocation strengths is em-ployed to solve PP-attachment in new texts.
An in-stance of the PP-attachment problem is the choicebetween two possible edges in a parse tree: (n1, pp)and (n2, pp), where pp is the prepositional phrase,and n1 and n2 are nodes in the tree (possible attach-ment sites).
This is solved by choosing the edge withthe node that has a stronger connection to the pp.On this approach, collocations (defined as a rela-tion between lexemes that co-occur more often thanwould be expected by chance) are detected by takingpairs of syntactic objects and only considering thelemmata of their semantic heads.
The natural ques-tion is whether this could be generalised to otherproperties of syntactic objects.
In the following, theterm feature will refer to any properties of linguis-tic objects taken into consideration in the processof finding collocation strengths between pairs of ob-jects.2.1 Lexical and Morphosyntactic FeaturesTo start with an example of a generalised colloca-tion, let us consider morphosyntactic valence.
Inorder to extract valence links between two objects,we should consider the lemma of one object (po-tential predicate) and the morphosyntactic tag, in-cluding the value of case, etc., of the other (potentialargument).
This differs from standard (lexical) col-location, where the same properties of both objectsare considered, namely, their lemmata.Formally, we define a feature f to be a pairof functions lf : so ?
Lf and rf : so ?
Rf , whereso stands for the set of syntactic objects and Lf , Rfare the investigated properties.
For example, to learndependencies between verbs and case values of theirobjects, we can take lf (w) = base(semhead(w))(the lemma of the semantic head of w) and rf (w) =case(synhead(w)) (the case value of the syntactichead of w).
On the other hand, in order to obtain theusual collocations, it is sufficient to take both func-tions as mapping a syntactic object to a base formof its semantic head.What features should be considered in the taskof finding dependencies between syntactic objects?The two features mentioned above, aimed at findinglexical collocations and valence relations, are obvi-ously useful.
However, in a morphologically richlanguage, like Polish, taking the full morphosyntac-tic tag as the value of a feature function leads tothe data sparsity problem.
Clearly, the most im-portant valence information a tag may contribute ispart of speech and grammatical case.
Hence, wedefine the second function in the ?valence?
featuremore precisely to be the base form and grammati-cal case (if any), if the syntactic object is a preposi-tion, or part of speech and grammatical case (if any),otherwise.
For example, consider the sentence Whocares for the carers?
and assume that it has alreadybeen split into basic syntactic objects in the follow-ing way: [Who] [cares] [for the carers] [?].
The syn-tactic head of the third object is for and the lemma ofthe semantic head is CARER.
So, the valence featurefor the pair care and for the carers (both defined be-low via their syntactic and semantic heads) will give:lval (?CARE:verb, 3s; CARE:verb, 3s?)
= CARErval (?FOR:prep, obj; CARER:noun, pl?)
= ?FOR, obj?,where 3s stands for the ?3rd person singular?
prop-erty of verbs and obj stands for the objective case inEnglish.Additionally, 7 morphosyntactic features are de-fined by projecting both syntactic objects onto any(but the same of the two objects) combinationof grammatical case, gender and number.
For exam-ple one of those features is defined in the followingway:lf (w) = rf (w) == ?case(synhead(w)), gender(synhead(w))?.Another feature relates the two objects?
syntacticheads, by looking at the part of speech of the firstone and the case of the other one.
The final feature43records information about syntactic (number, gen-der, case) agreement between the objects.2.2 Lexico-Semantic FeaturesObviously, the semantics of syntactic objects is im-portant in deciding which two objects are directlyconnected in a syntactic tree.
To this end, we utilisea wordnet.Ideally, we would like to represent a syntactic ob-ject via its semantic class.
In wordnets, semanticclasses are approximated by synsets (synonym sets)which are ordered by the hyperonymy relation.
Wecould represent a syntactic object by its directly cor-responding synset, but in terms of generalisation thiswould hardly be an improvement over representingsuch an object by its semantic head.
In most caseswe need to represent the object by a hypernym ofits synset.
But how far up should we go along thehypernymy path to find a synset of the right granu-larity?
This is a difficult problem, so we leave it tothe classifier.
Instead, lexico-semantic features aredefined in such a way that, for a given lexeme, all itshypernyms are counted as observations.After some experimentation, three features basedon this idea are defined:1. lf (w) = base(semhead(w))rf (w) = sset(w)(for all sset(w) ?
hypernyms(w)),2. lf (w) = base(semhead(w))rf (w) = ?sset(w), case(synhead(w))?
(for all sset(w) ?
hypernyms(w)),3. lf (w) = sset(w)rf (w) = sset(w)In the last feature, where both objects are repre-sented by synsets, only those minimally general hy-pernyms of the two objects are considered that co-occur in the training corpus more than T (thresh-old) times.
In the experiments described below,performed on a 1-million-word training corpus, thethreshold was set to 30.2.3 Association MeasuresFor any two syntactic objects in the same sentencethe strength of association is computed betweenthem using each of the 14 features (standard col-locations, 10 morphosyntactic features, 3 lexico-semantic features) defined above.
In fact, we usenot 1 but 6 association measures most suitable forlanguage analysis according to (Seretan, 2011): loglikehood ratio, chi-squared, t-score, z-score, point-wise mutual information and raw frequency.
Thelast choice may seem disputable, but as was shownin (Krenn and Evert, 2001) (and reported in vari-ous works on valence acquisition), in some casesraw frequency behaves better than more sophisti-cated measures.We are well aware that some of the employedmeasures require the distribution of frequencies tomeet certain conditions that are not necessarily ful-filled in the present case.
However, as explained inthe following subsection, the decision which mea-sures should ultimately be taken into account is leftto a classifier.2.4 ClassifiersLet us first note that no treebank is needed forcomputing the features and measures presented inthe previous section.
These measures represent co-occurrence strengths of syntactic objects based ondifferent grouping strategies (by lemma, by partof speech, by case, gender, number, by wordnetsynsets, etc.).
Any large, morphosyntactically an-notated (and perhaps chunked) corpus is suitable forcomputing such features.
A treebank is only neededto train a classifier which uses such measures as in-put signals.2In order to apply Machine Learning classifiers,one must formally define what counts as an instanceof the classification problem.
In the current case, foreach pair of syntactic objects in a sentence, a singleinstance is generated with the following signals:?
absolute distance (in terms of the number ofsytnactic objects in between),?
ordering (the sign of the distance),?
6 measures (see ?
2.3) of lexical collocation,?
10 ?
6 = 60 values of morphosyntactic co-occurrence measures,?
3?
6 = 18 values of lexico-semantic (wordnet-based) co-occurrence measures,?
a single binary signal based on 14 high-precision low-recall handwritten syntactic de-2We use the term signal instead of the more usual feature inorder to avoid confusion with features defined in ?
2.1 and in?
2.2.44cision rules which define common grammati-cal patterns like verb-subject agreement, geni-tive construction, etc.
; the rules look only at themorphosyntactic tags of the heads of syntacticobjects,?
the classification target from the treebank: a bi-nary signal describing whether the given pair ofsyntactic objects form an edge in the parse tree.The last signal is used for training the classifier andthen for evaluation.
Note that lexical forms of thecompared syntactic objects or their heads are notpassed to the classifier, so the size of the trainingtreebank can be kept relatively small.An inherent problem that needs to be addressedis the imbalance between the sizes of two classifi-cation categories.
Of course, most of the pairs ofthe syntactic objects do not form an edge in theparse tree, so a relatively high classification accu-racy may be achieved by the trivial classifier whichfinds no edges at all.
We experimented with variouswell-known classifiers, such as decision trees, Sup-port Vector Machines and clustering algorithms, andalso tried subsampling3 of the imbalanced data.
Fi-nally, satisfactory results were achieved by employ-ing a Balanced Random Forest classifier.Random Forest (Breiman, 2001) is a set of un-pruned C4.5 (Quinlan, 1993) decision trees.
Whenbuilding a single tree in the set, only a random subsetof all attributes is considered at each node and thebest is selected for splitting the data set.
BalancedRandom Forest (BRF, (Chen et al, 2004)) is a mod-ified version of the Random Forest.
A single treeof BRF is built by first randomly subsampling themore frequent instances in the training set to matchthe number of less frequent ones and then creatinga decision tree from this reduced data set.3 Experiments and EvaluationThe approach presented above has been evaluated onPolish.First, a manually annotated 1-million-wordsubcorpus of the National Corpus of Polish(Przepi?rkowski et al, 2010), specifically, its mor-phosyntactic and shallow syntactic annotation, was3Removing enough negative instances in the training set tobalance the numbers of instances representing both classes.used to compute the co-occurrence statistics.
Thewordnet used for lexico-semantic measures wasS?owosiec?
(Piasecki et al, 2009; Maziarz et al,2012), the largest Polish wordnet.Then a random subset of sentences from this cor-pus was shallow-parsed by Spejd (Buczyn?ski andPrzepi?rkowski, 2009) and given to linguists, whoadded annotation for the dependency links betweensyntactic objects.
Each sentence was processed bytwo linguists, and in case of any discrepancy, thesentence was simply rejected.
The final corpus con-tains 963 sentences comprising over 8000 tokens.From this data we obtained over 23 500 classi-fication problem instances.
Then we performedthe classification using a BRF classifier written forWeka (Witten and Frank, 2005) as part of the re-search work on definition extraction with BRFs(Kobylin?ski and Przepi?rkowski, 2008).
The re-sults were 10-fold cross-validated.
A similar exper-iment was performed taking into account only thoseinstances which describe syntactic objects with se-mantic heads present in the wordnet.
The resultswere measured in terms of precision and recall overedges in the syntactic tree: what percentage of foundedges are correct (precision) and what percentage ofcorrect edges were found by the algorithm (recall).The obtained measures are presented in Table 1.ExpectedYES NO Classified2674 319 YES1781 21250 NOPrecision: 0.89Recall: 0.60F-measure: 0.72ExpectedYES NO Classified1933 241 YES1008 13041 NOPrecision: 0.89Recall: 0.66F-measure: 0.76Table 1: Confusion matrix (# of instances) and measuresfor the full data set and for data present in wordnet.45We also looked at the actual decision trees thatwere generated during the training.
We note thatthe signal most frequently observed near the tops ofdecision trees was the one from handwritten rules.The second one was the distance.
By looking atthe trees, we could not see any clear preferences forother types of signals.
This suggests that both mor-phosyntactic and lexico-semantic signals contributeto the accuracy of the classification.Based on this inspection of decision trees, we per-formed another experiment to learn how much im-provement we get from generalised collocation sig-nals.
We evaluated ?
on the same data ?
a not sotrivial baseline algorithm which, for each syntacticobject, creates an edge to its nearest neighbour ac-cepted by the handwritten rules, if any.
Note thatthis baseline builds on the fact that a node in a parsetree has at most one parent, whereas the algorithmdescribed above does not encode this property, yet;clearly, there is still some room for improvement.The baseline reaches 0.78 precision and 0.47 recall(F-measure is 0.59).
Therefore, the improvementfrom co-occurrence signals over this strong baselineis 0.13, which is rather high.
Also, given the highprecision, our algorithm may be suitable for usingin a cascade of classifiers.4 Related WorkThere is a plethora of relevant work on resolving PP-attachment ambiguities in particular and finding de-pendency links in general, and we cannot hope to doit sufficient justice here.One line of work, exemplified by the early influ-ential paper (Hindle and Rooth, 1993), posits theproblem of PP-attachment as the problem of choos-ing between a verb v and a noun n1 when attachinga prepositional phrase defined by the syntactic headp and the semantic head n2.
Early work, including(Hindle and Rooth, 1993), concentrated on lexicalassociations, later also using wordnet information,e.g., (Clark and Weir, 2000), in a way similar tothat described above.
Let us note that this scenariowas criticised as unrealistic by (Atterer and Sch?tze,2007), who argue that ?PP attachment should notbe evaluated in isolation, but instead as an integralcomponent of a parsing system, without using in-formation from the gold-standard oracle?, as in theapproach proposed here.Another rich thread of relevant research is con-cerned with valence acquisition, where shallowparsing and association measures based on mor-phosyntactic features are often used at the stageof collecting evidence, (Manning, 1993; Korhonen,2002), also in work on Polish, (Przepi?rkowski,2009).
However, the aim in this task is the construc-tion of a valence dictionary, rather than disambigua-tion of attachment possibilities in a corpus.A task more related to the current one is presentedin (Van Asch and Daelemans, 2009), where a PP-attacher operates on top of a shallow parser.
How-ever, this memory-based module is fully trained ona treebank (Penn Treebank, in this case) and is con-cerned only with finding anchors for PPs, rather thanwith linking any dependents to their heads.Finally, much work has been devoted during thelast decade to probabilistic dependency parsing (see(K?bler et al, 2009) for a good overview).
Clas-sifiers deciding whether ?
at any stage of depen-dency parsing ?
to perform shift or reduce typicallyrely on lexical and morphosyntactic, but not lexico-semantic information (Nivre, 2006).
Again, suchclassifiers are fully trained on a treebank (convertedto parser configurations).5 ConclusionTreebanks are very expensive, morphosyntacticallyannotated corpora are relatively cheap.
The maincontribution of the current paper is a novel approachto factoring out syntactic training in the processof learning of syntactic attachment.
All the fine-grained lexical training data were collected froma relatively large morphosyntactically annotated andchunked corpus, and only less than 100 signals (al-though many of them continuous) were used fortraining the final classifier on a treebank.
The ad-vantage of this approach is that reasonable resultscan be achieved on the basis of tiny treebanks (here,less than 1000 sentences).We are not aware of work fully analogous to ours,either for Polish or for other languages, so we cannotfully compare our results to the state of the art.
Thecomparison with a strong baseline algorithm whichuses handwritten rules shows a significant improve-ment ?
over 0.13 in terms of F-measure.46AcknowledgmentsThis research is supported by the POIG.01.01.02-14-013/09 project which is co-financed by the Eu-ropean Union under the European Regional Devel-opment Fund.ReferencesMichaela Atterer and Hinrich Sch?tze.
2007.
Preposi-tional phrase attachment without oracles.
Computa-tional Linguistics, 33(4):469?476.Leo Breiman.
2001.
Random forests.
Machine Learn-ing, 45:5?32.Aleksander Buczyn?ski and Adam Przepi?rkowski.
2009.Spejd: A shallow processing and morphological dis-ambiguation tool.
In Zygmunt Vetulani and HansUszkoreit, editors, Human Language Technology:Challenges of the Information Society, volume 5603of Lecture Notes in Artificial Intelligence, pages 131?141.
Springer-Verlag, Berlin.Chao Chen, Andy Liaw, and Leo Breiman.
2004.
Us-ing random forest to learn imbalanced data.
TechnicalReport 666, University of California, Berkeley.Stephen Clark and David Weir.
2000.
A class-basedprobabilistic approach to structural disambiguation.
InIn Proceedings of the 18th International Conferenceon Computational Linguistics, pages 194?200.Donald Hindle and Mats Rooth.
1993.
Structural ambi-guity and lexical relations.
Computational Linguistics,19(1):103?120.
?ukasz Kobylin?ski and Adam Przepi?rkowski.
2008.Definition extraction with balanced random forests.In Bengt Nordstr?m and Aarne Ranta, editors, Ad-vances in Natural Language Processing: GoTAL 2008,Gothenburg, Sweden, volume 5221 of Lecture Notesin Artificial Intelligence, pages 237?247, Berlin.Springer-Verlag.Anna Korhonen.
2002.
Subcategorization Acquisition.PhD Thesis, University of Cambridge.Brigitte Krenn and Stefan Evert.
2001.
Can we do betterthan frequency?
A case study on extracting PP-verbcollocations.
In Proceedings of the ACL Workshop onCollocations, Toulouse, France.Sandra K?bler, Ryan McDonald, and Joakim Nivre.2009.
Dependency Parsing.
Morgan & Claypool.Christopher D. Manning.
1993.
Automatic acquisition ofa large subcategorization dictionary from corpora.
InProceedings of the 31st Annual Meeting of the Associ-ation for Computational Linguistics, pages 235?242,Columbus, OH.Marek Maziarz, Maciej Piasecki, and Stanis?aw Sz-pakowicz.
2012.
Approaching plWordNet 2.0.
InProceedings of the 6th Global Wordnet Conference,Matsue, Japan.Joakim Nivre.
2006.
Inductive Dependency Parsing.Springer-Verlag, Berlin.Maciej Piasecki, Stanis?aw Szpakowicz, and BartoszBroda.
2009.
A Wordnet from the GroundUp.
Oficyna Wydawnicza Politechniki Wroclawskiej,Wroc?aw.Adam Przepi?rkowski, Rafa?
L. G?rski, Marek ?azin?ski,and Piotr Pe?zik.
2010.
Recent developments in theNational Corpus of Polish.
In Proceedings of the Sev-enth International Conference on Language Resourcesand Evaluation, LREC 2010, Valletta, Malta.
ELRA.Adam Przepi?rkowski.
2009.
Towards the automatic ac-quisition of a valence dictionary for Polish.
In Ma?-gorzata Marciniak and Agnieszka Mykowiecka, edi-tors, Aspects of Natural Language Processing, volume5070 of Lecture Notes in Computer Science, pages191?210.
Springer-Verlag, Berlin.John Ross Quinlan.
1993.
C4.5 Programs for MachineLearning.
Morgan Kaufmann.Violeta Seretan.
2011.
Syntax-Based Collocation Ex-traction.
Text, Speech and Language Technology.Springer, Dordrecht.Vincent Van Asch and Walter Daelemans.
2009.
Prepo-sitional phrase attachment in shallow parsing.
InProceedings of the International Conference RANLP-2009, pages 12?17, Borovets, Bulgaria, September.Ian H. Witten and Eibe Frank.
2005.
Data Mining: Prac-tical machine learning tools and techniques.
MorganKaufmann, San Francisco, CA, 2nd edition.47
