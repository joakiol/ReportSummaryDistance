Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 67?70,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsNegotiating causal implicaturesLuciana BenottiUniversidad Nacional de Co?rdobaGrupo PLNCiudad Universitaria5000 Co?rdoba, Argentinaluciana.benotti@gmail.comPatrick BlackburnINRIA Nancy Grand-EstEquipe TALARIS615, rue du Jardin Botanique54602 Villers le`s Nancy, Francepatrick.blackburn@loria.frAbstractIn this paper we motivate and describea dialogue manager which is able to in-fer and negotiate causal implicatures.
Acausal implicature is a type of Gricean re-lation implicature, and the ability to inferthem is crucial in situated dialogue.
Be-cause situated dialogue interleaves conver-sational acts and physical acts, the dia-logue manager needs to have a grasp oncausal implicatures in order not only to de-cide what physical acts to do next but alsoto generate causally-aware clarifications.1 IntroductionIn conversation, an important part of the contentconveyed is not explicitly said, rather it is impli-cated.
However, Grice (1975)?s classic concept ofconversational implicature (CI) is far from fullyunderstood.
Traditionally CIs have been classifiedusing the Gricean maxims: there are relation CIs(also known as relevance CIs), quantity CIs, qual-ity CIs and manner CIs.
In formal pragmatics, themost studied CIs are quantity CIs, probably be-cause they are the ones most obviously amenableto theoretical analysis; see (Geurts, in press) fora survey of the state of the art.
Far less studied(and traditionally regarded as somewhat obscure)are relation CIs.
Obscure perhaps, but crucial: ithas been argued that they subsume all other typesof CIs (Wilson and Sperber, 2004).
This paper is afirst step towards their formalization.We shall analyze a kind of CI that we call causalCIs.
Causal CIs are relation CIs as defined byGrice (1975) where the crucial relation is task do-main causality.
Consider the following example:Mary: The chest is locked, the crown is insideBill: Give me the crownBill causally implicated: Unlock the chestIn order to carry out the task action required byBill (to give him the crown) it is necessary to un-lock the chest.
Hence we say that Bill is implicat-ing, by trading on the domain causal relations (af-ter all, the contents of a chest are not accessible un-less the chest is unlock) that Mary is to unlock thechest.
Now, once Mary has inferred the causal CI,she may accept this inference silently or negotiateit.
Mary might decide to silently accept it becauseshe knows how to get the key; in this case we willsay that Mary constructed an internal bridge fromthe current task situation (that is, the crown beinginside the locked chest) to the proposal made byBill (giving him the crown).
If Mary decides shehas insufficient information to construct the inter-nal bridge (maybe she has no key, or sees that thelock is rusty) she may start a sub-dialogue that wewill call an external bridge; she might say, for ex-ample: But how can I unlock the chest?
The in-ternal process of bridging is what in the literaturehas been called accommodation (Lewis, 1979) orbridging (Clark, 1975).
The external processes ofbridging constitutes a large part of what we callconversation.This paper presents a dialogue system (calledFrolog) which infers and negotiates causal CIs inthe context of situated task-oriented dialogue; theframework is intended as a proof-of-concept of theideas just sketched.
We proceed as follows.
InSection 2, we motivate the study of causal CIs indialogue.
In Section 3 we present Frolog?s dia-logue manager which infers causal CIs in situateddialogue.
And in Section 4 we illustrate how thenegotiation (external bridging) of causal CIs incre-mentally grounds a pragmatic goal proposed byone of the dialogue participants.
Section 5 con-cludes the paper.2 Causal implicatures and dialogueThe motivation for our work is both theoreticaland practical.
On the theoretical side, we believe67that it is crucial to explore CIs in the setting ofnaturally occurring dialogues.
Strangely enough(after all, Grice did call them conversational im-plicatures) this view appears to be novel, perhapseven controversial.
In the formal pragmatics lit-erature, CIs are often simply viewed as inferencesdrawn by a hearer on the basis of a speaker?s ut-terance, contextual information, and the Griceanmaxims.
We find this perspective too static.
CIs(especially relations CIs) are better viewed as in-trinsically interactional inferences that arise fromthe dynamics of conversation.
As conversationsprogress, speakers and hearers switch roles: mean-ing are negotiated and inference becomes bidirec-tional (Thomason et al, 2006).
Moreover, evenwithin a single turn, hearers are not restricted tosimply drawing (or failing to draw) ?the?
CI: infact, choosing between internal and external bridg-ing is better viewed as part of the process of nego-tiating what the CI at stake actually is.
We be-lieve that interactive perspectives will be neces-sary to extend the theory of CIs beyond the rel-atively narrow domain of quantity CIs.
We alsobelieve that the dialog-centered approach we ad-vocate may have practical consequences.
In par-ticular, modeling the external process of bridgingis a step towards having a pragmatically incremen-tal dialogue manager in the spirit of that sketchedin (Bu?
and Schlangen, 2010).This is a broad goal, in this paper we focus onclausal implicatures.
This restriction gives us anempirical handle of CIs.
It is not controversial that(in non-conversational activities) the causal rela-tions between acts define the expectations of theinteraction.
But also in conversational activitiessituated in a physical task causal relations guidethe interaction; we did an empirical study on sucha kind of corpus (Benotti, 2009) and we found that,in this corpus, most CIs for which there is evidence(because they are made explicit in a clarificationrequest) can be explained in terms of causal rela-tions.
For our empirical study, we annotated andclassified the clarification requests (CRs) that ap-pear in the SCARE corpus (Stoia et al, 2008).3 Inferring causal implicaturesIn order to model the causal CIs that we observedin the SCARE corpus, and to experiment with dif-ferent strategies for negotiating these CIs, we de-signed a system that mimics the instruction givingsetup of the SCARE corpus.
In our setup, the DFis a dialogue system that we will call Frolog.
Thehuman participant that plays the role of the DG wewill call ?the player?.In a nutshell, Frolog uses an off-the-shelf plan-ner to compute causal implicatures.
That is, ituses classical planning (a well explored and com-putationally efficient AI technique) to fill out themicro-structure of discourse (the bridging infor-mation required in the next step).1 We do so us-ing the planner BLACKBOX (Kautz and Selman,1999).
Like all classical planners, BLACKBOXtakes three inputs: the initial state, the goal, andthe available actions.
The question of what thesethree elements should be raises a number of issues.In Frolog, two types of information are regis-tered: complete and accurate information aboutthe game world in the world KB and a represen-tation of the common ground in the interactionKB.
Which of these should be used in the initialstate?
In fact, we need both: we infer the actionsintended by the player using the information in theinteraction KB but we have to verify this sequenceof actions on the world KB to check if it can actu-ally be executed.Let us now define what the goal of the planningproblem should be.
Frolog should act to make thepreconditions of the action true with one restric-tion.
The restriction is that it must be possible forFrolog to manipulate these preconditions.
How-ever, we don?t need to worry about this restric-tion because the planner should take care of whichpropositions are manipulable by Frolog and whichare not, given the current state.
So we can just de-fine the goal as the conjunction of all the precon-ditions of the command uttered by the player.To complete the picture, the actions available tothe planner are all the actions in the game actiondatabase.
This means that we are assuming thatall the actions that can be executed, are mutuallyknown to Frolog and the player.In order to be able to perform bridging to themutual information it must be mutually knownwhat the preconditions and the effects of the ac-tions involved are.
The assumption that the playerand Frolog know the exact specification of all theactions that can be executed in the game world is1Thus the work reported here is very different from thetraditional work of (Perrault and Allen, 1980; Allen andAllen, 1994): classic papers in the plan-based tradition useplan recognition (a more computationally expensive task) tointerpret utterances by inserting them into the plan the macro-structure (the global shape) of discourse.68a simplifying assumption.
We make it because itenables us to avoid deciding (and implementing)how differing knowledge about actions get coordi-nated; dealing with such issues simply too difficultat present.4 Negotiating with a dialogue systemIn this section we present a worked out example ofhow the solutions of the planning problems intro-duced in the previous section can be used in orderto perform internal bridging and trigger externalbridging when appropriate.In this example Frolog does not have enoughknowledge yet in order to infer the bridge.2 Thisis the case in instruction (37) in Figure 1.
In thisinstruction the player wants Frolog to open thechest but Frolog does not know how to do this.In the screen-shot in the right you can see state ofthe interaction KB from turns (37) to (39).
In thismodel we can see that the player does not haveinformation about what fits into the chest, in or-der to unlock it.
This is why the planner is notable to find a plan that achieves the precondition(unlocked chest1) of the command ?open thechest?
in instruction (37).
The instruction in (39)fails as well making the obstacle explicit.
Utter-ance (40) is an example of a CR caused by a re-quired and unknown thematic relation filler (thesecond most frequent CR in the SCARE corpus).Player(32): look at the chestFrolog(33): the chest is closed and          locked and woodenPlayer(34): look at FrologFrolog(35): Frolog is aliveFrolog(36): Frolog holds the sword, the worm                   and the golden keyPlayer(37): open the chestFrolog(38): Frolog can't do that!
the chest is not unlockedPlayer(39): unlock the chestFrolog(40): Frolog can't do that!
Frolog doesn't know what fits into the chestPlayer(41): unlock the chest with the golden keyFrolog(42): [Frolog unlocks the chest] Frolog(43): the chest is unlockedPlayer(44): lock the chest with the keyFrolog(45): [Frolog locks the chest] Frolog(46): the chest is lockedPlayer(47): open the chestFrolog(48): Frolog can't do that!
the chest is not unlocked fitsin?????
?Figure 1: External bridging in FrologFrolog?s behavior continues as expected untilturn (48) in which Frolog again is not able tobridge the command open the chest.
It is to beexpected that the fact that the golden key fits into2For illustrations of other reasons that trigger negotiationof CIs see (Benotti, 2010).the chest is mutual knowledge by now but Frologis not reacting accordingly.In order to overcome this issue there are twooptions: (1) either we allow different sources toupdate the mutual information loosing uniformityin the update process or (2) we add actions thatmanipulate this kind of information.
Here we de-scribe option (1) that turns out to be the proce-dural version of ?strict accommodation?
(as de-fined in (Beaver and Geurts, in press)), and whengeneralized is of a piece with abduction (Hobbs,1985).
For an discussion of (2) we refer the readerto (Benotti, 2010).We could say that the intuition behind the strictnotion of accommodation is that when the speakerutters a sentence, she is not only trying to achievethe obvious effects of the utterance, but is alsocommunicating the ways in which she assumes theworld to be, and on which the success of the utter-ance depends.
Following this intuition it can beargued that the intention behind the utterance ?un-lock the chest with the golden key?
in turn (41) istwofold.
It is clear that the player wants to achievethe effects of the action, that is, she wants to havethe chest unlocked.
But the player also expectsFrolog to recognize the assumptions she is makingand on which the success of the utterance depends.In particular, she expects Frolog to recognize thatshe is assuming that the golden key fits into thechest lock (this is why Frolog can coherently askwhy do you think that the golden key will fit?
).This means that, when an action is executed, theinteraction KB will be updated not only with theeffects of the action but also with its preconditions.And those preconditions that were not in the inter-action KB before will be verbalized as in turn (9)in Figure 2.Player(32): olkth:cse:tse4cFrolog(3): Frolog thecs io sdhsa :::::::::::::::Frklkg:7ke4opc:hokn::::::::::::::::nsac:iuc4duock:cse:tse4cPlayer(92):lkkh:ac:yk Frolog(n): kow hr5 hlv65Frolog(,): kow doli h goli5e m5kPlayer('2): olkth:cse:tse4c:nucs:cse:gkl7eo:heyFrolog(y): 8Frolog welotm' sd5 td5's                 !vsd sd5 goli5e m5k4Frolog(0): sd5 td5's v' welotm5iFrolog(2): cse:hey:iuc4duock:cse:tse4cPlayer(3w2):lkth:cse:tse4cFrolog([[): 8Frolog lotm' sd5 td5's :::::::::::::::::!vsd sd5 goli5e m5k4Frolog([3): sd5 td5's v' lotm5iPlayer(392):lkkh:ac:cse:tse4cFrolog([n): sd5 td5's v' tlo'5i hei          lotm5i hei !ooi5ePlayer(3f2):k1eo:cse:tse4cFrolog([u): 8Frolog welotm' sd5 td5's !vsd sd5 goli5e m5k4Frolog([y): sd5 td5's v' welotm5iFrolog([0): 8Frolog o]5e' sd5 td5's4Frolog([2): sd5 td5's v' o]5eFrolog(3?
): sd5 td5's doli h goli5e tro!e:action?open?:arguments??????(agent??w)?(theme??x)???:precondition?????????(accessible??x)?????????(closed??x)?????????(unlocked??x)?:effect?????????(not(closed??x))?????????(open??x):action?unlock?:arguments??????(agent??w)?(theme??x)?(inst??y)??:precondition?????????(accessible??x)?????????(locked??x)?????????(fitsin??y??x)?????????(hold??w??y)????:effect?????????(not(locked??x))?????????(unlocked??x)????????
?Figure 2: External bridging becomes internal69The rest of the interaction (from turns (10)to (15)) show that once the proposition (fitsinkey1 chest1) is added to the interaction KB theaction ?open the chest?
can be internally bridgedeven when the chest is locked.
Because the playerand Frolog mutually know which key fits into thechest.5 DiscussionClearly, our inference framework is limited inmany ways.
But we think we?ve made a smallstep in the right direction.
Dialogue systems arereaching a development level in which they cannotelude drawing inferences for much longer.
Thispaper is a step in this direction.Causal implicatures are a kind of relationimplicature (historically Grice?s most obscureand crucial implicature) whose inference?we?veargued?is essential in situated dialogue if our di-alogue systems are not to violate the expectationsof the user.
Causal relations have a direct impacton the coherence structure of situated dialoguessuch as those in the SCARE corpus; in the SCAREcorpus most pragmatic clarification requests makeexplicit causal implicatures.We need to have a grasp on causal impli-catures in order for our dialogue systems notonly to decide what physical acts to do next?internal bridging?but also to generate causally-aware clarification requests?external bridging.Of course the inference framework presented herehas many limitations that we discussed through-out the paper and probably classical planning isnot the formalism that we will finally want to usein our dialogue systems (at least not in its presentform).
Our model is intended as a proof of con-cept, and intentionally stays at a level of formal-ization that is still simple enough so as not to looseour intuitions.
The two intuitions that we don?twant to loose sight of are (1) utterances are to beinterpreted in a context and need to be connectedto this context (through some kind of relation, be-ing causality one of the most important ones insituated dialogue) in order to be grounded (2) theprocess of connecting utterances to the context isa joint process, it is a negotiation that involves de-cisions of all the dialogue participants.With the intuitions in place we plan to extendthis work mainly by porting the inference frame-work into new domains.There is lot to do yet, but we believe that thenegotiation of causal implicatures is a step towardsan incremental dialogue manager.ReferencesJames Allen and Richard Allen.
1994.
Natural lan-guage understanding.
Addison Wesley, 2nd edition.David Beaver and Bart Geurts.
in press.
Presup-position.
In Handbook of Semantics.
Mouton deGruyter.Luciana Benotti.
2009.
Clarification potential of in-structions.
In Proc.
of SIGDIAL, pages 196?205,London, United Kingdom.Luciana Benotti.
2010.
Implicature as an InteractiveProcess.
Ph.D. thesis, Universite?
Henri Poincare?,INRIA Nancy Grand Est, France.
Supervised byP.
Blackburn.
Reviewed by N. Asher and B. Geurts.Okko Bu?
and David Schlangen.
2010.
Modellingsub-utterance phenomena in spoken dialogue sys-tems.
In The 2010 Workshop on the Semantics andPragmatics of Dialogue, Poznan?, Poland.Herbert Clark.
1975.
Bridging.
In Proc.
of the Work-shop on Theoretical issues in natural language pro-cessing, pages 169?174, Morristown, USA.
ACL.Bart Geurts.
in press.
Quantity implicatures.
Cam-bridge University Press.Paul Grice.
1975.
Logic and conversation.
In P. Coleand J. Morgan, editors, Syntax and Semantics, vol-ume 3, pages 41?58.
Academic Press, New York.Jerry Hobbs.
1985.
Granularity.
In Proceedings ofthe 9th International Joint Conference on ArtificialIntelligence, pages 432?435.
Morgan Kaufmann.Henry Kautz and Bart Selman.
1999.
Unifying SAT-based and graph-based planning.
In Proceedings ofthe 16th International Joint Conference on ArtificialIntelligence, pages 318?325, Stockholm, Sweden.David Lewis.
1979.
Scorekeeping in a language game.Journal of Philosophical Logic, 8:339?359.Raymond Perrault and James Allen.
1980.
A plan-based analysis of indirect speech acts.
Computa-tional Linguistics, 6(3-4):167?182.Laura Stoia, Darla Shockley, Donna Byron, and EricFosler-Lussier.
2008.
SCARE: A situated corpuswith annotated referring expressions.
In Proc.
ofLREC.Richmond Thomason, Matthew Stone, and David De-Vault.
2006.
Enlightened update: A computa-tional architecture for presupposition and other prag-matic phenomena.
In Presupposition Accommoda-tion.
Ohio State Pragmatics Initiative.Deirdre Wilson and Dan Sperber.
2004.
Relevancetheory.
In Handbook of Pragmatics, pages 607?632.Blackwell, Oxford.70
