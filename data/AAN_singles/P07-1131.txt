Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1040?1047,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsExtracting Social Networks and Biographical Facts From ConversationalSpeech TranscriptsHongyan JingIBM T.J. Watson Research Center1101 Kitchawan RoadYorktown Heights, NY 10598hjing@us.ibm.comNanda KambhatlaIBM India Research LabEGL, Domlur Ring RoadBangalore - 560071, Indiakambhatla@in.ibm.comSalim RoukosIBM T.J. Watson Research Center1101 Kitchawan RoadYorktown Heights, NY 10598roukos@us.ibm.comAbstractWe present a general framework forautomatically extracting social networksand biographical facts from conversationalspeech.
Our approach relies on fusingthe output produced by multiple informa-tion extraction modules, including entityrecognition and detection, relation detec-tion, and event detection modules.
Wedescribe the specific features and algo-rithmic refinements effective for conver-sational speech.
These cumulatively in-crease the performance of social networkextraction from 0.06 to 0.30 for the devel-opment set, and from 0.06 to 0.28 for thetest set, as measured by f-measure on theties within a network.
The same frame-work can be applied to other genres of text?
we have built an automatic biographygeneration system for general domain textusing the same approach.1 IntroductionA social network represents social relationshipsbetween individuals or organizations.
It consistsof nodes and ties.
Nodes are individual actorswithin the networks, generally a person or an or-ganization.
Ties are the relationships between thenodes.
Social network analysis has become a keytechnique in many disciplines, including modernsociology and information science.In this paper, we present our system for au-tomatically extracting social networks and bio-graphical facts from conversational speech tran-scripts by integrating the output of different IEmodules.
The IE modules are the building blocks;the fusing module depicts the ways of assemblingthese building blocks.
The final output depends onwhich fundamental IE modules are used and howtheir results are integrated.The contributions of this work are two fold.
Wepropose a general framework for extracting socialnetworks and biographies from text that applies toconversational speech as well as other genres, in-cluding general newswire stories.
Secondly, wepresent specific methods that proved effective forus for improving the performance of IE systems onconversational speech transcripts.
These improve-ments include feature engineering and algorithmicrevisions that led to a nearly five-fold performanceincrease for both development and test sets.In the next section, we present our frameworkfor extracting social networks and other biograph-ical facts from text.
In Section 3, we discuss therefinements we made to our IE modules in orderto reliably extract information from conversationalspeech transcripts.
In Section 4, we describe theexperiments, evaluation metrics, and the results ofsocial network and biography extraction.
In Sec-tion 5, we show the results of applying the frame-work to other genres of text.
Finally, we discussrelated work and conclude with lessons learnedand future work.2 The General FrameworkFor extraction of social networks and biographi-cal facts, our approach relies on three standard IEmodules ?
entity detection and recognition, rela-tion detection, and event detection ?
and a fusionmodule that integrates the output from the three IEsystems.2.1 Entity, Relation, and Event DetectionWe use the term entity to refer to a person, an or-ganization, or other real world entities, as adopted1040in the Automatic Content Extraction (ACE) Work-shops (ACE, 2005).
A mention is a reference toa real world entity.
It can be named (e.g.
?JohnLennon?
), nominal (e.g.
?mother?
), or pronomi-nal (e.g.
?she?
).Entity detection is generally accomplished intwo steps: first, a mention detection module iden-tifies all the mentions of interest; second, a co-reference module merges mentions that refer to thesame entity into a single co-reference chain.A relation detection system identifies (typi-cally) binary relationships between pairs of men-tions.
For instance, for the sentence ?I?m in NewYork?, the following relation exists: locatedAt (I,New York).An event detection system identifies events ofinterest and the arguments of the event.
For ex-ample, from the sentence ?John married Eva in1940?, the system should identify the marriageevent, the people who got married and the timeof the event.The latest ACE evaluations involve all of theabove tasks.
However, as shown in the next sec-tion, our focus is quite different from ACE ?we are particularly interested in improving perfor-mance for conversational speech and building ontop of ACE tasks to produce social networks andbiographies.2.2 Fusion ModuleThe fusion module merges the output from IEmodules to extract social networks and biographi-cal facts.
For example, if a relation detection sys-tem has identified the relation motherOf (mother,my) from the input sentence ?my mother is acook?, and if an entity recognition module hasgenerated entities referenced by the mentions {my,Josh, me, I, I, ......} and {mother, she, her, her,Rosa......}, then by replacing my and mother withthe named mentions within the same co-referencechains, the fusion module produces the follow-ing nodes and ties in a social network: motherOf(Rosa, Josh).We generate the nodes of social networks by se-lecting all the PERSON entities produced by theentity recognition system.
Typically, we only in-clude entities that contain at least one named men-tion.
To identify ties between nodes, we retrieveall relations that indicate social relationships be-tween a pair of nodes in the network.We extract biographical profiles by selecting theevents (extracted by the event extraction module)and corresponding relations (extracted by the rela-tion extraction module) that involve a given indi-vidual as an argument.
When multiple documentsare used, then we employ a cross-document co-reference system.3 Improving Performance forConversational Speech TranscriptsExtracting information from conversationalspeech transcripts is uniquely challenging.
In thissection, we describe the data collection used inour experiments, and explain specific techniqueswe used to improve IE performance on this data.3.1 Conversational Speech CollectionWe use a corpus of videotaped, digitized oral in-terviews with Holocaust survivors in our experi-ments.
This data was collected by the USC ShoahFoundation Institute (formerly known as the Vi-sual History Foundation), and has been used inmany research activities under the MultilingualAccess to Large Spoken Archives (MALACH)project (Gustman et al, 2002; Oard et al, 2004).The collection contains oral interviews in 32 lan-guages from 52,000 survivors, liberators, rescuersand witnesses of the Holocaust.This data is very challenging.
Besides the usualcharacteristics of conversational speech, such asspeaker turns and speech repairs, the interviewtranscripts contain a large percentage of ungram-matical, incoherent, or even incomprehensibleclauses (a sample interview segment is shown inFigure 1).
In addition, each interview covers manypeople and places over a long time period, whichmakes it even more difficult to extract social net-works and biographical facts.speaker2 in on that ninth of Novem-ber nineteen hundred thirty eight I waswith my parents at home we heardnot through the we heard even throughthe windows the crashing of glass thecrashing of and and they are our can?tFigure 1: Sample interview segment.3.2 The Importance of Co-referenceResolutionOur initial attempts at social network extractionfor the above data set resulted in a very poor score1041of 0.06 f-measure for finding the relations withina network (as shown in Table 3 as baseline perfor-mance).An error analysis indicated poor co-referenceresolution to be the chief culprit for the low per-formance.
For instance, suppose we have twoclauses: ?his mother?s name is Mary?
and ?hisbrother Mark went to the army?.
Further sup-pose that ?his?
in the first clause refers to aperson named ?John?
and ?his?
in the secondclause refers to a person named ?Tim?.
If theco-reference system works perfectly, the systemshould find a social network involving four peo-ple: {John, Tim, Mary, Mark}, and the ties: moth-erOf (Mary, John), and brotherOf (Mark, Tim).However, if the co-reference system mistakenlylinks ?John?
to ?his?
in the second clause and links?Tim?
to ?his?
in the first clause, then we will stillhave a network with four people, but the ties willbe: motherOf (Mary, Tim), and brotherOf (Mark,John), which are completely wrong.
This exampleshows that co-reference errors involving mentionsthat are relation arguments can lead to very badperformance in social network extraction.Our existing co-reference module is a state-of-the-art system that produces very competitive re-sults compared to other existing systems (Luo etal., 2004).
It traverses the document from left toright and uses a mention-synchronous approach todecide whether a mention should be merged withan existing entity or start a new entity.However, our existing system has shortcomingsfor this data: the system lacks features for han-dling conversational speech, and the system of-ten makes mistakes in pronoun resolution.
Re-solving pronominal references is very importantfor extracting social networks from conversationalspeech, as illustrated in the previous example.3.3 Improving Co-reference forConversational SpeechWe developed a new co-reference resolution sys-tem for conversational speech transcripts.
Simi-lar to many previous works on co-reference (Ng,2005), we cast the problem as a classification taskand solve it in two steps: (1) train a classifier todetermine whether two mentions are co-referent ornot, and (2) use a clustering algorithm to partitionthe mentions into clusters, based on the pairwisepredictions.We added many features to our model specifi-cally designed for conversational speech, and sig-nificantly improved the agglomerative clusteringused for co-reference, including integrating rela-tions as constraints, and designing better clusterlinkage methods and clustering stopping criteria.3.3.1 Adding Features for ConversationalSpeechWe added many features to our model specifi-cally designed for conversational speech:Speaker role identification.
In manual tran-scripts, the speaker turns are given and eachspeaker is labeled differently (e.g.
?speaker1?,?speaker2?
), but the identity of the speaker is notgiven.
An interview typically involves 2 or morespeakers and it is useful to identify the roles ofeach speaker (e.g.
interviewer, interviewee, etc.
).For instance, ?you?
spoken by the interviewer islikely to be linked with ?I?
spoken by the inter-viewee, but ?you?
spoken by the third person inthe interview is more likely to be referring to theinterviewer than to the interviewee.We developed a program to identify the speakerroles.
The program classifies the speakers intothree categories: interviewer, interviewee, andothers.
The algorithm relies on three indicators?
number of turns by each speaker, difference innumber of words spoken by each speaker, and theratio of first-person pronouns such as ?I?, ?me?,and ?we?
vs. second-person pronouns such as?you?
and ?your?.
This speaker role identifica-tion program works very well when we checkedthe results on the development and test set ?
theinterviewers and survivors in all the documents inthe development set were correctly identified.Speaker turns.
Using the results from thespeaker role identification program, we enrich cer-tain features with speaker turn information.
Forexample, without this information, the system can-not distinguish ?I?
spoken by an interviewer from?I?
spoken by an interviewee.Spelling features for speech transcripts.
Weadd additional spelling features so that mentionssuch as ?Cyla C Y L A Lewin?
and ?Cyla Lewin?are considered as exact matches.
Names withspelled-out letters occur frequently in our data col-lection.Name Patterns.
We add some features thatcapture frequent syntactic structures that speakersuse to express names, such as ?her name is Irene?,?my cousin Mark?, and ?interviewer Ellen?.Pronoun features.
To improve the perfor-1042mance on pronouns, we add features such as thespeaker turns of the pronouns, whether the twopronouns agree in person and number, whetherthere exist other mentions between them, etc.Other miscellaneous features.
We also in-clude other features such as gender, token dis-tance, sentence distance, and mention distance.We trained a maximum-entropy classifier usingthese features.
For each pair of mentions, the clas-sifier outputs the probability that the two mentionsare co-referent.We also modified existing features to makethem more applicable to conversational speech.For instance, we added pronoun-distance featurestaking into account the presence of other pronom-inal references in between (if so, the types of thepronouns), other mentions in between, etc.3.3.2 Improving Agglomerative ClusteringWe use an agglomerative clustering approachfor partitioning mentions into entities.
This is abottom-up approach which joins the closest pairof clusters (i.e., entities) first.
Initially, each men-tion is placed into its own cluster.
If we have Nmentions to cluster, we start with N clusters.The intuition behind choosing the agglomera-tive method is to merge the most confident pairsfirst, and use the properties of existing clusters toconstrain future clustering.
This seems to be espe-cially important for our data collection, since con-versational speech tends to have a lot of repetitionsor local structures that indicate co-reference.
Insuch cases, it is beneficial to merge these closelyrelated mentions first.Cluster linkage method.
In agglomerativeclustering, each cycle merges two clusters into asingle cluster, thus reducing the number of clus-ters by one.
We need to decide upon a method ofmeasuring the distance between two clusters.At each cycle, the two mentions with the high-est co-referent probability are linked first.
This re-sults in the merging of the two clusters that containthese two mentions.We improve upon this method by imposingmin-imal distance criteria between clusters.
Two clus-ters C1and C2can be combined only if the dis-tance between all the mentions from C1and allthe mentions from C2is above the minimal dis-tance threshold.
For instance, suppose C1={he, father}, and C2= {he, brother}, and ?he?from C1and ?he?
from C2has the highest linkageprobability.
The standard single linkage methodwill combine these two clusters, despite the factthat ?father?
and ?brother?
are very unlikely tobe linked.
Imposing minimal distance criteriacan solve this problem and prevent the linkage ofclusters which contain very dissimilar mentions.In practice, we used multiple minimal distancethresholds, such as minimal distance between twonamed mentions and minimal distance betweentwo nominal mentions.We chose not to use complete or average link-age methods.
In our data collection, the narrationscontain a lot of pronouns and the focus tends tobe very local.
Whereas the similarity model maybe reasonably good at predicting the distance be-tween two pronouns that are close to each other, itis not good at predicting the distance between pro-nouns that are furthur apart.
Therefore, it seemsmore reasonable to use single linkage method withmodifications than complete or average linkagemethods.Using relations to constrain clustering.
An-other novelty of our co-reference system is theuse of relations for constraining co-reference.
Theidea is that two clusters should not be merged ifsuch merging will introduce contradictory rela-tions.
For instance, if we know that person entityA is the mother of person entity B, and person en-tity C is the sister of B, then A and C should notbe linked since the resulting entity will be both themother and the sister of B.We construct co-existent relation sets from thetraining data.
For any two pairs of entities, we col-lect all the types of relations that exist betweenthem.
These types of relations are labeled asco-existent.
For instance, ?motherOf?
and ?par-entOf?
can co-exist, but ?motherOf?
and ?sis-terOf?
cannot.
By using these relation constraints,the system refrains from generating contradictoryrelations in social networks.Speed improvement.
Suppose the number ofmentions is N , the time complexity of simple link-age method is O(N2).
With the minimal dis-tance criteria, the complexity is O(N3).
However,N can be dramatically reduced for conversationaltranscripts by first linking all the first-person pro-nouns by each speaker.4 ExperimentsIn this section, we describe the experimental setupand present sample outputs and evaluation results.1043Train Dev TestWords 198k 73k 255kMentions 43k 16k 56kRelations 7K 3k 8kTable 2: Experimental Data Sets.4.1 Data AnnotationThe data used in our experiments consist of partialor complete English interviews of Holocaust sur-vivors.
The input to our system is transcripts ofinterviews.We manually annotated manual transcripts withentities, relations, and event categories, specifi-cally designed for this task and the results of care-ful data analysis.
The annotation was performedby a single annotator over a few months.
The an-notation categories for entities, events, and rela-tions are shown in Table 1.
Please note that theevent and relation definitions are slightly differentthan the definitions in ACE.4.2 Training and Test SetsWe divided the data into training, development,and test data sets.
Table 2 shows the size of eachdata set.
The training set includes transcripts ofpartial interviews.
The development set consistsof 5 complete interviews, and the test set con-sists of 15 complete interviews.
The reason thatthe training set contains only partial interviews isdue to the high cost of transcription and annota-tion.
Since those partial interviews had alreadybeen transcribed for speech recognition purpose,we decided to reuse them in our annotation.
In ad-dition, we transcribed and annotated 20 completeinterviews (each interview is about 2 hours) forbuilding the development and test sets, in orderto give a more accurate assessment of extractionperformance.4.3 ImplementationWe developed the initial entity detection, rela-tion detection, and event detection systems usingthe same techniques as our submission systems toACE (Florian et al, 2004).
Our submission sys-tems use statistical approaches, and have rankedin the top tier in ACE evaluations.
We easily builtthe models for our application by retraining exist-ing systems with our training set.The entity detection task is accomplished in twosteps: mention detection and co-reference resolu-tion.
The mention detection is formulated as a la-Figure 2: Social network extracted by the system.beling problem, and a maximum-entropy classifieris trained to identify all the mentions.Similarly, relation detection is also cast as aclassification problem ?
for each pair of men-tions, the system decides which type of relationexists between them.
It uses a maximum-entropyclassifier and various lexical, contextual, and syn-tactic features for such predications.Event detection is accomplished in two steps:first, identifying the event anchor words using anapproach similar to mention detection; then, iden-tifying event arguments using an approach similarto relation detection.The co-reference resolution system for conver-sational speech and the fusion module were devel-oped anew.4.4 The OutputThe system aims to extract the following types ofinformation:?
The social network of the survivor.?
Important biographical facts about each per-son in the social network.?
Track the movements of the survivor andother individuals in the social network.Figure 2 shows a sample social network ex-tracted by the system (only partial of the networkis shown).
Figure 3 shows sample biographicalfacts and movement summaries extracted by thesystem.
In general, we focus more on higher pre-cision than recall.4.5 EvaluationIn this paper, we focus only on the evaluationof social network extraction.
We first describethe metrics for social network evaluation and thenpresent the results of the system.1044Entity (12) Event (8) Relation (34)Social Rels (12) Event Args (8) Bio Facts (14)AGE CUSTODY aidgiverOf affectedBy bornAtCOUNTRY DEATH auntOf agentOf bornOnDATE HIDING cousinOf participantIn citizenOfDATEREF LIBERATION fatherOf timeOf diedAtDURATION MARRIAGE friendOf travelArranger diedOnGHETTOORCAMP MIGRATION grandparentOf travelFrom employeeOfOCCUPATION SURVIVAL motherOf travelPerson hasPropertyORGANIZATION VIOLENCE otherRelativeOf travelTo locatedAtOTHERLOC parentOf managerOfPEOPLE siblingOf memberOfPERSON spouseOf nearSALUTATION uncleOf partOfpartOfManyresideInTable 1: Annotation Categories for Entities, Events, and Relations.Sidonia Lax:date of birth: June the eighth nineteen twentysevenMovements:Moved To: AuschwitzMoved To: United States...
...Figure 3: Biographical facts and movement sum-maries extracted by the system.To compare two social networks, we first needto match the nodes and ties between the networks.Two nodes (i.e., entities) are matched if they havethe same canonical name.
Two ties (i.e., edges orrelations) are matched if these three criteria aremet: they contain the same type of relations, thearguments of the relation are the same, and the or-der of the arguments are the same if the relation isunsymmetrical.We define the the following measurements forsocial network evaluation: the precision for nodes(or ties) is the ratio of common nodes (or ties) inthe two networks to the total number of nodes (orties) in the system output, the recall for nodes (orties) is the ratio of common nodes (or ties) in thetwo networks to the total number of nodes/ties inthe reference output, and the f-measure for nodes(or ties) is the harmonic mean of precision and re-call for nodes (or ties).
The f-measure for ties in-dicates the overall performance of social networkextraction.F-mea Dev TestBaseline New Baseline NewNodes 0.59 0.64 0.62 0.66Ties 0.06 0.30 0.06 0.28Table 3: Performance of social network extraction.Table 3 shows the results of social network ex-traction.
The new co-reference approach improvesthe performance for f-measure on ties by five-foldon development set and by nearly five-fold for testset.We also tested the system using automatic tran-scripts by our speech recognition system.
Not sur-prisingly, the result is much worse: the nodes f-measure is 0.11 for the test set, and the systemdid not find any relations.
A few factors are ac-countable for this low performance: (1) Speechrecognition is very challenging for this data set,since the testimonies contained elderly, emotional,accented speech.
Given that the speech recogni-tion system fails to recognize most of the personnames, extraction of social networks is difficult.
(2) The extraction systems perform worse on au-tomatic transcripts, due to the quality of the auto-matic transcript, and the discrepancy between thetraining and test data.
(3) Our measurements arevery strict, and no partial credit is given to partiallycorrect entities or relations.We decided not to present the evaluation resultsof the individual components since the perfor-mance of individual components are not at all in-dicative of the overall performance.
For instance,a single pronoun co-reference error might slighlty1045change the co-reference score, but can introduce aserious error in the social network, as shown in theexample in Section 3.2.5 Biography Generation from GeneralDomain TextWe have applied the same framework to biogra-phy generation from general news articles.
Thisgeneral system also contains three fundamental IEsystems and a fusion module, similar to the workpresented in the paper.
The difference is that the IEsystems are trained on general news text using dif-ferent categories of entities, relations, and events.A sample biography output extracted fromTDT5 English documents is shown in Figure 4.The numbers in brackets indicate the corpus countof the facts.Saddam Hussein:Basic Information:citizenship: Iraq [203]occupation: president [4412], leader [1792],dictator [664],...relative: odai [89], qusay [65], uday [65],...Life Events:places been to: bagdad [403], iraq [270],palaces [149]...Organizations associated with: manager ofbaath party [1000], ...Custody Events: Saddam was arrested [52],Communication Events: Saddam said [3587]...
...Figure 4: Sample biography output.6 Related WorkWhile there has been previous work on extractingsocial networks from emails and the web (Culottaet al, 2004), we believe this is the first paper topresent a full-fledged system for extracting socialnetworks from conversational speech transcripts.Similarly, most of the work on co-reference res-olution has not focused on conversational speech.
(Ji et al, 2005) uses semantic relations to refineco-reference decisions, but in a approach differentfrom ours.7 Conclusions and Future WorkWe have described a novel approach for extractingsocial networks, biographical facts, and movementsummaries from transcripts of oral interviews withHolocaust survivors.
We have improved the per-formance of social network extraction five-fold,compared to a baseline system that already usesstate-of-the-art technology.
In particular, we im-proved the performance of co-reference resolutionfor conversational speech, by feature engineeringand improving the clustering algorithm.Although our application data consists of con-versational speech transcripts in this paper, thesame extraction approach can be applied togeneral-domain text as well.
Extracting general,rich social networks is very important in many ap-plications, since it provides the knowledge of whois connected to whom and how they are connected.There are many interesting issues involved inbiography generation from a large data collection,such as how to resolve contradictions.
The countsfrom the corpus certainly help to filter out falseinformation which would otherwise be difficult tofilter.
But better technology at detecting and re-solving contradictions will definitely be beneficial.AcknowledgmentWe would like to thank Martin Franz and BhuvanaRamabhadran for their help during this project.This project is funded by NSF under the Infor-mation Technology Research (ITR) program, NSFIIS Award No.
0122466.
Any opinions, findingsand conclusions or recommendations expressed inthis material are those of the authors and do notnecessarily reflect the views of the NSF.References2005.
Automatic content extraction.http://www.nist.gov/speech/tests/ace/.Aron Culotta, Ron Bekkerman, and Andrew McCal-lum.
2004.
Extracting social networks and con-tact information from email and the web.
In CEAS,Mountain View, CA.Radu Florian, Hany Hassan, Abraham Ittycheriah,Hongyan Jing, Nanda Kambhatla, Xiaoqiang Luo,Nicolas Nicolov, and Salim Roukos.
2004.
A sta-tistical model for multilingual entity detection andtracking.
In Proceedings of.
HLT-NAACL 2004.Samuel Gustman, Dagobert Soergeland Douglas Oard,William Byrne, Michael Picheny, Bhuvana Ramab-hadran, and Douglas Greenberg.
2002.
Support-ing access to large digital oral history archives.
InProceedings of the Joint Conference on Digital Li-braries, pages 18?27.1046Heng Ji, DavidWestbrook, and Ralph Grishman.
2005.Using semantic relations to refine coreference deci-sions.
In Proceedings of HLT/EMNLP?05, Vancou-ver, B.C., Canada.Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, NandaKambhatla, and Salim Roukos.
2004.
A mention-synchronous coreference resolution algorithm basedon the bell tree.
In Proceedings of the 42nd An-nual Meeting of the Association for ComputationalLinguistics (ACL2004), pages 135?142, Barcelona,Spain.Vincent Ng.
2005.
Machine learning for coreferenceresolution: From local classification to global rank-ing.
In Proceedings of ACL?04.D.
Oard, D. Soergel, D. Doermann, X. Huang, G.C.Murray, J. Wang, B. Ramabhadran, M. Franz,S.
Gustman, J. Mayfield, L. Kharevych, andS.
Strassel.
2004.
Building an information re-trieval test collection for spontaneous conversationalspeech.
In Proceedings of SIGIR?04, Sheffield, U.K.1047
