The VI framework program in Europe:some thoughts about Speech to Speech Translation research.Gianni LazzariCentro per la ricerca scientifica e tecnologica ITC-irstVia Sommarive 18 38050 Povo Trentolazzari@itc.itAbstractSignificant progress has been made in thefield of human language technologies.Various tasks like continuous speech rec-ognition for large vocabulary, speaker andlanguage identification, spoken informa-tion inquiry, information extraction andcross-language retrieval in restricted do-mains are today feasible and different pro-totypes and systems are running.
Thespoken translation problem on the otherhand is still a significant challenge:?Good text translation was hard enough topull off.
Speech to speech MT was be-yond going to the Moon ?
it was Mars??
[Steve Silbermann, Wired Magazine].Considering the major achievements ofthe last years obtained in the field and therelated challenges, a question arise: whatnext ?
Is it possible to  foresee in the nextdecade real services and applications ?How can we reach this goal ?
Shall we re-think the approach ?
Shall we need muchmore critical mass ?
How about data ?
Toanswer to these questions a new prepara-tory action, TC_STAR_P, funded in the Vframework, has been settled in Europe.Goals, objective  and activities of thispreparatory action will also be discussedin this paper1 IntroductionIn the last ten years, many projects addressed thespeech to speech translation problem, S2ST, i.e.VERBMOBIL [1], C-STAR [2], NESPOLE!
[3],EU-TRANS [4], BABYLON [5], ..
Many resultsand advancements have been achieved in method-ology, approaches and even performance.
Theseprojects have shown prototypes and demonstra-tions in different communicative situations: speechto speech translation over the telephone, machinemediated translation in a face to face communica-tion ( both in a real face to face or through  video-conferencing).
Some basic approaches have beenexplored: direct translation or data driven (bothexample based and statistical), indirect translationtrough interlingua-interchange format (IF) andmixed approaches, i.e.
multiengine.
In terms ofperformance significant  results have been obtainedin the VERBMOBIL project using a  statisticalapproach.Real applications using ASR technology  are usedin many applications in every day life [6].
Dicta-tion machines in limited domain, simple automaticservices over telephone, command and control incar, spoken document retrieval from broadcastnews.
Despite the new economy bubble and somedramatic events, like the L&H case, speech com-panies are still on the market.
However in terms oftechnology employed, we are far from providing afree communication functionality which is neces-sary when more complex automatic services areneeded, even considering communicative situa-tions where a small number of concepts are in-volved (very limited domain).
Automatic timeAssociation for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
129-135.Proceedings of the Workshop on Speech-to-Speech Translation:table inquiry systems are working in a strictlymenu driven approach.
Automatic directory assis-tance services can also be classified  in this class ofapplications.
Here a further  complexity is given bythe high perplexity of the directory names, but inthe end is still a complex communicative situation.In fact consider the difficulty in modelling  thehigh number of sentences that can be used whentrying to get the telephone number of an item ofthe Yellow Pages.The microelectronic and telecommunication  mar-ket offers  new opportunity of communication bycells phones, pdas, laptops in a wired or wirelessenvironment.
The communication process in thiscase is helped or ?complicated?
by multimodalinterfaces and multimedia information.
A newframework could be offered by the Web, which?integrates?
potentially multimedia data with mul-timodal communication.
In this case the paradigmis shifted towards a multimedia, multimodal personto person communication, in which the meaningsare conveyed by the language  and  enhanced withmultimedia content and non verbal cues.
The an-swer to a given question in a multilingual conver-sation could be more effective if given in textand/or visual form.
In this case the problem to af-ford becomes a combination of language under-standing, information extraction and multimediageneration in the target language.
Document re-trieval, summarization and translation could alsobe involved in this communication process.
Allthese technologies should be thought as pieces of awhole: a new model for person to person, informa-tion mediated, communication  that brings togetherall of the resources available: verbal and non ver-bal communication, multimedia, face to face.
Ap-proaching the multilingual communication as awhole means to implement each new technology asa brick within an entire edifice.Starting from the state of the art in speech tospeech translation research, considering the experi-ence carried on in setting real applications in ASRand having in mind the opportunities offered bynew devices in a wired and wireless environment,a question arise in order to develop real multilin-gual communication in the next decade: what next?Which are the main breakthroughs needed?
Manyissues need to be addressed.
First of all  how canwe reach the necessary performance required bythe three basic technologies needed, i.e.
speechrecognition, synthesis and machine translation.Shall we need a shift in the paradigm of research ?Is it mainly a matter of amount and quality of dataneeded?
How important are  issues as devices,multimedia information involved in a  human tohuman dialog, environmental-contextual informa-tion provided by intelligent networks?
How to in-tegrate all these contextual information in aconsistent way ?
Many steps and advancements areneeded in order to answer these questions.
Theseare  some of the questions addressed in a projectwhose acronym is TC-SPAR_P, technology andcorpora for speech to speech translation, recentlyfunded by European Union in the last call of the Vframework.
In what follows, first of all a state ofthe art of the basic technologies involved in aS2ST systems is summarized, then the most impor-tant challenges are listed and finally the TC-STAR_P project is presented.2 State of the art2.1 Speech recognitionIn the last 15 years a number of  speech recogni-tion tasks have been studied and evaluated.
Eachtask presented different challenges.
The featurescharacterizing these tasks are: type of speech (wellformed vs spontaneous), target of communication(computer, audience, person), bandwidth ( FWB,full bandwidth TWB, telephone bandwidth, FF, farfield).
Some of these tasks are dictation (WSJ),broadcast news, switchboard, voicemail and meet-ings.
In what follows, they are ordered in terms ofthe word error rate (wer)Dictation:          7%, well formed, computer,  FBWBroadcast news:  12%, various, audience,    FBWSwitchboard : 20-30% spontaneous, person, TBWVoicemail:  30% spontaneous, person, TWBMeetings:       50-60%  spontaneous, person  FFAt present the spontaneous speech is the featurewith the largest effect on word error rate, followedby environment effect and domain dependence.The main challenge for the next years will be todevelop speech recognition systems that mimicshuman performance.
This means in general inde-pendent of environment, domain and working  aswell for spontaneous as for read speech.
The focusareas will mainly concentrate first of all  on im-proving the spontaneous speech models ( i.e pro-sodic features and articolatory models,multispeaker speech, collect adequate amount ofconversational speech,?
), modeling and trainingtechniques for multi-environment and multi-domain.
Then another key issue will be languagemodeling.
It is well known  that  different staticlanguage models work best on specific domain.
Toimplement a  language model that works well onmany domains will be  an important achievementtowards the goal of mimicking the human per-formance.
A very quick dynamic adaptation at thelevel of word/sentence is an important target of theresearch.
Finally other factors driving progress willbe the continuous improving of computer speedover time, the independence from vocabulary andthe involvement of all the potential researchers inthe field, not only a few institutions.
Improvingthe performance of conversational speech and in-troducing highly dynamic language models are thetwo fundamental requirement for improving S2STperformances.
This is maybe the most critical pointbecause performing under 10%, in conversationalspeech, seems today an hard problem.2.2 Speech synthesisSpeech synthesis is an important component in aspeech to speech translation system.
To mimicshuman voice is still  one of the most challenginggoal for speech synthesis.
The multilingual humanto human communication  framework introducenew challenges,  gender, age and cultural adapta-tion.
Emotion and prosody are also very importantissues [7] [8].Today the most effective way to generate syntheticspeech is based on the concatenation of differentacoustic units.
This approach is in contrast to tradi-tional rule-based synthesis where the design of thedeterministic units required explicit knowledge andexpertise.
In a corpus based approach the unit se-lection process involves a combinatorial searchover the entire speech corpus, and consequently,fast search algorithms have been developed for thispurpose as an integral part of current synthesis sys-tems.Three are the main factors of the corpus-basedmethods for a specification of the speech segmentsrequired for concatenative synthesis: first of all  aunit selection algorithm, then some objectivemeasures used in the selection criteria and finallythe design of the required speech corpus.
From theapplication point of view the huge amount ofmemory necessary for exploiting the concatenationof  speech units,  strongly limits the class of appli-cation.Prosody and speaker characteristics are,  togetherwith speech segments design, the other two impor-tant issues in speech synthesis.
In order to controlprosody, it is necessary to ensure adequate intona-tion and stress, rhythm, tempo and accent.
Seg-mental duration control and fundamental frequencycontrol  are  needed.
Speech waveforms containnot only linguistic information but also speakervoice characteristics, as manifested in the glottalwaveform of voice excitation and in the globalspectral features representing vocal tract character-istics.
Moreover paralinguistic factors causechanges in speaking styles reflected in a change ofboth voice quality and prosody.Prosodic modeling is probably the domain fromwhich most of the improvements will come.
Inves-tigation in this direction, try to master linguisticand extra-linguistic phenomena, will addressprobably  multicultural issues, which are very im-portant in a multilingual human to human commu-nication framework.2.3 Machine TranslationBeside speech recognition and synthesis the  trans-lation component is the core of a speech to speechtranslation system.
The classical machine transla-tion (MT)  problem, to translate  a text in a givenlanguage, i.e.
Italian, in a target language, i.e.
Chi-nese, is a completely different problem from theS2PT problem First of all in the classical  MTproblem no human is involved.
The process is aone way process.
The text is supposed to be lin-guistically ?correct?.
In the S2ST process two hu-mans are involved, the process is bi-directional, thelanguage is conversational, spontaneous,  un-grammatical and mixed with non verbal cues.Moreover the  environment, in terms of acousticnoise and modality of interaction is a critical issue.A near real time translation is mandatory in S2ST.Then, because  humans are involved directly in theprocess, the understanding phase is carried on byhumans in a collaborative way.
Finally given thatanyhow a machine is involved in the translation animportant issue related to human machine commu-nication has also to be considered.
In order to af-ford the S2ST problem all these factors have to betaken into account.Different architectures have been exploited: someusing  an intermediate language (interlingua, inter-change format), some  exploiting a  direct transla-tion method.
A typical example of the first case isrepresented by JANUS [9] and NESPOLE!
archi-tectures.
The Italian implementation of NESPOLE!S2ST system architecture]  consists of two mainprocessing chains: the analysis chain and the syn-thesis chain.
The analysis chain converts a Italianacoustic signal into a (sequence of), IF    represen-tation(s) by going through: the recognizer, whichproduces a sequence of word hypotheses for theinput signal; the understanding module, which ex-ploits a multi-layer argument extractor and a statis-tical based classifier to deliver IF representations.The synthesis chain starts from an IF expressionand produces a target language  synthesized audiomessage expressing that content.
It consists of twomodules.
The generator first converts the IF repre-sentation into a more language oriented representa-tion and then integrates it with domain knowledgeto produce sentences in Italian.
Such sentencesfeed a speech synthesizer.An example of the direct translation approach isrepresented by the ATR-MATRIX [10] architec-ture, which exploit a cascade of a speech recog-nizer with a direct translation algorithm, TDMT,whose produced text is then  synthesized.
The di-rect translation  approach is implemented usingexample based algorithms.
A second example ofdirect translation, based on statistical modeling ,has been pioneered by  IBM[11] [12], starting fromtext translation.
Statistical translation has also beendeveloped in the European project EU-TRANSand in the framework of  German projectVERBMOBIL.At the moment research is going on in order to de-velop unified or integrated approaches.
To unifyspeech recognition, understanding, and translationas an entire statistical  processing is the ultimategoal of this approach as well stated in [13] ?
Weconsider this integrated approach and its suitableimplementation to be an open question for futureresearch on spoken language translation?From the performance point of view the most im-portant  experience obtained in the VERBMOBIL pro-ject, in particular a large-scale end-to-endevaluation, showed that the statistical approachresulted in significantly lower error rates than threecompeting translation approaches: the sentenceerror rate was 29% in comparison with 52% to62% for the other translation approaches.Finally a key issue for S2ST systems is the end toend evaluation methodology.
The goal is to de-velop a methodology based on objective measure-ment.
Evaluation methodologies have beenproposed and developed in VERBMOBIL, C-STAR, and by many other groups.3 Major Challenges3.1 Improve significantly the end-to-end per-formanceThis is the first challenge to be addressed in thenear future.
It seems that unified methodologiesbased on statistical modeling are very promising,provided that some key issues will be afforded andsuitable solutions worked out.
This methodologyallows to include acoustics, phonetic context,speaking rate, speaker variations, language featuressuch as syntax or semantics, etc.
into one unifiedway.
Then this approach jointly optimizes acous-tics, language and speaker effects.
From the mod-eling point of you it represents quite a shift fromthe source model.
Much more work is needed inproposing new computational tools and buildingup.
This approach is also consistent with thespeech synthesis perspective: corpus based anddata drivenA challenge will  also be the exploitation of realapplications in a limited domain, i.e.
tourism, ofsystems based on interlingua approaches.
Key is-sues in this case are portability and robustness.3.2 Produce aligned multilingual corpora andlexicaIn order to afford the challenge of  developing newmodels with the hope to improve significantly per-formance a key issue is given by corpora andlexica.
In order to afford the problem of spontane-ous speech recognition, there are proposals [14] ofcollecting and transcribing  5000 hours of  sponta-neous speech.
This issue is controversial; anyhowthis is what we have learn from the past experiencein speech recognition.
The test data could be amixture of current and new sources.
For translationaligned multilingual  text corpora are also crucial.An effort is going on in a joint cooperation withATR and IRST and with the other member of  C-STAR III consortium in order to set up an alignedtext corpora composed by the transcription andtranslation of  phrase book in the tourism domain.This phrase book cover a broad range of situations:emergency, time table, transport, sightseeing, di-rections, attractions, hotels, shopping?Alignedmultilingual lexical are also important languageresources for future S2ST systems development.
Acurrent activity is under development in LC-STAR[15] a new funded project in the Vth framework byEU.3.3 Integrate speech to speech translationcomponents in a real applicationsReal services and application involvingspeech communication need to manage the ?inter-face problem?, i.e.
the physical impact of the userwith a device which involves multimodal, multi-media in a  ubiquitous environment.
A wearabledevice, a PDA or 3G cellular  cannot be operatedby keyboard, and requires sophisticated naturalmultimodal human interfaces.
Speech, vision andhandwriting seem natural candidates for human-machine interaction.
But how can a system provideseamless integration between human-machine ser-vices and human-human services?
How can thesystem blend the two, provide assistance and guid-ance for a user to access and understand databasesand information resources, but also to serve as ago-between to facilitate the interaction with otherhumans or with a user?s direct environment?4 A new action in EuropeGiven the challenges previously discussed and theexperience carried on in the previous and ongoingprojects  a new and innovative initiative is neededto tackle to problem.
This initiative in order to besuccessful need first of all a critical mass of re-searchers.
Within Europe few research groups havethe capability to build up complete SST systems.Most research groups are small and work only onsome research themes, i.e prosody, acoustic model-ing, language modeling, speech synthesis.
Al-though these small groups may have excellentresearchers, their work has less impact on the de-velopment of SST-components.
This new initiativeshould provide an appropriate infrastructure to usein a effective way the intellectual potential ofEuropean researchers.
Given the big shift neededin order to set up this new action, a group of Euro-pean major players in the spoken language tech-nology, both research institutions,  industrialentities, and ELDA proposed a preparatory action,which acronym is TC-STAR_P (Technology andCorpora for speech translation).4.1  Goals and activities.The preparatory action, under negotiation, fits withthe action line IST2002-III.5.2 c) ?preparing forfuture research activities?.
It is scheduled to beginin July 2002.
The duration will be  one year withthe purpose of preparing and getting ready an inte-grated project for the VI Framework.
An integratedproject as is a large scale action  with the purposeto create the European Research Area, ERA.
Theactivity of the TC-STAR_P  will be carried on  bythe cooperation of  the four groups: an industrialgroup, with proven experience in SST technologydevelopment, a research group, with proven ex-perience in research in SST-technologies, an infra-structure group, with proven experience inproducing language resources for SST componentsand with proven experience of evaluation of SSTcomponents and systems.
Then a disseminationgroup  will be in charge of using and spreading theproject?s resultsThree are the main goals of this action:?
developing research roadmaps and as-sociated implementation models?
identifying and bringing together allrelevant actors in the Speech to SpeechTranslation (SST) area?
investigating effective mechanisms formanaging future activities4.1.1 Preparing RTD roadmaps and associatedimplementation modelsThe consortium is composed of different RTDcommunities: industrial, academics, and infrastruc-ture entities.
All these organizations will contributeto develop common visions and analyze researchrequirements for SST systems.
As a result of thesetasks, industrial partners will prepare roadmaps fortechnical implementations and services; the scien-tific and academic groups will prepare roadmapsfor technology improvements; and the infrastruc-ture group will provide roadmaps for LR-production and evaluation campaigns.The work will include a case study where indus-trial partners and research partners will provideapplication-oriented and research input respec-tively.
The infrastructure group will focus on pre-paratory tasks for setting up production, evaluationand validation centers for the needed LR.4.1.2 Identifying and bringing together all rele-vant actorsThe consortium includes some of the most relevantactors in the SST field.
One of the objectives dur-ing the lifetime of the project is to attract furtherkey actors from the industrial, research and infra-structure groups, as well as SMEs working withSST applications and related fields.Within the infrastructure group, a key action is toattract and prepare contacts with national agenciesfor funding language specific LR-production in thefuture FP6, and with entities working on evaluationand validation of language resources.
The devel-opment of language resources is a very expensiveactivity, which must be best tackled by coordinatedfunding actions at national and European levels.4.1.3 Investigating a new management modelAccording to the IST 2002 Work programme, Ac-tion Line 3.5.2 should focus on building andstrengthening RTD communities by encouragingresearch, business and user organisations to de-velop together common visions and analyse re-search requirements in order to identify commonchallenges and objectives; and on investigatingeffective mechanisms for managing future activi-ties.Moreover, a cornerstone of the future work to bedeveloped under the Integrated Project is the man-agement structure.
In accordance with Action Line3.5.2., the work to be performed under TC-STAR_P includes exploring a new organizationalmodel in order to allow partners to smoothly col-laborate in pursuing the final goal.
This importanttask will be investigated during the project.
Issuessuch as distribution of work and resources, admis-sion and withdrawal of participants, engagement ofadditional parties, scientific guidance and monitor-ing, etc.
will be examined.
The model has to beeffective to reach the envisaged goal, to react toexternal new trends, needs and demands comingfrom the market, society and scientific communitySection 2References[1] W. Wahlster (Ed.
): Verbmobil: Foundations ofspeech-to-speech translations.
Springer-Verlag, Ber-lin, Germany, 2000[2]  C-STAR Website:     http:// www.c-star.org/[3]  NESPOLE!
Website: http:// nespole!.itc.it[4] EU-TRANS Project; Instituto Tecnologico de In-formatica (ITI, Spain), Fondazione Ugo Bordoni(FUB, Italy), RWTH Aachen, Lehrstuhl f. InformatikVI (Germany), Zeres GmbH Bochum (Germany):Example-Based Language Translation Systems.
Fi-nal report of the EuTrans project (EU project num-ber 30268), July 2000.
[5]  BABYLON Web sitewww.darpa.mil/ipto/research/babylon/approach.html[6]  R.V.Cox, Candace A. Kamm, Lawrence R. Rabiner,J.
Schroeter,  J. G. Wilpon Speech and LanguageProcessing for Next-Millennium CommunicationsServices, Proceedings of the IEEE, Vol.
88, No.8, August 2000[7] Sammy Lemmety Review of speech SynthesisTechnology Master Thesis Helsinky University ofTechnology, 1999[8]  Ron Cole (Ed): Survey of the State of the Art inHuman Language Technology, Spoken Output Tech-nology, chapt.
5 Cambridge University Press 1996[9] A. Lavie, L. Levin, A. Waibel, D. Gates, M. Ga-valda, L. Mayfield: JANUS: Multi-lingual translationof spontaneous speech in a limited domain.
2nd Conf.Of the Association for Machine Translation in theAmericas pp.
252-255, Montreal, Quebec, Oct.
1995.
[10] Takezawa et al A Japanese-to-English speechtranslation system: ATR-MATRIX.
In Proceeding ofICSLP  1998 pp.
2779--2782[11] P. F. Brown, S. A. Della Pietra, V. J. Della Pietra,R.
L. Mercer: The mathematics of statistical machinetranslation: Parameter estimation.
ComputationalLinguistics, Vol.
19, No.
2, pp.
263?311, 1993[12] Yuqing Gao et alas.
Speech to speech  translation.In proceeding of  C-STAR III Workshop GuillinChina  march 13-14 2002[13] H. Ney: Speech Translation: Coupling of Recogni-tion and Translation.
IEEE Int.
Conf.
on Acoustics,Speech and Signal Processing, pp.
I-517-520, Phoe-nix, AR, March 1999.
[14] M.Padmanabham, M. Pichney, Large VocabularySpeech Recognition Algorithms, IEEE Computer,pag 42-50 april 2002[15] LC_STAR Website    www.lc-star.com
