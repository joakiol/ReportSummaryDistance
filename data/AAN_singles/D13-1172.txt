Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1655?1667,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsExploiting Domain Knowledge in Aspect ExtractionZhiyuan Chen, Arjun Mukherjee,Bing LiuMeichun Hsu, Malu Castellanos,Riddhiman GhoshUniversity of Illinois at Chicago HP LabsChicago, IL 60607, USA Palo Alto, CA 94304, USA{czyuanacm,arjun4787}@gmail.com,liub@cs.uic.edu{meichun.hsu, malu.castellanos,riddhiman.ghosh}@hp.comAbstractAspect extraction is one of the key tasks insentiment analysis.
In recent years, statisticalmodels have been used for the task.
However,such models without any domain knowledgeoften produce aspects that are not interpreta-ble in applications.
To tackle the issue, someknowledge-based topic models have beenproposed, which allow the user to input someprior domain knowledge to generate coherentaspects.
However, existing knowledge-basedtopic models have several major shortcom-ings, e.g., little work has been done to incor-porate the cannot-link type of knowledge orto automatically adjust the number of topicsbased on domain knowledge.
This paper pro-poses a more advanced topic model, calledMC-LDA (LDA with m-set and c-set), to ad-dress these problems, which is based on anExtended generalized P?lya urn (E-GPU)model (which is also proposed in this paper).Experiments on real-life product reviewsfrom a variety of domains show that MC-LDA outperforms the existing state-of-the-artmodels markedly.1 IntroductionIn sentiment analysis and opinion mining, aspectextraction aims to extract entity aspects or featureson which opinions have been expressed (Hu andLiu, 2004; Liu, 2012).
For example, in a sentence?The picture looks great,?
the aspect is ?picture.
?Aspect extraction consists of two sub-tasks: (1)extracting all aspect terms (e.g., ?picture?)
fromthe corpus, and (2) clustering aspect terms withsimilar meanings (e.g., cluster ?picture?
and ?pho-to?
into one aspect category as they mean thesame in the domain ?Camera?).
In this work, weadopt the topic modeling approach as it can per-form both sub-tasks simultaneously (see ?
2).Topic models, such as LDA (Blei et al 2003),provide an unsupervised framework for extractinglatent topics in text documents.
Topics are aspectcategories (or simply aspects) in our context.However, in recent years, researchers have foundthat fully unsupervised topic models may not pro-duce topics that are very coherent for a particularapplication.
This is because the objective functionsof topic models do not always correlate well withhuman judgments and needs (Chang et al 2009).To address the issue, several knowledge-basedtopic models have been proposed.
The DF-LDAmodel (Andrzejewski et al 2009) incorporatestwo forms of prior knowledge, also called twotypes of constraints: must-links and cannot-links.A must-link states that two words (or terms)should belong to the same topic whereas a cannot-link indicates that two words should not be in thesame topic.
In (Andrzejewski et al 2011), moregeneral knowledge can be specified using first-order logic.
In (Burns et al 2012; Jagarlamudi etal., 2012; Lu et al 2011; Mukherjee and Liu,2012), seeded models were proposed.
They enablethe user to specify prior knowledge as seedwords/terms for some topics.
Petterson et al(2010)also used word similarity as priors for guidance.However, none of the existing models is capableof incorporating the cannot-link type of knowledgeexcept DF-LDA (Andrzejewski et al 2009).
Fur-thermore, none of the existing models, includingDF-LDA, is able to automatically adjust the num-ber of topics based on domain knowledge.
Thedomain knowledge, such as cannot-links, maychange the number of topics.
There are two typesof cannot-links: consistent and inconsistent withthe domain corpus.
For example, in the reviews of1655domain ?Computer?, a topic model may generatetwo topics Battery and Screen that represent twodifferent aspects.
A cannot-link {battery, screen}as the domain knowledge is thus consistent withthe corpus.
However, words Amazon and Pricemay appear in the same topic due to their high co-occurrences in the Amazon.com review corpus.
Toseparate them, a cannot-link {amazon, price} canbe added as the domain knowledge, which is in-consistent with the corpus as these two words havehigh co-occurrences in the corpus.
In this case, thenumber of topics needs to be increased by 1 sincethe mixed topic has to be separated into two indi-vidual topics Amazon and Price.
Apart from theabove shortcoming, earlier knowledge-based topicmodels also have some major shortcomings:Incapability of handling multiple senses: Aword typically has multiple meanings or senses.For example, light can mean ?of little weight?
or?something that makes things visible.?
DF-LDAcannot handle multiple senses because its defini-tion of must-link is transitive.
That is, if A and Bform a must-link, and B and C form a must-link, itimplies a must-link between A and C, indicating A,B, and C should be in the same topic.
This casealso applies to the models in (Andrzejewski et al2011), (Petterson et al 2010), and (Mukherjee andLiu, 2012).
Although the model in (Jagarlamudi etal., 2012) allows multiple senses, it requires thateach topic has at most one set of seed words (seedset), which is restrictive as the amount ofknowledge should not be limited.Sensitivity to the adverse effect of knowledge:When using must-links or seeds, existing modelsbasically try to ensure that the words in a must-link or a seed set have similar probabilities under atopic.
This causes a problem: if a must-link com-prises of a frequent word and an infrequent word,due to the redistribution of probability mass, theprobability of the frequent word will decreasewhile the probability of the infrequent word willincrease.
This can harm the final topics becausethe attenuation of the frequent (often domain im-portant) words can result in some irrelevant wordsbeing ranked higher (with higher probabilities).To address the above shortcomings, we definem-set (for must-set) as a set of words that shouldbelong to the same topic and c-set (cannot-set) as aset of words that should not be in the same topic.They are similar to must-link and cannot-link butm-sets do not enforce transitivity.
Transitivity isthe main cause of the inability to handle multiplesenses.
Our m-sets and c-sets are also more con-cise providing knowledge in the context of a set.As in (Andrzejewski et al 2009), we assume thatthere is no conflict between m-sets and c-sets, i.e.,if ?1  is a cannot-word of ?2  (i.e., shares a c-setwith ?2), any word that shares an m-set with ?1 isalso a cannot-word of ?2.
Note that knowledge asm-sets has also been used in (Chen et al 2013a)and (Chen et al 2013b).We then propose a new topic model, called MC-LDA (LDA with m-set and c-set), which is not on-ly able to deal with c-sets and automatically adjustthe number of topics, but also deal with the multi-ple senses and adverse effect of knowledge prob-lems at the same time.
For the issue of multiplesenses, a new latent variable ?
is added to LDA todistinguish multiple senses (?
3).
Then, we employthe generalized P?lya urn (GPU) model(Mahmoud, 2008) to address the issue of adverseeffect of knowledge (?
4).
Deviating from thestandard topic modeling approaches, we proposethe Extended generalized P?lya urn (E-GPU)model (?
5).
E-GPU extends the GPU model toenable multi-urn interactions.
This is necessary forhandling c-sets and for adjusting the number oftopics.
E-GPU is the heart of MC-LDA.
Due to theextension, a new inference mechanism is designedfor MC-LDA (?
6).
Note that E-GPU is genericand can be used in any appropriate application.In summary, this paper makes the followingthree contributions:1.
It proposed a new knowledge-based topic mod-el called MC-LDA, which is able to use bothm-sets and c-sets, as well as automatically ad-just the number of topics based on domainknowledge.
At the same time, it can deal withsome other major shortcomings of early exist-ing models.
To our knowledge, none of the ex-isting knowledge-based models is as compre-hensive as MC-LDA in terms of capabilities.2.
It proposed the E-GPU model to enable multi-urn interactions, which enables c-sets to be nat-urally integrated into a topic model.
To the bestof our knowledge, E-GPU has not been pro-posed and used before.3.
A comprehensive evaluation has been conduct-ed to compare MC-LDA with several state-of-the-art models.
Experimental results based onboth qualitative and quantitative measuresdemonstrate the superiority of MC-LDA.16562  Related WorkSentiment analysis has been studied extensively inrecent years (Hu and Liu, 2004; Pang and Lee,2008; Wiebe and Riloff, 2005; Wiebe et al 2004).According to (Liu, 2012), there are three main ap-proaches to aspect extraction: 1) Using word fre-quency and syntactic dependency of aspects andsentiment words for extraction (e.g., Blair-goldensohn et al 2008; Hu and Liu, 2004; Ku etal., 2006; Popescu and Etzioni, 2005; Qiu et al2011; Somasundaran and Wiebe, 2009; Wu et al2009; Yu et al 2011; Zhang and Liu, 2011;Zhuang et al 2006); 2) Using supervised se-quence labeling/classification (e.g., Choi andCardie, 2010; Jakob and Gurevych, 2010;Kobayashi et al 2007; Li et al 2010); 3) Topicmodels (Branavan et al 2008; Brody and Elhadad,2010; Fang and Huang, 2012; Jo and Oh, 2011;Kim et al 2013; Lazaridou et al 2013; Li et al2011; Lin and He, 2009; Lu et al 2009, 2012,2011; Lu and Zhai, 2008; Mei et al 2007;Moghaddam and Ester, 2011; Mukherjee and Liu,2012; Sauper et al 2011; Titov and McDonald,2008; Wang et al 2010, 2011; Zhao et al 2010).Other approaches include shallow semantic pars-ing (Li et al 2012b), bootstrapping (Xia et al2009), Non-English techniques (Abu-Jbara et al2013; Zhou et al 2012), graph-based representa-tion (Wu et al 2011), convolution kernels(Wiegand and Klakow, 2010) and domain adap-tion (Li et al 2012).
Stoyanov and Cardie (2011),Wang and Liu (2011), and Meng et al(2012)studied opinion summarization outside the reviews.Some other works related with sentiment analysisinclude (Agarwal and Sabharwal, 2012; Kennedyand Inkpen, 2006; Kim et al 2009; Mohammad etal., 2009).In this work, we focus on topic models owing totheir advantage of performing both aspect extrac-tion and clustering simultaneously.
All other ap-proaches only perform extraction.
Although thereare several related works on clustering aspectterms (e.g., Carenini et al 2005; Guo et al 2009;Zhai et al 2011), they all assume that the aspectterms have been extracted beforehand.
We alsonotice that some aspect extraction models in sen-timent analysis separately discover aspect wordsand aspect specific sentiment words (e.g., Sauperand Barzilay, 2013; Zhao et al 2010).
Our pro-posed model does not separate them as most sen-timent words also imply aspects and most adjec-tives modify specific attributes of objects.
For ex-ample, sentiment words expensive and beautifulimply aspects price and appearance respectively.Regarding the knowledge-based models, be-sides those discussed in ?
1, the model (Hu et al2011) enables the user to provide guidance interac-tively.
Blei and McAuliffe (2007) and Ramage etal.
(2009) used document labels in supervised set-ting.
In (Chen et al 2013a), we proposed MDK-LDA to leverage multi-domain knowledge, whichserves as the basic mechanism to exploit m-sets inMC-LDA.
In (Chen et al 2013b), we proposed aframework (called GK-LDA) to explicitly dealwith the wrong knowledge when exploring thelexical semantic relations as the general (domainindependent) knowledge in topic models.
Butthese models above did not consider theknowledge in the form of c-sets (or cannot-links).The generalized P?lya urn (GPU) model(Mahmoud, 2008) was first introduced in LDA byMimno et al(2011).
However, Mimno et al(2011)did not use domain knowledge.
Our results in ?
7show that using domain knowledge can signifi-cantly improve aspect extraction.
The GPU modelwas also employed in topic models in our work of(Chen et al 2013a, 2013b).
In this paper, we pro-pose the Extended GPU (E-GPU) model.
The E-GPU model is more powerful in handling complexsituations in dealing with c-sets.3 Dealing with M-sets and Multiple SensesSince the proposed MC-LDA model is a majorextension to our earlier work in (Chen et al2013a), which can deal with m-sets, we includethis earlier work here as the background.To incorporate m-sets and deal with multiplesenses of a word, the MDK-LDA(b) model wasproposed in (Chen et al 2013a), which adds anew latent variable ?
into LDA.
The rationale hereis that this new latent variable ?
guides the modelto choose the right sense represented by an m-set.The generative process of MDK-LDA(b) is (thenotations are explained in Table 1):?
~ ?????????(?)??|??
~ ???????????(??)?
~ ?????????(?)??|??,?
~ ?????????????????
~ ?????????(?)??|??
, ??,?
~ ???????????????,??
?1657The corresponding plate is shown in Figure 1.
Un-der MDK-LDA(b), the probability of word ?
giv-en topic ?, i.e., ??(?
), is given by:??(?)
= ?
??(?)
?
??,?(?)?
?=1    (1)where ??(?)
denotes the probability of m-set ?occurring under topic ?
and ??,?(?)
is the proba-bility of word ?
appearing in m-set ?
under topic ?.According to (Chen et al 2013a), the condi-tional probability of Gibbs sampler for MDK-LDA(b) is given by (see notations in Table 1):????
= ?, ??
= ?
????
, ???
,?,?,?, ??
???,???
+ ??
???,????
+ ?????=1???,???
+ ??
???,????
+ ?????=1???,?,????
+ ???
???,?,????
+ ?????
?=1(2)The superscript ??
denotes the counts excludingthe current assignments (??
and ??)
for word ?
?.4 Handling Adverse Effect of Knowledge4.1 Generalized P?lya urn (GPU) ModelThe P?lya urn model involves an urn containingballs of different colors.
At discrete time intervals,balls are added or removed from the urn accordingto their color distributions.In the simple P?lya urn (SPU) model, a ball isfirst drawn randomly from the urn and its color isrecorded, then that ball is put back along with anew ball of the same color.
This selection processis repeated and the contents of the urn change overtime, with a self-reinforcing property sometimesexpressed as ?the rich get richer.?
SPU is actuallyexhibited in the Gibbs sampling for LDA.The generalized P?lya urn (GPU) model differsfrom the SPU model in the replacement schemeduring sampling.
Specifically, when a ball is ran-domly drawn, certain numbers of additional ballsof each color are returned to the urn, rather thanjust two balls of the same color as in SPU.4.2 Promoting M-sets using GPUTo deal with the issue of sensitivity to the adverseeffect of knowledge, MDK-LDA(b) is extended toMDK-LDA which employs the generalized P?lyaurn (GPU) sampling scheme.As discussed in ?
1, due to the problem of theadverse effect of knowledge, important words maysuffer from the presence of rare words in the samem-set.
This problem can be dealt with the verysampling scheme of the GPU model (Chen et al2013a).
Specifically, by adding additional ??,?
?,?balls of color ?
into ???
while keeping the drawnball, we increase the proportion (probability) ofseeing the m-set ?
under topic ?
and thus promotem-set ?
as a whole.
Consequently, each word in ?is more likely to be emitted.
We define ??,??,?
as:??,??,?
= ?1           ?
= ???
?
?
?,??
?
?,?
?
?
?0           otherwise(3)The corresponding Gibbs sampler for MDK-LDAwill be introduced in ?
6.Hyperparameters?, ?, ?
Dirichlet priors for ?,  ?,  ?Latent & Visible Variables?
Topic (Aspect)?
M-set?
Word?
Document-Topic distribution??
Topic distribution of document ??
Topic-M-set distribution??
M-set distribution of topic ??
Topic-M-set-Word distribution??,?
Word distribution of topic ?, m-set ?Cardinalities?
Number of documents??
Number of words in document ??
Number of topics?
Number of m-sets?
The vocabulary sizeSampling & Count Notations??
Topic assignment for word ????
M-set assignment for word ?????
Topic assignments for all words except ?????
M-set assignments for all words except ???
?,?Number of times that topic ?
is assignedto word tokens in document ??
?,?Number of times that m-set ?
occurs un-der topic ??
?,?,?Number of times that word ?
appears inm-set ?
under topic ?Table 1.
Meanings of symbols.Figure 1.
Plate notation for MDK-LDA(b) and MC-LDA.T?S NmM?T?
zw?
?s ?
?16585 Incorporating C-sets5.1 Extended Generalized P?lya urn ModelTo handle the complex situation resulted from in-corporating c-sets, we propose an Extended gener-alized P?lya urn (E-GPU) model.
Instead ofinvolving only one urn as in SPU and GPU, E-GPU model considers a set of urns in the samplingprocess.
The E-GPU model allows a ball to betransferred from one urn to another, enabling mul-ti-urn interactions.
Thus, during sampling, thepopulations of several urns will evolve even if on-ly one ball is drawn from one urn.
This capabilitymakes the E-GPU model more powerful as itmodels relationships among multiple urns.We define three sets of urns which will be usedin the new sampling scheme in the proposed MC-LDA model.
The first set of urns is the topic urns???{1??}?
, where each topic urn contains ?
colors(topics) and each ball inside has a color ?
?
{1 ??}.
It corresponds to the document-topic dis-tribution ?
in Table 1.
The second set of urns (m-set urn ???
{1??}? )
corresponds to the topic-m-setdistribution ?
, with balls of colors (m-sets)?
?
{1 ?
?}
in each m-set urn.
The third set ofurns is the word urns ??,??
,where ?
?
{1 ??}
and?
?
{1 ?
?}
.
Each ball inside a word urn has acolor (word) ?
?
{1 ??}.
The distribution ?
canbe reflected in this set of urns.5.2 Handling C-sets using E-GPUAs MDK-LDA can only use m-sets but not c-sets,we now extend MDK-LDA to the MC-LDA modelin order to exploit c-sets.
As pointed out in ?
1, c-sets may be inconsistent with the corpus domain,which makes them considerably harder to dealwith.
To tackle the issue, we utilize the proposedE-GPU model and incorporate c-sets handling in-side the E-GPU sampling scheme, which is alsodesigned to enable automated adjustment of thenumber of topics based on domain knowledge.Based on the definition of c-set, each pair ofwords in a c-set cannot both have large probabili-ties under the same topic.
As the E-GPU modelallows multi-urn interactions, when sampling aball represents word ?
from a word urn ??,??
, wewant to transfer the balls representing cannot-words of ?
(sharing a c-set with ?)
to other urns(see Step 3 a below).
That is, decrease the proba-bilities of those cannot-words under this topicwhile increasing their corresponding probabilitiesunder some other topics.
In order to correctlytransfer a ball that represents word ?, it should betransferred to an urn which has a higher proportionof ?
and its related words (i.e., words sharing m-sets with ?).
That is, we randomly sample an urnthat has a higher proportion of any m-set of ?
totransfer ?
to (Step 3 b below).
However, the situa-tion becomes more involved when a c-set is notconsistent with the corpus.
For example, aspectsprice and amazon may be mixed under one topic(say ?)
in LDA.
The user may want to separatethem by providing a c-set {price, amazon}.
In thiscase, according to LDA, word price has no topicwith a higher proportion of it (and its relatedwords) than topic ?.
To transfer it, we need to in-crement the number of topics by 1 and then trans-fer the word to this new topic urn (step 3 c below).Based on these ideas, we propose the E-GPU sam-pling scheme for the MC-LDA model below:1.
Sample a topic ?
from ???
, an m-set ?
from ??
?, anda word ?
from ??,??
sequentially, where ?
is the?th document.2.
Record ?, ?
and ?, put back two balls of color ?
in-to urn ???
, one ball of color ?
into urn ??
?, and twoballs of color ?
into urn ??,??
.
Given the matrix ?
(in Equation 3), for each word ??
?
?, we put back??,??
,?
number of balls of color ?
into urn ???.3.
For each word ??
that shares a c-set with ?
:a) Sample an m-set ??
from ???
which satisfies??
?
??
.
Draw a ball ?
of color ??
(to be trans-ferred) from ??,???
and remove it from ??,???
.
Thedocument of ball ?
is denoted by ??.
If no ballof color ??
can be drawn (i.e., there is no ballof color ??
in ??,???
), skip steps b) to d).b) Produce an urn set {???,??? }
such that each urn init satisfies the following conditions:i)   ??
?
?, ??
?
?
?ii) The proportion of balls of color ??
in ????
ishigher than that of balls of color ??
in ??
?.c) If {???,??? }
is not empty, randomly select one urn???,???
from it.
If {???,??? }
is empty, set ?
= ?
+1, ??
= ?, draw an m-set ??
from ????
which sat-isfies ??
?
??.
Record ??
for step d).d) Put the ball ?
drawn from Step a) into ???,???
, aswell as a ball of color ??
into ????
and a ball ofcolor ??
into ????
.Note that the E-GPU model cannot be reflected inthe graphical model in Figure 1 as it is essentially1659sampling scheme, and hence MC-LDA shares thesame plate as MDK-LDA(b).6 Collapsed Gibbs SamplingWe now describe the collapsed Gibbs sampler(Griffiths and Steyvers, 2004) with the detailedconditional distributions and algorithms for MC-LDA.
Inference of ?
and ?
can be computationallyexpensive due to the non-exchangeability of wordsunder the E-GPU models.
We take the approach of(Mimno et al 2011) which approximates the trueGibbs sampling distribution by treating each wordas if it were the last.For each word ??
, we perform hierarchicalsampling consisting of the following three steps(the detailed algorithms are given in Figures 2 and3):Step 1 (Lines 1-11 in Figure 2): We jointlysample a topic ??
and an m-set ??
(containing ??
)for ??
, which gives us a blocked Gibbs sampler(Ishwaran and James, 2001), with the conditionalprobability given by:?(??
= ?, ??
= ?|???
, ???
,?,?,?, ?,?)
???,???
+??
???,????
+?????=1??
?
??,??,??
???,?,???????=1??
?=1 +??
??
?
???,??,?????,??,???????=1???=1+?????=1???,?,????
+???
???,?,????
+?????
?=1(4)This step is the same as the Gibbs sampling for theMDK-LDA model.Step 2 (lines 1-5 in Figure 3): For every cannot-word (say ??)
of ?
?, randomly pick an urn ???,??
?from the urn set {???,??? }
where ???
?
??.
If there ex-ists at least one ball of color ??
in urn ???,???
, wesample one ball (say ?? )
of color ??
from urn???,???
, based on the following conditional distribu-tion:?(?
= ?
?|?, ?,?,?,?, ?,?)
????,?+??
????,??+????
?=1(5)where ??
denotes the document of the ball ??
ofcolor ?
?.Step 3 (lines 6-12 in Figure 3): For each drawnball ?
from Step 2, resample a topic ?
and an m-set?
(containing ?? )
based on the following condi-tional distribution:?(??
= ?, ??
= ?|???
, ???
,?,?,?, ?,?, ?
= ??)?
??0,????????(??????)?????(??)?
???,???
+ ??
???,????
+ ?????=1??
?
??,??,??
?
??,?,???????=1??
?=1 + ??
??
?
???,??,??
?
??,??,???????=1??
?=1 + ?????=1???,?,????
+ ???
???,?,????
+ ?????
?=1(6)where ??
(same as ??
in Figure 3) and ??
are theoriginal topic and m-set assignments.
The super-script ??
denotes the counts excluding the originalAlgorithm 1.
GibbsSampling(?, ??
, ?, ?, ?
)Input: Document ?, Word ??
, Matrix ?,Transfer cannot-word flag ?,A set of valid topics ?
to be assigned to ?
?1:   ??,??
?
??,??
?
1;2:   for each word ??
in ??
do3:       ???,??
?
???,??
?
???,??
,??
;4:   end for5:   ???,??,??
?
???,??,??
?
1;6:   Jointly sample ??
?
?
and ??
?
??
using Equation 2;7:   ??,??
?
??,??
+ 1;8:   for each word ??
in ??
do9:       ???,??
?
???,??
+ ???,??
,??
;10: end for11: ???,??,??
?
???,??,??
+ 1;12: if ?
is true then13:     TransferCannotWords(??
, ??
);14: end ifFigure 2.
Gibbs sampling for MC-LDA.Algorithm 2.TransferCannotWords(??
, ??
)Input: Word ??
, Topic ?
?,1:   for each cannot-word ??
of ??
do2:       Randomly select an m-set ??
from all m-sets of ??
;3:       Build a set ?
containing all the instances of ?
?from the corpus with topic and m-set assign-ments being ??
and ??
;4:       if ?
is not empty then5:            Draw an instance of ??
from ?
(denoting thedocument of this instance by ??)
usingEquation 5;6:            Generate a topic set ??
that each topic ??
insidesatisfies ????????(???(?? ))
> ???(??
).7:            if ??
is not empty then8:                GibbsSampling(?
?, ?
?, ?, false, ??
);9:            else10:              ?????
= ?
+ 1; // ?
is #Topics.11:              GibbsSampling(?
?, ?
?, ?, false, {?????
});12:          end if13:     end if14: end forFigure 3.
Transfer cannot-words in Gibbs sampling.1660assignments.
?
()  is an indicator function, whichrestricts the ball to be transferred only to an urnthat contains a higher proportion of its m-set.When no topic ?
can be successfully sampled andthe current sweep (iteration) of Gibbs samplinghas the same number of topic (?)
as the previoussweep, we increment ?
by 1.
And then assign ?
to??
.
The counts and parameters are also updatedaccordingly.7 ExperimentsWe now evaluate the proposed MC-LDA modeland compare it with state-of-the-art existing mod-els.
Two unsupervised baseline models that wecompare with are:?
LDA: LDA is the basic unsupervised topicmodel (Blei et al 2003).?
LDA-GPU: LDA with GPU (Mimno et al2011).
Specifically, LDA-GPU applies GPU inLDA using co-document frequency.As for knowledge-based models, we focus oncomparing with DF-LDA model (Andrzejewski etal., 2009), which is perhaps the best knownknowledge-based model and it allows both must-links and cannot-links.For a comprehensive evaluation, we considerthe following variations of MC-LDA and DF-LDA:?
MC-LDA: MC-LDA with both m-sets and c-sets.
This is the newly proposed model.?
M-LDA: MC-LDA with m-sets only.
This isthe MDK-LDA model in (Chen et al 2013a).?
DF-M: DF-LDA with must-links only.?
DF-MC: DF-LDA with both must-links andcannot-links.
This is the full DF-LDA model in(Andrzejewski et al 2009).We do not compare with seeded models in (Burnset al 2012; Jagarlamudi et al 2012; Lu et al2011; Mukherjee and Liu, 2012) as seed sets arespecial cases of must-links and they also do notallow c-sets (or cannot-links).7.1 Datasets and SettingsDatasets: We use product reviews from four do-mains (types of products) from Amazon.com forevaluation.
The corpus statistics are shown in Ta-ble 2 (columns 2 and 3).
The domains are ?Cam-era,?
?Food,?
?Computer,?
and ?Care?
(short for?Personal Care?).
We have made the datasets pub-lically available at the website of the first author.Pre-processing: We ran the Stanford Core NLPTools1 to perform sentence detection and lemmati-zation.
Punctuations, stopwords 2 , numbers andwords appearing less than 5 times in each corpuswere removed.
The domain name was also re-moved, e.g., word camera in the domain ?Camera?,since it co-occurs with most words in the corpus,leading to high similarity among topics/aspects.Sentences as documents: As noted in (Titov andMcDonald, 2008), when standard topic models areapplied to reviews as documents, they tend to pro-duce topics that correspond to global properties ofproducts (e.g., brand name), which make topicsoverlapping with each other.
The reason is that allreviews of the same type of products discuss aboutthe same aspects of these products.
Only the brandnames and product names are different.
Thus, us-ing individual reviews for modeling is not veryeffective.
Although there are approaches whichmodel sentences (Jo and Oh, 2011; Titov andMcDonald, 2008), we take the approach of (Brodyand Elhadad, 2010), dividing each review into sen-tences and treating each sentence as an independ-ent document.
Sentences can be used by all threebaselines without any change to their models.
Alt-hough the relationships between sentences are lost,the data is fair to all models.Parameter settings: For all models, posterior in-ference was drawn using 1000 Gibbs iterationswith an initial burn-in of 100 iterations.
For allmodels, we set ?
= 1 and ?
= 0.1.
We found thatsmall changes of ?
and ?
did not affect the resultsmuch, which was also reported in (Jo and Oh,2011) who also used online reviews.
For the num-ber of topics T, we tried different values (see ?7.2)as it is hard to know the exact number of topics.While non-parametric Bayesian approaches (Tehet al 2006) aim to estimate ?
from the corpus,they are often sensitive to the hyper-parameters(Heinrich, 2009).1 http://nlp.stanford.edu/software/corenlp.shtml2 http://jmlr.org/papers/volume5/lewis04a/a11-smart-stop-listDomain #Reviews #Sentences #M-sets #C-setsCamera 500 5171 173 18Food 500 2416 85 10Computer 500 2864 92 6Care 500 3008 119 13Average 500 3116 103 9Table 2.
Corpus statistics with #m-sets and #c-setshaving at least two words.1661For DF-LDA, we followed (Andrzejewski et al2009) to generate must-links and cannot-linksfrom our domain knowledge.
We then ran DF-LDA3 while keeping its parameters as proposed in(Andrzejewski et al 2009) (we also experimentedwith different parameter settings but they did notproduce better results).
For our proposed model,we estimated the thresholds using cross validationin our pilot experiments.
Estimated value ?
= 0.2in equation 3 yielded good results.
The secondstage (steps 2 and 3) of the Gibbs sampler for MC-LDA (for dealing with c-sets) is applied afterburn-in phrase.Domain knowledge: User knowledge about a do-main can vary a great deal.
Different users mayhave very different knowledge.
To reduce this var-iance for a more reliable evaluation, instead ofasking a human user to provide m-sets, we obtainthe synonym sets and the antonym sets of eachword that is a noun or adjective (as words of otherparts-of-speech usually do not indicate aspects)from WordNet (Miller, 1995) and manually verifythe words in those sets for the domain.
Note that ifa word ?
is not provided with any m-set, it istreated as a singleton m-set {?}.
For c-sets, we ranLDA in each domain and provide c-sets based onthe wrong results of LDA as in (Andrzejewski etal., 2009).
Then, the knowledge is provided toeach model in the format required by each model.The numbers of m-sets and c-sets are listed in col-umns 4 and 5 of Table 2.
Duplicate sets have beenremoved.7.2 Objective EvaluationIn this section, we evaluate our proposed MC-3 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.htmlLDA model objectively.
Topic models are oftenevaluated using perplexity on held-out test data.However, the perplexity metric does not reflect thesemantic coherence of individual topics learned bya topic model (Newman et al 2010).
Recent re-search has shown potential issues with perplexityas a measure: (Chang et al 2009) suggested thatthe perplexity can sometimes be contrary to humanjudgments.
Also, perplexity does not really reflectour goal of finding coherent aspects with accuratesemantic clustering.
It only provides a measure ofhow well the model fits the data.The Topic Coherence metric (Mimno et al2011) (also called the ?UMass?
measure (Stevensand Buttler, 2012)) was proposed as a better alter-native for assessing topic quality.
This metric re-lies upon word co-occurrence statistics within thedocuments, and does not depend on external re-sources or human labeling.
It was shown that topiccoherence is highly consistent with human expertlabeling by Mimno et al(2011).
Higher topic co-herence score indicates higher quality of topics,i.e., better topic interpretability.Effects of Number of TopicsSince our proposed models and the baseline mod-els are all parametric models, we first compareeach model given different numbers of topics.Figure 4 shows the average Topic Coherence scoreof each model given different numbers of topics.From Figure 4, we note the following:1.
MC-LDA consistently achieves the highest To-pic Coherence scores given different numbersof topics.
M-LDA also works better than theother baseline models, but not as well as MC-LDA.
This shows that both m-sets and c-setsare beneficial in producing coherent aspects.2.
DF-LDA variants, DF-M and DF-MC, do notperform well due to the shortcomings discussedFigure 4.
Avg.
Topic Coherence score of each modelacross different number of topics.Figure 5.
Avg.
Topic Coherence score for differentproportions of knowledge.-1600-1500-1400-1300-12003 6 9 12 15MC-LDA M-LDA LDADF-M DF-MC LDA-GPU-1320-1300-1280-1260-12400% 25% 50% 100%MC-LDA M-LDA DF-M DF-MC1662in ?
1.
It is slightly better than LDA when ?
=15, but worse than LDA in other cases.
We willfurther analyze the effects of knowledge onMC-LDA and DF-LDA shortly.3.
LDA-GPU does not perform well due to its useof co-document frequency.
As frequent wordsusually have high co-document frequency withmany other words, the frequent words areranked top in many topics.
This shows that theguidance using domain knowledge is more ef-fective than using co-document frequency.In terms of improvements, MC-LDA outperformsM-LDA significantly ( ?
< 0.03 ) and all otherbaseline models significantly (?
< 0.01) based ona paired t-test.
It is important to note that by nomeans do we say that LDA-GPU and DF-LDA arenot effective.
We only say that for the task of as-pect extraction and leveraging domain knowledge,these models do not generate as coherent aspectsas ours because of their shortcomings discussed in?
1.
In general, with more topics, the Topic Coher-ence scores increase.
We found that when ?
islarger than 15, aspects found by each model be-came more and more overlapping, with severalaspects expressing the same features of products.So we fix ?
= 15 in the subsequent experiments.Effects of KnowledgeTo further analyze the effects of knowledge onmodels, in each domain, we randomly sampleddifferent proportions of knowledge (i.e., differentnumbers of m-sets/must-links and c-sets/cannot-links) as shown in Figure 5, where 0% means noknowledge (same as LDA and LDA-GPU, whichdo not incorporate knowledge) and 100% meansall knowledge.
From Figure 5, we see that MC-LDA and M-LDA both perform consistently betterthan DF-MC and DF-M across different propor-tions of knowledge.
With the increasing number ofknowledge sets, MC-LDA and M-LDA achievehigher Topic Coherence scores (i.e., produce morecoherent aspects).
In general, MC-LDA performsthe best.
For both DF-MC and DF-M, the TopicCoherence score increases from 0% to 25%knowledge, but decreases with more knowledge(50% and 100%).
This shows that with limitedamount of knowledge, the shortcomings of DF-LDA are not very obvious, but with moreknowledge, these issues become more serious andthus degrade the performance of DF-LDA.7.3 Human EvaluationSince our aim is to make topics more interpretableand conformable to human judgments, we workedwith two judges who are familiar with Amazonproducts and reviews to evaluate the models sub-jectively.
Since topics from topic models are rank-ings based on word probability and we do notknow the number of correct topical words, a natu-ral way to evaluate these rankings is to use Preci-sion@n (or p@n) which was also used in(Mukherjee and Liu, 2012; Zhao et al 2010),where n is the rank position.
We give p@n for n =5 and 10.
There are two steps in human evaluation:topic labeling and word labeling.Topic Labeling: We followed the instructions in(Mimno et al 2011) and asked the judges to labeleach topic as good or bad.
Each topic was present-ed as a list of 10 most probable words in descend-ing order of their probabilities under that topic.The models which generated the topics for label-ing were obscure to the judges.
In general, eachtopic was annotated as good if it had more thanhalf of its words coherently related to each otherrepresenting a semantic concept together; other-wise bad.
Agreement of human judges on topicFigure 6.
Avg.
p@5 of good topics for each modelacross different domains.The models of each bar from left to rights are MC-LDA, M-LDA, LDA, DF-M, DF-MC, LDA-GPU.
(Same for Figure 7)Figure 7.
Avg.
p@10 of good topics for each modelacross different domains.0.50.60.70.80.91.0Camera Food Computer CareMC-LDA M-LDA LDADF-M DF-MC LDA-GPU0.50.60.70.80.91.0Camera Food Computer CareMC-LDA M-LDA LDADF-M DF-MC LDA-GPU1663labeling using Cohen?s Kappa yielded a score of0.92 indicating almost perfect agreements accord-ing to the scale in (Landis and Koch, 1977).
Thisis reasonable as topic labeling is an easy task andsemantic coherence can be judged well by humans.Word Labeling: After topic labeling, we chosethe topics, which were labeled as good by bothjudges, as good topics.
Then, we asked the twojudges to label each word of the top 10 words inthese good topics.
Each word was annotated ascorrect if it was coherently related to the conceptrepresented by the topic; otherwise incorrect.Since judges already had the conception of eachtopic in mind when they were labeling topics, la-beling each word was not difficult which explainsthe high Kappa score for this labeling task (score =0.892).Quantitative ResultsFigures 6 and 7 give the average p@5 and p@10of all good topics over all four domains.
The num-bers of good topics generated by each model areshown in Table 3.
We can see that the humanevaluation results are highly consistent with TopicCoherence results in ?7.2.
MC-LDA improvesover M-LDA significantly (?
< 0.01) and bothMC-LDA and M-LDA outperforms the other base-line models significantly ( ?
< 0.005 ) using apaired t-test.
We also found that when the domainknowledge is simple with one word usually ex-pressing only one meaning/sense (e.g., in the do-main ?Computer?
), DF-LDA performs better thanLDA.
In other domains, it performs similarly orworse than LDA.
Again, it shows that DF-LDA isnot effective to handle complex knowledge, whichis consistent with the results of effects ofknowledge on DF-LDA in ?7.2.Qualitative ResultsWe now show some qualitative results to give anintuitive feeling of the outputs from different mod-els.
There are a large number of aspects that aredramatically improved by MC-LDA.
Due to spaceconstraints, we only show some examples.
To fur-ther focus, we just show some results of MC-LDA,M-LDA and LDA.
The results from LDA-GPUand DF-LDA were inferior and hard for the humanjudges to match them with aspects found by theother models for qualitative comparison.Table 4 shows three aspects Amazon, Price,Battery generated by each model in the domain?Camera?.
Both LDA and M-LDA can only dis-cover two aspects but M-LDA has a higher aver-age precision.
Given the c-set {amazon, price,battery}, MC-LDA can discover all three aspectswith the highest average precision.8 ConclusionThis paper proposed a new model to exploit do-main knowledge in the form of m-sets and c-setsto generate coherent aspects (topics) from onlinereviews.
The paper first identified and character-ized some shortcomings of the existingknowledge-based models.
A new model calledMC-LDA was then proposed, whose samplingscheme was based on the proposed Extended GPU(E-GPU) model enabling multi-urn interactions.
Acomprehensive evaluation using real-life onlinereviews from multiple domains shows that MC-LDA outperforms the state-of-the-art models sig-nificantly and discovers aspects with high seman-tic coherence.
In our future work, we plan toincorporate aspect specific sentiments in the MC-LDA model.AcknowledgmentsThis work was supported in part by a grant fromNational Science Foundation (NSF) under grant no.IIS-1111092, and a grant from HP Labs Innova-tion Research Program.#GoodTopicsMC-LDA M-LDA LDA DF-M DF-MC LDA-GPUCamera 15/18 12 11 9 7 3Food 8/16 7 7 5 4 5Computer 12/16 10 7 9 6 4Care 11/16 10 9 10 9 3Average 11.5/16.5 9.75/15 8.5/15 8.25/15 6.5/15 3.75/15Table 3.
Number of good topics of each model.In x/y, x is the number of discovered good topics, and y is thetotal number of topics generated.MC-LDA M-LDA LDAAmazon Price Battery Price Battery Amazon Batteryreview price battery price battery card batteryamazon perform life lot review day screensoftware money day money amazon amazon lifecustomer expensive extra big life memory lcdmonth cost charger expensive extra product watersupport week water point day sd usbwarranty cheap time cost power week cablepackage purchase power photo time month caseproduct deal hour dot support item chargerhardware product aa purchase customer class hourTable 4.
Example aspects in the domain ?Camera?
;errors are marked in red/italic.1664ReferencesAmjad Abu-Jbara, Ben King, Mona Diab, andDragomir Radev.
2013.
Identifying OpinionSubgroups in Arabic Online Discussions.
InProceedings of ACL.Apoorv Agarwal and Jasneet Sabharwal.
2012.
End-to-End Sentiment Analysis of Twitter Data.
InProceedings of the Workshop on InformationExtraction and Entity Analytics on Social MediaData, at the 24th International Conference onComputational Linguistics (IEEASMD-COLING2012), Vol.
2.David Andrzejewski, Xiaojin Zhu, and Mark Craven.2009.
Incorporating domain knowledge into topicmodeling via Dirichlet Forest priors.
In Proceedingsof ICML, pages 25?32.David Andrzejewski, Xiaojin Zhu, Mark Craven, andBenjamin Recht.
2011.
A framework forincorporating general domain knowledge into latentDirichlet alcation using first-order logic.
InProceedings of IJCAI, pages 1171?1177.Sasha Blair-goldensohn, Tyler Neylon, Kerry Hannan,George A. Reis, Ryan Mcdonald, and Jeff Reynar.2008.
Building a sentiment summarizer for localservice reviews.
In Proceedings of In NLP in theInformation Explosion Era.David M. Blei and Jon D. McAuliffe.
2007.
SupervisedTopic Models.
In Proceedings of NIPS.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet Allocation.
Journal ofMachine Learning Research, 3, 993?1022.S.
R. K. Branavan, Harr Chen, Jacob Eisenstein, andRegina Barzilay.
2008.
Learning Document-LevelSemantic Properties from Free-Text Annotations.
InProceedings of ACL, pages 263?271.Samuel Brody and Noemie Elhadad.
2010.
Anunsupervised aspect-sentiment model for onlinereviews.
In Proceedings of NAACL, pages 804?812.Nicola Burns, Yaxin Bi, Hui Wang, and TerryAnderson.
2012.
Extended Twofold-LDA Model forTwo Aspects in One Sentence.
Advances inComputational Intelligence, Vol.
298, pages 265?275.
Springer Berlin Heidelberg.Giuseppe Carenini, Raymond T. Ng, and Ed Zwart.2005.
Extracting knowledge from evaluative text.
InProceedings of K-CAP, pages 11?18.Jonathan Chang, Jordan Boyd-Graber, Wang Chong,Sean Gerrish, and David Blei, M. 2009.
Reading TeaLeaves: How Humans Interpret Topic Models.
InProceedings of NIPS, pages 288?296.Zhiyuan Chen, Arjun Mukherjee, Bing Liu, MeichunHsu, Malu Castellanos, and Riddhiman Ghosh.2013a.
Leveraging Multi-Domain Prior Knowledgein Topic Models.
In Proceedings of IJCAI, pages2071?2077.Zhiyuan Chen, Arjun Mukherjee, Bing Liu, MeichunHsu, Malu Castellanos, and Riddhiman Ghosh.2013b.
Discovering Coherent Topics Using GeneralKnowledge.
In Proceedings of CIKM.Yejin Choi and Claire Cardie.
2010.
HierarchicalSequential Learning for Extracting Opinions andtheir Attributes, pages 269?274.Lei Fang and Minlie Huang.
2012.
Fine GranularAspect Analysis using Latent Structural Models.
InProceedings of ACL, pages 333?337.Thomas L. Griffiths and Mark Steyvers.
2004.
FindingScientific Topics.
PNAS, 101 Suppl, 5228?5235.Honglei Guo, Huijia Zhu, Zhili Guo, Xiaoxun Zhang,and Zhong Su.
2009.
Product feature categorizationwith multilevel latent semantic association.
InProceedings of CIKM, pages 1087?1096.Gregor Heinrich.
2009.
A Generic Approach to TopicModels.
In Proceedings of ECML PKDD, pages 517?
532.Minqing Hu and Bing Liu.
2004.
Mining andSummarizing Customer Reviews.
In Proceedings ofKDD, pages 168?177.Yuening Hu, Jordan Boyd-Graber, and BriannaSatinoff.
2011.
Interactive Topic Modeling.
InProceedings of ACL, pages 248?257.Hemant Ishwaran and LF James.
2001.
Gibbs samplingmethods for stick-breaking priors.
Journal of theAmerican Statistical Association, 96(453), 161?173.Jagadeesh Jagarlamudi, Hal Daum?
III, andRaghavendra Udupa.
2012.
Incorporating LexicalPriors into Topic Models.
In Proceedings of EACL,pages 204?213.Niklas Jakob and Iryna Gurevych.
2010.
ExtractingOpinion Targets in a Single- and Cross-DomainSetting with Conditional Random Fields.
InProceedings of EMNLP, pages 1035?1045.Yohan Jo and Alice H. Oh.
2011.
Aspect and sentimentunification model for online review analysis.
InProceedings of WSDM, pages 815?824.Alistair Kennedy and Diana Inkpen.
2006.
SentimentClassification of Movie Reviews Using ContextualValence Shifters.
Computational Intelligence, 22(2),110?125.Jungi Kim, Jinji Li, and Jong-Hyeok Lee.
2009.Discovering the Discriminative Views: MeasuringTerm Weights for Sentiment Analysis.
InProceedings of ACL/IJCNLP, pages 253?261.Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, andShixia Liu.
2013.
A Hierarchical Aspect-SentimentModel for Online Reviews.
In Proceedings of AAAI.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting Aspect-Evaluation and Aspect-ofRelations in Opinion Mining.
In Proceedings ofEMNLP, pages 1065?1074.Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen.
2006.Opinion Extraction, Summarization and Tracking in1665News and Blog Corpora.
In Proceedings of AAAISpring Symposium: Computational Approaches toAnalyzing Weblogs, pages 100?107.JR Landis and GG Koch.
1977.
The measurement ofobserver agreement for categorical data.
biometrics,33.Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder.2013.
A Bayesian Model for Joint UnsupervisedInduction of Sentiment, Aspect and DiscourseRepresentations.
In Proceedings of ACL.Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,Yingju Xia, Shu Zhang, and Hao Yu.
2010.Structure-Aware Review Mining andSummarization.
In Proceedings of COLING, pages653?661.Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, andXiaoyan Zhu.
2012a.
Cross-Domain Co-Extractionof Sentiment and Topic Lexicons.
In Proceedings ofACL (1), pages 410?419.Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang.
2011.Generating Aspect-oriented Multi-DocumentSummarization with Event-aspect model.
InProceedings of EMNLP, pages 1137?1146.Shoushan Li, Rongyang Wang, and Guodong Zhou.2012b.
Opinion Target Extraction Using a ShallowSemantic Parsing Framework.
In Proceedings ofAAAI.Chenghua Lin and Yulan He.
2009.
Jointsentiment/topic model for sentiment analysis.
InProceedings of CIKM, pages 375?384.Bing Liu.
2012.
Sentiment Analysis and OpinionMining.
Morgan & Claypool Publishers.Bin Lu, Myle Ott, Claire Cardie, and Benjamin K.Tsou.
2011.
Multi-aspect Sentiment Analysis withTopic Models.
In Proceedings of ICDM Workshops,pages 81?88.Yue Lu, Hongning Wang, ChengXiang Zhai, and DanRoth.
2012.
Unsupervised discovery of opposingopinion networks from forum discussions.
InProceedings of CIKM, pages 1642?1646.Yue Lu and Chengxiang Zhai.
2008.
Opinionintegration through semi-supervised topic modeling.In Proceedings of WWW, pages 121?130.Yue Lu, ChengXiang Zhai, and Neel Sundaresan.
2009.Rated aspect summarization of short comments.
InProceedings of WWW, pages 131?140.Hosam Mahmoud.
2008.
Polya Urn Models.
Chapman& Hall/CRC Texts in Statistical Science.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and ChengXiang Zhai.
2007.
Topic sentimentmixture: modeling facets and opinions in weblogs.
InProceedings of WWW, pages 171?180.Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou,Sujian Li, and Houfeng Wang.
2012.
Entity-centrictopic-oriented opinion summarization in twitter.
InProceedings of KDD, pages 379?387.George A. Miller.
1995.
WordNet: A Lexical Databasefor English.
Commun.
ACM, 38(11), 39?41.David Mimno, Hanna M. Wallach, Edmund Talley,Miriam Leenders, and Andrew McCallum.
2011.Optimizing semantic coherence in topic models.
InProceedings of EMNLP, pages 262?272.Samaneh Moghaddam and Martin Ester.
2011.
ILDA:interdependent LDA model for learning latentaspects and their ratings from online productreviews.
In Proceedings of SIGIR, pages 665?674.Saif Mohammad, Cody Dunne, and Bonnie J. Dorr.2009.
Generating High-Coverage SemanticOrientation Lexicons From Overtly Marked Wordsand a Thesaurus.
In Proceedings of EMNLP, pages599?608.Arjun Mukherjee and Bing Liu.
2012.
AspectExtraction through Semi-Supervised Modeling.
InProceedings of ACL, pages 339?348.David Newman, Youn Noh, Edmund Talley, SarvnazKarimi, and Timothy Baldwin.
2010.
Evaluatingtopic models for digital libraries.
In Proceedings ofJCDL, pages 215?224.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends inInformation Retrieval, 2(1-2), 1?135.James Petterson, Alex Smola, Tib?rio Caetano, WrayBuntine, and Shravan Narayanamurthy.
2010.
WordFeatures for Latent Dirichlet Allocation.
InProceedings of NIPS, pages 1921?1929.AM Popescu and Oren Etzioni.
2005.
Extractingproduct features and opinions from reviews.
InProceedings of HLT, pages 339?346.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011.Opinion Word Expansion and Target Extractionthrough Double Propagation.
ComputationalLinguistics, 37(1), 9?27.Daniel Ramage, David Hall, Ramesh Nallapati, andChristopher D. Manning.
2009.
Labeled LDA: asupervised topic model for credit attribution in multi-labeled corpora.
In Proceedings of EMNLP, pages248?256.Christina Sauper and Regina Barzilay.
2013.
AutomaticAggregation by Joint Modeling of Aspects andValues.
J. Artif.
Intell.
Res.
(JAIR), 46, 89?127.Christina Sauper, Aria Haghighi, and Regina Barzilay.2011.
Content Models with Attitude.
In Proceedingsof ACL, pages 350?358.Swapna Somasundaran and J. Wiebe.
2009.Recognizing stances in online debates.
InProceedings of ACL, pages 226?234.Keith Stevens and PKDAD Buttler.
2012.
ExploringTopic Coherence over many models and manytopics.
In Proceedings of EMNLP-CoNLL, pages952?961.Veselin Stoyanov and Claire Cardie.
2011.Automatically Creating General-Purpose Opinion1666Summaries from Text.
In Proceedings of RANLP,pages 202?209.Yee Whye Teh, Michael I. Jordan, Matthew J. Beal,and David M. Blei.
2006.
Hierarchical dirichletprocesses.
Journal of the American StatisticalAssociation, 1?30.Ivan Titov and Ryan McDonald.
2008.
Modeling onlinereviews with multi-grain topic models.
InProceedings of WWW, pages 111?120.Dong Wang and Yang Liu.
2011.
A Pilot Study ofOpinion Summarization in Conversations.
InProceedings of ACL, pages 331?339.Hongning Wang, Yue Lu, and Chengxiang Zhai.
2010.Latent aspect rating analysis on review text data: arating regression approach.
In Proceedings of KDD,pages 783?792.Hongning Wang, Yue Lu, and ChengXiang Zhai.
2011.Latent aspect rating analysis without aspect keywordsupervision.
In Proceedings of KDD, pages 618?626.Janyce Wiebe and Ellen Riloff.
2005.
CreatingSubjective and Objective Sentence Classifiers fromUnannotated Texts.
In Proceedings of CICLing,pages 486?497.Janyce Wiebe, Theresa Wilson, Rebecca F. Bruce,Matthew Bell, and Melanie Martin.
2004.
LearningSubjective Language.
Computational Linguistics,30(3), 277?308.Michael Wiegand and Dietrich Klakow.
2010.Convolution Kernels for Opinion Holder Extraction.In Proceedings of HLT-NAACL, pages 795?803.Yuanbin Wu, Qi Zhang, Xuanjing Huang, and LideWu.
2009.
Phrase dependency parsing for opinionmining.
In Proceedings of EMNLP, pages 1533?1541.Yuanbin Wu, Qi Zhang, Xuanjing Huang, and LideWu.
2011.
Structural Opinion Mining for Graph-based Sentiment Representation.
In Proceedings ofEMNLP, pages 1332?1341.Yunqing Xia, Boyi Hao, and Kam-Fai Wong.
2009.Opinion Target Network and Bootstrapping Methodfor Chinese Opinion Target Extraction.
InProceedings of AIRS, pages 339?350.Jianxing Yu, Zheng-Jun Zha, Meng Wang, and Tat-Seng Chua.
2011.
Aspect Ranking: IdentifyingImportant Product Aspects from Online ConsumerReviews.
In Proceedings of ACL, pages 1496?1505.Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia.
2011.Constrained LDA for grouping product features inopinion mining.
In Proceedings of the 15th Pacific-Asia Conference on Knowledge Discovery and DataMining (PAKDD), pages 448?459.Lei Zhang and Bing Liu.
2011.
Identifying NounProduct Features that Imply Opinions.
InProceedings of ACL (Short Papers), pages 575?580.Wayne Xin Zhao, Jing Jiang, Hongfei Yan, andXiaoming Li.
2010.
Jointly Modeling Aspects andOpinions with a MaxEnt-LDA Hybrid.
InProceedings of EMNLP, pages 56?65.Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao.
2012.Cross-Language Opinion Target Extraction inReview Texts.
In Proceedings of ICDM, pages1200?1205.Li Zhuang, Feng Jing, and Xiao-Yan Zhu.
2006.
Moviereview mining and summarization.
In Proceedings ofCIKM, pages 43?50.
ACM Press.1667
