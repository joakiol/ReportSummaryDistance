Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries, ACL-IJCNLP 2009, pages 27?35,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPClassification of Research Papers into a Patent Classification SystemUsing Two Translation ModelsHidetsugu anbaHiroshima City University3-4-1 Ozukahigashi, Hiroshima 731-3194 Japannanba@hiroshima-cu.ac.jpToshiyuki TakezawaHiroshima City University3-4-1 Ozukahigashi, Hiroshima 731-3194 Japantakezawa@hiroshima-cu.ac.jpAbstractClassifying research papers into patent classi-fication systems enables an exhaustive and ef-fective invalidity search, prior art search, andtechnical trend analysis.
However, it is verycostly to classify research papers manually.Therefore, we have studied automatic classifi-cation of research papers into a patent classifi-cation system.
To classify research papers intopatent classification systems, the differences interms used in research papers and patentsshould be taken into account.
This is becausethe terms used in patents are often more ab-stract or creative than those used in researchpapers in order to widen the scope of theclaims.
It is also necessary to do exhaustivesearches and analyses that focus on classifica-tion of research papers written in various lan-guages.
To solve these problems, we proposesome classification methods using two ma-chine translation models.
When translatingEnglish research papers into Japanese, the per-formance of a translation model for patents isinferior to that for research papers due to thedifferences in terms used in research papersand patents.
However, the model for patents isthought to be useful for our task because trans-lation results by patent translation models tendto contain more patent terms than those for re-search papers.
To confirm the effectiveness ofour methods, we conducted some experimentsusing the data of the Patent Mining Task in theNTCIR-7 Workshop.
From the experimentalresults, we found that our method using trans-lation models for both research papers and pa-tents was more effective than using a singletranslation model.1 IntroductionClassification of research papers into patent clas-sification systems makes it possible to conductan exhaustive and effective prior art search, inva-lidity search, and technical trend analysis.
How-ever, it would be too costly and time-consumingto have the research paper's authors or anotherprofessional classify such documents manually.Therefore, we have investigated the classificationof research papers into a patent classificationsystem.In previous studies, classification of patentswas conducted as subtasks in the 5th and 6thNTCIR workshops (Iwayama et al, 2005;Iwayama et al, 2007).
In these subtasks, partici-pants were asked to classify Japanese patentsusing the File Forming Term (F-term) system,which is a classification system for Japanese pa-tents.
Here, we have focused on the classificationof research papers, and we need to take into ac-count the differences in terms used in researchpapers and patents because the terms used in pa-tents are often more abstract or creative thanthose used in research papers in order to widenthe scope of the claims.
For example, the scho-larly term "machine translation" can be ex-pressed as "automatic translation" or "languageconversion" in patent documents.
In addition totaking the differences of genres into account, it isnecessary to do exhaustive searches and analysesfocusing on the classification of research paperswritten in various languages.To solve these problems, we propose someclassification methods using two machine trans-lation models.
When translating English researchpapers into Japanese, the performance of a trans-lation model for patents is generally inferior tothat for research papers, because the terms used27in patents are different from those in researchpapers.
However, we thought that a translationmodel for patents might be useful for our task,because translation results using the patent trans-lation model tend to contain more patent termsthan those obtained using the model for researchpapers.
In this paper, we confirm the effective-ness of our methods using the data of the Cross-genre Subtask (E2J) in the 7th NTCIR Workshop(NTCIR-7) Patent Mining Task (Nanba et al,2008:b).The remainder of this paper is organized asfollows.
Section 2 describes related work.
Sec-tion 3 describes our methods.
To investigate theeffectiveness of our methods, we conductedsome experiments, and Section 4 reports the ex-perimental results.
We present some conclusionsin Section 5.2 Related WorkIn this section, we describe some related studieson "cross-genre information access" and "cross-lingual information access".Cross-genre Information AccessMuch research has been done in the field ofcross-genre information retrieval and documentclassification.
The technical survey task in theNTCIR-3 workshop (Iwayama et al, 2002) is anexample.
This task aimed to retrieve patents re-levant to a given newspaper article.
In this task,Itoh et al (2002) focused on "Term Distillation".The distribution of the frequency of the occur-rence of words was known to be different be-tween newspaper articles and patents.
For exam-ple, the word "president" often appears in news-paper articles, while this word seldom appears inpatents.
As a result, unimportant words such as"president" were assigned high scores in patentswhen using tf*idf to weight words.
Term Distil-lation is a technique that can prevent such casesby filtering out words that can be assigned incor-rect weights.
This idea was also used to linknews articles and blog entries (Ikeda et al, 2006).Another approach for cross-genre informationretrieval was that used by Nanba et al (2008:a),who proposed a method to integrate a researchpaper database and a patent database by analyz-ing citation relations between research papersand patents.
For the integration, they extractedbibliographic information of cited literature in"prior art" fields in Japanese patent applications.Using this integrated database, users can retrievepatents that relate to a particular research paperby tracing citation relations between researchpapers and patents.
However, the number ofcited papers among patent applications is notsufficient to retrieve related papers or patents,even though the number of opportunities for cit-ing papers in patents or for citing patents in pa-pers has been increasing recently.As another approach for cross-genre informa-tion retrieval, Nanba et al (2009) proposed amethod to paraphrase scholarly terms into patentterms (e.g., paraphrasing "floppy disc" into"magnetic recording medium").
They focused oncitation relationships between research papersand patents for the paraphrased terms.
Generally,a research paper and a patent that have a citationrelationship tend to be in the same research field.Therefore, they paraphrased a scholarly term intoa patent term in two steps: (1) retrieve researchpapers that contain a given scholarly term in theirtitles, and (2) extract patent terms from patentsthat have citation relations with the retrieved pa-pers.The NTCIR-7 Patent Mining Task (Nanba etal., 2008:b) is another example of research doneon information access using research papers andpatents.
The aim of the Patent Mining Task wasto classify research papers written in either Japa-nese or English using the International PatentClassification (IPC) system, which is a globalstandard hierarchical patent classification system.The following four subtasks were included inthis task, and 12 groups participated in three ofthem: Japanese, English, and Cross-lingual (J2E)subtasks. Japanese subtask: classification of Japa-nese research papers using patent data writ-ten in Japanese. English subtask: classification of Englishresearch papers using patent data written inEnglish. Cross-lingual subtask (J2E): classificationof Japanese research papers using patent da-ta written in English. Cross-lingual subtask (E2J): classificationof English research papers using patent datawritten in Japanese.Because the number of categories (IPC codes)that research papers were classified into was verylarge (30,855), only two participating groupsemployed machine learning, which is the moststandard approach in the NLP field.
The othergroups used the k-Nearest Neighbor (k-NN) me-thod.
Among all participant groups, only Maseand Iwayama's group (2008) coped with theproblem of the differences in terms between re-28search papers and patents.
Mase and Iwayamaused a pseudo-relevance feedback method to col-lect related patent terms for a given research pa-per.
First, they retrieved patents relevant to agiven research paper.
Next, they extracted patentterms from the top n retrieved patents.
Then theyretrieved patents again using the patent termsextracted in the second step.
Finally, they classi-fied research papers using the k-NN method.However, they reported that a simple k-NNbased method was superior to the method basedon the pseudo-relevance feedback method.
Inthis paper, we also examined our methods usingthe data of the NTCIR-7 Patent Mining Task.TREC Chemistry Track 1  is another relatedstudy involving research papers and patents.
Thistrack aims for cross-genre information retrievalusing research papers and patents in the chemicalfield.
This track started in 2009 under the TextRetrieval Conference (TREC), and the detailsincluding experimental results will be reported atthe final meeting to be held in November 2009.Cross-lingual Information AccessMuch research has been done on cross-lingualinformation access using research papers andpatents.
In the NTCIR workshop, cross-lingualinformation retrieval tasks have been carried outusing research papers (Kando et al, 1999; Kandoet al, 2001) and patents (Fujii et al, 2004; Fujiiet al, 2005; Fujii et al, 2007).
In the CLEFevaluation workshop, the cross-lingual patentretrieval task "CLEF-IP" was initiated in 20092.The cross-lingual subtask in the NTCIR-7 PatentMining Task (Nanba et al, 2008:b) is anothercross-lingual information access study.Here, we describe two methods used in thecross-lingual subtask (J2E) in the Patent MiningTask (Bian and Teng, 2008, Clinchant and Rend-ers, 2008).
Bian and Teng (2008) translated Jap-anese research papers into English using threeonline translation systems (Google, Excite, andYahoo!
Babel Fish), and classified them using ak-NN-based text classifier.
Clinchant and Rend-ers (2008) automatically obtained a Japanese-English bilingual dictionary from approximately300,000 pairs of titles from Japanese and Englishresearch papers (Kando et al, 1999) using Giza3,a statistical machine translation toolkit.
Then1 https://wiki.ir-facility.org/index.php/TREC_Chemistry_Track2 http://www.ir-facility.org/the_irf/current-projects/clef-ip09-track/3 http://www.fjoch.com/GIZA++.htmlthey classified papers using this dictionary and ak-NN-based document classifier.
Bian and Clin-chant also participated in an English subtask andobtained almost the same mean average precision(MAP) scores as those of the J2E subtask.Although the direction of translation of oursystem is different from Bian and Clinchant, wealso tried our methods using the data of thecross-lingual subtask (E2J).
We utilized the Gizatoolkit in the same way as Clinchant, but our ap-proach was different from Clinchant, because wesolved the problem of "differences of terms usedin research papers and patents" by using twotranslation models obtained from both researchpapers and patents parallel corpora.3 Classification of Research Papers intoa Patent Classification System3.1 Our MethodsWe explain here the procedure of our cross-genre,cross-lingual document classification methoddepicted in Figure 1.
The goal of our task is toclassify document I written in language L1 ingenre G1 into a classification system (categories)using documents written in language L2 in genreG2, and classification codes were manually an-notated to each of these documents.
Generally,three steps are required for cross-genre, cross-lingual document classification: (1) translatedocument I into Language L2 using a translationmodel for genre G1 (document O in Figure 1),(2) paraphrase terms in document O into terms ingenre G2 (document O'), and (3) classify O' intoa classification system.
Here, if a translationmodel for genre G2 is available, steps (1) and (2)can be resolved using this translation model, be-cause terms in the translation results using themodel are more appropriate in genre G2.
How-ever, as it is assumed that the translation modeltranslates documents in genre G2, the translationresults might contain more mistranslations thanthe results obtained by a model for genre G1.
Wetherefore combine translation results (O+O')produced by translation models for genre G1 andfor G2.
These results can be expected to containterms in genre G2 and to minimize the effects ofmistranslation by using the translation model forgenre G1.29Figure 1: Overview of our method3.2 System ConfigurationThe goal of our study is to classify English re-search papers (Language L1=English, GenreG1=research papers) into a patent classificationusing a patent data set written in Japanese (Lan-guage L2=Japanese, Genre G2=patents).
Figure2 shows the system configuration.
Our system iscomprised of a "Japanese index creating module"and a "document classification module".
In thefollowing, we explain both modules.Figure 2: System configurationJapanese Index Creating ModuleWhen a title and abstract pair, as shown in Figure3, is given, the module creates a Japanese index,shown in Figure 44, using translation models forresearch papers and for patents.Here, the following two procedures (A) or (B)are possible for creating a Japanese index froman English paper: (A) translate the English titleand abstract into Japanese; then create a Japanese4 Numerical values shown with index terms indicateterm frequencies.index from them by extracting content terms5, or(B) create an English index6  from the Englishtitle and abstract, then translate each index terminto Japanese.
We conducted experiments usingboth procedures.As translation tools, we used Giza and Moses7.We obtained translation models using a patentbilingual corpus containing 1,800,000 pairs ofsentences (Fujii et al 2008) and a research paperbilingual corpus containing 300,000 pairs auto-matically created from datasets of NTCIR-1(Kando et al 1999), and 2 (Kando et al 2001)CLIR tasks.Title: A Sandblast-Processed Color-PDP Phos-phor ScreenAbstract: Barrier ribs in the color PDP haveusually been fabricated by multiple screen print-ing.
However, the precise rib printing of fine pat-terns for the high resolution display panel is dif-ficult to make well in proportion as the panel sizegrow larger.
On the other hand, luminance andluminous efficiency of reflective phosphorscreen will be expected to increase when thephosphor is deposited on the inner wall of dis-play cells.
Sandblasting technique has been ap-plied to make barrier ribs for the high resolutionPDP and nonffat phosphor screens on the innerwall of display cells.Figure 3: Example of an English title and abstract18 ??
(formation)18 ???
(PDP)18 ????
(type phosphor screen)12 ????
(barrier formation)12 ??
(barrier)12 ??
(phosphor)12 ??????
(color PDP)12 ?????
(reflective phosphor)12 ???
(type phosphor)12 ????????
(Sandblasting technique)9 ???????
(Sandblasting)(snip)Figure 4: Example of a Japanese index5 As content terms, we extracted noun phrases (seriesof nouns), adjectives, and verbs using the Japanesemorphological analyzer MeCab.
(http://mecab.sourceforge.net)6 We used TreeTagger as a POS tagging tool.
(http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/)7 http://www.statmt.org/moses/Lang.L1Lang.L2Genre G2 Genre G1IOO's ??
(1)(2)Our methodJapanese IndexCreating ModuleDocument Classifica-tion ModulePatent Data writtenin JapaneseList of IPC CodesOur systemEnglish paperCorrect dataComparisonand Evaluation30We used two phrase tables for research papersand patents when translating English index termsinto Japanese.
For a given English term, we se-lected the Japanese term with the highest transla-tion probability from the candidates in each table.These tables were automatically obtained in theprocess of constructing translation models forresearch papers and patents using Giza and Mos-es.
However, there are several other ways totranslate index terms, such as using bilingualdictionaries of technical terms or compositionalsemantics (Tonoike et al, 2007), we employed aphrase table-based method because the effective-ness of this method was experimentally con-firmed by Itakagi et al (2007).
In addition to thismethod, we also investigated using bilingual dic-tionaries of technical terms as baseline methods.Details of these methods are in Section 4.2.Document Classification ModuleWe used Nanba's k-NN-based system (Nanba,2008:c) for a Japanese subtask as a documentclassification module in our system.
This moduleuses a patent retrieval engine (Nanba, 2007)which was developed for the NTCIR-6 PatentRetrieval Task (Fujii et al, 2007).
This engineintroduced the Vector Space Model as a retrievalmodel, SMART (Salton, 1971) for term weight-ing, and noun phrases (sequence of nouns), verbs,and adjectives for index terms.
The classificationmodule obtained a list of IPC codes using thefollowing procedure.1.
Retrieve top 170 results using the patentretrieval engine for a given research paper.2.
Extract IPC codes with relevance scores forthe query from each retrieved patent in step1.3.
Rank IPC codes using the following equa-tion.nScore(X) = ?
Relevance score of each patenti=1Here, X and n indicate the IPC code and thenumber of patents that X was assigned to withinthe top 170 retrieved patents, respectively.
Nanbadetermined the value of 170 using the dry rundata and the training data of the NTCIR-7 PatentMining Task.3.3 Classification of Research Papers intoInternational Patent Classification(IPC)As a patent classification system for classifica-tion of research papers, we employed the Interna-tional Patent Classification (IPC) system.
TheIPC system is a global standard hierarchical pa-tent classification system.
The sixth edition ofthe IPC contains more than 50,000 classes at themost detailed level8.
The goal of our task was toassign one or more of these IPC codes at themost detailed level to a given research paper.4 ExperimentsTo investigate the effectiveness of our method,we conducted some experiments.
Section 4.1describes the experimental procedure.
Section4.2 explains several methods that were comparedin the experiments.
Section 4.3 reports the expe-rimental results, and Section 4.4 discusses them.4.1 Experimental MethodWe conducted some experiments using the dataof the cross-lingual subtask (E2J) in the NTCIR-7 Patent Mining Task.Correct data setWe used a data set for the formal run of thecross-lingual subtask in the NTCIR-7 PatentMining Task (Nanba, et al, 2008).
In the data set,IPC codes were manually assigned to each 879topics (research papers).
For each topic, an aver-age of 2.3 IPC codes was manually assigned.These correct data were compared with a list ofIPC codes 9  by systems, and the systems wereevaluated in terms of MAP (mean average preci-sion).
Here, the 879 topics were divided into twogroups: group A, in which highly relevant IPCcodes were assigned to 473 topics, and group B,in which relevant IPC codes were assigned to406 topics.
In our experiment, we evaluated sev-eral systems in two ways: using group A onlyand using both groups.Document SetsAn overview of document sets used in our expe-riments is in Table 1.
In the unexamined Japa-nese patent applications, manually assigned IPCcodes are included together with full text patentdata.
These data were utilised to apply the k-NNmethod in our document classification module.NTCIR-1 and 2 CLIR Task test collections wereused to obtain a translation model for researchpapers, which we mentioned in Section 3.2.8 Among 50,000 classes, 30,855 classes relevant toacademic fields were used in the NTCIR-7 PatentMining Task.9 The maximum number of IPC codes allowed to beoutput for a single topic was 1,000.31Table 1: Document sets4.2 AlternativesWe conducted examinations using seven baselinemethods, three proposed methods, and two up-per-bound methods shown as follows.
In the fol-lowing, "SMT(X)" is a method to create a Japa-nese index after translating research papers usinga translation model X.
"Index(X)" is a method tocreate an English index, and to translate the in-dex terms using a phrase table for translationmodel X.Baseline methods SMT(Paper): Create a Japanese index aftertranslating research papers using a transla-tion model for research papers. SMT(Patent): Create a Japanese index aftertranslating research papers using a modelfor patents. Index(Paper): First create an English index,then translate the index terms into Japaneseusing a phrase table for research papers. Index(Patent): First create an English index,then translate the index terms into Japaneseusing a phrase table for patents. SMT(Paper)+Hypernym: Paraphrase indexterms created from "SMT(Paper)" by theirhypernyms using a hypernym-hyponym the-saurus. Index(TechDic): Translate English indexterms using a Japanese-English dictionaryconsisting of 450,000 technical terms10. Index(EIJIRO): Translate English indexterms using EIJIRO 11 , a Japanese-Englishdictionary consisting of more than1,000,000 pairs of terms.Our methods Index(Paper)*Index(Patent): Product set of"Index(Paper)" and "Index(Patent)". Index(Paper)+Index(Patent): Union of "In-dex(Paper)" and "Index(Patent)".10 "Kagakugijutsu 45 mango taiyakujiten" NichigaiAssociates, Inc., 2001.11 http://www.eijiro.jp/ SMT(Paper)+Index(Patent): Union of"SMT(Paper)" and "Index(Patent)".Upper-bound methods Japanese subtask: This is the same as theJapanese subtask in the NTCIR-7 PatentMining Task.
For this subtask, Japanese re-search papers, which are manual (ideal)translations of corresponding English papers,are input into a system. Japanese subtask+Index(Patent): Union of"Japanese subtask" and "Index(Patent)".Another reason for using the baseline methods isthat the terms used in patents are often more ab-stract or creative than those used in research pa-pers, as mentioned in Section 1.
Therefore, weparaphrased index terms in SMT(Paper) by theirhypernyms using a hypernym/hyponym thesau-rus (Nanba, 2007).
Nanba automatically createdthis thesaurus consisting of 1,800,000 terms from10 years of unexamined Japanese patent applica-tions using a set of patterns, such as "NP0 ya NP1nadono NP2 (NP2 such as NP0 and NP1)" (Hearst,1992).4.3 Experimental ResultsExperimental results are given in Table 2.
Fromthe results, we can see that "SMT(Paper)" ob-tained the highest MAP scores when using topicsin group A+B and in group A.
Of the 10 methodsused (except for the upper-bound methods), ourmethod "SMT(Paper)+Index(Patent)" obtainedthe highest MAP score.4.4 DiscussionDifference of terms between research and pa-tents (Comparison of "Index(Paper)" and"Index(Patent)")Although the quality of phrase tables for researchpapers ("Index(Paper)") and patents  ("In-dex(Patent)") was not very different, the MAPscore of "Index(Paper)" was 0.01 better than thatof "Index(Patent)".
To investigate this gap, wecompared Japanese indices by "Index(Paper)"and "Index(Patent)".
There were 69,100 Englishindex terms in total, and 47,055 terms(47,055/69,100=0.681) were translated by themodel for research papers, while 40,427 terms(40,427/69,100=0.585) were translated by themodel for patents.
Ten percent of this gap indi-cates that terms used in research papers and inpatents are different, which causes the gap inMAP scores of "Index(Patent)" and "In-dex(Paper)".Data Year Size o.  Lang.UnexaminedJapanesepatent appli-cations1993-2002100GB3.50MJapaneseNTCIR-1and 2 CLIRTask1988-19991.4GB0.26MJapanese/English32Combination of "Index(Paper)" and "In-dex(Patent)"When a term translated by the model for researchpapers matches a term translated by the modelfor patents, they seem to be a correct translation.Therefore, we examined "In-dex(Paper)*Index(Patent)".
The method usesterms as an index when translation results byboth models match.
From the experimental re-sults, this method obtained 0.1830 and 0.2230 ofMAP scores when using topics in group A+Band in group A, respectively.
These results indi-cate that the overlap of lexicons between re-search papers and patents is relatively large, andterms in this overlap are effective for our task.However, the MAP score of "In-dex(Paper)*Index(Patent)" was 0.02 lower than"Index(Paper)" and "Index(Patent)", which indi-cates that there are not enough terms in the over-lap for our task.In addition to "Index(Paper)*Index(Patent)",we also examined "Index(Paper)+Index(Patent)",which is a union of "Index(Paper)" and "In-dex(Patent)".
From the experimental results, weobtained respective MAP scores of 0.2258 and0.2596 when using topics in group A+B and ingroup A.
These scores are 0.01 to 0.02 higherthan the scores of "Index(Paper)" and "In-dex(Patent)".
These encouraging results indicatethat our method using two translation models iseffective for a cross-genre document classifica-tion task.Effectiveness of "SMT(Paper)+Index(Patent)"In addition to "Index(Paper)", "SMT(Paper)"also obtained high MAP scores.
Therefore, wecombined "Index(Patent)" with "SMT(Paper)"instead of "Index(Paper)".
From the experimentalresults, we found that this approach("SMT(Paper)+Index(Patent)") produced MAPscores of 0.2633 when using topics in groupA+B and 0.2807 when using topics in group A.These scores were the highest of all, almost ap-proaching the results of upper-bound methods.Comparison of "Index(TechDic)", "In-dex(EIJIRO)", "Index(Paper)", and "In-dex(Patent)"Both "Index(TechDic)" and "Index(EIJIRO)"were worse than "Index(Paper)" and "In-dex(Patent)" by more than 0.05 in the MAPscores.
These results were due to the lower num-ber of terms translated by each method.
Becausephrase tables for research papers and patentswere automatically created, they were not as cor-rect as "TechDic" and "EIJIRO".
However, thephrase tables were able to translate more Englishterms into Japanese in comparison with "Tech-Dic" (30,008/69,100=0.434) and "EIJIRO"(37607/69,100=0.544), and these induced thedifference of MAP scores.Comparison of "SMT(Paper)+Hypernym"and "SMT(Paper)""SMT(Paper)+Hypernym" impaired"SMT(Paper)", because the method paraphrasedunnecessary terms into their hypernyms.
As aresult, irrelevant patents were contained withinthe top 170 search results, and the k-NN methodranked irrelevant IPC codes at higher levels.
Ourmethods using two translation models are differ-ent from "SMT(Paper)+Hypernym" in this pointbecause two translation models translate into thesame term when a scholarly term need not beparaphrased.Classification of Japanese research papersusing "Index(Patent)"As we mentioned above, the "In-dex(Paper)+Index(Patent)" and"SMT(Paper)+Index(Patent)" models improvedthe MAP scores of both "Index(Paper)" and"SMT(Paper)".
We further investigated whether"Index(Patent)" could also improve monolingualdocument classification ("Japanese sub-task+Index(Patent)").
In this method, a Japaneseindex was created from a manually written Japa-nese research paper, and this was combined with"Index(Patent)".
The results showed that "Japa-nese subtask+Index(Patent)" could slightly im-prove MAP scores when using topics in groupA+B and in group A.Practicality of our methodRecall values for the top n results by"SMT(Paper)+Index(Patent)", which obtainedthe highest MAP score, are in Table 3.
In thistable, the results using all topics (group A+B)and the topics in group A are shown.
The resultsindicate that almost 40% of the IPC codes werefound within top 10 results, and 70% were foundwithin the top 100.
For practical use, we need toimprove recall at the top 1, but we still believethat these results are useful for supporting begin-ners in patent searches.
It is often necessary forsearchers to use patent classification codes foreffective patent retrieval, but professional skilland much experience are required to select rele-vant IPC codes.
In such cases, our method is use-ful to look for relevant IPC codes.335 ConclusionWe proposed several methods that automaticallyclassify research papers into the IPC system us-ing two translation models.
To confirm the effec-tiveness of our method, we conducted some ex-aminations using the data of the NTCIR-7 PatentMining Task.
The results showed that one of ourmethods "SMT(Paper)+Index(Patent)" obtaineda MAP score of 0.2897.
This score was higherthan that of "SMT(Paper)", which used transla-tion results by the translation model for researchpapers, and this indicates that our method is ef-fective for cross-genre, cross-lingual documentclassification.rank group A group A+B1 0.117 (131/1115) 0.110 (  226/2051)2 0.186 (207/1115) 0.169 (  347/2051)3 0.239 (267/1115) 0.215 (  440/2051)4 0.278 (310/1115) 0.250 (  512/2051)5 0.311 (347/1115) 0.277 (  567/2051)10 0.420 (468/1115) 0.377 (  774/2051)20 0.524 (584/1115) 0.467 (  958/2051)50 0.659 (735/1115) 0.597 (1224/2051)100 0.733 (817/1115) 0.673 (1381/2051)500 0.775 (864/1115) 0.728 (1494/2051)1000 0.775 (864/1115) 0.728 (1494/2051)Table 3: Recall for top n results(SMT(Paper)+Index(Patent))ReferencesGuo-Wei Bian and Shun-Yuan Teng.
2008.
Integrat-ing Query Translation and Text Classification in aCross-Language Patent Access System, Proceedingof the 7th TCIR Workshop Meeting: 341-346.Stephane Clinchant and Jean-Michel Renders.
2008.XRCE's Participation to Patent Mining Task atNTCIR-7, Proceedings of the 7th TCIR WorkshopMeeting: 351-353.Atsushi Fujii, Makoto Iwayama, and Noriko Kando.2004.
Overview of Patent Retrieval Task atNTCIR-4, Working otes of the 4th TCIR Work-shop: 225-232.Atsushi Fujii, Makoto Iwayama, and Noriko Kando.2005.
Overview of Patent Retrieval Task atNTCIR-5, Proceedings of the 5th TCIR WorkshopMeeting: 269-277.Atsushi Fujii, Makoto Iwayama, and Noriko Kando.2007.
Overview of the Patent Retrieval Task atNTCIR-6 Workshop, Proceedings of the 6th TCIRWorkshop Meeting: 359-365.Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, andTakehito Utsuro.
2008.
Overview of the PatentTranslation Task at the NTCIR-7 Workshop, Pro-ceedings of the 7th TCIR Workshop Meeting: 389-400.Marti A. Hearst.
1992.
Automatic Acquisition of Hy-ponyms from Large Text Corpora, Proceedings ofthe 14th International Conference on Computation-al Linguistics: 539-545.Daisuke Ikeda, Toshiaki Fujiki, and Manabu Okumu-ra.
2006.
Automatically Linking News Articles toBlog Entries, Proceedings of AAAI Spring Sympo-sium Series Computational Approaches to Analyz-ing Weblogs: 78-82.Masaki Itagaki, Takako Aikawa, and Xiaodong He.2007.
Automatic Validation of Terminology Trans-lation Consistency with Statistical Method, Pro-ceedings of MT summit XI: 269-274.Hideo Itoh, Hiroko Mano, and Yasushi Ogawa.
2002.Term Distillation for Cross-db Retrieval, Workingotes of the 3rd TCIR Workshop Meeting, PartIII: Patent Retrieval Task: 11-14.Makoto Iwayama, Atsushi, Fujii, Noriko Kando, andAkihiko Takano.
2002.
Overview of Patent Re-Method groupA+Bgroup AOurmethodsIndex(Paper)*Index(Patent) 0.1830 0.2230Index(Paper)+Index(Patent) 0.2258 0.2596SMT(Paper)+Index(Patent) 0.2633 0.2897BaselinemethodsSMT(Paper) 0.2518 0.2777SMT(Patent) 0.2214 0.2507Index(Paper) 0.2169 0.2433Index(Patent) 0.2000 0.2373SMT(Paper)+Hypernym 0.2451 0.2647Index(TechDic) 0.1575 0.1773Index(EIJIRO) 0.1347 0.1347Upper-boundJapanese subtask 0.2958 0.3267Japanese subtask+Index(Patent) 0.3001 0.3277Table 2: Evaluation results34trieval Task at NTCIR-3, Working otes of the 3rdTCIR Workshop Meeting, Part III: Patent Re-trieval Task: 1-10.Makoto Iwayama, Atsushi Fujii, and Noriko Kando.2005.
Overview of Classification Subtask atNTCIR-5 Patent Retrieval Task, Proceedings of the5th TCIR Workshop Meeting: 278-286.Makoto Iwayama, Atsushi Fujii, and Noriko Kando.2007.
Overview of Classification Subtask atNTCIR-6 Patent Retrieval Task, Proceedings of the6th TCIR Workshop Meeting: 366-372.Noriko Kando, Kazuko Kuriyama, Toshihiko Nozue,Koji Eguchi, Hiroyuki Kato, and Soichiro Hidaka.1999.
Overview of IR Tasks at the first NTCIRWorkshop, Proceedings of the 1st TCIR Work-shop on Research in Japanese Text Retrieval andTerm Recognition: 11-44.Noriko Kando, Kazuko Kuriyama, and Makoto Yo-shioka.
2001.
Overview  of Japanese and EnglishInformation Retrieval Tasks (JEIR) at the SecondNTCIR Workshop, Proceedings of the 2nd TCIRWorkshop Meeting: 4-37 - 4-60.Hisao Mase and Makoto Iwayama.
2008.
NTCIR-7Patent Mining Experiments at Hitachi, Proceedingsof the 7th TCIR Workshop Meeting: 365-368.Hidetsugu Nanba.
2007.
Query Expansion using anAutomatically Constructed Thesaurus, Proceedingsof the 6th TCIR Workshop Meeting: 414-419.Hidetsugu Nanba, Natsumi Anzen, and ManabuOkumura:a.
2008.
Automatic Extraction of CitationInformation in Japanese Patent Applications, Inter-national Journal on Digital Libraries, 9(2): 151-161.Hidetsugu Nanba, Atsushi Fujii, Makoto Iwayama,and Taiichi Hashimoto:b.
2008.
Overview of thePatent Mining Task at the NTCIR-7 Workshop,Proceedings of the 7th TCIR Workshop Meeting:325-332.Hidetsugu Nanba:c. 2008.
Hiroshima City Universityat NTCIR-7 Patent Mining Task.
Proceedings ofthe 7th TCIR Workshop Meeting: 369-372.Hidetsugu Nanba, Hideaki Kamaya, Toshiyuki Take-zawa, Manabu Okumura, Akihiro Shinmori, andHidekazu Tanigawa.
2009.
Automatic Translationof Scholarly Terms into Patent Terms, Journal ofInformation Processing Society Japan TOD, 2(1):81-92.
(in Japanese)Gerald Salton.
1971.
The SMART Retrieval System -Experiments in Automatic Document Processing.Prentice-Hall, Inc., Upper Saddle River, NJ.Masatsugu Tonoike.
Mitsuhiro Kida, Toshihiro Taka-gi, Yasuhiro Sakai, Takehito Utsuro, and SatoshiSato.
2005.
Translation Estimation for TechnicalTerms using Corpus Collected from the Web, Pro-ceedings of the Pacific Association for Computa-tional Linguistics: 325-331.35
