Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 460?465, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsOPTWIMA: Comparing Knowledge-rich and Knowledge-poor Approachesfor Sentiment Analysis in Short Informal TextsAlexandra BalahurEuropean Commission Joint Research CentreVia E. Fermi 274921027 Ispra (VA), Italy{alexandra.balahur}@jrc.ec.europa.euAbstractThe fast development of Social Media made itpossible for people to no loger remain merespectators to the events that happen in theworld, but become part of them, comment-ing on their developments and the entities in-volved, sharing their opinions and distribut-ing related content.
This phenomenon is ofhigh importance to news monitoring systems,whose aim is to obtain an informative snap-shot of media events and related comments.This paper presents the strategies employed inthe OPTWIMA participation to SemEval 2013Task 2-Sentiment Analysis in Twitter.
Themain goal was to evaluate the best settings fora sentiment analysis component to be added tothe online news monitoring system.We describe the approaches used in the com-petition and the additional experiments per-formed combining different datasets for train-ing, using or not slang replacement and gener-alizing sentiment-bearing terms by replacingthem with unique labels.The results regarding tweet classification arepromising and show that sentiment generaliza-tion can be an effective approach for tweetsand that SMS language is difficult to tackle,even when specific normalization resourcesare employed.1 IntroductionSentiment analysis is the Natural Language Process-ing (NLP) task dealing with the detection and clas-sification of sentiments in texts.
Usually, the classesconsidered are ?positive?, ?negative?
and ?neutral?,although in some cases finer-grained categories areadded (e.g.
?very positive?
and ?very negative?)
oronly the ?positive?
and ?negative?
classes are takeninto account.This task has received a lot of interest from the re-search community in the past years.
The work doneregarded the manner in which sentiment can be clas-sified from texts pertaining to different genres anddistinct languages, in the context of various applica-tions, using knowledge-based, semi-supervised andsupervised methods [Pang and Lee, 2008].
The re-sult of the analyses performed have shown that thedifferent types of text require specialized methodsfor sentiment analysis, as, for example, sentimentsare not conveyed in the same manner in newspaperarticles and in blogs, reviews, forums or other typesof user-generated contents [Balahur et al 2010].In the light of these findings, dealing with senti-ment analysis in tweets and SMS (that we can gener-ally call ?short informal texts?)
requires an analysisof the characteristics of such texts and the design ofadapted methods.Our participation in the SemEval 2013 Task 2[Wilson et al 2013] had as objective to test howwell our proposed methods for sentiment analysisfor short informal texts (especially tweets) wouldperform.
The two subtasks proposed in this com-petition were: a) the classification of sentiment fromsnippets from tweets and SMS marked as start andend position and b) the classification of sentimentfrom entire tweets and SMS.
Each team could sub-mit 2 runs for each dataset and task, one employ-ing as training data only the data provided withinthe competition (?constrained?)
and the second em-460ploying any additional data (?unconstrained?).
Wesubmitted 2 of such runs for each of the subtasksand datasets.The main requirements for the system we imple-mented were: a) not to use language-specific NLPprocessing tools (since our final goal is to make thepresent system work for many more languages); andb) to work fast, so that it can be integrated in a nearreal time media monitoring system.2 Related Work and ContributionOne of the first studies on the classification of polar-ity in tweets was Go et al[2009].
The authors con-ducted a supervised classification study on tweetsin English, using the emoticons (e.g.
?
:)?, ?:(?,etc.)
as markers of positive and negative tweets.Read [2005] employed this method to generate acorpus of positive tweets, with positive emoticons?
:)?, and negative tweets with negative emoticons?:(?.
Subsequently, they employ different supervisedapproaches (SVM, Na?
?ve Bayes and Maximum En-tropy) and various sets of features and conclude thatthe simple use of unigrams leads to good results, butit can be slightly improved by the combination ofunigrams and bigrams.In the same line of thinking, Pak and Paroubek[2010] also generated a corpus of tweets for sen-timent analysis, by selecting positive and negativetweets based on the presence of specific emoticons.Subsequently, they compare different supervised ap-proaches with n-gram features and obtain the bestresults using Na?
?ve Bayes with unigrams and part-of-speech tags.Another approach on sentiment analysis in tweetis that of Zhang et al[2011].
Here, the authors em-ploy a hybrid approach, combining supervised learn-ing with the knowledge on sentiment-bearing words,which they extract from the DAL sentiment dictio-nary [Whissell, 1989].
Their pre-processing stageincludes the removal of retweets, translation of ab-breviations into original terms and deleting of links,a tokenization process, and part-of-speech tagging.They employ various supervised learning algorithmsto classify tweets into positive and negative, using n-gram features with SVM and syntactic features withPartial Tree Kernels, combined with the knowledgeon the polarity of the words appearing in the tweets.The authors conclude that the most important fea-tures are those corresponding to sentiment-bearingwords.
Finally, Jiang et al[2011] classify sentimentexpressed on previously-given ?targets?
in tweets.They add information on the context of the tweet toits text (e.g.
the event that it is related to).
Subse-quently, they employ SVM and General Inquirer andperform a three-way classification (positive, nega-tive, neutral).The main contributions of the approaches con-sidered for the competition reside in the evaluationof different strategies to adapt sentiment analysismethods to the language employed in short informaltexts.The methods employed in our system are simple,work fast and efficient and can be easily adaptedto other languages.
The main adaptations we con-sider are part of a pre-processing step, in which thelanguage in these short informal texts is normalized(brought to a dictionary form).Finally, the methods presented are compared ondifferent configurations and training sets, so that theconclusions drawn are relevant to the phenomenafound in this type of informal texts.3 Methods Employed by OPTWIMA inSemEval 2013 Task 2We employ two different approaches: a) onebased on supervised learning using Support VectorMachines Sequential Minimal Optimization (SVMSMO) using unigram and bigram features; and b) ahybrid approach, based on supervised learning witha SVM SMO linear kernel, on unigram and bigramfeatures, but exploiting as features sentiment dictio-naries, emoticon lists, slang lists and other socialmedia-specific features.
SVM SMO was preferreddue to the computation speed.
We do not employany specific language analysis software.
The aimis to be able to apply, in a straightforward manner,the same approach to as many languages as possible.The approach can be extended to other languages byusing similar dictionaries that have been created inour team Steinberger et al[2011].The sentiment analysis process contains twostages: preprocessing and sentiment classification.4613.1 Preprocessing of Short Informal TextsThe language employed in short informal texts suchas tweets and SMS is different from the one foundin other types of texts, such as newspaper articlesand the form of the words employed is sometimesnot the one we may find in a dictionary.
Furtheron, users writing on Twitter or SMS-ing on theircell phone employ a special ?slang?
(i.e.
informallanguage, with special expressions, such as ?lol?,?omg?
), emoticons, and often emphasize words byrepeating some of their letters.
Additionally, the lan-guage employed in Twitter has specific characteris-tics, such as the markup of tweets that were repostedby other users with ?RT?, the markup of topics us-ing the ?#?
(hash sign) and of the users using the?@?
sign.All these aspects must be considered at the timeof processing tweets and, to some extent, SMS.As such, before applying supervised learning toclassify the sentiment of the short informal textsconsidered, we preprocess them, to normalize thelanguage they contain and try to abstract on the con-cepts that are sentiment-bearing, by replacing themwith labels, according to their polarity1.
In case ofSMS messages, the slang employed, the short formsof words and the acronyms make these texts non pro-cessable without prior replacement and normaliza-tion of the slang.
The preprocessing stage containsthe following steps:?
Repeated punctuation sign normalization(RPSN).In the first step of the preprocessing, we detectrepetitions of punctuation signs (?.
?, ?!?
and???).
Multiple consecutive punctuation signsare replaced with the labels ?multistop?, forthe fullstops, ?multiexclamation?
in the case ofexclamation sign and ?multiquestion?
for thequestion mark and spaces before and after.?
Emoticon replacement (ER).In the second step of the preprocessing, we em-ploy the annotated list of emoticons from Sen-tiStrength2 and match the content of the tweets1The preprocessing steps involving the use of affect dictio-naries and modifier replacement are used only in one of the twomethods considered2http://sentistrength.wlv.ac.uk/against this list.
The emoticons found are re-placed with their polarity (?positive?
or ?nega-tive?)
and the ?neutral?
ones are deleted.?
Lower casing and tokenization (LCN).Subsequently, the tweets are lower cased andsplit into tokens, based on spaces and punctua-tion signs.?
Slang replacement (SR).The next step involves the normalization of thelanguage employed.
In order to be able toinclude the semantics of the expressions fre-quently used in Social Media, we employed thelist of slang expressions from dedicated sites 3.This step is especially relevant to SMS texts,whose language in their original form has littleto do with language employed in ordinary texts.?
Word normalization (WN).At this stage, the tokens are compared to entriesin Roget?s Thesaurus.
If no match is found, re-peated letters are sequentially reduced to two orone until a match is found in the dictionary (e.g.?perrrrrrrrrrrrrrrrrrfeeect?
becomes ?perrfeect?,?perfeect?, ?perrfect?
and subsequently ?per-fect?).
The words used in this form are makedas ?stressed?.?
Affect word matching (AWM).Further on, the tokens in the tweet are matchedagainst three different sentiment lexicons: Gen-eral Inquirer, LIWC and MicroWNOp, whichwere previously split into four different cate-gories (?positive?, ?high positive?, ?negative?and ?high negative?).
Matched words are re-placed with their sentiment label - i.e.
?posi-tive?, ?negative?, ?hpositive?
and ?hnegative?.?
Modifier word matching (MWM).Similar to the previous step, we employ a listof expressions that negate, intensify or dimin-ish the intensity of the sentiment expressed todetect such words in the tweets.
If such a wordis matched, it is replaced with ?negator?, ?in-tensifier?
or ?diminisher?, respectively.3www.noslang.com/dictionary, www.smsslang.com462?
User and topic labeling (UTL).Finally, the users mentioned in the tweet, whichare marked with ?
@?, are replaced with ?PER-SON?
and the topics which the tweet refers to(marked with ?#?)
are replaced with ?TOPIC?.3.2 Sentiment Classification of Short InformalTextsOnce the texts are preprocessed, they are passed onto the sentiment classification module.We employed supervised learning using SupportVector Machines Sequential Minimal Optimization(SVM SMO) [Platt, 1998] with a linear kernel, em-ploying boolean features - the presence or absenceof unigrams and bigrams determined from the train-ing data (tweets that were previousely preprocessedas described above) that appeared at least twice.
Bi-grams are used especially to spot the influence ofmodifiers (negations, intensifiers, diminishers) onthe polarity of the sentiment-bearing words.
Wetested different parameters for the kernel and modi-fied only the C constant to the best value determinedon the training data (5.0)/We tested the approach on different datasets anddataset splits, using the Weka data mining software4.
The training models are built on a cluster of com-puters (4 cores, 5000MB of memory each).4 Evaluation and DiscussionWe participated in SemEval 2013 in Task 2 withtwo versions of the system, for each of the two sub-tasks (A and B).
The main difference among them isthe use of dictionaries for affect and modifier wordmatching and replacement.
As such, in the firstmethod (denoted as ?Dict?
), we perform all the pre-processing steps mentioned above, while the secondmethod is applied on the data on which the AWMand MWM are not performed (i.e.
words that areassociated with a sentiment in a lexicon are not re-placed with labels).
This second method will be de-noted ?NoDict?.Another difference between the different evalu-ations we performed are the datasets employed fortraining.
We created different models, employing:1) For both the ?Constrained?
and ?Uncon-strained?
submissions, the development and train-4http://www.cs.waikato.ac.nz/ml/weka/ing data from the corresponding subtask (i.e.
usingas training the data in subtask A - the sets given astraining and development together - to train a classi-fier for the test data in task A; the same for subtaskB).
In this case, the training data is marked with thecorresponding subtask (i.e.
training data ?A?, train-ing data ?B?
);2) For both the ?Constrained?
and ?Uncon-strained?
submissions, the development and trainingdata from both subtasks - both training and develop-ment sets - to train one classifier which is used forboth subtasks.
This training set is denoted as ?A+B?
;3) For the ?Unconstrained?
submissions, weadded to the joint training and development datafrom both subtasks the set of MySpace commentsprovided by [Thelwall et al 2010].
This small setcontains 1300 short texts from the MySpace socialnetwork5.
The motivation behind this choice is thattexts from this source are very similar in languageand structure to tweets and (after slang replacement)SMS.Finally, we trained different classifiers on thetraining sets described, with and without replacingthe affective and modifier words and with and with-out employing the slang replacement pre-processingstep.The results are presented in Tables 1, 2, 3, 4, interms of average F-measure of the positive and neg-ative classes (as used by the organizers).
The runssubmitted in the competition are marked with an as-terisk (?*?).
We did not perform all the experimentsfor the sets of SMS without slang replacement, asthe first results were very low.As we can see from the results, our approach per-formed better in classifying the overall sentiment oftexts than small snippets.
The results were signifi-cantly better for the classification of tweets in com-parison to SMS, whose language (even with slangreplacement) made them difficult to tackle.
We canalso see that the joint use of slang replacement anddictionaries for tweets leads to significantly lowerresults, meaning that this step (at least with the re-sources we employed for slang treatment), is notnecessary for the treatment of tweets.
Instead, forthese texts, the use of affect dictionaries and mod-ifier lists and their generalizaton lead to better re-5http://www.myspace.com/463Trained on A+B with slang replacement (Constrained)Test set Dict NoDictTask A Tweets 0.35 0.37Task A SMS 0.35 0.37*Task B Tweets 0.45* 0.54Task B SMS 0.40* 0.47Table 1: Results obtained using A+B (train and developement data) as training set and replacing the slang.Trained on A+B+MySpace with slang replacement (Unconstrained)Test Set Dict NoDictTask A Tweets 0.36 0.39*Task A SMS 0.37* 0.37Task B Tweets 0.46 0.54*Task B SMS 0.40 0.37*Table 2: Results obtained using A+B+MySpace (train and developement data) as training set and replacing the slang.sults.
This proves that such a generalization, in thecontext of ?legible?
texts, is a useful tool for senti-ment analysis.
Further on, the results showed thatadding a small quantity of training data led to nosignificant growth in performance (for the data inwhich slang was replaced).
Additional evaluationscould be made to quantify the effect of this datawhen other methods to generalize are not applied.As an observation, our results were balanced for allthree classes, with even higher scores for the neutralclass.
We believe this class should have been con-sidered as well, since in real-world settings systemsfor sentiment analysis must also be able to classifytexts pertaining to this category.Finally, we can see that in the case of SMS, thedifference between the use of slang with or withoutaffect label generalizations is insignificant.
We be-lieve this is due to the fact that the expressions withwhich the slang is replaced are very infrequent intraditional sentiment dictionaries (such as the oneswe employed).
Even by replacing the short formsand slang with their equivalents, the texts obtainedcontain words that are infrequent in other types oftexts, even tweets.
However, we will perform addi-tional experiments with other lists of slang and add,as much as it is possible, the informal sentiment-bearing expressions to create new affect resourcesfor this types of texts.5 Conclusions and Future WorkIn this article, we presented and evaluated the ap-proaches considered for our participation in the Se-mEval 2013 Task 2.
We evaluated different com-binations of features, resources and training setsand applied different methods to tackle the issuesbrought by the informal language used in tweets andSMS.As future work, we would like to extend the sys-tem to more languages, using the dictionaries cre-ated by Steinberger et al[2011] and analyze and in-clude new features that are particular to social media- especially tweets - to improve the performance ofthe sentiment analysis component.
Further on, wewould like to quantify the influence of using linguis-tic processing tools to perform lemmatizing, POS-tagging and the inclusion of corresponding featureson the final performance of the system.
Finally, wewould like to explore additional resources to dealwith the issue of language informality in tweets andfurther explore the problems posed by the peculiarlanguage employed in SMS.ReferencesAlexandra Balahur, Ralf Steinberger, Mijail Kabad-jov, Vanni Zavarella, Erik van der Goot, MatinaHalkia, Bruno Pouliquen, and Jenya Belyaeva.Sentiment analysis in the news.
In Proceedings464Trained on data of subtask (A or B) with slang replacementTest Set Dict NoDictTask A Tweets 0.36 0.37Task A SMS 0.36 0.37Task B Tweets 0.5 0.55Task B SMS 0.49 0.53Table 3: Results obtained using A (train and developement data) or B (train and developement data) as training set andreplacing the slang.Trained on data of subtask (A or B), no slang replacement Trained on A+B, no slang replacementTest Set Dict NoDict Dict NoDictTask A Tweets 0.69* 0.59 0.6 0.69Task B Tweets 0.59 0.51 0.62 0.44Table 4: Results obtained for tweet classification using A+B or A or B as training set and not replacing the slang.of the Seventh International Conference on Lan-guage Resources and Evaluation (LREC?10), Val-letta, Malta, may 2010.Alec Go, Richa Bhayani, and Lei Huang.
Twittersentiment classification using distant supervision.Processing, pages 1?6, 2009.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, andTiejun Zhao.
Target-dependent twitter sentimentclassification.
In Proceedings of the 49th An-nual Meeting of the Association for Computa-tional Linguistics: Human Language Technolo-gies, HLT ?11, pages 151?160.
ACL, 2011.
ISBN978-1-932432-87-9.Alexander Pak and Patrick Paroubek.
Twitter as acorpus for sentiment analysis and opinion min-ing.
In Proceedings of the Seventh conferenceon International Language Resources and Eval-uation (LREC?10), Valletta, Malta; ELRA, may2010.
ELRA.
ISBN 2-9517408-6-7.
19-21.Bo Pang and Lillian Lee.
Opinion mining and sen-timent analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135, January 2008.
ISSN 1554-0669.John C. Platt.
Sequential minimal optimization:A fast algorithm for training support vector ma-chines.
Technical report, Advances in KernelMethods - Support Vector Learning, 1998.Jonathon Read.
Using emoticons to reduce depen-dency in machine learning techniques for senti-ment classification.
In Proceedings of the ACLStudent Research Workshop, ACLstudent ?05,pages 43?48, Stroudsburg, PA, USA, 2005.J.
Steinberger, P. Lenkova, M. Ebrahim,M.
Ehrmann, A. Hurriyetoglu, M. Kabad-jov, R. Steinberger, H. Tanev, V. Zavarella, andS.
Va?zquez.
Creating sentiment dictionaries viatriangulation.
In Proceedings of WASSA 2011,WASSA ?11, pages 28?36.
ACL, 2011.Mike Thelwall, Kevan Buckley, Georgios Paltoglou,Di Cai, and Arvid Kappas.
Sentiment in shortstrength detection informal text.
Journal of theAmerican Society for Information Science andTechnology, 61(12):2544?2558, December 2010.Cynthia Whissell.
The Dictionary of Affect in Lan-guage.
In Robert Plutchik and Henry Kellerman,editors, Emotion: theory, research and experi-ence, volume 4, The measurement of emotions.Academic Press, London, 1989.Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,Sara Rosenthal, Veselin Stoyanov, and Alan Rit-ter.
SemEval-2013 task 2: Sentiment analysis intwitter.
In Proceedings of the International Work-shop on Semantic Evaluation, SemEval ?13, June2013.Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil,Meichun Hsu, and Bing Liu.
Combining lexicon-based and learning-based methods for twitter sen-timent analysis.
Technical Report HPL-2011-89,HP, 21/06/2011 2011.465
