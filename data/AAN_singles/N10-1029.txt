Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 242?245,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsTask-based Evaluation of Multiword Expressions:a Pilot Study in Statistical Machine TranslationMarine Carpuat Mona DiabColumbia UniversityCenter for Computational Learning Systems475 Riverside Drive, New York, NY 10115{marine,mdiab}@ccls.columbia.eduAbstractWe conduct a pilot study for task-orientedevaluation of Multiword Expression (MWE)in Statistical Machine Translation (SMT).
Wepropose two different integration strategies forMWE in SMT, which take advantage of differ-ent degrees of MWE semantic compositional-ity and yield complementary improvements inSMT quality on a large-scale translation task.11 IntroductionA multiword expression (MWE) generally refers toa multiword unit or a collocation of words that co-occur together statistically more than chance.
AMWE is a cover term for different types of colloca-tions which vary in their transparency and fixedness.Identifying MWEs and understanding their meaningis considered essential to language understanding,and of crucial importance for any Natural LanguageProcessing (NLP) applications that aim at handlingrobust language meaning and use.
In fact, the sem-inal paper (Sag et al, 2002) refers to this problemas a key issue for the development of high-qualityNLP applications.
(Villavicencio et al, 2005) iden-tify Machine Translation as an application of partic-ular interest since ?
recognition of MWEs is neces-sary for systems to preserve the meaning and pro-duce appropriate translations and avoid the genera-tion of unnatural or nonsensical sentences in the tar-get language.
?However, statistical machine translation (SMT)typically does not model MWEs explicitly.
SMT1The research was partially funded by IBM under theDARPA GALE project.units are typically phrasal translations, defined with-out any direct syntactic or lexical semantic motiva-tion: they are simply n-grams that are consistentlytranslated in parallel corpora.
Phrasal translationsmight indirectly capture MWEs, but they are not dis-tinguished from any other n-gram.As a result, the usefulness of explicitly modelingMWEs in the SMT framework has not yet been stud-ied systematically.
Previous work has focused onautomatically learning and integrating translationsof very specific MWE categories, such as, for in-stance, idiomatic Chinese four character expressions(Bai et al, 2009) or domain specific MWEs (Ren etal., 2009).
MWEs have also been defined not froma lexical semantics perspective but from a SMT er-ror reduction perspective, as phrases that are hardto align during SMT training (Lambert and Banchs,2005).
For each of these particular cases, translationquality improved by augmenting the SMT transla-tion lexicon with the learned bilingual MWEs eitherdirectly or through improved word alignments.In this paper, we consider a more general prob-lem: we view SMT as an extrinsic evaluation ofthe usefulness of monolingual MWEs as used per-vasively in natural language regardless of domain,idiomaticity and compositionality.
A MWE is com-positional if its meaning as a unit can be predictedfrom the meaning of its component words such as inmake a decision meaning to decide.
Some MWEsare more predictable than others, for instance, kickthe bucket, when used idiomatically to mean to die,has nothing in common with the literal meaning ofeither kick or bucket, while make a decision is veryclearly related to to decide.
These expressions are242both considered MWEs but have varying degrees ofcompositionality and predictability.We explore strategies for integrating all MWEsalong this continuum in SMT.
Given a monolingualMWE lexicon, we propose (1) a static integrationstrategy that segments training and test sentences ac-cording to the MWE vocabulary, and (2) a dynamicintegration strategy that adds a new MWE-basedfeature in SMT translation lexicons.In a pilot study of the impact of WordNet MWEson a large-scale English to Arabic SMT system, weshow that static and dynamic strategies both improvetranslation quality and that their impact is not thesame for different types of MWEs.
This suggeststhat the proposed framework would be an interest-ing testbed for a task-driven evaluation of automaticMWE extraction.2 Static integration of MWE in SMTThe first strategy for integration can be seen asa generalization of word segmentation for MWEs.Given a MWE lexicon, we identify MWEs in run-ning text and turn them into a single unit by un-derscoring.
We call this integration method static,since, once segmented, all MWEs are consideredfrozen from the perspective of the SMT system.During training and decoding, MWEs are handledas distinct words regardless of their compositional-ity, and all knowledge of the MWE components islost.3 Dynamic integration of MWE in SMTThe second strategy attempts to encourage cohesivetranslations of MWEs without ignoring their com-ponents.
Word alignment and phrasal translationextraction are conducted without any MWE knowl-edge, so that the SMT system can learn word-for-word translations from consistently translated com-positional MWEs.
MWE knowledge is integrated asa feature in the translation lexicon.
For each entry,in addition to the standard phrasal translation proba-bilities, we define a count feature that represents thenumber of MWEs in the input language phrase.We refer to this integration strategy as dynamic,because the SMT system decides at decoding timehow to segment the input sentence.
The MWE fea-ture biases the system towards using phrases that donot break MWEs.
This can be seen as a generaliza-tion of the binary MWE feature in (Ren et al, 2009),repurposed for monolingual MWEs.4 Empirical EvaluationWe evaluate the impact of MWEs in SMT on a large-scale English-Arabic translation task.Using two languages from different families is achallenging testbed for MWEs in SMT.
In contrast,very closely related languages such as English andFrench might present less divergence in lexicaliza-tion.In addition, Arabic-English is a well-studied lan-guage pair in SMT, with large amounts of data avail-able.
However, we tackle the less common Englishto Arabic direction in order to take advantage of therich lexical resources available for English on the in-put side.Our test set consists of the 813 newswire sen-tences of the 2008 NIST Open Machine Transla-tion Evaluation, which is standard evaluation datafor Arabic-English translation.
The first English ref-erence translation is used as the input to our SMTsystem, and the single Arabic translation is used asthe unique reference2.
Translation quality is eval-uated using two automatic evaluation metrics: (1)BLEUr1n4 (Papineni et al, 2002), which is basedon n-gram precisions for n = 1..4, and (2) Trans-lation Edit Rate (TER) (Snover et al, 2006), whichgeneralizes edit distance beyond single-word edits.4.1 SMT systemWe use the open-source Moses toolkit (Koehn et al,2007) to build a standard phrase-based SMT system.Our training data consists of 2.5M sentence pairsfrom mostly newswire parallel corpora distributedby the Linguistic Data Consortium.
The Englishside is tokenized using simple punctuation-basedrules.
The Arabic side is segmented according to theArabic Treebank v3 tokenization scheme using theMADA+TOKAN morphological analyzer and tok-enizer (Habash et al, 2009).The parallel corpus is word-aligned usingGIZA++ in both translation directions, which are2We exclude weblog text since it consists of an informal mixof Modern Standard Arabic and Dialectal Arabic which is sub-optimal as a reference translation.243combined by intersection and the grow-diag-final-and heuristic (Koehn et al, 2007).
Phrase transla-tions of up to 10 words are extracted in the Mosesphrase-table.
We use a 5-gram language model withmodified Kneser-Ney smoothing.
Feature weightsare tuned on NIST-MT06.4.2 English MWEOur main source of English MWE is the WordNet3.0 lexical database (Fellbaum, 1998).
We use sim-ple rules to augment WordNet entries with morpho-logical variations (e.g., keep one?s eyes peeled is ex-panded into keep her eyes peeled, etc.).
In addi-tion when marking MWEs in text, we allow matchesnot only with surface forms, but also with lemma-tized forms (Schmid, 1994) to account for inflec-tions.
This results in a total of about 900 MWE to-kens and 500 types in our evaluation test set.
MWEidentification in running text is performed using astraightforward maximum forward match algorithm.Second, in order to contrast the impact of MWEswith that of frequent collocations in our dynamic in-tegration strategy, we consider the top 500 most fre-quent n-grams from the SMT test set, so that thesame number of n-gram types and WordNet MWEsare marked in the test set.
Unlike WordNet MWEs,these n-gram represent cohesive units, but are notnecessarily frozen or even a single concept.
We con-sider n-grams up to length 10 from the phrase-table,and compute their frequency in the English side ofthe parallel corpus.
The top 500 most frequent n-grams and the WordNet MWEs yield two very dif-ferent lexicons.
Only the following 10 entries ap-pear in both: at the same time, deputy prime minis-ter, for the first time, in the south, in the wake of, in-ternational atomic energy agency, islamic resistancemovement, on the other hand, osama bin laden, sec-retary of state.5 Static MWE Integration Improves SMTAs seen in Table 1, the static integration of the Word-Net MWE lexicon by segmentation of English train-ing and test sentences improves BLEU and TERcompared to the SMT baseline.
This suggests thatWordNet MWEs represent useful units of meaningfor alignment and translation into Arabic despite thefact that they are monolingually defined.MWE integration TER BLEUBaseline ?
59.43 30.49Top 500 n-grams dynamic 59.07 30.98WordNet MWE dynamic 58.89 31.07WordNet MWE static 58.98 31.27Table 1: Impact of MWE integration measured on NISTMT08Consider, for instance, the following input sen-tence: the special envoy of the secretary-general willsubmit an oral report to the international securitycouncil rather than a written report.
With static in-tegration, the MWE written report is correctly trans-lated as tqryrA mktwbA, while the baseline producesthe incorrect translation ktb Altqryr (writing the re-port or book of report).6 Dynamic MWE Integration ImprovesSMTDynamic integration of the WordNet MWE lexiconand the top 500 n-grams both improve BLEU andTER (Table 1), but WordNet MWEs yield slightlybetter scores.
This confirms the ability of the dy-namic integration method to handle compositionalMWEs, since the most frequent n-grams are highlycompositional by definition.7 DiscussionAt the corpus-level, static integration yields aslightly better BLEU score than dynamic withWordNet MWEs, while the opposite effect is ob-served on TER.
This suggests that the two integra-tion strategies impact translation in different ways.Sentence-level scores indeed reveal that dynamicand static integration strategies have an opposite im-pact on 27% of the test set (Table 2).For instance, the dynamic approach fails forphrasal verbs such as take out.
In who were thenallowed to take out as many unsecured loans as theywanted, take out is realized as b+ AlHSwl (acquire)with the static approach, while it is entirely droppedfrom the dynamic translation.In the static approach, translation quality is oftendegraded when our simple dictionary matching ap-proach incorrectly detects MWE.
For instance, in thesentence the perpetration of this heinous act on our244Dynamic integration helps hurtsStatic integrationhelps 45% 16%hurts 11% 28%Table 2: Percentage of sentences where each integrationstrategy helps or hurts both BLEU and TER compared tothe baseline SMT system.soil, act on is incorrectly identified as a MWE whichdegrades translation fluency.
This suggests that fur-ther gains in translation quality could be obtainedwith a more sophisticated MWE detection method.8 ConclusionWe have proposed a framework of two comple-mentary integration strategies for MWEs in SMT,which allows extrinsic evaluation of the usefulnessof MWEs of varying degree of compositionality.We conducted a pilot study using manually definedWordNet MWE and a dictionary matching approachto MWE detection.
This simple model improvesEnglish-Arabic translation quality, even on a largeSMT system trained on more than 2 Million sen-tence pairs.This result suggests that standard SMT phrasesdo not implicitly capture all useful MWE informa-tion.
It would therefore be interesting to conductthis study on a larger scale, using more generalMWE definitions such as automatically learned col-locations (Smadja, 1993) or verb-noun constructions(Diab and Bhutada, 2009).ReferencesMing-Hong Bai, Jia-Ming You, Keh-Jiann Chen, and Ja-son S. Chang.
2009.
Acquiring translation equiva-lences of multiword expressions by normalized corre-lation frequencies.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 478?486, Singapore, August.Mona Diab and Pravin Bhutada.
2009.
Verb noun con-struction MWE token classification.
In Proceedings ofthe Workshop on Multiword Expressions: Identifica-tion, Interpretation, Disambiguation and Applications,pages 17?22, Singapore, August.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.MADA+TOKAN: A toolkit for Arabic tokenization,diacritization, morphological disambiguation, POStagging, stemming and lemmatization.
In Proceedingsof the 2nd International Conference on Arabic Lan-guage Resources and Tools (MEDAR), Cairo, Egypt.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In AnnualMeeting of the Association for Computational Linguis-tics (ACL), demonstration session, Prague, Czech Re-public, June.Patrik Lambert and Rafael Banchs.
2005.
Data inferredmulti-word expressions for statistical machine transla-tion.
In Machine Translation Summit X, pages 396?403, Phuket, Thailand.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics.Zhixiang Ren, Yajuan Lu?, Jie Cao, Qun Liu, and YunHuang.
2009.
Improving statistical machine trans-lation using domain bilingual multiword expressions.In Proceedings of the Workshop on Multiword Expres-sions: Identification, Interpretation, Disambiguationand Applications, pages 47?54, Singapore, August.Ivan A.
Sag, Timothy Baldwin, Francis Bond, Ann A.Copestake, and Dan Flickinger.
2002.
Multiword ex-pressions: A pain in the neck for NLP.
In Proceed-ings of the Third International Conference on Com-putational Linguistics and Intelligent Text Processing,pages 1?15, London, UK.
Springer-Verlag.Helmut Schmid.
1994.
Probabilistic part?of?speechtagging using decision trees.
In Proceedings of theConference on New Methods in Language Processing,pages 44?49, Manchester, UK.Frank A. Smadja.
1993.
Retrieving collocations fromtext: Xtract.
Computational Linguistics, 19(1):143?177.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and John Makhoul.
2006.
A study of trans-lation edit rate with targeted human annotation.
InProceedings of AMTA, pages 223?231, Boston, MA.Association for Machine Translation in the Americas.Aline Villavicencio, Francis Bond, Anna Korhonen, andDiana McCarthy.
2005.
Introduction to the specialissue on multiword expressions: Having a crack at ahard nut.
Computer Speech & Language, 19(4):365 ?377.
Special issue on Multiword Expression.245
