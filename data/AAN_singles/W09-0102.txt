Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics, page 2,Athens, Greece, 30 March, 2009. c?2009 Association for Computational LinguisticsThe Annotation ConundrumMark LibermanUniversity of Pennsylvaniamyl@cis.upenn.eduAbstractWithout  lengthy,  iterative  refinement  ofguidelines, and equally lengthy and itera-tive training of annotators, the level of in-ter-subjective agreement on simple tasksof  phonetic,  phonological,  syntactic,  se-mantic,  and  pragmatic  annotation  isshockingly low.This is a significant practical problem inspeech  and  language  technology,  but  itposes questions  of  interest  to psycholo-gists, philosophers of language, and theo-retical linguists as well.1 IntroductionBiologists  believe  that  they know whatgenes,  organisms,  chemical  compounds,and  diseases  are.
Linguists  believe  thatthey know what nouns, verbs, and claus-es are.
Ordinary literate speakers of En-glish believe that they know what people,places, and organizations are.
And all ofthem believe that they can recognize andunderstand instances of  these categoriesin coherent text.When  two  biologists,  two  linguists,  ortwo English speakers discuss such texts,it seems plausible that they have under-stood  such  instances  in  the  same  way.Nevertheless,  if  they are asked to high-light  these  instances,  the  level  of  inter-subjective agreement will be shockinglylow.Similarly depressing results are obtainedin  tasks  such  as  phonetic  or  surface-phonemic transcription, co-reference an-notation,  identification  of  animacy,  etc.Things are usually not much better if wecompare  annotations  produced  by  thesame individuals on different occasions.A solution exists, in the practical sense ofproducing annotations with high inter-an-notator  agreement  scores.
The  initially-divergent results of multiple annotationsare discussed and adjudicated, and princi-ples of interpretation are defined for fu-ture  use.
This  process  is  repeated  overand  over  again,  typically  for  severalmonths, until the desired level of agree-ment is obtained, or funding runs out.At  least for  simple linguistic annotationtasks, this process, reminiscent of the de-velopment  of  common  law,  generallyconverges  (though the  residual  level  ofdisagreement may be depressingly high,especially when multiple judgments mustbe  cascaded).
The  resulting  annotationmanuals may be hundreds of pages long,even for fairly limited tasks; and new an-notators face weeks or months of trainingto become competent in learning to applythem.There  are  several  obvious  ideas  aboutwhy this might be true, but most of theseideas seem to be false.
It will be arguedthat part of the answer lies in understand-ing that most  linguistic annotation tasksare not really classification problems, butrather  translation  problems.
We  don?tnormally  assume  that  there  is  only onecorrect translation of a Chinese sentenceinto English; nor do we try to make thistrue by constructing elaborate translationguidelines to cover every relevant contin-gency, though in principle we could.Implications  in  engineering  and  sciencewill be discussed.2
