Criteria for Measuring Term RecognitionAndy LauristonDepartment ofLanguages and LinguisticsUniversity of Manchester Institute of Science and TechnologyP.O.
Box 88Manchester M60 1QDUnited Kingdomandyl@ccl.umist.ac.ukAbstractThis paper qualifies what a true term-recognition systems would have to recog-nize.
The exact bracketing of the maximaltermform is then proposed as an achieve-able goal upon which current system per-formance should be measured.
How recalland precision metrics are best adapted formeasuring term recognition is suggested.1 IntroductionIn recent years, the automatic extraction of termsfrom running text has become a subject of grow-ing interest.
Practical applications such as dictio-nary, lexicon and thesaurus construction and main-tenance, automatic indexing and machine transla-tion have fuelled this interest.
Given that concernsin automatic term recognition are practical, ratherthan theoretical, the lack of serious performancemeasurements in the published literature is surpris-ing.Accounts of term-recognition systems ometimesconsist of a purely descriptive statement of the ad-vantages of a particular approach and make no at-tempt o measure the pay-off the proposed approachyields (David, 1990).
Others produce partial fig-ures without any clear statement of how they arederived (Otman, 1991).
One of the best efforts toquantify the performance ofa term-recognition sys-tem (Smadja, 1993) does so only for one processingstage, leaving unassessed the text-to-output perfor-mance of the system.While most automatic term-recognition systemsdeveloped to date have been experimental or in-house ones, a few systems like TermCruncher (Nor-mand, 1993) are now being marketed.
Both thedevelopers and users of such systems would benefitgreatly by clearly qualifying what each system aimsto achieve, and precisely quantifying how closely thesystem comes to achieving its stated aim.Before discussing what a term-recognition systemshould be expected to recognize and how perfor-mance in recognition should be measured, two un-derlying premises hould be made clear.
Firstly,the automatic system is designed to recognize seg-ments of text that, conventionally, have been man-ually identified by a terminologist, indexer, lexicog-rapher or other trained individual.
Secondly, theperformance of automatic term-recognition systemsis best measured against human performance for thesame task.
These premises mean that for any givenapplication - terminological standardization a d vo-cabulary compilation being the focus here - it is pos-sible to measure the performance of an automaticterm-recognition system, and the best yardstick fordoing so is human performance.Section 2 below draws on the theory of terminol-ogy in order to qualify what a true term-recognitionsystem must achieve and what, in the short term,such systems can be expected to achieve.
Section3 specifies how the established ratios used in infor-mation retrieval - recall and precision - can best beadapted for measuring the recognition of single- andmulti-word noun terms.2 What is to be Recognized?Depending upon the meaning given to the expres-sion "term recognition", it can be viewed as either arather trivial, low-level processing task or one thatis impossible to automate.
A limited form of termrecognition has been achieved using current tech-niques (Pcrron, 1991; Bourigault, 1994; Normand,1993).
To appreciate what current limitations areand what would be required to achieve full termrecognition, it is useful to draw the distinction be-tween "term" and "termform" on the one hand, and"term recognition" and "term interpretation" on theother.2.1 Term vs TermformParticularly in the computing community, there is atendency to consider "terms" as strictly formal en-tities.
Although usage among terminologists varies,a term is generally accepted as being the "designa-tion of a defined concept in a special language by alinguistic expression" (ISO, 1988).
A term is hence17II Concept IIII IIII I TERM I III Termform If IFigure 1: Term vs Termformthe intersection between a conceptual realm (a de-fined semantic content) and a linguistic realm (anexpression or termform) as illustrated in Figure 1.A term, thus conceived, cannot be polysemous al-though te rmforms can, and often d% have severalmeanings.
As terms precisely defined in informationprocessing, "virus" and "Trojan Horse" are unam-biguous; as termforms they have other meanings inmedicine and Greek mythology respectively.This view of a term has one very important con-sequence when discussing term recognition.
Firstly,term recognition cannot be carried out on purelyformal grounds.
It requires some level of linguis-tic anMysis.
Indeed, two term-formation processesdo not result in new termforms: convers ion andsemant ic  dr i f t  1.
A third term-formation process,compress ion,  can also result in a new meaning be-ing associated with an existing termform 2.Proper attention to capitalization can generallyresult in the correct recognition of compressed forms.Part-of-speech tagging is required to detect newterms formed through conversion.
This is quitefeasible using statistical taggers like those of Gar-side (1987), Church (1988) or Foster (1991) whichachieve performance upwards of 97% on unrestrictedtext.
Terms formed through semantic drift are thewolves in sheep's clothing stealing through termino-logical pastures.
They are well enough conceMcd toallude at times even the human reader and no au-tomatic term-recognition system has attempted todistinguish such terms, despite the prevalence ofpol-ysemy in such fields as the social sciences (R.iggs,1993) and the importance for purposes of termi-nological standardization that "deviant" usage betracked.
Implementing a system to distinguish new1Conversion occurs when a term is formed by achange in grammatical category.
Verb-to-noun conver-sion commonly occurs for commands in programming orword processing (e.g.
Undelete works if you catch yourmistake quickly).
Semantic drift involves a (sometimessubtle) change in meaning without any change in gram-matical category (viz.
"term" as understood in this pa-per vs the loose ~Jsage of "~etm" to mc~n "termform").2Compression is the shortening of (usually complex)termforms to form acronyms or other initialisms.
ThusPAD can either designate a resistive loss in an electricalcircuit or a "packet assembler-disassembler'.meanings of established termforms would require an-alyzing discourse-level clues that an author is assign-ing a new meaning, and possibly require the appli-cation of pragmatic knowledge.
Until such advancedlevels of analysis can be practically implemented,"term recognition" will largely remain "termformrecognition" and the failure to detect new terms inold termforms will remain a qualitative shortcomingof all term-recognition systems.2.2 Term Recogn i t ion  vs TermI n te rpretat ionThe vast majority of terms in published technicaldictionaries and terminology standards are nouns.Furthermore, most terms have a complex termform,i.e.
they are comprise~t of more than one word.Sublanguages create series of complex termforms inwhich complex forms serve as modifiers (natural lan-guage ~ \[natural anguage\] processing) and/or arethemselves modified (applied \[\[natural language\] pro-cessing\]).
In special language, complex termformscontaining nested termforms, or significant subex-pressions (Baudot, 1984), have hundreds of possi-ble syntagmatic structures (Portelance, 1989; Lau-riston, 1993).
The challenge facing developers ofterm-recognition systems consists in determining thesyntactic and conceptual unity that complex nomi-nals must possess in order to achieve termhood 3Another, and it will be argued far more ambitious,undertaking is te rm in terpreta t ion .
Leonard(1984), Finen (1985) and others have attempted todevise systems that can produce a gloss explicat-ing the semantic relationship that holds between theconstituents of complex nominals (e.g.
family es-tate ~ estate owned by a family).
Such attemptsat achieving even limited "interpretation" result inlarge sets of possible relationships but fail to ac-count for all compounds.
Furthermore, they havegenerally been restricted to termforms with two con-stituents.
For complex termforms with three or moreconstituents, merely identifying how constituents arenested, i.e., between which constituents here existsa semantic relationship, can be difficult to automate(Sparck-:lones, 1985).In most cases, however, term recognition can beachieved without interpreting the meaning of theterm and without analyzing the internal structureof complex termforms.
Many term-recognition sys-tems like TERMINO (David, 1990), the noun-phrasedetector of LOGOS (Logos, 1987), LEXTER (Bouri-gault, 1994), etc., nevertheless attempt o recognizenested termforms.
Encountering "automatic protec-tion switching equipment", systems adopting thisSin this respect, complex termforms, unlike colloca-tions, must designate definable nodes of the conceptualsystem of an area of specialized human activity.
Hencegeneral trend may be as strong a collocation as generalelection, and yet only the latter be considered a term.18approach would produce as output several nestedtermforms (switching equipment, protection switch-ing, protection switching equipment, automatic pro-tection, automatic protection switching) as well asthe maximal termform automatic protection switch-ing equipment.
Because such systems list nestedtermforms in the absence of higher-level analysis,many erroneous "terms" are generated.It has been argued previously on pragmaticgrounds (Lauriston, 1994) that a safer approach isto detect only the maximal  termform.
It couldfurther be said that doing so is theoretically sound.Nesting termforms i a means by which an authorachieves transparency.
Once nested, however, atermform no longer fulfills the naming function.
Itserves as a mnemonic device.
In different languages,different nested termforms are sometimes selected toperform this mnemonic function (e.g.
on-line creditcard checking, for which a documented French equiv-alent is vdrification de crddit au point de vente, lit-erally "point-of-sale credit verification").
Only themaximal termform refers to the designated conceptand thus only recognition of the maximal termformconstitutes term recognition 4.Term interpretation may be required, however~ tocorrectly delimit complex termforms combined bymeans of conjunctions.
Consider the following threeconjunctive xpressions taken from telecommunica-tion texts:(1) buffer content and packet delay distributions(2) mean misframe and frame detection times(3) generalized intersymbol-interference and jitter-free modulated signalsEven the uninitiated reader would probably be in-clined to interpret, correctly, that expression (1) is acombination of two complex termforms: buffer con-tent distribution and packet delay distribution.
Syn-tax or coarse semantics do nothing, however, to pre-vent an incorrect reading: buffer content delay dis-tribution and buffer packet delay distribution.
Ex-pression (2) consists of words having the same se-quence of grammatical categories as expression (1),but in which this second reading is, in fact, correct:mean misframe detection time and mean frame de-tection time.
Although rather similar to the firsttwo, conjunctive xpression (3) is a single term,sometimes designated by the initialism GIJF.Complex termforms appearing in conjunctive x-pressions may thus require term interpretation forproper term recognition, i.e.
reconstructing the con-juncts.
If term recognition is to be carried out inde-pendently of and prior to term interpretation, asis'This does not imply that analyzing the internalstructure of complex termforms is valueless.
It has thevery important, but distinct, value of prodding clues toparadigmatic relationships between terms.presently feasible, then it can only be properly seenas "maximal termform recognition" with the mean-ing of "maximal termform" extended to include theoutermost bracketing of structurally ambiguous con-junctive expressions like the three examples above.This extension in meaning is not a matter of theo-retical soundness but simply of practical necessity.In summary, current systems recognize termformsbut lack mechanisms to detect new terms resultingfrom several term-formation processes, particularlysemantic drift.
Under these circumstances, it is bestto admit that "termform recognition" is the cur-rently feasible objective and to measure performancein achieving it.
Furthermore, since the nested struc-tures of complex termforms perform a mnemonicrather than a naming function, it is theoretically un-sound for an automatic term-recognition system topresent them as terms.
For purposes of measurementand comparison, "term recognition" should thus beregarded as "maximal termform recognition".
Oncethis goal has been reliably achieved, the output ofa term-recognition system could feed a future "terminterpreter", that would also be required to recog-nize terms in ambiguous conjunctive xpressions.3 How Can Recognit ion beMeasured?Once a consensus has been reached about what is tobe recognized, there must be some agreement con-cerning the way in which performance is to be mea-sured.
Fortunately, established performance mea-surements used in information retrieval - recall andprecision - can be adapted quite readily for mea-suring the term-recognition task.
These measureshave, in fact, been used previously in measuringterm recognition (Smadja, 1993; Bourigault, 1994;Lauriston, 1994).
No study, however, adequatelydiscusses how these measurements are applied toterm recognition.3.1 Recall and  PrecisionTraditionally, performance in document retrieval ismeasured by means of a few simple ratios (Salton,1989).
These are based on the premise that anygiven document in a collection is either pertinent ornon-pertinent to a particular user's needs.
Thereis no scale of relative pertinence.
For a given userquery, retrieving a pertinent document constitutes ahit, failing to retrieve a pertinent document consti-tutes a miss, and retrieving a non-pertinent docu-ment constitutes a false hit.
Recall, the ratio ofthe number of hits to the number of pertinent doc-uments in the collection, measures the effectivenessof retrieval.
Precision, the ratio of the number ofhits to the number of retrieved documents, measuresthe e~iciency of retrieval.
The complement of recallis omission (misses/total pertinent).
The comple-ment of precision is noise (false hits/total retrieved).19Ideally, recall and precision would equal 1.0, omis-sion and noise 0.0.
Practical document retrieval in-volves a trade-off between recall and precision.The performance measurements in document re-trieval are quite apparently applicable to term recog-nition.
The basic premise of a pertinent/non-pertinent dichotomy, which prevails in document re-trieval, is probably even better justified for termsthan for documents.
Unlike an evaluation ofthe pertinence of the content of a document, heterm/nonterm distinction is based on a relativelysimple and cohesive semantic ontentS.User judge-ments of document pertinence would appear to bemuch more subjective and difficult to quantify.If all termforms were simple, i.e.
single words,and only simple termforms were recognized, then us-ing document retrieval measurements would be per-fectly .straightforward.
A manually bracketed termwould give rise to a hit or a miss and an automati-cally recognized word would be a hit or a false hit.Since complex termforms are prevalent in sublan-guage texts, however, further clarification is neces-sary.
In particular, "hit" has to be defined moreprecisely.
Consider the following sentence:The latest committee draft reports progress towardconstitutional reform.A terminologist would probably recognize twoterms in this sentence: commiLtee draft and consti-tutional reform.
The termform of each is complex.Regardless of whether symbolic or statistical tech-niques are used, "hits" of debatable usefulness areapt to be produced by automatic term-recognitionsystems.
A syntactically based system might haveparticular difficulty with the three consecutive casesof noun-verb ambiguity draft, reports, progress.
Astatistically based system might detect draft reports,since this cooccurrence might well be frequent as atermform elsewhere in the text.
Consequently, thedefinition of "hit" needs further qualification.3.2 Perfect and Imperfect Recognit ionTwo types of hits must be distinguished.
A per-fect hit occurs when the boundaries assigned bythe term-recognition system coincide with those ofa term's maximal termform (\[committee draft\] and\[constitutional reform\] above).
An imperfect hitoccurs when the boundaries assigned o not coincidewith those of a term's maximal termform but containat least one wordform belonging to a term's maximaltermform.
A hit is imperfect if bracketing either in-dudes spurious wordforms (\[latest committee draft\]Sln practice, terminologists have some difficultyagreeing on the exact delimitation of complex termforms.Still five experienced terminologists scanning a 2,861word text were found to agree on the identity and bound-sties of complex termforms three-quarters of the time(Lauriston, 1993).TARGETTERMFORMSmissesRECOGNIZED TEKMFOKMS~ falseperfect Jl hitshits II?<=limperfect hitst=>?IIrecall =hits: perfect (+ imperfect?
)target termformsprecision =hits: perfect + (imperfect?
)recognized t ermformsFigure 2: Recall, Precision and Imperfect Hitsor \[committee draft reports\]), fails to bracket a termconstituent (committee \[draft\])or both (committee\[draft reports\]).
Bracketing a segment containing nowordform that is part of a term's maximal termformis, of course, a false hit (\[reports progress\]).The problematic case is clearly that of an imper-fect hit.
In calculating recall and precision, shouldimperfect hits be grouped with perfect hits, countedas misses, or somehow accounted for separately (Fig-ure 2)?
How do the perfect recall and precision ra-tios compare with imperfect recall and precision (in-cluding imperfect hits in the numerator) when theseperformance measurements are applied to real texts?Counting imperfectly recognized termforms as hitswill obviously lead to higher ratios for recall andprecision, but how much higher?To answer these questions, a complex-termformrecognition algorithm based on weighted syntacticterm-formation rules, the details of which are givenin Lauriston (1993), was applied to a tagged 2,861word text.
The weightings were based on the analy-sis of a 117,000 word corpus containing 11,614 com-plex termforms as determined by manual bracketing.The recognition algorithm includes the possibility ofweighting of the terminological strength of particu-lar adjectives.
This was carried out to produce theresults hown in Figure 3.Recall and precision, both perfect and imperfect,were plotted as the algorithm's term-recognitionthreshold was varied.
By choosing a higher thresh-old, only syntactically stronger links between ad-jacent words are considered "terminological links".Thus the higher the threshold, the shorter the av-erage complex termform, as weaker modifiers are201.0+0 .9+08+O7+06+05+04+03+02+01+00+r rr r r rr r r r pr r r p r pr r r p r pr r r p r pRr Rr p r p r pRr p Rr p r p r pRr p Rr p r p r pRr p Rr p r p r pRr p Rr p r p r pRr Pp Rr Pp Rr Pp r pRr Pp Rr Pp Rr Pp r pRr Pp Rr Pp Rr Pp r pRr Pp Rr Pp Rr Pp Rr PpRr Pp Rr Pp Rr Pp Rr PpRr Pp Rr Pp Rr Pp Rr PpRr Pp Rr Pp Rr Pp Rr PpRr Pp Rr Pp Rr Pp Rr Pp+ + + +0.05 0.40 0.75 0.95term-recognit ion thresholdKEY:R perfect recall (perfect hits only)r imperfect recall (imperfect also)P perfect precision (perfect hits only)p imperfect precision (imperfect also)Figure 3: Effect of Imperfect Hits of PerformanceRatiosstripped from the nucleus.
Lower recall and higherprecision can be expected as the threshold rises sinceonly constituents hat are surer bets are included inthe maximal termform.This Figure 3 shows that both recall and precisionscores are considerably higher when imperfect hitsare included in calculating the ratios.
As expected,raising the threshold results in lower recall regardlessof whether the ratios are calculated for perfect or im-perfect recognition.
There is a marked reduction inperfect recall, however, and only a marginal reduc-tion in imperfect recall.
The precision ratios providethe most interesting point of comparison.
As thethreshold is raised, imperfect precision increases justas the principle of recall-precision tradeoff in docu-ment retrieval would lead one to expect.
Perfect pre-cision, on the other hand, actually declines lightly.The difference between perfect and imperfect pre-cision (between the P-bar and p-bar in each group)increases appreciably as the threshold is raised.
Thisdifference is due to the greater number of recognizedcomplex termforms either containing spurious wordsor only part of the maximal termform.Two conclusions can be drawn from Figure 3.Firstly, the recognition algorithm implemented ispoor at perfect recognition (perfect recall ~, 0.70;perfect precision ~, 0.40) and only becomes pooreras more stringent rule-weighting is applied.
Sec-ondly, and more importantly for the purpose of thispaper, Figure 3 shows that allowing for imperfectbracketing in term recognition makes it possible toobtain artificially high performance ratios for bothrecall and precision.
Output that recognizes almostall terms but includes spurious words in complextermforms or fails short of recognizing the entiretermform leaves a burdensome filtering task for thehuman user and is next to useless if the "user" is an-other level of automatic text processing.
Only theexact bracketing of the maximal termform providesa useful standard for measuring and comparing theperformance of term-recognition systems.4 ConclusionThe term-recognition criteria proposed above - mea-suring recall and precision for the exact bracketing ofmaximal termforms- provide a basic minimum of in-formation eeded to assess ystem performance.
Forsome applications, it is useful to further specify howthese performance ratios differ for the recognition ofsimple and complex termforms, how they vary forterms resulting from different term-formation pro-cesses, what the ratios are for termform types as op-posed to tokens, or how well the system recognizesnovel termforms not already in a system lexicon orpreviously encountered in a training corpus.
Pre-cision measurements might usefully state to whatextent errors are due to syntact ic  noise (bracket-ing crossing syntactic onstituents) as distinguishedfrom terminological noise (bracketing includingnonclassificatory modifiers or omitting classificatoryones).Publishing such performance results for term-recognition systems would not only display theirstrengths but also expose their weaknesses.
Doingso would ultimately benefit researchers, developersand users of term-recognltion systems.ReferencesBaudot, Jean, and Andr4 Clas (1984).
A modelfor a bilingual terminology mini-bank.
In LebendeSprachen, Vo1.19, No.2, pp.283-298.Black, Ezra, Roger Garside, and Geoffrey Leech(1993).
Statistically-driven computer grammars ofEnglish: the IBM/Lancaster approach.
Amsterdam:Rodopi.Bouriganlt, Didier (1992).
LEXTER, un Logi-ciel d'EXtraction de TERminologie.
In Colloquesur le repdrage de l'information teztuelle, Montr4al,Qu4bec, Hydro-Quebec, March, pp.15-25.Bouriganlt, Didier (1994).
Extraction et struc-turation automatique de terminologie pour l'aidel'acquisition des connaissances ~ partir de textes.
InReconnaissance d s formes et intelligence artificielle(RFIA '9~), Paris, January.21Church, Kenneth W. (1988).
A stochastic partsprogram and noun phrase parser for unrestrictedtext.
In Proceedings of the Second Conferenceon Applied IVatural Language Processing, Austin,Texas.
Association for Computational Linguistics,Morristown, New Jersey, pp.136-143.Daille, B~atrice (1994).
Approche mizte pourl'eztraction automatique de terminologie : statis-tique lezicale et filtres linguistiques.
Universit~ deParis 7 (PhD Thesis), Paris, January.David, Sophie and Pierre Plante (1990).
De lan~cessitE d'une approche morphosyntaxique en anal-yse de textes.
In Intelligence artificielle et sci-ences cognitives au Qudbec, Vol.3 No.3, September,pp.140-155.Finin, Timothy W. (1986).
Constraining the in-terpretation ofnominM compounds ina limited con-text.
In Ralph Grishman and Richard Kittredge,editors, Analyzing language in restricted domains,Hillsdale, New Jersey: Lawrence Erlbaum Asso-ciates, pp.163-173.Foster, George F. (1991).
Statistical lezical dis-ambiguation.
McGill University (MSc Thesis),MontrEal, Quebec.Gaxside, Roger, Geoffrey Leech, and GeoffreySampson, editors (1987).
The computational nal-ysis of English: a corpus-based approach, London,Longman.Gaussier, \]~ric and Jean-Marc Lang~ (1994).
Somemethods for the extraction of bilingual terminol-ogy.
In Proceedings of the International Confer-ence on New Methods in Language Processing (NeM-LAP), Manchester, England, University of Manch-ester Institute of Science and Technology (UMIST),September, pp.242-247.International Organization for Standardization(ISO) (1988).
Terminolgy- vocabulary.
(ISO/DIS1087), Geneva, Switzerland.Jones, Leslie, Edward W. Gassie, and SridharRadhakrishnon (1990).
INDEX: the statistical basisfor an automatic conceptual phrase-indexing system.In Journal of the American Society for InformationScience, Vol.41, No.2, pp.87-97.Lauriston, Andy (1993).
Le rep~rage automa-tique des syntagmes terminologiques.
UniversitE duQuebec ~ Montreal (MA Thesis), MontrEal, Qutbec.Lauriston, Andy (1994).
Automatic recognitionof complex terms: problems and the "Termino" so-lution.
In Terminology: applications in interdisci-plinary communication, Vol.1, No.l, pp.147-170.Leonard, Rosemary (1984).
The interpretation ofEnglish noun sequences on the computer, Amster-dam, North-Holland.Logos Corporation (1987).
LOGOS EnglishSource Release 7.0, Dedham, Mass., Logos Corpo-ration.Normand, Diane (1993).
Quand la terminologies'automatise: du nouveau en terminotique: TermCruncher, un logicel de d~pouillement.
In Circuit,No.42, December, pp.29-30.Otman, Gabriel (1991).
Des ambitions et desperformances d'un syst~me de d~pouillement termi-nologique assist~ pax ordinateur.
In La Banque desroots (special issue on terminology software), No.4,pp.59-96.Perron, Jean (1991).
Presentation du progiciel ded~pouillement terminologique assistE par ordinateur:TerminG.
In Les industries de la langue: perspec-tives des armies 1990, Mont~al, Quebec, Office de lalangue fran~aise/SociEtd des traducteurs du Qudbec,pp.715-755.Portelance, Christine (1989).
Les formations yn-tagmatiques en langues de sp~cialitd.
Universit~ deMontreal, (PhD Thesis), Montreal, Quebec.Riggs, Fred (1993).
Social science terminology:basic problems and proposed solutions.
In Helmi B.Sonneveld and Kurt T. Loening, editors, Terminol-ogy: applications in interdisciplinary communica-tion, Amsterdam, John Benjamins, pp.195-222.Salton, Gerard (1989).
Automatic tezt process-ing: the transformation, analysis, and retrieval ofinforraation by computer, Reading, Mass., Addison-Wesley.Smadja, Frank (1993).
Retrieving collocationsfrom text: Xtract.
In Computational linguistics,Vo1.19, No.1.Spark-Jones, Kaxen (1985).
Compound NounInterpretation Problems.
In Frank Fallside andWilliam A.
Woods, editors, Computer Speech Pro-cessing, Englewood Cliffs, New Jersey, Prentice-Hall, pp.363-381.Van der Eijk, Pik (1993).
Automating the acqui-sition of bilingual terminology.
Proceedings of theEuropean Chapter of the Association for Computa-tional Linguistics (EA CL), pp.ll3-119.22
