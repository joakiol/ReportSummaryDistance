Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 263?272,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsVerb Classification using Distributional Similarityin Syntactic and Semantic StructuresDanilo CroceUniversity of Tor Vergata00133 Roma, Italycroce@info.uniroma2.itAlessandro MoschittiUniversity of Trento38123 Povo (TN), Italymoschitti@disi.unitn.itRoberto BasiliUniversity of Tor Vergata00133 Roma, Italybasili@info.uniroma2.itMartha PalmerUniversity of Colorado at BoulderBoulder, CO 80302, USAmpalmer@colorado.eduAbstractIn this paper, we propose innovative repre-sentations for automatic classification of verbsaccording to mainstream linguistic theories,namely VerbNet and FrameNet.
First, syntac-tic and semantic structures capturing essentiallexical and syntactic properties of verbs aredefined.
Then, we design advanced similarityfunctions between such structures, i.e., seman-tic tree kernel functions, for exploiting distri-butional and grammatical information in Sup-port Vector Machines.
The extensive empir-ical analysis on VerbNet class and frame de-tection shows that our models capture mean-ingful syntactic/semantic structures, which al-lows for improving the state-of-the-art.1 IntroductionVerb classification is a fundamental topic of com-putational linguistics research given its importancefor understanding the role of verbs in conveying se-mantics of natural language (NL).
Additionally, gen-eralization based on verb classification is central tomany NL applications, ranging from shallow seman-tic parsing to semantic search or information extrac-tion.
Currently, a lot of interest has been paid totwo verb categorization schemes: VerbNet (Schuler,2005) and FrameNet (Baker et al, 1998), whichhas also fostered production of many automatic ap-proaches to predicate argument extraction.Such work has shown that syntax is necessaryfor helping to predict the roles of verb argumentsand consequently their verb sense (Gildea and Juras-fky, 2002; Pradhan et al, 2005; Gildea and Palmer,2002).
However, the definition of models for opti-mally combining lexical and syntactic constraints isstill far for being accomplished.
In particular, the ex-haustive design and experimentation of lexical andsyntactic features for learning verb classification ap-pears to be computationally problematic.
For exam-ple, the verb order can belongs to the two VerbNetclasses:?
The class 60.1, i.e., order someone to do some-thing as shown in: The Illinois Supreme Court or-dered the commission to audit Commonwealth Edi-son ?s construction expenses and refund any unrea-sonable expenses .?
The class 13.5.1: order or request something likein: ... Michelle blabs about it to a sandwich manwhile ordering lunch over the phone .Clearly, the syntactic realization can be used to dis-cern the cases above but it would not be enough tocorrectly classify the following verb occurrence: ..ordered the lunch to be delivered .. in Verb class13.5.1.
For such a case, selectional restrictions areneeded.
These have also been shown to be use-ful for semantic role classification (Zapirain et al,2010).
Note that their coding in learning algorithmsis rather complex: we need to take into account syn-tactic structures, which may require an exponentialnumber of syntactic features (i.e., all their possiblesubstructures).
Moreover, these have to be enrichedwith lexical information to trig lexical preference.In this paper, we tackle the problem aboveby studying innovative representations for auto-matic verb classification according to VerbNet andFrameNet.
We define syntactic and semantic struc-tures capturing essential lexical and syntactic prop-erties of verbs.
Then, we apply similarity between263such structures, i.e., kernel functions, which can alsoexploit distributional lexical semantics, to train au-tomatic classifiers.
The basic idea of such functionsis to compute the similarity between two verbs interms of all the possible substructures of their syn-tactic frames.
We define and automatically extracta lexicalized approximation of the latter.
Then, weapply kernel functions that jointly model structuraland lexical similarity so that syntactic properties arecombined with generalized lexemes.
The nice prop-erty of kernel functions is that they can be usedin place of the scalar product of feature vectors totrain algorithms such as Support Vector Machines(SVMs).
This way SVMs can learn the associationbetween syntactic (sub-) structures whose lexical ar-guments are generalized and target verb classes, i.e.,they can also learn selectional restrictions.We carried out extensive experiments on verbclass and frame detection which showed that ourmodels greatly improve on the state-of-the-art (upto about 13% of relative error reduction).
Such re-sults are nicely assessed by manually inspecting themost important substructures used by the classifiersas they largely correlate with syntactic frames de-fined in VerbNet.In the rest of the paper, Sec.
2 reports on relatedwork, Sec.
3 and Sec.
4 describe previous and ourmodels for syntactic and semantic similarity, respec-tively, Sec.
5 illustrates our experiments, Sec.
6 dis-cusses the output of the models in terms of erroranalysis and important structures and finally Sec.
7derives the conclusions.2 Related workOur target task is verb classification but at the sametime our models exploit distributional models aswell as structural kernels.
The next three subsec-tions report related work in such areas.Verb Classification.
The introductory verb classi-fication example has intuitively shown the complex-ity of defining a comprehensive feature representa-tion.
Hereafter, we report on analysis carried out inprevious work.It has been often observed that verb senses tendto show different selectional constraints in a specificargument position and the above verb order is a clearexample.
In the direct object position of the examplesentence for the first sense 60.1 of order, we foundcommission in the role PATIENT of the predicate.
Itclearly satisfies the +ANIMATE/+ORGANIZATIONrestriction on the PATIENT role.
This is not truefor the direct object dependency of the alternativesense 13.5.1, which usually expresses the THEMErole, with unrestricted type selection.
When prop-erly generalized, the direct object information hasthus been shown highly predictive about verb sensedistinctions.In (Brown et al, 2011), the so called dynamicdependency neighborhoods (DDN), i.e., the set ofverbs that are typically collocated with a direct ob-ject, are shown to be more helpful than lexical in-formation (e.g., WordNet).
The set of typical verbstaking a noun n as a direct object is in fact a strongcharacterization for semantic similarity, as all thenounsm similar to n tend to collocate with the sameverbs.
This is true also for other syntactic depen-dencies, among which the direct object dependencyis possibly the strongest cue (as shown for examplein (Dligach and Palmer, 2008)).In order to generalize the above DDN feature, dis-tributional models are ideal, as they are designedto model all the collocations of a given noun, ac-cording to large scale corpus analysis.
Their abil-ity to capture lexical similarity is well established inWSD tasks (e.g.
(Schutze, 1998)), thesauri harvest-ing (Lin, 1998), semantic role labeling (Croce et al,2010)) as well as information retrieval (e.g.
(Furnaset al, 1988)).Distributional Models (DMs).
These models fol-low the distributional hypothesis (Firth, 1957) andcharacterize lexical meanings in terms of context ofuse, (Wittgenstein, 1953).
By inducing geometricalnotions of vectors and norms through corpus analy-sis, they provide a topological definition of seman-tic similarity, i.e., distance in a space.
DMs cancapture the similarity between words such as dele-gation, deputation or company and commission.
Incase of sense 60.1 of the verb order, DMs can beused to suggest that the role PATIENT can be inher-ited by all these words, as suitable Organisations.In supervised language learning, when few exam-ples are available, DMs support cost-effective lexi-cal generalizations, often outperforming knowledgebased resources (such as WordNet, as in (Pantel etal., 2007)).
Obviously, the choice of the context264type determines the type of targeted semantic prop-erties.
Wider contexts (e.g., entire documents) areshown to suggest topical relations.
Smaller con-texts tend to capture more specific semantic as-pects, e.g.
the syntactic behavior, and better captureparadigmatic relations, such as synonymy.
In partic-ular, word space models, as described in (Sahlgren,2006), define contexts as the words appearing in an-sized window, centered around a target word.
Co-occurrence counts are thus collected in a words-by-words matrix, where each element records the num-ber of times two words co-occur within a single win-dow of word tokens.
Moreover, robust weightingschemas are used to smooth counts against too fre-quent co-occurrence pairs: Pointwise Mutual Infor-mation (PMI) scores (Turney and Pantel, 2010) arecommonly adopted.Structural Kernels.
Tree and sequence kernelshave been successfully used in many NLP applica-tions, e.g., parse reranking and adaptation, (Collinsand Duffy, 2002; Shen et al, 2003; Toutanova etal., 2004; Kudo et al, 2005; Titov and Hender-son, 2006), chunking and dependency parsing, e.g.,(Kudo and Matsumoto, 2003; Daume?
III and Marcu,2004), named entity recognition, (Cumby and Roth,2003), text categorization, e.g., (Cancedda et al,2003; Gliozzo et al, 2005), and relation extraction,e.g., (Zelenko et al, 2002; Bunescu and Mooney,2005; Zhang et al, 2006).Recently, DMs have been also proposed in in-tegrated syntactic-semantic structures that feed ad-vanced learning functions, such as the semantictree kernels discussed in (Bloehdorn and Moschitti,2007a; Bloehdorn and Moschitti, 2007b; Mehdad etal., 2010; Croce et al, 2011).3 Structural Similarity FunctionsIn this paper we model verb classifiers by exploitingprevious technology for kernel methods.
In particu-lar, we design new models for verb classification byadopting algorithms for structural similarity, knownas Smoothed Partial Tree Kernels (SPTKs) (Croce etal., 2011).
We define new innovative structures andsimilarity functions based on LSA.The main idea of SPTK is rather simple: (i) mea-suring the similarity between two trees in terms ofthe number of shared subtrees; and (ii) such numberalso includes similar fragments whose lexical nodesare just related (so they can be different).
The con-tribution of (ii) is proportional to the lexical similar-ity of the tree lexical nodes, where the latter can beevaluated according to distributional models or alsolexical resources, e.g., WordNet.In the following, we define our models based onprevious work on LSA and SPTKs.3.1 LSA as lexical similarity modelRobust representations can be obtained throughintelligent dimensionality reduction methods.
InLSA the original word-by-context matrix M is de-composed through Singular Value Decomposition(SVD) (Landauer and Dumais, 1997; Golub and Ka-han, 1965) into the product of three new matrices:U , S, and V so that S is diagonal and M = USV T .M is then approximated by Mk = UkSkV Tk , whereonly the first k columns of U and V are used,corresponding to the first k greatest singular val-ues.
This approximation supplies a way to projecta generic term wi into the k-dimensional space us-ing W = UkS1/2k , where each row corresponds tothe representation vectors ~wi.
The original statisti-cal information about M is captured by the new k-dimensional space, which preserves the global struc-ture while removing low-variant dimensions, i.e.,distribution noise.
Given two words w1 and w2,the term similarity function ?
is estimated as thecosine similarity between the corresponding projec-tions ~w1, ~w2 in the LSA space, i.e ?
(w1, w2) =~w1?
~w2?
~w1??
~w2?.
This is known as Latent Semantic Ker-nel (LSK), proposed in (Cristianini et al, 2001),as it defines a positive semi-definite Gram matrixG = ?
(w1, w2) ?w1, w2 (Shawe-Taylor and Cris-tianini, 2004).
?
is thus a valid kernel and can becombined with other kernels, as discussed in thenext session.3.2 Tree Kernels driven by Semantic SimilarityTo our knowledge, two main types of tree kernelsexploit lexical similarity: the syntactic semantic treekernel defined in (Bloehdorn and Moschitti, 2007a)applied to constituency trees and the smoothedpartial tree kernels (SPTKs) defined in (Croce etal., 2011), which generalizes the former.
We reportthe definition of the latter as we modified it for ourpurposes.
SPTK computes the number of commonsubstructures between two trees T1 and T2 withoutexplicitly considering the whole fragment space.
Its265SVPS-NP-1NNcommission::nDTthe::dVBDTARGET-order::vNP-SBJNNPcourt::nNNPsupreme::nNNPillinois::nDTthe::dFigure 1: Constituency Tree (CT) representation of verbs.ROOTOPRDIMVBaudit::vTOto::tOBJNNcommission::nNMODDTthe::dVBDTARGET-order::vSBJNNPcourt::nNMODNNPsupreme::nNMODNNPillinois::nNMODDTthe::dFigure 2: Representation of verbs according to the Grammatical Relation Centered Tree (GRCT)general equations are reported hereafter:TK(T1, T2) =?n1?NT1?n2?NT2?
(n1, n2), (1)where NT1 and NT2 are the sets of the T1?s and T2?snodes, respectively and ?
(n1, n2) is equal to thenumber of common fragments rooted in the n1 andn2 nodes1.
The ?
function determines the richnessof the kernel space and thus induces different treekernels, for example, the syntactic tree kernel (STK)(Collins and Duffy, 2002) or the partial tree kernel(PTK) (Moschitti, 2006).The algorithm for SPTK?s ?
is the follow-ing: if n1 and n2 are leaves then ??
(n1, n2) =???
(n1, n2); else??
(n1, n2) = ??
(n1, n2)?
(?2 +?~I1,~I2,l(~I1)=l(~I2)?d(~I1)+d(~I2)l(~I1)?j=1??
(cn1(~I1j), cn2(~I2j))), (2)where (1) ?
is any similarity between nodes, e.g., be-tween their lexical labels; (2) ?, ?
?
[0, 1] are decayfactors; (3) cn1(h) is the hth child of the node n1;(4) ~I1 and ~I2 are two sequences of indexes, i.e., ~I =(i1, i2, .., l(I)), with 1 ?
i1 < i2 < .. < il(I); and (5)d(~I1) = ~I1l(~I1)?~I11+1 and d(~I2) = ~I2l(~I2)?~I21+1.Note that, as shown in (Croce et al, 2011), the av-erage running time of SPTK is sub-quadratic in thenumber of the tree nodes.
In the next section weshow how we exploit the class of SPTKs, for verbclassification.1To have a similarity score between 0 and 1, a normalizationin the kernel space, i.e.
TK(T1,T2)?TK(T1,T1)?TK(T2,T2)is applied.4 Verb Classification ModelsThe design of SPTK-based algorithms for our verbclassification requires the modeling of two differ-ent aspects: (i) a tree representation for the verbs;and (ii) the lexical similarity suitable for the task.We also modified SPTK to apply different similarityfunctions to different nodes to introduce flexibility.4.1 Verb Structural RepresentationThe implicit feature space generated by structuralkernels and the corresponding notion of similaritybetween verbs obviously depends on the input struc-tures.
In the cases of STK, PTK and SPTK differenttree representations lead to engineering more or lessexpressive linguistic feature spaces.With the aim of capturing syntactic features, westarted from two different parsing paradigms: phraseand dependency structures.
For example, for repre-senting the first example of the introduction, we canuse the constituency tree (CT) in Figure 1, where thetarget verb node is enriched with the TARGET label.Here, we apply tree pruning to reduce the computa-tional complexity of tree kernels as it is proportionalto the number of nodes in the input trees.
Accord-ingly, we only keep the subtree dominated by thetarget VP by pruning from it all the S-nodes alongwith their subtrees (i.e, all nested sentences are re-moved).
To further improve generalization, we lem-matize lexical nodes and add generalized POS-Tags,i.e., noun (n::), verb (v::), adjective (::a), determiner(::d) and so on, to them.
This is useful for constrain-ing similarity to be only contributed by lexical pairsof the same grammatical category.266TARGET-order::vVBDROOTto::tTOOPRDaudit::vVBIMcommission::nNNOBJthe::dDTNMODcourt::nNNPSBJsupreme::nNNPNMODillinois::nNNPNMODthe::dDTNMODFigure 3: Representation of verbs according to the Lexical Centered Tree (LCT)To encode dependency structure information in atree (so that we can use it in tree kernels), we use(i) lexemes as nodes of our tree, (ii) their dependen-cies as edges between the nodes and (iii) the depen-dency labels, e.g., grammatical functions (GR), andPOS-Tags, again as tree nodes.
We designed twodifferent tree types: (i) in the first type, GR are cen-tral nodes from which dependencies are drawn andall the other features of the central node, i.e., lexi-cal surface form and its POS-Tag, are added as ad-ditional children.
An example of the GR CenteredTree (GRCT) is shown in Figure 2, where the POS-Tags and lexemes are children of GR nodes.
(ii) Thesecond type of tree uses lexicals as central nodes onwhich both GR and POS-Tag are added as the right-most children.
For example, Figure 3 shows an ex-ample of a Lexical Centered Tree (LCT).
For bothtrees, the pruning strategy only preserves the verbnode, its direct ancestors (father and siblings) andits descendants up to two levels (i.e., direct childrenand grandchildren of the verb node).
Note that, ourdependency tree can capture the semantic head ofthe verbal argument along with the main syntacticconstruct, e.g., to audit.4.2 Generalized node similarity for SPTKWe have defined the new similarity ??
to be used inEq.
2, which makes SPTK more effective as shownby Alg.
1.
??
takes two nodes n1 and n2 and appliesa different similarity for each node type.
The latter isderived by ?
and can be: GR (i.e., SYNT), POS-Tag(i.e., POS) or a lexical (i.e., LEX) type.
In our exper-iment, we assign 0/1 similarity for SYNT and POSnodes according to string matching.
For LEX type,we apply a lexical similarity learned with LSA toonly pairs of lexicals associated with the same POS-Tag.
It should be noted that the type-based similarityallows for potentially applying a different similarityfor each node.
Indeed, we also tested an amplifica-tion factor, namely, leaf weight (lw), which ampli-fies the matching values of the leaf nodes.Algorithm 1 ??
(n1, n2, lw)??
?
0,if ?
(n1) = ?
(n2) = SYNT ?
label(n1) = label(n2) then??
?
1end ifif ?
(n1) = ?
(n2) = POS ?
label(n1) = label(n2) then??
?
1end ifif ?
(n1) = ?
(n2) = LEX ?
pos(n1) = pos(n2) then??
?
?LEX(n1, n2)end ifif leaf(n1) ?
leaf(n2) then??
?
??
?
lwend ifreturn ?
?5 ExperimentsIn these experiments, we tested the impact of our dif-ferent verb representations using different kernels,similarities and parameters.
We also compared withsimple bag-of-words (BOW) models and the state-of-the-art.5.1 General experimental setupWe consider two different corpora: one for VerbNetand the other for FrameNet.
For the former, we usedthe same verb classification setting of (Brown et al,2011).
Sentences are drawn from the Semlink cor-pus (Loper et al, 2007), which consists of the Prop-Banked Penn Treebank portions of the Wall StreetJournal.
It contains 113K verb instances, 97K ofwhich are verbs represented in at least one VerbNetclass.
Semlink includes 495 verbs, whose instancesare labeled with more than one class (including onesingle VerbNet class or none).
We used all instancesof the corpus for a total of 45,584 instances for 180verb classes.
When instances labeled with the noneclass are not included, the number of examples be-comes 23,719.The second corpus refers to FrameNet frame clas-sification.
The training and test data are drawn fromthe FrameNet 1.5 corpus2, which consists of 135Ksentences annotated according the frame semantics2http://framenet.icsi.berkeley.edu267(Baker et al, 1998).
We selected the subset offrames containing more than 100 sentences anno-tated with a verbal predicate for a total of 62,813sentences in 187 frames (i.e., very close to the Verb-Net datasets).
For both the datasets, we used 70% ofinstances for training and 30% for testing.Our verb (multi) classifier is designed withthe one-vs-all (Rifkin and Klautau, 2004) multi-classification schema.
This uses a set of binarySVM classifiers, one for each verb class (frame) i.The sentences whose verb is labeled with the classi are positive examples for the classifier i.
The sen-tences whose verbs are compatible with the class ibut evoking a different class or labeled with none(no current verb class applies) are added as negativeexamples.
In the classification phase the binary clas-sifiers are applied by (i) only considering classes thatare compatible with the target verbs; and (ii) select-ing the class associated with the maximum positiveSVM margin.
If all classifiers provide a negativescore the example is labeled with none.To learn the binary classifiers of the schemaabove, we coded our modified SPTK in SVM-Light-TK3 (Moschitti, 2006).
The parameterization ofeach classifier is carried on a held-out set (30% ofthe training) and is concerned with the setting of thetrade-off parameter (option -c) and the leaf weight(lw) (see Alg.
1), which is used to linearly scalethe contribution of the leaf nodes.
In contrast, thecost-factor parameter of SVM-Light-TK is set as theratio between the number of negative and positiveexamples for attempting to have a balanced Preci-sion/Recall.Regarding SPTK setting, we used the lexical simi-larity ?
defined in Sec.
3.1.
In more detail, LSA wasapplied to ukWak (Baroni et al, 2009), which is alarge scale document collection made up of 2 billiontokens.
M is constructed by applying POS tagging tobuild rows with pairs ?lemma, ::POS?
(lemma::POSin brief).
The contexts of such items are the columnsof M and are short windows of size [?3,+3], cen-tered on the items.
This allows for better captur-ing syntactic properties of words.
The most frequent20,000 items are selected along with their 20k con-texts.
The entries of M are the point-wise mutual3(Structural kernels in SVMLight (Joachims, 2000)) avail-able at http://disi.unitn.it/moschitti/Tree-Kernel.htmSTK PTK SPTKlw Acc.
lw Acc.
lw Acc.CT - 83.83% 8 84.57% 8 84.46%GRCT - 84.83% 8 85.15% 8 85.28%LCT - 77.73% 0.1 86.03% 0.2 86.72%Br.
et Al.
84.64%BOW 79.08%SK 82.08%Table 1: VerbNet accuracy with the none classSTK PTK SPTKlw Acc.
lw Acc.
lw Acc.GRCT - 92.67% 6 92.97% 0.4 93.54%LCT - 90.28% 6 92.99% 0.3 93.78%BOW 91.13%SK 91.84%Table 2: FrameNet accuracy without the none classinformation between them.
SVD reduction is thenapplied to M, with a dimensionality cut of l = 250.For generating the CT, GRCT and LCT struc-tures, we used the constituency trees generated bythe Charniak parser (Charniak, 2000) and the de-pendency structures generated by the LTH syntacticparser (described in (Johansson and Nugues, 2008)).The classification performance is measured withaccuracy (i.e., the percentage of correct classifica-tion).
We also derive statistical significance of theresults by using the model described in (Yeh, 2000)and implemented in (Pado?, 2006).5.2 VerbNet and FrameNet ClassificationResultsTo assess the performance of our settings, we alsoderive a simple baseline based on the bag-of-words(BOW) model.
For it, we represent an instance ofa verb in a sentence using all words of the sentence(by creating a special feature for the predicate word).We also used sequence kernels (SK), i.e., PTK ap-plied to a tree composed of a fake root and only onelevel of sentence words.
For efficiency reasons4, weonly consider the 10 words before and after the pred-icate with subsequence features of length up to 5.Table 1 reports the accuracy of different mod-els for VerbNet classification.
It should be notedthat: first, SK produces a much higher accuracy thanBOW, i.e., 82.08 vs. 79.08.
On one hand, this is4The average running time of the SK is much higher than theone of PTK.
When a tree is composed by only one level PTKcollapses to SK.268STK PTK SPTKlw Acc.
lw Acc.
lw Acc.CT - 91.14% 8 91.66% 6 91.66%GRCT - 91.71% 8 92.38% 4 92.33%LCT - 89.20% 0.2 92.54% 0.1 92.55%BOW 88.16%SK 89.86%Table 3: VerbNet accuracy without the none classgenerally in contrast with standard text categoriza-tion tasks, for which n-gram models show accuracycomparable to the simpler BOW.
On the other hand,it simply confirms that verb classification requiresthe dependency information between words (i.e., atleast the sequential structure information providedby SK).Second, SK is 2.56 percent points below the state-of-the-art achieved in (Brown et al, 2011) (BR), i.e,82.08 vs. 84.64.
In contrast, STK applied to our rep-resentation (CT, GRCT and LCT) produces compa-rable accuracy, e.g., 84.83, confirming that syntacticrepresentation is needed to reach the state-of-the-art.Third, PTK, which produces more general struc-tures, improves over BR by almost 1.5 (statisticallysignificant result) when using our dependency struc-tures GRCT and LCT.
CT does not produce the sameimprovement since it does not allow PTK to directlycompare the lexical structure (lexemes are all leafnodes in CT and to connect some pairs of them verylarge trees are needed).Finally, the best model of SPTK (i.e, using LCT)improves over the best PTK (i.e., using LCT) by al-most 1 point (statistically significant result): this dif-ference is only given by lexical similarity.
SPTK im-proves on the state-of-the-art by about 2.08 absolutepercent points, which, given the high accuracy of thebaseline, corresponds to 13.5% of relative error re-duction.We carried out similar experiments for frame clas-sification.
One interesting difference is that SK im-proves BOW by only 0.70, i.e., 4 times less than inthe VerbNet setting.
This suggests that word orderaround the predicate is more important for derivingthe VerbNet class than the FrameNet frame.
Ad-ditionally, LCT or GRCT seems to be invariant forboth PTK and SPTK whereas the lexical similaritystill produces a relevant improvement on PTK, i.e.,13% of relative error reduction, for an absolute accu-racy of 93.78%.
The latter improves over the state-50%60%70%80%90%0% 20% 40% 60% 80% 100%AccuracyPercentage of train examplesSPTKBOWBrown et alFigure 4: Learning curves: VerbNet accuracy with thenone Classof-the-art, i.e., 92.63% derived in (Giuglea and Mos-chitti, 2006), by using STK on CT on 133 frames.We also carried out experiments to understandthe role of the none class.
Table 3 reports on theVerbNet classification without its instances.
This isof course an unrealistic setting as it would assumethat the current VerbNet release already includes allsenses for English verbs.
In the table, we note thatthe overall accuracy highly increases and the differ-ence between models reduces.
The similarities playno role anymore.
This may suggest that SPTK canhelp in complex settings, where verb class character-ization is more difficult.
Another important role ofSPTK models is their ability to generalize.
To testthis aspect, Figure 4 illustrates the learning curvesof SPTK with respect to BOW and the accuracyachieved by BR (with a constant line).
It is impres-sive to note that with only 40% of the data SPTK canreach the state-of-the-art.6 Model Analysis and DiscussionWe carried out analysis of system errors and its in-duced features.
These can be examined by apply-ing the reverse engineering tool5 proposed in (Pighinand Moschitti, 2010; Pighin and Moschitti, 2009a;Pighin and Moschitti, 2009b), which extracts themost important features for the classification model.Many mistakes are related to false positives and neg-atives of the none class (about 72% of the errors).This class also causes data imbalance.
Most errorsare also due to lack of lexical information availableto the SPTK kernel: (i) in 30% of the errors, theargument heads were proper nouns for which thelexical generalization provided by the DMs was not5http://danielepighin.net/cms/software/flink269VerbNet class 13.5.1(IM(VB(target))(OBJ))(VC(VB(target))(OBJ))(VC(VBG(target))(OBJ))(OPRD(TO)(IM(VB(target))(OBJ)))(PMOD(VBG(target))(OBJ))(VB(target))(VC(VBN(target)))(PRP(TO)(IM(VB(target))(OBJ)))(IM(VB(target))(OBJ)(ADV(IN)(PMOD)))(OPRD(TO)(IM(VB(target))(OBJ)(ADV(IN)(PMOD))))VerbNet class 60(VC(VB(target))(OBJ))(NMOD(VBG(target))(OPRD))(VC(VBN(target))(OPRD))(NMOD(VBN(target))(OPRD))(PMOD(VBG(target))(OBJ))(ROOT(SBJ)(VBD(target))(OBJ)(P(,)))(VC(VB(target))(OPRD))(ROOT(SBJ)(VBZ(target))(OBJ)(P(,)))(NMOD(SBJ(WDT))(VBZ(target))(OPRD))(NMOD(SBJ)(VBZ(target))(OPRD(SBJ)(TO)(IM)))Table 4: GRCT fragmentsavailable; and (ii) in 76% of the errors only 2 or lessargument heads are included in the extracted tree,therefore tree kernels cannot exploit enough lexicalinformation to disambiguate verb senses.
Addition-ally, ambiguity characterizes errors where the sys-tem is linguistically consistent but the learned selec-tional preferences are not sufficient to separate verbsenses.
These errors are mainly due to the lack ofcontextual information.
While error analysis sug-gests that further improvement is possible (e.g.
byexploiting proper nouns), the type of generalizationscurrently achieved by SPTK are rather effective.
Ta-ble 4 and 5 report the tree structures characterizingthe most informative training examples of the twosenses of the verb order, i.e.
the VerbNet classes13.5.1 (make a request for something) and 60 (giveinstructions to or direct somebody to do somethingwith authority).In line with the method discussed in (Pighin andMoschitti, 2009b), these fragments are extracted asthey appear in most of the support vectors selectedduring SVM training.
As easily seen, the two classesare captured by rather different patterns.
The typ-ical accusative form with an explicit direct objectemerges as characterizing the sense 13.5.1, denot-ing the THEME role.
All fragments of the sense 60emphasize instead the sentential complement of theverb that in fact expresses the standard PROPOSI-TION role in VerbNet.
Notice that tree fragmentscorrespond to syntactic patterns.
The a posterioriVerbNet class 13.5.1(VP(VB(target))(NP))(VP(VBG(target))(NP))(VP(VBD(target))(NP))(VP(TO)(VP(VB(target))(NP)))(S(NP-SBJ)(VP(VBP(target))(NP)))VerbNet class 60(VBN(target))(VP(VBD(target))(S))(VP(VBZ(target))(S))(VBP(target))(VP(VBD(target))(NP-1)(S(NP-SBJ)(VP)))Table 5: CT fragmentsanalysis of the learned models (i.e.
the underlyingsupport vectors) confirm very interesting grammati-cal generalizations, i.e.
the capability of tree kernelsto implicitly trigger useful linguistic inductions forcomplex semantic tasks.
When SPTK are adopted,verb arguments can be lexically generalized intoword classes, i.e., clusters of argument heads (e.g.commission vs. delegation, or gift vs. present).
Au-tomatic generation of such classes is an interestingdirection for future research.7 ConclusionWe have proposed new approaches to characterizeverb classes in learning algorithms.
The key idea isthe use of structural representation of verbs based onsyntactic dependencies and the use of structural ker-nels to measure similarity between such representa-tions.
The advantage of kernel methods is that theycan be directly used in some learning algorithms,e.g., SVMs, to train verb classifiers.
Very interest-ingly, we can encode distributional lexical similar-ity in the similarity function acting over syntacticstructures and this allows for generalizing selectionrestrictions through a sort of (supervised) syntacticand semantic co-clustering.The verb classification results show a large im-provement over the state-of-the-art for both Verb-Net and FrameNet, with a relative error reductionof about 13.5% and 16.0%, respectively.
In the fu-ture, we plan to exploit the models learned fromFrameNet and VerbNet to carry out automatic map-ping of verbs from one theory to the other.Acknowledgements This research is partially sup-ported by the European Community?s Seventh Frame-work Programme (FP7/2007-2013) under grant numbers247758 (ETERNALS), 288024 (LIMOSINE) and 231126(LIVINGKNOWLEDGE).
Many thanks to the reviewersfor their valuable suggestions.270ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The berkeley framenet project.Marco Baroni, Silvia Bernardini, Adriano Ferraresi, andEros Zanchetta.
2009.
The wacky wide web: a collec-tion of very large linguistically processed web-crawledcorpora.
LRE, 43(3):209?226.Stephan Bloehdorn and Alessandro Moschitti.
2007a.Combined syntactic and semantic kernels for text clas-sification.
In Gianni Amati, Claudio Carpineto, andGianni Romano, editors, Proceedings of ECIR, vol-ume 4425 of Lecture Notes in Computer Science,pages 307?318.
Springer, APR.Stephan Bloehdorn and Alessandro Moschitti.
2007b.Structure and semantics for expressive text kernels.In CIKM?07: Proceedings of the sixteenth ACM con-ference on Conference on information and knowledgemanagement, pages 861?864, New York, NY, USA.ACM.Susan Windisch Brown, Dmitriy Dligach, and MarthaPalmer.
2011.
Verbnet class assignment as a wsd task.In Proceedings of the Ninth International Conferenceon Computational Semantics, IWCS ?11, pages 85?94,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Razvan Bunescu and Raymond Mooney.
2005.
A short-est path dependency kernel for relation extraction.
InProceedings of HLT and EMNLP, pages 724?731,Vancouver, British Columbia, Canada, October.Nicola Cancedda, Eric Gaussier, Cyril Goutte, andJean Michel Renders.
2003.
Word sequence kernels.Journal of Machine Learning Research, 3:1059?1082.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proceedings of NAACL?00.Michael Collins and Nigel Duffy.
2002.
New Rank-ing Algorithms for Parsing and Tagging: Kernels overDiscrete Structures, and the Voted Perceptron.
In Pro-ceedings of ACL?02.Nello Cristianini, John Shawe-Taylor, and Huma Lodhi.2001.
Latent semantic kernels.
In Carla Brodley andAndrea Danyluk, editors, Proceedings of ICML-01,18th International Conference on Machine Learning,pages 66?73, Williams College, US.
Morgan Kauf-mann Publishers, San Francisco, US.Danilo Croce, Cristina Giannone, Paolo Annesi, andRoberto Basili.
2010.
Towards open-domain semanticrole labeling.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics,pages 237?246, Uppsala, Sweden, July.
Associationfor Computational Linguistics.Danilo Croce, Alessandro Moschitti, and Roberto Basili.2011.
Structured Lexical Similarity via ConvolutionKernels on Dependency Trees.
In Proceedings ofEMNLP 2011.Chad Cumby and Dan Roth.
2003.
Kernel Methods forRelational Learning.
In Proceedings of ICML 2003.Hal Daume?
III and Daniel Marcu.
2004.
Np bracketingby maximum entropy tagging and SVM reranking.
InProceedings of EMNLP?04.Dmitriy Dligach and Martha Palmer.
2008.
Novel se-mantic features for verb sense disambiguation.
InACL (Short Papers), pages 29?32.
The Association forComputer Linguistics.J.
Firth.
1957.
A synopsis of linguistic theory 1930-1955.
In Studies in Linguistic Analysis.
PhilologicalSociety, Oxford.
reprinted in Palmer, F. (ed.
1968) Se-lected Papers of J. R. Firth, Longman, Harlow.G.
W. Furnas, S. Deerwester, S. T. Dumais, T. K. Lan-dauer, R. A. Harshman, L. A. Streeter, and K. E.Lochbaum.
1988.
Information retrieval using a sin-gular value decomposition model of latent semanticstructure.
In Proc.
of SIGIR ?88, New York, USA.Daniel Gildea and Daniel Jurasfky.
2002.
Automatic la-beling of semantic roles.
Computational Linguistic,28(3):496?530.Daniel Gildea and Martha Palmer.
2002.
The neces-sity of parsing for predicate argument recognition.
InProceedings of the 40th Annual Conference of theAssociation for Computational Linguistics (ACL-02),Philadelphia, PA.Ana-Maria Giuglea and Alessandro Moschitti.
2006.
Se-mantic role labeling via framenet, verbnet and prop-bank.
In Proceedings of ACL, pages 929?936, Sydney,Australia, July.Alfio Gliozzo, Claudio Giuliano, and Carlo Strapparava.2005.
Domain kernels for word sense disambiguation.In Proceedings of ACL?05, pages 403?410.G.
Golub and W. Kahan.
1965.
Calculating the singularvalues and pseudo-inverse of a matrix.
Journal of theSociety for Industrial and Applied Mathematics: Se-ries B, Numerical Analysis.T.
Joachims.
2000.
Estimating the generalization per-formance of a SVM efficiently.
In Proceedings ofICML?00.Richard Johansson and Pierre Nugues.
2008.Dependency-based syntactic?semantic analysiswith PropBank and NomBank.
In Proceedings ofCoNLL 2008, pages 183?187.Taku Kudo and Yuji Matsumoto.
2003.
Fast methods forkernel-based text analysis.
In Proceedings of ACL?03.Taku Kudo, Jun Suzuki, and Hideki Isozaki.
2005.Boosting-based parse reranking with subtree features.In Proceedings of ACL?05.Tom Landauer and Sue Dumais.
1997.
A solution toplato?s problem: The latent semantic analysis theory271of acquisition, induction and representation of knowl-edge.
Psychological Review, 104.Dekang Lin.
1998.
Automatic retrieval and clustering ofsimilar word.
In Proceedings of COLING-ACL, Mon-treal, Canada.Edward Loper, Szu ting Yi, and Martha Palmer.
2007.Combining lexical resources: Mapping between prop-bank and verbnet.
In In Proceedings of the 7th Inter-national Workshop on Computational Linguistics.Yashar Mehdad, Alessandro Moschitti, and Fabio Mas-simo Zanzotto.
2010.
Syntactic/semantic structuresfor textual entailment recognition.
In HLT-NAACL,pages 1020?1028.Alessandro Moschitti.
2006.
Efficient convolution ker-nels for dependency and constituent syntactic trees.
InProceedings of ECML?06, pages 318?329.Sebastian Pado?, 2006.
User?s guide to sigf: Signifi-cance testing by approximate randomisation.Patrick Pantel, Rahul Bhagat, Bonaventura Coppola,Timothy Chklovski, and Eduard Hovy.
2007.
Isp:Learning inferential selectional preferences.
In Pro-ceedings of HLT/NAACL 2007.Daniele Pighin and Alessandro Moschitti.
2009a.
Ef-ficient linearization of tree kernel functions.
In Pro-ceedings of CoNLL?09.Daniele Pighin and Alessandro Moschitti.
2009b.
Re-verse engineering of tree kernel feature spaces.
In Pro-ceedings of EMNLP, pages 111?120, Singapore, Au-gust.
Association for Computational Linguistics.Daniele Pighin and Alessandro Moschitti.
2010.
Onreverse feature engineering of syntactic tree kernels.In Proceedings of the Fourteenth Conference on Com-putational Natural Language Learning, CoNLL ?10,pages 223?233, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Sameer Pradhan, Kadri Hacioglu, Valeri Krugler, WayneWard, James H. Martin, and Daniel Jurafsky.
2005.Support vector learning for semantic argument classi-fication.
Machine Learning Journal.Ryan Rifkin and Aldebaro Klautau.
2004.
In defense ofone-vs-all classification.
Journal of Machine LearningResearch, 5:101?141.Magnus Sahlgren.
2006.
The Word-Space Model.
Ph.D.thesis, Stockholm University.Karin Kipper Schuler.
2005.
VerbNet: A broad-coverage, comprehensive verb lexicon.
Ph.D. thesis,University of Pennsylyania.Hinrich Schutze.
1998.
Automatic word sense discrimi-nation.
Journal of Computational Linguistics, 24:97?123.John Shawe-Taylor and Nello Cristianini.
2004.
KernelMethods for Pattern Analysis.
Cambridge UniversityPress.Libin Shen, Anoop Sarkar, and Aravind k. Joshi.
2003.Using LTAG Based Features in Parse Reranking.
InEmpirical Methods for Natural Language Processing(EMNLP), pages 89?96, Sapporo, Japan.Ivan Titov and James Henderson.
2006.
Porting statisti-cal parsers with data-defined kernels.
In Proceedingsof CoNLL-X.Kristina Toutanova, Penka Markova, and ChristopherManning.
2004.
The Leaf Path Projection View ofParse Trees: Exploring String Kernels for HPSG ParseSelection.
In Proceedings of EMNLP 2004.Peter D. Turney and Patrick Pantel.
2010.
From fre-quency to meaning: Vector space models of semantics.Journal of Artificial Intelligence Research, 37:141?188.Ludwig Wittgenstein.
1953.
Philosophical Investiga-tions.
Blackwells, Oxford.Alexander S. Yeh.
2000.
More accurate tests for the sta-tistical significance of result differences.
In COLING,pages 947?953.Ben?at Zapirain, Eneko Agirre, Llu?
?s Ma`rquez, and Mi-hai Surdeanu.
2010.
Improving semantic role classi-fication with selectional preferences.
In Human Lan-guage Technologies: The 2010 Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, HLT ?10, pages 373?376,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2002.
Kernel methods for relationextraction.
In Proceedings of EMNLP-ACL, pages181?201.Min Zhang, Jie Zhang, and Jian Su.
2006.
Explor-ing Syntactic Features for Relation Extraction using aConvolution tree kernel.
In Proceedings of NAACL.272
