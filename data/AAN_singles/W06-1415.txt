Proceedings of the Fourth International Natural Language Generation Conference, pages 103?110,Sydney, July 2006. c?2006 Association for Computational LinguisticsGenerating Intelligent Numerical Answersin a Question-Answering SystemVe?ronique MoriceauInstitut de Recherche en Informatique de Toulouse118, route de Narbonne, 31062 Toulouse, Francemoriceau@irit.frAbstractIn this paper, we present a question-answering system on the Web which aimsat generating intelligent answers to numer-ical questions.
These answers are gener-ated in a cooperative way: besides a directanswer, comments are generated to ex-plain to the user the variation of numericaldata extracted from the Web.
We presentthe content determination and realisationtasks.
We also present some elements ofevaluation with respect to end-users.1 IntroductionSearch engines on the Web and most existingquestion-answering (QA) systems provide the userwith a set of hyperlinks and/or Web page extractscontaining answer(s) to a question.
These answersmay be incoherent to a certain degree: they may beequivalent, complementary, contradictory, at dif-ferent levels of precision or specificity, etc.
It isthen quite difficult for the user to know which an-swer is the correct one.
Thus, an analysis of rel-evance and coherence of candidate answers is es-sential.1.1 Related workSearch engines on the Web produce a set of an-swers to a question in the form of hyperlinks orpage extracts, ranked according to content or pop-ularity criteria (Salton, 1989; Page et al, 1998).Some QA systems on the Web use other tech-niques: candidate answers are ranked accordingto a score which takes into account lexical re-lations between questions and answers, semanticcategories of concepts, distance between words,etc.
(Moldovan et al, 2003), (Narayanan andHarabagiu, 2004), (Radev and McKeown, 1998).Recently, advanced QA systems defined rela-tionships (equivalence, contradiction, ...) betweenWeb page extracts or texts containing possible an-swers in order to combine them and to producea single answer (Radev and McKeown, 1998),(Harabagiu and Lacatusu, 2004), (Webber et al,2002).Most systems provide the user with either a setof potential answers (ranked or not), or the ?best?answer according to some relevance criteria.
Theydo not provide answers which take into accountinformation from a set of candidate answers oranswer inconsistencies.
As for logical approachesused for database query, they are based on major-ity approach or on source reliability.
But, contraryto the assumption of (Motro et al, 2004), we notedthat reliability information (information about theauthor, date of Web pages, ...) is rather difficultto obtain, so we assume that all Web pages areequally reliable.1.2 Motivations and goalsOur framework is advanced QA systems over opendomains.
Our main goals are to model and to eval-uate a system which, from a factoid question innatural language (in French), selects a set of can-didate answers on the Web and generates cooper-ative answers in natural language.
Our challengeis (1) to generate a synthetic answer instead of alist of potential answers (in order to avoid provid-ing the user with too much information), and (2) togenerate relevant comments which explain the va-riety of answers extracted from the Web (in orderto avoid misleading the user) (Grice, 1975).
In acooperative perspective, we propose an approachfor answer generation which uses answer integra-tion.
When several possible answers are extractedfrom the Web, the goal is to define a coherent core103from candidate answers and to generate a cooper-ative answer, i.e.
an answer with explanations.In this paper, we focus on the integration of nu-merical data in order to generate natural languagecooperative answers to numerical questions.
Wefirst present some motivational problems for thegeneration of numerical answers in a QA system.Then, we present the content determination andrealization processes.
Finally, we give some el-ements of evaluation of our system outputs, withrespect to end-users.2 On numerical dataWe focus on the integration of numerical datafor the generation of natural language coopera-tive numerical answers.
We first present some re-lated work on generation from numerical data sets.Then we propose a model for the generation of co-operative numerical answers.2.1 Related workThe generation of summaries from numerical datahas been developed in some NLG systems.
For ex-ample, the system ANA (Kukich, 1983) generatesstock market reports by computing fluctuationsfor a day.
FoG (Goldberg et al 1994) producesweather forecasts from forecast data.
More re-cently, StockReporter (Dale, 2003) was developedto generate summaries describing how a stock per-forms over a period.
Yu et al (2005) propose asystem which generates summaries of sensor datafrom gas turbines.Those systems have input data analysis compo-nents which are more or less efficient and describenumerical time-series data.
In the framework ofQA systems, there are other major problems thatthe previous systems do not deal with.
When anumerical question is submitted to a QA system,a set of numerical data is extracted from the Web.Then, the goal is not to describe the whole data setbut to find an appropriate answer, dealing with theuser expectations (for example, contraints in thequestion) or data inconsistencies.
Another impor-tant point is the analysis of numerical input data inorder to identify causes (besides time) of variation.2.2 A typology of numerical answersOur challenge is to develop a formal frameworkfor the integration of numerical data extractedfrom Web pages in order to produce cooperativenumerical answers.To define the different types of numericalanswers, we collected a set of 80 question-answerpairs about prices, quantities, age, time, weight,temperature, speed and distance.
The goal isto identify for each question-answer pair whyextracted numerical values are different (is this aninconsistency?
an evolution?
).A numerical question may accept severalanswers when numerical values vary accordingto some criteria.
Let us consider the followingexamples.Example 1 :How many inhabitants are there in France?- Population census in France (1999): 60184186.- 61.7: number of inhabitants in France in 2004.Example 2 :What is the average age of marriage of women in2004?- In Iran, the average age of marriage of womenwas 21 years in 2004.- In 2004, Moroccan women get married at theage of 27.Example 3 :At what temperature should I serve wine?- Red wine must be served at room temperature.- Champagne: between 8 and 10 ?
C.- White wine: between 8 and 11 ?
C.The corpus analysis allows us to identify 3 mainvariation criteria, namely time (ex.1), place (ex.2)and restriction (ex.3: restriction on the focus, forexample: Champagne/wine).
These criteria can becombined: some numerical values vary accordingto time and place, to time and restrictions, etc.
(forexample, the average age of marriage vary accord-ing to time, place and restrictions on men/women).2.3 A model for cooperative numericalanswer generationThe system has to generate an answer from a setof numerical data.
In order to identify the differentproblems, let us consider the following example :What is the average age of marriage in France?- In 1972, the average age of marriage was 24.5for men and 22.4 for women.
In 2005, it is 30 formen and 28 for women.- The average age of marriage in France increasedfrom 24.5 to 26.9 for women and from 26.5 to 29for men between 1986 and 1995.104This set of potential answers may seem incoher-ent but their internal coherence can be made ap-parent once a variation criterion is identified.
In acooperative perspective, an answer can be for ex-ample:In 2005, the average age of marriage in Francewas 30 for men and 28 for women.It increased by about 5.5 years between 1972 and2005.This answer is composed of:1. a direct answer to the question,2.
an explanation characterizing the variationmode of the numerical value.To generate this kind of answer, it is necessary (1)to integrate candidate answers in order to elabo-rate a direct answer (for example by solving incon-sistencies), and (2) to integrate candidate answerscharacteristics in order to generate an explanation.Figure 1 presents the general architecture of oursystem which allows us to generate answers andexplanations from several different numerical an-swers.
Questions are submitted in natural lan-guage to QRISTAL1 which analyses them and se-lects potential answers from the Web.
Then, agrammar is applied to extract information neededfor the generation of an appropriate cooperativeanswer.
This information is mainly:- the searched numerical value (val),- the unit of measure,- the question focus,- the date and place of the information,- the restriction(s) on the question focus ,- the precision of the numerical value (for exampleadverbs or prepositions such as in about 700, ...),- linguistic clues indicating a variation of the value(temporal adverbs, verbs of change/movement asin the price increased to 200 euro).For the extraction of restrictions, a set of basicproperties is defined (colors, form, material, etc.
).Ontologies are also necessary.
For example, forthe question how many inhabitants are therein France?, population of overseas regions andmetropolitan population are restrictions of Francebecause they are daughters of the concept Francein the ontology.
On the contrary, prison popula-tion of France is not a restriction because prison isnot a daughter of France.
Several ontologies areavailable2 but the lack of available knowledge for1www.qristal.fr, Synapse De?veloppement2http://www.daml.org/ontologies/Figure 1: Architecturesome domains obviously influences the quality ofanswers.We define the set A = {a1, ..., aN}, with ai aframe which gathers all this information for a nu-merical value.
Figure 2 shows an extraction result.Figure 2: Extraction resultsFrom the frame set, the variation criteria andmode of the searched numerical value are iden-tified: these components perform content deter-mination.
Finally, a natural language answer isgenerated explaining those characteristics.
Eachof these stages is presented in the next sections.3 Content determination forexplanationsIn order to produce explanations for data variation,the system must have a data analysis component105which can infer, from extracted information, thevariation phenomena, criteria and mode.3.1 Variation criteriaOnce we have the frames representing the differentnumerical values, the goal is to determine if thereis a variation and to identify the variation criteriaof the value.
We assume that there is a variation ifthere is at least k different numerical values withdifferent criteria (time, place, restriction) amongthe N frames (for the moment, we arbitrarily setk = N/4, but this has to be evaluated).
Thus, anumerical value varies according to:1. time if T = {ai(V al), ?
aj ?
A,such as ai(V al) 6= aj(V al)?
ai(Unit) = aj(Unit)?
ai(Date) 6= aj(Date) }?
card(T ) ?
k2.
place if P = {ai(V al), ?
aj ?
A,such as ai(V al) 6= aj(V al)?
ai(Unit) = aj(Unit)?
ai(Place) 6= aj(Place) }?
card(P ) ?
k3.
restriction if Rt = {ai(V al), ?
aj ?
A,such as ai(V al) 6= aj(V al)?
ai(Unit) = aj(Unit)?
ai(Restriction) 6= aj(Restriction) }?
card(Rt) ?
k4.
time and place if (1) ?
(2)5. time and restriction if (1) ?
(3)6. place and restriction if (2) ?
(3)7. time, place and restriction if (1)?
(2)?
(3)Numerical values can be compared only if theyhave the same unit of measure.
If not, they have tobe converted.
More details about comparison rulesare presented in (Moriceau, 2006).3.2 Variation modeIn the case of numerical values varying over time,it is possible to characterize more precisely thevariation.
The idea is to draw a trend (increase,decrease, ...) of variaton over time so that a preciseexplanation can be generated.
For this purpose, wedraw a regression line which determines the rela-tionship between the two extracted variables valueand date.In particular, Pearson?s correlation coefficient (r),related to the line slope, reflects the degree of lin-ear relationship between two variables.
It rangesfrom +1 to ?1.
For example, figure 3 shows that apositive Pearson?s correlation implies a general in-crease of values whereas a negative Pearson?s cor-relation implies a general decrease.
On the con-trary, if r is low (?0.6 < r < 0.6), then we con-sider that the variation is random (Fisher, 1925).Figure 3: Variation modeFigure 4 shows the results for the question Howmany inhabitants are there in France?
Differ-ent numerical values and associated dates are ex-tracted from Web pages.
The Pearson?s correlationis 0.694 meaning that the number of inhabitantsincreases over time (between 1999 and 2005).Figure 4: Variation mode: How many inhabitantsare there in France?4 Answer generationOnce the searched numerical values have been ex-tracted and characterized by their variation crite-ria and mode, a cooperative answer is generated innatural language.
It is composed of two parts:- a direct answer if available,- an explanation of the value variation.4.1 Direct answer generation4.1.1 Question constraintsThe content determination process for the di-rect answer generation is mainly guided by con-straints which may be explicit or implicit in thequestion.
For example, in the question how manyinhabitants are there in France in 2006?, there106are explicit constraints on time and place.
Onthe contrary, in how many inhabitants are there inFrance?, there is no constraint on time.
Let C bethe set of question constraints: C = {Ct, Cp, Cr}with :- Ct: constraint on time (Ct ?
{exp time, ?
}),- Cp: constraint on place (Cp ?
{exp place, ?
}),- Cr: constraint on restrictions (Cr ?
{exp restr,?
}).For example, in the question what is the averageage of marriage in France?
: Ct = ?, Cp = Franceand Cr = ?.When there is no explicit constraint in the ques-tion, we distinguish several cases:- if there is no explicit constraint on time in thequestion and if a numerical variation over time hasbeen infered from the data set, then we assume thatthe user wants to have the most recent information:Ct = max({ai(date), ai ?
A}),- if there is no explicit constraint on place in thequestion and if a numerical variation according toplace has been infered from the data set, then weassume that the user wants to have the informationfor the closest place to him (the system can havethis information for example via a user model),- if there is no explicit constraint on restrictions inthe question and if a numerical variation accord-ing to restrictions has been infered from the dataset, then we assume that the user wants to have theinformation for any restrictions.For example, on figure 5: Ct = 2000 (the mostrecent information), Cp = France and Cr = ?.4.1.2 Candidate answersCandidate frames for direct answers are thosewhich satisfy the set of constraints C .
Let AC bethe set of frames which satisfy C (via subsump-tion):AC = {ai ?
A, such asai(date) = (Ct ?
?)
?
ai(place) = (Cp ?
?)
?ai(restriction) ={Cr ?
?
if Cr 6= ?exp rest ?
?
if Cr = ?For figure 5: AC = {a1, a2, a3, a4, a5, a6}.4.1.3 Choosing a direct answerA direct answer has to be generated fromthe set AC .
We define subsets of AC whichcontain frames having the same restrictions: adirect answer will be generated for each relevantrestriction.
Let A be the subsets of framessatisfying the question constraints and having thesame restrictions: A = {AC1, ..., ACM} with:ACi = {aj , such as ?
aj , ak ?
AC,aj(restriction) = ak(restriction)?
aj(restriction) = ?
},and AC1, ..., ACM are disjoint.For figure 5: A = {AC1, AC2} with:AC1 = {a1, a3, a5}, subset for restriction women,AC2 = {a2, a4, a6}, subset for restriction men.Then, for each element in A , an answer isgenerated :?
ACi ?
A , answer = generate answer(ACi).Each element of A may contain one or sev-eral frames, i.e.
one or several numerical data.Some of these values may be aberrant (for exam-ple, How high is the Eiffel Tower?
300m, 324m,18cm): they are filtered out via classical statisticalmethods (use of the standard deviation).
Amongthe remaining frames, values may be equal or notat different degrees (rounded values, for example).Those values have to be integrated so that a syn-thetic answer can be generated.There are many operators used in logical ap-proaches for fusion: conjunction, disjunction, av-erage, etc.
But, they may produce an answerwhich is not cooperative: a conjunction or disjunc-tion of all candidates may mislead users; the aver-age of candidates is an ?artificial?
answer since ithas been computed and not extracted from Webpages.Our approach allows the system to choose avalue among the set of possible values, dealingwith the problem of rounded or approximativedata.
Candidate values are represented by an ori-ented graph whose arcs are weighted with the costbetween the two linked values and the weight (w)of the departure value (its number of occurrences).A graph G of numerical values is defined by Nthe set of nodes (set of values) and A rc the set ofarcs.
The cost c(x, y) of arc(x, y) is:|x ?
y|y ?
(w(x) +n?i=1w(xi)) +n?i=1c(xi, x).with (x1, ..., xn, x) a path from x1 to x.Finally, we define a fusion operator whichselects the value which is used for the directanswer.
This value is the one which maximizesthe difference (cost(x)) between the cost to leavethis value and the cost to arrive to this value:107Figure 5: Data set for What is the average age of marriage in France?answer = y ?
N , such ascost(y) = max({ cost(n), ?
n ?
N ,cost(n) = cost leave(n) ?
cost arrive(n)})with: cost leave(x) =?i c(x, xi) and,cost arrive(x) =?i c(xi, x).Let us consider an example.
The following val-ues are candidate for the direct answer to the ques-tion How high is the Mont-Blanc?
: 4800, 4807(2 occurrences), 4808 (2 occurrences), 4808.75,4810 (8 occurrences) and 4813.
Figure 6 showsthe graph of values: in this example, the valuewhich maximizes the costs is 4810.From the selected value, the system generatesa direct answer in natural language in the formof Focus Verb (Precision) Value.
For example,the generated answer for How high is the Mont-Blanc?
is The Mont-Blanc is about 4810 metershigh.
Here the preposition about indicates to theuser that the given value is an approximation.For the question what is the average age of mar-riage in France?, a direct answer has to be gen-erated for each restriction.
For the restriction men(AC2), there are 3 candidate values: 29.8, 30 and30.6, the value which minimizes the costs being30.
For the restriction women (AC1), there arealso 3 candidate values: 27.7, 28 and 28.5, thevalue which minimizes the costs being 28.
Af-ter aggregation process, the generated direct an-swer is: In 2000, the average age of marriage inFrance was about 30 years for men and 28 yearsfor women.4.2 Explanation generationThe generation of the cooperative part of the an-swer is complex because it requires lexical knowl-edge.
This part of the answer has to explain tothe user variation phenomena of search values:when a variation of values is identified and char-acterised, an explanation is generated in the formof X varies according to Criteria.
In the case ofvariation according to restrictions or properties ofthe focus, a generalizer is generated.
For exam-ple, the average age of marriage varies for men andwomen: the explanation is in the form the averageage of marriage varies according to sex.
The gen-eralizer is the mother concept in the ontology or aproperty of the mother concept (Benamara, 2004).For numerical value varying over time, if the vari-ation mode (increase or decrease) is identified,a more precise explanation is generated: X in-creased/decreased between... and... instead of Xvaries over time.Here, verbs are used to express precisely numer-ical variations.
The lexicalisation process needsdeep lexical descriptions.
We use for that pur-pose a classification of French verbs (Saint-Dizier,1999) based on the main classes defined by Word-Net.
The classes we are interested in for ourtask are mainly those of verbs of state (have,be, weight, etc.
), verbs of change (increase, de-crease, etc.)
and verbs of movement (climb,move forward/backward, etc.)
used metaphori-cally (Moriceau et al 2003).
From these classes,we selected a set of about 100 verbs which can beapplied to numerical values.From these classes, we characterized sub-classesof growth, decrease, etc., so that the lexicalisationtask is constrained by the type of verbs which hasto be used according to the variation mode.A deep semantics of verbs is necessary to gen-erate an answer which takes into account the char-acteristics of numerical variation as well as pos-sible: for example, the variation mode but alsothe speed and range of the variation.
Thus, foreach sub-class of verbs and its associated varia-tion mode, we need a refined description of onto-logical domains and selectional restrictions so that108Figure 6: Graph of candidate values for How high is the Mont-Blanc?an appropriate verb lexicalisation can be chosen:which verb can be applied to prices, to age, etc.?
(Moriceau et al 2003).
We propose to use propor-tional series representing verb sub-classes accord-ing to the speed and amplitude of variation.
Forexample, the use of climb (resp.
drop) indicatesa faster growth (resp.
decrease) than go up (resp.go down): the verb climb is prefered for the gener-ation of Gas prices climb 20.3% in october 2005whereas go up is prefered in Gas prices went up7.2% in september 2005.Verbs can possibly be associated with a preposi-tion that refines the information (The average ageof marriage increased by about 5.5 years between1972 and 2005).4.3 Answer justificationOur system generates a cooperative answer com-posed of a direct answer to the question and an ex-planation for the possible variation of the searchednumerical value.
But the answer may not be surebecause of a too high/low number of candidatevalues to the direct answer.
In this case, it may beuseful to add some additional information for theuser in order to justify or complete the generatedanswer.We propose to add a know-how component toour system, which provides the user with one ortwo relevant Web page extracts besides the gen-erated answer whenever it is necessary.
These ex-tracts must contain information about the searchednumerical values, and for example some explana-tions of the causes of numerical variation.
Somelinguistic clues can be used to select page extracts:number of numerical values concerning the ques-tion focus, causal marks (because of, due to, ...),etc.
Figure 7 shows an output example of our sys-tem.Figure 7: An ouput example5 EvaluationIn this section, we present some elements of eval-uation of our system with respect to 15 end-users3 .We first evaluated how users behave when theyare faced with different candidate answers to aquestion.
To each user, we presented 5 numeri-cal questions and their candidate answers whichvary according to time or restrictions and ask themto produce their own answer from candidate an-swers.
For numerical answers varying accordingto restrictions, 93% of subjects produce answersexplaining the different numerical values for eachrestriction.
For numerical answers varying overtime, 80% of subjects produce answers giving themost recent information (20% of subjects producean answer which a summary of all candidate val-ues).
This validates our hypothesis presented insection 4.1.1.The second point we evaluated is the answer or-der.
Our system produces answers in the form ofa direct answer, then an explanation and a justi-fication (page extract) if necessary.
We proposedto users answers with these three parts arrangedrandomly.
Contrary to (Yu et al 2005) which pro-pose first an overview and then a zoom on inter-3Subjects are between 20 and 35 years old and are accus-tomed to using search engines.109esting phenomena, 73% of subjects prefered theorder proposed by our system, perhaps because, inQA systems, users wants to have a direct answerto their question before having explanations.The last point we evaluated is the quality of thesystem answers.
For this purpose, we asked sub-jects to choose, for 5 questions, which answer theyprefer among: the system answer, an average, aninterval and a disjunction of all candidate answers.91% of subjects prefered the system answer.
75%of subjects found that the explanation produced isuseful and only 31% of subjects consulted the Webpage extract (28% of these found it useful).6 ConclusionWe proposed a question-answering system whichgenerates intelligent answers to numerical ques-tions.
Candidate answers are first extracted fromthe Web.
Generated answers are composed ofthree parts: (1) a direct answer: the contentdetermination process ?chooses?
a direct answeramong candidates, dealing with data inconsisten-cies and approximations, (2) an explanation: thecontent determination process allows to identify,from data sets, the possible value variations andto infer their variation criteria (time, place or re-strictions on the question focus), and (3) a possi-ble Web page extract.
This work has several futuredirections among which we plan:- to define precisely in which cases it is useful topropose a Web page extract as a justification and,- to measure the relevance of restrictions on thequestion focus to avoid generating an enumerationof values corresponding to irrelevant restrictions.ReferencesF.
Benamara.
2004.
Generating Intensional Answersin Intelligent Question Answering Systems.
LNAISeries, volume 3123, Springer.R.
Dale.
2003. http://www.ics.mq.edu.au/ lgt-demo/StockReporter/.R.
A. Fisher 1925.
Statistical Methods for ResearchWorkers, originally published in London by Oliverand Boyd.E.
Goldberg, N. Driedger, R. Kittredge.
1994.
Us-ing natural language processing to produce weatherforecasts.
IEEE Expert 9(2).H.P.
Grice.
1975.
Logic and conversation.
In P. Coleand J.L.
Morgan, (eds.
): Syntax and Semantics, Vol.3, Speech Acts, New York, Academic Press.S.
Harabagiu and F. Lacatusu.
2004.
Strategies forAdvanced Question Answering.
Proceedings of theWorkshop on Pragmatics of Question Answering atHLT-NAACL 2004.K.
Kukich.
1983.
Knowledge-based report genera-tion: a knowledge engineering approach to naturallanguage report generation.
Ph.D. Thesis, Informa-tion Science Department, University of Pittsburgh.D.
Moldovan, C. Clark, S. Harabagiu and S. Maiorano.2003.
COGEX: A Logic Prover for Question An-swering.
Proceedings of HLT-NAACL 2003.V.
Moriceau and P. Saint-Dizier.
2003.
A ConceptualTreatment of Metaphors for NLP.
Proceedings ofICON, Mysore, India.V.
Moriceau.
2006.
Numerical Data Integrationfor Question-Answering.
Proceedings of EACL-KRAQ?06, Trento, Italy.A.
Motro, P. Anokhin.
2004.
Fusionplex: resolutionof data inconsistencies in the integration of hetero-geneous information sources.
Information Fusion,Elsevier.S.
Narayanan, S. Harabagiu.
2004.
Answering Ques-tions Using Adcanced Semantics and Probabilis-tic Inference.
Proceedings of the Workshop onPragmatics of Question Answering, HLT-NAACL,Boston, USA, 2004.L.
Page, S. Brin, R. Motwani, T. Winograd.
1998.
ThePageRank Citation Ranking: Bringing Ordre to theWeb.
Technical Report, Computer Science Depart-ment, Stanford University.D.R.
Radev and K.R.
McKeown.
1998.
Generat-ing Natural Language Summaries from Multiple On-Line Sources.
Computational Linguistics, vol.
24,issue 3 - Natural Language Generation.P.
Saint-Dizier.
1999.
Alternations and Verb SemanticClasses for French.
Predicative Forms for NL andLKB, Kluwer Academic.P.
Saint-Dizier.
2005.
PrepNet: a Framework forDescribing Prepositions: preliminary investigationresults.
Proceedings of IWCS?05, Tilburg, TheNetherlands.G.
Salton.
2002.
Automatic Text Processing.
TheTransformation, Analysis and Retrieval of Informa-tion by Computer, Addison-Wesley.B.
Webber, C. Gardent and J. Bos.
2002.
Positionstatement: Inference in Question Answering.
Pro-ceedings of LREC, Las Palmas, Spain.J.
Yu, E. Reiter, J.
Hunter, C. Mellish.
2005.
Choosingthe content of textual summaries of large time-seriesdata sets.
Natural Language Engineering, 11.110
