Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007), pages 1?8,Prague, 28 June 2007. c?2007 Association for Computational LinguisticsNaming the Past: Named Entity and Animacy Recognitionin 19th Century Swedish LiteratureLars Borin, Dimitrios Kokkinakis, Leif-J?ran OlssonLitteraturbanken and Spr?kdata/Spr?kbankenDepartment of Swedish Language, G?teborg UniversitySweden{first.last}@svenska.gu.seAbstractThis paper provides a description andevaluation of a generic named-entity rec-ognition (NER) system for Swedish appliedto electronic versions of Swedish literaryclassics from the 19th century.
We discussthe challenges posed by these texts and thenecessary adaptations introduced into theNER system in order to achieve accurateresults, useful both for metadata genera-tion, but also for the enhancement of thesearching and browsing capabilities of Lit-teraturbanken, the Swedish LiteratureBank, an ongoing cultural heritage projectwhich aims to digitize significant works ofSwedish literature.1 IntroductionIn this paper we investigate generic named entityrecognition (NER) technology and the necessaryadaptation required in order to automatically anno-tate electronic versions of a number of Swedishliterary works of fiction from the 19th century.Both the genre and language variety are markedlydifferent from the text types that our NER systemwas originally developed to annotate.
This presentsa challenge, posing both specific and more genericproblems that need to be dealt with.In section 2 we present briefly the backgroundand motivation for the present work, and section 3gives some information on related work.
In section4 we provide a description of the named entity rec-ognition system used in this work, its entity taxon-omy, including the animacy recognition compo-nent and the labeled consistency approach that isexplored.
Problems faced in the literary texts andthe kinds of adaptations performed in the recogni-tion system as well as evaluation and error analysisare given in section 5.
Finally, section 6 summa-rizes the work and provides some thoughts for fu-ture work.2 BackgroundLitteraturbanken <http://litteraturbanken.se/> (theSwedish Literature Bank) is a cultural heritage pro-ject financed by the Swedish Academy1.
Littera-turbanken has as its aim to make available onlinethe full text of significant works of Swedish litera-ture, old and new, in critical editions suitable forliterary research and for the teaching of literature.There is also abundant ancillary material on thewebsite, such as author presentations, bibliogra-phies, thematic essays about authorships, genres orperiods, written by experts in each field.Similarly to many other literature digitizationinitiatives, most of the works in Litteraturbankenare such for which copyright has expired (i.e., atleast 70 years have passed since the death of theauthor); at present the bulk of the texts are from the18th, 19th and early 20th century.
However, thereis also an agreement with the organizations repre-senting authors?
intellectual property rights, allow-ing the inclusion of modern works according to auniform royalty payment scheme.
At present, Lit-teraturbanken holds about 150 works ?
mainlynovels ?
by about 50 different authors.
The textcollection is slated to grow by 80?100 novel-lengthworks (appr.
4?6 million words) annually.1 The present permanent version of Litteraturbanken was pre-ceded by a two-year pilot project by the same name, funded bythe Bank of Sweden Tercentenary Foundation.1Even at outset of the Litteraturbanken project, itwas decided to design the technical solutions withlanguage technology in mind.
The rationale for thiswas that we saw these literary texts not only as rep-resenting Sweden?s literary heritage, but also ashigh-grade empirical data for linguistic investiga-tions, i.e.
as corpus components.
Hence, we wantedto build an infrastructure for Litteraturbankenwhich would allow this intended dual purpose ofthe material to be realized to the fullest.2 However,we soon started to think about how the kinds ofannotations that language technology could pro-vide could be of use to others than linguists, e.g.literary scholars, historians and researchers in otherfields in the humanities and social sciences.Here, we will focus on one of these annotationtypes, namely NER and entity annotation.
Com-bined with suitable interfaces for displaying,searching, selecting, correlating and browsingnamed entities, we believe that the recognition andannotation of named entities in Litteraturbankenwill facilitate more advanced research on literature(particularly in the field of literary onomastics; seeDalen-Oskam and Zundert, 2004), but also, e.g.,historians could find this facility useful, insofar asthese fictional narratives also contain, e.g.
descrip-tions of real locations, characterizations of realcontemporary public figures, etc.
Flanders et al(1998: 285) argue that references to people in his-torical sources are of intrinsic interest since theymay reveal ?networks of friendship, enmity, andcollaboration; familial relationships; and politicalalliances [?]
class position, intellectual affilia-tions, and literary bent of the author?.3 Related WorkThe presented work is naturally related to researchon NER, particularly as applied to dia-chronic/historical corpora.
The technology itselfhas been applied to various domains and genresover the last couple of decades such as financialnews and biomedicine, with performance rates dif-ficult to compare since the task is usually tied toparticular domains/genres and applications.
For aconcise overview of the technology see Borthwick,2 This precluded the use of ready-made digital library or CMSsolutions, as we wanted to be compatible with emerging stan-dards for language resources and tools, e.g.
TEI/(X)CES andISO TC37/SC07, which to our knowledge has never been aconsideration in the design of digital library or CM systems.(1999).
Even though this technology is widely usedin a number of domains, studies dealing with his-torical corpora are mostly comparatively recent(see for instance the recent workshop on historicaltext mining;<http://ucrel.lancs.ac.uk/events/htm06/>).Shoemaker (2005) reports on how the Old Bai-ley Proceedings, which contain accounts of trialsthat took place at the Old Bailey, the primarycriminal court in London, between 1674 and 1834,was marked up for a number of semantic catego-ries, including the crime date and location, the de-fendant?s gender, the victim?s name etc.
Most ofthe work was done manually while support wasprovided for automatic person name3 identification(cf.
Bontcheva et al, 2002).
The author mentionsfuture plans to take advantage of the structurednature of the Proceedings and to use the lists ofpersons, locations and occupations that have al-ready been compiled for annotating new texts.Crane and Jones (2006) discuss the evaluation ofthe extraction of 10 named entity classes (personalnames, locations, dates, products, organizations,streets, newspapers, ships, regiments and railroads)from a 19th century newspaper.
The quality oftheir results vary for different entity types, from99.3% precision for Streets to 57.5% precision forProducts.
The authors suggest the kinds of knowl-edge that digital libraries need to assemble as partof their machine readable reference collections inorder to support entity identification as a core ser-vice, namely, the need for bigger authority lists,more refined rule sets and rich knowledge sourcesas training data.At least least two projects are also relevant inthe context of NER and historical text processing,namely NORA <http://www.noraproject.org/> andARMADILLO<http://www.hrionline.ac.uk/armadillo/>.
The goalof the first is to produce text mining software fordiscovering, visualizing, and exploring significantpatterns across large collections of full-text hu-manities resources in existing digital libraries.
Thegoal of the latter is to evaluate the benefits ofautomated mining techniques (including informa-tion extraction) on a set of online resources ineighteenth-century British social history.3 By using the General Architecture for Text Engineering(GATE) platform; <http://gate.ac.uk>.24 Named Entity RecognitionNamed entity recognition (NER) or entity identifi-cation/extraction, is an important supporting tech-nology with numerous applications in a number ofhuman language technologies.
The system we useoriginates from the work conducted in the NomenNescio project; for details see Johannessen et al(2005).
In brief, the Swedish system is a multi-purpose NER system, comprised by a number ofmodules applied in a pipeline fash-ion.
Six majorcomponents can be distinguished, making a clearseparation between lexical, gram-matical and proc-essing resources.
The six compo-nents are:?
lists of multiword names, taken fromvarious Internet sites or extracted from vari-ous corpora, running directly over the to-kenised text being processed;?
a rule-based, shallow parsing componentthat uses finite-state grammars, one gram-mar for each type of entity recognized;?
a module that uses the annotations pro-duced by the previous two components,which have a high rate in precision, in orderto make decisions regarding other un-annotated entities.
This module is furtherdiscussed in Section 4.2;?
lists of single names (approx.
100,000);?
name similarity, this module is furtherdiscussed in Section 4.3;?
a theory revision and refinement mod-ule, which makes a final control of an anno-tated document, in order to detect and re-solve possible errors and assign new annota-tions based on existing ones, for instance byapplying name similarity or by combiningvarious annotation fragments.4.1 Named-Entity TaxonomyThe nature and type of named entities vary depend-ing on the task under investigation or the targetapplication.
In any case, personal names, locationand organization names are considered ?generic?.Since semantic annotation is not as well under-stood as grammatical annotation, there is no con-sensus on a standard tagset and content to be gen-erally applicable.
Recently, however, there havebeen attempts to define and apply richer name hi-erarchies for various tasks, both specific (Fleisch-man and Hovy, 2002) and generic (Sekine, 2004).Our current system implements a rather fine-grained named entity taxonomy with 8 mainnamed entitiy types as well as 57 subtypes.
Detailscan be found in Johannessen et al, 2005, and Kok-kinakis, 2004.
The eight main categories are:?
Person (PRS): people names (forenames,surnames), groups of people, animal/petnames, mythological, theonyms;?
Location (LOC): functional locations,geographical, geo-political, astrological;?
Organization (ORG): political, athletic,media, military, etc.;?
Artifact (OBJ): food/wine products,prizes, communic.
means (vehicles) etc.;?
Work&Art (WRK): printed material,names of films and novels, sculptures etc.;?
Event (EVN): religious, athletic, scien-tific, cultural etc.;?
Measure/Numerical (MSR): volume, age,index, dosage, web-related, speed etc.;?
Temporal (TME).Time expressions are important since they allowtemporal reasoning about complex events as wellas time-line visualization of the story developed ina text.
The temporal expressions recognized in-clude both relative (n?sta vecka ?next week?)
andabsolute expressions (klockan 8 p?
morgonen i dag?8 o?clock in the morning today?
), and sets or se-quences of time points or stretches of time (varjedag ?every day?
).4.2 Animacy RecognitionThe rule-based component of the person-name rec-ognition grammar is based on a large set of desig-nator words and a group of phrases and verbalpredicates that most probably require an animatesubject (e.g.
ber?tta ?to tell?, fundera ?to think?,tr?ttna ?to become tired?).
These are used in con-junction with orthographic markers in the text,such as capitalization, for the recognition of per-sonal names.
In this work, we consider the firstgroup (designators) as relevant knowledge to beextracted from the person name recognizer, whichis explored for the annotation of animate instances3in the literary texts.
The designators are imple-mented as a separate module in the current pipe-line, and constitute a piece of information which isconsidered important for a wide range of tasks (cf.Orasan and Evans, 2001).The designators are divided into four groups:designators that denote the nationality or the eth-nic/racial group of a person (e.g.
tysken ?the Ger-man [person]?
); designators that denote a profes-sion (e.g.
l?karen ?the doctor?
); those that denotefamily ties and relationships (e.g.
sv?rson ?son inlaw?
); and finally a group that indicates a humanindividual but cannot be unambiguously catego-rized into any of the three other groups (e.g.
pa-tienten ?the patient?).
Apart from this grouping,inherent qualities, for at least a large group of thedesignators, (internal evidence/morphologicalcues) also indicate referent (natural) gender.
In thisway, the animacy annotation is further specifiedfor male, female or unknown gender; unknown inthis context means unresolved or ambiguous, suchas barn ?child?.Swedish is a compounding language and com-pound words are written as a single orthographicunit (i.e.
solid compounds).
This fact makes therecognition of animacy straightforward with mini-mal resources and feasible by the use of a set ofsuitable headwords, and by capturing modifiers bysimple regular expressions.
Approximately 25 pat-terns are enough to identify the vast majority ofanimate entities in a text; patterns such as?inna/innan/innor?, ?man/mannen/m?n/m?nnen?,?log/logen/loger?, ?kt?r/kt?ren/kt?rer?
and?iker/ikern/ikerna?.
For instance, the pattern in (1)consists of a reliable suffix ?inna?
which is a typi-cal designator for female individuals, preceded bya set of obligatory strings and an optional regularexpression which captures a long list of com-pounds (2).
(1) [a-z???]*(kv|?lskar|man|grev|?
)inna(2) taleskvinna, yrkeskvinna, idrotts-kvinna, ungkvinna, Stockholmskvin-na, Dalakvinna, sambo?lskarinna,lyx?lskarinna, ex-?lskarinna, sam-largrevinna, ex?lskarinna, markgre-vinna, majgrevinna, ?nkegrevinna,?Examples of animacy annotations are given in (3).The attribute value FAM stands for FAmily relationand Male; PRM for PRofession and Male; FAF forFAmily relation and Female and finally UNF forUNknown and Female.
(3) [?
]<ENAMEX TYPE="FAM">riksgrefvin-nans far</ENAMEX>, <ENAMEX TYPE="PRM">?fveramiralen</ENAMEX> [?
]hade till <ENAMEX TYPE="FAF">mor</ENAMEX> <ENAMEX TYPE="UNF">gre-fvinnan</ENAMEX> Beata Wrangel fr?n[?
]Table (3) in Section 6.1 presents the results for theevaluation of this type of normative information.Note also, that in order to make the annotationsmore practical we have included the person namedesignators (e.g.
?herr?
?
?Mr?)
in the markup as in(4); here PRS stands for PeRSon:(4) <ENAMEX TYPE="UNM">Herr</ENAMEX><ENAMEX TYPE="PRS" SBT="HUM">Boman</ENAMEX> becomes <ENAMEX TYPE="PRS-UNM" SBT="HUM">Herr Boman</ENAMEX>4.3 Name SimilarityWe can safely assume that the various system re-sources will not be able to identify all possible en-tities in the texts, particularly personal and locationnames.
Although there is a large overlap betweenthe names in the texts and the gazetteer lists, therewere cases that could be considered as entity can-didates but were left unmarked.
This is becauseexhaustive lists of names even for limited domainsare hard to obtain, and, in some domains even dif-ficult to manage.
Therefore, we also calculated theorthographic similarity between such words andthe gazetteer content, according to the followingcriteria: a potential entity starts with a capital let-ter; it is ?
5 characters long; it is not part of anyother annotation and it does not stand in the begin-ning of a sentence.
We have empirically observedthat the length of 5 characters is a reliable thresh-old, unlikely to exclude many NEs.
As a matter offact, only two such cases could be found in theevaluation sample, namely ?tten Puff ?the familyPuff?
and ?Yen-?
in the context ?Yen- kenberg?As measure of orthographic similarity (or rather,difference) we used the Levenshtein distance (LD;also known as edit distance) between two strings.The LD is the number of deletions, insertions orsubstitutions required to transform a string intoanother string.
The greater the distance, the moredifferent the strings are.
We chose to regard 1 and2 as trustworthy values and disregarded the rest.We chose these two values since empirical obser-vations suggest that contemporary Swedish and419th century Swedish entities usually differ in oneor two characters.
In case of more than one match,we choose the most frequent alternative, as in thecase of Wenern below.
Table 1 illustrates variouscases and the obtained results.text word # gazeteer LD ann.
?
?Dalarne 6 Dalarna 1 loc yesAsptomten 1 --- --- --- -H?rnevi* 1 Arnevi 2 prs noSabbathsberg 1 Sabbatsberg 1 loc yesWenern* 7 Werner,WaernV?nern22prslocnoKakn?s 1 Valn?s,Ramn?s 2 loc yesKallmar 1 Kalmar 1 loc yesTable 1.
LD between potential NEs and the ga-zeteers; ?*?
: both are locations;????
: correct annot.
?5 The Document Centered ApproachThere is a known tradeoff between rule-based andstatistical systems.
Handcrafted grammar-basedsystems typically obtain better results, but at thecost of considerable manual effort by domain ex-perts.
Statistical NER systems typically require alarge amount of manually annotated training data,but can be ported to other domains or genres morerapidly and require less manual work.
Although theSwedish system is mainly rule-based, using ahandcrafted grammar for each entity group, it canalso be considered a hybrid system in the sensethat it applies a document-centered approach(DCA) to entity annotation, which is a differentparadigm compared to the local context approach,called external evidence by McDonald (1996).With DCA, information for the disambiguation ofa name is derived from the entire document.DCA as a term originates from the work byMikheev (2000: 138), who claims that:important words are typically used in adocument more than once and in differentcontexts.
Some of these contexts createvery ambiguous situations but some don?t.Furthermore, ambiguous words andphrases are usually unambiguously intro-duced at least once in the text unless theyare part of common knowledge presup-posed to be known by the readers.This implies a form of online learning from thedocument being processed where unambiguoususages are used for assigning annotations to am-biguous words, and information for disambiguationis derived from the entire document.Similarly, label consistency, the preference ofthe same annotation for the same word sequenceeverywhere in a particular discourse, is a compara-ble approach for achieving qualitatively higher re-call rates with minimal resource overhead (cf.Krishnan and Manning, 2006).
Such an approachhas been used, e.g., by Aramaki et al (2006), forthe identification of personal health information(age, id, date, phone, location and doctor?s and pa-tient?s names).Figure 1.
Example of label consistencyFigure 1 illustrates this approach with an exampletaken from Almqvist?s Collected Works, Vol.
30.
Inthis example, the first occurrence of the femaleperson name Micmac, which is not in the gazetteerlists, is introduced by the author with the unambi-guous designator faster ?aunt?.
Many of the subse-quent mentions of the same name are given with-out any reliable clue for appropriate labelling.However, as already discussed, there is strong evi-dence that subsequent mentions of the same nameshould be annotated with the same label, and sincethe same entity usually appears more than once inthe same discourse, in our case a book, labellingconsistency should guarantee better performance.There are exceptions for certain NE categorieswhich may consist of words that are not propernouns such as in the Work&Art category, and ofcourse the temporal and measure groups which areblocked from this type of processing; cf.
section6.2.6 Evaluation and Error AnalysisThe system was evaluated twice, while no nor-malization or other preprocessing was applied tothe original documents.
Problems identified duringthe first evaluation round were taken under consid-eration and specific changes were suggested to thesystem by incorporating appropriate modifications.5During the first run, no adaptations or enhance-ments were made to the original NER system.
Af-ter the first evaluation round, four major areaswere identified in which the system either failed toproduce an annotation or produced only partial orerroneous annotations.
These failures were causedby:?
Spelling variation: particularly the use of<f/w/e/q> instead of <v/v/?/k> as in modernSwedish.
Most of the cases could be easilysolved while other required different meanssuch as calculating the LD between thename lists and possible name mentions inthe texts (Section 4.3).
One case that couldbe easily tackled was the addition of alter-nate spelling forms for a handful of key-words and designators, especially the prepo-sition av/af common in temporal contexts,such as i b?rjan af/av 1790-talet ?in the be-ginning of the 1790s?
; or words suchbegge/b?gge ?both?
and qv?ll/kv?ll ?eve-ning?;?
A number of definite plural forms ofnouns, often designating a group of persons,with the suffix ?erne?
instead the ?erna?
asin modern Swedish, such as Kine-serne/Kineserna ?the Chinese [people]?
andSvenskarne/Svenskarna ?the Swedes?;?
Unknown names: mentioned once withunreliable context;?
Structure preservation: the documentstructure of the texts in Litteraturbankens isdesigned to create a faithful rendering of thevisual appearance of the original printedbooks.
In extracting the texts from the XMLformat used in Litteraturbanken, we did notwant to apply any kind of normalization orother processing.
Such an approach wouldhave altered the document structure.
Thisimplies that for a handful of the entities, forwhich the hyphenation in the original paperversion has divided a name into two parts, asin (5), correct identification cannot be ac-complished, while in some cases only a par-tial identification was possible, as in (6).
(5) [?]
Stock- holm(6) <ENAMEX TYPE=?PRS?
SBT=?HUM?>Berthavon Lichten-</ENAMEX> ried6.1 ResultsAs a baseline for the evaluation we use the resultof simple dictionary lookup in the single namegazetteer.
This process is very accurate (w.r.t.
pre-cision).
We could identify a number of cases witherroneous annotations, due to various circum-stances: Names in the gazetteer lists may havemultiple entity tags associated with them, and thusan entity may belong to more than one group thatcould not be disambiguated by the surroundingcontext, such as Ekhammar as a city and surname;many names are ambiguous with common nounsor verbs, such as Stig as a first name and as theverb ?step/walk?
; the gazetteers contained a num-ber of words that should not have been in the list inthe first place, such as Hvem ?Who?, styrman ?firstmate?
and f?nrik ?lieutenant?.
A probable cause ofthe latter problem is the fact that the name listshave been semi-automatically compiled from vari-ous sources including corpora and the Internet.We performed two evaluations, based on twodifferent random samples consisting of 500 seg-ments (roughly 30,000 tokens) each.
A segmentconsists of an integral number of sentences (up to10?20).
The overall results for all tests are shownin table 2.
Results for individual entities using thewhole system during both runs are found in table 3.The samples were evaluated according to preci-sion, recall and f-score using the formulas:Precision = (Total Correct + Partially Corrtect) /All ProducedRecall = (Total Correct + Partially Correct) /All PossibleF-score =2*P*R/P+R.Table 2.
Overall performance of the NER6Table 3.
Performance of the NER on the individualnamed entities including animacyPartially correct means that an annotation gets par-tial credit.
For instance, if the system produces anannotation for the functional location Nya Elemen-tarskolan as in (7) instead of the correct (8), thensuch annotations are given half a point, instead of aperfect score.
(7) Nya <ENAMEX TYPE=?LOC?
SBT=?FNC?>Elementarskolan</ENAMEX>(8) <ENAMEX TYPE=?LOC?
SBT=?FNC?>NyaElementarskolan</ENAMEX>If, on the other hand, the type is correct but thesubtype is wrong, then the annotation is given ascore of 0.75 points (e.g.
a functional location in-stead of a geopolitical location).6.2 Limitations of the Centering ApproachLabeling consistency and the DCA approach relieson the assumption that usage is consistent withinthe same document by the same author.
However,we have observed that there are problems with en-tities composed of more than a single word, par-ticularly within the group Work&Art, which canproduce conflicting information, if we allow theindividual words in such content (often nouns oradjectives) to be re-applied in the text.For instance, the name of the novel Syster ochbror occurred 32 times in one of the evaluationtexts (Almqvist?s Collected Works Volume 29).
Ifwe allow the individual words that constitute thetitle, Syster, och and bror to be re-applied in thetext as individual words (2 common nouns and aconjunction), then we would have degraded theprecision considerably since we would have al-lowed Work&Art annotations for irrelevant words.However, such cases can be resolved by simplyletting the system ignore multiword Work&Artannotations during the DCA processing.Figure 2.
Occurrences of the multi-word entity Sys-ter och bror; the rule-based system could reliablyidentify and annotate 2/32 occurrences.Generally speaking, the experimental results haveshown that any breaking of a multiword entity,except personal names, into its individual wordsoften has a negative effect on performance.
Thebest results are achieved when the DCA approachdeals with single or bigram entities, particularlypersonal names.77 Conclusions and Future ProspectsIn this paper we have described the application of ageneric Swedish named entity recognition systemto a number of literary texts, novels from the 19thcentury, part of Litteraturbanken, the Swedish Lit-erature Bank.
We evaluated the results of thenamed entity recognition and identified a numberof error sources which we tried to resolve and thenintroduce changes that would cover for such casesin the rule-based component of the system, in orderto increase its performance (precision and recall)during a second evaluation round.Entity annotations open up a whole new re-search spectrum for new kinds of qualitative andquantitative exploitations of literary and historicaltexts, allowing more semantically-oriented explo-ration of the textual content.
In the near future, wewill annotate and evaluate a larger sample and pos-sibly integrate machine learning techniques in or-der to improve the results even more.
We are alsoworking to integrate the handling of named entityannotations into Litteraturbanken?s search andbrowsing interfaces and hope to be able to conductour first demonstrations and tests with users laterthis year.ReferencesEiji Aramaki, Takeshi Imai, Kengo Miyo and KazuhikoOhe.
2006.
Automatic Deidentification by using Sen-tence Features and Label Consistency.
Challenges inNLP for Clinical Data Workshop.
Washington DC.Kalina Bontcheva, Diana Maynard, Hamish Cunning-ham and Horacio Saggion.
2002.
Using Human Lan-guage Technology for Automatic Annotation and In-dexing of Digital Library Content.
Proceedings of the6th European Conference on Research and AdvancedTechnology for Digital Libraries.Andrew Borthwick.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
PhD Thesis.New York University.Gregory Crane and Alison Jones.
2006.
The Challengeof Virginia Banks: an Evaluation of Named EntityAnalysis in a 19th-century Newspaper Collection.ACM/IEEE Joint Conference on Digital Libraries,JCDL.
Chapel Hill, NC, USA.
31?40.Karina van Dalen-Oskam and Joris van Zundert.
2004.Modelling Features of Characters: Some DigitalWays to Look at Names in Literary Texts.
Literaryand Linguistic Computing 19(3): 289?301.Julia Flanders, Syd Bauman, Paul Caton and MavisCournane.
1998.
Names Proper and Improper: Ap-plying the TEI to the Classification of Proper Nouns.Computers and the Humanities 31(4): 285?300.Michael Fleischman and Eduard Hovy.
2002.
FineGrained Classification of Named Entities.
Proceed-ings of the 19th International Conference on Compu-tational Linguistics.
Taipei, Taiwan.
1?7.Janne Bondi Johannessen, Kristin Hagen, ?sneHaaland, Andra Bj?rk J?nsdottir, Anders N?klestad,Dimitrios Kokkinakis, Paul Meurer, Eckhard Bickand Dorte Haltrup.
2005.
Named Entity Recognitionfor the Mainland Scandinavian Languages.
Literaryand Linguistic Computing.
20(1): 91?102.Dimitrios Kokkinakis.
2004.
Reducing the Effect ofName Explosion.
Proceedings of the LREC-Workshop: Beyond Named Entity Recognition - Se-mantic Labeling for NLP.
Lisbon, Portugal.Vijay Krishnan and Christopher D. Manning.
2006.
AnEfficient Two-Stage Model for Exploiting Non-LocalDependencies in Named Entity Recognition.
Pro-ceedings of COLING/ ACL 2006.
Sydney, Australia.1121?1128.David D. McDonald.
1996.
Internal and External Evi-dence in the Identification and Semantic Categorisa-tion of Proper Nouns.
Corpus-Processing for LexicalAcquisition.
James Pustejovsky and Bran Boguraev(eds).
MIT Press.
21?39.Andrei Mikheev.
2000.
Document Centered Approachto Text Normalization.
Proceedings of the 23rd ACMSIGIR Conference on Research and Development inInformation Retrieval.
Athens, Greece.
136?143.Satoshi Sekine.
2004.
Definition, Dictionaries and Tag-ger for Extended  Named Entity Hierarchy.
Proceed-ings of the Language Resources and Evaluation Con-ference (LREC).
Lisbon, Portugal.Constantin Orasan and Roger Evans.
2001.
Learning toIdentify Animate References.
Proceedings of theWorkshop on Computational Natural LanguageLearning (CoNLL-2001).
ACL-2001.
Toulouse,France.Robert Shoemaker.
2005.
Digital London.
Creating aSearchable Web of Interlinked Sources on EighteenthCentury London.
Program: Electronic Library & In-formation Systems 39(4): 297?311.8
