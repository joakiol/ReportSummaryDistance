Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 663?667,Dublin, Ireland, August 23-24, 2014.TMUNSW: Disorder Concept Recognition and Normalization inClinical Notes for SemEval-2014 Task 7JitendraJonnagaddalaTranslational CancerResearch Network,University ofNew South Wales,Sydney 2031,Australiaz3339253@unsw.edu.auManish KumarKrishagni SolutionsPty Ltd,Armadale 6112,Australiamanish.ku-mar@krishagni.comHong-Jie Dai* EnnyRachmaniChien-Yeh HsuGraduate Institute of Biomedical Informatics,College of Medical Science and TechnologyTaipei Medical University,Taipei City 110, Taiwan{hjdai, d610101005,cyhsu}@tmu.edu.twAbstractWe present our participation in Task 7 ofSemEval shared task 2014.
The goal ofthis particular task includes the identifica-tion of disorder named entities and themapping of each disorder to a unique Uni-fied Medical Language System conceptidentifier, which were referred to as TaskA and Task B respectively.
We partici-pated in both of these subtasks and usedYTEX as a baseline system.
We furtherdeveloped a supervised linear chain Con-ditional Random Field  model based onsets of features to predict disorder men-tions.
To take benefit of results from bothsystems we merged these results.
Understrict condition our best run evaluated at0.549 F-measure for Task A and an accu-racy of 0.489 for Task B on test dataset.Based on our error analysis we concludethat recall of our system can be signifi-cantly increased by adding more featuresto the Conditional Random Field modeland by using another type of tag represen-tation or frame matching algorithm to dealwith the disjoint entity mentions.1 IntroductionClinical notes are rich sources of valuable pa-tient?s information.
These clinical notes are oftenplain text records containing important entitymentions such as clinical findings, procedures anddisease mentions (Jimeno et al., 2008).
Using au-tomated tools to extract the aforementioned infor-mation can undoubtedly help researchers and cli-nicians with better decision making.
An importantsubtask of information extraction called namedentity recognition (NER) can recognize theboundary of named entity mention and classify itinto a certain semantic group.The focus of the SemEval-2104 task 7 is recogni-tion and normalization of disorder entities men-tioned in clinical notes.
As such, this task was fur-ther divided into two parts: first, task A which in-cludes recognition of mention of concepts that be-long to UMLS (Unified Medical Language Sys-tem) semantic group disorders (Bodenreider,2004).
The concepts considered in Task A includethe following eleven UMLS semantic types: Con-genital Abnormality; Acquired Abnormality; In-jury or Poisoning; Pathologic Function; Diseaseor Syndrome; Mental or Behavioral Dysfunction;Cell or Molecular Dysfunction; ExperimentalModel of Disease; Anatomical Abnormality; Ne-oplastic Process; and Signs and Symptoms.
Sec-ond, task B referred to as task of normalization in-volves the mapping of each disorder mention to aUMLS concept unique identifier (CUI).The map-ping was limited to UMLS CUI of SNOMED clin-ical term codes (Spackman, Campbell, & C?,1997).
We participated in both tasks and devel-This work is licensed under a Creative Commons Attrib-ution 4.0 International Licence.
Page numbers and proceed-ings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/*Corresponding author663oped a disorder concept recognition/normaliza-tion system based on several openly availabletools and machine learning algorithms.2 Methods2.1 System DesignFor both task A and B, YTEX (Garla et al.,2011) system was employed as a baseline system.We chose to use YTEX since it is specifically de-signed for processing clinical notes with improve-ments to cTAKES?s dictionary lookup algorithmand word sense disambiguation feature.
The pre-processing involves sentence detection, tokeniza-tion and part-of-speech (POS) tagging(Fiscus,1997).
Based on the tokenized tokens, several fea-tures along with the corresponding part-of-speechtags were extracted for the supervised learning al-gorithm?conditional random field (CRF) model(Lafferty, McCallum, & Pereira, 2001).
Aftertraining, the CRF model was used for recognizingdisorder mentions.
Furthermore the recognizeddisorder concepts were sent to MetaMap(Aronson & Lang, 2010) to look for their corre-sponding CUIs for generating normalized results.The results were finally merged with the output ofYTEX.
A high level diagram of the developedsystem is schematized in Figure 1.2.2 Disorder Concept RecognitionThe task A involves detecting boundaries of en-tity that belongs to UMLS semantic group, disor-ders.
We used the sequence tagging tool based onMallet?s implementation of the supervised linearchain CRF model to perform this task.
We fol-lowed the traditional BIO format to formulate thedisorder concept recognition task as a sequentiallabelling task, wherein each token was assigned alabel such as B is indicated the Beginning of en-tity, I is indicated the Inside an entity, or O is in-dicated the Outside of an entity.
Thus, the modelassigns each of the word into one of the abovethree labels.
We investigated various types of fea-tures proposed in previous works (Jiang et al.,2011; Li, Kipper-Schuler, & Savova, 2008; Tang,Cao, Wu, Jiang, & Xu, 2013), like semantic fea-ture which includes UMLS semantic group andsemantic type, to develop our classifier.
We alsoinvestigated various word features like POS, cap-italization, and ?position of word?
in the sentence.We also used ?previous word?, ?next word?
and?label of these words?
as a feature for developingour classifier.2.3 Disorder Concept NormalizationEach disorder concept recognized by our recogni-tion system was passed to a local installation ofMetaMap using MetaMap Java API to obtain itscandidate CUI.
To increase the recall, we mergedresults from both YTEX and MetaMap systems.Output from YTEX baseline system was mergedto the output from our CRF model with MetaMap.This method was used because it was observedthat our CRF/MetaMap model has higher preci-sion while YTEX baseline system has higher re-call.3 Results3.1 DatasetsFor Task A and Task B, the training and devel-opment datasets provided by the SemEval task 7organizers were used.
Both were derived fromShARe corpus containing de-identified  plain textclinical notes from MIMIC II database (Suominenet al., 2013).
These clinical notes were manuallyannotated for disorder mention and normalized toFig.
1: TMUNSW system design for SemEval-2014 Task 7.664an UMLS CUI when possible.
The corpus con-sisted of four types of clinical notes: dischargesummaries, electrocardiogram, echocardiogram,and radiology reports.
As the dataset, we includeddifferent types of clinical notes, further we traineda CRF model for each type and evaluated its per-formance on the corresponding development data.However, test set from task organizers containeddischarge summaries only.
Hence, the model de-veloped for discharge summary was selected forevaluation on the test set.3.2 Evaluation MetricsThe official evaluation script provided by or-ganizers of the shared task was used to evaluateour system ability to correct an identify spans oftext that belongs to semantic group disorders andto normalize them to the corresponding CUIs.We calculated the evaluation measures undertwo settings-strict and relaxed.
The strict settingmatches exact boundaries with the gold standard,while relaxed setting matches overlapping bound-aries in the gold standard.
The evaluationmeasures were calculated using the commonlyused evaluation measures including recall (R),precision (P), and F-measure (F) (Powers, 2007).3.3 System ConfigurationsWe used YTEX V0.8 with cTAKES V2.5.0 asthe baseline system for performance comparison.All default settings for YTEX, including the con-cept window of the length 10, were adopted.
Wesubmit two runs for both tasks.
For Task A, thefirst run, denoted as Run0, used the developedCRF model to recognize the disorder concepts.The second run was denoted as Run1, whichmerged the results of CRF model with YTEX.Similarly, for Task B, Run0 used the MetaMap2012 version to normalize the candidate disorderconcepts recognized by our CRF model.
ForRun1, we merged normalized annotation resultsof YTEX with Run0.3.4 System Performance ComparisonWe performed a ten-fold cross validation onthe combination of the training and developmentdatasets for examining the recognition and nor-malization performance of the developed CRFmodel combined with MetaMap (Run0), and com-pared with the YTEX as the baseline system.
Ta-ble 1 summarized the results for Task A and B.The results showed, for both tasks, Run0 sig-nificantly outperformed YTEX in the strict setting.The higher F-score of Run0 can be attributed bythe fact that Run0 is developed based on the re-leased corpus and the machine learning algorithmwhich is better suited for NER task as comparedto the rule based YTEX system.
In the relaxed set-ting, for Task A, Run0 also has significantlyhigher F-score than the YTEX baseline system.However, in case of Task B accuracy of YTEX issignificantly greater than Run0.
We believe thatthe higher accuracy of the baseline system can beattributed by the word sense disambiguation fea-ture within YTEX.TaskAYTEX Run0Strict Relaxed Strict RelaxedP 0.524 0.917 0.771 0.978R 0.469 0.670 0.615 0.811F 0.495 0.774 0.682 0.884TaskBYTEX Run0Strict Relaxed Strict RelaxedAccuracy 0.469 1.000 0.684 0.752Table 1.
Summary of Training Set Evaluation Re-sults.3.5 Official Evaluation ResultsTable 2 shows the official evaluation resultsof the submitted two configurations, Run0 andRun1.
Under the strict setting, Run1 achieves thebetter performance with an F-measure of 0.549 forTask A and an accuracy of 0.489 for Task B ontest dataset.
Our best run for Task A was ranked15 out of 21 participants, while for Task B it wasranked 9 out of 18 participants.TaskARun0 Run1Strict Relaxed Strict RelaxedP 0.622 0.899 0.524 0.914R 0.429 0.652 0.576 0.765F 0.508 0.756 0.549 0.833TaskBRun0 Run1Strict Relaxed Strict RelaxedAccuracy 0.358 0.834 0.489 0.849Table 2.
Summary of Test Set Evaluation Results.Table 2 shows that Run1 has higher F-scorethan Run0 because of its high recall.
On the otherhand, Run0 achieves significantly higher preci-sion compared to Run1 for Task A.
The result isin accordance with our expectation, because Run1integrated the results from YTEX to improve therecall of Run0 at the cost of the decrease in preci-sion.
The trade-off seems acceptable because itcan significantly improve the accuracy in normal-izing disorder concepts.6654 DiscussionWe performed error analysis on development da-taset and found that the lower recall of Run0 de-rived from the miss of many disjoint entities(where the tokens comprising the entity string arenon-adjacent), which cannot be captured by thecurrent BIO tag set.
For example, consider thesentence ?Abdomen is soft, nontender, non-distended, negative bruits.?
For this sentence thegold annotations contain three entities as ?Abdo-men bruits-CUI= C0221755?, ?Abdomennontender-CUI=CUI-less?
and ?nondistended-CUI=CUI-less?.
In the current BIO formulation,all of the above three disjoint entities cannot becorrectly recognized.
There are also abbreviationswhich were rarely seen in the training dataset butappeared more in the development/test sets.
Sowhen we test our developed model on test set theabbreviations which are not part of training anddevelopment set must have been missed by oursystem.
We believe that by incorporating medicalabbreviations database into our model develop-ment, the performance of our overall systemwould have been better.
Also, the precision inTask A of Run1 was lower than Run0 because ofsome disjoint annotations.5 ConclusionWe present a clinical NER system based on Mal-let?s implementation of CRF and a hybrid normal-ization system using MetaMap and YTEX.
Wedeveloped our system with limited features due tothe time constraint.
We can conclude from erroranalysis that recall of this system could be signif-icantly increased by adding more features to it.We plan to extend our system in future by usinganother type of tag representation or frame-basedpattern matching algorithm to handle disjointnamed entities.
Similarly missing abbreviationscan be handled by employing external resourcessuch as abbreviation recognition tools.AcknowledgementsThis project was supported by a Cancer InstituteNSW?s translational cancer research centre pro-gram grant, and the research grant TMU101-AE1-B55 of Taipei Medical University.ReferencesAronson, A. R., & Lang, F. M. (2010).
An overview ofMetaMap: historical perspective and recentadvances.
J Am Med Inform Assoc, 17(3), 229-236.doi: 10.1136/jamia.2009.002733Bodenreider, O.
(2004).
The unified medical languagesystem (UMLS): integrating biomedicalterminology.
Nucleic acids research, 32(suppl 1),D267-D270.Fiscus, J. G. (1997).
A post-processing system to yieldreduced word error rates: Recognizer output votingerror reduction (ROVER).
Paper presented at theAutomatic Speech Recognition and Understanding,1997.
Proceedings., 1997 IEEE Workshop on.Garla, V., Re, V. L., Dorey-Stein, Z., Kidwai, F.,Scotch, M., Womack, J., .
.
.
Brandt, C. (2011).
TheYale cTAKES extensions for documentclassification: architecture and application.
Journalof the American Medical Informatics Association,18(5), 614-620.Jiang, M., Chen, Y., Liu, M., Rosenbloom, S. T., Mani,S., Denny, J. C., & Xu, H. (2011).
A study ofmachine-learning-based approaches to extractclinical entities and their assertions from dischargesummaries.
Journal of the American MedicalInformatics Association, 18(5), 601-606.Jimeno, A., Jimenez-Ruiz, E., Lee, V., Gaudan, S.,Berlanga, R., & Rebholz-Schuhmann, D. (2008).Assessment of disease named entity recognition ona corpus of annotated sentences.
BMCBioinformatics, 9 Suppl 3, S3.
doi: 10.1186/1471-2105-9-S3-S3Lafferty, J., McCallum, A., & Pereira, F. (2001).Conditional random fields: Probabilistic models forsegmenting and labeling sequence data.
Paperpresented at the Proceedings of the 18thInternational Conference on Machine Learning(ICML).Li, D., Kipper-Schuler, K., & Savova, G. (2008).Conditional random fields and support vectormachines for disorder named entity recognition inclinical texts.
Paper presented at the Proceedings ofthe workshop on current trends in biomedicalnatural language processing.Powers, D. M. W. (2007).
Evaluation: From Precision,Recall and F-Factor to ROC, Informedness,Markedness & Correlation.
Journal of MachineLearning Technologies, 2(1), 37-63. doi: citeulike-article-id:10061513Spackman, K. A., Campbell, K. E., & C?, R. (1997).SNOMED RT: a reference terminology for healthcare.
Paper presented at the Proceedings of theAMIA annual fall symposium.Suominen, H., Salanter?, S., Velupillai, S., Chapman,W.
W., Savova, G., Elhadad, N., .
.
.
Jones, G.
J.(2013).
Overview of the ShARe/CLEF eHealthEvaluation Lab 2013 Information AccessEvaluation.
Multilinguality, Multimodality, andVisualization (pp.
212-231): Springer.666Tang, B., Cao, H., Wu, Y., Jiang, M., & Xu, H. (2013).Recognizing clinical entities in hospital dischargesummaries using Structural Support VectorMachines with word representation features.
BMCmedical informatics and decision making, 13(1), 1-10.667
