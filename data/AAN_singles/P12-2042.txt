Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 213?217,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsTowards the Unsupervised Acquisition of Discourse RelationsChristian ChiarcosInformation Sciences InstituteUniversity of Southern California4676 Admiralty Way, Marina del Rey, CA 90292chiarcos@daad-alumni.deAbstractThis paper describes a novel approach towardsthe empirical approximation of discourse re-lations between different utterances in texts.Following the idea that every pair of eventscomes with preferences regarding the rangeand frequency of discourse relations connect-ing both parts, the paper investigates whetherthese preferences are manifested in the distri-bution of relation words (that serve to signalthese relations).Experiments on two large-scale English webcorpora show that significant correlations be-tween pairs of adjacent events and relationwords exist, that they are reproducible on dif-ferent data sets, and for three relation words,that their distribution corresponds to theory-based assumptions.1 MotivationTexts are not merely accumulations of isolated ut-terances, but the arrangement of utterances conveysmeaning; human text understanding can thus be de-scribed as a process to recover the global structureof texts and the relations linking its different parts(Vallduv??
1992; Gernsbacher et al 2004).
To capturethese aspects of meaning in NLP, it is necessary todevelop operationalizable theories, and, within a su-pervised approach, large amounts of annotated train-ing data.
To facilitate manual annotation, weaklysupervised or unsupervised techniques can be ap-plied as preprocessing step for semimanual anno-tation, and this is part of the motivation of the ap-proach described here.Discourse relations involve different aspects ofmeaning.
This may include factual knowledgeabout the connected discourse segments (a ?subject-matter?
relation, e.g., if one utterance representsthe cause for another, Mann and Thompson 1988,p.257), argumentative purposes (a ?presentational?relation, e.g., one utterance motivates the reader toaccept a claim formulated in another utterance, ibid.,p.257), or relations between entities mentioned inthe connected discourse segments (anaphoric rela-tions, Webber et al 2003).
Discourse relations canbe indicated explicitly by optional cues, e.g., ad-verbials (e.g., however), conjunctions (e.g., but), orcomplex phrases (e.g., in contrast to what Peter saida minute ago).
Here, these cues are referred to asrelation words.Assuming that relation words are associated withspecific discourse relations (Knott and Dale 1994;Prasad et al 2008), the distribution of relation wordsfound between two (types of) events can yield in-sights into the range of discourse relations possi-ble at this occasion and their respective likeliness.For this purpose, this paper proposes a backgroundknowledge base (BKB) that hosts pairs of events(here heuristically represented by verbs) along withdistributional profiles for relation words.
The pri-mary data structure of the BKB is a triple whereone event (type) is connected with a particular re-lation word to another event (type).
Triples are fur-ther augmented with a frequency score (expressingthe likelihood of the triple to be observed), a sig-nificance score (see below), and a correlation score(indicating whether a pair of events has a positive ornegative correlation with a particular relation word).213Triples can be easily acquired from automaticallyparsed corpora.
While the relation word is usuallypart of the utterance that represents the source ofthe relation, determining the appropriate target (an-tecedent) of the relation may be difficult to achieve.As a heuristic, an adjacency preference is adopted,i.e., the target is identified with the main event of thepreceding utterance.1 The BKB can be constructedfrom a sufficiently large corpus as follows:?
identify event types and relation words?
for every utterance?
create a candidate triple consisting of theevent type of the utterance, the relationword, and the event type of the precedingutterance.?
add the candidate triple to the BKB, if itfound in the BKB, increase its score by (orinitialize it with) 1,?
perform a pruning on all candidate triples, cal-culate significance and correlation scoresPruning uses statistical significance tests to evalu-ate whether the relative frequency of a relation wordfor a pair of events is significantly higher or lowerthan the relative frequency of the relation word inthe entire corpus.
Assuming that incorrect candi-date triples (i.e., where the factual target of the rela-tion was non-adjacent) are equally distributed, theyshould be filtered out by the significance tests.The goal of this paper is to evaluate the validity ofthis approach.2 Experimental SetupBy generalizing over multiple occurrences of thesame events (or, more precisely, event types), onecan identify preferences of event pairs for one orseveral relation words.
These preferences capturecontext-invariant characteristics of pairs of eventsand are thus to considered to reflect a semantic pre-disposition for a particular discourse relation.Formally, an event is the semantic representa-tion of the meaning conveyed in the utterance.
We1Relations between non-adjacent utterances are constrainedby the structure of discourse (Webber 1991), and thus less likelythan relations between adjacent utterances.assume that the same event can reoccur in differ-ent contexts, we are thus studying relations be-tween types of events.
For the experiment describedhere, events are heuristically identified with the mainpredicates of a sentence, i.e., non-auxiliar, non-causative, non-modal verbal lexemes that serve asheads of main clauses.The primary data structure of the approach de-scribed here is a triple consisting of a source event, arelation word and a target (antecedent) event.
Thesetriples are harvested from large syntactically anno-tated corpora.
For intersentential relations, the tar-get is identified with the event of the immediatelypreceding main clause.
These extraction preferencesare heuristic approximations, and thus, an additionalpruning step is necessary.For this purpose, statistical significance tests areadopted (?2 for triples of frequent events and re-lation words, t-test for rare events and/or relationwords) that compare the relative frequency of a rela-tion word given a pair of events with the relative fre-quency of the relation word in the entire corpus.
Allresults with p ?
.05 are excluded, i.e., only triplesare preserved for which the observed positive or neg-ative correlation between a pair of events and a re-lation word is not due to chance with at least 95%probability.
Assuming an even distribution of incor-rect target events, this should rule these out.
Ad-ditionally, it also serves as a means of evaluation.Using statistical significance tests as pruning crite-rion entails that all triples eventually confirmed arestatistically significant.2This setup requires immense amounts of data: Weare dealing with several thousand events (theoreti-cally, the total number of verbs of a language).
Thechance probability for two events to occur in adja-cent position is thus far below 10?6, and it decreasesfurther if the likelihood of a relation word is takeninto consideration.
All things being equal, we thusneed millions of sentences to create the BKB.Here, two large-scale corpora of English are em-ployed, PukWaC and Wackypedia EN (Baroni et al2009).
PukWaC is a 2G-token web corpus of BritishEnglish crawled from the uk domain (Ferraresi et al2Subsequent studies may employ less rigid pruning criteria.For the purpose of the current paper, however, the statistical sig-nificance of all extracted triples serves as an criterion to evaluatemethodological validity.2142008), and parsed with MaltParser (Nivre et al2006).
It is distributed in 5 parts; Only PukWaC-1 to PukWaC-4 were considered here, constitut-ing 82.2% (72.5M sentences) of the entire corpus,PukWaC-5 is left untouched for forthcoming evalu-ation experiments.
Wackypedia EN is a 0.8G-tokendump of the English Wikipedia, annotated with thesame tools.
It is distributed in 4 different files; thelast portion was left untouched for forthcoming eval-uation experiments.
The portion analyzed here com-prises 33.2M sentences, 75.9% of the corpus.The extraction of events in these corpora usessimple patterns that combine dependency informa-tion and part-of-speech tags to retrieve the mainverbs and store their lemmata as event types.
Thetarget (antecedent) event was identified with the lastmain event of the preceding sentence.
As relationwords, only sentence-initial children of the sourceevent that were annotated as adverbial modifiers,verb modifiers or conjunctions were considered.3 EvaluationTo evaluate the validity of the approach, three funda-mental questions need to be addressed: significance(are there significant correlations between pairs ofevents and relation words ?
), reproducibility (canthese correlations confirmed on independent datasets ?
), and interpretability (can these correlationsbe interpreted in terms of theoretically-defined dis-course relations ?
).3.1 Significance and ReproducibilitySignificance tests are part of the pruning stage of thealgorithm.
Therefore, the number of triples eventu-ally retrieved confirms the existence of statisticallysignificant correlations between pairs of events andrelation words.
The left column of Tab.
1 showsthe number of triples obtained from PukWaC sub-corpora of different size.For reproducibility, compare the triples identifiedwith Wackypedia EN and PukWaC subcorpora ofdifferent size: Table 1 shows the number of triplesfound in both Wackypedia EN and PukWaC, and theagreement between both resources.
For two triplesinvolving the same events (event types) and the samerelation word, agreement means that the relationword shows either positive or negative correlationPukWaC (sub)corpus Wackypedia EN triplessentences triples common agreeing %1.2M 74 20 12 60.04.8M 832 177 132 75.519.2M 7,342 938 809 86.338.4M 20,106 1,783 1,596 89.972.5M 46,680 2,643 2,393 90.5Table 1: Agreement with respect to positive or nega-tive correlation of event pairs and relation words be-tween Wackypedia EN and PukWaC subcorpora of dif-ferent sizePukWaC triples agreement (%)total vs. H vs. T vs. H vs. TB: but 11,042 6,805 1,525 97.7 62.2H: however 7,251 1,413 66.9T: then 1,791Table 2: Agreement between but (B), however (H) andthen (T) on PukWaCin both corpora, disagreement means positive corre-lation in one corpus and negative correlation in theother.Table 1 confirms that results obtained on one re-source can be reproduced on another.
This indi-cates that triples indeed capture context-invariant,and hence, semantic, characteristics of the relationbetween events.
The data also indicates that repro-ducibility increases with the size of corpora fromwhich a BKB is built.3.2 InterpretabilityAny theory of discourse relations would predict thatrelation words with similar function should havesimilar distributions, whereas one would expect dif-ferent distributions for functionally unrelated rela-tion words.
These expectations are tested here forthree of the most frequent relation words found inthe corpora, i.e., but, then and however.
But andhowever can be grouped together under a general-ized notion of contrast (Knott and Dale 1994; Prasadet al 2008); then, on the other hand, indicates a tem-poral and/or causal relation.Table 2 confirms the expectation that event pairsthat are correlated with but tend to show the samecorrelation with however, but not with then.2154 Discussion and OutlookThis paper described a novel approach towards theunsupervised acquisition of discourse relations, withencouraging preliminary results: Large collectionsof parsed text are used to assess distributional pro-files of relation words that indicate discourse re-lations that are possible between specific types ofevents; on this basis, a background knowledge base(BKB) was created that can be used to predict an ap-propriate discourse marker to connect two utteranceswith no overt relation word.This information can be used, for example, to fa-cilitate the semiautomated annotation of discourserelations, by pointing out the ?default?
relation wordfor a given pair of events.
Similarly, Zhou et al(2010) used a language model to predict discoursemarkers for implicitly realized discourse relations.As opposed to this shallow, n-gram-based approach,here, the internal structure of utterances is exploited:based on semantic considerations, syntactic patternshave been devised that extract triples of event pairsand relation words.
The resulting BKB provides adistributional approximation of the discourse rela-tions that can hold between two specific event types.Both approaches exploit complementary sources ofknowledge, and may be combined with each otherto achieve a more precise prediction of implicit dis-course connectives.The validity of the approach was evaluated withrespect to three evaluation criteria: The extracted as-sociations between relation words and event pairscould be shown to be statistically significant, andto be reproducible on other corpora; for threehighly frequent relation words, theoretical predic-tions about their relative distribution could be con-firmed, indicating their interpretability in terms ofpresupposed taxonomies of discourse relations.Another prospective field of application can beseen in NLP applications, where selection prefer-ences for relation words may serve as a cheap re-placement for full-fledged discourse parsing.
In theNatural Language Understanding domain, the BKBmay help to disambiguate or to identify discourserelations between different events; in the context ofMachine Translation, it may represent a factor guid-ing the insertion of relation words, a task that hasbeen found to be problematic for languages that dif-fer in their inventory and usage of discourse mark-ers, e.g., German and English (Stede and Schmitz2000).
The approach is language-independent (ex-cept for the syntactic extraction patterns), and it doesnot require manually annotated data.
It would thusbe easy to create background knowledge bases withrelation words for other languages or specific do-mains ?
given a sufficient amount of textual data.Related research includes, for example, the un-supervised recognition of causal and temporal rela-tionships, as required, for example, for the recog-nition of textual entailment.
Riaz and Girju (2010)exploit distributional information about pairs of ut-terances.
Unlike approach described here, they arenot restricted to adjacent utterances, and do not relyon explicit and recurrent relation words.
Their ap-proach can thus be applied to comparably smalldata sets.
However, they are restricted to a spe-cific type of relations whereas here the entire band-width of discourse relations that are explicitly real-ized in a language are covered.
Prospectively, bothapproaches could be combined to compensate theirrespective weaknesses.Similar observations can be made with respect toChambers and Jurafsky (2009) and Kasch and Oates(2010), who also study a single discourse relation(narration), and are thus more limited in scope thanthe approach described here.
However, as their ap-proach extends beyond pairs of events to complexevent chains, it seems that both approaches providecomplementary types of information and their re-sults could also be combined in a fruitful way toachieve a more detailed assessment of discourse re-lations.The goal of this paper was to evaluate the meth-dological validity of the approach.
It thus representsthe basis for further experiments, e.g., with respectto the enrichment the BKB with information pro-vided by Riaz and Girju (2010), Chambers and Ju-rafsky (2009) and Kasch and Oates (2010).
Other di-rections of subsequent research may include addressmore elaborate models of events, and the investiga-tion of the relationship between relation words andtaxonomies of discourse relations.216AcknowledgmentsThis work was supported by a fellowship withinthe Postdoc program of the German Academic Ex-change Service (DAAD).
Initial experiments wereconducted at the Collaborative Research Center(SFB) 632 ?Information Structure?
at the Univer-sity of Potsdam, Germany.
I would also like tothank three anonymous reviewers for valuable com-ments and feedback, as well as Manfred Stede andEd Hovy whose work on discourse relations on theone hand and proposition stores on the other handhave been the main inspiration for this paper.ReferencesM.
Baroni, S. Bernardini, A. Ferraresi, andE.
Zanchetta.
The wacky wide web: a collec-tion of very large linguistically processed web-crawled corpora.
Language Resources and Eval-uation, 43(3):209?226, 2009.N.
Chambers and D. Jurafsky.
Unsupervised learn-ing of narrative schemas and their participants.
InProceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th Inter-national Joint Conference on Natural LanguageProcessing of the AFNLP: Volume 2-Volume 2,pages 602?610.
Association for ComputationalLinguistics, 2009.A.
Ferraresi, E. Zanchetta, M. Baroni, and S. Bernar-dini.
Introducing and evaluating ukwac, a verylarge web-derived corpus of english.
In Proceed-ings of the 4th Web as Corpus Workshop (WAC-4)Can we beat Google, pages 47?54, 2008.Morton Ann Gernsbacher, Rachel R. W. Robertson,Paola Palladino, and Necia K. Werner.
Manag-ing mental representations during narrative com-prehension.
Discourse Processes, 37(2):145?164,2004.N.
Kasch and T. Oates.
Mining script-like struc-tures from the web.
In Proceedings of the NAACLHLT 2010 First International Workshop on For-malisms and Methodology for Learning by Read-ing, pages 34?42.
Association for ComputationalLinguistics, 2010.A.
Knott and R. Dale.
Using linguistic phenomenato motivate a set of coherence relations.
Discourseprocesses, 18(1):35?62, 1994.J.
van Kuppevelt and R. Smith, editors.
Current Di-rections in Discourse and Dialogue.
Kluwer, Dor-drecht, 2003.William C. Mann and Sandra A. Thompson.
Rhetor-ical Structure Theory: Toward a functional theoryof text organization.
Text, 8(3):243?281, 1988.J.
Nivre, J.
Hall, and J. Nilsson.
Maltparser: Adata-driven parser-generator for dependency pars-ing.
In Proc.
of LREC, pages 2216?2219.
Cite-seer, 2006.R.
Prasad, N. Dinesh, A. Lee, E. Miltsakaki,L.
Robaldo, A. Joshi, and B. Webber.
The penndiscourse treebank 2.0.
In Proc.
6th InternationalConference on Language Resources and Evalua-tion (LREC 2008), Marrakech, Morocco, 2008.M.
Riaz and R. Girju.
Another look at causality:Discovering scenario-specific contingency rela-tionships with no supervision.
In Semantic Com-puting (ICSC), 2010 IEEE Fourth InternationalConference on, pages 361?368.
IEEE, 2010.M.
Stede and B. Schmitz.
Discourse particles anddiscourse functions.
Machine translation, 15(1):125?147, 2000.Enric Vallduv??.
The Informational Component.
Gar-land, New York, 1992.Bonnie L. Webber.
Structure and ostension in theinterpretation of discourse deixis.
Natural Lan-guage and Cognitive Processes, 2(6):107?135,1991.Bonnie L. Webber, Matthew Stone, Aravind K.Joshi, and Alistair Knott.
Anaphora and discoursestructure.
Computational Linguistics, 4(29):545?587, 2003.Z.-M. Zhou, Y. Xu, Z.-Y.
Niu, M. Lan, J. Su, andC.L.
Tan.
Predicting discourse connectives forimplicit discourse relation recognition.
In COL-ING 2010, pages 1507?1514, Beijing, China, Au-gust 2010.217
