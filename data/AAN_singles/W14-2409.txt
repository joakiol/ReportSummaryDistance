Proceedings of the ACL 2014 Workshop on Semantic Parsing, pages 45?49,Baltimore, Maryland USA, June 26 2014.c?2014 Association for Computational LinguisticsLow-Dimensional Embeddings of LogicTim Rockt?aschel?Matko Bosnjak?Sameer Singh?Sebastian Riedel?
?Department of Computer Science, University College London, UK?Computer Science & Engineering, University of Washington, Seattle{t.rocktaschel,m.bosnjak,s.riedel}@cs.ucl.ac.uk, sameer@cs.washington.eduAbstractMany machine reading approaches, fromshallow information extraction to deepsemantic parsing, map natural languageto symbolic representations of meaning.Representations such as first-order logiccapture the richness of natural languageand support complex reasoning, but oftenfail in practice due to their reliance on log-ical background knowledge and the diffi-culty of scaling up inference.
In contrast,low-dimensional embeddings (i.e.
distri-butional representations) are efficient andenable generalization, but it is unclear howreasoning with embeddings could supportthe full power of symbolic representationssuch as first-order logic.
In this proof-of-concept paper we address this by learningembeddings that simulate the behavior offirst-order logic.1 IntroductionMuch of the work in machine reading follows anapproach that is, at its heart, symbolic: languageis transformed, possibly in a probabilistic way,into a symbolic world model such as a relationaldatabase or a knowledge base of first-order for-mulae.
For example, a statistical relation extractorreads texts and populates relational tables (Mintzet al., 2009).
Likewise, a semantic parser canturn sentences into complex first-order logic state-ments (Zettlemoyer and Collins, 2005).Several properties make symbolic representa-tions of knowledge attractive as a target of ma-chine reading.
They support a range of well under-stood symbolic reasoning processes, capture se-mantic concepts such as determiners, negationsand tense, can be interpreted, edited and curatedby humans to inject prior knowledge.
However, onpractical applications fully symbolic approacheshave often shown low recall (e.g.
Bos and Markert,2005) as they are affected by the limited coverageof ontologies such as WordNet.
Moreover, due totheir deterministic nature they often cannot copewith noise and uncertainty inherent to real worlddata, and inference with such representations isdifficult to scale up.Embedding-based approaches address some ofthe concerns above.
Here relational worlds are de-scribed using low-dimensional embeddings of en-tities and relations based on relational evidence inknowledge bases (Bordes et al., 2011) or surface-form relationships mentioned in text (Riedel et al.,2013).
To overcome the generalization bottleneck,these approaches learn to embed similar entitiesand relations as vectors close in distance.
Subse-quently, unseen facts can be inferred by simple andefficient linear algebra operations (e.g.
dot prod-ucts).The core argument against embeddings is theirsupposed inability to capture deeper semantics,and more complex patterns of reasoning suchas those enabled by first-order logic (Lewis andSteedman, 2013).
Here we argue that this doesnot need to be true.
We present an approach thatenables us to learn low-dimensional embeddingssuch that the model behaves as if it follows a com-plex first-order reasoning process?but still oper-ates in terms of simple vector and matrix repre-sentations.
In this view, machine reading becomesthe process of taking (inherently symbolic) knowl-edge in language and injecting this knowledge intoa sub-symbolic distributional world model.
Forexample, one could envision a semantic parser thatturns a sentence into a first-order logic statement,45worksFor(A), profAt(A)profAt(B) ...profAt(x) => worksFor(x)worksFor(B)CurateIESPworksForprofAtALogical Inference AlgebraBCworksFor(B)DLogic Embedded LogicEvidenceFigure 1: Information extraction (IE) and semanticparsing (SP) extract factual and more general log-ical statements from text, respectively.
Humanscan manually curate this knowledge.
Instead ofreasoning with this knowledge directly (A) we in-ject it into low dimensional representations of en-tities and relations (B).
Linear algebra operationsmanipulate embeddings to derive truth vectors (C),which can be discretized or thresholded to retrievetruth values (D).just to then inject this statement into the embed-dings of relations and entities mentioned in thesentence.2 BackgroundFigure 1 shows our problem setup.
We as-sume a domain of a set of entities, such asSMITH and CAMBRIDGE, and relations amongthese (e.g.
profAt(?, ?)).
We start from aknowledge base of observed logical statements,e.g., profAt(SMITH, CAMBRIDGE) or ?x, y :profAt(x, y) =?
worksFor(x, y).
These state-ments can be extracted from text through informa-tion extraction (for factual statements), be the out-put from a semantic parsing (for first-order state-ments) or come from human curators or externalknowledge bases.The task at hand is to predict the truthvalue of unseen statements, for exampleworksFor(SMITH, CAMBRIDGE).
Assuming wehave the corresponding formulae, logical infer-ence can be used to arrive at this statement (arrowA in Figure 1).
However, in practice the relevantbackground knowledge is usually missing.
Bycontrast, a range of work (e.g.
Bordes et al., 2011;Riedel et al., 2013) has successfully predictedunseen factual statements by learning entity andrelation embeddings that recover the observedfacts and generalize to unseen facts throughdimensionality reduction (B).
Inference in theseapproaches amounts to a series of algebraicoperations on the learned embeddings that returnsa numeric representation of the degree of truth(C), which can be thresholded to arrive back at atrue or false statement (D) if needed.Our goal in this view is to generalize (B) to al-low richer logical statements to be recovered bylow-dimensional embeddings.
To this end we firstdescribe how richer logical statements can be em-bedded at full dimension where the number of di-mensions equals to the number of entities in thedomain.2.1 Tensor CalculusGrefenstette (2013) presents an isomorphism be-tween statements in predicate logic and expres-sions in tensor calculus.
Let [?]
denote this map-ping from a logical expression F to an expressionin tensor algebra.
Here, logical statements evaluat-ing to true or false are mapped to [true]:=> =[1 0]Tand [false]:= ?
=[0 1]Tre-spectively.Entities are represented by logical constants andmapped to one-hot vectors where each componentrepresents a unique entity.
For example, let k = 3be the number of entities in a domain, then SMITHmay be mapped to [SMITH] =[1 0 0]T. Unarypredicates are represented as 2?k matrices, whosecolumns are composed of > and ?
vectors.
Forexample, for a isProfessor predicate we may get[isProfessor ] =[1 0 10 1 0].In this paper we treat binary relations as unarypredicates over constants ?X, Y?
that correspond topairs of entities X and Y in the domain.1The application of a unary predicate to a con-stant is realized through matrix-vector multiplica-tion.
For example, for profAt and the entity pair?X, Y?
we get[profAt(?X, Y?)]
= [profAt ] [?X, Y?]
.In Grefenstette?s calculus, binary boolean oper-ators are mapped to mode 3 tensors.
For example,for the implication operator holds:[ =?
]:=[1 0 1 10 1 0 0].Let A and B be two logical statements that,when evaluated in tensor algebra, yield a vector1This simplifies our exposition and approach, and it canbe shown that both representations are logically equivalent.46in {>,?}.
The application of a binary operatorto statements A and B is realized via two con-secutive tensor-vector products in their respectivemodes (see Kolda and Bader (2009) for details),e.g.,[A =?
B]:= [ =?
]?1[A]?2[B] .3 MethodGrefenstette?s mapping to tensors exactly recov-ers the behavior of predicate logic.
However, italso inherits the lack of generalization that comeswith a purely symbolic representation.
To over-come this problem we propose an alternate map-ping.
We retain the representation of truth val-ues and boolean operators as the 2 ?
1 and the2 ?
2 ?
2 sized tensors respectively.
However,instead of mapping entities and predicates to one-hot representations, we estimate low-dimensionalembeddings that recover the behavior of their one-hot counterparts when plugged into a set of tensor-logic statements.In the following we first present a general learn-ing objective that encourages low-dimensionalembeddings to behave like one-hot representa-tions.
Then we show how this objective can beoptimized for facts and implications.3.1 ObjectiveLet R be the set of all relation embeddings andP be the set of all entity pair embeddings.
Givena knowledge base (KB) of logical formulae Kwhich we assume to hold, the objective ismin[p]?P, [R]?R?F?K?
[F ]?>?2.
(1)That is, we prefer embeddings for which the givenformulae evaluate to the vector representation fortruth.
The same can be done for negative data byworking with ?, but we omit details for brevity.To optimize this function we require the gradi-ents of ?
[F ]?>?2terms.
Below we discuss thesefor two types of formulae: ground atoms and first-order formulae.3.2 Ground AtomsThe KB may contain ground atoms (i.e.
facts) ofthe form F = R(p) for a pair of entities p and arelation R. These atoms correspond to observedcells in an entity-pair-relation matrix, and inject-ing these facts into the embedding roughly corre-sponds to matrix factorization for link predictionor relation extraction (Riedel et al., 2013).Let ?
?F:= ([F ]?>) / ?
[F ]?>?2, then it iseasy to show that the gradients with respect to re-lation embedding [R] and entity pair embedding[p] are?/?
[p] = [R] ?
?Fand ?/?
[R] = ??F?
[p] .3.3 First-order FormulaeCrucially, and in contrast to matrix factorization,we can inject more expressive logical formulaethan just ground atoms.
For example, the KBK may contain a universally quantified first-orderrule such as ?x : R1(x) =?
R2(x).
Assum-ing a finite domain, this statement can be unrolledinto a conjunction of propositional statements ofthe form F = R1(p) =?
R2(p), one for eachpair p. We can directly inject these propositionalstatements into the embeddings, and their gradi-ents are straightfoward to derive.
For example,?/?
[R1] = (([ =?
]?2[R2(p)]) ??F)?
[p] .3.4 Learning and InferenceWe learn embeddings for entity pairs and relationsby minimizing objective 1 using stochastic gradi-ent descent (SGD).
To infer the (two-dimensional)truth value (C in Figure 1) of a formula F in em-bedded logic we evaluate [F ].
An easier to intpretone-dimensional representation can be derived by(?
[F ] ,[1 ?1]T?+ 1)/2,followed by truncation to the interval [0, 1].
Otherways of projecting [F ] to R, such as using cosinesimilarity to >, are possible as well.4 ExperimentsWe perform experiments on synthetic data definedover 7 entity pairs and 6 relations.
We fix the em-bedding size k to 4 and train the model for 100epochs using SGD with `2-regularization on thevalues of the embeddings.
The learning rate andthe regularization parameter are set to 0.05.The left part of Table 1 shows the observed(bold) and inferred truth values for a set of fac-tual staments of the form R(p), mapped to R asdiscussed above.
Due to the generalization ob-tained by low-dimensional embeddings, the modelinfers that, for example, SMITH is an employeeat CAMBRIDGE and DAVIES lives in LONDON.However, we would like the model to also capturethat every professor works for his or her university47With Factual Constraints With Factual and First-Order ConstraintsprofAt worksFor employeeAt registeredIn livesIn bornIn profAt worksFor employeeAt registeredIn livesIn bornIn?JONES, UWASH?
1.00 1.00 1.00 0.00 0.18 0.01 0.98 0.98 0.95 0.03 0.00 0.04?TAYLOR, UCL?
1.00 1.00 0.98 0.00 0.20 0.00 0.98 0.96 0.95 0.05 0.00 0.06?SMITH, CAMBRIDGE?
0.98>0.00>0.64 0.75 0.07 0.72 0.92>0.97>0.89 0.04 0.04 0.05?WILLIAMS, OXFORD?
?0.02 1.00 0.08 0.00 0.93 0.02?0.05 0.91 0.02 0.05 0.87 0.06?BROWN, CAMBRIDGE?
?0.00 0.97 0.02?0.01 0.95 0.06?0.01 0.90 0.00?0.07 0.92 0.07?DAVIES, LONDON?
0.00 0.00 0.00 0.99>0.50 1.00 0.01 0.00 0.00 0.98>0.98 0.97?EVANS, PARIS?
0.00 0.00 0.00 1.00>0.48 1.00 0.00 0.00 0.00 0.97>1.00 0.96Table 1: Reconstructed matrix without (left) and with (right) the first-order constraints profAt =?worksFor and registeredIn =?
livesIn .
Predictions for training cells of factual constraints [R(p)] => are shown in bold, and true and false test cells are denoted by>and?respectively.and that, when somebody is registered in a city, heor she also lives in that city.When including such first-order constraints(right part of Table 1), the model?s predictionsimprove concerning different aspects.
First, themodel gets the implication right, demonstratingthat the low-dimensional embeddings encode first-order knowledge.
Second, this implication transi-tively improves the predictions on other columns(e.g.
SMITH is an employee at CAMBRIDGE).Third, the implication works indeed in an asym-metric way, e.g., the model does not predict thatWILLIAMS is a professor at OXFORD just becauseshe is working there.5 Related WorkThe idea of bringing together distributional se-mantics and formal logic is not new.
Lewis andSteedman (2013) improve the generalization per-formance of a semantic parser via the use of dis-tributional representations.
However, their targetrepresentation language is still symbolic, and it isunclear how this approach can cope with noise anduncertainty in data.Another line of work (Clark and Pulman, 2007;Mitchell and Lapata, 2008; Coecke et al., 2010;Socher et al., 2012; Hermann and Blunsom, 2013)uses symbolic representations to guide the com-position of distributional representations.
Read-ing a sentence or logical formula there amountsto compositionally mapping it to a k-dimensionalvector that then can be used for downstream tasks.We propose a very different approach: Reading asentence amounts to updating the involved entitypair and relation embeddings such that the sen-tence evaluates to true.
Afterwards we cannot usethe embeddings to calculate sentence similarities,but to answer relational questions about the world.Similar to our work, Bowman (2014) providesfurther evidence that distributed representationscan indeed capture logical reasoning.
AlthoughBowman demonstrates this on natural logic ex-pressions without capturing factual statements,one can think of ways to include the latter inhis framework as well.
However, the ap-proach presented here can conceptually injectcomplex nested logical statements into embed-dings, whereas it is not obvious how this can beachieved in the neural-network based multi-classclassification framework proposed by Bowman.6 ConclusionWe have argued that low dimensional embeddingsof entities and relations may be tuned to simu-late the behavior of logic and hence combine theadvantages of distributional representations withthose of their symbolic counterparts.
As a firststep into this direction we have presented an ob-jective that encourages embeddings to be consis-tent with a given logical knowledge base that in-cludes facts and first-order rules.
On a small syn-thetic dataset we optimize this objective with SGDto learn low-dimensional embeddings that indeedfollow the behavior of the knowledge base.Clearly we have only scratched the surfacehere.
Besides only using toy data and logical for-mulae of very limited expressiveness, there arefundamental questions we have yet to address.For example, even if the embeddings could en-able perfect logical reasoning, how do we pro-vide provenance or proofs of answers?
More-over, in practice a machine reader (e.g.
a semanticparser) incrementally gathers logical statementsfrom text?
how could we incrementally inject thisknowledge into embeddings without retraining thewhole model?
Finally, what are the theoreticallimits of embedding logic in vector spaces?48AcknowledgmentsWe would like to thank Giorgos Spithourakis,Thore Graepel, Karl Moritz Hermann and Ed-ward Grefenstette for helpful discussions, and An-dreas Vlachos for comments on the manuscript.This work was supported by Microsoft Researchthrough its PhD Scholarship Programme.
Thiswork was supported in part by the TerraSwarm Re-search Center, one of six centers supported by theSTARnet phase of the Focus Center Research Pro-gram (FCRP) a Semiconductor Research Corpora-tion program sponsored by MARCO and DARPA.ReferencesAntoine Bordes, Jason Weston, Ronan Collobert,and Yoshua Bengio.
2011.
Learning structuredembeddings of knowledge bases.
In AAAI.Johan Bos and Katja Markert.
2005.
Recognis-ing textual entailment with logical inference.
InProc.
of HLT/EMNLP, pages 628?635.Samuel R Bowman.
2014.
Can recursive neuraltensor networks learn logical reasoning?
InICLR?14.Stephen Clark and Stephen Pulman.
2007.
Com-bining symbolic and distributional models ofmeaning.
In AAAI Spring Symposium: Quan-tum Interaction, pages 52?55.Bob Coecke, Mehrnoosh Sadrzadeh, and StephenClark.
2010.
Mathematical foundations for acompositional distributional model of meaning.CoRR, abs/1003.4394.Edward Grefenstette.
2013.
Towards a formal dis-tributional semantics: Simulating logical calculiwith tensors.
In Proc.
of *SEM, pages 1?10.Karl Moritz Hermann and Phil Blunsom.
2013.The role of syntax in vector space models ofcompositional semantics.
In Proc.
of ACL,pages 894?904.Tamara G Kolda and Brett W Bader.
2009.
Tensordecompositions and applications.
SIAM review,51(3):455?500.Mike Lewis and Mark Steedman.
2013.
Combineddistributional and logical semantics.
In TACL,volume 1, pages 179?192.Mike Mintz, Steven Bills, Rion Snow, and DanielJurafsky.
2009.
Distant supervision for rela-tion extraction without labeled data.
In Proc.of ACL-IJCNLP, pages 1003?1011.Jeff Mitchell and Mirella Lapata.
2008.
Vector-based models of semantic composition.
In Proc.of ACL, pages 236?244.Sebastian Riedel, Limin Yao, Andrew McCallum,and Benjamin M Marlin.
2013.
Relation ex-traction with matrix factorization and universalschemas.
In Proc.
of NAACL-HLT, pages 74?84.Richard Socher, Brody Huval, Christopher DManning, and Andrew Y Ng.
2012.
Seman-tic compositionality through recursive matrix-vector spaces.
In Proc.
of EMNLP, pages 1201?1211.Luke S Zettlemoyer and Michael Collins.
2005.Learning to map sentences to logical form:Structured classification with probabilistic cat-egorial grammars.
In Proc.
of UAI, pages 658?666.49
