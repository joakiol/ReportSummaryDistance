An Algorithm for Open Text Semantic ParsingLei Shi and Rada MihalceaDepartment of Computer ScienceUniversity of North Texasleishi@unt.edu, rada@cs.unt.eduAbstractThis paper describes an algorithm for open text shal-low semantic parsing.
The algorithm relies on aframe dataset (FrameNet) and a semantic network(WordNet), to identify semantic relations betweenwords in open text, as well as shallow semantic fea-tures associated with concepts in the text.
Parsingsemantic structures allows semantic units and con-stituents to be accessed and processed in a moremeaningful way than syntactic parsing, moving theautomation of understanding natural language textto a higher level.1 IntroductionThe goal of the semantic parser is to analyze thesemantic structure of a natural language sentence.Similar in spirit with the syntactic parser ?
whosegoal is to parse a valid natural language sentenceinto a parse tree indicating how the sentence canbe syntactically decomposed into smaller syntacticconstituents ?
the purpose of the semantic parser isto analyze the structure of sentence meaning.
Sen-tence meaning is composed by entities and interac-tions between entities, where entities are assignedsemantic roles, and can be further modified by othermodifiers.
The meaning of a sentence is decom-posed into smaller semantic units connected by var-ious semantic relations by the principle of compo-sitionality, and the parser represents the semanticstructure ?
including semantic units as well as se-mantic relations, connecting them into a formal for-mat.In this paper, we describe the main componentsof the semantic parser, and illustrate the basic pro-cedures involved in parsing semantically open text.We believe that such structures, reflecting variouslevels of semantic interpretation of the text, can beused to improve the quality of text processing appli-cations, by taking into account the meaning of text.The paper is organized as follows.
We first de-scribe the semantic structure of English sentences,as the basis for semantic parsing.
We then intro-duce the knowledge bases utilized by the parser, andshow how we use this knowledge in the process ofsemantic parsing.
Next, we describe the parsingalgorithm and elaborate on each of the three mainsteps involved in the process of semantic parsing:(1) syntactic and shallow semantic analysis, (2) se-mantic role assignment, and (3) application of de-fault rules.
Finally, we illustrate the parsing processwith several examples, and show how the semanticparsing algorithm can be integrated into other lan-guage processing systems.2 Semantic StructureSemantics is the denotation of a string of symbols,either a sentence or a word.
Similar to a syn-tactic parser, which shows how a larger string isformed by smaller strings from a formal point ofview, the semantic parser shows how the denotationof a larger string ?
sentence, is formed by deno-tations of smaller strings ?
words.
Syntactic rela-tions can be described using a set of rules about howa sentence string is formally generated using wordstrings.
Instead, semantic relations between seman-tic constituents depend on our understanding of theworld, which is across languages and syntax.We can model the sentence semantics as describ-ing entities and interactions between entities.
Enti-ties can represent physical objects, as well as time,places, or ideas, and are usually formally realizedas nouns or noun phrases.
Interactions, usually real-ized as verbs, describe relationships or interactionsbetween participating entities.
Note that a partic-ipant can also be an interaction, which can be re-garded as an entity nominalized from an interaction.We assign semantic roles to participants, and theirsemantic relations are identified by the case frameintroduced by their interaction.
In a sentence, par-ticipants and interactions can be further modifiedby various modifiers, including descriptive modi-fiers that describe attributes such as drive slowly,restrictive modifiers that enforce a general denota-tion to become more specific such as musical in-strument, referential modifiers that indicate partic-ular instances such as the pizza I ordered.
Othersemantic relations can also be identified, such ascoreference, complement, and others.
Based on theprinciple of compositionality, the sentence semanticstructure is recursive, similar to a tree.The semantic parser analyzes shallow-level se-mantics, which is derived directly from linguis-tic knowledge, such as rules about semanticrole assignment, lexical semantic knowledge, andsyntactic-semantic mappings, without taking intoaccount any context or common sense knowledge.The parser can be used as an intermediate semanticprocessing tool before higher levels of text under-standing.3 Knowledge Bases for Semantic ParsingOne major problem faced by many natural languageunderstanding applications that rely on syntacticanalysis of text, is the fact that similar syntactic pat-terns may introduce different semantic interpreta-tions.
Likewise, similar meanings can be syntac-tically realized in many different ways.
The seman-tic parser attempts to solve this problem, and pro-duces a syntax-independent representation of sen-tence meaning, so that semantic constituents can beaccessed and processed in a more meaningful andflexible way, avoiding the sometimes rigid interpre-tations produced by a syntactic analyzer.
For in-stance, the sentences I boil water and water boilscontain a similar relation between water and boil,even though they have different syntactic structures.To deal with the large number of cases where thesame syntactic relation introduces different seman-tic relations, we need knowledge about how to mapsyntax to semantics.
To this end, we use two maintypes of knowledge ?
about words, and about rela-tions between words.
The first type of knowledgeis drawn from WordNet ?
a large lexical databasewith rich information about words and concepts.We refer to this as word-level knowledge.
The lat-ter is derived from FrameNet ?
a resource that con-tains information about different situations, calledframes, in which semantic relations are syntacti-cally realized in natural language sentences.
Wecall this sentence-level knowledge.
In addition tothese two lexical knowledge bases, the parser alsoutilizes a set of manually defined rules, which en-code mappings from syntactic structures to seman-tic relations, and which are also used to handle thosestructures not explicitly addressed by FrameNet orWordNet.In this section, we describe the type of infor-mation extracted from these knowledge bases, andshow how this information is encoded in a formataccessible to the semantic parser.3.1 Frame Identification and Semantic RoleAssignmentFrameNet (Johnson et al, 2002) provides theknowledge needed to identify case frames and se-mantic roles.
FrameNet is based on the theory offrame semantics, and defines a sentence level on-tology.
In frame semantics, a frame corresponds toan interaction and its participants, both of whichdenote a scenario, in which participants play somekind of roles.
A frame has a name, and we use thisname to identify the semantic relation that groupstogether the semantic roles.
In FrameNet, nouns,verbs and adjectives can be used to identify frames.Each annotated sentence in FrameNet exempli-fies a possible syntactic realization for the seman-tic roles associated with a frame for a given targetword.
By extracting the syntactic features and cor-responding semantic roles from all annotated sen-tences in the FrameNet corpus, we are able to auto-matically build a large set of rules that encode thepossible syntactic realizations of semantic frames.In our implementation, we use only verbs astarget words for frame identification.
Currently,FrameNet defines about 1700 verbs attached to 230different frames.
To extend the parser coverage toa larger subset of English verbs, we are using Verb-Net (Kipper et al, 2000), which allows us to handlea significantly larger set of English verbs.VerbNet is a verb lexicon compatible with Word-Net, but with explicitly stated syntactic and se-mantic information using Levin?s verb classification(Levin, 1993).
The fundamental assumption is thatthe syntactic frames of a verb as an argument-takingelement are a direct reflection of the underlying se-mantics.
Therefore verbs in the same VerbNet classusually share common FrameNet frames, and havethe same syntactic behavior.
Hence, rules extractedfrom FrameNet for a given verb can be easily ex-tended to verbs in the same VerbNet class.
To en-sure a correct outcome, we have manually validatedthe FrameNet-VerbNet mapping, and corrected thefew discrepancies that were observed between Verb-Net classes and FrameNet frames.3.1.1 Rules Learned from FrameNetFrameNet data ?is meant to be lexicographically rel-evant, not statistically representative?
(Johnson etal., 2002), and therefore we are using FrameNet asa starting point to derive rules for a rule-based se-mantic parser.To build the rules, we are extracting several syn-tactic features.
Some are explicitly encoded inFrameNet, such as the grammatical function (GF)and phrase type (PT) features.In addition, other syntactic features are extractedfrom the sentence context.
One such feature is therelative position (RP) to the target word.
Sometimesthe same syntactic constituent may play different se-mantic roles according to its position with respectto the target word.
For instance the sentences: I payyou.
and You pay me.
have different roles assignedto the same lexical unit you based on the relativeposition with respect to the target word pay.Another feature is the voice of the sentence.
Con-sider these examples: I paid Mary 500 dollars.
andI was paid by Mary 500 dollars.
In these two sen-tences, I has the same values for the features GF, PTand RP, but it plays completely different roles in thesame frame because of the difference of voice.If the phrase type is prepositional phrase (PP), wealso record the actual preposition that precedes thephrase.
Consider these examples: I was paid for mywork.
and I was paid by Mary.
The prepositionalphrases in these examples have the same values forthe features GF, PT, and RP, but different preposi-tions differentiate the roles they should play.After we extract all these syntactic features, thesemantic role is appended to the rule, which createsa mapping from syntactic features to semantic roles.Feature sets are arranged in a list, the order ofwhich is identical to that in the sentence.
The or-der of sets within the list is important, as illustratedby the following example: ?I give the boy a ball.
?Here, the boy and a ball have the same featuresas described above, but since the boy occurs be-fore a ball, then the boy plays the role of recipi-ent.
Altogether, the rule for a possible realizationof a frame exemplified by a tagged sentence is anordered sequence of syntactic features with their se-mantic roles.For instance, Table 1 lists the syntactic and se-mantic features extracted from FrameNet for thesentence I had chased Selden over the moor.I had chased Selden over the moorGF Ext obj compPT NP Target NP PPPosition before after afterVoice activePP overRole Theme Goal PathTable 1: Example sentence with syntactic and se-mantic featuresThe corresponding formalized rule for this sen-tence is:[active, [ext,np,before,theme], [obj,np,after,goal], [comp,pp,after,over,path]]In FrameNet, there are multiple annotated sen-tences for each frame to demonstrate multiple pos-sible syntactic realizations.
All possible realizationsof a frame are collected and stored in a list for thatframe, which also includes the target word, its syn-tactic category, and the name of the frame.
All theframes defined in FrameNet are transformed intothis format, so that they can be easily handled bythe rule-based semantic parser.3.2 Word Level KnowledgeWordNet (Miller, 1995) is the resource used to iden-tify shallow semantic features that can be attachedto lexical units.
For instance, attribute relations,adjective/adverb classifications, and others, are se-mantic features extracted from WordNet and storedtogether with the words, so that they can be directlyused in the parsing process.All words are uniformly defined, regardless oftheir class.
Features are assigned to each word, in-cluding syntactic and shallow semantic features, in-dicating the functions played by the word.
Syntacticfeatures are used by the feature-augmented syntac-tic analyzer to identify grammatical errors and pro-duce syntactic information for semantic role assign-ment.
Semantic features encode lexical semantic in-formation extracted from WordNet that is used todetermine semantic relations between words in var-ious situations.Features can be arbitrarily defined, as long asthere are rules to handle them.
The features wedefine encode information about the syntacticcategory of a word, number and countability fornouns, transitivity and form for verbs, type, degree,and attribute for adjectives and adverbs, and others.Table 2 lists the main features used for contentwords.Feature ValuesNounsNumber singular/pluralCountability countable/uncountableVerbsTransitivity transitive/intransitive/double transitiveForm normal/infi nitive/presentparticiple/past participleAdjectivesType descriptive/restrictive/referentialAttribute arbitraryDegree base/comparative/superlativeAdverbsType descriptive/restrictive/referentialAttribute arbitraryDegree base/comparative/superlativeTable 2: Features for content wordsFor example, for the word dog, the entry in thelexicon is defined as:lex(dog,W):- W= [parse:dog, cat:noun,num:singular, count:countable].Here, the category (cat) is defined as noun, thenumber (num) is singular, and we also record thecountability (count)1.For adjectives, the value of the attribute featureis also stored, which is provided by the attribute re-lation in WordNet.
This relation links a descriptiveadjective to the attribute (noun) it modifies, such asslow ?
speed.
For example, for the adjective slow,the entry in the lexicon is defined as:lex(slow,W):- W= [parse:slow, cat:adj,attr:speed, degree:base, type:descriptive].Here, the category (cat) is defined as adjective,the type is descriptive, degree is base form.
We alsorecord the attr feature, which is derived from the at-tribute relation in WordNet, and links a descriptiveadjective to the attribute (noun) it modifies, such asslow?
speed.We are also exploiting the transitional relationsfrom adverbs to adjectives and to nouns.
We noticedthat some descriptive adverbs have correspondenceto descriptive adjectives, which in turn are linked tonouns by the attribute relation.
Using these transi-tional links, we derive relations like: slowly?
slow?
speed.
A typical descriptive adverb is defined asfollows:lex(slowly,W):- W= [parse:slowly, cat:adv,attr:speed, degree:base, type:descriptive].In addition to incorporating semantic informationfrom WordNet into the lexicon, this word level on-tology is also used to derive default rules, as dis-cussed later.3.3 Hand-coded KnowledgeThe FrameNet database encodes various syntac-tic realizations only for semantic roles within aframe.
Syntax-semantics mappings other than se-mantic roles are manually encoded as rules inte-grated in the syntactic-semantic analyzer.
The an-alyzer determines the syntactic structure of the sen-tence, and once a particular syntactic constituentis identified, its corresponding mapping rules areimmediately applied.
The syntactic constituent is1The value for the feature (countability) is obtainedfrom word properties stored in the Link parser dictionaries(http://www.link.cs.cmu.edu/link/).
The Link dictionaries arealso used to derive the lists of words to be stored in the lexi-con.
Note however that the Link parser itself is not used in theparsing process.then translated into its corresponding semantic con-stituent, together with the relevant semantic infor-mation.Some semantic relations can be directly derivedfrom syntactic patterns.
For example, a restrictiverelative clause such as ?the man that you see?
servesas a referential modifier.
An adverbial clause be-ginning with ?because?
is a modifier describing the?reason?
of the interaction.
The inflection from?apple?
to ?apples?
adds an attributive modifier ofquantity to the entity ?apple?.However, syntactic relations may often introducesemantic ambiguity, with multiple possible interpre-tations.
To handle these cases, we encode rules thatdescribe all possible interpretations of any givenstructure, and then use lexical semantic informa-tion as selectional restrictions for ambiguity reso-lution.
For instance, in ?a book on Chinese his-tory?, on Chinese history describes the topic of thebook and this interpretation can be uniquely deter-mined by noting that history is not a physical object,and thus the interpretation of on Chinese history asdescribing location is semantically anomalous.
In-stead, in ?a book on the computer?, on the computermay describe a location, but it could also describethe book topic, and hence the correct interpretationof this sentence cannot be determined without ad-ditional context.
In such cases, the semantic parserproduces all possible interpretations, allowing sys-tems that use the semantic parser?s output to deter-mine the right interpretation that best fits the appli-cation at hand.Selectional restrictions ?
as part of the hand-coded knowledge ?
are used for both semanticrole identification and syntax-semantics translation.These additional rules are needed to supplement theinformation encoded in FrameNet, since FrameNetonly annotates syntactic features, which often timesdo not provide enough information for identifyingcorrect semantic roles.Consider for example ?I break the window?
vs.?The hammer breaks the window?.
According toour semantic parser, the participants in the interac-tion ?break?
have exactly the same syntactic fea-tures in both sentences, but they play different se-mantic roles (?I?
plays the agent role while ?ham-mer?
plays the instrument role), since they belongto different ontological categories: ?I?
refers to aperson and ?hammer?
refers to a tool.
This interpre-tation is not possible using only FrameNet informa-tion, and thus we fill the gap by attaching selectionalrestrictions to the rules extracted from FrameNet.The definition of selectional restriction is basedon WordNet 2.0 noun hierarchy.
We say that en-tity E belongs to the ontological category C if thenoun E is a child node of C in the WordNet seman-tic hierarchy of nouns.
For example, if we definethe ontological category for the role ?instrument?
asinstrumentality, then all hyponyms of instrumental-ity can play this role, while other nouns like ?boy?,which are not part of the instrumentality categorywill be rejected.
Selectional restrictions are definedusing a Disjunctive Normal Form (DNF) in the fol-lowing format:[Onto(ID,P),Onto(ID,P),...],[Onto(ID,P),...],...Here, ?Onto?
is a noun and ID is its Word-Net sense, which uniquely identifies Onto as anode in the semantic network.
?P?
can be setto p (positive) or n (negative), denoting if a nounshould belong to the given category or not.
Forexample, [person(1,n),object(1,p)],[substance(1,p)]means that the noun should belong to object(sense#1) but not person(sense #1)2, or it should belongto substance(sense #1).
This information is addedto the rules derived from FrameNet, and thereforeafter this step, a complete FrameNet rule entry is:[Voice,[GF,PT,SelectionalRestriction,Role],...].4 Semantic ParsingThe general procedure of semantic parsing consistsof three main steps3: (1) The syntactic-semanticanalyzer analyzes the syntactic structure, and useshand-coded rules as well as lexical semantic knowl-edge to identify some semantic relations betweenconstituents.
It also prepares syntactic features forsemantic role assignment in the next step.
(2) Therole assigner uses rules extracted from FrameNet,and assigns semantic roles for identified partici-pants, based on their syntactic features as producedin the first step.
(3) For those constituents not exem-plified in FrameNet, we apply default rules to decidetheir default meaning.4.1 Feature Augmented Syntactic-SemanticAnalyzerThe analyzer is implemented as a bottom-up chartparsing algorithm based on features.
We includerules of syntax-semantics mappings in the unifica-tion based formalism.
The parser analyzes syntac-tic relations and immediately applies correspondingmapping rules to obtain semantic relations when a2person(sense #1) is a child node of object(sense #1) inWordNet3The parsing algorithm is implemented as a rule-based sys-tem using a declarative programming language Prolog.syntactic relation is identified.
Most semantic rela-tions (e.g.
various modifiers) are identified in thisstep, except semantic role annotation and applica-tion of default rules, which are postponed for a laterstage.
The analyzer generates an intermediate for-mat, where target words and arguments are explic-itly tagged with their syntactic and semantic fea-tures, so that they can be matched against the rulesderived from FrameNet.
We are using a feature-based analyzer that accomplishes three main tasks:4.1.1 Check if the sentence is grammaticallycorrectThe syntactic analyzer is based on a feature aug-mented grammar, and therefore has the capability ofdetecting if a sentence is grammatically correct (un-like statistical parsers, which attempt to parse anysentence, regardless of their well-formness).
Thegrammar consists of a set of rules defining how con-stituents with different syntactic or semantic fea-tures can unify with each other.By defining a grammar in this way, using fea-tures, once the right features are selected, the an-alyzer can reject some grammatically incorrect sen-tences such as: I have much apples., You has mycar., and some semantically anomalous sentences:The technology is very military.4.4.1.2 Provide features for semantic roleassignmentThrough syntactic-semantic analysis in the firststep, sentences are transformed into a formatin which target words and syntactic constituentsare explicitly tagged with their features.
UnlikeFrameNet ?
which may also assign roles to adverbs,we only use the subject, object(s) and prepositionalphrases as potential participants in the interactionfor semantic role labeling5.
The analyzer marksverbs as target words for frame identification, iden-tifies constituents for semantic role assignment, andproduces features such as GF, PT, Voice, Preposi-tion, as well as ontological categories for each con-stituent, in a format identical to the rules extractedfrom FrameNet, so that they can be matched withthe frame definitions.The ontological categories of constituents areused to match selectional restrictions, and are au-tomatically derived from the head word of the nounphrase, or the head word of the noun phrase of theprepositional phrase.
For other constituents thatact like nouns, such as pronouns, infinitive forms,gerunds, or noun clauses, we have manually defined4Since military is not a descriptive adjective, it cannot bemodifi ed by very and predicative use is forbidden.5Adverbs are treated as modifi ers.ontological categories.
For example, ?book?
is theontological category of the phrase ?the interestingbook?
and ?on the book?.
?person?
is the ontolog-ical category we manually define for the pronoun?he?.
We have also defined several special onto-logical categories that are not in WordNet such asany, which can be matched to any selectional re-striction, nonperson, which means everything ex-cept person, and others.
Note that this matchingprocedure also plays the role of a word sense dis-ambiguation tool, by selecting only those categoriesthat match the current frame constituents.
Afterthis step, target words and syntactic constituents canbe assigned with the corresponding case frame andsemantic roles during the second step of semanticparsing.4.1.3 Identify some semantic relationsSome semantic relations can be identified in thisphase.
These semantic relations include word levelsemantic relations, and some semantic relationsthat have direct syntactic correspondence by usingsyntax-semantics mapping rules.
This phase canalso identify the function of the sentence such asassertion, query, yn-query, command etc, based onsyntactic patterns of the sentence.The output of the analyzer is an intermediate for-mat suitable for the semantic parser, which containssyntactic features and identified semantic relations.For example, the output for the sentence ?He kickedthe old dog.?
is:[assertion,[[tag, ext, np, person,[[entity, [he], reference(third)],[modification(attribute), quantity(single)],[modification(attribute), gender (male)]]],[target, v, kick, active, [kick]],[modification(attribute), time (past)],[tag, obj, np, dog,[[modification(reference), reference(the)],[modification(attribute), age(old)],[target, n, dog, [dog]]]]]]4.2 Semantic Role AssignmentIn the process of semantic role assignment, we firststart by identifying all possible frames, accordingto the target word.
Next, a matching algorithm isused to find the most likely match among all rulesof these frames, to identify the correct frame (orframes if several are possible), and assign semanticroles.In a sentence describing an interaction, we selectthe verb as the target word, which triggers the sen-tence level frame and uses the FrameNet rules ofthat target word for matching.
If the verb is notdefined in FrameNet and VerbNet, we use Word-Net synonymy relation to check if any of its syn-onyms is defined in FrameNet or VerbNet.
If suchsynonyms exist, their rules are applied to the tar-get word.
This approach is based on the idea in-troduced by Levin that ?what enables a speaker todetermine the behavior of a verb is its meaning?
(Levin, 1993).
Synonymous verbs always intro-duce the same semantic frame and usually have thesame syntactic behavior.
To minimize informationin the verb lexicon, non-frequently used verbs usu-ally inherit a subset of the syntactic behavior oftheir frequently used synonyms.
Since VerbNet hasdefined a framework of syntactic-semantic behav-ior for these frequently used verbs, the behavior ofother related verbs can be quite accurately predictedby using WordNet synonymy relations.
Using thisapproach, we achieve a coverage of more than 3000verbal lexical units.The matching algorithm relies on a scoringscheme to evaluate the similarity between two se-quences of features.
The matching starts from thefirst constituent of the sentence.
It looks throughthe list of entries in the rule and when a match isfound, it moves to the next constituent looking fora new match.
A match involves match of syntacticfeatures, as well as match of selectional restrictions.An exact match means that both syntactic featuresand selectional restrictions are matched, which in-crements the score of matching by 3.
We applyselectional restriction by looking up the WordNetnoun hierarchies.
If the node of the ontological cat-egory is within the areas that the selectional restric-tion describes, this is regarded as a match.
Whenapplying selectional restrictions, due to polysemyof the ontological entries, we try all possible senses,starting from the most frequently used sense accord-ing to WordNet, until one sense meets the selec-tional restriction.
If the syntactic features match ex-actly, but none of the possible word senses meet theselectional restrictions, this is regarded as a partialmatch, which increments the score by 2.Partial matching is also possible, for a relaxedapplication of selectional restriction.
This enablesanaphora and metaphor resolution, in which theconstituents have either unknown ontological cate-gory, or inherit features from other ontological cat-egories (by applying high level knowledge such aspersonification).
The number of subjects and ob-jects as well as their relative positions should bestrictly obeyed, since any variations may result insignificant differences for semantic role labeling.Prepositional phrases are free in their location be-cause the preposition is already a unique identi-fier.
Finally, after all constituents have found theirmatch, if there are still remaining entries in therule, the total score is decreased by 1.
This is apenalty paid by partial matches, since additionalconstituents may indicate different semantic role la-beling, which may change the interpretation of theentire sentence.A polysemous verb may belong to multipleframes, and a frame pertaining to a given targetword may have multiple possible syntactic realiza-tions, exemplified by different sentences in the cor-pus.
We try to match the syntactic features in the in-termediate format with all the rules of all the framesavailable for the target word, and compare theirmatching scores.
The rule with the highest scoreis selected, and used for semantic role assignment.Through this scoring scheme, the matching algo-rithm tries to maximize the utilization of syntacticand semantic information available in the sentence,to correctly identify case frames and semantic roles.4.2.1 Walk-Through ExampleAssume the following two rules, triggered for thetarget word break:1: [active,[ext,np,[[person(1,p)]],agent],[obj,np,[[object(1,p)]],theme],[comp,pp,with,[[instrumentality(3,p)]],instrument]]2: [[ext,np,[[instrumentality(3,p)]],instrument],[obj,np,[[person(1,n),object(1,p)]],theme]]3: [[ext,np,[[person(1,n),object(1,p)]],theme]]And the sentences:A: I break the window with a hammerB: The hammer breaks the windowC: The window breaks on the wallThe features identified by the analyzer are:A?:[[ext,np,active,person],[obj,np,active,window],[comp,pp,active,with,hammer]]B?:[[ext,np,active,hammer],[obj,np,active,window]]C?
:[[ext,np,active,window],[comp,pp,on,wall]]Using the matching/scoring algorithm, the scorefor matching A?
to rule 1 is determined as 9 sincethere are 3 exact matches, and to rule 2 as 5 sincethere is an exact match for ?the window?
but a par-tial match for ?I?.
Hence, the matching algorithmselects rule 1, and the semantic role for ?I?
is agent.Similarly, when we match B?
to rule 1, we obtain ascore of 4, since there is an exact match for ?thewindow?, a partial match for ?the hammer?, andrule 1 has an additional entry for a prepositionalphrase, which decrements the score by 1.
It makesa larger score of 6 for matching with rule 2.
There-fore, for the second case, the role assigned to ?thehammer?
is instrument.
Rule 3 is not applied to thefirst two sentences since they have additional ob-jects; similarly, rule 1 and 2 cannot be applied tosentence C for the same reason.
The first constituentin C finds an exact match in rule 3 with a total scoreof 3, and hence ?the window?
is assigned the correctrole theme.
The prepositional phrase ?on the wall?,for which no entry for labeling a role is found in rule3, will be handled by default rules (see Section 4.3).Based on the principle of compositionality, mod-ifiers and constituents assigned semantic roles candescribe interactions, so the semantic role assign-ment is performed recursively, until all roles withinframes triggered by all target words are assigned.4.3 Applying Default RulesWe always assign semantic roles to subjects and ob-jects6, but only some prepositional phrases can in-troduce semantic roles, as defined in the FrameNetcase frames.
Other prepositional phrases functionas modifiers; in order to handle these constituents,and allow for a complete semantic interpretation ofthe sentence, we have defined a set of default rulesthat are applied as the last step of the semantic pars-ing process.
For example, FrameNet defines a rolefor the prepositional phrase on him in ?I dependon him?
but not for on the street in ?I walk on thestreet?, because it does not play a role, but it is amodifier describing a location.
Since the role forthe prepositional phrase beginning with on is not de-fined for the target word walk in FrameNet, we ap-ply the default rule that ?on something?
modifies thelocation attribute of the interaction walk.
Note thatwe include selectional restriction in the default rulesince constituents with the same syntactic featuressuch as ?on Tuesday?
and ?on the table?
may haveobviously different semantic interpretations.
An ex-ample of a default rule is shown below, indicatingthat the interpretation of a prepositional phrase fol-lowed by a time period (where time period is anontological category from WordNet) is that of timemodifier:DefaultRule([_,pp,_,on,Onto,_],time):-SelectionalRestriction(Onto,1,[[time_period(1,p)]])We have defined around 100 such default rules,which are applied during the last step of the seman-6Where a subject and object are usually realized by nounphrases, noun clauses, or infi nitive forms.tic parsing process.5 Parser Output and EvaluationWe illustrate here the output of the semantic parseron a natural language sentence, and show thecorresponding semantic structure and tree7.
Forexample, for the sentence I like to eat Mexican foodbecause it is spicy, the semantic parser produces thefollowing encoding of sentence type, frames, se-mantic constituents and roles, and various attributesand modifiers:T = assertionP =[[experiencer, [[entity, [i], reference(first)],[modification(attribute), quantity(single)]]],[interaction(experiencer_subj),[love]],[modification(attribute), time(present)],[content, [[interaction(ingestion), [eat]],[ingestibles, [entity, [food]][[modification(restriction), [mexican]],]]]],[reason, [[agent, [[entity, [it],reference(third)],[modification(attribute), quantity(single)]]],[description,[modification(attribute), time(present)]],[modification(attribute),taste_property(spicy)]]]]The corresponding parse tree is shown in Figure 1.ingestion ), [eat]interaction(I love to eat Mexican food, because it is spicy.
{[I], reference(first)}S?
[assertion]interaction( experiencer_subj ), [love]{[it], reference(third)}time(present)quantity(single) {food}{mexican}taste_property(spicy)ingestiblesexperiencer content reasonam amsmamFigure 1: Semantic parse tree (am = attributive modifi er,rm = referential modifi er, sm = restrictive modifi er)We have conducted evaluations of the semanticrole assignment algorithm on 350 sentences ran-domly selected from FrameNet.
The test sentenceswere removed from the FrameNet corpus, and therules-extraction procedure described earlier in thepaper was invoked on this reduced corpus.
All testsentences were then semantically parsed, and fullsemantic annotations were produced for each sen-tence.
Notice that the evaluation is conducted only7The semantic parser was demonstrated in a major NaturalLanguage Processing conference, and can be also demonstratedduring the workshop.for semantic role assignment ?
since this is the onlyinformation available in FrameNet.
The other se-mantic annotations produced by the parser (e.g.
at-tribute, gender, countability) are not evaluated atthis point, since there are no hand-validated anno-tations of this kind available in current resources.Both frames and frame elements are automati-cally identified by the parser.
Out of all the elementscorrectly identified, we found that 74.5% were as-signed with the correct role (this is therefore theaccuracy of role assignment), which compares fa-vorably with previous results reported in the liter-ature for this task.
Notice also that since this is arule-based approach, the parser does not need largeamounts of annotated data, and it works well thesame for words for which only one or two sentencesare annotated.6 Interface and Integration to OtherSystemsThe semantic algorithm uses linguistic knowledge,such as syntactic realization of semantic roles in acase frame, syntax-semantics mappings, and lexicalsemantic knowledge, to parse the semantic structureof open text.
It can be regarded as a shallow se-mantic analyzer, which provides partial results forhigher level understanding systems that can effec-tively utilize context, commonsense, and other typesof knowledge, to achieve final accurate meaning in-terpretations, or use custom defined rules for highlevel processing in particular domains.The matching/scoring scheme integrated in ouralgorithm can effectively identify the right semanticinterpretation, but some semantic ambiguity cannotbe resolved without enough context and common-sense knowledge.
For example, although the fa-mous meaningless sentence ?colorless green ideassleep furiously?
can be correctly identified as se-mantically anomalous by the semantic parser, byanalyzing the syntactic behavior of ?sleep?
and theselectional restrictions that we attach to this frame,the sentence ?I saw the man in the park with thetelescope?
has several semantic interpretations.
Ac-cording to the commonsense knowledge that we en-code in the semantic parser (mostly drawn fromWordNet), telescope is defined as a tool to see some-thing, and we may infer that ?with telescope?
in thissentence describes an instrument of ?see?.
How-ever, without enough context, not even humans canrule out the possibility that the ?telescope?
is theman?s possession, rather than an instrument for theinteraction ?see?.
The semantic parser maintains allpossible interpretations that cannot be rejected bytheir syntactic and shallow semantic patterns, andrank all of them by their scores as the likelihood ofbeing the correct interpretation.
Other systems canuse high level knowledge such as common sense,context or user defined rules to choose the right in-terpretation.As an integral part of the parsing system, we pro-vide several interfaces that allow other systems oradditional modules to change the behavior of theparser based on their rules and knowledge.
Onesuch interface is the ontochg predicate, which iscalled whenever the ontological category is identi-fied for a constituent during the syntactic-semanticanalysis.
By default, it outputs the same ontolog-ical category as identified by the parser, but othersystems can change the content of this predicate toreplace the ontological category identified by theparser with other categories, according to their rulesand knowledge.
This is particularly useful for inte-grating add-ons capable of anaphora and metaphorresolution.
The adjatt predicate is another interfacefor add-ons that can resolve polysemy of descriptiveadjectives and adverbs.
Due to polysemy, some de-scriptive adjectives and adverbs may modify differ-ent attributes in different situations and sometimesthe resolution requires high level understanding us-ing commonsense knowledge and context.
Theseinterfaces make the semantic parser more flexible,robust, and easier to integrate into other systems thatachieve high level meaning processing and under-standing.7 Related WorkThere are several statistical approaches for auto-matic semantic role labeling based on PropBankand FrameNet.
(Gildea and Jurafsky, 2000) pro-posed a statistical approach based on FrameNet Idata for annotation of semantic roles.
Fleischman(Fleischman et al, 2003) used FrameNet annota-tions in a maximum entropy framework.
A moreflexible generative model is proposed in (Thomp-son et al, 2003), where null-instantiated roles canbe also identified, and frames are not assumed to beknown a-priori.
These approaches exclusively focuson semantic roles labeling based on statistical meth-ods, rather than analysis of the full structure of sen-tence semantics.
However, a rule-based approachis closer to the way humans interpret the semanticstructure of a sentence.
Moreover, as mentionedearlier, the FrameNet data is not meant to be ?sta-tistically representative?
(Johnson et al, 2002), butrather illustrative for various language constructs,and therefore a rule-based approach is more suitablefor this lexical resource.8 ConclusionsIn this paper, we proposed an algorithm for opentext shallow semantic parsing.
The algorithm hasthe capability to analyze the semantic structure ofa sentence, and show how the meaning of the en-tire sentence is composed of smaller semantic units,linked by various semantic relations.
The parsingprocess utilizes linguistic knowledge, consisting ofrules derived from a frame dataset (FrameNet), a se-mantic network (WordNet), as well as hand-codedrules of syntax-semantics mappings, which encodenatural selectional restrictions.
Parsing semanticstructures allows semantic units and constituents tobe accessed and processed in a more meaningfulway than syntactic parsing, and enables higher-leveltext understanding applications.
We believe that thesemantic parser will prove useful for a range of lan-guage processing applications that require knowl-edge of text meaning, including word sense disam-biguation, information retrieval, question answer-ing, machine translation, and others.ReferencesM.
Fleischman, N. Kwon, and E. Hovy.
2003.Maximum entropy models for FrameNet classi-fication.
In Proceedings of 2003 Conference onEmpirical Methods in Natural Language Pro-cessing EMNLP-2003, Sapporo, Japan.D.
Gildea and D. Jurafsky.
2000.
Automatic label-ing of semantic roles.
In Proceedings of the 38thAnnual Conference of the Association for Com-putational Linguistics (ACL 2000), pages 512?520, Hong Kong, October.C.
Johnson, C. Fillmore, M. Petruck, C. Baker,M.
Ellsworth, J. Ruppenhofer, and E. Wood.2002.
FrameNet: Theory and Practice.http://www.icsi.berkeley.edu/ framenet.K.
Kipper, H.T.Dang, and M. Palmer.
2000.
Class-based construction of a verb lexicon.
In Proceed-ings of Seventeenth National Conference on Arti-ficial Intelligence AAAI 2000, Austin,TX, July.B.
Levin.
1993.
English Verb Classes and Alterna-tion: A Preliminary Investigation.
The Univer-sity of Chicago Press.G.
Miller.
1995.
Wordnet: A lexical database.Communication of the ACM, 38(11):39?41.C.
Thompson, R. Levy, and C. Manning.
2003.
Agenerative model for FrameNet semantic role la-beling.
In Proceedings of the Fourteenth Euro-pean Conference on Machine Learning ECML-2003, Croatia.
