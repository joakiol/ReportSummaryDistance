Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 85?88,Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLPDiscriminative Approach to Predicate-Argument Structure Analysiswith Zero-Anaphora ResolutionKenji Imamura, Kuniko Saito, and Tomoko IzumiNTT Cyber Space Laboratories, NTT Corporation1-1 Hikarinooka, Yokosuka, Kanagawa, 239-0847, Japan{imamura.kenji,saito.kuniko,izumi.tomoko}@lab.ntt.co.jpAbstractThis paper presents a predicate-argumentstructure analysis that simultaneously con-ducts zero-anaphora resolution.
By addingnoun phrases as candidate arguments thatare not only in the sentence of the targetpredicate but also outside of the sentence,our analyzer identifies arguments regard-less of whether they appear in the sen-tence or not.
Because we adopt discrimi-native models based on maximum entropyfor argument identification, we can easilyadd new features.
We add language modelscores as well as contextual features.
Wealso use contextual information to restrictcandidate arguments.1 IntroductionPredicate-argument structure analysis is a type ofsemantic role labeling, which is an important mod-ule to extract event information such as ?who didwhat to whom?
from a sentence.
There are manyarguments called zero pronouns that do not appearin the surface of a sentence in Japanese.
In thiscase, predicate-argument structures cannot be con-structed if we only rely on the syntactic informa-tion of a single sentence.
Similar phenomena alsohappen in English noun predicates, in which ar-guments of noun predicates sometimes do not ex-ist in the sentence due to things such as ellipses(Jiang and Ng, 2006).
To correctly extract thestructures from such sentences, it is necessary toresolve what zero pronouns refer to by using otherinformation such as context.Although predicate-argument structure analysisand zero-anaphora resolution are closely related,it was not until recently that these two tasks werelumped together.
Due to the developments oflarge annotated corpora with predicate-argumentand coreference relations (e.g.,(Iida et al, 2007))and with case frames, several works using statisti-cal models have been proposed to solve these twotasks simultaneously (Sasano et al, 2008; Taira etal., 2008).In this paper, we present a predicate-argumentstructure analysis that simultaneously resolves theanaphora of zero pronouns in Japanese, based onsupervised learning.
The analyzer obtains candi-date arguments not only from the sentence of thetarget predicate but also from the previous sen-tences.
It then identifies the most likely argu-ments based on discriminative models.
To iden-tify arguments that appear in the sentence and arerepresented by zero pronouns without distinction,the analyzer introduces the following features andtechniques: the language model features of nounphrases, contextual features, and restrictions ofcandidate arguments.2 Predicate-Argument StructureAnalyzer2.1 Procedure and ModelsThe procedure of our predicate-argument structureanalyzer is as follows.
The input to the analyzer isan article (multiple sentences) because our targetis to identify arguments spread across sentences.1.
First, each sentence is individually analyzedand segmented into base phrases by a morpho-logical analyzer and a base phrase chunker.
InJapanese, a base phrase is usually constructedby one or more content words (such as basenoun phrases) and function words (such as caseparticles).
In addition, dependency relationsamong base phrases are parsed by a depen-dency parser.
In this paper, base phrases anddependency relations are acquired from an an-notated corpus (i.e., correct parses).2.
Next, predicates are extracted from the basephrases.
In general, a predicate is determined85Name NoteBaselineFeaturesPredicate Form and POS of the predi-cateNoun Form and POS of the head-word of the candidate phraseParticle Form and POS of the particleof the candidate phrasePath Dependency relation betweenthe predicate and the candi-date phrasePassive Passive auxiliary verbs thatthe predicate containsPhPosit Relative phrase position be-tween the predicate and thecandidate phraseSentPosit Relative sentence position be-tween the predicate and thecandidate phraseAdditionalFeatures(c.f.,Sec.
2.2and 2.3)LangModel Language model scoresUsed Flag whether the candidatephrase was used as argumentsof previous predicatesSRLOrder Order in Salient Referent ListTable 1: Features Used in this Paperbased on parts of speech such as verbs and ad-jectives.
In this paper, the predicates are alsoprovided from an annotated corpus.3.
Concurrently, noun phrases and their head-words are extracted as candidate argumentsfrom base phrases.
If an argument of a predi-cate is a zero pronoun, it is likely that the argu-ment itself has appeared in previous sentences.Therefore, the analyzer collects not only allphrases in the sentence but also some phrasesin the previous sentences.
We also add the spe-cial noun phrase NULL, which denotes that theargument of the predicate is not required or didnot appear in the article (i.e., exophoric).4.
Next, features needed for an argument iden-tifier are extracted from each pair of a predi-cate and a candidate argument.
Features usedin this paper are shown in Table 1.
Base-line features are roughly those of the predi-cate, the noun phrase, and their relations (onthe phrasal/sentential sequence and the depen-dency tree).
For binary features, we use allcombinations of these features listed above.5.
Finally, the argument identifier selects the bestphrases for nominative, accusative, and dativecases from the candidate arguments (Figure 1).In this paper, we use maximum entropy modelsnormalized for each predicate to each case.
Thatis, the identifier directly selects the best phrase thatNULL Phrase 1 Phrase 2 Phrase 3 Phrase 4 ...Candidate ArgumentsPhrase 1 Phrase 3 NULLCandidate Argumentsin Sentence of PredicateCandidate Argumentsbefore Sentences of Predicatezero-anaphoric(inter-sentential)exophoricor no argumentSelectBestPhraseDat.ModelSelectBestPhraseAcc.ModelSelectBestPhraseNom.ModelFigure 1: Summary of Argument Identificationsatisfies the following equations from the candi-date arguments:n?
= argmaxnj?NP (d(nj) = 1|Xj;Mc) (1)P (d(nj) = 1|Xj;Mc) =1Zc(X)exp?k{?ckfk(d(nj) = 1, Xj)}(2)Zc(X) =?nj?Nexp?k{?ckfk(d(nj) = 1, Xj)} (3)Xj= ?nj, v, A?
(4)where n, c, and v denote a noun phrase of an argu-ment, the case, and the target predicate, respec-tively, N denotes a set of candidate arguments,d(n) is a function that returns 1 iff the phrase nbecomes the argument, and Mcdenotes the modelof the case c. In addition, fk(d(nj) = 1, Xj) is afeature function, ?ckdenotes a weight parameterof the feature function, and A denotes an article inwhich all sentences are parsed.As shown, our analyzer can assign the best nounphrases to arguments regardless of whether theyappear in the sentence or not by collecting candi-dates spread across multiple sentences.
Further-more, because the identifier is regarded as a selec-tor based on the discriminative models, our ana-lyzer has two properties: 1) New features can beeasily added.
2) The precision can be improved byrestricting the candidate arguments appropriately.When we analyze predicate-argument struc-tures and zero-anaphora resolution, syntactic in-formation sometimes does not help because refer-ents of zero pronouns do not appear in the sen-tence of the predicate.
To overcome this problem,86we introduce additional information, i.e., languagemodel scores and contextual information.2.2 Language ModelsEven if syntactic information does not help toidentify arguments, we can expect that a certainnoun phrase might be the correct argument of thepredicate when we put it in place of the zeropronoun and the sentence becomes meaningful.Therefore, we add language model scores as fea-tures of the identifier.
Because the appearance or-der of argument phrases is not strongly constrictedin Japanese, we construct generation models thatreflect dependency relations among a predicate, itscase and a noun phrase.
That is, we regard gen-eration probabilities P (n|c, v) acquired from thedependency tree as the scores of language models.The language models are built from large plaintexts by using a dependency parser.
First, predi-cates and the base phrases that directly depend onthe predicates are aquired from parsed sentences.Next, case particles and headwords are extractedfrom the base phrases.
Finally, generation prob-abilities are computed using maximum likelihoodestimation.
Good-Turing discounting and backoffsmoothing are also applied.
Here, it is necessaryto assign generation probabilities to NULLs.
Re-garding the training corpus that will be describedin Section 3, the NULL rates of the nominative,accusative, and dative cases were 16.7%, 59.9%,and 81.6%, respectively.
We assign these rates tothe backoff term P (NULL|c).Using the language models, generation proba-bilities of the noun phrases are computed for ev-ery case of the predicate, and features that main-tain the logarithms of language model scores areadded (?LangModel?
features in Table 1).
Thus,the values of these feature functions are real.2.3 Usage of ContextCentering theory claims that noun phrases thathave been used once tend to be used again withinthe same context.
We adopt this claim and add twodifferent kinds of features.
One is the feature thatindicates whether a candidate has been used as anargument of predicates in the preceding sentences(?Used?
features).
However, the Used features areaffected by the accuracy of the previous analyses.Thus, we also adopt the Salience Reference List(Nariyama, 2002), which only uses explicit sur-face case markers or a topic marker, and addedTraining Development Test# of Articles 1,751 480 695# of Sentences 24,225 4,833 9,272# of Predicates 67,145 13,594 25,500# of ArgumentsNom.
56,132 11,969 21,931Acc.
26,899 5,566 10,329Dat.
12,332 3,147 5,944Table 2: Corpus Statisticstheir priority order to the List as another feature(?SRLOrder?
feature).Another way to adopt contextual informationis to restrict the candidate arguments.
When weanalyzed the training corpus from the viewpointof zero pronouns, it was found that 102.2 nounphrases on average were required as candidate ar-guments if we did not stipulate any restrictions.When the candidate arguments we had restrictedto those that had been used as arguments of thepredicate appeared in a previous one sentence(namely, noun phrases appeared in more than onesentence before have a chance to remain), then thenumber of candidate arguments significantly de-creased to an average of 3.2 but they covered the62.5% of the referents of zero pronouns.By using these characteristics, our analyzer re-stricts the candidate arguments to those that are ofthe same sentence, and those that were used as thearguments of another predicate in a previous sen-tence.3 Experiments3.1 Experimental SettingsCorpora: We used the NAIST Text Corpus ver-sion 1.4b (Iida et al, 2007) and the Kyoto TextCorpus 4.0 as the annotated corpora.
We couldobtain dependency and predicate-argument struc-tures because these corpora were annotated to al-most the same newspaper articles.
We dividedthem into training, development, and test sets asshown in Table 2.Argument Identification Models: Maximumentropy models were trained using the training set.In these experiments, we used the Gaussian prior,and the variance was tuned using the developmentset.
Candidate argument restrictions were appliedduring both training and decoding.Language Models: Language models weretrained from twelve years of newspaper articles(Mainichi Shinbun newspaper 1991-2002, about87# ofCase Type Args.
Prec.
Rec.
FNom.
Dep.
14,287 85.2% 88.8% 87.0%Zero-Intra 4,581 58.8% 43.4% 50.0%Zero-Inter 3,063 47.5% 7.6% 13.1%Total 21,931 79.4% 68.0% 73.2%Acc.
Dep.
9,316 95.6% 92.2% 93.9%Zero-Intra 742 53.7% 21.6% 30.8%Zero-Inter 271 25.0% 0.4% 0.7%Total 10,329 94.3% 84.7% 89.2%Dat.
Dep.
5,409 91.1% 72.6% 80.8%Zero-Intra 396 0.0% 0.0% 0.0%Zero-Inter 139 0.0% 0.0% 0.0%Total 5,944 91.1% 66.1% 76.6%Table 3: Results on the Test Set5.5M sentences) using the method described inSection 2.2.
However, we eliminated articles thatoverlap the NAIST Corpus.Evaluation: We evaluated the precision and re-call rates, and F scores, all of which were com-puted by comparing system output and the correctanswer of each argument.
We also evaluated therate at which all arguments of a predicate werecompletely identified as predicate-argument accu-racy.3.2 ResultsThe results are shown in Table 3.
This tableshows accuracies of the argument identificationaccording to each case and each dependency re-lation between predicates and arguments.
Thepredicate-argument accuracy on the test set was59.4% (15,140/25,500).First, focusing on the F scores of the Dep.
rela-tions, which denote a predicate and an argument inthe same sentence and directly depend upon eachother, scores of over 80% were obtained for allcases.
Compared with Taira et al (2008), theywere higher in the nominative and accusative casesbut were lower in the dative case.
Overall, we ob-tained F scores between 73.2% and 89.2%.Next, focusing on the intra-sentential (Zero-Intra) and inter-sentential (Zero-Intra) zero-anaphora, the analyzer identified arguments atsome level from the viewpoint of precision.
How-ever, the recall rates and F scores were verylow.
The Zero-Inter recall rate for the nominativecase, in which zero pronouns are centered, wasonly 7.6%.
This is because our method preferredNULL phrases over unreliable phrases appearingbefore the predicate sentence.
In fact, the analyzeroutput only 488 arguments, although the answerwas 3,063.
To control the NULL preference is afuture work for our analyzer.4 Discussions and ConclusionsWe proposed a predicate-argument structure anal-ysis that simultaneously conducts zero-anaphoraresolution.
By adding noun phrases as candidatearguments that are not only in the sentence ofthe target predicate but also outside of the sen-tence, our analyzer identified arguments regard-less of whether they appear in the sentence ornot.
Because we adopted discriminative modelsfor argument identification, we can easily add newfeatures.
By using this property, we added lan-guage model scores as well as contextual features.We also used contextual information to restrictcandidate arguments.
As a result, we achievedpredicate-argument accuracy of 59.4%, and accu-racies of argument identification were F-scores of73.2%?89.2%.Verifying argument structures by languagemodels evokes selectional preference of caseframes.
Sasano et al (2008) has proposed statis-tical models using case frames built from 1.6 Bsentences.
Because the amount of the resourcesused in our study is quite different, we cannot di-rectly compare the methods and results.
However,because our analyzer has scalability that can freelyadd new features, for our future work, we hope toadopt the case frames as new features and comparetheir effect.ReferencesRyu Iida, Mamoru Komachi, Kentaro Inui, and YujiMatsumoto.
2007.
Annotating a Japanese text cor-pus with predicate-argument and coreference rela-tions.
In Proceedings of the Linguistic AnnotationWorkshop in ACL-2007, pages 132?139.Zheng Ping Jiang and Hwee Tou Ng.
2006.
Seman-tic role labeling of nombank: A maximum entropyapproach.
In Proceedings of EMNLP-2006, pages138?145.Shigeko Nariyama.
2002.
Grammar for ellipsis res-olution in Japanese.
In Proceedings of TMI-2002,pages 135?145.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2008.
A fully-lexicalized probabilistic modelfor Japanese zero anaphora resolution.
In Proceed-ings of COLING-2008, pages 769?776.Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata.2008.
A Japanese predicate argument structure anal-ysis using decision lists.
In Proceedings of EMNLP-2008, pages 523?532.88
