Annotation Graphs and Servers and Multi-Modal Resources:Infrastructure for Interdisciplinary Education, Research andDevelopmentChristopher CieriUniversity of PennsylvaniaLinguistic Data Consortium3615 Market StreetPhiladelphia, PA. 19104-2608 USAccieri@ldc.upenn.eduSteven BirdUniversity of PennsylvaniaLinguistic Data Consortium3615 Market StreetPhiladelphia, PA. 19104-2608 USAsb@ldc.upenn.eduAbstractAnnotation graphs and annotationservers offer infrastructure to supportthe analysis of human languageresources in the form of time-seriesdata such as text, audio and video.
Thispaper outlines areas of common needamong empirical linguists andcomputational linguists.
Afterreviewing examples of data and toolsused or under development for each ofseveral areas, it proposes a commonframework for future tool development,data annotation and resource sharingbased upon annotation graphs andservers.1 IntroductionDespite different methodologies, goals andtraditions, researchers in a variety of specialtiesin linguistics and computational linguistics sharea core of assumptions and needs.
Researchcommunities in empirical linguistics, naturallanguage processing, speech recognition,information retrieval and language teachinghave a common need for language resourcessuch as observations of linguistic performance,annotations encoding human judgment,standards for maintaining consistency amongdistributed resources and processes forextracting relevant observations.
Where needsoverlap, there is the opportunity to reuseexisting resources and coordinate new initiativesso that communities share the burden ofdevelopment while benefiting from the results.Where computational linguistics interacts withother areas of language research and teaching,there are additional opportunities for symbiosis.Natural language technology may offer greateraccess and robustness to empirical linguisticresearch that in turn may offer new datanecessary to develop new technologies.
Thispaper discusses common infrastructure for theannotation of linguistic data and the applicationof that infrastructure to several traditionally verydiverse fields of inquiry.2 Common Assumptions, Needs andGoals in Natural Language StudiesHuman language resources, expensive tocreate and maintain, are in increasing demandamong a growing number of researchcommunities.
One solution to this expandingneed is to reannotate and reuse languageresources created for other purposes.
The nowclassic example is that of the Switchboard-1Corpus (ISBN: 1-58563-121-3), a collection of2400 two-sided telephone conversations among543 U.S. speakers, created by Texas Instrumentsin 1991.
Although collected for speakeridentification and topic spotting research,Switchboard has been widely used to supportlarge vocabulary conversational speechrecognition.
It has been extensively correctedtwice, once at Penn and NIST, and once atMississippi State.
Two excerpts have beenpublished as test corpora for government-sponsored projects.
At least 6 other annotationshave been created at various times and more-or-less widely distributed among research sites:part-of-speech annotation (Penn); syntacticstructure annotation (Penn); dysfluencyannotation (Penn); partial phonetic transcription(independently at UCLA and at Berkeley); anddiscourse function annotation (Colorado).
Theseannotations use different ?editions?
of theunderlying corpus and have sometimes silentlyintroduced their own corrections or modified thedata format to suit their needs.
Thus theColorado discourse function annotation wasbased on phrase structures introduced by thePenn dysfluency annotation, which in turn wasbased on the Penn/NIST corrections, which inturn were based on the original TI transcriptionsof the underlying (and largely unchanging)audio files.
Switchboard and its derivativesremain in active use worldwide, and newderivatives continue to be produced, along with(published and unpublished) corrections of oldones.
This worsens the already acute problem ofestablishing and maintaining coherent relationsamong the derivatives in common use today.The Switchboard-1 case is by no meansisolated (Graff & Bird 2000).
The TopicDetection and Tracking Corpus, TDT-2 (ISBN:1-58563-157-4) was created in 1998 by LDCand contains newswire and more than 600 hoursof transcribed broadcast news from 8 Englishand 3 Chinese sources sampled daily over sixmonths with annotations to indicate storyboundaries and relevance of those stories to 100randomly selected topics.
Since its release,TDT-2 has been used as training, development-test and evaluation data in the TDT evaluations;the audio has been used in TREC SDRevaluations (Garofalo, Auzanne and Voorhees2000), TDT text has been partially re-annotatedfor entity detection in the Automatic ContentExtraction project (Przybocki 2000) andportions have been used for the Center forSpoken Language Processing?s workshops inNovel Information Detection (Allan et.
al.1999), Mandarin-English Information (Meng et.al.
2000) and Audio-Visual Speech Recognition(Chalapati 2000).Switchboard and TDT are just two examplesof a growing trend toward reannotation andreuse of language resources, a trend that is notlimited to language engineering.
Miller andWalker (2001) have demonstrated the value ofthe CALLHOME German corpus (ISBN: 1-58563-117-5), developed to support speechrecognition research, for language teaching.Deckert & Yaeger-Dror (2000) have usedSwitchboard to study regional syntacticvariation in American English.Reannotation and reuse of linguistic datahighlight the need for common infrastructure tosupport resource development across disciplinesand specialties.3 Overlaps between Human LanguageTechnology and Other LinguisticResearchMany specialties in empirical linguistics andlanguage engineering require large volumes oflanguage data and tools for browsing andsearching the data efficiently.
The sections thatfollow provide examples of recent efforts toaddress emerging needs for language resources.Interlinear Texts and Linguistic ExplorationInterlinear text is a product of linguisticfieldwork often in low-density languages.
Thephysical appearance of interlinear text typicallyconsists of a main text line annotated withlinguistic transcriptions and analyses, such asmorphological representations, glosses atvarious levels, part-of-speech tags, and a freetranslation at the sentence level.
Fragments ofthese annotation lines are vertically aligned withthe corresponding fragments of text.
Phrasaltranslations and footnotes are often presented onother lines.
Interlinear texts come in many formsand can be represented digitally in many ways,e.g.
plain text with hard spacing, tables, specialmarkup, and special-purpose data structures.There are various methods for linking to audiodata and lexical entries, and for includingfootnotes and other marginalia.
This diversity ofform presents problems for general-purposesoftware for searching, exchanging, displayingand enriching interlinear texts.
Nonethelessinterlinear text is a precious resource withmultiple uses in natural language processing.
Itsvarious components can be used in thedevelopment of lexical and morphologicalresources, can support tagging and parsing andcan provide training material for machinetranslation.
Maeda and Bird (2000, 2001)demonstrated a tool for creating interlinear text.A screenshot appears in Figure 1.Figure 1: Interlinear text tool   using the AGToolkitSociolinguistic AnnotationThe quantitative analysis of linguisticvariation begins with empirical observation andstatistical description of linguistic behavior.Although general computer technologyencourages the collection, annotation, analysisand discussion of linguistic behavior whollywithin the digital domain, few tools exist to helpthe sociolinguist in this effort.
The project onData and Annotations for Sociolinguistics(DASL) is investigating best practices via a casestudy of well-documented sociolinguisticphenomena in several large speech corpora:TIMIT , Switchboard-1, CallHome and Hub-4.Researchers are currently annotating the corporafor t/d deletion, the process by which [t] and [d]sometimes fail to be realized under certainphonological, morphological and socialconditions.
The case study is also a means toaddress broader questions: How do the specifiedcorpora compare with the interview datatypically used in sociolinguistics?
Will the studyof corpus data reveal new patterns not evident inthe more common studies conducted within theframework of the speech community?
Canempirical research on language variation beorganized on a large scale with teams of non-specialist annotators?All of the data used in DASL were originallycreated to support human language technologydevelopment; the datasets are currently beingreannotated to support empirical studies oflinguistic variation.
A custom annotation toolallows users to query each corpus for tokens ofpotential interest greatly reducing effort relativeto traditional approaches.
Annotators can read orlisten to each token, access demographic dataand encode their observations in formatscompatible with other analytical software usedin the community.
The web-based interface inFigure 2 promotes multi-site annotation and thestudy of inter-annotator consistency (Cieri andStrassel, 2001).Authoring Resources and Tools for LanguageLearningAlthough current information technologyencourages new approaches in computer assistedlanguage learning and teaching, progress in thisarea is hampered by an inadequate supply oflanguage resources.
The SMART (Source MediaAuthoring Resources and Tools) pilot project isaddressing this problem by providingappropriately licensed data and softwareresources for preparing language-learningmaterial.
The Linguistic Data Consortium, apartner in this effort, is contributing several ofits large data sets including conversational andbroadcast data in Arabic, English, French andGerman.
The language resources overlap almostcompletely with those used in languageengineering.
SMART is building upon thedistribution model established in LDC Online, aservice that provides network-based access tohundreds of gigabytes of text and audio data andannotations.
Audio data are available digitally infiles corresponding to a conversation, broadcastor other linguistic event.
To facilitate searching,LDC Online includes, according to theiravailability, human- and machine-generatedFigure 2: Sociolinguistic Annotation Tooltranscripts time-aligned to permit more fine-grained access.
For example, where a time-aligned transcript of a conversation exists, usersmay extract, reformat and play any segmentspecified by the time stamps in the transcript.SMART is building upon this foundation byproviding additional data resources, browsingand search customized to the needs of languageteachers and additional output formats toaccommodate courseware authoring toolsavailable in the commercial market.SMART promises to benefit a wide range oflanguage teachers and learners but only to theextent that its resources are readily available.The volume of SMART data exceeds that whichcan be easily transferred over a network.
Evensmall video clips consume hundreds of megabitsof bandwidth.
Instead SMART data will bedelivered via servers that maintain raw data andassociated annotations, permit browsing andqueries and allow the user to specify the formatand granularity of the response.
The user willhave the option of downloading the data forlocal use or adding annotations that may be keptprivately or made public via the annotationserver.
The technology of the annotation servercoupled with the extensibility of annotationgraphs described below will enables nearlyunconstrained access to SMART data.These efforts to support interlinear text,sociolinguistic annotation and multimodal datain language teaching each require flexible accessto signal data and associated annotations.
Thesections that follow describe an architecture thatprovides such access.4 Annotation Graphs, AnnotationServers and a Query Language:Common Infrastructure forCoordinated Research, ResourceDevelopmentStoring and serving large amounts ofannotated data via the web requiresinteroperable data representations and toolsalong with methods for handling externalformats and protocols for querying anddelivering annotations.
Annotation graphs werepresented by Bird and Liberman (1999) as ageneral purpose model for representing andmanipulating annotations of time series data,regardless of their physical storage format.
Anannotation graph is a labeled, directed, acyclicgraph with time offsets on some of its nodes.The formalism is illustrated below byapplication to the TIMIT Corpus (Garofolo et al1986).
The original TIMIT word file containsstarting and ending offsets (in 16KHz samples)and transcripts of each word in the audio filetrain/dr1/fjsp0/sa1.wrd:2360    5200   she5200    9680   had9680   11077   your11077   16626   dark16626   22179   suit22179   24400   in24400   30161   greasy30161   36150   wash36720   41839   water41839   44680   all44680   49066   yearThe phone file provides the same informationfor each sound in the audio file.
This is thephonetic transcription for ?she had?.train/dr1/fjsp0/sa1.phn:0    2360    h#2360    3720    sh3720    5200    iy5200    6160    hv6160    8720    ae8720    9680    dcl9680   10173    y10173   11077    axr11077   12019    dcl12019   12257    dA section of the corresponding annotationgraph appears in Figure 3.
Each node displaysthe node identifier and the time offset.
The arcsare decorated with type and label information.Type W is for words and the type P is forphonetic transcriptions.Figure 3: A TIMIT annotation graphSince an annotation graph is just a set of(timed) nodes, arcs and labels, it can be triviallyrepresented using three relational tables:Time:       Arc:               Label:N     T      A   X   Y  T      A  L--------     -------------     -------0     0      1   0   1  P      1  h#1  2360      2   1   2  P      2  sh2  3270      3   2   3  P      3  iy3  5200      4   3   4  P      4  hv4  6160      5   4   5  P      5  ae5  8720      6   5   6  P      6  dcl6  9680      7   6   7  P      7  y7 10173      8   7   8  P      8  axr8 11077      9   8   9  P      9  dcl9 12019     10   9  10  P     10  d10 12257     19   3   6  W     18  she14 16626     20   6   8  W     19  had17 22179     21   8  14  W     20  your22  14  17  W     21  dark22  suitA large amount of annotation can beefficiently represented and indexed in thismanner.
This brings us to the question ofconverting (or loading) existing data into such adatabase.
The LDC's catalog alone includesnearly 200 publications, where each typicallyhas its own format (often more than one).
Thesheer quantity and diversity of the data presentsa significant challenge to the conversionprocess.
In addition, some corpora exist inmultiple versions, or include uncorrected,corrected and re-corrected parts.The Annotation Graph Toolkit, version 1.0,contains a complete implementation of theannotation graph model, import filters forseveral formats, loading/storing data to anannotation server (MySQL), applicationprogramming interfaces in C++ and Tcl/tk, andexample annotation tools for dialogue, ethologyand interlinear text.
The supported formats are:xlabel, TIMIT, BAS Partitur, Penn Treebank,Switchboard, LDC Callhome, CSV and AIFlevel 0.
Future work will provide Python andPerl interfaces, more supported formats, a querylanguage and interpreter, and a multi-channeltranscription tool.
All software is distributedunder an open source license, and is availablefrom http://www.ldc.upenn.edu/AG/.Given that the annotation data can be storedin a relational database, it can be querieddirectly in SQL.
More convenient, a domain-specific query language will be developed (seeCassidy and Bird 2000 and the work citedthere).
Query expressions will be transmittedover the web in the form of a CGI request, andtranslated into SQL by the annotation server.The resulting annotation data will be returned inthe form of an XML document.
An example forthe TIMIT database, using the languageproposed by Cassidy and Bird (2000), will serveto illustrate:Find word arcs spanning a sequence ofsegments beginning with hv and containing ae:http://BASE-URL/cgi-bin/query?X.[].Y<timit/word;X.[:hv].[]*.[:ae].
[]*.Y<-timit/phExecuted on the above annotation data, thisquery would return the XML document inFigure 4.Neither the query nor the returned documentare intended for human consumption.
A client-side annotation tool will initiate queries anddisplay annotation content on behalf of an end-user.<?xml version="1.0"?><!DOCTYPE AGSet SYSTEM "ag.dtd"><AGSet id="Timit" version="1.0" xmlns="http://www.ldc.upenn.edu/atlas/ag/"xmlns:xlink="http://www.w3.org/1999/xlink"xmlns:dc="http://purl.org/DC/documents/rec-dces-19990702.htm"><Timeline id="T1"><Signal id="S1" mimeClass="audio" mimeType="wav" encoding="wav"unit="16kHz" xlink:href="TIMIT/train/dr1/fjsp0/sa1.wav"/></Timeline><AG id="t1" type="transcription" timeline="T1"><Anchor id="A3" offset="5200" unit="16kHz"/><Anchor id="A6" offset="9680" unit="16kHz"/><Annotation id="Ann10" type="W" start="A3" end="A6"><Feature name="label">had</Feature></Annotation></AG></AGSet>Figure 4: Document returned by AG queryThis annotation tool and server are integratedusing the model shown below.
A simplifiedclient-server model, working at the level ofannotation files is already available with thecurrent distribution of the Annotation GraphToolkit.
Significantly, a networked annotationtool is identical to a standalone version, exceptthat the AG library fetches its data from aremote server instead of local disk.The annotation graph formalism, annotationservers and the emerging query language willprovide basic infrastructure to store, process anddeliver essentially arbitrary amounts and typesof signal annotations for a wide variety ofresearch and teaching tasks including thosedescribed above.
This infrastructure will enablereuse of existing resources and coordinateddevelopment of new resources both within andacross research communities working withannotated linguistic datasets.5 Remaining Challenges to LanguageResource DevelopmentWe have described a process wherebyannotated data in a variety of formats can beloaded into a central database server thatinteracts directly with annotation tools.
TheAnnotation Graph Toolkit, version 1.0, is thefirst implementation of this architecture.
As thetoolkit undergoes future development, it willneed to deal continually with conversion issues.Annotation data will continue to be created andmanipulated by multiple tools and to be storedin incompatible file formats.
Data will continueto be mapped between different formats so thatappropriate tools can be used, and appropriatelymanaged to keep inconsistencies from arising.There will still be times when we need to tracethe provenance of a particular item, backthrough a history involving several formats.These will always be hard problems; theproposed infrastructure will address them but noinfrastructure is likely to eliminate conversion,integrity and provenance issues.Annotation graphs focus on the problems ofdealing with time series.
They do not directlyaddress paradigmatic data such as lexicons anddemographic tables.
One should note however,that time series data and paradigmatic data canbe united efficiently.
As already mentioned,annotation graphs may be stored trivially inrelational tables, technology routinely  used forparadigmatic data.
In this way, conventional?joins?
of relational table can convolve time-series annotations with paradigms (e.g.
textswith dictionaries or utterances with speakerdemographics).Through judicious compromises - such asone-time computer-assisted conversion oflegacy annotation data and creating once-offinterfaces to existing useful tools - and throughthe judicious combination of simple and well-supported formalisms and technologies asdescribed above, we believe that themanagement problems can be substantiallyreduced in scale and severity.We can illustrate the advantages of AG witha example of the annotation of the Switchboardcorpus for ?t/d deletion.
Switchboard containstwo-channel audio of thousands of 5-minuteconversations among pairs of speakers that havebeen transcribed with the transcripts time-aligned to the audio.
A single utterance iswritten:274.35 279.50 A.119 Uh, he,uh, carves out different figuresin the, in the plants,giving the start and stop time of the utterance,channel, speaker ID and the transcript of theutterance.
This can be converted trivially intoAG format as above.Figure 5:  Interactions among annotation toolsand the annotation serverThe DASL tool concordances audiotranscripts and identifies utterances in which thetarget phenomenon (eg.
?t/d deletion) mayoccur.
A line of the concordance file containstwo IDs one to identify the utterance within theconcordance, the other to link back to theoriginal corpus.
The <annotate> tags identify apotential environment for the phenomenonunder study.<sample id="1" senid="10194">uhhe uh carves out <annotate>different figures </annotate> inthe in the p[lants]- plantsshrubs </sample>The link between the concordance and theoriginal corpus is maintained through a tablecontaining: Sentence_ID, File_ID, Start_Time,Stop_Time, Channel and Speaker.10194 2141 274.35  279.50 A 1139Speakers?
demographic data appears inanother table containing: Speaker_ID, Sex, Age,Region, Education_Level1139, MALE, 50, NORTHERN, 2The DASL interface embeds the concordanceresults in a template containing input fields foreach parameter to be annotated (see Figure 2).The linguist?s annotation of the utterance can bestored in AG formalism as in Figure 5.
Note thatalthough AGs provide an elegant and generalsolution to the annotation of time series data,they do not remove the need to deal with the adhoc formats one may encounter in variouscorpora.
Nor do they remove the need to trackthe relations among elements in time-series dataand paradigmatic material.6 ConclusionsResearchers in human language shareassumptions and needs within and acrossresearch communities.
Each group feels an acuteneed for language resources including data,annotations, formats and processes.
This paperhas summarized some common needs anddescribed an architecture for encodingannotations and delivering them via annotationservers using SQL or a custom query language.Much of the architecture discussed has alreadybeen created and is available in the AnnotationGraphic Toolkit.
Other components, especiallythe query language, are currently underdevelopment.
It is hoped that tools based onannotations graphs and annotation servers willencourage greater levels of resource sharing andthe coordination of future resource development.Figure 5: A sociolinguistic annotation in AG format<?xml version="1.0"?><!DOCTYPE AGSet SYSTEM "http://www.ldc.upenn.edu/AG/doc/xml/ag.dtd"><AGSet id="DASL" version="1.0"xmlns="http://www.ldc.upenn.edu/atlas/ag/" xmlns:xlink="http://www.w3.org/1999/xlink"xmlns:dc="http://purl.org/DC/documents/rec-dces-19990702.htm"><Metadata></Metadata><Timeline id="DASL:Timeline1"> <Signal id="DASL:Timeline1:Signal1" mimeClass="audio"mimeType="wav" encoding="mu-law" unit="8kHz" xlink:type="simple"xlink:href="LDC93S7:sw2141.wav"></Signal></Timeline><AG id="DASL:AG1" timeline="DASL:Timeline1"><Anchor id="DASL:AG1:Anchor1" offset="274.595" signals="DASL:Timeline1:Signal1"></Anchor><Anchor id="DASL:AG1:Anchor2" offset="280.671" signals="DASL:Timeline1:Signal1"></Anchor><Annotation id="DASL:AG1:Annotation1" type="csv" start="DASL:AG1:Anchor1"end="DASL:AG1:Anchor2"><Feature name="td">Deleted</Feature> <Feature name="Morphological">Monomorpheme</Feature><Feature name="EPreceding">AlveolarNasal</Feature> <Feature name="EFollowing">Obstruent</Feature><Feature name="Same_Prec_Foll">N/A</Feature>  <Feature name="Stress">Unstressed</Feature><Feature name="Cluster_complexity">Two_elements</Feature><Feature name="Sentence_id">1</Feature> <Feature name="Corpus_name">swb</Feature><Feature name="WPreceding">uh he uh carves out </Feature><Feature name="WMatched">different figures</Feature><Feature name="WFollowing"> in the in the p[lants]- plants shrubs</Feature><Feature name="File_name">/speech/swb0/sw2141.wav</Feature><Feature name="Speech_channel">1</Feature> <Feature name="Speaker_id">1139</Feature><Feature name="Sex">MALE</Feature>   <Feature name="Birth_year">1956</Feature><Feature name="Dialect">NORTHERN</Feature> <Feature name="Edu">2</Feature></Annotation></AG></AGSet>ReferencesJames Allan, et.
al., (1999) Topic Based NoveltyDetection 1999 Summer Workshop at CLSP FinalReport, http://www.clsp.jhu.edu/ws99/final/Topic-based.pdfSteven Bird & Mark Liberman (2001) A FormalFramework for Linguistic Annotation, SpeechCommunication 33(1,2) pp 23-60,http://arxiv.org/abs/cs/0010033Steven Bird, Peter Buneman & Wang-Chiew Tan(2000) Towards a query language for annotationgraphs, Proceedings of the Second InternationalConference on Language Resources andEvaluation, pp.
807-814.Steve Cassidy & Steven Bird (2000) Queryingdatabases of annotated speech, Proceedings of theEleventh Australasian Database Conference,http://www.ldc.upenn.edu/Papers/ADC2000/adc00.pdfCenter for Language and Speech Processing  (2000)Summer Workshop Pages,http://www.clsp.jhu.edu/workshops/.Chalapati, Neti, et.
al.
(2000) Audio Visual SpeechRecognition, Summer Workshop at CLSP FinalReport,http://www.clsp.jhu.edu/workshops/ws2000/final_reports/avsr/.Lea Christiansen, Christopher Cieri, Kathleen Egan,Anita Kulman, Milton Paul (2001) GettingSMART about Authoring, Presented at CALICO2001: Computer Aided Language InstructionConference, Orlando, University of CentralFlorida.Christopher Cieri and Stephanie Strassel (2001)DASL Project Pages,http://www.ldc.upenn.edu/Projects/DASL.Deckert & Yaeger-Dror (2000) Dialect variation innegation strategies in the LDC Switchboardcorpus Corpus Linguistics Conference 2, Boston 2,pp.
49-59.Garofalo, John, Cedric Auzanne and Ellen Voorhees(2000) The TREC Spoken Document RetrievalTrack: A Success Story,http://www.nist.gov/speech/tests/sdr/sdr2000/papers/01plenary1.pdfGarofalo, John S., Lori F. Lamel, William M. Fisher,Jonathan G. Fiscus, David S. Pallett, and Nancy L.Dahlgren, "The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus CDROM"(printed documentation; available on request fromthe LDC).David Graff, Steven Bird (2000) Many uses, manyannotations for large speech corpora, Proceedingsof the Second 2nd Language Resources andEvaluation Conference, Athens, Greece, pp.
427-433.http://www.ldc.upenn.edu/Papers/LREC2000/multiuse.pdf.Kazuaki Maeda and Steven Bird (2000) A FormalFramework for Interlinear Text, Web-BasedLanguage Documentation and DescriptionWorkshop, University of Pennsylvania,Philadelphia, December 2000http;//www.ldc.upenn.edu/exploration/expl2000/.Kazuaki Maeda and Steven Bird (2001), AnnotationTools Based on the Annotation Graph API,Proceedings of this workshop.Meng, Helen, et.
al., (2000) Mandarin EnglishInformation (MEI) : Investigation TranslingualSpeech Retrieval, 1999 Summer Workshop atCLSP Final Reporthttp://www.clsp.jhu.edu/ws2000/final_reports/mei/ws00mei.pdfDavid Miller and Kevin Walker (2001) TelephoneSpeech in the Foreign Language Classroom:Applications Methods and Technology, Presentedat CALICO 2001: Computer Aided LanguageInstruction Conference, Orlando, University ofCentral Florida.Przybocki, Mark (2000) Automatic ContentExtraction Web Page,http://www.nist.gov/speech/tests/ace/
