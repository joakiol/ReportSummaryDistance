Role of Verbs in Document AnalysisJ ud i th  K lavans*  and Min -Yen  Kan**Center for Research on Information Access* and Department of Computer Science**Columbia UniversityNew York, NY 10027, USAAbst rac tWe present results of two methods for assessingthe event profile of news articles as a functionof verb type.
The unique contribution of thisresearch is the focus on the role of verbs, ratherthan nouns.
Two algorithms are presented andevaluated, one of which is shown to accuratelydiscriminate documents by type and semanticproperties, i.e.
the event profile.
The initialmethod, using WordNet (Miller et al 1990),produced multiple cross-classification f arti-cles, primarily due to the bushy nature of theverb tree coupled with the sense disambiguationproblem.
Our second approach using EnglishVerb Classes and Alternations (EVCA) Levin(1993) showed that monosemous categorizationof the frequent verbs in WSJ made it possible tousefully discriminate documents.
For example,our results how that articles in which commu-nication verbs predominate nd to be opinionpieces, whereas articles with a high percentageof agreement verbs tend to be about mergers orlegal cases.
An evaluation is performed on theresults using Kendall's ~-.
We present convinc-ing evidence for using verb semantic lasses asa discriminant in document classification.
11 Mot ivat ionWe present techniques tocharacterize documenttype and event by using semantic lassificationof verbs.
The intuition motivating our researchis illustrated by an examination of the role of1The authors acknowledge earlier implementations byJames Shaw, and very valuable discussion from VasileiosHatzivassiloglou, Kathleen McKeown and Nina Wa-cholder.
Partial funding for this project was providedby NSF award #IRI-9618797 STIMULATE: GeneratingCoherent Summaries of On-Line Documents: CombiningStatistical and Symbolic Techniques (co-PI's McKeownand Klavans), and by the Columbia University Centerfor Research on Information Access.680nouns and verbs in documents.
The listing be-low shows the ontological categories which ex-press the fundamental conceptual componentsof propositions, using the framework of Jack-endoff (1983).
Each category permits the for-mation of a wh-question, e.g.
for \[THING\] "whatdid you buy?"
can be answered by the noun"a fish".
The wh-questions for \[ACTION\] and\[EVENT\] can only be answered by verbal con-structions, e.g.
in the question "what did youdo?
", where the response must be a verb, e.g.jog, write, fall, etc.\[TH,NG\] \[DmECT,ON\] \[ACTION\]\[eLAtE\] \[MANNER\] \[EVENT\]\[AMO,NT\]The distinction in the ontological categoriesof nouns and verbs is reflected in information ex-traction systems.
For example, given the nounphrases fares and US Air that occur within aparticular article, the reader will know what thestory is about, i.e.
fares and US Air.
However,the reader will not know the \[EVENT\], i.e.
whathappened to the fares or to US Air.
Did airfareprices rise, fall or stabilize?
These are the verbsmost typically applicable to prices, and whichembody the event.1.1 Focus on the NounMany natural anguage analysis ystems focuson nouns and noun phrases in order to identifyinformation on who, what, and where.
For ex-ample, in summarization, Barzilay and Elhadad(1997) and Lin and Hovy (1997) focus on multi-word noun phrases.
For information extractiontasks, such as the DARPA-sponsored MessageUnderstanding Conferences (1992), only a fewprojects use verb phrases (events), e.g.
Ap-pelt et al (1993), Lin (1993).
In contrast, thenamed entity task, which identifies nouns andnoun phrases, has generated numerous projectsas evidenced by a host of papers in recent con-ferences, (e.g.
Wacholder et al 1997, Palmerand Day 1997, Neumann et al 1997).
Althoughrich information on nominal participants, ac-tors, and other entities is provided, the namedentity task provides no information on whathappened in the document, i.e.
the event  oract ion.
Less progress has been made on waysto utilize verbal information efficiently.
In ear-lier systems with stemming, many of the verbaland nominal forms were conflated, sometimeserroneously.
With the development of more so-phisticated tools, such as part of speech taggers,more accurate verb phrase identification is pos-sible.
We present in this paper an effective wayto utilize verbal information for document ypediscrimination.1.2 Focus on the  VerbOur initial observations suggested that both oc-currence and distribution of verbs in news arti-cles provide meaningful insights into both ar-ticle type and content.
Exploratory analysisof parsed Wall Street Journal data 2 suggestedthat articles characterized by movement verbssuch as drop, plunge, or fall have a differentevent profile from articles with a high percent-age of communication verbs, such as report, say,comment, or complain.
However, without asso-ciated nominal arguments, it is impossible toknow whether the \[THING\] that drops refers toairfare prices or projected earnings.In this paper, we assume that the set of verbsin a document, when considered as a whole, canbe viewed as part of the conceptual map of theevents and action in a document, in the sameway that the set of nouns has been used as aconcept map for entities.
This paper reports ontwo methods using verbs to determine an eventprofile of the document, while also reliably cat-egorizing documents by type.
Intuitively, theevent profile refers to the classification of an ar-ticle by the kind of event.
For example, thearticle could be a discussion event, a reportingevent, or an argument event.To illustrate, consider a sample article fromWSJ of average length (12 sentences in length)with a high percentage of communication verbs.The profile of the article shows that there are19 verbs: 11 (57%) are communication verbs,including add, report, say, and tell.
Other2Penn TreeBank (Marcus et al 1994) from the Lin-guistic Data Consortium.681verbs include be skeptical, carry, produce, andclose.
Representative nouns include PolaroidCorp., Michael Ellmann, Wertheim SchroderCo., Prudential-Bache, savings, operating "re-sults, gain, revenue, cuts, profit, loss, sales, an-alyst, and spokesman.In this case, the verbs clearly contribute in-formation that this article is a report withmore opinions than new facts.
The prepon-derance of communication verbs, coupled withproper noun subjects and human nouns (e.g.spokesman, analyst) suggest a discussion arti-cle.
If verbs are ignored, this fact would beoverlooked.
Matches on frequent nouns like gainand loss do not discriminate this article fromone which announces a gain or loss as breakingnews; indeed, according to our results, a break-ing news article would feature a higher percent-age of motion verbs rather than verbs of com-munication.1.3 On Genre  Detect ionVerbs are an important factor in providing anevent profile, which in turn might be used in cat-egorizing articles into different genres.
Turningto the literature in genre classification, Biber(1989) outlines five dimensions which can beused to characterize genre.
Properties for dis-tinguishing dimensions include verbal featuressuch as tense, agentless passives and infinitives.Biber also refers to three verb classes: private,public, and suasive verbs.
Karlgren and Cut-ting (1994) take a computationally tractable setof these properties and use them to compute ascore to recognize text genre using discriminantanalysis.
The only verbal feature used in theirstudy is present-tense verb count.
As Karlgrenand Cutting show, their techniques are effectivein genre categorization, but they do not claimto show how genres differ.
Kessler et al (1997)discuss some of the complexities in automaticdetection of genre using a set of computation-ally efficient cues, such as punctuation, abbrevi-ations, or presence of Latinate suffixes.
The tax-onomy of genres and facets developed in Kessleret al is useful for a wide range of types, suchas found in the Brown corpus.
Although someof their discriminators could be useful for newsarticles (e.g.
presence of second person pronountends to indicate a letter to the editor), the in-dicators do not appear to be directly applicableto a finer classification of news articles.News articles can be divided into several stan-dard categories typically addressed in journal-ism textbooks.
We base our article categoryontology, shown in lowercase, on Hill and Breen(1977), in uppercase:1.
FEATURE STORIES  : feature;2.
INTERPRET IVE  STORIES:  editorial ,  opinion, report;3.
PROFILES;4.
PRESS RELEASES:  announcements, mergers, legal cases;5.
OB ITUARIES;6.
STAT IST ICAL  INTERPRETAT ION:  posted earnings;7.
ANECDOTES;8.
OTHER:  poems.The goal of our research is to identify therole of verbs, keeping in mind that event profileis but one of many factors in determining texttype.
In our study, we explored the contribu-tion of verbs as one factor in document type dis-crimination; we show how article types can besuccessfully classified within the news domainusing verb semantic classes.2 Initial Observat ionsWe initially considered two specific categories ofverbs in the corpus: communication verbs andsupport verbs.
In the WSJ  corpus, the two mostcommon main verbs are say, a communicationverb, and be, a support verb.
In addition tosay, other high frequency communication verbsinclude report, announce, and state.
In journal-istic prose, as seen by the statistics in Table 1,at least 20% of the sentences contain commu-nication verbs such as say and announce; thesesentences report point of view or indicate anattributed comment.
In these cases, the subor-dinated complement represents the main event,e.g.
in "Advisors announced that IBM stockrose 36 points over a three year period," thereare two actions: announce and rise.
In sen-tences with a communication verb as main verbwe considered both the main and the subor-dinate verb; this decision augmented our verbcount an additional 20% and, even more im-portantly, further captured information on theactual event in an article, not just the commu-nication event.
As shown in Table 1, supportverbs, such as go ("go out of business") or get("get alng"), constitute 30%, and other con-tent verbs, such as fall, adapt, recognize, or vow,make up the remaining 50%.
If we exclude allsupport type verbs, 70% of the verbs yield in-formation in answering the question "what hap-pened?"
or "what did X do?
"3 Event  P ro f i le :  WordNet  and  EVCASince our first intuition of the data suggestedthat articles with a preponderance of verbs of682Verb Type Sample Verbs %communication say, announce .... 20%support  have, get, go, ... 30%remainder abuse, claim, offer, ... 50%Table 1: Approximate Frequency of verbs bytype from the Wall Street Journal (main andselected subordinate verbs, n = 10,295).a certain semantic type might reveal aspects ofdocument ype, we tested the hypothesis thatverbs could be used as a predictor in provid-ing an event profile.
We developed two algo-rithms to: (1) explore WordNet (WN-Verber)to cluster related verbs and build a set of verbchains in a document, much as Morris and Hirst(1991) used Roget's Thesaurus or like Hirst andSt.
Onge (1998) used WordNet to build nounchains; (2) classify verbs according to a se-mantic classification system, in this case, us-ing Levin's (1993) English Verb Classes andAlternations (EVCA-Yerber) as a basis.
Forsource material, we used the manually-parsedLinguistic Data Consortium's Wall Street Jour-nal (WSJ) corpus from which we extracted mainand complement of communication verbs to testthe algorithms on.Us ing WordNet .
Our first technique wasto use WordNet to build links between verbsand to provide a semantic profile of the docu-ment.
WordNet is a general exical resource inwhich words are organized into synonym sets,each representing one underlying lexical concept(Miller et al 1990).
These synonym sets - orsynsets - are connected by different semanticrelationships uch as hypernymy (i.e.
plungingis a way of descending), synonymy, antonymy,and others (see Fellbaum 1990).
The determina-tion of relatedness via taxonomic relations has arich history (see Resnik 1993 for a review).
Thepremise is that words with similar meanings willbe located relatively close to each other in thehierarchy.
Figure 1 shows the verbs cite andpost, which are related via a common ancestorinform, .
.
.
,  let know.The WN-Verber tool .
We used the hypernymrelationship in WordNet because of its high cov-erage.
We counted the number of edges neededto find a common ancestor for a pair of verbs.Given the hierarchical structure of WordNet,the lower the edge count, in principle, the closerthe verbs are semantically.
Because WordNetcommon ancestorinform ..... let knowt e s t i f Y ~ ~ o u ~ c ~  ....abduct ..... cite attest .
.
.
.
report post soundFigure 1: Taxonomic Relations for cite and postin WordNet.allows individual words (via synsets) to be thedescendent of possibly more than one ances-tor, two words can often be related by morethan one common ancestor via different paths,possibly with the same relationship (grandpar-ent and grandparent, or with different relations(grandparent and uncle).Resu l ts  f rom WN-Verber.
We ran all arti-cles longer than 10 sentences in the WSJ cor-pus (1236 articles) through WN-Verber.
Outputshowed that several verbs - e.g.
go, take, andsay - participate in a very large percentage ofthe high frequency synsets (approximate 30%).This is due to the width of the verb forest inWordNet (see Fellbaum 1990); top level verbsynsets tend to have a large number of descen-dants which are arranged in fewer generations,resulting in a flat and bushy tree structure.
Forexample, a top level verb synset, inform, .
.
.
,give information, let know has over 40 children,whereas a similar top level noun synset, entity,only has 15 children.
As a result, using fewerthan two levels resulted in groupings that weretoo limited to aggregate verbs effectively.
Thus,for our system, we allowed up to two edges to in-tervene between a common ancestor synset andeach of the verbs' respective synsets, as in Fig-ure 2.acceptab le ?
\] i ?
unacceptable?2 a 2 0 ?2  vl  ?
1 14 ?
?
?
3  v~ v~ ?
?
v li v l  v2 ?
?
v2 ?
v2 ?Figure 2: Configurations for relating verbs inour system.In addition to the problem of the flat na-ture of the verb hierarchy, our results fromWN-Verber are degraded by ambiguity; similareffects have been reported for nouns.
Verbs withdifferences in high versus low frequency sensescaused certain verbs to be incorrectly related;683for example, have and drop are related by thesynset meaning "to give birth" although thissense of drop is rare in WSJ.The results of NN-Verber in Table 2 reflectthe effects of bushiness and ambiguity.
The fivemost frequent synsets are given in column 1; col-umn 2 shows some typical verbs which partici-pate in the clustering; column 3 shows the typeof article which tends to contain these synsets.Most articles (864/1236 = 70%) end up in thetop five nodes.
This illustrates the ineffective-ness of these most frequent WordNet synset todiscriminate between article types.Synset Sample Art icle typesVerbs (listed in order)in SynsetAct  have, relate, announcements, editori-(interact, act to- give, tell als, featuresgether, ...)Communicate  give, get, in- announcements, editori-(communicate, form, tell als, features, poemsi n tercommunicate ,.
.
.
)Change have, modify, poems, editorials, an-(change) take nouncements, featuresAlter convert, announcements, poems,(alter, change) make, get editorialsI n fo rm inform, ex- announcements, poems,(inform, round on, plain, de- features...) scribeTable 2: Frequent synsets and article types.Evaluat ion using Kenda l l ' s  Tau.
Wesought independent confirmation to assess thecorrelation between two variables' rank forWN-Verber results.
To evaluate the effects ofone synset's frequency on another, we usedKendall's tau (r) rank order statistic (Kendall1970).
For example, was it the case that verbsunder the synset act tend not to occur withverbs under the synset think?
If so, do ar-ticles with this property fit a particular pro-file?
In our results, we have information aboutsynset frequency, where each of the 1236 arti-cles in the corpus constitutes a sample.
Ta-ble 3 shows the results of calculating Kendall'sr with considerations for ranking ties, for all(10) = 45 pairing combinations of the top 10most frequently occurring synsets.
Correlationscan range from -1 .0  reflecting inverse correla-tion, to +1.0 showing direct correlation, i.e.
thepresence of one class increases as the presenceof the correlated verb class increases.
A T valueof 0 would show that the two variables' valuesare independent of each other.Results show a significant positive correlationbetween the synsets.
The range of correlationis from .850 between the communicat ion  verbsynset (give, get, inform, ...) and the act verbsynset (have, relate, give, ...) to .238 betweenthe th ink  verb synset (plan, study, give, ...) andthe change s ta te  verb synset (fall, come, close,.
.
. )
.These correlations show that frequent synsetsdo not behave independently of each other andthus confirm that the WordNet results are notan effective way to achieve document discrim-ination.
Although the WordNet results werenot discriminatory, we were still convinced thatour initial hypothesis on the role of verbs indetermining event profile was worth pursuing.We believe that these results are a by-productof lexical ambiguity and of the richness of theWordNet hierarchy.
We thus decided to pur-sue a new approach to test our hypothesis, onewhich turned out to provide us with clearer andmore robust results.act com chng alter infm exps thnk I judg I t rnf~tate .407 .296 .672 .461 .286 .269 .238 I .355 .268;rnsf .437 .436 .251 .436 .251 .404 .369 .359iudge .444 .414 .435 .450 .340 .348 .427.~xprs .444 .414 .435 .397 .322 .432;hink .444 .414 .435 .397 .398~nfrm .614 ,649 .341 .380~lter .501 .454 .619Table 3: Kendall's T for frequent WordNetsynsets.Ut i l i z ing EVCA.
A different approach totest the hypothesis was to use another semanticcategorization method; we chose the semanticclasses of Levin's EVCA as a basis for our nextanalysis.
3 Levin's seminal work is based on thetime-honored observation that verbs which par-ticipate in similar syntactic alternations tend toshare semantic properties.
Thus, the behaviorof a verb with respect o the expression and in-terpretation of its arguments can be said to be,in large part, determined by its meaning.
Levinhas meticulously set out a list of syntactic tests(about 100 in all), which predict membership nno less than 48 classes, each of which is dividedinto numerous ub-classes.
The rigor and thor-oughness of Levin's study permitted us to en-code our algorithm, EVCA-Verber, on a sub-set3Strictly speaking, our classification is based onEVCA.
Although many of our classes are precisely de-fined in terms of EVCA tests, we did impose some x-tensions.
For example, support verbs are not an EVCAcategory.of the EVCA classes, ones which were frequentin our corpus.
First, we manually categorizedthe 100 most frequent verbs, as well as 50 addi-tional verbs, which covers 56% of the verbs bytoken in the corpus.
We subjected each verb toa set of strict linguistic tests, as shown in Ta-ble 4 and verified primary verb usage againstthe corpus.Verb  C lass(sample verbs)Communicat ion(add, say, an-nounce,  .
.
.
)Mot ion(rise, fall, decl ine,.
.
.
)Agreement(agree, accept,  con-cur, .
.
.
)Argument(argue, debate,  ,.
.
.
)Causat ive(cause)Sample  Test(1) Does this involve a transfer of ideas?
(2) X verbed "someth ing .
"(1) * "X  verbed w i thout  moving" .
(1) "They  verbed to jo in forces.
"(2) involves more than one part ic ipant .
(1) "They  verbed (over)  the  issue.
"(2) indicates conf l ict ing views.
(3) involves more than one part ic ipant .
(1) X verbed Y ( to  happen/happened) .
(2) X br ings  about  a change in Y.Table 4: EVCA verb class testResu l ts  f rom EVCA-Verber.
In order to beable to compare article types and emphasizetheir differences, we selected articles that hadthe highest percentage of a particular verb classfrom each of the ten verb classes; we chose fivearticles from each EVCA class, yielding a to-tal of 50 articles for analysis from the full setof 1236 articles.
We observed that each classdiscriminated between different article types asshown in Table 5.
In contrast to Table 2, the ar-ticle types are well discriminated by verb class.For example, a concentration of communica -t ion class verbs (say, report, announce, ... ) in-dicated that the article type was a general an-nouncement of short or medium length, or alonger feature article with many opinions in thetext.
Articles high in mot ion  verbs were alsoannouncements, but differed from the commu-nication ones, in that they were commonly post-ings of company earnings reaching a new highor dropping from last quarter.
Agreement  andargument  verbs appeared in many of the samearticles, involving issues of some controversy.However, we noted that articles with agreementverbs were a superset of the argument ones inthat, in our corpus, argument verbs did not ap-pear in articles concerning joint ventures andmergers.
Articles marked by causat ive  classverbs tended to be a bit longer, possibly re-flecting prose on both the cause and effect of684a particular action.
We also used EVCA-Verberto investigate articles marked by the absence ofmembers of each verb class, such as articles lack-ing any verbs in the motion verb class.
However,we found that absence of a verb class was notdiscriminatory.Verb  C lass(sample verbs)Communicat ion(add, say, announce,  ...)Mot ion(rise, fall, decline, ...)Agreement(agree, accept, concur,...)Argument(argue, indicate, contend,.,.
)Causative(cause)Art i c le  types(l isted by frequency)issues, reports, opinions, editorialsposted earnings, announcementsmergers, legal cases, transactions(without buying and sell ing)legal cases, opinionsopinions, feature, editorialsTable 5: EVCA-based verb class results.Eva luat ion  of  EVCA verb  classes.
Tostrengthen the observations that articles domi-nated by verbs of one class reflect distinct arti-cle types, we verified that the verb classes be-haved independently ofeach other.
Correlationsfor EVCA classes are shown in Table 6.
Theseshow a markedly lower level of correlation be-tween verb classes than the results for WordNetsynsets, the range being from .265 between mo-tion and aspectual verbs to - .026 for motionverbs and agreement verbs.
These low valuesof T for pairs of verb classes reflects the inde-pendence of the classes.
For example, the com-mun icat ion  and exper ience  verb classes areweakly correlated; this, we surmise, may be dueto the different ways opinions can be expressed,i.e.
as factual quotes using communicat ionclass verbs or as beliefs using exper ience  classverbs.comun motion agree argue exp I aspect~ causeappear .122 .076 .077 .072 .182 \[ .112 J .037cause .093 .083 .000 .000 .073 .096aspect .246 .265 .034 .110 .189exp .260 .130 .054 .054argue .162 .045 .033argree .071 -.026Table 6: Kendall's r for EVCA based verbclasses.4 Resu l ts  and  Future  Work .Bas is  for WordNet  and EVCA compar i -son.
This paper reports results from two ap-proaches, one using WordNet and other based685on EVCA classes.
However, the basis for com-parison must be made explicit.
In the caseof WordNet, all verb tokens (n = 10K) wereconsidered in all senses, whereas in the case ofEVCA, a subset of less ambiguous verbs weremanually selected.
As reported above, we cov-ered 56% of the verbs by token.
Indeed, whenwe attempted to add more verbs to EVCA cat-egories, at the 59% mark we reached a point ofdifficulty in adding new verbs due to ambigu-ity, e.g.
verbs such as get.
Thus, although ourresults using EVCA are revealing in importantways, it must be emphasized that the compar-ison has some imbalance which puts WordNetin an unnaturally negative light.
In order to ac-curately compare the two approaches, we wouldneed to process either the same less ambiguousverb subset with WordNet, or the full set of allverbs in all senses with EVCA.
Although the re-sults reported in this paper permitted the vali-dation of our hypothesis, unless a fair compari-son between resources i  performed, conclusionsabout WordNet as a resource versus EVCA classdistinctions hould not be inferred.Verb Pat terns .
In addition to consideringverb type frequencies in texts, we have observedthat verb distribution and patterns might alsoreveal subtle information in text.
Verb class dis-tribution within the document and within par-ticular sub-sections also carry meaning.
For ex-ample, we have observed that when sentenceswith movement verbs such as rise or fall are fol-lowed by sentences with cause and then a telicaspectual verb such as reach, this indicates thata value rose to a certain point due to the actionsof some entity.
Identification of such sequenceswill enable us to assign functions to particularsections of contiguous text in an article, in muchthe same way that text segmentation programseeks identify topics from distributional vocab-ulary (Hearst, 1994; Kan et al, 1998).
We canalso use specific sequences of verbs to help indetermining methods for performing semanticaggregation of individual clauses in text gener-ation for summarization.Future  Work .
Our plans are to extend thecurrent research in terms of verb coverage andin terms of article coverage.
For verbs, we planto (1) increase the verbs that we cover to includephrasal verbs; (2) increase coverage of verbsby categorizing additional high frequency verbsinto EVCA classes; (3) examine the effects ofincreased coverage on determining article type.For articles, we plan to explore a general parserso we can test our hypothesis on additional textsand examine how our conclusions scale up.
Fi-nally, we would like to combine our techniqueswith other indicators to form a more robust sys-tem, such as that envisioned in Biber (1989) orsuggested in Kessler et al (1997).Conclus ion.
We have outlined a novel ap-proach to document analysis for news articleswhich permits discrimination of the event pro-file of news articles.
The goal of this research isto determine the role of verbs in document anal-ysis, keeping in mind that event profile is one ofmany factors in determining text type.
Our re-sults show that Levin's EVCA verb classes pro-vide reliable indicators of article type within thenews domain.
We have applied the algorithm toWSJ data and have discriminated articles withfive EVCA semantic lasses into categories suchas features, opinions, and announcements.
Thisapproach to document type classification usingverbs has not been explored previously in theliterature.
Our results on verb analysis coupledwith what is already known about NP identi-fication convinces us that future combinationsof information will be even more successful incategorization of documents.
Results such asthese are useful in applications such as passageretrieval, summarization, and information ex-traction.Re ferencesD.
Appelt, J. Hobbs, J.
Bear, D. Isreal, and M. Tyson.1993.
Fastus: A finite state processor for informationextraction from real world text.
In Proceedings of the13th International Joint Conference on Artificial In-telligence (LICAI), Chambery, l~rance.Regina Barzilay and Michael Elhadad.
1997.
Using lex-ical chains for text summarization.
In Proceedingsof the Intelligent Scalable Text Summarization Work-shop (ISTS'97), ACL, Madrid, Spain.Douglas Biber.
1989.
A typology of english texts.
Lan-guage, 27:3-43.Christiane Fellbaum.
1990.
English verbs as a semanticnet.
International Journal of Lexicography, 3(4):278-301.Maarti A. Hearst.
1994.
Multi-paragraph segmentationof expository text.
In Proceedings of the 32th AnnualMeeting of the Association of Computational Linguis-tics.Evan Hill and John J. Breen.
1977.
Reporting ~ Writ-ing the News.
Little, Brown and Company, Boston,Massachusetts.Graeme Hirst and David St-Onge.
1998.
Lexical chainsas representations of context for the detection and cor-686rection of malapropisms.
WordNet: An electronic lex-ical database and some of its applications.Ray Jackendoff.
1983.
Semantics and Cognition.
MITUniversity Press, Cambridge, Massachusetts.Min-Yen Kan, Judith L. Klavans, and Kathleen R. McK-eown.
1998.
Linear segmentation and segment rele-vance.
Unpublished Manuscript.Jussi Karlgren and Douglass Cutting.
1994.
Recogniz-ing text genres with simple metrics using discrimi-nant analysis.
In Fifteenth International Conferenceon Computational Linguistics (COLING '9~), Kyoto,Japan.Maurice G. Kendall.
1970.
Rank Correlation Methods.Griffin, London, England, 4th edition.Brent Kessler, Geoffrey Nunberg, and Hinrich Schiitze.1997.
Automatic detection of text genre.
In Proceed-ings of the 35th Annual Meeting of the Association ofComputational Linguistics, Madrid, Spain.Beth Levin.
1993.
English Verb Classes and Alterna-tions.
University of Chicago Press, Chicago, Ohio.Chin-Yew Lin and Eduard Hovy.
1997.
Identifying top-ics by position.
In Proceedings of the 5th A CL Confer-ence on Applied Natural Language Processing, pages283-290, Washington, D.C., April.Dekang Lin.
1993.
University of Manitoba: Descrip-tion of the NUBA System as Used for MUC-5.
InProceedings of the Fifth Conference on Message Un-derstanding MUC-5, pages 263-275, Baltimore, Mary-land.
ARPA.Mitch Marcus et al 1994.
The Penn Treebank: Anno-tating Predicate Argument Structure.
ARPA HumanLanguage Technology Workshop.George A. Miller, Richard Beckwith, Christiane Fell-baum, Derek Gross, and Katherine J. Miller.1990.
Introduction to WordNet: An on-line lexicaldatabase.
International Journal of Lexicography (spe-cial issue), 3(4):235-312.Jane Morris and Graeme Hirst.
1991.
Lexical coher-ence computed by thesaural relations as an indicatorof the structure of text.
Computational Linguistics,17(1):21-42.1992.
Message Understanding Conference -- MUC.Giinter Neumann, Rolf Backofen, Judith Baur, MarcusBecker, and Christian Braun.
1997.
An informationextraction core system for real world german text pro-cessing.
In Proceedings of the 5th A CL Conference onApplied Natural Language Processing, pages 209-216,Washington, D.C., April.David D. Palmer and David S. Day.
1997.
A statisticalprofile of the named entity task.
In Proceedings ofthe 5th A CL Conference on Applied Natural LanguageProcessing, pages 190-193, Washington, D.C., April.Philip Resnik.
1993.
Selection and Information: AClass-Based Approach to Lexical Relationships.
Ph.D.thesis, Department of Computer and Information Sci-ence, University of Pennsylvania.Nina Wacholder, Yael Ravin, and Misook Choi.
1997.Disambiguation of proper names in text.
In Proceed-ings of the 5th ACL Conference on Applied NaturalLanguage Processing, volume 1, pages 202-209, Wash-ington, D.C., April.
