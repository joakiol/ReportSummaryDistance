The Use  of  Lex ica l  Semant ics  in In fo rmat ion  Ext ract ion  *Joyce Yue Chai Alan W. BiermannDepartment ofComputer ScienceBox 90129, Duke UniversityDurham, NC 27708-0129chai@cs.duke.edu awb~cs.duke.eduAbstractThis paper presents a method for en-abling users to specialize an informationextraction system to satisfy their particularneeds.
The method allows the user to man-ually demonstrate the creation of seman-tic nodes and transitions while scanning asample text article using a graphical userinterface.
On the basis of such examples,the system creates rules that translate textto semantic nets; then it generalizes theserules so that they can apply to a broad classof text instead of only the training articles.Finally, the generalized rules are used toscan large numbers of articles to extractthe particular information targeted by theuser.
This paper concentrates on our de-sign of the generalization mechanism whichself modifies to precisely match the user'sspecification.1 IntroductionCustomizing information extraction systems acrossdifferent domains has become an important is-sue in Natural Language Processing.
Many re-search groups are making progress toward efficientcustomization, such as BBN (Weischedel, 1995),NYU (Grishman, 1995), SRI (Appelt et al, 1995),SRA (Krupka, 1995), MITRE (Aberdeen et al,1995), UMass (Fisher et al, 1995)...etc.
SRIdeveloped a specification language called FAST-SPEC that automatically translates regular produc-tions written by the developer into finite state ma-chines (Appelt et al, 1995).
FASTSPEC makes thecustomization easier by avoiding the effort in enu-merating all the possible ways of expressing the tar-get information.
The HASTEN system developed at~This work has been supported by a Fellowship fromIBM Corporation.SRA (Krupka, 1995) employs agraphical user inter-face that allows the user to create patterns by iden-tifying the important concepts in the text, as wellas the relationships between the concepts.
Then theconcepts are manually generalized to word classesbefore the patterns are applied to other texts fromthe domain.We have built a trainable information extractionsystem that enables any user  to adapt he system todifferent applications.
The trainability of the systemprovides users the ability to identify the patterns forthe information of interest.
The training process issimilar to the HASTEN system.
However, insteadof manual generalization asin HASTEN, our systemautomatically generalizes patterns by use of Word-Net hierarchies.
Automatic generalization of rulesmakes the customization process an easier one.This paper describes the automated rule general-ization method and the usage of WordNet (Miller,1990) in our system.
First, it introduces the ideaof generalization; then it describes our Generaliza-tion Tree (GT) model based on the WordNet andillustrates how GT controls the degree of generaliza-tion according to the user's needs.
Finally it demon-strates ome preliminary results from the experimentof applying GT in our trainable information extrac-tion system.2 Lexical AcquisitionOne way to achieve lexical acquisition is to use theexisting repositories of lexical knowledge, such asknowledge base, dictionaries and thesauruses.
Thekey issue is whether those repositories can be effec-tively applied for the computational purpose.
Manyresearchers have taken steps toward successful ex-traction of computationally useful lexical informa-tion from machine readable dictionaries and con-vert it into formal representation (Montemagnia andVanderwende, 1993) (Byrd et al, 1987) (Jensenand Binot, 1987).
Sparck Jones's pioneering re-61search (Jones, 1985), done in early 1960, proposeda lexical representation by synonym list.
Very closeto that proposal, George Miller and colleagues atPrinceton University constructed a large-scale re-source for lexical information-WordNet.The most useful feature of WordNet to NaturalLanguage Processing community is the organizationof lexical information in terms of word meanings,rather than word forms.
It is organized by parts ofspeech-nouns, verbs, adjectives, and adverbs.
Eachentry in the WordNet is a concept represented by alist of synonyms (synset).
The information is rep-resented in the form of semantic networks.
For in-stance, in the network for nouns, there are "partof", "is_a', "member of" .... relationships betweenconcepts.
Philip Resnik has studied the lexical rela-tionship by use of a WordNet axonomy.
He wrotethat "...it is difficult to ground taxonomic represen-tations such as WordNet in precise formal terms,the use of the WordNet taxonomy makes reason- ~ably clear the nature of the relationships being rep-resented. "
(Resnik, 1993).Some early work of applying WordNet for the lex- ~ical semantic acquisition can be found in NYU'sMUC-4 system (Grishman et al, 1992), which cused WordNet hierarchies for semantic classification.However, they ran into the problem of automatedsense disambiguation because the WordNet hierar-chy is sense dependent.
Ralph Grishman and hisgroup at NYU reached the conclusion that "Word-Net may be a good source of concepts, but that itwill not be of net benefit unless manually reviewedwith respect o a particular application" (Grish-man et al, 1992).
Other research concerns usingWordNet senses to tag large corpus with the lexi-cal semantics for automated word sense disambigua-tion (Ng, 1997) (Wiebe et al , 1997)3 App l i ca t ion  o f  WordNet  in theSystemOur system contains three major processes which,respectively, address training, rule generalization,and the scanning of new information.
WordNet isused in all three processes as shown in figure 1.During the training process, each article is par-tially parsed and segmented into Noun Phrases, VerbPhrases and Prepositional Phrases.
An IBM Lan-guageWare English Dictionary and Computing TermDictionary, a Partial Parser, a Tokenizer and a Pre-processor are used in the parsing process.
The To-kenizer and the Preprocessor a e designed to iden-tify some special categories such as e-mail address,phone number, state and city etc.
The user, with---------Braining Process\[ Scanning Process \]Figure 1: The Use of WordNet in the System120010008006004002000I I I |sense dtstnbutton2 3 4 5 6sense numberI I7 8Figure 2: The Sense Distributionthe help of a graphical user intefface(GUI) scans aparsed sample article and indicates a series of se-mantic net nodes and transitions that he or shewould like to create to represent the informationof interest.
Specifically, the user designates thosenoun phrases in the article that are of interest anduses the interface commands to translate them intosemantic net nodes.
Furthermore, the user desig-nates verb phrases and prepositions that relate thenoun phrases and uses commands to translate theminto semantic net transitions between odes.
In theprocess, the user indicates the desired translation ofthe specific information of interest into semantic netform that can easily be processed by the machine.When the user takes the action to create the seman-tic transitions, a Rule Generator keeps track of theuser's moves and creates the rules automatically.WordNet is used to provide the sense informa-tion during the training.
For each headword ina noun/verb phrase, many senses are available inWordNet.
We trained 24 articles with 1129 head-62words from "triangle.job" domain, and found that91.7% of headwords were used as sense one in Word-Net.
The sense distribution is shown in figure 2.Based on this observation, by default, the systemassigns ense one to every headword, while provid-ing the user the option to train the sense other thanone.
For example, "opening" often appears in thejob advertisement domain.
But instead of using thefirst sense as {opening, gap}, it uses the fourth senseas {opportunity, chance}.
The user needs to train"opening" to be sense four during the training pro-cess.
The Sense Table keeps the record of these head-words and their most frequently used senses (otherthan one).Rules created from the training process are spe-cific to the training articles and must be generalizedbefore being applied on other articles in the domain.According to different requirements from the user, inthe rule generalization process, a rule optimizationengine, based on WordNet, generalizes the specificrules and forms a set of optimized rules for process-ing new information.
This rule generalization pro-cess will be described in the later sections.During the scanning of new information, with thehelp of a rule matching routine, the system appliesthe optimized rules on a large number of unseen ar-ticles from the domain.
If headwords are not in theSense Table, sense one in WordNet will be assigned;otherwise, the Sense Table provides them their mostfrequently used senses in the domain.
The output ofthe system is a set of semantic transitions for eacharticle that specifically extract information of inter-est to the user.
Those transitions can then be usedby a Postprocessor to fill templates, answer queries,or generate abstracts.4 Rule GeneralizationThe Rule Generalization engine is crucial to thewhole system because it makes the customizing pro-cess easier.
The user only needs to train on a compa-rably small amount of data from the domain, and thesystem will automatically revise the rules to makethem applicable for large amount of new informa-tion.4.1 RulesIn a typical information extraction task, the most in-teresting part is the events and relationships holdingamong the events (Appelt et al, 1995).
These rela-tionships are usually specified by verbs and preposi-tions.
Based on this observation, the left hand side(LHS) of our information extraction rules is madeup of three entities.
The first and the third entitiesare the target objects in the form of noun phrases,the second entity is the verb or prepositional phraseindicating the relationship between the two objects.The right hand side (RHS) of the rule consists of theoperations required to create a semantic transition-ADD.NODE, ADD_RELATION.
ADD.NODE is toadd an object in the transitions.
ADD.RELATIONis to add a relationship between two objects.
Thespecific rule generated from the training process isshown in figure 3 rule 1.Rule 1 in figure 3 is very specific, and it can beactivated only by a sentence with the same patternas "DCR Inc. is looking for C programmers.
.
.
"It will not be activated by other Sentences such as"IBM Corporation seeks job candidates inLouisville,KY with HTML experience".
Semantically speak-ing, these two sentences are very much alike.
Bothof them are about a company that seeks some kindof person.
However, without generalization, the sec-ond sentence will not be processed.
So the use of thespecific rule is very limited.In order to make the specific rules applicable toa large number of unseen articles in the domain,a comprehensive g neralization mechanism is nec-essary.
We are not only interested in the general-ization itself, but also in a strategy to control thedegree of generalization for various applications indifferent domains.4.2 Generalization SchemeThe hierarchical organization of WordNet by wordmeanings (Miller, 1990) provides the opportu-nity for automated generalization.
With the largeamount of information i  semantic lassification andtaxonomy provided in WordNet, many ways of in-corporating WordNet semantic features with gener-alization are foreseeable.
At this stage, we only con-centrate on the Hypemym/Hyponym feature.A hyponym is defined in (Miller et al, 1990a) asfollows: " A noun X is said to be a hyponym of anoun Y if we can say that X is a kind of Y. Thisrelation generates a hierarchical tree structure, i.e.,a taxonomy.
A hyponym anywhere in the hierarchycan be said to be "a kind of" all of its superordi-nateds .
.
.
.  "
If X is a hyponym of Y, then Y is ahypernym of X.From the training process, the specific rules con-tain three entities on the LHS.
An abstract specificrule is shown in rule 2 in figure 3.
Each entity (sp)is a quadruple, in the form of (w, c, s, t), where w isthe headword of the trained phrase; c is the part ofthe speech of the word; s is the sense number ep-resenting the meaning of w; t is the semantic typeidentified by the preprocessor for w.For each sp = (w,c,s,t), if w exists in WordNet,631.
An Example of the Specific Rule:\[DCR Inc, NG, 1,company\], [look.for, VG, 1, other_type\], [programmer, NG, 1, other_type\]ADD.NODE(DCR Inc.), ADD_NODE(programmer),ADD_RELATION(look.for, DCR Inc., programmer)2.
An Abstract Specific Rule:(Wl, el, 81, tl), (W2, C2, 82, t2),(w3, c3, 83, t3)ADD_NODE(w1), ADD_NODE(w2), ADD_RELATION(w~, w2, w3)3.
An Abstract Generalized Rule:(W1, C1, $1, T1) E Generalize( spl , hl ) , (W2 ,C2, $2, T2 ) E Generalize( sp2, h2 ),(W~, C3, Ss, T3) E Generalize(sp3, h3)ADD_NODE(W1), ADD_NODE(Ws), ADD_RELATION(W2,Wi, W3)4.
An Example of the Most General Rule:(W1, C1, $1, T1) E {group...}, (W2, C2, $2, T2) e {look_for, ...}, (W3, C3, $3, T3) E {entity, ...})ADD_NODE(W1 ), ADD.NODE(W3), ADD_RELATION(Wz,W1, W3)Figure 3: Sample Rulesthen there is a corresponding synset in WordNet.The hyponym/hypernym hierarchical structure pro-vides a way of locating the superordinate concepts ofsp.
By following additional Hypernymy, we will getmore and more generalized concepts and eventuallyreach the most general concept, such as {entity}.Based on this scenario, for each concept, differentdegrees of generalization can be achieved by adjust-ing the distance between this concept and the mostgeneral concept in the WordNet hierarchy (Bagga etal., 1997).
The function to accomplish this task isGeneralize(x,h), which returns a synset list h levelsabove the concept z in the hierarchy.WordNet is an acyclic structure, which suggeststhat a synset might have more than one hypernym.However, This situation doesn't happen often.
Wetested on 150 randomly chosen articles from "tri-angle.job" newsgroup.
Totally there were 12115phrases including 1829 prepositions, 1173 phraseswith headwords not in WordNet and 9113 phraseswith headwords in WordNet.
Within 9113 head-words, 722 headwords (7.9%), either themselves ortheir hypernym had more than one superordinate.Furthermore, 90% of 722 cases came from two su-perordinates of{person, individual, someone, moral,human soul}, which are {life_form, organism, be-ing, living thing}, and {causal agent, cause, causalagency}.
Certainly, in some cases, {person...} is akind of {causal agent...}, but identifying it as hy-ponym of {life_form...} also makes the sense.
Basedon this scenario, for the sake of simplicity, the sys-tem selects the first superordinate if more than oneare presented.The process of generalizing rules consists of re-placing each sp = (w,c,s,t) in the specific rules bya more general superordinate synset from its hy-pernym hierarchy in WordNet by performing theGeneralize(s, h) function.
The degree of general-ization for rules varies with the variation of h inGeneralize( sp, h ).Rule 3 in figure 3 shows an abstract generalizedrule.
The E symbol signifies the subsumption rela-tionship.
Therefore, a E b signifies that a is sub-sumed by b, or, in WordNet terms, concept b is asuperordinate concept of concept a.
The generalizedrule states that the RHS of the rule gets executed if64Specific Rulek @\[ Most General Rule 1Transmu~Database for \]Acuvatmg Objects\[~ User's Reqmrementfor Pmclsmn (threshold)(Opt1 edRule 1Figure 4: Rule Generalization Processall of the following conditions hold:?
A sentence contains three phrases (not neces-sarily contiguous) with headwords W1, W2, andWs.
* The quadruples corresponding to these head-words are (W1, C1, $1, T1), (W2, U2, $2, T2), and(Ws, Cs, S3, T3).?
The synsets, in WordNet, corresponding to thequadruples, are subsumed by Generalize(spl,hi), Generalize(sp~, h2), and Generalize(sps,h3 ) respectively.5 General izat ion TreeThe generalization degree is adjustable by the user.Rules with different degrees of generalization ontheir different constituents will have a different be-havior when processing new texts.
Within a par-ticular rule, the user might expect one entity to berelatively specific and the other entity to be moregeneral.
For example, if a user is interested in find-ing all DCR Inc. related jobs, he/she might wantto hold the first entity as specific as that in rule 1in figure 3, and generalize the third entity.
We havedesigned a Generalization Tree (GT) to control thegeneralization degree.The rule generalization process with the help ofGT is illustrated in figure 4.
Each specific rule(asshown in rule 1 in figure 3) is generalized to its mostgeneral form(as shown in rule 4 in figure 3) by ageneralization engine based on WordNet.
Specifi-cally, the generalization e gine generalizes noun en-tities in the specific rule to their top hypernym inthe hierarchies.
The most general rule is appliedagain to the training corpus and some transitionsare created.
Some transitions are relevant, whileothers are not.
Then the user employs our system toclassify the created transitions as either acceptableor not.
The statistical classifier calculates the rele-vancy_rate for each object, which will be describedlater.
A database is maintained to keep the rele-vancy information for all the objects which activatethe most general concept in the most general rule.This database is later automatically transformed tothe GT structure.
While maintaining the semanticrelationships of objects as in WordNet, GTs collectthe relevancy information of all activating objectsand find the optimal level of generalization to fitthe user's needs.
The system will automatically ad-just the generalization levels for each noun entity tomatch the desires of the user.
The idea of this op-timization process is to first keep recall as high aspossible by applying the most general rules, then ad-just the precision by tuning the rules based on theuser's specific inputs.5.1 An Example of GTSuppose we apply rule 4 in figure 3 to the train-ing corpus, and the entity three in the rule is acti-vated by a set of objects shown in table 1.
Froma user interface and a statistical classifier, the rele-vancy_rate(re0 for each object can be calculated.rel(obj) = count of obj being relevanttotal count of occurence of objAs shown in table 1, for example, rel({analyst...}) =80%, which indicates that when (entity} in themost general rule is activated by analyst, 80% oftime it hits relevant information and 20% of timeit hits irrelevant information.
On the other hand,it suggests that if { entity} is replaced by the con-cept (analyst...}, a roughly 80% precision could beachieved in extracting the relevant information.
Thecorresponding GT for table 1 is shown in figure 5.In GT, each activating object is the leaf node inthe tree, with an edge to its immediate hypernym(parent).
For each hypernym list in the database,65object senseanalyst 1candidate 2individual 1participant 1professional 1software 1hypernym list depth rel_rate count{analyst} ~ {expert} ~ {individual} 4 80% 5=~ {life form} ~ {entity}{candidate} ~ {applicant} =~ {individual} 4 100% 3{life form} ~ {entity}{individual} ~ {life form} =~ {entity} 2 100% 55 0% 14 100% 25 0% 1. .
.
?
.
.
.
.
.Table 1: Sample Database for Objects Activating {entity}{Enuty} c = 17, r =82 3%{object } {hfeform, orgamsm } c=16,  r=SZ5%J{artifact } {person, individual } c = 16, r = 875%r=0%{crcauon } {~pen } {adult } {peer, equal } (apphcant} {,adtwdual}r - -O% r=80% r=100% r=0% r=100% rd=lO0%{producUon ) {analyst} {professlonal} {assocta~ } {candidate}c = 1 count = 5 count = 2 \[ c = 1 count = 3r = 0% rel = 80% rel = 100% I r = 0% rel = 100%{software} {partmtpant}Coun$ '  -~ 1 count  = Irel = 0% rel = 0%Figure 5: An Example of Generalization Treethere is a corresponding path in GT.
Besides the or-dinary hard edge represented by the solid line, thereis a soft edge represented by the dotted line.
Con-cepts connected by the soft edge are the same con-cepts.
The only difference between them is that theleaf node is the actual activating object, while theinternal node is the hypernym for other activatingobjects.
Hard edges and soft edges only have rep-resentational difference, as to the calculation, theyare treated the same.
Each node has two other fieldscounts of occurrence and relevancy_rate.
For the leafnodes, those fields can be filled from the database di-rectly.
For internal nodes, the instantiation of thesefields depends on its hyponym (children) nodes.
Thecalculation will be described later.If the relevancy.xate for the root node { entity} is82.3%, it indicates that, with the probability 82.3%,objects which activate { entity} are relevant.
If theuser is satisfied with this rate, then it's not neces-sary to alter the most general concept in the rule.If the user feels the estimated precision is too low,the system will go down the tree, and check the rel-evancy.xate in the next level.
For example, if 87.5%is good enough, then the concept {life form, organ-ism...} will substitute {entity} in the most generalrule.
If the precision is still too low, the system willgo down the tree, find {adult..}, {applicant..}, andreplace the concept { entity} in the most general rulewith the union of these two concepts.5.2 Generalization Tree Modelspecific.
.
.more generalmost generalobject 1 relation object 2T0XnY0.
.
?
?Table 2: concepts in the ruleZ0Z 3ZmFor the sake of simplicity, let's use x,, y,, zl to repre-sent the rule constituents- object one, relation, ob-66ject two respectively.
As shown in table 2, xo, yo,z0 are the concepts from the specific rule.
At themoment, we only consider the generalization  theobjects, zs and z~ are more general concepts thanx0 and z0.
x~ is the hypemym of xz-1 (i _< n); z: isthe hypernym of za-1 (j _< m).
Xn and Zm are themost general concepts for object one and object tworespectively.For each object concept, a corresponding GT iscreated.
Let's suppose xn is activated by q conceptsel ?, e2 ?, .... e?q; the times of activation for each e~ ?
arerepresented by c~.
Since e~?
(i _< q) activates xn, thereo ~ e~ =~ .... =~ xn in Word- exists a hypernym list e,Net, where e~ is the immediate hypernym of e~ -1.The system maintains a database of activation in-formation as shown in table 3, and builds GT fromthis database automatically.GT is an n-ary branching tree structure with thefollowing properties:?
Each node represents a concept, and each edgerepresents the hypernym relationship betweenthe concepts.
If e~ is the immediate hypernymof ca, then there is an edge between ode e~ andej.
e~ is one level above ea in the tree.?
The root node xn is the most general conceptfrom the most general rule.?
The leaf nodes .o ~0 .o el, 2,...~q are the conceptswhich activate xn.
The internal nodes are theconcepts e~ (i ~ 0 and 1 < j < q) from thehypernym paths for the activating concepts.o has three fields-concept it- , Every leaf node e~self e~ ?
, counts and relevancy_rate, which can beobtained from the database:counts(e~ ?)
= c,relevancy_rate( ~ ?)
= r~?
Every internal node e has three fields-conceptitself e, relevancy_rate and counts(e).For an internal node e, if it has n hyponymseo, ...en then:ncounts(e) = couNts(e,)s=lrelevancy_rate(e) = ~ P ( e~) *relevancy_rate( ~ )2=1whereP(e,) = counts(e,)counts(e)5.3 Searching GTDepending on user's different needs, a threshold 9is pre-selected.
The system will start from the rootnode, go down the tree, and find all the nodes e,such that relevancy.rate(e~) > 0.
If a node rele-vancy_rate is higher than 9, its hyponym (children)nodes will be ignored.
In this way, the system main-tains a set of concepts whose relevancy_rate is higherthan 8.
By substituting xn in the most general rulewith this set of concepts, an optimized rule is createdto meet the user's needs.The searching algorithm is basically the breadth-first search as follows:1.
Initialize Optimal-Concepts to be empty set.Pre-select he threshold 0.
If the user wantsto get the relevant information and particularlycares about the precision, 0 should be set high;if the user wants to extract as much as infor-mation possible and does not care about theprecision, 0 should be set low.2.
Starting from the root node x, perform theRecursive-Seareh algorithm, which is defined asthe following:Recursive-Seareh(coneept x){ i/(ret(x) > O) {put x into Optimal-Concepts set;exit;)else {let m denote the number of children nodes of x;let x, denote the child of x (0 < i _< m);for ( i  = 1; i < m; i++)Recursive-Seareh(x, ) ;);}5.4 Experiment and DiscussionAn experiment is conducted to test the applicabil-ity of GT in automatic information extraction.
Wetrained our system on 24 articles from the trian-gle.jobs USENET newsgroups, and created 25 spe-cific rules concerning the job position/title informa-tion.
For example, in "DCR.
is looking for softwareengineer", software engineer is the position name.The specific rules then were generalized totheir mostgeneral forms, and were applied again to the trainingset.
After the user's selection of the relevant ran-sitions, the system automatically generated a GTfor each most general concept in the most generalrule.
We predefined the threshold to be 0.2, 0.4, 0.5,0.6, 0.8, 0.9 and 1.0.
Based on the different hresh-olds, the system generated different sets of optimized67activating objectscysense counts hypernym listSl C1 e~ ~ e~ ~ ... ~ ~gn.
.
.
.
.
.
.
.
.
.8q Cq eq eq ...depthdzd2dqrelevancy_rater lr2rqTable 3: database of activating conceptsrules.
Those rules were then applied on 85 unseenarticles from the domain.The evaluation process consists of the followingstep: first, each unseen article is studied to see ifthere is position/title information presented in thearticle; second, the semantic transitions producedby the system are examined to see if they correctlyextract the position/title information.
Precision isthe number of transitions created which containingposition/title information out of the total numberof transitions produced by the system; recall is thenumber of articles which have been correctly ex-tracted position/title information out of the totalnumber of articles with position/title information.The overall performance of recall and precision isdefined by F-measurement (Chinchor, 1992), whichis(/~2 + 1.0) ?
P ?
R/32*P+Rwhere P is precision, R is recall,/~ = 1 if precisionand recall are equally important.
The precision ,recall and F-measurement curves with respect to thethreshold for relevancy_rate are shown in figure 6.The detailed result is shown in table 4.Q.10.90807060.504030.20.100.2i i t t t s I........ f~ l i "  .........?
.F -~asummenl  .
.
.
._ , , .
.
.
.
.
o rec ,s Jon  .
.
.
.
.ilfil;i::::?
"I I I I I I I0 3 0 4 0 5 0.6 0.7 0.8 0.9threshold for the relevancy_rateFigure 6: recall, precision, and F-measurement vs.thresholdThe recall achieves the highest at 81.3% when 0 =0.2.
It gradually declines and reaches 66.7% when8 = 1.0.
As expected, the precision increases when0 goes up.
It ranges from very low at 33.3% (0 =0.2) to very high at 94.6%( 0 = 1.0).
The overallperformance F-measurement goes up from 4?.2% to78.7% when 0 increases.
The result is consistentwith our expectation.
When the threshold is high,more tuning of the rules needs to be done, and thesystem is expected to perform better.Some problems were detected which prevent bet-ter performance of the system.
The current do-main is a newsgroup, where anyone can post any-thing which he/she believes is relevant to the news-group.
It is inevitable that some typographical er-rors and some abbreviations occur in the articles.And the format of the article sometimes i unpre-dictable.
The system performance is also hurt bythe error in the partial parsing.In the experiment, we found that WordNet hasabout 90% coverage of verbs and nouns in this do-main.
Most nouns not in WordNet are proper nouns,and in this domain, mostly are company names, soft-ware names.
This problem is solved by our Pre-processor, which identifies the proper nouns to beseveral semantic types, such as company name, soft-ware name, city name, and so on.
However Someimportant domain specific nouns may not exist inWordNet.
It would be nice if WordNet could pro-vide the friendly interface for users to add the newwords and create the links for their own applications.As to computational purpose, WordNet is well devel-oped.
Finding hypernym, synonyms...etc is very effi-cient.
Training senses at the training process olvesthe most problems of sense disambiguation.
How-ever, some problems till remain.
For example, if"better" is not trained in the training process, thenby default, it will be assigned sense one, which isa subtype of a person.
The hypernym list of "bet-ter" with sense one is {better} =~ {superior}{religion} ~ {Religionist} =~ {person}.
Butin the sentence "This position requires experiencewith 5.0 or better", "better" should be used assense two as in the hypernym list {better} =~{good, goodness} :-~ {asset, plus) ~ {quality}{attribute} ~ {abstraction} .
Despite occasionalsense disambiguation problem, generally, WordNetprovides a good method to achieve generalization i68threshold 0.2 0.4Precision 33.3% 49.7%Recall 81.3% 80.0%F-measurement 47.2% 61.3%0.551.0%80.0%62.3%0.6 0.8 0.9 1.0 l82.4% 94.6% 94.6% 94.6%73.3% 66,7% 66.7% 66.7%77.6% 78.7% 78.7% 78.7%Table 4: Precision/Recall/F-measurement wrt.
threshold of relevancy_ratethis domain.6 Conc lus ion  and  Future  WorkThis paper describes a rule generalization approachby using Generalization Tree and WordNet for infor-mation extraction.
The rule generalization makesthe customization process easier.
The Generaliza-tion Tree algorithm provides away to make the sys-tem adaptable to the user's needs.
The idea of firstachieving the highest recall with low precision, thenadjusting precision by user's needs has been success-ful.
We are currently studying how to enhance thesystem performance byfurther efining the general-ization approach.ReferencesAberdeen,John, John Burger, David Day, LynetteHirschman, Patricia Robinson, and Marc Vi-lain 1995.
MITRE: Description of the ALEM-BIC System Used for MUC-6, Proceedings oftheSixth Message Understanding Conference (MUC-6), pp.
141-155, November 1995.Appelt, Douglas E., Jerry It.
Hobbs, John Bear,David Israel, Megumi Kameyama, Andy Kehler,David Martin, Karen Myers, and Mabry Tyson1995.
SRI International: Description of the FAS-TUS System Used for MUC-6, Proceedings oftheSixth Message Understanding Conference (MUC-6), pp.
237-248, November 1995.Bagga, Amit, Joyce Y. Chai, and Alan W. Biermann1997 The Role of WordNet in the Creation ofa Trainable Message Understanding System, Toappear at The Innovative Applications of ArtificialIntelligence Conference, 1997.Byrd, Roy, Nicoletta Calzolari, Martin Chodorow,Judith Klavans, and Mary Neff 1987 Tools andmethods for computational linguistics, Computa-tional Linguistics, 13(3-4), pp.
219-240, 1987Chai, Joyce Y.and Alan W. Biermann 1997 AWordNet Based Rule Generalization Engine ForMeaning Extraction Submitted to Tenth Interna-tional Symposium On Methodologies For Intelli-gent Systems, 1997.Chinchor, Nancy 1992.
MUC-4 Evaluation Metrics,Proceedings of the Fourth Message Understand-ing Conference (MUC-J), June 1992, San Mateo:Morgan Kanfmann.Fisher, David, Stephen Soderland, Joseph Mc-Carthy, Fangfang Feng and Wendy Lehnert.
1995.Description of the UMass System as Used forMUC-6, Proceedings of the Szxth Message Un-derstanding Conference (MUC-6), pp.
127-140,November 1995.Grishman, Ralph, Catherine Macleod, and JohnSterling 1992.
New York University Descrip-tion of the Proteus System as Used for MUC-4,Proceedings ofthe Fourth Message UnderstandingConference (MUC-d), pp.
223-241, June 1992.Grishman, Ralph 1995.
The NYU System for MUC-6 or Where's the Syntax?
Proceedings of theSixth Message Understanding Conference (MUC-6), pp.
167-175, November 1995.Jensen, Karen, Jean-Louis Binot 1987.
Disam-biguating Prepositional Phrase Attachments byUsing On-line Dictionary Definitions Computa-tional Linguistics, 13(3) pp.
251-260, 1987.Jones, Sparck 1985.
Synonymy and Semantic Clas-sification, Edinburgh University Press, 1985Krupka, George It.
1995.
Description of the SRASystem as Used for MUC-6, Proceedings of theSixth Message Understanding Conference (MUC-6), pp.
221-235, November 1995.Miller, George A.
1990.
Introduction to WordNet:An On-Line Lexical Database.
WordNet Manuals,pp.
10-32, August 1993.Miller, George A., et al 1990a.
Five Papers onWordNet, Cognitive Science Laboratory, Prince-ton University, No.
43, July 1990.Montemagni, Simonetta, Lucy Vanderwende 1993Structural Patterns versus String Patterns for Ex-tracting Semantic Information from Dictionaries,Natural Language Processing: The PLNLP Ap-proach, pp.
149-159, 1993Ng, Hwee Tou 1997 Getting Serious about WordSense Disambiguation, A CL/SIGLEX Workshopon Tagging Text with Lexical Semantics, pp.
1-7,Washington DC, April, 199769Resnik, Philip 1993 Selection and Information: AClass Based Approach to Lexical Relationships,Ph.D Dissertation, University of Pennsylvania,1993.Weischedel, Ralph 1995.
BBN: Description of thePLUM System as Used for MUC-6, Proceedingsof the Sixth Message Understanding Conference(MUC-6), pp.
55-69, November 1995.Wiebe, Janyce, Julie Maples, Lei Duan, and Re-becca Bruce 1997 Experience in WordNet SenseTagging in Wall Street Journal, ACL/SIGLEXWorkshop on Tagging Text with Lexical Seman-tics, pp.
1-7, Washington DC, April, 199770
