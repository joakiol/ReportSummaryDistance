Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 568?572, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsNILC USP: A Hybrid System for Sentiment Analysis in Twitter MessagesPedro P. Balage Filho and Thiago A. S. PardoInterinstitutional Center for Computational Linguistics (NILC)Institute of Mathematical and Computer Science, University of Sa?o PauloSa?o Carlos - SP, Brazil{balage, taspardo}@icmc.usp.brAbstractThis paper describes the NILC USP systemthat participated in SemEval-2013 Task 2:Sentiment Analysis in Twitter.
Our systemadopts a hybrid classification process thatuses three classification approaches: rule-based, lexicon-based and machine learningapproaches.
We suggest a pipeline architec-ture that extracts the best characteristics fromeach classifier.
Our system achieved an F-score of 56.31% in the Twitter message-levelsubtask.1 IntroductionTwitter and Twitter messages (tweets) are a modernway to express sentiment and feelings about aspectsof the world.
In this scenario, understanding the sen-timent contained in a message is of vital importancein order to understand users behavior and for mar-ket analysis (Java et al 2007; Kwak et al 2010).The research area that deals with the computationaltreatment of opinion, sentiment and subjectivity intexts is called sentiment analysis (Pang et al 2002).Sentiment analysis is usually associated with atext classification task.
Sentiment classifiers arecommonly categorized in two basic approaches:lexicon-based and machine learning (Taboada et al2011).
A lexicon-based classifier uses a lexicon toprovide the polarity, or semantic orientation, of eachword or phrase in the text.
A machine learning clas-sifier learns features (usually the vocabulary) fromannotated corpus or labeled examples.In this paper, we present a hybrid system for senti-ment classification in Twitter messages.
Our systemcombines three different approaches: rule-based,lexicon-based and machine learning.
The purpose ofour system is to better understand the use of a hybridsystem in Twitter text and to verify the performanceof this approach in an open evaluation contest.Our system participated in SemEval-2013 Task2: Sentiment Analysis in Twitter (Wilson et al2013).
The task objective was to determine the sen-timent contained in Twitter messages.
The task in-cluded two sub-tasks: a expression-level classifi-cation (Task A) and a message-level classification(Task B).
Our system participated in Task B.
In thistask, for a given message, our system should classifyit as positive, negative, or neutral.Our system was coded using Python and theCLiPS Pattern library (De Smedt and Daelemans,2012).
This last library provides the part-of-speechtagger and the SVM algorithm used in this work1.2 Related workDespite the significant number of works in senti-ment analysis, few works have approached Twit-ter messages.
Agarwal et al(2011) explored newfeatures for sentiment classification of twitter mes-sages.
Davidov et al(2010) studied the use ofhashtags and emoticons in sentiment classification.Diakopoulos and Shamma (2010) analyzed the peo-ple?s sentiment on Twitter for first U.S. presidentialdebate in 2008.The majority of works in sentiment analysis useseither machine learning techniques or lexicon-based1Our system code is freely available athttp://github.com/pedrobalage/SemevalTwitterHybridClassifier568techniques.
However, some few works have pre-sented hybrid approaches.
Ko?nig and Brill (2006)propose a hybrid classifier that utilizes human rea-soning over automatically discovered text patterns tocomplement machine learning.
Prabowo and Thel-wall (2009) evaluates the effectiveness of differentclassifiers.
This study showed that the use of multi-ple classifiers in a hybrid manner could improve theeffectiveness of sentiment analysis.3 System architectureOur system is organized in four main components:normalization, rule-based classifier, lexicon-basedclassifier and machine learning classifier.
Thesecomponents are connected in a pipeline architecturethat extracts the best characteristics from each com-ponent.
The Figure 1 shows the system architecture.Figure 1: System architectureIn this pipeline architecture, each classifier, in asequential order, evaluates the Twitter message.
Ineach step, the classifier may determine the polarityclass of the message if a certain degree of confidenceis achieved.
If the classifier may not achieve thisconfidence threshold, the classifier in the next stepis called.
The machine learning classifier is the laststep in the process.
It is responsible to determine thepolarity if the previous classifiers failed to achievethe confidence level required to classification.
Thenormalization component is responsible to correctand normalize the text before the classifiers use it.This architecture improves the classification pro-cess because it takes advantage of the multiple ap-proaches.
For example, the rule-based classifier isthe most reliable classifier.
It achieves good resultswhen the text is matched by a high-confidence rule.However, due the freedom of language, rules maynot match 100% of the unseen examples, conse-quently it has a low recall rate.Lexicon-based classifiers, for example, are veryconfident in the process to determine if a text is polaror neutral.
Using sentiment lexicons, we can deter-mine that sentences containing sentiment words arepolar and sentences that do not contain such wordsare neutral.
Moreover, the presence of a high num-ber of positive or negative words in the text may bea strong indicative of the polarity.Finally, machine learning is known to be highlydomain adaptive and to be able to find deep corre-lations (Taboada et al 2011).
This last classifiermight provide the final decision when the previousmethods failed.
In the following sub-sections, wedescribe in more details the components in whichour system is based on.
In the next section, we ex-plain how the confidence level was determined.3.1 Normalization and rule-based classifierThe normalization module is in charge of correctingand normalizing the texts.
This module performs thefollowing operations:?
Elements such as hashtags, urls and mentionsare transformed into a consistent set of codes;?
Emoticons are grouped into representativecategories (such as happy, sad, laugh) and con-verted to particular codes;?
Signals of exaltation (such as repetitive excla-mation marks) are recognized;?
A simple misspelling correction is performed;?
Part-of-speech tagging is performed.The rule-based classifier is very simple.
The onlyrules applied here are concerned to the emoticonsfound in the text.
Empirically, we evidenced thatpositive emoticons are an important indicative ofpositiveness in texts.
Likewise, negative emoticons569indicate negativeness tendency.
This module re-turns the number of positive and negative emoticonsmatched in the text.3.2 Lexicon-based classifierThe lexicon-based classifier is based on the idea thatthe polarity of a text can be summarized by the sumof the individual polarity values of each word orphrase present in the text.
In this assumption, asentiment lexicon identifies polar words and assignspolarity values to them (known as semantic orienta-tions).In our system, we used the sentiment lexicon pro-vided by SentiStrength (Thelwall et al 2010).
Thislexicon provides an emotion vocabulary, an emoti-cons list, a negation list and a booster word list.In our algorithm, we sum the semantic orienta-tions of each individual word in the text.
If the wordis negated, the polarity is inverted.
If the word is in-tensified (boosted), we increase its polarity by a fac-tor determined in the sentiment lexicon.
A lexicon-based classifier usually assumes the signal of the fi-nal score as the sentiment class: positive, negativeor neutral (score zero).3.3 Machine learning classifierThe machine learning classifier uses labeled exam-ples to learn how to classify new instances.
Thealgorithm learns by using features extracted fromthese examples.
In our classifier, we used the SVMalgorithm provided by CLiPS Pattern.
The featuresused by the classifier are bag-of-words, the part-of-speech set, and the existence of negation in the sen-tence.4 Hybrid approach and tuningThe organization from SemEval-2013 Task 2: Senti-ment Analysis in Twitter provided three datasets forthe task (Wilson et al 2013).
A training dataset(TrainSet), with 6,686 messages2, a developmentdataset (DevSet), with 1,654 messages, and two test-ing datasets (TestSets), with 3,813 (Twitter TestSet)and 2,094 (SMS TestSet) messages each.As we said in the previous section, our system isa pipeline of classifiers where each classifier may2The number of messages may differ from other participantsbecause the data was collected by crawlingassign a sentiment class if it achieves a particularconfidence threshold.
This confidence threshold is afixed value we set for each system in order to havea decision boundary.
This decision was made by in-specting the results table obtained with the develop-ment set, as shown below.Table 1 shows how the rule-based classifier per-formed in the development dataset.
The classifierscore consists in the difference between the num-ber of positive emoticons and the number of nega-tive emoticons found in the message.
For example,for score of -1 we had 22 negative, 4 neutral and 2positive messages.Table 1: Correlation between the rule-based classifierscores and the gold standard classes in the DevSetRule-based Gold Standard Classclassifier score Negative Neutral Positive-1 22 4 20 311 708 4961 7 24 712 2 43 to 6 1 2Inspecting the Table 1 we adjusted the rule-basedclassifier boundary to decide when the score is dif-ferent from zero.
For values greater than zero, theclassifier will assign the positive class and, for val-ues below zero, the classifier will assign the negativeclass.
For values equal zero, the classifier will callthe lexicon-based classifier.Table 2 is similar to the Table 1, but it now showsthe scores obtained by the lexicon-based classifierfor the development set.
This score is the messagesemantic orientation computed by the sum of the se-mantic orientation for each individual word.Inspecting Table 2, we adjusted the lexicon-basedclassifier to assign the positive class when the totalscore is greater than 3 and negative class when thetotal score is below -3.
Moreover, we evidenced that,compared to the other classifiers, the lexicon-basedclassifier had better performance to determine theneutral class.
Therefore, we adjusted the lexicon-based classifier to assign the neutral class when thetotal score is zero.
For any other values, the machinelearning classifier is called.Finally, Table 3 shows the confusion matrix forthe machine learning classifier in the development570Table 2: Correlation between the lexicon-based classifierscore and the gold standard classes in the DevSetLexicon-based Gold Standard Classclassifier scores Negative Neutral Positive-11 to -6 26 8 4-5 15 6 4-4 31 20 9-3 32 24 5-2 57 86 22-1 25 31 200 74 354 1151 26 70 422 28 87 1033 12 29 814 8 9 565 2 6 426 to 13 4 9 72dataset.
The machine learning classifier does notoperate with a confidence threshold, so no decisionswere made for this classifier.
We see that machinelearning classifier does not have a good accuracyin general.
Our hybrid approach proposed aims toovercome this problem.
Next section shows the re-sults achieved for the Semeval test dataset.Table 3: Confusion matrix for the machine learning clas-sifier in the DevSetMachine learning Gold Standard Classclassifier class Negative Neutral Positivenegative 35 6 11neutral 232 595 262positive 73 138 3025 ResultsTable 4 shows the results obtained by each individ-ual classifier and the hybrid classifier for the testdataset.
In the task, the systems were evaluated withthe average F-Score obtained for positive and nega-tive classes3.
We see that the Hybrid approach couldimprove in relation to each classifier score, confirm-ing our hypothesis.3Semeval-2013 Task 2: Sentiment Analysis in Twitter com-pares the systems by the average F-score for positive and nega-tive classes.
For more information see Wilson et al(2013)Table 4: Average F-score (positive and negative) obtainedby each classifier and the hybrid approachClassifier Twitter TestSet SMS TestSetRule-based 0.1437 0.0665Lexicon-Based 0.4487 0.4282Machine Learning 0.4999 0.4029Hybrid Approach 0.5631 0.5012Table 5 shows the results in terms of precision,recall and F-score for each class by the hybrid clas-sifier in the Twitter dataset.
Inspecting our algo-rithm for the Twitter dataset, we had 277 examplesclassified by the rule-based classifier, 2,312 by thelexicon-based classifier and 1,224 the by machinelearning classifier.
The results for the SMS datasethad similar values.Table 5: Results for Twitter TestSetClass Precision Recall F-Scorepositive 0.6935 0.6145 0.6516negative 0.5614 0.4110 0.4745neutral 0.6152 0.7427 0.67296 ConclusionWe described a hybrid classification system used forSemeval-2013 Task 2: Sentiment Analysis in Twit-ter.
This paper showed how a hybrid classifier mighttake advantage of multiple sentiment analysis ap-proaches and how these approaches perform in aTwitter dataset.A future direction of this work would be im-proving each individual classifier.
In our system,we used simple methods for each employed classi-fier.
Thus, we believe the hybrid classification tech-nique applied might achieve even better results.
Thisstrengthens our theory that hybrid techniques mightoutperform the current state-of-art in sentiment anal-ysis.AcknowledgmentsWe would like to thank the organizers for their workconstructing the dataset and overseeing the task.
Wealso would like to thank FAPESP and CNPq for fi-nancial support.571ReferencesApoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow,and Rebecca Passonneau.
2011.
Sentiment analysisof twitter data.
In Proceedings of the Workshop onLanguages in Social Media, LSM ?11, pages 30?38,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Enhanced sentiment learning using twitter hashtagsand smileys.
In Proceedings of the 23rd InternationalConference on Computational Linguistics: Posters,COLING ?10, pages 241?249, Stroudsburg, PA, USA.Association for Computational Linguistics.Tom De Smedt and Walter Daelemans.
2012.
Pattern forpython.
The Journal of Machine Learning Research,13:2063?2067.Nicholas A. Diakopoulos and David A. Shamma.
2010.Characterizing debate performance via aggregatedtwitter sentiment.
In Proceedings of the SIGCHI Con-ference on Human Factors in Computing Systems, CHI?10, pages 1195?1198, New York, NY, USA.
ACM.Akshay Java, Xiaodan Song, Tim Finin, and Belle Tseng.2007.
Why we twitter: understanding microbloggingusage and communities.
In Proceedings of the 9th We-bKDD and 1st SNA-KDD 2007 workshop on Web min-ing and social network analysis, WebKDD/SNA-KDD?07, pages 56?65, New York, NY, USA.
ACM.Arnd Christian Ko?nig and Eric Brill.
2006.
Reducing thehuman overhead in text categorization.
In Proceed-ings of the 12th ACM SIGKDD international confer-ence on Knowledge discovery and data mining, KDD?06, pages 598?603, New York, NY, USA.
ACM.Haewoon Kwak, Changhyun Lee, Hosung Park, and SueMoon.
2010.
What is twitter, a social network ora news media?
In Proceedings of the 19th inter-national conference on World wide web, WWW ?10,pages 591?600, New York, NY, USA.
ACM.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
In Proceedings of theACL-02 conference on Empirical methods in natu-ral language processing - EMNLP ?02, pages 79?86,Morristown, NJ, USA, July.
Association for Computa-tional Linguistics.Rudy Prabowo and Mike Thelwall.
2009.
Sentimentanalysis: A combined approach.
Journal of Informet-rics, 3(2):143?157.Maite Taboada, Julian Brooke, Milan Tofiloski, KimberlyVoll, and Manfred Stede.
2011.
Lexicon-Based Meth-ods for Sentiment Analysis.
Computational Linguis-tics, 37(2):267?307, June.Mike Thelwall, Kevan Buckley, Georgios Paltoglou,Di Cai, and Arvid Kappas.
2010.
Sentiment in shortstrength detection informal text.
Journal of the Amer-ican Society for Information Science and Technology,61(12):2544?2558, December.Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, SaraRosenthal, Veselin Stoyanov, and Alan Ritter.
2013.SemEval-2013 task 2: Sentiment analysis in twitter.In Proceedings of the International Workshop on Se-mantic Evaluation, SemEval ?13, June.572
