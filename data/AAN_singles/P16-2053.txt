Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 326?331,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsTransductive Adaptation of Black Box PredictionsSt?ephane Clinchant, Gabriela Csurka and Boris ChidlovskiiXerox Research Centre Europe6 chemin Maupertuis, Meylan, FranceFirstname.Lastname@xrce.xerox.comAbstractAccess to data is critical to any machinelearning component aimed at training anaccurate predictive model.
In reality, datais often a subject of technical and legalconstraints.
Data may contain sensitivetopics and data owners are often reluc-tant to share them.
Instead of access todata, they make available decision mak-ing procedures to enable predictions onnew data.
Under the black box classifierconstraint, we build an effective domainadaptation technique which adapts classi-fier predictions in a transductive setting.We run experiments on text categorizationdatasets and show that significant gainscan be achieved, especially in the unsuper-vised case where no labels are available inthe target domain.1 IntroductionWhile huge volumes of unlabeled data are gener-ated and made available in various domains, thecost of acquiring data labels remains high.
Do-main Adaptation problems arise each time whenone leverage labeled data in one or more relatedsource domains, to learn a classifier for unseendata in a target domain which is related, but notidentical.
The majority of domain adaptationmethods makes an assumption of largely avail-able source collections; this allows to measurethe discrepancy between distributions and eitherbuild representations common to both target andsources, or directly reuse source instances for abetter target classification (Xu and Sun, 2012).Numerous approaches have been proposed toaddress domain adaptation for statistical machinetranslation (Koehn and Schroeder, 2007), opin-ion mining, part of speech tagging and documentranking (Daum?e, 2009), (Pan and Yang, 2010),(Zhou and Chang, 2014).
Most effective tech-niques include feature replication (Daum?e, 2009),pivot features (Blitzer et al, 2006), (Pan et al,2010) and finding topic models shared by sourceand target collections (Chen and Liu, 2014).
Do-main adaptation has equally received a lot of at-tention in computer vision (Gopalan et al, 2015)where domain shift is a consequence of changingconditions, such as background, location and pose,etc.More recently, domain adaptation has beentackled with word embedding techniques or deeplearning.
(Bollegala et al, 2015) proposed an un-supervised method for learning domain-specificword embedding while (Yang and Eisenstein,2014) relied on word2vec models (Mikolov etal., 2013) to compute feature embedding.
Deeplearning has been considered as a generic solu-tion to domain adaptation (Vincent et al, 2008;Glorot et al, 2011), (Chopra et al, 2013) andtransfer learning problems (Long et al, 2015).For instance, denoising autoencoders are success-ful models which find common features betweensource and target collection.
They are trained toreconstruct input data from partial random corrup-tion and can be stacked into a multi-layered net-work where the weights are fine-tuned with back-propagation (Vincent et al, 2008) or marginalizedout (Chen et al, 2012).Domain adaptation is also very attractive forservice companies operating customer businessprocesses as it can reduce annotation costs.
Forinstance, opinion mining components deployed ina service solution can be customized to a new cus-tomer and adapted with few annotations in orderto achieve a contractual performance.But, in reality, the simplifying assumption ofhaving access to source data rarely holds and lim-its therefore the application of existing domain326adaptation methods.
Source data are often a sub-ject of legal, technical and contractual constraintsbetween data owners and data customers.
Often,customers are reluctant to share their data.
In-stead, they often put in place decision making pro-cedures.
This allows to obtain predictions for newdata under a black box scenario.
Note that thisscenario is different from the differential privacysetting (Dwork and Roth, 2014) in the sense thatno queries to the raw source database are allowedwhereas, in our case, only requests for predict-ing labels of target documents are permitted.
Thismakes privacy preserving machine learning meth-ods inapplicable here (Chaudhuri and Monteleoni,2008), (Agrawal and Srikant, 2000).In addition, black boxes systems are frequent innatural language processing applications.
For in-stance, Statistical Machine Translation (SMT) sys-tems are often used as black box to extract fea-tures (Specia et al, 2009).
Similarly, the prob-lem of adapting SMT systems for cross lingualretrieval has been addressed in (Nikoulina et al,2012) where target document collections cannotbe accessed and the retrieval engine works as ablack box.In this paper we address the problem of adapt-ing classifiers trained on the source data and avail-able as black boxes.
The case of available sourceclassifiers has been studied by (Duan et al, 2009)to regularize supervised target classifiers, but weconsider here a transductive setting, where thesource classifiers are used to predict class scoresfor a set of available target instances.We then apply the denoising principle (Vin-cent et al, 2008) and consider these predictionson target instances as corrupted by the domainshift from the source to target.
More precisely,we use the stacked Marginalized Denoising Au-toencoders (Chen et al, 2012) to reconstruct thepredictions by exploiting the correlation betweenthe target features and the predicted scores.
Thismethod has the advantage of coping with unsuper-vised cases where no labels in the target domain isavailable.
We test the prediction denoising methodon two benchmark text classification datasets anddemonstrate its capacity to significantly improvethe classification accuracy.2 Transductive Prediction AdaptationThe domain adaptation problem consists of lever-aging the source labeled and target unlabeled datato derive a hypothesis performing well on thetarget domain.
To achieve this goal, most DAmethods compute correlation between features insource and target domains.
With no access tosource data, we argue that the above principle canbe extended to the correlation between target fea-tures and the source class decisions.
We tunean adaptation trick by considering predicted classscores as augmented features for target data.
Inother words, we use the source classifiers as apivot to transfer knowledge from source to target.In addition, one can exploit relations between thepredictions scores and the target feature distribu-tion to provide adapted predictions.2.1 Marginalized Denoising AutoencoderThe stacked Marginalized Denoising Autoencoder(sMDA) is a version of the multi-layer neural net-work trained to reconstruct input data from partialrandom corruption (Vincent et al, 2008) proposedby (Chen et al, 2012), where the random corrup-tion is marginalized out yielding the optimal re-construction weights in the closed form.The basic building block of the method is a one-layer linear denoising autoencoder where a set ofN input documents xnare corrupted M timesby random feature dropout with the probabilityp.
It is then reconstructed with a linear mappingW : Rd?
Rdby minimizing the squared recon-struction loss1:L(W) =N?n=1M?m=1||xn?Wx?nm||2.
(1)Let?X be the concatenation of M replicated ver-sion of the original data and?X be the matrix rep-resentation of the M corrupted versions.Then, the solution of (1) can be expressed asthe closed-form solution for ordinary least squaresW = PQ?1with Q =?X?X>and P =?X?X>,where the solution depends on the re-sampling ofx1, .
.
.
,xNand which features are randomly cor-rupted.It is preferable to consider all possible corrup-tions of all possible inputs when the denoisingtransformation W is computed, i.e.
letting m ??.
By the weak law of large numbers, the ma-trices P and Q converge to their expected valuesE[Q],E[P] as more copies of the corrupted data1A constant is added to the input, xn= [xn; 1], and anappropriate bias, never corrupted, is incorporated within W.327are created.
In the limit, one can derive their ex-pectations and express the corresponding mappingfor W in a closed form as W = E[P]E[Q]?1,where:E[Q]ij=[Sijqiqj, if i 6= j,Sijqi, if i = j,and E[P]ij= Sijqjwhere q = [1 ?
p, .
.
.
, 1 ?p, 1] ?
Rd+1and S = XX>is the covariance ma-trix of the uncorrupted data.
This closed form de-noising layer with a unique noise p is referred inthe following as marginalized denoising autoen-coder (MDA).It was shown by (Chen et al, 2012) that MDAcan be applied with success to domain adaptationwhere the source set Xsand target set Xtare con-catenated to form X and the mapping W can ex-ploit the correlation between source and target fea-tures.
The case of fully available source and targetdata is referred as a dream case in the evaluationsection.2.2 Prediction AdaptationWithout access to Xs, MDA cannot be directly ap-plied to [Xs;Xt].
Instead, we augment the fea-ture set Xtwith the class predictions representedas vector fs(xt) of class predictions Ps(Y =y|xtn), n = 1, .
.
.
, N .
Let utn= [xtn; fs(xtn)]be the target instance augmented with the sourceclassifier predictions and U = [ut1ut2.
.
.utN] bethe input to the MDA.
Then we compute the op-timal mapping W?= minW||U ?W?U||2thattakes into account the correlation between the tar-get features xtand class predictions fs(xt).
Thereconstructed class predictions can be obtained asW?[1:N,d+1:d+C]?
fs(xt), where C is the numberof classes, and used to label the target data.
Al-gorithm 1 summarizes all steps of the transductiveprediction adaptation for a single source domain;the generalization to multiple sources is straight-forward2.3 Experimental resultsWe test our approach on two standard domainadaptation datasets: the Amazon reviews (AMT)and the 20Newsgroups (NG).
The AMT datasetconsists of products reviews with 2 classes (posi-tive and negative) represented by tf-idf normalized2It requires concatenating the class predictions from dif-ferent sources at step 1 and averaging the reconstructed pre-dictions per class at step 3.Algorithm 1 Transductive prediction adaptation.Require: Unlabeled target dataset Xt?
RN?d.Require: Class predictions fs(xt) = [Ps(Y =1|xti), .
.
.
, Ps(Y = C|xtn)] ?
RC.1: Compose U ?
RN?
(d+C)with utn=[xtn; fs(xtn)].2: Use MDA with noise level p to estimateW?= minW||U?W?U||2.3: Get the denoised class predictions for xtasyt= W?[1:N,d+1:d+C]?
fs(xt).4: Label xtwith c?= argmaxc{ytc|yt}.5: return Labels for Xt.bag-of-words, used in previous studies on domainadaptation (Blitzer et al, 2011).
We consider the10,000 most frequent features and four domainsused in the studies: kitchen (k), dvd (d), books (b)and electronics (e) with roughly 5,000 documentsper domain.
We use all the source dataset as train-ing and test on the whole target dataset.
We setthe MDA noise level p to high values (e.g.
0.9),as document representations are sparse and addinglow noise have no effect on the features alreadyequal to zero.In Table 1, we show the performance of theTransductive Prediction Adaptation (TPA) on 12adaptation tasks in the AMT dataset.
The firstcolumn shows the accuracies for the dream casewhere the standard MDA is applied to both sourceand target data.
The second column shows thebaseline results (fs(Xt)) obtained directly as classpredictions by the source classifier.
The classifica-tion model is an l2regularized Logistic Regres-sion3cross-validated with regularized parameterC ?
[0.0001, 0.001, 0.1, 1, 10, 50, 100].The two last columns show the results obtainedwith two versions of TPA (results are underlinedwhen improving over the baseline and in boldwhen yielding the highest values).
In the first ver-sion, target instances xtncontains only features(words and bigrams) appearing in the source docu-ments and used to make the predictions f(xtn).
Inthe second version, denoted as TPAe, we extendTPA with words unseen in the source documents.If the extension part is denoted vtn, we obtain anaugmented representation utn= [xtn;vtn; f(xtn)]as input to MDA.3We also experimented with other classifiers, such asSVM , Multinomial Naive Bayes, and obtained similar im-provement after applying TPA.
Results are not shown due tothe space limitation.328Table 1: TPA results on the AMT dataset.S ?
T MDA?fs(Xt) TPA TPAed?
b 84.59 81.36 82.61 83.19e?
b 78.07 73.87 75.93 79.95k ?
b 78.75 73.50 75.02 78.39b?
d 85.07 82.54 83.56 84.32e?
d 79.99 76.46 77.67 81.60k ?
d 80.76 77.58 79.16 81.92b?
e 80.32 76.44 78.54 81.81d?
e 83.70 78.65 80.75 82.89k ?
e 89.05 87.55 88.38 88.50b?
k 84.00 79.46 81.44 85.21d?
k 86.08 80.83 83.15 86.14e?
k 90.76 89.97 91.10 90.86Avg 83.4 79.85 81.44 83.73As we can see, both TPA and TPAe signifi-cantly outperform the baseline fs(Xt) obtainedwith no adaptation.
Furthermore, extending TPAwith words present in target documents only al-lows to further improve the classification accuracyin most cases.
Finally, TPAe often outperformsthe dream case and also on average (note howeverthat MDA?uses the features common to sourceand target documents as input).To understand the effect of prediction adapta-tion we analyze the book ?
electronics adapta-tion task.
In the mapping W, we sort the weightscorresponding to the correlation between the posi-tive class and the target features.
Features with thehighest weights (up-weighted by TPA) are great,my, sound, easy, excellent, good, easy to, best, yo, a great,when, well, the best.
On contrary, the words that gotthe smallest weight (down-weighted by TPA) areno, was, number, don?t, after, money, if, work, bad, get, buy.As TPA is totally unsupervised, we run addi-tional experiments to understand its practical use-fulness.
We compare TPA to the case of weaklyannotated target data, where few target examplesare labelled and used for training a target classi-fier.
Trained with 40, 100 and 200 target exam-ples, a logistic regression yields an average accu-racy of 64.63%, 68.01% and 75.13% over 12 tasksand a Multinomial Naives Bayes reports 65.82%,71.49% and 76%, respectively.
Even with 200labeled target documents, the target versus tar-get classification results are significantly belowthe 79.8% average accuracy of the baseline sourceclassifier.All these values are therefore significantly be-low the 83.73% obtained with TPAe.
This stronglysupports the domain adaptation scenario, when asentiment analysis classifier trained on a largersource set and adapted to target documents cando better than a classifier trained on a small setof labeled target documents.
Furthermore, wehave seen that the baseline can be significantly im-proved by TPA and even more by TPAe withoutthe need of even a small amount of manual label-ing of the target set.The second group of evaluation tests is on the20Newsgroup dataset.
It contains around 20,000documents of 20 classes and represents a stan-dard testbed for text categorization.
For the do-main adaptation, we follow the setting describedin (Pan et al, 2012).
We filter out rare words (ap-pearing less than 3 times) and keep at most 10,000features for each task with a tf-idf termweight-ing.
As all documents are organized as a hi-erarchy, the domain adaptation tasks are definedon category pairs with sources and targets cor-responding to subcategories.
For example, forthe ?comp vs sci?
task, subcategories such ascomp.sys.ibm.pc.hardware and sci.crypt are set assource domains and comp.sys.ibm.mac.hardwareand sci.med as targets, respectively.In our experiments we consider 5 adaptationtasks on category pairs ( ?comp vs sci?,?rec vs talk?,?rec vs sci?, ?sci vs talk?
and ?comp vs rec?
as in(Pan et al, 2012) ), and run the baseline, TPA andTPAe methods.
For each category pair, we addi-tionally inverse the source and target roles; thisexplains two sets of experimental results for eachpair.
We show the evaluation results in Table 2.
Itis easy to observe again the significant improve-ment over the baseline fs(xtn) and the positive ef-fect of including the unseen words in the TPA.Table 2: TPA results on the 20Newsgroup dataset.class pair fs(Xt) TPA TPAe?comp vs sci?
71.06 80.24 80.4365.4 71.6 71.98?rec vs talk?
65.66 68.01 70.1869.93 75.84 77.2?rec vs sci?
76.02 85.97 86.4274.17 81.14 82.71?sci vs talk?
76.1 80.22 81.374.92 80.07 80.19?comp vs rec?
86.63 91.56 92.0686.97 92.67 93.34Avg 74.69 80.73 81.584 ConclusionIn this paper we address the domain adaptationscenario without access to source data and wheresource classifiers are available as black boxes.
Inthe transductive setting, the source classifiers can329predict class scores for target instances, and weconsider these predictions as corrupted by domainshift.
We use the Marginalized Denoising Autoen-coders (Chen et al, 2012) to reconstruct the pre-dictions by exploiting the ?correlation?
betweenthe target features and the predicted scores.
Wetest the transductive prediction adaptation on twoknown benchmarks and demonstrate that it cansignificantly improve the classification accuracy,comparing to the baseline and to the case of fullaccess to source data.
This is an encouraging re-sult because it demonstrates that domain adapta-tion can still be effective despite the absence ofsource data.
Lastly, in the future, we would like toexplore the adaptation of other language process-ing components, such as named entity recognition,with our method.References[Agrawal and Srikant2000] Rakesh Agrawal and Ra-makrishnan Srikant.
2000.
Privacy-preserving datamining.
In ACM SIGMOD International Conferenceon Management of Data (SIGMOD), pages 439?450.
[Blitzer et al2006] John Blitzer, Ryan McDonald, andFernando Pereira.
2006.
Domain adaptation withstructural correspondence learning.
In InternationalConference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 120?128.
[Blitzer et al2011] John Blitzer, Sham Kakade, andDean P. Foster.
2011.
Domain adaptation with cou-pled subspaces.
In International Conference on Ar-tificial Intelligence and Statistics (AISTATS), pages173?181.
[Bollegala et al2015] Danushka Bollegala, TakanoriMaehara, and Ken-ichi Kawarabayashi.
2015.
Un-supervised cross-domain word representation learn-ing.
In Annual Meeting of the Association for Com-putational Linguistics(ACL), pages 730?740.
[Chaudhuri and Monteleoni2008] Kamalika Chaudhuriand Claire Monteleoni.
2008.
Privacy-preservinglogistic regression.
In Annual Conference on NeuralInformation Processing Systems (NIPS), pages 289?296.
[Chen and Liu2014] Zhiyuan Chen and Bing Liu.2014.
Topic modeling using topics from many do-mains, lifelong learning and big data.
In Inter-national Conference on Machine Learning (ICML),pages 703?711.
[Chen et al2012] Minmin Chen, Zhixiang Xu, Kil-ian Q. Weinberger, and Fei Sha.
2012.
Marginal-ized denoising autoencoders for domain adaptation.In International Conference on Machine Learning(ICML), pages 767?774.
[Chopra et al2013] Sumit Chopra, Suhrid Balakrish-nan, and Raghuraman Gopalan.
2013.
DLID: Deeplearning for domain adaptation by interpolating be-tween domains.
In ICML Workshop on Challengesin Representation Learning (WREPL).
[Daum?e2009] H. Daum?e.
2009.
Frustratingly easy do-main adaptation.
CoRR, arXiv:0907.1815.
[Duan et al2009] Lixin Duan, Ivor W. Tsang, DongXu, and Tat-Seng Chua.
2009.
Domain adapta-tion from multiple sources via auxiliary classifiers.In International Conference on Machine Learning(ICML), pages 289?296.
[Dwork and Roth2014] Cynthia Dwork and AaronRoth.
2014.
The algorithmic foundations ofdifferential privacy.
Foundations and Trends inTheoretical Computer Science, 9:211?407.
[Glorot et al2011] Xavier Glorot, Antoine Bordes, andYoshua Bengio.
2011.
Domain adaptation for large-scale sentiment classification: A deep learning ap-proach.
In International Conference on MachineLearning (ICML), pages 513?520.
[Gopalan et al2015] Raghuraman Gopalan, Ruonan Li,Vishal M. Patel, and Rama Chellappa.
2015.
Do-main adaptation for visual recognition.
Foundationsand Trends in Computer Graphics and Vision, 8(4).
[Koehn and Schroeder2007] Philipp Koehn and JoshSchroeder.
2007.
Experiments in domain adaptationfor statistical machine translation.
In ACL Work-shop on Statistical Machine Translation (STAT-MT),pages 224?227.
[Long et al2015] Mingsheng Long, Yue Cao, JianminWang, and Michael I. Jordan.
2015.
Learningtransferable features with deep adaptation networks.In International Conference on Machine Learning(ICML).
[Mikolov et al2013] Tomas Mikolov, Kai Chen, GregCorrado, and Jeffrey Dean.
2013.
Efficient estima-tion of word representations in vector space.
CoRR,arXiv:1301.3781.
[Nikoulina et al2012] Vassilina Nikoulina, BogomilKovachev, Nikolaos Lagos, and Christof Monz.2012.
Adaptation of statistical machine transla-tion model for cross-lingual information retrieval ina service context.
In Conference of the EuropeanChapter of the Association for Computational Lin-guistics (EACL), pages 109?119.
[Pan and Yang2010] Sinno J. Pan and Qiang Yang.2010.
A survey on transfer learning.
Transactionson Knowledge and Data Engineering, 22(10):1345?1359.
[Pan et al2010] Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang Yang, and Zheng Chen.
2010.Cross-domain sentiment classification via spectralfeature alignment.
In International Conference onWorld Wide Web (WWW).330[Pan et al2012] Weike Pan, Erheng Zhong, and YangQiang.
2012.
Transfer learning for text mining.
InCharu C. Aggarwal and ChengXiang Zhai, editors,Mining Text Data, pages 223?257.
Springer.
[Specia et al2009] Lucia Specia, Marco Turchi, NicolaCancedda, Marc Dymetman, and Nello N. Cristian-ini.
2009.
Estimating the sentence-level quality ofmachine translation systems.
In Annual Conferenceof the European Association for Machine Transla-tion (EAMT), pages 28?35.
[Vincent et al2008] Pascal Vincent, Hugo Larochelle,Yoshua Bengio, and Pierre-Antoine Manzagol.2008.
Extracting and composing robust featureswith denoising autoencoders.
In International Con-ference on Machine Learning (ICML).
[Xu and Sun2012] Zhijie Xu and Shiliang Sun.
2012.Multi-source transfer learning with multi-view ad-aboost.
In Annual Conference on Neural Infor-mation Processing Systems (NIPS), volume LNCS7665, pages 332?339.
Springer.
[Yang and Eisenstein2014] Yi Yang and Jacob Eisen-stein.
2014.
Unsupervised multi-domain adaptationwith feature embeddings.
In Annual Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies (NAACL HLT), pages 672?682.
[Zhou and Chang2014] Mianwei Zhou and Kevin C.Chang.
2014.
Unifying learning to rank and domainadaptation: Enabling cross-task document scoring.In ACM SIGKDD Conference on Knowledge Dis-covery and Data Mining (SIGKDD, pages 781?790.331
