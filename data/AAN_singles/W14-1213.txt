Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 114?122,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsClassifying easy-to-read texts without parsingJohan Falkenjack, Arne J?nssonDepartment of Information and Computer ScienceLink?ping University581 83, Link?ping, Swedenjohan.falkenjack@liu.se, arne.jonsson@liu.seAbstractDocument classification using automatedlinguistic analysis and machine learning(ML) has been shown to be a viable roadforward for readability assessment.
Thebest models can be trained to decide if atext is easy to read or not with very highaccuracy, e.g.
a model using 117 parame-ters from shallow, lexical, morphologicaland syntactic analyses achieves 98,9% ac-curacy.In this paper we compare models createdby parameter optimization over subsets ofthat total model to find out to which extentdifferent high-performing models tend toconsist of the same parameters and if it ispossible to find models that only use fea-tures not requiring parsing.
We used a ge-netic algorithm to systematically optimizeparameter sets of fixed sizes using accu-racy of a Support Vector Machine classi-fier as fitness function.Our results show that it is possible to findmodels almost as good as the currentlybest models while omitting parsing basedfeatures.1 IntroductionThe problem of readability assessment is the prob-lem of mapping from a text to some unit repre-senting the text?s degree of readability.
Measuresof readability are mostly used to inform a readerhow difficult a text is to read, either to give thema hint that they may try to find an easier to readtext on the same topic or simply to inform themthat a text may take some time to comprehend.Readability measures are mainly used to informpersons with reading disabilities on the complex-ity of a text, but can also be used to, for instance,assist teachers with assessing the reading ability ofa student.
By measuring the reading abilities of aperson, it might also be possible to automaticallyfind texts that fits that persons reading ability.Since the early 2000s the speed and accuracyof text analysis tools such as lemmatizers, part-of-speech taggers and syntax parsers have madenew text features available for readability assess-ment.
By using machine learning a number ofresearchers have devised innovative ways of as-sessing readability.
For instance, phrase grammarparsing has been used to find the average numberof sub-clauses, verb phrases, noun phrases and av-erage tree depth (Schwarm and Ostendorf, 2005).The use of language models to assess the de-gree of readability was also introduced in the early2000s (Collins-Thompson and Callan, 2004) andlater combined with classification algorithms suchas support vector machines to further increase ac-curacy (Petersen, 2007; Feng, 2010).In this paper we investigate if it is possible tofind a set of parameters for easy-to-read classifica-tion, on par with the best models used today, with-out using parsing based features.
Finding such aset would facilitate portability and provide fasterassessment of readability.2 MethodTo train and test our classifier we used one easy-to-read corpus and five corpora representing ordi-nary language in different text genres.
The lattercorpora is referred to as non-easy-to-read in thispaper.
For each category we used 700 texts.Our source of easy-to-read material was theL?SBarT corpus (M?hlenbock, 2008).
L?SBarTconsists of manually created easy-to-read texts114from a variety of sources and genres.The non-easy-to-read material comprised textsfrom a variety of corpora.
This material con-sisted of 215 news text articles from GP2007 (TheSwedish news paper G?teborgs Posten), 34 wholeissues of the Swedish popular science magazineForskning och Framsteg, 214 articles from theprofessional news magazine L?kartidningen 05(physician news articles), 214 public informationnotices from The Public Health Agency of Swe-den (Smittskyddsinstitutet) and 23 full fiction nov-els from a Swedish book publisher (the Norstedtspublishing house).By using a corpus with such a variety of doc-uments we got non-easy-to-read documents fromdifferent genres which is important as we want tobe able to use the same model on all types of text.We also lowered the risk of genre classificationrather than degree of readability classification.The texts were preprocessed using the Korp cor-pus import tool (Borin et al., 2012).
Steps in thepreprocessing chain relevant for this study weretokenization, lemmatisation, part-of-speech tag-ging and dependency grammar parsing.We used a large number of different text fea-tures proposed for readability assessment for bothSwedish and English.
We use both the term?sfeature (property of the text) and parameter (in-put to the ML-system).
Some features consist ofmore than one parameter.
In the paper we usethe terms features and parameters somewhat in-terchangeably.
However, technically, a feature isa property of the text, a parameter is input to themachine learning system.
A few of the text fea-tures we use are represented as a combination ofparameters and in these cases we select single pa-rameters, not full features.2.1 Non-parsing featuresThe three most used traditional text quality metricsused to measure readability for Swedish are:LIX L?sbarhetsindex, readability index.
Ratio ofwords longer than 6 characters coupled withaverage sentence length, Equation 1.
Thisis the standard readability measure used forSwedish and can be considered baseline sim-ilar to the Flesch-Kincaid formula (Kincaidet al., 1975).lix =n(w)n(s)+(n(words > 6 chars)n(w)?100)(1)where n(s) denotes the number of sentencesand n(w) the number of words.OVIX Ordvariationsindex, word variation index,related to type-token ratio.
Logarithms areused to cancel out type-token ratio problemswith variable text length, Equation 2.ovix =log(n(w))log(2 ?log(n(uw))log(n(w)))(2)where n(w) denotes the number of words andn(uw) the number of unique words.NR Nominal ratio, the ratio of nominal word,used to measure formality of text rather thanreadability, however, this is traditionally as-sumed to correlate to readability, Equation 3.Nr =n(noun) + n(prep) + n(part)n(pro) + n(adv) + n(v)(3)where n(noun) denotes the number ofnouns, n(prep) the number of prepositions,n(part) the number of participles, n(pro) thenumber of pronouns, n(adv) the number ofadverbs, and n(v) the number of verbs.2.1.1 Shallow featuresThe shallow text features are the main featurestraditionally used for simple readability metrics.They occur in the "shallow" surface structure ofthe text and can be extracted after tokenization bysimply counting words and characters.
They in-clude:AWLC Average word length calculated as the av-erage number of characters per word.AWLS Average word length calculated as the av-erage number of syllables per word.
Thenumber of syllables is approximated bycounting the number of vowels.ASL Average sentence length calculated as theaverage number of words per sentence.115Longer sentences, as well as longer words, tendto predict a more difficult text as exemplified bythe performance of the LIX metric and related met-rics for English.
These types of features havebeen used in a number of readability studies basedon machine learning (Feng, 2010) and as baselinewhen evaluating new features (Pitler and Nenkova,2008).2.1.2 Lexical featuresOur lexical features are based on categorical wordfrequencies.
The word frequencies are extractedafter lemmatization and are calculated usingthe basic Swedish vocabulary SweVoc (HeimannM?hlenbock, 2013).
SweVoc is comparable to thelist used in the classic Dale-Chall formula for En-glish (Dale and Chall, 1949).
Though developedfor similar purposes, special sub-categories havebeen added (of which three are specifically consid-ered).
The following frequencies are calculated,based on different categories in SweVoc:SweVocC SweVoc lemmas fundamental for com-munication (category C).SweVocD SweVoc lemmas for everyday use (cat-egory D).SweVocH SweVoc other highly frequent lemmas(category H).SweVocT Unique, per lemma, SweVoc words (allcategories, including some not mentionedabove) per sentence.A high ratio of SweVoc words should indicate amore easy-to-read text.
The Dale-Chall metric(Chall and Dale, 1995) has been used as a simi-lar feature in a number of machine learning basedstudies of text readability for English (Feng, 2010;Pitler and Nenkova, 2008).
The SweVoc metricsare also related to the language model featuresused in a number of studies (Schwarm and Osten-dorf, 2005; Heilman et al., 2008).2.1.3 The morpho-syntactic featuresThe morpho-syntactic features concern a morphol-ogy based analysis of text.
For the purposes ofthis study the analysis relies on previously part-of-speech annotated text, which is investigated withregard to the following features:Part-of-speech tag ratio Unigram probabilitiesfor the different parts-of-speech tags in thedocument, that is, the ratio of each part-of-speech, on a per token basis, as individualparameters.
This is viewed as a single featurebut is represented by 26 parameters, see Ta-ble 2.
Such a language model based on part-of-speech, and similar metrics, has shown tobe a relevant feature for readability assess-ment for English (Heilman et al., 2007; Pe-tersen, 2007; Dell?Orletta et al., 2011) andfor Swedish (Falkenjack et al., 2013).RC The ratio of content words (nouns, verbs, ad-jectives and adverbs), on a per token basis,in the text.
Such a metric has been used ina number of related studies (Alusio et al.,2010).2.2 Parsing based featuresThese features are estimable after syntactic pars-ing of the text.
The syntactic feature set is ex-tracted after dependency parsing using the Malt-parser (Nivre et al., 2006).
Such parsers have beenused for preprocessing texts for readability assess-ment for Italian (Dell?Orletta et al., 2011).
Thedependency based features consist of:ADDD The average dependency distance in thedocument on a per dependent basis.
A longeraverage dependency distance could indicate amore complex text (Liu, 2008).ADDS The average dependency distance in thedocument on a per sentence basis.
Alonger average total dependency distanceper sentence could indicate a more complextext (Liu, 2008).RD The ratio of right dependencies to total num-ber of dependencies in the document.
A highratio of right dependencies could indicate amore complex text.SD The average sentence depth.
Sentences withdeeper dependency trees could be indicativeof a more complex text in the same wayas phrase grammar trees has been shown tobe (Petersen and Ostendorf, 2009).Dependency type tag ratio Unigram probabili-ties for the dependency type tags resultingfrom the dependency parsing, on a per to-ken basis, as individual parameters.
Thisis viewed as a single feature but is repre-sented by 63 parameters, see Tables 4 and 5.116These parameters make up a unigram lan-guage model and is comparable to the phrasetype rate based on phrase grammar pars-ing used in earlier research (Nenkova et al.,2010).
Such a language model was shown tobe a good predictor for degree of readabilityin Swedish text (Falkenjack et al., 2013).VR The ratio of sentences with a verbal root, thatis, the ratio of sentences where the root wordis a verb to the total number of sentences(Dell?Orletta et al., 2011).AVA The average arity of verbs in the document,calculated as the average number of depen-dents per verb (Dell?Orletta et al., 2011).UVA The ratio of verbs with an arity of 0-7 asdistinct features (Dell?Orletta et al., 2011).This is viewed as a single feature but is rep-resented by 8 parameters.TPC The average number of tokens per clause inthe document.
This is related to the shallowfeature average number of tokens per sen-tence.PreM The average number of nominal pre-modifiers per sentence.PostM The average number of nominal post-modifiers per sentence.PC The average number of prepositional comple-ments per sentence in the document.Compound models We have also created a num-ber of compound models, comprising metricsfrom sets of features; all traditional measures,all shallow features, all lexical features, allmorpho-syntactic features, all syntactic fea-tures, and all features (Total), see Table 3.Falkenjack et al.
(2013) also looked at incre-mental combinations of these same models.2.3 Parameter optimizationThe models for parameter optimization are cre-ated from various subsets of the text features us-ing a genetic algorithm.
Lau (2006) performedexperiments on using genetic algorithms to selectsignificant features that are useful when assessingreadability for Chinese.
Starting with 64 features,mainly various stroke features but also more tra-ditional features, such as, measuring amount offamiliar and common words, a genetic algorithmwas used to find optimal feature subsets.
Based oninvestigations of using three different fitness func-tions it was shown that a set of 15 features is suffi-cient and the best feature set for each fitness func-tion is selected for further studies.
These featuresets are then evaluated using SVR (Support VectorRegression) to train readability models and finallytest them on the texts.In our work we do not first select feature setsand then train the model on them.
Instead featuresets, generated by genetic search, are used to trainthe readability model, using SVM, and then themodels are tested.We performed a number of trials based on dif-ferent base sets of parameters.
In each case thespace we searched through had the size(|b|s),where b is the base set of parameters and s is thesize of the model we were searching for.We performed genetic searches through modelspaces for 1000 generations.
Each generation con-tained 10 chromosomes, i.e.
models, 7 created bycrossover and 3 randomly generated to avoid get-ting stuck in local maxima.The crossover worked by randomly selectingparameters from the locally optimal parameter setof the prior generation.
This locally optimal pa-rameter set was created by taking the union of thebest performing chromosomes until the size of theset exceeded the size of the target selection plus 4.In the rare cases where the parameters in thetotal parent generation did not exceed this num-ber all parameters from the parent generation wereused.The fitness function consisted of a 7-fold cross-validation test run of a Support Vector Ma-chine trained by Sequential Minimal Optimization(Platt, 1998).
For this we used the Waikato Envi-ronment for Knowledge Analysis, or Weka.
Theaccuracy of a model was used as its fitness andused to order each generation from best to worstperforming.3 ResultsWe first present results from using only the sin-gle features and the compound models.
We thenpresent the results from the various models gener-ated by our method.We provide performance measures for singlefeatures for comparison in Tables 1 and 2.
Theperformance for the 63 dependency types are pre-sented in Tables 4 and 5.117L?SBarT OtherModel Accuracy Prec.
Rec.
Prec.
Rec.LIX 84.6 (1.9) 87.9 80.4 82.0 88.9OVIX 85.6 (2.3) 86.8 84.4 84.9 86.9NR 55.3 (9.1) 53.5 99.1 96.0 11.4AWLC 79.6 (2.6) 82.3 75.7 77.4 83.4AWLS 75.6 (2.6) 78.7 70.3 73.1 80.9ASL 62.4 (8.1) 58.0 98.7 97.8 26.1SweVocC 79.3 (0.8) 84.3 72.0 75.6 86.6SweVocD 57.6 (3.8) 63.1 37.9 55.5 77.4SweVocH 63.1 (4.5) 63.1 63.4 63.2 62.9SweVocT 75.2 (1.4) 80.6 66.7 71.6 83.7POS-tags 96.8 (1.6) 96.9 96.7 96.7 96.9RC 50.4 (1.8) 50.4 52.7 50.4 48.1ADDD 88.5 (2.0) 88.5 88.6 88.6 88.4ADDS 53.9 (10.2) 52.8 99.7 28.1 8.1RD 68.9 (2.1) 70.6 65.1 67.7 72.7SD 75.1 (3.5) 79.1 68.4 72.2 81.9Dep-tags 97.9 (0.8) 97.7 98.0 98.0 97.7VR 72.6 (2.0) 77.0 64.6 69.5 80.6AVA 63.4 (3.0) 64.9 58.4 62.3 68.4UVA 68.6 (1.7) 70.2 65.0 67.4 72.3TPC 71.4 (4.7) 64.2 98.6 97.0 44.3PreM 83.4 (2.9) 78.1 93.0 91.3 73.9PostM 57.4 (4.3) 54.1 99.9 98.4 15.0PC 83.5 (3.5) 80.1 89.1 88.1 77.9Table 1: Performance of the single feature models.The accuracy represents the average percentage oftexts classified correctly, with the standard devia-tion within parentheses.
Precision and Recall arealso provided for both easy-to-read (L?SBarT) andnon-easy-to-read (Other) sets.
Italicized featuresconsist of more than one parameter.The results from using the full sets before pa-rameter optimization are listed in Table 3.
Usingall features provides the best model with 98.9%accuracy which could be considered the target ac-curacy of our parameter optimization.3.1 POS-ratio featuresThe first trial we performed was a search throughthe parameter space containing ratios of part-of-speech unigrams.
As our data contained 26 differ-ent POS-tags (additional morphological data wasignored in this search) the size of the spaces were(26s)where s is the size of the model we were op-timizing.
For 3-parameter models this is no largerthan(263)= 2600 while the maximum size is(2613)= 10400600.
We searched for optimal sub-sets of sizes from 1 to 25.
The best models arepresented in Table 6 and the performance resultsin Table 8.
Models comprising more than 10 fea-L?SBarT OtherModel Accuracy Prec.
Rec.
Prec.
Rec.VB 87.6 (1.7) 89.2 85.9 86.5 89.4MAD 87.1 (0.9) 91.1 82.3 83.9 91.9PAD 79.5 (1.6) 71.8 97.4 96.0 61.6MID 76.6 (2.9) 78.6 73.3 74.9 79.9PP 72.4 (3.8) 73.7 69.7 71.4 75.0PN 72.1 (2.7) 79.2 60.4 67.9 83.9NN 70.4 (2.6) 75.4 61.4 67.3 79.4DT 67.7 (3.3) 67.9 67.6 67.6 67.9PL 65.6 (2.5) 70.4 53.9 62.8 77.4JJ 64.1 (4.3) 63.6 65.7 64.7 62.4HA 62.4 (1.1) 66.5 49.9 59.9 74.9SN 59.4 (3.7) 64.7 42.1 57.0 76.7UO 58.2 (8.2) 55.1 98.4 94.6 18.0KN 56.6 (3.0) 57.9 48.9 55.7 64.4AB 56.0 (3.2) 58.4 43.0 54.7 69.0IN 53.0 (5.1) 60.0 78.7 16.1 27.3IE 52.6 (2.4) 61.5 19.0 51.5 86.1PS 52.6 (1.4) 59.4 17.7 51.5 87.4HP 52.5 (5.4) 69.9 24.0 47.2 81.0HS 52.4 (2.0) 51.2 99.7 89.3 5.0RG 51.6 (3.5) 51.1 96.9 69.6 6.4HD 50.4 (0.7) 50.2 31.7 35.9 69.1PLQS 50.0 (0.0) 50.0 100.0 0.0 0.0RO 49.7 (0.9) 49.8 89.3 48.8 10.1PM 49.7 (1.3) 49.8 95.0 54.9 4.4Table 2: Performance of the POS-tag ratio param-eters ordered by performance.
The various mod-els are tags used in the SUC corpus (Ejerhed etal., 2006), normally part of speech tags, e.g.
VB isverb, with some extensions, but the tags compriseother features as well e.g.
MAD comprises sen-tence terminating delimiters, PAD pair-wise de-limiters such as parentheses and MID other delim-iters such as comma and semicolon.
Measures asdescribed in Table 1.L?SBarT OtherModel Acc.
Pre.
Rec.
Pre.
Rec.TradComb 91.4 (3.0) 92.0 91.0 91.1 91.9Shallow 81.6 (2.7) 83.3 79.4 80.3 83.9Lexical 78.4 (2.2) 81.8 73.0 75.6 83.7Morpho 96.7 (1.6) 96.8 96.7 96.7 96.7Syntactic 98.0 (1.1) 97.9 98.1 98.1 97.9Total 98.9 (1.0) 98.9 98.9 98.9 98.9Table 3: Performance of the full feature sets.
Mea-sures as described in Table 1.tures are omitted as no significant performance im-provement is measured beyond this point.
See Ta-ble 7 for sizes.118L?SBarT Other# Accuracy Prec.
Rec.
Prec.
Rec.IP 89.4 (1.7) 92.9 85.3 86.5 93.4SS 87.4 (2.9) 88.2 86.4 86.7 88.3ROOT 83.0 (2.4) 88.0 76.4 79.2 89.6AT 78.1 (4.0) 75.9 82.9 81.0 73.3ET 77.7 (2.4) 79.6 74.7 76.3 80.7JR 76.4 (6.4) 69.0 97.7 96.0 55.0AN 76.2 (2.5) 72.3 85.6 82.4 66.9IQ 73.1 (2.1) 67.0 90.7 85.9 55.4IK 72.5 (2.5) 75.0 67.9 70.6 77.1OO 72.2 (5.3) 74.4 67.4 70.4 77.0IR 72.1 (3.4) 64.7 97.9 95.6 46.3DT 70.4 (1.4) 73.4 64.4 68.3 76.4VG 70.0 (2.4) 81.1 52.1 64.8 87.9PL 66.8 (2.7) 70.8 57.7 64.3 75.9JC 64.8 (4.3) 59.1 97.4 92.4 32.1CJ 64.0 (3.6) 62.2 71.7 66.6 56.3HD 62.5 (2.7) 59.0 84.7 73.2 40.3IC 61.3 (4.3) 56.8 97.1 90.8 25.4OA 61.0 (3.4) 66.9 43.3 58.2 78.7SP 60.7 (2.0) 67.4 42.4 57.9 79.0I?
60.6 (1.3) 78.4 29.3 56.5 91.9+A 60.1 (2.3) 58.6 68.9 62.4 51.4TA 59.8 (2.5) 63.9 46.0 57.7 73.6AG 59.7 (2.2) 57.0 81.6 68.4 37.9NA 59.5 (3.5) 63.3 45.0 57.5 74.0+F 59.0 (3.3) 64.4 40.4 56.6 77.6UA 58.6 (3.9) 63.7 41.1 56.3 76.1VA 58.2 (6.1) 56.2 85.3 67.1 31.1MS 57.5 (1.8) 62.5 38.3 55.4 76.7KA 57.5 (3.6) 75.6 35.4 47.3 79.6Table 4: Performance of the Dependency type ra-tio attributes ordered by performance.
Measuresas described in Table 1 Continued in table 5.3.2 Non-syntactic featuresThe second trial we performed was a searchthrough the parameter space of all non-syntacticfeatures.
As our data contained 37 such param-eters the size of the spaces were(37s)where sis the size of the model we were optimizing.For 3-parameter models this is no larger than(373)= 7770 while the maximum size is(3719)=17672631900.
We searched for optimal subsetsof sizes from 1 to 25.
The best models are pre-sented in Table 9 and the performance results inTable 10.
Models larger than 8 are omitted as nosignificant performance improvement is measuredbeyond this point.L?SBarT Other# Accuracy Prec.
Rec.
Prec.
Rec.IT 56.5 (1.8) 54.1 86.7 66.6 26.3PT 55.7 (2.9) 53.6 85.0 63.7 26.4IS 55.6 (5.9) 53.1 99.9 85.0 11.3JT 55.5 (3.8) 53.0 99.6 94.0 11.4AA 55.4 (3.1) 57.4 42.1 54.3 68.7IG 55.4 (2.8) 52.9 99.4 97.0 11.3IU 55.1 (2.4) 82.4 26.1 45.6 84.0RA 54.8 (2.5) 65.7 31.4 53.8 78.1IO 54.4 (2.3) 63.6 33.4 45.5 75.4MA 54.3 (3.3) 68.4 18.0 52.4 90.6FS 53.8 (2.3) 72.9 12.0 52.1 95.6CA 53.6 (3.9) 53.2 60.3 54.1 46.9XX 53.0 (1.6) 69.4 24.7 44.5 81.3ES 52.9 (1.7) 77.0 22.1 44.4 83.7EF 52.4 (4.4) 52.4 75.4 41.4 29.4++ 52.3 (1.7) 51.3 93.6 65.0 11.0XA 52.1 (1.7) 51.1 97.6 65.4 6.7XT 52.1 (2.2) 51.2 97.0 50.9 7.3EO 51.8 (2.4) 36.7 70.4 60.4 33.1IF 51.2 (2.3) 55.4 39.7 48.1 62.7FP 51.0 (1.3) 61.3 60.1 22.0 41.9JG 51.0 (1.7) 29.1 57.0 48.6 45.0DB 50.6 (0.9) 63.5 48.7 28.9 52.6IV 50.5 (0.5) 75.0 44.0 28.8 57.0OP 50.4 (0.9) 36.0 65.3 21.8 35.4FO 50.2 (0.3) 57.1 29.0 35.8 71.4VS 50.1 (0.4) 43.8 72.7 14.4 27.6YY 50.0 (0.0) 50.0 100.0 0.0 0.0XF 49.9 (0.2) 50.0 85.1 14.1 14.7FV 49.8 (1.0) 55.6 57.9 21.3 41.7VO 49.8 (3.3) 52.9 73.3 15.6 26.3Table 5: Performance of the Dependency type ra-tio attributes ordered by performance.
Measuresas described in Table 1.
Continued from table 4.# Set2 VB, MAD3 MAD, VB, MID4 VB, PAD, MID, MAD5 MAD, VB, MID, PAD, PM6 MID, VB, HA, PAD, AB, MAD7 PAD, JJ, PN, VB, MAD, KN, MID8 PAD, HD, PM, MID, PN, VB, PL, MAD9 PAD, SN, PLQS, MAD, DT, VB, RG, PM, MID10 MAD, PM, PAD, KN, MID, PLQS, IE, VB, HA, DTTable 6: Features in the best performing sets foundfor each size by the genetic search through thePOS-ratio space.4 DiscussionFrom the models using POS-ratio features, Tables6 and 8, we see that it is possible to find models119# Size1 and 25 262 and 24 3253 and 23 2 6004 and 22 14 9505 and 21 65 7806 and 20 230 2307 and 19 657 8008 and 18 1 562 2759 and 17 3 124 55010 and 16 5 311 73511 and 15 7 726 16012 and 14 9 657 70013 10 400 600Table 7: Sizes of model space based on number ofattributes in the target model.L?SBarT OtherModel Accuracy Prec.
Rec.
Prec.
Rec.2 95.4 (1.5) 94.7 96.3 96.2 94.63 96.4 (0.9) 96.2 96.7 96.7 96.14 96.9 (1.0) 97.0 96.9 96.9 97.05 97.0 (1.1) 97.0 97.0 97.0 97.06 97.0 (1.2) 97.6 96.4 96.5 97.67 97.0 (1.1) 96.8 97.3 97.3 96.78 96.9 (1.1) 96.9 97.0 97.0 96.99 96.9 (1.3) 96.8 97.1 97.1 96.710 97.4 (1.1) 97.6 97.1 97.2 97.6All(26) 96.8 (1.6) 96.9 96.7 96.7 96.9Table 8: Performance of the feature sets selectedfrom the set of POS-tag ratio features ordered bynumber of parameters.
Measures as described inTable 1.# Set2 OVIX, MAD3 OVIX, MAD, MID4 MID, PAD, MAD, OVIX5 MAD, OVIX, VB, SN, SweVocT6 MAD, HD, MID, PL, OVIX, SweVocC7 MAD, AB, PP, HD, MID, OVIX, DT8 MID, AB, PAD, OVIX, MAD, SweVocH, HS, RGTable 9: Features in the best performing sets foundfor each size by the genetic search through thenon-syntactic space.that outperform most single feature models.
Wehave in Table 8 included the performance of thefull, 26 feature, model which shows that perfor-mance might be increased slightly by filtering outconfusing features.L?SBarT OtherModel Accuracy Prec.
Rec.
Prec.
Rec.2 96.6 (1.0) 95.5 98.0 98.0 95.33 97.4 (1.3) 97.3 97.4 97.5 97.34 98.2 (1.3) 97.8 98.7 98.7 97.75 97.9 (1.2) 97.1 98.9 98.8 97.06 98.0 (1.0) 97.2 98.9 98.8 97.17 97.8 (1.3) 97.1 98.6 98.6 97.08 98.5 (1.0) 97.9 99.1 99.1 97.9All (37) 98.3 (1.0) 97.4 99.3 99.3 97.3Table 10: Performance of the feature sets selectedfrom the set of all non- syntactic features orderedby number of parameters.
Measures as describedin Table 1.We can also see that the sets beyond 4 param-eters do not fully correlate to the best performingsingle parameters in the parameter space.
This im-plies that combinations of some features may bebetter predictors than the individual features.When we search through all non-syntactic fea-tures we get results similar to the POS-ratio spacesearch.
While the first generated sets seem toconsist of the best performing single parameters,larger models seem to be more "exotic" using lowperforming single parameters to create strongercombination effects, see Table 9.The most interesting result here is that a modelwith 8 non-syntactic parameters, model 8 in Ta-ble 10, performs almost as well (-0.4 pp) as the117 parameter total model, see Table 3.Another interesting result is that the ratioof verbs (VB in Table 2) has an accuracy of87.6%, only outperformed by the syntactic featureADDD.Even more interesting is the fact that the ratioof sentence terminating delimiters (MAD in Table2) has such high performance.
Especially as theaverage sentence length (ASL) is not a very goodpredictor of readability, see Table 3 and Falken-jack et al.
(2013).Theoretically, the ratio of MADs is the inverseof the ASL and as such their performance shouldalign.
However, the two metrics are calculateddifferently, sentence length is based on parsingdata and MAD ratio is based on POS-tagging data.While a sentence should contain exactly one MADthere are instances where more than one (informallanguage, transcribed spoken language, misiden-tified ellipsis, quotations etc.)
or less than one(bullet points, tables etc.)
might occur in the ac-120tual text.
It should be noted that if the aforemen-tioned is true MAD might rather be a style predic-tor than a direct readability predictor.
However, inthat case style and readability appears to correlatewhich is not surprising.We further note how much accuracy can be im-proved by combining very few measures.
For in-stance, OVIX gives an accuracy of only 85.6% andMAD gives 87.1%, but combined they give 96.6%,set 2 in Table 105 ConclusionIn this paper we introduced and evaluated amethod for finding optimal subsets of text featuresfor readability based document classification.
Themethod uses genetic search to systematically gen-erate models using various sets of text features.
Asfitness function for the genetic algorithm we usedSVM created models that were 7-fold cross vali-dated on one easy-to-read corpus and one corpusof regular texts.Our results show that, at least for Swedish, itis possible to find models almost as good the cur-rently best models while omitting parsing basedfeatures.
Our algorithm found a model of 8 non-syntactic parameters which predicted readabilitywith an accuracy of 98.5%.
This is almost as accu-rate as a 117 parameter model, including parsingbased features, with an accuracy of 98.9%Our study was conducted for Swedish texts butonly a few of the metrics used are specific toSwedish and the optimization method itself is lan-guage independent, thus, the method can easilybe applied to other languages.
The method canbe used for optimization of readability assessmentsystems as well as for basic linguistic research intoreadability.AcknowledgmentsWe would like to thank Stiftelsen Marcus ochAmalia Wallenbergs Minnesfond and SICS EastSwedish ICT AB for funding this research as wellas the staff members at Spr?kbanken who createdand let us use the Korp corpus import tool.ReferencesSandra Alusio, Lucia Specia, Caroline Gasperin, andCarolina Scarton.
2010.
Readability assessment fortext simplification.
In Proceedings of the NAACLHLT 2010 Fifth Workshop on Innovative Use of NLPfor Building Educational Applications, pages 1?9.Lars Borin, Markus Forsberg, and Johan Roxendal.2012.
Korp ?
the corpus infrastructure of Spr?k-banken.
In Proceedings of the Eighth InternationalConference on Language Resources and Evaluation(LREC?12).Jeanne S. Chall and Edgar Dale.
1995.
Readabilityrevisited: The new Dale?Chall readability formula.Brookline Books, Cambride, MA.Kevyn Collins-Thompson and Jamie Callan.
2004.
ALanguage Modeling Approach to Predicting Read-ing Difficulty.
In Proceedings of the Human Lan-guage Technology Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics.Edgar Dale and Jeanne S. Chall.
1949.
The concept ofreadability.
Elementary English, 26(23).Felice Dell?Orletta, Simonetta Montemagni, and Giu-lia Venturi.
2011.
READ-IT: Assessing Readabil-ity of Italian Texts with a View to Text Simplifica-tion.
In Proceedings of the 2nd Workshop on Speechand Language Processing for Assistive Technolo-gies, pages 73?83, July.Eva Ejerhed, Gunnel K?llgren, and Benny Brodda.2006.
Stockholm Ume?
Corpus version 2.0.Johan Falkenjack, Katarina Heimann M?hlenbock, andArne J?nsson.
2013.
Features indicating read-ability in Swedish text.
In Proceedings of the19th Nordic Conference of Computational Linguis-tics (NoDaLiDa-2013), Oslo, Norway, NEALT Pro-ceedings Series 16.Lijun Feng.
2010.
Automatic Readability Assessment.Ph.D.
thesis, City University of New York.Michael J. Heilman, Kevyn Collins-Thompson, JamieCallan, and Maxine Eskenazi.
2007.
CombiningLexical and Grammatical Features to Improve Read-ability Measures for First and Second LanguageTexts.
In Proceedings of NAACL HLT 2007, pages460?467.Michael J. Heilman, Kevyn Collins-Thompson, andMaxine Eskenazi.
2008.
An Analysis of Statisti-cal Models and Features for Reading Difficulty Pre-diction.
In Proceedings of the Third ACL Workshopon Innovative Use of NLP for Building EducationalApplications, pages 71?79, June.Katarina Heimann M?hlenbock.
2013.
I see whatyou mean.
Assessing readability for specific tar-get groups.
Dissertation, Spr?kbanken, Dept ofSwedish, University of Gothenburg.J.
P. Kincaid, R. P. Fishburne, R. L. Rogers, and B. S.Chissom.
1975.
Derivation of new readability for-mulas (Automated Readability Index, Fog Count,and Flesch Reading Ease Formula) for Navy enlistedpersonnel.
Technical report, U.S.
Naval Air Station,Millington, TN.121Tak Pang Lau.
2006.
Chinese readability analysis andits applications on the internet.
Master?s thesis, TheChinese University of Hong Kong.Haitao Liu.
2008.
Dependency distance as a metric oflanguage comprehension difficulty.
Journal of Cog-nitive Science, 9(2):169?191.Katarina M?hlenbock.
2008.
Readable, Legibleor Plain Words ?
Presentation of an easy-to-readSwedish corpus.
In Anju Saxena and ?ke Viberg,editors, Multilingualism: Proceedings of the 23rdScandinavian Conference of Linguistics, volume 8of Acta Universitatis Upsaliensis, pages 327?329,Uppsala, Sweden.
Acta Universitatis Upsaliensis.Ani Nenkova, Jieun Chae, Annie Louis, and EmilyPitler.
2010.
Structural Features for Predicting theLinguistic Quality of Text Applications to MachineTranslation, Automatic Summarization and Human?Authored Text.
In E. Krahmer and M. Theune, ed-itors, Empirical Methods in NLG, pages 222?241.Springer-Verlag.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006.MaltParser: A Data-Driven Parser-Generator forDependency Parsing.
In Proceedings of the fifth in-ternational conference on Language Resources andEvaluation (LREC2006), pages 2216?2219, May.Sarah Petersen and Mari Ostendorf.
2009.
A machinelearning approach toreading level assessment.
Com-puter Speech and Language, 23:89?106.Sarah Petersen.
2007.
Natural language processingtools for reading level assessment and text simplifi-cation for bilingual education.
Ph.D. thesis, Univer-sity of Washington, Seattle, WA.Emily Pitler and Ani Nenkova.
2008.
Revisiting Read-ability: A Unified Framework for Predicting TextQuality.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Process-ing, pages 186?195, Honolulu, HI, October.John C. Platt.
1998.
Sequential Minimal Optimiza-tion: A Fast Algorithm for Training Support VectorMachines.
Technical Report MSR-TR-98-14, Mi-crosoft Research, April.Sarah E. Schwarm and Mari Ostendorf.
2005.
Readinglevel assessment using support vector machines andstatistical language models.
In Proceedings of the43rd Annual Meeting of the Association for Compu-tational Linguistics.Johan Sj?holm.
2012.
Probability as readability:A new machine learning approach to readabilityassessment for written Swedish.
Master?s thesis,Link?ping University.122
