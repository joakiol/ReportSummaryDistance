Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 1?5,Baltimore, Maryland, USA, June 22-27, 2014.c?2014 Association for Computational LinguisticsAugmenting FrameNet Via PPDBPushpendre Rastogi1and Benjamin Van Durme1,21Center for Language and Speech Processing2Human Language Technology Center of ExcellenceJohns Hopkins Universitypushpendre@jhu.edu, vandurme@cs.jhu.eduAbstractFrameNet is a lexico-semantic dataset thatembodies the theory of frame semantics.Like other semantic databases, FrameNetis incomplete.
We augment it via the para-phrase database, PPDB, and gain a three-fold increase in coverage at 65% precision.1 IntroductionFrame semantics describes the meaning of a wordin relation to real world events and entities.
Inframe semantics the primary unit of lexical analy-sis is the frame and the lexical unit.
A frame aimsto capture the most salient properties of a con-cept, situation or event.
For example, the framerepresenting the concept of Abandonment con-tains eight attributes:1Agent, Theme, Place,Time, Manner, Duration, Explanationand Depictive.
A lexical unit is a tuple of threeelements: the lemma of a word, its POS tag andthe associated frame.FrameNet is large lexico-semantic dataset thatcontains manually annotated information includ-ing frame descriptions, frame-frame relations andframe annotated sentences.
It has been used buildto frame semantic parsers, which are systems thatcan analyze a sentence and annotate its words withthe frames that they evoke and the correspond-ing frame elements.
The task of frame seman-tic parsing was introduced by Gildea and Jurafsky(2002) and later it matured into a community-wideshared task (Baker et al., 2007), with CMU?s SE-MAFOR system being the current state-of-the-artparser (Das et al., 2013).Common to rich, manually constructed seman-tic resources, the coverage of FrameNet across its1An attribute of a frame is also called a Frame Element.targetted language (English) is incomplete.
State-of-the-art frame semantic parsers thus employ var-ious heuristics to identify the frame evoked byout-of-vocabulary items (OOVs) at test-time.2Forinstance, an OOV if present in WordNet mightbe aligned to frame(s) assigned to in-vocabularyitems in shared synsets (see the work by Ferr?andezet al.
(2010) and the related works section therein).In this work we take a different approach andattempt to directly increase the coverage of theFrameNet corpus by automatically expanding thecollection of training examples via PPDB, TheParaphrase Database (Ganitkevitch et al., 2013).In Section 2 we analyze FrameNet and com-ment on the sparsity in its different parts.
In Sec-tion 3 we describe PPDB, and how it was used toaugment FrameNet.
We present our evaluation ex-periments and results in the latter half of the sec-tion followed by conclusions.2 FrameNet CoverageFrameNet is a rich semantic resource, yet cur-rently lacks complete coverage of the language.In the following we give examples of this incom-pleteness, in particular the OOV issue that we willfocus on in latter sections.Frames A frame represents an event, a situ-ation or a real life concept; FrameNet version1.5 contains 1,019 such frames.
These thou-sand frames do not cover all possible situa-tions that we might encounter.
For example,FrameNet does not have a frame for the activityof Programming even though it has frames forCreating, Text Creation, etc.
The situa-2For example the Abandonment frame lacks jettison asone of its lexical units, and further, that word is not listedas a lexical unit in FrameNet v1.5, making jettison an OOV.1tion of writing a computer program is stereotypi-cal and attributes that a reader might associate withsuch an activity are: agent (who wrote the pro-gram), language (the programming languageused) and function (the program?s purpose).Further, FrameNet?s granularity is at times un-even.
For example, the Explosion frameand the Become Triggered frames do nothave agentive attributes, instead there existseparate frames Detonate Explosive andTriggering which have the attributes Agentand Actor respectively.
This suggests a patternthat events which are frequently described withoutan agent are assigned their own frames.
However,there is no Burial frame which focuses on theevent corresponding to frame of Burying, whichitself focuses on the Actor.This difference in granularity could be resolvedby either making distinctions more evenly fine-grained: trying to automatically inducing newframes; or by making things more evenly-coarsegrained: automatically merging existing framesthat are deemed similar.
Researchers have ex-plored methods for automatically learning framesand on learning collocations of frames to theirsyntactic dependent phrases.
Recent examples in-clude using either a Bayesian topic model to learnclusters of words (O?
Connor, 2012; Materna,2012), or attempting to learn symbolic conceptsand attributes from dictionary definitions of words(Orfan and Allen, 2013).Frame-Frame Relations FrameNet encodescertain types of correlations between situationsand events by adding defeasible typed-relationsbetween frames encoding pairwise dependencies.There are eight types of frame-frame rela-tions: Inherits from, Perspective on,Precedes, Subframe of, See also,Uses, Is Inchoative of, andIs Causative of.3For example the frameBeing Born is related to Death through therelation Is Preceded By.
Such common-sense knowledge of event-event relationshipswould be of significant utility to general AI,however it is a large space to fill: with 1,019frames and 8 binary relations there is a largeupper bound on the number of total possible3Five frame-frame relations also have an antonymrelation: Is Used by, Is Inherited by,Is Perspectivized in, Has Subframe(s),Is Preceded by, however an antonym relation does notadd any extra information over its corresponding relation.relation pairs, even if not considering the pre-vious issue of incomplete frame coverage.
Forexample, the Experience bodily harm andHostile encounter frames are not relatedthrough the Is Causative Of relation, eventhough it is reasonable to expect that a hostileencounter would result in bodily harm.4Thoughresearchers have used FrameNet relations fortasks such as recognizing textual entailment(RTE) (Aharon et al., 2010) and for text under-standing (Fillmore and Baker, 2001), to the bestof our knowledge there has been no work onautomatically extending frame-frame relations.Frame Annotated Sentences FrameNet con-tains annotated sentences providing examples of:lexical units, frames those lexical units evoked,and frame elements present in the sentence (alongwith additional information).
These annotatedsentences can be divided into two types based onwhether all the frame evoking words were markedas targets or not.The first type, which we call lexicographic,contains sentences with a single target per sen-tence.
The second type, called fulltext, containssentences that have been annotated more com-pletely and they contain multiple targets per sen-tence.
There are 4,026 fulltext sentences con-taining 23,921 targets.
This data has proved tobe useful for lexico-semantic tasks like RTE andparaphrasing e.g.
(Aharon et al., 2010; Coyneand Rambow, 2009).
As compared to Prop-Bank (Palmer et al., 2005), which annotated allpredicates occurring within a collection of pre-existing documents, FrameNet provides examples,but not a corpus that allows for directly estimatingrelative frequencies.Frame-Lemma Mappings As said earlier, lexi-cal units are tuples of the lemma form of a word,its POS-tag and its associated frame.
One compo-nent of FrameNet is its information about whichwords/lemmas prompt a particular frame.
An an-notated word that evokes a frame in a sentenceis referred to as a Target.
There are two areaswhere these mappings could be incomplete: (1)lemmas contained within FrameNet may have al-ternate senses such that they should be placedin more Frames (or related: a currently missingframe might then give rise to another sense of4Reasonable highlights the issue that we would opti-mally like to know things that are even just possible/not-too-unlikely, even if not strictly entailed.2such a lemma); and (2) lemmas from the languagemay not be in FrameNet in any form.
Most re-search on mitigating this limitation involves map-ping FrameNet?s frames to WordNet?s synsets.5Fossati et al.
(2013) explored the feasibility ofcrowdsourcing FrameNet coverage, using the dis-tributed manual labor of Mechanical Turk to com-plete the lemma coverage.3 Augmenting FrameNet with PPDBIn order to expand the coverage of FrameNet, weperformed an initial study on the use of a newbroad-coverage lexical-semantic resource, PPDB,to first add new lemmas as potential triggers fora frame, and then automatically rewrite existingexample sentences with these new triggers.
Theeventual goal of would be to enable any existingFrameNet semantic parser to simply retrain on thisexpanded dataset, rather than needing to encodemethods for dynamic OOV-resolution at test-time(such as employed by SEMAFOR).PPDB Ganitkevitch et al.
(2013) released a largecollection of lexical, phrasal and syntactic para-phrases6collectively called PPDB.
We used thelexical rules in PPDB to find potential paraphrasesof target words of frame annotated sentences.
Alexical rule in PPDB looks like the following:[VB] ||| help ||| assist |||p(e|f)=2.832, p(f|e)=1.551, ...This rule conveys that the log-probability thathelp would be paraphrased by the word assist is-2.832 but the log probability of assist being para-phrased as help is -1.551.7Ganitkevitch et al.
(2013) released quality-sorted subsets of the full(large) collection, varying in size from S to XXXLby applying thresholds over a linear combinationof the feature values to prune away low qualityparaphrases.
They verified that the average humanjudgement score of randomly sampled paraphrasesfrom smaller sized collections was higher than the5It is worth noting that substituting a larger automaticallyderived WordNet (as derived in Snow et al.
(2004)) could im-prove the recall of some of the methods which automaticallylearn a mapping from FrameNet frames to WordNet synsets.6Lexical: Two words with the same meaning; phrasal:two strings of words with the same meaning; syntactic:strings of surface words and non-terminal categories that havethe same meaning.
These strings are templates with the non-terminals serving the role of constraints over what can go inthe blanks.7See complete list at http://github.com/jweese/thrax/wiki/Feature-functions .average human judgement score of a random sam-ple from a larger collection.Approach We used the lexical rules sans fea-tures along with a 5-gram Kneser-Ney smoothedlanguage model trained using KenLM (Heafieldet al., 2013) on the raw English sequence of An-notated Gigaword (Napoles et al., 2012) to para-phrase the fulltext frame annotated sentences ofFrameNet.
We used a combination of the WordNetmorphological analyzer and Morpha8for lemma-tization and Morphg9for generation.Evaluation We present our evaluation of thequantity and quality of generated paraphrases inthis section.
Note that we did not use syntac-tic reordering to generate the paraphrases.
Alsowe paraphrased the frame evoking targets individ-ually i.e.
we did not consider combinations ofparaphrases of individual targets to be a new para-phrase of a sentence and we ignored those frameevoking targets that contained multiple words.10With the above mentioned constraints weconducted the following experiments with dif-ferent sizes of PPDB.
In Experiment 1 wegenerated a set of candidate paraphrases forevery target word in a sentence by directlyquerying that word and its dictionary form inPPDB.
In Experiment 2 we first enlarged the setof lexical units mapped to a frame by merginglexical units of frames that were related to thetarget word?s frame through either of the fol-lowing relations: Is Perspectivized In,Is Inherited By, Has Subframe (s).For example, if frame A has a subframe B thenlexical units mapped to A can evoke B.
We thenqueried PPDB to gather paraphrases for all thelexical units collected so far.
This experimentsimulates the situation where a frame has beenmapped to a set of words, e.g.
synsets in WordNet,so that every word in that larger set is a paraphraseof any word that evokes a frame.
This procedureincreases the average number of paraphrasesmapped to a frame and we present those averagesin Table 1.For both these experiments we also calculatedthe incremental benefit of PPDB over WordNet by8http://ilexir.co.uk/applications/rasp/download9http://cl.naist.jp/?eric-n/ubuntu-nlp/pool/hardy/english/morph_0.0.20030918-2nlp1?0hardy1.tar.gz10Among fulltext sentences less than 3% of targets con-tained multiple tokens.3Database Lexical Unit/FrameFramenet 20.24PPDB S 23.15PPDB M 32.00PPDB L 74.08PPDB XL 214.99Table 1: Average count of lexical units per frame for differ-ent sizes of PPDB in experiment 2.The General Assembly should set aside money for anew state health lab , millions of doses of antiviraldrugs and a fund to help meet basic needs after a disas-ter , a legislative panel recommended Thursday .1: The General Assembly should set aside cash ...2: The General Assembly should set aside fund ...1: The General Assembly should set aside dough ...3: The General Assembly should set aside silver ...Table 2: Examples and their judgements, with the last beingdebatable.filtering out paraphrases that could have been re-trieved as synonyms11from WordNet v3.0.
Theresults of these experiments are in Table 3.To evaluate the quality of our additional outputover WordNet we assigned one of the followinglabels to 25 paraphrase sets generated at the end ofExperiment 1b12: 1, the paraphrase (a) invoked thecorrect frame and (b) was grammatical; or 2, only(a) held; or 3, (a) did not hold.
Table 4 presentsaggregates over the labels.PPDB 1a 1b 2a 2bS 4,582 2,574 1,064,926 1,022,533M 15,459 9,752 1,314,169 1,263,087L 73,763 55,517 2,417,760 2,347,656XL 340,406 283,126 ?
?Table 3: The total number of paraphrases generated for the23,226 input targets versus different sizes of PPDB.
The para-phrase count excludes the input.
Column 1a and 2a representunfiltered paraphrases as opposed to 1b and 2b where theyhave been filtered using WordNet v3.0.4 Discussion And ConclusionWe presented initial experiments on using PPDBto automatically expand FrameNet through para-phrastic re-writing.
We found that over a sampleof 25 target words the top three paraphrases pro-duced by PPDB XL evoked the correct frame andwere grammatical 65% of the time.13However,11Two lemmas that appear in the same synset at least onceare synonyms in our experiments.12Experiment 2 generated significantly more candidates;here we consider only the potential scope of expansion andrely on Experiment 1 to gauge the likely paraphrase quality.13We have released the generated corpus as well as themanual annotations at cs.jhu.edu/?prastog3/res/fnppdb.htmlPPDB Size 1 2 3 %(1+2) %(1)S 0 0 0 ?
?M 6 1 2 77.77 66.67L 27 15 11 86.25 50.94L rank 3 23 12 7 83.33 54.76XL 110 85 50 79.60 44.89XL rank 3 47 16 9 87.5 65.27XL rank 5 69 28 13 88.18 62.72XL rank 10 105 52 32 83.07 55.55Table 4: Average quality of all paraphrases for 25 ran-dom sentences.
Rows marked A rank B convey that we usedPPDB of size A and kept only the top B sentences after sortingthem by their language model score.
Column %(1) indicatesthe percentage of output which was grammatical and evokedthe correct frame.
Column%(1+2) represents the output thatevoked the correct frame.work remains in recognizing the contexts in whicha paraphrase is appropriately applied, and in im-proving the quality of PPDB itself.Upon error analysis, we found two major rea-sons for ungrammaticality of lexical paraphrases.First: within FrameNet some sentences will havea single token annotated as trigger, when in fact itis part of a multi-word expression.
For example, itwas grammatically infelicitous to replace part byportion in the expression part of the answer.
Theother major source of error was the inaccuracy inPPDB itself.
We found that for a large number ofcases when PPDB XL did not have a high numberof paraphrases the paraphrases were wrong (e.g.,PPDB XL had only 2 paraphrases for the wordslab and millions.
)Going forward we aim to increase the precisionof our paraphrases and our ability to recognizetheir appropriate contexts for application.
Fur-ther, we wish to augment additional resources ina similar way, for example PropBank or the ACEcorpus (Walker et al., 2006).
We should be ableto increase the precision by using the paraphraseprobability features of a PPDB rule and by usingbetter language models with lower perplexity thann-grams e.g.
recurrent neural net based languagemodels.
Improving the accuracy of PPDB, espe-cially in the large settings, would be another fo-cus area.
Also, we would use Amazon Mechani-cal Turk to evaluate the quality of a larger set ofparaphrases to make our evaluation robust and sothat we can evaluate the efficacy of our second ex-periment.Acknowledgments This material is based on re-search sponsored by the NSF under grant IIS-1249516 and DARPA under agreement numberFA8750-13-2-0017.4ReferencesRoni Ben Aharon, Idan Szpektor, and Ido Dagan.2010.
Generating entailment rules from framenet.In Proceedings of the ACL 2010 Conference ShortPapers, pages 241?246.Collin Baker, Michael Ellsworth, and Katrin Erk.2007.
Semeval?07 task 19: frame semantic structureextraction.
In Proceedings of the 4th InternationalWorkshop on Semantic Evaluations, pages 99?104.ACL.Bob Coyne and Owen Rambow.
2009.
Lexpar: Afreely available english paraphrase lexicon automat-ically extracted from framenet.
2012 IEEE SixthInternational Conference on Semantic Computing,pages 53?58.Dipanjan Das, Desai Chen, Andr?e F. T. Martins,Nathan Schneider, and Noah A. Smith.
2013.Frame-semantic parsing.
Computational Linguis-tics, 40(1):9?56.Oscar Ferr?andez, Michael Ellsworth, Rafael Munoz,and Collin F Baker.
2010.
Aligning framenetand wordnet based on semantic neighborhoods.
InLREC, volume 10, pages 310?314.Charles J Fillmore and Collin F Baker.
2001.
Framesemantics for text understanding.
In Proceedingsof WordNet and Other Lexical Resources Workshop,NAACL.Marco Fossati, Claudio Giuliano, and Sara Tonelli.2013.
Outsourcing framenet to the crowd.
In Pro-ceedings of the 51st Annual Meeting of the ACL,pages 742?747.Juri Ganitkevitch, Benjamin Van Durme, and ChrisCallison-Burch.
2013.
PPDB: The paraphrasedatabase.
In Proceedings of NAACL-HLT, pages758?764, Atlanta, Georgia, June.
ACL.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational linguis-tics, 28(3):245?288.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.Clark, and Philipp Koehn.
2013.
Scalable modi-fied Kneser-Ney language model estimation.
In Pro-ceedings of the 51st Annual Meeting of the ACL,Sofia, Bulgaria.Ji?r??
Materna.
2012.
Lda-frames: An unsupervised ap-proach to generating semantic frames.
In Compu-tational Linguistics and Intelligent Text Processing,volume 7181 of Lecture Notes in Computer Science,pages 376?387.
Springer Berlin Heidelberg.Courtney Napoles, Matthew Gormley, and BenjaminVan Durme.
2012.
Annotated gigaword.
In Pro-ceedings of the Joint Workshop on Automatic Knowl-edge Base Construction and Web-scale KnowledgeExtraction, pages 95?100.
ACL.Brendan O?
Connor.
2012.
Learning frames from textwith an unsupervised latent variable model.
In Tech-nical Report.
Carnegie Mellon University.Jansen Orfan and James Allen.
2013.
Toward learninghigh-level semantic frames from definitions.
In Pro-ceedings of the Second Annual Conference on Ad-vances in Cognitive Systems, volume 125.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31(1):71?106.Rion Snow, Daniel Jurafsky, and Andrew Y Ng.
2004.Learning syntactic patterns for automatic hypernymdiscovery.
In NIPS, volume 17, pages 1297?1304.Christopher Walker, Stephanie Strassel, Julie Medero,and Kazuaki Maeda.
2006.
Ace 2005 multilin-gual training corpus.
Linguistic Data Consortium,Philadelphia.5
