Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 1?4,Athens, Greece, 30 March 2009. c?2009 Association for Computational LinguisticsGrammatical Inference and Computational LinguisticsMenno van ZaanenTilburg Centre for Creative ComputingTilburg UniversityTilburg, The Netherlandsmvzaanen@uvt.nlColin de la HigueraUniversity of Saint- ?EtienneFrancecdlh@univ-st-etienne.fr1 Grammatical inference and its links tonatural language processingWhen dealing with language, (machine) learningcan take many different faces, of which the mostimportant are those concerned with learning lan-guages and grammars from data.
Questions inthis context have been at the intersection of thefields of inductive inference and computationallinguistics for the past fifty years.
To go backto the pioneering work, Chomsky (1955; 1957)and Solomonoff (1960; 1964) were interested, forvery different reasons, in systems or programs thatcould deduce a language when presented informa-tion about it.Gold (1967; 1978) proposed a little later a uni-fying paradigm called identification in the limit,and the term of grammatical inference seems tohave appeared in Horning?s PhD thesis (1969).Out of the scope of linguistics, researchers andengineers dealing with pattern recognition, underthe impulsion of Fu (1974; 1975), invented algo-rithms and studied subclasses of languages andgrammars from the point of view of what couldor could not be learned.Researchers in machine learning tackled relatedproblems (the most famous being that of infer-ring a deterministic finite automaton, given ex-amples and counter-examples of strings).
An-gluin (1978; 1980; 1981; 1982; 1987) introducedthe important setting of active learning, or learn-ing for queries, whereas Pitt and his colleagues(1988; 1989; 1993) gave several complexity in-spired results with which the hardness of the dif-ferent learning problems was exposed.Researchers working in more applied areas,such as computational biology, also deal withstrings.
A number of researchers from thatfield worked on learning grammars or automatafrom string data (Brazma and Cerans, 1994;Brazma, 1997; Brazma et al, 1998).
Simi-larly, stemming from computational linguistics,one can point out the work relating language learn-ing with more complex grammatical formalisms(Kanazawa, 1998), the more statistical approachesbased on building language models (Goodman,2001), or the different systems introduced to au-tomatically build grammars from sentences (vanZaanen, 2000; Adriaans and Vervoort, 2002).
Sur-veys of related work in specific fields can alsobe found (Natarajan, 1991; Kearns and Vazirani,1994; Sakakibara, 1997; Adriaans and van Zaa-nen, 2004; de la Higuera, 2005; Wolf, 2006).2 Meeting points between grammaticalinference and natural languageprocessingGrammatical inference scientists belong to a num-ber of larger communities: machine learning (withspecial emphasis on inductive inference), com-putational linguistics, pattern recognition (withinthe structural and syntactic sub-group).
There isa specific conference called ICGI (InternationalColloquium on Grammatical Inference) devotedto the subject.
These conferences have been heldat Alicante (Carrasco and Oncina, 1994), Mont-pellier (Miclet and de la Higuera, 1996), Ames(Honavar and Slutski, 1998), Lisbon (de Oliveira,2000), Amsterdam (Adriaans et al, 2002), Athens(Paliouras and Sakakibara, 2004), Tokyo (Sakak-ibara et al, 2006) and Saint-Malo (Clark et al,2008).
In the proceedings of this event it is pos-sible to find a number of technical papers.
Withinthis context, there has been a growing trend to-wards problems of language learning in the fieldof computational linguistics.The formal objects in common between thetwo communities are the different types of au-tomata and grammars.
Therefore, another meet-ing point between these communities has been thedifferent workshops, conferences and journals thatfocus on grammars and automata, for instance,1FSMNLP,GRAMMARS, CIAA, .
.
.3 Goal for the workshopThere has been growing interest over the last fewyears in learning grammars from natural languagetext (and structured or semi-structured text).
Thefamily of techniques enabling such learning is usu-ally called ?grammatical inference?
or ?grammarinduction?.The field of grammatical inference is often sub-divided into formal grammatical inference, whereresearchers aim to proof efficient learnability ofclasses of grammars, and empirical grammaticalinference, where the aim is to learn structure fromdata.
In this case the existence of an underlyinggrammar is just regarded as a hypothesis and whatis sought is to better describe the language throughsome automatically learned rules.Both formal and empirical grammatical infer-ence have been linked with (computational) lin-guistics.
Formal learnability of grammars hasbeen used in discussions on how people learn lan-guage.
Some people mention proofs of (non-)learnability of certain classes of grammars as ar-guments in the empiricist/nativist discussion.
Onthe more practical side, empirical systems thatlearn grammars have been applied to natural lan-guage.
Instead of proving whether classes ofgrammars can be learnt, the aim here is to pro-vide practical learning systems that automaticallyintroduce structure in language.
Example fieldswhere initial research has been done are syntac-tic parsing, morphological analysis of words, andbilingual modelling (or machine translation).This workshop organized at EACL 2009 aimedto explore the state-of-the-art in these topics.
Inparticular, we aimed at bringing formal and empir-ical grammatical inference researchers closer to-gether with researchers in the field of computa-tional linguistics.The topics put forward were to cover researchon all aspects of grammatical inference in rela-tion to natural language (such as, syntax, seman-tics, morphology, phonology, phonetics), includ-ing, but not limited to?
Automatic grammar engineering, including,for example,?
parser construction,?
parameter estimation,?
smoothing, .
.
.?
Unsupervised parsing?
Language modelling?
Transducers, for instance, for?
morphology,?
text to speech,?
automatic translation,?
transliteration,?
spelling correction, .
.
.?
Learning syntax with semantics,?
Unsupervised or semi-supervised learning oflinguistic knowledge,?
Learning (classes of) grammars (e.g.
sub-classes of the Chomsky Hierarchy) from lin-guistic inputs,?
Comparing learning results in differentframeworks (e.g.
membership vs. correctionqueries),?
Learning linguistic structures (e.g.
phonolog-ical features, lexicon) from the acoustic sig-nal,?
Grammars and finite state machines in ma-chine translation,?
Learning setting of Chomskyan parameters,?
Cognitive aspects of grammar acquisition,covering, among others,?
developmental trajectories as studied bypsycholinguists working with children,?
characteristics of child-directed speechas they are manifested in corpora suchas CHILDES, .
.
.?
(Unsupervised) Computational language ac-quisition (experimental or observational),4 The papersThe workshop was glad to have as invited speakerDamir ?Cavar, who presented a talk titled: On boot-strapping of linguistic features for bootstrappinggrammars.The papers submitted to the workshop and re-viewed by at least three reviewers each, covered avery wide range of problems and techniques.
Ar-ranging them into patterns was not a simple task!There were three papers focussing on transduc-ers:2?
Jeroen Geertzen shows in his paper DialogueAct Prediction Using Stochastic Context-FreeGrammar Induction, how grammar inductioncan be used in dialogue act prediction.?
In their paper (Experiments Using OSTIA fora Language Production Task), Dana Angluinand Leonor Becerra-Bonache build on previ-ous work to see the transducer learning algo-rithm OSTIA as capable of translating syn-tax to semantics.?
In their paper titled GREAT: a finite-statemachine translation toolkit implementing aGrammatical Inference Approach for Trans-ducer Inference (GIATI), Jorge Gonza?lez andFrancisco Casacuberta build on a long his-tory of GOATI learning and try to eliminatesome of the limitations of previous work.The learning concerns finite-state transducersfrom parallel corpora.Context-free grammars of different types wereused for very different tasks:?
Alexander Clark, Remi Eyraud and AmauryHabrard (A note on contextual binary fea-ture grammars) propose a formal study ofa new formalism called ?CBFG?, describethe relationship of CBFG to other standardformalisms and its appropriateness for mod-elling natural language.?
In their work titled Language models for con-textual error detection and correction, Her-man Stehouwer and Menno van Zaanen lookat spelling problems as a word predictionproblem.
The prediction needs a languagemodel which is learnt.?
A formal study of French treebanks is madeby Marie-He?le`ne Candito, Benoit Crabbe?
andDjame?
Seddah in their work: On statisticalparsing of French with supervised and semi-supervised strategies.?
Franco M. Luque and Gabriel Infante-Lopezstudy the learnability of NTS grammars withreference to the Penn treebank in their papertitled Upper Bounds for Unsupervised Pars-ing with Unambiguous Non-Terminally Sep-arated Grammars.One paper concentrated on morphology :?
In A comparison of several learners forBoolean partitions: implications for morpho-logical paradigm, Katya Pertsova compares arote learner to three morphological paradigmlearners.ReferencesP.
Adriaans and M. van Zaanen.
2004.
Computationalgrammar induction for linguists.
Grammars, 7:57?68.P.
Adriaans and M. Vervoort.
2002.
The EMILE4.1 grammar induction toolbox.
In Adriaans et al(Adriaans et al, 2002), pages 293?295.P.
Adriaans, H. Fernau, and M. van Zaannen, editors.2002.
Grammatical Inference: Algorithms and Ap-plications, Proceedings of ICGI ?02, volume 2484of LNAI, Berlin, Heidelberg.
Springer-Verlag.D.
Angluin.
1978.
On the complexity of minimuminference of regular sets.
Information and Control,39:337?350.D.
Angluin.
1980.
Inductive inference of formal lan-guages from positive data.
Information and Control,45:117?135.D.
Angluin.
1981.
A note on the number of queriesneeded to identify regular languages.
Informationand Control, 51:76?87.D.
Angluin.
1982.
Inference of reversible languages.Journal of the Association for Computing Machin-ery, 29(3):741?765.D.
Angluin.
1987.
Queries and concept learning.
Ma-chine Learning Journal, 2:319?342.A.
Brazma and K. Cerans.
1994.
Efficient learningof regular expressions from good examples.
In AII?94: Proceedings of the 4th International Workshopon Analogical and Inductive Inference, pages 76?90.Springer-Verlag.A.
Brazma, I. Jonassen, J. Vilo, and E. Ukkonen.
1998.Pattern discovery in biosequences.
In Honavar andSlutski (Honavar and Slutski, 1998), pages 257?270.A.
Brazma, 1997.
Computational learning theory andnatural learning systems, volume 4, chapter Effi-cient learning of regular expressions from approxi-mate examples, pages 351?366.
MIT Press.R.
C. Carrasco and J. Oncina, editors.
1994.
Gram-matical Inference and Applications, Proceedings ofICGI ?94, number 862 in LNAI, Berlin, Heidelberg.Springer-Verlag.N.
Chomsky.
1955.
The logical structure of linguis-tic theory.
Ph.D. thesis, Massachusetts Institute ofTechnology.3N.
Chomsky.
1957.
Syntactic structure.
Mouton.A.
Clark, F. Coste, and L. Miclet, editors.
2008.Grammatical Inference: Algorithms and Applica-tions, Proceedings of ICGI ?08, volume 5278 ofLNCS.
Springer-Verlag.C.
de la Higuera.
2005.
A bibliographical studyof grammatical inference.
Pattern Recognition,38:1332?1348.A.
L. de Oliveira, editor.
2000.
Grammatical Infer-ence: Algorithms and Applications, Proceedings ofICGI ?00, volume 1891 of LNAI, Berlin, Heidelberg.Springer-Verlag.K.
S. Fu and T. L. Booth.
1975.
Grammatical infer-ence: Introduction and survey.
Part I and II.
IEEETransactions on Syst.
Man.
and Cybern., 5:59?72and 409?423.K.
S. Fu.
1974.
Syntactic Methods in Pattern Recogni-tion.
Academic Press, New-York.E.
M. Gold.
1967.
Language identification in the limit.Information and Control, 10(5):447?474.E.
M. Gold.
1978.
Complexity of automaton identi-fication from given data.
Information and Control,37:302?320.J.
Goodman.
2001.
A bit of progress in language mod-eling.
Technical report, Microsoft Research.V.
Honavar and G. Slutski, editors.
1998.
Gram-matical Inference, Proceedings of ICGI ?98, number1433 in LNAI, Berlin, Heidelberg.
Springer-Verlag.J.
J. Horning.
1969.
A study of Grammatical Inference.Ph.D.
thesis, Stanford University.M.
Kanazawa.
1998.
Learnable Classes of CategorialGrammars.
CSLI Publications, Stanford, Ca.M.
J. Kearns and U. Vazirani.
1994.
An Introductionto Computational Learning Theory.
MIT press.L.
Miclet and C. de la Higuera, editors.
1996.
Pro-ceedings of ICGI ?96, number 1147 in LNAI, Berlin,Heidelberg.
Springer-Verlag.B.
L. Natarajan.
1991.
Machine Learning: a Theoret-ical Approach.
Morgan Kauffman Pub., San Mateo,CA.G.
Paliouras and Y. Sakakibara, editors.
2004.
Gram-matical Inference: Algorithms and Applications,Proceedings of ICGI ?04, volume 3264 of LNAI,Berlin, Heidelberg.
Springer-Verlag.L.
Pitt and M. Warmuth.
1988.
Reductions amongprediction problems: on the difficulty of predictingautomata.
In 3rd Conference on Structure in Com-plexity Theory, pages 60?69.L.
Pitt and M. Warmuth.
1993.
The minimum consis-tent DFA problem cannot be approximated withinany polynomial.
Journal of the Association forComputing Machinery, 40(1):95?142.L.
Pitt.
1989.
Inductive inference, DFA?s, and com-putational complexity.
In Analogical and Induc-tive Inference, number 397 in LNAI, pages 18?44.Springer-Verlag, Berlin, Heidelberg.Y.
Sakakibara, S. Kobayashi, K. Sato, T. Nishino, andE.
Tomita, editors.
2006.
Grammatical Infer-ence: Algorithms and Applications, Proceedings ofICGI ?06, volume 4201 of LNAI, Berlin, Heidelberg.Springer-Verlag.Y.
Sakakibara.
1997.
Recent advances of grammaticalinference.
Theoretical Computer Science, 185:15?45.R.
Solomonoff.
1960.
A preliminary report on a gen-eral theory of inductive inference.
Technical ReportZTB-138, Zator Company, Cambridge, Mass.R.
Solomonoff.
1964.
A formal theory of inductiveinference.
Information and Control, 7(1):1?22 and224?254.M.
van Zaanen.
2000.
ABL: Alignment-based learn-ing.
In Proceedings of COLING 2000, pages 961?967.
Morgan Kaufmann.G.
Wolf.
2006.
Unifying computing and cognition.Cognition research.4
