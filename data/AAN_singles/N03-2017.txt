Word Alignment with Cohesion ConstraintDekang Lin and Colin CherryDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada, T6G 2E8{lindek,colinc}@cs.ualberta.caAbstractWe present a syntax-based constraint for wordalignment, known as the cohesion constraint.
Itrequires disjoint English phrases to be mappedto non-overlapping intervals in the French sen-tence.
We evaluate the utility of this constraintin two different algorithms.
The results showthat it can provide a significant improvement inalignment quality.1 IntroductionThe IBM statistical machine translation (SMT) modelshave been extremely influential in computational linguis-tics in the past decade.
The (arguably) most striking char-acteristic of the IBM-style SMT models is their total lackof linguistic knowledge.
The IBM models demonstratedhow much one can do with pure statistical techniques,which have inspired a whole new generation of NLP re-search and systems.More recently, there have been many proposals tointroduce syntactic knowledge into SMT models (Wu,1997; Alshawi et al, 2000; Yamada and Knight, 2001;Lopez et al, 2002).
A common theme among theseapproaches is the assumption that the syntactic struc-tures of a pair of source-target sentences are isomor-phic (or nearly isomorphic).
This assumption seems toostrong.
Human translators often use non-literal transla-tions, which result in differences in syntactic structures.According to a study in (Dorr et al, 2002), such transla-tional divergences are quite common, involving 11-31%of the sentences.We introduce a constraint that uses the dependency treeof the English sentence to maintain phrasal cohesion inthe French sentence.
In other words, if two phrases aredisjoint in the English sentence, the alignment must notmap them to overlapping intervals in the French sentence.For example, in Figure 1, the cohesion constraint will ruleout the possibility of aligning to with a`.
The phrases thereboot and the host to discover all the devices are dis-joint, but the partial alignment in Figure 1 maps them tooverlapping intervals.
This constraint is weaker than iso-morphism.
However, we will show that it can produce asignificant increase in alignment quality.Therebootcausesthehosttodiscoverallthedevicesdetsubjdetsubjauxpredetobjmod?
laSuiter?initialisation  ,l'  h?terep?retouslesp?riph?riquesaftertotherebootthehostlocatealltheperipherals123456789101234567891011Figure 1: A cohesion constraint violation2 Cohesion ConstraintGiven an English sentence E = e1e2 .
.
.
el and a Frenchsentence F = f1f2 .
.
.
fm, an alignment is a set of linksbetween the words in E and F .
An alignment can berepresented as a binary relation A in [1, l] ?
[1,m].
Apair (i, j) is in A if ei and fj are a translation (or partof a translation) of each other.
We call such pairs links.In Figure 2, the links in the alignment are represented bydashed lines.Therebootcausesthehosttodiscoverallthedevicesdetsubjdetsubjauxpredetobjcomp?
laSuiter?initialisation  ,l'  h?terep?retouslesp?riph?riques123456789101234567891011aftertotherebootthehostlocatealltheperipheralsFigure 2: An example pair of aligned sentenceThe cohesion constraint (Fox, 2002) uses the depen-dency tree TE (Mel?c?uk, 1987) of the English sentenceto restrict possible link combinations.
Let TE(ei) bethe subtree of TE rooted at ei.
The phrase span of ei,spanP (ei, TE , A), is the image of the English phraseheaded by ei in F given a (partial) alignment A. Moreprecisely, spanP (ei, TE , A) = [k1, k2], wherek1 = min{j|(u, j) ?
A, eu ?
TE(ei)}k2 = max{j|(u, j) ?
A, eu ?
TE(ei)}The head span is the image of ei itself.
We definespanH(ei, TE , A) = [k1, k2], wherek1 = min{j|(i, j) ?
A}k2 = max{j|(i, j) ?
A}In Figure 2, the phrase span of the node discover is[6, 11] and the head span is [8, 8]; the phrase span of thenode reboot is [3, 4] and the head span is [4, 4].
The wordcause has a phrase span of [3,11] and its head span is theempty set ?.With these definitions of phrase and head spans, we de-fine two notions of overlap, originally introduced in (Fox,2002) as crossings.
Given a head node eh and its modi-fier em, a head-modifier overlap occurs when:spanH(eh, TE , A) ?
spanP (em, TE , A) 6= ?Given two nodes em1 and em2 which both modify thesame head node, a modifier-modifier overlap occurswhen:spanP (em1 , TE , A) ?
spanP (em2 , TE , A) 6= ?Following (Fox, 2002), we say an alignment is cohe-sive with respect to TE if it does not introduce any head-modifier or modifier-modifier overlaps.
For example, thealignment A in Figure 1 is not cohesive because thereis an overlap between spanP (reboot, TE , A)=[4, 4] andspanP (discover, TE , A)=[2, 11].If an alignmentA?
violates the cohesion constraint, anyalignment A that is a superset of A?
will also violate thecohesion constraint.
This is because any pair of nodesthat have overlapping spans in A?
will still have overlap-ping spans in A.Cohesion Checking Algorithm:We now present an algorithm that checks whether anindividual link (ei, fj) causes a cohesion constraint vi-olation when it is added to a partial alignment.
Letep0 , ep1 , ep2 , .
.
.
be a sequence of nodes in TE such thatep0=ei and epk=parentOf (epk?1) (k = 1, 2, .
.
.)1.
For all k ?
0, update the spanP and the spanH ofepk to include j.2.
For each epk (k > 0), check for a modifier-modifieroverlap between the updated the phrase span ofepk?1 and the the phrase span of each of the otherchildren of epk .3.
For each epk (k > 0), check for a head-modifieroverlap between the updated phrase span of epk?1and the head span of epk .4.
If an overlap is found, return true (the constraint isviolated).
Otherwise, return false.3 EvaluationTo determine the utility of the cohesion constraint, weincorporated it into two alignment algorithms.
The algo-rithms take as input an English-French sentence pair andthe dependency tree of the English sentence.
Both algo-rithms build an alignment by adding one link at a time.We implement two versions of each algorithm: one withthe cohesion constraint and one without.
We will describethe versions without cohesion constraint below.
For theversions with cohesion constraint, it is understood thateach new link must also pass the test described in Sec-tion 2.The first algorithm is similar to Competitive Linking(Melamed, 1997).
We use a sentence-aligned corpusto compute the ?2 correlation metric (Gale and Church,1991) between all English-French word pairs.
For a givensentence pair, we begin with an empty alignment.
Wethen add links in the order of their ?2 scores so that eachword participates in at most one link.
We will refer to thisas the ?2 method.The second algorithm uses a best-first search (withfixed beam width and agenda size) to find an alignmentthat maximizes P (A|E,F ).
A state in this search spaceis a partial alignment.
A transition is defined as the ad-dition of a single link to the current state.
The algorithmcomputes P (A|E,F ) based on statistics obtained from aword-aligned corpus.
We construct the initial corpus witha system that is similar to the ?2 method.
The algorithmthen re-aligns the corpus and trains again for three iter-ations.
We will refer to this as the P (A|E,F ) method.The details of this algorithm are described in (Cherry andLin, 2003).We trained our alignment programs with the same 50Kpairs of sentences as (Och and Ney, 2000) and tested it onthe same 500 manually aligned sentences.
Both the train-ing and testing sentences are from the Hansard corpus.We parsed the training and testing corpora with Minipar.1We adopted the evaluation methodology in (Och and Ney,2000), which defines three metrics: precision, recall andalignment error rate (AER).Table 1 shows the results of our experiments.
The firstfour rows correspond to the methods described above.
Asa reference point, we also provide the results reported in(Och and Ney, 2000).
They implemented IBM Model 4by bootstrapping from an HMM model.
The rows F?E1available at http://www.cs.ualberta.ca/?
lindek/minipar.htmTable 1: Evaluation ResultsMethod Prec Rec AER?2 w/o cohesion 82.7 84.6 16.5w/ cohesion 89.2 82.7 13.8P (A|E,F ) w/o cohesion 87.3 85.3 13.6w/ cohesion 95.7 86.4 8.7F?E 80.5 91.2 15.6Och&Ney E?F 80.0 90.8 16.0Refined 85.9 92.3 11.7and E?F are the results obtained by this model whentreating French as the source and English as the targetor vice versa.
The row Refined shows results obtainedby taking the intersection of E?F and F?E and thenrefining this intersection to increase recall.From Table 1, we can see that the addition of the cohe-sion constraint leads to significant improvements in per-formance with both algorithms.
The relative reduction inerror rate is 16% with the ?2 method and 36% with theP (A|E,F ) method.
The improvement comes primarilyfrom increased precision.
With the P (A|E,F ) method,this increase in precision does not come at the expense ofrecall.4 Related WorkThere has been a growing trend in the SMT communityto attempt to leverage syntactic data in word alignment.Methods such as (Wu, 1997), (Alshawi et al, 2000) and(Lopez et al, 2002) employ a synchronous parsing proce-dure to constrain a statistical alignment.
The work donein (Yamada and Knight, 2001) measures statistics on op-erations that transform a parse tree from one languageinto another.The syntactic knowledge that is leveraged in thesemethods is tightly coupled with the alignment method it-self.
We have presented a modular constraint that can beplugged into different alignment algorithms.
This has al-lowed us to test the contribution of the constraint directly.
(Fox, 2002) studied the extent to which the cohesionconstraint holds in a parallel corpus and the reasons forthe violations, but did not apply the constraint to an align-ment algorithm.5 ConclusionWe have presented a syntax-based constraint for wordalignment, known as the cohesion constraint.
It requiresdisjoint English phrases to be mapped to non-overlappingintervals in the French sentence.
Our experiments haveshown that the use of this constraint can provide a rela-tive reduction in alignment error rate of 36%.AcknowledgmentsWe wish to thank Franz Och for providing us with manu-ally aligned evaluation data.
This project is funded by andjointly undertaken with Sun Microsystems, Inc. We wishto thank Finola Brady, Bob Kuhns and Michael McHughfor their help.ReferencesHiyan Alshawi, Srinivas Bangalore, and Shona Douglas.2000.
Learning dependency translation models as col-lections of finite state head transducers.
Computa-tional Linguistics, 26(1):45?60.Colin Cherry and Dekang Lin.
2003.
A probabilitymodel to improve word alignment.
Submitted.Bonnie J. Dorr, Lisa Pearl, Rebecca Hwa, and NizarHabash.
2002.
Duster: A method for unravelingcross-language divergences for statistical word-levelalignment.
In Stephen D. Richardson, editor, Proceed-ings of AMTA-02, pages 31?43, Tiburon, CA, October.Springer.Heidi J.
Fox.
2002.
Phrasal cohesion and statistical ma-chine translation.
In Proceedings of EMNLP-02, pages304?311.W.A.
Gale and K.W.
Church.
1991.
Identifying wordcorrespondences in parallel texts.
In Proceedings ofthe 4th Speech and Natural Language Workshop, pages152?157.
DARPA, Morgan Kaufmann.Adam Lopez, Michael Nossal, Rebecca Hwa, and PhilipResnik.
2002.
Word-level alignment for multilingualresource acquisition.
In Proceedings of the Workshopon Linguistic Knowledge Acquisition and Representa-tion: Bootstrapping Annotated Language Data.I.
Dan Melamed.
1997.
A word-to-word model of trans-lational equivalence.
In Proceedings of the ACL-97,pages 490?497.
Association for Computational Lin-guistics.Igor A. Mel?c?uk.
1987.
Dependency syntax: theory andpractice.
State University of New York Press, Albany.Franz J. Och and Hermann Ney.
2000.
Improved sta-tistical alignment models.
In Proceedings of the 38thAnnual Meeting of the Association for ComputationalLinguistics, pages 440?447, Hong Kong, China, Octo-ber.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):374?403.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Meeting of the Associ-ation for Computational Linguistics, pages 523?530.
