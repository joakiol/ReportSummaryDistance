Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, page 87,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsSemEval-2 Task 15: Infrequent Sense Identification for MandarinText to Speech SystemsPeng Jin1 and Yunfang Wu21Laboratory of Intelligent Information Processing and Application, Leshan NormalUniversity, Leshan China2Institute of Computational Linguistics  Peking University, Beijing China{jandp, wuyf}@pku.edu.cn1 IntroductionThere are seven cases of grapheme to phoneme ina text to speech  system (Yarowsky, 1997).
Amongthem, the most difficult task is disambiguating thehomograph word, which has the same POS butdifferent pronunciation.
In this case, different pro-nunciations of the same word always correspond todifferent word senses.
Once the word senses aredisambiguated, the problem of GTP is resolved.There is a little different from traditional WSD,in this task two or more senses may correspond toone pronunciation.
That is, the sense granularity iscoarser than WSD.
For example, the preposition???
has three senses: sense1 and sense2 have thesame pronunciation {wei 4}, while sense3 corre-sponds to {wei 2}.
In this task, to the target word,not only the pronunciations but also the sense la-bels are provided for training; but for test, only thepronunciations are evaluated.
The challenge of thistask is the much skewed distribution in real text:the most frequent pronunciation occupies usuallyover 80%.In this task, we will provide a large volume oftraining data (each homograph word has at least300 instances) accordance with the truly distribu-tion in real text.
In the test data, we will provide atleast 100 instances for each target word.
Thesenses distribution in test data is the same as intraining data.All instances come from People Dailynewspaper (the most popular newspaper in Manda-rin).
Double blind annotations are executed manu-ally, and a third annotator checks the annotation.2 Participating SystemsTwo kinds of precisions are evaluated.
One ismicro-average:?
?===NiiNiimir nmP11/N is the number of all target word-types.
mi isthe number of labeled correctly to one specific tar-get word-type and ni is the number of all test in-stances for this word-type.
The other is macro-average:?==Niimar NpP1/ ,  iii nmp /=There are two teams participated in and submit-ted nine systems.
Table 1 shows the results, all sys-tems are better than baseline (Baseline is using themost frequent sense to tag all the tokens).System Micro-average Macro-average156-419 0.974432 0.951696205-332 0.97028 0.938844205-417 0.97028 0.938844205-423 0.97028 0.938844205-425 0.97028 0.938844205-424 0.968531 0.938871156-420 0.965472 0.942086156-421 0.965472 0.94146156-422 0.965472 0.942086baseline 0.923514 0.895368Table 1: The scores of all participating systemsReferencesYarowsky, David.
1997.
?Homograph disambiguationin text-to-speech synthesis.?
In van Santen, Jan T. H.;Sproat, Richard; Olive, Joseph P.; and Hirschberg,Julia.
Progress in Speech Synthesis.
Springer-Verlag,New York, 157-172.87
