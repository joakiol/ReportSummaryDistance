Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 308?316,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsOn the Syllabification of PhonemesSusan Bartlett?
and Grzegorz Kondrak?
and Colin Cherry?
?Department of Computing Science ?Microsoft ResearchUniversity of Alberta One Microsoft WayEdmonton, AB, T6G 2E8, Canada Redmond, WA, 98052{susan,kondrak}@cs.ualberta.ca colinc@microsoft.comAbstractSyllables play an important role in speechsynthesis and recognition.
We present sev-eral different approaches to the syllabifica-tion of phonemes.
We investigate approachesbased on linguistic theories of syllabification,as well as a discriminative learning techniquethat combines Support Vector Machine andHidden Markov Model technologies.
Ourexperiments on English, Dutch and Germandemonstrate that our transparent implemen-tation of the sonority sequencing principleis more accurate than previous implemen-tations, and that our language-independentSVM-based approach advances the currentstate-of-the-art, achieving word accuracy ofover 98% in English and 99% in German andDutch.1 IntroductionSyllabification is the process of dividing a wordinto its constituent syllables.
Although some workhas been done on syllabifying orthographic forms(Mu?ller et al, 2000; Bouma, 2002; Marchand andDamper, 2007; Bartlett et al, 2008), syllables are,technically speaking, phonological entities that canonly be composed of strings of phonemes.
Mostlinguists view syllables as an important unit ofprosody because many phonological rules and con-straints apply within syllables or at syllable bound-aries (Blevins, 1995).Apart from their purely linguistic significance,syllables play an important role in speech synthesisand recognition (Kiraz and Mo?bius, 1998; Pearsonet al, 2000).
The pronunciation of a given phonemetends to vary depending on its location within a syl-lable.
While actual implementations vary, text-to-speech (TTS) systems must have, at minimum, threecomponents (Damper, 2001): a letter-to-phoneme(L2P) module, a prosody module, and a synthesismodule.
Syllabification can play a role in all threemodules.Because of the productive nature of language, adictionary look-up process for syllabification is in-adequate.
No dictionary can ever contain all possi-ble words in a language.
For this reason, it is neces-sary to develop systems that can automatically syl-labify out-of-dictionary words.In this paper, we advance the state-of-the-artin both categorical (non-statistical) and supervisedsyllabification.
We outline three categorical ap-proaches based on common linguistic theories ofsyllabification.
We demonstrate that when imple-mented carefully, such approaches can be very ef-fective, approaching supervised performance.
Wealso present a data-driven, discriminative solution:a Support Vector Machine Hidden Markov Model(SVM-HMM), which tags each phoneme with itssyllabic role.
Given enough data, the SVM-HMMachieves impressive accuracy thanks to its abilityto capture context-dependent generalizations, whilealso memorizing inevitable exceptions.
Our ex-periments on English, Dutch and German demon-strate that our SVM-HMM approach substantiallyoutperforms the existing state-of-the-art learning ap-proaches.
Although direct comparisons are difficult,our system achieves over 99% word accuracy onGerman and Dutch, and the highest reported accu-racy on English.The paper is organized as follows.
We outlinecommon linguistic theories of syllabification in Sec-tion 2, and we survey previous computational sys-308tems in Section 3.
Our linguistically-motivated ap-proaches are described in Section 4.
In Section 5,we describe our system based on the SVM-HMM.The experimental results are presented in Section 6.2 Theories of SyllabificationThere is some debate as to the exact structure ofa syllable.
However, phonologists are in gen-eral agreement that a syllable consists of a nucleus(vowel sound), preceded by an optional onset andfollowed by an optional coda.
In many languages,both the onset and the coda can be complex, i.e.,composed of more than one consonant.
For exam-ple, the word breakfast [brEk-fst] contains two syl-lables, of which the first has a complex onset [br],and the second a complex coda [st].
Languages dif-fer with respect to various typological parameters,such as optionality of onsets, admissibility of co-das, and the allowed complexity of the syllable con-stituents.
For example, onsets are required in Ger-man, while Spanish prohibits complex codas.There are a number of theories of syllabification;we present three of the most prevalent.
The Legal-ity Principle constrains the segments that can be-gin and end syllables to those that appear at the be-ginning and end of words.
In other words, a sylla-ble is not allowed to begin with a consonant clus-ter that is not found at the beginning of some word,or end with a cluster that is not found at the end ofsome word (Goslin and Frauenfelder, 2001).
Thus,a word like admit [dmIt] must be syllabified [d-mIt] because [dm] never appears word-initially orword-finally in English.
A shortcoming of the le-gality principle is that it does not always imply aunique syllabification.
For example, in a word likeaskew [skju], the principle does not rule out any of[-skju], [s-kju], or [sk-ju], as all three employ le-gal onsets and codas.The Sonority Sequencing Principle (SSP) pro-vides a stricter definition of legality.
The sonor-ity of a sound is its inherent loudness, holding fac-tors like pitch and duration constant (Crystal, 2003).Low vowels like [a], the most sonorous sounds, arehigh on the sonority scale, while plosive consonantslike [t] are at the bottom.
When syllabifying aword, SSP states that sonority should increase fromthe first phoneme of the onset to the syllable?s nu-cleus, and then fall off to the coda (Selkirk, 1984).Consequently, in a word like vintage [vIntI], wecan rule out a syllabification like [vI-ntI] because[n] is more sonorant than [t].
However, SSP doesnot tell us whether to prefer [vIn-tI] or [vInt-I].Moreover, when syllabifying a word like vintner[vIntnr], the theory allows both [vIn-tnr] and [vInt-nr], even though [tn] is an illegal onset in English.Both the Legality Principle and SSP tell us whichonsets and codas are permitted in legal syllables, andwhich are not.
However, neither theory gives us anyguidance when deciding between legal onsets.
TheMaximal Onset Principle addresses this by statingwe should extend a syllable?s onset at the expenseof the preceding syllable?s coda whenever it is legalto do so (Kahn, 1976).
For example, the principlegives preference to [-skju] and [vIn-tI] over theiralternatives.3 Previous Computational ApproachesUnlike tasks such as part of speech tagging or syn-tactic parsing, syllabification does not involve struc-tural ambiguity.
It is generally believed that syllablestructure is usually predictable in a language pro-vided that the rules have access to all conditioningfactors: stress, morphological boundaries, part ofspeech, etymology, etc.
(Blevins, 1995).
However,in speech applications, the phonemic transcription ofa word is often the only linguistic information avail-able to the system.
This is the common assumptionunderlying a number of computational approachesthat have been proposed for the syllabification ofphonemes.Daelemans and van den Bosch (1992) present oneof the earliest systems on automatic syllabification:a neural network-based implementation for Dutch.Daelemans et al (1997) also explore the applicationof exemplar-based generalization (EBG), sometimescalled instance-based learning.
EBG generally per-forms a simple database look-up to syllabify a testpattern, choosing the most common syllabification.In cases where the test pattern is not found in thedatabase, the most similar pattern is used to syllab-ify the test pattern.Hidden Markov Models (HMMs) are anotherpopular approach to syllabification.
Krenn (1997)introduces the idea of treating syllabification as a309tagging task.
Working from a list of syllabifiedphoneme strings, she automatically generates tagsfor each phone.
She uses a second-order HMM topredict sequences of tags; syllable boundaries can betrivially recovered from the tags.
Demberg (2006)applies a fourth-order HMM to the syllabificationtask, as a component of a larger German text-to-speech system.
Schmid et al (2007) improve onDemberg?s results by applying a fifth-order HMMthat conditions on both the previous tags and theircorresponding phonemes.Kiraz and Mo?bius (1998) present a weightedfinite-state-based approach to syllabification.
Theirlanguage-independent method builds an automatonfor each of onsets, nuclei, and codas, by count-ing occurrences in training data.
These automatonsare then composed into a transducer accepting se-quences of one or more syllables.
They do not reportquantitative results for their method.Pearson et al (2000) compare two rule-based sys-tems (they do not elaborate on the rules employed)with a CART decision tree-based approach and a?global statistics?
algorithm.
The global statisticsmethod is based on counts of consonant clustersin contexts such as word boundaries, short vow-els, or long vowels.
Each test word has syllableboundaries placed according to the most likely lo-cation given a cluster and its context.
In experi-ments performed with their in-house dataset, theirstatistics-based method outperforms the decision-tree approach and the two rule-based methods.Mu?ller (2001) presents a hybrid of a categori-cal and data-driven approach.
First, she manuallyconstructs a context-free grammar of possible sylla-bles.
This grammar is then made probabilistic usingcounts obtained from training data.
Mu?ller (2006)attempts to make her method language-independent.Rather than hand-crafting her context-free grammar,she automatically generates all possible onsets, nu-clei, and codas, based on the phonemes existing inthe language.
The results are somewhat lower thanin (Mu?ller, 2001), but the approach can be more eas-ily ported across languages.Goldwater and Johnson (2005) also explore us-ing EM to learn the structure of English and Ger-man phonemes in an unsupervised setting, followingMu?ller in modeling syllable structure with PCFGs.They initialize their parameters using a deterministicparser implementing the sonority principle and esti-mate the parameters for their maximum likelihoodapproach using EM.Marchand et al (2007) apply their Syllabificationby Analogy (SbA) technique, originally developedfor orthographic forms, to the pronunciation do-main.
For each input word, SbA finds the most sim-ilar substrings in a lexicon of syllabified phonemestrings and then applies the dictionary syllabifica-tions to the input word.
Their survey paper also in-cludes comparisons with a method broadly based onthe legality principle.
The authors find their legality-based implementation fares significantly worse thanSbA.4 Categorical ApproachesCategorical approaches to syllabification are appeal-ing because they are efficient and linguistically intu-itive.
In addition, they require little or no syllable-annotated data.
We present three categorical al-gorithms that implement the linguistic insights out-lined in Section 2.
All three can be viewed as vari-ations on the basic pseudo-code shown in Figure 1.Every vowel is labeled as a nucleus, and every con-sonant is labeled as either an onset or a coda.
Thealgorithm labels all consonants as onsets unless it isillegal to do so.
Given the labels, it is straightfor-ward to syllabify a word.
The three methods differin how they determine a ?legal?
onset.As a rough baseline, the MAXONSET implemen-tation considers all combinations of consonants to belegal onsets.
Only word-final consonants are labeledas codas.LEGALITY combines the Legality Principle withonset maximization.
In our implementation, we col-lect all word-initial consonant clusters from the cor-pus and deem them to be legal onsets.
With thismethod, no syllable can have an onset that does notappear word-initially in the training data.
We do nottest for the legality of codas.
The performance ofLEGALITY depends on the number of phonetic tran-scriptions that are available, but the transcriptionsneed not be annotated with syllable breaks.SONORITY combines the Sonority SequencingPrinciple with onset maximization.
In this approach,an onset is considered legal if every member of theonset ranks lower on the sonority scale than ensuing310until current phoneme is a vowellabel current phoneme as an onsetend loopuntil all phonemes have been labeledlabel current phoneme as a nucleusif there are no more vowels in the wordlabel all remaining consonants as codaselseonset := all consonants before next vowelcoda := emptyuntil onset is legalcoda := coda plus first phoneme of onsetonset := onset less first phonemeend loopend ifend loopInsert syllable boundaries before onsetsFigure 1: Pseudo-code for syllabifying a string ofphonemes.consonants.
SONORITY requires no training data be-cause it implements a sound linguistic theory.
How-ever, an existing development set for a given lan-guage can help with defining and validating addi-tional language-specific constraints.Several sonority scales of varying complexityhave been proposed.
For example, Selkirk (1984)specifies a hierarchy of eleven distinct levels.
Weadopt a minimalistic scale shown in Figure 2. whichavoids most of the disputed sonority contrasts (Janyet al, 2007).
We set the sonority distance parame-ter to 2, which ensures that adjacent consonants inthe onset differ by at least two levels of the scale.For example, [pr] is an acceptable onset because itis composed of an obstruent and a liquid, but [pn] isnot, because nasals directly follow obstruents on oursonority scale.In addition, we incorporate several English-specific constraints listed by Kenstowicz (1994,pages 257?258).
The constraints, or filters, prohibitcomplex onsets containing:(i) two labials (e.g., [pw], [bw], [fw], [vw]),(ii) a non-strident coronal followed by a lateral(e.g., [tl], [dl], [Tl])(iii) a voiced fricative (e.g., [vr], [zw], except [vj]),(iv) a palatal consonant (e.g., [Sl], [?r], except [Sr]).Sound Examples LevelVowels u, , .
.
.
4Glides w, j, .
.
.
3Liquids l, r, .
.
.
2Nasals m, N, .
.
.
1Obstruents g, T, .
.
.
0Figure 2: The sonority scale employed by SONORITY.A special provision allows for prepending thephoneme [s] to onsets beginning with a voicelessplosive.
This reflects the special status of [s] in En-glish, where onsets like [sk] and [sp] are legal eventhough the sonority is not strictly increasing.5 Supervised Approach: SVM-HMMIf annotated data is available, a classifier can betrained to predict the syllable breaks.
A SupportVector Machine (SVM) is a discriminative super-vised learning technique that allows for a rich fea-ture representation of the input space.
In principle,we could use a multi-class SVM to classify eachphoneme according to its position in a syllable onthe basis of a set of features.
However, a traditionalSVM would treat each phoneme in a word as an in-dependent instance, preventing us from consideringinteractions between labels.
In order to overcomethis shortcoming, we employ an SVM-HMM1 (Al-tun et al, 2003), an instance of the Structured SVMformalism (Tsochantaridis et al, 2004) that has beenspecialized for sequence tagging.When training a structured SVM, each traininginstance xi is paired with its label yi, drawn fromthe set of possible labels, Yi.
In our case, the train-ing instances xi are words, represented as sequencesof phonemes, and their labels yi are syllabifications,represented as sequences of onset/nucleus/coda tags.For each training example, a feature vector ?
(x, y)represents the relationship between the example anda candidate tag sequence.
The SVM finds a weightvector w, such that w ??
(x, y) separates correct tag-gings from incorrect taggings by as large a marginas possible.
Hamming distance DH is used to cap-ture how close a wrong sequence y is to yi, which1http://svmlight.joachims.org/svm struct.html311in turn impacts the required margin.
Tag sequencesthat share fewer tags in common with the correct se-quence are separated by a larger margin.Mathematically, a (simplified) statement of theSVM learning objective is:?i?y?Yi,y 6=yi :[?
(xi, yi) ?
w > ?
(xi, y) ?
w +DH(y, yi)] (1)This objective is only satisfied when w tags all train-ing examples correctly.
In practice, slack variablesare introduced, which allow us to trade off trainingaccuracy and the complexity of w via a cost parame-ter.
We tune this parameter on our development set.The SVM-HMM training procedure repeatedlyuses the Viterbi algorithm to find, for the currentw and each (xi, yi) training pair, the sequence ythat most drastically violates the inequality shown inEquation 1.
These incorrect tag sequences are addedto a growing set, which constrains the quadratic op-timization procedure used to find the next w. Theprocess iterates until no new violating sequences arefound, producing an approximation to the inequalityover all y ?
Yi.
A complete explanation is given byTsochantaridis et al (2004).Given a weight vector w, a structured SVM tagsnew instances x according to:argmaxy?Y [?
(x, y) ?
w] (2)The SVM-HMM gets the HMM portion of its namefrom its use of the HMM Viterbi algorithm to solvethis argmax.5.1 FeaturesWe investigated several tagging schemes, describedin detail by Bartlett (2007).
During development,we found that tagging each phoneme with its syl-labic role (Krenn, 1997) works better than the simplebinary distinction between syllable-final and otherphonemes (van den Bosch, 1997).
We also dis-covered that accuracy can be improved by number-ing the tags.
Therefore, in our tagging scheme, thesingle-syllable word strengths [strENTs] would be la-beled with the sequence {O1 O2 O3 N1 C1 C2 C3}.Through the use of the Viterbi algorithm, our fea-ture vector ?
(x, y) is naturally divided into emis-sion and transition features.
Emission features linkan aspect of the input word x with a single tag in theMethod EnglishMAXONSET 61.38LEGALITY 93.16SONORITY 95.00SVM-HMM 98.86tsylb 93.72Table 1: Word accuracy on the CELEX dataset.sequence y.
Unlike a generative HMM, these emis-sion features do not require any conditional indepen-dence assumptions.
Transition features link tags totags.
Our only transition features are counts of adja-cent tag pairs occurring in y.For the emission features, we use the currentphoneme and a fixed-size context window of sur-rounding phonemes.
Thus, the features for thephoneme [k] in hockey [hAki] might include the [A]preceding it, and the [i] following it.
In experimentson our development set, we found that the optimalwindow size is nine: four phonemes on either sideof the focus phoneme.
Because the SVM-HMM is alinear classifier, we need to explicitly state any im-portant conjunctions of features.
This allows us tocapture more complex patterns in the language thatunigrams alone cannot describe.
For example, thebigram [ps] is illegal as an onset in English, but per-fectly reasonable as a coda.
Experiments on the de-velopment set showed that performance peaked us-ing all unigrams, bigrams, trigrams, and four-gramsfound within our context window.6 Syllabification ExperimentsWe developed our approach using the English por-tion of the CELEX lexical database (Baayen et al,1995).
CELEX provides the phonemes of a wordand its correct syllabification.
It does not designatethe phonemes as onsets, nuclei, or codas, which isthe labeling we want to predict.
Fortunately, extract-ing the labels from a syllabified word is straightfor-ward.
All vowel phones are assigned to be nuclei;consonants preceding the nucleus in a syllable areassigned to be onsets, while consonants followingthe nucleus in a syllable are assigned to be codas.The results in Table 1 were obtained on a test setof 5K randomly selected words.
For training theSVM-HMM, we randomly selected 30K words not312appearing in the test set, while 6K training exampleswere held out for development testing.
We reportthe performance in terms of word accuracy (entirewords syllabified correctly).
Among the categori-cal approaches, SONORITY clearly outperforms notonly LEGALITY, but also tsylb (Fisher, 1996), animplementation of the complex algorithm of Kahn(1976), which makes use of lists of legal Englishonsets.
Overall, our SVM-based approach is a clearwinner.The results of our discriminative method com-pares favorably with the results of competing ap-proaches on English CELEX.
Since there are nostandard train-test splits for syllabification, thecomparison is necessarily indirect, but note thatour training set is substantially smaller.
Forher language-independent PCFG-based approach,Mu?ller (2006) reports 92.64% word accuracy on theset of 64K examples from CELEX using 10-foldcross-validation.
The Learned EBG approach ofvan den Bosch (1997) achieves 97.78% word accu-racy when training on approximately 60K examples.Therefore, our results represent a nearly 50% reduc-tion of the error rate.Figure 3: Word accuracy on English CELEX as a func-tion of the number of thousands of training examples.Though the SVM-HMM?s training data require-ments are lower than previous supervised syllabi-fication approaches, they are still substantial.
Fig-ure 3 shows a learning curve over varying amountsof training data.
Performance does not reach accept-able levels until 5K training examples are provided.6.1 Error AnalysisThere is a fair amount of overlap in the errors madeby the SVM-HMM and the SONORITY.
Table 4shows a few characteristic examples.
The CELEXsyllabifications of tooth-ache and pass-ports fol-low the morphological boundaries of the compoundwords.
Morphological factors are a source of er-rors for both approaches, but significantly more sofor SONORITY.
The performance difference comesmainly from the SVM?s ability to handle many ofthese morphological exceptions.
The SVM gener-ates the correct syllabification of northeast [norT-ist], even though an onset of [T] is perfectly legal.On the other hand, the SVM sometimes overgener-alizes, as in the last example in Table 4.SVM-HMM SONORITYtu-Tek tu-Tek toothachepae-sports pae-sports passportsnorT-ist nor-Tist northeastdIs-plizd dI-splizd displeaseddIs-koz dI-skoz discosFigure 4: Examples of syllabification errors.
(Correctsyllabifications are shown in bold.
)6.2 The NETtalk DatasetMarchand et al (2007) report a disappointing wordaccuracy of 54.14% for their legality-based imple-mentation, which does not accord with the resultsof our categorical approaches on English CELEX.Consequently, we also apply our methods to thedataset they used for their experiments: the NETtalkdictionary.
NETtalk contains 20K English words; inthe experiments reported here, we use 13K trainingexamples and 7K test words.As is apparent from Table 2, our performancedegrades significantly when switching to NETtalk.The steep decline found in the categorical meth-ods is particularly notable, and indicates significantdivergence between the syllabifications employedin the two datasets.
Phonologists do not alwaysagree on the correct syllable breaks for a word,but the NETtalk syllabifications are often at oddswith linguistic intuitions.
We randomly selected 50words and compared their syllabifications againstthose found in Merriam-Webster Online.
We foundthat CELEX syllabifications agree with Merriam-Webster in 84% of cases, while NETtalk only agrees52% of the time.Figure 5 shows several words from the NETtalk313Method EnglishMAXONSET 33.64SONORITY 52.80LEGALITY 53.08SVM-HMM 92.99Table 2: Word accuracy on the NETtalk dataset.and CELEX datasets.
We see that CELEX fol-lows the maximal onset principle consistently, whileNETtalk does in some instances but not others.
Wealso note that there are a number of NETtalk syllab-ifications that are clearly wrong, such as the last twoexamples in Figure 5.
The variability of NETtalkis much more difficult to capture with any kind ofprincipled approach.
Thus, we argue that low per-formance on NETtalk indicate inconsistent syllabi-fications within that dataset, rather than any actualdeficiency of the methods.NETtalk CELEX?aes-taIz ?ae-staIz chastiserEz-Id-ns rE-zI-dns residencedI-strOI dI-strOI destroyfo-tAn fo-tAn photonAr-pE-io Ar-pE-i-o arpeggioDer--baU-t DE-r-baUt thereaboutFigure 5: Examples of CELEX and NETtalk syllabifica-tions.NETtalk?s variable syllabification practicesnotwithstanding, the SVM-HMM approach stilloutperforms the previous benchmark on the dataset.Marchand et al (2007) report 88.53% word accu-racy for their SbA technique using leave-one-outtesting on the entire NETtalk set (20K words).
Withfewer training examples, we reduce the error rate byalmost 40%.6.3 Other LanguagesWe performed experiments on German and Dutch,the two other languages available in the CELEX lex-ical database.
The German and Dutch lexicons ofCELEX are larger than the English lexicon.
For bothlanguages, we selected a 25K test set, and two dif-ferent training sets, one containing 50K words andthe other containing 250K words.
The results areMethod German DutchMAXONSET 19.51 23.44SONORITY 76.32 77.51LEGALITY 79.55 64.31SVM-HMM (50K words) 99.26 97.79SVM-HMM (250K words) 99.87 99.16Table 3: Word accuracy on the CELEX dataset.presented in Table 3.While our SVM-HMM approach is entirely lan-guage independent, the same cannot be said aboutother methods.
The maximal onset principle appearsto hold much more strongly for English than for Ger-man and Dutch (e.g., patron: [pe-trn] vs. [pat-ron]).LEGALITY and SONORITY also appear to be lesseffective, possibly because of greater tendency forsyllabifications to match morphological boundaries(e.g., English exclusive: [Ik-sklu-sIv] vs. Dutch ex-clusief [Eks-kly-zif]).
SONORITY is further affectedby our decision to employ the constraints of Ken-stowicz (1994), although they clearly pertain to En-glish.
We expect that adapting them to specific lan-guages would bring the results closer to the level ofthe English experiments.Although our SVM system is tuned using anEnglish development set, the results on both Ger-man and Dutch are excellent.
We could not findany quantitative data for comparisons on Dutch,but the comparison with the previously reported re-sults on German CELEX demonstrates the qual-ity of our approach.
The numbers that follow re-fer to 10-fold cross-validation on the entire lex-icon (over 320K entries) unless noted otherwise.Krenn (1997) obtains tag accuracy of 98.34%, com-pared to our system?s tag accuracy of 99.97% whentrained on 250K words.
With a hand-crafted gram-mar, Mu?ller (2002) achieves 96.88% word accuracyon CELEX-derived syllabifications, with a trainingcorpus of two million tokens.
Without a hand-crafted grammar, she reports 90.45% word accu-racy (Mu?ller, 2006).
Applying a standard smoothingalgorithm and fourth-order HMM, Demberg (2006)scores 98.47% word accuracy.
A fifth-order jointN -gram model of Schmid et al (2007) achieves99.85% word accuracy with about 278K trainingpoints.
However, unlike generative approaches, our314Method English GermanSONORITY 97.0 94.2SVM-HMM 99.9 99.4Categorical Parser 94.9 92.7Maximum Likelihood 98.1 97.4Table 4: Word accuracy on the datasets of Goldwater andJohnson (2005).SVM-HMM can condition each emission on largeportions of the input using only a first-order Markovmodel, which implies much faster syllabificationperformance.6.4 Direct Comparison with an MLE approachThe results of the competitive approaches that havebeen quoted so far (with the exception of tsylb)are not directly comparable, because neither the re-spective implementations, nor the actual train-testsplits are publicly available.
However, we managedto obtain the English and German data sets usedby Goldwater and Johnson (2005) in their study,which focused primarily on unsupervised syllabi-fication.
Their experimental framework is similarto (Mu?ller, 2001).
They collect words from runningtext and create a training set of 20K tokens and atest set of 10K tokens.
The running text was takenfrom the Penn WSJ and ECI corpora, and the syl-labified phonemic transcriptions were obtained fromCELEX.
Table 4 compares our experimental resultswith their reported results obtained with: (a) su-pervised Maximum Likelihood training procedures,and (b) a Categorical Syllable Parser implementingthe principles of sonority sequencing and onset max-imization without Kenstowicz?s (1994) onset con-straints.The accuracy figures in Table 4 are noticeablyhigher than in Table 1.
This stems from fundamen-tal differences in the experimental set-up; Goldwaterand Johnson (2005) test on tokens as found in text,therefore many frequent short words are duplicated.Furthermore, some words occur during both trainingand testing, to the benefit of the supervised systems(SVM-HMM and Maximum Likelihood).
Neverthe-less, the results confirm the level of improvementobtained by both our categorical and supervised ap-proaches.7 ConclusionWe have presented several different approaches tothe syllabification of phonemes.
The results of ourlinguistically-motivated algorithms, show that it ispossible to achieve adequate syllabification wordaccuracy in English with no little or no syllable-annotated training data.
We have demonstrated thatthe poor performance of categorical methods on En-glish NETtalk actually points to problems with theNETtalk annotations, rather than with the methodsthemselves.We have also shown that SVM-HMMs can beused to great effect when syllabifying phonemes.In addition to being both efficient and language-independent, they establish a new state-of-the-art forEnglish and Dutch syllabification.
However, theydo require thousands of labeled training examples toachieve this level of accuracy.
In the future, we planto explore a hybrid approach, which would benefitfrom both the generality of linguistic principles andthe smooth exception-handling of supervised tech-niques, in order to make best use of whatever data isavailable.AcknowledgementsWe are grateful to Sharon Goldwater for providingthe experimental data sets for comparison.
This re-search was supported by the Natural Sciences andEngineering Research Council of Canada and theAlberta Informatics Circle of Research Excellence.ReferencesYasemin Altun, Ioannis Tsochantaridis, and ThomasHofmann.
2003.
Hidden markov support vector ma-chines.
Proceedings of the 20Th International Confer-ence on Machine Learning (ICML).R.
Baayen, R. Piepenbrock, and L. Gulikers.
1995.
TheCELEX lexical database (CD-ROM).Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.2008.
Automatic syllabification with structured SVMsfor letter-to-phoneme conversion.
In Proceedings ofACL-08: HLT, pages 568?576, Columbus, Ohio.Susan Bartlett.
2007.
Discriminative approach to auto-matic syllabification.
Master?s thesis, Department ofComputing Science, University of Alberta.Juliette Blevins.
1995.
The syllable in phonologicaltheory.
In John Goldsmith, editor, The handbook ofphonological theory, pages 206?244.
Blackwell.315Gosse Bouma.
2002.
Finite state methods for hyphen-ation.
Natural Language Engineering, 1:1?16.David Crystal.
2003.
A dictionary of linguistics and pho-netics.
Blackwell.Walter Daelemans and Antal van den Bosch.
1992.
Gen-eralization performance of backpropagaion learningon a syllabification task.
In Proceedings of the 3rdTwente Workshop on Language Technology, pages 27?38.Walter Daelemans, Antal van den Bosch, and Ton Wei-jters.
1997.
IGTree: Using trees for compression andclassification in lazy learning algorithms.
Artificial In-telligence Review, pages 407?423.Robert Damper.
2001.
Learning about speech fromdata: Beyond NETtalk.
In Data-Driven Techniques inSpeech Synthesis, pages 1?25.
Kluwer Academic Pub-lishers.Vera Demberg.
2006.
Letter-to-phoneme conversion fora German text-to-speech system.
Master?s thesis, Uni-versity of Stuttgart.William Fisher.
1996.
Tsylb syllabification package.ftp://jaguar.ncsl.nist.gov/pub/tsylb2-1.1.tar.Z.
Last ac-cessed 31 March 2008.Sharon Goldwater and Mark Johnson.
2005.
Represen-tational bias in usupervised learning of syllable struc-ture.
In Prcoeedings of the 9th Conference on Compu-tational Natural Language Learning (CoNLL), pages112?119.Jeremy Goslin and Ulrich Frauenfelder.
2001.
A com-parison of theoretical and human syllabification.
Lan-guage and Speech, 44:409?436.Carmen Jany, Matthew Gordon, Carlos M Nash, andNobutaka Takara.
2007.
How universal is the sonor-ity hierarchy?
A cross-linguistic study.
In 16th Inter-national Congress of Phonetic Sciences, pages 1401?1404.Daniel Kahn.
1976.
Syllable-based generalizations inEnglish Phonology.
Ph.D. thesis, Indiana University.Michael Kenstowicz.
1994.
Phonology in GenerativeGrammar.
Blackwell.George Kiraz and Bernd Mo?bius.
1998.
Multilingualsyllabification using weighted finite-state transducers.In Proceedings of the 3rd Workshop on Speech Synthe-sis.Brigitte Krenn.
1997.
Tagging syllables.
In Proceedingsof Eurospeech, pages 991?994.Yannick Marchand and Robert Damper.
2007.
Can syl-labification improve pronunciation by analogy of En-glish?
Natural Language Engineering, 13(1):1?24.Yannick Marchand, Connie Adsett, and Robert Damper.2007.
Automatic syllabification in English: A com-parison of different algorithms.
Language and Speech.To appear.Karin Mu?ller, Bernd Mo?bius, and Detlef Prescher.
2000.Inducing probabilistic syllable classes using multivari-ate clustering.
In Prcoeedings of the 38th meeting ofthe ACL.Karin Mu?ller.
2001.
Automatic detection of syllableboundaries combining the advantages of treebank andbracketed corpora training.
Proceedings on the 39ThMeeting of the ACL.Karin Mu?ller.
2002.
Probabilistic context-free grammarsfor phonology.
Proceedings of the 6th Workshop of theACL Special Interest Group in Computational Phonol-ogy (SIGPHON), pages 80?90.Karin Mu?ller.
2006.
Improving syllabification mod-els with phonotactic knowledge.
Proceedings of theEighth Meeting of the ACL Special Interest Group onComputational Phonology At HLT-NAACL.Steve Pearson, Roland Kuhn, Steven Fincke, and NickKibre.
2000.
Automatic methods for lexical stress as-signment and syllabification.
In Proceedings of the 6thInternational Conference on Spoken Language Pro-cessing (ICSLP).Helmut Schmid, Bernd Mo?bius, and Julia Weidenkaff.2007.
Tagging syllable boundaries with joint N-grammodels.
In Proceedings of Interspeech.Elisabeth Selkirk.
1984.
On the major class features andsyllable theory.
In Language Sound Structure.
MITPress.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemin Altun.
2004.
Support vec-tor machine learning for interdependent and structuredoutput spaces.
Proceedings of the 21st InternationalConference on Machine Learning (ICML).Antal van den Bosch.
1997.
Learning to pronouncewritten words: a study in inductive language learning.Ph.D.
thesis, Universiteit Maastricht.316
