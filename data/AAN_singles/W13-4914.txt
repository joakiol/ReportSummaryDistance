Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 119?128,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsContext Based Statistical Morphological Analyzer and its Effect on HindiDependency ParsingDeepak Kumar Malladi and Prashanth MannemLanguage Technologies Research CenterInternational Institute of Information TechnologyHyderabad, AP, India - 500032{deepak.malladi, prashanth}@research.iiit.ac.inAbstractThis paper revisits the work of (Malladi andMannem, 2013) which focused on buildinga Statistical Morphological Analyzer (SMA)for Hindi and compares the performance ofSMA with other existing statistical analyzer,Morfette.
We shall evaluate SMA in vari-ous experiment scenarios and look at how itperforms for unseen words.
The later partof the paper presents the effect of the pre-dicted morph features on dependency parsingand extends the work to other morphologicallyrich languages: Hindi and Telugu, without anylanguage-specific engineering.1 IntroductionHindi is one of the widely spoken language in theworld with more than 250 million native speakers1.Language technologies could play a major role in re-moving the digital divide that exists between speak-ers of various languages.
Hindi, being a morpho-logically rich language with a relatively free wordorder (Mor-FOW), poses a variety of challenges forNLP that may not be encountered when working onEnglish.Morphological analysis is the task of analyzingthe structure of morphemes in a word and is gen-erally a prelude to further complex tasks such asparsing, machine translation, semantic analysis etc.These tasks need an analysis of the words in thesentence in terms of lemma, affixes, parts of speech(POS) etc.1http://www.ethnologue.com/statistics/sizeNLP for Hindi has suffered due to the lackof a high coverage automatic morphological ana-lyzer.
For example, the 2012 Hindi Parsing SharedTask (Sharma et al 2012) held with COLING-2012 workshop had a gold-standard input track andan automatic input track, where the former hadgold-standard morphological analysis, POS tags andchunks of a sentence as input and the automatic trackhad only the sentence along with automatic POStags as input.
The morphological information whichis crucial for Hindi parsing was missing in the au-tomatic track as the existing analyzer had limitedcoverage.
Parsing accuracies of gold-standard inputtrack were significantly higher than that of the othertrack.
But in the real scenario NLP applications,gold information is not provided.
Even Ambati etal.
(2010b) and Bharati et al(2009a) have exploitedthe role of morpho-syntactic features in Hindi de-pendency parsing.
Hence we need a high coverageand accurate morphological analyzer.2 Related workPrevious efforts on Hindi morphological analysisconcentrated on building rule based systems thatgive all the possible analyses for a word form ir-respective of its context in the sentence.
Theparadigm based analyzer (PBA) by Bharati et al(1995) is one of the most widely used applicationsamong researchers in the Indian NLP community.In paradigm based analysis, words are grouped intoa set of paradigms based on the inflections they take.Each paradigm has a set of add-delete rules to ac-count for its inflections and words belonging to aparadigm take the same inflectional forms.
Given a119L G N P C T/V?
?
?
?
?
?xeSa(country)xeSa m sg 3 d 0xeSa m pl 3 d 0xeSa m sg 3 o 0cAhie(want)cAha any sg 2h iecAha any pl 2h eML-lemma, G-gender, N-number, P-personC-case, T/V-TAM or VibhaktiTable 1: Multiple analyses given by the PBA for thewords xeSa and cAhieword, the PBA identifies the lemma, coarse POS tag,gender, number, person, case marker, vibhakti2 andTAM (tense, aspect, modality).
Being a rule-basedsystem, the PBA takes a word as input and gives allthe possible analyses as output.
(Table 1 presents anexample).
It doesn?t pick the correct analysis for aword in its sentential context.Goyal and Lehal?s analyser (2008), which is a re-implementation of the PBA with few extensions, hasnot done any comparative evaluation.
Kanuparthiet al(2012) built a derivational morphological ana-lyzer for Hindi by introducing a layer over the PBA.It identifies 22 derivational suffixes which helps inproviding derivational analysis for the word whosesuffix matches with one of these 22 suffixes.The large scale machine translation projects3 thatare currently under way in India use shallow parserbuilt on PBA and an automatic POS tagger.
Theshallow parser prunes the morphological analysesfrom PBA to select the correct one using the POStags from the tagger.
Since it is based on PBA, itsuffers from similar coverage issues for out of vo-cabulary (OOV) words.The PBA, developed in 1995, has a limited vo-cabulary and has received only minor upgrades sincethen.
Out of 17,666 unique words in the Hindi Tree-bank (HTB) released during the 2012 Hindi ParsingShared Task (Sharma et al 2012), the PBA doesnot have entries for 5,581 words (31.6%).Apart from the traditional rule-based approaches,Morfette (Chrupa?a et al 2008) is a modular, data-2Vibhakti is a Sanskrit grammatical term that encompassespost-positionals and case endings for nouns, as well as inflec-tion and auxiliaries for verbs (Pedersen et al 2004).3http://sampark.iiit.ac.in/Data #Sentences #WordsTraining 12,041 268,096Development 1,233 26,416Test 1,828 39,775Table 2: HTB statisticsdriven, probabilistic system which learns to performjoint morphological tagging and lemmatization frommorphologically annotated corpora.
The system iscomposed of two learning modules, one for mor-phological tagging and one for lemmati- zation, andone decoding module which searches for the best se-quence of pairs of morphological tags and lemmasfor an input sequence of wordforms.Malladi and Mannem (2013) have build a Statis-tical Morphological Analyzer (SMA) with minimalset of features but they haven?t compared their sys-tem with Morfette.
In our work we shall discussin detail about SMA with more concentration onevaluating the system in various scenarios and shallextend the approach to other morphologically richlanguages.
Later we evaluate the effect of the pre-dicted morph features (by SMA) on Hindi depen-dency parsing.3 Hindi Dependency Treebank (HTB)A multi layered and multi representational tree-bank for Hindi is developed by annotating withmorpho-syntactic (morphological analyses, POStags, chunk) and syntacto-semantic (dependency re-lations labeled in the computational paninian frame-work) information.
A part of the HTB (constitutingof 15,102 sentences) was released for Hindi Pars-ing Shared Task.
Table 2 shows the word counts oftraining, development and test sections of HTB.With the existing morph analyzer (PBA) perform-ing poorly on OOV words and the availability of anannotated treebank, Malladi and Mannem (2013) setout to build a high-coverage automatic Hindi morphanalyzer by learning each of the seven morpholog-ical attributes separately from the Hindi Treebank.During this process, it was realized that vibhaktiand TAM can be better predicted using heuristics onfine-grained POS tags than by training on the HTB.In the rest of the section, we discuss the meth-ods used by SMA to predict each of the seven mor-120MorphFeature ValuesGender masculine, feminine, any, noneNumber singular, plural, any, nonePerson 1, 1h, 2, 2h, 3, 3h, any, noneCaseMarker direct, oblique, any, noneTable 3: Morph features and the values they takesource target glossk i y A k a r a dol a d a k e l a d a k A boyl a d a k I l a d a k I girll a d a k I y A M l a d a k I girlTable 4: Sample parallel corpus for lemma predictionphological attributes and their effect on Hindi depen-dency parsing.
Table 3 lists the values that each ofthe morph attributes take in HTB.4 Statistical Morphological Analyzer(SMA)The output of a morphological analyzer depends onthe language that it is developed for.
Analyzers forEnglish (Goldsmith, 2000) predict just the lemmasand affixes mainly because of its restricted agree-ment based on semantic features such as animacyand natural gender.
But in Hindi, agreement de-pends on lexical features such as grammatical gen-der, number, person and case.
Hence, it is crucialthat Hindi analyzers predict these along with TAMand vibhakti which have been found to be useful forsyntactic parsing (Ambati et al 2010b; Bharati etal., 2009a).Hindi has syntactic agreement (of GNP and case)of two kinds: modifier-head agreement and noun-verb agreement.
Modifiers, including determiners,agree with their head noun in gender, number andcase, and finite verbs agree with some noun in thesentence in gender, number and person (Kachru,2006).
Therefore, apart from lemma and POS tags,providing gender, number and person is also crucialfor syntactic parsing.44While nouns, pronouns and adjectives have both GNP andcase associated with them, verbs only have GNP.
TAM is validonly for verbs and vibhakti (post-position) is only associatedwith nouns and pronouns.4.1 Lemma predictionThe PBA uses a large vocabulary along withparadigm tables consisting of add-delete rules to findthe lemma of a given word.
All possible add-deleterules are applied on a given word form and the re-sulting lemma is checked against the vocabulary tofind if it is right or not.
If no such lemma exists (forOOV words), it returns the word itself as the lemma.While the gender, number and person of a wordform varies according to the context (due to syntac-tic agreement with head words), there are very fewcases where a word form can have more than onelemma in a context.
For example, vaha can eitherbe masculine or feminine depending on the form thatthe verb takes.
It is feminine in vaha Gara gayI(she went home) and masculine in vaha GaragayA (he went home).
The lemma for vaha canonly be vaha irrespective of the context and alsothe lemma for gayI and gayA is jA.
This makeslemma simpler to predict among the morphologicalfeatures, provided there is access to a dictionary ofall the word forms along with their lemmas.
Unfor-tunately, such a large lemma dictionary doesn?t ex-ist.
There are 15,752 word types in training, 4,292word types in development and 5,536 word typesin test sections of HTB respectively.
Among these18.5% of the types in development and 20.2% in testdata are unseen in training data.SMA analyzer perceives lemma prediction from amachine translation perspective, with the charactersin the input word form treated as the source sentenceand those in the lemma as the target.
The stringson source and target side are split into sequencesof characters separated by space, as shown in Ta-ble 4.
The phrase based model (Koehn et al 2007)in Moses is trained on the parallel data created fromthe training part of HTB.
The translation model ac-counts for the changes in the affixes (sequence ofcharacters) from word form to lemma whereas thelanguage model accounts for which affixes go withwhich stems.
In this perspective, the standard MTexperiment of switching source and target to attainbetter accuracy would not apply since it is unrea-sonable to predict the word form from the lemmawithout taking the context into account.Apart from the above mentioned approach, we ap-ply a heuristic on top of SMA, wherein proper nouns121Gender Word Glossmasculine cAvala, paMKA rice, fanfeminine rela, xAla train, pulseany jA gonone karIba nearTable 5: Gender value examplesNumber Word Glosssingular ladZake boy-Sg-Obliqueplural ladZake boy-Pl-Directany banA makenone karIba nearTable 6: Number value examples(NNP) take the word form itself as the lemma.4.2 Gender, Number, Person and CasePredictionUnlike lemma prediction, SMA uses SVM (supportvector machine) machine learning algorithm to pre-dict GNP and case.Though knowing the syntactic head of a wordhelps in enforcing agreement (and thereby accu-rately predicting the correct GNP), parsing is usu-ally a higher level task and is not performed be-fore morphological analysis.
Hence, certain cases ofGNP prediction are similar in nature to the standardchicken and egg problem.4.2.1 GenderGender prediction is tricky in Hindi as even nativespeakers tend to make errors while annotating.
Gen-der prediction in English is easy when compared toHindi since gender in English is inferred based onthe biological characteristics the word is referringto.
For example, Train has neuter gender in En-glish whereas in Hindi, it exhibits feminine charac-teristics.
A dictionary of word-gender informationmay usually suffice for gender prediction in Englishbut in Hindi it isn?t the case as gender could varybased on its agreement with verb/modifier.
The val-ues that gender can take for a word in a given contextare masculine(m), feminine(f ), any (either m or f ) ornone (neither m nor f ).
Table 5 gives example foreach gender value.Nouns inherently carry gender information.
Pro-Case Word Glossdirect ladZake boy-Ploblique ladZake boy-sgany bAraha twelve (cardinals)none kaha sayTable 7: Case value examplesnouns (of genitive form), adjectives and verbs inflectaccording to the gender of the noun they refer to.4.2.2 NumberEvery noun belongs to a unique number class.Noun modifiers and verbs have different forms foreach number class and inflect accordingly to matchthe grammatical number of the nouns to which theyrefer.Number takes the values singular (sg), plural (pl),any (either sg or pl) and none (neither sg nor pl).
Ta-ble 6 lists examples for each of the values.
In it,ladZake takes the grammatical number sg (in di-rect case) or pl (in oblique case) depending on thecontext in which it occurs.
It may be noted that sincePBA does not consider the word?s context, it outputsboth the values and leaves the disambiguation to thesubsequent stages.4.2.3 PersonApart from first, second and third persons, Hindialso has the honorific forms, resulting in 1h, 2h and3h.
Postpositions do not have person information,hence none is also a possible value.
Apart from theabove mentioned grammatical person values, any isalso a feasible value.4.2.4 Case MarkerCase markers in Hindi (direct and oblique) are at-tributed to nouns and pronouns.
Table 7 lists fewexamples.Words which inflect for gender, number, personand case primarily undergo affixation at the end.Features for GNP & Case MarkerThe following features were tried out in buildingthe models for gender, number, person and case pre-diction:?
Word level features?
Word122?
Last 2 characters?
Last 3 characters?
Last 4 characters?
Character N-grams of the word?
Lemma?
Word Length?
Sentence level features?
Lexical category5?
Next word?
Previous wordCombinations of these features have been triedout to build the SVM models for GNP and case.
Foreach of these tasks, feature tuning was done sep-arately.
In Malladi and Mannem (2013), a linearSVM classification (Fan et al 2008) is used to buildstatistical models for GNP and case but we foundthat with RBF kernel (non-linear SVM)6 we achievebetter accuracies.
Furthermore, the parameters (C,?)
of the RBF kernel are learned using grid searchtechnique.4.3 Vibhakti and TAMVibhakti and TAM are helpful in identifying thekaraka7 dependency labels in HTB.
While nounsand pronouns take vibhakti, verbs inflect for TAM.Both TAM and vibhakti occur immediately after thewords in their respective word classes.Instead of building statistical models for vibhaktiand TAM prediction, SMA uses heuristics on POStag sequences to predict the correct value.
The POStags of words following nouns, pronouns and verbsgive an indication as to what the vibhakti/TAM are.Words with PSP (postposition) and NST (noun withspatial and temporal properties) tags are generallyconsidered as the vibhakti for the preceding nounsand pronouns.
A postposition in HTB is annotatedas PSP only if it is written separately (usane/PRPvs usa/PRP ne/PSP).
For cases where the postposi-tion is not written separately SMA relies on the tree-bank data to get the suffix.
Similarly, words with5POS is considered as a sentence level feature since taggingmodels use the word ngrams to predict the POS category6LIBSVM tool is used to build non-linear SVM models forour experiments (Chang and Lin, 2011).7karakas are syntactico-semantic relations which are em-ployed in Paninian framework (Begum et al 2008; Bharati etal., 2009b)VAUX tag form the TAM for the immediately pre-ceding verb.The PBA takes individual words as input andhence does not output the entire vibhakti or TAMof the word in the sentence.
It only identifies thesevalues for those words which have the informationwithin the word form (e.g.
usakA he+Oblique,kiyA do+PAST).In the sentence,rAma/NNP kA/PSP kiwAba/NNcori/NN ho/VM sakawA/VAUXhE/VAUXPBA identifies rAma?s vibhakti as 0 and ho?s TAMas 0.
Whereas in HTB, vibhakti and TAM of rAmaand ho are annotated as 0 kA and 0 saka+wA hErespectively.
SMA determines this information pre-cisely and Morfette which can predict other morphfeatures, is not capable of predicting TAM and Vib-hakti as these features are specific to Indian lan-guages.5 Evaluation SystemsSMA is compared with a baseline system, Morfetteand two versions of the PBA wherever relevant.
Thebaseline system takes the word form itself as thelemma and selects the most frequent value for therest of the attributes.Since PBA is a rule based analyzer which givesmore than one analysis for words, we use two ver-sions of it for comparison.
The first system is theoracle PBA (referred further as O-PBA) which usesan oracle to pick the best analysis from the list ofall analyses given by the PBA.
The second versionof the PBA (F-PBA) picks the first analysis from theoutput as the correct analysis.Morfette can perdict lemma, gender, number, per-son and case attributes but it cannot predict TAMand Vibhakti as they do not have a definite set of pre-defined values unlike other morphological attributes.6 Experiments and ResultsSMA approach to Hindi morphological analysisis based on handling each of the seven attributes(lemma, gender, number, person, case, vibhakti andTAM) separately.
However, evaluation is performed123AnalysisTest Data - Overall(%) Test Data - OOV of SMA(%)Baseline F-PBA O-PBA Morfette SMA Baseline F-PBA O-PBA Morfette SMAL 71.12 83.10 86.69 94.14 95.84 78.10 82.08 82.48 90.30 89.51G 37.43 72.98 79.59 95.05 96.19 60.22 43.07 44.06 72.03 82.65N 52.87 72.22 80.50 94.09 95.37 69.60 44.53 47.56 84.89 90.44P 45.59 74.33 84.13 94.88 96.38 78.30 52.51 53.89 84.76 94.85C 29.31 58.24 81.20 93.91 95.32 43.60 31.40 47.36 80.21 88.52V/T 65.40 53.05 59.65 NA 97.04 58.31 33.58 34.56 NA 96.04L+C 16.46 48.84 72.06 88.56 91.39 32.52 28.50 44.66 72.89 79.09L+V/T 54.78 44.57 51.71 NA 93.06 53.56 31.73 32.72 NA 86.41G+N+P 23.05 61.10 73.81 88.36 91.11 47.49 35.75 39.58 62.33 76.52G+N+P+C 9.72 45.73 70.87 84.43 87.78 21.04 20.91 35.95 55.74 69.99L+G+N+P 20.27 53.29 66.28 83.44 87.51 44.72 34.63 38.46 57.85 69.13L+G+N+P+C 8.57 38.25 63.41 79.73 84.25 19.33 19.92 34.89 51.52 63.06L+G+N+P+C+V/T 1.25 32.53 42.80 NA 82.12 4.02 14.51 18.67 NA 60.07L-lemma, G-gender, N-number, P-person, C-case, V/T-Vibhakti/TAMTable 8: Accuracies of SMA compared with F-PBA, O-PBA and baseline systems.on individual attributes as well as on the combinedoutput.SMA builds models for lemma, gender, number,person and case prediction trained on the trainingdata of the HTB.
All the models are tuned on devel-opment data and evaluated on test data of the HTB.Table 8 presents the accuracies of five systems(baseline, F-PBA, O-PBA, Morfette and SMA) inpredicting the morphological attributes of all thewords in the HTB?s test data and also for OOVwords of SMA (i.e.
words that occur in the test sec-tion but not in training section of HTB)8.
The accu-racies are the percentages of words in the data withthe correct analysis.
It may be noted that SMA per-forms significantly better than the best analyses ofPBA and the baseline system in all the experimentsconducted.
As far as Morfette is concerned, it per-forms on par with SMA in terms of overall accuracybut for OOV words, except for lemma prediction,SMA outperforms Morfette by significant margin.Table 13 lists the accuracies of lemma, gender,number, person and case for the most frequently oc-curring POS tags.
Table 12 reports the same forOOV words.
The number of OOV words in postpo-8OOV words for SMA need not be out of vocabulary forPBA?s dictionaries.
Table 8 lists accuracies for OOV words ofSMA.
We shall also report accuracies for OOV words of PBAin the later part of the paper (Table 11).Metric Exp-1a Exp-2b Exp-3cLAS 87.75 89.41 89.82UAS 94.41 94.50 94.81LA 89.89 91.67 91.96Table 9: MALT Parser?s accuracies on HTB test data.Unlabeled Attachment Score (UAS) is the percentage ofwords with correct heads.
Labeled Accuracy (LA) is thepercentage of words with correct dependency labels.
La-beled Attachment Score (LAS) is the percentage of wordswith both correct heads and labels.aExp-1: Without morph featuresbExp-2: With morph features predicted by SMAcExp-3: With gold morph features (as annotated in HTB)sition and pronoun categories is quite less and hencehave not been included in the table.Hindi derivational morph analyzer (Kanuparthiet al 2012) and the morph analyzer developed byPunjab University (Goyal and Lehal, 2008) do notadd much to PBA accuracy since they are devel-oped with PBA as the base.
Out of 334,287 wordsin HTB, the derivational morph analyzer identifiedonly 9,580 derivational variants.
For the remainingwords, it gives similar analysis as PBA.6.1 LemmaThe evaluation metric for lemma?s model is accu-racy, which is the percentage of predicted lemmas124that are correct.
The phrase based translation sys-tem used to predict lemmas achieved an accuracy of95.84% compared to O-PBA?s 86.69%.
For OOVwords, the PBA outputs the word itself as the lemmawhereas the translation-based lemma model is ro-bust enough to give the analysis.The translation-based lemma model and O-PBAreport accuracies of 89.51% and 82.48% respec-tively for OOV words of SMA.
In terms ofboth overall and OOV accuracies, translation-basedmodel outperforms PBA.
Though SMA performsbetter than Morfette in terms of overall accuracy, butfor OOV accuracy Morfette narrowly outperformsSMA.The postposition accuracy is significantly worsethan the overall accuracy.
This is because the con-fusion is high among postpositions in HTB.
For ex-ample, out of 14,818 occurrences of ke, it takes thelemma kA in 7,763 instances and ke in 7,022 cases.This could be the result of an inconsistency in the an-notation process of HTB.
The accuracies for verbsare low (when compared to Nouns, Adjectives) aswell mainly because verbs in Hindi take more inflec-tions than the rest.
The accuracy for verbs is evenlower for OOV words (69.23% in Table 12).6.2 Gender, Number, Person and CaseThe accuracies of gender, number, person and casehover around 95% but the combined (G+N+P) accu-racy drops to 91.11%.
This figure is important if onewants to enforce agreement in parsing.The OOV accuracy for person is close to overallaccuracy as most of the OOV words belong to the3rd person category.
It is not the same case for gen-der and number.
Gender particularly suffers a sig-nificant drop of 14% for OOV words confirming thetheory that gender prediction is a difficult problemwithout knowing the semantics of the word.The number and person accuracies for verbs areconsistently low for OOV words as well as for seenwords.
This could be because SMA doesn?t handlelong distance agreement during GNP prediction.Until now, we reported accuracies for OOV wordsof SMA.
Table 11 lists accuracies for OOV wordsof the PBA (i.e.
words which are not analyzed bythe PBA) in the test section of HTB.
SMA clearlyoutperforms baseline system and also performs bet-ter than F-PBA and O-PBA as they do not give anyAnalysis Accuracy OOV AccuracyGender 95.74 80.08Number 95.29 89.71Person 96.12 94.06Case 95.16 88.32G+N+P 90.92 74.14G+N+P+C 87.72 68.47Table 10: Joint Model for Gender, Number, Person, Caseanalyses.In a nutshell, we have evaluated SMA for OOVwords of the PBA as well as for OOV words ofSMA.
In both the cases, SMA performed better thanother systems.
We shall evaluate SMA in a chal-lenging scenario wherein training data consists ofthe words from the HTB which are analyzed by thePBA and test data consists of the remaining unana-lyzed words by the PBA.
Thereby, the entire test datacontains only out of vocabulary instances for bothSMA and PBA.
Table 14 presents the results of thisnew evaluation.
The results are almost similar withthat of OOV results shown in Table 8 except for Per-son.
The reason behind that could be, in the trainingdata there are only 0.1% instances of 3h class but intest data their presence is quite significant (approx-imately 10%).
The training instances for 3h classwere not sufficient for the model to learn and hencevery few of these instances were identified correctly.This explains the drop in Person accuracy for thisexperiment scenario.It may be noted that, we have used gold POS tagsfor all our experiments related to GNP and case pre-diction.
There are numerous efforts on building POStaggers for Hindi.
The ILMT pos tagger9 is 96.5%accurate on the test data of the HTB.
Table 15 re-ports the accuracies of gender, number, person andcase using the automatic POS tags predicted by theILMT tagger.
The results are similar to that of theexperiments conducted with gold POS tags.Malladi and Mannem (2013) have build separatemodels for gender, number, person and case.
Table10 reports the results of Joint Model for these morphattributes.
In terms of accuracy, Joint Model is asefficient as individual models.9http://ilmt.iiit.ac.in/125Analysis Baseline SMALemma 65.40 95.96Gender 57.09 95.93Number 76.79 95.17Person 65.76 96.42Case 46.39 95.17Table 11: Accuracy for OOV words of PBAAnalysis Noun Verb AdjectiveLemma 92.18 69.23 88.35Gender 80.49 86.15 92.23Number 92.35 76.92 87.38Person 96.64 75.38 100.00Case 88.81 98.46 70.87Table 12: OOV accuracies for words (by POS tags)6.3 TAM and VibhaktiThe proposed heuristics for Vibhakti and TAM pre-diction gave accuracy of 97.04% on test data set ofHTB.
On the entire HTB data, SMA achieved accu-racy of 98.88%.
O-PBA gave accuracy of 59.65%for TAM and Vibhakti prediction on test part ofHTB.
The reason behind low performance of O-PBA is that it identifies the TAM and vibhakti val-ues for each word separately and doesn?t considerthe neighbouring words in the sentence.7 Effect on ParsingThe effect of morphological features on parsing iswell documented (Ambati et al 2010a).
Previousworks used gold morphological analysis to provetheir point.
In this work, we also evaluated the effectof automatic morph features (predicted by SMA)on dependency parsing.
MALT parser was trainedAnalysis N V PSP JJ PRPLemma 98.50 94.28 89.41 97.99 98.78Gender 93.30 95.34 98.93 98.42 94.24Number 96.26 89.67 96.45 96.26 88.98Person 98.58 85.28 99.45 99.57 90.94Case 94.67 98.95 93.26 83.76 95.90N:Noun, V:Verb, PSP:postposition, JJ:adjective, PRP:pronounTable 13: Overall accuracies for words (by POS tags)Analysis Baseline SMAGender 57.09 73.09Number 76.79 85.71Person 65.76 77.93Case 33.62 89.05Table 14: Evaluation of SMA in a challenging scenario: train-ing data consists only of words analyzed by PBA and test dataconsists of remaining unanalyzed words.Analysis Overall OOVGender 95.68 80.41Number 94.97 90.30Person 96.09 96.17Case 94.61 88.19Table 15: Accuracy of SMA with auto POS tagson gold-standard POS tagged HTB data with andwith out morph features.
Table 9 lists the evaluationscores for these settings.
While the unlabeled at-tachment score (UAS) does not show significant im-provement, the labeled attachment score (LAS) andlabel accuracy (LA) have increased significantly.Ambati et al(2010a) also reported similar resultswith gold-standard morph features.
Lemma, case,vibhakti and TAM features contribute to the increasein label accuracy because of the karaka labels inPaninian annotation scheme (Begum et al 2008).Table 9 also lists the performance of MALT parserwith gold morph features (as annotated in HTB).It may be noted that, predicted morph features hadsimilar effect on hindi dependency parsing as of goldfeatures which is desirable making SMA usable forreal scenario applications.8 Extending the work to Telugu and UrduWe shall look at how SMA performs in predicitingGNP and case for other morphologically rich Indianlanguages: Telugu and Urdu.
At this stage, we havenot done any language-dependent engineering effortLanguage #Sentences #WordsUrdu 5230 68588Telugu 1600 6321Table 16: Telugu and Urdu Treebank Statistics126AnalysisTelugu UrduOverall OOV Overall OOVGender 96.49 89.85 89.14 88.18Number 90.65 75.13 91.62 91.35Person 94.82 85.79 93.37 95.53Case 96.49 89.34 85.49 79.01Table 17: SMA for other Mor-FOW languages: Telugu andUrduin improving the results rather we want to see howwell the system works for other languages using theminimalistic feature set employed for Hindi mor-phological analysis.Telugu Treebank was released for ICON 2010Shared Task(Husain et al 2010) and a modified ver-sion of that data is used for our experiments.
UrduTreebank which is still under development at IIITHyderabad10 is used for experiments related to Urdumorph analysis.
Refer table 16 for treebank statis-tics.Table 17 shows the evaluation results for Teluguand Urdu.9 Conclusion and Future workIn conclusion, SMA is a robust state-of-the-art sta-tistical morphological analyzer which outperformsprevious analyzers for Hindi by a considerable mar-gin.
SMA achieved an accuracy of 63.06% forlemma, gender, number, person and case whereasPBA and Morfette are 34.89% and 51.52% accuraterespectively.
With the predicted morphological at-tributes by SMA, we achieve a labeled attachmentscore of 89.41 while without these morphological at-tributes the parsing accuracy drops to 87.75.The agreement phenomenon in Hindi provideschallenges in predicting gender, number and personof words in their sentential context.
These can bebetter predicted if dependency relations are given asinput.
However, the standard natural language anal-ysis pipeline forbids using parse information duringmorphological analysis.
This provides an oppor-tunity to explore joint modelling of morphologicalanalysis and syntactic parsing for Hindi.
We plan toexperiment this as part of our future work.Performance of Morfette is comparable to SMA10iiit.ac.inand for lemma prediction in the case of OOV words,Morfette outperforms SMA.
We plan to build a hy-brid system whose feature set includes features fromboth the systems.ReferencesBharat Ram Ambati, Samar Husain, Sambhav Jain,Dipti Misra Sharma, and Rajeev Sangal.
2010a.
Twomethods to incorporate local morphosyntactic featuresin hindi dependency parsing.
In Proceedings of theNAACL HLT 2010 First Workshop on Statistical Pars-ing of Morphologically-Rich Languages, pages 22?30.Association for Computational Linguistics.Bharat Ram Ambati, Samar Husain, Joakim Nivre, andRajeev Sangal.
2010b.
On the role of morphosyn-tactic features in hindi dependency parsing.
In Pro-ceedings of the NAACL HLT 2010 First Workshopon Statistical Parsing of Morphologically-Rich Lan-guages, pages 94?102.
Association for ComputationalLinguistics.Rafiya Begum, Samar Husain, Arun Dhwaj, Dipti MisraSharma, Lakshmi Bai, and Rajeev Sangal.
2008.
De-pendency annotation scheme for indian languages.
InProceedings of IJCNLP.Akshar Bharati, Vineet Chaitanya, Rajeev Sangal, andKV Ramakrishnamacharyulu.
1995.
Natural lan-guage processing: A Paninian perspective.
Prentice-Hall of India New Delhi.Akshar Bharati, Samar Husain, Meher Vijay, KalyanDeepak, Dipti Misra Sharma, and Rajeev Sangal.2009a.
Constraint based hybrid approach to parsingindian languages.
Proc of PACLIC 23.
Hong Kong.Akshara Bharati, Dipti Misra Sharma, Samar Husain,Lakshmi Bai, Rafiya Begam, and Rajeev Sangal.2009b.
Anncorra: Treebanks for indian languages,guidelines for annotating hindi treebank.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM:A library for support vector machines.
ACM Transac-tions on Intelligent Systems and Technology, 2:27:1?27:27.Grzegorz Chrupa?a, Georgiana Dinu, and Josef Van Gen-abith.
2008.
Learning morphology with morfette.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A li-brary for large linear classification.
Journal of Ma-chine Learning Research, 9:1871?1874.John Goldsmith.
2000.
Linguistica: An automatic mor-phological analyzer.
In Proceedings of 36th meetingof the Chicago Linguistic Society.Vishal Goyal and G. Singh Lehal.
2008.
Hindi morpho-logical analyzer and generator.
In Emerging Trends in127Engineering and Technology, 2008.
ICETET?08.
FirstInternational Conference on, pages 1156?1159.
IEEE.Samar Husain, Prashanth Mannem, Bharat Ram Ambati,and Phani Gadde.
2010.
The icon-2010 tools conteston indian language dependency parsing.
Proceedingsof ICON-2010 Tools Contest on Indian Language De-pendency Parsing, ICON, 10:1?8.Yamuna Kachru.
2006.
Hindi, volume 12.
John Ben-jamins Publishing Company.Nikhil Kanuparthi, Abhilash Inumella, and Dipti MisraSharma.
2012.
Hindi derivational morphological an-alyzer.
In Proceedings of the Twelfth Meeting of theSpecial Interest Group on Computational Morphologyand Phonology, pages 10?16.
Association for Compu-tational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, et al2007.
Moses: Open source toolkit for sta-tistical machine translation.
In Proceedings of the 45thAnnual Meeting of the ACL on Interactive Poster andDemonstration Sessions, pages 177?180.
Associationfor Computational Linguistics.Deepak Kumar Malladi and Prashanth Mannem.
2013.Statistical morphological analyzer for hindi.
In Pro-ceedings of 6th International Joint Conference on Nat-ural Language Processing.Mark Pedersen, Domenyk Eades, Samir K Amin, andLakshmi Prakash.
2004.
Relative clauses in hindiand arabic: A paninian dependency grammar analy-sis.
COLING 2004 Recent Advances in DependencyGrammar, pages 9?16.Dipti Misra Sharma, Prashanth Mannem, Joseph Van-Genabith, Sobha Lalitha Devi, Radhika Mamidi, andRanjani Parthasarathi, editors.
2012.
Proceedings ofthe Workshop on Machine Translation and Parsing inIndian Languages.
Mumbai, India, December.128
