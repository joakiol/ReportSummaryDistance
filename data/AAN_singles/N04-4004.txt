An Empirical Study onMultiple LVCSR Model Combination by Machine LearningTakehito Utsuro?
Yasuhiro Kodama?
Tomohiro Watanabe?
?Hiromitsu Nishizaki??
Seiichi Nakagawa??
?Graduate School of Informatics, Kyoto University, Kyoto, 606-8501, Japan?Sony Corporation ?
?Toyohashi University of Technology ?
?University of YamanashiAbstractThis paper proposes to apply machine learn-ing techniques to the task of combining out-puts of multiple LVCSR models.
The proposedtechnique has advantages over that by votingschemes such as ROVER, especially when themajority of participating models are not reli-able.
In this machine learning framework, asfeatures of machine learning, information suchas the model IDs which output the hypothe-sized word are useful for improving the wordrecognition rate.
Experimental results showthat the combination results achieve a relativeword error reduction of up to 39 % against thebest performing single model and that of up to23 % against ROVER.
We further empiricallyshow that it performs better when LVCSR mod-els to be combined are chosen so as to cover asmany correctly recognized words as possible,rather than choosing models in descending or-der of their word correct rates.1 IntroductionSince current speech recognizers?
outputs are far fromperfect and always include a certain amount of recogni-tion errors, it is quite desirable to have an estimate of con-fidence for each hypothesized word.
This is especiallytrue for many practical applications of speech recogni-tion systems such as automatic weighting of additional,non-speech knowledge sources, keyword based speechunderstanding, and recognition error rejection ?
confir-mation in spoken dialogue systems.
Most of previousworks on confidence measures (e.g., (Kemp and Schaaf,1997) ) are based on features available in a single LVCSRmodel.
However, it is well known that a voting schemesuch as ROVER (Recognizer output voting error reduc-tion) for combining multiple speech recognizers?
outputscan achieve word error reduction (Fiscus, 1997; Ever-mann and Woodland, 2000).
Considering the success ofa simple voting scheme such as ROVER, it also seemsquite possible to improve reliability of previously stud-ied features for confidence measures by simply exploit-ing more than one speech recognizers?
outputs.
From thisobservation, we experimentally evaluated the agreementamong the outputs of multiple Japanese LVCSR models,with respect to whether it is effective as an estimate ofconfidence for each hypothesized word.Our previous study reported that the agreement be-tween the outputs with two different acoustic models canachieve quite reliable confidence, and also showed thatthe proposed measure of confidence outperforms previ-ously studied features for confidence measures such asthe acoustic stability and the hypothesis density (Kempand Schaaf, 1997).
We also reported evaluation resultswith 26 distinct acoustic models and identified the fea-tures of acoustic models most effective in achieving highconfidence (Utsuro et al, 2002).
The most remarkableresults are as follows: for the newspaper sentence ut-terances, nearly 99% precision is achieved by decreas-ing 94% word correct rate of the best performing singlemodel by only 7%.
For the broadcast news speech, nearly95% precision is achieved by decreasing 72% word cor-rect rate of the best performing single model by only 8%.Based on those results of our previous studies, this pa-per proposes to apply machine learning techniques to thetask of combining outputs of multiple LVCSR models.As a machine learning technique, the Support Vector Ma-chine (SVM) (Vapnik, 1995) learning technique is em-ployed.
A Support Vector Machine is trained for choos-ing the most confident one among several hypothesizedwords, where, as features of SVM learning, informationsuch as the model IDs which output the hypothesizedword, its part-of-speech, and the number of syllables areuseful for improving the word recognition rate.Model combination by high performance machinelearning techniques such as SVM learning has advantagesover that by voting schemes such as ROVER and oth-ers (Fiscus, 1997; Evermann and Woodland, 2000), espe-cially when the majority of participating models are notreliable.
In the model combination techniques based onvoting schemes, outputs of multiple LVCSR models arecombined according to simple majority vote or weightedmajority vote based on confidence of each hypothesizedword such as its likelihood.
The results of model com-bination by those voting techniques can be harmed whenthe majority of participating models have quite low per-formance and output word recognition errors with highconfidence.
On the other hand, in the model combinationby high performance machine learning techniques suchas SVM learning, among those participating models, re-liable ones and unreliable ones are easily discriminatedthrough the training process of machine learning frame-work.
Furthermore, depending on the features of hypoth-esized words such as its part-of-speech and the numberof syllables, outputs of multiple models are combined inan optimal fashion so as to minimize word recognitionerrors in the combination results.Experimental results show that model combination bySVM achieves the followings: i.e., for the newspaper sen-tence utterances, a relative word error reduction of 39 %against the best performing single model and that of 23% against ROVER; for the broadcast news speech, a rel-ative word error reduction of 13 % against the best per-forming single model and that of 8 % against ROVER.We further empirically show that it performs better whenLVCSR models to be combined are chosen so as to coveras many correctly recognized words as possible, ratherthan choosing models in descending order of their wordcorrect rates1.2 Specification of Japanese LVCSRSystems2.1 DecodersAs decoders of Japanese LVCSR systems, we use the onenamed Julius, which is provided by IPA Japanese dicta-tion free software project (Kawahara and others, 1998),as well as the one named SPOJUS (Kai et al, 1998),which has been developed in Nakagawa lab., ToyohashiUniv.
of Tech., Japan.
Both decoders are composed oftwo decoding passes, where the first pass uses the wordbigram, and the second pass uses the word trigram.2.2 Acoustic ModelsThe acoustic models of Japanese LVCSR systems arebased on Gaussian mixture HMM.
We evaluate phoneme-based HMMs as well as syllable-based HMMs.2.2.1 Acoustic Models with the Decoder JULIUSAs the acoustic models used with the decoder Julius,we evaluate phoneme-based HMMs as well as syllable-based HMMs.
The following four types of HMMs areevaluated: i) triphone model, ii) phonetic tied mixture1Compared with our previous report (Utsuro et al, 2003),the major achievement of the paper is this empirical result.Utsuro et al (2003) examined the correlation between eachword?s confidence and the word?s features, and then introducedthe framework of combining outputs of multiple LVCSR mod-els by SVM learning.
(PTM) triphone model, iii) monophone model, and iv)syllable model.
Every HMM phoneme model is gender-dependent (male).
For each of the four models above,we evaluate both HMMs with and without the short pausestate, which amount to 8 acoustic models in total.2.2.2 Acoustic Models with the Decoder SPOJUSThe acoustic models used with the decoder SPOJUS arebased on syllable HMMs, which have been developedin Nakagawa laboratory, Toyohashi University of Tech-nology, Japan (Nakagawa and Yamamoto, 1996).
Theacoustic models are gender-dependent (male) syllableunit HMMs.
Among various combinations of features ofacoustic models2, we carefully choose 9 acoustic modelsso that they include the best performing ones as well asa sufficient number of minimal pairs which have differ-ence in only one feature.
Then, for each of the 9 models,we evaluate both HMMs with and without the short pausestates, which amount to 18 acoustic models in total.2.3 Language ModelsAs the language models, the following two types of wordbigram / trigram language models for 20k vocabularysize are evaluated: 1) the one trained using 45 monthsMainichi newspaper articles, 2) the one trained using 5years Japanese NHK (Japan Broadcasting Corporation)broadcast news scripts (about 120,000 sentences).2.4 Evaluation Data SetsThe evaluation data sets consist of newspaper sentenceutterances, which are relatively easier for speech recog-nizers, and rather harder broadcast news speech: 1) 100newspaper sentence utterances from 10 male speakersconsisting of 1,565 words, selected by IPA Japanese dic-tation free software project (Kawahara and others, 1998)from the JNAS (Japanese Newspaper Article Sentences)speech data (Itou and others, 1998), 2) 175 JapaneseNHK broadcast news (June 1st, 1996) speech sentencesconsisting of 6,813 words, uttered by 14 male speakers(six announcers and eight reporters).2.5 Word Recognition RatesWord correct and accuracy rates of the individual LVCSRmodels for the above two evaluation data sets are mea-sured, where for the recognition of the newspaper sen-tence utterances, the language model used is the onetrained using newspaper articles, and for the recognitionof the broadcast news speech, the language model usedis the one trained using broadcast news scripts.
Wordrecognition rates for the above two evaluation data setsare summarized as below:2Sampling frequencies, frame shift lengths, feature param-eters, covariance matrices, and self loop transition / durationcontrol.
(a) Newspaper Sentence(b) Broadcast NewsFigure 1: Comparison among Combination by SVM /(Weighted) Majority Votes / Individual Modelsnewspaper sentence utterancesdecoder word correct (%) word accuracy (%)Julius 93.0(max) to 72.7(min) 90.4(max) to 69.4(min)SPOJUS 90.2(max) to 78.1(min) 85.3(max) to 51.0(min)broadcast news speechdecoder word correct (%) word accuracy (%)Julius 71.7(max) to 49.0(min) 68.8(max) to 39.7(min)SPOJUS 70.7(max) to 55.4(min) 62.8(max) to 36.2(min)3 Combining Outputs of Multiple LVCSRModels by SVMThis section describes the results of applying SVM learn-ing technique to the task of combining outputs of multipleLVCSR models considering the confidence of each word.We divide each of the data sets described in Section 2.4into two halves3, where one half is used for training andthe other half for testing.
A Support Vector Machineis trained for choosing the most confident one amongseveral hypothesized words from the outputs of the 26LVCSR models4.
As features of the SVM learning, weuse the model IDs which output the word, the part-of-speech of the word, and the number of syllables 5.
As3It is guaranteed that the two halves do not share speakers.4We used SVM light (http://svmlight.joachims.org/) as a tool for SVM learning.
We compared linear andquadratic kernels and the linear kernel performs better.5Contribution of the parts-of-speech and the numbers of syl-lables was slight.
We also evaluated the effect of acoustic and(a) Newspaper Sentence(b) Broadcast NewsFigure 2: Comparing Methods for Combining Outputs ofn (3 ?
n ?
26) Modelsclasses of the SVM learning, we use whether each hy-pothesized word is correct or incorrect.
Since SupportVector Machines are binary classifiers, we regard the dis-tance from the separating hyperplane to each hypothe-sized word as the word?s confidence.
The outputs of the26 LVCSR models are aligned by Dynamic Time Warp-ing, and the most confident one among those competinghypothesized words is chosen as the result of model com-bination.
We also require the confidence of hypothesizedwords to be higher than a certain threshold, and choosethe ones with the confidence above this threshold as theresult of model combination.The results of the performance evaluation against thetest data are shown in Figure 1.
All the results in Fig-ure 1 are the best performing ones among those for com-bining outputs of n (3 ?
n ?
26) models.
The resultsof model combination by SVM are indicated as ?SVM?.As a baseline performance, that of the best performingsingle model with respect to word correct rate (?Individ-ual Model with Max Cor?)
is shown.
(Note that theirword recognition rates are those for the half of the wholedata set, and thus different from those in Section 2.5.
)For both speech data, model combination by SVM sig-language scores of each hypothesized word as features of SVM,where their contribution to improving the overall performancewas very little.
(a) Newspaper Sentence(b) Broadcast NewsFigure 3: Comparison between Maximizing Recall ofUnion / Descending Order of Word Correct Ratesnificantly outperforms the best performing single model.In terms of word accuracy rate, relative word error re-duction are 39 % for the newspaper sentence utterancesand 13 % for the broadcast news speech.
Figure 1 alsoshows the performance of ROVER (Fiscus, 1997) as an-other baseline, where ?Majority Vote?
shows the perfor-mance of the strategy of outputting no word at a tie, while?Weighted Majority Vote?
shows the performance when,for each individual model, word correct rate for each sen-tence is estimated and used as the weight of hypothesizedwords.
Model combination by SVM mostly outperformsROVER for both speech data.
In terms of word accuracyrate, relative word error rate reduction are 23 % for thenewspaper sentence utterances and 8 % for the broadcastnews speech6.Figure 2 plots the changes of word accuracy ratesagainst the increasing number of models which partici-pate in LVCSR model combination.
Here, LVCSR mod-els to be combined are chosen so as to cover as many cor-rectly recognized words as possible, rather than choosingmodels in descending order of their word correct rates.
(As we show later, the former outperforms the latter.)
It6Remarkable improvements are achieved especially in wordaccuracy rates.
This is due to the strategy of requiring the confi-dence of hypothesized words to be higher than a certain thresh-old, where insertion error words tend to be discarded.is quite clear from this result that the difference of modelcombination by SVM and (weighted) majority votes be-comes much larger as more and more models participatein model combination.
This is because the majority ofparticipating models become unreliable in the second halfof the curves in Figure 2.Figure 3 compares the model selection procedures, i.e.,choosing models so as to cover as many correctly recog-nized words as possible (indicated as ?Maximizing Recallof Union?
), and choosing models in descending order oftheir word correct rates (indicated as ?Descending Orderof Word Correct Rates?).
The former performs better inthe first half of the curves.
This result indicates that, evenif recognition error words increase in the outputs of mod-els participating in LVCSR model combination, it is bet-ter to cover as many correctly recognized words as pos-sible.
This is because, in the model combination by highperformance machine learning techniques such as SVMlearning, reliable and unreliable hypothesized words areeasily discriminated through the training process.4 Concluding RemarksThis paper proposed to apply the SVM learning techniqueto the task of combining outputs of multiple LVCSRmodels.
The proposed technique has advantages over thatby voting schemes such as ROVER, especially when themajority of participating models are not reliable.ReferencesG.
Evermann and P. Woodland.
2000.
Posterior probabilitydecoding, confidence estimation and system combination.
InProc.
NIST Speech Transcription Workshop.J.
G. Fiscus.
1997.
A post-processing system to yield reducedword error rates: Recognizer output voting error reduction(ROVER).
In Proc.
ASRU, pages 347?354.K.
Itou et al 1998.
The design of the newspaper-basedJapanese large vocabulary continuous speech recognitioncorpus.
In Proc.
5th ICSLP, pages 3261?3264.A.
Kai, Y. Hirose, and S. Nakagawa.
1998.
Dealing with out-of-vocabulary words and speech disfluencies in an n-grambased speech understanding system.
In Proc.
5th ICSLP,pages 2427?2430.T.
Kawahara et al 1998.
Sharable software repository forJapanese large vocabulary continuous speech recognition.
InProc.
5th ICSLP, pages 3257?3260.T.
Kemp and T. Schaaf.
1997.
Estimating confidence usingword lattices.
In Proc.
5th Eurospeech, pages 827?830.S.
Nakagawa and K. Yamamoto.
1996.
Evaluation of segmen-tal unit input HMM.
In Proc.
21st ICASSP, pages 439?442.T.
Utsuro, T. Harada, H. Nishizaki, and S. Nakagawa.
2002.A confidence measure based on agreement among multipleLVCSR models ?
correlation between pair of acoustic mod-els and confidence ?.
In Proc.
7th ICSLP, pages 701?704.T.
Utsuro, Y. Kodama, T. Watanabe, H. Nishizaki, and S. Nak-agawa.
2003.
Confidence of agreement among multipleLVCSR models and model combination by SVM.
In Proc.28th ICASSP, volume I, pages 16?19.V.
N. Vapnik.
1995.
The Nature of Statistical Learning Theory.Springer-Verlag.
