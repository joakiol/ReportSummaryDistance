A Stacked, Voted, Stacked Model for Named Entity RecognitionDekai Wu??
and Grace Ngai?
and Marine Carpuat??
Human Language Technology CenterHKUSTDepartment of Computer ScienceUniversity of Science and TechnologyClear Water Bay, Hong Kong{dekai,marine}@cs.ust.hk?
Hong Kong Polytechnic UniversityDepartment of ComputingKowloonHong Kongcsgngai@polyu.edu.hkAbstractThis paper investigates stacking and votingmethods for combining strong classifiers likeboosting, SVM, and TBL, on the named-entityrecognition task.
We demonstrate several ef-fective approaches, culminating in a model thatachieves error rate reductions on the develop-ment and test sets of 63.6% and 55.0% (En-glish) and 47.0% and 51.7% (German) over theCoNLL-2003 standard baseline respectively,and 19.7% over a strong AdaBoost baselinemodel from CoNLL-2002.1 IntroductionWe describe multiple stacking and voting methods thateffectively combine strong classifiers such as boosting,SVM, and TBL, for the named-entity recognition (NER)task.
NER has emerged as an important step for manynatural language applications, including machine trans-lation, information retrieval and information extraction.Much of the research in this field was pioneered inthe Message Understanding Conference (MUC) (Sund-heim, 1995), which performed detailed entity extractionand identification on English documents.
As a result,most current NER systems which have impressive per-formances have been specially constructed and tuned forEnglish MUC-style documents.
It is unclear how wellthey would perform when applied to another language.Our system was designed for the CoNLL-2003 sharedtask, the goal of which is to identify and classify fourtypes of named entities: PERSON, LOCATION, ORGA-NIZATION and MISCELLANEOUS.
The task specifi-cations were that two languages would be involved.
We*The author would like to thank the Hong Kong Re-search Grants Council (RGC) for supporting this research inpart through two research grants (RGC 6083/99E and RGC6256/00E).were given about a month to develop our system on thefirst language, which was English, but only two weeks toadapt it to the surprise language, which was German.Given the goal of the shared task, we designed oursystem to achieve a high performance without relyingtoo heavily on knowledge that is very specific for a par-ticular language or domain.
In the spirit of language-independence, we avoided using features and informationwhich would not be easily obtainable for almost any ma-jor language.2 Classification MethodsTo carry out the stacking and voting experiments, we con-structed a number of relatively strong individual compo-nent models of the following kinds.2.1 BoostingThe main idea behind boosting algorithms is that a setof many weak classifiers can be effectively combined toyield a single strong classifier.
Each weak classifier istrained sequentially, increasingly focusing more heavilyon the instances that the previous classifiers found diffi-cult to classify.For the boosting framework, our system uses Ada-Boost.MH (Freund and Schapire, 1997), an n-ary classifi-cation variant of the original binary AdaBoost algorithm.It performs well on a number of natural language process-ing problems, including text categorization (Schapire andSinger, 2000) and word sense disambiguation (Escuderoet al, 2000).
In particular, it has also been demonstratedthat boosting can be used to build language-independentNER models that perform exceptionally well (Wu et al,2002; Carreras et al, 2002).2.2 Support Vector MachinesSupport Vector Machines (SVMs) have gained a con-siderable following in recent years (Boser et al, 1992),particularly in dealing with high-dimensional spacessuch as commonly found in natural language prob-lems like text categorization (Joachims, 1998).
SVMshave shown promise when applied to chunking (Kudoand Matsumoto, 2001) and named entity recognition(Sassano and Utsuro, 2000; McNamee and Mayfield,2002), though performance is quite sensitive to param-eter choices.2.3 Transformation-based LearningTransformation-based learning (Brill, 1995) (TBL) is arule-based machine learning algorithm that was first in-troduced by Brill and used for part-of-speech tagging.The central idea of transformation-based learning is tolearn an ordered list of rules which progressively improveupon the current state of the training set.
An initial as-signment is made based on simple statistics, and thenrules are greedily learned to correct the mistakes, untilno net improvement can be made.The experiments presented in this paper were per-formed using the fnTBL toolkit (Ngai and Florian, 2001),which implements several optimizations in rule learningto drastically speed up the time needed for training.3 Data Resources3.1 Preprocessing the DataThe data that was provided by the CoNLL organizers wassentence-delimited and tokenized, and hand-annotatedwith named entity chunks.
The English data was au-tomatically labeled with part-of-speech and chunk tagsfrom the memory-based tagger and chunker (Daelemanset al, 1996), and the German data was labelled with thedecision-tree-based TreeTagger (Schmidt, 1994).
We re-placed the English part-of-speech tags with those gener-ated by a transformation-based learner (Ngai and Florian,2001).
The chunk tags did not appear to help in eithercase and were discarded.As we did not want to overly rely on characteristicswhich were specific to the Indo-European language fam-ily, we did not perform detailed morphological analysis;but instead, an approximation was made by simply ex-tracting the prefixes and suffixes of up to 4 charactersfrom all the words.In order to let the system generalize over word types,we normalized the case information of all the words inthe corpus by converting them to uniform lower case.
Torecapture the lost information, each word was annotatedwith a tag that specified if it was in all lower case, allupper case, or was of mixed case.3.2 GazetteersApart from the training and test data, the CoNLL orga-nizers also provided two lists of named entities, one inEnglish and one in Dutch.
Part of the challenge for thisyear?s shared task was to find ways of using this resourcein the system.To supplement the provided gazetteers, a large col-lection of names and words was downloaded from var-ious web sources.
This collection was used to compilea gazetteer of 120k uncategorized English proper namesand a lexicon of 500k common English words.
As therewere no supplied gazetteers for German, we also com-piled a gazetteer of 8000 German names, which weremostly personal first and last names and geographical lo-cations, and a lexicon of 32k common German words.Named entities in the corpus which appeared in thegazetteers were identified lexically or using a maximumforward match algorithm similar to that used in Chineseword segmentation.
Once named entities have been iden-tified in this preprocessing step, each word can then beannotated with an NE chunk tag corresponding to the out-put from the system.
The learner can view the NE chunktag as an additional feature.The variations in this approach come from resolvingconflicts between different possible type information forthe same NE.
The different ways that we dealt with theproblem were: (1) Rank all the NE types by frequency inthe training corpus.
In the case of a conflict, default tothe more common NE.
(2) Give all the possible NEs tothe boosting learner as a set of possible NE chunk tags.
(3) Discard the NE type information and annotate eachword with a tag indicating whether it is inside an NE.4 Classifier CombinationIt is a well-known fact that if several classifiers are avail-able, they can be combined in various ways to createa system that outperforms the best individual classifier.Since we had several classifiers available to us, it was rea-sonable to investigate combining them in different ways.4.1 StackingLike voting, stacking is a learning paradigm that con-structs a combined model from several classifiers.
Thebasic concept behind stacking is to train two or more clas-sifiers sequentially, with each successive classifier incor-porating the results of the previous ones in some fashion.4.1.1 Integration of External ResourcesAs mentioned above, at the most basic level, lexiconand gazetteer information was integrated into our classi-fiers by including them as additional features.
Howeverwe also experimented with several different ways of in-corporating this information via stacking?one possibleapproach was to view the gazetteers as a separate systemthat would produce an output and then implement stack-ing to combine their outputs.4.1.2 Division into SubtasksOne of the most straightforward approaches to stack-ing can be applied to tasks that are naturally divisible intohierarchically ordered subtasks.
An example approach,which was taken by several of the participating teams inthe CoNLL-2002 shared task, is to split the NER task intothe identification phase, where named entities are identi-fied in the text; and the classification phase, where theidentified named entities are categorized into the varioussubtypes.
Provided that the performance of the individ-ual classifier is fairly high (otherwise errors made in theearlier stages could propagate down the chain), this hasthe advantage of reducing the complexity of the task foreach individual classifier.To construct such a system, we trained a stacked Ada-Boost.MH classifier to perform NE reclassification onboundaries identified in the base model.
The output of theinitial models are postprocessed to remove all NE typeinformation and then passed to this stacked classifier.
AsTable 1 shows, stacking the boosting models yields a sig-nificant gain in performance.English devel.
Precision Recall F?=1(Boost) Base 88.64% 87.68% 88.16(Boost) Base + Stacked 89.26% 88.29% 88.77Table 1: Improving classification of NE types via stackedAdaBoost.MH.4.1.3 Error CorrectionAnother approach to stacking that we investigated inthis work involves a closer interaction between the mod-els.
The general overview of this approach is for a givenmodel to use the output of another trained model as itsinitial state, and to improve beyond it.
The idea is thatthe second model, with a different learning and represen-tation bias, will be able to move out of the local maximathat the previous model has settled into.To accomplish this we introduced Stacked TBL(STBL), a variant of TBL tuned for this purpose (Wu etal., 2003).
We found TBL to be an appropriate point ofdeparture since it starts from an initial state of classifi-cation and learns rules to iteratively correct the currentlabeling.
We aimed to use STBL to improve the basemodel from the preceding section.STBL proved quite effective; in fact it yielded the bestbase model performance among all our models.
Table 2shows the result of stacking STBL on the boosting basemodel.4.2 VotingThe simplest approach to combining classifiers is throughvoting, which examines the outputs of the various mod-English devel.
Precision Recall F?=1(Boost) Base 88.64% 87.68% 88.16(Boost + STBL) Base 87.83% 88.79% 88.31Table 2: Improving the above AdaBoost.MH base model,via Stacked TBL (STBL).els and selects the classifications which have a weightexceeding some threshold, where the weight is depen-dent upon the models that proposed this particular clas-sification.
The variations in this approach stem from themethod by which weights are attached to the models.
Itis possible to assign varying weights to the models, in ef-fect giving one model more ?say?
than the others.
In oursystem, however, we simply assigned each model equalweight, and selected classifications which were proposedby a majority of models.Voting was thus used to further improve the basemodel.
Four models chosen for heterogeneity partici-pated in the voting: two variants of the AdaBoost.MHmodel, the SVM model, and the Stacked TBL model.As before, the stacked AdaBoost.MH reclassifier wasapplied to the voted result, yielding a final stacked votedstacked model.This model gave the best overall results on the task asa whole.
Table 3 shows the results of our system.English devel.
Precision Recall F?=1Boost1 + Stacked 89.26% 88.29% 88.77Boost2 + Stacked 82.98% 85.62% 84.28SVM + Stacked 84.41% 85.71% 85.05Boost + STBL + Stacked 89.09% 88.07% 88.57Voted + Stacked 90.18% 88.86% 89.51Table 3: Improving classification of NE types, via stackedvoted stacked AdaBoost.MH, STBL, and SVM models.5 Overall ResultsComplete results on the development and test sets, forboth English and German, are shown in Table 4.6 ConclusionThis paper has presented an overview of our entry tothe CoNLL-2003 shared task.
As individual componentmodels, we constructed strong AdaBoost.MH models,SVM models, and Stacked TBL models, and providedthem with detailed features on the data.We then demonstrated several stacking and votingmodels that proved capable of improving performancefurther.
This was non-trivial since the individual compo-nent models were all quite strong to begin with.
Becauseof this the vast majority of classifier combination modelswe tested actually turned out to degrade performance, orshowed zero improvement.
The models presented hereworked well because they were each motivated by de-tailed analyses.We did investigate a number of ways in whichgazetteers could be incorporated.
The gazetteer suppliedfor the shared task was found not to improve perfor-mance significantly, because our models were already ad-equately powerful to correctly identify most of the namedentities supplied by the gazetteer.
However, minimal ef-fort to augment the gazetteers did result in a performanceboost.
Moreover, performance was further improved bythe inclusion of a common word lexicon not containingany named entities.Inspection revealed that some errors found in theoutput of the system stemmed from either erroneoussentence boundaries in the test data, or difficult-to-avoidinconsistencies in the the gold standard annotations.
Forexample, in the following:1. .
.
.
[ Panamanian ]MISC boxing legend .
.
.2. .
.
.
[ U.S. ]LOC collegiate national champion .
.
.both ?Panamanian?
and ?U.S.?
are used as modifiers, butone is annotated as a MISC-type NE while the other isconsidered a LOC-type.The stacked voted stacked model obtained an improve-ment of 4.83 F-Measure points on the English devel-opment set over our best model from the CoNLL-2002shared task which we took as our baseline, resulting ina substantial 19.7% error rate reduction.
The systemachieves this respectable performance using very littlein the way of outside resources?only a part-of-speechtagger and some common wordlists?which can be ob-tained easily for almost any major language.
Most fea-tures we used can also be used for uninflected and non-Indo-European languages such as Chinese, where the pre-fixes and suffixes can be replaced by decomposing thewords at the character level.
This is in keeping with thethe language-independent spirit of the shared task.ReferencesBernhard E. Boser, Isabelle Guyon, and Vladimir Vapnik.
1992.
A training al-gorithm for optimal margin classifiers.
In David Haussler, editor, Proceedingsof the 4th Workshop on Computational Learning Theory, pages 144?152, SanMateo, CA.
ACM Press.Eric Brill.
1995.
Transformation-based error-driven learning and natural lan-guage processing: A case study in part of speech tagging.
ComputationalLinguistics, 21(4):543?565.Xavier Carreras, Llu?is Ma`rquez, and Llu?is Padro?.
2002.
Named entity extrac-tion using adaboost.
In Proceedings of CoNLL-2002, pages 167?170.
Taipei,Taiwan.Walter Daelemans, Jakub Zavrel, and Peter Berck.
1996.
MBT: A memory-basedpart of speech tagger-generator.Gerard Escudero, Llu?is Ma`rquez, and German Rigau.
2000.
Boosting applied toword sense disambiguation.
In European Conference on Machine Learning,pages 129?141.English devel.
Precision Recall F?=1LOC 91.88% 92.98% 92.42MISC 91.53% 83.19% 87.16ORG 86.43% 80.76% 83.50PER 90.39% 93.49% 91.91Overall 90.18% 88.86% 89.51English test Precision Recall F?=1LOC 86.27% 85.91% 86.09MISC 75.88% 77.07% 76.47ORG 78.19% 72.97% 75.49PER 83.94% 87.26% 85.57Overall 82.02% 81.39% 81.70German devel.
Precision Recall F?=1LOC 75.13% 61.39% 67.57MISC 75.46% 45.05% 56.42ORG 80.05% 47.86% 59.91PER 74.19% 61.96% 67.52Overall 75.92% 54.67% 63.56German test Precision Recall F?=1LOC 74.94% 60.97% 67.23MISC 72.77% 51.04% 60.00ORG 61.22% 42.69% 50.30PER 83.68% 73.39% 78.20Overall 75.20% 59.35% 66.34Table 4: Overall results of stacked voted stacked modelon development and test sets.Yoav Freund and Rob E. Schapire.
1997.
A decision-theoretic generalization ofon-line learning and an application to boosting.
In Journal of Computer andSystem Sciences, 55(1), pages 119?139.Thorsten Joachims.
1998.
Text categorization with support vector machines:learning with many relevant features.
In Claire Ne?dellec and Ce?line Rou-veirol, editors, Proceedings of ECML-98, 10th European Conference on Ma-chine Learning, number 1398, pages 137?142, Chemnitz, DE.
Springer Ver-lag, Heidelberg, DE.Taku Kudo and Yuji Matsumoto.
2001.
Chunking with support vector machines.In Proceedings of NAACL-2001.Paul McNamee and James Mayfield.
2002.
Entity extraction without language-specific resources.
In Proceedings of CoNLL-2002, pages 183?186.
Taipei,Taiwan.Grace Ngai and Radu Florian.
2001.
Transformation-based learning in the fastlane.
In Proceedings of NAACL?01, pages 40?47, Pittsburgh, PA. ACL.Manabu Sassano and Takehito Utsuro.
2000.
Named entity chunking techniquesin supervised learning for Japanese named entity recognition.
In Proceedingsof COLING-2000, pages 705?711.Rob E. Schapire and Yoram Singer.
2000.
BoosTexter: A boosting-based systemfor text categorization.
In Machine Learning, 39(2/3, pages 135?168.Helmut Schmidt.
1994.
Probabilistic part-of-speech tagging using decision trees.In International Conference on New Methods in Natural Language Process-ing, pages 44?49, Manchester, U.K.Beth Sundheim.
1995.
MUC6 named entity task defnition, version 2.1.
In Pro-ceedings of the Sixth Message Understanding Conference (MUC6).Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen, and Yongsheng Yang.2002.
Boosting for named entity recognition.
In Proceedings of CoNLL-2002,pages 195?198.
Taipei, Taiwan.Dekai Wu, Grace Ngai, and Marine Carpuat.
2003.
Forthcoming.
