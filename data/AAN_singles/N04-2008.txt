Greek Word Segmentation Using Minimal InformationC.
Anton RyttingDepartment of LinguisticsThe Ohio State UniversityColumbus, Ohio 43210rytting@ling.ohio-state.eduAbstractSeveral computational simulations have beenproposed for how children solve the wordsegmentation problem, but most have beentested only on a limited number of languages,often only English.
In order to extend thecross-linguistic dimension of word segmenta-tion research, a finite-state framework for test-ing various models of word segmentation issketched, and a very simple cue is tested inthis framework.
Data is taken from ModernGreek, a language with phonological patternsdistinct from English.
A small-scale simula-tion shows using this cue performs signifi-cantly better than chance.
The utility andflexibility of the finite-state approach is con-firmed; suggestions for improvement arenoted and directions for future work outlined.1 IntroductionA substantial portion of research in first-language ac-quisition focuses on the ?word segmentation prob-lem?
?how children learn to extract words (or wordcandidates) from a continuous speech signal prior tohaving acquired a substantial vocabulary.
Note that thehardware and software constraints on the human learnerare very different from those faced by a speech recogni-tion system, and hence strategies appropriate for onemay be irrelevant or disastrously inappropriate for theother.While a number of robust strategies have been pro-posed and tested for English and a few other languages(discussed below), it is not clear whether or how theseapply to other languages.
For example, the MetricalSegmentation Strategy (e.g., Cutler & Norris 1988)turns out to be very robust for English, but is not neces-sarily applicable to other languages, simply because notall languages share English?s predilection for strongword-initial syllables (though language-appropriatevariants of the strategy (stress-based for English) havebeen proposed, e.g., using the syllable in French (Cutler& Mehler, 1993) and the mora in Japanese (Otake,Hatano, Cutler, & Mehler, 1993)).Some more generic strategies (e.g., the PossibleWord Constraint: see e.g., Norris et al 1997, 2001) havebeen proposed and tested, primarily on English, but alsoon typologically distinct languages such as Sesotho(Cutler, Demuth, & McQueen, 2002).
Nevertheless,rigorous testing in a larger sample of languages seemsadvisable before making strong claims of universal ap-plicability.
One interesting strategy explored in e.g.,(Aslin et al, 1996) is the use of context around (andparticularly before) utterance boundaries to predict wordboundaries.
The applicability of this cue is discussedfor both English and Turkish; a simulation on Englishdata is reported.
One goal of the research presentedhere is to further explore that strategy on a different dataset, taken from a language with phonological patternsquite different from English or Turkish.The work presented here is intended as a small partof a more general line of research, whose purpose istwofold: on the one hand I wish to understand the natureof the cues present in Modern Greek, on the other I wishto establish a framework for orderly comparison ofword segmentation algorithms across the desired broadrange of languages.1.1 Infant StudiesAt least four types of information in the speech signalhave been identified as likely cues for infants: (1) super-segmental cues (e.g., stress) which begins to play a rolein (English-learning) 7.5 month-olds (Jusczyk, Houston,et al, 1999); (2) sub-segmental cues such as co-articulation and allophonic alternations, which infantsbegin using between 7.5 and 10.5 months of age (Jusc-zyk, Hohne, et al, 1999); (3) segmental cues, such aswordlikeness and phonotactic constraints, which seemto be available by 9 months of age (e.g., Jusczyk, Luce,et al, 1994; Mattys and Jusczyk, 2001), and (4) statisti-cal cues from recurrent patterns e.g., of syllables, evi-dent in English-learning 8-month-olds on an artificialmicro-language of 4 words (Saffran et al 1996).11.2 Computational ModelsWhile the infant studies discussed above focus primarilyon the properties of particular cues, computational stud-ies of word-segmentation must also choose betweenvarious implementations, which further complicatescomparisons.
In addition, several models (e.g.,Batchelder, 2002; Brent?s MLDP-1, 1999a; Davis,2000; de Marcken, 1996; Olivier, 1968) simultaneouslyaddress the question of vocabulary acquisition, usingpreviously learned word-candidates to bootstrap latersegmentations.
While these models are highly interest-ing both from their view of the long-term process oflanguage acquisition and their high success rate, theyare hard to relate to the infant studies discussed above.Hence, it is beyond the scope of this paper to discussthem at length.2Rather, this paper focuses on models that do not ac-cumulate a stored vocabulary, but rely on either on sta-tistics derived from utterance boundaries (typicallygeneralized over feature matrices, as in (Aslin et al,1996; Christiansen et al, 1998)) or from the degree ofpredictability of the next syllable (e.g., Saffran et al,1996) or segment (Christiansen et al, 1998).
The intui-tion here, first articulated by Harris (1954) is that wordboundaries will be marked by a spike in unpredictabilityof the following phoneme.
Christiansen et al (1998)also test the contribution of stress and phonemic infor-mation in addition to that of utterance boundaries, andshow that while stress contributes in certain circum-stances, it is not as crucial as featural information nearutterance boundaries.The general line of research herein proposed focuseson the same cues as (Christiansen et al, 1998) begin-ning (in the work reported here) with segmental prob-ability distributions at utterance boundaries.
This firststep corresponds most closely with (Aslin et al, 1996),where utterance boundaries were treated as a cue ontheir own.
Aslin and his colleagues propose that ?eventhe most minimal assumption about what an infant canrecognize as a word boundary--namely, the pause afteran utterance--is sufficient, in principle, for the learningthe word boundaries within an utterance?
(p. 133).
In1 Full mention of all the studies done is not possiblehere; for a fuller review see e.g., (Johnson & Jusczyk, 2001).2 For useful reviews of various computational models,see (Brent, 1999a,b).that study, however, a considerable amount of contextbefore such an utterance was given, namely 18-bit fea-ture vectors of one, two, or three phonemes immediatelypreceding the final utterance boundary.
For a modelwith 30 hidden units, the following results for boundarydetection are reported (as estimated from their bargraph, fig.8.8, p. 132), accompanied by the claim thatonly with two- and three-phoneme sequences is theirsystem capable of learning boundary locations:Hits  FalseAlarmsPrecision(H/(H+FA))3 phones 62% 22% 74%2 phones 53% 23% 70%1 phone 45% 44% 51%Random  5% 15% 25%Table 1.
Results reported in Aslin et al (1996,Fig.
8.8, p. 132).They further claim that feature vectors are necessary forlearning: a string of three phonemes (where each pho-neme is represented as an atomistic unit) is not suffi-cient information, although no comparative figures arelisted for this condition.This study may be seen as a replication of (Aslin etal., 1996); however, it differs in several crucial re-spects?not with an eye toward improving upon theirresults, but rather on examining further their definitionof ?minimal necessary cues.?
First, instead of trainingthe transitional probabilities indirectly with connection-ist networks, the probabilities are encoded directlywithin a finite-state framework.
Secondly, actual phoneidentities (rather than feature bundles) are used as sym-bols.
Finally, information about a single segment isused.
While this very austere use of minimal informa-tion is surely inadequate to the full task of segmentation,it nevertheless serves to demonstrate the gains even avery small amount of information can give.
Any evi-dence of better-than-chance results would suggest that,for Modern Greek at least, even more minimal cues arepossible than those Aslin et al (1996) propose.The results of this study may be taken as a roughapproximation of how predictable word boundaries arefrom (unigram) segmental information alone in the sub-set of Modern Greek experienced by young children.These findings may provide an additional baseline formeasuring and comparing the relative contributions ofother cues such as stress as a word segmentation cue.2 Constructing a Finite-State Model2.1 DataThe Greek CHILDES corpus (Stephany, 1995) is a da-tabase of conversations between children and caretak-ers, broadly transcribed, currently with no notations forlexical stress.
Audio tapes exist, but are currently un-available for general use (Stephany, p.c.).
However, thetranscriptions themselves give an indication at the pho-nemic level of the sort of input Greek children are likelyto have in learning their language.
In order to preserveadequate unseen data for future simulations and experi-ments, only a small subset of the total Greek CHILDEScorpus was used.As in other studies, only adult input was used fortraining and testing.
In addition, non-segmental infor-mation such as punctuation, dysfluencies, parentheticalreferences to real-world objects, etc.
were removed.Word boundaries are represented by the symbol #, ut-terance boundaries by $, following Brent (1999a).
Eachline of the file was assumed to be an independent utter-ance.
Spaces were assumed to represent word bounda-ries without comment or correction; however, it is worthnoting that the transcribers sometimes departed fromstandard orthographic practice with respect to certaintypes of word-clitic combinations.
The text also con-tains a significant number of unrealized final vowels(apocopy), such as [in] for /ine/ 'is'.
Such variation wasnot regularized, but treated as part of the learning task.The training corpus contains 367 utterance tokenswith a total of 1066 word tokens (319 types).
Whereasthe average number of words per utterance (2.9) is com-parable to the Korman (1984) corpus used byChristiansen et al (3.0), utterances and words wereslightly longer in terms of phonemes (12.8 and 4.4 pho-nemes respectively, compared to 9.0 and 3.0).
(Statis-tics on the corpus used in (Aslin et al, 1996) were notprovided.
)The test corpus consists of utterances by adults tothe same child as in the training corpus.
Utteranceswith dysfluencies, missing words, or other irregularitieswere discarded; the remaining utterances include 273utterance tokens with a total of 699 words (229 types).2.2 Model DesignThis model differs from incremental models such as(Brent 1999a) in that it pre-compiles statistics for thecandidate word-final phonemes off-line, over the entirecorpus.
These probabilities are thus static.
While thisdifference is not intended as a strong theoretical claim,it reflects the fact that even before infants seem to belearning the word segmentation process, they have al-ready been exposed to a large amount of linguistic ma-terial.
The information gleaned from the corpus isrepresented in three separate (but composible) finite-state machines:(1) Like most models in the literature, this model as-sumes (for sake of convenience and simplicity) that thechild hears the correct sequence of the actual segmentsproduced within an utterance.
Hence, the model doesnot take into account the possibility of mishearing asegment, as that would add undue complication at thisstage.
This assumption translates into the finite-statedomain as a simple acceptor (or equivalently, an iden-tity transducer) over the segment sequence for a givenutterance.3(2) An optional source of knowledge used is the numberof words in a given utterance.
This is naturally a strongassumption to make; it is included primarily to providecomparisons with baselines used by Brent (1999a) andChristiansen et al (1998), which provide pseudo-random baselines that make reference either to numberof boundaries directly or information concerning aver-age word length.
Results are given both with and with-out this constraint.
(3) The main item under examination is naturally therelative likelihood of breaking the word after a givensegment S.The third information source was tested in three vari-ants.
The first one is of course the approximation sug-gested by Aslin et al (1996), that P(#|S) may beapproximated by using P($|S), the probability of an ut-terance-break given the segment.
This approximationyields the ranking e>s>o>u>i>a>m>n, with /e/ mostlikely to end an utterance.
This information source wascompared to two related alternatives, which were usedas upper and lower bounds to measure the effectivenessof the utterance-boundary approximation of wordboundaries.
As an upper bound (3U), the true value forP(#|S) is used, corresponding to training on labeled data,or a store of already-learned vocabulary.4  The lowerbound (3L) consists of the seven final segments{a,e,i,o,u,n,s}, but the frequency ranking replaced by anequi-probable assumption.
In a sense, this is equivalentto a grammar book listing the possible final segments ofGreek without regard to their actual likelihood.
Finally,these three variants are compared with a random walkfor which no information is used, but boundaries areinserted completely by chance.
Each of these threetypes of knowledge was modeled by means of a finitestate machine, using the AT&T finite-state tools.53 While modeling the mishearing of segments is beyondthe scope of this study, a weighted transducer could in prin-ciple represent a segmental confusion matrix in a modularway and augment the current identity transducer.
Forfurther discussion of issues in using ?unsanitized data,?
(Sundaram, 2003) may be helpful.4   The resulting ranking, o>i>e>s>a>u>n>j>m>p, israther different than the one above, reflecting the frequencyof masculine and feminine articles /o/ and /i/, which arenever utterance-final.5  FSM Library Version 3.7, freely available fromhttp://www.research.att.com/sw/tools/fsm/(1) Segments: Linear FSA (trivially equivalent to anidentity transducer).
(2) Number of words: Unweighted FSA.
(3U) Upper bound: Weighted FST, with weights corre-sponding to -Log(P(#|S)) for a word boundaryand -Log(1-P(#|S)) for an arc with no word boundary.
(3) Utterance-Boundary Probabilities: Same as (3U),with weights corresponding to -Log(P($|S)) for a wordboundary and -Log(1-P($|S)) for no word boundary.
Inthe condition where (2) was not used, a weight of -1.7(determined empirically on the training data) was addedto the word-boundary arc, to offset the tendency ofP($|S) to underestimate P(#|S).
(3L) Unweighted (or equally weighted) version of (3).In the condition where (2) was not used, a weight of(-0.5) was added to the arc that adds boundaries, whichcaused the FST to insert word boundaries after everyinstance of a vowel, /n/, or /s/.3 ResultsSix different conditions were tested, corresponding tothe three variants FSTs (3), (3U), and (3L), both with andwithout the exact-word constraint in FSM (2).
Each ofthese were composed (separately) with the ?segmentidentity?
acceptor (1) for a given utterance.
The output-projection of the best path from each resulting FST wasconverted back into text and compared to the text of theoriginal utterance.
Scores for both boundaries andwords are reported (where a word is counted as cor-rectly segmented only if both its left and right bounda-ries are correctly placed).
In the case where severalbest-paths of equal cost exist, the average scores forprecision and recall are counted.The results with and without the number of wordsknown are shown in Tables 2 and 3, following.
In bothcases, the precision scores patterned as expected.
Theupper bound condition (representing a supervised case,where statistics on the word boundaries are available forthe training data) proved the most accurate on the testdata.
This suggests (as has been confirmed for Englishin such studies as Brent 1999a) that the learning of pat-terns over already-acquired vocabulary has perhaps thelargest effect in the acquisition of new vocabulary.The utterance-based approximation, correspondingmost closely to (Aslin et al, 1996), seems to be slightlybetter overall than the lower bound.
Without the num-ber of words known, (3) has an F-score of 20.2 forwords and 70.2 for boundaries, whereas (3L) has F-scores of only 17.0 (word) and 68.0 (boundaries),though this difference may not be significant.
This dif-ference was less than expected, given preliminary ex-amination of the training data; it may be that once theset of allowable word-final phonemes is observed, therelative probabilities of those phonemes is not as use-fully learned from utterance boundaries.
However, thelower bound (corresponding to purely symbolic knowl-edge of the allowable word-final segments) is signifi-cantly better than the random walk, suggesting that anyknowledge, no matter how rudimentary, begins to makea difference.Table 2: Test Results with Constraint (2)Words Word BoundariesPrecision Recall Precision RecallUpperbound219/720(30.4%)219/699(31.3%)737/993(74.2%)737/972(75.8%)Utt-prob.159/860(18.5%)159/699(22.7%)739/1133(65.2%)739/972(76.0%)Lowerbound195/1599(12.2%)195/699(27.9%)967/1872(51.7%)967/972(99.5%)RandomWalk39/1569(2.5%)39/699(5.6%)767/1842(41.6%)767/972(78.9%)Table 3: Test Results without Constraint (2)4 Discussion4.1 Comparisons with Aslin et al (1996)Obviously, the cues of preceding and following seg-ments are in and of itself insufficient to predict a wordboundary with any reasonable degree of accuracy, justas Christiansen et al (1998) found that no one cue wassufficient for English.
However, a few comparisonswith Aslin?s et al (1996) data in Table 1 may be useful,although they should be interpreted cautiously given thedifferences in the training and testing corpora betweentheir study and this one.
Their results for the single-phoneme condition have nearly equal hits and falsealarms?a precision of about 51%.
They apparently donot consider this sufficient evidence of learning, al-though it is significantly better than their random base-line.
Similarly, the worst non-random conditionWords Word BoundariesPrecision Recall Preci-sionRecallUpperbound277/699(39.6%)277/699(39.6%)751/972(77.3%)751/972(77.3%)Utt-prob.226/699(32.4%)226/699(32.4%)721/972(74.2%)721/972(74.2%)Lowerbound221/699(31.6%)221/699(31.6%)708/972(72.9%)708/972(72.9%)RandomWalk119/699(17.0%)119/699(17.0%)639/972(65.7%)639/972(65.7%)reported here (lower bound without constraint (2)) alsohas a precision of 51%.
This, too, is difficult to call?learning,?
as it represents the heuristic of always in-serting a word boundary any time there could be one.The only fact that has been learned is which segmentscannot be (excepting foreign loan-words) word-final.However, if the criterion for learning (or at leastsatisfactory performance) is hits exceeding false alarms,then the utterance-boundary statistical heuristic, with739 hits and only 396 false alarms, is nearly as accurateas Table 1?s two-phoneme condition.
While furtherinformation (whether phonological features, longerstrings of phonemes, or some other cue) is needed toreach the 74% accuracy of Table 1?s three-phonemecondition, it seems that even these very basic cues comecloser to Aslin?s et al (1996) results than might be sup-posed.
Importantly, the same general trend was shown--that utterance-final information translates into word-boundary information not only for English, but for otherlanguages such as Modern Greek as well.A number of further directions are possible underthis framework, including:(1) Using transitional probability (P(Sk+1| Sk)) and mu-tual information measures over two adjacent segmentsas cues to the likelihood of word boundaries betweenthose two segments, as suggested in e.g., (Brent, 1999a).
(2) Developing more plausible models for approximat-ing word-length distributions from utterance-length in-formation, distances between stressed vowels, pauseinformation, and other salient cues available to children.
(3) Incorporating stress cues (as potentially signalingboth beginnings and approaching ends of contentwords) both alone and in combination with segmentalcues.Preliminary work on each of these avenues is currentlyunderway.
While some of these heuristics may requirethe use of other techniques in addition to finite-statetechniques, the general finite-state framework is ex-pected to prove useful as an organizing tool for compar-ing various cues in a simple, rational, and transparentway.ReferencesAslin, Richard N., Woodward, Julide Z., LaMendola,Nicholas P., & Bever, Thomas G. 1996.
Models ofword segmentation in fluent maternal speech to in-fants.
In James L. Morgan & Katherine Demuth , edi-tors, Signal to syntax, pages 117-134.
Mahwah, NJ:Lawrence Erlbaum Associates.Batchelder, Elanor Olds  2002.
Bootstrapping the lexi-con: A computational model of infant speech seg-mentation.
Cognition 83:167-206.Brent, Michael R. 1999a.
An efficient, probabilisticallysound algorithm for segmentation and word discov-ery.
Machine Learning, 34:71-105.Brent, Michael R. 1999b.
Speech segmentation andword discovery: a computational perspective.
Trendsin Cognitive Sciences, 3(8):294-301.Christiansen, Morton H., Allen, Joseph, & Seidenberg,Mark S. 1998.
Learning to segment speech usingmultiple cues: A connectionist model.
Language andCognitive Processes, 13(2/3):221-268.Davis, Matt H. (2000) Lexical segmentation in spokenword recognition.
Unpublished PhD thesis, BirkbeckCollege, University of London.
Available:http://www.mrc-cbu.cam.ac.uk/personal/matt.davis/thesis/index.htmlde Marcken, Carl G. 1996b.
Unsupervised languageacquisition.
PhD dissertation, MIT, Cambridge, MA.Available: http://xxx.lanl.gov/abs/cmp- lg/9611002Harris, Zelig S. 1954.
Distributional structure.
Word,10:146-162.Johnson, Elizabeth K., & Jusczyk, Peter W. 2001.
Wordsegmentation by 8- month-olds: when speech cuescount more than statistics.
Journal of Memory andLanguage, 44 (4), 548 567.Joseph, Brian.
2001.
?Word?
in Modern Greek.
InR.M.W.
Dixon & A. Aikhenvald (eds.)
Proceedingsof the International Workshop on the Status of?Word?.
Cambridge: Cambridge University Press(2001).Jusczyk, Peter W., & Aslin, R. N. 1995.
Infant's detec-tion of sound patterns of words in fluent speech.Cognitive Psychology, 29:1-23.Jusczyk, Peter W., Hohne, E. A., & Bauman, A.
1999.Infants' sensitivity to allophonic cues for word seg-mentation.
Perception & Psychophysics, 61:1465-1476.Jusczyk, Peter W., Houston, Derek, & Newsome, Mary.1999.
The beginnings of word segmentation in Eng-lish-learning infants.
Cognitive Psychology, 39:159-207.Jusczyk, Peter W., Luce, Paul A., & Charles-Luce, Jan1994.
Infants' sensitivity to phonotactic patterns inthe native language.
Journal of Memory and Lan-guage, 33:630-645.Korman, Myron.
1984.
Adaptive aspects of maternalvocalizations in differing contexts at ten weeks.
FirstLanguage, 5:44-45.Mattys, Sven L., Jusczyk, Peter W., Luce, Paul A., &Morgan, James L. 1999.
Word segmentation in in-fants: How phonotactics and prosody combine.
Cog-nitive Psychology, 38:465-494.Mattys, Sven L. and Jusczyk, Peter W.  2001.
Phono-tactic cues for segmentation of fluent speech by in-fants.
Cognition 78:91-121.Olivier, D. C. 1968.
Stochastic grammars and languageacquisition mechanisms.
PhD dissertation, HarvardUniversity, Cambridge, MA.Saffran, Jenny R., Aslin, Richard N., & Newport, ElissaL.
1996.
Statistical cues in language acquisition:word segmentation by infants.
In G.W.
Cottrell, edi-tor, Proceedings of the 18th Annual Conference ofthe Cognitive Science Society.
pages 376-380.
Hills-dale, NJ: Lawrence Erlbaum Associates.Stephany, U.
1995.
The acquisition of Greek.
In D. I.Slobin, editor, The crosslinguistic study of languageacquisition.
Vol.
4.Sundaram, Ramasubramanian.
2003.
Effects of Tran-scription Errors on Supervised Learning in SpeechRecognition.
Unpublished Masters Thesis.
Missis-sippi State University, Mississippi State, MS.http://www.isip.msstate.edu/publications/books/msstate_theses/2003/transcription_errors/.
