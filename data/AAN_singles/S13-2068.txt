Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 414?417, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUmigon: sentiment analysis for tweetsbased on lexicons and heuristicsClement LevalloisDepartment of Marketing Management, Rotterda School of Managementand Erasmus Studio, Erasmus University RotterdamThe Netherlands.clevallois@rsm.nlAbstractUmigon is developed since December 2012 as aweb application providing a service of sentimentdetection in tweets.
It has been designed to befast and scalable.
Umigon also providesindications for additional semantic featurespresent in the tweets, such as time indications ormarkers of subjectivity.
Umigon is in continuousdevelopment, it can be tried freely atwww.umigon.com.
Its code is open sourced at:https://github.com/seinecle/Umigon1.
General principle of operationUmigon belongs to the family of lexicon basedsentiment classifiers (Davidov et al2010, Kouloumpiset al2011).
It is specifically designed to detectsentiment (positive, negative or neutral) in tweets.
The?sentiment detection engine?
of Umigon consists of 4main parts, which are detailed below:- detection of semantic features in the entire tweet.Smileys and onomatopes are given special attention.- evaluation of hashtags.- decomposition of the tweet into a list of its n-grams(up to 4-grams), comparison of each n-gram with theterms in lexicons.
In case of a match, a heuristic isapplied.- final series of heuristics at the level of the entiretweet, taking advantage of the semantic featuresdetected in the previous steps.
A final, uniquesentiment (pos, neg or neut) is ascribed to the tweet.2.
The four steps of the classification engineWe refer in footnotes to the Java classes whichimplement the processes described here.2.1   Global heuristicsSmileys and onomatopes carry strong indications ofsentiment, but also come in a variety of orthographicforms which require methods devoted to theirtreatment1.Onomatopes and exclamations often include repeatedvowels and consonants, as in yeaaaaahhhh (repeated?a?
and ?h?
), but also yeaah (repeated ?a?
),  oryeeeeaaaaah (repeated ?e?
and ?a?).
We list the mostcommon exclamations and use regular expressions tocapture the variety of forms they can assume.
If such aform is found in the tweet, the related sentiment(positive or negative) is saved, and will be evaluated ata final stage for the global sentiment of the entiretweet.Similarly, smileys are frequently spelled in multiplevariations: :-) can also be found as :-)) or :-)))))))) .
Forthis reason here also the flexibility of regularexpressions is used to detect spelling variations.
Inaddition, we consider that a smiley positioned at thevery end of a tweet gives an unambiguous signal as tothe sentiment of the tweet.
For instance:@mydearfriend You got to see Lady Gaga live, so lucky!Hate you :)))Here, whatever the negative sentiments (Hate you)signaled in the tweet, the final smiley has an overridingeffect and signals the strongest sentiment in the tweet.For this reason smileys located in final positions arerecorded as such.2.2   Evaluation of hashtagsHashtags are of special interest as they single out asemantic unit of special significance in the tweet.Exploiting the semantics in a hashtag faces the issuethat a hashtag can conflate several terms, as in#greatstuff or #notveryexciting.
Umigon applies a series1https://github.com/seinecle/Umigon/blob/master/src/java/Heuristics/SentenceLevelHeuristicsPre.java414of heuristics matching parts of the hashtag withlexicons2.
In the case of #notveryexciting , the startingletters not will be identified as one of the terms in thelexicon for negative terms.
Similarly, the letters verywill be identified as one of the terms present in thelexicon for ?strength of sentiment?.
exciting will bedetected as one of the terms in the lexicon for positivesentiment.
Taken together, not very exciting will leadto an evaluation of a negative sentiment for thishashtag.
This evaluation is recorded and will becombined with the evaluation of other features of thetweet at a later stage.2.3   Decomposition in ngramsThe text of the tweet is decomposed in a list ofunigrams, bigrams, trigrams and quadrigrams.
Forexample, the tweet This service leaves to be desiredwill be decomposed in list of the following expressions:?This, service, leaves, to, be, desired, This service,service leaves, leaves to, to be, be desired, Thisservice leaves, service leaves to, leaves to be, to bedesired, This service leaves to, service leaves to be,leaves to be desired?The reason for this decomposition is that some markersof sentiment are contained in expressions made ofseveral terms.
In the example above, to be desired is amarker of negative judgment recorded as such in thelexicon for negative sentiment, while desired is amarker of positive sentiment.Umigon loops through all the n-grams of the tweet andchecks for their presence in several lexicons3.If an n-gram is indeed found to be listed in one of thelexicons, the heuristic attached to this term in thislexicon is executed, returning a classification (positivesentiment, negative sentiment, or another semanticfeature).
Heuristics attached to terms in the lexiconsare described in detail in section 3.2.4   Post-processing: a last look at the entire tweet .At this stage, the methods described above may havereturned a large number of (possibly conflicting)sentiment categories for a single tweet.
For instance, inthe example This service leaves to be desired, theexamination of the n-grams has returned a positivesentiment classification (desired) and also negative (to2https://github.com/seinecle/Umigon/blob/master/src/java/Heuristics/HashtagLevelHeuristics.java3https://github.com/seinecle/Umigon/blob/master/src/java/Classifier/ClassifierMachine.javabe desired).
A series of heuristics adjucates which ofthe conflicting indications for sentiments should beretained in the end.
In the case above, the co-presenceof negative and positive sentiments without any furtherindication is resolved as the tweet being of a negativesentiment.
If the presence of a moderator is detectedin the tweet (such as but, even if, though), rules of amore complex nature are applied4.3.
A focus on lexicons and heuristicsFour lexicons are used for sentiment analysis (numberof terms in the lexicons in brackets): ?positive tone?
(332), ?negative tone?
(630), ?strength of sentiment?
(59), ?negations?
(45).
These lexicons have beencreated manually by the inspection of thousands oftweets, and continue to be expanded on a regularbasis.
Note that the same term can appear in differentlexicons (if rarely in practice).
For example, the termfucking appears in the lexicon for negative tone and inthe lexicon for strong sentiments.
Each term in alexicon is accompanied by a heuristics and a decisionrule.3.1   Simple case from the ?negative sentiments?lexicon:Term sadfacedHeuristics NoneDecision Rule 012If a tweet contains the term sadfaced, Umigon willdirectly add the code ?012?
(which stands for negativesentiment) to the tweet5.3.2   More complex case from the ?positive sentiments?lexicon:Term SatisfiedHeuristics!isImmediatelyPrecededByANegationDecision Rule 011|012If the term satisfied is present in a tweet, the heuristics!isImmediatelyPrecededByANegation is applied.
This s amethod checking whether the term immediately4https://github.com/seinecle/Umigon/blob/master/src/java/Heuristics/SentenceLevelHeuristicsPost.java5 See this class for the full list of possible classifications:https://github.com/seinecle/Umigon/blob/master/src/java/Classifier/Categories.java415preceding satisfied in the tweet is a negation or not6.This method returns a Boolean (true / false).
TheBoolean returned by this heuristics will determine theoutcome of the decision rule.
Here, the decision rule isa simple binary choice: codify as 011 (meaning, apositive sentiment) if satisfied is not preceded by anegation; codify it as 012 (negative sentiment)otherwise.3.3   Complex case from the ?negative sentiments?lexicon:Term hardHeuristics !isImmediatelyPrecededByANegation+++!isImmediatelyFollowedBySpecificTerm///work|diskDecision Rule A?(B?
(012):011)This example shows how several heuristics (separatedby +++) can be combined, leading to complex rules ofdecision.
In this example, whenever the term hard isdetected in a tweet, 2 heuristics are evaluated: is theterm preceded by a negation?
Is the term followed byspecific terms ?
work or disk, in this case?
Each of theseheuristics returns a Boolean.
The Booleans are fed intothe interpreter of the decision rule, where A and Brepresent the 2 Booleans7.
Depending on their value,the decision tree takes a different branch, leading tothe selection of one codification.
In the example:If A is false, return 011: a positive sentiment.Example: not hardIf A is true and B is true, return 012: a negativesentiment.
Example: it is hardIf A is true and B is false, returns null: nothing (a neutralsentiment).Example: this is a hard diskWhile in practice it is rarely needed to write up rules ofsuch complexity, they offer an extra flexibility to exploitthe semantic features of terms in varying contexts.6 The method actually checks the two terms before, in order tocapture cases such as ?not very satisfied?, where a negativeterm is present but not immediately preceding the term underreview.
See the details of all heuristics here:https://github.com/seinecle/Umigon/blob/master/src/java/Heuristics/Heuristic.java7 The class for the interpreter is:https://github.com/seinecle/Umigon/blob/master/src/java/RuleInterpreter/Interpreter.java4.
Performance4.1   AccuracyUmigon was formally evaluated in a semanticevaluation task proposed by SemEval-2013, theInternational Workshop on Semantic Evaluation(Wilson et al 2013).
The task consisted in classifying3,813 tweets as positive, negative or neutral in polarity(task B).
The results:class Pos neg neutprec 0.7721 0.4407 0.6471rec 0.5604 0.5507 0.7579fscore 0.6495 0.4896 0.6981average(pos and neg)  0.5696For reference, the best performing participant in thistask obtained the following results (Mohammad et al2013):class pos  neg neutprec 0.8138 0.6967 0.6765rec 0.6673 0.604 0.8262fscore 0.7333 0.6471 0.7439average(pos and neg) 0.6902We see that Umigon had an especially poor precisionfor tweets of a negative sentiment (results greyed inthe table).
This means that Umigon failed to identifymany negative tweets as such.
One reason accountingfor this poor performance is the definition we adopt forwhat a negative sentiment is.
For example, the SemEvaltask included this negative tweet:?Renewed fighting rocks Syria: An early morningexplosion rocked the flashpoint city of Deir Ezzor onSaturday in...?By design, Umigon has not been conceived to classifysuch a tweet as negative because if it contains negativeelements of a factual nature (explosion, fighting), butcontains no marker of a negative attitude.This question aside, the accuracy of Umigon should beimproved by increasing the number of terms andheuristics in the lexicons, which is an ongoing process.4.2   SpeedTested on a dataset provided by sentiment140.com8,Umigon performs the classification of 1.6 milliontweets in less than 15 minutes.
We believe that notrelying on Part of Speech tagging makes it a specially8 http://help.sentiment140.com/for-students416fast solution for lexicon-based sentiment classifiers.The classifier engine is implemented in such a way thatthe presence of absence of n-grams in the terms lists ischecked through look-ups on hashsets (is this n-gramcontained in a set?
), not loops through these sets.
Sincelook-ups in hashsets is typically of O(1) compexity9, thisinsures that the performance of Umigon will notdegrade even with expanded lexicons.ReferencesDavidov, D., Tsur, O., and Rappoport, A.
2010.Enhanced sentiment learning using twitter hashtagsand smileys.
Proceedings of Coling.Kouloumpis, E., Wilson, T., and Moore, J.
2011.
TwitterSentiment Analysis: The Good the Bad and the OMG!Proceedings of ICWSM.Mohammad, S., Kiritchenko, S. and Zhu, X.
2013.
NRC-Canada: Building the State-of-the-Art in SentimentAnalysis of Tweets.
In Proceedings of the InternationalWorkshop on Semantic Evaluation, SemEval ?13, June2013, Atlanta, Georgia.Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S.Stoyanov, V. and Alan Ritter.
2013.
SemEval-2013 Task2: Sentiment Analysis in Twitter.
In Proceedings of theInternational Workshop on Semantic Evaluation,SemEval ?13, June 2013, Atlanta, Georgia.9 http://stackoverflow.com/questions/6574916/hashset-look-up-complexity417
