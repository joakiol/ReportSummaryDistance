Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260?1269,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPUsing Morphological and Syntactic Structuresfor Chinese Opinion AnalysisLun-Wei Ku Ting-Hao Huang Hsin-Hsi ChenDepartment of Computer Science and Information EngineeringNational Taiwan UniversityNo.
1, Sec.
4, Roosevelt Road, Taipei, 10617 Taiwan{lwku,thhuang}@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.twAbstractThis paper employs morphological struc-tures and relations between sentence seg-ments for opinion analysis on words andsentences.
Chinese words are classifiedinto eight morphological types by twoproposed classifiers, CRF classifier andSVM classifier.
Experiments show thatthe injection of morphological informationimproves the performance of the word po-larity detection.
To utilize syntactic struc-tures, we annotate structural trios to repre-sent relations between sentence segments.Experiments show that considering struc-tural trios is useful for sentence opinionanalysis.
The best f-score achieves 0.77for opinion word extraction, 0.62 for opin-ion word polarity detection, 0.80 for opin-ion sentence extraction, and 0.54 for opin-ion sentence polarity detection.1 IntroductionSentiment analysis has attracted much attentionin recent years because a large scale of subjectiveinformation is disseminated through various plat-forms on the web.
Sentiment information can beapplied to a wide variety of fields, includingproduct recommendation, review summarization,public polling, and so on.Opinion dictionaries are important resourcesfor identifying subjective information.
Severalapproaches were proposed to collect such re-sources.
Wiebe (2000) learned subjective adjec-tives from corpora.
Takamura et al (2005) ex-tracted semantic orientations of words.
Ku et al(2007) measured sentiment degrees of Chinesewords by averaging the sentiment scores of thecomposing characters.
When the opinion wordsare available, the polarities of sentences anddocuments can be determined by them.
Riloffand Wiebe (2003) learned the extraction patternsfor subjective expressions.
Kim and Hovy (2004)found the polarity of subjective expressions.Pang et al (2002) and Dave et al (2003) ex-plored various techniques at document level.Morphological information has been widelyused in classifying words, telling the meanings,and doing other in-depth analysis (Tzeng andChen, 2002).
However, morphological informa-tion was seldom applied either in Chinese opin-ion extraction, or in solving the coverage prob-lem of opinion dictionary.
Instead of bag-of-characters approach (Ku et al, 2007), this paperemploys morphological structures of words toextract opinion words.Relations between sentence segments are alsodefined by linguistics in the Chinese language.These are similar to morphological structuresbetween Chinese characters.
Based on parsingtrees of sentences, we identify these relations andutilize them for opinion analysis on sentences.As the experimental corpus, some researchersmanaged to generate annotated materials andgold standards under many constraints.
Ku set astandard for generating final answers from anno-tations of multiple annotators (Ku et al, 2007),and Somasundaran annotated discourse informa-tion from meeting dialogs to train a sentimentmodel (Somasundaran et al, 2007).
For multi-lingual issues, researchers concerned mainlyabout the applicability of corpus and algorithmsfrom the native language to foreign languages(Banea et al, 2008; Bautin et al, 2008).Several opinion analysis systems have beendeveloped so far.
OASYS (Cesarano et al, 2007)and CopeOpi (Ku et al, 2007) allow users inputtheir queries and select preferred data sources,1260and then track opinions in a time zone.
For bothsystems, extracting opinions is the main focus,while holders and targets are identified implicitlywhen retrieving relevant documents.
Carenini?steam proposed a graphical user interface forevaluative texts (2006), in which color blockswere used to present the evaluations for compo-nents of products.
Fair News Reader, a Japanesenews Web system, incorporates sentiment infor-mation insensibly in an interesting way (Kawaiet al, 2007).
It provides readers ?balanced?
re-ports by analyzing the sentiment in news articleswhich readers have read, and suggests them newarticles according to the analysis results.
It leadsthe application of opinion analysis to the direc-tion of personalization.2 Chinese Morphological StructuresIn the Chinese language, a word is composed ofone or more Chinese characters, and its meaningcan be interpreted in terms of its composite char-acters.
The morphological structures of Chinesewords are formulated by three major processes inlinguistics: compounding, affixation, and conver-sion.
Compounding is a complex word-formation process.
In most cases, two or moremorphemes together are formed as a lexical itemby this process.
Affixation is a morphologicalprocess, by which grammatical or lexical infor-mation is added to a base form.
By the conver-sion process, a word is changed from one part ofspeech into another without the addition or dele-tion of any morphemes.Compounding is the most productive way toconstruct a Chinese word.
Mostly, a Chinesecharacter itself carries meanings, so that a mor-pheme can function as a character and has itsown part of speech.
In some cases, a Chinesemorpheme may carry no specific meaning andjust makes a word more readable.
Cheng andTian (1992) divided Chinese words into fivemorphological types based on the relations be-tween the morphemes in compounding words.
(1) Parallel Type: Two morphemes play coordi-nate roles in a word.
For example, the mor-phemes ???
(money) and ???
(wealth) are par-allel in the word ????
(money-wealth).
(2) Substantive-Modifier Type: A modifiedmorpheme follows a modifying morpheme.
Forexample, the morpheme ???
(cry) is modifiedby ???
(bitterly) in the word ????
(bitterly-cry).
(3) Subjective-Predicate Type: One morphemeis an expresser and the other one is described.The structure is like a subject-verb sentence con-densed in one word.
For example, the morpheme???
(heart) is a subject of the predicate ???
(hurt) in the word ????
(heart-hurt).
(4) Verb-Object Type: The first morpheme isusually a verb which governs the second one,making this word similar to a verb followed byits object.
For example, the morpheme ???
(control) serves as the object of the verb ???
(lose) in the word ????
(lose-control).
(5) Verb-Complement Type: The first mor-pheme is usually a verb but sometimes can be anadjective, and the second morpheme explains thefirst one from different aspects.
For example, themorpheme ???
(clearly) expresses the aspects ofthe action ???
(look).Chinese words constructed by affixation proc-ess can be one of the two cases ?
say, morphemeand morpheme, or morpheme and non-morpheme.In the case of morpheme and morpheme, the af-fixation word belongs to one of the above 5 typesif the prefix and the suffix are neither negationsnor confirmations.
Types 6 and 7 defined belowrepresent the affixation words whose prefix orsuffix is a negation or a confirmation.
The af-fixation words whose prefix or suffix charactersare not morphemes are classified into type 8.
(6) Negation Type: There is at least one nega-tion character in words of this type.
For example,the prefix ???
(no) is the negation morpheme inthe word ????
(no-method).
(7) Confirmation Type: There is at least oneconfirmation character in words of this type.
Forexample, the prefix  ???
(do) is a confirmationin the word ????
(do-depend on).
(8) Others: Those words that do not belong tothe above seven types are assigned to this type,such as words whose meanings are not a functionof their composite characters, words whose com-posite characters are not morphemes, such as ????
(nephew-suffix) and ????
(peppermint).3 Opinion Scores of Chinese WordsThe bag-of-characters approach proposed by Kuet al (2007) considers the observation probabili-ties of characters in Chinese opinion words.
Itcalculates the observation probabilities of char-acters from a set of seeds first, then dynamicallyenlarges the set and adjusts their probabilities.
In1261this approach, the opinion score of a word is de-termined by the combination of the observationprobabilities of its composite characters definedby Formulas (1) and (2).??
?===+= miiniiniineg,Cf/neg,Cfpos,Cf/pos,Cfpos,Cf/pos,CfposCP111)()()()()()(),( (1)??
?===+= miiniimiineg,Cf/neg,Cfpos,Cf/pos,Cfneg,Cf/neg,CfnegCP111)()()()()()(),( (2)),(),()( negCNposCPCS ?=(3))(1)...(121 ?==liil CSlCCCS(4)where C is an arbitrary Chinese character, f(C,polarity) counts the observed frequency of C in aset of Chinese words whose opinion polarity ispositive (pos) or negative (neg); P(C, pos) andP(C, neg) denote the observation probabilities ofC as a positive and a negative character, and nand m denote total number of unique charactersin positive and negative words.
The differenceof P(C, pos) and P(C, neg) in Formula (3) de-termines the sentiment score of character C, de-noted by S(C).
Formula (4) computes the opin-ion score of a word of l characters C1C2?Cl byaveraging their scores.Instead of counting the weights as in the bag-of-characters approaches, we consider the wordstructures and propose a scoring function foreach morphological type.
According to the Fre-quency Dictionary of Modern Chinese, 96.5% ofChinese words are unigrams and bigrams (Chen,et al, 1997).
In the following functions, S(C1C2)computes the opinion scores of words with char-acters C1 and C2.
SIGN(s) returns -1 if polaritydegree s is smaller than 0, i.e., negative, and re-turns 1 when positive.
(1) Parallel Type: Since the two compositecharacters of a word of this type are homogene-ous, the opinion score is the average score of twocharacters?
opinion scores.2)()()( 2121CSCSCCS+=(5)(2) Substantive-Modifier Type: The first mor-pheme of a word of this type modifies the secondone, so that its opinion weight comes from theabsolute opinion score of the first character,while the opinion polarity is determined by theoccurrence of negative opinion characters.
If atleast one negative opinion character appears, theword is negative, else it is positive.
For example,the word ????
(bitterly cry) is composed of???
(bitterly, negative) and ???
(cry, negative).Negative characters make this word negative andits opinion strength, i.e., the absolute value of thescore, is decided by the first character for thedegree of crying.
)()()( else)( 1- )( else)(  )( then  )0)(  and  0)(( ifthen)0)(  and  0)(( if21211211212121CSCSCCSCSCCSCSCCSCSCSCSCS+=?==>>??
(6)(3) Subjective-Predicate Type: The first mor-pheme of a word of this type is a subject and thesecond morpheme is the action it performs, sothat the action decides the opinion score of theword.
If the action is not an opinion or it is neu-tral, the subject determines the opinion score ofthis word.
For example, the word ????
(mud-slide, negative) is composed of ???
(mountain,non-opinion) and ???
(collapse, negative).
Itsopinion score depends only on the second char-acter ???
(collapse) since the first character is asubject and usually bears no opinions.
)()( else)()( then )0)(( if1212212CSCCSCSCCSCS==?
(7)(4) Verb-Object Type: The first morpheme ofwords of this type acts upon the second mor-pheme.
The effect depends not only on the ac-tion but on the target.
The weight is determinedby the action, but the polarity is the multiplica-tion of the signs of the two morphemes.
For ex-ample, the word ????
(to go away for thesummer, positive) is composed of ???
(hide,negative) and ???
(hot summer, negative).
Itsstrength depends on the strength of ???
(hide)and polarity is positive from the multiplication oftwo negatives.
)()()( else))(())(()()(    then)0)(  and  0)(( if21212112121CSCSCCSCSSIGNCSSIGNCSCCSCSCS+=??=??
(8)(5) Verb-Complement Type: The scoring func-tion for words of this type is defined the same asthat of a Subjective-Predicate type in Formula(7).
The complement morpheme is the decidingfactor of the opinion score.
For example, theword ????
(raise, positive) is composed of???
(carry or lift, non-opinion) and ???
(high,1262positive).
The complement morpheme ??
?
(high) describes the resulting state of the verbmorpheme ???
(raise), so both strength and po-larity depend on the morpheme ???
(high).
(6) Negation Type: A negative character speci-fied in a predefined set NC has a negation effecton the opinion score of the other character.
Thestrength depends on the modified morphemewhile the polarity of the word is the negation ofthe polarity of the modified morpheme.
( )( ) )(1)( else)(1)( then )( if1212211CSCCSCSCCSNCC??=??=?
(9)(7) Confirmation Type: A positive characterspecified in a predefined set PC ensures that theopinion score of a word only comes from theother character.
Therefore, the opinion score ofthis word is determined by the modified mor-pheme.
)()( else )()( then )( if 1212211 CSCCSCSCCSPCC ==?
(10)(8) Others: Since words of this type contain noclear cues for their morphological structures, wepostulate that both characters have the same con-tribution, and adopt Formula (5).4 Identification of Morphological TypesTo compute the opinion score of a word accord-ing to formulae in Section 3, we must know itsmorphological type from the morphologicalstructure, i.e., the parts of speech of the compos-ite morphemes.
Currently, part of speech tag-ging is performed at the word level rather thanthe morpheme level, and morpheme-tagging cor-pus is not available.
We consider an on-lineChinese dictionary, Dictionary of Chinese Wordsby Ministry of Education, Taiwan (MOEDCW),as a corpus, and compute the statistics of eachmorpheme in it.Two classifiers, CRF classifier and SVM clas-sifier are proposed to recognize morphologicaltypes (1)-(5).
Morphological types (6) to (8) aredetermined by rules such as whether two com-posite characters are morphemes; whether thereare confirmation/negation morphemes; and so on.4.1 MOEDCW CorpusMOEDCW corpus provides possible parts ofspeech for each morpheme by treating it as a uni-gram word, and possible senses under each partof speech.
In each entry, there are a sense defini-tion and some example words.
Figures 1 and 2show the specifications of two morphemes ??
?and ???.
The morpheme ???
has three partsof speech (verb, adverb and noun) and includes 3,1, and 1 senses.
There are 3, 3, and 2 examplewords listed under the three verb senses.We can find the correct parts of speech of thecomposite characters of a word when it is an ex-ample word in the dictionary.
However, not allwords are listed in the corpus.
Consider theword ????
(sweat, verb).
Figure 1 shows that????
(sweat) is an example word listed underthe verb sense of the character ???
(perspire),thus the character ???
(perspire) in the word ????
(sweat) functions as a verb.
However, ????
(sweat) is not an example for the character???
(sweat).
Figure 2 show that there are twopossible parts of speech, noun and verb, for thecharacter ???
(sweat).
We then show how toidentify its function in the word ???
?.1Goes out from the button to the top orfrom inside to outside.
For example,fume, smoking, and sweat.
?????????????????????????????
?2Burst into or regardless of.
For example,take risk, to offend, and offense.
???????????????????????
?verb3Fake or on the pretext of.
For example,personate and to pretend to be.
?????????????????
?ad-verb 1Crude or rash.
For example, offensivelyand advance rashly.
?????????????????
?noun 1 Family name.
?
?Figure 1: Specification of ???
in MOEDCW1Sweat.
For example, cold sweat, nightsweat, sweatiness, and to drip withsweat.
???????????????????????????????????????????
?noun2 Family name?
?verb 1 To sweat ??????
?Figure 2: Specification of  ???
in MOEDCW)( )( POS,CnsesNumberOfSePOS,CT =  (11)The number of possible meanings one charac-ter can bear when it functions as a certain part of1263speech is employed to estimate how often thispart of speech is used.
The function T(C, POS)shown in Formula (11) defines the score of acharacter C functioning as a particular part ofspeech POS.
Here, POS may be noun (N), adjec-tive (ADJ), verb (V), adverb (ADV), auxiliary(AUX), conjunction (CONJ), pronoun (PRON),preposition (PREP), and interjection (INT).
InFigure 2, T(?<sweat>, N) = 2 and  T(?<sweat>,V) = 1.4.2 Features for ClassifiersFeatures for training SVM and CRF classifiersinclude the pronunciation and the tone of theword, parts of speech of the first and the secondcharacters of training words, and the positioninformation of the composite characters.
Thetone of the word is acquired from MOEDCW.The parts of speech are estimated by Formula(11).
f(C, POS, k, start/end) counts the numberof k-grams (k=2, 3, 4).
In Figures 1 and 2, f(?,V, 2, start)=6, f(?, V, 2, end)= 2, f(?, ADV, 2,start) = 2, and f(?, ADV, 2, end)=0.
This ex-ample shows that when the character ???
func-tions as a verb or an adverb, it serves as the start-ing character more often than the ending charac-ter.4.3 CRF and SVM ClassifierCRF and SVM are both common used algorithmsfor building classifiers (Lafferty et al, 2001).We adopted CRF++1 and libSVM (Chang andLin, 2001) to develop our classifiers.
The fea-tures for training our CRF and SVM classifiersinclude the input word W, the tone of W, the firstand the second characters C1 and C2, T(C1, POS),T(C2, POS),  f(C1, POS, k, start), f(C1, POS, k,end), f(C2, POS, k, start), and f(C2, POS, k, end).POS denotes one of nine parts of speech inMOEDCW, and k equals to 2, 3 or 4.Using SVM is straightforward.
To classify aword into one of the morphological structuretypes, we construct the word's feature vector andinput the vector into SVM.
When using CRF, adifferent approach is taken.
When predicting theclasses of two successive instances, CRF takesthe predicted class of the first instance into ac-count when predicting the second instance's class.Here is how we exploit this capability.
In a nut-shell, we perform classification at the characterlevel instead of the word level.
Let W be a wordcomposed of the two characters C1 and C2.
Let v1 http://crfpp.sourceforge.net/be the feature vector of W.  Let t be the morpho-logical structure type of W.  We define C1's fea-ture vector to be composed of the features in vwhich are related to C1, e.g., T(C1, verb).
Simi-larly, C2's feature vector is composed of the fea-tures in v which are related to C2.
C1's class andC2's class are defined as t_1 and t_2, respectively.Since t has five possible values, there are 10character classes.To determine a word W's morphological struc-ture type, we first apply CRF on W's constituentcharacters C1 and C2's feature vectors.
For C1,CRF will return a set of probabilities P(C1,t_q),where q ?
{1, 2}, indicating the likelihood of C1being an instance of class t_q.
Similarly, a set ofprobabilities P(C2,t_q) is returned for C2.
W'smorphological structure type is defined as thevalue of t which maximizes the product ofP(C1,t_1) and P(C2,t_2).Though CRF is mostly used for sequential la-beling, the idea of using CRF is to tail this classi-fication questions into a labeling question in or-der to utilizing the position information of char-acters.
As mentioned, if a word W of two char-acters C1C2 is of type 1, CRF will label C1 1_1(type1_1st char) and C2 1_2 (type1_2nd char).The labeling of each character considers both theprevious character's features and the next charac-ter's features.
That is, if the current character isthe first character, its previous character is anempty character (which is used for segmentingsequences in CRF); if the current character is thesecond character, its next character is an emptycharacter.
Hence the position information will beconsidered by CRF.5 Experiments and DiscussionExperiments verify whether the morphologicaltypes benefit opinion polarity detection on words.The relation between the performance of mor-phological classifiers and opinion polarity detec-tion is discussed.5.1 Experimental SetupTo compare the bag-of-characters approach (Kuet al, 2007) with our morphological structureapproach, we adopt the same evaluation data setcontaining 836 words.
To evaluate the perform-ance of our two morphological classifiers, weprepare two sets of words, including the testingset of 836 words for word-level opinion predic-tion (abbreviated as OP), and a set of 8,186words selected from words in MOEDCW corpusand news documents except those can be classi-1264fied by patterns (abbreviated as TRAIN set), allwith their morphological types annotated.
Table1 lists the distributions of morphological types inOP and TRAIN sets.The polarity of words is predicted by theiropinion scores ranging between -1 to 1.
We set apositive threshold.
Those words with scoresabove it are considered as positive while thosebelow this threshold multiplied by (-1) are re-garded as negative.
The words with non-zeroscores falling between the positive and negativethresholds are neutral.
Fifty grids from 0 to 0.5are searched for the best threshold.
Since theopinion extraction at word level concerns onlyword structure, no retraining for the best thresh-old is need when domain shifts, which is a supe-riority of our method.5.2 Morphological Type Classification andPolarity DetectionThe performances of CRF and SVM classifierson each morphological type are listed in Table 2.We perform four-fold cross validation on theTRAIN set.
Results show that CRF classifierachieves better performance than SVM classifierin this task.
The accuracy of CRF classifier(0.70) is 8% higher than that of SVM classifier(0.62).
Note those type 8 words which could beextracted by rules are excluded from classifica-tion experiment.
The remaining type 8 words areusually proper names.
It is difficult for bothclassifiers to identify such words.Table 3 further shows the performance of po-larity prediction using morphological types de-termined by CRF classifier and SVM classifier.The performance of polarity detection is evalu-ated by the f-score defined in Formula (12).The f-scores of polarity detection using CRFclassified types and SVM classified types are0.5806 and 0.5938, respectively.
Both of themoutperform baseline?s f-score 0.5455, i.e., thebag-of-characters approach (Ku et al, 2007).Experiments show that adopting morphologicaltypes annotated by two classifiers for polarityprediction has little difference.
In other words,CRF and SVM classifiers have an 8% f-scoredifference in their best performance of classifica-tion, while the performance gap in word polarityprediction using morphological types providedby these two classifiers is around 1.3% only(0.5806 vs. 0.5938).
The reason may be that wedefine scoring functions of each morphologicaltype in a straightforward way.
If they are not thebest scoring functions, the benefit of consideringthe morphological type information could be re-stricted.
Nevertheless, experimental results showthat morphological type information is useful forword polarity detection (with p-value less than0.05).
)()()(opinionproposedpolaritycorrectopinioncorrectP?= ,)()()(opiniongoldpolaritycorrectopinioncorrectR?= ,RPRPscoref+?
?=?2 .
(12)set/type 1 2 3 4 5 6 7 8TRAIN 26.15 44.97 1.64 15.14 9.22 0 0 2.88OP 45.8 24.4 1.3 7.9 8.0 2.3 0.5 9.8Table 1: The Percentage of distribution for morphological types in TRAIN and OP setsMorphoType 1 2 3 4 5 8 AccuracyCRF 0.63 0.78 0.41 0.66 0.78 0.17 0.70SVM 0.49 0.73 0.22 0.52 0.55 0 0.62Table 2: The f-score of CRF and SVM classifiersWe further examine how well our polarity de-tection method works in combination with aword sentiment dictionary.
We use the NTUSD2word sentiment dictionary.
If a word appears inNTUSD, then the word's polarity is the onespecified in NTUSD.
If a word does not appearin NTUSD, then the word's polarity is deter-mined using our morphological type method.2 http://nlg18.csie.ntu.edu.tw:8080/opinion/After introducing a sentiment dictionaryNTUSD3, CRF and SVM classifiers both achievethe f-score 0.77 for opinion word extraction, andachieve f-scores 0.61 and 0.62 for polarity detec-tion, respectively.
Note that if only NTUSD isused to extract opinion words by string matching,the f-score is only 0.44.3 http://nlg18.csie.ntu.edu.tw:8080/opinion/1265Polarity f-score Without NTUSD With NTUSDKu 0.5455 0.5789CRF type 0.5806 0.6100SVM type 0.5938 0.6246Table 3: Prediction with Morphological TypesWe further analyze the improvement of polar-ity prediction for each morphological type.
Wefind that the f-scores of polarity prediction of allmorphological types are improved in differentdegrees, and among them the performance oftype 2 words are improved the most.
We haveshown that our method can assign an opinionscore to an arbitrary word without any wordthesauri by considering its morphological infor-mation.
Moreover, since the Substantive-Modifier (type 2) is the most common way toform a new word in the Chinese language(Cheng and Tian, 1992), the result presents thestrength of our method in solving the coverageproblem.6 Syntactic Structure for Chinese Opin-ion AnalysisAs mentioned, the relations introduced in Section2 exist not only within words, but also betweensentence segments.
Relations between sentencesegments are represented by structural trios here-after and will be introduced in next section.
Wehave already shown that morphological types areuseful when extracting opinion words and wouldlike to further testify whether structural trios alsobenefit the opinion analysis on sentences.
Weannotate these relations manually, propose amethod to identify these relations, and compareresults of experimental settings using structuraltrios with those not using structural trios.6.1 Structural TrioEach node in a parsing tree dominates a wordstring in a sentence.
Linguistics have shown thatthere are also five relations between sentencesegments: Parallel, Substantive-Modifier, Sub-jective-Predicate, Verb-Object, and Verb-Complement, same as morphological types (1) to(5).
Because parsing trees have hierarchicalstructures, we define a structural trio to representa relation between two nodes as follows:(1) A structure trio contains two childrennodes which bear a relation.
(2) A structure trio contains one head nodewhich is the nearest common parent of twochildren nodes in (1).Figure 3: Example of structural triosFigure 3 shows an example of a structure trio.It is a part of a parsing tree containing words ????
(obtain), ????
(happy), ????
(results).Two structural trios are shown in this example.The lower one contains two children nodes ????
(happy) and ????
(results), and is labeledas Substantive-Modifier (S-M (2)) in their near-est common parent node, while the upper onecontains two children nodes ????
(obtain) and??????
(happy results), and is labeled asVerb-Object (V-O (4)).6.2 Experimental CorpusTo experiment with structural trios, we need theparsing trees of all experimental sentences.
Forthis purpose, we adopted Chinese Treebank 5.14as the experimental materials.
Chinese Treebankcontains raw Chinese news documents togetherwith their segmented, part of speech tagged, andparsed versions.
The parsed documents areadopted in experiments utilizing structural trios,and the part of speech tagged documents are usedin experiments not utilizing structural trios.In Chinese Treebank, a unique ID is labeledon each sentence.
For each sentence, we hadthree annotators label their opinions and then wegenerate the gold standard following NTCIR 5MOAT protocol (Seki et al, 2008).
We alsoannotated structure trios in Chinese Treebank.
Atotal of 17,159 sentences are obtained after drop-ping some faulty sentences such as empty sen-tences and sentences composed of more than oneparsing tree.
The statistics of opinion sentencesand structural trios in the constructed experimen-tal materials are shown in Table 4 and Table 5.4 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2005T015 http://research.nii.ac.jp/ntcir/index-en.html1266Opinion Non-OpinionPositive Neutral Negative6,380 1,537 1,714 #9,6317,52866.24 15.96 17.80 %56.1343.87Table 4: Statistics of opinion sentencesTrio Type Number Percentage %2 18,483 36.853 13,687 27.294 15,970 31.845 965 1.92Others 1,054 2.10Total 50,159 100.00Table 5: Statistics of structural trios6.3 Experiment SetupThe aim of our experiments is to know howopinion analysis approach performs when mor-phological and syntactic structures are incorpo-rated.
They are compared with the bag-of-character and bag-of-word approaches.
We im-plemented the bag-of-word approach proposedby Ku et al (2007) to show its performance onChinese Treebank.
In their approach, the opin-ion scores of words are summed to generate theopinion scores of sentences, and the negationwords will negate the closest opinion words.Based on this approach, we further considerstructural trios to experiment whether syntacticstructures of sentences are beneficial for opinionanalysis.
Because the scoring functions may notbe straight forward as those we have adopted foropinion word extraction, we did not design scor-ing functions for utilizing all types of structuraltrios.
Instead, we emphasize their original opin-ion scores by multiplying a variable alpha to seewhether these structures are important.
In thispaper, alpha equals five.We have shown that word morphologicalstructures benefit the word opinion extraction.When we experiment on sentences, we also in-corporate the word morphological structures tosee whether they are also useful for opinionanalysis on sentences.
Five experimental set-tings are listed as below:(1) bag[w]-bag[s]: structural information isnot considered for both words and sen-tences.
The bag-of-character approachis used to calculate the opinion scores ofwords, and the bag-of-word approachsentences.
(2) struc[w]-bag[s]: morphological struc-tures are utilized to calculate word opin-ion scores, but structural trios are notconsidered.
The bag-of-word approachis used to calculate the opinion scores ofsentences.
(3) bag[w]-struc[s]: structural trios are con-sidered for calculating sentence opinionscores, while the bag-of-character ap-proach is used to calculate the opinionscores of words.
(4) struc[w]-(m)struc[s]: both word mor-phological structures and manually la-beled structural trios are adopted.
(5) struc[w]-struc[s]: both morphologicalstructure of words and system labeledstructural trios are adopted.As we have shown that NTUSD is beneficialto the opinion analysis at word level, it is used asdescribed in section 5.2 by default.Our system adopted CRF algorithm to labelstructural trios for setting (5).
The content stringand the part of speech of the current node, itsparent node, its offspring nodes in the next threegenerations, together with the depth of the cur-rent node in the Chinese Treebank, are used asthe features for each node in CRF.
The co-occurrence of the current node and all its siblingsare defined in CRF?s template file.
CRF willlabel whether the current node is the first child orthe second child of a certain relation in a struc-tural trio, or it is not part of any structural trios.A four-fold experiment is performed for thelearning and testing of this labeling  process byCRF.6.4 Results and DiscussionTable 6 shows the statistics of manually labeledstructural trios in Chinese Treebank and identifi-cation performance of CRF.
Table 7 shows theperformance of five experiment settings de-scribed in Section 6.3.
The experiment resultsshow that the morphological structures of wordsdo not have a large contribution for opinion sen-tence analysis (setting 1 vs. setting 2; setting 3 vs.setting 4).
However, considering the structuraltrios improve the performance.1267Trio Type Number Percentage f-Score2 18,483 36.85% 0.48833 13,687 27.29% 0.49444 15,970 31.84% 0.63605 965 1.92% 0.2034Others 1,054 2.10%Total 50159 100%Table 6: Statistics and Results of IdentifyingStructural TriosSetting Word [w]Sentence[s]f-Score(opinion)f-Score(polarity)1 bag bag 0.7073 0.49882 struc bag 0.7162 0.51173 bag struc 0.8000 0.53614 struc (m)struc 0.7922 0.52975 struc struc 0.7993 0.5187Table 7: Results of Opinion Extractionon Chinese TreebankBy summarizing the experimental results inSection 5 and this section, we can conclude thatconsidering the word morphological structuresbenefits the opinion polarity detection, but in thecurrent approach its assistance to words does notpropagate to sentences.
Considering the syntac-tic structures, however, do help in opinion analy-sis both for the opinion sentence extraction andthe polarity detection.
The performance of opin-ion extraction boosts to an f-score 0.80 and theperformance of polarity detection an f-score 0.54.However, the utilization of structure triosneeds the parsing tree of sentences as the priorknowledge.
Hence these two kinds of structuralinformation may be suitable for different applica-tions: structural trios for well written sentencessuch as those in the news articles, while the mor-phological structures for casually written sen-tences such as those appear in SMS messages orarticles with limit length on the Web.Because there are no opinion experiments per-formed on Chinese Treebank, we mention theperformance of Ku?s approach (setting (1)) foropinion sentence extraction, f-score 0.6846, inNTCIR-7 MOAT task, on news articles, as a re-sult for comparison.
Their approach was rankedthe second in this task, and the best teamachieved an f-score 0.7453.7 Conclusion and Future WorkThis paper considers morphological and syntac-tic structures in analyzing Chinese opinion wordsand sentences.
For morphological structures,eight Chinese morphological types are defined.CRF classifier and SVM classifier for morpho-logical type classification are proposed.
Experi-ments show that CRF classifier achieves the bestaccuracy 0.70 in type classification, which is 8%better than SVM classifier.
We further show thatword morphological structures benefit the opin-ion word extraction significantly.
With the helpof the sentiment dictionary NTUSD, the f-scoreof opinion word extraction achieves 0.77 and thef-score of the word polarity detection achieves0.62 when the word morphological types areprovided by the SVM classifier.
They are com-parably better than bag-of-character approachand the dictionary based approach.We defined structural trios to represent the re-lations between sentence segments and also ex-tract these relations using CRF algorithm.
Re-sults show that considering structural trios bene-fits the opinion analysis on sentences.
An f-score 0.80 for opinion extraction and an f-score0.54 for polarity detection are achieved, which isa great improvement.The opinion scoring functions for morphologi-cal types and structural trios are critical for polar-ity detection, and scoring functions for wordsdetermine the scoring functions for sentences.Now we define these functions intuitively basedon linguistic rules, but learning methods like re-gression will be investigated in the future.
Ex-amining the interaction of cues from word andsentence levels on the opinion sentence extrac-tion and the opinion polarity detection is our nextgoal.AcknowledgementResearch of this paper was partially supported by Na-tional Science Council, Taiwan, under the contractNSC95-2221-E-002-265-MY3.ReferencesBanea, C., Mihalcea, R., Wiebe, J. and Hassan, S.2008.
Multilingual Subjectivity Analysis UsingMachine Translation.
In Proceedings of EmpiricalMethods in Natural Language Processing (EMNLP2008).Bautin, M., Vijayarenu, L. and Skiena, S. 2008.
Inter-national sentiment analysis for news and blogs.
InProceedings of the International Conference onWeblogs and Social Media (ICWSM).Carenini, G., Ng, R. T. and Pauls, A.
2006.
InteractiveMultimedia Summaries of Evaluative Text.
In Pro-ceedings of the 11th International Conference onIntelligent User Interfaces (pp.
124-131), Sydney,Australia.1268Cesarano, C., Picariello, A., Reforgiato, D. andSubrahmanian, V.S.
2007.
The OASYS 2.0 Opin-ion Analysis System.
Demo in Proceedings of In-ternational Conference on Weblogs and SocialMedia (pp.
313-314), Boulder, CO USA.Chang, Chih-Chung and Lin, Chih-Jen.
2001.LIBSVM: a library for support vector machines,http://www.csie.ntu.edu.tw/~cjlin/libsvmChen, A., Xu, L., Gey, F.C.
and Meggs, J.
1997.
Chi-nese Text Retrieval without Using a Dictionary.ACM SIGIR Forum, Volume 31, Issue SI (pp.
42-49).Cheng, X.-H. and Tian, X.-L. 1992.
Modern Chinese.Bookman Books Ltd.Dave, K., Lawrence, S., and Pennock, D.M.
2003.Mining the Peanut Gallery: Opinion Extractionand Semantic Classification of Product Reviews.In Proc.
of the 12th International WWW Confer-ence (pp.
519-528).Kawai, Y., Kumamoto, T. and Tanaka, K. 2007.
FairNews Reader: Recommending news articles withdifferent sentiments based on user preference.
InProceedings of Knowledge-Based Intelligent In-formation and Engineering Systems (KES), No.4692 in Lecture Notes in Computer Science (pp.612?622).Kim, S.-M. and Hovy, E. 2004.
Determining the Sen-timent of Opinions.
In Proc.
of the 20th ICCL (pp.1367-1373).Ku, L.-W. and Chen, H.-H. 2007.
Mining Opinionsfrom the Web: Beyond Relevance Retrieval.
Jour-nal of American Society for Information Scienceand Technology, Special Issue on Mining Web Re-sources for Enhancing Information Retrieval,58(12), 1838-1850.Lafferty, J., McCallum, A. and Pereira, F. 2001.
Con-ditional Random Fields: Probabilistic Models forSegmenting and Labeling Sequence Data, In Proc.of ICML (pp.282-289).Pang, B., Lee, L. and Vaithyanathan, S. 2002.
Thumbsup?
Sentiment Classification Using MachineLearning Techniques.
In Proc.
of the 2002 Confer-ence on EMNLP (pp.
79-86).Riloff, E. and Wiebe, J.
2003.
Learning ExtractionPatterns for Subjective Expressions.
In Proc.
of the2003 Conference on EMNLP (pp.
105-112).Seki, Y., Evans, D. K., Ku, L.-W., Sun, L., Chen, H.-H.and Kando, N. 2008.
Overview of MultilingualOpinion Analysis Task at NTCIR-7.
In Proceed-ings of the 7th NTCIR Workshop Meeting onEvaluation of Information Access Technologies:Information Retrieval, Question Answering, andCross-Lingual Information Access.Somasundaran, S., Ruppenhofer, J. and Wiebe, J.2007.
Detecting arguing and sentiment in meetings.Proceedings of the SIGdial Workshop on Dis-course and Dialogue, 2007.8.6Takamura, H., Inui, T. and Okumura, M. 2005.
Ex-tracting Semantic Orientations of Words UsingSpin Model.
In Proc.
of the 43rd Annual Meetingof the ACL (pp.
133-140).Tzeng, H. and Chen, K.-J.
2002.
Design of ChineseMorphological Analyzer.
In Proc.
of the 1stSIGHAN Workshop on Chinese Language Process-ing, vol.18, 1-7.Wiebe, J.
2000.
Learning Subjective Adjectives fromCorpora.
In Proc.
of the 17th National Conferenceon AAAI and Twelfth Conference on IAAI (pp.
735-740).1269
