A Trigger Language Model-based IR SystemZHANG Jun-lin   SUN Le   QU Wei-min   SUN Yu-fangOpen System & Chinese Information Processing CenterInstitute of Software, The Chinese Academy of SciencesP.O.BOX 8718,Beijing 100080junlin01@iscas.cnAbstractLanguage model based IR system proposed inrecent 5 years has introduced the languagemodel approach in the speech recognitionarea into the IR community and improves theperformance of the IR system effectively.However, the assumption that all the indexedwords are irrelative behind the method is notthe truth.
Though statistical MT approachalleviates the situation by taking thesynonymy factor into account, it never helpsto judge the different meanings of the sameword in varied context.
In this paper wepropose the trigger language model based IRsystem to resolve the problem.
Firstly wecompute the mutual information of the wordsfrom training corpus and then design thealgorithm to get the triggered words of thequery in order to fix down the topic of querymore clearly.
We introduce the relativeparameters into the document language modelto form the trigger language model based IRsystem.
Experiments show that theperformance of trigger language model basedIR system has been improved greatly.
Theprecision of trigger language model increased12% and recall increased nearly 10.8%compared with Ponte language modelmethod.1 IntroductionUsing language models for informationretrieval has been studied extensivelyrecently(Jin et al2002 Lafferty and Zhai 2001Srikanth and Srihari 2002  Lavrenko and Croft2001 Liu and Croft 2002).
The basic idea is tocompute the conditional probability P(Q|D), i.e.the probability of generating a query Q given theobservation of a document D. Several differentmethods have been applied to compute thisconditional probability.
In most approaches, thecomputation is conceptually decomposed intotwo distinct steps: (1) Estimating a documentlanguage model; (2) Computing the querylikelihood using the estimated document modelbased on some query model.
For example, Ponteand Croft emphasized the first step, and usedseveral heuristics to smooth the MaximumLikelihood of the document language model, andassumed that the query is generated under amultivariate Bernoulli model (Ponte and Croft1998).
The BBN method (Miller et al1999)emphasized the second step and used a two-statehidden Markov model as the basis for generatingqueries, which, in effect, is to smooth the MLEwith linear interpolation, a strategy also adoptedin Hiemstra and Kraaij (Hiemstra and  Kraaij1999).
In Zhai and Lafferty (Zhai and  Lafferty2001), it has been found that the retrievalperformance is affected by both the estimationaccuracy of document language models and theappropriate modeling of the query, and a twostage smoothing method was suggested toexplicitly address these two distinct steps.It?s not hard to see that the unigramlanguage model IR method contains thefollowing assumption: Each word appearing inthe document set and query has nothing to dowith any other word.
Obviously this assumptionis not true in reality.
Though statistical MTapproach (Berger and  Lafferty 1999 ) alleviatesthe situation by taking the synonymy factor intoaccount, it never helps to judge the differentmeanings of the same word in varied context.
Inthis paper we propose the trigger language modelbased IR system to resolve the problem.
Thoughthe basic idea of using the triggered words toimprove the performance of language model wasproposed by Raymond almost 10 years ago(Raymond et al1993), Our method adopts adifferent approach for other objectivity in the IRfield.
Firstly we compute the mutual informationof the words from training corpus and thendesign the algorithm to get the triggered words ofthe query in order to fix down the topic of querymore clearly.
We introduce the relativeparameters into the document language model toform the trigger language model based IR system.Experiments show that the performance of triggerlanguage model based IR system has beenimproved greatly.In what follows, Section 2 describes triggerlanguage model based IR system in detail.Section 3 is our evaluation about the model.Finally, Section 4 summarizes the work in thispaper.2 Trigger Language Model based IRSystem2.1 Inter-relationship of Indexing WordsIn order to find out the inter-relationship ofwords in some specific context, we consider theco-occurring times of different words withinfixed sized text window of the document.
Whenthe co-occurring time is large enough, we thinkthat relationship is meaningful.
MutualInformation is a common tool to be applied underthis situation.
So we compute the mutualinformation as following:)()()1(),,()()()1(),,(),(bawwwbawbwawwwbabawNwNLNLwwNNwNNwNLNLwwNww????=???????????????????=?
(1)where  denotes the size of the vocabulary,is the co-occurring times ofword  and  within   sized windowin training set.
is the count of the wordappearing in the training set and  isthe count of word  appearing in the trainingset.wN, wb L ),( a wwNawawbw(NwL)awbw)( bwNWe use the corpus provided by IR task ofNTCIR2 (NTCIR 2002) as the training set tocompute the mutual information of words.
Thiscorpus contains nearly 100 thousands newsarticles encoding in BIG5 charset.
We think themutual information which is larger than 25 ismeaningful.
Considering the stop words indocument or query are useless to represent thecontent, we remove 200 highest frequent wordsfrom the document before computation.
Table 1shows some examples with higher mutualinformation.?
?(test)?
?
?
(alphabet):1895??(rail):1353?
?
(delimitation):758?
?
?
?(windtunnel):473???(meter):421??
(test paper):403?
?(missile)?
?
?
?(antiaircraft):1063??(develop):708?
??
(long-range):472???(anti-tank):354??(bribe)?
?
(tax dodging):3462????(jobbery):2603????(FBI):1041???(voter):730??(zhanjiang):478???(Utah):427?
?
?(truculency)????(scrutator):710?
?
?
?
(long-rangemissile):497????(terrorism):457?
?
(biochemistry):390??(equipoise):327??(plague):334???
(Bagdad):325Table 1.
Examples of Mutual Information2.2 Algorithm of Triggered Words byQueryGenerally speaking, a word alwaysrepresents many different meanings and its exactmeaning adopted in specific topic can bedetermined by the co-occurring words in itscontext.
Different meaning of a word often leadto the different vocabulary set of related word.In order to find out the exact meaning of thewords contained by the query in IR system, wedesign the algorithm to compute the triggeredvocabularies of query.
It is just these triggeredwords that show the exact meaning of the wordsin query in some specific context and help fixdown the topic of query more clearly.
The basicidea behind the algorithm is as following: Bycomputing the mutual information, we can derivethe relative words of a query word.
All thesewords mean the semantically related vocabulariesof the query word under different contexts.
Wepropose that if the intersection of the derivedrelated words of different words in query is notnull, the words in the intersection is useful tojudge the exact meaning of the words in query.At the same time, the more times an intersectionword appears in related vocabulary set ofdifferent query word, the higher the weight ofthis word to fix down the topic of the query is.
Sowe design the following algorithm to computethe triggered vocabulary set of query:Algorithm 1:Triggered vocabularies by queryInput: Vocabulary set I of query word and itsco-occurring words after removing the stopwords in the query.
},......,,......,,,{ 2211 ><><><><= nnii SqSqSqSqIOutput: Triggered vocabulary set T.Setp 1.
Initialize the set ?=T .Setp 2. for(i =2;i<=n;i++){for(j=1;j<= ;j++) inC{2.1get the differentcombination },......,,,{ ,,2,2,1,1, ><><><= ijijjjjjj SqSqSqLiwhich contains  elements from set I ;2.2 if any vocabulary set )1(, ikS kj <=<in  contains no element, then we turn to 2.4 ,otherwise we turn to 2.3;jL2.3 Compute the intersection  of allvocabulary set  in .HerejiT ,< mw)1(, ikS kj <=<,......,, 221 ><> wjL>i },,{ 1, <=ji wT ???
,where2log iw =?
, ( iw <==<1 ).
w?
is theword  weight decided by the length of ; jLjiTT ,?=w?q,,{ 11 ,,......, 22 <>>< mww ???+?
)|( jij dqp><><==otherwwdqqji)>m)( icsq<wm,,,,{ 2211 ??},....
)(Qli q?2.4 T , adopting the higher wordweight during the merging process;}}Step 3.
Output the triggered vocabulary set T ;2.3 Similarity Computation of Query andDocumentWe use the similar strategy with Pontelanguage model method (Ponte and Croft 1998)to compute the similarity between the query andthe document.
That is, we firstly construct thesimple language model according to thestatistical information of vocabulary and thencompute the generative probability of the query.The difference is that the trigger language modelmethod takes the context information of a wordinto account.
So we compute the triggered wordsset of query  according to algorithm 1.Thisway we get the triggered vocabulary set}><= mq wT .This set contains the words triggered by queryand it is these triggered words that determine theexact meaning of the vocabularies in queryamong the several optional choices.
This helpsfix down the topic of query more clearly.Introducing the triggered words factor into thedocument language model, we can form thetrigger language model based informationretrieval system.The similarity of query and document canbe computed as following:?
?= ==)(1)(1()|(QlidljdtfCMQP   (2)???????
?= Tddqdqp jjijji0}),......()(1)|( ?
(3)(1) ,......,{ 21 qqqQ =  denotes queryand is the length of the query;  )(Ql(2) denotes the trigger language model ofdocument ;dMd(3) denotes adocument in document set and is the lengthof the document;},....,....,{ )(21 dlj ddddd =(l )d(4))()(dldfC jj =jdis the weight parameter ofwords  in a document.
Here  meansthe account of the words  appearing in thedocument.
)( jdfjd(5)  denotes the probability ofbeing triggered by the document word .When2 words are same, the probability equals 1.
Ifthey are different and the word  belongs tothe triggered vocabulary set of query, theprobability equals the according parameter in the,otherwise the probability is 0?
)|( ji dqp iqjdjdqT(6)csqtf i )()iqiqis used for data smoothing; heredenotes times of query wordappearing in document set and   denotes thetotal length of documents which contains theword .
(tf iqcs3 Experiment Results3.1 CorpusThe corpus we used to evaluate theperformance of our proposed trigger languagemodel IR system is the document set offered bythe traditional Chinese Document set of NTCIR3for the IR task.
The corpus consists of 381681news articles from Hong Kong and Taiwan withvaried topics.
After the word segmentation, thedocument set contains 150700953 words.
Amongthem,127519 different words are the entries ofthe vocabulary.
The average length of eachdocument is 394.The 50 queries offered by NTCIR3 IR taskare contained in a XML file and each queryconsists of following elements: TopicNumber(NUM),Topic Title(TITLE),Topicquestion(DESC),Topic Narrative(NARR) andTopic Concepts(CONC).
In order to make iteaser to compare the performance of the differentIR methods, we adopt the Topic Question field asthe query and regard the top 1000 retrievaldocuments as the standard result of theexperiment.3.2 Analysis of Experiment ResultsWe design 3 relative experiments toevaluate the trigger language model IR method:vector space model, Ponte language model basedmethod and the trigger language model approach.Precision and recall are two main evaluationparameters.
As for the trigger model IR method,the optimal size of the text window is 20 contentwords and the mutual information over 25 isregarded as the meaningful information.Experiment results can be seen in table 2.The data of column %  in table 2 showsthe performance improvement of Ponte languagemodel compared with vector space model.
Thedata tells us that the precision of language modelbased method increased 10% and recall increasednearly 13.7%.
The data of column %?
in table2 shows the performance improvement of triggerlanguage model compared with Ponte languagemodel method.
From the data we can see that theprecision of trigger language model increased12% and recall increased nearly 10.8%.
We candraw the conclusion that the trigger languagemodel has improved the performance greatly.The performance comparison can be showedmore clearly in figure 1.1?200.10.20.30.40.50.60.70.80 0.2 0.4 0.6 0.8 1RecallPrecisiontfidfPonteLanguageModelTriggerLanguageModelFigure 1.
Precision-Recall of 3 methodsTfidf Lm(ponte) Trigger lm % 1?
%  2?Relevant: 3284 3284 3284 ----------Rel.ret: 1843 2096 2322 13.7 10.8Precision:0.
000.
100.
200.
300.
400.
500.
600.
700.
800.
901.
00Avg:0.
60160.
46070.
38120.
33360.
27380.
24950.
21790.
15660.
09780.
03890.
00190.23770.61090.48440.41230.37570.32550.28540.23130.17160.10410.04740.00250.26100.
75370.
53140.
45410.
40940.
36480.
32370.
25380.
20110.
11530.
04350.
00550.
2933+2+5+8+12+18+14+6+9+6+21+31+10+23+10+10+9+12+13+9+17+10-8+120+12Table 2.
Experiment results4  ConclusionLanguage model based IR system proposedin recent 5 years has introduced the languagemodel approach in the speech recognition areainto the IR community and improves theperformance of the IR system effectively.However, the assumption that all the indexedwords are irrelative behind the method is not thetruth.
Though statistical MT approach alleviatesthe situation by taking the synonymy factor intoaccount, it never helps to judge the differentmeanings of the same word in varied context.
Inthis paper we propose the trigger language modelbased IR system to resolve the problem.
.
Firstlywe compute the mutual information of the wordsfrom training corpus and then design thealgorithm to get the triggered words of the queryin order to fix down the topic of query moreclearly.
We introduce the relative parameters intothe document language model to form the triggerlanguage model based IR system.
Experimentsshow that the performance of trigger languagemodel based IR system has been improvedgreatly.AcknowledgementThis work is supported by Beijing New Star Planof Technology & Science(NO.H020820790130)and the National Science Fund of China undercontact 60203007.ReferencesBerger A. and  Lafferty J.
(1999).
Informationretrieval as statistical translation.
In Proceedings ofSIGIR ?99.
pp.
222-229.Jin R., Hauptmann A.G.  and Zhai C.(2002) TitleLanguage Model for Information Retrieval.
InProceedings of the 2002 ACM SIGIR Conferenceon Research and Development in InformationRetrieval.Hiemstra D. and  Kraaij W. (1999), Twenty-One atTREC-7: ad-hoc and cross-language track, InProceedings of the seventh Text RetrievalConference TREC-7, NIST Special Publication500-242, pages 227-238, 1999.Lafferty J. and Zhai.
C. (2001) Document languagemodels,query models and risk minimization forinformation retrieval.
In Proceedings of the 24thACM SIGIR Conference,pp.111-119.Lavrenko,V., and Croft,W.B.
(2001) .Relevance basedlanguage models.
In Proceedings of the 24th ACMSIGIR Conference.pp.120-127.Liu,X.
and Croft,W.B.
(2002).Passage RetrievalBased on Language Models.
In Proceedings of the11th  International Conference on Information andKnowledge Management.
Pp.375-382Miller D.,  Leek T.  and Schwartz  R. M. (1999).A hidden Markov model information retrievalsystem.
Proceedings of SIGIR?1999, pp.
214-222.
.NTCIR Workshop(research.nii.ac.jp/ntcir/index-en.html)Ponte J. and Croft W. B.
(1998).
A languagemodeling approach to information retrieval.
InProceedings of SIGIR?
1998, pp.
275-281.Raymond Lau, Roni Rosenfeld and SalimRoukos(1993) Trigger-based Language Models: AMaximum Entropy Apporach.
Proceedings ICASSP'93, Minneapolis, MN, pp.
II-45 - II-48.Srikanth M. and  Srihari.
R(2002).
BitermLanguage Models for Document Retrieval.
InProceedings of the 2002 ACM SIGIR Conferenceon Research and Development in InformationRetrieval.Zhai C. and Lafferty J.(2001).
A study of smoothingmethods for language models applied to ad hocinformation retrieval.
In Proceeding of SIGIR?01,2001, pp.
334-342.
