Proceedings of the 12th Conference of the European Chapter of the ACL, pages 487?495,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsImprovements in Analogical Learning:Application to Translating multi-Terms of the Medical DomainPhilippe LanglaisDIROUniv.
of Montreal, Canadafelipe@iro.umontreal.caFranc?ois Yvon and Pierre ZweigenbaumLIMSI-CNRSUniv.
Paris-Sud XI, France{yvon,pz}@limsi.frAbstractHandling terminology is an importantmatter in a translation workflow.
However,current Machine Translation (MT) sys-tems do not yet propose anything proactiveupon tools which assist in managing termi-nological databases.
In this work, we in-vestigate several enhancements to analog-ical learning and test our implementationon translating medical terms.
We showthat the analogical engine works equallywell when translating from and into a mor-phologically rich language, or when deal-ing with language pairs written in differ-ent scripts.
Combining it with a phrase-based statistical engine leads to significantimprovements.1 IntroductionIf machine translation is to meet commercialneeds, it must offer a sensible approach to trans-lating terms.
Currently, MT systems offer at bestdatabase management tools which allow a human(typically a translator, a terminologist or even thevendor of the system) to specify bilingual ter-minological entries.
More advanced tools aremeant to identify inconsistencies in terminologicaltranslations and might prove useful in controlled-language situations (Itagaki et al, 2007).One approach to translate terms consists in us-ing a domain-specific parallel corpus with stan-dard alignment techniques (Brown et al, 1993) tomine new translations.
Massive amounts of par-allel data are certainly available in several pairsof languages for domains such as parliament de-bates or the like.
However, having at our disposala domain-specific (e.g.
computer science) bitextwith an adequate coverage is another issue.
Onemight argue that domain-specific comparable (orperhaps unrelated) corpora are easier to acquire,in which case context-vector techniques (Rapp,1995; Fung and McKeown, 1997) can be usedto identify the translation of terms.
We certainlyagree with that point of view to a certain extent,but as discussed by Morin et al (2007), for manyspecific domains and pairs of languages, such re-sources simply do not exist.
Furthermore, the taskof translation identification is more difficult anderror-prone.Analogical learning has recently regained someinterest in the NLP community.
Lepage and De-noual (2005) proposed a machine translation sys-tem entirely based on the concept of formal anal-ogy, that is, analogy on forms.
Stroppa andYvon (2005) applied analogical learning to sev-eral morphological tasks also involving analogieson words.
Langlais and Patry (2007) applied it tothe task of translating unknown words in severalEuropean languages, an idea investigated as wellby Denoual (2007) for a Japanese to English trans-lation task.In this study, we improve the state-of-the-art ofanalogical learning by (i) proposing a simple yeteffective implementation of an analogical solver;(ii) proposing an efficient solution to the search is-sue embedded in analogical learning, (iii) investi-gating whether a classifier can be trained to recog-nize bad candidates produced by analogical learn-ing.
We evaluate our analogical engine on the taskof translating terms of the medical domain; a do-main well-known for its tendency to create newwords, many of which being complex lexical con-structions.
Our experiments involve five languagepairs, including languages with very different mor-phological systems.487In the remainder of this paper, we first presentin Section 2 the principle of analogical learn-ing.
Practical issues in analogical learning arediscussed in Section 3 along with our solutions.In Section 4, we report on experiments we con-ducted with our analogical device.
We concludethis study and discuss future work in Section 5.2 Analogical Learning2.1 DefinitionsA proportional analogy, or analogy for short, is arelation between four items noted [x : y = z : t ]which reads as ?x is to y as z is to t?.
Among pro-portional analogies, we distinguish formal analo-gies, that is, those we can identify at a graphemiclevel, such as [adrenergic beta-agonists, adren-ergic beta-antagonists, adrenergic alpha-agonists,adrenergic alpha-antagonists].Formal analogies can be defined in terms offactorizations1.
Let x be a string over an alpha-bet ?, a factorization of x, noted fx, is a se-quence of n factors fx = (f1x, .
.
.
, fnx ), such thatx = f1x  f2x  .
.
.
fnx , where  denotes theconcatenation operator.
After (Stroppa and Yvon,2005) we thus define a formal analogy as:Definition 1 ?
(x, y, z, t) ?
?
?4, [x : y = z : t] iffthere exist factorizations (fx, fy, fz, ft) ?
(?
?d)4of (x, y, z, t) such that, ?i ?
[1, d], (f iy, fiz) ?
{(f ix, fit ), (fit , fix)}.
The smallest d for which thisdefinition holds is called the degree of the analogy.Intuitively, this definition states that (x, y, z, t)are made up of a common set of alternating sub-strings.
It is routine to check that it captures theexemplar analogy introduced above, based on thefollowing set of factorizations:fx ?
(adrenergic bet, a-agonists)fy ?
(adrenergic bet, a-antagonists)fz ?
(adrenergic alph, a-agonists)ft ?
(adrenergic alph, a-antagonists)As no smaller factorization can be found, the de-gree of this analogy is 2.
In the sequel, we callan analogical equation an analogy where one item(usually the fourth) is missing and we note it [x :y = z : ?
].1Factorizations of strings correspond to segmentations.We keep the former term, to emphasize the genericity of thedefinition, which remains valid for other algebraic structures,for which factorization and segmentation are no longer syno-mymous.2.2 Analogical InferenceLet L = {(i, o) | i ?
I, o ?
O} be a learning setof observations, where I (O) is the set of possibleforms of the input (output) linguistic system understudy.
We denote I(u) (O(u)) the projection of uinto the input (output) space; that is, if u = (i, o),then I(u) ?
i and O(u) ?
o.
For an incompleteobservation u = (i, ?
), the inference procedure is:1. building EI(u) = {(x, y, z) ?
L3 | [I(x) :I(y) = I(z) : I(u) ]}, the set of input tripletsthat define an analogy with I(u) .2. building EO(u) = {o ?
O | ?
(x, y, z) ?EI(u) s.t.
[O(x) : O(y) = O(z) : o]} the setof solutions to the equations obtained by pro-jecting the triplets of EI(u) into the outputspace.3.
selecting candidates among EO(u).In the sequel, we distinguish the generatorwhich implements the first two steps, from the se-lector which implements step 3.To give an example, assume L containsthe following entries: (beeta-agonistit, adren-ergic beta-agonists), (beetasalpaajat, adrenergicbeta-antagonists) and (alfa-agonistit, adrener-gic alpha-agonists).
We might translate theFinnish term alfasalpaajat into the English termadrenergic alpha-antagonists by 1) identifyingthe input triplet: (beeta-agonistit, beetasalpaa-jat, alfa-agonistit) ; 2) projecting it into the equa-tion [adrenergic beta-agonists : adrenergic beta-antagonists = adrenergic alpha-agonists : ?
]; andsolving it: adrenergic alpha-antagonists is one ofits solutions.During inference, analogies are recognized in-dependently in the input and the output space, andnothing pre-establishes which subpart of one in-put form corresponds to which subpart of the out-put one.
This ?knowledge?
is passively capturedthanks to the inductive bias of the learning strat-egy (an analogy in the input space corresponds toone in the output space).
Also worth mentioning,this procedure does not rely on any pre-defined no-tion of word.
This might come at an advantage forlanguages that are hard to segment (Lepage andLardilleux, 2007).3 Practical issuesEach step of analogical learning, that is, search-ing for input triplets, solving output equations and488selecting good candidates involves some practicalissues.
Since searching for input triplets might in-volve the need for solving (input) equations, wediscuss the solver first.3.1 The solverLepage (1998) proposed an algorithm for solvingan analogical equation [x : y = z : ?
].
Analignment between x and y and between x and zis first computed (by edit-distance) as illustratedin Figure 1.
Then, the three strings are synchro-nized using x as a backbone of the synchroniza-tion.
The algorithm can be seen as a deterministicfinite-state machine where a state is defined by thetwo edit-operations being visited in the two tables.This is schematized by the two cursors in the fig-ure.
Two actions are allowed: copy one symbolfrom y or z into the solution and move one or bothcursors.x: r e a d e r x: r e a d e ry: r e a d a b l e z: d o e r4 4Figure 1: Illustration of the synchronization doneby the solver described in (Lepage, 1998).There are two things to realize with this algo-rithm.
First, since several (minimal-cost) align-ments can be found between two strings, severalsynchronizations are typically carried out whilesolving an equation, leading to (possibly many)different solutions.
Indeed, in adverse situations,an exponential number of synchronizations willhave to be computed.
Second, the algorithm failsto deliver an expected form in a rather frequentsituation where two identical symbols align fortu-itously in two strings.
This is for instance the casein our running example where the symbol d indoer aligns to the one in reader, which puzzles thesynchronization.
Indeed, dabloe is the only formproposed to [reader : readable = doer : ?
], whilethe expected one is doable.
The algorithm wouldhave no problem, however, to produce the formwritable out of the equation [reader : readable =writer : ?
].Yvon et al (2004) proposed an analogicalsolver which is not exposed to the latter prob-lem.
It consists in building a finite state transducerwhich generates the solutions to [x : y = z : ?
]while recognizing the form x.Theorem 1 t is a solution to [x : y = z : ?]
ifft belongs to {y ?
z}\x.shuffle and complement are two rational op-erations.
The shuffle of two strings w andv, noted w ?
v, is the regular language con-taining the strings obtained by selecting (with-out replacement) alternatively in w and v, se-quences of characters in a left-to-right man-ner.
For instance, spondyondontilalgiatis andondspondonylaltitisgia are two strings belong-ing to spondylalgia ?
ondontitis).
The comple-mentary set of w with respect to v, noted w\v, isthe set of strings formed by removing from w, ina left-to-right manner, the symbols in v. For in-stance, spondylitis and spydoniltis are belong-ing to spondyondontilalgiatis \ ondontalgia.Our implementation of the two rational operationsare sketched in Algorithm 1.Because the shuffle of two strings may con-tain an exponential number of elements with re-spect to the length of those strings, building suchan automaton may face combinatorial problems.Our solution simply consists in randomly sam-pling strings in the shuffle set.
Our solver, depictedin Algorithm 2, is thus controlled by a samplingsize s, the impact of which is illustrated in Ta-ble 1.
By increasing s, the solver generates more(mostly spurious) solutions, but also increases therelative frequency with which the expected outputis generated.
In practice, provided a large enoughsampling size,2 the expected form very often ap-pears among the most frequent ones.s nb (solution,frequency)10 11 (doable,7) (dabloe,3) (adbloe,3)102 22 (doable,28) (dabloe,21) (abldoe,21)103 29 (doable,333) (dabloe,196) (abldoe,164)Table 1: The 3-most frequent solutions generatedby our solver, for different sampling sizes s, forthe equation [reader : readable = doer : ?
].
nbindicates the number of (different) solutions gen-erated.
According to our definition, there are 32distinct solutions to this equation.
Note that oursolver has no problem producing doable.3.2 Searching for input tripletsA brute-force approach to identifying the inputtriplets that define an analogy with the incom-plete observation u = (t, ?)
consists in enumerat-ing triplets in the input space and checking for an2We used s = 2 000 in this study.489function shuffle(y,z)Input: ?y, z?
two formsOutput: a random word in y ?
zif y =  thenreturn zelsen?
rand(1,|y|)return y[1:n] .
shuffle(z,y[n+1:])function complementary(m,x,r,s)Input: m ?
y ?
z, xOutput: the set m \ xif (m = ) thenif (x = ) thens?
s ?
relsecomplementary(m[2:],x,r.m[1],s)if m[1] = x[1] thencomplementary(m[2:],x[2:],r,s)Algorithm 1: Simulation of the two rational op-erations required by the solver.
x[a:b] denotes thesequence of symbols x starting from index a toindex b inclusive.
x[a:] denotes the suffix of xstarting at index a.analogical relation with t. This amounts to checko(|I|3) analogies, which is manageable for toyproblems only.
Instead, Langlais and Patry (2007)proposed to solve analogical equations [y : x = t :? ]
for some pairs ?x, y?
belonging to the neighbor-hood3 of I(u), denotedN (t).
Those solutions thatbelong to the input space are the z-forms retained;EI(u) = { ?x, y, z?
: x ?
N (t) , y ?
N (x),z ?
[y : x = t : ? ]
?
I }This strategy (hereafter named LP) directly fol-lows from a symmetrical property of an analogy([x : y = z : t ] ?
[y : x = t : z]), and reducesthe search procedure to the resolution of a numberof analogical equations which is quadratic with thenumber of pairs ?x, y?
sampled.We found this strategy to be of little use forinput spaces larger than a few tens of thousandsforms.
To solve this problem, we exploit a prop-erty on symbol counts that an analogical relationmust fulfill (Lepage, 1998):[x : y = z : t ]?
|x|c + |t|c = |y|c + |z|c ?c ?
A3The authors proposed to sample x and y among the clos-est forms in terms of edit-distance to I(u).function solver(?x, y, z?, s)Input: ?x, y, z?, a triplet, s the sampling sizeOutput: a set of solutions to [x : y = z : ?
]sol?
?for i?
1 to s do?a, b?
?
odd(rand(0, 1))?
?z, y?
: ?y, z?m ?
shuffle(a,b )c?
complementary(m,x,,{})sol?
sol ?
creturn solAlgorithm 2: A Stroppa&Yvon flavored solver.rand(a, b) returns a random integer between aand b (included).
The ternary operator ?
: is tobe understood as in the C language.where A is the alphabet on which the forms arebuilt, and |x|c stands for the number of occur-rences of symbol c in x.Our search strategy (named TC) begins by se-lecting an x-form in the input space.
This en-forces a set of necessary constraints on the countsof characters that any two forms y and z must sat-isfy for [x : y = z : t ] to be true.
By consideringall forms x in turn,4 we collect a set of candidatetriplets for t. A verification of those that definewith t an analogy must then be carried out.
For-mally, we built:EI(u) = { ?x, y, z?
: x ?
I,?y, z?
?
C(?x, t?
),[x : y = z : t ] }where C(?x, t?)
denotes the set of pairs ?y, z?which satisfy the count property.This strategy will only work if (i) the numberof quadruplets to check is much smaller than thenumber of triplets we can form in the input space(which happens to be the case in practice), andif (ii) we can efficiently identify the pairs ?y, z?that satisfy a set of constraints on character counts.To this end, we proposed in (Langlais and Yvon,2008) to organize the input space into a data struc-ture which supports efficient runtime retrieval.3.3 The selectorStep 3 of analogical learning consists in selectingone or several solutions from the set of candidateforms produced by the generator.
We trained ina supervised manner a binary classifier to distin-guish good translation candidates (as defined by4Anagram forms do not have to be considered separately.490a reference) from spurious ones.
We applied tothis end the voted-perceptron algorithm describedby Freund and Schapire (1999).
Online voted-perceptrons have been reported to work well in anumber of NLP tasks (Collins, 2002; Liang et al,2006).
Training such a classifier is mainly a matterof feature engineering.
An example e is a pair ofsource-target analogical relations (r, r?)
identifiedby the generator, and which elects t?
as a transla-tion for the term t:e ?
(r, r?)
?
([x : y = z : t], [x?
: y?
= z?
: t?
])where x?, y?, and z?
are respectively the projectionsof the source terms x, y and z.
We investigatedmany features including (i) the degree of r and r?,(ii) the frequency with which a form is generated,5(iii) length ratios between t and t?, (iv) likelihoodsscores (min, max, avg.)
computed by a character-based n-gram model trained on a large general cor-pus (without overlap to DEV or TRAIN), etc.4 Experiments4.1 Calibrating the engineWe compared the two aforementioned searchingstrategies on a task of identifying triplets in aninput space of French words for 1 000 randomlyselected test words.
We considered input spacesof various sizes.
The results are reported in Ta-ble 2.
TC clearly outperforms LP by systemati-cally identifying more triplets in much less time.For the largest input space of 84 000 forms, TCcould identify an average of 746 triplets for 946test words in 1.2 seconds, while the best compro-mise we could settle with LP allows the identifi-cation of 56 triplets on average for 889 words in6.3 seconds on average.
Note that in this exper-iment, LP was calibrated for each input space sothat the best compromise between recall (%s) andspeed could be found.
Reducing the size of theneighborhood in LP improves computation time,but significantly affects recall.
In the following,we only consider the TC search strategy.4.2 Experimental ProtocolDatasets The data we used in this study comesfrom the Medical Subject Headings (MeSH) the-saurus.
This thesaurus is used by the US NationalLibrary of Medicine to index the biomedical sci-5A form t?
may be generated thanks to many examples.s %s (s) s %s (s) s %s (s)TC 34 83.1 0.2 261 94.1 0.5 746 96.4 1.2LP 17 71.7 7.4 46 85.0 7.6 56 88.9 6.3|I| 20 000 50 000 84 076Table 2: Average number s of input analogiesfound over 1 000 test words as a function of thesize of the input space.
%s stands for the percent-age of source forms for which (at least) one sourcetriplet is found; and (s) indicates the average time(counted in seconds) to treat one form.entific literature in the MEDLINE database.6 Itspreferred terms are called ?Main Headings?.
Wecollected pairs of source and target Main Head-ings (TTY = ?MH?)
with the same MeSH identi-fiers (SDUI).We considered five language pairs with threerelatively close European languages (English-French, English-Spanish and English-Swedish), amore distant one (English-Finnish) and one pairinvolving different scripts (English-Russian).7The material was split in three randomly se-lected parts, so that the development and test ma-terial contain exactly 1 000 terms each.
The char-acteristics of this material are reported in Table 3.For the Finnish-English and Swedish-English lan-guage pairs, the ratio of uni-terms in the Foreignlanguage (uf%) is twice the ratio of uni-terms inthe English counterpart.
This is simply due tothe agglutinative nature of these two languages.For instance, according to MeSH, the Englishmulti-term speech articulation tests correspondsto the Finnish uni-term a?a?nta?miskokeet and to theSwedish one artikulationstester.
The ratio of out-of-vocabulary forms (space-separated words un-seen in TRAIN) in the TEST material is ratherhigh: between 36% and 68% for all Foreign-to-English translation directions, but Finnish-to-English, where surprisingly, only 6% of the wordforms are unknown.Evaluation metrics For each experimental con-dition, we compute the following measures:Coverage the fraction of input words for whichthe system can generate translations.
If Nt wordsreceive translations among N , coverage is Nt/N .6The MeSH thesaurus and its translations are included inthe UMLS Metathesaurus.7Russian MeSH is normally written in Cyrillic, but someterms are simply English terms written in uppercase Latinscript (e.g., ACHROMOBACTER for English Achromobac-ter).
We removed those terms.491TRAIN TEST DEV TESTf nb uf% ue% nb uf% uf% oov%FI 19 787 63.7 33.7 1 000 64.2 64.0 5.7FR 17 230 29.8 29.3 1 000 30.8 28.3 36.3RU 21 407 38.6 38.6 1 000 38.5 40.2 44.4SP 19 021 31.1 31.1 1 000 31.7 33.3 36.6SW 17 090 67.9 32.5 1 000 67.4 67.9 68.4Table 3: Main characteristics of our datasets.
nbindicates the number of pairs of terms in a bi-text, uf% (ue%) stands for the percentage of uni-terms in the Foreign (English) part.
oov% indi-cates the percentage of out-of-vocabulary forms(space-separated forms of TEST unseen in TRAIN).Precision among the Nt words for which thesystem proposes an answer, precision is the pro-portion of those for which a correct translation isoutput.
Depending on the number of output trans-lations k that one is willing to examine, a correcttranslation will be output for Nk input words.
Pre-cision at rank k is thus defined as Pk = Nk/Nt.Recall is the proportion of the N input wordsfor which a correct translation is output.
Recall atrank k is defined as Rk = Nk/N .In all our experiments, candidate translationsare sorted in decreasing order of frequency withwhich they were generated.4.3 The generatorThe performances of the generator on the 10translation sessions are reported in Table 4.The coverage of the generator varies between38.5% (French-to-English) and 47.1% (English-to-Finnish), which is rather low.
In most cases, thesilence of the generator is due to a failure to iden-tify analogies in the input space (step 1).
The lastcolumn of Table 4 reports the maximum recall wecan obtain if we consider all the candidates outputby the generator.
The relative accuracy of the gen-erator, expressed by the ratio ofR?
to cov, rangesfrom 64.3% (English-French) to 79.1% (Spanish-to-English), for an average value of 73.8% overall translation directions.
This roughly means thatone fourth of the test terms with at least one solu-tion do not contain the reference.Overall, we conclude that analogical learningoffers comparable performances for all transla-tion directions, although some fluctuations are ob-served.
We do not observe that the approach isaffected by language pairs which do not share theCov P1 R1 P100 R100 R??
FI 47.1 31.6 14.9 57.7 27.2 31.9FR 41.2 35.4 14.6 60.4 24.9 26.5RU 46.2 40.5 18.7 69.9 32.3 34.8SP 47.0 41.5 19.5 69.1 32.5 35.9SW 42.8 36.0 15.4 66.8 28.6 31.9?
FI 44.8 36.6 16.4 66.7 29.9 33.2FR 38.5 47.0 18.1 69.9 26.9 29.4RU 42.1 49.4 20.8 70.3 29.6 32.3SP 42.6 47.7 20.3 75.1 32.0 33.7SW 44.6 40.8 18.2 69.5 31.0 32.9Table 4: Main characteristics of the generator, as afunction of the translation directions (TEST).same script (Russian/English).
The best (worse)case (as far as R?
is concerned) corresponds totranslating into Spanish (French).Admittedly, the largest recall andR?
values re-ported in Table 4 are disappointing.
Clearly, foranalogical learning to work efficiently, enough lin-guistic phenomena must be attested in the TRAINmaterial.
To illustrate this, we collected for theSpanish-English language pair a set of medicalterms from the Medical Drug Regulatory Activi-ties thesaurus (MedDRA) which contains roughlythree times more terms than the Spanish-Englishmaterial used in this study.
This extra material al-lows to raise the coverage to 73.4% (Spanish toEnglish) and 79.7% (English to Spanish), an abso-lute improvement of more than 30%.4.4 The selectorWe trained our classifiers on the several millionsof examples generated while translating the devel-opment material.
Since we considered numerousfeature representations in this study, this impliessaving many huge datafiles on disk.
In order tosave some space, we decided to remove forms thatwere generated less than 3 times.8 Each classifierwas trained using 20 epochs.It is important to note that we face a very unbal-anced task.
For instance, for the English to Finnishtask, the generator produces no less than 2.7 mil-lions of examples, among which only 4 150 arepositive ones.
Clearly, classifying all the examplesas negative will achieve a very high classificationaccuracy, but will be of no practical use.
There-fore, we measure the ability of a classifier to iden-8Averaged over all translation directions, this incurs anabsolute reduction of the coverage of 3.4%.492FI?EN FR?EN RU?EN SP?EN SW?ENp r p r p r p r p rargmax-f1 41.3 56.7 46.7 63.9 48.1 65.6 49.2 63.4 43.2 61.0s-best 53.6 61.3 57.5 68.4 61.9 66.7 64.3 70.0 53.1 64.4Table 5: Precision (p) and recall (r) of some classifiers on the TEST material.tify the few positive forms among the set of candi-dates.
We measure precision as the percentage offorms selected by the classifier that are sanctionedby the reference lexicon, and recall as the percent-age of forms selected by the classifier over the to-tal number of sanctioned forms that the classifiercould possibly select.
(Recall that the generatoroften fails to produce oracle forms.
)The performance measured on the TEST mate-rial of the best classifier we monitored on DEVare reported in Table 5 for the Foreign-to-Englishtranslation directions (we made consistent obser-vations on the reverse directions).
For compari-son purposes, we implemented a baseline classi-fier (lines argmax-f1) which selects the most-frequent candidate form.
This is the selectorused as a default in several studies on analogi-cal learning (Lepage and Denoual, 2005; Stroppaand Yvon, 2005).
The baseline identifies between56.7% to 65.6% of the sanctioned forms, at pre-cision rates ranging from 41.3% to 49.2%.
Weobserve for all translation directions that the bestclassifier we trained systematically outperformsthis baseline, both in terms of precision and recall.4.4.1 The overall systemTable 6 shows the overall performance of the ana-logical translation device in terms of precision, re-call and coverage rates as defined in Section 4.2.Overall, our best configuration (the one embed-ding the s-best classifier) translates between19.3% and 22.5% of the test material, with a preci-sion ranging from 50.4% to 63.2%.
This is betterthan the variant which always proposes the mostfrequent generated form (argmax-f1).
Allowingmore answers increases both precision and recall.If we allow up to 10 candidates per source term,the analogical translator translates one fourth ofthe terms (26.1%) with a precision of 70.9%, aver-aged over all translation directions.
The oraclevariant, which looks at the reference for select-ing the good candidates produced by the genera-tor, gives an upper bound of the performance thatcould be obtained with our approach: less thana third of the source terms can be translated cor-rectly.
Recall however that increasing the TRAINmaterial leads to drastic improvements in cover-age.4.5 Comparison with a PB-SMT engineTo put these figures in perspective, we mea-sured the performance of a phrase-based statisti-cal MT (PB-SMT) engine trained to handle thesame translation task.
We trained a phrase tableon TRAIN, using the standard approach.9 How-ever, because of the small training size, and therather huge OOV rate of the translation tasks weaddress, we did not train translation models onword-tokens, but at the character level.
There-fore a phrase is indeed a sequence of charac-ters.
This idea has been successively investigatedin a Catalan-to-Spanish translation task by Vi-lar et al (2007).
We tuned the 8 coefficients ofthe so-called log-linear combination maximizedat decoding time on the first 200 pairs of termsof the DEV corpora.
On the DEV set, BLEUscores10 range from 67.2 (English-to-Finnish) to77.0 (Russian-to-English).Table 7 reports the precision and recall of bothtranslation engines.
Note that because the SMTengine always propose a translation, its precisionequals its recall.
First, we observe that the preci-sion of the SMT engine is not high (between 17%and 31%), which demonstrates the difficulty ofthe task.
The analogical device does better for alltranslation directions (see Table 6), but at a muchlower recall, remaining silent more than half ofthe time.
This suggests that combining both sys-tems could be advantageous.
To verify this, weran a straightforward combination: whenever theanalogical device produces a translation, we pickit; otherwise, the statistical output is considered.The gains of the resulting system over the SMTalone are reported in column ?B.
Averaged over9We used the scripts distributed by Philipp Koehn to trainthe phrase-table, and Pharaoh (Koehn, 2004) for producingthe translations.10We computed BLEU scores at the character level.493FI?EN FR?EN RU?EN SP?EN SW?ENk Pk Rk Pk Rk Pk Rk Pk Rk Pk Rkargmax-f 1 41.3 17.3 46.7 16.8 47.8 18.6 48.7 19.2 43.4 18.110 61.6 25.8 62.8 22.6 61.7 24.0 69.3 27.3 62.1 25.9s-best 1 53.5 20.8 56.9 19.3 58.5 20.3 63.2 22.5 50.4 2110 69.4 27.0 69.0 23.4 71.8 24.9 78.4 27.9 65.7 27.4oracle 1 100 30.5 100 26.3 100 28.5 100 30.6 100 29.5Table 6: Precision and recall at rank 1 and 10 for the Foreign-to-English translation tasks (TEST).all translation directions, BLEU scores increase onTEST from 66.2 to 71.5, that is, an absolute im-provement of 5.3 points.?
EN ?
ENPsmt ?B Psmt ?BFI 20.2 +7.4 21.6 +6.4FR 19.9 +5.3 17.0 +6.0RU 24.1 +3.1 28.0 +6.4SP 22.1 +4.9 26.4 +5.5SW 25.9 +4.2 31.6 +3.2Table 7: Translation performances on TEST.
Psmtstands for the precision and recall of the SMT en-gine.
?B indicates the absolute gain in BLEUscore of the combined system.We noticed a tendency of the statistical engineto produce literal translations; a default the ana-logical device does not show.
For instance, theSpanish term instituciones de atencio?n ambulato-ria is translated word for word by Pharaoh intoinstitutions, atention ambulatory while analogicallearning produces ambulatory care facilities.
Wealso noticed that analogical learning sometimesproduces wrong translations based on morpholog-ical regularities that are applied blindly.
This is,for instance, the case in a Russian/English exam-ple where mouthal manifestations is produced, in-stead of oral manifestations.5 Discussion and future workIn this study, we proposed solutions to practical is-sues involved in analogical learning.
A simple yeteffective implementation of a solver is described.A search strategy is proposed which outperformsthe one described in (Langlais and Patry, 2007).Also, we showed that a classifier trained to se-lect good candidate translations outperforms themost-frequently-generated heuristic used in sev-eral works on analogical learning.Our analogical device was used to translatemedical terms in different language pairs.
Theapproach rates comparably across the 10 transla-tion directions we considered.
In particular, wedo not see a drop in performance when trans-lating into a morphology rich language (such asFinnish), or when translating into languages withdifferent scripts.
Averaged over all translation di-rections, the best variant could translate in first po-sition 21% of the terms with a precision of 57%,while at best, one could translate 30% of the termswith a perfect precision.
We show that the ana-logical translations are of better quality than thoseproduced by a phrase-based engine trained at thecharacter level, albeit with much lower recall.
Astraightforward combination of both approachesled an improvement of 5.3 BLEU points over theSMT alone.
Better SMT performance could beobtained with a system based on morphemes, seefor instance (Toutanova et al, 2008).
However,since lists of morphemes specific to the medicaldomain do not exist for all the languages pairs weconsidered here, unsupervised methods for acquir-ing morphemes would be necessary, which is leftas a future work.
In any case, this comparison ismeaningful, since both the SMT and the analogi-cal device work at the character level.This work opens up several avenues.
First, wewill test our approach on terminologies from dif-ferent domains, varying the size of the trainingmaterial.
Second, analyzing the segmentation in-duced by analogical learning would be interesting.Third, we need to address the problem of com-bining the translations produced by analogy into afront-end statistical translation engine.
Last, thereis no reason to constrain ourselves to translatingterminology only.
We targeted this task in the firstplace, because terminology typically plugs trans-lation systems, but we think that analogical learn-ing could be useful for translating infrequent enti-ties.494ReferencesP.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: Parameter estimation.
Compu-tational Linguistics, 19(2):263?311.M.
Collins.
2002.
Discriminative training methods forhidden markov models: theory and experiments withperceptron algorithms.
In EMNLP, pages 1?8, Mor-ristown, NJ, USA.E.
Denoual.
2007.
Analogical translation of unknownwords in a statistical machine translation framework.In MT Summit, XI, pages 10?14, Copenhagen.Y.
Freund and R. E. Schapire.
1999.
Large marginclassification using the perceptron algorithm.
Mach.Learn., 37(3):277?296.P.
Fung and K. McKeown.
1997.
Finding terminologytranslations from non-parallel corpora.
In 5th An-nual Workshop on Very Large Corpora, pages 192?202, Hong Kong.M.
Itagaki, T. Aikawa, and X.
He.
2007.
Auto-matic validation of terminology translation consis-tency with statistical method.
In MT Summit XI,pages 269?274, Copenhagen, Denmark.P.
Koehn.
2004.
Pharaoh: A beam search decoder forphrase-based statistical machine translation models.In AMTA, pages 115?124, Washington, DC, USA.P.
Langlais and A. Patry.
2007.
Translating unknownwords by analogical learning.
In EMNLP-CoNLL,pages 877?886, Prague, Czech Republic.P.
Langlais and F. Yvon.
2008.
Scaling up analogi-cal learning.
In 22nd International Conference onComputational Linguistics (COLING 2008), pages51?54, Manchester, United Kingdom.Y.
Lepage and E. Denoual.
2005.
ALEPH: an EBMTsystem based on the preservation of proportion-nal analogies between sentences across languages.In International Workshop on Statistical LanguageTranslation (IWSLT), Pittsburgh, PA, October.Y.
Lepage and A. Lardilleux.
2007.
The GREYC Ma-chine Translation System for the IWSLT 2007 Eval-uation Campaign.
In IWLST, pages 49?53, Trento,Italy.Y.
Lepage.
1998.
Solving analogies on words: an algo-rithm.
In COLING-ACL, pages 728?734, Montreal,Canada.P.
Liang, A.
Bouchard-Co?te?, D. Klein, and B. Taskar.2006.
An end-to-end discriminative approach to ma-chine translation.
In 21st COLING and 44th ACL,pages 761?768, Sydney, Australia.E.
Morin, B. Daille, K. Takeuchi, and K. Kageura.2007.
Bilingual terminology mining - using brain,not brawn comparable corpora.
In 45th ACL, pages664?671, Prague, Czech Republic.R.
Rapp.
1995.
Identifying word translation in non-parallel texts.
In 33rd ACL, pages 320?322, Cam-bridge,Massachusetts, USA.N.
Stroppa and F. Yvon.
2005.
An analogical learnerfor morphological analysis.
In 9th CoNLL, pages120?127, Ann Arbor, MI.K Toutanova, H. Suzuki, and A. Ruopp.
2008.
Ap-plying morphology generation models to machinetranslation.
In ACL-8 HLT, pages 514?522, Colom-bus, Ohio, USA.D.
Vilar, J. Peter, and H. Ney.
2007.
Can we trans-late letters?
In Proceedings of the Second Work-shop on Statistical Machine Translation, pages 33?39, Prague, Czech Republic, June.F.
Yvon, N. Stroppa, A. Delhay, and L. Miclet.
2004.Solving analogical equations on words.
Techni-cal Report D005, E?cole Nationale Supe?rieure desTe?le?communications, Paris, France, July.495
