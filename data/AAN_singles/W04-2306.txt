Semi-Automatic Generation of Dialogue Applicationsin the GEMINI Project ?Stefan W. Hamerich, Volker Schubert, Volker SchlessTEMIC Speech Dialog Systems, Ulm, Germany{stefan.hamerich|volker.schubert|volker.schless}@temic-sds.comRicardo de Co?rdoba, Jose?
M. Pardo, Luis F. d?HaroGrupo de Tecnolog?
?a del Habla, Universidad Polite?cnica de Madrid, Madrid, Spain{cordoba|pardo|lfdharo}@die.upm.esBasilis Kladis, Otilia KocsisKnowledge S.A. (LogicDIS group), Patras, Greece{bkladis|okocsis}@logicdis.grStefan IgelForschungsinstitut fu?r anwendungsorientierte Wissensverarbeitung (FAW), Ulm, Germanysigel@faw.uni-ulm.deAbstractGEMINI (Generic Environment for Multilin-gual Interactive Natural Interfaces) is an ECfunded research project, which has two mainobjectives: First, the development of a flexibleplatform able to produce user-friendly interac-tive multilingual and multi-modal dialogue in-terfaces to databases with a minimum of hu-man effort, and, second, the demonstration ofthe platform?s efficiency through the develop-ment of two different applications based on thisplatform: EG-Banking, a voice-portal for high-quality interactions for bank customers, andCitizenCare, an e-government platform frame-work for citizen-to-administration interactionwhich are available for spoken and web-baseduser interaction.1 IntroductionGEMINI1 exploits experience gained from previousprojects (see e.g.
(Ehrlich et al, 1997; Lehtinen et al,2000)) and from real-world use of similar systems, tocreate a generic platform for the development of user-friendly, natural, high quality, intuitive, platform in-dependent and multi-modal interactive interfaces to awide area of databases employed by information serviceproviders.
?This work was partly supported by the European Com-mission?s Information Society Technologies Programme undercontract no.
IST-2001-32343.
The authors are solely responsi-ble for the contents of this publication.1Refer to the GEMINI Project Homepage onwww.gemini-project.org for further details.The main idea of GEMINI is that, given a database, adescription of its structure and how to access the data aswell as a list of the kinds of requests the user may make,the system should be able to automatically generate thenecessary dialogue scripts to run the service.
In a sense,this is exactly what a human call center agent does whenbeing trained for the job.
Within the project we strive toget as close as possible to this ideal.Specifically, the application generation platform of theGEMINI project contains generic dialogue componentsavailable for adaptation to new services and languages.Thus, generation of multilingual and multi-modal inter-faces is achieved by incorporating the lexical and se-mantic relations of the databases contents, reducing thedevelopment time and facilitating the system?s mainte-nance and transportability to different applications andlanguages.
Furthermore, the platform enables a high de-gree of personalisation (i.e.
user modelling, speaker ver-ification, etc.
).This paper is organised as follows: First we describethe application generation platform (AGP) of the GEM-INI project.
Afterwards we introduce the two pilot appli-cations developed with our platform.
Next we compareour approach with other proposals made by different re-search groups.
Finally we conclude our major findings.2 Application Generation PlatformThe main target of the GEMINI project is the develop-ment of a platform for generating interactive, multilin-gual and multi-modal dialogue interfaces to databaseswith a minimum of cost and human effort.
The AGP isan integrated set of assistants to generate multi-modal di-alogue applications in a semi-automatic way.
Its openand modular architecture simplifies the adaptability ofapplications designed with the AGP to different use cases.Connecting to a different database, adding a new modal-ity or changing a scripting language can be achieved byadding or replacing the appropriate component withouttouching the other aspects of dialogue design again.The AGP consists of assistants, which are tools (partlywith a GUI) producing models.
All these models gen-erated within the AGP are described in GDialogXML(GEMINI Dialog XML), which is an object-oriented ab-stract dialogue modelling language.
It was created duringGEMINI for use with the AGP.
See Figure 1 for an exam-ple of the GDialogXML syntax.
For a detailed descrip-tion of GDialogXML refer to (Hamerich et al, 2003).<Var id = "xPersonName"><xType><Type refr = "String"/></xType></Var><Var id = "xPersonList"><xType><Type refr = "List"><xItemType><Type refr = "ObjEmbed"/><xClass><Class refr = "Person"/></xClass></xItemType></Type></xType></Var>Figure 1: Definition of variables in GDialogXMLAll models in the AGP may be saved as libraries forfuture applications.As shown in Figure 2 the AGP is not supposed to com-plete its task without any human interaction.
This is be-cause there will always be different ways for retrievingspecific information.
Consequently, the designer of dia-logue applications has to select the preferred flow of dia-logue manually by confirming the proposals of the AGPcomponents.
Most of these operations are simply drag& drop actions between various windows that contain allrelevant fields, which are automatically created from theprevious tools of the platform.2.1 AGP ArchitectureAll components of the AGP are integrated into one frame-work.
This eases the use of the platform and enables thedesigner to switch back and forward to different tools incase she or he wants to add or modify certain dialogues.In Figure 2 the architecture of the AGP is illustrated.The whole AGP consists of three layers.
These layers aredescribed in more detail in the following sections.2.1.1 Framework LayerThe framework layer is the first layer of the AGP (referto Figure 2).
It includes the application description as-sistant (ADA), the data modelling assistant (DMA), andthe data connector modelling assistant (DCMA).
As indi-			 	!"		#			 		$		%&%'	Figure 2: Schematic view of the AGP architecture.cated by the black arrow in the upper left corner of Fig-ure 2, all assistants are controlled manually.The designer has to provide the application descrip-tion, which mainly consists of the modalities for whichthe AGP should generate dialogue scripts, the languagesfor which the dialogues should be available, the dialoguestrategy for the resulting system, some settings for errorhandling and a rough application description containingthe major dialogue steps and their respective slots.The DMA helps creating the data model, which con-sists of class descriptions.
Also, the attributes and ele-mentary types of the data are specified here.
In this pro-cess, the GUI guides the designer, and there is the possi-bility to load libraries of previously created classes.Furthermore the DCMA helps creating APIs and im-plementation references for application specific data ac-cess functions.2 These functions could then be used inthe runtime system without any knowledge of the exist-ing database.2The implementation of data access functions has to be doneoutside of the AGP context, since special knowledge about thedatabase itself is needed for this.2.1.2 Retrievals LayerThe retrievals layer (shown as the second layer in Fig-ure 2) mainly consists of the retrieval modelling assis-tant (RMA).
This layer is modality and language inde-pendent, therefore no language or modality specific datais included here.The designer uses the RMA to create the abstract dia-logue flow.
It provides a user-friendly interface where thedesign process is accelerated.
Two main sources of infor-mation are used to automate the process: the data modeland the data connector.
Using the information in the datamodel, several dialogues are automatically generated: (1)candidate dialogues for attributes that the user should beasked for (we call them ?get information dialogues?)
and(2) another dialogue where that specific attribute is pre-sented by the system (?say information dialogues?).
Atthe same time, all procedures from the data connector areavailable to the designer, who can drag & drop any of thedialogues mentioned so far.In the ideal situation, where a dialogue only dependson items from the data model, it can be modelled withjust three drag actions: (1) drag & drop a get informationdialogue, (2) drag & drop a call to the database (from thedata connector), and (3) drag & drop a say informationdialogue.
All the values exchanged by these three func-tions are assigned automatically by the assistant, so thedesigner just has to press ?Accept?
for all assignments.When the dialogue depends on data not contained inthe data model (as questions to the user that do not cor-respond to an object from the data model), the designercan use a set of four different types of dialogues: dia-logue based on user input / on a variable / on a sequence/ on a loop.
In all of them, conditional, switch-case andloop constructs can be inserted.
So, the designer has bothautomation and a great flexibility in dialogue design.The resulting output is called generic retrieval model(GRM), which consists of the modality and language in-dependent parts of a dialogue, which is mainly the appli-cation flow.
The GRM is modelled in an object-orientedway using GDialogXML and mainly consists of dialoguemodules.
A dialogue module can call other modulesas subdialogues or can jump to another top level mod-ule.
This way, the application flow of dialogues in GDi-alogXML is modelled.As indicated by the dashed arrow, it may be necessaryto do some manual fine tuning on the GRM, as the com-plexity of the RMA depends on the application and maybe rather high and often there exist several ways to im-plement the application.2.1.3 Dialogue LayerThe dialogue layer is modality and language dependentas now the modality extensions from the modality exten-sion assistant (MEA) are added to the retrieval model.In the extension files the input and output behaviour ofan application is described for a specific modality.
Thecurrent implementation of the AGP supports the genera-tion of voice (speech modality) and web-based applica-tions (web modality).
For the speech modality the exten-sions consist of links to grammar and prompt concepts,which are language and modality independent.
For eachlanguage, there is a separate concept file, containing thewording for the prompts and the names of the grammarsused.
Additionally the modality extension consists ofspecial subdialogues which are specific for one modalityonly.All grammars and prompts of the AGP are handled ina global library, which eases the quick and easy reuse ofseveral components.The GRM is enriched by the modality extensions inthe Linker.
The resulting model is called dialogue model,which is processed by the speech script generator and/orthe web-page script generator depending on the selectedmodalities in the application description.
For the speechmodality VoiceXML scripts with some additional CGIscripts are generated.
The grammars are taken from theAGP grammar library or have to be generated with theMEA.
For the web modality a web-page script is gener-ated out of the dialogue model which enables dynamicweb pages.For the speech modality, some more tools are relevant,namely the language modelling tool and the vocabularybuilder.To have the runtime system ready for use, little efforthas to be spent on manual fine tuning again.
For examplethe recogniser dependent settings have to be adjusted forthe VoiceXML platform.2.2 Implementation of the AGPThe initial prototype of the AGP of the GEMINI projectwas finished in summer 2003.
This version?s architectureis shown on Figure 2.
In spring 2004 an extended andimproved version of the AGP will be implemented.
Thisversion covers additional features like mixed initiative di-alogues with over-answering, advanced user-modelling,natural language generation, and language-identification.As well, multilingual dialogues are possible with this fi-nal version.All platform components have been implemented us-ing Qt.
Due to this fact, the AGP is applicable on differ-ent operating systems.3 ApplicationsTwo pilot applications have been generated using theAGP for evaluation and validation.
All these applicationsare generated in a very user friendly way, taking into ac-count the automatic multi-modal error handling capabil-ities of the AGP, refer to (Wang et al, 2003) for moredetails about the error handling in GEMINI.3.1 EG-BankingThe voice banking application called EG-Banking appli-cation constitutes a voice portal for user-friendly, high-quality interactions for bank-customers.
The main func-tionality of EG-Banking includes a general informationpart (covering credit cards, accounts, loans infos) avail-able to the public and a transaction part (covering accountflow, account balance, statements, etc.)
available to cus-tomers of the bank only.
The multi-lingual application isaccessible via a cellular or fixed network telephone.A manually refined version of the generated applica-tion is installed at Egnatia Bank in Greece and is used asa commercial product for phone banking.3.2 CitizenCareCitizenCare is an e-government dialogue system forcitizen-to-administration interaction (via multiple chan-nels like internet and public terminals), filled with con-tent for an exemplary community.
The main functional-ity is an interactive authority and information guide, pro-viding different views like an administrative view, basedon the hierarchical structure of the authorities, and aconcern-oriented view, giving the citizen all the informa-tion needed to make use of services offered by public ad-ministration authorities.4 Comparison to Other ApproachesThe GEMINI approach for setting up new dialogue ap-plications differs in a lot of points from other proposals.In this section we compare our AGP with other existentapproaches.Compared with the REWARD system from (Br?ndstedet al, 1998) the GEMINI AGP allows the generation ofdialogues for several modalities.
Additionally in GEM-INI we generate dialogues in standardised descriptionlanguages (VoiceXML and XHTML), so we have no needto develop a special runtime system.
As done for the RE-WARD system, we focused a lot on reusability.In (Polifroni et al, 2003) a rapid development envi-ronment for speech dialogues from online resources wasdescribed.
The development process there first takesknowledge from various web applications and composesa database from it.
This is one of the differences to ourapproach.
Our AGP requires a filled database and allowsthe development of speech and web applications from it.Because of this, we do not need to extract any knowledge,which makes the GEMINI approach more domain inde-pendent.
Another important difference is, that the speechdialogue applications generated by the AGP will be im-plemented in VoiceXML, which allows the generated di-alogues to be executed with every VoiceXML interpreter.5 Conclusion and Future WorkIn the GEMINI project we aim at the design and imple-mentation of an application generation platform, whichgenerates state of the art speech and web applications.The platform architecture is open to generate multi-lingual dialogue applications from different databases inseveral modalities.
We can consider the platform a suc-cess, as we have streamlined the design process of theapplications thanks the help of our assistants.
The use ofstandards (e.g.
VoiceXML) places us in a good positionin the market of voice applications.To facilitate the communication between all modules,an abstract dialogue description language, called GDi-alogXML, was defined, which is another important resultfrom the project.Future work will cover the realisation of the improvedAGP, which will allow multi-lingual applications withmixed initiative, overanswering, and user modelling.
Ad-ditionally a graphical control flow will be available to thedesigner.
Furthermore the AGP will be evaluated againstother approaches of dialogue design.ReferencesT.
Br?ndsted, B. N. Bai, and J.
?.
Olsen.
1998.
The RE-WARD Service Creation Environment, an Overview.In Proceedings ICSLP, pages 1175?1178, Sydney,Australia.U.
Ehrlich, G. Hanrieder, L. Hitzenberger, P. Heis-terkamp, K. Mecklenburg, and P. Regel-Brietzmann.1997.
ACCeSS - Automated Call Center throughSpeech Understanding System.
In Proceedings EU-ROSPEECH, pages 1819?1822, Rhodes, Greece.S.
W. Hamerich, Y.-F. H. Wang, V. Schubert, V. Sch-less, and S. Igel.
2003.
XML-Based Dialogue De-scriptions in the GEMINI Project.
In Proceedings ofthe ?Berliner XML-Tage 2003?, pages 404?412, Berlin,Germany.G.
Lehtinen, S. Safra, M. Gauger, J.-L. Cochard, B. Kas-par, M. E. Hennecke, J. M. Pardo, R. de Co?rdoba,R.
San-Segundo, A. Tsopanoglou, D. Louloudis, andM.
Mantakas.
2000.
IDAS: Interactive Directory As-sistance Service.
In Proceedings of the internationalWorkshop ?Voice Operated Telecom Services?, pages51?54, Ghent, Belgium.
COST 249.J.
Polifroni, G. Chung, and S. Seneff.
2003.
To-wards the Automatic Generation of Mixed-InitiativeDialogue Systems from Web Content.
In ProceedingsEUROSPEECH, pages 193?196, Geneva, Switzerland.Y.-F. H. Wang, S. W. Hamerich, and V. Schless.
2003.Multi-Modal and Modality Specific Error Handling inthe GEMINI Project.
In Proceedings of the ISCAWorkshop on ?Error Handling in Spoken Dialogue Sys-tems?, pages 139?144, Chateau d?Oex, Switzerland.
