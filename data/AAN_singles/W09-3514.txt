Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 69?71,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPNEWS 2009 Machine Transliteration Shared Task System Description:Transliteration with Letter-to-Phoneme TechnologyColin Cherry and Hisami SuzukiMicrosoft ResearchOne Microsoft WayRedmond, WA, 98052{colinc,hisamis}@microsoft.comAbstractWe interpret the problem of transliterat-ing English named entities into Hindi orJapanese Katakana as a variant of theletter-to-phoneme (L2P) subtask of text-to-speech processing.
Therefore, we applya re-implementation of a state-of-the-art,discriminative L2P system (Jiampojamarnet al, 2008) to the problem, without fur-ther modification.
In doing so, we hopeto provide a baseline for the NEWS 2009Machine Transliteration Shared Task (Liet al, 2009), indicating how much can beachieved without transliteration-specifictechnology.
This paper briefly sum-marizes the original work and our re-implementation.
We also describe a bugin our submitted implementation, and pro-vide updated results on the developmentand test sets.1 IntroductionTransliteration occurs when a word is borrowedinto a language with a different character set fromits language of origin.
The word is transcribed intothe new character set in a manner that maintainsphonetic correspondence.When attempting to automate machine translit-eration, modeling the channel that transformssource language characters into transliterated tar-get language characters is a key component togood performance.
Since the primary signal fol-lowed by human transliterators is phonetic corre-spondence, it makes sense that a letter-to-phoneme(L2P) transcription engine would perform well atthis task.
Of course, transliteration is often framedwithin the larger problems of translation and bilin-gual named entity co-reference, making availablea number of other interesting features, such as tar-get lexicons (Knight and Graehl, 1998), distribu-tional similarity (Bilac and Tanaka, 2005), or thedates of an entity?s mentions in the news (Kle-mentiev and Roth, 2006).
However, this task?s fo-cus on generation has isolated the character-levelcomponent, which makes L2P technology a near-ideal match.
For our submission, we re-implementthe L2P approach described by Jiampojamarn etal.
(2008) as faithfully as possible, and apply itunmodified to the transliteration shared task forthe English-to-Hindi (Kumaran and Kellner, 2007)and English-to-Japanese Katakana1 tests.2 Approach2.1 Summary of L2P approachThe core of the L2P transduction engine is thedynamic programming algorithm for monotonephrasal decoding (Zens and Ney, 2004).
The mainfeature of this algorithm is its capability to trans-duce many consecutive characters with a singleoperation.
This algorithm is used to conduct asearch for a max-weight derivation according toa linear model with indicator features.
A samplederivation is shown in Figure 1.There are two main categories of features: con-text and transition features, which follow the firsttwo feature templates described by Jiampojamarnet al (2008).
Context features are centered arounda transduction operation.
These features includean indicator for the operation itself, which is thenconjoined with indicators for all n-grams of sourcecontext within a fixed window of the operation.Transition features are Markov or n-gram features.They ensure that the produced target string makessense as a character sequence, and are representedas indicators on the presence of target n-grams.The feature templates have two main parameters,the size S of the character window from whichsource context features are drawn, and the max-imum length T of target n-gram indicators.
Wefit these parameters using grid search over 1-best1Provided by http://www.cjk.org69ame ?A , ri ?J , can ?
SFigure 1: Example derivation transforming?American?
into ?AJS?.accuracy on the provided development sets.The engine?s features are trained using thestructured perceptron (Collins, 2002).
Jiampo-jamarn et al (2008) show strong improvementsin the L2P domain using MIRA in place of theperceptron update; unfortunately, we did not im-plement a k-best MIRA update due to time con-straints.
In our implementation, no special con-sideration was given to the availability of multi-ple correct answers in the training data; we alwayspick the first reference transliteration and treat itas the only correct answer.
Investigating the useof all correct answers would be an obvious nextstep to improve the system.2.2 Major differences in implementationOur system made two alternate design decisions(we do not claim improvements) over those madeby (Jiampojamarn et al, 2008), mostly based onthe availability of software.
First, we employed abeam of 40 candidates in our decoder, to enable ef-ficient use of large language model contexts.
Thisis put to good use in the Hindi task, where wefound n-gram indicators of length up to n = 6provided optimal development performance.Second, we employed an alternate characteraligner to create our training derivations.
Thisaligner is similar to recent non-compositionalphrasal word-alignment models (Zhang et al,2008), limited so it can only produce monotonecharacter alignments.
The aligner creates sub-string alignments, without insertion or deletionoperators.
As such, an aligned transliteration pairalso serves as a transliteration derivation.
We em-ployed a maximum substring length of 3.The training data was heuristically cleaned af-ter alignment.
Any derivation found by the alignerthat uses an operation occurring fewer than 3 timesthroughout the entire training set was eliminated.This reduced training set sizes to 8,511 pairsfor English-Hindi and 20,306 pairs for English-Katakana.Table 1: Development and test 1-best accuracies,as reported by the official evaluation toolSystem / Test set With Bug FixedHindi Dev 36.7 39.6Hindi Test 41.8 46.6Katakana Dev 46.0 47.1Katakana Test 46.6 46.93 The BugThe submitted version of our system had a bugin its transition features: instead of generating anindicator for every possible n-gram in the gener-ated target sequence, it generated n-grams overtarget substrings, defined by the operations usedduring transduction.
Consider, for example, thederivation shown in Figure 1, which generates?AJS?.
With buggy trigram transitionfeatures, the final operation would produce thesingle indicator [AJ|S], instead of the twocharacter-level trigrams [AJ|] and [J|S].This leads to problems with data sparsity, whichwe had not noticed on unrelated experiments withlarger training data.
We report results both withthe bug and with fixed transition features.
We doso to emphasize the importance of a fine-grainedlanguage discriminative language model, as op-posed to one which operates on a substring level.4 DevelopmentDevelopment consisted of performing a parametergrid search over S and T for each language pair?sdevelopment set.
All combinations of S = 0 .
.
.
4and T = 0 .
.
.
7 were tested for each languagepair.
Based on these experiments, we selected (forthe fixed version), values of S = 2, T = 6 forEnglish-Hindi, and S = 4, T = 3 for English-Katakana.5 ResultsThe results of our internal experiments with theofficial evaluation tool are shown in Table 1.
Wereport 1-best accuracy on both development andtest sets, with both the buggy and fixed versions ofour system.
As one can see, the bug makes less ofan impact in the English-Katakana setting, wheremore training data is available.706 ConclusionWe have demonstrated that an automatic letter-to-phoneme transducer performs fairly well onthis transliteration shared task, with no language-specific or transliteration-specific modifications.Instead, we simply considered Hindi or Katakanato be an alternate encoding for English phonemes.In the future, we would like to investigate properuse of multiple reference answers during percep-tron training.AcknowledgmentsWe would like to thank the NEWS 2009 MachineTransliteration Shared Task organizers for creatingthis venue for comparing transliteration methods.We would also like to thank Chris Quirk for pro-viding us with his alignment software.ReferencesSlaven Bilac and Hozumi Tanaka.
2005.
Extractingtransliteration pairs from comparable corpora.
InProceedings of the Annual Meeting of the NaturalLanguage Processing Society, Japan.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In EMNLP.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint processing and discriminativetraining for letter-to-phoneme conversion.
In ACL,pages 905?913, Columbus, Ohio, June.Alexandre Klementiev and Dan Roth.
2006.
Namedentity transliteration and discovery from multilin-gual comparable corpora.
In HLT-NAACL, pages82?88, New York City, USA, June.Kevin Knight and Jonathan Graehl.
1998.
Ma-chine transliteration.
Computational Linguistics,24(4):599?612.A.
Kumaran and Tobias Kellner.
2007.
A genericframework for machine transliteration.
In Proc.
ofthe 30th SIGIR.Haizhou Li, A. Kumaran, Vladimir Pervouchine, andMin Zhang.
2009.
Report on NEWS 2009 machinetransliteration shared task.
In Proceedings of ACL-IJCNLP 2009 Named Entities Workshop (NEWS2009), Singapore.Richard Zens and Hermann Ney.
2004.
Improvementsin phrase-based statistical machine translation.
InHLT-NAACL, pages 257?264, Boston, USA, May.Hao Zhang, Chris Quirk, Robert C. Moore, andDaniel Gildea.
2008.
Bayesian learning of non-compositional phrases with synchronous parsing.
InACL, pages 97?105, Columbus, Ohio, June.71
