Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 297?300,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsUsing Gaussian Mixture Models to Detect Figurative Language in ContextLinlin Li and Caroline SporlederSaarland University, Postfach 15 11 5066041 Saarbru?cken, Germany{linlin, csporled}@coli.uni-saarland.deAbstractWe present a Gaussian Mixture model for de-tecting different types of figurative languagein context.
We show that this model performswell when the parameters are estimated in anunsupervised fashion using EM.
Performancecan be improved further by estimating the pa-rameters from a small annotated data set.1 IntroductionFigurative language employs words in a way that de-viates from their normal meaning.
It includes id-iomatic usage, metaphor, metonymy or other typesof creative language.
Being able to detect figurativelanguage is important for a number of NLP applica-tions, e.g., machine translation.Simply checking the input against an idiom dic-tionary does not solve the problem.
While someexpressions (e.g., trip the light fantastic) are al-ways used idiomatically, many expressions (e.g.,spill the beans), can take on a literal meaning aswell.
Whether such expression is used idiomaticallyor not has to be inferred from the discourse context.Likewise, simple dictionary look-up would not workfor truly creative, one-off usages; these can neitherbe found in a dictionary nor can they be detectedby standard idiom extraction methods, which applystatistical measures to accumulated corpus evidencefor an expression to assess its ?idiomaticity?.
An ex-ample of a fairly creative usage can be found in (1),which is a variation of the idiom put a sock in.
(1) Take the sock out of your mouth and create abrand-new relationship with your mom.We propose a method for detecting figurative lan-guage in context.
Because we use context informa-tion rather than corpus statistics, our approach worksalso for truly creative usages.2 Related WorkMost studies on the detection of idioms and othertypes of figurative language focus on one of threeaspects: type-based extraction (detect idioms on thetype level), token-based classification (given a po-tentially idiomatic phrase in context, decide whetherit is used idiomatically), token-based detection (de-tect figurative expressions in running text).Type-based extractions exploit the fact that idiomshave many properties which differentiate them fromother expressions, e.g., they often exhibit a degree ofsyntactic and lexical fixedness.
These properties canbe used to identify potential idioms, for instance, byemploying measures of association strength betweenthe elements of an expression (Lin, 1999).Type-based approaches are unsuitable for expres-sions which can be used both figuratively and lit-erally.
These have to be disambiguated in context.Token-based classification aims to do this.
A num-ber of token-based approaches have been proposed:supervised (Katz and Giesbrecht, 2006), weakly su-pervised (Birke and Sarkar, 2006), and unsupervised(Fazly et al, 2009; Sporleder and Li, 2009).Finally, token-based detection can be viewedas a two stage task which is the combination oftype-based extraction and token-based classifica-tion.
There has been relatively little work on this sofar.
One exception are Fazly et al (2009) who detectidiom types by using statistical methods that modelthe general idiomaticity of an expression and thencombine this with a simple second-stage process thatdetects whether the target expression is used figura-tively in a given context, based on whether the ex-pression occurs in canonical form or not.However, modeling token-based detection as a297combination of type-based extraction and token-based classification has some drawbacks.
First,type-based approaches typically compute statisticsfrom multiple occurrences of a target expression,hence they cannot be applied to novel usages.
Sec-ond, these methods were developed to detect figu-ratively used multi-word expressions (MWEs) anddo not work for figuratively used individual words,like sparrow in example (2).
Ideally, one would liketo have a generic model that can detect any type offigurative usage in a given context.
The model wepropose in this paper is one step in this direction.
(2) During the Iraq war, he was a sparrow; hedidn?t condone the bloodshed but wasn?t both-ered enough to go out and protest.3 Using Gaussian Mixture Model to DetectFigurative LanguageWe address the problem by using Gaussian Mix-ture Models (GMMs).
We assume that the literal(l) and non-literal (n) data are generated by two dif-ferent Gaussians (literal and nonliteral Gaussian).The token-based detection task is done by compar-ing which Gaussian has the higher probability ofgenerating a specific instance.The Gaussian mixture model is defined as:p(x) =?c?
{l,n}wc ?N(x|?c,?c)Where, c is the category of the Gaussian, ?c is themean, ?c is the covariance matrix, and wc is theGaussian weight.Our method is based on the insight that figura-tive language exhibits less semantic cohesive tieswith the context than literal language (Sporleder andLi, 2009).
We use Normalized Google Distance tomodel semantic relatedness (Cilibrasi and Vitanyi,2007) and represent the data by five types of seman-tic relatedness features x = (x1, x2, x3, x4, x5):x1 is the average relatedness between the targetexpression and context words,x1 =2|T | ?
|C|?
(wi,cj)?T?Crelatedness(wi, cj)where wi is a component word of the target expres-sion (T); cj is one of the context words (C); |T | isthe total number of words in the target expression,and |C| is the total number of words in the context.The term 2|T |?|C| is the normalization factor, whichis the total number of relatedness pairs between tar-get component words and context words.x2 is the average semantic relatedness in the con-text of the target expression,x2 =1(|C|2)?
(ci,cj)?C?C,i6=jrelatedness(ci, cj)x3 is the difference between the average seman-tic relatedness between the target expression and thecontext words and the average semantic relatednessof the context (i.e., x3 = x1?
x2).
It is an indicatorof how strongly the target expression is semanticallyrelated to the discourse context.x4 is the feature used by Sporleder and Li (2009)for predicting literal or idiomatic use in the cohesiongraph based method,x4 ={1 if x3 < 00 elsex5 is a high dimensional vector which representsthe top relatedness scores between the componentwords of the target expression and the context,x5(k) = max(wi,cj)?T?C(k, {relatedness(wi, cj)})where the function max(k,A) is defined to choosethe kth highest element from the set A.1The detection task is done by a Bayes decisionrule, which chooses the category by maximizing theprobability of fitting the data into the different Gaus-sian components:c(x) = arg maxi?
{l,n}{wi ?N(x|?i,?i)}4 Evaluating the GMM Approach4.1 DataWe evaluate our method on two data sets.
Thefirst set (idiom set) is taken from Sporleder and Li(2009) and consists of 3964 idiom occurrences (17idiom types) which were manually labeled as ?lit-eral?
or ?figurative?.
The second data set (V+NPset), consists of a randomly selected sample of500 V+NP constructions from the Gigaword corpus,which were manually labeled.To determine how well our model deals with dif-ferent types of figurative usage, we distinguish fourphenomena: Phrase-level figurative means that the1We set k to be 100 in our experiment.298whole phrase is used figuratively.
We further dividethis class into expressions which are potentially am-biguous between literal and figurative usage (nsa),e.g., spill the beans, and those that are unambigu-ously figurative irrespective of the context (nsu),e.g., trip the light fantastic.
The latter can, theoreti-cally, be detected by dictionary look-up, the formercannot.
The label token-level figurative (nw) is usedwhen part of the phrase is used figuratively (e.g.,sparrow in (2)).
Often it is difficult to determinewhether a word is still used in a ?literal?
sense orwhether it is already used figuratively.
Since we areinterested in improving the performance of NLP ap-plications such as MT, we take a pragmatic approachand classify usages as ?figurative?
if they are not lex-icalized, i.e., if the specific sense is not listed in adictionary.2 For example, we would classify summitin the ?meeting?
sense as ?literal?
(l).
In our data set,7.3% of the instances were annotated as ?nsa?, 1.9%as ?nsu?, 9.2% as ?nw?
and 81.5% as ?l?.
A randomlyselected sample (100 instances) was annotated inde-pendently by a second annotator.
The kappa score(Cohen, 1960) is 0.84, which suggest that the anno-tations are reliable.4.2 GMM Estimated by EMWe used the MatLab package provided by Cali-non (2009) for estimating the GMM model.
TheGMM is trained by the EM algorithm.
The pri-ors of Gaussian components, means and covarianceof each components, are initialized by the k-meansclustering algorithm (Hartigan, 1975).To determine whether the GMM is able to per-form token-based idiom classification, we appliedit to the idiom data set.
The results (see Table 1)show that the GMM can distinguish usages quitewell and gains equally good results as Sporleder andLi?s cohesion graph method (Co-Graph).
In addi-tion, this method can deal with unobserved occur-rences of non-literal language.Table 2 shows the results on the second data set.The baseline predicts ?idiomatic?
and ?literal?
ac-cording to a biased probability which is based on thetrue distribution in the annotated set.
GMM showsthe performance on the whole V+NP set.
We alsosplit the test set into three different subsets to de-2We used http://www.askoxford.com.Model C Pre.
Rec.
F-S. Acc.Co-Graphn 90.55 80.66 85.3278.38l 50.04 69.72 58.26GMMn 90.69 80.66 85.3878.39l 50.17 70.15 58.50Table 1: Results on the idiom data set, n(on-literal) is theunion of the predefined three sub-classes (nsu, nsa, nw),l(iteral), Acc(uracy), Pre(cision), Rec(all), F-S(core)Model C Pre.
Rec.
F-S. Acc.Baselinen 21.79 22.67 22.2271.87l 83.19 82.47 82.83Co-Graphn 37.29 84.62 51.7670.92l 95.12 67.83 79.19GMMn 40.71 73.08 52.2975.41l 92.58 75.94 83.44GMM{nsu,l}n 8.79 1.00 16.1676.49l 1.00 75.94 86.33GMM{nsa,l}n 22.43 77.42 34.7876.06l 97.40 75.94 85.34GMM{nw,l}n 23.15 64.10 34.0174.74l 94.93 75.94 84.38Table 2: Results on the V+NP data set, Gaussian compo-nent parameters estimated by EMtermine how the GMM performs on distinguishingliteral usage from the different types of figurative us-age: GMM{nsu, l}, GMM{nsa, l}, GMM{nw, l}.The unsupervised GMM model beats the base-line and achieves good results on the V+NP data set.It also outperforms the Co-Graph approach, whichsuggests that the statistical model, GMM, is morelikely to boost the performance by capturing statisti-cal properties of the data for more difficult cases (id-ioms vs. general figurative usages), compared withthe Co-Graph approach.In conclusion, the model is not only able to clas-sify idiomatic expressions but also to detect new fig-urative expressions.
However, the performance onthe second data set is worse compared with run-ning the same model on the idiom data set.
Thisis because the V+NP data set contains more diffi-cult examples, e.g., expressions which are only par-tially figurative (e.g., (2)).
One would expect theliteral part of the expression to exhibit cohesive tieswith the context, hence the cohesion based featuresmay fail to detect this type of figurative usage.
Con-sequently the performance of the GMM is lowerfor figuratively used words (?nw?)
than for idioms(?nsa?, ?nsu?).
However, even for ?nw?
cases themodel still obtains a relatively high accuracy.2994.3 GMM estimated from Annotated DataIn a second experiment, we tested how well theGMM performs when utilizing the annotated idiomdata set to estimate the two Gaussian components in-stead of using EM.
We give equal weights to the twoGaussian components and predict the label on theV+NP data set by fixing the mixture model whichis estimated from the training set (GMM+f).
Thismethod further improves the performance comparedto the unsupervised approach (Table 3).We also experimented with setting a threshold andabstaining from making a prediction when the prob-ability of an instance belonging to the Gaussian isbelow the threshold (GMM+f+s).
Table 3 showsthe performance when only evaluating on the subsetfor which a classification was made.
It can be seenthat the accuracy and the overall performance on theliteral class improve, but the precision for the non-literal class remains relatively low, i.e., many literalinstances are still misclassified as ?non-literal?.
Onereason for this may be that there are a few instancescontaining named entities, which exhibit weak co-hesive ties with the context even if though they areused literally.
Using a named-entity tagger beforeapplying the GMM might solve the problem.Model C Pre.
Rec.
F-S. Acc.GMM+fn 42.22 73.08 53.5276.60l 92.71 77.39 84.36GMM+f+sn 41.38 54.55 47.0683.44l 92.54 87.94 90.18Table 3: Results on the V+NP data set, Gaussian compo-nent parameters estimated by annotated dataFinally, Table 4 shows the result when using dif-ferent idioms to generate the nonliteral Gaussian.The literal Gaussian can be generated from the au-tomatically obtained nonliteral examples by Li andSporleder (2009).
We found the estimation of theGMM is not sensitive to idioms; our model is robustand can use any existing idiom data to discover newfigurative expressions.
Furthermore, Table 4 alsoshows that the GMM does not need a large amountof annotated data for parameter estimation.
A fewhundred instances are sufficient.5 ConclusionWe described a GMM based approach for detectingfigurative expressions.
This method not only worksTrain (size) C Pre.
Rec.
F-S. Acc.bite one?s tongue n 40.79 79.49 53.9174.94(166) l 94.10 73.91 82.79break the ice n 39.05 52.56 44.8176.12(541) l 88.36 81.45 84.77Table 4: Results on the V+NP dataset, Gaussian compo-nent parameters estimated on different idiomsfor distinguishing literal and non-literal usages of apotential idiomatic expression in a discourse con-text, but also discovers new figurative expressions.The components of the GMM can be effectivelyestimated using the EM algorithm.
The performancecan be further improved when employing an anno-tated data set for parameter estimation.
Our resultsshow that the estimation of Gaussian componentsare not idiom-dependent.
Furthermore, a small an-notated data set is enough to obtain good results.AcknowledgmentsThis work was funded by the DFG within the Clusterof Excellence ?Multimodal Computing and Interaction?.Thanks to Benjamin Roth for discussions and comments.ReferencesJ.
Birke, A. Sarkar.
2006.
A clustering approach forthe nearly unsupervised recognition of nonliteral lan-guage.
In Proceedings of EACL-06.S.
Calinon.
2009.
Robot Programming by Demonstra-tion: A Probabilistic Approach.
EPFL/CRC Press.R.
L. Cilibrasi, P. M. B. Vitanyi.
2007.
The Google simi-larity distance.
IEEE Trans.
on Knowl.
and Data Eng.,19(3):370?383.J.
Cohen.
1960.
A coefficient of agreement for nominalscales.
Educational and Psychological Measurements,20:37?46.A.
Fazly, P. Cook, S. Stevenson.
2009.
Unsupervisedtype and token identification of idiomatic expressions.Computational Linguistics, 35(1):61?103.J.
A. Hartigan.
1975.
Clustering Algorithm.
Wiley.G.
Katz, E. Giesbrecht.
2006.
Automatic identificationof non-compositional multi-word expressions using la-tent semantic analysis.
In Proceedings of the ACL06Workshop on Multiword Expressions: Identifying andExploiting Underlying Properties.L.
Li, C. Sporleder.
2009.
Contextual idiom detectionwithout labelled data.
In Proceedings of EMNLP-09.D.
Lin.
1999.
Automatic identification of non-compositional phrases.
In Proceedings of ACL-99.C.
Sporleder, L. Li.
2009.
Unsupervised recognition ofliteral and non-literal use of idiomatic expressions.
InProceedings of EACL-09.300
