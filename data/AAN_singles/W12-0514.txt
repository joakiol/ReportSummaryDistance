Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data (Hybrid2012), EACL 2012, pages 106?114,Avignon, France, April 23 2012. c?2012 Association for Computational LinguisticsIncorporating Linguistic Knowledge inStatistical Machine Translation: Translating PrepositionsReshef ShilonDept.
of LinguisticsTel Aviv UniversityIsraelHanna FadidaDept.
of Computer ScienceTechnionIsraelShuly WintnerDept.
of Computer ScienceUniversity of HaifaIsraelAbstractPrepositions are hard to translate, becausetheir meaning is often vague, and the choiceof the correct preposition is often arbitrary.At the same time, making the correct choiceis often critical to the coherence of the out-put text.
In the context of statistical ma-chine translation, this difficulty is enhanceddue to the possible long distance betweenthe preposition and the head it modifies, asopposed to the local nature of standard lan-guage models.
In this work we use mono-lingual language resources to determine theset of prepositions that are most likely tooccur with each verb.
We use this informa-tion in a transfer-based Arabic-to-Hebrewstatistical machine translation system.
Weshow that incorporating linguistic knowl-edge on the distribution of prepositions sig-nificantly improves the translation quality.1 IntroductionPrepositions are hard to translate.
Prepositionalphrases modify both nouns and verbs (and, insome languages, other parts of speech); we onlyfocus on verbs in this work.
When a preposi-tional phrase modifies a verb, it can function asa complement or as an adjunct of the verb.
Inthe former case, the verb typically determines thepreposition, and the choice is rather arbitrary (oridiomatic).
In fact, the choice of preposition canvary among synonymous verbs even in the samelanguage.
Thus, English think takes either of orabout, whereas ponder takes no preposition at all(we view direct objects as prepositional phraseswith a null preposition in this work.)
Hebrew hkh?hit?
takes the accusative preposition at, whereasthe synonymous hrbic ?hit?
takes l ?to?.
ArabictfAdY ?watch out?
takes a direct object or mn?from?, whereas A$fq ?be careful of?
takes En?on?
and tHrz ?watch out?
takes mn ?from?.1In the latter case, where the prepositionalphrase is an adjunct, the choice of prepositiondoes convey some meaning, but this meaning isvague, and the choice is often determined by thenoun phrase that follows the preposition (the ob-ject of the preposition).
Thus, temporals suchas last week, on Tuesday, or in November, loca-tives such as on the beach, at the concert, or inthe classroom, and instrumentals such as with aspoon, are all translated to prepositional phraseswith the same preposition, b ?in?, in Hebrew(b+s?bw?
s?
?br, b+ywm s?lis?i, b+nwbmbr, b+ym,b+qwncrT, b+kth, and b+kp, respectively).Clearly, then, prepositions cannot be translatedliterally, and the head that they modify, as wellas the object of the preposition, have to be takeninto account when a preposition is chosen to begenerated.
Standard phrase-based statistical ma-chine translation (MT) does not always succeedin addressing this challenge, since the coherenceof the output text is determined to a large extentby an n-gram language model.
While such lan-guage models can succeed to discriminate in fa-vor of the correct preposition in local contexts, inlong-distance dependencies they are likely to fail.We propose a method for incorporating lin-guistic knowledge pertaining to the distributionof prepositions that are likely to occur with verbsin a transfer-based statistical machine translationsystem.
First, we use monolingual language re-sources to rank the possible prepositions that var-ious verbs subcategorize for.
Then, we use thisinformation in an Arabic-to-Hebrew MT system.1To facilitate readability we use a transliteration of He-brew using Roman characters; the letters used, in Hebrewlexicographic order, are abgdhwzxTiklmnspcqrs?t.
For Ara-bic we use the transliteration scheme of Buckwalter (2004).106The system is developed in the framework of Stat-XFER (Lavie, 2008), which facilitates the explicitexpression of synchronous (extended) context-free transfer rules.
We use this facility to im-plement rules that verify the correct selection ofprepositions by the verbs that subcategorize them.We show that this results in significant improve-ment in the translation quality.In the next section we briefly survey relatedwork.
Section 3 introduces the Stat-XFER frame-work in which our method is implemented.
Wepresent the problem of translating prepositionsbetween Hebrew and Arabic in Section 4, and dis-cuss possible solutions in Section 5.
Our proposedmethod consists of two parts: acquisition of verb-preposition mappings from corpora (Section 6),and incorporation of this knowledge in an actualtransfer-based MT system (Section 7).
Section 8provides an evaluation of the results.
We concludewith suggestions for future research.2 Related WorkAn explicit solution to the challenges of translat-ing prepositions was suggested by Trujillo (1995),who deals with the problem of translating spa-tial prepositions between Spanish and Englishin the context of a lexicalist transfer-based MTframework.
Trujillo (1995) categorizes spatialprepositions according to a lexical-semantic hier-archy, and after parsing the source language sen-tence, uses the representation of prepositions inthe transfer process, showing improvement in per-formance compared to other transfer-based sys-tems.
This requires resources much beyond thosethat are available for Arabic and Hebrew.More recent works include Gustavii (2005),who uses transformation-based learning to inferrules that can correct the choice of prepositionmade by a rule-based MT system.
Her reportedresults show high accuracy on the task of cor-rectly generating a preposition, but the overallimprovement in the quality of the translation isnot reported.
Li et al (2005) focus on three En-glish prepositions (on, in and at) and use Word-Net to infer semantic properties of the immedi-ate context of the preposition in order to correctlytranslate it to Chinese.
Again, this requires lan-guage resources that are unavailable to us.
Word-Net (and a parser) are used also by Naskar andBandyopadhyay (2006), who work on English-to-Bengali translation.The closest work to ours is Agirre et al (2009),who translate from Spanish to Basque in a rule-based framework.
Like us, they focus on prepo-sitional phrases that modify verbs, and includealso the direct object (and the subject) in their ap-proach.
They propose three techniques for cor-rectly translating prepositions, based on informa-tion that is automatically extracted from monolin-gual resources (including verb-preposition-headdependency triplets and verb subcategorization)as well as manually-crafted selection rules thatrely on lexical, syntactic and semantic informa-tion.
Our method is similar in principle, themain differences being: (i) we incorporate lin-guistic knowledge in a statistical decoder, facil-itating scalability of the MT system, (ii) we usemuch more modest resources (in particular, we donot parse either of the two languages), and (iii) wereport standard evaluation measures.Much work has been done regarding the auto-matic acquisition of subcategorization frames inEnglish (Brent, 1991; Manning, 1993; Briscoeand Carroll, 1997; Korhonen, 2002), Czech(Sarkar and Zeman, 2000), French (Chesley andSalmon-alt, 2006), and several other languages.The technique that we use here (Section 6) cannow be considered standard.3 Introduction to Stat-XFERThe method we propose is implemented in theframework of Stat-XFER (Lavie, 2008), a statis-tical machine translation engine that includes adeclarative formalism for symbolic transfer gram-mars.
A grammar consists of a collection of syn-chronous context-free rules, which can be aug-mented by unification-style feature constraints.These transfer rules specify how phrase struc-tures in a source-language correspond and trans-fer to phrase structures in a target language, andthe constraints under which these rules shouldapply.
The framework also includes a trans-fer engine that applies the transfer grammarto a source-language input sentence at runtime,and produces collections of scored word- andphrase-level translations according to the gram-mar.
Scores are based on a log-linear combinationof several features, and a beam-search controls theunderlying parsing and transfer process.Crucially, Stat-XFER is a statistical MTframework, which uses statistical informationto weigh word translations, phrase correspon-107dences and target-language hypotheses; in con-trast to other paradigms, however, it can utilizeboth automatically-created and manually-craftedlanguage resources, including dictionaries, mor-phological processors and transfer rules.
Stat-XFER has been used as a platform for develop-ing MT systems for Hindi-to-English (Lavie etal., 2003), Hebrew-to-English (Lavie et al, 2004),Chinese-to-English, French-to-English (Hanne-man et al, 2009) and many other low-resourcelanguage pairs, such as Inupiaq-to-English andMapudungun-to-Spanish.In this work, we use the Arabic-to-Hebrew MTsystem developed by Shilon et al (2010), whichuses over 40 manually-crafted rules.
Other re-sources include Arabic morphological analyzerand disambiguator (Habash, 2004), Hebrew mor-phological generator (Itai and Wintner, 2008) anda Hebrew language model compiled from avail-able corpora (Itai and Wintner, 2008).While our proposal is cast within the frame-work of Stat-XFER, it can be in principle adaptedto other syntax-based approaches to MT; specif-ically, Williams and Koehn (2011) show how toemploy unification-based constraints to the target-side of a string-to-tree model, integrating con-strain evaluation into the decoding process.4 Translating prepositions betweenHebrew and ArabicModern Hebrew and Modern Standard Arabic,both closely-related Semitic languages, sharemany orthographic, lexical, morphological, syn-tactic and semantic similarities, but they are stillnot mutually comprehensible.
Machine transla-tion between these two languages can indeed ben-efit from the similarities, but it remains a chal-lenging task.
Our current work is situated in theframework of the only direct MT system betweenthese two languages that we are aware of, namelyShilon et al (2010).Hebrew and Arabic share several similar prepo-sitions, including the frequent b ?in, at, with?and l ?to?.
However, many prepositions exist inonly one of the languages, such as Arabic En ?on,about?
or Hebrew s?l ?of?.
Hebrew uses a preposi-tion, at, to introduce definite direct objects (whichmotivates our choice of viewing direct objects asspecial kind of prepositional phrases, which maysometimes be introduced by a null preposition).The differences in how the two languages useprepositions are significant and common, as thefollowing examples demonstrate.
(1) AErbexpressed.3msAl+wzyrthe+ministerEnonAml+hhope+his?The minister expressed his hope?
(Arabic)h+s?rthe+ministerhbi?expressed.3msatacctqwt+whope+his?The minister expressed his hope?
(Hebrew)(2) HDrattended.3msAl+wzyrthe+ministerAl+jlspthe+meeting?The minister attended the meeting?
(Arabic)h+s?rthe+ministernkxattended.3msb+inh+is?ibhthe+meeting?The minister attended the meeting?
(Hebrew)In (1), the Arabic preposition En ?on, about?is translated into the Hebrew accusative markerat.
In contrast, (2) demonstrates the opposite casewhere the Arabic direct object (no preposition)is translated into a Hebrew prepositional phraseintroduced by b ?in?.
Clearly, despite the lex-ical and semantic similarity between many He-brew and Arabic prepositions, their licensing bysemantically-equivalent verbs is different in bothlanguages.An important issue is the selection of prepo-sitions to model.
We focus on a small list ofthe most common prepositions in both languages.The list was constructed by counting prepositionsin monolingual corpora from the news domain inthe two languages (500K tokens in Arabic, 120Ktokens in Hebrew).
In total, the Arabic data in-cludes 70K prepositions, which comprise 14% ofthe corpus tokens, whereas the Hebrew data in-cludes 19K prepositions, or 16% of the tokens.Not surprisingly, the most frequent prepositionswere those that are commonly used to introducecomplements.
The data are listed in Table 1.Based on these data, we decided to focus onthe set of top nine Arabic prepositions (fy, l, b,mn, ElY, AlY, En, mE and the direct object), andthe top six Hebrew prepositions (b, l, m, ?l, ?m,and the direct object), comprising over 80% of allpreposition occurrences in our corpora.2 Theseare also the most common complement-precedingprepositions, and therefore pose the main chal-lenge for the task of machine translation.2The preposition k ?as?
is omitted since it is translateddirectly to itself in most cases.108Arabic HebrewRank Preposition Count %?% Preposition Count %?%1 fy ?in?
13128 18.7 18.7 b ?in?
6030 31.6 31.62 dir-obj 12626 17.9 36.7 l ?to?
3386 17.7 49.33 l ?to?
9429 13.4 50.1 dir-obj 3250 17.0 66.34 b ?in, with?
7253 10.3 60.4 m ?from?
1330 6.9 73.35 mn ?from?
6859 9.7 70.2 ?l ?on?
1066 5.5 78.96 ElY ?on?
5304 7.5 77.8 k ?as?
354 1.8 80.77 AlY ?to?
4458 6.3 84.1 ?m ?with?
338 1.7 82.58 En ?on, about?
1871 2.6 86.8 bin ?between?
191 1.0 84.69 mE ?with?
1380 1.9 88.8 ?d ?until?
159 0.8 85.410 byn ?between?
1045 1.4 90.3 lpni ?before?
115 0.6 86.0Table 1: Counts of Arabic and Hebrew most frequent prepositions.
The columns list, for each preposition, itscount in the corpus, the percentage out of all prepositions, and the accumulated percentage including all thehigher-ranking prepositions.5 Possible solutionsIn order to improve the accuracy of translatingprepositions in a transfer-based system, severalapproaches can be taken.
We discuss some ofthem in this section.First, accurate and comprehensive statistics canbe acquired from large monolingual corpora ofthe target language regarding the distribution ofverbs with their subcategorized prepositions andthe head of the noun phrase that is the object ofthe preposition.
As a backoff model, one coulduse a bigram model of only the preposition andthe head of the following noun phrase, e.g., (on,Wednesday).
This may help in the case of tempo-ral and locative adjuncts that are less related to thepreceding verb.
Once such data are acquired, theymay be used in the process of scoring hypotheses,if a parser is incorporated in the process.One major shortcoming of this approach is thedifficulty of acquiring the necessary data, and inparticular the effect of data sparsity on the accu-racy of this approach.
In addition, a high qualityparser for the target language must be available,and it must be incorporated during the decodingstep, which is a heavy burden on performance.Alternatively, one could acquire lexical andsemantic mappings between verbs, the type oftheir arguments, the selectional restrictions theyimpose, and the possible prepositions used toexpress such relations.
This can be done us-ing a mapping from surface forms to lexical on-tologies, like WordNet (Fellbaum, 1998), andto a syntactic-semantic mapping like VerbNet(Schuler, 2005) which lists the relevant preced-ing preposition.
Similar work has been done byShi and Mihalcea (2005) for the purpose of se-mantic parsing.
These lexical-semantic resourcescan help map between the verb and its possiblearguments with their thematic roles, including se-lectional restrictions on them (expressed lexically,using a WordNet synset, like human or concrete).The main shortcoming of this solution is thatsuch explicit lexical and semantic resources ex-ist mainly for English.
In addition, even whentranslating into English, this information can onlyassist in limiting the number of possible preposi-tions but not in determining them.
For example,one can talk about the event, after the event, or atthe event.
The information that can determine thecorrect preposition is in the source sentence.Finally, a potential solution is to allow trans-lation of source-language prepositions to a lim-ited set of possible target-language prepositions,and then use both target-language constraints onpossible verb-preposition matches and an n-gramlanguage model to choose the most adequate so-lution.
Despite the fact that this solution doesnot model the probability of the target prepositiongiven its verb and the original sentence, it limitsthe number of possible translations by taking intoaccount the target-language verb and the possibleconstraints on the prepositions it licenses.
Thismethod is also the most adequate for a scenariothat employs a statistical decoder, such as the oneused in Stat-XFER.
This is the solution we advo-cate in this paper.
We describe the acquisition ofHebrew verb?preposition statistics in the follow-ing section, and the incorporation of this knowl-edge in a machine translation system in Section 7.1096 Acquisition of verb?preposition dataTo obtain statistics on the relations between verbsand prepositions in Hebrew we use the The-Marker, Knesset and Arutz 7 corpora (Itai andWintner, 2008), comprising 31M tokens.
The cor-pora include 1.18M (potentially inflected) verb to-kens, reflecting 4091 verb (lemma) types.The entire corpus was morphologically ana-lyzed and disambiguated (Itai and Wintner, 2008).We then collected all instances of prepositionsthat immediately follow a verb; this reflects theassumption that such prepositions are likely to bea part of the verb?s subcategorization frame.
Aspecial treatment of the direct object case was re-quired, because a Hebrew direct object is intro-duced by the accusative marker at when it is defi-nite, but not otherwise.
Since constituent order inHebrew is relatively free, the noun phrase that im-mediately follows the verb can also be its subject.Therefore, we only consider such noun phrasesif they do not agree with the verb in gender andnumber (and are therefore not subjects).We then use maximum likelihood estimation toobtain the conditional probability of each prepo-sition following a verb.
The result is a databaseof verb-preposition pairs, with an estimate oftheir probabilities.
Examples include nkll ?be in-cluded?, for which b ?in?
has 0.91 probability;hstpq ?be satisfied?
b ?in?
(0.99); xikh ?wait?
l?to?
(0.73); ht?lm ?ignore?
m ?from?
(0.83); andhtbss ?base?
?l ?on?
(0.93).
Of course, some otherverbs are less clear-cut.From this database, we filter out verb-preposition pairs whose score is lower than a cer-tain threshold.
We are left with a total of 1402verbs and 2325 verb-preposition pairs which weuse for Arabic-to-Hebrew machine translation, asexplained in the next section.
Note that we cur-rently ignore the probabilities of the prepositionsassociated with each verb; we only use the prob-abilities to limit the set of prepositions that are li-censed by the verb.
Ranking of these prepositionsis deferred to the language model.7 Incorporating linguistic knowledgeWe implemented the last method suggested inSection 5 to improve the quality of the Arabic-to-Hebrew machine translation system of Shilonet al (2010) as follows.First, we modified the output of the Hebrew{OBJ_ACC_AT,0}OBJ::OBJ [NP] -> ["AT" NP](X1::Y2)((X1 def) = +)((Y2 prep) = AT) #mark preposition(X0 = X1)(Y0 = Y2{OBJ_PP,0}OBJ::OBJ [PREP NP] -> [PREP NP](X1::Y1)(X2::Y2)((Y0 prep) = (Y1 lex)) #mark prep.
(X0 = X1)(Y0 = Y1){OBJ_NP_PP_B, 0}OBJ::OBJ [NP] -> ["B" NP](X1::Y2)((Y0 prep) = B) #mark preposition(X0 = X1)(Y0 = Y2)Figure 1: Propagating the surface form of the preposi-tion as a feature of the OBJ node.morphological generator to reflect also, for eachverb, the list of prepositions licensed by the verb(Section 6).
Stat-XFER uses the generator to gen-erate inflected forms of lemmas obtained from abilingual dictionary.
Each such form is associ-ated with a feature structure that describes someproperties of the form (e.g., its gender, numberand person).
To the feature structures of verbswe add an additional feature, ALLOWED PREPS,whose value is the list of prepositions licensed bythe verb.
For example, the feature structure of theHebrew verb sipr ?tell?
is specified as:(allowed_preps = (*OR* at l))Thus, whenever the Hebrew generator returns aninflected form of the verb sipr, the feature AL-LOWED PREPS lists the possible prepositions atand l ?to?, that are licensed by this verb.Then, we modified the transfer grammar to en-force constraints between the verb and its objects.This was done by adding a new non-terminal nodeto the grammar, OBJ, accounting for both directand indirect objects.
The idea is to encode the ac-tual preposition (in fact, its surface form) as a fea-ture of the OBJ node (Figure 1), and then, whena sentence is formed by combining a verb with itssubject and object(s), to check the value of this110{S_VB_NP_OBJ_swap, 1}S::S [VB NP OBJ] -> [NP VB OBJ](X1::Y2)(X2::Y1)(X3::Y3)((X1 num) = singular) # Arabic agr.
((X1 per) = (X2 per))((Y1 num) = (Y2 num)) # Hebrew agr.
((Y1 gen) = (Y2 gen))((Y1 per) = (Y2 per))((Y2 allowed_preps) = (Y3 prep))Figure 2: Enforcing agreement between a verb VB andits object OBJ on the Hebrew side.feature against the ALLOWED PREPS feature ofthe verb (Figure 2).Consider Figure 1.
The first rule maps an Ara-bic direct object noun phrase to a Hebrew directobject, and marks the preposition at on the He-brew OBJ node as the value of the feature PREP.The second rule maps an Arabic prepositionalphrase to Hebrew prepositional phrase, markingthe Hebrew OBJ (referred to here as Y1 lex)with the value of the feature PREP.
The third rulemaps an Arabic noun phrase to a Hebrew preposi-tional phrase introduced by the preposition b ?in?.The rule in Figure 2 enforces sentence-level agreement between the feature AL-LOWED PREPS of the Hebrew verb (here, Y2allowed preps) and the actual preposition ofthe Hebrew object (here, Y3 prep).To better illustrate the effect of these rules, con-sider the following examples, taken from the sys-tem?s actual output (the top line is the Arabic in-put, the bottom is the Hebrew output).
Therecan be four types of syntactic mappings betweenArabic and Hebrew arguments: (NP, NP), (NP,PP), (PP, NP) and (PP, PP).
Examples (3) and (4)demonstrate correct translation of the Arabic di-rect object into the Hebrew direct object (with andwithout the Hebrew definite accusative marker at,respectively).
Example (5) demonstrates the cor-rect translation of the Arabic direct object to aHebrew PP with the preposition l ?to?.
Exam-ple (6) demonstrates the correct translation of anArabic PP introduced by En ?on, about?
to a He-brew direct object, and Example (7) demonstratesthe translation of Arabic PP introduced by b ?in,with?
into a Hebrew PP introduced by ?m ?with?.
(3) rAytsee.past.1sAl+wldthe+boyraitisee.past.1satacc.defh+ildthe+boy?I saw the boy?
(4) rAytsee.past.1swldAboy.acc.indefraitisee.past.1sildboy?I saw a boy?
(5) Drbhit.past.3msAl+Abthe+fatherAl+wldthe+boyh+abthe+fatherhrbichit.past.3msl+toh+ildthe+boy?The father hit the boy?
(6) AErbexpress.past.3msAl+wzyrthe+ministerEnonAml+hhope+hish+s?rthe+ministerhbi?express.past.3msatacc.def.tqwt+whope+his?The minister expressed his hope?
(7) AjtmEmeet.past.3msAl+wzyrthe+ministerb+inAl+wldthe+boyh+s?rthe+ministernpgs?meet.past.3ms?mwithh+ildthe+boy?The minister met the boy?In (3), the input Arabic NP is definite and ismarked by accusative case.
A designated ruleadds the string at before the corresponding He-brew output, to mark the definite direct object.We create a node of type OBJ for both (direct)objects, with the feature PREP storing the lexicalcontent of the preposition in the target language.Finally, in the sentence level rule, we validate thatthe Hebrew verb licenses a direct object, by uni-fying the feature PREP of OBJ with the featureALLOWED PREPS of the verb VB.In (4), a similar process occurs, but this time noadditional at token is added to the Hebrew output(since the direct object is indefinite).
The samepreposition, at, is marked as the PREP feature ofOBJ (we use at to mark the direct object, whetherthe object is definite or not), and again, the fea-ture PREP of OBJ is validated against the featureALLOWED PREPS of VB.111Example (5) is created using a rule that mapsan Arabic direct object to a Hebrew prepositionalphrase introduced by a different preposition, herel ?to?.
Such rules exist for every Hebrew prepo-sition from the set of common prepositions wefocus on, since we have no prior knowledge ofwhich preposition should be generated.
We markthe lexical preposition l on the feature PREP of theHebrew OBJ node, and again, this is validated inthe sentence level against the prepositions allowedby the verb.In example (6) we use rules that map an Ara-bic prepositional phrase to a Hebrew noun phrase.Here, the Arabic preposition is not translated atall, and the Hebrew definite accusative marker atis added, depending on the definiteness of the He-brew noun phrase.
The only difference in ex-ample (7) compared to previous examples is thetranslation of the Arabic preposition into a differ-ent Hebrew preposition.
This is implemented inthe bilingual lexicon, in a lexical entry that mapsthe Arabic preposition b ?in, with?
to the Hebrewpreposition ?m ?with?.These rules help to expand the lexical vari-ety of the prepositions on one hand (as in Ex-ample (7)), while at the same time disqualify-ing some hypotheses that employ prepositionsthat are not licensed by the relevant verb, us-ing unification-style constraints.
After this pro-cess, the lattice may still include several differenthypotheses, from which the decoder statisticallychooses the best one.8 EvaluationTo evaluate the contribution of the proposedmethod, we created a test set of 300 sentencesfrom newspaper texts, which were manuallytranslated by three human translators.
Of those,we selected short sentences (up to 10 words), forwhich the bilingual lexicon used by the systemhad full lexical coverage.
This resulted in a setof 28 sentences (still with three reference transla-tions each), which allowed us to focus on the ac-tual contribution of the preposition-mapping so-lution rather than on other limitations of the MTsystem.
Unfortunately, evaluation on the entiretest set without accounting for full lexical cover-age yields such low BLEU scores that the compar-ison between different configurations of the sys-tem is meaningless.As a baseline system, we use exactly the samesetup, but withhold any monolingual linguisticknowledge regarding verb-prepositions relations:1.
We omit the restrictions (stated in the gram-mar) on which prepositions Hebrew verbs li-cense, such that each verb can be followedby each preposition.2.
We limit the lexical variance betweenprepositions in the lexicon, to only allowtranslation-pairs that occur in the bilingualdictionary.
For example, we use the map-ping of Arabic ElY ?on?
to Hebrew ?l ?on?
(which occurs in the bilingual dictionary),but remove the mapping of Arabic ElY ?on?to Hebrew b ?in?, which does not carry thesame meaning.Table 2 lists the BLEU (Papineni et al, 2002) andMETEOR (Denkowski and Lavie, 2011) scores ofboth systems.BLEU METEORBaseline 0.325 0.526With prepositions 0.370 0.560Table 2: Automatic evaluation scores.The system that incorporates linguistic knowl-edge on prepositions significantly (p < 0.05) out-performs the baseline system.
A detailed analysisof the obtained translations reveals that the base-line system generates prepositions that are not li-censed by their head verb, and the language modelfails to choose the hypothesis with the correctpreposition, if such a hypothesis is generated atall.As an example of the difference between theoutputs of both systems, consider Figure 3.
TheArabic input is given in (8).
The output of thesystem that incorporates our treatment of preposi-tions is given in (9).
Here, the Hebrew verb hdgis??emphasize?
is followed by the correct definiteaccusative marker at.
The output of the baselinesystem is given in (10).
Here, the Hebrew verbais?r ?approve?
is followed by the wrong preposi-tion, ?l ?on?, which is not licensed in this loca-tion.
Consequently, the lexical selections for thefollowing words of the translation differ and arenot as fluent as in (9), and the output is only par-tially coherent.112(8) Akdemphasize.past.3msAlHryryAlHaryryElYonAltzAm+hobligation+hisb+inAl+byAnthe+announcementAl+wzArythe+ministeriall+toHkwmpgovernmentAl+whdpthe+unityAl+wTnypthe+national?Alharyry emphasized his obligation in the ministerial announcement to the national government?
(9) alxririAlharyryhdgis?emphasize.past.3msatdef.accxwbt+wobligation+hisb+inh+hwd?hthe+announcementh+mms?ltitthe+governmentall+tomms?ltgovernmenth+axdwtthe+unityh+lawmitthe+national?Alharyry emphasized his obligation in the governmental announcement to the nationalgovernment?
(10) alxririAlharyryais?rconfirm.past.3ms?lonzkiwnpermits?l+wof+hisb+inh+hwd?hthe+announcementh+mms?ltitthe+governmentall+tomms?ltgovernmenth+axdwtthe+unityh+lawmitthe+national?Alharyry confirmed on his permit in the governmental announcement to the nationalgovernment?Figure 3: Example translation output, with and without handling of prepositions.9 ConclusionHaving emphasized the challenge of (machine)translation of prepositions, specifically betweenHebrew and Arabic, we discussed several solu-tions and proposed a preferred method.
We ex-tract linguistic information regarding the corre-spondences between Hebrew verbs and their li-censed prepositions, and use this knowledge forimproving the quality of Arabic-to-Hebrew ma-chine translation in the context of the Stat-XFERframework.
We presented encouraging evaluationresults showing that the use of linguistic knowl-edge regarding prepositions indeed significantlyimproves the quality of the translation.This work can be extended along various di-mensions.
First, we only focused on verb argu-ments that are prepositional phrases here.
How-ever, our Hebrew verb-subcategorization data in-clude also information on other types of comple-ments, such as subordinate clauses (introduced bythe complementizer s?
?that?)
and infinitival verbphrases.
We intend to extend our transfer gram-mar in a way that will benefit from this informa-tion in the future.
Second, we currently do not usethe weights associated with specific prepositionsin our subcategorization database; we are lookinginto ways to incorporate this statistical informa-tion in the decoding phase of the translation.Furthermore, our database contains also statis-tics on the distribution of nouns following eachpreposition (which are likely to function as theheads of the object of the preposition); such in-formation can also improve the accuracy of trans-lation, and can be incorporated into the system.Another direction is to acquire and incorporatesimilar information on deverbal nouns, which li-cense the same prepositions as the verbs theyare derived from.
For example, xtimh ?l hskm?signing.noun an agreement?, where the Hebrewpreposition ?l ?on?
must be used, as in the cor-responding verbal from xtm ?l hskm ?signed.verban agreement?.
We will address such extensionsin future research.AcknowledgementsWe are grateful to Alon Itai, Alon Lavie, and Gen-nadi Lembersky for their help.
This research wassupported by THE ISRAEL SCIENCE FOUN-DATION (grant No.
137/06).ReferencesEneko Agirre, Aitziber Atutxa, Gorka Labaka, MikelLersundi, Aingeru Mayor, and Kepa Sarasola.2009.
Use of rich linguistic information to trans-late prepositions and grammar cases to Basque.
InProceedings of the XIII Conference of the European113Association for Machine Translation, EAMT-2009,pages 58?65, May.Michael R. Brent.
1991.
Automatic acquisition ofsubcategorization frames from untagged text.
InProceedings of the 29th annual meeting on Associa-tion for Computational Linguistics, pages 209?214.Ted Briscoe and John Carroll.
1997.
Automatic ex-traction of subcategorization from corpora.
In Pro-ceedings of the 5th ACL Conference on Applied Nat-ural Language Processing, pages 356?363.Tim Buckwalter.
2004.
Buckwalter Arabic Morpho-logical Analyzer Version 2.0.
Linguistic Data Con-sortium, Philadelphia.Paula Chesley and Susanne Salmon-alt.
2006.
Au-tomatic extraction of subcategorization frames forFrench.
In Proceedings of the Language Resourcesand Evaluation Conference, LREC-2006.Michael Denkowski and Alon Lavie.
2011.
Meteor1.3: Automatic metric for reliable optimization andevaluation of machine translation systems.
In Pro-ceedings of the Sixth Workshop on Statistical Ma-chine Translation, pages 85?91.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
Language, Speech andCommunication.
MIT Press.Ebba Gustavii.
2005.
Target language preposition se-lection ?
an experiment with transformation-basedlearning and aligned bilingual data.
In Proceedingsof EAMT-2005, May.Nizar Habash.
2004.
Large scale lexeme basedarabic morphological generation.
In Proceedingsof Traitement Automatique du Langage Naturel(TALN-04), Fez, Morocco.Greg Hanneman, Vamshi Ambati, Jonathan H. Clark,Alok Parlikar, and Alon Lavie.
2009.
An improvedstatistical transfer system for French?English ma-chine translation.
In StatMT ?09: Proceedings ofthe Fourth Workshop on Statistical Machine Trans-lation, pages 140?144.Alon Itai and Shuly Wintner.
2008.
Language re-sources for Hebrew.
Language Resources and Eval-uation, 42(1):75?98, March.Anna Korhonen.
2002.
Subcategorisation acquisi-tion.
Ph.D. thesis, Computer Laboratory, Univer-sity of Cambridge.
Techical Report UCAM-CL-TR-530.Alon Lavie, Stephan Vogel, Lori Levin, Erik Pe-terson, Katharina Probst, Ariadna Font Llitjo?s,Rachel Reynolds, Jaime Carbonell, and RichardCohen.
2003.
Experiments with a Hindi-to-Englishtransfer-based MT system under a miserly data sce-nario.
ACM Transactions on Asian Language Infor-mation Processing (TALIP), 2(2):143?163.Alon Lavie, Shuly Wintner, Yaniv Eytani, Erik Peter-son, and Katharina Probst.
2004.
Rapid prototyp-ing of a transfer-based Hebrew-to-English machinetranslation system.
In Proceedings of TMI-2004:The 10th International Conference on Theoreticaland Methodological Issues in Machine Translation,Baltimore, MD, October.Alon Lavie.
2008.
Stat-XFER: A general search-based syntax-driven framework for machine trans-lation.
In Alexander F. Gelbukh, editor, CICLing,volume 4919 of Lecture Notes in Computer Science,pages 362?375.
Springer.Hui Li, Nathalie Japkowicz, and Caroline Barrie`re.2005.
English to Chinese translation of preposi-tions.
In Bala?zs Ke?gl and Guy Lapalme, editors,Advances in Artificial Intelligence, 18th Conferenceof the Canadian Society for Computational Stud-ies of Intelligence, volume 3501 of Lecture Notes inComputer Science, pages 412?416.
Springer, May.Christopher D. Manning.
1993.
Automatic acqui-sition of a large subcategorization dictionary fromcorpora.
In Proceedings of the 31st annual meet-ing on Association for Computational Linguistics,pages 235?242.Sudip Kumar Naskar and Sivaji Bandyopadhyay.2006.
Handling of prepositions in English toBengali machine translation.
In Proceedings ofthe Third ACL-SIGSEM Workshop on Prepositions,pages 89?94.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: a method for auto-matic evaluation of machine translation.
In ACL?02: Proceedings of the 40th Annual Meeting onAssociation for Computational Linguistics, pages311?318.Anoop Sarkar and Daniel Zeman.
2000.
Automaticextraction of subcategorization frames for Czech.In Proceedings of the 18th conference on Compu-tational linguistics, pages 691?697.Karin Kipper Schuler.
2005.
Verbnet: a broad-coverage, comprehensive verb lexicon.
Ph.D. the-sis, University of Pennsylvania, Philadelphia, PA.Lei Shi and Rada Mihalcea.
2005.
Putting piecestogether: Combining framenet, verbnet and word-net for robust semantic parsing.
In Alexander F.Gelbukh, editor, CICLing, volume 3406 of Lec-ture Notes in Computer Science, pages 100?111.Springer.Reshef Shilon, Nizar Habash, Alon Lavie, and ShulyWintner.
2010.
Machine translation between He-brew and Arabic: Needs, challenges and prelimi-nary solutions.
In Proceedings of AMTA 2010: TheNinth Conference of the Association for MachineTranslation in the Americas, November.Indalecio Arturo Trujillo.
1995.
Lexicalist machinetranslation of spatial prepositions.
Ph.D. thesis,University of Cambridge, April.Philip Williams and Philipp Koehn.
2011.
Agree-ment constraints for statistical machine translationinto German.
In Proceedings of the Sixth Workshopon Statistical Machine Translation, pages 217?226,Edinburgh, Scotland, July.114
