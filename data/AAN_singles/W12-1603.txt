Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 20?29,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics?Love ya, jerkface?
: using Sparse Log-Linear Models to BuildPositive (and Impolite) Relationships with TeensWilliam Yang Wang, Samantha Finkelstein, Amy Ogan, Alan W Black, Justine CassellSchool of Computer Science, Carnegie Mellon University{yww, slfink, aeo, awb, justine}@cs.cmu.eduAbstractOne challenge of implementing spoken di-alogue systems for long-term interaction ishow to adapt the dialogue as user and sys-tem become more familiar.
We believe thischallenge includes evoking and signaling as-pects of long-term relationships such as rap-port.
For tutoring systems, this may addi-tionally require knowing how relationships aresignaled among non-adult users.
We thereforeinvestigate conversational strategies used byteenagers in peer tutoring dialogues, and howthese strategies function differently amongfriends or strangers.
In particular, we use an-notated and automatically extracted linguis-tic devices to predict impoliteness and posi-tivity in the next turn.
To take into accountthe sparse nature of these features in real datawe use models including Lasso, ridge estima-tor, and elastic net.
We evaluate the predictivepower of our models under various settings,and compare our sparse models with stan-dard non-sparse solutions.
Our experimentsdemonstrate that our models are more ac-curate than non-sparse models quantitatively,and that teens use unexpected kinds of lan-guage to do relationship work such as signal-ing rapport, but friends and strangers, tutorsand tutees, carry out this work in quite differ-ent ways from one another.1 Introduction and Related WorkRapport, the harmonious synchrony between in-terlocutors, has numerous benefits for a range ofdialogue types, including direction giving (Cas-sell et al, 2007) or contributing to patient recov-ery (Vowles and Thompson, 2012).
In peer tutor-ing, an educational paradigm in which students ofsimilar ability tutor one another, friendship amongtutors and tutees leads to better learning (Gartner etal., 1971).
With the burgeoning use of spoken dia-logue systems in education, understanding the pro-cess by which two humans build and signal rapportduring learning becomes a vital step for implement-ing spoken dialogue systems (SDSs) that can initi-ate (and, as importantly, maintain) a successful re-lationship with students over time.
However, im-plementing a tutorial dialogue system that appropri-ately challenges students in the way that peers doso well (Sharpley et al, 1983), while still demon-strating the rapport that peers can also provide, callsfor understanding the differences in communicationbetween peer tutors just meeting and those who arealready friends.The Tickle-Degnen and Rosenthal (1990) modelprovides a starting point by outlining the compo-nents of rapport, including the finding that positiv-ity decreases over the course of a relationship.
Thepopularity of this model, however, has not dimin-ished the disproportionate attention that positivityand politeness receive in analyses of rapport (Brownand Levinson, 1978), including in the vast majorityof computational approaches to rapport-building indialogue (Stronks et al, 2002; Johnson and Rizzo,2004; Bickmore and Picard, 2005; Gratch et al,2006; McLaren et al, 2007; Cassell et al, 2007;Baker et al, 2008; Bickmore et al, 2011).
Thecreation and expression of rapport is complex, andcan also be signaled through negative, or impolite,exchanges (Straehle, 1993; Watts, 2003; Spencer-Oatey, 2008) that communicate affection and re-lationship security among intimates who can floutcommon social norms (Culpeper, 2011; Kienpoint-ner, 1997).However, it is an open question as to whether suchrudeness is likely to impress a new student on thefirst day of class.
We must better understand howand when impoliteness and other negative dialoguemoves can contribute to the development and ex-pression of the rapport that is so important in educa-tional relationships.
In this analysis, then, we beginwith a corpus of tutoring chat data annotated witha set of affectively-charged linguistic devices (e.g.complaining, emoticons), and then differentiate be-tween the linguistic devices that friend and strangerinterlocutors employ (with friendship standing as aproxy for pre-existent rapport) and the resulting so-cial effects or functions of those devices on the part-ners.Since our ultimate goal is to build an SDS thatcan adapt to the user?s language in real time, wealso automatically extract lexical and syntactic fea-tures from the conversations.
And, in order to deter-mine what the system should say to evoke particular20responses, we predict social effects in partner twofrom the use of the linguistic devices in partner one.Since we want to understand how the system candeal with newly met peers as well as peers whohave become friends, we develop and evaluate ourmodel on dyads of friends and then evaluate thesame model with dyads of strangers, to examinewhether dyads with less a priori rapport react dif-ferently to the same linguistic devices.Of course, in addition to understanding the phe-nomenon of rapport in all of its complexity, a majorchallenge for building rapport-signaling SDS is toconstruct a compact feature space that capture onlyreliable rapport signals and generalizes well acrossdifferent speakers.
Of course phenomena such as in-sults, complaints and pet names, no matter how im-portant, appear relatively rarely in data of this sort.Training discriminative models with maximum like-lihood estimators (MLE) on such datasets usually re-sults in assigning too much weight on less frequentsignals.
This standard MLE training method notonly produces dense models, but may also overes-timates lower frequency features that might be unre-liable signals and overfit to a particular set of speak-ers.
In recent studies on speaker state prediction thatuse lexical features, it has been shown that MLEestimators demonstrate large performance gaps be-tween non-overlapping speaker datasets (Jeon et al,2010; Wang et al, 2012a).On the other hand, recent studies on `1/`2based group penalty for evaluating dialogue systems(Gonza?lez-Brenes and Mostow, 2011), structuredsparsity for linguistic structure prediction (Mar-tins et al, 2011), and discovering historical legalopinions with a sparse mixed-effects latent vari-able model (Wang et al, 2012b) have all shownconcrete benefits of modeling sparsity in language-related predictive tasks.
We therefore apply sparsity-sensitive models that can prevent less frequentfeatures from overfitting.
We start with the `1-regularized Lasso (Tibshirani, 1994) model, since,compared to other covariance matrix based sparsemodels, such as sparse Principal Component Anal-ysis (PCA) and sparse Canonical Correlation Anal-ysis (CCA), the Lasso model is straightforward andrequires fewer computing resources when the fea-ture dimension is high.
Hence, we compare the con-tributions of both automated features and annotatedfeatures using the proposed Lasso model to predictimpoliteness and positivity.In addition to Lasso and a logistic regression base-line, we introduce two alternative penalty models:the non-sparse ridge (le Cessie and van Houwelin-gen, 1992) estimator, and an elastic net model (Zouand Hastie, 2005).
The ridge estimator applies aquadratic penalty for feature selection, resulting ina smooth objective function and a non-sparse fea-ture space, which can be seen as a strong non-sparsepenalty model.
We investigate the elastic net model,because it balances the pros and cons of Lasso andridge estimators, and enforces composite penalty.
Inaddition to the model comparisons, by varying thedifferent sizes of feature windows (number of turnsin the dialogue history), we empirically show thatour proposed sparse log-linear model is flexible, en-abling the model to capture long-range dependency.This approach also allows us to extend previouswork on speaker state prediction.
Although speakerstate prediction has attracted much attention in thedialogue research community, most studies have fo-cused on the analysis of anger, frustration, and otherclassic emotions (Litman and Forbes-Riley, 2004;Liscombe et al, 2005; Devillers and Vidrascu, 2006;Ai et al, 2006; Grimm et al, 2007; Gupta and Ni-tendra., 2007; Metallinou et al, 2011).
Recently,Wang and Hirschberg (2011) proposed a hierarchi-cal model that detects level of interest of speakersin dialogue, using a multistream prediction feedbacktechnique.
However, to the best of our knowledge,we are among the first to study the problem of auto-matic impoliteness and positivity prediction in dia-logue.
Because our ultimate goal is to build an SDSthat responds to users?
language use over time, thefeatures from the user?s target turn that the model isaiming to predict are not observable, which rendersthe task more difficult than previous speaker statedetection tasks.Our main contributions are three-fold: (1) analy-sis of linguistic devices that function to signal rap-port among friends - and their effects on non-frienddyads; (2) detailed analyses of language behaviorfeatures that predict these rapport behaviors - bothimpoliteness and positivity - in the next turn ofteenagers?
peer tutoring sessions; (3) an evaluationof non-sparse and sparse log-linear models for pre-dicting impoliteness and positivity.By understanding the signals of rapport that a per-son is likely to display in response to various lin-guistic devices, we can begin to build an SDS thatcan anticipate the social response and adapt to therapport-signaling efforts of its partner, both as anewly introduced technology, and, over time, as asystem with whom the user has a rapport.2 The CorpusWe use the data from a previous study evaluating theimpact of a peer tutoring intervention that monitoredstudents?
collaboration and in some cases providedadaptive support (Walker et al, 2011).
In the inter-vention, peer tutors observed the work of their tutee21and supported them through a chat interface as theycompleted algebra problems.
The system logged allchat and other information about the problem steps.Participants were 130 high school students (81 fe-male) in grades 7-12 from one American high schoolwith some prior knowledge of the algebra material.Participants were asked to sign up for the study witha friend.
Those who were interested but were un-able to participate with a friend, were matched withanother unmatched participant.
In an after-schoolsession, participants first took a 20-minute pre-teston the math concepts, and then spent 20 minutesworking alone with the computer to prepare for tu-toring.
One student in each dyad was then randomlyassigned the role of tutor, while the other was giventhe role of tutee, regardless of relative ability.
Theyspent the next 60 minutes engaging in tutoring.
Fi-nally, students were given a domain posttest isomor-phic to the pretest.54 dyads signed up as friends and 6 were un-matched strangers.
To compare behavior betweenfriends and strangers in the face of very differentdata set sizes we use 48 friend dyads for training,and select 6 friend and 6 stranger dyads as two sep-arate test sets.
The total number of utterances in thefriend training set, friend test set, and stranger testset are 4538, 468 and 402.
To perform turn-basedprediction experiments, we concatenate the text inthe utterances by the same speaker into a single turn,and perform an ?OR?
operation1 on features (SeeSection 3 for details) in multiple utterances of thesame speaker to generate the turn-based binary fea-tures.3 Feature EngineeringIn this section, we describe both the annotated andautomatically extracted features analyzed.3.1 Annotated Features and Labels2To understand what linguistic devices participated inpositivity and impoliteness during tutoring, we an-notated all 60 dyads for surface-level language be-haviors such as complaints, challenges (Culpeper,1996) and praise.
We also automatically identi-fied chat features that socially color the communi-cation, such as excessive punctuation[P] or capital-ization[Ca].
Utterances could receive more than onecode, and inter-rater reliability ranged from K=.71to K=1.Because these linguistic behaviors may serve arange of different functions in context, such as rude1If any of the utterances within one turn has this featureturned on, then we say that we have observed this feature inthis turn.2We thank Erin Walker for data collection and annotation.language serving to cement a relationship (Arding-ton, 2006), or teasing to increase rapport (Straehle,1993), we also annotate the social functionalityof each utterance in context, in terms of positivity(K=.79)3 and impoliteness (K=.76), which are seenas holding down opposite kinds of social functional-ity (Terkourafi, 2008).
Details of annotation can befound in our recent work (Ogan et al, 2012).Language Behavior FeaturesLanguage behavior features were annotated bytwo raters, based on previous work on impo-liteness (Culpeper, 1996), positivity (Boyer etal., 2008), and computer-mediated communica-tion (Herring and Zelenkauskaite, 2009), as fol-lows:.?
Insults[Di] (?=1): Personalized negative voca-tives or references.
eg.
?you are so weird.??
Challenges[Ch] (?
=.91): Directly questioningpartner?s decision or ability.
eg.
Partner 1:?see I am helping?, Partner 2: ?barely.??
Condescensions / brags[C] (?=1): Assertingauthority or partner?s inferiority.
eg.
Tutee:?nothing you have done has affected me whatso ever.??
Message enforcer[Ef] (?=.85): Emphasizingtext or attracting partner?s attention.
eg.
?Earthto Erin.??
Dismissal / Silencer / Curse[Cu] (?
=.76): As-serting unimportance of contribution/partner.eg.
?shuttttt up computer.??
Pet name[Pe] (?
= .9): Vocatives that may ormay not be insulting.
eg.
?whats up homie???
Criticisms / exclusive complaints[EC] (?=.8):Negative evaluation of partner.
eg.
?You are sobad at this dude.??
Inclusive complaints[I] (?=.78): Complaintsdirected outside the partner, such as at the task,computers, or study.
eg.
?This is really dumb,ya think???
Laughter[L] (?=1): eg.
?haha?, ?lol??
Off-task[O] (?=.71): Doesn?t pertain to or ad-vance tutorial dialogue.
eg.
?Coming over afterthis?
?Impoliteness and Positivity LabelsWhile the surface-level features were coded basedon a single utterance, context determined the labelsfor impoliteness and positivity, including the recenttone of the dialogue and the partner?s response tothe utterance.
Utterances were coded as positivity(?=.79) when they included goals that directly addedpositive affect into the exchange through praise, em-pathy, reassurance, cooperative talk (McLaren et al,3We use Cohen?s kappa in this study.222011), task enthusiasm, and making or respondingto jokes.
Impoliteness (?=.76) included both coop-eratively rude utterances such as teasing (typical eg.
?hahah you?re the worst tutor ever?)
and uncooper-atively rude utterances that may cause offense (typ-ical eg.
?um why don?t you try actually explaininurself..?)
(Kienpointner, 1997).3.2 Automated FeaturesTo compare the performance between what could beautomatically extracted from dialogue and hand an-notation, we extracted 2,872 unigram and 12,016 bi-gram features from the text corpus.
Using the Stan-ford PoS tagger4 with its attached model, we alsoextracted 46 common part-of-speech tags from thetext.
In addition to the above lexical and syntac-tic features, we automatically extracted the capital-ization features[Ca] that have at least one full word(eg.
?CALM DOWN?)
(Chovanec, 2009).
Sincea recent text prediction task (Wang and McKeown,2010) observed benefits from modeling punctua-tion features[P], we extracted the expressive punc-tuation that included at least one exclamation pointor more than one question-mark (eg.
?I don?t getit?!??!?)
(Crystal, 2001).
We used a smiley dictio-nary5 to extract the emoticons[E] that convey emo-tional states (Sa?nchez et al, 2006) from text.4 Sparse Log-Linear ModelsWe formulate our impoliteness and positivity predic-tion problems as binary classifications.
To do this,we estimate the label y?t ?
Bernoulli(??).
First, weintroduce a standard log-linear parametrization6 toour predictive tasks:?
?~yt =exp?i ~wi ~fi(~yt)1 + exp?i ~wi ~fi(~yt), (1)where ~f(~yt) is a set of feature functions computedon the observation vector ~yt.
The term ~wi puts aweight on feature i for predicting impoliteness, andour estimation problem is now to set these weights.The log-likelihood and the gradient are:` =?tyt log ?
?~yt + (1?
yt) log(1?
?
?~yt) (2)?`?
~w =?t(???~yt?
~w)(yt??~yt?
1?
yt1?
??~yt)(3)???~yt?
~w =(?
?~yt ?
(?
?~yt)2)~f(~yt), (4)4http://nlp.stanford.edu/software/tagger.shtml5http://www.techdictionary.com/emoticon.html6We thank Jacob Eisenstein for the formulation of logisticregression model.so the parameters can be set using gradient as-cent.
To control the overall complexity, we can ap-ply regularized models on the elements of ~w.
Asparsity-inducing model, such as the Lasso (Tibshi-rani, 1994) or elastic net (Zou and Hastie, 2005)model, will drive many of these weights to zero, re-vealing important interactions between the impolite-ness/positivity label and other features.
Instead ofmaximizing the log-likelihood, we can minimize thefollowing Lasso model that consists of the negativelog-likelihood loss function:min(?
`+?i?1||~wi||)(5)Since the Lasso penalty can introduce discontinu-ities to the original convex function, we can alsoconsider an alternative non-sparse ridge estima-tor (le Cessie and van Houwelingen, 1992) that hasthe convex property:min(?
`+?i?2||~wi||2)(6)In addition to the Lasso and ridge estimators, thecomposite penalty based elastic net model balancesthe sparsity and smoothness properties of both Lassoand ridge estimators:min(?
`+?i?1||wi||+?i?2||wi||2)(7)Our log-linear model is quite flexible; by compar-ing various restrictions, we can test different featureswhen modeling impoliteness and positivity.
In addi-tion, the model can incorporate features from previ-ous time windows, which requires much less compu-tational complexity compared to standard high orderMarkov models.
We use the L-BFGS method (Liuand Nocedal, 1989) for the numerical optimization.5 Empirical ExperimentsWe predict impoliteness vs. non-impoliteness andpositivity vs. non-positivity of an interlocutor in theimmediate future turn, given only information fromcurrent/previous turns.
Because accuracy, precision,recall and F-measure are threshold-based point esti-mation metrics that might prevent one from observ-ing the big picture of system performance, we con-sider the Receiver Operating Characteristic (ROC)metric to evaluate the dynamics of the true posi-tive rate vs. the false positive rate (Hanley and Mc-Neil, 1982) in our system.
We mainly use Area Un-der Curve (AUC) as a metric to compare classifiers,since it maps the ROC metric to a single scalar valuerepresenting expected performance.
A random clas-sifier will have an AUC of 0.5 (Fawcett, 2006).23Models P Ca E L O Ef Pe Di C EC Ch Cu IImpoliteness PredictionTr-Te .44 -1.10 .62 .72 .09 .64 .09 1.29 .96 .89 .69 .77 -0.19Te-Tr -2.48 .54 -0.26 0.15 .59 1.62 .24 .22 .89 .72 .75 .04 -0.18Positivity PredictionTr-Te -0.87 .19 .36 .55 1.06 -0.62 .69 -1.63 -1.57 .16 -0.41 1.22 .86Te-Tr -1.39 -0.46 .70 .48 .46 .33 .62 -0.71 .70 -0.65 -0.47 -0.54 .78Table 1: Comparing the Learned Weights of Different Features when Predicting the Partner?s Impoliteness in a Non-Sparse Log-Linear Model.
Tr-Te: predict tutee turn with tutor turn.
Te-Tr: predict tutor turn with tutee turn.
For fullname of features, see Section 3.5.1 Comparing the Learned Weights ofDifferent FeaturesIn our previous analysis of these data (Ogan et al,2012), a PCA method allowed us to group linguisticbehaviors in order to address the issue of data spar-sity.
With the use of log-linear models, we are ableto investigate the contributions of individual lan-guage behaviors in one student?s turn to the predic-tion of social functions in their partner?s next turn.
Inthis experiment, we evaluate the weights of variouslinguistic devices in a standard logistic regressionmodel.
We found that behaviors commonly asso-ciated with impoliteness were predictors of partnerimpoliteness in the next turn, while positive behav-iors such as laughter were predictors of upcomingpositivity.
SDSs can leverage this knowledge to takethe partners lead during a tutoring session, using thepartners positivity or impoliteness to determine theaffect of the systems upcoming move.
As we intendto develop a system that acts as a tutee, however, wefurther divided the analysis by tutoring role, inves-tigating how partners in different roles employ lan-guage features differently, such that the system canact in accordance with its given role.
Table 1 showsthe results.Similarly to the collapsed factors in our previouswork, we found here that tutors and tutees do infact use language behaviors differently, and to ac-complish different social functions.
Effectively, thismeans that certain language behaviors may instigateimpoliteness when said by one partner, but lead topositivity when expressed by the other.
For exam-ple, tutee bragging predicts a response of positiv-ity on behalf of the tutor (~w(TE)C = .7), perhaps be-cause the tutor wants to be supportive of a prote?ge?
?sself-efficacy and success.
Conversely, when the tu-tor brags during a peer tutoring dialogue, the tu-tee, who may feel threatened by the tutors bravado,is extremely likely to respond with impoliteness (~w(TR)C = .96).
In a peer tutoring paradigm, whenthe more powerful partner (the tutor) expresses dom-inance through self-inflation, the subordinate part-ner may use impoliteness to regain some social con-trol.
On the other hand, some language behaviorsactively work to tear down this power imbalance,such as inclusive complaining, where the partnerstake an us against the task approach, building sol-idarity through complaining about the experiment.These utterances predict positivity whether used bythe tutor ( ~w(TR)I = .86) or tutee ( ~w(TE)I = .78).Other comparisons between weighted features byrole demonstrate similarly theoretically-motivatedfindings that shed light on how language is used toachieve social functions.5.2 Comparing the Contributions of DifferentFeatures on Friend and Stranger DatasetsA previous study (Ogan et al, 2012) on these samedata seemed to indicate that negative conversationalstrategies composed of linguistic devices such ascomplaining and insults were correlated with learn-ing in the friend dyads and negatively correlatedwith learning in strangers.
However the small num-ber of stranger dyads prevented them from draw-ing conclusions about particular linguistic devicesfrom the data.
Here, we empirically show the pre-dictive performance of different feature sets on bothfriend and stranger test sets in Table 2 , using asparse Lasso model with features from only thecurrent turn.
In the impoliteness prediction task,when predicting on the test set that consists of onlyfriends, we observe statistically significant improve-ment over a random baseline, using surface-levellanguage behavior features, lexical, lexical + syn-tactic, all automatic, and all features.
When com-bining all features, the best AUC is .621.
The auto-matic features, mainly including n-grams and part-of-speech tags, have emerged as a useful automatedfeature space.
On the other hand, we do not observeany significant results on the stranger datasets, sug-gesting that strangers do not respond with impolite-ness in the same way that friends do.
When pre-dicting positivity on the friend dataset, we see that24the performance of surface-level language behaviorfeatures has dropped from the first task, and the sta-tistical t-test is non-significant when comparing toa random baseline.
This is not surprising, becausewe have shown in the previous section that surface-level language behavior features are strong indica-tors of impoliteness, but might not have advantagesin predicting positivity for friends.
Interestingly, theautomated features outperform the combination ofall features, indicating a promising future for the ac-tual deployment of an SDS that can interact usingappropriate positivity and impoliteness.When predicting positivity in the stranger dataset,we find the opposite trend.
In contrast to the impo-liteness prediction task, the overall performance onthe stranger dataset improved, and the lexical, lexi-cal+syntactic, and all feature combination have sig-nificantly outperformed the chance baseline.
Theseresults suggest that positivity is a predictable behav-ior among strangers, who may all express uniformpositivity across all dyads, while it is the impolite-ness that is predictable among friends.
Perhaps itis that through the development of a rapport with apartner, the particular ways in which positivity is ex-pressed becomes personalized to the dyad, and canno longer be applied to other groups who have theirown expressions of positivity.
In other words, un-like in Tolstoy?s world, here unhappy families are allalike; every happy family is happy in its own way.We must look to the easily-predictable impolitenessamong friends instead, arguing strongly for the in-clusion of impoliteness in a model of rapport.5.3 Comparing Logistic Regression, Lasso,Ridge, and Elastic NetWhile our previous work (Ogan et al, 2012) demon-strated that PCA is a useful feature selection methodwhen there are only a dozen features, in this experi-ment, the dimension of our feature space is substan-tially higher, which aligns to the size of vocabulary.Thus, covariance-based feature selection methods,such as PCA, might be too slow.
Here we comparethe performances of standard MLE trained logisticregression, Lasso, non-sparse ridge, and elastic netmodels.
In particular, we demonstrate the predic-tive power of Lasso and elastic net models, varyingdistinct levels of sparsity.
In the Figure 1, we showthe comparison of three different models in the im-politeness prediction task.
The horizontal axis rep-resents different values of regularization coefficient?.
For the Lasso model and the elastic net model,increasing the value ?
will result in a sparser featurespace, and we set the ?
= ?1 = ?2 in the elastic netmodel to promote same level of sparsity and smooth-ness.
The result at ?
= 0 represents the standardFeature Sets F-AUC p S-AUC pImpoliteness PredictionRandom .500 - .500 -Behavior .596 .017 .505 .473Lex .599 .014 .435 .819Lex + POS .605 .009 .425 .857All Auto .591 .022 .451 .751All Features .621 .003 .427 .850Positivity PredictionRandom .500 - .500 -Behavior .549 .141 .527 .302Lex .623 .003 .601 .025Lex + POS .646 .001 .587 .047All Auto .651 .001 .577 .070All Features .641 .001 .608 .019Table 2: Comparing contributions of different featurestreams on both friend and stranger testsets with Lassomodel when predicting impoliteness and positivity of thenext turn using only features from the current turn.
( F-:the friend test set.
S: the stranger test set.
p: one-tailedp-value by comparing to a random classifier.
Behavior:detailed surface-level language behavior features definedin Section 3.
Lex: unigram and bigram.
POS: part-of-speech features.
All Auto: all automatically extractedfeatures (Lex + POS + punctuation + caps + emoti-cons).
)non-sparse logistic regression model, which obtainsan AUC of .563.
When introducing penalty for largeweights in this standard model, .4 to .5 significantimprovements (p = .003 for Lasso, p = .007 forridge, and p = .004 for elastic net) of AUC areobserved from Lasso, ridge and elastic net modelswhen ?
= 1.
The elastic net model that balancessparsity and smoothness, has obtain the best resultin this experiment.
The best result of elastic netmodel is .63 when ?
= 7.
This experiment showsthat all three penalty models have outperformed thenon-sparse logistic regression model.
The elastic netmodel, which balances sparisty and smoothness, ob-tains the best results when predicting impoliteness.Figure 2 shows the comparison of three models onthe friend dataset in the positivity prediction task.When ?
= 0, the standard logistic regression modelhas an AUC of .638.
When increasing the ?
to 1,both Lasso and elastic net models have shown sig-nificant improvements (both p < .001) in AUC, butnot the non-sparse ridge estimator.
The Lasso modelis found to be the best model in this task: we obtainbetter results when the model gets sparser until themodel is too sparse when ?
= 6.
In contrast to theexperiment in Figure 1, we see that both the ridgeand elastic net models do not very strong advantages25in this positivity prediction task.
We hypothesizethat the reason why Lasso works better in the pos-itivity task is that the frequency of positivity labelsis substantially higher than the impoliteness labels inour corpus, so that a Lasso model that enforces full`1 penalty fits better in this task.
In contrast, sincethe impoliteness label is less frequent, a denser elas-tic net composite penalty model that preserve criticalfeatures, works the best in the impoliteness predic-tion task.
In general, we can see that sparse log-linear models outperform standard log-linear mod-els as well as non-sparse ridge estimators in the twotasks.Figure 1: Comparing Impacts of Different Levels of Spar-sity on the Friend Dataset When Predicting Impolitenesswith Lasso, Ridge, and Elastic Net ModelsFigure 2: Comparing Impacts of Different Levels of Spar-sity on the Friend Dataset When Predicting Positivitywith Lasso, Ridge, and Elastic Net Models5.4 Comparing Impacts of Different FeatureWindow SizesA practical problem for parameter estimation in bothgenerative and discriminative models for dialogueprocessing is to evaluate how much history the sys-tem should take into account, so that it can haveenough information to make correct predictions.
Inthis experiment, we investigate the impact of usingdifferent feature window sizes using the elastic netmodel.
We compare the two-tailed student t-test be-tween the baseline that only uses features from thecurrent turn and models that use current + previousn turn(s).
For the friend dataset, when only usingthe features from the current turn to predict the im-politeness in the immediate next turn, we observean AUC of .619.
The best result is obtained whenwe combine the previous two turns together with thecurrent feature turn: an AUC of .635, significantlybetter (p = .03) than only using the current turn win-dow.
The patterns on the non-friend dataset are lessclear, while the model obtains the best result whenwindow size is +3 previous turns, the improvementis not significant (p = .962).
In the positivity task,we also observe benefits to incorporating larger fea-ture windows.
The AUC on the friend test set startsat .638, when only using the current feature windowin the elastic net model.
After incorporating largerfeature windows, we obtain the best result of .675 atthe +4 window (p = .04).
Similarly, the AUC onnon-friend test set initializes at .618, but climbs to.632 at the +4 window.6 Error Analysis and DiscussionWe performed an error analysis to understand thecontexts under which our model failed to accuratelypredict a students?
social response, and discuss theimplications of these examples based on a theoret-ical understanding of the roles of tutors and tuteesas well as friends and strangers.
The following isan example error produced when looking only at theprevious turn to predict the current turn:?
Tutee (impolite): ?dude thats def wrong i gottasubract 16m not just 16?
(the current turn)?
Tutor (non-impolite): ?16m is what has to besubtracted from both sides?
(the next turn, pre-dicted incorrectly)In the segment above the tutee challenges the tutorby pointing out a ?def?
mistake; the tutor respondswith a task-oriented contribution that moves the di-alogue forward, but does not escalate the face threat(Ogan et al, 2012).
And, in fact, if we look onemore turn back in the history, the tutor once againuses calm language: ?wait it says youre wrong i dontknow why ust wait?.
The increased window sizeis implicitly evoking the differential conversationalstrategies of tutors vs. tutees.
And while the currentdata set is too small to build separate models for tu-tors and tutees, in this case (and based on the priorwork in Ogan et al, 2012), accounting for role dis-tinctions that differentiate strategies taken by tutorsand tutees is the likely reason behind the improve-ment due to window size.Conversely to the friend data set, the false nega-tives that occur when predicting impoliteness in thestranger data set are not improved by increasing the26window size, as is demonstrated in the following ex-change:?
Tutor (non-impolite): ?subtract ym from bothsides.??
Tutee (non-impolite): ?first step?
first Step???
Tutor (non-impolite): ?subtract hb from bothsides?
(the current turn)?
Tutee (impolite): ?first step?
FIRSTSTEP???????????
(the next turn, predicted in-correctly)The impolite tutee utterance at turn 4 is predictedto be non-impolite when analysis is limited to theprevious turn, as is also shown in the first examplein this section.
However, unlike the previous ex-ample which improved with an expanding windowsize, looking back to turns 1 and 2 does not improvethe model.
While we do not have enough strangerdyads to completely explore this phenomenon, itseems clear that strangers?
responses do not followthe same patterns as friends.
The current unpre-dictability of strangers can be due to a number ofsocial phenomena, such as less affect (both posi-tive and negative) overall, which results in a differ-ent conversational flow.
Less overall affect meansthat there is less likely to be useful information inthe previous utterances.
This is an important dis-tinction between designing models for dyads withrapport and those without, which is a primary con-cern in the development of social SDSs.
Amongstrangers, other techniques may need to be used toincrease model accuracy, such as looking at the con-tent of the utterances to determine whether or not aspeaker had been repeating themselves, as is shownin this example, which could likely be an indicatorof rudeness.As a final example of how the error analysiscan reveal important phenomena for future study,when examining the prediction of positivity on thestranger test set, we first observe that emoticonsare useful indicators of positivity.
However, some-times emoticons serve quite different social func-tions, which leads to false positives:?
Tutor (non-positivity): ?Simplify !
:)?
(the cur-rent turn)?
Tutee (non-positivity): ?y didnt it chang?
(thenext turn, predicted incorrectly)Here, the smiley face is used by the tutor primarilyto mitigate the face threat of an impolite command.However, since the experiment reported in Section6.1 shows that our model attributes more weight toemoticons when predicting positivity, the model errson this utterance.
Here the error analysis suggeststhat in fact we might need to investigate more com-plicated latent variable models to capture the subtlesocial functionality of some language use in context.7 ConclusionLong-term relationships involve the expression ofboth positive and negative sentiments and, paradox-ically, both can serve to increase closeness.
In thispaper, we have addressed the novel task of predict-ing impoliteness and positivity in teenagers?
peer tu-toring conversations, and our results shed light onwhat kinds of behaviors evoke these social functionsfor friends and for strangers, and for tutors and tu-tees.
Our investigation has successfully predictedimpoliteness and positivity on the basis of both an-notated and automatically extracted features, sug-gesting that a dialogue system will one day be able toemploy analyses such as these to signal relationshipswith users.
And while social features such as thosewe annotated are naturally quite rare in dialogue, ourquantitative experiments have demonstrated the ca-pabilities of modeling sparsity in log-linear models:elastic net and Lasso models outperformed standardlogistic regression model and the non-sparse ridgepenalty model.We found that positivity is much more predictablefor strangers than is impoliteness, while the oppo-site was true for friends.
This could lend support forthe importance of positivity as a rapport-signalingfunction in the early stages of a relationship (asin (Tickle-Degnen and Rosenthal, 1990)), and indi-cating the need for further research on the increasingimportance of impoliteness as a rapport signal overthe course of relationship development.We also found that performance on the predictiontasks increased with larger feature window sizes,particularly for impoliteness among friends and pos-itivity among strangers.
From our error analysis,we see that this improvement may arise because dif-ferent behaviors predict impoliteness and positivitybased on the social role of the speaker.
Thus tu-tee bragging predicts positivity in tutors, while tu-tor bragging negatively predicts positivity among tu-tees.
The power differential between the two maylead tutees to want to take tutors ?down a peg?
whiletutors struggle to maintain the position of power inthe dyad.While results such as these may seem specific toteenage peer tutors, the general conclusion remains,that linguistic devices have different social functionsin different contexts, and dialogue systems that in-tend to spend a lifetime on the job will do well toadapt their language to the stage of relationship witha user, and the social role they play.27ReferencesHua Ai, Diane J. Litman, Kate Forbes-Riley, Mihai Ro-taru, Joel Tetreault, and Amruta Purandare.
2006.Using system and user performance features to im-prove emotion detection in spoken tutoring dialogs.
InProceedings of the Ninth International Conference onSpoken Language Processing (Interspeech 2006).Angela M. Ardington.
2006.
Playfully negotiated activ-ity in girls talk.
Journal of Pragmatics, 38(1):73 ?
95.Rachel E. Baker, Alastair J. Gill, and Justine Cassell.2008.
Reactive redundancy and listener comprehen-sion in direction-giving.
In Proceedings of the 9thSIGdial Workshop on Discourse and Dialogue.Timothy W. Bickmore and Rosalind W. Picard.
2005.Establishing and maintaining long-term human-computer relationships.
ACM Transactions onComputer-Human Interaction.Timothy Bickmore, Laura Pfeifer, and Daniel Schulman.2011.
Relational agents improve engagement andlearning in science museum visitors.
In Proceedingsof the 10th international conference on Intelligent vir-tual agents, IVA?11.Kristy Elizabeth Boyer, Robert Phillips, Michael Wallis,Mladen Vouk, and James Lester.
2008.
Balancingcognitive and motivational scaffolding in tutorial di-alogue.
In Proceedings of the 9th international con-ference on Intelligent Tutoring Systems, ITS ?08.Penelope Brown and Stephen Levinson.
1978.
Uni-versals in language usage: Politeness phenomena.
InQuestions and politeness: Strategies in social interac-tion.Justine Cassell, Alastair J. Gill, and Paul A. Tepper.2007.
Coordination in conversation and rapport.
InProceedings of the Workshop on Embodied LanguageProcessing, EmbodiedNLP ?07, pages 41?50, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Jan Chovanec.
2009.
Simulation of spoken interaction inwritten online media texts.
Brno Studies in English.David Crystal.
2001.
Language and the internet.
Cam-bridge University Press.Jonathan Culpeper.
1996.
Towards an anatomy of impo-liteness.
In Journal of Pragmatics.Jonathan Culpeper.
2011.
Impoliteness: Using languageto cause offence.Laurence Devillers and Laurence Vidrascu.
2006.
Real-life emotions detection with lexical and paralinguisticcues on human-human call center dialogs.
In Proceed-ings of the Ninth International Conference on SpokenLanguage Processing (Interspeech 2006).A Gartner, M Kohler, and F Riessman.
1971.
Childrenteach children: Learning by teaching.
In New York andLondon: Harper and Row.Jose?
Gonza?lez-Brenes and Jack Mostow.
2011.
Whichsystem differences matter?
using l1/l2 regulariza-tion to compare dialogue systems.
In Proceedings ofthe SIGDIAL 2011 Conference, pages 8?17, Portland,Oregon, June.
Association for Computational Linguis-tics.Jonathan Gratch, Anna Okhmatovskaia, FrancoisLamothe, Stacy Marsella, Mathieu Morales, Rick J.van der Werf, and Louis-Philippe Morency.
2006.Virtual rapport.
In Proceedings of the InternationalConference on Intelligent Virtual Agents (IVA 2006).M.
Grimm, E. Mower K. Kroschel, and S. Narayanan.2007.
Primitives-based evaluation and estimation ofemotions in speech.
In Speech Communication.P.
Gupta and R. Nitendra.
2007.
Two-stream emo-tion recognition for call center monitoring.
In Pro-ceedings of the 8th Annual Conference of the Inter-national Speech Communication Association (Inter-speech 2007).Susan C. Herring and Asta Zelenkauskaite.
2009.
Sym-bolic capital in a virtual heterosexual market.
In Writ-ten Communication.Je Hun Jeon, Rui Xia, and Yang Liu.
2010.
Level of in-terest sensing in spoken dialog using multi-level fusionof acoustic and lexical evidence.
In Proceedings of the11th Annual Conference of the International SpeechCommunication Association (Interspeech 2010), IN-TERSPEECH 2010.W.
Lewis Johnson and Paola Rizzo.
2004.
Politeness intutoring dialogs: run the factory, thats what id do.
InIntelligent Tutoring Systems, Lecture Notes in Com-puter Science.Manfred Kienpointner.
1997.
Varieties of rudeness:types and functions of impolite utterances.
In Func-tions of Language.S.
le Cessie and J.C. van Houwelingen.
1992.
Ridgeestimators in logistic regression.
Applied Statistics,41(1):191?201.Jackson Liscombe, Julia Hirschberg, and Jennifer J. Ven-ditti.
2005.
Detecting certainness in spoken tutorialdialogues.
In Proceedings of the 6th Annual Confer-ence of the International Speech Communication As-sociation (Interspeech 2005).D.
Litman and K. Forbes-Riley.
2004.
Predicting stu-dent emotions in computer-human tutoring dialogues.In Proceedings of the 42nd Annual Meeting of the As-sociation for Computational Linguistics (ACL 2004).Dong C. Liu and Jorge Nocedal.
1989.
On the lim-ited memory bfgs method for large scale optimization.Mathematical Programming, 45:503?528.Andre Martins, Noah Smith, Mario Figueiredo, and Pe-dro Aguiar.
2011.
Structured sparsity in structuredprediction.
In Proceedings of the 2011 Conference on28Empirical Methods in Natural Language Processing,pages 1500?1511, Edinburgh, Scotland, UK., July.
As-sociation for Computational Linguistics.Bruce M. McLaren, Sung-Joo Lim, David Yaron, andKen Koedinger.
2007.
Can a polite intelligent tutor-ing system lead to improved learning outside of thelab?
In Proceedings of the 2007 conference on Arti-ficial Intelligence in Education: Building TechnologyRich Learning Contexts That Work.Bruce McLaren, DeLeeuwm Krista E., and Richard E.Mayer.
2011.
Polite web-based intelligent tutors: Canthey im-prove learning in classrooms?
In Computersand Education.Angeliki Metallinou, Martin Wollmer, AthanasiosKatsamanis, Florian Eyben, Bjorn Schuller, andShrikanth S. Narayanan.
2011.
Context-sensitivelearning for enhanced audiovisual emotion classifica-tion.
IEEE Transactions on Affective Computing.Amy Ogan, Samantha Finkelstein, Erin Walker, RyanCarlson, and Justine Cassell.
2012.
Rudeness andrapport: Insults and learning gains in peer tutoring.
InProceedings of the 11 International Conference on In-telligence Tutoring Systems (ITS 2012).J.
Alfredo Sa?nchez, Norma P. Herna?ndez, Julio C. Pena-gos, and Yulia Ostro?vskaya.
2006.
Conveying moodand emotion in instant messaging by using a two-dimensional model for affective states.
In Proceedingsof VII Brazilian symposium on Human factors in com-puting systems, IHC ?06, pages 66?72, New York, NY,USA.
ACM.A.
Sharpley, J. Irvine, and C. Sharpley.
1983.
An exami-nation of the effectiveness of a cross-age tutoring pro-gram in mathematics for elementary school children.In American Educational Research Journal.Helen Spencer-Oatey.
2008.
Face (im)politeness andrapport.
In Culturally Speaking: Culture, Communi-cation and Politeness Theory.Carolyn A. Straehle.
1993.
?samuel??
?yes dear??
teas-ing and conversatrion rapport.
In Framing in Dis-course.Bas Stronks, Anton Nijholt, Paul van Der Vet, DirkHeylen, and Aaron Machado.
2002.
Designing forfriendship: Becoming friends with your eca.
In Pro-ceedings of Embodied conversational agents - let?sspecify and evaluate (AAMAS).Marina Terkourafi.
2008.
Toward a unified theory of po-liteness, impoliteness, and rudeness.
Impoliteness inlanguage: studies on its interplay with power in the-ory and practice.Robert Tibshirani.
1994.
Regression shrinkage and se-lection via the lasso.
Journal of the Royal StatisticalSociety, Series B, 58:267?288.Linda Tickle-Degnen and Robert Rosenthal.
1990.
Thenature of rapport and its nonverbal correlates.
In Psy-chological Inquiry.Kevin E. Vowles and Miles Thompson.
2012.
Thepatient-provider relationship in chronic pain.
In Psy-chiatric Management of Pain.Erin Walker, Nikol Rummel, and Kenneth R. Koedinger.2011.
Is it feedback relevance or increased account-ability that matters?
In Proceedings of the 10th Inter-national Conference on Computer-Supported Collab-orative Learning (CSCL 2011).William Yang Wang and Julia Hirschberg.
2011.
Detect-ing levels of interest from spoken dialog with multi-stream prediction feedback and similarity based hier-archical fusion learning.
In Proceedings of the 12thannual SIGdial Meeting on Discourse and Dialogue(SIGDIAL 2011), Portland, OR., USA, June.
ACL.William Yang Wang and Kathleen McKeown.
2010.
?gotyou!?
: Automatic vandalism detection in wikipediawith web-based shallow syntactic-semantic modeling.In Proceedings of the 23rd International Conferenceon Computational Linguistics (Coling 2010), pages1146?1154, Beijing, China, August.
Coling 2010 Or-ganizing Committee.William Yang Wang, Fadi Biadsy, Andrew Rosenberg,and Julia Hirschberg.
2012a.
Automatic detectionof speaker state: Lexical, prosodic, and phonetic ap-proaches to level-of-interest and intoxication classifi-cation.
Computer Speech & Language.William Yang Wang, Elijah Mayfield, Suresh Naidu, andJeremiah Dittmar.
2012b.
Historical analysis of le-gal opinions with a sparse mixed-effects latent vari-able model.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguistics(ACL 2012).Richard J. Watts.
2003.
Politeness.
Cambridge Univer-sity Press.Hui Zou and Trevor Hastie.
2005.
Regularization andvariable selection via the elastic net.
Journal of theRoyal Statistical Society, Series B, 67:301?320.29
