AN APPL ICAT ION OF MONTAGUE GRAMMAR TO ENGL ISH- JAPANESE MACHINE TRANSLAT IONToyoak i  N ISH IDA and  Shu j i  DOSHITADept .
of In fo rmat ion  Sc ienceFacu l ty  of  Eng ineer ing ,  Kyoto  Un ivers i tySakyo-ku ,  Kyoto  606, JAPANABSTRACTEnglish-Japanese machine translationrequires a large amount of structural transfor-mations in both grammatical and conceptual level.In order to make its control structure clearerand more understandable, this paper proposes amodel based on Montague Gramamr.
Translationprocess is modeled as a data flow computationprocess.
Formal description tools are developedand a prototype system is constructed.
Variousproblems which arise in this modeling and theirso lu t ions  are  descr ibed .
Resu l t s  of exper imentsare shown and it i s  d i scussed  how far initialgoals are achieved.I .
GOAL OF INTERMEDIATE REPRESENTATION DESIGNDifferences between English and Japaneseexist not only in grammatical level but also inconceptual level.
Examples are illustrated inFig.l.
Accordingly, a large amount of transfor-mations in various levels are required in orderto obtain high quality translation.
The goal ofthis research is to provide a good framework forcarrying out those operations systematically.The solution depends on the design of intermedi-ate representation (IR).
Basic requirements tointermediate representation design are listedbelow.a) Accuracy: IR should retain logical conclu-sion of natural language expression.
The follow-ing distinctions, for example, should be made inIR level:- partial/total negation- any-ex is t /ex i s t -any"- act ive/pass ive- restrictive use/ nonrestrictive use, etc.In other words, scope of operators should berepresented precisely.GRAMMATICAL differencea) Case Marking:<E>: (relative position) + preposition<J>: postposition (called JOSHI)b) Word Order\[) simple sentence<E>: S+V+O : ~ a ~<J>: s?o?v : WAT-ASHi ~ O  ~f f~ET~ii) preposition vs postposit\[on<E>: PREP+NP : ,in, Lthe refrigerator,<J>: NP?JOS~I : q ~ - { I ?
N ~iii) order of modification<E>: NP?POSTMODIF\[ER: an apple on the box,<J>: PRENOMINAL MODIFIER+NP: HAKO NO UE NO RINGOLEXICAL difference<E> <J>translate HONYAKU SURUinterpret ~ KAISHAKU SURUunderstand RIKAI SURUgrasp / TSUKAMUhold ~ TAMOTSUkeep MAMORU.
, ,CONCEPTUAL difference<E2 her arrival makes him happy~.. \[s needed paraphrasing<j> KARE WA KANOJO GA TOUCHAKU SHITA NODEURESHII.
(he becomes happy because she has arrived)Fig.l.
Examples of Differences between Englishand Japanese.<E>: English; <J>: Japanese.156b) Ab i l i ty  of represent ing  semantic re la t ions :In  Eng l i sh - Japanese  t rans la t ion ,  i t  is of ten  thecase that  a g iven Engl ish  word must be t rans la tedin to  d i f fe rent  Japanese words or  phrases  i f  i thas more than one word meanings.
But i t  is  notreasonable to capture th is  problem so le ly  as aproblem of word meaning d isambiguat ion  in ana ly -s i s  phase; the needed depth of  d i samb?iuat iondepends on ta rget  language.
So i t  i s  a l sohandled in t rans fer  phase.
In genera l ,  meaningof  ?
given word is  recognized based on the re la -t ion  to o ther  const i tuents  in the sentence ortext  vhicb is semant ica l ly  re la ted  to the givenword.
To make th i s  poaslble in t rans fer  phase,IR must provide a l ink  to semant ica l ly  re la tedconst i tuents  of a g iven item.
For example, anob jec t  of a verb should be access ib le  in IR leve lfrom the verb,  even i f  the re la t ion  is  imp l i c i t~n the sur face  s t ruc ture  (as .
,  pass ives ,  re la t iveclaus=a, and the i r  combinations,  e tc .
)?)
Pred ic t ion  of cont ro l :  g iven an IR expres -s ion ,  the model should be able to pred ic texp l i c i t I y  what operat ions  are co be done in whato rder .d) Lexicon dr iven:  some sor t  of  t rans forma-t ion  ru les  ere word spec i f i c .
The IR in terpreta -t ion  system should be designed Co deal with thoseword spec i f i c  ru les eas i ly .e) Computabi l i ty :  A l l  processing= should bee f fec t ive ly  computable.
Any IR is useless i f  i tis not computable.2.
PRINCIPLE OF TP, ANSLATIONThis sect ion  out l ines  our so lu t ion  Co therequ i rements  posed in the preceding sect ion .
Weemploy MonCague Gram=mr (HonCague 1974, Dowry1981) as a theoret i ca l  bas i s  of t rans la t ion  model.I n te r~ed la te  representat ion  is designed based oni n tens iona l  logic.
I n termed ia te  representat ionfor  a given natura l  language expression isobtained by what we call functional analysis.2.1 Funct ional  Analys isIn funct iona l  ana lys i s ,  input sentence isdecomposed into groups of const i tuents  andin ter re la t ionsh ip  among those groups are analyzedin terms of function-argument relationships.Suppose a sentence:I don't have a book.
(l)The funct iona l  analys is  makes fo l low ing  twopo ints :a) (L) is decomposed as:" I  have a book" ?
"nOt".
(2)b) In the decomposi t ion (2) ,  "not"  is  anoperator  or funct ion  co " I  have a book.
"The resu l t  of  th is  analys is  can be depicted asfo l lows:~ ""I have a book" I (3)wherel >denotes a function and\[ Idenotesen argument.
The ro le  of  "not"  as a funct ion  i s :"not"  as a semantic opers tor :i t  negates a given propos i t ion ;"not"  i s  a syntact i c  operator :i t  inserts an appropr ia te  auxiliary verband = l ex ica l  i tem "not"  i n to  appropr ia tepos i t ion  of i t s  argument.
(4)This kind of analysis goes on further withembedded sentence unt i l  i t  is  decomposed intolex ica l  un i ts  or even morphemes.2.2 Montague Grammar as a Basic TheoryMontague Grammar (MG) gives a basis of func-tlonel analysis.
One of the advantages of MGcons ists  in its interpretation system of functionform (or intensional logical form).
In MG, inter-pretation of an intenelonal logical formula is amapping I from incenaional logical formulas toset  theoret i ca l  domain.
Important proper ty  ischat this ampping I is defined under the cons-trainC of compositlonality, that is, I satisfies:Z\ [ f (a ,b  .
.
.
.  )
\ ] ' I \ [ f l (Ha \ ] ,Z \ [b \ ]  .
.
.
.  )
,  (5)w i thout  regard to what f ,  a, b, e tc .
are.
Thisproperty s impl i f ies  control structure and it alsospec i f ies  what operat ions are done in what order .For example, suppose input data has a s t ruc turel i ke :AFor the sake of  property  (5) ,  ~he in terpreta t ionof (6) is done as a data flow computation processas followa:A ~I \ [A \ ]  , |A "II t s  c O }~7)By th is  p roper ty ,  we can eas i ly  grasp the process-ing stream.
In par t i cu la r ,  we can eas i ly  ~hooct rouble and source of  abnormal i ty  when debugginga system.Due to the above property  and others ,  Lnpar t i cu la r  due to i ts  r igorous framework based .
)nLogic, MG has been studied in ~nformation sciencef ie ld  (Hobbs 1978, Friedman |978, Yonezaki \[980,157Nish ida 1980, Landsbergen 1980, Moran 1982, Moore1981, Rosenschein 1982, .
.
. )
.
Application of MGto machine t rans la t ion  was a lso  attempted(Hauenschild 1979, Landsbergen 1982), but thosesystems have only partially utilized the power ofMG.
Our approach attempts to utilize the fullpower of MGo2.3 Application of Montague Grammar toMachine TranslationIn  o rder  to obta in  the syntact i c  s t ruc turein Japanese from an in tens iona l  log ica l  form, inthe same way as in terpretat ion  process  of MC, wechange the semant ic  domain from set  theoret i ca ldomain to conceptua l  domain for  Japanese .
Eachconceptual unit contains its syntactic expressionin Japanese.
Syntactic aspect is stressed forgenerating syntact i c  structure in Japanese.Conceptual information is utilized for semanticbased word choice end paraphras ing .For example,  the fo l low ing  funct ion  inJapanese syntact i c  domain is  ass igned to ?logical i tem "not":(LAMBDA (x) (SENTENCE x \[AUX "NAI"\])).
(8)3.1 Definition of Formal Toolse) English oriented Formal Representation (EFR)is a version of intensional logic, and gives arigorous formalism for describing the results offunctional analysis.
I t  is based on Cresswell'slambda deep s t ructure  (Cresawel l  1973).
Eachexpress ion  has a un ique ly  def ined type.
Lambdaform is  employed to denote funct ion  i t se l f .b) Conceptual  Phrase St ructure  (CPS) is  a datas t ruc ture  in which syntact i c  and semant ic  in fo rma-t ion  of a Japanese lex ice l  un i t  or phrase s t ruc -tu re  are  packed.i) example of CPS for a lexical item:EIGO:\[NP "EIGO" with,ZSAmLANGUAGE; ...,\] (9)category; lexical item; conceptual info.
; "EIGO" means English" language.ii) example of CPS for phrase structure:\[NP \[ADJ "AKAI" with ... \]\[NOUN "RINGO" with ... \] with ... \] (i0)Trans fer -generat ion  process  for  the sentence  (1)looks l i ke :"I don't have a book"~ ' , , I  have a book" I//?
TRANSFER /(LAMBDA (x){SENTENCE x \[AUX "NAI"\]})TRANS FE R, GENE RAT I ONSWATASHI-WA HON-WO MOTSU ,,-..._./SS AUXWATASHI-WA HON-WO MOTSU NAIMOTANAI; "AKAI" means red, and "RINGO" means apple.c) CPS Form (CPSF) is a form which denotesoperation or function on CPS domain.
It is usedto give descriptions to mappings from EFR to CPS.Const i tuents of CPSF are:i) Constants: CPS.ii) Variables: x, y, ...
.
(indicated by lower case strings).iii) Variables with constraints:e.g., (!
SENTENCE x).
; variable x which must beof category SENTENCE.iv) Transformations:e.g., (?
TENSE (TENSE-PAST~ x).indicator; operator-name; PARAMs; argumen~v) CPS construction:e.g., <SENTENCE (x y) with ... 7./ \new category; descendentsvi) Conditionals:\[ <condition> I -> <CPSF>I; ... \].vii) Lambda form:e.g., (LAMBDA (x) (+ PASSIVE () x))Using those description tools, translationprocess is modeled as a three staged process:3.
FORMAL TOOLSFormal description tools have been developedco provide a precise description of the idea men-tioned Ln the last section.stage I (analysis): anlyzes Englishsentence and extracts EFR form,stage 2 (transfer): substitutes CPSF toeach lexical item in the EFR form,158not)+NEGHe does not always cOme late.always ( he ( late ( comes ) ) ) )lq, kpS\[p< ~llIrF+V I A~V ,rll,l xIN\[p4 P IIIIL IJl LitS \ Z.a'?# z comes.A.L?e22::'JADVaZzoays ~=e comes ZaCe 4/: /.s not; Cite case  thuC~cotr4s ~Ce.
.
EFR  .
.~,RAN$FER).. CPSF ..?
.
CPS  .
.Fig.2.
Example of Translation Process / /  Prefix notation is used for CPSF,described using Formal Tools.
/ and syntactic aspect is emphasized.stage 3 (generation): evaluates the CPSF toget CPS; generation of surface s t ructurefrom CPS is straightforward.In order to give readers an overa l l  pers-pect ive ,  we i l l us t ra te  an example in F ig .2 .Note that the example i l l us t ra ted  includespar t ia l  negat ion.
Thus operator  "not"  isgiven a wider scope than "always".In the remaining part of this sectionwe will describe how to extract EFR expressionfrom a given sentence.
Then we will discuss theproblem which ar ises in eva luat ing CPSF, and giveits possible solution.3.2 Extracting EFR Expression from Input SentenceRules for translating English into EFR formin .~ssociated with each phrase structure rules.159For example, the rule looks l l ke :NP -> DET+NOUN where <NP>-<DET>(<NOUN>) (ii)where, <NP> stands for an EFR form assigned tu~he NP node, etc.
Rule (II) says chat EFR for anNP is a form whose function section is EFR for aDET node and whose argument sect ion is  EFR for  aNOUN node.
This ru le  can be incorporated intoconvent iona l  natural language parser.3.3 Evaluation of CPSFEvaluation process of CPSF is a sequence oflambda conversions and tree ~ransformations.Evaluation of CPSF is done by a LISP ~ncerpreter- like algorithm.
Aproblem which we call higherorder problem arose in designing the evaluationalgorithm.Higher Order ProblemBy higher order property we mean that thereexist functions which take other functions asarguments (Henderson 1980).
CPSF in fact hasthis property.
For example, an adjective "large"i s  modeled as a funct ion  which takes  a noun asi t s  a rgument .
For example ,la rge(database) ,"large database"  (12)On the o ther  hand,  adverbs  a re  modeled asfunctions to ad jec t ives ,  For example ,very(large), extremely(large),comparatively(large), etc.
(13)The difficulty with higher order functionsconsists in modifiction to function.
For explana-tion, l e t  our temporal goal be regeneration ofEnglish from EFR.
Suppose we assign to "large" alambde form like:(LAMBDA (x) (NOUN \[ADJ "LARGE"\] x>) (14)which takes  a noun and re turns  a complex noun bya t tach ing  an ad jec t ive  " la rge" .
I f  the ad jec t iveis modified by an adverb, say "very", we have tomodify (14); we have to transform (14) into alambda form like:(LASBDA (x)(NOUN \[ADJ \[ADV "VERY"\]\[ADJ "LARGE"\]\] x}), (15)which attaches a complex adjective "very large"to a given noun.
As is easily expected, it istoo ted ious  or even imposs ib le  to do th i s  taskin  genera l .
Accord ing ly ,  we take  an a l te rnat iveass ignment  ins tead  of (14) ,  namely:large <- \[ADJ "LARGE"\].
(16)Since this decision cuases a form:\[ADJ "LARGE"\](\[NOUN "DATABASE"\]), (17)to be created in the course of evaluation, wespecify what to do in such case.
The rule isdefiend as follows:\[ADj\](\[NOUN\]) - \[NOUN \[ADJI \[NOUN\]\].
(18)~y\[(the(table))(Ax\[(((*ap(on))(y))(block))(x)\])\], (20); which may read: is y:\[there is a uniquelyspecified ob ject  y referred to by an NP "thetable", such that y is a block which isres t r i c ted  to be located on x .
\ ]This lambda form is too complicated for treetransformation procedure to manipulate.
So itshould be transformed into equivalent CPS if itexists.
The type of the lambda form is knownfrom the context, namely one-place predicate.
Soif we apply the lambda form (20) to "known"entity, say "it", we can obtain sentence struc-ture like:SENTENCEUN PREDNOUNlNP NP JOSHI I / ' , ,  /'x ISORE WA TSUKUE NO UE NO BLOCK DEARUit a block on the ~able is(it is a block on the table) (21)From this result, we can infer that the lambdaform (20) is equivalent to a noun:NOUNMODIFIER NOUNNP f  SN, ITSUKUE NO UE NO BLOCK(block on the table)(22)The extraction rule can be written as a patternmatching rule like:SENTENCENP NP PREDI \SORE WA x:NOUN DEARU(It is ~ z)x(23)This rule is called an application rule.In general, evaluation of \[ambda formitself results in a function value (function as avalue).
This causes difficulty as mentionedabove.
Unfortunately, we can't dispense withlambda forms; lambda variables are needed to linkgap and its antecedent in relative clause, verband its dependants (subject, object, etc), pre-position and its object, etc.
For example, inour model, an complex noun modified by a PP:"block on the table" (19)?s assigned a following EFR:Of course, this way of processing is notdesirable; it introduces extra complexity.
Butthis i s  a trade off of employing formal seman-tics; the same sort of processing is also donerather opaque procedures in conventional MTsystem.4.
MODELING TRANSLATION PROCESSThis section illustrates how English-Japanese translation process is modeled usingformal tools.
Firstly, how several basiclinguistic constructions are treated is describedand then mechanism for word choice is presented.1604.1 Trans la t ing  Basic Const ruct ions  of Englisha) Sentence: sentence cons is ts  of an NP and aVF.
VP is  analyzed as a one-p lace  pred icate ,which const ructs  a propos i t ion  out of an ind iv i -dual re fer red  Co by the sub jec t .
VP i s  fu r therdecomposed in to  in t rans i t ive  verb or  c rana l t iveverb + ob jec t .
In t rans i t ive  verbs and t rans i t iveverbs ere analyzed as one-p lace  pred icates  andtwo-place pred icate ,  respect ive ly .
One-placepred icate  and two-p lace pred icate  are ass igned aCFSF function which generates a sentence ouc ofan ind iv idua l  and chat which generates  a sentenceout  of a pa i r  of ind iv idua ls ,  respect ive ly .
Thus,a t rans i t i ve  verb "const ructs"  i s  ass igned a CPSFform:(LAMBDA (x y)(SENTENCE(?
CASE-MAR/~R (CASE=AGENT) x)(+ C~SE-MARi~R (CASE=OBJ) y)\[ FRED ICATE \[ VERB "SAKUSEI-SURU" \] J )), (24); given two i nd iv idua ls ,  th i s  funct ion  a t tachesco each argument a case marker (cor respond ingto JOSHI or  Japanese post f ix )  and then gener -ates a sentence s t ruc ture .The ass ignment  (24) may be extended l a te r  toincorporate  word choice mechanism.Treatment of  NP in MonCague-besed semant icsi s  s ign i f i cant  in  chat EFR express ion  fo r  an NP i sg iven a wider scope then Chat for  a VP.
Thus theEFR form for  an ~P-VP const ruct ion  looks l lke:<~>(<w>) ,  (25)where <x> means EFR form for  x, x=NP, .
.
.
.The reason is  Co provide an appropriate model forEnglish quantifier which is syntact i ca l ly  localbut semant ica l ly  g loba l .
For example, f i r s torder  logical form for a sentence:"this command needs no operand" (267looks Like:nor(there-exists x\[needs("chis-command",x) &operand(x) \ ] ) ,  (27)where operator "not", which comes from a deter-miner "no", is given a wider scope than "needs".This translation is straightforward in our model;the following EFR is extracted from (26):( th i s ( round) )Ax \ [ (no(operand) ) ( ly \ [needs(x ,y ) \ ] ) \ ] ) .
(28)\[f we make appropriate assignment including:no <= (LAMBDA (p)(LAMBDA (q)"nor ( there  ex is ts  x\ [p(x)  & q(x)\])")), (29)we can get (27) from (28).161In  Eng l l sh - Japanese  -,-'chine t rans la t ion ,th i s  t reatment  gives an e legant  so lu t ion  to the: rana la t ion  of prenominal  negat ion ,  par t ia l  nega-t ion ,  etc.
Since Japanese language does not havea synCactlc device for prenominal negation, "no"must be translated into asainly two separateconstituents: one is a RENTAISHI (Japanese decer-miner)  and another  is an aux i l i a ry  verb of  nega-tion.
One possible assignment of CFSF looks like:no <= (LAMBDA (p)(U~NgDA (q)( ,  NEG ()(q (~  "DONNA" (t NOUN p) " ,~0") ) ) ) ) .
(30)In  genera l ,  correspondence of ~P and ind iv i -dual is ind i rec t  in EFR.
The assoc ia t ion  of anNF with i t s  re ferent  x is i nd icated  as fo l lows :<~>(Ix{ ... x ... ;).i',enCence typeone-p lace  predlcaCe type; <NP> stands  for  EFR express ion  for  NP.
(31)Most of ocher  NP's cor respond co icere ferent  more d i rec t ly .
The app l i ca t ion  ru lere f lec t ing  this fact is:\[NFJ(\[O~-eU~CE-PREDI) - \[ONE-PU~CE-FREOI(\[NP*\]),(32)where,  ix\] s tands  fo r  a CPS for  x.b) Internal structure of NP: the below illus-trates the s t ruc ture  of EFR express ion  ass ignedCO an NP:<DET>(<MOD\[FIER>(..
.
(<MDDIFIER>(<NOUN>)) ...)).
(33)By <MOD?FIER> we mean mod i f i ca t ion  to noun byad jec t ives ,  p repos i t iona l  phrases, in f in i t i ves ,present/past par t i c les ,  e tc .
The t rans la t ionprocess is determined by a CPSF assigned co <DET>,En cases of "the" or "a/an", translation processis ab ic  compl icated.
Et is almost the same asthe process described in deta i l  in sect ion  3:firstly the <MODIFIER>s and <NOUN> are applied Coan individual like "the chinE" (the) or "some-chinE" (a/an) and a sentence will be obtained;then a noun structure is extracted and appro-priate RENTAISHI or Japanese determiner isattached.c) Other cases: some ocher cases are illust-rated by examples in Fig.3.4.2"Word Choice Mechanism?
In order to obtain high quality translation,word choice .~chanism must be incorporated atleast  for  handling the cases l i ke :i) subordinate clause:"When SI, S2"&(when (<SI >) ) (<$2>)"TOKI" \[$I\]\[\[SI\] "TOKI 's\] \[$2\]\[\[Sl\] "TOKI" \[S2\]\]2) tense, aspect, modal:"I bought a car"did(<I buy a car>)"TA" "WATASHI-WA JIDOUSHA-WO KAU""WATASHI-WA JIDOUSHA-WO KAU TA"KATTA3) passive:" ... is broken ... "&... en(break) ...C~x~ ,,.GA,, y ,,.WO KOWASU ,,} ....~y{y "-GA KOWA SARERU" } ....; function "en" transforms a CPSF fora transitive verb into intransitive.4) interrogative:"Do ~ou have a car?
"#ques(whether(<you have a car>))+MKSENTENCE "KADOUKA .... ANATA-WA JIDOUSHA-WO MOTSU"-WA JIDOUSHA-W0 MOTSU-KADOUKA""ANATA-WA JIDOUSHA-WO MOTSU-KA""Which car do you have?
"#ques((which(car))(~y\[<you havey>~))+MKSENT~NCE I .
.
.
.
.
.
{(Xp{p("DON0-JIDOUSHA) KA } I , ,,kk,,  .wA, y .wo~IDOUSHA-W0 MOTSU-KA""ANATA-WA DONO-JIDOUSHA-WO MOTSU-KA"; indirect question is generated first, then it istransformed into a sentence.Fig.3.
Examples of Translation of Basic EnglishConstruction.
<x>, {x}, \[x\] and "x" standfor EFR for x, CPSF for x, CPS for x, andCPB for Japanese string x, respectively.verb in accordance with its object or its agent,adjective-noun,adverb-verb, andpreposition.Word choice is partially solved in the analysisphase as a word meaning disambiguation.
So thedesign problem \[s to determine to what degreeword sense is disamblguated in the analysis phaseand what kind of ambiguities is left untiltransfer-generation phase.
Suppose we are totranslate a given preposition.
The occurence ofa preposition \[s classified as:(a) when it is governed by verbs or nouns:(a-l) when governmant is strong:e.g., study on, belong to, provide for;(a-2) when govern.ment is weak:e.g., buy ... at store;(b) otherwise:(b-I) idiomatic:e.g., in particular, in addition;(b-2) related to its object:e.g., by bus, with high probability,without?ING.We treat (a) and (b-l) as an analysis problem andhandle them in the analysis phase.
(b-2) is moredifficult and is treated in the transfer-generation phase where partial semantic interpre-tation \[s done.162Word choice in t rans fer -generat lon  phase isdone by using, cond i t iona l  expression and a t t r i -but ive information included in CPS.
For example,a transitive verb "develop" is translated differ-ently according to its object:develop ~ (* system) ... KAINATSU-SURUt (+ film) GENZOU-SURU.
(34)The following assignment of CPSF makes this choiceposs ib le :deve lop<= (LAMBDA (x y)\[(CLASS y)=SYSTEM ->("x-GA y-WO KAIHATSU-SURU"} ;(CLASS y)-FILM ->("x-GA y-WO GENZOU-SURU"};?
.. \]), (35)operating-syStem<- \[NOUN "OS" with CLASS-system; ... \], (36)film<- \[NOUN "FUILUMU" with CLASS-film; ...
1.
(37)To make this type of processing possible in thecases where the deep object is moved from surfaceobject  position by transformations, link infor-mation between verb and its (deep) object shouldbe represented  exp l i c i t l y .
The below shows bowi t  is  done in the case of  re la t ive  c lause .Phrase Structu~ (for restrictive use):NP(which(Xx\[ .. x .. .
\]))(<noun>)l i nk  from head noun toplace ho ldery activitygent: GA ~agent :  NOocatl on: NI \ [1  ocati on: E-NOHONYAKU ~'~r e s - o b J / ~ T s  Z=~7:?~// / "~Ct i  vi ty { (agent: NO/NIYORUf ' ' '~=-~ ~Jobj :NO\[NONYAKU SURU~ ad j -ab le  _ ~source:KARANO((agent:C~ activitv-'~7 HONYAKU ~NOU NA~/source:KARA I '~ .
.
.
.
.
.
.
.
, -=  I ~Ldest :E /N!
L?D3~'su?3 -J (,fsubj :WA-)source: ~RALdest:E/NI5 ?
EXPERIMENTSCPSF assignment:whtch ~ (LAHBOA (P) (LAMBOA (Q){NOUN (+ HK-HODIFIER ()(P (+ MK-NULL-NP () O)))Q})),In EFR leve l ,  lambda variable x is exp l i c i t -l y  used as a place ho lder  fo r  the gap.A functor "which" dominates both the EFRfor the embedded sentence and that forthe head noun.
A CPSF assigned to thefunctor "which" sends conceptual informa-tion of the head noun to the gap asfollows: firstly it creates a null NFout of the head noun, then the null NPis substituted into the lambda variablefor the gap.In word choice or semantic based translationin general, various kinds of transformations arecarried out on target language structure.
Forexample,her a r r iva l  makes him happy, (38)must be paraphrased into:he becomes happy because she has arrived (39)since inanimate agent is unnatural in Japanese.In order to re t r ieve  appropr iate lex ica l  item ofta rget  language for transformation, mutual rela-tions among lexlcal items are organized usingnetwork formalism (lexical net).
The node repre-sents a lexicel item and a link represents anassociation with spec i f i ca t ion  of what operationcauses that link t() be passed through.
\[t alsocontains description of case ~ransformationneeded Ln order co map case structure appropr ia te -ly .
The below i l l us t ra te  s part of Lexical net:We have constructed a prototype  system.I t  is  s lmp l i f ied  then pract i ca l  system in:- i t  has only l imi ted  vocabu lary ,- interactive disembiguation is done insteadof automatic disambiguaCion, and- word choice mmchenism is limited to typicalcases since overall definition of ruleshave not yet  been completed.Sample texts  are taken from rea l  computermanuals or abst rac ts  of computer journa ls .Initially, four sample texts (40 sentences) arechosen.
Currently it is extended to I0 texts (72sentences).Add i t iona l  features are introduced Ln orderto make the system more pract i ca l .a) Parser: declarative rules are inefficientfor dealing with sentences in real cexts.
Theparser  uses production type rules each of whichis classified according to its invocation condi-tion.
Declarative rules are manually convertedinto this rule type.b) Automatic postedicor: transfer processdefined so far  concentrates on local processings.Even if certain kinds of ambiguities are re-solved in this phase, there s t i l l  remains aposs ib i l i ty  that new ambiguity is introduced ingenerat ion phase.
Instead of incorporat ing intothe transfer-generation phase a sophist icatedmechanism for  filtering out ambiguities, weattach a postprocessor which will "reform" aphrase structure y ie ld ing  ambiguous output.
Tree-tree transformation rules are utilized here.Current resu l t  of our machine cransLacionsystem is shown in Appendix.1636.
DISCUSSIONHaving completed initial experiments, it isshown that our framework is applicable to realtexts  under plausible assumption.
The prototypesystem has a clear architecture.
Central ruleinterpreter contains no complicated parts.Although several errors occured in the implementa-tion of translation rules, they were easilydetected and eliminated for the sake of data flowproper ty .The initial requ i rement  for i n te rmed ia terepresentation are filled in the following way:Requirement a: prec ise  representat ion  basedon in tens ioua l  logic,Requirement b: using lambda variables andscope ru les ,Requirement c: data flow computing modelbased on compositionality,Requirement d: any CPSF can be assignedto a given lexical itemif type is agreed,Requirement e: fact that computer modelhas been implemented.Some essent ia l  problems are left unsolved.I) Scope analysis: correct analysis of scope ofwords are cruc ia l  but difficult.
For example,scope relation of auxiliary and "not" d i f fe rscase by case:he can't swim-> not(can(<he>,<swim>)) (A0)you should not eat the banana-> should(not(<eat the banana>)) (41)it may not be h im-> may(not( <it-he> )) (42)you may not eat the banana-> not(may( <you eat banana>)) (43)2) Logic vs machine translation: The sentence(44) is logically equivalent to (45), butthat paraphrasing is bad in machine translation.he reads and writes English.
(44)he reads English and he writes English.
(45)7.
CONCLUSIONApplication of formal semantics to machinetranslation brings about new phase of machinetranslation.
It makes the translation processclearer than conventional systems.
The theoryhas been tested by implementing a prototype,which can translate real texts  with plausiblehuman assist.REFERENCESCresswell, M.J. (1973): Logic and Languages,Methuen and Company.Dowry, R. et al(1981): Introduction to MontagueSemantics, Reide l .Friedman, J.
(1978): Evaluating English Sentencesin a Logical Model, Abstract 16, COLING 78.Hauenschild, C., e ta l .
(1979): SALAT: MachineTranslation Via Semantic Representation,Bauerle et al(eds.
): Semantics From DifferentPoints of View, Springer-Verlag, 324-352.Henderson, P.(1980): Functional Programming --Application and Implementation, Prentice/Hall.Hobbs, J.R. and Rosenschein, S.J.
(1978): MakingComputational Sense of Montague's IncensionalLogic,  AI 9, 287-306.Landsbergen, J.
(1980): Adaptation of MontagueGrammar to the Requirement of Question Answer-ing, Proc?
COLING 80, 211-212.Landsbergen, J.
(1982): Machine Translation basedon Logically Isomorphic Montague Gra=mars,Proc.
COLING 82.Montague, R. (1974): Proper Treatment of Quantifi-cation in Ordinary English, Thompson (ed.
)Formal Philosophy, Yale University, 247-270.Moore, R.C.
(1981): Problems in Logical Form,Froc.
19th Annual Meeting of the ACL, I17-124.Moran, D.B.
(1982): The Representation ofInconsistent Information in a Dynamic Model-Theoretic Semantics, Proc.
20th Annual Meetingof the ACL, 16-18.Nishida, T. and Doshita, S. (1980): HierarchicalMeaning Representation and Analysis ofNatural Language Documents, Proc.
COLING 80,85-92.Rosenschein, S.J.
and Shieber, S.M.
(1982): Trans-lating English into Logical Form, Proc.
20thAnnual Meeting of the ACL, l-S.Yonezaki, H. and Enomoto, H. (1980): DatabaseSystem Based on Intensional Logic, Proc.
COLING80, 220-227.164INPUT TEXTAPPENDIX: Translation of a Sample Text.}((h?.
*ne: ,, a %~qem (or IOcai communlcat,on among computing statiOns Our experlmcn\[aiE.thcrnc; u~;.
: ~ppcc coaxial eabl~ Io c~rn ~urlaoie-len~th dlgltal data packets among, for example,pcrsonai minicomputers, pr~nung f'aciliues, iar~?
~ie s~orage de,.~ces, magnetic r~pe backup stauons.lar~er cenlra!
computers, and longer-haul communlcauor~ equzpment.The ,~hared communicauon facilit.~, a branchm8 E~er.
~s passive.
A sIauons E~heme~ interfaceconnecL~ b,-sonalb through an interface cabie to a Lranscezver which in turn ~ps mLo the passingF/her 4 packet is hmadcas{ onto the F:'ther.
is heard b.~ all smr/ons, and is cop~ed from the Er.herb.~ desunauons ~.hich soiL'c: ~!
accorain~ to the packe:s leadm8 address bits.
This ,s 0madc.~lpacke: s~tching alld shouic be disunguzshec~ from s(ore-and-t'or~ard packe( switchin 8 m wh,chmuun9 ~ nerformed h~ mtermedmte pruccssm~ elements.
To handle {he demand~ of ~,rowth.
anF/heine!
can be ex~ended usm@ packet repeaters (or signaJ regeneration, packe{ filters t'or crar~clocaJzzauon, an(~ p~ket gate~a.vs /'or intcmetwurk address extension.Control is completeb dnstrioutea among stauons with packet transmissions coordinated ',nmughsr, austical arbitration.
Transmissions inl~ated b) a s~aoon defer ~o an)' which may' alread.~ be mprogress.
Once s~arted, if interference v,.
:d~ ocher packe~ ~s detected, a transmission ts aborted andreschedu\[ed b;, ~LS source s~auon.
A~er a certain period of interference-tree transmission, a packetis heard b.v all s\[aoons and will run to completion without interference.
E~ernet controllers mcolliding sauons each generate random retransrniss~on inten-ab to avoid repeated co\[iismns.
Themean of a packer's retransmission inter, aiS is adjusted as a f~ncUon of co\]hsion histon.
to keepEther uulizauon near ~le opumum v.-,.h changing network load.E~en ~,nen transmuted w~thout source-detected interference, a packet may still not reach z~destination w~thouz error: thus.
packets are delivered only ~.~th high probabilio'.
Scauons requmng aresidual error rate lower than thai provided b.~ the bare Ethemet packet transport mechanism muSlfollo~ mutually agreed upon packet protOcols.cCted from: MeCcalfe, R.M.
and 8oggs, D.R.
(1975): E~hernec: D1scrlbuced Packec~Swi~chin 8 for Local Computer Networks, CSL-75-7, Xerox.OUTPUT TEXTcranslaglon is carr iedoue sengence by sentence;the result is assembledby hand.=-9 ,  E I \ ] ~ .
.
~ 7  ~ d Ju09x ~ U - 9"o~'~.
~ll~'-~,'~':, ~' "," J '2"x~ = - ~ 3I%~ ='r  ~ ~, ~- n,,~- -- ~a ,  ~ ;~o097-  xx9  = - :~ ~ > C2 o ( f f .~ I~1~T ~ 6 ~,  ~7.~ ">'_~ -~ ~ ~-.3, ~;o'~?
;~,& ~ i v -- x ~ T ~ , ~ / ~ : ~  L C,~ "~ ~ .9,'f~.~ ~."
L I~ '<.
~ ~ ~ ~.r .
-~ -- .~' :t~ ;~.. ~ ?)
l~?)
E THI-= RNET,  ~'r v b ~ I~/~IL  " ?
--, T t~f~ ~ tl "5 L er)j: ;) 'L ~"  ,~f~.~r)\[65
