From Words to Corpora: Recognizing TranslationNoah A. SmithDepartment of Computer ScienceJohns Hopkins UniversityBaltimore, MD 21218 USAnasmith@cs.jhu.eduAbstractThis paper presents a technique for discover-ing translationally equivalent texts.
It is com-prised of the application of a matching algo-rithm at two different levels of analysis and awell-founded similarity score.
This approachcan be applied to any multilingual corpus us-ing any kind of translation lexicon; it is there-fore adaptable to varying levels of multilingualresource availability.
Experimental results areshown on two tasks: a search for matchingthirty-word segments in a corpus where somesegments are mutual translations, and classifi-cation of candidate pairs of web pages that mayor may not be translations of each other.
Thelatter results compare competitively with pre-vious, document-structure-based approaches tothe same problem.1 IntroductionAs in most areas of natural language process-ing, recent approaches to machine translationhave turned increasingly to statistical modelingof the phenomenon (translation models) (Bergeret al, 1994).
Such models are learned auto-matically from data, typically parallel corpora:texts in two or more languages that are mutualtranslations.
As computational resources havebecome more powerful and less expensive, thetask of training translation models has becomefeasible (Al-Onaizan et al, 1999), as has thetask of translating (or ?decoding?)
text usingsuch models (Germann et al, 2001).
However,the success of the statistical approach to trans-lation (and also to other multilingual applica-tions that utilize parallel text) hangs cruciallyon the quality, quantity, and diversity of dataused in parameter estimation.If translation is a generative process, then onemight consider its reverse process of recognition:Given two documents, might it be determinedfully automatically whether they are transla-tions of each other?The ability to detect translations of a doc-ument has numerous applications.
The mostobvious is as a means to build a parallel corpusfrom a set of multilingual documents that con-tains some translation pairs.
Examples includemining the World-Wide Web for parallel text(Resnik, 1999; Nie et al, 1999; Ma and Liber-man, 1999) and building parallel corpora fromcomparable corpora such as multilingual collec-tions of news reports.
Another use of trans-lation detection might be as an aid in align-ment tasks at any level.
For example, considerthe task of aligning NP chunks (and perhapsalso the extra-NP material) in an NP-bracketedparallel corpus; a chunk-level similarity score(Fluhr et al, 2000) built from a word-levelmodel could be incorporated into a frameworkthat involves bootstrapping more complex mod-els of translation from simpler ones (Berger etal., 1994).
Finally, reliable cross-lingual dupli-cate detection might improve performance in n-best multilingual information retrieval systems;at the same time, by detecting the existence of atranslation in a multilingual corpus, the cost oftranslating a document of interest is eliminated.I present here an algorithm for classifyingdocument pairs as either translationally equiv-alent or not, which can be built upon anykind of word-to-word translation lexicon (au-tomatically learned or hand-crafted).
I pro-pose a score of translational similarity, thendescribe an evaluation task involving a con-strained search for texts (of arbitrary size) thatare translation pairs, in a noisy space, andpresent precision/recall results.
Finally, I showthat this algorithm performs competitively withthe approach of Resnik (1999), in which onlyAssociation for Computational Linguistics.Language Processing (EMNLP), Philadelphia, July 2002, pp.
95-102.Proceedings of the Conference on Empirical Methods in NaturalMaria does n?t like fruitMaria n?
aime pas de fruitsX:Y:NULLNULL NULLFigure 1: An example of two texts with links shown.structural information (HTML-markup) is usedto detect translation pairs, though the new algo-rithm does not require structural information.2 Quantifying SimilarityThis section shows how to compute a cross-lingual similarity score, tsim, for two texts.1Suppose parallel texts are generated accordingto Melamed?s (2000) symmetric word-to-wordmodel (Model A).
Let a link be a pair (x, y)where x is a word in language L1 and y is aword in L2.
Within a link, one of the wordsmay be NULL, but not both.
The model con-sists of a bilingual dictionary that gives a prob-ability distribution over all possible link types.In the generative process, a sequence of inde-pendent link tokens is generated according tothat distribution.The links are not observed; only the lexical(non-NULL) words in each language are ob-served.
The texts whose similarity score is to becomputed, X and Y , correspond to the mono-lingual lexical projections of the links.
For thepurposes of this discussion, the texts are viewedas unordered bags of words; scrambling of thelink tokens in the two texts is not modeled.An example is illustrated in Figure 1; there areseven link tokens shown, five of which are lexi-cal in X (the English side) and six of which arelexical in Y (the French side).The next step is to compute the probability ofthe most probable sequence that could have ac-counted for the two texts.
All permutations ofa given link sequence will have the same prob-ability (since the links are generated indepen-dently), so the order of the sequence is not im-portant.
As noted by Melamed (2000), underthe assumption that the quality of a link col-lection is the sum of the quality of the links,then this problem of finding the best set oflinks is equivalent to the maximum-weighted bi-partite matching (MWBM) problem: Given aweighted bipartite graph G = (V1 ?
V2, E) with|V1| = |V2| and edge weights ci,j(i ?
V1, j ?
V2),1I use the term ?text?
to refer to a piece of text ofany length.find a matching M ?
E such that each ver-tex has at most one edge in M , and?e?M ci,jis maximized.
The fastest known MWBM al-gorithm runs in O(ve + v2 log v) time (Ahujaet al, 1993).
Applied to this problem, that isO(max(|X|, |Y |)3).The similarity score should be high whenmany of the link tokens in the best link col-lection do not involve NULL tokens.
Further,it should normalize for text length.
Specifically,the score I use is:tsim =log Pr(two-word links in best matching)log Pr(all links in best matching)(1)This score is an example of Lin?s (1998) math-ematical definition of similarity, which is moti-vated by information theory:sim(X,Y ) =log Pr(common(X,Y ))log Pr(description(X,Y ))(2)where X and Y are any objects generated by aprobabilistic model.2In this research, I seek to show how multiplelinguistic resources can be exploited together torecognize translation.
The measure in (1) issimplified by assuming that all links in a giventranslation lexicon are equiprobable.
(In somecases I use an automatically induced translationlexicon that assigns probabilities to the entries,but for generality the probabilities are ignored.
)This reduces the formula in (1) totsim =# two-word links in best matching# links in best matching.
(3)Further, to compute tsim under the equiprob-ability assumption, we need not compute theMWBM, but only find the maximum cardi-nality bipartite matching (MCBM), since allpotential links have the same weight.
An2Another approach, due to Jason Eisner (personalcommunication) would be to use a log-likelihood ratioof two hypotheses: joint vs. separate generation of thetwo texts (log Pr(all links in the best sequence)Pr(all words in X) Pr(all words in Y ) ).
In orderto make this value (which is the Viterbi approximation topoint-wise mutual information between the two texts) ascore suitable for comparison between different pairs oftexts, it must be normalized by length.
With normal-ization, this score is monotonic in Lin?s (1998) sim if auniform unigram model is assumed for the tokens in thesingle-language models (the denominator terms).O(e?v) (or O(|X| ?
|Y | ?
?|X|+ |Y |) for thispurpose) algorithm exists for MCBM (Ahuja etal., 1993).
If the matching shown in Figure 1 isthe MCBM (for some translation lexicon), thentsim(X,Y ) = 47 under the simplifying assump-tion.If Equation (3) is applied to pairs of docu-ments in the same language, with a ?transla-tion lexicon?
defined by the identity relation,then tsim is a variant of resemblance (r), as de-fined by Broder et al (1997) for the problem ofmonolingual duplicate detection:r(X,Y ) =|S(X) ?
S(Y )||S(X) ?
S(Y )|(4)where S(Z) is a shingling of the words in Z; ashingling is the set of unique n-gram types in thetext for some fixed n (Damashek, 1995).
UnlikeBroder et al?s r, however, tsim is token-based,incorporating word frequency.
Specifically, theintersection of two bags (rather than sets) of to-kens contains the minimum count (over the in-tersected bags) of each type; the union containsthe maximum counts, e.g.,{a, a, a, b, b} ?
{a, a, b, b, b} = {a, a, b, b}{a, a, a, b, b} ?
{a, a, b, b, b} = {a, a, a, b, b, b}With the assumption of equiprobability, anytranslation lexicon (or, importantly, unionthereof) containing a set of word-to-word en-tries, can be used in computing tsim.3 Finding TranslationsFormally, the evaluation task I propose can bedescribed as follows: Extract all translationpairs from a pool of 2n texts, where n of themare known to be in language L1 and the othern are known to be in L2.
Each text can haveone or zero translations in the corpus; let thenumber of true translation pairs be k.The general technique for completing the taskis to first find the best matching of words intext pairs (posed as a bipartite matching prob-lem) in order to compute the tsim similarityscore.
Next, to extract translation pairs of textsfrom a corpus, find the best matching of textsbased on their pairwise tsim scores, which canbe posed as a ?higher-level?
MWBM problem:by matching the texts using their pair-wise sim-ilarity scores, a corpus of pairs of highly similartexts is extracted from the pool.If k is known, then the text-matching problemis a generalization of MWBM: Given a weightedbipartite graph G = (V1?V2, E) with |V1| = |V2|and edge weights ci,j , find a matching M ?
Eof size k such that each vertex has at most oneedge in M , and?e?M ci,j is maximized.
The setof texts in L1 is V1, and the set of texts in L2 isV2; the weights ci,j are the scores tsim(vi, vj).
Ido not seek a solution to the generalized prob-lem here; one way of approximating it is by tak-ing the top k tsim-scored elements from the setM (the MWBM).If k is not known, it can be estimated (viasampling and human evaluation); I take the ap-proach of varying the estimate of k by applyinga threshold ?
on the tsim scores, then comput-ing precision and recall for those pairs in Mwhose score is above ?
(call this set M?
):prec?
=|M?
?
T ||M?
|, rec?
=|M?
?
T |k(5)where T is the set of k true translation pairs.Performance results are presented as (precision,recall) pairs as ?
is lowered.3Melamed (2000) used a greedy approxi-mation to MWBM called competitive link-ing, which iteratively selects the edge withthe highest weight, links those two vertices,then removes them from the graph.
(Tiesare broken at random.)
A heap-based im-plementation of competitive linking runs inO(max(|X|, |Y |) log max(|X|, |Y |)).
In the firstexperiment, I show a performance comparisonbetween MWBM and competitive linking.4 Experiment: English-ChineseThis experiment used the Hong Kong HansardEnglish-Chinese parallel corpus.
The trainingcorpus is aligned at the sentence level, with seg-ment lengths averaging fifteen words (in eachlanguage).
The test corpus is aligned at the two-sentence level, with segment lengths averagingthirty words.
The first experiment involved ten-fold cross-validation with (for each fold) a train-ing corpus of 9,400 sentence pairs and a testcorpus of 1,000 two-sentence pairs.
The corpus3The selection of an appropriate ?
will depend onthe application, the corpus, the lexicons, etc.
In myevaluation on WWW data, I use a small developmentset to choose a threshold that maximizes one measure ofperformance.was randomly divided into folds, and no noisewas introduced (i.e., k = n).44.1 Translation LexiconThe main translation lexicon of interest is aunion of three word-to-word translation lexiconsfrom different sources.
I refer to this translationlexicon as UTL.The first component translation lexicon,DICT, was made from the union of twoEnglish-Chinese electronic dictionaries, specifi-cally, those from Meng et al (2000) and Levowet al (2000) (a total of 735,908 entries, many ofwhich are not one-to-one).
To make the dictio-nary exclusively one-to-one entries, each n-to-m entry was processed by removing all functionwords in either side of the entry (according toa language-specific stoplist), then, if both sideshave one or two words (no more), adding allword-pairs in the cross-product (otherwise theentry is discarded).5 The resulting translationlexicon contains 577,655 word pairs, 48,193 ofwhich contain two words that are present in thecorpus.
This translation lexicon has the advan-tage of broad coverage, though it does not gen-erally contain names or domain-specific words,which are likely to be informative, and does notcapture morphological variants.The second translation lexicon, TMTL, is au-tomatically generated by training a symmet-ric word-to-word translation model (Model A,(Melamed, 2000)) on the training corpus.6 Allword pairs with nonzero probability were addedto the translation lexicon (no smoothing orthresholding was applied).
On average (over tenfolds), this translation lexicon contained 6,282entries.
The TMTL translation lexicons are ex-pected to capture words specific to the domain(Hong Kong government transcripts), as well ascommon inflections of words, though they will4It is possible that random division gives a favorablebias in the translation model translation lexicon by in-creasing the probability that rare words that appear onlyin certain portions of the corpus will be present in bothtraining and test data.5The limit of two words per side is an arbitrary choiceintended to minimize the noise introduced by this pro-cessing step.6In parameter estimation, I used the aforementionedMWBM algorithm (instead of Melamed?s (2000) com-petitive linking), which is the maximum posterior ap-proximation to EM.
It is not clear, however, that thischange yields performance gains.also contain noise.The third translation lexicon, STR, is thestring identity lexicon: (x, y) is in the trans-lation lexicon iff the string x is identical tothe string y.
This translation lexicon capturespunctuation, numerals, alphanumeric stringsused to label sections, and English words in-cluded as-is in the Chinese corpus.
There were3,083 such pairs of word types in the corpus.4.2 FilteringChen and Nie (2000) note that text pairs thatare highly disparate in length are unlikely tobe translations.
In order to avoid computingtsim scores for all pairs in the cross-product, Ieliminated all segment pairs whose lengths areoutliers in a linear regression model estimatedfrom the training corpus.
Earlier experiments(on a different corpus) showed that, if a (1?p)-confidence interval is used, the size of the searchspace reduces exponentially as p increases, whilethe number of correct translation pairs that donot pass the filter is only linear in p (i.e., thefilter gives high recall and high precision).
Forthese experiments, p = 0.05; this value was se-lected based on the results presented in Smith(2001).4.3 ResultsWhen the length filter was applied to the1,000,000 possible pairs in the cross-product,47.9% of the pairs were eliminated, while 94.5%of the correct pairs were kept, on average (overten folds).
tsim was computed for each pairthat passed the filter, then each matching al-gorithm (MWBM and competitive linking) wasapplied.
As discussed above, a threshold canthen be applied to the matching to select thepairs about whose translational equivalence thescore is most confident.
Precision and recallplots are shown in Figure 2a.
Each line corre-sponds to a (translation lexicon, matching algo-rithm) pair, showing average precision and re-call over the ten folds as the threshold varies.The plots should be read from left to right, withrecall increasing as the threshold is lowered.When many resources are used, the techniqueis highly adept at selecting the translation pairs.TMTL alone outperforms DICT alone, proba-bly due to its coverage of domain-specific terms.The competitive linking algorithm lags behindMWBM in most cases, though its performancewas slightly better in the case of TMTL.
Inthe case of UTL, for recall up to 0.8251, thethresholded MWBM matching had significantlyhigher precision than the thresholded competi-tive linking matching at a comparable level ofrecall (based on a Sign Test over the ten cross-validation folds, p < 0.01).Table 1 shows the maximum performance(by F -score) for each translation lexicon underMWBM and competitive linking.4.4 Effects of NoiseNext, I performed an experiment to test thetechnique?s robustness to noise.
In this case,the test corpus contained 300 known transla-tion pairs (again, two-sentence texts).
From 0to 2700 additional English texts and the samenumber of Chinese texts were added.
These?noise?
texts were from the same corpus andwere guaranteed not to be aligned with eachother.7 The length filter eliminated 48.6% of the9,000,000 possible pairs in the cross-product,keeping 95.7% of the true pairs.
The filteredpairs were tsim-scored using UTL, then theMWBM was computed.
Precision and recallare plotted for various levels of noise in Fig-ure 2b.8 Only in the highest-noise condition( kn = 0.1) do we observe a situation where asufficiently strict threshold cannot be used toguarantee an extracted corpus of (nearly) ar-bitrarily high precision.
For example, if 90%precision is required, 88.3%, 60.3%, and 43.7%recall can be guaranteed when kn is 1, 0.5, and0.25, respectively.These experiments show that with a strictthreshold this technique is capable of produc-ing a highly precise matching of parallel textfrom a noisy corpus, though attainable recalllevels drop as noise is added.
Performance canbe boosted by incorporating additional bilingualresources.
Finally, even a fast, greedy approxi-7In general, robustness to noise will depend on thesource of the noise and how much the noise looks likethe true translations.
Hence the results presented heremay be better or worse than those achieved in specificapplications to which this technique might be applied,depending on those factors, filtering, etc.8Experiments were carried out for the TMTL andDICT translation lexicons, and also under competitivelinking.
Space does not permit a full discussion, thoughit is worth mentioning that, as in the noiseless experi-ment, UTL outperformed the others, likewise MWBMoutperformed competitive linking.Tr.
lex.
Algorithm ?
prec?
rec?
F?UTL MWBM 0.20000 0.908 0.836 0.871CL 0.22078 0.917 0.805 0.857DICT MWBM 0.10638 0.776 0.647 0.706CL 0.12121 0.770 0.590 0.668TMTL MWBM 0.00971 0.841 0.711 0.771CL 0.00909 0.854 0.711 0.776Table 1: Comparison of translation lexicons andmatching algorithms at their maximal F -scores.Note that thresholds, and tsim scores in general, arecomparable only for a given translation lexicon.
TheSTR translation lexicon offered a boost only whenused to supplement TMTL ?
DICT; when added toeach alone it had little or no effect.top 300 pairs maximum Fn prec rec ?
prec?
rec?
F?300 0.904 0.883 0.16667 0.925 0.863 0.893400 0.813 0.813 0.25641 0.897 0.787 0.838500 0.770 0.770 0.28000 0.881 0.717 0.791600 0.727 0.727 0.28000 0.782 0.707 0.743900 0.663 0.663 0.32142 0.829 0.600 0.6961200 0.630 0.630 0.32142 0.733 0.593 0.6563000 0.483 0.483 0.35849 0.617 0.440 0.514Table 2: Precision and recall when the top k (300)pairs are taken (i.e., k is known; in the case of n =300, the matching contained only 293 pairs), and atmaximal F -scores for various levels of noise.mation to the best matching can be useful.5 Experiment: English-FrenchAn important application of translation recog-nition is the construction of parallel text cor-pora.
One source of raw text in this task isthe World-Wide Web, for which several paral-lel text search systems currently exist (Resnik,1999; Nie et al, 1999; Ma and Liberman, 1999).These systems propose candidate pairs of pages,which are then classified as either translation-ally equivalent or not.
The STRAND system(Resnik, 1999), for example, uses structuralmarkup information from the pages, withoutlooking at their content, to attempt to alignthem.If the tsim technique can provide a classi-fier that rivals or complements the structuralone, using as it does an entirely orthogonal setof features, then perhaps a combined classifiercould provide even greater reliability.
In addi-tion, custom-quality parallel corpora could begenerated from comparable corpora that lackDICTTMTLUTLMWBMCL0.60.650.70.750.80.850.90.9510 0.2 0.4 0.6 0.8 1PrecisionRecall0 0.2 0.4 0.6 0.8 1Recall 0 0.20.4 0.60.8 1k / n00.20.40.60.81Precision(a) (b)Figure 2: (a.)
Precision and recall with no noise.
This plot shows precision and recall averaged over allten folds.
Each point corresponds to a threshold value; the threshold becomes less strict from left to right.Shown are curves for each of UTL, TMTL, and DICT under both algorithms (MWBM, CL); the maximumF scores are marked (see Table 1).
(b.)
Precision-recall curves at varying levels of noise.
k = 300 inall cases; the circles and dashed line show precision and recall for the top 300 pairs in the matching (i.e., if kwere known, it would not make sense to use a lower threshold, so the only reasonable thresholds are to theleft), and the squares and dotted line show precision and recall at each condition?s maximum F -score?thevalues are shown in Table 2.
(Note that the curves ?stop?
before reaching a point where recall is 1.0, sincea point is eventually reached where no more matches are possible (because of filtering).
)structural features.
This experiment also showsthat tsim is scalable to larger texts.5.1 Translation LexiconIn this experiment, the language pair is English-French.
Multiple sources for the translation lex-icon are used in a manner similar to Section 4.1.?
An English-French dictionary (a total of34,808 entries, 4,021 of which are not one-to-one).9 It contains morphological variants butdoes not include character accents.
Each n-to-m entry was processed by stoplisting and thenextracting all word-pairs in the remaining cross-product as in section 4.1.
Result: 39,348 wordpairs, 9,045 of which contain two words presentin the corpora.?
A word-to-word translation model (Melamed,2000) trained on a verse-aligned Bible usingMWBM (15,548 verses, averaging 25.5 Englishwords, 23.4 French words after tokenization).Result: 13,762 word pairs.?
English-French cognate pairs, identified us-ing the method of Tiedemann (1999).
Spacedoes not permit a full description of the tech-nique; I simply note that cognates were iden-tified by thresholding on a specially-trained9This dictionary was generated using a dictionary de-rived from one available at http://www.freedict.com.string-similarity score based on language-specific character-to-character weights.10 Re-sult: 35,513 word pairs.
An additional set of11,264 exact string matches were added.
Theseentries are quite noisy.The union of these translation lexicons consistsof 68,003 unique word pairs.
The experimentused only this union translation lexicon.5.2 ResultsIn order to compare tsim with structural simi-larity scoring, I applied it to 325 English-Frenchweb-document pairs.
These were the same pairsfor which human evaluations were carried out byResnik (1999).11 Note that this is not a match-ing task; the documents are presented as candi-date pairs, and there is no competition amongpages for matches in the other language.
At dif-ferent thresholds, a ?
score of agreement (witheach of Resnik?s (1999) two judges and their10Tiedemann trained these weights using a list ofknown cognates; I use a noisy list of weighted translationpairs (specifically, TMTL) Hence the resources requiredto extract cognates in this way are no different from thoserequired for the translation model.11One additional pair was thrown out because it con-tained compressed data; it is assumed that pair wouldnot pass a language identification filter.intersection) may be computed for comparisonwith Resnik?s STRAND system, along with re-call and precision against a gold standard (forwhich I use the intersection of the judges?theset of examples where the judges agreed).
Notethat recall in this experiment is relative to thecandidate set proposed by the STRAND searchmodule, not the WWW or even the set of pagesencountered in the search.The estimate of tsim (MWBM on the wordsin the document pair) is not computationallyfeasible for very large documents and transla-tion lexicons.
In preliminary comparisons, Ifound that representing long documents by asfew as their first 500 words results in excel-lent performance on the ?
measure.
This al-lows O(1) estimation of tsim for two documents:look only at the first (fixed) n words of eachdocument.
Further, the competitive linking al-gorithm appears to be as reliable as MWBM.The results reported here approximated tsim inusing competitive linking on the first 500 words.Of the 325 pairs, 32 were randomly selectedas a development set.
Maximizing ?
on this setyielded a value of ?
= 0.15.12 ?
scores againsteach judge and their intersection were then com-puted at that threshold on the test set (the re-maining 293 pairs).
These are compared to ?scores of the STRAND system, on the same testset, in Table 3.
In every case, the tsim classifieragreed more strongly with the human evalua-tions.At ?
= 0.15, precision was 0.680 and re-call was 0.921, F = 0.782 (on the sameset, STRAND structural classification achieved0.963 precision and 0.684 recall, F = 0.800).Figure 3 shows ?, precision, and recall plottedagainst ?
.6 Future DirectionsThe success of this approach suggests a way toconstruct parallel corpora from any large, seg-mented comparable corpus: start with a trans-lation model estimated on a small, high-qualityparallel text, and a core dictionary; then extractdocument pairs with high similarity (tsim) andadd them to the parallel corpus.
Next, esti-mate word-level translational equivalence em-pirically from the enlarged corpus and update12One could select such a threshold to maximize anyobjective function over the development set.Comparison N Pr(Agree) ?J1, J2 245 0.98 0.96J1, STRAND 250 0.88 0.70J2, STRAND 284 0.88 0.69J1 ?
J2, STRAND 241 0.90 0.75J1, tsim(?
= 0.15) 249 0.92 0.83J2, tsim(?
= 0.15) 283 0.92 0.82J1 ?
J2, tsim(?
= 0.15) 240 0.93 0.85Table 3: Comparison with STRAND.
The test set is294 of the 326 pairs in Resnik?s (1999) test set.
TheSTRAND ?
scores are similar to those published byResnik (1999).
The 32 development pairs were usedto select the 0.15 threshold.
N is the number ofexamples for which judgement-comparison was pos-sible in each case (human judges were sometimesundecided; those cases are ignored in computing ?
).STRAND:  best ?
?00.20.40.60.810 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4ThresholdPrecisionRecallCohen?sFigure 3: Performance measures as functions of thethreshold ?
: the ?
agreement score with the twojudges?
intersection, precision, and recall.
All mea-sures are on the test set.
The ?
score obtained bySTRAND is shown as well.the translation lexicon; extract documents iter-atively.
The experiments presented here showthat, even in highly noisy search spaces, tsimcan be used with a threshold to extract a high-precision parallel corpus at moderate recall.It is worth noting that the STRAND classi-fier and the tsim classifier disagreed 15% of thetime on the test set.
A simple combination bydisjunction (i.e., ?
(X,Y ) is a translation pair ifeither classifier says so?)
yields precision 0.768,recall 0.961, F = 0.854, and ?
(with the judges?intersection) at 0.878.
In future work, more so-phisticated combinations of the two classifiersmight integrate the advantages of both.7 ConclusionI have proposed a language-independent ap-proach to the detection of translational equiva-lence in texts of any size that works at variousbilingual resource levels.
Fast, effective approx-imations have also been described, suggestingscalability to very large corpora.
Notably, tsimis adaptable to any probabilistic model of trans-lational equivalence, because it is an instanceof a model-independent definition of similarity.The core of the technique is the computationof optimal matchings at two levels: betweenwords, to generate the tsim score, and betweentexts, to detect translation pairs.I have demonstrated the performance ofthis technique on English-Chinese and English-French.13 It is capable of pulling parallel textsout of a large multilingual collection, and itrivals the performance of structure-based ap-proaches to pair classification (Resnik, 1999),having better ?
agreement with human judges.AcknowledgementsThis work was supported in part by the Na-tional Science Foundation and DARPA/ITOCooperative Agreement N660010028910 (at theUniversity of Maryland) and a Fannie andJohn Hertz Foundation Fellowship.
The au-thor thanks Dan Melamed, Philip Resnik, DougOard, Rebecca Hwa, Jason Eisner, Hans Flo-rian, and Gideon Mann for advice and insight-ful conversations; also Gina Levow for makingavailable the bilingual dictionaries and PhilipResnik for sharing the STRAND test data andhuman judgements.ReferencesR.
K. Ahuja, T. L. Magnati, and J.
B. Orlin.
1993.Network Flows: Theory, Algorithms, and Appli-cations.
Prentice Hall, Englewood Cliffs, NJ.Y.
Al-Onaizan, J. Cur?in, M. Jahr, K. Knight, J. Laf-ferty, I. D. Melamed, N. A. Smith, F.-J.
Och,D.
Purdy, and D. Yarowsky.
1999.
Statistical Ma-chine Translation.
Technical report, Johns Hop-kins University.A.
L. Berger, P. F. Brown, S. A. Della Pietra,V.
J. Della Pietra, J. R. Gillett, J. D. Lafferty,R.
L. Mercer, H. Printz, and L. Ures?.
1994.13Comparable experiments using another version ofthe score showed performance for English-Spanish on thematching task to be even better than for English-Chinese(using that same score) (Smith, 2001).The Candide system for machine translation.
InARPA Workshop on Speech and Natural Lan-guage Technology, pages 157?163.
Morgan Kauf-man.A.
Z. Broder, S. C. Glassman, M. S. Manasse, andG.
Zweig.
1997.
Syntactic clustering of the Web.In Sixth International World-Wide Web Confer-ence, Santa Clara, CA.J.
Chen and J.-Y.
Nie.
2000.
Web parallel text min-ing for chinese-english cross-language informationretrieval.
In International Conference on ChineseLanguage Computing, Chicago, IL.M.
Damashek.
1995.
Gauging similarity with n-grams: language independent categorization oftext.
Science, 267:843?8.C.
Fluhr, F. Bisson, and F. Elkateb.
2000.
Mutualbenefit of sentence/word alignment and cross-lingual information retrieval.
In Ve?ronis, J.
(ed.
),Parallel Text Processing.
Kluwer Academic Pub-lishers, Dordrecht.U.
Germann, M. Jahr, K. Knight, D. Marcu, andK.
Yamada.
2001.
Fast decoding and optimaldecoding for machine translation.
In 39th ACL,Toulouse, France.G.-A.
Levow, D. W. Oard, and C. I. Cabezas.
2000.Translingual topic tracking with PRISE.
In TopicDetection and Tracking Workshop, Tysons Cor-ner, VA.D.
Lin.
1998.
An information-theoretic definitionof similarity.
In International Conference on Ma-chine Learning, Madison, WI.X.
Ma and M. Liberman.
1999.
BITS: a method forbilingual text search over the web.
In MachineTranslation Summit VII, Singapore.I.
D. Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.H.
Meng, B. Chen, E. Grams, S. Khudanpur, G.-A.Levow, W.-K.
Lo, D. W. Oard, P. Schone, H.-M.Wang, and J. Wang.
2000.
Mandarin-English: In-vestigating Translingual Speech Retrieval.
Tech-nical report, Johns Hopkins University.J.
Nie, P. Isabelle, M. Simard, and R. Durand.1999.
Cross-language information retrieval basedon parallel texts and automatic mining of paralleltexts from the Web.
In ACM-SIGIR Conference,pages 74?81, Berkeley, CA.P.
Resnik.
1999.
Mining the Web for bilingual text.In 37th ACL, College Park, MD.N.
A. Smith.
2001.
Detection of TranslationalEquivalence.
Undergraduate honors thesis, Uni-versity of Maryland.J.
Tiedemann.
1999.
Automatic construction ofweighted string similarity measures.
In Confer-ence on EMNLP and VLC, College Park, MD.
