Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1289?1297,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPOn the Use of Virtual Evidence in Conditional Random FieldsXiao LiMicrosoft ResearchOne Microsoft WayRedmond, WA 98052 USAxiaol@microsoft.comAbstractVirtual evidence (VE), first introducedby (Pearl, 1988), provides a convenientway of incorporating prior knowledge intoBayesian networks.
This work general-izes the use of VE to undirected graph-ical models and, in particular, to condi-tional random fields (CRFs).
We showthat VE can be naturally encoded into aCRF model as potential functions.
Moreimportantly, we propose a novel semi-supervised machine learning objective forestimating a CRF model integrated withVE.
The objective can be optimized us-ing the Expectation-Maximization algo-rithm while maintaining the discriminativenature of CRFs.
When evaluated on theCLASSIFIEDS data, our approach signif-icantly outperforms the best known solu-tions reported on this task.1 IntroductionStatistical approaches to sequential labeling prob-lems rely on necessary training data to model theuncertainty of a sequence of events.
Human?sprior knowledge about the task, on the other hand,often requires minimum cognitive load to spec-ify, and yet can provide information often com-plementary to that offered by a limited amount oftraining data.
Whenever prior knowledge becomesavailable, it is desired that such information is in-tegrated to a probabilistic model to improve learn-ing.Virtual evidence (VE), first introduced by Pearl(1988), offers a principled and convenient way ofincorporating external knowledge into Bayesiannetworks.
In contrast to standard evidence (alsoknown as observed variables), VE expresses aprior belief over values of random variables.
Ithas been shown that VE can significantly extendthe modeling power of Bayesian networks withoutcomplicating the fundamental inference method-ology (Bilmes, 2004; Reynolds and Bilmes,2005).This work extends the use of VE to undi-rected graphical models and, in particular, to con-ditional random fields (CRFs).
We show thatVE can be naturally encoded into an undirectedgraphical model as potential functions.
More im-portantly, we discuss a semi-supervised machinelearning setting for estimating CRFs with the pres-ence of VE.
As the conditional likelihood objec-tive of CRFs is not directly maximizable with re-spect to unlabeled data, we propose a novel semi-supervised learning objective that can be opti-mized using the Expectation-Maximization (EM)algorithm while maintaining the discriminativenature of CRFs.We apply our model to the CLASSIFIEDS data(Grenager et al, 2005).
Specifically, we use VE toincorporate into a CRF model two types of priorknowledge specified in previous works.
The firstis defined based on the notion of prototypes, i.e.,example words for a given label; and the other as-sumes that adjacent tokens tend to have the samelabel.
When unlabeled data becomes available,we further extend the sparse prototype informa-tion to other words based on distributional similar-ity.
This results in so-called collocation lists, eachconsisting of a relatively large number of noisy?prototypes?
for a label.
Given the fact that thesenoisy prototypes are often located close to eachother in an input sequence, we create a new typeof VE based on word collocation to reduce ambi-guity.1289We compare our CRF model integrated with VEwith two state-of-the-art models, i.e., constraint-driven learning (Chang et al, 2007) and gener-alized expectation criteria (Mann and McCallum,2008).
Experiments show that our approach leadsto sequential labeling accuracies superior to thebest results reported on this task in both supervisedand semi-supervised learning.2 Related workThere have been various works that make useof prior knowledge in sequential labeling tasks.Grenager et al (2005) explicitly constrain thetransition matrix of a hidden Markov model(HMM) to favor self transitions, assuming thatfields tend to consist of consecutive runs of thesame label.Prototype-drive learning (Haghighi and Klein,2006) specifies prior knowledge by providing afew prototypes (i.e., canonical example words) foreach label.
This sparse prototype information isthen propagated to other words based on distri-butional similarity.
The relation between wordsand their prototypes are then used as features ina Markov random field (MRF) model.
Since anMRF model aims to optimize the joint probabilityp(x,y) of input and state sequences, it is possibleto apply the EM algorithm for unsupervised/semi-supervised learning.Constraint-driven learning (Chang et al, 2007)expresses several kinds of constraints in a unifiedform.
In inference, a new decision function is pro-posed to penalize the violation of the desired con-straints as follows,argmaxy?
?
F (x,y) ?
?k?kd(y, 1Ck(x)) (1)Here ?
?
F (x,y) is a linear decision function ap-plicable to a number of sequential models, suchas HMMs, MRFs and CRFs.
Function d is imple-mented as the Hamming distance (or its approx-imation) between a hypothesis sequence and thespace of state sequences that satisfy the constraintCi.
Due to the nature of the distance function,their work approximates EM training by findingthe top K hypothesis sequences and using them asnewly labeled instances to update the model.
Thisprocess is repeated for a number of iterations in aself-training fashion (Yarowsky, 1995).Generalized expectation criteria (Mann andMcCallum, 2008) represent prior knowledge as la-beled features, and use such information to reg-ularize semi-supervised learning for CRFs.
For-mally, their learning objective consists of the stan-dard CRF training objective, plus a Gaussian prioron model parameters and an additional regulariza-tion term:1?ilog p?(y(i)|x(i))?12?2???2??D(p?||p??)
(2)In the last term, p?
and p?
?both refer to conditionaldistributions of labels given a feature.
While theformer is specified by prior knowledge, and thelatter is estimated from unlabeled data.Our approach incorporates prior knowledge asvirtual evidence to express preferences over thevalues of a set of random variables.
The no-tion of VE was first introduced by Pearl (1998)and further developed by Bilmes (2004), both inthe context of Bayesian networks.
Different fromconstraint-driven learning, VE can be formally en-coded as part of a graphical model.
The funda-mental inference methodology, therefore, does notneed to be altered.
Moreover, VE has the flexibil-ity of representing various kinds of prior knowl-edge.
For example, Reynolds and Bilmes (2005)use VE that explicitly favors self transitions in dy-namic Bayesian networks.This work extends the use of VE to CRFs.
Inessence, VE herein can be viewed as probabilisticconstraints in an undirected graph that allow exactinference.
One of the biggest challenges of such amodel lies in the semi-supervised machine learn-ing setting.
Since the entire state sequence of anunlabeled instance remains hidden, the conditionallikelihood objective of CRFs is not directly opti-mizable.
There have been a number of works thataddress this problem for conditional models.
Forexample, minimum entropy regularization (Grand-valet and Bengio, 2004; Jiao et al, 2006), aimsto maximize the conditional likelihood of labeleddata while minimizing the conditional entropy ofunlabeled data:?ilog p?(y(i)|x(i))?12?2???2?
?H(y|x) (3)This approach generally would result in ?sharper?models which can be data-sensitive in practice.Another approach (Suzuki and Isozaki, 2008)embeds a joint probability model (HMM in their1We slightly modify the notation here to be consistentwith the rest of the paper.1290case) into a CRF model as a new potential func-tion.
Semi-supervised learning is then conductedby iteratively (1) fixing the HMM and updatingCRF parameters on labeled data and (2) fixing theCRF model and updating the HMM on unlabeleddata.Additionally, when unlabeled instances havepartial labeling information, it is possible to op-timize a marginal distribution of the conditionallikelihood, i.e., p?
(y(i)o|x), on unlabeled data.Here y(i)ois a subvector of y(i) that denotes the setof observed state variables.
The optimization canbe done in a similar fashion as training a hidden-state CRF model (Quattoni et al, 2007).3 TaskWe consider the problem of extracting fields fromfree-text advertisements.
We use the CLASSI-FIEDS data (Grenager et al, 2005) which consistsof 8767 ads for apartment rental.
302 of the adsin the CLASSIFIEDS data have been manually-labeled with 12 fields, including size, rent, neigh-borhood and so on.
The labeled data has been di-vided into train/dev/test sets with 102/100/100 adsrespectively.
The evaluation metric is the token-level accuracy where tokens include both wordsand punctuations.Our goal in this work is two folds: (1) lever-age both the training data and the prior knowledgespecified for this task for supervised learning, and(2) additionally use the unlabeled data for semi-supervised learning.
We exploit two types of priorknowledge:?
K1: label consistency with prototypes;?
K2: label consistency within a sentence.K1 involves a set of prototype lists.
Each list isattached with a label and consists of a set of ex-ample words for that label.
In this work, we usethe prototype lists originally defined by Haghighiand Klein (2006) (HK06) and subsequently usedby Chang et al (2005) (CRR07) and Mann andMcCallum (2008) (MM08).
The labels as well astheir prototypes are shown in the first two columnsof Table 1.
Our model is desired to be consistentwith such prototype information.
Secondly, K2means that tokens tend to have consistent labelswithin a sentence.
A similar type of prior knowl-edge is implemented by CRR07 as a constraint ininference.4 Conditional Random FieldsConditional random fields are a probabilisticmodel that directly optimizes the conditional prob-ability of a state (label) sequence given an inputsequence (Lafferty et al, 2001).
Formally, we letx = (x1, x2, .
.
.
, xT) denote an input sequenceof T tokens, and y = (y1, y2, .
.
.
, yT) the cor-responding state sequence.
We further augmenty with two special states, Start and End,2 repre-sented by y0and yT+1respectively.
A linear-chainCRF model is an undirected graphical model asdepicted in Figure 1(a), with the conditional prob-ability given byp?
(y|x) =1Z?(x)?t?(t)?
(x, yt?1, yt) (4)The partition function Z?
(x) normalizes the expo-nential form to be a probability distribution.
?
(t)?are a set of potential functions defined on the max-imum cliques of the graph, i.e., (x, yt?1, yt) in thecase of a linear-chain CRF model.
The potentialfunctions are typically in the form of?(t)?
(x, yt?1, yt) = exp(?
?
f(x, yt?1, yt, t))(5)where ?
is a weight vector and f is a feature vectorof arbitrary functions of the corresponding clique.Given a set of labeled examples{x(i),y(i))}mi=1, we can estimate model pa-rameters in a supervised machine learning setting.The objective is to estimate ?
that maximizesthe conditional likelihood while regularizing themodel size:L1=m?i=1log p?
(y(i)|x(i)) ?12?2??
?2 (6)In this work, we optimize L1using stochastic gra-dient descent and use the accuracy on the develop-ment set as the stopping criterion.5 CRFs with Virtual EvidenceA canonical way of using virtual evidence (VE)in Bayesian networks is to have a directed edgefrom a hidden variable h to a VE variable v. Thevariable v will always be observed with a partic-ular value, e.g., v = 1, but the actual value itselfdoes not matter.
The prior knowledge about h is2Start and End are with regard to a document, which aredifferent from start and end of a sentence.1291xyT EndStart y1 y2(a)(b)xyTEndStart y1 y2vT=1v1=1 v2=1 vT+1=1Figure 1: Graphical model representations of (a) aCRF model and (b) a CRF model integrated withvirtual evidence.
Solid and empty nodes denoteobserved and hidden variables respectively.expressed via the conditional probability p(v =1|h).
For example, by setting p(v = 1|h = a) >p(v = 1|h = b), we know that h = a is morelikely a event than h = b.
This conditional distri-bution is not learned from data, Instead, it is pre-defined in such a way that reflects a prior beliefover the value of h.VE can be encoded in an undirected graphicalmodel in a similar fashion.
For our task, we mod-ify the structure of a linear-chain CRF model asdepicted in Figure 1(b) ?
we create a sequenceof VE variables, denoted by v1, v2, .
.
.
, vT+1, inparallel to the state variables.
Each vtis assigneda constant 1 (one), and is connected with yt?1and yt, forming a new set of maximum cliques(yt?1, yt, vt), t = 1, .
.
.
, T + 1.
We create cliquesof size 3 because it is the minimum size required torepresent the prior knowledge used in our task, aswill be discussed shortly.
However, it is possibleto have a different graph structure to incorporateother types of prior knowledge, e.g., using largecliques to represent constraints that involve morevariables.Next, in analogy to Equation (5), we define thecorresponding potential functions as follows,?
(t)(yt?1, yt, vt) = exp(?
?
s(yt?1, yt, vt, t))(7)s is a vector of VE feature functions and ?
is thecorresponding weight vector with pre-defined val-ues.
Given the new graphical model in Figure 1(b).It is natural to model the conditional probabilityof the state sequence given both the standard evi-dence and the VE as follows,p?(y|x,v)=1Z?(x,v)?t?(t)?
(x, yt?1, yt)?
(t)(yt?1, yt, vt)(8)Analogous to using p(v = 1|h) in Bayesian net-works, we can utilize ?
(t)(yt?1, yt,v = 1) to ex-press preferences over state hypotheses in a CRFmodel.
In general, the function form of ?
(t) mayor may not depend on the input x.
Even when ?
(t)does depend on x, the relation is completely deter-mined by external knowledge/systems (as opposedto by data).
Thus we do not explicitly connect vwith x in the graph.5.1 Incorporating prior knowledgeNow we show how to represent the prior knowl-edge introduced in Section 3 using the VE fea-ture functions.
Unless otherwise stated, we as-sume vt= 1 for all t = 1, .
.
.
, T and simply usevtinstead of vt= 1 in all equations.
First, wedefine a VE function s1that represents K1: labelconsistency with prototypes.
We let Pldenote aprototype list associated with the label l. If xtbe-longs to Pl, we should prefer yt= l as opposed toother values.
To this end, for cases where xt?
Pl,we set s1ass1(yt, vt, t) ={1 if yt= l0 otherwise (9)On the other hand, if xtis not a prototype, we willalways have s1(yt, vt, t) = 0 for all hypothesesof yt.
The impact of this prior knowledge is con-trolled by the weight of s1, denote by ?1.
At oneextreme where ?1= 0, the prior knowledge iscompletely ignored in training.
At the other ex-treme where ?1?
+?, we constrain the valuesof state variables to agree with the prior knowl-edge.
Note that although s1is implicitly related tox, we do not write s1as a function of x for consis-tency with the general definition of VE.1292To represent K2: label consistency within a sen-tence, we define a second VE feature function s2with weight ?2.
Assume that we have an exter-nal system that detects sentence boundaries.
If itis determined that xtis not the start of a sentence,we set s2ass2(yt?1, yt, vt, t) ={1 if yt?1= yt0 otherwise (10)It is easy to see that this would penalize state tran-sitions within a sentence.
On the other hand, if xtis a sentence start, we set s2(yt?1, yt, vt, t) = 0 forall possible (yt?1, yt) pairs.
In this work, we usea simple heuristics to detect sentence boundaries:we determine that xtis the start of a sentence if itsprevious token xt?1is a period (.
), a semi-colon(;) or an acclamation mark (!
), and if xtis not apunctuation.5.2 Semi-supervised learningWhen a large amount of unlabeled data is avail-able, it is often helpful to leverage such datato improve learning.
However, we cannot di-rectly optimize p(y|x,v) since the correct statesequences of the unlabeled data are hidden.
Oneheuristic approach is to adapt the self-training al-gorithm (Yarowsky, 1995) to our model.
Morespecifically, for each input in the unlabeled dataset{x(i)}ni=m+1, we decode the best state sequence,?y(i)= argmaxy(i)p(y(i)|x(i),v(i)) (11)Then we use {(x(i), ?y(i))}ni=m+1in addition to thelabeled data to train a supervised CRF model.
Thisapproach, however, does not have a theoreticalguarantee on optimality unless certain nontrivialconditions are satisfied (Abney, 2004).On the other hand, it is well known that unla-beled data can be naturally incorporated using agenerative approach that models a joint probabil-ity (Nigam et al, 2000).
This is achieved by max-imizing a marginal distribution of the joint proba-bility over hidden variables.
Inspired by the gen-erative approach, we propose to explicitly modelp(y,v|x).
In contrast to Equation (8), here wejointly model y and v but the probability is stillconditioned on x.
This ?joint?
distribution shouldbe chosen such that it results in the same condi-tional distribution p(y|x,v) as defined in Equa-tion (8).
To this end, we define p?
(y,v|x) asp?(y,v|x)=1Z??(x)?t?(t)?
(x, yt?1, yt)?
(t)(yt?1, yt, vt)(12)Here Z ??
(x) is a normalization function obtainedby summing the numerator over both y and v.By applying the Bayes rule, it is easy to see thatp(y|x,v) is exactly equal to Equation (8).Given unlabeled data {x(i)}ni=m+1, we aim tooptimize the following objective,3L2=m+n?i=1log p?(v(i)|x(i))?12?2??
?2 (13)This is essentially the marginal distribution ofp(y,v|x) over hidden variables y.
Here we ig-nore the labels of the dataset {(x(i),y(i))}mi=1, butwe do use the label information in initializing themodel which will described in Section 6.
To op-timize such an objective, we apply the EM algo-rithm in the same fashion as is used in a generativeapproach.
In other words, we iteratively optimizeQ(?)
=?yp?g(y|x,v) log p?
(y,v|x) where ?gdenotes the model estimated from the previous it-eration.
The gradient of the Q function is straight-forward to compute with the result given by?Q(?)?
?k=?t?yt?1,ytfk(yt?1, yt,x, t)?(p?
(yt?1, yt|x,v) ?
p?
(yt?1, yt|x))(14)We keep two sets of accumulators in running theForward-Backward algorithm, one for comput-ing p?
(yt?1, yt|x,v) and the other for computingp?
(yt?1, yt|x).
Loosely speaking, the model willconverge to a local optimum if the difference be-tween these two posterior probabilities becomestrivial.5.3 Collocation based virtual evidencePrior knowledge represented by prototypes is typ-ically sparse.
This sparse information, however,can be propagated across all data based on dis-tributional similarity (Haghighi and Klein, 2006).Following the same idea, we extend the prototypelists as follows.
(1) We merge all prototypes inPlinto a single word type wl.
(2) For each word3In Equation (13), the fact that v is assigned a constant 1does not mean p(v = 1|x) = 1 (Bilmes, 2004)1293Label Prototype lists of HK06 Collocation lists (top examples)ADDRESS address carlmont [4-digit] street [3-digit] streetsAVAILABLE immediately begin cheaper availableCONTACT [phone] call [time] [email] appointment email see today ...FEATURES kitchen laundry parking room new covered building garage ...NEIGHBORHOOD close near shopping transportation center located restaurants ...PHOTOS pictures image link [url] click view photosRENT $ month [amount] lease deposit security year agreement ...RESTRICTIONS pets smoking dog ok sorry please allowed negotiable ...ROOMMATES roommate respectful dramaSIZE [1-digit] br sq [4-digit] [3-digit] ft bath ba ...UTILITIES utilities pays electricity water included owner garbage paidTable 1: Field labels (except other) for the CLASSIFIEDS task, their respective prototype lists specifiedby prior knowledge, and collocation lists mined from unlabeled data.in the corpus, we collect a context vector of thecounts of all words (excluding stop words) thatoccur within a window of size k in either direc-tion, where the window is applied only within sen-tence boundaries.
(3) Latent semantic analysis(Deerwester et al, 1990) is performed on the con-structed context vectors.
(4) In the resulting latentsemantic space, all words (except stop words) thathave a high enough dot product with wlwill begrouped to form a new set, denoted as Cl, whichis a superset of Pl.
In this regard, Clcan be viewedas lists of noisy ?prototypes?.
As observed inHK06, another consequence of this method is thatmany neighboring tokens will share the same pro-totypes.Differently from previous works, we use Cldirectly as virtual evidence.
We could applys1in Equation (9) when xt?
Cl(as opposedto when xt?
Pl).
This, however, would con-taminate our model since Clare often noisy.For example, ?water?
is found to be distribu-tionally similar to the prototypes of utilities.Although in most cases ?water?
indeed meansutilities, it can mean features in the contextof ?water front view?.
To maximally reduceambiguity, we propose to apply s1in Equa-tion (9) if both of the following conditions hold,(1) xt?
Cl(2) There exists ?
s.t.
|?
?
t| < k, and x??
ClIn other words, we will impose a non-uniformprior on ytif xt?
Cl?collocates?, within ktokens, with another word that belongs to Cl.Based on K2, it is reasonable to believe thatneighboring tokens tend to share the same label.Therefore, knowing that two tokens close to eachother both belong to Clwould strengthen ourbelief that either word is likely to have label l.We thus refer to this type of virtual evidenceas collocation-based VE, and refer to Clascollocation lists.6 EvaluationWe use the CLASSIFIEDS data provided byGrenager et al (2005) and compare with re-sults reported by CRR07 (Chang et al, 2007) andMM08 (Mann and McCallum, 2008) for both su-pervised and semi-supervised learning.
Followingall previous works conducted on this task, we to-kenized both words and punctuations, and createda number of regular expression tokens for phonenumbers, email addresses, URLs, dates, moneyamounts and so on.
However, we did not tokenizenewline breaks, as CRR07 did, which might beuseful in determining sentence boundaries.
Basedon such tokenization, we extract n-grams, n =1, 2, 3, from the corpus as features for CRFs.As described in Section 3, we integrate the priorknowledge K1 and K2 in our CRF model.
Theprototypes that represent K1 are given in Table 1.CRR07 used the same two kinds of prior knowl-edge in the form of constraints, and they imple-mented another constraint on the minimum num-ber of words in a field chunk.
MM08 used almostthe same set of prototypes as labeled features, butthey exploited two sets of 33 additional featuresfor some experiments.
In this regard, the compar-ison between CRR07, MM08 and the method pre-sented here cannot be exact.
However, we showthat while our prior knowledge is no more thanthat used in previous works, our approach is able1294# labeled examplesSupervised model 10 25 100CRR07: HMM 61.6 70.0 76.3+ Constr in decoding 66.1 73.7 80.4MM08: CRF 64.6 72.9 79.4CRF 62.3 71.4 79.1+ VE in decoding 68.9 74.6 81.1CRF + VE (auto weights) 48.0 54.8 59.8+ VE in decoding 66.0 72.5 80.9Table 2: Token-level accuracy of supervised learn-ing methods; ?+ VE?
refers to the cases whereboth kinds of prior knowledge, K1 and K2, are in-corporated as VE in the CRF model.to achieve the state-of-art performance.6.1 Decoding settingsDepending on whether VE is used at test time, weexplore two decoding settings in all experiments:1.
Find y that maximizes p?
(y|x) as in standardCRF decoding, ignoring virtual evidence.2.
Find y that maximizes p(y|x,v).
We use ?+VE in decoding?
to represent this setting.These two scenarios are analogous to those inCRR07 which conducted HMM decoding with-out/with constraints applied.
We use ?+ constr.
indecoding?
to represent the latter scenario of theirwork.
MM08, on the other hand, found no accu-racy improvement when adding constraints at testtime.Note that in our second decoding setting, theweights for the VE feature functions, i.e., ?1and?2, are tuned on the development set.
This is doneby a greedy search that first finds the best ?1, andthen finds the best ?2while fixing the value of ?1,both with a step size 0.5.6.2 Supervised learning resultsFirst, we experimented with a standard CRFmodel with VE applied neither in training nor indecoding.
As shown in Table 2, our CRF imple-mentation performed slightly worse than the im-plementation by MM08, probably due to slightdifference in tokenization.
Secondly, we used thesame CRF model but additionally applied VE indecoding, corresponding to the second setting inSection 6.1.
This method gave a significant boostto the tagging performance, yielding the best su-pervised learning results (shown as bolded in the# labeled examplesSemi-supervised models 10 25 100CRR07: HMM + Constr 70.9 74.8 78.6+ Constr in decoding 74.7 78.5 81.7MM08: CRF + GE 72.6 76.3 80.1CRF + VE (Self-train) 69.0 74.2 81.4+ VE in decoding 69.1 75.2 81.2CRF + Col-VE (Self-train) 73.1 76.4 81.8+ Col-VE in decoding 75.7 77.6 82.9CRF + Col-VE (EM) 78.3 79.1 82.7+ Col-VE in decoding 78.8 79.5 82.9Table 3: Token-level accuracy of semi-supervisedlearning methods.
?+ Col-VE?
refers to caseswhere collocation-based VE is integrated in theCRF model in addition to the VE representing K1and K2.table).
This proves that the prior knowledge is in-deed complementary to the information offered bythe training data.Similar to the second decoding setting that in-corporates VE, we can have a counterpart settingat training time.
In other words, we can optimizep?
(y|x,v) instead of p?
(y|x) during learning.
Indeciding ?
= (?1, ?2), it is possible to learn ?from data in the same way as how we learn ?.This, however, might undermine the role of otheruseful features since we do not always have suffi-cient training data to reliably estimate the weightof prior knowledge.
As shown in Table 2, we ex-perimented with learning ?
automatically (shownas ?auto weights?).
While applying VE with suchweights in both training and decoding worked rea-sonably well, applying VE only in training but notin decoding yielded very poor performance (prob-ably due to excessively large estimates of ?1and?2).
Additionally, we repeated the above experi-ment with manually specified weights, but did notfind further accuracy improvement over the bestsupervised learning results.6.3 Semi-supervised learning resultsOne natural way of leveraging the unlabeled data(more than 8K examples) is to perform semi-supervised learning in a self-training fashion.
Tothis end, we used our best supervised model in Ta-ble 2 to decode the unlabeled examples as wellas the test-set examples (by treating them as un-labeled).
Note that by doing this our comparisonwith CRR07 and MM08 cannot be exact as they1295sampled the unlabeled examples, with differentrates, for semi-supervised learning, while we usedas much data as possible.
We applied the same ?that was used for the supervised model, and thencombined the newly labeled examples, in additionto the manually labeled ones, as training data tolearn a supervised CRF model.
On this particu-lar dataset, we did not find it helpful by selectingautomatically labeled data based on a confidencethreshold.
We simply used all data available inself-training.
This paradigm is referred to as ?CRF+ VE (self-train)?
in Table 3.
When no VE is ap-plied at test time, this semi-supervised CRF modelsignificantly outperformed the best model in Ta-ble 2.
When applying VE at test time, however,the improvement over its supervised counterpartbecame trivial.Next, following Section 5.3, we collected con-text vectors on the unlabeled data using a win-dow size k = 3, and extracted the top 50 singularvectors therefrom.4 We created collocation liststhat contain words close to the merged prototypewords in the latent semantic space.
Some exam-ples are given in the last column of Table 1.
Wethen augmented the prototype-based VE based onthe following rules: If xtbelongs to any prototypelist Pl, we directly apply s1in Equation (9); oth-erwise, we apply s1if xtand at least one neigh-bor (within 3 tokens from xt) belong to the samecollocation list Cl.
In our experiments, we let?Col-VE?
represent such collocation-based VE.We conducted self-training using a CRF model in-tegrated with Col-VE, where ?
was tuned a pri-ori by testing the same model on the develop-ment set.
As shown in the table, ?CRF + Col-VE(self-train)?
gave significant accuracy improve-ment over ?CRF + VE?, while adding Col-VE attest time further boosted the performance.
The ac-curacies were already on par with the best resultspreviously reported on this task.Finally, we implemented the EM algorithm pro-posed in Section 5.2 that iteratively optimizesp(v|x) on all data.
The model was initial-ized by the one obtained from ?CRF + Col-VE(self-train)?.
After the model was initialized,we performed the EM algorithm until the modelreached a maximum accuracy on the develop-ment set.
Note that in some cases, we observeda development-set accuracy degradation after thefirst iteration of the EM, but the accuracy quickly4The same configuration is used in HK06.recovered from the second iteration and kept in-creasing until a maximum accuracy was reached.5As shown in the last two rows in Table 3, thismethod is clearly advantageous over self-training,leading to the best tagging accuracies in both de-coding settings.
Our model achieved 2.6%?5.7%absolute accuracy increases in the three trainingsettings compared with MM08 which had the bestresults without using any constraints in decoding.When applying VE at test time, our model was1.2% ?
4.1% better than CRR07 which had thebest overall results.
Additionally, when comparedwith supervised learning results, our best semi-supervised model trained on only 10 labeled ex-amples performed almost as well as a standard su-pervised CRF model trained on 100 labeled exam-ples.7 ConclusionsWe have presented the use of virtual evidence asa principled way of incorporating prior knowledgeinto conditional random fields.
A key contribu-tion of our work is the introduction of a novelsemi-supervised learning objective for training aCRF model integrated with VE.
We also found ituseful to create so-called collocation-based VE,assuming that tokens close to each other tend tohave consistent labels.
Our evaluation on theCLASSIFIEDS data showed that the learning ob-jective presented here, combined with the use ofcollocation-based VE, yielded remarkably goodaccuracy performance.
In the future, we wouldlike to see the application of our approach to othertasks such as (Li et al, 2009).ReferencesSteven Abney.
2004.
Understanding the Yarowskyalgorithm.
Association for Computational Linguis-tics, 30(3):365?395.Jeff Bilmes.
2004.
On soft evidence in Bayesiannetworks.
Technical Report UWEETR-2004-0016,University of Washington, Dept.
of Electrical Engi-neering.Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007.Guiding semi-supervision with constraint-drivenlearning.
In Proceedings of ACL.5The initial degradation is probably due to the fact thatself-training can result in an initial model with decent accu-racy but low p(v|x); thus the EM algorithm that maximizesp(v|x) may temporarily decrease the accuracy.1296Scott Deerwester, Susan Dumais, Thomas Landauer,George Furnas, and Richard Harshman.
1990.Indexing by latent semantic analysis.
Journalof the American Society of Information Science,41(6):391?407.Yves Grandvalet and Yoshua Bengio.
2004.
Semi-supervised learning by entropy minimization.
In Ad-vances in Neural Information Processing Systems.Trond Grenager, Dan Klein, and Christopher D. Man-ning.
2005.
Unsupervised learning for field seg-mentation models for information extraction.
InProceedings of Association of Computational Lin-guistics.Aria Haghighi and Dan Klein.
2006.
Prototype-drivenlearning for sequence models.
In Proceedings ofHLT-NAACL.Feng Jiao, Shaojun Wang, Chi-Hoon Lee, RussellGreiner, and Dale Schuurmans.
2006.
Semi-supervised conditional random fields for improvedsequence segmentation and labeling.
In Proceed-ings of ACL.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of the InternationalConference on Machine Learning, pages 282?289.Xiao Li, Ye-Yi Wang, and Alex Acero.
2009.
Extract-ing structured information from user queries withsemi-supervised conditional random fields.
In Pro-ceedings of SIGIR.Gideon Mann and Andrew McCallum.
2008.
General-ized expectation criteria for semi-supervised learn-ing of conditional random fields.
In Proceedings ofACL.Kamal Nigam, Andrew Kachites Mccallum, SebastianThrun, and Tom Mitchell.
2000.
Text classificationfrom labeled and unlabeled documents using EM.Machine Learning, 39:103?134.Judea Pearl.
1988.
Probabilistic Reasoning in In-telligent Systems: Networks of Plausible Inference.Morgan Kaufmann, 2nd printing edition edition.A.
Quattoni, S. Wang, L.-P. Morency, M. Collins, andT.
Darrell.
2007.
Hidden conditional random fields.IEEE Transaction on Pattern Analysis and MachineIntellegence, 29(10):1848?1852.Sheila Reynolds and Jeff Bilmes.
2005.
Part-of-speechtagging using virtual evidence and negative training.In Proceedings of HLT/EMNLP.Jun Suzuki and Hideki Isozaki.
2008.
Semi-supervisedsequential labeling and segmentation using giga-word scale unlabeled data.
In Proceedings ofACL/HLT.David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In Pro-ceedings of ACL, pages 189?196.1297
