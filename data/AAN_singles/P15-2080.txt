Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 489?494,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsUser Based Aggregation for Biterm Topic ModelWeizheng Chen, Jinpeng Wang, Yan Zhang , Hongfei Yan and Xiaoming LiSchool of Electronic Engineering and Computer Science, Peking University, China{cwz.pku,wjp.pku,yhf1029}@gmail.com, zhy@cis.pku.edu.cn, lxm@pku.edu.cnAbstractBiterm Topic Model (BTM) is designedto model the generative process ofthe word co-occurrence patterns inshort texts such as tweets.
However,two aspects of BTM may restrict itsperformance: 1) user individualities areignored to obtain the corpus level wordsco-occurrence patterns; and 2) the strongassumptions that two co-occurring wordswill be assigned the same topic labelcould not distinguish background wordsfrom topical words.
In this paper, wepropose Twitter-BTM model to addressthose issues by considering user levelpersonalization in BTM.
Firstly, weuse user based biterms aggregation tolearn user specific topic distribution.Secondly, each user?s preference betweenbackground words and topical words isestimated by incorporating a backgroundtopic.
Experiments on a large-scalereal-world Twitter dataset show thatTwitter-BTM outperforms several state-of-the-art baselines.1 IntroductionIn recent years, short texts are increasingly preva-lent due to the explosive growth of online socialmedia.
For example, about 500 million tweets arepublished per day on Twitter1, one of the mostpopular online social networking services.
Proba-bilistic topic models (Blei et al., 2003) are broadlyused to uncover the hidden topics of tweets, s-ince the low-dimensional semantic representationis crucial for many applications, such as prod-uct recommendation (Zhao et al., 2014), hashtagrecommendation (Ma et al., 2014), user interesttracking (Sasaki et al., 2014), sentiment analysis1See https://about.Twitter.com/company(Si et al., 2013).
However, the scarcity of contextand the noisy words restrict LDA and its variationsin topic modeling over short texts.Previous works model topic distribution atthree different levels for tweets: 1) document,the standard LDA assumes each document isassociated with a topic distribution (Godin etal., 2013; Huang, 2012).
LDA and its variationssuffer from context sparsity in each tweet.
2)user, user based aggregation is utilized to alleviatethe sparsity problem in short texts (Weng et al.,2010; Hong and Davison, 2010).
In these models,all the tweets of the same user are aggregatedtogether as a pseudo document based on theobservation that the tweets written by the sameuser are more similar.
3) corpus, BTM (Yan et al.,2013) assumes that all the biterms (co-occurringword pairs) are generated by a corpus level topicdistribution to benefit from the global rich wordco-occurrence patterns.As far as we know, how to incorporate userfactor into BTM has not been studied yet.
Userbased aggregation has proven effective for LDA.But unfortunately, our preliminary experiments in-dicate that simple user-based aggregation for BTMwill generate incoherent topics.
To distinguish be-tween commonly used words (e.g., good, people,etc) and topical words (e.g., food, travel, etc), abackground topic is often incorporated into thetopic models.
Zhao et al.
(2011) use a back-ground topic in Twitter-LDA to distill discrimi-native words in tweets.
Sasaki et al.
(2014) re-duce the perplexity of Twitter-LDA by estimatingthe ratio between choosing background words andtopical words for each user.
They both make a verystrong assumption that one tweet only covers onetopic.
Yan et al.
(2015) use a background topic todistinguish between common biterms and burstybiterms, which need external data to evaluate theburstiness of each biterm as prior knowledge.
Un-like those above, we incorporate a background489topic to absorb non-discriminative common wordsin each biterm.
And we also estimate the user?spreference between common words and topicalwords.
Our new model is named as Twitter-BTM,which combines user based aggregation and thebackground topic in BTM.
Finally, experiments ona Twitter dataset show that Twitter-BTM not onlycan discover more coherent topics but also cangive more accurate topic representation of tweetscompared with several state-of-the-art baselines.We organize the rest of the paper as follows.Section 2 gives a brief review for BTM.
Section3 introduces our Twitter-BTM model and its im-plementation.
Section 4 describes experimentalresults on a large-scale Twitter dataset.
Finally,Section 5 contains a conclusion and future work.2 BTMThere are two major differences between BTMand LDA (Yan et al., 2013).
For one thing, con-sidering a topic is a mixture of highly correlatedwords, which implies that they often occur togeth-er in the same document, BTM models the gen-erative process of the word co-occurrence patternsdirectly.
Thus a document made up of n words willbe converted to C2nbiterms.
For another, LDA andits variants suffer from the severe data sparsity inshort documents.
BTM uses global co-occurrencepatterns to model the topic distribution over corpuslevel instead of document level.The graphical representation of BTM (Yan etal., 2013) is shown in Figure 1(a).
It assumesthat the whole corpus is associated with a distri-butions ?
over K topics drawn from a Dirichletprior Dir(?).
And each topic t is associated witha multinomial distribution ?tover a vocabularyof V unique words drawn from a Dirichlet pri-or Dir(?).
The generative process for a corpuswhich consists of NBbiterms B = {b1, ..., bNB},where bi= (wi1, wi2), is as follows:1 For each topic t=1,...,T(a) Draw ?t?
Dir(?
)2 For the whole tweets collection(a) Draw ?
?
Dir(?
)3 For each biterm b = 1,...,NB(a) Draw zb?Multi(?
)(b) Draw wb,1, wb,2?Multi(?zb)In the above process, zbis the topic assign-ment latent variable of biterm b.
To infer theparameters ?
and ?, collapsed Gibbs sampling??NB2wz?K?k?
?NuU2?y wz?
?K?k?B(a) BTM (b) Twitter-BTMFigure 1: Graphical representation of (a) BTM, (b)Twitter-BTMalgorithm (Griffiths and Steyvers, 2004) is usedfor approximate inference.Compared with the strong assumption that ashort document only covers a single topic (Diao etal., 2012; Ding et al., 2013), BTM makes a looserassumption that two words will be assigned thesame topic label if they have co-occurred.
Thus ashort document could cover more than one topic,which is more close to the reality.
But this assump-tion causes another issue, those commonly usedwords and those topical words are treated equally.Obviously it is inappropriate to assign same topiclabel to those words.3 Twitter-BTMIn this Section, we introduce our Twitter-BTMmodel.
Figure 1(b) shows the graphical represen-tation of Twitter-BTM.
The generative process ofTwitter-BTM is as follows:1 Draw ?B?
Dir(?
)2 For each topic t=1,...,T(a) Draw ?t?
Dir(?
)3 For each user u=1,...,U(a) Draw ?u?
Dir(?
), piu?
Beta(?
)(b) For each biterm b = 1,...,Nu(i) Draw zu,b?Multi(?u)(ii) For each word n = 1,2(A) Draw yu,b,n?
Bern(piu)(B) if yu,b,n= 0 Draw wu,b,n?Multi(?B)if yu,b,n= 1 Draw wu,b,n?Multi(?zu,b)490In the above process, user u?s topic interest ?uis a multinomial distribution over K topics drawnfrom a Dirichlet prior Dir(?).
The backgroundtopic B is associated with a multinomial distribu-tion ?Bdrawn from a Dirichlet prior Dir(?).
Theassumption that each user has a different prefer-ence between topical words and background word-s is shown to be effective in (Sasaki et al., 2014).We adopt this assumption in Twitter-BTM.
Useru?s preference is represented as a Bernoulli distri-bution with parameter piudrawn from a beta priorBeta(?).
Nuis the number of biterms of user u,zu,bis the topic assignment latent variable of useru?s biterm b.
For user u and his/her biterm b, n=1or 2, we use a latent variable yu,b,nto indicate theword type of the wordwb,n.
When yu,b,n= 1,wb,nis generated from topic zu,b.
When yu,b,n= 0,wb,nis generated from the background topic B.We adopt collapsed Gibbs Sampling to estimatethe parameters.
Because of the limitations of s-pace, we leave out the details about the samplingalgorithm.
Since we can?t get a document?s distri-bution over topics from the parameters estimatedby Twitter-BTM directly, we utilize the followingformula (Yan et al., 2013) to infer the topic distri-bution of document d. Given a document d whoseauthor is user u:P (z = t|d) =Nb?iP (z = t|bi)P (bi|d) (1)Now the problem is converted to how to estimateP (bi|d) and P (z = t|bi).
P (bi|d) is estimated byempirical distribution in d:P (bi|d) =NbiNb(2)where Nbiis the number of biterm bioccurred ind, Nbis the total number of biterms in d. Wecan apply Bayes?
rule to compute P (z = t|bi) viafollowing expression:?ut[piu?Bwi,1+ (1?
piu)?twi,1] [piu?Bwi,2+ (1?
piu)?twi,2]?k?uk[piu?Bwi,1+ (1?
piu)?kwi,1] [piu?Bwi,2+ (1?
piu)?kwi,2](3)4 ExperimentsIn this Section, we describe our experiments car-ried on a Twitter dataset collected form 10th Jun,2009 to 31st Dec, 2009.
Stop words and wordsoccur less than 5 times are removed.
We also filtertweets which only have one or two words.
Allletters are converted into lower case.
The dataset isdivided into two parts.
The first part whose statis-tics is shown in Table 1 is used for training.
Thesecond part which consists of 22,496,107 tweetsis used as the external dataset in topic coherenceevaluation task in Section 4.1.We compare the performance of Twitter-BTMwith five baselines:?
LDA-U, user based aggregation is appliedbefore training LDA.?
Twitter-LDA (Zhao et al., 2011), whichmakes a strong assumption that a tweet onlycovers one topic.?
TwitterUB-LDA (Sasaki et al., 2014), an im-proved version of Twitter-LDA, which mod-els the user level preference between topicalwords and background words.?
BTM (Yan et al., 2013), the Biterm TopicModel.?
BTM-U, a simplified version of Twitter-BTMwithout background topic.For all the above models, we use symmetricDirichlet priors.
The hyperparameters are set asfollows: for all the models, we set ?
= 50/K,?
= 0.01; for Twitter-LDA, TwitterUB-LDA andTwitter-BTM, we set ?
= 0.5.
We run Gibbssampling for 400 iterations.DataSet Twitter#tweets 1,201,193#users 12,006#vocabulary 71,038#avgTweetLen 7.04Table 1: Summary of datasetPerplexity metric is not used in our experimentssince it is not a suitable evaluation metric for BTM(Cheng et al., 2014).
The first reason is thatBTM and LDA optimize different likelihood.
Thesecond reason is that topic models which have bet-ter perplexity may infer less semantically topics(Chang et al., 2009).4.1 Topic CoherenceWe use PMI-Score (Newman et al., 2010) to quan-titatively evaluate the quality of topic component.491K 50 100method Top5 Top10 Top20 Top5 Top10 Top20LDA-U 2.83?0.07 1.93?0.06 1.40?0.04 3.11?0.09 1.89?0.09 1.15?0.04Twitter-LDA 2.58?0.04 1.90?0.03 1.39?0.03 2.97?0.20 1.98?0.09 1.44?0.06TwitterUB-LDA 2.57?0.05 1.87?0.07 1.45?0.04 3.07?0.11 2.05?0.05 1.45?0.05BTM 2.88?0.14 2.01?0.09 1.44?0.08 3.25?0.14 2.13?0.06 1.49?0.06BTM-U 2.92?0.10 1.89?0.05 1.33?0.04 3.03?0.07 1.95?0.05 1.34?0.07Twitter-BTM 3.04?0.10 2.05?0.08 1.47?0.05 3.27?0.12 2.15?0.08 1.48?0.05Table 2: PMI-Score of different topic modelsEquation (4) defines PMI (Pointwise Mutual In-formation) for two words wiand wj:PMI(wi, wj) = logP (wi, wj) + P (wi)P (wj)(4) is an extremely small constant (Stevens et al.,2012), which is equal to 10?12in this paper.
Theword probabilities and the co-occurrence proba-bilities are computed on the large-scale externaldataset empirically.
Here we use the second partTwitter dataset as the external dataset.
Then for atopic t and its top T words ranked by topic-wordprobability ?tw, the PMI-Score of topic t is definedas follow:PMI ?
Score(t)=1T (T ?
1)?1?i<j?TPMI(wi, wj)(5)The model?s PMI-Score is defined as the meanof all the topics?
PMI-Score.
Table 2 shows theaverage results over 10 runs of different models.When K = 50, Twitter-BTM outperforms allother models significantly.
When K = 100, ThePMI-Score of BTM and Twitter-BTM are veryclose.
BTM-U is worse than BTM, the reason maybe that each user?s biterm sets provide extremelylimited words co-occurring information.Table 3 shows top 10 words of topic ?food?learned by BTM, BTM-U and Twitter-BTM whenK = 50.
We use italic fonts to indicate back-ground words labeled by human judgement.
Com-pared with BTM and BTM-U, Twitter-BTM canrank those background words at lower level.
Itdemonstrates that representative words learned byTwitter-BTM are more coherent and meaningful.4.2 Document RepresentationTopic models are powerful dimension reductionmethods for texts.
Given a tweet d, we can in-fer its probability distribution over K topics withBTM BTM-U Twitter-BTMfood food veganeat vegan foodchicken eat eatgood good chickenvegan chicken chocolatelol #vegan cheesecheese cream creamchocolate cheese #veganlove chocolate icedinner ice dinnerTable 3: Top 10 words of topic foodequation (1).
Thus d can be represented as a topicprobability vector:d = [P (z = 1|d), ..., P (z = K|d)] (6)We use document classification task (Cheng etal., 2014) and document clustering task (Duanet al., 2012) to measure the quality of the docu-ments?
topic proportions.
Tweets in Twitter haveno explicit label information.
But some tweetsare labeled by one or more hashtags (a type oflabel whose form is ?#keyword?)
manually by itsauthor to indicate the topic the tweets involve.
Wefollow previous works (Cheng et al., 2014; Wanget al., 2014) and use hashtags as the tweets?
labels.Table 4 lists 38 frequent (at least appears in 100tweets ) hashtags relating to certain topic or eventmanually selected in our dataset.We choose those tweets which contain only oneof these hashtags appear in Table 4 from our o-riginal data in the following experiments.
Whenwe infer a tweet?s topic distribution, the hashtag isignored.
Because it doesn?t make sense to use thelabel information to construct the feature vectordirectly.We classify these selected tweets by RandomForest classifier (Breiman, 2001) implemented in492aaliyah afghanistan beatcancer birdingblogtalkradio digguser dmv dontyouhate factgiladshalit gno gov green haiku healthcarehonduras india iranelection jazz jesus krp lgbtmindsetshift nfl nn oink rhoa slaughterhousesocialmedia tech travel trueblood vegan vegasvoss weeklyfitnesschallenge wordpress yyjTable 4: Hashtags selected for evaluation10 20 30 40 50 60 70 80 90 100 1 X P E H U  R I  7 R S L F V0.250.300.350.400.450.500.550.600.650.70AccuracyLDA-UTwitter-LDATwitterUB-LDABTMTwitter-BTMBTM-UFigure 2: Performance of classificationsklearn2python module with 10-fold cross valida-tion.
Using accuracy as the evaluation metric, wereport the classification performance of differenttopic models in Figure 2.
With the increase ofthe topic number K, all the models?
accuraciesare tending to increase.
BTM is worse than allother models, which confirms the effectiveness ofuser based aggregation.
Twitter-BTM and BTM-U always outperform LDA-U, Twitter-LDA andTwitterUB-LDA.
Twitter-BTM?s accuracy is a lit-tle higher than BTM-U, which demonstrates thatthe background topic is helpful to capture moreaccurate topic representation of documents.We adopt k-means algorithm implemented insklearn python module as our clustering method.The number of cluster is set to 38.
Consider-ing we have the knowledge of ground truth classassignments of each tweet, and Adjusted RandIndex (ARI) and Normalized Mutual Informationare used as cluster validation indices in our exper-iments.
As shown in Figure 3 and Figure 4, Thehigher ARI and NMI value indicate that Twitter-BTM outperform other models.
And BTM per-forms worse than all other models.5 ConclusionIn this paper, we investigate the problem of topicmodeling over short texts with user factor.
Us-2See http://scikit-learn.org/stable/10 20 30 40 50 60 70 80 90 100 1 X P E H U  R I  7 R S L F V0.100.150.200.250.300.350.400.450.50ARILDA-UTwitter-LDATwitterUB-LDABTMTwitter-BTMBTM-UFigure 3: Performance of clustering (ARI)10 20 30 40 50 60 70 80 90 100 1 X P E H U  R I  7 R S L F V0.300.350.400.450.500.550.600.650.70NMILDA-UTwitter-LDATwitterUB-LDABTMTwitter-BTMBTM-UFigure 4: Performance of clustering (NMI)er individualities are sacrificed to obtain the cor-pus level words co-occurrence patterns in BTM.However, unlike LDA, simple user based aggre-gation will reduce the topic coherence for BTM.To address this problem, we propose Twitter-BTMwhich loosens the inappropriate assumption thattwo co-occurring words must have same topic la-bel made in BTM by leveraging user based ag-gregation and incorporating a background topic inBTM.
The experimental results show that Twitter-BTM substantially outperforms BTM.In the future, we plan to study the influence ofother factors such as temporal information to BTMand its variants.AcknowledgmentsThis work is supported by 973 Program withGrant No.2014CB340405, NSFC with GrantNo.61272340.
Yan Zhang is supported by NSFCwith Grant No.61370054.
We thank the threeanonymous reviewers for their comments andconstructive criticism.493ReferencesDavid M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent dirichlet allocation.
the Journal ofmachine Learning research, 3:993?1022.Leo Breiman.
2001.
Random forests.
MachineLearning, 45(1):5?32.Jonathan Chang, Sean Gerrish, Chong Wang, Jordan LBoyd-Graber, and David M Blei.
2009.
Readingtea leaves: How humans interpret topic models.
InAdvances in neural information processing systems,pages 288?296.Xueqi Cheng, Xiaohui Yan, Yanyan Lan, and JiafengGuo.
2014.
Btm: Topic modeling over shorttexts.
IEEE TRANSACTIONS ON KNOWLEDGEAND DATA ENGINEERING.Qiming Diao, Jing Jiang, Feida Zhu, and Ee-PengLim.
2012.
Finding bursty topics from microblogs.In ACL (1), pages 536?544.
The Association forComputer Linguistics.Zhuoye Ding, Xipeng Qiu, Qi Zhang, and XuanjingHuang.
2013.
Learning topical translationmodel for microblog hashtag suggestion.
InIJCAI 2013, Proceedings of the 23rd InternationalJoint Conference on Artificial Intelligence, Beijing,China, August 3-9, 2013.Dongsheng Duan, Yuhua Li, Ruixuan Li, Rui Zhang,and Aiming Wen.
2012.
Ranktopic: Ranking basedtopic modeling.
In ICDM, pages 211?220.Fr?ederic Godin, Viktor Slavkovikj, Wesley De Neve,Benjamin Schrauwen, and Rik Van de Walle.2013.
Using topic models for twitter hashtagrecommendation.
In Proceedings of the 22ndinternational conference on World Wide Web com-panion, pages 593?596.
International World WideWeb Conferences Steering Committee.T.
L. Griffiths and M. Steyvers.
2004.
Findingscientific topics.
Proceedings of the NationalAcademy of Sciences, 101:5228?5235.Liangjie Hong and Brian D. Davison.
2010.
Empiricalstudy of topic modeling in twitter.
In Proceedingsof the First Workshop on Social Media Analytics,SOMA ?10, pages 80?88, New York, NY, USA.ACM.Zhuoye Ding Qi Zhang XuanJing Huang.
2012.Automatic hashtag recommendation for microblogsusing topic-specific translation model.
In 24th Inter-national Conference on Computational Linguistics,page 265.
Citeseer.Zongyang Ma, Aixin Sun, Quan Yuan, and GaoCong.
2014.
Tagging your tweets: A probabilisticmodeling of hashtag annotation in twitter.
InProceedings of the 23rd ACM International Confer-ence on Conference on Information and KnowledgeManagement, pages 999?1008.
ACM.David Newman, Jey Han Lau, Karl Grieser, andTimothy Baldwin.
2010.
Automatic evaluation oftopic coherence.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for ComputationalLinguistics, pages 100?108.
Association for Com-putational Linguistics.Kentaro Sasaki, Tomohiro Yoshikawa, and TakeshiFuruhashi.
2014.
Online topic model for twitterconsidering dynamics of user interests and topictrends.
In Proceedings of the 2014 Conference onEmpircal Methods in Natural Language Processing,pages 1977?1985.Jianfeng Si, Arjun Mukherjee, Bing Liu, Qing Li,Huayi Li, and Xiaotie Deng.
2013.
Exploiting topicbased twitter sentiment for stock prediction.
In ACL(2), pages 24?29.Keith Stevens, Philip Kegelmeyer, David Andrzejew-ski, and David Buttler.
2012.
Exploring topiccoherence over many models and many topics.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Processingand Computational Natural Language Learning,pages 952?961.
Association for ComputationalLinguistics.Yuan Wang, Jie Liu, Jishi Qu, Yalou Huang, JimengChen, and Xia Feng.
2014.
Hashtag graph basedtopic model for tweet mining.
In 2014 IEEEInternational Conference on Data Mining, ICDM2014, Shenzhen, China, December 14-17, 2014,pages 1025?1030.Jianshu Weng, Ee-Peng Lim, Jing Jiang, and Qi He.2010.
Twitterrank: finding topic-sensitive influen-tial twitterers.
In WSDM, pages 261?270.
ACM.Xiaohui Yan, Jiafeng Guo, Yanyan Lan, and XueqiCheng.
2013.
A biterm topic model for short texts.In Proceedings of the 22nd international conferenceon World Wide Web, pages 1445?1456.
InternationalWorld Wide Web Conferences Steering Committee.Xiaohui Yan, Jiafeng Guo, Yanyan Lan, Jun Xu, andXueqi Cheng.
2015.
A probabilistic model forbursty topic discovery in microblogs.Wayne Xin Zhao, Jing Jiang, Jianshu Weng, Jing He,Ee-Peng Lim, Hongfei Yan, and Xiaoming Li.
2011.Comparing twitter and traditional media using topicmodels.
In Advances in Information Retrieval,pages 338?349.
Springer.Xin Wayne Zhao, Yanwei Guo, Yulan He, HanJiang, Yuexin Wu, and Xiaoming Li.
2014.
Weknow what you want to buy: a demographic-based system for product recommendation onmicroblogs.
In Proceedings of the 20th ACMSIGKDD international conference on Knowledgediscovery and data mining, pages 1935?1944.
ACM.494
