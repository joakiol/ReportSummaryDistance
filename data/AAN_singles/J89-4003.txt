A FORMAL MODEL FOR CONTEXT-FREE LANGUAGESAUGMENTED WITH REDUPLICATIONWalter J. SavitchDepartment of Computer Science and EngineeringUniversity of California, San DiegoLa Jol la, CA 92093A model is presented to characterize the class of languages obtained by adding reduplication tocontext-free languages.
The model is a pushdown automaton augmented with the ability to checkreduplication by using the stack in a new way.
The class of languages generated is shown to lie strictlybetween the context-free languages and the indexed languages.
The model appears capable ofaccommodating the sort of reduplications that have been observed to occur in natural languages, but itexcludes many of the unnatural constructions that other formal models have permitted.1 INTRODUCTIONContext-free grammars are a recurrent theme in many,perhaps most, models of natural anguage syntax.
It isclose to impossible to find a textbook or journal thatdeals with natural language syntax but that does notinclude parse trees someplace in its pages.
The modelsused typically augment he context-free grammar withsome additional computational power so that the classof languages described is invariably larger, and oftenmuch larger, than the class of context-free languages.Despite the tendency to use more powerful models,examples of natural anguage constructions that requiremore than a context-free grammar for weak generativeadequacy are rare.
(See Pullum and Gazdar 1982, andGazdar and Pullum 1985, for surveys of how rareinherently noncontext-free constructions appear to be.
)Moreover, most of the examples of inherently noncon-text-free constructions in natural anguages depend on asingle phenomenon, namely the reduplication, or ap-proximate reduplication, of some string.
Reduplicationis provably beyond the reach of context-free grammars.The goal of this paper is to present a model that canaccommodate hese reduplication constructions with aminimal extension to the context-free grammar model.Reduplication in its cleanest, and most sterile, formis represented by the formal language {ww I w ~ E*},where E is some finite alphabet.
It is well known thatthis language is provably not context-free.
Yet there arenumerous constructs in natural anguage that mimic thisformal language.
Indeed, most of the known, convinc-ing arguments that some natural language cannot (oralmost cannot) be weakly generated by a context-freegrammar depend on a reduplication similar to the oneexhibited by this formal language.
Examples include therespect ive ly  construct in English (Bar-Hillel and Shamir1964), noun-stem reduplication and incorporation inMohawk (Postal 1964), noun reduplication i  Bambara(Culy 1985), cross-serial dependency of verbs and ob-jects :in certain subordinate clause constructions inDutch (Huybregts 1976; Bresnan et al 1982) and inSwiss-German (Shieber 1985), and various reduplica-tion constructs in English, including the X or no Xconstruction as in: "reduplication or no reduplication, Iwant a parse tree" (Manaster-Ramer 1983, 1986).
Themodel presented here can generate languages with anyof these constructions and can do so in a natural way.To have some concrete examples at hand, we willreview a representative sample of these constructions.The easiest example to describe is the noun redupli-cation found in Bambara.
As described by Culy (1985),it is an example of the simplest sort of reduplication iwhich a string literally occurs twice.
From the noun wBambara can form w-o-w with the meaning "whateverw."
It is also possible to combine nouns productively inother ways to obtain new, longer nouns.
Using theselonger nouns in the w-o-w construction produces redu-plicated strings of arbitrary length.The respect ive ly  construction i English is one of theoldest well-known examples of reduplication (Bar-HillelCopyright 1989 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material isgranted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires afee and/or specific permission.0362-613 X/89/010250-261 $ 03.00250 ComputationaH Linguistics, Volume 15, Number 4, December 1989Walter J. Savitch A Formal Model for Context-Free Languages Augmented with Reduplicationand Shamir 1964).
It provides an example of reduplica-tion other than exact identity.
A sample sentence is:John, Sally, Mary, and Frank are awidower, widow, widow, and widower, respectively.In these cases, it has been argued that the names mustagree with "widow" or "widower" in gender, andhence the string from {widow, widower}* must be anapproximate r duplication of the string of names.
If oneaccepts the data, then this is an example of reduplica-tion using a notion of equivalence other than exactidentity.
In this case the equivalence would be that thesecond string is a homomorphic mage of the first one.However, one must reject he data in this case.
One canconvincingly argue that the names need not agree withthe corresponding occurrence of "widow" or "widow-er," because gender is not syntactic in this case.
It maybe false, but it is not ungrammatical to say "John is awidow."
(Perhaps it is not even false, since no syntacticrule prevents parents from naming a daughter "John.
")However, such dependency is at least potentially pos-sible in some language with truly syntactic gendermarkings.
Kac et al (1987) discuss a version of thisconstruction using subject-verb number agreement thatyields a convincing argument hat English is not acontext-free language.One of the least controversial rguments claiming toprove that a particular natural language cannot beweakly generated by a context-free grammar is Shie-ber's (1985) argument about Swiss-German.
In thiscase, the reduplication occurs in certain subordinateclauses uch as the following:... mer em Hans es huus h/ilfed aastriiche... we Hans-DAT the house-ACC helped paint'....we helped Hans paint the house.
'where to obtain a complete sentence, the above shouldbe preceded by some string such as "Jan s/iit das" ('Jansays that').
In this case, a list of nouns precedes a list ofan equal number of verbs and each noun in the listserves as the object of the corresponding verb.
Thecross-serial dependency that pushes the language be-yond the reach of a context-free grammar is an agree-ment rule that says that each verb arbitrarily demandseither accusative ordative case for its object.
Thus if wesubstitute "de Hans" (Hans-ACC) for "em Hans"(Hans-DAT) or "em huus" (the house-DAT) for "eshuus" (the house-ACC), then the above is ungrammat-ical because "h/ilfed" demands that its object be in thedative case and "aastriiche" requires the accusativecase.
Since the lists of nouns and verbs may be ofunbounded length, this means that Swiss-German con-tains substrings of the formsN 1 N2"'Nn VI V2... Vnwhere n may be arbitrarily large and where each nounN i is in either the dative or accusative case dependingon an arbitrary requirement of the verb V i.Bresnan et al (1982) describe a similar constructionin Dutch in which the strong agreement rule is notpresent and so the language (at least this aspect of it)can be weakly generated by a context-free grammar,even though it cannot be strongly generated by acontext-free grammar.
The context-free grammar togenerate the strings would pair nouns and verbs in amirror image manner, thereby ensuring that there areequal numbers of each.
Since Dutch does not have thestrong agreement rule that Swiss-German does, thisalways produces agrammatical c ause, even though thepairing of nouns and verbs is contrary to intuition.However, in cases such as this, it would be desirable tohave a model that recognizes reduplication as redupli-cation rather than one that must resort to some sort oftrick to generate weakly the reduplicated strings in ahighly unnatural manner.
This is true even if one isseeking only weak generative capacity because, as theDutch/Swiss-German pair indicates, if a minor andplausible addition to a construct in one natural languagewould make it demonstrably noncontext-free, then wecan suspect hat some other language may exhibit thisor a similar inherently noncontext-free property, evenwhen considered purely as a string set.Some of these arguments are widely accepted.
Oth-ers are often disputed.
We will not pass judgment hereexcept o note that, whether or not the details of thedata are sharp enough to support a rigorous proof ofnoncontext-freeness, it i  nonetheless clearly true that,in all these cases, something like reduplication is occur-ring.
A model that could economically capture theseconstructions a well as any reasonable variant on theseexamples would go a long way toward the goal ofprecisely describing the class of string sets that corre-spond to actual and potential human languages.We do not contend that the model to be presentedhere will weakly describe all natural anguages withouteven the smallest exception.
Any such claim for anymodel, short of ridiculously powerful models, isdoomed to failure.
Human beings taken in their entiretyare general-purpose computers capable of performingany task that a Turing machine or other general-purposecomputer model can perform, and so humans canpotentially recognize any language describable by anyalgorithmic process whatsoever (although sometimestoo slowly to be of any practical concern).
The humanlanguage facility appears to be restricted to a much lesspowerful computational mechanism.
However, sincethe additional power is there for purposes other thanlanguage processing, some of this power inevitably willfind its way into language processing in some smallmeasure.
Indeed, we discuss one Dutch constructionthat our model cannot handle.
We claim that our modelcaptures most of the known constructions that makenatural language provably not context-free as stringsets, and that it does so with a small addition to thecontext-free grammar model.
No more grandiose claimsare made.It is easy to add power to a model, and there arenumerous models that can weakly generate languagesrepresenting all of these noncontext-free constructions.Computational Linguistics, Volume 15, Number 4, December 1989 251Walter J. Savitch A Formal Modeli for Context-Free Languages Augmented with ReduplicationHowever, they all appear to be much too powerful forthe simple problems that extend natural anguage be-yond the capacity of context-free grammar.
One of theless powerful of the well-known models is indexedgrammar, as introduced by Aho (1968) and more re-cently summarized in the context of natural language byGazdar (1985).
However, even the indexed languagesappear to be much more powerful than is needed fornatural language syntax.
We present a model that isweaker than the indexed grammar model, simpler thanthe indexed grammar model, and yet capable of han-dling all context-free constructs plus reduplication.A number of other models extend the context-freegrammar model in a limited way.
Four models that areknown to be weakly equivalent and to be strictly weakerthan indexed grammars are: the Tree Adjoining Gram-mars (TAGs) of Joshi (1985, 1987), the Head Grammarsof Pollard (1984), the Linear Indexed Grammars ofGazdar (1985), and the Combinatory Categorial Gram-mars of Steedman (1987, 1988).
For a discussion of thisequivalence see Joshi et al (1989).
The oldest of thesefour models is the TAG grammar of Joshi, and we shallrefer to the class of languages generated by any of theseequivalent grammar formalisms as TAG languages.However, the reader should keep in mind that this classof languages could be represented by any of the fourequivalent grammar formalisms.
As we will see later inthis paper, there are TAG languages that cannot beweakly generated by our model.
Our model seems toexclude more unnatural strings sets than these modelsdo.
Of course, our model may also miss some naturalstring sets that are TAG languages.
Recent work ofJoshi (1989) appears to support our conjecture that theclass of language described by our model is a subset,and hence a strict subset, of the TAG languages.However, all the details of the proof have not yet beenworked out, and so any more detailed comparisons toTAG languages will be left for another paper.This paper assumes ome familarity with the notationand results of formal anguage theory.
Any reader whohas worked with context-free grammars, who knowswhat a pushdown automaton (PDA) is, and who knowswhat it means to say that PDAs accept exactly thecontext-free languages should have sufficient back-ground to read this paper.
Any needed background canbe found in almost any text on formal language theory,such as Harrison (1978) or Hopcroft and Ullman (1979).2 THE RPDA MODELThe model we propose here is an automata-based modelsimilar to the pushdown automaton that characterizesthe context-free languages.
A formal definition willfollow shortly, but the informal description given nowshould be understandable to anybody who has workedin this area.
The model is called a Reduplication PDA, ormore simply an RPDA.
It consists of an ordinary PDAaugmented with a special stack symbol, which is de-noted ~, and a special type of instruction to check forreduplication.
The symbol $ is inserted in the stack justlike any other stack symbol, and the stack grows abovethis symbol just as in an ordinary PDA.
To check for anoccurrence of a simple reduplication ww,  the RPDApushe,; $ onto the stack and then pushes the first w ontothe stack symbol by symbol.
At that point the stackcontains + with w on top of it, but while the stacksymbols are ordered so that it would be easy to comparethe w in the stack with w n (i.e., w reversed), they are inthe wrong order to compare them with w. To overcomethis; problem an RPDA is allowed, in one step, tocorapare the entire string above the $ to an initialsegment of the remaining input and to do so in the orderstarting at the special symbol ~ rather than at the top ofthe stack.
(The comparison consumes both the stackcontents above the marker ~ and the input with which itis compared.)
One way to view this is to say that theRPDA can decide to treat the stack above the symbollike a queue, but once it decides to do so, all that itcan do is empty the queue.
The RPDA cannot add to thequeue once it starts to empty it.
If the RPDA decides tocheck xy  to see if x = y, and x does not in fact equal y(or any initial segment of y), then the computationblock,;.
While placing symbols on top of the symbol $,the stack may grow or shrink just like the stack on anordinary PDA.
The model allows more than one marker$ to be placed in the stack, and hence, it can check forredup!lications ested within reduplications.Because an RPDA is free to push something on thestack other than w when processing some input wx,  themodel can check not only whether w = x, but also cancheck the more general question of whether somespecific finite-state transduction maps w onto x. AfinJite-state transduction is any relation that can becomputed using only a finite-state machine.
The finite-state transductions include all of the simple word-to-word equivalences used in known reduplicationconstructions.
For example, for the Swiss-German sub-ordinate clauses described by Shieber, w is a string ofnouns, marked for either dative or accusative case, andx is a string of verbs that each select one and only oneof the: cases for their corresponding, cross-serially lo-cated object noun.
The finite-state transduction wouldmap each noun in the accusative case onto a verbnondeterministically chosen from the finite set of verbsthat take the accusative case, and would do a similarthing with nouns in the dative case and their corre-sponding class of verbs.
Without this, or some similargenerality, the only reduplication allowed would beexact symbols by symbol identity.The formal details of the definitions are now routine,but to avoid any misunderstanding, wepresent them insome detail.1.
A Reduplication PDA (abbreviated RPDA) consistsof the following items:(i) A finite set of states S, an element qo in S to serve252 Computational Linguistics, Volume 15, Number 4, December 1989Walter J. Savitch A Formal Model for Context-Free Languages Augmented with Reduplicationas the start state, and a finite subset F of S to serve asthe accepting states;(ii) A finite input alphabet E;(iii) A finite pushdown store alphabet Fsuch that E CF, a distinguished symbol Z o in F to serve as the startpushdown symbol, and a distinguished stack marker ~,which is an element of F -E ;(iv) A transition function 8 that maps triples (q, a, Z)consisting of a state q, an input symbol a, and apushdown store symbol Z, onto a finite set of instruc-tions, where each instruction is in one of the followingtwo forms:(1) An ordinary PDA move: (p, push  a, A), where p is astate, a is a string of pushdown symbols, and A isone of the two instructions + 1 and 0 standing for"advance the input head" and "do not advance theinput head,"  respectively.
(The word "push"serves no function in the mathematics, but it doeshelp make the notation more readable.
)(2) A check-copy move: These instructions consist onlyof a state p. (As explained in the next two defini-tions, this is the state of the finite control after asuccessful move.
A successful move matches thatportion of the stack contents between the highestmarker $ and the top of the stack against an initialsegment of the remaining input and does so in theright order for checking reduplication.)2.
An instantaneous description (ID) of an RPDA M is atriple (q, w, 3"), where q is a state, w is the portion ofinput left to be processed, and 3' is the string of symbolson the pushdown store.
(The top symbol is at the leftend of 3", which is the same convention as that normallyused for ordinary PDA's.)3.
The next ID relation F is defined as follows:(t7, aw, Za)  F (q, w, floO, provided (q, push /3 ,  + l)?
:ffp, a, Z);(p, aw,  Za)  F (q, aw,  /3a), provided (q, push /3 ,  O)8(p, a, Z)  ;(p, axw,  Z3" ~ a) F (q, w,  a), provided q E 8 (p, a, Z)and ax = (Z3,) R, where (Z3') R denotes Z3" writtenbackwards (so the a matches the symbol just abovethe stack marker $.
Note that Z3' cannot contain thesymbol $,  because $ is not in the input alphabet).As usual, F* denotes the reflexive-transitive closure ofF.
Notice that the relation F is not a function.
A given IDmay have more than one next ID, and so these machinesare nondeterministic.4.
An RPDA is said to be deterministic provided that(p, a, Z) contains at most one element for each triple(p, a, Z).5.
The language accepted by the RPDA M by finalstate is defined and denoted as follows: L(M) = { w I (qo,w, Z) F* (/9, A, 3") for some p E F, 3" E F*}, where q0 isthe start state and F is the set of accepting states.
(A isused to denote the empty string.)
If  a language isaccepted by some RPDA by final state it is called anRPDA language.
If a language is accepted by somedeterministic RPDA by final state, then it is called adeterministic RPDA language.6.
The language accepted by the RPDA M by emptystore is defined and denoted as follows: N(M) = { w I (qo,w, Z ) F* (p, A, A) for some p ~ S}.As in the case of ordinary PDAs, it turns out that forRPDAs acceptance by empty store is equivalent oacceptance by final state.
The proof is essentially thesame as it is for PDAs and so we will not repeat it here.The formal statement of the result is our first theorem.Theorem 1.
A language L is accepted by some RPDAby final state if and only if it is accepted by some(typically different) RPDA by empty store.As with ordinary PDAs, and for the same reasons,Theorem 1 does not hold for deterministic RPDAs.3 EXAMPLES AND COMPARISON TO OTHER CLASSESWe next explain how RPDAs can be constructed toaccept each of the following sample languages.Examples of RPDA languages.L o={wwlwE{a,b}*}L 1 = {wcwl  w E {a, b} *}L 2 = {wh(w)l w E {a, b} *}where h is the homomorphism h(a) = c and h(b) =dde.L 3 = {wxw I w ~ {a, b} * and x E {c, d} *}L4 = {al Wl Wl a2 w2 w2""an w n w n a n a n an_ I .-.a I I a le{a, b}, w ig  {c, d} *}L5 = {XlCX2 c ...cx n ca n a , _ j  ...a I I a i ~ {a, b} , x i E {a,b}*, x i is of the form ww if and only if ai = b}L 6 = {x!
cx  2 c ...cx n ca I a 2 ...an I ai ~ {a, b}, x i E {a,b}*, xi is of the form ww if and only if a i = b}L 0 is the simplest possible reduplication language.
Toaccept this language, all that an RPDA need do is toinsert the marker $ into the stack, copy symbols intothe stack, guess when it has reached the midpoint, andthen perform a check-copy move.
If the center of thestring is marked with a punctuation symbol, then theRPDA can be deterministic, so L~ is a deterministicRPDA language.The language L2 illustrates the fact that reduplicationneed not be symbol-by-symbol identity.
The RPDA toaccept L 2 is similar to the one .that accepts Lo, exceptthat on reading an a it pushes a c into the stack insteadof an a, and on reading a b it pushes edd on the stackinstead of b.L 3 illustrates the fact that reduplication may bechecked despite the intervention of an arbitrarily longstring.
The construction of the RPDA is easy.The language L 4 illustrates the facts that reduplica-tion can be checked any number of times and that thesechecks may be embedded in a context free-like con-struction.
To accept L 4 an RPDA would push a~ andthen $ onto the stack and proceed to check for areduplication w~ w~ as described for L o.
If such a w~ w~is found, that will leave just a~ on the stack.
The RPDAnext pushes $ a 2 on the stack (the $ is on top of the a2)Computational Linguistics, Volume 15, Number 4, December 1989 253Walter J. Savitch A Formal Model for Context-Free Languages Augmented with Reduplicationand checks for w 2 w 2.
After processing an initial inputstring of the forma 1 w t w I a2 w2 w2 ""an Wn Wnthe stack will contain a~ an_ I ...at with a,, on top of thestack.
It can then easily che~k for the occurrence of amatching ending a~ an_ l ...al.
(It is also easy to checkfor an ending in the reduplicating order al a2 ""an usingthe techniques discussed below for L6.
)L 5 and L 6 illustrate the fact that reduplication can beused as a distinguishable f ature to carry some syntacticor semantic information.
For example, the reduplicatedstrings might be nouns and the reduplication might beused to indicate a plural.
The string of ais might beagreeing adjectives or verbs or whatever.
L 5 using themirror image construction is not meant to be typical ofnatural anguage but merely to illustrate that the redu-plication might be embedded in some sort of phrasestructure.
L 6 shows that the RPDA model can obtain thesame language with cross-serial dependency instead ofmirror imaging.To accept L 6 the RPDA needs to have two markersymbols $ in the stack at one time.
To accept L 6 anRPDA would push the marker ~ on the stack.
This firstmarker will eventually produce the stack contents(1) a~ a n - i  ""al ~ (the top is on the left)which it then compares to the ending string a~ a 2 ...a~.To construct his string in the stack, it guesses the a~and uses a second marker to check its guesses.
Forexample, if the RPDA guesses that a~ = b then it pushesa~ = b onto the stack and proceeds to check that Xl is areduplication string.
To do this it pushes another markeronto the stack and checks x I in the way described forL o and other languages.
If x~ does not check out, thenthe computation aborts.
If x t does check out, the stackcontains a 1 ~, (the top is on the left) and the RPDA thenguesses a2.
Say it guesses that a 2 ----- a and hence mustcheck that a 2 is not of the form ww.
The RPDA thenpushes a 2 onto the stack and performs the check.
Onestraightforward way to perform the check is to push amarker ~ on the stack and then read the first half of x2guessing at where it differs from the second half.
TheRPDA pushes its guess of the second half on the stack.If the RPDA correctly guesses the second half and if itensures that it guesses at least one difference from thefirst half, then x2 checks out.
If x2 checks out, then thestack will contain a 2 a l $ after all this.
Proceeding inthis way, the RPDA obtains the stack contents hown in(1) and then performs a final check-copy move to see ifit matches the rest of the input string.By examining these examples it is easy to see how anRPDA could deal with the reduplication constructionsfrom natural anguage that were mentioned in the intro-duction.
For example, in the Swiss-German subordinateclause construction, an RPDA would first push thestack marker ~ onto the stack, then it would read thelist of nouns, then for each noun it would nondetermin-istically choose a verb that requires the case of thatnoun.
It would then push the chosen verb onto thestack, and when it reaches the list of verbs it wouldperform a check-copy move.
Hence RPDAs seem ca-pable of weakly generating languages that exhibit theproperties that keep many natural anguages from beingcontext-free.
As the next result indicates, their power isstrictly between the context-free grammars and theindexed grammars.
Most of the theorem is easy toprove, given known results.
However,  a proof thatthere is an indexed language that is not an RPDAlanguage will have to wait until later in this paper whenwe will prove that the indexed language {anbnc n I n >- 0 }is not an RPDA language.Theorem 2.
Context-Free Languages C RPDA Lan-guages C Indexed Languages (and the inclusions areproper)Partial proof.
The first inclusion follows from thedefinitions.
To see that the inclusion is proper ecall that{ ww I w E {a, b} *}, which is well known to not becontext-free, is an RPDA language.
The second inclu-sion follows from the fact that an RPDA can be simu-lated by a one-way stack automaton, and all languagesaccepted by one-way stack automata re indexed lan-guages, as shown in Aho (1969).
The proof that there isan indexed language that is not an RPDA language willbe proven in a later section of this paper.V14 VARIATIONS ON THE RPDA MODELThere are a number of variations on the RPDA modelthat one might try.
One tempting variant is to replacethe check-copy move with a stack-flipping move.
Thisvariant would allow the entire stack contents above themarker ~ to be flipped so that, in one move, thepushdown-store contents a ~ T would change to c~ $ T.(The " top"  is always the left end.)
This would allow themachine to check for reduplication.
However,  it alsoallows the machine to check for everything else.
Thisflipping stack variant is equivalent to a Turing machinebecause it can simulate a Turing machine tape bycontinuaUy flipping the stack and using its finite controlto " rotate"  to any desired stack position.
For example,af'~ ~, 'y can be transformed into f la $ T by moving onesymbol at a time from the top of the stack to just abovethe n~tarker $.
The top symbol is moved by remember-ing the symbol in the finite-control, flipping the stack,placing the remembered symbol on the stack, andflipping again.One way to avoid the "Turing tar pit" in this flippingstack variant would be to deprive the machine of itsstack marker $ after a flip.
This would appear to limitthe number of flips and so prevent he Turing machinesimulation outlined.
However,  a nondeterministic ma-chine; could simply place a large supply of markers inthe stack so that when one was taken away anotherwould be at hand.
To foil this trick, one might limit thatmachine to one stack marker, but this would restrict hemachine so that it cannot naturally handle reduplica-tions nested inside of reduplications.
In Section 8,254 Computational Linguistics, Volume 15, Number 4, December 1989Walter J. Savitch A Formal Model for Context-Free Languages Augmented with ReduplicationRPDAs with only a single marker (and possessing oneother restriction at the same time) are studied.
Thatsection concludes with a discussion of why some natu-ral language constructs appear to require multiple mark-ers.When using a copy-check move, an RPDA can readan arbitrarily long piece of input in one move.
Thisdefinition was made for mathematical convenience.
Arealistic model would have to read input one symbol perunit time.
However, the formal model does not seri-ously misrepresent realistic run times.
If the model werechanged to read the input one symbols at a time whileemptying the stack contents above the marker, then therun time would at most double.5 CLOSURE PROPERTIESThe next two theorems illustrate the fact that RPDAlanguages behave very much like context-free lan-guages.
The proofs are straightforward generalizationsof well-known proofs of the same results for context-free languages.
Using the PDA characterization f con-text-free languages and the proofs in that framework,one need do little more than replace the term "PDA" by"RPDA" to obtain the corresponding results for RPDAlanguages.Theorem 3.
The class of RPDA languages i closedunder the following operations: intersection with afinite-state language, union, star closer, and finite-statetransduction (including the special cases of homomor-phism and inverse homomorphism).Theorem 4.
The class of deterministic RPDA lan-guages is closed under the operations of intersectionwith a finite-state language and complement.One detail of the proof of Theorem 3does merit somemention.
It may not, at first glance, seem obvious thatthe class of RPDA languages i closed under intersec-tion with a regular set, since the proof that is usuallyused for ordinary PDAs does not carry over withoutchange.
In the ordinary PDA case, all that is needed isto have a finite-state machine compute in parallel withthe PDA.
In the case of an RPDA this is a bit morecomplicated, since the RPDA does not read its inputsymbol by symbol.
In a check-copy move, an RPDAcan read an arbitrarily long string in one move.
How-ever, the finite-state control can easily keep a tableshowing the state transitions produced by the entirestring above the marker $.
When a second ~ is insertedinto the stack, the old transition table is stored on thestack and a new transition table is started.
The otherdetails of the proof are standard.Theorem 3 implies that the class of RPDA languagesis a full AFL (Abstract Family of Languages), which insome circles invests the class with a certain respectabil-ity.
This is because such closure properties determinemuch of the character of well-known language classes,such as context-free languages and finite-state lan-guages.
(A Full AFL is any class of languages thatcontains at least one nonempty language and that isclosed under union, A-free concatenation f two lan-guages, homomorphism, inverse homomorphism, andintersection with any finite-state language.
See Salomaa1973, for more details.
)The notion of a finite-state transduction is importantwhen analyzing pushdown machines.
If a finite-statecontrol reads a string of input while pushing some stringonto the stack (without any popping), then the string inthe stack is a finite-state ransduction fthe input string.Unfortunately, the concept of a finite-state transductionis fading out of the popular textbooks.
We will thereforegive a brief informal definition of the concept.Definition.
A finite-state transducer is a nondetermin-istic finite-state machine with output.
That is, it is afinite-state machine that reads its input in a singleleft-to-right pass.
In one move it does all of the follow-ing: either read a symbol or move without consumingany input (called moving on the empty input) and then,on the basis of this symbol or the empty input, as wellas the state of the finite-state machine, it changes tateand outputs astring of symbols.
(If, on first reading, youignore moving on the empty string, the definition is veryeasy to understand.
Moving on the empty string simplyallows the transducer toproduce output without readingany input.)
There is a designated start state and a set ofdesignated accepting states.In a computation of a finite-state transducer there isan output string consisting of the concatenation f theindividual strings output, but not all output strings areconsidered valid.
The computation begins in the startstate and is considered valid if and only if the compu-tation ends in one of a designated set of acceptingstates.
A string y is said to be a finite-state transductionof the string x via the finite-state transducer T providedthat there is a valid computation of T with input x andoutput y.To motivate the following definition, consider chang-ing a language so that plurals are marked by reduplica-tion.
For example, in English "papers" would changeto "paperpaper."
A sentence such as "Writers needpens to survive" would change to "Writerwriter needpenpen to survive."
This change of English can beobtained by first replacing all plural nouns with a specialsymbol (a in the definition) and then performing areduplication substitution as described in the definition.If the change were other than an exact copy, it wouldstill satisfy the definition provided that a finite-statemachine could compute the approximate copy.
Thisoperation allows us to take a language and introducereduplication i place of any suitably easily recognizedclass of words and so obtain a language that usesreduplication tomark that class.
The following theoremsays that RPDA languages are closed under these sortsof operations.Definition.
Let L be a language, a a symbol, and T afinite-state transduction.
Define the language L' toComputational Linguistics, Volume 15, Number 4, December 1989 255Walter J. Savitch A Formal ldodd for Context-Free Languages Augmented with Reduplicationconsist of all strings w that can be written in the formXo Yo xl Yl ""Xn -1 Yn - I  Xn where(i) each xi contains no a, s(ii) Xo axl a ""Xn - I  ax ,  E L ,  and(iii) each Yi is of the form vv' where v' is a finite-statetransduction of v via T.A language L' ,  obtained in this way, is called a redupli-cation substitution of the language L via T by substitutingreduplication strings for a.
More simply, L' is called areduplication substitution of L provided there is somesymbol a and some such finite-state transduction T suchthat L'  can be obtained from L in this way.Theorem 5.
If L' is a reduplication substitution of acontext-free language, then L' is an RPDA language.Among other things, Theorem 5 says that if you addreduplication to a context-free language in a very simpleway, then you always obtain an RPDA language.
InSection 8, we will prove a result that is stronger thanTheorem 5 and so we will not present a proof here.6 NoNRPDA LANGUAGESTo prove that certain languages cannot be accepted byany RPDA, we will need a technical lemma.
Despite themessy notation, it is very intuitive and fairly straight-forward to prove.
It says that if the stack marker ~ isused to check arbitrarily long reduplications, then thesereduplications can be pumped up (and down).
Forexample, suppose an RPDA accepts a string of the formusst  and does so by pushing $,  then s onto the stack,and then matching the second s by a check-copy move.It must then be true that, if s is long enough, then s canbe written in the form s I s 2 s 3 and for all i > 0, the RPDAcan do a similar pushing and checking of sls2gs3 toaccept USIS2 i S 3 S 1 S2 i s3t.Pumping Lemma 1.
For every RPDA M, there is aconstant k such that the following holds.
If length(s) >k and(Pl, rst, ~ \[3) F* (P2, st, s n $ fl ) F (P3, t, ~),where the indicated string $/3 is never disturbed, thenr and s may be decomposed into r = r~ rE r3 and s =s~ s2 s3, such that s2 is nonempty and for all i - O, (pl,r I rE i r 3 s I Sz i S 3 t, $ /3) F* (P2, S1 Sz i S3 t, (S I $2 i S3) R ~?
/3)I- (P3, t, /3).Proof.
Without loss of generality, we will assume thatM pushes at most one symbol onto the stack duringeach move.
Let k be the product of the number of statesin M and the number of stack symbols of M. Considerthe subcomputation(191, rst, $/3) F* (P2, st, s R ~ /3)Let s = a~a 2 ... a m where the a i are single symbols andm > k. Let q~, q2 .
.
.
.
.
qm be the state of M after it placesthis occurrence of ai onto the stack so that, after thispoint, ag is never removed from the stack until after thissubcomputation.
Since m > k, there must be i < j suchthat a i = aj and qg = qj .
Set$2 : a i  + 1 a i  + 2 .
.
.
a jand then define s 1 and s 3 by the equation s = sl s,2 s3.Define r z to be the portion of input consumed whilepushing s2 onto the stack, and then define r~ and r 3 bythe equation r = r 1 r z r 3.
It is then straightforward toshow that the conclusion of the lemma holds.\[\]Our second pumping lemma for RPDAs draws thesame conclusion as a weak form of the pumping lemmafor context-free languages.
Since the pumping lemmafor context-free languages will be used in the proof ofthe second pumping lemma for RPDAs, we reproducethe context-free version for reference.Weak Pumping Lemma for CFLs.
If L is a context-free language, then there is a constant k, depending onL, :such that the following holds: If z E L and length (z)> k, then z can be written in the form z = uvwxy whereeither v or x is nonempty and uv g wx i y E L for all i -> 0.The following version of the pumping lemma forRPDAs makes the ident ical  conclusion as the abovepumping lemma for context-free languages.\]Pumping Lemma 2.
If L is an RPDA language, thenthere is a constant k, depending on L, such that thefollowing holds: If z E L and length (z) > k, then z canbe written in the form z = uvwxy,  where either v or x isnonempty and lgV i WX i y E L for all i -> 0.Proof.
Let M be an RPDA accepting L and let k be asin the Pumping Lemma 1.
We decompose L into twolanguages o that L = L 1 U L 2.
Define L 1 to be the setof all strings z in L such that the Pumping Lemma 1applies to at least one accepting computation on z. Inother words, z is in LI if and only if there is acomputation of M of the form(qo', Z, Zo) F* (Pl, rst, $ fl) F* (P2, st, s n $ \[3) F(P3., t, /3) F* (pf, A, T)where qo is the start state, pf is an accepting state, andlength(s) > k. By Pumping Lemma 1, it follows that theconclusion of Pumping Lemma 2 applies to all strings inL 1.
(In this case we can even conclude that x-is alwaysnonempty.
However, we will not be able to make sucha conclusion for strings in L2.
)L 2 is defined as the set of all strings accepted by aparticular ordinary PDA M 2 that simulates many of thecomputations of the RPDA M. Define M2 to mimic thecomputation of M but to buffer the top k + 1 symbols ofthe stack in its finite-state control, and make the follow-ing modifications to ensure that it is an ordinary PDA: ifM2 has to mimic a check-copy move that matches k orfewer symbols above the marker $,  it does so using thestack buffer in its finite-state control.
If M2 ever needsto mimic a check-copy move that matches more than kstack symbols above the $,  it aborts the computation ia nonaccepting state.
M 2 can tell if it needs to abort acomputation by checking the finite stack buffer in itsfinite-state control.
If the buffer contains k + 1 symbolsbut no marker $,  and if M would do a check-copymove, then ME aborts its computation.By definition, L = L~ U L 2 .
(The sets L~ and L 2 need256 Computational Linguistics, Volume 15, Number 4, December 1989Waiter J. Savitch A Formal Model for Context-Free Languages Augmented with Reduplicationnot be disjoint, since M may be nondeterministic, andhence, a given string may have two different acceptingcomputations.
However, this does not affect the argu-ment.)
Because it is accepted by an ordinary PDA, L 2 isa context-free language, and the Pumping Lemma forcontext-free languages holds for it and some different k.Hence, by redefining k to be the maximum of the ks forLI and L2, we can conclude that the Pumping Lemma 2holds for L = L~ U L2 and this redefined k.\[~The next theorem and its proof using the pumpinglemma illustrates the fact that RPDAs, like context-freegrammars, can, in some sense, check only "two thingsat a time.
"Theorem 6.
L = {a nb ncn ln_>0} isnotanRPDAlanguage.Proof.
Suppose L is an RPDA language.
We willderive a contradiction.
By Pumping Lemma 2, there is avalue of n and strings u, v, w, x, and y such that a n b n c n= uvwxy with either v or x nonempty and such that uv iwx i y E L for all i > 0.
A straightforward analysis of thepossible cases leads to the conclusion that uv 2 wx 2 y isnot in L, which is the desired contradiction.if\]Since it is known that the language L in Theorem 6 isa TAG language, and since the TAG languages areincluded in the indexed languages, we obtain the follow-ing corollaries.
The second corollary is the promisedcompletion of the proof of Theorem 2.Corollary.
There is a TAG language that is not anRPDA language.Corollary.
There is an indexed language that is not anRPDA language.There are many versions of the pumping lemma forcontext-free languages.
(See Ogden 1968; Harrison1978; Hopcroft and Ullman 1979.)
Most versions makethe additional conclusion that length(vwx)  <- k. Oftenone can prove that a language is not context-freewithout using this additional conclusion about thelength of vwx.
In other words, we can often prove thata language is not context-free by using only the weakform of the pumping lemma given above.
One suchlanguage is the one given in Theorem 6.
If you reviewthe proof of Theorem 6, then you will see that all weneeded was the Pumping Lemma 2.
Moreover, thatpumping lemma has the identical conclusion as that ofthe Weak Pumping Lemma for context-free languages.This leads us to the following informal metatheorem:Metatheorem.
If L can be proven to not be context-free via the Weak Pumping Lemma for CFLs, then L isnot an RPDA language.This is not an official theorem since the phrase "viathe Weak Pumping Lemma" is not mathematicallyprecise.
However, the metatheorem is quite clear andquite clearly valid in an informal sense.
It can be madeprecise, but that excursion into formal logic is beyondthe scope of this paper.To see the limits of this metatheorem, note that thelanguage { ww I w ~ {a, b} *} is an RPDA language, andso to prove that it is not a context-free language, weshould need more than the Weak Pumping Lemma.Indeed, one cannot get a contradiction by assumingonly that the Weak Pumping Lemma applies to thislanguage.
A proof that this language is not context-freemust use some additional fact about context-free lan-guages, such as the fact that we can assume thatlength(vwx)  <_ k, where vwx is as described in thepumping lemma.The metatheorem is another indication that theRPDA languages are only a small extension of thecontext-free languages.
If it is easy to prove that alanguage is not context-free (i.e., if the language is"very noncontext-free"), then the language is not anRPDA language ither.7 A CONSTRUCTION MISSED BY THE MODELAs we have already noted, both Dutch and Swiss-German contain constructions consisting of a string ofnouns followed by an equal (or approximately equal)number of verbs.
Hence these languages contain sub-strings of the formN l N 2 .
.
.N n V ,  V 2 ...V,,In the case of Swiss-German, additional agreementrules suffice to show that these constructions are be-yond the reach of context-free grammar, although notbeyond the reach of RPDAs.
(See the discussion ofShieber 1985 earlier in this paper.)
Because Dutch lacksthe strong agreement rule present in Swiss German, thesame proof does not apply to Dutch.
Manaster-Ramer(1987) describes an extension of this construction withinDutch and argues that this extension takes Dutch be-yond the weak generative capacity of context-freegrammar.
Although we are admittedly oversimplifyingthe data, the heart of his formal argument is that twosuch strings of verbs may be conjoined.
Hence, Dutchcontains ubstrings that approximate he formNl  N2 ...Nn VI V2 ...Vn en ( 'and' )  V i V2 ""VoThe Dutch data support only the slightly weaker claimthat the number of nouns is less than or equal to thenumber of verbs.
Hence, Manaster-Ramer's argumentis, in essence, that Dutch contains a construction simi-lar to the following formal anguage:g = {a i l~c J l i~ j}He uses this observation to argue, via the PumpingLemma for Context-Free Languages, that Dutch is nota context-free language.
A careful reading of his argu-ment reveals that, with minor alterations, the argumentcan be made to work using only the Weak PumpingLemma.
Hence by the metatheorem presented here (ora careful review of his proof), it follows that his argu-ment generalizes to show that the language L is not anRPDA language.
Hence, if one accepts his data, thesame argument shows that Dutch is not an RPDAlanguage.Computational Linguistics, Volume 15, Number 4, December 1989 257Walter J. Savitch A Formal Mode~ for Context-Free Languages Augmented with ReduplicationThe RPDA model could be extended to take accountof this and similar natural language constructionsmissed by the model.
One possibility is simply to allowthe RPDA to check an arbitrary number of input stringsto see if they are finite-state transductions of the stringabove the marker $.
There are a number of ways to dothis.
However, it seems preferable to keep the modelclean until we have a clearer idea of what constructions,other than reduplication, place natural language beyondthe reach of context-free grammar.
The RPDA model,as it stands, captures the notion of context-free gram-mar plus reduplication, and that constitutes one goodapproximation to natural anguage string sets.8 REDUPLICATION GRAMMARSAlthough we do not have a grammar characterization fRPDA languages, we do have a grammar class that is anextension of context-free grammar and that is adequatefor a large subclass of the RPDA languages.
The modelconsists of a context-free grammar, with the additionthat the right-hand side of rewrite rules may contain alocation for an unboundedly ong reduplication string ofterminal symbols (as well as the usual terminal andnonterminal symbols).Definition.
A reduplication context-free grammar(RCFG) is a grammar consisting of terminal, nontermi-nal, and start symbols as in an ordinary context-freegrammar, but instead of a finite set of productions, ithas a finite set of rule schemata of the following form:(A --~ ct, T) where A is a nonterminal symbol, a is astring of terminal and/or nonterminal symbols, andwhere T is a finite-state transducer.
(Thus, A ~ a is anordinary context-free rule, but it will be interpreteddifferently than normal.
)The production set associated with the schema (A --~a, T) is the set of all context-free rules of the form: A --*ww'ct, where w is a string of terminal symbols, and w' isobtained from w by applying the finite-state transduc-tion T to the string w.The next step relation f f  for derivations i defined asfollows:a ~ /3 if there is some context-free rule in someproduction set of some rule schema of the grammarsuch that a ~ /3 via this rule in the usual manner forcontext-free r write rules.
As usual, ~ is the reflexive-transitive closure of ~ .The language generated by an RCFG, G, is definedand denoted in the usual way: L(G) = { w L w a string ofterminal symbols and S ~ w}, where S is the startsymbol.Notice that an RCFG is a special form of infinitecontext-free grammar.
It consists of a context-freegrammar with a possibly infinite set of rewrite rules,namely the union of the finitely many production setsassociated with the schemata.
However, there are verysevere restrictions on which infinite sets of productionsare allowed.
Also notice that RCFGs generalize con-text-free grammars.
If we take T to be the transductionthat accepts only the empty string as input and output,then the set of productions associated with the schema(A -~ ct, I) consists of the single context-free productionA -~ a.
In particular, every context-free grammar is(except for notational detail) an RCFG.Recall that a context-free grammar in Greibach Nor-mal Form is one in which each production is of the formA --~ actwhere a is a terminal symbol and ct is a string consistingentirely of nonterminals.
It is well known that everycontext-free language can be (weakly) generated by acontext-free grammar in Greibach Normal Form.
Theschemata described in the definition of RCFGs havesome similarity to context-free rules in Greibach Nor-mal Form, except hat they start with a reduplicationstring, rather than a single terminal symbol, and theremaining string may contain terminal symbols.
Alsothe leading reduplication string may turn out to be theempty string.
Thus, these are very far from being inGreibach Normal Form.
Yet, as the proof of the nextresult shows, the analogy to Greibach Normal Form cansometimes be productive.Theorem 7.
If L is a reduplication substitution of acontext-free language, then there is an RCFG G suchthat L = L(G).Proof.
Let G' be a context-free grammar, T a finite-state transduction and a a symbol such that L isobtained from L(G') via T by substituting reduplicationstrings for a.
Without loss of generality, we can assumethat G' is in Greibach Normal Form.
The RCFG Gpromised in the theorem will be obtained by modifyingG'.
To obtain G from G' we replace ach G' rule of theformA --~ aA 1 A 2 ...A n,where a is the symbol used for the reduplication substi-tution, by the schema(A --~ Al A2 ""An, T)The remaining rules of G' are left unchanged except forthe technicality of adding a finite-state transduction thataccepts only the empty string as input and output, andso leaves the rule unchanged for purposes of generation.A routine induction then shows that the resulting RCFGG is such that L(G) = L.\[3Parsing with an RCFG does not require the fullpower of an RPDA, but only requires the restricted typeof R\]PDA that is described next.Definition.
A simple RPDA is an RPDA such that, inany computation:(i) there is at most one occurrence of the marker $ inthe stack at any one time, and(ii) as long as the marker symbol $ is in the stack, theRPDA never removes a symbol from the stack.More formally, an RPDA M is a simple RPDAprovided that the following condition holds: if theinstruction (p, push a, A) E 8(q, a, Z) can ever be used258 Computational Linguistics, Volume 15, Number 4, December 1989Walter J. Savitch A Formal Model for Context-Free Languages Augmented with Reduplicationwhen $ is in the stack, then a = /3 Z for some/3 anddoes not occur in a.Like Theorem 1, the following equivalence for simpleRPDAs is trivial to prove by adapting the proof of thesame result for ordinary PDAs.Theorem 8.
A language L is accepted by some simpleRPDA by final state if and only if it is accepted by some(typically different) simple RPDA by empty store.The next theorem says that RCFGs are equivalent tosimple RPDAs.Theorem 9.
For any language L, L is generated bysome RCFG if and only if L is accepted by some simpleRPDA.Proof.
Suppose that G is an RCFG such that L =L(G).
We can construct a simple RPDA that acceptsL(G).
All we need do is adapt the standard nondeter-ministic top-down algorithm for accepting a context-free language by empty store on an ordinary PDA.
Wethen obtain a simple RPDA that accepts L(G) by emptystore.
The details follow.The RPDA starts with the start nonterminal in thestack and proceeds to construct a leftmost derivation inthe stack.
If a nonterminal A is on the top of the stack,then it nondeterministically chooses a schema ( A ---> a,T) and does all of the following:1.
Pops A and pushes a.
(As usual, the symbols of a goin so the leftmost one is on the top of the stack.)2.
Pushes the marker symbol $ onto the stack.3.
Nondeterministically advances the input head pastsome string w while simultaneously computing astring w' such that w' is a finite-state transduction ofw via T. The string w' is pushed onto the stack as itis produced.4.
Executes a check-copy move to verify that w' is aninitial segment of the remaining input, thereby alsousing up the input w'.If the top symbol is a terminal and there is no ~ in thestack, then it simply matches the stack symbol to theinput symbol, consuming both the stack symbol and theinput symbol.A routine induction shows that the RPDA acceptsexactly the language L = L(G).Conversely, suppose that M is a simple RPDA suchthat L(M) = L. Without loss of generality, we willassume that M always pushes at least one symbol on thestack after pushing the marker symbols $,  that everymarker symbol $ on the stack is eventually used in acopy-check move, and that the marker symbol ~ is notleft in the stack at the end of any accepting computa-tion.
We reprogram M to obtain an ordinary PDA M'that accepts a different but related language L' .
M'  isdefined as follows: M' has all the input symbols of Mplus one new symbol, denoted <q, p>,  for each pair ofM states (q, p).
Intuitively, a new symbol <q, p> isused to stand in for a reduplication string that M wouldprocess starting in state q and ending up in state p aftera successful check-copy move.
M' mimics M step bystep as long as M would not have the marker $ in thestack and as long as the input is not one of the newsymbols <q, p>.
I fM'  reads a new symbol <q, p>,  andM' is simulating M in the state q, then M' guesses aninput symbol a of M and simulates M on input a.
If Mwould consume the input symbol a without pushing themarker ~ on the stack, then M' aborts its computation.If M would eventually push the marker $ on the stackwhile scanning (and possibly consuming) a, then M'continues to simulate M, guessing additional input sym-bols for M until it needs to simulate M performing acheck-copy move.
At this point it assumes that thecheck-copy move succeeds.
If that simulated check-copy move leaves the simulated M in the simulated statep, then M' consumes <q, p> and continues the simu-lation of M. If any of these conditions are not met, thenM' simply aborts its computation.Remember that, intuitively, a new symbol <q, p> isused to stand in for a reduplication string that M wouldprocess starting in state q and ending up in state p aftera successful check-copy move.
For any state q in whichM would push ~ on the stack, M will go on to push afinite-state transduction of the input onto the stack untilit wants to execute a check-copy move.
Let T(q, p) bethat finite-state transducer with start state q and thesingle accepting state p such that T simulates M startingin state q and pushing symbols on the stack and suchthat M accepts if and only if it ends the simulation in astate that allows a check-copy move that will leave M instate p. (Aside from start and accepting state, all theT(q, p) are essentially the same transducer.)
Now, M'accepts ome context-free language L' with the follow-ing property:(A) Suppose x o < ql, Pl > Xl < q2, P2 > X2 "'"< q., q.
> X. is such that each x; contains no newsymbols and suppose that the strings u i andv; (i <-- n) are such that each vi is a finite-statetransduction of ui by T (qi, Pi).
Under these as-sumptions, x 0 < q~, p~ > x~ < q2, P2 > X2""< q,,, qn> x. E L' = L (M') if and only i fx  0 ul vl xl u2 v2?
..u, v, x~ E L(M)Finally let G' be a context-free grammar in GreibachNormal Form for the context-free language L'.
Con-struct an RCFG, G, as follows:(i) For each rule of G' of the form A ~ < q, p > A lA 2 ... A n add the following schema to G:(A ~ A l A 2 ... An, T(q, p))(ii) For all other rules of G' simply add the rule to Gunchanged (except for cosmetic hanges in notation tomake them look like schemata).By (A) and a routine induction it follows that L(G) =L(M).OTheorem 9 makes simple RPDAs sound better be-haved than regular RPDAs and if there were no evi-dence to the contrary, the weaker model would bepreferred.
However, the fact that natural anguages canComputational Linguistics, Volume 15, Number 4, December 1989 259Walter J. Savitch A Formal Model for Context-Free Languages Augmented with Reduplicationhave complicated phrase structures embedded within areduplication construction indicates that simple RPDAsmay not be adequate for natural language syntax.
If oneassumes a language like English but with syntacticgender, strong agreement rules, and a well-behaved useof respectively, then one can easily see why one mightwant more power than that provided by a simple RPDA.An example of a kind of sentence that seems beyond thereach of simple RPDAs is the following:Tom, who has had three wives, Sally, who has hadseven husbands, Mary, who lost John, Hank, andSammy to cancer, heart disease, and stroke, respec-tively, and Frank, who had only one wife and lost herlast January, are a widower, widow, widow, andwidower, respectively.The natural way to handle these sorts of sentences withan RPDA is to have two markers + in the stack at once,and we conjecture that a single marker will not suffice.English does not have the syntactic gender andstrong agreement rules that would allow us to prove, viathis construction, that English is not context-free.
Wemerely put it forth as an example of a potential naturallanguage situation.9 SUMMARYWe have seen that the RPDA model is very similar tothe PDA characterization of context-free languages.Thus from an automata theoretic point of view, RPDAlanguages are very much like context-free languages.We have seen that both classes have similar closureproperties, and so they are similar from an algebraicpoint of view as well.
Moreover, the context-free lan-guages and the RPDA languages have similar pumpinglemmas that exclude many of the same unnatural lan-guage sets and even exclude them for the same reasons.Hence, the class of RPDAs are only mildly strongerthan context-free grammars.
However, the model issufficiently strong to handle the many reduplicationconstructions that are found in natural language and thatseem to place natural language outside of the class ofcontext-free languages.
The RPDA languages do not, asyet, have a grammar characterization similar to that ofcontext-free grammar, but the RCFG grammars arecontext-free like grammars that do capture at least alarge subclass of the RPDA languages.ACKNOWLEDGMENTSThis research was supported in part by NSF grant DCR-8604031.
BillChen and Alexis Manaster-Ramer provided a number of usefuldiscussions on this material.
A preliminary version of this work waspresented at the Workshop on Mathematical Theories of Language,LSA Summer Institute, Stanford University, Summer 1987.
Com-ments of the workshop participants, particularly those of AravindJoshi, K. Vijay-Shanker, and David Weir, helped shape the currentversion of this work.
A number of remarks by two anonymousreferees also help in the preparation of the final draft of this paper.
Iexpress my thanks to all these individuals for their help in this work.REFERENCESAho, Alfred V. 1968 Indexed Grammars--an Extension to ContextFree Grammars.
Journal of the Association for Computing Ma-chinery 15: 647-671.Aho, Alfred V. 1969 Nested-Stack Automata.
Journal of the Associ-ation for Computing Machinery 16: 383-406.Bar-HiUel, Y. and Shamir, E. 1964 Finite State Languages: FormalRepresentations and Adequacy Problems.
In: Bar-Hillel, Y.
(ed.
),Language and Information.
Addison-Wesley, Reading, MA: 87-98.Bre, snan, J.; Kaplan, R. M.; Peters, S. and Zaenen, A.
1982 Cross-Serial Dependencies in Dutch.
Linguistic Inquiry 13: 613-635.Culy, Christopher 1985 The Complexity of the Vocabulary of Bam-bara.
Linguistics and Philosophy 8: 345-351.Gazdar, Gerald 1985 Applicability of Indexed Grammars to NaturalLanguages, Report No.
CSLI-85-34.
Center for the Study ofLanguage and Information.
Palo Alto, CA.Gazdar, Gerald and Pullum, Geoffrey K. 1985 Computationally Rel-evant Properties of Natural Languages and their Grammars.
NewGeneration Computing 3: 273-306.Harrison, Michael A.
1978 Introduction to Formal Language Theory.Addison-Wesley, Reading, MA.Hopcroft, John E. and Ullman, Jeffrey D. 1979 Introduction toAutomata Theory, Languages, and Computation.
Addison-Wes-ley.
Reading, MA.Huybregts, M. A. C. 1976 Overlapping Dependencies in Dutch.Utrecht Working Papers in Linguistics l: 24-65.Joshi, Aravind K. 1985 Tree Adjoining Grammars: How MuchContext-Sensitivity s Required to Provide Reasonable StructuralDescriptions?
In: Dowty, D. R.; Karttunen, L. and Zwicky, A.
M.(eds.
), Natural Language Processing: Psycholinguistic, Compu-tational, and Theoretic Perspectives.
Cambridge University Press,New York, NY.Joshi, Aravind K. 1987 An Introduction to Tree Adjoining Grammars.In: Manaster-Ramer, A.
(ed.
), Mathematics of Language.
JohnBenjamins, Philadelphia, PA: 87.Joshi, Aravind K. 1989 Processing Crossed and Nested Dependen-cies: An Automaton Perspective on the Psycholinguistic Results.Preprint, Department of Computer and Information Sciences,University of Pennsylvania, Philadelphia, PA.Joshi, Aravind K.; Vijay-Shanker, K. and Weir, D. J.
1989 TheConvergence of Mildly Context-Sensitive Grammar Formalisms.Report MS-CIS-89-14, LINC LAB 144.
Department of Computeranci Information Science, University of Pennsylvania, Philadel-phia, PA.Kac, lvl.
B., Manaster-Ramer, A. and Rounds, W. C. 1987 Simulta-neous-Distributed Coordination and Context-Freeness.
Computa-tional Linguistics 13: 25-30.Manaster-Ramer, Alexis 1983 The Soft Formal Underbelly of Theo-retical Syntax.
Papers from the Nineteenth Regional Meeting.Chicago Linguistic Society 254-262.Manaster-Ramer, Alexis 1986 Copying in Natural Languages, Con-text-Freeness, and Queue Grammars.
Proceedings of the 24thAnnual Meeting of the Association for Computational Linguistics85-89.Manaster-Ramer, Alexis 1987 Dutch as a Formal Language.
Linguis-tics and Philosophy 10: 221-246.Ogden, W. F. 1968 A Helpful Result for Proving Inherent Ambiguity.Mathematical Systems Theory 2: 191-194.Pollard, Carl J.
1984 Generalized Phrase Structure Grammars, HeadGrammars, and Natural Languages.
Ph.D. thesis, Stanford Uni-versity, Stanford, CA.Postail, Paul 1964 Limitations of Phrase Structure Grammars.
In:Fodor, J.A.
; and Katz, J.J.
(eds.
), The Structure of Language:Readings in the Philosophy of Language.
Prentice-Hall, Engle-wood Cliffs, N.J.: 137-151.Pullum, Geoffrey K. and Gazdar, G. 1982 Natural Languages andContext Free Languages.
Linguistics and Philosophy 4: 471-504.260 Computational Linguistics, Volume 15, Number 4, December 1989Walter J. Savitch A Formal Model for Context-Free Languages Augmented with ReduplicationRoach, Kelly 1987 Formal Properties of Head Grammars.
In: Man-asteroRamer, A.
(ed.
), Mathematics of Language.
John Ben-jamins, Philadelphia, PA : 293-347.Rounds, William C.; Manaster-Ramer, A.; and Friedman, J.
1987Finding Natural Language a Home in Formal Language Theory.In: Manaster-Ramer, A.
(ed.
), Mathematics of Language.
JohnBenjamins, Philadelphia, PA : 87-114.Salomaa, A.
1973 Formal Languages.
Academic Press, New York,NY.Shieber, Stuart M. 1985 Evidence Against the Context-Freeness ofNatural Language.
Linguistics and Philosophy 8: 333-343.Steedman, M. J.
1987 Combinatory Grammars and Parasitic Gaps.Natural Language and Linguistic Theotw 5: 403-439.Steedman, M. J.
1988 Combinators and Grammars.
In: Oehrle, R.;B. ach, E.; and Wheeler, D.
(eds.
), Categorial Grammars andNatural Language Structures.
Reidel, Dordrecht, The Nether-lands : 417--442.Vijay-Shanker, K.; Weir, D. J.; and Joshi, A. K. 1987 On theProgression from Context-Free to Tree Adjoining Languages.
In:Manaster-Ramer, A.
(ed.
), Mathematics of Language, John Ben-jamins, Philadelphia, PA : 389-401.Weir, D.J.
; Vijay-Shanker, K.; and Joshi,A.
K. 1986 The Relationshipof Tree Adjoining Grammars and Head Grammars.
Proceedings ofthe 24th Annual Meeting of the Association for ComputationalLinguistics, New York, NY : 67-74.Computational Linguistics, Volume 15, Number 4, December 1989 261
