DisambiguatingGrammatically Ambiguous SentencesBy AskingM-~saru TomitaComputer Science DepartmentCarnegie-Mellon UniversityPittsburgh, PA 15213AbstractThe problem addressed in this paper is todisambiguate grammatically ambiguous inputsemences by asking the user.
who need not be acomputer specialist or a linguist, without showing anyparse trees or phrase structure rules.
Explanation ListComgarison (ELC) is the technique that implementsthis process.
It is applicable to all parsers which arebased on phrase structure grammar, regardless of theparser implementation.
An experimental system hasbeen implemented at Carnegie-Mellon University, and ithas been applied to English-Japanese machinetranslation at Kyoto University.1.
Introduction/~ F=rge number of techniques using semantic information havebeen deve!oped to resolve natural language ambiguity.
However,not all ambiguity problems can be solved by those techniques atthe current state of art.
Moreover, some sentences are absolutelyambiguous, that is, even a human cannot disambiguate them.Therefore.
it is important for the system to be capable of asking auser questions interactively to disambiguate a sentence.Here, we make an important condition that an user is neither acomputer scientist nor a linguist.
Thus, an user may ROt recognizean;, spec=al terms or notations like a tree structure, phrasestructure grammar, etc.The first system to disambiguate sentences by askinginteractively is perhaps a program called "disambiguator" in Kay'sMINO system \[2\].
Although the disambiguation algorithm is notpresented in \[2\], some basic ideas have been alreadyimplemented in the Kay's system 2.
In this paper, we shall onlydeal with grammatical ambiguity, or in other words, syntacticambiguity.
Other umhiguity problems, such as word-senseambiguity and referential ambiguity, are excluded.Suppose a system is given the sentence:"Mary saw a man with a telescope"and the system has a phrase structure grammar including thefollowing rules <a> - <g>:<a> S - ->  NP + VP<b> S - ->  NP + VP + PP<c> NP - -> *noun<d> NP - -> *det+ *noun<e> NP --> NP + PP<f> PP - -> *prep + NP<g> VP - -> *verb  + NPThe system would produce two parse trees from the inputsentence (I. using rules <b>,<c>,<g>,<d>,<f>,<d>; II.
using rules<a>,<c>,<g>,<e>,<d>,<f>,<d>).
The difference is whether thepreposition phrase "with a telescope" qualifies the noun phrase"a man" or the sentence "Mary saw a man".
This paper shalldiscuss on how to ask the user" to select his intendedinterpretation without showing any kind of tree structures orphrase structure grammar rules.
Our desired questior~ for thatsentence is thus something like:1) The action "Mary saw a man" takes place "with a telescope"2) "a man" is "with a telescope"NUMBER ?The technique to implement this, which is described in thefollowing sections, is called Explanation List Comparison.2.
Explanation List ComparisonThe basic idea is to attach an Explanation Template to each rule.For example, each of the rules <a> - <g> would have anexplanation template as follows:<a><b><c><d><e><f><g>Exp lanat ion  Template(1)  is  a sub jec t  o f  the ac t ion  (2)The act ion  (1 2) takes  p \ ]ace  (3)(1)  is  a noun(1)  is  a determiner  o f  (2 )(1)  is  (2 )(1) is  a p repos i t ion  o f  (2 )(2) is  an ob jec t  of  the verb (1)tThi: lesearcn was sponsored by the Defense Advanced Research Projects:~ger',:y {('~O~3), ~.PP.,'~ Order No.
3597, monitored by the Air Force AvionicsLahor;llor~, !JnOer Contract F3.3615-81 K-1539.
The views and conclusionsc~,lte,:l~J in fi=is d~cumnnt are those ef the authors and should not be interpretedas reor.e~,~ntinq the official L)olicies.
eilher expressed or implied, of the DefenseAdvanceO Rgsearch Projects Agency or the US Government.2personal communication.Whenever a rule is employed to parse a sentence, anexplanation is generated from its explanation template.
Numbersin an explanation template indicate n-th constituent of the righthand side of the rule.
For instance, when the rule <f>PP - ->  *prep + NPmatches "w i th  a te lescope"  (*prep = "WITH"; NP = "s476te' lescope"), the explanation"(with) is a preposition of (a telescope)"is uenerated.
Whenever the system builds a parse tree, it alsobuilds a list of explanations wnich are generated from explanationtemplates ot all rules employed.
We refer to such a list as anexplanation list.
the explanation lists of the parse trees in theexample above are:Alternative I.<b> The action (Mary saw a man) takes place (with a telescope)<c3 (Mary) is a noun<g> (a man) is an object of the verb (saw)Cd> (A) is a determiner of (man)<f> (v:ith) =s a preposition of (a telescope)<d> (A) is a dete,'miner of (telescope)Alternative II.<a> (Mary) is a subject of the action (saw a man with a telescope)<c> (Mary) is a noun<g> (~ man with a telescope) is an object of the verb (saw)<e> (a man) is (with a telescope)<d> (A) is a determiner of (man)<f> (with is a preposition of (a telescope)<d> (A) is a determiner of (telescope)In order to disambiguate a sentence, the system only examinesthese Explc, nation Lists, but not parse trees themselves?
Thismakes our method independent from internal representation of ar~a~se tree.
Loosely speaking, when a system produces more thanerie parse tree, explanation lists of the trees are "compared" andthe "diliere,~ce" is shown to the user.
The user is, then, asked toselect the correct alternative.3.
The revised version of ELCUr, fortunately, the basic idea described in the preceding sectiondoes not work quite well.
For instance, the difference of the twoexplanation lists in our example is1)The action (Mary saw a man) takes place (with a telescope),(a man) is an object of the verb (saw);2)(k.laf y) is a subject of the action (saw a man with a telescope),(a man with a telescope) is an object of the verb (saw),(a man) is (with a telescope);despite the fact that the essential difference is only1) The action (Mary saw a man) takes place (with a telescope)2) (a man) is (with a telescope)Two refinement ideas, head and multiple explanations, areintroduced to solve this problem.3.1.
HeadWe define head as a word or a minimal cluster of words whichare syntactically dominant in a group and could have the samesyntactic function as the whole group if they stood alone.
Forexample, the head of "VERY SMART PLAYERS IN NEW YORK" is"PLAYERS", and the head o!
"INCREDIBLY BEAUTIFUL" is"BEAUTIFUL", but the head of "1 LOVE CATS" is "1 LOVE CATS"ilk, elf.
The idea is that.
whenever the system shows a part of aninput sentence to the user, only the ilead of it is shown.
Toimplement his idea, each rule must hove a head definition besidesan explanation template, as follows.Rule Head<a> \[z z\]<b> \ [1Z\ ]<c> \[1\]<d> \[1 2\]<e> I t \ ]<f> I t  Z\]<g> \[1 2\]For instance, the head definition of the rule <b) says that thehead of the construction "NP + VP + PP" is a concatenation ofthe head of 1.st constituent (NP) and the head of 2-nd constituent(VP).
The i~ead of "A GIRL with A RED BAG saw A GREEN TREEWITH a telescope" is, therefore, "A GIRL saw A TREE", becausethe head of "A GIRL with A RED BAG" (NP) is "A GIRL" and thehead of "saw A GREEN "IREE" (VP) is "saw A TREE".in our example, the explanation(Mary) is a subject of the action (saw a man with a telescope)becomes(Mary) is a subject of the action (saw a man),and the explanation(a man with a telescope) is an object of the verb (saw)becomes(a man) is an object of the verb (saw),because the head of "saw a man with a telescope" is "saw aman", and the head of "a man with a telescope" is "a man".The difference of the two alternatives are now:t)The action (Mary saw a man) take place (with a telescope);2)(Mary) is a subject of the action (saw a man),(a man) is (with a telescope);3.2.
Multiple explanationsIn the example system we have discussed above, each rulegenerates exactly one explanation..
In general, multipleexplanations (including zero) can be generated by each rule.
Forexample, rule <b)S - -> NP + VP + PPshould have two explanation templates:(1)  ts a subject  of Lhe acLton (2)The actton (1 2) takes place (3 ) ,whereas rule <a>S - -> NP + VPshould have only one explanation template:(1) "Is a sub jec t  of  the ac t ton  (2 ) .With the idea of head and multiple explanations, the system nowproduces the ideal question, as we shall see below.3.3.
Revised ELCTo summarize, the system has a phrase structure grammar, andeach rule is followed by a head definition followed by an arbitrarynumber of explanation templates.477Rule Ilead Exp lanat ion  Iemplate<a> \[1 2\] ( t )  is  a sub jec t  of  the ac t ion  (2)<b> \ [ t  2\ ]  (1)  is a sub jec t  of the ac t ion  (2)The ac t ion  (1 2) takes p lace  (3)<c> \[t\] <<none>><d> \ [ t  2\]  (1)  is a determiner  of  (2)<e> \ [1 \ ]  (1)  is (2)<f> I t  2\]  (1)  is a p repos i t ion  of  (2)<g> \ [ t  2\]  (2)  is an ob jec t  of the verb (1)With the ideas of head and multiple explanation, the systembuilds the following two explanation lists from the sentence "Marysaw a man with a telescope".A l ternat ive I.<b> (Mary) is a subject of the action (saw a man)<b> The action (Mary saw a man) takes place (with a telescope)<g> (a man) is an object of tile verb (saw)<d> (A) is a determiner of (man)<f> (with) is a preposition of (a telescope)<d> (A) is adeterminer of (telescope)A l ternat ive II.<a> (Mary) is a subject of the action (saw a man)<g> (a man) is an object of the verb (saw)<e> (a man) is (with a telescope)<d> (A) is a determiner of (man)<f> (with is a preposition of (a telescope)<d> (A) is adeterminer of (telescope)The difference between these two isThe action (Mary saw a man) takes place (with a telescope)and(a man) is (with a telescope).Thus, the system can ask the ideal question:1) The action (Mary saw a man) takes place (with a telescope)2) (a man) is (with a telescope)Number?.4 .
More  Complex  ExampleThe example in the preceding sections is somewhatoversimplified, in the sense that there are only two alternativesand only two explanation lists are compared.
If there were threeor more alternatives, comparing explanation lists would be not aseasy as comparing just two.Consider the following example sentence:Mary saw a man in the park with a telescope.This s~ntence is ambiguous in 5 ways, and its 5 explanation listsare shown below.Al ternat ive I.
(a man) is (in the park)(the Gark) is (with a telescope)A l ternat ive II.
(a man) is (with a telescope)(a man) is (in the park): :A l ternat ive III.The action (Mary saw a man) takes place (with a te lescope)(a man) is (ill the park)A l ternat ive IV.The action (Mary saw a man) takes place (in the park)(the park) is (with a telescope): :: :A l ternat ive V.The action (Mary saw a man) takes place (with a telescope)The action (Mary saw a man) takes place (in the park): :With these 5 explanation lists, the system asks the user aquestion twice, as follows:1) (a man) is (in the park)2) The action (Mary saw a man) takes place (in the park)NUMBER?
1i) (the park) is (with a telescope)2) (a man) is (with a telescope)3) The action (Mary saw a man) takes place (with a telescope)NUMBER?
3The implementation of this is described in the following.We refer to the set of explanation lists to be compared, {/1' L2 ....}, as A.
If the number of explanation lists in A is one ; jusl returnthe parsed tree which is associated with that explanation list.
Ifthere are more than one explanation list in A, the system makes aQlist (Question list).
The Qlist is a list of explanationsQlist = { e I, e 2 .
.
.
.
.
en}which is shown to the user to ask a question as follows:t )  e I2) e 2n) e nNumber?Qlist must satisfy the following two conditions to make sure thatalways exactly one explanation is true.?
Each explanation list / in A must contain at least oneexplanation e which is also in Olist.
Mathematically,the following predicate must be satisfied.VL3e(e E L A e E Qlist)This condition makes sure that at least one ofexplanations in a Qlist is true.?
No explanation list L in A contains more than oneexplanation in a Qlist.
That is,478~(gLgege'(L E AAeEL  Ae 'ELA e G Qlist A e' E Qlist A p =e')This condition makes sure that at most one ofexplanations in Qlist is true.The detailed algorithm of how to construct a Qlist is presented inAppendix.Once a Olist is created, ~t is presented to the user.
The user isasked to select one correct explanation in the Qlist, called the keyexplanation.
All explanation lists which do not contain the keyexplanation are removed from A.
If A still contains more than oneexplanation list, another Olist for this new A is created, and shownto the user.
This process is repeated until A contains only oneexplanation list.5.
Concluding RemarksAn experimental system has been written in Maclisp, andrunning on Tops-20 at Computer Science Department, Carnegie-Mellon University.
The system parses input sentences provided bya user according to grammar rules and a dictionary provided by asuper user.
The system, then.
asks the user questions, ifnecessary, to disambiguate the sentence using the technique ofExplanation List Comparison.
The system finally produces onlyone parse tree of the sentence, which is the intendedinterpretation of the user.
1he parsor is implemented in a bottom-up, breath-first manner, but the idea described in the paper isindependent from the parser implementation and from anyspecific grammar or dictionary.The kind of ambiguity we have discussed is structural ambiguity.An ambiguity is structural when two different structures can bebui!t up out of smaller constituents of the same given structureand type.
On the other hand, an ambiguity is lexical when oneword can serve as various parts of speech.
Resolving lexicalambiguity is somewhat easier, and indeed, it is implemented in thesystem.
As we can see in the Sample Runs below, the system firstresolves lexical ambiguity m the obvious manner, if necessary.Recently, we have integrated our system into an English-Japanese Machine Translation system \[3\], as a first step towarduser-friendly interactive machine translation \[6\].
The interactiveEnglish Japanese machine translation system has beenimplemented at Kyoto University in Japan \[4, 5\].AcknowledgementsI would like to thank Jaime Carbonell, Herb Simon,Martin Kay, Jun-ich Tsujii, Toyoaki Nishida, ShujiDoshita and Makoto Nagao for thoughtful commentson an earlier version of this paper.Appendix A: Qlist-Construction Algorithminput A : set of explanation listsoutput Qlist : set of explanationslocal e : explanationL : explanation list (set of explanations)U, C : set of explanation lists1 :C~2: U~A3: Qlist ~4: i fU = ~then return Qlist5: select one explanation e such thate is in some explanation list E U,but not in any explanation list E C;if no such e exists, return ERROR6: Qlist ~ Qlist + {e}7: C=C + {L IeELALEU }8: U= {L leEL  ALE (U)}9: goto 4?
The input to this procedure is a set of explanationlists, {L1, L 2 .... }.The output of this procedure is a list of explanations,{e I, e 2 .
.
.
.
.
en}, such that each explanation list, li,contains exactly one explanation which is in the Qlist.?
An explanation list L is called covered, if someexplanation e in L is also in Qlist.
L is calleduncovered, if any of the explanations in L is not inOlist.
C is a set of covered explanation lists in A, andU is a set of uncovered explanation lists in A.?
1-3: initialization, let Olisl be empty.
All explanationlists in A are uncovered.?
4: if all explanation lists are covered, quit.?
5-6: select an explanation e and put it into Qlist tocover some of uncovered not explanation lists, emust be such that it does 6xist in any of coveredexplanation lists (if it does exist, the explanation listhas two explanation in A, violating the Qlistcondition).?
7-8: make uncovered explanation lists which are nowcovered by e to be covered.?
9: repeat the process until everything is covered.479References\[1\] Kay, M.The MIND System.Algorithmic Press, New York, 1973,.\[2\] Nishida, T. and Doshita, S.An Application of Montague Grammar to English-JapaneseMachine Translation.Proceedings of conference on Applied Natural LanguageProcessing :156-165, 1983.\[3\] Tomita, M., Nishida, T. and Doshita, S.An Interactive English.Japanese Machine TranslationSystem.Forthcoming (in Japanese), 1984.\[4\] Tomita, M., Nishida, T. and Doshita, S.User Front-End for disambiguation i Interactive MachineTranslation System.In Tech.
Reports of WGNLP.
Information Processing~ociety of Japan, (in Japanese, forthcoming), 1984.\[5\] Tomita, M.The Design Philosophy of Personal Machine TranslationSystem.Technical Report, Computer Science Department,Carnegie-Mellon University, 1983.Appendix B: Sample Runs(transl ine '(time fl ies like an arrow in Japan)}(---END OF PARSE-- I0 ALTERNATIVES)(The word TIME (1) is : )(Z : VERB)(Z : NOUN)NUMBER>(The word FLIES (2) is : )(1 : VERB)(Z : NOUN)NUMBER> !
(I : (AN ARROW) IS (IN JAPAN))(2 : THE ACTION (IIME FLIES) TAKES PLACE (IN JAPAN))NUMBER>(S (MP (TIME *NOUN))(FLIES *VERB)(PP (LIKE "PREPOSITION) (NP (AN "DETERMINER) (ARROW "NOUN)))(PP (IN "PREPOSIT\[ON) (JAPAN "NOUN)))(transl ine '(Mary saw a man in the apartment with a telescope))(---END OF PARSE-- 5 ALTERNAIIVES)(I : (A MAN) IS (IN TIIE APARTMENT))(2 : Tile ACTION (MARY SAW A MAN) TAKES PLACE (IN TIIE APARTMENT))NUMBER> i(1 : (A MAN) IS (WITH A TELESCOPE))(2 : (THE APARTMENT) IS (WIIH A TELESCOPE))(3 : THE ACIION (MARY SAW A MAN) TAKES PLACE (WITH A TELESCOPE))NUMBER>(S (NP (MARY "NOUN))(VP (SAW "VERB)(NP (NP (A "DETERMINER) !MAN *NOUN))(PP (IN *PREPOSIIION)(NP (IHE *DETERMINER) (APARTMENT "NOUN)))))(PP (WITH "PREPOSITION)(NP (A "DETERMINER) (TELESCOPE "NOUN))))480
