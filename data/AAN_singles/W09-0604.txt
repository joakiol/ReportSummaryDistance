Proceedings of the 12th European Workshop on Natural Language Generation, pages 25?32,Athens, Greece, 30 ?
31 March 2009. c?2009 Association for Computational LinguisticsIs sentence compression an NLG task?Erwin Marsi, Emiel KrahmerTilburg UniversityTilburg, The Netherlandse.j.krahmer@uvt.nle.c.marsi@uvt.nlIris Hendrickx, Walter DaelemansAntwerp UniversityAntwerpen, Belgiumiris.hendrickx@ua.ac.bewalter.daelemans@ua.ac.beAbstractData-driven approaches to sentence com-pression define the task as dropping anysubset of words from the input sentencewhile retaining important information andgrammaticality.
We show that only 16%of the observed compressed sentences inthe domain of subtitling can be accountedfor in this way.
We argue that part of thisis due to evaluation issues and estimatethat a deletion model is in fact compat-ible with approximately 55% of the ob-served data.
We analyse the remainingproblems and conclude that in those casesword order changes and paraphrasing arecrucial, and argue for more elaborate sen-tence compression models which build onNLG work.1 IntroductionThe task of sentence compression (or sentence re-duction) can be defined as summarizing a singlesentence by removing information from it (Jingand McKeown, 2000).
The compressed sentenceshould retain the most important information andremain grammatical.
One of the applicationsis in automatic summarization in order to com-press sentences extracted for the summary (Lin,2003; Jing and McKeown, 2000).
Other appli-cations include automatic subtitling (Vandeghin-ste and Tsjong Kim Sang, 2004; Vandeghinste andPan, 2004; Daelemans et al, 2004) and displayingtext on devices with very small screens (Corston-Oliver, 2001).A more restricted version defines sentencecompression as dropping any subset of wordsfrom the input sentence while retaining impor-tant information and grammaticality (Knight andMarcu, 2002).
This formulation of the task pro-vided the basis for the noisy-channel en decision-tree based algorithms presented in (Knight andMarcu, 2002), and for virtually all follow-up workon data-driven sentence compression (Le andHoriguchi, 2003; Vandeghinste and Pan, 2004;Turner and Charniak, 2005; Clarke and Lapata,2006; Zajic et al, 2007; Clarke and Lapata, 2008)It makes two important assumptions: (1) onlyword deletions are allowed ?
no substitutions orinsertions ?
and therefore no paraphrases; (2) theword order is fixed.
In other words, the com-pressed sentence must be a subsequence of thesource sentence.
We will call this the subsequenceconstraint, and refer to the corresponding com-pression models as word deletion models.
Anotherimplicit assumption in most work is that the scopeof sentence compression is limited to isolated sen-tences and that the textual context is irrelevant.Under this definition, sentence compression isreduced to a word deletion task.
Although onemay argue that even this counts as a form oftext-to-text generation, and consequently an NLGtask, the generation component is virtually non-existent.
One can thus seriously doubt whether itreally is an NLG task.Things would become more interesting from anNLG perspective if we could show that sentencecompression necessarily involves transformationsbeyond mere deletion of words, and that this re-quires linguistic knowledge and resources typicalto NLG.
The aim of this paper is therefore to chal-lenge the deletion model and the underlying subse-quence constraint.
To use an analogy, our aim is toshow that sentence compression is less like carv-ing something out of wood - where material canonly be removed - and more like molding some-thing out of clay - where the material can be thor-25oughly reshaped.
In support of this claim we pro-vide evidence that the coverage of deletion modelsis in fact rather limited and that word reorderingand paraphrasing play an important role.The remainder of this paper is structured as fol-lows.
In Section 2, we introduce our text materialwhich comes from the domain of subtitling.
Weexplain why not all material is equally well suitedfor studying sentence compression and motivatewhy we disregard certain parts of the data.
Wealso describe the manual alignment procedure andthe derivation of edit operations from it.
In Sec-tion 3, an analysis of the number of deletions, in-sertions, substitutions, and reorderings in our datais presented.
We determine how many of the com-pressed sentences actually satisfy the subsequenceconstraint, and how many of them could in prin-ciple be accounted for.
That is, we consider al-ternatives with the same compression ratio whichdo not violate the subsequence constraint.
Nextis an analysis of the remaining problematic casesin which violation of the subsequence constraintis crucial to accomplish the observed compressionratio.
We single out (1) reordering after deletionand (2) paraphrasing as important factors.
Giventhe importance of paraphrases, Section 3.4 dis-cusses the perspectives for automatic extraction ofparaphrase pairs from large text corpora, and triesto estimate how much text is required to obtain areasonable coverage.
We finish with a summaryand discussion in Section 4.2 MaterialWe study sentence compression in the context ofsubtitling.
The basic problem of subtitling is thaton average reading takes more time than listen-ing, so subtitles can not be a verbatim transcrip-tion of the speech without increasingly lagging be-hind.
Subtitles can be presented at a rate of 690to 780 characters per minute, while the averagespeech rate is considerably higher (Vandeghinsteand Tsjong Kim Sang, 2004).
Subtitles are there-fore often a compressed representation of the orig-inal spoken text.Our text material stems from the NOS Journaal,the daily news broadcast of the Dutch public tele-vision.
It is parallel text with on one side the au-tocue sentences (aut), i.e.
the text the news readeris reading, and on the other side the correspondingsubtitle sentences (sub).
It was originally collectedand processed in two earlier research projects ?Atranos and Musa ?
on automatic subtitling (Van-deghinste and Tsjong Kim Sang, 2004; Vandegh-inste and Pan, 2004; Daelemans et al, 2004).
Alltext was automatically tokenized and aligned atthe sentence level, after which alignments weremanually checked.The same material was further annotated in anongoing project called DAESO1, in which the gen-eral goal is automatic detection of semantic over-lap.
All aligned sentences were first syntacticallyparsed after which their parse trees were manuallyaligned in more detail.
Pairs of similar syntacticnodes ?
either words or phrases ?
were aligned andlabeled according to a set of five semantic similar-ity relations (Marsi and Krahmer, 2007).
For cur-rent purposes, only the alignment at the word levelis used, ignoring phrasal alignments and relationlabels.Not all material in this corpus is equally wellsuited for studying sentence compression as de-fined in the introduction.
As we will discuss inmore detail below, this prompted us to disregardcertain parts of the data.Sentence deletion, splitting and merging For astart, autocue and subtitle sentences are often notin a one-to-one alignment relation.
Table 1 speci-fies the alignment degree (i.e.
the number of othersentences that a sentence is aligned to) for autocueand subtitle sentences.
The first thing to noticeis that there is a large number of unaligned sub-titles.
These correspond to non-anchor text from,e.g., interviews or reporters abroad.
More inter-esting is that about one in five autocue sentencesis completely dropped.
A small number of about4 to 8 percent of the sentence pairs are not one-to-one aligned.
A long autocue sentence may besplit into several simpler subtitle sentences, eachcontaining only a part of the semantic content ofthe autocue sentence.
Conversely, one or more -usually short - autocue sentences may be mergedinto a single subtitle sentence.These decisions of sentence deletion, splittingand merging are worthy research topics in the con-text of automatic subtitling, but they should notbe confused with sentence compression, the scopeof which is by definition limited to single sen-tence.
Accordingly we disregarded all sentencepairs where autocue and subtitle are not in a one-to-one relation with each other.
This reduced thedata set from 15289 to 11034 sentence pairs.1http://daeso.uvt.nl26Degree: Autocue: (%) Subtitle: (%)0 3607 (20.74) 12542 (46.75)1 12382 (71.19) 13340 (49.72)2 1313 (7.55) 901 (3.36)3 83 (0.48) 41 (0.15)4 8 (0.05) 6 (0.02)Table 1: Degree of sentence alignmentWord compression A significant part of the re-duction in subtitle characters is actually not ob-tained by deleting words but by lexical substitutionof a shorter token.
Examples of this include sub-stitution by digits (?7?
for ?seven?
), abbreviationsor acronyms (?US?
for ?United States?
), symbols(euro symbol for ?Euro?
), or reductions of com-pound words (?elections?
for ?state-elections?
).We will call this word compression.
Although animportant part of subtitling, we prefer to abstractfrom word compression and focus here on sen-tence compression proper.
Removing all sentencepairs containing a word compression has the dis-advantage of further reducing the data set.
Insteadwe choose to measure compression ratio (CR) interms of tokens2 rather than characters.CR =#toksub#tokaut(1)This means that the majority of the word com-pressions do not affect the sentence CR.Variability in compression ratio The CR ofsubtitles is not constant, but varies depending(mainly) on the amount of provided autocue ma-terial in a given time frame.
The histogram inFigure 1 shows the distribution of the CR (mea-sured in words) for one-to-one aligned sentences.In fact, autocue sentences are most likely not tobe compressed at all (thus belonging to the largestbin, from 1.00 to 1.09 in the histogram).3 In orderto obtain a proper set of compression examples,we retained only those sentence pairs where thecompression ratio is less than one.Parsing failures As mentioned earlier detailedalignment of autocue and subtitle sentences wascarried out on their syntactic trees.
However,for various reasons a small number of sentences(0.2%) failed to pass the parser and received noparse tree.
As a consequence, their trees could not2Throughout this study we ignore punctuation and lettercase.3Some instances even show a CR larger than one, becauseoccasionally there is sufficient time/space to provide a clari-fication, disambiguation, update, or stylistic enhancement.Figure 1: Histogram of compression ratioMin: Max: Sum: Mean: SD:aut-tokens 2 43 80651 15.41 5.48sub-tokens 1 29 53691 10.26 3.72CR 0.07 0.96 nan 0.69 0.17Table 2: Properties of the final data set of5233 pairs of autocue-subtitle sentences: mini-mum value, maximal value, total sum, mean andstandard deviation for number of tokens per au-tocue/subtitle sentence and Compression Ratiobe aligned and there is no alignment at the wordlevel available either.
Variability in CR and pars-ing failures are together responsible for a furtherreduction down to 5233 sentence pairs, the finalsize of our data set, with an overall CR of 0.69.Other properties of this data set are summarized inTable 2.4Word deletions, insertions and substitutionsHaving a manual alignment of similar words inboth sentences allows us to simply deduce worddeletions, substitutions and insertions, as well asword order changes, in the following way:?
if an autocue word is not aligned to a subtitleword, then it is was deleted?
if a subtitle word is not aligned to an autocueword, then it was inserted?
if different autocue and subtitle words arealigned, then the former was substituted bythe latter?
if alignments cross each other, then the wordorder was changedThe remaining option is where the alignedwords are identical (ignoring differences in case).4We use the acronym nan (?not a number?)
for unde-fined/meaningless values.27Without the word alignment, we would haveto resort to automatically calculating the edit dis-tance, i.e.
the sum of the minimal number ofinsertions, deletions and substitutions required totransform one sentence in to the other.
However,this would result in different and often counter-intuitive sequences of edit operations.
Our ap-proach clearly distinguishes word order changesfrom the edit operations; the conventional edit dis-tance, by contrast, can only account for changesin word order by sequences of the edit operations.Another difference is that substitution can also beaccomplished as deletion followed by insertion,which means edit operations need to have an as-sociated weight.
Global tuning of these weightsturns out to be hard.3 Analysis3.1 Edit operationsThe observed deletions, insertions, substitutions,edit distances, and word order changes are shownin Table 3.
As expected, deletion is the most fre-quent operation, with on average seven deletionsper sentence.
Insertion and substitutions are farless frequent.
Note also that ?
even though the taskis compression ?
insertions are somewhat morefrequent than substitutions.
Word order changesoccur in 1688 cases (32.26%).
Here, reordering isa binary variable ?
i.e.
the word order is changedor not ?
hence Min, Max and SD are undefined.Another point of view is to look at the numberof sentence pairs containing a certain edit oper-ation.
Here we find 5233 pairs (100.00%) withdeletion, 2738 (52.32%) with substitution, 3263(62.35%) with insertion, and 1688 (32.26%) withreordering.The average CR for subsequences is 0.68(SD = 0.20) versus 0.69 (SD = 0.17)for non-subsequences.
A detailed inspection ofthe relation between the subsequence/non ?subsequence ratio and CR revealed no clear cor-relation, so we did not find indications that non-subsequences occur more frequently at highercompression ratios.3.2 Percentage of subsequencesThe subtitle is a subsequence of the autocue ifthere are no insertions, no substitutions, and noword order changes.
In contrast, if any of thesedo occur, the subtitle is not a subsequence.
It turnsMin: Max: Sum: Mean: SD:del 1 34 34728 6.64 4.57sub 0 6 4116 0.79 0.94ins 0 17 7768 1.48 1.78dist 1 46 46612 8.91 5.78reorder nan nan 1688 0.32 nanTable 3: Observed word deletions, insertions, sub-stitutions, and edit distancesout that only 843 (16.11%) subtitles are a subse-quence, which is rather low.At first sight, this appears to be bad news forany deletion model, as it seems to imply that themodel cannot account for close to 84% the ob-served data.
However, the important thing to keepin mind is that compression of a given sentenceis a problem for which there are usually multiplesolutions (Belz and Reiter, 2006).
This is exactlywhat makes it so hard to perform automatic evalu-ation of NLG systems.
There may very well existsemantically equivalent alternatives with the sameCR which do satisfy the subsequence constraint.For this reason, a substantial part of the observednon-subsequences may have subsequence counter-parts which can be accounted for by a deletionmodel.
The question is: how many?In order to address this question, we took arandom sample of 200 non-subsequence sentencepairs.
In each case we tried to come up withan alternative subsequence subtitle with the samemeaning and the same CR (or when opportune,even a lower CR).
Table 4 shows the distribu-tion of the difference in tokens between the orig-inal non-subsequence subtitle and the manually-constructed equivalent subsequence subtitle.
Ap-parently 95 out of 200 (47%) subsequence sub-titles have the same (or even fewer) tokens, andthus the same (or an even lower) compression ra-tio.
This suggests that the subsequence constraintis not as problematic as it seemed and that the cov-erage of a deletion model is in fact far better thanit appeared to be.
Recall that 16% of the originalsubtitles were already subsequences, so our anal-ysis suggests that a deletion model is compatiblewith 55% (16% plus 47% of 84%).3.3 Problematic non-subsequencesAnother result of this exercise in rewriting sub-titles is that it allows us to identify those caseswhere the attempt to create a proper subse-quence fails.
In (1), we show one representa-tive example of a problematic subtitle, for which28(1) Aut dethebronsourcewaswaseenageriatrischegeriatricpatientpatientdiewhozonderwithouthetitzelfselftetomerkennoticeuitzonderlijkexceptionallyveelmanylarvenlarvaebijwithzichhimbleekappearedtetodragencarryenandeenagrotelargeverspreidingspreadingveroorzaaktecaused?the source was a geriatric patient who unknowingly carried exceptionally many larvae and caused a wide spreading?Sub eenageriatrischegeriatricpatientpatientmetwithlarvenlarvaeheefthasdetheverspreidingspreadingveroorzaaktcausedSeq de bron was een geriatrische patient die veel larven bij zich bleek te dragen en een verspreiding veroorzaakte(2) Aut ininverbandrelationmettodethelawinerampavalanche-disasteriningalu?rGaltu?rhebbenhavedethepolitiekepoliticalpartijenpartiesinintirolTirolgezamenlijktogetherbeslotendecideddetheverkiezingscampagneelection-campaignvoorforhettheregionaleregionalparlementparliamentopuptetoschortenpostponeSub dethepolitiekepoliticalpartijenpartiesinintirolTirolhebbenhavebeslotendecideddetheverkiezingenelectionsopuptetoschortenpostpone?Political parties in Tirol have decided to postpone the elections?
(3) Aut velenmanyvanofhenthemwordenaredoorbydetheservie?rsSerbsininvolgeladencrammedtreinentrainsgedeporteerddeportedSub vluchtelingenrefugeeswordenareperbytreintraingedeporteerddeportedtoken-diff: count: (%:)-2 4 2.00-1 18 9.000 73 36.501 42 21.002 32 16.003 11 5.504 9 4.505 5 2.507 2 1.008 2 1.009 1 0.5011 1 0.50Table 4: Distribution of difference in tokensbetween original non-subsequence subtitle andequivalent subsequence subtitlethe best equivalent subsequence we could ob-tain still has nine more tokens than the origi-nal non-subsequence.
These problematic non-subsequences reveal where insertion, substitutionand/or word reordering are essential to obtain asubtitle with a sufficient CR (i.e.
the CR observedin the real subtitles).
At least three different typesof phenomena were observed.Word order In some cases deletion of a con-stituent necessitates a change in word order to ob-tain a grammatical sentence.
In example (2), theautocue sentence has the PP modifier in verbandmet de lawineramp in galu?r in its topic position(first sentence position).
Deleting this modifier, asis done in the subtitle, results in a sentence thatstarts with the verb hebben, which is interpreted asa yes-no question.
For a declarative interpretation,we have to move the subject de politieke partijento the first position, as in the subtitle.
Incidentally,this indicates that it is instructive to apply sentencecompression models to multiple languages, as aword order problem like this never arises in En-glish.Similar problems arise whenever an embeddedclause is promoted to a main clause, which re-quires a change in the position of the finite verbin Dutch.
In total, a word order problem occurredin 24 out 200 sentences.Referring expressions Referring expressionsare on many occasions replaced by a shorterone ?
usually a little less precise.
Forexample, de belgische overheid ?the Belgianauthorities?
is replaced by belgie ?Belgium?.Extreme cases of this occur where a longNP like deze tweede impeachment-procedurein de amerikaanse geschiedenis ?this secondimpeachment-procedure in the American history?is replaced by an anaphor like het ?it?.Since a referring expression or anaphor must beappropriate in the given context, substitutions likethese transcend the domain of a single sentenceand require taking the preceding textual contextinto account.
This is especially clear in exam-ples like (3) in which ?many of them?
is replacedthe ?refugees?.
It is questionable whether thesetypes of substitutions belong to the task of sen-tence compression.
We prefer to regard it as one ofthe additional tasks in automatic subtitling, apartfrom compression.
Incidentally, it is interestingthat the challenge of generating referring expres-sions is also relevant for automatic subtitling.29Paraphrasing Apart from the reduced referringexpressions, there are nominal paraphrases reduc-ing a noun phrases like medewerkers van banken?employees of banks?
to a compound word likebankmedewerkers ?bank-employees?.
Likewise,there are adverbial paraphrases such as sinds eenpaar jaar ?since a few years?
to tegenwoordig?nowadays?, and van de afgelopen tijd ?of the pasttime?
to recent ?recent?.
However, the majority ofthe paraphrasing concerns verbs as in the two ex-amples below.
(4) Aut XXneemttakeshettheinitiatiefinitiativetottooprichtingraisingvanofYYSub XXzetsetsYYopup(5) Aut XXomforzijnhisuitleveringextraditionvroegaskedmaarbutYYdiethatweigerderefusedSub YYhemhimnietnotwildewanteduitleverenextraditeaantoXY?Y refused to extradite him to Y?Even though not all paraphrases are actuallyshorter, it seems that at least some of them boostcompression beyond what can be accomplishedwith only word deletion.
In the next Section, welook at the possibilities of automatic extraction ofsuch paraphrases.3.4 Perspectives for automatic paraphraseextractionThere is a growing amount of work on automaticextraction of paraphrases from text corpora (Linand Pantel, 2001; Barzilay and Lee, 2003; Ibrahimet al, 2003; Dolan et al, 2004).
One general pre-requisite for learning a particular paraphrase pat-tern is that it must occur in the text corpus with asufficiently high frequency, otherwise the chancesof learning the pattern are proportionally small.
Inthis section, we investigate to what extent the para-phrases encountered in our random sample of 200pairs can be retrieved from a reasonably large textcorpus.In a first step, we manually extracted 106paraphrase patterns.
We filtered these pat-terns and excluded anaphoric expressions, generalverb alternation patterns like active/passive andcontinuous/non-continuous, as well as verbal pat-terns involving more than two slots.
After this fil-tering step, 59 pairs of paraphrases remained, in-cluding the examples shown in the preceding Sec-tion.The aim was to estimate how big our corpushas to be to cover the majority of these para-phrase pairs.
We started with counting for eachof the paraphrase pairs in our sample how oftenthey occur in a corpus of Dutch news texts, theTwente News Corpus5, which contains approxi-mately 325M tokens and 20M sentences.
We em-ployed regular expressions to count the number ofparaphrase pattern matches.
The corpus turned outto contain 70% percent of all paraphrase pairs (i.e.both patterns in the pair occur at least once).
Wealso counted how many pairs have a frequencies ofat least 10 and 100.
To study the effect of corpussize on the percentage of covered paraphrases, weperformed these counts on 1, 2, 5, 10, 25, 50 and100% of the corpus.
Figure 2 shows the percent-age of covered paraphrases dependent on the cor-pus size.
The most strict threshold that only countspairs that occur at least 100 times in our corpus,does not retrieve any counts on 1% of the corpus(3M words).
At 10% of the corpus size only 4%of the paraphases is found, and on the full data set25% of the pairs is found.For 51% percent of the patterns (with a fre-quency of at least 10) we find substantial evidencein our corpus of 325M tokens.
We fitted a curvethrough our data points, and found a logarithmicline fit with adjusted R2 value of .943.
This sug-gests that in order to get 75% of the patterns, wewould need a corpus that is 18 times bigger thanour current one, which amounts to roughly 6 bil-lion words.
Although this seems like a lot of text,using the WWW as our corpus would easily giveus these numbers.
Today?s estimate of the IndexDutch World Wide Web is 688 million pages6.
Ifwe assume that each page contains at least 100 to-kens on average, this implies a corpus size of 68billion tokens.The patterns used here are word-based and inmany cases they express a particular verb tense orverb form (e.g.
3rd person singular), and wordorder.
This implies that our estimations are theminimum number of matches one can find.
Formore abstract matching, we would need syntacti-cally parsed data (Lin and Pantel, 2001).
We ex-pect that this would also positively affect the cov-erage.5http://www.vf.utwente.nl/?druid/TwNC/TwNC-main.html6http://www.worldwidewebsize.com/index.php?lang=NL, as measured in December200830Figure 2: Percentage of covered paraphrases as afunction of the corpus size4 DiscussionWe found that only 16.11% of 5233 subtitle sen-tences were proper subsequences of the corre-sponding autocue sentence, and therefore 84% cannot be accounted for by a deletion model.
Oneconsequence appears to be that the subsequenceconstraint greatly reduces the amount of avail-able training material for any word deletion model.However, an attempt to rewrite non-subsequencesto semantically equivalent sequences with thesame CR suggests that a deletion model could inprinciple be adequate for 55% of the data.
More-over, in those cases where an application can toler-ate a little slack in the CR, a deletion model mightbe sufficient.
For instance, if we are willing to tol-erate up to two more tokens, we can account for asmuch as 169 (84%) of the 200 non-subsequencesin our sample, which amounts to 87% (16% plus84% of 84%) of the total data.It should be noted that we have been very strictregarding what counts as a semantically equiva-lent subtitle: every piece of information occurringin the non-subsequence subtitle must reoccur inthe sequence subtitle.
However, looking at ouroriginal data, it is clear that considerable libertyis taken as far as conserving semantic content isconcerned: subtitles often drop substantial piecesof information.
If we relax the notion of seman-tic equivalence a little, an even larger part of thenon-subsequences can be rewritten as proper se-quences.The remaining problematic non-subsequencesare those where insertion, substitution and/or wordreordering are essential to obtain a sufficient CR.One of the issues we identified is that deletionof certain constituents must be accompanied by achange in word order to prevent an ungrammati-cal sentence.
Since changes in word order appearto require grammatical modeling or knowledge,this brings sentence compression closer to beingan NLG task.Nguyen and Horiguchi (2003) describe an ex-tension of the decision tree-based compressionmodel (Knight and Marcu, 2002) which allows forword order changes.
The key to their approachis that dropped constituents are temporarily storedon a deletion stack, from which they can later bere-inserted in the tree where required.
Althoughthis provides an unlimited freedom for rearrangingconstituents, it also complicates the task of learn-ing the parsing steps, which might explain whytheir evaluation results show marginal improve-ments at best.In our data, most of the word order changes ap-pear to be minor though, often only moving theverb to second position after deleting a constituentin the topic position.
We believe that unrestrictedword order changes are perhaps not necessary andthat the vast majority of the word order problemscan be solved by a fairly restricted way of reorder-ing.
In particular, we plan to implement a parser-based model with an additional swap operationthat swaps the two topmost items on the stack.
Weexpect that this is more feasible as a learning taskthan a model with a deletion stack.Apart from reordering, other problems for worddeletion models are the insertions and substitu-tions as a result of paraphrasing.
Within a deci-sion tree-based model, paraphrasing of words orcontinuous phrases may be modeled by a combi-nation of a paraphrase lexicon and an extra opera-tion which replaces the n topmost elements on thestack by the corresponding paraphrase.
However,paraphrases involving variable arguments, as typ-ical for verbal paraphrases, cannot be accountedfor in this way.
More powerful compression mod-els may draw on existing NLG methods for textrevision (Inui et al, 1992) to accommodate fullparaphrasing.We also looked at the perspectives for auto-matic paraphrase extraction from large text cor-pora.
About a quarter of the required paraphrasepatterns was found at least a hundred times in ourcorpus of 325M tokens.
Extrapolation suggeststhat using the web at its current size would give usa coverage of approximately ten counts for three31quarters of the paraphrases.Incidentally, we identified two other tasks inautomatic subtitling which are closely related toNLG.
First, splitting and merging of sentences(Jing and McKeown, 2000), which seems relatedto content planning and aggregation.
Second, gen-eration of a shorter referring expression or ananaphoric expression, which is currently one ofthe main themes in data-driven NLG.In conclusion, we have presented evidence thatdeletion models for sentence compression are notsufficient, and that more elaborate models in-volving reordering and paraphrasing are required,which puts sentence compression in the field ofNLG.AcknowledgmentsWe would like to thank Nienke Eckhardt, Paul van Pelt, Han-neke Schoormans and Jurry de Vos for the corpus annota-tion work, and Erik Tsjong Kim Sang and colleagues for theautocue-subtitle material from the ATRANOS project, andMartijn Goudbeek for help with curve fitting.
This work wasconducted within the DAESO project funded by the Stevinprogram (De Nederlandse Taalunie).ReferencesRegina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: an unsupervised approach using multiple-sequence alignment.
In Proceedings of the 2003 Confer-ence of the North American Chapter of the Association forComputational Linguistics on Human Language Technol-ogy, pages 16?23, Morristown, NJ, USA.Anja Belz and Ehud Reiter.
2006.
Comparing automatic andhuman evaluation of NLG systems.
In Proceedings of the11th Conference of the European Chapter of the Associa-tion for Computational Linguistics, pages 313?320.James Clarke and Mirella Lapata.
2006.
Models for sentencecompression: a comparison across domains, training re-quirements and evaluation measures.
In Proceedings ofthe 21st International Conference on Computational Lin-guistics and the 44th annual meeting of the Association forComputational Linguistics, pages 377?384, Morristown,NJ, USA.James Clarke and Mirella Lapata.
2008.
Global inferencefor sentence compression an integer linear programmingapproach.
Journal of Artificial Intelligence Research,31:399?429.Simon Corston-Oliver.
2001.
Text compaction for displayon very small screens.
In Proceedings of the Workshopon Automatic Summarization (WAS 2001), pages 89?98,Pittsburgh, PA, USA.Walter Daelemans, Anita Ho?thker, and Erik Tjong Kim Sang.2004.
Automatic sentence simplification for subtitling inDutch and English.
In Proceedings of the 4th Interna-tional Conference on Language Resources and Evalua-tion, pages 1045?1048.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.
Unsuper-vised construction of large paraphrase corpora: Exploitingmassively parallel news sources.
In Proceedings of the20th International Conference on Computational Linguis-tics, pages 350?356, Morristown, NJ, USA.Ali Ibrahim, Boris Katz, and Jimmy Lin.
2003.
Extract-ing structural paraphrases from aligned monolingual cor-pora.
In Proceedings of the 2nd International Work-shop on Paraphrasing, volume 16, pages 57?64, Sapporo,Japan.Kentaro Inui, Takenobu Tokunaga, and Hozumi Tanaka.1992.
Text Revision: A Model and Its Implementation.In Proceedings of the 6th International Workshop on Nat-ural Language Generation: Aspects of Automated NaturalLanguage Generation, pages 215?230.
Springer-VerlagLondon, UK.Hongyan Jing and Kathleen McKeown.
2000.
Cut and pastebased text summarization.
In Proceedings of the 1st Con-ference of the North American Chapter of the Associationfor Computational Linguistics, pages 178?185, San Fran-cisco, CA, USA.Kevin Knight and Daniel Marcu.
2002.
Summarization be-yond sentence extraction: A probabilistic approach to sen-tence compression.
Artificial Intelligence, 139(1):91?107.Nguyen Minh Le and Susumu Horiguchi.
2003.
A New Sen-tence Reduction based on Decision Tree Model.
In Pro-ceedings of the 17th Pacific Asia Conference on Language,Information and Computation, pages 290?297.Dekang Lin and Patrick Pantel.
2001.
Discovery of infer-ence rules for question answering.
Natural Language En-gineering, 7(4):343?360.Chin-Yew Lin.
2003.
Improving summarization perfor-mance by sentence compression - A pilot study.
In Pro-ceedings of the Sixth International Workshop on Informa-tion Retrieval with Asian Languages, volume 2003, pages1?9.Erwin Marsi and Emiel Krahmer.
2007.
Annotating a par-allel monolingual treebank with semantic similarity re-lations.
In Proceedings of the 6th International Work-shop on Treebanks and Linguistic Theories, pages 85?96,Bergen, Norway.Jenine Turner and Eugene Charniak.
2005.
Supervised andunsupervised learning for sentence compression.
In Pro-ceedings of the 43rd Annual Meeting of the Associationfor Computational Linguistics, pages 290?297, Ann Ar-bor, Michigan, June.Vincent Vandeghinste and Yi Pan.
2004.
Sentence com-pression for automated subtitling: A hybrid approach.
InProceedings of the ACL Workshop on Text Summarization,pages 89?95.Vincent Vandeghinste and Erik Tsjong Kim Sang.
2004.Using a Parallel Transcript/Subtitle Corpus for SentenceCompression.
In Proceedings of LREC 2004.David Zajic, Bonnie J. Dorr, Jimmy Lin, and RichardSchwartz.
2007.
Multi-candidate reduction: Sentencecompression as a tool for document summarization tasks.Information Processing Management, 43(6):1549?1570.32
