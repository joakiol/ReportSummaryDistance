Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1360?1365,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsChinese Zero Pronoun Resolution: Some Recent AdvancesChen Chen and Vincent NgHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson, TX 75083-0688{yzcchen,vince}@hlt.utdallas.eduAbstractWe extend Zhao and Ng's (2007) Chineseanaphoric zero pronoun resolver by (1) usinga richer set of features and (2) exploiting thecoreference links between zero pronouns dur-ing resolution.
Results on OntoNotes showthat our approach significantly outperformstwo state-of-the-art anaphoric zero pronoun re-solvers.
To our knowledge, this is the firstwork to report results obtained by an end-to-end Chinese zero pronoun resolver.1 IntroductionA zero pronoun (ZP) is a gap in a sentence that isfound when a phonetically null form is used to referto a real-world entity.
An anaphoric zero pronoun(AZP) is a ZP that corefers with one or more preced-ing noun phrases (NPs) in the associated text.
Un-like overt pronouns, ZPs lack grammatical attributesthat are useful for overt pronoun resolution such asnumber and gender.
This makes ZP resolution morechallenging than overt pronoun resolution.We aim to improve the state of the art in ChineseAZP resolution by proposing two extensions.
First,while previous approaches to this task have primarilyfocused on employing positional and syntactic fea-tures (e.g., Zhao and Ng (2007) [Z&N], Kong andZhou (2010) [K&Z]), we exploit a richer set of fea-tures for capturing the context of an AZP and itscandidate antecedents.
Second, to alleviate the diffi-culty of resolving an AZP to an antecedent far awayfrom it, we break down the process into smaller, in-termediate steps, where we allow coreference linksbetween AZPs to be established.We apply our two extensions to a state-of-the-artChinese AZP resolver proposed by Z&N and eval-uate the resulting resolver on the OntoNotes cor-pus.
Experimental results show that this resolver sig-nificantly outperforms both Z&N's resolver and an-other state-of-the-art resolver proposed by K&Z.
Itis worth noting that while previous work on ChineseZP resolution has reported results obtained via goldinformation (e.g., using gold AZPs and extractingcandidate antecedents and other features from goldsyntactic parse trees), this is the first work to reportthe results of an end-to-end Chinese ZP resolver.The rest of this paper is organized as follows.
Sec-tion 2 describes the two baselineAZP resolvers.
Sec-tions 3 and 4 discuss our two extensions.
We presentour evaluation results in Section 5 and our conclu-sions in Section 6.2 Baseline AZP Resolution SystemsAn AZP resolution algorithm takes as input a setof AZPs produced by an AZP identification system.Below we first describe the AZP identifier we em-ploy, followed by our two baseline AZP resolvers.2.1 Anaphoric Zero Pronoun IdentificationWe employ two steps to identifyAZPs.
In the extrac-tion step, we heuristically extract candidate ZPs.
Inthe classification step, we train a classifier to distin-guish AZPs from non-AZPs.To implement the extraction step, we use Z&N'sand K&Z's observation: ZPs can only occur before aVP node in a syntactic parse tree.
However, accord-ing to K&Z, ZPs do not need to be extracted fromevery VP: if a VP node occurs in a coordinate struc-ture or is modified by an adverbial node, then only itsparent VP node needs to be considered.
We extractZPs from all VPs that satisfy the above constraints.1360Syntacticfeatures(13)whether z is the first gap in an IP clause; whether z is the first gap in a subject-less IP clause, and ifso, POS(w1); whether POS(w1) is NT; whether t1 is a verb that appears in a NP or VP; whether Pl isa NP node; whether Pr is a VP node; the phrasal label of the parent of the node containing POS(t1);whether V has a NP, VP or CP ancestor; whether C is a VP node; whether there is a VP node whoseparent is an IP node in the path from t1 to C.Lexicalfeatures(13)the words surrounding z and/or their POS tags, including w1, w?1, POS(w1), POS(w?1)+POS(w1),POS(w1)+POS(w2), POS(w?2)+POS(w?1), POS(w1)+POS(w2)+POS(w3), POS(w?1)+w1, andw?1+POS(w1); whether w1 is a transitive verb, an intransitive verb or a preposition; whether w?1 isa transitive verb without an object.Other fea-tures (6)whether z is the first gap in a sentence; whether z is in the headline of the text; the type of the clause inwhich z appears; the grammatical role of z; whether w?1 is a punctuation; whether w?1 is a comma.Table 1: Features for AZP identification.
z is a zero pronoun.
V is the VP node following z. wi is the ith word to theright of z (if i is positive) or the ith word to the left of z (if i is negative).
C is lowest common ancestor of w?1 andw1.
Pl and Pr are the child nodes of C that are the ancestors of w?1 and w1 respectively.Featuresbetween aand z (4)the sentence distance between a and z; the segment distance between a and z, where segments areseparated by punctuations; whether a is the closest NP to z; whether a and z are siblings in theassociated parse tree.Featureson a (12)whether a has an ancestor NP, and if so, whether this NP is a descendent of a's lowest ancestor IP;whether a has an ancestor VP, and if so, whether this VP is a descendent of a's lowest ancestor IP;whether a has an ancestor CP; the grammatical role of a; the clause type in which a appears; whethera is an adverbial NP, a temporal NP, a pronoun or a named entity; whether a is in the headline of thetext.Featureson z (10)whether V has an ancestor NP, and if so, whether this NP node is a descendent of V's lowest ancestorIP; whether V has an ancestor VP, and if so, whether this VP is a descendent of V's lowest ancestor IP;whether V has an ancestor CP; the grammatical role of z; the type of the clause in which V appears;whether z is the first or last ZP of the sentence; whether z is in the headline of the text.Table 2: Features for AZP resolution in the Zhao and Ng (2007) baseline system.
z is a zero pronoun.
a is a candidateantecedent of z. V is the VP node following z in the parse tree.To implement the classification step, we train aclassifier using SVMlight (Joachims, 1999) to distin-guishAZPs from non-AZPs.
We employ 32 features,13 of which were proposed by Z&N and 19 of whichwere proposed by Yang and Xue (2010).
A brief de-scription of these features can be found in Table 1.2.2 Two Baseline AZP ResolversThe Zhao and Ng (2007) [Z&N] baseline.
Inour implementation of the Z&N baseline, we useSVMlight to train amention-pairmodel for determin-ing whether an AZP z and a candidate antecedentof z are coreferent.
We consider all NPs preced-ing z that do not have the same head as its parentNP in the parse tree to be z's candidate antecedents.We use Soon et als (2001) method to create train-ing instances: we create a positive instance betweenan AZP, z, and its closest overt antecedent, and wecreate a negative instance between z and each of theintervening candidates.
Each instance is representedby the 26 features employed by Z&N.
A brief de-scription of these features can be found in Table 2.During testing, we adopt the closest-first resolutionstrategy, resolving an AZP to the closest candidateantecedent that is classified as coreferent with it.1The Kong and Zhou (2010) [K&Z] baseline.K&Z employ a tree kernel-based approach to AZPresolution.
Like Z&N, K&Z (1) train a mention-pair model for determining whether an AZP z anda candidate antecedent of z are coreferent, (2) useSoon et als method to create training instances, and(3) resolve an AZP to its closest coreferent can-didate antecedent.
Unlike Z&N, however, K&Zuse the SVMlight?TK learning algorithm (Moschitti,1When resolving a goldAZP z, if none of the preceding can-didate antecedents is classified as coreferent with it, we resolveit to the candidate that has the highest coreference likelihoodwith it.
Here, we employ the signed distance from the SVMhyperplane to measure the coreference likelihood.13612006) to train their model, employing a parse sub-tree known as a dynamic expansion tree (Zhou et al2008) as a structured feature to represent an instance.3 Extension 1: Novel FeaturesWe propose three kinds of features to better capturethe context of an AZP, as described below.Antecedent compatibility.
AZPs are omitted sub-jects that precede VP nodes in a sentence's parsetree.
From the VP node, we can extract its head verb(Predz) and the head of its object NP (Obj), if any.Note that Predz and Obj contain important contex-tual information for an AZP.Next, observe that if a NP is coreferent with anAZP, it should be able to fill the AZP's gap and becompatible with the gap's context.
Consider the fol-lowing example:E1: ??????????????
?pro????????????????
(They are trying that service.
That means ?pro?hope that our visitors can try it when they come inSeptember.
)The head of the VP following ?pro?
is ??(hope).
There are two candidate antecedents, ??
(They) and ????
(that service).
If we try us-ing them to fill this AZP's gap, we know based onselectional preferences that ????
(They hope)makes more sense than??????
(that servicehope).
We supply the AZP resolver with the fol-lowing information to help it make these decisions.First, we find the head word of each candidate an-tecedent, Headc.
Then we form two strings, Headc+ Predz and Headc + Predz + Obj (if the objectof the VP is present).
Finally, we employ them as bi-nary lexical features, setting their feature values to 1if and only if they can be extracted from the instanceunder consideration.
The training data can be usedto determine which of these features are useful.2Narrative event chains.
A narrative event chain isa partially ordered set of events related by a commonprotagonist (Chambers and Jurafsky, 2008).
For ex-ample, we can infer from the chain "borrow-s invest-s spend-s lend-s" that a person who borrows (pre-2We tried to apply Kehler et als (2004) and Yang etal.
's (2005) methods to learn Chinese selectional preferencesfrom unlabeled data, but without success.sumably money) can invest it, spend it, or lend it toother people.3 Consider the following example:E2: ???????pro?????????????????
(The country gives our department money, but all?pro?
provides is exactly what we worked for.
)In E2, ?pro?
is coreferent with ??
(The coun-try), and the presence of the narrative event chain????
(gives?provides) suggests that the subjectsof the two events are likely to be coreferent.However, given the unavailability of induced orhand-crafted narrative chains in Chinese4, we makethe simplifying assumption that two verbs form alexical chain if they are lexically identical.5 Wecreate two features to exploit narrative event chainsfor a candidate NP, c, if it serves as a subject orobject.
Specifically, let the verb governing c bePredc.
The first feature, which encodes whethernarrative chains are present, has three possible val-ues: 0 if Predc and Predz are not the same; 1 ifPredc and Predz are the same and c is a subject;and 2 if Predc and Predz are the same and c is anobject.
The second feature is a binary lexical fea-ture, Predc+Predz+Subject/Object; its value is1 if and only if Predc, Predz , and Subject/Objectcan be found in the associated instance, whereSubject/Object denotes the grammatical role of c.Final punctuation hint.
We observe that the punc-tuation (Punc) at the end of a sentence where anAZP occurs also provides contextual information,especially in conversation documents.
In conversa-tions, if a sentence containing an AZP ends with a3"-s" denotes the fact that the protagonist serves as the gram-matical subject in these events.4We tried to construct narrative chains for Chinese usingboth learning-based and dictionary-based methods.
Specifi-cally, we induced narrative chains using Chambers and Juraf-sky's (2008) method, but were not successful owing to the lackof an accurate Chinese coreference resolver.
In addition, weconstructed narrative chains using both lexically identical verbsand the synonyms obtained from a WordNet-like Chinese re-source called Tongyicicilin, but they did not help improve reso-lution performance.5Experiments on the training data show that if an AZP anda candidate antecedent are subjects of (different occurrences of)the same verb, then the probability that the candidate antecedentis coreferent with the AZP is 0.703.
This result suggests that ourassumption, though somewhat simplistic, is useful as far as AZPresolution is concerned.1362A:?????????
(A: How is her life now?
)B: ?pro1???????????????
(B: ?pro1?
attitude toward life is plain and simple.)A:??
(A: Yes.
)A: ?pro2???????????
(A: ?pro2?
is living in Beijing or the USA?
)B: ?pro3?????
(B: ?pro3?
is living in the USA.
)Figure 1: An illustrative example.question mark, the mention this AZP refers to is lesslikely to be the speaker himself6, as illustrated in thefollowing example:E3: ??
?pro????
(Are ?pro?
cold in the winter?
)Here, ?pro?
refers to the person the speaker talkswith.
To capture this information, we create a binarylexical feature, Headc+Punc, whose value is 1 ifand only if Headc and Punc appear in the instanceunder consideration.4 Extension 2: Zero Pronoun Links4.1 MotivationLike an overt pronoun, a ZP whose closest overtantecedent is far away from it is harder to resolvethan one that has a nearby overt antecedent.
How-ever, a corpus study of our training data reveals thatonly 55.2% of the AZPs appear in the same sentenceas their closest overt antecedent, and 22.7% of theAZPs appear two or more sentences away from theirclosest overt antecedent.Fortunately, we found that some of the difficult-to-resolve AZPs (i.e., AZPs whose closest overt an-tecedents are far away from them) are coreferentialwith nearby ZPs.
Figure 1, which consists of a set ofsentences from a conversation, illustrates this phe-nomenon.
There are three AZPs (denoted by ?proi?,where 1 ?
i ?
3), all of which refer to the overtpronoun ?
(She) in the first sentence.
In this ex-ample, it is fairly easy to resolve ?pro1?
correctly,6One may wonder whether we can similarly identify con-straints on the antecedents of a ZP from clause conjunctions.Our preliminary analysis suggests that the answer is no.Training TestDocuments 1,391 172Sentences 36,487 6,083Words 756,063 110,034ZPs 23,065 3,658AZPs 12,111 1,713Table 3: Statistics on the training and test sets.since its antecedent is the subject of previous sen-tence.
However, ?pro3?
and its closest overt an-tecedent?
(She) are four sentences apart.
Togetherwith the fact that there are many intervening candi-date antecedents, it is not easy for a resolver to cor-rectly resolve ?pro3?.To facilitate the resolution of ?pro3?
and difficult-to-resolve AZPs in general, we propose the follow-ing idea.
We allow an AZP resolver to (1) establishcoreferent links between two consecutive ZPs (i.e.,?pro1???pro2?
and ?pro2???pro3?
in our exam-ple), which are presumably easy to establish becausethe two AZPs involved are close to each other; andthen (2) treat them as bridges and infer that ?pro3?
'sovert antecedent is?
(She).4.2 Modified Resolution AlgorithmWe implement the aforementioned idea by modify-ing the AZP resolver as follows.
Whenwe resolve anAZP z during testing, we augment the set of candi-date antecedents for z with the set of AZPs precedingz.
Since we have only specified how to compute fea-tures for instances composed of an AZP and an overtcandidate antecedent thus far (see Section 2.2), thequestion, then, is: how can we compute features forinstances composed of two AZPs?To answer this question, we first note that theAZPs in a test text are resolved in a left-to-right man-ner.
Hence, by the time we resolve an AZP z, all theAZPs preceding z have been resolved.
Hence, whenwe create a test instance i between z and one of thepreceding AZPs (say y), we create i as if the gap ywas filled with the smallest tree embedding the NPto which y was resolved.By allowing coreference links between (presum-ably nearby) ZPs to be established, we can reasonover the resulting coreference links, treating them asbridges that can help us find an overt antecedent thatis far away from an AZP.1363Gold AZP System AZP System AZPGold Parse Tree Gold Parse Tree System Parse TreeSystem Variation R P F R P F R P FK&Z Baseline System 38.0 38.0 38.0 17.7 22.4 19.8 10.6 13.6 11.9Z&N Baseline System 41.5 41.5 41.5 22.4 24.4 23.3 12.7 14.2 13.4Z&N Baseline + Contextual Features 46.2 46.2 46.2 25.2 27.5 26.3 14.4 16.1 15.2Z&N Baseline + Zero Pronoun Links 42.7 42.7 42.7 22.5 24.6 23.5 13.2 14.8 13.9Full System 47.7 47.7 47.7 25.3 27.6 26.4 14.9 16.7 15.7Table 4: Resolution results on the test set.5 Evaluation5.1 Experimental SetupDataset.
For evaluation, we employ the portion oftheOntoNotes 4.0 corpus that was used in the officialCoNLL-2012 shared task.
The shared task dataset iscomposed of a training set, a development set, anda test set.
Since only the training set and the de-velopment set are annotated with ZPs, we use thetraining set for classifier training and reserve the de-velopment set for testing purposes.
Statistics on thedatasets are shown in Table 3.
In these datasets, a ZPis marked as ?pro?.
We consider a ZP anaphoric ifit is coreferential with a preceding ZP or overt NP.Evaluation measures.
We express the results ofboth AZP identification and AZP resolution in termsof recall (R), precision (P) and F-score (F).5.2 Results and DiscussionThe three major columns of Table 4 show the re-sults obtained in three settings, which differ interms of whether gold/system AZPs and manu-ally/automatically constructed parse trees are used toextract candidate antecedents and features.In the first setting, the resolvers are provided withgold AZPs and gold parse trees.
Results are shown incolumn 1.
As we can see, the Z&N baseline signifi-cantly outperforms the K&Z baseline by 3.5% in F-score.7 Adding the contextual features, the ZP links,and both extensions to Z&N increase its F-score sig-nificantly by 4.7%, 1.2% and 6.2%, respectively.In the next two settings, the resolvers operate onthe system AZPs provided by the AZP identificationcomponent.
When gold parse trees are employed,the recall, precision and F-score of AZP identifica-tion are 50.6%, 55.1% and 52.8% respectively.
Col-umn 2 shows the results of the resolvers obtained7All significance tests are paired t-tests, with p < 0.05.when these automatically identified AZPs are used.As we can see, Z&N again significantly outperformsK&Z by 3.5% in F-score.
Adding the contextual fea-tures, the ZP links, and both extensions to Z&N in-crease its F-score by 3.0%, 0.2% and 3.1%, respec-tively.
The system with contextual features and thefull system both yield results that are significantlybetter than those of the Z&N baseline.
A closer ex-amination of the results reveals why the ZP links arenot effective in improving performance: when em-ploying systemAZPs, many erroneous ZP linkswereintroduced to the system.Column 3 shows the results of the resolvers whenwe employ system AZPs and the automatically gen-erated parse trees provided by the CoNLL-2012shared task organizers to compute candidate an-tecedents and features.
Hence, these are end-to-endZP resolution results.
To our knowledge, these arethe first reported results on end-to-end Chinese ZPresolution.
Using automatic parse trees, the perfor-mance on AZP identification drops to 30.8% (R),34.4% (P) and 32.5% (F).
In this setting, Z&N stilloutperforms K&Z significantly, though by a smallermargin when compared to the previous settings.
In-corporating the contextual features, the ZP links, andboth extensions increase the F-score by 1.8%, 0.5%and 2.3%, respectively.
The system with contextualfeatures and the full system both yield results that aresignificantly better than those of the Z&N baseline.6 ConclusionsWe proposed two extensions to a state-of-the-art Chinese AZP resolver proposed by Zhao andNg (2007).
Experimental results on the OntoNotesdataset showed that the resulting resolver signifi-cantly improved both Zhao and Ng's and Kong andZhou's (2010) resolvers, regardless of whether goldor system AZPs and syntactic parse trees are used.1364AcknowledgmentsWe thank the three anonymous reviewers for theirdetailed and insightful comments on an earlier draftof the paper.
This work was supported in part byNSF Grants IIS-1147644 and IIS-1219142.
Anyopinions, findings, conclusions or recommendationsexpressed in this paper are those of the authors anddo not necessarily reflect the views or official poli-cies, either expressed or implied, of NSF.ReferencesNathanael Chambers and Dan Jurafsky.
2008.
Unsu-pervised learning of narrative event chains.
In Pro-ceedings of the 46th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, pages 787--797.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Bernhard Scholkopf and Alexan-der Smola, editors, Advances in Kernel Methods - Sup-port Vector Learning, pages 44--56.
MIT Press.Andrew Kehler, Douglas Appelt, Lara Taylor, and Alek-sandr Simma.
2004.
Competitive self-trained pronouninterpretation.
In Proceedings of HLT-NAACL 2004:Short Papers, pages 33--36.Fang Kong and Guodong Zhou.
2010.
A tree kernel-based unified framework for Chinese zero anaphoraresolution.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing,pages 882--891.Alessandro Moschitti.
2006.
Making tree kernels prac-tical for natural language processing.
In Proceedingsof the 11th Conference of the European Chapter of theAssociation for Computational Linguistics, pages 113--120.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to corefer-ence resolution of noun phrases.
Computational Lin-guistics, 27(4):521--544.Yaqin Yang and Nianwen Xue.
2010.
Chasing the ghost:recovering empty categories in the Chinese Treebank.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters, pages 1382--1390.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2005.
Im-proving pronoun resolution using statistics-based se-mantic compatibility information.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics, pages 165--172.Shanheng Zhao and Hwee Tou Ng.
2007.
Identificationand resolution of Chinese zero pronouns: A machinelearning approach.
In Proceedings of the 2007 JointConference on Empirical Methods on Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 541--550.GuoDong Zhou, Fang Kong, and Qiaoming Zhu.
2008.Context-sensitive convolution tree kernel for pronounresolution.
In Proceedings of the 3rd InternationalJoint Conference on Natural Language Processing,pages 25--31.1365
