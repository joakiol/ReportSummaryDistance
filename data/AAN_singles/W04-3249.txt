Unsupervised Domain Relevance Estimationfor Word Sense DisambiguationAlfio Gliozzo and Bernardo Magnini and Carlo StrapparavaITC-irst, Istituto per la Ricerca Scientica e Tecnologica, I-38050 Trento, ITALY{gliozzo, magnini, strappa}@itc.itAbstractThis paper presents Domain Relevance Estima-tion (DRE), a fully unsupervised text categorizationtechnique based on the statistical estimation of therelevance of a text with respect to a certain cate-gory.
We use a pre-defined set of categories (wecall them domains) which have been previously as-sociated to WORDNET word senses.
Given a cer-tain domain, DRE distinguishes between relevantand non-relevant texts by means of a Gaussian Mix-ture model that describes the frequency distributionof domain words inside a large-scale corpus.
Then,an Expectation Maximization algorithm computesthe parameters that maximize the likelihood of themodel on the empirical data.The correct identification of the domain of thetext is a crucial point for Domain Driven Dis-ambiguation, an unsupervised Word Sense Disam-biguation (WSD) methodology that makes use ofonly domain information.
Therefore, DRE has beenexploited and evaluated in the context of a WSDtask.
Results are comparable to those of state-of-the-art unsupervised WSD systems and show thatDRE provides an important contribution.1 IntroductionA fundamental issue in text processing and under-standing is the ability to detect the topic (i.e.
the do-main) of a text or of a portion of it.
Indeed, domaindetection allows a number of useful simplificationsin text processing applications, such as, for instance,in Word Sense Disambiguation (WSD).In this paper we introduce Domain Relevance Es-timation (DRE) a fully unsupervised technique fordomain detection.
Roughly speaking, DRE can beviewed as a text categorization (TC) problem (Se-bastiani, 2002), even if we do not approach theproblem in the standard supervised setting requir-ing category labeled training data.
In fact, recently,unsupervised approaches to TC have received moreand more attention in the literature (see for example(Ko and Seo, 2000).We assume a pre-defined set of categories, eachdefined by means of a list of related terms.
Wecall such categories domains and we consider themas a set of general topics (e.g.
SPORT, MEDICINE,POLITICS) that cover the main disciplines and ar-eas of human activity.
For each domain, the listof related words is extracted from WORDNET DO-MAINS (Magnini and Cavaglia`, 2000), an extensionof WORDNET in which synsets are annotated withdomain labels.
We have identified about 40 domains(out of 200 present in WORDNET DOMAINS) andwe will use them for experiments throughout the pa-per (see Table 1).DRE focuses on the problem of estimating a de-gree of relatedness of a certain text with respect tothe domains in WORDNET DOMAINS.The basic idea underlying DRE is to combine theknowledge in WORDNET DOMAINS and a proba-bilistic framework which makes use of a large-scalecorpus to induce domain frequency distributions.Specifically, given a certain domain, DRE considersfrequency scores for both relevant and non-relevanttexts (i.e.
texts which introduce noise) and representthem by means of a Gaussian Mixture model.
Then,an Expectation Maximization algorithm computesthe parameters that maximize the likelihood of theempirical data.DRE methodology originated from the effort toimprove the performance of Domain Driven Dis-ambiguation (DDD) system (Magnini et al, 2002).DDD is an unsupervised WSD methodology thatmakes use of only domain information.
DDD as-signes the right sense of a word in its context com-paring the domain of the context to the domain ofeach sense of the word.
This methodology exploitsWORDNET DOMAINS information to estimate bothDomain #Syn Domain #Syn Domain #SynFactotum 36820 Biology 21281 Earth 4637Psychology 3405 Architecture 3394 Medicine 3271Economy 3039 Alimentation 2998 Administration 2975Chemistry 2472 Transport 2443 Art 2365Physics 2225 Sport 2105 Religion 2055Linguistics 1771 Military 1491 Law 1340History 1264 Industry 1103 Politics 1033Play 1009 Anthropology 963 Fashion 937Mathematics 861 Literature 822 Engineering 746Sociology 679 Commerce 637 Pedagogy 612Publishing 532 Tourism 511 Computer Science 509Telecommunication 493 Astronomy 477 Philosophy 381Agriculture 334 Sexuality 272 Body Care 185Artisanship 149 Archaeology 141 Veterinary 92Astrology 90Table 1: Domain distribution over WORDNET synsets.the domain of the textual context and the domain ofthe senses of the word to disambiguate.
The formeroperation is intrinsically an unsupervised TC task,and the category set used has to be the same usedfor representing the domain of word senses.Since DRE makes use of a fixed set of target cat-egories (i.e.
domains) and since a document col-lection annotated with such categories is not avail-able, evaluating the performance of the approach isa problem in itself.
We have decided to perform anindirect evaluation using the DDD system, whereunsupervised TC plays a crucial role.The paper is structured as follows.
Section 2introduces WORDNET DOMAINS, the lexical re-source that provides the underlying knowledge tothe DRE technique.
In Section 3 the problem of es-timating domain relevance for a text is introduced.In particular, Section 4 briefly sketchs the WSD sys-tem used for evaluation.
Finally, Section 5 describesa number of evaluation experiments we have carriedout.2 Domains, WORDNET and TextsDRE heavily relies on domain information as itsmain knowledge source.
Domains show interestingproperties both from a lexical and a textual point ofview.
Among these properties there are: (i) lexi-cal coherence, since part of the lexicon of a text iscomposed of words belonging to the same domain;(ii) polysemy reduction, because the potential am-biguity of terms is sensibly lower if the domain ofthe text is specified; and (iii) lexical identifiabilityof text?s domain, because it is always possible to as-sign one or more domains to a given text by consid-ering term distributions in a bag-of-words approach.Experimental evidences of these properties are re-ported in (Magnini et al, 2002).In this section we describe WORDNET DO-MAINS1 (Magnini and Cavaglia`, 2000), a lexical re-source that attempts a systematization of relevantaspects in domain organization and representation.WORDNET DOMAINS is an extension of WORD-NET (version 1.6) (Fellbaum, 1998), in which eachsynset is annotated with one or more domain la-bels, selected from a hierarchically organized set ofabout two hundred labels.
In particular, issues con-cerning the ?completeness?
of the domain set, the?balancing?
among domains and the ?granularity?of domain distinctions, have been addressed.
Thedomain set used in WORDNET DOMAINS has beenextracted from the Dewey Decimal Classification(Comaroni et al, 1989), and a mapping between thetwo taxonomies has been computed in order to en-sure completeness.
Table 2 shows how the sensesfor a word (i.e.
the noun bank) have been associatedto domain label; the last column reports the numberof occurrences of each sense in Semcor2.Domain labeling is complementary to informa-tion already present in WORDNET.
First of all,a domain may include synsets of different syn-tactic categories: for instance MEDICINE groupstogether senses from nouns, such as doctor#1and hospital#1, and from verbs, such asoperate#7.
Second, a domain may includesenses from different WORDNET sub-hierarchies(i.e.
deriving from different ?unique beginners?
orfrom different ?lexicographer files?).
For example,SPORT contains senses such as athlete#1, deriv-ing from life form#1, game equipment#1from physical object#1, sport#11WORDNET DOMAINS is freely available athttp://wndomains.itc.it2SemCor is a portion of the Brown corpus in which wordsare annotated with WORDNET senses.Sense Synset and Gloss Domains Semcor frequencies#1 depository financial institution, bank, banking con-cern, banking company (a financial institution.
.
.
)ECONOMY 20#2 bank (sloping land.
.
. )
GEOGRAPHY, GEOLOGY 14#3 bank (a supply or stock held in reserve.
.
. )
ECONOMY -#4 bank, bank building (a building.
.
. )
ARCHITECTURE, ECONOMY -#5 bank (an arrangement of similar objects...) FACTOTUM 1#6 savings bank, coin bank, money box, bank (a con-tainer.
.
.
)ECONOMY -#7 bank (a long ridge or pile.
.
. )
GEOGRAPHY, GEOLOGY 2#8 bank (the funds held by a gambling house.
.
. )
ECONOMY, PLAY#9 bank, cant, camber (a slope in the turn of a road.
.
. )
ARCHITECTURE -#10 bank (a flight maneuver.
.
. )
TRANSPORT -Table 2: WORDNET senses and domains for the word ?bank?.from act#2, and playing field#1 fromlocation#1.Domains may group senses of the same wordinto thematic clusters, which has the important side-effect of reducing the level of ambiguity when weare disambiguating to a domain.
Table 2 showsan example.
The word ?bank?
has ten differ-ent senses in WORDNET 1.6: three of them (i.e.bank#1, bank#3 and bank#6) can be groupedunder the ECONOMY domain, while bank#2 andbank#7 both belong to GEOGRAPHY and GEOL-OGY.
Grouping related senses is an emerging topicin WSD (see, for instance (Palmer et al, 2001)).Finally, there are WORDNET synsets that do notbelong to a specific domain, but rather appear intexts associated with any domain.
For this reason,a FACTOTUM label has been created that basicallyincludes generic synsets, which appear frequentlyin different contexts.
Thus the FACTOTUM domaincan be thought of as a ?placeholder?
for all otherdomains.3 Domain Relevance Estimation for TextsThe basic idea of domain relevance estimation fortexts is to exploit lexical coherence inside texts.From the domain point of view lexical coherenceis equivalent to domain coherence, i.e.
the fact thata great part of the lexicon inside a text belongs tothe same domain.From this observation follows that a simpleheuristic to approach this problem is counting theoccurrences of domain words for every domain in-side the text: the higher the percentage of domainwords for a certain domain, the more relevant thedomain will be for the text.
In order to perform thisoperation the WORDNET DOMAINS information isexploited, and each word is assigned a weighted listof domains considering the domain annotation ofits synsets.
In addition, we would like to estimatethe domain of the text locally.
Local estimationof domain relevance is very important in order totake into account domain shifts inside the text.
Themethodology used to estimate domain frequency isdescribed in subsection 3.1.Unfortunately the simple local frequency countis not a good domain relevance measure for sev-eral reasons.
The most significant one is that veryfrequent words have, in general, many senses be-longing to different domains.
When words are usedin texts, ambiguity tends to disappear, but it is notpossible to assume knowing their actual sense (i.e.the sense in which they are used in the context) inadvance, especially in a WSD framework.
The sim-ple frequency count is then inadequate for relevanceestimation: irrelevant senses of ambiguous wordscontribute to augment the final score of irrelevantdomains, introducing noise.
The level of noise isdifferent for different domains because of their dif-ferent sizes and possible differences in the ambigu-ity level of their vocabularies.In subsection 3.2 we propose a solution for thatproblem, namely the Gaussian Mixture (GM) ap-proach.
This constitutes an unsupervised way to es-timate how to differentiate relevant domain infor-mation in texts from noise, because it requires onlya large-scale corpus to estimate parameters in anExpectation Maximization (EM) framework.
Usingthe estimated parameters it is possible to describethe distributions of both relevant and non-relevanttexts, converting the DRE problem into the problemof estimating the probability of each domain givenits frequency score in the text, in analogy to thebayesian classification framework.
Details aboutthe EM algorithm for GM model are provided insubsection 3.3.3.1 Domain Frequency ScoreLet t ?
T , be a text in a corpus T composed by a listof words wt1, .
.
.
, wtq .
Let D = {D1, D2, ..., Dd} bethe set of domains used.
For each domain Dk thedomain ?frequency?
score is computed in a windowof c words around wtj .
The domain frequency scoreis defined by formula (1).F (Dk, t, j) =j+cXi=j?cRword(Dk, wti)G(i, j, (c2)2) (1)where the weight factor G(x, ?, ?2) is the densityof the normal distribution with mean ?
and standarddeviation ?
at point x and Rword(D,w) is a functionthat return the relevance of a domain D for a wordw (see formula 3).
In the rest of the paper we use thenotation F (Dk, t) to refer to F (Dk, t,m), where mis the integer part of q/2 (i.e.
the ?central?
point ofthe text - q is the text length).Here below we see that the information containedin WORDNET DOMAINS can be used to estimateRword(Dk, w), i.e.
domain relevance for the wordw, which is derived from the domain relevance ofthe synsets in which w appears.As far as synsets are concerned, domain informa-tion is represented by the function Dom : S ?P (D)3 that returns, for each synset s ?
S, whereS is the set of synsets in WORDNET DOMAINS, theset of the domains associated to it.
Formula (2) de-fines the domain relevance estimation function (re-member that d is the cardinality of D):Rsyn(D, s) =8<:1/|Dom(s)| : if D ?
Dom(s)1/d : if Dom(s) = {FACTOTUM}0 : otherwise(2)Intuitively, Rsyn(D, s) can be perceived as an es-timated prior for the probability of the domain giventhe concept, as expressed by the WORDNET DO-MAINS annotation.
Under these settings FACTO-TUM (generic) concepts have uniform and low rel-evance values for each domain while domain con-cepts have high relevance values for a particular do-main.The definition of domain relevance for a word isderived directly from the one given for concepts.
In-tuitively a domain D is relevant for a word w if Dis relevant for one or more senses c of w. Moreformally let V = {w1, w2, ...w|V |} be the vocab-ulary, let senses(w) = {s|s ?
S, s is a sense ofw} (e.g.
any synset in WORDNET containing theword w).
The domain relevance function for a wordR : D ?
V ?
[0, 1] is defined as follows:Rword(Di, w) =1|senses(w)|Xs?senses(w)Rsyn(Di, s) (3)3P (D) denotes the power set of D3.2 The Gaussian Mixture AlgorithmAs explained at the beginning of this section, thesimple local frequency count expressed by formula(1) is not a good domain relevance measure.In order to discriminate between noise and rel-evant information, a supervised framework is typ-ically used and significance levels for frequencycounts are estimated from labeled training data.
Un-fortunately this is not our case, since no domainlabeled text corpora are available.
In this sectionwe propose a solution for that problem, namely theGaussian Mixture approach, that constitutes an un-supervised way to estimate how to differentiate rel-evant domain information in texts from noise.
TheGaussian Mixture approach consists of a parameterestimation technique based on statistics of word dis-tribution in a large-scale corpus.The underlying assumption of the Gaussian Mix-ture approach is that frequency scores for a cer-tain domain are obtained from an underlying mix-ture of relevant and non-relevant texts, and that thescores for relevant texts are significantly higher thanscores obtained for the non-relevant ones.
In thecorpus these scores are distributed according to twodistinct components.
The domain frequency distri-bution which corresponds to relevant texts has thehigher value expectation, while the one pertaining tonon relevant texts has the lower expectation.
Figure1 describes the probability density function (PDF )for domain frequency scores of the SPORT domainestimated on the BNC corpus4 (BNC-Consortium,2000) using formula (1).
The ?empirical?
PDF ,describing the distribution of frequency scores eval-uated on the corpus, is represented by the continu-ous line.From the graph it is possible to see that the empir-ical PDF can be decomposed into the sum of twodistributions, D = SPORT and D = ?non-SPORT?.Most of the probability is concentrated on the left,describing the distribution for the majority of nonrelevant texts; the smaller distribution on the rightis assumed to be the distribution of frequency scoresfor the minority of relevant texts.Thus, the distribution on the left describes thenoise present in frequency estimation counts, whichis produced by the impact of polysemous wordsand of occasional occurrences of terms belongingto SPORT in non-relevant texts.
The goal of thetechnique is to estimate parameters describing thedistribution of the noise along texts, in order to as-4The British National Corpus is a very large (over 100 mil-lion words) corpus of modern English, both spoken and written.0501001502000 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04DensityNon-relevantRelevantF(D, t)densityfunctionFigure 1: Gaussian mixture for D = SPORTsociate high relevance values only to relevant fre-quency scores (i.e.
frequency scores that are not re-lated to noise).
It is reasonable to assume that suchnoise is normally distributed because it can be de-scribed by a binomial distribution in which the prob-ability of the positive event is very low and the num-ber of events is very high.
On the other hand, thedistribution on the right is the one describing typicalfrequency values for relevant texts.
This distributionis also assumed to be normal.A probabilistic interpretation permits the evalu-ation of the relevance value R(D, t, j) of a certaindomain D for a new text t in a position j only byconsidering the domain frequency F (D, t, j).
Therelevance value is defined as the conditional prob-ability P (D|F (D, t, j)).
Using Bayes theorem weestimate this probability by equation (4).R(D, t, j) = P (D|F (D, t, j)) = (4)= P (F (D, t, j)|D)P (D)P (F (D, t, j)|D)P (D) + P (F (D, t, j)|D)P (D)where P (F (D, t, j)|D) is the value of the PDFdescribing D calculated in the point F (D, t, j),P (F (D, t, j)|D) is the value of the PDF describ-ing D, P (D) is the area of the distribution describ-ing D and P (D) is the area of the distribution forD.In order to estimate the parameters describing thePDF of D and D the Expectation Maximization(EM) algorithm for the Gaussian Mixture Model(Redner and Walker, 1984) is exploited.
Assumingto model the empirical distribution of domain fre-quencies using a Gaussian mixture of two compo-nents, the estimated parameters can be used to eval-uate domain relevance by equation (4).3.3 The EM Algorithm for the GM modelIn this section some details about the algorithm forparameter estimation are reported.It is well known that a Gaussian mixture (GM)allows to represent every smooth PDF as a linearcombination of normal distributions of the type informula 5p(x|?)
=m?j=1ajG(x, ?j , ?j) (5)withaj ?
0 andm?j=1aj = 1 (6)andG(x, ?, ?)
= 1?2pi?e?(x??
)22?2 (7)and ?
= ?a1, ?1, ?1, .
.
.
, am, ?m, ?m?
is a pa-rameter list describing the gaussian mixture.
Thenumber of components required by the GaussianMixture algorithm for domain relevance estimationis m = 2.Each component j is univocally determined by itsweight aj , its mean ?j and its variance ?j .
Weightsrepresent also the areas of each component, i.e.
itstotal probability.The Gaussian Mixture algorithm for domain rele-vance estimation exploits a Gaussian Mixture to ap-proximate the empirical PDF of domain frequencyscores.
The goal of the Gaussian Mixture algorithmis to find the GM that maximize the likelihood onthe empirical data, where the likelihood function isevaluated by formula (8).L(T , D, ?)
=?t?Tp(F (D, t)|?)
(8)More formally, the EM algorithm for GM modelsexplores the space of parameters in order to find theset of parameters ?
such that the maximum likeli-hood criterion (see formula 9) is satisfied.
?D = argmax?
?L(T , D, ??)
(9)This condition ensures that the obtained modelfits the original data as much as possible.
Estima-tion of parameters is the only information requiredin order to evaluate domain relevance for texts us-ing the Gaussian Mixture algorithm.
The Expecta-tion Maximization Algorithm for Gaussian MixtureModels (Redner and Walker, 1984) allows to effi-ciently perform this operation.The strategy followed by the EM algorithm isto start from a random set of parameters ?0, thathas a certain initial likelihood value L0, and theniteratively change them in order to augment like-lihood at each step.
To this aim the EM algo-rithm exploits a growth transformation of the like-lihood function ?(?)
= ??
such that L(T , D, ?)
6L(T , D, ??).
Applying iteratively this transforma-tion starting from ?0 a sequence of parameters isproduced, until the likelihood function achieve astable value (i.e.
Li+1 ?
Li 6 ).
In our settingsthe transformation function ?
is defined by the fol-lowing set of equations, in which all the parametershave to be solved together.?(?)
= ?
(?a1, ?1, ?1, a2, ?2, ?2?)
(10)= ?a?1, ?
?1, ?
?1, a?2, ?
?2, ?
?2?a?j =1|T ||T |?k=1ajG(F (D, tk), ?j , ?j)p(F (D, tk), ?)(11)?
?j =?|T |k=1 F (D, tk) ?ajG(F (D,tk),?j ,?j)p(F (D,tk),?
)?|T |k=1ajG(F (D,tk),?j ,?j)p(F (D,tk),?)(12)?
?j =?|T |k=1 (F (D, tk) ?
?
?j)2 ?aiG(F (D,tk),?i,?i)p(F (D,tk),?
)?|T |k=1ajG(F (D,tk),?j ,?j)p(F (D,tk),?)
(13)As said before, in order to estimate distribu-tion parameters the British National Corpus (BNC-Consortium, 2000) was used.
Domain frequencyscores have been evaluated on the central positionof each text (using equation 1, with c = 50).In conclusion, the EM algorithm was used to es-timate parameters to describe distributions for rele-vant and non-relevant texts.
This learning methodis totally unsupervised.
Estimated parameters hasbeen used to estimate relevance values by formula(4).4 Domain Driven DisambiguationDRE originates to improve the performance of Do-main Driven Disambiguation (DDD).
In this sec-tion, a brief overview of DDD is given.
DDD is aWSD methodology that only makes use of domaininformation.
Originally developed to test the role ofdomain information for WSD, the system is capableto achieve a good precision disambiguation.
Its re-sults are affected by a low recall, motivated by thefact that domain information is sufficient to disam-biguate only ?domain words?.
The disambiguationprocess is done comparing the domain of the con-text and the domains of each sense of the lemma todisambiguate.
The selected sense is the one whosedomain is relevant for the context5 .In order to represent domain information we in-troduced the notion of Domain Vectors (DV), thatare data structures that collect domain information.These vectors are defined in a multidimensionalspace, in which each domain represents a dimen-sion of the space.
We distinguish between two kindsof DVs: (i) synset vectors, which represent the rel-evance of a synset with respect to each considereddomain and (ii) text vectors, which represent the rel-evance of a portion of text with respect to each do-main in the considered set.More formally let D = {D1, D2, ..., Dd} be theset of domains, the domain vector ~s for a synset sis defined as ?R(D1, s), R(D2, s), .
.
.
, R(Dd, s)?where R(Di, s) is evaluated using equation(2).
In analogy the domain vector ~tj fora text t in a given position j is defined as?R(D1, t, j), R(D2, t, j), .
.
.
, R(Dd, t, j)?
whereR(Di, t, j) is evaluated using equation (4).The DDD methodology is performed basically inthree steps:1.
Compute ~t for the context t of the word w to be disam-biguated2.
Compute s?
= argmaxs?Senses(w)score(s, w, t) wherescore(s,w, t) = P (s|w) ?
sim(~s,~t)Ps?Senses(w) P (s|w) ?
sim(~s,~t)3. if score(s?, w, t) > k (where k ?
[0, 1] is a confidencethreshold) select sense s?, else do not provide any answerThe similarity metric used is the cosine vectorsimilarity, which takes into account only the direc-tion of the vector (i.e.
the information regarding thedomain).P (s|w) describes the prior probability of senses for word w, and depends on the distribution ofthe sense annotations in the corpus.
It is esti-mated by statistics from a sense tagged corpus (weused SemCor)6 or considering the sense order in5Recent works in WSD demonstrate that an automatic es-timation of domain relevance for texts can be profitable usedto disambiguate words in their contexts.
For example, (Escud-ero et al, 2001) used domain relevance extraction techniquesto extract features for a supervised WSD algorithm presentedat the Senseval-2 competion, improving the system accuracy ofabout 4 points for nouns, 1 point for verbs and 2 points for ad-jectives, confirming the original intuition that domain informa-tion is very useful to disambiguate ?domain words?, i.e.
wordswhich are strongly related to the domain of the text.6Admittedly, this may be regarded as a supervised compo-nent of the generally unsupervised system.
Yet, we consideredthis component as legitimate within an unsupervised frame-WORDNET, which roughly corresponds to sensefrequency order, when no example of the wordto disambiguate are contained in SemCor.
In theformer case the estimation of P (s|w) is based onsmoothed statistics from the corpus (P (s|w) =occ(s,w)+?occ(w)+|senses(w)|??
, where ?
is a smoothing fac-tor empirically determined).
In the latter caseP (s|w) can be estimated in an unsupervised wayconsidering the order of senses in WORDNET(P (s|w) = 2(|senses(w)|?sensenumber(s,w)+1)|senses(w)|(|senses(w)|+1) wheresensenumber(s, w) returns the position of senses of word w in the sense list for w provided byWORDNET.5 Evaluation in a WSD taskWe used the WSD framework to perform an evalu-ation of the DRE technique by itself.As explained in Section 1 Domain Relevance Es-timation is not a common Text Categorization task.In the standard framework of TC, categories arelearned form examples, that are used also for test.In our case information in WORDNET DOMAINS isused to discriminate, and a test set, i.e.
a corpus oftexts categorized using the domain of WORDNETDOMAINS, is not available.
To evaluate the accu-racy of the domain relevance estimation techniquedescribed above is thus necessary to perform an in-direct evaluation.We evaluated the DDD algorithm described inSection 4 using the dataset of the Senseval-2 all-words task (Senseval-2, 2001; Preiss and Yarowsky,2002).
In order to estimate domain vectors for thecontexts of the words to disambiguate we used theDRE methodology described in Section 3.
Varyingthe confidence threshold k, as described in Section4, it is possible to change the tradeoff between preci-sion and recall.
The obtained precision-recall curveof the system is reported in Figure 2.In addition we evaluated separately the perfor-mance on nouns and verbs, suspecting that nounsare more ?domain oriented?
than verbs.
The effec-tiveness of DDD to disambiguate domain words isconfirmed by results reported in Figure 3, in whichthe precision recall curve is reported separately forboth nouns and verbs.
The performances obtainedfor nouns are sensibly higher than the one obtainedfor verbs, confirming the claim that domain infor-mation is crucial to disambiguate domain words.In Figure 2 we also compare the results ob-tained by the DDD system that make use of theDRE technique described in Section 3 with the re-work since it relies on a general resource (SemCor) that doesnot correspond to the test data (Senseval all-words task).0.550.60.650.70.750.80.850.90.950.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6PrecisionRecallDDD newDDD oldFigure 2: Performances of the system for all POS0.40.450.50.550.60.650.70.750.80.850 0.1 0.2 0.3 0.4 0.5 0.6 0.7PrecisionRecallNounsVerbsFigure 3: Performances of the system for Nouns andVerbssults obtained by the DDD system presented at theSenseval-2 competition described in (Magnini et al,2002), that is based on the same DDD methodol-ogy and exploit a DRE technique that consists ba-sically on the simply domain frequency scores de-scribed in subsection 3.1 (we refer to this systemusing the expression old-DDD, in contrast to the ex-pression new-DDD that refers to the implementationdescribed in this paper).Old-DDD obtained 75% precision and 35% re-call on the official evaluation at the Senseval-2 En-glish all words task.
At 35% of recall the new-DDDachieves a precision of 79%, improving precisionby 4 points with respect to old-DDD.
At 75% pre-cision the recall of new-DDD is 40%.
In both casesthe new domain relevance estimation technique im-proves the performance of the DDD methodology,demonstrating the usefulness of the DRE techniqueproposed in this paper.6 Conclusions and Future WorksDomain Relevance Estimation, an unsupervised TCtechnique, has been proposed and evaluated in-side the Domain Driven Disambiguation frame-work, showing a significant improvement on theoverall system performances.
This technique alsoallows a clear probabilistic interpretation providingan operative definition of the concept of domain rel-evance.
During the learning phase annotated re-sources are not required, allowing a low cost imple-mentation.
The portability of the technique to otherlanguages is allowed by the usage of synset-alignedwordnets, being domain annotation language inde-pendent.As far as the evaluation of DRE is concerned, forthe moment we have tested its usefulness in the con-text of a WSD task, but we are going deeper, con-sidering a pure TC framework.AcknowledgementsWe would like to thank Ido Dagan and MarcelloFederico for many useful discussions and sugges-tions.ReferencesBNC-Consortium.
2000.
British national corpus,http://www.hcu.ox.ac.uk/BNC/.J.
P. Comaroni, J. Beall, W. E. Matthews, and G. R.New, editors.
1989.
Dewey Decimal Classica-tion and Relative Index.
Forest Press, Albany,New York, 20th edition.G.
Escudero, L. Ma`rquez, and G. Rigau.
2001.Using lazy boosting for word sense disambigua-tion.
In Proc.
of SENSEVAL-2 Second Inter-national Workshop on Evaluating Word SenseDisambiguation System, pages 71?74, Toulose,France, July.C.
Fellbaum.
1998.
WordNet.
An Electronic LexicalDatabase.
The MIT Press.Y.
Ko and J. Seo.
2000.
Automatic text categoriza-tion by unsupervised learning.
In Proceedings ofCOLING-00, the 18th International Conferenceon Computational Linguistics, Saarbru?cken, Ger-many.B.
Magnini and G. Cavaglia`.
2000.
Integrating sub-ject field codes into WordNet.
In Proceedingsof LREC-2000, Second International Conferenceon Language Resources and Evaluation, Athens,Greece, June.B.
Magnini, C. Strapparava, G. Pezzulo, andA.
Gliozzo.
2002.
The role of domain informa-tion in word sense disambiguation.
Natural Lan-guage Engineering, 8(4):359?373.M.
Palmer, C. Fellbaum, S. Cotton, L. Delfs, andH.T.
Dang.
2001.
English tasks: All-wordsand verb lexical sample.
In Proceedings ofSENSEVAL-2, Second International Workshop onEvaluating Word Sense Disambiguation Systems,Toulouse, France, July.J.
Preiss and D. Yarowsky, editors.
2002.
Pro-ceedings of SENSEVAL-2: Second InternationalWorkshop on Evaluating Word Sense Disam-biguation Systems, Toulouse, France.R.
Redner and H. Walker.
1984.
Mixture densi-ties, maximum likelihood and the EM algorithm.SIAM Review, 26(2):195?239, April.F.
Sebastiani.
2002.
Machine learning in auto-mated text categorization.
ACM Computing Sur-veys, 34(1):1?47.Senseval-2.
2001. http://www.senseval.org.
