Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 44?52,Sydney, July 2006. c?2006 Association for Computational LinguisticsSPMT: Statistical Machine Translation withSyntactified Target Language PhrasesDaniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin KnightLanguage Weaver Inc.4640 Admiralty Way, Suite 1210Marina del Rey, CA 90292{dmarcu,wwang,aechihabi,kknight}@languageweaver.comAbstractWe introduce SPMT, a new class of sta-tistical Translation Models that use Syn-tactified target language Phrases.
TheSPMT models outperform a state of the artphrase-based baseline model by 2.64 Bleupoints on the NIST 2003 Chinese-Englishtest corpus and 0.28 points on a human-based quality metric that ranks translationson a scale from 1 to 5.1 IntroductionDuring the last four years, various implemen-tations and extentions to phrase-based statisticalmodels (Marcu and Wong, 2002; Koehn et al,2003; Och and Ney, 2004) have led to signif-icant increases in machine translation accuracy.Although phrase-based models yield high-qualitytranslations for language pairs that exhibit simi-lar word order, they fail to produce grammaticaloutputs for language pairs that are syntacticallydivergent.
Recent models that exploit syntacticinformation of the source language (Quirk et al,2005) have been shown to produce better outputsthan phrase-based systems when evaluated on rel-atively small scale, domain specific corpora.
Andsyntax-inspired formal models (Chiang, 2005), inspite of being trained on significantly less data,have shown promising results when compared onthe same test sets with mature phrase-based sys-tems.
To our knowledge though, no previous re-search has demonstrated that a syntax-based sta-tistical translation system could produce better re-sults than a phrase-based system on a large-scale,well-established, open domain translation task.
Inthis paper we present such a system.Our translation models rely upon and naturallyexploit submodels (feature functions) that havebeen initially developed in phrase-based systemsfor choosing target translations of source languagephrases, and use new, syntax-based translation andtarget language submodels for assembling targetphrases into well-formed, grammatical outputs.After we introduce our models intuitively, wediscuss their formal underpinning and parametertraining in Section 2.
In Section 3, we present ourdecoder and, in Section 4, we evaluate our modelsempirically.
In Section 5, we conclude with a briefdiscussion.2 SPMT: statistical Machine Translationwith Syntactified Phrases2.1 An intuitive introduction to SPMTAfter being exposed to 100M+ words of parallelChinese-English texts, current phrase-based statis-tical machine translation learners induce reason-ably reliable phrase-based probabilistic dictionar-ies.
For example, our baseline statistical phrase-based system learns that, with high probabilities,the Chinese phrases ?ASTRO- -NAUTS?, ?FRANCEAND RUSSIA?
and ?COMINGFROM?
can be trans-lated into English as ?astronauts?/?cosmonauts?,?france and russia?/?france and russian?
and?coming from?/?from?, respectively.
1 Unfortu-nately, when given as input Chinese sentence 1,our phrase-based system produces the outputshown in 2 and not the translation in 3, whichcorrectly orders the phrasal translations into agrammatical sequence.
We believe this hap-pens because the distortion/reordering models thatare used by state-of-the-art phrase-based systems,which exploit phrase movement and ngram target1To increase readability, in this paper, we represent Chi-nese words using fully capitalized English glosses and En-glish words using lowercased letters.44language models (Och and Ney, 2004; Tillman,2004), are too weak to help a phrase-based de-coder reorder the target phrases into grammaticaloutputs.THESE 7PEOPLE INCLUDE COMINGFROMFRANCE AND RUSSIA p-DE ASTRO- -NAUTS .
(1)the 7 people including those from franceand the russian cosmonauts .
(2)these 7 people include astronauts comingfrom france and russia .
(3)One method for increasing the ability of a de-coder to reorder target language phrases is thatof decorating them with syntactic constituent in-formation.
For example, we may make ex-plicit that the Chinese phrase ?ASTRO- -NAUTS?may be translated into English as a noun phrase,NP(NNS(astronauts)); that the phrase FRANCE ANDRUSSIA may be translated into a complex noun-phrase, NP(NP(NNP(france)) CC(and) NP(NNP(russia)));that the phrase COMINGFROM may be translatedinto a partially realized verb phrase that is look-ing for a noun phrase to its right in order to befully realized, VP(VBG(coming) PP(IN(from) NP:x0));and that the Chinese particle p-DE, when occurringbetween a Chinese string that was translated intoa verb phrase to its left and another Chinese stringthat was translated into a noun phrase to its right,VP:x1 p-DE NP:x0, should be translated to noth-ing, while forcing the reordering of the two con-stituents, NP(NP:x0, VP:x1).
If all these translationrules (labeled r1 to r4 in Figure 1) were availableto a decoder that derives English parse trees start-ing from Chinese input strings, this decoder couldproduce derivations such as that shown in Fig-ure 2.
Because our approach uses translation ruleswith Syntactified target language Phrases (see Fig-ure 1), we call it SPMT.2.2 A formal introduction to SPMT2.2.1 Theoretical foundationsWe are interested to model a generative processthat explains how English parse trees pi and theirassociated English string yields E, foreign sen-tences, F , and word-level alignments, A, are pro-duced.
We assume that observed (pi, F,A) tripletsare generated by a stochastic process similar tor1 :NP(NNS(astronauts)) ?
ASTRO- -NAUTSr2 :NP(NP(NNP(france)) CC(and) NP(NNP(russia)))?FRANCE AND RUSSIAr3 :VP(VBG(coming) PP(IN(from) NP:x0)) ?COMINGFROM x0r4 :NP(NP:x0, VP:x1) ?
x1 p-DE x0r5 :NNP(france) ?
FRANCEr6 :NP(NP(NNP(france)) CC(and) NP:x0) ?
FRANCE AND x0r7 :NNS(astronauts) ?
ASTRO- -NAUTSr8 :NNP(russia) ?
RUSSIAr9 :NP(NNS:x0)?
x0r10 :PP(IN:x0 NP:x1) ?
x0 x1r11 :NP(NP:x0 CC:x1 NP:x2) ?
x0 x1 x2r12 :NP(NNP:x0)?
x0r13 :CC(and) ?
ANDr14 :NP(NP:x0 CC(and) NP:x1) ?
x0 AND x1r15 :NP(NP:x0 VP(VBG(coming) PP(IN(from) NP:x1))) ?x1 COMINGFROM x0Figure 1: Examples of xRS rules.that used in Data Oriented Parsing models (Bon-nema, 2002).
For example, if we assume that thegenerative process has already produced the topNP node in Figure 2, then the corresponding par-tial English parse tree, foreign/source string, andword-level alignment could be generated by therule derivation r4(r1, r3(r2)), where each rule isassumed to have some probability.The extended tree to string transducers intro-duced by Knight and Graehl (2005) provide a nat-ural framework for expressing the tree to stringtransformations specific to our SPMT models.The transformation rules we plan to exploit areequivalent to one-state xRS top-down transduc-ers with look ahead, which map subtree patternsto strings.
For example, rule r3 in Figure 1 canbe applied only when one is in a state that has aVP as its syntactic constituent and the tree pat-tern VP(VBG(coming) PP(IN(from) NP)) immediatelyunderneath.
The rule application outputs the string?COMINGFROM?
as the transducer moves to thestate co-indexed by x0; the outputs produced fromthe new state will be concatenated to the right ofthe string ?COMINGFROM?.Since there are multiple derivations that couldlead to the same outcome, the probability of atuple (pi, F,A) is obtained by summing over allderivations ?i ?
?
that are consistent with the tu-45Figure 2: English parse tree derivation of the Chi-nese string COMINGFROM FRANCE AND RUSSIA p-DE ASTRO- -NAUTS.ple, c(?)
= (pi, F,A).
The probability of eachderivation ?i is given by the product of the proba-bilities of all the rules p(rj) in the derivation (seeequation 4).Pr(pi, F,A) =??i??,c(?)=(pi,F,A)?rj?
?ip(rj) (4)In order to acquire the rules specific to ourmodel and to induce their probabilities, we parsethe English side of our corpus with an in-houseimplementation (Soricut, 2005) of Collins pars-ing models (Collins, 2003) and we word-align theparallel corpus with the Giza++2 implementationof the IBM models (Brown et al, 1993).
Weuse the automatically derived ?English-parse-tree,English-sentence, Foreign-sentence, Word-level-alignment?
tuples in order to induce xRS rules forseveral models.2.2.2 SPMT Model 1In our simplest model, we assume that eachtuple (pi, F,A) in our automatically annotatedcorpus could be produced by applying a com-bination of minimally syntactified, lexicalized,phrase-based compatible xRS rules, and mini-mal/necessary, non-lexicalized xRS rules.
We calla rule non-lexicalized whenever it does not haveany directly aligned source-to-target words.
Rulesr9?r12 in Figure 1 are examples of non-lexicalizedrules.Minimally syntactified, lexicalized, phrase-based-compatible xRS rules are extracted via a2http://www.fjoch.com/GIZA++.htmlsimple algorithm that finds for each foreign phraseF ji , the smallest xRS rule that is consistent withthe foreign phrase F ji , the English syntactic treepi, and the alignment A.
The algorithm finds foreach foreign/source phrase span its projected spanon the English side and then traverses the En-glish parse tree bottom up until it finds a nodethat subsumes the projected span.
If this node haschildren that fall outside the projected span, thenthose children give rise to rules that have variables.For example, if the tuple shown in Figure 2 is inour training corpus, for the foreign/source phrasesFRANCE, FRANCE AND, FRANCE AND RUSSIA, andASTRO- -NAUTS, we extract the minimally syntac-tified, lexicalized phrase-based-compatible xRSrules r5, r6, r2, and r7 in Figure 1, respectively.Because, as in phrase-based MT, all our rules havecontinuous phrases on both the source and targetlanguage sides, we call these phrase-based com-patible xRS rules.Since these lexicalized rules are not sufficient toexplain an entire (pi, F,A) tuple, we also extractthe required minimal/necessary, non-lexicalizedxRS rules.
The minimal non-lexicalized rules thatare licensed by the tuple in Figure 2 are labeledr4, r9, r10, r11 and r12 in Figure 1.
To obtain thenon-lexicalized xRS rules, we compute the set ofall minimal rules (lexicalized and non-lexicalized)by applying the algorithm proposed by Galley etal.
(2006) and then remove the lexicalized rules.We remove the Galley et al?s lexicalized rulesbecause they are either already accounted for bythe minimally syntactified, lexicalized, phrase-based-compatible xRS rules or they subsume non-continuous source-target phrase pairs.It is worth mentioning that, in our framework,a rule is defined to be ?minimal?
with respect to aforeign/source language phrase, i.e., it is the min-imal xRS rule that yields that source phrase.
Incontrast, in the work of Galley et al (2004; 2006),a rule is defined to be minimal when it is necessaryin order to explain a (pi, F,A) tuple.Under SPMT model 1, the tree in Figure 2 canbe produced, for example, by the following deriva-tion: r4(r9(r7), r3(r6(r12(r8)))).2.2.3 SPMT Model 1 ComposedWe hypothesize that composed rules, i.e., rulesthat can be decomposed via the application of asequence of Model 1 rules may improve the per-formance of an SPMT system.
For example, al-though the minimal Model 1 rules r11 and r13 are46Figure 3: Problematic syntactifications of phrasaltranslations.sufficient for building an English NP on top of twoNPs separated by the Chinese conjunction AND,the composed rule r14 in Figure 1 accomplishesthe same result in only one step.
We hope that thecomposed rules could play in SPMT the same rolethat phrases play in string-based translation mod-els.To test our hypothesis, we modify our rule ex-traction algorithm so that for every foreign phraseF ji , we extract not only a minimally syntactified,lexicalized xRS rule, but also one composed rule.The composed rule is obtained by extracting therule licensed by the foreign/source phrase, align-ment, English parse tree, and the first multi-childancestor node of the root of the minimal rule.
Ourintuition is that composed rules that involve the ap-plication of more than two minimal rules are notreliable.
For example, for the tuple in Figure 2,the composed rule that we extract given the for-eign phrases AND and COMINGFROM are respec-tively labeled as rules r14 and r15 in Figure 1.Under the SPMT composed model 1,the tree in Figure 2 can be produced,for example, by the following derivation:r15(r9(r7), r14(r12(r5), r12(r8))).2.2.4 SPMT Model 2In many instances, the tuples (pi, F,A) in ourtraining corpus exhibit alignment patterns that canbe easily handled within a phrase-based SMTframework, but that become problematic in theSPMT models discussed until now.Consider, for example, the (pi, F,A) tuple frag-ment in Figure 3.
When using a phrase-basedtranslation model, one can easily extract thephrase pair (THE MUTUAL; the mutual) and use itduring the phrase-based model estimation phraseand in decoding.
However, within the xRS trans-ducer framework that we use, it is impossible toextract an equivalent syntactified phrase transla-tion rule that subsumes the same phrase pair be-cause valid xRS translation rules cannot be multi-headed.
When faced with this constraint, one hasseveral options:?
One can label such phrase pairs as non-syntactifiable and ignore them.
Unfortu-nately, this is a lossy choice.
On our par-allel English-Chinese corpus, we have foundthat approximately 28% of the foreign/sourcephrases are non-syntactifiable by this defini-tion.?
One can also traverse the parse tree upwardsuntil one reaches a node that is xRS valid, i.e.,a node that subsumes the entire English spaninduced by a foreign/source phrase and thecorresponding word-level alignment.
Thischoice is also inappropriate because phrasepairs that are usually available to phrase-based translation systems are then expandedand made available in the SPTM models onlyin larger applicability contexts.?
A third option is to create xRS compati-ble translation rules that overcome this con-straint.Our SPMT Model 2 adopts the third option byrewriting on the fly the English parse tree for eachforeign/source phrase and alignment that lead tonon-syntactifiable phrase pairs.
The rewriting pro-cess adds new rules to those that can be createdunder the SPMT model 1 constraints.
The processcreates one xRS rule that is headed by a pseudo,non-syntactic nonterminal symbol that subsumesthe target phrase and corresponding multi-headedsyntactic structure; and one sibling xRS rule thatexplains how the non-syntactic nonterminal sym-bol can be combined with other genuine nonter-minals in order to obtain genuine parse trees.
Inthis view, the foreign/source phrase THE MUTUALand corresponding alignment in Figure 3 licensesthe rules ?NPB?
NN(DT(the) JJ(mutual)) ?
THE MU-TUAL and NPB(?NPB?
NN:x0 NN:x1) ?
x0 x1 eventhough the foreign word UNDERSTANDING isaligned to an English word outside the NPB con-situent.
The name of the non-syntactic nontermi-nal reflects the intuition that the English phrase ?themutual?
corresponds to a partially realized NPB thatneeds an NN to its right in order to be fully real-ized.47Our hope is that the rules headed by pseudononterminals could make available to an SPMTsystem all the rules that are typically available toa phrase-based system; and that the sibling rulescould provide a sufficiently robust generalizationlayer for integrating pseudo, partially realized con-stituents into the overall decoding process.2.2.5 SPMT Model 2 ComposedThe SPMT composed model 2 uses all ruletypes described in the previous models.2.3 Estimating rule probabilitiesFor each model, we extract all rule instances thatare licensed by a symmetrized Giza-aligned paral-lel corpus and the constraints we put on the model.We condition on the root node of each rule and usethe rule counts f(r) and a basic maximum likeli-hood estimator to assign to each rule type a condi-tional probability (see equation 5).p(r|root(r)) = f(r)?r?:root(r?
)=root(r) f(r?
)(5)It is unlikely that this joint probability modelcan be discriminative enough to distinguish be-tween good and bad translations.
We are not tooconcerned though because, in practice, we decodeusing a larger set of submodels (feature functions).Given the way all our lexicalized xRS rules havebeen created, one can safely strip out the syntac-tic information and end up with phrase-to-phrasetranslation rules.
For example, in string-to-stringworld, rule r5 in Figure 1 can be rewritten as ?france?
FRANCE?
; and rule r6 can be rewritten as ?franceand ?
FRANCE AND?.
When one analyzes the lex-icalized xRS rules in this manner, it is easy to as-sociate with them any of the submodel probabilitydistributions that have been proven useful in statis-tical phrase-based MT.
The non-lexicalized rulesare assigned probability distributions under thesesubmodels as well by simply assuming a NULLphrase for any missing lexicalized source or targetphrase.In the experiments described in this paper, weuse the following submodels (feature functions):Syntax-based-like submodels:?
proot(ri) is the root normalized conditionalprobability of all the rules in a model.?
pcfg(ri) is the CFG-like probability of thenon-lexicalized rules in the model.
The lexi-calized rules have by definition pcfg = 1.?
is lexicalized(ri) is an indicator feature func-tion that has value 1 for lexicalized rules, andvalue 0 otherwise.?
is composed(ri) is an indicator feature func-tion that has value 1 for composed rules.?
is lowcount(ri) is an indicator feature func-tion that has value 1 for the rules that occurless than 3 times in the training corpus.Phrase-based-like submodels:?
lex pef(ri) is the direct phrase-based con-ditional probability computed over the for-eign/source and target phrases subsumed bya rule.?
lex pfe(ri) is the inverse phrase-based condi-tional probability computed over the sourceand target phrases subsumed by a rule.?
m1(ri) is the IBM model 1 probability com-puted over the bags of words that occur onthe source and target sides of a rule.?
m1inv(ri) is the IBM model 1 inverse prob-ability computed over the bags of words thatoccur on the source and target sides of a rule.?
lm(e) is the language model probability ofthe target translation under an ngram lan-guage model.?
wp(e) is a word penalty model designed tofavor longer translations.All these models are combined log-linearly dur-ing decoding.
The weights of the models arecomputed automatically using a variant of theMaximum Bleu training procedure proposed byOch (2003).The phrase-based-like submodels have beenproved useful in phrase-based approaches toSMT (Och and Ney, 2004).
The first two syntax-based submodels implement a ?fused?
translationand lexical grounded distortion model (proot) anda syntax-based distortion model (pcfg).
The indi-cator submodels are used to determine the extentto which our system prefers lexicalized vs. non-lexicalized rules; simple vs. composed rules; andhigh vs. low count rules.483 Decoding3.1 Decoding with one SPMT modelWe decode with each of our SPMT models usinga straightforward, bottom-up, CKY-style decoderthat builds English syntactic constituents on thetop of Chinese sentences.
The decoder uses a bina-rized representation of the rules, which is obtainedvia a syncronous binarization procedure (Zhang etal., 2006).
The CKY-style decoder computes theprobability of English syntactic constituents in abottom up fashion, by log-linearly interpolating allthe submodel scores described in Section 2.3.The decoder is capable of producing nbestderivations and nbest lists (Knight and Graehl,2005), which are used for Maximum Bleu train-ing (Och, 2003).
When decoding the test cor-pus, the decoder returns the translation that has themost probable derivation; in other words, the sumoperator in equation 4 is replaced with an argmax.3.2 Decoding with multiple SPMT modelsCombining multiple MT outputs to increase per-formance is, in general, a difficult task (Matusovet al, 2006) when significantly different enginescompete for producing the best outputs.
In ourcase, combining multiple MT outputs is muchsimpler because the submodel probabilities acrossthe four models described here are mostly iden-tifical, with the exception of the root normalizedand CFG-like submodels which are scaled differ-ently ?
since Model 2 composed has, for example,more rules than Model 1, the root normalized andCFG-like submodels have smaller probabilities foridentical rules in Model 2 composed than in Model1.
We compare these two probabilities across thesubmodels and we scale all model probabilities tobe compatible with those of Model 2 composed.With this scaling procedure into place, we pro-duce 6,000 non-unique nbest lists for all sentencesin our development corpus, using all SPMT sub-models.
We concatenate the lists and we learn anew combination of weights that maximizes theBleu score of the combined nbest list using thesame development corpus we used for tuning theindividual systems (Och, 2003).
We use the newweights in order to rerank the nbest outputs on thetest corpus.4 Experiments4.1 Automatic evaluation of the modelsWe evaluate our models on a Chinese to Englishmachine translation task.
We use the same trainingcorpus, 138.7M words of parallel Chinese-Englishdata released by LDC, in order to train severalstatistical-based MT systems:?
PBMT, a strong state of the art phrase-basedsystem that implements the alignment tem-plate model (Och and Ney, 2004); this is thesystem ISI has used in the 2004 and 2005NIST evaluations.?
four SPMT systems (M1, M1C, M2, M2C)that implement each of the models discussedin this paper;?
a SPMT system, Comb, that combines theoutputs of all SPMT models using the pro-cedure described in Section 3.2.In all systems, we use a rule extraction algo-rithm that limits the size of the foreign/sourcephrases to four words.
For all systems, we usea Kneser-Ney (1995) smoothed trigram languagemodel trained on 2.3 billion words of English.
Asdevelopment data for the SPMT systems, we usedthe sentences in the 2002 NIST development cor-pus that are shorter than 20 words; we made thischoice in order to finish all experiments in time forthis submission.
The PBMT system used all sen-tences in the 2002 NIST corpus for development.As test data, we used the 2003 NIST test set.Table 1 shows the number of string-to-string ortree-to-string rules extracted by each system andthe performance on both the subset of sentences inthe test corpus that were shorter than 20 words andthe entire test corpus.
The performance is mea-sured using the Bleu metric (Papineni et al, 2002)on lowercased, tokenized outputs/references.The results show that the SPMT models clearlyoutperform the phrase-based systems ?
the 95%confidence intervals computed via bootstrap re-sampling in all cases are around 1 Bleu point.
Theresults also show that the simple system combina-tion procedure that we have employed is effectivein our setting.
The improvement on the develop-ment corpus transfers to the test setting as well.A visual inspection of the outputs shows signif-icant differences between the outputs of the fourmodels.
The models that use composed rules pre-fer to produce outputs by using mostly lexicalized49System # of rules Bleu score Bleu score Bleu score(in millions) on Dev on Test on Test(4 refs) (4 refs) (4 refs)< 20 words < 20 wordsPBMT 125.8 34.56 34.83 31.46SPMT-M1 34.2 37.60 38.18 33.15SPMT-M1C 75.7 37.30 38.10 32.39SPMT-M2 70.4 37.77 38.74 33.39SPMT-M2C 111.1 37.48 38.59 33.16SPMT-Comb 111.1 39.44 39.56 34.10Table 1: Automatic evaluation results.rules; in contrast, the simple M1 and M2 mod-els produce outputs in which content is translatedprimarily using lexicalized rules and reorderingsand word insertions are explained primarily by thenon-lexical rules.
It appears that the two strategiesare complementary, succeeding and failing in dif-ferent instances.
We believe that this complemen-tarity and the overcoming of some of the searcherrors in our decoder during the model rescoringphase explain the success of the system combina-tion experiments.We suspect that our decoder still makes manysearch errors.
In spite of this, the SPTM outputsare still significantly better than the PBMT out-puts.4.2 Human-based evaluation of the modelsWe also tested whether the Bleu score improve-ments translate into improvements that can be per-ceived by humans.
To this end, we randomly se-lected 138 sentences of less than 20 words fromour development corpus; we expected the transla-tion quality of sentences of this size to be easier toassess than that of sentences that are very long.We prepared a web-based evaluation interfacethat showed for each input sentence:?
the Chinese input;?
three English reference translations;?
the output of seven ?MT systems?.The evaluated ?MT systems?
were the six systemsshown in Table 1 and one of the reference trans-lations.
The reference translation presented asautomatically produced output was selected fromthe set of four reference translations provided byNIST so as to be representative of human transla-tion quality.
More precisely, we chose the secondbest reference translation in the NIST corpus ac-cording to its Bleu score against the other threereference translations.
The seven outputs wererandomly shuffled and presented to three Englishspeakers for assessment.The judges who participated in our experimentwere instructed to carefully read the three refer-ence translations and seven machine translationoutputs, and assign a score between 1 and 5 toeach translation output on the basis of its quality.Human judges were told that the translation qual-ity assessment should take into consideration boththe grammatical fluency of the outputs and theirtranslation adequacy.
Table 2 shows the averagescores obtained by each system according to eachjudge.
For convenience, the table also shows theBleu scores of all systems (including the humantranslations) on three reference translations.The results in Table 2 show that the humanjudges are remarkably consistent in preferring thesyntax-based outputs over the phrase-based out-puts.
On a 1 to 5 quality scale, the difference be-tween the phrase-based and syntax-based systemswas, on average, between 0.2 and 0.3 points.
Alldifferences between the phrase-based baseline andthe syntax-based outputs were statistically signif-icant.
For example, when comparing the phrase-based baseline against the combined system, theimprovement in human scores was significant atP = 4.04e?6(t = 4.67, df = 413).The results also show that the LDC referencetranslations are far from being perfect.
Althoughwe selected from the four references the secondbest according to the Bleu metric, this human ref-erence was judged to be at a quality level of only4.67 on a scale from 1 to 5.
Most of the translationerrors were fluency errors.
Although the humanoutputs had most of the time the right meaning,the syntax was sometimes incorrect.In order to give readers a flavor of the typesof re-orderings enabled by the SPMT models, wepresent in Table 3, several translation outputs pro-duced by the phrase-based baseline and the com-50System Bleu score Judge 1 Judge 2 Judge 3 Judgeon Dev avg(3 refs)< 20 wordsPBMT 31.00 3.00 3.34 2.95 3.10SPMT-M1 33.79 3.28 3.49 3.04 3.27SPMT-M1C 33.66 3.23 3.43 3.26 3.31SPMT-M2 34.05 3.24 3.45 3.10 3.26SPMT-M2C 33.42 3.24 3.48 3.13 3.28SPMT-Combined 35.33 3.31 3.59 3.25 3.38Human Ref 40.84 4.64 4.62 4.75 4.67Table 2: Human-based evaluation results.bined SPMT system.
The outputs were selected toreflect both positive and negative effects of large-scale re-orderings.5 DiscussionThe SPMT models are similar to the models pro-posed by Chiang (2005) and Galley et al (2006).If we analyze these three models in terms of ex-pressive power, the Galley et al (2006) model ismore expressive than the SPMT models, whichin turn, are more expressive than Chiang?s model.The xRS formalism utilized by Galley et al (2006)allows for the use of translation rules that havemulti-level target tree annotations and discontin-uous source language phrases.
The SPMT mod-els are less general: they use translation rules thathave multi-level target tree annotations but requirethat the source language phrases are continuous.The Syncronous Grammar formalism utilized byChiang is stricter than SPMT since it allows onlyfor single-level target tree annotations.The parameters of the SPMT models presentedin this paper are easier to estimate than those ofGalley et als (2006) and can easily exploit andexpand on previous research in phrase-based ma-chine translation.
Also, the SPMT models yieldsignificantly fewer rules that the model of Galleyet al In contrast with the model proposed by Chi-ang, the SPMT models introduced in this paper arefully grounded in syntax; this makes them goodcandidates for exploring the impact that syntax-based language models could have on translationperformance.From a machine translation perspective, theSPMT translation model family we have proposedin this paper is promising.
To our knowledge,we are the first to report results that show that asyntax-based system can produce results that arebetter than those produced by a strong phrase-based system in experimental conditions similarto those used in large-scale, well-established in-dependent evaluations, such as those carried outannually by NIST.Although the number of syntax-based rulesused by our models is smaller than the numberof phrase-based rules used in our state-of-the-artbaseline system, the SPMT models produce out-puts of higher quality.
This feature is encouragingbecause it shows that the syntactified translationrules learned in the SPMT models can generalizebetter than the phrase-based rules.We were also pleased to see that the Bleuscore improvements going from the phrase- to thesyntax-based models, as well as the Bleu improve-ments going from the simple syntax-based modelsto the combined models system are fully consis-tent with the human qualitative judgments in oursubjective evaluations.
This correlation suggeststhat we can continue to use the Bleu metric to fur-ther improve our models and systems.Acknowledgements.
This research was par-tially supported by the National Institute of Stan-dards and Technology?s Advanced TechnologyProgram Award 70NANB4H3050 to LanguageWeaver Inc.ReferencesR.
Bonnema.
2002.
Probability models for DOP.
InData-Oriented Parsing.
CSLI publications.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
Themathematics of statistical machine translation: Pa-rameter estimation.
Computational Linguistics,19(2):263?311.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics (ACL?05), pages263?270, Ann Arbor, Michigan, June.51System OutputPBMT fujian is china ?s coastal areas most rapid development of foreign trade of the region .SPMT-Combined china ?s coastal areas of fujian is one of the areas of the most rapid development offoreign trade and economic cooperation .PBMT investment in macao has become the largest foreign investors .SPMT-Combined the chinese - funded enterprises have become the largest foreign investor in macao.PBMT they are now two people were unaccounted for .SPMT-Combined currently , both of them remain unaccounted for .PBMT there was no further statement .SPMT-Combined the statement did not explain further .Table 3: Sample translations.Michael Collins.
2003.
Head-driven statistical modelsfor natural language parsing.
Computational Lin-guistics, 29(4):589?637, December.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translationrule?
In HLT-NAACL?2004: Main Proceedings,pages 273?280, Boston, Massachusetts, USA, May2 - May 7.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and IgnacioThayer.
2006.
Scalable inferences and trainingof context-rich syntax translation models.
In Pro-ceedings of the Annual Meeting of the Associationfor Computational Linguistics (ACL?2006), Sydney,Australia, July.Reinhard Kneser and Hermann Ney.
1995.
Improvedbacking-off for m-gram language modeling.
In Pro-ceedings of the International Conference on Acous-tics, Speech, and Signal Processing (ICASSP?95),volume 1, pages 181?184.Kevin Knight and Jonathan Graehl.
2005.
Anoverview of probabilistic tree transducers for natu-ral language processing.
In Proc.
of the Sixth In-ternational Conference on Intelligent Text Process-ing and Computational Linguistics (CICLing?2005),pages 1?25.
Springer Verlag.Philipp Koehn, Franz Joseph Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the Human Language Technology andNorth American Association for Computational Lin-guistics Conference (HLT-NAACL?2003), Edmon-ton, Canada, May 27?June 1.Daniel Marcu and William Wong.
2002.
A phrase-based, joint probability model for statistical machinetranslation.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP?2002), pages 133?139, Philadelphia, PA,July 6-7.Evgeny Matusov, Nicola Ueffing, and Hermann Ney.2006.
Computing consensus translation from mul-tiple machine translation systems using enhancedhypothesis alignment.
In Proceedings of the An-nual Meeting of the European Chapter of the Asso-ciation for Computational Linguistics (EACL?2006),Trento, Italy.Franz Joseph Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4), Decem-ber.Franz Joseph Och.
2003.
Minimum error trainingin statistical machine translation.
In Proceedingsof the Annual Meeting of the Association for Com-putational Linguistics (ACL?2003), pages 160?167,Sapooro, Japan.Kishore Papineni, Salim Roukos, Todd Ward, JohnHenderson, and Florence Reeder.
2002.
Corpus-based comprehensive and diagnostic MT evaluation:Initial Arabic, Chinese, French, and Spanish results.In Proceedings of the Human Language TechnologyConference (ACL?2002), pages 124?127, San Diego,CA, March 24-27.Chris Quirk, Arul Menezes, and Colin Cherry.
2005.Dependency treelet translation: Syntactically in-formed phrasal SMT.
In Proceedings of the 43rdAnnual Meeting of the Association for Computa-tional Linguistics (ACL?2005), pages 271?279, AnnArbor, Michigan, June.Radu Soricut.
2005.
A reimplementation of Collins?sparsing models.Christoph Tillman.
2004.
A unigram orienta-tion model for statistical machine translation.
InHLT-NAACL 2004: Short Papers, pages 101?104,Boston, Massachusetts, USA, May 2 - May 7.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Syncronous binarization for ma-chine translation.
In Proceding of the Human Lan-guage Technology and North American Chapter ofthe Association for Computational Linguistics (HLT-NAACL?2006), New York, June.52
