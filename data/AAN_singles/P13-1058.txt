Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 593?603,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsUsing subcategorization knowledge to improve case predictionfor translation to GermanMarion Weller1 Alexander Fraser2 Sabine Schulte im Walde11Institut fu?r Maschinelle 2Centrum fu?r Informations-Sprachverarbeitung und SprachverarbeitungUniversita?t Stuttgart Ludwig-Maximilians-Universita?t Mu?nchen{wellermn|schulte}@ims.uni-stuttgart.de fraser@cis.uni-muenchen.deAbstractThis paper demonstrates the need and im-pact of subcategorization information forSMT.
We combine (i) features on source-side syntactic subcategorization and (ii)an external knowledge base with quantita-tive, dependency-based information abouttarget-side subcategorization frames.
Amanual evaluation of an English-to-German translation task shows that thesubcategorization information has a posi-tive impact on translation quality throughbetter prediction of case.1 IntroductionWhen translating from a morphologically poorlanguage to a morphologically rich language weare faced with two major problems: (i) the rich-ness of the target-language morphology causesdata sparsity problems, and (ii) information aboutmorphological features on the target side is notsufficiently contained in the source language mor-phology.We address these two problems using a two-step procedure.
We first replace inflected formsby their stems or lemmas: building a translationsystem on a stemmed representation of the targetside leads to a simpler translation task, and themorphological information contained in the sourceand target language parts of the translation modelis more balanced.
In the second step, the stemmedoutput of the translation is then inflected: the mor-phological features are predicted, and the inflectedforms are generated using the stem and predictedmorphological features.In this paper, we focus on improving case pre-diction for noun phrases (NPs) in German trans-lations.
The NP feature case is extremely dif-ficult to predict in German: while the NP fea-tures gender and number are part of the stem orcan be derived from the source-side input, respec-tively, the prediction of case requires informationabout the subcategorization of the entire clause.This is due to German being a less configurationallanguage than English, which encodes grammati-cal relations (e.g.
subject-hood, object-hood, etc.
)through the position of constituents.
German sen-tences exhibit a freer constituent order, and thuscase is an important indicator of the grammaticalfunctions of noun phrases.
Correct case predic-tion is a crucial factor for the adequacy of SMToutput, cf.
the example in table 1 providing anerroneously inflected output (this is taken from abaseline ?simple inflection prediction?
system, cf.section 5.2).
The translation of the English inputsentence in terms of stems is perfectly acceptable;after the inflection step, however, the translationof NP4 ongoing military actions represents a geni-tive modifier of the subject NP2, instead of a directobject NP of the verb anordnen (to order).
Themeaning is thus why the government of the ongo-ing military actions ordered, which has only oneNP and is completely wrong.The translation in table 1 needs verb subcatego-rization information.
This is demonstrated by theinvented examples (1) and (2):(1) [Der Mitarbeiter]NPnom hat [den Bericht]NPacc [demKollegen]NPdat gegeben.
[The employee]NPnom gave [his colleague]NPdat [thereport]NPacc(2) [Der Mitarbeiter]NPnom hat [dem Bericht]NPdat [desKollegen]NPgen zugestimmt.
[The employee]NPnom agreed [on the report]PP [ofhis colleague]PPBoth inflected sentences rely on the stem sequence[d Mitarbeiter] [d Bericht] [d Kollege] ?verb?,so the case assignment can only be determined bythe verb: While geben ( to give) has a strong pref-erence for selecting a ditransitive subcategoriza-tion frame1, including an agentive subject (nomi-1A ditransitive verb takes a subject and two objects.593input [why]1 [the government]2 [ordered]3 [the ongoing military actions]4output stemmed [warum]1 [d Regierung]2 [d anhaltend milita?risch Aktion]4 [angeordnet]3inflected [warum]1 [die Regierung]2 [der anhaltenden milita?rischen Aktionen]4 [angeordnet]3Table 1: Example for case confusion in SMT output when using a simple prediction system.native case), a benefactive (dative case) and a pa-tient (accusative case), zustimmen (to agree) hasa strong preference for only selecting an agentivesubject (nominative case) and an indirect objecttheme (dative case).
So in the latter case the NP[d Kollege] cannot receive case from the verb andis instead the genitive modifier of the dative NP.While for examples (1) and (2) knowledgeabout the syntactic verb subcategorization func-tions is sufficient to correctly predict the NP cases,examples (3) to (6) require subcategorization in-formation at the syntax-semantic interface.
(3) [Der Mitarbeiter]NPnom hat [dem Kollegen]NPdat[den Bericht]NPacc gegeben.
(4) [Der Mitarbeiter]NPnom hat [den Bericht]NPacc [demKollegen]NPdat gegeben.
(5) [Dem Kollegen]NPdat hat [der Mitarbeiter]NPnom[den Bericht]NPacc gegeben.
(6) [Den Bericht]NPacc hat [der Mitarbeiter]NPnom [demKollegen]NPdat gegeben.In all four examples, the verb and the participat-ing noun phrases Mitarbeiter (employee), Kollege(colleague) and Bericht (report) are identical, andthe noun phrases are assigned the same case.
How-ever, given that the stemmed output of the trans-lation does not tell us anything about case fea-tures, in order to predict the appropriate cases ofthe three noun phrases, we either rely on orderingheuristics (such that the nominative NP is morelikely to be in the beginning of the sentence (theGerman Vorfeld) than the accusative or dative NP,even though all three of these would be grammati-cal), or we need fine-grained subcategorization in-formation beyond pure syntax.
For example, bothMitarbeiter and Kollege would satisfy the agentivesubject role of the verb geben better than Bericht,and Bericht is more likely to be the patient ofgeben.The contribution of this paper is to improve theprediction of case in our SMT system by imple-menting and combining two alternative routes tointegrate subcategorization information from thesyntax-semantic interface: (i) We regard the trans-lation as a function of the source language in-put, and project the syntactic functions of the En-glish nouns to their German translations in theSMT output.
This subcategorization model is nec-essary when there are several plausible solutionsfor the syntactic functions of a noun in combina-tion with a verb.
For example, both Mitarbeiterand Kollege are plausible subjects and direct ob-jects of the verb geben, so the information aboutthese nouns?
roles in the input sentence allowsfor disambiguation.
(ii) The case of an NP is de-rived from an external knowledge base comprisingquantitative, dependency-based information aboutGerman verb subcategorization frames and nounmodification.
The verb subcategorization infor-mation is not restricted to syntactic noun func-tions but models association strength for verb?noun pairs with regard to the entire subcatego-rization frame plus the syntactic functions of thenouns.
For example, the database can tell us thatwhile the verb geben is very likely to subcatego-rize a ditransitive frame, the verb zustimmen isvery likely to subcategorize only a direct object,next to the obligatory subject (subcat frame pre-diction).
Furthermore, we can retrieve the infor-mation that the noun Bericht is less likely to ap-pear as subject of geben than the nouns Mitar-beiter and Kollege (verb?noun subcat case pre-diction).
And we can look up that the noun Aktionis very unlikely to be a genitive modification ofRegierung (cf.
table 1), while Kollege is a plausi-ble genitive modification of Bericht (noun?nounmodification case prediction, cf.
example (2)).In summary, model (i) applies when there are noobvious preferences concerning verb?noun sub-categorization or noun?noun modification.
Model(ii) predicts case relying on the subcategoriza-tion and modification preferences.
The combina-tion of our two models approaches a simplifiedlevel of semantic role definition but only relies ondependency information that is considerably eas-ier and cheaper to define and obtain than a veryhigh quality semantic parser and/or a corpus an-notated with semantic role information.
Integrat-ing semantic role information into SMT has beendemonstrated by various researchers to improvetranslation quality (cf.
Wu and Fung (2009a), Wuand Fung (2009b), Liu and Gildea (2008), Liuand Gildea (2010)).
Our approach is in line with594Wu and Fung (2009b) who demonstrated that onthe one hand 84% of verb syntactic functions ina 50-sentence test corpus projected from Chineseto English, and that on the other hand about 15%of the subjects were not translated into subjects,but their semantic roles were preserved across lan-guage.
These two findings correspond to the ex-pected uses of our models (i) and (ii), respectively.2 Previous workPrevious work has already introduced the idea ofgenerating inflected forms as a post-processingstep for a translation system that has beenstripped of (most) target-language-specific fea-tures.
Toutanova et al (2008) and Jeong et al(2010) built translation systems that predict in-flected word forms based on a large array of mor-phological and syntactic features, obtained fromboth source and target side.
Kholy and Habash(2012) and Green and DeNero (2012) work on En-glish to Arabic translation and model gender, num-ber and definiteness, focusing primarily on im-proving fluency.Fraser et al (2012) used a phrase-based systemto transfer stems and generated inflected formsbased on the stems and their morphological fea-tures.
For case prediction, they trained a CRF withaccess to lemmas and POS-tags within a givenwindow.
We re-implemented the system by Fraseret al as a hierarchical machine translation systemusing a string-to-tree setup.
In contrast to the flatphrase-based setting of Fraser et al (2012), syn-tactic trees on the SMT output allow us to workwith verb?noun structures, which are relevant forcase prediction.
While the CRF used for case pre-diction in Fraser et al (2012) has access to lexi-cal information, it is limited to a certain windowsize and has no direct information about the rela-tion of verb?noun pairs occurring in the sentence.Using a window of a limited size is particularlyproblematic for German, as there can be large gapsbetween the verb and its subcategorized nouns; in-troducing information about the relation of verbsand nouns helps to bridge such gaps.
Furthermore,that model was not able to make effective use ofsource-side features.One of the objectives of using an inflectionprediction model is morphologically well-formedoutput.
Kirchhoff et al (2012) evaluated user re-actions to different error types in machine trans-lation and came to the result that morphologicalwell-formedness has only a marginal impact onthe comprehensibility of SMT output in the caseof English-Spanish translation.
As already dis-cussed, German case is essential to the meaningof the sentence, so this result will not hold for Ger-man output.3 Translation pipelineThis section presents an overview of our two-steptranslation process.
In the first step, English in-put is translated to German stems.
In the sec-ond step, morphological features are predicted andinflected forms are generated based on the wordstems and the morphological features.
In subsec-tions 3.1 to 3.4, we present the simple version ofthe inflection prediction system; our new featuresare described in sections 4.2 and 4.3.3.1 Stemmed representation/feature markupWe first parse the German side of the paralleltraining data with BitPar (Schmid, 2004).
Thismaps each surface form appearing in normal textto a stem and morphological features (case, gen-der, number).
We use this representation to createthe stemmed representation for training the trans-lation model.
With the exception of stem-markup(discussed below), all morphological features areremoved from the stemmed representation.
Thestem markup is used as part of the input to the fea-ture prediction; the basic idea is that the given fea-ture values are picked up by the prediction modeland then propagated over the phrase.Nouns, as the head of NPs and PPs, are anno-tated with gender and number.
We consider gen-der as part of the stem, whereas the value for num-ber is derived from the source-side: if marked fornumber, singular/plural nouns are distinguishedduring word alignment and then translated accord-ingly.
Prepositions are also annotated with case;many prepositions are restricted to only one case,some are ambiguous and allow for either dativeor accusative.
Other words which are subject tofeature prediction (e.g.
adjectives, articles) are re-duced to their stems with no feature markup, asare all remaining words.
As sole exception, wekeep the inflected forms of verbs (verbal inflec-tion is not modelled).
In addition to the transla-tion model, the target-side language model, as wellas the reference data for parameter tuning use thisrepresentation.5953.2 Building a stemmed translation modelWe use a hierarchical translation system.
Insteadof translating phrases, a hierarchical system ex-tracts translation rules (Galley et al, 2004) whichallow the decoder to provide a tree spanning overthe translated sentence.
In order to avoid sparsityduring rule extraction, we use a string-to-treesetup, where only the target-side part of the datais parsed.
Translation rules are of the followingform:[X]1 allows [X]2 ?
[NP]1 [NP]2 erlaubt[X]1 allows [X]2 ?
[NP]1 erlaubt [NP]2This example illustrates how rules can cover thedifferent word ordering possibilities in German.PP nodes are annotated with their respectivecase, as well as with the lemma of the prepositionthey contain.
In our experiments, this enriched an-notation has small improvements over the simplersetting with only head categories (details omit-ted).
This outcome, in particular that adding thelemma of the preposition to the PP node helps toimprove translation quality, has been observed be-fore in tree restructuring work for improving trans-lation (Huang and Knight, 2006).3.3 Feature prediction and generation ofinflected formsIn this section we discuss our focus, which is pre-diction of case, but also the prediction of num-ber, gender and strong/weak adjectival inflection.The latter feature is German-specific; its values2(strong/weak) depend on the combination of theother features, as well as on the type of determiner(e.g.
definite/indefinite/none).Morphological features are predicted on fourseparate CRF models, one for each feature.
Themodels for case, number and gender are indepen-dent of another, whereas the model for adjecti-val inflection requires information about these fea-tures, and is thus the last one to be computed, tak-ing the output of the 3 other models as part of itsinput.
In contrast, the adjectival inflection modelin Fraser et al (2012) is independent from theother features.
Each model has access to stems,POS-tags and the feature to be modelled within awindow of four positions to the right and the leftof the current position3.2Note that the values for strong/weak inflection are notalways the same over the phrase, but follow a certain patterndepending on the settings of case, number and gender.3Preliminary experiments showed that larger windows donot improve translation quality.Table 2 illustrates the different steps of the in-flection process: the markup (number and genderon nouns) in the stemmed output of the SMT sys-tem is part of the input to the respective featureprediction.
For gender and number, the valuesgiven on the stems of the nouns are then propa-gated over the phrase.
While the case of prepo-sitional phrases is determined by the case annota-tion on prepositions, the case of nominal phrasesis computed only based on the respective contexts.After predicting all morphological features, the in-formation required to generate inflected forms iscomplete: based on the stems and the features, weuse the morphological tool SMOR (Schmid et al,2004) for the generation of inflected forms.One general problem with feature-prediction isthat the ill-formed SMT output is not well repre-sented by the training data which consists of well-formed sentences.
This problem was also men-tioned by Stymne and Cancedda (2011) and Kholyand Habash (2012).
They deal with this problemby translating the training data and annotating itwith the respective features, and then adding thisnew data set to the original training data.
Asthis method comes with its own problems, such astransferring the morphological annotation to notnecessarily isomorphically translated text, we donot use translated data as part of the training data.Instead, we limit the power of the CRF modelthrough experimenting with the removal of fea-tures, until we had a system that was robust to thisproblem.3.4 Dealing with word formation issuesTo reduce data sparsity, we split portmanteauprepositions.
Portmanteaus are compounds ofprepositions and articles, e.g.
zur = zu der (to the).Being components of nominal phrases, they haveto agree in all morphological features with the restof the phrase.
As only some combinations of arti-cles and prepositions can form a portmanteau, thedecision of whether to merge prepositions and ar-ticles is made after feature prediction.
Since ourfocus is case prediction, we do not do special mod-elling of German compounds.4 Using subcategorization informationWithin the area of (automatic) lexical acquisition,the definition of lexical verb information has beena major focus, because verbs play a central rolefor the structure and the meaning of sentences and596SMT output predicted features inflected forms glossbeeinflussen<VVFIN> ?
beeinflussen influenced<ART> Fem.Acc.Sg.St die thepolitisch<ADJ> Fem.Acc.Sg.Wk politische politicalStabilita?t<NN><Fem><Sg> Fem.Acc.Sg.Wk Stabilita?t stabilityTable 2: Overview of the inflection process: the stem markup is highlighted in the SMT output.discourse.
On the one hand, this has led to a rangeof manually or semi-automatically developed lex-ical resources focusing on verb information, suchas the Levin classes (Levin, 1993), VerbNet (Kip-per Schuler, 2006), FrameNet4 (Fillmore et al,2003), and PropBank (Palmer et al, 2005).
On theother hand, we find automatic approaches to theinduction of verb subcategorization information atthe syntax-semantics interface for a large num-ber of languages, e.g.
Briscoe and Carroll (1997)for English; Sarkar and Zeman (2000) for Czech;Schulte im Walde (2002a) for German; Messiant(2008) for French.
This basic kind of verb knowl-edge has been shown to be useful in many NLPtasks such as information extraction (Surdeanu etal., 2003; Venturi1 et al, 2009), parsing (Carroll etal., 1998; Carroll and Fang, 2004) and word sensedisambiguation (Kohomban and Lee, 2005; Mc-Carthy et al, 2007).4.1 Extracting subcategorization informationAs described in the introductory section, we makeuse of two5 major kinds of subcategorization in-formation.
Verb?noun tuples referring to spe-cific syntactic functions within verb subcatego-rization (verb?noun subcat case prediction) areintegrated with an associated probability for ac-cusative (direct object), dative (indirect object)and nominative (subject).6 Further to the sub-ject and object noun phrases, the subcategoriza-tion information provides quantitative triples forverb?preposition?noun pairs, thus predicting thecase of NPs within prepositional phrases (we dothis only when the prepositions are ambiguious,i.e., they could subcategorize either a dative oran accusative NP).
In addition to modelling sub-categorization information, it is also important todifferentiate between subcategorized noun phrases(such as object or subject), and noun phrases4Even though the FrameNets approach does not only in-clude knowledge about verbal predicates, the actual lexiconsare skewed towards verb behaviour.5The third kind of information, subcat frame predictionis implicit, since verb?noun tuples rely on specific frames.6Genitive objects can also occur in German verb subcate-gorization frames, but this is extremely rare and verb-specificand thus not considered in our model.V-SUBJ V-OBJAcc V-OBJDatEP 454,350 332,847 53,711HGC 712,717 329,830 160,377Both 1,089,492 607,541 206,764Table 3: Number of verb-noun types extractedfrom Europarl (EP) and newspaper data (HGC).that modify nouns (noun?noun modification caseprediction).
Typically, these NP modifiers aregenitive NPs.
To this end, we integrate noun-nounGen tuples with their respective frequencies.These preferences for a certain function (i.e.
sub-ject, object or modifier) are passed on to the sys-tem at the level of nouns and integrated into theCRF through the derived probabilities.The tuples and triples are obtained fromdependency-parsed data by extracting all occur-rences of the respective relations; table 3 gives anoverview of the number of extracted tuple types.For the subcategorization information, the verb-noun tuples (verb-subject, verb-objectAcc, verb-objectDat) are then grouped as follows:tuple gloss Acc Dat NomSchemaN folgenV pattern follow 0 322 19We compute the probabilities for the verb-noun tu-ple to occur in the respective functions based onthe relative frequencies.
In the case of SchemaNfolgenV , we find that the function of Schema as da-tive object is predominant (to follow a pattern), butit can also occur in the subject position (the pat-tern follows).
The fact that two functions are pos-sible for this noun are reflected in their probabili-ties.
The probabilities are discretized into 5 buck-ets (Bp=0, B0<p?0.25, B0.25<p?0.5, B0.5<p?0.75,B0.75<p?1).
In contrast, noun modification innoun-nounGen construction is represented by co-occurrence frequencies.77The frequencies are bucketed to the powers of ten, i.e.f = 1, 2 ?
f ?
10, 11 ?
f ?
100 , etc.
and also f = 0:this representation allows for a more fine-grained distinctionin the low-to-mid frequency range, providing a good basisfor the decision of whether a given noun-noun pair is a truenoun-nounGen structure or just a random co-occurrence oftwo nouns.597Gloss Stem Tag Acc Dat Nom Verb Gen N1 Gold1 companies Unternehmen<NN> NN 0.00 0.00 1.00 erhalten ?
?
Nom2 should sollten<VVFIN> VVFIN ?
?
?
?
?
?
?3 financial finanziell<ADJ> ADJ ?
?
?
?
?
?
Acc4 funding Mittel<NN> NN 1.00 0.00 0.00 erhalten ?
?
Acc5 for fu?r APPR<Acc> PRP ?
?
?
?
?
?
?6 the d<ART> ART ?
?
?
?
?
?
Acc7 introduction Einfu?hrung<NN> NN ?
?
?
?
?
?
Acc8 new neu<ADJ> ADJ ?
?
?
?
?
?
Gen9 technologies Technologie<NN> NN ?
?
?
?
100 Einfu?hrung<NN> Gen10 obtain erhalten<VVINF> VVINF ?
?
?
?
?
?
?Table 4: Adding subcategorization information into SMT output.
(EN input: companies should obtainfinancial funding for the introduction of new technologies).
On the right, the correct labels are given.4.2 Integrating subcategorization knowledgeThere are two possibilities to integrate subcat-egorization information into the case predictionmodel: (i) It can be integrated into the data setusing the tree-structure provided by the decoder.Here, verb-noun tuples are extracted from VP andS structures, and then the probabilities for the dif-ferent functions are looked up.
Similarly, for twoadjacent NPs, the occurrence frequencies of therespective two nouns are looked up in the list ofnoun-nounGen constructions.
(ii) The subcatego-rization information can be integrated based onthe verb-noun tuples obtained by using tuples ob-tained from source-side dependencies.The classification task of the CRF consists inpredicting a sequence of labels: case values forNPs/PPs or no value otherwise, cf.
table 4.
Themodel has access to the basic features stem andtag, as well as the new features based on subcat-egorizaion information (explained below), usingunigrams within a window of up to four positionsto the right and the left of the current position, aswell as bigrams and trigrams for stems and tags(current item + left and/or right item).An example for integrating subcategorizationfeatures is given in table 4.
The first word Un-ternehmen (companies) is annotated as subject oferhalten (obtain) with probability 1, and Mittel(funding) is annotated as direct object of erhal-ten with probability 1.
The word Technologie(technology) has been marked as a candidate fora genitive in a noun-nounGen construction8; theco-occurrence frequency of the tuple Einfu?hrung-Technologie (introduction - technology) lies in thebucket 11. .
.
100.In addition to the probability/frequency of therespective functions, we also provide the CRFwith bigrams containing the two parts of the tuple,8There is no annotation on Einfu?hrung as the prepositionfu?r is always in accusative case.DE stemmed outputwarum<PWAV>die<ART>Regierung<NN><Sg><Fem>die<ART>anhaltend<ADJ>milit?risch<ADJ>Aktion<NN><Pl><Fem>angeordnet<VVFIN>derived featuresSUBJ  V:anordnenOBJ  V:anordnenSUBJOBJEN inputwhythe governmentorderedtheongoingmilitaryactionsFigure 1: Deriving features from dependency-parsed English data via the word alignment.i.e.
verb+noun or the two nouns of possible noun-nounGen constructions.
As can be seen in the ex-ample in table 4, the subject (line 1) and the verb(line 10) are far apart from each other.
By pro-viding the parts of the tuple as unigrams, bigramsor trigrams to the CRF, all relevant informationis available: verb, noun and the probabilities forthe potential functions of the noun in the sentence.In addition to bridging the long distance betweenverbs and subcategorized nouns, a very commonproblem for German, this type of precise informa-tion also helps to close the gap between the well-formed training data and the broken SMT-outputas it replaces to a certain extent the target-languagecontext information (n-grams of stems or lemmaswithin a small window).4.3 Integrating source-side featuresFor predicting case in SMT output, informationabout an NP?s function in the input sentence isessential.
Syntax-semantic functions can be iso-morphic (e.g., English subjects and objects mayhave the same function in a German translation),but this is not necessarily the case.
Despite this,an important advantage of integrating source-sidefeatures is that the well-formed source-side textcan be reliably parsed, whereas SMT output is of-ten disfluent and cannot be reliably parsed.The English features are obtained fromdependency-parsed data (Choi and Palmer, 2012).The relevant annotation of the parser is transferred598to the SMT output via word alignment.
We focuson English subjects, direct objects and noun-of-noun structures (often equivalent to noun-nounGenphrases on the German side): these structuresare generally likely to correspond to each otherwithin source and target language.
In contrastto the subcategorization-based information, thedifference between well-formed training data anddisfluent SMT output tends to work to our benefithere: while the parallel sentences of the trainingdata were manually translated with the objectiveto produce good target-language sentences, thesyntactic structures of the source and targetsentences are often diverging.
In contrast, theSMT system often produces more isomorphictranslations, which is helpful for annotatingsource-side features on the target language.Figure 1 shows the process of integratingsource-side features: for each German noun thatis aligned with an English noun labelled as subjector direct object, this annotation is transferred to thetarget-side.
Using the English dependency struc-tures, the verb subcategorizing the respective nounis identified, and via the alignment, the equivalentGerman verb is obtained.
Similarly, candidates fornoun-nounGen structures are identified by extract-ing and aligning English noun-of-noun phrases.5 Experiments and evaluationIn this section, we present experiments using dif-ferent feature combinations.
We also present amanual evaluation of our best system which showsthat the new features improve translation quality.5.1 Data and experimental setupWe use the hierarchical translation system thatcomes with the Moses SMT-package and GIZA++to compute the word alignment, using the ?grow-diag-final-and?
heuristics.
The rule table wascomputed with the default parameter setting forGHKM extraction (Galley et al, 2004) in the im-plementation by Williams and Koehn (2012).Our training data contains 1,485,059 parallelsentences9; the German part of the parallel datais used as the target-side language model.
The devand test sets (1025/1026 lines) are wmt-2009-a/b.For predicting the grammatical features, weused the Wapiti Toolkit (Lavergne et al, 2010).109English/German data released for the 2009 ACL Work-shop on Machine Translation shared task.10To eliminate irrelevant features, we use L1 regulariza-We train four CRFs on data prepared as shownin section 3.
The corpora used for the extrac-tion of subcategorization tuples were Europarl andGerman newspaper data (200 million words).
Wechoose this particular data combination in order toprovide data that matches the training data, as wellas to add new data of the test set?s domain (news).The German part of Europarl was dependency-parsed with Bohnet (2010), and subcategorizationinformation was extracted as described in Scheibleet al (2013); the newspaper data (HGC - HugeGerman Corpus) was parsed with Schmid (2000),and subcategorization information was extractedas described in Schulte im Walde (2002b).5.2 ResultsWe report results of two types of systems (ta-ble 5): first, a regular translation system built onsurface forms (i.e., normal text) and second, fourinflection prediction systems.
The first inflectionprediction system (1) uses a simple case predic-tion model, whereas the remaining systems areenriched with (2) subcategorization information(cf.
section 4.2), (3) source-side features (cf.
sec-tion 4.3), and (4) both source-side features andsubcategorization information.
In (2) and (4), thesubcategorization information was included usingtuples obtained from source-side dependencies11.The simple prediction system corresponds to thatpresented in section 3; for all inflection predic-tion systems, the same SMT output and models fornumber, gender and strong/weak inflection wereused; thus the only difference with the simple pre-diction system is the model for case prediction.We present three types of evaluation: BLEUscores (Papineni et al, 2001), prediction accuracyon clean data and a manual evaluation of the bestsystem in section 5.3.Table 5 gives results in case-insensitive BLEU.While the inflection prediction systems (1-4) aresignificantly12 better than the surface-form sys-tem (0), the different versions of the inflection sys-tems are not distinguishable in terms of BLEU;however, our manual evaluation shows that thenew features have a positive impact on translationquality.tion; the regularization parameter is optimized on held outdata.11Using tuples extracted from the target-side parse tree(produced by the decoder) results in a BLEU score of 14.00.12We used Kevin Gimpel?s implementation of pairwisebootstrap resampling with 1000 samples.5990 1 2 3 4surface simple subcat.
features source-side source-sidesystem prediction (tuples from EN side) features + subcat.
featuesBLEU 13.43 14.02 14.05 14.10 14.17Clean ?
85.05 % 85.65 % 85.61 % 85.81 %Table 5: Results of the simple prediction vs. three systems enriched with extra features.One problem with using BLEU as an evalua-tion metric is that it is a precision-oriented met-ric and tends to reward fluency rather than ade-quacy (see (Wu and Fung, 2009a; Liu and Gildea,2010)).
As we are working on improving ade-quacy, this will not be fully reflected by BLEU.Furthermore, not all components of an NP do nec-essarily change their inflection with a new casevalue; it might happen that the only indicator forthe case of an NP is the determiner: er sieht [denalten Mann]NPacc (he sees the old man) vs. erfolgt [dem alten Mann]NPdat (he follows the oldman).
While the case marking of NPs is essentialfor comprehensibility, one changed word per nounphrase is hardly enough to be reflected by BLEU.An alternative to study the effectiveness of thecase prediction model is to evaluate the predictionaccuracy on parsed clean data, i.e.
not on SMToutput.
In this case, we measure (using the devset) how often the case of an NP is predicted cor-rectly13.
In all cases, the prediction accuracy isbetter for the enriched systems.
This shows thatthe additional features improve the model, but alsothat a gain in prediction accuracy on clean data isnot necessarily related to a gain in BLEU.
We ob-served that the more complex the model, the lessrobust it is to differences between the test dataand the training data.
Related to this problem,we observed that high-order n-gram POS/lemma-based features in the simple prediction (sequencesof lemmas and tags) are given too much weight intraining and thus make it difficult for the new fea-tures to have a larger impact, so we restricted then-gram order of this type of feature to trigrams.5.3 Manual evaluation of the best systemIn order to provide a better understanding of theimpact of the presented features, in particular tosee whether there is an improvement in adequacy,we carried out a manual evaluation comparing sys-13The numbers in table 5 are artificially high and downplaythe difference as they also include cases which are very easyto predict, such as nouns in PPs where only one value for caseis possible.
We measure how many case labels were correctlypredicted, not correct inflected forms.enriched simple equalpreferred preferredperson 1 23 11 12(a) person 2 21 8 17person 3 26 11 9person 1 23 5 18(b) person 2 21 11 14person 3 29 8 9(c) agreement 17 2 6Table 6: Manual evaluation of 46 sentences: with-out (a) and with (b) access to EN input, and theannotators?
agreement in the second part (c).tem (4) with the simple prediction system (1).From the set of different sentences between thesimple prediction system and the enriched system(144 of 1026), we evaluated those where the En-glish input sentence was between 8 and 25 wordslong (46 sentences in total).
We specifically re-stricted the test set in order to provide sentenceswhich are less difficult to annotate, as longer sen-tences are often very disfluent and too hard to rate.Most of the sentences in the evaluation set differonly in the realization of one NP.
For comparingthe two systems, the sentences were presented inrandom order to 3 native speakers of German.The evaluation consists of two parts: first, theparticipants were asked to decide which sentenceis better without being given the English input(this measures fluency).
In the second part, theyshould to mark that sentence which better repro-duces the content of the English input sentence(this measures adequacy).
The test set is the samefor both tasks, the only difference being that theEnglish input is given in the second part.
The re-sults are given in table 6.
Summarizing we cansay that the participants prefer the enriched sys-tem over the simple system in both parts; there is ahigh agreement (17 cases) in decisions over thosesentences which were rated as enriched better.When looking at the pairwise inter-annotatoragreement for the task of annotating the test-setwith the 3 possible labels enriched preferred, sim-ple preferred and no preference, we find that theannotators P1 and P2 have a substantial agreement600input hundreds of policemen were on alert , and [a helicopter]Subj circled the area with searchlights .1 simple Hunderte von Polizisten auf Trab , und [einen Helikopter]Acc eingekreist das Gebiet mit searchlights .enriched Hunderte von Polizisten auf Trab , und [ein Helikopter]Nom eingekreist das Gebiet mit searchlights .input while 38 %percent put [their trust]Obj in viktor orba?n .2 simple wa?hrend 38 % [ihres Vertrauens]Gen schenken in Viktor Orba?n .enriched wa?hrend 38 % [ihr Vertrauen]Acc schenken in Viktor Orba?n .input more than $ 100 billion will enter [the monetary markets]Obj by means of public sales .3 simple mehr als 100 Milliarden Dollar werden durch o?ffentlichen Verkauf [der Geldma?rkte]Gen treten .enriched mehr als 100 Milliarden Dollar werden durch o?ffentlichen Verkauf [die Geldma?rkte]Acc treten .Table 7: Output from the simple system (1) and the enriched system (4).in terms of Kappa (?
= 0.6184), whereas the agree-ment of P3 with P1/P2 respectively leads to lowerscores (?
= 0.4467 and ?
= 0.3596).
However, theannotators tend to agree well on sentences withthe label enriched preferred, but largely disagreeon sentences labelled as either simple preferred orno preference.
The number of decisions where allthree annotators agree on a label when given theEnglish input is listed in table 6(c): for example,only two sentences were given the label baseline isbetter by all three annotators.
This outcome showshow difficult it is to rate disfluent SMT output.
Forevaluating the case prediction system, the distinc-tion between enriched preferred and enriched dis-preferred is the most important question to answer.Redefining the annotation task to annotating onlytwo values by grouping the labels simple preferredand no preference into one annotation possibilityleads to ?
= 0.7391, ?
= 0.4048 and ?
= 0.5652.5.4 ExamplesTable 7 shows some examples for output from thesimple system and the system using source-sideand subcategorization features.
In the first sen-tence, the subject NP a helicopter was inflectedas a direct object in the simple system, but as asubject in the enriched system, which was pre-ferred by all three annotators.
In the second sen-tence, the NP their trust, i.e.
a direct object of put,was incorrectly predicted as genitive-modifier of38 % (i.e.
38 % of their trust) in the simple sys-tem.
The enriched system made use of the prefer-ence for accusative for the pair Vertrauen schenken(place trust), correctly inflecting this NP as di-rect object.
Interestingly, only two annotators pre-ferred the enriched system, whereas one was unde-cided.
The third sentence illustrates how difficultit is to rate case marking on disfluent SMT output:there are two possibilities to translate enter themoney market; the direct equivalent of the Englishphrase (den GeldmarktAcc betreten), or via the useof a prepositional phrase (auf den GeldmarktAcctreten: ?to step into the money market?).
TheSMT-output contains a mix of both, i.e.
the verbtreten (instead of betreten), but without the prepo-sition, which cannot lead to a fully correct inflec-tion.
While the inflection of the simple system (agenitive construction meaning the public sales ofthe money market) is definitely wrong, the inflec-tion obtained in the enriched system is not use-ful either, due to the structure of the translation14.This difficulty is also reflected by the annotators,who gave twice the label no preference and oncethe label enriched better.6 ConclusionWe illustrated the necessity of using externalknowledge sources like subcategorization infor-mation for modelling case for English to Ger-man translation.
We presented a translation sys-tem making use of a subcategorization databasetogether with source-side features.
Our methodis language-independent with regard to the sourcelanguage; furthermore, no language-specific high-quality semantic annotation is needed for the tar-get language, but the data required to model thesubcategorization preferences can be obtained us-ing standard NLP techniques.
We showed in amanual evaluation that the proposed features havea positive impact on translation quality.AcknowledgementsThis work was funded by the DFG ResearchProject Distributional Approaches to Semantic Re-latedness (Marion Weller), the DFG HeisenbergFellowship SCHU-2580/1-1 (Sabine Schulte imWalde), as well as by the Deutsche Forschungsge-meinschaft grant Models of Morphosyntax for Sta-tistical Machine Translation (Alexander Fraser).14Furthermore, with treten being polysemous, dieGeldma?rkte treten can also mean to kick the money markets.601ReferencesBernd Bohnet.
2010.
Top Accuracy and Fast Depen-dency Parsing is not a Contradiction.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics (COLING) 2010, pages 89?97, Beijing, August.Ted Briscoe and John Carroll.
1997.
Automatic Ex-traction of Subcategorization from Corpora.
In Pro-ceedings of the 5th ACL Conference on Applied Nat-ural Language Processing, pages 356?363, Wash-ington, DC.John Carroll and Alex C. Fang.
2004.
The Auto-matic Acquisition of Verb Subcategorisations andtheir Impact on the Performance of an HPSG Parser.In Proceedings of the 1st International Joint Confer-ence on Natural Language Processing, pages 107?114, Sanya City, China.John Carroll, Guido Minnen, and Ted Briscoe.
1998.Can Subcategorisation Probabilities Help a Sta-tistical Parser?
In Proceedings of the 6thACL/SIGDAT Workshop on Very Large Corpora,Montreal, Canada.Jinho D. Choi and Martha Palmer.
2012.
Getting theMost out of Transition-Based Dependency Parsing.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies.Charles J. Fillmore, Christopher R. Johnson, andMiriam R.L.
Petruck.
2003.
Background toFrameNet.
International Journal of Lexicography,16:235?250.Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-bienne Cap.
2012.
Modeling Inflection and Word-Formation in SMT.
In Proceedings of the the Euro-pean Chapter of the Association for ComputationalLinguistics (EACL), Avignon, France.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a Translation Rule?In Proceedings of the Human Language Technologyand North American Association for ComputationalLinguistics Conference (HLT-NAACL).Spence Green and John DeNero.
2012.
A Class-Based Agreement Model for Generating AccuratelyInflected Translations.
pages 146?155.Bryant Huang and Kevin Knight.
2006.
Relabel-ing Syntax Trees to Improve Syntax-Based MachineTranslation Quality.
In Proceedings of the Hu-man Language Technology Conference of the NorthAmerican Chapter of the ACL.Minwoo Jeong, Kristina Toutanova, Hisami Suzuki,and Chris Quirk.
2010.
A Discriminative LexiconModel for Complex Morphology.
In Proceedings ofthe Ninth Conference of the Association for MachineTranslation in the Americas (AMTA 2010).Ahmed El Kholy and Nizar Habash.
2012.
Translate,Predict or Generate: Modeling Rich Morphology inStatistical Machine Translation.
In European Asso-ciation for Machine Translation.Karin Kipper Schuler.
2006.
VerbNet: A Broad-Coverage, Comprehensive Verb Lexicon.
Ph.D. the-sis, University of Pennsylvania, Computer and In-formation Science.Katrin Kirchhoff, Daniel Capurro, and Anne Turner.2012.
Evaluating User Preferences in MachineTranslation Using Conjoint Analysis.
In EuropeanAssociation for Machine Translation.Upali S. Kohomban and Wee Sun Lee.
2005.
LearningSemantic Classes for Word Sense Disambiguation.In Proceedings of the 43rd Annual Meeting on Asso-ciation for Computational Linguistics, pages 34?41,Ann Arbor, MI.Thomas Lavergne, Olivier Cappe?, and Franc?ois Yvon.2010.
Practical very large scale CRFs.
In Proceed-ings the 48th Annual Meeting of the Association forComputational Linguistics (ACL), pages 504?513.Association for Computational Linguistics, July.Beth Levin.
1993.
English Verb Classes and Alterna-tions.
The University of Chicago Press.Ding Liu and Daniel Gildea.
2008.
Improved Tree-to-String Transducers for Machine Translation.
InACL Workshop on Statistical Machine Translation.Ding Liu and Daniel Gildea.
2010.
Semantic RoleFeatures for Machine Translation.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics (COLING) 2010.Diana McCarthy, Rob Koeling, Julie Weeds, and JohnCarroll.
2007.
Unsupervised Acquisition of Pre-dominant Word Senses.
Computational Linguistics,33(4):553?590.Ce?dric Messiant.
2008.
A Subcategorization Acqui-sition System for French Verbs.
In Proceedings ofthe Student Research Workshop at the 46th AnnualMeeting of the Association for Computational Lin-guistics, pages 55?60, Columbus, OH.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An annotated Re-source of Semantic Roles.
Computational Linguis-tics, 31(1):71?106.Kishore A. Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2001.
BLEU: a Method for Auto-matic Evaluation of Machine Translation.
TechnicalReport RC22176 (W0109-022), IBM Research Di-vision, Thomas J. Watson Research Center.Anoop Sarkar and Daniel Zeman.
2000.
AutomaticExtraction of Subcategorization Frames for Czech.In Proceedings of the 18th International Conferenceon Computational Linguistics, Saarbru?cken, Ger-many.602Silke Scheible, Sabine Schulte im Walde, MarionWeller, and Max Kisselew.
2013.
A Compact butLinguistically Detailed Database for German VerbSubcategorisation relying on Dependency Parsesfrom a Web Corpus.
In Proceedings of the 8th Webas Corpus Workshop, Lancaster, UK.
To appear.Helmut Schmid, Arne Fitschen, and Ulrich Heid.2004.
SMOR: a German Computational Morphol-ogy Covering Derivation, Composition, and Inflec-tion.
In Proceedings of the Fourth InternationalConference on Language Resources and Evaluation(LREC).Helmut Schmid.
2000.
LoPar: Design and Imple-mentation.
Arbeitspapiere des Sonderforschungs-bereichs 340 ?Linguistic Theory and the Foun-dations of Computational Linguistics?
149, Insti-tut fu?r Maschinelle Sprachverarbeitung, Universita?tStuttgart.Helmut Schmid.
2004.
Efficient Parsing of HighlyAmbiguous Context-Free Grammars with Bit Vec-tors.Sabine Schulte im Walde.
2002a.
A Subcategorisa-tion Lexicon for German Verbs induced from a Lex-icalised PCFG.
In Proceedings of the 3rd Confer-ence on Language Resources and Evaluation, vol-ume IV, pages 1351?1357, Las Palmas de Gran Ca-naria, Spain.Sabine Schulte im Walde.
2002b.
A Subcategorisa-tion Lexicon for German Verbs induced from a Lex-icalised PCFG.
In Proceedings of the 3rd Confer-ence on Language Resources and Evaluation, vol-ume IV, pages 1351?1357, Las Palmas de Gran Ca-naria, Spain.Sara Stymne and Nicola Cancedda.
2011.
ProductiveGeneration of Compound Words in Statistical Ma-chine Translation.
In Proceedings of the Sixth Work-shop on Machine Translation.Mihai Surdeanu, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using Predicate-ArgumentStructures for Information Extraction.
In Proceed-ings of the 41st Annual Meeting of the Associationfor Computational Linguistics, pages 8?15, Sap-poro, Japan.Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.2008.
Applying Morphology Generation Models toMachine Translation.
In Proceedings of the 46th An-nual Meeting of the Association for ComputationalLinguistics (ACL): Human Language Technologies.Giulia Venturi1, Simonetta Montemagni, SimoneMarchi, Yutaka Sasaki, Paul Thompson, John Mc-Naught, and Sophia Ananiadou.
2009.
Bootstrap-ping a Verb Lexicon for Biomedical InformationExtraction.
In Alexander Gelbukh, editor, Linguis-tics and Intelligent Text Processing, pages 137?148.Springer, Heidelberg.Philip Williams and Phillipp Koehn.
2012.
GHKM-Rule Extraction and Scope-3 Parsing in Moses.
InProceedings of the 7th Workshop on Statistical Ma-chine Translation, ACL.Dekai Wu and Pascale Fung.
2009a.
Can SemanticRole Labeling Improve SMT?
In Proceedings of the13th Annual Conference of the European Associa-tion for Machine Translation (EAMT).Dekai Wu and Pascale Fung.
2009b.
Semantic Rolesfor SMT: A Hybrid two-pass Model.
In Proceed-ings of the North American Chapter of the Associa-tion for Computational Linguistics and Human Lan-guage Technologies Conference (NAACL-HLT).603
