Proceedings of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP 2009, pages 3?10,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPThe Development of a Question-Answering Services System forthe Farmer through SMS: Query AnalysisMukda Suktarachan,Patthrawan RattanamaneeDepartment of Computer Engineer-ing, Kasetsart University, Bangkok,Thailand, 10900naist_da_da@yahoo.com,tiptop317@hotmail.comAsanee KawtrakulDepartment of Computer Engineering, KasetsartUniversity, Bangkok, Thailand, 10900National Electronics and Computer TechnologyCenter, Thailandasanee_naist@yahoo.comasanee.kawtrakul@nectec.or.thAbstractIn this paper, we propose the development ofthe Question-Answering Services System forthe Farmer, through SMS, by focusing onquery analysis and annotation based on a simi-lar technique previously applied to languagegeneration, thematic roles, and primitive sys-tems of the Lexical Conceptual Structure(LCS).
The annotation places emphasis on thesemantics model of ?What?
and ?How?
que-ries, lexical inference identification, and se-mantic role, for the answer.
Finally, we showhow these annotations and inference rules con-tribute to the generalization of the matchingsystem over semantic categories in order tohave a large scale question-answering system.1    Challenges and GoalsIn the era of Information and CommunicationsTechnology (ICT), mobile is a fast and conven-ient way to communicate over a network.Knowledge service via a mobile as ?a right in-formation for a right man?
is a challenging task.However, this means of interchange betweenpersons has the limitation of personal timing.Therefore, Short Message Service (SMS) is abetter way for giving knowledge service, espe-cially automatic interchange of short text mes-sages, by providing the information from anautomatic Question & Answering System.From the results of the statistical ICT datasurvey concerning the number and percent of thepopulation 6 years of age and over who use in-formation and communication technology: 2003- 2007 by the National Statistical Office1, Thai-land, it was found that  47.2% of people in theentire kingdom have owned their mobile(s).Consequently, communicating via SMS facili-tates an effective knowledge service for support-ing the farmers in problem-solving, decisionmaking, and early warning, and also supports thegovernment, or a related organization, in order toe-communicate to the farmer by changing themodel of ?Training and Visit?
to e-service andchanging the collective to support cooperativeproblem solving.
This kind of communicationwill provide the necessary long-term cost reduc-tions to the agricultural economy in the areas oftravel, visiting, productivity, etc.Nowadays, providing a knowledge servicethrough SMS is not limited to only a Question-Answering Services System, but also for suchone-way services as early warning systems, forexample, a Tsunami Alert System2, a FloodSMS?
Early Detection and Warning of CatastrophicFlooding via SMS3, etc.The development of a Question-AnsweringServices System through SMS is not the designof a new technology.
There have been severaltheories developed earlier, in the context of NLPor cognitive sciences, such as Natural LanguageInformation Retrieval (NLIR), rule based Q&A,etc.
Nevertheless, some former theories of Q&Arelied on complex semantic information.
For in-stance, a Wireless Natural Language Search En-gine [6] was implemented using a system resid-1  http://web.nso.go.th/en/survey/keystat/keystat08.pdf2  http://www.wap.ait.ac.th/tsunami.html3  http://www.netsquared.org/projects/floodsms-%E2%80%93-early-detection-and-warning-catastrophic-flooding-sms3ing on a server, which can translate questions orphrases into search engine queries or queries toSOAP Web services, where a gateway mediatesbetween the mobile network and the Internet.Also, [15] developed the SMS for Question-Answering in the m-Learning Scenario Systemby using the Simple Matching Algorithm tomatch the learners?
answer messages with theoriginal answer string, thus facilitating the learn-ers to get the necessary feedback and assessment.In this paper, we propose the development ofthe Question-Answering Services System for theFarmer through SMS by focusing on queryanalysis and annotation, as well as on selectedtext matching utilizing lexical inference and se-mantic roles.
The annotation emphasizes the se-mantics model of ?What?
and ?How?
queries.Finally, we show how these annotations and in-ference rules contribute to the generalization ofthe matching system over semantic categories inorder to have a large scale question-answeringsystem.In the current stage, we have designed Q&Aschema with thematic roles and have borrowedsome primitive systems of the Lexical Concep-tual Structure (LCS).
Also, we are annotating1000 questions and text related to the query (butwe randomly choose 100 pairs of Q&A for theexperiment).
In the same time, we are generaliz-ing inference rules in order to match a questionto its answer.
This is particularly crucial whenthere is no straightforward response, e.g.
whenthey require some form of lexical inference,elaboration, and reasoning or when the responseis not a simple item, but a well-formed fragmentof text, e.g.
a chain of events leading to a conse-quence, a procedure, etc.The project we present here emerged from aneed of the real end-users, the Agricultural LandReform Office, Ministry of Agriculture and Co-operative, Thailand, in the project of ALRO Cy-berBrain [3], which is a social network frame-work that combines approaches based on knowl-edge science and engineering with language en-gineering, consisting of an ontology-based searchengine, information extraction for Q&A system,knowledge aggregation through a knowledgeportal and visualized in a browser with semanticlinks between problems, methods of problemssolving and man who is the problem solver(PMM map Model) [1].
The main goal is to de-velop tools for e-Farming, in particular rice farm-ing, so that farmers can easily get information onfarming rice and rice diseases.
Now, it has beenextended to provide question-answering servicesfor the farmers through SMS [2].2    Problem StatementsThere are two main problems in Q&A analy-sis: semantic interpretation for a question wordand answer identification.2.1    Question?s Semantic Roles2.1.1    Question Word Interpretation.In general, when we query for the answer by atraditional search engine system, we might getmany answers at different levels, depending onthe role of the question: Definition vs Fact or setof Facts.
For example, with the questionQ1: ????|????|???|????
?Rice| Blast| is| what?What is a Rice Blast?
?The answer can be returned as the definitions,fact or a set of facts, which are:A1.1: Blast, also called rotten neck, is one of themost destructive diseases of Missouri rice.Blast does not develop every year but isvery destructive when it occurs.4A1.2:   Disease of Leave Burnt caused by Pyricu-laria Oryzae can destroy all rice growingperiod  from start until harvest period.5The answer can be returned as the characteris-tics detail or set of facts, such as the following:A1.3 : Blast symptoms can occur on leaves,leaf collars, nodes and panicles.
Leaf spots aretypically diamond shaped, with gray- white cen-ters and brown to red-brown margins.
Fully de-veloped leaf lesions are approximately 0.4 to 0.7inch long and 0.1 to 0.2 inch wide.
Both theshape and color vary depending on the environ-ment, age of the lesion and rice variety.62.1.2    Variety of Question Forms.In natural language, the question can be askedwith different words and styles, for example:Q2.1:??????|????????|???|???|????|????|??????
?situation| outbreak| of| disease| Rice Blast|is| how?What is the situation of Rice Blast??Q2.2:????????|???|???|????|??|??????|??????
?outbreak| of| disease| Rice Blast| is| characteristic| how?How does the rice blast outbreak look like?
?4  http://aes.missouri.edu/delta/muguide/mp645.stm5  http://www.sotus.co.th/article_4.html6  http://aes.missouri.edu/delta/muguide/mp645.stm4Q2.3:???|????|?????|???|??????
?Rice Blast| disperse| able| how?How can the rice blast disperse?
?The reply can be returned the same answerswith a descriptive set of events, as the following:A2.1: To prevent the Rice Blast: for the placesthat we often found the disease, use the dis-ease-resistant rice variety.
Don't sow therice seed too densely.
Don't use to much Ni-trogen.
If it is severe outbreak and it is thestate of young plant, plow and sow again.
Ifit was the epidemic state, use Fungus-Removal chemical as Carbendasim.A2.2: Brown spot may be reduced by balancedfertilization, crop rotation, and the use ofhigh quality planting seed.
Seed treatmentfungicides reduce the incidence and severityof seedling blight caused by this fungus.The examples above show that using differentverbs or noun phrases can be represent the samemeaning.
Moreover, there is non-correspondentfocus word between Q and A.2.2    Answer Type Identification2.2.1    Ambiguity between subtopic and an-swer formTo identify the answer, sometimes there is anambiguity that verb phrases occurring after thefocus word of the question can be both subtopicsand the answer, like a procedural answer, forexample,:Q3: ???????|???????|???|????|???|???|??????
?method| control| Rice Blast| to do| how?What method can be used to control RiceBlast?
?A3:  ???????|???????|???|????|??|?????
?method| control| Rice Blast| have| such as?Methods for preventing the Rice Blast are:??
???|???????|???|??????
?use| Chemical Substance | that| appropriate?Use appropriate Chemical Substance.??
???|??????|???|??????
?use| type of rice | that| appropriate?Use appropriate type of rice.??
???|????|??|???|??????
?use| mechanism| in| prevent?Use mechanism to prevent.??
???|???????|??????
?use| methods| hybrid?Use hybrid  methods.
?The examples above convey the 4 types ofmethod for Rice Blast control or names of meth-ods, but it is not the process or the answers thatrepresent how to control the disease.2.2.2    Non-correspondence between Q & A:Sometimes, the question and answer were notmatched because the clue words or focus wordsin the question have never appeared in the an-swers.
This makes the question not correspond tothe answer and also causes difficulty in findingthe expected answer.
For example,Q4: ??????|??????|????|?????|????|????????|???|??????
?can| control| pests | rice | these | How?How can these rice pests be controlled?
?A4: ????|?????|????????|??????|??????|???|???|???|???????|????|??????|???|??
?| |??
?| |????|????|??????|???????|??
?|,| |????|????|???|?????
?|, |??????|?????|????|??|??
|???|???|???|???|???|???|????|???|???|???|????|???|?????|?????||???|??
?|?These pests can be managed through inte-grated approach including sowing insect re-sistant rice varieties, sowing rice crop at rec-ommended time, proper water managementconservation and augmentation of bio-controlpredators.
?From the example, the focus word of thequestion is ?control,?
but there is no word ?con-trol?
in the answer.
For this kind of Q&A match-ing solution, WordNet and ontology are neces-sary.3    Outline of the Project and Methodol-ogyThe needs of the Thai Ministry of Agriculturehave been specified in a simple way via a corpuscomposed of (1) questions raised in real life byfarmers (about 1000 questions), (2) the responseswhich have been provided by experts, based onexisting documents (possibly several responsesper question) and, quite often, (3) the texts theyoriginate from.
In general, the response is foundin a unique text: there are no multiple answers,since most texts are not redundant, althoughsome responses, in particular complex (e.g.evaluative questions) or indirect ones, may in-volve the taking into account of several inde-pendent texts.
We will not address here the prob-lem of message length reduction so that it fitsinto an SMS format (although this is also an im-portant semantic problem).The system overview is shown in Figure 2.5Figure 2.
System ArchitectureTo develop a Thai QA system, the preprocess-ing of Thai morphology and syntax is necessary.The NAIST lab at the University of Kasetsart hasbasic tools to manage morphological analysis,parts-of-speech recognition, simple syntacticanalysis, as well as Thai parsing, and an ElementDiscourse Unit System (EDU).
These tools weredesigned as basic tools in natural language proc-essing applications.
(accessible onhttp://vivaldi.cpe.ku.ac.th:9292/ with a recom-mendation to use the Mozilla Firefox browser)A few examples of question-answer pairs are:Q5:  ???????|???????|??????|????|??????|???|???|???????
?How to prevent the Weedy rice?A5.1: ???|????|????|????|???|???
?Skip some seasons when growing rice,?A5.2: ????|???|???|?????|????
?Grow hydrotonics plants.
?Q6:  ???|??|???|?????|???|??|???????|??????|???????
?How to control the Bacterial LeafStreak  Disease?A6: ???|???|???|????|????????|???|?????
?|?Do not put too much Nitrogen.
?Q7:  ???|??|??????|??|????
?| |??????|??????|????|???|???|????|????|??
?How to eradicate the rice thrips?A7:  ???|???|????|?????????|????|?????????|???|??????
?|  |???|????|???|???|????|??
?| |?| |???|???
?Spray with Malathion or Carbarylevery week, add fertilizer and waterevery two days.
?Questions are essentially factoid questions(e.g.
best periods for rice planting, rice varietiessuggestion, symptoms of a disease), why ques-tions, where responses are chains of events (rea-sons for something to happen) and a large num-ber of procedural questions [4], in particular fortreating diseases.
There are relatively few com-parative or evaluative questions besides generalquestions, such as: What are the major ricepests?In most cases, questions do not have responseswhich can be immediately found in the texts bystandard term matching techniques.
For example:?How does the Sheath Blight affect the ricegrowth??
has the following response in a text:Plants heavily infected at these stages producepoorly filled grain, particularly in the lower por-tion of the panicle.
Additional losses result from...
Therefore, some lexical semantics devices(e.g.
a semantic link between affect and infect) ormore elaborated reasoning schemas, based ondomain knowledge, are needed to allow appro-priate question-text matching [11, 7].
The kind ofdomain knowledge at stake may be quite unex-pected (i.e., not the main topics that everyoneknows, but more subtle pieces of information, aswill be seen in 4.3).
This is the major challengeof this work, which we try to resolve via a fullannotation of the matching process, from ques-tion parsing to response production, identifyingmatching and reasoning aspects.Complex questions may, e.g., require theelaboration of a diagnosis from premises given inthe question before finding the response, eitherfactoid or procedural (My rice has weedy leavesand some yellow spots, what should I do?).
Thisquestion requires one to select all texts wheresuch a symptom is identified, and then, e.g., toenter into a dialogue with the user if there areseveral possible diagnoses, leading to differenttreatments.The second aspect of this problem is to be ableto extract the complete text portion that respondsto the question.
For that purpose we are develop-ing an annotation methodology whose goal is toidentify the different processes at stake and theneeded resources.
This method allows us to iden-tify relevant text portions and then to delimitthem appropriately.4    The Question-Answering Process An-notationSince the task is quite large (a large group of stu-dents are annotating a set of 600 questions andrelated texts), we need to establish norms andannotation guidelines.
Using the research con-ducted at IRIT on annotating procedural ques-tions and instructions based on semantic rolesQuestionQuestion Analysisand AnnotationWordNetOntologyQ&A Matching andAnswer GenerationPreprocessing ProcessWord SegmentationPOS TaggingName Entities RecognitionEDU SegmentationText Analysis and AnnotationDocument IndexingTitles RecognitionText Annotation6(TextCoop project) and a few rhetorical relations(e.g.
elaboration, example, explanation), we firstannotated the questions and their correspondingresponses in texts provided by the Thai Ministryof Agriculture.
One of the challenges was toidentify relevant linguistic marks or patterns [9,10, 14].There are many attempts to annotate argu-ments by means of primitives; our approach,here, is oriented towards the precise task at stakeand the specific actions.
Therefore roles are notas standard as they are in general.
An earlier at-tempt with a similar technique applied to lan-guage generation was carried out in, e.g., [10, 7].Semantic tags are either close to thematic roles(instrument, location, etc.)
[8], or borrowed fromthe primitive systems of the Lexical ConceptualStructure (LCS) [13], in particular, to establishuseful links between arguments or between alarge variety of constituents, which thematicroles cannot do.
For example, in the first Thaiuniversity we have a link between 'first' and 'Thaiuniversity' which is either loctemp or loc+char+ident,depending on the interpretation of first (oldest orthe best).
However, in a majority of cases, se-mantic roles based on thematic roles have a suf-ficient granularity, and these are the ones whichare used in the examples in 4.1.The main roles we consider are: agents (forhumans and animals like insects, and metaphori-cally for diseases and natural forces), themes(undergoing actions, basically plants and soils,and artificial products), location (spatial), time(covering dates and also periods), instruments(from tools to chemical products), manners,means, conditions (under which to realize an ac-tion, or related to observation e.g.
of a disease),cause, goals, and results.Besides, the tags <action>?</action> or<fact>?</fact> were considered to tag the verbwith it?s arguments or adjuncts.In the remainder of this section we briefly re-port the different steps of the process as theystand at the moment, i.e.
almost at the end of theexperimental stage, before automating knowl-edge acquisition, and implementing the applica-tion.4.1    Dealing with QuestionsAs in most systems dealing with complex typesof questions, questions are represented by a tri-ple: the question type (which can be in our casepolymorphic), the question focus (usually an NPor a VP in case events or procedures are induced)and the question body, annotated by means ofsemantic roles, as indicated above.The main types of questions we have identi-fied from our corpus are the following; they arequite different from standard classifications, butthey correspond to more operational views:F: fact, with subtypes: temp (temporal, time,date), loc (location) or product,E: an event (with a subtype event: cause)SF: set of factsSE: set of events (not related, and without anyform of sequence: different from SqE be-low)PROC: procedure, more or less complex, itmay be just a single instruction; it can alsodescribe the use of an instrument.SqE: sequence of events, which follow eachother.EVAL: evaluation, making value decisionsabout issues or resolving controversies ordifferences of opinion.DEF: definition, the description of object.Some questions may bear several non-conflicting types, in particular when the nature ofthe response is not straightforward to determinefrom the question.
For example, ?What is thesymptom of Bakanae??
would get the types SFand SE.An annotated question is, for example:As can be noted, the response is the set ofthose facts that contribute, together or independ-ently, to the spreading of the disease.By the observation from 100 random inter-rogative sentences corpus analysis, we found thatthe semantic types of questions correspondent tothe question words are the followingQ-Types What When Where Why Who Which HowF 11 6 1   1 9 2E       1     6SF 3         15 3SE 7         2 5PROC             15SqE             7EVAL 2       1DEF 3Table 1 the correspondence between questionsand semantic types of questionsFrom Table 1, it is clear that ?what?
and?how?
questions vary in types of question, be-cause they have many forms to use, for example,?how + verb to be + noun?, ?how + do(es) +noun + verb?, ?how to?, ?how can?, etc.
or?what + verb to be + noun?, ?what + noun +auxiliary verb?, etc.
This is why we point out the?What?
and ?How?
questions.<question type=?
SF or SE?
focus=?
symptom ofBakanae?> What <fact> is <theme> the symp-tom of Bakanae </theme> </fact> ?
</question>74.2    Dealing with texts: document indexingand associated annotationsTexts are initially indexed based on the mainterms they contain which are relevant w.r.t.
thequestions given in the corpus.
Our representationresembles a frame approach, but it is moreflexible since there is no predefined structure torepresent indexes.
This is more in accordancewith the variety of texts in terms of contents.
In-dexes basically are formed from:?
Top-level terms that structure the domain:for example, concepts like symptom,spreading, treatment, time, place, effect,etc.
where predicative (action terms) termsas well as entities are found,?
relatively generic terms, found in thequestions and structured in the domain on-tology: water, clean, control, eradicate,etc., which are organized w.r.t.
the topconcepts above,?
named entities, typed as: disease names,location names, chemical product names,bacteria names, etc.In our representation, those generic terms (andnear synonyms) are represented as predicates,while arguments are represented as attribute-value pairs (or attributes alone), include typedname entities and any kind of terms besides thegeneric terms.Indexes are associated with texts in the textdatabase.
Indexes must remain general so thatindexing is fast and as reliable as possible.
Theidea is that when a question is uttered, a smallnumber of texts are first selected on the basis ofthe indexes for further analysis.
An examplebelow can be indexed and annotated [2] as thefollowing:Index: disease-name (Bakanae), symptoms (disease: Bakanae),origin (disease: Bakanae, place: California, date: 1999), spread-ing(disease: Bakanae, period: winter, medium: [soil, water]), treat-ment(disease: Bakanae, product).<title type=?goal?
level=?1?
> Rice Bakanae </title><title type=?goal?
level=?2?>SYMPTOMS </title><task type = ?SF?><theme>Symptoms of Bakanae</theme> first appear about amonth after planting.
Infected seedlings appear to be taller, moreslender, and slightly chlorotic ...
The rapid elongation of infectedplants is caused by the pathogen?s production of the plant hormone,gibberellin.....</task><title type=?goal?
level=?2?>COMMENTS ON THE DISEASE</title>Bakanae is one of the oldest known diseases of rice in Asia but hasonly been observed in California rice since 1999 and now occurs inall California rice-growing regions.
While very damaging in Asia,the extent to which Bakanae may effect California rice productionis unknown.
As diseased plants .....4.3   Matching selected texts with questions:the deep indexing levelThe main words of the question focus and bodyare used to select a subset of indexed texts aspotential candidates containing the response.Then, in each of these texts, the few sentenceswhere the terms of the question or derived terms(closely related terms) are effectively found areannotated by means of semantic roles as for thequestion, for further analysis and investigations.For that purpose, we have developed guide-lines for annotating those text fragments wherethe response is and the associated knowledge,based on the same semantic roles as those usedin the questions.
These annotations remain so farexploratory, in terms of feasibility and automa-tion.
Our major concern is to develop a methodfor annotators so that a large number of texts canbe tagged homogeneously and also so that thetechnique can be reproduced for other technicalareas.
Finally, in terms of response identification,the goal is to define a metric that defines the bestmatch and selects the text fragment(s) that bestrespond(s) to the question among several poten-tial candidates.Let us first consider a simple example.
Giventhe question:Q8: ?How to eradicate Bakanae ?
?with the following representation:The main terms of the question are ?eradicate?and ?Bakanae?.
The text above is therefore se-lected on the basis of its indexes, because ?treat-ment?
is a closely related term (in terms of se-mantic relation: ?way to realize an event?)
of?eradicate?
in the domain ontology.Then, the question terms are searched in theselected text and the sentences that contain themare annotated using semantic roles.
For example,the following sentence is a candidate:The most effective means to treat this diseaseis the use of noninfested seeds.It is tagged as:<title type=?goal?
level=?2?>MANAGEMENT</title><task type = ?PROC?>The most effective means to<action> treat <theme> this disease</theme> </action> is the <instruction compound><instructiontype="imperative">use of noninfested seed</instruction>.Also,<connector type="advice"> when possible</connector>, <ad-vice>burning plant residues</advice> with known infection in fallmay help limit the disease.
..... Field trials indicate that a seed treat-ment with sodium hypochlorite (Ultra Clorox Germicidal Bleach) iseffective at reducing the incidence of this disease.... </instructioncompound></task><question type=?PROC or SqE?
focus ?eradi-cate Bakanae?
> How to <action> eradicate<theme> Bakanae </theme>  </action> ?</question>8The answer is the above sentence and the textfragment that follows (introduced by the connec-tor also) since the response is of type procedure:The most effective means to treat this diseaseis the use of noninfested seed.
Also, when possi-ble, burning plant residues with known infectionin fall may help limit the disease.Following [5], this structure is annotated as asingle instructional compound, which is the fun-damental unit in a procedural text.
This is thestructure which is typically returned to users.Let us present here another illustrative exam-ple of a text fragment where the response is an-notated together with the required related reason-ing elements:Q9: ?How can thrips destroy the rice ?
?annotation:The text fragment that corresponds to the an-swer is annotated as follows:To match the action ?destroy?
in the questionwith the text portion from which the response isextracted, it is then necessary to identify the in-ference:This example shows that (1) in the questionand in the answer, annotations are used to iden-tify the different components, arguments, ad-juncts, but also some other components (e.g.temporal adverbs), and (2) the annotation is de-veloped to characterize the matching steps andinferential components (either lexical or domainknowledge) between the question and the an-swer.
This latter form of annotation, which isquite time-consuming to develop, is the meanswe use to induce and develop domain dependentforms of lexical inference (or other phenomenalike synonymy, lexical equivalence, etc.)
andrelevant domain knowledge.
The types and lexi-cal functions which are introduced are then usedin the process of induction of generalizationsover some semantic categories (plants, products,etc.
), and verb classes.
This way of annotatingknowledge and inferences is obviously a simplebottom-up process, with well known limitations,but we feel it may have some advantages for in-ducing an upper organization of knowledge, inconjunction, and as a complement to, the domainontology.
It is also simple and accessible to an-notators.
Obviously this remains to be evaluated.4.4  Generalizing inferences for question-answer matchingAt this level, the inferences which may be drawnare directly attached to the terms which aretagged.
This is obviously too limited.
We arenow experimenting with different generalizationstrategies in order to tune the lexical inferencerules.
This process involves:(1) developing various generic principles overdifferent types and categories (via the domainontology), We will annotation the title for match-ing the ?theme?
of the answer to the ?theme?
and?Focus?
of the question by using word net andontology as shown below.Surface Form Conceptdestroy, destruct, eliminate, kill,?
destroytreat, prevent, eradicate, protect,?
managesuck, eat, bite, drink,?
consumespread out, diffuse, disperse,?
spread(2) a set of principles that limit these generali-zations via, for example, the taking into accountof the semantics restrictions imposed by lexicalitems, in particular verbs.
The main words of thequestion focus and text body that already anno-tated will be considered for extracting the poten-tial candidates containing the response.
The sen-tences, where the terms of the question or de-rived terms (closely related terms) are effectivelyfound, will be the corresponding answer by usingmatching function as shown below.Function Matching (Question Q, Answer A){Match = false;// Relevant documentIf  (Q.focus  =  A.index)  then// Relevant answerIf  (Q.type =  A.task type) then//Detect Answer for the QuestionIf (Q.focus = A.title) thenMatch = true;Else if (Q.action = A.action andQ.theme = A.theme orQ.agent = A.agent) thenMatch = true;End IfEnd IfEnd IfReturn Match;}The tuning of the level of these generalizationsis obviously one main parameter of our project.It has several conceptual dimensions that we ex-plore and may also be domain dependent.<lex_inference>  <action> Suck sap of X</action>  <entail>  <modality> probably</modality>  <action> destroy X </action></entail> ,  <type> X : plant </type><part-of> sap : X </part-of >  </lex inference><response>  <agent> The rice thrips</agent><action>  sucks the sap <source>  from the youngplant.
</source> </action> </response><question type=?SqE?
focus = ?destroy?>Howcan <agent> thrips </agent> <action>destroy<theme>the rice</theme> </action>?</question>?<action> treat <theme> this disease </theme>is the use of <instrument> noninfested seeds</instrument> </action> .9PerspectivesThe matching problem between questions anddocuments to retrieve answers in question-answering systems in concrete applicative con-texts is often a difficult problem.
This matchingprocedure often requires very accurate domainknowledge, besides ontological descriptions.
It isnot always easy to access this knowledge in astructured way or to extract it from texts.
Thepresent contribution, still experimental and in anearly stage of development, is an attempt, viaannotations, at resolving this problem, followinga simple and clear methodology.This task needs to be developed and evaluatedgradually.
So far, it is too early to evaluate thequality of the generalizations and the inferentialpatterns we get.This approach, and the principles we havebriefly outlined, allow us to introduce a workingmethod for the development of question-answering systems for concrete applications, es-pecially for non-factoid questions, an area whichis still not very much developed in spite of itsobvious usefulness.
One of the reasons is thatnon-factoid questions require a language proc-essing technology, analysis methods, reasoningaspects, and a conceptual approach, which aresubstantially different from what is used for fac-toid questions.AcknowledgmentsThe work described in this paper has been sup-ported by the NECTEC No.
NT-B-22-KE-12-50-19, within the project, ?I-KnowII: CAT, EAT,RATs,?
and ?Agricultural Question & Answer-ing Service System,?
granted by the KURDI,Kasetsart University.
We would like to espe-cially thank Prof. Patrick Saint Dizier for origi-nating, advising and collaborating in the devel-opment of Q&A system.
We also thank Prof.William I. Grosky for helping to revise our Eng-lish.References1.
Asanee Kawtrakul, et al Chaveevan Pechsiri, Sa-chit Rajbhandari,  Frederic Andres, Problems-Solving Map Extraction with Collective Intelli-gence Analy-sis and Language Engineering , BookChapter 18, Medical Information Science Refer-ence in Information Retrieval in BiomedicineISBN: 978-1-60566-274-9; pp 4602.
Asanee Kawtrakul, et al 2009.
From CyberBrain toQ&A Services: A Development of Question - An-swering Services System for the Farmer throughthe SMS, WCCA2009, Grand Sierra Resort, Reno,Nevada, USA.3.
Asanee Kawtrakul, et al 2008.
?CyberBrain: To-wards the Next Generation Social Intelligence?IAALD AFITA WCCA 2008, Tokyo, Japan.4.
Dan Moldovan, Sanda Harabagiu, Marius Pasca,Rada Mihalcea, Roxana Girju, Richard Goodrum,Vasile Rus.
2000.
The Structure and Performanceof an Open-Domain Question Answering System,Proceedings of the 38th Meeting of the Associationfor Computational Linguistics (ACL), Hong Kong.5.
Estelle Delpech, Patrick Saint-Dizier.
2008.
Inves-tigating the Structure of Procedural Texts for An-swering How-to Questions, LREC2008, Marra-kech.6.
Jochen L. Leidner, 2005.
A wireless natural lan-guage search engine.
Proceedings of the 28th an-nual international ACM SIGIR conference on Re-search and development in information retrievaltable of contents: 677 ?
677, ACM,  New York,USA7.
Judy Delin, Anthony Hartley, Cecile Paris,  DoniaScott, Keith Vander Linden.
1994.
Expressing Pro-cedural Relation-ships in Multilingual Instructions,Proceedings of the 7th International Workshop onNatural Language Generation: 61-70, Maine, USA.8.
Karen Sparck Jones, Branimir Boguraev.1987.
Anote on a study of cases, research note in Computa-tional Linguistics archive, Volume 13 ,  Issue 1-2(January-June 1987) : 65 - 68.9.
Leonard Talmy.
1976.
Semantic Causative Types,In M. Shibatani (ed.
), Syntax and Semantics 6: TheGrammar of Causative Constructions.
New York:Academic Press: 43-116.10.
Leonard Talmy.
1985.
Lexicalization Patterns:Seman-tic Structure in Lexical Forms, in LanguageTypol-ogy and Syntactic Description 3: Grammati-cal Categories and the Lexicon, T.
Shopen(ed.
),57-149, Cambridge University Press.11.
Mark Thomas Maybury.
2004.
New Directions inQuestion Answering, The MIT Press, Menlo Park.12.
Mineki Takechi, Takenobu Tokunaga, Yuji Ma-tsumoto, Hozumi Tanaka.
2003.
Feature Selectionin Categorizing Procedural Expressions, The 6thInternational Workshop on Information Retrievalwith Asian Languages (IRAL2003):49-56.13.
Ray Jackendoff.
1990.
Semantic Structures, MITPress.14.
Robert E. Longacre.
1982.
Discourse Typology inRelation to Language Typology, Sture Allen ?ed.,Text Processing, Proceeding of Nobel Symposium51, Stockholm, Almquist and Wiksell, 457-486.15.
Sadhu  Balasundaram  Ramakishnan andBalakrishnan  Ramadoss.
2007.
SMS for Question-Answering in the m-Learning Scena-rio, Journal ofComputer Science 3(2):119-121.10
