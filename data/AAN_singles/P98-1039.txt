Hybrid Approaches to Improvement of Translation Qualityin Web-based English-Korean Machine TranslationSung-Kwon Choi, Han-Min Jung,ChuI-Min Sim, Taewan Kim, Dong-In ParkMT Lab.
SERI1 Eoun-dong, Yuseong-gu,Taejon, 305-333, Korea{skchoi, jhm, cmsim, twkim, dipark}@seri.re.krJun-Sik Park, Key-Sun ChoiDept.
of Computer Science, KAIST373-I Kusong-dong, Yuseong-gu,Taejon, 305-701, Koreajspark@world.kaist.ac.krkschoi@cs.kaist.ac.krAbstractThe previous English-Korean MT systemthat was the transfer-based MT system andapplied to only written text enumerated afollowing brief list of the problems that hadnot seemed to be easy to solve in the nearfuture : 1) processing of non-continuousidiomatic expressions 2) reduction of toomany ambiguities in English syntacticanalysis 3) robust processing for failed or ill-formed sentences 4) selecting correct wordcorrespondence b tween several alternatives5) generation of Korean sentence style.
Theproblems can be considered as factors thathave influence on the translation quality ofmachine translation system.
This paperdescribes the symbolic and statistical hybridapproaches to solutions of problems of theprevious English-to-Korean machinetranslation system in terms of theimprovement of translation quality.
Thesolutions are now successfully applied to theweb-based English-Korean machinetranslation system "FromTo/EK" which hasbeen developed from 1997.IntroductionThe transfer-based English-to-Korean machinetranslation system "MATES/EK" that has beendeveloped from 1988 to 1992 in KAIST(KoreanAdvanced Institute of Science and Technology)and SERl(Systems Engineering ResearchInstitute) enumerated following list that doesn'tseem to be easy to solve in the near future interms of the problems for evolution of thesystem (Choi et.
al., 1994) :?
processing of non-continuous idiomaticexpressions?
generation of Korean sentence style?
reduction or ranking of too manyambiguities in English syntactic analysis?
robust processing for failed or ill-formedsentences?
selecting correct word correspondencybetween several alternativesThe problems result in dropping a translationassessment such as fidelity, intelligibility, andstyle (Hutchins and Somers, 1992).
They can bethe problems with which MATES/EK as well asother MT systems have faced.This paper describes the symbolic and statisticalhybird approaches to solve the problems and toimprove the translation quality of web-basedEnglish-to-Korean machine translation.1 System OverviewEnglish-to-Korean machine translation system"FromTo/EK" has been developed from 1997,solving the problems of its predecessor"MATES/EK" and expanding its coverage toWWW.
FromTo/EK has basically the sameformalism as MATES/EK that does Englishsentence analysis, transforms the result (parse251U serI n ter faceTrans la t ion  Eng ineEngL:'I?
H "" Re n Ler  Ana l,u \ [ l?
l l~f  ,o f t rn~r..........
I t  = ....
I I( 'o re  pound E lVlII,*R ?
I~ l la~l  I T I" t 'n i l  " P I r I I r  zer  ~ .
.
.
.
.
.
.
.
; .
.
.
.x., I K.,~,.,,r,,r t -~  ~'nn','lrx~rPr 'Knowledge  and D ic t ionaryUserI n ter faceFigure 1: The System Configuration of FromTo/EKtree) into an intermediate representation, andthen transforms it into a Korean syntacticstructure to construct a Korean sentence.
Figure1 shows the overall configuration of FromTo/EK.FromTo/EK consists of user interface forEnglish and Korean, translation engine, andknowledge and dictionaries.
The black boxes inthe Figure 1 mean the modules that have existedin MATES/EK, while the white ones are the newmodules that have been developed to improvethe translation quality.
Next chapters describethe new modules in detail.2 Domain Recognizer and Koreansentence styleIn order to identify the domain of text andconnect it to English terminology lexicon andKorean sentence style in Korean generation, wehave developed a domain recognizer.We adapted a semi-automated decision treeinduction using C4.5 (Quinlan, 1993) amongdiverse approaches to text categorization such asdecision tree induction (Lewis et.
al., 1994) andneural networks (Ng et.
aL, 1997), because asemi-automated approach showed perhaps thebest performance in domain identificationaccording to (Ng et.
al., 1997).
Twenty-fivedomains were manually chosen from thecategories of awarded Web sites.
We collected0.4 million Web pages by using Web searchrobot and counted the frequency of words toextract features for domain recognition.
Thewords that appeared more than 200 times wereused as features.
Besides we added somemanually chosen words to features because thefeatures extracted automatically were not able toshow the high accuracy.Given an input text, our domain recognizerassigns one or more domains to an input text.The domains can raise the translation quality byactivating the corresponding domain-specificterminology and selecting the correct Koreansentence style.
For example, given a "driver", itmay be screw driver, taxi driver or device driverprogram.
After domain recognizer determineseach domain of input text, "driver" can betranslated into its appropriate Korean equivalent.The domain selected by the domain recognizer isable to have a contribution to generate a betterKorean sentence style because Korean sentencestyle can be represented in various ways by theverbal endings relevant to the domain.
Forexample, the formal domains uch as technology252and law etc.
make use of the plain verbal endinglike 'ta' because they have carateristics offormality, while the informal domains such asweather, food and fashion etc.
are related to thepolite verbal ending 'supnita' because they havecarateristics ofpoliteness.3 Compound Unit Recognitionparsing mechanism.
Partial parser operates oncyclic trie and simple CFG rules for the fastsyntactic constraint check.
The experimentalresult showed our syntactic verificationincreased the precision of CU recognition to99.69%.4 Competitive Learning GrammarOne of the problems of rule-based translationhas been the idiomatic expression which hasbeen dealt mainly with syntactic grammar rules(Katoh and Aizawa, 1995) "Mary keeps up withher brilliant classmates."
and "I prevent himfrom going there."
are simple examples ofuninterupted and interupted idiomaticexpressions expectively.In order to solve idiomatic expressions as well ascollocations and frozen compound nouns, wehave developed the compound unit(CU)recognizer (Jung et.
al., 1997).
It is a plug-inmodel locating between morphological andsyntactic analyzer.
Figure 2 shows the structureof CU recognizer.English ------~.
Morphological Analyzer ~ ,~ S)'atac " '.
.
.
.
CFG Grammar ,~Figure 2 : System structure of CU recognizerThe recognizer searches all possible CUs in theinput sentence using co-occurrence constraintstring/POS and syntactic onstraint and makesthe CU index.
Syntactic verifier checks thesyntactic verification of variable constituents inCU.
For syntactic verifier we use a partialFor the parse tree ranking of too manyambiguities in English syntactic analysis, we usethe mechanism to insert the competitiveprobabilistics into the rules.
To decide thecorrect parse tree ranking, we compare twopartial parse trees on the same node level withcompetitive relation and add ct (currently, 0.01)to the better one, but subtract ct from the worseone on the base of the intuition of linguists.
Thisresults now in raising the better parse tree higherin the ranking list of the parse trees than theworse one.5 Robust TranslationIn order to deal with long sentences, parsing-failed or ill-formed sentences, we activate therobust ranslation.
It consists of two steps: first,long sentence segmentation and then failsoftening.5.1 Long Sentence SegmentationThe grammar rules have generally a weak pointto cover long sentences.
If there are no grammarrules to process a long sentence, the whole parsetree of a sentence can not be produced.
Longsentence segmentation produces simplefrom long sentences before parsing fragementsfails.We use theclue of thesentencePOS sequence of input sentence as asegmentation.
If the length of inputexceeds pre-defined threshold,currently 21 for segmentation level I and 25 forlevel II, the sentence is divided into two or moreparts.
Each POS trigram is separately applied tothe level 1 or II.
After segmenting, each part of253input sentence is analyzed and translated.
Thefollowing example shows an extremely longsentence (45 words) and its long sentencesegmentation result.\[Input sentence\]"Were we to assemble a Valkyrie to challengeIBM, we could play Deep Blue in as manygames as IBM wanted us to in a single match, infact, we could even play multiple games at thesame time.
Now - - wouldn't that beinteresting?
"\[Long Sentence Segmentation\]"Were we to assemble a Valkyrie to challengeIBM, / (noun PUNCT pron) we could play DeepBlue in as many games as IBM wanted us to in asingle match, / (noun PUNCT adv) in fact, /(noun PUNCT pron) we could even playmultiple games at the same time, / (adv PUNCTadv) Now - - / (PUNCT PUNCT aux) wouldn'tthat be interesting?
"5.2 Fail SofteningFor robust translation we have a module 'failsoftening' that processes the failed parse trees incase of parsing failure.
Fail softening finds set ofedges that covers a whole input sentence andmakes a parse tree using a virtual sentence tag.We use left-to-right and right-to-left scanningwith "longer-edge-first" policy.
In case that thereis no a set of edges for input sentence in ascanning, the other scanning is preferred.
If bothmake a set of edges respectively, "smaller-set-first" policy is applied to select a preferred set,that is, the number of edges in one set should besmaller than that of the other (e.g.
if n(LR)=6and n(RL)=5, then n(RL) is selected as the firstranked parse tree, where n(LR) is the number ofleft-to-right scanned edges, and n(RL) is thenumber of right-to-left scanned edges).
We use avirtual sentence tag to connect the selected set ofedges.
One of our future works is to have amechanism to give a weight into each edge bysyntactic preference.6 Large Collocation DictionaryWe select a correct word equivalent by usinglexical semantic marker as informationconstraint and large collocation dictionary in thetransfer phase.The lexical semantic marker is applied to theterminal node for the relational representation,while the collocation information is applied tothe non-terminal node.The large collocation dictionary has beencollected from two resources; EDR dictionaryand Web documents.7 Test and EvaluationA semi-automated decision tree of our domainrecognizer uses as a feature twenty to sixtykeywords which are representative wordsextracted from twenty-five domains.
To raise theaccuracy of the domain identifier, manuallychosen words has been also added as features.For learning of the domain identifier, eachthousand sentence from twenty-five domains isused as training sets.
We tested 250 sentencesthat are the summation of each ten sentencesextracted from twenty-five domains.
These testsentences were not part of training sets.
Thedomain identifier outputs two top domains as itsresult.
The accuracy of first top domain shows45% for 113 sentences.
When second topdomains are applied, the accuracy rises up to75%.In FromTo/EK, the analysis dictionary consistsof about 70,000 English words, 15,000 Englishcompound units, 80,000 English-Koreanbilingual words, and 50,000 bilingualcollocations.
The domain dictionary has 5,000words for computer science that were extractedfrom IEEE reports.In order to make the evaluation as objective aspossible we compared FromTo/EK withMATES/EK on 1,708 sentences in the IEEEcomputer magazine September 1991 issue,which MATES/EK had tested in 1994 and254whose length had been less than 26 words.
Table1 shows the evaluation criteria.Table 1 : The evaluation criteriaDegree Meaning4 The meaning of the sentence is(Perfect) perfectly clear.3 (Good)2 (OK)The meaning of the sentence isalmost clear.The meaning of the sentence can beunderstood after several readings.1 (Poor) The meaning of the sentence can beguessed only after a lot of readings.0(Fail) The meaning of the sentencecannot be guessed at all.With the evaluation criteria three master degreestudents whom we randomly selected comparedand evaluated the translation results of 1,708sentences of MATES/EK and those ofFromTo/EK.
We have considered the degrees 4,3, and 2 in the table 1 as successful translationresults.
Figure 3 shows the evaluation result.tSumh~ d mo~,~lb.Inmlll~l m )1000 ~4 5 6 7 8 9 lO 11 12 13 14 15 16 1"7 18 19 20 21 ~' 23 24Figure 3 : The evaluation of 1,708 sentencesFigure 3 shows a translation quality of bothFromTo/EK and MATES/EK according to thelength of a sentence.
More than 84% ofsentences that FromTo/EK has translated isunderstood by human being.8 ConclusionIn this paper we described the hybrid approachesto resolution of various problems thatMATES/EK as the predecessor f FromTo/Ekhad to overcome.
The approaches result inimproving the translation quality of web-baseddocuments.FromTo/EK is still under growing, aiming at thebetter Web-based machine translation, andscaling up the dictionaries and the grammaticalcoverage to get the better translation quality.ReferencesChoi K.S., Lee S.M., Kim H.G., and Kim D.B.
(1994) An English-to-Korean MachineTranslator: MA TES/EK.
COLING94, pp.
129-133.Hutchins W.J.
and Somers H.L.
(1992) AnIntroduction to Machine Translation.Academic Press.Jung H.M., Yuh S.H., Kim T.W., and Park D.I.
(1997) Compound Unit Recognition forEfficient English-Korean Translation.Proceedings of ACH-ALLC.Katoh N. and Aizawa T. (1995) MachineTranslation of Sentences with Fixed Expression.Proceedings of the 4 th Applied NaturalLanguage Processing.Lewis D.D.
and Ringuette M. (1994) Acomparison of two learning algorithms for textcategorization.
Symposium on DocumentAnalysis and Information Retrieval, pp.81-93.Ng H., Goh W., and Low K. (1997) FeatureSelection, Perceptron Learning, and aUsability Case Study for Text Categorizatio.Proceedings of the 20 th Annual InternationalACM SIGIR Conference on Research andDevelopment in Information Retrieval.Quinlan J.
(1993) C4.5: Programs for MachineLearning.
Morgan Kaufmann Publishers.255
