Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 573?578,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsDeep Neural Networks for Syntactic Parsing of Morphologically RichLanguagesJo?el Legrand1,2and Ronan Collobert?3,11Idiap Research Institute, Martigny, Switzerland2Ecole Polytechnique F?ed?erale de Lausanne (EPFL), Lausanne, Switzerland3Facebook AI Research, Menlo Park (CA), USAAbstractMorphologically rich languages (MRL)are languages in which much of the struc-tural information is contained at the word-level, leading to high level word-formvariation.
Historically, syntactic parsinghas been mainly tackled using genera-tive models.
These models assume inputfeatures to be conditionally independent,making difficult to incorporate arbitraryfeatures.
In this paper, we investigate thegreedy discriminative parser described in(Legrand and Collobert, 2015), which re-lies on word embeddings, in the context ofMRL.
We propose to learn morphologicalembeddings and propagate morphologicalinformation through the tree using a recur-sive composition procedure.
Experimentsshow that such embeddings can dramati-cally improve the average performance ondifferent languages.
Moreover, it yieldsstate-of-the art performance for a majorityof languages.1 IntroductionMorphologically rich languages (MRL) are lan-guages for which important information concern-ing the syntactic structure is expressed throughword formation, rather than constituent-order pat-terns.
Unlike English, they can have complexword structure as well as flexible word order.
Acommon practice when dealing with such lan-guages is to incorporate morphological informa-tion explicitly (Tsarfaty et al, 2013).
Howeverthis poses two problems to the classical generativemodels: they assume input features to be condi-tionally independent which makes the incorpora-?All research was conducted at the Idiap Research Insti-tute, before Ronan Collobert joined Facebook AI Researchtion of arbitrary features difficult.
Moreover, re-fining input features leads to a data sparsity issue.In the other hand, neural network-based mod-els using continuous word representations as inputhave been able to overcome the data sparsity prob-lem inherent in NLP (Huang and Yates, 2009).Furthermore, neural networks allow to incorporatearbitrary features and learn complex non-linearrelations between them.
Legrand and Collobert(2015) introduced a greedy syntactic parser, basedon neural networks which relies on word embed-dings.
This model maintains a history of the previ-ous node predictions, in the form of vector repre-sentations, by leveraging a recursive compositionprocedure.In this paper, we propose to enhance this modelfor syntactic parsing of MRL, by learning morpho-logical embeddings.
We take advantage of a re-cursive composition procedure similar to the oneused in (Legrand and Collobert, 2015) to propa-gate morphological information during the pars-ing process.
We evaluate our approach on theSPMRL (Syntactic Parsing of MRL) Shared Task2014 (Seddah et al, 2013) on nine different lan-guages.
Each of them comes with a set of morpho-logical features allowing to augment words withinformation such as their grammatical functions,relation with other words in the sentence, prefixes,affixes and lemmas.
We show that integrating mor-phological features allows to increase dramaticallythe average performance and yields state-of-the-art performance for a majority of languages.1.1 Related workBoth the baseline (Berkeley parser) and the currentstate-of-the-art model on the SPMRL Shared Task2014 (Bj?orkelund et al, 2014) rely on probabilisticcontext free grammar (PCFG)-based features.
Thelatter uses a product of PCFG with latent annota-tion based models (Petrov, 2010), with a coarse-to-573Did you hear the falling bombs ?VBD PRP VB DT VBG NNS .NP NP(R1) (R2)(a)Did R1 hear R2 ?VBD NP VB NP .VP (R3)(b)Did R1 R3 ?VBD NP VP .SQ(c)IW: Did you hear the falling bombs ?
(a) IT: VBD PRP VB DT VBG NNS .O : O S-NP O B-NP I-NP E-NP OIW: Did R1 hear R2 .
(b) IT: VBD NP VB NP .O : O O B-VP E-VP .IW: Did R1 R3 ?
(c) IT: VDB NP VP .O : B-SQ I-SQ I-SQ E-SQFigure 1: Greedy parsing algorithm (3 iterations), on the sentence ?Did you hear the falling bombs ?
?.IW, ITandO stand for input words (or composed word representations Ri), input syntactic tags (parsingor part-of-speech) and output tags (parsing), respectively.
The tree produced after 3 greedy iterations canbe reconstructed as the following: (SQ (VBD Did) (NP (PRP you)) (VP (VB hear) (NP(DT the) (VBG falling) (NNS bombs))) (.
?
)).fine decoding strategy.
The output is then discrim-inatively reranked (Charniak and Johnson, 2005)to select the best analysis.
In contrast, the parserused in this paper constructs the parse tree in agreedy manner and relies only on word, POS tagsand morphological embeddings.Several other papers have reported results forthe SPMRL Shared Task 2014.
(Hall et al, 2014)introduced an approach where, instead of propa-gating contextual information from the leaves ofthe tree to internal nodes in order to refine thegrammar, the structural complexity of the gram-mar is minimized.
This is done by moving asmuch context as possible onto local surface fea-tures.
This work was refined in (Durrett and Klein,2015), taking advantage of continuous word rep-resentations.
The system used in this paper alsoleverages words embeddings but has two majordifferences.
First, it proceeds step-by-step in agreedy manner (Durrett and Klein, 2015) by usingstructured inference (CKY).
Second, it leverages acompositional node feature which propagates in-formation from the leaves to internal nodes, whichis exactly what is claimed not to be done.
(Fern?andez-Gonz?alez and Martins, 2015) pro-posed a procedure to turn a dependency tree intoa constituency tree.
They showed that encodingorder information in the dependency tree make itisomorphic to the constituent tree, allowing anydependency parser to produce constituents.
Likethe parser we used, their parser do not need tobinarize the treebank as most of the others con-stituency parsers.
Unlike this system, we do notuse the dependency structure as an intermediaterepresentation and directly perform constituencyparsing over raw words.2 Recurrent greedy parsingIn this paper, we used the model presented in(Legrand and Collobert, 2015).
It is a NN-basedmodel which performs parsing in a greedy recur-rent way.
It follows a bottom-up iterative pro-cedure: the tree is built starting from the termi-nal nodes (sentence words), as shown in Figure 1.Each step can be seen as a sequence tagging task.A BIOES1prefixing scheme is used to rewrite thischunk (here node) prediction problem into a wordtagging problem.
Each iteration of the proceduremerges input constituents into new nodes by ap-plying the following steps:?
Node tagger: a neural network sliding win-dow is applied over the input sequence ofconstituents (leaves or heads of trees pre-dicted so far).
This procedure (see Figure2) outputs for each constituent a score siforeach BIOES-prefixed parsing tag t ?
T (Tbeing the parsing tags ensemble).?
Dynamic programming: a coherent path ofBIOES tags is retrieved by decoding over aconstrained graph.
This insures (for instance)that a B-A can be followed only by a I-A ora E-A (for all parsing tag A).1(Begin, Intermediate, Other, End, Single)574?
Compositional procedure: new nodes arecreated, merging input constituents, accord-ing to the dynamic programming predictions.A neural network composition module is thenused to compute vector representations forthe new nodes, according to the representa-tions of the merged constituents, as well astheir corresponding tags (POS or parsing).The procedure ends when the top node is pro-duced.3 Parsing Morphologically RichLanguagesXi?2Xi?1XiXi+1Xi+2...............AdditionalfeaturesWordembeddings.. POS tagsConcath(M1?
.)M2?
.s1 s2 st. .
.Figure 2: A constituent Xi(word or node previ-ously predicted) is tagged by considering a fixedsize context window of size K (here K = 5).
Theconcatenated output of the compositional historyand constituent tags is fed as input to the tagger.A standard two-layers neural network outputs ascore sifor each BIOES-prefixed parsing tag.
Ad-ditional features can be easily fed to the network.Each category is assigned a new lookup table con-taining a vector of feature for every possible tag.3.1 Morphological featuresMorphological features enable the augmentationof input tokens with information expressed at aword level, such as grammatical function or rela-tion to other words.
For parsing MRL, they haveproven to be very helpful (Cowan and Collins,2005).
The SMPRL corpus provides a differentset of morphological features associated to theCgen3Cgen2...hearn/a...thef...fallingf...bombsfg2g4Figure 3: Recursive composition of the morpho-logical feature gender (male (m) / female (f) /not applicable (n/a)).
Cgeniare the correspond-ing composition modules.
The representation g2is first computed using the 3-inputs module Cgen3.g4is obtained by using the 2-inputs module Cgen2.tree terminals (tokens) for every language.
Thesefeatures include morphosyntactic features such ascase, number, gender, person and type, as well asspecific morphological information such as verbalmood, proper/common noun distinction, lemma,grammatical function.
They also include manylanguage-specific features.
For more details aboutthe morphological features available, the readercan refer to (Seddah et al, 2013).3.2 Morphological EmbeddingsThe parser from (Legrand and Collobert, 2015) re-lies only on word and tag embeddings.
Besidesthese features, our model takes advantage of ad-ditional morphological features.
As illustrated inFigure 2, each additional feature m is assigneda different lookup table containing morphologicalfeature vectors of size dm.
The output vectors ofthe different morphological lookup-tables are sim-ply concatenated to form the input of the next neu-ral network layer.3.3 Morphological compositionMorphological features are available only forleaves.
To propagate morphological informationto the nodes, we take advantage of a composi-tion procedure similar to the one used in (Legrandand Collobert, 2015) for words and POS.
As il-lustrated in Figure 3, every morphological featurem is assigned a set on composition modules Cmiwhich take as input i morphological embeddings575Model Ara.
Bas.
Fre.
Ger.
Heb.
Hun.
Kor.
Pol.
Swe.
AVGBerkeley+POS 80.8 76.2 81.8 80.3 92.2 87.6 82.9 88.1 82.9 83.7Berkeley RAW 79.1 69.8 80.4 79.0 87.3 81.4 73.3 79.5 78.9 78.7(Bj?orkelund et al, 2014) 82.2 90.0 84.0 82.1 91.6 92.6 86.5 88.6 85.1 87.0Proposed approach 84.1 91.0 85.7 84.6 91.7 91.2 87.8 94.1 82.5 88.1Table 1: Results for all languages in terms of F1-score, using gold POS and morphological tags.
Berke-ley+POS and Berkeley RAW are the two baseline system results provided by the organizers of the sharedtask.
Our experiments used an ensemble of 5 models, trained starting from different random initializa-tions.of dimension dm.
Each composition module per-form a matrix-vector operation followed by a non-linearityCmi(x) = h(Mim.x)where Mim?
Rdm?idmis a matrix of parame-ters to be trained and h a pointwise non-linearityfunction.
x = [x1...xi] is the concatenation of thecorresponding input morphological embeddings.Note that given a morphological feature we havea different matrix of weight for every possible sizei.
In practice most tree nodes do not merge morethan a few constituents and we only consider com-position sizes < 5.4 Experiments4.1 CorpusExperiments were conducted on the SPMRL cor-pus provided for the Shared Task 2014 (Seddah etal., 2013).
It provides sentences and tree anno-tations for 9 different languages (Arabic, Basque,French, German, Hebrew, Hungarian, Korean,Polish and Swedish) coming from various sources.For each language, gold part-of-speech and mor-phological tags are provided.
Results for two base-line baseline system are provided in order to eval-uate our models.4.2 SetupThe model was trained using a stochastic gradientdescent over the available training data.
Hyper-parameters were tuned on the provided validationsets.
The word embedding size and POS/parsingtag size were set to DW= 100 and DT= 30, re-spectively.
The morphological tag embedding sizewas set to 10.
The window size of the tagger wasset to K = 7 and its number of hidden units to300.
All parameters were initialized randomly (in-cluding the words embeddings).
As suggested in(Plaut and Hinton, 1987), the learning rate was di-vided by the size of the input vector of each layer.We applied the same dropout regularization as in(Legrand and Collobert, 2015).4.3 ResultsTable 2 presents the influence of adding morpho-logical features to the model.
We observe signif-icant improvement for every languages except forHebrew.
On average, morphological features al-lowed to overcome the original model by 2 F1-score.language Words + POS + morphArabic 80.7 82.9Basque 82.7 90.6French 81.1 85.0German 81.5 83.1Hebrew 91.6 91.5Hungarian 89.6 90.3Korean 86.1 86.7Polish 93.2 93.7Swedish 81.1 81.5AVG 85.3 87.3Table 2: Influence of the additional morphologicalembeddings in terms of F1-scoreTable 1 compares the performance in F1-score(obtained with the provided EVALB SPMRL tool)of different systems, using the provided gold POSand morphological features.
We compare our re-sults with the two baselines provided with thetask: (1) Berkeley parser with provided POS Tags(Berkeley+POS).
(2) Berkeley Parser in raw modewhere the parser do its own POS tagging (Berke-ley RAW).
We also report the results of the currentstate-of-the art model for this task (Bj?orkelund etal., 2014).
We included the same voting procedureas in citelegrand:2015, using 5 models trainedstarting from different random initializations.
At576Model Ara.
Bas.
Fre.
Ger.
Heb.
Hun.
Kor.
Pol.
Swe.
AVGBerkeley+POS 78.7 74.7 79.8 78.3 85.4 85.2 78.6 86.7 80.6 80.9Berkeley RAW 79.2 70.5 80.4 78.3 87.0 81.6 71.4 79.2 79.2 78.5(Durrett and Klein, 2015) 80.2 85.4 81.2 80.9 88.6 90.7 82.2 93.0 83.4 85.1(Fern?andez and Martins, 2015) n/a 85.9 78.7 78.7 89.0 88.2 79.3 91.2 82.8 84.2(Bj?orkelund et al, 2014) 81.3 87.9 81.8 81.3 89.5 91.8 84.3 87.5 84.0 85.5Proposed approach 80.4 87.5 80.8 82.0 91.6 90.0 84.8 93.0 80.5 85.6Table 3: Results for all languages in terms of F1-score using predicted POS and morphological tags.Berkeley+POS and Berkeley RAW are the two baseline system results provided by the organizers ofthe shared task.
Our experiments used an ensemble of 5 models, trained starting from different randominitializations.each iteration of the greedy parsing procedure,the BIOES-tag scores are averaged and the newnode representations (words+POS and morpho-logical composition) are computed for each modelby composing the sub-tree representations corre-sponding to the given model, using its own com-positional network.
One can observe that the pro-posed model outperforms the best model by 1.1F1-score on average.
Moreover, it yields state-of-the art performance for 6 among the 9 availablelanguages.Finally, Table 3 compares the performance ofdifferent systems for a more realistic parsing sce-nario where the gold POS and morphological tagsare unknown.
For these experiments, we use thesame tags as in (Bj?orkelund et al, 2014)2obtainedusing the freely available tool MarMoT (Muelleret al, 2013).
We compare our results with thesame model as for the the gold tags experiences.Additionnaly, we compare our results with tworecent models reporting results for the SPMRLShared Task 2014.
We see that the proposed modelyields state-of-the art performance for 4 out of 9available languages.5 ConclusionIn this paper, we proposed to extend the parserintroduced in (Legrand and Collobert, 2015) bylearning morphological embeddings.
We take ad-vantage of a recursive procedure to propagate mor-phological information through the tree during theparsing process.
We showed that using the mor-phological embeddings boosts the F1-score andallows to outperform the current state-of-the-artmodel on the SPMRL Shared Task 2014 corpus.Moreover, our approach yields state-of-the art per-formance for a majority of languages.2The tags used are available here: http://cistern.cis.lmu.de/marmot/models/CURRENT/AcknoledgmentsThis work was supported by NEC LaboratoriesAmerica.
We would like to thank Dimitri Palaz forour fruitful discussions and Marc Ferras for proof-reading this paper.ReferencesAnders Bj?orkelund, Ozlem Cetinoglu, AgnieszkaFalenska, Rich?ard Farkas, Thomas Mueller, Wolf-gang Seeker, and Zsolt Sz?ant?o.
2014.
Introduc-ing the ims-wroc?aw-szeged-cis entry at the SPMRL2014 shared task: Reranking and morpho-syntaxmeet unlabeled data.
Proceedings of the First JointWorkshop on Statistical Parsing of MorphologicallyRich Languages and Syntactic Analysis of Non-Canonical Languages.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine N-best parsing and MaxEnt discriminativereranking.
In Proceedings of the 43rd Annual Meet-ing on Association for Computational Linguistics.Brooke Cowan and Michael Collins.
2005.
Morphol-ogy and reranking for the statistical parsing of span-ish.
In Proceedings of Human Language TechnologyConference and Conference on Empirical Methodsin Natural Language Processing.Greg Durrett and Dan Klein.
2015.
Neural CRF pars-ing.
In Proceedings of the Association for Compu-tational Linguistics.Daniel Fern?andez-Gonz?alez and Andr F. T. Martins.2015.
Parsing as reduction.
In Annual Meeting ofthe Association for Computational Linguistics ACL.David Hall, Greg Durrett, and Dan Klein.
2014.
Lessgrammar, more features.
In Proceedings of the 52ndAnnual Meeting of the Association for Computa-tional Linguistics.Fei Huang and Alexander Yates.
2009.
Distributionalrepresentations for handling sparsity in supervisedsequence-labeling.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natural577Language Processing of the AFNLP: Volume 1 - Vol-ume 1.Jo?el Legrand and Ronan Collobert.
2015.
Joint RNN-based greedy parsing and word composition.
In Pro-ceedings of ICLR.T.
Mueller, H. Schmid, and H. Sch?utze.
2013.
Effi-cient higher-order CRFs for morphological tagging.In Proceedings of the 2013 Conference on EmpiricalMethods in Natural Language Processing.Slav Petrov.
2010.
Products of random latent variablegrammars.
In NAACL-HLT.David C. Plaut and Geoffrey E. Hinton.
1987.
Learn-ing sets of filters using back-propagation.
ComputerSpeech and Language.Djam?e Seddah, Reut Tsarfaty, Sandra K?ubler, MarieCandito, Jinho D. Choi, Rich?ard Farkas, Jen-nifer Foster, Iakes Goenaga, Koldo Gojenola,Yoav Goldberg, Spence Green, Nizar Habash,Marco Kuhlmann, Wolfgang Maier, Joakim Nivre,Adam Przepi?orkowski, Ryan Roth, WolfgangSeeker, Yannick Versley, Veronika Vincze, MarcinWoli?nsk, Alina Wr?oblewska, and?Eric VillemonteDe La Clergerie.
2013.
Overview of the SPMRL2013 shared task: A cross-framework evaluation ofparsing morphologically rich languages.
In Pro-ceedings of the 4th Workshop on Statistical Parsingof Morphologically Rich Languages: Shared Task.Reut Tsarfaty, Djam?e Seddah, Sandra Kbler, andJoakim Nivre.
2013.
Parsing morphologically richlanguages: Introduction to the special issue.
Com-putational Linguistics.578
