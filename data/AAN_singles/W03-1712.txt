Building A Large Chinese CorpusAnnotated With Semantic DependencyLI MingqinDepartment of Electronic Engineering,Tsinghua University,Beijing 100084, Chinalmq@thsp.ee.tsinghua.edu.cnLI JuanziDepartment of Computer Scienceand Technology,Tsinghua University,Beijing 100084, Chinaljz@thsp.ee.tsinghua.edu.cnDONG ZhendongResearch Centre of Computer &Language Engineering,Chinese Academy of Sciences,Beijing, 100084,Chinadzd@keenage.comWANG ZuoyingDepartment of Electronic Engineering,Tsinghua University,Beijing 100084, Chinawzy-dee@tsinghua.edu.cnLU DajinDepartment of Electronic Engineering,Tsinghua University,Beijing 100084, Chinaludj@mail.tsinghua.edu.cnAbstractAt present most of corpora are annotatedmainly with syntactic knowledge.
In thispaper, we attempt to build a large corpusand annotate semantic knowledge withdependency grammar.
We believe thatwords are the basic units of semantics,and the structure and meaning of asentence consist mainly of a series ofsemantic dependencies betweenindividual words.
A 1,000,000-word-scale corpus annotated with semanticdependency has been built.
Comparedwith syntactic knowledge, semanticknowledge is more difficult to annotate,for ambiguity problem is more serious.
Inthe paper, the strategy to improveconsistency is addressed, and congruenceis defined to measure the consistency oftagged corpus..
Finally, we will compareour corpus with other well-knowncorpora.1   IntroductionAs basic research tools for investigators in naturallanguage processing, large annotated corpora playan important role in investigating diverse lan-guage phenomena, building statistical languagemodels, evaluating and comparing kinds of pars-ing models.
At present most of corpora are anno-tated mainly with syntactic knowledge, thoughsome function tags are added to annotate semanticknowledge.
For example, the Penn Treebank(Marcus et al, 1993) was annotated with skeletalsyntactic structure, and many syntactic parserswere evaluated and compared on the corpus.
ForChinese, some corpora annotated with phrasestructure also have been built, for instance thePenn Chinese Treebank (Xia et al, 2000) and SinaCorpus (Huang and Chen, 1992).
A syntactic an-notation scheme based on dependency was pro-posed by (Lai and Huang, 2000), and a smallcorpus was built for testing.
However, very lim-ited work has been done with annotation semanticknowledge in all languages.
From 1999, Berkeleystarted FrameNet project (Baker et al, 1998),which produced the frame-semantic descriptionsof several thousand English lexical items andbacked up these description with semantically an-notated attestations from contemporary Englishcorpus.
Although few corpora annotated with se-mantic knowledge are available now, there aresome valuable lexical databases describing thelexical semantics in dictionary form, for exampleEnglish WordNet (Miller et al, 1993) and ChineseHowNet (Dong and Dong, 2001).For Chinese, many attentions have been natu-rally paid to researches on semantics, becauseChinese is a meaning-combined language, its syn-tax is very flexible, and semantic rules are morestable than syntactic rules.
For instance, in Chi-nese it is very pervasive that more than one part-of-speeches a word has, and a word does not havetense or voice flectional transition under differenttenses or voices.
Nevertheless, no large Chinesecorpus annotated with semantic knowledge hasever been built at present.
In Semantic Depend-ency Net (SDN), we try to describe deeper seman-tic dependency relationship between individualwords and represent the meaning and structure ofa sentence by these dependencies.Compared with syntactic corpus, it is more dif-ficult to build a semantic corpus, for the granular-ity of semantic knowledge is smaller, andbehaviors of different words differ more greatly.Furthermore, ambiguity in semantics is commoner.Different people may have different opinions onunderstanding the same word in the same sentence,and even the same people may have differentopinions on understanding the same word in dif-ferent occasions.
In this paper, we emphaticallydiscuss the strategy to improve the consistency ofSemantic Dependency Net.The paper is organized as follows.
The taggingscheme is discussed in Section 2, which describesthe semantic dependency grammar and the tag setof semantic relations.
In section 3, we describe thetagging task.
First, we briefly introduce the text ofthis corpus, which has been tagged with semanticclasses.
Second, we describe the strategy to im-prove consistency during tagging and checking.At last, congruence is defined to measure the con-sistency of tagged corpus.
In Section 4, we brieflyintroduce some of the works on the corpus, andindicate the directions that the project is likely totake in the future.
Finally, we compare SDN cor-pus with some other well-known corpora.Figure 1:  A sample sentence from the corpus.
(a) The sentence tagged with semantic classes; (b) The sen-tence annotated with semantic dependency; (c) The semantic dependency tree of the sentence, headwordsare linked with bold lines, and modifier words are linked with arrow lines.2 The tagging scheme of semantic depend-ency2.1 Semantic dependency grammarLike Word grammar (Hudson, 1998), We believethat words are the basic units of semantics, andthe structure and meaning of a sentence consistmainly of semantic dependencies between indi-vidual words.
So a sentence could be annotatedwith a series of semantic dependency relations (LiJuanzi and Wang, 2002).
Let S be a sentencecomposed of words tagged with semantic classes,},,,,,,{ 2211 ><><><= nn swswswS L. Alist of semantic dependency relations is defined as:)}(,),2(),1({ nSRSRSRSRL L=,where ),()( ii rhiSR = .
SR stands for ?
semanticrelation?.
),()( ii rhiSR =  states that the ih -thword is the headword to the i-th word with seman-tic relation ir .
If the word j is the root, )( jSR  isdefined to be (-1, ?kernel word?
).For example, a sample sentence from the cor-pus is shown in Figure 1 (a).
The semantic de-pendency relation list and semantic dependencytree are shown in Figure 1 (b) and (c) respectively.More samples will be seen in Appendix A.In semantic dependency grammar, the head-word of sentence represents the main meaning ofthe whole sentence, and the headword of constitu-ent represents the main meaning of the constituent.In a compound constituent, the headword inheritsthe headword of the head sub-constituent, andheadwords of other sub-constituents are dependenton that headword.
We select the word that canrepresent the meaning of the constituent to themost extent as headword.
For example, the verb isthe headword of verb phrase, the object is theheadword of preposition phrase, and the locationnoun is the headword of the location phrase.At the same time, semantic dependency rela-tions do not damage the phrase structure, that is,all words in the same phrase are in the same sub-tree whose root is the headword of the phrase.Therefore, when tagging dependency relations,semantic and syntactic restrictions are both takeninto account.
The structures of dependency treeare mainly determined by syntactic restrictions,and the semantic relations are mainly determinedby semantic restrictions.
For example, in Figure 1the phrase ??
( of his invention pro-duction) modifies the phrase ??
(popu-larization and application) in syntax, so the word??
(popularization) governs the word ??(production).
However, the production is the con-tent of the action popularization in semantics, sothe relation between them is ?content?.Our tagging scheme is more concise comparedwith phrase structure grammar, in which theboundaries of all phrases have to be marked andthe corresponding labels have to be tagged.
In thesemantic dependency grammar, phrases are im-plicit, but play no part in grammar.
More empha-sis is paid to the syntactic and semantic functionsof the word, especially of the headword.2.2 The dependency relation tag setThe dependency relation tag set mainly consists ofthree kinds of relations: semantic relations, syn-tactic relations and special relations.
Semantics isthe main content of this corpus, so semantic rela-tions are in the majority, and syntactic relationsare used to annotate the special structures that donot have exact sense in terms of semantics.
In ad-dition, there are two special relations: ?kernelword?
is to indicate the headword of a sentence,and ?failure?
is to indicate the word that cannot beannotated with dependency relations because thesentence is not completed.The selections of semantic relations were re-ferred to HowNet (Dong and Dong, 2001).HowNet is a lexical database, which describes therelations among words and concepts as a network.In HowNet, senventy-six semantic relations aredefined to describe all relations among variousconcepts, and most of them describe the semanticrelations between action and other concepts.
Withthese semantic relations, necessary role frame isfurther defined.
The roles in the necessary roleframe must take part in the action in real word,while these roles may not appear in the same sen-tence.
Hong Kong Technology University hassuccessfully tagged a news corpus with the neces-sary role frame (Yan and Tan, 1999), whichshows that these roles can describe all semanticphenomena in real texts.In order to make tagging task easier and thecorpus more suitable for statistical learning, wehave pared down some relations in HowNet andgot fifty-nine semantic relations.
Some HowNetrelations seldom occurred in the corpus, and theirsemantic functions are somewhat similar, so theyare merged.
Some relations are ambiguous, forexample ?degree?
and ?range?.
In order to im-prove the consistency, we also merge these tworelations.Semantic relations can describe the relationsbetween notional words, but they cannot annotatefunction words in some special phrase structures.So nine syntactic relations are added.The tag set is listed in table 1.
Full definitionof each dependency relation can be seen in (LiMingqin et al, 2002).	!
"#$%&!''"#(&$%&')*()*+,+,(-.-.
*/0'1)%23''45'67'!8967'-:;67<=6>?
6>'/0'!8967'-:;67?
6><=6>'/12@A2!B@A2-:@A2C@A%!BDE%-:DEF"GH '3456)* 'IJ)(K>!'LM(NO%78BPQ&RS-T&USemanticRelations599:;&V?<WXYZ=>&&*?
?Q [\?>%>?>&>?
]?Q\^ \2-+_\@A/BCBDE(&CFDESyntacitcRelations9`_\&aT1_\b_\Specialrelaions2GH&cde-\fgTable 1: The dependency relation tag set.3   The tagging and checking of semanticdependency relations3.1 Texts of corpusA part of Tsinghua Corpus (Zhang, 1999) anno-tated with semantic classes was selected as rawdata of our corpus.
The texts of Tsinghua corpuscome from the news of People?s Daily.
The se-lected part consists of about 1,000,000 words, ap-proximately 1,500,000 Chinese characters.
Itsdomain covers the politics, economy, science,sports, etc.
The proportion of different domains isshown in figure 2.Figure 2: The proportion of texts of different do-mainsBecause Chinese is not written with word de-limiters, first the text was segmented into wordsaccording to the lexicon of 100,000 words.
Theneach word was tagged with semantic class, whosedefinition follows Tongyici Cilin (Dictionary ofSynonymous Words) (Mei  et al, 1983).The seman-tic classes are organized as a tree, which has threelevels.
The first level contains 18 classes, the sec-ond level contains 101 classes, and the third levelcontains 1434 classes.
These hierarchical semanticclasses are helpful to express the superordinate andsubordinate information among words.All the text in Tsinghua Corpus was seg-mented, tagged and checked manually.
Since thecorpus was built in 1998, it has been used for sev-eral years in the researches on automatic sense tag-ging and class-based language model.
Now, theaccuracy of tagging system has reached to 92.7%(Zhang, 1999).3.2 Tagging toolsA computer-aided tagging tool was developed toassist annotators in tagging semantic dependencyrelations.
To tag a word, annotator only need toselect its headword and their relation by clickingmouse.
After a sentence has been tagged, the cor-responding semantic dependency tree will be dis-played to help annotators check the sentencestructure.Two additional functions are also provided inthe tool: dependency grammar checking and on-line reference of HowNet.
Dependency grammarchecking guarantees that the tagged sentence con-forms to four axioms of dependency grammar(Robinson, 1970):(a) One and only one element is independent;(b) All others depend directly on some ele-ment;(c) No element depends directly on more thanone other(d) If A depends directly on B and some ele-ment C intervenes between them (in linear or-der of string), then C depends directly on A orB or some other intervening element.During annotating procedure, the tool checkswhether the tagged relation conforms to depend-ency grammar, and prompts the grammar errors intime.On-line HowNet reference facilitates lookingup semantic knowledge and helps to ensure theconsistency of tagging.
Semantic knowledge ismore difficult to grasp than syntactic knowledge.Even for annotators majored in linguistics, it is toodifficult to grasp all semantic relations of wordsonly after a short-term training.
And different opin-ions about relations will lead to the inconsistency.However, HowNet defines the necessary roleframe for verbs frequently used in real world, andthese roles can be mapped to our semantic relations,so HowNet has set up a detail annotating manualfor us.
For example, in HowNet the role frame ofthe verb ??
(pay attention to) is defined as{experiencer, target, cause}.
With basic semanticknowledge, annotators can easily identify the rela-tion between ??
(doctor) and ??
(pay at-tention to) as ?experiencer?, and the relationbetween ??
(popularization) and ??
(payattention to) as ?target?.
We integrated the on-linereference of HowNet to the tool, which has beenproved in practice to be very helpful in improvingthe consistency and speed of tagging.3.3 CheckingOur work is the first attempt to annotate semanticdependency relations on a large corpus, and noprior knowledge is available, so the whole corpusis tagged manually.
But in checking procedure wehave learned some experience and knowledge,which should be used as possible as we can.
So weadopt two checking modes.
In the first mode?manual checking, checkers correct all errors byhand; in second mode?semiautomatic checking,computer-aided checking tool automaticallysearches for the errors and then human checkerscorrect them, and it means checkers need to readonly about 1/3 or less questionable sentences.In semiautomatic checking, all the files arescanned automatically to search for three kinds oferrors:1.
To check whether the semantic relationsconform to the necessary role frame definedby HowNet.2.
To check whether the relations conform toerror rules.
Some errors frequently occurredduring manual checking.
For example, the re-lation between words ? /?
(again) and averb must be ?frequency?, but in incorrectsentences it was tagged otherwise.
We sum-marized these errors, and wrote them as rules.3.
To check whether the score of semanticdependency model (equation 1) is below somethreshold.
A simple semantic dependencymodel was built on the corpus.
Although thescore of tagged sentence cannot be the crite-rion of correctness, at least it can show theconsistency of a kind of sentences.
?==nkkkk rwhwPTP1)),(,()(                     (1)where n  is the length of the sentence, kw  is thek-th word in the sentence, )( kwh  is the headwordto kw  with semantic relation kr .The semiautomatic checking interface couldprompt some possible errors, but the necessary roleframes defined by HowNet may be not complete,the error rules may be not restrict, and the score ofsemantic structure model may be not credible.
Theprompted errors may be false, so the decisionwhether the error is true and how to correct it mustbe made by human checkers.
This is the reasonwhy it is called semiautomatic checking.The checking procedure consisted of fiverounds of selective manual checking and a roundof semiautomatic checking.
In tagging procedure,we dispatched the raw files to annotators in agroup of 10 files.
In a round of selective manualchecking, one file in every group was selected tocheck.
All corrections were recorded by the check-ing interface, and the reasons for corrections wereexplained by the checker.
If too many error sen-tences occurred in the selected file, all files in thisgroup needed correcting by original annotatorsafter referring to the corrected sentences and theirexplanations.After four rounds of selective manual check-ing, most of errors have been corrected, but therewere still some files that have not been checked orcorrected.
We semi-automatically checked all files.Finally, the fifth round of manual checking wastaken.Fourteen graduate studentstook part in anno-tating, most of them are majored in linguistics.Seven excellent students were elected for checkingamong annotators, and they were not allowed tocheck their own files.
According to our statistics,the average speed to annotate by hand is about 1.15hours per 100 sentences; the average speed tocheck by hand is about 0.25 hours per 100 sen-tences; and the speed to check half automatically isabout 0.08 hours per 100 sentences.
In manualchecking procedure, there were 50% of all filesthat were manually checked, 75.45% that wereturned to the original annotator to correct.
(Whencounting the files corrected by original annotators,if the same group of files were corrected in tworounds, we count them as two groups.)
And allfiles were checked in semiautomatic checking pro-cedure.3.4 CongruenceUnder the given annotating manual, consistency isan important criterion to evaluate the corpus.
Iftagged sentence is independently checked andpassed by several experts, the annotation may becredible; otherwise, if some experts do not agree tothe annotation, it may be not credible enough.
Ifseveral experts evaluate tagged sentences inde-pendently, the inter-checker agreement is definedas the measure of consistency.Relation Congruence (RCn) and SentenceCongruence (SCn) are defined.
RCn is the numberof relations for which n judges agreed, divided bythe total number of relations, in which n can be 1,2, 3.
SCn is the number of sentences for which njudges agreed, divided by the total number of sen-tences, in which n can be 1, 2, 3.
For example, ifthree experts take part in evaluating, RC3 is thepercentage of the annotated relation that all threeexperts are agree to one annotation, and SC1 is thepercentage of the annotated sentence for which allthree judges?
opinions are different from one an-other.Before checking, 500 sentences were evalu-ated by three experts.
After checking, 1,400 sen-tences were evaluated by three experts.
In order tobalance the coverage and workload of evaluation,another 4,900 sentences were evaluated by twoexperts.
The congruency is shown in table 2.RC3 RC2 RC1Unchecked(500) 90.78% 8.65% 0.57%Checked(1400) 96.24% 3.64% 0.12%Checked(4900)--------- 97.56% 2.44%SC3 SC2 SC1Unchecked(500) 69.20% 23.00% 7.80%Checked(1400) 83.43% 14.07% 2.50%Checked(4900)---------- 89.10% 10.90%Table 2: the congruency of data before and aftercheckingThe results show that the quality of corpus isimproved greatly after checking, and high rela-tion/sentence congruency of 96.24%/83.43%among three experts was satisfactory.4   Future worksAlthough the tagging task is completed, much fur-ther work will be needed.
A user-friendly, interac-tive interface for corpus investigation is needed tosearch the example sentences and to maintain thetagged data.
Inconsistencies still exist in the corpus,and it may become more apparent with time.
Howto reduce inconsistencies is a challenging problem.The role frame of verbs can to be extracted fromthe corpus, which could be integrated withHowNet to build a larger database.
The correlationframe of nouns, which can represent the order ofmodifier phrases, can be extracted, too.More statistical researches could be carriedout on the corpus.
Researches on Chinese informa-tion structure have been carried out on the corpus(You et al, 2002).
Auto-tagging the semantic de-pendency structure of this kind is under going.
Andwe hope the SDN corpus could be exploited inmore areas: speech recognition, natural languageunderstanding, machine translation, informationextraction, and so on.5   Comparison with other corporaOur Corpus is compared with other famous cor-pora for English and Chinese in table 3.Corpus Languge Content Scale InstitutionSDN Chinese Semantic dependency1,000,000words TsinghuaFrameNet English Frame Semantics250,000sentences BerkeleyTreeBank(C) Chinese Phrasestructure500,000words UPennTable 3: Comparison with other corporaThe FrameNet is annotated with semanticknowledge, which emphasizes on describing theframe and scene of several thousands verbs.
Theyfirst build a frame database, which contains de-scriptions of each frame of the verbs, and then an-notated example sentences of these frames.
UnlikeFrameNet, we first annotated semantic dependencyrelations of sentences according to HowNet, andhope to extract frames from the corpus later.
Fra-meNet only described the frame of verbs, whilefrom Semantic Dependency Net the correlationframe of nouns and verbs could be automaticallylearned by machine.ReferencesCollin F. Baker, Charles J. Fillmore, John B. Lowe.1998.
The Berkeley FrameNet Project, Proceedingsof the COLING-ACL, Montreal, Canada.Zhendong Dong and Qiang Dong.
2001.
Construction ofa Knowledge System and its Impact on Chinese Re-search, Contemporary Linguistics, 3: 33-44, Beijing.Chu-Ren Huang and Keh-jiann Chen.
1992.
A ChineseCorpus for Linguistics Research.
In the Proceedingsof the COLING.
1214-1217.
Nantes, FranceRichard Hudson.
1998.
Word Grammars, Dependencyand Valency, An International Handbook of Con-temporary Research.
Edited by Vilmos Agel,Ludwig M. Eichinger, etc.
Berlin, Walter de Gruyter.Tom B. Y. Lai and Changning Huang.
2000.
Depend-ency-based syntactic analysis of Chinese and Anno-tation of Parsed Corpus.
The 38th Annual Meeting ofthe Association for Computational Linguistics, HongKong.Juanzi Li and Zuoying Wang.
2002.
Chinese StatistcalParser Based on Semantic Dependecies, TsinghuaScience and Technology, 7(6): 591-595.Mingqin Li, Fang You, Juanzi Li, Zuoying Wang.
2002.Manual of Tagging Semantic Dependency (thirdVersion), Technical Report, Tsinghua University,Department of Electronic Engineering.Mitchell P. Marcus, Beatrice Santorini, Mary Ann Mar-cinkiewicz.
1993.
Building a large annotated corpusof English: The Penn Treebank.
Computational Lin-guistics, 19(2): 313-330.Jiaju Mei, Yiming Zhu and YunQi Gao, Yin Hongxiang,Edited.
1983.
Tongyici Cilin (Dictionary ofSynonymous Words), Shanghai Cishu Publisher.George A. Miller, Richard Beckwith, Christiane Fell-baum, Derek Gross, and Katherine Miller.
1993.
In-troduction to WordNet: An On-line Lexical Database,Five papers on WordNet, CSL Report 43, CognitiveScience Laboratory.
Princeton University.Jane J. Robinson.
1970.
Dependency Structures andTransformation Rules.
Lanuage, 46: 259-285.Fei Xia, Martha Palmer, Nianwen Xue, Mary EllenOkurowski, John Kovarik, Fu-Dong Chiou, ShizheHuang, Tony Kroch, and Mitch Marcus.
2000.
Pro-ceedings of the second International Conference onLanguage Resources and Evaluation (LREC 2000),Athens, Greece.Guowei Yan and Huimin Tan.
1999.
Corpus AnnotatingMannual Based on HowNet (Jiyu ZhiWang deYuliao Biaozhu Shouce), Technical Report, the De-partment of computer science, Hong Kong Univer-sity of Sience of Techonolgy.http://www.keenage.comFang You, Juanzi Li and Zuoying Wang.
2002.
An ap-proach Based HowNet for Extracting Chinese Mes-sage Structure, Computer Engineering andApplications, 38: 56-58.Jianping Zhang.
1999.
A Study of Language Model andUnderstanding Algorithm for Large VocabularySpontaneous Speech Recognition.
Doctor Disserta-tion, The Department of Electronic Engineering,Tsinghua University, Beijing.Appendix A. samples from corpusSentence 1:    01/Scope1-1-1 /Kernel word23/Restrictive38/Restrictive4	 3?
?
/?De?
dependency56/Descriptive68/Restrictive7	 6?
?
/?De?
dependency81/Content  Sentence 2:  ! " # $% &' () * +, -.0  1 ! /0/Preposition1 ! 4$% 12/Location2"  4$% 340/Correlative3#  4$% 56/Comment4$% -1-1 /Kernel word5&' 6() /Restrictive6() 11/Restrictive7*  8+, /0/Preposition8+, 9-.
712/LocationIni9-.
1189/Patient10	  9-.
?
?
/?De?
dependency114$% /ContentSentence 3: :; < => ?
@ :A BC D E F G H IJK  LM N 	 OP QR0:; 2=>  S9/Agent1<  2=>  56/Comment2=>  -1-1 /Kernel word3?
@ 4:A T/Modifier4:A 18QR/Restrictive5BC 4:A UVW/Appositive6D  11I  XY/Quantity7E  6D  Z[/Connection8F  6D  Z[/Connection9G  6D  Z[/Connection10H  6D  Z[/Connection11I  18QRXY/Quantity12JK 18QR3\]/Relevant13   15N /Restrictive14LM 15N /Restrictive15N 12JK ^ _/Isa16	  12JK ?
?
/?De?
dependency17OP 18QRT/Modifier18QR2=>  89/Patient  Sentence 4: `a b c de f gh ij 	 Ak lm0` a  -1-1 /Kernel word1b   2c 56/Comment2c 0` a  /Content3de 8Ak nop/Experiencer4f 6ij /Restrictive5gh 6ij /Restrictive6ij 3de qr/Target7	  3de ?
?
/?De?
dependency8Ak 9lm/Restrictive9lm2c stu/Possession  Sentence 5:  v w x y 	 z{ 0   6z{ /0/Preposition1v  6z{ 3\]/Relevant2w  1v  |}/Contrast3x  1v  Z[/Coordination4y  3x  |}/Contrast5	  1v  ?
?
/?De?
dependency6z{ -1-1 /Kernel word7 6z{ ~V0/LocationPreposition
