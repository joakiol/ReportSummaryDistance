Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638?646,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPQuantitative modeling of the neural representation of adjective-nounphrases to account for fMRI activationKai-min K. Chang1   Vladimir L. Cherkassky2   Tom M. Mitchell3   Marcel Adam Just2Language Technologies Institute1Center for Cognitive Brain Imaging2Machine Learning Department3Carnegie Mellon UniversityPittsburgh, PA 15213, U.S.A.{kkchang,cherkassky,tom.mitchell,just}@cmu.eduAbstractRecent advances in functional MagneticResonance Imaging (fMRI) offer a significantnew approach to studying semantic represen-tations in humans by making it possible to di-rectly observe brain activity while peoplecomprehend words and sentences.
In thisstudy, we investigate how humans compre-hend adjective-noun phrases (e.g.
strong dog)while their neural activity is recorded.
Classi-fication analysis shows that the distributedpattern of neural activity contains sufficientsignal to decode differences among phrases.Furthermore, vector-based semantic modelscan explain a significant portion of system-atic variance in the observed neural activity.Multiplicative composition models of thetwo-word phrase outperform additive models,consistent with the assumption that peopleuse adjectives to modify the meaning of thenoun, rather than conjoining the meaning ofthe adjective and noun.1 IntroductionHow humans represent meanings of individualwords and how lexical semantic knowledge iscombined to form complex concepts are issuesfundamental to the study of human knowledge.There have been a variety of approaches fromdifferent scientific communities trying to charac-terize semantic representations.
Linguists havetried to characterize the meaning of a word withfeature-based approaches, such as semantic roles(Kipper et al, 2006), as well as word-relationapproaches, such as WordNet (Miller, 1995).Computational linguists have demonstrated that aword?s meaning is captured to some extent bythe distribution of words and phrases with whichit commonly co-occurs (Church & Hanks, 1990).Psychologists have studied word meaningthrough feature-norming studies (Cree & McRae,2003) in which human participants are asked tolist the features they associate with variouswords.
There are also efforts to recover the latentsemantic structure from text corpora using tech-niques such as LSA (Landauer & Dumais, 1997)and topic models (Blei et al, 2003).Recent advances in functional MagneticResonance Imaging (fMRI) provide a significantnew approach to studying semanticrepresentations in humans by making it possibleto directly observe brain activity while peoplecomprehend words and sentences.
fMRImeasures the hemodynamic response (changes inblood flow and blood oxygenation) related toneural activity in the human brain.
Images can beacquired at good spatial resolution and reason-able temporal resolution ?
the activity level of15,000 - 20,000 brain volume elements (voxels)of about 50 mm3 each can be measured every 1second.
Recent multivariate analyses of fMRIactivity have shown that classifiers can betrained to decode which of several visually pre-sented objects or object categories a person iscontemplating, given the person?s fMRI-measured neural activity (Cox and Savoy, 2003;O'Toole et al, 2005; Haynes and Rees, 2006;Mitchell et al, 2004).
Furthermore, Mitchell etal.
(2008) showed that word features computedfrom the occurrences of stimulus words (within atrillion-token Google text corpus that capturesthe typical use of words in English text) canpredict the brain activity associated with the638meaning of these words.
They developed agenerative model that is capable of predictingfMRI neural activity well enough that it cansuccessfully match words it has not yetencountered to their previously unseen fMRIimages with accuracies far above chance level.The distributed pattern of neural activity encodesthe meanings of words, and the model?s successindicates some initial access to the encoding.Given these early succesess in using fMRI todiscriminate categorial information and to modellexical semantic representations of individualwords, it is interesting to ask whether a similarapproach can be used to study the representationof adjective-noun phrases.
In this study, weapplied the vector-based models of semanticcomposition used in computational linguistics tomodel neural activation patterns obtained whilesubjects comprehended adjective-noun phrases.In an object-contemplation task, human partici-pants were presented with 12 text labels of ob-jects (e.g.
dog) and were instructed to think ofthe same properties of the stimulus object consis-tently during multiple presentations of each item.The participants were also shown adjective-nounphrases, where adjectives were used to modifythe meaning of nouns (e.g.
strong dog).Mitchell and Lapata (2008) presented aframework for representing the meaning ofphrases and sentences in vector space.
Theydiscussed how an additive model, amultiplicative model, a weighted additive model,a Kintsch (2001) model, and a model whichcombines multiplicative and additive models canbe used to model human behavior in similiarityjudgements when human participants werepresented with a reference containing a subject-verb phrase (e.g., horse ran) and two landmarks(e.g., galloped and dissolved) and asked tochoose which landmark was most similiar to thereference (in this case, galloped).
They comparedthe composition models to human similarityratings and found that all models werestatistically significantly correlated with humanjudgements.
Moreover, the multiplicative andcombined model performed signficantlly betterthan the non-compositional models.
Ourapproach is similar to that of Mitchell and Lapata(2008) in that we compared additive andmultiplicative models to non-compositionalmodels in terms of their ability to model humandata.
Our work differs from these efforts becausewe focus on modeling neural activity whilepeople comprehend adjective-noun phrases.In section 2, we describe the experiment andhow functional brain images were acquired.
Insection 3, we apply classifier analysis to see ifthe distributed pattern of neural activity containssufficient signal to discriminate among phrases.In section 4, we discuss a vector-based approachto modeling the lexical semantic knowledgeusing word occurrence measures in a text corpus.Two composition models, namely the additiveand the multiplicative models, along with twonon-composition models, namely the adjectiveand the noun models, are used to explain thesystematic variance in neural activation.
Section5 distinguishes between two types of adjectivesthat are used in our stimuli: attribute-specifyingadjectives and object-modifying adjectives.Classifier analysis suggests people interpret thetwo types of adjectives differently.
Finally, wediscuss some of the implications of our work andsuggest some future studies.2 Brain Imaging Experiments on Adjec-tive-Noun Comprehension2.1 Experimental ParadigmNineteen right-handed adults (aged between 18and 32) from the Carnegie Mellon communityparticipated and gave informed consent approvedby the University of Pittsburgh and CarnegieMellon Institutional Review Boards.
Four addi-tional participants were excluded from the analy-sis due to head motion greater than 2.5 mm.The stimuli were text labels of 12 concretenouns from 4 semantic categories with 3exemplars per category.
The 12 nouns were bear,cat, dog (animal); bottle, cup, knife (utensil);carrot, corn, tomato (vegetable); airplane, train,and truck (vehicle; see Table 1).
The fMRIneural signatures of these objects have beenfound in previous studies to elicit different neuralactivity.
The participants were also shown eachof the 12 nouns paired with an adjective, wherethe adjectives are expected to emphasize certainsemantic properties of the nouns.
For instance, inthe case of strong dog, the adjective is used toemphasize the visual or physical aspect (e.g.muscular) of a dog, as opposed to the behavioralaspects (e.g.
play, eat, petted) that people moreoften associate with the term.
Notice that the lastthree adjectives in Table 1 are marked by aster-isks to denote they are object-modifying adjec-tives.
These adjectives appear to behave differ-ently from the ordinary attribute-specifying ad-jectives.
Section 5 is devoted to discussing thedifferent adjective types in more detail.639Adjective Noun CategorySoft Bear AnimalLarge Cat AnimalStrong Dog AnimalPlastic Bottle UtensilSmall Cup UtensilSharp Knife UtensilHard Carrot VegetableCut Corn VegetableFirm Tomato VegetablePaper* Airplane VehicleModel* Train VehicleToy* Truck VehicleTable 1.
Word stimuli.
Asterisks mark the ob-ject-modifying adjectives, as opposed to the or-dinary attribute-specifying adjectives.To ensure that participants had a consistent setof properties to think about, they were eachasked to generate and write a set of properties foreach exemplar in a session prior to the scanningsession (such as ?4 legs, house pet, fed by me?for dog).
However, nothing was done to elicitconsistency across participants.
The entire set of24 stimuli was presented 6 times during thescanning session, in a different random ordereach time.
Participants silently viewed thestimuli and were asked to think of the same itemproperties consistently across the 6 presentationsof the items.
Each stimulus was presented for 3s,followed by a 7s rest period, during which theparticipants were instructed to fixate on an Xdisplayed in the center of the screen.
There weretwo additional presentations of fixation, 31seach, at the beginning and end of each session, toprovide a baseline measure of activity.2.2 Data Acquisition and ProcessingFunctional images were acquired on a SiemensAllegra 3.0T scanner (Siemens, Erlangen,Germany) at the Brain Imaging Research Centerof Carnegie Mellon University and theUniversity of Pittsburgh using a gradient echoEPI pulse sequence with TR = 1000 ms, TE = 30ms, and a 60?
flip angle.
Seventeen 5-mm thickoblique-axial slices were imaged with a gap of 1-mm between slices.
The acquisition matrix was64 x 64 with 3.125 x 3.125 x 5-mm voxels.
Dataprocessing were performed with StatisticalParametric Mapping software (SPM2, WellcomeDepartment of Cognitive Neurology, London,UK; Friston, 2005).
The data were corrected forslice timing, motion, and linear trend, and weretemporally smoothed with a high-pass filterusing a 190s cutoff.
The data were normalized tothe MNI template brain image using a 12-parameter affine transformation and resampled to3 x 3 x 6-mm3 voxels.The percent signal change (PSC) relative tothe fixation condition was computed for eachitem presentation at each voxel.
The mean of thefour images (mean PSC) acquired within a 4swindow, offset 4s from the stimulus onset (toaccount for the delay in hemodynamic response),provided the main input measure for subsequentanalysis.
The mean PSC data for each wordpresentation were further normalized to havemean zero and variance one to equate thevariation between participants over exemplars.Due to the inherent limitations in the temporalproperties of fMRI data, we consider here onlythe spatial distribution of the neural activity afterthe stimuli are comprehended and do not attemptto model the cogntive process of comprehension.3 Does the distribution of neural activ-ity encode sufficient signal to classifyadjective-noun phrases?3.1 Classifier AnalysisWe are interested in whether the distribution ofneural activity encodes sufficient signal to de-code both nouns and adjective-noun phrases.Given the observed neural activity when partici-pants comprehended the adjective-noun phrases,Gaussian Na?ve Bayes classifiers were trained toidentify cognitive states associated with viewingstimuli from the evoked patterns of functionalactivity (mean PSC).
For instance, the classifierwould predict which of the 24 exemplars the par-ticipant was viewing and thinking about.
Sepa-rate classifiers were also trained for classifyingthe isolated nouns, the phrases, and the 4 seman-tic categories.Since fMRI acquires the neural activity at15,000 ?
20,000 distinct voxel locations, many ofwhich might not exhibit neural activity that en-codes word or phrase meaning, the classifieranalysis selected the voxels whose responses tothe 24 different items were most stable acrosspresentations.
Voxel stability was computed asthe average pairwise correlation between 24 itemvectors across presentations.
The focus on themost stable voxels effectively increased thesignal-to-noise ratio in the data and facilitatedfurther analysis by classifiers.
Many of ourprevious analyses have indicated that 120 voxelsis a set size suitable for our purposes.640Classification results were evaluated using 6-fold cross validation, where one of the 6 repeti-tions was left out for each fold.
The voxel selec-tion procedure was performed separately insideeach fold, using only the training data.
Sincemultiple classes were involved, rank accuracywas used (Mitchell et al, 2004) to evaluate theclassifier.
Given a new fMRI image to classify,the classifier outputs a rank-ordered list of possi-ble class labels from most to least likely.
Therank accuracy is defined as the percentile rank ofthe correct class in this ordered output list.
Rankaccuracy ranges from 0 to 1.
Classificationanalysis was performed separately for each par-ticipant, and the mean rank accuracy was com-puted over the participants.3.2 Results and DiscussionTable 2 shows the results of the exemplar-levelclassification analysis.
All classification accura-cies were significantly higher than chance (p <0.05), where the chance level for each classifica-tion is determined based on the empirical distri-bution of rank accuracies for randomly generatednull models.
One hundred null models were gen-erated by permuting the class labels.
The classi-fier was able to distinguish among the 24 exem-plars with mean rank accuracies close to 70%.We also determined the classification accuraciesseparately for nouns only and phrases only.
Dis-tinct classifiers were trained.
Classification accu-racies were significantly higher (p < 0.05) for thenouns, calculated with a paired t-test.
For 3 par-ticipants, the classifier did not achieve reliableclassification accuracies for the phrase stimuli.Moreover, we determined the classification accu-racies separately for each semantic category ofstimuli.
There were no significant differences inaccuracy across categories, except for the differ-ence between vegetables and vehicles.Classifier RaccAll 24 exemplars 0.69Nouns 0.71Phrases 0.64Animals 0.67Tools 0.66Vegetables 0.65Vehicles 0.69Table 2.
Rank accuracies for classifiers.
Distinctclassifiers were trained to distinguish all 24 ex-amples, nouns only, phrases only, and onlywords within each of the 4 semantic categories.High classification accuracies indicate that thedistributed pattern of neural activity does encodesufficient signal to discriminate differencesamong stimuli.
The classification accuracy forthe nouns was on par with previous research,providing a replication of previous findings(Mitchell et al 2004).
The classifiers performedbetter on the nouns than the phrases, consistentwith our expectation that characterizing phrasesis more difficult than characterizing nouns inisolation.
It is easier for participants to recallproperties associated with a familiar object thanto comprehend a noun whose meaning is furthermodified by an adjective.
The classificationanalysis also helps us to identify participantswhose mental representations for phrases areconsistent across phrase presentations.
Subse-quent regression analysis on phrase activationwill be based on subjects who perform the phrasetask well.4 Using vector-based models of seman-tic representation to account for thesystematic variances in neural activity4.1 Lexical Semantic RepresentationComputational linguists have demonstrated that aword?s meaning is captured to some extent bythe distribution of words and phrases with whichit commonly co-occurs (Church and Hanks,1990).
Consequently, Mitchell et al (2008) en-coded the meaning of a word as a vector of in-termediate semantic features computed from theco-occurrences with stimulus words within theGoogle trillion-token text corpus that capturesthe typical use of words in English text.
Moti-vated by existing conjectures regarding the cen-trality of sensory-motor features in neural repre-sentations of objects (Caramazza and Shelton,1998), they selected a set of 25 semantic featuresdefined by 25 verbs: see, hear, listen, taste,smell, eat, touch, rub, lift, manipulate, run, push,fill, move, ride, say, fear, open, approach, near,enter, drive, wear, break, and clean.
These verbsgenerally correspond to basic sensory and motoractivities, actions performed on objects, and ac-tions involving changes in spatial relationships.Because there are only 12 stimuli in our ex-periment, we consider only 5 sensory verbs (seehear, smell, eat and touch) to avoid overfittingwith the full set of 25 verbs.
Following the workof Bullinaria and Levy (2007), we consider the?basic semantic vector?
which normalizes n(c,t),the count of times context word c occurs within awindow of 5 words around the target word t. The641basic semantic vector is thus the vector of condi-tional probabilities,( ) ( )( )( )( )?==ctcntcntptcptcp,,,|where all components are positive and sum toone.
Table 3 shows the semantic representationfor strong and dog.
Notice that strong is heavilyloaded on see and smell, whereas dog is heavilyloaded on eat and see, consistent with the intui-tive interpretation of these two words.See Hear Smell Eat TouchStrong 0.63 0.06 0.26 0.03 0.03Dog 0.34 0.06 0.05 0.54 0.02Table 3.
The lexical semantic representation forstrong and dog.4.2 Semantic CompositionWe adopt the vector-based semantic compositionmodels discussed in Mitchell and Lapata (2008).Let u and v denote the meaning of the adjectiveand noun, respectively, and let p denote the com-position of the two words in vector space.
Weconsider two non-composition models, theadjective model and the noun model, as well astwo composition models, the additive model andthe multplicative model.The adjective model assumes that the meaningof the composition is the same as the adjective:up =The noun model assumes that the meaning ofthe composition is the same as the noun:vp =The adjective model and the noun model cor-respond to the assumption that when peoplecomprehend phrases, they focus exclusively onone of the two words.
This serves as a baselinefor comparison to other models.The additive model assumes the meaning ofthe composition is a linear combination of theadjective and noun vector:vBuAp ?+?=where A and B are vectors of weighting coeffi-cients.The multiplicative model assumes the mean-ing of the composition is the element-wise prod-uct of the two vectors:vuCp ?
?=Mitchell and Lapata (2008) fitted the parame-ters of the weighting vectors A, B, and C, thoughwe assume A = B = C = 1, since we are interestedin the model comparison.
Also, there are nomodel complexity issues, since the number ofparameters in the four models is the same.More critically, the additive model and multi-plicative model correspond to different cognitiveprocesses.
On the one hand, the additive modelassumes that people concatenate the meanings ofthe two words when comprehending phrases.
Onthe other hand, the multiplicative model assumesthat the contribution of u is scaled to its rele-vance to v, or vice versa.
Notice that the formerassumption of the multiplicative model corre-sponds to the modifier-head interpretation whereadjectives are used to modify the meaning ofnouns.
To foreshadow our results, we found themodifier-head interpretation of the multiplicativemodel to best account for the neural activity ob-served in adjective-noun phrase data.Table 4 shows the semantic representation forstrong dog under each of the four models.
Al-though the multiplicative model appears to havesmall loadings on all features, the relative distri-bution of loadings still encodes sufficient infor-mation, as our later analysis will show.
Noticehow the additive model concatenates the mean-ing of two words and is heavily loaded on see,eat, and smell, whereas the multiplicative modelzeros out unshared features like eat and smell.
Asa result, the multiplicative model predicts that thevisual aspects will be emphasized when a par-ticipant is thinking about strong dog, while theadditive model predicts that, in addition, the be-havioral aspects (e.g., eat, smell, and hear) ofdog will be emphasized.See Hear Smell Eat TouchAdj 0.63 0.06 0.26 0.03 0.03Noun 0.34 0.06 0.05 0.54 0.02Add 0.96 0.12 0.31 0.57 0.04Multi 0.21 0.00 0.01 0.01 0.00Table 4.
The semantic representation for strongdog under the adjective, noun, additive, andmultiplicative models.642Notice that these 4 vector-based semanticcomposition models ignore word order.
This cor-responds to the bag-of-words assumption, suchthat the representation for strong dog will be thesame as that of dog strong.
The bag-of-wordsmodel is used as a simplifying assumption inseveral semantic models, including LSA (Lan-dauer & Dumais, 1997) and topic models (Blei etal., 2003).There were two main hypotheses that wetested.
First, people usually regard the noun inthe adjective-noun pair as the linguistic head.Therefore, meaning associated with the nounshould be more evoked.
Thus, we predicted thatthe noun model would outperform the adjectivemodel.
Second, people make more interpreta-tions that use adjectives to modify the meaningof the noun, rather than disjunctive interpreta-tions that add together or take the union of thesemantic features of the two words.
Thus, wepredicted that the multiplicative model wouldoutperform the additive model.4.3 Regression FitIn this analysis, we train a regression model to fitthe activation profile for the 12 phrase stimuli.We focused on subjects for whom the classifierestablished reliable classification accuracies forthe phrase stimuli.
The regression model exam-ined to what extent the semantic feature vectors(explanatory variables) can account for the varia-tion in neural activity (response variable) acrossthe 12 stimuli.
All explanatory variables wereentered into the regression model simultane-ously.
More precisely, the predicted activity av atvoxel v in the brain for word w is given by( )?=+=niviviv wfa1?
?where fi(w) is the value of the ith intermediatesemantic feature for word w, ?vi is the regressioncoefficient that specifies the degree to which theith intermediate semantic feature activates voxelv, and ?v is the model?s error term that representsthe unexplained variation in the response vari-able.
Least squares estimates of ?vi were obtainedto minimize the sum of squared errors in recon-structing the training fMRI images.
An L2 regu-larization with lambda = 1.0 was added to pre-vent overfitting given the high parameter-to-data-points ratios.
A regression model wastrained for each of the 120 voxels and the re-ported R2 is the average across the 120 voxels.R2 measures the amount of systematic varianceexplained by the model.
Regression results wereevaluated using 6-fold cross validation, whereone of the 6 repetitions was left out for each fold.Linear regression assumes a linear dependencyamong the variables and compares the variancedue to the independent variables against the vari-ance due to the residual errors.
While the linear-ity assumption may be overly simplistic, it re-flects the assumption that fMRI activity oftenreflects a superimposition of contributions fromdifferent sources, and has provided a useful firstorder approximation in the field (Mitchell et al,2008).4.4 Results and DiscussionThe second column of Table 5 shows the R2 re-gression fit (averaged across 120 voxels) of theadjective, noun, additive, and multiplicativemodel to the neural activity observed in adjec-tive-noun phrase data.
The noun model signifi-cantly (p < 0.05) outperformed the adjectivemodel, estimated with a paired t-test.
Moreover,the difference between the additive and adjectivemodels was not significant, whereas the differ-ence between the additive and noun models wassignificant (p < 0.05).
The multiplicative modelsignificantly (p < 0.05) outperformed both of thenon-compositional models, as well as the addi-tive model.More importantly, the two hypotheses that wewere testing were both verified.
Notice Table 5supports our hypothesis that the noun modelshould outperform the adjective model based onthe assumption that the noun is generally morecentral to the phrase meaning than is the adjec-tive.
Table 5 also supports our hypothesis thatthe multiplicative model should outperform theadditive model, based on the assumption thatadjectives are used to emphasize particular se-mantic features that will already be representedin the semantic feature vector of the noun.
Ourfindings here are largely consistent with Mitchelland Lapata (2008).R2 RaccAdjective 0.34 0.57Noun 0.36 0.61Additive 0.35 0.60Multiplicative 0.42 0.62Table 5.
Regression fit and regression-basedclassification rank accuracy of the adjective,noun, additive, and multiplicative models forphrase stimuli.643Following Mitchell et al (2008), the regres-sion model can be used to decode mental states.Specifically, for each regression model, the esti-mated regression weights can be used to generatethe predicted activity for each word.
Then, a pre-viously unseen neural activation vector is identi-fied with the class of the predicted activation thathad the highest correlation with the given ob-served neural activation vector.
Notice that,unlike Mitchell et al (2008), where the regres-sion model was used to make predictions foritems outside the training set, here we are justshowing that the regression model can be usedfor classification purposes.The third column of Table 5 shows the rankaccuracies classifying mental concepts using thepredicted activation from the adjective, noun,additive, and multiplicative models.
All rank ac-curacies were significantly higher (p < 0.05) thanchance, where the chance level for each classifi-cation is again determined by permutation test-ing.
More importantly, here we observe a rank-ing of these four models similar to that observedfor the regression analysis.
Namely, the nounmodel performs significantly better (p < 0.05)than the adjective model, and the multiplicativemodel performs significantly better (p < 0.05)than the additive model.
However, the differencebetween the multiplicative model and the nounmodel is not statistically significant in this case.5 Comparing the attribute-specifyingadjectives with the object-modifyingadjectivesSome of the phrases contained adjectives thatchanged the meaning of the noun.
In the case ofvehicle nouns, adjectives were chosen to modifythe manipulability of the nouns (e.g., to make anairplane more manipulable, paper was chosen asthe modifier).
This type of modifier raises twoissues.
First, these modifiers (e.g.
paper, model,toy) more typically assume the part of speech(POS) tag of nouns, unlike our other modifiers(e.g., soft, large, strong) whose typical POS tagis adjective.
Second, these modifiers combinewith the noun to denote a very different objectfrom the noun in isolation (paper airplane,model train, toy truck), in comparison to othercases where the adjective simply specifies anattribute of the noun (soft bear, large cat, strongdog, etc.).
In order to study this difference, weperformed classification analysis separately forthe attribute-specifying adjectives and the object-modifying adjectives.Our hypothesis is that the phrases with attrib-ute-specifying adjectives will be much more dif-ficult to distinguish from the original nouns thanthe adjectives that change the referent.
For in-stance, we hypothesize that it is much more dif-ficult to distinguish the neural representation forstrong dog versus dog than it is to distinguish theneural representation for paper airplane versusairplane.
To verify this, Gaussian Na?ve Bayesclassifiers were trained to discriminate betweeneach of the 12 pairs of nouns and adjective-nounphrases.
The average classification for phraseswith object-modifying adjectives is 0.76,whereas classification accuracies for phraseswith attribute-specifying adjectives are 0.68.
Thedifference is statistically significant at p < 0.05.This result supports our hypothesis.Furthermore, we performed regression-basedclassification separately for the two types of ad-jectives.
Notice that the number of phrases withobject-modifying adjectives is much less than thenumber of phrases with attribute-specifying ad-jectives (3 vs. 9).
This affects the parameter-to-data-points ratio in our regression model.
Conse-quently, an L2 regularization with lambda = 10.0was used to prevent overfitting.
Table 6 shows apattern similar to that seen in section 4 is ob-served for the attribute-specifying adjectives.That is, the noun model outperformed the adjec-tive model and the multiplicative model outper-formed the additive model when using attribute-specifying adjectives.
However, for the object-modifying adjectives, the noun model no longeroutperformed the adjective model.
Moreover, theadditive model performed better than the nounmodel.
Although neither difference is statisticallysignificant, this clearly shows a pattern differentfrom the attribute-specifying adjectives.
Thisresult suggests that when interpreting phraseslike paper airplane, it is more important to con-sider contributions from the adjectives, comparedto when interpreting phrases like strong dog,where the contribution from the adjective is sim-ply to specify a property of the item typicallyreferred to by the noun in isolation.Attribute-specifyingObject-modifyingAdjective 0.57 0.65Noun 0.62 0.64Additive 0.61 0.65Multiplicative 0.63 0.67Table 6.
Separate regression-based classificationrank accuracy for phrases with attribute-specifying or object-modifying adjectives.644In light of this observation, we plan to extendour analysis of adjective-nouns phrases to noun-noun phrases, where participants will be shownnoun phrases (e.g.
carrot knife) and instructed tothink of a likely meaning for the phrases.
Unlikeadjective-noun phrases, where a single interpre-tation often dominates, noun-noun combinationsallow multiple interpretations (e.g., carrot knifecan be interpreted as a knife that is specificallyused to cut carrots or a knife carved out of car-rots).
There exists an extensive literature on theconceptual combination of noun-noun phrases.Costello and Keane (1997) provide extensivestudies on the polysemy of conceptual combina-tion.
More importantly, they outline differentrules of combination, including property map-ping, relational mapping, hybrid mapping, etc.
Itwill be interesting to see if different compositionmodels better account for neural activation whendifferent kinds of combination rules are used.6 Contribution and ConclusionExperimental results have shown that the distrib-uted pattern of neural activity while people arecomprehending adjective-noun phrases does con-tain sufficient information to decode the stimuliwith accuracies significantly above chance.
Fur-thermore, vector-based semantic models can ex-plain a significant portion of systematic variancein observed neural activity.
Multiplicative com-position models outperform additive models, atrend that is consistent with the assumption thatpeople use adjectives to modify the meaning ofthe noun, rather than conjoining the meaning ofthe adjective and noun.In this study, we represented the meaning ofboth adjectives and nouns in terms of their co-occurrences with 5 sensory verbs.
While thistype of representation might be justified for con-crete nouns (hypothesizing that their neural rep-resentations are largely grounded in sensory-motor features), it might be that a different repre-sentation is needed for adjectives.
Further re-search is needed to investigate alternative repre-sentations for both nouns and adjectives.
More-over, the composition models that we presentedhere are overly simplistic in a number of ways.We look forward to future research to extend theintermediate representation and to experimentwith different modeling methodologies.
An al-ternative approach is to model the semantic rep-resentation as a hidden variable using a genera-tive probabilistic model that describes how neu-ral activity is generated from some latent seman-tic representation.
We are currently exploring theinfinite latent semantic feature model (ILFM;Griffiths & Ghahramani, 2005), which assumes anon-parametric Indian Buffet prior to the binaryfeature vector and models neural activation witha linear Gaussian model.
The basic propositionof the model is that the human semantic knowl-edge system is capable of storing an infinite listof features (or semantic components) associatedwith a concept; however, only a subset is ac-tively recalled during any given task (context-dependent).
Thus, a set of latent indicator vari-ables is introduced to indicate whether a featureis actively recalled at any given task.
We are in-vestigating if the compositional models also op-erate in the learned latent semantic space.The premise of our research relies on ad-vancements in the fields of computational lin-guistics and cognitive neuroimaging.
Indeed, weare at an especially opportune time in the historyof the study of language, when linguistic corporaallow word meanings to be computed from thedistribution of word co-occurrence in a trillion-token text corpus, and brain imaging technologyallows us to directly observe and model neuralactivity associated with the conceptual combina-tion of lexical items.
An improved understandingof language processing in the brain could yield amore biologically-informed model of semanticrepresentation of lexical knowledge.
We there-fore look forward to further brain imaging stud-ies shedding new light on the nature of humanrepresentation of semantic knowledge.AcknowledgementsThis research was supported by the National Sci-ence Foundation, Grant No.
IIS-0835797, and bythe W. M. Keck Foundation.
We would like tothank Jennifer Moore for help in preparation ofthe manuscript.ReferencesBlei, D. M., Ng, A. Y., Jordan, and M. I.. 2003.
La-tent dirichlet alocation.
Journal of Machine Learn-ing Research 3, 993-1022.Bullinaria, J., and Levy, J.
2007.
Extracting semanticrepresentations from word co-occurrence statistics:A computational study.
Behavioral ResearchMethods, 39:510-526.Caramazza, A., and Shelton, J. R. 1998.
Domain-specific knowledge systems in the brain the ani-mate inanimate distinction.
Journal of CognitiveNeuroscience 10(1), 1-34.645Church, K. W., and Hanks, P. 1990.
Word associationnorms, mutual information, and lexicography.Computational Linguistics, 16, 22-29.Cree, G. S., and McRae, K. 2003.
Analyzing the fac-tors underlying the structure and computation ofthe meaning of chipmunk, cherry, chisel, cheese,and cello (and many other such concrete nouns).Journal of Experimental Psychology: General132(2), 163-201.Costello, F., and Keane, M. 2001.
Testing two theo-ries of conceptual combination: Alignment versusdiagnosticity in the comprehension and productionof combined concepts.
Journal of ExperimentalPsychology: Learning, Memory & Cognition,27(1): 255-271.Cox, D. D., and Savoy, R. L. 2003.
Functioning mag-netic resonance imaging (fMRI) "brain reading":Detecting and classifying distributed patterns offMRI activity in human visual cortex.
NeuroImage19, 261-270.Friston, K. J.
2005.
Models of brain function in neuro-imaging.
Annual Review of Psychology 56, 57-87.Griffiths, T. L., and Ghahramani, Z.
2005.
Infinitelatent feature models and the Indian buffet process.Gatsby Unit Technical Report GCNU-TR-2005-001.Haynes, J. D., and Rees, G. 2006.
Decoding mentalstates from brain activity in humans.
Nature Re-views Neuroscience 7(7), 523-534.Kintsch, W. 2001.
Prediction.
Cognitive Science,25(2):173-202.Landauer, T.K., and Dumais, S. T. 1997.
A solution toPlato?s problem: The latent semantic analysis the-ory of acquisition, induction, and representation ofknowledge.
Psychological Review, 104(2), 211-240.Miller, G. A.
1995.
WordNet: A lexical database forEnglish.
Communications of the ACM 38, 39-41.Mitchell, J., and Lapata, M. 2008.
Vector-based mod-els of semantic composition.
Proceedings of ACL-08: HLT, 236-244.Mitchell, T., Hutchinson, R., Niculescu, R. S.,Pereira, F., Wang, X., Just, M. A., and Newman, S.D.
2004.
Learning to decode cognitive states frombrain images.
Machine Learning 57, 145-175.Mitchell, T., Shinkareva, S.V., Carlson, A., Chang,K.M., Malave, V.L., Mason, R.A., and Just, M.A.2008.
Predicting human brain activity associatedwith the meanings of nouns.
Science 320, 1191-1195.O'Toole, A. J., Jiang, F., Abdi, H., and Haxby, J. V.2005.
Partially distributed representations of ob-jects and faces in ventral temporal cortex.
Journalof Cognitive Neuroscience, 17, 580-590.646
