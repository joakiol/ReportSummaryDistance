Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 114?124,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDecentralized Entity-Level Modeling for Coreference ResolutionGreg Durrett, David Hall, and Dan KleinComputer Science DivisionUniversity of California, Berkeley{gdurrett,dlwh,klein}@cs.berkeley.eduAbstractEfficiently incorporating entity-level in-formation is a challenge for coreferenceresolution systems due to the difficulty ofexact inference over partitions.
We de-scribe an end-to-end discriminative prob-abilistic model for coreference that, alongwith standard pairwise features, enforcesstructural agreement constraints betweenspecified properties of coreferent men-tions.
This model can be represented asa factor graph for each document that ad-mits efficient inference via belief propaga-tion.
We show that our method can useentity-level information to outperform abasic pairwise system.1 IntroductionThe inclusion of entity-level features has been adriving force behind the development of manycoreference resolution systems (Luo et al, 2004;Rahman and Ng, 2009; Haghighi and Klein, 2010;Lee et al, 2011).
There is no polynomial-time dy-namic program for inference in a model with ar-bitrary entity-level features, so systems that usesuch features typically rely on making decisionsin a pipelined manner and sticking with them, op-erating greedily in a left-to-right fashion (Rahmanand Ng, 2009) or in a multi-pass, sieve-like man-ner (Raghunathan et al, 2010).
However, suchsystems may be locked into bad coreference deci-sions and are difficult to directly optimize for stan-dard evaluation metrics.In this work, we present a new structured modelof entity-level information designed to allow effi-cient inference.
We use a log-linear model that canbe expressed as a factor graph.
Pairwise featuresappear in the model as unary factors, adjacentto nodes representing a choice of antecedent (ornone) for each mention.
Additional nodes modelentity-level properties on a per-mention basis, andstructural agreement factors softly drive propertiesof coreferent mentions to agree with one another.This is a key feature of our model: mentions man-age their partial membership in various corefer-ence chains, so that information about entity-levelproperties is decentralized and propagated acrossindividual mentions, and we never need to explic-itly instantiate entities.Exact inference in this factor graph is in-tractable, but efficient approximate inference canbe carried out with belief propagation.
Our modelis the first discriminatively-trained model that bothmakes joint decisions over an entire document andmodels specific entity-level properties, rather thansimply enforcing transitivity of pairwise decisions(Finkel and Manning, 2008; Song et al, 2012).We evaluate our system on the dataset fromthe CoNLL 2011 shared task using three differ-ent types of properties: synthetic oracle proper-ties, entity phi features (number, gender, animacy,and NER type), and properties derived from un-supervised clusters targeting semantic type infor-mation.
In all cases, our transitive model of en-tity properties equals or outperforms our pairwisesystem and our reimplementation of a previousentity-level system (Rahman and Ng, 2009).
Ourfinal system is competitive with the winner of theCoNLL 2011 shared task (Lee et al, 2011).2 ExampleWe begin with an example motivating our use ofentity-level features.
Consider the following ex-cerpt concerning two famous auction houses:When looking for [art items], [people] goto [Sotheby?s and Christie?s] because [they]Abelieve [they]B can get the best price for[them].The first three mentions are all distinct entities,theyA and theyB refer to people, and them refers toart items.
The three pronouns are tricky to resolve114automatically because they could at first glance re-solve to any of the preceding mentions.
We focusin particular on the resolution of theyA and them.In order to correctly resolve theyA to people ratherthan Sotheby?s and Christie?s, we must take ad-vantage of the fact that theyA appears as the sub-ject of the verb believe, which is much more likelyto be attributed to people than to auction houses.Binding principles prevent them from attachingto theyB.
But how do we prevent it from choos-ing as its antecedent the next closest agreeing pro-noun, theyA?
One way is to exploit the correctcoreference decision we have already made, theyAreferring to people, since people are not as likelyto have a price as art items are.
This observa-tion argues for enforcing agreement of entity-levelsemantic properties during inference, specificallyproperties relating to permitted semantic roles.Because even these six mentions have hundredsof potential partitions into coreference chains, wecannot search over partitions exhaustively, andtherefore we must design our model to be able touse this information while still admitting an effi-cient inference scheme.3 ModelsWe will first present our BASIC model (Sec-tion 3.1) and describe the features it incorporates(Section 3.2), then explain how to extend it to usetransitive features (Sections 3.3 and 3.4).Throughout this section, let x be a variable con-taining the words in a document along with anyrelevant precomputed annotation (such as parse in-formation, semantic roles, etc.
), and let n denotethe number of mentions in a given document.3.1 BASIC ModelOur BASIC model is depicted in Figure 1 in stan-dard factor graph notation.
Each mention i hasan associated random variable ai taking values inthe set {1, .
.
.
, i?1, <new>}; this variable spec-ifies mention i?s selected antecedent or indicatesthat it begins a new coreference chain.
Let a =(a1, ..., an) be the vector of the ai.
Note that a setof coreference chains C (the final desired output)can be uniquely determined from a, but a is notuniquely determined by C.We use a log linear model of the conditional dis-tribution P (a|x) as follows:P (a|x) ?
exp( n?i=1wT fA(i, ai, x))When looking for [art items], [people] go to [Sotheby'sand Christie's] because [they]Abelieve [they]Bcan getthe best price for [them].art items 0.15people 0.4Sotheby?s andChristie?s0.4<new> 0.05a2a3a4a1A1A2A3A4art items 0.05<new> 0.95antecedentchoicesantecedentfactors}}Figure 1: Our BASIC coreference model.
A de-cision ai is made independently for each men-tion about what its antecedent mention shouldbe or whether it should start a new coreferencechain.
Each unary factor Ai has a log-linear formwith features examining mention i, its selected an-tecedent ai, and the document context x.where fA(i, ai, x) is a feature function that exam-ines the coreference decision ai for mention i withdocument context x; note that this feature functioncan include pairwise features based on mention iand the chosen antecedent ai, since informationabout each mention is contained in x.Because the model factors completely over theindividual ai, these feature functions fA can be ex-pressed as unary factors Ai (see Figure 1), withAi(j) ?
exp(wT fA(i, j, x)).
Given a setting ofw, we can determine a?
= argmaxa P (a|x) andthen deterministically compute C(a), the final setof coreference chains.While the features of this model factor overcoreference links, this approach differs from clas-sical pairwise systems such as Bengtson and Roth(2008) or Stoyanov et al (2010).
Because poten-tial antecedents compete with each other and withthe non-anaphoric hypothesis, the choice of ai ac-tually represents a joint decision about i?1 pair-wise links, as opposed to systems that use a pair-wise binary classifier and a separate agglomera-tion step, which consider one link at a time duringlearning.
This approach is similar to the mention-ranking model of Rahman and Ng (2009).3.2 Pairwise FeaturesWe now present the set of features fA used by ourunary factors Ai.
Each feature examines the an-115tecedent choice ai of the current mention as wellas the observed information x in the document.For each of the features we present, two conjoinedversions are included: one with an indicator of thetype of the current mention being resolved, andone with an indicator of the types of the currentand antecedent mentions.
Mention types are eitherNOMINAL, PROPER, or, if the mention is pronom-inal, a canonicalized version of the pronoun ab-stracting away case.1Several features, especially those based on theprecise constructs (apposition, etc.)
and those in-corporating phi feature information, are computedusing the machinery in Lee et al (2011).
Otherfeatures were inspired by Song et al (2012) andRahman and Ng (2009).Anaphoricity features: Indicator of anaphoric-ity, indicator on definiteness.Configurational features: Indicator on distancein mentions (capped at 10), indicator on dis-tance in sentences (capped at 10), does the an-tecedent c-command the current mention, are thetwo mentions in a subject/object construction, arethe mentions nested, are the mentions in determin-istic appositive/role appositive/predicate nomina-tive/relative pronoun constructions.Match features: Is one mention an acronym ofthe other, head match, head contained (each way),string match, string contained (each way), relaxedhead match features from Lee et al (2011).Agreement features: Gender, number, ani-macy, and NER type of the current mention andthe antecedent (separately and conjoined).Discourse features: Speaker match conjoinedwith an indicator of whether the document is anarticle or conversation.Because we use conjunctions of these base fea-tures together with the antecedent and mentiontype, our system can capture many relationshipsthat previous systems hand-coded, especially re-garding pronouns.
For example, our system hasaccess to features such as ?it is non-anaphoric?,?it has as its antecedent a geopolitical entity?, or?I has as its antecedent I with the same speaker.
?1While this canonicalization could theoretically impairour ability to resolve, for example, reflexive pronouns, con-joining features with raw pronoun strings does not improveperformance.We experimented with synonymy and hyper-nymy features from WordNet (Miller, 1995), butthese did not empirically improve performance.3.3 TRANSITIVE ModelThe BASIC model can capture many relationshipsbetween pairs of mentions, but cannot necessarilycapture entity-level properties like those discussedin Section 2.
We could of course model entitiesdirectly (Luo et al, 2004; Rahman and Ng, 2009),saying that each mention refers to some prior en-tity rather than to some prior mention.
However,inference in this model would require reasoningabout all possible partitions of mentions, which iscomputationally infeasible without resorting to se-vere approximations like a left-to-right inferencemethod (Rahman and Ng, 2009).Instead, we would like to try to preserve thetractability of the BASIC model while still beingable to exploit entity-level information.
To do so,we will allow each mention to maintain its owndistributions over values for a number of proper-ties; these properties could include gender, named-entity type, or semantic class.
Then, we will re-quire each anaphoric mention to agree with its an-tecedent on the value of each of these properties.Our TRANSITIVE model which implements thisscheme is shown in Figure 2.
Each mention ihas been augmented with a single property nodepi ?
{1, ..., k}.
The unary Pi factors encode priorknowledge about the setting of each pi; these fac-tors may be hard (I will not refer to a plural entity),soft (such as a distribution over named entity typesoutput by an NER tagger), or practically uniform(e.g.
the last name Smith does not specify a partic-ular gender).To enforce agreement of a particular property,we require a mention to have the same propertyvalue as its antecedent.
That is, for mentions i andj, if ai = j, we want to ensure that pi and pjagree.
We can achieve this with the following setof structural equality factors:Ei?j(ai, pi, pj) = 1?
I[ai = j ?
pi 6= pj ]In words, this factor is zero if both ai = j andpi disagrees with pj .
These equality factors es-sentially provide a mechanism by which these pri-ors Pi can influence the coreference decisions: if,for example, the factors Pi and Pj disagree verystrongly, choosing ai 6= j will be preferred in or-der to avoid forcing one of pi or pj to take an un-desirable value.
Moreover, note that although ai116E4-3a2a4p4p3p2E4-2A2A3A4P2P3P4antecedentchoicesantecedentfactorspropertyfactorspropertiesequalityfactorsa3}}}}}peopleSotheby'sand Christie'stheyFigure 2: The factor graph for our TRANSI-TIVE coreference model.
Each node ai now hasa property pi, which is informed by its own unaryfactor Pi.
In our example, a4 strongly indicatesthat mentions 2 and 4 are coreferent; the factorE4?2 then enforces equality between p2 and p4,while the factor E4?3 has no effect.only indicates a single antecedent, the transitivenature of the E factors forces pi to agree with thep nodes of all other mentions likely to be in thesame entity.3.4 Property ProjectionSo far, our model as specified ensures agreementof our entity-level properties, but strictly enforc-ing agreement may not always be correct.
Supposethat we are using named entity type as an entity-level property.
Organizations and geo-political en-tities are two frequently confused and ambiguoustags, and in the gold-standard coreference chainsit may be the case that a single chain contains in-stances of both.
We might wish to learn that or-ganizations and geo-political entities are ?compat-ible?
in the sense that we should forgive entitiesfor containing both, but without losing the abilityto reject a chain containing both organizations andpeople, for example.To address these effects, we expand our modelas indicated in Figure 3.
As before, we have aset of properties pi and agreement factors Eij .
Ontop of that, we introduce the notion of raw prop-erty values ri ?
{1, ..., k} together with priors inthe form of the Ri factors.
The ri and pi could inprinciple have different domains, but for this workwe take them to have the same domain.
The Pifactors now have a new structure: they now rep-resent a featurized projection of the ri onto thepi, which can now be thought of as ?coreference-p4p3p2r4r3r2P2P3P4R2R3R4raw propertyfactorsraw propertiesprojectionfactorsprojectedproperties}}}}a2a4A2A3A4a3E3-1E4-1Figure 3: The complete factor graph for ourTRANSITIVE coreference model.
Compared toFigure 2, the Ri contain the raw cluster posteriors,and the Pi factors now project raw cluster values riinto a set of ?coreference-adapted?
clusters pi thatare used as before.
This projection allows men-tions with different but compatible raw propertyvalues to coexist in the same coreference chain.adapted?
properties.
The Pi factors are defined byPi(pi, ri) ?
exp(wT fP (pi, ri)), where fP is a fea-ture vector over the projection of ri onto pi.
Whilethere are many possible choices of fP , we chooseit to be an indicator of the values of pi and ri, sothat we learn a fully-parameterized projection ma-trix.2 The Ri are constant factors, and may comefrom an upstream model or some other source de-pending on the property being modeled.Our description thus far has assumed that weare modeling only one type of property.
In fact,we can use multiple properties for each mentionby duplicating the r and p nodes and the R, P ,and E factors across each desired property.
Weindex each of these by l ?
{1, .
.
.
,m} for each ofm properties.The final log-linear model is given by the fol-lowing formula:P (a|x) ??p,r????
?i,j,lEl,i?j(ai, pli, plj)?????i,lRli(rli)?
?exp(wT?i(fA(i, ai, x) +?lfP (pli, rli)))]where i and j range over mentions, l ranges over2Initialized to zero (or small values), this matrix actuallycauses the transitive machinery to have no effect, since allposteriors over the pi are flat and completely uninformative.Therefore, we regularize the weights of the indicators of pi =ri towards 1 and all other features towards 0 to give each rawcluster a preference for a distinct projected cluster.117each of m properties, and the outer sum indicatesmarginalization over all p and r variables.4 LearningNow that we have defined our model, we mustdecide how to train its weights w. The firstissue to address is one of the supervision pro-vided.
Our model traffics in sets of labels awhich are more specified than gold coreferencechains C, which give cluster membership for eachmention but not antecedence.
Let A(C) be theset of labelings a that are consistent with a setof coreference chains C. For example, if C ={{1, 2, 3}, {4}}, then (<new>, 1, 2, <new>) ?A(C) and (<new>, 1, 1, <new>) ?
A(C) but(<new>, 1, <new>, 3) /?
A(C), since this im-plies the chains C = {{1, 2}, {3, 4}}The most natural objective is a variant ofstandard conditional log-likelihood that treats thechoice of a for the specified C as a latent variableto be marginalized out:`(w) =t?i=1log??
?a?A(Ci)P (a|xi)??
(1)where (xi, Ci) is the ith labeled training example.This optimizes for the 0-1 loss; however, we aremuch more interested in optimizing with respectto a coreference-specific loss function.To this end, we will use softmax-margin (Gim-pel and Smith, 2010), which augments the proba-bility of each example with a term proportional toits loss, pushing the model to assign less mass tohighly incorrect examples.
We modify Equation 1to use a new probability distribution P ?
insteadof P , where P ?
(a|xi) ?
P (a|xi) exp (l(a,C))and l(a,C) is a loss function.
In order toperform inference efficiently, l(a,C) must de-compose linearly across mentions: l(a,C) =?ni=1 l(ai, C).
Commonly-used coreference met-rics such as MUC (Vilain et al, 1995) and B3(Bagga and Baldwin, 1998) do not have this prop-erty, so we instead make use of a parameterizedloss function that does and fit the parameters togive good performance.
Specifically, we takel(a,C) =n?i=1[c1I(K1(ai, C)) + c2I(K2(ai, C))+ c3I(K3(ai, C))]where c1, c2, and c3 are real-valued weights, K1denotes the event that ai is falsely anaphoric whenit should be non-anaphoric, K2 denotes the eventthat ai is falsely non-anaphoric when it should beanaphoric, and K3 denotes the event that ai is cor-rectly determined to be anaphoric but .
These canbe computed based on only ai and C. By settingc1 low and c2 high relative to c3, we can forcethe system to be less conservative about makinganaphoricity decisions and achieve a better bal-ance with the final coreference metrics.Finally, we incorporate L1 regularization, giv-ing us our final objective:`(w) =t?i=1log??
?a?A(Ci)P ?(a|xi)?
?+ ?
?w?1We optimize this objective using AdaGrad(Duchi et al, 2011); we found this to be faster andgive higher performance than L-BFGS using L2regularization (Liu and Nocedal, 1989).
Note thatbecause of the marginalization over A(Ci), eventhe objective for the BASIC model is not convex.5 InferenceInference in the BASIC model is straightforward.Given a set of weights w, we can predicta?
= argmaxaP (a|x)We then report the corresponding chains C(a)as the system output.3 For learning, the gradi-ent takes the standard form of the gradient of alog-linear model, a difference of expected featurecounts under the gold annotation and under noannotation.
This requires computing marginalsP ?
(ai|x) for each mention i, but because themodel already factors this way, this step is easy.The TRANSITIVE model is more complex.
Ex-act inference is intractable due to theE factors thatcouple all of the ai by way of the pi nodes.
How-ever, we can compute approximate marginals forthe ai, pi, and ri using belief propagation.
BP hasbeen effectively used on other NLP tasks (Smithand Eisner, 2008; Burkett and Klein, 2012), and iseffective in cases such as this where the model islargely driven by non-loopy factors (here, the Ai).From marginals over each node, we can com-pute the necessary gradient and decode as before:a?
= argmaxaP?
(a|x)3One could use ILP-based decoding in the style of Finkeland Manning (2008) and Song et al (2012) to attempt to ex-plicitly find the optimal C with choice of a marginalized out,but we did not explore this option.118This corresponds to minimum-risk decoding withrespect to the Hamming loss over antecedence pre-dictions.Pruning.
The TRANSITIVE model requires in-stantiating a factor for each potential setting ofeach ai.
This factor graph grows quadratically inthe size of the document, and even approximate in-ference becomes slow when a document containsover 200 mentions.
Therefore, we use our BA-SIC model to prune antecedent choices for eachai in order to reduce the size of the factor graphthat we must instantiate.
Specifically, we prunelinks between pairs of mentions that are of men-tion distance more than 100, as well as values forai that fall below a particular odds ratio thresholdwith respect to the best setting of that ai in theBASIC model; that is, those for whichlog( PBASIC (ai|x)maxj PBASIC (ai = j|x))is below a cutoff ?.6 Related WorkOur BASIC model is a mention-ranking approachresembling models used by Denis and Baldridge(2008) and Rahman and Ng (2009), though it istrained using a novel parameterized loss function.It is also similar to the MLN-JOINT(BF) modelof Song et al (2012), but we enforce the single-parent constraint at a deeper structural level, al-lowing us to treat non-anaphoricity symmetricallywith coreference as in Denis and Baldridge (2007)and Stoyanov and Eisner (2012).
The model ofFernandes et al (2012) also uses the single-parentconstraint structurally, but with learning via la-tent perceptron and ILP-based one-best decod-ing rather than logistic regression and BP-basedmarginal computation.Our TRANSITIVE model is novel; while Mc-Callum and Wellner (2004) proposed the idea ofusing attributes for mentions, they do not actu-ally implement a model that does so.
Other sys-tems include entity-level information via hand-written rules (Raghunathan et al, 2010), inducedrules (Yang et al, 2008), or features with learnedweights (Luo et al, 2004; Rahman and Ng, 2011),but all of these systems freeze past coreference de-cisions in order to compute their entities.Most similar to our entity-level approach isthe system of Haghighi and Klein (2010), whichalso uses approximate global inference; however,theirs is an unsupervised, generative system andthey attempt to directly model multinomials overwords in each mention.
Their system could be ex-tended to handle property information like we do,but our system has many other advantages, such asfreedom from a pre-specified list of entity types,the ability to use multiple input clusterings, anddiscriminative projection of clusters.7 ExperimentsWe use the datasets, experimental setup, and scor-ing program from the CoNLL 2011 shared task(Pradhan et al, 2011), based on the OntoNotescorpus (Hovy et al, 2006).
We use the standardautomatic parses and NER tags for each docu-ment.
Our mentions are those output by the sys-tem of Lee et al (2011); we also use their postpro-cessing to remove appositives, predicate nomina-tives, and singletons before evaluation.
For eachexperiment, we report MUC (Vilain et al, 1995),B3 (Bagga and Baldwin, 1998), and CEAFe (Luo,2005), as well as their average.Parameter settings.
We take the regularizationconstant ?
= 0.001 and the parameters of oursurrogate loss (c1, c2, c3) = (0.15, 2.5, 1) for allmodels.4 All models are trained for 20 iterations.We take the pruning threshold ?
= ?2.7.1 SystemsBesides our BASIC and TRANSITIVE systems, weevaluate a strictly pairwise system that incorpo-rates property information by way of indicator fea-tures on the current mention?s most likely propertyvalue and the proposed antecedent?s most likelyproperty value.
We call this system PAIRPROP-ERTY; it is simply the BASIC system with an ex-panded feature set.Furthermore, we compare against a LEFT-TORIGHT entity-level system like that of Rahmanand Ng (2009).5 Decoding now operates in a se-quential fashion, with BASIC features computedas before and entity features computed for eachmention based on the coreference decisions madethus far.
Following Rahman and Ng (2009), fea-tures for each property indicate whether the cur-4Additional tuning of these hyper parameters did not sig-nificantly improve any of the models under any of the exper-imental conditions.5Unfortunately, their publicly-available system is closed-source and performs poorly on the CoNLL shared taskdataset, so direct comparison is difficult.119rent mention agrees with no mentions in the an-tecedent cluster, at least one mention, over half ofthe mentions, or all of the mentions; antecedentclusters of size 1 or 2 fire special-cased features.These additional features beyond those in Rah-man and Ng (2009) were helpful, but more in-volved conjunction schemes and fine-grained fea-tures were not.
During training, entity features ofboth the gold and the prediction are computed us-ing the Viterbi clustering of preceding mentionsunder the current model parameters.6All systems are run in a two-pass manner:first, the BASIC model is run, then antecedentchoices are pruned, then our second-round modelis trained from scratch on the pruned data.77.2 Noisy Oracle FeaturesWe first evaluate our model?s ability to exploit syn-thetic entity-level properties.
For this experiment,mention properties are derived from corrupted or-acle information about the true underlying corefer-ence cluster.
Each coreference cluster is assumedto have one underlying value for each of m coref-erence properties, each taking values over a do-main D. Mentions then sample distributions overD from a Dirichlet distribution peaked around thetrue underlying value.8 These posteriors are takenas the Ri for the TRANSITIVE model.We choose this setup to reflect two importantproperties of entity-level information: first, that itmay come from a variety of disparate sources, andsecond, that it may be based on the determinationsof upstream models which produce posteriors nat-urally.
A strength of our model is that it can acceptsuch posteriors as input, naturally making use ofthis information in a model-based way.Table 1 shows development results averagedacross ten train-test splits with m = 3 proper-ties, each taking one of |D| = 5 values.
We em-phasize that these parameter settings give fairlyweak oracle information: a document may havehundreds of clusters, so even in the absence ofnoise these oracle properties do not have high dis-6Using gold entities for training as in Rahman and Ng(2009) resulted in a lower-performing system.7We even do this for the BASIC model, since we foundthat performance of the pruned and retrained model was gen-erally higher.8Specifically, the distribution used is a Dirichlet with?
= 3.5 for the true underlying cluster and ?
= 1 for othervalues, chosen so that 25% of samples from the distributiondid not have the correct mode.
Though these parameters af-fect the quality of the oracle information, varying them didnot change the relative performance of the different models.NOISY ORACLEMUC B3 CEAFe Avg.BASIC 61.96 70.66 47.30 59.97PAIRPROPERTY 66.31 72.68 49.08 62.69LEFTTORIGHT 66.49 73.14 49.46 63.03TRANSITIVE 67.37 74.05 49.68 63.70Table 1: CoNLL metric scores for our four dif-ferent systems incorporating noisy oracle data.This information helps substantially in all cases.Both entity-level models outperform the PAIR-PROPERTY model, but we observe that the TRAN-SITIVE model is more effective than the LEFT-TORIGHT model at using this information.criminating power.
Still, we see that all mod-els are able to benefit from incorporating this in-formation; however, our TRANSITIVE model out-performs both the PAIRPROPERTY model and theLEFTTORIGHT model.
There are a few reasonsfor this: first, our model is able to directly use softposteriors, so it is able to exploit the fact that morepeaked samples from the Dirichlet are more likelyto be correct.
Moreover, our model can propagateinformation backwards in a document as well asforwards, so the effects of noise can be more eas-ily mitigated.
By contrast, in the LEFTTORIGHTmodel, if the first or second mention in a clusterhas the wrong property value, features indicatinghigh levels of property agreement will not fire onthe next few mentions in those clusters.7.3 Phi FeaturesAs we have seen, our TRANSITIVE model can ex-ploit high-quality entity-level features.
How doesit perform using real features that have been pro-posed for entity-level coreference?Here, we use hard phi feature determinationsextracted from the system of Lee et al (2011).Named-entity type and animacy are both com-puted based on the output of a named-entity tag-ger, while number and gender use the dataset ofBergsma and Lin (2006).
Once this informa-tion is determined, the PAIRPROPERTY and LEFT-TORIGHT systems can compute features over it di-rectly.
In the TRANSITIVE model, each of the Rifactors places 34 of its mass on the determined la-bel and distributes the remainder uniformly amongthe possible options.Table 2 shows results when adding entity-levelphi features on top of our BASIC pairwise system(which already contains pairwise features) and ontop of an ablated BASIC system without pairwise120PHI FEATURESMUC B3 CEAFe Avg.BASIC 61.96 70.66 47.30 59.97LEFTTORIGHT 61.34 70.41 47.64 59.80TRANSITIVE 62.66 70.92 46.88 60.16PHI FEATURES (ABLATED BASIC)BASIC-PHI 59.45 69.21 46.02 58.23PAIRPROPERTY 61.88 70.66 47.14 59.90LEFTTORIGHT 61.42 70.53 47.49 59.81TRANSITIVE 62.23 70.78 46.74 59.92Table 2: CoNLL metric scores for our systems in-corporating phi features.
Our standard BASIC sys-tem already includes phi features, so no results arereported for PAIRPROPERTY.
Here, our TRAN-SITIVE system does not give substantial improve-ment on the averaged metric.
Over a baselinewhich does not include phi features, all systemsare able to incorporate them comparably.phi features.
Our entity-level systems successfullycaptures phi features when they are not present inthe baseline, but there is only slight benefit overpairwise incorporation, a result which has beennoted previously (Luo et al, 2004).7.4 Clustering FeaturesFinally, we consider mention properties derivedfrom unsupervised clusterings; these propertiesare designed to target semantic properties of nom-inals that should behave more like the oracle fea-tures than the phi features do.We consider clusterings that take as input pairs(n, r) of a noun head n and a string r which con-tains the semantic role of n (or some approxima-tion thereof) conjoined with its governor.
Two dif-ferent algorithms are used to cluster these pairs: aNAIVEBAYES model, where c generates n and r,and a CONDITIONAL model, where c is generatedconditioned on r and then n is generated from c.Parameters for each can be learned with the ex-pectation maximization (EM) algorithm (Demp-ster et al, 1977), with symmetry broken by a smallamount of random noise at initialization.Similar models have been used to learn sub-categorization information (Rooth et al, 1999)or properties of verb argument slots (Yao et al,2011).
We choose this kind of clustering for its rel-ative simplicity and because it allows pronouns tohave more informed properties (from their verbalcontext) than would be possible using a model thatmakes type-level decisions about nominals only.Though these specific cluster features are novelto coreference, previous work has used similarCLUSTERSMUC B3 CEAFe Avg.BASIC 61.96 70.66 47.30 59.97PAIRPROPERTY 62.88 70.71 47.45 60.35LEFTTORIGHT 61.98 70.19 45.77 59.31TRANSITIVE 63.34 70.89 46.88 60.37Table 3: CoNLL metric scores for our systemsincorporating clustering features.
These featuresare equally effectively incorporated by our PAIR-PROPERTY system and our TRANSITIVE system.governmentofficialscourtauthoritiesARG0:saidARG0:sayARG0:foundARG0:announcedpricessharesindexratesARG1:roseARG1:fellARG1:cutARG1:closedwaylawagreementplanARG1:signedARG1:announcedARG1:setARG1:approvedattackproblemsattackschargesARG1:causeARG2:followingARG1:reportedARG1:filed... ...... ...... ......
......Figure 4: Examples of clusters produced by theNAIVEBAYES model on SRL-tagged data withpronouns discarded.types of fine-grained semantic class information(Hendrickx and Daelemans, 2007; Ng, 2007; Rah-man and Ng, 2010).
Other approaches incorpo-rate information from other sources (Ponzetto andStrube, 2006) or compute heuristic scores for real-valued features based on a large corpus or the web(Dagan and Itai, 1990; Yang et al, 2005; Bansaland Klein, 2012).We use four different clusterings in ourexperiments, each with twenty clusters:dependency-parse-derived NAIVEBAYES clusters,semantic-role-derived CONDITIONAL clusters,SRL-derived NAIVEBAYES clusters generatinga NOVERB token when r cannot be determined,and SRL-derived NAIVEBAYES clusters with allpronoun tuples discarded.
Examples of the latterclusters are shown in Figure 4.
Each clusteringis learned for 30 iterations of EM over EnglishGigaword (Graff et al, 2007), parsed with theBerkeley Parser (Petrov et al, 2006) and withSRL determined by Senna (Collobert et al, 2011).Table 3 shows results of modeling these clusterproperties.
As in the case of oracle features, thePAIRPROPERTY and LEFTTORIGHT systems usethe modes of the cluster posteriors, and the TRAN-SITIVE system uses the posteriors directly as theRi.
We see comparable performance from incor-porating features in both an entity-level frameworkand a pairwise framework, though the TRANSI-121MUC B3 CEAFe Avg.Prec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1 F1BASIC 69.99 55.59 61.96 80.96 62.69 70.66 41.37 55.21 47.30 59.97STANFORD 61.49 59.59 60.49 74.60 68.25 71.28 47.57 49.45 48.49 60.10NOISY ORACLEPAIRPROPERTY 76.49 58.53 66.31 84.98 63.48 72.68 41.84 59.36 49.08 62.69LEFTTORIGHT 76.92 58.55 66.49 85.68 63.81 73.14 42.07 60.01 49.46 63.03TRANSITIVE 76.48 60.20 *67.37 84.84 65.69 *74.05 42.89 59.01 *49.68 63.70PHI FEATURESLEFTTORIGHT 69.77 54.73 61.34 81.40 62.04 70.41 41.49 55.92 47.64 59.80TRANSITIVE 70.27 56.54 *62.66 79.81 63.82 *70.92 41.17 54.44 46.88 60.16PHI FEATURES (ABLATED BASIC)BASIC-PHI 67.04 53.41 59.45 78.93 61.63 69.21 40.40 53.46 46.02 58.23PAIRPROPERTY 70.24 55.31 61.88 81.10 62.60 70.66 41.04 55.38 47.14 59.90LEFTTORIGHT 69.94 54.75 61.42 81.38 62.23 70.53 41.29 55.87 47.49 59.81TRANSITIVE 70.06 55.98 *62.23 79.92 63.52 70.78 40.90 54.52 46.74 59.92CLUSTERSPAIRPROPERTY 71.77 55.95 62.88 81.76 62.30 70.71 40.98 56.35 47.45 60.35LEFTTORIGHT 69.75 54.82 61.39 81.48 62.29 70.60 41.62 55.89 47.71 59.90TRANSITIVE 71.54 56.83 *63.34 80.55 63.31 *70.89 40.77 55.14 46.88 60.37Table 4: CoNLL metric scores averaged across ten different splits of the training set for each experiment.We include precision, recall, and F1 for each metric for completeness.
Starred F1 values on the individualmetrics for the TRANSITIVE system are significantly better than all other results in the same block at thep = 0.01 level according to a bootstrap resampling test.MUC B3 CEAFe Avg.Prec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1 F1BASIC 68.84 56.08 61.81 77.60 61.40 68.56 38.25 50.57 43.55 57.97PAIRPROPERTY 70.90 56.26 62.73 78.95 60.79 68.69 37.69 51.92 43.67 58.37LEFTTORIGHT 68.84 55.56 61.49 78.64 61.03 68.72 38.97 51.74 44.46 58.22TRANSITIVE 70.62 58.06 *63.73 76.93 62.24 68.81 38.00 50.40 43.33 58.62STANFORD 60.91 62.13 61.51 70.61 67.75 69.15 45.79 44.55 45.16 58.61Table 5: CoNLL metric scores for our best systems (including clustering features) on the CoNLL blindtest set, reported in the same manner as Table 4.TIVE system appears to be more effective than theLEFTTORIGHT system.7.5 Final ResultsTable 4 shows expanded results on our develop-ment sets for the different types of entity-levelinformation we considered.
We also show in inTable 5 the results of our system on the CoNLLtest set, and see that it performs comparably tothe Stanford coreference system (Lee et al, 2011).Here, our TRANSITIVE system provides modestimprovements over all our other systems.Based on Table 4, our TRANSITIVE system ap-pears to do better on MUC andB3 than on CEAFe.However, we found no simple way to change therelative performance characteristics of our varioussystems; notably, modifying the parameters of theloss function mentioned in Section 4 or changingit entirely did not trade off these three metrics butmerely increased or decreased them in lockstep.Therefore, the TRANSITIVE system actually sub-stantially improves over our baselines and is notmerely trading off metrics in a way that could beeasily reproduced through other means.8 ConclusionIn this work, we presented a novel coreference ar-chitecture that can both take advantage of standardpairwise features as well as use transitivity to en-force coherence of decentralized entity-level prop-erties within coreference clusters.
Our transitivesystem is more effective at using properties thana pairwise system and a previous entity-level sys-tem, and it achieves performance comparable tothat of the Stanford coreference resolution system,the winner of the CoNLL 2011 shared task.AcknowledgmentsThis work was partially supported by BBN underDARPA contract HR0011-12-C-0014, by an NSFfellowship for the first author, and by a Google fel-lowship for the second.
Thanks to the anonymousreviewers for their insightful comments.122ReferencesAmit Bagga and Breck Baldwin.
1998.
Algorithms forScoring Coreference Chains.
In Proceedings of theConference on Language Resources and EvaluationWorkshop on Linguistics Coreference.Mohit Bansal and Dan Klein.
2012.
Coreference Se-mantics from Web Features.
In Proceedings of theAssociation for Computational Linguistics.Eric Bengtson and Dan Roth.
2008.
Understandingthe Value of Features for Coreference Resolution.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing.Shane Bergsma and Dekang Lin.
2006.
Bootstrap-ping Path-Based Pronoun Resolution.
In Proceed-ings of the Conference on Computational Linguisticsand the Association for Computational Linguistics.David Burkett and Dan Klein.
2012.
Fast Inference inPhrase Extraction Models with Belief Propagation.In Proceedings of the North American Chapter ofthe Association for Computational Linguistics.Ronan Collobert, Jason Weston, Le?on Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural Language Processing (Almost) fromScratch.
Journal of Machine Learning Research,12:2493?2537, November.Ido Dagan and Alon Itai.
1990.
Automatic Process-ing of Large Corpora for the Resolution of AnaphoraReferences.
In Proceedings of the Conference onComputational Linguistics - Volume 3.Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-bin.
1977.
Maximum Likelihood from IncompleteData via the EM Algorithm.
Journal of the RoyalStatistical Society, Series B, 39(1):1?38.Pascal Denis and Jason Baldridge.
2007.
Joint Deter-mination of Anaphoricity and Coreference Resolu-tion using Integer Programming.
In Proceedings ofthe North American Chapter of the Association forComputational Linguistics.Pascal Denis and Jason Baldridge.
2008.
SpecializedModels and Ranking for Coreference Resolution.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing.John Duchi, Elad Hazan, and Yoram Singer.
2011.Adaptive Subgradient Methods for Online Learningand Stochastic Optimization.
Journal of MachineLearning Research, 12:2121?2159, July.Eraldo Rezende Fernandes, C?
?cero Nogueira dos San-tos, and Ruy Luiz Milidiu?.
2012.
Latent StructurePerceptron with Feature Induction for UnrestrictedCoreference Resolution.
In Proceedings of the JointConference on Empirical Methods in Natural Lan-guage Proceedings and Conference on Computa-tional Natural Language Learning - Shared Task.Jenny Rose Finkel and Christopher D. Manning.
2008.Enforcing Transitivity in Coreference Resolution.In Proceedings of the Association for ComputationalLinguistics: Short Papers.Kevin Gimpel and Noah A. Smith.
2010.
Softmax-Margin CRFs: Training Log-Linear Models withCost Functions.
In Proceedings of the North Amer-ican Chapter for the Association for ComputationalLinguistics.David Graff, Junbo Kong, Ke Chen, and KazuakiMaeda.
2007.
English Gigaword Third Edi-tion.
Linguistic Data Consortium, Catalog NumberLDC2007T07.Aria Haghighi and Dan Klein.
2010.
Coreference Res-olution in a Modular, Entity-Centered Model.
InProceedings of the North American Chapter of theAssociation for Computational Linguistics.Iris Hendrickx and Walter Daelemans, 2007.
AddingSemantic Information: Unsupervised Clusters forCoreference Resolution.Eduard Hovy, Mitchell Marcus, Martha Palmer,Lance Ramshaw, and Ralph Weischedel.
2006.OntoNotes: the 90% solution.
In Proceedings ofthe North American Chapter of the Association forComputational Linguistics: Short Papers.Heeyoung Lee, Yves Peirsman, Angel Chang,Nathanael Chambers, Mihai Surdeanu, and Dan Ju-rafsky.
2011.
Stanford?s Multi-Pass Sieve Corefer-ence Resolution System at the CoNLL-2011 SharedTask.
In Proceedings of the Conference on Compu-tational Natural Language Learning: Shared Task.Dong C. Liu and Jorge Nocedal.
1989.
On the LimitedMemory BFGS Method for Large Scale Optimiza-tion.
Mathematical Programming, 45(3):503?528,December.Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, NandaKambhatla, and Salim Roukos.
2004.
AMention-Synchronous Coreference Resolution Al-gorithm Based on the Bell Tree.
In Proceedings ofthe Association for Computational Linguistics.Xiaoqiang Luo.
2005.
On Coreference ResolutionPerformance Metrics.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing.Andrew McCallum and Ben Wellner.
2004.
Condi-tional Models of Identity Uncertainty with Applica-tion to Noun Coreference.
In Proceedings of Ad-vances in Neural Information Processing Systems.George A. Miller.
1995.
WordNet: A LexicalDatabase for English.
Communications of the ACM,38:39?41.Vincent Ng.
2007.
Semantic class induction and coref-erence resolution.
In Proceedings of the Associationfor Computational Linguistics.123Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning Accurate, Compact, and In-terpretable Tree Annotation.
In Proceedings of theConference on Computational Linguistics and theAssociation for Computational Linguistics.Simone Paolo Ponzetto and Michael Strube.
2006.Exploiting Semantic Role Labeling, WordNet andWikipedia for Coreference Resolution.
In Proceed-ings of the North American Chapter of the Associa-tion of Computational Linguistics.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and NianwenXue.
2011.
CoNLL-2011 Shared Task: ModelingUnrestricted Coreference in OntoNotes.
In Proceed-ings of the Conference on Computational NaturalLanguage Learning: Shared Task.Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-garajan, Nathanael Chambers, Mihai Surdeanu, DanJurafsky, and Christopher Manning.
2010.
A Multi-Pass Sieve for Coreference Resolution.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing.Altaf Rahman and Vincent Ng.
2009.
SupervisedModels for Coreference Resolution.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.Altaf Rahman and Vincent Ng.
2010.
Inducing Fine-Grained Semantic Classes via Hierarchical and Col-lective Classification.
In Proceedings of the Interna-tional Conference on Computational Linguistics.Altaf Rahman and Vincent Ng.
2011.
Narrowingthe Modeling Gap: A Cluster-Ranking Approach toCoreference Resolution.
Journal of Artificial Intel-ligence Research, 40(1):469?521, January.Mats Rooth, Stefan Riezler, Detlef Prescher, GlennCarroll, and Franz Beil.
1999.
Inducing a Semanti-cally Annotated Lexicon via EM-Based Clustering.In Proceedings of the Association for ComputationalLinguistics.David A. Smith and Jason Eisner.
2008.
DependencyParsing by Belief Propagation.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing.Yang Song, Jing Jiang, Wayne Xin Zhao, Sujian Li, andHoufeng Wang.
2012.
Joint Learning for Corefer-ence Resolution with Markov Logic.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.Veselin Stoyanov and Jason Eisner.
2012.
Easy-firstCoreference Resolution.
In Proceedings of the In-ternational Conference on Computational Linguis-tics.Veselin Stoyanov, Claire Cardie, Nathan Gilbert, EllenRiloff, David Buttler, and David Hysom.
2010.Coreference Resolution with Reconcile.
In Pro-ceedings of the Association for Computational Lin-guistics: Short Papers.Marc Vilain, John Burger, John Aberdeen, Dennis Con-nolly, and Lynette Hirschman.
1995.
A Model-Theoretic Coreference Scoring Scheme.
In Pro-ceedings of the Conference on Message Understand-ing.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2005.
Im-proving Pronoun Resolution Using Statistics-BasedSemantic Compatibility Information.
In Proceed-ings of the Association for Computational Linguis-tics.Xiaofeng Yang, Jian Su, Jun Lang, Chew L. Tan, TingLiu, and Sheng Li.
2008.
An Entity-Mention Modelfor Coreference Resolution with Inductive LogicProgramming.
In Proceedings of the Association forComputational Linguistics.Limin Yao, Aria Haghighi, Sebastian Riedel, and An-drew McCallum.
2011.
Structured Relation Discov-ery Using Generative Models.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing.124
