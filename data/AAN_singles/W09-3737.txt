Proceedings of the 8th International Conference on Computational Semantics, pages 326?332,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsTowards a Cognitive Approach for the AutomatedDetection of Connotative MeaningJaime Snyder*, Michael A.
D?Eredita, Ozgur Yilmazel, andElizabeth D. LiddySchool of Information Studies, Syracuse University, Syracuse, NY, USA* Corresponding author, jasnyd01@syr.edu1 IntroductionThe goal of the research described here is to automate the recognition of con-notative meaning in text using a range of linguistic and non-linguistic fea-tures.
Pilot results are used to illustrate the potential of an integrated multi-disciplinary approach to semantic text analysis that combines cognitive-oriented human subject experimentation with Machine Learning (ML) basedNatural Language Processing (NLP).
The research presented here was fundedthrough the Advanced Question and Answering for Intelligence (AQUAINT)Project of the U.S. federal government?s Intelligence Advanced ResearchProjects Activity (IARPA) Office.
Funded as an exploratory ?Blue Sky?project, this award enabled us to develop an extensible experimental setupand to make progress towards training a machine learning system.Automated understanding of connotative meaning of text requires anunderstanding of both the mechanics of text and the human behaviors in-volved in the disambiguation of text.
We glean more from text than whatcan be explicitly parsed from parts of speech or named entities.
There areother aspects of meaning that humans take away from text, such as a sincereapology, an urgent request for help, a serious warning, or a perception ofpersonal threat.
Merging cognitive and social cognitive psychology researchwith sophisticated machine learning could extend current NLP systems toaccount for these aspects.
Building on current natural language processingresearch [?
], this pilot project encapsulates an end-to-end research method-ology that begins by 1) establishing a human-understanding baseline forthe distinction between connotative and denotative meaning, 2) then ex-tends the analysis of the mechanics of literal versus non-literal meaning by326applying NLP tools to the human-annotated text, and 3) uses these cu-mulative results to feed a machine learning system that will be taught torecognize the potential for connotative meaning at the sentence level, acrossa much broader corpus.
This paper describes the preliminary iteration ofthis methodology and suggests ways that this approach could be improvedfor future applications.2 Analytic framework: A cognitive approachWe view an excerpt of text to be a stimulus, albeit much more complex thanmost stimuli used in typical psychological experiments.
The meaning of anyexcerpt of text is tieds to a constructive cognitive process that is heavilyinfluenced by previous experience and cues, or features, embedded withinthe text.
Our goal is to gain a better understanding of (1) what features areattended to when the text is being interpreted, (2) which of these featuresare most salient and (3) how these features affect connotative meaning.One?s ability to derive connotative meaning from text is behavior thatis learned, becoming intuitive in much the same way an individual learnsany skill or behavior.
When this process of attending and learning is re-peated across instances, specific skills become more automatic, or reliable[?, ?].
This process is considered to be constructive and episodic in nature,yet heavily dependent upon ?cues?
that work to draw or focus one?s atten-tion [?].
Further, research on communities suggests that the meaning of anartifact (e.g., a specific excerpt of text) is heavily influenced by how it isused in practice [?]
The meaning of text is constructed in a similar manner.Members of a speech community tend to make similar assumptions, or in-ferences.
The mechanics of making such inferences are scaled to the amountof contextual information provided.
Our preliminary research suggests thatwhen presented with a sentence that is out of context an individual seem-ingly makes assumptions about one or all of the following: who created thetext, the context from which it was pulled and the intended meaning giventhe features of the text.3 Methods3.1 DataBlog text was used as the corpus for this research.
Sentences were deemedthe most practical and fruitful unit of analysis because words were consid-327ered too restrictive and pieces of text spanning more than one sentence toounwieldy.
A single sentence presented enough context while still allowingfor a wide range of interpretation.
Sentences were randomly selected froma pool of texts automatically extracted from blogs, using a crawler set withkeywords such as ?oil?, ?Middle East?
or ?Iraq.?
Topics were selected withthe intention of narrowing the range of vocabulary used in order to aid themachine learning experiments.3.2 Preliminary phaseTo start, we conducted a series of eight semi-structured, face-to-face inter-views.
Individuals were presented with 20 sentences selected to include sometexts that were expected to be perceived as highly connotative as well assome expected to be perceived as highly denotative.
Each interviewee wasasked to exhaustively share all possible meanings they could derive fromthe stimulus text, while also pinpointing what it was about the text thatled them to make their conclusions.
Based on these interviews, we modifiedour probes slightly and moved the human evaluation process to an open-ended, on-line instrument in order to increase the number of responses.
Wepresented a series of 20 sentences to participants (N=193) and, for each stim-ulus text, asked: 1) ?What does this sentence suggest??
& ?What makesyou think this??
; and 2) ?What else does this sentence suggest??
& ?Whatmakes you think this??
Upon analysis of the responses, we found that whileinterpretations of the text were relatively idiosyncratic, how people allocatedtheir attention was more consistent.
Most people tended to be making as-sumptions about the (1) author (addressing who created the artifact), (2)context (addressing from where the sentence was taken) and/or (3) intendedmeaning of the words.
We interpreted this to mean that these three areaswere potentially important for identifying inferred meanings of texts.3.3 Design of pilot experimentNext, our efforts focused on designing a reusable and scalable online evalu-ation tool that would allow us to systematically gather multiple judgmentsfor each sentence using a much larger pool of stimulus text.
Scaling up thehuman evaluations also allowed us to decipher between responses that wereeither systematically patterned or more idiosyncratic (or random).
Accord-ing to our forced-choice design, each online participant was presented witha series of 32 pairs of sentences, one pair at a time, and asked to identify thesentence that provided more of an opportunity to read between the lines.328Half the participants were presented with a positive prompt (which sentenceprovides the most opportunity) and half were presented with a negativeprompt (which sentence provides the least opportunity).
Positive/negativeassignment was determined randomly.
The 16 sentences selected duringthe first round were re-paired in a second round.
This continued until 4sentences remained, representing sentences that were more strongly conno-tative or denotative, depending on the prompt.
Final sentence scores wereaveraged across all evaluations received.The forced choice scenario requires a sample of only 13 participants toevaluate 832 sentences.
This was a significant improvement over previousmethods, increasing the number of sentences and the number of evaluationsper sentence and therefore increasing the reliability of our findings.
For ex-ample, using this scalable setup on a set of 832 sentences we need only 26participants to generate two evaluations per sentence in the set, 39 partici-pants to yield three evaluations per sentence, etc.
We ran the system witha randomly selected sample of both sentences and participants with the in-tent to eventually make direct comparison among more controlled samplesof sentences and participants.
This has direct implication for the evalua-tion phase of our pilot.
Because sentences were selected at random, withoutguarantee of a certain number of each type of sentence, our goal was toachieve results on a par with chance.
Anything else would reveal systematicbias in the experiment design or implementation.
This also provides us witha baseline for future investigations where the stimulus text would be morewilfully controlled.4 Results4.1 Evaluation of text by human subjectsIn the first iteration of the pilot setup, each of 832 sentences were viewedby six different participants, three assigned to a positive group and three toa negative group, as described above.
The denotative condition ranged inratings from 0 to -3 while the connotative condition ranged in rating from 0to 3.
These were then averaged to achieve an overall score for each sentence.Because they were randomly selected, each sentence had predictable chanceof ultimately being identified as connotative or denotative.
In other words,each sentence had an equal chance of being identified as connotative.Having established a baseline based on chance, we can next control forvarious features and evaluate the relative impact as systematic differencesfrom the baseline.
We will be able to say with a relatively high degree of329certainty that ?x,?
?y?
or ?z?
feature, sentence structure, behavior, etc.was responsible for skewing the odds in a reliable manner because we willbe able to control for these variables across various experimental scenarios.This, combined with improved validity resulting from an increased numberof human judgments and an increased number of sentences viewed, marksthe strength of this methodology.Additionally, we will be able to compare sentences within each scenarioeven when an overall chance outcome occurs.
For example, in the initial runof our sentences, we achieved an overall chance outcome.
However, ?anoma-lies?
emerged, sentences that were strongly skewed towards being assigned aneutral evaluation score or towards an extreme score (either distinctly con-notative or distinctly denotative).
This allowed us to gather a reliable andvalid subset of data that can be utilized in ML experiments.
See below fora very short list of sample sentences grouped according to the overall scoresthey received determine by the six human reviewers:Denotative examples-?
The equipment was a radar system.?
Kosovo has been part of modern day Serbia since 1912.?
The projected figure for 2007 is about $ 3100.Connotative examples-?
In fact, do what you bloody well like .?
But it?s pretty interesting , in a depressing sort of way .?
It?s no more a language than American English or Quebecois French4.2 Experimental Machine Learning systemOur preliminary analysis suggests that humans are consistent in recogniz-ing the extremes of connotative and denotative sentences and an automaticrecognition system could be built to identify when a text is likely to conveyconnotative meaning.
Machine Learning (ML) techniques could be used toenable a system to first classify a text according to whether it conveys aconnotative or denotative level of meaning, and eventually, identify specificconnotations.
ML techniques usually assume a feature space within whichthe system learns the relative importance of features to use in classification.Since humans process language at various levels (morphological, lexical, syn-tactic, semantic, discourse and pragmatic), some multi-level combination offeatures is helping them reach consistent conclusions.
Hence, the initial ma-chine learning classification decision will be made based on a class of critical330features, as cognitive and social-cognitive theory suggests happens in humaninterpretation of text.TextTagger, an Information Extraction System developed at SyracuseUniversity?s Center for Natural Language Processing, currently can identifysentence boundaries, part-of-speech tag words, stem and lemmatize words,identify various types of phrases, categorize named entities and commonnouns, recognize relations, and resolve co-references in text.
We are in theprocess of designing a ML framework that utilizes these tags and can learnfrom a few examples provided by the human subject experiments describedabove, then train on other sets of similar data marked by analysts as pos-sessing the features illustrated by the sentences consistently identified asconveying connotative meaning.For preliminary ML-based analysis, the data collection included 266 sen-tences (from the original 832 used in human subject experiments), 145tagged as strongly connotative and 121 tagged as strongly denotative bysubjects.
Fifty sentences from each set became a test collection and theremaining 95 connotative and 71 denotative sentences were used for train-ing.
Our baseline results (without TextTagger annotations) were: Precision:44.77 ; Recall: 60; F: 51.28.
After tagging, when we only use proper namesand common nouns the results improved: Precision: 51.61 Recall: 92; F:67.13.
Although these results are not as high as some categorization resultsreported in the literature for simpler categorization tasks such as documentlabeling or spam identification, we believe that using higher level linguisticfeatures extracted by our NLP technology will significantly improve them.More sophisticated analysis will be conducted during future applications ofthis methodology.5 Discussion and Future WorkBy allowing the ML system to do time- and labor-intensive analysis, andexploiting a natural human ability to ?know it when they see it?
(in this case?it?
referring to connotative meaning), we feel that this pilot methodologyhas great potential to deliver robust results.
In addition to the significantcontribution this research will make in the area of natural language process-ing, it will also provide a model for future work that seeks to create similarbridges between psychological investigation and system building.
Prelimi-nary results suggest that our approach is viable and that a system composedof multiple layers of analysis-with each level geared towards reducing thevariability of the next-holds promise.331Future work will concentrate efforts in two areas.
First, the notion ofspeech communities will be addressed.
The pilot study looked at a very gen-eralized speech community, expecting to achieve equally generalized results.While this has merit, there is much to be learned by implementing this ap-proach using a more targeted community.
Second, the protocol used in thispilot study was run using a relatively modest number of human evaluatorsand a relatively small set of data.
With the experience gained during thepilot, the reliability of the data used to train the ML system can be easilyimproved by increasing the size of both human subject samples and datasets.
With a more robust set of initial data, ML experiments can progressbeyond the basic proof-of-concept results reported here and produce action-able feature sets tuned to specific speech communities.References[1] M. A.
D?Eredita and C. Barreto.
How does tacit knowledge proliferate?
Orga-nization Studies, 27(12):1821, 2006.
[2] E.D.
Liddy, E. Hovy, J. Lin, J. Prager, D. Radev, L. Vanderwende, andR.
Weischedel.
Natural Language Processing.
Encyclopedia of Library andInformation Science, pages 2126?2136, 2003.
[3] G. D. Logan.
Toward an instance theory of automatization.
PsychologicalReview, 95(4):492?527, 1988.
[4] E. Wenger.
Communities of Practice: Learning, Meaning, and Identity.
Cam-bridge University Press, 1999.
[5] R.S.
Wyer and J.A.
Bargh.
The Automaticity of Everyday Life.
LawrenceErlbaum Associates, 1997.332
