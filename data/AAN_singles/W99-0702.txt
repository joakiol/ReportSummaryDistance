Experiments in UnsupervisedEntropy-Based Corpus SegmentationAndrd  KempeXerox  Research  Cent re  Europe  - Grenob le  Laboratory6 chemin  de Mauper tu is  - 38240 Mey lan  - F ranceandre, kempe@xrce,  xerox, cornht tp : / /gg la ,  x rce .
xerox ,  corn / research /mi t tAbstractThe paper presents an entropy-based approach tosegment a corpus into words, when no additionalinformation about the corpus or the language, andno other resources uch as a lexicon or grammarare available.
To segment the corpus, the algorithmsearches for separators, without knowing a priory bywhich symbols they are constituted.
Good resultscan be obtained with corpora containing "clearlyperceptible" separators such as blank or new-line.1 Introduct ionThe paper presents an approach to segment a cor-pus into words, based on entropy.
We assume thatthe corpus is not annotated with additional informa-tion, and that we have no information whatsoeverabout the corpus or the language, and no linguisticresources such as a lexicon or grammar.
Such a situ-ation may occur e.g.
if there is a (sufficiently large)corpus of an unknown or unidentified language andalphabet.
1 Based on entropy, we search for separa-tors, without knowing a priory by which symbols orsequences of symbols they are constituted.Over the last decades, entropy has frequently beenused to segment corpora \[Wolff, 1977, Alder, 1988,Hutchens and Alder, 1998, among many others\].and it is commonly used with compression tech-niques.
Harris \[1955\] proposed an approach for seg-menting words into morphemes that, although it didnot use entropy, was based on an intuitively similarconcept: Every symbol of a word is annotated withthe count of all possible successor symbols given the.substring that ends with the current symbol, andwith the count of all possible predecessor symbolsI Such a corpus can be electronically encoded with arbi-trarily defined symbol codes.given the tail of the word that starts with the cur-rent symbol.
Maxima in these counts are used tosegment the word into morphemes.All steps of the present approach will be describedon the example of a German corpus.
In addition, wewill give results obtained on modified versions of thiscorpus, and on an English corpus.2 The Approach2.1  The  CorpusWe assume that any corpus C can be described bythe expression:c = S .
T IS+ T\]* 3 ,  (1)There must be at least one token T ("word") whichis a string of one or more symbols s :T = s+ (2)Different tokens T must be separated form eachother by one or more separators S which are stringsof zero or more symbols s :S = s* (3)Separators can consist of blanks, new-line, or "'real"symbols.
They can also be empty strings.2 .2  Recod ing  the  CorpusWe will describe the approach on the example of aGerman corpus.First, all symbols s (actually all character codes)of the corpus are recoded by strings of "'visible"ASCII characters.
For example: 22In this example, \ denotes that the current line is notfinished yet but rather continues on the next Ihle.!!!
!Fiir Instandsetzung und Neubau der \Kanalisation diirften inden n~ichsten zehn Jahren Betr~ige in \MilliardenhShe ausgegeben werden.Allein in den alten Bundesl~indern miissen bis \zur Jahrhundertwende ieKom.munen km des insgesamt km langen \Kanal- undLeitungsnetzes sanieren.is recoded as:aF i i r  BL Ins t  andset  zungBLundBLNeu bau  BL der  BLK  an  a l i sa t  ionBL  d i i r  ft en  BLi  n NLden BLn ~ichs  ten  BL ze  h nBL J ah  ren  BLB e t r~ igeBL i  nBL  M i l l i  ardenhSheBLausgegebenBLwerden?
NL A l le i  n BL inBL  d enBLa l t  enBL  B undes l?nder  n BLmi i sse  nBL b i s  BL z ur BL J ahr  hunder  twendeBLd ieNLKom munenBL  kmBLdesBL insgesamtBL km BL l an  g e nBL K ana l -  BLund NLLe i t  ungsnet  zesBLsan ieren .
BLIf the language and the alphabet are unknownor unidentified, the symbols of the corpus can beencoded by arbitrarily defined ASCII strings.2 .3  In fo rmat ion  and  Ent ropyWe estimate probabilities of symbols of the corpususing a 3rd order Markov model based on maximumlikelihood.
The probability of a symbol s with re-spect to this model M and to a context c can beestimated by:f(s, M, c) p(slM, c) = (4) \](U,c)The inIormation of a symbol s with respect o themodel M and to a context c is defined by:I(s\]U, c) = -log2 p(slU, c) (5)Intuitively, information can be considered as the sur-prise of the model about the symbol s after havingseen the context c. The more the symbol is unex-pected from the model's experience, the higher is thevalue of information \[Shannon and Weaver, 1949\]?The entropy of a context c with respect to thismodel M expresses the expected value of informa-tion, and is defined by:g(Af ,  c) = Zp(s\]M,c ) I(slM, c) (6)sEEMonitoring entropy and information across a cor-pus shows that maxima often correspond with word3Note that blanks become "BL" and new-lines become"NL".boundaries \[Alder, 1988, Hutchens and Alder, 1998,among many others\].More exactly, maxima in left-to-right entropyHLR and information ILR often mark the end ofa separator string S, and maxima in right-to-leftentropy Hn and information IR~ often mark thebeginning of a separator string, as can be seen inFigure 1.
Here, an information value is assigned toevery symbol.
This value expresses the informationof the symbol in a given left or right context.
Anentropy value is assigned between every two sym-bols.
It expresses the model's uncertainty after hav-ing seen the left or right context, but not yet thesymbol?When going from left to right, all end of a sep-arator, is often marked by a maximum in entropybecause the next word to the right can start withalmost any symbol, and the model has no "idea"what it will be.
There is also a maximum in infor-mation because the first symbol of the word is (moreor less) unexpected; the model has no particular ex-pectation.Similarly, when going from right to left, a begin-ning of a separator is often marked by a maximumin entropy because the word next to the left call endwith almost any symbol.
There is also a maximumin information because the last symbol of the wordis (more or less) unexpected; the model has no par-ticular expectation.Usually, there is no maximum at a beginning ofa separator, when going from left to right, and nomaximum at a separator ending, when going fromright to left, because words often have "typical" be-ginnings or endings, e.g.
prefixes or suffixes?This means, when we come from inside a word tothe beginning or end of this word then the modelwill anticipate a separator, and since the numberof alternative separators i usually small, the modelwill not be "surprised" to see a particular one.
Onthe other side, when we come from inside a separatorto the beginning or end of this separator, althoughthe model will expect a word, it will be "surprised"about any particular word because the uumber ofalternative beginnings or endings of words is large.It  also may be observed that the maxima in onedirection are bigger then the maxima in the otherdirection due to the fact that a particular languagemay have e.g.
stronger constraints on endings thanon beginnings of words: A language may employsuffixes with most words in a corpus, which limitsthe number of endings, but rarely use prefixes, whichallows a word to start with almost any symbol?/6 "l- Entropy I ,RI20 i i ,  |o  | l , | , ,  o 1 .
, o , , , o , , , , , , ,  o , , , , o , , , , .
o , , , , , o , o , .
l o .
, , , o , .
i .
, .
= .
, , , o .
o , * , .
, o , o  , , , '6 ~ ~ Entropy RL| I, 2F*r{-}lnlstandset~'l.ng nd Ne,ba.
dt, r Kana l l s ln t ion -d*r f ten .
in*den .n*chst , .n -~,ehn  JahrI l} ~} l} I 1} 1} 1} 1" l} l} I" 1} l} I6 ~lnfornlation LR ~ A _ " A2O : 1:!2Figure 1: Entropy and information across a section of a German corpus2.4 Thresho ldsNot all maxima correspond with word boundaries.Hutchens and Alder \[1998\] apply a threshold of0.5 log2 \[1~\]\[ to select among all maxima, those thatrepresent boundaries.The present approach uses two thresholds thatare based on the corpus data and contain no otherfactors: The first threshold van is the average of allvalues of the particular function, HLR, HI{L, ILR, orII{L, across the corpus.
The second threshold Vm,~ isthe average of all maxima of the particular function.All graphs of Figure 1 contain both thresholds (asdotted lines).To decide whether a value v of HLa, HRL, ILR,or II{n should be considered as a boundary, we usethe four functions:bo(v) : v>T.
,~  (7)b,(v) : v ~vatt (S)b2(v) : ismax(v) (9)b3(v) : ~ismin(v) (10)2.5 Detect ion  o f  SeparatorsTo find a separator, we are looking for a strongboundary to serve as a beginning or end of the sep-arator.
In the current example, we have chosen as acriterion for strong boundaries:(bo(h) A 2(h)) A (bi(i) V b3(i)) = (11)((h > rma=(H)) A ismax(h))A ((i > Tan(I)) V -~isrnin(I))Here H and I mean either HLR and ILR if we arelooking for the end of a separator, or HRL and Inn ifwe are looking for the beginning of a separator.
Thevariables h and i denote values of these functions atthe considered point.Once a strong boundary is found, we search for aweak boundary to serve as an ending that matchesthe previously found beginning, or to serve as a be-ginning that matches the previously found ending.For weak boundaries, we use the criterion:(51 (h) A b2(h)) A (bz(i) V b3(i)) = (12)((h > Tall(H)) A ismax(h))A ((i > raU(I)) V ~ismin(I))If a matching pair of boundaries, i.e.
a beginningand an end of a separator, are found, the separator9iis marked.
In Figure 1 this is visualized by \] forempty and { } for non-empty separators.The search for a weak boundary that matches astrong one is stopped (without success) either aftera certain distance 4 or at a breakpoint.
For example,if we have the beginning of a separator and searchfor a matching end then the occurrence of anotherbeginning will stop the search.
As a criterion for abreakpoint we have chosen:(bl (h) A b~(h) ) V (bl (i) A b2(i) ) =((h > Tau(H)) A ismax(h))V ((i > ran(I)) A ismax(i))(13)If the search for a matching point has beenstopped for either eason, we need to decide whetherthe initially found strong boundary should bemarked despite the missing match.
It will only bemarked if it is an obligatory boundary.
Here we ap-ply the criterion:(bo(h) A b2(h)) A (bo(i) A b2(i)) =((h > rma=(H)) A ismax(h))A ((i >_ rrnax(I)) A ismax(i))(14)In Figure 1 these unmatched obligatory boundariesare visualized by {u or }u.Each of the four criteria, for strong bound-aries, weak boundaries, break points, and obligatoryboundaries, can be built of any of the four functionsboo to b30 (eq.s 7' to 10).2.6 Validation of SeparatorsAll separator strings that have a matching beginningand end marker are collected and counted.Alias fsepar fcontezt95 103 1 484h 10 841 85045 475 6213 464 450697 360E 1 271 2811 328 2413 223 199h 6 793 1603 306 12611o 545 119I l l  162 I08Table 1:ftotal Separator115 619 BL20 011 NL1 024 15211 637 t BL3 0965 736 .
BL17 053 e BL48 136 s138 769 e32 049 e r4 110 .
NL1 372 t NLSeparators from a German corpus(truncated list)4In the example, the maximal separator length is set to 6.This seems ufficient because we found no separators longerthan 3 so far (Tables 1 to 5).Table 1 shows such separators collected from theGerman example corpus.
Column 5 contains thestrings that constitute the separators, column 2shows the count of these strings as separators, col-unm 3 says in how may different contexts s the sep-arators occurred, colunm 4 shows the total countof the strings in the corpus, and column 1 containsaliases furtheron used to denote the separators.
InTable 1 all separators are sorted with respect o col-umn 3.
From these separators we retain those thatare above a defined threshold relative to the numberof different contexts of the top-most separator.
Inall examples throughout this article, we are using arelative threshold of 0.5, which means in this case(Table 1) that the top-most wo separators, "BL"and "NL" that occur ifi 1484 and 850 different con-texts respectively, are retained.
6In the corpus, all separators that have been re-tained (Table 1) and that have at least one detectedboundary (Fig.
1), are validated and marked.
Forthe above corpus section this leads to:F i i r  I o lns tandsetzung Iound IoNeubau  Ioder IoKana l i sa t ion  Jod i i r f ten10 inNLden 6n~ichsten  6zehn 10Jahren 6Bet r~ ige  10in IoMi l l i a rdenhShe 10ausgegeben 10werden .
hA l le lnloin 6den  Ioa l ten  IoBundes l~ indernIomf i ssen  ~b is  ~zur  Jo Jahrhunder t .wende Jod ieNLKommunen 6km'10des 10 insgesamtBLkm ~langen \ [0Kana l -BLund h Le i tungsnetzesBLsan ie ren .
BL2.7 Reca l l  o f  SeparatorsFor the above corpus we measured a recall of 86.0 %for both blank (BL) and new-line (NL) together (Ta-ble 2).Alias Separator Recall r io.n,  t flo.~tt0 BL 88.6 % 102 412 115 619~I NL  71.2 % 14 254 20 011All 86.0 % 116 666 135 630Table 2: Recall of separators from a GermancorpusDue to the approach, the precision for BL and NLis 100 %.
A string which is different from BL andNL cannot be marked as a separator in the aboveexample.
If empty string separators were admitted,the precision would decrease.5As context of a separator, we consider the preceding andthe following symbol.6In the Tables 1 to 5 the retained separator strings areseparated by a horizontal line form the others.103 More  ExamplesWe applied the approach to modified versions of theabove mentioned German corpus and to an Englishcorpus.3.1 German with Empty String Sep-aratorsFor this experiment, we remove all original separa-tors, "BL" and "NL", from the above German cor-pus:F i i r Ins tandsetzungundNeubauder Kana l i sa t iondf i r f ten indenn$chs tenzehn J  ahrenBet r~ ige in  M i l l i ardenhSheausgegebenwerden.
A l le in inden  a l t  enBundes l~ indernmf issenb iszur Jahrhunder twended ieKommunenkmdes insgesamtkmlangenKana l -  undLe i tungsnetzessan ie ren .From this corpus, we collected the separators inTable 3Alias IseVar Icontezt Itotal Separator110 969 1 257 888 522II 6 355 580 33 335 e n5 872 466 54 278 t7 975 407 138 769 e5 661 374 32 158 e r916 345 11 1783 063 306 48 136 sb 5O5 297 3 096399 206 4 566 t e n621 189 15 836 t eTable 3: Separators from a German corpuswithout blanks and new-line (truncated list)and obtained the result:F i i r In  lost 10andsetz  lou 10ng loundloNeu lobau  loder  loKana l i s  loat iond i i r f  l o ten  lo inden  lon~ich los ten  lozehn Jahren  loBet r~ ig  \]oe loin loMi l l i ard  \[oen IohSh loeaus  ~ge \ [0geben lowerden  Io.
A l l  loe loin lo ind loen loa l ten loBun lod loes lol~ind loer lonmi i ssen lob iszur  \ [0 Jahrh  lound loer lo twende \[0die loKommunen lokrnde los loins logesarn  \[0t lokm lo langen loKana l -und  loLei  lot loungs  lonetzessan  loieren  lo.3.2 German w i th  Mod i f ied  Separa -to rsFor the next experiment, we chmlged all original sep-arators, "BL" and "NL", in the above German cor-pus into a string from the list { .
.
.
.
.
.
.
.
, "- -", ,,#,,, -# #,,, ,,__ _,,, ,,# #, ,  ,,_ _,, ~ :7F i i r - - - Ins tandset  z ung# #und- -Neubauder -Kana l i sa t  ion - -d i i r  f ten # in  # # den- - -n~ic  hs ten  # # zehn-- JahrenBet r~ ige- in - -  M i l l i a r  denh5he#ausgegeben##werden .
.
.
.
Al l e in  # # in - -dena l ten-  B u n des l i indern - -mi i ssen  #b is# #zur - - -  Jahrhunder twende##die - -Kommunenkm-des - - insgesamt#km##langen- - -Kana l -# # und- -Le i t  ungsnetzessan ieren .
-From this corpus, we collected the separators inTable 4Alias \]se~ar127 490h 4 9663 875h 3 516h 6 8764 4943 699b 5 161378335Ito 1 588In 1 555fcontezt ftotal Separator844 1 108 920618 33 907 # #591 17 247 - - -532 68 198 - -292268265227189179170140138 76932 05948 13654 2782 4373 73232 90941 035eerSt.##e naTable 4: Separators from a German corpus withmodified separators (truncated list)and obtained the result:F i i r  6 In  6s t  6and los loetz  loung Io## lound loNeu lobau  loder -K  loa loon loal  l o i sa t ion  lo - -d i i r f  l o ten#in  h denh lon~ich los ten  \[1 zehn \[3 Io JahrenBet r~ ige- in  h loMi l l i a rd  loenhSh loe#loaus  loge logeb  loen lo## lowerdenlo.
hA I le in  lo## 6 in  hd loena l  lo ten-Bundes l i indern  h lomi i ss  Ioen#bis I1 lozur  h Jahrhund loer lo twendelo##die  hKommun Ioen lokm-des  lo--  lo ins  logesamt#km## lo langen\[2 \ [0Kana l  lo -##und hL loe i t  l oungslonetz  loe lossan  lo ie ren .
-7The replacement of every blank and new-line w~s doneby rotation through the list.113.3  Eng l i sh  CorpusOn an English corpus where all original separatorshave been preserved: sIn the days when the spinning-wheels \hummed busily in thefarmhouses and even great ladies clothed \in silk andthread lace had their toy spinning-wheels \of polished oak there might be seen in \districts far away among the lanesor deep in the bosom of the hills certain \pallid undersizedmen who by the side of the brawny \country-folk lookedlike the remnants of a disinherited race.we measured the information and entropy shown inFigure 2, collected the separators in Table 5,Alias fsepa~ fconte=t164 744 1 082\[l 7 700 602h 19 983 374h 2 689 323k 4 009 223734 2166 039 171b 357 167646 154b 489 99ho 1 932 96\[I l 180 96ftotal Separator181 518 BL20 000 NL1 096 3015 895  .
BL32 576 e BLI 253 .
NL.105 185 e647 ' NL.2 876 .
NL17 789 t BL71 247 a1 742 -Table 5: Separators from an English corpus(truncated list)and obtained the result:In \[othe iodays  iowhen \[othe \ [osp inning -whee ls  \ [ohummed bbus i ly  ~ in\[othe h fa rmhouses  ~and \ [oeven logteat  1o lad ies  \ [oc lo thed  loin Iosilk \[oandNLthread  \[olace \ [ohad ~the i r  \]atoy  iosp inn ing-whee lsBLof  iapol isfled \ [ooak  \ [o there  \ [omight  lobe \[oseen loin \ [od is t r i c ts  \ ]o fa r  10awayBLamong \ [o the  \ [o lanesNLor  \ [odeep b in  10the  ~)bosom \[oof  \ [o the  \ [oh i l l s  \ [0cer tain  \ [0pa l l id  \ [0unders i zed  \ [ lmen \[owho \ [0by \ [o the  \ [os ideBLof  \ [o the  \ [0brawny  \ [0count ry - fo lk  \ [01ooked h l i ke  \[0the  \ [0 remnantsBLof  ~a \ [0d is inher ited  \ [o race .Sln this example, \ denotes that the current line is notfinished yet but rather continues on the next line"4 Conclusion and Future In-vestigationsThe paper attempted to show that entropy and in-formation can be used to segment a corpus intowords, when no additional knowledge about the cor-pus or the language, and no other resources such asa lexicon or grammar are available.To segment the corpus, the algorithm searches forseparators, without knowing a priory by which sym-bols or sequences of symbols they are constituted.Good results were obtained with a Germanand an English corpus with "clearly perceptible"separators (blank and new-line).
Precision andrecall decrease if the original separators of thesecorpora are removed or changed into a set ofdifferent co-occurring separators.So far, only separators and their frequencies havebeen taken into account.
Future investigations mayinclude:?
the use of frequencies of tokens and their differ-ent alternative contexts, to validate these to-kens and the adjacent separators, and?
a search for criteria (based on the corpus it-self and on the obtained result) to evaluate the"quality" of segmentation, thus enabling a self-optimizing approach.AcknowledgementsMany thanks to the anonymous reviewers of my ar-ticle and to my colleagues.References\[Alder, 1988\] Mike Alder.
Stochastic grammaticalinference.
Master's thesis, University of WesteruAustralia, 1988.\[Harris, 1955\] Zellig S. Harris.
From phoneme tomorpheme.
Language, 31(2):190-222, 1955.\[Hutchens and Alder, 1998\] Jason L. Hutchens andMichael D. Alder.
Finding structure via com-pression.
In David M. W. Powers, editor, NeM-LaP3/CoNLL98: Joint Conference on New Meth-ods in Natural Language Processing and Compu-tational Natural Language Processing Learning,pages 79-82, Sydney, Australia, 1998.
Associationfor Computational Linguistics.12t Entropy T.R' l ' = .
l = l , = l = = = l = l l = l l l l = = I  J l ?
,= , l==|e--- Entropy RI,= ~ | l  w i=  i *  i i  i i m  i l l  i i=  f ~ J | i |  = I l l  , , , , * D = l ~  ~ = = , J , l l  = I I  ~ = I I I  J I ~ I ~ I t I I = , ~ lIn{ }!
h \['{.
}d a ysl-jwh ,.
nl.it h,.|-lS p i,  n, ng-wh ,-~" I~1 }h ,,rmw d .
{,,  {}bus ilul,-.
(\] in-{ }th ,-.
{ }far mh o,, s,.
{u s{ }a, ,1{-},.
v ,.
n{.
}~.
rt Information I,RFigure 2: Entropy and information across a section of an English corpus\[Shannon and Weaver, 1949\] Claude E. Shannonand Warren Weaver.
The Mathematical Theoryof Communication.
University of Illinois Press,1949.\[Wolff, 1977\] J. G. Wolff.
The discovery of segmentsin natural anguage.
British Journal o.f Psychol-ogy, 68:97-106, 1971.13!
