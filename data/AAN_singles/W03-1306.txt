Boosting Precision and Recall of Dictionary-Based Protein NameRecognitionYoshimasa Tsuruoka??
and Jun?ichi Tsujii??
?Department of Computer Science, University of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 Japan?CREST, JST (Japan Science and Technology Corporation)Honcho 4-1-8, Kawaguchi-shi, Saitama 332-0012 Japan{tsuruoka,tsujii}@is.s.u-tokyo.ac.jpAbstractDictionary-based protein name recogni-tion is the first step for practical infor-mation extraction from biomedical doc-uments because it provides ID informa-tion of recognized terms unlike machinelearning based approaches.
However, dic-tionary based approaches have two se-rious problems: (1) a large number offalse recognitions mainly caused by shortnames.
(2) low recall due to spelling vari-ation.
In this paper, we tackle the for-mer problem by using a machine learningmethod to filter out false positives.
Wealso present an approximate string search-ing method to alleviate the latter prob-lem.
Experimental results using the GE-NIA corpus show that the filtering usinga naive Bayes classifier greatly improvesprecision with slight loss of recall, result-ing in a much better F-score.1 IntroductionThe rapid increase of machine readable biomedicaltexts (e.g.
MEDLINE) makes automatic informationextraction from those texts much more attractive.Especially extracting information of protein-proteininteractions from MEDLINE abstracts is regarded asone of the most important tasks today (Marcotte etal., 2001; Thomas et al, 2000; Ono et al, 2001).To extract information of proteins, one has to firstrecognize protein names in a text.
This kind of prob-lem has been studied in the field of natural languageprocessing as named entity recognition tasks.
Ohtaet al (2002) provided the GENIA corpus, an an-notated corpus of MEDLINE abstracts, which canbe used as a gold-standard for evaluating and train-ing named entity recognition algorithms.
Thereare some research efforts using machine learningtechniques to recognize biological entities in texts(Takeuchi and Collier, 2002; Kim and Tsujii, 2002;Kazama et al, 2002).One drawback of these machine learning basedapproaches is that they do not provide identificationinformation of recognized terms.
For the purposeof information extraction of protein-protein interac-tion, the ID information of recognized proteins, suchas GenBank 1 ID or SwissProt 2 ID, is indispensableto integrate the extracted information with the datain other information sources.Dictionary-based approaches, on the other hand,intrinsically provide ID information because theyrecognize a term by searching the most similar(or identical) one in the dictionary to the targetterm.
This advantage currently makes dictionary-based approaches particularly useful as the first stepfor practical information extraction from biomedicaldocuments (Ono et al, 2001).However, dictionary-based approaches have twoserious problems.
One is a large number of falsepositives mainly caused by short names, which sig-nificantly degrade overall precision.
Although thisproblem can be avoided by excluding short namesfrom the dictionary, such a solution makes it impos-sible to recognize short protein names.
We tackle1GenBank is one of the largest genetic sequence databases.2The Swiss-Prot is an annotated protein sequence database.this problem by using a machine learning technique.Each recognized candidate is checked if it is reallyprotein name or not by a classifier trained on an an-notated corpus.The other problem of dictionary based approachesis spelling variation.
For example, the protein name?NF-Kappa B?
has many spelling variants such as?NF Kappa B,?
?NF kappa B,?
?NF kappaB,?
and?NFkappaB.?
Exact matching techniques, however,regard these terms as completely different terms.We alleviate this problem by using an approximatestring matching method in which surface-level sim-ilarities between terms are considered.This paper is organized as follows.
Section 2describes the overview of our method.
Section 3presents the approximate string searching algorithmfor candidate recognition.
Section 3 describes howto filter out false recognitions by a machine learningmethod.
Section 5 presents the experimental resultsusing the GENIA corpus.
Some related work is de-scribed in Section 6.
Finally, Section 7 offers someconcluding remarks.2 Method OverviewOur protein name recognition method consists oftwo phases.
In the first phase, we scan the text forprotein name candidates using a dictionary.
In thesecond phase, we check each candidate whether it isreally protein name or not using a machine learningmethod.
We call these two phases recognition phaseand filtering phase respectively.
The overview of themethod is given below.?
Recognition phaseProtein name candidates are identified using aprotein name dictionary.
To alleviate the prob-lem of spelling variation, we use an approxi-mate string matching technique.?
Filtering phaseEvery protein name candidates is classified into?accepted?
or ?rejected?
by a classifier.
Theclassifier uses the context of the term and theterm itself as the features for the classification.Only ?accepted?
candidates are recognized asprotein names.In the following sections, we describe the detailsof each phase.21234-22345132123R43212G43211E432102-RG1343451313R431G4311E4310-RGFigure 1: Dynamic Programming Matrix3 Candidate RecognitionThe most straightforward way to exploit a dictio-nary for candidate recognition is the exact (longest)match algorithm.
For exact match, many fast match-ing algorithms (e.g.
Boyer-Moore algorithm (1977))have been proposed.
However, the existence ofmany spelling variations for the same protein namemakes the exact matching less attractive.
For exam-ple, even a short protein name ?EGR-1?
has at leastthe six following variations:EGR-1, EGR 1, Egr-1, Egr 1, egr-1, egr 1.Since longer protein names have a huge numberof possible variations, it is impossible to enrich thedictionary by expanding each protein name as de-scribed above.3.1 Approximate String SearchingTo deal with the problem of spelling variation, weneed a kind of ?elastic?
matching algorithm, bywhich a recognition system scan a text to find a sim-ilar term to (if any) a protein name in the dictio-nary.
We need a similarity measure to do such a task.The most popular measure of similarity betweentwo strings is edit distance, which is the minimumnumber of operations on individual characters (e.g.substitutions, insertions, and deletions) required totransform one string of symbols into another.
For ex-ample, the edit distance between ?EGR-1?
and ?GR-2?
is two, because one substitution (1 for 2) and onedeletion (E) are required.To calculate the edit distance between two strings,we can use a dynamic programming technique.
Fig-ure 1 illustrates an example.
For clarity of presen-tation, all costs are assumed to be 1.
The matrixC0..|x|,0..|y| is filled, where Ci,j represents the mini-mum number of operations needed to match x1..i toy1..j .
This is computed as follows (Navarro, 1998)Ci,0 = i (1)C0,j = j (2)Ci,j = if (xi = yj) then Ci?1,j?1 (3)else 1 + min(Ci?1,j , Ci,j?1, Ci?1,j?1)The calculation can be done by either a row-wise left-to-right traversal or a column-wise top-to-bottom traversal.There are many fast algorithms other than the dy-namic programming for uniform-cost edit distance,where the weight of each edit operation is constantwithin the same type (Navarro, 2001).
However,what we expect is that the distance between ?EGR-1?
and ?EGR 1?
will be smaller than that between?EGR-1?
and ?FGR-1?, while the uniform-cost editdistances of them are equal.The dynamic programming based method is flex-ible enough to allow us to define arbitrary costs forindividual operations depending on a letter being op-erated.
For example, we can make the cost of thesubstitution between a space and a hyphen muchlower than that of the substitution between ?E?
and?F.?
Therefore, we use the dynamic programmingbased method for our task.Table 1 shows the cost function used in our ex-periments.
Both insertion and deletion costs are 100except for spaces and hyphens.
Substitution costsfor similar letters are 10.
Substitution costs for theother different letters are 50.3.2 String SearchingWe have described a method for calculating thesimilarity between two strings in the previous sec-tion.
However, what we need is approximate stringsearching in which the recognizer scans a text tofind a similar term to (if any) a term in the dictio-nary.
The dynamic programming based method canbe easily extended for approximate string searching.The method is illustrated in Figure 2.
The pro-tein name to be matched is ?EGR-1?
and the textto be scanned is ?encoded by EGR include.?
Stringsearching can be done by just setting the elementscorresponding separators (e.g.
space) in the first rowTable 1: Cost FunctionOperation Letter CostInsertion space or hyphen 10Other letters 100Deletion space or hyphen 10Other letters 100Substitution A letter for the same letter 0A numeral for a numeral 10space for hyphen 10hyphen for space 10A capital letter for thecorresponding small letter 10A small letter for thecorresponding capital letter 10Other letters 50to zero.
After filling the whole matrix, one can findthat ?EGR-1?
can be matched to this text at the placeof ?EGR 1?
with cost 1 by searching for the lowestvalue in the bottom row.To take into account the length of a term, we adopta normalized cost, which is calculated by dividingthe cost by the length of the term:(nomalized cost) = (cost) + ?
(length of the term) (4)where ?
is a constant value 3.
When the costs of twoterms are the same, the longer one is preferred dueto this constant.To recognize a protein name in a given text, weperform the above calculation for every term con-tained in the dictionary and select the term that hasthe lowest normalized cost.If the normalized cost is lower than the predefinedthreshold.
The corresponding range in the text isrecognized as a protein name candidate.3.3 Implementation Issues for String SearchingA naive way for string searching using a dictionaryis to conduct the procedure described in the previ-ous section one by one for every term in the dictio-nary.
However, since the size of the dictionary isvery large, this naive method takes too much time toperform a large scale experiment.3?
was set to 0.4 in our experiments.7654444321123444476544444-765554321223455557655555516666d7777e54333321012333376543333R54322222101222276543222G54321111210121176543211E54321010321021076543210ulcni1RGEybdedocne654444321123444465444446555432122345555655555516666d e5433332101233336543333R5432222210122226543222G5432111121012116543211E5432101032102106543210ulcni1RGEybdedocneFigure 2: Example of String Searching using Dynamic Programming MatrixNavarro (2001) have presented a way to reduceredundant calculations by constructing a trie of thedictionary.
The trie is used as a device to avoidrepeating the computation of the cost against sameprefix of many patterns.
Suppose that we have justcalculated the cost of the term ?EGR-1?
and next wehave to calculate the cost of the term ?EGR-2,?
it isclear that we do not have to re-calculated the firstfour rows in the matrix (see Figure 2).
They alsopointed out that it is possible to determine, prior toreaching the bottom of the matrix, that the currentterm cannot produce any relevant match: if all thevalues of the current row are larger than the thresh-old, then a match cannot occur since we can onlyincrease the cost or at best keep it the same.4 Filtering Candidates by a Naive BayesClassifierOne of the serious problems of dictionary-basedrecognition is a large number of false recognitionsmainly caused by short entries in the dictionary.
Forexample, the dictionary constructed from GenBankcontains an entry ?NK.?
However, the word ?NK?is frequently used as a part of the term ?NK cells.
?In this case, ?NK?
is an abbreviation of ?naturalkiller?
and is not a protein name.
Therefore this en-try makes a large number of false recognitions lead-ing to low precision performance.In the filtering phase, we use a classifier trained onan annotated corpus to suppress such kind of falserecognition.
The objective of this phase is to im-prove precision without the loss of recall.We conduct binary classification (?accept?
or ?re-ject?)
on each candidate.
The candidates that areclassified into ?rejected?
are filtered out.
In otherwords, only the candidates that are classified into?accepted?
are recognized as protein names.In this paper, we use a naive Bayes classifier forthis classification task.4.1 Naive Bayes classifierThe naive Bayes classifier is a simple but effectiveclassifier which has been used in numerous applica-tions of information processing such as image recog-nition, natural language processing and informationretrieval (Lewis, 1998; Escudero et al, 2000; Peder-sen, 2000; Nigam and Ghani, 2000).Here we briefly review the naive Bayes model.Let ~x be a vector we want to classify, and ck be apossible class.
What we want to know is the prob-ability that the vector ~x belongs to the class ck.
Wefirst transform the probability P (ck|~x) using Bayes?rule,P (ck|~x) = P (ck) ?P (~x|ck)P (~x) (5)Class probability P (ck) can be estimated from train-ing data.
However, direct estimation of P (ck|~x) isimpossible in most cases because of the sparsenessof training data.By assuming the conditional independenceamong the elements of a vector, P (~x|ck) isdecomposed as follows,P (~x|ck) =d?j=1P (xj|ck), (6)where xj is the jth element of vector ~x.
Then Equa-tion 5 becomesP (ck|~x) = P (ck) ?
?dj=1 P (xj |ck)P (~x) (7)By this equation, we can calculate P (ck|~x) and clas-sify ~x into the class with the highest P (ck|~x).There are some implementation variants of thenaive Bayes classifier depending on their event mod-els (McCallum and Nigam, 1998).
In this paper, weadopt the multi-variate Bernoulli event model.4.2 FeaturesAs the input of the classifier, the features of the tar-get must be represented in the form of a vector.
Weuse a binary feature vector which contains only thevalues of 0 or 1 for each element.In this paper, we use the local context surround-ing a candidate term and the words contained in theterm as the features.
We call the former contextualfeatures and the latter term features.The features used in our experiments are given be-low.?
Contextual FeaturesW?1 : the preceding word.W+1 : the following word.?
Term FeaturesWbegin : the first word of the term.Wend : the last word of the term.Wmiddle : the other words of the term withoutpositional information (bag-of-words).Suppose the candidate term is ?putative zinc fin-ger protein, ?
and the sentence is:... encoding a putative zinc finger protein wasfound to derepress beta- galactosidase ...We obtain the following active features for thisexample.
{W?1 a}, {W+1 was}, {Wbegin putative}, {Wendprotein}, {Wmiddle zinc}, {Wmiddle finger}.4.3 TrainingThe training of the classifier is done with an anno-tated corpus.
We first scan the corpus for proteinname candidates by dictionary matching.
If a recog-nized candidate is annotated as a protein name, thiscandidate and its context are used as a positive (?ac-cepted?)
example for training.
Otherwise, it is usedas a negative (?rejected?)
example.5 Experiment5.1 Corpus and DictionaryWe conducted experiments of protein name recogni-tion using the GENIA corpus version 3.01 (Ohta etal., 2002).
The GENIA corpus is an annotated cor-pus, which contains 2000 abstracts extracted fromMEDLINE database.
These abstracts are selectedfrom the search results with MeSH terms Human,Blood Cells, and Transcription Factors.The biological entities in the corpus are annotatedaccording to the GENIA ontology.
Although thecorpus has many categories such as protein, DNA,RNA, cell line and tissue, we used only the proteincategory.
When a term was recursively annotated,only the innermost (shortest) annotation was consid-ered.The test data was created by randomly selecting200 abstracts from the corpus.
The remaining 1800abstracts were used as the training data.
The proteinname dictionary was constructed from the trainingdata by gathering all the terms that were annotatedas proteins.Each recognition was counted as correct if theboth boundaries of the recognized term exactlymatched the boundaries of an annotation in the cor-pus.5.2 Improving Precision by FilteringWe first conducted experiments to evaluate howmuch precision is improved by the filtering process.In the recognition phase, the longest matching algo-rithm was used for candidate recognition.The results are shown in Table 2.
F-measure is de-fined as the harmonic mean for precision and recallas follows:F = 2 ?
precision ?
recallprecision + recall (8)Table 2: Precision Improvement by FilteringPrecision Recall F-measurew/o filtering 48.6 70.7 57.6with filtering 74.3 65.3 69.5Table 3: Recall Improvement by ApproximateString SearchThreshold Precision Recall F-measure1.0 72.6 39.5 51.22.0 73.7 63.7 68.33.0 74.0 66.5 70.14.0 73.9 66.8 70.25.0 73.4 67.1 70.16.0 73.6 67.1 70.27.0 73.5 67.2 70.28.0 73.1 67.4 70.29.0 72.9 67.8 70.210.0 72.6 67.7 70.0The first row shows the performances achievedwithout filtering.
In this case, all the candidatesidentified in the recognition phase are regarded asprotein names.
The second row shows the perfor-mance achieved with filtering by the naive Bayesclassifier.
In this case, only the candidates that areclassified into ?accepted?
are regarded as proteinnames.
Notice that the filtering significantly im-proved the precision (from 48.6% to 74.3%) withslight loss of the recall.
The F-measure was alsogreatly improved (from 57.6% to 69.5%).5.3 Improving Recall by Approximate StringSearchWe also conducted experiments to evaluate howmuch we can further improve the recognition per-formance by using the approximate string search-ing method described in Section 3.
Table 3 showsthe results.
The leftmost columns show the thresh-olds of the normalized costs for approximate stringsearching.
As the threshold increased, the preci-sion degraded while the recall improved.
The bestF-measure was 70.2%, which is better than that ofexact matching by 0.7% (see Table 2).Table 4: Performance using Different Feature SetFeature Set Precision Recall F-measureContextual 61.0 62.6 61.8featuresTerm 71.3 67.9 69.5featuresAll features 73.5 67.2 70.25.4 Efficacy of Contextual FeaturesThe advantage of using a machine learning tech-nique is that we can exploit the context of a candi-date for deciding whether it is really protein name ornot.
In order to evaluate the efficacy of contexts, weconducted experiments using different feature sets.The threshold of normalized cost was set to 7.0.Table 4 shows the results.
The first row shows theperformances achieved by using only contextual fea-tures.
The second row shows those achieved by us-ing only term features.
The performances achievedby using both feature sets are shown in the third row.The results indicate that candidate terms them-selves are strong cues for classification.
However,the fact that the best performance was achievedwhen both feature sets were used suggests that thecontext of a candidate conveys useful informationabout the semantic class of the candidate.6 Related WorkKazama et al (2002) reported an F-measure of56.5% on the GENIA corpus (Version 1.1) usingSupport Vector Machines.
Collier et al (2001)reported an F-measure of 75.9% evaluated on 100MEDLINE abstracts using a Hidden Markov Model.These research efforts are machine learning basedand do not provide ID information of recognizedterms.Krauthammer et al (2000) proposed a dictionary-based gene/protein name recognition method.
Theyused BLAST for approximate string matching bymapping sequences of text characters into sequencesof nucleotides that can be processed by BLAST.They achieved a recall of 78.8% and a precision of71.1% by a partial match criterion, which is lessstrict than our exact match criterion.7 ConclusionIn this paper we propose a two-phase protein namerecognition method.
In the first phase, we scan textsfor protein name candidates using a protein namedictionary and an approximate string searching tech-nique.
In the second phase, we filter the candidatesusing a machine learning technique.Since our method is dictionary-based, it can pro-vide ID information of recognized terms unlike ma-chine learning based approaches.
False recognition,which is a common problem of dictionary-based ap-proaches, is suppressed by a classifier trained on anannotated corpus.Experimental results using the GENIA corpusshow that the filtering using a naive Bayes classi-fier greatly improves precision with slight loss of re-call.
We achieved an F-measure of 70.2% for proteinname recognition on the GENIA corpus.The future direction of this research involves:?
Use of state-of-the-art classifiersWe have used a naive Bayes classifier in ourexperiments because it requires a small com-putational resource and exhibits good perfor-mance.
There is a chance, however, to improveperformance by using state-of-the-art machinelearning techniques including maximum en-tropy models and support vector machines.?
Use of other elastic matching algorithmsWe have restricted the computation of similar-ity to edit distance.
However, it is not uncom-mon that the order of the words in a proteinname is altered, for example,?beta-1 integrin?
?integrin beta-1?The character-level edit distance cannot capturethis -kind of similarities.ReferencesRobert S. Boyer and J. Strother Moore.
1977.
A faststring searching algorithm.
Communications of theACM, 20(10):762?772.Nigel Collier, Chikashi Nobata, and Junichi Tsujii.
2001.Automatic acquisition and classification of molecularbiology terminology using a tagged corpus.
Journal ofTerminology, 7(2):239?258.G.
Escudero, L. arquez, and G. Rigau.
2000.
Naive bayesand exemplar-based approaches to word sense disam-biguation revisited.
In Proceedings of the 14th Euro-pean Conference on Artificial Intelligence.Jun?ichi Kazama, Takaki Makino, Yoshihiro Ohta, andJun?ichi Tsujii.
2002.
Tuning support vector machinesfor biomedical named entity recognition.
In Proceed-ings of the ACL-02 Workshop on Natural LanguageProcessing in the Biomedical Domain.Jin Dong Kim and Jun?ichi Tsujii.
2002.
Corpus-basedapproach to biological entity recognition.
In Text DataMining SIG (ISMB2002).Michael Krauthammer, Andrey Rzhetsky, Pavel Moro-zov, and Carol Friedman.
2000.
Using BLAST foridentifying gene and protein names in journal articles.Gene, 259:245?252.David D. Lewis.
1998.
Naive Bayes at forty: The inde-pendence assumption in information retrieval.
In Pro-ceedings of ECML-98, 10th European Conference onMachine Learning, number 1398, pages 4?15.Edward M. Marcotte, Ioannis Xenarios, and David Eisen-berg.
2001.
Mining literature for protein-protein inter-actions.
BIOINFORMATICS, 17(4):359?363.Andrew McCallum and Kamal Nigam.
1998.
A com-parison of event models for naive bayes text classifi-cation.
In AAAI-98 Workshop on Learning for TextCategorization.G.
Navarro, R. Baeza-Yates, and J.M.
Arcoverde.
2001.Matchsimile: A flexible approximate matching tool forpersonal names searching.
In Proceedings of the XVIBrazilian Symposium on Databases (SBBD?2001),pages 228?242.Gonzalo Navarro.
1998.
Approximate Text Searching.Ph.D.
thesis, Dept.
of Computer Science, Univ.
ofChile.Gonzalo Navarro.
2001.
A guided tour to approximatestring matching.
ACM Computing Surveys, 33(1):31?88.Kamal Nigam and Rayid Ghani.
2000.
Analyzing the ef-fectiveness and applicability of co-training.
In CIKM,pages 86?93.Tomoko Ohta, Yuka Tateishi, Hideki Mima, and Jun?ichiTsujii.
2002.
Genia corpus: an annotated researchabstract corpus in molecular biology domain.
In Pro-ceedings of the Human Language Technology Confer-ence.Toshihide Ono, Haretsugu Hishigaki, Akira Tanigami,and Toshihisa Takagi.
2001.
Automated extractionof information on protein-protein interactions from thebiological literature.
BIOINFORMATICS, 17(2):155?161.Ted Pedersen.
2000.
A simple approach to building en-sembles of naive bayesian classifiers for word sensedisambiguation.
In Proceedings of the First AnnualMeeting of the North American Chapter of the Associ-ation for Computational Linguistics, pages 63?69.K.
Takeuchi and N. Collier.
2002.
Use of support vec-tor machines in extended named entity recognition.
InProceedings of the 6th Conference on Natural Lan-guage Learning 2002 (CoNLL-2002), pages 119?125.James Thomas, David Milward, Christos Ouzounis,Stephen Pulman, and Mark Carroll.
2000.
Automaticextraction of protein interactions from scientific ab-stracts.
In Proceedings of the Pacific Symposium onBiocomputing (PSB2000), volume 5, pages 502?513.
