Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1332?1341,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsStructural Opinion Mining for Graph-based Sentiment RepresentationYuanbin Wu, Qi Zhang, Xuanjing Huang, Lide WuFudan UniversitySchool of Computer Science{ybwu,qz,xjhuang,ldwu}@fudan.edu.cnAbstractBased on analysis of on-line review corpuswe observe that most sentences have compli-cated opinion structures and they cannot bewell represented by existing methods, such asframe-based and feature-based ones.
In thiswork, we propose a novel graph-based rep-resentation for sentence level sentiment.
Aninteger linear programming-based structurallearning method is then introduced to producethe graph representations of input sentences.Experimental evaluations on a manually la-beled Chinese corpus demonstrate the effec-tiveness of the proposed approach.1 IntroductionSentiment analysis has received much attention inrecent years.
A number of automatic methods havebeen proposed to identify and extract opinions, emo-tions, and sentiments from text.
Previous researcheson sentiment analysis tackled the problem on vari-ous levels of granularity including document, sen-tence, phrase and word (Pang et al, 2002; Riloff etal., 2003; Dave et al, 2003; Takamura et al, 2005;Kim and Hovy, 2006; Somasundaran et al, 2008;Dasgupta and Ng, 2009; Hassan and Radev, 2010).They mainly focused on two directions: sentimentclassification which detects the overall polarity of atext; sentiment related information extraction whichtries to answer the questions like ?who expresseswhat opinion on which target?.Most of the current studies on the second direc-tion assume that an opinion can be structured as aframe which is composed of a fixed number of slots.Typical slots include opinion holder, opinion expres-sion, and evaluation target.
Under this representa-tion, they defined the task as a slots filling prob-lem for each of the opinions.
Named entity recog-nition and relation extraction techniques are usuallyapplied in this task (Hu and Liu, 2004; Kobayashiet al, 2007; Wu et al, 2009).However, through data analysis, we observe that60.5% of sentences in our corpus do not follow theassumption used by them.
A lot of important infor-mation about an opinion may be lost using those rep-resentation methods.
Consider the following exam-ples, which are extracted from real online reviews:Example 1: The interior is a bit noisy on the free-way1.Example 2: Takes good pictures during the day-time.
Very poor picture quality at night2.Based on the definition of opinion unit proposedby Hu and Liu (2004), from the first example, theinformation we can get is the author?s negative opin-ion about ?interior?
using an opinion expression?noisy?.
However, the important restriction ?on thefreeway?, which narrows the scope of the opinion,is ignored.
In fact, the tuple (?noisy?,?on the free-way?)
cannot correctly express the original opinion:it is negative but under certain condition.
The sec-ond example is similar.
If the conditions ?during thedaytime?
and ?at night?
are dropped, the extractedelements cannot correctly represent user?s opinions.Example 3: The camera is actually quite good foroutdoors because of the software.Besides that, an opinion expression may induceother opinions which are not expressed directly.
Inexample 3, the opinion expression is ?good?
whose1http://reviews.carreview.com/blog/2010-ford-focus-review-the-compact-car-that-can/2http://www.dooyoo.co.uk/digital-camera/sony-cyber-shot-dsc-s500/1151680/1332target is ?camera?.
But the ?software?
which trig-gers the opinion expression ?good?
is also endowedwith a positive opinion.
In practice, this inducedopinion on ?software?
is actually more informativethan its direct counterpart.
Mining those opinionsmay help to form a complete sentiment analysis re-sult.Example 4: The image quality is in the middle ofits class, but it can still be a reasonable choice forstudents.Furthermore, the relations among individual opin-ions also provide additional information which islost when they are considered separately.
Example4 is such a case that the whole positive comment ofcamera is expressed by a transition from a negativeopinion to a positive one.In order to address those issues, this paper de-scribes a novel sentiment representation and analysismethod.
Our main contributions are as follows:1.
We investigate the use of graphs for repre-senting sentence level sentiment.
The ver-tices are evaluation target, opinion expression,modifiers of opinion.
The Edges representrelations among them.
The semantic rela-tions among individual opinions are also in-cluded.
Through the graph, various informa-tion on opinion expressions which is ignoredby current representation methods can be wellhandled.
And the proposed representation islanguage-independent.2.
We propose a supervised structural learningmethod which takes a sentence as input and theproposed sentiment representation for it as out-put.
The inference algorithm is based on in-teger linear programming which helps to con-cisely and uniformly handle various propertiesof our sentiment representation.
By setting ap-propriate prior substructure constraints of thegraph, the whole algorithm achieves reasonableperformances.The remaining part of this paper is organized asfollows: In Section 2 we discuss the proposed rep-resentation method.
Section 3 describes the com-putational model used to construct it.
Experimentalresults in test collections and analysis are shown inSection 4.
In Section 5, we present the related workand Section 6 concludes the paper.2 Graph-based Sentiment RepresentationIn this work, we propose using directed graph torepresent sentiments.
In the graph, vertices aretext spans in the sentences which are opinion ex-pressions, evaluation targets, conditional clauses etc.Two types of edges are included in the graph: (1)relations among opinion expressions and their mod-ifiers; (2) relations among opinion expressions.
Theedges of the first type exist within individual opin-ions.
The second type of the edges captures the re-lations among individual opinions.
The followingsections detail the definition.2.1 Individual Opinion RepresentationLet r be an opinion expression in a sentence, the rep-resentation unit for r is a set of relations {(r, dk)}.For each relation (r, dk), dk is a modifier which is aspan of text specifying the change of r?s meaning.The relations between modifier and opinion ex-pression can be the type of any kind.
In this work,we mainly consider two basic types:?
opinion restriction.
(r, dk) is called an opin-ion restriction if dk narrows r?s scope, adds acondition, or places limitations on r?s originalmeaning.?
opinion expansion.
(r, dk) is an opinion expan-sion if r?s scope expands to dk, r induces an-other opinion on dk, or the opinion on dk is im-plicitly expressed by r.Mining the opinion restrictions can help to get ac-curate meaning of an opinion, and the opinion ex-pansions are useful to cover more indirect opinions.As with previous sentiment representations, we ac-tually consider the third type of modifier which dk isthe evaluation target of r.Figure 1 shows a concrete example.
In this ex-ample, there are three opinion expressions: ?good?,?sharp?, ?slightly soft?.
The modifiers of ?good?are ?indoors?
and ?Focus accuracy?, where relation(?good?,?indoors?)
is an opinion restriction because?indoors?
is the condition under which ?Focus ac-curacy?
is good.
On the other hand, the relation1333(?sharp?, ?little 3x optical zooms?)
is an opinion ex-pansion because the ?sharp?
opinion on ?shot?
im-plies a positive opinion on ?little 3x optical zooms?.It is worth to remark that: 1) a modifier dk can re-late to more than one opinion expression.
For exam-ple, multiple opinion expressions may share a samecondition; 2) dk itself can employ a set of relations,although the case appears occasionally.
The follow-ing is an example:Example 5: The camera wisely get rid of manyredundant buttons.In the example, ?redundant buttons?
is the eval-uation target of opinion expression ?wisely get ridof?, but itself is a relation between ?redundant?and ?buttons?.
Such nested semantic structure isdescribed by a path: ?wisely get rid of?
target?????[?redundant?
target??????buttons?
]nested target.2.2 Relations between Individual OpinionRepresentationAssume ?ri?
are opinion expressions ordered bytheir positions in sentence, and each of them hasbeen represented by relations {(ri, dik)} individu-ally (the nested relations for dik have also been de-termined).
Then we define two relations on adja-cent pair ri, ri+1: coordination when the polaritiesof ri and ri+1 are consistent, and transition whenthey are opposite.
Those relations among ri form aset B called opinion thread.
In Figure 1, the opin-ion thread is: {(?good?, ?sharp?
), (?sharp?, ?slightlysoft?
)}.The whole sentiment representation for a sentencecan be organized by a direct graphG = (V,E).
Ver-tex set V includes all opinion expressions and mod-ifiers.
Edge set E collects both relations of eachindividual opinion and relations in opinion thread.The edges are labeled with relation types in label setL={?restriction?, ?expansion?, ?target?, ?coordina-tion?, ?transition?}
3.Compared with previous works, the advantages ofusing G as sentiment representation are: 1) for in-dividual opinions, the modifiers will collect moreinformation than using opinion expression alone.3We don?t define any ?label?
on vertices: if two span of textsatisfy a relation in L, they are chosen to be vertices and anedge with proper label will appear inE.
In other words, verticesare identified by checking whether there exist relations amongthem.Focus accuracy was good indoors, and although thelittle 3x optical zooms produced sharp shots, theedges were slightly soft on the Canon.Focusaccuracyedgesslightly soft shotssharplittle 3x opticalzoomsindoorsgoodExpansionTargetCoordinateTransitionTargetTargetRestrictionr1r2r3d11d12d21d22d31Figure 1: Sentiment representation for an example sen-tenceThus G is a relatively complete and accurate rep-resentation; 2) the opinion thread can help to catchglobal sentiment information, for example the gen-eral polarity of a sentence, which is dropped whenthe opinions are separately represented.3 System DescriptionTo produce the representation graph G for a sen-tence, we need to extract candidate vertices andbuild the relations among them to get a graph struc-ture.
For the first task, the experimental results inSection 4 demonstrate that the standard sequentiallabeling method with simple features can achievereasonable performance.
In this section, we focuson the second task, and assume the vertices in thegraph have already been correctly collected in thefollowing formulation of algorithm.3.1 PreliminariesIn order to construct graph G, we use a structurallearning method.
The framework is from the first or-der discriminative dependency parsing model (Mc-donald and Pereira, 2005).
A sentence is denoted bys; x are text spans which will be vertices of graph;xi is the ith vertex in x ordered by their positions ins.
For a set of vertices x, y is the graph of its sen-timent representation, and e = (xi, xj) ?
y is thedirect edge from xi to xj in y.
In addition, x0 is a1334virtual root node without inedge.
G = {(xn,yn)}Nnis training set.Following the edge based factorization, the scoreof a graph is the sum of its edges?
scores,score(x,y) =?
(xi,xj)?yscore(xi, xj)=?
(xi,xj)?y?T f(xi, xj), (1)f(xi, xj) is a high dimensional feature vector of theedge (xi, xj).
The components of f are either 0 or 1.For example the k-th component could befk(xi, xj) =??
?1 if xi.POS = JJ and xj .POS = NNand label of (xi, xj)is restriction0 otherwise.Then the score of an edge is the linear combinationof f ?s components, and the coefficients are in vector?.Algorithm 1 shows the parameter learning pro-cess.
It aims to get parameter ?
which will assignthe correct graph y with the highest score among allpossible graphs of x (denoted by Y).Algorithm 1 Online structural learningTraining Set:G = {(xn, yn)}Nn1: ?0 = 0, r = 0, T =maximum iteration2: for t = 0 to T do3: for n = 0 to N do4: y?
= argmaxy?Y score(xn, y) B Inference5: if y?
6= yn then6: update ?t to ?t+1 B PA7: r = r + ?t+18: end if9: end for10: end for11: return ?
= r/(N ?
T )3.2 InferenceLike other structural learning tasks, the ?argmax?operation in the algorithm (also called inference)y?
= argmaxy?Yscore(x,y)= argmaxy?Y?
(xi,xj)?y?T f(xi, xj) (2)is hard because all possible values of y form a hugesearch space.
In our case, Y is all possible directedacyclic graphs of the given vertex set, which num-ber is exponential.
Directly solving the problem offinding maximum weighted acyclic graph is equiva-lent to finding maximum feedback arc set, which is aNP-hard problem (Karp, 1972).
We will use integerlinear programming (ILP) as the framework for thisinference problem.3.2.1 Graph PropertiesWe first show some properties of graph G eitherfrom the definition of relations or corpus statistics.Property 1.
The graph is connected and withoutdirected cycle.
From individual opinion represen-tation, each subgraph of G which takes an opinionexpression as root is connected and acyclic.
Thusthe connectedness is guaranteed for opinion expres-sions are connected in opinion thread; the acyclic isguaranteed by the fact that if a modifier is shared bydifferent opinion expressions, the inedges from themalways keep (directed) acyclic.Property 2.
Each vertex can have one outedgelabeled with coordination or transition at most.
Theopinion thread B is a directed path in graph.Property 3.
The graph is sparse.
The averagein-degree of a vertex is 1.03 in our corpus, thus thegraph is almost a rooted tree.
In other words, thecases that a modifier connects to more than one opin-ion expression rarely occur comparing with thosevertices which have a single parent.
An explainationfor this sparseness is that opinions in online reviewsalways concentrate in local context and have localsemantic connections.3.2.2 ILP FormulationBased on the property 3, we divide the inferencealgorithm into two steps: i) constructing G?s span-ning tree (arborescence) with property 1 and 2; ii)finding additional non-tree edges as a post process-ing task.
The first step is close to the works on ILPformulations of dependency parsing (Riedel andClarke, 2006; Martins et al, 2009).
In the secondstep, we use a heuristic method which greedily addsnon-tree edges.
A similar approximation methodis also used in (Mcdonald and Pereira, 2006) foracyclic dependency graphs.Step 1.
Find MST.
Following the multicommodity1335flow formulation of maximum spanning tree (MST)problem in (Magnanti and Wolsey, 1994), the ILPfor MST is:max.
?i,jyij ?
score(xi, xj) (3)s.t.
?i,jyij = |V | ?
1 (4)?ifuij ?
?kfujk = ?uj ,1 ?
u, j ?
|V | (5)?kfu0k = 1, 1 ?
u ?
|V | (6)fuij ?
yij , 1 ?
u, j ?
|V |,0 ?
i ?
|V | (7)fuij ?
0, 1 ?
u, j ?
|V |,0 ?
i ?
|V | (8)yij ?
{ 0, 1}, 0 ?
i, j ?
|V |.
(9)In this formulation, yij is an edge indicator vari-able that (xi, xj) is a spanning tree edge when yij =1, (xi, xj) is a non-tree edge when yij = 0.
Thenoutput y is represented by the set {yij , 0 ?
i, j ?|V |} 4.
Eq(4) ensures that there will be exactly|V | ?
1 edges are chosen.
Thus if the edges cor-responding to those non zero yij is a connected sub-graph, y is a well-formed spanning tree.
Objectivefunction just says the optimal solution of yij havethe maximum weight.The connectedness is guaranteed if for every ver-tex, there is exactly one path from root to it.
It is for-mulated by using |V | ?
1 flows {fu, 1 ?
u ?
|V |}.fu starts from virtual root x0 towards vertex xu.Each flow fu = {fuij , 0 ?
i, j ?
|V |}.
fuij indi-cates whether flow fu is through edge (xi, xj).
soit should be 0 if edge (xi, xj) does not exist (by(7)).
The Kronecker?s delta ?uj in (5) guarantees fuis only assumed by vertex xu, so fu is a well-formedpath from root to xu.
(6) ensures there is only oneflow (path) from root to xu.
Thus the subgraph isconnected.
The following are our constraints:c1: Constraint on edges in opinion thread (10)-(11).From the definition of opinion thread, we imposea constraint on every vertex?s outedges in opinionthread, which are labeled with ?coordination?
or4For simplicity, we overload symbol y from the graph of thesentiment represetation to the MST of it.?transition?.
Let Iob be a characteristic function onedges: Iob((j, k)) = 1 when edge (xj , xk) is labeledwith ?coordination?
or ?transition?, otherwise 0.
Wedenote q variables for vertices:qj =?kyjk ?
Iob((j, k)), 0 ?
j ?
|V |.
(10)Then following linear inequalities bound the numberof outedges in opinion thread (?
1) on each vertex:qj ?
1, 0 ?
j ?
|V |.
(11)c2: Constraint on target edge (12).We also bound the number of evaluation targetsfor a vertex in a similar way.
Let It be characteris-tic function on edges identifing whether it is labeledwith ?target?,?kyjk ?
It((j, k)) ?
Ct, 0 ?
j ?
|V |.
(12)The parameter Ct can be adjusted according to thestyle of document.
In online reviews, authors tendto use simple and short comments on individual tar-gets, so Ct could be set small.c3: Constraint on opinion thread (13)-(18).From graph property 2, the opinion thread shouldbe a directed path.
It implies the number of con-nected components whose edges are ?coordination?or ?transition?
should be less than 1.
Two set of ad-ditional variables are needed: {cj , 0 ?
j ?
|V |} and{hj , 0 ?
j ?
|V |}, wherecj ={1 if an opinion thread starts at xj0 otherwise ,andhj =?iyij ?
Iob((i, j)).
(13)Then cj = ?hj ?
qj , which can be linearized bycj?
qj ?
hj , (14)cj?
1 ?
hj , (15)cj?
qj , (16)cj?
0.
(17)If the sum of cj is no more than 1, the opinion threadof graph is a directed path.
?jcj ?
1.
(18)13361234567(a)(b)123456 7(c)12 34567Figure 2: The effects of c1 and c3.
Assume solid linesare edges labeled with ?coordination?
and ?transition?,dot lines are edges labeled with other types.
(a) is anarbitrary tree.
(b) is a tree with c1 constraints.
(c) is atree with c1 and c3.
It shows c1 are not sufficient forgraph property 2: the edges in opinion thread may not beconnected.Figure 2 illustrates the effects of c1 and c3.Equations (10)-(18), together with basic multi-commodity flow model build up the inference algo-rithm.
The entire ILP formulation involves O(|V |3)variables and O(|V |2) constraints.
Generally, ILPfalls into NPC, but as an important result, in the mul-ticommodity flow formulation of maximum span-ning tree problem, the integer constraints (9) on yijcan be dropped.
So the problem reduces to a linearprogramming which is polynomial solvable (Mag-nanti and Wolsey, 1994).
Unfortunately, with ouradditional constraints the LP relaxation is not valid.Step 2.
Adding non-tree edges.
We examine thecase that a modifier attaches to different opinion ex-pressions.
That often occurs as the result of thesharing of modifiers among adjacent opinion expres-sions.
We add those edges in the following heuristicway: If a vertex ri in opinion thread does not haveany modifier, we search the modifiers of its adjacentvertices ri+1, ri?1 in the opinion thread, and addedge (ri, d?)
whered?
= argmaxd?Sscore(ri, d),and S are the modifiers of ri?1 and ri+1.3.3 TrainingWe use online passive aggressive algorithm (PA)with Hamming cost of two graphs in training (Cram-mer et al, 2006).Unigram Feature Templatexi.text w0.text w1.textw0.POS w1.POSwk?1.text wk.textInside wk?1.POS wk.POSFeatures xi.hasDigitalxi.isSingleWordxi.hasSentimentWordxi.hasParallelPhrasew?1.text w?2.textw?1.POS w?2.POSwk+1.text wk+2.textOutside wk+1.POS wk+2.POSFeatures c?1.text c?2.textc?1.POS c?2.POScl+1.text cl+2.textcl+1.POS cl+2.POSOther Featuresdistance between parent and childdependency parsing relationsTable 1: Feature set3.4 Feature ConstructionFor each vertex xi in graph, we use 2 sets of fea-tures: inside features which are extracted inside thetext span of xi; outside features which are outsidethe text span of xi.
A vertex xi is described both inword sequence (w0, w1, ?
?
?
, wk) and character se-quence (c0, c1, ?
?
?
, cl), for the sentences are in Chi-nese.?
?
?
, w?1, w0, w1, w2, ?
?
?
, wk?1, wk?
??
?xi, wk+1 ?
?
??
?
?
, c?1, c0, c1, c2, ?
?
?
, cl?1, cl?
??
?xi, cl+1 ?
?
?For an edge (xi, xj), the high dimensional featurevector f(xi, xj) is generated by using unigram fea-tures in Table 1 on xi and xj respectively.
The dis-tance between parent and child in sentence is alsoattached in features.
In order to involve syntacticinformation, whether there is certain type of depen-dency relation between xi and xj is also used as afeature.13374 Experiments4.1 CorpusWe constructed a Chinese online review corpus fromPcpop.com, Zol.com.cn, and It168.com, which havea large number of reviews about digital camera.
Thecorpus contains 138 documents and 1735 sentences.Since some sentences do not contain any opinion,1390 subjective sentences were finally chosen andmanually labeled.Two annotators labeled the corpus independently.The annotators started from locating opinion expres-sions, and for each of them, they annotated othermodifiers related to it.
In order to keep the relia-bility of annotations, another annotator was askedto check the corpus and determine the conflicts.
Fi-nally, we extracted 6103 elements, which are con-nected by 6284 relations.Relation NumberTarget 2479Coordinate 1173Transition 154Restriction 693Expansion 386Table 2: Statistics of relation typesTable 2 shows the number of various relationtypes appearing in the labeled corpus.
We observe60.5% of sentences and 32.1% of opinion expres-sions contain other modifiers besides ?target?.
Thusonly mining the relations between opinion expres-sions and evaluation target is actually at risk of inac-curate and incomplete results.4.2 Experiments ConfigurationsIn all the experiments below, we take 90% of the cor-pus as training set, 10% as test set and run 10 foldercross validation.
In feature construction, we usean external Chinese sentiment lexicon which con-tains 4566 positive opinion words and 4370 nega-tive opinion words.
For Chinese word segment, weuse ctbparser 5.
Stanford parser (Klein and Man-ning, 2003) is used for dependency parsing.
In thesettings of PA, the maximum iteration number is5http://code.google.com/p/ctbparser/set to 2, which is chosen by maximizing the test-ing performances, aggressiveness parameter C is setto 0.00001.
For parameters in inference algorithm,Ct = 2, the solver of ILP is lpsolve6.We evaluate the system from the following as-pects: 1) whether the structural information helpsto mining opinion relations.
2) How the proposedinference algorithm performs with different con-straints.
3) How the various features affect the sys-tem.
Except for the last one, the feature set used fordifferent experiments are the same (?In+Out+Dep?in Table 5).
The criteria for evaluation are simi-lar to the unlabeled attachment score in parser eval-uations, but due to the equation |E| = |V | ?
1is not valid if G is not a tree, we evaluate pre-cision P = #true edges in result graph#edges in result graph , recallR = #true edges in result graph#edges in true graph , and F-scoreF = 2P ?RP+R .4.3 Results1.
The effects of structural information.
An alter-native method to extract relations is directly usinga classifier to judge whether there is a relation be-tween any two elements.
Those kinds of methodswere used in previous opinion mining works (Wuet al, 2009; Kobayashi et al, 2007).
To show theentire structural information is important for min-ing relations, we use SVM for binary classificationon candidate pairs.
The data point representing apair (xi, xj) is the same as the high dimensional fea-ture vectors f(xi, xj).
The setting of our algorithm?MST+c1+c2+c3?
is the basic MSTwith all the con-straints.
The results are shown in the Table 3.P R FSVM 64.9 24.0 35.0MST+c1+c2+c3-m 61.5 74.0 67.2MST+c1+c2+c3 73.1 71.0 72.1Table 3: Binary classifier and structural learningFrom the results, the performance of SVM (espe-cially recall) is relatively poor.
A possible reasonis that the huge imbalance of positive and negativetraining samples (only ?
(n) positive pairs amongall n2 pairs).
And the absence of global structural6http://sourceforge.net/projects/lpsolve/1338knowledge makes binary classifier unable to usethe information provided by classification results ofother pairs.In order to examine whether the complicated sen-timent representation would disturb the classifier infinding relations between opinion expressions andits target, we evaluate the system by discarding themodifiers of opinion restriction and expansion fromthe corpus.
The result is shown in the second row ofTable 3.
We observe that ?MST+c1+c2+c3?
is stillbetter which means at least on overall performancethe additional modifiers do not harm.2.
The effect of constraints on inference algo-rithm.
In the inference algorithm, we utilized theproperties of graph G and adapted the basic multi-commodity flow ILP to our specific task.
To evaluatehow the constraints affect the system, we decomposethe algorithm and combine them in different ways.P R FMST 69.3 67.3 68.3MST+c1 70.0 68.0 69.0MST+c2 69.8 67.8 68.8MST+c1+c2 70.6 68.6 69.6MST+c1+c3 72.4 70.4 71.4MST+c1+c2+c3 73.1 71.0 72.1MST+c1+c2+c3+g 72.5 72.3 72.4Table 4: Results on inference methods.
?MST?
is the ba-sic multicommodity flow formulation of maximum span-ning tree; c1, c2, c3 are groups of constraint from Section3.2.2; ?g?
is our heuristic method for additional non span-ning tree edges.From Table 4, we observe that with any additionalconstraints the inference algorithm outperforms thebasic maximum spanning tree method.
It implies al-though we did not use high order model (e.g.
involv-ing grandparent and sibling features), prior struc-tural constraints can also help to get a better out-put graph.
By comparing with different constraintcombinations, the constraints on opinion thread (c1,c3) are more effective than constraints on evaluationtargets (c2).
It is because opinion expressions aremore important in the entire sentiment representa-tion.
The main structure of a graph is clear once therelations between opinion expressions are correctlydetermined.3.
The effects of various features.
We evaluate theperformances of different feature configurations inTable 5.
From the results, the outside feature set ismore effective than inside feature set, even if it doesnot use any external resource.
A possible reason isthat the content of a vertex can be very complicated(a vertex even can be a clause), but the features sur-rounding the vertex are relatively simple and easyto identify (for example, a single preposition canidentify a complex condition).
The dependency fea-ture has limited effect, due to that lots of online re-view sentences are ungrammatical and parsing re-sults are unreliable.
And the complexity of verticesalso messes the dependency feature.P R FIn-s 66.3 66.3 66.3In 66.7 66.4 66.6Out 67.8 67.4 67.6In+Out 72.0 70.5 71.0In+Out+Dep 72.5 72.3 72.4Table 5: Results with different features.
?In?
repre-sents the result of inside feature set; ?In-s?
is ?In?
with-out the external opinion lexicon feature; ?Out?
uses theoutside feature set; ?In+Out?
uses both ?In?
and ?Out?,?In+Out+Dep?
adds the dependency feature.
The infer-ence algorithm is ?MST+c1+c2+c3+g?
in Table 4.We analyze the errors in test results.
A mainsource of errors is the confusion of classifier be-tween ?target?
relations and ?coordination?, ?tran-sition?
relations.
The reason may be that for a mod-ification on opinion expression (r, dk), we allowdk recursively has its own modifiers (Example 5).Thus an opinion expression can be a modifier whichbrings difficulties to classifier.4.
Extraction of vertices.
Finally we conduct anexperiment on vertex extraction using standard se-quential labeling method.
The tag set is simply {B,I, O} which are signs of begin, inside, outside of avertex.
The underlying model is conditional randomfield 7.
Feature templates involved are in Table 6.We only use basic features in the experiment.
10folder cross validation results are in table 7.
We sus-pect that the performances (especially recall) couldbe improved if some external resources(i.e.
ontol-ogy, domain related lexicon, etc.)
are involved.7We use CRF++ toolkit, http://crfpp.sourceforge.net/1339Unigram Templateci.char characterci.isDigit digitci.isAlpha english letterci.isPunc punctuationci.inDict in a sentiment wordci.BWord start of a wordci.EWord end of a wordTable 6: Features for vertex extraction.
The sequentiallabeling is conducted on character level (ci).
The senti-ment lexicon used in ci.inDict is the same as Table1.
Wealso use bigram feature templates on ci.char, ci.isAlpha,ci.inDict with respect to ci?1 and ci+1.P R FE+Unigram 56.8 45.1 50.3E+Unigram+Bigram 57.3 47.9 52.1O+Unigram 71.9 57.2 63.7O+Unigram+Bigram 72.3 60.2 65.6Table 7: Results on vertices extraction with 10 foldercross validation.
We use two criterion: 1) the vertex iscorrect if it is exactly same as ground truth(?E?
), 2) thevertex is correct if it overlaps with ground truth(?O?
).5 Related WorkOpinion mining has recently received considerableattentions.
Large amount of work has been done onsentimental classification in different levels and sen-timent related information extraction.
Researches ondifferent types of sentences such as comparative sen-tences (Jindal and Liu, 2006) and conditional sen-tences (Narayanan et al, 2009) have also been pro-posed.Kobayashi et al (2007) presented their work onextracting opinion units including: opinion holder,subject, aspect and evaluation.
They used slotsto represent evaluations, converted the task to twokinds of relation extraction tasks and proposed a ma-chine learning-based method which used both con-textual and statistical clues.Jindal and Liu (2006) studied the problem of iden-tifying comparative sentences.
They analyzed dif-ferent types of comparative sentences and proposedlearning approaches to identify them.Sentiment analysis of conditional sentences werestudied by Narayanan et al (2009).
They aimedto determine whether opinions expressed on dif-ferent topics in a conditional sentence are posi-tive, negative or neutral.
They analyzed the con-ditional sentences in both linguistic and computi-tional perspectives and used learning method to doit.
They followed the feature-based sentiment anal-ysis model (Hu and Liu, 2004), which also use flatframes to represent evaluations.Integer linear programming was used in manyNLP tasks (Denis and Baldridge, 2007), for itspower in both expressing and approximating variousinference problems, especially in parsing (Riedeland Clarke, 2006; Martins et al, 2009).
Martinsetc.
(2009) also applied ILP with flow formulationfor maximum spanning tree, besides, they also han-dled dependency parse trees involving high orderfeatures(sibling, grandparent), and with projectiveconstraint.6 ConclusionsThis paper introduces a representation method foropinions in online reviews.
Inspections on corpusshow that the information ignored in previous sen-timent representation can cause incorrect or incom-plete mining results.
We consider opinion restric-tion, opinion expansions, relations between opin-ion expressions, and represent them with a directedgraph.
Structural learning method is used to producethe graph for a sentence.
An inference algorithm isproposed based on the properties of the graph.
Ex-perimental evaluations with a manually labeled cor-pus are given to show the importance of structuralinformation and effectiveness of proposed inferencealgorithm.7 AcknowledgementThe author wishes to thank the anonymous review-ers for their helpful comments.
This work waspartially funded by 973 Program (2010CB327906),National Natural Science Foundation of China(61003092, 61073069),863 Program of China(2009AA01A346), Shanghai Science and Tech-nology Development Funds(10dz1500104), Doc-toral Fund of Ministry of Education of China(200802460066), Shanghai Leading Academic Dis-cipline Project (B114), and Key Projects inthe National Science & Technology Pillar Pro-1340gram(2009BAH40B04).ReferencesKoby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
Journal of Machine LearningResearch, 7:551?585.Sajib Dasgupta and Vincent Ng.
2009.
Mine the easy,classify the hard: A semi-supervised approach to auto-matic sentiment classification.
In Proceedings of ACL-IJCNLP.Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: opinion extractionand semantic classification of product reviews.
In Pro-ceedings of WWW.Pascal Denis and Jason Baldridge.
2007.
Joint determi-nation of anaphoricity and coreference resolution us-ing integer programming.
In Proceedings of NAACL-HLT.Ahmed Hassan and Dragomir R. Radev.
2010.
Identify-ing text polarity using random walks.
In Proceedingsof ACL, pages 395?403, Uppsala, Sweden, July.
Asso-ciation for Computational Linguistics.Minqing Hu and Bing Liu.
2004.
Mining and summariz-ing customer reviews.
In Proceedings of SIGKDD.Nitin Jindal and Bing Liu.
2006.
Identifying comparativesentences in text documents.
In Proceedings of SIGIR.R.
Karp.
1972.
Reducibility among combinatorial prob-lems.
In R. Miller and J. Thatcher, editors, Complex-ity of Computer Computations, pages 85?103.
PlenumPress.Soo-Min Kim and Eduard Hovy.
2006.
Automatic iden-tification of pro and con reasons in online reviews.
InProceedings of the COLING-ACL.Dan Klein and Christopher D.Manning.
2003.
Fast exactinference with a factored model for natural languageparsing.
In In Advances in Neural Information Pro-cessing Systems 15 (NIPS, pages 3?10.
MIT Press.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-of rela-tions in opinion mining.
In Proceedings of EMNLP-CoNLL.Thomas L. Magnanti and Laurence A. Wolsey.
1994.Optimal trees.Andre Martins, Noah Smith, and Eric Xing.
2009.
Con-cise integer linear programming formulations for de-pendency parsing.
In Proceedings of ACL-IJCNLP.R.
Mcdonald and F. Pereira.
2005.
Identifying geneand protein mentions in text using conditional randomfields.
BMC Bioinformatics.Ryan Mcdonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing al-gorithms.
In Proc.
of EACL, pages 81?88.Ramanathan Narayanan, Bing Liu, and Alok Choudhary.2009.
Sentiment analysis of conditional sentences.
InProceedings of EMNLP.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification using ma-chine learning techniques.
In Proc.
of EMNLP 2002.Sebastian Riedel and James Clarke.
2006.
Incrementalinteger linear programming for non-projective depen-dency parsing.
In Proceedings of EMNLP.Ellen Riloff, Janyce Wiebe, and Theresa Wilson.
2003.Learning subjective nouns using extraction patternbootstrapping.
In Proceedings of the seventh confer-ence on Natural language learning at HLT-NAACL.Swapna Somasundaran, Janyce Wiebe, and Josef Rup-penhofer.
2008.
Discourse level opinion interpreta-tion.
In Proceedings of COLING.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words usingspin model.
In Proceedings of ACL.Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu.2009.
Phrase dependency parsing for opinion mining.In Proceedings of EMNLP.1341
