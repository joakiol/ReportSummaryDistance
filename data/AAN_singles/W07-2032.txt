Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 157?160,Prague, June 2007. c?2007 Association for Computational LinguisticsGPLSI: Word Coarse-grained Disambiguation aided by Basic LevelConcepts?Rube?n Izquierdo Armando Sua?rezGPLSI Group, DLSIUniversity of AlicanteSpain{ruben, armando}@dlsi.ua.esGerman RigauIXA NLP GroupEHU/UPVDonostia, Basque Countrygerman.rigau@ehu.esAbstractWe present a corpus-based supervised lear-ning system for coarse-grained sense disam-biguation.
In addition to usual features fortraining in word sense disambiguation, oursystem also uses Base Level Concepts au-tomatically obtained from WordNet.
BaseLevel Concepts are some synsets that gene-ralize a hyponymy sub?hierarchy, and pro-vides an extra level of abstraction as well asrelevant information about the context of aword to be disambiguated.
Our experimentsproved that using this type of features re-sults on a significant improvement of preci-sion.
Our system has achieved almost 0.8 F1(fifth place) in the coarse?grained Englishall-words task using a very simple set of fea-tures plus Base Level Concepts annotation.1 IntroductionThe GPLSI system in SemEval?s task 7, coarse?grained English all-words, consists of a corpus-based supervised-learning method which uses lo-cal context information.
The system uses Base Le-vel Concepts (BLC) (Rosch, 1977) as features.
Inshort, BLC are synsets of WordNet (WN) (Fell-baum, 1998) that are representative of a certain hy-ponymy sub?hierarchy.
The synsets that are se-lected to be BLC must accomplish certain condi-tions that will be explained in next section.
BLC?This paper has been supported by the European Union un-der the project QALL-ME (FP6 IST-033860) and the SpanishGovernment under the project Text-Mess (TIN2006-15265-C06-01) and KNOW (TIN2006-15049-C03-01)are slightly different from Base Concepts of Eu-roWordNet1 (EWN) (Vossen et al, 1998), Balkanet2or Meaning Project3 because of the selection crite-ria but also because our method is capable to definethem automatically.
This type of features helps oursystem to achieve 0.79550 F1 (over the First?Sensebaseline, 0.78889) while only four systems outper-formed ours being the F1 of the best one 0.83208.WordNet has been widely criticised for being asense repository that often offers too fine?grainedsense distinctions for higher level applications likeMachine Translation or Question & Answering.
Infact, WSD at this level of granularity, has resistedall attempts of inferring robust broad-coverage mo-dels.
It seems that many word?sense distinctions aretoo subtle to be captured by automatic systems withthe current small volumes of word?sense annotatedexamples.
Possibly, building class-based classifierswould allow to avoid the data sparseness problem ofthe word-based approach.Thus, some research has been focused on deri-ving different sense groupings to overcome the fine?grained distinctions of WN (Hearst and Schu?tze,1993) (Peters et al, 1998) (Mihalcea and Moldo-van, 2001) (Agirre et al, 2003) and on using predefi-ned sets of sense-groupings for learning class-basedclassifiers for WSD (Segond et al, 1997) (Ciaramitaand Johnson, 2003) (Villarejo et al, 2005) (Curran,2005) (Ciaramita and Altun, 2006).
However, mostof the later approaches used the original Lexico-graphical Files of WN (more recently called Super-1http://www.illc.uva.nl/EuroWordNet/2http://www.ceid.upatras.gr/Balkanet3http://www.lsi.upc.es/ nlp/meaning157senses) as very coarse?grained sense distinctions.However, not so much attention has been paid onlearning class-based classifiers from other availablesense?groupings such as WordNet Domains (Mag-nini and Cavaglia, 2000), SUMO labels (Niles andPease, 2001), EuroWordNet Base Concepts or TopConcept Ontology labels (Atserias et al, 2004).
Ob-viously, these resources relate senses at some levelof abstraction using different semantic criteria andproperties that could be of interest for WSD.
Pos-sibly, their combination could improve the overallresults since they offer different semantic perspecti-ves of the data.
Furthermore, to our knowledge, todate no comparative evaluation have been performedexploring different sense?groupings.This paper is organized as follows.
In section 2,we present a method for deriving fully automatica-lly a number of Base Level Concepts from any WNversion.
Section 3 shows the details of the wholesystem and finally, in section 4 some concluding re-marks are provided.2 Automatic Selection of Base LevelConceptsThe notion of Base Concepts (hereinafter BC) wasintroduced in EWN.
The BC are supposed to be theconcepts that play the most important role in the va-rious wordnets4 (Fellbaum, 1998) of different lan-guages.
This role was measured in terms of twomain criteria:?
A high position in the semantic hierarchy;?
Having many relations to other concepts;Thus, the BC are the fundamental building blocksfor establishing the relations in a wordnet and giveinformation about the dominant lexicalization pat-terns in languages.
BC are generalizations of featu-res or semantic components and thus apply to a ma-ximum number of concepts.
Thus, the LexicograficFiles (or Supersenses) of WN could be consideredthe most basic set of BC.Basic Level Concepts (Rosch, 1977) should notbe confused with Base Concepts.
BLC are the resultof a compromise between two conflicting principlesof characterization:4http://wordnet.princeton.edu#rel.
synset18 group 1,grouping 119 social group 137 organisation 2,organization 110 establishment 2,institution 112 faith 3,religion 25 Christianity 2,church 1,Christian church 1#rel.
synset14 entity 1,something 129 object 1,physical object 139 artifact 1,artefact 163 construction 3,structure 179 building 1,edifice 111 place of worship 1, ...19 church 2,church building 1#rel.
synset20 act 2,human action 1,human activity 169 activity 15 ceremony 311 religious ceremony 1,religious ritual 17 service 3,religious service 1,divine service 11 church 3,church service 1Table 1: Possible Base Level Concepts for the nounChurch?
Represent as many concepts as possible;?
Represent as many features as possible;As a result of this, Basic Level Concepts typicallyoccur in the middle of hierarchies and less than themaximum number of relations.
BC mostly involvethe first principle of the Basic Level Concepts only.Our work focuses on devising simple methods forselecting automatically an accurate set of Basic Le-vel Concepts from WN.
In particular, our method se-lects the appropriate BLC of a particular synset con-sidering the relative number of relations encoded inWN of their hypernyms.The process follows a bottom-up approach usingthe chain of hypernym relations.
For each synsetin WN, the process selects as its Base Level Con-cept the first local maximum according to the rela-tive number of relations.
For synsets having multi-ple hypernyms, the path having the local maximumwith higher number of relations is selected.
Usually,this process finishes having a number of ?fake?
BaseLevel Concepts.
That is, synsets having no descen-dants (or with a very small number) but being thefirst local maximum according to the number of re-lations considered.
Thus, the process finishes che-cking if the number of concepts subsumed by the158Senses BLC SuperSensesNouns 4.92 4.10 3.01Verbs 11.00 8.67 1.03Nouns + Verbs 7.66 6.16 3.47Table 2: Polysemy degree over SensEval?3preliminary list of BLC is higher than a certain th-reshold.
For those BLC not representing enoughconcepts according to a certain threshold, the pro-cess selects the next local maximum following thehypernym hierarchy.An example is provided in table 1.
This tableshows the possible BLC for the noun ?church?
usingWN1.6.
The table presents the hypernym chain foreach synset together with the number of relations en-coded in WN for the synset.
The local maxima alongthe hypernym chain of each synset appears in bold.Table 2 presents the polysemy degree for nounsand verbs of the different words when grouping itssenses with respect the different semantic classes onSensEval?3.
Senses stand for the WN senses, BLCfor the Automatic BLC derived using a threshold of20 and SuperSenses for the Lexicographic Files ofWN.3 The GPLSI systemThe GPLSI system uses a publicly available imple-mentation of Support Vector Machines, SVMLight5(Joachims, 2002), and Semcor as learning corpus.Semcor has been properly mapped and labelled withboth BLC6 and sense-clusters.Actually, the process of training-classification hastwo phases: first, one classifier is trained for eachpossible BLC class and then the SemEval test datais classified and enriched with them, and second, aclassifier for each target word is built using as addi-tional features the BLC tags in Semcor and SemE-val?s test.Then, the features used for training the classifiersare: lemmas, word forms, PoS tags7, BLC tags, andfirst sense class of target word (S1TW).
All features5http://svmlight.joachims.org/6Because BLC are automatically defined from WN, some tu-ning must be performed due to the nature of the task 7.
We havenot enough room to present the complete study but threshold 20has been chosen, using SENSEVAL-3 English all-words as testdata.
Moreover, our tests showed roughly 5% of improvementagainst not using these features.7TreeTagger (Schmid, 1994) was usedwere extracted from a window [?3.. + 3] except forthe last type (S1TW).
The reason of using S1TWfeatures is to assure the learning of the baseline.
It iswell known that Semcor presents a higher frequencyon first senses (and it is also the baseline of the taskfinally provided by the organizers).Besides, these are the same features for both firstand second phases (obviously except for S1TW be-cause of the different target set of classes).
Nevert-heless, the training in both cases are quite different:the first phase is class-based while the second isword-based.
By word-based we mean that the lear-ning is performed using just the examples in Semcorthat contains the target word.
We obtain one classi-fier per polysemous word are in the SemEval testcorpus.
The output of these classifiers is a sense-cluster.
In class-based learning all the examples inSemcor are used, tagging those ones belonging to aspecific class (BLC in our case) as positive exam-ples while the rest are tagged as negatives.
We ob-tain so many binary classifiers as BLC are in Se-mEval test corpus.
The output of these classifiersis true or false, ?the example belongs to a class?or not.
When dealing with a concrete target word,only those BLC classifiers that are related to it are?activated?
(i.e, ?animal?
classifier will be not usedto classify ?church?
), ensuring that the word will betagged with coherent labels.
In order to avoid statis-tical bias because of very large set of negative exam-ples, the features are defined from positive examplesonly (although they are obviously used to characte-rize all the examples).4 Conclusions and further workThe WSD task seems to have reached its maxi-mum accuracy figures with the usual framework.Some of its limitations could come from the sense?granularity of WN.
In particular, SemEval?s coarse-grained English all-words task represents a solutionin this direction.Nevertheless, the task still remains oriented towords rather than classes.
Then, other problemsarise like data sparseness just because the lack ofadequate and enough examples.
Changing the set ofclasses could be a solution to enrich training corporawith many more examples Another option seems tobe incorporating more semantic information.159Base Level Concepts (BLC) are concepts that arerepresentative for a set of other concepts.
A simplemethod for automatically selecting BLC from WNbased on the hypernym hierarchy and the number ofstored relationships between synsets have been usedto define features for training a supervised system.Although in our system BLC play a simple roleaiding to the disambiguation just as additional fea-tures, the good results achieved with such simplefeatures confirm us that an appropriate set of BLCwill be a better semantic discriminator than sensesor even sense-clusters.ReferencesE.
Agirre, I. Aldezabal, and E. Pociello.
2003.
A pi-lot study of english selectional preferences and theircross-lingual compatibility with basque.
In Procee-dings of the International Conference on Text Speechand Dialogue (TSD?2003), CeskBudojovice, CzechRepublic.J.
Atserias, L. Villarejo, G. Rigau, E. Agirre, J. Carroll,B.
Magnini, and P. Vossen.
2004.
The meaning mul-tilingual central repository.
In Proceedings of GlobalWordNet Conference (GWC?04), Brno, Czech Repu-blic.M.
Ciaramita and Y. Altun.
2006.
Broad-coveragesense disambiguation and information extraction witha supersense sequence tagger.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP?06), pages 594?602, Syd-ney, Australia.
ACL.M.
Ciaramita and M. Johnson.
2003.
Supersense taggingof unknown nouns in wordnet.
In Proceedings of theConference on Empirical methods in natural languageprocessing (EMNLP?03), pages 168?175.
ACL.J.
Curran.
2005.
Supersense tagging of unknown nounsusing semantic similarity.
In Proceedings of the 43rdAnnual Meeting on Association for ComputationalLinguistics (ACL?05), pages 26?33.
ACL.C.
Fellbaum, editor.
1998.
WordNet.
An Electronic Lexi-cal Database.
The MIT Press.M.
Hearst and H. Schu?tze.
1993.
Customizing a lexiconto better suit a computational task.
In Proceedingnsof the ACL SIGLEX Workshop on Lexical Acquisition,Stuttgart, Germany.Thorsten Joachims.
2002.
Learning to Classify TextUsing Support Vector Machines.
Kluwer AcademicPublishers.B.
Magnini and G. Cavaglia.
2000.
Integrating subjectfields codes into wordnet.
In Proceedings of the Se-cond International Conference on Language Resour-ces and Evaluation (LREC?00).R.
Mihalcea and D. Moldovan.
2001.
Automatic ge-neration of coarse grained wordnet.
In Proceding ofthe NAACL workshop on WordNet and Other LexicalResources: Applications, Extensions and Customiza-tions, Pittsburg, USA.I.
Niles and A. Pease.
2001.
Towards a standard up-per ontology.
In Proceedings of the 2nd InternationalConference on Formal Ontology in Information Sys-tems (FOIS-2001), pages 17?19.
Chris Welty and Ba-rry Smith, eds.W.
Peters, I. Peters, and P. Vossen.
1998.
Automaticsense clustering in eurowordnet.
In First Internatio-nal Conference on Language Resources and Evalua-tion (LREC?98), Granada, Spain.E.
Rosch.
1977.
Human categorisation.
Studies inCross-Cultural Psychology, I(1):1?49.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In Proceedings of NemLap-94, pages 44?49, Manchester, England.F.
Segond, A. Schiller, G. Greffenstette, and J. Chanod.1997.
An experiment in semantic tagging using hid-den markov model tagging.
In ACL Workshop on Au-tomatic Information Extraction and Building of Lexi-cal Semantic Resources for NLP Applications, pages78?81.
ACL, New Brunswick, New Jersey.L.
Villarejo, L. Ma`rquez, and G. Rigau.
2005.
Explo-ring the construction of semantic class classifiers forwsd.
In Proceedings of the 21th Annual Meeting ofSociedad Espaola para el Procesamiento del LenguajeNatural SEPLN?05, pages 195?202, Granada, Spain,September.
ISSN 1136-5948.P.
Vossen, L. Bloksma, H. Rodriguez, S. Climent, N. Cal-zolari, A. Roventini, F. Bertagna, A. Alonge, andW.
Peters.
1998.
The eurowordnet base concepts andtop ontology.
Technical report, Paris, France, France.160
