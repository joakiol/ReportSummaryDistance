Learning Rules for Chinese Prosodic Phrase Prediction?Zhao Sheng  ?Tao Jianhua   ?Cai LianhongDepartment of Computer Science and TechnologyTsinghua University, Beijing, 100084, China?szhao00@mails.tsinghua.edu.cn    {?jhtao, ?clh-dcs}@tsinghua.edu.cnAbstractThis paper describes a rule-learning approachtowards Chinese prosodic phrase prediction forTTS systems.
Firstly, we prepared a speechcorpus having about 3000 sentences andmanually labelled the sentences with two-levelprosodic structure.
Secondly, candidatefeatures related to prosodic phrasing and thecorresponding prosodic boundary labels areextracted from the corpus text to establish anexample database.
A series of comparativeexperiments is conducted to figure out themost effective features from the candidates.Lastly, two typical rule learning algorithms(C4.5 and TBL) are applied on the exampledatabase to induce prediction rules.
The paperalso suggests general evaluation parameters forprosodic phrase prediction.
With theseparameters, our methods are compared withRNN and bigram based statistical methods onthe same corpus.
The experiments show thatthe automatic rule-learning approach canachieve better prediction accuracy than thenon-rule based methods and yet retain theadvantage of the simplicity andunderstandability of rule systems.
Thus it isjustified as an effective alternative to prosodicphrase prediction.1 IntroductionProsodic phrase prediction or prosodicphrasing plays an important role in improvingthe naturalness and intelligence of TTSsystems.
Linguistic research shows that theutterance produced by human is structured in ahierarchy of prosodic units, includingphonological phrase, intonation phrase andutterance.
(Abney, 1995) But the output of textanalysis of TTS systems is often a structure ofsyntactic units, such as words or phrases,which are not equivalent to the prosodic ones.Therefore the object of prosodic phrasing is tomap the syntactic structure into its prosodiccounterpart.A lot of methods have been introduced topredict prosodic phrase in English text such asClassification and Regression Tree (Wang andHirschberg, 1992), Hidden Markov Model(Paul and Alan, 1998).
For Chinese prosodicphrasing, the traditional method is based onhandcrafted rules.
Recurrent Neural Network(Ying and Shi, 2001) as well as POS bigramand CART based methods (Yao and Min, 2001)is also experimented recently.
Due to thedifference in training corpus and evaluationmethods between researchers, these results aregenerally less comparable.In this paper, a rule-learning approach isproposed to predict prosodic phrase inunrestricted Chinese text.
Rule-based systemsare simple and easy to understand.
Buthandcrafted rules are usually difficult toconstruct, maintain and evaluate.
Thus twotypical rule-learning algorithms (C4.5induction and transformation-based learning)are employed to automatically induceprediction rules from examples instead ofhuman.
Generally speaking, automaticrule-learning has two obvious advantages overthe previous methods:1) Statistical methods like bigram or HMMusually need large training corpus toavoid sparse data problem whilerule-learning doesn?t have the restriction.In the case of prosodic phrase prediction,the corpus with prosodic labelling is oftenrelatively small.
Rule-learning is justsuitable for this task.2) CART, RNN or other neural networkmethods have good learning ability butthe learned knowledge is represented astrees or network weights, which are not somuch understandable as rules.Once rules are learned from examples, theycan be analyzed by human to check if theyagree with the common linguistic knowledge.We can add prediction rules converted fromour linguistic knowledge to the rule set, whichis especially useful when the training corpusdoesn?t cover wide enough phenomena ofprosodic phrasing.
Furthermore, we can try tointerpret and understand rules learned bymachine so as to enrich our linguisticknowledge.
Hence rule-learning also helps usmine knowledge from examples.Since features related to prosodic phrasingcome from various linguistic sources, severalcomparative experiments are conducted toselect the most effective features from thecandidates.
The paper also suggests generalevaluation parameters for prosodic phraseprediction.
With these parameters, our methodsare compared with RNN and bigram basedstatistical methods on the same corpus.
Theexperiments show that the automaticrule-learning approach can achieve betterprediction accuracy than the non-rule basedmethods and yet retain the advantage of thesimplicity and understandability of rulesystems.
The paper proceeds as follows.Section 2 introduces the rule-learningalgorithms we used.
Section 3 describesprosodic phrase prediction and its evaluationparameters.
Section 4 discusses the featureselection and rule-learning experiments indetail.
Section 5 reports the evaluation resultsof rule based and none-rule based methods.Section 6 presents the conclusion and the viewof future work.2 Rule Learning AlgorithmsResearch on machine learning hasconcentrated in the main on inducing rulesfrom unordered set of examples.
Andknowledge represented in a collection of rulesis understandable and effective way to realizesome kind of intelligence.
C4.5 (Quinlan, 1986)and transformation-based learning (Brill, 1995)are typical rule-learning algorithms that havebeen applied to various NLP tasks such aspart-of-speech tagging and named entityextraction etc.Both algorithms are supervised learning andcan be used to induce rules from examples.But they also have difference from each other.Firstly the C4.5 rule induction is a completelyautomatic process.
What we need to do is toextract appropriate features for our problem.As to transformation-based learning(henceforth TBL), transformation ruletemplates, which determine the effectivenessof the acquired rules, have to be designedmanually before learning.
Thus TBL can onlybe viewed as a semi-automatic method.Secondly the induction of C4.5 rules using adivide-and-conquer strategy is much fasterthan the greedy searching for TBL ones.
Inview of the above facts, C4.5 rules are inducedfrom examples first in our experiments.
Andthen the rules are used to guide the design ofrule templates for TBL.
See section 4.8 fordetail.3 Prosodic Phrase Prediction3.1 The MethodologyLinguistic research has suggested that Chineseutterance is also structured in a prosodichierarchy, in which there are mainly threelevels of prosodic units: prosodic word,prosodic phrase and intonation phrase (Li andLin, 2000)..
Figure 1 shows the prosodicstructure of a Chinese sentence.
In the treestructure, the non-leaf nodes are prosodic unitsand the leaves are syntactic words.
A prosodicphrase is composed of several prosodic words,each of which in turn consists of severalsyntactic words.
Since intonation phrase isusually indicated by punctuation marks, weonly need to consider the prediction ofprosodic word and phrase.UPP PP5?PW PW PW??
Z?X 6?PWJPW PW PWt?
Z ??
?W X J?Figure 1: Two-level prosodic structure tree (Ufor intonation phrase, PP for prosodic phrase,PW for prosodic word)Suppose we have a string of syntactic wordsi.e.nwww ,..., 21 , the boundary between twoneighbouring words is representedas >?< +1ii ww .
There are total three types ofboundaries labelled as B0 ( 1, +ii ww  are in thesame prosodic word), B1 (the words are in thesame prosodic phrase, but not the sameprosodic word), or B2 (the words are indifferent prosodic phrases) respectively.
Thusprosodic phrase prediction is to predict suchboundary labels, which can be viewed as aclassification task.
We believe these labels aredetermined by the contextual linguisticinformation around the boundary.
If we have aspeech corpus with prosodic labelling, featuresrelated to prosodic phrasing can be extracted ateach boundary and combined with thecorresponding boundary labels to establish anexample database.
Then rule-learningalgorithms are executed on the database toinduce rules for predicting boundary labels.3.2 Evaluation ParametersAs a classification task, prosodic phraseprediction should be evaluated withconsideration on all the classes.
The rulesinduced from examples are applied on a testcorpus to predict the label of each boundary.The predicted labels are compared with labelsgiven by human, which are thought to be true,to get a confusion matrix as follows:Predicted labels Truelabels  B0 B1 B2B0 C00 C01 C02B1 C10 C11 C12B2 C20 C21 C22Table 1: Confusion matrixCijs are the counts of boundaries whose truelabel are Bi but predicted as Bj.
From thesecounts, we can deduce the evaluationparameters for prosodic phrasing.
)2,1,0(/Re20== ?=iCCcjijiii(1))2,1,0(/Pr20== ?=iCCejjiiii(2))2,1,0)(Pr/(RePr*Re*2 =+= iececF iiiii  (3)?
?
?= ===2020201 /j iijiii CCAcc(4)???
?= == =+=20200021212 /)(j iijj iij CCCAcc(5)icRe  defines the recall rate of boundarylabel Bi.
iePr  defines the precision rate ofBi.
iF  is a combination of recall and precisionrate, suggested by (Rijsbergen, 1979).
1Acc  isthe overall accuracy of all the labels.
If wemerge B1 and B2 into one label, which can beviewed as   the prediction of prosodic wordboundary, 2Acc defines the overall accuracy ofthis case.4 Experiments4.1 The CorpusIn our experiments, the speech corpus of ourTTS system is used for training and testing.The corpus has 3167 sentences, which arerandomly selected from newspaper and readby a radiobroadcaster.
We manually labelledthe sentences with two-level prosodic structureby listening to the record speech.
For example,the sentence in Figure 1 is labelled as ?5?/ B1?
?/B0Z/B1?/B0X/B06?/B2J/B1t?/B0Z /B1 ?
?
/B0 ?
W /B0 X /B1 J ?
/B2?.Preliminary tests show that manually labellingcan achieve a high consistency rate amonghuman.
Therefore it is reasonable to make themanually labelled results as the target oflearning algorithms.The sentences of the corpus are alsoprocessed with a text analyzer, where Chineseword segmentation and part-of-speech taggingare accomplished in one step using a statisticallanguage model.
The segmentation andtagging yields a gross accuracy rate over 94%.The output of the text analyzer is directly usedas the training data of learning algorithmswithout correcting segmentation or taggingerrors because we want to train classifiers withnoisy data in the real situation.Here are some statistical figures about thecorpus.
There are 56446 Chinese characters inthe corpus, which constitute 37669 words.
Thenumber of prosodic word boundaries is 16194and that of prosodic phrase ones is only 7231.The average length of syntactic word, prosodicword, prosodic phrase and sentence are 1.5,2.4, 7.8 and 17.0 in character, respectively.4.2 Candidate FeaturesFeature selection is crucial to the classificationof prosodic boundary labels.
Linguisticinformation around the word boundary is themain source of features.
The features maycome from different levels including syllable,word, phrase, sentence level.
And the type offeatures may be phonetic, lexical, syntactic,semantic or pragmatic.
Which features havemost close relation with prosodic phrasing andhow to represent them are still open researchproblems.
In our approach, we decide to list allthe possible features first and figure out themost effective ones by experiments.
Thefeatures we currently consider are presented inthe following.4.2.1 Phonetic informationChinese is well known as a monosyllabic,tonal language.
And phonetic study showssound will change in continuous speechbecause of context or prosodic structure.Retroflex, neutral tone and tone sandhi areimportant phonetic phenomena that causesound variation.
(Li and Lin, 2000).
Thusphonetic information about phone and syllableis related to prosodic phasing.
There are toomany tonal syllables (about 1300) in Chineseto consider.
Instead, the initials and finals ofthe syllables (total about 60) near a wordboundary are taken into accounts, which arerepresented as SYIF in the following text.Similarly the tones of the syllables, denoted byTONE, are also included as phonetic features.4.2.2    Lexical informationWords in natural language have differentoccurrence frequency.
And words that havehigh occurrence frequency may be especiallyimportant to prosodic phrasing (e.g.
somefunctional words in Chinese,  X? `etc).
Therefore lexical word is treated as acandidate feature, represented as WORD.4.2.3 Syntactic informationSyntactic information has close relation withprosodic structure.
POS, which denotespart-of-speech of words, is a basic syntacticfeature much easier to obtain with automaticPOS taggers.
And it has been widely adoptedin previous researches.
Since POS tag setsvaries with taggers, we try to determine thebest one for predicting prosodic phrase byexperiments.4.2.4 Other informationFrom the statistical figures of the corpus, bothprosodic word and phrase have limitation inlength.
The length of syntactic word (WLEN),the length of the sentence in character (SLENC)and word (SLENW) are considered as lengthfeatures.
In HMM-based methods, the chain ofboundary labels in a sentence is supposed toconform to Markov assumption.
Andaccording to experience, it is less possible fortwoboundaries with label B2  to locate veryclose to each other.
Thus the label of previousboundaries (BTYPE) and the distances fromthem to current position are also possiblefeatures.4.3 Example DatabaseAll of the possible features are extracted fromthe corpus at each boundary to establish anexample database.
Table 2 shows parts of theexample entries of two word boundaries inFigure 1.
Each row is a type of feature.
Therow name has a format of feature name plus anumber.
The number indicates which word thefeature comes from.
And the range of thenumber is limited by a window size.
Forexample, POS_0 denotes part-of-speech of theword just before the word boundary, POS_-1denotes that of the second word previous to theboundary and POS_1 denotes that of the wordjust after the boundary.
The rest may bededuced by analogy.
BTYPE_0 is the label ofcurrent boundary and also the target to bepredicted.BoundariesFeatures<5???
?> <6?
?J>SYIF_0 an engSYIF_1 z bTONE_0 3 2TONE_1 4 4WORD_05?
6?WORD_1??
JPOS_0 vn vPOS_1 v cPOS_-1 w uWLEN_0 2 2WLEN_1 2 1BTYPE_0 B1 B2Table 2: Example database entries4.4 Feature Selection ExperimentsOnce the example database is established, wecan begin to induce rules from it with rulelearners.
If all the features were used in oneexperiment, the feature space would get toolarge to learn rules quickly.
Moreover we wantto eliminate less significant features from thedatabase.
A series of comparative experimentsis carried out to figure out the effectivefeatures.
C4.5 learner is used to perform thelearning task in the following experiments.4.4.1 Baseline experiment (No.1)Since POS features are widely used, a baselineexperiment is performed with only two POSfeatures that are POS_0 and POS_1.
The POStag set has total 30 tags from the tagger.4.4.2 POS window-size (No.2-9)The window size determines the number ofwords whose features are considered.
Supposethe window size is L+R, which means thefeatures of L words left to the boundary and Rwords right to it are used.
We designexperiments with the combination of differentvalue of L and R to find the best window ofPOS features.
The features in the window aredenoted by POS{-L+1, R} in a range form.4.4.3 POS set (No.10-11)Experiments are conducted on three POS sets,which are BSET, LSET and CSET.
BSET is thebasic POS set from the tagger.
LSET is anenlarged version of BSET, which includes themost frequent 100 words as independent tags.CSET is built with clustering technique.
EachPOS in the BSET is represented as a6-dimension vector, whose components are theprobabilities of the boundary labels after andbefore that POS.
Then these vectors areclustered into 10 groups.
The window sizeused is 1+1.4.4.4 Other experiments (No.12-17)WORDLEN and SLEN are added into thebaseline system to investigate the importanceof length features in No.12 and 13.
SYIF,TONE features of syllables around theboundary are considered in No.14.
Previousboundary labels (BTYPE_-1, BTYPE_-2) aretested in the experiments No.15 and 16.WORD features are used in No.17 to find ifthere exist some words that have specialprosodic effects.No.
Features POS tag set F0 F1 F2 Acc1 Acc21 POS{0,1} BSET 0.69 0.72 0.76 0.72 0.792 POS{0,0} BSET 0.57 0.53 0.14 0.50 0.643 POS{-1,0} BSET 0.55 0.59 0.37 0.54 0.684 POS{0,2} BSET 0.70 0.72 0.76 0.72 0.795 POS{-1,1} BSET 0.71 0.71 0.76 0.72 0.796 POS{-1,2} BSET 0.71 0.70 0.75 0.71 0.797 POS{-2,1} BSET 0.71 0.70 0.75 0.71 0.798 POS{-2,2} BSET 0.70 0.70 0.75 0.71 0.799 POS{-3,3} BSET 0.71 0.70 0.74 0.71 0.7910 POS{0,1} LSET 0.72 0.74 0.77 0.74 0.8111 POS{0,1} CSET 0.67 0.67 0.73 0.68 0.7512 POS{0,1},WLEN{0,1} BSET 0.81 0.77 0.76 0.79 0.8613 POS{0,1},WLEN{0,1},SLEN BSET 0.82 0.76 0.74 0.78 0.8714 POS{0,1},TONE,SYIF BSET 0.71 0.72 0.75 0.72 0.7915 POS{0,1},BTYPE_-1 BSET 0.75 0.74 0.76 0.75 0.8216 POS{0,1},BTYPE_{-1,-2} BSET 0.75 0.73 0.76 0.74 0.8217 POS{0,1},WORD{0,1} BSET 0.64 0.72 0.72 0.70 0.78Table 3: Results of feature selection (F0, F1, F2, Acc1, Acc2 are defined in section 3.2)4.5 Feature selection resultsThe results of these experiments are listed inTable 3.
From the evaluation figures in thetable, we can draw the following conclusionson the effect of the features on prosodic phraseprediction:1) Part-of-speech is a basic and usefulfeature.
A window size of 2+1 is alreadyenough.
Larger window size will greatlylengthen the time of training but make nosignificant improvement on the accuracyrate.2) The largest POS set LSET performs betterthan smaller ones like BSET and CSET.That?s because small POS sets lead tosmall feature space, which may be not bigenough to distinguish the trainingexamples.3) Length features are beneficial to prosodicphrase prediction.4) Phonetic features are less useful than whatwe think before.5) Former boundary information is alsouseful.
When training, the former andlatter boundary labels are both known, butwhen testing, exact former boundarylabels do not exist.
We can use theboundary labels that are already predictedto help make decision on current label.Although the error prediction of formerlabels may lead to error of currentprediction, the result shows the accuracyrate is improved.6) WORD feature is not appropriate to use,since the using of it greatly enlarges thefeature space and needs more trainingexamples.4.6 C4.5 ExperimentsAccording to the feature selection results, weknow some features are effective to prosodicphrase prediction but some are not.
And thesolely using of effective features doesn?t resultin a high enough accuracy rate.
In order toimprove the prediction accuracy, we combinethe effective features such as WLEN{-1, 1},BTYPE{-1}, SLEN and POS{-1,1} in LSET tagset together to induce C4.5 rules.4.7 Examples of C4.5 RulesAs mentioned above, rule systems have theadvantage of simplicity and understandability.We examine the rules learned by C4.5 and findthey certainly reflect the usage of prosodicstructure in some sense.
Here are some rulesfollowed by example sentences with thecurrent boundary labels in bold:1) if POS_1 == Z then BTYPE_0 = B0?/B0?/B1?
?/B0Z/B1|=?/B22) if POS_1 == X then BTYPE_0 = B0:?/B0X/B1?W/B1?
?/B23) if POS_0 == ?
then BTYPE_0 = B0n$/B1?/B0S/B24) if POS_0 == v && POS_1 == b thenBTYPE_0 = B0?/B1?/B0b/B11998H/B25) if POS_1 == c && WLEN_0 > 2 thenBTYPE_0 = B2?
?/B2J/B1u?/B1?7/B2M/ B1J/B0?/B1?/B09/B26) if POS_-1 == n && POS_0 ==  &&BTYPE_-1 == B0 then BTYPE_0 = B2?/B0/B2??/B0X/B0?
?/B2Rule 1, 2 and 3 shows the special prosodiceffect of functional words such as ?Z?, ?X?,??
?, which tends to adhere to prosodic wordsin the sentences.
Rule 4 exemplifies that thesyntactic structure ?Verb+b?
usually acts as aprosodic word.
Rule 5 concerns theconjunction word, the boundary before whichwould be B2 (prosodic phrase boundary) if theprevious word had a length above 2.
The B2boundary is thought to accentuate the wordbefore the conjunction.
Rule 6 deals with thestructure ?Noun+?.
We can see that theserules coincide with the experience of prosodicphrasing by human.4.8 TBL ExperimentsA general TBL toolkit (Grace and Radu, 2001)is used in our TBL experiments.
The analysison C4.5 rules casts lights on the design of thetransformation rule templates of TBL.
Sincethe same features as C4.5 learning are used inthe rule templates, linguistic knowledge, whichhas been embodied by C4.5 rules, should alsobe captured by transformation rule templates.Suppose a C4.5 rule, ?if (POS_0 == n &&POS_1 == u) then BTYPE_0 = B0?, has a highprediction accuracy, it is reasonable to makethis rule as an instantiation of TBL ruletemplates.
Table 4 lists some of the ruletemplates used in TBL experiments.POS_0 POS_1 => BTYPE_0POS_-1 POS_0 POS_1 => BTYPE_0BTYPE _0 POS_0 POS_1 => BTYPE_0BTYPE _0 POS_-1 POS_0 POS_1 => BTYPE_0POS_0 POS_1 WLEN_0 WLEN_1=> BTYPE_0WORD_0 POS_0 POS_1 => BTYPE_0WORD_0 POS_-1 POS_0 POS_1 => BTYPE_0BTYPE_0 WORD_0 POS_0 POS_1=>BTYPE_0......Table 4: Rule templates for TBLThe left part of a rule template is a list offeatures, and the right is the target, BTYPE_0.For example, ?POS_0 POS_1 => BTYPE_0?,which is a short form of ?if (POS_0 == X &&POS_1 == Y) then BTYPE_0 = Z?, means ifcurrent POS were X and the next POS were Y,the boundary label would be Z. X, Y, Z aretemplate variables.
Let X=n Y=u Z=B0, thetemplate is instantiated into the C4.5 ruleabove.Due to the mechanism of TBL rules, thereexist rule templates like ?BTYPE_0 POS_0POS_1 => BTYPE_0?, in which the formerBTYPE_0 is the label before applying the ruleand the latter is after applying it.
That?sactually what transformation means.
Whentraining, the initial boundary labels are all setto B1.
At each step, the algorithm tries all thepossible values for template variables to findan instantiated rule that can achieve the bestscore.
When testing, the initial boundary labelsare set the same way, and then transformationrules are applied one by one.5 Evaluation ResultsTo evaluate the generalization ability of theacquired rules, 5-fold cross validation tests areexecuted on the corpus for both C4.5 and TBL.We reimplemented the RNN algorithm andPOS bigram statistical model to predictprosodic word boundary on the same corpusfor comparison.
Since our corpus is not largeenough for HMM training and the CARTmethod is also decision-tree based as C4.5, wedidn?t realize them in our experiments.
Theevaluation results are shown in Table 5.Both the C4.5 rules and the TBL rulesoutperform the RNN algorithm and POSbigram method because the overall accuracyrates Acc2 of the rule based methods are higher.TBL achieves comparable accuracy with C4.5induction, which demonstrates that the designof transformation rule templates is successful.Comparing Acc1 and Acc2 in Table 5, wediscover that prosodic word boundaries can bemore accurately predicted than prosodic phraseones.
It can be explained as follows.
Prosodicword is the smallest prosodic unit in theprosodic hierarchy, which has more relationwith the word level features such as POS,word length etc.
Prosodic phrase is a largerprosodic unit less related to word level features,thus it cannot be predicted accurately usingthese features.Tests Reco Pre0 F0 Rec1 Pre1 F1 Rec2 Pre2 F2 Acc1 Acc2C4.5 0.914 0.837 0.874 0.814 0.822 0.818 0.712 0.829 0.766 0.829 0.904TBL 0.849 0.884 0.866 0.782 0.848 0.814 0.851 0.613 0.713 0.818 0.895bigram 0.653 0.746 0.696 0.874 0.816 0.844 N/A N/A N/A N/A 0.793RNN 0.764 0.803 0.783 0.883 0.857 0.870 N/A N/A N/A N/A 0.837Table 5: Evaluation results6 Conclusion and Future WorkIn this paper, we describe an effectiveapproach to generate rules for Chineseprosodic phrase prediction.
The main idea is toextract appropriate features from the linguisticinformation and to apply rule-learningalgorithms to automatically induce rules forpredicting prosodic boundary labels.
C4.5 andTBL algorithms are experimented in ourresearch.
In order to find the most effectivefeatures, a series of feature selectionexperiments is conducted.
The acquired rulesachieve a best accuracy rate above 90% on testdata and outperform the RNN and bigrambased methods, which justifies rule-learning asan effective alternative to prosodic phraseprediction.But the problem of prosodic phraseprediction is far from solved.
The bestaccuracy rate got by machine is still muchlower than that by human.
In our future work,the study on this problem will go more deepand wide.
Other machine learning methodswill be experimented and compared with C4.5and TBL.
Features from deep syntactic,semantic or discourse information will be paidmore attention to (Julia and Owen, 2001).
Andthe speech corpus will be enlarged to covermore types of text and speaking styles.AcknowledgementsOur work is sponsored by 863 Hi-TechResearch and Development Program of China(No: 2001AA114072).
We also would like tothank the anonymous reviewers of the FirstSigHAN Workshop for their comments.ReferencesAbney Steven.
(1995) Chunks anddependencies: bringing processing evidenceto bear on syntax.
ComputationalLinguistics and Foundations of LinguisticTheory, CSLI.Eric Brill.
(1995) Transformation-Based Error?Driven Learning and Natural LanguageProcessing: A Case Study in Part-of-SpeechTagging.
Computational Linguistics21(4):543- 565.C.J.
van Rijsbergen.
(1979) InformationRetrieval.
Butterworths, London.Grace Ngai and Radu Florian.
(2001)Transformation-Based Learning in the FastLane.
Proceedings of the 39th ACLConference.Julia Hirschberg, Owen Rambow.
(2001)Learning Prosodic Features using a TreeRepresentation.
Eruospeech2001.Li Aijun, Lin Maocan.
(2000)  Speech corpusof Chinese discourse and the phoneticresearch.
ICSLP2000.Michelle Wang and Julia Hirschberg.
(1992)Automatic classication of intonationalphrase boundaries.
Computer Speech andLanguage 6:175?196.Paul Taylor and Alan W Black.
(1998)Assigning phrase breaks frompart-of-speech sequences.
Computer Speechand Language v12.Quinlan,J.R.
(1986) Induction of decision trees.Machine Learning, 1(1):81-106.Yao Qian, Min Chu, Hu Peng.
(2001)Segmenting unrestricted chinese text intoprosodic words instead of lexical words.ICASSP2001.Zhiwei Ying and Xiaohua Shi.
(2001) AnRNN-based algorithm to detect prosodicphrase for Chinese TTS.
ICASSP2001.
