Finite-state Approximation of Constraint-based Grammars usingLeft-corner Grammar TransformsMark  Johnson*Cognit ive and Linguist ic Sciences, Box 1978Brown Univers i tyMark_.Johnson@Brown.eduAbst ractThis paper describes how to construct a finite-statemachine (FSM) approximating a 'unification-based'grammar using a left-corner grammar transform.The approximation is presented as a series of gram-mar transforms, and is exact for left-linear and right-linear CFGs, and for trees up to a user-specifieddepth of center-embedding.1 In t roduct ionThis paper describes a method for approximat-ing grammars with finite-state machines.
Unlikethe method derived from the LR(k) parsing algo-rithm described in Pereira and Wright (1991), thesemethods use grammar transformations based on theleft-corner grammar transform (Rosenkrantz andLewis II, 1970; Aho and Ullman, 1972).
One ad-vantage of the left corner methods is that they gen-eralize straightforwardly to complex feature "unifi-cation based" grammars, unlike the LR(k) based ap-proach.
For example, the implementation describedhere translates a DCG version of the example gram-mar given by Pereira nd Wright (1991) directly intoa FSM without constructing an approximating CFG.Left-corner based techniques are natural for thiskind of application because (with the simple opti-mization described below) they can parse pure left-branching or pure right-branching structures witha stack depth of one (two if terminals are pushedand popped from the stack).
Higher stack depthoccurs with center-embedded structures, which hu-mans find difficult to comprehend.
This suggeststhat we may get a finite-state approximation to hu-man performance by simply imposing a stack depthbound.
We provide a simple tree-geometric descrip-tion of the configurations that cause an increase ina left corner parser's tack depth below.The rest of this paper is structured as follows.The remainder of this section outlines the "gram-mar transform" approach, summarizes the top-down* Th is  research was supported by NSF grant SBR526978.
Ibegan this research while I was on sabbatical  at the XeroxResearch Centre in Grenoble, France.
I would like to thankthem and my colleages at Brown for their support .parsing algorithm and discusses how finite stateapproximations of top-down parsers can be con-structed.
The fact that this approximation is not ex-act for left linear grammars (which define finite-statelanguages) motivates a finite-state approximationbased on the left-corner parsing algorithm (whichis presented as a grammar transform in section 2).In its standard form the approximation based on theleft-corner parsing algorithm suffers from the com-plementary problem to the top-down approximation:it is not exact for right-linear grammars, but the"optimized" variants presented in section 3 over-come this deficiency, resulting in finite-state CFGapproximations which are exact for left-linear andright-linear grammars.
Section 4 discusses how thesetechniques can be combined in an implementation.1.1 Parsing strategies as grammart ransformat ionsThe parsing algorithms discussed here are presentedas grammar trans\]ormations, i.e., functions T thatmap a context-free grammar G into another context-free grammar T(G).
The transforms have the prop-erty that a top-down parse using the transformedgrammar is isomorphic to some other kind of parseusing the original grammar.
Thus grammar trans-forms provide a simple, compact way of describingvarious parsing algorithms, as a top-down parser us-ing T(G) behaves identically to the kind of parserwe want to study using G.1.2 Mappings from trees to treesThe transformations presented here can also be un-derstood as isomorphisms from the set of parse treesof the source grammar G to parse trees of the trans-formed grammar which preserve terminal strings.Thus it is convenient to explain the transforms interms of their effect on parse trees.
We call a parsetree with respect to the source grammar G an anal-ysis tree, in order to distinguish it from parse treeswith respect o some transform of G. The analy-sis tree t in Figure 1 will be used as an examplethroughout this paper.619$z .c , ( t )  =DET S-DETthe N S-NPs dog ve s-s t=NP VP V VP-VDET N V ADV ran ADV VP-VPI I I I Ithe dog ran fast fast$ =DET S-DET /:C4(t) : $r /Nthe N S-NP DET S-DETJ J Idog vP the N S-NP/N  i /NV VP-V dog v vP-vI I I Iran ADV ran ADVI Ilast lastFigure 1: The analysis tree t used as a running example below, and its left-corner transforms ~Ci(t).
Notethat the phonological forms are treated here as annotations on the nodes drawn above them, rather thanindependent nodes.
That is, DEW (annotated with the) is a terminal node.1.3 Top-down parsers  and parse  t reesThe "predictive" or "top-down" recognition algo-rithm is one of the simplest CFG recognition al-gorithms.
Given a CFG G = (N, T, P, S), a (top-down) stack state is a sequence of terminals andnonterminals.
Let Q = (N U T)* be the set of stackstates for G. The start state qo E Q is the sequenceS, and the final state ql E Q is the empty sequence .The state transition function 6 : Q x (TU {e}) ~ 2 Qmaps a state and a terminal or epsilon into a set ofstates.
It is the smallest function 5 that satisfies thefollowing conditions:-~ ~ ~(a% a) : a ~ T,'~ ~ (N u T)*.f17 E ~(AT, e) : A E N, 3' E (N W T)*, A --~ fl ?
P.A string w is accepted by the top-down recognitionalgorithm if q/ E 5*(q0,w), where 5* is the reflex-ive transitive closure of 6 with respect to epsilonmoves.
Extending this top-down parsing algorithmto a 'unification-based' grammar is straight-forward,and described in many textbooks, such as Pereiraand Shieber (1987).It is easy to read off the stack states of a top-down parser constructing a parse tree from the treeitself.
For any node X in the tree, the stack contentsof a top-down parser just before the constructionof X consists of (the label of) X followed by thesequence of labels on the right siblings of the nodesencountered on the path from X back to the root.It is easy to check that a top-down parser equires astack of depth 3 to construct he tree t depicted inFigure 1.1.4 F in i te -s ta te  approx imat ionsWe obtain a finite-state approximation to a top-down parser by restricting attention to only a finitenumber of possible stack states.
The system imple-mented here imposes a stack depth restriction, i.e.,the transition function is modified so that there areno transitions to any stack state whose size is largerthan some user-specified limit.
1 This restriction en-sures that there is only a finite number of possiblestack states, and hence that the top down parseris an finite-state machine.
The resulting finite-statemachine accepts a subset of the language generatedby the original grammar.The situation becomes more complicated when wemove to 'unification-based' grammars, since theremay be an unbounded number of different categoriesappearing in the accessible stack states.
In the sys-tem implemented here we used restriction (Shieber,1985) on the stack states to restrict attention to afinite number of distinct stack states for any givenstack depth.
Since the restriction operation mapsa stack state to a more general one, it produces afinite-state approximation which accepts a supersetof the language generated by the original unificationgrammar.
Thus for general constraint-based gram-mars the language accepted by our finite-state ap-proximation is not guaranteed to be either a supersetor a subset of the language generated by the inputgrammar.2 The  le f t -corner  t rans formWhile conceptually simple, the top-down parsing al-gorithm presented in the last section suffers froma number of drawbacks for a finite-state approxi-mation.
For example, the number of distinct ac-cessible stack states is unbounded if the grammaris left-recursive, yet left-linear grammars alwaysgenerate regular languages.
This section presents1With the optimized left-corner transforms described be-low we obtain acceptable approximations with a stack sizelimit of 5 or less.
In many useful cases, including the examplegrammar provided by Pereira and Wright (1991), this stackbound is never reached and the system reports that the FSAit returns is exact.620the standard left-corner grammar transformation(Rosenkrantz and Lewis II, 1970; Aho and Ull-man, 1972); these references should be consulted forproofs of correctness.
This transform serves as thebasis for the further transforms described in the nextsection; these transforms have the property that theoutput grammar induces a finite number of distinctaccessible stack states if their input is a left-recursiveleft-linear grammar.Given an input grammar G with nonterminalsN and terminals T, these transforms ?Ci producegrammars with an enlarged set of nonterminals N t =N O (N x (N O T)).
The new "pair" categories inN x (N U T) are written A-X ,  where A is a non-terminal of G and X is either a terminal or non-terminal of G. It turns out that if A =~* X7 then GA-X  ~*~cI(G) 7, i.e., a non-terminal A-X  in thetransformed grammar derives the difference betweenA and X in the original grammar, and the notationis meant to be suggestive of this.The left-corner trans/orm of a CFG G =(N, T, P, S) is a grammar/2C1 (G) = (N', T, P1, S),where P1 contains all productions of the form (1.a-1.c).
This paper assumes that N n T = 0, as isstandard.
To save space we assume that P does notcontain any epsilon productions (but it is straight-forward to deal with them).A --4 a A-a  : A e N, a e T. (1.a)A-X  --~ fl A -B  : A e N, B -+ X fl e P. (1.b)A-A  ~ e : A e N. (1.c)Informally, the productions (1.a) start the left-corner recognition of A by recognizing a terminala as a possible left-corner of A.
The actual left-corner recognition is performed by the productions(1.b), which extend the left-corner from X to itsparent B by recognizing fl; these productions areused repeatedly to construct increasingly larger left-corners.
Finally, the productions (1.c) terminate therecognition of A when this left-corner constructionprocess has constructed an A.The left-corner transform preserves the numberof parses of a string, so it defines an isomorphismfrom analysis trees (i.e., parse trees with respect oG) to parse trees with respect o ?gl  (G).
If t is aparse tree with respect o G then (abusing notation)?Cl(t) is the corresponding parse tree with respectto ?CI(G).
Figure 1 shows the effect of this map-ping on a simple tree.
The transformed tree is con-siderably more complex: it has double the numberof nodes of the original tree.
In a top-down parseof the tree ?Cl(t) in Figure 1 the maximum stackdepth is 3, which occurs at the recognition of theterminals ran and/ast.2.1 F i l te r ing  useless categoriesIn general the grammar produced by the transform?
?1(G) contains a large number of useless nonter-minals, i.e., non-terminals which can never appearin any complete derivation, even if the grammar G isfully pruned (i.e., contains no useless productions).While ?C1(G) can be pruned using standard algo-rithms, given the observation about the relationshipbetween the pair non-terminals in ?
:C1 (G) and non-terminals in G, it is clear that certain productionscan be discarded immediately as useless.
Define thelef-eorner elation ?
C (N U T) x N as follows:X ~A iff 3ft.
A ~ Xf l  E P,Let 4" be the reflexive and transitive closure of 4.It is easy to show that a category A-X  is uselessin ?CI(G) (i.e., derives no sequence of terminals)unless X 4" A.
Thus we can restrict he productionsin (1.a-l.c) without affecting the language (strongly)generated to those that only contain pair categoriesA-X  where X 4" A.2.2 Unification grammarsOne of the main advantages of left-corner parsingalgorithms over LR(k) based parsing algorithms isthat they extend straight-forwardly to complex fea-ture based "unification" grammars.
The transfor-mation ?C1 itself can be encoded in several lines ofProlog (Matsumoto et al, 1983; Pereira and Shieber,1987).
This contrasts with the LR(k) methods.
InLR(k) parsing a single LR state may correspondto several items or dotted rules, so it is not clearhow the feature "unification" constraints hould beassociated with transitions from LR state to LRstate (see Nakazawa (1995) for one proposal).
Incontrast, extending the techniques described hereto complex feature based "unification" grammar isstraight-forward.The main complication is the filter on useless non-terminals and productions just discussed.
General-izing the left-corner closure filter on pair categoriesto complex feature "unification" grammars in an ef-ficient way is complicated, and is the primary diffi-culty in using left-corner methods with complex fea-ture based grammars, van Noord (1997) providesa detailed discussion of methods for using such a"left-corner filter" in unification-grammar parsing,and the methods he discusses are used in the imple-mentation described below.3 Extended le f t -corner  t rans formsThis section presents ome simple extensions to thebasic left-corner transform presented above.
The'tail-recursion' optimization permits bounded-stackparsing of both left and right linear constructions.Further manipulation of this transform puts it into aform in which we can identify precisely the tree con-figurations in the original grammar which cause thestack size of a left-corner parser to increase.
These621observations motivate the special binarization meth-ods described in the next section, which minimizestack depth in grammars that contain productionsof length no greater than two.3.1 A tail-recursion optimizationIf G is a left-linear grammar, a top-down parser us-ing ?.C1 (G) can recognize any string generated by Gwith a constant-bounded stack size.
However, thecorresponding operation with right-linear grammarsrequires a stack of size proportional to the lengthof the string, since the stack fills with paired cate-gories A-A  for each non-left-corner nonterminal inthe analysis tree.The 'tail recursion' or 'composition' optimiza-tion (Abney and Johnson, 1991; Resnik, 1992) per-mits right-branching structures to be parsed withbounded stack depth.
It is the result of epsilon re-moval applied to the output of ?C1, and can be de-scribed in terms of resolution or partial evaluationof the transformed grammar with respect o pro-ductions (1.c).
In effect, the schema (1.b) is splitinto two cases, depending on whether or not therightmost nonterminal A-B  is expanded by the ep-silon rules produced by schema (1.c).
This expansionyields a grammar L:C2 (G) = (N', T, P2, S), where P2contains all productions of the form (2.a-2.c).
(Inthese schemata A,B E N; a E T; X E N U T andfl E (NOT)* ) .A ~ a A-a (2.a)A-X  -+ ~ A-B  : B ~ X /3  E P. (2.b)A-X  --+/3 : A --+ X /3  E P. (2.c)Figure 1 shows the effect of the transform L:C2 onthe example tree.
The maximum stack depth re-quired for this tree is 2.
When this 'tail recursion'optimization is applied, pair categories in the trans-formed grammar encode proper left-corner relation-ships between odes in the analysis tree.
This letsus strengthen the 'useless category' filter describedabove as follows.
Let ,~+ be the transitive closure ofthe left-corner elation ~ defined above.
It is easyto show that a category A-X  is useless in L:C2(G)(i.e., derives no sequence of terminals) unless X,~ + A.Thus we can restrict the productions in (2.a-2.b)without affecting the language (strongly) generatedto just those that only contain pair categories A-Xwhere X 4 + A.3.2 The special case of b inary productionsWe can get a better idea of the properties of transfor-mation L:C2 if we investigate the special case wherethe productions of G are unary or binary.
In thissituation, transformation ?C2(G) can be more ex-plicitly written as /:C3(G) = (N', T, P3, S), whereP3 contains all instances of the production schemata(3.a-3.e).
(In these schemata, a E T; A, B E N andX,  Y E NoT) ./ ~  .
:CaA-X  ~ a C -a  A -B  (4.0Figure 2: The highly distinctive "zig-zag" or "light-ning bolt" configuration of nodes in the analysis treecharacteristic of the use of production schema (4.
0in transform ?C4.
This is the only configurationwhich causes an increase in stack depth in a top-down parser using a grammar transformed with L:C4.A --+ a A-a.
(3.a)A-X  --~ A-B  : B ~ X E P. (3.b)A-X  ~ ~ : A --+ X ~ P. (3.c)A-X  -~ Y A -B  : B --+ X Y E P. (3.d)A-X  --+ Y : A --~ X Y E P. (3.e)Productions (3.b-3.c) and (3.d-3.e) correspond tounary and binary productions respectively in theoriginal grammar.
Now, note that nonterminalsfrom N only appear in the right hand sides of pro-ductions of type (3.d) and (3.e).
Moreover, any suchnonterminals must be immediately expanded by aproduction of type (3.a).
Thus these non-terminalsare eliminable by resolving them with (3.a); theonly remaining nonterminal is the start symbol S.This expansion yields a new transform ?
:C4, whereEC4(G) = ({S} U (N ?
(NUT) ) ,T ,  P4,S) .
P4, de-fined in (4.a-4.g), still contains productions of type(3.a), but these only expand the start symbol, as alloccurences of nonterminals in N have been resolvedaway.
(In these schemata E T; A, B, C, D E Nand X E NUT) .S --+ a S-a .
(4.a)A-X  --~ A-B  : B --~ X E P. (4.b)A-X  ~ e : A -~ X E P. (4.c)A-X  --+ a A -B  : B -~ X a E P. (4.d)A-X  -~ a : A -~ X a E P. (4.e)A-X  -~ a C -a  A -B  : B -~ X C E P. (4.f)A-X  --+ a C -a  : A ~ X C E P. (4.g)In the production schemata defining/2C4, (4.a-4.c)are copied directly from (3.a-3.c) respectively.
Theschemata (4.d-4.e) are obtained by instantiating Yin (3.d-3.e) to a terminal a E T, while the other twoschemata (4.f-4.g) are obtained by instantiating Y in(3.d-3.e) with the right hand sides of (3.a).
Figure 1shows the result of applying the transformation ?1C4to the example analysis tree t.The transform also simplifies the specification offinite-state machine approximations.
Because allterminals are introduced as the left-most symbols in622their productions, there is no need for terminal sym-bols to appear on the parser's tack, saving an ep-silon transition associated with a stack push and animmediately following stack pop with respect to thestandard left-corner algorithm.
Productions (4.a)and (4.d-4.g) can be understood as transitions overa terminal a that replace the top stack element witha sequence of other elements, while the other produc-tions can be interpreted as epsilon transitions thatmanipulate the stack contents accordingly.Note that the right hand sides of all of theseproductions except for schema (4.f) are right-linear.Thus instances of this schema re the only produc-tions that can increase the stack size in a top-downparse with EC4(G), and the stack depth requiredto parse an analysis tree is the maximum numberof "zig-zag" patterns in the path in the analysistree from any terminal node to the root.
Figure 2sketches the configuration of nodes in the analysistrees in which instances of schemata (4.f) would beused in a parse using ?C4(G).
This highly distinc-tive "zig-zag" or "lightning bolt" pattern does notoccur at all in the example tree t in Figure 1, so themaximum required stack depth is 2.
(Recall that ina traditional top-down parser terminals are pushedonto the stack and popped later, so initializationproductions (4.a) cause two symbols to be pushedonto the stack).
It follows that this finite state ap-proximation is exact for left-linear and right-linearCFGs.
Indeed, analysis trees that consist simply of aleft-branching subtree followed by a right-branchingsubtree, such as the example tree t, are transformedinto strictly right-branching trees by/:C4.4 Imp lementat ionThis section provides further details of the finite-state approximator implemented in this research.The approximator is written in Sicstus Prolog.
Ittakes a user-specifier Definite Clause Grammar G(without Prolog annotations) as input, which it bi-narizes and then applies transform/:C4 to.The implementation annotates each transitionwith the production it corresponds to (representedas a pair of a /2C4 schema number and a produc-tion number from G), so the finite-state approxima-tion actually defines a transducer which transducesa lexical input to a sequence of productions whichspecify a parse of that input with respect to/:C4(G).A following program inverts the tree transform EC4,returning a corresponding parse tree with respectto G. This parse tree can be checked by perform-ing complete unifications with respect o the orig-inal grammar productions if so desired.
Thus thefinite-state approximation provides an efficient wayof determining if an analysis of a given input stringwith respect o a unification grammar G exists, andif so, it can be used to suggest such analyses.5 Conc lus ionThis paper surveyed the issues arising in the con-struction of finite-state approximations of left-cornerparsers.
The different kinds of parsers were pre-sented as grammar transforms, which let us abstractaway from the algorithmic details of parsing algo-rithms themselves.
It derived the various forms ofthe left-corner parsing algorithms in terms of gram-mar transformations from the original left-cornergrammar transform.ReferencesStephen Abney and Mark Johnson.
1991.
Mem-ory requirements and local ambiguities of parsingstrategies.
Journal of Psycholinguistic Research,20(3):233-250.Alfred V. Aho and Jeffery D. Ullman.
1972.
TheTheory of Parsing, Translation and Compiling;Volume 1: Parsing.
Prentice-Hall, EnglewoodCliffs, New Jersey.Yuji Matsumoto, Hozumi Tanaka, Hideki Hirakawa,Hideo Miyoshi, and Hideki Yasukawa.
1983.BUP: A bottom-up arser embedded in Prolog.New Generation Computing, 1(2):145-158.Tsuneko Nakazawa.
1995.
Construction ofLR pars-ing tables for grammars using feature-based syn-tactic categories.
In Jennifer Cole, Georgia M.Green, and Jerry L. Morgan, editors, Linguis-tics and Computation, umber 52 in CSLI LectureNotes Series, pages 199-219, Stanford, California.CSLI Publications.Fernando C.N.
Pereira and Stuart M. Shieber.
1987.Prolog and Natural Language Analysis.
Num-ber 10 in CSLI Lecture Notes Series.
Chicago Uni-versity Press, Chicago.Fernando C. N. Pereira and Rebecca N. Wright.1991.
Finite state approximation f phrase struc-ture grammars.
In The Proceedings of the 29thAnnual Meeting of the Association for Computa-tional Linguistics, pages 246-255.Philip Resnik.
1992.
Left-corner parsing and psy-chological plausibility.
In The Proceedings of thefifteenth International Conference on Computa-tional Linguistics, COLING-92, volume 1, pages191-197.Stanley J. Rosenkrantz and Philip M. Lewis II.1970.
Deterministic left corner parser.
In IEEEConference Record of the 11th Annual Symposiumon Switching and Automata, pages 139-152.Stuart M. Shieber.
1985.
Using Restriction to ex-tend parsing algorithms for unification-based for-malisms.
In Proceedings of the 23rd Annual Meet-ing of the Association for Computational Linguis-tics, pages 145-152, Chicago.Gertjan van Noord.
1997.
An efficient implemen-tation of the head-corner parser.
ComputationalLinguistics, 23(3):425-456.623
