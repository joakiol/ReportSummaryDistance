Carsim: A System to Visualize Written Road Accident Reports as Animated3D ScenesRichard Johansson David Williams Anders Berglund Pierre NuguesLUCAS, Department of Computer Science, Lund UniversityBox 118SE-221 00 Lund, Sweden{richard, pierre}@cs.lth.se, {d98dw, d98ab}@efd.lth.seAbstractThis paper describes a system to create animated3D scenes of car accidents from reports written inSwedish.
The system has been developed usingnews reports of varying size and complexity.
Thetext-to-scene conversion process consists of twostages.
An information extraction module createsa structured representation of the accident and a vi-sual simulator generates and animates the scene.We first describe the overall structure of the text-to-scene conversion and the structure of the repre-sentation.
We then explain the information extrac-tion and visualization modules.
We show snapshotsof the car animation output and we conclude withthe results we obtained.1 Text-to-Scene ConversionAs noted by Michel Denis, language and images aretwo different representation modes whose cooper-ation is needed in many forms of cognitive opera-tions.
The description of physical events, mathe-matical theorems, or structures of any kind usinglanguage is sometimes difficult to understand.
Im-ages and graphics can then help understand ideas orsituations and realize their complexity.
They havean indisputable capacity to represent and to commu-nicate knowledge and are an effective means to rep-resent and explain things, see (Kosslyn, 1983; Tufte,1997; Denis, 1991).Narratives of a car accidents, for instance, oftenmake use of space descriptions, movements, anddirections that are sometimes difficult to grasp formost readers.
We believe that forming consistentmental images are necessary to understand themproperly.
However, some people have difficulties inimagining situations and may need visual aids pre-designed by professional analysts.In this paper, we will describe Carsim, a text-to-scene converter that automates the generation of im-ages from texts.2 Related WorkThe conversion of natural language texts into graph-ics has been investigated in a few projects.
NALIG(Adorni et al, 1984; Manzo et al, 1986) is an earlyexample of them that was aimed at recreating static2D scenes.
One of its major goals was to study rela-tionships between space and prepositions.
NALIGconsidered simple phrases in Italian of the type sub-ject, preposition, object that in spite of their simplic-ity can have ambiguous interpretations.
From whatis described in the papers, NALIG has not been ex-tended to process sentences and even less to texts.WordsEye (Coyne and Sproat, 2001) is an im-pressive system that recreates 3D animated scenesfrom short descriptions.
The number of 3D objectsWordsEye uses ?
12,000 ?
gives an idea of its am-bition.
WordsEye integrates resources such as theCollins?
dependency parser and the WordNet lexicaldatabase.
The narratives cited as examples resembleimaginary fairy tales and WordsEye does not seemto address real world stories.CogViSys is a last example that started with theidea of generating texts from a sequence of videoimages.
The authors found that it could also beuseful to reverse the process and generate syntheticvideo sequences from texts.
The logic engine be-hind the text-to-scene converter (Arens et al, 2002)is based on the Discourse Representation Theory.The system is limited to the visualization of singlevehicle maneuvers at an intersection as the one de-scribed in this two-sentence narrative: A car camefrom Kriegstrasse.
It turned left at the intersection.The authors give no further details on the text cor-pus and no precise description of the results.3 CarsimCarsim (Egges et al, 2001; Dupuy et al, 2001) isa program that analyzes texts describing car acci-dents and visualizes them in a 3D environment.
Ithas been developed using real-world texts.The Carsim architecture is divided into two partsthat communicate using a formal representation ofInput TextLinguisticComponentFormalDescriptionVisualizerComponentOutputAnimationFigure 1: The Carsim architecture.the accident.
Carsim?s first part is a linguistic mod-ule that extracts information from the report and fillsthe frame slots.
The second part is a virtual scenegenerator that takes the structured representation asinput, creates the visual entities, and animates them(Figure 1).4 A Corpus of Traffic AccidentDescriptionsAs development and test sets, we have collected ap-proximately 200 reports of road accidents from vari-ous Swedish newspapers.
The task of analyzing thenews reports is made more complex by their vari-ability in style and length.
The size of the textsranges from a couple of sentences to more than apage.
The amount of details is overwhelming insome reports, while in others most of the informa-tion is implicit.
The complexity of the accidents de-scribed ranges from simple accidents with only onevehicle to multiple collisions with several partici-pating vehicles and complex movements.Although our work has concentrated on the pressclippings, we also have access to accident reportsfrom the STRADA database (Swedish TRaffic Ac-cident Data Acquisition) of Va?gverket, the Swedishtraffic authority.
STRADA registers nearly all theaccidents that occur in Sweden (Karlberg, 2003).
(All the accidents where there are casualties.)
Af-ter an accident, the victims describe the locationand conditions of it in a standardized form col-lected in hospitals.
The corresponding reports aretranscribed in a computer-readable format in theSTRADA database.
This source contains two kindsof reports: the narratives written by the victims ofthe accident and their transcriptions by traffic ex-perts.
The original texts contain spelling mistakes,abbreviations, and grammatical errors.
The tran-scriptions often simplify, interpret the original texts,and contain jargon.The next text is an excerpt from our developmentcorpus.
This report is an example of a press wiredescribing an accident.En do?dsolycka intra?ffade inatt so?derom Vissefja?rda pa?
riksva?g 28.
Det var enbil med tva?
personer i som kom av va?gen ien va?nsterkurva och ko?rde i ho?g hastighetin i en gran.
Passageraren, som var fo?dd-84, dog.
Fo?raren som var 21 a?r gam-mal va?rdas pa?
sjukhus med sva?ra skador.Polisen missta?nker att bilen de fa?rdades i,en ny Saab, var stulen i Emmaboda ochdet ska under dagen underso?kas.Sveriges Radio, November 9, 2002A fatal accident took place tonight southof Vissefja?rda on Road 28.
A car carry-ing two persons departed from the roadin a left-hand curve and crashed at a highspeed into a spruce.
The passenger, whowas born in 1984, died.
The driver, whowas 21 years old, is severely injured andis taken care of in a hospital.
The policesuspects that the car they were travelingin, a new Saab, was stolen in Emmabodaand will investigate it today.The text above, our translation.5 Knowledge RepresentationThe Carsim language processing module reducesthe text content to a formal representation that out-lines what happened and enables a conversion to asymbolic scene.
It uses information extraction tech-niques to map a text onto a structure that consists ofthree main elements:?
A scene object, which describes the static pa-rameters of the environment, such as weather,light, and road configuration.?
A list of road objects, for example cars, trucks,and trees, and their associated sequences ofmovements.?
A list of collisions between road objects.The structure of the formalism, which sets thelimit of what information can be expressed, was de-signed with the help of traffic safety experts at theDepartment of Traffic and Road at Lund University.It contains the information necessary to reproduceand animate the accident entities in our visualiza-tion model.
We used an iterative process to designit.
We started from a first incomplete model (Dupuyet al, 2001) and we manually constructed the rep-resentation of about 50 texts until we had reached asufficient degree of expressivity.The representation we use is a typical example offrames a` la Minsky, where the objects in the rep-resentation consist of a number of attribute/valuesslots which are to be filled by the information ex-traction module.
Each object in the representationFigure 2: Representation of the accident in the ex-ample above.belongs to a concept in a domain ontology we havedeveloped.
The concepts are ordered in an inheri-tance hierarchy.Figure 2 shows how Carsim?s graphical user in-terface presents the representation of the accidentin the example above.
The scene element containsthe location of the accident and the configuration ofroads, in this case a left-hand bend.
The list of roadobjects contains one car and one tree.
The eventchain for the car describes the movements: the carleaves the road.
Finally, the collision list describesone collision between the car and the tree.6 The Information Extraction ModuleThe information extraction subsystem fills the frameslots.
Its processing flow consists in analyzing thetext linguistically using the word groups obtainedfrom the linguistic modules and a sequence of se-mantic modules.
The information extraction sub-system uses the literal content of certain phrases itfinds in the text or infers the environment and theactions.We use a pipeline of modules in the first stagesof the natural language processing chain.
Thetasks consists of tokenizing, part-of-speech tagging,splitting into sentences, detecting the noun groups,clause boundaries, and domain-specific multiwords.We use the Granska part-of-speech tagger (Carl-berger and Kann, 1999) and Ejerhed?s algorithm(Ejerhed, 1996) to detect clause boundaries.6.1 Named Entity RecognitionCarsim uses a domain-specific named entity recog-nition module, which detects names of persons,places, roads, and car makes (Persson and Daniels-son, 2004).The recognition is based on a small database of2,500 entries containing person names, city and re-gion names, and car names.
It applies a cascadeof regular expressions that takes into account themorphology of Swedish proper noun formation andthe road nomenclature.
The recall/precision perfor-mance of the detector is 0.89/0.97.6.2 Finding the ParticipantsThe system uses the detected noun groups to iden-tify the physical objects, which are involved in theaccident.
It extracts the headword of each group andassociates it to an entity in the ontology.
We usedparts of the Swedish WordNet as a resource to de-velop this dictionary (A?ke Viberg et al, 2002).We track the entities along the text with a sim-ple coreference resolution algorithm.
It assumesthat each definite expression corefers with the lastsortally consistent (according to the ontology) en-tity which was mentioned.
Indefinite expressionsare assumed to be references to previously unmen-tioned entities.
This is similar to the algorithm men-tioned in (Appelt and Israel, 1999).
Although thisapproach is relatively simple, we get reasonable re-sults with it and could use it as a baseline when in-vestigating other approaches.Figure 3 shows an excerpt from a text with theannotation of the participants as well as their coref-erences.Olyckan intra?ffade na?r [bilen]1 som de femfa?rdades i ko?rde om [en annan personbil]2 .
Na?r[den]1 sva?ngde tillbaka in framfo?r [den omko?rdabilen]2 fick [den]1 sladd och for med sidan raktmot fronten pa?
[den mo?tande lastbilen]3 .The accident took place when [the car]1 where thefive people were traveling overtook [another car]2.When [it]1 pulled in front of [the overtaken car]2,[it]1 skidded and hit with its side the front of [thefacing truck]3.Figure 3: A sentence where references to road ob-jects have been marked.6.3 Resolution of MetonymyUse of metonymy, such as alternation between thedriver and his vehicle, is frequent in the Swedishpress clippings.
An improper resolution of it intro-duces errors in the templates and in the visualiza-tion.
It can create independently moving graphicentities i.e.
the vehicle and its driver, that should berepresented as one single object, a moving vehicle,or stand together.We detect the metonymic relations betweendrivers and their vehicles.
We use either cue phraseslike lastbilschauffo?ren (?the truck driver?)
or the lo-cation or instrument semantic roles in phrases likeMannen som fa?rdades i lastbilen (?The man whowas traveling in the truck?).
We then apply con-straints on the detected events and directions to ex-clude wrong candidates.
For example, given thephrase Mannen krockade med en traktor (?The mancollided with a tractor?
), we know that the man can-not be the driver of the tractor.We do not yet handle the metonymic relations be-tween parts of vehicles and the vehicles themselves.They are less frequent in the texts we have exam-ined.6.4 Marking Up the EventsEvents in car accident reports correspond to vehiclemotions and collisions.
We detect them to be ableto visualize and animate the scene actions.
To carryout the detection, we created a dictionary of words?
nouns and verbs ?
depicting vehicle activity andmaneuvers.
We use these words to anchor the eventidentification as well as the semantic roles of thedependents to determine the event arguments.6.4.1 Detecting the Semantic RolesFigure 4 shows a sentence that we translated fromour corpus of news texts, where the groups havebeen marked up and labeled with semantic roles.
[En personbil]Actor ko?rde [vid femtiden]T ime[pa?
torsdagseftermiddagen]T ime [in i ett rad-hus]V ictim [i ett a?ldreboende]Loc [pa?
Alva?gen]Loc[i Enebyberg]Loc [norr om Stockholm]Loc .
[About five]T ime [on Thursday afternoon]T ime , [acar]Actor crashed [into a row house]V ictim [in anold people?s home]Loc [at Alva?gen street]Loc [inEnebyberg]Loc [north of Stockholm]Loc.Figure 4: A sentence tagged with semantic roles.Gildea and Jurafsky (2002) describe an algorithmto label automatically semantic roles in a generalcontext.
They use the semantic frames and associ-ated roles defined in FrameNet (Baker et al, 1998)and train their classifier on the FrameNet corpus.They report a performance of 82 percent.Carsim uses a classification algorithm similar tothe one described in this paper.
However, as there isno lexical resource such as FrameNet for Swedishand no widely available parser, we adapted it.
Ourclassifier uses a more local strategy as well as a dif-ferent set of attributes.The analysis starts from the words in our dictio-nary for which we designed a specific set of framesand associated roles.
The classifier limits the scopeof each event to the clause where it appears.
It iden-tifies the verb and nouns dependents: noun groups,prepositional groups, and adverbs that it classifiesaccording to semantic roles.The attributes of the classifier are:?
Target word: the keyword denoting the event.?
Head word: the head word of the group to beclassified.?
Syntactic class of head word: noun group,prepositional group, or adverb.?
Voice of the target word: active or passive.?
Domain-specific semantic type: Dynamic ob-ject, static object, human, place, time, cause,or speed.The classifier chooses the role, which maximizesthe estimated probability of a role given the valuesof the target, head, and semantic type attributes:P?
(r|t, head, sem) = C(r, t, head, sem)C(t, head, sem) .If a particular combination of target, head, andsemantic type is not found in the training set, theclassifier uses a back-off strategy, taking the otherattributes into account.We annotated manually a set of 819 examples onwhich we trained and tested our classifier.
We useda random subset of 100 texts as a test set and therest as a learning set.
On the test set, the classi-fier achieved an accuracy of 90 percent.
A classi-fier based on decision trees built using the ID3 algo-rithm with gain ratio measure yielded roughly thesame performance.The value of the semantic type attribute is set us-ing domain knowledge.
Removing this attribute de-graded the performance of the classifier to 80 per-cent.6.4.2 Interpreting the EventsWhen the events have been detected in the text, theycan be represented and interpreted in the formal de-scription of the accidents.We observed that event coreferences are very fre-quent in longer texts: A same action like a colli-sion is repeated in several places in the text.
Asfor metonymy, duplicated events in the template en-tails a wrong visualization.
We solve it through theunification of as many events as possible, takingmetonymy relations into account, and we removethe duplicates.6.5 Time Processing and Event OrderingIn some texts, the order in which events are men-tioned does not correspond to their chronologicalorder.
To address this issue and order the events cor-rectly, we developed a module based on the genericTimeML framework (Pustejovsky et al, 2002).
Weuse a machine learning approach to annotate thewhole set of events contained in a text and from thisset, we extract events used specifically by the Car-sim template ?
the Carsim events.TimeML has tags for time expressions (today),?signals?
indicating the polarity (not), the modal-ity (could), temporal prepositions and connectivessuch as for, during, before, after, events (crashed,accident), and tags that indicate relations betweenentities.
Amongst the relations, the TLINKs arethe most interesting for our purposes.
They ex-press temporal relations between time expressionsand events as well as temporal relations betweenpairs of events.We developed a comprehensive phrase-structuregrammar to detect the time expressions, signals, andTimeML events and to assign values to the enti-ties?
attributes.
The string den tolfte maj (?May12th?)
is detected as a time expression with theattribute value=?YYYY-05-12?.
We extended theTimeML attributes to store the events?
syntactic fea-tures.
They include the part-of-speech annotationand verb group structure, i.e.
auxiliary + participle,etc.We first apply the PS rules to detect the time ex-pressions, signals, and events.
Let e1, e2, e3, ...,en be the events in the order they are mentionedin a text.
We then generate TLINKs to relate theseevents together using a set of decision trees.We apply three decision trees on se-quences of two to four consecutive events(ei, ei+1, [, ei+2[, ei+3]]), with the constraintthat there is no time expression between them,as they might change the temporal ordering sub-stantially.
The output of each tree is the temporalrelation holding between the first and last eventof the considered sequence, i.e.
respectively:adjacent pairs (ei, ei+1), pairs separated by oneevent (ei, ei+2), and by two events (ei, ei+3).
Thepossible output values are simultaneous, after,before, is included, includes, and none.
As a result,each event is linked by TLINKs to the three otherevents immediately after and before it.We built automatically the decision trees usingthe ID3 algorithm (Quinlan, 1986).
We trained themon a set of hand-annotated examples, which consistsof 476 events and 1,162 TLINKs.As a set of features, the decision trees use certainattributes of the events considered, temporal signalsbetween them, and some other parameters such asthe number of tokens separating the pair of eventsto be linked.
The complete list of features with xranging from 0 to 1, 0 to 2, and 0 to 3 for each treerespectively, and their possible values is:?
Eventi+xTense: none, past, present, future,NOT DETERMINED.?
Eventi+xAspect: progressive, per-fective, perfective progressive, none,NOT DETERMINED.?
Eventi+xStructure: NOUN,VB GR COP INF, VB GR COP FIN,VB GR MOD INF, VB GR MOD FIN,VB GR, VB INF, VB FIN.?
temporalSignalInbetween: none, before, after,later, when, still, several.?
tokenDistance: 1, 2 to 3, 4 to 6, 7 to 10, greaterthan 10.?
sentenceDistance: 0, 1, 2, 3, 4, greater than 4.?
punctuationSignDistance: 0, 1, 2, 3, 4, 5,greater than 5.The process results in an overgeneration of links.The reason for doing this is to have a large set ofTLINKs to ensure a fine-grained ordering of theevents.
As the generated TLINKs can be conflict-ing, we assign each of them a score, which is de-rived from the C4.5 metrics (Quinlan, 1993).We complement the decision trees with heuris-tics and hints from the event interpreter that eventsare identical.
Heuristics represent common-senseknowledge and are encoded as nine productionrules.
An example of them is that an event in thepresent tense is after an event in the past tense.Event identity and heuristics enable to connectevents across the time expressions.
The TLINKsgenerated by the rules also have a score that is ruledependent.When all TLINKs are generated, we resolve tem-poral loops by removing the TLINK with the lowestscore within the loop.
Finally, we extract the Carsimevents from the whole set of TimeML events and weorder them using the relevant TLINKs.6.6 Detecting the RoadsThe configuration of roads is inferred from the in-formation in the detected events.
When one of theinvolved vehicles makes a turn, this indicates thatthe configuration is probably a crossroads.Additional information is provided using key-word spotting in the text.
Examples of relevant key-words are korsning (?crossing?
), ?rondell?
(?round-about?)
and kurva (?bend?
), which are very likelyindicators of the road configuration if seen in thetext.These methods are very simple, but the caseswhere they fail are quite rare.
During the evalua-tion described below, we found no text where theroad configuration was misclassified.7 Evaluation of the InformationExtraction ModuleTo evaluate the performance of the information ex-traction component, we applied it to 50 previouslyunseen texts, which were collected from newspapersources on the web.
The size of the texts rangedfrom 31 to 459 words.
We calculated precision andrecall measures for detection of road objects and fordetection of events.
A road object was counted ascorrectly detected if there was a corresponding ob-ject in the text, and the type of the object was cor-rect.
The same criteria apply to the detection ofevents, but here we also add the criterion that theactor (and victim, where this applies) must be cor-rect.
The performance figures are shown in Tables 1and 2.Total number of objects in the texts 105Number of detected objects 110Number of correctly detected objects 94Precision 0.85Recall 0.90F-measure (?
= 1) 0.87Table 1: Statistics for the detection of road objectsin the test set.Total number of events in the texts 92Number of detected events 91Number of correctly detected events 71Precision 0.78Recall 0.77F-measure (?
= 1) 0.78Table 2: Statistics for the detection of events in thetest set.The system was able to extract or infer all rele-vant information correctly in 23 of the 50 texts.
Inorder to find out the causes of the errors, we investi-gated what simplifications of the texts needed to beFigure 5: Planning the trajectories.made to make the system produce a correct analysis.The result of this investigation is shown in Table 3.Object coreference 6Role labeling 5Metonymy 5Clause segmentation 3Representational expressivity 3Unknown objects 2Event detection 2Unknown event 1Tagger error 1PP attachment 1Table 3: Causes of errors.8 Scene Synthesis and VisualizationThe visualizer reads its input from the formal de-scription.
It synthesizes a symbolic 3D scene andanimates the vehicles.
We designed the graphic el-ements in the scene with the help of traffic safetyexperts.The scene generation algorithm positions thestatic objects and plans the vehicle motions.
It usesrule-based modules to check the consistency of thedescription and to estimate the 3D start and end co-ordinates of the vehicles.The visualizer uses a planner to generate the vehi-cle trajectories.
A first module determines the startand end positions of the vehicles from the initial di-rections, the configuration of the other objects in thescene, and the chain of events as if they were no ac-cident.
Then, a second module alters these trajecto-ries to insert the collisions according to the accidentslots in the accident representation (Figure 5).This two-step procedure can be justified by thedescriptions found in most reports.
The car driversgenerally start the description of their accident as ifit were a normal movement, which is subsequentlybeen modified by the abnormal conditions of the ac-cident.Finally, the temporal module of the planner as-signs time intervals to all the segments of the trajec-tories.Figure 6 shows two screenshots that the Carsimvisualizer produces for the text above.
It should benoted that the graphic representation is intended tobe iconic in order not to convey any meaning whichis not present in the text.9 Conclusion and PerspectivesWe have presented an architecture and a strategybased on information extraction and a symbolic vi-sualization that enable to convert real texts into 3Dscenes.
We have obtained promising results that val-idate our approach.
They show that the Carsim ar-chitecture is applicable to Swedish and other lan-guages.
As far as we know, Carsim is the onlytext-to-scene conversion system working on non-invented narratives.We are currently improving Carsim and we hopein future work to obtain better results in the reso-lution of coreferences.
We are implementing andadapting algorithms such as the one described in(Soon et al, 2001) to handle this.
We also intendto improve the visualizer to handle more complexscenes and animations.The current aim of the Carsim project is to visu-alize the content of a text as accurately as possible,with no external knowledge.
In the future, we wouldlike to integrate additional knowledge sources in or-der to make the visualization more realistic and un-derstandable.
Geographical and meteorological in-formation systems are good examples of this, whichcould be helpful to improve the realism.
Anothertopic, which has been prominent in our discussionswith traffic safety experts, is how to reconcile dif-ferent narratives that describe a same accident.In our work on the information extraction mod-ule, we have concentrated on the extraction of datawhich are relevant for the visual reconstruction ofthe scene.
We believe that the information extrac-tion component could be interesting in itself to ex-tract other relevant data, for example casualty statis-tics or traffic conditions.AcknowledgementsWe are very grateful to Karin Brundell-Freij, A?seSvensson, and Andra?s Va?rhelyi, traffic safety ex-perts at LTH, for helping us in the design the Carsimtemplate and advising us with the 3D graphic repre-sentation.This work is partly supported by grant num-ber 2002-02380 from the Spra?kteknologi programof Vinnova, the Swedish Agency of InnovationSystems.ReferencesGiovanni Adorni, Mauro Di Manzo, and FaustoGiunchiglia.
1984.
Natural language driven im-age generation.
In Proceedings of COLING 84,pages 495?500, Stanford, California.Douglas E. Appelt and David Israel.
1999.
In-troduction to information extraction technology.Tutorial Prepared for IJCAI-99.
Artificial Intelli-gence Center, SRI International.Michael Arens, Artur Ottlik, and Hans-HellmutNagel.
2002.
Natural language texts for a cogni-tive vision system.
In Frank van Harmelen, edi-tor, ECAI2002, Proceedings of the 15th EuropeanConference on Artificial Intelligence, Lyon, July21-26.Collin F. Baker, Charles J. Fillmore, and John B.Lowe.
1998.
The Berkeley FrameNet Project.
InProceedings of COLING-ACL?98, pages 86?90,Montre?al, Canada.Johan Carlberger and Viggo Kann.
1999.
Imple-menting an efficient part-of-speech tagger.
Soft-ware Practice and Experience, 29:815?832.Bob Coyne and Richard Sproat.
2001.
Wordseye:An automatic text-to-scene conversion system.In Proceedings of the Siggraph Conference, LosAngeles.Michel Denis.
1991.
Imagery and thinking.
In Ce-sare Cornoldi and Mark A. McDaniel, editors,Imagery and Cognition, pages 103?132.
SpringerVerlag.Sylvain Dupuy, Arjan Egges, Vincent Legendre,and Pierre Nugues.
2001.
Generating a 3D simu-lation of a car accident from a written descrip-tion in natural language: The Carsim system.In Proceedings of The Workshop on Temporaland Spatial Information Processing, pages 1?8,Toulouse, July 7.
Association for ComputationalLinguistics.Arjan Egges, Anton Nijholt, and Pierre Nugues.2001.
Generating a 3D simulation of a car ac-cident from a formal description.
In Venetia Gi-agourta and Michael G. Strintzis, editors, Pro-ceedings of The International Conference onAugmented, Virtual Environments and Three-Dimensional Imaging (ICAV3D), pages 220?223,Mykonos, Greece, May 30-June 01.Eva Ejerhed.
1996.
Finite state segmentation ofdiscourse into clauses.
In Proceedings of the 12thEuropean Conference on Artificial Intelligence(ECAI-96) Workshop on Extended Finite StateModels of Language, Budapest, Hungary.Daniel Gildea and Daniel Jurafsky.
2002.
Auto-Figure 6: Screenshots from the animation of the text above.matic labeling of semantic roles.
ComputationalLinguistics, 28(3):245?288.Nils-Olof Karlberg.
2003.
Field results fromSTRADA ?
a traffic accident data system tellingthe truth.
In ITS World Congress, Madrid, Spain,November 16-20.Stephen Michael Kosslyn.
1983.
Ghosts in theMind?s Machine.
Norton, New York.Mauro Di Manzo, Giovanni Adorni, and FaustoGiunchiglia.
1986.
Reasoning about scene de-scriptions.
IEEE Proceedings ?
Special Issue onNatural Language, 74(7):1013?1025.Lisa Persson and Magnus Danielsson.
2004.
Nameextraction in car accident reports for Swedish.Technical report, LTH, Department of Computerscience, Lund, January.James Pustejovsky, Roser Saur?
?, Andrea Setzer, RobGaizauskas, and Bob Ingria.
2002.
TimeML An-notation Guidelines.
Technical report.John Ross Quinlan.
1986.
Induction of decisiontrees.
Machine Learning, 1(1):81?106.John Ross Quinlan.
1993.
C4.5: Programs for Ma-chine Learning.
Morgan Kauffman.A?ke Viberg, Kerstin Lindmark, Ann Lindvall, andIngmarie Mellenius.
2002.
The Swedish Word-Net project.
In Proceedings of Euralex 2002,pages 407?412, Copenhagen.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Edward R. Tufte.
1997.
Visual Explanations: Im-ages and Quantities, Evidence and Narrative.Graphic Press.
