Proceedings of the 6th Workshop on Statistical Machine Translation, pages 433?439,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsInfluence of Parser Choice on Dependency-Based MTMartin Popel, David Marec?ek, Nathan Green and Zdene?k Z?abokrtsky?Charles University in PragueFaculty of Mathematics and PhysicsInstitute of Formal and Applied Linguistics{popel,marecek,green,zabokrtsky}@ufal.mff.cuni.czAbstractAccuracy of dependency parsers is one of thekey factors limiting the quality of dependency-based machine translation.
This paper dealswith the influence of various dependency pars-ing approaches (and also different trainingdata size) on the overall performance of anEnglish-to-Czech dependency-based statisti-cal translation system implemented in theTreex framework.
We also study the relation-ship between parsing accuracy in terms of un-labeled attachment score and machine transla-tion quality in terms of BLEU.1 IntroductionIn the last years, statistical n-gram models domi-nated the field of Machine Translation (MT).
How-ever, their results are still far from perfect.
Thereforewe believe it makes sense to investigate alternativestatistical approaches.
This paper is focused on ananalysis-transfer-synthesis translation system calledTectoMT whose transfer representation has a shapeof a deep-syntactic dependency tree.
The system hasbeen introduced by Z?abokrtsky?
et al (2008).
Thetranslation direction under consideration is English-to-Czech.It has been shown by Popel (2009) that the currentaccuracy of the dependency parser employed in thistranslation system is one of the limiting factors fromthe viewpoint of its output quality.
In other words,the parsing phase is responsible for a large portionof translation errors.
The biggest source of trans-lation errors in the referred study was (and prob-ably still is) the transfer phase, however the pro-portion has changed since and the relative impor-tance of the parsing phase has grown, because thetranfer phase errors have already been addressed byimprovements based on Hidden Markov Tree Mod-els for lexical and syntactic choice as shown byZ?abokrtsky?
and Popel (2009), and by context sensi-tive translation models based on maximum entropyas described by Marec?ek et al (2010).Our study proceeds along two directions.
First,we train two state-of-the-art dependency parsers ontraining sets with varying size.
Second, we usefive parsers based on different parsing techniques.In both cases we document the relation betweenparsing accuracy (in terms of Unlabeled AttachmentScore, UAS) and translation quality (estimated bythe well known BLEU metric).The motivation behind the first set of experimentsis that we can extrapolate the learning curve and tryto predict how new advances in dependency parsingcan affect MT quality in the future.The second experiment series is motivated bythe hypothesis that parsers based on different ap-proaches are likely to have a different distributionof errors, even if they can have competitive perfor-mance in parsing accuracy.
In dependency parsingmetrics, all types of incorrect edges typically havethe same weight,1 but some incorrect edges can bemore harmful than others from the MT viewpoint.For instance, an incorrect attachment of an adverbialnode is usually harmless, while incorrect attachmentof a subject node might have several negative conse-1This issue has been tackled already in the parsing literature;for example, some authors disregard placement of punctuationnodes within trees in the evaluation (Zeman, 2004).433quences such as:?
unrecognized finiteness of the governing verb,which can lead to a wrong syntactization on thetarget side (an infinitive verb phrase instead ofa finite clause),?
wrong choice of the target-side verb form (be-cause of unrecognized subject-predicate agree-ment),?
missing punctuation (because of wrongly rec-ognized finite clause boundaries),?
wrong placement of clitics (because of wronglyrecognized finite clause boundaries),?
wrong form of pronouns (personal and posses-sive pronouns referring to the clause?s subjectshould have reflexive forms in Czech).Thus it is obvious that the parser choice is im-portant and that it might not be enough to choose aparser, for machine translation, only according to itsUAS.Due to growing popularity of dependency syntaxin the last years, there are a number of dependencyparsers available.
The present paper deals withfive parsers evaluated within the translation frame-work: three genuine dependency parsers, namely theparsers described in (McDonald et al, 2005), (Nivreet al, 2007), and (Zhang and Nivre, 2011), and twoconstituency parsers (Charniak and Johnson, 2005)and (Klein and Manning, 2003), whose outputs wereconverted to dependency structures by Penn Con-verter (Johansson and Nugues, 2007).As for the related literature, there is no publishedstudy measuring the influence of dependency parserson dependency-based MT to our knowledge.2The remainder of this paper is structured as fol-lows.
The overall translation pipeline, within whichthe parsers are tested, is described in Section 2.
Sec-tion 3 lists the parsers under consideration and theirmain features.
Section 4 summarizes the influenceof the selected parsers on the MT quality in terms ofBLEU.
Section 5 concludes.2However, the parser bottleneck of the dependency-basedMT approach was observed also by other researchers (RobertMoore, personal communication).2 Dependency-based Translation in TreexWe have implemented our experiments in the Treexsoftware framework (formerly TectoMT, introducedby Z?abokrtsky?
et al (2008)), which already offerstool chains for analysis and synthesis of Czech andEnglish sentences.We use the tectogrammatical (deep-syntactic)layer of language representation as the transfer layerin the presented MT experiments.
Tectogrammat-ics was introduced by Sgall (1967) and furtherelaborated within the Prague Dependency Treebankproject (Hajic?
et al, 2006).
On this layer, eachsentence is represented as a tectogrammatical tree,whose main properties (from the MT viewpoint) arethe following:1. nodes represent autosemantic words,2.
edges represent semantic dependencies (a nodeis an argument or a modifier of its parent),3. there are no functional words (prepositions,auxiliary words) in the tree, and the autose-mantic words appear only in their base forms(lemmas).
Morphologically indispensable cat-egories (such as number with nouns or tensewith verbs, but not number with verbs as it isonly imposed by agreement) are stored in sep-arate node attributes (grammatemes).The intuitions behind the decision to use tec-togrammatics for MT are the following: we be-lieve that (1) tectogrammatics largely abstracts fromlanguage-specific means (inflection, agglutination,functional words etc.)
of expressing non-lexicalmeanings and thus tectogrammatical trees are sup-posed to be highly similar across languages, (2)it enables a natural transfer factorization,3 (3) andlocal tree contexts in tectogrammatical trees carrymore information (especially for lexical choice) thanlocal linear contexts in the original sentences.The translation scenario is outlined in the rest ofthis section.3Morphological categories can be translated almost inde-pendently from lemmas, which makes parallel training data?denser?, especially when translating from/to a language withrich inflection such as Czech.4342.1 AnalysisThe input English text is segmented into sentencesand tokens.
The tokens are lemmatized and taggedwith Penn Treebank tags using the Morce tagger(Spoustova?
et al, 2007).
Then one of the studieddependency parsers is applied and a surface-syntaxdependency tree (analytical tree in the PDT termi-nology) is created for each sentence.This tree is converted to a tectogrammatical tree.Each autosemantic word with its associated func-tional words is collapsed into a single tectogram-matical node, labeled with a lemma, formeme,4 andsemantically indispensable morphologically cate-gories; coreference is also resolved.2.2 TransferThe transfer phase follows, whose most difficult partconsists especially in labeling the tree with target-side lemmas and formemes.
There are also othertypes of changes, such as node addition and dele-tion.
However, as shown by Popel (2009), changesof tree topology are required relatively infrequentlydue to the language abstractions on the tectogram-matical layer.Currently, translation models based on Maxi-mum Entropy classifiers are used both for lemmasand formemes (Marec?ek et al, 2010).
Tree label-ing is optimized using Hidden Tree Markov Mod-els (Z?abokrtsky?
and Popel, 2009), which makesuse of target-language dependency tree probabilisticmodel.All models used in the transfer phase are trainedusing training sections of the Czech-English parallelcorpus CzEng 0.9 (Bojar and Z?abokrtsky?, 2009).2.3 SynthesisFinally, surface sentence shape is synthesized fromthe tectogrammatical tree, which is basically thereverse operation of the tectogrammatical analy-sis.
It consists of adding punctuation and functional4Formeme captures the morphosyntactic means which areused for expressing the tectogrammatical node in the surfacesentence shape.
Examples of formeme values: v:that+fin ?finite verb in a subordinated clause introduced with conjunctionthat, n:sb ?
semantic noun in a subject position, n:for+X ?semantic noun in a prepositional group introduced with prepo-sition for, adj:attr ?
semantic adjective in an attributive po-sition.words, spreading morphological categories accord-ing to grammatical agreement, performing inflection(using Czech morphology database (Hajic?, 2004)),arranging word order etc.The difference from the analysis phase is thatthere is not very much space for optimization in thesynthesis phase.
In other words, final sentence shapeis determined almost uniquely by the tectogrammat-ical tree (enriched with formemes) resulting fromthe transfer phase.
However, if there are not enoughconstraints for a unique choice of a surface form ofa lemma, then a unigram language model is used forthe final decision.
The model was trained using 500million words from the Czech National Corpus.53 Involved ParsersWe performed experiments with parsers fromthree families: graph-based parsers, transition-based parsers, and phrase-structure parsers (withconstituency-to-dependency postprocessing).3.1 Graph-based ParserIn graph-based parsing, we learn a model for scoringgraph edges, and we search for the highest-scoringtree composed of the graph?s edges.
We used Max-imum Spanning Tree parser (Mcdonald and Pereira,2006) which is capable of incorporating second or-der features (MST for short).3.2 Transition-based ParsersTransition-based parsers utilize the shift-reduce al-gorithm.
Input words are put into a queue andconsumed by shift-reduce actions, while the out-put parser is gradually built.
Unlike graph-basedparsers, transition-based parsers have linear timecomplexity and allow straightforward application ofnon-local features.We included two transition-based parsers into ourexperiments:?
Malt ?
Malt parser introduced by Nivre et al(2007) 65http://ucnk.ff.cuni.cz6We used stackeager algorithm, liblinear learner, andthe enriched feature set for English (the same configu-ration as in pretrained English models downloadable athttp://maltparser.org.435?
ZPar ?
Zpar parser7 which is basically an al-ternative implementation of the Malt parser,employing a richer set of non-local features asdescribed by Zhang and Nivre (2011).3.3 CFG-based Tree ParsersAnother option how to obtain dependency trees isto apply a constituency parser, recognize heads inthe resulting phrase structures and apply a recur-sive algorithm for converting phrase-structure treesinto constituency trees (the convertibility of the twotypes of syntactic structures was studied already byGaifman (1965)).We used two constituency parsers:?
Stanford ?
The Stanford parser (Klein andManning, 2003),8?
CJ ?
a MaxEnt-based parser combined withdiscriminative reranking (Charniak and John-son, 2005).9Before applying the parsers on the text, the systemremoves all spaces within tokens.
For instance U. S.becomes U.S. to restrict the parsers from creatingtwo new tokens.
Tokenization built into both parsersis bypassed and the default tokenization in Treex isused.After parsing, Penn Converter introduced by Jo-hansson and Nugues (2007) is applied, with the-conll2007 option, to change the constituentstructure output, of the two parsers, into CoNLL de-pendency structure.
This allows us to keep the for-mats consistent with the output of both MST andMaltParser within the Treex framework.There is an implemented procedure for cre-ating tectogrammatical trees from the Englishphrase structure trees described by Kuc?erova?
andZ?abokrtsky?
(2002).
Using the procedure is morestraightforward, as it does not go through theCoNLL-style trees; English CoNLL-style trees dif-fer slightly from the PDT conventions (e.g.
in at-taching auxiliary verbs) and thus needs additional7http://sourceforge.net/projects/zpar/ (version 0.4)8Only the constituent, phrase based, parsed output is used inthese experiments.9We are using the default settings from the August 2006 ver-sion of the software.postprocessing for our purposes.
However, we de-cided to stick to Penn Converter, so that the similar-ity of the translation scenarios is maximized for allparsers.3.4 Common Preprocessing: Shallow SentenceChunkingAccording to our experience, many dependencyparsers have troubles with analyzing sentences thatcontain parenthesed or quoted phrases, especially ifthey are long.We use the assumption that in most cases the con-tent of parentheses or quotes should correspond toa connected subgraph (subtree) of the syntactic tree.We implemented a very shallow sentence chunker(SentChunk) which recognizes parenthesed wordsequences.
These sequences can be passed to aparser first, and be parsed independently of the restof the sentence.
This was shown to improve not onlyparsing accuracy of the parenthesed word sequence(which is forced to remain in one subtree), but alsothe rest of the sentence.10In our experiments, SentChunk is used onlyin combination with the three genuine dependencyparsers.4 Experiments and Evaluation4.1 Data for Parsers?
Training and EvaluationThe dependency trees needed for training the parsersand evaluating their UAS were created from thePenn Treebank data (enriched first with internalnoun phrase structure applied via scripts providedby Vadas and Curran (2007)) by Penn Converter (Jo-hansson and Nugues, 2007) with the -conll2007option (PennConv for short).All the parsers were evaluated on the same data ?section 23.All the parsers were trained on sections 02?21,except for the Stanford parser which was trainedon sections 01?21.
We were able to retrain theparser models only for MST and Malt.
For theother parsers we used pretrained models available onthe Internet: CJ?s default model ec50spfinal,Stanford?s wsjPCFG.ser.gz model, and10Edge length is a common feature in dependency parsers, so?deleting?
parenthesed words may give higher scores to correctdependency links that happened to span over the parentheses.436ZPar?s english.tar.gz.
The model of ZParis trained on data converted to dependencies usingPenn2Malt tool,11 which selects the last member ofa coordination as the head.
To be able to compareZPar?s output with the other parsers, we postpro-cessed it by a simple ConjAsHead code that con-verts this style of coordinations to the one used inCoNLL2007, where the conjuction is the head.4.2 Reference Translations Used for EvaluationTranslation experiments were evaluated using refer-ence translations from the new-dev2009 data set,provided by the organizors of shared translation taskwith the Workshop on Statistical Machine Transla-tion.4.3 Influence of Parser Training Data SizeWe trained a sequence of parser models for MST andMalt, using a roughly exponentially growing se-quence of Penn Treebank subsets.
The subsets arecontiguous and start from the beginning of section02.
The results are collected in Tables 1 and 2.12#tokens UAS BLEU NIST100 0.362 0.0579 3.6375300 0.509 0.0859 4.38531000 0.591 0.0995 4.65483000 0.623 0.1054 4.797210000 0.680 0.1130 4.969530000 0.719 0.1215 5.0705100000 0.749 0.1232 5.1193300000 0.776 0.1257 5.1571990180 0.793 0.1280 5.1915Table 1: The effect of training data size on parsing accu-racy and on translation performance with MST.The trend of the relation between the training datasize and BLEU is visible also in Figure 1.
It is ob-vious that increasing the training data has a positiveeffect on the translation quality.
However, the paceof growth of BLEU is sublogarithmic, and becomesunconvincing above 100,000 training tokens.
It in-dicates that given one of the two parsers integrated11http://w3.msi.vxu.se/?nivre/research/Penn2Malt.html12To our knowledge, the best system participating in theshared task reaches BLEU 17.8 for this translation direction.#tokens UAS BLEU NIST100 0.454 0.0763 4.0555300 0.518 0.0932 4.46981000 0.591 0.1042 4.67693000 0.616 0.1068 4.747210000 0.665 0.1140 4.910030000 0.695 0.1176 4.9744100000 0.723 0.1226 5.0504300000 0.740 0.1238 5.1005990180 0.759 0.1253 5.1296Table 2: The effect of training data size on parsing accu-racy and on translation performance with Malt.0.050.060.070.080.09 0.10.110.120.131001000100001000001e+06BLEUtrainingtokensMST MaltFigure 1: The effect of parser training data size of BLEUwith Malt and MST parsers.into our translation framework, increasing the parsertraining data alone would probably not lead to a sub-stantial improvement of the translation performance.4.4 Influence of Parser ChoiceTable 3 summarizes our experiments with the fiveparsers integrated into the tectogrammatical transla-tion pipeline.
Two configurations (with and withoutSentChunk) are listed for the genuine dependencyparsers.
The relationship between UAS and BLEUfor (the best configurations of) all five parsers is de-picted also in Figure 2.Additionally, we used paired bootstrap 95% con-fidence interval testing (Zhang et al, 2004), to checkwhich BLEU differences are significant.
For thefive compared parser (with SentChunk if appli-cable), only four comparisons are not significant:MST-CJ, MST-Stanford, Malt-Stanford,and CJ-Stanford.437Parser Training data Preprocessing Postprocessing UAS BLEU NIST TERMST PennTB + PennConv SentChunk ?
0.793 0.1280 5.192 0.735MST PennTB + PennConv ?
?
0.794 0.1236 5.149 0.739Malt PennTB + PennConv SentChunk ?
0.760 0.1253 5.130 0.740Malt PennTB + PennConv ?
?
0.761 0.1214 5.088 0.744Zpar PennTB + Penn2Malt SentChunk ConjAsHead 0.793 0.1176 5.039 0.749Zpar PennTB + Penn2Malt ?
ConjAsHead 0.792 0.1127 4.984 0.754CJ PennTB ?
PennConv 0.904 0.1284 5.189 0.737Stanford PennTB ?
PennConv 0.825 0.1277 5.137 0.740Table 3: Dependency parsers tested in the translation pipeline.0.10.1050.110.1150.120.1250.130.1350.140.1450.150.740.760.780.80.820.840.860.880.90.92BLEUUASMST MaltZparStanford CJFigure 2: Unlabeled Attachment Score versus BLEU.Even if BLEU grows relatively smoothly withUAS for different parsing models of the same parser,one can see that there is no obvious relation be-tween UAS and BLEU accross all parsers.
MST andZpar have the same UAS but quite different BLEU,whereas MST and CJ have very similar BLEU butdistant UAS.
It confirms the original hypothesis thatit is not only the overall UAS, but also the parser-specific distribution of errors what matters.4.5 Influence of Shallow Sentence ChunkingTable 3 confirms that parsing the contents paren-theses separately from the rest of the sentence(SentChunk) has a positive effect with all threedependency parsers.
Surprisingly, even if the effecton UAS is negligible, the improvement is almosthalf of BLEU point which is significant for all thethree parsers.4.6 Discussion on Result ComparabilityWe tried to isolate the effects of the properties ofselected parsers, however, the separation from otherinfluencing factors is not perfect due to several tech-nical issues:?
So far, we were not able to retrain the modelsfor all parsers ourselves and therefore their pre-trained models (one of them based on slightlydifferent Penn Treebank division) must havebeen used.?
Some parsers make their own choice of POStags within the parsed sentences, while otherparsers require the sentences to be tagged al-ready on their input.?
The trees in the CzEng 0.9 parallel treebankwere created using MST.
CzEng 0.9 was usedfor training translation models used in thetransfer phase of the translation scenario; thusthese translation models might compensate forsome MST?s errors, which might handicap otherparsers.
So far we were not able to reparse 8million sentence pairs in CzEng 0.9 by all stud-ied parsers.5 ConclusionsThis paper is a study of how the choice of a de-pendency parsing technique influences the quality ofEnglish-Czech dependency-based translation.
Ourmain observations are the following.
First, BLEUgrows with the increasing amount of training depen-dency trees, but only in a sublogarithmic pace.
Sec-ond, what seems to be quite effective for translation438is to facilitate the parsers?
task by dividing the sen-tences into smaller chunks using parenthesis bound-aries.
Third, if the parsers are based on differentapproaches, their UAS does not correlate well withtheir effect on the translation quality.AcknowledgmentsThis research was supported by thegrants MSM0021620838, GAUK 116310,GA201/09/H057, and by the European Com-mission?s 7th Framework Program (FP7) undergrant agreements n?
238405 (CLARA), n?
247762(FAUST), and n?
231720 (EuroMatrix Plus).ReferencesOndr?ej Bojar and Zdene?k Z?abokrtsky?.
2009.
CzEng0.9, Building a Large Czech-English Automatic Par-allel Treebank.
The Prague Bulletin of MathematicalLinguistics, 92:63?83.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proceedings of the 43rd Annual Meeting ofAssociation for Computational Linguistics, ACL ?05,pages 173?180, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Haim Gaifman.
1965.
Dependency systems and phrase-structure systems.
Information and Control, pages304?337.Jan Hajic?
et al 2006.
Prague Dependency Treebank 2.0.CD-ROM, Linguistic Data Consortium, LDC CatalogNo.
: LDC2006T01, Philadelphia.Jan Hajic?.
2004.
Disambiguation of Rich Inflection ?Computational Morphology of Czech.
Charles Uni-versity ?
The Karolinum Press, Prague.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProceedings of NODALIDA 2007, pages 105?112,Tartu, Estonia, May 25-26.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stAnnual Meeting of Association for Computational Lin-guistics, pages 423?430.Ivona Kuc?erova?
and Zdene?k Z?abokrtsky?.
2002.
Trans-forming Penn Treebank Phrase Trees into (Praguian)Tectogrammatical Dependency Trees.
The PragueBulletin of Mathematical Linguistics, (78):77?94.David Marec?ek, Martin Popel, and Zdene?k Z?abokrtsky?.2010.
Maximum entropy translation model independency-based MT framework.
In Proceedings ofthe Joint Fifth Workshop on Statistical Machine Trans-lation and MetricsMATR, pages 201?201, Uppsala,Sweden.
Association for Computational Linguistics.Ryan Mcdonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing al-gorithms.
In Proceedings of EACL, pages 81?88.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedings ofHLT / EMNLP, pages 523?530, Vancouver, Canada.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,Gulsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,and Erwin Marsi.
2007.
MaltParser: A language-independent system for data-driven dependency pars-ing.
Natural Language Engineering, 13(2):95?135.Martin Popel.
2009.
Ways to Improve the Quality ofEnglish-Czech Machine Translation.
Master?s thesis,Institute of Formal and Applied Linguistics, CharlesUniversity, Prague, Czech Republic.Petr Sgall.
1967.
Generativn??
popis jazyka a c?eska?
dek-linace.
Academia, Prague.Drahom?
?ra Spoustova?, Jan Hajic?, Jan Votrubec, PavelKrbec, and Pavel Kve?ton?.
2007.
The Best of TwoWorlds: Cooperation of Statistical and Rule-BasedTaggers for Czech.
In Proceedings of the Workshopon Balto-Slavonic Natural Language Processing, ACL2007, pages 67?74, Praha.David Vadas and James Curran.
2007.
Adding NounPhrase Structure to the Penn Treebank.
In Proceed-ings of the 45th Annual Meeting of the Associationof Computational Linguistics, pages 240?247, Prague,Czech Republic, June.
Association for ComputationalLinguistics.Zdene?k Z?abokrtsky?
and Martin Popel.
2009.
HiddenMarkov Tree Model in Dependency-based MachineTranslation.
In Proceedings of the ACL-IJCNLP 2009Conference Short Papers, pages 145?148, Suntec, Sin-gapore.Zdene?k Z?abokrtsky?, Jan Pta?c?ek, and Petr Pajas.
2008.TectoMT: Highly Modular MT System with Tec-togrammatics Used as Transfer Layer.
In Proceedingsof the 3rd Workshop on Statistical Machine Transla-tion, ACL, pages 167?170.Daniel Zeman.
2004.
Parsing with a Statistical Depen-dency Model.
Ph.D. thesis, Faculty of Mathematicsand Physics, Charles University in Prague.Yue Zhang and Joakim Nivre.
2011.
Transition-baseddependency parsing with rich non-local features.
In Toappear in the Proceedings of the 49th Annual Meetingof the Association of Computational Linguistics.Ying Zhang, Stephan Vogel, and Alex Waibel.
2004.
In-terpreting bleu/nist scores: How much improvementdo we need to have a better system.
In Proceedings ofLREC, volume 4, pages 2051?2054.439
