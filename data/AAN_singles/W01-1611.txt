Condence-based Adaptivity in Response Generationfor a Spoken Dialogue SystemKristiina JokinenUniversity of Art and Design Helsinki00560 Helsinki, Finlandkjokinen@uiah.fiGraham WilcockUniversity of Helsinki00014 Helsinki, FinlandGraham.Wilcock@helsinki.fiAbstractThe paper addresses the issue of how to increaseadaptivity in response generation for a spokendialogue system.
Realization strategies for dia-logue responses depend on communicative con-dence levels and interaction management goals.We rst describe a Java/XML-based generatorwhich produces dierent realizations of systemresponses based on agendas specied by the di-alogue manager.
We then discuss how greateradaptivity can be achieved by using a set of dis-tinct generator agents, each of which is special-ized in its realization strategy (e.g.
highly ellip-tical or highly explicit).
This allows a simplerdesign of each generator agent, while increas-ing the overall system adaptivity to meet therequirements forexible cooperation in incre-mental and immediate interactive situations.1 IntroductionWhen describing the desired characteristics ofhuman-computer interaction, the common key-words are cooperation and naturalness.
Coop-eration is used to refer to the participants' abil-ity to collaborate with each other on a giventask and to provide informative and helpful con-tributions in a given task context.
Naturalness,however, describes the participants' reactionwhich is appropriate in the current communica-tive context, and usually presupposes reasoningthrough which the participants can adapt them-selves to the requirements of the situation andto the knowledge level of their partner.Naturalness in spoken interaction can becharacterised by features such as incrementalityand immediacy (Jokinen et al, 1998).
Speak-ers exchange information and present the newinformation in a stepwise manner, constructinga common ground by providing new pieces ofrelevant information to complete the task thatthe interaction was initiated for.
They mon-itor their own presentations and react to thepartner's contributions immediately, often si-multaneously, to prevent potential misunder-standings growing and causing problems to theinteraction.
Spoken dialogue systems that aimat natural interaction with the user should thushave capabilities for incremental and immedi-ate management of interaction.
In other words,they should be able to produce responses thattake into account the requirements of an incre-mental and immediate interactive situation.
Inthis paper we discuss how various types of sys-tem responses can be generated taking into ac-count the special requirements of incrementaland immediate interaction situations.The paper is structured as follows.
In Sec-tion 2 we discuss concrete examples from a spo-ken dialogue system, in which dierent formsof surface realization are required in order toachieve interaction management goals.
Thismay involve, for example, deliberate repetitionof old information to get implicit conrmationof speech recognition accuracy.
When there isa high level of condence in the eectiveness ofthe communication channel, however, the pre-ferred form of response realization is to includeonly the new information in the response.Section 3 describes an implementation of dia-logue response generation based on Java, XMLand XSL transformations.
The implementationcan generate the dierent realizations discussedin Section 2.
The way in which the genera-tor chooses between the dierent realizationsis based on detailed specications of the infor-mation status of dierent concepts, given in anagenda by the dialogue manager component.In Section 4 we then discuss an alternativeapproach to the choice of realization, in whicha set of distinct generation agents are used, eachagent being specialized in its realization strat-egy (e.g.
highly elliptical or highly explicit).The design of the individual generation agentsis therefore simpler, but the system as a wholeincreases in adaptivity by choosing which agentto use according to the wider dialogue context.We describe a Java and XML-based frameworkwhich supports this architecture, and discuss astrategy for adaptivity based on communicativecondence.2 Interaction ManagementIn this section we discuss concrete examplesfrom a spoken dialogue system.
The domainis public transportation in Helsinki.2.1 Agenda, NewInfo and TopicTo enable incremental presentation and imme-diate reaction, Jokinen et al (1998) structurethe context with the help of NewInfo and Topic,so that the generator can distinguish the new in-formation that is meant to be put across in thecurrent dialogue situation, and the backgroundinformation that the new information is linkedto.
The pool of contextual information includesan agenda, a set of concepts marked with thehelp of 'topic' and 'newinfo' tags, the tags be-ing determined by the dialogue manager whichdecides how the system is to react next.The generator can freely use the tagged piecesof information in order to realise the system'sintention as a surface string, but it is not forcedto include in the response all the concepts thatthe dialogue manager has designated as rele-vant in the agenda.
Thus the dialogue managerand the generator communicate via the specif-ically marked conceptual items in the sharedknowledge-base, but they both make their owndecisions on the basis of their own reasoning andtask management.
The dialogue manager neednot know about particular rules of surface real-isation while the generator need not know howto decide the information status of the conceptsin the current dialogue situation.While the notions of NewInfo and Topic areoften used to illustrate the characteristics ofword-order variation, their importance in spo-ken dialogue systems can be mostly shown inthe planning process that lies at the borderof dialogue processing and tactical generation.Consider rst the following questions by theuser:(1) Which bus goes to Malmi?
(2) How do I get to Malmi?The dialogue manager has analysed them astimetable requests related to the user's going toMalmi.
It has also recognized that NewInfo in(1) is the information concerning bus numberswhile NewInfo in (2) concerns means of trans-portation.In the case of (1), the information that thedialogue manager gets from the task managerwhich consults the timetable database, is thatthere is bus 74 that goes to Malmi.
The dialoguemanager decides to put the following conceptsinto the agenda in the shared knowledge pool(using XML as discussed in Section 3):<agenda><concept info="Topic"><type>means-of-transportation</type><value>bus</value></concept><concept info="Topic"><type>destination</type><value>malmi</value></concept><concept info="Topic"><type>bus</type><value>exists</value></concept><concept info="NewInfo"><type>busnumber</type><value>74</value></concept></agenda>The dialogue manager also tags the conceptsas NewInfo or Topic, reecting its knowledge ofhow the concepts relate to the current dialoguesituation.
The concept 'busnumber' is taggedas NewInfo, and the other three as Topic, sincethis is a match with the new information askedin the previous utterance, and the user will belikely to link the response correctly.The generator can then select the conceptsand decide the surface realisation as describedin Section 4.
The simplest realisation is:(1a) Number 74.2.2 Indirect RequestsFor example (2), however, the situation is some-what more complicated since the user questioncan be understood either as a literal questionabout public transportation to Malmi, or as anindirect request for buses that go to Malmi.
In-formation about the previous dialogue situationmust thus be used, and we relate the dierenceto the Topic of the conversation: in the 'literal'case, the Topic is Malmi, the destination wherethe speaker wants to nd out transportationfor, whereas in the indirect request, the Topic isthe bus as a means of transportation to Malmi.Consequently, in the 'literal' case, the dialoguemanager consults the task manager by request-ing a value for the concept 'means of trans-portation', while in the indirect request, the di-alogue manager requests task manager to givea value for the busnumber.
In both cases, how-ever, the information that the dialogue man-ager gets from the task manager is the same:that there exists a means of transportation toMalmi, namely a bus and the busnumber is 74.1When deciding on the response to the 'lit-eral' case, the dialogue manager regards themeans of transportation as NewInfo and thedestination to Malmi as Topic, continuing theinformation structure of the previous question.The two other concepts, 'bus' and 'busnumber',are also tagged as new but since the NewInfothat matches the dialogue situation concernsthe public transportation to Malmi, the piece ofinformation of the bus number is extra informa-tion that can be seen as a sign of cooperation onthe system's side, rather than a necessary newinformation to be told to the user, i.e.
theycan be added in the response if the time con-straints allow this and the level of cooperationso requests.The agenda in the shared knowledge pool incase (2a) is as follows:<agenda><concept info="NewInfo"><type>means-of-transportation</type><value>bus</value></concept><concept info="Topic">1The dialogue manager and task manager commu-nicate with each other via a particular task-form whichhas as its parameters the concepts important for the taskmanager to fetch information from the database.
If theform is lled in so that a database query can be per-formed, the task manager returns the form with all theappropriate parameters lled in, and thus lets the dia-logue manager decide on the status of the parametersand their values with respect to the dialogue situation.<type>destination</type><value>malmi</value></concept><concept info="NewInfo"><type>bus</type><value>exists</value></concept><concept info="NewInfo"><type>busnumber</type><value>74</value></concept></agenda>In the case of an indirect request, the dia-logue manager again relies on the dialogue con-text when tagging the concepts for the agenda.The Topic is the means of transportation toMalmi, whereas the NewInfo concerns the bus-number, and so only the 'bus' and 'busnumber'are tagged as new.
For (2b), the shared knowl-edge is thus as follows:<agenda><concept info="Topic"><type>means-of-transportation</type><value>bus</value></concept><concept info="Topic"><type>destination</type><value>malmi</value></concept><concept info="NewInfo"><type>bus</type><value>exists</value></concept><concept info="NewInfo"><type>busnumber</type><value>74</value></concept></agenda>The dierence in the system responses is re-ected in the alternatives (2a) and (2b):(2a) By bus - number 74.
(2b) Bus 74 goes there.2.3 Condence LevelsThe next example is related to a dierent as-pect of spoken dialogue systems: condence inspeech recognition results.
The dialogue man-ager gets the recognized words together withtheir recognition scores, and decides on the ap-propriate action depending on the condencelevels.
(3) When will the next bus leave for Malmi?
(a) 2.20pm(b) It will leave at 2.20pm(c) The next bus to Malmi leaves at2.20pmAs is common, we assume that if recognitionis above a certain condence level, the systemwill use the simplest and most straightforwardanswer, while if the recognition error becomesbigger, a conrmation strategy has to be used.Thus response (3a) is used when the system hascondence that the user has indeed asked aboutnew information concerning the next bus leav-ing for Malmi (cf.
1a).
Response (3b) is alsoused in the similar situation where the system iscondent about its recognition, but the dialoguesituation diers from the one in (3a) in thatnow the system assumes that the user expects apolite full response, instead of an elliptical an-swer as in (3a) where the user has talked aboutthe buses to Malmi and just wants to check thenext one leaving.
The alternative (3c) is usedwhen the system explicitly wants to conrm theTopic (= next bus to Malmi), so as not to allowuser to draw false implicatures about which bustimetable the answer concerns.The agendas for the alternatives (3a) and (3b)are similar, and the dierence in the surface re-alizations is due to the dierent interaction his-tory: in the former case the Topic continues andthe dialogue history contains the concepts des-tination and bus as previous Topics, whereas inthe latter case, the previous Topics may be dif-ferent concepts or there may me no previousTopic at all (beginning of the dialogue).
(3a,b)<agenda><concept info="Topic"><type>means-of-transportation</type><value>bus</value></concept><concept info="Topic"><type>destination</type><value>malmi</value></concept><concept info="Topic"><type>bus</type><value>exists</value></concept><concept info="NewInfo"><type>bustime</type><value>2.20pm</value></concept></agenda>Also the agenda for the alternative (3c) looksthe same, except for the feature <confidence>which characterizes the system's own evaluationof how condent it is of the correctness of therecognized concepts.
The value 1 marks cer-tainty as in the case of bustime whose value isretrieved from the database.
This feature hasbeen left out in the other representations forthe sake of clarity: if the condence is abovethe threshold, the concept is treated accordingto its information status in the shared pool.
(3c)<agenda><concept info="Topic"><type>means-of-transportation</type><value>bus</value><confidence>0.6</confidence></concept><concept info="Topic"><type>destination</type><value>malmi</value><confidence>0.2</confidence></concept><concept info="Topic"><type>bus</type><value>exists</value><confidence>0.6</confidence></concept><concept info="NewInfo"><type>bustime</type><value>2.20pm</value><confidence>1.0</confidence></concept></agenda>3 Dialogue Response GenerationThe system's competence in dialogue manage-ment is shown in the two tasks that the sys-tem must perform: evaluating the user goal,and response generation.
The former resultsin strategic decision about operationally appro-priate goals, while the latter concerns how thesame goal can be realised in dierent ways indierent contexts.We now describe the framework which per-forms the dialogue response generation.
Thecontent determination has been done by the di-alogue manager, which has selected the relevantconcepts to put on the agenda.
The discourseplanning is based closely on the specication ofTopic and NewInfo by the dialogue manager,but also includes specic decisions by the gener-ator described in Section 3.2.
The response gen-eration continues with an aggregation stage, de-scribed in Section 3.3, followed by a stage whichcombines lexicalization and generation of refer-ring expressions, described in Section 3.4.
Mor-phological generation, which is very importantfor one of the languages generated (Finnish), isdone in a separate stage.The framework is based on Java, XML andXSL transformations.
The implemented systemcan generate the responses which we have dis-cussed.
In the next section, we will describe anextension to this framework, suitable for adap-tive andexible response generation.3.1 A Pipeline ArchitectureThe generator starts from an agenda of con-cepts specied in XML, set up by the dialoguemanager as shown in the examples in Section 2.The generator produces linguistic output whichis also specied in XML, to be passed to thespeech synthesizer.
We are therefore generatingXML from XML.
The simplest way to do thisis to apply a set of XML transformations spec-ied in XSL (XML Stylesheet Language).
Wedo this using the Xalan XSL Processor (ApacheXML Project, 2001) which is open-source soft-ware written entirely in Java.With the Xalan XSL Processor it is easy toset up a sequence of transformations, in whichthe output of one transformation becomes theinput to the next transformation.
This kind of\piping" is a natural way to implement the stan-dard pipeline architecture regularly used in nat-ural language generation systems (Reiter andDale, 2000).The ease of setting up a pipeline architecturewith XSL raises the general question of whetherXSL transformations are suitable for wider usein NLG systems.
This is discussed by Cawsey(2000), who concludes that relatively simpleXSL transformations can be used for generationwhen the input is fairly constrained, but XSL isnot suitable for less constrained input, when weneed to turn to general purpose programminglanguages or NLG tools.However, XSL can be combined with gen-eral purpose programming languages by embed-ding extension functions in the XSL templates.These functions can be written in Java (ApacheXML Project, 2001).
This means that evenwhere general purpose programming languagesare required for specic purposes, such as com-plex morphology, a pipeline of XSL transforma-tions can still be used as a general framework.3.2 Focus-based GenerationThe model of dialogue response generationwhich we use is based on generation from thenew information focus, as proposed by Jokinenet al (1998).
In this model, response planningstarts from the new information focus, calledNewInfo.
One of the tasks of the generator isto decide how to present the NewInfo to theuser: whether it should be presented by itselfor whether it should be wrapped in appropriatelinking information.The wrapping of the NewInfo depends onthe pragmatic requirements of the dynamic dia-logue context.
When the context permits au-ent exchange of contributions, wrapping will beavoided and the response will be based on newinformation only.
When the context requiresmore clarity and explicitness, the new informa-tion will be wrapped by Topic information inorder to avoid ambiguity and misunderstand-ing.
When the communication channel is work-ing well, wrapping will be reduced, and whenthere are uncertainties about what was actuallysaid, wrapping will be increased to provide im-plicit conrmation.Typically, XSL transformations are usedto convert information content represented inXML into a desired presentation format, for ex-ample in HTML.
There is usually no need forcomplex re-ordering of the content.
Here how-ever, the generator must convert the unorderedbag of concepts in the agenda into a syntacti-cally correct ordered sequence of words to bepassed to the speech synthesizer.
Also, the newinformation focus tends to come last in surfaceorder, so the linking information (if any) willgenerally precede the new information in thesurface realization.Simple reordering can be performed in XSL,for example by using XSL modes.
We have ex-perimented with applying XSL templates rstwith a Topic mode (if required), followed by aNewInfo mode.
The usefulness of XSL modesfor such purposes is noted by Cawsey (2000).However, as we must also handle detailed syn-tactic ordering, we use aggregation templates asdescribed in Section 3.3.If the real-time requirements of the system al-low su?cient time, the generator can decide onthe optimum way to wrap the new information,but if there is extreme urgency to produce a re-sponse, the generator can simply give the newinformation without wrapping it.
If this leadsto misunderstanding, the system can attemptto repair this in subsequent turns.
In this sense,the model oers an any-time algorithm, impor-tant for providing incremental and immediateresponses for spoken interactive situations.3.3 AggregationThe aggregation stage selects those conceptsmarked as NewInfo as the basis for generation,and also decides whether NewInfo will be theonly output, or whether it will be preceded bythe Topic linking concepts.In order to implement detailed syntactic or-dering, we use aggregation templates as a formof sentence plan specication.
The aggregationtemplates are implemented by means of XSLnamed templates, as in the following simpliedexample:<xsl:template name="NUM-DEST-TIME"><aggregation><tree><node>S</node><tree><node>NP</node><xsl:copy-of select="./concept[type='busnumber']"/></tree><tree><node>V</node><xsl:copy-of select="./concept[type='bus']"/></tree><tree><node>PP</node><xsl:copy-of select="./concept[type='destination']"/></tree><tree><node>PP</node><xsl:copy-of select="./concept[type='bustime']"/></tree></tree></aggregation></xsl:template>The selected aggregation template creates anew XML document instance, with root node<aggregation>.
Its child nodes are one or more<tree> nodes, containing syntactic categoriesand other features.
The trees contain variableslots, which will be lled in later by the lexical-ization and referring expression stages.
In theaggregation stage, the concepts from the agendaare copied directly into the appropriate slots bymeans of <xsl:copy-of> statements.Our aggregation templates are quite similarto the syntactic templates described by Theune(2000).
As argued by van Deemter et al (1999),this kind of syntactic template-based approach,which rather resembles TAG-based generation,is fundamentally well-founded.The selection of an appropriate aggregationtemplate is based on which concept types are inthe agenda and on their information status asTopic or NewInfo.
The logic is implemented bymeans of nested <xsl:choose> statements, asin the following example:<!-- CHOOSE TEMPLATE BASED ON AGENDA --><xsl:template match="agenda"><xsl:choose><xsl:when test="concept[@info='NewInfo']/type='means-of-transportation'"><xsl:call-template name="BY-TRANSPORT"/></xsl:when><xsl:when test="concept[@info='NewInfo']/type='bus'"><xsl:choose><xsl:when test="concept[@info='NewInfo']/type='busnumber'"><xsl:call-template name="NUM-DEST-TIME"/></xsl:when>...</xsl:choose></xsl:when><xsl:when test="concept[@info='NewInfo']/type='busnumber'"><xsl:call-template name="NUMBER-ONLY"/></xsl:when>...</xsl:choose></xsl:template>Here, if means-of-transportation is NewInfoas in (2a), the template named BY-TRANSPORTis selected.
If means-of-transportation is notNewInfo, but bus and busnumber are NewInfoas in (2b), template NUM-DEST-TIME is selected.If only busnumber is NewInfo, as in (1a), thetemplate NUMBER-ONLY is selected.3.4 Referring ExpressionsIn the lexicalization and referring expressionstages of the response generation pipeline, theconcepts in the aggregation templates are re-placed by lexical items and referring expres-sions.
In general, concepts which are markedas Topic are realized as pronouns, as shown bythe following simplied examples:<!-- REFERRING EXPRESSIONS: PRONOUNS --><xsl:templatematch="concept[@info='Topic']"mode="referring-expression"><xsl:choose><xsl:when test="type='busnumber'"><xsl:text> it </xsl:text></xsl:when><xsl:when test="type='destination'"><xsl:text> there </xsl:text></xsl:when><xsl:when test="type='bustime'"><xsl:text> then </xsl:text></xsl:when></xsl:choose></xsl:template>Here, a destination concept marked as Topicis pronominalized as there, as in (2b).
By con-trast, concepts which are marked as NewInfoare realized as full descriptions.
In the followingtemplate, the destination concept is realized bya prepositional phrase, to followed by the textvalue of the destination placename, obtained bythe <xsl:value-of> statement.<!-- REFERRING EXPRESSIONS: DESCRIPTIONS --><xsl:templatematch="concept[@info='NewInfo']"mode="referring-expression"><xsl:choose><xsl:when test="type='busnumber'"><xsl:text> number </xsl:text><xsl:value-of select="value/text()"/></xsl:when><xsl:when test="type='destination'"><xsl:text> to </xsl:text><xsl:value-of select="value/text()"/></xsl:when><xsl:when test="type='bustime'"><xsl:text> at </xsl:text><xsl:value-of select="value/text()"/></xsl:when></xsl:choose></xsl:template>The above examples are simplied to showsimple text output.
The nal stages of responsegeneration actually perform syntactic and mor-phological realization producing XML output(SABLE or VoiceXML) which is passed to thespeech synthesizer.4 Condence-based AdaptivityIn general, when condence in speech recog-nition accuracy goes down, the dialogue sys-tem needs to adapt by increasing the repetitionof old information to check that it is correct.When condence in speech recognition accuracyis high, the system should adapt by reducing therepetition of old information, given the dialoguecontext itself does not require this.
Normally,with high speech recognition condence, au-ent dialogue will be made up of responses withonly new information.4.1 A Development FrameworkIn order to allow this kind of variation in the re-sponses produced, the framework in which thedialogue management is embedded must itselfbe designed specically to support adaptivity.One such system is the Jaspis adaptive speechapplication framework (Turunen and Hakuli-nen, 2000).
Jaspis is a general agent-based de-velopment architecture, and on the most generallevel it contains managers which handle generalcoordination between the system componentsand functional modules (such as the Input Man-ager, the Dialogue Manager and the Presenta-tion Manager).
Within each manager there areseveral agents which handle various interactionsituations, as well as a set of evaluators whichtry to choose the best possible agent to handleeach situation.
The architecture also exploitsa shared knowledge-base called the InformationStorage, where the information about the cur-rent state of the system is kept and which eachof the agents can read and update.The adaptivity-oriented architecture of ourdialogue system is shown in Figure 1 (the In-put Manager is left out).
The Dialogue Man-ager consists of a number of dialogue agents thatare experts on one specic aspect of dialoguemanagement and whose activities are controlledand coordinated by a particualr dialogue con-troller (which thus currently acts as the centralevaluator for all the dialogue agents).
The Di-alogue Manager decides what to say next onFigure 1: Part of the system architecturethe basis of the dialogue context recorded inthe Information Storage by the various agents,and by consulting the Task Manager, wheneverthe requested information requires factual in-formation about the task itself.
The output ofthis reasoning is expressed in terms of conceptsmarked as NewInfo and Topic, and stored in theshared Information Storage in the XML formatas shown in the examples in Section 2.The response generation takes place in thepresentation management module, which con-tains several generator agents, each of whichspecialized in one particular type of generation.The agents may, for example, generate in dier-ent languages (we are developing generators forEnglish and Finnish).
In the current implemen-tation, we mainly consider agents for pronomi-nalization, explicitness and politeness.We are developing generation agents at threedistinct explicitness levels.
The rst agent gen-erates NewInfo only, and is suitable for quick in-formal interactions with high speech recognitioncondence like example (3a).
The second agentgenerates NewInfo wrapped by Topic, whereTopic is normally realized as a minimal refer-ring expression such as a pronoun.
This agentis suitable for more polite interactions with goodspeech recognition, as in example (3b).
Thethird agent generates a fully explicit Topic, andis suitable for situations where speech recogni-tion condence is low, and conrmation of thetopic is required, as in example (3c).
One ad-vantage of this approach is that the design ofthe individual generators is simplied, as theycan follow a xed realization strategy, but theoverall adaptivity of the system is increased.The selection of the appropriate generatoragent is the task of the component called theAdapter in Figure 1.
The Adapter is a particu-lar kind of evaluator based on a neural networkimplementation.
Input consists of a number offeatures which are encoded as binary features,and output consists of categories that representthe dierent generators.
The features are ex-tracted from the shared information storage andconcern e.g.
the content of the planned utter-ance (Topic, NewInfo), recognition condenceof the previous user utterance, and general re-quirements for cooperative, natural responses.4.2 AdaptivityAdaptivity is one of the desirable properties forlearning dialogue systems (Jokinen, 2000).
Itis linked to the system's cooperation with theuser, i.e.
its capability to provide informativeand helpful responses but also its capability totailor responses according to various situationsthe users nd themselves in.In the above framework, one approach to pro-viding the desired adaptivity is to have gen-erator agents with dierent levels of explicit-ness.
Changing levels of condence in speechrecognition accuracy can then lead to selectinggenerator agents with more or less explicitness.The detailed mechanisms for switching betweenthese dierent agents by means of the evalua-tors in the Jaspis framework, including a softcomputing approach based on neural networks,are being evaluated.Related research has studied adaptivity withrespect to system strategies, and identied con-rmation as one of the helpful strategies thatspoken dialogue systems can use in order toshow cooperation and allow the user to cor-rect misrecognized words (Danieli and Gerbino,1995).
The use of system initiative also helps re-duce misrecognition errors and thus contributesto user satisfaction (Walker et al, 1998).
How-ever, a xed dialogue strategy may not suit allusers, whose knowledge of the system's capabil-ities may dier.
Adaptivity can thus be relatedto the system's ability to change from a user ini-tiative strategy to a system initiative one, or touse varied conrmation strategies, in responseto circumstances and the user model.
Empiri-cal evaluation of one such system shows that anadaptable system outperforms a non-adaptableone (Litman and Pan, 2000).We have widened the notion of adaptivityto concern also the system's generation strate-gies in maintaining natural interaction with theuser.
The dialogue manager can be said to selectamong dialogue strategies, such as conrmationor initiative, and the choice is implicitly shownin the selection of the concepts in the agenda.The presentation manager then selects a gener-ator agent to realise the agenda, and can be saidto further extend the system's adaptivity as anaspect of the realization possibilities availablefor the system.
The same agenda can be re-alised dierently (as in examples 3a and 3b) bydierent generator agents, and thus the systemcan adapt on dierent levels.
The selection ofconrmation or non-conrmation strategy canalso depend on the system's other capabilities.4.3 CondenceThe aim of the adaptivity-oriented architectureis to enable the spoken dialogue system to adaptits responses to the changing condence lev-els concerning the system's knowledge of thecurrent dialogue situation.
At the start of anew dialogue, when there is no previous historyon which to establish any general communica-tive condence, the system should start with ahighly explicit response generator, and gradu-ally, if some level of condence is established,switch to a less explicit generator.The high level of explicitness in the systemresponses has several aspects.
Simply by pro-viding a quantity of words to be recognised andacknowledged, the system can verify its under-standing of the relevant concepts.
Explicitnessthus enables speech recognition condence to beestablished, and is related to the system's con-rmation strategy as in example (3c).It is also associated with politeness: a highlevel of explicitness is more polite, and a highlevel of elliptical expression is more friendly.Since politeness is expected with strangers,more explicitness is therefore appropriate at thestart of a dialogue and less appropriate as thedialogue proceeds: it is thus inversely relatedto the condence of the partner which gets es-tablished in the shared situation.
This patternof gradual change from a more formal initialregister to a more informal register as the di-alogue progresses is well known, at least in cul-tures in which register is not dictated strictlyby social hierarchy.
Dierences between En-glish dialogues (dynamic register adaptivity)and Japanese dialogues (xed register through-out) have been studied (Kume et al, 1989).Generation of referring expressions is mainlyconcerned with enabling successful discrimina-tion of the correct referent.
However, referringexpressions in dialogue systems are also stronglyaected by the level of condence.
When thereis some doubt, it is safer to use highly explicitreferring expressions.
When there is a high levelof condence, it is normal to take certain risksfor the sake ofuent interaction.
In fact thedierence between denite descriptions and pro-nouns is based on condence: if an entity hasnot been mentioned previously, it has no historyon which any condence can be established, soa high level of explicitness is required.4.4 Communicative ObligationsAs argued by Allwood (1976), communicationcreates normative social obligations which con-cern the speaker's rational coordinated interac-tion.
Obligations are connected to a particularactivity and a role in the activity, varying alsoaccording to the speakers' familiarity and rela-tive status with each other.In dialogue systems, communicative obliga-tions are usually part of the system's controlstructure.
The system can take the initiative,give helpful information in anticipation of theuser's questions or to resolve problematic sit-uations (misheard words, ambiguous referents,etc.
), or simply react to the user input as bestas it can.
Obligations are thus used as a basicmotivation for action (Traum and Allen, 1994).In our framework communicative obligationsare dispersed among the agents and evaluatorcontrol.
This allows us to make the obligationsovert, since they can be implemented as simpledialogue agents.
However, as their applicationorder is not xed, the overall architecture sup-portsexible interaction where the basic com-municative ability of the system is shown in thefunctioning of the system itself.
The systems'scooperation is not only a pre-assigned disposi-tion to act in a helpful way, but involves reason-ing about the appropriate act in the context.5 ConclusionWe have described our work on adaptivity in re-sponse generation for a spoken dialogue system,and have argued in favour of a system architec-ture using highly specialized agents.
The sys-tem adapts its responses to dialogue situationsby means of the detailed agendas specied bythe dialogue manager and the selection of thegenerator agent by the presentation manager.Further evaluation of a larger demonstrator sys-tem is planned.ReferencesJens Allwood.
1976.
Linguistic Communicationas Action and Cooperation.
Department ofLinguistics, University of Goteborg.
Gothen-burg Monographs in Linguistics 2.Apache XML Project.
2001.
Xalan-Javaversion 2.1.0. http://xml.apache.org/xalan-j/index.html.Alison Cawsey.
2000.
Presenting tailored re-source descriptions: Will XSLT do the job?In 9th International Conference on the WorldWide Web.Morena Danieli and Elisabetta Gerbino.
1995.Metrics for evaluating dialogue strategies ina spoken language system.
In Proceedingsof the AAAI Spring Symposium on Empiri-cal Methods in Discourse Interpretation andGeneration, pages 34{39.Kristiina Jokinen, Hideki Tanaka, and AkioYokoo.
1998.
Planning dialogue contribu-tions with new information.
In Proceedingsof the Ninth International Workshop on Nat-ural Language Generation, pages 158{167,Niagara-on-the-Lake, Ontario.Kristiina Jokinen.
2000.
Learning dialogue sys-tems.
In L. Dybkjaer, editor, LREC 2000Workshop: From Spoken Dialogue to FullNatural Interactive Dialogue - Theory, Em-pirical Analysis and Evaluation, pages 13{17,Athens.Masako Kume, Gayle K. Sato, and Kei Yoshi-moto.
1989.
A descriptive framework fortranslating speaker's meaning: Towards a di-alogue translation system between Japaneseand English.
In Fourth Conference of theEuropean Chapter of the Association forComputational Linguistics, pages 264{271,Manchester.Diane Litman and Shimei Pan.
2000.
Predict-ing and adapting to poor speech recognitionin a spoken dialogue system.
In Proceed-ings of the Seventeenth National Conferenceon Articial Intelligence (AAAI-2000), pages722{728, Austin, TX.Ehud Reiter and Robert Dale.
2000.
BuildingNatural Language Generation Systems.
Cam-bridge University Press.Mariet Theune.
2000.
From Data to Speech:Language Generation in Context.
Ph.D. the-sis, Eindhoven University of Technology.David Traum and James F. Allen.
1994.
Dis-course obligations in dialogue processing.
In32nd Annual Meeting of the Association forComputational Linguistics, pages 1{8, LasCruces.Markku Turunen and Jaakko Hakulinen.
2000.Jaspis - a framework for multilingual adaptivespeech applications.
In Proceedings of 6th In-ternational Conference on Spoken LanguageProcessing, Beijing.Kees van Deemter, Emiel Krahmer, and MarietTheune.
1999.
Plan-based vs. template-based NLG: A false opposition?
In Proceed-ings of the KI'99 Workshop: May I SpeakFreely?, pages 1{5, Saarbrucken.Marilyn Walker, Diane Litman, CandaceKamm, and Alicia Abella.
1998.
Evaluat-ing spoken dialogue agents with PARADISE:Two case studies.
Computer Speech and Lan-guage, 12-3.
