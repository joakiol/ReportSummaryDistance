Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 129?136,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsSupport Collaboration by Teaching FundamentalsMatthew StoneComputer Science and Cognitive ScienceRutgers, The State University of New Jersey110 Frelinghuysen Road, Piscataway NJ 08854-8019Matthew.Stone@Rutgers.EDUAbstractThis paper argues for teaching computer sci-ence to linguists through a general course atthe introductory graduate level whose goal isto prepare students of all backgrounds for col-laborative computational research, especiallyin the sciences.
We describe our work overthe past three years in creating a model coursein the area, called Computational Thinking.What makes this course distinctive is its com-bined emphasis on the formulation and solu-tion of computational problems, strategies forinterdisciplinary communication, and criticalthinking about computational explanations.1 IntroductionThe central long-term challenge of computationallinguistics is meaningfulness.
I want to build situ-ated, embodied interactive agents that can work withpeople through language to achieve a shared under-standing of the world.
We have an increasing toolkitto approach such problems.
Linguistics gives uspowerful resources for representing utterance struc-ture and interpretation, for example through the fam-ily of formalisms and models that have grown uparound dynamic semantics and discourse representa-tion theory.
Supervised machine learning has provedto be a profoundly successful software engineeringmethodology for scaling representations and mod-els from isolated instances to systematic wide cov-erage.
Nevertheless, talking robots are a long wayoff.
This is not a problem that is likely to be solvedby writing down a corpus of interpretations for sen-tences (whatever that might mean) and training upthe right kind of synchronous grammar.
Nor isit likely to be solved by some one lone genius?half Aravind Joshi, half Richard Stallman?drivento learn and implement solo all of linguistics, artifi-cial intelligence and cognitive science.
Progress willcome through teamwork, as groups from disparatebackgrounds come together to share their discov-eries, perspectives, and technical skills on concreteprojects of mutual interest.
In the course such col-laborations, I expect research to unlock fundamentalnew insights about the nature of meaning, about itsdependence on perception, action, linguistic knowl-edge and social relationships, and about the archi-tecture of systems that can pick up on, create, andgeneralize meanings in their experience.
This pa-per offers an interim summary of my reflections onpreparing the next generation of scientists for thisendeavor.My efforts are anchored to the specific commu-nity where I work.
Semantics at Rutgers involves acore group of eight faculty from linguistics, philoso-phy and computer science, with a committed groupof about twice that many PhD students.
That?s threeor four students a year: not much if you?re think-ing of running a class for them, but pretty big if theaim is to place graduates, as we successfully haverecently, in positions where they can continue to dosemantics (that is, in academic research and tenure-track faculty jobs).
Interdisciplinary interaction isthe norm for our group; it means that each seman-tics project inevitably introduces the team to ques-tions, concepts and methodologies that lie outsidethe background expertise its members bring to theproject as individuals.
My own work is a good ex-129ample: papers like (DeVault et al, 2006) or (Lep-ore and Stone, 2007) reveal interconnections be-tween computational ideas and philosophical analy-sis that my colleagues and I discovered in attemptingto bridge our different perspectives on meaning andmeaningfulness.In my experience, what makes it possible for theseefforts to take up sophisticated computational ideasis not getting everyone up to speed with a spe-cific programming environment or linguistic formal-ism.
The key step is to get outsiders to appreciatethe arguments that computer scientists make, andwhy they make them.
Jeannette Wing (2006) callsthis Computational Thinking.
Wing argues that youshould have a course where you teach first-year col-lege students to think like computer scientists.
Buther arguments apply just as cogently to graduate stu-dents in the sciences, and to linguists in particu-lar.
Computation as a framework for data collec-tion, data analysis, inference, and explanation hasbecome the norm in the physical and life sciences,and is rapidly transforming the behavioral sciencesand especially now the environmental sciences.
Thesituation is not so different in the cultural fields ofmedia, arts and entertainment either?as video gamedesigners are quick to remind us.
A wide swathof researchers in any university are now interestedin supporting exploratory and innovative interdisci-plinary computing research, and specifically in train-ing future faculty to pursue and mentor such collab-orations.
We decided to make common cause withthem at Rutgers, since computational linguistics issuch a small group.
So our computer science depart-ment offers a general course called ComputationalThinking at the introductory graduate level, aimedat preparing researchers across fields to work oncollaborative projects involving computational re-search.
You have an opportunity to do the same.2 Overview of the CourseWe hold Computational Thinking in three hourblocks once a week.
This responds to Rutgers?squirky geography, with philosophy, linguistics andcomputer science each on different campuses alonga five-mile stretch of the main local thoroughfare,route 18.
Elsewhere, it might make more sense tomeet in more frequent, shorter sessions.Each meeting is divided so that students spendabout half of each lecture session (and half ofeach week?s work) on technical material drawnfrom the standard computer science curriculum.As outlined in Section 2.1, the technical mate-rial mixes programming practice, problem-solvingtechniques and theoretical tools, and aims to pro-vide the key elements that are needed to appre-ciate the computational considerations of an inter-disciplinary research project.
The typical formatof these sessions is live interactive literate pro-gramming.
We work in Scheme, supported bythe DrScheme system available at http://www.plt-scheme.org/software/drscheme/.
I beam an image ofthe Scheme development environment in front of theclass and write, run, analyze and debug short pro-grams on the fly.
Students follow along on their lap-tops, doing exercises, asking questions, and seeingresults as they go.The remainder of each class meeting (and the as-sociated outside coursework) explicitly focuses onthe interpretive effort and people skills required toreframe the ideas and methodologies of another fieldin computational terms.
Partly, as outlined in Sec-tion 2.2, that involves developing a shared under-standing of how computers accomplish the represen-tation, processing and problem solving they do, sothat students become comfortable at viewing com-putational systems abstractly as manipulating gen-erative scientific models and knowledge.
Funda-mentally this understanding is what enables an in-terdisciplinary team to reconcile the principles of anoutside field with the practice of computer science.In addition, as outlined in Section 2.3, we offer ex-plicit discussion of the conversational strategies andinteractive skills involved in bridging the differentperspectives of an interdisciplinary team, and over-coming the divides of disjoint academic cultures, thestresses of work and deadlines, and the many possi-bilities for misunderstanding.Homework mixes short benchmark problems,which allow students to assess their progress againstobjective standards, with open-ended collaborativeassignments that let students apply their domain ex-pertise and challenge their developing skills and pro-gramming, problem solving and teamwork.
Thisyear students worked individually on a set of exer-cises on list processing, matching of recursive struc-130tures, and interpreting programming languages de-signed to give some general competence in Scheme.Then they worked in teams of three to four to de-velop a web site using DrScheme?s Scheme servletarchitecture.
Finally, they explored the possibilitiesfor computational research in their home field in abrief speculative paper.The course has been offered twice, with about adozen students participating each session.
Three orfour each year?the expected number?come fromlinguistics and the philosophy of language.
Thesmall numbers nevertheless add up.
Already morethan half the students in this spring?s dissertationreading group in the philosophy of language hadtaken Computational Thinking.
The group?s focuswas context, and the related problems of commonground, presupposition, anaphora and accommoda-tion.
You could feel the difference ComputationalThinking made for many of the students, philoso-phers included, who succeeded not only in framingcomputational arguments about context and contextchange, but also in synthesizing computational con-cerns with philosophical ones in explaining linguis-tic interpretation in terms of context.2.1 Technical ideasThe technical goal of the course is to give stu-dents greater facility in stating problems in compu-tational terms and understanding and building so-lutions to computational problems.
The perspec-tive aligns with the online textbook How to DesignPrograms (Felleisen et al, 2001), which accompa-nies the Dr Scheme distribution, but we emphasizeits continuity with the general mathematical prob-lem solving that students have been doing since el-ementary school (Polya, 1945).
Indeed, followingWing (2006), we see computational thinking as or-dinary and pervasive.
?It?s not just the software andhardware artifacts we produce that will be physicallypresent everywhere and touch our lives all the time,it will be the computational concepts we use to ap-proach and solve problems, manage our daily lives,and communicate and interact with other people?
(Wing, 2006, p. 35).On our view, the main challenge of learning tothink like a computer scientist?or to argue withone?is the abstraction and flexibility you need.For example, modern machine learning techniquesamount to finding a solution to a problem that is par-tially specified in advance but partially determinedby empirical evidence that is available to the systembut not to the programmer.
Thus we teach compu-tational problem solving through case studies whoseinput and output gets progressively more and moreabstract and remote from the programmer.
The pro-gression is suggested by the following examples,which we cover either by developing solutions in in-class literate programming demonstrations or by as-signing them as programming projects.?
Answer a determinate mathematical question,but one whose size or complexity invites the useof an automatic tool in obtaining the results.
Thesieve of Eratosthenes is a representative case: listthe prime numbers less than 100.?
Answer a mathematical question parameterizedby an arbitrary and potentially open-ended input.Prototypical example: given a list of numbers de-termine its maximum element.?
Answer a mathematical question where the in-put needs to be understood as a generative, compo-sitional representation.
Given the abstract syntax ofa formula of propositional logic as a recursive liststructure and an interpretation assigning truth val-ues to the atomic proposition letters, determine thetruth value of the whole formula.?
Answer a question where the input needs tobe understood as the specification of a computation,and thus fundamentally similar in kind to the so-lution.
Write an interpreter for a simple program-ming language (a functional language, like a frag-ment of scheme; an imperative language involvingaction and state; or a logical language involving theconstruction of answer representations as in a pro-duction rule shell).?
Answer a mathematical question where the out-put may best be understood as the specification of acomputation, depending on input programs or data.A familiar case is taking the derivative of an inputfunction, represented as a Scheme list.
A richerexample that helps to suggest the optimization per-spective of machine learning algorithms is Huffmancoding.
Given a sequence of input symbols, comeup with programs that encode each symbol as a se-quence of bits and decode bit sequences as symbolsequences in such a way that the encoded sequence131is as short as possible.?
Answer a question where both input and outputneed to be understood as generative compositionalrepresentations with a computational interpretation.Reinforcement learning epitomizes this case.
Giventraining data of a set of histories of action in theworld including traces of perceptual inputs, outputsselected and reward achieved, compute a policy?a suitable function from perception to action?thatacts to maximize expected reward if the environmentcontinues as patterned in the training data.We go slowly, spending a couple weeks on eachcase, and treat each case as an opportunity to teach arange of important ideas.
Students see several usefuldata structures, including association lists (neededfor assignments of values to variables in logical for-mulas and program environments), queues (as anabstraction of data-dependent control in productionrules for example), and heaps (part of the infrastruc-ture for Huffman coding).
They get an introductionto classic patterns for the design of functional pro-grams, such as mapping a function over the elementsof a list, traversing a tree, accumulating results, andwriting helper functions.
They get some basic the-oretical tools for thinking about the results, such asmachine models of computation, the notion of com-putability, and measures of asymptotic complexity.Finally, they see lots of different kinds of represen-tations through which Scheme programs can encodeknowledge about the world, including mathemati-cal expressions, HTML pages, logical knowledgebases, probabilistic models and of course Schemeprograms themselves.The goal is to have enough examples that stu-dents get a sense that it?s useful and powerful tothink about computation in a more abstract way.Nevertheless, it?s clear that the abstraction involvedin these cases eventually becomes very difficult.There?s no getting around this.
When these stu-dents are working successfully on interdisciplinaryteams, we don?t want them struggling across dis-ciplines to encode specific facts on a case-by-casebasis.
We want them to be working collaborativelyto design tools that will let team members expressthemselves directly in computational terms and ex-plore their own computational questions.2.2 Interdisciplinary ReadingsThere is a rich literature in cognitive science whichreflects on representation and computation as expla-nations of complex behavior.
We read extensivelyfrom this literature throughout the course.
Engagingwith these primary sources helps students see howtheir empirical expertise connects with the mathe-matical principles that we?re covering in our techni-cal sessions.
It energizes our discussions of knowl-edge, representation and algorithms with provoca-tive examples of real-world processes and a dynamicunderstanding of the scientific questions involved inexplaining these processes as computations.For example, we read Newell and Simon?s fa-mous discussions of knowledge and problem solv-ing in intelligent behavior (Newell and Simon, 1976;Newell, 1982).
But Todd and Gigerenzer (2007)have much better examples of heuristic problemsolving from real human behavior, and much bet-ter arguments about how computational thinking andempirical investigation must be combined togetherto understand the problems that intelligent agentshave to solve in the real world.
Indeed, studentsshould expect to do science to find out what repre-sentations and computations the brain uses?that?swhy interdisciplinary teamwork is so important.
Weread Gallistel?s survey (2008) to get a sense of the in-creasing behavioral evidence from a range of speciesfor powerful and general computational mechanismsin cognition.
But we also read Brooks (1990) and hiscritics, especially Kirsh (1991), as a reminder thatthe final explanations may be surprising.We also spend a fair amount of time consider-ing how representations might be implemented inintelligent hardware?whether that hardware takesthe form of silicon, neurons, or even the hydraulicpipes, tinkertoys, dominoes and legos described byHillis (1999).
Hardware examples like Agre?s net-work models of prioritized argumentation for prob-lem solving and decision making (1997) demystifycomputation, and help to show why the knowledgelevel or symbol level is just an abstract, functionalcharacterization of a system.
Similarly, readingsfrom connectionism such as (Hinton et al, 1986)dramatize the particular ways that network mod-els of parallel representation and computation an-ticipate possible explanations in cognitive neuro-132science.
However, we also explore arguments thatsymbolic representations, even in a finite brain, maynot be best thought of as a prewired inventory of fi-nite possibilities (Pylyshyn, 1984).
Computationalcognitive science like Hofstadter?s (1979)?whichemphasizes the creativity that inevitably accompa-nies compositional representations and general com-putational capacity?is particularly instructive.
Inemphasizing the paradoxes of self-reference and thegenerality of Turing machines, it tells a plausiblebut challenging story that?s diametrically opposed tothe ?modular?
Zeitgeist of domain-specific adaptivecognitive mechanisms.2.3 CommunicationAnother tack to motivate course material and keepstudents engaged is to focus explicitly on interdis-ciplinary collaboration as a goal and challenge forwork in the course.
We read descriptions of more orless successful interdisciplinary projects, such as Si-mon?s description of Logic Theorist (1996) and Cas-sell?s account of interdisciplinary work on embod-ied conversational agents (2007).
We try to find ourown generalizations about what allowed these teamsto work together as well as they did, and what wecould do differently.In tandem, we survey social science researchabout what allows diverse groups to succeed inbridging their perspectives and communicating ef-fectively with one another.
Our sourcebook is Diffi-cult Conversations (Stone et al, 1999), a guidebookfor conflict resolution developed by the Harvard Ne-gotiation Project.
It can be a bit awkward to teachsuch personal material in a technical class, but manystudents are fascinated to explore suggestions aboutinteraction that work just as well for roommates andsignificant others as for interdisciplinary colleagues.Anyway, the practices of Difficult Conversations dofit with the broader themes of the class; they play outdirectly in the joint projects and collaborative dis-cussions that students must undertake to completethe class.I think it?s crucial to take collaboration seriously.For many years, we offered a graduate computer sci-ence course on computational linguistics as a firstinterdisciplinary experience.
We welcomed scien-tists from the linguistics, philosophy and library andinformation science departments, as well as engi-neers from the computer science and electrical andcomputer engineering departments, without expect-ing anyone to bring any special background to thecourse.
Nevertheless, we encouraged both individ-ualized projects and team projects, and worked tosupport interdisciplinary teams in particular.We were unsatisfied with this model based on itsresults.
We discovered that we hadn?t empoweredscience students to contribute their expertise effec-tively to joint projects, nor had we primed com-puter science students to anticipate and welcometheir contributions.
So joint projects found computerscientists doing too much translating and not enoughenabling for their linguist partners.
Linguists feltlike they weren?t pulling their weight or engagingwith the real issues in the field.
Computer scientistsgrew frustrated with the distance of their work fromspecific practical problems.Reading and reflecting on about generally-accessible examples goes a long way to bridge thedivide.
One case study that works well is the historyof Logic Theorist?the first implemented softwaresystem in the history of AI, for building proofs inthe propositional logic of Whitehead and Russell?sPrincipia Mathematica (1910).
In 1955?56, whenHerb Simon, Allen Newell and Cliff Shaw wroteit, they were actually an interdisciplinary team.
Si-mon was a social scientist trained at the Univer-sity of Chicago, now a full professor of business,at what seemed like the peak of a distinguished ca-reer studying human decisions in the managementof organizations.
Newell and Shaw were whiz-kidhackers?Newell was a Carnegie Tech grad studentinterested in software; Shaw was RAND corpora-tion staff and a builder of prototype research com-puters.
Their work together is documented in twofun chapters of Simon?s memoir Models of My Life(1996).
The story shows how computational col-laboration demands modest but real technical exper-tise and communication skills of all its practitioners.Reading the story early on helps students appreciatethe goal of the computational thinking class fromthe beginning: to instill these key shared concepts,experiences, attitudes and practices, and thereby toscaffold interdisciplinary technical research.To work together, Simon, Newell and Shawneeded to share a fairly specific understanding ofthe concept of a representation (Newell and Si-133mon, 1976).
Their work together consisted of tak-ing knowledge about their domain and regiment-ing it into formal structures and manipulations thatthey could actually go on to implement.
The frame-work they developed for conceptualizing this pro-cess rested on representations as symbolic struc-tures: formal objects which they could understandas invested with meaning and encoding knowledge,but which they could also realize in computer sys-tems and use to define concrete computational op-erations.
In effect, then, the concept of representa-tion defined their project together, and they all hadto master it.Simon, Newell and Shaw also needed a shared un-derstanding of the computational methodology thatwould integrate their different contributions into thefinal program.
Their work centered around the de-velopment of a high-level programming languagethat allowed Simon, Newell and Shaw to coordinatetheir efforts together in a particularly transparentway.
Simon worked in the programming language,using its abstract resources to specify formulas andrules of inference in intuitive but precise terms; onhis own, he could think through the effects of theseprograms.
Newell and Shaw worked to build theprogramming language, by developing the underly-ing machinery to realize the abstract computationsthat Simon was working with.
The programminglanguage was a product of their effort together; itsfeatures were negotiated based on Simon?s evolvingconceptual understanding of heuristic proof searchand Newell and Shaw?s engagement with the prac-tical demands of implementation.
The language isin effect a fulcrum where both domain expertise andcomputational constraints exercise their leverage onone another.
This perspective on language designcomes as a surprise both to scientists, who are usedto thinking of programming paradigms as remoteand arcane, and to computer scientists, who are usedto thinking of them solely in terms of their softwareengineering patterns, but it remains extremely pow-erful.
To make it work, everyone involved in the re-search has to understand how their judicious collab-orative exploration of new techniques for specifica-tion and programming can knit their work together.In the course of developing their language, Si-mon, Newell and Shaw also came to share a setof principles for discussing the computational fea-sibility of alternative design decisions.
Proof, likemost useful computational processes, is most natu-rally characterized as a search problem.
Inevitably,this meant that the development of Logic Theoristran up against the possibility of combinatorial explo-sions and the need for heuristics and approximationsto overcome them.
The solutions Simon, Newell andShaw developed reflected the team?s combined in-sight in constructing representations for proof searchthat made the right information explicit and affordedthe right symbolic manipulations.
Many in the class,especially computer scientists, will have seen suchideas in introductory AI courses, so it?s challeng-ing and exciting for them to engage with Simon?spresentation of these ideas in their original interdis-ciplinary context as new, computational principlesgoverning psychological explanations.Finally?and crucially?this joint effort reflectedthe team?s social engagement with each other, notjust their intellectual relationships.
In their decadesof work together, Simon and Newell cultivated andperfected a specific set of practices for engaging andsupporting each other in collaborative work.
Simonparticularly emphasizes their practice of open dis-cussion.
Their talk didn?t always aim directly atproblem-solving or design.
In the first instance, thetwo just worked towards understanding?distillingpotential insights into mutually-satisfying formula-tions.
They put forward vague and speculative ideas,and engaged with them constructively, not critically.Simon?s memoirs also bring out the respectthe teammates had for each others?
expertise andwork styles, especially when different?as Newell?sbrash, hands-on, late-night scheming was forSimon?and the shared commitment they broughtto making their work together fun.
Their good re-lationship as people may have been just as impor-tant to their success at interdisciplinary research asthe shared interests, ideas and intellectual techniquesthey developed together.These kinds of case studies allow students tomake sense of the goals and methods of the coursein advance of the technical and interpretive details.Not much has changed since Logic Theorist.
Effec-tive computational teamwork still involves develop-ing a conceptual toolbox that allows all participantson the project to formulate precise representationsand engage with those representations in computa-134tional terms.
And it still requires a more nuanced ap-proach to communication, interaction and collabora-tion than more homogeneous efforts?one focusednot just on solving problems and getting work donebut on fostering teammates?
learning and commu-nication, by addressing phenomena from multipleperspectives, building shared vocabulary, and find-ing shared values and satisfaction.
These skills areabstract and largely domain independent.
The classallows students to explore them.3 Interim AssessmentThe resources for creating our ComputationalThinking class came from the award of a train-ing grant designed to crossfertilize vision researchbetween psychology and computer science.
Thecourse has now become a general resource for ourcognitive science community.
It attracts psychol-ogists from across the cognitive areas, linguists,philosophers, and information scientists.
We alsomake sure that there is a critical mass of computerscientists to afford everyone meaningful collabora-tive experiences across disciplines.
For example,participation is required for training grant partici-pants from computer science, and other interdisci-plinary projects invite their computer science stu-dents to build community.One sign of the success of the course is that stu-dents take responsibility for shaping the course ma-terial to facilitate their own joint projects.
Our ini-tial version of the course emphasized the technicalideas and programming techniques described in Sec-tion 2.1.
Students asked for more opportunities forcollaboration; we added it right away in year one.Students also asked for more reading and discussionto get a sense of what computation brings to inter-disciplinary research, and what it requires of it.
Weadded that in year two, providing much of the ma-terials now summarized in Sections 2.2 and 2.3.
Ingeneral, we found concrete and creative discussionsaimed at an interdisciplinary audience more helpfulthan the general philosophical statements that com-puter scientists offer of the significance of computa-tion as a methodology.
We will continue to broadenthe reading list with down-to-earth materials cover-ing rich examples.From student feedback with the second runningof the class, the course could go further to get stu-dents learning from each other and working togetherearly on.
We plan to respond by giving an initialpretest to get a sense of the skills students bringto the class and pair people with partners of dif-fering skills for an initial project.
As always thisproject will provide a setting where all students ac-quire a core proficiency in thinking precisely aboutprocesses and representations.
But by connectingmore experienced programmers with novices fromthe beginning, we hope to allow students to ramp upquickly into hands-on exploration of specification,program design and collaborative computational re-search.
Possible initial projects include writing aproduction rule shell and using it to encode knowl-edge in an application of identifying visual objects,recognizing language structure, diagnosing causesfor observed phenomena or planning goal-directedactivity; or writing an interpreter to evaluate math-ematical expressions and visualize the shapes ofmathematical objects or probabilistic state spaces.Anecdotally, we can point to a number of caseswhere Computational Thinking has empowered stu-dents to leverage computational methods in theirown research.
Students have written programs tomodel experimental manipulations, analyze data, orwork through the consequences of a theory, whereotherwise they would have counted on pencil-and-paper inference or an off-the-shelf tool.
However, asyet, we have only a preliminary sense of how wellthe course is doing at its goal of promoting com-putational research and collaboration in the cogni-tive science community here.
Next year we will getour first detailed assessment, however, with the firstoffering of a new follow-on course called ?Inter-disciplinary Methods in Perceptual Science?.
Thiscourse explicitly requires students to team up inextended projects that combine psychological andcomputational methods for visual interaction.
Wewill be watching students?
experience in the newclass closely to see whether our curriculum supportsthem in developing the concepts, experiences, atti-tudes and practices they need to work together.4 ConclusionTeamwork in computational linguistics often startsby endowing machine learning methods with mod-135els or features informed by the principles and re-sults of linguistic theory.
Teams can also worktogether to formalize linguistic knowledge and in-terpretation for applications, through grammar de-velopment and corpus annotation, in ways that fitinto larger system-building efforts.
More generally,we need to bridge the science of conversation andsoftware architecture to program interactive systemsthat exhibit more natural linguistic behavior.
Andwe can even bring computation and linguistics to-gether outside of system building: pursuing compu-tational theories as an integral part of the explanationof human linguistic knowledge and behavior.To work on such teams, researchers do have tomaster a range of specific intellectual connections.But they need the fundamentals first.
They haveto appreciate the exploratory nature of interdisci-plinary research, and understand how such work canbe fostered by sharing representational insight, de-signing new high-level languages and thinking crit-ically about computation.
Computational Thinkingis our attempt to teach the fundamentals directly.You should be find it easy to make a case for thiscourse at your institution.
In these days of declin-ing enrollments and interdisciplinary fervor, mostdepartments will welcome a serious effort to culti-vate the place of CS as a bridge discipline for re-search projects across the university.
ComputationalThinking is a means to get more students taking ourclasses and drawing on our concepts and discoveriesto work more effectively with us!
As the course sta-bilizes, we plan to reach out to other departmentswith ongoing computational collaborations, espe-cially economics and the life and environmental sci-ences departments.
You could design the coursefrom the start for the full spectrum of computationalcollaborations already underway at your university.AcknowledgmentsSupported by IGERT 0549115.
Thanks to the stu-dents in 198:503 and reviewers for the workshop.ReferencesPhilip E. Agre.
1997.
Computation and Human Experi-ence.
Cambridge.Rodney A. Brooks.
1990.
Elephants don?t play chess.Robotics and Autonomous Systems, 6:3?15.Justine Cassell.
2007.
Body language: Lessons fromthe near-human.
In J. Riskin, editor, Genesis Redux:Essays in the History and Philosophy of Artificial In-telligence, pages 346?374.
Chicago.David DeVault, Iris Oved, and Matthew Stone.
2006.
So-cietal grounding is essential to meaningful languageuse.
In Proceedings of AAAI, pages 747?754.Matthias Felleisen, Robert Bruce Findler, Matthew Flatt,and Shriram Krishnamurthi.
2001.
How to DesignPrograms: An Introduction to Computing and Pro-gramming.
MIT.C.
R. Gallistel.
2008.
Learning and representation.
InJohn H. Byrne, editor, Learning and Memory: A Com-prehensive Reference.
Elsevier.W.
Daniel Hillis.
1999.
The Pattern on the Stone.
BasicBooks.Geoffrey E. Hinton, David E. Rumelhart, and James L.McClelland.
1986.
Distributed representations.
InParallel Distributed Processing: Explorations in theMicrostructure of Cognition, Volume 1: Foundations,pages 77?109.
MIT.Douglas Hofstadter.
1979.
Go?del, Escher, Bach: AnEternal Golden Braid.
Basic Books.David Kirsh.
1991.
Today the earwig, tomorrow man?Artificial Intelligence, pages 161?184.Ernest Lepore and Matthew Stone.
2007.
Logic and se-mantic analysis.
In Dale Jacquette, editor, Handbookof the Philosophy of Logic, pages 173?204.
Elsevier.Allen Newell and Herbert A. Simon.
1976.
Computerscience as empirical inquiry: Symbols and search.Communications of the ACM, 19(3):113?126.Allen Newell.
1982.
The knowledge level.
ArtificialIntelligence, 18:87?127.G.
Polya.
1945.
How to Solve it.
Princeton.Zenon Pylyshyn.
1984.
Computation and Cognition: To-ward a Foundation for Cognitive Science.
MIT.Herbert A. Simon, 1996.
Models of My Life, chapterRoots of Artificial Intelligence and Artificial Intelli-gence Achieved, pages 189?214.
MIT.Douglas Stone, Bruce Patton, and Sheila Heen.
1999.Difficult Conversations: How to Discuss What MattersMost.
Penguin.Peter M. Todd and Gerd Gigerenzer.
2007.
Environ-ments that make us smart: Ecological rationality.
Cur-rent Directions in Psych.
Science, 16(3):170?174.Alfred North Whitehead and Bertrand Russell.
1910.Principia Mathematica Volume 1.
Cambridge.Jeannette M. Wing.
2006.
Computational thinking.Communications of the ACM, 49(3):33?35.136
