Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1020?1028,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsSyntactic/Semantic Structures for Textual Entailment RecognitionYashar MehdadFBK-IRST, DISIUniversity of TrentoPovo (TN) - Italymehdad@fbk.euAlessandro MoschittiDISIUniversity of TrentoPovo (TN) - Italymoschitti@disi.unitn.itFabio Massimo ZanzottoDISPUniversity of Rome ?Tor Vergata?Roma - Italyzanzotto@info.uniroma2.itAbstractIn this paper, we describe an approach basedon off-the-shelf parsers and semantic re-sources for the Recognizing Textual Entail-ment (RTE) challenge that can be generallyapplied to any domain.
Syntax is exploitedby means of tree kernels whereas lexical se-mantics is derived from heterogeneous re-sources, e.g.
WordNet or distributional se-mantics through Wikipedia.
The joint syn-tactic/semantic model is realized by means oftree kernels, which can exploit lexical related-ness to match syntactically similar structures,i.e.
whose lexical compounds are related.
Thecomparative experiments across different RTEchallenges and traditional systems show thatour approach consistently and meaningfullyachieves high accuracy, without requiring anyadaptation or tuning.1 IntroductionRecognizing Textual Entailment (RTE) is ratherchallenging as effectively modeling syntactic andsemantic for this task is difficult.
Early deep seman-tic models (e.g., (Norvig, 1987)) as well as more re-cent ones (e.g., (Tatu and Moldovan, 2005; Bos andMarkert, 2005; Roth and Sammons, 2007)) rely onspecific world knowledge encoded in rules for draw-ing decisions.
Shallower models exploit matchingmethods between syntactic/semantic graphs of textsand hypotheses (Haghighi et al, 2005).
The match-ing step is carried out after the application of somelexical-syntactic rules that are used to transform thetext T or the hypothesis H (Bar-Haim et al, 2009)at surface form level.
For all these methods, the ef-fective use of syntactic and semantic information de-pends on the coverage and the quality of the specificrules.
Lexical-syntactic rules can be automaticallyextracted from plain corpora (e.g., (Lin and Pantel,2001; Szpektor and Dagan, 2008)) but the quality(also in terms of little noise) and the coverage is low.In contrast, rules written at the semantic level aremore accurate but their automatic design is difficultand so they are typically hand-coded for the specificphenomena.In this paper, we propose models for effectivelyusing syntactic and semantic information in RTE,without requiring either large automatic rule acqui-sition or hand-coding.
These models exploit lexi-cal similarities to generalize lexical-syntactic rulesautomatically derived by supervised learning meth-ods.
In more detail, syntax is encoded in the form ofparse trees whereas similarities are defined by meansof WordNet simlilarity measures or Latent Seman-tic Analysis (LSA) applied to Wikipedia or to theBritish National Corpus (BNC).
The joint syntac-tic/semantic model is realized by means of novel treekernels, which can match subtrees whose leaves arelexically similar (so not just identical).To assess the benefit of our approach, we carriedout comparative experiments with previous work:especially with the method described in (Zanzottoand Moschitti, 2006; Zanzotto et al, 2009).
Thisconstitutes our strong baseline as, although it canonly exploit lexical-syntactic rules, it has achievedtop accuracy in all RTE challenges.
The results,across different RTE challenges, show that our ap-proach constantly and significantly improves the1020baseline model.
Moreover, our approach does notrequire any adaptation or tuning and uses a compu-tation for the similarity function based on Wikipediawhich is faster than the computation of tools basedon WordNet or other resources (Basili et al, 2006).The remainder of the paper is organized as fol-lows: Section 2 critically reviews the previous workby highlighting the need of generalizing lexico-syntactic rules.
Section 3 describes lexical similar-ity approaches, which can serve the generalizationpurpose.
Section 4 describes how to integrate lex-ical similarity in syntactic structures using syntac-tic/semantic tree kernels (SSTK) whereas Section 5shows how to use SSTK in a kernel-based RTE sys-tem.
Section 6 describes the experiments and re-sults.
Section 7 discusses the efficiency and accu-racy of our system compared with other RTE sys-tems.
Finally, we draw the conclusions in Section8.2 Related workLexical-syntactic rules are largely used in textual en-tailment recognition systems (e.g., (Bar-Haim et al,2007; Dinu and Wang, 2009)) as they convenientlyencode world knowledge into linguistic structures.For example, to decide whether the simple sentencesare in the entailment relation:T2 ?
?H2T2 ?In 1980 Chapman killed Lennon.
?H2 ?John Lennon died in 1980.?we need a lexical-syntactic rule such as:?3 = XkilledY ?
Ydiedalong with such rules, the temporal informationshould be taken into consideration.Given the importance of lexical-syntactic rules inRTE, many methods have been proposed for theirextraction from large corpora (e.g., (Lin and Pantel,2001; Szpektor and Dagan, 2008)).
Unfortunately,these unsupervised methods in general produce rulesthat can hardly be used: noise and coverage are themost critical issues.Supervised approaches were experimented in(Zanzotto and Moschitti, 2006; Zanzotto et al,2009), where lexical-syntactic rules were derivedfrom examples in terms of complex relational fea-tures.
This approach can easily miss some usefulinformation and rules.
For example, given the pair?T2,H2?, to derive the entailment value of the fol-lowing case:T4 ?
?H4T4 ?In 1963 Lee Harvey Oswald mur-dered JFK?H4 ?JFK died in 1963?we can only rely on this relatively interestinglexical-syntactic rule (i.e.
which is in common be-tween the two examples):?5 = (V P (V BZ)(NP X )) ?
(S(NP X )(V P (V BZ died)))Unfortunately, this can be extremely misleadingsince it also derives similar decisions for the follow-ing example:T6 ?
?H6T6 ?In 1956 JFK met Marilyn Monroe?H6 ?Marilyn Monroe died in 1956?The problem is that the pairs ?T2,H2?
and?T4,H4?
share more meaningful features than therule ?5, which should make the difference with re-spect to the relation between the pairs ?T2,H2?
and?T6,H6?.
Indeed, the word ?kill?
is more semanti-cally related to ?murdered?
than to ?meet?.
Usingthis information, it is possible to derive more effec-tive rules from training examples.There are several solutions for taking this infor-mation into account, e.g.
by using FrameNet se-mantics (e.g., like in (Burchardt et al, 2007)), it ispossible to encode a lexical-syntactic rule using theKILLING and the DEATH frames, i.e.
:?7 = KILLING(Killer :X ,V ictim : Y ) ?DEATH(Protagonist : Y )However, to use this model, specific rules and asemantic role labeler on the specific corpora areneeded.3 Lexical similaritiesPrevious research in computational linguistics hasproduced many effective lexical similarity mea-sures based on many different resources or corpora.For example, WordNet similarities (Pedersen et al,2004) or Latent Semantic Analysis over a large cor-pus are widely used in many applications and for1021the definition of kernel functions, e.g.
(Basili et al,2006; Basili et al, 2005; Bloehdorn et al, 2006).In this section we present the main component ofour new kernel, i.e.
a lexical similarity derived fromdifferent resources.
This is used inside the syntac-tic/semantic tree kernel defined in (Bloehdorn andMoschitti, 2007a; Bloehdorn and Moschitti, 2007b)to enhance the basic tree kernel functions.3.1 WordNet SimilaritiesWordNet similarities have been heavily used in pre-vious NLP work (Chan and Ng, 2005; Agirre et al,2009).
All WordNet similarities apply to pairs ofsynonymy sets (synsets) and return a value indicat-ing their semantic relatedness.
For example, the fol-lowing measures, that we use in this study, are basedon path lengths between concepts in the Wordnet Hi-erarchy:Path the measure is equal to the inverse of theshortest path length (path length) between twosynsets c1 and c2 in WordNetSimPath =1path length(c1, c2)(1)WUP the Wu and Palmer (Wu and Palmer, 1994)similarity metric is based on the depth of two givensynsets c1 and c2 in the WordNet taxonomy, and thedepth of their least common subsumer (lcs).
Theseare combined into a similarity score:SimWUP =2?
depth(lcs)depth(c1) + depth(c2)(2)Wordnet similarity measures on synsets can beextended to similarity measures between words asfollows:?S(w1, w2) = max(c1,c2)?C1?C2SimS(c1, c2)(3)where S is Path or WUP and Ci is the set of thesynsets related to the word wi.3.2 Distributional Semantic SimilarityLatent Semantic Analysis (LSA) is one of thecorpus-based measure of distributional semanticsimilarity, proposed by (Landauer et al, 1998).Words ~wi are represented in a document space.
Eachfeauture is a document and its value is the frequencyof the word in the document.
The similarity is gen-erally computed as a cosine similarity:?LSI(w1, w2) =~w1 ~w2|| ~w1|| ?
|| ~w2||(4)In our approach we define a proximity matrix Pwhere pi,j represents ?LSI(wi, wj) The core of ourapproach lies on LSI (Latent Semantic Indexing)over a large corpus.
We used singular value de-composition (SVD) to build the proximity matrixP = DDT from a large corpus, represented by itsword-by-document matrix D.SVD decomposes D (weighted matrix of termfrequencies in a collection of text) into three matri-ces U?V T , where U (matrix of term vectors) andV (matrix of document vectors) are orthogonal ma-trices whose columns are the eigenvectors of DDTand DTD respectively, and ?
is the diagonal matrixcontaining the singular value of D.Given such decomposition, P can be obtained asUk?2kUTk , where Uk is the matrix containing the firstk columns of U and k is the dimensionality of thelatent semantic space.
This is efficiently used to re-duce the memory requirements while retaining theinformation.
Finally we computed the term simi-larity using the cosine measure in the vector spacemodel (VSM).Generally, LSA can be observed as a way to over-come some of the drawbacks of the standard vectorspace model, such as sparseness and dimensionality.In other words, the LSA similarity is computed ina lower dimensional space, in which second-orderrelations among words and documents are exploited(Mihalcea et al, 2006).It is worth mentioning that the LSA similaritymeasure depends on the selected corpus but it ben-efits from a higher computation speed in compari-son to the construction of the similarity matrix basedon the WordNet Similarity package (Pedersen et al,2004).4 Lexical similarity in Syntactic TreeKernelsSection 2 has shown that the role of the syntax is im-portant in extracting generalized rules for RTE but itis not enough.
Therefore, the lexical similarity de-scribed in the previous section should be taken into1022SPPINCD1963NPNNPLeeNNPHarveyNNPOswaldVPVBNmurderedNNPJFK?SPPINCDNP VPVBNmurderedNNPSPPINCDNP VPVBN NNPSPPINNP VPVBN NNPVPVBNmurderedNNPJFKVPVBNmurderedNNPVPVBN NNPJFKVPVBNkilledNNPKennedyFigure 1: A syntactic parse tree (on the left) along with some of its fragments.
After the bar there is an importantfragment from a semantically similar sentence, which cannot be matched by STK but it is matched by SSTK.account in the model definition.
Since tree kernelshave been shown to be very effective for exploit-ing syntactic information in natural language tasks, apromising idea is to merge together the two differentapproaches, i.e.
tree kernels and semantic similari-ties.4.1 Syntactic Tree Kernel (STK)Tree kernels compute the number of common sub-structures between two trees T1 and T2 without ex-plicitly considering the whole fragment space.
Thestandard definition of the STK, given in (Collins andDuffy, 2002), allows for any set of nodes linked byone or more entire production rules to be valid sub-structures.
The formal characterization is given in(Collins and Duffy, 2002) and is reported hereafter:Let F = {f1, f2, .
.
.
, f|F|} be the set of treefragments and ?i(n) be an indicator function,equal to 1 if the target fi is rooted at node nand equal to 0 otherwise.
A tree kernel func-tion over T1 and T2 is defined as TK(T1, T2) =?n1?NT1?n2?NT2?
(n1, n2), where NT1 and NT2are the sets of nodes in T1 and T2, respectively and?
(n1, n2) =?|F|i=1 ?i(n1)?i(n2).?
function counts the number of subtrees rootedin n1 and n2 and can be evaluated as follows:1. if the productions at n1 and n2 are differentthen ?
(n1, n2) = 0;2. if the productions at n1 and n2 are the same,and n1 and n2 have only leaf children (i.e.
theyare pre-terminal symbols) then ?
(n1, n2) = ?;3.
if the productions at n1 and n2 are the same,and n1 and n2 are not pre-terminals then?
(n1, n2) = ?
?l(n1)j=1 (1 + ?
(cn1(j), cn2(j))),where l(n1) is the number of children of n1,cn(j) is the j-th child of node n and ?
is a de-cay factor penalizing larger structures.Figure 1 shows some fragments (out of the over-all 472) of the syntactic parse tree on the left, whichis derived from the text T4.
These fragments sat-isfy the constraint that grammatical rules cannot bebroken.
For example, (VP (VBN (murdered) NNP(JFK))) is a valid fragment whereas (VP (VBN (mur-dered)) is not.
One drawback of such kernel is thattwo sentences expressing similar semantics but withdifferent lexicals produce structures which will notbe matched.
For example, after the vertical barthere is a fragment, extracted from the parse treeof a semantically identical sentences: In 1963Oswald killed Kennedy.
In this case, muchless matches will be counted by the kernel functionapplied to such parse trees and the one of T4.
In par-ticular, the complete VP subtree will not be matched.To tackle this problem the Syntactic SemanticTree Kernel (SSTK) was defined in (Bloehdorn andMoschitti, 2007a); hereafter, we report its definition.4.2 Syntactic Semantic Tree kernels (SSTK)An SSTK produces all the matches of STK.
More-over, the fragments, which are identical but for theirlexical nodes, produce a match proportional to theproduct of the similarity between their correspond-ing words.
This is a sound definition.
Indeed, sincethe structures are the same, each word in position iof the first fragment can be associated with a wordlocated in the same position i of the second frag-ment.
More formally, the fast evaluation of ?
forSTK can be used for computing the semantic ?
forSSTK by simply adding the following step0.
if n1 and n2 are pre-terminals and label(n1) =label(n2) then ?
(n1, n2) = ?
?S(ch1n1 , ch1n2),where label(ni) is the label of node ni and ?S isa term similarity kernel, e.g.
based on Wikipedia,Wordnet or BNC, defined in Section 3.
Note that:(a) since n1 and n2 are pre-terminals of a parse tree1023they can have only one child (i.e.
ch1n1 and ch1n2 )and such children are words and (b) Step 2 of theoriginal ?
evaluation is no longer necessary.For example, the fragments: (VP (VBN (murdered)NNP (JFK))) has a match with (VP (VBN (killed)NNP (Kennedy))) equal to ?S(murdered, kill) ?
?S(JFK,Kennedy).Beside the novelty of taking into account treefragments that are not identical it should be notedthat the lexical semantic similarity is constrainedin syntactic structures, which limit errors/noise dueto incorrect (or, as in our case, not provided) wordsense disambiguation.Finally, it should be noted that when a valid ker-nel is used in place of ?S , SSTK is a valid kernel fordefinition of convolution kernels (Haussler, 1999).Since the matrix P derived by applying LSA pro-duces a semi-definite matrix (see (Cristianini andHolloway, 2001)) we can always use the similaritymatrix derived by LSA in SSTK.
In case of Wordnet,the validity of the kernel will depend of the kind ofsimilarity used.
In our experiments, we have carriedout single value decomposition and we have verifiedthat our Wordenet matrices, Path and WUP, are in-deed positive semi-definite.5 Kernels for Textual EntailmentRecognitionIn this section, we describe how we use the syntac-tic tree kernel (STK) and the semantic/syntactic treekernel (SSTK) for modeling lexical-syntactic ker-nels for textual entailment recognition.
We buildon the kernel described in (Zanzotto and Moschitti,2006; Zanzotto et al, 2009) that can model lexical-syntactic rules with variables (i.e., first-order rules).5.1 Anchoring and pruningKernels for modeling lexical-syntactic rules withvariables presuppose that words in texts T are ex-plicitly related to words in hypotheses H .
This cor-relation is generally called anchoring and it is imple-mented with placeholders that co-index the syntactictrees derived from T and H .
Words and intermediatenodes are co-indexed when they are equal or similar.For example, in the pair:T8 ?
?H8T8 ?Lee Harvey Oswald was born inNew Orleans, Louisiana, and wasof English, German, French andIrish ancestry.
In 1963 1 Oswaldmurdered JFK 2 ?H8 ?JFK 2 died in 1963 1 ?Moreover, the set of anchors also allows us toprune fragments of the text T that are irrelevantfor the final decision: we can discard sentencesor phrases uncovered by placeholders.
For exam-ple, in the pair ?T8,H8?, we can infer that ?LeeH.
.
.
ancestry?
is not a relevant fragment and removeit.
This allows us to focus on the critical part for de-termining the entailment value.5.2 Kernels for capturing lexical-syntacticrulesOnce placeholders are available in the entailmentpairs, we can apply the model proposed in (Zan-zotto et al, 2009).
This derives the maximal simi-larity between pairs of T and H based on the lexico-syntactic information encoded by the syntactic parsetrees of T and H enriched with placeholders.
Moreformally, the original kernel is based on the follow-ing equation:maxSTK(?T,H?, ?T ?, H ??)
= maxc?C (5)(STK(t(T, c), t(T ?, i)) + STK(t(H, c), t(H ?, i)),where: (i) C is the set of all bijective mappings be-tween the placeholders (i.e., the possible variables)from ?T,H?
into ?T ?,H ??
; (ii) c ?
C is a substitu-tion function, which implements such mapping; (iii)t(?, c) returns the syntactic tree enriched with place-holders replaced by means of the substitution c; and(iv) STK(?1, ?2) is a tree kernel function.The new semantic-syntactic kernel for lexical-syntactic rules, maxSSTK, substitutes STK withSSTK in Eq.
5 thus enlarging the coverage of thematching between the pairs of texts and the pairs ofhypotheses.6 ExperimentsThe aim of the experiments is to investigate if ourRTE system exploiting syntactic semantic kernels(SSTK) can effectively derive generalized lexico-syntactic rules.
In more detail, first, we determinethe best lexical similarity suitable for the task, i.e.1024No Semantic Wiki BNC Path WUPRTE2 j = 1 63.12 63.5 62.75 62.88 63.88j = 0.9 63.38 64.75 62.26 63.88 64.25RTE3 j = 1 66.88 67.25 67.25 66.88 66.5j = 0.9 67.25 67.75 67.5 67.12 67.38RTE5 j = 1 65.5 66.5 65.83 66 66j = 0.9 65.5 66.83 65.67 66 66.33Table 1: Accuracy of plain (WOK+STK+maxSTK) and Semantic Lexico-Syntactic (WOK+SSTK+maxSSTK) Ker-nels.
The latter according to different similaritiesdistributional vs. Wordnet-based approaches.
Sec-ond, we derive qualitative and quantitative proper-ties, which justify the selection of one with respectto the other.For this purpose, we tested four different versionof SSTK, i.e.
using Path, WUP, BNC and WIKIlexical similarities on three different RTE datasets.These correspond to the three different challenges inwhich the development set was provided.6.1 Experimental SetupWe used the data from three recognizing textual en-tailment challenge: RTE2 (Bar-Haim et al, 2006),RTE3 (Giampiccolo et al, 2007), and RTE5, alongwith the standard split between training and test sets.We did not use RTE1 as it was differently built fromthe others and RTE4 as it does not contain the devel-opment set.We used the following publicly available tools:the Charniak Parser (Charniak, 2000) for pars-ing sentences and SVM-light-TK (Moschitti, 2006;Joachims, 1999), in which we coded our new kernelsfor RTE.
Additionally, we used the Jiang&Conrath(J&C) distance (Jiang and Conrath, 1997) com-puted with wn::similarity package (Pedersenet al, 2004) to measure the similarity between T andH .
This similarity is also used to define the text-hypothesis word overlap kernel (WOK).The distributional semantics is captured by meansof LSA: we used the java Latent Semantic Indexing(jLSI) tool (Giuliano, 2007).
In particular, we pre-computed the word-pair matrices for RTE2, RTE3,and RTE5.
We built different LSA matrices fromthe British National Corpus (BNC) and Wikipedia(Wiki).
The British National Corpus (BNC) is a bal-anced synchronic text corpus containing 100 mil-lion words with morpho-syntactic annotation.
ForWikipedia, we created a model from the 200,000most visited Wikipedia articles, after cleaning theunnecessary markup tags.
Articles are our doc-uments for creating the term-by-document matrix.Wikipedia provides the largest coverage knowledgeresource developed by a community, besides the no-ticeable coverage of named entities.
This furthermotivates the design of a similarity measure.
Wealso consider two typical WordNet similarities (i.e.,Path and WUP, respectively) as described in Sec.3.1.The main RTE model that we consider is consti-tuted by three main kernels:?
WOK, i.e.
the kernel based on only the text-hypothesis lexical overlapping words (this is anintra-pair similarity);?
STK, i.e.
the sum of the standard tree kernel(see Section 4.1) applied to the two text parse-trees and the two hypothesis parse trees;?
SSTK, i.e.
the same as STK with the use oflexical similarities as explained in Section 4.2;?
maxSTK and maxSSTK, i.e.
the kernel forRTE, illustrated in Section 5.2, where the lat-ter exploits similarity since it uses SSTK in Eq.5.Note that the model presented in (Zanzotto et al,2009), our baseline, corresponds to the combinationkernel: WOK+maxSTK.
In this paper, in addition tothe role of lexical similarities, we also study severalcombinations (we just need to sum the separated ker-nels), i.e.
WOK+STK+maxSTK, SSTK+maxSSTK,WOK+SSTK+maxSSTK and WOK+maxSSTK.Finally, we measure the performance of our sys-tem with the standard accuracy and then we deter-mine the statistical significance by using the model1025STK SSTK maxSTK maxSSTK STK+maxSTK SSTK+maxSSTK ?RTE2 +WOK 61.5 61.12 63.88 64.12 63.12 63.50 60.6252.62 52.75 61.25 59.38 61.25 58.75 -RTE3 +WOK 66.38 66.5 66.5 67.0 66.88 67.25 66.7553.25 54.5 62.25 64.38 63.12 63.62 -RTE5 +WOK 62.0 62.0 64.83 64.83 65.5 66.5 60.6754.33 57.33 63.33 62.67 61.83 62.67 -Table 2: Comparing different lexico-syntactic kernels with Wiki-based semantic kernelsdescribed in (Yeh, 2000) and implemented in (Pado?,2006).6.2 Distributional vs. WordNet-basedSemanticsThe first experiment compares the basic kernel, i.e.WOK+STK+maxSTK, with the new semantic ker-nel, i.e.
WOK+SSTK+maxSSTK, where SSTKand maxSSTK encode four different kinds of sim-ilarities, BNC, WIKI, WUP and Path.
The aimis twofold: understanding if semantic similaritiescan be effectively used to derive generalized lexico-syntactic rules and to determine the best similaritymodel.Table 1 shows the results according to No Seman-tics, Wiki, BNC, Path and WUP.
The three pairs ofrows represent the results over the three differentdatasets, i.e., RTE2, RTE3, and RTE5.
For eachpair, we have two rows representing a different jparameter of SVM.
An increase of j augments theweight of positive with respect to negative examplesand during learning it tunes-up the Recall/Precisionrate.
We use two values j = 1 (the default value)and j = 0.9 (selected during a preliminary experi-ment on a validation set on RTE2).
j = 0.9 was usedto minimally increase the Precision, considering thatthe semantic model tends to improve the Recall.The results show that:?
WIKI semantics constantly improves the basickernel (no Semantics) for any datasets or pa-rameter.?
The distributional semantics is almost alwaysbetter than the WordNet-based one.?
In one case WUP improves WIKI, i.e.
63.88 vs63.5 and in another case BNC reaches WIKI,i.e.
67.25 but this happens for the default valuesof the j parameters, i.e.
j = 1, which was notselected by our limited parameter validation.Finally, the difference between the accuracy of thebest WIKI kernels and the No Semantic kernels arestatistically significant (p << 0.05).6.3 Kernel ComparisonsThe previous experiments (Sec.
6.2) show thatWikipedia-based distributional semantics providesan effective similarity to generalize lexico-syntacticrules (features).
As our RTE kernel is a compositionof other basic kernels, we experimented with dif-ferent combinations to understand the role of eachcomponent.
Moreover, to obtain results independentof parameterization we used the default parameter j.Table 2 reports the accuracy of different kernelsand their combinations on different RTE datasets.Each row describes the results for each dataset andit is split in two according to the use of WOK or notin the RTE model.
In the each column, the differentkernels are reported.
For example, the entry in the4th column and the 2nd row refers to the accuracy ofSSTK in combination with WOK, i.e.
WOK+SSTKfor the RTE2.We observe that: first WOK produces a very highaccuracy in RTE challenges, i.e.
60.62, 66.75 and60.67 and it is an essential component of RTE sys-tems since its ablation always causes a large accu-racy decrease.
This is reasonable as the major sourceof information to establish entailment between sen-tences is their word overlap.Second, STK and SSTK, when added to WOK,improve it on RTE2 and RTE5 but do not improveit on RTE3.
This suggests a difficulty of exploitingsyntactic information for RTE3.Third, maxSTK+WOK relevantly improvesWOK on RTE2 and RTE5 but fails in RTE3.
Again,the syntactic rules (with variables) which this kernel1026BNC WN WIKIRTE2 0.55 0.42 0.83RTE3 0.54 0.41 0.83RTE5 0.45 0.34 0.82Table 3: Coverage of the different resources for the wordsof the three datasetscan provide are not enough general for RTE3.
Incontrast, maxSSTK+WOK improves WOK on alldatasets thanks to its generalization ability.Finally, STK and SSTK added to maxSTK+WOKor to maxSSTK+WOK tend to produce an accuracyincrease, although not in every condition.7 Discussion7.1 Coverage and efficiencyAs already mentioned, the practical use ofWikipedia to design lexical similarities is motivatedby a large coverage.
Deriving similarities from otherresources such as WordNet is more time-consuming.To prove our claim, we performed an analysis on thecoverage and efficiency in computing the pair termsimilarity.Table 3 shows the coverage of the content wordsof the three datasets.
The coverage of Wikipedia isabout two times more than the other resources in allexperimented datasets.Speed MillisecondsLSA 0.54WN with POS 5.3WN without POS 15.2Table 4: The comparison in terms of speed calculatedover 10000 pairs after loading the model.Moreover, Table 4 shows that the computationof the LSA matrix on Wikipedia is faster than us-ing the WordNet similarity software (Pedersen et al,2004).
Even if the accuracy of some WordNet mod-els can reach the one based on Wikipedia, the latteris preferable for the smaller computational cost.7.2 Comparison with previous workThe results of our models show that lexical se-mantics for building more effective lexical-syntacticrules is promising.
Here, we compare our ap-proaches with other RTE systems to show that ourAverage Acc.
Our rank # participantsRTE2 59.8 3rd 23RTE3 64.5 4th 26RTE5 61.5 4th 20Table 5: Comparison with other approaches to RTEresults are indeed state-of-the-art.
Unfortunately,deriving a reasonable accuracy value to represent thestate-of-the-art is extremely difficult as many fac-tors can determine the final score.
For example, thebest systems in RTE2 and RTE3 (Giampiccolo et al,2007) have an accuracy 10% higher than the othersbut they generally use resources that are not publiclyavailable.Table 5 shows the average accuracy of the partici-pant systems, the rank of our system that we proposein this paper and the number of participants.
Ourmodel accuracy is absolutely above the average andit is ranked at the top positions.
We can also carryout a finer comparison with respect to RTE2 (Bar-Haim et al, 2006).
Our system results are the bestwhen compared with systems using semantic mod-els based on FrameNet, indeed the best ranked sys-tem in this class, i.e., (Burchardt et al, 2007), scoresonly 62.5.
Among systems using logical inference,our model is instead the 3rd out of 8 systems usinglogical inference that perform worse than ours.
Fi-nally, it is the 2nd among systems using supervisedmachine learning models.8 ConclusionIn this paper we presented a model to effectively in-clude semantics in lexical-syntactic features for tex-tual entailment recognition.
We have experimentallyshown that LSA-derived lexical semantics embed-ded in syntactic structures is a promising approach.The model that we have presented is one of thebest system in the RTE challenges.
Additionally, incontrast to many other methods it does not requirelarge sets of handcrafted or corpus extracted lexical-syntactic rules.AcknowledgementsThe research of Alessandro Moschitti has been par-tially supported by Trustworthy Eternal Systems viaEvolving Software, Data and Knowledge (EternalS,project number FP7 247758).1027ReferencesE.
Agirre, E. Alfonseca, K. Hall, J. Kravalova, M. Pas?ca,and A. Soroa.
2009.
A study on similarity and re-latedness using distributional and wordnet-based ap-proaches.
In NAACL ?09: Proc.
HLT/NAACL.R.
Bar-Haim, I. Dagan, B. Dolan, L. Ferro, D. Giampic-colo, and I. Magnini, B. Szpektor.
2006.
The iiPASCAL recognising textual entailment challenge.
InProc.
of the II PASCAL Challenges Workshop.R.
Bar-Haim, I. Dagan, I. Greental, and E. Shnarch.2007.
Semantic inference at the lexical-syntactic level.In AAAI?07: Proc.
of the 22nd national conference onArtificial intelligence.R.
Bar-Haim, J. Berant, and I. Dagan.
2009.
A com-pact forest for scalable inference over entailment andparaphrase rules.
In Proc.
of EMNLP.R.
Basili, M. Cammisa, and A. Moschitti.
2005.
Effec-tive use of wordnet semantics via kernel-based learn-ing.
In CoNLL.R.
Basili, M. Cammisa, and A. Moschitti.
2006.
A se-mantic kernel to classify texts with very few trainingexamples.
In Informatica.S.
Bloehdorn and A. Moschitti.
2007a.
Combined syn-tactic and semantic kernels for text classification.
InECIR.S.
Bloehdorn and A. Moschitti.
2007b.
Structure and se-mantics for expressive text kernels.
In Proc.
of CIKM?07.S.
Bloehdorn, R. Basili, M. Cammisa, and A. Moschitti.2006.
Semantic kernels for text classification based ontopological measures of feature similarity.
In Proc.
ofICDM 06, Hong Kong, 2006.J.
Bos and K. Markert.
2005.
Recognising textual entail-ment with logical inference.
In HLT ?05: Proc.
of theconference on HLT and EMNLP.A.
Burchardt, N. Reiter, S. Thater, and A. Frank.
2007.Semantic Approach to Textual Entailment: SystemEvaluation and Task Analysis.
In Proc.
of the 3rd-PASCAL Workshop on Textual Entailment, Prague.Y.
S. Chan and H. T. Ng.
2005.
Word sense disambigua-tion with distribution estimation.
In Proc.
of IJCAI?05.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proc.
of the 1st NAACL conference.M.
Collins and N. Duffy.
2002.
New ranking algorithmsfor parsing and tagging: kernels over discrete struc-tures, and the voted perceptron.
In Proc.
of ACL ?02.N.
Cristianini and R. Holloway.
2001.
Latent semantickernels.G.
Dinu and R. Wang.
2009.
Inference rules and theirapplication to recognizing textual entailment.
In Proc.of the EACL ?09.D.
Giampiccolo, B. Magnini, Ido Dagan, and B. Dolan.2007.
The third pascal recognizing textual entailmentchallenge.
In Proc.
of the ACL-PASCAL Workshop onTextual Entailment and Paraphrasing.Claudio Giuliano.
2007. jLSI a for latent se-mantic indexing.
http://tcc.itc.it/research/textec/tools-resources/jLSI.html.A.
D. Haghighi, A. Y. Ng, and C. D. Manning.
2005.Robust textual inference via graph matching.
In HLT?05: Proc.
of the conference on HLT and EMNLP.David Haussler.
1999.
Convolution kernels on discretestructures.
Technical report.J.
J. Jiang and D. W. Conrath.
1997.
Semantic similaritybased on corpus statistics and lexical taxonomy.
InProc.
of the 10th ROCLING.Thorsten Joachims.
1999.
Making large-scale supportvector machine learning practical.Landauer, Foltz, and Laham.
1998.
Introduction to latentsemantic analysis.
In Discourse Processes 25.D.
Lin and P. Pantel.
2001.
DIRT-discovery of inferencerules from text.
In Proc.
of the ACM KDD-01.R.
Mihalcea, C. Corley, and C. Strapparava.
2006.Corpus-based and knowledge-based measures of textsemantic similarity.
In Proc.
of AAAI06.Alessandro Moschitti.
2006.
Making tree kernels practi-cal for natural language learning.
In Proc.
of EACL.Peter Norvig.
1987.
A unified theory of inference fortext understanding.
Technical report, USA.Sebastian Pado?, 2006.
User?s guide to sigf: Signifi-cance testing by approximate randomisation.T.
Pedersen, S. Patwardhan, and J. Michelizzi.
2004.Wordnet::similarity - measuring the relatedness ofconcepts.
In Proc.
of 5th NAACL.D.
Roth and M. Sammons.
2007.
Semantic and logi-cal inference model for textual entailment.
In Proc.of the ACL-PASCAL Workshop on Textual Entailmentand Paraphrasing.I.
Szpektor and I. Dagan.
2008.
Learning entailmentrules for unary templates.
In Proc.
of COLING ?08.M.
Tatu and D. Moldovan.
2005.
A semantic approachto recognizing textual entailment.
In HLT ?05: Proc.of HLT/EMNLP.Z.
Wu and M. Palmer.
1994.
Verb semantics and lexicalselection.
In Proc.
of ACL.Alexander Yeh.
2000.
More accurate tests for the statis-tical significance of result differences.
In Proc.
of ACL2000, Morristown, NJ, USA.F.
M. Zanzotto and A. Moschitti.
2006.
Automatic learn-ing of textual entailments with cross-pair similarities.In Proc.
of ACL ?06.F.
M. Zanzotto, M. Pennacchiotti, and A. Moschitti.2009.
A machine learning approach to textual en-tailment recognition.
NATURAL LANGUAGE ENGI-NEERING.1028
