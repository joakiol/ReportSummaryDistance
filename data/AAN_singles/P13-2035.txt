Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 196?200,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsIs word-to-phone mapping better than phone-phone mapping forhandling English words?Naresh Kumar ElluruSpeech and Vision LabIIIT Hyderabad, Indianareshkumar.elluru@research.iiit.ac.inAnandaswarup VadapalliSpeech and Vision LabIIIT Hyderabad, Indiaanandaswarup.vadapalli@research.iiit.ac.inRaghavendra ElluruSpeech and Vision LabIIIT Hyderabad, Indiaraghavendra.veera@gmail.comHema MurthyDepartment of CSEIIT Madras, Indiahema@iitm.ac.inKishore PrahalladSpeech and Vision LabIIIT Hyderabad, Indiakishore@iiit.ac.inAbstractIn this paper, we relook at the problemof pronunciation of English words usingnative phone set.
Specifically, we in-vestigate methods of pronouncing Englishwords using Telugu phoneset in the con-text of Telugu Text-to-Speech.
We com-pare phone-phone substitution and word-phone mapping for pronunciation of En-glish words using Telugu phones.
We arenot considering other than native languagephoneset in all our experiments.
This dif-ferentiates our approach from other worksin polyglot speech synthesis.1 IntroductionThe objective of a Text-to-Speech (TTS) system isto convert a given text input into a spoken wave-form.
Text processing and waveform generationare the two main components of a TTS system.The objective of the text processing component isto convert the given input text into an appropriatesequence of valid phonemic units.
These phone-mic units are then realized by the waveform gener-ation component.
For high quality speech synthe-sis, it is necessary that the text processing unit pro-duce the appropriate sequence of phonemic units,for the given input text.There has been a rise in the phenomenon of?code mixing?
(Romaine and Kachru, 1992).
Thisis a phenomenon where lexical items of two lan-guages appear in a single sentence.
In a multi-lingual country such as India, we commonly findIndian language text being freely interspersed withEnglish words and phrases.
This is particularly no-ticeable in the case of text from web sources likeblogs, tweets etc.
An informal analysis of a Telugublog on the web showed that around 20-30% of thetext is in English (ASCII) while the remaining isin Telugu (Unicode).
Due to the growth of ?codemixing?
it has become necessary to develop strate-gies for dealing with such multilingual text in TTSsystems.
These multilingual TTS systems shouldbe capable of synthesizing utterances which con-tain foreign language words or word groups, with-out sounding unnatural.The different ways of achieving multilingualTTS synthesis are as follows (Traber et al, 1999;Latorre et al, 2006; Campbell, 1998; Campbell,2001).1.
Separate TTS systems for each language:In this paradigm, a seperate TTS system isbuilt for each language under consideration.When the language of the input text changes,the TTS system also has to be changed.This can only be done between two sen-tences/utterances and not in the middle of asentence.2.
Polyglot speech synthesis:This is a type of multilingual speech syn-thesis achieved using a single TTS system.This method involves recording a multi lan-guage speech corpus by someone who is flu-ent in multiple languages.
This speech cor-pus is then used to build a multilingual TTSsystem.
The primary issue with polyglotspeech synthesis is that it requires develop-ment of a combined phoneset, incorporatingphones from all the languages under consid-eration.
This is a time consuming processrequiring linguistic knowledge of both lan-guages.
Also, finding a speaker fluent in mul-196tiple languages is not an easy task.3.
Phone mapping:This type of multilingual synthesis is basedupon phone mapping, whereby the phonesof the foreign language are substituted withthe closest sounding phones of the primarylanguage.
This method results in a strongforeign accent while synthesizing the foreignwords.
This may not always be acceptable.Also, if the sequence of the mapped phonesdoes not exist or is not frequently occurringin the primary language, then the synthesizedoutput quality would be poor.
Hence, an aver-age polyglot synthesis technique using HMMbased synthesis and speaker adaptation hasbeen proposed (Latorre et al, 2006).
Suchmethods make use of speech data from dif-ferent languages and different speakers.In this paper, we relook at the problem of pro-nunciation of English words using native phoneset.
Specifically, we investigate methods of pro-nouncing English words using Telugu phoneset inthe context of Telugu Text-to-Speech.
Our moti-vation for doing so, comes from our understand-ing of how humans pronounce foreign words whilespeaking.
The speaker maps the foreign words toa sequence of phones of his/her native languagewhile pronouncing that foreign word.
For exam-ple, a native speaker of Telugu, while pronounc-ing an English word, mentally maps the Englishword to a sequence of Telugu phones as opposedto simply substituting English phones with the cor-responding Telugu phones.
Also, the receiver ofthe synthesized speech would be a Telugu nativespeaker, who may not have the knowledge of En-glish phone set.
Hence, approximating an Englishword using Telugu phone sequence may be moreacceptable for a Telugu native speaker.We compare phone-phone substitution andword-phone mapping (also referred to LTS rules)for the pronunciation of English words using Tel-ugu phones.
We are not considering other thannative language phoneset in all our experiments.This differentiates our work from other works inpolyglot speech synthesis.2 Comparison of word-phone andphone-phone mappingTable 1 shows an example of the word computerrepresented as a US English phone sequence, En-ComputerUS English Phones /k ax m p y uw t er/[k @ m p j u t 3~]phone-phone mapping /k e m p y uu t: r/[k e m p j u: ?
r]word-phone mapping /k a m p y uu t: a r/[k a m p j u: ?
a r]Table 1: English word computer represented asUS English phone sequence, US English phone-Telugu phone mapping and English word-Teluguphone mappingglish phone-Telugu phone mapping and Englishword-Telugu phone mapping, along with the cor-responding IPA transcription.
The English word-Telugu phone mapping is not a one to one map-ping, as it is in the case of English phone-Teluguphone mapping.
Each letter has a correspondencewith one or more than one phones.
As some let-ters do not have a equivalent pronunciation sound(the letter is not mapped to any phone) the termepsilon is used whenever there is a letter whichdoes not have a mapping with a phone.To compare word-phone (W-P) mapping andphone-phone (P-P) mapping, we manually pre-pared word-phone and phone-phone mappings for10 bilingual utterances and synthesized them us-ing our baseline Telugu TTS system.
We then per-formed perceptual listening evaluations on thesesynthesized utterances, using five native speakersof Telugu as the subjects of the evaluations.
Theperceptual listening evaluations were setup bothas MOS (mean opinion score) evaluations and asABX evaluations.
An explanation of MOS andABX evaluations is given in Section 4.
Table 2shows that results of these evaluations.MOS ABXW-P P-P W-P P-P No.
Pref3.48 2.66 32/50 4/50 14/50Table 2: Perceptual evaluation scores for baselineTelugu TTS system with different pronunciationrules for English197An examination of the results in Table 2 showsthat manually prepared word-phone mapping ispreferred perceptually when compared to manualphone-phone mapping.
The MOS score of 3.48indicates that native speakers accept W-P mappingfor pronouncing English words in Telugu TTS.For the remainder of this paper, we focus ex-clusively on word-phone mapping.
We propose amethod of automatically generating these word-phone mapping from data.
We experiment ourapproach by generating a word-phone mappingwhich maps each English word to a Telugu phonesequence (henceforth called EW-TP mapping).We report the accuracy of learning the word-phonemappings both on a held out test set and on a testset from a different domain.
Finally, we incorpo-rate this word-phone mapping in our baseline Tel-ugu TTS system and demonstrate its usefulness bymeans of perceptual listening tests.3 Automatic generation of word-phonemappingWe have previously mentioned that letter to phonemapping is not a one to one mapping.
Each let-ter may have a correspondence with one or morethan one phones, or it may not have correspon-dence with any phone.
As we require a fixed sizedlearning vector to build a model for learning word-phone mapping rules, we need to align the letter(graphemic) and phone sequences.
For this we usethe automatic epsilon scattering method.3.1 Automatic Epsilon Scattering MethodThe idea in automatic epsilon scattering is to esti-mate the probabilities for one letter (grapheme) Gto match with one phone P , and then use stringalignment to introduce epsilons maximizing theprobability of the word?s alignment path.
Oncethe all the words have been aligned, the associa-tion probability is calculated again and so on untilconvergence.
The algorithm for automatic epsilonscattering is given below (Pagel et al, 1998).3.2 Evaluation and ResultsOnce the alignment between the each word and thecorresponding phone sequence was complete, webuilt two phone models using Classification andRegression Trees (CART).
For the first model, weused data from the CMU pronunciation dictionarywhere each English word had been aligned to a se-quence of US English phones (EW-EP mapping).Algorithm for Epsilon Scattering :/*Initialize prob(G,P ) the probability of Gmatching P*/1.
for each wordi in training setcount with string alignment all possible G/Passociation for all possible epsilon positions in thephonetic transcription/* EM loop */2.
for each wordi in training setalignment path = argmax?i,jP (Gi, Pj)compute probnew(G,P ) on alignment path3.
if(prob 6= probnew) go to 2The second model was the EW-TP mapping.Once both the models had been built, they wereused to predict the mapped phone sequences foreach English word in the test data.
For the pur-poses of testing, we performed the prediction onboth held out test data as well as on test data froma different domain.
The held out test data was pre-pared by removing every ninth word from the lex-icon.As we knew the correct phone sequence foreach word in the test data, a ground truth againstwhich to compute the accuracy of prediction wasavailable.
We measured the accuracy of the pre-diction both at the letter level and at the word level.At the letter level, the accuracy was computed bycounting the number of times the predicted letterto phone mapping matched with the ground truth.For computing the accuracy at the word level, wecounted the number of times the predicted phonesequence of each word in the test data matchedwith the actual phone sequence for that word (de-rived from the ground truth).
We also varied thesize of the training data and then computed theprediction accuracy for each model.
We did so inorder to study the effect of training data size on theprediction accuracy.Tables 3, 4 show the accuracy of the models.An examination of the results in the two tablesshows that incrementally increasing the size of thetraining data results in an increase of the predic-tion accuracy.
The native speakers of Indian lan-guages prefer to speak what is written.
As a resultthere are fewer variations in word-phone mappingas compared to US English.
This is reflected inour results, which show that the word level pre-diction accuracy is higher for EW-TP mapping ascompared to EW-EP mapping.198Training set Held-out(%) Testing(%)sizeLetters words Letters words1000 92.04 39 81.43 16.62000 94.25 44.98 82.47 17.55000 94.55 47 84.40 25.110000 95.82 59.86 89.46 44.7100000 94.09 56.37 93.27 55.10Table 3: Accuracy of prediction for English word- English phone mappingTraining set Held-out(%) Testing(%)sizeLetters words Letters words1000 92.37 28 82.22 18.82000 94.34 45.45 83.79 25.15000 95.89 68.2 88.40 42.710000 96.54 71.67 94.74 70.9Table 4: Accuracy of prediction for English word-Telugu phone mapping4 Integrating word-phone mapping rulesin TTSFor the purpose of perceptual evaluations we builta baseline TTS systems for Telugu using theHMM based speech synthesis technique (Zen etal., 2007).To conduct perceptual evaluations of the word-phone mapping rules built from data in 3.2, weincorporated these rules in our Telugu TTS sys-tem.
This system is henceforth refered to as T A.A set of 25 bilingual sentences were synthesizedby the Telugu TTS, and ten native speakers of Tel-ugu performed perceptual evaluations on the syn-thesized utterances.
As a baseline, we also synthe-sized the same 25 sentences by incorporating man-ually written word-phone mapping for the Englishwords, instead of using the automatically gener-ated word-phone mapping rules.
We refer to thissystem as T M.The perceptual evaluations were set up bothas MOS (mean opinion score) evaluations and asABX evaluations.
In the MOS evaluations, thelisteners were asked to rate the synthesized utter-ances from all systems on a scale of 1 to 5 (1 beingworst and 5 best), and the average scores for eachsystem was calculated.
This average is the MOSscore for that system.
In a typical ABX evalua-tion, the listeners are presented with the the sameset of utterances synthesized using two systems Aand B, and are asked to mark their preference foreither A or B.
The listeners also have an option ofmarking no preference.
In this case, the listenerswere asked to mark their preference between T Aand T M. The results of the perceptual evaluationsare shown in Table 5.MOS ABX TestT M T A T M T A No.
Pref3.48 3.43 51/250 38/250 161/250Table 5: Perceptual results comparing systemsT M and T AAn examination of the results shows that per-ceptually there is no significant preference for themanual system over the automated system.
TheMOS scores also show that there is not much sig-nificant difference between the ratings of the man-ual and the automated system.5 ConclusionsIn this paper we present a method of automati-cally learning word-phone mapping rules for syn-thesizing foreign words occurring in text.
Weshow the effectiveness of the method by com-puting the accuracy of prediction and also bymeans of perceptual evaluations.
The synthe-sized multilingual wave files are available fordownload at https://www.dropbox.com/s/7hja51r5rpkz5mz/ACL-2013.zip.6 AcknowledgementsThis work is partially supported by MCIT-TTSconsortium project funded by MCIT, Governmentof India.
The authors would also like to thank allthe native speakers who participated in the percep-tual evaluations.ReferencesA.W.
Black and K. Lenzo.
2004.
Multilingual Text toSpeech synthesis.
In Proceedings of ICASSP, Mon-treal, Canada.N.
Campbell.
1998.
Foreign language speech synthe-sis.
In Proceedings ESCA/COCOSDA workshop onspeech synthesis, Jenolan Caves, Australia.N.
Campbell.
2001.
Talking foreign.
Concatena-tive speech synthesis and the language barrier.
InProceedings Eurospeech, pages 337?340, Aalborg,Denmark.199J.
Latorre, K. Iwano, and S. Furui.
2006.
New ap-proach to polygot speech generation by means of anHMM based speaker adaptable synthesizer.
SpeechCommunication, 48:1227?1242.V.
Pagel, K. Lenzo, and A.W.
Black.
1998.
Letter tosound rules for accented lexicon compression.
InProceedings of ICSLP 98, volume 5, Sydney, Aus-tralia.Suzzane Romaine and Braj Kachru.
1992.
The Ox-ford Companion to the English Language.
OxfordUniversity Press.C.
Traber, K. Huber, K. Nedir, B. Pfister, E. Keller,and B. Zellner.
1999.
From multilingual to polyglotspeech synthesis.
In Proceedings of Eurospeech 99,pages 835?838.H.
Zen, T. Nose, J. Yamagishi, S. Sako, T. Masuko,A.W.
Black, and K. Tokuda.
2007.
The HMM-based speech synthesis system version 2.0.
In Pro-ceedings of ISCA SSW6, Bonn, Germany.200
