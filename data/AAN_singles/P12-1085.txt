Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 805?814,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsStructuring E-Commerce InventoryKarin MaugeeBay Research Labs2145 Hamilton AvenueSan Jose, CA 95125kmauge@ebay.comKhash RohanimanesheBay Research Labs2145 Hamilton AvenueSan Jose, CA 95125krohanimanesh@ebay.comJean-David RuvinieBay Research Labs2145 Hamilton AvenueSan Jose, CA 95125jruvini@ebay.comAbstractLarge e-commerce enterprises feature mil-lions of items entered daily by a large vari-ety of sellers.
While some sellers providerich, structured descriptions of their items, avast majority of them provide unstructurednatural language descriptions.
In the paperwe present a 2 steps method for structuringitems into descriptive properties.
The first stepconsists in unsupervised property discoveryand extraction.
The second step involves su-pervised property synonym discovery using amaximum entropy based clustering algorithm.We evaluate our method on a year worth of e-commerce data and show that it achieves ex-cellent precision with good recall.1 IntroductionOnline commerce has gained a lot of popularity overthe past decade.
Large on-line C2C marketplaceslike eBay and Amazon, feature a very large andlong-tail inventory with millions of items (productoffers) entered into the marketplace every day by alarge variety of sellers.
While some sellers (gener-ally large professional ones) provide rich, structureddescription of their products (using schemas or viaa global trade item number), the vast majority onlyprovide unstructured natural language descriptions.To manage items effectively and provide the bestuser experience, it is critical for these marketplacesto structure their inventory into descriptive name-value pairs (called properties) and ensure that itemsof the same kind (digital cameras for instance) aredescribed using a unique set of property names(brand, model, zoom, resolution, etc.)
and values.For example, this is important for measuring itemsimilarity and complementarity in merchandising,providing faceted navigation and various businessintelligence applications.
Note that structuring itemsdoes not necessarily mean identifying products asnot all e-commerce inventory is manufactured (an-imals for examples).Structuring inventory in the e-commerce domainraises several challenges.
First, one needs to iden-tify and extract the names and the values used byindividual sellers from unstructured textual descrip-tions.
Second, different sellers may describe thesame product in very different ways, using differ-ent terminologies.
For example, Figure 1 shows3 item descriptions of hard drives from 3 differentsellers.
The left description mentions ?rotationalspeed?
in a specification table while the other twodescriptions use the synonym ?spindle speed?
in abulleted list (top right) or natural language speci-fications (bottom right).
This requires discoveringsemantically equivalent property names and valuesacross inventories from multiple sellers.
Third, thescale at which on-line marketplaces operate makesimpractical to solve any of these problems manually.For instance, eBay reported 99 million active usersin 2011, many of whom are sellers, which may trans-late into thousands or even millions of synonyms todiscover accross more than 20,000 categories rang-ing from consumer electronics to collectible and art.This paper describes a two step process for struc-turing items in the e-commerce domain.
The firststep consists in an unsupervised property extrac-tion technique which allows discovering name-value805pairs from unstructured item descriptions.
The sec-ond step consists in identifying semantically equiv-alent property names amongst these extracted prop-erties.
This is accomplished using supervised max-imum entropy based clustering.
Note that, althoughvalue synonym discovery is an equally importanttask for structuring items, this is still an area of on-going research and is not addressed in this paper.The remainder of this paper is structured as fol-lows.
We first review related work.
We then describethe two steps of our approach: 1) unsupervised prop-erty discovery and extraction and 2) property namesynonym discovery.
Finally, we present experimen-tal results on real large-scale e-commerce data.2 Related WorkThis section reviews related work for the two com-ponents of our method, namely unsupervised prop-erty extraction and supervised property name syn-onym discovery.2.1 Unsupervised Property ExtractionA lot of progress has been accomplished in the areaof property discovery from product reviews since thepioneering work by (Hu and Liu, 2004).
Most ofthis work is based on the observation, later formal-ized as double propagation by (Qiu et al, 2009),that in reviews, opinion words are usually asso-ciated with product properties in some ways, andthus product properties can be identified from opin-ion words and opinion words from properties alter-nately and iteratively.
While (Hu and Liu, 2004) ini-tially used association mining techniques; (Liu et al,2005) used Part-Of-Speech and supervised rule min-ing to generate language patterns and identify prod-uct properties; (Popescu and Etzioni, 2005) usedpoint wise mutual information between candidateproperties and meronymy discriminators; (Zhuanget al, 2006; Qiu et al, 2009) improved on previouswork by using dependency parsing; (Kobayashi etal., 2007) mined property-opinion patterns using sta-tistical and contextual cues; (Wang and Wang, 2008)leveraged property-opinion mutual information andlinguistic rules to identify infrequent properties; and(Zhang et al, 2010) proposed a ranking scheme toimprove double propagation precision.
In this pa-per, we are focusing on extracting properties fromproduct descriptions which do not contain opinionwords.In a sense, item properties can be viewed as slotsof product templates and our work bears similari-ties with template induction methods.
(Chambersand Jurafsky, 2011) proposed a method for inferringevent templates based on word clustering accordingto their proximity in the corpus and syntactic func-tion clustering.
Unfortunately, this technique can-not be applied to our problem due to the lack of dis-course redundancy within item descriptions.
(Putthividhya and Hu, 2011) and (Sachan et al,2011) also addressed the problem of structuringitems in the e-commerce domain.
However, theseworks assume that property names are known inadvance and focus on discovering values for theseproperties from very short product titles.Although we are primarily concerned with unsu-pervised property discovery, it is worth mentioning(Peng and McCallum, 2004) and (Ghani et al, 2006)who approached the problem using supervised ma-chine learning techniques and require labeled data.2.2 Property Name Synonym DiscoveryOur work is related to the synonym discovery re-search which aims at identifying groups of wordsthat are semantically identical based on some de-fined similarity metric.
The body of work onthis problem can be divided into two major ap-proaches (Agirre et al, 2009): methods that arebased on the available knowledge resources (e.g.,WordNet, or available taxonomies) (Yang and Pow-ers, 2005; Alvarez and Lim, 2007; Hughes and Ra-mage, ), and methods that use contextual/propertydistribution around the words (Pereira et al, 1993;Chen et al, 2006; Sahami and Heilman, 2006; Pan-tel et al, 2009).
(Zhai et al, 2010) propose a con-strained semi-supervised learning method using anaive Bayes formulation of EM seeded by a smallset of labeled data and a set of soft constraints basedon the prior knowledge of the problem.
There hasbeen also some recent work on applying topic mod-eling (e.g., LDA) for solving this problem (Guo etal., 2009).Our work is also related to the existing researchon schema matching problem where the objective isto identify objects that are semantically related crossschemas.
There has been an extensive study on the806Figure 1: Three examples of item descriptions containing a specification table (left image), a bulleted list (top right)and natural language specifications (bottom right).problem of schema matching (for a comprehensivesurvey see (Rahm and Bernstein, 2001; Bellahseneet al, 2011; Bernstein et al, 2011)).
In general thework can be classified into rule-based and learning-based approaches.
Rule-based systems (Castanoand de Antonellis, 1999; Milo and Zohar, 1998;L. Palopol and Ursino, 1998) often utilize only theschema information (e.g., elements, domain typesof schema elements, and schema structure) to definea similarity metric for performing matching amongthe schema elements in a hard coded fashion.
Incontrast learning based approaches learn a similar-ity metric based on both the schema informationand the data.
Earlier learning based systems (Liand Clifton, 2000; Perkowitz and Etzioni, 1995;Clifton et al, 1997) often rely on one type of learn-ing (e.g., schema meta-data, statistics of the datacontent, properties of the objects shared betweenthe schemas, etc).
These systems do not exploitthe complete textual information in the data con-tent therefore have limited applicability.
Most re-cent systems attempt to incorporate the textual con-tents of the data sources into the system.
Doan etal.
(2001) introduce LSD which is a semi-automaticmachine learning based matching framework thattrains a set of base learners using a set of user pro-vided semantic mappings over a small data sources.Each base learner exploits a different type of in-formation, e.g.
source schema information and in-formation in the data source.
Given a new datasource, the base learners are used to discover se-mantic mappings and their prediction is combinedusing a meta-learner.
Similar to LSD, GLUE (Doanet al, 2003) also uses a set of base learners com-bined into a meta-learner for solving the match-ing problem between two ontologies.
Our work ismostly related to (Wick et al, 2008) where theypropose a general framework for performing jointlyschema matching, co-reference and canonicalizationusing a supervised machine learning approach.
Inthis approach the matching problem is treated asa clustering problem in the schema attribute space,where a cluster captures a matched set of attributes.A conditional random field (CRF) (Lafferty et al,2001) is trained using user provided mappings be-tween example schemas, or ontologies.
CRF bene-807fits from first order logic features that capture bothschema/ontology information as well as textual fea-tures in the related data sources.3 Unsupervised Property ExtractionThe first step of our solution to structuring e-commerce inventory aims at discovering and ex-tracting relevant properties from items.Our method is unsupervised and requires no priorknowledge of relevant properties or any domainknowledge as it operates the exact same way forall items and categories.
It maintains a set of pre-viously discovered properties called known proper-ties with popularity information.
The popularity ofa given property name N (resp.
value V ) is definedas the number of sellers who are using N (resp.
V ).A seller is said to use a name or a value if we areable to extract the property name or value from atleast one of its item descriptions.
The method isincremental in that it starts with an empty set ofknown properties, mines individual items indepen-dently and incrementally builds and updates the setof known properties.The key intuition is that the abundance of datain e-commerce allows simple and scalable heuris-tic to perform very well.
For property extraction thistranslates into the following observation: althoughwe may need complex natural language processingfor extracting properties from each and every item,simple patterns can extract most of the relevant prop-erties from a subset of the items due to redundancybetween sellers.
In other words, popular propertiesare used by many sellers and some of them writetheir descriptions in a manner that makes these prop-erties easy to extract.
For example one pattern thatsome sellers use to describe product properties oftenstarts by a property name followed by a colon andthen the property value (we refer to this pattern asthe colon pattern).
Using this pattern we can minecolon separated short strings like ?size : 20 inches?or ?color : light blue?
which enables us to discovermost relevant property names.
However, such a pat-tern extracts properties from a fraction of the inven-tory only and does not suffice.
We are using 4 pat-terns which are formally defined in Table 1.All patterns run on the entire item description.Pattern 1 skips the html markers and scripts andapplies only to the content sentences.
It ignoresany candidate property which name is longer than30 characters and values longer than 80 characters.These length thresholds may be domain dependent.They have been chosen empirically.
Pattern 2, 3 and4 search for known property names.
Pattern 2 ex-tracts the closest value to the right of the name.
It al-lows the name and the value to be separated by spe-cial characters or some html markups (like ?<TR>?,?<TD>?, etc.).
It captures a wide range of namevalue pair occurrences including rows of specifica-tion tables.Syntactic cleaning and validation is performedon all the extracted properties.
Cleaning consistsmainly in removing bullets from the beginning ofnames and punctuation at the end of names and val-ues.
Validation rejects properties which names arepure numbers, properties that contain some specialcharacters and names which are less than 3 charac-ters long.
All discovered properties are added to theset of known properties and their popularity countsare updated.Note that for efficiency reasons, Part-Of-Speech(POS) tagging is performed only on sentences con-taining the anchor of a pattern.
The anchor of pat-tern 1 is the colon sign while the anchor of the otherpatterns is the known property name KN.
We use(Toutanova et al, 2003) for POS tagging.4 Property Synonym DiscoveryIn this section we briefly overview a probabilisticpairwise property synonym model inspired by (Cu-lotta et al, 2007).4.1 Probabilistic ModelGiven a category C, let XC = {x1, x2, .
.
.
, xn} bethe raw set of n property names (prior to synonymdiscovery) extracted from a corpus of data associ-ated with that category.
Every property name is as-sociated with pairs of values and popularity count(as defined in Section 3) Vxi = {?vij , ci(vij)?
}mj=1,where vij is the jth value associated for the prop-erty name xi and ci(vij) is the popularity of value vij .Given a pair of property names xij = {xi, xj}, letthe binary random variable yij be 1 if xi and xj aresynonyms.
Let F = {fk(xij , y)} be a set of fea-tures over xij .
For example, fk(xij , y) may indicate808# Pattern Example1 [NP][:][optional DT][NP] ?color : light blue?2 [KN][optional html][NP] ?size</TD><TD><FONT COLOR="red">20 inches?3 [!IN][KN]["is" or "are"][NP] ?color is red?4 [NP][KN] ?red color?Table 1: Patterns used to extract properties from item description.
The macro tag NP denotes any of the tags NN,NNP, NNS, NNPS, JJ, JJS or CD.
The KN tag is defined as a NP tag over a known property name.
Pattern 1 only candiscover new names; patterns 2 to 4 aim at capturing values for known property names.whether xi and xj have both numerical values.
Eachfeature fk has an associated real-valued parameter?k.
The pairwise model is given by:P(yij |xij) =1Zxijexp?k?kfk(xij , yij) (1)where Zxij is a normalizer that sums over the twosettings of yij .
This is a maximum-entropy classifier(i.e.
logistic regression) in which P(yij |xij) is theprobability that xi and xj are synonyms.
To estimate?
= {?k} from labeled training data, we performgradient ascent to maximize the log-likelihood of thelabeled data.Given a data set in which property names aremanually clustered, the training data can be cre-ated by simply enumerating over each pair of syn-onym property names xij , where yij is true if xiand xj are in the same cluster.
More practically,given the raw set of extracted properties, first wemanually cluster them.
Positive examples are thenpairs of property names from the same cluster.
Neg-ative examples are pairs of names cross two dif-ferent clusters randomly selected.
For example,let assume that the following four property nameclusters have been constructed: {color, shade},{size, dimension}, {weight}, {features}.
Theseclusters implies that ?color?
and ?shade?
are syn-onym; that ?size?
and ?dimension?
are synonym andthat ?weight?
and ?features?
don?t have any syn-onym.
The pair (color, shade) is a positive exam-ples, while (size, shade) and (weight, features)are negative examples.Now, given an unseen category C?
and the set ofraw properties (property names and values) minedfrom that category, we can construct an undirected-weighted graph in which vertices correspond to theproperty names NC?
and edge weights are propor-tional to P(yij |xij).
The problem is now reduced tofinding the maximum a posteriori (MAP) setting ofyijs in the new graph.
The inference in such mod-els is generally intractable, therefore we apply ap-proximate graph partitioning methods where we par-tition the graph into clusters with high intra-clusteredge weights and low inter-cluster edge weights.
Inthis work we employ the standard greedy agglom-erative clustering, in which each noun phrase wouldbe assigned to the most probable cluster accordingto P(yij |xij).4.2 FeaturesGiven a pair of property names xij = {xi, xj} wehave designed a set of features as follows:Property name string similarity/distance: Thismeasures string similarity between two names.
Wehave included various string edit distances such asJaccard distance over n-grams extracted from theproperty names, and also Levenstein distance.
Wehave also included a feature that compares the twoproperty names after their commoner morphologi-cal and inflectional endings have been removed us-ing the Porter Stemmer algorithm.Property value set coverage: We compute aweighted Jaccard measure given the values and thevalue frequencies associated with a property name.J (Vxi ,Vxj ) =?v?
(Vxi?Vxj )min(ci(v), cj(v))?v?
(Vxi?Vxj )max(ci(v), cj(v))This feature essentially computes how many prop-erty values are common between the two propertynames, weighted by their popularity.Property name co-occurrence: This is an inter-esting feature which is based on the observation that809two property names that are synonyms, rarely oc-cur together within the same description.
This isbased on the assumption that sellers are consistentwhen using property names throughout a single de-scription.
For example when they are specifying thesize of an item, they either use size or dimensionsexclusively in a single description.
However, it ismore likely that two property names that are not syn-onyms appear together within a single description.To conform this assumption, we ran a separate ex-periment that measures the co-occurrence frequencyof the property names in a single category.
Table 2shows a measurement of pairwise co-occurrence ofa few example property names computed over theAudio books eBay category.
Given a property namex let I(x) be the total number of descriptions thatcontain the name x.
Now, given two property namesxi and xj , we define a measure of co-occurrence ofthese names as:CO(xi, xj) =I(xi) ?
I(xj)I(xi) ?
I(xj)In Table 2 it can be seen that synonym prop-erty names such as ?author?
and ?by?
have a zeroco-occurrence measure, while semantically differentproperty names such as ?format?
and ?read by?
havea non-zero co-occurrence measure.5 Experimental resultsThis section presents experimental results on a realdataset.
We first describe the dataset used for theseexperiments and then provide results for propertyextraction and property name synonym discovery.5.1 Data set and methodologyAll the results we are reporting in this paper were ob-tained from a dataset of several billion descriptionscorresponding to a year worth of eBay item (no sam-pling was performed).For listing an item on eBay, a seller must pro-vide a short descriptive title (up to 80 characters) andcan optionally provide a few descriptive name valuepairs called item specifics, and a free-form html de-scription.
Contrary to item specifics, a vast majorityof sellers provide a rich description containing veryuseful information about the property of their item.Figure 1 shows 3 examples of eBay descriptions.eBay organizes items into a six-level categorystructure similar to a topic hierarchy comprising20,000 leaf categories and covering most of thegoods in the world.
An item is typically listed inone category but some items may be suitable for andlisted in two categories.Although this dataset is not publicly available,very similar data can be obtained from the eBay website and through eBay Developers API 1.In the following, we report precision and recallresults.
Evaluation was performed by two annota-tors (non expert of the domain).
For property ex-traction, they were asked to decide whether or not anextracted property is relevant for the correspondingitems; for synonym discovery to decide whether ornot sellers refer to the same semantic entity.
Anno-tators were asked to reject the null hypothesis onlybeyond reasonable doubt and we found the annotatoragreement to be extremely high.5.2 Property Extraction ResultsWe have been running the property extractionmethod described in Section 3 on our entire dataset.The properties extracted have been aggregated at theleaf category level and ranked by popularity (as de-fined in Section 3).
Because no gold standard datais available for this task, evaluation has to be per-formed manually.
However, it is impractical to re-view results for 20,000 categories and we uniformlysampled 20 categories randomly.Precision.
Table 3 shows the weighted (by cat-egory size) average precision of the extracted prop-erty names up to rank 20.
Precision at rank k for agiven category is defined as the number of relevantproperties in the top k properties of that categories,divided by k. Table 4 shows the top 15 propertiesextracted for five eBay categories.Although we did not formally evaluate the preci-sion of the discovered values, informal reviews haveshown that this method extracts good quality val-ues.
Examples are ?n/a?, ?well?, ?storage or well?,?would be by well?
and ?by well?
for the prop-erty name ?Water?
in the Land category; ?metal?,?plastic?, ?nylon?, ?acetate?
and ?durable o matter?for ?Frame material?
in Sunglasses; or ?acrylic?,1See https://www.x.com/developers/ebay/ fordetails.810author by read by format narrated byauthor 0 0.06 0.06 0.006by 0 0.17 0.005 0.013read by 0.06 0.17 0.035 0format 0.06 0.005 0.035 0.006narrated by 0.006 0.013 0 0.006Table 2: Co-occurrence measure computed over a subset of property names in the Audio books category.
Somesynonym property names such as author and by have zero co-occurrence frequency, while semantically differentproperty names such as format and read by sometimes appear together in some of the item descriptions.Rank 1 2 3 4 5 6 7 8 9 10Precision 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.992 0.992 0.986Rank 11 12 13 14 15 16 17 18 19 20Precision 0.986 0.997 0.986 1 0.998 1 1 0.959 0.722 0.747Table 3: Weighted average precision of the top 20 extracted property names.
?oil?, ?acrylic on canvas?
and ?oil on canvas?
for?Medium?
in Paintings.Sets of values tend to contain more synonymsthan names.
Also, we observed that some namesexhibit polysemy issues in that their values clearlybelong to several semantic clusters.
An exampleof polysemy is the name ?Postmark?
in the ?Post-cards?
categories which contains values like ?none,postally used, no, unused?
and years (?1909, 1908,1910...?).
Cleaning and normalizing values is on-going research effort.Recall.
Evaluating recall of our method requirescomparing for each category, the number of relevantproperties extracted to the number of relevant prop-erties the descriptions in this category contain.
Itis dauntingly expensive.
As a proxy for name re-call, we examined 20 categories and found that ourmethod discovered all the relevant popular propertynames.It is quite remarkable that an unsupervisedmethod like ours achieves results of that quality andis able to cover most of the good of the world withdescriptive properties.
To our knowledge, this hasnever been accomplished before in the e-commercedomain.5.3 Synonym discovery resultsTo train our name synonym discovery algorithm, wemanually clustered properties from 27 randomly se-lected categories as described in Section 4.
This re-sulted in 178 clusters, 113 of them containing a sin-gle property (no synonym) and 65 containing 2 ormore properties and capturing actual synonym in-formation.
Note that although estimating the co-occurrence table (see Table 2) can be computation-ally expensive, it is very manageable for such a smallset of clusters.
Scalability issues due to the largenumber of eBay categories (nearly 20,000) made im-practical to use the solutions proposed in the past tosolve that problem as baselines.Results were produced by applying the trainedmodel to the top 20 discovered properties for eachand every eBay categories.
The algorithm discov-ered 10672 synonyms spanning 2957 categories.Precision.
To measure the precision of our algo-rithm, we manually labeled 6618 synonyms as cor-rect or incorrect.
6076 synonyms were found to becorrect and 542 incorrect, a precision of 91.8%.
Ta-ble 5 shows examples of synonyms and one of thecategories where they have been discovered.
Someof them are very category specific.
For instance,while ?hp?
means ?horsepower?
for air compres-sors, it is an acronym of a well known brand in con-sumer electronics.Recall.
Evaluating recall is a more labor inten-sive task as it involves comparing, for each of the2957 categories, the number of synonyms discov-ered to the number of synonyms the category con-811Land Aquariums iPod & MP3 Players Acoustic Guitars PostcardsState Dimensions Weight Top ConditionZoning Height Width Scale length PublisherCounty Size Depth Neck SizeWater Width Height Bridge PostmarkLocation Includes Color Finish Postally usedTaxes Weight Battery type Rosette TypeSize Depth Dimensions Binding AgeSewer Capacity Frequency response Fingerboard StampPower Color Storage capacity Tuning machines DateRoads Power Display Case TitleLot size LCD size Capacity Pickguard PostmarkedUtilities Length Screen size Tuners SubjectParcel number Material Battery Nut width LocationCable length Length CornersCondition Thickness EraTable 4: Examples of discovered properties for 5 eBay categories.Category SynonymsRechargeable Batteries {Battery type, Chemical composition}Lodging {Check-in, Check-in time}Flower seeds {Bloom time, Flowering season}Doors & Door Hardware {Colour,Color, Main color}Gemstone {Cut, Shape}Air Compressors {Hp, Horsepower}Decorative Collectibles {Item no, Item sku, Item number}Router Memory {Memory (ram), Memory size}Equestrian Clothing {Bust, Chest}Traiding Cards {Rarity, Availability}Paper Calendar {Time period, Calendars era}Table 5: Examples of discovered property name synonyms.tains.
As a proxy we labeled 40 randomly selectedcategories.
For these categories, we found the recallto be 51%.
As explained in Section 4, the overlapof values between two names is an important featurefor our algorithm.
The fact that we are not cleaningand normalizing the values discovered by our prop-erty extraction algorithm clearly impacts recall.
Thisis definitively an important direction for further im-provements.6 ConclusionWe presented a method for structuring e-commerceinventory into descriptive properties.
This methodis based on unsupervised property discovery and ex-traction from unstructured item descriptions, and onproperty name synonym discovery achieved usinga supervised maximum entropy based clustering al-gorithm.
Experiments on a large real e-commercedataset showed that both techniques achieve verygood results.
However, we did not address the issueof property value cleaning and normalization.
Thisis an important direction for future work.812ReferencesEneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pas?ca, and Aitor Soroa.
2009.
Astudy on similarity and relatedness using distributionaland wordnet-based approaches.
In Proceedings of Hu-man Language Technologies: The 2009 Annual Con-ference of the North American Chapter of the Asso-ciation for Computational Linguistics, NAACL ?09,pages 19?27, Stroudsburg, PA, USA.
Association forComputational Linguistics.Marco A. Alvarez and SeungJin Lim.
2007.
A graphmodeling of semantic similarity between words.
InProceedings of the International Conference on Se-mantic Computing, pages 355?362, Washington, DC,USA.
IEEE Computer Society.Zohra Bellahsene, Angela Bonifati, and Erhard Rahm,editors.
2011.
Schema Matching and Mapping.Springer.Philip A. Bernstein, Jayant Madhavan, and Erhard Rahm.2011.
Generic schema matching, ten years later.
Pro-ceedings of the VLDB Endowment, 4(11):695?701.Silvana Castano and Valeria de Antonellis.
1999.
Aschema analysis and reconciliation tool environmentfor heterogeneous databases.
In Proceedings of the1999 International Symposium on Database Engineer-ing & Applications, IDEAS ?99, pages 53?, Washing-ton, DC, USA.
IEEE Computer Society.Nathanael Chambers and Dan Jurafsky.
2011.
Template-based information extraction without the templates.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies - Volume 1, HLT ?11, pages 976?986, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Hsin-Hsi Chen, Ming-Shun Lin, and Yu-Chuan Wei.2006.
Novel association measures using web searchwith double checking.
In Proceedings of the 21stInternational Conference on Computational Linguis-tics and the 44th annual meeting of the Associationfor Computational Linguistics, ACL-44, pages 1009?1016, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Chris Clifton, Ed Housman, and Arnon Rosenthal.
1997.Experience with a combined approach to attribute-matching across heterogeneous databases.
In In Proc.of the IFIP Working Conference on Data Semantics(DS-7.Aron Culotta, Michael Wick, Robert Hall, and AndrewMccallum.
2007.
First-order probabilistic modelsfor coreference resolution.
In In Proceedings of HLT-NAACL 2007.AnHai Doan, Pedro Domingos, and Alon Y. Halevy.2001.
Reconciling schemas of disparate data sources:a machine-learning approach.
In Proceedings ofthe 2001 ACM SIGMOD international conference onManagement of data, SIGMOD ?01, pages 509?520,New York, NY, USA.
ACM.AnHai Doan, Jayant Madhavan, Robin Dhamankar, Pe-dro Domingos, and Alon Halevy.
2003.
Learningto match ontologies on the semantic web.
The VLDBJournal, 12:303?319, November.Rayid Ghani, Katharina Probst, Yan Liu, Marko Krema,and Andrew Fano.
2006.
Text mining for product at-tribute extraction.
SIGKDD Explor.
Newsl., 8:41?48,June.Honglei Guo, Huijia Zhu, Zhili Guo, XiaoXun Zhang,and Zhong Su.
2009.
Product feature categorizationwith multilevel latent semantic association.
In Pro-ceedings of the 18th ACM conference on Informationand knowledge management, CIKM ?09, pages 1087?1096, New York, NY, USA.
ACM.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, KDD ?04, pages 168?177, New York, NY, USA.
ACM.Thad Hughes and Daniel Ramage.
Lexical semantic re-latedness with random graph walks.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL), pages581?589.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-of re-lations in opinion mining.
In Proceedings of the2007 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL.D.
Sacca` L. Palopol and D. Ursino.
1998.
Semi-automatic, semantic discovery of properties fromdatabase schemes.
In Proceedings of the 1998 Inter-national Symposium on Database Engineering & Ap-plications, pages 244?, Washington, DC, USA.
IEEEComputer Society.John D. Lafferty, Andrew McCallum, and Fernando C. N.Pereira.
2001.
Conditional random fields: Proba-bilistic models for segmenting and labeling sequencedata.
In Proceedings of the Eighteenth InternationalConference on Machine Learning, ICML ?01, pages282?289, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.Wen-Syan Li and Chris Clifton.
2000.
Semint: a toolfor identifying attribute correspondences in heteroge-neous databases using neural networks.
Data Knowl.Eng., 33:49?84, April.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: analyzing and comparing opinions813on the web.
In Proceedings of the 14th internationalconference on World Wide Web, WWW ?05, pages342?351, New York, NY, USA.
ACM.Tova Milo and Sagit Zohar.
1998.
Using schema match-ing to simplify heterogeneous data translation.
In Pro-ceedings of the 24rd International Conference on VeryLarge Data Bases, VLDB ?98, pages 122?133, SanFrancisco, CA, USA.
Morgan Kaufmann PublishersInc.Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-Maria Popescu, and Vishnu Vyas.
2009.
Web-scaledistributional similarity and entity set expansion.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume 2 -Volume 2, EMNLP ?09, pages 938?947, Stroudsburg,PA, USA.
Association for Computational Linguistics.Fuchun Peng and Andrew McCallum.
2004.
Accu-rate information extraction from research papers usingconditional random fields.
In HLT-NAACL04, pages329?336.Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.Distributional clustering of english words.
In Pro-ceedings of the 31st annual meeting on Association forComputational Linguistics, ACL ?93, pages 183?190,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Mike Perkowitz and Oren Etzioni.
1995.
Category trans-lation: learning to understand information on the in-ternet.
In Proceedings of the 14th international jointconference on Artificial intelligence - Volume 1, pages930?936, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
InProceedings of the conference on Human LanguageTechnology and Empirical Methods in Natural Lan-guage Processing, HLT ?05, pages 339?346, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Duangmanee Putthividhya and Junling Hu.
2011.
Boot-strapped named entity recognition for product attributeextraction.
In EMNLP, pages 1557?1567.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009.Expanding domain sentiment lexicon through doublepropagation.
In Proceedings of the 21st internationaljont conference on Artifical intelligence, IJCAI?09,pages 1199?1204, San Francisco, CA, USA.
MorganKaufmann Publishers Inc.Erhard Rahm and Philip A. Bernstein.
2001.
A survey ofapproaches to automatic schema matching.
The VLDBJournal, 10:334?350.Mrinmaya Sachan, Tanveer Faruquie, L. V. Subrama-niam, and Mukesh Mohania.
2011.
Using text reviewsfor product entity completion.
In Poster at the 5thInternational Joint Conference on Natural LanguageProcessing, IJCNLP?11, pages 983?991.Mehran Sahami and Timothy D. Heilman.
2006.
A web-based kernel function for measuring the similarity ofshort text snippets.
In Proceedings of the 15th inter-national conference on World Wide Web, WWW ?06,pages 377?386, New York, NY, USA.
ACM.Kristina Toutanova, Dan Klein, Christopher D. Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of the 2003 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics on Human Language Technology - Volume 1,NAACL ?03, pages 173?180, Stroudsburg, PA, USA.Association for Computational Linguistics.Bo Wang and Houfeng Wang.
2008.
Bootstrapping bothproduct features and opinion words from chinese cus-tomer reviews with cross-inducing.
In Proceedings ofthe Third International Joint Conference on NaturalLanguage Processing.Michael L. Wick, Khashayar Rohanimanesh, KarlSchultz, and Andrew McCallum.
2008.
A unified ap-proach for schema matching, coreference and canoni-calization.
In Proceedings of the 14th ACM SIGKDDinternational conference on Knowledge discovery anddata mining, KDD ?08, pages 722?730, New York,NY, USA.
ACM.Dongqiang Yang and David M. W. Powers.
2005.
Mea-suring semantic similarity in the taxonomy of word-net.
In Proceedings of the Twenty-eighth Australasianconference on Computer Science - Volume 38, ACSC?05, pages 315?322, Darlinghurst, Australia, Aus-tralia.
Australian Computer Society, Inc.Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia.
2010.Grouping product features using semi-supervisedlearning with soft-constraints.
In Proceedings of the23rd International Conference on Computational Lin-guistics, COLING ?10, pages 1272?1280, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Lei Zhang, Bing Liu, Suk Hwan Lim, and EamonnO?Brien-Strain.
2010.
Extracting and ranking prod-uct features in opinion documents.
In Proceedings ofthe 23rd International Conference on ComputationalLinguistics: Posters, COLING ?10, pages 1462?1470,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Li Zhuang, Feng Jing, and Xiao-Yan Zhu.
2006.
Moviereview mining and summarization.
In CIKM ?06: Pro-ceedings of the 15th ACM international conference onInformation and knowledge management, pages 43?50, New York, NY, USA.
ACM.814
