Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 29?35,Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational LinguisticsSemi-automatic Construction of Cross-period ThesaurusChaya Liebeskind, Ido Dagan, Jonathan SchlerComputer Science DepartmentBar-Ilan UniversityRamat-Gan, Israelliebchaya@gmail.com, dagan@cs.biu.ac.il, schler@gmail.comAbstractCross-period (diachronic) thesaurus con-struction aims to enable potential users tosearch for modern terms and obtain se-mantically related terms from earlier pe-riods in history.
This is a complex task notpreviously addressed computationally.
Inthis paper we introduce a semi-automaticiterative Query Expansion (QE) schemefor supporting cross-period thesaurus con-struction.
We demonstrate the empiricalbenefit of our scheme for a Jewish cross-period thesaurus and evaluate its impact onrecall and on the effectiveness of lexicog-rapher manual effort.1 Introduction and BackgroundIn the last decade, there is a growing interest in ap-plying Natural Language Processing (NLP) meth-ods to historical texts due to the increased avail-ability of these texts in digital form (Sporleder,2010; Sa?nchez-Marco et al 2011; Piotrowski,2012).
The specific linguistic properties of histor-ical texts, such as nonstandard orthography, gram-mar and abbreviations, pose special challenges forNLP.
One of this challenges, which has not beenaddressed so far, is the problem of bridging thelexical gap between modern and ancient language.In this paper, we address the interesting taskof cross-period thesaurus (a.k.a.
diachronic the-saurus) construction.
A thesaurus usually containsthousands of entries, denoted here as target terms.Each entry includes a list of related terms, cover-ing various semantic relations.
A cross-period the-saurus aims to enable the potential user to searchfor a modern term and get related terms from ear-lier periods.
Thus, in a cross-period thesaurusthe target terms are modern while their relatedterms are ancient.
In many cases, while the actualmodern term (or its synynom) does not appear inearlier historical periods, different aspects of thatterm were mentioned.
For example, in our Jewishhistorical corpora, the modern term birth control,has no equivalent ancient term, However, differentcontraceptive methods were described in our his-torical texts that are semantically similar to birthcontrol.
Thus, a related term is considered sim-ilar to the target term when it refers to the sameconcept.The goal of our research is to support con-structing a high-quality publishable thesaurus, asa cultural resource on its own, alongside beinga useful tool for supporting searches in the do-main.
Since the precision of fully automatically-constructed thesauri is typically low (e.g.
(Mi-halcea et al 2006)), we present a semi-automaticsetting for supporting thesaurus construction by adomain expert lexicographer.
Our recall-orientedsetting assumes that manual effort is worthwhilefor increasing recall as long as it is being utilizedeffectively.Corpus-based thesaurus construction is an ac-tive research area (Curran and Moens, 2002; Kil-garriff, 2003; Rychly?
and Kilgarriff, 2007; Liebe-skind et al 2012; Zohar et al 2013).
Typi-cally, two statistical approaches for identifying se-mantic relatedness between words were investi-gated: first-order (co-occurrence-based) similarityand second-order (distributional) similarity (Lin,1998; Gasperin et al 2001; Weeds and Weir,2003; Kotlerman et al 2010).
In this research,we focus on statistical measures of first-order sim-ilarity (see Section 2).
These methods were foundto be effective for thesaurus construction as stand-alone methods and as complementary to second-order methods (Peirsman et al 2008).
First-ordermeasures assume that words that frequently occurtogether are topically related (Schu?tze and Peder-sen, 1997).
Thus, co-occurrence provides an ap-propriate approach to identify highly related termsfor the thesaurus entries.29In general, there are two types of historically-relevant corpora: ancient corpora of ancient lan-guage, and modern corpora with references andmentions to ancient language (termed here mixedcorpora).
Since in our setting the thesaurus?
targetterms are modern terms, which do not appear inancient corpora, co-occurrence methods would bedirectly applicable only over a mixed corpus.
Ina preliminary experiment, we applied the Liebe-skind et al(2012) algorithmic scheme, which ap-plies first-order similarity and morphological as-pects of corpus-based thesaurus construction, ona mixed corpus of our historical domain.
We ob-served that the target terms had low frequency inthis corpus.
Since statistical co-occurrence mea-sures have poor performance over low statistics,the experiment?s results were not satisfactory.
Wetherefore looked for ways to increase the numberof documents in the statistical extraction process,and decided that applying query expansion (QE)techniques might be a viable solution.We recognized two potential types of sourcesof lexical expansions for the target terms.
Thefirst is lexical resources available over the inter-net for extracting different types of semantic rela-tions (Shnarch et al 2009; Bollegala et al 2011;Hashimoto et al 2011).
The second is lists ofrelated terms extracted from a mixed corpus bya first-order co-occurrence measure.
These listscontain both ancient and modern terms.
Althoughonly ancient terms will be included in the finalthesaurus, modern terms can be utilized for QEto increase thesaurus coverage.
Furthermore, ex-panding the target term with ancient related termsenables the use of ancient-only corpora for co-occurrence extraction.Following these observations, we present an it-erative interactive QE scheme for bootstrappingthesaurus construction.
This approach is used tobridge the lexical gap between modern and ancientterminology by means of statistical co-occurrenceapproaches.
We demonstrate the empirical advan-tage of our scheme over a cross-period Jewish do-main and evaluate its impact on recall and on theeffectiveness of the lexicographer manual effort.The remainder of this paper is organized as fol-lows: we start with a description of the statisticalthesaurus construction method that we utilize inour scheme.
Our main contribution of the itera-tive scheme is described in Section 3, followed bya case-study in Section 4 and evaluation and sum-mary in Sections 5 and 6.2 Automatic Thesaurus ConstructionAutomatic thesaurus construction focuses on theprocess of extracting a ranked list of candidaterelated terms (termed candidate terms) for eachgiven target term.
We assume that the top rankedcandidates will be further examined (manually) bya lexicographer, who will select the eventual re-lated terms for the thesaurus entry.Statistical measures of first-order similarity(word co-occurrence), such as Dice coefficient(Smadja et al 1996) and Pointwise Mutual In-formation (PMI) (Church and Hanks, 1990), werecommonly used to extract ranked lists of candi-date related terms.
These measures consider thenumber of times in which each candidate term co-occurs with the target term, in the same document,relative to their total frequencies in the corpus.In our setting, we construct a thesaurus for amorphologically rich language (Hebrew).
There-fore, we followed the Liebeskind et al(2012) al-gorithmic scheme designed for these cases, sum-marized below.
First, our target term is repre-sented in its lemma form.
For each target term weretrieve all the corpus documents containing thisgiven target term.
Then, we define a set of candi-date terms, which are represented in their surfaceform, that consists of all the terms in all these doc-uments.
Next, the Dice co-occurrence score be-tween the target term and each of the candidatesis calculated, based on their document-level statis-tics in the corpus.
After sorting the terms based ontheir scores, the highest rated candidate terms areclustered into lemma-based clusters.
Finally, werank the clusters by summing the co-occurrencescores of their members and the highest rated clus-ters constitute the candidate terms for the giventarget term, to be presented to a domain expert.3 Iterative Semi-automatic Scheme forCross-period Thesaurus ConstructionAs explained in Section 1, our research focuseson a semi-automatic setting for supporting cross-period thesaurus construction by a lexicographer.In this work, we assume that a list of modern tar-get terms is given as input.
Then, we automaticallyextract a ranked list of candidate related terms foreach target term using statistical measures, as de-tailed in Section 2.
Notice that at this first step re-lated terms can be extracted only from the mixed30corpora, in which the given (modern) target termmay occur.
Next, a lexicographer manually se-lects, from the top ranked candidates, ancient re-lated terms for the thesaurus entry as well as termsfor QE.
The QE terms may be either ancient ormodern terms from the candidate list, or termsfrom a lexical resource.
Our iterative QE schemeiterates over the QE terms.
In each iteration, a QEterm replaces the target term?s role in the statisticsextraction process.
Candidate related terms areextracted for the QE term and the lexicographerjudges their relevancy with respect to the originaltarget term.
Notice that if the QE term is modern,only the mixed corpora can be utilized.
However,if the QE term is ancient, the ancient corpora arealso utilized and may contribute additional relatedterms.The algorithmic scheme we developed for the-saurus construction is illustrated in Figure 1.
Ourinput is a modern target term.
First, we au-tomatically extract candidates by statistical co-occurrence measures, as described in Section 2.Then, a domain-expert annotates the candidates.The manual selection process includes two de-cisions on each candidate (either modern or an-cient): (i) whether the candidate is related to thetarget term and should be included in its thesaurusentry, and (ii) whether this candidate can be usedas a QE term for the original target term.
Thesecond decision provides input to the QE process,which triggers the subsequent iterations.
Follow-ing the first decision we filter the modern termsand include only ancient ones in the actual the-saurus.The classification of a candidate term as ancientor modern is done automatically by a simple clas-sification rule: If a term appears in an ancient cor-pus, then it is necessarily an ancient term; other-wise, it is a modern term (notice that the converseis not true, since an ancient term might appear inmodern documents).In parallel to extracting candidate related termsfrom the corpus, we extract candidate terms alsofrom our lexical resources, and the domain expertjudges their fitness as well.
Our iterative processis applied over the expansions list.
In each itera-tion, we take out an expansion term and automat-ically extract related candidates for it.
Then, theannotator selects both ancient related terms for thethesaurus and suitable terms, either modern or an-cient, for the expansion list for further iterations.Figure 1: Semi-automatic Algorithmic SchemeFor efficiency, only new candidates that were notjudged in pervious iterations are given for judge-ment.
The stopping criterion is when there are noadditional expansions in the expansions list.Since the scheme is recall-oriented, the aim ofthe annotation process is to maximize the the-saurus coverage.
In each iteration, the domainexpert annotates the extracted ranked list of can-didate terms until k sequential candidates werejudged as irrelevant.
This stopping criterion foreach iteration controls the efforts to increase recallwhile maintaining a low, but reasonable precision.In our setting, we extract ancient related termsfor modern terms.
Therefore, in order to utilizeco-occurrence statistics extraction, our scheme re-quires both ancient and mixed corpora, wherethe first iteration utilizes only the mixed corpora.Then, our iterative scheme enables subsequent it-erations to utilize the ancient corpora as well.4 Case Study: Cross-period JewishThesaurusOur research targets the construction of a cross-period thesaurus for the Responsa project1.
Thecorpus includes questions on various daily issuesposed to rabbis and their detailed rabbinic an-swers, collected over fourteen centuries, and wasused for previous IR and NLP research (Chouekaet al 1971; Choueka et al 1987; HaCohen-Kerner et al 2008; Liebeskind et al 2012; Zoharet al 2013).The Responsa corpus?
documents are divided tofour periods: the 11th century until the end of the15th century, the 16th century, the 17th throughthe 19th centuries, and the 20th century until to-1Corpus kindly provided: http://biu.ac.il/jh/Responsa/31day.
We considered the first three periods as ourancient corpora along with the RaMBaM (Hebrewacronym for Rabbi Mosheh Ben Maimon) writ-ings from the 12th century.
For the mixed corpuswe used the corpus?
documents from the last pe-riod, but due to relatively low volume of moderndocuments we enriched it with additional moderncollections (Tchumin collection 2, ASSIA (a Jour-nal of Jewish Ethics and Halacha), the Medical-Halachic Encyclopedia3, a collection of questionsand answers written by Rabbi Shaul Israeli4, andthe Talmudic Encyclopedia (a Hebrew languageencyclopedia that summarizes halachic topics ofthe Talmud in alphabetical order).
Hebrew Wik-tionary was used as a lexical resource for syn-onyms.For statistics extraction, we applied (Liebeskindet al 2012) algorithmic scheme using Dice coef-ficient as our co-occurrence measure (see Section2).
Statistics were calculated over bigrams fromcorpora consisting of 81993 documents.5 Evaluation5.1 Evaluation SettingWe assessed our iterative algorithmic scheme byevaluating its ability to increase the thesaurus cov-erage, compared to a similar non-iterative co-occurrence-based thesaurus construction method.In our experiments, we assumed that it is worthspending the lexicographer?s time as long as it isproductive, thus, all the manual annotations werebased on the lexicographer efforts to increase re-call until reaching the stopping criterion.We used Liebeskind et al(2012) algorithmicscheme as our non-iterative baseline (Baseline).For comparison, we ran our iterative scheme, cal-culated the average number of judgments per tar-get term (88) and set the baseline stopping crite-rion to be the same number of judgements per tar-get.
Thus, we ensured that the number of judge-ments for our iterative algorithm and for the base-line is equal, and thus coverage increase is due to abetter use of lexicographer?s effort.
For complete-ness, we present the results of the non-iterative al-gorithm with the stopping criterion of the iterativealgorithm, when reaching k (k=10 was empirically2http://www.zomet.org.il/?CategoryID=1703http://medethics.org.il/website/index.php/en/research-2/encyclopedia-of-jewish-medical-ethics4http://www.eretzhemdah.org/data/uploadedfiles/ebooks/14-sfile.pdfMethod RT R Pro JFirst-iteration 50 0.31 0.038 1307Baseline 63 0.39 0.024 2640Iterative 151 0.94 0.057 2640Table 1: Results Comparisonselected in our case) sequential irrelevant candi-dates (First-iteration).To evaluate our scheme?s performance, we usedseveral measures: total number of ancient relatedterms extracted (RT), relative recall (R) and pro-ductivity (Pro).
Since we do not have any pre-defined thesaurus, our micro-averaged relative-recall considered the number of ancient relatedterms from the output of both methods (baselineand iterative) as the full set of related terms.
Pro-ductivity was measured by dividing the total num-ber of ancient related terms extracted (RT) by thetotal number of the judgments performed for themethod (J).5.2 ResultsTable 1 compares the performance of our semi-automatic iterative scheme with that of the base-line over a test set of 30 modern target terms.
Ouriterative scheme increases the average number ofextracted related terms from 2.1 to 5, i.e., increas-ing recall by 240%.
The relative recall of the first-iteration (0.31) is included in the relative recall ofboth the baseline and our iterative method.
Iterat-ing over the first iteration increases recall by 300%(from 50 to 151 terms), while adding more judge-ments to the non-iterative method increases recallonly by 26% (to 63 terms).
The productivity of theiterative process is higher even than the productiv-ity of the first iteration, showing that the iterativeprocess optimizes the lexicographer?s manual ef-fort.Table 2 shows examples of thesaurus targetterms and their ancient related terms, which wereadded by our iterative scheme5.
Since the relatedterms are ancient Halachic terms, we explain themrather than translate them to English.We further analyze our scheme by comparingthe use of ancient versus modern terms in the itera-tive process.
Although modern related terms werenot included in our cross-period thesaurus, in thejudgement process the lexicographer judged their5To facilitate readability we use a transliteration of He-brew using Roman characters; the letters used, in Hebrewlexico-graphic order, are abgdhwzxTiklmns`pcqrs?t.32Figure 2: The extraction of ancient terms versus modern terms in the iterative processTarget term Related termzkwiwt iwcrim (copyright) hsgt gbwl (trespassing)iwrd lamnwt xbrw ([competitively] enter his friend?s profession)`ni hmhpk bxrrh (a poor man is deciding whether to buy a cake and anotherperson comes and takes it)hmtt xsd (euthanasia) rwb gwssin lmith (most dying people die)xii s?`h (living for the moment)hpsqt hriwn (abortion) xwtkin h`wbr (killing the fetus)hwrg nps?
(killing a person)rwdp (pursuer, a fetus endangering its mother?s life)tiknwn hms?pxh (birth control) s?lws?
ns?im ms?ms?wt bmwk (three types of women allowed to use cotton di-aphragm)ds?
mbpnim wzwrh mbxwc (withdrawal method)hprt xwzh (breach of contract) biTwl mqx (cancelling a purchase)dina dgrmi (indirect damage)mqx t`wt (erroneous bargain)srwb pqwdh (insubordination) mwrd bmlkwt (rebel against the sovereign [government])imrh at pik (to disobey)Avner and khni Nob (a biblical story: king Saul ordered to slay Ahimilech to-gether with 85 priests.
Avner, the captain of Saul?s guard, disobeyed the order.
)Table 2: Examples for the iterative scheme?s contributionrelevancy too.
In Figure 2, we report the numberof modern related terms in comparison to the num-ber of ancient related terms for each iteration.
Inparallel, we illustrate the number of ancient expan-sions in proportion to the number of modern ex-pansions.
The x-axis?
values denote the iterations,while the y-axis?
values denote the number of ex-pansions and related terms respectively.
For eachiteration, the expansions chart presents the expan-sions that were extracted while the related termschart presents the extracted related terms, of whichthe ancient ones were included in the thesaurus.Since the input for our scheme is a modern targetterms, the first iteration extracted more modern re-lated terms than ancient terms and utilized moremodern expansions than ancient.
However, thisproportion changed in the second iteration, prob-ably thanks to the ancient expansions retrieved inthe first iteration.Although there are often mixed results onthe effectiveness of QE for information retrieval(Voorhees, 1994; Xu and Croft, 1996), our resultsshow that QE for thesaurus construction in an iter-ative interactive setting is beneficial for increasingthesaurus?
coverage substantially.6 Conclusions and Future WorkWe introduced an iterative interactive scheme forcross-period thesaurus construction, utilizing QEtechniques.
Our semi-automatic algorithm signif-icantly increased thesaurus coverage, while op-timizing the lexicographer manual effort.
Thescheme was investigated for Hebrew, but can begenerically applied for other languages.We plan to further explore the suggested schemeby utilizing additional lexical resources and QEalgorithms.
We also plan to adopt second-orderdistributional similarity methods for cross-periodthesaurus construction.33ReferencesD.
Bollegala, Y. Matsuo, and M. Ishizuka.
2011.A web search engine-based approach to mea-sure semantic similarity between words.
Knowl-edge and Data Engineering, IEEE Transactions on,23(7):977?990.Yaacov Choueka, M. Cohen, J. Dueck, Aviezri S.Fraenkel, and M. Slae.
1971.
Full text documentretrieval: Hebrew legal texts.
In SIGIR, pages 61?79.Yaacov Choueka, Aviezri S. Fraenkel, Shmuel T. Klein,and E. Segal.
1987.
Improved techniques for pro-cessing queries in full-text systems.
In SIGIR, pages306?315.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lexicog-raphy.
Comput.
Linguist., 16(1):22?29, March.James R. Curran and Marc Moens.
2002.
Improve-ments in automatic thesaurus extraction.
In Pro-ceedings of the ACL-02 workshop on Unsupervisedlexical acquisition - Volume 9, ULA ?02, pages 59?66, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Caroline Gasperin, Pablo Gamallo, Alexandre Agus-tini, Gabriel Lopes, Vera De Lima, et al2001.
Us-ing syntactic contexts for measuring word similarity.In Workshop on Knowledge Acquisition and Catego-rization, ESSLLI, Helsinki, Finland.Yaakov HaCohen-Kerner, Ariel Kass, and Ariel Peretz.2008.
Combined one sense disambiguation of ab-breviations.
Proceedings of ACL08: HLT, Short Pa-pers, pages 61?64.Chikara Hashimoto, Kentaro Torisawa, StijnDe Saeger, Junichi Kazama, and Sadao Kuro-hashi.
2011.
Extracting paraphrases from definitionsentences on the web.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics (ACL), pages 1087?1097.Adam Kilgarriff.
2003.
Thesauruses for natu-ral language processing.
In Proceedings of theJoint Conference on Natural Language Processingand Knowledge Engineering, pages 5?13, Beijing,China.Lili Kotlerman, Ido Dagan, Idan Szpektor, and MaayanZhitomirsky-geffet.
2010.
Directional distributionalsimilarity for lexical inference.
Nat.
Lang.
Eng.,16(4):359?389, October.Chaya Liebeskind, Ido Dagan, and Jonathan Schler.2012.
Statistical thesaurus construction for a mor-phologically rich language.
In *SEM 2012: TheFirst Joint Conference on Lexical and Computa-tional Semantics, pages 59?64, Montre?al, Canada,7-8 June.
Association for Computational Linguis-tics.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In Proceedings of the 36th AnnualMeeting of the Association for Computational Lin-guistics and 17th International Conference on Com-putational Linguistics - Volume 2, ACL ?98, pages768?774, Stroudsburg, PA, USA.
Association forComputational Linguistics.Rada Mihalcea, Courtney Corley, and Carlo Strappa-rava.
2006.
Corpus-based and knowledge-basedmeasures of text semantic similarity.
In Proceedingsof the 21st national conference on Artificial intelli-gence - Volume 1, AAAI?06, pages 775?780.
AAAIPress.Yves Peirsman, Kris Heylen, and Dirk Speelman.2008.
Putting things in order.
First and second ordercontext models for the calculation of semantic sim-ilarity.
In 9es Journe?es internationales d?Analysestatistique des Donne?es Textuelles (JADT 2008).Lyon, France.Michael Piotrowski.
2012.
Natural language process-ing for historical texts.
Synthesis Lectures on Hu-man Language Technologies, 5(2):1?157.Pavel Rychly?
and Adam Kilgarriff.
2007.
An ef-ficient algorithm for building a distributional the-saurus (and other sketch engine developments).
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,ACL ?07, pages 41?44, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Cristina Sa?nchez-Marco, Gemma Boleda, and Llu??sPadro?.
2011.
Extending the tool, or how to anno-tate historical language varieties.
In Proceedings ofthe 5th ACL-HLT Workshop on Language Technol-ogy for Cultural Heritage, Social Sciences, and Hu-manities, LaTeCH ?11, pages 1?9, Stroudsburg, PA,USA.
Association for Computational Linguistics.Hinrich Schu?tze and Jan O. Pedersen.
1997.
Acooccurrence-based thesaurus and two applicationsto information retrieval.
Inf.
Process.
Manage.,33(3):307?318, May.Eyal Shnarch, Libby Barak, and Ido Dagan.
2009.
Ex-tracting lexical reference rules from wikipedia.
InProceedings of the Joint Conference of the 47th An-nual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processingof the AFNLP: Volume 1 - Volume 1, ACL ?09, pages450?458, Stroudsburg, PA, USA.
Association forComputational Linguistics.Frank Smadja, Kathleen R. McKeown, and VasileiosHatzivassiloglou.
1996.
Translating collocations forbilingual lexicons: a statistical approach.
Comput.Linguist., 22(1):1?38, March.Caroline Sporleder.
2010.
Natural language process-ing for cultural heritage domains.
Language andLinguistics Compass, 4(9):750?768.34Ellen M. Voorhees.
1994.
Query expansion usinglexical-semantic relations.
In Proceedings of the17th annual international ACM SIGIR conferenceon Research and development in information re-trieval, SIGIR ?94, pages 61?69, New York, NY,USA.
Springer-Verlag New York, Inc.Julie Weeds and David Weir.
2003.
A general frame-work for distributional similarity.
In Proceedings ofthe 2003 conference on Empirical methods in nat-ural language processing, EMNLP ?03, pages 81?88, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Jinxi Xu and W. Bruce Croft.
1996.
Query expan-sion using local and global document analysis.
InProceedings of the 19th annual international ACMSIGIR conference on Research and development ininformation retrieval, SIGIR ?96, pages 4?11, NewYork, NY, USA.
ACM.Hadas Zohar, Chaya Liebeskind, Jonathan Schler, andIdo Dagan.
2013.
Automatic thesaurus constructionfor cross generation corpus.
Journal on Comput-ing and Cultural Heritage (JOCCH), 6(1):4:1?4:19,April.35
