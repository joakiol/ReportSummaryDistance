Reference Resolution over a Restricted Domain: References to DocumentsAndrei POPESCU-BELISISSCO/TIM/ETIUniversity of GenevaBd.
du Pont d?Arve 40Geneva, CH-1211, Switzerlandandrei.popescu-belis@issco.unige.chDenis LALANNEDIUFUniversity of FribourgCh.
du Muse?e 3Fribourg, CH-1700, Switzerlanddenis.lalanne@unifr.chAbstractThis article studies the resolution of referencesmade by speakers to documents discussed duringa meeting.
The focus is on transcribed record-ings of press review meetings, in French.
Afteran overview of the required framework for refer-ence resolution?specification of the task, data an-notation, and evaluation procedure?we propose,analyze and evaluate an algorithm for the resolu-tion of references to documents (ref2doc) based onanaphora tracking and context matching.
Appli-cations to speech-to-document alignment and moregenerally to meeting processing and retrieval are fi-nally discussed.1 IntroductionThe references made by the speakers to the entitiesthat they talk about are one of the keys to the un-derstanding of human dialogs.
When speakers dis-cuss one or more documents, as in a press reviewmeeting, the references to these documents consti-tute a significant proportion of all the occurring ref-erences.A computer representation of the referents isavailable in this case, unlike references to moreabstract objects, since here the documents can bestored in electronic format.
Reference resolutionamounts thus to the construction of links betweeneach referring expression (RE) and the correspond-ing document element.
For example, if someonesays: ?I do not agree with the title of our latest re-port?, then ?our latest report?
refers to a documentavailable as a computer file, and ?the title of our lat-est report?
refers precisely to its title, an element thatcan be retrieved from the file.We propose here an algorithm for the resolutionof references to documents, or ref2doc.
Its imple-mentation and evaluation require a computationalframework that includes several types of data?documents, transcriptions, and links?and an eval-uation measure.We summarize our view of reference resolutionover a restricted domain in Section 2.
Then, wesituate the present task in the overall speech-to-document alignment process (Section 3).
The an-notated data and the evaluation metric are describedin Section 4, along with empirical results regardingthe patterns of the REs.
The resolution algorithmis presented in Section 5, and the results obtainedin various configurations are analyzed in Section 6,with conclusions about their relevance.
Section 7outlines the applications of the ref2doc algorithm tothe exploitation of documents in meeting processingand retrieval applications.2 Challenges of Reference Resolution overa Restricted DomainFrom a cognitive point of view, the role of referringexpressions in discourse is to specify the entitiesabout which the speaker talks.
It has long been ob-served that a more accurate view is that REs ratherspecify representations of entities in the speaker?s orhearer?s mind, an abstraction called discourse enti-ties or DEs (Sidner, 1983; Grosz et al, 1995).Reference resolution can be defined as the con-struction of the discourse entities specified by re-ferring expressions, or rather, the construction ofcomputational representations of DEs.
This diffi-cult but important task in discourse understandingby computers appears to be more tractable whenenough knowledge about a domain is available toa system (Gaizauskas and Humphreys, 1997), orwhen the representations are considerably simpli-fied (Popescu-Belis et al, 1998).The coreference and anaphoric links, that is,links between REs only, are somewhat different as-pects of the phenomenon of reference (Devitt andSterelny, 1999; Lycan, 2000).
Coreference is the re-lation between two REs that specify the same DE.Anaphora is a relation between two REs, called an-tecedent RE and anaphoric RE, where the DE spec-ified by the latter is determined by knowledge of theDE specified by the former.
In other terms, the DEspecified by the anaphoric RE cannot be fully de-termined without knowledge of the antecedent RE.Depending on how the referent of the second RE isdetermined by the referent of the first one, the twoREs may be coreferent, as in example (1) below, orthey can be related by other referring relations, e.g.whole/part, function/value, etc., as in (2).1.
The first articlei is particularly relevant to ourcompany.
Iti discusses .
.
.2.
The first articlei is particularly relevant to ourcompany.
The titlej suggests that we.
.
.In the present case, reference resolution overa restricted domain differs significantly both fromanaphora resolution (Mitkov, 2002) and from coref-erence resolution (Hirschman, 1997; van Deemterand Kibble, 2000).
The REs available in the dialogtranscript must be matched against the set of poten-tial referents or DEs, which can be derived from thedocument structure.
Therefore a computational rep-resentation of the referents is here available to serveas DEs.
This advantage results directly from ourpresent research goal and could be later extended toDEs derived computationally from document con-tent, such as the persons mentioned in an article.Reference resolution in a restricted domainpresents similarities with problems in natural lan-guage generation (NLG) and in command dialogs,that is, when the sets of referents are known a pri-ori to the system.
In NLG, the problem is to gen-erate REs from existing computational descriptionsof entities?see Paraboni and van Deemter (2002)for an application to intra-document references.
Incommand dialogs, the problem is to match the REsproduced by the user against the objects managedby the interface, again known formally to the sys-tem (Huls et al, 1995; Skantze, 2002).3 Components of a Fully AutomatedRef2doc System3.1 OverviewWithin the overall goal of a fully automated un-derstanding of references to documents in meet-ing dialogs, several related sub-tasks can be dis-tinguished, most simply envisaged as separate pro-cesses in a computational architecture:1.
Generate a transcript of the utterances pro-duced by each speaker.2.
Detect the REs from the transcripts that makereferences to the documents of the meeting.3.
Generate a formal representation of the docu-ments: articles, titles, etc.4.
Connect or match each RE to the document el-ement it refers to.Each of these components can be further subdi-vided.
Our main focus here is task (4).
For this task,an evaluation procedure, an algorithm, and its eval-uation are provided respectively in Sections 4.3, 5,and 6.
Task (3) is discussed below in Section 3.2.1.Task (1), which amounts more or less to auto-mated speech recognition, is of course a standardone, for which the performance level, as measuredby the word error rate (WER), depends on the mi-crophone used, the environment, the type of themeeting, etc.
To factor out these problems, whichare far beyond the scope of this paper, we usemanual transcripts of recorded meetings (see Sec-tion 4.2.1).The present separation between tasks (2) and (4)needs further explanations?see also (van Deemterand Kibble, 2000; Popescu-Belis, 2003) for moredetails.
Our interest here is the construction of ref-erence links between REs and document elements(from which coreference can be inferred), so we donot focus on task (2).
Instead, we use a set of REsidentified by humans.Task (2) is not trivial, but could be carried outusing a repertoire of pattern matching rules.
Thepatterns of the manually detected REs shown in Ta-ble 1 (Section 4.4) are a first step in this direction.The difficulty is that sometimes task (2) proposescandidate REs, for which only task (4) can decidewhether they can really be matched to a documentelement or not.
For instance, REs such as pronouns(?it?)
or deictics (?this?)
that refer to document ele-ments can only be detected using a combination of(2) and (4).
This is one of our future goals.3.2 Construction of the Logical Structure ofDocumentsInferring the structure of a document from its graph-ical aspect is a task that can be automated with goodperformances, as explained elsewhere (Hadjar et al,2004).
Here, the documents are front pages of news-papers, in French.
We first define the template ofdocument structures, then summarize the construc-tion method.3.2.1 Targeted Document StructureMany levels of abstraction are present in the lay-out and content of a document.
They are conveyedby its various structures: thematic, physical, log-ical, relational or even temporal.
The form of adocument, i.e.
its layout and its logical structure,carries important (and often underestimated) cluesabout the content, in particular for newspaper pages,Newspaper -> Date, Name,MasterArticle,Highlight*, Article+,Other*, FilenameMasterArticle -> Title, Subheading?,Summary*, Author*,Source?, Content?,Reference?, Other*,JournalArticle*Article -> Title, Subtitle?,Source?, Content,Author*, Summary*,Reference*, Other?JournalArticle -> Title, Source?,Summary*, Content?,Reference+Highlight -> Title, Subtitle,Reference+Figure 1: Logical structure of a newspaper frontpage (in DTD style).
Terminal nodes contain text.where articles are organized by zones, and titles areclearly marked.We consider that newspaper front pages havea hierarchical structure, which can be expressedusing a very simple ontology.
This is summa-rized in Figure 1 using a DTD-like declaration,as the document structure is encoded in XML.For instance, the first rule in Figure 1 statesthat a Newspaper front page bears the newspa-per?s Name, the Date, one Master Article,zero, one or more Highlights, one or moreArticles, etc.
Each content element has an IDattribute bearing a unique index.3.2.2 Document Structure ExtractionThe document structure can be extracted automat-ically from the PDF version of a document, alongwith a logical representation of the layout.
Our ap-proach merges low level extraction methods appliedto PDF files with layout analysis of a syntheticallygenerated TIFF image (Hadjar et al, 2004).
A seg-mentation algorithm first extracts from the imagethe threads, frames and text lines, then separatesimage and text zones, and finally merges lines intohomogeneous blocks.
In parallel, the objects con-tained in the PDF file (text, images, and graphics)are extracted and matched with the result of the lay-out analysis; for instance, text is associated to phys-ical (graphical) blocks.
Finally, the cleaned PDF isparsed into a unique tree, which can be transformed<dialog><channel id="1">...<er id="12">The title</er>reads...</channel>...<ref2doc>...<ref er-id="12"doc-file="LeMonde030404.Logic.xml"doc-id="//Article[@ID=?3?
]/Author"/>...</ref2doc></dialog>Figure 2: Sample annotation of a dialog transcrip-tion with ref2doc information (er stands for RE).either into SVG or into an XML document, and usedfor various applications.4 Evaluation Method and DataTwo important elements for testing are the avail-able data (4.2), which must be specifically annotated(4.1), and a scoring procedure (4.3), which is quitestraightforward, and provides several scores.4.1 Annotation ModelThe annotation model for the references to docu-ments builds upon a shallow dialog analysis model(Popescu-Belis et al, 2004), implemented in XML.The main idea is to add external annotation blocksthat do not alter the master resource?here the timedmeeting transcription, divided into separate chan-nels.
However, REs are annotated on the dialogtranscription itself.
A more principled solution, butmore complex to implement, would be to index themaster transcriptions by the number of words, thenexternalize the annotation of REs as well (Salmon-Alt and Romary, 2004).As shown in Figure 2, the ref pointers fromthe REs to the document elements are grouped in aref2doc block at the end of the document, usingas attributes the index of the RE (er-id), the docu-ment filename (doc-file), and an XPath expres-sion (doc-id) that refers to a document elementfrom the XML document representation.4.2 Annotation Procedure and Results4.2.1 Data Recording and TranscriptionA document-centric meeting room has been set upat the University of Fribourg to record differenttypes of meetings.
Several modalities related todocuments are recorded, thanks to a dozen cam-eras and eight microphones.
These devices are con-trolled and synchronized by a master computer run-ning a meeting capture and archiving application,which helps the users organize the numerous datafiles (Lalanne et al, 2004).At the time of writing, 22 press-review meet-ings of ca.
15 minutes each were recorded, betweenMarch and November 2003.
In such meetings, par-ticipants discuss (in French) the front pages of oneor more newspapers of the day.
Each participantpresents a selection of the articles to his/her col-leagues, for information purposes.
In general, aftera monologue of 5-10 utterances that summarize anarticle, a brief discussion ensues, made of questions,answers and comments.
Then, the chair of the meet-ing shifts the focus of the meeting to another article.The recordings of the 22 meetings were manu-ally transcribed using Transcriber,1 then exported asXML files.
The structure of the documents was alsoencoded as XML files using the procedure describedabove (3.2.1) with manual correction to ensure near100% accuracy.4.2.2 Ref2doc AnnotationThe annotation of the ground truth references wasdone directly in the XML format described above(Figure 2).
We have annotated 15 meetings witha total of 322 REs.
In a first pass, the annotatormarked the REs (with <er>...</er> tags), ifthey referred to an article or to one of its parts, forinstance its title or author.
However, REs that corre-sponded only to quotations of an article?s sentenceswere not annotated, since they refer to entities men-tioned in the documents, rather than to the documentelements.
Table 1 synthesizes the observed patternsof REs.The REs were then automatically indexed, anda template for the ref2doc block and an HTMLview were generated using XSLT.
In a second pass,the annotator filled in directly the attributes of theref2doc block in the template.
The annotatorswere instructed to fill in, for each RE (er-id),the name of the journal file that the RE referred to(doc-file), and the XPath to the respective doc-ument element (doc-id), using its ID.
Exampleswere provided for XPath expressions.
The follow-ing separate windows are all required for the anno-tation:?
text/XML editor for the ref2doc block of thedialog annotation file;?
HTML browser for the serialized HTML tran-script (with REs in boldface);1www.etca.fr/CTA/gip/Projets/Transcriber?
XML browser for the document structure rep-resentation (one per document);?
PDF viewer for the actual layout of the articles(one per document).4.2.3 Inter-Annotator AgreementWe tested the reliability of the annotators on the sec-ond part of their task, viz., filling in the ref2docblocks.
The experiment involved three annotators,for the three meetings that discuss several docu-ments at a time, with a total of 92 REs.
In a firststage, annotation was done without any communi-cation between annotators, only using the annota-tion guidelines.
The result was on average 96%agreement for document assignment (that is, 3 er-rors for 92 REs), and 90% agreement on documentelements (that is, 9 errors).2In a second stage, we analyzed and solved someof the disagreements, thus reaching 100% agree-ment on document assignment, and 97% agreementon document elements, that is only two disagree-ments.
These resulted from different interpretationsof utterances?e.g., they in ?they say.
.
.
?
could de-note the author, the newspaper, etc.
?and could notbe solved.This experiment shows that ref2doc annotation isa very reliable task: referents can be clearly identi-fied in most cases.
A perfect system would matchthe human performance at more than 95%.34.3 Evaluation MetricsUnlike intra-document coreference resolution, forwhich evaluation is a complex task (Popescu-Belis,2003), the evaluation of reference resolution over aspecific domain is quite straightforward.
One mustcompare for each RE the referent found by the sys-tem with the correct one selected by the annotators.If the two are the same, the system scores 1, oth-erwise it scores 0.
The total score is the numberof correctly solved REs out of the total number ofREs (100% means perfect).
The automatic evalua-tion measure we implemented using the XML anno-tation described above provides in fact three scores:1.
The number of times the document an RErefers to is correctly identified.
This is infor-mative only when a dialog deals with morethan one document.2These numbers were found using the evaluation softwaredescribed below (Section 4.3).
Document element agreementmeans here that the elements had the same ID.3As for the first part of the process, recognizing the REsthat refer to documents, we can only hypothesize that inter-annotator agreement is lower than for the second part.2.
The number of times the document element,characterized by its ID attribute, is cor-rectly identified.
Here, the possible typesof document elements are article: Master-Article, JournalArticle, Articleor Highlight.3.
The number of times the specific part of an ar-ticle is correctly identified (e.g., content, title,author, image, as indicated by the XPath anno-tation in the XML output format).The third score is necessarily lower than the sec-ond one, and the second one is necessarily lowerthan the first one.
The third score is not used for themoment, since our ref2doc algorithms do not targetsub-article elements.
To help adjust the resolutionalgorithm, the scoring program also outputs a de-tailed evaluation report for each meeting, so that ahuman scorer can compare the system?s output andthe correct answer explicitly.4.4 Empirical Analysis of Occurring REsThe patterns of the annotated REs are synthesizedin Table 1 according to the type of entity they re-fer to.
This analysis attempts to derive regular ex-pressions that describe the range of variation of theREs that refer to documents, but without general-izing too much.
Words in capital letters representclasses of occurring words: NEWSP are newspa-per names, SPEC is a specifier (one or more words,e.g., an adjective or a relative sentence), DATE andTITLE are obvious.
Items in brackets are optional,and | indicates an exclusive-or.
The patterns derivedhere could be used to recognize automatically suchREs, except for two categories?anaphors and (dis-course) indexicals?that must be disambiguated.5 Ref2doc Algorithms5.1 Preliminary StudyThe first resolution method we implemented usesco-occurrences of words in the speech transcript andin the documents.
More precisely, for each RE an-notated in the transcript as referring to documents,the words it contains and the words surrounding itin the same utterance are matched, using the cosinemetric, with the bag of words of each logical blockof the document: article, title, author, etc.
To in-crease the importance of the words within the REs,their weight is double the weight of the surroundingwords.
The most similar logical block is consideredto be the referent of the RE, provided the similarityvalue exceeds a fixed threshold (confidence level).Referent # REJournal 6 (le|du) NEWSP2 le journalFront 33 la une NEWSPpage 6 la une DATE+NEWSP(une) 5 (la|une) uneArticle 33 (l?|le premier|le dernier) article31 cet article15 [l?]
article suivant14 un [petit] article SPEC11 [un] autre article [SPEC]7 l?article SPEC5 [l?article] ?TITLE?Title 10 le [grand] titre [principal]4 (premier|second|autre) titreOther 12 [un] autre (point|sujet|text fait) [SPEC]elements 10 .
.
.
(rubrique|encart|enque?te|page|actualite?|highlight|analyse) .
.
.5 (premier|dernier) point3 un [petit] point [SPEC]3 les grands points de l?actualite?3 (le|au) point de vue [SPEC]Graphic 11 .
.
.
(dessin|photo|sche?ma|elements image|figure) .
.
.Authors 6 l?auteur5 le journalisteAnaphors 27 ils12 il8 l?4 (le|au) dernier3 autre chose [SPEC]2 onIndexicals 5 la`4 c?a4 celui-la`2 celui-ci2 celui SPECTable 1: Patterns of REs that refer to documents, inFrench, ordered by the type of the referent (9 REsout of 322 did not follow these patterns).5.2 Algorithm based on Anaphora TrackingA more complex algorithm was designed, which isbased on the identification of anaphoric vs. non-anaphoric REs, as well as co-occurrences of words.The algorithm scans each meeting transcript lin-early (not by channel/speaker), and stores as vari-ables the ?current document?
and the ?current docu-ment element?
or article.
For each RE, the algorithmassigns first the hypothesized document, from thelist of documents associated to the meeting.
REsthat make use of a newspaper?s name are consid-ered to refer to the respective newspaper; the otherones are supposed to refer to the current newspaper,i.e.
they are anaphors.
This simple method does nothandle complex references such as ?the other news-paper?, but obtains nevertheless a sufficient score(see Section 6 below).The algorithm then attempts to assign a documentelement to the current RE.
First, it attempts to findout whether the RE is anaphoric or not, by match-ing it against a list of typical anaphors found in themeetings: ?it?, ?the article?
(bare definite), ?this arti-cle?, ?the author?
(equivalents in French).
If the REis anaphoric, then it is associated to the current arti-cle or document element?a very simple implemen-tation of a focus stack (Grosz et al, 1995)?exceptif the RE is the first one in the meeting, which isnever considered to be anaphoric.If the RE is not considered to be anaphoric, thenthe algorithm attempts to link it to a document el-ement by comparing the content words of the REwith those of each article.
The words of the REare considered, as well as those of its left and rightcontexts.
A match with the title of the article, orthe author name, is weighted more than one withthe content.
Finally, the article that scores the mostmatches is considered to be the referent of the RE,and becomes the current document element.Several parameters govern the algorithm, in par-ticular the weights of the various matches?the ninepairs generated by {RE word, left context word,right context word} ?
{title or subtitle word, au-thor word, contents word}?and the size of the leftand right context?the number of preceding andfollowing utterances, and the number of words re-tained.
Evaluation provides insights about the bestvalues for these parameters.6 Results and Observations6.1 Baseline and Best ScoresWe provide first some baseline scores on the set of15 meetings and 322 REs, that is, scores of verysimple methods against which our algorithms mustbe compared (rather than against a 0% score).
ForRE ?
document association, always choosing themost frequent newspaper leads to 82% accuracy(265 REs out of 322).
But some meetings dealonly with one document; if we look only at meet-ings that involve more than one newspaper, then thescore of this baseline procedure is 50% (46/92), amuch lower value.
Regarding RE ?
document ele-ment association, if the referent is always the frontpage as a whole (/Newspaper), then accuracyis 16%.
If the referent is always the main article(/MasterArticle[ID=?1?
]), then accuracy is18%?in both cases quite a low value.The word co-occurrence algorithm (described inSection 5.1) correctly solves more than 50% of theselected REs, in a preliminary evaluation performedon six meetings.
This simple algorithm gives inter-esting results especially when REs belong to an ut-terance that is thematically close to the content ofa document?s logical block.
However, the methoduses only thematic linking and, furthermore, doesnot take advantage of all the various documentstructures.4 The 50% score should thus be consid-ered more as another baseline.The second algorithm (described in Section 5.2)reaches 98% accuracy for the identification of doc-uments referred to by REs, or 93% if we take intoaccount only the meetings with several documents;remember that baseline was 82%, respectively 50%.The accuracy for document element identificationis 73% (237 REs out of 322).
If we score onlyREs for which the document was correctly identi-fied, the accuracy is 74% (236 REs out of 316), alittle higher.6.2 Score-based Analysis of the AlgorithmThe best scores quoted above are obtained whenonly the right context of the RE is considered formatching (i.e.
the words after the RE), not the leftone.
Also, the optimal number of words to look forin the right context is about ten.
If the right contextis not considered either, the score drops at 40%.Regarding the weights, a match between the REand the title of an article appears to be more im-portant than one between the right context and thetitle, and much more important than matches withthe content of the article: weights are about 15 vs.10 vs. 1.
All these values have been determined em-pirically, by optimizing the score on the availabledata.
It is possible that they change slightly whenmore data is available.If anaphor tracking is disabled, the accuracy ofdocument element identification drops at 65%, i.e.35% of the REs are linked to the wrong documentelement.
Anaphor tracking is thus useful, thoughapparently not essential: dropping it leads to an al-gorithm close to our first attempt (Section 5.1).Since the automatic scorer provides a detailedevaluation report for each meeting, we are in the4For instance, it cannot solve references related to the doc-ument topological information (e.g.
?the figure at the bottom?
),or related to the document logical structure (e.g.
?the author ofthe first article?
), which need a semantic analysis of the REs.process of analyzing the errors to find systematicpatterns, which could help us improve the algo-rithm.
Rules depending on the lexical items in theRE seem to be required.7 Applications7.1 Speech to Document AlignmentThe resolution of references to documents is partof a cross-channel process aimed at detecting linksbetween what was said during a meeting and thedocuments related to the meeting.
The process en-hances dialog and document processing, as well asthe multi-media rendering of the results.
Transcript-to-document alignment allows the generation of anenhanced transcript which is aligned also with therelevant documents, thanks to hyperlinks from tran-script to document zones.
Such a mechanism is in-tegrated in the query and browsing interfaces thatwe are building.Reference-based alignment is not the only wayto align documents with the speech transcript.
Wehave proposed two other techniques (Mekhaldi etal., 2003; Lalanne et al, 2004).
Citation-basedalignment is a pure lexicographic match betweenterms in documents and terms in the speech tran-scription.
Thematic alignment is derived from se-mantic similarity between sections of documents(sentences, paragraphs, logical blocks, etc.)
andunits of the dialog structure (utterances, turns, andthematic episodes).
We have implemented an al-gorithm that uses various state-of-the-art similar-ity metrics (cosine, Jaccard, Dice) between bags ofweighted words.For matching spoken utterances with documentlogical blocks, using cosine metric, recall is 0.84,and precision is 0.77, which are encouraging re-sults.
And when matching speech turns with log-ical blocks, recall stays at 0.84 and precision risesto 0.85.
On the other hand, alignment of spoken ut-terances to document sentences is less precise butis more promising since it relies on less processing.Using Jaccard metric, recall is 0.83, and precision is0.76 (Lalanne et al, 2004).
Thematic units have notbeen considered yet, for want of reliable automaticsegmentation.Reference-based alignment is complementary toother methods; these could be integrated in a com-mon framework, so that they can be consolidatedand compared.
Their fusion should allow for morerobust document-to-speech alignment.7.2 Overall Application: Meeting Processingand RetrievalA promising use of human dialog understanding isfor the processing and retrieval of staff or businessmeetings (Armstrong et al, 2003).
When meetingsdeal with one or several documents, it is importantto link in a precise manner each episode or even ut-terance of the meeting to the sections of the doc-uments that they refer to.
Considering users whohave missed a meeting or want to review a meet-ing that they attended, this alignment is required fortwo types of queries that appear in recent studies ofuser requirements (Lisowska et al, 2004).
First, theusers could look for episodes of a meeting in whicha particular section of a given document was dis-cussed, so that they can learn what was said aboutthat section.
Second, the relevant documents couldautomatically be displayed when the users browse agiven episode of a meeting?so that a rich, multi-modal context of the meeting episode is presented.8 ConclusionThis article described a framework and an algorithmfor solving references made to documents in meet-ing recordings by linking referring expressions tothe document elements they denote.
The imple-mentation of the algorithm, together with test data(annotated meeting documents and transcripts) andan evaluation metric, show that the best results areobtained when combining anaphora tracking with aweighted lexical matching between RE plus rightcontext, against title plus article contents.An extension of the present algorithm is understudy, in which REs are processed differently ac-cording to their type: REs explicitly referring to anarticle (?the article?, ?the section?
), REs referring topositions (?the article at the bottom left?
), REs refer-ring to the entities of the contents, etc.
These couldbe matched to various data categories from the doc-ument representations.Since printed documents and spoken interactionare two important modalities in communication, thisarticle is also a step towards cross-modal appli-cations.
The reference-based alignment betweentranscripts and documents generates enriched tran-scripts, with explicit information about the contentsand the timing of document mentions; conversely, italso helps document structuring.
These in turn en-hance browsing and searching capabilities for mul-timodal meeting processing and retrieval.AcknowledgementsThis work is part of (IM)2, Interactive Mul-timodal Information Management, a NCCRsupported by the FNS / Swiss Govern-ment (www.im2.ch).
The authors are in-volved in two (IM)2 projects: IM2.MDM,Multimodal Dialogue Management (seehttp://www.issco.unige.ch/projects/im2/mdm/) and IM2.DI, Document Integration(see http://diuf.unifr.ch/im2/).The data we used is available fromhttp://diuf.unifr.ch/im2/data.html.We thank Emmanuel Palacio, intern at ISSCO, forhis contribution to the inter-annotator agreementtest.
We are also grateful to the reviewers for theirhelpful suggestions.ReferencesSusan Armstrong, Alexander Clark, GiovanniCoray, Maria Georgescul, Vincenzo Pallotta, An-drei Popescu-Belis, David Portabella, Martin Ra-jman, and Marianne Starlander.
2003.
Naturallanguage queries on natural language data: adatabase of meeting dialogues.
In NLDB 2003,Burg/Cottbus, Germany.Michael Devitt and Kim Sterelny.
1999.
Languageand Reality: an Introduction to the Philosophyof Language.
The MIT Press, Cambridge, MA,USA, 2nd edition.Robert Gaizauskas and Kevin Humphreys.
1997.Using a semantic network for information extrac-tion.
Natural Languge Engineering, 3(2-3):147?169.Barbara J. Grosz, Aravind K. Joshi, and Scott We-instein.
1995.
Centering: A framework for mod-eling the local coherence of discourse.
Computa-tional Linguistics, 21(2):203?225.Karim Hadjar, Maurizio Rigamonti, Denis Lalanne,and Rolf Ingold.
2004.
Xed: a new tool for ex-tracting hidden structures from electronic docu-ments.
In Workshop on Document Image Analy-sis for Libraries, Palo Alto, CA, USA.Lynette Hirschman.
1997.
MUC-7 coreference taskdefinition 3.0.
Technical report, MITRE Corp.,13 July 1997.Carla Huls, Wim Claassen, and Edwin Bos.
1995.Automatic referent resolution of deictic andanaphoric expressions.
Computational Linguis-tics, 21(1):59?79.Denis Lalanne, Dalila Mekhaldi, and Rolf Ingold.2004.
Talking about documents: revealing amissing link to multimedia meeting archives.In Document Recognition and Retrieval XI -IS&T/SPIE?s Annual Symposium on ElectronicImaging, San Jose, CA, USA.Agnes Lisowska, Andrei Popescu-Belis, and SusanArmstrong.
2004.
User query analysis for thespecification and evaluation of a dialogue pro-cessing and retrieval system.
In LREC 2004, Lis-bon, Portugal.William G. Lycan.
2000.
Philosophy of Language:a Contemporary Introduction.
Routledge, Lon-don, UK.Dalila Mekhaldi, Denis Lalanne, and Rolf Ingold.2003.
Thematic alignment of recorded speechwith documents.
In ACM DocEng 2003, Greno-ble, France.Ruslan Mitkov.
2002.
Anaphora Resolution.
Long-man, London, UK.Ivandre?
Paraboni and Kees van Deemter.
2002.
To-wards the generation of document deictic refer-ences.
In Kees van Deemter and Rodger Kib-ble, editors, Information Sharing: Reference andPresupposition in Language Generation and In-terpretation, pages 329?352.
CSLI Publications,Stanford, CA, USA.Andrei Popescu-Belis, Isabelle Robba, and Ge?rardSabah.
1998.
Reference resolution beyond coref-erence: a conceptual frame and its application.In Coling-ACL ?98, volume II, pages 1046?1052,Montre?al, Canada.
Universite?
de Montre?al.Andrei Popescu-Belis, Maria Georgescul, Alexan-der Clark, and Susan Armstrong.
2004.
Buildingand using a corpus of shallow dialogue annotatedmeetings.
In LREC 2004, Lisbon, Portugal.Andrei Popescu-Belis.
2003.
Evaluation-driven de-sign of a robust reference resolution system.
Nat-ural Language Engineering, 9(3):281?306.Susanne Salmon-Alt and Laurent Romary.
2004.RAF: Towards a reference annotation framework.In LREC 2004), Lisbon, Portugal.Candace Sidner.
1983.
Focusing in the compre-hension of definite anaphora.
In M. Brady andR.
Berwick, editors, Computational Models ofDiscourse, pages 267?330.
MIT Press, Cam-bridge, MA.Gabriel Skantze.
2002.
Coordination of referringexpressions in multimodal human-computer dia-logue.
In ICSLP 2002, Denver, CO, USA.Kees van Deemter and Rodger Kibble.
2000.
Oncoreferring: Coreference in muc and related an-notation schemes.
Computational Linguistics,26(4):629?637.
