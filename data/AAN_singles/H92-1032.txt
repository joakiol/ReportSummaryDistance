RECENT TOPICS IN SPEECH RECOGNIT ION RESEARCHAT NTT LABORATORIESSadaoki Furui, Kiyohiro Shikano, Shoichi Matsunaga, Tatsuo Matsuoka,Satoshi Takahashi, and Tomokazu YamadaNTT Human Interface Laboratories3-9-11, Midori-cho, Musashino-shi, Tokyo, 180 JapanABSTRACTThis paper introduces three recent opics in speech recognitionresearch at NTT (Nippon Telegraph and Telephone) Human In-terface Laboratories.The first topic is a new HMM (hidden Markov model) techniquethat uses VQ-code bigrams to constrain the output probabilitydistribution of the model according to the VQ-codes of previonsframes.
The output probability distribution changes dependingon the previous frames even in the same state, so this methodreduces the overlap of feature distributions with different pho-nemes.The second topic is approaches for adapting a syllable trigrammodel to a new task in Japanese continuous speech recognition.An approach which uses the most recent input phrases for adap-tation is effective in reducing the perplexity and improvingphrase recognition rates.The third topic is stochastic language models for sequences ofJapanese characters to be used in a Japanese dictation systemwith unlimited vocabulary.
Japanese characters consist of Kanji(Chinese characters) and Kana (Japanese alphabets), and eachKanji has several readings depending on the context.
Our dicta-tion system uses character-trigram probabilities as a sourcemodel obtained from a text database consisting of both Kanji andKana~ and generates Kanji-and-Kana sequences directly frominput speech.1.
PHONEME HMM CONSTRAINED BYSTATISTICAL VQ-CODE TRANSITION1.1 IntroductionSpeaker-independent phoneme models need a largeamount of training dam to cover the phonetic features ofvarious speakers and various phoneme nvironments.However, more training data leads to broader spectral fea-ture distributions of each phoneme.
One speaker's spec-tral feature distribution often overlaps the distributions ofdifferent phonemes of other speakers.
This causes confu-sion and degrades recognition performance.It has widely been confirmed that transitional spectral in-formation, such as that represented by the so-called elta-cepstrum, is effective for decreasing these overlaps andimproving the performance of speaker-independent rec-ognition when it is used together with instantaneous spec-tral information \[1\].
The delta-cepstrum attempts tomodel the differential spectnma.
The second-order differ-ential spectrum \[2\]\[3\] has also been used to further im-prove the performance.In the vector quantization (VQ) -based recognition, an-other kind of transitional spectral information can be rep-resented by VQ-code sequences.
Conditional models ofVQ-code transitions have been proposed to obtain accu-rate speech models \[4\]\[5\].
However, it is very difficult toobtain conditional models from the training data in a realsituation, since numerous parameters must be estimated.We have tried to use bigrams of VQ-code sequences torepresent statistical transitional information and restrictthe feature distributions to a suitable region \[6\].
Thismethod reduces the overlap of feature distributions be-tween phonemes without requiring a huge amount oftraining data.1.2 Bigram-constrained HMMA bigram-constrained HMM is obtained by combining aVQ-code bigram and the conventional HMM.
The outputprobability distribution of the model changes dependingon the VQ-code of the previous frame even in the samestate.
A block diagram of the procedure generating thebigram-constrained HMM is shown in Fig.
1.First, a universal codebook is generated from a largeamount of speech data consisting of utterances of manyspeakers, and conventional speaker-independent pho-neme HMMs are trained using this codebook.
Speechdata for calculating a VQ-code bigram is collected andfuzzy-vector-quantized using the universal codebook.The VQ-eode bigram probability is given by162Input speechI Ve,~,~r L quantizafion \]lBigram modelBigram probability:e (e j l  el)lBigram-constrainedphoneme HMMokt(~ j i ~i) = ~ p (~i i ~.# ok~ci~p (c m I c i) okt(cm)m=1Fig.
1.
Block diagram for generating bigram-constrained HMMu~,.,,c~u~,c)p (c~lc)= 't m(1)where c. and c i are VQ-codes of the current and the pre-ceding t/rames, respectively.
Here, u(y:c/) is the member-ship value of the VQ-code % for feature vector y,.The output probability of each VQ-code associated withthe transition from state k to state I is calculated as a condi-tional probability according to the preceding frame VQ-code, such asp (c~l c) o~t(c)o~(c~l c~ - Np (c,I c) ok~c,9m=l(2)where oM(~) is the output probability of the current frameVQ-code % for the transition from state k to state l, and Nis the codebook size.There are several types of bigram-constrained HMMs de-pending on the method of calculating the VQ-codebigram.
A speaker-dependent bigram-constrained HMMis obtained by using speech data of an input speaker forthe bigram calculation.
A speaker-independent bigram-constrained HMM, on the other hand, is obtained by usingspeech data of many speakers different from the inputspeaker.
Moreover, the bigram can be calculated sepa-rately for each phoneme (phoneme-dependent bigram) orjointly for all phonemes (phoneme-independent bigrarn).1.3 Experimental ResultsThe proposed method was evaluated by an 18-Japanese-consonant recognition task.
The 5240-Japanese word setsuttered by 10 males and 10 females were used.
Phonemeperiods extracted from the even-numbered words by 16speakers were used for training the conventional HMMs,and those from odd-numbered words of the other fourspeakers were used for evaluation.
216 phonetically-bal-anced-Japanese-word sets uttered by the four test speakerswere used to calculate speaker-dependent bigrams.
Aspeaker-independent bigram was obtained using all thetraining utterances by the 16 training speakers.Multiple codebooks were created for each set of the fea-ture parameters: 16 cepstrum coefficients, 16 delta cep-strum coefficients, and delta energy.
The frame period forfeature xtraction was 8,ms.
Codebook sizes were 256,256, and 64, respectively.
The VQ-code bigrams werecalculated independently for each codebook.
Phoneme-dependent bigrams were calculated referring to manuallysegmented phoneme labels.
The HMMs had four statesand three loops.
Each phoneme had two models, one forthe beginning and the other for the middle of words.Average phoneme recognition rates for various bigramconditions are shown in Table 1.
It can be concluded thatthe phoneme-dependent bigram is much better than thephoneme-independent bigram.
The recognition rate usingthe phoneme- and speaker-dependent bigrams achieved78.6%, which is 7.8% higher than that obtained by the tra-ditional HMM without combining the bigrams.
Even thespeaker-independent bigrarn can improve the recognitionrate by 5.5%.Table 1 - Phoneme recognition rateSpeaker-Bigram- independe~atconstrainedHMM Speaker-dependentPhoneme-independent73.8%Phoneme-dependent76.3%74.9% 78.6%Conventional HMM 70.8% (speaker-independent)These experiments confirm the effectiveness of thebigram-constrained HMM, with which output probabili-ties are conditioned by the VQ-code bigram.1632.
'\]?ASK ADAPTATION IN STOCHASTICLANGUAGE MODELS FORCONTINUOUS SPEECH RECOGNITION2.1 IntroductionOne of the ultimate goals of automatic speech recognitionis to create a device capable of transcribing speech intowritten text.
The most typical structure of the recognizerconsists of an acoustic processor and a linguistic decoder.Most of the recent linguistic decoders use stochastic lan-guage models, such as bigrams and trigrams of linguisticunits.
In order to obtain a reliable stochastic languagemodel, which achieves good recognition performance, itis necessary to use a very large text database.
It is alsonecessary that the task of the database is similar to the rec-ognition task.
When the recognition task is changed, rec-ognition performance decreases because the languagemodel is no longer appropriate.
However, it is not alwayspossible to obtain a very large text database for each newtask.
Therefore, it is very important to establish amethodof adapting the statistical language model to a new taskusing a small amount of text similar to the recognitiontask.2.2 Model AdaptationWe have investigated two approaches for adapting a syl-lable-trigram odel to a new task in a Japanese transcrip-tion system, a phonetic typewriter, based on continuousspeech recognition \[7\].
In this system, sentences are as-sumed to be spoken phrase by phrase.
Japanese syllables,which are basic linguistic units, roughly correspond toconsonant-vowel concatenation u its.
The first adapta-tion method, "preliminary learning", uses a small amountof text similar to the recognition task, and the secondmethod, "successive l arning", is based on supervisedlearning using the most recent input phrases.
Since thegoal of the system is to transcribe speech into written text,recognition errors are finally corrected by the user.
There-fore, supervised learning can be applied using text whichhas recently been input to the system.The successive learning method using "cache" text wasfirst proposed by Kuhn et al for a stochastic languagemodel based on a word-trigram odel \[8\].
They showedthat this method greatly reduced the test-set perplexity.We applied this method to the syllable-trigram odels.An initial syllable-trigram odel based on a large text da-tabase on a specific task or on a general task covetingseveral fields is assumed to be given.
Figure 2 shows theadaptation approaches for trigram models by preliminarylearning and successive l arning.
On the right-hand sideof the figure, the top row corresponds tosuccessive l arn-ing and the second row corresponds topreliminary learn-ing.
The adapted trigram is generated using the deletedinterpolation technique.\Ad tedgram modelJ/Successive l arning ,r?
~ \[ Most recent \[--(Trlgram model ~ input  phrases)Preliminary learning\I Specific/general 1 trigram modelfrom large amount of textFig.
2.
Adaptation of tfigram models2.3 Experimental ResultsThe effect of each adaptation method was evaluated withsyllable perplexities and phrase recognition rates.
Twolarge text databases about conference r gistration (1.4 ?104 kbytes, 9.3 ?
10 4 phrases) and about travel arrange-ment (1.1 ?
104 kbytes, 7.9 ?
10 4 phrases) were used in theexperiments.
The recognition task concerned conferenceregistration.
The travel arrangement database was used togenerate an initial trigram model on a specific task differ-ent from the recognition task.In successive l arning, the initial trigrarn model generatedfrom the travel arrangement database was modified usingthe most recent 100 phrases at every fixed number of inputphrases.
Since the number of available phrases for thefirst 100 input phrases was less than 100, phrases of thesimilar task were added to keep the total number of train-ing phrases at 100, as shown in Fig.
3.1-st phrase , 61-st phrase , Over 101-st phrase40 phrases ~ 100 most=7:pots J 100 phrases J r=ent inputsFig.
3.
Construction of learning text in successive l arning164The recognition process flow of the phonetic typewriter isas follows: Cepstra, delta-cepstra and delta-energy are ex-tracted for each frame of input speech and are fuzzy-vec-tor-quantized.
Phoneme sequence likelihood is then cal-culated as a joint likelihood combining acoustic and syn-tactic likelihoods.
The acoustic likelihood is derived fromphoneme-based HMMs, and the syntactic one is obtainedby a predictive LR parser \[9\] and the syllable trigram.Each HMM is trained by word utterances.
The joint like-lihood is maximized to obtain the solution.As a reference, speaker-dependent recognition tests werefirst carried out on 279 phrases uttered by one malespeaker.
The trigrarn model was generated from the largeconference registration text database, which is the sametask as the recognition task.
The syllable perplexity andthe phrase recognition rate were 12.2 and 64.2%, respec-tively.
These values were the targets for the adaptation.Table 2 shows syllable perplexities and phrase recogni-tion rates for various learning conditions.
For the succes-sive learning ease, the perplexities are shown as a functionof the learning period.
The perplexity was reduced from24.5 to 18.1 by the adaptation using 100 phrases of thesimilar text, and was reduced to 14.6 by successive l arn-ing at every 10 phrases using the most recent 100 phrases.This clearly shows that successive l arning is more effec-tive than preliminary learning, and that the more frequentthe successive l arning is, the more effective it becomes.Table 2 - Syllable perplexity and phrase recognition rateLearning methodNo adaptationPreliminary learningSuccessiveevery 30 phrasesevery 20 phrasesevery 10 phrese~evea'y 5phrasesPe~le~ty~.518.115.815A14.614ARecognitionrate42.3%46.6%50.9%A recognition experiment for successive learning wasconducted with learning at every 10 phrases.
The recogni-tion rates were improved from 42.3% to 46.6% by pre-liminary learning and to 50.9% by successive learning.Although still there is a gap between the performancesbased on training using a large text database and adapta-tion, these results confirm that the successive learningmethod is effective.3.
CHARACTER SOURCE MODELINGFOR A JAPANESE DICTATION SYSTEM3.1 IntroductionJapanese sentences are usually written using both Kana(Japanese alphabets) and Kanji (Chinese characters).Kana are the minimal inguistic units in the written formand correspond to Japanese syllables, which consist of aconsonant-vowel pair or a single vowel.
Kanji are linguis-tic units having one or more meanings and pronuncia-tions, and the pronunciations can be written by Kana se-quences.
Japanese words are made up of sequences ofKana and Kanji.
For convenience we will use "Kanji" torepresent both Kana and Kanji.In English, word sequence probability is usually used tomake a language model.
However in Japanese, sincewords are not clearly defined, Kana sequence probabilityhas usually been effectively used for speech recognition.We are trying to build a Japanese dictation system using a"Kanji" source model, instead of using a Kana sourcemodel, for the following reasons \[10\]\[11\].1) For a given length of character source, a "Kanji" sourcemodel can effectively deal with a longer phoneme con-text.2) A "Kanji" source model can directly convert speechinto Kana and Kanji sequences, without post-processingof Kana-to-Kanji conversion.3.2 Character Source ModelingA "Kanji"-trigram probability is calculated using a textdatabase to construct a character source model.
Since or-dinary Japanese texts use several thousand different"Kanji", the trigrams obtained using practical databasesare very sparse.
To alleviate this problem, the deleted in-terpolation algorithm is used.
That is, the improvedtrigram ~a) is estimated by linear combination of a zero-gram poor, unigrarn p?o, bigram pat, and trigram p~3~:^o~ 2o p<O~ 23pO) (3) p _= +~pO)+~p~2)+Test-set perplexities and the number of different charac-ters for three different tasks are listed in Table 3.
The taskof the recognition test data is the conference r gistration.When the tasks of training and test data are the same, theKana-based perplexities of "Kanji" source models aresmaller than those of Kana source models.
The results165shown in the table indicate that a "Kanji" source model isefficient for the Japanese dictation system, and that thesource model is highly dependent on the task.Table 3 - Test-set Kana-based perplexity for text databaseand number of different charactersTe~ttdatabasefo~ trainingConferenceregistrationTravelarrangcmeaatBothKana-basedperplexityKana "Kanji"10.5 9,718.6 31.39.6 10.1Number of differentcharactersKana "Kanji"117 1362114 1480120 16963.3 Japanese Dictation SystemFigure 4 is a schematic diagram of the dictation system.This system dictates phrase-by-phrase input speech usingthe HMM-LR method.
HMMs are used for phoneme rec-ognition, and a "Kanji" source model and a predictive LRparser are used for the language processing.
The predic-tive LR parser predicts aphoneme of the input speech suc-cessively from left to fight (from the beginning to the end)according to the context-free r writing rules, and sends itto the HMM phoneme verifier.
The phoneme verifier cal-culates the likelihood of the predicted phoneme for theinput speech, and returns the score to the LR parser.
In thereduce action of the LR parser, a phoneme sequence isconverted into a "Kanji", based on the weighted sum ofthe HMM likelihood and the trigram likelihood.HMM phonememodels1PhonemeverifierSpeech inputI I IPhoneme \]I prediction I Predictive, ~  LR parser"Kanji" ~..quer~eoutputFig.
4.
Schematic diagram of Japanese dictation systemEach Kanji character has several readings deper~ding onthe context.
The "Kanji" trigram, however, is calculatedfrom only the character sequences in the training text da-tabase, neglecting the reading of the "Kanji", and context-independent rewriting rules for a "Kanji"-to-phoneme se-quence are given to make an LR table.
Therefore, theparser produces many contextually wrong candidates.
Tosolve this problem, we added the step of consulting adic-tionary to check the phoneme sequence of the candidateand eliminated the candidates whose phoneme sequenceswere inappropriate o the "Kanji" sequence.
The test-setKana-based perplexities for the "Kanji" source modelswith and without a pronunciation check using a dictionaryare listed, in Table 4.Table 4 , Test-set Kana-based perplexityfor "Kanji" source modelsTextdatabasefor trainingConferenceregistrationKana-bascd perplexityWithoutdictionary9.7Withdictionary7.7Travel 31.3 25.7arrangementBoth 10.1 8.03.4 Experimental ResultsSpeaker-dependent transcription experiments were per-formed.
HMM phoneme models were made from 5240Japanese words and 216 phonetically balanced words spo-ken by a male speaker.
The "Kanji" source model wasobtained from the text database of the conference r gistra-tion task.
Test data consisted of 274 phrases uttered by thesame speaker.The transcription rates (top and top four) are shown inTable 5.
A correct phrase, here, means an output phrasecandidate whose "Kanji" sequence and pronunciation areboth correct, and the character t anscription rate is calcu-lated by the summation of correct output characters, ne-glecting insertion and deletion.
These results indicate thatthe proposed method of pruning based on the "Kanji" se-quence pronunciation is effective in eliminating candi-dates whose readings do not fit the context.166We are also trying another method using a pronunciation-tagged "Kanji" source model to further educe erroneousoutputs that have inappropriate r adings of "Kanji" \[11\].Table 5 - Phrase and character t anscription rateDictionary(Is058A%Transcription ratePhrases(lst- 4th)70.8%"Kanji"charactersWithout 71.2%With 63.9% 74.5% 78.5%model for speech recognition", IEEE Trans.
PAMI-12, 6,pp.570-583 (1990)\[9\] T. Hanazawa, K. Kita, S. Nakamura, T. Kawabata nd K.Shikano: "ATR HMM-LR continuous peech recognitionsystem", Proe.
IEEE ICASSP 90, $2.4, pp.53-56 (1990)\[10\] T. Yamada; T. Hanazawa, T. Kawabata, S. Matsunaga ndK.
Shikano: "Phonetic typewriter based on phoneme sourcemodeling", Proe.
IEEE ICASSP 91, $3.4, pp.169-172(1991)\[11\] T. Yamada, S. Matsunaga nd K. Shikano: "Japanese dicta-tion system using character source modeling", Proc.
IEEEICASSP 92 (1992) (to be published)4.
DISCUSSIONThree recent opics in speech recognition research at N ITHuman Interface Laboratories were introduced in this pa-per.
We are still continuing our investigations of thesetopics to improve the recognition performances.
Othertopics in progress, but not mentioned here, include re-search on spontaneous speech recognition, neural-net-work-based approaches, HMM training techniques, newevaluation methods of continuous peech recognition, andspeaker ecognition.REFERENCES\[1\] S. Furui: "Speaker-independent isolated word recognitionusing dynamic features of speech spectrum", IEEE Trans.ASSP-34, 1, pp.52-59 (1986)\[2\] S. Furui: "Cepstral analysis technique for automatic speakerverification", IEEE Trans.
ASSP-29, 2, pp.254-272 (1981)\[3\] H. Ney: "Experiments on mixture-density phoneme-mod-elling for the speaker-independent 1000-word speech recog-nition DARPA task", Proc.
IEEE ICASSP 90, S13.9,pp.713-716 (1990)\[4\] P. F. Brown: "The acoustic-modeling problem in automaticspeech recognition", Doctoral thesis, CMU (1987)\[5\] C. J. Wellekens: "Explicit correlation in hidden Markovmodel for speech recognition", Proc.
IEEE ICASSP 87,10.7, pp.384-386 (1987)\[6\] S. Takahashi, T. Matsuoka nd K. Shikano: "PhonemicHMM constrained by statistical VQ-code transition", Proc.IEEE ICASSP 92 (1992) (to be published)\[7\] S. Matsunaga, T. Yamada nd K. Shikano: "Language modeladaptation for continuous speech recognition", 1991 IEEE-SPS Arden House Workshop on Speech Recognition, 8.2(1991)\[8\] R. Kuhn and R. DeMori: "A cache-based natural language167
