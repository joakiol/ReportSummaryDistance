Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 810?820,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsA Probabilistic Morphological Analyzer for SyriacPeter McClanahan, George Busby, Robbie Haertel, Kristian Heal ?,Deryle Lonsdale?, Kevin Seppi, Eric RinggerDepartment of Computer Science, ?Department of Linguistics,?Center for the Preservation of Ancient Religious Texts (CPART)Brigham Young UniversityProvo, Utah 84604 USAhttp://nlp.cs.byu.edu/AbstractWe define a probabilistic morphological ana-lyzer using a data-driven approach for Syriac inorder to facilitate the creation of an annotatedcorpus.
Syriac is an under-resourced Semiticlanguage for which there are no available lan-guage tools such as morphological analyzers.We introduce novel probabilistic models forsegmentation, dictionary linkage, and morpho-logical tagging and connect them in a pipelineto create a probabilistic morphological analyzerrequiring only labeled data.
We explore the per-formance of models with varying amounts oftraining data and find that with about 34,500labeled tokens, we can outperform a reason-able baseline trained on over 99,000 tokens andachieve an accuracy of just over 80%.
Whentrained on all available training data, our jointmodel achieves 86.47% accuracy, a 29.7% re-duction in error rate over the baseline.1 IntroductionOur objective is to facilitate the annotation of a largecorpus of classical Syriac (referred to simply as ?Syr-iac?
throughout the remainder of this work).
Syr-iac is an under-resourced Western Semitic languageof the Christian Near East and a dialect of Aramaic.It is currently employed almost entirely as a liturgi-cal language but was a true spoken language up un-til the eighth century, during which time many pro-lific authors wrote in Syriac.
Even today there aretexts still being composed in or translated into Syr-iac.
By automatically annotating these texts with lin-guistically useful information, we will facilitate sys-tematic study by scholars of Syriac, the Near East,and Eastern Christianity.
Furthermore, languagesthat are linguistically similar to Syriac (e.g., Arabicand Hebrew) may benefit from the methodology pre-sented here.Our desired annotations include morphologicalsegmentation, links to dictionary entries, and mor-phological attributes.
Typically, annotations of thiskind are made with the assistance of language tools,such as morphological analyzers, segmenters, orpart-of-speech (POS) taggers.
Such tools do notexist for Syriac, but some labeled data does exist:Kiraz (1994) compiled an annotated version of thePeshitta New Testament (1920) and a concordancethereof.
We aim to replicate this kind of annota-tion on a much larger scale with more modern tools,building up from the labeled New Testament data,our only resource.
Motivated by this state of affairs,our learning and annotation framework requires onlylabeled data.We approach the problem of Syriac morphologicalannotation by creating five probabilistic sub-modelsthat can be trained in a supervised fashion and com-bined in a joint model of morphological annota-tion.
We introduce novel algorithms for segmenta-tion, dictionary linkage, and morphological tagging.We then combine these sub-models into a joint n-best pipeline.
This joint model outperforms a strong,though na?ve, baseline for all amounts of trainingdata over about 9,900 word tokens.1.1 Syriac BackgroundSince Syriac is an abjad, its writing system doesnot require vowels.
As a dialect of Aramaic, itis an inflected language with a templatic (non-concatenative) morphology, based on a system oftriliteral consonantal roots, with prefixes, suffixes,infixes, and enclitic particles.
Syriac is written from810right to left.
For the purposes of this work, all Syr-iac is transliterated according to the Kiraz (1994)transliteration1 and is written left-to-right whenevertransliterated; the Syriac appearing in the Serto scriptin this paper is shown right-to-left.Since there is no standardized nomenclature forthe parts of a Syriac word, we define the followingterms to facilitate the definitions of segmentation,dictionary linkage, and morphological tagging:?
word token - contiguous characters delimited bywhitespace and/or punctuation?
stem - an inflected form of the baseform andthe main part of the word to which prefixes andsuffixes can be attached; the affixes do not in-flect the stem but include prepositions, objectsuffixes, and enclitic pronouns?
baseform - the dictionary citation form; alsoknown as a lexeme or lemma?
root - the form from which the baseform is de-rivedTo clarify, we will use an example word token??????
?, LMLCCON, which means ?to your (mas-culine plural) king?.
For this word, the stem is ??
?,MLC; the baseform is ???
?, MLCA ?king?
; and theroot is ???,MLC.
To clarify, note that the word token(including the stem) can be spoken and written withvowels as diacritics; however, since the vowels arenot written in common practice and since most textdoes not include them, this work omits any indica-tion of vowels.
Furthermore, the stem is an inflectedbaseform and does not necessarily form a word onits own.
Also, the (unvocalized) stem and root arenot necessarily identical.
In Syriac, the same root??
?, MLC is the foundation for other words such aspromise, counsel, deliberate, reign, queen, kingdom,and realm.1.2 Sub-tasksSegmentation, or tokenization as it is sometimescalled (e.g., Habash and Rambow, 2007), is the pro-cess of dividing a word token into its prefix(es) (ifany), a stem, and a suffix (if any).
For Syriac, each1According to this transliteration all capital letters includingA (?, olaph) and O (?, waw) are consonants.
Additionally, thesemi-colon (;), representing (?, yod), is also a consonant.word token consists of exactly one stem, from zeroto three prefixes, and zero or one suffix.
Each pre-fix is exactly one character in length.
Segmenta-tion does not include the process of parsing the stemfor its inflectional morphology; that step is handledseparately in subsequent processes described below.While segmenting a Syriac word, we can handle allprefixes as a single unit.
It is trivial to segment aprefix cluster into its individual prefixes (one charac-ter per prefix).
Suffixes may be multiple charactersin length and encode the morphological attributes ofthe suffix itself (not of the stem); the suffix usuallyencodes the object of the stem and has its own gram-matical attributes, which we list later.
As an exampleof token segmentation, for the word token ??????
?,LMLCCON, the prefix is ?, L ?to?, the stem is ??
?,MLC ?king?, and the suffix is ??
?, CON ?
(masculineplural) your?.Dictionary linkage is the process of linking a stemto its associated baseform and root.
In most Syriacdictionaries, all headwords are either baseforms orroots, and for a given word these are the only rele-vant entries in the dictionary.
Each Syriac stem isderived from a baseform, and each baseform is de-rived from a root.
There is ambiguity in this cor-respondence which can be caused by, among otherthings, homographic stems generated from differentroots or even from homographic roots.
As such, link-age may be thought of as two separate processes: (1)baseform linkage, where the stem is mapped to itsmost likely baseform; and (2) root linkage, wherethe baseform is mapped to its most likely root.
Forour example ??????
?, LMLCCON, baseform linkagewould map stem ??
?,MLC to baseform ???
?,MLCA,and root linkage would map baseform ???
?,MLCA toroot ??
?, MLC.Morphological tagging is the process of labelingeach word token with its morphological attributes.Morphological tagging may be thought of as twoseparate tagging tasks: (1) tagging the stem and (2)tagging the suffix.
For Syriac, scholars have definedfor this task a set of morphological attributes con-sisting of twelve attributes for the stem and four at-tributes for the suffix.
The attributes for the stemare as follows: grammatical category, verb conju-gation, aspect, state, number, person, gender, pro-noun type, demonstrative category, noun type, nu-meral type, and participle type.
The morphological811Attribute ValueGrammatical Category nounVerb Conjugation N/AAspect N/AState emphaticNumber singularPerson N/AGender masculinePronoun Type N/ADemonstrative Category N/ANoun Type commonNumeral Type N/AParticiple Type N/ATable 1: The values for the morphological attributes ofthe stem ??
?,MLC, ?king?.Attribute ValueGender masculinePerson secondNumber pluralContraction normal suffixTable 2: The values for the morphological attributes ofthe suffix ??
?, CON, ?
(masculine plural) your?.attributes for the suffix are gender, person, number,and contraction.
The suffix contraction attribute en-codes whether the suffix is normal or contracted, aphonological process involving the attachment of anenclitic pronoun to a participle.
These morphologi-cal attributes were heavily influenced by those usedby Kiraz (1994), but were streamlined in order to fo-cus directly on grammatical function.
During mor-phological tagging, each stem is labeled for each ofthe stem attributes, and each suffix is labeled for eachof the suffix attributes.
For a given grammatical cat-egory (or POS), only a subset of the morphologicalattributes is applicable.
For those morphological at-tributes (both of the stem and of the suffix) that donot apply, the correct label is ?N/A?
(not applicable).Tables 1 and 2 show the correct stem and suffix tagsfor the word ??????
?, LMLCCON.The remainder of the paper will proceed as fol-lows: Section 3 outlines our approach.
In Section 4,we describe our experimental setup; we present re-sults in Section 5.
Section 6 contrasts previous workwith our approach.
Finally, in Section 7 we brieflyconclude and offer directions for future work.2 The Syromorph ApproachSince lack language tools, we focus on automaticallyannotating Syriac text in a data-driven fashion basedon the labeled data we have available.
Since seg-mentation, linkage, and morphological tagging arenot mutually independent tasks, we desire modelsfor the sub-tasks to influence each other.
To accom-modate these requirements, we use a joint pipelinemodel (Finkel et al, 2006).
In this section, we willfirst discuss this joint pipeline model, which we callsyromorph.
We then examine each of the individualsub-models.2.1 Joint Pipeline ModelOur approach is to create a joint pipeline model con-sisting of a segmenter, a baseform linker, a rootlinker, a suffix tagger, and a stem tagger.
Figure 1shows the dependencies among the sub-models inthe pipeline for a single word.
Each sub-model(oval) has access to the data and predictions (rect-angles) indicated by the arrows.
For example, for agiven word, the stem tagger has access to the previ-ously predicted stem, baseform, root, and suffix tag.The baseform linker has access to the segmentation,most importantly the stem.The training of syromorph is straightforward.Each of the individual sub-models is trained sepa-rately on the true labeled data.
Features are extractedfrom the local context in the sentence.
The local con-text consists first of predictions for the entire sen-tence from earlier sub-tasks (those sub-tasks uponwhich the sub-task in question depends).
We cre-ated the dependencies shown in Figure 1 taking intoaccount the difficulty of the tasks and natural depen-dencies in the language.
In addition to the predic-tions for the entire sentence from previous sub-tasks,the local context also includes the previous o tags ofthe current sub-task, as the standard order o Markovmodel does.
For example, when the stem tagger isbeing trained on a particular sentence, the local con-text consists of the words in the sentence, the pre-dicted segmentation, baseform, root, and suffix tagsfor each word in the sentence, and additionally thelabels for the previous o stems.
To further elaborate812Figure 1: The syromorph model.
Each rectangle is aninput or output and each oval is a process employing asub-model.on the example, since features are extracted from thelocal context, for stem tagging we extract featuressuch as current stem, previous stem, current base-form, previous baseform, current root, previous root,current suffix tags, and previous suffix tags.
(Here,?previous?
refers to labels on the immediately pre-ceding word token.
)2.2 SegmentationThe syromorph segmentation model is a hybridword- and consonant-level model, based on themodel of Haertel et al (2010) for data-driven dia-critization.
Each of our probabilistic sequence mod-els is a maximum entropy Markov model (MEMM).Haertel et al (2010) showed that the distributionover labels is different for known and words and rarewords.
In this work, we only consider words notseen in training (i.e., ?unknown?)
to be rare.
Follow-ing Haertel et al?s (2010) model, a separate modelis trained for each word type seen in training withthe intent of choosing the best segmentation giventhat word.
This approach is closely related to theidea of ambiguity classes mentioned in Haji?
andHladk?
(1998).To handle unknown words, we back off to aconsonant-level model.
Our consonant-level seg-mentation model uses the notion of BI (Beginningand Inside) tags, which have proven successful innamed-entity recognition.
Since there are threelabels in which we are interested (prefix, stem, andsuffix), we apply the beginning and inside notionto each of them to create six tags: BEGINNING-PREFIX, INSIDE-PREFIX, BEGINNING-STEM,INSIDE-STEM, BEGINNING-SUFFIX, andINSIDE-SUFFIX.
We train an MEMM to predictone of these six tags for each consonant.
Further-more, we constrain the decoder to allow only legalpossible transitions given the current prediction,so that prefixes must come before stems and stemsbefore suffixes.
In order to capture the unknownword distributions, we train the consonant-levelmodel on words occurring only once during training.We call this word- and consonant-level segmenta-tion model hybrid.
As far as we are aware, this is anovel approach to segmentation.2.3 Dictionary LinkageFor dictionary linkage, we divide the problem intotwo separate tasks: baseform linkage and root link-age.
For both of these tasks, we use a hybrid modelsimilar to that used for segmentation, consisting ofa collection of separate MEMMs for each word type(either a stem or baseform, depending on the linker)and amodel for unknown (or rare) words.
For the un-known words, we compare two distinct approaches.The first approach for unknown words is basedon the work of Chrupa?a (2006), including the Mor-fette system.
Instead of predicting a baseform givena stem, we predict what Chrupa?a calls a lemma-class.
A lemma-class is the transformation specifiedby the minimum edit distance between the baseform(which he calls a lemma) and the stem.
The trans-formation is a series of tuples, where each tuple in-cludes (1) whether it was an insertion or deletion,(2) the letter inserted or deleted, and (3) the positionof the insertion or deletion in the string (positionsbegin at zero).
All operations are assumed to oc-cur sequentially, as in Morfette.
For example, thetransformation of XE;N to XEA would proceed asfollows: delete ; from position 2, insert A into po-sition 2, delete N from position 3.813In hybrid-morfette baseform linkage (respec-tively, root linkage), we predict a lemma-class (i.e.,transformation) for each baseform (respectively,root).
The predicted transformation is then appliedto the stem (respectively, baseform) in order to con-struct the actual target baseform (respectively, root).The advantage to this method is that common trans-formations are grouped into a single class, therebyallowing the model to generalize and adequatelypredict baseforms (and roots) that have not beenseen during training, but whose transformations havebeen seen.
This model is trained on all words in or-der to capture as many transformations as possible.The second approach for unknown words, calledhybrid-maxent, uses an MEMM trained on allwords seen in training.
Given a stem (respectively,baseform), this approach predicts only baseforms(respectively, roots) that were observed in trainingdata.
Thus, this method has a distinct disadvan-tage when it comes to predicting new forms.
Thisapproach corresponds directly to the approach tohandling unknown -words by Toutanova and Man-ning (2000) for POS tagging.With regard to baseform and root linkage, we donot use the dictionary to constrain possible base-forms or roots, since we make no initial assumptionsabout the completeness of a dictionary.2.4 Morphological TaggingFor morphological tagging, we break the task intotwo separate tasks: tagging the suffix and taggingthe stem.
Since there are a number of values thatneed to be predicted, we define two ways to ap-proach the problem.
We call the first approach themonolithic approach, in which the label is the con-catenation of all the morphological attribute values.Table 3 illustrates the tagging of an example sen-tence: the stem tag and suffix tag columns containthe monolithic tags for stem tagging and suffix tag-ging.
We use an MEMM to predict a monolithic tagfor each stem or suffix and call this model maxent-mono.
No co-occurrence restrictions among relatedor complementary morphological tags are directlyenforced.
Co-occurrence patterns are observed inthe data, learned, and encoded in the models of thetagging process.
It is worth noting further that con-straints provided by the baseforms ?
predicted bydictionary linkage ?
on the morphological attributesare likewise not directly enforced.
Enforcement ofsuch constraints would require an infusion of expertknowledge into the system.The second approach is to assume that morpho-logical attributes are independent of each other.
Wecall this the independent approach.
Here, each tagis predicted by a tagger for a single morphologicalattribute.
For example, the gender model is ignorantof the other 11 sub-tags during stem tagging.
Usingits local context (which does not include other stemsub-tags), the model predicts the best gender for agiven word.
The top prediction of each of these tag-gers (12, for stem tagging) is then combined na?velywith no notion of what combinations may be validor invalid.
We use MEMMs for each of the single-attribute taggers.
This model is calledmaxent-ind.2.5 DecodingOur per-task decoders are beam decoders, withbeam-size b.
In particular, we limit the number ofper-stage back-pointers to b due to the large size ofthe tagset for some of our sub-models.
AlthoughViterbi decoding produces the most probable labelsequence given a sequence of unlabeled words, it ispotentially intractible on our hybrid models due tothe unbounded dependence on previous consonant-level decisions.
Our beam decoders produce a goodapproximation when tuned properly.Decoding in syromorph consists of extending theper-task decoders to allow transitions from each sub-model to the next sub-model in the pipe.
For exam-ple, in our pipeline, the first sub-model is segmen-tation.
We predict the top n segmentations for thesentence (i.e., sequences of segmentations), where nis the number of transitions tomaintain between eachsub-task.
Then, we run the remaining sub-tasks witheach of the n sequences as a possible context.
Aftereach sub-task is completed, we narrow the numberof possible contexts back to n.We swept b and n for various values, and foundb = 5 and n = 5 to be good values that balancedbetween accuracy and time; larger values saw onlyminute gains in accuracy.814Word Transliteration Pre.
Stem Suffix Baseform Root Suff.
Tags Stem Tags?????
OEBDT O EBDT EBD EBD 0000 011012200000????
ANON ANON HO HO 0000 300023222000????
LALHN L ALH N ALHA ALH 1011 200310200200??????
MLCOTA MLCOTA MLCOTA MLC 0000 200310300200?????
OCHNA O CHNA CHNA CHN 0000 200320200200??????
OMLCA O MLCA MLCA MLC 0000 200320200200Table 3: Part of a labeled Syriac sentence ??????
?????
??????
????
????
????
?, ?And you have made them a kingdom andpriests and kings for our God.?
(Revelation 5:10)3 Experimental SetupWe are using the Syriac Peshitta New Testament inthe form compiled by Kiraz (1994).2 This data issegmented, annotated with baseform and root, andlabeled with morphological attributes.
Kiraz andothers in the Syriac community refined and correctedthe original annotation while preparing a digital andprint concordance of the New Testament.
We aug-mented Kiraz?s version of the data by segmentingsuffixes and by streamlining the tagset.
The datasetconsists of 109,640 word tokens.Table 3 shows part of a tagged Syriac sentence us-ing this tagset.
The suffix and stem tags consist ofindices representing morphological attributes.
In theexample sentence, the suffix tag 1011 represents thevalues ?masculine?, ?N/A?, ?plural?, ?normal suf-fix?
for the suffix attributes of gender, person, num-ber, and contraction.
Each value of 0 for each stemand suffix attribute represents a value of ?N/A?, ex-cept for that of grammatical category, which alwaysmust have a value other than ?N/A?.
Therefore, thesuffix tag 0000 means there is no suffix.For the stem tags, the attribute order is the sameas that shown in Table 1 from top to bottom.
Thefollowing describes the interpretation of the stemvalues represented in Table 3.
Grammatical cate-gory values 0, 2, and 3 represent ?verb?, ?noun?,and ?pronoun?, respectively.
(Grammatical cate-gory has no ?N/A?
value.)
The verb conjugationvalue 1 represents ?peal conjugation?.
Aspect value1 represents ?perfect?.
State value 3 represents ?em-phatic?.
Number values 1 and 2 represent ?singular?and ?plural?.
Person values 2 and 3 represent ?sec-2The Way International, a Biblical research ministry, anno-tated this version of the New Testament by hand and required15 years to do so.ond?
and ?third?
person.
Gender values 2 and 3 rep-resent ?masculine?
and ?feminine?.
Pronoun typevalue 2 represents ?demonstrative?.
Demonstrativecategory value 2 represents ?far?.
Finally, noun type2 represents ?common?.
The last two columns of 0represent ?N/A?
for numeral type and particle type.We implement five sub-tasks: segmentation, base-form linkage, root linkage, suffix tagging, and stemtagging.
We compare each sub-task to a na?ve ap-proach as a baseline.
In addition to desiring goodsub-models, we also want a joint pipeline model thatsignificantly outperforms the na?ve joint approach,which is formed by using each of the following base-lines in the pipeline framework.The baseline implementation of segmentation is tochoose the most-frequent label: for a given word,the baseline predicts the segmentation with whichthat word appeared most frequently during training.For unknown words, it chooses the largest prefixand largest suffix that is possible for that word fromthe list of prefixes and suffixes seen during train-ing.
(This na?ve baseline for unknown words doesnot take into account the fact that the stem is often atleast three characters in length.
)For dictionary linkage, the baseline is similar:both baseform linkage and root linkage use the most-frequent label approach.
Given a stem, the baselinebaseform linker predicts the baseform with whichthe stem was seen most frequently during training;likewise, the baseline root linker predicts the rootfrom the baseform in a similar manner.
For the un-known stem case, the baseline baseform linker pre-dicts the baseform to be identical to the stem.
Forthe unknown baseform case, the baseline root linkerpredicts a root identical to the first three consonantsof the baseform, since for Syriac the root is exactly815three consonants in a large majority of the cases.The baselines for stem and suffix tagging are themost-frequent label approaches.
These baselinesare similar to maxent-mono and maxent-ind, us-ing the monolithic and independent approaches usedby maxent-mono and maxent-ind.
The differenceis that instead of using maximum entropy, the na?vemost-frequent approach is used in its place.The joint baseline tagger uses each of the compo-nent baselines in then-best joint pipeline framework.Because this framework is modular, we can triviallyswap in and out different models for each of the sub-tasks.4 Experimental ResultsSince we are focusing on under-resourced circum-stances, we sweep the amount of training data andproduce learning curves to better understand howour models perform in such circumstances.
For eachpoint in our learning curves and for all other eval-uations, we employ ten-fold cross-validation.
Thelearning curves use the chosen percentage of the datafor training and a fixed-size test set from each foldand report the average accuracy.The reported task accuracy requires the entire out-put for that task to be correct in order to be counted ascorrect.
For example, during stem tagging, if one ofthe sub-tags is incorrect, then the entire tag is said tobe incorrect.
Furthermore, for syromorph, the out-puts of every sub-task must be correct in order forthe word token to be counted as correct.Moving beyond token-level metrics, in order tounderstand performance of the system at the levelof individual decisions (including N/A decisions),we compute decision-level accuracy: we call thismetric total-decisions.
For the syromorph methodreported here, there are a total of 20 decisions: 2for segmentation (prefix and suffix boundaries), 1for baseform linkage, 1 for root linkage, 4 for suf-fix tagging, and 12 for stem tagging.
This accuracyhelps us to assess the number of decisions a humanannotator would need to correct, if data were pre-annotated by a given model.
Excluding N/A deci-sions, we compute per-decision coverage and accu-racy.
These metrics are called applicable-coverageand applicable-accuracy.We show results on both the individual sub-tasksand the entire joint task.
Since previous sub-tasks can adversely affect tasks further down inthe pipeline, we evaluate the sub-models by plac-ing them in the pipeline with other (simulated) sub-models that correctly predict every instance.
Forexample, when testing a root linker, we place theroot linker to be evaluated in the pipeline with asegmenter, baseform linker, and taggers that returnthe correct label for every prediction.
This gives anupper-bound for the individual model, removes thepossibility of error propagation, and shows how wellthat model performs without the effects of the othermodels in the pipeline.For our results, unknown accuracy is the accuracyof unknown instances, specific to the task, at trainingtime.
In the case of baseform linkage, for example,a stem is considered unknown if that stem was notseen during training.
It is therefore possible to havea known word with an unknown stem and vice versa.As in other NLP problems, unknown instances are amanifestation of training data sparsity.4.1 Baseline ResultsTable 4 is grouped by sub-task and reports the resultsof each of the baseline sub-tasks in the first row ofeach group.
Each of the baselines performs surpris-ingly well.
The accuracies of the baselines for mostof the tasks are high because the ambiguity of thelabels given the instance is quite low: the averageambiguity across word types for segmentation, base-form linkage, root linkage, suffix tagging, and stemtagging are 1.01, 1.05, 1.02, 1.35, and 1.47, respec-tively.Preliminary experiments indicated that if we hadtrained a baseline model using a single prediction (amonolithic concatenation of the predictions for alltasks) per token rather than separating the tasks, thebaseline tagging accuracy would have been lower.Note that the unknown tagging accuracy for themonolithic suffix tagger is not applicable, becausethere were no test suffixes that were not seen duringtraining.4.2 Individual Model ResultsTable 4 also shows the results for the individualmodels.
In the table, SEG, BFL, RTL, SUFFIX,and STEM represent segmentation, baseform link-age, root linkage, suffix tagging, and stem tagging,816Model Total Known UnkSEG baseline 96.75 99.64 69.11hybrid 98.87 99.70 90.83BFL baseline 95.64 98.45 22.28hybrid-morfette 96.19 98.05 78.40hybrid-maxent 96.19 99.15 67.86RTL baseline 98.84 99.56 80.20hybrid-morfette 99.05 99.44 88.86hybrid-maxent 98.34 99.45 69.30SUFFIXmono.
baseline 98.75 98.75 N/Aind.
baseline 96.74 98.78 0.01maxent-mono 98.90 98.90 N/Amaxent-ind 98.90 98.90 N/ASTEMmono.
baseline 83.08 86.26 0.01ind.
baseline 53.24 86.90 0.00maxent-mono 89.48 92.87 57.04maxent-ind 88.43 90.26 40.59Table 4: Word-level accuracies for the individual sub-models used in the syromorph approach.respectively.
Even though the baselines were high,each individual model outperformed its respectivebaseline, with the exception of the root linker.
Twoof the most interesting results are the known ac-curacy of the baseform linkers hybrid-maxent andhybrid-morfette.
As hybrid models, the differencebetween them lies only in the treatment of unknownwords; however, the known accuracy of the mor-fette model drops fairly significantly.
This is dueto the unknown words altering the weights for fea-tures in which those words occur.
For instance, ifthe previous word is unknown and a baseform thatwas never seen was predicted, then the weights onthe next word for all features that contain that un-known word will be quite different than if that pre-vious word were a known word.It is also worth noting that the stem tagger is byfar the worst model in this group of models, but it isalso the most difficult task.
The largest gains in im-proving the entire systemwould come from focusingattention on that task.4.3 Joint Model ResultsTable 5 shows the accuracies for the joint mod-els.
The joint model incorporating ?maxent?
vari-ants performs best overall and on known cases.
TheModel Total Known UnkBaseline 80.76 85.74 28.07Morfette Monolithic 85.96 89.85 44.86Maxent Monolithic 86.47 90.77 40.93Table 5: Word-level accuracies for various joint syro-morph models.0.10.20.30.40.50.60.70.80.90  10  20  30  40  50  60  70  80  90  100Total AccuracyPercentage of Training Databaselinehybrid / hybrid-maxent / maxent-monohybrid / hybrid-morfette / maxent-monoFigure 2: The total accuracy of the joint model.joint model incorporating the ?morfette?
variantsperforms best on unknown cases.Decision-level metrics for the SEG:hybrid /BFL and RTL:hybrid-maxent / SUFFIX andSTEM:maxent-mono model are as follows: fortotal-decisions, the model achieves an accuracyof 97.08%, compared to 95.50% accuracy for thebaseline, amounting to a 35.11% reduction in errorrate over the baseline; for applicable-coverage andapplicable-accuracy this model achieved 93.45%and 93.81%, respectively, compared to the baseline?s90.03% and 91.44%.Figures 2, 3, and 4 show learning curves for to-tal, known, and unknown accuracies for the jointpipeline model.
As can be seen in Figure 2, by thetime we reach 10% of the training data, syromorphis significantly better than the baseline.
In fact, at35% of the training data, our joint pipeline modeloutperforms the baseline trained with all availabletraining data.Figure 3 shows the baseline performing quite wellon known words with very low amounts of data.Since the x-axis varies the amount of training data,the meaning of ?known?
and ?unknown?
evolves aswe move to the right of the graph; consequently, the8170.650.70.750.80.850.90.950  10  20  30  40  50  60  70  80  90  100KnownAccuracyPercentage of Training Databaselinehybrid / hybrid-maxent / maxent-monohybrid / hybrid-morfette / maxent-monoFigure 3: The accuracy of the joint model on knownwords.00.050.10.150.20.250.30.350.40.450  10  20  30  40  50  60  70  80  90  100UnknownAccuracyPercentage of Training Databaselinehybrid / hybrid-maxent / maxent-monohybrid / hybrid-morfette / maxent-monoFigure 4: The accuracy of the joint model on unknownwords.left and right sides of the graph are incomparable.When the percentage of training data is very low,the percentage of unknown words is high, and thenumber of known words is relatively low.
On thisdataset, the more frequent words tend to be less am-biguous, giving the most-frequent taggers an advan-tage in a small random sample.
For this reason, thebaseline performs very well on known accuracy withlower amounts of training data.Figure 4 clearly shows that hybrid-morfette link-ers outperform hybrid-maxent linkers on unknownwords.
However, Figures 2- 4 show that hybrid-morfette?s advantage on unknown words is coun-teracted by its lower performance on known words;therefore, it has slightly lower overall accuracy thanhybrid-maxent.5 Related WorkThe most closely related work to our approach isthe Morfette tool for labeling inflectional morphol-ogy (Chrupa?a et al, 2008).
Chrupa?a et al cre-ated a tool that labels Polish, Romanian, and Span-ish with morphological information as well as base-forms.
It is a supervised learning approach thatrequires data labeled with both morphological tagsand baseforms.
This approach creates two separatemodels (a morphological tagger and a lemmatizer)and combines the decoding process in order to cre-ate a joint model that predicts both morphologicaltags and the baseform.
Morfette uses MEMMs forboth models and has access to predicted labels inthe feature set.
Reported accuracy rates are 96.08%,93.83%, and 81.19% for joint accuracy on datasetstrained with fewer than 100,000 tokens for Roma-nian, Spanish, and Polish, respectively.
The majordifference between this work and ours is the degreeof morphological analysis required by the languages.Chrupa?a et al neglect segmentation, a task not asintuitive for their languages as it is for Syriac.
Theselanguages also require only linkage to a baseform, asno root exists.Also closely related is the work of Daya, Roth, andWintner (2008) on Hebrew.
The authors use the no-tion of patterns into which root consonants are in-jected to compose Semitic words.
They employ lin-guistic knowledge (specifically, lists of prefixes, suf-fixes, and ?knowledge of word-formation processes?combined with SNoW, a multi-class classifier thathas been shown to work well in other NLP tasks.The major difference between this approach and themethod presented in this paper is that this methoddoes not require the extra knowledge required to en-code word-formation processes.
A further point ofdifference is our use of hybrid word- and consonant-level models, after Haertel et al (2010).
Their workbuilds on the work of Shacham and Wintner (2007),which is also related to that of Habash and Rambow,described below.Work by Lee et al (2003) is themost relevant workfor segmentation, since they segment Arabic, closelyrelated to Syriac, with a data-driven approach.
Leeet al use an unsupervised algorithm bootstrappedwith manually segmented data to learn the segmen-tation for Arabic without any additional language re-818sources.
At the heart of the algorithm is a word-leveltrigram language model, which captures the correctweights for prefixes and suffixes.
They report an ac-curacy of 97%.
We opted to use our own segmenterbecause we felt we could achieve higher accuracywith the hybrid segmenter.Mohamed and K?bler (2010a, 2010b) report onclosely related work for morphological tagging.They use a data-driven approach to find the POS tagsfor Arabic, using both word tokens and segmentedwords as inputs for their system.
Although their seg-mentation performance is high, they report that ac-curacy is lower when first segmenting word tokens.They employ TiMBL, a memory-based learner, astheir model and report an accuracy of 94.74%.Habash and Rambow (2005) currently have themost accurate approach for Arabic morphologicalanalysis using additional language tools.
They focuson morphological disambiguation (tagging), givenmorphological segmentation in the output of themorphological analyzer.
For each word, they firstrun it through the morphological analyzer to reducethe number of possible outputs.
They then train aseparate Support Vector Machine (SVM) for eachmorphological attribute (ten in all).
They look at dif-ferent ways of combining these outputs to match anoutput from the morphological analyzer.
For theirbest model, they report an overall tag accuracy of97.6%.Others have used morphological analyzers andother language tools for morphological disambigua-tion coupled with segmentation.
The followingworks exemplify this approach: Diab et al (2004)use a POS tagger to jointly segment, POS tag, andchunk base-phrases for Arabic with SVMs.
Kudoet al (2004) use SVMs to morphologically tagJapanese.
Smith et al (2005) use SVMs for seg-mentation, lemmatization, and POS tagging for Ara-bic, Korean, and Czech.
Petkevi?
(2001) use a mor-phological analyzer and additional simple rules formorphological disambiguation of Czech.
Mansouret al (2007) and Bar-haim et al (2008) both use hid-denMarkov models to POS tag Hebrew, with the lat-ter including segmentation as part of the task.For Syriac, a morphological analyzer is not avail-able.
Kiraz (2000) created a Syriac morphologicalanalyzer using finite-state methods; however, it wasdeveloped on outdated and now inaccessible equip-ment and is no longer working or available to us.6 Conclusions and Future WorkWe have shown that we can effectively model seg-mentation, linkage to headwords in a dictionary, andmorphological tagging using a joint model called sy-romorph.
We have introduced novel approaches forsegmentation, dictionary linkage, and morphologi-cal tagging, and each of these approaches has out-performed its corresponding na?ve baseline.
Further-more, we have shown that for Syriac, a data-drivenapproach seems to be an appropriate way to solvethese problems in an under-resourced setting.We hope to use this combined model for pre-annotation in an active learning setting to aid anno-tators in labeling a large Syriac corpus.
This corpuswill contain data spanning multiple centuries and avariety of authors and genres.
Future work will re-quire addressing issues encountered in this corpus.In addition, there is much to do in getting the over-all tag accuracy closer to the accuracy of individualdecisions.
We leave further feature engineering forthe stem tagger and the exploration of possible newmorphological tagging techniques for future work.Finally, future work includes the application of thesyromorph methodology to other under-resourcedSemitic languages.AcknowledgmentsWe would like to thank David Taylor of the OrientalInstitute at Oxford University for collaboration onthe design of the simplified tagset.
We also recog-nize the assistance of Ben Hansen of BYU on a sub-set of the experimental results.
Finally, we wouldlike to thank the anonymous reviewers for helpfulguidance.ReferencesRoy Bar-haim, Khalil Sima?an, and Yoad Winter.
2008.Part-of-speech tagging ofmodern hebrew text.
NaturalLanguage Engineering, 14(2):223?251.British and Foreign Bible Society, editors.
1920.
TheNew Testament in Syriac.
Oxford: Frederick Hall.Grzegorz Chrupa?a, Georgiana Dinu, and Josef van Gen-abith.
2008.
Learning morphology with Morfette.
InProceedings of the Sixth International Language Re-sources and Evaluation (LREC?08).819Grzegorz Chrupa?a.
2006.
Simple data-drivencontext-sensitive lemmatization.
In Procesamiento delLenguaje Natural, volume 37, pages 121 ?
127.Ezra Daya, Dan Roth, and Shuly Wintner.
2008.Identifying Semitic roots: Machine learning withlinguistic constraints.
Computational Linguistics,34(3):429?448.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.2004.
Automatic tagging of Arabic text: Fromraw text to base phrase chunks.
In Proceedings ofthe 5th Meeting of the North American Chapter ofthe Association for Computational Linguistics/HumanLanguage Technologies Conference (HLT-NAACL04),pages 149?152.Jenny Rose Finkel, Christopher D. Manning, and An-drew Y. Ng.
2006.
Solving the problem of cascadingerrors: Approximate Bayesian inference for linguisticannotation pipelines.
In EMNLP ?06: Proceedings ofthe 2006 Conference on Empirical Methods in NaturalLanguage Processing, pages 618?626.
Association forComputational Linguistics.Nizar Habash and Owen Rambow.
2005.
Arabic to-kenization, part-of-speech tagging and morphologicaldisambiguation in one fell swoop.
In ACL ?05: Pro-ceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics, pages 573?580.
Asso-ciation for Computational Linguistics.Nizar Habash and Owen Rambow.
2007.
Arabic diacriti-zation through full morphological tagging.
In HumanLanguage Technologies 2007: The Conference of theNorth American Chapter of the Association for Com-putational Linguistics; Companion Volume, Short Pa-pers, pages 53?56.
Association for Computational Lin-guistics.Robbie Haertel, Peter McClanahan, and Eric K. Ring-ger.
2010.
Automatic diacritization for low-resourcelanguages using a hybrid word and consonant cmm.In Human Language Technologies: The 2010 AnnualConference of the North American Chapter of the Asso-ciation for Computational Linguistics, pages 519?527.Association for Computational Linguistics.Jan Haji?
and Barbora Hladk?.
1998.
Tagging inflectivelanguages: Prediction of morphological categories fora rich, structured tagset.
In Proceedings of the 17th In-ternational Conference on Computational Linguistics,pages 483?490.
Association for Computational Lin-guistics.George Kiraz.
1994.
Automatic concordance generationof Syriac texts.
In R. Lavenant, editor, VI SymposiumSyriacum 1992, pages 461?.George Anton Kiraz.
2000.
Multitiered nonlinear mor-phology using multitape finite automata: a case studyon Syriac and Arabic.
Computational Linguistics,26:77?105.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields to japanesemorphological analysis.
In Proceedings of EMNLP,pages 230?237.Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-sama Emam, and Hany Hassan.
2003.
Languagemodel based Arabic word segmentation.
In ACL ?03:Proceedings of the 41st Annual Meeting on Associationfor Computational Linguistics, pages 399?406.
Associ-ation for Computational Linguistics.Saib Mansour, Khalil Sima?an, and Yoad Winter.
2007.Smoothing a lexicon-based pos tagger for Arabic andHebrew.
In Semitic ?07: Proceedings of the 2007Workshop on Computational Approaches to SemiticLanguages, pages 97?103.
Association for Computa-tional Linguistics.Emad Mohamed and Sandra K?bler.
2010a.
Arabicpart of speech tagging.
In Proceedings of the Sev-enth International Language Resources and Evalua-tion (LREC?10).Emad Mohamed and Sandra K?bler.
2010b.
Is Arabicpart of speech tagging feasible without word segmen-tation?
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages705?708.
Association for Computational Linguistics.Vladim?r Petkevi?.
2001.
Grammatical agreementand automatic morphological disambiguation of inflec-tional languages.
In TSD ?01: Proceedings of the4th International Conference on Text, Speech and Dia-logue, pages 47?53.
Springer-Verlag.Danny Shacham and Shuly Wintner.
2007.
Morpholog-ical disambiguation of Hebrew: a case study in clas-sifier combination.
In Proceedings of EMNLP-CoNLL2007, the Conference on Empirical Methods in NaturalLanguage Processing and the Conference on Compu-tational Natural Language Learning.
Association forComputational Linguistics.Noah A. Smith, David A. Smith, and Roy W. Tromble.2005.
Context-based morphological disambiguationwith random fields.
In HLT ?05: Proceedings ofthe conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 475?482.
Association for Computational Lin-guistics.K.
Toutanova and C. Manning.
2000.
Enriching theknowledge sources used in a maximum entropy part-of-speech tagger.
In Proceedings of EMNLP, pages63?70.820
