Correct parts extraction from speech recognition results usingsemantic distance calculation, and its application to speechtranslationYumi  WAKITA ,  Jun  KAWAI ;  H i tosh i  I IDAATR Interpret ing Telecommunicat ions Research LaboratoriesAbst ractThis paper proposes a method for extractingthe correct parts from speech recognition resultsby using an example-based approach for parsingthose results that include several recognition er-rors.
Correct parts are extracted using two fac-tors: (1) the semantic distance between the inputexpression and example expression, and (2) thestructure selected by the shortest semantic dis-tance.
We examined the correct parts extractionrate and the effectiveness of the method in im-proving the speech understanding rate and thespeech translation rate.
The examination resultsshowed that the proposed method is able to ef-ficiently extract the correct parts from speechrecognition results.
About ninety-six percentof the extracted parts are correct.
The resultsalso showed that the proposed method is effec-tive in understanding misrecognition speech sen-tences and in improving speech translation re-sults.
The misunderstanding rate for erroneoussentences i reduced about haiti Sixty-nine per-cent of speech translation results are improvedfor misrecognized sentences.1 In t roduct ionIn continuous peech recognition, N-grams havebeen widely used as effective linguistic con-straints for spontaneous speech \[1\].
To reducethe search effort, N of a high-order can be quitepowerful; but making the large corpus necessaryto calculate a reliable high-order N is unrealis-tic.
For a realistic linguistic constraint, almostall speech recognition systems use a low-orderN-gram, like a bi-gram or tri-gram, which canbe constrainted only to the local parts.
How-ever this is one of the reasons why many mis-recognized sentences using N-grams are strangeon long parts spanning over N words.
During*Now working at Toyo Information Systems Co., Ltdthe recognition process, several candidates haveto be pruned if the beam width is too small, andthe pruning cannot but use only those local partsalready recognized.
Even if we could get a largeenough corpus to train a high-order N-gram, itwould be impossible to determine the best recog-nition candidate in consideration of the wholesentence.
To put a speech dialogue system or aspeech translation system into practical use, it isnecessary to develop a mechanism that can parsethe misrecognized results using global linguisticconstraints.Several methods have already been proposedto parse ill-formed sentences or phrases usingglobal linguistic constraints based on a context-free-grammar (CFG) framework, and their effec-tiveness against some misrecognized speech sen-tences have been confirmed \[2, 3\].
Also theseparsings are used for translation ( see for exam-ple the use of the GLR parser in Janus\[4\] ).
Inthese studies, even if the parsing was unsuccess-ful for erroneous parts, the parsing could be con-tinued by deleting or recovering the erroneousparts.
The parsing was done on the assump-tion that every input sentence is well-formed af-ter all erroneous parts are recovered.
In real-ity, however spontaneous speech contains a lot ofill-formed sentences and it is difficult to analyzeevery spontaneous sentence by the CFG frame-work.
Concerning the CFG framework, syntacticrules written by subtrees are proposed \[5\].
Evenif a whole sentence can not be analyzed by CFG,the sentence can be expressed by combining sev-eral subtrees.
The subtrees are effective in pars-ing spontaneous speech parts.
Still, because thesubtrees can deal only with local parts like in N-gram modeling basically, parsing is not sufficientfor parsing misrecognized sentences.
Further-more, the subtrees are not sufficient in extract-ing suitable meaningful candidate structures, be-cause that these linguistic constraints are basedon the grammatical constraint without seman-tics.24To parse misrecognized sentences of sponta-neous speech, we propose a correct parts extrac-tion (CPE) method that uses global linguisticand semantic 0nstraints by an example-basedapproach.In the next section, we describe the CPEmethod.
In the following section, we show eval-uation results of CPE applied to Japanese-to-English speech translation experiments.2 Cor rect  Par ts  Ext rac t ion  us-ing  Const i tuent  BoundaryParser2.1 Const i tuent  Boundary  Parser(CB-parser )For effective and robust spoken-language transla-tion, a speech translation system called TransferDriven Machine Translation (TDMT) which car-ries out analysis and translation in an example-based framework has been proposed\[6\].
TDMTwhich refers to as Example-Based Machinetranslation(EBMT)\[7\] does not require a fullanalysis and instead defines patterns on sen-tences/phrases expressed by "variables" and"constituent boundaries".
These patterns areclassified into several classes, for example a com-plex sentence pattern class, an embedded clausepattern class, and phrase class.
A long-distancedependency structure can be handled by com-plex sentence patterns.
The process employs afast nearest-matching method to find the closesttranslation example by measuring the semanticconceptual distance of a given linguistic expres-sion from a set of equivalents in the example cor-pus.In general, the EBMT method is particularlyeffective when the structure of an input expres-sion is short or well-defined and its bounds havebeen recognized.
When applying it in transla-tion of longer utterances, the input must firstbe chunked to determine potential patterns byanalyzing it into phrases after adding part-of-speech tags.
In TDMT, translation is performedby means of stored translation examples whichare represented by "constituent boundary pat-terns".
These are built using limited word-taginformation, derived from morphological naly-sis, in the following sequence\[6\]: (a) insertionof constituent boundary markers, (b) deriva-tion of possible structures by pattern matching,and (c) structural disambiguation using similar-ity calculation\[8\].Language model for speech recognition: word hi-gramThreshold for semantic distance: 0.2Input sentence : He says the bus leaves Kyoto at 11 a.rn.Recognition result : He sells though the bus leaves; Kyoto at 11 a.m.He sells though I the bus leaves Kyoto at 11 a.rn.Jo"'.._ -* ~,e,.
?
?
0 .4XFigure 1: Example of correct part extractionIf the process of the similarity calculations forcandidate phrase patterns were executed top-down ~: breadth-first, hen the calculation costwould be too expensive and the decision onthe best phrase would have to be postponed.The translation cost are reduced in TDMT andphrases or partial sentences are analyzed becausethat the current TDMT uses instead on incre-mental method to determine the best structurelocally in a bottom-up & best-only way to con-strain the number of competing structures.
Thismeans that even TDMT fails for a whole sen-tence analysis, substructures partially analyzedcan be gotten.2.2 Cor rect  Par ts  Ext rac t ionOur proposed correct parts extraction (CPE)method obtains correct parts from recognitionresults by using the CB-parser.
CPE uses thefollowing two factors for the extraction: (1) thesemantic distance between the input expressionand an example xpression, and (2) the structureselected by the shortest semantic distance.The merits of using the CB-parser are as fol-lows.The CB-parser can analyze spontaneousspeech which can not be analyzed by theCFG framework, only if the example xpres-sions are selected from a spontaneous speechcorpus.
With more expressions in sponta-neous speech, there is an increased abilityto distinguish between erroneous entencesand correct ones.The CB-parser can deal with patterns in-cluding over N words which can not be dealtwith during speech recognition.
(see Table5).?
The CB-parser can extract some partialstructures independently from results of25 Phoneme ?EMnetWord bi-gramInputSpeech Ispeech I II.-... IaGmnSfe r knowledge em~ rammar, Example pattantic dictionaryLanguage Translation I Translation I Resultsource Idcorrect I.~.~trans,ationll,.~language F~'l parts I lextraction I | to  target I Iparsing I ~ (CPE) I / 'anguag e l lFigure 2: Speech translation system using CPEparsing, even if the parsing fails for a wholesentence.Correct parts are extracted under the follow-ing conditions:?
When expressions including er-roneous words show big distance values tothe examples.
When the distances are overthe distance threshold, the parts are definedas "erroneous parts".?
Correct parts are extracted only from globalparts consisting of over N words.
If localparts including less than N words can nothave a relation to other parts, the parts aredefined as "erroneous parts", even if the se-mantic distances are under the threshold.Figure 1 shows an example of CPE.
The inputsentence /He says the bus leaves Kyoto at 11a.m./ is recognized as /He sells though the busleaves Kyoto at 11 a.m./ by continuous peechrecognition using a word bi-gram.
The solidlines in Figure 1 indicate partial structures andthe number for each structure denotes the cor-responding semantic distance value.
The dottedline indicates the failure analysis result.
In thisexample, the analysis for the whole sentence isunsuccessful because the part /He says/ is  mis-recognized as /He  sell though/.
At first, the dis-tance value of the longest par t , / though the busleaves Kyoto at 11 a.m./, is compared with thethreshold value .
The part is considered to in-clude erroneous words because the distance value0.4 is larger than the threshold value 0.2 .
Sec-ondly, the next longest par t / the  bus leaves Ky-oto at 11 a.m./ is evaluated.
This part is ex-tracted as a correct part because the distance0.005 is under the threshold value.
Thirdly, theremaining par t /He  sells/is evaluated.
The dis-tance of the par t /He  sells/is under the thresholdvalue, but the part includes only two words whichare under N, so the part /He sells/ is regardedas an erroneous part.3 Evaluat ionWe evaluated CPE using the speech translationsystem shown in Figure 2.
CPE has already beenintegrated into TDMT as explained in the pre-vious section.
At first, the obtained recognitionresults were analyzed and then partial structuresand their semantic distances were output.
Next,the correct parts were extracted and only theextracted parts were translated into target sen-tences.We evaluated the following three things: (1)the recall and precision rates of the extractedparts , (2) the effectiveness of the method in un-derstanding misrecognized results, and (3) the ef-fectiveness of the method in improving the trans-lation rate.
For the evaluations, we used 70erroneous results output by a speech recogni-tion experiment using the ATR spoken languagedatabase on travel arrangement \[10\].3.1 Rate  of  cor rec t  par ts  ext rac t ionTo evaluate CPE, we compared the recall andprecision rates after extraction to the same ratesbefore extraction.
Recall and precision are de-fined as follows:recall =number of correct words in extracted partsnumber of words in the correct sentenceprecision =num.
of correct words in extracted partsnum.
of words in the recognition resultsThe extraction defines the threshold for thenumber of words in the structure to be N+I,on the assumption that the semantic distancesof the local parts consisting of under N words261009oi80'70605040Recall & Precision (%)Iw  ?
1 ~" recall after (I;PE I '!
~s precision be ore CPE.
.
.
.
.
.
.
.
.
.
.
.
.
.  "
.
.
.
.
.
.
.
.
.
.
.
.|.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
=~.
precision a~er CPE =I =~' l==o==.=.=,eBIThreshold for the number of wordsincluded in one structureFigure 3: Relationship between the extractionrate and the number of words in a structure1009080 ..i7060Recall & Precision (%)~ iecall after CP i. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
_ ! '
'272.
2:2.
"_c._P E. .
.
.
.
.
.
.
.
.
.
; .
.
.
.
.
.
.precision after CC~E,==pioesg=, i .=e=mulo i= I~ i ie=eg lea==~ole6u lmQ=alm .0.5 1.0 1.5 2.0Threshold for the semantic distanceFigure 4: Relationship between the extractionrate and the threshold of the semantic distanceare not useful for determining whether the partsare correct or not.
To confirm whether the as-sumption is true or not, extraction experimentswere performed under variable threshold condi-tions for the number of words in the structure.Figure 3 shows the obtained recall and precisionrates.?
The recall rates under all conditions are over92% and the best recall rate is 97%.
Thisindicates that the rates increased over 15%from before the extraction.?
The precision rates show a decrease of over20% from before the extraction.
This meansthat some correct parts could not be ex-tracted.?
When the threshold is two, the recall ratesdecrease much more than when the thresh-old is over three.?
When the threshold is over four, the preci-sion rate deceases a lot.Furthermore, extraction experiments wereperformed under variable threshold values of thesemantic distance for examining the relation be-tween the threshold for the semantic distanceand the rate of correct parts extraction.
Therecall and precision rates are shown in Figure 4.?
There is a general trend that when thethreshold increases, the recall rate decreasesand the precision rate increases.
But thedifferences of these rates are less than thedifferences by changing the threshold of thenumber of words as shown in Figure 3.
\[nparticular, the precision rate changes onlyslightly.?
When the threshold is defined as below 0.2.the recall and precision rates do not change.These results show the following;?
Words extracted by CPE are almost he realcorrect words.?
The threshold for the number of wordsshould be defined as over three when a "BI"gram is adopted, because the recall rates de-crease when the threshold is two.
It there-fore seems the assumption is true that localparts consisting of under N words are notuseful for determining the correct parts.?
The best threshold condition for the numberof words is three in consideration of both therecall and the precision.
Under this condi-tion, the recall rate is typically 96% and theprecision rate is typically 63%.?
The best threshold condition for the seman-tic distance is 0.2, because when the thresh-old is defined as over 0.2, the recall rate de-creases.3.2 Effect to speech  unders tand ingTo confirm the effectiveness of CPE  in under-standing speech recognition sentences, we com-pared the understanding rate of extracted partsusing CPE  with the rate of the recognition re-sults before extraction.
The same 70 erroneoussentences as in the previous experiments wereused.
The threshold for the number of wordswas defined as three and the threshold for thesemantic distance was defined as 0.2, which wereconfirmed to be the best values in Figure 3 andFigure 4.
The recognition results were evaluatedby five Japanese.
They gave one of the followingfive levels (Li)-(L5) to each misrecognition resultbefore extraction and after extraction, by com-paring the results with the corresponding correct27sentence before speech recognition.
The five lev-els were:( L I ) Able to understand the same meaning as thecorrect sentence.
(L2)(L3)(L4)(L5)Able to understand, but the expression isslightly awkward.Unable to understand, but the result is help-ful in imagining the correct sentence.Understanding of the wrong meaning.
CPEis not helpful.Output of the message "Recognition impos-sible.
"Each of the average rates of the five evaluatorsis shown in Table 1.
CPE was effective in reduc-ing the misunderstanding rate over half (35.5%to 15.2%).
The results able to be understoodwhich are given (L1) and (L2) increased but onlya little ( 19.6% to 20.3% for (L1), 22.0% to 22.6%for (L2)) by using CPE.
The tendency was thatmost of the misrecognition sentences includingonly negligible rrors could be understood evenwithout CPE, because the evaluators could seethe errors themselves while reading the misrecog-nition results.
On the other hand, most of themisrecognition sentences that included many er-roneous parts were understood incorrectly.
Theproposed CEP was very effective here in prevent-ing misunderstandings.
Nonetheless, other addi-tional mechanisms seem necessary, like an errorrecovering mechanism that increases the numberof understandable sentences.3.3 Ef fect  to speech  t rans la t ionWe evaluated the effectiveness of CPE inJapanese-English peech translation experimentsusing the speech translation system shown inFigure 2.
The conditions for the database,and the threshold values for the CPE methodwere the same as in the previous experiments.The translation results were evaluated by threeJapanese ach with a high ability to converse inthe English language.
They gave one of five levels( L i)-(L5 ) to each translation result of the misrec-ognized sentences, by comparing the result withthe corresponding translation result of the cor-rect sentence before speech recognition.
(L1)-(L4) for the evaluations were the same as in theprevious experiments and (L5) meant "Cannottranslate".Each of the average rates of the three evalua-tors is shown in Table 2.Without CPE, 85.7% of the recognition resultscould not be translated.
It seems that CPE isgood for (L1)-(L3) but poor for (L4): (L5) showsnegligible ffect.
The correctness rate for trans-lation after CPE is more than double the ratebefore CPE (11.9% to 25.7%}.
The sum of (LI)-(L3) is 69%.
This means that the proposed CPEis effective in improving the translation perfor-mance.
However, we cannot ignore the fact that21% of the recognition results were translated toerroneous sentences.4 D iscuss ionsSome deletion errors of function words are solvedby TDMT even without CPE.
This is becausethe translation trains a lot of the spontaneousspeech in which identical function words hadbeen deleted.
On the other hand, CPE is ef-fective for many erroneous sentences.
Importantmisrecognition characteristics effectively handledby CPE are as follows:(a) Some insertion errors between words(b) Errors at the tail parts of sentences(c) Strange xpressions including over N words(d) Expressions not similar to examples(e) Input too complicated to parse (but not er-rors)In contrast, characteristics not effectively han-dled by CPE are as follows:(f) Errors of final parts causing ambiguity, e.g,of a person, of a situation, whether a sen-tence is negative or positive, or whether asentence is interrogative or affirmative.
Inthese cases, the translation results are in-correct even if CPE is used.Table 3 - Table 7 show examples for each of thecharacteristics.
The top sentence of each table isthe input sentence and the second sentence is therecognition result; the final word sequences areonly parts extracted from the recognition results.All of the words are Japanese words expressed inR.oman characters and the words or sentences inbrackets are the translated English equivalents.4.1 Inser t ion  er rorsFilled-pauses, e.g., "umm" or "well", are oftenspoken in spontaneous speech.
Many speechrecognition systems deal with filled-pauses as28Table 1: The effect of CPE toward understanding misrecognition resultsI Levels II (L1) I(L2)I(L3)I(L4)I(L5)tafter CPE 20.3% 22.6% 36.8% 15.2% 5.4%Table 2: The effect of CPE toward translating misrecognition resultsLevelswithout CPEafter CPEH (L1) \[ (L2) (L3) (L4) (L5)\ ]11 .9%\]0% 0%2.4%8.5 .7%25 .7%16.7%26.6%21.0%10.0%recognized words.
Many Japanese filled-pausesconsist of only one phoneme, e.g., "e","q", or"'n".
and it is easy for mismatches to parts ofother words to occur.
Furthermore, filled-pauseshave no strong relations to any words and itis difficult to constrain them with an N-gramframework.
These are the reasons why insertionerrors of filled-pauses are often found in misrec-ognized results.Table 3 is an example of insertion errors byfilled-pauses.
For this example, a structureanalysis for the whole sentence failed.
How-ever, the parts before and after the filled-pauses,/deNwa(telephone) baNgou(number) wa/ and/go(five) ni(two) nana(seven)/ could be ex-tracted as correct parts.
The two words/kyuu(nine)/ and /desu(is)/ could not be ex-tracted because the part /kyuu desu/ includedonly two words.4.2 Errors at the tail parts of sen-tencesFor an indirect expression or an honorific expres-sion, several function words are often spoken suc-cessively at the final part of the sentence.
Mis-recognition often occurs at this part.
When thewords necessary for understanding an utterancehave been spoken before the final part, it is pos-sible to perform translation to an understand-able sentence by extracting only the beginningparts.
Table 4 shows an example of an error oc-curring at a final par t /N  desu keredomo/.
Thepart /N desu keredomo/ is part of an honorificexpression and all of the words in this part arefunction words.
The proposed extraction selectsonly the beginning par t /heya  no yoyaku wo one-gai sitai(would like to reserve a room)/.
Thetranslation result is a little strange but it can beunderstood and almost has the correct meaning.Actually, only / I /  could not be translated be-cause the misrecognized par t /N  desu keredomo/included a keyword to determine the person.4.3 Strange expression consisting ofover N wordsTable 5 shows an example of a strange expres-sion consisting of over N words.
In this exam-ple, every word pair is not strange because allof them have already been constrained by bi-gram modeling.
But the expression consistingof three words i.e.,/oyako(parent and child) nogokibou(preference)/ is strange.
The part /oy-ako no /can  be said to be an erroneous part be-cause it can be connected to other parts and con-sists only of two words.4.4 Expressions not similar to exam-plesThe important merit of the example-based ap-proach is that any structural ambiguity or se-mantic ambiguity can be reduced in considera-tion of the similarity to examples.
The recogni-tion result shown in Table 6 was misrecognizedin the part / i i (am)/ to / i (s tay) / .
But the mis-recognized result/Suzuki Naoko to i masu (I amstaying with Suzuki Naoko)/ is very natural ingeneral.
It seems therefore that CFG can parsean erroneous entence without any problem andthe sentence can be understood although with adifferent meaning.
( /I am staying with SuzukiNaoko/which is different from the correct mean-ing /I  am Suzuki Naoko/ ).
However, this israre for a travel arrangement corpus and the se-mantic distance value of the whole sentence isover the threshold.
As a result of CPE, only/Suzuki Naoko/can be extracted and translatedto /Naoko Suzuki/.294.5 An  ut te rance  inc lud ing  severa lsentencesEven if a recbgnition result is correct, whenone utterance includes several sentences, TDMTwithout CPE  sometimes fails because the bound-arv of the sentences can not be understood, forexample./waka ri masi ta (\[ see).
doumo ariga-tou (Thank you)/.
Though the translation failswithout CPE, CPE  can extract each sentence oneby one and the translation result after CPE  iscorrect.4.6 Express ion  of  bad  effect by  CPEThe keywords for determining whether a sen-tence is negative or positive, or whether a sen-tence is interrogative or affirmative, are oftenspoken at the final part of the sentence.
Whenthese keywords are misrecognized, the transla-tion result is quite different from the correcttranslation result.
The input sentence in Table 7is a negative sentence.
The keyword determiningthe sentence to be negative is /naku/ ,  but is mis-recognized.
As a result of the translation afterCPE, a positive sentence is translated and themeaning is opposite to the intended meaning.5 ConclusionThis paper proposed a method for extract-lag correct parts from speech recognition re-suits in order to understand recognition resultsfrom speech inputs which may include erroneousparts.
Correct parts are extracted using (a) thesemantic distances between the input expressionand an example xpression and (b) the structureselected by the shortest semantic distance.We examined three things: (1) the correctparts extraction rate, (2) the effectiveness of themethod in improving the speech understandingrate.
and (3) the effectiveness of the method inimproving the speech translation rate.
Resultsshowed that the proposed method is able to ef-ficiently extract the correct parts from speechrecognition results; ninety-six percent of theextracted parts are correct.
The results alsoshowed that the proposed method is effectivein preventing the misunderstanding of the er-roneous entences and in improving the speechtranslation results.
The misunderstanding ratefor erroneous entences i reduced over half andsixty-nine percent of the speech translation re-sults can be improved for misrecognized sen-tences.In the future, we will try to feed the extractionresults back into the speech recognition processfor re-recognizing only the non-extracted partsand to improve the speech recognition perfor-mance.
By repeating the correct parts extrac-tion and the feedback, we will confirm whetherthere is an improvement in the understandingand translation performance.
Furthermore.
wewill confirm the effectiveness of the proposedmethod using other languages.References\[ll L.R.Bahl, F.Jelinek and R.L.Mercer: "'A Maxi-mum Likelihood Approach to Continuous SpeechRecognition," In IEEE Trans.
on Pattern Anal-ysis and Machine Intelligence, pp.179-190, t983.\[2\] C.S.Mellish:"Some chart-based techniques forparsing ill-formed input.
", In proc.
of the An-nual Meeting of the ACL, pp.102-109, 1989.\[3\] H.Saitou,M.Tomita:"Parsing noisy sentences,",In proc.
of COLING'88, pp.561-566.
1988.\[4\] A.Lavie, D.Gates, M.GAvalda, L.Mayfield,A.Waibel, and L.Levin:"Multilingual Translationof Spontaneously Spoken Language in a Lim-ited Domain" In Proc.of I6th ICCL, pp.442-447.1996.\[5\] T.Takezawa,T.Morimoto: "Dialogue SpeechRecognition Method using Rules based on Sub-trees and Preterminal Bigrams" In IEICE Transin Japanese, D-II Vol.J79-D-II No.12 pp.2078-2085.
1996.\[61 O.Furuse, H.Iida:"Constituent Boundary Parsingfor Example-Based Machine Translation" In proc.of COLING'9J, pp.105-111.
994.\[7\] E.Sumita, H.Iida:"Experiments and Prospects ofExample-based Machine Translation" \[n Proc.
of29th ACL, pp.185-192, 1991.\[8\] E.Surnita, H.Iida:"An Example-Based Disarn-biguation of English Prepositional Phrase attach-ment" In Proc.
Syst.
and Corn.
in Japan Vol.26,No.4, pp.30-41, 1995.\[9\] O.Furuse, H.Iida:"Incremental Translation Utiliz-ing Constituent Boundary Patterns" In proc.
ofCOLING'96, pp.412-417.
1996.\[10\] T.Morimoto et al: "A Speech and languagedatabase for speech translation research" In Proc.of ICSLP'9~, pp.1791-1794, 1994.30Table 3: Example of insertion errors between wordsInput sentenceRecognition result/ / : insertion errorsResult after CPE... : non-extracted partsdeNwa baNgou wa go ni nana kyuu desu( The telephone number is five two seven nine )deNwa baNgou wa/q /  /o /go  ni nana /aq /kyuu  desu(telephone)(number) (five) (two) (seven) (nine) (is)deNwa baNgou wa ............ go ni nana ......( The telephone number ....... five two seven ..... )Table 4: Example of errors at the final part of a sentenceInput sentenceRecognition result: erroneous partsResu l ts  after CPE... : non-extracted partsheya no yoyaku wo onegai sitai N desu keredomo.
(I would like to reserve a room.
)heya no yoyaku wo onegai sitai ne su tomo(room) (reserve) (would like to)heya no yoyaku wo onegai sitai ....( ... would like to reserve a room )Table 5: Example of a strange expression over N wordsInput sentenceRecognition result: erroneous parts-Result  after CPE... : non-extracted partsoheya no gokibou wa gozai masu ka ?
(room) (preference)( Do you have any preference for a room ?
)oyako no gokibou wa gozai masu ka ?
(parent and child) (preference)................ gokibou wa gozafi masu ka( Do you have any preference ...... ?
)Table 6: Example of an expression not similar to the example sentencesInput sentenceRecognition result_ : erroneous partsresult ~ter CPE... : non-extracted partsSuzuki Naoko to i i masu(Suzuki)(Naoko) (I am)(I am Naoko Suzuki)Suzuki Naoko to i masu(Suzuki)(Naoko) (stay)Suzuki Naoko to .....( ..... Naoko Suzuki)Table 7: Example of bad effect by CPEInput sentenceRecognition iesult: deletion errorsmresult after CPE... : non-extracted partstsugou de tomare naku natta(reason) (stay) (can't)(I can't stay for some reason)tsugou de tomare __  natta(reason) (stay)tsugou de tomare ......... can stay for some reason31
