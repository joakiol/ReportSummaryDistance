Proceedings of EACL '99Complement ing WordNet with Roget's and Corpus-basedThesauri for Information RetrievalRila Mandala, Takenobu Tokunaga and Hozumi TanakaAbstractThis paper proposes a method to over-come the drawbacks of WordNet whenapplied to information retrieval by com-plementing it with Roget's thesaurus andcorpus-derived thesauri.
Words and rela-tions which are not included in WordNetcan be found in the corpus-derived the-sauri.
Effects of polysemy can be min-imized with weighting method consider-ing all query terms and all of the the-sauri.
Experimental results show thatour method enhances information re-trieval performance significantly.Department of Computer ScienceTokyo Institute of Technology2-12-1 Oookayama Meguro-KuTokyo 152-8522 Japan{rila,take,tanaka}@cs.titech.ac.jpexpansion (Voorhees, 1994; Smeaton and Berrut,1995), computing lexical cohesion (Stairmand,1997), word sense disambiguation (Voorhees,1993), and so on, but the results have not beenvery successful.Previously, we conducted query expansion ex-periments using WordNet (Mandala et al, to ap-pear 1999) and found limitations, which can besummarized as follows :1 IntroductionInformation retrieval (IR) systems can be viewedbasically as a form of comparison between doc-uments and queries.
In traditional IR methods,this comparison is done based on the use of com-mon index terms in the document and the query(Salton and McGill, 1983).
The drawback of suchmethods is that if semantically relevant docu-ments do not contain the same terms as the query,then they will be judged irrelevant by the IR sys-tem.
This occurs because the vocabulary that theuser uses is often not the same as the one used indocuments (Blair and Maron, 1985).To avoid the above problem, several researchershave suggested the addition of terms which havesimilar or related meaning to the query, increasingthe chances of matching words in relevant docu-ments.
This method is called query expansion.A thesaurus contains information pertaining toparadigmatic semantic relations uch as term syn-onymy, hypernymy, and hyponymy (Aitchison andGilchrist, 1987).
It is thus natural to use a the-saurus as a source for query expansion.Many researchers have used WordNet (Miller,1990) in information retrieval as a tool for query?
Interrelated words may have different partsof speech.?
Most domain-specific relationships betweenwords are not found in WordNet.?
Some kinds of words are not included inWordNet, such as proper names.To overcome all the above problems, we pro-pose a method to enrich WordNet with Roget'sThesaurus and corpus-based thesauri.
The ideaunderlying this method is that the automaticallyconstructed thesauri can counter all the abovedrawbacks of WordNet.
For example, as we statedearlier, proper names and their interrelations arenot found in WordNet, but if proper names bearsome strong relationship with other terms, theyoften cooccur in documents, as can be modelledby a corpus-based thesaurus.Polysemous words degrade the precision of in-formation retrieval since all senses of the originalquery term are considered for expansion.
To over-come the problem of polysemous words, we ap-ply a restriction in that queries are expanded byadding those terms that are most similar to theentirety of the query, rather than selecting termsthat are similar to a single term in the query.In the next section we describe the details ofour method.94Proceedings of EACL '992 Thesaur i2.1 WordNetIn WordNet, words are organized into taxonomieswhere each node is a set of synonyms (a synset)representing a single sense.
There are 4 differ-ent taxonomies based on distinct parts of speechand many relationships defined within each.
Inthis paper we use only noun taxonomy withhyponymy/hypernymy (or is-a) relations, whichrelates more general and more specific senses(Miller, 1988).
Figure 1 shows a fragment of theWordNet taxonomy.The similarity between word wl and we is de-fined as the shortest path from each sense ofwl to each sense of w2, as below (Leacock andChodorow, 1988; Resnik, 1995)sim(wl, w2) = max\[- log(2~) \]where N v is the number of nodes in path p fromwl to w2 and D is the maximum depth of thetaxonomy.2.2 Roget 's  ThesaurusIn Roget's Thesaurus (Chapman, 1977), wordsare classified according to the ideas they express,and these categories of ideas are numbered in se-quence.
The terms within a category are furtherorganized by part of speech (nouns, verbs, adjec-tives, adverbs, prepositions, conjunctions, and in-terjections).
Figure 2 shows a fragment of Roget'scategory.In this case, our similarity measure treat all thewords in Roger as features.
A word w possessesthe feature f if f and w belong to the same Ro-get category.
The similarity between two wordsis then defined as the Dice coefficient of the twofeature vectors (Lin, 1998).sim(wl,w2) = 21R(wl) n R(w~)ltn(w,)l + In(w )lwhere R(w) is the set of words that belong tothe same Roget category as w.2.3 Corpus-based Thesaurus2.3.1 Co-occurrence-based ThesaurusThis method is based on the assumption that apair of words that frequently occur together in thesame document are related to the same subject.Therefore word co-occurrence information can beused to identify semantic relationships betweenwords (Schutze and Pederson, 1997; Schutze andPederson, 1994).
We use mutual information as atool for computing similarity between words.
Mu-tual information compares the probability of theco-occurence of words a and b with the indepen-dent probabilities of occurrence of a and b (Churchand Hanks, 1990).P(a, b)I(a, b) = log P(a)P(b)where the probabilities of P(a) and P(b) are esti-mated by counting the number of occurrences ofa and b in documents and normalizing over thesize of vocabulary in the documents.
The jointprobability is estimated by counting the numberof times that word a co-occurs with b and is alsonormalized over the size of the vocabulary.2.3.2 Syntact ica l ly -based ThesaurusIn contrast to the previous ection, this methodattempts to gather term relations on the ba-sis of linguistic relations and not document co-occurrence statistics.
Words appearing in simi-lax grammatical contexts are assumed to be sim-ilar, and therefore classified into the same class(Lin, 1998; Grefenstette, 1994; Grefenstette, 1992;Ruge, 1992; Hindle, 1990).First, all the documents are parsed using theApple Pie Parser.
The Apple Pie Parser is anatural anguage syntactic analyzer developed bySatoshi Sekine at New York University (Sekineand Grishman, 1995).
The parser is a bottom-upprobabilistic hart parser which finds the parsetree with the best score by way of the best-firstsearch algorithm.
Its grammar is a semi-contextsensitive grammar with two non-terminals andwas automatically extracted from Penn Tree Banksyntactically tagged corpus developed at the Uni-versity of Pennsylvania.
The parser generates asyntactic tree in the manner of a Penn Tree Bankbracketing.
Figure 3 shows a parse tree producedby this parser.The main technique used by the parser is thebest-first search.
Because the grammar is prob-abilistic, it is enough to find only one parsetree with highest possibility.
During the parsingprocess, the parser keeps the unexpanded activenodes in a heap, and always expands the activenode with the best probability.Unknown words are treated in a special man-ner.
If the tagging phase of the parser finds anunknown word, it uses a list of parts-of-speech de-fined in the parameter file.
This information hasbeen collected from the Wall Street Journal cor-pus and uses part of the corpus for training andthe rest for testing.
Also, it has separate lists forsuch information as special suffices like -ly, -y, -ed,-d, and -s. The accuracy of this parser is reported95Proceedings of EACL '99Synonyms/Hypernyms (Ordered by Frequency) of noun correlation2 senses of correlationSense 1correlation, correlativity=> reciprocality, reciprocity=> relation=> abstractionFigure 1: An Example WordNet entry9.
Relation.
-- N. relation, bearing, reference, connection,concern,, cogaation ; correlation c. 12; analogy; similarity c. 17;affinity, homology, alliance, homogeneity, association; approximation c.(nearness) 197; filiation c. (consanguinity) 11\[obs3\]; interest; relevancyc.
23; dependency, relationship, relative position.comparison c. 464; ratio, proportion.link, tie, bond of union.Figure 2: A fragment of a Roget's Thesaurus entryas parseval recall 77.45 % and parseval precision75.58 %.Using the above parser, the following syntacticstructures are extracted :?
Subject-Verba noun is the subject of a verb.?
Verb-Objecta noun is the object of a verb.?
Adjective-Nounan adjective modifies a noun.?
Noun-Nouna noun modifies a noun.Each noun has a set of verbs, adjectives, andnouns that it co-occurs with, and for each suchrelationship, a mutual information value is calcu-lated.?
I~b(Vi, nj) = log f,~b(~,~,)/g,~b ?
(fsub(nj)/Ns,~b)(f(Vi)/Nzub)where fsub(vi, nj) is the frequency of noun njoccurring as the subject of verb vi, L~,b(n~)is the frequency of the noun nj occurring assubject of any verb, f (v i )  is the frequency ofthe verb vi, and Nsub is the number of subjectclauses.fob~ (nj ,11i )/Nobj?
Iobj(Vi, n j )  = log (Yob~(nj)/Nob~)(f(vl)/Nob~)where fobj(Vi, nj) is the frequency of noun njoccurring as the object of verb vi, fobj(nj)is the frequency of the noun nj occurring asobject of any verb, f(vi) is the frequency ofthe verb vi, and Nsub is the number of objectclauses.?
Iadj(ai,nj) = log I?d;(n~'ai)/N*ai(fadj(nj)/Nadj)(f(ai)/ga#4)where f(ai ,  nj) is the frequency of noun njoccurring as the argument of adjective ai,fadj(nj) is the frequency of the noun nj oc-curring as the argument of any adjective,f(ai) is the frequency of the adjective ai, andNadj is the number of adjective clauses.?
Inoun(n i ,n j )  =log f .
.
.
.
(~j,~)/N .
.
.
.
where (f oun (nj )/ Nnou.
)(f (ni )/ Nnoun )f (a i ,n j )  is the frequency of noun nj occur-ring as the argument of noun hi, fnoun(nj) isthe frequency of the noun n~ occurring as theargument of any noun, f(ni) is the frequencyof the noun hi, and N.o~,n is the number ofnoun clauses.The similarity sim(w,wz) between two wordsw~ and w2 can be computed as follows :(r,w) 6T(w, )nT(w2)Ir(wl,w)+(r,w) 6T(wt ) (r,w) eT(w2)Where r is the syntactic relation type, and w is?
a verb, if r is the subject-verb or object-verbrelation.?
an adjective, if r is the adjective-noun rela-tion.96Proceedings of EACL '99NPDT J J  NNThat quill penVP/NADJVBZ JJ CClooks good andVPVPNPVBZ DT JJ NNis a new productFigure 3: An example parse tree?
a noun, if r is the noun-noun relation.and T(w) is the set of pairs (r,w') such thatIt(w, w') is positive.3 Combinat ion  and  TermExpans ion  MethodA query q is represented by the vector -~ =(ql, q2,---, qn), where each qi is the weight of eachsearch term ti contained in query q.
We usedSMART version 11.0 (Saiton, 1971) to obtain theinitial query weight using the formula ltc as be-lows :(log(tfik) + 1.0) * log(N/nk)~-~\[(log(tfo + 1.0) * log(N/nj)\] 2j= lwhere tfik is the occurrrence frequency of term tkin query qi, N is the total number of documents inthe collection, and nk is the number of documentsto which term tk is assigned.Using the above weighting method, the weightof initial query terms lies between 0 and 1.
Onthe other hand, the similarity in each type of the-saurus does not have a fixed range.
Hence, weapply the following normalization strategy to eachtype of thesaurus to bring the similarity value intothe range \[0, 1\].simold -- S imminSimnew =Simmaz -- 8 imminThe similarity value between two terms in thecombined thesauri is defined as the average oftheir similarity value over all types of thesaurus.The similarity between a query q and a term tjcan be defined as belows :simqt(q, tj) = Z qi * sim(ti, tj)tiEqwhere the value of sim(ti, tj) is taken from thecombined thesauri as described above.With respect o the query q, all the terms in thecollection can now be ranked according to theirsimqt.
Expansion terms are terms tj with highsimqt (q, t j).The weight(q, tj) of an expansion term tj is de-fined as a function of simqt(q, tj):weight(q, tj) - simqt(q, tj)ZtiEq qiwhere 0 < weight(q, tj) < 1.The weight of an expansion term depends bothon all terms appearing in a query and on the sim-ilarity between the terms, and ranges from 0 to 1.The weight of an expansion term depends both onthe entire query and on the similarity between theterms.
The weight of an expansion term can beinterpreted mathematically as the weighted meanof the similarities between the term tj and all thequery terms.
The weight of the original queryterms are the weighting factors of those similari-ties (Qiu and Frei, 1993).Therefore the query q is expanded by addingthe following query :~ee = (a l ,  a2,  ..., at)where aj is equal to weight(q, tj) if tj belongs tothe top r ranked terms.
Otherwise aj is equal to0.97Proceedings of EACL '99The resulting expanded query is :~ezpanded "~- ~ o ~eewhere the o is defined as the concatenation oper-ator.The method above can accommodate polysemy,because an expansion term which is taken from adifferent sense to the original query term is givena very low weight.4 Exper imentsExperiments were carried out on the TREC-7 Col-lection, which consists of 528,155 documents and50 topics (Voorhees and Harman, to appear 1999).TREC is currently de facto standard test collec-tion in information retrieval community.Table 1 shows topic-length statistics, Table 2shows document statistics, and Figure 4 shows anexample topic.We use the title, description, and combined ti-tle+description+narrative of these topics.
Notethat in the TREC-7 collection the description con-tains all terms in the title section.For our baseline, we used SMART version 11.0(Salton, 1971) as information retrieval engine withthe Inc.ltc weighting method.
SMART is an infor-mation retrieval engine based on the vector spacemodel in which term weights are calculated basedon term frequency, inverse document frequencyand document length normalization.Automatic indexing of a text in SMART systeminvolves the following steps :?
Tokenizat ion : The text is first tokenizedinto individual words and other tokens.?
Stop word  removal  : Common functionwords (like the, of, an, etc.)
also called stopwords, are removed from this list of tokens.The SMART system uses a predefined list of571 stop words.?
S temming:  Various morphological variantsof a word are normalized to the same stem.SMART system uses the variant of Lovinmethod to apply simple rules for suffix strip-ping.?
Weight ing : The term (word and phrase)vector thus created for a text, is weighted us-ing t f ,  idf, and length normalization consid-erations.Table 3 gives the average of non-interpolatedprecision using SMART without expansion (base-line), expansion using only WordNet, expansionusing only the corpus-based syntactic-relation-based thesaurus, expansion using only the corpus-based co-occurrence-based thesaurus, and expan-sion using combined thesauri.
For each method wealso give the relative improvement over the base-line.
We can see that the combined method out-perform the isolated use of each type of thesaurussignificantly.Table 1:TREC-7 Topic length statisticsTopic Section Min Max MeanTitle 1 3 2.5Description 5 34 14.3Narrative 14 92 40.8All 31 114 57.65 Discuss ionIn this section we discuss why our method usingWordNet is able to improve information retrievalperformance.
The three types of thesaurus weused have different characteristics.
Automaticallyconstructed thesauri add not only new terms butalso new relationships not found in WordNet.
Iftwo terms often co-occur in a document then thosetwo terms are likely to bear some relationship.The reason why we should use not only auto-matically constructed thesauri s that some rela-tionships may be missing in them For example,consider the words colour and color.
These wordscertainly share the same context, but would neverappear in the same document, at least not witha frequency recognized by a co-occurrence-basedmethod.
In general, different words used to de-scribe similar concepts may never be used in thesame document, and are thus missed by cooccur-rence methods.
However their relationship may befound in WordNet, Roget's, and the syntactically-based thesaurus.One may ask why we included Roget's The-saurus here which is almost identical in nature toWordNet.
The reason is to provide more evidencein the final weighting method.
Including Roget'sas part of the combined thesaurus is better thannot including it, although the improvement is notsignificant (4% for title, 2% for description and0.9% for all terms in the query).
One reason isthat the coverage of Roget's is very limited.A second point is our weighting method.
Theadvantages of our weighting method can be sum-marized as follows:?
the weight of each expansion term considersthe similarity of that term to all terms in the98Proceedings of EACL '99Table 2 :TREC-7 Document statisticsSource Size(Mb) #Docs  I Med ian# t Mean#Words/Doc Words/DocDisk 4FT 564 t210,1581 316 412.71155,630 588 644.7 FR94 395Disk 5FBIS 4701130,47113221543.6131,896 351 526.5 LA Times 475Title :ocean remote sensingDescription:Identify documents discussing the development and application of spaceborneocean remote sensing.Narrative:Documents discussing the development and application of spaceborne ocean re-mote sensing in oceanography, seabed prospecting and mining, or any marine-science activity are relevant.
Documents that discuss the application of satelliteremote sensing in geography, agriculture, forestry, mining and mineral prospect-ing or any land-bound science are not relevant, nor are references to interna-tional marketing or promotional advertizing of any remote-sensing technology.Synthetic aperture radar (SAR) employed in ocean remote sensing is relevant.Figure 4: Topics Exampleoriginal query, rather than to just one queryterm.?
the weight of an expansion term also dependson its similarity within all types of thesaurus.Our method can accommodate polysemy, be-cause an expansion term taken from a differentsense to the original query term sense is givenvery low weight.
The reason for this is that theweighting method depends on all query terms andall of the thesauri.
For example, the word bankhas many senses in WordNet.
Two such senses arethe financial institution and river edge senses.
Ina document collection relating to financial banks,the river sense of bank will generally not be foundin the cooccurrence-based thesaurus because of alack of articles talking about rivers.
Even though(with small possibility) there may be some doc-uments in the collection talking about rivers, ifthe query contained the finance sense of bank thenthe other terms in the query would also tend to beconcerned with finance and not rivers.
Thus riverswould only have a relationship with the bank termand there would be no relations with other termsin the original query, resulting in a low weight.Since our weighting method depends on both thequery in its entirety and similarity over the threethesauri, wrong sense expansion terms are givenvery low weight.6 Re la ted  ResearchSmeaton (1995) and Voorhees (1994; 1988) pro-posed an expansion method using WordNet.
Ourmethod differs from theirs in that we enrich thecoverage of WordNet using two methods of auto-matic thesaurus construction, and we weight theexpansion term appropriately so that it can ac-commodate polysemy.Although Stairmand (1997) and Richardson(1995) proposed the use of WordNet in informa-tion retrieval, they did not use WordNet in thequery expansion framework.Our syntactic-relation-based thesaurus i basedon the method proposed by Hindle (1990), al-though Hindle did not apply it to informationretrieval.
Hindle only extracted subject-verband object-verb relations, while we also extractadjective-noun and noun-noun relations, in themanner of Grefenstette (1994), who applied his99Proceedings of EACL '99Table 3: Average non-interpolated precision for expansion using single or combined thesauri.Topic Type BaseTitle 0.1175Description 0.1428All 0.1976Expanded withWordNet Roget Syntac Cooccur Combinedonly only only only method0.1276 0 .1236 0 .1386 0.1457 0.2314(+8.6%) (+5.2 %) (+17.9%) (+24.0%) (+96.9%)0.1509 0 ,1477 0 .1648 0.1693 0.2645(+5.7%) (+3.4%) (+15.4%) (+18.5%) (+85.2%)0.2010 0 .1999 0.2131 0.2191 0.2724(+1.7%) (+1.2%) (+7.8%) (+10.8%) (+37.8%)syntactically-based thesaurus to information re-trieval with mixed results.
Our system improveson Grefenstette's results since we factor in the-sauri which contain hierarchical information ab-sent from his automatically derived thesaurus.Our weighting method follows the Qiu and Frei(1993) method, except hat Qiu used it to expandterms from a single automatically constructed the-sarus and did not consider the use of more thanone thesaurus.This paper is an extension of our previous work(Mandala et al, to appear 1999) in which we ddidnot consider the effects of using Roget's Thesaurusas one piece of evidence for expansion and usedthe Tanimoto coefficient as similarity coefficientinstead of mutual information.7 Conc lus ionsWe have proposed the use of different types of the-saurus for query expansion.
The basic idea under-lying this method is that each type of thesaurushas different characteristics and combining themprovides a valuable resource to expand the query.Wrong expansion terms can be avoided by design-ing a weighting term method in which the weightof expansion terms not only depends on all queryterms, but also depends on their similarity valuesin all type of thesaurus.Future research will include the use of a parserwith better performance and the use of more re-cent term weighting methods for indexing.8 AcknowledgementsThe authors would like to thank Mr. TimothyBaldwin (TIT, Japan) and three anonymous ref-erees for useful comments on the earlier versionof this paper.
We also thank Dr. Chris Buck-ley (SabIR Research) for support with SMART,and Dr. Satoshi Sekine (New York University)for providing the Apple Pie Parser program.
Thisresearch is partially supported by JSPS projectnumber JSPS-RFTF96P00502.Re ferencesJ.
Aitchison and A. Gilchrist.
1987.
ThesaurusConstruction: A Practical Manual.
Aslib.D.C.
Blair and M.E.
Maron.
1985.
An evalua-tion of retrieval effectiveness.
Communicationsof the ACM, 28:289-299.Robert L. Chapman.
1977.
Roget's InternationalThesaurus (Forth Edition).
Harper and Row,New York.Kenneth Ward Church and Patrick Hanks.
1990.Word association orms, mutual informationand lexicography.
In Proceedings of the 27thAnnual Meeting of the Association for Compu-tational Linguistics, pages 76-83.Gregory Grefenstette.
1992.
Use of syntacticcontext o produce term association lists fortext retrieval.
In Proceedings of the 15th An-nual International ACM SIGIR Conference onResearch and Development in Information Re-trieval, pages 89-97.Gregory Grefenstette.
1994.
Explorations inAutomatic Thesaurus Discovery.
Kluwer Aca-demic Publisher.Donald Hindle.
1990.
Noun classification frompredicate-argument structures.
In Proceedingsof the 28th Annual Meeting of the Associationfor Computational Linguistic, pages 268-275.Claudia Leacock and Martin Chodorow.
1988.Combining local context and WordNet similar-ity for word sense identification.
In ChristianeFellbaum, editor, WordNet, An Electronic Lex-ical Database, pages 265-283.
MIT Press.Dekang Lin.
1998.
Automatic retrieval and clus-tering of similar words.
In Proceedings of theCOLING-ACL'98, pages 768-773.100Proceedings of EACL '99Rila Mandala, Takenobu Tokunaga, and HozumiTanaka.
to appear, 1999.
Combining eneralhand-made and automatically constructed the-sauri for information retrieval.
In Proceedingsof the 16th International Joint Conference onArtificial Intelligence (IJCAI-99).George A. Miller.
1988.
Nouns in WordNet.In Christiane Fellbaum, editor, WordNet, AnElectronic Lexieal Database, pages 23-46.
MITPress.George A. Miller.
1990.
Special issue, WordNet:An on-line lexical database.
International Jour-nal of Lexicography, 3(4).Yonggang Qiu and Hans-Peter Frei.
1993.
Con-cept based query expansion.
In Proceedingsof the 16th Annual International ACM SIGIRConference on Research and Development inInformation Retrieval, pages 160-169.Philip Resnik.
1995.
Using information contentto evaluate semantic similarity in a taxonomy.In Proceedings of the l~th International JointConference on Artificial Intelligence (1JCAI-95), pages 448-453.R.
Richardson and Alan F. Smeaton.
1995.
UsingWordNet in a knowledge-based approach to in-formation retrieval.
Technical Report CA-0395,School of Computer Applications, Dublin CityUniversity.Gerda Ruge.
1992.
Experiments on linguistically-based term associations.
Information Process-ing and Management, 28(3):317-332.Gerard Salton and M McGill.
1983.
An In-troduction to Modern Information Retrieval.McGraw-Hill.Gerard Salton.
1971.
The SMART Retrieval Sys-tem: Experiments in Automatic Document Pro-cessing.
Prentice-Hall.Hinrich Schutze and Jan O. Pederson.
1994.
Acooccurrence-based thesaurus and two applica-tions to information retrieval.
In Proceedings ofthe RIA O 94 Conference.Hinrich Schutze and Jan 0.
Pederson.
1997.
Acooccurrence-based thesaurus and two applica-tions to information retrieval.
Information Pro-cessing and Management, 33(3):307-318.Satoshi Sekine and Ralph Grishman.
1995.
Acorpus-based probabilistic grammar with onlytwo non-terminals.
In Proceedings of the Inter-national Workshop on Parsing Technologies.Alan F. Smeaton and C. Berrut.
1995.
RunningTREC-4 experiments: A chronological report ofquery expansion experiments carried out as partof TREC-4.
In Proceedings of The Fourth TextREtrieval Conference (TREC-4).
NIST specialpublication.Mark A. Stairmand.
1997.
Textual context anal-ysis for information retrieval.
In Proceedingsof the 20th Annual International A CM-SIGIRConference on Research and Development inInformation Retrieval, pages 140-147.Ellen M. Voorhees and Donna Harman.
to ap-pear, 1999.
Overview of the Seventh Text RE-trieval Conference (TREC-7).
In Proceedings ofthe Seventh Text REtrieval Conference.
NISTSpecial Publication.Ellen M. Voorhees.
1988.
Using WordNet for textretrieval.
In Christiane Fellbaum, editor, Word-Net, An Electronic Lexical Database, pages 285-303.
MIT Press.Ellen M. Voorhees.
1993.
Using wordnet o dis-ambiguate word senses for text retrieval.
InProceedings of the 16th Annual InternationalACM-SIGIR Conference on Research and De-velopment in Information Retrieval, pages 171-180.Ellen M. Voorhees.
1994.
Query expansion usinglexical-semantic relations.
In Proceedings of the17th Annual International ACM-SIGIR Con-ference on Research and Development in Infor-mation Retrieval, pages 61-69.I01
