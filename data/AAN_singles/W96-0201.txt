A Geometric Approach toMapping Bitext CorrespondenceI .
Dan  Me lamedDept .
of Computer  and In format ion  Sc ienceUn ivers i ty  of Pennsy lvan iaPh i lade lph ia ,  PA,  19104, U.S.A.melamed?unagi, cis.
upenn, eduAbst ractThe  f irst step in most  corpus -based mul-t i l ingual  NLP  work is to  const ruct  a de-ta i led  map of  the  cor respondence  betweena text  and  its t rans lat ion .
Several  auto-mat ic  methods  for  this task have been pro-posed in recent  years.
"Yet even the bestof  these methods  can er r  by several  typesetpages.
The  Smooth  In ject ive  Map Recog-n izer  (S IMR)  is a new b i text  mapp ing  al-gor i thm.
S IMR's  er rors  are smal ler  thanthose  o f  the  prev ious  f ront - runner  by morethan  a fac tor  of  4.
I ts robustness  has en-ab led  new commerc ia l -qua l i ty  appl icat ions.The  greedy  nature  of  the  a lgor i thm makes itindependent  of  memory  resources.
Unl ikeo ther  b i text  mapp ing  a lgor i thms,  S IMR al-lows crossing cor respondences  to accountfor  word  order  di f ferences.
I ts output  canbe conver ted  quickly and easi ly into a sen-tence  a l ignment .
S IMR's  output  has beenused to al ign more  than  200 megabytes  ofthe  Canad ian  Hansards  for  pub l i ca t ion  bythe  L inguist ic  Data  Consor t ium.1.
In t roduct ionThe first step in most corpus-based multilin-gual NLP work is to construct a detailed mapof the correspondence between a text and itstranslation (a b i text  map).
Several auto-matic methods have been proposed for thistask in recent years.
However, most of thesemethods address only the sub-problem of align-ment (Catizone et al 1989, Brown et al 1991,Gale & Church 1991, Debili & Sammouda 1992,Simard et al 1992, Kay & RSscheisen 1993,Wu 1994).
Alignment algorithms assume theavailability of text unit boundary information andtheir output has less expressive power than a gen-eral bitext map.
The only published solution tothe more difficult general bitext mapping problem(Church 1993) can err by several typeset pages.Such frailty can expose lexicographers and ter-minologists to spurious concordances, feed noisytraining data into statistical translation models,and degrade the performance of corpus-based ma-chine translation.
Some multilingual NLP tasks,such as automatic validation of terminological con-sistency (Macklovitch 1995) and automatic detec-tion of omissions in translations (implemented forthe first time in (Melamed 1996)), have been tech-nologically impossible until now, because they arehighly sensitive to large errors in the bitext map.The Smooth Injective Map Recognizer(SIMR) is a greedy algorithm for mapping bitextcorrespondence.
SIMR borrows several insightsfrom previous work.
Like Gale & Church (1991)and Brown et al (1991), SIMR relies on the highcorrelation between the lengths of mutual trans-lations.
Like char_.align (Church 1993), SIMRinfers bitext maps from likely points of correspon-dence between the two texts, points that are plot-ted in a two-dimensional space of possibilities.
Un-like previous methods, SIMR searches for only ahandful of points of correspondence at a time.Each set of correspondence points is foundin two steps.
First, SIMR generates a numberof possible points of correspondence b tween thetwo texts, as described in Section 3.1.
Second,SIMR selects those points whose geometric ar-rangement most resembles the typical arrange-ment of true points of correspondence.
This selec-tion involves localized pattern recognition heuris-tics, which Section 3.2 refers to collectively as thechain recogn i t ion  heur ist ic .
SIMR then inter-polates between successive selected points to pro-duce a bitext map, as described in Section 3.3.2.
Def in i t ionsSeveral key terms will help to explain SIMR.
First,a b i text  (Harris 1988) comprises two versions ofa text, such as a text in two different languages.Translators create a bitext each time they trans-late a text.
Second, each bitext defines a rectan-gular b i text  space, such as Figure 1.
The widthO4._CC00 Q.-8II>.,terminus~ diagonaorigin x = character position i  text 1Figure 1: a bi~ext spaceand height of the rectangle are the lengths of thetwo component exts, in characters.
The lowerleft corner of the rectangle is the or ig in  of thebitext space and represents the two texts' begin-nings.
The upper right corner is the te rminusand represents the texts' ends.
The line betweenthe origin and the terminus is the main  diago-nal.
The slope of the main diagonal is the b i texts lope.Each bitext space contains a number of t ruepo in ts  of  cor respondence  (TPCs) ,  other thanthe origin and the terminus.
For example, if a to-ken at position p on the x-axis and a token at posi-tion q on the y-axis are translations of each other,then the coordinate (p, q) in the bitext space is aTPC 1.
TPCs also exist at corresponding bound-aries of text units such as sentences, paragraphs,and sections.
Groups of TPCs with a roughlylinear arrangement in the bitext space are calledchains.B i text  maps  are bijective functions in bitextspaces.
For each bitext,  the t rue  b i text  map(TBM)  is the shortest bitext map that runsthrough all the TPCs.
The purpose of a b i textmapp ing  a lgor i thm is to produce bitext mapsthat are the best possible approximations of eachbitext's TBM.3.
S IMRMost of SIMR's effort is spent searching for TPCs,one short chain at a time.
The search for eachchain begins in a small rectangular region of thebitext space, whose dimensions are proportional tothose of the whole bitext space.
Within this search1Since distances in the bitext space are measuredin characters, the position of a token is defined to bethe mean position of its characters.rectangle, the search alternates between a gener-ation phase and a recognition phase, which aredescribed in more detail in Sections 3.1 and 3.2.In the generation phase, SIMR generates all thepoints of correspondence that satisfy the suppliedmatching predicate (explained below).
In therecognition phase, SIMR calls the chain recogni-tion heuristic to search for suitable chains amongthe generated points.
If no suitable chains arefound, the search rectangle is proportionally ex-panded up and to the right and the generation-recognition cycle is repeated.
The rectangle keepsexpanding until at least one acceptable chain isfound.
If more than one chain is found, SIMR ac-cepts the chain whose points are least dispersedaround its least-squares line.
Then, SIMR selectsanother egion of the bitext space to search for thenext chain.SIMR employs a simple heuristic to select re-gions of the bitext space to search.
To a firstapproximation, TBMs are monotonically increas-ing functions.
This means that if SIMR accepts achain, it should look for others either above andto the right or below and to the left of the oneit has just located.
All SIMR needs is a place tostart the trace, and a good place to start is at thebeginning.
The origin of the bitext space is alwaysa TPC.
So, the first search rectangle is anchoredat the origin.
Subsequent search rectangles areanchored at the top right corner of the previouslyfound chain, as shown in Figure 2.\[e disc?veredTPC 1 o ?
~o undiscoverdTPC | o 7main ~search-~ searchJ ?
?
~reviouschainFigure 2: SIMR's "expanding rectangle" searchstrategy.
The search reclangle is anchored at thetop right corner of the previously found chain.
Itsdiagonal remains parallel to the main diagonal.The expanding-rectangle search strategymakes SIMR robust in the face of TBM discontinu-ities.
Figure 2 shows a segment of the TBM tracethat contains a vertical gap (an omission in thetext on the x-axis).
As the search rectangle grows,it will eventually pick up the TBM's trail, even if2the discontinuity is quite large (Melamed 1996).Section 3.8 explains why SIMR will not be ledastray by false points of correspondence.3.1 Po int  Generat ionA match ing  pred icate  is a heuristic for guess-ing whether a given point in the bitext space is aTPC.
I have considered only token-based match-ing predicates, which can only return TRUE for apoint (x, y) if x is the position of a token e on thex-axis and y is the position of a token f on the y-axis.
For each such point, the matching predicatemust decide whether the e and f are likely to bemutual translations.Various knowledge sources can be broughtto bear on the decision.
The most universalknowledge source is a translation lexicon.
Trans-lation lexicons can be extracted from machine-readable bilingual dictionaries (MRBDs), in therare cases where MRBDs are available.
In othercases, they can be induced automatically using anyof several existing methods (Dagan et al 1993,Fung ~ Church 1991, Melamed 1995).
Since thematching predicate does not require perfect ac-curacy, the induced lexicons need not be perfect.When a large translation lexicon is not available, asmall hand-constructed translation lexicon for thekey terms in a given bitext may suffice to producea rough map for that bitext.If the languages involved have similar alpha-bets, then it may be possible to construct a match-ing predicate with very little effort, using themethod of cognates.
Cognates are words witha common etymology and a similar meaning indifferent languages.
The etymological similar-ity is often reflected in the words' orthographyand/or pronunciation.
Languages that are closelyrelated will often share a large number of cog-nates.
For example, in the non-technical Cana-dian Hansards (parliamentary debate transcriptsavailable in English and French), cognates can befound for roughly one quarter of all text tokens(Melamed 1995).
A cognate-based matching pred-icate will generate more points for more similarlanguage pairs, and for text genres where moreword borrowing occurs, such as technical texts.For English and French, such a matching predicatecan generate nough points in the bitext space toobviate the need for a translation lexicon.Phonetic cognates can be used to map be-tween language pairs with dissimilar alphabets,even when the languages are not closely related.When language L1 borrows a word from languageL2, the word is usually written in L1 similarlyto the way it sounds in L2.
Thus, French andRussian /p~rtmone/ are cognates, as are English/s Is tom/and Japanese/~isutemu/.
For many lan-398400982009800097800.~  9760097400972009700096800109000?
*oo,e* eo~ o %.
e .,oo .
* ooo?~* o o.o oi i109500 110000position in text 1*e00i110500 111000Figure 3: Part of a typical scatterplot in bitextspace, the true points of correspondence trace thetrue bitext map parallel to the main diagonal.guages, it is not difficult to construct an approxi-mate mapping from the orthography to its under-lying phonological form.
Given such a mappingfor L1 and L2, it is possible to identify cognatesdespite incomparable orthographies.SIMR was tested on French and English withtwo different matching predicates.
The firstmatching predicate relies on orthographic og-nates and a stop-list of closed-class words for bothlanguages.
SIMR judges the cognateness of eachtoken pair by their Longest Common SubsequenceRatio (LCSR).
The LCSR of a token pair is thenumber of characters that appear in the same or-der in both tokens divided by the length of thelonger token (Melamed 1995).
The common char-acters need not be contiguous.
The matchingpredicate considers a token pair cognates if theirLCSR exceeds a certain threshold.
The LCSRthreshold was optimized together with SIMR'sother parameters, as described in Section 3.7.
Thestop-list of closed-class words made the match-ing predicate more accurate, because closed-classwords are unlikely to have cognates.
On the con-trary, they often produce spurious matches.
Ex-amples for French and English include a, an, onand par.The second matching predicate was just likethe first, except that it also evaluated to TRUEwhenever the input token pair appeared as an en-try in a translation lexicon.
The translation lexi-con was automatically extracted from an MRBD(Cousin et al 1991).3.2 Point  Select ionAs illustrated in Figure 3, even short sequences ofTPCs form characteristic patterns.
In particular,TPCs have the following properties:?
L inear i ty :  TPCs tend to line up straight.
Setsof points with a roughly linear arrangement arecalled chains.?
Constant  Slope: The slope of a TPC chain israrely much different from the bitext slope.?
In jec t iv i ty :  No two points in a chain of TPCscan have the same x -  or y-co-ordinates.SIMR exploits these properties to decide whichchains in the scatterplot might be TPC chains.The chain recognition heuristic involves twothreshold parameters: max imum po in t  dis-persa l  and max imum ang le  dev iat ion .
Eachthreshold is used to filter candidate chains.
First,the linearity of each chain is judged by measur-ing the root mean squared distance of the chain'spoints from the chain's least-squares line.
If thisdistance exceeds the maximum point dispersalthreshold, the chain is rejected.
Second, the an-gle of each chain's least-squares line is compared tothe arctangent of the bitext slope.
If the differenceexceeds the maximum angle deviation threshold,the chain is rejected.
Lastly, chains that lack theinjectivity property are rejected.3.3 Reducing the Search SpaceIn a region of the scatterplot containing n points,there are 2 n possible chains - -  too many to searchby brute force.
The.properties of TPCs listedabove provide two ways to constrain the search.The Linearity property leads to a constrainton the chain size.
Chains of only a few points areunreliable, because they often line up straight bycoincidence.
Chains that are too big will span toolong a segment of the TBM to be well approxi-mated by a line.
SIMR chooses a fixed chain sizek, 6 < k < 9.
Fixing the chain size at k reducesthe number of candidate chains tok (nFortypicalvaluesofnandk, ( n ) k can stillreach into the millions.
The Constant Slope prop-erty suggests another constraint: SIMR shouldconsider only chains that are roughly parallel tothe main diagonal.
Two lines are parallel if theperpendicular displacement between them is con-stant.
So, if we want to find chains that areroughly parallel to the main diagonal, we shouldlook for chains whose points all have roughlythe same displacement 2 from the main diagonal.Points with similar displacement can be groupedtogether by sorting, as illustrated in Figure 4.Then, chains that are most parallel to the main2Displacement can be negative.4subsequence 1 ~i mna i l~ J(points 1 thru 6) a ~subsequence 8(points 5 thru 10) " "Figure 4: The points of correspondence are num-bered according to their displacement from themain diagonal.
The chain most parallel to themain diagonal is always one of the contiguous ub-sequences of this ordering.
For a fixed chain sizeof 6, there are 13 - 6 + 1 = 8 contiguous ubse-quences in this region of 13 points.
Of these 8,subsequence 5 is the best chain.diagonal will be contiguous ubsequences of thesorted point sequence.
In a region of the scatter-plot containing n points, there will be only n-k+lsuch subsequences of length k. Sorting the pointsby their displacement is the most computationallyexpensive step in the recognition process.SIMR's chain recognition heuristic acceptsnon-monotonic chains.
This is a desirable prop-erty, because ven languages with similar syntax,like French and English, have well-known differ-ences in word order.
For example, English (ad-jective, noun) pairs usually correspond to French(noun, adjective) pairs.
Such inversions result inchains that contain a pattern like points 5 and 9in Figure 4.
SIMR has no problem accepting theinverted points, unlike bitext mapping algorithmsthat try to minimize the distance between TPCs.To my knowledge, no other bitext mapping algo-rithm allows non-monotonic map segments.You may wonder how SIMR will fare with lan-guages that are less closely related, which haveeven more word order variation.
This is an openquestion, but there is reason to be optimistic.
Toaccommodate language pairs with vastly differentword order, it may suffice for SIMR to increase themaximum point dispersal threshold, relaxing thelinearity constraint on TPC chains.aaaa~ atlJh h hFrench textFigure 5: Frequent oken types cause false points ofcorrespondence that line up in rows and columns.3.4 Reducing NoiseThe Injectivity property also leads to a heuris-tic which reduces the number of candidate chains,although the chief aim of this heuristic is to in-crease the signal-to-noise ratio in the scatterplot.The heuristic was introduced after inspection ofseveral scatterplots in bitext spaces revealed a re-curring noise pattern.
This noise pattern is illus-trated in Figure 5.
It consists of correspondencepoints that line up in rows or columns associatedwith frequent token types.
Token types like theEnglish article "a" can produce one or more cor-respondence points for almost every sentence inthe opposite text.
Since only one of these corre-spondence points can be correct, all but one ofthe points in each row and column are noise.
It 'sdifficult to measure xactly how much noise is gen-erated by frequent okens, and of course the pro-portion is different for every bitext.
Visual inspec-tion of some scatterplots indicated that frequenttokens are often responsible for the lion's share ofthe noise.
Reducing this source of noise makes itmuch easier for SIMR to stay on track.Other bitext mapping algorithms mitigatethis source of noise either by assigning lowerweights to correspondence points associated withfrequent token types (Church 1993) or by sim-ply deleting frequent oken types from the bitext(Dagan et al 1993).
However, a frequent tokentype can be rare in some parts of the text.
In thoseparts, the token type can provide valuable clues tocorrespondence.
On the other hand, many tokensof a relatively rare type can be concentrated in ashort segment of the text, resulting in many falsecorrespondence points.
The varying concentrationof identical tokens suggests that more localized*G)1-IIIM2 .
?ML"".'"
, . '
"d' M2 L MERI I .
.
.
.
.
.
.
.
.
.
Sentence A .
.
.
.
.
.
.
.
.
.
.
.IFigure 6: Two text segments at the end of Sen-fence A were switched uring translation, resultingin a non-monotonic segment.
To interpolate in-jective bitext maps, non-monotonic segments mustbe encapsulated in Minimum Enclosing Rectangles(MERs).
A unique bitext map can then be in-terpolated by using the lower left and upper rightcorners of the MER (map M2), instead of usingthe non-monotonic orrespondence points (func-tion M1).noise filters would be more effective.
SIMR's lo-calized search strategy provides the perfect vehiclefor a localized noise filter.The filter is based on another threshold pa-rameter, the max imum po in t  ambigu i ty  level(MaxPAL) .
For each point p = (x, y), let X bethe number of points in column x within the searchrectangle, and let Y be the number of points in rowy within the search rectangle.
Then,ambiguity level of p = X + Y - 2.Thus, if p is the only point in its row and col-umn, its ambiguity level is zero.
SIMR ignorespoints whose ambiguity level exceeds the MaxPALthreshold.
What makes this a localized filter isthat only points within the search rectangle counttowards each other's ambiguity level.
This meansthat the ambiguity level of a given point can in-crease as the search rectangle xpands; the set ofpoints that SIMR ignores can change dynamically.3.5 InterpolationA bitext map can be derived from a set of cor-respondence points by linear interpolation.
Theonly complication is that linear interpolation isnot well-defined for non-monotonic sets of points.It would be incorrect to simply connect the dotsleft to right, because the resulting function maynot be one-to-one.
To interpolate injeetive bitextmaps, non-monotonic segments must be encapsu-lated in Minimum Enclosing Rectangles (MERs),as shown in Figure 6.
A unique bitext map canbe interpolated by using the lower left and up-per right corners of the MER, instead of using thenon-monotonic correspondence points.3.6 EnhancementsThere are many possible enhancements o the al-gorithm outlined above.
The following subsectionsdescribe but two of the more interesting extensionsin the current implementation.Large  Non-monoton ic  Segments  SIMR hasno problem with small non-monotonic segmentsinside chains.
However, the expanding rectanglesearch strategy can miss larger non-monotonic seg-ments, which cannot fit inside one chain.
If a moreprecise map is desired, these larger non-monotonicsegments can be easily recovered uring a secondsweep through the bitext space??
TPC \]i- - -  SIMR',  /:: .
/ "firstpass J: .. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
; .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
=-&- .... /.I i ?
It j..... i~s~.g.~i_ii_ii~~!.i = i .
...........Figure 7: Segments i and j switched placed dur-ing translation.
If  a more precise map is desired,these larger non-monotonic segments can be easilyrecovered uring a second sweep through the bitextspace.
Any non-monotonic segment of the TBMwill occupy the intersection of a vertical gap anda horizontal gap in the monotonic first-pass map.Non-monotonic TBM segments result in acharacteristic map pattern, as a consequence ofthe injectivity of bitext maps.
In Figure 7, thevertical range of segment j corresponds to a ver-tical gap in SIMR's first-pass map.
The horizon-tal range of segment j corresponds to a horizon-tal gap in SIMR's first-pass map.
Similarly, anynon-monotonic segment of the TBM will occupythe intersection of a vertical gap and a horizon-tal gap in the monotonic first-pass map.
Further-more, switched segments are almost always adja-cent and relatively short.
Therefore, to recovernon-monotonic segments of the TBM, SIMR needsonly to search gap intersections that are close to6the first-pass map.
There are usually very fewsuch intersections that are also large enough to ac-commodate new chains, so the second-pass searchrequires only a small fraction of the computationaleffort of the first pass.Local  S lope Var ia t ion  To ensure that SIMRrejects spurious chains, the maximum angle devi-ation threshold must be set low.
However, like anyheuristic filter, this one will reject some perfectlyvalid candidates.
The injectivity of bitext mapsenables a method for recovering some of the re-jected valid chains.
Valid chains that are rejectedby the angle deviation filter sometimes occur be-tween two accepted chains, as shown in Figure 8.If chains C and D are accepted as valid, then thee > maximum angle .
mam.deviation threshold cllagonal/?..ii ,,.I T @ .-'" Ol ' e~ ~hain x /?
?
J ~2ndpasssearch spaceFigure 8: Chain X is perfectly valid, even thoughit has a highly deviant slope.
Such chains can berecovered by re-searching regions between acceptedchains.
The slope of the local main diagonal canbe quite different from the slope of the global maindiagonal.slope of the TBM between the end of Chain C andthe start of Chain D must be much closer to theslope of Chain X than to the slope of the main di-agonal.
Chain X should be accepted.
When SIMRmakes its second-pass earch for non-monotonicsegments, it also searches for sandwiched chainsin any space between two accepted chains that islarge enough to accommodate another chain.
Thissubspace of the bitext space will have its own maindiagonal.
The slope of this local main diagonal canbe quite different from the slope of the global maindiagonal.Another source of local slope variation is"non-linguistic" text, such as white space or ta-bles of numbers.
Usually, such text is copied "asis" during translation, resulting in regions of bitextspace where the slope of the TBM is exactly 1.The problem is that these regions can be largeenough to severely skew the slope of the main di-agonal.
Thus, they can fool SIMR into search-ing the whole bitext space for TPC chains whoseslope is close to 1, even though most of the bitextTable 1: Comparison of error distributions for SIMR and char_al ign,  in characters.bitext"easy"Hansard(7123 ref.
pts.
)"hard"Hansard(2693 ref.
pts.
)algorithmchar_alignSIMRSIMR with MRBDchar_alignSIMRSIMR with MRBDmedianabsolute rrornot reported0.490.61180.480.6099thpercentile20050492005544root meansquared error571313469.88.6map between "linguistic" parts of the bitext has avery different slope.
Sometimes, the translation ofnon-linguistic text is completely erratic, especiallywhere white space is concerned.
Not surprisingly,SIMR cannot perform well on such text.It should not be difficult to recognize bitextsections that consist of "non-linguistic" text.Then, SIMR will be better able to follow the vari-ations in the slope of the TBM.
This extension toSIMR is next in line.3.7 EvaluationThe standard method of evaluating bitext map-ping algorithms is to compare their output to ahand-constructed reference set of TPCs.
MichelSimard of CITI  graciously provided me with sev-eral such reference sets for French-English bi-texts, including the same "easy" and "hard"Hansard bitexts that have been used to evaluateother bitext mapping and alignment algorithms inthe literature (Church 1993, Simard et al 1992,Dagan et al 1993).
A non-Hansard reference setwas used for SIMR's development.
All of SIMR'sparameters, namely the thresholds for maximumpoint dispersal, maximum angle deviation, maxi-mum point ambiguity, and the LCSR used in thematching predicate, as well as the fixed chain size,were simultaneously optimized on this data set us-ing simulated annealing (Vidal 1993).
Differentparameter settings considered by the optimizationprocess resulted in different bitext maps for thedevelopment bitext.
Each set of parameter valueswas scored according to the root mean squarederror between the resulting bitext map and thereference set of TPCs.
The best-scoring set of pa-rameter values was used to evaluate SIMR.SIMR was evaluated on the "easy" and "hard"Hansard bitexts.
Note that these bitexts are sonamed because one was easier than the otherfor the alignment algorithm that was first eval-uated on them.
There is no a priori reason tobelieve that one or the other will be easier forSIMR.
Table 1 compares SIMR's error distribu-tion on these bitexts with that of the previousfront-runner, char._al:i.gn, as reported by Church7(1993).
SIMR's RMS error is lower by more thana factor of 4.
SIMR is also much more robust:it rarely errs by more than half the length of anaverage sentence.
Such robustness has enabled atleast one new commercial-quality application - -automatic detection of omissions in translations(Melamed 1996).
This task was impossible untilnow, because it cannot tolerate even a few wilderrors, such as those produced by an independentimplementation f char_al:i.gn (Simard 1995).Note that the error between a bitext map andeach reference point can be defined as the hori-zontal distance, the vertical distance, or the dis-tance perpendicular to the main diagonal.
Thelatter distance will always be shortest, on aver-age.
Church (1993) did not specify which metriche used.
Of the three possibilities, Table 1 con-servatively reports the highest error estimates forSIMR.
The lowest estimates for SIMR without thetranslation lexicon are an RMS error of 6.1 for the"easy" bitext and 5.4 for the "hard" bitext.
Withthe translation lexicon, the lowest error estimatesdrop to 6.0 for the "easy" bitext and 4.6 for the"hard" bitext.3.8 DiscussionOne concern about greedy algorithms is that ifthey wander off track, they may not be able tofind their way back.
There is no guarantee thatthis will never happen with SIMR.
However, thereis evidence that it is extremely unlikely.
First,SIMR can wander off the right track only if thereis an alternative (wrong) track.
The noise re-duction heuristics mentioned in Section 3.5 en-sure that very few points of correspondence canbe generated away from the TBM trace.
Thosepoints that are generated are extremely unlikelyto be sufficiently linear and to have the properslope to fool the chain recognition heuristic.
Thefixed chain size parameter also plays a role.
Thelonger the chain, the less probable it is that a setof false points of correspondence will take on avalid-looking arrangement.The development bitext used in the simulatedannealing parameter optimization contained over40000 words.
During the optimization, SIMR oc-casionally veered off course when the fixed chainsize was 5 or less.
It rarely got lost with a fixedchain size of 6 and never with a fixed chain size of 7or more.
The optimal fixed chain size with respectto the RMS error metric was 9 when the transla-tion lexicon was used, and 8 when it was not.
Thechances of 8 or 9 false points of correspondence sat-isfying the maximum point dispersal, maximumangle deviation, and maximum point ambiguitylevel thresholds are negligible.Finally, if SIMR does get lost, the result-ing bitext map will contain telltale discontinuities.Such discontinuities can be automatically detectedwith high reliability (Melamed 1996).
With thissanity check in place, manual verification shouldnever be necessary.4.
Al ignmentSIMR has no idea that words are often used tomake sentences.
It just outputs a series of cor-responding token positions, leaving users free todraw their own conclusions about how the texts'larger units correspond.
However, many existingtranslators' tools and machine translation strate-gies are based on aligned sentences.
What canSIMR do for them?There are several papers in the literatureabout bitext alignment.
The algorithms thatseem to work best rely on the high correlationbetween the lengths of corresponding sentences(Brown et al 1991, Gale & Church 1991).
How-ever, these algorithms can fumble in bitext sec-tions that contain many sentences of very similarlength, like this vote record:English FrenchMr.
McInnis?Yes.Mr.
Saunders?No.Mr.
Cossitt?YeS.M.
Mclnnis?Oui.M.
Saunders?Non.M.
Cossitt?Oui.Source: (Chen 1993)The only way to ensure a correct alignment in suchregions is to look at the words.
For this reason,Chen (1993) adds a statistical translation modelto the Brown et al alignment algorithm, and Wu(1994) adds a translation lexicon to the Gale &Church alignment algorithm.A set of points of correspondence l ads toalignment more directly than a translation modelor a translation lexicon, because points of corre-spondence are a relation between token instances,not between token types.
Moreover, a set of cor-respondence points, supplemented with sentenceboundary information, expresses entence  cor-respondence ,  which is a richer representationthan sentence alignment.
Figure 9 illustrates howsentence boundaries form a grid over the bitextspace 3.
Each cell in the grid represents the in-tersection of two sentences, one from each com-ponent text.
A point of correspondence inside cell(X,y) indicates that some token in sentence X cor-responds with some token in sentence y; i.e.
sen-tences X and y correspond.
Thus, Figure 9 indi-cates that sentence  corresponds with sentences Gand H.In contrast o a correspondence r lation, "ana l ignment  is a segmentation of the two textssuch that the nth segment of one text is thetranslation of the nth segment of the other.
"(Simard et al 1992) For example, given the to-ken correspondences in Figure 9, the segment(G, H) should be aligned with the segment (e, f) .If sentences (X i , .
.
.
,Xn)  align with sentences(yl, .
.
.
,y,~), then ( (X1, .
.
.
,X ,~) , (y l , .
.
.
,y ,~))  isan a l igned block.
In geometric terms, alignedblocks are rectangular regions of the bitext space,such that the sides of the rectangles coincide withsentence boundaries, and such that no two rectan-gles overlap either vertically or horizontally.
Thealigned blocks in Figure 9 are outlined with solidlines.SIMR's initial output has more expressivepower than the alignment that can be derived fromit.
One illustration of this difference is that sen-tence correspondence can express inversions, butsentence alignment cannot.
Inversions occur sur-prisingly often in real bitexts, even for sentence-size text units.
Figure 9 provides another illustra-tion.
If, instead of the point in cell (I-I,e), therewas a point in cell (G,f), the correct alignmentfor that region would still be ((G, g ) ,  (e, f)).
Ifthere were points of correspondence in both (HI,e)and (G,f), the correct alignment would still be thesame.
Yet, the three cases are clearly different.
Ifa lexicographer wanted to see a word in sentence Gin its bilingual context, it would be useful to knowwhether sentence f is relevant.Converting from sentence correspondence tosentence alignment is of dubious practical value.Nevertheless, in order to facilitate comparison ofthe geometric approach with other alignment al-gorithms, I have designed the Geometr i c  Sen-tence  A l ignment  (GSA)  algorithm to reduce3The techniques presented in this section can beapplied equally well to paragraphs, lists of items, orany other text units for which boundary informationis available.8hf=o edCbai i i i i i iI I I I I I I @I I I I I I I ?.
.
.
.
I - -  - -  - F  - -  - - I - -  - -  + .
.
.
.
- I -  - -  - -  ' - t  .
.
.
.
I .
.
.
.
I .
.
.
.I ?
@II ?I ?I @.
.
.
.
.
.
.
.
.
.
.
T .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.III.
.
.
.
.
.
T~,,i .
.
.
.
T,,,~ .... Tj,,i .
.
.
.
.
.
.
.
.
.  "
~ ?
.
.
.
.
.
.
T,~,, .
.
.
.- -  T, - ?
?
- -I. .
.
.
.
.
T .
.
.
.
T .
.
.
.
.
.
.
.
.
.
I~  .
.
.
.
.
.
.
.
.
.
.
.
.
.
T .
.
.
.
.
.
.
.
.
.
.I I I II I I ?
II I I ?
I. .
.
.
,"--T--~--," ,~' ?
?
?1 .
.
.
.
.
.
.
.
.
.
.
.
.
T,,, .
.
.
.
.
.
.
.
.
.
.
.- - I -  - -  1 -  - -  - - I  .
.
.
.
- I  .
.
.
.
I .
.
.
.
I .
.
.
.
.
I .
.
.
.
.
.
1 -  .
.
.
.
.
.
.
I .
.
.
.
.I I I I I I I I I I II I I I I I I I I I I. .
.
.
I - -  - -  $ - -  - - I - -  - -  4,- .
.
.
.
'4.
- -  - -  .4  .
.
.
.
I .
.
.
.
I .
.
.
.
.
I .
.
.
.
.
.
4 -  .
.
.
.
.
.
.
I .
.
.
.
.I I I I I I I I I I II I I I I I I I I I II I I I I I I I I I I" ~ \ ] - -  -- 1" -- --I-- -- T .
.
.
.
T -- -- I .
.
.
.
I .
.
.
.
I .
.
.
.
.
I .
.
.
.
.
.
T .
.
.
.
.
.
.
I .
.
.
.
.I I I I I I I I I II I I I I I I I I II I I I I I I I I II I I I I I I I I IABCD E F G H I J K Lsentences on x-axisFigure 9: Sentence boundaries form a grid over the bitext space.
Each cell in the grid represents the productof two sentences, one from each component text.
A point of correspondence inside cell (X, y) indicates thatsome token in sentence X corresponds with some token in sentence y; i.e.
the sentences X and y correspond.So, for example, sentence E corresponds with sentence d. The aligned blocks are outlined with solid lines.sets of correspondence points to alignments.
Thealgorithm's first step is to perform a transitive clo-sure over the input correspondence r lation.
Forinstance, if the input contains (G,e), (H,e), and(H,f), then GSA adds the pairing (G,f).
Next,GSA forces all segments to be contiguous: If sen-tence Y corresponds with sentences x and z, butnot y, the pairing (Y,y) is added.
In geomet-ric terms, these two operations arrange all cellsthat contain points of correspondence into non-overlapping rectangles, while adding as few cellsas possible.
The result is an alignment relation.A complete set of TPCs, together with appro-priate boundary information, guarantees a perfectalignment.
Alas, the points of correspondence pos-tulated by SIMR are neither complete nor noise-free.
Fortunately, the noise in SIMR's outputcauses alignment errors in very predictable ways.GSA employs a couple of backing-off heuristics toelimninate most of the errors.SIMR makes errors of omission and errors ofcommission.
Typical errors of commission arestray points of correspondence like the one in cell(H, e) in Figure 9.
This point indicates that(G, H) and (e, f)  should form a 2x2 aligned block,whereas the lengths of the component sentencessuggest hat a pair of lx l  blocks is more likely.
Ina separate development bitext, I have found thatSIMR is usually wrong in these cases.
To com-bat such errors, GSA re-aligns any aligned blockthat is not lx l ,  using the Gale & Church length-based alignment algorithm (Gale & Church 1991,Simard 1995).
Whenever the component sentencelengths suggest a more fine-grained alignment,SIMR's output is not trusted.Typical errors of omission are illustrated inFigure 9 by the complete absence of correspon-dence points between sentences (B ,C ,D)  and(b, c).
This block of sentences i  sandwiched be-tween aligned blocks.
It is highly likely that at9Table 2: Comparison of alignment algorithms.
One error is counted for each aligned block in the referencealignment that is missing from the test alignment.errors, given errors, not givenbitext algorithm hard constraints hard constraints"easy"Hansard(n = 7123)"hard"Hansard(n = 2693)Gale & Church (1991)Simard et al (1992)SIMR/GSASIMR/GSA with MRBDGale & Church (1991)Simard et al (1992)S IMR/GSAS IMR/GSA with MRBDnot applicable114 (1.6%)104 (1.5%)80 (1.1%)not applicable50 (1.9%)50 (1.9%)45 (:.7%)128 (1.8%)171 (2.4%):15 (:.6%)90 (1.3%)80 (3.0%)102 (3.8%)61 (2.3%)48 (1.8%)least some of these sentences are mutual transla-tions, despite SIMR's failure to find any pointsof correspondence b tween them.
Therefore, GSAtreats all empty blocks just like aligned blocks.
Ifan empty block is not lx l ,  GSA re-aligns it using alength-based algorithm, just like it would re-alignany other many-to-many aligned block.The most difficult problem occurs when an er-ror of omission occurs next to an error of commis-sion, like in blocks ((), (h)) and ((J, K), (i)).
If thepoint in cell (J,i) should really be in cell (J,h), re-alignment inside the erroneous blocks would notsolve the problem.
A naive solution is to mergethese blocks and then to re-align them using alength-based method.
Unfortunately, this kindof alignment pattern, i.e.
0xl followed by 2xl,is surprisingly often correct.
Length-based meth-ods assign very low probabilities to such patternsequences and usually get them wrong.
There-fore, GSA also considers the confidence level withwhich the length-based alignment algorithm re-ports its re-alignment.
If this confidence level issufficiently high, GSA accepts the length-basedre-alignment; otherwise, the alignment indicatedby SIMR's points of correspondence is retained.The minimum confidence at which GSA trusts thelength-based re-alignment is a GSA parameter,which has been optimized on a separate develop-ment bitext.Due to the paucity of development resourcesat my disposal, GSA's backing-off heuristics aresomewhat ad hoc.
Even so, GSA performs at leastas well as other alignment algorithms, and usu-ally better.
Table 2 compares SIMR's accuracyon the "easy" and "hard" reference bitexts withthe accuracy of two other alignment algorithms,as reported by Simard et al (1992).
The errormetric counts one error for each aligned block inthe reference alignment hat is missing from thetest alignment.
The hard constraints correspondto paragraph boundaries.More important han GSA's current perfor-mance is GSA's potential performance.
With abigger development bitext, more effective backing-off heuristics can be developed.
More precise inputwould also make a big difference: GSA's perfor-mance will improve whenever SIMR's performanceimproves.Although GSA sometimes backs off to aquadratic-time alignment algorithm, in practiceits running time is linear in the number of in-put sentences.
The points of correspondence inSIMR's output are sufficiently dense and precisethat GSA backs off only for very small alignedblocks.
When the translation lexicon was usedin SIMR's matching predicate, the largest alignedblock that needed to be re-aligned in the "easy"and "hard" test bitexts was 5x5.
Without thetranslation lexicon, the largest re-aligned blockwas 7x7.
So, GSA's running time is O(kn), wheren is the number of input sentences and k is a smallconstant proportional to the size of the largest re-aligned block.Admittedly, GSA is only useful when a goodbitext map is available.
In such cases, there arethree reasons to favor GSA over other optionsfor alignment: One, it is simply more accurate.Two, its running time is linear in the numberof sentences, faster than dynamic programmingmethods.
Therefore, three, it is not necessaryto manually segment he component exts intosmaller units before input to GSA.
GSA worksalmost as well without such "hard constraints.
"Hard constraints are necessary for alignment algo-rithms that use dynamic programming, in orderto maintain an acceptable running time on longerbitexts(Gale & Church 1991, Simard et al 1992).SIMR produced bitext maps for 200 mega-bytes of the Canadian Hansards.
GSA convertedthese maps into alignments.
The Linguistic DataConsortium plans to publish both the maps andthe alignments in the near future.\ ]05.
Conc lus ionThe Smooth Injective Map Recognizer (SIMR) hasfive advantages over previous bitext mapping al-gorithms.
First, it lowers average rrors by morethan a factor of 4.
Second, it avoids very largeerrors, improving robustness to a level that en-ables new commercial-quality applications.
Third,it does not require large amounts of computermemory to run.
Fourth, it accepts non-monotonicsegments to account for inversions and word or-der differences.
Fifth, its output can be convertedquickly and easily into an accurate sentence align-ment.There are many possible extensions to thiswork.
One interesting observation is that alignedsentences can be used to induce translation lex-icons, and translation lexicons are an importantinformation source for bitext mapping and align-ment (Kay & RSscheisen 1993, Chen 1993).
Iplan to explore an interactive loop between SIMR,GSA and my algorithm for inducing translationlexicons (Melamed 1995).It would also be interesting to experimentwith SIMR and GSA on language pairs that arenot as closely related as English and French.
Theonly technique for mapping between more dis-parate languages that has been rigorously evalu-ated (Wu 1994) relies on length correlations sprin-kled with some lexical information.
From thispoint of view, Wu's technique is similar to the oneused by Simard et al (1992).
So, I am eager to seewhether the geometric approach will compare asfavorably to Wu's results on English and Chineseas it has to Simard et al's results on English andFrench.AcknowledgmentsThis research began while I was a visitorat the Centre d'Innovation en Technologies del'Information i  Laval, Canada.
I am indebtedto Pierre Isabelle for informing me that the bitextmapping problem is far from being solved.
Thispaper has benefited tremendously from the in-sights and comments ofthe following people: MikeCollins, Jason Eisner, George Foster, Pierre Is-abelle, Elliott Macklovitch, Mitch Marcus, Ad-wait Ratnaparkhi, Michel Simard, Eero Simon-celli, Matthew Stone, Lyle Ungar and three anony-mous reviewers.
My work was partially fundedby ARO grant DAAL03-89-C0031 PRIME and byARPA grants N00014-90-J-1863 and N6600194C6043.11References\[Brown et al 1991\] P. F. Brown, J. C. Lai ~ R. L.Mercer, "Aligning Sentences in Parallel Cor-pora," Proceedings of the 29th Annual Meet-ing of the Association for Computational Lin-guistics, Berkeley, CA, 1991.\[Catizone et al 1989\] R. Catizone, G. Russell &S. Warwick "Deriving Translation Data fromBilingual Texts," Proceedings of the FirstInternational Lexical Acquisition Workshop,Detroit, MI, 1993.\[Chen 1993\] S. Chen, "Aligning Sentences inBilingual Corpora Using Lexical Informa-tion," Proceedings of the 31st Annual Meet-ing of the Association for Computational Lin-guistics, Columbus, OH, 1993.\[Church 1993\] K. W. Church, "Char_align: AProgram for Aligning Parallel Texts at theCharacter Level," Proceedings of the 31st An-nual Meeting of the Association for Compu-tational Linguistics, Columbus, OH, 1993.\[Cousin et al 1991\] P. g. Cousin, L. Sinclair, J.F.
Allain & C. E. Love, The Collins Paper-back French Dictionary, Harper Collins Pub-lishers, Glasgow, 1991.\[Dagan et al 1993\] I. Dagan, K. Church, & W.Gale, "Robust Word Alignment for MachineAided Translation," Proceedings of the Work-shop on Very Large Corpora: Academic andIndustrial Perspectives, available from theACL, 1993.\[Debili & Sammouda 1992\] F. Debili & E. Sam-mouda "Appariement des Phrases de TextesBilingues," Proceedings of the 14th Interna-tional Conference on Computational Linguis-tics, Nantes, France, 1992.\[Fung L: Church 1991\] P. Fung & K. W. Church,"K-vec: A New Approach for Aligning Par-allel Texts," Proceedings of the 15th Interna-tional Conference on Computational Linguis-tics, Kyoto, Japan, 1994.\[Gale & Church 1991\] W. Gale & K. W. Church,"A Program for Aligning Sentences in Bilin-gual Corpora," Proceedings of the 29th An-nual Meeting of the Association for Compu-tational Linguistics, Berkeley, CA, 1991.\[Harris 1988\] B. Harris, "Bi-Text, a New Conceptin Translation Theory," Language Monthly#54, 1988.\[Isabelle 1995\] P. Isabelle, personal communica-tion, 1995.\[Kay & RSscheisen 1993\]M. Kay & M. R6scheisen "Text-TranslationAlignment," Computational Linguistics 19:1,Boston, MA, 1995.\[Macklovitch 1995\] E, Macklovitch, "Peut-on ver-ifier automatiquement la coherence ter-minologique?"
Proceedings of the IV e~Journdes scientifiques, Lexicommalique tDictionnairiques, organized by AUPELF-UREF, Lyon, France, 1995.\[Melamed 1995\] I. D. Melamed "Automatic Eval-uation and Uniform Filter Cascades for In-ducing N-best Translation Lexicons," Pro-ceedings of the Third Workshop on Very LargeCorpora, Boston, MA, 1995.\[Melamed 1996\] I. D. Melamed "Automatic De-tection of Omissions in Translations," Pro-ceedings of the 16th International Conferenceon Computational Linguistics, Copenhagen,Denmark, 1996.\[Simard et al 1992\] M. Simard, G. F. Foster & P.Isabelle, "Using Cognates to Align Sentencesin Bilingual Corpora," in Proceedings of theFourth International Conference on Theorel-ical and Methodological Issues in MachineTranslation, Montreal, Canada, 1992.\[Simard 1995\] M. Simard, personal communica-tion, 1995.\[Vidal 1993\] R. V. V. Vidal, Applied SimulatedAnnealing, Springer-Verlag, Heidelberg, Ger-many, 1993.\[Wu 1994\] D. Wu, "Aligning a Parallel English-Chinese Corpus Statistically with Lexical Cri-teria," Proceedings of the 32nd Annual Meet-ing of the Association for Computational Lin-guistics, Las Cruces, NM, 1994.12
