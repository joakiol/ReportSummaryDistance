Proceedings of the 8th International Conference on Computational Semantics, pages 181?194,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsUsing English for commonsense knowledgeAllan Ramsay Debora FieldSchool of Computer Science Dept of Computer ScienceUniv of Manchester Univ of SheffieldManchester M60 1QD, UK Sheffield S1 4DP, UKAbstractThe work reported here arises from an attempt to provide a bodyof simple information about diet and its effect on various commonmedical conditions.
Expressing this knowledge in natural languagehas a number of advantages.
It also raises a number of difficult issues.We will consider solutions, and partial solutions, to these issues below.1 Commonse knowledgeSuppose you wanted to have a system that could provide advice about whatyou should and should not eat if you suffer from various common medicalconditions.
You might expect, at the very least, to be able to have dialogueslike (1).
(1) a.
User: I am allergic to eggs.Computer: OKUser: Should I eat pancakesComputer: No, because pancakes contain eggs, and eating things whichcontain eggs will make you ill if you are allergic to eggs.b.
User: My son is very fat.Computer: OKUser: Should he go swimming.Computer: Yes, because swimming is a form of exercise, and exercise isgood for people who are overweight.c.
User: I have scurvy.Computer: OKUser: Is eating berries good for me?Computer: Yes, because berries contain vitamin C and eating fruit whichcontains vitamin C is good for people who scurvy.181These are comparatively simple dialogues, requiring a very limitedamount of knowledge about foods and medical conditions.
As we will see,however, dealing with them does require a remarkable amount of knowledgeabout language.The framework we are using makes a number of very basic assumptionsabout how you design a system to deal with such dialogues.?
To give appropriate answers to these questions you have to considerwhether the available information supports or contradicts the queriedproposition.?
In order to see whether the available information supports or contra-dicts a proposition you need a body of domain knowledge, and youneed to be able to reason with it.?
Natural languages provide numerous ways of saying almost identicalthings.
There is, for instance, almost no difference between ?I amallergic to eggs?
and ?I have an allergy to eggs?
.
You therefore have tohave a way of dealing with paraphrases.We will explore each of these issues in turn below.2 Answering questionsWe will concentrate here on polar (YES/NO) questions.
We also take thevery simple view that when someone asks a polar question it is because theywant to know whether the proposition encoded in the question is true ornot.
Someone who asks ?Is it safe for me to eggs??
wants to be told ?Yes?if it is and ?No?
if it is not.
We have explored the nature of WH-questionselsewhere (Ramsay & Seville, 2001), and we have discussed situations wherepeople use language in indirect ways (Ramsay & Field, 2008), but for themoment just trying to answer polar questions will pose enough problems tokeep us occupied.In order to answer such a question by saying ?Yes?
you have to seewhether ?It is safe for the speaker to eat eggs?
follows from what you knowabout the speaker and your general knowledge.
You cannot, however, say?No?
simply because your attempted proof that it is safe failed.
If you failedto prove that it is safe you should then see whether you can prove that it isnot.
If, and only if, you can then you should say ?no?
.In general, then, answering a polar question may involve two attemptedproofs?one aimed at showing that the proposition under discussion is true182and then possibly a second aimed at showing that it is false.
If you arelucky you might discover evidence that the proposition is false while you aretrying to show that it is true, but in general you may have to attempt twoproofs.In order to carry out proofs you need an inference engine.
Inferenceengines come in all sorts of shapes and sizes?fast or slow, sound or unsound,complete or incomplete?and they can be applied to a variety of knowledgerepresentation schemes.
The choice of representation scheme, and of theinference engine that you apply to it, will depend on what you want to dowith it.
For our current task we assume that soundness is crucial, sinceyou really would not want a medical advice system to give wrong advice;and that the representation scheme has to be highly expressive, since therelations involved are subtle and need to be represented very carefully.This leads us to a very classical architecture: we construct formal para-phrases (logical forms, LFs) of the user?s statements and questions, and weuse a theorem prover to investigate the status of the propositions encoded inthe user?s questions.
We are, in particular, not following the pattern match-ing path taken in most ?textual entailment?
systems, since the informal rulesused in such systems are not guaranteed to be sound.We use ?property theory?
(Turner, 1987; Chierchia & Turner, 1987) as ourformal language.
There are very strong grounds for believing that naturallanguage is inherently intensional (we will see some examples below, butthe simple presence of verbs of propositional attitude is hard to cope withunless you allow some degree of intensionality).
There are a number oflogics which allow for a degree of intensionality?the typed logic used byMontague (Montague, 1974; Dowty et al, 1981), the notion of non-well-founded sets (Aczel, 1988) used in situation semantics (Barwise & Perry,1983), Bealer (1989)?s intensional logic, and so on.
We choose propertytheory because one of Turner?s axiomatisations draws a very strong analogywith modal logic which in turn suggests ways of adapting standard first-ordertheorem proving techniques for it.
We have developed a theorem prover fora constructive version of property theory along these lines (Ramsay, 1995;Cryan & Ramsay, 1997), and have shown that it is sound (Ramsay, 2001).No theorem prover for a logic with this degree of expressive power can becomplete?property theory, like default logic, is worse than first-order logicin this respect, in that it is not even recursively enumerable.
Practicalsystems for first-order logic, however, do not proceed by enumerating all thetheorems.
They do their best, and if they cannot find an answer within areasonable period of time then they give up.
This the only sensible thing todo, and it is just as sensible when reasoning with more expressive languages.183We do not, however, just want to find out whether the answer to theuser?s question is ?Yes?
or ?No?
.
We would also like to provide them withsome explanation of how we arrived at our conclusion.
It is much better toanswer ?Should I eat pancakes??
with ?No, because pancakes contain eggs,and eating things which contain eggs will make you ill if you are allergicto eggs.?
than just by saying ?No?
.
The user will be more likely to acceptthe system?s answer if it comes with some supporting explanation, and theymay also be able to generalise from the explanation to cover other cases.Where might we get such explanatory material from?
The obvious placeto look is in the trace of the proof that led to the conclusion.
The prooftree contains the facts and rules that the system used in arriving at itsconclusion.
Showing these facts and rules to the user would let them seewhy the system believes that the queried proposition is true or false, andlets them judge the trustworthiness of what the system says.There are two difficult problems to be addressed here.
The first is thatthe proof tree will contain a mixture of things that the user themselvessaid, things are blindingly obvious and things that the system suspects thatthe user might not know.
The explanation should probably concentrate onthings that the user might not have been aware of, so we should be lookingfor items in the proof tree that the system believes the user may not know.In other words, we need an epistemic version of property theory, and weneed to be able to inspect facts and rules to see who has access to them.We will not discuss this further here, except to note that in the concreteexamples below we are not doing this, so that the support for the system?sconclusions currently includes material that the user would actually alreadybe aware of.The second problem is that it is extremely difficult to generate naturallanguage text from arbitrary logical expressions.
We use standard composi-tional techniques to build our logical forms on the basis of the form of theinput text (van Genabith & Crouch, 1997; Konrad et al, 1996).
However,as with virtually any practical theorem prover, we then perform a number oftransformations (Skolemisation, distribution of negation, splitting rules withconjunctive heads) to our logical forms in order to make them amenable tothe theorem prover.
By the time we have done this there is very little hopeof using the compositional semantics in reverse to generate natural languagetext from elements of the proof tree.
There is, in particular, no chance ofusing head-driven generation (Shieber et al, 1990) to produce text from el-ements of the logical form, since this approach requires that the elements ofthe logical form be unifiable with the meanings of lexical items in order todrive the selection and combination of words.
This is just not feasible with184the elements of a proof tree.Where do the facts and rules that appear in the proof tree come from?We clearly have to specify them in advance in some form.
Some of thisinformation comes from the user, in the form of statements about theirconditions, but most of it will have to provided explicitly.We can do this in a variety of ways.
We could try to use some existingresource?WordNet, CYC, some medical ontology.
It turns out that these re-sources, or at least the publicly available ones, lack a great deal of what weneed.
Very few such resources contain the kind of rules you need for answer-ing questions such as the ones in (1).
Lexical resources contain informationabout relations between words.
WordNet, for instance, provides hypersensi-tivity reaction, hypersensitivity, sensitivity, susceptibility, condition, state,attribute, abstraction, entity as hypernyms of ?allergy?
?all perfectly sensi-ble hypernyms, but not all that useful for answering (1a).
Likewise theonly mention of allergy or allergic in the ontology in OpenGalen (version7, downloaded 09/10/08) says that an allergy is a kind of pathology, andSnoMed has ?propensity to adverse reactions?
and disease as hypernyms, anda variety of links to special types of allergies and other related conditions.This is not, of course, an exhaustive search of all potentially relevantontologies, but it does suggest that the kind of information stored in a typicalontology is not what we require for answering our questions.
It is, however,extremely interesting to note that WordNet contains an English gloss for?allergy?
as ?hypersensitivity reaction to a particular allergen; symptoms canvary greatly in intensity?
, OpenGalen contains the text ?Hypersensitivitycaused by exposure to a particular antigen (allergen) resulting in a markedincrease in reactivity to that antigen upon subsequent exposure sometimesresulting in harmful immunologic consequences.?
and SnoMed provides verybrief English glosses.
It seems as though when ontology designers want tosay what a term really means, they resort to natural language.It also seems as though this kind of ontology fails to include ?common-sense?
knowledge, e.g.
that if you are allergic to a foodstuff then you shouldnot eat it.
We need this kind of information in order to answer questions.The prevalence of natural language glosses in ontological resources of thiskind, suggests that expressing it in natural language might be a good idea.Using natural language to express the knowledge that we need has anumber of advantages:?
It is comparatively easy.
Most people (even logicians and semanti-cists!)
generally find it easiest to express themselves in their nativelanguage.
It is much easier to write ?If you are allergic to something185then eating it will make you ill?
than to express the same rule in someformal language.?
Linking knowledge that has been expressed in natural language withfacts and queries that have been expressed in natural language obvi-ates the need for a set of terminological mappings between domainknowledge and natural language.
The vocabularies used in termino-logical databases tend to have a superfical resemblance to words innatural languages, but the mapping is seldom exact, and indeed thetypes associated with such terms are often quite different.
If all yourknowledge is expressed in natural language then this kind of problemcan be avoided.?
Finally, it makes it much easier to generate answers.
If we keep a linkbetween surface text and logic we can retrieve the surface text fromthe proof tree.
This does not entirely solve the problem of producingcoherent natural language answers, but it does make it much simpler.3 English with variablesWe therefore want to try writing down various commonsense rules in English.To make it slightly easier to write rules, we allow variables in various places.Thus we write (2b) rather than (2a).
(2) a.
Eating fruit which contains vitamin C is good for you if you havescurvyb.
Eating fruit which contains vitamin C is good for X if X has scurvyThis is helpful here simply to get around the fact that ?you?
is normallytaken to be a reference to the hearer, whereas in (2a) it is being used in arather generic way.
Rather than allowing ?you?
to be ambiguous in this way,we simply allow variables to be used in natural language.The logical form we obtain for (2b) is shown in Fig.
1.
There are anumber of things to note about Fig.
1:?
It?s enormous.
Reading it you can see how it relates to (2b) itself,but producing something like this by hand would certainly be a majorchallenge.
However, if we have a set of rules that explain the relation-ship between structural (lexical and syntactic) choices and semanticsthen we can obtain Fig.
1 directly from the parse tree of (2b).
This and186?X?Bevent(B ,have)&?C : {scurvy(C , D)}?
(B ,object ,C )&?
(B ,agent ,X )&aspect(now ,simple,B)?
?Estate(E,?F (?Gevent(G,eat)& ?H : {fruit(H , I)& ?Jevent(J ,contain)& ?
(J ,object,ref (?K(vitamin(K )& ?
(K ,type,ref (?L(named(L,C )))))))& ?
(J ,agent ,H )& aspect(now ,simple,J )}?
(G,object ,H )& ?
(G, agent, F )),?M(?N(good(N ,M ,normal))))&for(E ,X )&aspect(now ,simple,E )Figure 1: Logical form for (2b)all other logical forms in this paper were produced by applying compo-sitional rules to the first parse we obtained from the relevant texts.
Soalthough it is indeed enormous, and complicated, all we have to do iswrite the rule in English and the system will take care of the rest.?
The analysis of ?eating fruit which contains vitamin C is good for you?introduces a relationship between two intensional objects, namely ?thekind of event where someone eats fruit which contains vitamin C?
and?the property of being good?.
This has significant consequences for thekind of inference that is required.
We will explore this further below.Once we allow variables in places where you might expect an NP, itbecomes tempting to introduce them in other places.
The consequences ofdoing this are interesting:(3) a.
Eating something will make you ill if you are allergic to itb.
Eating P will make X ill if X is allergic to P187Again the second version of the rule sidesteps some tricky details to dowith pronouns, but the formal paraphrase throws up some awkward issues.
?X?P?Cstate(C ,X , ?D(?E(allergic(E ,D ,normal)))) &to(C ,P)&aspect(now ,simple,C )?
?F : {future(now ,F )}?Bevent(B ,make)&?
(B ,object ,X )&?
(B ,object1 , ?G(?H(ill(H ,G,normal))))&?
(B,agent,?I ?Jevent(J ,eat)&?K : {P : K}?
(J ,object ,K )&?
(J ,agent ,I ))&aspect(F ,simple,B)Figure 2: Logical form for (3b)The new problem in Fig.
2 is the paraphrase of ?eating P will make X ill?
,where ?P?
stands for something like ?something of type P?
.
In other words,P here is a variable noun rather than a variable NP.Under almost any analysis, nouns denote kinds rather than individuals.But that means that (3b) involves quantification over kinds, which is againvery intensional.4 InferenceConstructing LFs which involve relations between intensional entities is notproblematic.
As noted above, we know there are formal languages which al-low for intensionality, so all we have to do is choose one of these for our LFs.Indeed, most approaches to compositionality exploit ?-abstraction and ?-reduction, so the intermediate objects that are constructed are inherently in-tensional anyway.
Anyone who takes the interpretation of ?man in a park?
tobe something like ?A(?B : {park(B , C)}?D(man(D , E) & in(D ,B))&(A :D)) (i.e.
the standard Montague representation) is using an intensionallanguage as an intermediate representation.Problems only arise when we try to reason with representations of thiskind.
There is, however, very little point in making LFs if you are not goingto reason with them, so we do have to worry about it.
To see a concreteexample, reconsider (1c), repeated as (4):188(4) [ User: I have scurvy.Computer: OKUser: Is eating berries good for me?Computer: Yes, because berries contain vitamin C and eating fruit whichcontains vitamin C is good for people who scurvy.Our rule about scurvy says that events of a certain kind are good forpeople who have scurvy.
The description of these events occupies an argu-ment position in the LF, as one of the terms describing the general state ofaffairs that holds if someone has scurvy.In Prolog-based first-order theorem provers, you determine whether youcan use a rule to prove a goal by unifying the arguments of the goal withthe arguments of the consequent of the rule1.
In the current case, this wouldmean unifying the terms describing ?eating fruit which contains vitamin C?-events and ?eating berries?-events.Clearly these descriptions will not unify.
What we have to do is to acceptthat the rule can be used with terms that describe subsets of the classes thatappear in argument positions.We do not want to do this everywhere.
This is a characteristic of the ruleabout the link between vitamin C and scurvy, not a general characteristicof all rules.
When we want to allow for this, we have to say so explicitly.We therefore include a rule which says that the idea that events of somekind are good or bad or safe or .
.
.
for you is ?downward entailing?
: if eatingfruit which contains vitamin C is good for you then eating berries is goodfor you, because the set of ?eating berries?-events is a subset of the set of?eating fruit which contains vitamin C?-events.
This rule is given in Fig.
3.?B?C?D : {?F : {state(B ,F ,E ,for(C ))&(?G(D:G) ?
(F:G))}state(B ,D ,E ,for(C ))Figure 3: Downward entailment for statesFig.
3 says that if events that satisfy the description F satisfy the propertyE for the individual C, then so do all events whose description G entails F .We need a similar rule to say that this kind of relationship is upwardentailing in the third argument?that anything which is good for you, for1Prolog-based theorem proving is a special case of resolution theorem proving.
Ingeneral resolution theorem provers you have to unify some positive literal in one clause witha negative one in another.
For simplicity we will talk in terms of goals and consequents,but the analysis would apply to other resolution-based engines.189instance, is also safe for you.
Rules like these exploit a notion of ?guardedintensionality?, in that they are only applicable when you already know whatproperties you are interested in.
They thus essentially act as schemas forfirst-order rules.
If we only use them backwards, in situations where weknow what properties we are interested in, they can be applied in a fairlycontrolled way, and hence do not introduce wild combinatorial problems.This is not the only kind of intensional rule that we need, but it doescover a substantial number of interesting cases.
The theorem prover de-scribed in (Ramsay, 2001) can cope with more general intensional rules, butguarded rules of this kind can be dealt with more efficiently than generalrules, and they are particularly useful for axiomatising the phenomena thatinterest us.5 Paraphrases and other lexical relationsIt is clear that we need to treat with a variety of relations between everydayterms.
We will return, as an example, to (1b), repeated here as (5).
(5) User: My son is very fat.Computer: OKUser: Should he go swimming.Computer: Yes, because swimming is a form of exercise, and exercise is goodfor people who are overweight.The computer?s answer to the user?s question clearly depends on anunderstanding that if something is good for you then you should do it.To say this is not, of course, to provide a complete characterisation of themeaning of ?should?
.
It is just a piece of commonsense.
Nonetheless, for asystem to be able to cope with (1b) it has to have access to this piece ofcommonsense.
Fig.
4 shows the axiomatisation of this notion: if events ofthe kind described by B are good C, then if I describes an action whoseperformance entailed that B held for C then I should happen.
?B?C?D : {state(D ,B , ?E(?F (good(E ,F ,G))),for(C ))&(?H(I:H )) ?
(B:C ))}?J : {aspect(now ,simple,J )}should(J ,I )Figure 4: If something?s good for you then you should do it190There are a variety of other very basic elements of commonsense whichhave to be captured, and which are not generally included in formal ontolo-gies.
We need to know, for instance, that something cannot be both goodand bad, and that dangerous things are bad, and so on.
Some of these canonly be axiomatised manually, but the aim is to keep things that have tobe encoded manually to a minimum.
As noted earlier, writing axioms inEnglish is generally easier and it also makes them easily available for usein explanations.
Very basic things like the fact that things cannot be bothgood and bad are unlikely to be required for explanations, even if they dotake part in proofs, so the fact that they are unavailable for this purposedoes not matter.Some of these basic relations turn out to be bi-equivalences, or as near tobi-equivalences as makes no difference.
It is extremely difficult, for instance,to articulate any difference between (6a) and (6b).
(6) a. I have an allergy to eggs.b.
I am allergic to eggs.We could take account of this by introducing a pair of implications: ?Xhas an allergy to P if X is allergic to P?
and ?X is allergic to P if X hasan allergy to P?
.
This would work, in the sense that we would be able touse these two constructions interchangeably, but it would slow the inferenceengine down considerably.
The presence of any pair of rules of the formP ?
Q and Q ?
P will inevitably slow any theorem prover down, since anyattempt to prove Q is likely to lead to an attempt to prove P , which will inturn lead to an attempt to prove Q.
It is not difficult to catch simple loopsof this kind, but it is better to avoid them in the first place if possible.We therefore use rules like this as part of the normal-forming pro-cess.
Construction of normal forms generally involves application of bi-equivalences where one side has a form which is particularly well-suited tothe needs of a particular theorem proving algorithm.
In resolution, for in-stance, the rules ?
(P&Q) ?
(?P ?
?Q) and ?
(P ?
Q) ?
(?P&?Q) areused during the construction of the normal form because resolution looksfor matching positive and negative literals, so axioms that can be used toensure that the only negation signs appear at the lowest possible level areuseful.The point of normal-forming, then, is to ensure that bi-equivalences areapplied just once, and in just one direction.
We thus apply bi-equivalenceslike the one between (6a) and (6b) during the construction the constructionof logical forms.
This lets us cope with the fact that natural languages191typically provide a range of ways of saying virtually the same thing withoutincurring the expense of applying rules which potentially lead to loops whenwe are carrying out inferences.There is a complication here.
The system needs to realise that (7a) and(7b) are also the same (and likewise for other variations).
(7) a. I have a severe allergy to eggs.b.
I am severely allergic to eggs.Dealing with this requires considerable care in the design of logical forms.Space precludes a deeper discussion of this issue, but this is something wehave to take care over.6 ConclusionsThe work described here covers very similar ground to work in textual en-tailment (Dagan et al, 2005), in that we want to draw inferences basedon facts and rules expressed in natural language.
Producing logical formsand then using a theorem prover to carry out the required inference leadsto more reliable conclusions, since we can check that the theorem prover issound, and hence we can rely on the conclusions that it draws.
It also leadsto deeper chains of inference, since the pattern matching algorithms gen-erally employed for textual entailment do not lend themselves to repeatedapplication.The approach outlined here does involve a number of risks.
We mightnot be able to express all the knowledge we want in natural language; wemight not be able to produce logical forms from our natural language rules;when we have more rules the theorem prover might not be able to cope.The last of these is the most dangerous.
If there are rules which wecannot express in natural language, or where we cannot convert the naturallanguage into a logical form, we can always express them directly in propertytheory (or property theory with procedural attachment of appropriate, e.g.mathematical, rules (Steels, 1979)).
How long will it take when there arelarge numbers of rules?
The proofs for the examples here take around 0.1sec.
Most of this time is spent investigating intensional rules.
Most of thecommonsense knowledge, however, is represented as Horn clauses.
Indeed itis represented as pure Prolog.
The speed of Prolog programs is not affectedby the number of clauses that are present, so we are confident that addingmore rules will have very little effect on the performance so long as theycan be represented as Horn clauses.
The key issue, then, is how many new192intensional rules we will need.
Only time will tell, but we are hopeful thatwe will retain a reasonable level of performance even when we have a moresubstantial set of rules.
If not, we will just have to make the theorem proverfaster.ReferencesP.
Aczel (1988).
Non-Well-Founded-Sets.
CSLI Publications, Stanford.J.
Barwise & J. Perry (1983).
Situations and Attitudes.
Bradford Books, Cambridge,MA.G.
Bealer (1989).
?Fine-grained type-free intensionality?.
In G. Chierchia, B. H.Partee, & R. Turner (eds.
), Properties, types and meaning: vol I, foundationalissues.
Kluwer Academic Publishers, Dordrecht/Boston/London.G.
Chierchia & R. Turner (1987).
?Semantics and Property Theory?.
Linguisticsand Philosophy 11(3).M.
Cryan & A. M. Ramsay (1997).
?A Normal Form for Property Theory?.
In Pro-ceedings of the 14th International Conference on Automated Deduction (CADE-14), vol.
1249 of Lecture Notes in Artificial Intelligence, pp.
237?251, Berlin.Springer-Verlag.I.
Dagan, et al (2005).
?The PASCAL Recognising Textual Entailment Challenge?.In Proceedings of Pascal Challenge Workshop on Recognizing Textual Entailment.D.
R. Dowty, et al (1981).
Introduction to Montague Semantics.
D. Reidel, Dor-drecht.K.
Konrad, et al (1996).
?An education and research tool for computational se-mantics?.
In Proceedings of the 16th International Conference on ComputationalLinguistics (COLING-96), pp.
1098?1102, Copenhagen.R.
Montague (1974).
?The proper treatment of quantification in ordinary English?.In R. Thomason (ed.
), Formal Philosophy: Selected Papers of Richard Montague,New Haven.
Yale University Press.A.
M. Ramsay (1995).
?A Theorem Prover for an Intensional Logic?.
Journal ofAutomated Reasoning 14:237?255.A.
M. Ramsay (2001).
?Theorem proving for untyped constructive ?-calculus: im-plementation and application?.
Logic Journal of the Interest Group in Pure andApplied Logics 9(1):89?106.A.
M. Ramsay & D. G. Field (2008).
?Speech acts, epistemic planning and Grice?smaxims?.
Logic and Computation 18:431?457.A.
M. Ramsay & H. L. Seville (2001).
?Relevant Answers to WH-questions?.
In 3rdInternational Conference on Inference in Computational Semantics, pp.
73?86,Siena.193S.
M. Shieber, et al (1990).
?Semantic-Head-Driven Generation?.
ComputationalLinguistics 16(1):30?42.L.
Steels (1979).
?Procedural attachment?.
Tech.
rep., MIT.R.
Turner (1987).
?A Theory of Properties?.
Journal of Symbolic Logic 52(2):455?472.J.
van Genabith & R. Crouch (1997).
?How to glue a donkey to an f-structure?.In H. C. Bunt, L. Kievit, R. Muskens, & M. Verlinden (eds.
), 2nd InternationalWorkshop on Computational Semantics, pp.
52?65, University of Tilburg.Appendix: commonsense rules(8) a. eating P will make X ill if X is allergic to P.b.
exercise is good for X if X is overweight.c.
swimming is good for X if exercise is good for X.d.
walking is good for X if exercise is good for X.e.
eating fruit which contains vitamin C is good for X if X has scurvy.f.
X eats P if X eats something which contains P.g.
X is dangerous for Y if X will make Y ill.194
