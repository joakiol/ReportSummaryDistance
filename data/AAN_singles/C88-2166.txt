COMPLEX:  A Computational Lexicon for Natural Language SystemsJuditll KLAVANSIBM Thomas J. Watson Research CenterP.
O.
Box 704Yorktown Heights, NY 10598USAAbstractAlthough every natural language system needsa computational lexicon, each system puts differentamounts and types of information into its lexiconaccording to its individual needs.
However, someof the intonnation eeded across systems is sharedor "identical" information.
This paper presents ourexperienc~" in planning and building COMPLEX, acomputational lexicon designed to be a repositoryof shared lexical information for use by NaturalLanguage Processing (NLP) systems.
We havedrawn primarily on explicit and implicit informa-tion fi'om machlne-readable dictionaries (MRD's)to create a broad coverage l xicon.1.
The Computat ional  Meta -Lex icou\]'here is growing awareness among computa-tional linguists that much of the informationneeded for lexical entries across systems is basicallyshared or "identical" information /lngria 1986,Zaencn 1986/.
An example for verbs is subcategor-ization hffonnation (transitive, intransitive, takes athat-complement), and selectional features (takes ahuman object, selects for inanimate subject); anexample for nouns is gender (female, male).
Itshould be possible for much of this shared informa-tion to be collected into a large "polytheoretical"data base for use by individual systems.
Thislexicon (sometimes called a "recta-lexicon") wouldconsist of the overlapping set of the various attri-butes, features, characteristics, etc., that are necdedby all or most NLP systems.
Each system couldthen consult he repository of infonnation stored inthe central lexicon and extract he informatkm itmight need.
The extracted information could beenhanced by theory-specific and application-specificinformation.
Thus, instead of each system dupli-cating efforts, the computational "recta-lexicon"gathers together lexical information for use by pro-grams, in the same way tlmt traditional dictionariescontain information for use by people.One of the goals of the Lexical Systemsproject at IBM is to desigu and build such alexicon.
We have called the system COMPI~EX(for COMPutational H;.Xicon).
Although this isan ambitious goal, we believe that carefullexicographic, linguistic, and computationalresearch will permit us to represent whatever infor-mation is common to most NLP systems in aneutral representation a d in a uniform data struc-ture so as to be compatible with a range of require-ments of natural language systems.Corollary to the goal of designing andbuilding a data structure containing information fordifferent NLP systems is tile goal of broad cov-erage.
Indeed, until recently, the lexicon was nottile primary focus of most natural anguage proc-essmg (NLP) projects.
\]'he result (with a fewexceptions) has been a proliferation of descriptivelyrich syntactic and semantic analyzers withimpoverished lexieal coverage.
Many NLP systemshave small hand-built lexicons, hand-tailored to theidiosyncrasies of formatting and processing requiredby the system.
Our aim is to extract inh)rmationautomatically or semi-automatically using machine-readable sources, and in this way to achieve broadcoverage.
Currently, our primary resources aremachine readable dictionaries although we haveplans to expand to text corpora in the near future.Initially, we restrict our attention to buildingF.nglish lexicons but there is good evidence thatsome inlbrmation may be transferable to computa-tional lexicons for other languages via bilingual dic-tionaries.2.
ApplicationsThe initial impetus for building a computa-tional lexicon arose from the needs of the CRI-TIQUE text-critiquing system (previously calledEPISTLE, Ileidom et al 1982).
Basic syntacticinformation such as part of speech, subcategori-zation for verbs (e.g.
trans, intrans, complementtaking properties), irregular forms, some inherentsemantic information (such as male, female fornouns), some graphemic, phonological, and stylisticB15features were gathered from a range of (primarily)maelfine-readable sources.
This system (calledUDICT, the ultimate dictionary) is described inByrd 1983 and Byrd et al 1986.
A modifiedversion of the original dictionary is still in use bythat project.Our experience in attempting to build a solidbroad-coverage computational lexicon revealed tous the range of projects potentially in need of sucha lexical resource.
Unfortunately, it also revealedto us a range of problems.
First, the projects: wereceived requests for information from NIA'projects such as the experimental English-to-German machine translation system I,MT/McCord 1988/, the natural language data hasequery project TQA/Damerau et al 1982, Johnson1984/, the kind-types Knowledge Representationsystem KT /Dahlgrcn and McDowell 1986/, andothers.
In fact, the LMT system uses UDICT forlexicon back-up when the LMT lexicon does notcontain or does not analyze an item/McCord andWolff 1987/.
The analyses output from UDICTare compiled into LMT internal format for use byLMT.
This is exactly the use we envision forCOMPLEX.In addition to use by NLP systems, some ofthe information in COMPLEX might be useddirectly by lexicographers to aid in creatinglexicographers' workstations for projects such asdictionary building and machine-assisted trans-lation.
It could also be useful to psycholinguistsseeking lists of words with particnlar lexical proper-ties for test materials.
/Taft mad Forster 1976,Cutler 1983/.
Since COMPLEX is machine read-able, it is a simple matter to extract lists withselected features.Some of the problems that arose as a result ofour experience in attempting to build and provide asolid broad-coverage computational lexicon forNLP projects are discussed in the next section.Most important is the problem of polysemy.
Werealized that until the problem of sense distinctionsis tackled, may computational lexicon will be oflimited usefulness.
The other problem particular tousing machine readable dictionaries is the Mappingproblem, also discussed below.3.
The Polysemy Problem and TheMapping Problem?Each entry in UDICT consists of lists of feaotures and attribute-value pairs.
There is one list foreach part of speech.
For example, the word"claim" has two parts of speech in U1)ICF:1. claim(NOUN SING AXNT IzACTVE TOVSTOREI) (STRUCTURE < * > N)).
elaim(VERl3 PLI.JR TRAN AXNT PRESINF THATCOMP STORED HUMSJCOH,I1UMSJ IIUMF, XPSJ (STRUCTURIE< *>V))In this case, "claim" is morphologically simple sothe STRU(TI'URE value is tim same as the inputword.The polysemy problem arises because of thefact that there is only one list of features ~permittedfor each part of speech.
The question is to decidewhat features to put into the feature bundle.
This isnot a trivial matter but there are several options.One is to put only those features that apply to ~dlsenses of a word, that is, the intersection of the setof features for each sense.
Another would be to listthe un#m of all features for each sense.
Of course,there is the option of representing different sensesof a word, with the corresponding set of features,but then this brings along another more funda-mental problem: what is a sense?Consider a system such as that reported inBoguraev 1986 and 1987 in which sense distinctionsare in fact made.
The grammar developmentsystem, intended for a GPSG-style parser, utilizesthe grammatical codes in the ixmgman Dictionaryof Contemporary English /1978/, henceforthI,I)OCE, as the basis for fisting of feature?valuesets.
llowever, notice that tiffs system is forced toaccept the sense distinctions from I,I)OCE, forbetter or for worse.
Similarly, the projectdescribed in Wilks et al 1987 uses LDOCE defi~nitions as the basis for lexlcal semantic structures.Semantic information is to be extracted from dic-tionary entries in LI)OCE to build sense frames.These structures (with sorne enhancements) are toprovide the basis for knowledge-based parsing.Both project s are pursuing important paths in NLPresearch, and in particular in the use o1' machinereadable dictionaries.
However, each is constrainedby the sense distinctions dictated by  LDOCE.LDOCF, is a small dictionary, so there are manydistinctions omitted.
Furthermore, often importantgrammatical distinctions ate merged for the sake ofFrom now on, the term "features" is used to apply to both features and attribute-value pairs in UDICI'.816space.
As human readers, we may be able todecode such abbreviatkms, but it is doubtful thatcompt~tecs are capable of such interpretation.
Takefor example, the entry tbr the verb "button":but ton  (v)TIt I0; c lot :h ing;  Subj : l{mnan;DO: Movcmble So i id?
go (cm~ae to )  c loae  or fast:err w i thbut tom; :  to  but ton  (up) one 's  sh i r tMy sh i r t  doesn ' t  bot ton  (up) eas i ly?The entry is listed as requiting a human subject, yettlm CXarmple sentence has the surface subject "shirt/'The problem here is that the underlying Agent i~'7~uma~/' but not the surface subject.
Regularaltematkms like this are sometimes capturedhnplicifly ia the definition in the fomt of the parewthcsized ~(cause to)", but this is in no way explicitin the dictionary resource.
A detailed study of thesemantic odes for subject from H)OCE is givet~below.
'Fo sum, there are various solutions lo theproblem of senses, each of them inadequate in oneway or another.
The solution to list only the inter-section of fi~atures (the approach in most ofUDICT) or the solution to list the ration of t'ca~tures (taken for the verbs in IJDICI') does notcapture the fact that difibrent senses et 'a  wordexhibit different syntactic behavior, hnportantinformation is obscured mid omitted .by theseapproach,~s.
On the other band, the solutionchosen b:?
Wilks et al 1987 or by Boguraev 1986and 1987 is to take the sense distinctions providedby LDOCE.
But this then requires a system toadopt LDOCE senses, even when they are ineomopletc or incorrect.
In order to use more than oneMRD, a way te map senses in one dictionary ontosenses in another is required, since sense dis?tinctkms across dictionaries rarely correspond.Altemativdy, one could compose a set of ideal datastructures~ and thcn hunt in various resources,including dk:tionarles, for informatiou which cotn-pletes the required lields.
This is the proposal setforth in Atkins 1987, 2and it is the route we arc cur.-rcntly pursuing although our results arc still tooprellminmy to be reported.4o COIVIt~LEX - The Lexicall SystemsLe?ico~4.~.
CONIPLEX S~nuctureTile previous sections of this paper havedescribed the limitations of UDICT.
With this in.tnind, this section gives the information to be eon~rained in COMPLEX.
Currently, we draw on thefollowing sources: 31. enhanced UDICT (\[mxSys)2.
Brandeis Verb Lexicon3.
defirdfions and grammatical information fi'omI,DOCF,/ix)ngman 1978/,We have, plans to use inlbrmation from:1. definitions, synonyms, and etymologies fromWebster's Seventh/Mcrriam 1963/,2.
taxonomy files created from Webster's Seventh/Merriam 1963/ using techniques reported inChodorow et al 1985,3. synonyms from the Collins Thesaurus /Collins1984/,4.
Collins bilingual dictionaries for English/Italian,English/French, English/Spanisla, andEnglish/German5.
text corporaWe too arc using tile sense distinctions cmLDOCII';, although we are aware of its limitations.
(See also Michiels 1982).
Our system is not hard,,wired into I,I)OCE.
Ccmsider the design fer onesense of the verb "bring":--Lcxicai Systems Analysis(MORPH(INFLECTION(PAST brought)))(PASTPART brought)))(PIION(AXNT))(SYNTACTIC(CONSTRUCTION (MWESTART)))(INHERENT (INF)))(IRREG)))(NUMBER (PLUR)))(SUBCAT (DITRAN)))(NPING)))(NPTOV)))(TRAN)))(TENSE (PRES)))(SYSTEM(STORED))~-Br:mdeis Verb Lexico.I)O D@-PIO-NP IO-DO D0-TONPWe acknowledge the valuable input of Beryl T~ (Sue) Atkins, who was visiting the Lexical Systems Group atH~M during April, 1988.
We also acknowledge input from Beth l.evin.The Brandeis Verb Lexicou was devcJopcd by Jane Grimshaw and Ray JackendoWs, NSF grant numberNSF ~STo81-20403 awarded to Brandeis University.817.--LDOCE:SENSENUM.
I:SGRAMCODES.
DI ( to, for );TI:SUBJCODES.
NONE:SEL RES_SUBJ.
NONE:SEL_RES_DO.
NONE:SEL_RES IO.
NONE:DEF.
to come wlth or lead:Note that there are three distinct data sets.
Each ofthese structures will be described in turn.4.2 Lexieal Systems.In the example above, the Lexical Systemsdata show four feature types: two MORl'Hological,one PHONological, nine SYNTACTIC and oneSYSTEM feature.
Other feature types not shownin this analysis are SEMANTIC, STYLISTIC,and GRAPHEMIC.
The two morphological fea-tures (MORPH) give the irregular inflectionalattribute-value pairs for the past and past participialforms of the verb (PAST brought) and(PASTPART brought).
The next feature isphonological (PHON); AXNT means that theword is accented on the final syllable.
In the caseof "bring" the word is monosyllabic, but in a wordlike ,,"persuade" the AXNT feature distinguishesword initial from word final stress.
Thisphonological feature is needed for somemorphological rules in English2 The next nine fea-tures are syntactic: "bring" can start multi-wordconstructions such as "bring about"(MWESTART); it is an infinitival form (INF), andit is inherently irregular IRREG; its number isPLUR; it subcategorizes as a di-transitiveDITRAN (i.e.
it takes two objects), takes anNPING and NPTOV complement, and that it is atransitive verb; its tense is PRES.
The SYSTEMfeature STORED shows that the word iS stored inour database rather than resulting from analysis byour affixation and compounding rules.The data structure displayed under theLexieal Systems Analysis (LexSys) is based onUDICT.
As shown in the example above for"claim", UDICT data is an tmstructw'ed list of fea-tures and attribute-value pairs, This output is thenstructured into a feature hierarchy according tofeature type.
There are six categories at the toplevel: SYNTACTIC, PHONological,MORPHological, SEMANTIC, STYLISTIC, andGRAPHEMIC.
Features are then listed under partof speech for each category, and there are up to fivelevels of depth.
This has important implicationsfor feature addition, since the system needs toforbid occurrence of certain features under certainnodes.
For example, THATCOMP cannot applyto determiners in English or MALE cannot be aninherent property of verbs in English, although averb could have the contextual property of selectingfor MALE arguments.
The arrangement of thedata in a structure also permits efficient querying.Thu,;, if an application requires only one type offeature, such as phonological or syntactic, thisfeature set is easily extracted from the larger datastructure.4.3 Brandeis Codes for "bring"The Brandeis Codes subcategorize "bring" fordirect object (DO).
Furthermore, if the verb takesa DO with the preposition "to" (Pl0), then it alsotakes an NP.
If an indirect object is present (IO),then so is a DO.
Finally, "bring" will take a DOfollowing by an indirect object introduced by "to";this code is not intended to apply to other uses of"to ".Observe that, like the features for UDICT,Brandeis Codes represent the intersection of subcat~egorization properties of verbs.
There are about900 verbs, 28 features, and 19 prepositions or pre-position types.
The codes characterize someinherent features (such as "Modal"), control proper?ties, and contextual features (such as ACCING"accusative followed by -ing phrase).
Cases wherecombinations of features are required are indicatedin the codes.Note also that there is some overlap of infer-marion between the Lexical Systems analysis andthe Brandeis analysis, such as SUISCAT(TRAN)and DO.
This is a clear example of identical infor-mation in different systems.
By gathering togetherdifferent computational lexicons into one generalrepository, we can both eliminate duplication whentwo systems overlap, and increase coverage whenthey differ.
Of course, we will also need methodsfor resolving disagreements when they arise.4.4LDOCEThe LDOCE data first gives the headwordand part of speech; these two values hold for eachsubsequent sense.
Then entries are broken intosense numbers.
In this example, sense one has thegrammatical codes of "DI" (ditransitive verb usedwith two or more objects) and "T 1" (transitive withone object when used with the prepositions "to"and "for").
There is no subject area, (such as "modeicine", "mathematics", law"), nor are there anyselectional restrictions.
Next follows the definitionand example sentences, which are included for thepurpose of helping the human user.
They are notrelevant to a computational lexicon except as apotential source of implicit information.
(SeeAtkins et al 1986).BIBQuestions were put to us concerning theaccuracy and completeness of the LDOCE codes.We decided to undertake an in-depth study ofselectional restrictions for subject to get some con-crete data on how precise and thorough theI~,IDOCE codes really are.
This study is describedin the next section.5.
Evaluat ing the Semant ic  Codes  inLDOCE5.1 MelhodologySelectional restrictions for verbs specify thatargument(s) of that verb must have particulm'semantic properties, .as opposed to subcategori-zation information which simply tells whether theverb can take a certain number of arguments, orcan occur in a certain syntactic ontext.
Our posi-tion on selectional restrictions is close to that ofJackendoff 1987: "...a selectional restriction ... ispart of the verb's meaning and should be fully inte-grated into the verb's argument structure."
(p.285)Although our computational lexicon is far moresurface-structure oriented than that required by?
Jackendoff, the spirit of the claim still applies.
Wedo not yet have a distinct level of Izxical Concep-tual Structure/Jackendoff 1983, Levin, to appear/.Sclectional restrictions can be as peculiar andvaried as the entire conceptual and semantic systemof a language.
For this reason, we picked "subject"because all sentences require subjects at some level;we picked "human" because all systems eem toagree on the need tor this feature,The machine-readable form of LDOCE isenhanced with a set of codes called "Box Codes".There are ten fields of information in the BoxCodes giving such information as register (e.g.informal), or dialect (e..g. Scottish).
For verbs,three of the fields gwe semantic selectionalrestrictions on the arguments ubject, object, andindirect object.To illustrate, the following are the two linesof codes from LDOCE for the entry "admire";there is one line for each sense in the dictionaryentry.admire  < .
.
.
.
It .
.
.
.
Z<v<Wv4 ; TI>( fo r )<<admire  < .... }I .... Z<v<Wv4;  T I<<The subcategorization information in these codes,such as "TI" for "verb followed by NP" or "Wv4"memfing "occurs in the gerundive for the adjectivalform", is what Boguraev 1986 has used in con-verting intbrmation front LI)OCE to more tradi-tional subcategorization formats.
In addition to thegrammatical codes; there are ten fields for furtherinformation.
These fields are shown between thelirst two '< '  signs in the previous figure.
Eachfield has letter code, or a '.'
for no code.
For verbs,field five gives selectional restrictions on subject,field ten on direct object, and field eight on indirectobject.
In the example above, "I!"
is "lluman",and "Z" is "Unmarked (no semantic restriction).
"The box codes are only available in the machine-readable version of the dictionary.In order to extract a list of verbs fromLI)OCI~ that was truly likely to require humansubjects in all senses, a constraint was imposed.Only those verbs that are marked with an "lI" inposition iive for all senses were considered.
Thistechnique yielded a list of 2323 candidate verbs.Each of the verbs was subjectcd to six testsreflecting observations about what could count as ahuman subject, and observations about syntacticvariations.
Test one was for collective humannouns such as "chorus", "class".
Test two was forhuman actions; this applies to machines uch as"robot" or "computer" which are not necessarilyhumanoid but easily anthropomorphosized, l:ramethree tested human-expression ouns such as"film", "article", in which case the noun usuallyrefers to the person behind the work.
The next testcheeks to see if a singular human subject isrequired.
The fifth test is to check for cases like"button" where human applies to agent role, butthe theme or object can still appear in surfacesubject position.
Finally, we observed that manyof the verbs Ifl)OCE claims select for humansubject actually take any animate subject.
This isparticularly applicable to biologically based activ-ities, such as "gag".
To sum,a.
Co l lec t ive  noun sub jec tb.
t luman-act ion  sub jec tt!
t!
c. tluman express ion  sub jec td.
Ob l igator i l y  s ingu lare.
Causat ive / tnchoat ive  a l te rnat ionf .
An imate sub jec tSimple substitution frame tests wcrc constructed toinsert a properly inflected version of the verb to betested into a set of six representative sentenceframes.
Judgments on grammaticality were storedin a matrix:abcde  fadmire  .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ - + - -car icature  .
.
.
.
.
.
.
.
.
.
+ - + + ~gag  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ - - +\[319Features reflecting the judgment patterns were thengenerated from this matrix.
Only the relewmt fea-tures are shown in the folk)wing figure: 41. admire : (VERB +I tUMSJ  +COLL I IUMSJ )2. caricature: (VEP, B + IIUMS.I+ COLLHUMSJ  + I IUMEXPSJ)3. gag: (VERB +I IUMSJ  +COLLHI,  JMSJ+ ANI MS J)5.2 ResultsThe next figure summarize the results of tilejudgqnents on these verbs/LDOCEBroad 59%Narrow 36%Animate 13%Rejects  28%n=2323Broad = Human, Human Collective,IIuman Expression, Human ActionNarrow = Human, Human CollectiveWe were disappointed that only 59% of these verbsrequired human subjects in all senses.
There maybe several reasons for this: LDOCE is small somany senses are omitted; the "button" type verbswere listed as requiring human subjects; and verbsrequiring animate subjects were listed as requMnghuman subjects.
We suspect hat what may havehappened is that the question was asked of theseverbs "is a human subject possible?"
rather than "isa human subject necessary?
"This data shows that the Box Codes inLDOCI3 have to be carefully re-evaluated beforethey can be used.
llowever, it is not our intentionto witch-hunt in LDOCE.
The dictionary isimmensely useful, particularly since it is based on adetailed and thorough grammatical analysis ofEnglish/Quirk and Greenbaum 1972/.
Rather, ourgoal is to utilize what LDOCE has to offer.
Withthis more positive goal in mind, we took the erieginal list of 2323 verbs which select R)r humansubject fi'om Id)OCE, and used it as the basis toexplore whether the list could be expanded usingother tools we have:developed.
Although ourresults are limited, it must be remembered thatwilhout tim I,DOCE box codes, we w(mld havehad no seed list.6o Using Semantic Codes in LDOCE6.1 MethodologyOur goal in the second study was to use theLDOCF, list of 2323 verbs said to select for humansubject as the basis to discover other verbs whichselect for human subject.
We compared the resultsabove with two other methodologies:I. hnplicit Information in Concept llicrarchies(Taxonymies)2.
Implicit Information from Morphological CluesThe first technique used clues fi'om the defi~nitions themselves.
Chodorow, Byrd, and l leidom1985 devised a methodology to constructtaxonymlc hierarchies based on tile genus tcnns ofdefinitions in Merriam 1963.
Two procedures arebased on tile taxonym files: Sprouting and Fil-tering.
In brief, Sprouting uses concept hierarchiesto add words of a semantically related field to aseed list.
Filtering is a method to enlarge a list ofwords in terms of the heads of their definitions/We had used Filtering in tim past to augment listsof nouns with a given inherent feature, such asI IUMAN.
Ilowever, we had never b6tbre tried tofilter with a list of verbs with a given sclectionalfeature.
If our results were good, we would havesome proof of tim hypothesis that ge,ms termsrellcct certain properties of their correspondingheadwords.
More specifically, we would have evbdeuce that selectional restrictions may be inheritedfi'om hypernyms just as are inherent features.
Ourresults show that this hypothesis i correct.Using the 2323 verbs from LDOCE we ranFilter on our taxonym fles, and extracted 312 can..didate human subject verbs.
Each of these verbsObviously, more detail would be needed to capture tile fact that a verb like ~gag" requires an animate subjectwith a wind-plpe.
Can a virus gag?There is some degree of' error throughout rinse judgments.
What is needed is a large number of diflbrentpeople giving such judgments.
However, I will assume that the errors are equally distributed tlwoughout tiledata, and thus can be assumed for now to be neutralized.
What we have at the very least is a complete andthorough account of at least one person's ideoleclical intuitions on human subject verbs.Filtering was used in later parts of the procedure when we started with small seed lists to be used to labelnouns which were human_collectlve, human_.expressions, etc.
We did not use lilterlng for verbs.820was subjected to the same six tests, and matrices ofproperties were constructed.
Interestingly, sinceMerriam 1963 has more headwords than LDOCE,many of the verbs we obtained from Filtering werequite esoteric.
These verbs are also lesspolysemoos, probably as a result of their being lesscomm(m.For compariso,l and curiosity, we also triedt~sing a more risky method.
Morphology is oftet~ achin to .
';ema*ltie lbatures, both of tim base and ofttm deri,ed word?
Under the assumption that thenonfinalizing ~er suffix in English sometimes marksagentivity, and in order to test the hypothesis thattile verbal bases of these agentive nouns might havea tendency to select tbr human subjects, weextracted about 4000 nouns ending in -er from alarge (100,000+) word list.
Then we sent theserJouns through our morphological analyzer toextract those with verb bases.
Of the over 1000nouns which had verb bases, 712 were not alreadyon the LDOCE fist augmented by Filtering.
Theseverbs were added to the candidate list of possibleverbs selecting tbr human subjects.
Although wcknew that ~slng the multiply ambiguous -er suffixwas more speculative, we decided to follow throughwith our experiment so we could get a measure ofhow usethl the technique is.~o2 Res~IsTim next figure summarize the results of timjudgments on these verbs in comparison with theprevious results:LDOCE FILTER -e~Broad 59% 45% 20%Narz'ow 36% 25% 8%Animate 13% 1,4% 21%R~jects 28% 41% 59%~=2323 n~316 ~=71~B~oad ~:: Ro_~an, ~uman goliectlve~}~.~mt ~xpression, Human ActionNa_~.
',,~ow =~ ~%lmax b Human CollectiveNot snrp~ishlgly, the best source of verbs whichselect re, Human Subject in all senses wast,D()CE.
However, remember that the candidateverbs were supposed to select for Human Subjectin a~t senses, yet only 59% of these verbs reallycon~brmed to that rcqtfirement.
The next resultconcerns lqltedng.
Nearly half of the verbs pro~posed by Filtering were acceptable.
This givessome interesting irtsights into the internal organiz.a,~tim, of Merriam 1983.
It shows that gent, s termsreflect ce~qtain properties of their correspondinghcadwords.
More spedtically, there is some eriedeuce that seh:cfional restrictions may be hfiteritedfrom hypemyms just as are inhe,'ent li:atures.
Aresult like this wonkt be greatly strengthened ifsense distinctions were made, rather thau requh'ingthat the restriction apply to all senses.
Finally, notsmprisingly, the morphological method gave theworst results.
Only 20% of the candidate verbs fir-filled tbur of the six tests.7?
Futm'eThere are many other ways to tap maclfine.~readable sources that we would like to try.
Con-.cerning subjects, we would like to extract data fromtext corpora to confirm (or refute) our intuitions onthe verbs we tested.
We would also like to useexample scr, tcnces to verify hypotheses aboutlexical Ibatures.
As shown above "button", e?amplesentences often contradh:t claims in the Box Codes.l\[nformation about verbs, such as "button", whichpemfit an underlying object to appear as stibjectmight bc implicit in LDOCE.
We are working todevelop a mechanism to enable mitosis when sensedivision is motivated either by semantic or syntacticfacts.
We are also expkn~ing mechatfisms to useseveral dictk)naries to get maximum coverage.
Wcare working on a practical solution to the mappingproblem (see Byrd et al 1987).The COMPLEX system has been imple-mented and incmporated into the WordSmithon-line dictionary system, described in Nell" andByrd 1988, wlfich allows flexible access to diction?
:.tries stored as DAM ~ files and lexical data bases.IJltimately, COMPLEX structures will be placed ina lx~xieal Data Base so they can be queried by theIvxical Query Language /Nell" et al 1988/.
Weintend to expand our data structures as we itlcorpo-rate more and different iulbrmation into ore' lexicalrepositoo,.
The goal is to create a rich cemputaofional lexicon that can be utilized by NLP systems.We are working intensively on a practical solutionto both the polysemy problem and to the mappingproblem as they apply to  the construction ofCOMPLEX.
"/ DAIVt ("Dictionary Access Method") is an access method subsystem which gives programs ~hst and coaven otent access to large files of inlbrmation associated with set.n of keys.tl 2 itBibliographyAtkins, Beryl T. (1987) "Semantic ID tags: CorpusEvidence for Dictionary Senses", in The Uses ofLarge Text Databases, Proceedings of the ThirdAnnual Conference of the UW Centre for the NewOxford English Dictionary, University of Waterloo:Waterloo, Canada.Atkins, Beryl S., Judy Kegl, Beth Levin (1986)"Explicit and Implicit Information in Dictionaries",in Advances in Lexicology.
University of Waterloo:Waterloo, Canada.Boguraev, Branimir (1986) Machine-Readable Dic-tionaries and Research in Computational Lingu&tics,Paper presented at the Workshop on Automatingthe Lexicon, Marina di Grosseto, Italy.Boguraev, Branimir (1987) "Experiences with aMachine-Readable Dictionary" in The Uses ofLarge Text Databases, Proceedings of the ThirdAnnual Conference of the UW Centre for the NewOxford English Dictionary, University of Waterloo:Waterloo, Canada.Byrd, R. J.
(198.3) "Word formation in natural lan-e S" guage processmg syst m., Proceedings ofIJCAI-VIII, 704-706.Byrd, R. J., J. L. Klavans, M. Aronoff, and F.Anshen (1986) "Computer methods formorphological nalysis," Proceedings of the Associ-ation for Computational Linguistics, 120-127.Byrd, Roy J., Nicoletta Calzolari, Martin S.Chodorow, Judith L. Klavans, Mary S. Neff,Omneya A. Rizk (1987) "Tools and Methods forComputational Lexicology," Computational Lin-guistics.Chodorow, M. S., R..1.
Byrd, and G. E. lleidorn(1985) "Extracting Semantic Itierarclfies from aLarge On-line Dictionary," Proceedings of the Asso-ciation for Computational Linguistics, 299-304.Chodorow, Martin, Yael Ravin and lloward E.Sachar (1988) "Investigating the SynonymyRelation in a Sense-Disambiguated Thesaurus"Proceedings of the 2rid Conference on AppliedNatural Language Processing Association for Com-putational Linguistics: Morristown, New Jersey.Collins.
1984 The New Collins Thesaurus.
CollinsPublishers, Glasgow.Cutler, A.
(1983) Lexical Complexity and SentenceProcessing, in G. B. Flores d'Arcais and R.J.Jarvella, eds.
The Process of Language.
Under-standing.
Wiley: New York.Dalflgren, K., and J. McDowell (1986) Kind Typesin Knowledge Representation.
Proceedings ofCOLING86.
Bonn, Germany.Damerau, F. J., S. R. Petrick, M. Pivovonsky, andW.
J. Plath (1982) "Transformational Question-Answering (TQA) System '~, SIGART NewsletterNo.
79:62-64.Ileidorn, G. E., K. Jensen, L. A. Miller, R. J.Byrd, and M. S. Chodorow (1982) "The EPISTLEText-Critiquing System," IBM Systems JournalIngria, Robert (1986) "Lexical Information forParsing Systems: Points of Convergence andDivergence", Paper presented at the Workshop onAutomating the Lexicon, Marina di Grosseto, Italy.Jackendoff, Ray.
(1983) Semantics and Cognition,MIT Press: Cambridge, Massachusetts.Jackendoff, Ray.
(1987) "The Status of ThematicRelations in Linguistic Theory", in LinguisticInquiry, Volume 18:3:369-411.Johnson, David E. (1984) "I)esign of a Robust,Portable Natural Language Interface Grammar"IBM Research Report Number: RC 10867.Levin, I3., to appear, "Approaches to LexicalSemantics Representation," in D. Walker, A.Zampolli, N. Calzolari, eds., Automating theMIT Press, Cambridge, Massachusetts.t~ongrnan (1978) Longman Dictionary of Contempo-rary English, Longman Group, London.MeCord, Michael C. and Susanne Wolff (1987)"The Lexicon and Morphology for LMT, AIh'olog-Based MT System" IBM Research Report,Number: RC 13403McCord, Michael C. (1988) "Design of LMT: Al'rolog-Based Machine Translation System" IBMReport Number: RC 13536Merriam (1963) Websters Seventh New CollegiateDictionary G. & C. Merriam, Springfield,Massachusetts.Michiels, Archibal (1982) Exploiting a Large Dic-tionary Data Base.
PhD Dissertation.
University ofLiege, Liege, Holland.Neff, M. S. and R. J. Byrd (1988) WordSmithUsers Guide.
IBM Research Report Number: RC13411, T..I.
Watson Research Center, YorktownHeights, New York.822Neff, Mary S, Roy J. Byrd, and Omneya R~k(1988) Cleating mad Querying Lexieal Data Bases.Proceding of the Applied Association of Computa-tional Linguistics Austin: Texas.Quirk, Randolph, Sidney Greenbaum, GeoffreyLeech, and Jan Svartik.
(1972) A Grammar ofContemporary English.
Longman: ltarlow andLondon, )\[~ngland.Taft, Marcus and Kenneth I. Forster (1976)Lexical Storage and Retrieval of Polymorphemicand Polysyllabic Words.
Journal of VerbalLearning and Berbal Behavior.
15, pp.
607-620.Wilks, Y, D. Fass, C-M Guo, J.E.
McDonald, T.Plate, and B. M. Slater (1987) A TractableMachine Dictionary as a Resource for Computa-tional Semantics.
Computing Research Labora-tory, New Mexico State University, Las Cruces,New Mexico.Zaencn, Annie (1986) Project Report on theLexical Project.
CSLI Monthly, Volume 1,Number 3.823
