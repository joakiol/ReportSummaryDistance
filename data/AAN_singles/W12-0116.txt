Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 119?128,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsLinguistically-Augmented Bulgarian-to-English Statistical MachineTranslation ModelRui WangLanguage Technology LabDFKI GmbHSaarbru?cken, Germanyruiwang@dfki.dePetya Osenova and Kiril SimovLinguistic Modelling Department, IICTBulgarian Academy of SciencesSofia, Bulgaria{petya,kivs}@bultreebank.orgAbstractIn this paper, we present our linguistically-augmented statistical machine translationmodel from Bulgarian to English, whichcombines a statistical machine translation(SMT) system (as backbone) with deep lin-guistic features (as factors).
The motiva-tion is to take advantages of the robust-ness of the SMT system and the linguis-tic knowledge of morphological analysisand the hand-crafted grammar through sys-tem combination approach.
The prelimi-nary evaluation has shown very promisingresults in terms of BLEU scores (38.85) andthe manual analysis also confirms the highquality of the translation the system deliv-ers.1 IntroductionIn the recent years, machine translation (MT)has achieved significant improvement in termsof translation quality (Koehn, 2010).
Bothdata-driven approaches (e.g., statistical MT(SMT)) and knowledge-based (e.g., rule-basedMT (RBMT)) have achieved comparable resultsshown in the evaluation campaigns (Callison-Burch et al, 2011).
However, according to thehuman evaluation, the final outputs of the MT sys-tems are still far from satisfactory.Fortunately, recent error analysis shows that thetwo trends of the MT approaches tend to be com-plementary to each other, in terms of the typesof the errors they made (Thurmair, 2005; Chen etal., 2009).
Roughly speaking, RBMT systems of-ten have missing lexicon and thus lack of robust-ness, while handling linguistic phenomena requir-ing syntactic information better.
SMT systems, onthe contrary, are in general more robust, but some-times output ungrammatical sentences.In fact, instead of competing with each other,there is also a line of research trying to com-bine the advantages of the two sides using ahybrid framework.
Although many systemscan be put under the umbrella of ?hybrid?
sys-tems, there are various ways to do the combi-nation/integration.
Thurmair (2009) summarizedseveral different architectures of hybrid systemsusing SMT and RBMT systems.
Some widelyused ones are: 1) using an SMT to post-edit theoutputs of an RBMT; 2) selecting the best trans-lations from several hypotheses coming from dif-ferent SMT/RBMT systems; and 3) selecting thebest segments (phrases or words) from differenthypotheses.For the language pair Bulgarian-English, therehas not been much study on it, mainly due to thelack of resources, including corpora, preproces-sors, etc.
There was a system published by Koehnet al (2009), which was trained and tested on theEuropean Union law data, but not on other do-mains like news.
They reported a very high BLEUscore (Papineni et al, 2002) on the Bulgarian-English translation direction (61.3), which in-spired us to further investigate this direction.In this paper, we focus on the Bulgarian-to-English translation and mainly explore the ap-proach of annotating the SMT baseline with lin-guistic features derived from the preprocessingand hand-crafted grammars.
There are three mo-tivations behind our approach: 1) the SMT base-line trained on a decent amount of parallel cor-pora outputs surprisingly good results, in terms ofboth statistical evaluation metrics and preliminarymanual evaluation; 2) the augmented model gives119us more space for experimenting with differentlinguistic features without losing the ?basic?
ro-bustness; 3) the MT system can profit from con-tinued advances in the development of the deepgrammars thereby opening up further integrationpossibilities.The rest of the paper will be organized as fol-lows: Section 2 presents our work on cleaningthe corpora and Section 3 briefly describes thepreprocessing of the data.
Section 4 introducesour factor-based SMT model which allows usto incorporate various linguistic features into anSMT baseline, among which those features com-ing from the MRS are described in Section 5 indetail.
We show our experiments in Section 6 aswell as both automatic and manual evaluation ofthe results.
Section 7 briefly mentions some re-lated work and then we summarize this paper inSection 8.2 Data PreparationIn our experiments we are using the SETIMESparallel corpus, which is part of the OPUS parallelcorpus1.
The data in the corpus was aligned auto-matically.
Thus, we first checked the consistencyof the automatic alignments.
It turned out thatmore than 25% of the sentence alignments werenot correct.
Since SETIMES appeared to be anoisy dataset, our effort was directed into cleaningit as much as possible before the start of the ex-periments.
We first corrected manually more than25.000 sentence alignments.
The the rest of thedata set includes around 135,000 sentences.
Al-together the data set is about 160,000 sentences,when the manually checked part is added.
Thus,two actions were taken:1.
Improving the tokenization of the Bulgar-ian part.
The observations from the man-ual check of the set of 25,000 sentencesshowed systematic errors in the tokenizedtext.
Hence, these cases have been detectedand fixed semi-automatically.2.
Correcting and removing the suspiciousalignments.
Initially, the ratio of the lengthsof the English and Bulgarian sentences wascalculated in the set of the 25,000 manuallyannotated sentences.
As a rule, the Bulgarian1OPUS?an open source parallel corpus,http://opus.lingfil.uu.se/sentences are longer than the English ones.The ratio is 1.34.
Then we calculated the ra-tio for each pair of sentences.
After this, theoptimal interval was manually determined,such that if the ratio for a given pair of sen-tences is within the interval, then we assumethat the pair is a good one.
The interval forthese experiments is set to [0.7; 1.8].
All thepairs with ratio outside of the interval havebeen deleted.
Similarly, we have cleanedEMEA dataset.The size of the resulting datasets are: 151,718sentence pairs for the SETIMES dataset.
Simi-lar approach was undertaken for another datasetfrom OPUS corpus - EMEA.
After the cleaning704,631 sentence pairs were selected from theEMEA dataset.
Thus, the size of the originaldatasets was decreased by 10%.3 Linguistic PreprocessingThe data in SETIMES dataset was analysed on thefollowing levels:?
POS tagging.
POS tagging is performed bya pipe of several modules.
First we applySVM POS tagger which takes as an inputa tokenised text and its output is a taggedtext.
The performance is near 91% accuracy.The SVM POS tagger is implemented us-ing SVMTool (Gimnez and Mrquez, 2004).Then we apply a morphological lexicon anda set of rules.
The lexicon add all the pos-sible tags for the known words.
The rulesreduce the ambiguity for some of the surecases.
The result of this step is a tagged textwith some ambiguities unresolved.
The thirdstep is application of the GTagger (Georgievet al, 2012).
It is trained on an ambigu-ous data and select the most appropriate tagsfrom the suggested ones.
The accuracy of thewhole pipeline is 97.83%.
In this pipelineSVM POS Tagger plays the role of guesserfor the GTagger.?
Lemmatization.
The lemmatization mod-ule is based on the same morphological lexi-con.
From the lexicon we extracted functionswhich convert each wordform into its basicform (as a representative of the lemma).
Thefunctions are defined via two operations on120wordforms: remove and concatenate.
Therules have the following form:if tag = Tag then {remove OldEnd; concatenateNewEnd}where Tag is the tag of the wordform, Old-End is the string which has to be removedfrom the end of the wordform and NewEndis the string which has to be concatenated tothe beginning of the word form in order toproduce the lemma.
The rules are for wordforms in the lexicon.
Less than 2% of thewordforms are ambiguous in the lexicon (butthey are very rare in real texts).
Similar rulesare defined for unknown words.
The accu-racy of the lemmatizer is 95.23%.?
Dependency parsing.
We have trained theMALT Parser on the dependency version ofBulTreeBank2.
We did this work togetherwith Svetoslav Marinov who has experiencein using the MALT Parser and Johan Hallwho is involved in thedevelopment of MaltParser.
The trained model achieves 85.6%labeled parsing accuracy.
It is integrated ina language pipe with the POS tagger and thelemmatizer.After the application of the language pipeline,the result is represented in a table form followingthe CoNLL shared task format3.4 Factor-based SMT ModelOur approach is built on top of the factor-basedSMT model proposed by Koehn and Hoang(2007), as an extension of the traditional phrase-based SMT framework.
Instead of using only theword form of the text, it allows the system to takea vector of factors to represent each token, bothfor the source and target languages.
The vec-tor of factors can be used for different levels oflinguistic annotations, like lemma, part-of-speech(POS), or other linguistic features.
Furthermore,this extension actually allows us to incorporatevarious kinds of features if they can be (somehow)represented as annotations to the tokens.The process is quite similar to supertagging(Bangalore and Joshi, 1999), which assigns ?richdescriptions (supertags) that impose complex2http://www.bultreebank.org/dpbtb/3http://ufal.mff.cuni.cz/conll2009-st/task-description.htmlconstraints in a local context?.
In our case, allthe linguistic features (factors) associated witheach token form a supertag to that token.
Singhand Bandyopadhyay (2010) had a similar ideaof incorporating linguistic features, while theyworked on Manipuri-English bidirectional trans-lation.
Our approach is slightly different from(Birch et al, 2007) and (Hassan et al, 2007), whomainly used the supertags on the target languageside, English.
We primarily experiment with thesource language side, Bulgarian.
This potentiallyhuge feature space provides us with various possi-bilities of using our linguistic resources developedin and out of our project.In particular, we consider the following factorson the source language side (Bulgarian):?
WF - word form is just the original text to-ken.?
LEMMA is the lexical invariant of the orig-inal word form.
We use the lemmatizerdescribed in Section 3, which operates onthe output from the POS tagging.
Thus,the 3rd person, plural, imperfect tense verbform ?varvyaha?
(?walking-were?, They werewalking) is lemmatized as the 1st person,present tense verb ?varvya?.?
POS - part-of-speech of the word.
We usethe positional POS tag set of the BulTree-Bank, where the first letter of the tag indi-cates the POS itself, while the next letters re-fer to semantic and/or morphosyntactic fea-tures, such as: Dm - where ?D?
stands for?adverb?, and ?m?
stand for ?modal?
; Ncmsi- where ?N?
stand for ?noun?, ?c?
means?common?, ?m?
is ?masculine?, ?s?
is ?singu-lar?,and ?i?
is ?indefinite?.?
LING - other linguistic features derived fromthe POS tag in the BulTreeBank tagset (seeabove).In addition to these, we can also incorporatesyntactic structure of the sentence by breakingdown the tree into dependency relations.
For in-stance, a dependency tree can be represented asa set of triples in the form of <parent, relation,child>.
<loves, subject, John> and <loves, ob-ject, Mary> will represent the sentence ?Johnloves Mary?.
Consequently, three additional fac-tors are included for both languages:121?
DEPREL - is the dependency relation be-tween the current word and the parent node.?
HLEMMA is the lemma of the current word?sparent node.?
HPOS is the POS tag of the current word?sparent node.Here is an example of a processed sentence.The sentence is ?spored odita v elektricheskitekompanii politicite zloupotrebyavat s dyrzhavnitepredpriyatiya.?
The glosses for the words inthe Bulgarian sentence are: spored (according)odita (audit-the) v (in) elektricheskite (electrical-the) kompanii (companies) politicite (politicians-the) zloupotrebyavat (abuse) s (with) dyrzhavnite(state-the) predpriyatiya (enterprises).
The trans-lation in the original source is : ?electricity au-dits prove politicians abusing public companies.
?The result from the linguistic processing and theaddition of information about head elements arepresented in the first seven columns of Table 1.We extend the grammatical features to have thesame size.
All the information is concatenated tothe word forms in the text.
In the next section wepresent how we extend this format to incorporatethe MRS analysis.
In the next section we will ex-tend this example to incorporate the MRS analysisof the sentence.5 MRS SupertaggingOur work on Minimal Recursion Semantic anal-ysis of Bulgarian text is inspired by the workon MRS and RMRS (Robust Minimal RecursionSemantic) (see (Copestake, 2003) and (Copes-take, 2007)) and the previous work on transferof dependency analyses into RMRS structures de-scribed in (Spreyer and Frank, 2005) and (Jakobet al, 2010).
In this section we present first a shortoverview of MRS and RMRS.
Then we discussthe new features added on the basis of the RMRSstructures.MRS is introduced as an underspecified se-mantic formalism (Copestake et al, 2005).
It isused to support semantic analyses in the EnglishHPSG grammar ERG (Copestake and Flickinger,2000), but also in other grammar formalisms likeLFG.
The main idea is that the formalism avoidsspelling out the complete set of readings resultingfrom the interaction of scope bearing operatorsand quantifiers, instead providing a single under-specified representation from which the completeset of readings can be constructed.
Here we willpresent only basic definitions from (Copestake etal., 2005).
For more details the cited publicationshould be consulted.
An MRS structure is a tu-ple ?
GT , R, C ?, where GT is the top handle,R is a bag of EPs (elementary predicates) and Cis a bag of handle constraints, such that there isno handle h that outscopes GT .
Each elementarypredication contains exactly four components: (1)a handle which is the label of the EP; (2) a rela-tion; (3) a list of zero or more ordinary variablearguments of the relation; and (4) a list of zero ormore handles corresponding to scopal argumentsof the relation (i.e., holes).
RMRS is introducedas a modification of MRS which to capture the se-mantics resulting from the shallow analysis.
Herethe following assumption is taken into account theshallow processor does not have access to a lexi-con.
Thus it does not have access to arity of therelations in EPs.
Therefore, the representation hasto be underspecified with respect to the numberof arguments of the relations.
The names of rela-tions are constructed on the basis of the lemma foreach wordform in the text and the main argumentfor the relation is specified.
This main argumentcould be of two types: referential index for nounsand event for the other part of speeches.Because in this work we are using only theRMRS relation and the type of the main argumentas features to the translation model, we will skiphere the explanation of the full structure of RMRSstructures and how they are constructed.
Thus, wefirstly do a match between the surface tokens andthe MRS elementary predicates (EPs) and thenextract the following features as extra factors:?
EP - the name of the elementary predicate,which usually indicates an event or an entitysemantically.?
EOV indicates the current EP is either anevent or a reference variable.Notice that we do not take all the informationprovided by the MRS, e.g., we throw away thescopal information and the other arguments of therelations.
This kind of information is not straight-forward to be represented in such ?tagging?-stylemodels, which will be tackled in the future.This information for the example sentence is122WF Lemma POSex Ling DepRel HLemma HPOS EP EoVspored spored R adjunct zloupotrebyavam VP spored r eodita odit Nc npd prepcomp spored R odit n vv v R mod odit Nc v r eelektricheskite elektricheski A pd mod kompaniya Nc elekticheski a ekompanii kompaniya Nc fpi prepcomp v R kompaniya n vpoliticite politik Nc mpd subj zloupotrebyavam Vp politik n vzloupotrebyavat zloupotrebyavam Vp tir3p root - - zloupotrebyavam v es s R indobj zloupotrebyavam Vp s r edyrzhavnite dyrzhaven A pd mod predpriyatie Nc dyrzhaven a epredpriyatiya predpriyatie Nc npi prepcomp s R predpriyatie n vTable 1: The sentence analysis with added head information ?
HLemma and HPOS.represented for each word form in the last twocolumns of Table 1.All these factors encoded within the corpusprovide us with a rich selection of factors for dif-ferent experiments.
Some of them are presentedwithin the next section.
The model of encodingMRS information in the corpus as additional fea-tures does not depend on the actual semantic anal-ysis ?
MRS or RMRS, because both of them pro-vide enough semantic information.6 Experiments6.1 Experiments with the Bulgarian rawcorpusTo run the experiments, we use the phrase-basedtranslation model provided by the open-sourcestatistical machine translation system, Moses4(Koehn et al, 2007).
For training the translationmodel, the parallel corpora (mentioned in Sec-tion 2) were preprocessed with the tokenizer andlowercase converter provided by Moses.
Then theprocedure is quite standard:?
We run GIZA++ (Och and Ney, 2003) for bi-directional word alignment, and then obtainthe lexical translation table and phrase table.?
A tri-gram language model is estimated us-ing the SRILM toolkit (Stolcke, 2002).?
Minimum error rate training (MERT) (Och,2003) is applied to tune the weights for theset of feature weights that maximizes the of-ficial f-score evaluation metric on the devel-opment set.The rest of the parameters we use the defaultsetting provided by Moses.4http://www.statmt.org/moses/We split the corpora into the training set, thedevelopment set and the test set.
For SETIMES,the split is 100,000/500/1,000 and for EMEA, itis 700,000/500/1,000.
For reference, we also runtests on the JRC-Acquis corpus5.
The final resultsunder the standard evaluation metrics are shownin the following table in terms of BLEU (Papineniet al, 2002):Corpora Test Dev Final DropSETIMES?
SETIMES 34.69 37.82 36.49 /EMEA?
EMEA 51.75 54.77 51.62 /SETIMES?
EMEA 13.37 / / 61.5%SETIMES?
JRC-Acquis 7.19 / / 79.3%EMEA?
SETIMES 7.37 / / 85.8%EMEA?
JRC-Acquis 9.21 / / 82.2%Table 2: Results of the baseline SMT system(Bulgarian-English)As we mentioned before, the EMEA corpusis mainly about the description of medicine us-age, and the format is quite fixed.
Therefore, itis not surprising to see high performance on thein-domain test (2nd row in Table 2).
SETIMES,consisting of news articles, is in a less controlledsetting.
The BLEU score is lower6.
The results onthe out-of-domain tests are in general much lowerwith a drop of more than 60% in BLEU score (thelast column).
For the JRC-Acquis corpus, in con-trast to the in-domain scores given by Koehn etal.
(2009) (61.3), the low out-of-domain resultsshows a very similar situation as EMEA.
A briefmanual check of the results indicate that the out-of-domain tests suffer severely from the missing5http://optima.jrc.it/Acquis/6Actually, the BLEU score itself is higher than for mostof the other language pairs http://matrix.statmt.org/.
As the datasets are different, the results are not di-rectly comparable.
Here, we just want to get a rough pic-ture.
Achieving better performance for Bulgarian-to-Englishtranslation than for other language pairs is not the focus ofthe paper.123lexicon, while the in-domain test for the news arti-cles contains more interesting issues to look into.The better translation quality also makes the sys-tem outputs human readable.6.2 Experiments with theLinguistically-Augmented BulgarianCorpusAs we described the factor-based model in Sec-tion 4, we also perform experiments to test theeffectiveness of different linguistic annotations.The different configurations we considered areshown in the first column of Table 3.These models can be roughly grouped intofive categories: word form with linguistic fea-tures; lemma with linguistic features; modelswith dependency features; MRS elementary pred-icates (EP) and the type of the main argument ofthe predicate (EOV); and MRS features withoutword forms.
The setting of the system is mostlythe same as the previous experiment, except for1) increasing the training data from 100,000 to150,000 sentence pairs; 2) specifying the factorsduring training and decoding; and 3) without do-ing MERT7.
We perform the finer-grained modelonly on the SETIMES data, as the language ismore diverse (compared to the other two corpora).The results are shown in Table 3.The first model is served as the baseline here.We show all the n-gram scores besides the finalBLEU, since the some of the differences are verysmall.
In terms of the numbers, POS seems tobe an effective factor, as Model 2 has the highestscore.
Model 3 indicates that linguistic featuresalso improve the performance.
Model 4-6 showthe necessity of including the word form as oneof the factors, in terms of BLEU scores.
Model10 shows significant decrease after incorporatingHLEMMA feature.
This may be due to the datasparsity, as we are actually aligning and translat-ing bi-grams instead of tokens.
This may also in-dicate that increasing the number of factors doesnot guarantee performance enhancement.
Afterreplacing the HLEMMA with HPOS, the result isclose to the others (Model 8).
The experimentswith features from the MRS analyses (Model 11-16) show improvements over the baseline consis-tently and using only the MRS features (Model7This is mainly due to the large amount of computationrequired.
We will perform MERT on the better-performingconfigurations in the future.17-18) also delivers descent results.
In future ex-periments we will consider to include more fea-ture from the MRS analyses.So far, incorporating additional linguisticknowledge has not shown huge improvement interms of statistical evaluation metrics.
However,this does not mean that the translations deliveredare the same.
In order to fully evaluate the system,manual analysis is absolutely necessary.
We arestill far from drawing a conclusion at this point,but the preliminary scores calculated already indi-cate that the system can deliver decent translationquality consistently.6.3 Manual EvaluationWe manually validated the output for all the mod-els mentioned in Table 3.
The guideline in-cludes two aspects of the quality of the transla-tion: Grammaticality and Content.
Grammati-cality can be evaluated solely on the system out-put and Content by comparison with the referencetranslation.
We use a 1-5 score for each aspect asfollows:Grammaticality1.
The translation is not understandable.2.
The evaluator can somehow guess the mean-ing, but cannot fully understand the wholetext.3.
The translation is understandable, but withsome efforts.4.
The translation is quite fluent with some mi-nor mistakes or re-ordering of the words.5.
The translation is perfectly readable andgrammatical.Content1.
The translation is totally different from thereference.2.
About 20% of the content is translated, miss-ing the major content/topic.3.
About 50% of the content is translated, withsome missing parts.4.
About 80% of the content is translated, miss-ing only minor things.5.
All the content is translated.For the missing lexicons or not-translatedCyrillic tokens, we ask the evaluators to score 2124ID Model BLEU 1-gram 2-gram 3-gram 4-gram1 WF 38.61 69.9 44.6 31.5 22.72 WF, POS 38.85 69.9 44.8 31.7 23.03 WF, LEMMA, POS, LING 38.84 69.9 44.7 31.7 23.04 LEMMA 37.22 68.8 43.0 30.1 21.55 LEMMA, POS 37.49 68.9 43.2 30.4 21.86 LEMMA, POS, LING 38.70 69.7 44.6 31.6 22.87 WF, DEPREL 36.87 68.4 42.8 29.9 21.18 WF, DEPREL, HPOS 36.21 67.6 42.1 29.3 20.79 WF, LEMMA, POS, LING, DEPREL 36.97 68.2 42.9 30.0 21.310 WF, LEMMA, POS, LING, DEPREL, HLEMMA 29.57 60.8 34.9 23.0 15.711 WF, POS, EP 38.74 69.8 44.6 31.6 22.912 WF, POS, LING, EP 38.76 69.8 44.6 31.7 22.913 WF, EP, EOV 38.74 69.8 44.6 31.6 22.914 WF, POS, EP, EOV 38.74 69.8 44.6 31.6 22.915 WF, LING, EP, EOV 38.76 69.8 44.6 31.7 22.916 WF, POS, LING, EP, EOV 38.76 69.8 44.6 31.7 22.917 EP, EOV 37.22 68.5 42.9 30.2 21.618 EP, EOV, LING 38.38 69.3 44.2 31.3 22.7Table 3: Results of the factor-based model (Bulgarian-English, SETIMES 150,000)for one Cyrillic token and score 1 for more thanone tokens in the output translation.The results are shown in the following two ta-bles, Table 4 and Table 5, respectively.
The cur-rent results from the manual validation are on thebasis of 150 sentence pairs.
The numbers shownin the tables are the number of sentences given thecorresponding scores.
The ?Total?
column sumsup the scores of all the output sentences by eachmodel.The results show that linguistic and seman-tic analyses definitely improve the quality of thetranslation.
Exploiting the linguistic processingon word level ?
LEMMA, POS and LING ?
pro-duces the best result.
However, the model withonly EP and EOV features also delivers very goodresults, which indicates the effectiveness of theMRS features from the deep hand-crafted gram-mars.
Including more factors (especially the in-formation from the dependency parsing) drops theresults because of the sparseness effect over thedataset, which is consistent with the automaticevaluation BLEU score.
The last two rows areshown for reference.
?Google?
shows the resultsof using the online translation service provided byhttp://translate.google.com/.
Thehigh score (very close to the reference translation)may be because our test data are not excludedfrom their training data.
In future we plan to dothe same evaluation with a larger dataset.The problem with the untranslated Cyrillic to-kens in our view could be solved in most of thecases by providing additional lexical informationfrom a Bulgarian-English lexicon.
Thus, we alsoevaluated the possible impact of such a lexicon ifit had been available.
In order to do this, we sub-stituted each copied Cyrillic token with its trans-lation when there was only one possible transla-tion.
We did such substitutions for 189 sentencepairs.
Then we evaluated the result by classify-ing the translations as acceptable or unacceptable.The number of the acceptable translations are 140in this case.The manual evaluation of the translation mod-els on a bigger scale is in progress.
The current re-sults are promising.
Statistical evaluation metricscan give us a brief overview of the system perfor-mance, but the actual translation quality is muchmore interesting to us, as in many cases, the dif-ferent surface translations can convey exactly thesame meaning in the context.7 Related WorkOur work is also enlightened by another line ofresearch, transfer-based MT models, which areseemingly different but actually very close.
In thissection, before we mention some previous workin this research direction, we firstly introduce thebackground of the development of the deep HPSGgrammars.The MRSes are usually delivered together withthe HPSG analyses of the text.
There already125ID Model 1 2 3 4 5 Total1 WF 20 47 5 32 46 4872 WF, POS 20 48 5 37 40 4793 WF, LEMMA, POS, LING 20 47 6 34 43 4834 LEMMA 15 34 11 46 44 5205 LEMMA, POS 15 38 12 51 34 5016 LEMMA, POS, LING 20 48 5 34 43 4827 WF, DEPREL 32 48 3 29 38 4438 WF, DEPREL, HPOS 45 41 7 23 34 4109 WF, LEMMA, POS, LING, DEPREL 34 47 5 30 34 43310 WF, LEMMA, POS, LING, DEPREL, HLEMMA 101 32 0 8 9 24211 WF, POS, EP 19 49 4 34 44 48512 WF, POS, LING, EP 19 49 3 39 40 48213 WF, EP, EOV 20 49 2 41 38 47814 WF, POS, EP, EOV 19 50 3 31 47 48715 WF, LING, EP, EOV 19 48 5 37 41 48316 WF, POS, LING, EP, EOV 19 49 5 37 40 48017 EP, EOV 15 41 10 44 40 50318 EP, EOV, LING 20 49 7 38 36 47119 GOOGLE 0 2 20 52 76 65220 REFERENCE 0 0 5 51 94 689Table 4: Manual evaluation of the grammaticalityexist quite extensive implemented formal HPSGgrammars for English (Copestake and Flickinger,2000), German (Mu?ller and Kasper, 2000), andJapanese (Siegel, 2000; Siegel and Bender, 2002).HPSG is the underlying theory of the interna-tional initiative LinGO Grammar Matrix (Benderet al, 2002).
At the moment, precise and lin-guistically motivated grammars, customized onthe base of the Grammar Matrix, have been orare being developed for Norwegian, French, Ko-rean, Italian, Modern Greek, Spanish, Portuguese,Chinese, etc.
There also exists a first version ofthe Bulgarian Resource Grammar - BURGER.
Inthe research reported here, we use the linguisticmodeled knowledge from the existing English andBulgarian grammars.
Since the Bulgarian gram-mar has limited coverage on news data, depen-dency parsing has been performed instead.
Then,mapping rules have been defined for the construc-tion of RMRSes.However, the MRS representation is still quiteclose to the syntactic level, which is not fully lan-guage independent.
This requires a transfer at theMRS level, if we want to do translation from thesource language to the target language.
The trans-fer is usually implemented in the form of rewrit-ing rules.
For instance, in the Norwegian LO-GON project (Oepen et al, 2004), the transferrules were hand-written (Bond et al, 2005; Oepenet al, 2007), which included a large amount ofmanual work.
Graham and van Genabith (2008)and Graham et al (2009) explored the automaticrule induction approach in a transfer-based MTsetting involving two lexical functional grammars(LFGs), which was still restricted by the perfor-mance of both the parser and the generator.
Lackof robustness for target side generation is one ofthe main issues, when various ill-formed or frag-mented structures come out after transfer.
Oepenet al (2007) use their generator to generate textfragments instead of full sentences, in order to in-crease the robustness.
We want to make use ofthe grammar resources while keeping the robust-ness, therefore, we experiment with another wayof transfer involving information derived from thegrammars.In our approach, we take an SMT system as our?backbone?
which robustly delivers some trans-lation for any given input.
Then, we augmentSMT with deep linguistic knowledge.
In general,what we are doing is still along the lines of previ-ous work utilizing deep grammars, but we build amore ?light-weighted?
transfer model.8 Conclusion and Future WorkIn this paper, we report our work on build-ing a linguistically-augmented statistical machinetranslation model from Bulgarian to English.126ID Model 1 2 3 4 5 Total1 WF 20 46 5 23 56 4992 WF, POS 20 48 5 24 53 4923 WF, LEMMA, POS, LING 20 47 1 24 58 5034 LEMMA 15 32 5 33 65 5515 LEMMA, POS 15 35 9 32 59 5356 LEMMA, POS, LING 20 48 5 22 55 4947 WF, DEPREL 32 49 4 14 51 4538 WF, DEPREL, HPOS 45 41 2 21 41 4229 WF, LEMMA, POS, LING, DEPREL 34 48 3 20 45 44410 WF, LEMMA, POS, LING, DEPREL, HLEMMA 101 32 0 6 11 24411 WF, POS, EP 19 49 3 20 59 50112 WF, POS, LING, EP 19 50 2 20 59 50013 WF, EP, EOV 19 50 4 16 61 50014 WF, POS, EP, EOV 19 50 2 23 56 49715 WF, LING, EP, EOV 19 48 4 18 61 50416 WF, POS, LING, EP, EOV 19 50 3 24 54 49417 EP, EOV 14 38 7 31 60 53518 EP, EOV, LING 19 49 7 20 55 49319 GOOGLE 1 0 9 42 98 68620 REFERENCE 1 0 5 37 107 699Table 5: Manual evaluation of the contentBased on our observations of the previous ap-proaches on transfer-based MT models, we de-cide to build a hybrid system by combining anSMT system with deep linguistic resources.
Weperform a preliminary evaluation on several con-figurations of the system (with different linguis-tic knowledge).
The high BLEU score shows thehigh quality of the translation delivered by theSMT baseline; and manual analysis confirms theconsistency of the system.There are various aspects we can improve theongoing project: 1) The MRSes are not fully ex-plored yet, since we have only considered the EPand EOV features.
2) We would like to add factorson the target language side (English) as well.
3)The guideline of the manual evaluation needs fur-ther refinement for considering the missing lexi-cons as well as how much of the content is trulyconveyed (Farreu?s et al, 2011).
4) We also needmore experiments to evaluate the robustness ofour approach in terms of out-domain tests.AcknowledgementsThis work was supported by the EuroMatrix-Plus project (IST-231720) funded by the Euro-pean Community under the Seventh FrameworkProgramme for Research and Technological De-velopment.
The authors would like to thank TaniaAvgustinova for fruitful discussions and her help-ful linguistic analysis; and also to Laska Laskova,Stanislava Kancheva and Ivaylo Radev for doingthe human evaluation of the data.ReferencesSrinivas Bangalore and Aravind K. Joshi.
1999.
Supertag-ging: an approach to almost parsing supertagging: an ap-proach to almost parsing supertagging: an approach toalmost parsing.
Computational Linguistics, 25(2), June.Emily M. Bender, Dan Flickinger, and Stephan Oepen.2002.
The grammar Matrix.
An open-source starter-kitfor the rapid development of cross-linguistically consis-tent broad-coverage precision grammar.
In Proceedingsof the Workshop on Grammar Engineering and Evalua-tion at the 19th International Conference on Computa-tional Linguistics, Taipei, Taiwan.Alexandra Birch, Miles Osborne, and Philipp Koehn.
2007.Ccg supertags in factored statistical machine translation.In Proceedings of the Second Workshop on Statistical Ma-chine Translation, pages 9?16, Prague, Czech Republic,June.Francis Bond, Stephan Oepen, Melanie Siegel, Ann Copes-take, and Dan Flickinger.
2005.
Open source machinetranslation with DELPH-IN.
In Proceedings of the Open-Source Machine Translation Workshop at the 10th Ma-chine Translation Summit, pages 15 ?
22, Phuket, Thai-land, September.Chris Callison-Burch, Philipp Koehn, Christof Monz, andOmar F. Zaidan.
2011.
Findings of the 2011 workshopon statistical machine translation.
In Proceedings of the6th Workshop on SMT.Yu Chen, M. Jellinghaus, A. Eisele, Yi Zhang, S. Hunsicker,S.
Theison, Ch.
Federmann, and H. Uszkoreit.
2009.127Combining multi-engine translations with moses.
In Pro-ceedings of the 4th Workshop on SMT.Ann Copestake and Dan Flickinger.
2000.
An open sourcegrammar development environment and broad-coverageenglish grammar using hpsg.
In Proceedings of the 2ndInternational Conference on Language Resources andEvaluation, Athens, Greece.Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan Sag.2005.
Minimal recursion semantics: An introduction.Research on Language & Computation, 3(4):281?332.Ann Copestake.
2003.
Robust minimal recursion semantics(working paper).Ann Copestake.
2007.
Applying robust semantics.
In Pro-ceedings of the 10th Conference of the Pacific Assocationfor Computational Linguistics (PACLING), pages 1?12.Mireia Farreu?s, Marta R. Costa-jussa`, and Maja Popovic?Morse.
2011.
Study and correlation analysis of linguis-tic, perceptual and automatic machine translation evalu-ations.
Journal of the American Society for InformationSciences and Technology, 63(1):174?184, October.Georgi Georgiev, Valentin Zhikov, Petya Osenova, KirilSimov, and Preslav Nakov.
2012.
Feature-rich part-of-speech tagging for morphologically complex languages:Application to bulgarian.
In Proceedings of EACL 2012.MIT Press, Cambridge, MA, USA.Jess Gimnez and Llus Mrquez.
2004.
Svmtool: A generalpos tagger generator based on support vector machines.In Proceedings of the 4th LREC.Yvette Graham and Josef van Genabith.
2008.
Packed rulesfor automatic transfer-rule induction.
In Proceedings ofthe European Association of Machine Translation Con-ference (EAMT 2008), pages 57?65, Hamburg, Germany,September.Yvette Graham, Anton Bryl, and Josef van Genabith.
2009.F-structure transfer-based statistical machine translation.In Proceedings of the Lexical Functional Grammar Con-ference, pages 317?328, Cambridge, UK.
CSLI Publica-tions, Stanford University, USA.Hany Hassan, Khalil Sima?an, and Andy Way.
2007.
Su-pertagged phrase-based statistical machine translation.
InProceedings of ACL, Prague, Czech Republic, June.Max Jakob, Marke?ta Lopatkova?, and Valia Kordoni.
2010.Mapping between dependency structures and composi-tional semantic representations.
In Proceedings of the7th International Conference on Language Resources andEvaluation (LREC 2010), pages 2491?2497.Philipp Koehn and Hieu Hoang.
2007.
Factored translationmodels.
In Proceedings of EMNLP.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Constantin,and Evan Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedings of ACL(demo session).Philipp Koehn, Alexandra Birch, and Ralf Steinberger.2009.
462 machine translation systems for europe.
InProceedings of MT Summit XII.Philipp Koehn.
2010.
Statistical Machine Translation.Cambridge University Press, January.Stefan Mu?ller and Walter Kasper.
2000.
HPSG analy-sis of German.
In Wolfgang Wahlster, editor, Verbmo-bil.
Foundations of Speech-to-Speech Translation, pages238 ?
253.
Springer, Berlin, Germany, artificial intelli-gence edition.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment models.Computational Linguistics, 29(1).Franz Josef Och.
2003.
Minimum error rate training in sta-tistical machine translation.
In Proceedings of ACL.Stephan Oepen, Helge Dyvik, Jan Tore L?nning, Erik Vell-dal, Dorothee Beermann, John Carroll, Dan Flickinger,Lars Hellan, Janne Bondi Johannessen, Paul Meurer,Torbj?rn Nordga?rd, , and Victoria Rose?n.
2004.
Som a?kapp-ete med trollet?
towards MRS-based norwegian toenglish machine translation.
In Proceedings of the 10thInternational Conference on Theoretical and Method-ological Issues in Machine Translation, Baltimore, MD.Stephan Oepen, Erik Velldal, Jan Tore L?nning, PaulMeurer, Victoria Rose?n, and Dan Flickinger.
2007.
To-wards hybrid quality-oriented machine translation ?
onlinguistics and probabilities in MT.
In Proceedings of the11th Conference on Theoretical and Methodological Is-sues in Machine Translation (TMI-07), Skovde, Sweden.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2002.
Bleu: a method for automatic evaluation ofmachine translation.
In Proceedings of ACL.Melanie Siegel and Emily M. Bender.
2002.
Efficientdeep processing of japanese.
In Proceedings of the 19thInternational Conference on Computational Linguistics,Taipei, Taiwan.Melanie Siegel.
2000.
HPSG analysis of Japanese.
In Wolf-gang Wahlster, editor, Verbmobil.
Foundations of Speech-to-Speech Translation, pages 265 ?
280.
Springer, Berlin,Germany, artificial intelligence edition.Thoudam Doren Singh and Sivaji Bandyopadhyay.
2010.Manipuri-english bidirectional statistical machine trans-lation systems using morphology and dependency rela-tions.
In Proceedings of the Fourth Workshop on Syn-tax and Structure in Statistical Translation, pages 83?91,Beijing, China, August.Kathrin Spreyer and Anette Frank.
2005.
Projecting RMRSfrom TIGER Dependencies.
In Proceedings of the HPSG2005 Conference, pages 354?363, Lisbon, Portugal.Andreas Stolcke.
2002.
Srilm ?
an extensible languagemodeling toolkit.
In Proceedings of the InternationalConference on Spoken Language Processing, volume 2.Gregor Thurmair.
2005.
Hybrid architectures for machinetranslation systems.
Language Resources and Evalua-tion, 39(1).Gregor Thurmair.
2009.
Comparing different architecturesof hybrid machine translation systems.
In Proceedings ofMT Summit XII.128
