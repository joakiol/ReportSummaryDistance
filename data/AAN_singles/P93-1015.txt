Parsing Free Word Order Languages in thePaninian FrameworkAkshar  BharatiRajeev SangalDepar tment  of  Computer  Sc ience  and  Eng ineer ingInd ian  Ins t i tu te  of  Techno logy  KanpurKanpur  208016 Ind iaIn ternet :  sanga l@i i tk .e rnet .
inAbst ractThere is a need to develop a suitable computationalgrammar formalism for free word order languagesfor two reasons: First, a suitably designed formal-ism is likely to be more efficient.
Second, such aformalism is also likely to be linguistically more ele-gant and satisfying.
In this paper, we describe sucha formalism, called the Paninian framework, thathas been successfully applied to Indian languages.This paper shows that the Paninian frameworkapplied to modern Indian languages gives an elegantaccount of the relation between surface form (vib-hakti) and semantic (karaka) roles.
The mappingis elegant and compact.
The same basic accountalso explains active-passives and complex sentences.This suggests that the solution is not just adhoc buthas a deeper underlying unity.A constraint based parser is described for theframework.
The constraints problem reduces to bi-part ite graph matching problem because of the na-ture of constraints.
Efficient solutions are knownfor these problems.It is interesting to observe that such a parser (de-signed for free word order languages) compares wellin asymptotic time complexity with the parser forcontext free grammars (CFGs) which are basicallydesigned for positional anguages.1 In t roduct ionA major i ty of human languages including Indianand other languages have relatively free word or-der.
tn free word order languages, order of wordscontains only secondary information such as em-phasis etc.
Pr imary information relating to 'gross'meaning (e.g., one that includes semantic relation-ships) is contained elsewhere.
Most existing compu-tational grammars are based on context free gram-mars which are basically positional grammars.
Itis important to develop a suitable computationalgrammar formalism for free word order languagesfor two reasons:1.
A suitably designed formalism will be more ef-ficient because it will be able to make use ofprimary sources of information directly.2.
Such a formalism is also likely to be linguisti-cally more elegant and satisfying.
Since it willbe able to relate to pr imary sources of informa-tion, the grammar is likely to be more econom-ical and easier to write.In this paper, we describe such a formalism, calledthe Paninian framework, that has been successfullyapplied to Indian languages.
1 It uses the notionof karaka relations between verbs and nouns in asentence.
The notion of karaka relations is cen-tral to the Paninian model.
The karaka relationsare syntactico-semantic (or semantico-syntactic) re-lations between the verbals and other related con-stituents in a sentence.
They by themselves donot give the semantics.
Instead they specify re-lations which mediate between vibhakti  of nom-inals and verb forms on one hand and semanticrelations on the other (Kiparsky, 1982) (Cardona(1976), (1988)).
See Fig.
1.
Two of the impor-tant karakas are karta karaka and karma karaka.Frequently, the karta karaka maps to agent thetarole, and the karma to theme or goal theta role.Here we will not argue for the linguistic significanceof karaka relations and differences with theta rela-tions, as that has been done elsewhere (Bharati  etal.
(1990) and (1992)).
In summary, karta karakais that part ic ipant in the action that is most inde-pendent.
At times, it turns out to be the agent.But that need not be so.
Thus, 'boy'  and 'key' arerespectively the karta karakas in the following sen-tences1The Paninian framework was originally designed morethan two millennia go for writing a grammar of Sanskrit;it has been adapted by us to deal with modern Indianlanguages.105--- semantic level (what the speakerl has in mind)--- karaka levelI--- vibhakti levelI--- surface level (uttered sentence)Fig.
I: Levels in the Paninian modelThe boy opened the lock.The key opened the lock.Note that in the first sentence, the karta (boy) mapsto agent heta role, while in the second, karta (key)maps to instrument theta role.As part of this framework, a mapping is specifiedbetween karaka relations and vibhakti (which covers A.
2collectively case endings, post-positional markers,etc.).
This mapping between karakas and vibhaktidepends on the verb and its tense aspect modality(TAM) label.
The mapping is represented by twostructures: default karaka charts and karaka charttransformations.
The default karaka chart for a verbor a class of verbs gives the mapping for the TAM la-bel tA_hE called basic.
It specifies the vibhakti per-mitted for the applicable karaka relations for a verbwhen the verb has the basic TAM label.
This basicTAM label roughly corresponds to present indefinitetense and is purely syntactic in nature.
For other B.
1TAM labels there are karaka chart transformationrules.
Thus, for a given verb with some TAM la-bel, appropriate karaka chart can be obtained usingits basic karaka chart and the transformation rule B.2depending on its TAM label.
2In Hindi for instance, the basic TAM label istA_hE (which roughly stands for the present indef-inite).
The default karaka chart for three of the B.3karakas is given in Fig.
2.
This explains the vibhak-tis in sentences A.1 to A.2.
In A.1 and A.2, 'Ram'is karta and 'Mohan' is karma, because of their vib-hakti markers ?
and ko, respectively.
3 (Note that B.4'rAma' is followed by ?
or empty postposition, and'mohana' by 'ko' postposition.
)A.I rAma mohana ko pltatA hE.2The transformation rules are a device to represent thekaraka charts more compactly.
However, as is obvious, theyaffect he karaka charts and not the parse structure.
There-fore, they are different from transformational granmlars.Formally, these rules can be eliminated by having separatekaraka charts for each TAM label.
But one would miss theliguistic generalization f relating the karaka charts based onTAM labels in a systematic manner.3In the present examples karta and karma tm'n out to beagent and theme, respectively.KARAKA VIBHAKTI PRESENCEKarta ?
mandatoryKarma ko or ?
mandatoryKarana se or optionaldvArAFig.
2: A default karaka ChartTAM LABEL TRANSFORMEDVIBHAKTI FOR KARTAyA nenA_padA koyA_gayA se or dvArA (and karta isoptional)Fig.
3: Transformation rulesRam Mohan -ko beats is(Ram beats Mohan.
)mohana ko rAma pItatA hE.Mohan -ko Ram beats is(Ram beats Mohan.)Fig.
3 gives some transformation rules for thedefault mapping for Hindi.
It explains the vibhaktiin sentences B.1 to B.4, where Ram is the karta buthas different vibhaktis, ?, he, ko, se, respectively.In each of the sentences, if we transform the karakachart of Fig.2 by the transformation rules of Fig.3,we get the desired vibhakti for the karta Ram.rAma Pala ko KAtA hE.Ram fruit -ko eats is(Ram eats the fruit.
)rAma ne Pala KAyA.Ram -ne fruit ate(Ram ate the fruit.
)rAma ko Pala KAnA padA.Ram -ko fruit eat had to(Ram had to eat the fruit.
)rAma se Pala nahI KAyA gayARam -se fruit not eat could(Ram could not eat the fruit.
)In general, the transformations affect not onlythe vibhakti of karta but also that of other karakas.They also 'delete' karaka roles at times, that is, the'deleted' karaka roles must not occur in the sen-tence.The Paninian framework is similar to the broadclass of case based grammars.
What distinguishesthe Paninian framework is the use of karaka re-lations rather than theta roles, and the neat de-pendence of the karaka vibhakti mapping on TAMs106and the transformation rules, in case of Indian lan-guages.
The same principle also solves the problemof karaka assignment for complex sentences (Dis-cussed later in Sec.
3.
)2 Constraint  Based ParsingThe Paninian theory outlined above can be usedfor building a parser.
First stage of the parser takescare of morphology.
For each word in the inputsentence, a dictionary or a lexicon is looked up, andassociated grammatical information is retrieved.
Inthe next stage local word grouping takes place, inwhich based on local information certain words aregrouped together yielding noun groups and verbgroups.
These are the word groups at the vibhaktilevel (i.e., typically each word group is a noun orverb with its vibhakti, TAM label, etc.).
These in-volve grouping post-positional markers with nouns,auxiliaries with main verbs etc.
Rules for local wordgrouping are given by finite state machines.
Finally,the karaka relations among the elements are identi-fied in the last stage called the core parser.Morphological analyzer and local word grouperhave been described elsewhere (Bharati et al, 1991).Here we discuss the core parser.
Given the localword groups in a sentence, the task of the coreparser is two-fold:1.
To identify karaka relations among wordgroups, and2.
To identify senses of words.The first task requires karaka charts and transfor-mation rules.
The second task requires lakshancharts for nouns and verbs (explained at the endof the section).A data structure corresponding to karaka chartstores information about karaka-vibhakti mappingincluding optionality of karakas.
Initially, the de-fault karaka chart is loaded into it for a given verbgroup in the sentence.
Transformations are per-formed based on the TAM label.
There is a sep-arate data structure for the karaka chart for eachverb group in the sentence being processed.
Eachrow is called a karaka restricl ion in a karaka chart.For a given sentence after the word groups havebeen formed, karaka charts for the verb groupsare created and each of the noun groups is testedagainst he karaka restrictions in each karaka chart.When testing a noun group against a karaka re-striction of a verb group, vibhakti information ischecked, and if found satisfactory, the noun groupbecomes a candidate for the karaka of the verbgroup.The above can be shown in the form of a con-straint graph.
Nodes of the graph are the wordbaccA hATa se kelA KAtA hEFig.
4: Constraint graphgroups and there is an arc labeled by a karaka froma verb group to a noun group, if the noun groupsatisfies the karaka restriction in the karaka chartof the verb group.
(There is an arc from one verbgroup to another, if the karaka chart of the formershows that it takes a sentential or verbal karaka.
)The verb groups are called demand groups as theymake demands about their karakas, and the noungroups are called source groups because they sat-isfy demands.As an example, consider a sentence containing theverb KA (eat):baccA hATa se kelA KAtA hE.child hand -se banana eats(The child eats the banana with his hand.
)Its word groups are marked and KA (eat) has thesame karaka chart as in Fig.
2.
Its constraint graphis shown in Fig.
4.A parse is a sub-graph of the constraint graphsatisfying the following conditions:1.
For each of the mandatory karakas in a karakachart for each demand group, there should beexactly one out-going edge from the demandgroup labeled by the karaka.2.
For each of the optional karakas in a karakachart for each demand group, there should beat most one outgoing edge from the demandgroup labeled by the karaka.3.
There should be exactly one incoming arc intoeach source group.If several sub-graphs of a constraint graph satisfythe above conditions, it means that there are multi-ple parses and the sentence is ambiguous.
If no sub-graph satisfies the above constraints, the sentencedoes not have a parse, and is probably ill-formed.There are similarities with dependency grammarshere because such constraint graphs are also pro-duced by dependency grammars (Covington, 1990)(Kashket, 1986).107It differs from them in two ways.
First, thePaninian framework uses the linguistic insight re-garding karaka relations to identify relations be-tween constituents in a sentence.
Second, the con-straints are sufficiently restricted that they reduceto well known bipartite graph matching problemsfor which efficient solutions are known.
We discussthe latter aspect next.If karaka charts contain only mandatory karakas,the constraint solver can be reduced to finding amatching in a bipartite graph.
4 Here is whatneeds to be done for a given sentence.
(Perraju,1992).
For every source word group create a nodebelonging to a set U; for every karaka in the karakachart of every verb group, create a node belongingto set V; and for every edge in the constraint graph,create an edge in E from a node in V to a node inU as follows: if there is an edge labeled in karakak in the constraint graph from a demand node dto a source node s, create an edge in E in the bi-partite graph from the node corresponding to (d,k) in V to the node corresponding to s in U. Theoriginal problem of finding a solution parse in theconstraint graph now reduces to finding a completematching in the bipartite graph {U,V,E} that coversall the nodes in U and V. 5 It has several known effi-cient algorithms.
The time complexity of augment-ing path algorithm is O (rain (IV\], \[U\]).
\]ED whichin the worst case is O(n 3) where n is the numberof word groups in the sentence being parsed.
(SeePapadimitrou et al (1982), ihu ja  et al (1993).
)The fastest known algorithm has asymptotic orn-of O (IV\[ 1/2 .
\[E\[) and is based on max flow\] %plexity\]problem (Hopcroft and Sarp (1973)).If we permit optional karakas, the problem stillhas an efficient solution.
It now reduces to findinga matching which has the maximal weight in theweighted matching problem.
To perform the reduc-tion, we need to form a weighted bipartite graph.We first form a bipartite graph exactly as before.Next the edges are weighted by assigning a weightof 1 if the edge is from a node in V representinga mandatory karaka and 0 if optional karaka.
Theproblem now is to find the largest maximal match-ing (or assignment) that has the maximum weight(called the maximum bipartite matching problem orassignment problem).
The resulting matching rep-resents a valid parse if the matching covers all nodesin U and covers those nodes in V that are for manda-tory karakas.
(The maximal weight condition en-4 We are indebted to Sonmath Biswas for suggesting theconnection.5A matching in a bipartite graph {U,V,E)is a subgraphwith a subset of E such that no two edges are adjacent.
Acomplete matching isalso a largest maximal matching (Deo,197"4).sures that all edges from nodes in V representingmandatory karakas are selected first, if possible.
)This problem has a known solution by the Hun-garian method of time complexity O(n 3) arithmeticoperations (Kuhn, 1955).Note that in the above theory we have madethe following assumptions: (a) Each word groupis uniquely identifiable before the core parser ex-ecutes, (b) Each demand word has only one karakachart, and (c) There are no ambiguities betweensource word and demand word.
Empirical data forIndian languages shows that, conditions (a) and (b)hold.
Condition (c), however, does not always holdfor certain Indian languages, as shown by a cor-pus.
Even though there are many exceptions forthis condition, they still produce only a small num-ber of such ambiguities or clashes.
Therefore, foreach possible demand group and source group clash,a new constraint graph can be produced and solved,leaving the polynomial time complexity unchanged.The core parser also disambiguates word senses.This requires the preparation of lakshan charts (ordiscrimination ets) for nouns and verbs.
A lak-shan chart for a verb allows us to identify the senseof the verb in a sentence given its parse.
Lakshancharts make use of the karakas of the verb in thesentence, for determining the verb sense.
Similarlyfor the nouns.
It should be noted (without discus-sion) that (a) disambiguation of senses is done onlyafter karaka assignment is over, and (b) only thosesenses are disambiguated which are necessary fortranslationThe key point here is that since sense disambigua-tion is done separately after the karaka assignmentis over it leads to an efficient system.
If this were notdone the parsing problem would be NP-complete(as shown by Barton et al (1987) if agreement andsense ambiguity interact, they make the problemNP-complete).3 Act ive-Pass ives  and Com-plex SentencesThis theory captures the linguistic intuition that infree word order languages, vibhakti (case endings orpost-positions etc.)
plays a key role in determiningkaraka roles.
To show that the above, though neat,is not just an adhoc mechanism that explains theisolated phenomena of semantic roles mapping tovibhaktis, we discuss two other phenomena: active-passive and control.No separate theory is needed to explain active-passives.
Active and passive turn out to be specialcases of certain TAM labels, namely those used tomark active and passive.
Again consider for exam-ple in Hindi.108F.I rAma mohana ko pItatA hE.
(active)Ram Mohan -ko beat pres.
(Ram beats Mohan.
)F.2 rAma dvArA mohana ko pItA gayA.
(passv.
)Ram by Mohan -ko beaten was(Mohan was beaten by Ram.
)Verb in F.2 has TAM label as yA_gayA.
Conse-quently, the vibhakti 'dvArA' for karta (Ram) fol-lows from the transformation already given earlierin Fig.
3.A major support for the theory comes from com-plex sentences, that is, sentences containing morethan one verb group.
We first introduce the prob-lem and then describe how the theory provides ananswer.
Consider the ttindi sentences G.1, G.2 andG.3.In G.1, Ram is the karta of both the verbs: KA(eat) and bulA (call).
However, it occurs only once.The problem is to identify which verb will controlits vibhakti.
In G.2, karta Ram and the karmaPala (fruit) both are shared by the two verbs kAta(cut) and KA (eat).
In G.3, the karta 'usa' (he) isshared between the two verbs, and 'cAkU' (knife)the karma karaka of 'le' (take) is the karana (instru-mental) karaka of 'kAta' (cut).G.I rAma Pala KAkara mohana ko bulAtA hE.Ram fruit having-eaten Mohan -ko calls(Having eaten fruit, Ram calls Mohan.
)G.2 rAma ne Pala kAtakara KAyA.Ram ne fruit having-cut ate(Ram ate having cut the fruit.
)G.3 Pala kAtane ke liye usane cAkU liyA.fruit to-cut for he-ne knife took(To cut fruit, he took a knife.
)The observation that the matrix verb, i.e., mainverb rather than the intermediate verb controls thevibhakti of the shared nominal is true in the abovesentences, as explained below.
The theory we willoutline to elaborate on this theme will have twoparts.
The first part gives the karaka to vibhaktimapping as usual, the second part identifies haredkarakas.The first part is in terms of the karaka vibhaktimapping described earlier.
Because the interme-diate verbs have their own TAM labels, they arehandled by exactly the same mechanism.
For ex-ample, kara is the TAM label 6 of the intermedi-ate verb groups in G.1 and G.2 (KA (eat) in G.1and kAta (cut) in G.2), and nA 7 is the TAM label6,kara, TAM label roughly means 'having completed theactivity'.
But note that TAM labels are purely syntactic,hence the meaning isnot required by the system.ZThis is the verbal noun.TAM LABEL TRANSFORMATIONkara Karta mustnot be present.
Karma isoptional.nA Karta and karma are op-tional.tA_huA Karta mustnot be present.
Karma isoptional.Fig.
5: More transformation rulesof the intermediate verb (kAta (cut)) in G.3.
Asusual, these TAM labels have transformation rulesthat operate and modify the default karaka chart.In particular, the transformation rules for the twoTAM labels (kara and nA) are given in Fig.
5.
Thetransformation rule with kara in Fig.
5 says thatkarta of the verb with TAM label kara must not bepresent in the sentence and the karma is optionallypresent.By these rules, the intermediate v rb KA (eat) inG.1 and kAta (cut) in G.2 do not have (indepen-dent) karta karaka present in the sentence.
Ram isthe karta of the main verb.
Pala (fruit) is the karmaof the intermediate v rb (KA) in G.1 but not in G.2(kAta).
In the latter, Pala is the karma of the mainverb.
All these are accommodated by the abovetransformation rule for 'kara'.
The tree structuresproduced are shown in Fig.
6 (ignore dotted linesfor now) where a child node of a parent expresses akaraka relation or a verb-verb relation.In the second part, there are rules for obtainingthe shared karakas.
Karta of the intermediate verbKA in G.1 can be obtained by a sharing rule of thekind given by S1.Ru le  SI:  Karta of a verb with TAM label 'kara' isthe same as the karta of the verb it modifies .The sharing rule(s) are applied after the tentativekaraka assignment (using karaka to vibhakti map-ping) is over.
The shared karakas are shown bydotted lines in Fig.
6.4 Conc lus ion  and future  workIn summary, this paper makes everal contributions:?
It shows that the Paninian framework appliedto modern Indian languages gives an elegantaccount of the relation between vibhakti andkaraka roles.
The mapping is elegant and com-pact.8The modified verb in the present sentences is the mainverb.109bulA (call) kar/ ~arma~rec derAma mohana KA (eat)karta.~5 ~armarAma Pala(~ruit)KA (eat)rAma Pala kAta (cut)( f ru i t )karta .
karmarAma Palale (take)kar t /~arma~~urpos  evaha cAkU kAta (cut)(he) (knife) /akarta rmaU-aha Pala(he) (fruit)?
karana(knife)Fig.
6: Modifier-modified relations for sentencesG.1, G.2 and G.3,respectively.
(Shared karakasshown by dotted lines.)?
The same basic account also explains active-passives and complex sentences in these lan-guages.
This suggest hat the solution is notjust adhoc but has a deeper underlying unity.?
It shows how a constraint based parser can bebuilt using the framework.
The constraintsproblem reduces to bipartite graph matchingproblem because of the nature of constraints.Efficient solutions are known for these prob-lems.It is interesting to observe that such a parser(designed for free word order languages) com-pares well in asymptotic time complexity withthe parser for context free grammars (CFGs)which are basically designed for positional lan-guages.A parser for Indian languages based on thePaninian theory is operational s part of a machinetranslation system.As part of our future work, we plan to apply thisframework to other free word order languages (i.e.,other than the Indian languages).
This theory canalso be attempted on positional languages such asEnglish.
What is needed is the concept of general-ized vibhakti n which position of a word gets inco-porated in vibhakti.
Thus, for a pure free word or-der language, the generalized vibhakti contains pre-or post-positional markers, whereas for a pure posi-tional language it contains position information of aword (group).
Clearly, for most natural anguages,generalized vibhakti would contain information per-taining to both markers and position.AcknowledgementVineet Chaitanya is the principal source of ideasin this paper, who really should be a co-author.We gratefully acknowledge the help received fromK.V.
Ramakrishnamacharyulu of Rashtriya San-skrit Sansthan, Tirupati in development of the the-ory.
For complexity results, we acknowledge thecontributions of B. Perraju, Somnath Biswas andRavindra K. Ahuja.Support for this and related work comes from thefollowing agencies of Government ofIndia: Ministryof Human Resource Development, Department ofElectronics, and Department of Science and Tech-nology.ReferencesAhuja, R.K., Thomas L. Magnanti, and JamesB.
Orlin, Network Flows: Theory, Algorithms110and Applications, Prentice-Hall, 1993 (forth-coming).Barton, G. Edward, Robert C. Berwick, and EricS.
Ristad, Computational Complexity and Nat-ural Language, MIT Press, Cambridge, MA,1987.Bharati, Akshar, Vineet Chaitanya, and RajeevSangal, A Computational Grammar for IndianLanguages Processing, Journal of Indian Lin-guistics, IL-51.
(Also available as TRCS-90-96,Dept.
of CSE, IIT Kanpur, 1990.
)Bharati, Akshar, Vineet Chaitanya, and RajeevSangal, Local Word Grouping and Its Rel-evance to Indian Languages, in Frontiers inKnowledge Based Computing (KBCS90), V.P.Bhatkar and K.M.
Rege (eds.
), Narosa Publish-ing House, New Delhi, 1991, pp.
277-296.Bharati, Akshar, Vineet Chaitanya, and RajeevSangal, LFG, GB, and Paninian Frameworks:An NLP Viewpoint, Part of NLP tutorial forCPAL-2: UNESCO 2nd Regional Workshop onComputer Processing of Asian Languages, 12-16 March 1992, I.I.T.
Kanpur.
(Also availableas TRCS-92-140, Dept.
of CSE, IIT Kanpur.
)Cardona, George, Panini: A Survey of Research,Mouton, Hague-Paris, 1976.Cardona, George, Panini: His Work and Its Tra-dition (Vol.
1: Background and Introduction),Motilal Banarsidas, Delhi, 1988.Covington, Michael A., Parsing DiscontinuousConstituents in Dependency Grammar (Tech-nical Correspondence), Computational Lin-guistics, 16,4 (Dec. 1990), p.234.Deo, Narsingh, Graph Theory, Prentice-Hall, 1974.Hopcroft, J.E.
and R.M.
Karp, "A n 5/2 Algorithmfor Maximum Matching in Bipartite Graphs,"J. SIAM Comp.
2 (1973), pp.225-231.Kashket, Michael B., Parsing a free-word-orderlanguage: Warlpiri, Proc.
of 24th AnnualMeeting of ACL, pp.
60-66.Kiparsky, P., Some Theoretical Problems inPanini's Grammar, Bhandarkar Oriental Re-search Institute, Poona, India, 1982.Kuhn, H.W.
"The Hungarian Method for the As-signment Problem", Naval Research LogisticsQuarterly, 2 (1955), pp.83-97.Papadimitrou, Christos H., and K. Steiglitz, Com-binatorial Optimization, Prentice-Hall, Engle-wood Cliffs, 1982.Perraju, Bendapudi V.S., Algorithmic Aspectsof Natural Language Parsing using PaninianFramework, M.Tech.
thesis, Dept.
of Com-puter Science and Engineering, I.I.T.
Kanpur,Dec.
1992.111
