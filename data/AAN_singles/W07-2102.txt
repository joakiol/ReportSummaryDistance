Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 460?463,Prague, June 2007. c?2007 Association for Computational LinguisticsUTD-SRL: A Pipeline Architecture for Extracting FrameSemantic StructuresCosmin Adrian Bejan and Chris HathawayHuman Language Technology Research InstituteThe University of Texas at DallasRichardson, TX 75083-0688, USA{ady,chris}@hlt.utdallas.eduAbstractThis paper describes our system for the taskof extracting frame semantic structures inSemEval?2007.
The system architectureuses two types of learning models in eachpart of the task: Support Vector Machines(SVM) and Maximum Entropy (ME).
De-signed as a pipeline of classifiers, the seman-tic parsing system obtained competitive pre-cision scores on the test data.1 IntroductionThe SemEval?2007 task for extracting frame se-mantic structures relies on the human annotateddata available in the FrameNet (FN) database.
TheBerkeley FrameNet project (Baker et al, 1998) isan ongoing effort of building a semantic lexicon forEnglish based on the theory of frame semantics.
Inframe semantics, the meaning of words or word ex-pressions, also called target words (TW), comprisesaspects of conceptual structures, or frames, that de-scribe specific situations.
The semantic roles, orframe elements (FE), associated with a target wordare locally defined in the frame evoked by the tar-get word.
Currently, the FN lexicon includes morethan 135,000 sentences extracted from the BritishNational Corpus containing more than 6,100 targetwords that evoke more than 825 semantic frames.For this task, we extended our previous work atSenseval-3 (Bejan et al, 2004) by (1) experiment-ing with additional features, (2) adding new classifi-cation sub-tasks to accomplish all the requirements,and (3) integrating these sub-tasks into a pipeline ar-chitecture.2 System DescriptionGiven a sentence, the frame semantic structure ex-traction task consists of recognizing the word ex-pressions that evoke semantic frames, assigning thecorrect frame to them and, for each target word,detecting and labeling the corresponding frame el-ements properly.
The task also requires the de-termination of syntactic realizations associated to aframe element, such as grammatical function (GF)and phrase type (PT).
The following illustrates asentence example annotated with frame elements to-gether with their corresponding grammatical func-tions and phrase types for the target word ?tie?
:FE = Content2GF = DepPT = PPFE = Content1GF = ExtPT = NPAEOI?s activities and facilities  have been  tied   to several universities .Frame = Make_Cognitive_ConnectionevokesTo extract semantic structures similar to those il-lustrated in the example we divide the SemEval?2007 task into four sub-tasks: (1) target word framedisambiguation (TWFD); (2) FE boundary detection(FEBD); (3) GF label classification (GFLC) and (4)FE label classification (FELC).
The sub-tasks TWFDand GFLC are natural extensions of the approach de-scribed in (Bejan et al, 2004) for the task of se-mantic role labeling at Senseval-03.
We design ma-chine learning classifiers specific for each of the foursub-tasks and arrange them in a pipeline architecturesuch that a classifier can use information predictedby its previous classifiers.
The system architectureis illustrated in Figure 1.
In the data processing step,we parse each sentence into a syntactic tree using theCollins parser and extract named entities using an in460Target word listTest dataNamed EntityRecognizerTest DataTarget wordFrameFE BoundaryGFSVM model ME model SVM model ME model SVM model ME modelSVM model ME modelME trainSVM trainFeature ExtractorME trainone multi?class classifierSVM trainFeature ExtractorME trainSVM trainFeature Extractorone binary classifierME trainSVM trainFeature Extractor556 multi?class classifiers 489 multi?class classifiersTest DataTrain DataFeatureFeatureTest DataTarget wordFrameFeatureFeatureTest DataTarget wordFrameFE BoundaryFN AnnotationFE BoundaryPredictorFramePredictor PredictorFE LabelPredictorExtractor Extractor Extractor ExtractorGF LabelSyntacticParserGF Label Classification FE Label ClassificationFE Boundary DetectionFrame DisambiguationFrameNetLexiconData ProcessingFigure 1: System architecture.house implementation of a named entity recognizer.We also extract from the FN lexicon mappings oftarget words and the semantic frames they evoke.Various features corresponding to constituentswere extracted and passed to SVM and ME clas-sifiers.
For example, in Figure 2, the frame dis-activitiesNNSAEOINNP POS?sNPandCCfacilitiesNNSNPJJseveralInhibit_movementRope_manipulationAttachingClosureActivity_finishFinish_competitionImmobilizationMake_cognitive_connectionKnot_creationForming_relationshipsFrame Disambiguationpositive negativeFE Boundary DetectionHeadNULLObjQuantAppositiveDepExtGenGF ClassificationVBPhaveVPVPVBNVBNbeenStied NPtoPPNNSuniversitiesVP Concept_1Concept_2EvidenceCognizerConceptsTimePlaceCircumstancesFrequencyFE Classif.Figure 2: Classification examples for each sub-task.ambiguation sub-task extracts features correspond-ing to the constituent tied in order to predict theright frame between the semantic frames that can beevoked by this target word.
In this figure, the correctcategories for each sub-task are shown in boldface.The complete set of features extracted for all theclassification sub-tasks is illustrated in Figure 3.These represent a subset of features used in previ-ous works (Gildea and Jurafsky, 2002; Florian et al,2002; Surdeanu et al, 2003; Xue and Palmer, 2004;Bejan et al, 2004; Pradhan et al, 2005) for auto-matic semantic role labeling and word sense disam-biguation.
Figure 3 also indicates whether or not afeature is selected for a specific classification task.In the remaining part of this section we describein detail each classification sub-task and the featuresthat have the most salient effect on improving thecorresponding classifiers.2.1 Frame DisambiguationIn FrameNet, some target words can evoke multiplesemantic frames.
In order to extract the semanticstructure of an ambiguous target word, the first stepis to assign the correct frame to the target word ina given context.
This task is similar with the wordsense disambiguation task.We select from the FN lexicon 556 target wordsthat evoke at least two semantic frames and have atleast five sentences annotated for each frame, andassemble a multi-class classifier for each ambiguoustarget word.
As described in Figure 3, for this taskwe extract features used in word sense disambigua-tion (Florian et al, 2002), lexical features of the tar-get word, and NAMED ENTITY FLAGS associatedwith the root node in a syntactic parse tree.
Forthe rest of the ambiguous target words that have lessthan five sentences annotated we randomly choose aframe as being the correct frame in a given context.2.2 Frame Element IdentificationThe idea of splitting the automatic semantic role la-beling task into FE boundary detection and FE labelclassification was first proposed in (Gildea and Ju-rafsky, 2002) and then adopted by other works inthis task.
The problem of detecting the FE bound-aries is cast as the problem of deciding whether ornot a constituent is a valid candidate for a FE.461TWFDGFLCFeature DescriptionNO NO Feature DescriptionTWFDGFLCFEBDFEBDFELCFELCCW: The content word of the constituent computed as described in(Surdeanu et al, 2003);v20CW POS: The POS corresponding to the content word;v21CW STEM: Stemmed content word;v22GOVERNING CATEGORY: Test whether the noun phrase constituents arevv23dominated by verbal phrases or sentence phrases;SYNTACTIC DISTANCE: The length of the syntactic path;v24PP FIRST WORD: If the constituent is a prepositional phrase, return the firstword in the phrase;v25HUMAN: Test whether the constituent phrase is either a personal pronounor a hyponym of first sense of PERSON synset in WordNet;v26CONSTITUENTS NUMBER: The number of candidate FEs;v27CONSTITUENTS LIST: Constituents labels list of the candidate FEs;v28SAME CLAUSE: Test whether the constituent is in the same clause withv29the target word;GF: The grammatical function of a candidate frame element;v30GF LIST: The list of grammatical functions associated to the candidate FEs;v31FRAME: The name of the semantic frame that is evoked by the target word;vvv32NP SISTER: Determine whether the constituent has a noun phrase sister;v33FIRST/LAST WORD: Return the first/last word of the constituent phrase;v34FIRST/LAST POS: Return the first/last POS in the constituent;vv35LEFT/RIGHT SISTER LABEL: Return the left/right sibling constituent label;v36LEFT/RIGHT SISTER HEAD: Return the left/right sibling head word;v37LEFT/RIGHT SISTER STEM HEAD: Return the left/right sibling stemmedv38head word;LEFT/RIGHT SISTER POS HEAD: Return the left/right sibling head POS;v39HW POS: The syntactic head POS of the constituent;HW STEM: The stem word of the constituent?s head word;v vv1819TW STEM & HW STEM: Join of TW STEM and HW STEM;TW STEM & PHRASE TYPE: Join of TW STEM and PHRASE TYPE;vv4041VOICE & POSITION: Join of VOICE and POSITION.v42TW UNIGRAMS: The words, stem words and part of speech (POS) unigramsv01that are adjacent to target word expressions;TW BIGRAMS: The words, stem words and POS bigrams that are adjacent to02target word expressions;TW WORD: The target word expression;03TW STEM: The stem word(s) of the target word expression;v v04vTW POS: The POS of the target word;vTW CLASS: The lexical class of the target word, e.g.
verb, noun, adjective;vv0605NAMED ENTITY FLAGS: Set of binary features indicating whether a consti?vv07tuent contains, is contained or exactly identifies a named entity;VERB WSD: If the target word is a verb, extract the head noun of the directobject and the prepositional object included in the verbal phrase;v08vNOUN WSD: If the target word is a noun, extract the head word of the verbalphrase that is in a verb?subject or verb?object relation with the noun;09 vADJECTIVE WSD: If the target word is an adjective, extract the head nounthat is modified by the adjective;10 vPHRASE TYPE: The syntactic category of the constituent;vv11DIRECTED PATH: Path in the syntactic parse tree between the constituentand the target word preserving the movement direction;vvv12UNDIRECTED PATH: Same syntactic path as DIRECTED PATH without13 vpreserving the movement direction;PARTIAL PATH: Path from the constituent to the earlier common ancestor ofthe target word and the constituent;v14POSITION: Test whether the constituent contains the target word, or appearsbefore or after the target word;vv v15VOICE: Test if the verbal target word has active or passive construction;vv16HW: The head word of the constituent;v vv17Figure 3: Feature set for extracting frame semantic structures.We consider a binary classifier over the entire FNdata and extract features for each constituent from asyntactic parse tree.
Because this experimental setupallows training the binary classifier on a large set ofexamples, the best feature combination consists ofa restrained number of features.
Most of these fea-tures are from the set proposed by (Gildea and Juraf-sky, 2002).
Another feature that improved the pre-diction of FE boundaries in every feature selectionexperiment is the FRAME feature.
Since the framedisambiguation is executed before the FE boundarydetection in the pipeline architecture, we can use theFRAME feature at this step.
This feature helps thebinary classifier distinguish between frame elementstructures from different semantic frames.2.3 Grammatical Function ClassificationOnce we identify the candidate boundaries for frameelements, the next step is to assign the grammat-ical functions to these boundaries.
In FrameNet,the grammatical functions represent the manner inwhich the frame elements satisfy grammatical con-straints with respect to the target word.For this task we train a multi-class classifier overthe entire lexicon to predict seven categories of GFsthat exist in FN.
In addition, we assign the NULLcategory for those FEs that double as target words.The features are extracted only for the constituentsthat are identified as FEs in the previous FE bound-ary identification sub-task.
The best feature set inthis phase includes the features proposed by (Gildeaand Jurafsky, 2002) and the FRAME feature.2.4 Frame Element ClassificationThe task of FE classification is to assign FE labels toevery constituent identified as FE.
In order to predictthe frame elements, which are locally defined foreach semantic frame, we built 489 multi-class clas-sifiers, where each classifier corresponds to a framein FrameNet.
This partitioning of the FN lexicon hasthe advantage of increasing the overall classificationperformance and efficiently learning the frame ele-ments labels.
On the other hand, this approach suf-fers from the lack of annotated data in some framesand hence it requires using a large set of features.The advantage of designing the classifiers in apipeline architecture is best illustrated in this sub-task.
Some of the most effective features for FEclassification are extracted using information fromprevious sub-tasks: FRAME feature is made avail-able by the TWFD sub-task, CONSTITUENTS NUM-BER and CONSTITUENTS LIST are made availableby the FEBD sub-task, and GF and GF LIST aremade available by the GFLC sub-task.4623 Experimental ResultsWe report experimental results on all four classi-fication sub-tasks.
In our experiments we trainedtwo types of classification models for each sub-task:SVM and ME.
In order to optimize the performancemeasure of each sub-task and to find the best config-uration of classification models we used 20% of thesub-tasks training data as validation data.
Table 1lists the best configuration of classification modelsas well as the best sub-task results when runningthe experiments on the validation data.
For framedisambiguation, we obtained 76.71% accuracy com-pared to a baseline of 60.72% accuracy that alwayspredicts the most annotated frame for each of the556 target words.
The results for GFLC and FELCsub-tasks listed in Table 1 were achieved by usinggold FE boundaries.Frame DisambiguationGF Label ClassificationFE Label ClassificationFE Boundary DetectionTaskSVMSVM76.71Best Model96.0088.93MEMEAccuracyF1?measureRecall73.65Precision87.08 79.80Table 1: Task results on the validation set.The SemEval?2007 organizers provided fully an-notated training files, a scorer to evaluate thesetraining files, and testing files containing flat sen-tences.
In the evaluation process, a semantic depen-dency graph corresponding to a fully system anno-tated sentence is created and then matched with itsgold dependency graph.
The matching process notonly evaluates every semantic structure of a targetword, but also considers frame-to-frame and FE-to-FE graph relations between the semantic structures.In addition, various scoring options were consid-ered: exact or partial frame matching, partial creditfor evaluating the named entities, evaluation of theflat frame elements labels, and an option for match-ing only the frames in evaluation.
The evaluation forflat frame elements labels is similar with the evalu-ation performed at Senseval-3.
The only differenceis that for this scorer the FE boundaries must matchexactly.In Table 2, we present the averaged precision,recall and F1 measures for evaluating the seman-tic dependency graphs and detecting the semanticframes on the testing files.
The ?Options?
col-umn represents the configuration parameters of thescorer: (E)xact/(P)artial frame matching, seman-tic (D)ependency or (L)abels only evaluation, and(Y)es/(N)o named entity evaluation.E D NP D NE L YP L YE D YP D YE L NP L NSemantic Dependency EvaluationF1?measureRecallPrecision51.1050.2954.7851.8551.3856.1355.5656.5927.7427.0529.4827.5926.9529.4530.1930.1435.8835.1138.2635.9435.2938.5739.0439.2569.1671.6980.3569.1671.6980.3577.8277.8242.7344.4349.7942.7344.4349.7948.0948.0952.7154.7461.3552.7154.7461.3559.3259.32Precision Recall F1?measureOptions Frame Detection EvaluationTable 2: System results on the test set.Although the system achieved good precisionscores on the test data, the recall values caused thesystem to obtain unsatisfactory F1-measure values.We expect that the recall will increase by consid-ering various heuristics for a better mapping of theframe elements to constituents in parse trees.4 ConclusionsWe described a system that participated in SemEval?2007 for the task of extracting frame semantic struc-tures.
We showed that a pipeline architecture of theSVM and ME classifiers as well as an adequate se-lection of the classification models can improve theperformance measures of each sub-task.ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998.The Berkeley FrameNet project.
In Proceedings of theCOLING-ACL, Montreal, Canada.Cosmin Adrian Bejan, Alessandro Moschitti, Paul Mora?rescu,Gabriel Nicolae, and Sanda Harabagiu.
2004.
SemanticParsing Based on FrameNet.
In Senseval-3: Workshop onthe Evaluation of Systems for the Semantic Analysis of Text.Radu Florian, Silviu Cucerzan, Charles Schafer, and DavidYarowsky.
2002.
Combining classifiers for word sense dis-ambiguation.
Natural Language Engineering.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic Labelingof Semantic Roles.
Computational Linguistic.Sameer Pradhan, Kadri Hacioglu, Valeri Krugler, Wayne Ward,James H. Martin, and Daniel Jurafsky.
2005.
Support vec-tor learning for semantic argument classification.
Journal ofMachine Learning Research.Mihai Surdeanu, Sanda M. Harabagiu, John Williams, and PaulAarseth.
2003.
Using predicate-argument structures for in-formation extraction.
In Proceedings of ACL.Nianwen Xue and Marta Palmer.
2004.
Calibrating features forsemantic role labeling.
In Proceedings of EMNLP.463
