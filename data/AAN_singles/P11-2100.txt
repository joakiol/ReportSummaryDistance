Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 569?574,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsSemi-supervised latent variable models for sentence-level sentiment analysisOscar Ta?ckstro?mSICS, Kista / Uppsala University, Uppsalaoscar@sics.seRyan McDonaldGoogle, Inc., New Yorkryanmcd@google.comAbstractWe derive two variants of a semi-supervisedmodel for fine-grained sentiment analysis.Both models leverage abundant natural super-vision in the form of review ratings, as well asa small amount of manually crafted sentencelabels, to learn sentence-level sentiment clas-sifiers.
The proposed model is a fusion of afully supervised structured conditional modeland its partially supervised counterpart.
Thisallows for highly efficient estimation and infer-ence algorithms with rich feature definitions.We describe the two variants as well as theircomponent models and verify experimentallythat both variants give significantly improvedresults for sentence-level sentiment analysiscompared to all baselines.1 Sentence-level sentiment analysisIn this paper, we demonstrate how combiningcoarse-grained and fine-grained supervision bene-fits sentence-level sentiment analysis ?
an importanttask in the field of opinion classification and retrieval(Pang and Lee, 2008).
Typical supervised learning ap-proaches to sentence-level sentiment analysis rely onsentence-level supervision.
While such fine-grainedsupervision rarely exist naturally, and thus requireslabor intensive manual annotation effort (Wiebe etal., 2005), coarse-grained supervision is naturallyabundant in the form of online review ratings.
Thiscoarse-grained supervision is, of course, less infor-mative compared to fine-grained supervision, how-ever, by combining a small amount of sentence-levelsupervision with a large amount of document-levelsupervision, we are able to substantially improve onthe sentence-level classification task.
Our work com-bines two strands of research: models for sentimentanalysis that take document structure into account;and models that use latent variables to learn unob-served phenomena from that which can be observed.Exploiting document structure for sentiment anal-ysis has attracted research attention since the earlywork of Pang and Lee (2004), who performed min-imal cuts in a sentence graph to select subjectivesentences.
McDonald et al (2007) later showed thatjointly learning fine-grained (sentence) and coarse-grained (document) sentiment improves predictionsat both levels.
More recently, Yessenalina et al(2010) described how sentence-level latent variablescan be used to improve document-level predictionand Nakagawa et al (2010) used latent variables oversyntactic dependency trees to improve sentence-levelprediction, using only labeled sentences for training.In a similar vein, Sauper et al (2010) integrated gen-erative content structure models with discriminativemodels for multi-aspect sentiment summarizationand ranking.
These approaches all rely on the avail-ability of fine-grained annotations, but Ta?ckstro?mand McDonald (2011) showed that latent variablescan be used to learn fine-grained sentiment using onlycoarse-grained supervision.
While this model wasshown to beat a set of natural baselines with quite awide margin, it has its shortcomings.
Most notably,due to the loose constraints provided by the coarsesupervision, it tends to only predict the two dominantfine-grained sentiment categories well for each docu-ment sentiment category, so that almost all sentencesin positive documents are deemed positive or neutral,and vice versa for negative documents.
As a way ofovercoming these shortcomings, we propose to fusea coarsely supervised model with a fully supervisedmodel.Below, we describe two ways of achieving sucha combined model in the framework of structuredconditional latent variable models.
Contrary to (gen-erative) topic models (Mei et al, 2007; Titov and569a) yd?
?
?
ysi?1 ysi ysi+1 ?
?
??
?
?
si?1 si si+1 ?
?
?b) yd?
?
?
ysi?1 ysi ysi+1 ?
?
??
?
?
si?1 si si+1 ?
?
?Figure 1: a) Factor graph of the fully observed graphical model.
b) Factor graph of the corresponding latent variablemodel.
During training, shaded nodes are observed, while non-shaded nodes are unobserved.
The input sentences si arealways observed.
Note that there are no factors connecting the document node, yd, with the input nodes, s, so that thesentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences.McDonald, 2008; Lin and He, 2009), structured con-ditional models can handle rich and overlapping fea-tures and allow for exact inference and simple gradi-ent based estimation.
The former models are largelyorthogonal to the one we propose in this work andcombining their merits might be fruitful.
As shownby Sauper et al (2010), it is possible to fuse gener-ative document structure models and task specificstructured conditional models.
While we do modeldocument structure in terms of sentiment transitions,we do not model topical structure.
An interestingavenue for future work would be to extend the modelof Sauper et al (2010) to take coarse-grained task-specific supervision into account, while modelingfine-grained task-specific aspects with latent vari-ables.Note also that the proposed approach is orthogonalto semi-supervised and unsupervised induction ofcontext independent (prior polarity) lexicons (Turney,2002; Kim and Hovy, 2004; Esuli and Sebastiani,2009; Rao and Ravichandran, 2009; Velikovich et al,2010).
The output of such models could readily beincorporated as features in the proposed model.1.1 PreliminariesLet d be a document consisting of n sentences, s =(si)ni=1, with a document?sentence-sequence pair de-noted d = (d, s).
Let yd = (yd,ys) denote randomvariables1 ?
the document level sentiment, yd, and thesequence of sentence level sentiment, ys = (ysi )ni=1.1We are abusing notation throughout by using the same sym-bols to refer to random variables and their particular assignments.In what follows, we assume that we have access totwo training sets: a small set of fully labeled in-stances, DF = {(dj ,ydj )}mfj=1, and a large set ofcoarsely labeled instances DC = {(dj , ydj )}mf+mcj=mf+1.Furthermore, we assume that yd and all ysi take val-ues in {POS, NEG, NEU}.We focus on structured conditional models in theexponential family, with the standard parametrizationp?
(yd,ys|s) = exp{??
(yd,ys, s), ??
?A?
(s)},where ?
?
<n is a parameter vector, ?(?)
?
<n is avector valued feature function that factors accordingto the graph structure outlined in Figure 1, and A?is the log-partition function.
This class of models isknown as conditional random fields (CRFs) (Laffertyet al, 2001), when all variables are observed, and ashidden conditional random fields (HCRFs) (Quattoniet al, 2007), when only a subset of the variables areobserved.1.2 The fully supervised fine-to-coarse modelMcDonald et al (2007) introduced a fully super-vised model in which predictions of coarse-grained(document) and fine-grained (sentence) sentiment arelearned and inferred jointly.
They showed that learn-ing both levels jointly improved performance at bothlevels, compared to learning each level individually,as well as to using a cascaded model in which thepredictions at one level are used as input to the other.Figure 1a outlines the factor graph of the corre-570sponding conditional random field.2 The parameters,?F , of this model can be estimated from the set offully labeled data, DF , by maximizing the joint con-ditional likelihood functionLF (?F ) =mf?j=1log p?F (ydj ,ysj |sj)??
?F ?22?2F,where ?2F is the variance of the Normal(0, ?2F ) prior.Note that LF is a concave function and consequentlyits unique maximum can be found by gradient basedoptimization techniques.1.3 Latent variables for coarse supervisionRecently, Ta?ckstro?m and McDonald (2011) showedthat fine-grained sentiment can be learned fromcoarse-grained supervision alone.
Specifically, theyused a HCRF model with the same structure as thatin Figure 1a, but with sentence labels treated as la-tent variables.
The factor graph corresponding to thismodel is outlined in Figure 1b.The fully supervised model might benefit from fac-tors that directly connect the document variable, yd,with the inputs s. However, as argued by Ta?ckstro?mand McDonald (2011), when only document-levelsupervision is available, the document variable, yd,should be independent of the input, s, conditionedon the latent variables, ys.
This prohibits the modelfrom bypassing the latent variables, which is crucial,since we seek to improve the sentence-level predic-tions, rather than the document-level predictions.The parameters, ?C , of this model can be esti-mated from the set of coarsely labeled data, DC , bymaximizing the marginalized conditional likelihoodfunctionLC(?C) =mf+mc?j=mf+1log?ysp?C (ydj ,ys|sj)??
?C?22?2C,where the marginalization is over all possible se-quences of latent sentence label assignments ys.Due to the introduction of latent variables, themarginal likelihood function is non-concave and thusthere are no guarantees of global optimality, how-ever, we can still use a gradient based optimizationtechnique to find a local maximum.2Figure 1a differs slightly from the model employed by Mc-Donald et al (2007), where they had factors connecting thedocument label yd with each input si as well.2 Combining coarse and full supervisionThe fully supervised and the partially supervisedmodels both have their merits.
The former requiresan expensive and laborious process of manual an-notation, while the latter can be used with readilyavailable document labels, such as review star rat-ings.
The latter, however, has its shortcomings inthat the coarse-grained sentiment signal is less infor-mative compared to a fine-grained signal.
Thus, inorder to get the best of both worlds, we would like tocombine the merits of both of these models.2.1 A cascaded modelA straightforward way of fusing the two models isby means of a cascaded model in which the predic-tions of the partially supervised model, trained bymaximizing LC(?C) are used to derive additionalfeatures for the fully supervised model, trained bymaximizing LF (?F ).Although more complex representations are pos-sible, we generate meta-features for each sentencebased solely on operations on the estimated distribu-tions, p?C (yd, ysi |s).
Specifically, we encode the fol-lowing probability distributions as discrete featuresby uniform bucketing, with bucket width 0.1: thejoint distribution, p?C (yd, ysi |s); the marginal docu-ment distribution, p?C (yd|s); and the marginal sen-tence distribution, p?C (ysi |s).
We also encode theargmax of these distributions, as well as the pair-wise combinations of the derived features.The upshot of this cascaded approach is that it isvery simple to implement and efficient to train.
Thedownside is that only the partially supervised modelinfluences the fully supervised model; there is noreciprocal influence between the models.
Given thenon-concavity of LC(?C), such influence could bebeneficial.2.2 Interpolating likelihood functionsA more flexible way of fusing the two models is tointerpolate their likelihood functions, thereby allow-ing for both coarse and joint supervision of the samemodel.
Such a combination can be achieved by con-straining the parameters so that ?I = ?F = ?C andtaking the mean of the likelihood functions LF andLC , appropriately weighted by a hyper-parameter ?.571The result is the interpolated likelihood functionLI(?I) = ?LF (?I) + (1?
?
)LC(?I) .A simple, yet efficient, way of optimizing this ob-jective function is to use stochastic gradient ascentwith learning rate ?.
At each step we select a fullylabeled instance, (dj ,ydj ) ?
DF , with probability ?and a coarsely labeled instance, (dj , ydj ) ?
DC , withprobability (1?
?).
We then update the parameters,?I , according to the gradients ?LF and ?LC , respec-tively.
In principle we could use different learningrates ?F and ?C as well as different prior variances?2F and ?2C , but in what follows we set them equal.Since we are interpolating conditional models, weneed at least partial observations of each instance.Methods for blending discriminative and generativemodels (Lasserre et al, 2006; Suzuki et al, 2007;Agarwal and Daume?, 2009; Sauper et al, 2010),would enable incorporation of completely unlabeleddata as well.
It is straightforward to extend the pro-posed model along these lines, however, in practicecoarsely labeled sentiment data is so abundant onthe web (e.g., rated consumer reviews) that incorpo-rating completely unlabeled data seems superfluous.Furthermore, using conditional models with sharedparameters throughout allows for rich overlappingfeatures, while maintaining simple and efficient in-ference and estimation.3 ExperimentsFor the following experiments, we used the same dataset and a comparable experimental setup to that ofTa?ckstro?m and McDonald (2011).3 We compare thetwo proposed hybrid models (Cascaded and Interpo-lated) to the fully supervised model of McDonald etal.
(2007) (FineToCoarse) as well as to the soft vari-ant of the coarsely supervised model of Ta?ckstro?mand McDonald (2011) (Coarse).The learning rate was fixed to ?
= 0.001, whilewe tuned the prior variances, ?2, and the number ofepochs for each model.
When sampling according to?
during optimization of LI(?I), we cycle throughDF and DC deterministically, but shuffle these setsbetween epochs.
Due to time constraints, we fixed theinterpolation factor to ?
= 0.1, but tuning this could3The annotated test data can be downloaded fromhttp://www.sics.se/people/oscar/datasets.potentially improve the results of the interpolatedmodel.
For the same reason we allowed a maximumof 30 epochs, for all models, while Ta?ckstro?m andMcDonald (2011) report a maximum of 75 epochs.To assess the impact of fully labeled versuscoarsely labeled data, we took stratified samples with-out replacement, of sizes 60, 120, and 240 reviews,from the fully labeled folds and of sizes 15,000 and143,580 reviews from the coarsely labeled data.
Onaverage each review consists of ten sentences.
Weperformed 5-fold stratified cross-validation over thelabeled data, while using stratified samples for thecoarsely labeled data.
Statistical significance was as-sessed by a hierachical bootstrap of 95% confidenceintervals, using the technique described by Davisonand Hinkley (1997).3.1 Results and analysisTable 1 lists sentence-level accuracy along with 95%confidence interval for all tested models.
We firstnote that the interpolated model dominates all othermodels in terms of accuracy.
While the cascadedmodel requires both large amounts of fully labeledand coarsely labeled data, the interpolated modelis able to take advantage of both types of data onits own and jointly.
Still, by comparing the fullysupervised and the coarsely supervised models, thesuperior impact of fully labeled over coarsely labeleddata is evident.
As can be seen in Figure 2, whenall data is used, the cascaded model outperforms theinterpolated model for some recall values, and viceversa, while both models dominate the supervisedapproach for the full range of recall values.As discussed earlier, and confirmed by Table 2,the coarse-grained model only performs well on thepredominant sentence-level categories for each docu-ment category.
The supervised model handles nega-tive and neutral sentences well, but performs poorlyon positive sentences even in positive documents.The interpolated model, while still better at capturingthe predominant category, does a better job overall.These results are with a maximum of 30 trainingiterations.
Preliminary experiments with a maximumof 75 iterations indicate that all models gain frommore iterations; this seems to be especially true forthe supervised model and for the cascaded modelwith less amount of course-grained data.572|DC | = 15,000 |DC | = 143,580|DF | = 60 |DF | = 120 |DF | = 240 |DF | = 60 |DF | = 120 |DF | = 240FineToCoarse 49.3 (-1.3, 1.4) 53.4 (-1.8, 1.7) 54.6 (-3.6, 3.8) 49.3 (-1.3, 1.4) 53.4 (-1.8, 1.7) 54.6 (-3.6, 3.8)Coarse 49.6 (-1.5, 1.8) 49.6 (-1.5, 1.8) 49.6 (-1.5, 1.8) 53.5 (-1.2, 1.4) 53.5 (-1.2, 1.4) 53.5 (-1.2, 1.4)Cascaded 39.7 (-6.8, 5.7) 45.4 (-3.1, 2.9) 42.6 (-6.5, 6.5) 55.6 (-2.9, 2.7) 55.0 (-3.2, 3.4) 56.8 (-3.8, 3.6)Interpolated 54.3 (-1.4, 1.4) 55.0 (-1.7, 1.6) 57.5 (-4.1, 5.2) 56.0 (-2.4, 2.1) 54.5 (-2.9, 2.8) 59.1 (-2.8, 3.4)Table 1: Sentence level results for varying numbers of fully labeled (DF ) and coarsely labeled (DC) reviews.
Bold:significantly better than the FineToCoarse model according to a hierarchical bootstrapped confidence interval, p < 0.05.0 10 20 30 40 50 60 70 80 90 100Recall0102030405060708090100PrecisionPOS sentencesFineToCoarseCascadedInterpolated0 10 20 30 40 50 60 70 80 90 100Recall0102030405060708090100PrecisionNEG sentencesFineToCoarseCascadedInterpolatedFigure 2: Interpolated POS / NEG sentence-level precision-recall curves with |DC | = 143,580 and |DF | = 240.POS docs.
NEG docs.
NEU docs.FineToCoarse 35 / 11 / 59 33 / 76 / 42 29 / 63 / 55Coarse 70 / 14 / 43 11 / 71 / 34 43 / 47 / 53Cascaded 43 / 17 / 61 0 / 75 / 49 10 / 64 / 50Interpolated 73 / 16 / 51 42 / 72 / 48 54 / 52 / 57Table 2: POS / NEG / NEU sentence-level F1-scores perdocument category (|DC | = 143,580 and |DF | = 240).4 ConclusionsLearning fine-grained classification tasks in a fully su-pervised manner does not scale well due to the lack ofnaturally occurring supervision.
We instead proposedto combine coarse-grained supervision, which is natu-rally abundant but less informative, with fine-grainedsupervision, which is scarce but more informative.To this end, we introduced two simple, yet effective,methods of combining fully labeled and coarselylabeled data for sentence-level sentiment analysis.First, a cascaded approach where a coarsely super-vised model is used to generate features for a fullysupervised model.
Second, an interpolated modelthat directly optimizes a combination of joint andmarginal likelihood functions.
Both proposed mod-els are structured conditional models that allow forrich overlapping features, while maintaining highlyefficient exact inference and robust estimation prop-erties.
Empirically, the interpolated model is superiorto the other investigated models, but with sufficientamounts of coarsely labeled and fully labeled data,the cascaded approach is competitive.AcknowledgmentsThe first author acknowledges the support of theSwedish National Graduate School of LanguageTechnology (GSLT).
The authors would also like tothank Fernando Pereira and Bob Carpenter for earlydiscussions on using HCRFs in sentiment analysis.573ReferencesArvind Agarwal and Hal Daume?.
2009.
Exponentialfamily hybrid semi-supervised learning.
In Proceed-ings of the International Jont conference on ArtificalIntelligence (IJCAI).Anthony C. Davison and David V. Hinkley.
1997.
Boot-strap Methods and Their Applications.
Cambridge Se-ries in Statistical and Probabilistic Mathematics.
Cam-bridge University Press, Cambridge, UK.Andrea Esuli and Fabrizio Sebastiani.
2009.
SentiWord-Net: A publicly available lexical resource for opinionmining.
In Proceedings of the Language Resource andEvaluation Conference (LREC).Soo-Min Kim and Eduard Hovy.
2004.
Determiningthe sentiment of opinions.
In Proceedings of the In-ternational Conference on Computational Linguistics(COLING).John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In Pro-ceedings of the International Conference on MachineLearning (ICML).Julia A. Lasserre, Christopher M. Bishop, and Thomas P.Minka.
2006.
Principled hybrids of generative anddiscriminative models.
In Proceedings of the IEEEComputer Society Conference on Computer Vision andPattern Recognition (CVPR).Chenghua Lin and Yulan He.
2009.
Joint sentiment/topicmodel for sentiment analysis.
In Proceeding of the Con-ference on Information and Knowledge Management(CIKM).Ryan McDonald, Kerry Hannan, Tyler Neylon, MikeWells, and Jeff Reynar.
2007.
Structured models forfine-to-coarse sentiment analysis.
In Proceedings ofthe Annual Conference of the Association for Computa-tional Linguistics (ACL).Q.
Mei, X. Ling, M. Wondra, H. Su, and C.X.
Zhai.
2007.Topic sentiment mixture: modeling facets and opin-ions in weblogs.
In Proceedings of the InternationalConference on World Wide Web (WWW).Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.2010.
Dependency Tree-based Sentiment Classificationusing CRFs with Hidden Variables.
In Proceedings ofthe North American Chapter of the Association forComputational Linguistics (NAACL).Bo Pang and Lillian Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In Proceedings of the Associ-ation for Computational Linguistics (ACL).Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Now Publishers.Ariadna Quattoni, Sybor Wang, Louis-Philippe Morency,Michael Collins, and Trevor Darrell.
2007.
Hiddenconditional random fields.
IEEE Transactions on Pat-tern Analysis and Machine Intelligence.Delip Rao and Deepak Ravichandran.
2009.
Semi-supervised polarity lexicon induction.
In Proceedingsof the European Chapter of the Association for Compu-tational Linguistics (EACL).Christina Sauper, Aria Haghighi, and Regina Barzilay.2010.
Incorporating content structure into text analy-sis applications.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).Jun Suzuki, Akinori Fujino, and Hideki Isozaki.
2007.Semi-supervised structured output learning based ona hybrid generative and discriminative approach.
InPorceedings of the Conference on Emipirical Methodsin Natural Language Processing (EMNLP).Oscar Ta?ckstro?m and Ryan McDonald.
2011.
Discov-ering fine-grained sentiment with latent variable struc-tured prediction models.
In Proceedings of the Euro-pean Conference on Information Retrieval (ECIR).Ivan Titov and Ryan McDonald.
2008.
Modeling onlinereviews with multi-grain topic models.
In Proceedingsof the Annual World Wide Web Conference (WWW).Peter Turney.
2002.
Thumbs up or thumbs down?
Senti-ment orientation applied to unsupervised classificationof reviews.
In Proceedings of the Annual Conference ofthe Association for Computational Linguistics (ACL).Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Han-nan, and Ryan McDonald.
2010.
The viability ofweb-derived polarity lexicons.
In Proceedings of theNorth American Chapter of the Association for Compu-tational Linguistics (NAACL).Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.Annotating expressions of opinions and emotions inlanguage.
In Language Resources and Evaluation(LREC).Ainur Yessenalina, Yisong Yue, and Claire Cardie.
2010.Multi-level structured models for document-level senti-ment classification.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Processing(EMNLP).574
