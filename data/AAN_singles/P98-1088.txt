Memoisation for Glue Language Deduction and Categorial ParsingMark  Hepp leDepartment of Computer ScienceUniversity of SheffieldRegent Court, 211 Portobello StreetSheffield S1 4DP, UKhepple@dcs, he f .
ac.
ukAbst rac tThe multiplicative fragment of linear logic hasfound a number of applications in computa-tional linguistics: in the "glue language" ap-proach to LFG semantics, and in the formu-lation and parsing of various categorial gram-mars.
These applications call for efficient de-duction methods.
Although a number of de-duction methods for multiplicative linear logicare known, none of them are tabular meth-ods, which bring a substantial efficiency gainby avoiding redundant computation (c.f.
chartmethods in CFG parsing): this paper presentssuch a method, and discusses its use in relationto the above applications.1 In t roduct ionThe multiplicative fragment of linear logic,which includes just the linear implication (o-)and multiplicative (?)
operators, has found anumber of applications within linguistics andcomputational linguistics.
Firstly, it can beused in combination with some system of la-belling (after the 'labelled deduction' method-ology of (Gabbay, 1996)) as a general methodfor formulating various categorial grammar sys-tems.
Linear deduction methods provide a com-mon basis for parsing categorial systems formu-lated in this way.
Secondly, the multiplicativefragment forms the core of the system used inwork by Dalrymple and colleagues for handlingthe semantics of LFG derivations, providing a'glue language' for assembling the meanings ofsentences from those of words and phrases.Although there are a number of deductionmethods for multiplicative linear logic, there is anotable absence of tabular methods, which, likechart parsing for CFGs, avoid redundant com-putation.
Hepple (1996) presents a compilationmethod which allows for tabular deduction forimplicational linear logic (i.e.
the fragment withonly o--).
This paper develops that method tocover the fragment hat includes the multiplic-ative.
The use of this method for the applica-tions mentioned above is discussed.2 Multiplicative Linear LogicLinear logic is a 'resource-sensitive' logic: in anydeduction, each assumption ('resource') is usedprecisely once?
The formulae of the multiplicat-ive fragment of (intuitionistic) linear logic aredefined by ~" ::= A I ~'o-~" J 9 v ?
~ (A anonempty set of atomic types).
The followingrules provide a natural deduction formulation:Ao--B : a B :bo-EA:  (ab)\[B : v\]A:ao--IAo -B  : ),v.a\[B: x\],\[C : y\] B?C:  bA :a  A :a  B :b?E ?IA" @ ?
E.,~(b, a) A?B:  (a ?
b)The elimination (E) and introduction (I) rulesfor o-- correspond to steps of functional ap-plication and abstraction, respectively, as theterm labelling reveals.
The o--I rule dis-charges precisely one assumption (B) withinthe proof to which it applies.
The ?I rulepairs together the premise terms, whereas ?Ehas a substitution like meaning.
1 Proofsthat Wo--(Xo--Z), Xo--Y, Yo--Z =~ W and thatXo-Yo-Z, Y@Z =v X follow:Wo-(Xo-Z)  : w Xo-Y :x  Yo -Z :y  \[Z:z\]Y:  (yz)x:Xo--Z : Az.x(yz)w:1The meaning is more obvious in the notat ion of(Benton et al, 1992): ( let  b be  x~y in a).538Xo-Yo-Z  : x \[Z: z\] \[Y: y\] Y?Z:wXo-Y: (zz)X: (zzu)x E~,,(w, (=z~))The differential status of the assumptions andgoal of a deduction (i.e.
between F and A inF =v A) is addressed in terms of polarity: as-sumptions are deemed to have positive polar-ity, and goals negative polarity.
Each Sub-formula also has a polarity, which is determ-ined by the polarity of the immediately con-taining (sub)formula, ccording to the followingschemata (where 15 is the opposite polarity to p):(i) (X  p o--Y~)P (ii) (X  p?Yp)pFor example, the leftmost assumption of thefirst proof above has the polarity pattern( W + o- (X- o- Z + )- )+.
The proofs illustratethe phenomenon of 'hypothetical reasoning',where additional assumptions (called 'hypothet-icals') are used, which are later discharged.
Theneed for hypothetical reasoning in a proof isdriven by the types of the assumptions and goal:the hypotheticals correspond to positive polar-ity subformulae of the assumptions/goal thatoccur in the following subformula contexts:i) (X- o--Y+)- (giving hypothetical Y)ii) (X + ?Y+)+ (giving hypo's X and Y)The subformula (Xo-Z) of Wo--(Xo-Z) in theproof above is an instance of context (i), so ahypothetical Z results.
Subformulae that are in-stances of patterns (i,ii) may nest within othersuch instances (e.g.
in ((A?B)?C)o-D, both((A?B)@C) and (A?B) are instances of (ii)).In such cases, we can focus on the maximal pat-tern instances (i.e.
not contained within anyother), and then examine the hypotheticals pro-duced for whether they in turn license hypothet-ical reasoning.
This approach makes explicitthe patterns of dependency amongst hypothet-ical elements.3 F i r s t -o rder  Compi la t ion  forImp l i ca t iona l  L inear  LogicHepple (1996) shows how deductions in implic-ational linear logic can be recast as deductionsinvolving only first-order formulae, using onlya single inference rule (a variant of o-E).
Themethod involves compiling the original formulaeto indexed first-order formulae, where a higher-order 2 initial formula yields multiple compiledformulae, e.g.
(omitting indices) Xo--(Yo--Z)would yield Xo--Y and Z, i.e.
with the sub-formula Z, relevant o hypothetical reasoning,being excised to be treated as a separate as-sumption, leaving a first-order esidue.
3 Index-ing is used to ensure general inear use of re-sources, but also notably to ensure proper useof excised subformulae, i.e.
so that Z, in our ex-ample, must be used in deriving the argumentof Xo-Y, or otherwise invalid deductions wouldresult).
Simplifying Xo--(Yo--Z) to Xo--Y re-moves the need for an o--I inference, but theeffect of such a step is not lost, since it is com-piled into the semantics of the formula.The approach is best explained by example.In proving Xo--(Yo--Z), Yo-W, Wo--Z =v X,the premise formulae compile to the indexed for-mulae (1-4) shown in the proof below.
Eachof these formulae (1-4) is associated with aset containing a single index, which serves asa unique identifier for that assumption.1.2.
{j}:Z:z2.
{k}:Yo--(W:0):Au.yu4.5.
{j, 1} :W:wz6.
{j,k, l} :Y:y(wz)7.
{i,j, k,l}: X:x( z.y(wz))\[2+4\]\[3+5\]\[1+6\]The formulae (5-7) arise under combination, al-lowed by the single rule below.
The index setsof these formulae identify precisely the assump-tions from which they are derived, with appro-priate indexation being ensured by the condi-tion 7r = ?~?
of the rule (where t2 stands fordisjoint union, which enforces linear usage).?
:Ao--(B:a):)~v.a ?
:B :b  7r = ?~?rr: A: a\[b//v\]2The key division here is between higher-order formu-lae, which are are functors that seek at least one argu-ment that bears a a functional type (e.g.
Wo--(Xo--Z)),and first-order formulae, which seek no such argument.3This 'excision' step has parallels to the 'emit' stepused in the chart-parsing approaches for the associativeLambek calculus of (KSnig, 1994) and (Hepple, 1992),although the latters differs in that there is no removalof the relevant subformula, i.e.
the 'emitting formula' isnot simplified, remaining higher-order.539Assumptions (1) and (4) both come fromXo-(Yo--Z): note how (1)'s argument is markedwith (4)'s index (j).
The condition c~ C ?
of therule ensures that (4) must contribute to the de-rivation of (1)'s argument.
Finally, observe thatthe rule's semantics involves not simple applic-ation, but rather by direct substitution for thevariable of a lambda expression, employing aspecial variant of substitution, notated _\[_//_\],which specifically does not act to avoid acci-dental binding.
Hence, in the final inference ofthe proof, the variable z falls within the scope ofan abstraction over z, becoming bound.
The ab-straction over z corresponds to an o-I  step thatis compiled into the semantics, o that an expli-cit inference is no longer required.
See (Hepple,1996) for more details, including a precise state-ment of the compilation procedure.4 F i r s t -o rder  Compi la t ion  forMu l t ip l i ca t ive  L inear  Log icIn extending the above approach to the multi-plicative, we will address the ?I and @E rulesas separate problems.
The need for an ?I usewithin a proof is driven by the type of eithersome assumption or the proof's overall goal,e.g.
to build the argument of an assumptionsuch as Ao-(B@C).
For this specific example,we might try to avoid the need for an expli-cit @I use by transforming the assumption tothe form Ao-Bc -C  (note that the two formu-lae are interderivable).
This line of explora-tion, however, leads to incompleteness, ince themanoeuvre results in proof structures that lacka node corresponding to the result of the ?I in-ference (which is present in the natural deduc-tion proof), and this node may be needed as thelocus of some other inference.
4 This problemcan be overcome by the use of goal atoms, whichare unique pseudo-type atoms, that are intro-duced into types by compilation (in the par-lance of lisp, they are 'gensymmed' atoms).
Anassumption Ao-(B@C) would compile to Ao--Gplus Go-Bo-C, where G is the unique goal atom(gl, perhaps).
A proof using these types doescontain a node corresponding to (what wouldbe) the result of the @ inference in the natural4Specifically, the node must be present o allowfor steps corresponding to @E inferences.
The ex-pert reader should be able to convince themselvesof this fact by considering an example such asXo- ( (Y?U)~- (Z?U)) ,  Yo -Z  ~ X.deduction proof, namely that bearing type G,the result of combining Go--Bo-C with its ar-guments.This method can be used in combination withthe existing compilation approach.
For ex-ample, an initial assumption Ao-((B?C)o--D)would yield a hypothetical D, leaving theresidue Ao-(B@C), which would become Ac~-Gplus Go--Bo-C, as just discussed.
This methodof uniquely-generated 'goal atoms' can also beused in dealing with deductions having complextypes for their intended overall result (whichmay license hypotheticals, by virtue of real-ising the polarity contexts discussed in section2).
Thus, we can replace an initial deductionF =~ A with Co--A, F ~ G, making the goal Apart of the left hand side.
The new premiseGo---A can be compiled just like any other.
Sincethe new goal formula G is atomic, it requires nocompilation.
For example, a goal type Xo-Ywould become an extra premise Go--(Xo--Y),which would compile to formulae Go-X plus Y.Turning next to ?E, the rule involves hypo-thetical reasoning, so compilation of a maximalpositive polarity subformula B?C will add hy-potheticals B,C.
No further compilation of B?Citself is then required: whatever is needed forhypothetical reasoning with respect to the in-ternal structure of its subformulae will ariseelsewhere by compilation of the hypotheticalsB,C.
Assume that these latter hypotheticalshave identifying indices i, j and semantic vari-ables x, y respectively.
A rule for ?E mightcombine B?C (with term t, say) with any otherformula A (with term s, say) provided that thelatter has a disjoint index set that includes i, j,to give a result that is also of type A, that is as-signed semantics E~y(t, s).
To be able to con-struct this semantics, the rule would need tobe able to access the identities of the variablesx, y.
The need to explicitly annotate this iden-tity information might be avoided by 'raising'the semantics of the multiplicative formula atcompilation time to be a function over the otherterm, e.g.
t might be raised to Au.E~y(t,u).
Ausable inference rule might then take the follow-ing form (where the identifying indices of thehypotheticals have been marked on the producttype):(?,A,s) {?,(B?C): {i,j},Au.t) i , j ?
?~r = ?w?Gr, A, t\[sllu\])540Note that we can safely restrict the rule to re-quire that the type A of the minor premiseis atomic.
This is possible since firstly, thefirst-order compilation context ensures that thearguments required by a functor to yield anatomic result are always present (with respect ocompleting a valid deduction), and secondly, thealternatives of combining a functor with a mul-tiplicative under the rule either before or aftersupplying its arguments are equivalent.
5In fact, we do not need the rule above, aswe can instead achieve the same effects us-ing only the single (o--) inference rule that wealready have, by allowing a very restricted useof type polymorphism.
Thus, since the aboverule's conclusion and minor premise are thesame atomic type, we can in the compilationsimply replace a formula XNY, with an implic-ation .Ao---(.A: {i,j}), where ,4 is a variable overatomic types (and i , j  the identifying indicesof the two hypotheticals generated by compil-ation).
The semantics provided for this functoris of the 'raised' kind discussed above.
However,this approach to handling ?E inferences withinthe compiled system has an undesirable charac-teristic (which would also arise using the infer-ence rule discussed above), which is that it willallow multiple derivations that assign equival-ent proof terms for a given type combination.This is due to non-determinism for the stageat which a type such as Ao---(A: {i,j}) particip-ates in the proof.
A proof might contain sev-eral nodes bearing atomic types which containthe required hypotheticals, and Ao-(al: {i, j})might combine in at any of these nodes, givingequivalent results.
6The above ideas for handling the multiplicat-ive are combined with the methods developed5This follows from the proof term equivalenceE~,y(f,(ga)) = (E~,~(f,9) a) where x,y  E freevars(g).The move of requiring the minor premise to be atomiceffects a partial normalisation which involves not onlythe relative ordering of ?E and o--E steps, but also thatbetween interdependent ?E steps (as might arise for anassumption such as ((ANB)?C)).
It is straightforwardto demonstrate that the restriction results in no loss ofreadings.
See (Benton et al, 1992) regarding term as-signment and proof normalisation for linear logic.6It is anticipated that this problem can be solved byusing normalisation results as a basis for discarding par-tial analyses during processing, but further work is re-quired in developing this idea.for the implicational fragment to give the com-pilation procedure (~-), stated in Figure 1.
Thistakes a sequent F => A as input (case T1), whereA is a type and each assumption in F takesthe form Type:Sere (Sere minimally just someunique variable), and it returns a structure(~, ?, A}, where ~ is a goal atom, ?
the set ofall identifying indices, and A a set of indexedfirst order formulae (with associated semantics).Let A* denote the result of closing A under thesingle inference rule.
The sequent is proven iff(?, ~, t) E A* for some term t, which is a com-plete proof term for the implicit deduction.
Thestatement of the compilation procedure here issomewhat different to that given in (Hepple,1996), which is based on polar translation func-tions.
In the version here, the formula relatedcases address only positive formulae.
TAs an example, consider the deductionXo--Y, Y?Z => XNZ.
Compilation returns thegoal atom gO, the full index set {g, h, i, j, k, l},)lus the formulae show in (1-6) below.1.
({9},gOo-(gl: {h}),At.t)2.
({h},glo-(X:O)o-(Z:O),AvAw.
(w ?v))3.
({i},Xo-(Y:O),kx.(ax))4.
({j},A~-(A: {k, 0), ~.E~z(b, u)>5.
{{k},Y,y}6.
({/},Z,z)7.
({i, k}, X, (ay)) \[3+5\]8.
<{h,l},glo---(X:O),Aw.
(w?z)) \[2+6\]9.
{{h,i, k,l}, gl, ((ay) ?
z)) \[7+8\]10.
({h,i,j,k,l},gl, E~z(b,((ay)?z))) \[4+9\]11.
({g,h,i,j,k,l},gO, E~(b,((ay)?z))) \[1+11\]12.
{{g, h,i, k, l}, gO, ((ay) ?
z)) \[1+9\]13.
({9, h,i,j,k,l},gO, E~(b,((ay) Nz))) \[4+12\]The formulae (7-13) arise under combination.Formulae (11) and (13) correspond to success-ful overall analyses (i.e.
have type gO, and arelabelled with the full index set).
The proof il-lustrates the possibility of multiple derivations7Note that the complexity of the compilation is linearin the 'size' of the initial deduction, as measured by acount of type atoms.
For applications where the formulaethat may participate are preset (e.g.
they are drawnfrom lexicon), formulae can be precompiled, although theresults of precompilation would need to be parametisedwith respect o the variables/indices appearing, with asufficient supply 'fresh' symbols being generated at timeof lexical access, to ensure uniqueness.541(T1) T(X I :X l , .
.
.
,Xn :x  n =:~ Xo)  -- (~,4, i )where i0 , .
.
.
, in  fresh indices; ~ a fresh goal atom; ?
= indices(A)A = 7-(<i0, Go-Xo,  y.y>)u 7-(<il, Xl,  xl>) u .
.
.
u 7-(<in, xn,(7-2) 7"((4, X, 8)) : (4, X, s) where X atomic(7-3) 7-((?,Xo-Y,s)) = 7-((4, Xo-(Y:O),s)) where Y has no (inclusion) index set(7-4) T((4, X lo- (Y :?)
,s ) )  = (4, X2o--(Y:?
),;~x.t) UFwhere Y is atomic; x a fresh variable; 7-((4, X1, (sx))) = (4, X2, t) +ttJF(T5) 7-((4, Xo-( (Yo-Z) :  ?
), s)) = 7-((?, Xo-(Y:  ~r), Ay.s()~z.y))) U 7-((i, Z, z))where i a fresh index; y, z fresh variables; 7r = i U ?
(7-6) 7-((4, Xo- ( (Y  ?
Z): ?
), s)) = 7-((4, Xo-(G: ~), s)) u 7-((i, ~o-Yo-Z,  ~z~y.
(y ?
z)))where i a fresh index; G a fresh goal atom; y, z fresh variables; 7r = i U(77) T((4, X ?
Y,s)) = (4, Ao---(A: {i, j}),At.
(E~(s,t)))  UT-((i,X,x)) U T((j,Y,y))where i, j fresh indices; x, y, t fresh variables; .4 a fresh variable over atomic typesFigure 1: The Compilation Procedureassigning equivalent readings, i.e.
(11) and (13)have identical proof terms, that arise by non-determinism for involvement of formula (4).5 Comput ing  Exc lus ion  Const ra in tsThe use of inclusion constraints (i.e.
require-ments that some formula must be used in de-riving a given functor's argument) within theapproach allows us to ensure that hypotheticalsare appropriately used in any overall deductionand hence that deductions are valid.
However,the approach allows that deduction can generatesome intermediate r sults that cannot be part ofan overall deduction.
For example, compiling aformula Xo--(Yo--(Zo--W))o--(Vo-W) gives thefirst-order esidue Xo-Yo--V, plus hypothetic-als Zo-W and W. A partial deduction in whichthe hypothetical Zo-W is used in deriving theargument V of Xo--Yo-V cannot be extendedto a successfull overall deduction, since its useagain for the functor's second argument Y (asan inclusion constraint will require) would viol-ate linear usage.
For the same reason, a directcombination of the hypotheticals Zo-W and Wis likewise a deductive dead end.This problem can be addressed via exclusionconstraints, i.e.
annotations to forbid statedformulae having been used in deriving a givenfuntor's argument, as proposed in (Hepple,1998).
Thus, a functor might have the formXo---(Y:{i}:{j}) to indicate that i must appearin its argument's index set, and that j must not.Such exclusions can be straightforwardly com-puted over the set of compiled formulae that de-rive from each initial assumption, using simple(set-theoretic) patterns of reasoning.
For ex-ample, for the case above, since W must beused in deriving the argument V of the mainresidue formula, it can be excluded from the ar-gument Y of that formula (which follows fromthe disjointness condition on the single inferencerule).
Given that the argument Y must includeZo--W, but excludes W, we can infer that Wcannot contribute to the argument of Zo--W,giving an exclusion constraint hat (amongstother things) blocks the direct combination ofZo--W and W. See (Hepple, 1998) for more de-tails (although a slightly different version of thefirst-order formalism is used there).6 Tabu lar  Deduct ionA simple algorithm for use with the above ap-proach, which avoids much redundant compu-tation, is as follows.
Given a possible theoremto prove, the results of compilation (i.e.
in-dexed types plus semantics) are gathered on anagenda.
Then, a loop is followed in which anitem is taken from the agenda nd added to thedatabase (which is initially empty), and thenthe next triple is taken from the agenda and542so on until the agenda is empty.
Whenever anentry is added to the database, a check is madeto see if it can combine with any that are alreadythere, in which case new agenda items are gen-erated.
When the agenda is empty, a check ismade for any successful overall analyses.
Sincethe result of a combination always bears an in-dex set larger than either parent, and since themaximal index set is fixed at compilation time,the above process must terminate.However, there is clearly more redundancyto be eliminated here.
Where two items dif-fer only in their semantics, their subsequentinvolvement in any further deductions will beprecisely parallel, and so they can be collapsedtogether.
For this purpose, the semantic om-ponent of database ntries is replaced with aunique identifer, which serves as a 'hook' forsemantic alternatives.
Agenda items, on theother hand, instead record the way that theagenda item was produced, which is either 'pre-supplied' (by compilation) or 'by combination',in which case the entries combined are recordedby their identifiers.
When an agenda item isadded to the database, a check is made for anentry with the same indexed type.
If there isnone, a new entry is created and a check madefor possible combinations (giving rise to newagenda items).
However, if an appropriate x-isting entry is found, a record is made for thatentry of an additional way to produce it, butno check made for possible combinations.
If atthe end there is a successful overall analsysis,its unique identifier, plus the records of whatcombined to produce what, can be used to enu-merate directly the proof terms for successfulanalyses.7 App l i ca t ion  ~1:  Categor ia lParsingThe associative Lambek calculus (Lambek,1958) is perhaps the most familiar representat-ive of the class of categorial formalisms that fallwithin the 'type-logical' tradition.
Recent workhas seen proposals for a range of such systems,differing in their resource sensitivity (and hence,implicitly, their underlying notion of 'linguisticstructure'), in some cases combining differingresource sensitivities in one system, s Many ofSSee, for example, the formalisms developed in(Moortgat et al, 1994), (Morrill, 1994), (Hepple, 1995).these proposals employ a 'labelled deductivesystem' methodology (Gabbay, 1996), wherebytypes in proofs are associated with labels whichrecord proof information for use in ensuring cor-rect inferencing.
A natural 'base logic' on whichto construct such systems is the multiplicat-ive fragment of linear logic, since (i) it standsabove the various categorial systems in the hier-archy of substructural logics, and (ii) its oper-ators correspond to precisely those appearing inany standard categorial logic.
The key require-ment for parsing categorial systems formulatedin this way is some theorem proving methodthat is sufficient for the fragment of linear logicemployed (although some additional work willbe required for managing labels), and a num-ber of different approaches have been used, e.g.proof nets (Moortgat, 1992), and SLD resolu-tion (Morrill, 1995).
Hepple (1996) introducesfirst-order compilation for implicational linearlogic, and shows how that method can be usedwith labelling as a basis parsing implicationalcategorial systems.
No further complicationsarise for combining the extended compilationapproach described in this paper with labellingsystems as a basis for efficient, non-redundantparsing of categorial formalisms in the core mul-tiplicative fragment.
See (Hepple, 1996) for aworked example.8 App l i ca t ion  ~2:  G lue  LanguageDeduct ionIn a line of research beginning with Dalrympleet al (1993), a fragment of linear logic is used asa 'glue language' for assembling sentence mean-ings for LFG analyses in a 'deductive' fashion(enabling, for example, an direct treatment ofquantifier scoping, without need of additionalmechanisms).
Some sample expressions:hates:VX, Y.
(s ~t  hates(X, Y) )o-( (f .,., eX) ?
(g"-% Y) )everyone:  VH, S.(H-,-*t every(person, S))o-(Vx.
(H x))The operator ~ serves to pair together a 'role'with a meaning expression (whose semantictype is shown by a subscript), where a 'role'is essentially a node in a LFG f-structure.
Forour purposes roles can be treated as if they werejust atomic symbols.
For theorem proving pur-poses, the universal quantifiers above can be de-leted: the uppercase variables can be treated543as Prolog-like variables, which become instanti-ated under matching during proof construction;the lowercase variables can be replaced by arbit-rary constants.
Such deletion leaves a residuethat can be treated as just expressions of mul-tiplicative linear logic, with role/meaning pairsserving as 'basic formulae'.
9An observation contrasting the categorial andglue language approaches is that in the cat-egorial case, all that is required of a deductionis the proof term it returns, which (for 'lin-guistic derivations') provides a 'semantic recipe'for combining the lexical meanings of initial for-mulae directly.
However, for the glue languagecase, given the way that meanings are foldedinto the logical expressions, the lexical termsthemselves must participate in a proof for thesemantics of a LFG derivation to be produced.Here is one way that the first-order compila-tion approach might be used for glue languagededuction (other ways are possible).
Firstly,we can take each (quantifier-free) glue term, re-place each role/meaning pair with just the rolecomponent, and associate the resulting formulawith a unique semantic variable.
The set of for-mulae so produced can then undergo the first-order compilation procedure.
Crucially for com-pilation, although some of the role expressionsin the formulae may be ('Prolog-like') variables,they correspond to atomic formulae (so there isno 'hidden structure' that compilation cannotaddress).
A complication here is that occur-rences of a single role variable may end up indifferent first-order formulae.
In any overall de-duction, the binding of these multiple variableinstances must be consistent, but we cannot relyon a global binding context, since alternativeproofs will typically induce distinct (but intern-ally consistent) bindings.
Hence, bindings mustbe handled locally (i.e.
relative to each databaseformula) and combinations will involve mergingof local binding contexts.
Each proof term thattabular deduction returns corresponds to a nat-ural deduction proof over the precompilationformulae.
If we mechanically mirror this pat-tern of proof over the original glue terms (withmeanings, but quantifier-free), a role/meaning9See (Fry, 1997), who uses a proof net method for gluelanguage deduction, for relevant discussion.
This paperalso provides examples of glue language uses that requirea full deductive system for the multiplicative fragment.pair that provides a reading of the original LFGderivation will result.ReferencesNick Benton, Gavin Bierman, Valeria de Paiva& Martin Hyland.
1992.
'Term Assignmentfor Intuitionistic Linear Logic.'
Tech.
Report262, Cambridge University Computer Lab.Mary Dalrymple, John Lamping & VijaySaraswat.
1993.
'LFG semantics via con-straints.'
Proc.
EACL-6, Utrecht.John Fry 1997.
'Negative Polarity Licensingat the Syntax-Semantics Interface.'
Proc.A CL/EA CL-97 Joint Con\]erence, Madrid.Dov M. Gabbay.
1996.
Labelled deductive sys-tems.
Volume 1.
Oxford University Press.Mark Hepple.
1992.
'Chart Parsing LambekGrammars: Modal Extensions and Incre-mentality', Proc.
COLING-92.Mark Hepple.
1995.
'Mixing Modes of Lin-guistic Description in Categorial Grammar.'Proc.
EA CL-7, Dublin.Mark Hepple.
1996.
'A Compilation-ChartMethod for Linear Categorial Deduction.'Proc.
COLING-96, Copenhagen.Mark Hepple.
1998.
'Linear Deduction viaFirst-order Compilation.'
Proc.
First Work-shop on Tabulation in Parsing and Deduc-tion.Esther KSnig.
1994.
'A Hypothetical ReasoningAlgorithm for Linguistic Analysis.'
Journalof Logic and Computation, Vol.
4, No 1.Joachim Lambek.
1958.
'The mathematics ofsentence structure.'
American MathematicalMonthly, 65, pp154-170.Michael Moortgat.
1992.
'Labelled deduct-ive systems for categorial theorem proving.'Proc.
o/Eighth Amsterdam Colloquium, ILLI,University of Amsterdam.Michael Moortgat & Richard T. Oehrle.
1994.
'Adjacency, dependency and order.'
Proc.
ofNinth Amsterdam Colloquium.Glyn Morrill.
1994.
Type Logical Grammar:Categorial Logic of Signs.
Kluwer AcademicPublishers, Dordrecht.Glyn Morrill.
1995.
'Higher-order Linear Lo-gic Programming of Categorial Deduction.'Proc.
of EACL-7, Dublin.544
