Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 35?43,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsFinding Arguing Expressions of Divergent Viewpoints in Online DebatesAmine TrabelsiDepartment of Computing ScienceUniversity of Albertaatrabels@ualberta.caOsmar R.
Za?
?aneDepartment of Computing ScienceUniversity of Albertazaiane@ualberta.caAbstractThis work suggests a fine-grained min-ing of contentious documents, specificallyonline debates, towards a summarizationof contention issues.
We propose a JointTopic Viewpoint model (JTV) for the un-supervised identification and the cluster-ing of arguing expressions according tothe latent topics they discuss and the im-plicit viewpoints they voice.
A set of ex-periments is conducted on online debatesdocuments.
Qualitative and quantitativeevaluations of the model?s output are per-formed in context of different contentionissues.
Analysis of experimental resultsshows the effectiveness of the proposedmodel to automatically and accurately de-tect recurrent patterns of arguing expres-sions in online debate texts.1 IntroductionThis paper addresses the issue of improving thequality of opinion mining from online contentioustexts like the posts in debate sites.
Mining andsummarizing these new resources is crucial, es-pecially when the opinion is related to a subjectthat stimulates divergent viewpoints within peo-ple (e.g.
Healthcare Reform, Same-Sex Marriage).We refer to such subjects as issues of contentions.A contentious issue is ?likely to cause disagree-ment between people?
(cf.
Oxford Dictionaries).Documents such as debate sites?
posts may containmultiple contrastive viewpoints regarding a partic-ular issue of contention.
Table 1 presents an exam-ple of short-text documents expressing divergentopinions where each is exclusively supporting oropposing a healthcare legislation1.1extracted from a Gallup Inc. surveyhttp://www.gallup.com/poll/126521/favor-oppose-obama-healthcare-plan.aspxOpinion in contentious issues is often expressedimplicitly, not necessarily through the usage ofusual negative or positive opinion words, like?bad?
or ?great?.
This makes its extraction a chal-lenging task.
It is usually conveyed through thearguing expression justifying the endorsement ofa particular point of view.
The act of arguing is?to give reasons why you think that something isright/wrong, true/not true, etc, especially to per-suade people that you are right?
(cf.
Oxford Dic-tionaries).
For example, the arguing expression?many people do not have healthcare?, in Table 1,implicitly explains that the reform is intended tofix the problem of uninsured people, and thus, theopinion is probably on the supporting side.
On theother hand, the arguing expression ?it will producetoo much debt?
denotes the negative consequencethat may result from passing the bill, making it onthe opposing side.The automatic identification and clustering ofthese kind of arguing expressions, according totheir topics and the viewpoints they convey, is en-ticing for a variety of application domains.
For in-stance, it can save journalists a substantial amountof work and provide them with drafting elements(viewpoints and associated arguing expressions)about controversial issues.
In addition, it wouldenhance the output quality of the opinion summa-rization task in general.The rest of this paper is organized as follows.Section 2 covers the details of the problem state-ment.
Section 3 explains the key issues in the con-text of recent related work.
Section 4 providesthe technical details of our model, the Joint TopicViewpoint model (JTV) .
Section 5 describes theclustering task that might be used to obtain a fea-sible solution.
Section 6 provides a description ofthe experimental set up.
Section 7 assesses the ad-equacy and the performance of our solution.
Sec-tion 8 concludes the paper.35Support Viewpoint Oppose ViewpointMany people do not have health care The government should not be involvedProvide health care for 30 million people It will produce too much debtThe government should help old people The bill would not help the peopleTable 1: Excerpts of support and opposition opinion to a healthcare bill in the USA.2 Problem StatementThis paper examines the task of mining the topicsand the viewpoints of arguing expressions towardsthe summarization of contentious text.
An exam-ple of a human-made summary of arguing expres-sions (Jones, 2010) on, what is commonly knownas, the Obama healthcare reform is presented inTable 2.
Ultimately, the target is to automaticallygenerate similar summaries given a corpus of con-tentious documents.
However, this paper tack-les the sub-problem of identifying recurrent wordsand phrases expressing arguing and cluster themaccording to their topics and viewpoints.
Thiswould help solve the general problem.
We useTable 2?s examples to define some key conceptswhich can help us formulate this latter.
Here, thecontentious issue yielding the divergent positionsis the Obama healthcare.
The documents are peo-ple?s verbatim responses to the question ?Why doyou favor or oppose a healthcare legislation simi-lar to President Obama?s ?
?.We define a contention question as a questionthat can generate expressions of two or more di-vergent viewpoints as a response.While the previous question explicitly asks forthe reasons (?why?
), we relax this constraint andconsider also usual opinion questions like ?Is thepassing of Obamacare bad for Americans ??
or?Do you favor or oppose Obamacare ?
?.A contentious document is a document thatcontains expressions of one or more divergentviewpoints in response to the contention question.In the context of online debate, a post usually ex-presses one viewpoint, although it can mention ar-guing used to justify a different viewpoint.Table 2 is split into two parts according to theviewpoint: supporting or opposing the healthcarebill.
Each row contains one or more phrases, eachexpressing a reason (or an explanation), e.g.
?costsare out of control?
and ?would help control costs?.Though lexically different, these phrases share acommon hidden theme (or topic), e.g.
insurance?scost, and implicitly convey the same hidden view-point?s semantics, e.g.
support the healthcare bill.Thus, we define an arguing expression as the setof reasons (words or phrases) sharing a commontopic and justifying the same viewpoint regardinga contentious issue.We assume that a viewpoint (e.g.
a column ofTable 2) in a contentious document is a stance, inresponse to a contention question, which is implic-itly expressed by a set of arguing expressions (e.g.rows of a column in Table 2).Thus, the arguing expressions voicing the sameviewpoint differ in their topics, but agree in thestance.
For example, arguing expressions repre-sented by ?system is broken?
and ?costs are outof control?
discuss different topics, i.e.
healthcaresystem and insurance?s cost, but both support thehealthcare bill.
On the other hand, arguing ex-pressions of divergent viewpoints may have sim-ilar topic or may not.
For instance, ?governmentshould help elderly?
and ?government should notbe involved?
share the same topic, i.e.
govern-ment?s role, while conveying opposed viewpoints.Our research problem and objectives in termsof the newly introduced concepts are stated asfollows.
Given a corpus of unlabeled con-tentious documents {doc1, doc2, .., docD}, whereeach document docdexpresses one or more view-points ~vdfrom a set of L possible viewpoints{v1, v2, .., vL}, and each viewpoint vlcan be con-veyed using one or more arguing expressions~?lfrom a set of possible arguing expressions dis-cussing K different topics {?1l, ?2l, .., ?Kl}, theobjective is to perform the following two tasks:1. automatically extracting coherent words andphrases describing any distinct arguing ex-pression ?kl;2. grouping extracted distinct arguing expres-sions ?klfor different topics, k = 1..K, intotheir corresponding viewpoint vl.This paper focuses on the first task while layingthe ground for solving the second one.
In carry-ing out the first task, we must meet the main chal-lenge of recognizing arguing expressions having36Support Viewpoint Oppose ViewpointPeople need health insurance/too many uninsured Will raise cost of insurance/ less affordableSystem is broken/needs to be fixed Does not address real problemsCosts are out of control/would help control costs Need more information on how it worksMoral responsibility to provide/Fair Against big government involvement (general)Would make healthcare more affordable Government should not be involved in healthcareDon?t trust insurance companies Cost the government too muchTable 2: Human-made summary of arguing expressions supporting and opposing Obamacare.the same topic and viewpoint but which are lexi-cally different, e.g.
?provide health care for 30million people ?
and ?
many people do not havehealthcare?.
For this purpose we propose a JointTopic Viewpoint Model (JTV) to account for thedependence structure of topics and viewpoints.3 Related Work3.1 Classifying StancesAn early body of work addresses the challenge ofclassifying viewpoints in contentious or ideolog-ical discourses using supervised techniques (Kimand Hovy, 2007; Lin et al., 2006).
Although themodels give good performances, they remain data-dependent and costly to label, making the unsuper-vised approach more appropriate for the existinghuge quantity of online data.
A similar trend ofstudies scrutinizes the discourse aspect of a docu-ment in order to identify opposed stances (Thomaset al., 2006; Park et al., 2011).
However, thesemethods utilize polarity lexicon to detect opinion-ated text and do not look for arguing expression,which is shown to be useful in recognizing op-posed stances (Somasundaran and Wiebe, 2010).Somasundaran and Wiebe (2010) classify ideolog-ical stances in online debates using a generated ar-guing clues from the Multi Perspective QuestionAnswering (MPQA) opinion corpus2.
Our prob-lem is not to classify documents, but to recognizerecurrent pattern of arguing phrases instead of ar-guing clues.
Moreover, our approach is indepen-dent of any annotated corpora.3.2 Topic Modeling in Reviews DataAnother emerging body of work applies proba-bilistic topic models on reviews data to extract ap-praisal aspects and the corresponding specific sen-timent lexicon.
These kinds of models are usuallyreferred to as joint sentiment/aspect topic models(Jo and Oh, 2011; Titov and McDonald, 2008;2http://mpqa.cs.pitt.edu/Zhao et al., 2010).
Lin and He (2009) propose theJoint Sentiment Topic Model (JST) to model thedependency between sentiment and topics.
Theymake the assumption that topics discussed on a re-view are conditioned on sentiment polarity.
Re-versely, our JTV model assumes that a viewpointendorsement (e.g., oppose reform) is conditionedon the discussed topic (e.g., government?s role)and its application is different from that of JST.Most of the joint aspect sentiment topic models areeither semi-supervised or weakly supervised usingsentiment polarity words (Paradigm lists) to boosttheir efficiency.
In our case, viewpoints are oftenexpressed implicitly and finding specific arguinglexicon for different stances is a challenging taskin itself.
Indeed, our model is enclosed in anotherbody of work that based on a probabilistic TopicModel framework to mine divergent viewpoints.3.3 Topic Modeling in Contentious TextA recent study by Mukherjee and Liu (2012)examines mining contention from discussion fo-rums data where the interaction between differ-ent authors is pivotal.
It attempts to jointlydiscover contention/agreement indicators (CA-Expressions) and topics using three different JointTopic Expressions Models (JTE).
The JTEs?
out-put is used to discover points (topics) of con-tention.
The model supposes that people ex-press agreement or disagreement through CA-expressions.
However, this is not often the casewhen people express their viewpoint via otherchannels than discussion forums like debate sitesor editorials.
Moreover, agreement or disagree-ment may also be conveyed implicitly through ar-guing expressions rejecting or supporting anotheropinion.
JTEs do not model viewpoints and usethe supervised Maximum Entropy model to detectCA-expressions.Recently, Gottipati et al.
(2013) propose a topicmodel to infer human interpretable text in the do-37main of issues using Debatepedia3as a corpus ofevidence.
Debatepedia is an online authored en-cyclopedia to summarize and organize the mainarguments of two possible positions.
The modeltakes advantage of the hierarchical structure of ar-guments in Debatepedia.
Our work aims to modelunstructured online data, with unrestricted num-ber of positions, in order to, ultimately, output aDebatepedia-like summary.The closest work to ours is the one presentedby Paul et al.
(2010).
It introduces the problemof contrastive summarization which is very simi-lar to our stated problem in Section 2.
They pro-pose the Topic Aspect Model (TAM) and use theoutput distributions to compute similarities?
scoresfor sentences.
Scored sentences are used in a mod-ified Random Walk algorithm to generate the sum-mary.
The assumption of TAM is that any wordin the document can exclusively belong to a topic(e.g., government), a viewpoint (e.g., good), both(e.g., involvement) or neither (e.g., think).
How-ever, according to TAM?s generative model, an au-thor would choose his viewpoint and the topic totalk about independently.
Our JTV encodes thedependency between topics and viewpoints.4 Joint Topic Viewpoint ModelLatent Dirichlet Allocation (LDA) (Blei et al.,2003) is one of the most popular topic models usedto mine large text data sets.
It models a documentas a mixture of topics where each topic is a dis-tribution over words.
However, it fails to modelmore complex structures of texts like contentionwhere viewpoints are hidden.We augment LDA to model a contentious doc-ument as a pair of dependent mixtures: a mixtureof arguing topics and a mixture of viewpoints foreach topic.
The assumption is that a document dis-cusses the topics in proportions, (e.g.
80% gov-ernment?s role, 20% insurance?s cost).
Moreover,as explained in Section 2, each one of these top-ics can be shared by divergent arguing expres-sions conveying different viewpoints.
We supposethat for each discussed topic in the document, theviewpoints are expressed in proportions.
For in-stance, 70% of the document?s text discussing thegovernment?s role expresses an opposing view-point to the reform while 30% of it conveys a sup-porting viewpoint.
Thus, each term in a docu-ment is assigned a pair topic-viewpoint label (e.g.3http://dbp.idebate.orgFigure 1: The JTV?s graphical model (plate nota-tion)?government?s role-oppose reform?).
A term is aword or a phrase i.e.
n-grams (n>1).
For eachtopic-viewpoint pair, the model generates a topic-viewpoint probability distribution over terms.
Thistopic-viewpoint distribution would corresponds towhat we define as an arguing expression in Sec-tion 2, i.e.
a set of terms sharing a common topicand justifying the same viewpoint regarding a con-tentious issue.
The Joint Topic Viewpoint (JTV),is similar to the Joint Sentiment Topic model (JST)(Lin and He, 2009), as it models documents as twodependent mixtures.
However, here we conditionviewpoints on topics instead of conditioning top-ics on sentiment.
Moreover, the application is dif-ferent from that of JST which intend to model re-views data.Formally, assume that a corpus contains D doc-uments d1..D, where each document is a term?svector ~wdof size Nd; each term wdnin a docu-ment belongs to the corpus vocabulary of distinctterms of size V .
Let K be the total number of top-ics andL be the total number of viewpoints.
Let ?ddenote the probabilities (proportions) of K topicsunder a document d; ?dkbe the probability distri-butions (proportions) of L viewpoints for a topick in the document d (the number of viewpoints Lis the same for all topics); and ?klbe the multino-mial probability distribution over terms associatedwith a topic k and a viewpoint l. The generative38process (see.
the JTV graphical model in Figure1) is the following:?
for each topic k and viewpoint l, draw amultinomial distribution over the vocabularyV : ?kl?
Dir(?);?
for each document d,draw a topic mixture ?d?
Dir(?
)for each topic k, draw a viewpoint mixture?dk?
Dir(?
)for each term wdn, sample a topic assignmentzdn?Mult(?d); sample a viewpoint assign-ment vdn?Mult(?dzdn); and sample a termwdn?Mult(?zdnvdn).We use fixed symmetric Dirichlet?s parameters ?,?
and ?.
They can be interpreted as the priorcounts of: terms assigned to viewpoint l and topick in a document; a particular term w assigned totopic k and viewpoint l within the corpus; termsassigned to a topic k in a document, respectively.In order to learn the hidden JTV?s parameters?kl, ?dkand ?d, we draw on approximate in-ference as exact inference is intractable (Blei etal., 2003).
We use the collapsed Gibbs Sampling(Griffiths and Steyvers, 2004), a Markov ChainMonte Carlo algorithm.
The collapsed Gibbs sam-pler integrate out all parameters ?, ?
and ?
in thejoint distribution of the model and converge to astationary posterior distribution over viewpoints?assignments ~v and all topics?
assignments ~z in thecorpus.
It iterates on each current observed tokenwiand samples each corresponding viand zigivenall the previous sampled assignments in the model~v?i, ~z?iand observed ~w?i, where ~v = {vi, ~v?i},~z = {zi, ~z?i}, and ~w = {wi, ~w?i}.
The derivedsampling equation is:p(zi= k, vi= l|~z?i, ~v?i, wi= t, ~w?i) ?n(t)kl,?i+ ?V?t=1n(t)kl,?i+ V ?.n(l)dk,?i+ ?L?l=1n(l)dk,?i+ L?.n(k)d,?i+ ?
(1)where n(t)kl,?iis the number of times term t was as-signed to topic k and the viewpoint l in the corpus;n(l)dk,?iis the number of times viewpoint l of topic kwas observed in document d; and n(k)d,?iis the num-ber of times topic k was observed in document d.All these counts are computed excluding the cur-rent token i, which is indicated by the symbol ?i.AW GM ObCareView pt allow not illegal not bad not#doc 213 136 44 54 129 54tot.#toks 44482 10666 22733avg.#toks.doc.127.45 108.83 124.22Table 3: Statistics on the three used data setsAfter the convergence of the Gibbs algorithm, theparameters ?, ?
and ?
are estimated using the lastobtained sample.5 Clustering Arguing ExpressionsAlthough we are not tackling the task of cluster-ing arguing expressions according to their view-points in this paper (Task 2 in Section 2), we ex-plain how the structure of JTV lays the ground forperforming it.
We mentioned in the previous Sec-tion that an inferred topic-viewpoint distribution?klcan be assimilated to an arguing expression.For convenience, we will use ?arguing expression?and ?topic-viewpoint?
interchangeably to refer tothe topic-viewpoint distribution.Indeed, two topic-viewpoint ?kland ?k?l, hav-ing different topics k and k?, do not necessarilyexpress the same viewpoint, despite the fact thatthey both have the same index l. The reason stemsfrom the nested structure of the model, where thegeneration of the viewpoint assignments for a par-ticular topic k is completely independent from thatof topic k?.
In other words, the model does nottrace and match the viewpoint labeling along dif-ferent topics.
Nevertheless, the JTV can still helpovercome this problem.
According to the JTV?sstructure, a topic-viewpoint ?kl, is more similarin distribution to a divergent topic-viewpoint ?kl?,related to the same topic k, than to any other topic-viewpoint ?k?
?, corresponding to a different topick?.
Therefore, we can formulate the problem ofclustering arguments as a constrained clusteringproblem (Basu et al., 2008).
The goal is to groupthe similar topics-viewpoints ?kls into L clusters(number of viewpoints), given the constraint thatthe ?kls of the same topic k should not belong tothe same cluster.
The similarity between the topic-viewpoint distributions can be measured using theJensen-Shannon Divergence (Bishop, 2006).396 Experimental Set upIn order to evaluate the performances of the JTVmodel, we experiment with three different cor-pora of contentious documents.
Recall, we assumethat any input document to the JTV is answer-ing a contentious question which makes it con-tentious according to the definitions stated in Sec-tion 2.
Posts in online debate websites, like ?creat-edebate.com?
or ?debate.org?, match this require-ment.
They correspond to online users?
takes ona clearly stated contention question making themmore adequate for our matter than debate forums?posts.
These latter contain online interactions be-tween users where the objective is not necessar-ily answering a contention question but rather dis-cussing a contentious topic.
Classifying a docu-ment as contentious or not is not an issue consid-ered in this paper but can be explored in our futurework.
Table 3 describes the used data sets.Assault Weapons (AW)4: includes posts ex-tracted from ?debate.com?.
The contention ques-tion is ?Should assault weapons be allowed in theUnited States as means of allowing individuals todefend themselves??.
The viewpoints are either?should be allowed?
or ?should not be allowed?.Gay Marriage (GM)5: contains posts from?debate.com?
related to the contention question?Should gay marriage be illegal??.
The posts?stance are either ?should be illegal?
or ?should belegal?.Obama Healthcare (ObCare)6: includes postsfrom ?debate.org?
responding to the contentionquestion ?Is the passing of ObamaCare bad for theAmerican public??.
Stances are either ?bad?
or?not bad?.Paul et al.
(2010) stress out the importance ofnegation features in detecting contrastive view-points.
Thus, we performed a simple treatmentof merging any negation indicators, like ?noth-ing?, ?no one?, ?never?, etc., found in text withthe following occurring word to form a single to-ken.
Moreover, we merge the negation ?not?
withany Auxiliary verb (e.g., is, was, could, will) pre-ceding it.
Then, we removed the stop-words.4http://www.debate.org/opinions/should-assault-weapons-be-allowed-in-the-united-states-as-means-of-allowing-individuals-to-defend-themselves5http://www.debate.org/opinions/should-gay-marriage-be-illegal6http://www.debate.org/opinions/is-the-passing-of-obamacare-bad-for-the-american-publicThroughout the experiments below, the JTV?shyperparameters are set to fixed values.
The ?
isset, according to Steyvers and Griffiths?s (Steyversand Griffiths, 2007) hyperparameters settings, to50/L, where L is the number of viewpoints.
?and ?
are adjusted manually, to give reasonableresults, and are both set to 0.01.
Along the exper-iments, we try different number of topics K. Thenumber of viewpoints L is equal to 2.
The TAMmodel (Paul et al., 2010) (Section 3.3) is run as ameans of comparison during the evaluation proce-dure.
Its default parameters are used.7 Model Evaluation7.1 Qualitative EvaluationTables 4 and 5 present the inferred topic-viewpoints words, i.e.
arguing expressions, byJTV for the Obama Healthcare and Gay Marriagedata sets, respectively.
We set a number of topicsof K = 3 for the former and K = 2 for the lat-ter.
The number of viewpoints is L = 2 for bothdata sets.
For the Obamacare data set, we run themodel with balanced number of posts from ?bad?and ?not bad?
stances.
Each topic-viewpoint pair(e.g.
Topic 1-view 1) is represented by the set oftop terms.
The terms are sorted in descending or-der according to their probabilities.
Inferred prob-abilities over topics, and over viewpoints for eachtopic, are also reported.
We try to qualitativelyobserve the distinctiveness of each arguing (topic-viewpoint) and assess the coherence in terms ofthe topic discussed and the viewpoint conveyedand its divergence with the corresponding pair-element.In both Tables 4 and 5, most of the topic-viewpoint pairs, corresponding to a same topic,are conveying opposite stances.
For instance, tak-ing a closer look to the original data suggests thatTopic3-view5 (Table 4) criticizes the healthcaresystem and compares it to the other countries (e.g.a sample from the original documents:?revise ourhealthcare system with the most efficient systemsin the world?).
On the other side, Topic 3-view6 explains the negative consequence of obamacareon middle class, e.g.
?ObamaCare was supposedto help the poor and the middle class.
In theend, the businesses fire all the people because ofthe ObamaCare taxes and then IT IS THE MID-DLE CLASS PEOPLE WHO SUFFER!?.
Simi-larly, Topic1-view1 advances the question of thecosts that the bill will cause at the level of people40Topic 1 0.328 Topic 2 0.334 Topic 3 0.337view 1 0.64 view 2 0.36 view 3 0.59 view 4 0.41 view 5 0.63 view 6 0.37pay universal people insurance healthcare obamacarepeople care insurance health obamacare healthcaremake life good companies system governmentmoney law free medicare americans classcosts act health doctors affordable taxesgovernment poor work plan country/world middleTable 4: JTV?s generated topics-viewpoints (arguing expressions) from Obamacare data setTopic 1 0.50 Topic 2 0.50view 1 0.47 view 2 0.53 view 3 0.60 view 4 0.40marriage marriage people gaylove man gay childrenlife woman religion peoplecouples god shouldnt sexperson bible wrong parentslegal illegal rights naturalmarried wrong government humanhappy love marry populationsamesex homosexual freedom oppositeillegal word argument raceTable 5: JTV?s generated topics-viewpoints (arguing expressions) from Gay Marriage data setand government, e.g.
?The government doesn?teven have enough money to pay of a fraction of thetowering debt that we?ve accrued?, ?forcing peo-ple to buy insurance or pay an even higher tax willmake more families poverty stricken?.
However,Topic1-view2 stresses out the importance of hav-ing a universal healthcare, e.g.
?ObamaCare cer-tainly has problems, but just like any law, we canwork on these problems and make the law better(..).
The fundamental goal is Universal Health-care (...)?, ?If you were poor and had a herniathat needed surgery, you need money to pay forit.
Denying Obama?s Plan for a health care sys-tem means you cannot pay for it which means youwill DIE.?.
Similar pattern is observed in Topic 2.The results on Gay Marriage 1 dataset (Table5) encompass the notion of shared topic betweendivergent arguing expressions (Section 2) moreclearly than the results obtained from Obamacare.This may be related to the nature of the contention.For instance, Topic 1 in Table 5 is ?the concept ofmarriage?
and it is shared by both view 1 and view2.
However, the concept is perceived differentlyaccording to the stance.
The terms in view 1 (notillegal) suggest that marriage is about love, hap-piness and it wouldn?t disturb anyone?s life (as itmay be read from original data).
The view 2 (il-legal) may emphasize the notion of a marriage asa union between man and woman and the sacred-ness aspect of it (god, bible).
Similarly, Topic 2is about ?people who are gay?.
The terms in view3 (not illegal) may advocate that religious argu-ments from opposing stance do not make senseand that gay people are free and have the samerights as other people.
Moreover, the governmentshould not interfere in this matter.
View 4 (illegal)suggests that gay people can not have childrenwhich raises the problem of population decrease.It also casts doubt on their ability to be parents.7.2 Quantitative EvaluationWe assess the ability of the model to fit the onlinedebate data and generate distinct topic-viewpointpairs by comparing it with TAM which modelsalso the topic-viewpoint dimension.7.2.1 Held-Out PerplexityWe use the perplexity criterion to measure the abil-ity of the learned topic model to fit a new held-out data.
Perplexity assesses the generalizationperformance and, subsequently, provides a com-41(a) AW (b) GM (c) ObCareFigure 2: JVT and TAM?s perplexity plots for three different data setsFigure 3: Average of overall topic-viewpoint di-vergences of JTV and TAMparing framework of learned topic models.
Thelower the perplexity, the less ?perplexed?
is themodel by unseen data and the better the general-ization.
It algebraically corresponds to the inversegeometrical mean of the test corpus?
terms likeli-hoods given the learned model parameters (Hein-rich, 2009).
We compute the perplexity under es-timated parameters of JTV and compare it to thatof TAM for our three unigrams data sets (Section6).Figure 2 exhibits, for each corpus, the perplex-ity plot as function of the number of topics Kfor JTV and TAM.
Note that for each K, we runthe model 50 times.
The drawn perplexity corre-sponds to the average perplexity on the 50 runswhere each run compute one-fold perplexity froma 10-fold cross-validation.
The figures show evi-dence that the JTV outperforms TAM for all datasets, used in the experimentation.7.2.2 Kullback-Leibler DivergenceKullback-Leibler (KL) Divergence is used to mea-sure the degree of separation between two proba-bility distributions.
We utilize it to assess the dis-tinctiveness of generated topic-viewpoint by JTVand TAM.
This is an indicator of a good ag-gregation of arguing expressions.
We computean overall-divergence quantity, which is an av-erage KL-Divergence between all pairs of topic-viewpoint distributions, for JTV and TAM andcompare them.
Figure 3 illustrates the results forall datasets.
Quantities are averages on 20 runs ofthe models.
Both models are run with a numberof topics K = 5.
Comparing JTV and TAM, wenotice that the overall-divergence of JTV?s topic-viewpoint is significantly (p ?
value < 0.01)higher for all data sets.
This result reveals a betterquality of our JTV extracting process of arguingexpressions (the first task stated in Section 2)8 ConclusionWe suggested a fine grained probabilistic frame-work for improving the quality of opinion min-ing from online contention texts.
We proposeda Joint Topic Viewpoint model (JTV) for the un-supervised detection of arguing expressions.
Un-like common approaches the proposed model fo-cuses on arguing expressions that are implicitlydescribed in unstructured text according to the la-tent topics they discuss and the implicit viewpointsthey voice.
The qualitative and quantitative analy-sis of the experimental results show the effective-ness of our (JTV) model in generating informativesummaries of recurrent topics and viewpoints pat-terns in online debates?
texts.
Future study needsto give more insights into the clustering of arguingexpressions according to their viewpoints, as wellas their automatic extractive summary.ReferencesSugato Basu, Ian Davidson, and Kiri Wagstaff.
2008.Constrained Clustering: Advances in Algorithms,42Theory, and Applications.
Chapman & Hall/CRC,1 edition.Christopher M. Bishop.
2006.
Pattern Recognitionand Machine Learning (Information Science andStatistics).
Springer-Verlag New York, Inc., Secau-cus, NJ, USA.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet allocation.
Journal of Ma-chine Learning Research, 3:993?1022, March.Yi Fang, Luo Si, Naveen Somasundaram, and ZhengtaoYu.
2012.
Mining contrastive opinions on politicaltexts using cross-perspective topic model.
In Pro-ceedings of the fifth ACM international conferenceon Web search and data mining, WSDM ?12, pages63?72, New York, NY, USA.
ACM.Swapna Gottipati, Minghui Qiu, Yanchuan Sim, JingJiang, and Noah A. Smith.
2013.
Learning topicsand positions from debatepedia.
In Proceedings ofConference on Empirical Methods in Natural Lan-guage Processing, EMNLP ?13.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences of the United States of Amer-ica, 101(Suppl 1):5228?5235.Gregor Heinrich.
2009.
Parameter estimation fortext analysis.
Technical report, Fraunhofer IGD,September.Yohan Jo and Alice H. Oh.
2011.
Aspect and sen-timent unification model for online review analysis.In Proceedings of the fourth ACM international con-ference on Web search and data mining, WSDM ?11,pages 815?824, New York, NY, USA.
ACM.Jeffrey M. Jones.
2010.
In u.s., 45% favor, 48% op-pose obama healthcare plan.
Gallup, March.Soo-Min Kim and Eduard H Hovy.
2007.
Crystal: An-alyzing predictive opinions on the web.
In EMNLP-CoNLL, pages 1056?1064.Chenghua Lin and Yulan He.
2009.
Joint senti-ment/topic model for sentiment analysis.
In Pro-ceedings of the 18th ACM conference on Informa-tion and knowledge management, CIKM ?09, pages375?384, New York, NY, USA.
ACM.Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side are youon?
: identifying perspectives at the document andsentence levels.
In Proceedings of the Tenth Con-ference on Computational Natural Language Learn-ing, CoNLL-X ?06, pages 109?116, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Arjun Mukherjee and Bing Liu.
2012.
Mining con-tentions from discussions and debates.
In Proceed-ings of the 18th ACM SIGKDD international con-ference on Knowledge discovery and data mining,KDD ?12, pages 841?849, New York, NY, USA.ACM.Souneil Park, KyungSoon Lee, and Junehwa Song.2011.
Contrasting opposing views of news articleson contentious issues.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies- Volume 1, HLT ?11, pages 340?349, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Michael J. Paul, ChengXiang Zhai, and Roxana Girju.2010.
Summarizing contrastive viewpoints in opin-ionated text.
In Proceedings of the 2010 Confer-ence on Empirical Methods in Natural LanguageProcessing, EMNLP ?10, pages 66?76, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Swapna Somasundaran and Janyce Wiebe.
2010.
Rec-ognizing stances in ideological on-line debates.
InProceedings of the NAACL HLT 2010 Workshop onComputational Approaches to Analysis and Gener-ation of Emotion in Text, CAAGET ?10, pages 116?124, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Mark Steyvers and Tom Griffiths.
2007.
Probabilistictopic models.
Handbook of latent semantic analysis,427(7):424?440.Matt Thomas, Bo Pang, and Lillian Lee.
2006.
Getout the vote: determining support or opposition fromcongressional floor-debate transcripts.
In Proceed-ings of the 2006 Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?06,pages 327?335, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Ivan Titov and Ryan McDonald.
2008.
Modelingonline reviews with multi-grain topic models.
InProceedings of the 17th international conference onWorld Wide Web, WWW ?08, pages 111?120, NewYork, NY, USA.
ACM.Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-ing Li.
2010.
Jointly modeling aspects and opin-ions with a maxent-lda hybrid.
In Proceedings ofthe 2010 Conference on Empirical Methods in Nat-ural Language Processing, EMNLP ?10, pages 56?65, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.43
