Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 129?132,Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLPEnglish-Chinese Bi-Directional OOV Translationbased on Web Mining and Supervised LearningYuejie Zhang, Yang Wang and Xiangyang XueSchool of Computer ScienceShanghai Key Laboratory of Intelligent Information ProcessingFudan University, Shanghai 200433, P.R.
China{yjzhang,072021176,xyxue}@fudan.edu.cnAbstractIn Cross-Language Information Retrieval(CLIR), Out-of-Vocabulary (OOV) detectionand translation pair relevance evaluation stillremain as key problems.
In this paper, an Eng-lish-Chinese Bi-Directional OOV translationmodel is presented, which utilizes Web miningas the corpus source to collect translation pairsand combines supervised learning to evaluatetheir association degree.
The experimental re-sults show that the proposed model can suc-cessfully filter the most possible translationcandidate with the lower computational cost,and improve the OOV translation ranking ef-fect, especially for popular new words.1 IntroductionIn Cross-Language Information Retrieval (CLIR),most of queries are generally composed of shortterms, in which there are many Out-of-Vocabulary (OOV) terms like named entities,new words, terminologies and so on.
The transla-tion quality of OOVs directly influences the pre-cision of querying relevant multilingual informa-tion.
Therefore, OOV translation has become avery important and challenging issue in CLIR.The translation of OOVs can either be ac-quired from parallel or comparable corpus (Lee,2006) or mining from Web (Lu, 2004).
However,how to evaluate the degree of association be-tween source query term and its target translationis quite important.
In this paper, an OOV transla-tion model is established based on the combina-tion pattern of Web mining and translation rank-ing.
Given an OOV, its related information aregotten from search results by search engine, fromwhich the possible translation terms in targetlanguage can be extracted and then rankedthrough supervised learning such as SupportVector Machine (SVM) and Ranking-SVM (Cao,2006).
The basic framework of the translationmodel is shown in Figure 1.Figure 1.
The basic framework of English-Chinese Bi-Directional OOV translation model.2 Related Research WorkWith the rapid growth of Web information, in-creasing new terms and terminologies cannot befound in bilingual dictionaries.
The state-of-artOOV translation strategies tend to use Web itselfas a big corpus (Wang, 2004; Zhang, 2004).
Thequick and direct way of getting required informa-tion from Web pages is to use search engines,such as Google, Altavista or Yahoo.
Therefore,many OOV translation models based on Webmining are proposed by researchers (Fang, 2006;Wu, 2007).By introducing supervised learning mechan-ism, the relevance between original OOV termand extracted candidate translation can be accu-rately evaluated.
Meanwhile, the model proposedexhibits better applicability and can also be ap-plied in processing OOVs with different classes.3 Chinese OOV Extraction based onPAT-TreeFor a language that has no words boundary likeChinese, PAT-Tree data structure is adopted toextract OOV terms (Chien, 1997).
The most out-standing property of this structure is its SemiInfinite String, which can store all the semi-strings of whole corpus in a binary tree.
In thistree, branch nodes indicate direction of search129and child nodes store information about indexand frequency of semi infinite strings.
Withcommon strings being extracted, large amountsof noisy terms and fragments are also extracted.For example, when searching for the translationof English abbreviation term ?FDA?, some noisyChinese terms are extracted, such as ?????
(17 times), ??????
(16 times), ???????
(9 times).
In order to filter noisy fragments,the simplified Local-Maxima algorithm is used(Wang, 2004).4 Translation Ranking based on Super-vised Learning4.1 Ranking by Classification and OrdinalRegressionBased on the extracted terms, the correct transla-tion can be chosen further.
A direct option is torank them by their frequency or length.
It workswell when the OOV term has a unique meaningand all the Web snippets are about the same topic.However, in much more cases only the highlyrelated fragments of OOV terms can be found,rather than their correct translations.
To evaluatethe relevance of translation pair precisely, SVMand Ranking-SVM are employed as classifierand ordinal regression model respectively.4.2 Feature RepresentationThe same feature set is utilized by SVM andRanking-SVM.
(1) Term frequency: fq denotes the frequency ofOOV to be translated in all the Web snippetsof search results.
tfi indicates the number ofthe translation candidate in all the snippets.dfi represents the number of Web snippetsthat contains the candidate.
dft means thenumber of snippets that contains both OOVto be translated and the candidate.
(2) Term length: Len( ) is the length of the can-didate.
(3) Cooccurrence Distance: C-Dist is the aver-age distance between the OOV query and thetranslation candidate, computed as follows.
( )-tSum DistC Distdf=            (1)where Sum(Dist) is the sum of distance ineach translation pair of every snippet.
(4) Length Ratio: This is the ratio of OOV querylength and translation candidate length.
(5) Rank Value:i.
Top Rank (T-Rank): The rank of snippetthat first contains the candidate.
Thisvalue indicates the rank given by searchengine.ii.
Average_Rank (A-Rank): It is the aver-age position of candidate in snippets ofsearch results, shown as follows.
( )idfRankSumRankA =?
(2)where Sum(Rank) denotes the sum ofevery single rank value of snippets thatcontains the candidate.iii.
Simple_Rank (S-Rank): It is computedbased on Rank(i)=tfi*Len(i), which aimsat investigating the impact of these twofeatures on ranking translation.iv.
R-Rank: This rank method is utilized as acomparison basis, computed as follows.
( )OOVnnffLSRankR ??+?=?
??
1            (3)where ?
is set as 0.25 empirically, |Sn|represents the length of candidate term,L is the largest length of candidate terms,fn is tfi, and foov is fq in Feature (1).v.
Df_Rank (D-Rank): It is similar to S-Rank and computed based on Rank(i)=dfi *Len(i).
(6) Mark feature: Within a certain distance(usually less than 10 characters) between theoriginal OOV and candidate, if there is sucha term like ???
?, ????
?, ??????,?????
?, ?????
?, ????
?, ????
?, ????
?, ?????
?, this feature willbe labeled as ?+1?, else ?-1?
instead.Among these features above, some featurescome from search engine like (1) and (5) andsome ones from heuristic rules like (3) and (6).Through the establishment of feature set, thetranslation candidate can be optimized efficientlyand the noisy information can also be filtered.5 Experiment and Analysis5.1 Data SetFor the performance evaluation of Chinese-English OOV translation, the corpus of NER taskin SIGHAN 2008 provided by Peking Universityis used.
The whole corpus contains 19,866 per-son names, 22,212 location names and 7,837 or-ganization names, from which 100 person names,100 location names and 100 organization namesare selected for testing.
Meanwhile, 300 Englishnamed entities are chosen randomly from theterms of 9 categories, which include movie name,book title, organization name, brand name, ter-minology, idiom, rare animal name, person name130and so on.
These new terms are used as the test-ing data for English-Chinese OOV translation.5.2 Evaluation MetricsThree parameters are used for the evaluation oftranslation and ranking candidates.translatedbetotermsOOVofnumbertotalnstranslatioNtopinntranslatiocorrectofnumberRateInclusionN=??
(4)( )translatedbetotermfornstranslatiocorrectofnumbernstranslatioRtopinntransaltiocorrectofnumbertermecisionPrRii=?
(5)( )translatedbetotermsOOVofnumbertotaltermecisionPrRecisionPrRTii?=?=?1(6)where T denotes the number of testing entities.The first one is a measurement for translationand the others are used for ranking measurement.5.3 Experiment on Parameter SettingFrequency and length are two crucial features fortranslation candidates.
To get the most relatedterms into top 10 before the final ranking, a pre-rank testing is performed based on S-Rank, R-Rank and D-Rank.
It can be seen from Figure 2that the pre-rank by D-Rank exhibits better per-formance in translation experiment.Figure 2.
The impact of different Pre-Rank man-ners on English-Chinese OOV translation.In search results, for some English OOV termssuch as ?BYOB(????
)?, there are few candi-dates with better quality in top 20 snippets.Therefore, in order to find how many snippetsare suitable in translation, the experiment onsnippet number is performed.
It can be observedfrom Figure 3 that the best performance can beobtained by utilizing 200 snippets.Figure 3.
The impact of different snippet numberon English-Chinese OOV translation.5.4 Experiment On English-Chinese Bi-Directional OOV TranslationThe experimental results on 300 English newterms are shown in Table 1.N-Inclusion-Rate English-Chinese OOV TranslationTop-1 0.313Top-3 0.587Top-5 0.627Top-7 0.707Top-9 0.763Table 1.
The experimental results on English-Chinese OOV translation.The experimental results on 300 Chinesenamed entities are shown in Table 2.N-Inclusion-RatePersonNameLocationNameOrganizationNameTop-1  0.210   0.510   0.110Top-3 0.390 0.800 0.280Top-5 0.490 0.900 0.400Top-7 0.530 0.920 0.480Top-9 0.540 0.930 0.630Table 2.
The experimental results on Chinese-English OOV translation.It can be observed from Table 2 that the per-formance of Chinese location name translation ismuch higher than the other two categories.
Thisis because most of the location names are famouscities or countries.
The experimental resultsabove demonstrate that the proposed model canbe applicable in all kinds of OOV terms.5.5 Experiment on RankingIn SVM-based and Ranking-SVM-based rankingexperiment, the statistics on training data areshown in Table 3.
For SVM training data, the?Related?
candidates are neglected.
The experi-mental results on ranking in English-Chinese andChinese-English OOV translation are shown inTable 4 and 5 respectively.Number ofCandidates Correct Related IndifferentEnglish-Chinese 234 141 250Chinese-English 240 144 373Table 3.
Statistics of training data for ranking.English-ChineseTop-1InclusionTop-3InclusionR-PrecisionD-Rank 0.313 0.587 0.417T-Rank 0.217 0.430 0.217SVM 0.530 0.687 0.533Ranking-SVM 0.550 0.687 0.547Table 4.
The experimental results on ranking inEnglish-Chinese OOV translation.131Chinese-EnglishTop-1InclusionTop-3InclusionR-PrecisionTF-Rank 0.277 0.490 0.287T-Rank 0.197 0.387 0.207SVM 0.347 0.587 0.347Ranking-SVM 0.357 0.613 0.387Table 5.
The experimental results on ranking inChinese-English OOV translation.From the experiments above, it can be con-cluded that the supervised learning significantlyoutperform the conventional ranking strategies.5.6 Analysis and DiscussionThrough analysis about the experimental resultsin extraction and ranking, it can be observed thatthe OOV translation quality is highly related tothe following aspects.
(1) The translation results are related to thesearch engine used, especially for some spe-cific OOV terms.
For example, given a queryOOV term ?????
?, the mining resultbased on Google in China is ?three directlinks?, while some meaningless informationis mined by the other engines like Live Trans.
(2) Some terms are conventional terminologiesand cannot be translated literally.
For exam-ple, ?woman pace-setter?, a proper name withthe particular Chinese characteristic, shouldbe translated into ??????
?, rather than???????
or ????.
(3) The proposed model is sensitive to the nota-bility degree of OOV term.
For famous per-son name and book title, the translation per-formance is very promising.
However, forother OOV terms with lower notability, suchas ??????
and ????
?, the correcttranslation cannot even be retrieved bysearch engine.
(4) Word Sense Disambiguation (WSD) shouldbe added to improve the whole translationperformance.
Although most of OOVs haveunique semantic definition, there are still afew OOVs with ambiguity.
For example,?Rice?
can either be a person name or a kindof food.
Another example is ?AARP?, whichalso has two kinds of meaning, that is, ?????????
and ???????
?.6 Conclusions and Future WorkIn this paper, the proposed model improves theacquirement ability for OOV translation throughWeb mining and solves the translation pair eval-uation problem in a novel way by introducingsupervised learning in translation ranking.
In ad-dition, it is very significant to apply the keytechniques in traditional machine translation intoOOV translation, such as OOV recognition, sta-tistical machine learning, alignment of sentenceand phoneme, and WSD.
The merits of thesetechniques should be integrated.
All these as-pects above will become the research focus inour future work.AcknowledgmentsThis paper is supported by National NaturalScience Foundation of China (No.
60773124),National Science and Technology Pillar Programof China (No.
2007BAH09B03) and ShanghaiMunicipal R&D Foundation (No.
08dz1500109).Yang Wang is the corresponding author.ReferencesChun-Jen Lee, Jason S. Chang, and Jyh-Shing R. Jang.2006.
Alignment of Bilingual Named Entities inParallel Corpora Using Statistical Models andMultiple Knowledge Sources.
ACM Transactionson Asian Language Processing, 5(2):121-145.Gaolin Fang, Hao Yu, and Fumihito Nishino.
2006.Chinese-English Term Translation Mining Basedon Semantic Prediction.
In Proceedings of theCOLING/ACL on Main Conference Poster Ses-sions, pp.199-206.Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, Wen-Hsiang Lu, and Lee-Feng Chien.
2004.
TranslatingUnknown Cross-Lingual Queries in Digital Libra-ries Using a Web-based Approach.
In Proceedingsof the 4th ACM/IEEE-CS Joint Conference on Dig-ital Libraries, pp.108-116.Jian-Cheng Wu and Jason S. Chang.
2007.
Learningto Find English to Chinese Transliterations on theWeb.
In Proceedings of the 2007 Joint Conferenceon Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, pp.996-1004.L.
F. Chien.
1997.
PAT-Tree-Based Keyword Extrac-tion for Chinese Information Retrieval.
In Proceed-ings of SIGIR?97, pp.50-58.Wen-Hsiang Lu and Lee-Feng Chien.
2004.
AnchorText Mining for Translation of Web Queries: ATransitive Translation Approach.
ACM Transac-tions on Information Systems, 22(2): 242-269.Ying Zhang and Phil Vines.
2004.
Detection andTranslation of OOV Terms Prior to Query Time.
InProceedings of SIGIR?04, pp.524-525.Yunbo Cao, Jun Xu, Tie-Yan LIU, Hang Li, YalouHUANG, and Hsiao-Wuen HON.
2006.
AdaptingRanking SVM to Document Retrieval.
In Proceed-ings of SIGIR?06, pp.186-193.132
