Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 161?167,Sydney, July 2006. c?2006 Association for Computational LinguisticsRelationship between Utterances and ?Enthusiasm?in Non-task-oriented Conversational DialogueRyoko TOKUHISAToyota Central R&D Labs., INC.Nagakute Aichi JAPANtokuhisa@mosk.tytlabs.co.jpRyuta TERASHIMAToyota Central R&D Labs., INC.Nagakute Aichi JAPANryuta@mosk.tytlabs.co.jpAbstractThe goal of this paper is to show howto accomplish a more enjoyable and en-thusiastic dialogue through the analysisof human-to-human conversational dia-logues.
We first created a conversationaldialogue corpus annotated with two typesof tags: one type indicates the particu-lar aspects of the utterance itself, whilethe other indicates the degree of enthusi-asm.
We then investigated the relationshipbetween these tags.
Our results indicatethat affective and cooperative utterancesare significant to enthusiastic dialogue.1 IntroductionFor a non-task-oriented conversational dialoguesystem (e.g.
home robots), we should strive fora dialogue strategy that is both enjoyable andenthusiastic, as well as efficient.
Many studieshave been conducted on efficient dialogue strate-gies (Walker et al, 1998; Litman et al, 2000; Ko-matani et al, 2002), but it is not clear how to ac-complish a more ?human-like enthusiasm?
for aconversational dialogue.
The goal of this paper isto show the types of utterances that contribute toenthusiasm in conversational dialogues.2 Corpus AnnotationWe created a conversational corpus annotated withtwo types of tags: one type indicates particularaspects of the utterance itself, while the other in-dicates the degree of enthusiasm in the dialogue.This section describes our corpus and taggingscheme in detail.2.1 Corpus CollectionAs a result of previous works, several conversa-tional dialogue corpora have been collected withvarious settings (Graff and Bird, 2000; TSENG,2001).
The largest conversational dialogue cor-pus is the Switchboard Corpus, which consists ofabout 2400 conversational English dialogues be-tween two unfamiliar speakers over the telephoneon one of 70 topics (e.g.
pets, family life, educa-tion, gun control, etc.
).Our corpus was collected from face-to-face in-teraction between two unfamiliar speakers.
Thereasons were 1) face-to-face interaction increasesthe number of enthusiastic utterances, relative tolimited conversational channel interaction such asover the telephone; 2) the interaction between un-familiar speakers reduces the enthusiasm resultingfrom unobserved reasons during the recording; 3)the exchange in a twoparty dialogue will be sim-pler than that of a multiparty dialogue.We created a corpus containing ten conversa-tional dialogues that were spoken by an operator(thirties, female) and one of ten subjects (twentiesto sixties, equal numbers of males and females).Before beginning the recording session, the sub-ject chose three cards from fifteen cards on the fol-lowing topics:Food, Travel, Sport, Hobbies, Movies, Prizes,TV Programs, Family, Books, School, Music,Pets, Shopping, Recent Purchases, CelebritiesStraying from the selected topic was permitted,because these topic cards were only ever intendedas a prompt to start the dialogue.
Thus, we col-lected ten dialogues, each about 20 minutes long.For convenience, in this paper, we refer to the op-erator as speaker1, and the subject as speaker2.1612.2 Annotation of DAs and RRs2.2.1 Definition of tagging schemeDialogue Acts (DAs) and Rhetorical Relations(RRs) are well-known tagging schemes for anno-tating an utterance or a sentence.
DAs are tags thatpertain to the function of an utterance itself, whileRRs indicate the relationship between sentences orutterances.
We adopted both tags to allow us to an-alyze the aspects of utterances in various ways, butadapted them slightly for our particular needs.The DA annotations were based on SWBD-DAMSL and MRDA (Jurafsky et al, 1997;Dhillon et al, 2004).
The SWBD-DAMSL isthe DA tagset for labeling a conversational dia-logue.
The Switchboard Corpus mentioned abovewas annotated with SWBD-DAMSL.
On the otherhand, MRDA is the DA tagset for labeling thedialogue of a meeting between multiple partici-pants.
Table 1 shows the correspondence betweenSWBD-DAMSL/MRDA and our DAs1.
We de-scribe some of the major adaptations below.The tags pertaining to questions: In SWBD-DAMSL and MRDA, the tags pertaining to ques-tions were classified by the type of their form(e.g.
Wh-question).
We re-categorized them intorequest and confirm in terms of the ?act?
forJapanese.The tags pertaining to responses: We subdividedAccept and Reject into objective responses (ac-cept,denial) and subjective responses (agree, dis-agree).The emotional tags: We added tags that indicatethe expression of admiration and interest.The overlap tags with the RRs definition: Wedid not use any tags (e.g.
Summary), that over-lapped the RR definition.Consequently, we defined 47 DAs for analyzing aconversational dialogue.The RR annotations were based on the rhetor-ical relation defined in Rhetorical Structure The-ory (RST) (Mann and Thompson, 1988; Stent andAllen, 2000).
Our RR definition was based onlyon informational level relation defined in RST be-cause we annotated the intentional level with DAs.Table 2 shows the correspondence between the in-formational relation of RST and our RRs.
We de-scribe some of the major adaptations below.Subdivide evaluation: The evaluation reflects thedegree of enthusiasm in the dialogue, so we di-1The tags listed in italics are based on SWBD-DAMSLwhile those in boldface are based on MRDA.Table 1: Dialogue Act DefinitionSWBD-DAMSL/MRDAOur DAs DefinitionStatement nonopinioninform objectivefactinform non opin-ionStatement opin-ioninform subjectiveelementinform opinionWh-Question request objectivefactrequest non opin-ionYes-No-questionrequest agreement request agreementopinionOpen-Questionconfirm objectivefactconfirm non opin-ionOr-Question confirm agreement confirm agreementopinionAccept accept accept non opinionagree accept opinionReject denial denial non opiniondisagree denial opinionnot marked express admiration inform admirationSummary DEL.
(mark as RR) ????
?Table 2: Rhetorical Relation DefinitionMann?s RST Our RRs definitionevaluation(positive)U2 is a positive evaluationabout U1Evaluation evaluation(negative)U2 is a negative evalua-tion about U1evaluation(neutral)U2 is neutral evaluationabout U1Volitionalcausevolitionalcause-effectU2 is a volitional action,and U1 cause U2Volitional re-sultNo Definition addition U2 consists of a part of U1vided the Evaluation into three types of evaluation(positive/negative/neutral).Integrate the causal relations: We use a di-rected graph representation for RR annotations, sothat we integrate Non-volitional cause and Non-volitional result into non-volitional cause-effect,and Volitional cause and Volitional result into vo-litional cause-effect.Add addition relation: The RRs initially repre-sent the structure of the written text, segmentedinto clause-like units.
Therefore, they do not coverthose cases in which one clause is uttered by onespeaker, but communicatively completed by an-other.
So, we added an addition to our RRs.
Thefollowing is an example of addition.speaker A: the lunch in our company cafeteriaspeaker B: is good value for moneyWe defined 16 RRs as a result of these adaptations.162Context: The father of speaker2 likes watching movies, and so established a home theater system in their living room.1:speaker2 [addition] that s why my family really loves movies these days <inform objective fact>you watch them one after another, don t you?
<signal understanding><confirm objective fact>2:speaker1[apposition][elaboration]about 2 or 3 movies per week <accept><inform objective fact>so many?
<signal understanding><exclamation><confirm objective fact>[evaluation3:speaker24:speaker1we sometimes watch many more <accept><inform objective fact>5:speaker2 [elaboration]I suppose you <signal understanding>6:speaker1I suppose it s nice to watch them in your homewithout interruptions, right?<signal understanding><confirmagreement><confirm objective fact>[volitionalelaboration](neutral)]elaboration]cause-effect]Figure 1: Example of Dialogue annotated with DAs and RRs (Originally in Japanese)2.2.2 Annotation of DAs and RRsDAs and RRs are annotated using the MMAX2Annotation Tool 2 (Muller and Strube, 2003).
Fig-ure 1 shows an example of our corpus annotatedwith DAs and RRs.
The ?
?
symbol in Figure 1indicates a DA, while the [ ] symbol indicates anRR.
Below, we describe our annotation process forDAs and RRs.Step 1.
Utterance Segmentation: All the utter-ances in the dialogue are segmented into DA seg-ments, each of which we define as an utterance.In Figure 1, the utterance is surrounded with asquare.
In this step, we also eliminated backchan-nels from the exchange.Step 2.
Annotation of DAs: DAs are annotatedto all utterances.
In those cases in which one DAalone cannot represent an utterance, two or moreDAs are used (see Figure 1 line 2).Step 3.
Annotation of Adjacency Pairs: Adja-cency pairs (APs) are labeled.
An AP consists oftwo utterances where each part is produced by adifferent speaker.
In Figure 1, the solid and dottedlines correspond to links between the APs.Step 4.
Annotation of RRs: RRs on APs are la-beled.
A solid line indicates an AP that is labeledwith RRs, while a dotted line indicates an AP thatis not labeled with RRs.
If a single RR cannotrepresent the type of the relationship, two or moreRRs are used.2.3 Annotation of Enthusiasm2.3.1 Related Work on Annotating the degreeof enthusiasmWrede et al annotated Involvement to the ICSIMeeting Recorder Corpus (Wrede and Shriberg,2This supports multilevel annotation and the creationof a relationship between utterances.
http://www.eml-research.de/english/research/nlp/down-load/mmax.phputterance... backchannel...Part Of Dialogue...PODDialoguespeaker2speaker1Ui-4 Ui-3 Ui-2 Ui-1 Ui Ui+1 Ui+2 Ui+3 Ui+4PODi-2PODi-1PODiPODi+1PODi+2Si-2Si-1S iSi+1Si+2Score of enthusiasm...SFigure 2: Rating the score of the enthusiasm2003b; Wrede and Shriberg, 2003a).
In theirmethod, a rater judges involvement (agreement,disagreement, other) or Not especially involved orDon?t Know, by listening to each utterance with-out the context of the dialogue.
In the exper-iment, nine raters provided ratings on 45 utter-ances.
Inter-rater agreement between Involved andNot especially involved yielded a Kappa of ?=.59(p<.01), but 13 of the 45 utterances (28.9%) wererated as Don?t Know by at least one of the raters.For automatic detection, it is certainly effective torate Involvement without context.
However, the re-sults indicate that it is quite difficult to recognizeInvolvement from a single utterance.
Moreover,the fluctuation of Involvement can not be recog-nized by this method because Involvement is cate-gorized into five categories only.2.3.2 Our Method of Annotating EnthusiasmIn this section, we propose a method for eval-uating the degree of enthusiasm.
We describe theprocess for evaluating the degree of enthusiasm.Step 1.
Rating the score of enthusiasm for PODA rater estimates a score of the enthusiasmcorresponding to the part of dialogue (POD),which is a series of five utterances.
As men-tioned above, the backchannels are not re-garded as utterances.
In Figure 2, Sidenotes163the score for the enthusiasm of PODi.
Thevalue of the score can be from 10 to 90.90 ... Extreme70 ... Moderate50 ... Neutral30 ... Low10 ... NoWhen rating the score, a rater must obey thefollowing four rules.1.
Listen to each POD more than threetimes.2.
Perform estimation based on the entirePOD and not just part of the POD.3.
Be sure that own ratings represented aconsistent continuum.4.
Estimate as participants, not as side-participants.We did not give any definitions or examplesto rate the enthusiasm, a rater estimated ascore based on their subjective determination.Step 2.
Calculate the score of enthusiasm for anutteranceThe score of enthusiasm for an utterance Uiis given by the average of the scores of thePODs that contain utterance Ui.V (Ui) =15i+2?j=i?2Sj(1)Step 3.
Calculate the degree of enthusiasm for anutterance and an adjacency pairIn this paper, we deal with all the degrees ofenthusiasm as a normalized score, which wecall Enthusiasm, because different raters mayhave different absolute levels of enthusiasm.Then, Enthusiasm for Uiis given as follows:E(Ui) =V (Ui) ?
V (U)?
(2)whereV (U) =1nn?i=1V (Ui)?
=???
?1nn?i=1{V (Ui) ?
V (U)}2n denotes the number of utterances in the di-alogue.In addition, Enthusiasm for APiis given bythe average of Enthusiasms of the utteranceswhere are APi.E(APi) =12{E(Uj) + E(Uk)} (3)Ujand Ukdenote the utterances in APi.3 Estimation of Annotated Corpus3.1 Reliability of DAs and RRsWe examined the inter-annotator reliability fortwo annotators3 for DAs, RRs and APs, using fourdialogues mentioned above.
Before the start of theinvestigation, one annotator segmented a dialogueinto utterances.
The number of segmented utter-ances was 697.
The annotaters annotated them asdescribed in steps 2 to 4 of Section 2.2.2.DAs annotation: We can not apply the Kappastatistics since it cannot be applied to multiple tagannotations.
We then apply formula 4 to examinethe reliability.ag.
= (AgreedDAs) ?
2Total of DAs annotated by A1andA2?100 (4)The result of agreement was 1542 DAs (65.5%)from a total of 2355 DAs.
The major reasons forthe disagreement were as follows.?
Disagreement of subjective/objective ... 124(15.3%)?
Disagreement of request/confirm ... 112(13.8%)?
Disagreement of partial/whole ... 72(8.9%)Building APs: We examined the agreement ofbuilding APs between utterances.
The result ofagreement was 536 APs (85.2%) from the total ofthe 629 APs that were built by the annotators.
Thisresult shows that the building of APs is reliable.RRs annotation: We also examined the agree-ment of RRs annotation.
We applied formula 5to this examination.ag.
= (AgreedRRs) ?
2Total of RRs annotated by A1andA2?100 (5)As a result, we found agreement for 576 RRs(59.6%) out of a total of 967 RRs.3We refer to these annotators as A1 and A2.
A1 is one ofthe authors of this paper.164Table 3: Correlation between random rating andsequential ratingcorrelation coefficientspeaker1 speaker2twenties,female 0.833 0.881twenties,male 0.971 0.950sixties,female 0.972 0.973sixties,male 0.971 0.958-3-2-10123timeEnthusiasmR3(speaker1) R3(speaker2)R4(speaker1) R4(speaker2)Figure 3: Enthusiasm of dialogue of speaker1 andspeaker2(thirties,female)3.2 Estimation Context Influence on therating of EnthusiasmIn order to examine the influence of the context onthe rating of Enthusiasm, one rater noted Enthusi-asm under two conditions: 1) Listening to PODsrandomly, and 2) Listening to PODs sequentiallyas dialogue.
Table 3 shows the correlation be-tween the random rating and the sequential rating.The correlation coefficient was calculated for theEnthusiasm of each of the two participants.
The?speaker1?
shows the correlation of the Enthusi-asm rated as speaker1, and ?speaker2?
shows thecorrelation of the Enthusiasm rated as speaker2.This was found to be approximately 0.9 in bothcases.
These results show that Enthusiasm can beestimated stably and that the context has little in-fluence.4 Relationship between DAs/RRs andEnthusiasmWe investigated the relationship betweenDAs/RRs and Enthusiasm, using four dia-logues.
The DAs/RRs corpus annotated by A1was used in this analysis because A1 is oneof the authors of this paper and has a betterknowledge of the DAs and RRs tagging schemethan A2.
The Enthusiasm corpus annotated byR3 was used because we found that R4 ratedEnthusiasm based on non-subjective reasons:after the examination of the rating, R4 said thatspeaker1 spoke enthusiastically but that it seemedunnatural because speaker1 had to manage therecording of the dialogue, which appears in theresults as speaker1?s Enthusiasm as annotated byR4 as a notable difference (see Figure 3).Figure 4 and 5 show the ratio of the frequencyof DAs and RRs in each of the levels of Enthu-siasm over a range of 0.5.
If DAs and RRs wereevenly annotated for any level of Enthusiasm, thegraph will be completely even.
However, thegraph shows the right side as being higher if theDAs and RRs increase as Enthusiasm increases.Conversely, the graph shows the left side as beinghigher if the DAs and RRs fall as Enthusiasm in-creases.
The number in Figure 4 and 5 indicatesthe average Enthusiasm for each DA and RR.
Ifthe average is positive, it means that the frequencyof the DAs and RRs is high in that part in whichEnthusiasm is positive.
In contrast, if the averageis negative, it means that the frequency of the DAsand RRs is high in that part in which Enthusiasmis negative.We determined the following two points aboutthe tendency of the DAs frequency.Tendency of subjective and objective DAs: Theratio of the frequency of those DAs related to sub-jective elements tends to increase as Enthusiasmincreases (see *1 in Figure 4).
In contrast, the ra-tio of the frequency of those DAs pertaining to ob-jective matters tends to decrease (see *2 in Figure4) or equilibrate as Enthusiasm increases (see *3in Figure 4) .
We can thus conclude that those ex-changes related to subjective elements increases inthe enthusiastic dialogue, but those related to ob-jective elements decrease or equilibrate.Tendency of affective DAs: The ratio of the fre-quency of those DAs related to the affective con-tents tends to increase as Enthusiasm increases(see *4 in Figure 4).
However, express admiration,which is also related to affective contents, tends todecrease (see *5 in Figure 4).
We then analyzedseveral instances of admiration.
As a result, wefound that the prosodic characteristic of admira-tion utterance will cause this tendency.Furthermore, we noted the following two pointsabout the tendency of the RRs frequency.Tendency of additional utterances: The ratio ofthe frequency of addition, which completes the165signalunderstanding acceptinformobjective fact confirmobjective fact informsubjectiveelementagreerequestfactexclamationshow interestconfirmagreementexpressadmirationsignal partial nounderstandingsympathyneutralrequestrepetitionconfirm other'ssbjective denialshow humorDialogue ActFrequency(ratio)-2.5 ?-2.0 -2.0?-1.5 -1.5 ?-1.0 -1.0?-0.5 -0.5 ?0.0 0.0?0.5 0.5 ?1.0 1.0?1.5 1.5 ?2.00.03 -0.12 -0.03 -0.110.30 0.12-0.07 0.04 0.29 0.11 -0.62 -0.06 -0.04 0.03 0.27 0.70 0.14 1.07*2*2*2*1 *1 *1*4 *4*5*4*3*3*1Figure 4: Frequency of DAs per Enthusiasm00.10.20.30.40.50.60.7elaboration additionappositionnonvolitionalcause-effectinterpretationvolitional cause-effectevaluation(positive)antithesisinstancecircumstanceevaluation(neutral)summaryRhetorical RelationFrequency(ratio)-2.5 ?-2.0 -2.0?-1.5 -1.5 ?-1.0 -1.0?-0.5 -0.5 ?0 0?0.5 0.5 ?1.0 1.0?1.5 1.5 ?2.0    *6 *7Figure 5: Frequency of RRs per EnthusiasmContext:Mother of speaker2 does not cook dinner when thefather is out.1 speaker1: but if he s there then she2 speaker2: cooks a really delicious dinner3 speaker1: wowFigure 6: Example of additionother participant?s utterance, tends to increase asEnthusiasm increases (see *6 in Figure 5).
Figure6 shows a dialogue example.
There are additionrelations between lines 1 and 2.
This shows thatthe participant makes an utterance cooperativelyby completing the other?s utterances in enthusias-tic dialogues.
Such cooperative utterance is a sig-nificant component of enthusiastic dialogues.Tendency of positive evaluation: The ratio of thefrequency of positive evaluation tends to increaseat lower Enthusiasm and higher Enthusiasm (see*7 in Figure 5).
We analyzed some instances ofContext:About a hamster and its exercise instrument.1 speaker2: two hamsters run together in their exercise wheel2 speaker2: they run up and down and side by side3 speaker1: but surely they can t they run together if they aren t4 speaker2: exactly5 speaker2: one gets carried along if it stops when the othercontinues to run6 speaker1: is it?
does it lean forward?getting along very well?7 speaker2: yes8 speaker2: sometimes it falls out9 speaker1: that s so cuteFigure 7: Example of positive evaluationpositive evaluation, we then found that the speakertries to arouse the dialogue by an utterance ofpositive evaluation at lower Enthusiasm, and thespeaker summarizes the previous discourse with apositive evaluation at higher Enthusiasm.
Figure7 shows an example of positive evaluation in theenthusiastic dialogue.
In this case, speaker1 ex-166presses positive evaluation on line 9 about the el-ement on line 8.
The utterance on line 9 also hasthe function of expressing an overall positive eval-uation of the previous discourse.5 Conclusion and Future ResearchWe analyzed the relationship between utterancesand the degree of enthusiasm in human-to-humanconversational dialogue.
We first created a conver-sational dialogue corpus annotated with two typesof tags: DAs/RRs and Enthusiasm.
The DA andRR tagging scheme was adapted from the defini-tion given in a previous work, and an Enthusiasmtagging scheme is proposed.
Our method of ratingEnthusiasm enables the observation of the fluctu-ation of Enthusiasm, which enables the detailedanalysis of the relationship between utterances andEnthusiasm.
The result of the analysis shows thefrequency of objective and subjective utterancesrelated to the level of Enthusiasm.
We also foundthat affective and cooperative utterances are sig-nificant in an enthusiastic dialogue.In this paper, we only analyzed the relationshipbetween DAs/RRs and Enthusiasm, but we expectthe non-linguistic-feature related with Enthusiasmso that we would analyze the relationship in futureresearch.
And, we try to achieve more reliable an-notation by reviewing our tagging scheme.
Fur-thermore, we would apply the results of the analy-sis to our conversational dialogue system.ReferencesRajdip Dhillon, Sonali Bhagat, Hannah Carvey, andElizabeth Shriberg.
2004.
Meeting RecorderProject: Dialog Act Labeling Guide.
ICSI Techni-cal Report, (TR-04-002).David Graff and Steven Bird.
2000.
Many Uses, ManyAnnotations for Large Speech Corpora: Switch-board and TDT as Case Studies.
LREC2000.Dan Jurafsky, Liz Shriberg, and Debra Biasca.1997.
Switchboard SWBD-DAMSL Shallow-Discourse-Function Annotation Coders Manual.www.dcs.shef.ac.uk/nlp/amities/files/bib/ics-tr-97-02.pdf.Kazunori Komatani, Tatsuya Kawahara, Ryosuke Ito,and Hiroshi Okuno.
2002.
Efficient Dialogue Strat-egy to Find Users?
Intended Items from InformationQuery Results.
In Proceedings of the COLING.Diane Litman, Satinder Singh, Michael Kearns, andMarilyn Walker.
2000.
NJFun: A ReinforcementLearning Spoken Dialogue System.
In Proceedingsof the ANLP/NAACL.William C. Mann and Sandra A. Thompson.
1988.Rhetorical Structure Theory: Toward a FunctionalTheory of Text Organization.
Text, 8(3):243?281.Christoph Muller and Michael Strube.
2003.
Multi-Level Annotation in MMAX.
In Proceedings of the4th SIGdial Workshop on Discourse and Dialogue.Amanda Stent and James Allen.
2000.
Annotating Ar-gumentation Acts in Spoken Dialog.
Technical Re-port 740.Shu-Chuan TSENG.
2001.
Toward a Large Sponta-neous Mandarin Dialogue Corpus.
In Proceedingsof the 2nd SIGdial Workshop on Discourse and Dia-logue.Marilyn A. Walker, Jeanne C. Fromer, and ShrikanthNarayanan.
1998.
Learning Optimal DialogueStrategies: A Case Study of a Spoken DialogueAgent for Email.
In Proceedings of COLING/ACL.Britta Wrede and Elizabeth Shriberg.
2003a.
Spotting?Hot Spots?
in Meetings: Human Judgements andProsodic Cues.
Eurospeech-03, pages 2805?2808.Britta Wrede and Elizabeth Shriberg.
2003b.
The Re-lationship between Dialogue Acts and Hot Spots inMeetings.
IEEE ASRU Workshop.167
