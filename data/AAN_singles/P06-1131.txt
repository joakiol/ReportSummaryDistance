Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1041?1048,Sydney, July 2006. c?2006 Association for Computational LinguisticsIncremental generation of spatial referring expressionsin situated dialog?John D. KelleherDublin Institute of TechnologyDublin, Irelandjohn.kelleher@comp.dit.ieGeert-Jan M. KruijffDFKI GmbHSaarbru?cken, Germanygj@dfki.deAbstractThis paper presents an approach to incrementallygenerating locative expressions.
It addresses the is-sue of combinatorial explosion inherent in the con-struction of relational context models by: (a) con-textually defining the set of objects in the contextthat may function as a landmark, and (b) sequenc-ing the order in which spatial relations are consid-ered using a cognitively motivated hierarchy of re-lations, and visual and discourse salience.1 IntroductionOur long-term goal is to develop conversationalrobots with whom we can interact through natural,fluent, visually situated dialog.
An inherent as-pect of visually situated dialog is reference to ob-jects located in the physical environment (Moratzand Tenbrink, 2006).
In this paper, we present acomputational approach to the generation of spa-tial locative expressions in such situated contexts.The simplest form of locative expression is aprepositional phrase, modifying a noun phrase tolocate an object.
(1) illustrates the type of locativewe focus on generating.
In this paper we use theterm target (T) to refer to the object that is beinglocated by a spatial expression and the term land-mark (L) to refer to the object relative to whichthe target?s location is described.
(1) a. the book [T] on the table [L]Generating locative expressions is part of thegeneral field of generating referring expressions(GRE).
Most GRE algorithms deal with the sameproblem: given a domain description and a targetobject, generate a description of the target objectthat distinguishes it from the other objects in thedomain.
We use distractor objects to indicate the?The research reported here was supported by the CoSyproject, EU FP6 IST ?Cognitive Systems?
FP6-004250-IP.objects in the context excluding the target that ata given point in processing fulfill the descriptionof the target object that has been generated.
Thedescription generated is said to be distinguishingif the set of distractor objects is empty.Several GRE algorithms have addressed the is-sue of generating locative expressions (Dale andHaddock, 1991; Horacek, 1997; Gardent, 2002;Krahmer and Theune, 2002; Varges, 2004).
How-ever, all these algorithms assume the GRE compo-nent has access to a predefined scene model.
Fora conversational robot operating in dynamic envi-ronments this assumption is unrealistic.
If a robotwishes to generate a contextually appropriate ref-erence it cannot assume the availability of a fixedscene model, rather it must dynamically constructone.
However, constructing a model containing allthe relationships between all the entities in the do-main is prone to combinatorial explosion, both interms of the number objects in the context (the lo-cation of each object in the scene must be checkedagainst all the other objects in the scene) and num-ber of inter-object spatial relations (as a greaternumber of spatial relations will require a greaternumber of comparisons between each pair of ob-jects).1 Also, the context free a priori constructionof such an exhaustive scene model is cognitivelyimplausible.
Psychological research indicates thatspatial relations are not preattentively perceptuallyavailable (Treisman and Gormican, 1988), theirperception requires attention (Logan, 1994; Lo-gan, 1995).
Subjects appear to construct contex-tually dependent reduced relational scene models,not exhaustive context free models.Contributions We present an approach to in-1In English, the vast majority of spatial locatives are bi-nary, some notable exceptions include: between, amongst etc.However, we will not deal with these exceptions in this paper.1041crementally generating locative expressions.
It ad-dresses the issue of combinatorial explosion in-herent in relational scene model construction byincrementally creating a series of reduced scenemodels.
Within each scene model only one spatialrelation is considered and only a subset of objectsare considered as candidate landmarks.
This re-duces both the number of relations that must becomputed over each object pair and the number ofobject pairs.
The decision as to which relationsshould be included in each scene model is guidedby a cognitively motivated hierarchy of spatial re-lations.
The set of candidate landmarks in a givenscene is dependent on the set of objects in thescene that fulfil the description of the target objectand the relation that is being considered.Overview ?2 presents some relevant back-ground data.
?3 presents our GRE approach.
?4illustrates the framework on a worked exampleand expands on some of the issues relevant to theframework.
We end with conclusions.2 DataIf we consider that English has more than eightyspatial prepositions (omitting compounds such asright next to) (Landau, 1996), the combinatorialaspect of relational scene model construction be-comes apparent.
It should be noted that for ourpurposes, the situation is somewhat easier becausea distinction can be made between static and dy-namic prepositions: static prepositions primarily2denote the location of an object, dynamic preposi-tions primarily denote the path of an object (Jack-endoff, 1983; Herskovits, 1986), see (2).
How-ever, even focusing just on the set of static prepo-sitions does not remove the combinatorial issueseffecting the construction of a scene model.
(2) a. the tree is behind [static] the houseb.
the man walked across [dyn.]
the roadIn general, static prepositions can be dividedinto two sets: topological and projective.
Topo-logical prepositions are the category of preposi-tions referring to a region that is proximal to thelandmark; e.g., at, near, etc.
Often, the distinc-tions between the semantics of the different topo-logical prepositions is based on pragmatic con-traints, e.g.
the use of at licences the target to be2Static prepositions can be used in dynamic contexts, e.g.the man ran behind the house, and dynamic prepositions canbe used in static ones, e.g.
the tree lay across the road.in contact with the landmark, whereas the use ofnear does not.
Projective prepositions describe aregion projected from the landmark in a particulardirection; e.g., to the right of, to the left of.
Thespecification of the direction is dependent on theframe of reference being used (Herskovits, 1986).Static prepositions have both qualitative andquantitative semantic properties.
The qualitativeaspect is evident when they are used to denote anobject by contrasting its location with that of thedistractor objects.
Using Figure 1 as visual con-text, the locative expression the circle on the leftof the square illustrates the contrastive semanticsof a projective preposition, as only one of the cir-cles in the scene is located in that region.
TakingFigure 2, the locative expression the circle nearthe black square shows the contrastive semanticsof a topological preposition.
Again, of the two cir-cles in the scene only one of them may be appro-priately described as being near the black square,the other circle is more appropriately described asbeing near the white square.
The quantitative as-pect is evident when a static preposition denotesan object using a relative scale.
In Figure 3 thelocative the circle to the right of the square showsthe relative semantics of a projective preposition.Although both the circles are located to the right ofthe square we can distinguish them based on theirlocation in the region.
Figure 3 also illustrates therelative semantics of a topological preposition Fig-ure 3.
We can apply a description like the circlenear the square to either circle if none other werepresent.
However, if both are present we can inter-pret the reference based on relative proximity tothe landmark the square.Figure 1: Visual context illustrating contrastive se-mantics of projective prepositionsFigure 2: Visual context illustrating contrastive se-mantics of topological prepositionsFigure 3: Visual context illustrating relative se-mantics of topological and projective prepositions10423 ApproachWe base our GRE approach on an extension ofthe incremental algorithm (Dale and Reiter, 1995).The motivation for basing our approach on this al-gorithm is its polynomial complexity.
The algo-rithm iterates through the properties of the targetand for each property computes the set of distrac-tor objects for which (a) the conjunction of theproperties selected so far, and (b) the current prop-erty hold.
A property is added to the list of se-lected properties if it reduces the size of the dis-tractor object set.
The algorithm succeeds whenall the distractors have been ruled out, it fails if allthe properties have been processed and there arestill some distractor objects.
The algorithm canbe refined by ordering the checking of propertiesaccording to fixed preferences, e.g.
first a taxo-nomic description of the target, second an absoluteproperty such as colour, third a relative propertysuch as size.
(Dale and Reiter, 1995) also stipulatethat the type description of the target should be in-cluded in the description even if its inclusion doesnot make the target distinguishable.We extend the original incremental algorithmin two ways.
First we integrate a model of ob-ject salience by modifying the condition underwhich a description is deemed to be distinguish-ing: it is, if all the distractors have been ruled outor if the salience of the target object is greaterthan the highest salience score ascribed to anyof the current distractors.
This is motivated bythe observation that people can easily resolve un-derdetermined references using salience (Duweand Strohner, 1997).
We model the influenceof visual and discourse salience using a functionsalience(L), Equation 1.
The function returnsa value between 0 and 1 to represent the relativesalience of a landmark L in the scene.
The relativesalience of an object is the average of its visualsalience (Svis ) and discourse salience (Sdisc),salience(L) = (Svis(L) + Sdisc(L))/2 (1)Visual salience Svis is computed using the algo-rithm of (Kelleher and van Genabith, 2004).
Com-puting a relative salience for each object in a sceneis based on its perceivable size and its centralityrelative to the viewer focus of attention, return-ing scores in the range of 0 to 1.
The discoursesalience (Sdisc) of an object is computed basedon recency of mention (Hajicova?, 1993) exceptwe represent the maximum overall salience in thescene as 1, and use 0 to indicate that the landmarkis not salient in the current context.
Algorithm 1gives the basic algorithm with salience.Algorithm 1 The Basic Incremental AlgorithmRequire: T = target object; D = set of distractor objects.Initialise: P = {type, colour, size}; DESC = {}for i = 0 to |P | doif T salience() >MAXDISTRACTORSALIENCE thenDistinguishing description generatedif type(x) !?
DESC thenDESC = DESC ?
type(x)end ifreturn DESCelseD?
= {x : x ?
D,P i(x) = P i(T )}if |D?| < |D| thenDESC = DESC ?
P i(T )D = {x : x ?
D,P i(x) = P i(T )}end ifend ifend forFailed to generate distinguishing descriptionreturn DESCSecondly, we extend the incremental algorithmin how we construct the context model used bythe algorithm.
The context model determines toa large degree the output of the incremental al-gorithm.
However, Dale and Reiter do not de-fine how this set should be constructed, they onlywrite: ?
[w]e define the context set to be the set ofentities that the hearer is currently assumed to beattending to?
(Dale and Reiter, 1995, pg.
236).Before applying the incremental algorithm wemust construct a context model in which we cancheck whether or not the description generateddistinguishes the target object.
To constrain thecombinatorial explosion in relational scene modelconstruction we construct a series of reducedscene models, rather than one complex exhaus-tive model.
This construction is driven by a hi-erarchy of spatial relations and the partitioning ofthe context model into objects that may and maynot function as landmarks.
These two componentsare developed below.
?3.1 discusses a hierarchy ofspatial relations, and ?3.2 presents a classificationof landmarks and uses these groupings to create adefinition of a distinguishing locative description.In ?3.3 we give the generation algorithm integrat-ing these components.3.1 Cognitive Ordering of ContextsPsychological research indicates that spatial re-lations are not preattentively perceptually avail-able (Treisman and Gormican, 1988).
Rather,their perception requires attention (Logan, 1994;1043Logan, 1995).
These findings point to subjectsconstructing contextually dependent reduced rela-tional scene models, rather than an exhaustive con-text free model.
Mimicking this, we have devel-oped an approach to context model constructionthat constrains the combinatorial explosion inher-ent in the construction of relational context mod-els by incrementally building a series of reducedcontext models.
Each context model focuses ona different spatial relation.
The ordering of thespatial relations is based on the cognitive load ofinterpreting the relation.
Below we motivate anddevelop the ordering of relations used.We can reasonably asssume that it takes lesseffort to describe one object than two.
Follow-ing the Principle of Minimal Cooperative Effort(Clark and Wilkes-Gibbs, 1986), one should onlyuse a locative expression when there is no distin-guishing description of the target object using asimple feature based approach.
Also, the Princi-ple of Sensitivity (Dale and Reiter, 1995) statesthat when producing a referring expression, oneshould prefer features the hearer is known to beable to interpret and see.
This points to a prefer-ence, due to cognitive load, for descriptions thatidentify an object using purely physical and easilyperceivable features ahead of descriptions that usespatial expressions.
Experimental results supportthis (van der Sluis and Krahmer, 2004).Similarly, we can distinguish between the cog-nitive loads of processing different forms of spa-tial relations.
In comparing the cognitive load as-sociated with different spatial relations it is im-portant to recognize that they are represented andprocessed at several levels of abstraction.
For ex-ample, the geometric level, where metric prop-erties are dealt with, the functional level, wherethe specific properties of spatial entities derivingfrom their functions in space are considered, andthe pragmatic level, which gathers the underly-ing principles that people use in order to discardwrong relations or to deduce more information(Edwards and Moulin, 1998).
Our discussion isgrounded at the geometric level.Focusing on static prepositions, we assumetopological prepositions have a lower percep-tual load than projective ones, as perceivingtwo objects being close to each other is eas-ier than the processing required to handle frameof reference ambiguity (Carlson-Radvansky andIrwin, 1994; Carlson-Radvansky and Logan,1997).
Figure 4 lists the preferences, furtherFigure 4: Cognitive loaddiscerning objectstype as the easi-est to process, be-fore absolute grad-able predicates (e.g.color), which is stilleasier than relativegradable predicates(e.g.
size) (Dale and Reiter, 1995).We can refine the topological versus projectivepreference further if we consider their contrastiveand relative uses of these relations (?2).
Perceiv-ing and interpreting a contrastive use of a spatialrelation is computationally easier than judging arelative use.
Finally, within projective preposi-tions, psycholinguistic data indicates a perceptu-ally based ordering of the relations: above/beloware easier to percieve and interpret than in frontof /behind which in turn are easier than to the rightof /to the left of (Bryant et al, 1992; Gapp, 1995).In sum, we propose the following ordering: topo-logical contrastive < topological relative < pro-jective constrastive < projective relative.For each level of this hierarchy we require acomputational model of the semantics of the rela-tion at that level that accomodates both contrastiveand relative representations.
In ?2 we noted thatthe distinctions between the semantics of the dif-ferent topological prepositions is often based onfunctional and pragmatic issues.3 Currently, how-ever, more psycholinguistic data is required to dis-tinguish the cognitive load associated with the dif-ferent topological prepositions.
We use the modelof topological proximity developed in (Kelleher etal., 2006) to model all the relations at this level.Using this model we can define the extent of a re-gion proximal to an object.
If the target or one ofthe distractor objects is the only object within theregion of proximity around a given landmark thisis taken to model a contrastive use of a topologi-cal relation relative to that landmark.
If the land-mark?s region of proximity contains more than oneobject from the target and distractor object set thenit is a relative use of a topological relation.
Wehandle the issue of frame of reference ambiguityand model the semantics of projective prepostionsusing the framework developed in (Kelleher et al,2006).
Here again, the contrastive-relative distinc-3See inter alia (Talmy, 1983; Herskovits, 1986; Vande-loise, 1991; Fillmore, 1997; Garrod et al, 1999) for morediscussion on these differences1044tion is dependent on the number of objects withinthe region of space defined by the preposition.3.2 Landmarks and DescriptionsIf we want to use a locative expression, we mustchoose another object in the scene to function aslandmark.
An implicit assumption in selecting alandmark is that the hearer can easily identify andlocate the object within the context.
A landmarkcan be: the speaker (3)a, the hearer (3)b, the scene(3)c, an object in the scene (3)d, or a group of ob-jects in the scene (3)e.4(3) a. the ball on my right [speaker]b. the ball to your left [hearer]c. the ball on the right [scene]d. the ball to the left of the box [an objectin the scene]e. the ball in the middle [group of ob-jects]Currently, we need new empirical research tosee if there is a preference order between theselandmark categories.
Intuitively, in most situa-tions, either of the interlocutors are ideal land-marks because the speaker can naturally assumethat the hearer is aware of the speaker?s locationand their own.
Focusing on instances where anobject in the scene is used as a landmark, severalauthors (Talmy, 1983; Landau, 1996; Gapp, 1995)have noted a target-landmark asymmetry: gener-ally, the landmark object is more permanently lo-cated, larger, and taken to have greater geometriccomplexity.
These characteristics are indicative ofsalient objects and empirical results support thiscorrelation between object salience and landmarkselection (Beun and Cremers, 1998).
However, thesalience of an object is intrinsically linked to thecontext it is embedded in.
For example, in Figure5 the ball has a relatively high salience, becauseit is a singleton, despite the fact that it is smallerand geometrically less complex than the other fig-ures.
Moreover, in this scene it is the only objectthat can function as a landmark without recourseto using the scene itself or a grouping of objects.Clearly, deciding which objects in a given con-text are suitable to function as landmarks is a com-plex and contextually dependent process.
Someof the factors effecting this decision are object4See (Gorniak and Roy, 2004) for further discussion onthe use of spatial extrema of the scene and groups of objectsin the scene as landmarksFigure 5: Landmark saliencesalience and the functional relationships betweenobjects.
However, one basic constraint on land-mark selection is that the landmark should be dis-tinguishable from the target.
For example, giventhe context in Figure 5 and all other factors be-ing equal, using a locative such as the man to theleft of the man would be much less helpful thanusing the man to the right of the ball.
Followingthis observation, we treat an object as a candidatelandmark if the following conditions are met: (1)the object is not the target, and (2) it is not in thedistractor set either.Furthermore, a target landmark is a memberof the candidate landmark set that stands in re-lation to the target.
A distractor landmark is amember of the candidate landmark set that standsin the considered relation to a distractor object.
Wethen define a distinguishing locative descriptionas a locative description where there is target land-mark that can be distinguished from all the mem-bers of the set of distractor landmarks under therelation used in the locative.3.3 AlgorithmWe first try to generate a distinguishing descrip-tion using Algorithm 1.
If this fails, we divide thecontext into three components: the target, the dis-tractor objects, and the set of candidate landmarks.We then iterate through the set of candidate land-marks (using a salience ordering if there is morethan one, cf.
Equation 1) and try to create a distin-guishing locative description.
The salience order-ing of the landmarks is inspired by (Conklin andMcDonald, 1982) who found that the higher thesalience of an object the more likely it appears inthe description of the scene it was embedded in.For each candidate landmark we iterate throughthe hierarchy of relations, checking for each re-lation whether the candidate can function as a tar-get landmark under that relation.
If so we createa context model that defines the set of target anddistractor landmarks.
We create a distinguishinglocative description by using the basic incrementalalgorithm to distinguish the target landmark fromthe distractor landmarks.
If we succeed in generat-ing a distinguishing locative description we return1045the description and stop.Algorithm 2 The Locative Incremental AlgorithmDESC = Basic-Incremental-Algorithm(T,D)if DESC != Distinguishing thencreate CL the set of candidate landmarksCL = {x : x != T,DESC(x) = false}for i = 0 to |CL| by salience(CL) dofor j = 0 to |R| doif Rj (T,CLi)=true thenTL = {CLi}DL = {z : z ?
CL,Rj (D, z) = true}LANDDESC = Basic-Incremental-Algorithm(TL, DL)if LANDDESC = Distinguishing thenDistinguishing locative generatedreturn {DESC,Rj ,LANDDESC}end ifend ifend forend forend ifFAILIf we cannot create a distinguishing locative de-scription we face two choices: (1) iterate on to thenext relation in the hierarchy, (2) create an embed-ded locative description distinguishing the land-mark.
We adopt (1) over (2), preferring the dogto the right of the car over the dog near the carto the right of the house.
However, we can gener-ate these longer embedded descriptions if needed,by replacing the call to the basic incremental algo-rithm for the landmark object with a call to thewhole locative expression generation algorithm,using the target landmark as the target object andthe set of distractor landmarks as the distractors.An important point in this context is the issueof infinite regression (Dale and Haddock, 1991).A compositional GRE system may in certain con-texts generate an infinite description, trying to dis-tinguish the landmark in terms of the target, andthe target in terms of the landmark, cf.
(4).
But,this infinite recursion can only occur if the con-text is not modified between calls to the algorithm.This issue does not affect Algorithm 2 as each callto the algorithm results in the domain being parti-tioned into those objects we can and cannot use aslandmarks.
This not only reduces the number ofobject pairs that relations must be computed for,but also means that we need to create a distin-guishing description for a landmark on a contextthat is a strict subset of the context the target de-scription was generated in.
This way the algorithmcannot distinguish a landmark using its target.
(4) the bowl on the table supporting the bowlon the table supporting the bowl ...3.4 ComplexityThe computational complexity of the incrementalalgorithm is O(nd*nl ), with nd the number of dis-tractors, and nl the number of attributes in the finalreferring description (Dale and Reiter, 1995).
Thiscomplexity is independent of the number of at-tributes to be considered.
Algorithm 2 is bound bythe same complexity.
For the average case, how-ever, we see the following.
For one, with everyincrease in nl , we see a strict decrease in nd : themore attributes we need, the fewer distractors westrictly have due to the partitioning into distrac-tor and target landmarks.
On the other hand, wehave the dynamic construction of a context model.This latter factor is not considered in (Dale andReiter, 1995), meaning we would have to multiplyO(nd*nl ) with a constant Kctxt for context con-struction.
Depending on the size of this constant,we may see an advantage of our algorithm in thatwe only consider a single spatial relation each timewe construct a context model, we avoid an expo-nential number of comparisons: we need to makeat most nd * (nd ?
1) comparisons (and only ndif relations are symmetric).4 DiscussionWe examplify the approach on the visual scene onthe left of Figure 6.
This context consists of twored boxes R1 and R2 and two blue balls B1 andB2.
Imagine that we want to refer to B1.
We be-gin by calling Algorithm 2.
This in turn calls Al-gorithm 1, returning the property ball.
This is notsufficient to create a distinguishing description asB2 is also a ball.
In this context the set of can-didate landmarks equals {R1,R2}.
We take R1 asfirst candidate landmark, and check for topologi-cal proximity in the scene as modeled in (Kelle-her et al, 2006).
The image on the right of Fig-ure 6 illustrates the resulting scene analysis: thegreen region on the left defines the area deemed tobe proximal to R1, and the yellow region on theright defines the area proximal to R2.
Clearly, B1is in the area proximal to R1, making R1 a tar-get landmark.
As none of the distractors (i.e., B2)are located in a region that is proximal to a can-didate landmark there are no distractor landmarks.As a result when the basic incremental algorithmis called to create a distinguishing description forthe target landmark R1 it will return box and thiswill be deemed to be a distinguishing locative de-scription.
The overall algorithm will then return1046Figure 6: A visual scene and the topological anal-sis of R1 and R2the vector {ball, proximal, box} which would re-sult in the realiser generating a reference of theform: the ball near the box.5The relational hierarchy used by the frame-work has some commonalities with the relationalsubsumption hierarchy proposed in (Krahmer andTheune, 2002).
However, there are two importantdifferences between them.
First, an implication ofthe subsumption hierarchy proposed in (Krahmerand Theune, 2002) is that the semantics of the rela-tions at lower levels in the hierarchy are subsumedby the semantics of their parent relations.
For ex-ample, in the portion of the subsumption hierarchyillustrated in (Krahmer and Theune, 2002) the re-lation next to subsumes the relations left of andright of.
By contrast, the relational hierarchy de-veloped here is based solely on the relative cogni-tive load associated with the semantics of the spa-tial relations and makes not claims as to the se-mantic relationships between the semantics of thespatial relations.
Secondly, (Krahmer and Theune,2002) do not use their relational hierarchy to guidethe construction of domain models.By providing a basic contextual definition ofa landmark we are able to partition the contextin an appropriate manner.
This partitioning hastwo advantages.
One, it reduces the complexityof the context model construction, as the relation-ships between the target and the distractor objectsor between the distractor objects themselves donot need to be computed.
Two, the context usedduring the generation of a landmark descriptionis always a subset of the context used for a tar-get (as the target, its distractors and the other ob-jects in the domain that do not stand in relationto the target or distractors under the relation beingconsidered are excluded).
As a result the frame-work avoids the issue of infinite recusion.
Further-more, the target-landmark relationship is automat-5For more examples, see the videos available athttp://www.dfki.de/cosy/media/.ically included as a property of the landmark as itsfeature based description need only distinguish itfrom objects that stand in relation to one of the dis-tractor objects under the same spatial relationship.In future work we will focus on extending theframework to handle some of the issues effect-ing the incremental algorithm, see (van Deemter,2001).
For example, generating locative descrip-tions containing negated relations, conjunctions ofrelations and involving sets of objects (sets of tar-gets and landmarks).5 ConclusionsWe have argued that an if a conversational robotfunctioning in dynamic partially known environ-ments needs to generate contextually appropriatelocative expressions it must be able to constructa context model that explicitly marks the spatialrelations between objects in the scene.
However,the construction of such a model is prone to theissue of combinatorial explosion both in terms ofthe number objects in the context (the location ofeach object in the scene must be checked againstall the other objects in the scene) and number ofinter-object spatial relations (as a greater numberof spatial relations will require a greater numberof comparisons between each pair of objects.We have presented a framework that addressesthis issue by: (a) contextually defining the set ofobjects in the context that may function as a land-mark, and (b) sequencing the order in which spa-tial relations are considered using a cognitivelymotivated hierarchy of relations.
Defining the setof objects in the scene that may function as a land-mark reduces the number of object pairs that a spa-tial relation must be computed over.
Sequencingthe consideration of spatial relations means thatin each context model only one relation needs tobe checked and in some instances the agent neednot compute some of the spatial relations, as itmay have succeeded in generating a distinguishinglocative using a relation earlier in the sequence.A further advantage of our approach stems fromthe partitioning of the context into those objectsthat may function as a landmark and those thatmay not.
As a result of this partitioning the al-gorithm avoids the issue of infinite recursion, asthe partitioning of the context stops the algorithmfrom distinguishing a landmark using its target.We have employed the approach in a system forHuman-Robot Interaction, in the setting of object1047manipulation in natural scenes.
For more detail,see (Kruijff et al, 2006a; Kruijff et al, 2006b).ReferencesR.J.
Beun and A. Cremers.
1998.
Object reference in ashared domain of conversation.
Pragmatics and Cogni-tion, 6(1/2):121?152.D.J.
Bryant, B. Tversky, and N. Franklin.
1992.
Internaland external spatial frameworks representing describedscenes.
Journal of Memory and Language, 31:74?98.L.A.
Carlson-Radvansky and D. Irwin.
1994.
Referenceframe activation during spatial term assignment.
Journalof Memory and Language, 33:646?671.L.A.
Carlson-Radvansky and G.D. Logan.
1997.
The influ-ence of reference frame selection on spatial template con-struction.
Journal of Memory and Language, 37:411?437.H.
Clark and D. Wilkes-Gibbs.
1986.
Referring as a collab-orative process.
Cognition, 22:1?39.E.
Jeffrey Conklin and David D. McDonald.
1982.
Salience:the key to the selection problem in natural language gen-eration.
In ACL Proceedings, 20th Annual Meeting, pages129?135.R.
Dale and N. Haddock.
1991.
Generating referring ex-pressions involving relations.
In Proceeding of the FifthConference of the European ACL, pages 161?166, Berlin,April.R.
Dale and E. Reiter.
1995.
Computational interpretationsof the Gricean maxims in the generation of referring ex-pressions.
Cognitive Science, 19(2):233?263.I.
Duwe and H. Strohner.
1997.
Towards a cognitive modelof linguistic reference.
Report: 97/1 - Situierte Ku?nstlicheKommunikatoren 97/1, Univerista?t Bielefeld.G.
Edwards and B. Moulin.
1998.
Towards the simula-tion of spatial mental images using the vorono??
model.
InP.
Oliver and K.P.
Gapp, editors, Representation and pro-cessing of spatial expressions, pages 163?184.
LawrenceErlbaum Associates.C.
Fillmore.
1997.
Lecture on Deixis.
CSLI Publications.K.P.
Gapp.
1995.
Angle, distance, shape, and their relation-ship to projective relations.
In Proceedings of the 17thConference of the Cognitive Science Society.C Gardent.
2002.
Generating minimal definite descrip-tions.
In Proceedings of the 40th International Confernceof the Association of Computational Linguistics (ACL-02),pages 96?103.S.
Garrod, G. Ferrier, and S. Campbell.
1999.
In and on:investigating the functional geometry of spatial preposi-tions.
Cognition, 72:167?189.P.
Gorniak and D. Roy.
2004.
Grounded semantic compo-sition for visual scenes.
Journal of Artificial IntelligenceResearch, 21:429?470.E.
Hajicova?.
1993.
Issues of sentence structure and discoursepatterns.
In Theoretical and Computational Linguistics,volume 2, Charles University, Prague.A Herskovits.
1986.
Language and spatial cognition: Aninterdisciplinary study of prepositions in English.
Stud-ies in Natural Language Processing.
Cambridge Univer-sity Press.H.
Horacek.
1997.
An algorithm for generating referentialdescriptions with flexible interfaces.
In Proceedings of the35th Annual Meeting of the Association for ComputationalLinguistics, Madrid.R.
Jackendoff.
1983.
Semantics and Cognition.
CurrentStudies in Linguistics.
The MIT Press.J.
Kelleher and J. van Genabith.
2004.
A false colouring realtime visual salency algorithm for reference resolution insimulated 3d environments.
AI Review, 21(3-4):253?267.J.D.
Kelleher, G.J.M.
Kruijff, and F. Costello.
2006.
Prox-imity in context: An empirically grounded computationalmodel of proximity for processing topological spatial ex-pressions.
In Proceedings ACL/COLING 2006.E.
Krahmer and M. Theune.
2002.
Efficient context-sensitivegeneration of referring expressions.
In K. van Deemterand R. Kibble, editors, Information Sharing: Referenceand Presupposition in Language Generation and Interpre-tation.
CLSI Publications, Standford.G.J.M.
Kruijff, J.D.
Kelleher, G. Berginc, and A. Leonardis.2006a.
Structural descriptions in human-assisted robot vi-sual learning.
In Proceedings of the 1st Annual Confer-ence on Human-Robot Interaction (HRI?06).G.J.M.
Kruijff, J.D.
Kelleher, and Nick Hawes.
2006b.
Infor-mation fusion for visual reference resolution in dynamicsituated dialogue.
In E.
Andre?, L. Dybkjaer, W. Minker,H.Neumann, and M. Weber, editors, Perception and Inter-active Technologies (PIT 2006).
Springer Verlag.B Landau.
1996.
Multiple geometric representations of ob-jects in language and language learners.
In P Bloom,M.
Peterson, L Nadel, and M. Garrett, editors, Languageand Space, pages 317?363.
MIT Press, Cambridge.G.
D. Logan.
1994.
Spatial attention and the apprehensionof spatial realtions.
Journal of Experimental Psychology:Human Perception and Performance, 20:1015?1036.G.D.
Logan.
1995.
Linguistic and conceptual control of vi-sual spatial attention.
Cognitive Psychology, 12:523?533.R.
Moratz and T. Tenbrink.
2006.
Spatial reference inlinguistic human-robot interaction: Iterative, empiricallysupported development of a model of projective relations.Spatial Cognition and Computation.L.
Talmy.
1983.
How language structures space.
In H.L.Pick, editor, Spatial orientation.
Theory, research and ap-plication, pages 225?282.
Plenum Press.A.
Treisman and S. Gormican.
1988.
Feature analysis inearly vision: Evidence from search assymetries.
Psycho-logical Review, 95:15?48.K.
van Deemter.
2001.
Generating referring expressions:Beyond the incremental algorithm.
In 4th Int.
Conf.
onComputational Semantics (IWCS-4), Tilburg.I van der Sluis and E Krahmer.
2004.
The influence of targetsize and distance on the production of speech and gesturein multimodal referring expressions.
In Proceedings ofInternational Conference on Spoken Language Processing(ICSLP04).C.
Vandeloise.
1991.
Spatial Prepositions: A Case StudyFrom French.
The University of Chicago Press.S.
Varges.
2004.
Overgenerating referring expressions in-volving relations and booleans.
In Proceedings of the 3rdInternational Conference on Natural Language Genera-tion, University of Brighton.1048
