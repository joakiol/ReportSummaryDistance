First Joint Conference on Lexical and Computational Semantics (*SEM), pages 425?429,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsMIXCD: System Description for Evaluating Chinese Word Similarity atSemEval-2012Yingjie ZhangNanjing University22 Hankou RoadJiangsu P. R. Chinajillzhyj@139.comBin LiNanjing UniversityNanjing Normal University122 Ninghai RoadJiangsu P. R. Chinagothere@126.comXinyu DaiNanjing University22 Hankou RoadJiangsu P. R. Chinadxy@nju.edu.cnJiajun ChenNanjing University22 Hankou RoadJiangsu P. R. Chinacjj@nju.eud.cnAbstractThis document describes three systems calcu-lating semantic similarity between two Chi-nese words.
One is based on MachineReadable Dictionaries and the others utilizeboth MRDs and Corpus.
These systems areperformed on SemEval-2012 Task 4: Evaluat-ing Chinese Word Similarity.1 IntroductionThe characteristics of polysemy and synonymy thatexist in words of natural language have alwaysbeen a challenge in the fields of Natural LanguageProcessing (NLP) and Information Retrieval (IR).In many cases, humans have little difficulty in de-termining the intended meaning of an ambiguousword, while it is extremely difficult to replicatethis process computationally.
For many tasks inpsycholinguistics and NLP, a job is often decom-posed to the requirement of resolving the semanticsimilarity between words or concepts.There are two ways to get the similarity betweentwo words.
One is to utilize the machine readabledictionary (MRD).
The other is to use the corpus.For the 4th task in SemEval-2012 we are re-quired to evaluate the semantic similarity of Chi-nese word pairs.
We consider 3 methods in thisstudy.
One uses MRDs only and the other two useboth MRD and corpus.
A post processing will bedone on the results of these methods to treat syno-nyms.In chapter 2 we introduce the previous works onthe evaluation of Semantic Similarity.
Chapter 3shows three methods used in this task.
Chapter 4reveals the results of these methods.
And conclu-sion is stated in chapter 5.2 Related WorkFor words may have more than one sense, similari-ty between two words can be determined by thebest score among all the concept pairs which theirvarious senses belong to.Before constructed dictionary is built, Lesksimilarity (Lesk, 1986) which is proposed as a so-lution for word sense disambiguation is often usedto evaluating the similarity between two concepts.This method calculates the overlap between thecorresponding definitions as provided by a diction-ary.
(     )  |     (  )       (  )|Since the availability of computational lexiconssuch as WordNet, the taxonomy can be representedas a hierarchical structure.
Then we use the struc-ture information to evaluate the semantic similarity.In these methods, the hierarchical structure is oftenseen as a tree and concepts as the nodes of the treewhile relations between two concepts as the edges.
(Resnik, 1995) determines the conceptual simi-larity of two concepts by calculating the infor-mation content (IC) of the least common subsumer(LCS) of them.
(     )    (   (     ))where the IC of a concept can be quantified asfollow:( )        ( )425This method do not consider the distance of twoconcepts.
Any two concepts have the same LCSwill have the same similarity even if the distancesbetween them are different.
It is called node-basedmethod.
(Leacock and Chodorow, 1998) develops a simi-larity measure based on the distance of two sensesand   .
They focus on hypernymy links andscaled the path length by the overall depth   of thetree.
(     )(     )(Wu and Palmer, 1994) combines the depth ofthe LCS of two concepts into a similarity score.
(     )(   (     ))(  )       (  )These approaches are regarded as edge-basedmethods.
They are more natural and direct to eval-uating semantic similarity in taxonomy.
But theytreat all nodes as the same and do not consider thedifferent information of different nodes.
(Jiang and Conrath, 1998) uses the informationcontent of concept instead of its depth.
So bothnode and edge information can be considered toevaluate the similarity.
It performs well in evaluat-ing semantic similarity between two texts (Zhanget al, 2008; Corley and Mihalcea, 2005; Pedersen,2010).
(     )(  )   (  )     (   (     ))SemCor is used in Jiang's work to get the fre-quency of a word with a specific sense treated bythe Lagrange Smoothing.3 ApproachesFor SemEval-2012 task 4, we use two MRDs andone corpus as our knowledge resources.
One MRDis HIT IR-Lab Tongyici Cilin (Extended) (Cilin)and the other is Chinese Concept Dictionary(CCD).
The corpus we used in our system is Peo-ple's Daily.
Three systems are proposed to evaluatethe semantic similarity between two Chinese words.The first one utilizes both the MRDs calledMIXCC (Mixture of Cilin and CCD) and other twonamed MIXCD1 (Mixture of Corpus and Diction-ary) and MIXCD2 respectively combine the infor-mation derived from both corpus and dictionaryinto the similarity score.
A post processing is doneto trim the similarity of words with the same mean-ing.3.1 Knowledge ResourcesHIT IR-Lab Tongyici Cilin (Extended) is built byHarbin Institute of Technology which contained77343 word items.
Cilin is constructed as a treewith five levels.
With the increasing of the level,word senses are more fine-grained.
All word itemsin Cilin are located at the fifth level.
The largerlevel the LCS of an item pair has, the closer theirconcepts are.Chinese Concept Dictionary (CCD) is a ChineseWordNet produced by Peking University.
Wordconcepts in it are represented as Synsets and one-one corresponding to WordNet 1.6.
There are 4types of hierarchical semantic relations in CCD asfollows:?
Synonym: the meanings of two words areequivalence?
Antonym: two synsets contain the wordswith opposite meaning?
Hypernym and Hyponym: two synsetswith the IS-A relation?
Holonym and Meronym: two synsets withthe IS-PART-OF relationAdditionally there is another type of semanticrelation such as Attribute in CCD This relationtype often happens between two words with differ-ent part-of-speech.
Even though it is not the hierar-chical relation, this relation type can make twowords with different POS have a path betweenthem.
In WordNet it is often shown as a Morpho-logical transform between two words, while it mayhappen on two different words with closed mean-ing in CCD.The corpus we use in our system is People'sDaily 2000 from January to June which has beenmanually segmented.3.2 MIXCCMIXCC utilizes both Cilin and CCD to evaluatethe semantic similarity of word pair.
In this methodwe get the rank in three steps.First, we use Cilin to separate the list of wordpairs into five parts and sort them in descendingorder of LCS's level.
The word pairs having thesame level of LCS will be put in the same part.426Second, for each part we compute the similarityalmost by Jiang and Conrath's method mentionedin Section 2 above.
Only Synonym and Hypernym-Hyponym relations of CCD concepts are consid-ered in this method.
So CCD could be constructedas a forest.
We add a root node which combinedthe forest into a tree to make sure that there is apath between any two concepts.
(     )(  )(  )(     )and   compose a word pair needed to cal-culate semantic similarity between them.
(  ) isthe Synset in CCD which contains   (  ).Because there is no sense-tagged corpus forCCD, the frequency of every word in each conceptis always 1.After       (     )  of all word pairs in thesame part are calculated, we sort the scores in adecreasing order again.
Then we get five groups ofranked word pairs.At last the five groups are combined together asthe result shown in table 1.3.3 MIXCDMIXCD combines the information of corpus andMRDs to evaluate semantic similarity.In this system we use trial data to learn a multiplelinear regression function.
There are two classes offeatures for this study which are derived from CCDand People's Daily respectively.
One class of fea-ture is the mutual information of a word pair andthe other is the shortest path between two conceptscontaining the words of which the similarity need-ed to be evaluated.We consider CCD as a large directed graph.
Thenodes of the graph are Synsets and edges are thesemantic relations between two Synsets.
All fivetypes of semantic relation showed in Section 3.1will be used to build the graph.For each word pair, the shortest path betweentwo Synsets which contain the words respectivelyis found.
Then the path is represented in two forms.In one form we record the vector consisting ofthe counts of every relation type in the path.
Thesystem using this path's form is called MIXCD0.For example the path between "???
(psy-chology)" and "????
(psychiatry)" is repre-sented as (0, 0, 3, 2, 0).
It means that "???"
and"????"
are not synonym and the shortest pathbetween them contained 3 IS-A relations and 2 IS-PART-OF relations.We suppose that the path's length is a significantfeature to measure the semantic similarity of aword pair.
So in the other form the length is addedinto the vector as the first component.
And thecounts of each relation are recorded in proportionto the length.
This form of path representation isused in the submitted system called MIXCD.
Thenthe path between "???"
and "????"
is rep-resented as (5, 0, 0, 0.6, 0.4, 0).In both forms, the Synonym feature will be 1 ifthe length of the path is 0.The mutual information of all word pairs is cal-culated via the segmented People's Daily.Last we use the result of multiple linear regres-sion to forecast the similarity of other word pairsand get the rank.3.4 Post ProcessingThe word pair with the same meaning may be con-sisted of two same words or two different wordsbelong to the same concept.
It is difficult for bothsystems to separate one from the other.
Thereforewe display a post processing on our systems tomake sure that the similarity between the samewords has a larger rank than two different words ofthe same meaning.4 Experiments and ResultsWe perform our systems on trial data and then useKendall tau Rank Correlation (Kendall, 1995;Wessa, 2012) to evaluate the results shown in Ta-ble 1.
The trial data contains 50 word pairs.
Thesimilarity of each pair is scored by several expertsand the mean value is regarded as the standard an-swer to get the manual ranking.Method Kendall tau 2-sided p valueMIXCC 0.273469 0.005208MIXCD0 0.152653 0.119741MIXCD 0.260408 0.007813Manual(upper) 0.441633 6.27E-06Table 1: Kendall tau Rank Correlation of systems on trialFrom Table 1, we can see the tau value of MIX-CD0 is 0.1526 and MIXCD is 0.2604.
MIXCDperformed notably better than MIXCD0.
It shows427that path's length between two words is on an im-portant position of measuring semantic similarity.This feature does improve the similarity result.
The2-sided p value of MIXCD0 is 0.1197.
It is muchlarger than the value of MIXCD which is 0.0078.So the ranking result of MIXCD0 is much moreoccasional than result of MIXCD.The tau value of MIXCC is 0.2735 and it ismuch smaller than the manual ranking result whichis 0.4416 seen as the upper bound.
It shows that thesimilarity between two words in human's mindsdose not only depend on their hierarchical relationrepresented in Dictionary.
But the value is largerthan that of MIXCD.
It seems that the mutual in-formation derived from corpus which is expectedto improve the result reduces the correction of rankresult contrarily.
There may be two reasons on it.First, because of the use of trial data in MIXCD,the result of similarity ranking strongly dependedon this data.
The reliability of trial data's rankingmay influent the performance of our system.
Wecalculate the tau value between every manual andthe correct ranking.
The least tau value is 0.4416and the largest one is 0.8220 with a large disparity.We use the Fleiss' kappa value (Fleiss, 1971) toevaluate the agreement of manual ranking and theresult is 0.1526 which showed the significant disa-greement.
This disagreement may make the regres-sion result cannot show the relation betweenfeatures and score correctly.
To reduce the disa-greement's influence we calculate the mean ofmanual similarity score omitting the maximum andminimum ones and get a new standard rank (trial2).Then we perform MIXCD on trail2 and show thenew result as MIXCD-2 in Form 2.
MIXCC's re-sult is also compared with trail2 shown as MIXCC-2.MIXCC-2 MIXCD-2 MIXCC MIXCDKendall tau 0.297959 0.265306 0.273469 0.260408Table 2: tau value on new standard (omit max/min manualscores)From Table 2 we can see the tau values ofMIXCC rose to 0.2980 and MIXCD to 0.2653.
Itshows that omitting the maximum and minimummanual scores can reduce some influence of thedisagreement of artificial scoring.Second, the combination method of mutual in-formation and semantic path in MRD may alsoinfluent the performance of our system.
The ranksbetween MIXCD and MIXCC are also comparedand the tau value is 0.2065.
It shows a low agree-ment of semantic similarity measurements betweenMRD and Corpus.
The mutual information exerts alarge influence on the measure of similarity andsometimes may bring the noise to the result mak-ing it worse.We also perform our systems on test data con-taining 297 words pairs in the same form of trialdata and got the follow result:Method Kendall tauMIXCC 0.050MIXCD0 -0.064MIXCD 0.040Table 3 tau values of the result of test dataThe ranking on test data of our systems showsan even worse result.
Because of the low confi-dence of trial data ranking, multiple linear regres-sion function learning from the trial data performsbad on other word pairs.5 ConclusionIn this paper we propose three methods to evaluatethe semantic similarity of Chinese word pairs.
Thefirst one uses MRDs and the second one adds theinformation derived from corpus.
The third oneuses the same knowledge resources as the secondone but highlights the path length of the word pair.The results of the systems show a large differenceand all have a low score.
From the results we cansee the similarity showed in corpus is much differ-ent from the one expressed in MRD.
One reason ofthe low score is that the manual rank given by thetask has a low agreement among them.
We get anew manual rank which reduces some influence ofdisagreement by calculating the mean value ofscores omitting the maximum and minimum ones.Comparing the result of our systems with the newranking, all of them get a higher tau value.AcknowledgementThis paper is supported in part by National NaturalScience Fund of China under contract 61170181,National Social Science Fund of China under con-tract 10CYY021, State Key Lab.
for Novel Soft-ware Technology under contract KFKT2011B03,Jiangsu PostDoc Fund under contract 1101065C.428ReferencesMike E. Lesk, 1986.
Automatic sense disambiguationusing machine readable dictionaries: How to tell apine cone from an ice cream cone.
In Proceedings ofthe SIGDOC Conference 1986, Toronto, June.Philip Resnik, 1995.
Using information content to eval-uate semantic similarity.
In Proceedings of the 14thInternational Joint Conference on Artificial Intelli-gence, Montreal, Canada.Claudia Leacock and Martin Chodorow, 1998.
Combin-ing local context and WordNet sense similiarity forword sense disambiguation.
In WordNet, An Elec-tronic Lexical Database.
The MIT Press.Zhibiao Wu and Martha Palmer, 1994.
Verb semanticsand lexical selection.
In Proceedings of the 32nd An-nual Meeting of the Association for ComputationalLinguistics, Las Cruces, New Mexico.Jay J. Jiang and David W. Conrath, 1998.
Semantic sim-ilarity based on corpus statistics and lexical taxono-my.
In Proceedings of the International Conferenceon Research in Computational Linguistics.Ce Zhang , Yu-Jing Wang , Bin Cui , Gao Cong, 2008.Semantic similarity based on compact concept ontol-ogy.
In Proceeding of the 17th international confer-ence on World Wide Web, April 21-25, 2008, Beijing,ChinaCourtney Corley , Rada Mihalcea, 2005.
Measuring thesemantic similarity of texts.
In Proceedings of theACL Workshop on Empirical Modeling of SemanticEquivalence and Entailment, p.13-18, June 30-30,2005, Ann Arbor, Michigan.Ted Pedersen, 2010.
Information content measures ofsemantic similarity perform better without sense-tagged text.
In Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, p.329-332, June 02-04, 2010, Los Angeles,California.M.
G. Kendall, 1955.
Rank Correlation Methods.
NewYork: Hafner Publishing Co.P.
Wessa, 2012.
Free Statistics Software, Office for Re-search Development and Education, version 1.1.23-r7, URL http://www.wessa.net/Jordan L. Fleiss, 1971.
Measuring nominal scale agree-ment among many raters.
Psychological Bulletin, Vol.76, No.
5 pp.
378?382.429
