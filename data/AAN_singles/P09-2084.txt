Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 333?336,Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLPWhere's the Verb?Correcting Machine Translation During Question AnsweringWei-Yun Ma, Kathleen McKeownDepartment of Computer ScienceColumbia UniversityNew York, NY 10027, USA{ma,kathy}@cs.columbia.eduAbstractWhen a multi-lingual question-answering (QA)system provides an answer that has beenincorrectly translated, it is very likely to beregarded as irrelevant.
In this paper, wepropose a novel method for correcting adeletion error that affects overallunderstanding of the sentence.
Our post-editingtechnique uses information available at querytime: examples drawn from related documentsdetermined to be relevant to the query.
Ourresults show that 4%-7% of MT sentences aremissing the main verb and on average, 79% ofthe modified sentences are judged to be morecomprehensible.
The QA performance alsobenefits  from the improved MT: 7% ofirrelevant response sentences become relevant.1.
IntroductionWe are developing a multi-lingual question-answering (QA) system that must providerelevant English answers for a given query,drawing pieces of the answer from translatedforeign source.
Relevance and translation qualityare usually inseparable: an incorrectly translatedsentence in the answer is very likely to beregarded as irrelevant even when thecorresponding source language sentence isactually relevant.
We use a phrase-basedstatistical machine translation system for the MTcomponent and thus, for us, MT serves as ablack box that produces the translateddocuments in our corpus; we cannot change theMT system itself.
As MT is used in more andmore multi-lingual applications, this situationwill become quite common.We propose a novel method which usesredundant information available at question-answering time to correct errors.
We present apost-editing mechanism to both detect andcorrect errors in translated documentsdetermined to be relevant for the response.
Inthis paper, we focus on cases where the mainverb of a Chinese sentence has not beentranslated.
The main verb usually plays a crucialrole in conveying the meaning of a sentence.
Incases where only the main verb is missing, anMT score relying on edit distance (e.g., TER orBleu) may be high, but the sentence maynonetheless be incomprehensible.Handling this problem at query time ratherthan during SMT gives us valuable informationwhich was not available during SMT, namely, aset of related sentences and their translationswhich may contain the missing verb.
By usingtranslation examples of verb phrases andalignment information in the related documents,we are able to find an appropriate English verband embed it in the right position as the mainverb in order to improve MT quality.A missing main verb can result in an incom-prehensible sentence as seen here where theChinese verb ????
was not translated at all.MT:          On December 13 Saddam .REF :        On December 13 Saddam was arrested.Chinese:   12?13??????
?In other cases, a deleted main verb can resultin miscommunication; below the Chinese verb????
should have been translated as?reduced?.
An English native speaker couldeasily misunderstand the meaning to be ?Peoplelove classical music every year.?
which happensto be the opposite of the original intendedmeaning.MT:          People of classical music loving every year.REF :        People?s love for classical music reduced every year.Chinese:   ???????????????2.
Related WorkPost-editing has been used in full MT systemsfor tasks such as article selection (a, an, the) for333English noun phrases (Knight and Chander1994).
Simard et alin 2007 even developed astatistical phrase based MT system in a post-editing task, which takes the output of a rule-based MT system and produces post-editedtarget-language text.
Zwarts et al (2008) targetselecting the best of a set of outputs fromdifferent MT systems through theirclassification-based approach.
Others have alsoproposed using the question-answering contextto detect errors in MT, showing how to correctnames (Parton et.
al 2008, Ji et.
al 2008).3.
System OverviewThe architecture of our QA system is shown inFigure 1.
Our MT post-editing system (the boldblock in Figure 1) runs after document retrievalhas retrieved all potentially relevant documentsand before the response generator selectssentences for the answer.
It modifies any MTdocuments retrieved by the embeddedinformation retrieval system that are missing amain verb.
All MT results are provided by aphrase-based SMT system.Post-editing includes three steps: detect aclause with a missing main verb, determinewhich Chinese verb should have been translated,and find an example sentence in the relateddocuments with an appropriate sentence whichcan be used to modify the sentence in question.To detect clauses, we first tag the corpus using aConditional Random Fields (CRF) POS taggerand then use manually designed regularexpressions to identify main clauses of thesentence, subordinate clauses (i.e., clauses whichare arguments to a verb) and conjunct clauses ina sentence with conjunction.
We do not handleadjunct clauses.
Hereafter, we simply refer to allof these as ?clause?.
If a clause does not haveany POS tag that can serve as a main verb (VB,VBD, VBP, VBZ), it is marked as missing amain verb.MT alignment information is used to furtherensure that these marked clauses are reallymissing main verbs.
We segment and tag theChinese source sentence using the StanfordChinese segmenter and the CRF Chinese POStagger developed by Purdue University.
If wefind a verb phrase in the Chinese sourcesentence that was not aligned with any Englishwords in the SMT alignment tables, then welabel it as a verb translation gap (VTG) andconfirm that the marking was correct.In the following sections, we describe how wedetermine which Chinese verb should have beentranslated and how that occurs.Query in EnglishDocument RetrievalDetecting Possible Clauseswith no Main VerbFinding the Main Verb PositionObtain Translation of the MainVerb and embed it to thetranslated sentenceCorpus of translatedEnglish documents withChinese-English wordalignmentDynamic VerbPhrase TableStatic VerbPhrase TableRetrieved English docsModified English docsResponse GeneratorResponse in EnglishFigure 1.
The System Pipeline4.
Finding the Main Verb PositionChinese ordering differs from English mainlyin clause ordering (Wang et al, 2007) andwithin the noun phrase.
But within a clausecentered by a verb, Chinese mostly uses a SVOor SV structure, like English (Yamada andKnight 2001), and we can assume the localalignment centered by a verb between Chineseand English is a linear mapping relation.
Underthis assumption, the translation of ????
in theabove example should be placed in the positionbetween ?Saddam?
and ?.?.
Thus, once we find aVTG, its translation can be inserted into thecorresponding position of the target sentenceusing the alignment.This assumes, however, that there is only oneVTG found within a clause.
In practice, morethan one VTG may be found in a clause.
If wechoose one of them, we risk making the wrongchoice.
Instead, we insert the translations of bothVTGs simultaneously.
This strategy could resultin more than one main verb in a clause, but it ismore helpful than having no verb at all.5.
Obtaining a VTG TranslationWe translate VTGs by using verb redundancyin related documents: if the VTG was translatedin other places in related documents, the existingtranslations can be reused.
Related documentsare likely to use a good translation for a specificVTG as it is used in a similar context.
A verb?saspect and tense can be directly determined byreferencing the corresponding MT examples andtheir contexts.
If, unfortunately, a given VTG334did not have any other translation record, thenthe VTG will not be processed.To do this, our system first builds verb phrasetables from relevant documents and then usesthe tables to translate the VTG.
We use two verbphrase tables: one is built from a collection ofMT documents before any query and is calledthe ?Static Verb Phrase Table?, and the otherone is dynamically built from the retrievedrelevant MT documents for each query and iscalled the ?Dynamic Verb Phrase Table?.The construction procedure is the same forboth.
Given a set of related MT documents andtheir MT alignments, we collect all Chinese verbphrases and their translations along with theirfrequencies and contexts.One key issue is to decide appropriatecontextual features of a verb.
A number ofresearchers (Cabezas and Resnik 2005, Carpuatand Wu 2007) provide abundant evidence thatrich context features are useful in MT tasks.Carpuat and Wu (2007) tried to integrate aPhrase Sense Disambiguation (PSD) model intotheir Chinese-English SMT system and theyfound that the POS tag preceding a given phrase,the POS tag following the phrase and bag-of-words are the three most useful features.Following their approach, we use the wordpreceding and the word following a verb as thecontext features.The Static and Dynamic Verb Phrase Tablesprovide us with MT examples to translate aVTG.
The system first references the DynamicVerb Phrase Table as it is more likely to yield agood translation.
If the record is not found, theStatic one is referenced.
If it is not found ineither, the given VTG will not be processed.
Nomatter which table is referenced, the followingNaive Bayes equation is applied to obtain thetranslation of a given VTG.
))|(log)|(log)((logmaxarg),|(maxarg'kkktkttfwPtpwPtPfwpwtPtkk++==pw, fw and tk respectively represent thepreceding source word, the following sourceword and a translation candidate of a VTG.6.
ExperimentsOur test data is drawn from Chinese-English MTresults generated by Aachen?s 2007 RWTH sys-tem (Mauser et al, 2007), a phrase-based SMTsystem with 38.5% BLEU score on IWSLT2007 evaluation data.Newswires and blog articles are retrieved forfive queries which served as our experimentaltest bed.
The queries are open-ended and on av-erage, answers were 30 sentences in length.Q1: Who/What is involved in Saddam Hussein's trialQ2: Produce a biography of Jacques Rene ChiracQ3: Describe arrests of person from Salafist Group forPreaching and CombatQ4: Provide information on Chen Sui BianQ5: What connections are there between World Cup games andstock markets?We used MT documents retrieved by IR foreach query to build the Dynamic Verb PhraseTable.
We tested the system on 18,886 MTsentences from the retrieved MT documents forall of the five queries.
Among these MTsentences, 1,142 sentences were detected andmodified (6 % of all retrieved MT sentences).6.1 Evaluation MethodologyFor evaluation, we used human judgments of themodified and original MT.
We did not havereference translations for the data used by ourquestion-answering system and thus, could notuse metrics such as TER or Bleu.
Moreover, atbest, TER or Bleu score would increase by asmall amount and that is only if we select thesame main verb in the same position as thereference.
Critically, we also know that amissing main verb can cause major problemswith comprehension.
Thus, readers could betterdetermine if the modified sentence bettercaptured the meaning of the source sentence.
Wealso evaluated relevance of a sentence to a querybefore and after modification.We recruited 13 Chinese native speakers whoare also proficient in English to judge MTquality.
Native English speakers cannot tellwhich translation is better since they do notunderstand the meaning of the original Chinese.To judge relevance to the query, we used nativeEnglish speakers.Each modified sentence was evaluated bythree people.
They were shown the Chinesesentence and two translations, the original MTand the modified one.
Evaluators did not knowwhich MT sentence was modified.
They wereasked to decide which sentence is a bettertranslation, after reading the Chinese sentence.An evaluator also had the option of answering?no difference?.6.2 Results and DiscussionWe used majority voting (two out of three) todecide the final evaluation of a sentence judgedby three people.
On average, 900 (79%) of the3351142 modified sentences, which comprise 5% ofall 18,886 retrieved MT sentences, are betterthan the original sentences based on majorityvoting.
And for 629 (70%) of these 900 bettermodified sentences all three evaluators agreedthat the modified sentence is better.Furthermore, we found that for everyindividual query, the evaluators preferred moreof the modified sentences than the original MT.And among these improved sentences, 81%sentences reference the Dynamic Verb PhraseTable, while only 19% sentences had to drawfrom the Static Verb Phrase Table, thusdemonstrating that the question answeringcontext is quite helpful in improving MT.We also evaluated the impact of post-editingon the 234 sentences returned by our responsegenerator.
In our QA task, response sentenceswere judged as ?Relevant(R)?, ?PartiallyRelevant(PR)?, ?Irrelevant(I)?
and ?Too littleinformation to judge(T)?
sentences.
With ourpost-editing technique, 7% of 141 I/T responsesbecome R/PR responses and none of the R/PRresponses become I/T responses.
This meansthat R/PR response percentage has an increase of4%, thus demonstrating that our correction ofMT truly improves QA performance.
Anexample of a change from T to PR is:Question: What connections are there between World Cup gamesand stock markets?Original QA answer: But if winning the ball, not necessarily inthe stock market.Modified QA answer: But if winning the ball, not necessarily inthe stock market increased.6.3 Analysis of Different MT SystemsIn order to examine how often missing verbsoccur in different recent MT systems, in additionto using Aachen?s up-to-date system ?
?RWTH-PBT?of 2008, we also ran the detection processfor another state-of-the-art MT system ?
?SRI-HPBT?
(Hierarchical Phrase-Based System) of2008 provided by SRI, which uses a grammar onthe target side as well as reordering, and focuseson improving grammaticality of the targetlanguage.
Based on a government 2008 MTevaluation, the systems achieve 30.3% and30.9% BLEU scores respectively.
We used thesame test set, which includes 94 written articles(953 sentences).Overall, 7% of sentences translated byRWTH-PBT are detected with missing verbswhile 4% of sentences translated by SRI-HPBTare detected with missing verb.
This shows thatwhile MT systems improve every year, missingverbs remain a problem.7 ConclusionsIn this paper, we have presented a technique fordetecting and correcting deletion errors in trans-lated Chinese answers as part of a multi-lingualQA system.
Our approach uses a regular gram-mar and alignment information to detect missingverbs and draws from examples in documentsdetermined to be relevant to the query to insert anew verb translation.
Our evaluation demon-strates that MT quality and QA performance areboth improved.
In the future, we plan to extendour approach to tackle other MT error types byusing information available at query time.AcknowledgmentsThis material is based upon work supportedby the Defense Advanced Research ProjectsAgency under Contract No.
HR0011-06-C-0023ReferencesClara Cabezas and Philip Resnik.
2005.
Using WSDTechniques for Lexical Selection in StatisticalMachine, Translation Technical report CS-TR-4736Marine Carpuat and Dekai Wu.
2007.
Context-Dependent Phrasal Translation Lexicons forStatistical Machine Translation, MachineTranslation Summit XI, CopenhagenHeng Ji, Ralph Grishman and Wen Wang.
2008.Phonetic Name Matching For Cross-lingualSpoken Sentence Retrieval, IEEE-ACL SLT08.Goa, IndiaK.
Knight and I. Chander.
1994.
AutomatedPostediting of Documents, AAAIKristen Parton, Kathleen R. McKeown, James Allan,and Enrique Henestroza.
2008.
Simultaneousmultilingual search for translingual informationretrieval,  ACM 17th CIKMArne Mauser, David Vilar, Gregor Leusch, YuqiZhang, and Hermann Ney.
2007.
The RWTHMachine Translation System for IWSLT 2007,IWSLTMichel Simard, Cyril Goutte and Pierre Isabelle.2007.
Statistical Phrase-based Post-Editing,NAACL-HLTChao Wang, Michael Collins, and Philipp Koehn.2007.
Chinese Syntactic Reordering forStatistical Machine Translation, EMNLP-CoNLL.Kenji Yamada , Kevin Knight.
2001.
A syntax-basedstatistical translation model, ACLS.
Zwarts and M. Dras.
2008.
Choosing the RightTranslation: A Syntactically InformedApproach, COLING336
