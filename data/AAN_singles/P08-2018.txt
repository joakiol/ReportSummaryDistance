Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 69?72,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsBlog Categorization Exploiting Domain Dictionary andDynamically Estimated Domains of Unknown WordsChikara HashimotoGraduate School of Science and EngineeringYamagata UniversityYonezawa-shi, Yamagata, 992-8510, Japanch@yz.yamagata-u.ac.jpSadao KurohashiGraduate School of InformaticsKyoto UniversitySakyo-ku, Kyoto, 606-8501, Japankuro@i.kyoto-u.ac.jpAbstractThis paper presents an approach to text cate-gorization that i) uses no machine learning andii) reacts on-the-fly to unknown words.
Thesefeatures are important for categorizing Blogarticles, which are updated on a daily basisand filled with newly coined words.
We cat-egorize 600 Blog articles into 12 domains.
Asa result, our categorization method achievedan accuracy of 94.0% (564/600).1 IntroductionThis paper presents a simple but high-performancemethod for text categorization.
The method assignsdomain tags to words in an article, and categorizesthe article as the most dominant domain.
In thisstudy, the 12 domains in Table 1 are used follow-ing (Hashimoto and Kurohashi, 2007) (H&K here-after)1.
Fundamental words are assigned with a do-Table 1: Domains Assumed in H&KCULTURE LIVING SCIENCERECREATION DIET BUSINESSSPORTS TRANSPORTATION MEDIAHEALTH EDUCATION GOVERNMENTmain tag by H&K?s domain dictionary, while thedomains of non-fundamental words (i.e.
unknownwords) are dynamically estimated, which makes themethod different from previous ones.
Another hall-mark of the method is that it requires no machine1In addition, NODOMAIN is prepared for words belonging tono particular domain like blue or people.learning.
All you need is the domain dictionary andthe access to the Web.2 The Domain DictionaryH&K constructed a domain dictionary, where about30,000 Japanese fundamental content words (JFWs)are associated with appropriate domains.
For exam-ple, homer is associated with SPORTS.2.1 Construction Process1 Preparing Keywords for each Domain About20 keywords for each domain were collected manu-ally from words that appear frequently in the Web.They represent the contents of domains.2 Associating JFWs with Domains A JFW isassociated with a domain of the highest Ad score.An Ad score of domain is calculated by summingup the top five Ak scores of the domain.
Then,an Ak score, which is defined between a JFW anda keyword of a domain, is a measure that showshow strongly the JFW and the keyword are related.H&K adopt the ?2 statistics to calculate an Ak scoreand use web pages as a corpus.
The number ofco-occurrences is approximated by the number ofsearch engine hits when the two words are used asqueries.
Ak score between a JFW (jw) and a key-word (kw) is given as below.Ak(jw, kw) =n(ad ?
bc)2(a + b)(c + d)(a + c)(b + d) (1)where n is the total number of Japanese web pages,a = hits(jw & kw), b = hits(jw) ?
a,c = hits(kw) ?
a, d = n ?
(a + b + c).69Note that hits(q) represents the number of searchengine hits when q is used as a query.3 Manual Correction Manual correction of theautomatic association2 is done to complete the dic-tionary.
Since the accuracy of 2 is 81.3%, manualcorrection is not time-consuming.2.2 Distinctive FeaturesH&K?s method is independent of what domains toassume.
You can create your own dictionary.
Allyou need is prepare keywords of your own domains.After that, the same construction process is applied.Also note that H&K?s method requires no text col-lection that is typically used for machine learningtechniques.
All you need is the access to the Web.3 Blog CategorizationThe categorization proceeds as follows: 1 Extractwords from an article, 2 Assign domains and IDFsto the words, 3 Sum up IDFs for each domain, 4Categorize the article as the domain of the highestIDF.3 As for 2 , the IDF is calculated as follows:4IDF(w) = log Total # of Japanese web pages# of hits of w (2)Fundamental words are assigned with their do-mains and IDFs by the domain dictionary, whilethose for unknown words are dynamically estimatedby the method described in ?4.4 Domain Estimation of Unknown WordsThe domain (and IDF) of unknown word is dynam-ically estimated exploiting the Web.
More specifi-cally, we use Wikipedia and Snippets of Web search,in addition to the domain dictionary.
The estimationproceeds as follows (Figure 1): 1 Search the Webwith an unknown word, acquire the top 100 records,and calculate the IDF.
2 Get the Wikipedia articleabout the word from the search result if any, estimatethe domain of the word with the Wikipedia-strictmodule (?4.1), and exit.
3 When no Wikipedia arti-cle about the word is found, then get any Wikipedia2In H&K?s method, reassociating JFWs with NODOMAIN isrequired before 3 .
We omit that due to the space limitation.3If the domain of the highest IDF is NODOMAIN, the articleis categorized as the second highest domain.4We used 10,000,000,000 as the total number.Unknown WordSearch Result: 100 recordsIs There the WikipediaArticle about the Word inthe Search Result?Is There Any WikipediaArticle in the Top 30 inthe Search Result?Is There Any Snippet Leftin the Search Result?Does the Input ContainFundamental Words?FailureWikipedia-strictWikipedia-looseSnippetsComponentsDomain and IDFNoNoNoNoYesYesYesYesRemove Corporate Snippets in the ResultWeb Search & IDF CalculationFigure 1: Domain Estimation Processarticle in the top 30 of the search result if any, es-timate the domain with the Wikipedia-loose module(?4.1), and exit.
4 If no Wikipedia article is foundin the top 30 of the search result, then remove allcorporate snippets.
5 Estimate the domain with theSnippets module (?4.2) if any snippet is left in thesearch result, and exit.
6 If no snippet is left but theunknown word is a compound word containing fun-damental words, then estimate the domain with theComponents module (?4.3), and exit.
7 If no snip-pet is left and the word does not contain fundamentalwords, then the estimation is a failure.4.1 Wikipedia(-strict|-loose) ModuleThe two Wikipedia modules take the following pro-cedure: 1 Extract only fundamental words from theWikipedia article.
2 Assign domains and IDFs tothe words using the domain dictionary.
3 Sum upIDFs for each domain.
4 Assign the domain of thehighest IDF to the unknown word.
If the domainis NODOMAIN, the second highest domain is chosenfor the unknown word under the condition below:70Second-highest-IDF/ NODOMAIN?s-IDF>0.154.2 Snippets ModuleThe Snippets module takes as input the snippets thatare left in the search result after removing thoseof corporate web sites.
We remove snippets inwhich corporate keywords like sales appear morethan once.
The keywords were collected from theanalysis of our preliminary experiments.
Remov-ing corporate snippets is indispensable because theybias the estimation toward BUSINESS.
This moduleis the same as the Wikipedia modules except that itextracts fundamental words from residual snippets.4.3 Components ModuleThis is basically the same as the others except that itextracts fundamental words from the unknown worditself.
For example, the domain of finance market isestimated from the domains of finance and market.5 Evaluation5.1 Experimental ConditionData We categorized 600 Blog articles from Ya-hoo!
Blog (blogs.yahoo.co.jp) into the 12 do-mains (50 articles for each domain).
In Yahoo!
Blog,articles are manually classified into Yahoo!
Blog cat-egories (' domains) by authors of the articles.Evaluation Method We measured the accuracy ofcategorization and the domain estimation.
In cate-gorization, we tried three kinds of words to be ex-tracted from articles: fundamental words (F only inTable 3), fundamental and simplex unknown words(i.e.
no compound word) (F+SU), and fundamen-tal and all unknown words (both simplex and com-pound, F+AU).
Also, we measured the accuracy ofN best outputs (Top N).
During the categorization,about 12,000 unknown words were found in the 600articles.
Then, we sampled 500 estimation resultsfrom them.
Table 2 shows the breakdown of the 500unknown words in terms of their correct domains.The other 167 words belong to NODOMAIN.5.2 Result of Blog CategorizationTable 3 shows the accuracy of categorization.
TheF only column indicates that a rather simple methodlike the one in ?3 works well, if fundamental wordsare given good clues for categorization: the domainTable 2: Breakdown of Unknown WordsCULT 42 LIVI 19 SCIE 38RECR 15 DIET 19 BUSI 32SPOR 27 TRAN 28 MEDI 23HEAL 22 EDUC 24 GOVE 44Table 3: Accuracy of Blog CategorizationTop N F only F+SU F+AU1.
0.89 0.91 0.942.
0.96 0.97 0.983.
0.98 0.98 0.99in our case.
This is consistent with Kornai et al(2003), who claim that only positive evidence mat-ter in categorization.
Also, F+SU slightly outper-formed F only, and F+AU outperformed the others.This shows that the domain estimation of unknownwords moderately improves Blog categorization.Errors are mostly due to the system?s incorrect fo-cus on topics of secondary importance.
For exam-ple, in an article on a sightseeing trip, which shouldbe RECREATION, the author frequently mentions themeans of transportation.
As a result, the article waswrongly categorized as TRAFFIC.5.3 Result of Domain EstimationThe accuracy of the domain estimation of unknownwords was 77.2% (386/500).
Table 4 shows the fre-quency in use and accuracy for each domain esti-mation module.5 The Snippets module was usedTable 4: Frequency and Accuracy for each ModuleFrequency AccuracyWiki-s 0.146 (73/500) 0.85 (62/73)Wiki-l 0.208 (104/500) 0.70 (73/104)Snippt 0.614 (307/500) 0.76 (238/307)Cmpnt 0.028 (14/500) 0.64 (9/14)Failure 0.004 (2/500) ?
?most frequently and achieved the reasonably goodaccuracy of 76%.
Though the Wikipedia-strict mod-ule showed the best performance, it was used not5Wiki-s, Wiki-l, Snippt and Cmpnt stand for Wikipedia-strict, Wikipedia-loose, Snippets and Components, respectively.71so often.
However, we expect that as the numberof Wikipedia articles increases, the best performingmodule will be used more frequently.An example of newly coined words whose do-mains were estimated correctly is , whichis the abbreviation of 	day-trade.It was correctly assigned with BUSINESS by theWikipedia-loose module.Errors were mostly due to the subtle boundary be-tween NODOMAIN and the other particular domains.For instance, person?s names that are common andpopular should be NODOMAIN.
But in most casesthey were associated with some particular domain.This is due to the fact that virtually any person?sname is linked to some particular domain in the Web.6 Related WorkPrevious text categorization methods like Joachims(1999) and Schapire and Singer (2000) are mostlybased on machine learning.
Those methods needhuge quantities of training data, which is hard to ob-tain.
Though there has been a growing interest insemi-supervised learning (Abney, 2007), it is in anearly phase of development.In contrast, our method requires no training data.All you need is a manageable amount of fundamen-tal words with domains.
Also note that our methodis NOT tailored to the 12 domains.
If you wantyour own domains to categorize, it is only neces-sary to construct your own dictionary, which is alsodomain-independent and not time-consuming.In fact, there have been other proposals withoutthe burden of preparing training data.
Liu et al(2004) prepare representative words for each class,by which they collect initial training data to buildclassifier.
Ko and Seo (2004) automatically collecttraining data using a large amount of unlabeled dataand a small amount of seed information.
However,the novelty of this study is the on-the-fly estimationof unknown words?
domains.
This feature is veryuseful for categorizing Blog articles that are updatedon a daily basis and filled with newly coined words.Domain information has been used for many NLPtasks.
Magnini et al (2002) show the effectivenessof domain information for WSD.
Piao et al (2003)use domain tags to extract MWEs.Previous domain resources include WordNet(Fellbaum, 1998) and HowNet (Dong and Dong,2006), among others.
H&K?s dictionary is the firstfully available domain resource for Japanese.7 ConclusionThis paper presented a text categorization methodthat exploits H&K?s domain dictionary and the dy-namic domain estimation of unknown words.
In theBlog categorization, the method achieved the accu-racy of 94%, and the domain estimation of unknownwords achieved the accuracy of 77%.ReferencesSteven Abney.
2007.
Semisupervised Learning for Com-putational Linguistics.
Chapman & Hall.Zhendong Dong and Qiang Dong.
2006.
HowNet andthe Computation of Meaning.
World Scientific Pub CoInc.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press.Chikara Hashimoto and Sadao Kurohashi.
2007.
Con-struction of Domain Dictionary for Fundamental Vo-cabulary.
In ACL ?07 Poster, pages 137?140.Thorsten Joachims.
1999.
Transductive Inference forText Classification using Support Vector Machines.
InProceedings of the Sixteenth International Conferenceon Machine Learning, pages 200?209.Youngjoong Ko and Jungyun Seo.
2004.
Learning withUnlabeled Data for Text Categorization Using Boot-strapping and Feature Projection Techniques.
In ACL?04, pages 255?262.Andra?s Kornai, Marc Krellenstein, Michael Mulligan,David Twomey, Fruzsina Veress, and Alec Wysoker.2003.
Classifying the Hungarian web.
In EACL ?03,pages 203?210.Bing Liu, Xiaoli Li, Wee Sun Lee, , and Philip Yu.
2004.Text Classification by Labeling Words.
In AAAI-2004,pages 425?430.Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo,and Alfio Gliozzo.
2002.
The Role of Domain Infor-mation in Word Sense Disambiguation.
Natural Lan-guage Engineering, special issue on Word Sense Dis-ambiguation, 8(3):359?373.Scott S. L. Piao, Paul Rayson, Dawn Archer, AndrewWilson, and Tony McEnery.
2003.
Extracting multi-word expressions with a semantic tagger.
In Proceed-ings of the ACL 2003 workshop on Multiword expres-sions, pages 49?56.Robert E. Schapire and Yoram Singer.
2000.
BoosTex-ter: A Boosting-based System for Text Categorization.Machine Learning, 39(2/3):135?168.72
