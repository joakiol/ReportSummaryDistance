Proceedings of the NAACL HLT 2010: Tutorial Abstracts, pages 21?24,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsTextual EntailmentMark Sammons, University of IllinoisIdan Szpektor, Yahoo!V.G.
Vinod Vydiswaran, University of IllinoisThe NLP and ML communities are rising to grander, larger-scalechallenges such as Machine Reading, Learning by Reading, and Learningto Read, challenges requiring deeper and more integrated naturallanguage understanding capabilities.The task of Recognizing Textual Entailment (RTE) requires automatedsystems to identify when two spans of text share a common meaning --for example, that ``Alphaville Inc.'s attempted acquisition of Bauhausled to a jump in both companies' stock prices'' entails ``Bauahaus'stock rose'', but not ``Alphaville acquired Bauhaus''.
This generalcapability would be a solid proxy for Natural Language Understanding,and has direct relevance to the grand challenges named above.Moreover, it could be used to improve performance in a large range ofNatural Language Processing tasks such as Information Extraction,Question Answering, Exhaustive Search, Machine Translation and manyothers.
The operational definition of Textual Entailment used byresearchers in the field avoids commitment to any specific knowledgerepresentation, inference method, or learning approach, thusencouraging application of a wide range of techniques to the problem.Techniques developed for RTE have now been successfully applied in thedomains of Question Answering, Relation Extraction, and Machinetranslation, and RTE systems continue to improve their performanceeven as the corpora on which they are evaluated (provided first byPASCAL, and now by NIST TAC) have become progressively morechallenging.
Over the sequence of RTE challenges from PASCAL and NISTTAC, the more successful systems seem to have converged in theiroverall approach.The goal of this tutorial is to introduce the task of RecognizingTextual Entailment to researchers from other areas of NLP.
We willidentify and analyze common inference and learning approaches from arange of the more successful RTE systems, and investigate the role ofknowledge resources.
We will examine successful applications of RTEtechniques to Question Answering and Machine Translation, and identifykey research challenges that must be overcome to continue improvingRTE systems.21Tutorial Outline1.
Introduction (35 minutes)Define and motivate the Recognizing Textual Entailment (RTE)task.
Introduce the RTE evaluation framework.
Define the relationshipbetween RTE and other major NLP tasks.
Identify (some of) thesemantic challenges inherent in the RTE task, including theintroduction of 'contradiction' as an entailment category.
Describethe use of RTE components/techniques in Question Answering, MachineTranslation, and Relation Extraction.2.
The State of the Art (35 minutes)Outline the basic structure underlying RTE systems.
With reference torecent publications on RTE: cover the range of preprocessing/analysisthat may be used; define representations/data structures typicallyused; outline inference procedures and machine learning techniques.Identify challenging aspects of the RTE problem in the contextof system successes and failures.3.
Machine Learning for Recognizing Textual Entailment (35 minutes)Describe the challenges involved in applying machine learning techniquesto the Textual Entailment problem.
Describe in more detail the mainapproaches to inference, which explicitly or implicitly use the conceptof alignment.
Show how alignment fits into assumptions of semanticcompositionality, how it facilitates machine learning approaches, andhow it can accommodate phenomena-specific resources.
Show how itcan be used for contradiction detection.4.
Knowledge Acquisition and Application in Textual Entailment (35 minutes)Establish the role of knowledge resources in Textual Entailment,and the consequent importance of Knowledge Acquisition.Identify knowledge resources currently used in RTE systems, and theirlimitations.
Describe existing knowledge acquisition approaches,emphasizing the need for learning directional semantic relations.Define suitable representations and algorithms for using knowledge,including context-sensitive knowledge application.
Discuss theproblem of noisy data, and the prospects for new knowledgeresources/new acquisition approaches.225.
Key Challenges for Recognizing Textual Entailment (15 minutes)Identify the key challenges in improving textual entailment systems:more reliable inputs (when is a solved problem not solved), domainadaptation, missing knowledge, scaling up.
The need for a commonentailment infrastructure to promote resource sharing and development.Biographical Information of the PresentersMark SammonsUniversity of Illinois201 N. Goodwin Ave.Urbana, IL 61801 USAPhone: 1-217-265-6759Email: mssammon@illinois.eduMark Sammons is a Principal Research Scientist working with the CognitiveComputation Group at the University of Illinois.
His primary interests are in NaturalLanguage Processing and Machine Learning, with a focus on integrating diverseinformation sources in the context of Textual Entailment.
His work has focused ondeveloping a Textual Entailment framework that can easily incorporate new resources;designing appropriate inference procedures for recognizing entailment; and identifyingand developing automated approaches to recognize and represent implicit content innatural language text.
Mark received his MSC in Computer Science from the Universityof Illinois in 2004, and his PhD in Mechanical Engineering from the University of Leeds,England, in 2000.Idan SzpektorYahoo!
Research, Building 30 Matam Park, Haifa 31905, ISRAEL.Phone: + 972-74-7924666; Email: idan@yahoo-inc.comIdan Szpektor is a Research Scientist at Yahoo!
Research.
His primary researchinterests are  in natural language processing, machine learning and informationretrieval.
Idan recently submitted his PhD thesis at Bar-Ilan University where he workedon unsupervised acquisition and application of broad-coverage knowledge-bases forTextual Entailment.
He has been a main organizer of the second PASCAL RecognizingTextual Entailment Challenge and an advisor for the third RTE Challenge.
He served onthe program committees of EMNLP and TextInfer and reviewed papers for ACL,COLING and EMNLP.
Idan Szpektor received his M.Sc.
from Tel-Aviv University in2005, where he worked on unsupervised knowledge acquisition for Textual Entailment.V.G.Vinod VydiswaranUniversity of Illinois201 N. Goodwin Ave.Urbana, IL 61801 USA23Phone: 1-217-333-2584Email: vgvinodv@illinois.eduV.G.Vinod Vydiswaran is a 3rd year Ph.D. student in the Department of ComputerScience at the University of Illinois at Urbana-Champaign.
His research interests includetext informatics, natural language processing, machine learning, and informationextraction.
His work has included developing a Textual Entailment system, and applyingTextual Entailment to relation extraction and information retrieval.
He received hisMasters degree from Indian Institute of Technology Bombay, India in 2004, where heworked on Conditional models for Information Extraction.
Later, he worked at Yahoo!Research & Development Center at Bangalore, India, on scaling Information Extractiontechnologies over the Web.24
