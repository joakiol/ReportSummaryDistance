Transactions of the Association for Computational Linguistics, 1 (2013) 151?164.
Action Editor: Patrick Pantel.Submitted 12/2012; Revised 2/2013; Published 5/2013.
c?2013 Association for Computational Linguistics.Dijkstra-WSA: A Graph-Based Approach to Word Sense AlignmentMichael Matuschek ?
and Iryna Gurevych ???
Ubiquitous Knowledge Processing Lab (UKP-DIPF),German Institute for Educational Research and Educational InformationSchlo?str.
29, 60486 Frankfurt, Germany?Ubiquitous Knowledge Processing Lab (UKP-TUDA),Department of Computer Science, Technische Universita?t DarmstadtHochschulstr.
10, 64289 Darmstadt, Germanyhttp://www.ukp.tu-darmstadt.deAbstractIn this paper, we present Dijkstra-WSA, anovel graph-based algorithm for word sensealignment.
We evaluate it on four differentpairs of lexical-semantic resources with dif-ferent characteristics (WordNet-OmegaWiki,WordNet-Wiktionary, GermaNet-Wiktionaryand WordNet-Wikipedia) and show that itachieves competitive performance on 3 outof 4 datasets.
Dijkstra-WSA outperforms thestate of the art on every dataset if it is com-bined with a back-off based on gloss similar-ity.
We also demonstrate that Dijkstra-WSAis not only flexibly applicable to different re-sources but also highly parameterizable to op-timize for precision or recall.1 IntroductionLexical-semantic resources (LSRs) are a corner-stone for many Natural Language Processing (NLP)applications such as word sense disambiguation(WSD) and information extraction.
However, thegrowing demand for large-scale resources in dif-ferent languages is hard to meet.
The PrincetonWordNet (WN) (Fellbaum, 1998) is widely used forEnglish, but for most languages corresponding re-sources are considerably smaller or missing.
Col-laboratively constructed resources like Wiktionary(WKT) and OmegaWiki (OW) provide a viable op-tion for such cases and seem especially suitablefor smaller languages (Matuschek et al 2013), butthere are still considerable gaps in coverage whichneed to be filled.
A related problem is that thereusually does not exist a single resource which worksbest for all purposes, as different LSRs cover differ-ent words, senses and information types.These considerations have sparked increasing re-search efforts in the area of word sense alignment(WSA).
It has been shown that aligned resourcescan indeed lead to better performance than using theresources individually.
Examples include seman-tic parsing using FrameNet (FN), WN, and VerbNet(VN) (Shi and Mihalcea, 2005), word sense disam-biguation using an alignment of WN and Wikipedia(WP) (Navigli and Ponzetto, 2012) and semanticrole labeling using a combination of PropBank, VNand FN in the SemLink project (Palmer, 2009).Some of these approaches to WSA either rely heav-ily on manual labor (e.g.
Shi and Mihalcea (2005))or on information which is only present in fewresources such as the most frequent sense (MFS)(Suchanek et al 2008).
This makes it difficult toapply them to a larger set of resources.In earlier work, we presented the large-scale re-source UBY (Gurevych et al 2012).
It containsnine resources in two languages which are mappedto a uniform representation using the LMF standard(Eckle-Kohler et al 2012).
They are thus struc-turally interoperable.
UBY contains pairwise sensealignments between a subset of these resources, andthis work also presented a framework for creat-ing alignments based on the similarity of glosses(Meyer and Gurevych, 2011).
However, it is notclear to what extent this approach can be applied toresources which lack this kind of information (seeSection 3).In summary, aligning senses is a key requirementfor semantic interoperability of LSRs to increase the151coverage and effectiveness in NLP tasks.
Still, exist-ing efforts are mostly focused on specific types of re-sources (most often requiring glosses) or applicationscenarios.
In this paper, we propose an approach toalleviate this and present Dijkstra-WSA, a novel, ro-bust algorithm for word sense alignment which isapplicable to a wide variety of resource pairs andlanguages.
For the first time, we apply a graph-basedalgorithm which works on full graph representationsof both resources to word sense alignment.
This en-ables us to take a more abstract perspective and re-duce the problem of identifying equivalent senses tothe problem of matching nodes in these graphs.
Alsofor the first time, we comparatively evaluate a WSAalgorithm on a variety of different datasets with dif-ferent characteristics.The key properties of Dijkstra-WSA are:Robustness The entities within the LSRs whichare to be aligned (usually senses or synsets) are mod-eled as nodes in the graph.
These nodes are con-nected by an edge if they are semantically related.While, for instance, semantic relations lend them-selves very well to deriving edges, different possi-bilities for graph construction are equally valid asthe algorithm is agnostic to the origin of the edges.Language-independence No external resourcessuch as corpora or other dictionaries are needed; thegraph construction and alignment only rely on theinformation from the considered LSRs.Flexibility The graph construction as well as theactual alignment are highly parameterizable to ac-commodate different requirements regarding preci-sion or recall.The rest of this paper is structured as follows:In Section 2 we give a precise problem descriptionand introduce the resources covered in our experi-ments, in Section 3 we discuss some related work,while our graph-based algorithm Dijkstra-WSA ispresented in Section 4.
We describe an evaluationon four datasets with different properties, includingan error analysis, in Section 5 and conclude in Sec-tion 6, pointing out directions for future work.2 Notation and Resources2.1 Problem DescriptionA word sense alignment, or alignment for short, isformally defined as a list of pairs of senses fromtwo LSRs.
A pair of aligned senses denote the samemeaning.
E.g., the two senses of letter ?The conven-tional characters of the alphabet used to representspeech?
and ?A symbol in an alphabet, bookstave?
(taken from WN and WKT, respectively) are clearlyequivalent and should be aligned.2.2 Evaluation ResourcesFor the evaluation of Dijkstra-WSA, we align fourpairs of LSRs used in previous work, namely WN-OW (Gurevych et al 2012), WN-WKT (Meyer andGurevych, 2011), GN-WKT (Henrich et al 2011)and WN-WP (Niemann and Gurevych, 2011).
Ourgoal is to cover resources with different character-istics: Expert-built (WN, GN) and collaborativelyconstructed LSRs (WP, WKT, OW), resources indifferent languages (English and German) and alsoresources with few sense descriptions (GN) or se-mantic relations (WKT).
We contrastively discussthe results of the Dijkstra-WSA algorithm on thesedifferent datasets and relate the results to the prop-erties of the LSRs involved.
Moreover, using exist-ing datasets ensures comparability to previous workwhich discusses only one dataset at a time.WordNet (WN) (Fellbaum, 1998) is a lexical re-source for the English language created at PrincetonUniversity.
The resource is organized in sets of syn-onymous words (synsets) which are represented byglosses (sometimes accompanied by example sen-tences) and organized in a hierarchy.
The latest ver-sion 3.0 contains 117,659 synsets.Wikipedia (WP) is a freely available, multilin-gual online encyclopedia.
WP can be edited by ev-ery Web user, which causes rapid growth: By Febru-ary 2013 the English WP contained over 4,000,000article pages.
Each article usually describes a dis-tinct concept, and articles are connected by hyper-links within the article texts.Wiktionary (WKT) is the dictionary pendant toWP.
By February 2013 the English WKT containedover 3,200,000 article pages, while the German edi-tion contained over 200,000 ones.
For each word,multiple senses can be encoded.
Similar to WN,they are represented by a gloss and usage exam-ples.
There also exist hyperlinks to synonyms, hy-pernyms, meronyms etc.
The targets of these rela-tions are not senses, however, but merely lexemes(i.e.
the relations are not disambiguated).152LSRs P /R/F1/Acc.
ApproachMeyer and Gurevych (2011) WN-WKT 0.67/0.65/0.66/0.91 Gloss similarity + Machine learningNiemann and Gurevych (2011) WN-WP 0.78/0.78/0.78/0.95 Gloss similarity + Machine learningHenrich et al(2011) GN-WKT 0.84/0.85/0.84/0.94 Pseudo-gloss overlapde Melo and Weikum (2010) WN-WP 0.86/NA/NA/NA Gloss/article overlapLaparra et al(2010) FN-WN 0.79/0.79/0.79/NA Dijkstra-SSI+ (WSD algorithm)Navigli (2009) WN 0.64/0.64/0.64/NA Graph-based WSD of WN glossesPonzetto and Navigli (2009) WN-WP NA/NA/NA/0.81 Graph-based, only for WP categoriesNavigli and Ponzetto (2012) WN-WP 0.81/0.75/0.78/0.83 Graph-based WSA using WN relationsTable 1: Summary of various approaches to WSA.
?NA?
stands for ?Not Available?.OmegaWiki (OW) is a freely editable onlinedictionary like WKT.
However, there do not ex-ist distinct language editions as OW is organizedin language-independent concepts (?Defined Mean-ings?)
to which lexicalizations in various languagesare attached.
These can be considered as multilin-gual synsets, and they are interconnected by unam-biguous relations just like WN.
As of February 2013,OW contains over 46,000 of these concepts and lex-icalizations in over 400 languages.GermaNet (GN) is the German counterpart toWN (Hamp and Feldweg, 1997).
It is also organizedin synsets (around 70,000 in the latest version 7.0)which are connected via semantic relations.3 Related WorkThe are two strands of closely related work:Similarity-based and graph-based approaches toword sense alignment.
To our knowledge, there ex-ists no previous work which fully represents bothLSRs involved in an alignment as graphs.
We give asummary of different approaches in Table 1.3.1 Similarity-based ApproachesNiemann and Gurevych (2011) and Meyer andGurevych (2011) created WN-WP and WN-WKTalignments using a framework which first calcu-lates the similarity of glosses (or glosses and ar-ticles in the case of WN-WP) using either cosineor personalized page rank (PPR) similarity (Agirreand Soroa, 2009) and then learns a threshold on thegold standard to classify each pair of senses as a(non-)valid alignment.
This approach was later ex-tended to cross-lingual alignment between the Ger-man OW and WN (Gurevych et al 2012) using amachine translation component.
However, its appli-cability depends on the availability and quality of theglosses, which are not present in every case (e.g.
forVN).
Moreover, as it involves supervised machinelearning, it requires the initial effort of manually an-notating a sufficient amount of training data.
Hen-rich et al(2011) use a similar approach for align-ing GN and WKT.
However, they use word over-lap as a similarity measure and do not require a ma-chine learning component as they align to the can-didate sense with the highest similarity regardless ofthe absolute value.
The alignment of WP articlesand WN synsets reported by de Melo and Weikum(2010) also relies on word overlap.Although these approaches give reasonable re-sults (with precision in the range of 0.67-0.84), theyall depend on the lexical knowledge contained in theglosses, yielding low recall if there is insufficientlexical overlap (known as the ?lexical gap?, see forinstance (Meyer and Gurevych, 2011)).
Considerthese two senses of Thessalonian in WKT and WN:?A native or inhabitant of Thessalonica?
and ?Some-one or something from, or pertaining to, Thessa-loniki?.
These are (mostly) identical and should bealigned, but there is no word overlap due to the in-terchangeable usage of the synonyms Thessalonicaand Thessaloniki.3.2 Graph-based ApproachesLaparra et al(2010) utilize the SSI-Dijkstra+ al-gorithm to align FN lexical units (LUs) with WNsynsets.
The basic idea is to align monosemous LUsfirst and, based on this, find the closest synset in WNfor the other LUs in the same frame.
However, asSSI-Dijkstra+ is a word sense disambiguation (notalignment) algorithm, the LUs are merely consid-ered as texts which are to be disambiguated; thereis no attempt made to build a global graph structurefor FN.
Moreover, the algorithm solely relies on the153semantic relations found in WN and eXtended WN(Mihalcea and Moldovan, 2001).
Thus, it is not ap-plicable to other resources which have no or onlyfew relations such as WKT.Navigli (2009) aims at disambiguating WNglosses, i.e.
assigning the correct senses to all non-stopwords in each WN gloss.
His approach is tofind the shortest possible circles in the WN relationgraph to identify the correct disambiguation.
In laterwork, this idea was extended to the disambiguationof translations in a bilingual dictionary (Flati andNavigli, 2012).
However, there is no discussion ofhow this idea could be applied to word sense align-ment of two or more resources.
We build upon thisidea of finding shortest paths (circles are a specialkind of path) and extend it to multiple resources andedges other than semantic relations, in particular WPlinks and links to senses of monosemous lexemesappearing in glosses.Ponzetto and Navigli (2009) propose a graph-based method to tackle the related, but slightly dif-ferent problem of aligning WN synsets and WP cat-egories (not articles).
Using semantic relations, theybuild WN subgraphs for each WP category and thenalign those synsets which best match the categorystructure.
In later work, Navigli and Ponzetto (2012)also align WN with the full WP.
They build ?disam-biguation contexts?
for the senses in both resourcesby using, for instance, WP redirects or WN glossesand then compute the similarity between these con-texts.
Again, a graph structure is built from WN se-mantic relations covering all possible senses in thesecontexts.
The goal is to determine which WN senseis closest to the WP sense to be aligned.
While theseapproaches are in some respects similar to Dijkstra-WSA, they do not take the global structure of bothresources into account.
Instead, they merely relyon a (locally restricted) subset of WN relations forcreating the alignment.
Thus, applying these ap-proaches to resources in different languages mightbe difficult if WN relations are not applicable.4 Dijkstra-WSAIn this section, we discuss our approach to aligninglexical-semantic resources based on the graph struc-ture.
This includes two steps: (i) the initial construc-tion of the graphs using appropriate parameters, and(ii) the alignment itself.4.1 Graph ConstructionWe represent the set of senses (or synsets, if appli-cable) of an LSR L as a set of nodes V where the setof edges E,E ?
V ?
V between these nodes rep-resents semantic relatedness between them.
We callthis a resource graph.
A WP article is considered asense as it represents a distinct concept.There are multiple options for deriving the edgesfrom the resource.
The most straightforward ap-proach is to directly use the existing semantic rela-tions (such as hyponymy), as it has been reported inprevious work (Laparra et al 2010; Navigli, 2009).For WP, we can directly use the given hyperlinks be-tween articles as they also express a certain degreeof relatedness (Milne and Witten, 2008).
However,for many LSRs no or only few semantic relationsexist.
Consider WKT: Its relations are not sense dis-ambiguated (Meyer and Gurevych, 2012).
We thuscannot determine the correct target sense if a relationis pointing to an ambiguous word.Our solution to this is twofold: First, for eachsense s, we create an edge (s, t) for those seman-tic relations which have a monosemous target t, asin this case the target sense is unambiguous.
Thisapproach, however, only recovers a subset of the re-lations, and it is not applicable to resources whereno sense relations exist at all, e.g.
FN.
For this case,we propose to use the glosses of senses in the LSRto derive additional edges in the following way: Foreach monosemous, non-stopword lexeme l (a com-bination of lemma and part of speech) in the glossof a sense s1 with a sense sl, we introduce an edge(s1, sl).
Moreover, if there is another sense s2 with lin its gloss, we also introduce an edge (s1, s2).
Thistechnique will be called linking of monosemous lex-emes or monosemous linking throughout the rest ofthis paper.
The intuition behind this is that monose-mous lexemes usually have a rather specific mean-ing, and thus it can be expected that the senses inwhose description they appear have at least a certaindegree of semantic relationship.
This directly re-lates to the notion of ?information content?
(Resnik,1995), stating that senses in an LSR which are morespecific (and hence more likely to be monosemous)are more useful for evaluating semantic similarity.Note that this step requires part of speech tagging154of the glosses, which we perform as a preprocess-ing step.
Thereby we filter out stopwords and wordstagged as ?unknown?
by the POS tagger.As an example, consider the gloss of Java: ?Anobject-oriented programming language?.
Even inthe absence of any semantic relations, we couldunambiguously derive an edge between this senseof Java and the multiword noun programming lan-guage if the latter is monosemous, i.e.
if there existsexactly one sense for this lexeme in the LSR.
Also,if programming language appears in the gloss of oneof the senses of Python, we can derive an edge be-tween these senses of Java and Python, expressingthat they are semantically related.An important factor to keep in mind, however, isthe density of the resulting graph.
In preliminary ex-periments, we discovered that linking every monose-mous lexeme yielded very dense graphs with shortpaths between most senses.
In turn, we decided toexclude ?common?
lexemes and focus on more spe-cific ones in order to increase the graph?s meaning-fulness.
The indicator for this is the frequency of alexeme in the LSR, i.e.
how often it occurs in theglosses.
Our experiments on small development sets(100 random samples of each gold standard) indeedshow that a strict filter leads to discriminative edgesresulting in high precision, while at the same timegraph sparsity decreases recall.
Independently ofthe resource pair, we discovered that setting this fre-quency limit value ?
to about 1/100 of the graph size(e.g.
1,000 for a graph containing 100,000 senses)gives the best balance between precision and recall;larger values of ?
usually led to no significant im-provement1 in recall while the precision was contin-uously degrading.
Note that WP was excluded fromthese experiments as the identification and linking ofmonosemous lexemes in all WP articles proved tootime-consuming; instead, we decided to use only thealready given links (see Section 5.3).4.2 Computing Sense AlignmentsInitialization After resource graphs for both LSRsA and B are created, the trivial alignments are re-trieved and introduced as edges between them.
Triv-ial alignments are those between senses which have1All significance statements throughout the paper are basedon McNemar?s test and the confidence level of 1%.Dijkstra-WSA(A,B)1 ASenseSet = A.senses2 BSenseSet = B.senses3 UnalignableSenses = ?45 foreach sense s ?
ASenseSet6 if(s.isMonosemous)7 t = findTrivialMatch(s, BSenseSet)8 if(t != null)9 ASenseSet.remove(s)10 BSenseSet.remove(t)11 createEdge(s,t)1213 foreach sense s?
?
ASenseSet14 ASenseSet.remove(s?
)15 T=findCandidatesWithSameLexeme(s?, B)16 if(T!= ?
)17 t?=findShortestPathToCandidates(s?, T)18 if(t?
!= null)19 createEdge(s?, t?
)20 else21 UnalignableSenses.put(s?
)22 else23 UnalignableSenses.put(s?
)Table 2: Pseudocode of the Dijkstra-WSA algorithm.the same attached lexeme inA andB and where thislexeme is also monosemous within either resource.E.g., if the noun phrase programming language iscontained in either resource and has exactly onesense in each one, we can directly infer the align-ment.
For WP, a lexeme was considered monose-mous if there was exactly one article with this title,also counting titles with a bracketed disambiguation(e.g., Java (programming language) and Java (is-land) are two distinct senses of Java).
While thismethod does not work perfectly, we observed a pre-cision> 0.95 for monosemous gold standard senses,which is in line with the observations by Henrich etal.
(2011).Alignment We consider each sense s ?
A whichhas not been aligned in the initialization step.
Forthis, we first retrieve the set of possible target sensesT ?
B (those with matching lemma and part ofspeech) and compute the shortest path to each ofthem with Dijkstra?s shortest path algorithm (Dijk-155stra, 1959).
The candidate t ?
T with the shortestdistance is then assigned as the alignment target, andthe algorithm continues with the next still unalignedsense in A until either all senses are aligned or nopath can be found for the remaining senses.
The in-tuition behind this is that the trivial alignments fromthe initialization serve as ?bridges?
between A andB, such that a path starting from a sense s1 in A tra-verses edges to find a nearby already aligned senses2, ?jumps?
to B using a cross-resource edge lead-ing to t2 and then ideally finds an appropriate targetsense t1 in the vicinity of t2.
Note that with eachsuccessful alignment, edges are added to the graphso that, in theory, a different ordering of the consid-ered senses would lead to different results.
Whilewe observed slight differences for repeated runs us-ing the same configuration, these were in no casestatistically significant.
The pseudo code of this al-gorithm can be found in Table 2, while an examplecan be found in Figure 1.Figure 1: An example of how Dijkstra-WSA works.While there exist 2 candidates for aligning a sense s1 ?
A(dashed lines) (a), the correct one t1 ?
B can be deter-mined by finding the shortest path using an already es-tablished edge between two monosemous senses s2 ?
Aand t2 ?
B (solid line) (b).Parameter Influence Apart from the alreadymentioned parameter ?
for limiting the number ofedges in the graph, another important variable is themaximum allowed path length ?
of Dijkstra?s algo-rithm.
In general, allowing an unbounded search forthe candidate senses is undesirable as long paths,while increasing recall, usually also lead to a de-crease in precision, as the nodes which can bereached in many steps are usually also semanticallydistant from the source sense.
In this respect, wefound significant differences between the optimalconfiguration for individual resource pairs.
How-ever, the general observation is that short paths (?
?3) lead to a very high precision, while paths longerthan 10 do not increase recall significantly any more.A modification of the algorithm is to not onlyalign the closest target sense, but all senses whichcan be reached with a certain number of steps.
Thiscaters to the fact that, due to different sense granu-larities, one coarser sense inA can be represented byseveral senses in B and vice versa (see Table 3 forthe fraction of 1:n alignments in the datasets).
Re-garding this modification, we made the observationthat the recall improved (sometimes considerably),but at the same time the precision decreased, some-times to an extent where the overall F-Measure (theharmonic mean of precision and recall) got worse.In the evaluation section, we state which setting isused for which datasets and configurations.5 Experimental Work5.1 Datasets and their CharacteristicsWN 3.0-English OW The previous alignment be-tween these two resources reported in Gurevych etal.
(2012) is based on the German OW (databasedump from 2010/01/03) and WN 3.0 and utilizesgloss similarities using machine translation as an in-termediate component.
This does not pose a prob-lem since for each synset in the German part of OW,there is a translation in the English part.
This makesthe German-English gold standard directly usablefor our purposes.2 Table 3 presents the details aboutthis as well as the other evaluation datasets, includ-ing the observed inter-rater agreement A0 (whereavailable) which can be considered as an upperbound for automatic alignment accuracy and the de-gree of polysemy (i.e.
the number of possible align-ment targets per sense) which is a hint towards thedifficulty of the alignment task.WN 3.0-English WKT We use the gold stan-dard dataset from Meyer and Gurevych (2011) with-out any modification, thus for comparability to this2Cross-lingual alignment is left to future work.156work, we use the same WKT dump version (from2010/02/01) which contains around 421,000 senses.GN 7.0-German WKT Henrich et al(2011)aligned the German WKT (dump from 2011/04/02,72,000 senses) and GN 7.0.
This is the only existingalignment between these two resources so far, andwe use their freely available dataset3 to test Dijkstra-WSA on a language other than English.
As thisalignment is fairly large (see Table 3), we created arandom sample as a gold standard to keep the com-putation time at bay.
However, the datasets are stillsimilar enough to allow direct comparison of theresults.
Note that no inter-annotator agreement isavailable for this study.WN 3.0-English WP We use the gold standardfrom Niemann and Gurevych (2011).
For compa-rability, we use the same Wikipeda dump version(from 2009/08/22) with around 2,921,000 articles.5.2 BaselinesWN-OW We used the same configuration as inGurevych et al(2012) to calculate a similarity-based alignment for the monolingual case (i.e.
with-out the translation step) as a baseline and achievedcomparable results.WN-WKT As stated above, the alignment4 pre-sented in Meyer and Gurevych (2011) was createdby calculating the similarity of glosses and traininga machine-learning classifier on the gold standard toclassify each pair of senses.GN-WKT The automatic alignment results (i.e.the outcome of the algorithm without manual post-correction) reported by Henrich et al(2011) wereunavailable for us as a baseline.
Thus, we utilizethe alignment approach by Meyer and Gurevych(2011) to create a similarity-based baseline, with mi-nor modifications.
Unlike the original approach, wedirectly align senses regardless of their similarity ifthe decision is trivial (see Section 4.2).
We also donot train a machine learning component on a goldstandard.
Instead, we adapt the idea of Henrich et al(2011) to align the most similar candidate regardlessof the absolute value.WN-WP The alignment reported in Niemann andGurevych (2011) was created in the same way as3http://www.sfs.uni-tuebingen.de/GermaNet/wiktionary.shtml4Available at http://www.ukp.tu-darmstadt.de/data/lexical-resources/wordnet-wiktionary-alignment/the WN-WKT alignment described in Meyer andGurevych (2011).
Note that while the full alignmentresults5 proved incomplete, the correct alignment re-sults on the gold standard were available and thusused in our experiments.We will henceforth mark these similarity-basedresults with SB.5.3 System ConfigurationsFor the construction of the resource graphs we ex-perimented with three options:Semantic relations only (SR) OW, WN and GNall feature disambiguated sense relations which canbe directly used as edges between senses.
Note thatin the expert-built resources, the majority of nodesare connected by sense relations, while this is notthe case for OW.
For WKT, only the unambiguoussemantic relations can be used (see Section 4.1), re-sulting in graphs less dense and with many isolatednodes.
However, as we reported in Matuschek etal.
(2013), the English WKT is almost 6 times aslarge as the German one for the versions we used inour experiments (421,000 senses vs. 72,000 senses),while it contains not even twice as many relations(720,000 vs. 430,000).
This is directly reflected inthe fewer isolated nodes for the German WKT.
WPlinks are also unambiguous as they lead to a distinctarticle.
However, intuitively not all links in an arti-cle are equally meaningful.
Thus, for the SR config-uration, we decided to retain only the category linksand the links within the first paragraph of the article.We assume that the targets of these links are mostclosely related to the sense an article represents asthe first paragraph usually includes a concise defini-tion of a concept, and the category links allow deter-mining the topic an article belongs to.Linking of monosemous lexemes only (LM) Forthis configuration, the limiting parameter ?
was setto 1/100 of the graph size for every resource ex-cept WP as described in section 4.1.
As our ex-periments show, linking the monosemous lexemes inthe glosses while disregarding semantic relations re-sults in well-connected graphs for all resources butGN and WKT.
Only about 10% of the GN senseshave a gloss, thus this option was completely disre-5Available at http://www.ukp.tu-darmstadt.de/data/lexical-resources/wordnet-wikipedia-alignment/157Pair Aligned Not Aligned Sum 1:n Alignments % Polysemy Sampling A0WN-OW 210 473 683 10.7% 1.50 Random 0.85WN-WKT 313 2,110 2,423 2.7% 4.76 Balanced 0.93GN-WKT (full) 27,127 18,509 45,636 5.6% 1.78 All N/AGN-WKT (sample) 1,000 751 1,751 4.8% 1.84 Random N/AWN-WP 227 1,588 1,815 5.2% 5.7 Balanced 0.97Table 3: Characteristics of the gold standards used in the evaluation.
A0 is the observed inter-rater agreement whichcan be considered as an upper bound for alignment accuracy.
The degree of polysemy (i.e.
the number of possiblealignment targets per sense) hints towards the difficulty of the alignment task.garded in this case.
For both WKTs, an analysis ofthe graphs revealed that the reason for the relativelyhigh number of isolated nodes are very short glosses,containing many polysemous lexemes.
For WP, werefrained from monosemous linking due to the pro-hibitive computation time.
Instead, we decided touse the fully linked WP (excluding the links usedfor the SR configuration) in this case.
The rationaleis that in the majority of articles many meaningfulterms link to the corresponding articles anyway, sothat the resulting graph is comparable with those forthe other LSRs.Combining both (SR+LM) This configurationyields the maximum number of available edges.
Wereport the results for GN only for this configurationand omit the SR results for the sake of brevity asthe influence on the F-Measure for the GN-WKTalignment (see Section 5.4) is not statistically sig-nificant.
For WKT, this configuration only increasesthe number of connected nodes slightly (as insuffi-cient glosses often coincide with missing semanticrelations), while for OW an almost connected graphcan be constructed.Table 4 gives an overview of the fraction of iso-lated nodes for each resource in every configuration.Note again that for each alignment task (i.e.
eachpair of resources), we tuned the parameters on 100random samples from each gold standard for a resultbalancing precision and recall as discussed above.Individual tuning of parameters was necessary foreach pair due to the greatly varying properties of theLSRs (e.g.
the number of senses).
While it wouldhave been ideal to train and test on disjoint sets, wecalculated the overall results on the full gold stan-dards including the development sets to ensure com-parability with the previous work.Hybrid Approach Manual inspection of the re-sults revealed that the alignments found by Dijkstra-Resource SR LM SR+LMWN 0.25 0.07 0.02GN 0.0 0.92 0.0WKT-en 0.98 0.32 0.30WKT-de 0.69 0.18 0.15OW 0.41 0.33 0.04WP 0.06 0.05 0.04Table 4: This table describes what percentage of nodesremains isolated (i.e.
with 0 attached edges) in differ-ent graph configurations using semantic relations (SR),monosemous linking (LM) (?
= 1/100) or both(SR+LM).
Note that this number is highest for the En-glish WKT as the few semantic relations and shortglosses do not offer many possibilities for connectingnodes, while the German WKT and OW do not sufferfrom this problem as much.
GN is fully linked via re-lations, but has only few glosses which makes monose-mous linking ineffective.
WN and WP are relatively well-linked in all configurations.
Also note that for WP, SRmeans that we used category links and links from the firstparagraph, while links from the rest of the article wereused for the LM configuration.WSA are usually different from those based on thegloss similarity.
While the latter precisely recog-nizes alignments with similar wording of glosses,Dijkstra-WSA is advantageous if the glosses are dif-ferent but the senses are still semantically close inthe graph.
Section 5.5 will analyze this in greaterdetail.
Exploiting this fact, we experimented witha hybrid approach: We perform an alignment us-ing Dijkstra-WSA, tuned for high precision (i.e.
us-ing shorter path lengths) and fall back to using theresults of the similarity-based approaches for thosecases where no alignment target could be found inthe graph.
These results are marked with +SB in theresult overview (Table 5).158WordNet-OmegaWiki WordNet-Wiktionary GermaNet-Wiktionary WordNet-WikipediaP R F1 Acc.
P R F1 Acc.
P R F1 Acc.
P R F1 Acc.Random 0.46 0.35 0.40 0.51 0.21 0.59 0.31 0.67 0.44 0.51 0.47 0.54 0.49 0.62 0.53 0.86SB 0.55 0.53 0.54 0.73 0.67 0.65 0.66 0.91 0.93 0.74 0.83 0.83 0.78 0.78 0.78 0.95SR 0.66 0.45 0.53 0.76 0.95 0.13 0.23 0.89 0.94 0.65 0.77 0.78 0.82 0.63 0.71 0.93LM 0.62 0.54 0.58 0.77 0.72 0.24 0.36 0.89 0.89 0.75 0.81 0.80 0.65 0.66 0.65 0.91SR+LM 0.56 0.69 0.62 0.74 0.68 0.27 0.39 0.89 0.90 0.78 0.83 0.82 0.75 0.67 0.71 0.93SR+SB 0.60 0.65 0.63 0.76 0.68 0.67 0.68 0.92 0.90 0.82 0.86 0.84 0.75 0.87 0.81 0.95LM+SB 0.60 0.70 0.64 0.76 0.68 0.70 0.69 0.92 0.86 0.87 0.87 0.85 0.70 0.87 0.78 0.94SR+LM+SB 0.57 0.75 0.65 0.75 0.68 0.71 0.69 0.92 0.87 0.88 0.87 0.85 0.75 0.87 0.81 0.95A0 - - - 0.85 - - - 0.93 - - - N/A - - - 0.97Table 5: Alignment results for all datasets and configurations: Using semantic relations (SR), monosemous links(LM) or both (SR+LM).
The similarity-based (SB) baselines, also used as a back-off for the hybrid approaches (+SB),were created using the approach reported in Gurevych et al(2012).
Note that for GN, the SR+LM configuration wasalways used.
The different configurations given for this alignment thus only apply to WKT.
For WP, SR means thatonly category links and links within the first paragraph were used, while LM uses links from the full article.
A randombaseline and the inter-annotator agreement A0 of the gold standard annotation (if available) are given for reference.5.4 Experimental ResultsWN-OW When using only semantic relations (SR),we achieved an F-Measure of 0.53 which is com-parable with the 0.54 from Gurevych et al(2012).Notably, our approach has a high precision, whilethe recall is considerably worse due to the relativesparsity of the resulting OW resource graph.
Whenadding more edges to the graph by linking monose-mous lexemes (SR+LM), we can drastically improvethe recall, leading to an overall F-Measure of 0.62,which is a significant improvement over our previ-ous results (Gurevych et al 2012).
Using monose-mous links only (LM), the result of 0.58 still out-performs Gurevych et al(2012) due to the higherprecision.
Building a graph from glosses alone isthus a viable approach if no or only few semanticrelations are available.
Regarding the path lengths,?
= 10 works best when semantic relations are in-cluded in the graph, while for the LM configura-tion shorter paths (?
?
5) were more appropriate.The intuition behind this is that for semantic rela-tions, unlike monosemous links, even longer pathsstill express a high degree of semantic relatedness.Also, when semantic relations are involved allow-ing multiple alignments increases the overall results(which is in line with the relatively high number of1:n alignments in the gold standard), while this is notthe case for the LM configuration; here, the edgesagain do not sufficiently express relatedness.Using the hybrid approach (+SB), we can increasethe F-Measure up to 0.65 if semantic relations andmonosemous linking are combined (SR+LM) andthe parameters are tuned for high precision (?
?
3,1:1 alignments).
This is significantly better thanDijkstra-WSA alone in any configuration.
In thisscenario, we also observe the best overall recall.WN-WKT Experiments using only the semanticrelations (SR) yield a very low recall - the smallnumber of sense relations with monosemous targetsin WKT leaves the graph very sparse.
Nevertheless,the alignment targets which Dijkstra-WSA finds aremostly correct, with a precision greater than 0.95even when allowing 1:n alignments.
Using onlymonosemous links (LM) improves the recall consid-erably, but unlike the WN-OW alignment, it staysfairly low.
Consequently, even when using seman-tic relations and monosemous links in conjunction(SR+LM), the recall can only be increased slightly,leading to an overall F-Measure of 0.39.
As men-tioned above, this is due to the WKT glosses.
Inmany cases, they are very short, often consistingof only 3-5 words, many of which are polysemous.This leads to many isolated nodes in the graph withno or only very few connecting edges.
The ideal,rather short path length ?
of 2-3 stems from the rela-tively high polysemy of the gold standard (see Table3).
We experimented with ?
?
4, achieving rea-sonable recall, but in this case the precision was solow that this configuration, in conclusion, does notincrease the F-Measure.
However, 1:n alignmentswork well with these short paths as the correct align-ments are mostly in the close vicinity of a sense,159hence we achieve an increase in recall in this casewithout too much loss of precision.For the hybrid approach, we achieve anF-Measure of 0.69 when using all edges(SR+LM+SB), setting the path length to 2, andalso allowing 1:n alignments.
This is a statisticallysignificant improvement over Meyer and Gurevych(2011) which again confirms the effectiveness ofthe hybrid approach.GN-WKT As stated above, we used the SR+LMconfiguration for GN in every case.
For the GermanWKT, the much greater number of relations com-pared to its English counterpart is directly reflectedin the results, as using the semantic relations only(SR) not only yields the best precision of 0.94 butalso a good recall of 0.65.
Using the semantic re-lations together with monosemous links (SR+LM)yields the F-Measure of 0.83, which is on par withthe similarity-based (SB) approach.In the hybrid configuration, we can increasethe performance to an F-Measure of up to0.87 (SR+LM+SB), significantly outperforming allgraph-based and similarity-based configurations.In general, results for this pair of LSRs are higherin comparison with the others.
We attribute this tothe fact that the German WKT and GN both aredensely linked with semantic relations which is es-pecially beneficial for the recall of Dijkstra-WSA.This is also reflected in the ideal ?
of 10-12: Manyhigh-confidence edges allow long paths which stillexpress a considerable degree of relatedness.
How-ever, while the results for 1:n alignments are al-ready good, restricting oneself to 1:1 alignmentsgives the best overall results as the precision canthen be pushed towards 0.90 without hurting recalltoo much.
An important factor in this respect is thatthe GN-WKT dataset has a relatively low degree ofpolysemy (compared to WN-WKT) and only few1:n alignments (compared to WN-OW), two factswhich make the task significantly easier.WN-WP The SR configuration (WN relations +WP category/first paragraph links) yields the bestprecision (0.82), even outperforming the SB ap-proach, and an F-Measure of 0.71.
This again showsthat using an appropriate parametrization (?
?
4in this case) Dijkstra-WSA can detect alignmentswith high confidence.
The relatively low recall of0.63 could be increased by allowing longer paths,however, as hyperlinks do not express relatedness asreliably as semantic relations, this introduces manyfalse positives and thus hurts precision considerably.This issue of ?misleading?
WP links becomes evenmore prominent when the links from the full articlesare used as edges (LM); while the increase in recallis relatively small the precision drops substantially.However, using all possible links (SR+LM) allowsus to balance out precision and recall to some extent,while yielding the same F-Measure as the SR config-uration.
Note that 1:1 alignments were enforced inany case, as the high polysemy of the dataset in con-junction with the dense WP link structure rendered1:n alignments very imprecise.Using the hybrid approach, we can increase the F-Measure up to 0.81 (SR+SB), outperforming the re-sults reported in Niemann and Gurevych (2011) bya significant margin.
The F-Measure for LM+SB isslightly worse due to the lower precision.
Combin-ing all edges (SR+LM+SB) does not influence theresults any more, but in any case the hybrid configu-ration achieves the best overall recall (0.87).In conclusion, our experiments on all fourdatasets consistently demonstrate that combiningDijkstra-WSA with a similarity-based approach asa back-off yields the strongest performance.
The re-sults of these best alignments will be made freelyavailable to the research community on our website(http://www.ukp.tu-darmstadt.de).5.5 Error AnalyisThe by far most significant error source, reflected inthe relatively low recall for different configurations,is the high number of false negatives, i.e.
sense pairswhich were not aligned although they should havebeen.
This is especially striking for the WN-WKTalignment.
As discussed earlier, WKT contains asignificant number of short glosses, which in manycases also contain few or no monosemous terms.
Aprototypical example is the first sense of seedling:?A young plant grown from seed?.
This gloss hasno monosemous words which could be linked, andas there are also no semantic relations attached tothis sense which could be exploited, the node is iso-lated in the graph.
Our experiments show that forthe English WKT, even when optimizing the param-eters for recall, around 30% of the senses remainisolated, i.e.
without edges.
This is by far the high-160est value across all resources (see Table 4).
Solv-ing this problem would require making the graphmore dense, and especially finding ways to includeisolated nodes as well.
However, this example alsoshows why the hybrid approach works so well: Thecorrect WN sense ?young plant or tree grown froma seed?
was recognized by the similarity-based ap-proach with high confidence.With regard to false positives, Dijkstra-WSA andthe similarity-based approaches display very similarperformance.
This is because senses with very sim-ilar wording are likely to share the same monose-mous words, leading to a close vicinity in the graphand the false alignment.
As an example, considertwo senses of bowdlerization in WN (?written mate-rial that has been bowdlerized?)
and WKT (?The ac-tion or instance of bowdlerizing; the omission or re-moval of material considered vulgar or indecent.?
).While these senses are clearly related, they are notidentical and should not be aligned, nevertheless thesimilar wording (and especially the use of the highlyspecific verb ?bowdlerize?)
results in an alignment.Similarly to the similarity-based approaches, it is anopen question how this kind of error can be effec-tively avoided (Meyer and Gurevych, 2011).There is a considerable number of exam-ples where Dijkstra-WSA recognizes an alignmentwhich similarity-based approaches do not.
The twosenses of Thessalonian from the introductory exam-ple (Section 3) contain the terms Thessalonica andThessaloniki in their glosses which are both monose-mous in WN as well as in WKT, sharing the alsomonosemous noun Greece in their glosses.
Thisyields the bridge between the resources to find a pathand correctly derive the alignment.6 Conclusions and Future WorkIn this work, we present Dijkstra-WSA, a graph-based algorithm for word sense alignment.
Weshow that this algorithm performs competitively on3 out of 4 evaluation datasets.
A hybrid approachleads to a statistically significant improvement oversimilarity-based state of the art results on everydataset.
Dijkstra-WSA can operate on glosses orsemantic relations alone (although it is beneficial ifboth are combined), and it does not require any ex-ternal knowledge in the form of annotated trainingdata or corpora.
Additionally, it is flexibly config-urable for different pairs of LSRs in order to opti-mize for precision or recall.An important task for future work is to evalu-ate Dijkstra-WSA on LSRs which structurally dif-fer from the ones discussed here.
It is importantto determine how resources like FN or VN can bemeaningfully transformed into a graph representa-tion.
Another idea is to extend the approach tocross-lingual resource alignment, which would re-quire a machine translation component to identifysense alignment candidates with the correct lexeme.Regarding the algorithm itself, the main directionfor future work is to increase recall while keepinghigh precision.
One possible way would be to notonly link monosemous lexemes, but also to createedges for polysemous ones.
Laparra et al(2010)discuss a possibility to do this with high precision.The main idea is to focus on lexemes with a low de-gree of polysemy and align if one of the possiblesenses is clearly more similar to the source sensethan the other(s).
If recall is still low, more poly-semous lexemes can be examined.A weighting of edges (e.g.
based on gloss simi-larities) has not been considered at all, but would beeasily applicable to the existing framework.A more elaborate idea would be to investigateentirely different graph-based algorithms, e.g.
formatching nodes in bipartite graphs.
Also, we plan toinvestigate if and how our approach can be extendedto align more than two resources at once using thegraph representations.
This might improve align-ment results as more information about the overallalignment topology becomes available.AcknowledgementsThis work has been supported by the VolkswagenFoundation as part of the Lichtenberg ProfessorshipProgram under grant No.
I/82806 and by theHessian research excellence program ?Landes-Offensive zur Entwicklung Wissenschaftlich-o?konomischer Exzellenz (LOEWE)?
as part of theresearch center ?Digital Humanities?.
We wouldlike to thank Christian M. Meyer, Wolfgang Stille,Karsten Weihe and Tristan Miller for insightfuldiscussions and comments.
We also thank theanonymous reviewers for their helpful remarks.161ReferencesEneko Agirre and Aitor Soroa.
2009.
Personaliz-ing PageRank for Word Sense Disambiguation.
InProceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 33?41, Athens, Greece.Gerard de Melo and Gerhard Weikum.
2010.
Pro-viding Multilingual, Multimodal Answers to LexicalDatabase Queries.
In Proceedings of the 7th LanguageResources and Evaluation Conference (LREC 2010),pages 348?355, Valetta, Malta.Edsger.
W. Dijkstra.
1959.
A note on two problemsin connexion with graphs.
Numerische Mathematik,1:269?271.
10.1007/BF01386390.Judith Eckle-Kohler, Iryna Gurevych, Silvana Hartmann,Michael Matuschek, and Christian M. Meyer.
2012.UBY-LMF - A Uniform Model for Standardizing Het-erogeneous Lexical-Semantic Resources in ISO-LMF.In Proceedings of the 8th International Conferenceon Language Resources and Evaluation (LREC?12),pages 275?282, Istanbul, Turkey.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press.Tiziano Flati and Roberto Navigli.
2012.
The CQC al-gorithm: Cycling in graphs to semantically enrich andenhance a bilingual dictionary.
Journal of ArtificialIntelligence Research (JAIR), 43:135?171.Iryna Gurevych, Judith Eckle-Kohler, Silvana Hartmann,Michael Matuschek, Christian M. Meyer, and Chris-tian Wirth.
2012.
UBY - A Large-Scale UnifiedLexical-Semantic Resource Based on LMF.
In Pro-ceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Linguis-tics (EACL?12), pages 580?590, Avignon, France.Birgit Hamp and Helmut Feldweg.
1997.
Germanet - alexical-semantic net for german.
In In Proceedings ofACL workshop Automatic Information Extraction andBuilding of Lexical Semantic Resources for NLP Ap-plications, pages 9?15.Verena Henrich, Erhard Hinrichs, and Tatiana Vodola-zova.
2011.
Semi-Automatic Extension of GermaNetwith Sense Definitions from Wiktionary.
In Proceed-ings of the 5th Language and Technology Conference(LTC 2011), pages 126?130, Poznan, Poland.Egoitz Laparra, German Rigau, and Montse Cuadros.2010.
Exploring the integration of WordNet andFrameNet.
In Proceedings of the 5th Global WordNetConference (GWC?10), Mumbai, India.Michael Matuschek, Christian M. Meyer, and IrynaGurevych.
2013.
Multilingual Knowledge inAligned Wiktionary and OmegaWiki for Computer-Aided Translation.
Translation: Computation, Cor-pora, Cognition.
Special Issue on ?Language Technol-ogy for a Multilingual Europe?, to appear.Christian M. Meyer and Iryna Gurevych.
2011.
WhatPsycholinguists Know About Chemistry: AligningWiktionary and WordNet for Increased Domain Cov-erage.
In Proceedings of the 5th International JointConference on Natural Language Processing (IJC-NLP), pages 883?892, Chiang Mai, Thailand.Christian M. Meyer and Iryna Gurevych.
2012.
Wik-tionary: A new rival for expert-built lexicons?
Ex-ploring the possibilities of collaborative lexicography.In Sylviane Granger and Magali Paquot, editors, Elec-tronic Lexicography, chapter 13, pages 259?291.
Ox-ford University Press.Rada Mihalcea and Dan I. Moldovan.
2001. eXtendedWordNet: progress report.
In Proceedings of NAACLWorkshop on WordNet and Other Lexical Resources,pages 95?100, Pittsburgh, PA, USA.David Milne and Ian H. Witten.
2008.
An effective,low-cost measure of semantic relatedness obtainedfrom Wikipedia links.
In Proceedings of the AAAIWorkshop on Wikipedia and Artificial Intelligence: anEvolving Synergy, pages 25?30, Chicago, IL, USA.Roberto Navigli and Simone Paolo Ponzetto.
2012.
Ba-belNet: The automatic construction, evaluation andapplication of a wide-coverage multilingual semanticnetwork.
Artificial Intelligence, 193:217?250.Roberto Navigli.
2009.
Using Cycles and Quasi-Cyclesto Disambiguate Dictionary Glosses.
In Proceedingsof the 12th Conference of the European Chapter of theAssociation for Computational Linguistics (EACL?09),pages 594?602, Athens, Greece.Elisabeth Niemann and Iryna Gurevych.
2011.
The Peo-ple?s Web meets Linguistic Knowledge: AutomaticSense Alignment of Wikipedia and WordNet.
In Pro-ceedings of the 9th International Conference on Com-putational Semantics (IWCS), pages 205?214, Oxford,UK.Martha Palmer.
2009.
SemLink: Linking PropBank,VerbNet and FrameNet.
In Proceedings of the Genera-tive Lexicon ConferenceGenLex-09, pages 9?15, Pisa,Italy.Simone Paolo Ponzetto and Roberto Navigli.
2009.Large-scale taxonomy mapping for restructuring andintegrating Wikipedia.
In Proceedings of the 21st In-ternational Joint Conference on Artificial Intelligence,pages 2083?2088, Pasadena, CA, USA.Philip Resnik.
1995.
Using Information Content toEvaluate Semantic Similarity in a Taxonomy.
In In-ternational Joint Conference for Artificial Intelligence(IJCAI-95), pages 448?453, Montreal, Canada.Lei Shi and Rada Mihalcea.
2005.
Putting Pieces To-gether: Combining FrameNet, VerbNet and WordNetfor Robust Semantic Parsing.
In Computational Lin-guistics and Intelligent Text Processing: 6th Interna-tional Conference, volume 3406 of Lecture Notes in162Computer Science, pages 100?111.
Berlin/Heidelberg:Springer.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2008.
YAGO: A Large Ontology fromWikipedia and WordNet.
Web Semantics, 6(3):203?217.163164
