Toward Memory--based TranslationSatoshi SATO and Ma.koto NAGAODept.
of Electrical Engineering, Kyoto  UniversityYoshida-honmachi,  Sa.kyo, K.yoto, 606, Ja.pansa.to@kuee.kyoto-u.ac.jpAbst ractAn essential problem of example-based transla-tion is how to utilize more than one translationexample for translating one source sentence.This 1)aper proposes a method to solve thisproblem.
We introduce tile representation,called .matching e,,z:pressio~z, which tel)resentsthe combination of fragments of translation ex-amples.
The translation process consists ofthree steps: (.1) Make the source matching ex-pression from lhe source sentence.
(2) TransDrthe source matching expression into the targetmatching expression.
(3) Construct the targetsentence from the target matching expression.This mechanism generates some candidates oftranslation.
To select, the best translation outof them, we define the score of a translation.1 In t roduct ionUse of extracted information fiom examplesor example-based translation is becoming thenew wave of machine translation.
The ba.-sic idea.
of example~based translation is verysimple: translate a source sentence by imitat-ing the translation example of a similar sen-tence in the database.
The idea first appearedin \[Nagao 84\], and some research has followedit \[Sumita 88\]\[Sato 89\]\[Sadler 89a.\]\[Sadler 89b\].But a great deal of effort is still needed to im-plemenl the idea.In our previous work, we show how to select.the best target word in case-frame translationbased on examples\[Sato 89\].
In this paper, weconcentrate on two problems:1. ltow to combine some fragments of trans-lation examph~s in order to translate onesentence?2.
tlow to select tile best tra.nslation out ofinany candidates?We show partial solutions for them in MBT2.MBT2 is the second prototype system in ourMemory-based Translation Project.. MBT2 ca.ndo bi-directional m~nslation between an Englishword-dependency tree and a Japanese word-dependency tree.
It is implemented in SicstusProlog.2 Need to Combine  Frag-me nt sThe basic idea of example-based translation isvery simple: translate a source sentence by im-itating the translation example of similar sen-tencein the database.
But in many cases, it isnecessary to imitate more than one translationexample and combine some fragments of them.Let's consider the translation of the followingsentence.
(1) He buys a book on international politics.If we know the following translation examt)le(2) and (3), we can translate sentence (1) intosentence (4) by imitating examples and colnbin-ing fragments of them.
(2) He buys a notebook.Kate ha nouto wo ka~.
(3) I read a boo\]~ on international polilics.Watt, hi ha kokusaiseiji nit,suite l:akaretahon wo yomu.
(4) Kate ha kokusMseiji nitsuite kM~reta honWO ka~ll.It is easy for a human to do this, but notso for a machine.
The ability to combine somefragments of translation examples is essential toexample-based translation.
A lack of this abil-ity restricts the power of example-based trans-lation.
In this paper, we concentrate on theimplementation of this ability on machine.i 24 73 Matching ExpressionTo implenrent the ability to combine some frag-ments of t.ra.nslation example in order to trans-late one sentence, we must determine the fol-lowing:?
how to represent translation examples?
what is a fragment?
how to represe.t he combination of flag-lnent.s3.1 Trans la t ion  DatabaseThe translation database is the collection oftranslation examples.
A t~anslation exampleconsists of three parts:?
an English word-dependency tree (EWD)?
a Japanese word-dependency tree (JWD)?
correspondence linksFor example, in Prolog,ewd e( \ [e l , \ [buy ,v \ ] ,\[e2,\[he,pron\]\],\[e3, \[notebook,n\],\ [e4,  \ [a ,det \ ] \ ] \ ] \ ] )  .%% He buys a notebook.jwd_e(  \ [ j I ,  \[kau,v\] ,\ [ j2 ,  \ [ha ,p \ ]  ,\[ j3,\[kare,pron\]\]\],\ [ j4 ,  \[wo,p\] ,\ [ j5 ,  \[nouto,n\]\]\]\]).%% Kare ha nouto wo kau.c l inks(\[ \ [el , j l \ ] , \ [e2, j3\] , \ [e3, j5\] \]) .%% el <-> jl, e2 <-> j3, e3 <-> j5Each number with prefix 'e' or 'j' in word-dependency trees represents the ID of the sub-tree.
Each node in a tree contains a word (inroot form) and its syntactic ategory.
A corre-spondence link is represented as a pair of iDs.3.2 T rans la t ion  Un i tA word-dependency (sub)tree which has a cor-respondence link is transhttable; .g.
el,  e2, e3,j l ,  j3, j5.
A translatable tree in which sometranslatable subtrees are removed is also trans-lata.ble; e.g.
e l -e2,  e l -e3,  e l -e2-e3,  j l - j3 ,j l - j5 ,  j l - j a - jS .
Both of them are tra.nslat-M)le fragments.
Sadler calls them translationw,,its\[Sadler 89a,\].3.3 Match ing  Express ionNext we will introduce the concept 'matchingexpression.'
Matching expression(ME) is de-fined as the following:<HE> : :=  \[<ID>I<ME-Commands>\]<ME-Commands> : : =\[\]or \[<ME-Command> I <ME-Commands>\]<ME-Command> : :=\[d, < ID>\]or \[r,<ID>, <ME>\]or \[a,<ID>,<ME>\]%% delete <ID>%% rep lace  <ID>%% with <ME>%% add <ME> as a%% ch i ld  of  root%% node o f  <ID>Every ID in an ME should be translatable.We assume the example in Section 3.1 andthe following example.ewd_e( fell, freud,v\] ,\[el2, \['I ),prOn\]\] ,\[el3, \[book,n\] ,\[el4, \[a,det\] \] ,\[elb, Ion,p\] ,\[el6, \[politics,n\] ,felT, \[international, adj\]\ ] \ ] \ ] \ ]1 ) .Y,Y, I read a book on international%% politics.jwd_e(\[j l l ,  \[yomu,v\] ,\[j12, \[ha,p\] ,\[j13, \[watashi,pron\] \]\] ,\ [ j14 ,  \[wo,p\] ,\[j15, \[hon,n\] ,\ [ j16 ,  \ [ ta ,  aux\] ,\[j17, \[reru,aux\] ,\[j18, \[kaku,v\] ,\[j19, \[nitsuite,p\] ,\[j20, \[kokusaiseij i,n\]1\] \ ]11\] \ ] \ ] ) .%% Watash i  ha kokusa ise i j i  n i t su i .
te%% kakareta  hon wo yomu.cl inks(\[el l , \ ] l l \ ] , \ [e12, j13\] , \ [e13, j15\] ,\ [e16 , j20 \ ] \ ] ) .Under this assumption, the word-dependencytree (a) can be represented by the matching ex-pression (b).
(a)  \[ \[buy,v1 ,\ [ \ [he ,pron \ ] \ ]  ,\[\[book,hi ,\ [ \ [a ,det \ ] \ ]  ,\[ Ion,p\],\[\[politics,n\] ,\[ \[ international,adj\]\]\] \] \] \]%% He buys a book on internationalY,Y, polit ics.
(b) \ [e l , \ [ r ,e3 , \ [e l3 \ ] \ ] \ ]248 2Source WD (SWD)#Source ME (SME)Target ME (TME)g~.,ompo~itiol~ \]Target WD (TWD)Figure 1: Flow of TranslatonThe matching expression (b) consists of twotransla,tion units: el-e3, e13.
And it has theinformation to combine them.4 Tl'anslation via MatchingExpressionFigure 1 shows the flow of the translation pro-.
cess.
The translation process consists of threesteps: decomposition, transfer, and composi-tion.
This process generates all candidatesof translation using Prolog's backtrack mecha-nism.4.1 Decompos i t ionIn decomposition, the system decomposes asource word-dependency tree(SWD) into trans-lation units, and makes a source matching ex-pression(SME).
For example,SWD = \[\[buy,v\],\[ \[he,pron\] \] ,\[ \[book,n\] ,\ [ \ [a,det\] \ ]  ,\[\[on,p\],\[ \[politics ,n\],\[ \[international, adj\] \] \] \] \] \]SME = \ [e l , \ [ r ,ea , \ [e l3 \ ] \ ] \ ]The main tasks in this step are to retrievetranslation units and compare the source WDwith retrieved translation units.
To retrievetranslation units quickly, we use some hashingtechniques.
There are two program to do thecomparison task; one for English WDs and onefor Japanese WDs.
In comparison of JapaneseWDs, the order of subtrees is not inlportant.To reduce the search space and the num-ber of candidates, we define replaceablity be-tween syntactic categories.
If two nodesare replaceable, system makes only ~ replace-command.
As a result, the the system doesnot make some matching expressions; e.g.\[el, \[d,e3\] , \ [a,el ,  \ [e13\]\] \ ]4.2 Transferin the transfer step, the system replaces everyID in the source matching expression with itscorresponding ID.
For example,SME = \[el,\[r,eS,\[el3\]\]\]TME = \[j1,\[r,jS,\[j15\]\]\]4.3 Compos i t ionin the composition step, the system composesthe target word-dependency tree according tothe target matching expression.
For example.TME = \ [ j l , \ [ r , j5 ,  \ [ j lS \ ] \ ] \ ]TWD = \[\[kau,v\],\[ \[ha,p\] ,\[ \[kare,pron\] \] \] ,\[\[wo,p\],\[ \[hon ,n\] ,\[\[ta, aux\],\[ \[tern, aux\],\[ \[kaku, v\] ,\[ \[nitsuite,p\] ,\[ \[kokusaiseiji,n\] \] \] \] \] \] \] \] \]~,~.
Kate ha kokusaisei j i  nitsuite~,~, kakareta hon wo kau.This step divides into two sub-steps; themain composing step and validity checking.
Inthe main composing step, there is no ambi-guity with one exception.
Because an add-command \[a,<ID>,<ME>\] specifies only theparent node(<ID>) to add the tree(<ME>), thereare some choices in composing English word-dependency trees.
In this step, all possibilitiesare generated.Validity of the composed word-dependencytrees are checked using syntactic categories.Validity is checked in every parent-childrenunit.
For example, in the above target word-dependency tree,\[v, \[p,p\] \] , \[p, \ [prom \], \[p, \[n\] \],In, \[aux\] ] .
.
.
.are checked.
A unit is valid if there is aunit which has the same category pattern in thedatabase.
A word-dependency tree is valid if allparent-children units are valid.3 249z"/ 7t2 L1 " / ~l I I ,\ 7/5 71,7 .2. .
~ ._.___-- res t r i c ted  env iornment  ~ / "  '~" \'nll  / m2 (= n2) ", mlo/ m,8 2/ ,-dTranslation Gx~mple Source (or Target) WDFigure 2: Restricted Environments of TU5 Score o f  T rans la t ionTo select the best translation out of all can-didates generated by system, we introduce thescore of a tra.nslM.ion.
We define it based on thescore of the matching expression, because thematching expression determines the translationouti)ut.
The scores of.the source matching ex-pression and the target matching expression arecalculated separately.5.1 Score  o f  T rans la t ion  Un i tFirst, we will define the score of a translationunit.
The score of a translation unit shouldreflect the correctness of the translation unit.Which translation unit is better?
Two main fac-t.ors are:1.
A larger translation unit is better.2.
A translation unit in a matching expressionis a fragment of a source (or target) word-dependency tree, and also a fragment of atranslation example.
There are two envi-ronments of a translation unit; in a source(or target) tree and in a translation exam-ple.
The more similar these two environ-meuts are, the better.To calculate 1, we define the size of a trans-lation unit(TU ).size(TU) = the number of nodes in TUTo calculate 2, we need a measure of simi-larity between two environments, i.e.
externalsimilarity.
To estimate xternal similarity, weintroduce a unit called restricted environment.A restricted environment consists of the nodesone link outside of a TU normally.
If corre-sponding nodes are same in two environments,those environments are extended one more linkoutside.
Figure 2 illustrates restricted environ-ments of a TU.
We estimate xternal similarityas the best matching of two restricted environ-ments.
To find the best matching, we first deter-mine the correspondences between odes in tworestricted environments.
Some nodes have sev-eral candidates of correspondence.
For example,n7 corresponds with rn6 or m7.
In this case,we select the most similar node.
To do this,we assume that similarity values between odes(words) are defined as numeric values between 0and 1 in a thesaurus.
When the best matchingis found, we can calculate the matching pointbetween two environments, mpoint(TU, WD).mpoint (TU,  WD)  =summation of similarity values between corre-sponding nodes in two restricted environments~t the best matchingWe use this value as a measure of similaritybetween two environments.Finally, we define the score of a translationunit, seore(TU, WD).score(TU, WD) =size(TU) x (size(Tg) + mpoiut(TU, WD))For example, we assume that the followingsimilarity vMues are defined in a thesaurus.250 4s im(\[book,n\] ,  \ [notebook,n\] ,O.8).sire( \[buy,v\] , \[read,v\] ,0.5) .sire( \[hon,n\] , \[nouto,n\] ,0.8).s im( \ [kau,v \ ] , \ [yomu,v \ ] ,O .5) .Then i.he scores of translation units in theprevious section are the followings.j l - j5  I\[ '!
\[ 0.SI J s___2_JLL5.2 Score  o f  Match ing  Express ion\]?he score of a nlatching expression is defined asthe following.score.
( .'tiE:.
It'D) F~YUCME score(TU, WD) s izc(WD) 2FOl; exaul ple,\ [ j l ,  \ [ r , jS ,  \[j15\]5.3 Score  o f  T rans la t ionFinally, we define the score of a translation asthe following.scur~:(SWD.
SME,  TME,  TWD)  =~,n i~( seo,'~( S ME.
S WD), score( T~I E, TW D ) )For example, the score of the translation in?
the previous section is 0.6.I2.6 ExamplesThe English verb eat corresponds to twoJapanese verbs, tabcrv and okasu.
For exam-pie.
(4) The mall eats w.:getabtes.Hito ha yasal wo taberu.
(5) Acid eats metal.San ha kinzoku wo oka.qu.Figure 3 shows translation outl)uts based onexample (,t) and (5) by MBT2.
MBT2 chooseshtberu for he cat.s t~ota, toes and okasu for sulfuricacid cals i ron.
***  T r&ns la t ion  Source  ***\[ \ [eat ,  v\]  ,\[ the,pron\] \] ,\[ \[potato,n\] \] \]Y,Y, He eats potatoes.
*** Trans lat ion Results  ***No.
I (Score = 0.5889)\[ \[taberu, v\] ,\[ \[ha,p\],\[ \[kare,pron\] \] \] ,\[\[wo,p\],\[ \[ jagaimo,n\] \] \] \]No.
2 (Score = 0.4S56)\[ \[okasu, v\],\[ \[ha, p\],\[ \[kare,pron\] \] \] ,\[ \[~o,p\],\[ \[ jagaimo,n\]\] \]\]*** Trans lat ion  Source ***\[\[eat,v\] ,\[\[acid,n\] ,\[ \ [sulfur ic,adj\] \]  \] ,\[\[ iron,n\]\]\]%% Sulfur ic  acid eats iron.
*** Trans lat ion Results  ***No.
I (Score = 0.5500)\[ \[okasu, v\],\[ \[ha, p\] ,\[ \[ryuusan,n\] \] \] ,\[ \[wo,p\],\ [ \ [ te tsu ,n \ ]  \] \]\]No.
2 (Score = 0.4688)\[\[taberu, v\] ,\[ \[ha, p\],\[ \[ryuusan,n\]\] \],\[\[wo,p\],\[\[tetsu,n\]\]Figure 3: Translation Outputs by MBT25 2517 Discuss ionAlthough MBT2 is not a full realization of Na-gao's idea., it contains ome merits from the orig-inal idea.1.
It is easy to modify the system.The knowledge of the system is in the formof translation examl)les and thesauri.
Wecan modify the system with addition oftranslation examples..
It can do high quality translation.The system sees as wide a scope as possiblein a sentence and uses the largest transla-tion units.
It produces high quality trans-lations..
It can translate some metaphorical sen-tences.In the system, semantic information is notused as constraints.
As a result, the systemcan translate some metaphorical sentences.Demerits or problems of the system are:1.
A great deal of computation is needed.2.
Can we make good thesauri?The first l)roblem is not serious.
Parallel compu-tation or some heuristics will overcome it.
Butthe second problem is serious.
We have to studyhow to construct large thesauri.acknowlegmentsThe authors would like to thank Mort Websterfor his proof reading.References\[Nagao 84\] Makoto Nagao, A Framework ofa Mechanical Translation between Japaneseand English by Analogy Principle, in ARTI-FICIAL AND tIUMAN INTELMGENCE(A. Elithorn and R. Banerji, editors), El-sevier Science Publishers, B.V, 198.t.\[Sadler 89a\] Victor Sadler, The BilingualKnowledge Bank(BKB), BSO/Research,1989.\[Sadler 89b\] Victor Sadler, Translating with asimulated Bilingual Knowledge Bank{ BKB),BSO/Research, 1989.\[Sato 89\] Satoshi Sa.to and Makoto Nagao,Memory-based Translation, IPSJ-WG, NL-70-9, 1989.
(in Japanese)\[Sumita 88\] E. Sumita and Y. Tsutsumi, ATranslation Aid System Using Flexible TextRetrieval Based on Syntax-Matching, TRLResearch Report, TR-87-1019, Tokyo Re-search Laboratory, IBM, 1988.8 Conclus ionThis paper describes how to combine sometranslation units in order to translate one sen-tence and how to select tile best translation outof some candidates generated by system.
Torepresent he combination of fragments, we in-troduce the representation called matching ex-pression.
To select the best translation, we de-fine the score of translation based on the scoreof the matching expression.This framework can be applied to not only thetranslation between word-dependency trees butalso the translation between other data struc-tures.
We hope that generation can be imple-mented in same framework as the translationfrom a word-dependency tree to a list or string.252 6
