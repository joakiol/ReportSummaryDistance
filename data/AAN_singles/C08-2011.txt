Coling 2008: Companion volume ?
Posters and Demonstrations, pages 43?46Manchester, August 2008Word Sense Disambiguation for All Words using Tree-StructuredConditional Random FieldsJun Hatori?Yusuke Miyao?Jun?ichi Tsujii???
?Graduate School of Interdisciplinary Information Studies, University of Tokyo?Graduate School of Information Science and Technology, University of Tokyo?National Centre for Text Mining / 131 Princess Street, Manchester, M1 7DN, UK?School of Computer Science, University of Manchester{hatori,yusuke,tsujii}@is.s.u-tokyo.ac.jpAbstractWe propose a supervised word sensedisambiguation (WSD) method usingtree-structured conditional random fields(TCRFs).
By applying TCRFs to asentence described as a dependency treestructure, we conduct WSD as a labelingproblem on tree structures.
To incorpo-rate dependencies between word senses,we introduce a set of features on treeedges, in combination with coarse-grainedtagsets, and show that these contributeto an improvement in WSD accuracy.We also show that the tree-structuredmodel outperforms the linear-chain model.Experiments on the SENSEVAL-3 dataset show that our TCRF model performscomparably with state-of-the-art WSDsystems.1 IntroductionWord sense disambiguation (WSD) is one of thefundamental underlying problems in computa-tional linguistics.
The task of WSD is to determinethe appropriate sense for each polysemous wordwithin a given text.Traditionally, there are two task settings forWSD: the lexical sample task, in which only onetargeted word is disambiguated given its context,and the all-words task, in which all content wordswithin a text are disambiguated.
Whilst most ofthe WSD research so far has been toward the lex-ical sample task, the all-words task has receivedc?
Jun Hatori, Yusuke Miyao, and Jun?ichi Tsu-jii, 2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.relatively less attention, suffering from a seriousknowledge bottleneck problem.
Since it is con-sidered to be a necessary step toward practical ap-plications, there is an urgent need to improve theperformance of WSD systems that can handle theall-words task.In this paper, we propose a novel approach forthe all-words task based on tree-structured condi-tional random fields (TCRFs).
Our TCRF modelincorporates the inter-word sense dependencies, incombination with WORDNET hierarchical infor-mation and a coarse-grained tagset, namely super-senses, by which we can alleviate the data sparse-ness problem.2 Background2.1 Inter-word sense dependenciesSince the all-words task requires us to disam-biguate all content words, it seems reasonable toassume that we could perform better WSD by con-sidering the sense dependencies among words, andoptimizing word senses over the whole sentence.Specifically, we base our model on the assumptionthat there are strong sense dependencies between ahead word and its dependents in a dependency tree;therefore, we employ the dependency tree struc-tures for modeling the sense dependencies.There have been a few WSD systems that incor-porate the inter-word sense dependencies (e.g.
Mi-halcea and Faruque (2004)).
However, to the ex-tent of our knowledge, their effectiveness has notexplicitly examined thus far for supervised WSD.2.2 WORDNET informationSupersense A supersense corresponds to thelexicographers?
file ID in WORDNET, with whicheach noun or verb synset is associated.
Since43they are originally introduced for ease of lexicog-raphers?
work, their classification is fairly gen-eral, but not too abstract, and is hence expectedto act as good coarse-grained semantic categories.The numbers of the supersenses are 26 and 15for nouns and verbs.
The effectiveness of theuse of supersenses and other coarse-grained tagsetsfor WSD has been recently shown by several re-searchers (e.g.
Kohomban and Lee (2005), Cia-ramita and Altun (2006), and Mihalcea et al(2007)).Sense number A sense number is the number ofa sense of a word in WORDNET.
Since senses of aword are ordered according to frequency, the sensenumber can act as a powerful feature for WSD,which offers a preference for frequent senses, andespecially as a back-off feature, which enables ourmodel to output the first sense when no other fea-ture is available for that word.2.3 Tree-structured CRFsConditional Random Fields (CRFs) are graph-based probabilistic discriminative models pro-posed by Lafferty et al (2001).Tree-structured CRFs (TCRFs) are differentfrom widely used linear-chain CRFs, in that theprobabilistic variables are organized in a tree struc-ture rather than in a linear sequence.
Therefore, wecan consider them more appropriate for modelingthe semantics of sentences, which cannot be repre-sented by linear structures.Although TCRFs have not yet been applied toWSD, they have already been applied to some NLPtasks, such as semantic annotation (Tang et al,2006), proving to be useful in modeling the seman-tic structure of a text.Formulation In CRFs, the conditional probabil-ity of a label set y for an observation sequence xis calculated byp(y|x) =1Z(x)exp[?e?E,j?jfj(e,x,y)+?v?V,k?kgk(v,x,y)](1)where E and V are the sets of edges and vertices,fjand gkare the feature vectors for an edge and avertex, ?jand ?kare the weight vectors for them,and Z(x) is the normalization function.
For a de-tailed description of TCRFs, see Tang et al (2006).ROOTdestroyconfidencemanthe inbankROOTdestroyconfidencemanbank<NMOD><ROOT> <ROOT><NMOD><NMOD> : in<PMOD><SBJ> <OBJ><SBJ> <OBJ>Figure 1: An example sentence described as a de-pendency tree structure.3 WSD Model using Tree-structuredCRFs3.1 OverviewLet us consider the following sentence.
(i) The man destroys confidence in banks.In the beginning, we parse a given sentence byusing a dependency parser.
The left-hand side ofFigure 1 shows the dependency tree for Sentence(i) in the CoNLL-X dependency format.Next, we convert the outputted tree into a tree ofcontent words, as illustrated in the right-hand sideof Figure 1, since our WSD task does not focus onthe disambiguation of function words.Finally, we conduct WSD as a labeling task ontree structures, by maximizing the probability ofa tree of word senses, given scores for vertex andedge features.3.2 Sense LabelsUsing the information in WORDNET, we definefour sense labels for a word: a sense s1(v), a synsets2(v), a topmost synset s3(v), and a supersenses4(v).
A topmost synset s3(v) is the superordi-nate synset at the topmost level in the WORDNEThierarchy, and note that a supersense s4(v) is onlyavailable for nouns and verbs.
We incorporate allthese labels together into the vertex and edge fea-tures described in the following sections.3.3 Vertex featuresMost of the vertex features we use are those usedby Lee and Ng (2002).
All these features are com-bined with each of the four sense labels sn(v), andincorporated as gkin Equation (1).?
Word form, lemma, and part of speech.?
Word forms, lemmas, and parts of speech ofthe head and dependents in a dependency tree.44#sentences #wordsDevelopment 470 5,178Brown-1 10,712 100,804Brown-2 8,956 85,481SENSEVAL-3 300 2,081Table 1: Statistics of the corpora.?
Bag-of-words within 60-words window.?
Parts-of-speech of neighboring six words.?
Local n-gram within neighboring six words.Additionally, we include as a vertex feature thesense number, introduced in Section 2.2.3.4 Edge featuresFor each edge, all possible sense bigrams(i.e.
s1(v)-s1(v?),s1(v)-s2(v?),?
?
?
,s4(v)-s4(v?
)),and the combination of sense bigrams with de-pendency relation labels (e.g.
?SUB,?
?NMOD?
)and/or removed function words in between (e.g.?of,?
?in?)
are defined as edge features, which cor-respond to fjin Equation (1).4 Experiment4.1 Experimental settingsIn the experiment, we use as our main evalua-tion data set the Brown-1 and Brown-2 sections ofSEMCOR.
The last files in the five largest cate-gories in Brown-1 are used for development, andthe rest of Brown-1 and all files in Brown-2 are al-ternately used for training and testing.
We also usethe SENSEVAL-3 English all-words data (Snyderand Palmer, 2004) for testing, in order to comparethe performance of our model with other systems.The statistics of the data sets are shown in Table 1.All sentences are parsed by the Sagae?s depen-dency parser (Sagae and Tsujii, 2007), and theTCRF model is trained using Amis (Miyao andTsujii, 2002).
During the development phase, wetune the parameter of L2regularization for CRFs.Note that, in all experiments, we try all contentwords annotated with WORDNET synsets; there-fore, the recalls are always equal to the precisions.4.2 ResultsFirst, we trained and evaluated our models onSEMCOR.
Table 2 shows the overall performanceof our models.
BASELINE model is the first sensebaseline.
NO-EDGE model uses only the ver-tex features, while each of the Sn-EDGE modelsmakes use of the edge features associated withSystem RecallPNNL (Tratz et al, 2007) 67.0%Simil-Prime (Kohomban and Lee, 2005) 66.1%ALL-EDGE 65.5%GAMBL (Decadt et al, 2004) 65.2%SENSELEARNER (Mihalcea et al,2004) 64.6%BASELINE 62.2%Table 3: The comparison of the performance ofWSD systems evaluated on the SENSEVAL-3 En-glish all-words test set.a sense label sn, where n ?
{1, 2, 3, 4}.
TheALL-EDGE model incorporates all possible com-binations of sense labels.
The only differencein the ALL-EDGE?
model is that it omits fea-tures associated with dependency relation labels,so that we can compare the performance with theALL-EDGE?
(Linear) model, which is based on thelinear-chain model.In the experiment, all models with one or moreedge features outperformed both the NO-EDGEand BASELINE model.
The ALL-EDGE modelachieved 75.78% and 77.49% recalls for the twodata sets, with 0.41% and 0.43% improvementsover the NO-EDGE model.
By the stratified shuf-fling test (Cohen, 1995), these differences areshown to be statistically significant1, with theexception of S3-EDGE model.
Also, the tree-structured model ALL-EDGE?
is shown to outper-form the linear-chain model ALL-EDGE?
(Linear)by 0.13% for both data sets (p = 0.013, 0.006).Finally, we trained our models on the Brown-1and Brown-2 sections, and evaluated them on theSENSEVAL-3 English all-words task data.
Table 3shows the comparison of our model with the state-of-the-art WSD systems.
Considering the differ-ence in the amount of training data, we can con-clude that the performance of our TCRF modelis comparable to state-of-the-art WSD systems,for all systems in Table 3 other than Simil-Prime(Kohomban and Lee, 2005)2utilizes other sense-annotated data, such as the SENSEVAL data setsand example sentences in WORDNET.1Although some of the improvements seem marginal, theyare still statistically significant.
This is probably becausesense bigram features are rarely active, given the size of thetraining corpus, and most of the system outputs are the firstsenses.
Indeed, 91.3% of the outputs of ALL-EDGE modelare the first senses, for example.2Kohomban and Lee (2005) used almost the same train-ing data as our system, but they utilize the instance weightingtechnique and the combination of several classifiers, whichour system does not.45Training set Brown-1 Brown-2Testing set Brown-2 Brown-1Model Recall Offset #correct Recall Offset #correctALL-EDGE?
75.77% 0.40%  64766/85481 77.45% 0.39%  78077/100804ALL-EDGE?
(Linear) 75.64% 0.27%  64662/85481 77.32% 0.26%  77944/100804ALL-EDGE 75.78% 0.41%  64779/85481 77.49% 0.43%  78114/100804S4-EDGE 75.46% 0.09%  64507/85481 77.15% 0.09%  77769/100804S3-EDGE 75.40% 0.03% ?
64452/85481 77.13% 0.07%  77750/100804S2-EDGE 75.45% 0.08%  64494/85481 77.12% 0.06%  77738/100804S1-EDGE 75.44% 0.07%  64491/85481 77.10% 0.04% > 77724/100804NO-EDGE 75.37% 0.00% 64427/85481 77.06% 0.00% 77677/100804BASELINE 74.36% 63567/85481 75.91% 76524/100804Table 2: The performance of our system trained and evaluated on SEMCOR.
The statistical significanceof the improvement over NO-EDGE model is shown in the ?Offset?
fields, where ?
,?
?>,?
and ???
denotep < 0.01, p < 0.05, and p ?
0.05, respectively.5 ConclusionIn this paper, we proposed a novel approach for theall-words WSD based on TCRFs.
Our proposalsare twofold: one is to apply tree-structured CRFsto dependency trees, and the other is to use bigramsof fine- and coarse-grained senses as edge features.In our experiment, the sense dependency fea-tures are shown to improve the WSD accuracy.Since the combination with coarse-grained tagsetsare also proved to be effective, they can be used toalleviate the data sparseness problem.
Moreover,we explicitly proved that the tree-structured modeloutperforms the linear-chain model, indicating thatdependency trees are more appropriate for repre-senting semantic dependencies.Although our model is based on a simple frame-work, its performance is comparable to state-of-the-art WSD systems.
Since we can use addition-ally other sense-annotated resources and sophisti-cated machine learning techniques, our model stillhas a great potential for improvement.ReferencesCiaramita, M. and Y. Altun.
2006.
Broad-coveragesense disambiguation and information extractionwith a supersense sequence tagger.
In Proc.
of theConf.
on Empirical Methods in Natural LanguageProcessing (EMNLP).Cohen, P. R. 1995.
Empirical methods for artificialintelligence.
MIT Press.Decadt, B., V. Hoste, W. Daelemans, and A. V. denBosch.
2004.
GAMBL, genetic algorithm optimiza-tion of memory-based WSD.
In Senseval-3: ThirdInt?l Workshop on the Evaluation of Systems for theSemantic Analysis of Text.Kohomban, U. S. and W. S. Lee.
2005.
Learning se-mantic classes for word sense disambiguation.
InProc.
of the 43rd Annual Meeting on Association forComputational Linguistics (ACL).Lafferty, J., A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of 18thInt?l Conf.
on Machine Learning (ICML).Lee, Y. K. and H. T. Ng.
2002.
An empirical evalu-ation of knowledge sources and learning algorithmsfor word sense disambiguation.
In Proc.
of the Conf.on Empirical Methods in Natural Language Process-ing (EMNLP).Mihalcea, R. and E. Faruque.
2004.
SenseLearner:Minimally supervised word sense disambiguationfor all words in open text.
In Proc.
of ACL/SIGLEXSenseval-3, Barcelona, Spain, July.Mihalcea, R., A. Csomai, and M. Ciaramita.
2007.UNT-Yahoo: SuperSenseLearner: CombiningSenseLearner with SuperSense and other coarse se-mantic features.
In Proc.
of the 4th Int?l Workshopon the Semantic Evaluations (SemEval-2007).Miyao, Y. and J. Tsujii.
2002.
Maximum entropy esti-mation for feature forests.
In Proc.
of Human Lan-guage Technology Conf.
(HLT 2002).Sagae, K. and J. Tsujii.
2007.
Dependency parsing anddomain adaptation with LR models and parser en-sembles.
In Proc.
of the CoNLL Shared Task Sessionof EMNLP-CoNLL 2007.Snyder, B. and M. Palmer.
2004.
The english all-wordstask.
In Senseval-3: Third Int?l Workshop on theEvaluation of Systems for the Semantic Analysis ofText.Tang, J., M. Hong, J. Li, and B. Liang.
2006.
Tree-structured conditional random fields for semantic an-notation.
In Proc.
of the 5th Int?l Semantic Web Conf.Tratz, S., A. Sanfilippo, M. Gregory, A. Chappell,C.
Posse, and P. Whitney.
2007.
PNNL: A super-vised maximum entropy approach to word sense dis-ambiguation.
In Proc.
of the 4th Int?l Workshop onSemantic Evaluations (SemEval-2007).46
