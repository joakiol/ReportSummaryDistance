Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1073?1083,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsWeak semantic context helps phonetic learningin a model of infant language acquisitionStella Franksfrank@inf.ed.ac.ukILCC, School of InformaticsUniversity of EdinburghEdinburgh, EH8 9AB, UKNaomi H. Feldmannhf@umd.eduDepartment of LinguisticsUniversity of MarylandCollege Park, MD, 20742, USASharon Goldwatersgwater@inf.ed.ac.ukILCC, School of InformaticsUniversity of EdinburghEdinburgh, EH8 9AB, UKAbstractLearning phonetic categories is one of thefirst steps to learning a language, yet is hardto do using only distributional phonetic in-formation.
Semantics could potentially beuseful, since words with different mean-ings have distinct phonetics, but it is un-clear how many word meanings are knownto infants learning phonetic categories.
Weshow that attending to a weaker source ofsemantics, in the form of a distribution overtopics in the current context, can lead toimprovements in phonetic category learn-ing.
In our model, an extension of a pre-vious model of joint word-form and pho-netic category inference, the probability ofword-forms is topic-dependent, enablingthe model to find significantly better pho-netic vowel categories and word-forms thana model with no semantic knowledge.1 IntroductionInfants begin learning the phonetic categories oftheir native language in their first year (Kuhl et al,1992; Polka and Werker, 1994; Werker and Tees,1984).
In theory, semantic information could offera valuable cue for phoneme induction1by helpinginfants distinguish between minimal pairs, as lin-guists do (Trubetzkoy, 1939).
However, due to awidespread assumption that infants do not know themeanings of many words at the age when they arelearning phonetic categories (see Swingley, 2009for a review), most recent models of early phoneticcategory acquisition have explored the phoneticlearning problem in the absence of semantic infor-mation (de Boer and Kuhl, 2003; Dillon et al, 2013;1The models in this paper do not distinguish between pho-netic and phonemic categories, since they do not capturephonological processes (and there are also none present inour synthetic data).
We thus use the terms interchangeably.Feldman et al, 2013a; McMurray et al, 2009; Val-labha et al, 2007).Models without any semantic information arelikely to underestimate infants?
ability to learn pho-netic categories.
Infants learn language in the wild,and quickly attune to the fact that words have (pos-sibly unknown) meanings.
The extent of infants?semantic knowledge is not yet known, but existingevidence shows that six-month-olds can associatesome words with their referents (Bergelson andSwingley, 2012; Tincoff and Jusczyk, 1999, 2012),leverage non-acoustic contexts such as objects or ar-ticulations to distinguish similar sounds (Teinonenet al, 2008; Yeung and Werker, 2009), and mapmeaning (in the form of objects or images) to newword-forms in some laboratory settings (Friedrichand Friederici, 2011; Gogate and Bahrick, 2001;Shukla et al, 2011).
These findings indicate thatyoung infants are sensitive to co-occurrences be-tween linguistic stimuli and at least some aspectsof the world.In this paper we explore the potential contribu-tion of semantic information to phonetic learningby formalizing a model in which learners attend tothe word-level context in which phones appear (asin the lexical-phonetic learning model of Feldmanet al, 2013a) and also to the situations in whichword-forms are used.
The modeled situations con-sist of combinations of categories of salient ac-tivities or objects, similar to the activity contextsexplored by Roy et al (2012), e.g.,?getting dressed?or ?eating breakfast?.
We assume that child learn-ers are able to infer a representation of the situ-ational context from their non-linguistic environ-ment.
However, in our simulations we approximatethe environmental information by running a topicmodel (Blei et al, 2003) over a corpus of child-directed speech to infer a topic distribution for eachsituation.
These topic distributions are then used asinput to our model to represent situational contexts.The situational information in our model is simi-1073lar to that assumed by theories of cross-situationalword learning (Frank et al, 2009; Smith and Yu,2008; Yu and Smith, 2007), but our model does notrequire learners to map individual words to their ref-erents.
Even in the absence of word-meaning map-pings, situational information is potentially usefulbecause similar-sounding words uttered in similarsituations are more likely to be tokens of the samelexeme (containing the same phones) than similar-sounding words uttered in different situations.In simulations of vowel learning, inspired byVallabha et al (2007) and Feldman et al (2013a),we show a clear improvement over previous mod-els in both phonetic and lexical (word-form) cate-gorization when situational context is used as anadditional source of information.
This improve-ment is especially noticeable when the word-levelcontext is providing less information, arguably themore realistic setting.
These results demonstratethat relying on situational co-occurrence can im-prove phonetic learning, even if learners do not yetknow the meanings of individual words.2 Background and overview of modelsInfants attend to distributional characteristics oftheir input (Maye et al, 2002, 2008), leading tothe hypothesis that phonetic categories could beacquired on the basis of bottom-up distributionallearning alone (de Boer and Kuhl, 2003; Vallabhaet al, 2007; McMurray et al, 2009).
However, thiswould require sound categories to be well sepa-rated, which often is not the case?for example,see Figure 1, which shows the English vowel spacethat is the focus of this paper.Recent work has investigated whether infantscould overcome such distributional ambiguity byincorporating top-down information, in particular,the fact that phones appear within words.
At sixmonths, infants begin to recognize word-formssuch as their name and other frequently occurringwords (Mandel et al, 1995; Jusczyk and Hohne,1997), without necessarily linking a meaning tothese forms.
This ?protolexicon?
can help differen-tiate phonetic categories by adding word contextsin which certain sound categories appear (Swingley,2009; Feldman et al, 2013b).
To explore this ideafurther, Feldman et al (2013a) implemented theLexical-Distributional (LD) model, which jointlylearns a set of phonetic vowel categories and a setof word-forms containing those categories.
Simula-tions showed that the use of lexical context greatly500100015002000250030003500 F220040060080010001200F1oauwawoouhaherehaeiheiiyFigure 1: The English vowel space (generated fromHillenbrand et al (1995), see Section 6.2), plottedusing the first two formants.improved phonetic learning.Our own Topic-Lexical-Distributional (TLD)model extends the LD model to include an addi-tional type of context: the situations in which wordsappear.
To motivate this extension and clarify thedifferences between the models, we now providea high-level overview of both models; details aregiven in Sections 3 and 4.2.1 Overview of LD modelBoth the LD and TLD models are computational-level models of phonetic (specifically, vowel) cat-egorization where phones (vowels) are presentedto the model in the context of words.2The task isto infer a set of phonetic categories and a set oflexical items on the basis of the data observed foreach word token xi.
In the original LD model, theobservations for token xiare its frame fi, whichconsists of a list of consonants and slots for vowels,and the list of vowel tokenswi.
(The TLD modelincludes additional observations, described below.
)A single vowel token, wij, is a two dimensionalvector representing the first two formants (peaksin the frequency spectrum, ordered from lowest tohighest).
For example, a token of the word kittywould have the frame fi= k t , containing twoconsonant phones, /k/ and /t/, with two vowel phoneslots in between, and two vowel formant vectors,2For a related model that also tackles the word segmenta-tion problem, see Elsner et al (2013).
In a model of phono-logical learning, Fourtassi and Dupoux (submitted) show thatsemantic context information similar to that used here remainsuseful despite segmentation errors.1074wi0= [464, 2294] and wi1= [412, 2760].3Given the data, the model must assign eachvowel token to a vowel category, wij= c. Boththe LD and the TLD models do this using inter-mediate lexemes, `, which contain vowel categoryassignments, v`j= c, as well as a frame f`.
If aword token is assigned to a lexeme, xi= `, thevowels within the word are assigned to that lex-eme?s vowel categories, wij= v`j= c.4The wordand lexeme frames must match, fi= f`.Lexical information helps with phonetic catego-rization because it can disambiguate highly over-lapping categories, such as the ae and eh categoriesin Figure 1.
A purely distributional learner who ob-serves a cluster of data points in the ae-eh region islikely to assume all these points belong to a singlecategory because the distributions of the categoriesare so similar.
However, a learner who attends tolexical context will notice a difference: contextsthat only occur with ae will be observed in one partof the ae-eh region, while contexts that only oc-cur with eh will be observed in a different (thoughpartially overlapping) space.
The learner then hasevidence of two different categories occurring indifferent sets of lexemes.Simulations with the LD model show that usinglexical information to constrain phonetic learningcan greatly improve categorization accuracy (Feld-man et al, 2013a), but it can also introduce errors.When two word tokens contain the same consonantframe but different vowels (i.e., minimal pairs),the model is more likely to categorize those twovowels together.
Thus, the model has trouble distin-guishing minimal pairs.
Although young childrenalso have trouble with minimal pairs (Stager andWerker, 1997; Thiessen, 2007), the LD model mayoverestimate the degree of the problem.
We hypoth-esize that if a learner is able to associate words withthe contexts of their use (as children likely are), thiscould provide a weak source of information for dis-ambiguating minimal pairs even without knowingtheir exact meanings.
That is, if the learner hearskV1t and kV2t in different situational contexts, theyare likely to be different lexical items (and V1andV2different phones), despite the lexical similaritybetween them.3In simulations we also experiment with frames in whichconsonants are not represented perfectly.4The notation is overloaded: wijrefers both to the vowelformants and the vowel category assignments, and xirefersto both the token identity and its assignment to a lexeme.2.2 Overview of TLD modelTo demonstrate the benefit of situational informa-tion, we develop the Topic-Lexical-Distributional(TLD) model, which extends the LD model by as-suming that words appear in situations analogousto documents in a topic model.
Each situation his associated with a mixture of topics ?h, which isassumed to be observed.
Thus, for the ith token insituation h, denoted xhi, the observed data will beits frame fhi, vowels whi, and topic vector ?h.From an acquisition perspective, the observedtopic distribution represents the child?s knowledgeof the context of the interaction: she can distin-guish bathtime from dinnertime, and is able to rec-ognize that some topics appear in certain contexts(e.g.
animals on walks, vegetables at dinnertime)and not in others (few vegetables appear at bath-time).
We assume that the child would learn thesetopics from observing the world around her andthe co-occurrences of entities and activities in theworld.
Within any given situation, there might bea mixture of different (actual or possible) topicsthat are salient to the child.
We assume further thatas the child learns the language, she will begin toassociate specific words with each topic as well.Thus, in the TLD model, the words used in a sit-uation are topic-dependent, implying meaning, butwithout pinpointing specific referents.
Although themodel observes the distribution of topics in eachsituation (corresponding to the child observing hernon-linguistic environment), it must learn to asso-ciate each (phonetically and lexically ambiguous)word token with a particular topic from that distri-bution.
The occurrence of similar-sounding wordsin different situations with mostly non-overlappingtopics will provide evidence that those words be-long to different topics and that they are thereforedifferent lexemes.
Conversely, potential minimalpairs that occur in situations with similar topic dis-tributions are more likely to belong to the sametopic and thus the same lexeme.Although we assume that children infer topicdistributions from the non-linguistic environment,we will use transcripts from CHILDES to create theword/phone learning input for our model.
Thesetranscripts are not annotated with environmentalcontext, but Roy et al (2012) found that topicslearned from similar transcript data using a topicmodel were strongly correlated with immediate ac-tivities and contexts.
We therefore obtain the topicdistributions used as input to the TLD model by1075training an LDA topic model (Blei et al, 2003)on a superset of the child-directed transcript datawe use for lexical-phonetic learning, dividing thetranscripts into small sections (the ?documents?
inLDA) that serve as our distinct situations h. Asnoted above, the learned document-topic distribu-tions ?
are treated as observed variables in theTLD model to represent the situational context.
Thetopic-word distributions learned by LDA are dis-carded, since these are based on the (correct andunambiguous) words in the transcript, whereas theTLD model is presented with phonetically ambigu-ous versions of these word tokens and must learn todisambiguate them and associate them with topics.3 Lexical-Distributional ModelIn this section we describe more formally the gen-erative process for the LD model (Feldman et al,2013a), a joint Bayesian model over phonetic cat-egories and a lexicon, before describing the TLDextension in the following section.The set of phonetic categories and the lexicon areboth modeled using non-parametric Dirichlet Pro-cess priors, which return a potentially infinite num-ber of categories or lexemes.
A DP is parametrizedas DP (?,H), where ?
is a real-valued hyperpa-rameter andH is a base distribution.H may be con-tinuous, as when it generates phonetic categoriesin formant space, or discrete, as when it generateslexemes as a list of phonetic categories.A draw from a DP, G ?
DP (?,H), returnsa distribution over a set of draws from H , i.e., adiscrete distribution over a set of categories or lex-emes generated by H .
In the mixture model setting,the category assignments are then generated fromG, with the datapoints themselves generated by thecorresponding components fromH .
IfH is infinite,the support of the DP is likewise infinite.
Duringinference, we marginalize over G.3.1 Phonetic Categories: IGMMFollowing previous models of vowel learning (deBoer and Kuhl, 2003; Vallabha et al, 2007; Mc-Murray et al, 2009; Dillon et al, 2013) we assumethat vowel tokens are drawn from a Gaussian mix-ture model.
The Infinite Gaussian Mixture Model(IGMM) (Rasmussen, 2000) includes a DP prior,as described above, in which the base distributionHCgenerates multivariate Gaussians drawn froma Normal Inverse-Wishart prior.5Each observation,a formant vector wij, is drawn from the Gaussiancorresponding to its category assignment cij:?c,?c?
HC= NIW(?0,?0, ?0) (1)GC?
DP (?c, HC) (2)cij?
GC(3)wij|cij= c ?
N(?c,?c) (4)The above model generates a category assignmentcijfor each vowel token wij.
This is the baselineIGMM model, which clusters vowel tokens usingbottom-up distributional information only; the LDmodel adds top-down information by assigning cat-egories in the lexicon, rather than on the tokenlevel.3.2 LexiconIn the LD model, vowel phones appear withinwords drawn from the lexicon.
Each such lexemeis represented as a frame plus a list of vowel cate-gories v`.
Lexeme assignments for each token aredrawn from a DP with a lexicon-generating basedistribution HL.
The category for each vowel to-ken in the word is determined by the lexeme; theformant values are drawn from the correspondingGaussian as in the IGMM:GL?
DP (?l, HL) (5)xi= ` ?
GL(6)wij|v`j= c ?
N(?c,?c) (7)HLgenerates lexemes by first drawing the num-ber of phones from a geometric distribution and thenumber of consonant phones from a binomial dis-tribution.
The consonants are then generated from aDP with a uniform base distribution (but note theyare fixed at inference time, i.e., are observed cate-gorically), while the vowel phones v`are generatedby the IGMM DP above, v`j?
GC.Note that two draws from HLmay result in iden-tical lexemes; these are nonetheless considered tobe separate (homophone) lexemes.4 Topic-Lexical-Distributional ModelThe TLD model retains the IGMM vowel phonecomponent, but extends the lexicon of the LDmodel by adding topic-specific lexicons, which cap-ture the notion that lexeme probabilities are topic-dependent.
Specifically, the TLD model replaces5This compound distribution is equivalent to?c?
IW(?0, ?0), ?c|?c?
N(?0,?c?0)1076the Dirichlet Process lexicon with a HierarchicalDirichlet Process (HDP; Teh (2006)).
In the HDPlexicon, a top-level global lexicon is generated asin the LD model.
Topic-specific lexicons are thendrawn from the global lexicon, containing a subsetof the global lexicon (but since the size of the globallexicon is unbounded, so are the topic-specific lex-icons).
These topic-specific lexicons are used togenerate the tokens in a similar manner to the LDmodel.
There are a fixed number of lower leveltopic-lexicons; these are matched to the numberof topics in the LDA model used to infer the topicdistributions (see Section 6.4).More formally, the global lexicon is generatedas a top-level DP: GL?
DP (?l, HL) (see Sec-tion 3.2; remember HLincludes draws from theIGMM over vowel categories).
GLis in turn usedas the base distribution in the topic-level DPs,Gk?
DP (?k, GL).
In the Chinese RestaurantFranchise metaphor often used to describe HDPs,GLis a global menu of dishes (lexemes).
The topic-specific lexicons are restaurants, each with its owndistribution over dishes; this distribution is definedby seating customers (word tokens) at tables, eachof which serves a single dish from the menu: alltokens x at the same table t are assigned to thesame lexeme `t. Inference (Section 5) is definedin terms of tables rather than lexemes; if multipletables draw the same dish from GL, tokens at thesetables share a lexeme.In the TLD model, tokens appear within situa-tions, each of which has a distribution over topics?h.
Each token xhihas a co-indexed topic assign-ment variable, zhi, drawn from ?h, designating thetopic-lexicon from which the table for xhiis to bedrawn.
The formant values for whijare drawn inthe same way as in the LD model, given the lexemeassignment at xhi.
This results in the followingmodel, shown in Figure 2:GL?
DP (?l, HL) (8)Gk?
DP (?k, GL) (9)zhi?Mult(?h) (10)xhi= t|zhi= k ?
Gk(11)whij|xhi= t, v`tj= c ?
N(?c,?c) (12)5 Inference: Gibbs SamplingWe use Gibbs sampling to infer three sets of vari-ables in the TLD model: assignments to vowel cat-egories in the lexemes, assignments of tokens to?0, ?0,?0, ?0HCGC?c?c,?c?
?HLGL?lGk?kKzhixhifhiwhij|whi||xh|D?hFigure 2: TLD model, depicting, from left to right,the IGMM component, the LD lexicon compo-nent, the topic-specific lexicons, and finally thetoken xhi, appearing in document h, with observedvowel formants whijand frame fhi.
The lexemeassignment xhiand the topic assignment zhiareinferred, the latter using the observed document-topic distribution ?h.
Note that fiis deterministicgiven the lexeme assignment.
Squared nodes depicthyperparameters.
?
is the set of hyperparametersused by HLwhen generating lexical items (seeSection 3.2).topics, and assignments of tokens to tables (fromwhich the assignment to lexemes can be read off).5.1 Sampling lexeme vowel categoriesEach vowel in the lexicon must be assigned to acategory in the IGMM.
The posterior probability ofa category assignment is composed of the DP priorover categories and the likelihood of the observedvowels belonging to that category.
We use w`jtodenote the set of vowel formants at position j inwords that have been assigned to lexeme `.
Then,P (v`j= c|w,x, `\`)?
P (v`j= c|`\`)p(w`j|v`j= c,w\`j) (13)The first (DP prior) factor is defined as:P (v`j= c|v\`j) ={ncPcnc+?cif c exists?cPcnc+?cif c new(14)where ncis the number of other vowels in the lex-icon, v\lj, assigned to category c. Note that thereis always positive probability of creating a newcategory.The likelihood of the vowels is calculated bymarginalizing over all possible means and vari-ances of the Gaussian category parameters, given1077the NIW prior.
For a single point (if |w`j| = 1),this predictive posterior is in the form of a Student-tdistribution; for the more general case see Feldmanet al (2013a), Eq.
B3.5.2 Sampling table & topic assignmentsWe jointly sample x and z, the variables assigningtokens to tables and topics.
Resampling the tableassignment includes the possibility of changing toa table with a different lexeme or drawing a newtable with a previously seen or novel lexeme.
Thejoint conditional probability of a table and topicassignment, given all other current token assign-ments, is:P (xhi= t, zhi= k|whi, ?h, t\hi, `,w\hi)= P (k|?h)P (t|k, `t, t\hi)?c?Cp(whi?|v`t?= c,w\hi) (15)The first factor, the prior probability of topic kin document h, is given by ?hkobtained from theLDA.
The second factor is the prior probability ofassigning word xito table t with lexeme ` giventopic k. It is given by the HDP, and depends onwhether the table t exists in the HDP topic-lexiconfor k and, likewise, whether any table in the topic-lexicon has the lexeme `:P (t|k, `, t\hi) ?????
?nktnk+?kif t in k?knk+?km`m+?lif t new, ` known?knk+?k?`m+?lif t and ` new(16)Here nktis the number of other tokens at table t,nkare the total number of tokens in topic k, m`is the number of tables across all topics with thelexeme `, and m is the total number of tables.The third factor, the likelihood of the vowel for-mantswhiin the categories given by the lexeme vl,is of the same form as the likelihood of vowel cate-gories when resampling lexeme vowel assignments.However, here it is calculated over the set of vow-els in the token assigned to each vowel category(i.e., the vowels at indices where v`t?= c).
For anew lexeme, we approximate the likelihood using100 samples drawn from the prior, each weightedby ?/100 (Neal, 2000).5.3 HyperparametersThe three hyperparameters governing the HDP overthe lexicon, ?land ?k, and the DP over vowel cate-gories, ?c, are estimated using a slice sampler.
Theremaining hyperparameters for the vowel categoryand lexeme priors are set to the same values usedby Feldman et al (2013a).6 Experiments6.1 CorpusWe test our model on situated child directed speech,taken from the C1 section of the Brent corpus inCHILDES (Brent and Siskind, 2001; MacWhinney,2000).
This corpus consists of transcripts of speechdirected at infants between the ages of 9 and 15months, captured in a naturalistic setting as par-ent and child went about their day.
This ensuresvariability of situations.Utterances with unintelligible words or quotesare removed.
We restrict the corpus to contentwords by retaining only words tagged as adj,n, part and v (adjectives, nouns, particles, andverbs).
This is in line with evidence that infantsdistinguish content and function words on the basisof acoustic signals (Shi and Werker, 2003).
Vowelcategorization improves when attending only tomore prosodically and phonologically salient to-kens (Adriaans and Swingley, 2012), which gen-erally appear within content, not function words.The final corpus consists of 13138 tokens and 1497word types.6.2 Hillenbrand VowelsThe transcripts do not include phonetic information,so, following Feldman et al (2013a), we synthe-size the formant values using data from Hillenbrandet al (1995).
This dataset consists of a set of 1669manually gathered formant values from 139 Amer-ican English speakers (men, women and children)for 12 vowels.
For each vowel category, we con-struct a Gaussian from the mean and covariance ofthe datapoints belonging to that category, using thefirst and second formant values measured at steadystate.
We also construct a second dataset using onlydatapoints from adult female speakers.Each word in the dataset is converted to a phone-mic representation using the CMU pronunciationdictionary, which returns a sequence of Arpabetphoneme symbols.
If there are multiple possiblepronunciations, the first one is used.
Each vowelphoneme in the word is then replaced by formantvalues drawn from the corresponding HillenbrandGaussian for that vowel.10786.3 Merging Consonant CategoriesThe Arpabet encoding used in the phonemic rep-resentation includes 24 consonants.
We constructdatasets both using the full set of consonants?the?C24?
dataset?and with less fine-grained conso-nant categories.
Distinguishing all consonant cate-gories assumes perfect learning of consonants priorto vowel categorization and is thus somewhat unre-alistic (Polka and Werker, 1994), but provides anupper limit on the information that word-contextscan give.In the ?C15?
dataset, the voicing distinction iscollapsed, leaving 15 consonant categories.
Thecollapsed categories are B/P, G/K, D/T, CH/JH,V/F, TH/DH, S/Z, SH/ZH, R/L while HH, M, NG,N, W, Y remain separate phonemes.
This datasetmirrors the finding in Mani and Plunkett (2010) that12 month old infants are not sensitive to voicingmispronunciations.The ?C6?
dataset distinguishes between only6 coarse consonant phonemes, corresponding tostops (B,P,G,K,D,T), affricates (CH,JH), fricatives(V, F, TH, DH, S, Z, SH, ZH, HH), nasals (M,NG, N), liquids (R, L), and semivowels/glides (W,Y).
This dataset makes minimal assumptions aboutthe category categories that infants could use in thislearning setting.Decreasing the number of consonants increasesthe ambiguity in the corpus: bat not only sharesa frame (b t) with boat and bite, but also, in theC15 dataset, with put, pad and bad (b/p d/t), andin the C6 dataset, with dog and kite, among manyothers (STOP STOP).
Table 1 shows the percent-age of types and tokens that are ambiguous in eachdataset, that is, words in frames that match multiplewordtypes.
Note that we always evaluate againstthe gold word identities, even when these are notdistinguished in the model?s input.
These datasetsare intended to evaluate the degree of reliance onconsonant information in the LD and TLD models,and to what extent the topics in the TLD model canreplace this information.6.4 TopicsThe input to the TLD model includes a distributionover topics for each situation, which we infer inadvance from the full Brent corpus (not only theC1 subset) using LDA.
Each transcript in the Brentcorpus captures about 75 minutes of parent-childinteraction, and thus multiple situations will beincluded in each file.
The transcripts do not delimitDataset C24 C15 C6Input Types 1487 1426 1203Frames 1259 1078 702Ambig Types % 27.2 42.0 80.4Ambig Tokens % 41.3 56.9 77.2Table 1: Corpus statistics showing the increasingamount of ambiguity as consonant categories aremerged.
Input types are the number of word typeswith distinct input representations (as opposed togold orthographic word types, of which there are1497).
Ambiguous types and tokens are those withframes that match multiple (orthographic) wordtypes.situations, so we do this somewhat arbitrarily bysplitting each transcript after 50 CDS utterances,resulting in 203 situations for the Brent C1 dataset.As well as function words, we also remove thefive most frequent content words (be, go, get, want,come).
On average, situations are only 59 wordslong, reflecting the relative lack of content wordsin CDS utterances.We infer 50 topics for this set of situations usingthe mallet toolkit (McCallum, 2002).
Hyperpa-rameters are inferred, which leads to a dominanttopic that includes mainly light verbs (have, let,see, do).
The other topics are less frequent but cap-ture stronger semantic meaning (e.g.
yummy, peach,cookie, daddy, bib in one topic, shoe, let, put, hat,pants in another).
The word-topic assignments areused to calculate unsmoothed situation-topic distri-butions ?
used by the TLD model.6.5 EvaluationWe evaluate against adult categories, i.e., the ?gold-standard?, since all learners of a language even-tually converge on similar categories.
(Since ourmodel is not a model of the learning process, wedo not compare the infant learning process to thelearning algorithm.)
We evaluate both the inferredphonetic categories and words using the clusteringevaluation measure V-Measure (VM; Rosenbergand Hirschberg, 2007).6VM is the harmonic meanof two components, similar to F-score, where thecomponents (VC and VH) are measures of crossentropy between the gold and model categorization.6Other clustering measures, such as 1-1 matching andpairwise precision and recall (accuracy and completeness)showed the same trends, but VM has been demonstrated tobe the most stable measure when comparing solutions withvarying numbers of clusters (Christodoulopoulos et al, 2010).107924 Cons 15 Cons 6 Cons75808590DatasetVMLD-allTLD-allLD-wTLD-wFigure 3: Vowel evaluation.
?all?
refers to datasetswith vowels synthesized from all speakers, ?w?
todatasets with vowels synthesized from adult femalespeakers?
vowels.
The bars show a 95% ConfidenceInterval based on 5 runs.
IGMM-all results in a VMscore of 53.9 (CI=0.5); IGMM-w has a VM scoreof 65.0 (CI=0.2), not shown.For vowels, VM measures how well the inferredphonetic categorizations match the gold categories;for lexemes, it measures whether tokens have beenassigned to the same lexemes both by the modeland the gold standard.
Words are evaluated againstgold orthography, so homophones, e.g.
hole andwhole, are distinct gold words.6.6 ResultsWe compare all three models?TLD, LD, andIGMM?on the vowel categorization task, andTLD and LD on the lexical categorization task(since IGMM does not infer a lexicon).
The datasetscorrespond to two sets of conditions: firstly, eitherusing vowel categories synthesized from all speak-ers or only adult female speakers, and secondly,varying the coarseness of the observed consonantcategories.
Each condition (model, vowel speak-ers, consonant set) is run five times, using 1500iterations of Gibbs sampling with hyperparametersampling.
Overall, we find that TLD outperformsthe other models in both tasks, across all condi-tions.Vowel categorization results are shown in Fig-ure 3.
IGMM performs substantially worse thanboth TLD and LD, with scores more than 30 pointslower than the best results for these models, clearlyshowing the value of the protolexicon and repli-500100015002000250030003500 F220040060080010001200F1Figure 4: Vowels found by the TLD model; su-pervowels are indicated in red.
The gold-standardvowels are shown in gold in the background but aremostly overlapped by the inferred categories.cating the results found by Feldman et al (2013a)on this dataset.
Furthermore, TLD consistently out-performs the LD model, finding better phoneticcategories, both for vowels generated from the com-bined categories of all speakers (?all?)
and vowelsgenerated from adult female speakers only (?w?
),although the latter are clearly much easier for bothmodels to learn.
Both models perform less wellwhen the consonant frames provide less informa-tion, but the TLD model performance degrades lessthan the LD performance.Both the TLD and the LD models find ?super-vowel?
categories, which cover multiple vowel cat-egories and are used to merge minimal pairs into asingle lexical item.
Figure 4 shows example vowelcategories inferred by the TLD model, includingtwo supervowels.
The TLD supervowels are usedmuch less frequently than the supervowels foundby the LD model, containing, on average, only two-thirds as many tokens.Figure 5 shows that TLD also outperforms LDon the lexeme/word categorization task.
Again per-formance decreases as the consonant categoriesbecome coarser, but the additional semantic infor-mation in the TLD model compensates for the lackof consonant information.
In the individual com-ponents of VM, TLD and LD have similar VC(?recall?
), but TLD has higher VH (?precision?
),demonstrating that the semantic information givenby the topics can separate potentially ambiguouswords, as hypothesized.Overall, the contextual semantic information108024 Cons 15 Cons 6 Cons92949698100DatasetVMLD-allTLD-allLD-wTLD-wFigure 5: Lexeme evaluation.
?all?
refers to datasetswith vowels synthesized from all speakers, ?w?
todatasets with vowels synthesized from adult femalespeakers?
vowels.added in the TLD model leads to both better pho-netic categorization and to a better protolexicon,especially when the input is noisier, using degradedconsonants.
Since infants are not likely to have per-fect knowledge of phonetic categories at this stage,semantic information is a potentially rich sourceof information that could be drawn upon to offsetnoise from other domains.
The form of the seman-tic information added in the TLD model is itselfquite weak, so the improvements shown here are inline with what infant learners could achieve.7 ConclusionLanguage acquisition is a complex task, in whichmany heterogeneous sources of information maybe useful.
In this paper, we investigated whethercontextual semantic information could be of helpwhen learning phonetic categories.
We found thatthis contextual information can improve phoneticlearning performance considerably, especially insituations where there is a high degree of pho-netic ambiguity in the word-forms that learnershear.
This suggests that previous models that haveignored semantic information may have underesti-mated the information that is available to infants.Our model illustrates one way in which languagelearners might harness the rich information that ispresent in the world without first needing to acquirea full inventory of word meanings.The contextual semantic information that theTLD model tracks is similar to that potentiallyused in other linguistic learning tasks.
Theoriesof cross-situational word learning (Smith and Yu,2008; Yu and Smith, 2007) assume that sensitivityto situational co-occurrences between words andnon-linguistic contexts is a precursor to learning themeanings of individual words.
Under this view, con-textual semantics is available to infants well beforethey have acquired large numbers of semantic min-imal pairs.
However, recent experimental evidenceindicates that learners do not always retain detailedinformation about the referents that are present in ascene when they hear a word (Medina et al, 2011;Trueswell et al, 2013).
This evidence poses a di-rect challenge to theories of cross-situational wordlearning.
Our account does not necessarily requirelearners to track co-occurrences between wordsand individual objects, but instead focuses on moreabstract information about salient events and topicsin the environment; it will be important to investi-gate to what extent infants encode this informationand use it in phonetic learning.Regardless of the specific way in which infantsencode semantic information, our method of addingthis information by using LDA topics from tran-script data was shown to be effective.
This methodis practical because it can approximate semanticinformation without relying on extensive manualannotation.The LD model extended the phonetic catego-rization task by adding word contexts; the TLDmodel presented here goes even further, addinglarger situational contexts.
Both forms of top-downinformation help the low-level task of classifyingacoustic signals into phonetic categories, furtheringa holistic view of language learning with interac-tion across multiple levels.AcknowledgmentsThis work was supported by EPSRC grantEP/H050442/1 and a James S. McDonnell Founda-tion Scholar Award to the final author.ReferencesFrans Adriaans and Daniel Swingley.
Distribu-tional learning of vowel categories is supportedby prosody in infant-directed speech.
In Pro-ceedings of the 34th Annual Conference of theCognitive Science Society (CogSci), 2012.E.
Bergelson and D. Swingley.
At 6-9 months,human infants know the meanings of many1081common nouns.
Proceedings of the NationalAcademy of Sciences, 109(9):3253?3258, Feb2012.David M. Blei, Thomas L. Griffiths, Michael I. Jor-dan, and Joshua B. Tenenbaum.
Hierarchicaltopic models and the nested Chinese restaurantprocess.
In Advances in Neural Information Pro-cessing Systems 16, 2003.Michael R. Brent and Jeffrey M. Siskind.
The roleof exposure to isolated words in early vocabularydevelopment.
Cognition, 81(2):B33?B44, 2001.Christos Christodoulopoulos, Sharon Goldwater,and Mark Steedman.
Two decades of unsuper-vised POS induction: How far have we come?In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics(ACL), pages 575?584, Cambridge, MA, Octo-ber 2010.
Association for Computational Lin-guistics.Bart de Boer and Patricia K. Kuhl.
Investigating therole of infant-directed speech with a computermodel.
Acoustics Research Letters Online, 4(4):129, 2003.Brian Dillon, Ewan Dunbar, and William Idsardi.
Asingle-stage approach to learning phonologicalcategories: Insights from Inuktitut.
CognitiveScience, 37(2):344?377, Mar 2013.Micha Elsner, Sharon Goldwater, Naomi Feldman,and Frank Wood.
A cognitive model of earlylexical acquisition with phonetic variability.
InProceedings of the 18th Conference on Empir-ical Methods in Natural Language Processing(EMNLP), 2013.Naomi H. Feldman, Thomas L. Griffiths, SharonGoldwater, and James L. Morgan.
A role for thedeveloping lexicon in phonetic category acquisi-tion.
Psychological Review, 2013a.Naomi H. Feldman, Emily B. Myers, Katherine S.White, Thomas L. Griffiths, and James L. Mor-gan.
Word-level information influences phoneticlearning in adults and infants.
Cognition, 127(3):427?438, 2013b.Abdellah Fourtassi and Emmanuel Dupoux.
A rudi-mentary lexicon and semantics help bootstrapphoneme acquisition.
Submitted.Michael C. Frank, Noah D. Goodman, andJoshua B. Tenenbaum.
Using speakers?
refer-ential intentions to model early cross-situationalword learning.
Psychological Science, 20(5):578?585, 2009.Manuela Friedrich and Angela D. Friederici.
Wordlearning in 6-month-olds: Fast encoding?weakretention.
Journal of Cognitive Neuroscience, 23(11):3228?3240, Nov 2011.Lakshmi J. Gogate and Lorraine E. Bahrick.
In-tersensory redundancy and 7-month-old infants?memory for arbitrary syllable-object relations.Infancy, 2(2):219?231, Apr 2001.J.
Hillenbrand, L. A. Getty, M. J. Clark, andK.
Wheeler.
Acoustic characteristics of Ameri-can English vowels.
Journal of the AcousticalSociety of America, 97(5 Pt 1):3099?3111, May1995.P.
W. Jusczyk and Elizabeth A. Hohne.
Infants?memory for spoken words.
Science, 277(5334):1984?1986, Sep 1997.Patricia K. Kuhl, Karen A. Williams, FranciscoLacerda, Kenneth N. Stevens, and Bjorn Lind-blom.
Linguistic experience alters phonetic per-ception in infants by 6 months of age.
Science,255(5044):606?608, 1992.Brian MacWhinney.
The CHILDES Project: Toolsfor Analyzing Talk.
Lawrence Erlbaum Asso-ciates, 2000.D.
R. Mandel, P. W. Jusczyk, and D. B. Pisoni.Infants?
recognition of the sound patterns of theirown names.
Psychological Science, 6(5):314?317, Sep 1995.Nivedita Mani and Kim Plunkett.
Twelve-month-olds know their cups from their keps and tups.Infancy, 15(5):445470, Sep 2010.Jessica Maye, Daniel J. Weiss, and Richard N.Aslin.
Statistical phonetic learning in infants:facilitation and feature generalization.
Develop-mental Science, 11(1):122?134, Jan 2008.Jessica Maye, Janet F Werker, and LouAnn Gerken.Infant sensitivity to distributional informationcan affect phonetic discrimination.
Cognition,82(3):B101?B111, Jan 2002.Andrew McCallum.
MALLET: A machine learn-ing for language toolkit, 2002.Bob McMurray, Richard N. Aslin, and Joseph C.Toscano.
Statistical learning of phonetic cate-gories: insights from a computational approach.Developmental Science, 12(3):369?378, May2009.1082Tamara Nicol Medina, Jesse Snedeker, John C.Trueswell, and Lila R. Gleitman.
How wordscan and cannot be learned by observation.
Pro-ceedings of the National Academy of Sciences,108(22):9014?9019, 2011.Radford Neal.
Markov chain sampling methodsfor Dirichlet process mixture models.
Journalof Computational and Graphical Statistics, 9:249?265, 2000.Linda Polka and Janet F. Werker.
Developmen-tal changes in perception of nonnative vowelcontrasts.
Journal of Experimental Psychology:Human Perception and Performance, 20(2):421?435, 1994.Carl Rasmussen.
The infinite Gaussian mixturemodel.
In Advances in Neural Information Pro-cessing Systems 13, 2000.Andrew Rosenberg and Julia Hirschberg.
V-measure: A conditional entropy-based externalcluster evaluation measure.
In Proceedings ofthe 12th Conference on Empirical Methods inNatural Language Processing (EMNLP), 2007.Brandon C. Roy, Michael C. Frank, and Deb Roy.Relating activity contexts to early word learningin dense longitudinal data.
In Proceedings of the34th Annual Conference of the Cognitive ScienceSociety (CogSci), 2012.Rushen Shi and Janet F. Werker.
The basis of pref-erence for lexical words in 6-month-old infants.Developmental Science, 6(5):484?488, 2003.M.
Shukla, K. S. White, and R. N. Aslin.
Prosodyguides the rapid mapping of auditory word formsonto visual objects in 6-mo-old infants.
Proceed-ings of the National Academy of Sciences, 108(15):6038?6043, Apr 2011.Linda B. Smith and Chen Yu.
Infants rapidly learnword-referent mappings via cross-situationalstatistics.
Cognition, 106(3):1558?1568, 2008.Christine L. Stager and Janet F. Werker.
Infantslisten for more phonetic detail in speech percep-tion than in word-learning tasks.
Nature, 388:381?382, 1997.D.
Swingley.
Contributions of infant word learningto language development.
Philosophical Trans-actions of the Royal Society B: Biological Sci-ences, 364(1536):3617?3632, Nov 2009.Yee Whye Teh.
A hierarchical Bayesian languagemodel based on Pitman-Yor processes.
In Pro-ceedings of the 44th Annual Meeting of the As-sociation for Computational Linguistics (ACL),pages 985 ?
992, Sydney, 2006.Tuomas Teinonen, Richard N. Aslin, Paavo Alku,and Gergely Csibra.
Visual speech contributes tophonetic learning in 6-month-old infants.
Cogni-tion, 108:850?855, 2008.Erik D. Thiessen.
The effect of distributional infor-mation on children?s use of phonemic contrasts.Journal of Memory and Language, 56(1):16?34,Jan 2007.R.
Tincoff and P. W. Jusczyk.
Some beginnings ofword comprehension in 6-month-olds.
Psycho-logical Science, 10(2):172?175, Mar 1999.Ruth Tincoff and Peter W. Jusczyk.
Six-month-olds comprehend words that refer to parts of thebody.
Infancy, 17(4):432444, Jul 2012.N.
S. Trubetzkoy.
Grundz?uge der Phonologie.
Van-denhoeck und Ruprecht, G?ottingen, 1939.John C. Trueswell, Tamara Nicol Medina, AlonHafri, and Lila R. Gleitman.
Propose but ver-ify: Fast mapping meets cross-situational wordlearning.
Cognitive Psychology, 66:126?156,2013.G.
K. Vallabha, J. L. McClelland, F. Pons, J. F.Werker, and S. Amano.
Unsupervised learningof vowel categories from infant-directed speech.Proceedings of the National Academy of Sci-ences, 104(33):13273?13278, Aug 2007.Janet F. Werker and Richard C. Tees.
Cross-language speech perception: Evidence for per-ceptual reorganization during the first year oflife.
Infant Behavior and Development, 7:49?63,1984.H.
Henny Yeung and Janet F. Werker.
Learningwords?
sounds before learning how words sound:9-month-olds use distinct objects as cues to cat-egorize speech information.
Cognition, 113(2):234?243, Nov 2009.Chen Yu and Linda B. Smith.
Rapid word learningunder uncertainty via cross-situational statistics.Psychological Science, 18(5):414?420, 2007.1083
