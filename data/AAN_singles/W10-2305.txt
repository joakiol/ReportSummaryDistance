Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 33?41,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsHierarchical spectral partitioning of bipartite graphs to cluster dialectsand identify distinguishing featuresMartijn WielingUniversity of GroningenThe Netherlandsm.b.wieling@rug.nlJohn NerbonneUniversity of GroningenThe Netherlandsj.nerbonne@rug.nlAbstractIn this study we apply hierarchical spectralpartitioning of bipartite graphs to a Dutchdialect dataset to cluster dialect varietiesand determine the concomitant sound cor-respondences.
An important advantage ofthis clustering method over other dialec-tometric methods is that the linguistic ba-sis is simultaneously determined, bridgingthe gap between traditional and quantita-tive dialectology.
Besides showing thatthe results of the hierarchical clusteringimprove over the flat spectral clusteringmethod used in an earlier study (Wielingand Nerbonne, 2009), the values of thesecond singular vector used to generate thetwo-way clustering can be used to identifythe most important sound correspondencesfor each cluster.
This is an important ad-vantage of the hierarchical method as itobviates the need for external methods todetermine the most important sound corre-spondences for a geographical cluster.1 IntroductionFor almost forty years quantitative methods havebeen applied to the analysis of dialect variation(Se?guy, 1973; Goebl, 1982; Nerbonne et al,1999).
Until recently, these methods focusedmostly on identifying the most important dialectalgroups using an aggregate analysis of the linguis-tic data.One of these quantitative methods, clustering,has been applied frequently to dialect data, espe-cially in an effort to compare computational anal-yses to traditional views on dialect areas (Davisand Houck, 1995; Clopper and Pisoni, 2004; Hee-ringa, 2004; Moisl and Jones, 2005; Mucha andHaimerl, 2005; Prokic?
and Nerbonne, 2009).While viewing dialect differences at an ag-gregate level certainly gives a more comprehen-sive view than the analysis of a single subjec-tively selected feature, the aggregate approach hasnever fully convinced traditional linguists of itsuse as it fails to identify the linguistic distinc-tions among the identified groups.
Recently, how-ever, Wieling and Nerbonne (2009; 2010) an-swered this criticism by applying a promisinggraph-theoretic method, the spectral partitioningof bipartite graphs, to cluster varieties and simulta-neously determine the linguistic basis of the clus-ters.The spectral partitioning of bipartite graphs hasbeen a popular method for the task of co-clusteringsince its introduction by Dhillon in 2001.
Besidesbeing used in the field of information retrievalfor co-clustering words and documents (Dhillon,2001), this method has also proven useful in thefield of bioinformatics, successfully co-clusteringgenes and conditions (Kluger et al, 2003).Wieling and Nerbonne (2009) used spectral par-titioning of bipartite graphs to co-cluster dialectvarieties and sound correspondences with respectto a set of reference pronunciations.
They reporteda fair geographical clustering of the varieties inaddition to sensible sound correspondences.
In afollow-up study, Wieling and Nerbonne (2010) de-veloped an external method to rank the sound cor-respondences for each geographic cluster, whichalso conformed largely to the subjectively selected?interesting?
sound correspondences in their ear-lier study (Wieling and Nerbonne, 2009).In all the aforementioned studies, the spectralgraph partitioning method was used to generate aflat clustering.
However, Shi and Malik (2000)indicated that a hierarchical clustering obtainedby repeatedly grouping in two clusters should bepreferred over the flat clustering approach as ap-proximation errors are reduced.
More importantly,genealogical relationships between languages (ordialects) are generally expected to have a hierar-chical structure due to the dynamics of language33Figure 1: Distribution of GTRP varieties includingprovince nameschange in which early changes result in separatevarieties which then undergo subsequent changesindependently (Jeffers and Lehiste, 1979).In this study, we will apply the hierarchicalspectral graph partitioning method to a Dutch di-alect dataset.
Besides comparing the results tothe flat clustering obtained by Wieling and Ner-bonne (2009), we will also show that identifyingthe most important sound correspondences is in-herent to the method, alleviating the need for anexternal ranking method (e.g., see Wieling andNerbonne, 2010).While the current study applies the hierarchicalclustering and (novel) ranking method to pronun-ciation data, we would also like to point out thatthese methods are not restricted to this type of dataand can readily be applied to other domains suchas information retrieval and bioinformatics whereother spectral methods (e.g., principal componentanalysis) have already been applied successfully(e.g., see Furnas et al, 1988 and Jolicoeur andMosimann, 1960).2 MaterialIn this study, we use the same dataset as dis-cussed by Wieling and Nerbonne (2009).
In short,the Goeman-Taeldeman-Van Reenen-project data(GTRP; Goeman and Taeldeman, 1996; Van den9DDOV6LWDUG$SSHOVFKD2XGHJDFigure 2: Example of a bipartite graph of varietiesand sound correspondencesBerg, 2003) is the most recent Dutch dialectdataset digitally available consisting of 1876 pho-netically transcribed items for 613 dialect varietiesin the Netherlands and Flanders.
We focus ona subset of 562 words selected by Wieling et al(2007) for all 424 Netherlandic varieties.
We donot include the Belgian varieties, as the transcrip-tions did not use the same number of tokens asused for the Netherlandic transcriptions.
The geo-graphic distribution of the GTRP varieties includ-ing province names is shown in Figure 1.3 MethodsThe spectral graph partitioning method we applyrequires as input an undirected bipartite graph.
Abipartite graph is a graph consisting of two sets ofvertices where each edge connects a vertex fromone set to a vertex in the other set.
Vertices withina set are not connected.
An example of a bipartitegraph is shown in Figure 2.
The vertices on the leftside represent the varieties, while the vertices onthe right side represent the sound correspondences(each individual sound is surrounded by a set ofsquare brackets).
An edge between a variety anda sound correspondence indicates that the soundcorrespondence occurs in that variety with respectto a specific reference variety.As we are interested in clustering dialect vari-eties and detecting their underlying linguistic ba-sis, our bipartite graph consists of dialect varietiesand for each variety the presence of sound corre-spondences compared to a reference variety (indi-cated by an edge; see Figure 2).
Because we donot have pronunciations of standard (or historical)Dutch, we use the pronunciations of the city Delftas our reference, since they are close to standard34Dutch (Wieling and Nerbonne, 2009) and allow amore straightforward interpretation of the soundcorrespondences than those of other varieties.3.1 Obtaining sound correspondencesWe obtain the sound correspondences by aligningthe pronunciations of Delft against the pronuncia-tions of all other dialect varieties using the Leven-shtein algorithm (Levenshtein, 1965).
The Leven-shtein algorithm generates an alignment by mini-mizing the number of edit operations (insertions,deletions and substitutions) needed to transformone string into the other.
For example, the Lev-enshtein distance between [bInd@n] and [bEind@],two Dutch dialect pronunciations of the word ?tobind?, is 3:bInd@n insert E 1bEInd@n subst.
i/I 1bEind@n delete n 1bEind@3The corresponding alignment is:b I n d @ nb E i n d @1 1 1When all edit operations have the same cost, itis clear that the vowel [I] in the alignment abovecan be aligned with either the vowel [E] or thevowel [i].
To improve the initial alignments, weuse an empirically derived segment distance tableobtained by using the pointwise mutual informa-tion (PMI) procedure as introduced by Wieling etal.
(2009).1 They showed that applying the PMIprocedure resulted in much better alignments thanusing several other alignment procedures.The initial step of the PMI procedure consistsof obtaining a starting set of alignments.
In ourcase we obtain these by using the Levenshteinalgorithm with a syllabicity constraint: vowelsmay only align with (semi-)vowels, and conso-nants only with consonants, except for syllabicconsonants which may also be aligned with vow-els.
Subsequently, the substitution cost of everysegment pair (a segment can also be a gap, rep-resenting an insertion or a deletion) can be calcu-lated according to a pointwise mutual informationprocedure assessing the statistical dependence be-tween the two segments:1The PMI procedure is implemented in the dialectom-etry package RUG/L04 which can be downloaded fromhttp://www.let.rug.nl/ kleiweg/L04.PMI(x, y) = log2(p(x, y)p(x) p(y))Where:?
p(x, y) is estimated by calculating the num-ber of times x and y occur at the same posi-tion in two aligned strings X and Y , dividedby the total number of aligned segments (i.e.the relative occurrence of the aligned seg-ments x and y in the whole data set).
Notethat either x or y can be a gap in the case ofinsertion or deletion.?
p(x) and p(y) are estimated as the numberof times x (or y) occurs, divided by the totalnumber of segment occurrences (i.e.
the rel-ative occurrence of x or y in the whole dataset).
Dividing by this term normalizes the co-occurrence frequency with respect to the fre-quency expected if x and y are statisticallyindependent.In short, this procedure adapts the distance be-tween two sound segments based on how likely itis that they are paired in the alignments.
If twosounds are seen more (less) often together than wewould expect based on their relative frequency inthe dataset, their PMI score will be positive (neg-ative).
Higher scores indicate that segments tendto co-occur in correspondences more often, whilelower scores indicate the opposite.
New segmentdistances (i.e.
segment substitution costs) are ob-tained by subtracting the PMI score from 0 andadding the maximum PMI score (to enforce thatthe minimum distance is 0).
Based on the adaptedsegment distances we generate new alignmentsand we repeat this procedure until the alignmentsremain constant.We extract the sound correspondences from thefinal alignments and represent the bipartite graphby a matrix A having 423 rows (all varieties, ex-cept Delft) and 957 columns (all occurring soundcorrespondences).
We do not include frequencyinformation in this matrix, but use binary values toindicate the presence (1) or absence (0) of a soundcorrespondence with respect to the reference pro-nunciation.2 To reduce the effect of noise, we only2We decided against using (the log) of the frequencies,as results showed that this approach gave too much weightto uninformative high-frequent substitutions of two identicalsounds.35regard a sound correspondence as present in a vari-ety when it occurs in at least three aligned pronun-ciations.
Consequently, we reduce the number ofsound correspondences (columns of A) by morethan half to 477.3.2 Hierarchical spectral partitioning ofbipartite graphsSpectral graph theory is used to find the princi-pal properties and structure of a graph from itsgraph spectrum (Chung, 1997).
Wieling and Ner-bonne (2009) used spectral partitioning of bipar-tite graphs as introduced by Dhillon (2001) toco-cluster varieties and sound correspondences,enabling them to obtain a geographical cluster-ing with a simultaneously derived linguistic basis(i.e.
the clustered sound correspondences).
WhileWieling and Nerbonne (2009) focused on theflat clustering approach, we will use the hierar-chical approach by iteratively clustering in twogroups.
This approach is preferred by Shi and Ma-lik (2000), because approximation errors are re-duced compared to the flat clustering approach.The hierarchical spectral partitioning algorithm,following Dhillon (2001), proceeds as follows:1.
Given the 423 ?
477 variety-by-segment-correspondence matrix A as discussed pre-viously, formAn = D1?1/2AD2?1/2with D1 and D2 diagonal matrices such thatD1(i, i) = ?jAij and D2(j, j) = ?iAij2.
Calculate the singular value decomposition(SVD) of the normalized matrix AnSVD(An) = U?V Tand take the singular vectors u2 and v23.
Compute z2 =[D1?1/2 u2D2?1/2 v2]4.
Run the k-means algorithm on z2 to obtainthe bipartitioning5.
Repeat steps 1 to 4 on both clusters separatelyto create the hierarchical clusteringThe following example (taken from Wieling andNerbonne, 2010) shows how we can co-cluster thegraph of Figure 2 in two groups.
The matrix rep-resentation of this graph is as follows:[2]:[I] [-]:[@] [d]:[w]Appelscha (Friesland) 1 1 0Oudega (Friesland) 1 1 0Vaals (Limburg) 0 1 1Sittard (Limburg) 0 1 1The first step is to construct matrices D1 andD2 which contain the total number of edges fromevery variety (D1) and every sound correspon-dence (D2) on the diagonal.
Both matrices areshown below.D1 =???
?2 0 0 00 2 0 00 0 2 00 0 0 2????
D2 =?
?2 0 00 4 00 0 2?
?The normalized matrix An can be calculatedusing the formula displayed in step 1 of the hierar-chical bipartitioning algorithm:An =???
?.5 .35 0.5 .35 00 .35 .50 .35 .5???
?Applying the singular value decomposition to Anyields:U =????
?.5 .5 .71 0?.5 .5 ?.71 0?.5 ?.5 0 ?.71?.5 ?.5 0 .71?????
=???
?1 0 00 .71 00 0 00 0 0???
?V T =??
?.5 ?.71 ?.5.71 0 ?.71?.5 .71 ?.5?
?Finally, we look at the second singular vector ofU (second column) and V T (second row; i.e.
sec-ond column of V ) and compute the 1-dimensionalvector z2:z2 =[.35 .35 ?.35 ?.35 .5 0 ?.5]TThe first four values correspond with the placesAppelscha, Oudega, Vaals and Sittard, while the36last three values correspond to the segment substi-tutions [2]:[I], [-]:[@] and [d]:[w].After running the k-means algorithm (with ran-dom initialization) on z2, the items are assigned toone of two clusters as follows:[1 1 2 2 1 1 2]TThis clustering shows that Appelscha andOudega are grouped together (corresponding tothe first and second item of the vector, above) andlinked to the clustered segment substitutions of[2]:[I] and [-]:[@] (cluster 1).
Also, Vaals and Sit-tard are clustered together and linked to the clus-tered segment substitution [d]:[w] (cluster 2).
Thesegment substitution [-]:[@] (an insertion of [@]) isactually not meaningful for the clustering of thevarieties (as can be seen in A), because the middlevalue of V T corresponding to this segment substi-tution equals 0.
It could therefore just as likely begrouped cluster 2.
Nevertheless, the k-means al-gorithm always assigns every item to one cluster.33.3 Determining the importance of soundcorrespondencesWieling and Nerbonne (2010) introduced a posthoc method to rank each sound correspondence[a]:[b] based on the representativenessR in a clus-ter ci (i.e.
the proportion of varieties v in cluster cicontaining the sound correspondence):R(a, b, ci) =|v in ci containing [a]:[b]||v in ci|and the distinctiveness D (i.e.
the number of vari-eties v within as opposed to outside cluster ci con-taining the sound correspondence normalized bythe relative size of the cluster):D(a, b, ci) =O(a, b, ci)?
S(ci)1?
S(ci)Where the relative occurrence O and the relativesize S are given by:O(a, b, ci) =|v in ci containing [a]:[b]||v containing [a]:[b]|S(ci) =|v in ci||all v?s|3Note that we could also have decided to drop this soundcorrespondence.
However using our ranking approach (seeSecion 3.3) already ensures that the uninformative sound cor-respondences are ranked very low.The importance I is then calculated by averagingthe distinctiveness and representativeness:I(a, b, ci) =R(a, b, ci) +D(a, b, ci)2An extensive explanation of this method can befound in Wieling and Nerbonne (2010).As we now only use a single singular vectorto determine the partitioning (in contrast to thestudy of Wieling and Nerbonne, 2010 where theyused multiple singular vectors to determine theflat clustering), we will investigate if the valuesof the singular vector v2 reveal information aboutthe importance (as defined above) of the individ-ual sound correspondences.
We will evaluate thesevalues by comparing them to the importance val-ues on the basis of the representativeness and dis-tinctiveness (Wieling and Nerbonne, 2010).4 ResultsIn this section, we will report the results of apply-ing the hierarchical spectral partitioning method toour Dutch dialect dataset.
In addition, we will alsocompare the geographical clustering to the resultsobtained by Wieling and Nerbonne (2009).We will only focus on the four main clusterseach consisting of at least 10 varieties.
Whileour method is able to detect smaller clusters inthe data, we do not believe these to be sta-ble.
We confirmed this by applying three well-known distance-based clustering algorithms (i.e.UPGMA, WPGMA and Ward?s Method; Prokic?and Nerbonne, 2009) to our data which also onlyagreed on four main clusters.
In addition, Wielingand Nerbonne (2009) reported reliable results on amaximum of 4 clusters.4.1 Geographical resultsFigure 3 shows a dendrogram visualizing the ob-tained hierarchy as well as a geographic visualiza-tion of the clustering.
For comparison, Figure 4shows the visualization of four clusters based onthe flat clustering approach of Wieling and Ner-bonne (2009).It is clear that the geographical results of thehierarchical approach (Figure 3) are comparableto the results of the flat clustering approach (Fig-ure 4) of Wieling and Nerbonne (2009).4 How-4Note that the results of the flat clustering approach werebased on all 957 sound correspondences.
No noise-reducingfrequency threshold was applied there, as this was reported tolead to poorer results (Wieling and Nerbonne, 2009).37Figure 3: Geographic visualization of the clus-tering including dendrogram.
The shades of greyin the dendrogram correspond with the map (e.g.,the Limburg varieties can be found at the bottom-right).ever, despite the Frisian area (top-left) being iden-tical, we clearly observe that both the Low Saxonarea (top-right) and the Limburg area (bottom-right) are larger in the map based on the hierar-chical approach.
As this better reflects the tradi-tional Dutch dialect landscape (Heeringa, 2004),the hierarchical clustering method seems to bean improvement over the flat clustering method.Also the hierarchy corresponds largely with theone found by Heeringa (2004, Chapter 9), identi-fying Frisian, Limburg and Low Saxon as separategroups.4.2 Most important sound correspondencesTo see whether the values of the singular vector v2can be used as a substitute for the external rankingmethod, we correlated the absolute values of theFigure 4: Geographic visualization of the flat clus-tering reported in Wieling and Nerbonne (2009).The shades of grey are identical to the shades ofgrey in Figure 3.singular vector with the importance values basedon the distinctiveness and representativeness.
Forthe sound correspondences of the Frisian area weobtained a high Spearman?s rank correlation co-efficient ?
of .92 (p < .001).
For the Low Saxonarea and the Limburg area we obtained similar val-ues (?
= .87, p < .001 and ?
= .88, p < .001,respectively).
These results clearly show that thevalues of the second singular vector v2 can beused as a good substitute for the external rankingmethod.Frisian areaThe following table shows the five most importantsound correspondences for the Frisian area.Rank 1 2 3 4 5Reference - [x] [f] [x] [a]Frisian [S] [j] - [z] [i]While we have limited overlap (only [x]:[z]; oc-curing in e.g.
zeggen ?say?
Dutch [zEx@], Frisian[siz@]) with the sound correspondences selectedand discussed by Wieling and Nerbonne (2010)who used the flat clustering method without a fre-quency threshold (also causing some of the differ-ences), we observe more overlap with the subjec-38tively selected sound correspondences in Wielingand Nerbonne (2009; [x]:[j] in e.g.
geld ?money?Dutch [xElt], Frisian [jIlt]; and [a]:[i] in e.g.
kaas?cheese?
Dutch [kas], Frisian [tsis]).
In addition,we detected two novel sound correspondences([f]:[-] and [-]:[S]).We commonly find the correspondence [-]:[S]in the infinitive form of verbs such as wachten?wait?
Dutch [waxt@], Frisian [waxtS@]; vechten?fight?
Dutch [vExt@], Frisian [vExtS@]; or spuiten?spray?
Dutch [sp?Yt@], Frisian [spoYtS@], but italso appears e.g.
in Dutch tegen ?against?
[teix@],Frisian [tSIn].
The [f]:[-] correspondence is foundin words like sterven ?die?
standard Dutch [stERf@],Frisian [stER@].Low Saxon areaThe most important sound correspondences of theLow Saxon area are shown in the table below.Rank 1 2 3 4 5Reference [k] [v] [@] [f] [p]Low Saxon [P] [b] [m] [b] [P]These sound correspondences overlap to a largeextent with the most important sound correspon-dences identified and discussed by Wieling andNerbonne (2010).
The correspondence [k]:[P] canbe found in words like planken ?boards?, Dutch[plANk@], Low Saxon [plANPN"], while the corre-spondence [v]:[b] is found in words like bleven?remain?
Dutch [blEv@n], Low Saxon [blibm"].The final overlapping correspondence [f]:[b] canbe observed in words like proeven ?test?
Dutch[pruf@], Low Saxon [proybm"].The sound correspondence [@]:[m] was dis-cussed and selected by Wieling and Ner-bonne (2009) as an interesting sound correspon-dence, occurring in words like strepen ?stripes?Dutch [strep@], Low Saxon [strepm"].The new correspondence [p]:[P] occurs inwords such as lampen ?lamps?
standard Dutch[lamp@], Aduard (Low Saxon) [lamPm"], but alsopostvocalically, as in gapen ?yawn?, standardDutch [xap@], Aduard (Low Saxon) [xoPm"].
Itis obviously related to the [k]:[P] correspondencediscussed above.Limburg areaThe most important sound correspondences for theLimburg area are displayed in the table below.Rank 1 2 3 4 5Reference [r] [s] [o] [n] [r]Limburg [x] [Z] - [x] [?
]For this area, we observe limited overlap withthe most important sound correspondences basedon distinctiveness and representativeness (Wielingand Nerbonne, 2010; only [n]:[x] overlaps, occur-ing in words like kleden ?cloths?
Dutch [kled@n],Limburg [klEId@x]), as well as with the subjec-tively selected interesting sound correspondences(Wieling and Nerbonne, 2009; only [r]:[?]
over-laps, which occurs in words like breken ?to break?Dutch [brek@], Limburg [b?Ek@]).The sound correspondence [o]:[-] can be foundin wonen ?living?, pronounced [woun@] in ourreference variety Delft and [wun@] in Limburg.As the standard Dutch pronunciation is actually[won@], this correspondence is caused by thechoice of our reference variety, which is unfortu-nately not identical to standard Dutch.The other two sound correspondences are moreinformative.
The sound correspondence [r]:[x] canbe found in words like vuur ?fire?
Dutch [fyr],Limburg [vy@x] and is similar to the sound cor-respondence [r]:[?]
discussed above.
The othercorrespondence [s]:[Z] occurs when comparing thestandard-like Delft variety to Limburg varietes inwords such as zwijgen ?to be silent?
[sweix@], Lim-burg [ZwiG@]; or zwemmen ?swim?
[swEm@], Lim-burg [Zw8m@].Hierarchical versus flat clusteringIn general, then, the sound correspondences un-covered by the hierarchical version of the spectralclustering technique turn out to be at least as in-teresting as those uncovered by the flat clustering,which leads us to regard the hierarchical cluster-ing technique as defensible in this respect.
Sincedialectologists are convinced that dialect areas areorganized hierarchically, we are naturally inclinedtoward hierarchical clustering techniques as well.We note additionally that the using the values ofthe second singular vector is an adequate substitu-tion of the external ranking method based on dis-tinctiveness and representativeness, which meansthat the present paper also marks a step forward insimplifying the methodology.5 DiscussionIn this study we showed that using hierarchi-cal spectral partitioning of bipartite graphs results39in an improved geographical clustering over theflat partitioning method and also results in sen-sible concomitant sound correspondences.
Oneof the reasons for the improvement of the geo-graphical clustering could be the approximationerrors which arise when going from the real val-ued solution to the discrete valued solution, andwhich increase with every additional singular vec-tor used (Shi and Malik, 2000).In addition, we showed that using the values ofthe second singular vector obviates the need foran external ranking method (e.g., see Wieling andNerbonne, 2010) to identify the most importantsound correspondences.Since the spectral partitioning of bipartitegraphs appears to be identifying significant (rep-resentative and distinctive) correspondences well?
both in the flat clustering design and in the(present) hierarchical scheme, several further op-portunities become worthy of exploration.
First,we might ask if we can automatically identifya threshold of significance for such correspon-dences, as to-date we have only sought to verifysignificance, not to exclude marginally significantelements.
Second, while we have applied the tech-nique exclusively to data for which the correspon-dence consists of a comparison of dialect data to(near) standard data, the analysis of historical data,in which varieties are compared to an earlier form,is within reach.
As the first step, we should wish tocompare data to a well-established historical pre-decessor as further steps might require genuine re-construction, still beyond anyone?s reach (as far aswe know).
Third, the technique would be moregenerally applicable if it did not require agree-ing on a standard, or pole of comparison.
Thissounds difficult, but multi-alignment techniquesmight bring it within reach (Prokic?
et al, 2009).It is intriguing to note that Nerbonne (in press)found only sporadic correspondences using fac-tor analysis on data which incorporated frequencyof correspondence, and we have likewise foundfrequency-weighted data less successful as a ba-sis for spectral bipartite clustering.
Shackleton(2007), Wieling and Nerbonne (2010) and the cur-rent paper are more successful using data whichlacks information about the frequency of occur-rence of sounds and/or sound correspondences.The question arises as to whether this is generaland why this is so.
Is it due to the skewness of fre-quency distributions, in which a suitable normal-ization might be attempted?
Or is it simply morestraightforward to focus on the absolute presenceor absence of a sound or sound correspondence?While sound correspondences function well asa linguistic basis, it might also be interesting toinvestigate morphological distinctions present inthe GTRP corpus.
This would enable us to com-pare the similarity of the geographic distributionsof pronunciation variation and morphological vari-ation.Finally, while we only tested this method on asingle dataset, it would be interesting to see if ourresults and conclusions also hold when applied tomore and different datasets.
We also realize thatthe evaluation in this study is rather qualitative, butwe intend to develop more quantitative evaluationmethods for future studies.AcknowledgementsWe thank Gertjan van Noord and Tim Van deCruys for their comments during a presentationabout the flat spectral graph partitioning method,which instigated the search for an inherent rank-ing method.ReferencesFan Chung.
1997.
Spectral graph theory.
AmericanMathematical Society.Cynthia G. Clopper and David B. Pisoni.
2004.
Someacoustic cues for the perceptual categorization ofAmerican English regional dialects.
Journal of Pho-netics, 32(1):111?140.L.M.
Davis and C.L.
Houck.
1995.
What Determines aDialect Area?
Evidence from the Linguistic Atlas ofthe Upper Midwest.
American Speech, 70(4):371?386.Inderjit Dhillon.
2001.
Co-clustering documents andwords using bipartite spectral graph partitioning.
InProceedings of the seventh ACM SIGKDD interna-tional conference on Knowledge discovery and datamining, pages 269?274.
ACM New York, NY, USA.George Furnas, Scott Deerwester, Susan Dumais,Thomas Landauer, Richard Harshman, LynnStreeter, and Karen Lochbaum.
1988.
Informationretrieval using a singular value decompositionmodel of latent semantic structure.
In Proceedingsof the 11th annual international ACM SIGIR confer-ence on Research and development in informationretrieval, pages 465?480.
ACM.Hans Goebl.
1982.
Dialektometrie: Prinzipienund Methoden des Einsatzes der NumerischenTaxonomie im Bereich der Dialektgeographie.40O?sterreichische Akademie der Wissenschaften,Wien.Ton Goeman and Johan Taeldeman.
1996.
Fonolo-gie en morfologie van de Nederlandse dialecten.Een nieuwe materiaalverzameling en twee nieuweatlasprojecten.
Taal en Tongval, 48:38?59.Wilbert Heeringa.
2004.
Measuring Dialect Pronunci-ation Differences using Levenshtein Distance.
Ph.D.thesis, Rijksuniversiteit Groningen.Robert Jeffers and Ilse Lehiste.
1979.
Principles andmethods for historical linguistics.
MIT Press, Cam-bridge.Pierre Jolicoeur and James E. Mosimann.
1960.
Sizeand shape variation in the painted turtle.
A principalcomponent analysis.
Growth, 24:339?354.Yuval Kluger, Ronen Basri, Joseph Chang, and MarkGerstein.
2003.
Spectral biclustering of microarraydata: Coclustering genes and conditions.
GenomeResearch, 13(4):703?716.Vladimir Levenshtein.
1965.
Binary codes capable ofcorrecting deletions, insertions and reversals.
Dok-lady Akademii Nauk SSSR, 163:845?848.Hermann Moisl and Val Jones.
2005.
Cluster anal-ysis of the newcastle electronic corpus of tynesideenglish: A comparison of methods.
Literary andLinguistic Computing, 20(supp.
):125?146.Hans-Joachim Mucha and Edgard Haimerl.
2005.Automatic validation of hierarchical cluster anal-ysis with application in dialectometry.
In ClausWeihs and Wolgang Gaul, editors, Classification?the Ubiquitous Challenge.
Proc.
of the 28th Meet-ing of the Gesellschaft fu?r Klassifikation, Dortmund,March 9?11, 2004, pages 513?520, Berlin.
Springer.John Nerbonne, Wilbert Heeringa, and Peter Kleiweg.1999.
Edit distance and dialect proximity.
In DavidSankoff and Joseph Kruskal, editors, Time Warps,String Edits and Macromolecules: The Theory andPractice of Sequence Comparison, 2nd ed., pages v?xv.
CSLI, Stanford, CA.John Nerbonne.
in press.
Various Variation Aggre-gates in the LAMSAS South.
In C. Davis and M. Pi-cone, editors, Language Variety in the South III.University of Alabama Press, Tuscaloosa.Jelena Prokic?
and John Nerbonne.
2009.
Recognizinggroups among dialects.
In John Nerbonne, CharlotteGooskens, Sebastian Kurschner, and Rene van Be-zooijen, editors, International Journal of Humani-ties and Arts Computing, special issue on LanguageVariation.Jelena Prokic?, Martijn Wieling, and John Nerbonne.2009.
Multiple sequence alignments in linguistics.In Lars Borin and Piroska Lendvai, editors, Lan-guage Technology and Resources for Cultural Her-itage, Social Sciences, Humanities, and Education,pages 18?25.Jean Se?guy.
1973.
La dialectome?trie dans l?atlas lin-guistique de gascogne.
Revue de Linguistique Ro-mane, 37(145):1?24.Robert G. Shackleton, Jr. 2007.
Phonetic variation inthe traditional english dialects.
Journal of EnglishLinguistics, 35(1):30?102.Jianbo Shi and Jitendra Malik.
2000.
Normalized cutsand image segmentation.
IEEE Transactions on pat-tern analysis and machine intelligence, 22(8):888?905.Boudewijn van den Berg.
2003.
Phonology & Mor-phology of Dutch & Frisian Dialects in 1.1 milliontranscriptions.
Goeman-Taeldeman-Van Reenenproject 1980-1995, Meertens Instituut ElectronicPublications in Linguistics 3.
Meertens Instituut(CD-ROM), Amsterdam.Martijn Wieling and John Nerbonne.
2009.
Bipartitespectral graph partitioning to co-cluster varieties andsound correspondences in dialectology.
In Mono-jit Choudhury, Samer Hassan, Animesh Mukher-jee, and Smaranda Muresan, editors, Proc.
of the2009 Workshop on Graph-based Methods for Nat-ural Language Processing, pages 26?34.Martijn Wieling and John Nerbonne.
2010.
Bipartitespectral graph partitioning for clustering dialect va-rieties and detecting their linguistic features.
Com-puter Speech and Language.
Accepted to appear ina special issue on network models of social and cog-nitive dynamics of language.Martijn Wieling, Wilbert Heeringa, and John Ner-bonne.
2007.
An aggregate analysis of pronuncia-tion in the Goeman-Taeldeman-Van Reenen-Projectdata.
Taal en Tongval, 59:84?116.Martijn Wieling, Jelena Prokic?, and John Nerbonne.2009.
Evaluating the pairwise alignment of pronun-ciations.
In Lars Borin and Piroska Lendvai, editors,Language Technology and Resources for CulturalHeritage, Social Sciences, Humanities, and Educa-tion, pages 26?34.41
