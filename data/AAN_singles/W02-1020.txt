User-Friendly Text Prediction for TranslatorsGeorge Foster and Philippe Langlais and Guy LapalmeRALI, Universite?
de Montre?al{foster,felipe,lapalme}@iro.umontreal.caAbstractText prediction is a form of interactivemachine translation that is well suited toskilled translators.
In principle it can as-sist in the production of a target text withminimal disruption to a translator?s nor-mal routine.
However, recent evaluationsof a prototype prediction system showedthat it significantly decreased the produc-tivity of most translators who used it.
Inthis paper, we analyze the reasons for thisand propose a solution which consists inseeking predictions that maximize the ex-pected benefit to the translator, rather thanjust trying to anticipate some amount ofupcoming text.
Using a model of a ?typ-ical translator?
constructed from data col-lected in the evaluations of the predictionprototype, we show that this approach hasthe potential to turn text prediction into ahelp rather than a hindrance to a translator.1 IntroductionThe idea of using text prediction as a tool for trans-lators was first introduced by Church and Hovy asone of many possible applications for ?crummy?machine translation technology (Church and Hovy,1993).
Text prediction can be seen as a form of in-teractive MT that is well suited to skilled transla-tors.
Compared to the traditional form of IMT basedon Kay?s original work (Kay, 1973)?in which theuser?s role is to help disambiguate the source text?prediction is less obtrusive and more natural, allow-ing the translator to focus on and directly control thecontents of the target text.
Predictions can benefita translator in several ways: by accelerating typing,by suggesting translations, and by serving as an im-plicit check against errors.The first implementation of a predictive tool fortranslators was described in (Foster et al, 1997), inthe form of a simple word-completion system basedon statistical models.
Various enhancements to thiswere carried out as part of the TransType project(Langlais et al, 2000), including the addition of a re-alistic user interface, better models, and the capabil-ity of predicting multi-word lexical units.
In the fi-nal TransType prototype for English to French trans-lation, the translator is presented with a short pop-up menu of predictions after each character typed.These may be incorporated into the text with a spe-cial command or rejected by continuing to type nor-mally.Although TransType is capable of correctly antic-ipating over 70% of the characters in a freely-typedtranslation (within the domain of its training cor-pus), this does not mean that users can translate in70% less time when using the tool.
In fact, in a trialwith skilled translators, the users?
rate of text pro-duction declined by an average of 17% as a resultof using TransType (Langlais et al, 2002).
Thereare two main reasons for this.
First, it takes time toread the system?s proposals, so that in cases wherethey are wrong or too short, the net effect will be toslow the translator down.
Second, translators do notalways act ?rationally?
when confronted with a pro-posal; that is, they do not always accept correct pro-posals and they occasionally accept incorrect ones.Many of the former cases correspond to translatorssimply ignoring proposals altogether, which is un-derstandable behaviour given the first point.Association for Computational Linguistics.Language Processing (EMNLP), Philadelphia, July 2002, pp.
148-155.Proceedings of the Conference on Empirical Methods in NaturalThis paper describes a new approach to text pre-diction intended to address these problems.
Themain idea is to make predictions that maximize theexpected benefit to the user in each context, ratherthan systematically proposing a fixed amount of textafter each character typed.
The expected benefit isestimated from two components: a statistical trans-lation model that gives the probability that a can-didate prediction will be correct or incorrect, and auser model that determines the benefit to the trans-lator in either case.
The user model takes into ac-count the cost of reading a proposal, as well as therandom nature of the decision to accept it or not.This approach can be characterized as making fewerbut better predictions: in general, predictions willbe longer in contexts where the translation model isconfident, shorter where it is less so, and absent incontexts where it is very uncertain.Other novel aspects of the work we describe hereare the use of a more accurate statistical translationmodel than has previously been employed for textprediction, and the use of a decoder to generate pre-dictions of arbitrary length, rather than just singlewords or lexicalized units as in the TransType pro-totype.
The translation model is based on the max-imum entropy principle and is designed specificallyfor this application.To evaluate our approach to prediction, we simu-lated the actions of a translator over a large corpus ofpreviously-translated text.
The result is an increaseof over 10% in translator productivity when usingthe predictive tool.
This is a considerable improve-ment over the -17% observed in the TransType trials.2 The Text Prediction TaskIn the basic prediction task, the input to the predictoris a source sentence s and a prefix h of its translation(ie, the target text before the current cursor position);the output is a proposed extension x to h. Figure 1gives an example.
Unlike the TransType prototype,which proposes a set of single-word (or single-unit)suggestions, we assume that each prediction consistsof only a single proposal, but one that may span anarbitrary number of words.As described above, the goal of the predictor isto find the prediction x?
that maximizes the expecteds: Let us return to serious matters.t:h?
??
?On va rx??
??
?evenir aux choses se?rieuses.x: evenir a`Figure 1: Example of a prediction for English toFrench translation.
s is the source sentence, h is thepart of its translation that has already been typed,x?
is what the translator wants to type, and x is theprediction.benefit to the user:x?
= argmaxxB(x,h, s), (1)where B(x,h, s) measures typing time saved.
Thisobviously depends on how much of x is correct, andhow long it would take to edit it into the desired text.A major simplifying assumption we make is that theuser edits only by erasing wrong characters from theend of a proposal.
Given a TransType-style interfacewhere acceptance places the cursor at the end of aproposal, this is the most common editing method,and it gives a conservative estimate of the cost at-tainable by other methods.
With this assumption,the key determinant of edit cost is the length of thecorrect prefix of x, so the expected benefit can bewritten as:B(x,h, s) =l?k=0p(k|x,h, s)B(x,h, s, k), (2)where p(k|x,h, s) is the probability that exactly kcharacters from the beginning of x will be correct,l is the length of x, and B(x,h, s, k) is the benefitto the user given that the first k characters of x arecorrect.Equations (1) and (2) define three main problems:estimating the prefix probabilities p(k|x,h, s), esti-mating the user benefit function B(x,h, s, k), andsearching for x?.
The following three sections de-scribe our solutions to these.3 Translation ModelThe correct-prefix probabilities p(k|x,h, s) arederived from a word-based statistical translationmodel.
The first step in the derivation is to con-vert these into a form that deals explicitly with char-acter strings.
This is accomplished by noting thatp(k|x,h, s) is the probability that the first k charac-ters of x are correct and that the k + 1th character(if there is one) is incorrect.
For k < l:p(k|x,h, s) = p(xk1|h, s)?
p(xk+11 |h, s)where xk1 = x1 .
.
.
xk.
If k = l, p(k|x,h, s) =p(x|h, s).
Also, p(x01) ?
1.The next step is to convert string probabilitiesinto word probabilities.
To do this, we assumethat strings map one-to-one into token sequences, sothat:p(xk1|h, s) ?
p(v1, w2, .
.
.
, wm?1, um|h, s),where v1 is a possibly-empty word suffix, each wi isa complete word, and um is a possibly empty wordprefix.
For example, if x in figure 1 were evenir auxchoses, then x141 would map to v1 = evenir, w2 =aux, and u3 = cho.
The one-to-one assumption isreasonable given that entries in our lexicon containneither whitespace nor internal punctuation.To model word-sequence probabilities, we applythe chain rule:p(v1, w2, .
.
.
, wm?1, um|h, s) =p(v1|h, s)m?1?i=2p(wi|h, v1, wi?12 , s)?p(um|h, v1, wm?12 , s).
(3)The probabilities of v1 and um can be expressed interms of word probabilities as follows.
Letting u1be the prefix of the word that ends in v1 (eg, r infigure 1), w1 = u1v1, and h = h?u1:p(v1|h, s) = p(w1|h?, s)/?w:w=u1vp(w|h?, s),where the sum is over all words that start with u1.Similarly:p(um|h?, wm?11 , s) =?w:w=umvp(w|h?, wm?11 , s).
(4)Thus all factors in (3) can be calculated fromprobabilities of the form p(w|h, s) which give thelikelihood that a word w will follow a previous se-quence of words h in the translation of s.1 This isthe family of distributions we have concentrated onmodeling.Our model for p(w|h, s) is a log-linear combina-tion of a trigram language model for p(w|h) and amaximum-entropy translation model for p(w|s), de-scribed in (Foster, 2000a; Foster, 2000b).
The trans-lation component is an analog of the IBM model 2(Brown et al, 1993), with parameters that are op-timized for use with the trigram.
The combinedmodel is shown in (Foster, 2000a) to have signif-icantly lower test corpus perplexity than the linearcombination of a trigram and IBM 2 used in theTransType experiments (Langlais et al, 2002).
Bothmodels supportO(mJV 3) Viterbi-style searches forthe most likely sequence of m words that follows h,where J is the number of tokens in s and V is thesize of the target-language vocabulary.Compared to an equivalent noisy-channel combi-nation of the form p(t)p(s|t), where t is the tar-get sentence, our model is faster but less accurate.It is faster because the search problem for noisy-channel models is NP-complete (Knight, 1999), andeven the fastest dynamic-programming heuristicsused in statistical MT (Niessen et al, 1998; Till-mann and Ney, 2000), are polynomial in J?for in-stance O(mJ4V 3) in (Tillmann and Ney, 2000).
Itis less accurate because it ignores the alignment rela-tion between s and h, which is captured by even thesimplest noisy-channel models.
Our model is there-fore suitable for making predictions in real time, butnot for establishing complete translations unassistedby a human.3.1 ImplementationThe most expensive part of the calculation in equa-tion (3) is the sum in (4) over all words in the vo-cabulary, which according to (2) must be carried outfor every character position k in a given predictionx.
We reduce the cost of this by performing sumsonly at the end of each sequence of complete tokensin x (eg, after revenir and revenir aux in the aboveexample).
At these points, probabilities for all pos-sible prefixes of the next word are calculated in a1Here we ignore the distinction between previous words thathave been sanctioned by the translator and those that are hy-pothesized as part of the current prediction.single recursive pass over the vocabulary and storedin a trie for later access.In addition to the exact calculation, we also ex-perimented with establishing exact probabilities viap(w|h, s) only at the end of each token in x, and as-suming that the probabilities of the intervening char-acters vary linearly between these points.
As a re-sult of this assumption, p(k|x,h, s) = p(xk1|h, s)?p(xk+11 |h, s) is constant for all k between the end ofone word and the next, and therefore can be factoredout of the sum in equation (2) between these points.4 User ModelThe purpose of the user model is to determine theexpected benefit B(x,h, s, k) to the translator of aprediction x whose first k characters match the textthat the translator wishes to type.
This will dependon whether the translator decides to accept or rejectthe prediction, so the first step in our model is thefollowing expansion:B(x,h, s, k) =?a?
{0,1}p(a|x,h, s, k)B(x,h, s, k, a),where p(a|x,h, s, k) is the probability that the trans-lator accepts or rejects x, B(x,h, s, k, a) is the ben-efit they derive from doing so, and a is a randomvariable that takes on the values 1 for acceptance and0 for rejection.
The first two quantities are the mainelements in the user model, and are described in fol-lowing sections.
The parameters of both were esti-mated from data collected during the TransType trialdescribed in (Langlais et al, 2002), which involvednine accomplished translators using a prototype pre-diction tool for approximately half an hour each.
Inall cases, estimates were made by pooling the datafor all nine translators.4.1 Acceptance ProbabilityIdeally, a model for p(a|x,h, s, k) would take intoaccount whether the user actually reads the proposalbefore accepting or rejecting it, eg:p(a|x,h, s, k) =?r?
{0,1}p(a|r,x,h, s, k)p(r|x,h, s, k)where r is a boolean ?read?
variable.
However, thisinformation is hard to extract reliably from the avail-able data; and even if were obtainable, many of the?60 ?50 ?40 ?30 ?20 ?10 0 10 20 30 40 50 6000.10.20.30.40.50.60.70.80.91probabilityofacceptinggain (length of correct prefix ?
length of incorrect suffix)rawsmoothedmodelFigure 2: Probability that a prediction will be ac-cepted versus its gain.factors which influence whether a user is likely toread a proposal?such as a record of how many pre-vious predictions have been accepted?are not avail-able to the predictor in our formulation.
We thusmodel p(a|x,h, s, k) directly.Our model is based on the assumption that theprobability of accepting x depends only on what theuser stands to gain from it, defined according to theediting scenario given in section 2 as the amount bywhich the length of the correct prefix of x exceedsthe length of the incorrect suffix:p(a|x,h, s, k) ?
p(a|2k ?
l),where k?
(l?k) = 2k?
l is called the gain.
For in-stance, the gain for the prediction in figure 1 wouldbe 2?
7?
8 = 6.
The strongest part of this assump-tion is dropping the dependence on h, because thereis some evidence from the data that users are morelikely to accept at the beginnings of words.
How-ever, this does not appear to have a severe effect onthe quality of the model.Figure 2 shows empirical estimates of p(a =1|2k?
l) from the TransType data.
There is a certainamount of noise intrinsic to the estimation proce-dure, since it is difficult to determine x?, and there-fore k, reliably from the data in some cases (whenthe user is editing the text heavily).
Nonetheless, itis apparent from the plot that gain is a useful abstrac-0 10 20 30 40 50 6005001000150020002500300035004000average timetoaccept (msecs)length of proposal (chars)rawleast?squares fit0 10 20 30 40 50 6005001000150020002500300035004000average timetoreject(msecs)length of proposal (chars)rawleast?squares fitFigure 3: Time to read and accept or reject proposals versus their lengthtion, because the empirical probability of acceptanceis very low when it is less than zero and rises rapidlyas it increases.
This relatively clean separation sup-ports the basic assumption in section 2 that benefitdepends on k.The points labelled smoothed in figure 2 wereobtained using a sliding-average smoother, and themodel curve was obtained using two-componentGaussian mixtures to fit the smoothed empiricallikelihoods p(gain|a = 0) and p(gain|a = 1).
Themodel probabilities are taken from the curve at in-tegral values.
As an example, the probability of ac-cepting the prediction in figure 1 is about .25.4.2 BenefitThe benefit B(x,h, s, k, a) is defined as the typingtime the translator saves by accepting or rejectinga prediction x whose first k characters are correct.To determine this, we assume that the translator firstreads x, then, if he or she decides to accept, uses aspecial command to place the cursor at the end of xand erases its last l ?
k characters.
Assuming inde-pendence from h, s as before, our model is:B(x, k, a) ={?R1(x) + T (x, k)?
E(x, k), a = 1?R0(x), a = 0where Ra(x) is the cost of reading x when it ul-timately gets accepted (a= 1) or rejected (a= 0),T (x, k) is the cost of manually typing xk1 , andE(x, k) is the edit cost of accepting x and erasingto the end of its first k characters.A natural unit for B(x, k, a) is the number ofkeystrokes saved, so all elements of the above equa-tion are converted to this measure.
This is straight-forward in the case of T (x, k) and E(x, k), whichare estimated as k and l ?
k + 1 respectively?forE(x, k), this corresponds to one keystroke for thecommand to accept a prediction, and one to eraseeach wrong character.
This is likely to slightly un-derestimate the true benefit, because it is usuallyharder to type n characters than to erase them.As in the previous section, read costs are inter-preted as expected values with respect to the proba-bility that the user actually does read x, eg, assuming0 cost for not reading, R0(x) = p(r=1|x)R?0(x),where R?0(x) is the unknown true cost of readingand rejecting x.
To determine Ra(x), we measuredthe average elapsed time in the TransType data fromthe point at which a proposal was displayed to thepoint at which the next user action occurred?eitheran acceptance or some other command signalling arejection.
Times greater than 5 seconds were treatedas indicating that the translator was distracted andwere filtered out.
As shown in figure 3, read timesare much higher for predictions that get accepted, re-flecting both a more careful perusal by the translatorand the fact the rejected predictions are often simplyignored.2 In both cases there is a weak linear rela-2Here the number of characters read was assumed to includethe whole contents of the TransType menu in the case of rejec-tions, and only the proposal that was ultimately accepted in thecase of acceptances.tionship between the number of characters read andthe time taken to read them, so we used the least-squares lines shown as our models.
Both plots arenoisy and would benefit from a more sophisticatedpsycholinguistic analysis, but they are plausible andempirically-grounded first approximations.To convert reading times to keystrokes for thebenefit function we calculated an average time perkeystroke (304 milliseconds) based on sections ofthe trial where translators were rapidly typing andwhen predictions were not displayed.
This gives anupper bound for the per-keystroke cost of reading?compare to, for instance, simply dividing the totaltime required to produce a text by the number ofcharacters in it?and therefore results in a conser-vative estimate of benefit.To illustrate the complete user model, in the fig-ure 1 example the benefit of accepting would be7?2?4.2 = .8 keystrokes and the benefit of reject-ing would be?.2 keystrokes.
Combining these withthe acceptance probability of .25 gives an overall ex-pected benefit B(x,h, s, k = 7) for this proposal of0.05 keystrokes.5 SearchSearching directly through all character strings xin order to find x?
according to equation (1) wouldbe very expensive.
The fact that B(x,h, s) is non-monotonic in the length of x makes it difficult to or-ganize efficient dynamic-programming search tech-niques or use heuristics to prune partial hypotheses.Because of this, we adopted a fairly radical searchstrategy that involves first finding the most likely se-quence of words of each length, then calculating thebenefit of each of these sequences to determine thebest proposal.
The algorithm is:1.
For each length m = 1 .
.
.M , find the bestword sequence:w?m = argmaxw1:(w1=u1v), wm2p(wm1 |h?, s),where u1 and h?
are as defined in section 3.2.
Convert each w?m to a corresponding characterstring x?m.3.
Output x?
= argmaxm B(x?m,h, s), or theempty string if all B(x?m,h, s) are non-positive.M average time maximum time1 0.0012 0.012 0.0038 0.233 0.0097 0.514 0.0184 0.555 0.0285 0.57Table 1: Approximate times in seconds to generatepredictions of maximum word sequence length M ,on a 1.2GHz processor, for the MEMD model.In all experiments reported below, M was set to amaximum of 5 to allow for convenient testing.
Step1 is carried out using a Viterbi beam search.
Tospeed this up, the search is limited to an active vo-cabulary of target words likely to appear in transla-tions of s, defined as the set of all words connectedby some word-pair feature in our translation modelto some word in s. Step 2 is a trivial deterministicprocedure that mainly involves deciding whether ornot to introduce blanks between adjacent words (egyes in the case of la + vie, no in the case of l?
+an).
This also removes the prefix u1 from the pro-posal.
Step 3 involves a straightforward evaluationof m strings according to equation (2).Table 1 shows empirical search timings for vari-ous values of M , for the MEMD model describedin the next section.
Times for the linear model aresimilar.
Although the maximum times shown wouldcause perceptible delays for M > 1, these occurvery rarely, and in practice typing is usually not no-ticeably impeded when using the TransType inter-face, even at M = 5.6 EvaluationWe evaluated the predictor for English to Frenchtranslation on a section of the Canadian Hansardcorpus, after training the model on a chronologi-cally earlier section.
The test corpus consisted of5,020 sentence pairs and approximately 100k wordsin each language; details of the training corpus aregiven in (Foster, 2000b).To simulate a translator?s responses to predic-tions, we relied on the user model, accepting prob-abilistically according to p(a|x,h, s, k), determin-ing the associated benefit using B(x,h, s, k, a), andadvancing the cursor k characters in the case of anconfig M1 2 3 4 5fixed -8.5 -0.4 -3.60 -11.6 -20.8linear 6.1 9.40 8.8 8.1 7.8exact 5.3 10.10 10.7 10.0 9.7corr 5.8 10.7 12.0 12.5 12.6best 7.9 17.90 24.5 27.7 29.2fixed -11.5 -9.3 -15.1 -22.0 -28.2exact 3.0 4.3 5.0 5.2 5.2best 6.2 12.1 15.4 16.7 17.3Table 2: Results for different predictor configura-tions.
Numbers give % reductions in keystrokes.user M1 2 3 4 5superman 48.6 53.5 51.8 51.1 50.9rational 11.7 17.8 17.2 16.4 16.1real 5.3 10.10 10.7 10.0 9.7Table 3: Results for different user simulations.Numbers give % reductions in keystrokes.acceptance, 1 otherwise.
Here k was obtained bycomparing x to the known x?
from the test corpus.It may seem artificial to measure performance ac-cording to the objective function for the predictor,but this is biased only to the extent that it misrepre-sents an actual user?s characteristics.
There are twocases: either the user is a better candidate?typesmore slowly, reacts more quickly and rationally?than assumed by the model, or a worse one.
Thepredictor will not be optimized in either case, butthe simulation will only overestimate the benefit inthe second case.
By being conservative in estimatingthe parameters of the user model, we feel we haveminimized the number of translators who would fallinto this category, and thus can hope to obtain real-istic lower bounds for the average benefit across alltranslators.Table 2 contains results for two different trans-lation models.
The top portion corresponds to theMEMD2B maximum entropy model described in(Foster, 2000a); the bottom portion corresponds tothe linear combination of a trigram and IBM 2 usedin the TransType experiments (Langlais et al, 2002).Columns give the maximum permitted number ofwords in predictions.
Rows show different predic-tor configurations: fixed ignores the user model andmakes fixedM -word predictions; linear uses the lin-ear character-probability estimates described in sec-tion 3.1; exact uses the exact character-probabilitycalculation; corr is described below; and best givesan upper bound on performance by choosing m instep 3 of the search algorithm so as to maximizeB(x,h, s, k) using the true value of k.Table 3 illustrates the effects of different compo-nents of the user model by showing results for sim-ulated users who read infinitely fast and accept onlypredictions having positive benefit (superman); whoread normally but accept like superman (rational);and who match the standard user model (real).
Foreach simulation, the predictor optimized benefits forthe corresponding user model.Several conclusions can be drawn from these re-sults.
First, it is clear that estimating expected bene-fit is a much better strategy than making fixed-word-length proposals, since the latter causes an increasein time for all values of M .
In general, making ?ex-act?
estimates of string prefix probabilities worksbetter than a linear approximation, but the differenceis fairly small.Second, the MEMD2B model significantly out-performs the trigram+IBM2 combination, produc-ing better results for every predictor configurationtested.
The figure of -11.5% in bold correspondsto the TransType configuration, and corroborates thevalidity of the simulation.3Third, there are large drops in benefit due to read-ing times and probabilistic acceptance.
The biggestcost is due to reading, which lowers the best possi-ble keystroke reduction by almost 50% for M = 5.Probabilistic acceptance causes a further drop ofabout 15% for M = 5.The main disappointment in these results is thatperformance peaks at M = 3 rather than continu-ing to improve as the predictor is allowed to con-sider longer word sequences.
Since the predictorknows B(x,h, s, k), the most likely cause for thisis that the estimates for p(w?m|h, s) become worsewith increasing m. Significantly, performance lev-3Although the drop observed with real users was greater atabout 20% (= 17% reduction in speed), there are many dif-ferences between experimental setups that could account forthe discrepancy.
For instance, part of the corpus used for theTransType trials was drawn from a different domain, whichwould adversely affect predictor performance.els off at three words, just as the search loses di-rect contact with h through the trigram.
To correctfor this, we used modified probabilities of the form?m p(w?m|h, s), where ?m is a length-specific cor-rection factor, tuned so as to optimize benefit on across-validation corpus.
The results are shown in thecorr row of table 2, for exact character-probabilityestimates.
In this case, performance improves withM , reaching a maximum keystroke reduction of12.6% at M = 5.7 Conclusion and Future WorkWe have described an approach to text prediction fortranslators that is based on maximizing the benefitto the translator according to an explicit user modelwhose parameters were set from data collected inuser evaluations of an existing text prediction proto-type.
Using this approach, we demonstrate in sim-ulated results that our current predictor can reducethe time required for an average user to type a textin the domain of our training corpus by over 10%.We look forward to corroborating this result in testswith real translators.There are many ways to build on the work de-scribed here.
The statistical models which arethe backbone of the predictor could be improvedby making them adaptive?taking advantage of theuser?s input?and by adding features to capture thealignment relation between h and s in such a way asto preserve the efficient search properties.
The usermodel could also be made adaptive, and it could beenriched in many other ways, for instance so as tocapture the propensity of translators to accept at thebeginnings of words.We feel that the idea of creating explicit user mod-els to guide the behaviour of interactive systems islikely to have applications in areas of NLP apartfrom translators?
tools.
For one thing, most of theapproach described here carries over more or lessdirectly to monolingual text prediction, which is animportant tool for the handicapped (Carlberger et al,1997).
Other possibilities include virtually any ap-plication where a human and a machine communi-cate through a language-rich interface.ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent Della J.Pietra, and Robert L. Mercer.
1993.
The mathematicsof Machine Translation: Parameter estimation.
Com-putational Linguistics, 19(2):263?312, June.Alice Carlberger, Johan Carlberger, Tina Magnuson,Sira E. Palazuelos-Cagigas, M. Sharon Hunnicutt, andSantiago Aguilera Navarro.
1997.
Profet, a new gen-eration of word prediction: an evaluation study.
InProceedings of the 2nd Workshop on NLP for Commu-nication Aids, Madrid, Spain, July.Kenneth W. Church and Eduard H. Hovy.
1993.
Goodapplications for crummy machine translation.
Ma-chine Translation, 8:239?258.George Foster, Pierre Isabelle, and Pierre Plamondon.1997.
Target-text Mediated Interactive MachineTranslation.
Machine Translation, 12:175?194.George Foster.
2000a.
Incorporating position infor-mation into a Maximum Entropy / Minimum Di-vergence translation model.
In Proceedings of the4th Computational Natural Language Learning Work-shop (CoNLL), Lisbon, Portugal, September.
ACLSigNLL.George Foster.
2000b.
A Maximum Entropy / MinimumDivergence translation model.
In Proceedings of the38th Annual Meeting of the Association for Computa-tional Linguistics (ACL), Hong Kong, October.Martin Kay.
1973.
The MIND system.
In R. Rustin,editor, Natural Language Processing, pages 155?188.Algorithmics Press, New York.Kevin Knight.
1999.
Decoding complexity in word-replacement translation models.
Computational Lin-guistics, Squibs and Discussion, 25(4).Philippe Langlais, George Foster, and Guy Lapalme.2000.
Unit completion for a computer-aided transla-tion typing system.
Machine Translation, 15(4):267?294, December.Philippe Langlais, Guy Lapalme, and Marie Loranger.2002.
TransType: From an idea to a system.
MachineTranslation.
To Appear.S.
Niessen, S. Vogel, H. Ney, and C. Tillmann.
1998.A DP based search algorithm for statistical machinetranslation.
In Proceedings of the 36th Annual Meet-ing of the ACL and 17th COLING 1998, pages 960?967, Montre?al, Canada, August.C.
Tillmann and H. Ney.
2000.
Word re-ordering andDP-based search in statistical machine translation.
InProceedings of the International Conference on Com-putational Linguistics (COLING) 2000, Saarbrucken,Luxembourg, Nancy, August.
