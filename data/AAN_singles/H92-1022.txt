A S IMPLE  RULE-BASED PART OF SPEECH TAGGEREr ic  Br i l l  *Depar tment  of Computer  Sc ienceUn ivers i ty  of  Pennsy lvan iaPh i lade lph ia ,  Pennsy lvan ia  19104br i l l~unag i .c i s .upenn.eduABSTRACTAutomatic part of speech tagging is an area of natural an-guage processing where statistical techniques have been moresuccessful than rule-based methods.
In this paper, we presenta simple rule-based part of speech tagger which automati-cally acquires its rules and tags with accuracy comparableto stochastic taggers.
The rule-based tagger has many ad-vantages over these taggers, including: a vast reduction instored information required, the perspicuity of a small setof meaningful rules, ease of finding and implementing im-provements to the tagger, and better portability from onetag set, corpus genre or language to another.
Perhaps thebiggest contribution of this work is in demonstrating thatthe stochastic method is not the only viable method for partof speech tagging.
The fact that a simple rule-based taggerthat automatically earns its rules can perform so well shouldoffer encouragement for researchers to further explore rule-based tagging, searching for a better and more expressiveset of rule templates and other variations on the simple buteffective theme described below.1.
INTRODUCTIONThere has been a dramatic increase in the application ofprobabilistic models to natural anguage processing overthe last few years.
The appeal of stochastic techniquesover traditional rule-based techniques comes from theease with which the necessary statistics can be automat-ically acquired and the fact that very little handcraftedknowledge need be built into the system.
In contrast,the rules in rule-based systems are usually difficult toconstruct and are typically not very robust.One area in which the statistical approach as done par-ticularly well is automatic part of speech tagging, as-signing each word in an input sentence its proper part ofspeech \[1, 2, 3, 4, 6, 9, 11, 12\].
Stochastic taggers have*A version of this paper appears in Proceedings of the ThirdConference on Applied Computational Linguistics (ACL), Trento,Italy, 1992.
Used by permission of the Association for Computa-tional Linguistics; copies of the publication from which this ma-terial is derived can can be obtained from Dr. Donald E. Walker(ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morris-town, NJ 07960-1910, USA.
The author would like to thank MitchMarcus and Rich Pito for valuable input.
This work was supportedby DARPA and AFOSR jointly under grant No.
AFOSR-90-0066,and by ARO grant No.
DAAL 03-89-G0031 PRI.112obtained a high degree of accuracy without performingany syntactic analysis on the input.
These stochasticpart of speech taggers make use of a Markov modelwhich captures lexical and contextual information.
Theparameters of the model can be estimated from tagged\[1, 3, 4, 6, 12\] or untagged \[2, 9, 11\] text.
Once theparameters of the model are estimated, a sentence canthen be automatically tagged by assigning it the tag se-quence which is assigned the highest probability by themodel.
Performance is often enhanced with the aid ofvarious higher level pre- and postprocessing proceduresor by manually tuning the model.A number of rule-based taggers have been built \[10, 7, 8\].\[10\] and \[7\] both have error rates substantially higherthan state of the art stochastic taggers.
\[8\] disam-biguates words within a deterministic parser.
We wantedto determine whether a simple rule-based tagger with-out any knowledge of syntax can perform as well as astochastic tagger, or if part of speech tagging really is adomain to which stochastic techniques are better suited.In this paper we describe a rule-based tagger which per-forms as well as taggers based upon probabilistic models.The rule-based tagger overcomes the limitations commonin rule-based approaches to language processing: it isrobust, and the rules are automatically acquired.
In ad-dition, the tagger has many advantages over stochastictaggers, including: a vast reduction in stored informa-tion required, the perspicuity of a small set of meaningfulrules as opposed to the large tables of statistics neededfor stochastic taggers, ease of finding and implementingimprovements o the tagger, and better portability fromone tag set or corpus genre to another.2.
THE TAGGERThe tagger works by automatically recognizing and rem-edying its weaknesses, thereby incrementally improvingits performance.
The tagger initially tags by assigningeach word its most likely tag, estimated by examining alarge tagged corpus, without regard to context.
In bothsentences below, run would be tagged as a verb:The run  lasted thirty minutes.We run  three miles every day.The initial tagger has two procedures built in to improveperformance; both make use of no contextual informa-tion.
One procedure is provided with information thatwords that were not in the training corpus and are cap-italized tend to be proper nouns, and attempts to fixtagging mistakes accordingly.
This information could beacquired automatically (see below), but is prespecifiedin the current implementation.
In addition, there is aprocedure which attempts to tag words not seen in thetraining corpus by assigning such words the tag mostcommon for words ending in the same three letters.
Forexample, blahblahous would be tagged as an adjective,because this is the most common tag for words endingin ous.
This information is derived automatically fromthe training corpus.This very simple algorithm has an error rate of about7.9% when trained on 90% of the tagged Brown Corpus 1\[5\], and tested on a separate 5% of the corpus.
~ Trainingconsists of compiling a list of the most common tag foreach word in the training corpus.The tagger then acquires patches to improve its perfor-mance.
Patch templates are of the form:have been tagged with tagb in the patch corpus.
Next, foreach error triple, it is determined which instantiation ofa template from the prespecified set of patch templatesresults in the greatest error reduction.
Currently, thepatch templates are:Change tag a to tag b when:1.
The preceding (following) word is tagged z.2.
The word two before (after) is tagged z.3.
One of the two preceding (following) words is taggedZ.4.
One of the three preceding (following) words istagged z.5.
The preceding word is tagged z and the followingword is tagged w.6.
The preceding (following) word is tagged z and theword two before (after) is tagged w.7.
The current word is (is not) capitalized.8.
The previous word is (is not) capitalized.?
If a word is tagged a and it is in context C, thenchange that tag to b, or?
If a word is tagged a and it has lexical property P,then change that tag to b, or?
If a word is tagged a and a word in region R haslexical property P, then change that tag to b.The initial tagger was trained on 90% of the corpus (thetraining corpus).
5% was held back to be used for thepatch acquisition procedure (the patch corpus) and 5%for testing.
Once the initial tagger is trained, it is used totag the patch corpus.
A list of tagging errors is compiledby comparing the output of the tagger to the correcttagging of the patch corpus.
This list consists of triples< taga,tagb, number >, indicating the number of timesthe tagger mistagged a word with taga when it shouldI The  Brown Corpus contains about  I .
i  mil l ion words from avariety of genres of wr i t ten English.
There are 192 tags in the tagset, 96 of which occur more than one hundred t imes in the corpus.2The test set contained text  from all genres in the BrownCorpus.113For each error triple < taga,tagb,number > and patch,we compute the reduction in error which results fromapplying the patch to remedy the mistagging of a wordas taga when it should have been tagged tagb.
We thencompute the number of new errors caused by applyingthe patch; that is, the number of times the patch resultsin a word being tagged as tagb when it should be taggedtaga.
The net improvement is calculated by subtractingthe latter value from the former.For example, when the initial tagger tags the patch cor-pus, it mistags 159 words as verbs when they should benouns.
If the patch change the tag from verb to noun ifone off the two preceding words is lagged as a determineris applied, it corrects 98 of the 159 errors.
However,it results in an additional 18 errors from changing tagswhich really should have been verb to noun.
This patchresults in a net decrease of 80 errors on the patch corpus.The patch which results in the greatest improvement tothe patch corpus is added to the list of patches.
Thepatch is then applied in order to improve the tagging ofthe patch corpus, and the patch acquisition procedurecontinues.The first ten patches found by the system are listed Patch Application and Error Reductionbelow 3.
(1) TO IN NEXT-TAG AT(2) VBN VBD PREV-WORD-IS-CAP YES(3) VBD VBN PREV-1-OR-2-OR-3-TAG HVD(4) VB NN PREV-1-OR-2-TAG AT(5) NN VB PREV-TAG TO(6) TO IN NEXT-WORD-IS-CAP YES(7) NN VB PREV-TAG MD(8) PPS PPO NEXT-TAG.
(9) VBN VBD PREV-TAG PPS(10) NP NN CURRENT-WORD- IS-CAP NOThe first patch states that i fa  word is tagged TO and thefollowing word is tagged AT, then switch the tag fromTO to IN.
This is because a noun phrase is much morelikely to immediately follow a preposition than to im-mediately follow infinitive TO.
The second patch statesthat a tag should be switched from VBN to VBD if thepreceding word is capitalized.
This patch arises from twofacts: the past verb tag is more likely than the past par-ticiple verb tag after a proper noun, and is also the morelikely tag for the second word of the sentence.
4 The thirdpatch states that VBD should be changed to VBN ifany of the preceding three words are tagged HVD.Once the list of patches has been acquired, new textcan be tagged as follows.
First, tag the text using thebasic lexical tagger.
Next, apply each patch in turn tothe corpus to decrease the error rate.
A patch whichchanges the tagging of a word from a to b only appliesif the word has been tagged b somewhere in the trainingcorpus.Note that one need not be too careful when constructingthe list of patch templates.
Adding a bad template to thelist will not worsen performance.
If a template is bad,then no rules which are instantiations of that templatewill appear in the final list of patches learned by thetagger.
This makes it easy to experiment with extensionsto the tagger.3AT = ar t i c le ,  HVD = had,  IN = prepos i t ion ,  MD = moda l ,NN = s ing.
noun,  NP  = proper  noun,  PPS  = 3rd  s ing.
nom.pronoun,  PPO = ob j .
persona l  p ronoun,  TO = in f in i t ive  to,  VB= verb ,  VBN = past  par t .
verb ,  VBD = past  verb.4Both  the  f i rst  word  of  a sentence  and  proper  nouns  axecap i ta l i zed .I I I20 40 60Number  of Pa lches3.
RESULTSThe tagger was tested on 5% of the Brown Corpus in-cluding sections from every genre.
First, the test corpuswas tagged by the simple lexical tagger.
Next, each ofthe patches was in turn applied to the corpus.
Below is agraph showing the improvement in accuracy from apply-ing patches.
It is significant hat with only 71 patches,an error rate of 5.1% was obtained 5.
Of the 71 patches,66 resulted in a reduction in the number of errors in thetest corpus, 3 resulted in no net change, and 2 resultedin a higher number of errors.
Almost all patches whichwere effective on the training corpus were also effectiveon the test corpus.Unfortunately, it is difficult to compare our results withother published results.
In \[12\], an error rate of 3-4%on one domain, Wall Street Journal articles and 5.6%on another domain, texts on terrorism in Latin Amer-ican countries, is quoted.
However, both the domainsand the tag set are different from what we use.
\[1\] re-ports an accuracy of "95-99% correct, depending on thedefinition of correct".
We implemented a version of the5We ran the experiment three times.
Each time we divided thecorpus into training, patch and test sets in a different way.
Allthree runs gave an error rate of 5%.114algorithm described in \[1\] which did not make use of adictionary to extend its lexical knowledge.
When trainedand tested on the same samples used in our experiment,we found the error rate to be about 4.5%.
\[3\] quotesa 4% error rate when testing and training on the sametext.
\[6\] reports an accuracy of 96-97%.
Their proba-bilistic tagger has been augmented with a handcraftedprocedure to pretag problematic "idioms".
This proce-dure, which requires that a list of idioms be laboriouslycreated by hand, contributes 3% toward the accuracy oftheir tagger, according to \[3\].
The idiom list would haveto be rewritten if one wished to use this tagger for adifferent ag set or a different corpus.
It is interestingto note that the information contained in the idiom listcan be automatically acquired by the rule-based tagger.For example, their tagger had difficulty tagging as oldas.
An explicit rule was written to pretag as old as withthe proper tags.
According to the tagging scheme of theBrown Corpus, the first as should be tagged as a quali-fier, and the second as a subordinating conjunction.
Inthe rule-based tagger, the most common tag for as issubordinating conjunction.
So initially, the second as istagged correctly and the first as is tagged incorrectly.
Toremedy this, the system acquires the patch: if the cur-rent word is tagged as a subordinating conjunction, andso is the word two positions ahead, then change the tag ofthe current word to qualifierfi The rule-based tagger hasautomatically earned how to properly tag this "idiom.
"Regardless of the precise rankings of the various taggers,we have demonstrated that a simple rule-based taggerwith very few rules performs on par with stochastic tag-gers.
It should be mentioned that our results were ob-tained without the use of a dictionary.
Incorporating alarge dictionary into the system would improve perfor-mance in two ways.
First, it would increase the accuracyin tagging words not seen in the training corpus, sincepart of speech information for some words not appearingin the training corpus can be obtained from the dictio-nary.
Second, it would increase the error reduction re-suiting from applying patches.
When a patch indicatesthat a word should be tagged with tagb instead of taga,the tag is only switched if the word was tagged with tagbsomewhere in the training corpus.
Using a dictionarywould provide more accurate knowledge about the setof permissible part of speech tags for a particular word.We plan to incorporate a dictionary into the tagger inthe future.As an estimate of the improvement possible by usinga dictionary, we ran two experiments where all wordswere known by the system.
First, the Brown Corpus6This was one of  the 71 patches acquired by the rule-basedtagger.was divided into a training corpus of about one millionwords, a patch corpus of about 65,000 words and a testcorpus of about 65,000 words.
Patches were acquiredas described above.
When tested on the test corpus,with lexical information derived solely from the trainingcorpus, the error rate was 5%.
Next, the same patcheswele used, but lexical information was gathered fromthe entire Brown Corpus.
This reduced the error rate to4.1%.
Finally, the same experiment was run with lexicalinformation gathered solely from the test corpus.
Thisresulted in a 3.5% error rate.
Note that the patches usedin the two experiments with no unknown words werenot the optimal patches for these tests, since they werederived from a corpus that contained unknown words.4.
CONCLUSIONSWe have presented a simple rule-based part of speechtagger which performs as well as existing stochastic tag-gers, but has significant advantages over these taggers.The tagger is extremely portable.
Many of the higherlevel procedures used to improve the performance ofstochastic taggers would not readily transfer over to adifferent ag set or genre, and certainly would not trans-fer over to a different language.
Everything except forthe proper noun discovery procedure is automatically ac-quired by the rule-based tagger 7, making it much moreportable than a stochastic tagger.
If the tagger weretrained on a different corpus, a different set of patchessuitable for that corpus would be found automatically.Large tables of statistics are not needed for the rule-based tagger.
In a stochastic tagger, tens of thousandsof lines of statistical information are needed to capturecontextual information.
This information is usually a ta-ble of trigram statistics, indicating for all tags taga, tagband tagc the probability that tagc follows taga and tagb.In the rule-based tagger, contextual information is cap-tured in fewer than eighty rules.
This makes for a muchmore perspicuous tagger, aiding in better understandingand simplifying further development of the tagger.
Con-textual information is expressed in a much more compactand understandable form.
As can be seen from compar-ing error rates, this compact representation f contextualinformation is just as effective as the information hiddenin the large tables of contextual probabilities.Perhaps the biggest contribution of this work is indemonstrating that the stochastic method is not the onlyviable approach for part of speech tagging.
The fact thatthe simple rule-based tagger can perform so well shouldoffer encouragement for researchers to further explorerule-based tagging, searching for a better and more ex-7And even this could be learned by the tagger.115pressive set of patch templates and other variations onthis simple but effective theme.References1.
Church, K. A Stochastic Parts Program and NounPhrase Parser for Unrestricted Text.
In Proceedings o/the Second Conference on Applied Natural LanguageProcessing, ACL, 136-143, 1988.2.
Cutting, D., Kupiec, J., Pederson, J. and Sibun, P. APractical Part-of-Speech Tagger.
In Proceedings of theThird Conference on Applied Natural Language Process-ing, AUL, 1992.3.
DeRose, S.J.
Grammatical Category Disambiguation byStatistical Optimization.
Computational Linguistics 14:31-39, 1988.4.
Deroualt, A. and Merialdo, B.
Natural language mod-eling for phoneme-to-text transcription.
IEEE Transac-tions on Pattern Analysis and Machine Intelligence, Vol.PAMI-8, No.
6, 742-749, 1986.5.
Francis, W. Nelson and Ku~era, Henry, Frequency anal-ysis of English usage.
Lexicon and grammar.
HoughtonMifflin, Boston, 1982.6.
Garside, R., Leech, G. & Sampson, G. The Computa-tional Analysis of English: A Corpus-Based Approach.Longman: London, 1987.7.
Green, B. and Rubin, G. Automated Grammatical Tag-ging of English.
Department of Linguistics, Brown Uni-versity, 1971.8.
Hindle, D. Acquiring disambiguation rules from text.Proceedings of the PTth Annual Meeting of the Associ-ation for Computational Linguistics, 1989.9.
Jelinek, F. Markov source modeling of text generation.In J. K. Skwirzinski, ed., Impact of Processing Tech-niques on Communication, Dordrecht, 1985.10.
Klein, S. and Simmons, R.F.
A Computational Ap-proach to Grammatical Coding of English Words.
JA CM10: 334-47.
1963.11.
Kupiec, J. Augmenting a hidden Markov model forphrase-dependent word tagging.
In Proceedings of theDARPA Speech and Natural Language Workshop, Mor-gan Kaufmann, 1989.12.
Meteer, M., Schwartz, R., and Weischedel, R. EmpiricalStudies in Part of Speech Labelling, Proceedings of theDARPA Speech and Natural Language Workshop, Mor-gan Kaufmann, 1991.116
