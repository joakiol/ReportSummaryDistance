Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 243?249,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsKLcpos3?
a Language Similarity Measurefor Delexicalized Parser TransferRudolf Rosa and Zden?ek?Zabokrtsk?yCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostransk?e n?am?est??
25, Prague, Czech Republic{rosa, zabokrtsky}@ufal.mff.cuni.czAbstractWe present KLcpos3 , a language similar-ity measure based on Kullback-Leibler di-vergence of coarse part-of-speech tag tri-gram distributions in tagged corpora.
Ithas been designed for multilingual delexi-calized parsing, both for source treebankselection in single-source parser trans-fer, and for source treebank weighting inmulti-source transfer.
In the selection task,KLcpos3 identifies the best source treebankin 8 out of 18 cases.
In the weighting task,it brings +4.5% UAS absolute, comparedto unweighted parse tree combination.1 IntroductionThe approach of delexicalized dependency parsertransfer is to train a parser on a treebank for asource language (src), using only non-lexical fea-tures, most notably part-of-speech (POS) tags, andto apply that parser to POS-tagged sentences of atarget language (tgt) to obtain dependency parsetrees.
Delexicalized transfer yields worse resultsthan a supervised lexicalized parser trained on atarget language treebank.
However, for languageswith no treebanks available, it may be useful toobtain at least a lower-quality parse tree for taskssuch as information retrieval.Usually, multiple source treebanks are avail-able, and it is non-trivial to select the best one for agiven target language.
As a solution, we present alanguage similarity measure based on KL diver-gence (Kullback and Leibler, 1951) of distribu-tions of coarse POS tag trigrams in POS-taggedcorpora, which we call KLcpos3 .
The measure hasbeen designed and tuned specifically for multilin-gual delexicalized parser transfer, and it often suc-ceeds in selecting the best source treebank in asingle-source setting, as well as in appropriatelyweighting the source treebanks by similarity to thetarget language in a multi-source parse tree com-bination approach.2 Related WorkDelexicalized parser transfer was conceived byZeman and Resnik (2008), who also introducedtwo important preprocessing steps ?
mappingtreebank-specific POS tagsets to a common setusing Interset (Zeman, 2008), and harmonizingtreebank annotation styles into a common style,which later developed into the HamleDT harmo-nized treebank collection (Zeman et al, 2012).McDonald et al (2011) applied delexicalizedtransfer in a setting with multiple source treebanksavailable, finding that the problem of selecting thebest source treebank without access to a target lan-guage treebank for evaluation is non-trivial.
Theycombined all source treebanks by concatenatingthem but noted that this yields worse results thanusing only the best source treebank.An alternative is the (monolingual) parse treecombination method of Sagae and Lavie (2006),who apply several independent parsers to the in-put sentence and combine the resulting parse treesusing a maximum spanning tree algorithm.
Sur-deanu and Manning (2010) enrich tree combi-nation with weighting, assigning each parser aweight based on its Unlabelled Attachment Score(UAS).
In our work, we introduce an extension ofthis method to a crosslingual setting by combiningparsers for different languages and using source-target language similarity to weight them.Several authors (Naseem et al, 2012; S?gaardand Wulff, 2012; T?ackstr?om et al, 2013b) em-ployed WALS (Dryer and Haspelmath, 2013)to estimate source-target language similarity fordelexicalized transfer, focusing on genealogy dis-tance and word-order features.
S?gaard and Wulff(2012) also introduced weighting into the tree-bank concatenation approach, using a POS n-gram model trained on a target-language corpus243to weight source sentences in a weighted percep-tron learning scenario (Cavallanti et al, 2010).
KLdivergence (Kullback and Leibler, 1951) of POStag distributions, as well as several other measures,was used by Plank and Van Noord (2011) to esti-mate monolingual domain similarity.As is quite common in parsing papers, includ-ing those dealing with semi-supervised and unsu-pervised parsing, we use gold POS tags in all ourexperiments.
This enables us to evaluate the ef-fectiveness of our parsing method alone, not influ-enced by errors stemming from the POS tagging.Based on the published results, it seems to be con-siderably easier to induce POS tags than syntacticstructure for under-resourced languages, as thereare several high-performance weakly-supervisedPOS taggers.
Das and Petrov (2011) report an av-erage accuracy of 83% using word-aligned texts,compared to 97% reached by a supervised tag-ger.
T?ackstr?om et al (2013a) further improve thisto 89% by leveraging Wiktionary.
For some lan-guages, there are even less resources available;Agi?c et al (2015b) were able to reach accuraciesaround 70% by using partial or full Bible transla-tion.
Our methods could thus be applied even ina more realistic scenario, where gold POS tags arenot available for the target text, by using a weakly-supervised POS tagger.
We intend to evaluate theperformance of our approach in such a setting infuture.3 Delexicalized Parser TransferThroughout this work, we use MSTperl (Rosa,2015b), an implementation of the unlabelledsingle-best MSTParser of McDonald et al(2005b), with first-order features and non-projective parsing, trained using 3 iterations ofMIRA (Crammer and Singer, 2003).1Our delexicalized feature set is based on the setof McDonald et al (2005a) with lexical featuresremoved.
It consists of combinations of signededge length (distance of head and parent, bucketedfor values above 4 and for values above 10) withPOS tag of the head, dependent, their neighbours,and all nodes between them.2We use the Univer-sal POS Tagset (UPOS) of Petrov et al (2012).1Note that while our approach does not depend in princi-ple on the actual parser used, our results and conclusions maynot be valid for other parsers.2The feature set, as well as scripts and configuration filesfor the presented experiments, are available in (Rosa, 2015a).3.1 Single-source Delexicalized TransferIn the single-source parser transfer, the delexical-ized parser is trained on a single source treebank,and applied to the target corpus.
The problem thusreduces to selecting a source treebank that willlead to a high performance on the target language.3.2 Multi-source Delexicalized TransferIn our work, we extend the monolingual parse treecombination method to a multi-source crosslin-gual delexicalized parser transfer setting:1.
Train a delexicalized parser on each sourcetreebank.2.
Apply each of the parsers to the target sen-tence, obtaining a set of parse trees.3.
Construct a weighted directed graph as acomplete graph over all tokens of the targetsentence, where each edge is assigned a scoreequal to the number of parse trees in which itappears (each parse tree contributes by either0 or 1 to the edge score).
In the weighted vari-ant of the method, the contribution of eachparse tree is multiplied by its weight.4.
Find the final dependency parse tree as themaximum spanning tree over the graph, us-ing the algorithm of Chu and Liu (1965) andEdmonds (1967).4 KLcpos3Language SimilarityWe introduce KLcpos3 , a language similarity mea-sure based on distributions of coarse POS tags insource and target POS-tagged corpora.
This is mo-tivated by the fact that POS tags constitute a keyfeature for delexicalized parsing.The distributions are estimated as frequencies ofUPOS trigrams3in the treebank training sections:f(cposi?1, cposi, cposi+1) ==count(cposi?1, cposi, cposi+1)?
?cposa,b,ccount(cposa, cposb, cposc); (1)we use a special value for cposi?1or cposi+1ifcposiappears at sentence beginning or end.We then apply the Kullback-Leibler divergence3Bigrams and tetragrams performed comparably on theweighting task, but worse on the selection task.
Using morefine-grained POS tags led to worse results as fine-grained fea-tures tend to be less shared across languages.244DKL(tgt ||src) to compute language similarity:4KLcpos3(tgt , src) ==?
?cpos3?tgtftgt(cpos3) ?
logftgt(cpos3)fsrc(cpos3), (2)where cpos3is a coarse POS tag trigram.
Forthe KL divergence to be well-defined, we set thesource count of each unseen trigram to 1.4.1 KLcpos3 for Source SelectionFor the single-source parser transfer, we computeKLcpos3 distance of the target corpus to each ofthe source treebanks and choose the closest sourcetreebank to use for the transfer.4.2 KL?4cpos3for Source WeightingTo convert KLcpos3 from a negative measure oflanguage similarity to a positive source parserweight for the multi-source tree combinationmethod, we take the fourth power of its invertedvalue.5The parse tree produced by each sourceparser is then weighted by KL?4cpos3(tgt , src).5 DatasetWe carry out our experiments using HamleDT 2.0of Rosa et al (2014), a collection of 30 treebanksconverted into Universal Stanford Dependencies(de Marneffe et al, 2014), with POS tags con-verted into UPOS; we use gold-standard POS tagsin all experiments.
We use the treebank trainingsections for parser training and language similarityestimation, and the test sections for evaluation.65.1 TuningTo avoid overfitting the exact definition of KLcpos3and KL?4cpos3to the 30 treebanks, we used only 124The KL divergence is non-symmetric; DKL(P ||Q) ex-presses the amount of information lost when a distribution Qis used to approximate the true distribution P .
Thus, in oursetting, we use DKL(tgt ||src), as we try to minimize the lossof using a src parser as an approximation of a tgt parser.5A high value of the exponent strongly promotes the mostsimilar source language, giving minimal power to the otherlanguages, which is good if there is a very similar source lan-guage.
A low value enables combining information from alarger number of source languages.
We chose a compromisevalue of 4 based on performance on the development data.6Contrary to the motivation, we do not evaluate ourmethod on truly underresourced languages, since automaticintrinsic evaluation is not possible on languages without tree-banks.
Still, e.g., Bengali and Telugu can be considered low-resourced, since their treebanks are very small.Measure Avg SD BestKL?4cpos3(tgt , src) 51.0 16.7 6KL?4cpos3(src, tgt) 50.6 17.4 4JS?4cpos3(tgt , src) 49.6 18.0 2coscpos3(tgt , src) 49.0 17.7 1Table 1: Weighted multi-source transfer using var-ious similarity measures.
Evaluation using aver-age UAS on the development set.Avg = Average UAS.SD = Standard sample deviation of UAS, serving as an indi-cation of robustness of the measure.Best = Number of targets for which the measure scored best.development treebanks for hyperparameter tuning:ar, bg, ca, el, es, et, fa, fi, hi, hu, it, ja.7Table 1 contains evaluation of several lan-guage similarity measures considered in the tuningphase, applied to weighted multi-source transferand evaluated using average UAS on the develop-ment set.
We evaluated KL divergences computedin both directions, as well as Jenses-Shannon di-vergence (Lee, 2001) and cosine similarity.
Basedon the results, KL?4cpos3was selected, as it per-formed best in all aspects.Once the hyperparameters were fixed, we ap-plied the parser transfer methods to the full set of30 treebanks; our final evaluation is based on theresults on the 18 test treebanks as targets.5.2 Other datasetsAdditionally, we also report preliminary results onthe Prague style conversion of HamleDT, whichloosely follows the style of the Prague Depen-dency Treebank of B?ohmov?a et al (2003), and onthe subset of CoNLL 2006 and 2007 shared tasks(Buchholz and Marsi, 2006; Nilsson et al, 2007)that was used by McDonald et al (2011).86 Evaluation6.1 ResultsTable 2 contains the results of our methods both onthe test languages and the development languages.7We tuned the choice of the similarity measure, POS n-gram length, and the way of turning KLcpos3into KL?4cpos3.To tune our method to perform well in many different situa-tions, we chose the development set to contain both smallerand larger treebanks, a pair of very close languages (ca, es), avery solitary language (ja), multiple members of several lan-guage families (Uralic, Romance), and both primarily left-branching (bg, el) and right-branching (ar, ja) languages.8The CoNLL subset is: da, de, el, en, es, it, nl, pt, sv.245For each target language, we used all remaining 29source languages for training (in the single-sourcemethod, only one of them is selected and applied).Our baseline is the treebank concatenationmethod of McDonald et al (2011), i.e., a singledelexicalized parser trained on the concatenationof the 29 source treebanks.As an upper bound,9we report the results ofthe oracle single-source delexicalized transfer: foreach target language, the oracle source parser isthe one that achieves the highest UAS on the targettreebank test section.10For space reasons, we donot include results of a higher upper bound of a su-pervised delexicalized parser (trained on the targettreebank), which has an average UAS of 68.5%.
Itwas not surpassed by our methods for any targetlanguage, although it was reached for Telugu, andapproached within 5% for Czech and Latin.6.2 DiscussionThe results show that KLcpos3 performs wellboth in the selection task and in the weightingtask, as both the single-source and the weightedmulti-source transfer methods outperform the un-weighted tree combination on average, as well asthe treebank concatenation baseline.
In 8 of 18cases, KLcpos3 is able to correctly identify the ora-cle source treebank for the single-source approach.In two of these cases, weighted tree combinationfurther improves upon the result of the single-source transfer, i.e., surpasses the oracle; in theremaining 6 cases, it performs identically to thesingle-source method.
This proves KLcpos3 to be asuccessful language similarity measure for delex-icalized parser transfer, and the weighted multi-source transfer to be a better performing approachthan the single-source transfer.The weighted tree combination is better than itsunweighted variant only for half of the target lan-guages, but it is more stable, as indicated by itslower standard deviation, and achieves an averageUAS higher by 4.5% absolute.
The unweightedtree combination, as well as treebank concatena-tion, perform especially poorly for English, Ger-man, Tamil, and Turkish, which are rich in deter-miners, unlike the rest of the treebanks;11there-9This is a hard upper-bound for the single-source transfer,but can be surpassed by the multi-source transfer.10We do not report the matrix of all source/target combina-tion results, as this amounts to 870 numbers.11In the treebanks for these four languages, determinersconstitute around 5-10% of all tokens, while most other tree-banks contain no determiners at all; in some cases, this isTgt TB Oracle Single-src Multi-srclang conc del trans KL ?1 ?wbn 61.0 te 66.7 0.5 te 66.7 63.2 66.7cs 60.5 sk 65.8 0.3 sk 65.8 60.4 65.8da 56.2 en 55.4 0.5 sl 42.1 54.4 50.3de 12.6 en 56.8 0.7 en 56.8 27.6 56.8en 12.3 de 42.6 0.8 de 42.6 21.1 42.6eu 41.2 da 42.1 0.7 tr 29.1 40.8 30.6grc 43.2 et 42.2 1.0 sl 34.0 44.7 42.6la 38.1 grc 40.3 1.2 cs 35.0 40.3 39.7nl 55.0 da 57.9 0.7 da 57.9 56.2 58.7pt 62.8 en 64.2 0.2 es 62.7 67.2 62.7ro 44.2 it 66.4 1.6 la 30.8 51.2 50.0ru 55.5 sk 57.7 0.9 la 40.4 57.8 57.2sk 52.2 cs 61.7 0.2 sl 58.4 59.6 58.4sl 45.9 sk 53.9 0.2 sk 53.9 47.1 53.9sv 45.4 de 61.6 0.6 da 49.8 52.3 50.8ta 27.9 hi 53.5 1.1 tr 31.1 28.0 40.0te 67.8 bn 77.4 0.4 bn 77.4 68.7 77.4tr 18.8 ta 40.3 0.7 ta 40.3 23.2 41.1Test 44.5 55.9 0.7 48.6 48.0 52.5SD 16.9 10.8 14.4 15.0 11.8ar 37.0 ro 43.1 1.7 sk 41.2 35.3 41.3bg 64.4 sk 66.8 0.4 sk 66.8 66.0 67.4ca 56.3 es 72.4 0.1 es 72.4 61.5 72.4el 63.1 sk 61.4 0.7 cs 60.7 62.3 63.8es 59.9 ca 72.7 0.0 ca 72.7 64.3 72.7et 67.5 hu 71.8 0.9 da 64.9 70.5 72.0fa 30.9 ar 35.6 1.1 cs 34.7 32.5 33.3fi 41.9 et 44.2 1.1 et 44.2 41.7 47.1hi 24.1 ta 56.3 1.1 fa 20.8 24.6 27.2hu 55.1 et 52.0 0.7 cs 46.0 56.5 51.2it 52.5 ca 59.8 0.3 pt 54.9 59.5 59.6ja 29.2 tr 49.2 2.2 ta 44.9 28.8 34.1Dev 48.5 57.1 0.9 52.0 50.3 53.5SD 15.2 12.5 16.1 16.5 16.7All 46.1 56.4 0.8 50.0 48.9 52.9SD 16.1 11.3 15.0 15.4 13.7PRG test 60.0 49.7 55.7 58.1PRG dev 64.0 57.5 58.0 61.1PRG all 61.5 52.8 56.6 59.3CoNLL 58.3 53.1 58.1 55.7Table 2: Evaluation using UAS on test target tree-banks (upper part of the table) and developmenttarget treebanks (lower part).For each target language, all 29 remaining non-target tree-banks were used for training the parsers.
The best scoreamong our transfer methods is marked in bold; the base-line and upper bound scores are marked in bold if equal toor higher than that.Legend:Tgt lang = Target treebank language.TB conc = Treebank concatenation.Oracle del trans = Single-source delexicalized transfer usingthe oracle source language.Single-src = Single-source delexicalized transfer using sourcelanguage with lowest KLcpos3distance to the target language(language bold if identical to oracle).Multi-src = Multi-source delexicalized transfer, unweighted(?1) and KL?4cpos3weighted (?w).Test, Dev, All, SD = Average on test/development/all, and itsstandard sample deviation.PRG, CoNLL = Preliminary results (average UAS) on Pragueconversion of HamleDT, and on subset of CoNLL used byMcDonald et al (2011).246fore, determiners are parsed rather randomly.12Inthe weighted methods, this is not the case any-more, as for a determiner-rich target language,determiner-rich source languages are given a highweight.For target languages for which KLcpos3 of theclosest source language was lower or equal to itsaverage value of 0.7, the oracle treebank was iden-tified in 7 cases out of 12 and a different but com-petitive one in 2 cases; when higher than 0.7, anappropriate treebank was only chosen in 1 case outof 6.
When KLcpos3 failed to identify the oracle,weighted tree combination was always better orequal to single-source transfer but mostly worsethan unweighted tree combination.
This showsthat for distant languages, KLcpos3 does not per-form as good as for close languages.We believe that taking multiple characteristicsof the languages into account would improve theresults on distant languages.
A good approachmight be to use an empirical measure, such asKLcpos3 , combined with supervised informationfrom other sources, such as WALS.
Alternatively,a backoff approach, i.e.
combining KLcpos3 withe.g.
KLcpos2 , might help to tackle the issue.Still, for target languages dissimilar to anysource language, a better similarity measure willnot help much, as even the oracle results are usu-ally poor.
More fine-grained resource combinationmethods are probably needed there, such as selec-tively ignoring word order, or using different setsof weights based on POS of the dependent node.6.3 Evaluation on Other DatasetsIn (Rosa, 2015c), we show that the accuracies ob-tained when parsing HamleDT treebanks in theUniversal Stanford Dependencies annotation styleare significantly lower than when using the Praguestyle.
Preliminary experiments using the Praguestyle conversion of HamleDT generally show ourmethods to be effective even on that dataset, al-though the performance of KLcpos3 is lower insource selection ?
it achieves lower UAS than un-weighted tree combination, and only identifies theoracle source treebank in 30% cases.
This may bedue to us having used only the Stanfordized tree-banks for tuning the exact definition of the mea-sure.related to properties of the treebank annotation or its harmo-nization rather than properties of the language.12UAS of determiner attachment tends to be lower than5%, which is several times less than for any other POS.Preliminary trials on the subset of CoNLL usedby McDonald et al (2011) indicated that our meth-ods do not perform well on this dataset.
The bestresults by far are achieved by the unweighted com-bination, i.e., it is best not to use KLcpos3 at allon this dataset.
We believe this to be a deficiencyof the dataset rather than of our methods ?
it israther small, and there is low diversity in the lan-guages involved, most of them being either Ger-manic or Romanic.
The HamleDT dataset is largerand more diverse, and we believe it to correspondbetter to the real-life motivation for our methods,thus providing a more trustworthy evaluation.In the near future, we intend to reevaluate ourmethods using the Universal Dependencies tree-bank collection (Nivre et al, 2015; Agi?c et al,2015a), which currently contains 18 languages ofvarious types and seems to be steadily growing.
Apotential benefit of this collection is the fact thatthe annotation style harmonization seems to bedone with more care and in a more principled waythan in HamleDT, presumably leading to a higherquality of the dataset.7 ConclusionWe presented KLcpos3 , an efficient language sim-ilarity measure designed for delexicalized depen-dency parser transfer.
We evaluated it on a largeset of treebanks, and showed that it performs wellin selecting the source treebank for single-sourcetransfer, as well as in weighting the source tree-banks in multi-source parse tree combination.Our method achieves good results when appliedto similar languages, but its performance drops fordistant languages.
In future, we plan to explorecombinations of KLcpos3 with other language sim-ilarity measures, so that similarity of distant lan-guages is estimated more reliably.In this work, we only used the unlabelled first-order MSTParser.
We intend to also employ otherparsers in future, possibly in combination, and ina labelled as well as unlabelled setting.AcknowledgmentsThis research was supported by the grants GAUK1572314, SVV 260 224, and FP7-ICT-2013-10-610516 (QTLeap).
This work has been using lan-guage resources developed, stored and distributedby the LINDAT/CLARIN project of the Ministryof Education, Youth and Sports of the Czech Re-public (project LM2010013).247References?Zeljko Agi?c, Maria Jesus Aranzabe, Aitziber Atutxa,Cristina Bosco, Jinho Choi, Marie-Catherinede Marneffe, Timothy Dozat, Rich?ard Farkas,Jennifer Foster, Filip Ginter, Iakes Goenaga,Koldo Gojenola, Yoav Goldberg, Jan Haji?c, An-ders Tr?rup Johannsen, Jenna Kanerva, JuhaKuokkala, Veronika Laippala, Alessandro Lenci,Krister Lind?en, Nikola Ljube?si?c, Teresa Lynn,Christopher Manning, H?ector Alonso Mart?
?nez,Ryan McDonald, Anna Missil?a, Simonetta Monte-magni, Joakim Nivre, Hanna Nurmi, Petya Osen-ova, Slav Petrov, Jussi Piitulainen, Barbara Plank,Prokopis Prokopidis, Sampo Pyysalo, WolfgangSeeker, Mojgan Seraji, Natalia Silveira, Maria Simi,Kiril Simov, Aaron Smith, Reut Tsarfaty, VeronikaVincze, and Daniel Zeman.
2015a.
Universal De-pendencies 1.1.
http://hdl.handle.net/11234/LRT-1478.
?Zeljko Agi?c, Dirk Hovy, and Anders S?gaard.
2015b.If all you have is a bit of the bible: Learning POStaggers for truly low-resource languages.
In The53rd Annual Meeting of the Association for Compu-tational Linguistics and the 7th International JointConference of the Asian Federation of Natural Lan-guage Processing (ACL-IJCNLP 2015).
Hrvatskaznanstvena bibliografija i MZOS-Svibor.Alena B?ohmov?a, Jan Haji?c, Eva Haji?cov?a, and BarboraHladk?a.
2003.
The Prague dependency treebank.
InTreebanks, pages 103?127.
Springer.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceedings of the Tenth Conference on Computa-tional Natural Language Learning, pages 149?164.Association for Computational Linguistics.Giovanni Cavallanti, Nicolo Cesa-Bianchi, and Clau-dio Gentile.
2010.
Linear algorithms for onlinemultitask classification.
The Journal of MachineLearning Research, 11:2901?2934.Yoeng-Jin Chu and Tseng-Hong Liu.
1965.
Onshortest arborescence of a directed graph.
ScientiaSinica, 14(10):1396.Koby Crammer and Yoram Singer.
2003.
Ultracon-servative online algorithms for multiclass problems.The Journal of Machine Learning Research, 3:951?991.Dipanjan Das and Slav Petrov.
2011.
Unsupervisedpart-of-speech tagging with bilingual graph-basedprojections.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies-Volume 1,pages 600?609.
Association for Computational Lin-guistics.Marie-Catherine de Marneffe, Natalia Silveira, Tim-othy Dozat, Katri Haverinen, Filip Ginter, JoakimNivre, and Christopher D. Manning.
2014.
Uni-versal Stanford dependencies: A cross-linguistic ty-pology.
In Proc.
of LREC?14, Reykjav?
?k, Iceland.ELRA.Matthew S. Dryer and Martin Haspelmath, editors.2013.
WALS Online.
Max Planck Institute for Evo-lutionary Anthropology, Leipzig.Jack Edmonds.
1967.
Optimum branchings.
Journalof Research of the National Bureau of Standards B,71(4):233?240.Solomon Kullback and Richard A Leibler.
1951.
Oninformation and sufficiency.
The annals of mathe-matical statistics, pages 79?86.Lillian Lee.
2001.
On the effectiveness of the skewdivergence for statistical language analysis.
In Arti-ficial intelligence and statistics, volume 2001, pages65?72.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005a.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd an-nual meeting on ACL, pages 91?98.
ACL.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Haji?c.
2005b.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedingsof the conference on Human Language Technologyand Empirical Methods in Natural Language Pro-cessing, pages 523?530.
ACL.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?11, pages 62?72, Stroudsburg, PA, USA.ACL.Tahira Naseem, Regina Barzilay, and Amir Globerson.2012.
Selective sharing for multilingual dependencyparsing.
In Proceedings of the 50th Annual Meetingof the ACL: Long Papers - Volume 1, ACL ?12, pages629?637, Stroudsburg, PA, USA.
ACL.Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007.The CoNLL 2007 shared task on dependency pars-ing.
In Proceedings of the CoNLL shared task ses-sion of EMNLP-CoNLL, pages 915?932.
sn.Joakim Nivre, Cristina Bosco, Jinho Choi, Marie-Catherine de Marneffe, Timothy Dozat, Rich?ardFarkas, Jennifer Foster, Filip Ginter, Yoav Gold-berg, Jan Haji?c, Jenna Kanerva, Veronika Laippala,Alessandro Lenci, Teresa Lynn, Christopher Man-ning, Ryan McDonald, Anna Missil?a, SimonettaMontemagni, Slav Petrov, Sampo Pyysalo, NataliaSilveira, Maria Simi, Aaron Smith, Reut Tsarfaty,Veronika Vincze, and Daniel Zeman.
2015.
Univer-sal Dependencies 1.0. http://hdl.handle.net/11234/1-1464.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Proc.
of LREC-2012, pages 2089?2096, Istanbul, Turkey.
ELRA.248Barbara Plank and Gertjan Van Noord.
2011.
Effec-tive measures of domain similarity for parsing.
InProceedings of the 49th Annual Meeting of the ACL:Human Language Technologies-Volume 1, pages1566?1576.
ACL.Rudolf Rosa, Jan Ma?sek, David Mare?cek, MartinPopel, Daniel Zeman, and Zden?ek?Zabokrtsk?y.2014.
HamleDT 2.0: Thirty dependency treebanksStanfordized.
In Proceedings of the 9th Interna-tional Conference on Language Resources and Eval-uation (LREC 2014), pages 2334?2341, Reykjav??k,Iceland.
ELRA.Rudolf Rosa.
2015a.
MSTperl delexicalized parsertransfer scripts and configuration files.
http://hdl.handle.net/11234/1-1485.Rudolf Rosa.
2015b.
MSTperl parser (2015-05-19).http://hdl.handle.net/11234/1-1480.Rudolf Rosa.
2015c.
Multi-source cross-lingual delex-icalized parser transfer: Prague or Stanford?
In EvaHaji?cov?a and Joakim Nivre, editors, Proceedings ofthe Third International Conference on DependencyLinguistics, Depling 2015, Uppsala, Sweden.
Upp-sala University.Kenji Sagae and Alon Lavie.
2006.
Parser combi-nation by reparsing.
In Proceedings of the HumanLanguage Technology Conference of the NAACL,Companion Volume: Short Papers, pages 129?132.ACL.Anders S?gaard and Julie Wulff.
2012.
An empiri-cal study of non-lexical extensions to delexicalizedtransfer.
In COLING (Posters), pages 1181?1190.Mihai Surdeanu and Christopher D. Manning.
2010.Ensemble models for dependency parsing: Cheapand good?
In Human Language Technologies:The 2010 Annual Conference of the North Ameri-can Chapter of the ACL, HLT ?10, pages 649?652,Stroudsburg, PA, USA.
ACL.Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, RyanMcDonald, and Joakim Nivre.
2013a.
Token andtype constraints for cross-lingual part-of-speech tag-ging.
Transactions of the Association for Computa-tional Linguistics, 1:1?12.Oscar T?ackstr?om, Ryan McDonald, and Joakim Nivre.2013b.
Target language adaptation of discrimina-tive transfer parsers.
In Proceedings of NAACL-HLT2013, pages 1061?1071.Daniel Zeman and Philip Resnik.
2008.
Cross-language parser adaptation between related lan-guages.
In IJCNLP 2008 Workshop on NLP for LessPrivileged Languages, pages 35?42, Hyderabad, In-dia.
Asian Federation of Natural Language Process-ing, International Institute of Information Technol-ogy.Daniel Zeman, David Mare?cek, Martin Popel,Loganathan Ramasamy, Jan?St?ep?anek, Zden?ek?Zabokrtsk?y, and Jan Haji?c.
2012.
HamleDT: Toparse or not to parse?
In Proceedings of the EightInternational Conference on Language Resourcesand Evaluation (LREC?12), Istanbul, Turkey, May.ELRA.Daniel Zeman.
2008.
Reusable tagset conversion us-ing tagset drivers.
In Proceedings of the 6th Interna-tional Conference on Language Resources and Eval-uation (LREC 2008), pages 213?218, Marrakech,Morocco.
ELRA.249
