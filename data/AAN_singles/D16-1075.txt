Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 784?794,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsNews Stream Summarization using Burst Information NetworksTao Ge1,2?, Lei Cui3, Baobao Chang1,2, Sujian Li1,2, Ming Zhou3, Zhifang Sui1,21Key Laboratory of Computational Linguistics, Ministry of Education,School of EECS, Peking University, Beijing, 100871, China2Collaborative Innovation Center for Language Ability, Xuzhou, Jiangsu, 221009, China3Microsoft Researchgetao@pku.edu.cn, lecu@microsoft.com, chbb@pku.edu.cnlisujian@pku.edu.cn, mingzhou@microsoft.com, szf@pku.edu.cnAbstractThis paper studies summarizing key informa-tion from news streams.
We propose sim-ple yet effective models to solve the problembased on a novel and promising representationof text streams ?
Burst Information Networks(BINets).
A BINet can be aware of redundantinformation, allows global analysis of a textstream, and can be efficiently built and dy-namically updated, which perfectly fits the de-mands of text stream summarization.
Exten-sive experiments show that the BINet-basedapproaches are not only efficient and can beused in a real-time online summarization set-ting, but also can generate high-quality sum-maries, outperforming the state-of-the-art ap-proach.1 IntroductionText stream summarization aims to summarize keyinformation from a text stream containing hugenumbers of documents, which is an important anduseful task that can be used for many real-world ap-plications.
For example, a news portal website ed-itor needs to summarize news streams in the pastday for generating a list of headline news; an edi-tor of Sports Weekly may want a summary of thepast week news stream for editing the magazine; andgeologists and meteorologists will benefit from asummary of disaster events from the past year newsstream (as shown in Table 1) for their study.In contrast to traditional text summarization tasks(e.g., single and multi-document summarization)?
This work was done when the first author was visitingMicrosoft Research Asiasingle-document summarization multi-document summarization stream summarization= sentence = documentFigure 1: Stream summarization paradigm.that have been extensively studied for decades, thetask of stream summarization is a younger researchproblem which attempts to solve a summarizationproblem in the big-data setting.
For a text streamwith millions of documents involving various topicsand events, traditional single- and multi-documentsummarization approaches cannot address the infor-mation overload challenge.
For example, a single-document summarization model will generate 1 mil-lion document summaries for a text stream with 1million documents, which are still overwhelming fora person to learn the key information in the stream.In such cases, one needs to a summary of the wholestream instead of summaries of each document.Figure 1 shows the paradigm of stream sum-marization.
Compared with single- and multi-document summarization, stream summarizationhas three differences: (1) it summarizes a textstream containing millions of documents involvinga variety of topics and events while single- and7842009 disaster summary 2010 disaster summary?
... ?
...?
Sep 2, 2009: About 60 people die when a 7.1-magnitude earthquake hit the island of Java.?
Jan 12, 2010: A 7.0-magnitude earthquake hit Haiti,killing about 200,000 people.?
Sep 9, 2009: More than 30 people are killed whenfast moving floods caused by heavy rain sweep throughIstanbul.?
Feb 27, 2010: An 8.8-magnitude earthquake rockedChile, killing at least 700 people dead and affectingmore than 1.5 million people.?
Sep 30, 2009: A 7.6-magnitude earthquake hit theisland of Sumatra, leaving more than 1,000 people deadand thousands injured.?
Apr 5, 2010: An explosion in a West Virginia coalmine kills at least 25 people and leaves 4 unaccountedfor.?
... ?
...Table 1: Stream summary about disasters in 2009 and 2010.
The disaster summary of 2009 can be used a reference summary tosupervise generating a disaster summary for the 2010 news stream.multi-document summarization summarizes one ora handful of documents about the same news event;(2) instead of selecting sentences to generate a sum-mary, stream summarization selects representativedocuments to summarize a text stream; (3) sum-maries for a text stream may vary significantly forusers who have different interests and preferences(e.g., summaries for an environmental expert anda sports fan should not be the same).
Therefore,in order to generate targeted summaries for spe-cific users, a stream summary needs to be generatedbased on a reference summary.
For instance, onecan use the 2009 disaster summary (the left part inTable 1) as a reference to learn how to write the 2010disaster summary (the right part in Table 1).In general, there are three challenges for summa-rizing a text stream.
First, a stream summarizationmodel should be able to be aware of redundant in-formation in the stream for avoiding generating re-dundant content in the summary; second, a streamsummarization algorithm should be capable of an-alyzing text content on the stream level for identi-fying the most important information in the stream;third, a stream summarization model should be effi-cient, scalable and able to run in an online fashionbecause data size of a text stream is usually huge,and it is dynamic and updated every second.The previous approaches (e.g., (Ge et al, 2015b))tend to cluster similar documents as event detectionto avoid redundancy, rank the clusters based on theirsizes and topical relevance to the reference sum-maries, and select one document from each clusteras representative documents.
Due to the high timecomplexity of clustering models, their approachesusually run slowly and are not scalable.To overcome the limitations, we propose Burst In-formation Networks (BINet) as a novel representa-tion of a text stream.
In a BINet (Figure 2), a node isa burst word (including entities) with the time spanof one of its burst periods, and an edge between twonodes indicates how strongly they are related.
Basedon the BINet representation, we propose two mod-els ?
NodeRank and AreaRank ?
for summarizing anews stream.
We conduct extensive experiments toevaluate our approaches by comparing several base-lines and the state-of-the-art approaches in varioussettings and show that the BINet-based approachesare efficient, scalable and can work in an online fash-ion and that they can generate high-quality sum-maries for a news stream, outperforming the state-of-the-art.The major contributions of this paper are:?
We propose BINets as a novel representationof text streams.
BINets can perfectly addressthe challenges of text stream summarization,which can be aware of information redundancy(Section 3), enables global analysis of the textstream (Section 4.1 and 4.2), and be efficientlybuilt and updated incrementally (Section 4.3).?
We propose two ranking-based models basedon the BINet representation, which can effec-tively learn to summarize a text stream from areference summary, and outperform the state-of-the-art model.?
We create and release a new benchmark datasetfor evaluating real-time stream summarization.2 Stream SummarizationThe task of text stream summarization is to gen-erate a summary including key information from a785earthquake (Jan 12 - Jan 31)Haitimagnitudehitkillaidinjuredonationgovernmentpolicedamage house quakeHaitianWorld Cup (Jun 11 - Jul 14)Spain finalSouth Africagoal PKNetherlandForlanMVP Uruguaychampion Iniestahostgrouptournamentstandings???
?Figure 2: Illustration of a BINet.
Due to space limitation, we only show the burst period of some nodes.given text stream (e.g., 1-year news stream).
In con-trast to traditional summarization tasks which sum-marize a single or a handful of documents relatedto the same event by extracting sentences, the taskof stream summarization aims to summarize a textstream which contains huge numbers of documentsinvolving a variety of topics and events by select-ing representative documents, as Figure 1 shows.In a stream summary, each selected document isconsidered as an entry which can be shown us-ing the title or the first paragraph of the document.Since documents in a news stream are always aboutnews events, we also call an entry as an event en-try and call a stream summary as an event chron-icle which is a list of event entries, as shown inTable 1.
In a stream summary, entries should notbe redundant.
Formally, we define a stream sum-mary (i.e., event chronicle) E = {e1, e2, ?
?
?
, eK}where ek = (tek ,wek) is an event entry includingthe event?s time information tek and text descriptionwek which is set of words in text.Due to the diversity of ways to summarize a textstream as Section 1 discusses, we use a referencesummary of a text stream during an early period tosupervise summary generation for new text streams.It is a practical setting since many historical manu-ally edited summaries of early streams are availableand can be used as an example to demonstrate whatkind of information is preferred in a stream sum-mary.3 Representing a text stream using BurstInformation Network3.1 BurstA word?s burst refers to a remarkable increase in thenumber of occurrences of the word during a periodand might indicate important events or trending top-ics.
For example, as shown in Figure 3, the wordearthquake has bursts from the Jan 12 to Jan 31,2010 and from Feb 27 to Mar 8, 2010 because ofthe strong earthquakes occurring in Haiti and Chilerespectively.Days0 10 20 30 40 50 60 70 80 90 100Frequency0100200300400500600Figure 3: Frequency of earthquake during the first 90 days inthe 2010 news stream.Specifically, if a word w is in a burst state at everytime t during a period, we call this period as a burstperiod of w, and w has a burst during this period.
InFigure 3, earthquake has 2 burst periods (i.e., (Jan12 - Jan 31) and (Feb 27 - Mar 8))Formally, we define P as one burst period of theword w. P is a consecutive time sequence duringwhich w bursts at every time epoch t:P = (ti, ti+1, ti+2, ..., ti+n)?t ?
P st = 1where st is a binary indicator of the burst state of wat time t.3.2 Burst Information NetworkTo build an information network which can repre-sent associations between key facts in a text stream,we propose a new representation called ?Burst Infor-mation Network (BINet)?
by using burst elements asnodes:A Burst Element is a burst of a word.
It can berepresented by a tuple: ?w,P?
where w denotes the786word and P denotes one burst period of w.According to the above definition, a burst elementis a joint representation of a word type and one of itsburst periods.
A word may have multiple burst peri-ods while a burst element only has one burst period.A word during its different burst periods will be re-garded as different burst elements.Formally, we define the BINet G = ?V,E?
as fol-lows.
Each node v ?
V is a burst element and eachedge e ?
E denotes the association between burst el-ements.
Intuitively, if two burst elements frequentlyco-occur, the edge between them should be highlyweighted.
We define ?i,j as the weight of an edgebetween vi and vj , which is equal to the number ofdocuments where vi and vj co-occur.Besides w(v) and P(v) that denote a node v?sword and burst period respectively, we also recorda node?s context words1 and its source documentswhich the node is from during constructing a BINet.Formally, we use C(v) and D(v) to denote the con-text word set and source document set of v. Also, fora document d in the stream, we use A(d) to denotethe set of nodes whose source documents include d.Since nodes in A(d) are usually adjacent, we alsocallA(d) document d?s area on the BINet.
The con-struction of a BINet is efficient: the time complexityof building a BINet is O(n) where n is the numberof documents in a stream.BINets can be properly aware of redundant in-formation: since nodes in a community in a BINetare topically and temporally coherent, informationabout the same news event tends to be adjacent andredundant information of the same event is naturallyremoved.
For example, assuming that there are hun-dreds of documents about Haiti earthquake in a textstream, by using the BINet representation, the infor-mation is concentrated in a few adjacent nodes with-out redundancy (left part in Figure 2).
Moreover, in-formation about different events is not considered asredundant.
For example, the information regardingHaiti earthquake and Chile earthquake is not treatedas redundant, which is allocated to different areas inthe BINet, as Figure 2 shows.
Therefore, as long aswe do not select overlapping areas on the BINet, wecan avoid selecting redundant content as entries.1Here, the context window size is set to 10.
Note that inour experiments, only words frequently (more than 5 times) co-occur in the context will be reserved.0.10.90.10.7 0.50.20.3 1.00.80.30.2Figure 4: NodeRank (left) and AreaRank (right).In addition to the awareness of information redun-dancy, BINets also allow global importance analysison the stream level and online stream summariza-tion, which will be discussed in Section 4.4 Summarizing a text stream on the BINetBased on the BINet representation, we propose twomodels ?
NodeRank and AreaRank ?
to summarizea text stream by generating entries of the summary.As Figure 4 shows, the NodeRank model scores ev-ery node on the BINet independently for identify-ing the most valuable information to be includedin the stream summary, while the AreaRank modelattempts to score an area that covers a handful ofnodes for locating the most informative informationblocks.To train NodeRank and AreaRank models, weuse reference summaries and the (reference) BINetsbuilt from the text stream during the reference sum-mary?s period as supervision.4.1 NodeRankIntuitively, if we can find the most valuable infor-mation on the BINet that should be included in thesummary, then we can generate a high-quality sum-mary of a text stream.
For this goal, we label thecorresponding nodes of words appearing in the ref-erence summary on the reference BINet as score 1(positive).
Formally, for a reference summary E , welabel the following set of nodes in the reference BI-Net Gr = ?Vr, Er?
as score 1:Vpos =?ek?E{v|v ?
Vr ?
w(v) ?
wek ?
tek ?
P(v)}(1)where w(v) and P(v) are word and burst period ofnode v respectively, ek is an event entry in the ref-erence summary E , wek is the set of words in ek?stext, and tek is ek?s time.
The nodes that are notin Vpos in the reference BINet will be labeled as 0(negative).787After labeling the reference BINet, we train alearning to rank (L2R) model2 using the follow-ing features for scoring nodes in the target BINetG?
= {V?
, E?}
(shown in Figure 4):?
w(v): the word of node v, indicating its seman-tic information.?
pr(v): node v?s PageRank value can reflect theglobal importance of the node on the streamlevel, which can be easily obtained by runningthe PageRank algorithm on the BINet.?
C(v): the context words of node v defined inSection 3.2, indicating the topic information.After scoring nodes in the target BINet, we greed-ily choose a document areaA(d) that covers a set ofnodes whose score is the largest:d?
= arg maxd?D?
?v?A(d)scoreNR(v) (2)where D?
is the document sets in the target streamand scoreNR(v) is the score of node v outputted byNodeRank model.
Document d?
?s first paragraphand its document creation time (DCT) will be usedto generate an event entry for the summary of thetarget stream.
Note that though we do not normal-ize the length of a document in Eq (2), we constrainthe maximum length of a document?s first paragraphis 50 words and will not select the document whosefirst paragraph is longer than 50 words.By repeating this step for k times, we can generatea stream summary with k event entries.
Note thatin order to avoid generating redundant entries in thesummary, we will not choose d?
if its document areaA(d?)
overlaps with the areas of the documents thathave been already chosen as entries.4.2 AreaRankInstead of scoring nodes independently like NodeR-ank, we propose AreaRank model for scoring anarea on the BINet for finding areas that correspondsto the most important news events in the stream.Different from NodeRank where each instance isone node in the BINet, instances are areas on the BI-Net in the AreaRank model, as shown in Figure 4.
Inthis paper, we mainly consider document area A(d)2We use SVMRank (Joachims, 2006).
During training, werandomly sample 50% of negative examples which are used togenerate the training set with positive examples.since we select representative documents as entriesin the summary.As NodeRank, we first label reference BINet us-ing the reference summary.
In the AreaRank model,we find the areas on the reference BINet correspond-ing to each event entry in the reference summary andlabel such areas as score 1 (positive).
Formally, fora reference summary E , the positive areas are in thefollowing set:Apos =?ek?E{A|A = Vek} (3)where Vek = {v|v ?
Vr ?
w(v) ?
wek ?
tek ?P(v)} is the set of nodes to which words in ek cor-respond in the reference BINet.We label other document areas that do not over-lap any positive area on the reference BINet as score0.
Then, we use the training data to train AreaRankusing the following features:?
w(A): words of nodes in areaA, indicating thearea?s semantic and topic information.?
pr(A): this feature includes maximum, sumand average of PageRank value of nodes in thearea and sum of top 3 PageRank value of nodesin the area, indicating the area?s general im-portance, which can reflects the impact of theevents corresponding to the area in the stream.?
C(A): context of nodes in area A.
This featureis useful for indicating topical information.In the test phase, we use AreaRank model to scoreall possible document areas on the target BINet.Then, we greedily choose the document area withthe top score to generate an event entry for the sum-mary:d?
= arg maxd?D?scoreAR(A(d)) (4)As NodeRank, d?
?s first paragraph and DCT willbe used to generate an event entry for the streamsummary if d?
?s areaA(d) does not overlap the areasof the documents that have been already selected forgenerating event entries.
The maximum length ofthe first paragraph of a document is 50 words.
Thisstep will be repeated for multiple times for generat-ing event entries of the summary.7884.3 Online stream summarizationAn advantage of the BINet is that it can be incre-mentally updated when new streams arrive, which isuseful for online stream summarization.
Assumingwe have a news stream from time t0 to tk at hand,we can detect word bursts and construct a BINet Gbased on the stream.
When the news stream at tk+1comes, we first detect burst words in the newly arriv-ing data, update the BINet and calculate the PageR-ank value for G(tk+1) which denotes the slice of BI-Net G at time tk+1, which is defined as follows:G(t) = ?V (t), E(t)?where V (t) = {v|t ?
P(v)} and E(t) ={ei,j |ei,j ?
E ?
i ?
V (t) ?
j ?
V (t)}.
Then, wecan apply NodeRank and AreaRank on G(tk+1) togenerate a stream summary at tk+1.5 Experiments and Evaluations5.1 Experiments on Gigaword corpusFor comparison to the previous work, we use thesame data with Ge et al (2015b) (i.e., 2009 and2010 APW and XIN news stories in English Giga-word (Graff et al, 2003)) as a news stream.
We de-tect burst words using Kleinberg algorithm (Klein-berg, 2003), which models word burst detection asa burst state decoding problem.
In total, there are140,557 documents in the dataset.Topic #Entry #Entry in corpusDisaster 35 28Sports 19 12Politics 8 5Military 14 13Comprehensive 85 64Table 2: The number of event entries in the reference sum-maries.
The third column is the number of event entries exclud-ing those events that do not appear in the corpus.We removed stopwords and used StanfordCoreNLP (Manning et al, 2014) to do lemmatiza-tion and named tagging, and built BINets on thenews stream during 2009 and 2010 separately.
Onthe 2009 news stream, there are 31,888 nodes and833,313 edges while there are 32,997 nodes and825,976 edges on the 2010 stream.Ge et al (2015b) used manually edited eventchronicles of various topics on the web3 during 20093http://www.mapreport.com; http://www.infoplease.com;as reference summaries for summarizing the newsstream during 2010.
The information of the refer-ence summaries is summarized in Table 2.
In evalu-ation, they pooled entries in stream sumamries gen-erated by various approaches, annotated each entrybased on the reference summary and the manuallyedited event chronicles on the web, and used preci-sion@K to evaluate the quality of top K event entriesin a stream summary instead of using ROUGE (Lin,2004) because news stream summaries are event-centric.In this paper, we adopt the same evaluation settingand use the same reference summaries and the anno-tations with our previous work (Ge et al, 2015b) toevaluate our summaries?
quality.
For the event en-tries that are not in Ge et al (2015b)?s annotations,we have 3 human judges annotate them accordingto the previous annotation guideline and consider anentry correct if it is annotated as correct by at least 2judges.We evaluate our approaches by comparing to Geet al (2015b)?s approach and the baselines in theirwork:?
RANDOM: this baseline randomly selects doc-uments in the dataset as event entries.?
NB: this baseline uses Naive Bayes to clus-ter documents for event detection and ranks theclusters based on the combination score of top-ical relevance and the event impact (i.e., eventcluster size).
The earliest documents in the top-ranked clusters are selected as entries.?
B-HAC: similar to NB except that BurstVSMrepresentation (Zhao et al, 2012) is used forevent detection using Hierarchical Agglomera-tive Clustering algorithm.?
TAHBM: similar to NB except that the state-of-the-art event detection model (TaHBM) pro-posed by Ge et al (2015b) is used for event de-tection.?
Ge et al (2015b): the state-of-the-art streamsummarization approach which used TaHBMto detect events and L2R model to rank events.Note that we did not compare with previous multi-document summarization models because the goaland setting of stream summarization are differentfrom multi-document summarization, as Section 1https://en.wikipedia.org/wiki/2009789sports politics disaster military comprehensiveP@50 P@100 P@50 P@100 P@50 P@100 P@50 P@100 P@50 P@100Random 0.02 0.08 0 0 0.02 0.04 0 0 0.02 0.03NB 0.08 0.12 0.18 0.19 0.42 0.36 0.18 0.17 0.38 0.31B-HAC 0.10 0.13 0.30 0.26 0.50 0.47 0.30 0.22 0.36 0.32TaHBM 0.18 0.15 0.30 0.29 0.50 0.43 0.46 0.36 0.38 0.33Ge et al (2015b) 0.20 0.15 0.38 0.36 0.64 0.53 0.54 0.41 0.40 0.33BINet-NodeRank 0.24 0.20 0.38 0.30 0.54 0.51 0.48 0.43 0.36 0.33BINet-AreaRank 0.40 0.33 0.40 0.34 0.80 0.62 0.50 0.49 0.32 0.30Table 3: Performance of various approaches on stream summarization on five topics.discussed.
Moreover, these two tasks differ greatlyin the data size and redundancy identification mech-anism.
Therefore, it is not feasible to directly com-pare multi-document summarization models to ourapproaches unless they are adapted for our setting.The results are shown in Table 3.
It can be clearlyobserved that BINet-based approaches outperformbaselines and perform comparably to the state-of-the-art model on generating the summaries on mosttopics: AreaRank achieves the significant improve-ment over the state-of-the-art model on sports anddisasters, and performs comparably on politics andmilitary and NodeRank?s performance achieves thecomparable performance to previous state-of-the-artmodel though it is inferior to AreaRank on most top-ics.
Among these five topics, almost all models per-form well on disaster and military topics becausedisaster and military reference summaries have moreentries than the topics such as politics and sportsand topics of event entries in the summaries are fo-cused.
The high-quality training data benefits mod-els?
performance especially for AreaRank which ispurely data-driven.
In contrast, on sports and pol-itics, the number of entries in the reference sum-maries is small, which results in weaker supervi-sion and affect the performance of models.
It is no-table that AreaRank does not perform well on gen-erating the comprehensive summary in which top-ics of event entries are miscellaneous.
The reasonfor the undesirable performance is that the topics ofevent entries in the comprehensive reference sum-mary are not focused, which results in very few ref-erence (positive) examples for each topic.
As a re-sult, the miscellaneousness of topics of positive ex-amples makes them tend to be overwhelmed by largenumbers of negative examples during training themodel, leading to very week supervision and mak-ing it difficult for AreaRank to learn the patternsModel Features Precision@100NodeRankw(v) 0.18w(v)+pr(v) 0.22w(v)+C(v) 0.46w(v)+pr(v)+C(v) 0.51AreaRankw(A) 0.25w(A) + pr(A) 0.34w(A)+C(A) 0.58w(A)+pr(A)+C(A) 0.62Table 4: Ablation test on feature combination for generatingdisaster summaries.Model Topic Irrelevant Minor RedundantNodeRankdisaster 35.3% 64.7% 0sports 21.3% 77.5% 1.3%comprehensive - 100% 0AreaRankdisaster 34.2% 63.1% 2.6%sports 7.5% 91.1% 1.5%comprehensive - 100% 0Table 5: Error analysis of BINet-based approaches.of positive examples.
Compared to AreaRank, thestrategy of selecting documents for generating evententries in other baselines and NodeRank use more orless heuristic knowledge, which makes these modelsperform stably even if the training examples are notsufficient.We conducted an ablation test to study the effectsof features on generating summaries in our model.Table 4 shows the performance of models using vari-ous feature combination on generating disaster sum-maries.
In both NodeRank and AreaRank models,PageRank features enhance the models that only useword features of nodes, demonstrating the effects ofglobal importance analysis on the stream level.
Con-text features are also useful for improving the resultsbecause words (both burst and non-burst words) incontext can help the model learn the preference oftopics and styles from the reference summary.We conducted error analysis for NodeRank andAreaRank, shown in Table 5.
Among topically irrel-evant, minor and redundant event entries, minor (i.e.,790Model Module Run time Can be run in parallelBINetburst detection 14ms per word YesBINet construction 213.88s on 1-year news PartiallyPageRank 1.36s per iteration NoRanking negligible NoGe et al (2015b) Event detection 1,018s per iteration NoRanking negligible NoTable 6: Run time of BINet-based approaches and Ge et al (2015b)?s approachtrivial) event entries that are not important enough tobe included in the stream summary account for themajority of errors for both models.
This is becauseit is difficult to distinguish these trivial events sincethe corpus we used as a text stream is not as ideal asthe assumption that the more important events, themore times they are reported.
As shown in Table 2,many entries in the reference summaries even do notappear or burst in our corpus because the Gigawordcorpus used is just a small sample of news streamduring the period.
As a result, the importance fea-tures (e.g., PageRank value) in our ranking model donot work very well for distinguishing trivial events.At last, we tested the run time of our BINet ap-proach and compare to the state-of-the-art modelproposed by Ge et al (2015b) in terms of efficiency.The results are shown in Table 6.
The run time istested on a workstation with Intel Xeon 3.5 GHzCPU and 64GB RAM.
The efficiency of our modelis much better than Ge et al (2015b)?s approachwhose event detection model takes much time to it-erate thousands of times for Gibbs sampling.
Formemory cost, the peak memory cost of our BINet-based approaches is 5GB while Ge et al (2015b)?sapproach needs more than 10GB memory to run theevent detection model and thus cannot work on alarge dataset.5.2 Experiments on a real-time news streamTo evaluate our approaches in a real setting, we cre-ate a benchmark dataset4 containing 7.9 million En-glish news stories (without exact duplication) dur-ing Feb 5 to Mar 31, 2015, collecting from Bingnews portal5.
On average, there are approximately150,000 news documents per day.We applied our BINet-based approaches (i.e.,4The dataset and the gold standard are available athttp://getao.github.io5https://www.bing.com/newsModels Disaster AttackRandom 0.012 0.019Online-B-HAC 0.096 0.138NodeRank 0.111 0.153AreaRank 0.182 0.157Table 7: MRR of BINet-based approaches on generating sum-maries for the real-time news stream.NodeRank and AreaRank) on the real-time stream.Specifically, we used news stream during Feb 5 toMar 23 for training to generate news summaries forevery day during Mar 24 to Mar 30 in an online fash-ion.
This is a practical setting and can be useful forautomatically generating headline news every day.Daily news summaries in Current Event Portal6 atWikipedia are used as reference summaries for train-ing and gold standard for evaluating our approaches.In this paper, we tested on generating summarieson Disaster and accident (Disaster) and Armed con-flicts and attacks (Attack) topics.
Instead of evaluat-ing Precision@K as we did on the Gigaword corpuswhich is a small dataset, we used Mean ReciprocalRank (MRR) which is defined as follows to see theranking position of event entries of the gold standardin the summaries generated by our approaches:MRR =?t?Ttest(?ek?E(t)gold1rank(t)ek)?t?Ttest |E(t)gold|(5)where E(t)gold is the gold standard summaries at timet, Ttest is the period of test set (i.e., Mar 24 to Mar30) and rank(t)ek is the highest rank of an event entryek of the gold standard summary in our summaryat t. A high MRR means the event entries of goldstandard tend to be ranked at top positions in ourgenerated summaries.
The evaluation is conductedmanually.Table 7 shows the performance of BINet-based6https://en.wikipedia.org/wiki/Portal:Current events/791approaches on the real-time news stream.
TheBINet-based approaches achieve better results thanthe online version of B-HAC model on both topics,demonstrating the advantages of the BINet represen-tation.
It is also notable that AreaRank performsbetter than NodeRank because it scores a documentarea as a whole by taking into account various in-formation of the area.
For AreaRank, MRR on thedisaster topic is about 0.2, meaning that the averageranking position of gold standard event entries is 5,which is a promising result and shows our approachcan be effective to find key information.
More im-portantly, it only takes 500 seconds to build a BINetand 388 seconds to run PageRank for 1,000 itera-tions for global importance analysis on the 7.9 mil-lion documents while other methods in Table 3 evencannot be applied on the stream because they cannothandle so large scale of data or work in an onlinefashion, which is why we did not compare to themin this setting.6 Related WorkStream summarization is not a hot topic in NLPcommunity.
Despite the related work that studiescorpus summarization of research papers (Sipos etal., 2012), Ge et al (2015b) is the only work ex-actly dealing with the news stream summarizationchallenge.
However, they studied the problem on astatic timestamped corpus instead of on a dynamictext stream and their proposed pipeline-style ap-proach cannot be applied on a real-time text streamdue to high complexity in time and space.
Otherprevious work dealing with stream data is mainlyfocused on topic and event detection (Yang et al,1998; Swan and Allan, 2000; Allan, 2002; He et al,2007; Sayyadi et al, 2009; Sakaki et al, 2010; Zhaoet al, 2012; Ge et al, 2015a), dynamic language andtopic modelling (Blei and Lafferty, 2006; Iwata etal., 2010; Wang et al, 2012; Yogatama et al, 2014),incremental (temporal) summarization and timelinegeneration for one major news event (Allan et al,2001; Hu et al, 2011; Yan et al, 2011; Lin et al,2012; Li and Li, 2013; Kedzie et al, 2015; Tran etal., 2015; Yao et al, 2016), a sports match (Taka-mura et al, 2011) or users on the social network (Liand Cardie, 2014).Different from traditional single and multi-document summarization (Carbonell and Goldstein,1998; Lin, 2004; Erkan and Radev, 2004; Con-roy et al, 2004; Li et al, 2007; Wan and Yang,2008; Chen and Chen, 2012; Wan and Zhang, 2014)whose focus is to select important sentences, the fo-cus of stream summarization is to select representa-tive documents referring to important news events.The novel paradigm focuses on the summarizationproblem in the big data age and is useful for manyapplications.7 Conclusions and Future workIn this paper, we study the news stream summa-rization problem by proposing a novel text streamrepresentation ?
Burst Information Networks andpresenting two summarization models based on it.The proposed approaches can efficiently generatehigh-quality summaries, achieving the state-of-the-art performance.
Moreover, the experiments on ourcreated benchmark dataset showed our approach canbe effectively applied on the real-time news streamfor finding key information, demonstrating its po-tential values for many real-world applications (e.g.,personalized headline news recommendation).In the future, we plan to generalize the streamsummarization problem to various streams such associal (e.g., Twitter), image (e.g., Imgur) and evenvideo streams (e.g., Youtube), which would yieldmany interesting and practical applications (Lu etal., 2016) to deal with the information overload chal-lenge in the big data era.AcknowledgmentsWe would like to thank the anonymous reviewers fortheir helpful comments.
We also want to speciallythank Prof. Heng Ji for her valuable suggestionsand discussion on the early ideas of this work.
Thiswork is supported by the National Key Basic Re-search Program of China (No.2014CB340504) andthe National Natural Science Foundation of China(No.61375074,61273318).
The contact author isZhifang Sui.ReferencesJames Allan, Rahul Gupta, and Vikas Khandelwal.
2001.Temporal summaries of new topics.
In SIGIR.792James Allan.
2002.
Topic detection and tracking: event-based information organization, volume 12.
SpringerScience & Business Media.David M Blei and John D Lafferty.
2006.
Dynamic topicmodels.
In ICML.Jaime Carbonell and Jade Goldstein.
1998.
The use ofmmr, diversity-based reranking for reordering docu-ments and producing summaries.
In SIGIR.Chien Chin Chen and Meng Chang Chen.
2012.
Tscan:A content anatomy approach to temporal topic sum-marization.
Knowledge and Data Engineering, IEEETransactions on, 24(1):170?183.John M Conroy, Judith D Schlesinger, Jade Goldstein,and Dianne P Oleary.
2004.
Left-brain/right-brainmulti-document summarization.
In DUC.Gu?nes Erkan and Dragomir R Radev.
2004.
Lexrank:Graph-based lexical centrality as salience in text sum-marization.
Journal of Artificial Intelligence Re-search, pages 457?479.Tao Ge, Wenzhe Pei, Baobao Chang, and Zhifang Sui.2015a.
Distinguishing specific and daily topics.
InAPWeb.Tao Ge, Wenzhe Pei, Heng Ji, Sujian Li, Baobao Chang,and Zhifang Sui.
2015b.
Bring you to the past: Auto-matic generation of topically relevant event chronicles.In ACL.David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda.2003.
English gigaword.
Linguistic Data Consortium,Philadelphia.Qi He, Kuiyu Chang, and Ee-Peng Lim.
2007.
Us-ing burstiness to improve clustering of topics in newsstreams.
In ICDM.Po Hu, Minlie Huang, Peng Xu, Weichang Li, Adam KUsadi, and Xiaoyan Zhu.
2011.
Generatingbreakpoint-based timeline overview for news topic ret-rospection.
In ICDM.Tomoharu Iwata, Takeshi Yamada, Yasushi Sakurai, andNaonori Ueda.
2010.
Online multiscale dynamic topicmodels.
In KDD.Thorsten Joachims.
2006.
Training linear svms in lineartime.
In SIGKDD.Chris Kedzie, Kathleen McKeown, and Fernando Diaz.2015.
Predicting salient updates for disaster summa-rization.Jon Kleinberg.
2003.
Bursty and hierarchical structurein streams.
Data Mining and Knowledge Discovery,7(4):373?397.Jiwei Li and Claire Cardie.
2014.
Timeline generation:Tracking individuals on twitter.
In WWW.Jiwei Li and Sujian Li.
2013.
Evolutionary hierarchicaldirichlet process for timeline summarization.
In ACL.Sujian Li, You Ouyang, Wei Wang, and Bin Sun.
2007.Multi-document summarization using support vectorregression.
In DUC.
Citeseer.Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang, YangChen, and Tao Li.
2012.
Generating event storylinesfrom microblogs.
In CIKM.Chin-Yew Lin.
2004.
Rouge: A package for auto-matic evaluation of summaries.
In Text summarizationbranches out: Proceedings of the ACL-04 workshop,volume 8.Di Lu, Clare Voss, Fangbo Tao, Xiang Ren, Rachel Guan,Rostyslav Korolov, Tongtao Zhang, Dongang Wang,Hongzhi Li, Taylor Cassidy, Heng Ji, Shih-fu Chang,Jiawei Han, William Wallace, James Hendler, Mei Si,and Lance Kaplan.
2016.
Cross-media event extrac-tion and recommendation.
In NAACL Demo Session.Christopher D Manning, Mihai Surdeanu, John Bauer,Jenny Rose Finkel, Steven Bethard, and David Mc-Closky.
2014.
The stanford corenlp natural languageprocessing toolkit.
In ACL (System Demonstrations),pages 55?60.Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.2010.
Earthquake shakes twitter users: real-time eventdetection by social sensors.
In WWW.Hassan Sayyadi, Matthew Hurst, and Alexey Maykov.2009.
Event detection and tracking in social streams.In ICWSM.Ruben Sipos, Adith Swaminathan, Pannaga Shivaswamy,and Thorsten Joachims.
2012.
Temporal corpussummarization using submodular word coverage.
InCIKM.Russell Swan and James Allan.
2000.
Automatic gener-ation of overview timelines.
In SIGIR.Hiroya Takamura, Hikaru Yokono, and Manabu Oku-mura.
2011.
Summarizing a document stream.
InAdvances in Information Retrieval, pages 177?188.Springer.Giang Tran, Mohammad Alrifai, and Eelco Herder.
2015.Timeline summarization from relevant headlines.
InAdvances in Information Retrieval.Xiaojun Wan and Jianwu Yang.
2008.
Multi-documentsummarization using cluster-based link analysis.
InSIGIR.Xiaojun Wan and Jianmin Zhang.
2014.
Ctsum: extract-ing more certain summaries for news articles.
In SI-GIR.Chong Wang, David Blei, and David Heckerman.
2012.Continuous time dynamic topic models.
arXivpreprint arXiv:1206.3298.Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,Xiaoming Li, and Yan Zhang.
2011.
Evolution-ary timeline summarization: a balanced optimizationframework via iterative substitution.
In SIGIR.Yiming Yang, Tom Pierce, and Jaime Carbonell.
1998.A study of retrospective and on-line event detection.In SIGIR.793Jin-ge Yao, Feifan Fan, Wayne Xin Zhao, Xiaojun Wan,Edward Chang, and Jianguo Xiao.
2016.
Tweet time-line generation with determinantal point processes.
InAAAI.Dani Yogatama, Chong Wang, Bryan R Routledge,Noah A Smith, and Eric P Xing.
2014.
Dynamiclanguage models for streaming text.
Transactions ofthe Association for Computational Linguistics, 2:181?192.Wayne Xin Zhao, Rishan Chen, Kai Fan, Hongfei Yan,and Xiaoming Li.
2012.
A novel burst-based textrepresentation model for scalable event detection.
InACL.794
