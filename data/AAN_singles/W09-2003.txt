Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 17?23,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsUnderstanding EggcornsSravana ReddyDepartment of Computer ScienceThe University of Chicagosravana@cs.uchicago.eduAbstractAn eggcorn is a type of linguistic error wherea word is substituted with one that is seman-tically plausible ?
that is, the substitution isa semantic reanalysis of what may be a rare,archaic, or otherwise opaque term.
We builda system that, given the original word and itseggcorn form, finds a semantic path betweenthe two.
Based on these paths, we derive a ty-pology that reflects the different classes of se-mantic reinterpretation underlying eggcorns.1 IntroductionThe term ?eggcorn?
was coined in 2003 by Geof-frey Pullum (Liberman, 2003) to refer to a certaintype of linguistic error where a word or phrase isreplaced with one that is phonetically similar andsemantically justifiable.
The eponymous example isacorn?
eggcorn, the meaning of the latter form be-ing derived from the acorn?s egg-like shape and thefact that it is a seed (giving rise to corn).
These er-rors are distinct from mere misspellings or mispro-nunciations in that the changed form is an alternateinterpretation of the original.The reinterpretation may be related to either theword?s perceived meaning or etymology (as in thecase of acorn), or some context in which the word iscommonly used.
In this sense, eggcorns are similarto folk etymologies ?
errors arising from the misin-terpretation of borrowed or archaic words ?
with thedifference being that the latter are adopted by an en-tire culture or linguistic community, while eggcornsare errors made by one or more individual speakers.The formation of eggcorns and folk etymolo-gies, mistakes though they are, involves a creativeleap within phonetic and semantic constraints (muchlike what is required for puns or certain classes ofjokes).
Eggcorns range from simple reshapings offoreign words (paprika ?
pepperika) and substitu-tions from similar domains (marshal?
martial), tothe subtly clever (integrate?
intergrade), the tech-nological (sound bite ?
sound byte), or the funny(stark-raving mad?
star-craving mad).
The sourceof reinterpretation may be a weak imagined link(wind turbine?
wind turban), or an invented myth(give up the ghost?
give up the goat1).
And often,it is not clear what the exact link is between the de-rived and the original forms, although it is usuallyobvious (to the human eye) that there is a connec-tion.This paper explores some ways of automaticallytracing the link between a word and its eggcorn.In reality, we are chiefly concerned with comput-ing the connections between a word and its rein-terpreted form.
Such pairs may also occur as folketymologies, puns, riddles, or get used as a poeticdevice.
However, we use eggcorns as a testbedfor three main reasons: there are a number of doc-umented examples, the reanalyses are accidental(meaning the semantic links are more unpredictableand tenuous than in the cases of deliberate reshap-ings), and the errors are idiosyncratic and relativelymodern ?
and hence have not been fossilized in thelexicon ?
making them transparent to analysis (asopposed to many folk etymologies and other histor-ical errors).
That said, much of the work describedhere can be potentially applied to other instances ofsemantic reinterpretation as well.1http://eggcorns.lascribe.net/english/714/goat/17The first part of the paper describes an algorithm(the ?Cornalyzer?)
for finding a semantic path be-tween the original and reinterpreted forms of aneggcorn pair.
We then proceed to use the resultsof this algorithm to cluster the eggcorn examplesinto 5 classes, with a view to learning a typologyof eggcorns.2 Related WorkOne work related to this area (Nelken and Ya-mangil, 2008) uses Wikipedia to automatically mineeggcorns by searching for pairs of phonemicallysimilar words that occur in the same sentence con-text in different revisions.
However, the mined ex-amples are reported to contain many false positivessince the algorithm does not include a notion of se-mantic similarity.Folk etymologies, the closest cousin to eggcorns,have been studied from a linguistic point of view, in-cluding some of the same questions we tackle here(only, not from a computational side) ?
how is annew word derived from the original, and what arethe different categories of folk etymologies?
(Rund-blad and Kronenfeld, 1998), (Scholfield, 1988).
Tothe best of our knowledge, there has been no pre-vious work in inducing or computationally under-standing properties of neologisms and errors de-rived through misinterpretation.
However, there isa substantial literature on algorithmic humor, someof which uses semantic relationships ?
(Stock andStrapparava, 2006), (Manurung et al, 2008), amongothers.3 DataThe list of eggcorns is taken directly from theEggcorn Database2 as of the submission date.
Toassure soundness of the data, we include only thoseexamples whose usage is attested and which are con-firmed to be valid and contemporary reanalyses3,giving a total of 509 instances.
Table 1 shows a sam-ple of the data.Every example can be denoted by the tuple(w, e, c) where c is the list of obligatory contexts in2http://eggcorns.lascribe.net/3In other words, all examples that are classified as ?ques-tionable?
(or otherwise indicated as being questionable), ?not aneggcorn?, ?citational?
or ?nearly-mainstream?
are eliminated.Table 1: A few eggcorns.
?X?
can be replaced for w ore to give the original form in context, or the eggcorn incontext respectively.Original Changed Contextform w form e cbludgeon bloodgeon Xfew view name a Xentree ontray Xpraying preying X mantisjaw jar X-droppingdissonance dissidence cognitive Xwhich the reanalysis takes place, w is the originalform, and e is the modified (eggcorned) form.The Cornalyzer uses WordNet (Fellbaum, 1998)version 3.0, including the built-in morphologicaltools for lemmatization and dictionary definitions4.4 Automated Understanding of EggcornGenerationBroadly speaking, there are two types of eggcorns:1.
Ones where e or a part of e is semantically re-lated to the original word w (lost ?
loss in?no love lost?)
or the context c (pied ?
pipein ?pied-piper?).2.
Eggcorns where e is related to an image or ob-ject that is connected to or evoked by the origi-nal (like ?song?
in lip-sync?
lip-sing).For the first, a database of semantic relations be-tween words (like WordNet) can be used to find asemantic connection between w and e. The sec-ond type is more difficult since external knowledgeis needed to make the connection.
To this end, wemake use of the ?glosses?
?
dictionary definitions ofword senses ?
included in WordNet.
For instance,the ?lip-sing?
eggcorn is difficult to analyze usingonly semantic relations, since neither ?sync?
nor ?lip?are connected closely to the word ?sing?.
However,the presence of the word song in the gloss of lip-sync:move the lips in synchronization(with recorded speech or song)4From http://wordnet.princeton.edu/18makes the semantic connection fairly transparent.The Cornalyzer first attempts to analyze aneggcorn tuple (w, e, c) using semantic relations(?4.1).
If no sufficiently short semantic path isfound, the eggcorn is presumed to be of the secondtype, and is analyzed using a combination of seman-tic relations and dictionary glosses (?4.2).4.1 Analysis using Word Relations4.1.1 Building the Semantic GraphWordNet is a semantic dictionary of English, con-taining a list of synsets.
Each synset consists of aset of synonymous words or collocations, and its re-lations (like hypernymy, antonymy, or meronymy)with other synsets.
The dictionary also includes lex-ical relations ?
relations between words rather thansynsets (for instance, a pertainym of a noun is anadjective that is derived from the noun).WordNet relations have been used to quantify se-mantic similarity between words for a variety of ap-plications (see Budanitsky and Hirst (2001) for a re-view of similarity measures).
The Cornalyzer usesthe same basic idea as most existing measures ?
find-ing the shortest path between the two words ?
withsome modifications to fit our problem.We adopt the convention that two words w1 andw2 have the relation R if they are in different synsetsS1 and S2, and R(S1, S2) is true.
We also define twonew lexical relations that are not directly indicatedin the dictionary: w1 and w2 are synonyms if theyare in the same synset, and homographs if they haveidentical orthographic forms and lexical categoriesbut are in different synsets.
5This relational network can hence be used to de-fine a graph Gs over words, where there is an edgeof type tR from w1 to w2 if R(w1, w2) holds.
Someof the relations in WordNet (like antonymy) are ig-nored, either because they invert semantic similarity,or are not sufficiently informative.
Table 2 summa-rizes the relations used.This graph can be used to find the semantic re-lationships between an original word w and its5This paper uses ?word?
to include sense ?
i.e, ?bank?
as inslope beside a body of water and ?bank?
as in financial institu-tion are distinct.
When required for disambiguation, the Word-Net sense number, which is the index of the sense in the list ofthe word?s senses, is added in parenthesis; e.g.
bank (2) for thefinancial institution sense.Table 2: WordNet relations used to build the semanticgraph.Relation Parts of Reflexive ExampleSpeech RelationSynonym (N, N) Synonym (forest, wood)(V, V) (move, displace)(Adj, Adj) (direct, lineal)(Adv, Adv) (directly, at once)Homograph (All, All) Homograph (call [greet],call [order])Hypernym (V, V) Troponym/ (move, jump)(N, N) Hyponym (canine, fox)Meronym (N, N) Holonym (forest, tree)Has Instance (N, N) Instance Of (city, Dresden)Cause (V, V) Caused by (affect, feel)Entails (V, V) not specified (watch, look)Similar To (Adj, Adj) Similar To (lucid, clear)Related (V, V) Related(Adj, Ad) (few, some)Same Group (V, V) Same Group (displace, travel)Has Attribute (Adj, N) Attribute Of (few, numerousness)Derivational (N, V) Derivational (movement, move)Relation (N, Adj) Relation (movement, motional)(V, Adj) (move, movable)Pertainym (Adj, N) not specified (direct, directness)(Adv, Adj) (directly, direct)eggcorn form e, if both forms are in the dictionary,and there exists a path from w to e. However, it isoften the case that e or w are not in the dictionary,or that a path does not exist.
This could be becauseone of the forms is an inflected form or compound,or that some substring of e ?
rather than the wholeword or collocation ?
is the reinterpreted segment.It is also essential to consider the strings in c, sincemany eggcorns result from semantic reinterpretationof the contexts.Hence, three new non-semantic relations are de-fined: w1 is a substring of w2 if the orthographicform of w1 is a substring of that of w2, and w1 andw2 are contextually linked if they occur in the samecollocation or compound.
If w2 can be derived fromw1 using WordNet?s lemmatizer, w2 is an inflectedform of w1.A new graph Ge is constructed by adding edgesof types tsubstring, tcontext, and tinflect to Gs.
Forall eggcorn tuples (w, e, c):1.
If e or w are not in the dictionary, add them toGe as a vertex2.
Add edges of type inflect between e and its baseform.3.
Add edges of type substring from e to every19substring of length ?
3 that is in the dictionary(except those substrings which are base formsof e), and edges of type supstring in the otherdirection.4.
Extract a set of ?context words?
from c by split-ting it along spaces and hyphenation.
Selectthose words which are in the dictionary.5.
Add edges of type context from w and e to eachextracted context word.For example, given the data in table 1, the follow-ing vertices and edges will be added to Ge:Vertices bloodgeon, ontray, preying, prayingSubstring edges (bloodgeon, blood), (bloodgeon, loo),(bloodgeon, eon), (view, vie), (entree, tree), (ontray,ray), (ontray, tray)Superstring edges above edges in the other directionInflectional edges (preying, prey), (praying, pray).These edges are bidirectional.Context edges (few, name), (view, name), (few, a),(view, a), (praying, mantis), (preying, mantis), (jaw,dropping), (jar, dropping), (dissonance, cognitive),(dissidence, cognitive).
These edges are also bidi-rectional.4.1.2 Tracing the Semantic PathGiven the semantic graph, our working assump-tion is that e is generated from w by following theshortest path from w to e (denoted by P (w, e, c)).1.
If w and e are both in the dictionary, findP1(w, e) = the shortest path from w to e in Gs2.
Find P2(w, e, c) = the shortest path using sub-strings of e and/or c in Ge(Since the edges are unweighted, the shortest pathfrom w to e is found simply by performing breadth-first search starting at w.)P (w, e, c) is simply the shorter of P1(w, e) (if itexists) and P2(w, e, c).
Note that there may be sev-eral shortest paths, especially since words that aresynonymous have almost the same incident semanticedges.
Since the candidate shortest paths generallydo not differ much from one another (as far as theirsemantic implications), an arbitrary path is chosento be P .Table 3 shows the paths found by the algorithmfor some eggcorns.4.2 Analysis using Dictionary DefinitionsAs described in ?4, the source of many eggcornsis knowledge external to the original word or con-texts through some concept or object suggested bythe original.
In such cases, a semantic network willnot suffice to find the reinterpretation path.
One pos-sible way of accessing the additional information isto search for w and e in a large corpus, and extractthe key words that appear in conjunction with theseforms.However, filtering and extracting the represen-tative information can quickly become a complexproblem beyond the scope of this paper.
Hence, as afirst approximation, we use the dictionary definitions(glosses) that accompany synsets in WordNet.
Tooptimize efficiency and to avoid having noise addedby the definitions, the Cornalyzer only resorts to thisstep if a sufficiently short path ?
that is, a path oflength?
k for some threshold k ?
is not found whenonly using word relations.
(The results suggest 7as a good threshold, since most of discovered pathsthat are longer than 7 tend not to reflect the semanticrelationships between the eggcorn and the originalform.
)Every gloss from all senses of a lexical item6 x(for all x in the dictionary) is first tokenized, andpunctuation stripped.
All tokens are stemmed usingthe built-in lemmatizer.
Only those tokens t that arealready present as vertices in Ge are taken into con-sideration.
However, it should be clear that not alltokens t are equally relevant to x.
For instance, con-sider one gloss of the noun ?move?
:the act of changing location from oneplace to anotherwhich gives the tokens act, changing, location,one, place, another.
Clearly, the tokens changing,location, and place rank higher than the others interms of how indicative they are of the meaning ofthe noun.6A lexical item is a word independent of sense, e.g, allsenses of ?bank?
constitute a single lexical item.20Table 3: A sample of semantic similarity paths.
x R??
y means ?y is an R of x?.
When relevant, WordNet sensenumbers are indicated.Eggcorn tuple Path from word to eggcorn(word, eggcorn, context)(mince, mix, ?X words?)
mince hypernym????????
change hyponym???????
mix(few, view, ?name a X?)
few deriv????
fewness hypernym????????
number hypernym????????
amounthypernym????????
magnitude hyponym???????
extent hyponym???????
scope hyponym???????
view(dissonance, dissidence, dissonance synonym???????
disagreement (1) homograph????????
disagreement (3)cognitive X) hyponym???????
dissidence(ado, [to-do, to do], [?much X ado synonym???????
stir (3) homograph????????
stir (1) hypernym????????
to-doabout nothing?, ?without further X?
])(jaw, jar, X-dropping) jaw context??????
dropping inflect????
?drop hypernym???????
?displace hyponym??????
?jar(ruckus, raucous, X) ruckus homograph????????
din deriv????
cacophonous similar?????
?raucous(segue, segway, X) segue hypernym????????
passage (1) homograph????????
passage (3) hypernym???????
?way supstring???????
segwayOne way of reflecting these distinctions in theCornalyzer is to weight these terms appropriately,with something resembling the TF-IDF (Salton andBuckley, 1988) measure used in information re-trieval.
Let tf(t, x) = the frequency of the to-ken t in the glosses of x, and idf(t) = log Ndf(t)where N = the number of lexical items in the dic-tionary and df(t) = the number of lexical itemsin the dictionary whose glosses contain t. DefineW (t, x) = tf(t, x) ?
idf(t).A new graph Gd is constructed from Ge by addingedges of type hasdef from every lexical item x totokens t in its glosses with the edge-weight 1 +1/W (t, x), and reflexive edges of type indef fromt to x with the same weight.
All existing edges inthe original graph Ge are assigned the weight 1.The semantic path from w to e is found by theprocess similar to what was described in ?4.1.2:first find P1(w, e) and P2(w, e, c) as well asP3(w, e, c) = the shortest path from w to e in Gd,and let P (w, e, c) be the shortest of the three.
SinceGd has weighted edges, the shortest path P3 is com-puted using Dijkstra?s algorithm.Dictionary-definition-based paths P2 for someeggcorns are shown in Table 4.
The shortest P2 pathsare also shown for comparison.
The P3 paths gener-ally appear to be closer to a human judgment of whatthe semantic reinterpretation constitutes.
In the caseof (bludgeon?
bloodgeon), for example, P2 showsno indication of the key connection (bleeding due tobeing bludgeoned), whereas P3 captures it perfectly.Of the 509 eggcorns, paths were found for 238instances by using only Gs or Ge as the relationalgraph.
Paths for a total of 372 eggcorns were foundwhen using dictionary glosses in the graph Gd.5 From Generation to TypologyA quick glance at tables 3 and 4 shows that the pathsvary in shape and structure: some paths move upand down the hypernym/homonym tree, while oth-ers move laterally along synonyms and polysemes;some use no external knowledge, while others makeprimary use of context information and dictionaryglosses.
A natural next step, therefore, is to groupthe eggcorns into some number of classes that rep-resent general categories of semantic reanalysis.
Wecan achieve this by clustering eggcorns based ontheir semantic shortest paths.5.1 Clustering of PathsOne natural choice for a feature space is the set of all24 relations (edge-types) used in Gd.
An eggcorn(w, e, c) is represented as a vector [v1, v2, .
.
.
v24]where vi = the number of times that relation Ri (orthe reflexive relation of Ri) appears in P (w, e, c).These vectors are then clustered using k-means21Table 4: Some semantic paths using dictionary glosses.
As before, x R??
y stands for ?y is an R of x?, and the numbersin parentheses following a lexical item are the WordNet sense numbers corresponding to that word.Eggcorn tuple Path from word to eggcorn(bludgeon, bloodgeon, X) P3 (length 6): bludgeon hypernym????????
hit (3) homograph????????
hit (6) hypernym????????
woundindef?????
gore hypernym????????
blood supstring???????
bloodgeonP2 (length 11): bludgeon hypernym????????
club hypernym????????
stick hypernym????????
implementhypernym????????
instrumentality hypernym????????
artefact hyponym???????
structure hyponym???????
areahyponym??????
?room hyponym??????
?lavatory hyponym???????
loo supstring???????
bloodgeon(entree, [ontray, on-tray], X) P3 (length 4): entree indef?????
meal indef?????
food hasdef?????
tray supstring???????
ontrayP2 (length 8): entree hyponym???????
plate (8) homograph????????
plate (4) hypernym????????
flatwarehypernym????????
tableware hyponym???????
tea set meronym???????
tea tray hypernym????????
traysupstring???????
on-tray(praying, preying, X mantis) P3 (length 6): praying context??????
mantis indef?????
predacious synonym???????
predatory (3)homograph????????
predatory (2) indef?????
prey inflect?????
preyingP2 (length 8): praying context??????
mantis hypernym????????
dictyopterous insecthypernym????????
insect hypernym????????
arthropod hypernym????????
invertebrate hypernym????????
animalhyponym???????
prey inflect?????
preyingand a Euclidean distance metric.
We experimentedwith a few different values of k and found that k =5 produces clusters that are the most semanticallycoherent.5.2 ResultsThe five clusters roughly correspond to the each ofthe following characteristic paths P (w, e, c):1.
Independent of dictionary glosses and of con-text, and mostly contain synonym, homograph,related, or similar to types of edges.2.
Contain several hypernym and hyponym edges.3.
Contain several substring, supstring, and inflector derivational edges.4.
Heavily dependent on context edges.5.
Heavily dependent on dictionary glosses.Eggcorns in these clusters can be interpreted tobe (1) Near-synonyms, (2) Semantic cousins ?
de-riving from a common general concept or entity,(3) Segmentally related ?
being linked by morpho-logical operations, (4) Contextually similar, or (5)Linked by implication ?
deriving from an implicitconcept.A sample of the cluster membership is shown inTable 5.6 DiscussionThis paper presents a procedure for computationallyunderstanding the semantic reanalyses of words.
Weidentified the two general types of eggcorns, andbuilt the appropriate networks overlying the Word-Net graph and dictionary in order to trace the se-mantic path from a word to its eggcorn.An obvious drawback to our method stems fromthe fact that the semantic dictionary is not perfect,or fully reflective of human information.
Similarly,dictionary glosses are a limited source of external in-formation.
It would hence be worth exploring data-driven methods to augment a source like WordNet,such as building a word graph from co-occurrencesin text, or using corpora to derive distributional sim-ilarity measures.The Cornalyzer is only an exploratory first step?
there are a wealth of other possible computa-tional problems related to eggcorns.
Semantic path-finding can be extended to defining some measure ofeggcorn strength or plausibility.
The algorithm canalso be used to mine for new eggcorns ?
a thresh-old or a set of criteria for an ?eggcornish?
path can22Table 5: A look at the clustered eggcorns.Cluster Examples1 (cognitive dissonance?
cognitive dissidence), (ado?
to-do), (slake thirst?
slack thirst),(ruckus?
raucous), (sparkle (protests, etc)?
spark), (poise to do?
pose to do), ...2 (sow wild oats?
sow wild oaks), (name a few?
name a view), (whet, wet),(curb hunger?
curve hunger), (entree?
ontray), (mince words?
mix words), ...3 (utmost?
upmost), (valedictorian?
valevictorian), (quote unquote?
quote on quote),(playwright?
playwrite), (no love lost?
no love loss), (snub?
snob), ...4 (pied piper?
pipe piper), (powerhouse?
powerhorse), (jaw-dropping?
jar-dropping),(sell (something) down the river?
sail (something) down the river), ...5 (renowned, reknowned), (praying mantis?
preying mantis), (expatriate?
expatriot),(skim milk?
skimp milk), (sopping wet?
soaping wet), (pique?
peak), ...be set based on the paths found for known eggcorns,thus helping separate them from false positives (ty-pos and misspellings).Another possible line of work is finding general-izations in pronunciation changes from the original.
?The Eggcorn Database?
website includes a partialcatalogue of phonetic changes like t-flapping andcot/caught merger ?
it would be interesting to see ifsuch patterns and categories can be learnt.
The basicmodel of the Cornalyzer can potentially also be ex-tended to applications in other domains of semanticreanalysis like folk etymologies and puns.AcknowledgmentsWe would like to thank the anonymous reviewers fortheir excellent and insightful comments.ReferencesAlexander Budanitsky and Graeme Hirst.
2001.
Seman-tic distance in wordnet:an experimental, application-oriented evaluation of five measures.
In Proceedingsof the ACL Workshop on WordNet and Other LexicalResources.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge, MA.Mark Liberman.
2003.
Egg corns: folk et-ymology, malapropism, mondegreen, ??
?http://158.130.17.5/ myl/languagelog/archives/000019.html.Ruli Manurung, Graeme Ritchie, Helen Pain, AnnaluWaller, Dave O?Mara, and Rolf Black.
2008.
The con-struction of a pun generator for language skills devel-opment.
Applied Artificial Intelligence, 22:841?869.Rani Nelken and Elif Yamangil.
2008.
MiningWikipedia?s article revision history for training com-putational linguistics algorithms.
In Proceedings ofthe AAAI Workshop on Wikipedia and Artificial Intel-ligence.Gabriella Rundblad and David B Kronenfeld.
1998.Folk-etymology: Haphazard perversion or shrewdanalogy?
In Julie Coleman and Christian Kay, edi-tors, Lexicology, Semantics, and Lexicography.
JohnBenjamins, Manchester.Gerard Salton and Christopher Buckley.
1988.
Termweighting approaches in automatic text retrieval.
In-formation Processing and Management, 24(5):513?523.Phil Scholfield.
1988.
Documenting folk etymologicalchange in progress.
English Studies, 69:341?347.Oliviero Stock and Carlo Strapparava.
2006.
Laughingwith hahacronym, a computational humor system.
InProceedings of the 21st AAAI Conference on ArtificialIntelligence.23
