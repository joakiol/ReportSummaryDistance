The Multimedia Articulation of Answers in a NaturalLanguage Database Query SystemSusan  E. BrennanStanford  Un ivers i tyandHewlet t  Packard  Labs1501 Page  Mi l l  RoadPa lo  A l to ,  CA  94304AbstractThis paper describes a domain independent strategyfor the multimedia rticulation of answers elicited bya natural language interface to database query ap-plications.
Multimedia answers include videodisc im-ages and heuristically-produced complete sentencesin text or text-to-speech form.
Deictic reference andfeedback about the discourse are enabled.
The inter-face thus presents the application as cooperative andconversational.1 Int roduct ionIt is useful to evaluate human-computer communica-tion in light of Grice's cooperative principle and max-ims \[Gri75\].
Recently there has been much interestin a "cooperative response" paradigm for interfacesto database query and expert systems \[Ste87\].
Themost promising strategies in this area of investigationinvolve applying insights gained from psycholinguis-tics research in order to create better conversationalhuman/computer interfaces.
However, inventing ad-equate user modeling and inferencing systems for thispurpose is no easy task, and much of the literatureon the subject describes proposals for systems yetunimplemented or theoretical approaches which maydepend heavily on a particular domain model.
Ourmultimedia rticulator consists of principled solutionswhich have been implemented in a domain indepen-dent manner and which produce answers that are rea-sonably relevant, informative, and conversational instyle.
Such a system makes it possible to begin tostudy users interacting with a question-answering ap-plication.2 System overv iewThe system described here functions as a conversa-tional human/computer interface to database querysystems.
It consists of a natural language front endand a module which articulates multimedia nswers.The system accepts well-formed strings as input;these sentences are interpreted by an HPSG-basedparser \[PS87\] which produces a parse tree.
After fur-ther processing by a semantics module, a pragmaticsprocessor \[BFP87\] and a disambiguator, a logical for-mula in the language NFLT \[CP85\] is produced.
Thisformula is transduced into a database query.
Twodatabase query formats are currently supported: aframe-based representation language, HPRL, and thestandard relational database query language, SQL.Answers returned from the database are then pack-aged appropriately by the articulator for presentationto the user.The two database applications currently supportedare a database of people and equipment (a subsetof which we have proposed as a natural languageevaluation test suite \[FNSW87\]), and a database ofpaintings by 19th century Dutch artist Vincent VanGogh and his contemporaries.
The latter databasewas based on the index to a commercially availablevideodisc \[Nim82\] and augmented from other sources.Both applications can be run on workstations config-ured with or without multimedia output devices.3 Database  answer  fo rmatThe driver of a database query application (i.e.
thedomain dependent part of the system) is responsiblefor returning answers in a list format which consists ofa keyword specifying the type of the answer, followedby the answer itself.
The answer types expected bythe articulator are boolean, number, item, set, quan-tity, and table.In deciding how to package a response, the articu-lator uses the answer type along with additional in-formation provided by the parser which identifies theillocutionary act of a query as imperative, declara-tive, yes/no question, or wh-question.
An answeris presented textually as a single phrase, as a com-plete sentence which parallels the user's query, oras a table.
In addition, depending on answer typeand the system's hardware configuration, an answermay include videodisc images, text-to-speech, iconsand maps.
While a user can request answers in aparticular medium via menus, a default strategy isin place which yields a fairly satisfying style of hu-man/computer interaction.4 Text  answers4.1  S ty leQuestions and answers are a common kind of adja-cency pair in human language use.
The preferredstyle of an answer is often elliptical and shows paral-lelism with the surface syntactic structure of the pre-ceding question \[CC77\].
In addition, lexical choicein the answer is constrained by that in the question.An answer which is articulated using different lexicalentries than its projecting question may lead the userto infer that the system is making a distinction whenit is in fact only using a synonym.Although elliptical answers may be the norm in hu-man/human conversation, the articulator describedhere defaults to "verbose mode"; it responds to mostqueries with complete sentence answers.
The moti-vation for this approach arose when we noticed thatshorter answers were unsatisfying in certain situa-tions.
When additional textual material interveneson the user's screen after the input query is typed inand before the answer appears, and in other caseswhere the user is distracted or not watching thescreen when the textual answer arrives, a short an-swer takes on something of the character of a non-sequitur.
This problem manifested itself in an earlyversion of our system that worked by having userssend queries over the network via electronic mail toa single natural language server which in due timemailed its responses back to the user, and also inthe current system, which returns most answers ina few seconds but can be operated in a mode whichprints modular timing and status information duringprocessing.
Even more unsatisfying was the articula-tion of answers using text-to-speech hardware.
Gen-erated speech is often hard for users to understand\[TRC84\] and in our system, short answers deliveredthis way often failed even to attract a user's atten-tion as information-bearing.
To echo the query au-dibly seemed confusing; what was needed was thecapability to frame the answer in a complete sen-tence based on the query.
The final impetus forthe verbose articulator was our desire to approxi-mate some of the effects that real natural languagegeneration capability might provide in a question-answering human/computer interface, before com-mitting resources to a full-scale natural anguage gen-eration effort.In verbose mode, a sententi~d answer consists sim-ply of a string derived from the formatted atabaseanswer with constituents of the user's original querywrapped around it.
Articulation achieves the dualpurposes of satisfying the user's request for informa-tion while preserving a conversational style of inter-action (figure 1).
It is interesting to compare theseanswers with the kind of paraphrasing capacity thatone finds in some other systems which are commer-cially available (figure 2).To paraphrase a user's query in a form that reflectsthe actual database access method (figure 1) can beextremely helpful in identifying misinterpretations ofthe query.
However, that approach may interfere with2User: Who has a terminal?System: DAN FLICKINGER HAS A TERMINAL.Figure 1: Adjacency pairUser: Who has a terminal?System: Shall I do the following?
Create areport showing the full name andthe manager and the equipment fromthe forms on which the equipmentincludes "TERMINAL"?
"Figure 2: Dialogue from Q&A \[Hen85\]natural interaction by insisting that the user confirmhis or her every conversational move.
Furthermore,whether the system's interpretation of what the usermeant by the query with respect o the database isa correct mapping or not, the user is forced to re-formulate his or her question in a program-like orlogical form.
Such an interface imposes a significantcognitive load on the user.
Presumably, a central mo-tivation for providing a natural anguage interface toa database is to avoid forcing the user to use a for-eign language.
This strategy pays homage to Grice'smaxim of manner, "avoid obscurity of expression".On the other hand, the argument has been madethat separate, non-equivalent representations provid-ing different views of the world should be maintainedby the system \[Spa83\]; each of these views shouldbe available to the user at appropriate times.
Thuslogical paraphrases, desirable in establishing initialsystem credibility, should be available upon specificrequest by the user.4 .2  "Namely"  answersGrice's maxim of quantity for cooperative communi-cation is a reminder that it is frequently desirable toprovide more information in an answer than was lit-erally requested.
For example, when a user asks "Arethere any secretaries?"
the best answer may be not"Yes", but "Yes - namely, X, Y, and Z" (where X,Sentence: How many employees are there?Answer list: (NUMBER 4 (NAMELY {abrams}{chiang} {devito} {browne}))Articulated: THERE ARE 4 EMPLOYEES -NAMELY, IRA ABRAMS, LYNCHIANG, KAT DEVITO, ANDDEREK BROWNE.Figure 3: "Namely" answerY, and Z are the names of the secretaries).
Severalquestion-answering systems have addressed issues ofthis sort \[WMJB83\] \[WJMM82\].
While our systemdoes not explicitly model the user's goals or knowanything about indirect speech acts, it provides ex-tended answers to some queries via a list containingthe keyword namely, which appears as the last itemin the answer list passed to the articulator (figure 3).Extended answer lists are constructed as follows.When an answer is of type number and its cardinal-ity is below a certain threshold, or else when it isboth of type boolean and affirmative, the articulatormakes an additional query to the database which re-turns information for constructing the "namely" an-swer.
This additional information is combined withthe short answer to the user's original query, to cre-ate an extended answer.
In this way we attempt ocomply with Grice's maxims of manner and quan-tity: to "be brief' and to "make your contribution asinformative as is required".4 .3  Verbose  modeVerbose mode works as follows.
Initially, a short an-swer string is created from the formatted list that thedatabase returns.
First, the type keyword is strippedoff the answer list.
Depending on the type, the re-maining short answer list is transformed into a stringwhich is a textual phrase consisting of one of the fol-lowing: a name or names (for type set or item thedatabase is queried and returns appropriate nounsor proper names), a string containing an integer (fortype number), a string containing a number followedby units of measure (for type quantity), or the strings"yes" or "no" (for type boolean).
Set answers areexpanded into coordinated noun phrases with appro-priate punctuation.
If  the type is table, a table isproduced.In constructing the short answers to wh-questions,some simple additional heuristics are used.
First, ifthe short answer string was derived from a null setor null item, the answer is converted from the emptystring to an appropriate string: "nowhere" if the wh-question word is "where", "never" for "when", "no-body's" for "whose", and either "none" or else "no"plus the string corresponding to the modified NPhead for "which", "what" or "how many" phrases.Otherwise, when the answer is not an empty set andthe wh-question word is "whose", " 's" is appendedto the answer.
When "whose" modifies the head ofa noun phrase, the noun phrase is appended to theanswer.Then, once the short answer has been produced, ifthe query is not an imperative (and the answer isnot a table), the input query's parse tree represen-tation is transformed into a template with which toframe the short answer.
Four functions traverse theparse tree and return strings corresponding to con-stituents from the input query: these constituentsare subject, auxiliary verb (if there is one), main verbphrase, and preposition (if the wh-question word iswithin a prepositional phrase or fills a trace in one).An end-of-sentence string is created which contains,simply, terminating punctuation, or else an expandedphrase consisting of "namely," followed by a coor-dinated noun phrase with appropriate punctuation.This expanded phrase is constructed whenever ashort to medium-length namely list is available at theend of an answer list, as shown in figure 3.Finally, the verbose answer string is constructed us-ing one of two strategies: if the wh-question wordis in subject position in the query, the constituentsare positioned in the answer as follows, (the itemsin parentheses may or may not be present): answer(aux-verb) (main-verb-phrase) (preposition) end-of-sentence; if the wh-question word is in non-subjectposition, the positioning is: subject (aux-verb) main-verb-phrase (preposition) answer end-of-sentence.If the query is a declarative or a yes/no question, aboolean answer results.
When a boolean answer is af-firmative, the string "yes," with the modified inputstring appended, is articulated.
For negative booleananswers, if the input string contains an auxiliary verb,Sentence:Answer list:Articulated:Does Ira program?
(BOOLEAN NIL)NO, IRA DOES NOT PROGRAM.Figure 4: NegationSentence:Answer list:Articulated:Sentence:Answer list:Articulated:Are there any consultants?
(BOOLEAN T (NAMELY {WASOW}{SAG}))YES, THERE ARE SOMECONSULTANTS - NAMELY,TOM WASOW AND IVAN SAG.Will any consultants workfor Kat?
(BOOLEAN NIL)NO, NO CONSULTANTS WILL WORKFOR KAT.Figure 5: Some/anythe following sequence is articulated: "No," sub-ject auz-verb "not" main-verb-phrase end-of-sentence(figure 4).
If there is no auxiliary verb in the nega-tive answer, the canned phrase "No, it is not truethat," with the original input string appended, is ar-ticulated.
In addition, a some/any transformation isapplied to yes/no questions.
"Any of" is replaced by"none of" or "some of", depending on whether theanswer is affirmative or negative.
If the input querycontains an auxiliary verb and the word "any" with-out "of' ,  "any" is replaced by "no" or "some" (figure5).
If the constructed answer template contains suc-cessive double negatives (as might result from a querycontaining a negation), these are removed.Finally, contrast he situation where the answer listis (BOOLEAN NIL) with the one where the answerlist is simply NIL (which means the database failed toreturn an answer).
In this case, the system answers "Idon't know whether" with the modified input queryappended (figure 6).The style of the articulator's verbose responses, whilesomewhat quaint, appears cooperative because theanswer is delivered using the same lexical and syn-Sentence:Answer list:Articulated:Do any v icepres idents  work?NILI DON'T KNOW WHETHER ANYVICE PRESIDENTS DO WORK.Figure 6: Successful failureSentence:Answer list:Articulated:Which manager is Kat Devito?
(ITEM)KAT DEVITO IS NO MANAGER.Figure 7: Pragmatic strangenessSentence:Answer list:Articulated:Sentence:Ans.er list:Articulated:WHAT SELF-PORTRAITS DIDVAN GOGH PAINT?
(SET "F0296 .... F0627 .... F0522")VAN GOGH DID PAINTSELF-PORTRAIT, SELF-PORTRAIT,AND SELF-PORTRAITWITH GRAY FELT HAT.SHOW ME STARRY NIGHT.
(ITEM "F0612")STARRY NIGHT.Figure 8: When words aren't enoughtactic forms that the user chooses in the query.
Ofcourse, this technique of wrapping the query aroundthe answer works only in very simple question-answering applications, where the system has little ofits own to say.
Failure in the form of ungrammaticalanswers to wh-questions sometimes occurs due to lackof agreement; rather than extend the verbose articu-lator any further, it seems a better strategy to simplydetect those cases and suppress an ungrammaticalverbose answer in favor of a short one.
Pragmaticfailures that are still syntactically well-formed mayalso occur, particularly in negative boolean answersand empty set answers; we have not arrived at a con-sistently successful strategy for detecting and treat-ing presuppositional failures (figure 7).
Our imple-mentation Mso does not take into account syntacticconstraints on given/new information in framing theanswer in the query.
Despite these limitations, theappeal of verbose articulation argues for integratinga real generation capability with a natural anguageinterface to database query.5 Mu l t imed iaWhile the articulator always manages to producesome sort of textual answer, it is often desirable torespond with an answer in a different medium (fig-ure 8).
Visual images from a videodisc can be dis-played whencver item or set answers are associatedwith videodisc frames in the database, in addition towhenever an imperative is used to explicitly requestimages.The articulator consults a module called circus whichcontains the drivers and methods pertaining to thevideodisc player and the text-to-speech hardware.This module queries the database application to dis-cover whether any entities in the answer list can bedisplayed as videodisc images.
These images are rep-resented and accessed by videodisc frame numberswhich are stored in the database in SQL tables or inHPRL slots.When the system is configured with the text-to-speech generator and the items in a set answer areassociated with videodisc images, the entire textualanswer is displayed first.
Then a synchronizing func-tion in circus articulates the items in the set by dis-playing the approprate image on the video monitorand speaking the corresponding items, one at a time.Thus the user hears the name of an item spoken im-mediately after it comes up on the video monitor;videodisc images are displayed for a few seconds each.We have not synchronized the textual answers withthe videodisc answers, since these media are displayedon two separate screens at somewhat different ratesand it would be difficult for a user to attend simul-taneously to both.
Laser videodiscs in CAV format(constant angular velocity) advertise fast, random ac-cess to still images, yet with most videodisc playersthere is some time cost to searching for frames on adisc and for changing search direction.
We minimizethis cost by reordering the items in the set accordingto their videodisc frame numbers, which correspondto their ordering on the disc.It seems appropriate to mention here that videodiscimagery, like sex and violence, can be either gratu-itous or meaningful.
In the course of our project, wehave demonstrated both.
In the context of our peo-ple and equipment database, the articulator is capa-ble of displaying a picture of a featureless cubicle or aslide show of nervously posed employees in conjunc-tion with a textual answer.
On the other hand, thedatabase of Van Gogh paintings has proven to be avery appealing application for visual articulation.With visually articulated answers, we were providedwith an opportunity to begin to experiment with de-ictic reference.
While personal pronouns are inter-preted by the pragmatics processor using a discoursemodel which takes a centering approach \[Gro77\]\[Sid79\] [JW81\] \[GJW83\] \[BFP87\], demonstrative pro-nouns are interpreted via a rudimentary environmentmodel that knows which painting is currently dis-played on the video screen.
Note that the displayedimage may not be the one currently under discussionin the the discourse, but may be left over from an ear-lier query if no intervening queries elicited videodiscanswers.
Since imagery can be such a salient partof the user's environment, it is necessary to supportdeictic references to the current image.
At present inour system, "this" and "that" have the same interpre-tation, but we are exploring alternatives such as inter-preting "that" as referring to the previously displayedimage when it appears contrastively in the same con-text as "this".
A more thorough treatment should ofcourse integrate spatial, temporal and discourse per-spective \[Lin79\].
We are attempting to model moreof the visual environment, including graphic elementson the screen, and to integrate deictic informationmore fully into the discourse.By now it should be evident that one should not con-sider articulation of answers entirely independentlyfrom discourse.
A natural language interface to adatabase query application can provide textual feed-back about the discourse apart from the literal an-swer.
Our articulator makes explicit the interpre-tation of the user's pronominal reference by sub-stituting the phrase it cospecifies for the pronounin the verbose answer (figure 9).
Thus the useris likely to discover any misunderstanding instantly.On the other hand, since verbose answers rely onmore or less blindly-applied heuristics to wrap textaround the answer, the articulator is not a full part-ner in the discourse and is not capable of achievingQ: What did Gauguin paint?A: GAUGUIN PAINTED VINCENT PAINTING.Q: How many pictures of Van Gogh were notpainted by him?A: 8 PICTURES OF VAN GOGH WERE NOT PAINTEDBY GAUGUIN.Figure 9: References made explicitsubtle but nevertheless critical discourse functionsthrough syntactic choices.
A true generation com-ponent would presumably exercise lexical and syntaxchoices, thus avoiding eccentric as well as ungram-matical exchanges.6 Conc lus ionObviously there is much ground to be covered in theareas of natural language communication and con-versational human/computer interfaces.
Yet interimapplications can be built which are incrementally im-proved over previous ones.
This approach is necessaryin order to observe real users of these systems.The domain independent articulation strategy pre-sented here enables two very different database querysystems to present answers conversationally.
Gen-erality is achieved through the use of answer typekeywords (provided by the application driver) andthe illocutionary act of the query (provided by theparser).
From this information, multimedia nswersare assembled and templates in which to frame thetextual answer are constructed from the input query.Although it lacks inferencing ability, the articulatordescribed here provides everal features desirable in acooperative interface.
These features include answerspresented in a style that parallels the user's question,extended answers, the ability to refer deictically to animage, and explicit feedback regarding co-specifiers ofpersonal pronouns.Finally, multimedia articulation provides serendipi-tous opportunities for dispersing ambiguity, due tomultiple representation of the answer.
Take the fol-lowing query to our Van Gogh database: "Showme the pictures of Van Gogh that he didn't paint.
"The textual answer came back: "The pictures ofVan Gogh that Van Gogh didn't paint are VincentPainting and Self-Portrait."
As we puzzled over "Self-Portrait" (how could a self portrait be of Van Gogh,but not painted by him?)
the videodisc answer wasdisplayed on the adjacent screen: first, a portrait ofVan Gogh that had been painted by his friend Gau-guin, and - surprisingly - a self portrait of Van Goghthat was not painted, but drawn.7 AcknowledgementsThe work reported herein was jointly supportedby the National Science Foundation and HewlettPackard Labs.
It was done in collaboration withHPLab's Natural Language group.
I would especiallylike to thank Lew Creary, Dan Flickinger, Lyn Fried-man and Herb Clark.References\[BFP87\]\[CC77\]\[cP851\[FNSW87\]\[cJwsz\]S.E.
Brennan, M.W.
Friedman, and C.J.Pollard.
A centering approach to pro-nouns.
In Proc., 25st Annual Meetingof the ACL, Association of Computa-tional Linguistics, pages 155-162, Stan-ford, CA, 1987.H.H.
Clark and E.V.
Clark.
Psychol-ogy and Language.
Harcourt Brace Jo-vanovich, Publishers, 1977.L.
Creary and C.J.
Pollard.
A computa-tional semantics for natural language.
InProc., 23st Annual Meeting of the ACL,Association of Computational Linguis-tics, pages 172-179, Chicago, IL, 1985.D.P.
Flickinger, J. Nerbonne, I.
Sag, andT.
Wasow.
Toward evaluation of NLPsystems (in conjunction with panel).
In25st Annual Meeting of the ACL, As-sociation of Computational Linguistics,Stanford, CA, 1987.B.J.
Grosz, A.K.
Joshi, and S. Weinstein.Providing a unified account of definite\[Gri75\]\[Gro77\]\[cs85\]\[Hen85\]\[Jw81\]\[Kap82\]\[KJM86\]\[Lin79\]\[LS85\]noun phrases in discourse.
In Proc., 21stAnnual Meeting of the ACL, Associationof Computational Linguistics, pages 44-50, Cambridge, MA, 1983.H.P.
Grice.
Logic and conversation(from the William James lectures, Har-vard University, 1967).
In P. Cole and J.Morgan, editors, Syntax and Semantics3: Speech Acts, pages 41-58, AcademicPress, Inc., 1975.Barbara.J.
Grosz.
The representationand use of focus in dialogue understand-ing.
Technical Report 151, SRI Inter-national, 333 Ravenswood Ave, MenloPark, Ca.
94025, 1977.B.J.
Grosz and C.L.
Sidner.
The struc-ture of discourse structure.
TechnicalReport CSLI-85-39, Center for the Studyof Language and Information, Stanford,CA, 1985.G.
Hendrix.
Q&A.
Software, Symantec,1985.A.K.
Joshi and S. Weinstein.
Controlof inference: role of some aspects of dis-course structure - centering.
In Proe.,International Joint Conference on Arti-ficial Intelligence, pages 385-387, Van-couver, B.C., 1981.S.J.
Kaplan.
Cooperative r sponses froma portable natural anguage query sys-tem.
Artificial Intelligence, 2(19), 1982.J.
Kalita, M. Jobes, and G. McCalla.Summarizing natural anguage databaseresponses.
Computational Linguistics,12(2):107-124, 1986.C.
Linde.
Focus of attention and thechoice of pronouns in discourse.
In T.Givon, editor, Syntax and Semantics,pages 337-354, Academic Press, Inc.,1979.W.G.
Lehnert and S.P.
Schwartz.
Database querying by computer.
In A.C.Graesser and J.B. Black, editors, ThePsychology of Questions, pages 359-374,Lawrence Erlbaum Associates, Publish-ers, 1985.\[Nim82\]\[Po185\]\[PS87\]\[ReiSS\]\[Sid79\]\[Sid81\]\[Spa83\]\[Ste87\]\[TRC84\]\[WJMM82\]\[WMJB83\]L. Nimoy.
Vincent Van Gogh: a portraitin two parts.
Videodisc, Philips Interna-tional/North American Philips Corpora-tion, 1982.M.
Pollack.
Information sought andinformation provided.
In CHI '85,pages 155-160, San Francisco, CA, 1985.C.
Pollard and I.A.
Sag.
Information-Based Syntax and Semantics.
Vol.
i:Fundamentals.
(in press).
Lecture notesseries no.
13, Center for the Study ofLanguage and Information, Stanford,CA, 1987.R.
Reichman.
Getting Computers toTalk Like You and Me.
MIT Press, Cam-bridge, MA, 1985.Candace L. Sidner.
Toward a computa-tional theory of definite anaphora com-prehension in English.
Technical Re-port AI-TR-537, MIT, 1979.C.L.
Sidner.
Focusing for interpreta-tion of pronouns.
American Journalof Computational Linguistics, 7(4):217-231, 1981.K.
Sparck-Jones.
Shifting meaning rep-resentations.
In Proc., InternationalJoint Conference on Artificial Intelli-gence, pages 621-623, 1983.P.
Stenton.
Designing a co-operative in-terface to an expert system.
TechnicalReport HPL-BRC-TM-87-023, HPLabsTechnical Memo, 1987.J.C.
Thomas, M.B.
Rosson, and M.Chodorow.
Human factors and syn-thetic speech.
In Proc., INTERA CT '84,pages 37-42, 1984.B.
Webber, A. Joshi, E. Mays, and K.McKeown.
Extended natural languagedata base interactions.
InternationalJournal of Computers and Mathematics:Special issue on computational linguis-tics, 1982.W.
Walster, H. Marburger, A. Jameson,and S. Busemann.
Over-answering yes-no questions: extended responses in aNL interface to a vision system.
In Proc.,International Joint Conference on Arti-ficial Intelligence, pages 643-646, 1983.
