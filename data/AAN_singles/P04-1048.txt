Inducing Frame Semantic Verb Classes from WordNet and LDOCERebecca Green,  Bonnie J. Dorr,  and Philip Resnik*??
*?
*?Institute for Advanced Computer Studies*Department of Computer Science?College of Information Studies?University of MarylandCollege Park, MD 20742 USA{rgreen, bonnie, resnik}@umiacs.umd.eduAbstractThis paper presents SemFrame, a systemthat induces frame semantic verb classesfrom WordNet and LDOCE.
Semanticframes are thought to have significantpotential in resolving the paraphraseproblem challenging many language-based applications.When compared to the handcraftedFrameNet, SemFrame achieves its bestrecall-precision balance with 83.2%recall (based on SemFrame's coverage ofFrameNet frames) and 73.8% precision(based on SemFrame verbs?
semanticrelatedness to frame-evoking verbs).
Thenext best performing semantic verbclasses achieve 56.9% recall and 55.0%precision.1 IntroductionSemantic content can almost always be expressedin a variety of ways.
Lexical synonymy (Sheesteemed him highly vs. She respected himgreatly), syntactic variation (John paid the bill vs.The bill was paid by John), overlapping meanings(Anna turned at Elm vs. Anna rounded the cornerat Elm), and other phenomena interact to producea broad range of choices for most languagegeneration tasks (Hirst, 2003; Rinaldi et al, 2003;Kozlowski et al, 2003).
At the same time, naturallanguage understanding must recognize whatremains constant across paraphrases.The paraphrase phenomenon affects manycomputational linguistic applications, includinginformation retrieval, information extraction,question-answering, and machine translation.
Forexample, documents that express the samecontent using different linguistic means shouldtypically be retrieved for the same queries.Information sought to answer a question needs tobe recognized no matter how it is expressed.Semantic frames (Fillmore, 1982; Fillmoreand Atkins, 1992) address the paraphrase problemthrough their slot-and-filler templates, representingfrequently occurring, structured experiences.Semantic frame types of an intermediate granularityhave the potential to fulfill an interlingua role withina solution to the paraphrase problem.Until now, semantic frames have beengenerated by hand (as in Fillmore and Atkins,1992), based on native speaker intuition; theFrameNet project (http://www.icsi.berkeley.edu/~framenet; Johnson et al, 2002) now couples thisgeneration with empirical validation.
Onlyrecently has this project begun to achieve relativebreadth in its inventory of semantic frames.
Tohave a comprehensive inventory of semanticframes, however, we need the capacity to generatesemantic frames semi-automatically (the need formanual post-editing is assumed).To address these challenges, we havedeveloped SemFrame, a system that inducessemantic frames automatically.
Overall, thesystem performs two primary functions:  (1)identification of sets of verb senses that evoke acommon semantic frame (in the sense that lexicalunits call forth corresponding conceptualstructures); and (2) identification of theconceptual structure of semantic frames.
Thispaper explores the first task of identifying framesemantic verb classes.
These classes have severaltypes of uses.
First, they are the basis foridentifying the internal structure of the frameproper, as set forth in Green and Dorr, 2004.Second, they may be used to extend FrameNet.Third, they support applications needing access tosets of semantically related words, for example,text segmentation and word sense disambiguation,as explored to a limited degree in Green, 2004.Section 2 presents related research efforts ondeveloping semantic verb classes.
Section 3summarizes the features of WordNet(http://www.cogsci.princeton.edu/~wn) andLDOCE (Procter, 1978) that support theautomatic induction of semantic verb classes, definitions and example sentences often mentionwhile Section 4 sets forth the approach taken by their participants using semantic-type-like nouns,SemFrame to accomplish this task.
Section 5 thus mapping easily to the corresponding framepresents a brief synopsis of SemFrame?s results, element.
Corpus data, however, are more likelywhile Section 6 presents an evaluation of to include instantiated participants, which maySemFrame?s ability to identify semantic verb not generalize to the frame element.
Second,classes of a FrameNet-like nature.
Section 7 lexical resources provide a consistent amount ofsummarizes our work and motivates directions for data for word senses, while the amount of data infurther development of SemFrame.
a corpus for word senses is likely to vary widely.2 Previous WorkThe EAGLES (1998) report on semanticencoding differentiates between two approachesto the development of semantic verb classes:those based on syntactic behavior and those basedon semantic criteria.Levin (1993) groups verbs based on ananalysis of their syntactic properties, especiallytheir ability to be expressed in diathesisalternations; her approach reflects the assumptionthat the syntactic behavior of a verb is determinedin large part by its meaning.
Verb classes at thebottom of Levin?s shallow network grouptogether (quasi-) synonyms, hierarchically relatedverbs, and antonyms, alongside verbs with loosersemantic relationships.The verb categories based on Pantel and Lin(2002) and Lin and Pantel (2001) are inducedautomatically from a large corpus, using anunsupervised clustering algorithm, based onsyntactic dependency features.
The resultingclusters contain synonyms, hierarchically relatedverbs, and antonyms, as well as verbs moreloosely related from the perspective ofparaphrase.The handcrafted WordNet (Fellbaum, 1998a)uses the hyperonymy/hyponymy  relationship tostructure the English verb lexicon into a semanticnetwork.
Each collection of a top-level nodesupplemented by its descendants may be seen asa semantic verb class.In all fairness, resolution of the paraphraseproblem is not the explicit goal of most efforts tobuild semantic verb classes.
However, they canprocess some paraphrases through lexicalsynonymy, hierarchically related terms, andantonymy.3 Resources Used in SemFrameWe adopt an approach that relies heavily onpre-existing lexical resources.
Such resourceshave several advantages over corpus data inidentifying semantic frames.
First, bothThird, lexical resources provide their data in amore systematic fashion than do corpora.Most centrally, the syntactic arguments of theverbs used in a definition often correspond to thesemantic arguments of the verb being defined.For example, Table 1 gives the definitions ofseveral verb senses in LDOCE that evoke theCOMMERCIAL TRANSACTION frame, whichincludes as its semantic arguments a Buyer, aSeller, some Merchandise, and Money.
Wordscorresponding to the Money (money, value), theMerchandise (property, goods), and the Buyer(buyer, buyers) are present in, and to some extentshared across, the definitions; however, no wordscorresponding to the Seller are present.Verb LDOCE Definitionsensebuy 1 to obtain (something) by giving money(or something else of value)buy 2 to obtain in exchange for something,often something of great valuebuy 3 to be exchangeable forpurchase 1 to gain (something) at the cost ofeffort, suffering, or loss of somethingof valuesell 1 to give up (property or goods) toanother for money or other valuesell 2 to offer (goods) for salesell 3 to be bought; get a buyer or buyers;gain a saleTable 1.
LDOCE Definitions for VerbsEvoking the COMMERCIAL TRANSACTION FrameOf available machine-readable dictionaries,LDOCE appears especially useful for thisresearch.
It uses a restricted vocabulary of about2000 words in its definitions and examplesentences, thus increasing the likelihood thatwords with closely related meanings will useMerge pairs, filtering out thosenot meeting threshold criteriaMap WordNet synsetsto LDOCE sensesExtract verb sensepairs from WordNetExtract verb sensepairs from LDOCEBuild fully-connected verb groupsCluster related verb groupsVerb sense framesetsthe same words in their definitions and support WordNet verb synsets and LDOCE verb sensesthe pattern of discovery envisioned.
LDOCE?s relies on finding matches between the datasubject field codes also accomplish some of the available for the verb senses in each resourcesame type of grouping as semantic frames.
(e.g., other words in the synset; words inWordNet is a machine-readable lexico- definitions and example sentences; words closelysemantic database whose primary organizational related to these words; and stems of these words).structure is the synset?a set of synonymous word The similarity measure used is the average of thesenses.
A limited number of relationship types proportion of words on each side of the(e.g., antonymy, hyponymy, meronymy, comparison that are matched in the other.
Thistroponymy, entailment) also relate synsets within mapping is used both to relate LDOCE verb senses,a part of speech.
(Version 1.7.1 was used.)
that map to the same WordNet synset (fig.
3f) and toFellbaum (1998b) suggests that relationships translate previously paired WordNet verb synsetsin WordNet ?reflect some of the structure of into LDOCE verb sense pairs.frame semantics?
(p. 5).
Through the relational In the third stage, the resulting verb sensestructure of WordNet, buy, purchase, sell, and pay pairs are merged into a single data set, retainingare related together:  buy and purchase comprise one only those pairs whose cumulative supportsynset; they entail paying and are opposed to sell.
exceeds thresholds for either the number ofThe relationship of buy, purchase, sell, and supporting data sources or strength of support,pay to other COMMERCIAL TRANSACTION thus achieving higher precision in the mergedverbs?for example, cost, price, and the demand data set than in the input data sets.
Then, thepayment sense of charge?is not made explicit in graph formed by the verb sense pairs in theWordNet, however.
Further, as Roger Chaffin merged data set is analyzed to find the fullyhas noted, the specialized vocabulary of, for connected components.example, tennis (e.g.
racket, court, lob) is not co- Finally, these groups of verb senses becomelocated, but is dispersed across different branches input to a clustering operation (Voorhees, 1986).of the noun network (Miller, 1998, p. 34).
Those groups whose similarity (due to overlap in4 SemFrame ApproachSemFrame gathers evidence about framesemantic relatedness between verb senses byanalyzing LDOCE and WordNet data from avariety of perspectives.
The overall approachused is shown in Figure 1.
The first stage ofprocessing extracts pairs of LDOCE andWordNet verb senses that potentially evoke thesame frame.
By exploiting many different cluesto semantic relatedness, we overgenerate thesepairs, favoring recall; subsequent stages improvethe precision of the resulting data.Figures 2 and 3 give details of the algorithmsfor extracting verb pairs based on different typesof evidence.
These include:  clustering LDOCEverb senses/WordNet synsets on the basis ofwords in their definitions and example sentences(fig.
2); relating LDOCE verb senses defined interms of the same verb (fig.
3a); relating LDOCEverb senses that share a common stem (fig.
3b);extracting explicit sense-linking relationships inLDOCE (fig.
3c); relating verb senses that sharegeneral or specific subject field codes in LDOCE(fig.
3d); and extracting (direct or extended)semantic relationships in WordNet (fig.
3e).In the second stage, mapping betweenmembership) exceed a threshold are mergedtogether, thus reducing the number of verb sensegroups.
The verb senses within each resultinggroup are hypothesized to evoke the samesemantic frame and constitute a frameset.Figure 1.
Approach for BuildingFrame Semantic Verb Classeswgtwordf 1frequencyfwgtwordf .01Input.
SW, a set of stop words; M, a set of(word, stem) pairs; F, a set of (word,frequency) pairs; DE, a set of(verb_sense_id, def+ex) pairs, wheredef+ex  = the set of words in theddefinitions and example sentences ofverb_sense_iddStep 1. forall d  DE, append to def+ex : dverb_sense_id  and remove fromddef+ex  any word w  SWdStep 2. forall d  DEforall m  Mif word  exists in def+ex , m   dsubstitute stem  for wordm  mStep 3. forall f  Fif frequency   > 1,f,else if frequency   == 1,fStep 4.
O Voorhees?
average link clusteringalgorithm applied to DE, with initialweights forall t in def+ex set to wgttStep 5. forall o  Oreturn all combinations of twomembers from oFigure 2.
Algorithm for GeneratingClustering-based Verb Pairs5 ResultsWe explored a range of thresholds in the finalstage of the algorithm.
In general, the lower the1threshold, the looser the verb grouping.
Thenumber of verb senses retained (out of 12,663non-phrasal verb senses in LDOCE) and the verbsense groups produced by using these thresholdsare recorded in Table 2.6 EvaluationOne of our goals is to produce sets of verb sensescapable of extending FrameNet's coverage whilerequiring reasonably little post-editing.
This goalhas two subgoals: identifying new frames andidentifying additional lexical units that evokeThreshold Num verb senses Num groups0.5 6461 13381.0 6414 17591.5 5607 14212.0 5604 1563Table 2.
Results of Frame Clustering Processpreviously recognized frames.
We use the hand-crafted FrameNet, which is of reliably highprecision, as a gold standard  for the initial2evaluation of SemFrame's ability to achieve thesesubgoals.
For the first, we evaluate SemFrame?sability to generate frames that correspond toFrameNet?s frames, reasoning that the systemmust be able to identify a large proportion ofknown frames if the quality of its output is goodenough to identify new frames.
(At this stage wedo not measure the quality  of new frames.)
Forthe second subgoal we can be more concrete:  Forframes identified by both systems, we measure thedegree to which the verbs identified bySemFrame can be shown to evoke those frames,even if FrameNet has not identified them asframe-evoking verbs.FrameNet includes hierarchically organizedframes of varying levels of generality: Somesemantic areas are covered by a general frame,some by a combination of specific frames, andsome by a mix of general and specific frames.Because of this variation we determined thedegree to which SemFrame and FrameNet overlapby automatically finding and comparingcorresponding frames instead of fully equivalentframes.
Frames correspond if the semantic scopeof one frame is included within the semanticFor the clustering algorithm used, the clustering FrameNet's frames are more syntactically than1threshold range is open-ended.
The values semantically motivated (e.g., EXPERIENCER-OBJECT,investigated in the evaluation are fairly low.
EXPERIENCER-SUBJECT).Certain constraints imposed by FrameNet's2development strategy restrict its use as a full-fledgedgold standard for evaluating semantic frame induction.
(1) As of summer 2003, only 382 frames had beenidentified within the FrameNet project.
(2) Low recallaffects not only the set of semantic frames identifiedby FrameNet, but also the sets of frame-evoking unitslisted for each frame.
No verbs are listed for 38.5% ofFrameNet's frames, while another 13.1% of them listonly 1 or 2 verbs.
The comparison here is limited tothe 197 FrameNet frames for which at least one verbis listed with a counterpart in LDOCE.
(3) Some ofa.
Relates LDOCE verb senses that are defined in terms of the same verbInput.
D, a set of (verb_sense_id, def_verb) pairs, where def_verb  = the verb in terms of whichdverb_sense_id  is defineddStep 1. forall v that exist as def_verb in D, form DV   D, by extracting all (verb_sense_id, def_verb)vpairs where v = def_verbStep 2. remove all DV  for which | DV  | > 40v    vStep 3. forall v that exist as def_verb in D, return all combinations of two members from DVvb.
Relates LDOCE verb senses that share a common stemInput.
D, a set of (verb_sense_id, verb_stem) pairs, where verb_stem  = the stem for the verb on whichdverb_sense_id  is baseddStep 1. forall m that exist as verb_stem in D, form DV   D, by extracting all (verb_sense_id,mverb_stem) pairs where m = verb_stemStep 2. forall m that exist as verb_stem in D, return all combinations of two members from DVvc.
Extracts explicit sense-linking relationships in LDOCEInput.
D, a set of (verb_sense_id, def) pairs, where def  = the definition for verb_sense_idd     dStep 1. forall d  D, if def  contains compare or opposite note, extract related_verb from note; generated(verb_sense_id , related_verb ) pair d  dStep 2. forall d  D, if def  defines verb_sense_id  in terms of a related standalone verb (in BLOCKd  dCAPS), extract related_verb from definition; generate (verb_sense_id , related_verb ) pair d  dStep 3. forall (verb_sense_id , related_verb ) pairs, if there is only one sense of related_verb , choose itd  d          dand return (verb_sense_id , related_verb_sense_id ), else apply generalized mappingd  dalgorithm to return (verb_sense_id , related_verb_sense_id ) pairs where overlap occurs ind  dthe glosses of verb_sense_id  and related_verb_sense_idd  dd.
Relates verb senses that share general or specific subject field codes in LDOCEInput.
D, a set of (verb_sense_id, subject_code) pairs, where subject_code  = any 2- or 4-characterdsubject field code assigned to verb_sense_idStep 1. forall c that exist as subject_code in D, form DV   D, by extracting all (verb_sense_id,csubject_code) pairs where c = subject_codeStep 2. forall c that exist as subject_code in D,return all combinations of two members from DVve.
Extracts (direct or extended) semantic relationships in WordNetInput.
WordNet data file for verb synsetsStep 1. forall synset lines in input filereturn (synset, related_synset) pairs for all synsets directly related through hyponymy,antonymy, entailment, or cause_to relationships in WordNet(for extended relationship pairs, also return (synset, related_synset) pairs for all synsets withinhyponymy tree, i.e., no matter how many levels removed)f. Relates LDOCE verb senses that map to the same WordNet synsetInput.
mapping of LDOCE verb senses to WordNet synsetsStep 1. forall lines in input filereturn all combinations of two LDOCE verb senses mapped to the same WordNet?synsetFigure 3.
Algorithms for Generating Non-clustering-based Verb Pairsscope of the other frame or if the semantic scopes SemFrame?s verb classes list specific LDOCEof the two frames have significant overlap.
Since verb senses.
In extending FrameNet, verbs fromFrameNet lists evoking words, without SemFrame would be word-sense-disambiguatedspecification of word sense, the comparison was in the same way that FrameNet verbs currentlydone on the word level rather than on the word are, through the correspondence of lexeme andsense level, as if LDOCE verb senses were not frame.specified in SemFrame.
However, it is clearly Incompleteness in the listing of evoking verbsspecific word senses that evoke frames, and in FrameNet and SemFrame precludes a straight-forward detection of correspondences between incrust, and ornament.
Two of the verbs?adorntheir frames.
Instead, correspondence between and decorate?are shared.
In addition, the frameFrameNet and SemFrame frames is established names are semantically related through ausing either of two somewhat indirect approaches.
WordNet synset consisting of decorate, adornIn the first approach, a SemFrame frame is (which CatVar relates to ADORNING), grace,deemed to correspond to a FrameNet frame if the ornament (which CatVar relates totwo frames meet both a minimal-overlap ORNAMENTATION), embellish, and beautify.
Thecriterion (i.e., there is some, perhaps small, two frames are therefore designated asoverlap between the FrameNet and SemFrame corresponding frames by meeting both theframesets) and a frame-name-relatedness minimal-overlap and the frame-name relatednesscriterion.
The minimal-overlap criterion is met if criteria.either of two conditions is met:  (1) If the In the second approach, a SemFrame frame isFrameNet frame lists four or fewer verbs (true of deemed to correspond to a FrameNet frame if theover one-third of the FrameNet frames that list two frames  meet either of two relatively stringentassociated verbs), minimal overlap occurs when verb overlap criteria, the majority-match criterionany one verb associated with the FrameNet frame or the majority-related criterion, in which casematches a verb associated with a SemFrame examination of frame names is unnecessary.frame.
(2) If the FrameNet frame lists five or The majority-match criterion is met if the setmore verbs, minimal overlap occurs when two or of verbs shared by FrameNet and SemFramemore verbs in the FrameNet frame are matched by framesets account for half or more of the verbs inverbs in the SemFrame frame.
either frameset.
For example, the APPLY_HEATThe looseness of the minimal overlap frame in FrameNet includes 22 verbs:  bake,criterion is tightened by also requiring that the blanch, boil, braise, broil, brown, char, coddle,names of the FrameNet and SemFrame frames be cook, fry, grill, microwave, parboil, poach, roast,closely related.
Establishing this frame-name saute, scald, simmer, steam, steep, stew, andrelatedness involves identifying individual toast, while the BOILING frame in SemFramecomponents of each frame name  and augmenting includes 7 verbs:  boil, coddle, jug, parboil,3this set with morphological variants from CatVar poach, seethe, and simmer.
Five of these(Habash and Dorr 2003).
The resulting set for verbs?boil, coddle, parboil, poach, andeach FrameNet and SemFrame frame name is simmer?are shared across the two frames andthen searched in both the noun and verb WordNet constitute over half of the SemFrame frameset.networks to find all the synsets that might Therefore the two frames are deemed tocorrespond to the frame name.
To these sets are correspond by meeting the majority-matchalso added all synsets directly related to the criterion.synsets corresponding to the frame names.
If the The majority-related criterion is met if half orresulting set of synsets gathered for a FrameNet more of the verbs from the SemFrame frame areframe name intersects with the set of synsets semantically related to verbs from the FrameNetgathered for a SemFrame frame name, the two frame (that is, if the precision of the SemFrameframe names are deemed to be semantically verb set is at least 0.5).
To evaluate this criterion,related.
each FrameNet and SemFrame verb is associatedFor example, the FrameNet ADORNING frame with the WordNet verb synsets it occurs in,contains 17 verbs: adorn, blanket, cloak, coat, augmented by the synsets to which the initial setscover, deck, decorate, dot, encircle, envelop, of synsets are directly related.
If the sets offestoon, fill, film, line, pave, stud, and wreathe.
synsets corresponding to two verbs share one orThe SemFrame ORNAMENTATION frame contains more synsets, the two verbs are deemed to be12 verbs:  adorn, caparison, decorate, embellish, semantically related.
This process is extendedembroider, garland, garnish, gild, grace, hang, one further level, such that a SemFrame verbfound by this process to be semantically related toa SemFrame verb, whose semantic relationship toa FrameNet verb has already been established,will also be designated a frame-evoking verb.
Ifhalf or more of the verbs listed for a SemFrameframe are established as evoking the same frameas the list of WordNet verbs, then the FrameNetAll SemFrame frame names are nouns.
(See3Green and Dorr, 2004 for an explanation of theirselection.)
FrameNet frame names (e.g., ABUNDANCE,A C T I V I T Y _ S T A R T ,  C A U S E _ T O _ B E _ W E T ,INCHOATIVE_ATTACHING), however, exhibitconsiderable variation.and SemFrame frames are hypothesized to bound on the task, i.e., 100% recall and 100%correspond through the majority-related criterion.
precision.
The Lin & Pantel results are here aFor example, the FrameNet ABUNDANCE lower bound for automatically induced semanticframe includes 4 verbs: crawl, swarm, teem, and verb classes and probably reflect the limitations ofthrong.
The SemFrame FLOW frame likewise using only corpus data.
Among efforts to developincludes 4 verbs:  pour, teem, stream, and semantic verb classes, SemFrame?s resultspullulate.
Only one verb?teem?is shared, so correspond more closely to semantic frames thanthe majority-match criterion is not met, nor is the do others.related-frame-name criterion met, as the framenames are not semantically related.
The majority-related criterion, however, is met through aWordNet verb synset that includes pour, swarm,stream, teem, and pullulate.Of the 197 FrameNet frames that include atleast one LDOCE verb, 175 were found to have acorresponding SemFrame frame.
But this 88.8%recall level should be balanced against theprecision ratio of SemFrame verb framesets.After all, we could get 100% recall by listing allverbs in every SemFrame frame.The majority-related function computes theprecision ratio of the SemFrame frame for eachpair of FrameNet and SemFrame frames beingcompared.
By modifying the minimum precisionthreshold, the balance between recall andprecision, as measured using F-score, can beinvestigated.
The best balance for the SemFrameversion is based on a clustering threshold of 2.0and a minimum precision threshold of 0.4, whichyields a recall of 83.2% and overall precision of73.8%.To interpret these results meaningfully, onewould like to know if SemFrame achieves moreFrameNet-like results than do other available verbcategory data, more specifically the 258 verbclasses from Levin, the 357 semantic verb classesof WordNet 1.7.1, or the 272 verb clusters of Linand Pantel, as described in Section 2.For purposes of comparison with FrameNet,Levin?s verb class names have been hand-editedto isolate the word that best captures the semanticsense of the class; the name of a WordNet-basedframe is taken from the words for the root-levelsynset; and the name of each Lin and Pantelcluster is taken to be the first verb in the cluster.4Evaluation results for the best balancebetween recall and precision (i.e., the maximumF-score) of the four comparisons are summarizedin Table 3.
FrameNet itself constitutes the upperSemantic verb Precision Recall Precisionclasses thresholdat max F-scoreSemFrame 0.40 0.832 0.738Levin 0.20 0.569 0.550WordNet 0.15 0.528 0.466Lin & Pantel 0.15 0.472 0.407Table 3.
Best Recall-Precision BalanceWhen Compared with FrameNet7 Conclusions and Future WorkWe have demonstrated that sets of verbs evokinga common semantic frame can be induced fromexisting lexical tools.
In a head-to-headcomparison with frames in FrameNet, the framesemantic verb classes developed by theSemFrame approach achieve a recall of 83.2%and the verbs listed for frames achieve a precisionof 73.8%; these results far outpace those of othersemantic verb classes.
On a practical level, alarge number of frame semantic verb classes havebeen identified.
Associated with clusteringthreshold 1.5 are 1421 verb classes, averaging14.1 WordNet verb synsets.
Associated withclustering threshold 2.0 are 1563 verb classes,averaging 6.6  WordNet verb synsets.Despite these promising results, we arelimited by the scope of our input data set.
WhileLDOCE and WordNet data are generally of highquality, the relative sparseness of these resourceshas an adverse impact on recall.
In addition, themapping technique used for picking outcorresponding word senses in WordNet andLDOCE is shallow, thus constraining  the recalland precision of SemFrame outputs.
Finally, themulti-step process of merging smaller verb groupsinto verb groups that are intended to correspondto frames sometimes fails to achieve anappropriate degree of correspondence (all the verbclasses discovered are not distinct).Lin and Pantel have taken a similar approach,4?naming?
their verb clusters by the first three verbslisted for a cluster, i.e., the three most similar verbs.In our future work, we will experiment withthe more recent release of WordNet (2.0).
Thisversion provides derivational morphology linksbetween nouns and verbs, which will promote fargreater precision in the linking of verb sensesbased on morphology than was possible in ourinitial implementation.
Another significantaddition to WordNet 2.0 is the inclusion ofcategory domains, which co-locate wordspertaining to a subject and perform the samefunction as LDOCE's subject field codes.Finally, data sparseness issues may beaddressed by supplementing the use of the lexicalresources used here with access to, for example,the British National Corpus, with its broadcoverage and carefully-checked parse trees.AcknowledgmentsThis research has been supported in part by aNational Science Foundation Graduate ResearchFellowship NSF ITR grant #IIS-0326553, andNSF CISE Research Infrastructure AwardEIA0130422.ReferencesBoguraev, Bran and Ted Briscoe.
1989.
Introduction.
InB.
Boguraev and T. Briscoe (Eds.
), ComputationalLexicography for Natural Language Processing, 1-40.
London: Longman.EAGLES Lexicon Interest Group.
1998.
EAGLESPreliminary Recommendations on SemanticEncoding: Interim Report,  <http://www.ilc.cnr.it/EAGLES96/rep2/ rep2.html>.Fellbaum, Christiane (Ed.).
1998a.
WordNet: AnElectronic Lexical Database.
Cambridge, MA:The MIT Press.Fellbaum, Christiane.
1998b.
Introduction.
In C.Fellbaum, 1998a, 1-17.Fillmore, Charles J.
1982.
Frame semantics.
InLinguistics in the Morning Calm, 111-137.
Seoul:Hanshin.Fillmore, Charles J. and B. T. S. Atkins.
1992.Towards a frame-based lexicon: The semantics ofRISK and its neighbors.
In A. Lehrer and E. F.Kittay (Eds.
), Frames, Fields, and Contrasts, 75-102.
Hillsdale, NJ: Erlbaum.Green, Rebecca.
2004.
Inducing Semantic Framesfrom Lexical Resources.
Ph.D. dissertation,University of Maryland.Green, Rebecca and Bonnie J. Dorr.
2004.
Inducing ASemantic Frame Lexicon from WordNet Data.
InProceedings of the 2nd Workshop on TextMeaning and Interpretation (ACL 2004).Habash, Nizar and Bonnie Dorr.
2003.
A categorialvariation database for English.
In Proceedings ofNorth American Association for ComputationalLinguistics, 96-102.Hirst, Graeme.
2003.
Paraphrasing paraphrased.Keynote address for The Second InternationalWorkshop on Paraphrasing: ParaphraseAcquisition and Applications, ACL 2003,<http://nlp.nagaokaut.ac.jp/IWP2003/pdf/Hirst-slides.pdf>.Johnson, Christopher R., Charles J. Fillmore,Miriam R. L. Petruck, Collin F. Baker,Michael Ellsworth, Josef Ruppenhofer, andEsther J.
Wood.
2002.
FrameNet: Theory andP r a c t i c e ,  v e r s i o n  1 .
0 ,< h t t p : / / w w w .
i c s i .
b e r k e l e y .
e d u /~framenet/book/book.html>.Kozlowski, Raymond, Kathleen F. McCoy, and K.Vijay-Shanker.
2003.
Generation ofsingle-sentence paraphrases frompredicate/argument structure usinglexico-grammatical resources.
In The SecondInternational Workshop on Paraphrasing:Paraphrase Acquisition and Applications(IWP2003), ACL 2003, 1-8.Levin, Beth.
1993.
English Verb Classes andAlternations: A Preliminary Investigation.Chicago: University of Chicago Press.Lin, Dekang and Patrick Pantel.
2001.
Induction ofsemantic classes from natural language text.
InProceedings of ACM SIGKDD Conference onKnowledge Discovery and Data Mining, 317-322.Litkowski, Ken.
2004.
Senseval-3 task: Word-sensedisambiguation of WordNet glosses,<http://www.clres.com/SensWNDisamb.html>.Miller, George A.
1998.
Nouns in WordNet.
In C.Fellbaum, 1998a, 23-67.Pantel, Patrick and Dekang Lin.
2002.
Discoveringword senses from text.
In Proceedings of theEighth ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining, 613-619.Procter, Paul (Ed.).
1978.
Longman Dictionary ofContemporary English.
Longman Group Ltd.,Essex, UK.Rinaldi, Fabio, James Dowdall, Kaarel Kaljurand,Michael Hess, and Diego Moll?.
2003.
Exploitingparaphrases in a question answering system.
InThe Second International Workshop onParaphrasing: Paraphrase Acquisition andApplications (IWP2003), ACL 2003, 25-32.Voorhees, Ellen.
1986.
Implementing agglomerativehierarchic clustering algorithms for use indocument retrieval.
Information Processing &Management 22/6: 465-476.
