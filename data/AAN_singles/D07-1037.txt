Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
351?359, Prague, June 2007. c?2007 Association for Computational LinguisticsTopic Segmentation with Hybrid Document IndexingIrina MatveevaDepartment of Computer ScienceUniversity of ChicagoChicago, IL 60637matveeva@cs.uchicago.eduGina-Anne LevowDepartment of Computer ScienceUniversity of ChicagoChicago, IL 60637levow@cs.uchicago.eduAbstractWe present a domain-independent unsuper-vised topic segmentation approach based onhybrid document indexing.
Lexical chainshave been successfully employed to evalu-ate lexical cohesion of text segments and topredict topic boundaries.
Our approach isbased in the notion of semantic cohesion.
Ituses spectral embedding to estimate seman-tic association between content nouns over aspan of multiple text segments.
Our methodsignificantly outperforms the baseline on thetopic segmentation task and achieves perfor-mance comparable to state-of-the-art meth-ods that incorporate domain specific infor-mation.1 IntroductionThe goal of topic segmentation is to discover storyboundaries in the stream of text or audio recordings.Story is broadly defined as segment of text contain-ing topically related sentences.
In particular, thetask may require segmenting a stream of broadcastnews, addressed by the Topic Detection and Track-ing (TDT) evaluation project (Wayne, 2000; Allan,2002).
In this case topically related sentences belongto the same news story.
While we are consideringTDT data sets in this paper, we would like to posethe problem more broadly and consider a domain-independent approach to topic segmentation.Previous research on topic segmentation hasshown that lexical coherence is a reliable indicatorof topical relatedness.
Therefore, many approacheshave concentrated on different ways of estimatinglexical coherence of text segments, such as seman-tic similarity between words (Kozima, 1993), sim-ilarity between blocks of text (Hearst, 1994), andadaptive language models (Beeferman et al, 1999).These approaches use word repetitions to evaluatecoherence.
Since the sentences covering the samestory represent a coherent discourse segment, theytypically contain the same or related words.
Re-peated words build lexical chains that are conse-quently used to estimate lexical coherence.
This canbe done either by analyzing the number of overlap-ping lexical chains (Hearst, 1994) or by building ashort-range and long-range language model (Beefer-man et al, 1999).
More recently, topic segmentationwith lexical chains has been successfully applied tosegmentation of news stories, multi-party conversa-tion and audio recordings (Galley et al, 2003).When the task is to segment long streams of textcontaining stories which may continue at a laterpoint in time, for example developing news stories,building of lexical chains becomes intricate.
In ad-dition, the word repetitions do not account for syn-onymy and semantic relatedness between words andtherefore may not be able to discover coherence ofsegments with little word overlap.Our approach aims at discovering semantic relat-edness beyond word repetition.
It is based on thenotion of semantic cohesion rather than lexical cohe-sion.
We propose to use a similarity metric betweensegments of text that takes into account semantic as-sociations between words spanning a number of seg-ments.
This method approximates lexical chains byaveraging the similarity to a number of previous text351segments and accounts for synonymy by using a hy-brid document indexing scheme.
Our text segmen-tation experiments show a significant performanceimprovement over the baseline.The rest of the paper is organized as follows.
Sec-tion 2 discusses hybrid indexing.
Section 3 describesour segmentation algorithm.
Section 5 reports theexperimental results.
We conclude in section 6.2 Hybrid Document IndexingFor the topic segmentation task we would like to de-fine a similarity measure that accounts for synonymyand semantic association between words.
This simi-larity measure will be used to evaluate semantic co-hesion between text units and the decrease in seman-tic cohesion will be used as an indicator of a storyboundary.
First, we develop a document representa-tion which supports this similarity measure.Capturing semantic relations between words ina document representation is difficult.
Differentapproaches tried to overcome the term indepen-dence assumption of the bag-of-words representa-tion (Salton and McGill, 1983) by using distribu-tional term clusters (Slonim and Tishby, 2000) andexpanding the document vectors with synonyms, see(Levow et al, 2005).
Since content words can becombined into semantic classes there has been aconsiderable interest in low-dimensional representa-tions.
Latent Semantic Analysis (LSA) (Deerwesteret al, 1990) is one of the best known dimension-ality reduction algorithms.
In the LSA space doc-uments are indexed with latent semantic concepts.LSA maps all words to low dimensional vectors.However, the notion of semantic relatedness is de-fined differently for subsets of the vocabulary.
In ad-dition, the numerical information, abbreviations andthe documents?
style may be very good indicators oftheir topic.
However, this information is no longeravailable after the dimensionality reduction.We use a hybrid approach to document indexingto address these issues.
We keep the notion of la-tent semantic concepts and also try to preserve thespecifics of the document collection.
Therefore, wedivide the vocabulary into two sets: nouns and therest of the vocabulary.
The set of nouns does notinclude proper nouns.
We use a method of spec-tral embedding, as described below and compute alow-dimensional representation for documents usingonly the nouns.
We also compute a tf-idf represen-tation for documents using the other set of words.Since we can treat each latent semantic concept inthe low-dimensional representation as part of the vo-cabulary, we combine the two vector representationsfor each document by concatenating them.2.1 Spectral EmbeddingA vector space representation for documents andsentences is convenient and makes the similaritymetrics such as cosine and distance readily avail-able.
However, those metrics will not work if theydon?t have a meaningful linguistic interpretation.Spectral methods comprise a family of algo-rithms that embed terms and documents in a low-dimensional vector space.
These methods use pair-wise relations between the data points encoded in asimilarity matrix.
The main step is to find an embed-ding for the data that preserves the original similari-ties.GLSA We use Generalized Latent Semantic Anal-ysis (GLSA) (Matveeva et al, 2005) to computespectral embedding for nouns.
GLSA computesterm vectors and since we would like to use spectralembedding for nouns, it is well-suited for our ap-proach.
GLSA extends the ideas of LSA by definingdifferent ways to obtain the similarities matrix andhas been shown to outperform LSA on a number ofapplications (Matveeva and Levow, 2006).GLSA begins with a matrix of pair-wise term sim-ilarities S, computes its eigenvectors U and uses thefirst k of them to represent terms and documents, fordetails see (Matveeva et al, 2005).
The justifica-tion for this approach is the theorem by Eckart andYoung (Golub and Reinsch, 1971) stating that innerproduct similarities between the term vectors basedon the eigenvectors of S represent the best element-wise approximation to the entries in S. In otherwords, the inner product similarity in the GLSAspace preserves the semantic similarities in S.Since our representation will try to preserve se-mantic similarities in S it is important to have a ma-trix of similarities which is linguistically motivated.352Word Nearest Neighbors in GLSA Spacewitness testify prosecutor trial testimony juror eyewitnessfinance fund bank investment economy crisis categorybroadcast television TV satellite ABC CBS radiohearing hearing judge voice chatter sound appealsurprise announcement disappointment stunning shock reaction astonishmentrest stay remain keep leave portion economyTable 1: Words?
nearest neighbors in the GLSA semantic space.2.2 Distributional Term SimilarityPMI Following (Turney, 2001; Matveeva et al,2005), we use point-wise mutual information (PMI)to compute the matrix S. PMI between random vari-ables representing the words wi and wj is computedasPMI(wi, wj) = logP (Wi = 1,Wj = 1)P (Wi = 1)P (Wj = 1).
(1)Thus, for GLSA, S(wi, wj) = PMI(wi, wj).Co-occurrence Proximity An advantage of PMIis the notion of proximity.
The co-occurrence statis-tics for PMI are typically computed using a slidingwindow.
Thus, PMI will be large only for words thatco-occur within a small context of fixed size.Semantic Association vs. Synonymy AlthoughGLSA was successfully applied to synonymy in-duction (Matveeva et al, 2005), we would like topoint out that the GLSA discovers semantic associ-ation in a broad sense.
Table 1 shows a few wordsfrom the TDT2 corpus and their nearest neighborsin the GLSA space.
We can see that for ?witness?,?finance?
and ?broadcast?
words are grouped intocorresponding semantic classes.
The nearest neigh-bors for ?hearing?
and ?stay?
represent their differ-ent senses.
Interestingly, even for the abstract noun?surprise?
the nearest neighbors are meaningful.2.3 Document IndexingWe have two sets of the vocabulary terms: a set ofnouns, N , and the other words, T .
We compute tf-idfdocument vectors indexed with the words in T :~di = (?i(w1), ?i(w2), ..., ?i(w|T |)), (2)where ?i(wt) = tf(wt, di) ?
idf(wt).We also compute a k-dimensional representationwith latent concepts ci as a weighted linear combi-nation of GLSA term vectors ~wt:~di = (c1, ..., ck) =?t=1:|N |?i(wt) ?
~wt, (3)We concatenate these two representations to gener-ate a hybrid indexing of documents:~di = (?i(w1), ..., ?i(w|T |), c1, ...ck) (4)In our experiments, we compute documentand sentence representation using three indexingschemes: the tf-idf baseline, the GLSA represen-tation and the hybrid indexing.
The GLSA index-ing computes term vectors for all vocabulary words;document and sentence vectors are generated as lin-ear combinations of term vectors, as shown above.2.4 Document similarityOne can define document similarity at different lev-els of semantic content.
Documents can be similarbecause they discuss the same people or events andbecause they discuss related subjects and contain se-mantically related words.
Hybrid Indexing allowsus to combine both definitions of similarity.
Eachrepresentation supports a different similarity mea-sure.
tf-idf uses term-matching, the GLSA represen-tation uses semantic association in the latent seman-tic space computed for all words, and hybrid index-ing uses a combination of both: term-matching fornamed entities and content words other than nounscombined with semantic association for nouns.In the GLSA space, the inner product betweendocument vectors contains all pair-wise inner prod-uct between their words, which allows one to detectsemantic similarity beyond term matching:?~di, ~dj?
=?w?di?v?dj?i(w)?j(v)?~w,~v?
(5)353If documents contain words which are different butsemantically related, the inner product between theterm vectors will contribute to the document similar-ity, as illustrated with an example in section 5.When we compare two documents indexed withthe hybrid indexing scheme, we compute a combi-nation of similarity measures:?~di, ~dj?
=?nk?di?nm?dj?i(nk)?j(nm)?
~nk, ~nm?+?t?T?i(t) ?
?j(t).
(6)Document similarity contains semantic associationbetween all pairs of nouns and uses term-matchingfor the rest of the vocabulary.3 Topic Segmentation with SemanticCohesionOur approach to topic segmentation is based onsemantic cohesion supported by the hybrid index-ing.
Topic segmentation approaches use either sen-tences (Galley et al, 2003) or blocks of words astext units (Hearst, 1994).
We used both variantsin our experiments.
When using blocks, we com-puted blocks of a fixed size (typically 20 words) slid-ing over the documents in a fixed step size (10 or5 words).
The algorithm predicts a story boundarywhen the semantic cohesion between two consecu-tive units drops.
Blocks can cross story boundaries,thus many predicted boundaries will be displacedwith respect to the actual boundary.Averaged similarity In our preliminary experi-ments we used the largest difference in score to pre-dict story boundary, following the TextTiling ap-proach (Hearst, 1994).
We found, however, that inour document collection the word overlap betweensentences was often not large and pair-wise similar-ity could drop to zero even for sentences within thesame story, as will be illustrated below.
We couldnot obtain satisfactory results with this approach.Therefore, we used the average similarity by us-ing a history of fixed size n. The semantic cohesionscore was computed for the position between twotext units, ti and tj as follows:score(ti, tj) =1nn?1?k=0?ti?k, tj?
(7)Our approach predicts story boundaries at the min-ima of the semantic cohesion score.Approximating Lexical Chains One of the mo-tivations for our cohesion score is that it approxi-mates lexical chains, as for example in (Galley et al,2003).
Galley et al (Galley et al, 2003) define lex-ical chains R1, .., RN by considering repetitions ofterms t1, .., tN and assigning larger weights to shortand compact chains.
Then the lexical cohesion scorebetween two text units ti and tj is based on the num-ber of chains that overlap both of them:score(ti, tj) =N?k=1wk(ti)wk(tj), (8)where wk(ti) = score(Rj) if the chain Rj over-laps ti and zero otherwise.
Our cohesion score takesinto account only the chains for words that occur intj and have another occurrence within n previoussentences.
Due to this simplification, we computethe score based on inner products.
Once we makethe transition to inner products, we can use hybridindexing and compute semantic cohesion score be-yond term repetition.4 Related ApproachesWe compare our approach to the LCseg algorithmwhich uses lexical chains to estimate topic bound-aries (Galley et al, 2003).
Hybrid indexing allowsus to compute semantic cohesion score rather thanthe lexical cohesion score based on word repetitions.Choi at al.
used LSA for segmentation (Choi etal., 2001).
LSA (Deerwester et al, 1990) is a spe-cial case of spectral embedding and Choi at al.
(Choiet al, 2001) used all vocabulary words to com-pute low-dimensional document vectors.
We useGLSA (Matveeva et al, 2005) because it computesterm vectors as opposed to the dual document-termrepresentation with LSA and uses a different ma-trix of pair-wise similarities.
Furthermore, Choiat al.
(Choi et al, 2001) used clustering to predictboundaries whereas we used the average similarityscores.354s1: The Cuban news agency Prensa Latina called Clinton ?s announcement Friday that Cubans picked upat sea will be taken to Guantanamo Bay naval base a ?
new and dangerous element ?
in U S immigration policy.s2: The Cuban government has not yet publicly reacted to Clinton ?s announcement that Cuban rafterswill be turned away from the United States and taken to the U S base on the southeast tip of Cuba.s5: The arrival of Cuban emigrants could be an ?
extraordinary aggravation ?
to the situation , Prensa Latina said.s6: It noted that Cuba had already denounced the use of the base as a camp for Haitian refugees.whom it had for many years encouraged to come to the United States.s8: Cuba considers the land at the naval base , leased to the United States at the turn of the century,to be illegally occupied.s10: General Motors Corp said Friday it was recalling 5,600 1993-94 model Chevrolet Lumina, PontiacTrans Sport and Oldsmobile Silhouette minivans equipped with a power sliding door and built-in child seats.s14: If this occurs , the shoulder belt may not properly retract , the carmaker said.s15: GM is the only company to offer the power-sliding door.s16: The company said it was not aware of any accidents or injuries related to the defect.s17: To correct the problem , GM said dealers will install a modified interior trim piece that will reroute the seat belt.Table 2: TDT.
The first 17 sentences in the first file.Existing approaches to hybrid indexing used dif-ferent weights for proper nouns, nouns phrase headsand use WordNet synonyms to expand the docu-ments, for example (Hatzivassiloglou et al, 2000;Hatzivassiloglou et al, 2001).
Our approach doesnot require linguistic resources and learning theweights.
The semantic associations between nounsare estimated using spectral embedding.5 Experiments5.1 DataThe first TDT collection is part of the LCsegtoolkit1 (Galley et al, 2003) and we used it to com-pare our approach to LCseg.
We used the part of thiscollection with 50 files with 22 documents each.We also used the TDT2 collection2 of news arti-cles from six news agencies in 1998.
We used only9,738 documents that are assigned to one topic andhave length more than 50 words.
We used the Lemurtoolkit3 with stemming and stop words list for thetf-idf indexing; we used Bikel?s parser4 to obtainthe POS-tags and select nouns; we used the PLA-PACK package (Bientinesi et al, 2003) to computethe eigenvalue decomposition.1http://www1.cs.columbia.edu/ galley/tools.html2http://nist.gov/speech/tests/tdt/tdt98/3http://www.lemurproject.org/4http://www.cis.upenn.edu/ dbikel/software.htmlEvaluation For the TDT data we use the errormetric pk (Beeferman et al, 1999) and WindowD-iff (Pevzner and Hearst, 2002) which are imple-mented in the LCseg toolkit.
We also used theTDT cost metric Cseg5, with the default parametersP(seg)=0.3, Cmiss=1, Cfa=0.3 and distance of 50words.
All these measures look at two units (wordsor sentences) N units apart and evaluate how wellthe algorithm can predict whether there is a bound-ary between them or not.
Lower values mean betterperformance for all measures.Global vs. Local GLSA Similarity To obtain thePMI values we used the TDT2 collection, denoted asGLSAlocal.
Since co-occurrence statistics based onlarger collections give a better approximation to lin-guistic similarities, we also used 700,000 documentsfrom the English GigaWord collection, denoted asGLSA.
We used a window of size 8.5.2 Topic SegmentationThe first set of experiments was designed to evaluatethe advantage of the GLSA representation over thebaseline.
We compare our approach to the LCsegalgorithm (Galley et al, 2003) and use sentences assegmentation unit.
To avoid the issue of parameterssetting when the number of boundaries is not known,we provide each algorithm with the actual numbers5www.nist.gov/speech/tests/tdt/tdt98/doc/tdt2.eval.plan.98.v3.7.ps35510 21 27 45 52 65 73 89 9900.10.20.30.40.50.60.70.80.9110 21 27 45 52 65 73 89 9900.10.20.30.40.50.60.70.80.90 2 4 6 8 10 12 14 16 18 2000.10.20.30.40.50.60.70.80.9GLSAtfidfFigure 1: TDT.
Pair-wise sentence similarities for tf-idf (left), GLSA (middle); x-axis shows story bound-aries.
Details for the first 20 sentences, table 2 (right).10 21 27 45 52 65 73 89 9900.10.20.30.40.50.60.710 21 27 45 52 65 73 89 9900.10.20.30.40.50.60.710 21 27 45 52 65 73 89 990.30.40.50.60.70.80.91Figure 2: TDT.
Pair-wise sentence similarities for tf-idf (left), GLSA (middle) averaged over 10 preceedingsentences; LCseg lexical cohesion scores (right).
X-axis shows story boundaries.of boundaries.TDT We use the LCseg approach and our ap-proach with the baseline tf-idf representation and theGLSA representation to segment this corpus.
Ta-ble 2 shows a few sentences.
Many content wordsare repeated, so the lexical chains is definitely asound approach.
As shown in Table 2, in the firststory the word ?Cuba?
or ?Cuban?
is repeated in ev-ery sentence thus generating a lexical chain.
On thetopic boundary, the word overlap between sentencesis very small.
At the same time, the repetition ofwords may also be interrupted within a story: sen-tence 5, 6 and sentences 14, 15, 16 have little wordoverlap.
LCseg deals with this by defining severalparameters to control chain length and gaps.
Thissimple example illustrates the potential benefit of se-mantic cohesion.
Table 2 shows that ?General Mo-tors?
or ?GM?
are not repeated in every sentence ofthe second story.
However, ?GM?, ?carmaker?
and?company?
are semantically related.
Making thisinformation available to the segmentation algorithmallows it to establish a connection between each sen-tence of the second story.We computed pair-wise sentence similarities be-tween pairs of consecutive sentences in the tf-idf andGLSA representations.
Figure 1 shows the similar-ity values plotted for each sentence break.
The pair-wise similarities based on term-matching are veryspiky and there are many zeros within the story.
TheGLSA-based similarity makes the dips in the simi-larities at the boundaries more prominent.
The lastplot gives the details for the sentences in table 2.In the tf-idf representation sentences without wordoverlap receive zero similarity but the GLSA repre-sentation is able to use the semantic association be-tween between ?emigrants?
and ?refugees?
for sen-tences 5 and 6, and also the semantic association be-tween ?carmaker?
and ?company?
for sentences 14356Measure tf-idf GLSA LCsegPmiss 0.29 0.19 N/APfa 0.14 0.09 N/ACseg 0.18 0.08 N/Apk 0.24 0.17 0.07wd 0.27 0.21 0.10Table 3: TDT segmentation results.and 15.This effect increases as we use the semantic cohe-sion score as in equation 7.
Figure 2 shows the simi-larity values for tf-idf and GLSA and also the lexicalcohesion scores computed by LCseg.
The GLSA-based similarities are not quite as smooth as the LC-seg scores, but they correctly discover the bound-aries.
LCseg parameters are fine-tuned for this doc-ument collection.
We used a general TDT2 GLSArepresentation for this collection, and the only seg-mentation parameter we used is to avoid placingnext boundary within n=3 sentences of the previ-ous one.
For this reason the predicted boundary maybe one sentence off the actual boundary.
These re-sults are summarized in Table 3.
The GLSA repre-sentation performs significantly better than the tf-idfbaseline.
Its pk and WindowDiff scores with defaultparameters for LCseg are worse than for LCseg.
Weattribute it to the fact that we did not fine-tuned ourmethod to this collection and that boundaries are of-ten placed one position off the actual boundary.TDT2 For this collection we used three differentindexing schemes: the tf-idf baseline, the GLSA rep-resentation and the hybrid indexing.
Each represen-tation supports a different similarity measure.
OurTDT experiments showed that the semantic cohe-sion score based on the GLSA representation im-proves the segmentation results.
The variant ofthe TDT corpus we used is rather small and well-balanced, see (Galley et al, 2003) for details.
Inthe second phase of experiments we evaluate our ap-proach on the larger TDT2 corpus.
The experimentswere designed to address the following issues:?
performance comparison between GLSA andHybrid indexing representations.
As men-tioned before, GLSA embeds all words ina low-dimensional space.
Whereas semantic#b knownMethod Pmiss Pfa Csegtf-idf 0.52 0.14 0.19GLSA 0.4 0.1 0.14GLSA local 0.44 0.12 0.16Hybrid 0.34 0.10 0.12Hybrid local 0.38 0.09 0.13LCseg 0.80 0.19 0.28#b unknownMethod Pmiss Pfa Csegtf-idf 0.42 0.2 0.17GLSA 0.37 0.13 0.14GLSA local 0.35 0.19 0.14Hybrid 0.26 0.16 0.11Hybrid local 0.27 0.18 0.12Table 4: TDT2 segmentation results.
Sliding blockswith size 20 and stepsize 10; similarity averagedover 10 preceeding blocks.classes for nouns have theoretical linguistic jus-tification, it is harder to motivate a latent spacerepresentation for example for proper nouns.Therefore, we want to evaluate the advantageof using spectral embedding only for nouns.?
collection dependence of similarities.
The sim-ilarity matrix S is computed using the TDT2corpus (GLSAlocal) and using the larger Giga-Word corpus.
The larger corpus provides morereliable co-occurrence statistics.
On the otherhand, word distribution is different from thatin the TDT2 corpus.
We wanted to evaluatewhether semantic similarities are collection in-dependent.Table 4 shows the performance evaluation.
We showthe results computed using blocks containing 20words (after preprocessing) with step size 10.
Wetried other parameter values but did not achieve bet-ter performance, which is consistent with other re-search (Hearst, 1994; Galley et al, 2003).
We showthe results for two settings: predict a known num-ber of boundaries, and predict boundaries using athreshold.
In our experiments we used the averageof the smallest N scores as threshold, N = 4000showing best results.357The spectral embedding based representations(GLSA, Hybrid) significantly outperform the base-line.
This confirms the advantage of the semanticcohesion score vs. term-matching.
Hybrid index-ing outperforms the GLSA representation support-ing our intuition that semantic association is best de-fined for nouns.We used the GigaWord corpus to obtain the pair-wise word associations for the GLSA and Hybridrepresentations.
We also computed GLSAlocal andHybridlocal using the TDT2 corpus to obtain thepair-wise word associations.
The co-occurrencestatistics based on the GigaWord corpus providemore reliable estimations of semantic associationdespite the difference in term distribution.
The dif-ference is larger for the GLSA case when we com-pute the embedding for all words, GLSA performsbetter than GLSAlocal.
Hybridlocal performs onlyslightly worse than Hybrid.
This seems to supportthe claim that semantic associations between nounsare largely collection independent.
On the otherhand, semantic associations for proper names arecollection dependent at least because the collectionsare static but the semantic relations of proper namesmay change over time.
The semantic space for aname of a president, for example, is different for theperiod of time of his presidency and for the time be-fore and after that.Disappointingly, we could not achieve good re-sults with LCseg.
It tends to split stories into shortparagraphs.
Hybrid indexing could achieve resultscomparable to state-of-the art approaches, see (Fis-cus et al, 1998) for an overview.6 Conclusion and Future WorkWe presented a topic segmentation approach basedon semantic cohesion scores.
Our approach is do-main independent, does not require training or useof lexical resources.
The scores are computed basedon the hybrid document indexing which uses spec-tral embedding in the space of latent concepts fornouns and keeps proper nouns and other specifics ofthe documents collections unchanged.
We approxi-mate the lexical chains approach by simplifying thedefinition of a chain which allows us to use innerproducts as basis for the similarity score.
The simi-larity score takes into account semantic relations be-tween nouns beyond term matching.
This semanticcohesion approach showed good results on the topicsegmentation task.We intend to extend the hybrid indexing approachby considering more vocabulary subsets.
Syntacticsimilarity is more appropriate for verbs, for exam-ple, than co-occurrence.
As a next step, we intend toembed verbs using syntactic similarity.
It would alsobe interesting to use lexical chains for proper namesand learn the weights for different similarity scores.ReferencesJ.
Allan, editor.
2002.
Topic Detection and Tracking:Event-based Information Organization.
Kluwer Aca-demic Publishers.Doug Beeferman, Adam Berger, and John D. Lafferty.1999.
Statistical models for text segmentation.
Ma-chine Learning, 34(1-3):177?210.Paolo Bientinesi, Inderjit S. Dhilon, and Robert A. van deGeijn.
2003.
A parallel eigensolver for dense sym-metric matrices based on multiple relatively robustrepresentations.
UT CS Technical Report TR-03-26.Freddy Choi, Peter Wiemer-Hastings, and JohannaMoore.
2001.
Latent Semantic Analysis for text seg-mentation.
In Proceedings of EMNLP, pages 109?117.Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-dauer, George W. Furnas, and Richard A. Harshman.1990.
Indexing by Latent Semantic Analysis.
Jour-nal of the American Society of Information Science,41(6):391?407.J.
G. Fiscus, George Doddington, John S. Garofolo, andAlvin Martin.
1998.
NIST?s 1998 topic detection andtracking evaluation (tdt2).
In Proceedings of NIST?s1998 Topic Detection and Tracking Evaluation.M.
Galley, K. McKeown, E. Fosler-Lussier, and H. Jing.2003.
Discourse segmentation of multi-party conver-sation.
In Proceedings of ACL.G.
Golub and C. Reinsch.
1971.
Handbook for Ma-trix Computation II, Linear Algebra.
Springer-Verlag,New York.V.
Hatzivassiloglou, Luis Gravano, and Ankineedu Mag-anti.
2000.
An investigation of linguistic features andclustering algorithms for topical document clustering.In Proceedings of SIGIR, pages 224?231.V.
Hatzivassiloglou, Regina Barzilay Min-Yen Kan Ju-dith L. Klavans, Melissa L. Holcombe, and Kath-leen R. McKeown.
2001.
Simfinder: A flexible358clustering tool for summarization.
In Proceedings ofNAACL, pages 41?49.Marti A. Hearst.
1994.
Multi-paragraph segmentation ofexpository text.
In Proceedings of ACL, pages 9?16.Hideki Kozima.
1993.
Text segmentation based on sim-ilarity between words.
In Proceedings of ACL, pages286?288.Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.2005.
Dictionary-based techniques for cross-languageinformation retrieval.
Information Processing andManagement: Special Issue on Cross-language Infor-mation Retrieval.Irina Matveeva and Gina-Anne Levow.
2006.
Graph-based Generalized Latent Semantic Analysis for docu-ment representation.
In Proc.
of the TextGraphs Work-shop at HLT/NAACL.Irina Matveeva, Gina-Anne Levow, Ayman Farahat, andChristian Royer.
2005.
Generalized Latent SemanticAnalysis for term representation.
In Proc.
of RANLP.Lev Pevzner and Marti A. Hearst.
2002.
A critique andimprovement of an evaluation metric for text segmen-tation.
Comput.
Linguist., 28(1):19?36.Gerard Salton and Michael J. McGill.
1983.
Introductionto Modern Information Retrieval.
McGraw-Hill.Noam Slonim and Naftali Tishby.
2000.
Document clus-tering using word clusters via the information bottle-neck method.
In Research and Development in Infor-mation Retrieval, pages 208?215.Peter D. Turney.
2001.
Mining the web for synonyms:PMI?IR versus LSA on TOEFL.
Lecture Notes inComputer Science, 2167:491?502.C.
Wayne.
2000.
Multilingual topic detection and track-ing: Successful research enabled by corpora and eval-uation.
In Proceedings of Language Resources andEvaluation Conference (LREC), pages 1487?1494.359
