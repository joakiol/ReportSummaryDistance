THE LRC MACHINE TRANSLAT ION SYSTEMWinf ie ld  S. Bennet t  1Siemens Communication Systems, Inc.J onathan  S locumMicroelectronics and ComputerTechnology Corporat ion (MCC)The Linguistics Research Center (LRC) of the University of Texas at Austin is currently developingMETAL, a fully-automatic high quality Machine Translation (MT) system.
After outlining the historyand status of the project, this paper discusses the system's projected application environment andbriefly describes our general translation approach.
After detailing the salient linguistic and compu-tational techniques on which METAL is based, we consider some of the practical aspects of such anapplication, including experimental results that imply the system is now ready for production use.
Twoexhibits are appended: a German original text and its raw METAL translation.
(This is not the besttranslation ever produced by METAL, but it is better than average.)
We close by indicating somefuture directions for the project.1 HISTORY AND STATUSMachine translation research at the LRC began with thefounding of the center in 1961.
For much of the historyof this research, funding came from the U.S. Air Force'sRome Air Development Center and other U.S. govern-ment agencies.
In January 1979, Siemens AG beganfunding the current development phase of the METALsystem; the project then comprised one full-time and fiveor six half-time workers.
As a result of Siemens'ssupport, the existing system was scrapped and a newimplementation effort was undertaken in the spring ofthat year; the project staff grew slowly at first, but with arecent substantial increase now numbers seven full-timeand five half-time workers.
The first operational versionof the system was delivered to the sponsor for markettesting in January 1985.The current system translates only from German intoEnglish, although work to add other Target Languages(Spanish and Chinese), as well as a second SourceLanguage (English), is underway.
The German grammarin its present form contains more than 600 rules; the lexi-con has well in excess of 20,000 monolingual entries forGerman and English, and is expected to double in size inthe near future.2 APPL ICATION ENVIRONMENTLike any modern MT system, METAL is to be used in atechnical translation environment where human revisionof the output is expected - just as is the case with humantranslation around the world.
The justification for usingan MT system is a combination of pure economics (costreduction) and necessity (to achieve the desired speed,perhaps required to get the job done at all); the trade-offbetween these two differs, depending on the organizationand circumstance.
In general, we expect that the LRCMT system must prove cost-effective in order to gain useracceptance: speed per se will be a secondary consider-ation.
This means that the cost of using METAL for drafttranslation, and a human revisor thereafter, must besignificantly \[not marginally\] less than the cost of usinghumans for draft translation, and a human revisor there-after; the cost of "using" METAL must include its fullamortization, etc.In an environment of technical translation, particularlyof operation and maintenance manuals, one of the bigproblems is text format.
As a glance at any technicalmanual will show, it is not the case that all material in adocument must or can be translated.
Large portions of at Current address: Linguistics Research Center; P.O.
Box 7247;University Station; Austin, TX 78712Copyright1985 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is granted provided thatthe copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or  specific permission.0362-613X/85/020111-121503.00Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985 111Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation Systemformatted text (up to 50% of the characters, in our expe-rience) may not be translatable; the bulk of this may falloutside "sentence" boundaries, but some will fall withinthem.
Thus, it is necessary for a text to be marked, orannotated, to distinguish that which is to be translated(e.g., tables of contents, instructions, prose paragraphs)from that which is not (e.g., flowchart box boundaries,sentence-internal formulas and acronyms, and variousattention-focusing devices).
The translatable units (notalways "complete sentences") must then be extracted,translated, and finally reconstituted so as to appear likethe original text.In the LRC MT system, special programs have beendeveloped to handle the formatting problems associatedwith technical manuals.
This software automaticallymarks texts and extracts translatable units for input toMETAL, and reformats the translation afterwards(Slocum and Bennett 1982; Slocum et al 1984).
Theonly human intervention expected prior to translation ischecking and correcting the output of the routines thatmark translatable units; the human does not, for exam-ple, resolve anaphora or disambiguate homographs orword senses.
Nothing in the LRC MT system providesfor human intervention during the actual translationphase.Text processing is presently done on a DEC-2060,post-editing on a PDP-11, and the actual translation onSymbolics Lisp Machines.
For the foreseeable future aLisp Machine will continue to be used as the "translationengine."
The project sponsor is constructing a microcom-puter .front end supporting four to six translator work-stations (as well as OCR devices, floppy-disk drives,printers, 'etc.
), on which texts will be prepared and sentto the batch translation unit, and on which the output willbe reformatted and revised; software specially suited totext preparation and post-editing is being programmed.Thus, the production version will constitute a completetranslation environment.3 GENERAL TRANSLATION APPROACHIn METAL, translation proper consists of four successivephases: Analysis (parsing), Integration, Transfer, andSynthesis (generation).
The Integration phase workswith analysis tree structures, performing (at the presenttime) inter- and extra-sentential naphora resolution.Until recently, the Transfer and Synthesis phases wereessentially a single phase, but work is in progress to splitthis phase, and introduce a much more powerful Synthe-sis phase.
In this section we describe "Transfer" anddefend it as our general translation approach; in the nextsection we discuss our linguistic techniques more fully.It is frequently argued that translation should be aprocess of analyzing the Source Language (SL) into a"deep representation" of some sort, then directly synthe-sizing the Target Language (TL) (e.g.
Carbonell 1978).We and others (King 1981) contest his claim - especial-ly with regard to "similar languages" (e.g., those in theIndo-European family).
One objection is based on large-scale, long-term trials of the "deep representation" (inMT, called the "pivot language") approach by the CETAgroup at Grenoble (Boitet and Nedobejkine 1980).After an enormous investment in time and energy,including experiments with massive amounts (400,000words) of text, it was decided that the development of asuitable pivot language (for use in Russian-French trans-lation) was not yet possible.
Another objection is basedon practical considerations: ince it is not likely that anyNLP system will in the foreseeable future become capableof handling unrestricted input - even in the technicalarea(s) for which it might be designed - it is clear that a"fail-soft" technique is necessary.
It is not obvious thatsuch is possible in a system based solely on a pivotlanguage; a hybrid system capable of dealing with shal-lower levels of understanding seems necessary in a prac-tical setting.
This being the case, it is better in near-termapplications to start off with a system employing a"shallow" but usable level of analysis, and deepen thelevel of analysis as experience dictates, and theory plusproject resources permit.The standard alternative, which we have adopted, is tohave a transfer component that maps "shallow analyses ofsentences" in the SL into "shallow analyses of equivalentsentences" in the TL, from which synthesis then takesplace.
This assumes the form of a transfer dictionary anda transfer grammar.
While we and the rest of the NLPcommunity continue to explore the nature of an adequatepivot language (i.e., the nature of deep semantic modelsand the processing they entail), we can, we believe,proceed to construct usable systems amenable toprogressive nhancement as linguistic theory becomesable to support deeper models.4 LINGUISTIC TECHNIQUESOur distinction between "linguistic techniques" and"computational techniques" (discussed in the next majorsection) is somewhat artificial, but it has some validity ina broad sense, as should become clear from an overviewof the points considered.
In this section we discuss ouruse of the following linguistic techniques:?
allomorphic lexical analysis;?
a phrase-structure grammar;?
syntactic features;?
semantic features;?
scored interpretations;?
transformations indexed to specific rules; and?
attached procedures to effect translation.4.1 ALLOMORPHIC LEXICAL ANALYSISEntries in METAL monolingual dictionaries are indexedby both canonical form (the usual spelling one finds in aprinted dictionary) and allomorph (the stem, withoutproductive affixes).
The affixes themselves are separatedictionary entries; although their semantics is necessarilydifferent in kind from content morphemes, they are treat-ed identically by the system software.
If a particular112 Computational Linguistics, Volume 1 !, Numbers 2-3, April-September 1985Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation Systemstem exhibits internal inflection (e.g., German nouns thatumlaut in the plural), or varies for other reasons, thenmultiple entries are stored, one for each stem variation\[allomorph\].
At first this may seem wasteful, but themajority of such cases in our dictionaries are Germanstrong verbs - which sometimes behave differently,depending on inflection, and thus would require separateentries anyway.At system-generation time, the allomorphs are enteredinto a letter tree, which is searched uring lexical analy-sis.
The analysis of a word occurrence, then, is normallyone or more sequences of morphemes (stems and affixes,mixed), each morpheme being an allomorph correspond-ing to one or more dictionary entries.
These are fed tothe parser as if they had been separate \[alternativesequences of\] "words" in the text (except that eachmorpheme is marked according to whether it was word-initial and/or word-final), which parses them \[back\] intowords while it is parsing the words into a sentence.
Lexi-cal ambiguity (including homography and polysemy, aswell as ambiguity in morphological decomposition) istolerated as a natural phenomenon i the system, and isresolved according to a scoring scheme, discussed below,which handles yntactic ambiguity as well.4.2 PHRASE STRUCTURE GRAMMARIn the LRC MT system we employ a phrase-structuregrammar, augmented by strong lexical controls andextensive use of transformations.
The LRC MT system iscurrently equipped with over 600 PS rules describing thebest-developed Source Language (German), and over10,000 lexical entries in each of the two main languages(German and English).
The current state of our cover-age of German is that the system is able to parse andacceptably translate the majority of sentences in previ-ously-unseen texts, within the subject areas bounded byour dictionaries.
We have recently begun the process ofadding to the system an analysis grammar of the currentTL (English), so that the direction of translation may bereversed; we anticipate bringing the English grammar upto the level of the German grammar in a few years' time.Our expectations for eventual coverage are that, for eachSL, around 1,000 PS rules will be adequate to account foralmost all sentence forms actually encountered in techni-cal texts.
We do not feel constrained to account forevery possible sentence form in such texts - and certainlynot for sentence forms never found in such texts (as inthe case of poetry) - since the required effort would notbe cost-effective, whether measured in financial orhuman terms, even if it were possible using currentlinguistic techniques (which we doubt).4.3 SYNTACTIC FEATURESOur use of syntactic features is relatively noncontrover-sial, given our choice of the PS rule formalism.
Weemploy syntactic features for two purposes.
One is theusual practice of using such features to restrict he appli-cation of PS rules (e.g., by enforcing subject-verbnumber agreement).
The other use is perhaps peculiar toour type of application: once an analysis is achieved,certain syntactic features are employed to control thecourse (and outcome) of translation - i.e., generation ofthe TL sentence.
The "augmentations" to our PS rulesinclude operators that manipulate features by restrictingtheir presence, their values if present, etc., and bymoving them from node to node in the parse tree duringthe course of the analysis.
As is the case with otherresearchers employing such techniques, we have foundthis to be an extremely powerful (and, of course, neces-sary) means of restricting the activities of the parser.4.4 SEMANTIC FEATURESWe employ simple semantic features, as opposed tocomplex models of the domain.
Our reasons are primari-ly practical.
First, features eem sufficient for at least theinitial stage of our application.
Second, the thought ofwriting complex models of even one complete technicaldomain is staggering: one set of operation and mainte-nance manuals we have worked with (describing a digitaltelephone switching system) is part of a documentcollection that is expected to comprise some 100,000pages of text when complete.
A typical NLP researchgroup would not even be able to read that volume ofmaterial, much less write the "necessary" semanticmodels subsumed by it, in any reasonable amount oftime.
(The group members would also have to becomeelectronics engineers, in all likelihood, in order to under-stand the text.)
If such models are indeed required forour application, we will never succeed.As it turns out, we are doing surprisingly well withoutsuch models.
In fact, our semantic feature system is notyet being employed to restrict the analysis effort at all;instead, it is used during Transfer to improve the qualityof the translations, primarily of prepositions.
We lookforward to extending the use of semantic features toother parts of speech, and to substantive utilizationduring analysis; but even we have been surprised at theresults achieved using only syntactic features during anal-ysis.4.5 SCORED INTERPRETATIONSIt is a well-known fact that NLP systems tend to producemany readings of their input sentences (unless, of course,constrained to produce the first reading only - which canresult in the "right" interpretation being overlooked).The LRC MT system may produce multiple interpreta-tions of the input "sentence," assigning each of them ascore, or plausibility factor (Robinson 1982).
This tech-nique can be used, in theory, to select a "best" interpre-tation from the available readings of an ambiguoussentence.
We base our scores on both lexical preferenc-ing and grammatical phenomena - plus the types of anyspelling/typographical errors, which can sometimes be"corrected" in more than one way.Scoring begins at the lowest level of the tree - at themorpheme level, based on lexical preference coded forComputational Linguistics, Volume 11, Numbers 2-3, April-September !
985 113Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation Systemdictionary entries (one per allomorph) and any spellingcorrection factors - and propagates upwards as the anal-ysis proceeds.
Homography and polysemy are dealt withas a natural consequence of the selection, from among allalternatives, of the most plausible \[highest scoring\]reading(s).
Thus, nowhere in the system is there specialprovision for dealing with these problems: all sources ofambiguity are handled by the identical mechanism.Our experiences relating to the reliability and stabilityof heuristics based on this technique are decidedly posi-tive: we employ only the highest-scoring reading fortranslation (the others are discarded), and our informalexperiments indicate that it is rarely true that a bettertranslation results from a lower-scoring analysis.
(Surprisingly often, a number of the higher-scoring inter-pretations will be translated identically.
But poorertranslations are frequently seen from the lower-scoringinterpretations, demonstrating that the technique isindeed effective.)
This does require some careful"tuning" by the linguists, but this has been a manageableproblem.4.6 INDEXED TRANSFORMATIONSWe employ a transformational component, during boththe analysis phase and the translation phase.
The trans-formations, however, are indexed to specific syntax rules,or even lexical entries, rather than loosely keyed tosyntactic onstructs.
(Actually, both styles are available,but our linguists have never seen the need or practicalityof employing the open-ended variety.)
It is clearly moreefficient to index transformations to specific rules orwords when possible; the import of our findings is that itseems to be unnecessary to have open-ended transforma-tions - even during analysis, when one might intuitivelyexpect them to be useful.
A transformation tied to aparticular syntactic rule may be written as part of thatrule, or called by name if the linguist wishes several rulesto share the same transformation (e.g., a 12-21 constitu-ent reversal is common).4.7 ATI'ACHED TRANSLATION PROCEDURESOur Transfer procedures (which effect the actual trans-lation of SL into TL) are tightly bound to nodes in theanalysis (parse tree) structure (Paxton 1977).
They are,in effect, suspended procedures - parts of the sameprocedures that constructed the corresponding parse treenodes to begin with.
We prefer this over a more general,loose association based on, e.g., syntactic structurebecause, aside from its advantage in sheer computationalefficiency (search for matching structural transfer ules iseliminated), it prevents the "wrong" procedure frombeing applied to a construct.
The only real argumentagainst this technique, as we see it, is based on spaceconsiderations: to the extent that different constructsshare the same transfer operations, wasteful replicationof the procedures that implement said operations (andediting effort to modify them) is possible.
We have notnoticed this to be a problem.
For a while, our systemload-up procedure searched for duplicates of this natureand automatically eliminated them; however, the gainsturned out to be minimal: different structures typically dorequire different ranslation operations.5 COMPUTATIONAL TECHNIQUESAgain, our separation of "linguistic" from "compu-tational" techniques is somewhat artificial, but neverthe-less useful.
In this section we discuss our use of thefollowing computational techniques:?
a "some-paths", parallel, bottom-up arser;?
associated rule-body procedures;?
spelling correction;?
another fail-soft analysis technique; and?
recursive parsing of parenthetical expressions.5.1 SOME-PATHS, PARALLEL, BOTTOM-UP PARSERAmong all our choices of computational techniques, theuse of a "some-paths", parallel, bottom-up parser isprobably the most controversial.
Our current parseroperates on the sentence in a well-understood parallel,bottom-up fashion; however, the notion of "some-paths"will require some explanation.
In the METAL system, thegrammar ules are grouped into "levels" indexed numer-ically (0, 1, 2 .... ), and the parser always applies rules at alower level (e.g., 0) before applying any rules at a higherlevel (e.g., 1).
Thus, the application of rules is partiallyordered.
Furthermore, once the parser has applied allrules at a given level it halts if there exist one or more"sentence" interpretations of the input; only if there arenone does it apply more rules - and then, it always startsback at level 0 (in case any rules at that level have beenactivated through the application of rules at a higherlevel, as can happen with a recursive grammar).
Thus,the rule-application algorithm is Markov-like, and thesystem will not necessarily produce all interpretations ofan input possible with the given rule base.
Generallyspeaking, the lower-level rules are those most likely tolead to readings of an input sentence, and the higher-lev-el rules are those least likely to be relevant (though theymay be necessary for particular input sentences, in whichcase they will eventually be applied).
As a result, thereadings derived by our parser are the "most likely"readings (as judged by the linguists, who assign the rulesto levels).
This works very well in practice.Our evolving choices of parsing methodologies havereceived our greatest experimental scrutiny.
We havecollected a substantial body of empirical evidence relat-ing to parsing techniques and strategy variations.
Sinceour evidence and conclusions would require lengthydiscussion, and have received some attention elsewhere(Slocum 1981), we will only state for the record that ouruse of a some-paths, parallel, bottom-up arser is justi-fied based on our findings.
First of all, all-paths parsershave certain desirable advantages over first-path parsers(discussed below); second, our some-paths parser (whichis a variation on an all-paths technique) has displayed114 Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation Systemclear performance advantages over its predecessor tech-nique: doubling the throughput rate while increasing theaccuracy of the resulting translations.
We justify ourchoice of technique as follows:- first, the dreaded "exponential explosion" of process-ing time has not appeared, on the average (and ourgrammar and test texts are among the largest in theworld), but instead processing time appears to be line-ar with sentence length - even though our system mayproduce all possible readings;- second, top-down parsing methods suffer inherentdisadvantages in efficiency;- third, it is difficult to persuade a top-down parser tocontinue the analysis effort to the end of the sentence,when it blocks somewhere in the middle - whichmakes the implementation of "fail-soft" techniqueshaving production utility that much more difficult; and- last, the lack of any strong notion of how to constructa "best-path" parser, coupled with the raw speed ofwell-implemented parsers, implies that a some-pathsparser that scores interpretations and can continue theanalysis to the end of the sentence, come what may,may be best in a contemporary application such asOURS.5.2 ASSOCIATED RULE-BODY PROCEDURESWe associate a procedure directly with each individualsyntax rule, and evaluate it as soon as the parser deter-mines the rule to be (seemingly) applicable (Pratt 1973;Hendrix et al 1978) - hence the term ru le -body  proce-dure .
This practice is equivalent to what is done in ATNsystems.
From the linguist's point of view, the contentsof our rule-body procedures appear to constitute a formallanguage dealing with syntactic and semanticfeatures/values of nodes in the tree - i.e., no knowledgeof LISP is necessary to code effective procedures.
Sincethese procedures are compiled into LISP, all the power ofLISP is available as necessary.
The chief linguist on ourproject, who has a vague knowledge of LISP, hasemployed OR and AND operators to a significant extent(we didn't bother to include them in the specifications ofthe formal language, though we obviously could have),and on rare occasions has resorted to using COND.
Noother calls to true LISP functions (as opposed to ourformal operators, which are few and typically quite primi-tive) have seemed necessary, nor has this capability beenrequested, to date.
The power of our rule-body proce-dures seems to lie in the choice of features/values thatdecorate the nodes, rather than the processing capabili-ties of the procedures themselves.5.3 SPELLING CORRECTIONThere are limitations and dangers to spelling correction ingeneral, but we have found it to be an indispensablecomponent of an applied system.
People do make spell-ing and typographical errors, as is well known; even in"polished" documents they appear with surprisingfrequency (about every page or two, in our experience).Arguments by LISP programmers egarding INTERLISP'sDWIM aside, users of applied NLP systems distinctlydislike being confronted with requests for clarification -or, worse, unnecessary failure - in lieu of automatedspelling correction.
Spelling correction, therefore, isnecessary.Luckily, almost all such errors are treatable withsimple techniques: single-letter additions, omissions, andsubstitutions, plus two- or three-letter transpositionsaccount for almost all mistakes.
Unfortunately, it is notinfrequently the case that there is more than one way to"correct" a mistake (i.e., resulting in different correctedversions).
Even a human cannot always determine thecorrect form in isolation, and for NLP systems it is evenmore difficult.
There is yet another problem with auto-matic spelling correction: how-much to correct.
Givenunlimited rein, any word can be "corrected" to any other.Clearly there must be limits, but what are they?Our informal findings concerning how much one maysafely "correct" in an application such as ours are these:the few errors that simple techniques have not handledare almost always bizarre (e.g., repeated syllables or larg-er portions of words) or highly unusual (e.g., blanksinserted within words); correction of more than a singleerror in a word is dangerous (it is better to treat the wordas unknown, hence a noun); and "correction" of errorsthat have converted one word into another (valid inisolation) should not be tried.5.4 FAIL-SOFF GRAMMATICAL ANALYSISIn the event of failure to achieve a comprehensive analy-sis of the sentence, a system such as ours - which is to beapplied to hundreds of thousands of pages of text -cannot indulge in the luxury of simply replying with anerror message stating that the sentence cannot be inter-preted.
Such behavior is a significant problem, onewhich the NLP community has failed to come to gripswith in any coherent fashion.
There have, at least, beensome forays.
Weischedel and Black (1980) discuss tech-niques for interacting with the linguist/developer to iden-tify insufficiencies in the grammar.
This is fine forsystem development purposes.
But, of course, in anapplied system the user will be neither the developer nora linguist, so this approach has no value in the field.Hayes and Mouradian (1981) discuss ways of allowingthe parser to cope with ungrammatical utterances; suchwork is in its infancy, but it is stimulating nonetheless.We look forward to experimenting with similar tech-niques in our system.What we require now, however, is a means of dealingwith "ungrammatical" input (whether through thehuman's error or the shortcomings of our own rules) thatis highly efficient, sufficiently general to account for alarge, unknown range of such errors on its first andsubsequent outings, and which can be implemented in ashort period of time.
We found just such a techniqueseveral years ago: a special procedure (invoked when theanalysis effort has been carried through to the end of theComputational Linguistics, Volume 11, Numbers 2-3, April-September 1985 115Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation Systemsentence) searches through the parser's chart to find theshortest path from one end to the other; this path repre-sents the fewest, longest-spanning phrases constructedduring the analysis.
Ties are broken by use of the stand-ard scoring mechanism that provides each phrase in theanalysis with a score, or plausibility measure (discussedearlier).
We call this procedure phrasal analysis.Our phrasal analysis technique has proven to be usefulfor both the developers and the end users, in our applica-tion: the system translates each phrase individually, whena comprehensive s ntence analysis is not available.
Thelinguists use the results to pin-point missing (or faulty)rules.
The users (who are professional translators, edit-ing the MT system's output) have available the besttranslation possible under the circumstances, rather thanno usable output of any kind.
Phrasal analysis - which issimple and independent of both language and grammar -should prove useful in other applications of NLP technol-ogy; indeed, IBM's EPISTLE system (Miller et al 1980)employs an almost identical technique (Jensen & Heidorn1982).5.5 RECURSIVE PARSING OF PARENTHETICALEXPRESSIONSFew NLP systems have ever dealt with parentheticalexpressions; but MT researchers know well that theseconstructs appear in abundance in technical texts.
Wedeal with this phenomenon i the following way: ratherthan treating parentheses as lexical items, we make use ofLISP's natural treatment of them as list delimiters, andtreat the resulting sublists as individual "words" in thesentence; these "words" are "lexically analyzed" viarecursive calls to the parser, which, of course, actuallyperforms grammatical analysis.
Besides sheer elegance,this has the added advantage that "ungrammatical"parenthetical expressions may undergo phrasal analysisand thus become single-phrase entities as far as the anal-ysis of the encompassing sentence is concerned; thus,ungrammatical parenthetical expressions need not resultin ungrammatical (hence poorly handled) sentences.6 PRACTICAL CONSIDERATIONSFrom a user's viewpoint, there are four aspects on whichMT systems hould be judged: text preparation, diction-ary update, actual translation, and post-editing.
Otherthan dictionary update, these aspects are discussed else-where in this paper.
We will therefore comment on ourlexical maintenance procedures, and the users' accept-ance thereof, before proceeding to our experimentalresults.6.1 LEXICAL MAINTENANCEThe factors important to the terminologists who maintainlexical data bases include the kinds of information thatone is required to supply, and the method used to enterthat information in the dictionary (Whiffin, in press).
Ifthe lexical coding process is too complex, semantic errorswill multiply and translation quality will suffer.
Menuschemes wherein one selects the proper value of a featurefrom a short (10 item) list of options are greatlypreferred over long lists of options or, worse, a schemewherein one must volunteer the information via type-in.Even better is a scheme wherein the system, with mini-mal clues (e.g., root form and part of speech) generatesan entry likely to be mostly correct, which the terminolo-gist then verifies and edits (again, via menu selection) asnecessary.
Needless to say, arcane codes that one musthave a manual to keep track of are to be avoided at allcost.The lexicon for METAL is stored in an on-line DBMSwritten in LISP.
Input of lexical entries is facilitated byan INTERCODER, a menu-driven interface that asks theuser for information in English and converts the answersinto the internal form used by the system.
An integralpart of the INTERCODER is the "lexical default"program that accepts minimal information about theparticular entry (root form and lexical category) andheuristically encodes most of the remaining necessaryfeatures and values.
Entries may also be created usingany text editor, without the aid of the INTERCODER orlexical defaulter.Interfacing with the lexical data base is done by meansof a number of functions that permit the user to access,edit, copy, and/or  delete entries individually, in smallgroups (using specific features), by entire categories, orin toto (essentially no longer done for reasons of size).In order to assure a high degree of lexicon integrity theMETAL system includes validation programs that identifyerrors in format and/or  syntax.
The validation process isautomatically used to check lexical items that have beenedited or added, to ensure that no errors have been intro-duced.Our terminologists indicate substantial subjectivesatisfaction with METAL's lexical coding scheme.Performance measurements indicate that, for categoriesother than verbs, a very few (2-5) minutes is all that isrequired to enter a pair of terms (in two languages, thusthree dictionaries including Transfer); for verbs, theprocess is more complex, requiring as much as 20minutes per word pair.
But these times include the termi-nology research per se - i.e., the process of discoveringor generating a proper translation of a term - so theoverall burden of lexical maintenance seems quite accept-able, and cost-effectiveness i  not adversely affected.6.2 EXPERIMENTAL RESULTSIn the last five years, METAL has been applied to thetranslation into English of over 1,000 pages of Germantelecommunication a d data processing texts.
To date,no definitive comparisons of METAL translations withhuman translations have been attempted.
(It is not obvi-ous that this would be relevant, or of significant benefit.
)However, some stimulating quantitative and qualitativestatistics have been gathered.Measuring translation quality is a vexing problem - aproblem not exclusive to machine translation or technical116 Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation Systemtexts, to be sure.
In evaluating claims of "high-quality"MT, one must carefully consider how "quality" isdefined; "percentage of words \[or sentences\] correct \[oracceptable\]", for example, requires definition of theoperative word, "correct".
A closely related question isthat of who determines correctness.
Acceptability is ulti-mately defined by the user, according to his particularneeds: what is acceptable to one user in one situationmay be quite unacceptable in another situation, or toanother user in the same situation.
For example, someprofessional post-editors have candidly informed us thatthey actually look forward to editing MT output becausethey "can have more control over the result".
For socio-logical reasons, there seems to be only so much that theydare change in human translations; but as everyoneknows (and our informants pointed out), "the machinedoesn't care."
The clear implication here is that"correctness" has traditionally suffered where humantranslation is concerned; or, alternately, that"acceptability" depends in part on the relationshipbetween the translator and the revisor.
Either way,judgements of "correctness" or "acceptability" by post-editors is likely to be more harsh when directed towardMT than when directed toward human translation (HT).It is not yet clear what the full implications of this situ-ation are, but the general import should be of someconcern to the MT community.
Since the errors commit-ted by an MT system seldom resemble rrors made byhuman translators, the possibility of a "Turihg test" foran MT system does not exist at the current ime.For different (and obvious) reasons, qualitativeassessments by MT system vendors are subject to bias -generally unintentional - and must be treated withcaution.
But one must also consider other circumstancesunder which the measurement experiment is conducted:whether (and for how long, and in what form) the textbeing translated, and/or its vocabulary, was made avail-able to the vendor before the experiment; whether theMT system was previously exercised on that text, or simi-lar.texts; etc.
At the LRC, we conduct two kinds ofmeasurement experiments: "blind", and "follow-up".When a new text is acquired from the project sponsor, itsvocabulary is extracted by various lexical analysis proce-dures and given to the lexicographers who then write("code") entries for any novel words discovered in thelist.
The linguistic staff never sees the text prior to ablind experiment.
Once the results of the blind trans-lation are in, the project staff are free to update thegrammar ules and lexical entries according to what islearned from the test, and may try out their revisions onsample sentences from the text.
Some time later, thesame text is translated again, so that some idea of theamount of improvement can be obtained.6.3 TRANSLATION SPEEDOn our Symbolics 3600 LISP Machine, with 512K 36-bitwords of physical memory, preliminary measurementsindicate an average performance of about 2+ seconds(real time) per input word; this is already 10 times thespeed of a human translator, for like material.
Thepaging rate indicates that, with added memory, we couldexpect a significant boost in this performance ratio; forother (predictable) reasons, as well, further speedincreases are anticipated.6.4 CORRECTNESSIn addition to collecting some machine performancestatistics, we count the number of "correct" sentencetranslations and divide by the total number of sentenceunits in the text, in order to arrive at a "correctness"figure.
(For our purposes, "correct" is defined as "notedto be unchanged for morphological, syntactic, or seman-tic reasons, with respect to the original machine trans-lation, after revision by professional post-editors iscomplete."
Non-essential stylistic changes are not consid-ered to be errors.)
In the course of experimenting withover 1,000 pages of text in the last five years, our"correctness" figures have varied from 45% to 85% (offull-sentence units) depending on the individual text andwhether the experiment was of the "blind" or "follow-up" variety.
During a recent "blind" test, for example,METAL achieved a 75% "correctness" figure on amoderately long text (ca.
10 pages).6.5 INTERPRETATION OF THE RESULTSCertain objections have been raised concerning the pres-ent feasibility of MT.
It has been argued that, unless anMT system constitutes an almost perfect ranslator, it willbe useless in any practical setting (Kay 1980).
As weinterpret it, the argument proceeds omething like this:(1) there are classical problems in ComputationalLinguistics that remain unsolved to this day (e.g.,anaphora, quantifiers, conjunctions);(2) these problems will, in any practical setting,compound on one another so as to result in a verylow probability that any given sentence will becorrectly translated;(3) it is not in principle possible for a system sufferingfrom malady (1) above to reliably identify and markits probable rrors;(4) if the human post-editor must check every sentenceto determine whether it has been correctly trans-lated, then the translation is useless.We accept claims (1) and (3) without question.
Weconsider claim (2) to be a matter for empirical validation- surely not a very controversial contention.
As ithappens, a substantial body of empirical evidence gath-ered at the LRC to date refutes such claims: the"correctness" figures reported above (measured by oursponsor's post-editors) establish this contention.
\[Inpoint of fact, we consider "correctness" figures to bevirtually meaningless, aside from being unreliable, as willbecome obvious.
But Kay's claim (2) assumes that"correctness" is a valid measure, and thus falls in eithercase.\]Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985 117Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation SystemRegarding (4), we embrace the assumption that ahuman post-editor will have to check the eniire trans-lation, sentence-by-senfence; but we argue that Kay'sconclusion ("then the translation is useless") is againproperly a matter for empirical validation.
Meanwhile,we are operating under the assumption that this conclu-sion is patently false - after all, where translation is takenseriously, human translations are routinely edited viaexhaustive review, but no one claims that they are there-fore useless!
In other words, Kay's claim (4) also falls,based on empirical evidence that relates to HT directly -but, by extension, to MT as well.6.6 ACCEPTANCE AND COST-EFFECTIVENESSThere is a meaningful, more-or-less objective metric bywhich any MT system can and should be judged: overall(man/machine) translation performance.
The idea issimple.
The MT system must achieve two simultaneousgoals: first, the system's output must be acceptable to thepost-editor for the purpose of revision; second, the costof the total effort (including amortization and mainte-nance of the hardware, the software, and the diction-aries) must be less than the current alternative for likematerial - human translation followed by post-editing.Regarding user acceptance, we can relate that theeditors revising METAL translations in a series of exper-iments spanning the past few years have recently statedthat the system has achieved a level of quality that theyfind acceptable for their day-to-day work (Whiffin,personal communication).
From our experimentalevidence, it would seem that this is a harder goal to reachthan mere cost-effectiveness; i.e., "cost-effectiveness"can be demonstrated in experimental settings, with anoutput quality that the editors will not accept on a dailybasis.
In addition, translators have noted that the timerequired to create a triple of METAL dictionary entries -monolingual German term, monolingual English equiv-alent, and bilingual Transfer pair - varies from two totwenty minutes, depending on the part of speech and theamount of terminology research \[needed for humantranslation in any case\] required.
On an on-going aver-age basis, a new term can be expected once per page oftext.Until METAL is evaluated by unbiased third parties,taking into account the full costs of translation andrevision using METAL versus conventional (human) tech-niques, the question of METAL's cost-effectivenesscannot be answered definitively.
However, we haveidentified some performance parameters that are interest-ing.
Our sponsor has calculated that METAL shouldprove cost-effective if it can be implemented on a systemsupporting four to six post-editors who can sustain anaverage total output of about 60 revised pages per day.At 275 words per page, and eight hours per day, thisworks out to 1.7 seconds per word, minimum real-timemachine performance.
Our mid-84 real-time perform-ance figure of 2+ seconds per word on a Symbolics 3600approaches this goal; it also compares very favorablywith the human translation rate (experienced at Siemens,for decades) of four to eight pages per day for like mate-rial.
If this level of performance can be slightly increasedwhile maintaining a high enough standard of quality soan individual revisor can indeed edit 10 to 15 pages perday, on a daily basis, METAL will have achieved cost-ef-fectiveness.Most important, we have also measured revisionperformance: the amount of time required to edit textstranslated by METAL.
In the first such experiment,conducted late in 1982, two 'Siemens post-editors revisedMETAL's translations at the rate of 15 to 17 pages perday (depending on the particular editor).
In a secondexperiment, conducted in mid-83, the rates were onlyslightly higher (15-20 pages/day), but the revisors never-theless reported a significant improvement in theirsubjective impression of the quality of the output.
In athird experiment, conducted in early 1984, the editorsreported further improvement in their subjectiveimpression of the quality of the output, and their revisionrates were much higher: almost 30 pages per day.
In afourth experiment, conducted in mid 1984, their averagerevision rate climbed to over 40 pages per day; this figurealso compares favorably with the revision rate of humantranslations experienced at Siemens: eight to twelvepages per day for like material (not including originaltranslation time: four to six pages per day).
These MTrevision figures are surely biased by virtue of the exper-imental setting itself (i.e., one-shot measures of post-ed-iting performance on human translations would besignificantly higher than the on-going eight to twelveaverage quoted above), but nevertheless these numbersindicate that we have probably reached the goal of cost-effectiveness.7 FUTURE DIRECTIONSThe METAL German-English configuration was readyfor market esting in January 1985.
Current plans are tocontinue improving the present system and to branch offinto other target languages, specifically Spanish andChinese.
If our estimates are correct, a German-Spanishsystem should be ready for testing sometime in 1986, anda German-Chinese system sometime thereafter.
Thereare also plans to begin serious work on an English-Ger-man system during 1985.
If the planned work is success-ful, we will initiate work on English-Spanish andEnglish-Chinese MT systems.We anticipate retaining most of the system as-is, asidefrom the usual sorts of maintenance modifications;however, as mentioned above, we are in the process ofupgrading the power of the Synthesis component.
Inaddition, there are plans to change the format andcontent of Transfer lexical entries so as to standardizetheir format (verbs are structured ifferently from otherparts of speech) and increase their ability to controlstructural transfer.
These changes, we anticipate, willallow further improvement in the quality of the raw118 Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985Winfield S. Bennett and Jonathan SIocum The LRC Machine Translation Systemoutput of the LRC MT system, and so further enhance itsattraction and cost-effectiveness.8 REFERENCESBoitet, Ch.
and Nedobejkine, N. 1980 Russian-French at GETA:Outline of the Method and Detailed Example.
Proceedings of theEighth International Conference on Computational Linguistics,Tokyo.Carbonell, J.; Cullingford, R.E.
; and Gershman, A.V.
1978 Know-ledge-Based Machine Translation.
Research Report #146 (Decem-ber).
Department of Computer Science, Yale University.Hayes, P.J.
and Mouradian, G.V.
1981 Flexible Parsing.
AmericanJournal of Computational Linguistics 7(4): 232-242.Hendrix, G.G.
; Sacerdoti, E.D.
; Sagalowicz, D.; and Slocum, J.
1978Developing a Natural Language Interface to Complex Data.
ACMTransactions on Database Systems 3(2): 105-147.
Reprinted inLarson, J.A.
and Freeman, H.A., Eds., Tutorial: Data Base Manage-ment in the 1980"s. IEEE Computer Society Press, Los Alamitos,California: 89-131.Jensen, K. and Heidorn, G.E.
1982 The Fitted Parse: 100% ParsingCapability in a Syntactic Grammar of English.
Research ReportRC-9729.
Computer Sciences Department, IBM Thomas J. WatsonResearch Center, Yorktown Heights, New York.Kay, M. 1980 The Proper Place of Man and Machines in Languageand Translation.
Technical Report.
Xerox PARC, Palo Alto, Cali-fornia.King, M. 1981 Design Characteristics of a Machine TranslationSystem.
Proceedings of the Seventh International Joint Conferenceon Artificial Intelligence \[7th IJCAI\].
Vancouver, B.C., Canada:Vol.
1, 43-46.Lehmann, W.P.
; Bennett, W.S.
; Slocum, J.; et al 1981 The METALSystem.
Final Technical Report RADC-TR-80-374 (January).Rome Air Development Center, Griffiss Air Force Base, New York.Available as Report AO-97896, National Technical InformationService, U.S. Department of Commerce, Springfield, VA.Miller, L.A.; Heidorn, G.E.
; and Jensen, K. 1980 Text-Critiquing withthe EPISTLE System: An Author's Aid to Better Syntax.
ResearchReport RC 8601.
Behavioral Sciences and Linguistics Group,Computer Sciences Department, IBM Thomas J. Watson ResearchCenter, Yorktown Heights, New York.Paxton, W.H.
1977 A Framework for Speech Understanding.
Ph.D.dissertation available as Technical Note 142.
Artificial IntelligenceCenter, SRI International, Menlo Park, California.Pratt, V.W.
1973 A Linguistics Oriented Programming Langua\[.z.Proceedings of the Third International Joint Conference on Artifi-cial Intelligence \[3rd IJCAI\].
Stanford University, California: 372-381.Robinson, J.J. 1982 DIAGRAM: A Grammar for Dialogues.
Commu-nications of the ACM 25(1): 27-47.Slocum, J.
1981 A Practical Comparison of Parsing Strategies forMachine Translation and Other Natural Language ProcessingPurposes.
University Microfilms International, Ann Arbor, Michi-gan.Slocum, J. and Bennett, W.S.
1982 The LRC Machine TranslationSystem: An Application of State-of-the-Art Text and NaturalLanguage Processing Techniques to the Translation of TechnicalManuals.
Working Paper LRC-82-1.
Linguistics Research Center,University of Texas.Slocum, J. et al 1984 METAL: The LRC Machine TranslationSystem.
Presented at the ISSCO Tutorial on Machine Translation,Lugano, Switzerland (2-6 April).
Also available as Working PaperLRC-84-2 (April).
Linguistics Research Center, University ofTexas.Weischedel, R.M.
and Black, J.E.
1980 If the Parser Fails.Proceedings of the 18th Annual Meeting of the ACL, University ofPennsylvania.Whiffin, L. 1985 Machine Assisted Translation Systems: User Accept-ability.
Submitted to the Second Conference of the EuropeanChapter of the ACL (28-29 March 1985).Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985 119Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation SystemEXHIBIT A: A GERMAN DP TEXTEINTEILUNG DES PLATTENSPEICHERSBLOCKSTRUKTURDie kleinste adressierbare Informationseinheit ist einBlock = 1 Sektor.
Zu jedem Block gehoert ein Header.Der Header enthaelt die gesamte Adresse, sowie Anga-ben ueber den Zustand des Blockes (Benutzbarkeit!
).Zur Sicherung der Header-Information und der Datenbefindet sich am Ende des Headers und des Datenfeldesein Pruefzeichen yon 16 Bit.Vor dem Headerfeld befindet sich eine Praeambel yon42 Byte Laenge fuer den Ausgleich aller Toleranzen.Vor dem Datenfeld befindet sich eine Praeambel yon5 Byte Laenge zur Aufsynchronisierung der Leseverst-aerker.
Vor und hinter dem Datenfeld befindet sich eineLuecke.
Die Luecken sind aus folgenden Gruendennotwendig:Luecke 1 :56  Bit wegen Schreib-Loesch-Kopfab-stand.Zu Beginn der Daten-Schreiboperationmuss gewaehrleistet sein, dass der Loeschkopfden Header nicht zerstoeren kann.Luecke 2 :316  Bit im Normalmodus wegen der Toleran-zen in der Umdrehungsgeschwindigkeit.
Esmuss die Moeglichkeit beruecksichtigtwerden, dass das Schreiben des Blockes(Header + Datenfeld) an der unteren undoberen Grenze der Umdrehungsgeschwindig-keit erfolgen kann.Im Spezialmodus wird diese Luecke wegender kleineren Bloecke 1340 Bit lang.Am Ende des Header- und Datenfeldes befindet sich 1Postambel yon 8 Bit Laenge.SPURSTRUKTUREine Spur wird eingeteilt in 4 bzw.
8 Sektoren.
DieUnterteilung tier Spur in Sektoren erfolgt dutch Index-und Sektormarken.Die Indexmarke wird magnetisch durch einen Schlitzauf der untersten Platte des Plattenstapels erkannt unddient als allgemeiner Bezugspunkt fuer den Aufbau derSpurstruktur.
Vom Indexpunkt ausgehend wird die Spurmit einem eigens dafuer vorgesehenen Dienstprogramm(oder Simulator!)
mit Headern beschrieben.
Die Bitzahlfuer das Datenfeld wird so bemessen, dass auch beiunguenstiger Drehzahl (= 2448 U/min)  immer noch 4bzw.
8 vollstaendige Bloecke Platz linden.
(SieheAbschnitt 4.1 Luecke 2).
Je nachdem bei welcherGeschwindigkeit die Spur beschrieben wird, entstehtzwischen Ende des Datenfeldes und Indexmarke bzw.Sektormarke eine mehr oder weniger grosse Luecke.EXHIBIT B: A RAW METAL TRANSLATIONDIVISION OF DISK STORAGEBLOCK STRUCTUREThe smallest addressable information unit is a block = 1sector.
A header is part of every block.
The headerincludes the entire address, sowie specifications about thestate of the block (usability!).
A check character of 16bits is found for the saving of the header information andthe data at the end of the header and the data field.A preamble of 42 byte length for the adjustment of alltolerances i found in front of the header field.A preamble of 5 byte length is found in front of thedata field for the synchronization of the read amplifier.A gap is found in front of and behind the data field.
Thegaps are necessary from the following reasons:Gap 1: 56 Bit because of distance between write anderase heads.
At the beginning of the data writeoperation it must be guaranteed, that the erasehead can not destroy the header.Gap 2: 316 Bit in the normal mode because of thetolerances in the rotational speed.
The possi-bility must be considered that writing the block(header + data field) at the lower and upperl imit/boundary of the rotational speed canoccur.This gap becomes 1340 bits long in specialmode because of the smaller blocks.The 1 postamble Of 8 bit length is found at the end of theheader and data field.TRACK STRUCTUREA track is divided into 4 and/or  8 sectors.
The subdivi-sion of the track into sectors occurs through index labeland sector marks.The index label is recognized magnetically by a slot onthe lowest disk of the disk pack and is used for the trackstructure as the general reference point for establishing.By the index point, the track with a utility program desig-nated especially for that (or simulator!)
is described withheaders.
The number of bits for the data field is calcu-lated then that always still 4 and/or  8 complete blocks doalso find space with unfavorable rotationalspeed/number of revolutions (= 2448 r.p.m.s).
(Seesection 4.1 gaps 2.)
Depending on with which speed thetrack is described, a more or less large gap occursbetween the end of the data field and index label and/orsector mark.120 Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985Winfield S. Bennett and Jonathan Slocum The LRC Machine Translation SystemSEKTORMARKIERUNGDie Sektormarke wird ebenso wie die Indexmarke vonder Schiitzplatte, die sich als Bodenplatte an jedem Plat-tenstapel befindet, magnetisch abgenommen.
Im Handelwerden Plattenstapel mit 32 und mit 20 Schlitzen ange-boten.
Im vorliegenden Fall soil der Plattenstapel mit 20Schlitzen beim WSP 411 und mit 32 Schlitzen beim WSP414 verwendet werden.
Eine Maske, dargestellt durcheinen Zaehler blendet aus den 20 bzw.
32 Sektormarken4 bzw.
8 aus, so dass 4 bzw.
8 gleich grosse Sektorenentstehen.
Die Maske bzw.
der Zaehler wird von derHerstellerfirma (CDS) in jeden Wechselplattenspeicherfest eingebaut.SEKTORMARKIERUNGDargestellt ist die Struktur des WSP 411.Ein Plattenstapel umfasst 6 bzw.
11 Platten mit 10bzw.
20 benutzbaren Oberflaechen.
Pro Oberflaechebefindet sich ein Kopf.
Jeder Kopf ueberstreicht 203Spuren.
Die Gesamtheit aller Spuren mit gleichem Radi-us nennt man Zylinder.Der Plattenstapel umfasst also 203 Zylinder.
DieZylinder haben die Adressen 000-202, die Koepfe habenentsprechend den Plattenseiten die Adressen 0-9 bzw.0-19.Bei einer fortlaufenden Uebertragung wird dieAdresse in der Reihenfolge Sektor, Kopf, Zylindererhoeht.SECTOR MARKERLikewise the index label is read in the sector mark as bythe slot disk which is found as a bottom disk at every diskpack magnetically.
The disk packs with 32 and with 20slotting are offered on the market.
The disk pack shouldbe used in this case with the 20 slots with the WSP 411and with the 32 slots with the WSP 414.A mask, represented through a counter masks out 4and/or 8 from the 20 and/or 32 sector marks so thatlarge sectors result similar to 4 and/or 8.
The maskand/or the counter is incorporated by the Herstellerfirma(CDS) into every removable disk storage.STORAGE STRUCTUREThe structure of the WSP 411 is represented.A disk pack contains the 6 and/or 11 disks with 10and/or 20 usable surfaces.
A heading is found persurface.
Every heading covers 203 tracks.
The entiretyof all tracks with same radius calls one cylinder.Therefore the disk pack contains 203 cylinders.
Thecylinders have the addresses 000-202, the headings havethe addresses 0-9 and/or 0-19 corresponding to the disksurfaces.Sector, heading, cylinder is increased the addressduring a continuous transfer in the sequence.Computational Linguistics, Volume 11, Numbers 2-3, April-September 1985 121
