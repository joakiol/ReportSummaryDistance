Multilinguality and Reversibility in Computational SemanticLexiconsEve lyne  V iegas  and  Stephen Bea leviegas@crl.nmsu.edu and sb,.~crl.nmsu.eduComputing Research LaboratoryLas Cruces, NM 88003 USAAbstractIn this paper, we address the issue of generatingmultilingua.1 computational semantic lexicons fromanalysis lexicons, showing the necessity of rely-ing on a conceptual lexicon.
We first discuss thetype of information which should be found in NLPlexicons, whatever their use (analysis, generation,speech, robotics).
We claim that we should takeadvantage of the existing large-scale analysis lex-icons and use tliem as the starting point in theprocess of building large-scale generation lexicons,by first reversing tliem and then enhancing them.Tliis implies having access to a conceptual lexi-con, which will serve as a pivot point between theanalysis and the generation lexicons.
We imple-mented the work reported here for Spanish andEnglish MT projects, within the knowledge-basedparadigm.
From a theoretical point of view, regen-erating the source text with the reversed analysislexicon enabled us to enhance several issues as di-verse as: evaluating analysis lexicons, testing thesemantic analyser, evaluating which informationshould be added to the generation lexicon; andtesting the grain-size of the pivot point betweenanalysis and generation.I n t roduct ionThere is no consensus on the type of lexiconswhich should be used for generators.
It seemsto depend on the type of generator.
It alsoseems to depend on the kind of application in-volved: monolingual generation, naultilingualgeneration, machine translation: generation ofsentences vs. texts vs. speech; or also genera-tion from raw data vs. from conceptual repre-sentations built with generation in mind.Once one has an application in mind, thenthere are three main approaches one can adoptto build the lexicon:lex icographic :  very attractive for NLP ap-plications at first sight, as they provide a usefuldescription of the vocabulary; entries are dis-tinguished on the basis of multiple senses andWe would like to thank in the mikrokosmos team,Tom Herndon, .Jeff Longwel, Oscar Cossio and JavierOchoa.subcategorisations.
But in practice, this ap-proach complicates the process of lexical dis-ambiguation for parsing and lexical choice ingeneration by an unjustified proliferation of en-tries.stat ist ical:  very attractive for NLP appli-cations as it seems to replace knowledge-basedapproaches and therefore supplant the needsfor human acquisition of large-scale seman-tic lexicons, which is a very time consumingtask.
However, the limits of statistical ap-proaches haw: been pointed out by \[Smadja,1993\].
Moreover, some phenomenon, such asevent ellipsis (EE) cannot be handled by a purestatistical approach nor by a lexicographic ap-proach, as its recovery necessitates a seman-tic treatment, (\[Viegas and Nirenburg, 1995a\]),which is, in fact, handled by a computalionalLinguistic approach making use of semantics.computat iona l  inguistic: the main ad-vantage of this approach is that it is usu-ally theoretically grounded, and is domain-and application-independent.
Moreover, it canhandle phenomena which are out of the reachof other approaches and yet are necessary toenhance lexical choice in generation.
For in-stance, the EE triggered by enjoy as in i) \[enjoyed the salmon very much, must be mod-eled with a semantic representation so that itsrecovery can be taken care of as in ii) I enjoyedeating ....
This is part of lex.ical choice as onecan choose to realise the synthet ic  version orthe ana lyt ic  version of the EE, as exempli-fied in i) and ii) respectively (cf.
\[Viegas andNirenburg, 1995a\]).However necessary, adopting a linguistic ap-proach is a difficult task, as one of the maindrawbacks of this approach is that it is timeconsuming as far as the building of the lexiconis concerned.
We address in next section howto bypass this drawback.49A Multi-purpose Knowledge BaseSince building computational semantic lexi-coas is a very time-consuming task, we shouldaim at lexicons which conform to the three fol-lowing conditions:a multi-lingual: French, Engfish,Japanese, Russain, Spanish, etc..., (format ofthe lexicon)b - multi-rr'~d'._: .
'_'" .
.
.
.
.
:... 1~ .
.
.
.
;~tic information for natural language process-ing, phonological information, essentially forspeech recognition and production, (structureof the lexicons)c - mult i -use:  so that they can be usedfor analysis, generation (mono/multi-lingual),MT, or speech processing.
(reversibility of thelexicons)The way we organised and structured ourlexicons directly follows these conditions.Large-scale computational generation lexiconscarrying semantic information are indeed notthat common, the obvious reason being thatacquiring semantic information is a difficultand time consuming task.
However, it is byno means an unattainable task, if we structureand organise our analysis lexicons in such away so that the information they contain canbe used at best for building generation lexi-cons.Acquiring a large-scale l xicon is very expen-sive, which is why building lexicons that arereusable for other domains or applications isrecommended.
It is well known in computa-tional lexical semantics that a sense enumer-ation approach only based on subcategorisa-tion differences is computationally expensiveand unrealistic from a theoretical viewpoint.Our lexicons are composed of superentries,where each entry consists of a list of words,stored there independently of their part ofspeech (the verb and noun form of walk areunder the same superentry), as described inlength in \[Onyshkevych and Nirenburg, 1994\].Revers ing  an  Ana lys i s  Lex iconBefore addressing the issue of reversing theanalysis lexicon, we want first to show how wecould acquire a large-scale analysis lexicon.Acquisition of the Analysis LexiconWe acquired a Spanish semantic lexicon ofabout 40,000 word meanings, for an MTProject, described in \[Beale t al., 1995\].
Weautomated as much as possible the task of ac-quisition by providing the lexicographers withaccess to on-fine dictionaries, on-fine corpora,and also software allowing lexicographers toac-cess all this on fine information in an easy way(see \[Viegas and Nirenburg, 1995b\] for the taskof acquisition).
Our interfaces have been de-signed with respect to users needs, and con-tinue to evolve on a needed basis.We give below the example of the partial en-try cornpafii'a in Spanish, with two differentmarmings, represented by the following con-cepts in our world model (or ontology): COR-PORATION, INTEIrtACT-SOCIALLY.
One impor-tant point here to notice is our transcatego-rim approach.
There is no one-to-one map-ping between semantic ategories or conceptsand lexical items, and some EVENTS,  (such asINTERACT-SOCIALLY here) can be lexicalisedas nouns (Figure 1) 1 or verbs such as inacorn ~afiar:"cornpafi{a-N 1syn:~em:compafi{a-N2syn:sem:corpora,ion\]\[r?
?t: @ \[::tm: ~\ ]  \]\[\[~\[~\] interact-socially\]Figure l: Sense Entries for the Spanish lexical itemcompa~i'a.Let us now consider some of the entries forthe Spanish verb adquirir with the followingcorresponding semantics: ACQUIRE, LEARN,displayed in (Figure 2).The sub-entries for adquirir have differentselectional restrictions for the theme, OBJECTand INFORMATION for ACQUIRE and LEARN re-spectively.We have acquired about 1/5 of our lexi-con semi-automatically and have developed amorpho-semantic a quisition program, whichhas allowed us to acquire the remaining 4/5entirely automatically to create at the end alarge-scale l xicon of about 40000 word senses.
2The main advantage of our approach is that itenabled us to economically multiply the size ofthe lexicon.
The main drawback is that the en-tries produced automatically need some semi-manual checking.
We bypass this drawback by1We use the typed feature structures (tfs) as de-scribed in \[Pollard and Sag, 1987)9.2See \[Viegas et al, 1996\] which describes the ad-vantages and drawbacks of using lexical rules to buildlexicons.50"adquirir-V 1syn:sem:adquirir-V2"root: \[\]?
\[cat: ~Ii_i\]Psubj: \[B lsem: ~\]PJ ,cat:obj: \[\] \[sem:acqu i reagent: \[~\] humavtheme: \[~\] object"root: \[\]sub j: \[\] |sere: sun:,obj: NLsem:l earnsem: agent: ~ humantheme: \[Z\] informationFigure 2: Sense Entries for the Spanish lexical itemadquirir.using the reversed lexicon to regenerate he en-try as explained below.The  Reversed  Lex iconThe algorithm to "reverse" the analysis lexicon(AL) to produce the generation lexicon (GL)mainly involves rearranging, modifying, delet-ing, and adding certain items.
We focus belowon the zones which have been reversed, namely:SYN (subcategorisation information) and SEN\[(providing the semantic information with as-sociated selectional restrictions), as shown in( Figure 3).
"corporation-C1syn: \[root:sere:corporation-C2syn: \[root:sere:, \[cat:?
\[cat: 1Figure 3: Partial Entry for the concept CORPORA-TION.Our transcategorial pproach to sense dis-crimination is a good basis for paraphrasing,thus the concept ACQUIRE from the ontol-ogy, can be lexicafised in our Spanish lex-icon, at least in: adquirir, obtener, con-seguir (verbs), adquisicidn, obtcnciSn, en-riquecimiento (nouns), codicioso (adjective).We only show partial entries for superentry ofthe concept ACQUIIIE, as shown in (Figure 4).-acquire-C 1syn:sem:acquire-C2syn:sem:tEE\] \]cat:aspect{tefic: yes\]\]?
root: adquirir \[C~ \[se?
\[cat: NFsubj: \[\] |sere: fie k?
\ [cat :  NP \ ]?bJ: ~\[sem: ~\]J0~agent: \[55\] humantheme: ~ objectFigure 4: Partial Entry for the concept ACQUIRE.We are now in the phase of enhancing the re-versed lexicon for producing the Spanish andEngfish generation lexicons: namely, we are en-coding information which is specific to the pro-cess of generation and which can be avoided inan analysis lexicon, such as word order (in Adj-noun constructions), and collocational infor-mation acquired semi-automatically fi'om cor-pora ( hacer una adquisici6n).Moreover, with this technique, we can pro-duce multifingual generation lexicons by lex-icafising the concepts of the reversed lexiconsin different languages, this ensures that we willhave a lexical item or phrase for lexicallsationavailable.Another advantage of reversing an analysislexicon is using it to regenerate the same textthat was parsed to gain some insight into theissue of the pivot point between parsing andgeneration, and as a resnlt of this, what is thebest input for generation.Advantages  o f  a Reversed  Lex iconA reversed lexicon has advantages beyond itspractical use in generation.
We have identified,and in some cases begun work on the followingareas:Eva luat ion  of  semant ic  analysis?
Witha reversed lexicon that is based on the originalanalysis lexicon, it is possible to take the out-put semantic representations from the analyserand submit them to a text generator.
The out-put surface structures can then be comparedto the input text.
Apart from this, evaluationof semantic analyses can be difficult because51it involves reading and understanding complexmeaning representations.Evaluating Text Meaning Representa-tion language.
For example, the granularityof semantic representation can be studied.
Isthe representation precise enough to correctlytranslate all meaning components, or is a spe-cific source term mapped into a generalised onefrom which the original meaning cannot be re-covered?
This will be especially helpful in amultilingual environment where meaning com-ponents might be bundled differently.Testing lexicon entries.
We have devel-oped a suite of tools to help in testing the anal-ysis lexicon, to ensure the high-quality of ourlarge-scale lexicon.
These tools range in com-plexity from checking placement of parenthesesto automatically creating sentences to test in-dividual exicon entries.
For the latter, havinga reversed lexicon available is extremely help-ful.
For example, a simple lexicon entry for theEnglish word read might look like:READ-V 1syn-s t ruc  :root : readSubj : VARI0BJ : VAR2sem-st ruc  :READAGENT: VARi  = HUMANTHEME: VAR2 = BOOKWe can then use the reversed lexicon togenerate sentences that conform to the givensyn-struc but substitute appropriate words orphrases in place of the variables.
Sentencessuch as the following would signal problems:The book read John.John read into the book.John read the cheese.This is especially helpful for automaticallygenerated lexicon entries such as nominalisa-tions, which are created from verbal entriesusing lexical rules.
Many thousands of suchentries have been created; tools such as thisprovide a simple way to check their accuracy.ConclusionIn this paper we argued that, although lexico-graphic and statistical approaches have theirplace in natural language processing, compu-tational semantic lexicons are necessary for awide range of phenomena nd are applicableto a number of purposes.
Unfortunately, large-scale acquisition of computational lexicons isdifficult.
Compounding this problem is the factthat analysis ystems require different informa-tion than generation lexicons.We have developed a method that enablesus to take advantage of the large investmentmade in the Mikrokosmos analysis lexicon.
Weoutlined a relatively simple process for revers-ing analysis lexicons for eventual use in gener-ation.
This process transfers relevant informa-tion and re-indexes it according to the needsof generation.
The process is not perfect; someinformation required in generation, such as col-locational constraints, is not typically recordedin analysis lexicons.
Nevertheless, the methodsdescribed here provide a baseline to which ad-ditional information can be added.Creating these reversed lexicons has pro-duced a number of additional advantages be-yond those originally envisioned, mostly in thearea of testing and evaluating the semanticanalysis system.
By back-translating the re-sults of semantic analysis, evaluation is simpli-fied.
Testing the content of individual exiconentries can also be made easier by generatingsample sentences that conform to them.
Andfinally, theoretical issues concerning the con-tent of analysis lexicons, generation lexiconsand the text meaning representation languagecan be more fully investigated.ReferencesBeale, S,, Nirenburg, S. and Mahesh.
K.(1995) Semantic Analysis in the MikrokosmosMachine Translation Project.
In Plvceedings ofthe 2nd Symposium on NLP, Bangkok, Thai-land.Onyshkevych, B. et S. Nirenburg (1994) TheLexicon in the Scheme of KBMT Things.
Tech-nical Report MCCS-94-277, CRL, NMSU.Smadja, F. (1993) Retrieving Collocationsfrom Texts: Xtract.
In Computational Lin-guistics, i9(1).Viegas, E. and Nirenburg, S. (1995a) TheSemantic Recovery of Event Ellipsis: its Com-putational Treatment.
In Proceedings of theWorkshop "Context in Natural Language Pro-cessing", of (IJCAI95), Montr4al, Qu4bec.Viegas, E. and Nirenburg, S. (1995b) Acqui-sition semi-automatique du lex.ique.
Proceed-ings of LTT, Lyon 95, France.Viegas, E., Onyshkevych, B., Raskin, V.,Nirenburg, S. (1996) From Submit o Submit-ted via Submission: on Lexical Rules in Large-scale Lexicon Acquisition.
In ACL'96, Santa-Cruz, California.52
