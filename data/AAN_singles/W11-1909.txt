Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 66?70,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational LinguisticsCombining Syntactic and Semantic Features by SVM for UnrestrictedCoreference ResolutionHuiwei Zhou1, Yao Li2, Degen Huang3, Yan Zhang4, Chunlong Wu5, Yuansheng Yang6Dalian University of TechnologyDalian, Liaoning, China{1zhouhuiwei,3huangdg,6yangys}@dlut.edu.cn2tianshanyao@mail.dlut.edu.cn4zhangyan zyzy@yeah.net5wuchunlong@gmail.comAbstractThe paper presents a system for the CoNLL-2011 share task of coreference resolution.
Thesystem composes of two components: one formentions detection and another one for theircoreference resolution.
For mentions detec-tion, we adopted a number of heuristic rulesfrom syntactic parse tree perspective.
Forcoreference resolution, we apply SVM by ex-ploiting multiple syntactic and semantic fea-tures.
The experiments on the CoNLL-2011corpus show that our rule-based mention iden-tification system obtains a recall of 87.69%,and the best result of the SVM-based corefer-ence resolution system is an average F-score50.92% of the MUC, B-CUBED and CEAFEmetrics.1 IntroductionCoreference resolution, defined as finding the dif-ferent mentions in a document which refer to thesame entity in reality, is an important subject in Nat-ural Language Processing.
In particular, coreferenceresolution is a critical component of information ex-traction systems (Chinchor and Nancy, 1998; Sund-heim and Beth, 1995) and a series of coreferenceresolution tasks have been introduced and evaluatedfrom MUC (MUC-6, 1995).
Some machine learningapproaches have been applied to coreference resolu-tion (Soon et al, 2001; Ng and Cardie, 2002; Bengt-son and Roth, 2008; Stoyanov et al, 2009).
Soonet al(2001) use a decision tree classifier to decidewhether two mentions in a document are coreferen-t. Bergsma and Lin (2006) exploit an effective fea-ture of gender and number to a pronoun resolutionsystem and improve the performance significantly,which is also appeared in our feature set.
Howev-er, automatic coreference resolution is a hard tasksince it needs both syntactic and semantic knowl-edge and some intra-document knowledge.
To im-prove the performance further, many deep knowl-edge resources like shallow syntactic and seman-tic knowledge are exploited for coreference resolu-tion (Harabagiu et al, 2001; McCallum and Well-ner, 2004; Denis and Baldridge, 2007; Ponzetto andStrube, 2005; Versley, 2007; Ng, 2007).
In order tomake use of more syntactic information, Kong et al(2010) employ a tree kernel to anaphoricity determi-nation for coreference resolution and show that ap-plying proper tree structure in corefernce resolutioncan achieve a good performance.The CoNLL-2011 Share Task (Pradhan etal., 2011) ?Modeling Unrestricted Coreference inOntoNotes?
proposes a task about unrestrictedcoreference resolution, which aims to recognizementions and find coreference chains in one docu-ment.
We participate in the closed test.In this paper, we exploit multi-features to acoreference resolution system for the CONLL-2011Share Task, including flat features and a tree struc-ture feature.
The task is divided into two steps inour system.
In the first step, we adopt some heuristicrules to recognize mentions which may be in a coref-erence chain; in the second step, we exploit a num-ber of features to a support vector machine (SVM)classifier to resolute unrestricted coreference.
Theexperiments show that our system gets a reasonableresult.The rest of the paper is organized as follows.
In66Section 2, we describe in detail how our system doesthe work of coreference resolution, including howwe recognize mentions and how we mark the coref-erence chains.
The experimental results are dis-cussed in Section 3.
Finally in Section 4, we givesome conclusion.2 The Coreference Resolution SystemThe task of coreference resolution is divided intotwo steps in our system: mentions detection andcoreference resolution.
In the first step, we use someheuristic rules to extract mentions which may re-fer to an entity.
In the second step, we make upmention-pairs with the mentions extracted in thefirst step, and then classify the mention-pairs in-to two groups with an SVM model: Coreferent orNotCoreferent.
Finally we get several coreferencechains in a document according to the result of clas-sification.
Each coreference chain stands for one en-tity.2.1 Rule-based Identification of MentionsThe first step for coreference resolution is to identifymentions from a sequence of words.
We have triedthe machine-learning method detecting the bound-ary of a mention.
But the recall cannot reach a highlevel, which will lead to bad performance of coref-erence resolution.
So we replace it with a rule-basedmethod.
After a comprehensive study, we find thatmentions are always relating to pronouns, named en-tities, definite noun phrases or demonstrative nounphrases.
So we adopt the following 5 heuristic rulesto extract predicted mentions:1.
If a word is a pronoun, then it is a mention.2.
If a word is a possessive pronoun or a posses-sive, then the smallest noun phrase containingthis word is a mention.3.
If a word string is a named entity, then it is amention.4.
If a word string is a named entity, then the s-mallest noun phrase containing it is a mention.5.
If a word is a determiner (a, an, the, this, these,that, etc.
), then all the noun phrase beginningwith this word is a mention.2.2 Coreference Resolution withMulti-FeaturesThe second step is to mark the coreference chain us-ing the model trained by an SVM classifier.
We ex-tract the marked mentions from the training data andtake mention-pairs in one document as instances totrain the SVM classifier like Soon et al(2001) .
Thementions with the same coreference id form the pos-itive instances while those between the nearest posi-tive mention-pair form the negative instance with thesecond mention of the mention-pair.The following features are commonly used inNLP processes, which are also used in our system:?
i-NamedEntity/j-NamedEntity: the named en-tity the mention i/j belongs to?
i-SemanticRole/j-SemanticRole: the semanticrole the mention i/j belongs to which?
i-POSChain/j-POSChain: the POS chain of themention i/j?
i-Verb/j-Verb: the verb of the mention i/j?
i-VerbFramesetID/j-VerbFramesetID: the verbframeset ID of the mention i/j, which works to-gether with i/j-VerbAll the 5 kinds of features above belong to a sin-gle mention.
For mention-pairs, there are another 4kinds of features as below:?
StringMatch: after cutting the articles, 1 if thetwo mentions can match completely, 2 if one isa substring of the other, 3 if they partly match,4 else.?
IsAlias: after cutting the articles, 1 if one men-tion is the name alias or the abbreviation of theother one, 0 else?
Distance: it is the number of sentences betweentwo mentions, 0 if the two mentions are fromone sentenci-Verb/j-Verb: the verb of the men-tion i/j?
SpeakerAgreement: 1 if both the speakers ofthe two mentions are unknown, 2 if both thetwo mentions come from the same speaker, 3 ifthe mentions comes from different speakers.67All of the 14 simple and effective features aboveare applied in the baseline system, which use thesame method with our system.
But coreference res-olution needs more features to make full use of theintra-documental knowledge, so we employ the fol-lowing 3 kinds of features to our system to catchmore information about the context.?
i-GenderNumber/j-GenderNumber (GN): 7values: masculine, feminine, neutral, plu-ral, ?rst-person singular, ?rst-person plural,second-person.?
SemanticRelation (SR): the semantic relationin WordNet between the head words of the t-wo mentions: synonym, hyponym, no relation,unknown.?
MinimumTree (MT): a parse tree represents thesyntactic structure of a sentence, but corefer-ence resolution needs the overall context in adocument.
So we add a super root to the forestof all the parse trees in one document, and thenwe get a super parse tree.
The minimum tree(MT) of a mention-pair in a super parse tree isthe minimum sub-tree from the common par-ent mention to the two mentions, just like themethod uesd by Zhou(2009).
And the similari-ty of two trees is calculated using a convolutiontree kernel (Collins and Duffy, 2001), whichcounts the number of common sub-trees.We try all the features in our system, and get someinteresting results which is given in Experiments andResults Section.3 Experiments and ResultsOur experiments are all carried out on CONLL-2011share task data set (Pradhan et al, 2007).The result of mention identification in the firststep is evaluated through mention recall.
And theperformance of coreference resolution in the secondstep is measured using the average F1-measures ofMUC, B-CUBED and CEAFE metrics (Recasens etal., 2010).
All the evaluations are implemented us-ing the scorer downloaded from the CONLL-2011share task website 1 .1http://conll.bbn.com/index.php/software.html3.1 Rule-based Identification of MentionsThe mention recall of our system in the mention i-dentification step reaches 87.69%, which can resultin a good performance of the coreference resolutionstep.
We also do comparative experiments to inves-tigate the effect of our rule-based mention identifica-tion.
The result is shown in Table 1.
The CRF-basedmethod in Table 1 is to train a conditional randomfield (CRF) model with 6 basic features, includingWord, Pos, Word ID, Syntactic parse label, Namedentity, Semantic role.Method Recall Precision F-scoreRule-based 87.69 32.16 47.06CRF-based 59.66 50.06 54.44Table 1: comparative experiments of CRF-based andrule-based methods of mention identification(%)Table 1 only shows one kind of basic machine-learning methods performs not so well as our rule-based method in recall measure in mention iden-tification, but the F1-measure of the CRF-basedmethod is higher than that of the rule-based method.In our system, the mention identification step shouldprovide as many anaphoricities as possible to thecoreference resolution step to avoid losing corefer-ent mentions, which means that the higher the recal-l of mention identification is, the better the systemperforms.3.2 Coreference Resolution withMulti-FeaturesIn the second step of our system, SVM-LIGHT-TK1.2 implementation is employed to coreferenceresolution.
We apply the polynomial kernel forthe flat features and the convolution tree kernel forthe minimum tree feature to the SVM classifier, inwhich the parameter d of the polynomial kernel isset to 3 (polynomial (a ?
b + c)d) and the combin-ing parameter r is set to 0.2 (K = tree?
forest ?kernel ?
r + vector ?
kernel).
All the other pa-rameters are set to the default value.
All the exper-iments are done on the broadcast conversations partof CoNLL-2011 corpus as the calculating time ofSVM-LIGHT-TK1.2 is so long.Experimental result using the baseline methodwith the GenderNumber feature added is shown in68d=?
MUC B3 CEAFE AVE2 47.49 61.14 36.15 48.263 51.37 62.82 38.26 50.82Table 2: parameter d in polynomial kernel in coreferenceresolution using the baseline method with the GN fea-ture(%)Talbe 2.
The result shows that the parameter d inpolynomial kernel plays an important role in ourcoreference resolution system.
The score when d is3 is 2.56% higher than when d is 2, but the runningtime becomes longer, too.r=?
MUC B3 CEAFE AVE1 31.41 45.08 22.72 33.070.25 34.15 46.87 23.63 34.880 51.37 62.82 38.26 50.82Table 3: combining parameter r (K = tree ?
forest ?kernel ?
r + vector?
kernel) in coreference resolutionusing the baseline with the GN and MT features(%)In Table 3, we can find that the lower the combin-ing parameter r is, the better the system performs,which indicates that the MT feature plays a negativerole in our system.
There are 2 possible reasons forthat: the MT structure is not proper for our coref-erence resolution system, or the simple method ofadding a super root to the parse forest of a documentis not effective.Method MUC B3 CEAFE AVEbaseline 42.19 58.12 33.6 44.64+GN 51.37 62.82 38.26 50.82+GN+SR 49.61 64.18 38.13 50.64+GN 50.97 62.53 37.96 50.49+SEMCLASSTable 4: effect of GN and SR features in coreference res-olution using no MT feature (%)Table 4 shows the effect of GenderNumber fea-ture and SemanticRelation feature, and the last itemis the method using the SemanticClassAgreement-Feature (SEMCLASS) used by (Soon et al, 2001)instead of the SR feature of our system.
The GN fea-ture significantly improves the performance of oursystem by 6.18% of the average score, which maybe greater if we break up the gender and numberfeature into two features.
As the time limits, wehaven?t separated them until the deadline of the pa-per.
The effect of the SR feature is not as good aswe think.
The score is lower than the method with-out SR feature, but is higher than the method usingSEMCLASS feature.
The decreasing caused by S-R feature may be due to that the searching depth inWordNet is limited to one to shorten running time.To investigate the performance of the second step,we do an experiment for the SVM-based corefer-ence resolution using just all the anaphoricities asthe mention collection input.
The result is shown inTable 5.
As the mention collection includes no in-correct anaphoricity, any mistake in coreference res-olution step has double effect, which may lead to arelatively lower result than we expect.MUC B3 CEAFE AVE65.55 58.77 39.96 54.76Table 5: using just all the anaphoricities as the mentioncollection input in coreference resolution step (%)In the three additional features, only the GN fea-ture significantly improves the performance of thecoreference resolution system, the result we finallysubmitted is to use the baseline method with GN fea-ture added.
The official result is shown in Table 6.The average score achieves 50.92%.MUC B3 CEAFE AVE48.96 64.07 39.74 50.92Table 6: official result in CoNLL-2011 Share Task usingbaseline method with GN feature added (%)4 ConclusionThis paper proposes a system using multi-featuresfor the CONLL-2011 share task.
Some syntactic andsemantic information is used in our SVM-based sys-tem.
The best result (also the official result) achievesan average score of 50.92%.
As the MT and S-R features play negative roles in the system, futurework will focus on finding a proper tree structurefor the intra-documental coreference resolution andcombining the parse forest of a document into a treeto make good use of the convolution tree kernel.69ReferencesA.
McCallum and B. Wellner.
2004.
Conditional modelsof identity uncertainty with application to noun coref-erence.
In Advances in Neural Information ProcessingSystems (NIPS), 2004.Chinchor, Nancy A.
1998.
Overview of MUC-7/MET-2.In Proceedings of the Seventh Message UnderstandingConference (MUC-7).Eric Bengtson, Dan Roth.
2008.
Understanding the Val-ue of Features for Coreference Resolution Proceed-ings of the 2008 Conferenceon Empirical Methods inNatural Language Processing, pages294C303.Fang Kong, Guodong Zhou, Longhua Qian, QiaomingZhu.
2010.
Dependency-driven Anaphoricity Deter-mination for Coreference Resolution Proceedings ofthe 23rd International Conferenceon ComputationalLinguistics (Coling2010), pages599C607.Guodong Zhou, Fang Kong.
2009.
Global Learning ofNoun Phrase Anaphoricity in Coreference Resolutionvia Label Propagation.
In Proceedings of the 2009Coreference on Empirical Methods in Natural Lan-guage Processing, pages 978-986, 2009.M.
Collins, N.Duffy.
2001.
Convolution Kernels for Nat-ural Language Resolution NIPS?
2001.Marta Recasens, Llu?s Mrquez, Emili Sapena, M.
AntniaMart?, Mariona Taul, Vronique Hoste, Massimo Poe-sio, Yannick Versley 2010.
SemEval-2010 Task 1:Coreference Resolutionin Multiple Languages In Pro-ceeding SemEval 2010 Proceedings of the 5th Interna-tional Workshop on Semantic Evaluation, 2010.MUC-6.
1995.
Coreference task definition (v2.3, 8 Sep95) In Proceedings of the Sixth Message Understand-ing Conference (MUC-6), pages 335-344.P.Denis, J.Baldridge.
2007.
Joint determination ofanaphoricity and coreference resolution using integerprogramming.
In Proceedings of HLT/NAACL, 2007.V.
Ng and C. Cardie.
2002.
Improving machine learningapproaches to coreference resolution.
In Proceedingsof ACL, 2002.V.
Ng.
2007.
Shallow semantics for coreference resolu-tion.
In Proceedings of IJCAI, 2007.Veselin Stoyanov, Nathan Gilbert, Claire Cardie, EllenRiloff.
2009.
Conundrums in Noun Phrase Corefer-ence Resolution: Making Sense of the State-of-the-ArtProceeding ACL ?09 Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL.W.Soon,H.Ng,and D.Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrase.
Com-putational Linguistics, 27(4):521-544,2001.S.
M.Harabagiu,R.C.Bunescu,and S.J.
Maiorano.
2001.Text and knowledge mining for coreference resolution.In Proceedings of NAACL, 2001.S.Ponzetto, M.Strube.
2005.
Semantic role labeling forcoreference resolution.
In Proceedings of EACL, Italy,April 2005.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, Nianwen Xue.2011.
CoNLL-2011 Shared Task: Modeling Unre-stricted Coreference in OntoNotes.
Proceedings of theFifteenth Conference on Computational Natural Lan-guage Learning (CoNLL 2011).Sameer S. Pradhan, Lance Ramshaw, Ralph Weischedel,Jessica MacBride, Linnea Micciulla.
2007.
Unre-stricted Coreference: Identifying Entities and Eventsin OntoNotes.
In International Conference on Seman-tic Computing, 2007.Shane Bergsma, Dekang Lin.
2006.
Bootstrapping Path-Based Pronoun Resolution.
In Proceedings of the 21stInternational Conference on Computational Linguis-tics, 2006.Sundheim, Beth M. 1995.
Overview of results of theMUC-6 evaluation.
In Proceedings of the Sixth Mes-sage Understanding Conference (MUC-6), pages 13-31.Y.Versley.
2007.
Antecedent selection techniques forhigh-recall coreference resolution.
In Proceedings ofEMNLP/CoNLL, 2007.70
