SOME I 33UE3 IH P&RSING AHD NATURAL L INGUAGE UNDERSTANDINGRober t  J. BobrowBo l t  Beranek  and ~ewman Inc.Bonn ie  L. WebberDepar tment  of Computer  & In format ion  Sc ienceUn ivers i ty  of  Pennsy lvan iaLan&ua~e is a system for ancodln~ andtrans~tttlnK ideas.
A theory that seeks toexplain llnKulstlc phenomena in terme of thisfact is a fun~t~1 theory.
One that does not?
?sses the point.
\[10\]PREAMBLEOur response to the questions posed to this panel isinfluenced by a number of beliefs (or biasesl) which wehave deve loped in  the  course  o f  bu i ld ing  and ana lyz in~the operation of several natural language understanding(NLU) systems.
\[I, 2, 3, 12\] While the emphasis of thepanel i~ on parslnK, we feel that the recovery of thesyntactic structure of a natural lan~unKe utterancemust be viewed as part of a larger process ofreeoverlnK the meaning, intentions and goals underlyingits generation.
Hence it is inappropriate to considerdesigning or evaluatln~ natural language parsers orErem,~ra without taking into account the architectureof the whole ~LU system of which they're a part.
I Thisis the premise from which Our beliefs arise, beliefswhich concern two thinks:o the distribution of  various types ofknowledge, in particular syntactic knowledge,amonK the  modules  o f  an NLU sys temo the  in format ion  and cont ro l  Flow emonK thosemodules.As to the first belief, in the HLU systems we haveworked on, most syntactic information is localized in a"syntactic module", although that module does notproduce a rallied data structure representing thesyntactlo description of an utterance.
Thus, if"parslnK" is taken as requlrln~ the production of sucha rallied structure, then we do not believe in itsnecessity.
However we do believe in the existence of amodule which provides syntactic information to thoseother parts of the system whose decisions ride on it.As to  the second belief, we feel that syntax, semanticsand prat t les  effectively constitute parallel butinteracting processors, and that information such aslocal syntactic relations is determined by Jointdecisions -monk them.
Our experience shows that withmlnir"al loss of efficiency, one can design theseprocessors to interface cleanly with one another, so asto allow independent design, implementatlon andmodification.
We spell out these beliefs in slightlymore detail below, and at greater length in \[~\].1We are  not  c la iming  that  the on ly  fac tors  shap ing  aparser or a gr~-mar, beyond syntaotlo conslderatlofls,are thlrLKs llke meanlng, intention, etc.
There areclearly mechanical and memory factors, aa well anlaziness - a speoXer's penchant for trylnK to get awaywith the mdniEal level of effort needed to accomplishthe task f97The Comoutatiom~l PersneetiveThe f i r s t  se t  o f  quest ion~ to  th i s  pane l  concern  thecomputat iona l  perspect ive ,  and the use fu l  purposesserved  by d is t ingu ish ing  pars ing  f rom in terpretat ion .We be l ieve  that  syntact i c  knowledge p lays  an impor tantro le  in  NLU.
In  par t i cu la r ,  we be l ieve  that  there  i s  as ign i f i cant  type  o f  u t terance  descr ip t ion  that  can bedetermined on pure ly  syntact i c  g rounds  2,  a lbe i t  notnecessar i l y  un ique ly .
Th is  descr ip t ion  can  be used  togu ide  semant ic  and d iscourse  leve l  s t ructure  recoveryprocesses  such  as in terpretat ion ,  anaphor ic  reso lu t ion ,focus  t rack ing ,  g iven/new d is t inc t ions ,  e l l ips i sreso lu t ion ,  e tc .
in  a manner that  i s  independent  o f  thelex ica l  and conceptua l  content  o f  the  u t terance .
Thereare  severa l  advantages  to  fac tor ing  out  such  knowledgef rom the re ,~-~nder  o f  the  NLU sys tem and prowld ing  a?
syntact i c  modu le"  whose in teract ions  w i th  the  res t  o fthe system prov ide  information on the syntacticstructure of an utterance.
The first advantage is tosimplify system building, an we know fl-omexperience \[I, 2, 3, 4, 5, 12\].
Once the pattern ofcommunication between processors is settled, it iseasier to attach a new semnntlcs to the hooks alreadyprovided in the Kr~,mar than to build a new semanticprocessor.
In addition, because each module ban onlyto consider a portion of the constraints implicit inthe data (e.g.
syntactic constraints, semanticconstraints and discourse context), each module can bedesigned to optimize its own processing and provide anefficient system.The panel has also been charged wlth _ ~oslder lngpaa'allel processing as a challenge to its views onparsing.
Thls touches on our beliefs about theInteraction among the modules that comprise the HLUsystem.
To respond to this issue, we first want todlstlngulsh between two types of parallelism: one, inwhich many instances of the same thin6 are done at once ~(an in an array of parallel adders-) and another, inwhich the many thinks done slmul~aneously can bedifferent.
Supporting this latter type of parallelismdoesn*t change our view of parsing, but ratherunderlies it.
We believe that the Interconnectedprocesses involved in NLU must support a banjoo~eratinK pr i~ip le  that Herman and Bobrow \[14\] havecalled "The Principle of Continually Available Output":,(CAO).
This states that the Interactlng processes muat~ben in  to  prov ide  output  over  a wide range  o f  resourceallocations, even before their analyses are complete,and even before all input data is available.
We takethis position for two rensons: one, it facilitatescomputational efficiency, and two, it seems to becloser to human parsing ~rocesses (a point which wewill get to in answerlnK the next question).The requirement that syntactic analysis, semanticinterpretation and discourse processlng must be able tooperate in (pseudo-)parallel, obeying the CAO2that  i s ,  so le ly  on the baa?s  o f  syntact i ccategor ies / features  and order ing  In format ionprinciple, has sparked our interest in the design ofcalrs of processes which can pass forward and backwardunet~Ll In/ormatlon/advlce/questlons as soon aspossible.
The added potential for interaction of suchprocessors can increase the capab i l i ty  and efficiencyof the overall HLU process.
Thus, for example, if thesyntactic module makes its intermediate decisionsava i lab le  to semantics and~or pragmatlcs, then thoseprocessors can evaluate those decisions, guide syntax'sfu ture  behav ior  and ,  in  add i t ion ,  deve lop  in  para l le lthe i r  own ana lyses .
Hav ing  sent  on i t s  la tes tassertlon/advlce/question, whether syntax then decidesto  continue on with something else or  walt fo r  aresponse will depend on the  particular k ind  o f  messagesent.
Thus, the parsers and grammars that concern usare ones able to work with other appropriately designedcompoconts to  support CAO.
While the equipment we areUSing to implement and tes t  our ideas is serial, wetake very seriously the notion of parallelism.Finally under the heading of "ComputationalPerspect ive" ,  we are  anked about  what  might  mot ivateour  t ry ing  to  make pars ing  procedures  s imulate  what  wesuspect human parsing processes to be like.
Onemotivation for us is the belief that natural languageis so tuned to the part extraordinary, part banalcognitive capabilities of human beings that only bysimulating human parsing processes can we cover all andon ly  the language phenomena that  we are  called upon toprocess.
A particular (extraordinary) aspect of hu~ancognitive (and hence, parsing) behavior that we want toexplore and eventually simulate is people's ability torespond even under  degraded data  or  resourcel im i ta t ions .
There  are  examples  o f  l i s tenersin i t ia t ing  reasonab le  responses  to  an ut terance  evenbefore the utterance is complete, and in some case evenbefore a complete syntactic unit has been heard.Simultaneous translation is ode notable example \[8\],and another  i s  p rov ided  by the  per fo rmance  o f  sub jectsin  a verba l ly  gu ided  assembly  task  repor ted  by P. Cohen\ [6 \ ] .
Such an ab i l i ty  to  produce  output  be fore  a l linput  data  is available (or before enough processingresources  have  been made ava i lab le  to  produce  the  bestposs ib le  response)  i s  what  led  Norman and Bobrow tofo rmulate  the i r  CAO Pr inc ip le .
Our in teres t  i s  inarchitectures for NLU systems which support CAO and in?
search  strategies through such architectures fo r  anopti~"l interpretation.The LimnLiStlC ~rs~et lveWe have been asked to comment on legitimate inferencesabout human linsulstic competence and performance thatwe can draw from our experiences with mechanicalpars ing  o f  formal grammar.
Our response is thatwhatever parsing is for natural languages, it is stillonly part of a larger process.
Just because we knowwhat parsing is in formal language systems, we do notsecsssarily know what role it plays is in the contextOf total communication.
S imply  put, formal notions ofparsing underconstraln the goals of  the syntacticcomponent of an NLU system.
Efficiency meanures, basedon  the resources required for generation of one or allcomplete  parses for s sentence, without  semantic orpra~e~-tlc Intera~tlon, do not secessarily specifydesirable properties o f  a natural language syntacticanalysis component.As for whether the efficiency of parsing algorlthm~ forCF or regular grammars suggest that the core of NLigremmars la CF or regular, we want to dlstlngulsh thatpart of perception (and hence, syntactic analysis)which groups the stimulus into recognizable units fromthat  part which fills in gaps in in/ormatlon(inferentially) on the baals of such groups.
Resultsin CF grammar theory says that grouping is not bestdose  pure ly  bot tom-up,  that there are advantages tot ~us lng  predictive mechanlsms a~ well \[9, 7\].
Thlssnggests two things for parsing natural language:I.
There is a level of evidence and a processfor using it that is worEing to suggestgroups .2.
There is another filtering, inferenclngmechanism that maEes predictions anddiagnoses on the basis of those groups.It is possible that the grouping mechanism may make useof strategies applicable to CF parsing, such as well-formed substrlng tables or charts, without requiringthe overall language specification be CF.
In ourcurrent RUS/PSI-ELONE system, grouping is a function ofthe syntactic module: its output consists of suggestedgroupings.
These snggestlons may be at abstract,specific or disjunctive.
For example, an abstractdescription m~ht  be "this is the head of an NP,everyth ing  to  i t s  le f t  i s  a pre -mod i f le r " .
Here therei s  co comment about  exact ly  how these  pre -mod l f le rsg roup .
A d i s junct ive  descr ip t ion  wou ld  cons is t  o f  anexp l i c i t  enumerat ion  o f  a l l  the  poss ib i l i t ies  a t  somepo in t  (e .g .
,  " th i s  i s  e i ther  a t ime prepos i t iona lphrase  (PP) o r  an agent ive  PP or  a locat ive  PP, e tc . "
) .Disjunctive descriptions allow us to  prune .possibilities via cane a~alysls.In short, we believe in using as much evidence fromformal systemn a~ seems understandable and reasonable,to const ra in  what the  system should be do ing .The InteraetlonsF ina l ly ,  we have  been asked  about  the  nature  o f  there la t ionsh ip  between a gr~mar  and a procedure  fo rapp ly ing  i t .
On the  sys tems bu i ld ing  s ide ,  cur  fee l ingis that while one should be able to take a grammar andconvert it to a recognition or generationprocedure \[I0\], it is likely that such procedures willembody a whole set of principles that are controlstructure related, and not part of the grammar.
Forexample, a gr',-mr seed not specify in what order tolook for thln~s or  in  what order decisions should bemade.
Thus, one may not be able to reconstruct thegrammar unlcuelv from a procedure for applying it.On the other hand, on the b ,m-  parsing side, wedefinitely feel that natural language is strongly tunedto both people's means of production and their means ofrecognition, and that principles llke MnDonalds 'Znde l ib l l l ty  Pr"Inoiple \[13\] or  Marcus' DeterminismHypothesis \[11\] shape what are (and are not) seen ansentences of the language.REFERENCESI.
Bobrow, R. J.
The RUS System.
BEN Report 3878,Bolt Beranek and Rewman Inc., 1978.2.
Bobrow, R. J.
& Webber, B. L. PS I -ELONE-  Parsingand Semantic Interpretation in the BBN Natural LanguageUnderstanding System.
CSCSI/C~EI0 Annual Conference,CSC3I/CSEIO, 1980.3.
Bobrow, R. J .
& Webber,  B. L. KnowledgeRepresentat ion  fo r  Syntact i c /Semant ic  P rocess ing .P roceed ings  o f  The F i r s t  Annual  Nat iona l  Conference  onAr t i t i c ia l  In te l l igence ,  Amer ican  Assoc ia t ion  fo rArtif icial Intelligence, 1980.98~.
Bobrow, R.J. & Webber, B.L.
Pars ing and SemanticIn terpretat ion  as an Incremental  Recognit ion Process.Proceedings of  a Symposium on Modelling Human ParsingSt ra teg ies ,  Center for  Cognitive Science, Univers i ty  o\[Texas, Austin TZ, 1981.5.
Bobrow, R.J. & Webber, B.L.
Systems Considerat ionsfor  Search by Cooperating Processes:  ProvidingContinual ly Ava/lable Output.
Proceedings of the SixthIJCAI, In ternat iona l  Jo in t  Conference on Ar t i f i c ia lIn te l l igenoe ,  1981.6.
Cohen, P. personal  communication, videotape ofexperimental task7.
Eau-ley, J .
An e f f i c ient  context- f l 'ee pars ingalgor i thm.
~ of the ACM /~ (February1970), 9~',- 102.8.
Gold~an-Eisler, F. Psyohologloal Heohanisms ofSpeech Produotlon as SSudled through the Analysis ofSimultaneous Translation.
In B. Butterworth, Ed.,Lan~rn~e Production, Aoademlc Press, 1980.9.
Graham, S., Harrison, M. and Ruzzo, W. An ImprovedContext-Free Recognizer.
ACM ~ onPnom,-mm4,~ Lana~es  and Systems (July 1980), "16-@63.10.
Kay, M. An Algorithm for Compiling Parsing Tablesf~om a Grammar.
Prooeedings of a Symposium onModelling Human Parsing Strate~Les, Center forCognitive Science, University of Texas, Austin TX,1981.11.
MaPcus, M. A Theory of .qvntactic ~ forMat~a l  Lan~e.
MIT Press, 1980.12.
Mark, W. S. & Barton, G. E. The RUSGrammarParsing System.
GMR 32"3, General Motors ResearchLaboratories, 1980.13.
MoDonald, D.
???.
Ph.D.
Th., MassachusettsInstitute o?
Technology, 1980.I,.
~orman, D. & Bobrow, D. On Data- i i~ted andResource-llmlted ProoesSes.
CSL7,-2, Xerox PARC, Msy,197,.99
