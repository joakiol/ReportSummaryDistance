Proceedings of EACL '99A Flexible Architecture for Reference ResolutionDonna K. Byron and Joel R. TetreaultDepartment of Computer ScienceUniversity of RochesterRochester NY 14627, U.S.A.dbyron/tetreaul@cs, rochester, eduAbstractThis paper describes an architecturefor performing anaphora resolution ina flexible way.
Systems which con-form to these guidelines are well-encapsulated and portable, and canbe used to compare anaphora resolu-tion techniques for new language un-derstanding applications.
Our im-plementation of the architecture ina pronoun resolution testing platformdemonstrates the flexibility of the ap-proach.1 IntroductionWhen building natural language understand-ing systems, choosing the best technique foranaphora resolution is a challenging task.
Thesystem builder must decide whether to adopt anexisting technique or design a new approach.A huge variety of techniques are described inthe literature, many of them achieving high suc-cess rates on their own evaluation texts (cf.Hobbs 1986; Strube 1998; Mitkov 1998).
Eachtechnique makes different assumptions about thedata available to reference resolution, for ex-ample, some assume perfect parses, others as-sume only POS-tagged input, some assume se-mantic information is available, etc.
The chancesare high that no published technique will ex-actly match the data available to a particular sys-tem's reference resolution component, so it mayThe authors thank James Allen for help on this project, aswell as the anonymous reviewers for helpful comments onthe paper.
This material is based on work supported byUSAF/Rome Labs contract F30602-95-1-0025, ONR grantN00014-95-1 - 1088, and Columbia Univ.
grant OPG: 1307.229not be apparent which method will work best.Choosing a technique is especially problematicfor designers of dialogue systems trying to pre-dict how anaphora resolution techniques devel-oped for written monologue will perform whenadapted for spoken dialogue.
In an ideal world,the system designer would implement and com-pare many techniques on the input data availablein his system.
As a good software ngineer, hewould also ensure that any pronoun resolutioncode he implements can be ported to future ap-plications or different language domains withoutmodification.The architecture described in this paper wasdesigned to provide just that functionality.Anaphora resolution code developed within thearchitecture is encapsulated to ensure portabil-ity across parsers, language genres and domains.Using these architectural guidelines, a testbedsystem for comparing pronoun resolution tech-niques has been developed at the University ofRochester.
The testbed provides a highly config-urable environment which uses the same pronounresolution code regardless of the parser front-endand language type under analysis.
It can be used,inter alia, to compare anaphora resolution tech-niques for a given application, to compare newtechniques to published baselines, or to comparea particular technique's performance across lan-guage types.2 The Architecture2.1 Encapsulation of layersFigure 1 depicts the organization of the architec-ture.
Each of the three layers have different re-sponsibilities:Proceedings of EACL '99Layer 1: Supervisor layer controls which Translation and Anaphora resolution modules are active for the current est.Treebank Translator 2: TRAINS93 surroundingsystem\[ T lator3: \] .
.
.
.Other domainOl.~OurSe / iAnalysi .
.
.
.
.
I / /  Context: /Structure l discourse referent'?
\[ containsanalysis J k \ ] \ [d i  .
.
.
.
.
.
{~ referent tokens~\ in a standard \ Layer 2: Translation layer turns input text ~ formatinto standard format for discourse referents.Coreference \[Semantic type matching 1nalysis for \[lbr pronouns Jefinite NPSHobbs naive lagreement for |algorithm \[,pronouns jIT emporal anaphora qesolution JLayer 3: Anaphora Resolution posts resultsof its analysis back to the discourse context.Figure 1: Reference Resolution Architecture?
Layer 1: The supervisor controls whichmodules in Layers 2 and 3 execute, In ourimplementation, the supervisor sets a run-time switch for each module in layer 2 and3, and the first instruction of each of thosemodules checks its runtime flag to see if it isactive for the current experiment.?
Layer 2: Translation reads the input textand creates the main data structure usedfor reference resolution, called the discoursecontext (DC).
The DC consists of discourseentities (DEs) introduced in the text, some ofwhich are anaphoric.
This layer contains allsyntactic and semantic analysis componentsand all interaction with the surrounding sys-tem, such as access to a gender database ora lexicon for semantic restrictions.
All fea-tures that need to be available to referenceresolution are posted to the DC.
This layeris also responsible for deciding which inputconstituents create DEs.?
Layer 3: Anaphora resolution contains avariety of functions for resolving differenttypes of anaphora.
Responsibilities of thislayer include determining what anaphoricphenomena are to be resolved in the currentexperiment, determining what anaphora res-olution technique(s) will be used, and de-termining what updates to make to the DC.Even though the modules are independent ofthe input format, they are still somewhat de-pendent on the availability of DE features.If a feature needed by a particular esolutionmodule was not created in a particular ex-periment, the module must either do withoutit or give up and exit.
This layer's output isan updated DC with anaphoric elements re-230solved to their referents.
If labeled trainingdata is available, this layer is also responsi-ble for calculating the accuracy of anaphoraresolution.2.2 Benefits of this designThis strict delineation of responsibilities betweenlayers provides the following advantages:?
Once a translation layer is written for aspecific type of input, all the implementedanaphora resolution techniques are immedi-ately available and can be compared.?
Different models of DC construction can becompared using the same underlying refer-ence resolution modules.?
It is simple to activate or deactivate achcomponent of the system for a particular ex-periment.3 ImplementationWe used this architecture to implement a testingplatform for pronoun resolution.
Several experi-ments were run to demonstrate the flexibility ofthe architecture.
The purpose of this paper is notto compare the pronoun resolution results for thetechniques we implemented, so pronoun resolu-tion accuracy of particular techniques will not bediscussed here.l Instead, our implementation isdescribed to provide some examples of how thearchitecture can be put to use.3.1 Supervisor layerThe supervisor layer controls which moduleswithin layers 2 and 3 execute for a particular ex-periment.
We created two different supervisort See (Byron and Allen.
1999; Tetreault, 1999) for resultsof pronoun resolution experiments run within the testbed.Proceedings of EACL '99modules in the testbed.
One of them simply readsa configuration file with runtime flags hard-codedby the user.
This allows the user to explicitly con-trol which parts of the system execute, and will beused when a final reference resolution techniquesis chosen for integration into the TRIPS systemparser (Ferguson and Allen, 1998).The second supervisor layer was coded as a ge-netic algorithm (Byron and Allen, 1999).
In thismodule, the selection of translation layer modulesto execute was hard-coded for the evaluation cor-pus, but pronoun resolution modules and meth-ods for combining their results were activated andde-activated by the genetic algorithm.
Using pro-noun resolution accuracy as the fitness function,the algorithm learned an optimal combination ofpronoun resolution modules.3.2 Translation layerTranslation layer modules are responsible for allsyntactic and semantic analysis of the input text.There are a number of design features that mustbe controlled in this layer, such as how the dis-course structure affects antecedent accessibilityand which surface constituents rigger DEs.
Allthese design decisions hould be implemented asindependent modules so that they can be turnedon or off for particular experiments.Our experiments created translation modulesfor two evaluation corpora: written news sto-ries from the Penn Treebank corpus (Marcus etal., 1993) and spoken task-oriented ialoguesfrom the TRAINS93 corpus (Heeman and Allen,1995).
The input format and features added ontoDEs from these two corpora are very different,but by encapsulating the translation layer, thesame pronoun resolution code can be used forboth domains.
In both of our experiments onlysimple noun phrases in the surface form triggeredDEs.Treebank texts contain complete structuralparsers, POS tags, and annotation of theantecedents of definite pronouns (added byGe et al 1998).
Because of the thorough syntac-tic information, DEs can be attributed with ex-plicit phrase structure information.
This corpuscontains unconstrained news stories, so semantictype information is not available.
The Treebanktranslator module adds the following features toeach1.DE:Whether its surface constituent is containedin reported speech;2.
A list of parent nodes containing its surfaceconstituent in the parse tree.
Each node'sunique identifier encodes the phrase type(i.e.
VB, NP, ADJP);3.
Whether the surface constituent is in the sec-ond half of a compound sentence;4.
The referent's animacy and gender from ahand-coded agreement-feature database.A second translation module was created for aselection of TRAINS93 dialogue transcripts.
Theinput was POS-tagged words with no structuralanalysis.
Other information, such as basic punc-tuation and whether each pronoun was in a mainor subordinate clause, had previously been hand-annotated onto the transcripts.
We also created aninterface to the semantic type hierarchy within theTrains system and added semantic information tothe DEs.Common DE attributes for both corpora:I. Plural or singular numeric agreement;2.
Whether" the entity is contained in the subjectof the matrix clause;3.
Linear position of the surface constituent;4.
Whether its surface constituent is definite orindefinite;5.
Whether its surface constituent is containedin quoted speech;6.
For pronoun DEs, the id of the correct an-tecedent (used for evaluation).3.3 Anaphora resolution layerModules within this layer can be coded to resolvea variety of anaphoric phenomena in a variety ofways.
For example, a particular experiment maybe concerned only with resolving pronouns or itmight also require determination of coreferencebetween definite noun phrases.
This layer is rem-iniscent of the independent anaphora resolutionmodules in the Lucy system (Rich and LuperFoy,1988), except hat modules in that system werenot designed to be easily turned on or off.For our testbed, we implemented a variety ofpronoun resolution techniques.
Each technique231Proceedings of EACL '99Pronoun resolution moduleBaseline most-recent technique that chooses closest entity to the left of the pronounChoose most recent entity that matches sub-categorization restrictions on the verbStrobe's -list algorithm (Strube, 1998)Boost salience for the first entity in each sentenceDecrease salience for entities in prepositional phrases or relative clausesIncrease the salience for non-subject entities for demonstrative pronoun resolution (Schiffman, 1985)Decrease salience for indefinite ntitiesDecrease salience for entities in reported speechIncrease the salience of entities in the subject of the previous sentenceIncrease the salience of entities whose surface form is pronominalActivated forTreebankActivated forTRAINS93X XXXX XX XXXX Xxx xx xTable 1" Pronoun resolution modules used in our experimentscan run in isolation or with the addition of meta-modules that combine the output of multiple tech-niques.
We implemented meta-modules to in-terface to the genetic algorithm driver and tocombine different salience factors into an over-all score (similar to (Carbonell and Brown, 1988;Mitkov, 1998)).
Table 1 describes the pronounresolution techniques implemented at this point,and shows whether they are activated for theTreebank and the TRAINS93 experiments.
Al-though each module could run for both experi-ments without error, if the features a particularmodule uses in the DE were not available, wesimply de-activated the module.
When we mi-grate the TRIPS system to a new domain thisyear, all these pronoun resolution methods will beavailable for comparison.4 SummaryThis paper has described a framework for ref-erence resolution that separates details of thesyntactic/semantic interpretation process fromanaphora resolution in a plug-and-play architec-ture.
The approach is not revolutionary, it sim-ply demonstrates how to apply known softwareengineering techniques to the reference resolu-tion component of a natural anguage understand-ing system.
The framework enables compari-son of baseline techniques across corpora and al-lows for easy modification of an implementedsystem when the sources of information availableto anaphora resolution change.
The architecturefacilitates experimentation different mixturesof discourse context and anaphora resolution al-gorithms.
Modules written within this frameworkare portable across domains and language gen-res.ReferencesDonna K. Byron and James E Allen.
1999.
A geneticalgorithms approach to pronoun resolution.
Techni-cal Report 713, Department of Computer Science,University of Rochester.Jaime G. Carbonell and R.D.
Brown.
1988.
Anaphoraresolution: a multy-strategy approach.
In COL-ING '88, pages 96--101.George Ferguson and James E Allen.
1998.
Trips:An intelligent integrated problem-solving assistant.In Proceedings of AAAI '98.Niyu Ge, John Hale, and Eugene Charniak.
1998.
Astatistical approach to anaphora resolution.
In Pro-ceedings of the Sixth Workshop on Very Large Cor-pora.Peter A. Heeman and James E Allen.
1995.
TheTrains spoken dialog corpus.
CD-ROM, Linguis-tics Data Consortium.Jerry Hobbs.
1986.
Resolving pronoun reference.
InReadings in Natural Language Processing.
MorganKaufmann.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of english: The Penn Treebank.
Computa-tional Linguistics, 19(2):313-330.Ruslan Mitkov.
1998.
Robust pronoun resolution withlimited knowledge.
In Proceedings of ACL '98,pages 869-875.Elaine Rich and Susann LuperFoy.
1988.
An archi-tecture for anaphora resolution.
In Conference onApplied NLP, pages 18-24.Rebecca Schiffman.
1985.
Discourse constraints on'it' and 'that': A study of language use in career-counseling interviews.
Ph.D. thesis, University ofChicago.Michael Strube.
1998.
Never look back: An alterna-98, pa=es tive to centering.
In Proceedings of ACL ' "1251-1257.Joel R. Tetreault.
1999.
Analysis of syntax-basedpronoun resolution methods.
In Proceedings ofACL '99.232
