Proceedings of the Joint Conference on EMNLP and CoNLL: Shared Task, pages 83?87,Jeju Island, Korea, July 13, 2012. c?2012 Association for Computational LinguisticsSimple Maximum Entropy Models for Multilingual Coreference ResolutionXinxin Li, Xuan Wang, Xingwei LiaoComputer Application Research CenterHarbin Institute of Technology Shenzhen Graduate SchoolShenzhen, Chinalixxin2@gmail.comAbstractThis paper describes our system participat-ing in the CoNLL-2012 shared task: Mod-eling Multilingual Unrestricted Coreferencein Ontonotes.
Maximum entropy models areused for our system as classifiers to deter-mine the coreference relationship between ev-ery two mentions (usually noun phrases andpronouns) in each document.
We exploit richlexical, syntactic and semantic features for thesystem, and the final features are selected us-ing a greedy forward and backward strategyfrom an initial feature set.
Our system partici-pated in the closed track for both English andChinese languages.1 IntroductionIn this paper, we present our system for the CoNLL-2012 shared task which aims to model coreferenceresolution for multiple languages.
The task of coref-erence resolution is to group different mentions in adocument into coreference equivalent classes (Prad-han et al, 2012).
Plenty of machine learning al-gorithms such as Decision tree (Ng and Cardie,2002), maximum entropy model, logistic regres-sion (Bjo?rkelund and Nugues, 2011), Support Vec-tor Machines, have been used to solve this problem.Meanwhile, the CoNLL-2011 shared task on En-glish language show that a well-designed rule-basedapproach can achieve a comparable performance asa statistical one (Pradhan et al, 2011).Our system treats coreference resolution problemas classification problem by determining whetherevery two mentions in a document has a corefer-ence relationship or not.
We use maximum entropy(ME) models to train the classifiers.
Previous workreveal that features play an important role on coref-erence resolution problem, and many different kindsof features has been exploited.
In this paper, we usemany different lexical, syntactic and semantic fea-tures as candidate features, and use a greedy forwardand backward approach for feature selection for MEmodels.2 System DescriptionThe framework of our system is shown in figure 1.
Itincludes four components: candidate mention selec-tion, training example generation, model generation,and decoding algorithm for test data.
The details ofeach component as described below.2.1 Candidate Mention SelectionIn both training and test sets, our system only con-sider all noun phrases (NP) and pronouns (PRP,PRP$) as candidate mentions for both English andChinese.
The mentions in each sentence are ob-tained from given syntactic tree by their syntacticlabel.
Other phrases in the syntactic tree are omit-ted due to their small proportion.
For example, inthe English training dataset, our candidate mentionsincludes about 91% of golden mentions.2.2 Training Example GenerationThere are many different training example gen-eration algorithms, e.g., McCarthy and Lehnert?smethod, Soon et als method, Ng and Cardiesmethod (Ng, 2005).
For our baseline system, wechoose Soon et al?s method because it is easily un-derstandable, implemented and popularly used.
It83Figure 1: The framework of our coreference resolutionsystemselects pairs of two coreferent mentions as positiveexamples, and pairs between mentions among thetwo mentions and the last mention as negative ex-amples.2.3 Feature SelectionRich and meaningful features are important forcoreference resolution.
Our system starts withSoon?s 12 features as baseline features (Soon et al,2001), and exploits many lexical, syntactic, and se-mantic features as candidate features.
Totally 71 fea-tures are considered in our system, and summarizedbelow: Distance features: sentence distance, distancein phrases, whether it?s a first mention (Strubeet al, 2002) Lexical features: string match, partial match,apposition, proper name match, head wordmatch, partial head word match, minimum editdistance (Daume?
III and Marcu, 2005) Grammatical features: pronoun, demonstrativenoun phrase, embedded noun, gender agree-ment, number agreement (Soon et al, 2001) Syntactic features: same head, maximal NP,syntactic path (Yang et al, 2006) Semantic features: semantic class agreement,governing verb and its grammatical role, predi-cate (Ponzetto and Strube, 2006)For English, the number agreement and genderagreement features can be obtained through the gen-der corpus provided.
However, there is no corpusfor Chinese.
Our system obtains this informationby collecting dictionaries for number and gender in-formation from training dataset.
For example, theAlgorithm 1 Greedy forward and backward featureselectionInitialization: all candidate features in set CChoose initial feature setCompute F1 with features cwhile forward jj backward:while forward:for each feature f in C-cCompute F1 with features c+fif best(F1) increases:backward = true, c=c+f, continue forwardelse forward = falsewhile backward:for each feature f in in cCompute F1 with features c-fif best(F1) increases:forward = true, c=c-f continue backwardelse backward = falsepronoun ???
(he) denotes a male mention, and thenoun phrase ?s??
(girlfriend) represents a femalemention.
Similarly for number information, e.g., thementions containing ???
(and), ???
(group) areplural.
We use these words to build number andgender dictionaries, and determine the number andgender information of a new mention by checkingwhether one of the words in the dictionaries is in themention.For semantic class agreement feature in English,the relation between two mentions is extracted fromWordNet 3.0 (Ng, 2007),(Miller, 1995).
There is nocorresponding dictionary for Chinese, so we keepit blank.
The head word for each mention is se-lected by its dependency head, which can be ex-tracted throught the conversion head rules ( English1 and Chinese 2).Maximum Entropy modeling is used to train theclassifier for our system 3.
We employ a greedy for-ward and backward procedure for feature selection.The procedure is shown in Algorithm 1.The algorithm will iterate forward and backwardprocedures until the performance does not improve.We use two initial feature sets: a blank set andSoon?s baseline feature set.
Both feature sets start1http://w3.msi.vxu.se/ nivre/research/headrules.txt2http://w3.msi.vxu.se/ nivre/research/chn headrules.txt3http://homepages.inf.ed.ac.uk/lzhang10/maxent.html84with a forward procedure.2.4 DecodingFor every candidate mention pair, to determine theircoreference relationship is simple because the prob-ability whether they are coreferent can be obtainedby our maximum entropy model.
We can just set athreshold  = 0:5 and select the pairs with probabil-ity larger than .
But usually it is hard for multiplementions.
Suppose there are three mentions A, B, Cwhere the probability between A and B, A and C islarger than , but B and C is small.
Thus choosingan appropriate decoding algorithm is necessary.We use best-first clustering method for our systemwhich for each candidate mention in a document,chooses the mention before it with best probabilitylarger than threshold .
The difference between En-glish and Chinese is that we consider the coreferencerelationship of two mentions nested in Chinese, butnot in English.3 Experiments3.1 SettingOur system participates in the English and Chineseclosed tracks with auto mentions.
For both the En-glish and Chinese datasets, we use gold annotatedtraining data for training, and a portion of auto an-notated development data for feature selection.
Onlypart of development data is chosen because the eval-uation procedure takes lot of time.
To simplify, Weonly select one or two file in each directory as ourdevelopment data.The performance of the system is evaluated onMUC, B-CUBED, CEAF(M), CEAF(E), BLANCmetrics.
The official metric is calculated as(MUC+B3+CEAF )=3.3.2 Development setFigures 2 and 3 show the performance on the En-glish and Chinese development datasets using fea-ture selection starting from a empty feature set andSoon?s baseline feature set.
The x-axis means thenumber of iterations with either forward or back-ward selection.
The performance on Soon?s baselinefeature set for both languages are shown on 1st itera-tion.
The performance from empty feature set startson 2nd iteration.
From these figures, we can see thatFigure 2: Performance of English development data withFeature selectionFigure 3: Performance of Chinese development data withFeature selectionusing feature selection in both initial feature sets, theperformance improves.However the performance of our system is im-proved only on a few iteration.
The best system forEnglish stops at the 4th iteration with total 10 fea-tures left, which starts from Soon?s baseline featureset.
Similarly, the system for Chinese achieves itsbest performance at the 4th iteration with only 8 fea-tures.
The phenomenon reveals that most of the fea-tures left for our system are still from Soon?s base-line features, and our newly exploited lexical, syn-tactic, and semantic features are not well utilized.Then we evaluate our model on the entire devel-opment data.
The results are shown on Table 1.Comparing Figures 2, 3 and Table 1, we can observethat the performance on entire development data islower than part one, about 1% decrease.3.3 TestFor test data, we retrain our model on both goldtraining data and development data using the se-lected features.
The final results for English andChinese are shown in Table 2.85Model English ChineseMUC 49.28 48.31B3 62.79 67.97CEAF(M) 46.77 49.49CEAF(E) 38.19 38.9BLANC 66.31 68.91Average 50.09 51.73Table 1: Results on entire development dataModel English ChineseMUC 48.27 48.09B3 61.37 68.31CEAF(M) 44.83 49.92CEAF(E) 36.68 38.89BLANC 65.42 71.44Official 48.77 51.76Table 2: Results on test dataComparing tables 2 and 1, we can observe thatthe performance for the Chinese test data is similaras the development data.
The result seems reason-able because the model for testing use additional de-velopment data which is much smaller than trainingdata.
However, the result on English test data seem alittle odd.
The performance is about 1.4% less thanthat on the development data.
The result needs fur-ther analysis.4 ConclusionIn this paper, we presented our coreference resolu-tion system which uses maximum entropy model todetermine the coreference relationship between twomentions.
Our system exploits many lexical, syn-tactic and semantic features.
However, using greedyforward and backward feature selection strategy forME model, these rich features are not well utilized.In future work we will analyze the reason for thisphenomenon and extend these features to other ma-chine learning algorithms.ReferencesAnders Bjo?rkelund and Pierre Nugues.
2011.
Explor-ing lexicalized features for coreference resolution.
InProceedings of the Fifteenth Conference on Compu-tational Natural Language Learning: Shared Task,pages 45?50, Portland, Oregon, USA, June.
Associ-ation for Computational Linguistics.Hal Daume?
III and Daniel Marcu.
2005.
A large-scaleexploration of effective global features for a joint en-tity detection and tracking model.
In Proceedings ofHuman Language Technology Conference and Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 97?104, Vancouver, British Columbia,Canada, October.
Association for Computational Lin-guistics.George A. Miller.
1995.
Wordnet: a lexical databasefor english.
Communications of the ACM, 38:39?41,November.Vincent Ng and Claire Cardie.
2002.
Improvingmachinelearning approaches to coreference resolution.
In Pro-ceedings of the ACL, pages 104?111.Vincent Ng.
2005.
Machine learning for coreference res-olution: From local classification to global ranking.
InProceedings of the 43rd Annual Meeting of the Asso-ciation for Computational Linguistics (ACL?05), pages157?164, Ann Arbor, Michigan, June.
Association forComputational Linguistics.Vincent Ng.
2007.
Semantic class induction and coref-erence resolution.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 536?543, Prague, Czech Republic, June.Association for Computational Linguistics.Simone Paolo Ponzetto and Michael Strube.
2006.
Ex-ploiting semantic role labeling, wordnet and wikipediafor coreference resolution.
In Proceedings of the Hu-man Language Technology Conference of the NAACL,Main Conference, pages 192?199, New York City,USA, June.
Association for Computational Linguis-tics.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and Nianwen Xue.2011.
Conll-2011 shared task: Modeling unrestrictedcoreference in ontonotes.
In Proceedings of the Fif-teenth Conference on Computational Natural Lan-guage Learning: Shared Task, pages 1?27, Portland,Oregon, USA, June.
Association for ComputationalLinguistics.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 shared task: Modeling multilingual unrestrictedcoreference in OntoNotes.
In Proceedings of theSixteenth Conference on Computational Natural Lan-guage Learning (CoNLL 2012), Jeju, Korea.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to coref-erence resolution of noun phrases.
Comput.
Linguist.,27:521?544, December.Michael Strube, Stefan Rapp, and Christoph Mu?ller.2002.
The influence of minimum edit distance on86reference resolution.
In Proceedings of the ACL-02conference on Empirical methods in natural languageprocessing - Volume 10, EMNLP ?02, pages 312?319,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2006.Kernel-based pronoun resolution with structured syn-tactic knowledge.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics and44th Annual Meeting of the Association for Compu-tational Linguistics, pages 41?48, Sydney, Australia,July.
Association for Computational Linguistics.87
