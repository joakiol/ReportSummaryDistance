Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 54?61,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsStatistical Machine Translation in Low Resource SettingsAnn IrvineCenter for Language and Speech ProcessingJohns Hopkins UniversityAbstractMy thesis will explore ways to improve theperformance of statistical machine translation(SMT) in low resource conditions.
Specif-ically, it aims to reduce the dependence ofmodern SMT systems on expensive paralleldata.
We define low resource settings as hav-ing only small amounts of parallel data avail-able, which is the case for many languagepairs.
All current SMT models use paralleldata during training for extracting translationrules and estimating translation probabilities.The theme of our approach is the integrationof information from alternate data sources,other than parallel corpora, into the statisti-cal model.
In particular, we focus on makinguse of large monolingual and comparable cor-pora.
By augmenting components of the SMTframework, we hope to extend its applicabil-ity beyond the small handful of language pairswith large amounts of available parallel text.1 IntroductionStatistical machine translation (SMT) systems areheavily dependent on parallel data.
SMT doesn?twork well when fewer than several million lines ofbitext are available (Kolachina et al 2012).
Whenthe available bitext is small, statistical models per-form poorly due to the sparse word and phrasecounts that define their parameters.
Figure 1 gives alearning curve that shows this effect.
As the amountof bitext approaches zero, performance drops dras-tically.
In this thesis, we seek to modify the SMTmodel to reduce its dependence on parallel data and,thus, enable it to apply to new language pairs.Specifically, we plan to address the followingchallenges that arise when using SMT systems inlow resource conditions:l ll lll lll l lll l1e+02 1e+03 1e+04 1e+05 1e+060510152025Lines of Training BitextBLEUscoreFigure 1: Learning curve that shows how SMT per-formance on the Spanish to English translation task in-creases with increasing amounts of parallel data.
Perfor-mance is measured with BLEU and drops drastically asthe amount of bitext approaches zero.
These results usethe Europarl corpus and the Moses phrase-based SMTframework, but the trend shown is typical.?
Translating unknown words.
In the contextof SMT, unknown words (or out-of-vocabulary,OOV) are defined as having never appeared inthe source side of the training parallel corpus.When the training corpus is small, the percentof words which are unknown can be high.?
Inducing phrase translations.
In high re-source conditions, a word aligned bitext is usedto extract a list of phrase pairs or translationrules which are used to translate new sentences.With more parallel data, this list is increasinglycomprehensive.
Using multi-word phrases in-stead of individual words as the basic transla-tion unit has been shown to increase translationperformance (Koehn et al 2003).
However,when the parallel corpus is small, so is the num-ber of phrase pairs that can be extracted.?
Estimating translation probabilities.
In thestandard SMT pipeline, translation probabil-ities are estimated using relative frequencycounts over the training bitext.
However, whenthe bitext counts are sparse, probability esti-54Language #Words Language #WordsNepali 0.4 Somali 0.5Uzbek 1.4 Azeri 2.6Tamil 3.7 Albanian 6.5Bengali 6.6 Welsh 7.5Bosnian 12.9 Latvian 40.2Indonesian 21.8 Romanian 24.1Serbian 25.8 Turkish 31.2Ukrainian 37.6 Hindi 47.4Bulgarian 49.5 Polish 104.5Slovak 124.3 Urdu 287.2Farsi 710.3 Spanish 972Table 1: Millions of monolingual web crawl andWikipedia word tokensmates are likely to be noisy.My thesis focuses on translating into English.
Weassume access to a small amount of parallel data,which is realistic, especially considering the recentsuccess of crowdsourcing translations (Zaidan andCallison-Burch, 2011; Ambati, 2011; Post et al2012).
Additionally, we assume access to largermonolingual corpora.
Table 1 lists the 22 languagesfor which we plan to perform translation experi-ments, along with the total amount of monolingualdata that we will use for each.
We use web crawledtime-stamped news articles and Wikipedia for eachlanguage.
We have extracted the Wikipedia pageswhich are inter-lingually linked to English pages.2 Translating Unknown WordsOOV words are a major challenge in low resourceSMT settings.
Here, we describe several approachesto identifying translations for unknown words.2.1 TransliterationFor non-roman script languages, in some cases,OOV words may be transliterated rather than trans-lated.
This is often true for named entities,where transliterated words are pronounced approxi-mately the same across languages but have differentspellings in the source and target language alphabets(e.g.
Russian Anna translates as English Anna).
Inthe case of roman script languages, of course, suchwords are often translated correctly without change(e.g.
French Anna translates as English Anna).In my prior work, Irvine et al(2010a) andIrvine et al(2010b), I have presented a language-independent approach to gathering pairs of translit-erated words (specifically, names) in a pair of lan-guages, built a module to transliterate from one lan-guage to the other, and integrated the output into anend-to-end SMT system.
In my thesis, I will usethis technique to hypothesize translations for OOVwords.
Additionally, I plan to include techniquesthat build upon the one described in Hermjakob etal.
(2008) in order to predict when words are likelyto be transliterated rather than translated.
That workuses features based on an Arabic named entity tag-ger.
In our low resource setting, we cannot assumeaccess to such off-the-shelf tools and must adapt thisexisting technique accordingly.2.2 Bilingual Lexicon InductionBilingual lexicon induction is the task of identify-ing word translation pairs in source and target lan-guage monolingual or comparable corpora.
The taskis well-researched, however, in prior work, Irvineand Callison-Burch (2013), we were the first to pro-pose using supervised methods.
Because we assumeaccess to some small amount of parallel data, we canextract a bilingual dictionary from it to use for posi-tive supervision.
In my prior work and in the thesis,we use the following signals estimated over com-parable source and target language corpora: ortho-graphic, topic, temporal, and contextual similarity.Here, we give brief descriptions of each.Orthographic We measure orthographic similar-ity between a pair of words as the normalized1 editdistance between the two words.
For non-Romanscript languages, we transliterate words into the Ro-man script before measuring orthographic similarity.Topic We use monolingual Wikipedia pages to es-timate topical signatures for each source and targetlanguage word.
Signatures contain counts of howmany times a given word appears on each interlin-gually linked Wikipedia page, and we use cosinesimilarity to compare pairs of signatures.Temporal We use time-stamped web crawl datato estimate temporal signatures, which, for a givenword, contain counts of how many times that wordappeared in news articles with a certain date.
We ex-pect that source and target language words which aretranslations of one another will appear with similarfrequencies over time in monolingual data.1Normalized by the average of the lengths of the two words55Contextual We score monolingual contextualsimilarity by first collecting context vectors for eachsource and target language word.
The context vectorfor a given word contain counts of how many timeswords appear in its context.
We use bag of wordscontexts in a window of size two.
We gather bothsource and target language contextual vectors fromour web crawl data and Wikipedia data (separately).Frequency Words that are translations of one an-other are likely to have similar relative frequenciesin monolingual corpora.
We measure the frequencysimilarity of two words as the absolute value of thedifference between the log of their relative monolin-gual corpus frequencies.We propose using a supervised approach to learn-ing how to combine the above signals into a sin-gle discriminative binary classifier which predictswhether a source and target language word are trans-lations of one another or not.
Given a classificationscore for each source language word paired with allEnglish candidates, we rerank candidates and evalu-ate on the top-k. We give some preliminary experi-mental details and results here.We have access to bilingual dictionaries for the 22languages listed in Table 12.
For each language, wechoose up to 8, 000 source language words amongthose that occur in the monolingual data at leastthree times and that have at least one translation inour dictionary.
We randomly divide the source lan-guage words into three equally sized sets for train-ing, development, and testing.
We use the train-ing data to train a classifier, the development datato choose the best classification settings and featureset, and the test set for evaluation.For all experiments, we use a linear classifiertrained by stochastic gradient descent to minimizesquared error3 and perform 100 passes over thetraining data.4 The binary classifiers predict whethera pair of words are translations of one another or not.The translations in our training data serve as posi-tive supervision, and the source language words in2Details about the dictionaries in work under review.3We tried using logistic rather than linear regression, butperformance differences on our development set were verysmall and not statistically significant.4We use http://hunch.net/~vw/ version 6.1.4, andrun it with the following arguments that affect how updates aremade in learning: ?exact adaptive norm ?power t 0.5l0.00.20.40.60.81.0Accuracyin Top?10WikiTopic WikiContext DiffLog?Freq EditDist.
EditDist.
RR CrawlContext AllFeaturesFigure 2: Performance goes up as features are greedilyadded to the feature space.
Mean performance is slightlyhigher using this subset of six features (second to last bar)than using all features (last bar).
Each plot representsresults over our 22 languages.the training data paired with random English words5serve as negative supervision.
We used our develop-ment data to tune the number of negative examplesto three for each positive example.
At test time, af-ter scoring all source language words in the test setpaired with all English words in our candidate set,6we rank the English candidates by their classifica-tion scores and evaluate accuracy in the top-k.We use raw similarity scores based on the signalsenumerated above as features.
Additionally, for eachsource word, we rank all English candidates withrespect to each signal and include their reciprocalranks as another set of features.
Finally, we includea binary feature that indicates if a given source andtarget word are identical strings or not.We train classifiers separately for each of the 22languages listed in Table 1, and the learned weightsvary based on, for example, corpora size and the re-latedness of the source language and English (e.g.edit distance is informative if there are many cog-nates).
When we use the trained classifier to pre-dict which English words are translations of a givensource word, all English words appearing at leastfive times in our monolingual data are candidates,and we rank them by their classification scores.Figure 2, from left to right, shows a greedy search5Among those that appear at least five times in our monolin-gual data, consistent with our candidate set.6All English words appearing at least five times in ourmonolingual data.
In practice, we further limit the set to thosethat occur in the top-1000 ranked list according to at least oneof our signals.56Lang MRR Supv.
Lang MRR Supv.Nepali 11.2 13.6 Somali 16.7 18.1Uzbek 23.2 29.6 Azeri 16.1 29.4Tamil 28.4 33.3 Albanian 32.0 45.3Bengali 19.3 32.8 Welsh 36.1 56.4Bosnian 32.6 52.8 Latvian 29.6 47.7Indonesian 41.5 63.5 Romanian 53.3 71.6Serbian 29.0 33.3 Turkish 31.4 52.1Ukrainian 29.7 46.0 Hindi 18.2 34.6Bulgarian 40.2 57.9 Polish 47.4 67.1Slovak 34.6 53.5 Urdu 13.2 21.2Farsi 10.5 21.1 Spanish 74.8 85.0Table 2: Top-10 Accuracy on test set.
Performanceincreases for all languages moving from the baseline(MRR) to discriminative training (Supv).for the best subset of features.
The Wikipedia topicscore is the most informative stand-alone feature,and Wikipedia context is the most informative sec-ond feature.
Adding features to the model beyondthe six shown in the figure does not yield additionalperformance gains over our set of languages.We use a model based on the six features shown inFigure 2 to score and rank English translation candi-dates for the test set words in each language.Our unsupervised baseline method is based onranked lists derived from each of the signals listedabove.
For each source word, we generate rankedlists of English candidates using the following sixsignals: Crawls Context, Crawls Time, WikipediaContext, Wikipedia Topic, Edit distance, and LogFrequency Difference.
Then, for each English can-didate we compute its mean reciprocal rank7 (MRR)based on the six ranked lists.
The baseline ranks En-glish candidates according to the MRR scores.
Forevaluation, we use the same test sets, accuracy met-ric, and correct translations.Table 2 gives results for the baseline and our su-pervised technique.
Across languages, the averagetop-10 accuracy using the baseline is 30.4, and us-ing our technique it is 43.9, about 44% higher.In Section 3 we use the same features to score allphrase pairs in a phrase-based MT model and in-clude them as features in tuning and decoding.7The MRR of the jth English word, ej , is 1N?Ni=11rankij ,where N is the number of signals and rankij is ej?s rank ac-cording to signal i.2.3 Distributed RepresentationsOur third method for inducing OOV translations em-ploys a similar intuition to that of contextual simi-larity.
However, unlike standard contextual vectorsthat represent words as large vectors of counts ofnearby words, we propose to use distributed rep-resentations.
These word representations are low-dimensional and are induced iteratively using thedistributed representations of nearby words, not thenearby words themselves.
Using distributed repre-sentations helps to alleviate data sparsity problems.Recently, Klementiev et al(2012b) induced dis-tributed representations for the crosslingual setting.There, the induced embedding is learned jointly overmultiple languages so that the representations of se-mantically similar words end up ?close?
to one an-other irrespective of language.
They simultaneouslyuse large monolingual corpora to induce represen-tations for words in each language and use paralleldata to bring the representations together across lan-guages.
The intuition for their approach to crosslin-gual representation induction comes from the multi-task learning setup of Cavallanti et al(2010).
Theyapply this set-up to a variant of a neural probabilisticlanguage model (Bengio et al 2003).In my thesis, I propose to use the distributed rep-resentations proposed by Klementiev et al(2012b)in order to induce translations for OOV words.
Ad-ditionally, I plan to learn how to compose the rep-resentations of individual words in a phrase into asingle representation, allowing for the induction ofphrase translations in addition to single words.3 Inducing and Scoring a Phrase TableAlthough by extracting OOV word translations wemay increase the coverage of our SMT model,inducing phrase translations may increase perfor-mance further.
In order to do so, we need to be ableto score pairs of phrases to determine which havehigh translation probabilities.
Furthermore, using al-ternate sources of data to score phrase pairs directlyextracted from a small bitext may help distinguishgood translation pairs from bad ones, which couldresult from incorrect word alignments, for example.In moving from words to phrases, we make use ofmany of the same techniques described in Section 2.Here, I present several proposals for addressing the57major additional challenges that arise for phrases,and Section 4 presents some experimental results.3.1 Phrase translation inductionThe difficulty in inducing a comprehensive set ofphrase translations is that the number of phrases, onboth the source and target side, is very large.
Inmoving from the induction of word translations tophrase translations, the number of comparisons nec-essary to do an exhaustive search becomes infeasi-ble.
I propose to explore several ways to speed upthat search in my thesis:?
Use distributed phrase representations.?
Use filters to limit the phrase pair search space.Filters should be fast and could include in-formation such as word translations, phraselengths, and monolingual frequencies.?
Predict when phrases should be translated as aunit, rather than compositionally.
If it is pos-sible to accurately translate a phrase composi-tionally from its word translations, then there isno need to induce a translation for the phrase.3.2 Phrase translation scoringIn our prior work, Klementiev et al(2012a), wehave started to explore scoring a phrase table us-ing comparable corpora.
Given a set of phrase pairs,either induced or extracted from a small bitext, theidea is to score them using the same signals derivedfrom comparable corpora described in the context ofbilingual lexicon induction in Section 2.2.
No matterthe source of the phrase pairs, the hope is that suchscores will help an SMT model distinguish betweengood and bad translations.
We estimate both phrasaland lexical similarity features over phrase pairs.
Weestimate the first using contextual, temporal, andtopical signatures over entire phrases.
We estimatethe latter by using the lexical contextual, temporal,topical, and orthographic signatures of each wordin each phrase.
We use phrasal word alignmentsin order to compute the lexical similarity betweenphrases.
That is, we compute each similarity met-ric for each pair of aligned words and then, for eachsimilarity metric, average over the word pairs.
Thisapproach is analogous to the lexical weighting fea-ture introduced by Koehn et al(2003).Language Train Dev OOV Dev OOVWords Word Types Word TokensTamil 452k 44% 25%Bengali 272k 37% 18%Hindi 708k 34% 11%Table 3: Information about datasets released by Post etal.
(2012).
Training data gives the number of words in thesource language training set.
OOV rates give the percentof development set word types and work tokens that donot appear in the training data.4 Preliminary ResultsHere we show preliminary results using our methodsfor translating OOV words and our methods for scor-ing a phrase table in end-to-end low resource ma-chine translation.
Post et al(2012) used Amazon?sMechanical Turk to collect a small parallel corpusfor several Indian languages.
In our experiments, weuse their Tamil, Bengali, and Hindi datasets.
We usethe data splits given by Post et al(2012) and, fol-lowing that work, report results on the devtest set.Table 3 shows statistics about the datasets.In our experiments, we use the Moses phrase-based machine translation framework (Koehn et al2007).
For each language, we extract a phrase ta-ble from the training data with a phrase limit ofseven and, like Post et al(2012), use the Englishside of the training data to train a language model.Throughout our experiments, we use MIRA (Chianget al 2009) for tuning the feature set.Our experiments compare the following:?
A baseline phrase-based model, using phrasepairs extracted from the training data and thestandard phrasal and lexical translation proba-bilities based on the bitext.?
Baseline supplemented with word translationsinduced by our baseline unsupervised bilinguallexicon induction method (Section 2.2)?
Baseline supplemented with word translationsinduced by our supervised bilingual lexicon in-duction methods (Section 2.2).?
Baseline model supplemented with additionalfeatures, estimated over comparable corpora(Section 3.2).?
Baseline model supplemented with inducedword translations and also additional features.Table 4 shows our results.
Adding additionalphrase table features increased BLEU scores from58Tamil Bengali HindiExperiment K BLEU Diff.
BLEU Diff.
BLEU Diff.Baseline 9.16 12.14 14.85+ Mono.
Features 9.70 +0.54 12.54 +0.40 15.16 +0.31+ Unsupervised Word Translations 1 9.33 +0.17 12.11 -0.03 15.37 +0.52+ Supervised Word Translations 1 9.76 +0.60 12.38 +0.24 15.64 +0.79+ Mono.
Feats.
& Sup.
Trans.
1 10.20 +1.04 13.01 +0.87 15.84 +0.99+ Mono.
Feats.
& Sup.
Trans.
5 10.41 +1.25 12.64 +0.50 16.02 +1.17+ Mono.
Feats.
& Sup.
Trans.
10 10.12 +0.96 12.57 +0.43 15.86 +1.01Table 4: BLEU performance gains that target coverage and accuracy separately and together.
We add the top-Kranked translations for each OOV source word.0.31 BLEU points for Hindi to 0.54 for Tamil.Next, we monolingually induced translations forall development and test set source words.
Weexperimented with adding translations for sourcewords with low training data frequencies in additionto OOV words but did not observe BLEU improve-ments beyond what was gained by translating OOVsalone.
Our BLEU score gains that result from im-proving OOV coverage, +Supervised Word Transla-tions, range from 0.24 for Bengali to 0.79 for Hindiand outperform the unsupervised lexicon inductionbaseline for all three languages.Using comparable corpora to supplement both thefeature space and the coverage of OOVs results intranslations that are better than applying either tech-nique alone.
For all languages, the BLEU improve-ments are approximately additive.
For Tamil, the to-tal BLEU point gain is 1.25, and it is 1.17 for Hindiand 0.87 for Bengali.
Table 4 shows results as weadd the top-k ranked translation for each OOV wordand vary k. For Tamil and Hindi, we get a slightboost by adding the top-5 translations instead of thesingle best but get no further gains with the top-10.5 Previous WorkPrior work on bilingual lexicon induction has shownthat a variety of signals derived from monolingualdata, including distributional, temporal, topic, andstring similarity, are informative (Rapp, 1995; Fungand Yee, 1998; Koehn and Knight, 2002; Schaferand Yarowsky, 2002; Monz and Dorr, 2005; Huanget al 2005; Schafer, 2006; Klementiev and Roth,2006; Haghighi et al 2008; Mimno et al 2009;Mausam et al 2010; Daum?
and Jagarlamudi,2011).
This thesis builds upon this work and usesa diverse set of signals for translating full sentences,not just words.
Recently, Ravi and Knight (2011),Dou and Knight (2012), and Nuhn et al(2012) haveworked toward learning a phrase-based translationmodel from monolingual corpora, relying on deci-pherment techniques.
In contrast to that researchthread, we make the realistic assumption that a smallparallel corpus is available for our low resource lan-guages.
With a small parallel corpus, we are able totake advantage of supervised techniques, changingthe problem setting dramatically.Since the early 2000s, the AVENUE (Carbonellet al 2002; Probst et al 2002; Lavie et al 2003)project has researched ways to rapidly develop MTsystems for low-resource languages.
In contrastto that work, my thesis will focus on a language-independent approach as well as integrating tech-niques into current state-of-the-art SMT frame-works.
In her thesis, Gangadharaiah (2011) tack-les several data sparsity issues within the example-based machine translation (EBMT) framework.
Herwork attempts to tackle some of the same data spar-sity issues that we do including, in particular, phrasetable coverage.
However, our models for doing soare quite different and focus much more on the useof a variety of new non-parallel data resources.Other approaches to low resource machine trans-lation include extracting parallel sentences fromcomparable corpora (e.g.
Smith et al(2010)) andtranslation crowdsourcing.
Our efforts are orthogo-nal and complementary to these.6 ConclusionMy thesis will explore using alternative datasources, other than parallel text, to inform statisti-cal machine translation models.
In particular, I willbuild upon a long thread of research on bilingual lex-icon induction from comparable corpora.
The resultof my thesis will be broadening the applicability ofcurrent SMT frameworks to language pairs and do-mains for which parallel data is limited.597 AcknowledgementsThe research presented in this paper was done in col-laboration with my advisor, Chris Callison-Burch.This material is based on research sponsored byDARPA under contract HR0011-09-1-0044 and bythe Johns Hopkins University Human LanguageTechnology Center of Excellence.
The views andconclusions contained in this publication are thoseof the authors and should not be interpreted as repre-senting official policies or endorsements of DARPAor the U.S. Government.ReferencesVamshi Ambati.
2011.
Active Learning for MachineTranslation in Scarce Data Scenarios.
Ph.D. thesis,Carnegie Mellon University.Yoshua Bengio, R?jean Ducharme, Pascal Vincent, andChristian Janvin.
2003.
A neural probabilistic lan-guage model.
Journal of Machine Learning Research(JMLR), 3:1137?1155.Jaime G. Carbonell, Katharina Probst, Erik Peterson,Christian Monson, Alon Lavie, Ralf D. Brown, andLori S. Levin.
2002.
Automatic rule learning forresource-limited mt.
In Proceedings of the Confer-ence of the Association for Machine Translation in theAmericas (AMTA).Giovanni Cavallanti, Nicol?
Cesa-bianchi, and ClaudioGentile.
2010.
Linear algorithms for online multitaskclassification.
Journal of Machine Learning Research(JMLR), 11:2901?2934.David Chiang, Kevin Knight, and Wei Wang.
2009.11,001 new features for statistical machine translation.In Proceedings of the Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics (NAACL).Hal Daum?, III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by mining un-seen words.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InProceedings of the Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compara-ble texts.
In Proceedings of the Conference of the As-sociation for Computational Linguistics (ACL).Rashmi Gangadharaiah.
2011.
Coping with Data-sparsity in Example-based Machine Translation.Ph.D.
thesis, Carnegie Mellon University.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of the Con-ference of the Association for Computational Linguis-tics (ACL).Ulf Hermjakob, Kevin Knight, and Hal DaumO?
Iii.2008.
Name translation in statistical machine transla-tion learning when to transliterate.
In Proceedings ofthe Conference of the Association for ComputationalLinguistics (ACL).Fei Huang, Ying Zhang, and Stephan Vogel.
2005.
Min-ing key phrase translations from web corpora.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing (EMNLP).Ann Irvine and Chris Callison-Burch.
2013.
Supervisedbilingual lexicon induction with multiple monolingualsignals.
In Proceedings of the Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (NAACL).Ann Irvine, Chris Callison-Burch, and Alexandre Kle-mentiev.
2010a.
Transliterating from all languages.In Proceedings of the Conference of the Associationfor Machine Translation in the Americas (AMTA).Ann Irvine, Mike Kayser, Zhifei Li, Wren Thornton, andChris Callison-Burch.
2010b.
Integrating output fromspecialized modules in machine translation: translit-erations in joshua.
Prague Bulletin of MathematicalLinguistics, pages 107?116.Alexandre Klementiev and Dan Roth.
2006.
Weaklysupervised named entity transliteration and discoveryfrom multilingual comparable corpora.
In Proceed-ings of the Conference of the Association for Compu-tational Linguistics (ACL).Alex Klementiev, Ann Irvine, Chris Callison-Burch, andDavid Yarowsky.
2012a.
Toward statistical machinetranslation without parallel corpora.
In Proceedings ofthe Conference of the European Association for Com-putational Linguistics (EACL).Alexandre Klementiev, Ivan Titov, and Binod Bhattarai.2012b.
Inducing crosslingual distributed representa-tions of words.
In Proceedings of the InternationalConference on Computational Linguistics (COLING).Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In ACLWorkshop on Unsupervised Lexical Acquisition.Philipp Koehn, Franz Joseph Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of the Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, Richard60Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the Conference of the Association for Compu-tational Linguistics (ACL).Prasanth Kolachina, Nicola Cancedda, Marc Dymetman,and Sriram Venkatapathy.
2012.
Prediction of learn-ing curves in machine translation.
In Proceedings ofthe Conference of the Association for ComputationalLinguistics (ACL).Alon Lavie, Stephan Vogel, Lori Levin, Erik Peterson,Katharina Probst, Ariadna Font, Rachel Reynolds,Jaime Carbonelle, and Richard Cohen.
2003.
Experi-ments with a Hindi-to-English transfer-based MT sys-tem under a miserly data scenario.
ACM Transactionson Asian Language Information Processing (TALIP),2.Mausam, Stephen Soderland, Oren Etzioni, Daniel S.Weld, Kobi Reiter, Michael Skinner, Marcus Sammer,and Jeff Bilmes.
2010.
Panlingual lexical transla-tion via probabilistic inference.
Artificial Intelligence,174:619?637, June.David Mimno, Hanna Wallach, Jason Naradowsky, DavidSmith, and Andrew McCallum.
2009.
Polylingualtopic models.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).Christof Monz and Bonnie J. Dorr.
2005.
Iterative trans-lation disambiguation for cross-language informationretrieval.
In Proceedings of the Conference on Re-search and Developments in Information Retrieval (SI-GIR).Malte Nuhn, Arne Mauser, and Hermann Ney.
2012.Deciphering foreign language by combining languagemodels and context vectors.
In Proceedings of theConference of the Association for Computational Lin-guistics (ACL).Matt Post, Chris Callison-Burch, and Miles Osborne.2012.
Constructing parallel corpora for six indianlanguages via crowdsourcing.
In Proceedings of theWorkshop on Statistical Machine Translation (WMT).Katharina Probst, Lori Levin, Erik Peterson, Alon Lavie,and Jaime Carbonell.
2002.
MT for minority lan-guages using elicitation-based learning of syntactictransfer rules.
Machine Translation, 17:245?270, De-cember.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the Conference ofthe Association for Computational Linguistics (ACL).Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated English and German cor-pora.
In Proceedings of the Conference of the Associ-ation for Computational Linguistics (ACL).Sujith Ravi and Kevin Knight.
2011.
Deciphering for-eign language.
In Proceedings of the Conference ofthe Association for Computational Linguistics (ACL).Charles Schafer and David Yarowsky.
2002.
Induc-ing translation lexicons via diverse similarity measuresand bridge languages.
In Proceedings of the Confer-ence on Natural Language Learning (CoNLL).Charles Schafer.
2006.
Translation Discovery Using Di-verse Similarity Measures.
Ph.D. thesis, Johns Hop-kins University.Jason R. Smith, Chris Quirk, and Kristina Toutanova.2010.
Extracting parallel sentences from comparablecorpora using document level alignment.
In Proceed-ings of the Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL).Omar F. Zaidan and Chris Callison-Burch.
2011.
Crowd-sourcing translation: Professional quality from non-professionals.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).61
