Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 204?205,Vancouver, October 2005. c?2005 Association for Computational LinguisticsRobust Extraction of Subcategorization Data from Spoken LanguageJianguo Li & Chris Brew Eric Fosler-LussierDepartment of Linguistics Department of Computer Science & EngineeringThe Ohio State University, USA The Ohio State University, USA{jianguo|cbrew}@ling.ohio-state.edu fosler@cse.ohio-state.edu1 IntroductionSubcategorization data has been crucial for variousNLP tasks.
Current method for automatic SCF ac-quisition usually proceeds in two steps: first, gen-erate all SCF cues from a corpus using a parser,and then filter out spurious SCF cues with statisti-cal tests.
Previous studies on SCF acquisition haveworked mainly with written texts; spoken corporahave received little attention.
Transcripts of spokenlanguage pose two challenges absent in writtentexts: uncertainty about utterance segmentation anddisfluency.Roland & Jurafsky (1998) suggest that there aresubstantial subcategorization differences betweenspoken and written corpora.
For example, spokencorpora tend to have fewer passive sentences butmany more zero-anaphora structures than writtencorpora.
In light of such subcategorization differ-ences, we believe that an SCF set built from spo-ken language may, if of acceptable quality, be ofparticular value to NLP tasks involving syntacticanalysis of spoken language.2 SCF Acquisition SystemFollowing the design proposed by Briscoe andCarroll (1997), we built an SCF acquisition systemconsisting of the following four components:Charniak?s parser (Charniak, 2000); an SCF ex-tractor; a lemmatizer; and an SCF evaluator.
Thefirst three components are responsible for generat-ing SCF cues from the training corpora and the lastcomponent, consisting of the Binomial HypothesisTest (Brent, 1993) and a back-off algorithm(Sarkar & Zeman, 2000), is used to filter SCF cueson the basis of their reliability and likelihood.We evaluated our system on a million wordwritten corpus and a comparable spoken corpusfrom BNC.
For type precision and recall, we used14 verbs selected by Briscoe & Carroll (1997) andevaluated our results against SCF entries inCOMLEX (Grishman et al, 1994).
We also calcu-lated token recall and the results are summarized inthe following table.Corpus Written Spokentype precision 93.1% 91.2%type recall 48.2% 46.4%token recall 82.3% 80%Table 1: Type precision, recall and token recall3 Detecting Incorrect SCF CuesWe examined the way segmentation errors anddisfluency affects our acquisition system ?
the sta-tistical parser and the extractor in particular ?
inproposing SCF cues and explored ways to detectincorrect SCF cues.
We extracted 500 SCF cuesfrom the ViC corpus (Pitt, et al 2005) and identi-fied four major reasons that seem to have causedthe extractor to propose incorrect SCF cues: multi-ple utterances; missing punctuation; disfluency;parsing errors.Error analysis reveals that segmentation errorsand disfluencies cause the parser and the extractorto tend to make systematic errors in proposing SCFcues ?
incorrect SCF cues are likely to have anextra complement.
We therefore proposed the fol-lowing two sets of linguistic heuristics for auto-matically detecting incorrect SCF cues:Linguistic Heuristic Set 1: The following SCFcues are extremely unlikely whatever the verb.
Re-ject an SCF cue as incorrect if it contains the fol-lowing patterns:?
[(NP) PP NP]: We reach out [to your friends] [yourneighbor].?
[NP PP-to S]: Would I want them to say [that][tome] [would I want them to do that to me].?
[NP NP S]: They just beat [Indiana in basketball][the- Saturday] [I think it was um-hum].204?
[PP-p PP-p]: He starts living [with the] [with theguys].Linguistic Heuristic Set 2: The following SCFcues are all possibly valid SCFs: for SCF cues ofthe following type, check if the given verb takes itin COMLEX.
If not, reject it:?
[(NP) S]: When he was dying [what did he say].?
[PP-to S]: The same thing happened [to him] [uhhe had a scholarship].?
[(NP) NP]: OU had a heck of time beating [them][uh-hum].?
[(NP) INF]: You take [the plate] from the table[rinse them off] and put them by the sink.Given the utilization of a gold standard in theheuristics, it would be improper to build an end-to-end system and evaluate against COMLEX.
In-stead, we evaluate by seeing how often our heuris-tics succeed producing results agreeable to ahuman judge.To evaluate the robustness of our linguistic heu-ristics, we conducted a cross-corpora and cross-parser comparison.
We used 1,169 verb tokensfrom the ViC corpus and another 1,169 from theSwitchboard corpus.Cross-corpus Comparison: The purpose of thecross-corpus comparison is to show that our lin-guistic heuristics based on the data from one spo-ken corpus can be applied to other spoken corpora.Therefore, we applied our heuristics to the ViC andthe Switchboard corpus parsed by Charniak?sparser.
We calculated the percentage of incorrectSCF cues before and after applying our linguisticheuristics.
The results are shown in Table 2.Charniak?s parser ViC Switchboardbefore heuristics 18.8% 9.5%after heuristics 6.4% 4.6%Table 2: Incorrect SCF cue rate before and after heuristicsTable 2 shows that the incorrect SCF cue ratehas been reduced to roughly the same level for thetwo spoken corpora after applying our linguisticheuristics.Cross-parser Comparison: The purpose of thecross-parser comparison is to show that our lin-guistic heuristics based on the data parsed by oneparser can be applied to other parsers as well.
Tothis end, we applied our heuristics to theSwitchboard corpus parsed by both Charniak?sparser and Bikel?s parsing engine (Bikel, 2004).Again, we calculated the percentage of incorrectSCF cues before and after applying our heuristics.The results are displayed in Table 3.Although our linguistic heuristics works slightlybetter for data parsed by Charniak?
parser, the in-correct SCF cue rate after applying heuristics re-mains at about the same level for the two differentparsers we used.Switchboard Charniak Bikelbefore heuristics 9.5% 9.2%after heuristics 4.6% 5.4%Table 3: Incorrect SCF cue rate before and after heuristics4 ConclusionWe showed that it should not be assumed that stan-dard statistical parsers will fail on language that isvery different from what they are trained on.
Spe-cifically, the results of Experiment 1 showed that itis feasible to apply current SCF extractiontechnology to spoken language.
Experiment 2showed that incorrect SCF cues due to segmenta-tion errors and disfluency can be recognized by ourlinguistic heuristics.
We have shown that our SCFacquisition system as a whole will work for thedifferent demands of spoken language.5 AcknowledgementsThis work was supported by NSF grant 0347799 tothe second author, and by a summer fellowshipfrom the Ohio State Center for Cognitive Scienceto the first author.ReferencesBiekl, D. 2004.
Intricacies of Collins?
Parsing Model.
ComputationalLinguistics, 30(4): 470-511Brent, M. 1993.
From Grammar to Lexicon: Unsupervised Learningof Lexical Syntax.
Computational Lingusitics: 19(3): 243-262Briscoe, E. & Carroll, G. 1997.
Automatic Extraction of Subcategori-zation from Corpora.
In Proceedings of the 5th ACL Conference onApplied Natural Language Processing, Washington, DC.
356-363Chaniak, E. 2000.
A Maximum-Entropy-Inspired Parser.
In Proceed-ings of the 2000 Conference of the North American Chapter ofACL.
132-139Grishman, R., Macleod, C. & Meyers, A.
1994.
COMLEX Syntax:Building a Computational Lexicon.
In Proceedings of the Interna-tional Conference on Computational Lingusitics, COLING-94,Kyoto, Japan.
268-272Pitt, M., Johnson, K., Hume, E., Kiesling, S., Raymond, W. 2005.They Buckeye Corpus of Conversational Speech: Labeling Con-ventions and a Test of Transcriber Reliability.
Speech Communica-tion, 45: 89-95Roland, D. & Jurafsky, D. 1998.
How Verb Subcategorization Fre-quency Affected by the Corpus Choice.
In Proceedings of 17th In-ternational Conference on Computational Lingusitics, 2: 1122-1128Sarkar, A.
& Zeman, D. 2000.
Automatic Extraction of Subcategoriza-tion Frames for Czech.
In Proceedings of the 19th InternationalConference on Computational Lingusitics.
691-697205
