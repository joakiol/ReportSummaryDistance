LAW VIII - The 8th Linguistic Annotation Workshop, pages 38?47,Dublin, Ireland, August 23-24 2014.Sentence diagrams: their evaluation and combinationJirka Hana and Barbora Hladk?a and Ivana Luk?sov?aCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsPrague, Czech Republic{hana,hladka,luksova} (at) ufal.mff.cuni.czAbstractThe purpose of our work is to explore the possibility of using sentence diagrams produced byschoolchildren as training data for automatic syntactic analysis.
We have implemented a sentencediagram editor that schoolchildren can use to practice morphology and syntax.
We collect theirdiagrams, combine them into a single diagram for each sentence and transform them into a formsuitable for training a particular syntactic parser.
In this study, the object language is Czech,where sentence diagrams are part of elementary school curriculum, and the target format is theannotation scheme of the Prague Dependency Treebank.
We mainly focus on the evaluation ofindividual diagrams and on their combination into a merged better version.1 IntroductionSyntactic parsing has been an attractive topic for both theoretical and computational linguists for manyyears.
In combination with supervised machine learning techniques, several corpus-based parsers havebeen implemented (e.g., (Nivre et al., 2007), (de Marneffe et al., 2006), (McDonald et al., 2005)), com-bined (e.g., (Surdeanu and Manning, 2010)), and adapted (e.g., (McClosky et al., 2010),(Zhang andWang, 2009)).
The performance of such techniques directly correlates with the size of training data: themore annotated data, the better.
However, the annotation process is very resource consuming, thus wehave been seeking for alternative ways of faster and cheaper annotation.
Namely, we have been inspiredby the solution of crowdsourcing, see e.g.
(Brabham, 2013).In Czech schools, practicing morphology and syntax is an obligatory part of the curriculum.Schoolchildren draw sentence diagrams similar to syntactic trees in dependency grammar theories (Hud-son, 1984; Sgall et al., 1986; Mel?
?cuk, 1988), with labeled nodes and edges.
Our goal is to collect suchdiagrams and transform them into the annotation scheme of the Prague Dependency Treebank (Haji?cet al., 2006).
Thereby we enlarge training data for taggers and parsers of Czech.
Traditionally, dia-grams that we need are only in students?
notebooks so they are not accessible to us at all.
Since werequire diagrams electronically, we have been developing a sentence diagram editor?Capek.
We havedesigned it both as a CALL (Computer-Assisted Language Learning) system for practicing morphologyand dependency-based syntax and as a crowdsourcing system for getting annotated data.
In addition, theeditor can be used for drawing sentence diagrams in any natural language.
On the other hand, transfor-mation rules have to be specified with respect to a particular target annotation scheme.
We introducedthis approach in (Hana and Hladk?a, 2012).Data quality belongs to the most important issues related to crowdsourcing, see e.g.
(Sabou et al.,2012), (Wang et al., 2010), (Hsueh et al., 2009).
We discuss the data quality from two aspects: (i)evaluation of students?
diagrams against teachers?
and/or other students?
diagrams, i.e.
we consider howdiagrams are similar; (ii) combination of students?
diagrams of one sentence to get a better diagram, i.e.we deal with multiple, possibly noisy, annotations and we study if they are useful.Our paper is organized as follows: in Section 2, we describe Czech sentence diagrams and how theydiffer from the PDT annotation scheme.
We introduce the?Capek editor in Section 3.
Section 4 introducesThis work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedingsfooter are added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/38a tree edit distance metric we use to quantify the difference between diagrams.
Section 5 discusses analgorithm combining alternative diagrams into a single structure.
Finally, some initial evaluation andother statistics are presented in Section 6.2 Czech sentence diagramsIn the Czech sentence diagrams (hence SDs), a sentence is represented as a type of dependency structure.1The structure is a directed acyclic graph (roughly a tree) with labeled nodes.
The nodes correspond towords: one (most common), multiple (auxiliary words are considered markings on their heads, e.g.preposition and noun, or a complex verb form share a single node) or none (in case of dropped subjects).The edges capture the dependency relation between nodes (e.g., between an object and its predicate).The node label expresses the type of dependency, or syntactic function.Formally, a sentence diagram over a sentence s = w1w2.
.
.
wnis a directed acyclic graph D =(Nodes,Edges), where Nodes is a partition of s. Moreover, the Nodes set might contain a dummynode corresponding to a dropped subject.
The first node N1of an edge E = (N1, N2) is a child node ofthe second node N2.For illustration, let?s consider the sentence in (1) and its diagram in Figure 1:(1) (?
)IR?anoin the morningp?ujduwill gosewithsv?ymmykamar?ademfriendna houby.mushrooming.
?I will go mushrooming with my friend in the morning.
?Since our goal is to get more data annotated according to the PDT schema (the so-called a-layer orsurface syntax), we characterize certain aspects of SD with respect to the PDT conventions depicted inFigure 2:?
Tokenization.
There is a 1:1 correspondence between tokens and nodes in PDT; all punctuationmarks have their corresponding nodes.
Cf.
8 tokens and 8 nodes in Example 1 and Figure 2.
InSDs, there is an N:1 correspondence between tokens and nodes (N can be 0 for dropped subjects);punctuation is mostly ignored.
Cf.
8 tokens and 6 nodes in Example 1 and Figure 1.?
Multi-token nodes.
SDs operate on both single-token (p?ujdu ?will go?)
and multi-token nodes (sekamar?adem ?with friend?, na houby ?for mushrooms?).
The tokens inside each multi-token node areordered in accordance with their surface word order.
Auxiliary words, auxiliary verbs, prepositions,modals etc.
do not have their own nodes and are always part of a multi-token node.
PDT handlessingle-token nodes only.?
Subject and predicate.
In PDT, predicate is the root and the subject depends on it; in Figure 1,they are on the same level; cf.
the nodes for (j?a) p?ujdu ?I will go?.?
PRO subject.
SDs introduce nodes for elided subjects (see the --- node in Figure 1), which arecommon in Czech.
PDT does not represent them explicitly.?
Morphological tags.
We adopt the system of positional tags used in PDT to capture morphologicalproperties of words.
Tags are assigned to each token in the sentence, not to the nodes.?
Syntactical tags (functors).
Our SDs use 14 syntactical tags (Subject, Predicate, Attribute, Adver-bial of time/place/manner/degree/means/cause/reason/condition/opposition, Verbal Complement).PDT distinguishes significantly higher number of functors, but most of the additional tags are usedin rather specific situations that are captured by different means in school syntax (parenthesis, ellip-sis), are quite technical (punctuation types), etc.
In the vast majority of cases, it is trivial to map SDfunctors to PDT functors.1For expository reasons, in this paper, we ignore complex sentences consisting of multiple clauses.
Their SD is a discon-nected graph where each component is an SD of a single clause.
Such sentences and graphs are however part of the evaluationin Section 6.39Figure 1: A sample of sentence diagramFigure 2: A sample of PDT treeFigure 3: A possible sentence diagram draw in?Capek3?Capek editorSince we wanted to provide students with a sentence diagram editor that is easy to use, we have de-cided not to use the TrEd editor,2a versatile, flexible but also complex tool, which is used as the mainannotation tool of the Prague Dependency Treebanks.
Instead, we decided to implement?Capek, a newsystem.
It exists as a desktop application, written in Java on top of the Netbeans Platform,3and as a webapplication.4Students use the editor in a similar way as they are used to use chalk/pen at school.
A simple andintuitive GUI supports the following operations:?
JOIN Merge two nodes into a single multi-token node.?
SPL Divide a multi-token into nodes corresponding to single tokens.?
INS Create a node for elided subject.?
LINK Link a node to its governing parent node.?
LAB Label a node with syntactic function.?
MLAB Label a token with morphological function.Intentionally, we did not make?Capek to perform any consistency checks, except acyclicity of the graph.Thus students can create a graph with several components, all nodes can be a subject, etc.4 Similarity of sentence diagramsWe compute the similarity between sentence diagrams using a tree edit distance.
Our definition is basedon a tree edit distance in (Bille, 2005).
It assumes two trees T1, T2and three edit operations: relabelinga node, deleting a non-root node, and inserting a node.
T1is transformed into T2by a sequence of edit2http://ufal.mff.cuni.cz/tred3http://platform.netbeans.org4http://capek.herokuapp.com/40operations S. Each operation has a particular cost, the cost of the sequence S is simply the sum of thecost of individual operations.
Then tree edit distance between two trees is the cost of a cheapest sequenceof operations turning one tree into another.Our situation is similar, however:?
the compared sentence diagrams are always over the same sentence, i.e.
over the same set of tokens?
diagrams are not trees: they are acyclic graphs but unlike trees they might consist of several compo-nents (either because they capture complex sentences, or because the students did not finish them).In addition, a diagram usually has two ?roots?
: one for the subject and one for predicate.
However,it is trivial to transform them into the corresponding tree, considering the subject to be the daughterof the predicate.Thus, we modify the distance from (Bille, 2005).
For an example, see Figure 4 with nodes of twoparticular diagrams over a 6-token sentence.
The arrows show a token-node mapping specified by theannotator of D1:?
Let D1and D2be sentence diagrams; we are turning D2into D1.?
We consider the following operations:?
SPL ?
detaching a token from a node?
JOIN ?
adding a token to a node?
INS ?
adding an empty node (used for elided subjects)?
LINK ?
linking a node with its parent and removing all inconsistent edges.
If manipulating anon-root node, relink the node to its new parent and remove the edge to its former parent.
Ifmanipulating a root node, like a in Figure 5 a), link the node to its new parent, e.g.
to e, seeFigure 5 b).
Then the diagram consists of a single cycle.
Thus remove the edge from e to itsformer parent c and e becomes a root, see Figure 5 c).?
SLAB ?
change node syntactic labelAll operations are assumed to have the cost of 1.
Without loss of generality, we can assume thatoperations are performed in stages: first all SPLs, then all JOINs, etc.
In Figure 4, first we applySPL twice on the nodes [b, c], [d, e, f ] and then JOIN also twice on the nodes [a], [b] and [e], [f ].?
Finally, the measure is normalized by sentence length.
Thus, we redefine the tree edit distanceTED(D1, D2, n) for diagrams D1, D2and sentence of n tokens as follows:TED(D1, D2, n) = (#SPL+ #JOIN + #INS + #LINK + #SLAB)/n.?
We define the tree edit distance for annotators A1, A2and a set of sentences S (si?
S) as theaverage tree distance over those sentences:TED(A1, A2, S) =1|S||S|?i=1TED(DiA1, DiA2, |si|).41Figure 4: Turning nodes of D2into nodes of D1Figure 5: Linking a root node5 Combination of sentence diagramsWe deal with sentence diagrams and their differences before transformation into a target annotationscheme.
We propose a majority-voting method to combine m multiple diagrams D1, .
.
.
, Dmcreatedby m different users over the sentence s = w1w2.
.
.
wn.
In some sense, our task is similar to thetask of combination independently-trained syntactic parsers.
However, at least to our knowledge, theexperiments performed so far, e.g.
(Surdeanu and Manning, 2010), are based on the assumption that allinput parsers build syntactic structures on the same set of nodes.
Given that, we address a significantlydifferent task.
We approach it using the concept of assigning each candidate node and edge a scorebased on the number of votes it received from the input diagrams.
The votes for edges are weighted by aspecific criterion.To build a final diagram, we first create its set of nodes FinalNodes, then its set of edges FinalEdgeslinking nodes in FinalNodes, and finally extend the set of nodes by any empty nodes.
The method canproduce both nodes and edges that do not occur in any of the input diagrams.Building FinalNodes1.
?t, u ?
s .
v(t, u) =?mk=1?
([t, u], Dk), where ?
([t, u], D) = 1 if the tokens t and u are in thesame node in the diagram D, and 0 otherwise.
We compute the number of votes v(t, u) to measureuser preferences for having token pair t, u in one node.
In total, there are(|s|2)token pairs.2.
The set FinalNodes is formed as a partition over tokens induced by the v(t, u) equivalence rela-tion:FinalNodes = s/eq where eq(t, u)?
v(t, u) > m/2For illustration, we start with the sentence a b c d and three diagrams with nodes displayed in Figure 6.All of them consist of two nodes, namelyNodes1= {[a, b, c], [d]},Nodes2= {[a], [b, c, d]},Nodes3={[a, b], [c, d]}.
First, we calculate the votes for each possible token pairs, see Table 1.
There are twocandidates with a majority of votes, namely (a, b) and (b, c), both with two votes.
Thus, FinalNodes ={[a, b, c], [d]}.
A final diagram consists of n nodes [w1], .
.
.
, [wn] if there is no candidate with majorityof votes, see Figure 7 and Table 2.42Figure 6: Sentence a b c d and nodes in three diagramsa b c da x 2 1 0b x x 2 1c x x x 1d x x x xTable 1: Two candidates for joiningFigure 7: Sentence a b c d and nodes in three other diagramsa b c da x 1 0 1b x x 1 0c x x x 1d x x x xTable 2: No candidates with the great majority of votesBuilding FinalEdges1.
fn = |FinalNodes|2.
?Dk=1,...,m, ?E = (N1, N2) ?
Edgesk, ?
(t, u) ?
tokens(N1) ?
tokens(N2) : vk(t, u) =1/(|tokens(N1)||tokens(N2)|).
We compute vk(t, u) to measure user preference for having tokent in a node dependent on a node containing u.
We take it proportionally to the number of tokens intwo particular nodes.3.
We initialize a set of potential edges as a set of all possible edges over the final nodes.
I.e.PotentialEdges is formed as a variation of fn nodes choose 2.
Let p = |PotentialEdges| =fn(fn?
1).
Then weights are assigned to the potential edges:?E = (N1, N2) ?
PotentialEdges : vE=?mk=1vk(t, u), (t, u) ?
tokens(N1)?
tokens(N2)4.
Sort PotentialEdges so that vE1?
vE2?
?
?
?
?
vEp5.
FinalEdges := ?6.
until PotentialEdges = ??
FinalEdges := FinalEdges ?
E1?
PotentialEdges := PotentialEdges \ E1?
PotentialEdges := PotentialEdges \ ?E1?
PotentialEdges := PotentialEdges \ {E : E ?
FinalEdges has a cycle}For illustration, we assume three diagrams D1, D2, D3displayed in Figure 8.
We compute weightsof token pairs proportionally to the number of tokens in nodes identifying a given edge, e.g.
the edge([a, b], [c]) in D1determines two token pairs (a, c) and (b, c), each of them with the weight 1/2.
SeeTable 3 for other weights.
Let FinalNodes = {[a, b], [c], [d]}.
There are six possible edges connectingthe final nodes, namely ([a, b], [c]),([c], [a, b]),([a, b], [d]),([d], [a, b]),([c], [d]),([d], [c]).
For each of them,we compute its weight, see Table 4.
Then we sort them ?
([a, b], [c]), ([c], [d]), ([a, b], [d]), ([c], [a, b]),([d], [a, b]), ([d], [c]).
Table 5 traces the algorithm for adding edges into a final diagram.
Finally, we getthe diagram D in Figure 8.43([a, b], [c]) ([c], [a, b]) ([a, b], [d]) ([d], [a, b]) ([c], [d]) ([d], [c])weight 13/6 0 1/2 0 1 0Table 4: Computing weights of edges-candidates to be added into a final diagram1stFinalEdgesPotentialEdges ([a, b], [c]) ([c], [d]) ([a, b], [d]) ([c], [a, b]) ([d], [a, b]) ([d], [c])2ndFinalEdges ([a, b], [c])PotentialEdges ([c], [d]) ([a, b], [d])([c], [a, b]) ([d], [a, b]) ([d], [c])3rdFinalEdges ([a, b], [c]) ([c], [d])PotentialEdges([a, b], [d])([d], [a, b])([d], [c])Table 5: Adding edges into a final diagramFigure 8: Input diagrams D1, D2, D3and final diagram DD1D2D3token weight token weight token weightpair pair pair(a, c) 1/2 (a, c) 1/4 (a, c) 1/3(b, c) 1/2 (a, d) 1/4 (b, c) 1/3(c, d) 1 (b, c) 1/4 (d, c) 1/3(b, d) 1/4Table 3: Assigning weights to token pairs6 Data and initial experimentsWe randomly selected a workbench of 101 sentences from a textbook of Czech language for elementaryschools (Stybl?
?k and Melichar, 2005) with the average length of 8.5 tokens, for details see Figure 9.These sentences were manually analysed according to the school system with the emphasis placed onsyntactic analysis.
Namely, elementary school teachers T1 and T2 and secondary school students S1 andS2 drew school system diagrams using?Capek 1.0.
Teachers T1 and T2 are colleagues from the sameschool but they were drawing diagrams separately.
Students S1 and S2 study at different schools andthey are students neither of T1 nor T2.
In Table 6, we present TED for pairs of teachers and students.As we expected, the teachers?
diagrams are the most similar ones and on the other hand, the students?diagrams are the most different one.
Taking teacher T1 as a gold-standard data, student S1 made lesserrors that student S2.
We analyzed differences in details considering two aspects:?
Do nodes closer to the root node cause more differences?
A diagram D2 is transformed into adiagram D1 by a sequence of operations (SPL, JOIN, INS, LINK, SLAB) where the first operationFigure 9: Length of sentences in the workbenchFigure 10: TED vs.
Sentence length44(T1,T2) (T1,S1) (T1,S2) (S1,S2) U1 U2 U3 U4 U5 U6 U7 MV# of sentences 101 91 101 91 10 10 10 10 10 10 10 10TED 0.26 0.49 0.56 0.69 0.78 0.63 0.56 0.76 0.38 0.62 1.21 0.40Table 6: TED for pairs of teachers and students, for pairs of teacher T1 and users U1,...,U7 and their combination MVFigure 11: First Error Depthis applied on the node in some depth of D2 (where the depth of a node is the length of the path fromthe root to that node).
Figure 11 illustrates this depth for pairs of teachers and students.
We observethat the very first operation is applied in the root nodes mostly.
So we can suppose that recognizingpredicate and its dependent nodes is the most difficult step for users.?
Do longer sentences cause more difficulties?
In Figure 10, we observe that the sentence length doesnot influence discrepancies between teachers at all (measured by TED).
For students, we can seepeaks for sentences of 12, 15, 17, 23 tokens.
However, we suppose that longer sentences do notcause obstacles for them.A group of 7 users U1, .
.
.
, U7, graduate and undergraduate students, drew diagrams for 10 (S10)sentences randomly selected from the workbench using?Capek 2.0.
We merged their analyses usingthe MV algorithm.
When the final diagrams are compared to the diagrams by the T1 teacher, we getTED(T1,MV (U1, .
.
.
, U8), S10) = 0.4.
To see whether we built a better final diagram, we computedTED(T1, Ui, S10) for each user ?
see columns U1,.
.
.
,U7 in Table 6.
One can see that only one user(U5) has a slightly better agreement with the T1 diagrams.
The user U7 actually managed to have morethan one error (differences from T1) per annotated token.7 ConclusionIn this paper, we have shown our motivation for getting more syntactically annotated data by sentencediagrams transformation.
We have implemented?Capek, a diagram editor, which allows students to per-form sentence analysis electronically.
We can then collect their diagrams easily.
The editor is designedas both a CALL and crowdsourcing system for practicing morphology and syntax and for collecting dia-grams over a given set of sentences.
Both aspects have to deal with a quantitative measure of agreement,therefore we designed a tree edit distance metric comparing two or multiple diagrams.
In addition, wehave formulated an algorithm combining multiple crowdsourced diagrams into a single better diagram.Finally, we presented the results of a pilot study with promising results.In the near future, to get more statistically significant results, we plan to address the following issues:?
evaluating the combination algorithm on complex sentences?
specifying the practice of crowdsourcing: how to distribute tasks, and how to assign voting weightsto users based on their past results?
getting more diagrams45AcknowledgementsThe authors would like to thank numerous persons for their sentence diagrams drawn using?Capek.
Wegratefully acknowledge support from the Charles University Grant Agency (grant no.
1568314), CharlesUniversity in Prague, Faculty of Mathematics and Physics.
This work has been using language resourcesdeveloped and/or stored and/or distributed by the LINDAT/CLARIN project of the Ministry of Education,Youth and Sports of the Czech Republic (project LM2010013).ReferencesPhilip Bille.
2005.
A survey on tree edit distance and related problems.
Theoretical computer science, 337(1):217?239.Daren C. Brabham.
2013.
Crowdsourcing.
MIT Press.Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning.
2006.
Generating typed dependencyparses from phrase structure parses.
In Proceedings of the 8th International Conference on Language Resourcesand Evaluation (LREC 2006), pages 449?454.Jan Haji?c, Eva Haji?cov?a, Jarmila Panevov?a, Petr Sgall, Petr Pajas, Jan?St?ep?anek, Ji?r??
Havelka, and Marie Mikulov?a.2006.
Prague Dependency Treebank 2.0.
Number LDC2006T01.
Linguistic Data Consortium.Jirka Hana and Barbora Hladk?a.
2012.
Getting more data: Schoolkids as annotators.
In Proceedings of the 8thInternational Conference on Language Resources and Evaluation (LREC 2012), pages 4049?4054,?Istanbul,Turkey.
European Language Resources Association.Pei-Yun Hsueh, Prem Melville, and Vikas Sindhwani.
2009.
Data quality from crowdsourcing: A study of an-notation selection criteria.
In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for NaturalLanguage Processing, HLT ?09, pages 27?35, Stroudsburg, PA, USA.
Association for Computational Linguis-tics.Richard Hudson.
1984.
Word Grammar.
Blackwell.David McClosky, Eugene Charniak, and Mark Johnson.
2010.
Automatic domain adaptation for parsing.
InHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the Associationfor Computational Linguistics, HLT ?10, pages 28?36, Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Haji?c.
2005.
Non-projective dependency parsing usingspanning tree algorithms.
In Proceedings of the Conference on Human Language Technology and EmpiricalMethods in Natural Language Processing, HLT ?05, pages 523?530, Stroudsburg, PA, USA.
Association forComputational Linguistics.Igor Mel??cuk.
1988.
Dependency syntax: theory and practice.
State University of New York Press.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, Glsen Eryigit, Sandra K?ubler, Svetoslav Marinov, andErwin Marsi.
2007.
Maltparser: A language-independent system for data-driven dependency parsing.
NaturalLanguage Engineering, 13(2):95?135.Marta Sabou, Kalina Bontcheva, and Arno Scharl.
2012.
Crowdsourcing research opportunities: Lessons fromnatural language processing.
In Proceedings of the 12th International Conference on Knowledge Managementand Knowledge Technologies, i-KNOW ?12, pages 17:1?17:8, New York, NY, USA.
ACM.Petr Sgall, Eva Haji?cov?a, and Jarmila Panevov?a.
1986.
The Meaning of the Sentence and Its Semantic andPragmatic Aspects.
Academia/Reidel Publishing Company, Prague, Czech Republic/Dordrecht, Netherlands.Vlastimil Stybl?
?k and Ji?r??
Melichar.
2005.?Cesk?y jazyk - P?rehled u?civa z?akladn??
?skoly.
Fortuna.Mihai Surdeanu and Christopher D. Manning.
2010.
Ensemble models for dependency parsing: Cheap andgood?
In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of theAssociation for Computational Linguistics, HLT ?10, pages 649?652, Stroudsburg, PA, USA.
Association forComputational Linguistics.Aobo Wang, Cong Duy Vu Hoang, and Min-Yen Kan. 2010.
Perspectives on crowdsourcing annotations fornatural language processing.46Yi Zhang and Rui Wang.
2009.
Cross-domain dependency parsing using a deep linguistic grammar.
In Proceed-ings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ?09, pages 378?386, Stroudsburg,PA, USA.
Association for Computational Linguistics.47
