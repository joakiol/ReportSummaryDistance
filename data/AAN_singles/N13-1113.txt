Proceedings of NAACL-HLT 2013, pages 928?937,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsImproved Information Structure Analysis of Scientific Documents ThroughDiscourse and Lexical ConstraintsYufan GuoUniversity of Cambridge, UKyg244@cam.ac.ukRoi ReichartUniversity of Cambridge, UKrr439@cam.ac.ukAnna KorhonenUniversity of Cambridge, UKalk23@cam.ac.ukAbstractInferring the information structure of scien-tific documents is useful for many down-stream applications.
Existing feature-basedmachine learning approaches to this task re-quire substantial training data and suffer fromlimited performance.
Our idea is to guidefeature-based models with declarative domainknowledge encoded as posterior distributionconstraints.
We explore a rich set of discourseand lexical constraints which we incorporatethrough the Generalized Expectation (GE) cri-terion.
Our constrained model improves theperformance of existing fully and lightly su-pervised models.
Even a fully unsupervisedversion of this model outperforms lightly su-pervised feature-based models, showing thatour approach can be useful even when no la-beled data is available.1 IntroductionTechniques that enable automatic analysis of the in-formation structure of scientific articles can help sci-entists identify information of interest in the grow-ing volume of scientific literature.
For example,classification of sentences according to argumenta-tive zones (AZ) ?
an information structure schemethat is applicable across scientific domains (Teufelet al 2009) ?
can support information retrieval, in-formation extraction and summarization (Teufel andMoens, 2002; Tbahriti et al 2006; Ruch et al2007; Liakata et al 2012; Contractor et al 2012).Previous work on sentence-based classification ofscientific literature according to categories of infor-mation structure has mostly used feature-based ma-chine learning, such as Support Vector Machines(SVM) and Conditional Random Fields (CRF) (e.g.
(Teufel and Moens, 2002; Lin et al 2006; Hiro-hata et al 2008; Shatkay et al 2008; Guo et al2010; Liakata et al 2012)).
Unfortunately, the per-formance of these methods is rather limited, as indi-cated e.g.
by the relatively low numbers reported byLiakata et al(2012) in biochemistry and chemistrywith per-class F-scores ranging from .18 to .76.We propose a novel approach to this task in whichtraditional feature-based models are augmented withexplicit declarative expert and domain knowledge,and apply it to sentence-based AZ.
We explore twosources of declarative knowledge for our task - dis-course and lexical.
One way to utilize discourseknowledge is to guide the model predictions by en-coding a desired predicted class (i.e.
informationcategory) distribution in a given position in the doc-ument.
Consider, for example, sentence (1) from thefirst paragraph of the Discussion section in a paper:(1) In time, this will prove to be most suitable fordetailed analysis of the role of these hormones inmammary cancer development.Although the future tense and cue phrases such as?in time?
can indicate that authors are discussing fu-ture work (i.e.
the ?Future work?
class in the AZscheme), in this case they refer to their own contri-bution (i.e.
the ?Conclusion?
class in AZ).
As mostauthors discuss their own contribution in the begin-ning of the Discussion section and future directionsin the end, encoding the desired class distribution asa function of the position in this section can guidethe model to the right decision.Likewise, lexical knowledge can guide the model928through predicted class distributions for sentencesthat contain specific vocabulary.
Consider, for ex-ample, sentence (2):(2) The values calculated for lungs include thepresumed DNA adduct of BA and might thus beslightly overestimated.The verb ?calculated?
usually indicates the?Method?
class, but, when accompanied by themodal verb ?might?, it is more likely to imply thatauthors are interpreting their own results (i.e.
the?Conclusion?
class in AZ).
This can be explicitlyencoded in the model through a target distributionfor sentences containing certain modal verbs.Recent work has shown that explicit declarationof domain and expert knowledge can be highly use-ful for structured NLP tasks such as parsing, POStagging and information extraction (Chang et al2007; Mann and McCallum, 2008; Ganchev et al2010).
These works have encoded expert knowledgethrough constraints, with different frameworks dif-fering in the type of constraints and the inferenceand learning algorithms used.
We build on the Gen-eralized Expectation (GE) framework (Mann andMcCallum, 2007) which encodes expert knowledgethrough a preference (i.e.
soft) constraints for pa-rameter settings for which the predicted label distri-bution matches a target distribution.In order to integrate domain knowledge with afeatures-based model, we develop a simple taxon-omy of constraints (i.e.
desired class distributions)and employ a top-down classification algorithm ontop of a Maximum Entropy Model augmented withGE constraints.
This algorithm enables us to breakthe multi-class prediction into a pipeline of consecu-tive, simpler predictions which can be better assistedby the encoded knowledge.We experiment in the biological domain with theeight-category AZ scheme (Table 1) adapted from(Mizuta et al 2006) and described in (Contractoret al 2012).
The results show that our constrainedmodel substantially outperforms a baseline uncon-strained Maximum Entropy Model.
While this typeof constrained models have previously improvedthe feature-based model performance mostly in theweakly supervised and domain adaptation scenarios(e.g.
(Mann and McCallum, 2007; Mann and Mc-Callum, 2008; Ganchev et al 2010)), we demon-strate substantial gains both when the Maximum En-Table 1: The AZ categories included in the categorizationscheme of this paper.Zone DefinitionBackground (BKG) the background of the studyProblem (PROB) the research problemMethod (METH) the methods usedResult (RES) the results achievedConclusion (CON) the authors?
conclusionsConnection (CN) work consistent with the current workDifference (DIFF) work inconsistent with the current workFuture work (FUT) the potential future direction of the researchtropy Model is fully trained and when its trainingdata is sparse.
This demonstrates the importance ofexpert knowledge for our task and supports our mod-eling decision that combines feature-based methodswith domain knowledge encoded via constraints.2 Previous workInformation structure analysis The informationstructure of scientific documents (e.g.
journal ar-ticles, abstracts, essays) can be analyzed in termsof patterns of topics, functions or relations observedin multi-sentence scientific text.
Computational ap-proaches have mainly focused on analysis basedon argumentative zones (Teufel and Moens, 2002;Mizuta et al 2006; Hachey and Grover, 2006;Teufel et al 2009), discourse structure (Burstein etal., 2003; Webber et al 2011), qualitative dimen-sions (Shatkay et al 2008), scientific claims (Blake,2009), scientific concepts (Liakata et al 2010) andinformation status (Markert et al 2012).Most existing methods for analyzing scientifictext according to information structure use fullsupervision in the form of thousands of manu-ally annotated sentences (Teufel and Moens, 2002;Burstein et al 2003; Mizuta et al 2006; Shatkayet al 2008; Guo et al 2010; Liakata et al 2012;Markert et al 2012).
Because manual annotation isprohibitively expensive, approaches based on lightsupervision are now emerging for the task, includingthose based on active learning and self-training (Guoet al 2011) and unsupervised methods (Varga et al2012; Reichart and Korhonen, 2012).
Unfortunately,these approaches do not reach the performance levelof fully supervised models, let ale exceed it.
Ournovel method addresses this problem.Declarative knowledge and constraints Previ-ous work has shown that incorporating declara-tive constraints into feature-based machine learning929models works well in many NLP tasks (Chang etal., 2007; Mann and McCallum, 2008; Druck et al2008; Bellare et al 2009; Ganchev et al 2010).Such constraints can be used in a semi-supervised orunsupervised fashion.
For example, (Mann and Mc-Callum, 2008) shows that using CRF in conjunctionwith auxiliary constraints on unlabeled data signif-icantly outperforms traditional CRF in informationextraction, and (Druck et al 2008) shows that usingdeclarative constraints alone for unsupervised learn-ing achieves good results in text classification.
Weshow that declarative constraints can be highly use-ful for the identification of information structure ofscientific documents.
In contrast with most previousworks, we show that such constraints can improvethe performance of a fully supervised model.
Theconstraints are particularly helpful for identifyinglow-frequency information categories, but still yieldhigh performance on high-frequency categories.3 Maximum-Entropy Estimation andGeneralized Expectation (GE)In this section we describe the Generalized Expecta-tion method for declarative knowledge encoding.Maximum Entropy (ME) The idea of General-ized Expectation (Dud?
?k, 2007; Mann and McCal-lum, 2008; Druck et al 2008) stems from the prin-ciple of maximum entropy (Jaynes, 1957; Pietra andPietra, 1993) which raises the following constrainedoptimization problem:maxpH(?
)subject to Ep[f(?)]
= Ep?[f(?)]p(?)
?
0?p(?)
= 1, (1)where p?(?)
is the empirical distribution, p(?)
is aprobability distribution in the model and H(?)
is thecorresponding information entropy, f(?)
is a collec-tion of feature functions, and Ep[f(?)]
and Ep?[f(?
)]are the expectations of f with respect to p(?)
andp?(?).
An example of p(?)
could be a conditionalprobability distribution p(y|x), and H(?)
could bea conditional entropy H(y|x).
The optimal p(y|x)will take on an exponential form:p?
(y|x) =1Z?exp(?
?
f(x, y)), (2)where ?
is the Lagrange multipliers in the corre-sponding unconstrained objective function, and Z?is the partition function.
The dual problem be-comes maximizing the conditional log-likelihood oflabeled data L (Berger et al 1996):max??(xi,yi)?Llog(p?
(yi|xi)), (3)which is usually known as a Log-linear or MaximumEntropy Model (MaxEnt).ME with Generalized Expectation The objec-tive function and the constraints on expectations in(1) can be generalized to:max???xp?(x)D(p?(y|x)||p0(y|x))?
g(Ep?(x)[Ep?
(y|x)[f(x, y)|x]]), (4)where D(p?||p0) is the divergence from p?
to a basedistribution p0, and g(?)
is a constraint/penalty func-tion that takes empirical evidence Ep?
(x,y)[f(x, y)] asa reference point (Pietra and Pietra, 1993; Chen etal., 2000; Dud?
?k, 2007).
Note that a special case ofthis is MaxEnt where p0 is set to be a uniform distri-bution, D(?)
to be the KL divergence, and g(?)
to bean equality constraint.The constraint g(?)
can be set in a relaxed manner:?k12?2k(Ep?(x)[Ep?
(y|x)[fk(x, y)|x]]?
Ep?
(x,y)[fk(x, y)])2,which is the logarithm of a Gaussian distributioncentered at the reference values with a diagonal co-variance matrix (Pietra and Pietra, 1993), and thedual problem will become a regularized MaxEntwith a Gaussian prior (?k = 0, ?2k =1?2k) over theparameters:max??(xi,yi)?Llog(p?(yi|xi))?
?k?2k2?2k(5)Such a model can be further extended to includeexpert knowledge or auxiliary constraints on unla-beled data U (Mann and McCallum, 2008; Druck etal., 2008; Bellare et al 2009):max??(xi,yi)?Llog(p?(yi|xi))??k?2k2?2k?
?g?(Ep?(y|x)[f?
(x, y)]) (6)where f?(?)
is a collection of auxiliary feature func-tions on U , g?(?)
is a constraint function that takesexpert/declarative knowledge Ep?(y|x)[f?
(x, y)] as areference point, and ?
is the weight of the auxiliaryGE term.930The auxiliary constraint g?(?)
can take on manyforms and the one we used in this work is an L2penalty function (Dud?
?k, 2007).
We trained themodel with L-BFGS (Nocedal, 1980) in supervised,semi-supervised and unsupervised fashions on la-beled and/or unlabeled data, using the Mallet soft-ware (McCallum, 2002).4 Incorporating Expert Knowledge intoGE constraintsWe defined the auxiliary feature functions ?
the ex-pert knowledge on unlabeled data as1:f?k (x, y) = 1(xk,yk)(x, y),such that Ep?
(y|x)[fk(x, y)] = p?
(yk|xk), (7)where 1(xk,yk)(x, y) is an indicator function, andp?
(yk|xk) is a conditional probability specified inthe form ofp?
(yk|xk) ?
[ak, bk] (8)by experts.
In particular, we tookp?
(yk|xk) =??
?ak if p?
(yk|xk) < abk if p?
(yk|xk) > bp?
(yk|xk) if a ?
p?
(yk|xk) ?
b(9)as the reference point when calculating g?(?
).We defined two types of constraints: those basedon discourse properties such as the location of a sen-tence in a particular section or paragraph, and thosebased on lexical properties such as citations, refer-ences to tables and figures, word lists, tenses, andso on.
Note that the word lists actually contain bothlexical and semantic information.To make an efficient use of the declarative knowl-edge we build a taxonomy of information structurecategories centered around the distinction betweencategories that describe the authors?
OWN work andthose that describe OTHER work (see Section 5).
Inpractice, our model labels every sentence with anAZ category augmented by one of the two cate-gories, OWN or OTHER.
In evaluation we consideronly the standard AZ categories which are part ofthe annotation scheme of (Contractor et al 2012).1Accordingly, Ep?
(y|x)[fk(x, y)] = p?
(yk|xk)Table 2: Discourse and lexical constraints for identifying infor-mation categories at different levels of the information structuretaxonomy.
(a) OWN / OTHEROWN Discourse(1) Target(last part of paragraph) = 1(2) Target(last part of section) = 1Lexical(3) Target(tables/figures) ?
1(4) ?x ?
{w|w?we} Target(x) = 1?
?y ?
{w|w?previous} Target(y) = 0(5) ?x ?
{w|w?thus} Target(x) = 1OTHER Lexical(6) Target(cite) = 1(7) Target(cite) > 1(8) Backward(cite) = 1?
?x ?
{w|w?in addition} Target(x) = 1(b) PROB / METH / RES / CON / FUTPROB Discourse(1) Target(last part in section) = 1Lexical(2) ?x ?
{w|w?aim} Target(x) = 1(3) ?x ?
{w|w?question} Target(x) = 1(4) ?x ?
{w|w?investigate} Target(x) = 1METH Lexical(5) ?x ?
{w|w?
{use,method}} Target(x) = 1RES Lexical(6) Target(tables/figures) ?
1(7) ?x ?
{w|w?observe} Target(x) = 1CON Lexical(8) Target(cite) ?
1(9) ?x ?
{w|w?conclude} Target(x) = 1(10) ?x ?
{w|w?
{suggest, thus, because, likely}}Target(x) = 1FUT Discourse(11) Target(first part in section) = 1(12) Target(last part in section) = 1?
?x ?
{w|w?
{will,need,future}} Target(x) = 1Lexical(13) ?x {w|w?will,future} Target(x) = 1(14) Target(present continuous tense) = 1(c) BKG / CN / DIFFBKG Discourse(1) Target(first part in paragraph) = 1(2) Target(first part in section) = 1Lexical(3) ?x ?
{w|w?we} Target(x) = 1?
?y ?
{w|w?previous} Target(y) = 0(4) Forward(cite) = 1?
?x ?
{w|w?
{consistent,inconsistent,than}}(Target(x) = 0 ?
Forward(x) = 0)CN Lexical(5) ?x ?
{w|w?consistent} Target(x) = 1(6) ?x ?
{w|w?consistent} Forward(x) = 1DIFF Lexical(7) ?x ?
{w|w?inconsistent} Target(x) = 1(8) ?x ?
{w|w?inconsistent} Forward(x) = 1(9) ?x ?
{w|w?
{inconsistent,than,however}}Forward(x) = 1 ?
?y ?
{w|w?we} Forward(y) = 1?
?z ?
{w|w?previous}} Forward(z) = 0931Table 3: The lexical sets used as properties in the constraints.Cue Synonymswe our, present studyprevious previously, recent, recentlythus thereforeaim objective, goal, purposequestion hypothesis, ?investigate explore, study, test, examine, evaluate, assess, deter-mine, characterize, analyze, report, presentuse employmethod algorithm, assayobserve see, find, showconclude conclusion, summarize, summarysuggest illustrate, demonstrate, imply, indicate, confirm, re-flect, support, prove, revealbecause result from, attribute tolikely probable, probably, possible, possibly, may, couldneed remainfuture furtherconsistent match, agree, support, in line, in agreement, similar,same, analogousinconsistent conflicting, conflict, contrast, contrary, differ, differ-ent, differencethan comparehowever other hand, although, though, butThe constraints in Table 2(a) refer to the top levelof this taxonomy: distinction between the authors?own work and the work of others, and the constraintsin Tables 2(b)-(c) refer to the bottom level of the tax-onomy: distinction between AZ categories related tothe authors?
own work (Table 2(b)) and other?s work(Table 2(c)).The first and second columns in each table referto the y and x variables in Equation (8), respectively.The functions Target(?
), Forward(?)
and Backward(?
)refer to the property value for the target, next andpreceding sentence, respectively.
If their value is 1then the property holds for the respective sentence,if it is 0, the property does not hold.
In some casesthe value of such functions can be greater than 1,meaning that the property appears multiple times inthe sentence.
Terms of the form {w|w?
{wi}} referto any word/bi-grams that have the same sense aswi,where the actual word set we use with every exampleword in Table 2 is described in Table 3.For example, take constraints (1) and (4) in Table2(a).
The former is a standard discourse constraintthat refers to the probability that the target sentencedescribes the authors?
own work given that it appearsin the last of the ten parts in the paragraph.
The lat-ter is a standard lexical constraint that refers to theprobability that a sentence presents other people?swork given that it contains any words in {we, our,present study} and that it doesn?t contain any wordsFigure 1: The constraint taxonomy for top-down modeling.INFO [Table 2(a)]OWN [Table 2(b)]PROB METH RES CON FUTOTHER [Table 2(c)]BKG CN DIFFin {previous, previously, recent, recently}.
Our con-straint set further includes constraints that combineboth types of information.
For example, constraint(12) in Table 2(b) refers to the probability that a sen-tence discusses future work given that it appears inthe last of the ten parts of the section (discourse) andthat it contains at least one word in {will, future, fur-ther, need, remain} (lexical).5 Top-Down ModelAn interesting property of our task and domain isthat the available expert knowledge does not directlysupport the distinctions between AZ categories, butit does provide valuable indirect guidance.
For ex-ample, the number of citations in a sentence is onlyuseful for separating the authors?
work from otherpeople?s work, but not for further fine grained dis-tinctions between zone categories.
Moreover, thoseconstraints that are useful for making fine graineddistinctions between AZ categories are usually use-ful only for a particular subset of the categories only.For example, all the constraints in Table 2(b) areconditioned on the assumption that the sentence de-scribes the authors?
own work.To make the best use of the domain knowledge,we developed a simple constraint taxonomy, and ap-ply a top-down classification approach which uti-lizes it.
The taxonomy is presented in Figure 1.
Forclassification we trained three MaxEnt models aug-mented with GE constraints: one for distinguishingbetween OWN and OTHER2, one for distinguishingbetween the AZ categories under the OWN auxiliarycategory and one for distinguishing between the AZcategories under the OTHER auxiliary category.
Attest time we first apply the first classifier and basedon its prediction we apply either the classifier thatdistinguishes between OWN categories or the onethat distinguishes between OTHER categories.2For the training of this model, each training data AZ cate-gory is mapped to its respective auxiliary class.9326 ExperimentsData We used the full paper corpus used by Contrac-tor et al(2012) which contains 8171 sentences from50 biomedical journal articles.
The corpus is anno-tated according to the AZ scheme described in Table1.
AZ describes the logical structure, scientific argu-mentation and intellectual attribution of a scientificpaper.
It was originally introduced by Teufel andMoens (2002) and applied to computational linguis-tics papers, and later adapted to other domains suchas biology (Mizuta et al 2006) ?
which we used inthis work ?
and chemistry (Teufel et al 2009).Table 4 shows the AZ class distribution in full ar-ticles as well as in individual sections.
Since sectionnames vary across scientific articles, we groupedsimilar sections before calculating the statistics (e.g.Discussion and Conclusions sections were groupedunder Discussion).
We can see that although there isa major category in each section (e.g.
CON in Dis-cussion), up to 36.5% of the sentences in each sec-tion still belong to other categories.Features We extracted the following featuresfrom each sentence and used them in the feature-based classifiers: (1) Discourse features: location inthe article/section/paragraph.
For this feature eachtext batch was divided to ten equal size parts and thecorresponding feature value identifies the relevantpart; (2) Lexical features: number of citations andreferences to tables and figures (0, 1, or more), word,bi-gram, verb, and verb class (obtained by spectralclustering (Sun and Korhonen, 2009)); (3) Syntac-tic features: tense and voice (POS tags of main andauxiliary verbs), grammatical relation, subject andobject.
The lexical and the syntactic features wereextracted for the represented sentence as well as forits surrounding sentences.
We used the C&C POStagger and parser (Curran et al 2007) for extract-ing the lexical and the syntactic features.
Note thatall the information encoded into our constraints isalso encoded in the features and is thus available tothe feature-based model.
This enables us to properlyevaluate the impact of our modeling decision whichaugments a feature-based model with constraints.Baselines We compared our model against fourbaselines, two with full supervision: Support Vec-tor Machines (SVM) and Maximum Entropy Mod-els (MaxEnt), and two with light supervision: Trans-Table 4: Class distribution (shown in percentages) in articlesand their individual sections in the AZ-annotated corpus.BKG PROB METH RES CON CN DIFF FUTArticle 16.9 2.8 34.8 17.9 22.3 4.3 0.8 0.2Introduction 74.8 13.2 5.4 0.6 5.9 0.1 - -Methods 0.5 0.2 97.5 1.4 0.2 0.2 0.1 -Results 4.0 2.1 11.7 68.9 12.1 1.1 0.1 -Discussion 16.9 1.1 0.7 1.5 63.5 13.3 2.4 0.7Table 5: Performance of baselines on the Discussion section.BKG PROB METH RES CON CN DIFF FUTFull supervisionSVM .56 0 0 0 .84 .35 0 0MaxEnt .55 .08 0 0 .84 .38 0 0Light supervision with 150 labeled sentenceSVM .26 0 0 0 .80 .05 0 0TSVM .25 .04 .04 .03 .33 14 .06 .02MaxEnt .25 0 0 0 .80 .10 0 0MaxEnt+ER .23 0 0 0 .80 .07 0 0ductive SVM (TSVM) and semi-supervised Max-Ent based on Entropy Regularization (ER) (Vapnik,1998; Jiao et al 2006).
SVM and MaxEnt haveproved successful in information structure analysis(e.g.
(Merity et al 2009; Guo et al 2011)) but,to the best of our knowledge, their semi-supervisedversions have not been used for AZ of full articles.Parameter tuning The boundaries of the ref-erence probabilities (ak and bk in Equation (8))were defined and optimized on the development datawhich consists of one third of the corpus.
We con-sidered six types of boundaries: Fairly High for1, High for [0.9,1), Medium High for [0.5,0.9),Medium Low for [0.1,0.5), Low for [0,0.1), andFairly Low for 0.Evaluation We evaluated the precision, recall andF-score for each category, using a standard ten-foldcross-validation scheme.
The models were tested oneach of the ten folds and trained on the rest of them,and the results were averaged across the ten folds.7 ResultsWe report results at two levels of granularity.
Wefirst provide detailed results for the Discussion sec-tion which should be, as is clearly evident from Ta-ble 4, the most difficult section for AZ prediction asonly 63.5% of its sentences take its most dominantclass (CON).
As we show below, this is also whereour constrained model is most effective.
We thenshow the advantages of our model for other sections.Results for the Discussion section To get a bet-933Table 6: Discussion section performance of MaxEnt, MaxEnt+GE and a MaxEnt+GE model that does not include our top-downclassification scheme.
Results are presented for different amounts of labeled training data.
The MaxEnt+GE (Top-down) modeloutperforms the MaxEnt in 44 out of 48 cases, and MaxEnt+GE (Flat) in 39 out of 48 cases.MaxEnt MaxEnt + GE (Top-down) MaxEnt + GE (Flat)50 100 150 500 1000 Full 50 100 150 500 1000 Full 50 100 150 500 1000 FullBKG .10 .26 .25 .44 .48 .55 .49 .49 .48 .52 .55 .57 .35 .37 .37 .46 .51 .53PROB 0 0 0 0 0 0 .38 .16 .29 .13 .30 .41 .38 .23 .19 .39 .38 .33METH 0 0 0 0 0 0 .17 .22 .37 .35 .50 .39 .16 .17 .21 .24 .32 .29RES 0 0 0 0 0 0 .18 .24 .58 0 0 .46 .13 .05 .21 .31 .25 .34CON .79 .80 .80 .83 .83 .84 .77 .78 .82 .83 .84 .84 .63 .66 .68 .74 .78 .78CN .02 .04 .10 .24 .34 .38 .29 .31 .33 .35 .40 .39 .21 .21 .24 .26 .30 .32DIFF 0 0 0 0 0 0 .26 .25 .25 .19 .24 .21 .14 .16 .15 .14 .18 .17FUT 0 0 0 0 0 0 .35 .38 .31 .25 .35 .31 .36 .36 .39 .33 .25 .37Figure 2: Performance of the MaxEnt and MaxEnt+GE models on the Introduction (left), Methods (middle) and Results (right)sections.
The MaxEnt+GE model is superior.00.20.40.60.81BKG PROB METH RES CON CN DIFF FUTF-scoreMaxEnt MaxEnt+GE00.20.40.60.81BKG PROB METH RES CON CN DIFF FUTF-scoreMaxEnt MaxEnt+GE00.20.40.60.81BKG PROB METH RES CON CN DIFF FUTF-scoreMaxEnt MaxEnt+GE00.20.40.60.81BKG PROB METH RES CON CN DIFF FUTF-scoreMaxEnt MaxEnt+GETable 7: Discussion section performance of the MaxEnt, Max-Ent+GE and unsupervised GE models when the former two aretrained with 150 labeled sentences.
Unsupervised GE outper-forms the standard MaxEnt model for all categories except forCON ?
the major c tegory of the section.
The result pattern forthe other sections are very similar.MaxEnt MaxEnt + GE Unsup GEP R F P R F P R FBKG .38 .19 .25 .49 .48 .48 .49 .44 .46PROB 0 0 0 .38 .23 .29 .28 .38 .32METH 0 0 0 .29 .50 .37 .08 .56 .14RES 0 0 0 .68 .51 .58 .08 .51 .14CON .69 .96 .80 .81 .84 .82 .74 .69 .71CN .35 .06 .10 .39 .29 .33 .40 .13 .20DIFF 0 0 0 .21 .30 .25 .12 .13 .12FUT 0 0 0 .24 .44 .31 .26 .61 .36ter understanding of the nature of the challenge weface, Table 5 shows the F-scores of fully- and semi-supervised SVM and MaxEnt on the Discussion sec-tion.
The dominant zone category CON, which ac-counts for 63.5% of the section sentences, has thehighest F-scores for all methods and scenarios.
Mostof the methods also identify the second and the thirdmost frequent zones BKG and CN, but with relativelylower F-scores.
Other low-frequency categories canhardly be identified by any of the methods regardlessof the amount of labeled data available for training.Note that the compared models perform quite sim-ilarly.
We therefore use the MaxEnt model, whichTable 8: Analysis of the impact of the different constraint typesfor the lightly supervised and the fully supervised cases.
Resultsare presented for the Discussion section.
Using only the lexicalconstraints is generally preferable in the fully supervised case.Combining the different constraint types is preferable for thelightly supervised case.Discourse Lexical Discourse+Lexical150 Full 150 Full 150 FullBKG .29 .55 .46 .58 .48 .57PROB 0 0 .37 .40 .29 .41METH 0 .11 .29 .35 .37 .39RES 0 .06 .32 .47 .58 .46CON .81 .84 .80 .84 .82 .84CN .12 .34 .35 .42 .33 .39DIFF 0 0 .21 .21 .25 .21FUT 0 0 0 .29 .31 .31is most naturally augmented with GE constraints, asthe baseline unconstrained model.When adding the GE constraints we observe asubstantial performance gain, in both the fully andthe lightly supervised cases, especially for the low-frequency categories.
Table 6 presents the F-scoresof MaxEnt with and without GE constraints (?Max-Ent+GE (Top-down)?
and ?MaxEnt?)
in the lightand full supervision scenarios.
Incorporating GEinto MaxEnt results in a substantial F-score im-provement for all AZ categories except for the ma-jor category CON for which the performance is keptvery similar.
In total, MaxEnt+GE (Top-down) is934better in 44 out of the 48 cases presented in the table.Importantly, the constrained model provides sub-stantial improvements for both the relatively high-frequency classes (BKG and CN which together label30.2% of the sentences) and for the low-frequencyclasses (which together label 6.4% of the sentences).The table also clearly demonstrates the impact ofour tree-based top-down classification scheme, bycomparing the Top-down version of MaxEnt+GEto the standard ?Flat?
version.
In 39 out of 48cases, the Top-down model performs better.
In somecases, especially for high-frequency categories andwhen the amount of training data increases, un-constrained MaxEnt even outperforms the flat Max-Ent+GE model.
The results presented in the rest ofthe paper for the MaxEnt+GE model therefore referto its Top-down version.All sections We next turn to the performance ofour model on the three other sections.
Our exper-iments show that augmenting the MaxEnt modelwith domain knowledge constraints improves per-formance for all the categories (either low or highfrequency), except the major section category, andkeep the performance for the latter on the same level.Figure 2 demonstrates this pattern for the lightly su-pervised case with 150 training sentences but thesame pattern applies to all other amounts of trainingdata, including the fully supervised case.
Naturally,we cannot demonstrate all these cases due to spacelimitations.
The result patterns are very similar tothose presented above for the Discussion section.Unsupervised GE We next explore the quality ofthe domain knowledge constraints when used in iso-lation from a feature-based model.
The objectivefunction of this model is identical to Equation (6)except that the first (likelihood) term is omitted.
Ourexperiments reveal that this unsupervised GE modeloutperforms standard MaxEnt for all the categoriesexcept the major category of the section, when upto 150 training sentences are used.
Table 7 demon-strates this for the Discussion section.
This patternholds for the other scientific article sections.
Evenwhen more than 150 labeled sentences are used, theunsupervised model better detects the low frequencycategories (i.e.
those that label less than 10% ofthe sentences) for all sections.
These results providestrong evidence for the usefulness of our constraintseven when they are used with no labeled data.Model component analysis We finally analyzethe impact of the different types of constraints onthe performance of our model.
Table 8 presents theDiscussion section performance of the constrainedmodel with only one or the full set of constraints.Interestingly, when the feature-based model is fullytrained the application of the lexical constraintsalone results in a very similar performance to theapplication of the full set of lexical and discourseconstraints.
It is only in the lightly supervised casewhere the full set of constraints is required and re-sults in the best performing model.8 Conclusions and Future WorkWe have explored the application of posterior dis-course and lexical constraints for the analysis of theinformation structure of scientific documents.
Ourresults are strong.
Our constrained model outper-forms standard feature-based models by a large mar-gin in both the fully and the lightly supervised cases.Even an unsupervised model based on these con-straints provides substantial gains over feature-basedmodels for most AZ categories.We provide a detailed analysis of the resultswhich reveals a number of interesting properties ofour model which may be useful for future research.First, the constrained model significantly outper-forms its unconstrained counterpart for low-mediumfrequency categories while keeping the performanceon the major section category very similar to that ofthe baseline model.
Improved modeling of the majorcategory is one direction for future research.
Sec-ond, our full constraint set is most beneficial in thelightly supervised case while the lexical constraintsalone yield equally good performance in the fullysupervised case.
This calls for better understand-ing of the role of discourse constraints for our taskas well as for the design of additional constraintsthat can enhance the model performance either incombination with the existing constraints or whenseparately applied to the task.
Finally, we demon-strated that our top-down tree classification schemeprovides a substantial portion of our model?s impact.A clear direction for future research is the design ofmore fine-grained constraint taxonomies which canenable efficient usage of other constraint types andcan result in further improvements in performance.935ReferencesKedar Bellare, Gregory Druck, and Andrew McCallum.2009.
Alternating projections for learning with expec-tation constraints.
In Proceedings of the Twenty-FifthConference on Uncertainty in Artificial Intelligence,UAI ?09, pages 43?50, Arlington, Virginia, UnitedStates.
AUAI Press.Adam L. Berger, Vincent J. Della Pietra, and StephenA.
Della Pietra.
1996.
A maximum entropy approachto natural language processing.
Comput.
Linguist.,22(1):39?71.Catherine Blake.
2009.
Beyond genes, proteins, andabstracts: Identifying scientific claims from full-textbiomedical articles.
J Biomed Inform, 43(2):173?89.Jill Burstein, Daniel Marcu, and Kevin Knight.
2003.Finding the write stuff: Automatic identification ofdiscourse structure in student essays.
IEEE IntelligentSystems, 18(1):32?39.M.W.
Chang, L. Ratinovc, and D. Roth.
2007.
Guidingsemi-supervision with constraint-driven learning.
InACL.Stanley F. Chen, Ronald Rosenfeld, and Associate Mem-ber.
2000.
A survey of smoothing techniques for memodels.
IEEE Transactions on Speech and Audio Pro-cessing, 8:37?50.Danish Contractor, Yufan Guo, and Anna Korhonen.2012.
Using argumentative zones for extractive sum-marization of scientific articles.
In COLING.J.
R. Curran, S. Clark, and J. Bos.
2007.
Linguisti-cally motivated large-scale nlp with c&c and boxer.
InProceedings of the ACL 2007 Demonstrations Session,pages 33?36.Gregory Druck, Gideon Mann, and Andrew McCallum.2008.
Learning from labeled features using gener-alized expectation criteria.
In Proceedings of the31st annual international ACM SIGIR conference onResearch and development in information retrieval,pages 595?602.Miroslav Dud??k.
2007.
Maximum entropy densityestimation and modeling geographic distributions ofspecies.
Ph.D. thesis.K.
Ganchev, J. Graca, J. Gillenwater, and B. Taskar.2010.
Posterior regularization for structured latentvariable models.
Journal of Machine Learning Re-search.Yufan Guo, Anna Korhonen, Maria Liakata, Ilona SilinsKarolinska, Lin Sun, and Ulla Stenius.
2010.
Identi-fying the information structure of scientific abstracts:an investigation of three different schemes.
In Pro-ceedings of BioNLP, pages 99?107.Yufan Guo, Anna Korhonen, and Thierry Poibeau.
2011.A weakly-supervised approach to argumentative zon-ing of scientific documents.
In Proceedings of the2011 Conference on Empirical Methods in NaturalLanguage Processing, pages 273?283.Ben Hachey and Claire Grover.
2006.
Extractive sum-marisation of legal texts.
Artif.
Intell.
Law, 14:305?345.K.
Hirohata, N. Okazaki, S. Ananiadou, and M. Ishizuka.2008.
Identifying sections in scientific abstracts us-ing conditional random fields.
In Proceedings of 3rdInternational Joint Conference on Natural LanguageProcessing, pages 381?388.E.
T. Jaynes.
1957.
Information Theory and StatisticalMechanics.
Physical Review Online Archive (Prola),106(4):620?630.F.
Jiao, S. Wang, C. Lee, R. Greiner, and D. Schuur-mans.
2006.
Semi-supervised conditional randomfields for improved sequence segmentation and label-ing.
In COLING/ACL, pages 209?216.M.
Liakata, S. Teufel, A. Siddharthan, and C. Batchelor.2010.
Corpora for the conceptualisation and zoning ofscientific papers.
In Proceedings of LREC?10.Maria Liakata, Shyamasree Saha, Simon Dobnik, ColinBatchelor, and Dietrich Rebholz-Schuhmann.
2012.Automatic recognition of conceptualisation zones inscientific articles and two life science applications.Bioinformatics, 28:991?1000.J.
Lin, D. Karakos, D. Demner-Fushman, and S. Khu-danpur.
2006.
Generative content models for struc-tural analysis of medical abstracts.
In Proceedings ofBioNLP-06, pages 65?72.G.
Mann and A. McCallum.
2007.
Simple, robust, scal-able semi-supervised learning via expectation regular-ization.
In ICML.G.
Mann and A. McCallum.
2008.
Generalized expec-tation criteria for semi-supervised learning of condi-tional random fields.
In ACL.Katja Markert, Yufang Hou, and Michael Strube.
2012.Collective classification for fine-grained informationstatus.
In Proceedings of ACL 2012, pages 795?804.A.
K. McCallum.
2002.
Mallet: A machine learning forlanguage toolkit.
http://mallet.cs.umass.edu.S.
Merity, T. Murphy, and J. R. Curran.
2009.
Accurateargumentative zoning with maximum entropy models.In Proceedings of the 2009 Workshop on Text and Ci-tation Analysis for Scholarly Digital Libraries, pages19?26.Y.
Mizuta, A. Korhonen, T. Mullen, and N. Collier.
2006.Zone analysis in biology articles as a basis for in-formation extraction.
International Journal of Med-ical Informatics on Natural Language Processing inBiomedicine and Its Applications, 75(6):468?487.Jorge Nocedal.
1980.
Updating Quasi-Newton Matriceswith Limited Storage.
Mathematics of Computation,35(151):773?782.936S.
Della Pietra and V. Della Pietra.
1993.
Statistical mod-eling by me.
Technical report, IBM.Roi Reichart and Anna Korhonen.
2012.
Document andcorpus level inference for unsupervised and transduc-tive learning of information structure of scientic docu-ments.
In Proceedings of COLING 2012.P.
Ruch, C. Boyer, C. Chichester, I. Tbahriti, A. Geiss-buhler, P. Fabry, J. Gobeill, V. Pillet, D. Rebholz-Schuhmann, C. Lovis, and A. L. Veuthey.
2007.
Usingargumentation to extract key sentences from biomedi-cal abstracts.
Int J Med Inform, 76(2-3):195?200.H.
Shatkay, F. Pan, A. Rzhetsky, and W. J. Wilbur.
2008.Multi-dimensional classification of biomedical text:Toward automated, practical provision of high-utilitytext to diverse users.
Bioinformatics, 24(18):2086?2093.L.
Sun and A. Korhonen.
2009.
Improving verb cluster-ing with automatically acquired selectional preference.In Proceedings of EMNLP, pages 638?647.I.
Tbahriti, C. Chichester, Frederique Lisacek, andP.
Ruch.
2006.
Using argumentation to retrievearticles with similar citations.
Int J Med Inform,75(6):488?495.S.
Teufel and M. Moens.
2002.
Summarizing scien-tific articles: Experiments with relevance and rhetor-ical status.
Computational Linguistics, 28:409?445.S.
Teufel, A. Siddharthan, and C. Batchelor.
2009.
To-wards discipline-independent argumentative zoning:Evidence from chemistry and computational linguis-tics.
In EMNLP.V.
N. Vapnik.
1998.
Statistical learning theory.
Wiley,New York.Andrea Varga, Daniel Preotiuc-Pietro, and FabioCiravegna.
2012.
Unsupervised document zone iden-tification using probabilistic graphical models.
InProceedings of the Eight International Conference onLanguage Resources and Evaluation (LREC?12).B.
Webber, M. Egg, and V. Kordoni.
2011.
Discoursestructure and language technology.
Natural LanguageEngineering, 18:437?490.937
