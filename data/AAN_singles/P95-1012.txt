Compil ing HPSG type constraints into definite clause programsTh i lo  G~tz  and Wal t  Detmar  Meurers*SFB 340, Universit?t Tf ibingcnKleine Wilhelmstrat~e 11372074 TfibingenGermany~tg, dm}?sf s. nphil, uni-tuebingen, deAbst rac tWe present a new approach to HPSG pro-cessing: compiling HPSG grammars ex-pressed as type constraints into definiteclause programs.
This provides a clearand computationally useful correspondencebetween linguistic theories and their im-plementation.
The compiler performs off-line constraint inheritance and code opti-mization.
As a result, we are able to effi-ciently process with HPSG grammars with-out haviog to hand-translate them into def-inite clause or phrase structure based sys-tems.1 In t roduct ionThe HPSG architecture as defined in (Pollard andSag, 1994) (henceforth HPSGII) is being used byan increasing number of linguists, since the formallywell-defined framework allows for a rigid and ex-plicit formalization of a linguistic theory.
At thesame time, the feature logics which provide the for-mal foundation of HPSGII have been used as basisfor several NLP systems, such as ALE (Carpenter,1993), CUF (DSrre and Dorna, 1993), Troll (Gerde-mann and King, 1993) or TFS (Emele and Zajac,1990).
These systems are - at least partly - intendedas computational environments for the implementa-tion of HPSG grammars.HPSG linguists use the description language ofthe logic to express their theories in the form of im-plicative constraints.
On the other hand, most of thecomputational setups only allow feature descriptionsas extra constraints with a phrase structure or defi-nite clause based language.
1 From a computationalpoint of view the latter setup has several advantages.It provides access to the pool of work done in the*The authors are listed alphabetically.1One exception is the TFS system.
However, the pos-sibility to express recursive relations on the level of thedescription language l ads to serious control problems inthat system.area of natural language processing, e.g., to efficientcontrol strategies for the definite clause level basedon tabelling methods like Earley deduction, or differ-ent parsing strategies in the phrase structure setup.The result is a gap between the description lan-guage theories of HPSG linguists and the definiteclause or phrase structure based NLP systems pro-vided to implement these theories.
Most grammarscurrently implemented therefore have no clear corre-spondence to the linguistic theories they originatedfrom.
To be able to use implemented grammars toprovide feedback for a rigid and complete formal-ization of linguistic theories, a clear and computa-tionMly useful correspondence has to be established.This link is also needed to stimulate further devel-opment of the computational systems.
Finally, anHPSGII style setup is also interesting to model froma software ngineering point of view, since it permitsa modular development and testing of the grammar.The purpose of this paper is to provide the de-sired link, i.e., to show how a HPSG theory formu-lated as implicative constraints can be modelled onthe level of the relational extension of the constraintlanguage.
More specifically, we define a compilationprocedure which translates the type constraints ofthe linguistic theory into definite clauses runnable insystems uch as Troll, ALE, or CUF.
Thus, we per-form constraint inheritance and code optimizationoff-line.
This results in a considerable efficiency gainover a direct on-line treatment oftype constraints as,e.g., in TFS.The structure of the paper is as follows: A shortdiscussion of the logical setup for HPSGII providesthe necessary formal background and terminology.Then the two possibilities for expressing a theory -using the description language as in HPSGII or therelational level as in the computational architectures- are introduced.
The third section provides asimplepicture of how HPSGII theories can be modelledon the relational level.
This simple picture is thenrefined in the fourth section, where the compilationprocedure and its implementation is discussed.
Asmall example grammar isprovided in the appendix.852 Background2.1 The HPSGI I  architectureA HPSG grammar consists of two components: thedeclaration of the structure of the domain of linguis-tic objects in a signature (consisting of the type hi-erarchy and the appropriateness conditions) and theformulation of constraints on that domain.
The sig-nature introduces the structures the linguist wantsto talk about.
The theory the linguist proposes dis-tinguishes between those objects in a domain whichare part of the natural language described, and thosewhich are not.HPSGII gives a closed world interpretation to thetype hierarchy: every object is of exactly one min-imal (most specific) type.
This implies that everyobject in the denotation of a non-minimal type isalso described by at least one of its subtypes.
Ourcompilation procedure will adhere to this interpre-tation.2.2 The theories of HPSGI I :  Directlyconstraining the domainA HPSGII theory consists of a set of descriptionswhich are interpreted as being true or false of anobject in the domain.
An object is admissible withrespect o a certain theory iff it satisfies each of thedescriptions in the theory and so does each of itssubstructures.
The descriptions which make up thetheory are also called constraints, since these de-scriptions constrain the set of objects which are ad-missible with respect o the theory.Figure 1 shows an example of a constraint, thehead-feature principle of HPSGII.
Throughout thepaper we will be using HPSG style AVM notationfor descriptions.phrase - .
.
*DTRS headed-strutSYNSEM\]LOC\[CAT\[HEADDTRSIH AD DTRISYNSE I' OClC  l" 'Figure 1: The Head-Feature Principle of HPSGIIThe intended interpretation f this constraint isthatevery object which is being described by type phraseand by \[DTI~S h~aded-str~c\] alsohas to be described bythe consequent, i.e.
have its head value shared withthat of its head-daughter.In the HPSG II architecture any description can beused as antecedent of an implicative constraint.
Asshown in (Meurers, 1994), a complex description canbe expressed as a type by modifying the signatureand/or adding theory statements.
In the following,we therefore only deal with implicative constraintswith type antecedents, he type definitions.2.3 Theories in constraint logicprogramming: expressing definiteclause relationsAs mentioned in the introduction, in most computa-tional systems for the implementation f HPSG the-ories a grammar is expressed using a relational ex-tension of the description language 2 such as definiteclauses or phrase structure rules.
Figure 2 schemat-ically shows the embedding of HPSG II descriptionsin the definition of a relation.relo (D1 .
.
.
.
.
D~) : -  tell(E1,..., Ej),re/n(Fl .
.
.
.
, Fh).Figure 2: Defining relation reloThe HPSG description language is only used tospecify the arguments of the relations, in the exam-ple noted as D, E, and F. The organization of thedescriptions, i.e.
their use as constraints to narrowdown the set of described objects, is taken over bythe relational level.
This way of organizing descrip-tions in definite clauses allows efficient processingtechniques of logic programming to be used.The question we are concerned with in the follow-ing is how a HPSG II theory can be modelled in sucha setup.3 Mode l l ing  HPSGI I  theor ies  on  are la t iona l  leve l :  a s imp le  p ic tureThere are three characteristics of HPSGII theorieswhich we need to model on the relational level: oneneeds to be able to1.
express constraints on any kind of object,2.
use the hierarchical structure of the type hier-archy to organize the constraints, and3.
check any structure for consistency with thetheory.A straightforward encoding isachieved by express-ing each of these three aspects in a set of relations.Let us illustrate this idea with a simple example.
As-sume the signature given in figure 3 and the HPSGII2 For the logical foundations of relational extensions ofarbitrary constraint languages see (HShfeld and Smolka,1988).86style theory of figure 4.T /-=b cFigure 3: An example signatureo _b --.
\ [Q?IFigure 4: An example theory in a HPSGII setupFirst, we define a relation to express the con-straints immediately specified for a type on the ar-gument of the relation:?
a o,, ) :- T ,vp ,G) .?
b b :-?
c ?on , (c ) .For every type, the relation specifies its only argu-ment to bear the type information and the conse-quents of the type definition for that type.
Notethat the simple type assignment \[G a\] leads to a callto the relation atvp~ imposing all constraints for typea, which is defined below.Second, a relation is needed to capture the hier-archical organization of constraints:?
; .
.
.
.?
ah i ,~(~) : -  a,o,,,(\[~\]), ( bh, ,~(~);  chi,r(\[~) ).?
bhi,r(\]~\]):-  bco,, ,(~).Each hierarchy relation of a type references the con-straint relation and makes ure that the constraintsbelow one of the subtypes are obeyed.Finally, a relation is defined to collect all con-straints on a type:?
atyp~(~) :- This,-( ri-1 a ).?
bt,p~(E~ \]) :- Thief( \[-i~b ).
* ctvpe(\[~\]) :- Thier( r-~c ).aA disjunction of the immediate subtypes of T.Compared to the hierarchy relation of a type whichcollects all constraints on the type and its subtypes,the last kind of relation additionally references thoseconstraints which are inherited from a supertype.Thus, this is the relation that needs to be queried tocheck for grammaticality.Even though the simple picture with its tripartitedefinition for each type yields perspicuous code, itfalls short in several respects.
The last two kindsof relations (reltype and relhier) just perform inheri-tance of constraints.
Doing this at run-time is slow,and additionally there are problems with multipleinheritance.A further problem of the encoding is that the valueof an appropriate feature which is not mentionedin any type definition may nonetheless be implicitlyconstrained, since the type of its value is constrained.Consider for example the standard HPSG encodingof list structures.
This usually involves a type he_listwith appropriate f atures HD and TL, where underHD we encode an element of the list, and under TLthe tail of the list.
Normally, there will be no extraconstraints on ne_list.
But in our setup we clearlyneed a definite clausehe_listne_listcon,( HD ) :- Ttvp~(\[~), listtyp?
(~\])..TLsince the value of the feature HD may be of a typewhich is constrained by the grammar.
Consequently,since he_list is a subtype of list, the value of TL needsto be constrained as well.4 Compi l ing  HPSG type  const ra in tsin to  de f in i te  c lausesAfter this intuitive introduction to the problem, wewill now show how to automatically generate definiteclause programs from a set of type definitions, ina way that avoids the problems mentioned for thesimple picture.4.1 The a lgor i thmBefore we can look at the actual compilation proce-dure, we need some terminology.Definit ion (type interaction)Two types interact if they have a common subtype.Note that every type interacts with itself.Definit ion (defined type)A defined type is a type that occurs as antecedent ofan implicational constraint in the grammar.Definit ion (constrained type)A constrained type is a type that interacts with adefined type.87Whenever we encounter a structure of a constrainedtype, we need to check that the structure conformsto the constraint on that type.
As mentioned insection 2.1, due to the closed world interpretation oftype hierarchies, we know that every object in thedenotation of a non-minimal type t also has to obeythe constraints on one of the minimal subtypes of t.Thus, if a type t has a subtype t' in common witha defined type d, then t ~ is a constrained type (byvirtue of being a subtype of d) and t is a constrainedtype (because it subsumes t').Def in i t ion  (hiding type)The set of hiding types is the smallest set s.t.
if t isnot  a constrained type and subsumes a type to thathas a feature f appropriate s.t.
approp(to,f) is a con-strained type or a hiding type, then t is a hiding type.The type ne_list that we saw above is a hiding type.Def in i t ion  (hiding feature)I f  t is a constrained or hiding type, then f is a hidingfeature on t iff approp(t,f) is a constrained or hidingtype.Def in i t ion  (simple type)A simple type is a type that is neither a constrainednor  a hiding type.When we see a structure of a simple type, we don'tneed to apply any constraints, neither on the topnode nor on any substructure.Partitioning the types in this manner helps usto construct definite clause programs for type con-straint grammars.
For each type, we compute aunary relation that we just give the same name asthe type.
Since we assume a closed world interpre-tation of the type hierarchy, we really only need tocompute proper definitions for minimal types.
Thebody of a definition for a non-minimal type is justa disjunction of the relations defining the minimalsubtypes of the non-minimal type.When we want to compute the defining clause fora minimal type, we first of all check what sort oftype it is.
For each simple type, we just introducea unit clause whose argument is just the type.
Fora constrained type t, first of all we have to performconstraint inheritance from all types that subsume t.Then we transform that constraint to some internalrepresentation, usually a feature structure (FS).
Wenow have a schematic defining clause of the formt(FS) :- ?.Next, we compute the missing right-hand side(RHS) with the following algorithm.1.
Compute HF, the set of hiding features on thetype of the current node, then insert these fea-tures with appropriate types in the structureP':<.
}/ARG2 list I e_list /HD T //ARG3 iist~ I.TL ,i,tJLGOALS list.\](FS) if they're not already there.
For each nodeunder a feature in HF, apply step 2.2.
Let t be the type on the current node and X itstag (a variable).
(a) If t is a constrained type, enter t(X) intoRHS (if it's not already there).
(b) Elseif t is a hiding type, then check if itshiding features and the hiding features ofall its hiding subtypes are identical.
If theyare identical, then proceed as in step 1.
Ifnot, enter t(X) into RHS.
(c) Else (t is a simple type) do nothing at all.For hiding types, we do exactly the same thing, ex-cept that we don't have any structure to begin with.But this is no problem, since the hiding features getintroduced anyway.4.2 An  exampleA formal proof of correctness of this compiler is givenin (GStz, 1995) - here, we will try to show by ex-ample how it works.
Our example is an encodin~of a definite relation in a type constraint setup2append_c appends an arbitrary list onto a list of con-stants.TconstantFigure 5: The signature for the append_c exampleWe will stick to an AVM style notation for our ex-amples, the actual program uses a standard featureterm syntax.
List are abbreviated in the standardHPSG manner, using angled brackets.append_c -*\[A O1ARG 2ARG3GOALS e_listJ"ARG 1ARG2ARG3VGOALS15q oo.,,..,i 5q ?\[\]IE\]I\[EIARG 1 \[~\]ARG2ARG3Figure 6: A constraint on append_cNote that the set of constrained types is {append_c,4This sort of encoding was pioneered by (Ait-Kaci,1984), but see also (King, 1989) and (Carpenter, 1992).88T} and the set of hiding types is {list, ne_list}.
Con-verting the first disjunct of append_c into a featurestructure to start our compilation, we get somethinglike'append_c I ARG1 v--a\[\]e-list\]append_c( ARG2 121 listARG3.GOALS e_list.I: - ?
.Since the values of the features of append_c are oftype list, a hiding type, those features are hidingfeatures and need to be considered.
Yet looking atnode \[-i7, the algorithm finds e_list, a simple type,and does nothing.
Similarly with node \[~\].
On node~\] ,  we find the hiding type list.
Its one hiding sub-type, ne_list, has different hiding features (list has nofeatures appropriate at all).
Therefore, we have toenter this node into the RHS.
Since the same nodeappears under both ARG1 and ARG2, we're doneand have\[ 1 append_c ARG1 e_listappend_c( I ARG3ARG2 ~__lisq):-\]Jst(~).LGOALS e_list jwhich is exactly what we want.
It means that astructure of type append_c is well-formed if it unifieswith the argument of the head of the above clauseand whatever is under ARG2 (and AR.G3) is a well-formed list.
Now for the recursive disjunct, we startout withappend_el"append_crne_listARGI E\] l \ [ \ ]  constant\ [ \ ]  .stARG2 \[~\] listrne-list t\]he.list -append_c \]GOALS\[\] HD ~\] ARG2 L.~J|\[\] 4,: mJ: - ?
.Node E \ ]  bears a hiding type with no subtypes.Therefore we don't enter that node in the RHS, butproceed to look at its features.
Node \ [ \ ]  bears a sim-ple type and we do nothing, but node \ [ \ ]  is again alist and needs to be entered into the RHS.
Similarlywith nodes \ [ \ ]  and \['~.
append_c on node \ [ \ ]  is a con-strained type and \ [ \ ]  also has to go onto the RHS.The final result then isappend_c("append_cme-list constant\]ARG2 \[~\] listme-list t\]rne_list/ rapP:-d_c "1/ IARG1 r31 |._l ist(~), list(\[~\]), list(\[~\]), append_c(~\]).This is almost what we want, but not quite.
Con-sider node ~\] .
Clearly it needs to be checked, butwhat about nodes ~\] ,  \ [ \ ]  and E\]?
They are all em-bedded under node \ [ \ ]  which is being checked any-way, so listing them here in the RHS is entirely re-dundant.
In general, if a node is listed in the RHS,then no other node below it needs to be there aswell.
Thus, our result should really beappend_c("append_crne-list constant\]ARG2 r~1 listme-list t\]rne-listI r append-e 1IHD GOALS I I| LAFtG3 16~JLTL e_list:_appendoc(\[~\]).Our implementation f the compiler does in factperform this pruning as an integrated part of thecompilation, not as an additional step.It should be pointed out that this compilation re-sult is quite a dramatic improvement on more naiveon-line approaches to ttPSG processing.
By reason-ing with the different kinds of types, we can dras-tically reduce the number of goals that need to bechecked on-line.
Another way of viewing this wouldbe to see the actual compilation step as being muchsimpler (just check every possible feature) and tosubsequently apply program transformation tech-niques (some sophisticated form of partial evalua-tion).
We believe that this view would not simplifythe overall picture, however.894.3 Implementat ion  a d ExtensionsThe compiler as described in the last section hasbeen fully implemented under Quintus Prolog.
Ourinterpreter at the moment is a simple left to rightbacktracking interpreter.
The only extension is tokeep a list of all the nodes that have already beenvisited to keep the same computation from beingrepeated.
This is necessary since although we avoidredundancies a shown in the last example, there arestill cases where the same node gets checked morethan once.This simple extension also allows us to processcyclic queries.
The following query is allowed by oursystem.me_list ~\]Query> \[~\] [THDFigure 7: A permitted cyclic queryAn interpreter without the above-mentioned exten-sion would not terminate on this query.The computationally oriented reader will nowwonder how we expect o deal with non-terminationanyway.
At the moment, we allow the user to specifyminimal control information.?
The user can specify an ordering on type expan-sion.
E.g., if the type hierarchy contains a typesign with subtypes word and phrase, the usermay specify that word should always be triedbefore phrase.?
The user can specify an ordering on feature x-pansion.
E.g., HD should always be expandedbefore TL in a given structure.Since this information is local to any given structure,the interpreter does not need to know about it, andthe control information is interpreted as compilerdirectives.5 Conc lus ion  and  Out lookWe have presented a compiler that can encodeHPSG type definitions as a definite clause program.This for the first time offers the possibility to ex-press linguistic theories the way they are formulatedby linguists in a number of already existing compu-tational systems.The compiler finds out exactly which nodes of astructure have to be examined and which don't.
Indoing this off-line, we minimize the need for on-lineinferences.
The same is true for the control informa-tion, which is also dealt with off-line.
This is not tosay that the interpreter wouldn't profit by a moresophisticated selection function or tabulation tech-niques (see, e.g., (DSrre, 1993)).
We plan to applyEarley deduction to our scheme in the near futureand experiment with program transformation tech-niques and bottom-up interpretation.Our work addresses a similar problem as Carpen-ter's work on resolved feature structures (Carpen-ter, 1992, ch.
15).
However, there are two majordifferences, both deriving form the fact that Car-penter uses an open world interpretation.
Firstly,our approach can be extended to handle arbitrar-ily complex antecedents of implications (i.e., arbi-trary negation), which is not possible using an openworld approach.
Secondly, solutions in our approachhave the so-called subsumption monotonicity or per-sistence property.
That means that any structuresubsumed by a solution is also a solution (as in Pro-log, for example).
Quite the opposite is the case inCarpenter's approach, where solutions are not guar-anteed to have more specific extensions.
This is un-satisfactory at least from an HPSG point of view,since HPSG feature structures are supposed to bemaximally specific.AcknowledgmentsThe research reported here was carried out in thecontext of SFB 340, project B4, funded by theDeutsche Forschungsgemeinschaft.
We would like tothank Dale Gerdemann, Paul John King and twoanonymous referees for helpful discussion and com-ments.ReferencesHassan Ait-Kaci.
1984.
A lattice theoretic approachto computation based on a calculus of partially or-dered type structures.
Ph.D. thesis, University ofPennsylvania.Bob Carpenter.
1992.
The logic of typed features~ructures, volume 32 of Cambridge Tracts in The-oretical Computer Science.
Cambridge UniversityPress.Bob Carpenter.
1993.
ALE - the attributelogic engine, user's guide, May.
Laboratory forComputational Linguistics, Philosophy Depart-ment, Carnegie Mellon University, Pittsburgh, PA15213.Jochen DSrre and Michael Dorna.
1993.
CUF -a formalism for linguistic knowledge representa-tion.
In Jochen DSrre, editor, Computational as-pects of constraint based linguistic descriptions I,pages 1-22.
DYANA-2 Deliverable R1.2.A, Uni-versit~t Stuttgart, August.Jochen DSrre.
1993.
Generalizing earley deductionfor constraint-based grammars.
In Jochen DSrre,editor, Computational aspects of constraint basedlinguistic descriptions I, pages 25-41.
DYANA-2 Deliverable R1.2.A, Universit~t Stuttgart, Au-gust.Martin C. Emele and R~mi Zajac.
1990.
Typedunification grammars.
In Proceedings of the 13 'h90International Conference on Computational Lin-guistics.Dale Gerdemann and Paul John King.
1993.Typed feature structures for expressing and com-putationally implementing feature cooccurrencerestrictions.
In Proceedings of 4.
Fachtagungder Sektion Computerlinguistik der DeutschenGesellschafl ffr Sprachwissenschaft, pages 33-39.Thilo GStz.
1995.
Compiling HPSG constraintgrammars into logic programs.
In Proceedings ofthe joint ELSNET/COMPULOG-NET/EAGLESworkshop on computational logic for natural lan-guage processing.M.
HShfeld and Gert Smolka.
1988.
Definite rela-tions over constraint languages.
LILOG technicalreport, number 53, IBM Deutschland GmbH.Paul John King.
1989.
A logical formalism for head.driven phrase structure grammar.
Ph.D. thesis,University of Manchester.W.
Detmar Meurers.
1994.
On implementingan HPSG theory - Aspects of the logical archi-tecture, the formalization, and the implementa-tion of head-driven phrase structure grammars.In: Erhard W. Hinrichs, W. Detmar Meurers,and Tsuneko Nakazawa: Partial- VP and Split-NPTopicalization in German - An HPSG Analysisand its Implementation.
Arbeitspapiere des SFB340 Nr.
58, Universit?t Tfibingen.Carl Pollard and Ivan A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
Chicago: Universityof Chicago Press and Stanford: CSLI Publica-tions.Append ix  A.
A small grammarThe following small example grammar, togetherwith a definition of an append type, generates sen-tences like "John thinks cats run".
It is a modifiedversion of an example from (Carpenter, 1992).phrase --,A"CAT sDTRI IAGRLPHONI AGR, LPHO NA RG IGOALS ( I ARG2\[ARG3"CAT vpAGR \ [~r?ATV DTRI IAGRLPHONT.DTR2 \[PHON\]word ---}VVVV"CATPHONAGRICAT:PHONAGRrCAT~PHONAGR'CATPHON~GR'CATPHONAGRp \] ( john V raary }singular( cats V dogs )pluralup( runs V jumps  ) singular( run v jump )plural"" \]( knows v thinks )singularHere's an example query.
Note that the featureGOALS has been suppressed in the result.Query> \[PHON { john, runs )\]Result>"phraseCATPHONDTR1DTR2\ [~ j ob .
I ~ \ ]  ( ru .s  ) )"word t CAT npAGR {~ingularPHON )"wordAGRPHONFor the next query we get exactly the same result.query> \[DTR2 \[FHON { runs91
