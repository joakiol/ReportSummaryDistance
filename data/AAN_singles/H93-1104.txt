Information Retrieval from Large TextbasesK.L.
KwokComputer Science DepartmentQueens College, City University of  New YorkFlushing, NY 11367PROJECT GOALSOur objective is to enhance the effectiveness ofretrieval and routing operations for large scaletextbases.
Retrieval concerns the processing of adhoc queries against astatic document collection, whilemuting concerns the processing of static, trainedqueries against a document stream.
Both may beviewed as trying to rank relevant answer documentshigh in the output.
Our text processing and retrievalsystem PIRCS is based on the probabilistic model andextended with the concept of document components.Components are regarded as single content-bearingterms as an approximation.
Considering documentsand queries as constituted of conceptual componentsallows one to define initial term weights naturally, tomake use of nonbinary term weights, and to facilitatedifferent ypes of retrieval processes.
The approachis automatic, based mainly on statistical techniques,and is generally language and domain independent.Our focus is on three areas: 1) improvements ondocument representation; 2) combination of retrievalalgorithms; and 3) network implementation withlearning capabilities.
Using representation with morerestricted contexts uch as phrases or sub-documentunits help to decrease ambiguity.
Combiningevidences from different reuieval algorithms is knownto improve results.
Viewing retrieval in a networkhelps to implement query-focused and document-focused retrieval and feedback, as well as queryexpansion.
It also provides aplatform for using otherlearning techniques uch as those from artificialneural networks.RECENT RESULTSDuring 1992, we participated in TREC1 and experi-mented with the 0.5 GByte Wall Street Journalcollection of the Tipster program.
Our results basedon precision-recall evaluation compared veryfavorably with other participants in both ad hocretrieval and routing environments.
Our experi-mental results support the general conclusion thattechniques which work for small collections also workin this large scale environment.
Specifically:?
Breaking documents with unrelated stories, or longdocuments into more uniform length sub-documentsat paragraph boundaries, together with InverseCollection Term Frequency weighting to account forthe discrimination power of content terms, is a viableinitial term weighting strategy.
It is also useful toaugment single terms with two-word phrases forrepresentation.?
PIRCS's combination of query-focused anddocument-focused r lrieval works well.
Combiningthem with a soft-boolean retrieval strategy producesadditional gains.
Our boolean expressions for queriesare manually formed.?
Known relevant documents used for feedbacklearning in our network lead to improvementscompared with no feedback.
More performanceincreases are obtained by expanding queries withterms from the relevant feedback documents.PLANS FOR THE COMING YEARWe will enhance our system in both hardware andsoftware in order to handle the two GByte multi-source textbase.
We need to segment our network tofit available memory.
In document representation, wewill test a more powerful initial term weightingmethod based on document serf-learning.
We willgenerate two-word phrases automatically using wordadjacency information captured during textprocessing.
We plan to obtain boolean expressionsfrom the well-slructured query 'topics' automatically.Because more relevant documents are known, we willexperiment with various learning schedules anddifferent learning samples.410
