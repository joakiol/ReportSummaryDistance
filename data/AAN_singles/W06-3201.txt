Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, pages 1?10,New York City, USA, June 2006. c?2006 Association for Computational LinguisticsA Combined Phonetic-Phonological Approach to Estimating Cross-Language Phoneme Similarity in an ASR EnvironmentLynette Melnarlynette.melnar@motorola.comChen Liuchen.liu@motorola.comAbstractThis paper presents a fully automated lin-guistic approach to measuring distancebetween phonemes across languages.
Inthis approach, a phoneme is representedby a feature matrix where feature catego-ries are fixed, hierarchically related andbinary-valued; feature categorization ex-plicitly addresses allophonic variation andfeature values are weighted based on theirrelative prominence derived from lexicalfrequency measurements.
The relativeweight of feature values is factored intophonetic distance calculation.
Two pho-nological distances are statistically de-rived from lexical frequencymeasurements.
The phonetic distance iscombined with the phonological distancesto produce a single metric that quantifiescross-language phoneme distance.The performances of target-languagephoneme HMMs constructed solely withsource language HMMs, first selected bythe combined phonetic and phonologicalmetric and then by a data-driven, acous-tics distance-based method, are comparedin context-independent automatic speechrecognition (ASR) experiments.
Resultsshow that this approach consistently per-forms equivalently to the acoustics-basedapproach, confirming its effectiveness inestimating cross-language similarity be-tween phonemes in an ASR environment.1 IntroductionSpeech technologists typically use acoustic meas-urements to determine similarity among acousticspeech models (phone(me) HMMs) and there are avariety of distance metrics available that prove theeffectiveness of this method (see Sooful and Botha2002).
Additionally, HMM similarity can beevaluated indirectly through comparison of HMMperformances in ASR experiments.For acoustic measurements, speech data mustbe accessible for model training.
However, speechdata unavailability is a practical concern in thatmost commercially available speech databases arerestricted to widely spoken languages in largebusiness markets.
The vast majority of languageshave not been exposed to intense data collectionand resources for these languages are subsequentlyeither limited or completely unavailable.
Hence aknowledge-based phoneme distance metric poten-tially has great value in acoustic modeling for re-source-limited languages in that it can predictcross-language HMM similarity in the absence oftarget-language speech data.Knowledge-based approaches to HMM similar-ity generally attempt to identify articulatory simi-larity between phonemes across languages.
Thetypical strategy is subjective and label-based,where two phonemes are judged to be more or lesssimilar depending on their transcription labels(K?hler 1996; Schultz and Waibel 1997, 2000).A label-based approach suffers for two obviousreasons.
First, phone inventories designed forspeech technology applications are predominantlyphonemic in orientation.
Thus, transcription labelsdo not transfer with the same phonetic value toother languages, even where international phonetictranscription labels are employed.
In a phonemictranscription strategy, transcription labels are gen-1erally restricted to only the most basic symbols,usually unmodified letters of the Roman alphabet(IPA 1999).
Second, phoneme transcription labelsfail to capture allophony.
The best phonetic defini-tion that a phoneme transcription label can offer isthe most typical phonetic realization of that pho-neme.
Not surprisingly, label-based cross-languagetransfer experiments have produced poor perform-ance results.In contrast to the subjective, label-based strat-egy, researchers in such fields as language recon-struction, dialectometry, and child languagedevelopment, commonly use automatic feature-based approaches to articulatory similarity betweenphonemes.
In these methods, phonemes are repre-sented by a distinctive feature vector and a pho-netic distance or similarity algorithm is used toalign phoneme strings between related words(Connolly 1997; Kessler 1995, 2005; Kondrak2002; Nerbonne and Heeringa 1997; Somers1998).
Significantly, in these approaches, phono-logical similarity is generally assumed.In principle, the feature-based approach to pho-netic distance admits more precise specification ofphonemes because it supports allophonic variance.For example, a standard feature-based approach toallophony representation restricts feature inclusionto only those features relevant to all realizations ofthe phoneme.
Another common approach retainsfeatures that are relevant to all allophonic variants,but leaves their values underspecified (Archangeli1988).
However, it is unclear from the literaturewhether allophony is explicitly addressed in thecurrent feature-based approaches to phoneme simi-larity.A strategy for specifying allophony and charac-terizing phonetic distance between phonemes isonly one component in predicting phoneme simi-larity among diverse languages without acousticdata in an ASR environment.
Because HMMs rep-resent phonemes and significant allophones in alanguage-dependent context, it is necessary to con-sider the overall constructed target-language HMMsystem.
Thus phonological distance quantities thatregulate the priority of source languages for pho-neme selection in accordance to their phonologicalsimilarity to the target language are also in order.In this paper, we describe an automated, com-bined phonetic-phonological (CPP) approach toestimating phoneme similarity across languages inASR.
Elsewhere, we provide the phonetic andphonological distance algorithms (Liu and Melnar2005, 2006), though offer little linguistic justifica-tion of the approach or evaluation of the experi-ment results due to space limitations.
Here, wefocus on explaining the linguistic principles behindthe algorithms and analyzing the results.The CPP approach is fundamentally based onarticulatory phonetic features and is designed tohandle allophonic variation.
Feature salience andphonetic distance are automatically calculated andphoneme distance is constrained by statistically-derived phonological similarity biases.
Unlikeother distinctive feature-based approaches to pho-neme similarity, phonological distance is not as-sumed.
In testing this approach in cross-languagetransfer experiments, target-language resources arerestricted to lexica and phonology descriptions anddo not include speech data.In the next section, we describe our feature-based phoneme specification method.
In sectionthree, we show how our phoneme specificationapproach is used in calculating phonetic distancebetween phonemes.
Section four describes twoother distance metrics that predict phonologicalsimilarity between languages.
We explain how thethree distance metrics combine to quantify cross-language phoneme distance and select target-language phoneme HMM inventories.
In sectionfive, we describe the experiments that we con-ducted to evaluate our approach to phoneme simi-larity prediction.
Here, the CPP method iscompared with an acoustic distance method in con-text-independent speech recognition.
We offer ourevaluation and conclusions in section 6.2 Phoneme specificationIn the CPP approach to estimating cross-languagephoneme similarity, each phoneme in our multilin-gual ASR dataset is associated with a distinctivefeature matrix.
Feature categories are fixed for allphonemes, hierarchically related, and binary-valued.
Feature-contradiction, associated with al-lophonic variance, is explicitly addressed throughthe introduction of a small set of special corollaryfeatures.2.1 The phoneme feature matrixAs noted in the introduction, cross-language pho-neme comparison requires accurate feature specifi-cation.
Because a phoneme comprises one or more2allophones which may contrast in particular fea-tures, a distinctive feature strategy that allows forfeature contradiction is preferred.
Omitting contra-dictory features and underspecifying contradictoryvalues are two well-known methods.However, cross-language phoneme comparisonin a computational environment is greatly facili-tated by agreeing on a fixed set of binary-valuedfeatures for all phonemes.
A fixed set of distinctivefeatures is favored as this enables cross-class pho-neme comparison.
A binary-valued system is easyto manipulate and naturally lends itself to mathe-matical formulation.
However, strict binary-valuedfeature systems only indicate the presence or ab-sence of a feature, and feature contradiction mustthen be indicated by feature omission - which isnot possible in a fixed distinctive feature set.The phoneme specification method that we em-ploy indicates feature contradiction associated withallophony in a strict binary-valued, fixed set ofdistinctive features through the introduction ofspecial feature categories.
Specifically, we utilize asmall set of corollary features to mark the occa-sional, allophonic realizations of some primaryfeatures.
A corollary feature is defined as a featurethat supplements a primary feature in the system.The corollary features mark ?occasionality?
(asso-ciated with context dependency, dialectal variation,speech style variation, etc.)
in the primary featureas either present or absent.2.2 Primary and corollary featuresOur feature set includes twenty-six primary articu-latory features and six corollary features.
The se-lected primary features conform to a typical set ofhierarchically-related distinctive features (e.g.
syl-labic, sonorant, consonantal, labial, coronal, nasal,continuant, high, low, back, etc.)
(Ladefoged1975).
In this hierarchical system, the presence ofone feature presupposes the presence of those hier-archically dominant features.
For example, thepresence of the feature [alveolar] requires the pres-ence of the feature [coronal], and the presence ofthe feature [nasal] requires the presence of the fea-ture [sonorant].
Significantly, the reverse of theserelations is not true.
As is explained later in thenext section, this feature structure allows for a lin-guistically-principled determination of feature sali-ence in phonetic distance calculation.Corollary features are restricted to specifyingthose primary features that are judged to be mostsignificant to cross-language phoneme comparisonin an ASR environment.
Phoneme inventories de-signed for ASR comprise both phonemes and sig-nificant allophones, where a significant allophoneis characteristically both acoustically distinct fromthe primary allophone and associated with a suffi-ciently high count of occurrence in the associatedspeech database.
Thus American English ASRinventories regularly include an alveolar tap, a con-textually-realized allophonic variant of both /t/ and/d/.
Furthermore, pronunciation transcriptions inASR lexica are typically phonetic - within the con-text of the phoneme-based inventory.
So, word-final voice neutralization in German is overtly in-dicated throughout the lexicon (e.g.
hund : h U n t).A typical ASR phoneme then does not represent atrue phoneme; rather it encompasses only thatphonemic variation that is not explicitly capturedby its existing significant allophones in the inven-tory.Corollary features specify variance that is notusually overtly indicated in ASR inventories andlexica but that is important to cross-language pho-neme comparison in an acoustic, ASR environ-ment.
Internal phoneme recognition experimentsindicate that generally major class features (syl-labic, sonorant, etc.
), manner features (nasal, con-tinuant, etc.)
and laryngeal features (voice, spreadglottis, etc.)
are more robustly identified than placefeatures (labial, coronal, etc.
); accordingly, the setof corollary features, provided in Table 1, pre-dominantly targets particular major class, manner,and laryngeal features.Table 1: Corollary featuresCorollaryFeatureDescriptionsyllabic-occ positive value marks the occasionalrealization of the phoneme as a syl-labic consonant or glidevoice-occ positive value marks the occasionalvoicing of phonemeslabial-occ positive value marks the occasionalrounding of vowelsnasal-occ positive value marks the occasionalnasalization of vowels and glidesrhotic-occ positive value marks the occasionalrhotization of liquids and vowelsspread-occ positive value marks the occasionalaspiration of obstruentsIt should be pointed out that allophones that ex-press a place contrast or difference in continuance3with the primary realization of a phoneme are typi-cally considered significant allophones in the ASRphoneme system and are therefore overtly repre-sented.As an illustration of the usefulness of corollaryfeatures in cross-language phoneme comparison,consider Table 2 which includes a partial featurematrix for the phoneme /k/ associated with 17 lan-guages and dialects:Table 2: Partial distinctive feature tableLanguages phoneme spreadglottisspread-occArabic k 0 0Danish k 1 1German k 1 1British English k 1 1U.S.
English k 1 1Lat.
Spanish k 0 0Can.
French k 0 0Parisian French k 0 0Italian k 0 0Japanese k 1 1Dutch k 0 0Brz.
Portuguese k 0 0Eur.
Portuguese k 0 0Swedish k 1 1Korean k 1 0Cantonese k 1 0Mandarin k 1 0Note that the realization of the phoneme /k/ differsacross the seventeen languages and dialects in thetwo features provided: [spread glottis] and [spread-occ].
The presence of the feature [spread glottis],marked by 1, and the non-presence of the corollaryfeature [spread-occ], marked by 0, indicates thatthe glottis is always open during the articulation ofthe phoneme; i.e.
this phoneme is consistently as-sociated with aspiration.
The precise IPA transcrip-tion of this segment is /kh/.
A positive value for thecorollary feature [spread-occ] means that the pho-neme is only sometimes associated with aspiration.This phoneme has two principle phonetic realiza-tions, marked [k] and [kh] in IPA notation.
A 0value for the feature [spread glottis] and corollaryfeature [spread-occ] indicates that the segment isnever aspirated.
Thus this phoneme is most accu-rately labeled /k/ in IPA labeling.Because this methodology incorporates pho-neme feature contradiction, overall phonologicalsimilarity among languages and dialects is moreprecisely predicted:Table 3: Phoneme similarity across languagesphoneme allophone(s) language lang.
familyDanish GermanicGerman GermanicBr.
Eng.
GermanicAmer.
Eng.
GermanicJapanese Altaickh, kSwedish GermanicKorean AltaicMandarin Sinitic khCantonese SiniticArabic Afro-AsiaticLat.
Span.
RomanceParisian Fr.
RomanceCanadian Fr.
RomanceItalian RomanceDutch GermanicBrz.
Port.
RomancekkEur.
Port.
RomanceTable 3 reveals that Germanic languages tend toonly occasionally aspirate /k/, Romance languagesavoid aspirating /k/, and Sinitic languages typicallyaspirate /k/.
Of course, closely related languagestend to be phonologically similar.3 Phonetic distanceMost techniques for measuring phonetic distancebetween phonemes that do not assume speech dataavailability are based on articulatory features,though perceptual distance, judged (subjective)distance, and historical distance are also attested(Kessler 2005).
We base our phonetic distancemeasurement on articulatory features because oftheir cross-linguistic consistency and generalavailability.As Kessler notes, standard phonological theoryprovides no guidance in comparing phonetic dis-tance between phonemes across multiple features(Kessler 2005).
In our experiments to date, we usethe Manhattan distance where the distance betweenphonemes equals the sum of the absolute values ofindividual feature distances.
This approach is fairlystandard in the literature, though the Euclideandistance has also been reported to attain good re-sults (Kessler 2005).Because features are known to differ in relativeimportance (Ladefoged 1969), some researchersapply weights or saliencies to the individual fea-tures for distance calculation.
Nerbonne and Heer-inga (1997), for example, weighted each feature byinformation gain, or entropy reduction.
Kondrak(2002) expressed weights as coefficients that could4be changed to any numeric value.
He adjusted thecoefficients until he achieved optimal performanceon aligning cognate words.In our approach, weights are derived from thelexica of all the considered languages.
Specifically,the value of a weight for a feature is derived fromthe frequency of the feature in the lexica.
Each lan-guage is treated equally in this approach; thus, theweights are not subject to the relative size of a lan-guage?s lexicon.Because our phoneme specification method in-corporates hierarchical relations between features,feature weights are necessarily interdependent.Hierarchically dominant features are more fre-quently attested than their subordinate features andthus receive more weight.
Further, hierarchicallysuperior features tend to correspond to major pho-netic categories (sonorant, consonantal, syllabic,etc.
), which are expected to be more contrastive ordistant to each other than sister subordinate catego-ries.
Thus, in a hierarchical feature system, lexicalfrequency of features is a reasonable indication offeature importance in phonetic contrast or distance.In the following two subsections the phoneticdistance algorithm is described.Quantitative representation of phonemesA phoneme is denoted by )(ipl , where l (=1,?,L)represents the language that includes the phoneme,and i (=1,?,Il) represents the index of the pho-neme in language l. Thus, the phoneme inventoryof language l is(1) },,1|)({ ll Iiip K= .A phoneme )(ipl  is represented by a vector of Jfeatures(2)      TlllTll Jivjivivjivip )],(,),,(,),1,([)],([)]([ KK==fwhere each ),( jivl  is a binary feature, lIi ,,1L= ,Jj ,,1L= , Ll ,,1L= , and the superscript T denotesvector transposition.Weighted phonetic distanceAs mentioned, the value of a weight for a featurein the present phonetic distance approach is de-rived from the frequency of the feature in thelexica of all the considered languages.
Let )]([ ipc lldenote the occurrence count of a phoneme )(ipl  ina lexicon of language l, then the frequency of eachfeature j contributed by the phoneme )(ipl  is),()]([ jivipc lll , and the frequency of each feature jcontributed by all the phonemes in language l is?=lIi lll jivipc1 ),()]([ .
The global weights derived fromall the phonemes in all the languages are(3) )}(,),(,),1({)( Jwjwwdiagj LL=Wwhere(4)????
?== =====LlJjIilllIilllLlllljivipcjivipcLjwLjw11 111 ),()]([),()]([1)(1)(  Jj ,,1L=where diag(vector) gives a diagonal matrix withelements of the vector as the diagonal entries.
Wedefine the phonetic distance between phonemes)(ipl  and )(kpt  in the form of a Manhattan dis-tance, which is expressed as(5)?=?=?=Jjtltllt jkvjivjwkpipjkid11),(),()()])([)]([)((),( ffWwhere lIi ,,1L= , tIk ,,1L= , and the weights, givenin a diagonal matrix )( jW , are dependent upon thefeature identity j.4 Phonological distance metricsAlthough our phoneme specification approach isdesigned to account for allophonic variance, not allvariation is captured.
Because of this, the effec-tiveness of measuring phonetic distance as a stand-alone strategy to predicting cross-language pho-neme similarity is compromised.
Furthermore,phonetic distance does not determine relative pho-neme similarity in the not atypical scenario wheretwo or more phonemes share the same phoneticdistance to some target phoneme.
In order to ad-dress these problems, phonological distance met-rics are used to bias cross-language phonemesimilarity predictions toward languages that havesimilar phoneme inventories and phoneme fre-quency distributions.
The general idea is that themore similar the phoneme inventory and relativeimportance of each corresponding phoneme be-tween languages, the more likely it is that the cor-responding phonemes will be more similar.Phonological distance consideration is espe-cially desirable in an ASR environment becauseultimately HMMs corresponding to those source-language phonemes predicted to be most similar to5target-language phonemes must interact in a sys-tem that is intended to reflect a single target lan-guage.
Use of phonological metrics then ensuresthat the overall model pool will have a bias towarda reduced set of phonologically similar languages,and it is reasonable to expect that similarity in lan-guages of the model pool provides consistency inthe target HMM system (see Schultz and Waibel2000).In this section, we define two distance metricsto characterize cross-language phonological simi-larity.
One is based on monophoneme inventorieswhile the other is based on biphoneme inventories.4.1 Monophoneme distribution distanceMonophoneme distribution distance characterizesthe difference in lexical phoneme distribution be-tween two languages.
Specifically, the distribution,or normalized histogram, of the phonemes is ob-tained from a large lexicon of a language, with theprobability in the distribution corresponding to thefrequency of a phoneme in the lexicon.
We derivethe distribution from a lexicon as we consider itmore representative of a language?s phonologythan a particular database.The monophoneme distribution metric is a ty-pological comparison that is based on two princi-pal classes of information: (1) types of sounds and(2) frequencies of these sounds in the lexicon.
Theformer class is directly associated with phonemeinventory correspondence while the latter concernsrelative phoneme importance.Because the phoneme inventories of the twolanguages to be compared may not be identical, wefirst need to define a combined inventory for them(6)},,1|)({},,1|)({},,1|)({ ttllltlt IkkpIiipImmp KKK =?===where )(mplt  is a phoneme in the combined inven-tory where there are total ltI  phonemes.The frequency of the phoneme )(mplt  in lan-guage l can be expressed as(7)?==lIillltlltlipcmpcmp1)]([)]([)]([?
, ltIm ,,1L=where )]([ mpc ltl  is the occurrence count of pho-neme )(mplt  in a lexicon of language l. If a pho-neme )(mplt  does not exist in the language, itsfrequency would be zero.
The difference of pho-neme frequencies between the two languages canbe calculated as(8) )]([)]([)]([ mpmpmpd lttltlltlt ???
?=    ltIm ,,1L=Then the monophoneme distribution distancebetween the target language t and source languagel is(9) ?==ltImltltlt mpdD1)]([??
.The distance is calculated between the target lan-guage and every one of the source languages.In view of the known differences in phonologi-cal characteristics between vowels and consonants,we make separate calculations for the vowel andconsonant categories.
Thus Eq.
(9) becomes(10) ??=gmpltltgltltmpdD)()]([?
?where g=Vowels or Consonants.4.2 Biphoneme distribution distanceThe biphoneme distribution distance metric char-acterizes the difference in lexical distribution ofphoneme pairs, or biphonemes, between two lan-guages.
Similar to the monophoneme distributiondistance, the distribution of biphonemes in a lan-guage is obtained based on the frequency of bipho-nemes in a large lexicon.The biphoneme metric indicates how phonemescan combine in a language and how importantthese combinations are.
Though the phonotacticsprovided in this approach is limited to only a se-quence of two, the overall biphoneme inventoryand distribution provides important phonologicalinformation.
For example, it indicates if and towhat extent consonants can cluster.
Some lan-guages tend to disfavor consonant clustering, likethe Romance languages, while others allow forbroad clustering, like the Germanic languages.
Italso indicates if and to what extent vowels may co-occur.
Many languages require an onset consonantso vowels will never co-occur; other languageshave no such restriction.The biphoneme metric then yields types of in-formation that are distinct from the monophonememetric.
It explicitly provides a biphoneme inven-tory, permissible phonotactic sequences, and pho-notactic sequence importance.
It also implicitlyincorporates phoneme inventory and phonologicalcomplexity information.Similar to the monophoneme distribution dis-tance, the distribution of biphonemes in a language6is obtained based on the frequency of a biphonemein a large lexicon.
The biphoneme inventory forthe target language t is expressed as(11) },,1|)({ tt Ikkq ?= Kwhile the biphoneme inventory for a source lan-guage l is(12) },,1|)({ ll Iiiq ?= KThen the combined biphoneme inventory for thetwo languages to be compared is(13)},,1|)({},,1|)({},,1|)({ ttllltlt IkkqIiiqInnq ?=?
?==?= KKKwhere )(nqlt  is a biphoneme in the combined in-ventory where there are total ltI ?
biphonemes.
For aphoneme at the beginning or end of a word, )(nqlttakes the format of ?void+phoneme?
or ?pho-neme+void?, respectively.The frequency of a biphoneme )(nqlt  in lan-guage l can be expressed as(14)??==lIillltlltliqcnqcnq1)]([)]([)]([?
, ltIn ?= ,,1Lwhere )]([ nqc ltl  is the occurrence count of bipho-neme )(nqlt  in a lexicon of language l. The differ-ence of biphoneme frequencies between the twolanguages is(15) )]([)]([)]([ nqnqnqd lttltlltlt ???
?=  ltIn ?= ,,1LThen the biphoneme distribution distance betweenthe target language t and source language l is(16) ?
?==ltInltltlt nqdD1)]([??
.Similarly, the distance is better characterizedwithin the categories of vowels and consonantsseparately.
In our algorithm we count each bipho-neme twice, the first time as a left-contact bipho-neme and second time as a right-contactbiphoneme.
Thus(17) ???
?+=gnqltltgnqltltgltltltnqdnqdD)( ofleft )( ofright)]([)]([ ??
?where g=Vowels or Consonants.4.3 CPP phoneme distanceFor phoneme similarity prediction, we unite thephonetic and phonological distance metrics to ar-rive at the CPP phoneme distance measurement.Since the three distances are from different do-mains and provide distinct types of information,normalization is necessary before combination.The normalization, aimed at extracting the relativeranking between source phonemes and languages,is a linear processing that scales the score rangefrom each domain into the range [0 1].We equate the overall importance of phoneticswith that of phonology by providing a weight of 2to the phonetic score and 1 to each of the phono-logical scores.
By doing this, a source-languagephoneme can have a greater phonetic distance tosome target-language phoneme than other source-language phonemes but a lower phonological dis-tance and receive a lower overall phoneme dis-tance score.
It is because phonological distance isconsidered as important as phonetic distance thatthe overall constructed target-language model poolwill tend to be restricted to a subset of phonologi-cally similar languages.The feature-based phoneme distance metric isdefined as(18)NgltNgltNltd DDkidkiCPP ][][)],([),( ?????
??
?+?+?=where ),( kiCPP  represents the distance betweenphoneme )(ipl  from language l and phoneme )(kptfrom language t, and both phonemes belong to thesame phonological category g (vowels or conso-nants).
The weights d?
, ??
, and ??
represent therelative importance of each quantity.
As men-tioned, ( d?
, ??
, ??
)=(2,1,1).
The symbol [?
]N de-notes that the quantity inside is linearly scaled intothe range [0 1].
For gltD?
andgltD?
, the originalrange is determined by scores of all the source lan-guages.
Their scaling is done once for a target lan-guage t. While for ),( kidlt , we found that it is betterto do scaling once for each target phoneme )(kpt ,and the original range is determined by scores of agroup of candidate phonemes that includes at leastone phoneme from any source language.5 ExperimentsTo test our CPP approach to phoneme similarityprediction, we compared it to an acoustic distanceapproach in ASR experiments.
Because native lan-guage speech data is used in measuring model dis-tance in the acoustic approach, it is expected towork better than the knowledge-based approach,which only estimates acoustic similarity indirectlythrough articulatory phonetic distance and overallphonological distance.75.1 Model constructionWe employ the regular 3-state, left-right, mul-timixture, continuous-Gaussian HMMs as theacoustic models and assume that the models fromall the source and target languages have the sametopology except that the number of mixtures in astate may vary.
Once the top source phonemes aredetermined from our feature-based phoneme dis-tance metric for each target phoneme, the targetHMM is constructed by gathering all the mixturesfor a corresponding state from the source candi-dates.
The original mean and variance values aremaintained while the mixture weights are uni-formly scaled down so that the new weights add upto one for each state.
It is possible to weigh mix-tures according to the relative importance of thecandidates if the importance as reflected by thephoneme distance metric has a significantly largedifference.
The transition probabilities are adoptedfrom the top one candidate model.5.2 CPP phoneme model constructionWe used the 17 languages and dialects provided inTable 2 in the experiments testing our CPP pho-neme distance approach to phoneme HMM simi-larity.
For each language, a native monolingualmodel set had been built by training with nativespeech data.
The acoustic features are 39 regularMFCC features including cepstral, delta, and delta-delta.
The individual ASR databases derive from avariety of projects and protocols, including, but notlimited to, CallHome, EUROM, SpeechDat, Poly-phone, and GlobalPhone.
In each of the followingexperiments, we select one language as the targetlanguage, and construct its acoustic models by us-ing all the other languages as source languages.
Aphoneme distance score is calculated for each tar-get phoneme and the top two candidate source-language phonemes are chosen for HMM modelconstruction.
We conducted experiments with Ital-ian, Latin American Spanish, European Portu-guese, Japanese, and Danish as target languages.5.3 Acoustic model constructionIn the acoustics distance approach, models are builtwith the top two models chosen from source lan-guages based on their acoustic distance from thecorresponding native target model.
For these ex-periments, we adopt the widely used Bhat-tacharyya metric for the distance measurement(Mak and Barnard 1996).
It should be noted thatthe recognition performance of the acoustics-constructed models is not a theoretically strict up-per bound for HMM similarity because the meas-urement in the acoustic space is probabilistic.5.4 ResultsEach recognition task includes about 3000 utter-ances of digit strings, command words, and sen-tences.
The word accuracy results in Table 4include the native baseline performance, i.e.
theperformance of the native monolingual, context-independent models from each target language, aswell as the acoustics-based and feature-based per-formances.
These results show that the perform-ance of models selected by the CPP phonemedistance approach is equivalent overall to that ofmodels selected by acoustic distance.Table 4: Model performanceTargetLanguageNativeBaselineAcousticDistanceCPPDistanceLat.
Spanish 94.49 88.61 93.06Italian 98.42 98.27 98.52Japanese 95.36 76.72 78.76Danish 94.36 72.95 70.15Eur.
Portuguese 96.31 77.91 72.74The performance of models selected by the CPPapproach nearly matches the performance of thenative models for Latin American Spanish andsurpasses those for Italian.
This approach performsbetter than the acoustic distance approach for LatinAmerican Spanish, Italian, and Japanese and not aswell for Danish and European Portuguese.6 Evaluation and conclusionWe suggest four principal performance factors toexplain the results provided in Table 4: (1) rarephonemes in the target-language inventory; (2)target-language inventory complexity; (3) degreeof source-language phonological distance to thetarget language; (4) reliability of source-languagemodels.
Because the CPP approach has only beentested on five languages, we consider this analysispreliminary.Regarding the first factor, rare phonemes in thetarget-language inventory, it is worth noting thatneither Latin American Spanish nor Italian hasphonemes whose exact feature specifications areunattested in phonemes from other languages in8our dataset.
For these languages, all phonemeshave exact source-language matches.
In contrast,Japanese, Danish, and European Portuguese eachcontain phonemes with feature specificationsunique to their language.
Based on this analysis,we propose that, all other factors being equal, thegreater the overall phoneme correspondence be-tween the target language and the source lan-guages, the better the target-language HMMperformance.In general, it appears that target languages as-sociated with inventories that are greater in sizethan their least phonologically distant source lan-guages perform worse than target languages asso-ciated with smaller inventories relative to theirclosest source languages.
For example, the vowelsystems of Danish, European Portuguese, andJapanese are the most complex of the five targetlanguages, with Danish having 26 vowels, Euro-pean Portuguese having 14 vowels, and Japanesehaving ten vowels.
In sharp contrast, Latin Ameri-can Spanish has only five vowels and Italian hasseven.
Both Latin American Spanish and Italianare phonologically similar to other Romance lan-guages in the dataset that have greater vowel con-trasts: Brazilian Portuguese (13 vowels), EuropeanPortuguese (14 vowels), Parisian French (17 vow-els) and Canadian French (19 vowels).
Here, wesuggest that target languages that have a similar orlesser number of phoneme contrasts compared tothe source languages are more likely to achievehigher recognition performances, all other factorsbeing equal.Relative phonological distance of the sourcelanguages to the target language and reliability ofsource language models additionally impact target-language ASR performance.
Consider Table 5where the difference in these factors for Italian andEuropean Portuguese are given.
First, Italian andEuropean Portuguese are both Romance languagesand our dataset includes a total of six, presumablyphonologically similar, Romance languages anddialects.
However, the recognition results of themodels selected by both the feature-based andacoustics-based phoneme distance method are verydifferent for the two languages.Table 5: Phonological distance and native baseline per-formance factors in target-language recognitionTarget Language Italian Eur.
PortugueseTop 3 least distantlangs.
(1) Lat.
Spanish(2) Parisian Fr.
(3) Brz.
Port.
(1) Brz.
Port.
(2) Lat.
Spanish(3) Canadian Fr.Avg.
phonolog.distance of top 3langs.0.7399 0.8945Avg.
phonolog.distance of top 1lang.0.5757 0.8248Avg.
native base-line of top 3 langs.89 91.94Native baseline oftop 1 lang.94.49 84.25If we compare the phonological distances betweenthe least distant source languages to Italian andEuropean Portuguese, we observe that Italian?sclosest languages are less distant overall thanEuropean Portuguese?s closest languages.Because the phonologically least distant sourcelanguages contribute the majority of target-language HMMs, it is reasonable to expect thatlesser phonological distance to the target languageby a greater number of source languages is likelyto result in a better target-language HMM per-formance, all other factors being equal.Finally, note the substantial discrepancy in na-tive baseline performance between the phonologi-cally least distant source languages for Italian andEuropean Portuguese.
The majority of selectedmodels for Italian derive from Latin AmericanSpanish which is associated with a high native rec-ognition baseline.
European Portuguese models,on the other hand, largely come from BrazilianPortuguese which has a much lower native base-line.
This suggests that the most reliable source-language HMMs, as judged from their native rec-ognition performance, contribute to better target-language recognition performance, all other fac-tors being equal.In future work, we intend to test our CPP pho-neme similarity approach on new target languagesand expand the preliminary evaluation providedhere.
In particular, we are interested to what extentthis method can predict recognition performancefor new target languages.9ReferencesArchangeli, D., ?Aspects of Underspecification The-ory?.
Phonology 5:183-207, 1988.Connolly, J. H., ?Quantifying target-realization differ-ences,?
Clinical Linguistics & Phonetics, 11:267?298, 1997.IPA, Handbook of the International Phonetic Associa-tion, Oxford University Press, 1999.Kessler, B., ?Computational dialectology in IrishGaelic,?
Proc.
6th Conf.
European Chapter of ACL,60?67, 1995.Kessler, B., ?Phonetic comparison algorithms,?
Trans-actions of the Philological Society, 2005K?hler J., ?Multilingual phoneme recognition exploitingacoustic-phonetic similarities of sounds,?
ICSLP?96,2195-2198, Philadelphia, 1996.Kondrak, G., Algorithms for Language Reconstruction,Ph.D.
thesis, University of Toronto, 2002.Ladefoged P., ?The measurement of phonetic similar-ity,?
Int Conf on Comp Linguistics, Stockholm, Swe-den, 1969.Ladefoged P. A Course in Phonetics.
Harcourt BraceJovanovich, New York, 1975.Liu, C. and Melnar, L., ?An automated linguisticknowledge-based cross-language transfer method forbuilding acoustic models for a language without na-tive training data,?
Interspeech?05, 1365-1368, Lis-bon, 2005.Liu, C. and Melnar, L., ?Training acoustic models withspeech data from different languages,?MULTILING?06, Stellenbosch, 2006.Mak, B. and Barnard, E., ?Phone clustering using theBhattacharyya distance,?
ICSLP?96, 2005-2008,1996.Nerbonne, J. and Heeringa, W., ?Measuring dialect dis-tance phonetically,?
Proc.
3rd Meeting ACL SpecialInterest Group in Comp.
Phonology, 1997.Schultz, T. and Waibel, A., ?Fast bootstrapping ofLVCSR systems with multilingual phoneme sets,?Eurospeech 97, 1:371-373, 1997.Schultz, T. and Waibel, A.., ?Polyphone Decision TreeSpecialization for Language Adaptation?, In Proc.
ofICASSP 2000.
Istanbul, 2000.Somers, H. L., ?Similarity metrics for aligning chil-dren?s articulation data,?
Proc.
36th Annual MeetingACL and 17th Int.
Conf.
Comp.
Ling., 1227?1231,1998.Sooful, J. J. and Botha, E. C., ?Comparison of acousticdistance measures for automatic cross-language pho-neme mapping,?
ICSLP?02, 521-524, 2002.10
