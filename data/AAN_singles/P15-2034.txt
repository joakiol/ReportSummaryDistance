Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 205?211,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsWord Order Typology through Multilingual Word AlignmentRobert?OstlingDepartment of LinguisticsStockholm UniversitySE-106 91 Stockholm, Swedenrobert@ling.su.seAbstractWith massively parallel corpora of hun-dreds or thousands of translations of thesame text, it is possible to automaticallyperform typological studies of languagestructure using very large language sam-ples.
We investigate the domain of wordorder using multilingual word alignmentand high-precision annotation transfer in acorpus with 1144 translations in 986 lan-guages of the New Testament.
Results areencouraging, with 86% to 96% agreementbetween our method and the manually cre-ated WALS database for a range of differ-ent word order features.
Beyond reproduc-ing the categorical data in WALS and ex-tending it to hundreds of other languages,we also provide quantitative data for therelative frequencies of different word or-ders, and show the usefulness of this forlanguage comparison.
Our method hasapplications for basic research in linguis-tic typology, as well as for NLP taskslike transfer learning for dependency pars-ing, which has been shown to benefit fromword order information.1 IntroductionSince the work of Greenberg (1963), word orderfeatures have played a central role in linguistic ty-pology research.
There is a great deal of varia-tion across languages, and interesting interactionsbetween different features which may hint at cog-nitive constraints in the processing of human lan-guage.
A full theoretical discussion on word ordertypology is beyond the scope of this paper, but theinterested reader is referred to e.g.
Dryer (2007)for an overview of the field.This study uses multilingual word alignment(?Ostling, 2014) and high-precision annotation pro-jection of part-of-speech (PoS) tags and depen-dency parse trees to investigate five differentword order properties in 986 different languages,through a corpus of New Testament translations.The results are validated through comparison torelevant chapters in the World Atlas on LanguageStructures, WALS (Dryer and Haspelmath, 2013),and we find a very high level of agreement be-tween this database and our method.We identify two primary applications of thismethod.
First, it provides a new tool for basic re-search in linguistic typology.
Second, it has beenshown that using these word order features leadsto increased accuracy during dependency parsingmodel transfer (T?ackstr?om et al, 2013).
Thesebenefits can now be extended to hundreds of morelanguages.
The quantified word order characteris-tics computed for each of the 986 languages in theNew Testament corpus, including about 600 not inthe WALS samples for these features, are availablefor download.12 Related workUsing parallel texts for linguistic typology has be-come increasingly popular recently, as massivelyparallel texts with hundreds or thousands of lan-guages have become easily accessible through theweb (Cysouw and W?alchli, 2007; Dahl, 2007;W?alchli, 2014).
Specific applications includedata-driven language classification (Mayer andCysouw, 2012) and lexical typology (W?alchli andCysouw, 2012).
However, unlike our work, noneof these authors developed automatic methods forstudying syntactic properties like word order, nordid they utilize recent advances in the field of wordalignment algorithms.1http://www.ling.su.se/acl2015-wordorder.zip2053 MethodThe first step consists of using supervised systemsfor annotating the source texts with Universal PoSTags (Petrov et al, 2012) and dependency struc-ture in the Universal Dependency Treebank format(McDonald et al, 2013).
For PoS tagging, we usethe Stanford Tagger (Toutanova et al, 2003) fol-lowed by a conversion step from the Penn Tree-bank tagset to the ?universal?
PoS tags using thetables published by Petrov et al Next, we use theMaltParser dependency parser (Nivre et al, 2007)trained on the Universal Dependency Treebank us-ing MaltOptimizer (Ballesteros and Nivre, 2012).The corpus is then aligned using the multilin-gual alignment tool of?Ostling (2014).
This modellearns an ?interlingua?
representation of the text,in this case the New Testament, to which all trans-lations are then aligned independently.
An inter-lingua sentence e is assumed to generate the cor-responding sentences f(l)for each of the L lan-guages through a set of alignment variables a(l)for each language.
This can be seen as a multilin-gual extension of the IBM model 1 (Brown et al,1993) with Dirichlet priors (Mermer and Sarac?lar,2011), where not only the alignment variables arehidden but also the source e. The probability of asentence and its alignments (in L languages) underthis model isP (a(1...L),f(1...L)|e) =L?l=1J?j=1pt(f(l)j|ea(l)j) ?I?i=1pc(ei)(1)where the translation distributions ptare assumedto have symmetric Dirichlet priors and the sourcetoken distribution pca Chinese Restaurant Processprior.
Given the parallel sentences f(1...L), thena(1...L)and e are sampled using Gibbs sampling.The advantage of this method is that the multi-source transfer can be done once, to the interlin-gua representation, then transferred in a secondstep to all of the 986 languages investigated.
Itwould be possible to instead perform 986 separatemulti-source projection steps, but at the expense ofhaving to perform a large number of bitext align-ments.From the annotated source texts, PoS and de-pendency annotations are transferred to the inter-lingua representation.
Since alignments are noisyand low recall is acceptable in this task, we usean aggressive filtering scheme: dependency linksmust be transferred from at least 80% of sourcetexts in order to be included.
For PoS tags,which are only used to double-check grammati-cal relations and should not impact precision neg-atively, the majority tag among aligned words isused.
Apart from compensating for noisy align-ments and parsing errors, this method also helpsto catch violations against the direct correspon-dence assumption (Hwa et al, 2002) by filter-ing out instances where different source texts usedifferent constructions, favoring the most proto-typical cases.
Each word order feature is codedin terms of dependency relations, with additionalconstraints on the parts of speech that can be in-volved.
For instance, when investigating the orderbetween nouns and their modifying adjectives welook for an AMOD dependency relation betweenan ADJ-tagged and a NOUN-tagged word, and notethe order between the adjective and the noun.
Thismethod rests on the assumption that translationequivalents have the same grammatical functionsacross translations, which is not always the case.For instance, if one language uses a passive con-struction where the source texts all use the activevoice, we would obtain the wrong order betweensubject and object.To summarize, our algorithm consists of the fol-lowing steps:1.
Compute an interlingua representation of theparallel text, as well as word alignments link-ing it to each of the translations.2.
Annotate a subset of translations with PoStags and dependency structure.3.
Use multi-source annotation projection fromthis subset to the interlingua representation,including only dependency links where thesame link is projected from at least 80% ofthe source translations.4.
Use single-source annotation projection fromthe interlingua representation to each of the986 translations.5.
For each construction of interest, and for eachlanguage, count the frequency of each order-ing of its constituents.4 EvaluationWe evaluate our method through comparisonto the WALS database (Dryer and Haspelmath,206SOV SVO OSV OVS VSO VOSPolynesian (Hawaiian, Maori)3 31 2 2 70 36 26 5 4 76 18Sinitic (Mandarin, Hakka)54 235 6 0 3 518 84 1 2 5 3Turkic (Kara-Kalpak, Kumyk)114 2 8 7 0 089 1 12 11 4 1Table 1: Number of transitive clauses with a givenorder of subject/object/verb, according to our al-gorithm, for six languages (from three families).2013), by manual analysis of selected cases, andby cluster analysis of the word order propertiescomputed for each language by our method.4.1 Data and methodologyA corpus of web-crawled translations of the NewTestament was used, comprising 1144 translationsin 986 different languages.
Of these, we used fiveEnglish translations as source texts for annotationprojection.
Ideally more languages should be usedas sources, but since we only had access to com-plete annotation pipelines for English and Germanwe only considered these two languages, and pre-liminary experiments using some German transla-tions in addition to the English ones did not leadto significantly different results.
A typologicallymore diverse set of source languages would helpto identify those instances in the text which aremost consistently translated across languages, inorder to reduce the probability that peculiarities ofthe source language(s) will bias the results.In order to evaluate our method automatically,we used data from the WALS database (Dryer andHaspelmath, 2013) which classifies languages ac-cording to a large number of features.
Several fea-tures concern word order, and we focused on fiveof these (listed in Table 2).
Only languages whichare represented both in the New Testament cor-pus and the WALS data were used for the evalua-tion.
In addition, we exclude languages for whichWALS does not indicate a particular word order.This might be due to e.g.
lacking adpositions alto-gether (which makes the adposition/noun order ofthat language undefined), or because no specificorder is considered dominant.The frequencies of all possible word orders fora feature are then counted, and for the purpose ofevaluation the most common order is chosen as thealgorithm?s output.
Although the relative frequen-cies of the different possible word orders are dis-carded for the sake of comparability with WALS,these frequencies are themselves an important re-sult of our work and tell a much richer story of theword order properties (see Table 1 and Figure 1).Counting the number of instances (token fre-quency) of each word order is the most straight-forward way to estimate the relative proportions ofeach ordering, but the results are biased towardsthe behavior of the most frequent words, whichoften have idiosyncratic, non-productive features.Therefore, we also compute the correspondingstatistics where each type is counted only once foreach word order it participates in, disregarding itsfrequency.
The type-based counts should bettercapture the behavior of productive patterns in thelanguage.
For the purpose of this study, we definethe type of our relations as follows:?
adjective-noun: the form of the adjective?
adposition-noun: the forms of both adposi-tion and noun?
verb-(subject)-(object): the form of the verbFor instance, given the following three sentences:?we see him,?
?I see her?
and ?them I see?, wewould increase the count by one for SVO orderand for OVS order, because these are the orders inwhich the verb see has been observed to partici-pate.In cases where there are multiple translationsinto a particular language, information is aggre-gated from all these translations into a single pro-file for the language.
This is problematic in somecases, such as when a very long time separates twotranslations and word order characteristics haveevolved, or simply due to different translators orsource texts.
However, since the typical case is asingle translation per language, and WALS onlycontains one data point per language, we leaveinter-language comparison to future research.4.2 Results and DiscussionTable 1 shows how the output of our token-basedalgorithm looks for three pairs of languages se-lected from different families.
The absolute countsvary due to our filtering procedure and differingnumbers of translations, but as we might expect207SouthernAltai(T)Tuvinian(T)Tatar(T)Kara-Kalpak (T)Kazakh (T)Karachay-Balkar(T)Khakas(T)Uighur (T)Kirghiz (T)Kumyk (T)Gagauz(T)Afrikaans (G)Plautdietsch(G)Dutch(G)German(G)Swabian(G)Samoan(P)Maori(P)Hawaiian(P)Kapingamarangi(P)Romanian (R)French (R)Italian(R)Catalan(R)Spanish(R)Portuguese(R)Mandarin Chinese(S)HakkaChinese(S)English(G)Icelandic(G)Swedish(G)Faroese(G)Danish (G)Norwegian(G)Figure 1: Hierarchical clustering based on word order statistics from our algorithm.
Language familiesrepresented are (G)ermanic, (R)omance, (T)urkic, (P)olynesian and (S)initic.the relative numbers are quite similar within eachpair.As a way of visualizing our data, we alsotried performing hierarchical clustering of lan-guages, by normalizing the word order count vec-tors and treating them (together) as a single 14-dimensional vector.
The result confirmed that lan-guages can be grouped remarkably well on basisof these five automatically extracted word orderfeatures.
A subset of the clustering containingall languages from five language families repre-sented in the New Testament corpus can be foundin Figure 1.
While the clustering mostly followstraditional genealogical boundaries, it is perhapsmore interesting to look at the cases where it doesnot.
The most glaring case is the wide split be-tween the West Germanic and the North Germaniclanguages, which in spite of their shared ances-try have widely different word order characteris-tics.
Interestingly, English is not grouped withthe West Germanic languages, but rather with theNorth Germanic languages which it has been inclose contact with.2One can also note that theSinitic languages, with respect to word order, arequite close to the North Germanic languages.Table 2 shows the agreement between the algo-rithm?s output and the corresponding WALS chap-2One reviewer pointed us to the controversial claim ofEmonds (2011), that modern English in fact is a North Ger-manic language, albeit with strong influence from the extinctWest Germanic language of Old English.ter for each feature.
The level of agreement ishigh, even though the sample consists mainly oflanguages unrelated to English, from which thedependency structure and PoS annotations weretransferred.
The most common column gives theratio of the most common ordering for each fea-ture (according to WALS), which can serve as anaive baseline.As expected, the lowest level of agreement isobserved for WALS chapter 81A, which has alower baseline since it allows six permutations ofthe verb, subject and object, whereas all the otherfeatures are binary.
In addition, this feature re-quires that two dependency relations (subject-verband object-verb) have been correctly transferred,which substantially reduces the number of rela-tions available for comparison.The fact that sources sometimes differ as tothe basic word order of a given language makesit evident that the disagreement reported in Ta-ble 2 is not necessarily due to errors made byour algorithm.
Another example of this can befound when looking at the order of adjective andnoun in some Romance languages (Spanish, Cata-lan, Portuguese, French and Italian), which are allclassified as having noun-adjective order (Dryer,2013a).
It turns out that adjective-noun order infact dominates in all of these languages, narrowlywhen using type counts and by a fairly large mar-gin when using token counts.
This result wasconfirmed by manual inspection, which leads us208Table 2: Agreement between WALS and our results, on languages present in both datasets.
The relativefrequency of the most common ordering is given for comparison.
Types is the agreement using type-based counts (see text for details), whereas Tokens uses token-based counts.Feature Languages Types Tokens Most common81A: Subject, Object, Verb (Dryer, 2013e) 342 85.4% 85.7% SOV: 43.3%82A: Subject, Verb (Dryer, 2013d) 376 89.4% 90.4% SV: 79.8%83A: Object, Verb (Dryer, 2013c) 387 96.4% 96.4% VO: 54.8%85A: Adposition, Noun Phrase (Dryer, 2013b) 329 94.8% 95.1% Prep: 50.4%87A: Adjective, Noun (Dryer, 2013a) 334 85.9% 88.0% AdjN: 68.9%to search further for an explanation for the dis-crepancy.3The Universal Dependency Treebank(McDonald et al, 2013) version 2 contains sub-corpora in French, Italian, Spanish and BrazilianPortuguese.
In all of these, noun-adjective or-der is dominant, which casts further doubts onour result.
The key difference turns out to be thegenre: whereas the modern texts used for the Uni-versal Dependency Treebank have mainly noun-adjective order, we used our supervised annota-tion pipeline to confirm that the French transla-tions of the New Testament indeed are dominatedby adjective-noun order.
This should serve as awarning about extrapolating too far from resultsobtained in one very specific genre, let alne in asingle text.5 Conclusions and future directionsThe promising results from this study show thathigh-precision annotation transfer is a realisticway of exploring word order features in very largelanguage samples, when a suitable parallel text isavailable.
Although the WALS features on wordorder already use very large samples (over a thou-sand languages), using our method with the NewTestament corpus contributes about 600 additionaldata points per feature, and adds quantitative datafor all of the 986 languages contained in the cor-pus.There are many other structural properties oflanguages that could be investigated with high-precision annotation transfer in massively paral-lel corpora, not just regarding word order but alsowithin in domains such as negation, comparisonand tense/aspect systems.
While there are lim-its to the quality and types of answers obtainable,our work demonstrates that for some problems it ispossible to obtain quick, quantitative answers that3Thanks to Francesca Di Garbo for helping with this.can be used to guide more traditional and thoroughtypological research.On the technical side, the alignment model usedis based on a non-symmetrized IBM model 1, andmore elaborate methods for alignment and annota-tion projection could potentially lead to more ac-curate results.
Preliminary results however indi-cate that adding a HMM-based word order modelakin to Vogel et al (1996) actually leads to some-what reduced agreement with the WALS classifi-cation, because the projections become biased to-wards the word order characteristics of the sourcelanguage(s), in our case English.
This indicatesthat using the less accurate but also less biasedIBM model 1 is in fact an advantage, when ag-gressive high-precision filtering is used.AcknowledgmentsThanks to Calle B?orstell,?Osten Dahl, FrancescaDi Garbo, Joakim Nivre, Janet B. Pierrehumbert,J?org Tiedemann, Bernhard W?alchli, Mats Wir?enand the anonymous reviewers for helpful com-ments and discussions.209ReferencesMiguel Ballesteros and Joakim Nivre.
2012.
Mal-tOptimizer: An optimization tool for MaltParser.In Proceedings of the Demonstrations at the 13thConference of the European Chapter of the Asso-ciation for Computational Linguistics, EACL ?12,pages 58?62, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics,19(2):263?311, June.Michael Cysouw and Bernhard W?alchli.
2007.
Paral-lel texts: Using translational equivalents in linguistictypology.
STUF - Language Typology and Univer-sals, 60(2):95?99.
?Osten Dahl.
2007.
From questionnaires to parallel cor-pora in typology.
STUF - Language Typology andUniversals, 60(2):172?181.Matthew S. Dryer and Martin Haspelmath.
2013.
TheWorld Atlas of Language Structures Online.
http://wals.info.Matthew S. Dryer.
2007.
Word order.
In Timo-thy Shopen, editor, Language Typology and Syntac-tic Description, volume I, chapter 2, pages 61?131.Cambridge University Press.Matthew S. Dryer.
2013a.
Order of adjective and noun.In Matthew S. Dryer and Martin Haspelmath, edi-tors, The World Atlas of Language Structures On-line.
Max Planck Institute for Evolutionary Anthro-pology, Leipzig.Matthew S. Dryer.
2013b.
Order of adposition andnoun phrase.
In Matthew S. Dryer and MartinHaspelmath, editors, The World Atlas of LanguageStructures Online.
Max Planck Institute for Evolu-tionary Anthropology, Leipzig.Matthew S. Dryer.
2013c.
Order of object and verb.In Matthew S. Dryer and Martin Haspelmath, edi-tors, The World Atlas of Language Structures On-line.
Max Planck Institute for Evolutionary Anthro-pology, Leipzig.Matthew S. Dryer.
2013d.
Order of subject and verb.In Matthew S. Dryer and Martin Haspelmath, edi-tors, The World Atlas of Language Structures On-line.
Max Planck Institute for Evolutionary Anthro-pology, Leipzig.Matthew S. Dryer.
2013e.
Order of subject, object andverb.
In Matthew S. Dryer and Martin Haspelmath,editors, The World Atlas of Language Structures On-line.
Max Planck Institute for Evolutionary Anthro-pology, Leipzig.Joseph Emonds.
2011.
English as a North Germaniclanguage: From the Norman conquest to the present.In Roman Tru?sn?
?k, Katar?
?na Nem?cokov?a, and Gre-gory Jason Bell, editors, Proceedings of the Sec-ond International Conference on English and Amer-ican Studies, pages 13?26, Zl?
?n, Czech Republic,September.Joseph H. Greenberg.
1963.
Some universals of gram-mar with particular reference to the order of mean-ingful elements.
In Joseph H. Greenberg, editor,Universals of Human Language, pages 73?113.
MITPress, Cambridge, Massachusetts.Rebecca Hwa, Philip Resnik, Amy Weinberg, andOkan Kolak.
2002.
Evaluating translational cor-respondence using annotation projection.
In Pro-ceedings of the 40th Annual Meeting on Associationfor Computational Linguistics, ACL ?02, pages 392?399, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Thomas Mayer and Michael Cysouw.
2012.
Lan-guage comparison through sparse multilingual wordalignment.
In Proceedings of the EACL 2012 JointWorkshop of LINGVIS & UNCLH, EACL 2012,pages 54?62, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuz-man Ganchev, Keith Hall, Slav Petrov, HaoZhang, Oscar T?ackstr?om, Claudia Bedini, N?uriaBertomeu Castell?o, and Jungmee Lee.
2013.
Uni-versal dependency annotation for multilingual pars-ing.
In Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 92?97, Sofia, Bulgaria,August.
Association for Computational Linguistics.Cos?kun Mermer and Murat Sarac?lar.
2011.
Bayesianword alignment for statistical machine translation.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies: short papers - Volume 2,HLT ?11, pages 182?187, Stroudsburg, PA, USA.Association for Computational Linguistics.Joakim Nivre, Johan Hall, Jens Nilsson, AtanasChanev, G?ulsen Eryigit, Sandra K?ubler, SvetoslavMarinov, and Erwin Marsi.
2007.
MaltParser:A language-independent system for data-driven de-pendency parsing.
Natural Language Engineering,13:95?135, 6.Robert?Ostling.
2014.
Bayesian word alignment formassively parallel texts.
In Proceedings of the 14thConference of the European Chapter of the Associa-tion for Computational Linguistics, volume 2: ShortPapers, pages 123?127, Gothenburg, Sweden, April.Association for Computational Linguistics.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Proceed-ings of the Eight International Conference on Lan-guage Resources and Evaluation (LREC?12), Istan-bul, Turkey, may.
European Language ResourcesAssociation (ELRA).210Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, RyanMcDonald, and Joakim Nivre.
2013.
Token andtype constraints for cross-lingual part-of-speech tag-ging.
Transactions of the Association for Computa-tional Linguistics, 1:1?12.Kristina Toutanova, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology- Volume 1, NAACL ?03, pages 173?180, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statisticaltranslation.
In Proceedings of the 16th Conferenceon Computational Linguistics - Volume 2, COLING?96, pages 836?841, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Bernhard W?alchli and Michael Cysouw.
2012.
Lex-ical typology through similarity semantics: To-ward a semantic map of motion verbs.
Linguistics,50(3):671?710.Bernhard W?alchli.
2014.
Algorithmic typology andgoing from known to similar unknown categorieswithin and across languages.
In Benedikt Szm-recsanyi and Bernhard W?alchli, editors, LinguisticVariation in Text and Speech, number 28 in Linguae& Litterae, pages 355?393.
De Gruyter.211
