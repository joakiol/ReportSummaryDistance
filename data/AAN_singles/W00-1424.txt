Generating Vague DescriptionsKees  van  DeemterITR I ,  Univers i ty  of  Br ightonLewes Road,  Wat ts  Bu i ld ingBr ighton  BN2 4G J, Un i ted  K ingdomKees.
van.
Deemter~itri.
brighton, ac.
ukAbst ractThis paper deals with the generation of definite(i.e., uniquely referring) descriptions containing se-mantically vague expressions ('large', 'small', etc.
).Firstly, the paper proposes a semantic analysis ofvague descriptions that does justice to the context-dependent meaning of the vague expressions inthem.
Secondly, the paper shows how this semanticanalysis can be implemented using a modification ofthe Dale and Reiter (1995) algorithm for the gener-ation of referring expressions.
A notable feature ofthe new algorithm is that, unlike Dale and Reiter(1995), it covers plural as well as singular NPs.
Thisalgorithm has been implemented in an experimentalNLG program using ProFIT.
The paper concludes byformulating some pragmatic onstraints that couldallow a generator to choose between different seman-tically correct descriptions.1 In t roduct ion :  Vague proper t iesand  Gradab le  Ad jec t ivesSome properties can apply to an object to a greateror lesser degree.
Such continuous, or vague proper-ties, which can be expressed by, among other pos-sibilities, gradable adjectives (e.g., 'small', 'large',e.g.
Quirk et al 1972 sections 5.5 and 5.39), pose adifficult challenge to existing semantic theories, the-oretical as well as computational.
The problems arecaused partly by the extreme context-dependence ofthe expressions involved, and partly by the resis-tance of vague properties to discrete mathematicalmodeling (e.g., Synthese 1975, Pinkal 1995).
Theweight of these problems is increased by fact thatvague expressions are ubiquitous in many domains.The present paper demonstrates how a Natural Lan-guage Generation (NLG) program can be enabled to-generate uniquely referring descriptions containingone gradable adjective, despite the vagueness of theadjective.
Having presented a semantic analysis forsuch vague descriptions, we describe the semanticcore of an NLG algorithm that has numerical data asinput and vague (uniquely referring) descriptions asoutput.One property setting our treatment of vaguenessapart from that in other NLC programs-(e.g.
Gold-berg 1994) is that it uses ?
?vague properties for anexact task, namely the ruling out of distractors inreferring expressions (Dale and Reiter 1995).
An-other distinctive property is that our account allowsthe 'meaning' of vague expressions to be determinedby a combination of linguistic ontext (i.e., the Com-mon Noun following the adjective) and nonlinguisticcontext (i.e., the properties of the elements in thedomain).2 The  Mean ing  o f  VagueDescr ip t ionsSeveral different analyses are possible of what itmeans to be, for example, 'large': larger than aver-age, larger than most, etc.
But there is not necess-rily just one correct analysis.
Consider a domain offour mice, sized 2,5,7, and 10cm.
1 In this case, forexample, one can speak of1.
The large mouse(= the one whose size is lOcm), and of2.
The two large mice(= the two whose sizes are 7 and lOcm).Clearly, what it takes to be large has not been writ-ten in stone: the speaker may decide that 7cm isenough (as in (2)), or she may set the standardshigher (as in (1)).
A numeral (explicit, or implicitas in (1)), allows the reader to make inferences aboutthe standards employed by the speaker3 More pre-cisely, it appears that in a definite description, theabsolute form of the adjective is semantically equiv-alent with the superlative form:The n large mice - The largest n miceThe large mice - The largest miceThe large mouse - The largest mouse.1For simplicity, the adjectives involved will be assumedto be one-dimensional.
Note that the degree of precision re-flected by the units of measurement affects the descriptionsgenerated, and even the objects (or sets) that can  be de-scribed, since it determines which objects count as havingthe same size.2Thanks are due to Matthew Stone for this observation.179This claim, which has been underpinned by a smallexperiment with human subjects (see Appendix),means that if a sentence containing .one element ofa pair is true then so is the corresponding sentencecontaining the other.
There are bound to be differ-ences between the two forms, but these will be takento be of a pragmatic nature, having to do with felic-ity rather than truth (see section 5.2).An important qualification must be made with re-spect to the analysis that we propose: to simplifymatters, we assume that the entire domain of rele-vant individuals is: available -and ~ha'g it-is-:this d~:main alone which is taken into account when the ad-jective is applied.
In the case of the example above,this means that all mice are irrelevant except thefour that are mentioned: no other knowledge aboutthe size of mice is assumed to be available.
32.1 A Formal Semantics for VagueDescriptionsLet us be more precise.
In our presentation, we willfocus on the adjective 'large', without intended lossof generality.
For simplicity, 'large' will be treatedas semantically one-dimensional.i. '
The  largest n mouse/mice ' .
Imagine a setC of contextually relevant animals.
Then the NP'The largest n mouse/mice' (n > 0) presupposesthat there is an S C_ C that contains n elements,all of which are mice, and such that (1) C - S ?
?and (2) every mouse in C - S is smaller than ev-ery mouse in S. If such a set S exists then the NPdenotes S. The case where n = 1, realized as 'The\[Adj\]-est \[CN~g\]' (sg = singular), falls out automat-ically.ii. '
The  largest mice' .
This account can beextended to cover cases of the form 'The \[Adj\]-est\[CNpt\]' (pl = plural), where the numeral n is sup-pressed: these will be taken to be ambiguous be-tween all expressions of the form 'The \[Adj\]-est n\[CN\]' where n > 1.
Thus, in a domain where thereare five mice, of sizes 4,4,4,5,6 cm, the only possiblevalue of n. is 2, causing the NP to denote the twomice of 5 and 6 cm size.iii. '
The  n large mouse/mice ' .
We analyse 'Then \[Adj\] \[CN\]' (n > 0) as semantically equivalent withthe corresponding NP of the form 'The \[Adj\]-est n\[CN\]'.
The two large mice', for example, denotes aset of two mice, each of which is bigger than all othercontextually relevant mice.iv. '
The  large mice' .
Expressions of this form canbe analysed as being of the form 'The n \[Adj\] \[CN\]'for some value of n. In other words, we will takealn other words, only perceptual context-dependence istaken into account, as opposed to no,'maltve or functionalcontext-dependence Ebeling and Gehnan (1994).them to be ambiguous or unspecific - the differencewill not matter for present purposes - between 'The.2 large mice', 'The 3. large mice', etc.3 Generation of Crisp DescriptionsGeneration of descriptions covers a number of tasks,one of which consists of finding a set L of propertieswhich allows a reader to pick out a given unique in-dividual or set of individuals.
The state of the artis discussed in Dale and Reiter (1995), who presenta computationally tractable algorithm for character-:.
izing~i~dividuods.x This,algorithm-(henceforth_D&R),deals with vague properties, such as size, to someextent, but these are treated as if they were context-independent: always applying to the same sets ofobjects.In many cases, generating vague descriptions in-volves generating a plural and no generally acceptedaccount of the generation of plural descriptions hasbeen advanced so far.
In the following section, there-fore, a generalization or D&R will be offered, calledD& RPlur, which focuses on sets of individuals.
Char-acterization of an individual will fall out as a specialcase of the algorithm.3.1 Plural  Descriptions: Dale and Reitergeneral izedThe properties which form the basis of D&Rpt~r aremodeled as pairs of the form {Attribute,Value).
Inour presentation of the algorithm, we will focus oncomplete properties (i.e., (Attribute,Value) pairs)rather than attributes, as in Dale and Reiter (1995),since this facilitates the use of set-theoretic termi-nology.
Suppose S is the 'target' set of individu-als (i.e., the set of individuals to be characterized)and C (where S C_ C) is the set of individuals fromwhich S is to be selected.
4 Informally - and for-getting about the special treatment of head nouns -what happens is the following: Tile algorithm iter-ates through a list P in which the properties appearin order of 'preference'; for each attribute, it checkswhether specifying a value for that attribute wouldrule out at least one additional member of C; if so,the attribute is added to L, with a suitable value.
(The value can be optimized using some further con-straints but these will be disregarded here.)
Individ-uals that are ruled out by a property are removedfrom C. The process of expanding L and contractingC continues until C = S. The properties in L canbe used by a linguistic realization module to pro-duce NPs such as 'The white mice', 'The white mice?
that arepregnant', etc.
Schematically, the algorithmgoes as follows: (Notation: Given a property Q, theset of objects that have the property Q is denoted\[\[o\]\].)?
1Note that C contains r, unlike Dale and Reiter's 'contrastset'  C, which consists of those elements of the domain fromwhich r is set apart.180L := (D {# L is initialized to the empty set #}For each Pie P doIf S C_ \[\[Pi\]\] ~ :C ~ '\[l~Pi\]\] {# Adding Piwould remove distractors from C #}then doL := L O {Pi} {# Property Pi is addedto L #}C := C n \[\[P~\]\] {# All elements outside\[\[Pi\]\] are removed from C #}If C = S then Return L {# Success #}Return Failure-'{S,d: All-properties in Phave  beentested, yet C -7= S ~ }of one vague property.
Case i of section 2.1, 'Thelargest n chihuahuas' will be discussed in some de-tail.
All the others are minor variations.
'Success' means that the properties in L are suffi-cient to characterize S. Thus, ~{\[\[Pi\]\] : Pie L} = S.The case in which S is a singleton set amounts tothe generation of a singular description: D~RPIurbecomes equivalent to D&R (describing the individ-ual r) when S in D&aPlur is replaced by {r}.D&RPlu r uses hill climbing: an increasingly goodapproximation of S is achieved with every contrac-tion of C. Provided the initial C is finite, D&apt~,-finds a suitable L if there exists one.
Each propertyis considered at most once, in order of 'preference'.As a consequence, L can contain semantically redun-dant properties - causing the descriptions to becomemore natural, of.
Dale and Reiter 1995 - and the al-gorithm is polynomial in the cardinality of P.Caveats.
D&RPtur does not allow a generator to in-clude collective properties in a description, as in 'thetwo neighbouring houses', for example.
Furthermore,D~l-tPlur cannot be employed to generate conjoinedNPs: It generates NPs like 'the large white mouse'but not 'tile black cat and the large white mouse'.From a general viewpoint of generating descriptions,this is an important limitation which is, moreover,difficult to overcome in a computationally tractableaccount.
In the present context, however, the lim-itation is inessential, since what is crucial here isthe interaction between an Adjective and a (possiblycomplex) Common Noun following it: in more com-plex constructs of the form 'NP and the Adj CN',only CN affects the meaning of Adj.
5 There is noneed for us to solve the harder problem of finding anefficient algorithm for generating NPs uniquely de-scribing arbitrary sets of objects, but only the easierproblem of doing this whenever a (nonconjunctive)NP of the form 'tile Adj CN' is possible.4 Generat ion  o f  Vague Descr ip t ions\Ve nOw turn our attention to extensions of D&RPlurthat generate descriptions containing the expression~\[n "The elephant and the big mous(,', for example, themouse does not have to be bigger than any elephant.Super la t ive  adject ives.
First, 'The largest chi-huahua'.
We will assume that s i ze  is stored (in theKB that forms the input to the generator) as an at-tribute with exact numerical values.
We will takethem to be of the form n crn, where n is a positivenatural number.
For example,type = dog, chihuahua?
co.lou_v ~_blac, k~ blue, yellows i ze  = lcm, 2cm, ..., 10cm.With this KB as input, D~R allows us to generateNPs based on L = {yellow,chihuahua,9~n}, for ex-ample, exploiting the number-valued attribute s ize.The result could be the NP 'The 9cm yellow chi-huahua', for example.
The challenge, however, isto generate superlatives like 'The largest yellow chi-huahua' instead.There are several ways in which this challengemay be answered.
One possibility is to replacean exact value like 9cm, in L, by a superlativevalue whenever all distractors happen to have asmaller size.
The result would be a new list L ={yellow,chihuahua,largestl}, where ' largestt' is theproperty 'being the unique largest element of C'.This list can then be realized as a superlative NP.We will present a different approach that is moreeasily extended to plurals, given that a plural de-scription like 'the 2 large mice' does not require thetwo mice to have the same size.Suppose s i ze  is the only vague property in the KB.Vague properties are less 'preferred' (in the senseof section 3.1) than others (Krahmer and Theune1999).6 As a result, when they are taken into consid-eration, all tile other relevant properties are alreadyin L. For instance, assume that this is the KB, andthat the object to be described is c4:type(cl, c~.
c3, c,l) =chihuahuatype(ph) =poodlesize(c1 )=3cnlsize(c.2)=hcnlsize(ca)=8cmsize(c4) =size(ps) =9cmAt this point, inequalities of tile form size(x) >m cm are added to the KB.
For every value of,the form n ~n oecuring in-the oldKB, all..inequat-ities of the form size(x) > n an are added whosetruth follows from the old I<B.
Inequalities are more6Note, by contrast, that vague properties tend to be real-ized first (Greenbaum et al 1985, Shaw and Hatzivassiloglou1999).
Surface realization, however, is not the topic of lidspaper.181preferred than equalities, while logicaUy stronger in-equalities are more preferred than logically weakerones.
7 Thus, in order of preference .
.
.
.size(c4),size(ps) > 8cmsize(c3),size(c4),size(ps) > 5cmsize (c2),size(ca ),size(c4 ),size(p5) > 3cm.The first property that makes it into L is 'chi-huahua', which removes Ps but not ca from the con-text set.
(Result: C = {cl,...,c4}.)
Now size istaken into account, and the property size(x) > 8cmsingles out c4..The .resulting.listA s L =,~cchihuahua ,> 8cm}.
This implies that c4 is the only chihuahuain the KB that is greater than 8cm and consequently,the property size(x) > 8cm can be replaced, in L, bythe property of 'being larger than all other elementsof C'.
The result is a list that may be written asL = {chihuahua, largesh }, which can be employedto generate the description 'the largest chihuahua'.Plurals can be treated along analogous lines.
Sup-pose, for example, the facts in the KB are the sameas above and the target set S is {ca, c4}.
Its two ele-ments share the property size(x) > 5cm.
This prop-erty is exploited by n&Rm~ to construct he listL = {chihuahua,>5cm}.
Analogous to the singularcase, the inequality can be replaced by the property'being a set al of whose elements are larger thanall other elements of C' (largestm for short), leadingto NPs such as 'the largest chihuahuas'.
Optionally,the numeral may be included in the NP ('the twolargest chihuahuas').- 'Abso lu te '  adject ives.
The step from the su-perlative descriptions of case i to the analogous 'ab-solute' descriptions i a small one.
Let us first turnto case iii, 'The n large mouse/mice'.
Assuming thecorrectness of the semantic analysis in section 2, theNP 'The n large mouse/mice' is semantically equiv-alent to the one discussed under i. Consequently,an obvious variant of the algorithm that was justdescribed can be used for generating it.
(For prag-matic issues, see section 5.2)Finally.
case iv, 'The large mice'.
Semantically,this does not introduce an 3" new problems, sinceit is to case i i i  what case i i  is to case i. Accord-ing to the semantic analysis of section 2.1 'Thelarge mice' should be analysed just like 'The n largemouse/mice', except that the muneral n is sup-pressed.
This means that a simplified version (i.e.,without a cardinality check) of the algorithm thattakes care of case i i i  will be sufificient to generatedescriptions of this kind.rE .g ,  size(x) > m is preferred over sZze(x) > n iff m > n.The  preference for inequal i t ies  causes the generator  to avoidthe ment ion ing  of measurements  unless they are needed forthe ident i f icat ion ~ff the target  object .5 Conc lus ions  and  loose  endsWe have shown how vague descriptions can be gen-.. ~erated .that'.make.use-of-one vague-propeift~.
We be-lieve our account o be an instructive model of howthe 'raw data' in a standard knowledge base can bepresented in English expressions that have a very dif-ferent structure.
The numerical data that are the in-put to our algorithm, for example, take a very differ-ent form in the descriptions generated, and yet thereis, in an interesting sense, no loss of information: adescription has the same reference, whether it uses?
...:,..exaet~.anforroataon:(~he:3c~zz.mouse.)
~or ...~ague:.
m,--formation ('The large mouse'), s5.1 L imi ta t ions  o f  the  semant ic  ana lys i sOur proposal covers the generation of vague descrip-tions 'from absolute values', which is argued in Daleand Reiter (1995, section 5.1.2) to be most practi-cally useful.
When vague input is available (e.g., inthe generation component of a Machine Translationsystem, or in WVSlWYM-style generation (Power andScott 1998)), simpler methods can be used.
Our ownaccount is limited to the generation of definite de-scriptions and no obvious generalization to indefiniteor quantified NPs exists.
Other limitations includea.
Descriptions that contain properties for otherthan individuating reasons (as when someoneasks you to clean 'the dirty table cloth' whenonly one table cloth is in sight).
This limitationis inherited directly from the D&R algorithmthat our own algorithm extends.b.
Descriptions containing more than one vagueproperty, such as 'The fat tall bookcase', whosemeaning is more radically unclear than that ofdefinite descriptions containing only one vagueterm.
(The bookcase may be neither the fattestnor the tallest, and it is not clear how the twodimensions are weighed.)c.
Descriptions that rely on the salience of con-textually available objects.
Krahmer and The-une (1998) have shown that a contextuallymore adequate version of D~:R can  be obtainedwhen degrees of salience are taken into account.Their account can be summarized as analysing'the black dog' as denoting the unique mostsalient object in the domain that is both blackand a dog.
(Generalizations of this idea toD&Rmu~ are conceivable but nontrivial sincenot all elements of the set S have to be equallysalient.)
Our own extensions of D&R (and per-haps O&Rmu~) could be 'contextualized' if theSThis  may be contrasted w i th  the vague express ions  gemcrated in (Goldberg et al 1994), where  there is a real -- andintended Ioss of in format ion.
(E.g.
,  'Heavy  rain fell on Tues-day',  bmsed on the in format ion  that  the rainfal l  on 'lhlesdayequal led ,15rnm.
)182role of salience is changed slightly: focusing onthe singular case, the algorithm can, for exam-ple, be adapted, to, legislate.that:'the, large(est) :mouse' denotes the largest of all those micethat are salient (according to some standard ofsalience).
Note that this analysis predicts am-biguity when the largest mouse that is salientaccording to one standard is smaller than thelargest mouse that is salient according to a morerelaxed standard.
Suppose, for example,then 'the large(est) mouse' may designate i-ther m2 or m3 depending on the standardsof salience used.
What this illustrates is thatsalience and size are both vague properties, andthat - as we have seen under point b - combin-ing vague properties is a tricky business.5.2 PragmaticsAn experimental ProFIT (Erbach 1995) program hasimplemented the algorithms described so far, gen-erating different descriptions, each of which wouldallow a reader/hearer to identify an object or a setof objects.
But of course, an NLG program has to domore than determine under what circumstances theuse of a description leads to a true statement: anadditional problem is to choose the most appropri-ate description from those that are semantically cor-rect.
This makes NLG an ideal setting for exploringissues that have plagued semanticists and philoso-phers when they studied the meaning of vague ex-pressions, such as whether it can be true for twoobjects x and y which are indistinguishable in sizethat x is large and y is not (e.g.
Synthese 1975).The present setting allows us to say that a statementof this kind may be true yet infelicitous (becausethey conflict with certain pragmatic onstraints),and consequently to be avoided by a generator.As for the choice between the 'absolute'/superlativeforms of the gradable adjective, we conjecture thatthe following constraints apply:C1.
Dist inguishabi l i ty .
Expressions of the form'The (n) large \[CN\]'  are infelicitous when thesmallest element of the designated set S (namedx) and the largest CN smaller than all elementsof S (named y) are perceptually indistinguish-able.C2.
Natura l  Group ing .
Expressions of the form'The (n) large \[CN\]' are better avoided when thedifference in size between x and y is 'compara-t i veh  small.
One way of making this precise isby requiring that the difference hetween x andC3.y cannot be smaller than that between eitherx or y and one of their neighbouring elements.Consider, for.
example,.
: a domain .consisting .ofmice that are lcm, lcm, 2cm, 7cm, 9cm and9cm large; then C2 predicts that the only felic-itous use of 'the large mice' refers to the largestthree of the group.Min imal i ty .
Otherwise, preference is given tothe absolute form.
This implies that when ob-jects of only two sizes are present, and the differ-Salient (strict): ence is perceptually distinguishable, the abso-ml  (2em);,m~.
(Scm) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ ?
: .,~.~Ante~formds~pr.eferEedover:t~hes~perta'~iv~fovm.Salient ( re laxed):  (For example, in a domain where there are twoml (2cm), m2 (5cm), m3 (7cm); sizes of pills, we are much more likely to speakof 'the large pills' than of 'the largest pills'.
)In languages in which the superlative form ismorphologically more complex than the abso-lute form, constraint C3 can be argued to followfrom general Gricean principles (Grice 1975)).As for the presence/absence of the numeral, weconjecture that the disambiguating numeral (asin 'the n large mice' or 'the n largest mice') canbe omitted under two types of circumstances: (1)when any ambiguity resulting from different valuesof n is likely to be inconsequential (see Van Deemterand Peters (1996) for various perspectives); (2)when the domain allows only one 'natural grouping'(in the sense of C2).
Before and until a moreaccurate version of the notion of a natural groupingis available (perhaps using fuzzy logic as in Zim-mermann 1985), generators could be forbidden toomit the numeral, except in the case of a definitedescription in the singular.Append ix :  A Suppor t ing  Exper imentHuman subjects were asked to judge the correctnessof an utterance in a variety of situations.
The ex-periment was set up to make plausible that, in a sit-uation in which only perceptual context-dependence(see section 1) is relevant, expressions of the form'the n. large CN' can be used whenever certain sim-ple conditions are fullfilled.
Note that this (0 )  di-rection of the hypothesis is most directly relevantto the design of a generator, since we expect a gen-erator to avoid mistakes rather than ahvays use anexpression whenever it is legitimate.Hypothesis (=>): In a situation in whichthe domain D represents the set of percep-tually relevant objects, an expression of theform 'the n large CN' (where n 2 1), canbe used to refer to a set S of cardinality nif all objects in D - S are smaller than anvof the n..183The experiment explores whether 'the n large CN'can refer to the n largest objects in the domain,whether or not this set of objects is held together byspatial position or other factors.
Subjects were pre-sented with 26 different situations, in each of whichthey had to say whether the sentenceThe two high numbers appear in bracketswould constitute a correct utterance.
The literal textof our question was:Suppose you want to inform a hearer*.which numbers:.,irr~'a:,gi~ren.list:,appeav in-brackets*, where the hearer knows whatthe numbers are, but not which of them ap-pear in brackets.
For example, the hearerknows that the list is 1 2 1 7 7 1 1 3 1.You, as a speaker, know that only thetwo occurrences of the number 7 appearin brackets: 1 2 1 (7) (7) 1 1 3 1.
Ourquestion to you is: Would it be *correct*to convey this information by saying "Thetwo high numbers appear in brackets"?(...
).All subjects were shown the 26 situations in thesame, arbitrary, order.
Each situation presented tothe subjects contained a list of nine numbers.
In 24cases, the lists had the following form:l l l xyz l l l ,where each of x, y, z equalled either 6 or 9, and wherethere were always two numbers among x, y, z thatappear in brackets.
In 16 out of 24 cases, the twobracketed positions are right next to each other, al-lowing us to test whether spatial contiguity' playsany role.
Subjects were presented with two addi-tional situations, namely 1 1 1 (6) 1 (7) 1 1 1 and1 1 1 (7) 1 (6) 1 1 1 in which, unlike the other 24situations, the two largest numbers are not equallylarge, to make sure that the descriptions do not re-quire the elements in their denotation to be similarin that respect.
Our questions were presented viaemail to 30 third-year psychology/cognitive sciencestudents at the University of Durham.
UK.
all ofwhom were native speakers of English and ten ofwhich responded.Resu l ts :  Eight subjects responded in exact confor-mance with the analysis of section 2.1, marking alland only those five sequences in which the highest2 numbers appeared in brackets.
Only two subjectsdeviated slightly from this analysis: one of the two(subject 9) described all the expected situations as'correct' plus the two cases in which two contiguous6-es appeared in brackets: the other subject (subject10) appears to have made a typing err~n, confusingtwo subsequent situations in the experiment?
Allother responses of subjects 9 and 10 were as pre-dicted.
This means: tha t all .sub.jects except subject10 were consistent with our '=#' hypothesis.
The ex-periment suggests that the converse of the hypoth-esis might also be true, in which it is claimed thatexpressions of the form 'the n large CN' cannot beemployed to refer to the set S unless S consists ofthe n largest objects in D:Hypothesis (.
?=): In a situation in whichthe domain D represents the set of percep-t_..: .......... ~ ~.t.ually: relevmtt, ob_jects>a~:-expressionof t~he.form 'the n large CN' (where n _> 1), canonly be used to refer to a set S of cardi-nality n if all objects in D - S are smallerthan any of the n.Again disregarding subject 10, eight out of ninesubjects act in accordance with Hypothesis .
?=,while only one appears to follow a somewhat moreliberal rule.
Given these findings, it appears tobe safe to build a generator that implements bothhypotheses, since none of our subjects would belikely to disagree with any of the descriptionsgenerated by it.This experiment has evident limitations.
In partic-ular, it has no bearing on the pragmatic onstraintssuggested in section 5.2, which might be tested in afollow-up experiment.AcknowledgementsThanks are due to: Richard Power for discussionsand implementation; Emiel Krahmer, Ehud Reiterand Matthew Stone for comments on an earlierdraft; Hua Cheng for observations on linguisticrealization; Rosemary Stevenson and Paul Piwekfor their help with the experiment described in theAppendix.6 References- Dale and Reiter 1995.
R. Dale and E. Reiter.
Con>putationat Interpretations of the Gricean Maximesin the Geueration of Referring Expressions.
Co.qni-tive Science 18: 233-263.- Ebeling and Gelrnan 1994.
Ebeling, K.S.. GehnanS.A.
1994.
Children's use of context in interpreting"big" and "little".
Child Development 65(4): 1178-1192.- Erbach 1995.
G. Erbach.
Web page on the ProFIT9The s i tuat ions  that  we suspect  to  have  been confused  are1 1 1 (9) (9) 9 1 1 1, wh ich  was  marked  as cor rec t  (a l though,remarkab ly ,  none of the  o ther  ' th ree  n ines '  s i tuat ions  weremarked  as cor rec t )  and  1 I 1 (9) (9} 6 1 1 I.184programming language, http://coli.uni-sb.de/ r-bach/formal/profit/profit.html..... Goldberg et al 1994.
E .
Goldberg,.tN.
Driedger,and R. Kitteridge.
Using Natural-Language Pro-cessing to Produce Weather Forecasts.
mEE Expert9 no.2: 45-53.- Greenbaum et al 1985.
"A Comprehensive Gram-mar of the English Language".
Longman, Harlow,Essex.- Grice 1975.
P. Grice.
Logic and Conversation.In P. Cole and J. Morgan (Eds.
), "Syntax and Se-mantics: Vol 3, Speech Acts"!- 43~-58.
New Ym'k,Academic Press.- Krahmer and Theune 1999.
E. Krahmer and M.Theune.
Generating Descriptions in Context.
InR.
Kibble and K. van Deemter (Eds.
), Procs.
ofworkshop The Generation of Nominal Expressions,associated with the l l th  European Summer Schoolin Logic, Language, and Information (ESSLLI'99).- Pinkal 1995.
M. Pinkal.
"Logic and Lexicon".
Ox-ford University Press.- Power and Scott 1998.
R. Power and D. Scott.Multilingual Authoring using Feedback Texts.
InProc.
COLING/ACL, Montreal.- Quirk et al 1972.
R. Quirk, S. Greenbaum, andG.
Leech.
"A Grammar of Contemporary English".Longman, Harlow, Essex.- Shaw and Hatzivassiloglou 1999.
Ordering AmongPremodifiers.
In Proes.
of ACL99, Univ.
Maryland.- Synthese 1975.
Special issue of the journal Syn-these on semantic vagueness.
Synthese 30.- Van Deemter and Peters 1996.
K. van Deemterand S. Peters (Eds.)
"Semantic Ambiguity and Un-derspecification".
CSLI Publications, Stanford.- Zimmermann 1985.
H. J. Zimmermann.
"FuzzySet Theory - and its Applications".
Kluwer Aca-demic Publishers, Boston/Dordrecht/Lancaster.185
