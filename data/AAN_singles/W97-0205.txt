A Lexicon for Underspecified Semantic TaggingPau l  Bui te laarDept.
of Computer  ScienceBrandeis UniversityWal tham,  MA 02254-9110, USApaulb@cs, brandeis,  eduAbst ractThe paper defends the notion that seman-tic tagging should be viewed as more thandisambiguation between senses.
Instead,semantic tagging should be a first stepin the interpretation process by assigningeach lexJ.cal item a representation of allof its sy=stematically related senses, fromwhich fuxther semantic processing stepscan derive discourse dependent interpre-tations.
This leads to a new type of se-mantic lexicon (CoRv.Lzx) that supportsunderspecified semantic tagging througha design based on systematic polysemousclasses and a class-based acquisition of lex-ical knowledge for specific domains.1 Underspec i f ied  semant ic  tagg ingSemantic tagging has mostly been considered asnothing more than disambiguation to be performedalong the same lines as part-of-speech tagging: givenn lexical items each with m senses apply linguis-tic heuristics and/or statistical measures to pickthe most likely sense for each lexical item (see eg:(Yarowsky, 1Q92) (Stevenson and Wilks, 1997)).I do not believe this to be the right approach becauseit blurs the distinction between 'related' (systematicpolysemy) and 'unrelated' senses (homonymy : bank- bank).
Although homonyms need to be tagged witha disambiguated sense, this is not necessarily so inthe case of systematic polysemy.
There are two rea-sons for this that I will discuss briefly here.First, the problem of multiple reference.
Considerthis example from the BROWN corpus:\[A long book heavily weighted withmil ltary technlcalities\]Np, in this edi-tion it is neither so long nor so technical asit was originally.The discourse marker (it) refers back to an NP  thatexpresses more than one interpretation at the sametime.
The head of the NP  (book) has a numberof systematically related senses that are being ex-pressed simultaneously.
The meaning of book in thissentence cannot be disambiguated between the num-ber of interpretations that are implied: the informa-tional content of the book (military technicali-ties), its physical appearance (heavily weighted)and the events that are involved in its constructionand use (long).The example illustrates the fact that disambigua-tion between related senses is not always possible,which leads to the further question if a discrete dis-tinction between such senses is desirable at all.
Anumber of researchers have answered this questionnegatively (see eg: (Pustejovsky, 1995) (Killgariff,1992)).
Consider these examples from BROWN:(1) fast run-up (of the stock)(2) fast action (by the city government)(3) fast footwork (by Washington)(4) fast weight gaining(5) fast condition (of the track)(6) fast response time(7) fast people(8) fast ballEach use of the adjective 'fast' in these examples hasa slightly different interpretation that could be cap-tured in a number of senses, reflecting the differentsyntactic and semantic patterns.
For instance:1.
'a fast action' (1, 2, 3, 4)2.
'a fast state of affairs' (5, 6)3.
'a fast object '  (7, 8)25On the other hand all of the interpretations havesomething in common also, namely the idea of'speed'.
It seems therefore useful to underspecifythe lexical meaning of 'fast' to a representation thatcaptures this primary semantic aspect and gives ageneral structure for its combination with other lex-ical items, both locally (in compositional semantics)and globally (in discourse structure).Both the multiple reference and the sense enumer-ation problem show that lexical items mostly havean indefinite number of related but highly discoursedependent interpretations, between which cannot bedistinguished by semantic tagging alone.
Instead, se-mantic tagging should be a first step in the interpre-tation process by assigning each lexical item a repre-sentation of all of its systematically related 'senses'.Further semantic processing steps derive discoursedependent interpretations from this representation.Semantic tags are therefore more like pointers tocomplex knowledge representations, which can beseen as underspecified lexical meanings.2 CORELEX: A Semantic Lexiconwith Systematic PolysemousClassesIn this section I describe the structure and contentof a lexicon (CORELEX) that builds on the assump-tions about lexical semantics and discourse outlinedabove.
More specifically, it is to be 'structured insuch a way that it reflects the lexical semanticsof a language in systematic and predictable ways'(Pustejovsky, Boguraev, and Johnston, 1995).
Thisassumption is fundamentally different from the de-sign philosophies behind existing lexical semantic re-sources like WORDNET that do not account for anyregularities between senses.
For instance, WORD-NET  assigns to the noun book the following senses:the content that is being communicated (commu-nicatiofl) and the medium of communication (ar-tifact).
More accurately, book should be assigned aqualia structure which implies both of these interpre-tations and connects them to each of the more spe-cific senses that WORDNET assigns: that is, facts,d rama and a journal can be part-of the content of abook; a section is part-of both the content and themedium; publication, production and record-ing are all events in which both the content and themedium aspects of a book can be involved.An important advantage of the CORELEX approachis more consistency among the assignments of lex-ical semantic structure.
Consider the senses thatWORDNET assigns to door, gate and window:doormovable_barrier -,~ artifactentrance ~-~ openingaccess ~* cognition, knowledgehouse ~-, ?
?room ~-~ ?
?gatemovable_barrier -,~ artifactcomputer_circult -,~ openinggrossAncome -,~ openingwindowopening -~ openingpanel --~ artifactdisplay ~-* cognition, knowledgepublicationproduct, productionfactdramatic_composltion, dramatic_workrecordsection, subdivisionjournalFigure I: WORDNET senses for the noun bookAt the top of the WORDNET hierarchy these sevensenses can be reduced to two unrelated 'basic senses':26Figure 2: WORDNET senses for the nouns door,window and gateObviously these are similar words, something whichis not expressed in the WORDNET sense assign-ments.
In the CORELEX approach, these nouns aregiven the same semantic type, which is underspeci-fled for any specific 'sense' but assigns them consis-tently with the same basic lexical semantic structurethat expresses the regularities between all of theirinterpretations.However, despite its shortcomings WORDNET is avast resource of lexical semantic knowledge that canmmmmmm\[\]mmn\[\]mmnmmmmmnmmbe mined, restructured and extended, which makesit a good starting point for the construction ofCORELEX.
The next sections describe how system-atic polysem0us classes and underspecified semantictypes can be derived from WORDNET.
In this pa-per I only consider classes of noun,s, but the processdescribed here can also be applied to other parts ofspeech.2.1 Systematic po lysemous classesWe can arrive at classes of systematically poly-semous lexical items by investigating which itemsshare the same senses and are thus polysemous inthe same way.
This comparison is done at the toplevels of the WORDNET hierarchy.
WORDNET doesnot have an explicit level structure, but for the pur-pose of this research one can distinguish a set of 32=basic senses' that partly coincides with, but is notbased directly on WORDNET 'S  list of 26 'top types':act (act), agent (agt), animal (~.m),artifact (art) ,  attr ibute (air) ,  blun-der (bln), cell (cel), chemical (chm),communication (corn),event (evl;), food (rod), form (frm),group_biological (grb), group (grp),group_social (grs), h -m~n (hum), lln-ear_measure (1me), location (loc), 1o-cation_geographical (log), measure(mea), natural_object (nat), phe-nomenon (p\]m), plant (plt),  posses-sion (pos), part (prt), psychological(psy), quantity_definite (qud), quan-tity_indefinite (qui), relation (re1),space (spc), state (sta), t ime (tree)Figure 3 shows their distribution among noun stemsin the BROWN corpus.
For instance there are 2550different noun stems (with 49,824 instances) thathave each 2 out of the 32 'basic senses' assigned tothem in 238 different combinations (a subset of 322= 1024 possible combinations).We now reduce all of WORDNET 'S  sense assignmentsto these basic senses.
For instance, the seven differ-ent senses that WORDNET assigns to the lexical itembook (see Figure I above) can be reduced to the twobasic senses: 'art corn'.
We do this for each lexicalitem and then group them into classes according totheir assignments.From these one can filter out those classes that haveonly one member  because they obviously do not rep-resent a systematically polysemous class.
The lexicalitems in those classes have a highly idiosyncratic be-havior and are most likely homonyms.
This leaves27senses comb's stems instances2 238 2550 498243 379 936 356084 268 347 225435 148 154 153456 52 52 59157 27 27 50738 10 10 32739 3 3 1450I0 1 1 48311 2 2 95912 1 1 4411161 10797 140914Figure 3: Polysemy of nouns in BROWNa set of 442 polysemous classes, of which Figure 4gives a selection:act art evt relact art logact evt natchin stacom prtfrm staline qudloc psylog pos staphm postel staclick modification reverseberth habitation mooringascent climbgrease ptomaineappendix brickbat indexsolid vacancy voidem fathom fthm inch milbourn bourne demarcationfairyland rubicon trend vertexbarony provinceaccretion usance wastagebaronetcy connectednesscontext efficiency inclusionliquid relationshipFigure 4: A selection of polysemous classesNot all of the 442 classes are systematically polyse-mous.
Consider for example the following classes:Some of these classes are collections of homonymsthat are ambigtzotz,s in similar ways, but do not leadto any kind of predictable polysemous behavior, forinstance the class 'act anm art' with the lexicalitems: drill ruff solitaire stud.
Other classes con-sist of both homonyms and systematically polyse-mous lexical items like the class act log, which in-cludes caliphate, clearing, emirate, prefecture, repair,wheeling vs. bolivia, charleston, chicago, michigan.mmact  ~nm ar tact logact pltaxt rod locchmpsyrod hum pltdrill ruff solitaire studbolivia caliphate charlestonchicago clearing emirate michiganprefecture repair santiago wheelingchess grapevine rapepike portcomplex incensemandarin sage swedeFigure 5: A selection of ambiguous classesWhereas the first group of nouns express two sepa-rated but related meanings (the act of clearing, re-pair, etc.
takes place at a certain location), thesecond group expresses two meanings that are notrelated (the charleston dance which was named afterthe town by the same name).The ambiguous classes need to be removed alto-gether, while the ones with mixed ambiguous andpolllsemous lexical items are to be weeded out care-fully.2.2 Underspecif ied semantic typesThe next step in the research is to organize the re-maining classes into knowledge representations thatrelate their senses to each other.
These representa-tions are based on Generative Lexicon theory (G?
),using qualia roles and (dotted) types (Pustejovsky,19os).Qualia roles distinguish different semantic aspects:FORMAL ind icates  semantic type; CONSTITUTIVEpart-whole information; AGENTIVE and  TELIC asso -c ia ted  events (the first dealing with the origin ofthe object, the second with its purpose).
Each roleis typed to a specific class of lexical items.
Typesare either simple (human, artifact,...) or complex(e.g., information.physical).
Complex types arecalled dotted types after the 'dots' that are used astype constructors.
Here I introduce two kinds ofdots:Closed clots ' . '
connect systematically re-lated types that are always interpreted si-multaneonsly.Open dots 'o' connect systematically re-lated types that are not (normally) inter-preted simultaneously.Both '#*~" and 'aor' denote sets of pairs of objects(a, b), a an object of type ~ and b an object of type~'.
A condition aRb restricts this set of pairs to onlythose for which some relation R holds, where R de-notes a subset of the Cartesian product of the setsof type ~ objects and type r objects.The difference between types '#or' and 'cot' is inthe nature of the objects they denote.
The type'aer' denotes sets of pairs of objects where eachpair behaves as a complex object in discourse struc-ture.
For instance, the pairs of objects that are in-troduced by the type informationephysical (book,journal, scoreboard .... ) are addressed as the complexobjects (x:information, y:physical) in discourse.On  the other hand, the type '#or' denotes simplya set of pairs of objects that do not occur togetherin discourse structure.
For instance, the pairs of ob-jects that are introduced by the type form.artifact(door, gate, window .
.
.
.  )
are not (normally) ad-dressed simultaneously in discourse, rather one sideof the object is picked out in a particular context.Nevertheless, the pair as a whole remains active dur-ing processing.The resulting representations can be seen as under-specified lexical meanings and are therefore referredto as underspecified semantic types.
CORELEX cur-rently covers 104 underspecified semantic types.This section presents a number of examples, for acomplete overview see the CORELEX webpage:ht tp : / /~ ,  ca.
brandeis, edu/"paulb/Cor eLex/corelex, htmlClosed Dots Consider the underspecified repre-sentation for the semantic type actorelation:FORMAL = Q:act.relat ionCONSTITUTIVE =X:act V Y:relation V Z:act,relationTELIC ---P:event (acterelation) A act (R1) Arelation(R2,Rs)Figure 6: Representation for type: actorelationThe representation introduces a number of objectsthat are of a certain type.
The FORMAL role in-troduces an object Q of type actorelation.
TheCONSTITUTIVE introduces objects that are in a part-whole relationship with Q.
These are either of thesame type actorelation or of the simple types act orrelation.
The TELIC expresses the event P that canbe associated with an object of type acterelation.For instance, the event of increase as in 'increasing thecommunication between member states' implies 'in-creasing' both the act of communicating an object28mmmmmmmmm\[\]mmmmmmmmmmmmmmmmmmmmmmRI and the communication relation between twoobjects R2 and Rs.
All these objects are introducedon the semantic level and correspond to a numberof objects that will be realized in syntax.
However,not all semantic objects will be realized in syntax.
(See Section 3.4 for more on the syntax-semanticsinterface.
)The instances for the type act*relation are givenin Figure 7, covering three different systematic pol-ysemous classes.
We could have chosen to includeonly the instances of the 'act rel' class, but thenouns in the other two classes seem similar enoughto describe all of them with the same type.generative the lexicon should be and if one allowsovergeneration f semantic objects..nm rod  bluepoint capon clam cockle crawdadcrawfish crayfish duckling fowlgrub hen lamb langouste limpetlobster monkfish mussel octopus panfishpartridge pheasant pigeon poultryprawn pullet quail saki scallopscollop shellfish shrimp snailsquid whelk whitebait whitefish winkleact evt relact relact rel s~ablend competition fluxtransformationacceleration communicationdealings designation discourse gaitglide likening negation neologismneology prevention qualifyingsharing synchronisationsynchronization synchronizingcoordination gradation involvementFigure 7: Instances for the type: act*relationOpen Dots The type act .relat ion describes in-terpretations that can not be separated from eachother (the act and relation aspects are intimatelyconnected).
The following representation for type-nimalofood escribes interpretations that can notoccur simultaneously but are however elated ~.
Ittherefore uses a 'o' instead of a ' . '
as a type con-structor:FORMAL = Q:animalofoodCONSTITUTIVE = X:an~mal V Y:foodTELIC =Pz :act (Rz,"n|mal) V P2 :act (animal,R2)v P3:act(R3,food)Figure 8: Representation fortype: animalofoodThe instances for this type only cover the class ' ~,mrod'.
A case could be made for including also everyinstance of the class c~-m' because in principal everyanimal could be eaten.
This is a question of how1See the literature on animal grinding, for instance(Copestake and Briscoe, 1992)29Figure 9: Instances for the type: animalofood2.3 HomonymsCORELEX is designed around the idea of system-atic polysemons classes that exclude homonyms.Traditionally a lot of research in lexical semanticshas been occupied with the problem of ambiguityin homonyms.
Our research shows however thathomonyms only make up a fraction of the whole ofthe lexicon of a language.
Out of the 37,793 nounstems that were derived from WORDNET 1637 areto be viewed as true homonyms because they havetwo or more unrelated senses, less than 5%.
The re-maining 95% are nouns that do have (an indefinitenumber of) different interpretations, hut all of theseare somehow related and should be inferred from acommon knowledge representation.
These numberssuggest a stronger emphasis in research on system-atic polysemy and less on homonyms, an approachthat is advocated here (see also (Killgariff, 1992)).In CORZLEX homonyms are simply assigned two ormore underspecified semantic types, that need to bedisambiguated in a traditional way.
There is how-ever an added value also here because ach disam-biguated type can generate any number of contextdependent interpretations.3 Adapt ing  CORELEx to  DomainSpeci f ic  CorporaThe underspectfied semantic type that CORELEX as-signs to a noun provides a basic lexical semanticstructure that can be seen as the class-wide back-bone semantic description on top of which specificinformation for each lexical item is to be defined.That is, doors and gates are both artifacts but theyhave different appearances.
Gates are typically openconstructions, whereas doors tend to be solid.
Thiskind of information however is corpus specific andtherefore needs to be adapted specifically to and onthe basis of that particular corpus of texts.This process involves a number of consecutive stepsthat includes the probabilistic lassification of un-known lexical items:1.
Assignment of underspecified semantic tags tothose nouns that are in CORELEX2.
Running class-sensitive patterns over the(partly) tagged corpus3.
(a) Constructing a probabilistic classifier fromthe data obtained in step 2.
(b) Probabilistically tag nouns that are not inCORELEX according to this classifier4.
Relating the data obtained in step 2. to one ormore qualia rolesStep 1. is trivial, but steps 2. through 4. forma complex process of constructing a corpus specificsemantic lexicon that is to be used in additionalprocessing for knowledge intensive reasoning steps(i.e.
abduction (Hobbs et al, 1993)) that would solvemetaphoric, metonymic and other non-literal use oflanguage.3.1 Assignment of CORELEX TagsThe first step in analyzing a new corpus involvestagging each noun that is in CORELEX with an un-derspecified semantic tag.
This tag represents hefollowing information: a definition of the type ofthe noun (FORMAL); a definition of types of pos-sible nouns it can stand in a part-whole relation-ship with (CONSTITUTIVE); a definition of types ofpossible verbs it can occur with and their argumentstructures (AGENTIVE / TELIC).
CORELEX is imple-mented as a database of associative arrays, whichallows a fast lookup of this information in patternmatching.3.2 Class-Sensitive Pattern MatchingThe pattern matcher runs over corpora that are:part-of-speech tagged using a widely used tagger(Brill, 1992); stemmed by using an experimental sys-tem that extends the Porter stemmer, a stemmingalgorithm widely used in information retrieval, withthe Celex database on English morphology; (partly)semantically tagged using the CORELEX set of un-derspecified semantic tags as discussed in the previ-ous section.There are about 30 different patterns that are ar-ranged around the headnoun of an NP.
They cover30the following syntactic onstructions that roughlycorrespond to a VP, an S, an NP and an NP fol-lowed by a PP:?
verb-headnoun?
headnoun-verb?
ad ject ive -headnoun?
modif lernoun-headnoun?
headnoun-preposition-headnounThe patterns assume NP's of the following genericstructure 2:PreDet* Det* Num* (Adj INamelNoun)* NounThe heuristics for finding the headnoun is then sim-ply to take the rightmost noun in the NP, which forEnglish is mostly correct.The verb-headnoun patterns approach that of atrue 'verb-obj' analysis by including anormalizationof passive constructions a follows:\[Noun Have?
Be Adv?
Verb\] =~ \[Verb Noun\]Similarly, the headnoun-verb patterns approacha true 'sub j-verb' analysis.
However, because nodeep syntactic analysis is performed, the patternscan only approximate subjects and Objects in thisway and I therefore do not refer to these patterns as'subject-verb' and 'verb-object' respectively.The pattern matching isclass-sensitive in employingthe assigned CORELEX tag to determine if the appli-cation of this pattern is appropriate.
For instance,one of the headnoun-preposit ion-headnoun pat-terns is the following, that is used to detect part-whole (CONSTITUTIVE) relations:PreDet* Det* Num* (Adj \[ Name \[ Noun)* Noun ofPreDet* Det* Num* (Adj \[NameJNoun)* NounClearly not every syntactic construction that fits thispattern is to be interpreted as the expression of apart-whole relation.
One of the heuristics we there-fore use is that the pattern may only apply if bothhead nouns carry the same CORELEx tag or if thetag of the second head noun subsumes the tag of thefirst one through a dotted type.
That is, if the sec-ond head noun is of a dotted type and the first is ofone of its composing types.
For instance, 'paragraph'~The interpretation of '*' and '?'
in this section fol-lows that of common usage in regular expressions: 'windicates 0 or more occurrences; '?'
indicates 0 or 1occurrenceand 'journal' can be in a part-whole relation to eachother because the first is of type in format ion,  whilethe second is of type informat ion*physical .
Simi-lar heuristics can be identified for the application ofother patterns.Recall of the patterns (percentage of nouns thatare covered) is on average, among different cor-pora (wsJ, BROWN,  PDGF - a corpus we constructedfor independent purposes from 1000 medical ab-stracts in the MEDLINE database on Platelet DerivedGrowth Factor - and DARWIN - the complete Originof Species), about 70% to 80%.
Precision is muchharder to measure, but depends both on the accu-racy of the output of the part-of-speech tagger andon the accuracy of class-sensitive h uristics.3.3 Probabilistic ClassificationThe knowledge about the linguistic context of nounsin the corpus that is collected by the pattern matcheris now used to classify unknown ouns.
This involvesa similarity measure between the linguistic contextsof classes of nouns that are in CORELEX and thelinguistic context of unknown nouns.
For this pur-pose the pattern matcher keeps two separate arrays,one that collects knowledge only on COrtELEx nounsand the other collecting knowledge on all nouns.The classifier uses mutual information (MI) scoresrather than the raw frequences of the occurring pat-terns (Church and Hanks, 1990).
Computing MIscores is by now a standard procedure for measuringthe co-occurrence between objects relative to theiroverall occurrence.
MI is defined in general as fol-lows:y)I ix y) = log2 P(x) P(y)We can use this definition to derive an estimate ofthe connectedness between words, in terms of collo-cations (Smadja, 1993), but also in terms of phrasesand grammatical relations (Hindle, 1990).
For in-stance the co-occurrence of verbs and the heads oftheir NP objects iN: size of the corpus, i.e.
the num-ber of stems):N Cobj (v n) = log2 /(v) /(n)N NAll nouns are now classified by running a simi-laxity measure over their MI scores and the MIscores of each CoRELEx class.
For this we use theJaccard measure that compares objects relative tothe attributes they share (Grefenstette, 1994).
Inour case the 'attributes' are the different linguisticconstructions a noun occurs in: headnoun-verb,ad ject ive-headnoun,  modi f iernoun-headnoun,etc .The Jaccard measure is defined as the number ofattributes shared by two objects divided by the totalnumber of unique attributes shared by both objects:AA+B+CA : attributes hared by both objectsB : attributes unique to object 1C : attributes unique to object 2The Jaccard scores for each CORELEx class aresorted and the class with the highest score is as-signed to the noun.
If the highest score is equal to0, no class is assigned.The classification process is evaluated in terms ofprecision and recall figures, but not directly on theclassified unknown nouns, because their precision ishard to measure.
Rather we compute precision andrecall on the classification of those nouns that are inCoreLex, because we can check their class automati-cally.
The assumption then is that the precision andrecall figures for the classification of nouns that areknown correspond to those that are unknown.
Anadditional measure of the effectiveness of the clas-sifter is measuring the recall on classification of allnouns, known and unknown.
This number seems tocorrelate with the size of the corpus, in larger cor-pora more nouns are being classified, but not nec-essarily more correctly.
Correct classification ratherseems to depend on the homogeneity of the corpus:if it is written in one style, with one theme and soon.Recall of the classifier (percentage of all nouns thatare classified > 0) is on average, among differentlarger corpora (> 100,000 tokens), about 80% to90%.
Recall on the nouns in CoRELEx is between35% and 55%, while precision is between 20% and40%.
The last number is much better on smaller cor-pora (70% on average).
More detailed informationabout the performance ofthe classifier, matcher andacquisition tool (see below) can be obtained from(Buitelaar, forthcoming).3.4 Lexical  Knowledge AcquisitionThe final step in the process of adapting CORELExto a specific domain involves the 'translation' of ob-served syntactic patterns into corresponding seman-tic ones and generating a semantic lexicon represent-ing that information.31There are basically three kinds of semantic patternsthat are utilized in a CORELEX lexicon: hyponymy(sub-supertype information) in the FORMAL role,meronymy (part-whole information) in the CONSTI-TUTIVE role and predicate-argument structure in theTELIC and AGENTIVE roles.
There are no compellingreasons to exclude other kinds of information, butfor now we base our basic design on ~?,  which onlyincludes these three in its definition of qualia struc-ture.Hyponymic information is acquired through the clas-sification process discussed in Sections 2.2 and 3.3.Meronymic information is obtained through a trans-lation of various VP  and PP  patterns into 'has-part'and 'part-of' relations.
Predicate-argument struc-ture finally, is derived from verb-headnoun andheadnoun-verb constructions.The semantic lexicon that is generated in such away comes in two formats: T2)?, a Type De-scription Language based on typed feature-logic(Krieger and Schaefer, 1994a) (Krieger and Schae-fer, 1994b) and HTML, the markup language for theWorld Wide Web.
The first provides a constraint-based formalism that allows CORELEX lexicons tobe used stralghtforwardiy in constraint-based gram-mars.
The second format is used to present a gen-erated semantic lexicon as a semantic index on aWorld Wide Web document.
We will not elaborateon this further because the subject of semantic in-dexing is out of the scope of this paper, but we referto (Pustejovsky et al, 1997).3.5 An Example: The PDGF LexiconThe semantic lexicon we generated for the PDGFcorpus covers 1830 noun stems, spread over 81CORELEX types.
For instance, the noun evidenceis of type communication.psychological  and thefollowing representation is generated:4 Conc lus ionIn this paper I discuss the construction of a newtype of semantic lexicon that supports underspeci-fled semantic tagging.
Traditional semantic taggingassumes a number of distinct senses for each lexicalitem between which the system should choose.
Un-derspecified semantic tagging however assumes nofinite lists of senses, but instead tags each lexicalitem with a comprehensive knowledge representa-tion from which a specific interpretation can be con-structed.
CORZLEx provides uch knowledge rep-resentations, and as such it is fundamentally differ-ent from existing semantic lexicons like WORDNET.32"evidenceFORMAL "-= \[ARG1 = commlmlcat ion \ ] \ ]CLOSED LARG2 psychological J JCONSTITUTIVE -~I HAS-PAI~ -----TELIC = ip ov,.e \] FIRSTL ARG-STRUCT ---~ ...REST ---- .o.FIRST = structure\]  1REST ...Figure 10: Lexical entry for: evidenceAdditionally, it was shown that Co I~LEx  providesfor more consistent assignments of lexical semanticstructure among classes of lexical items.
Finally,the approach described above allows one to gener-ate domain specific semantic lexicons by enhancingCORELEX lexical entries with corpus based informa-tion.ReferencesBriU, Eric.
1992.
A simple rule-based part of speechtagger.
In Procee~ngs ofthe Third Conference onApplied Natural Language Processing.
ACL.Buitelaar, Paul.
forthcoming.
CORELEX: AnAdaptable Semantic Lexicon with Systematic Pol-ysemous Classes.
Ph.D. thesis, Brandeis Univer-sity, Department of Computer Science.Church, K. W.  and P. Hanks.
1990.
Word associa-tion norms, mutual information, and lexicography.Computational Linguistics, 16:22-29.Copestake, A. and E. Briscoe.
1992.
Lexical opera-tions in a unification-based framework.
In JamesPustejovsky and Sabine Bergler, editors, Lez/ca/Semantics and Knowledge Representation.
Lec-ture Notes in Artificial Intelligence 627, pages 22-29, Berlin.
Springer Verlag.Grefenstette, Gregory.
1994.
Explorations in Au-tomatic Thesaurus Discovery.
Kluwer AcademicPress, Boston.Hindle, Donald.
1990.
Noun classification frompredicate-argument structures.
In Proceedings ofthe 28th Annual Meeting of the ACL, pages 268-275.Hobbs, J., M. Stickel, P. Martin, and D. Edwards.1993.
Interpretation asabduction.
Artificial In-teUigence, 63.KiUgariff, Adam.
1992.
Polysemy.
Ph.D. thesis,University of Sussex, Brighton.Krieger, Hans-Ulrich and Ulrich Schaefer.
1994a.Tdl-a type description language for hpsg.
partl:Overview.
Technical Report RR-94-37, DFKI,Saarbruecken, Germany.Krieger, Hans-Ulrich and Ulrich Schaefer.
1994b.Tdloa type description language for hpsg.
part2:Reference manual.
Technical Report D-94-14,DFKI, Saarbruecken, Germany.Pustejovsky, J., B. Boguraev, M. Verhagen, P.P.Buitelaar, and M. Johnston.
1997.
Semantic in-dexing and typed hyperlinking.
In AAAI Spring1997 Workshop on Natural Language Processingfor the World Wibe Web.Pustejovsky, James.
1995.
The Generative Lexicon.MIT Press, Cambridge, MA.Pustejovsky, James, Bran Boguraev, and MichaelJohnston.
1995.
A core lexical engine: The con-textual determination f word sense.
Technicalreport, Department of Computer Science, Bran-deis University..Smadja, Frank.
1993.
Retrieving collocations fromtext: Xtraet.
Computational Linguistics, 19(1).Stevenson, Mark and Yorick Wilks.
1997.
Thegrammar of sense: Is word-sense tagging muchmore than part-of-speech tagging?
To appear ina Special Issue of Computational Linguistics onWord sense Disambiguation.Yarowsky, David.
1992.
Word sense disambigua-tion using statistical models of roget's categoriestrained on large corpora.
In Proceedings ofCOL-ING92, pages 454-460.33
