Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1057?1067,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsCross Language Text Classification by Model Translation andSemi-Supervised LearningLei ShiYahoo!
Global R&DBeijing, Chinalshi@yahoo-inc.comRada MihalceaUniversity of North TexasDenton, TX, U.S.A.rada@cs.unt.eduMingjun TianYahoo!
Global R&DBeijing, Chinamingjun@yahoo-inc.comAbstractIn this paper, we introduce a method that au-tomatically builds text classifiers in a new lan-guage by training on already labeled data inanother language.
Our method transfers theclassification knowledge across languages bytranslating the model features and by usingan Expectation Maximization (EM) algorithmthat naturally takes into account the ambigu-ity associated with the translation of a word.We further exploit the readily available un-labeled data in the target language via semi-supervised learning, and adapt the translatedmodel to better fit the data distribution of thetarget language.1 IntroductionGiven the accelerated growth of the number of mul-tilingual documents on the Web and elsewhere, theneed for effective multilingual and cross-lingual textprocessing techniques is becoming increasingly im-portant.
There is a growing number of methods thatuse data available in one language to build text pro-cessing tools for another language, for diverse taskssuch as word sense disambiguation (Ng et al, 2003),syntactic parsing (Hwa et al, 2005), information re-trieval (Monz and Dorr, 2005), subjectivity analysis(Mihalcea et al, 2007), and others.In this paper, we address the task of cross-lingualtext classification (CLTC), which builds text classi-fiers for multiple languages by using training data inone language, thereby avoiding the costly and time-consuming process of labeling training data for eachindividual language.
The main idea underlying ourapproach to CLTC is that although content can beexpressed in different forms in different languages,there is a significant amount of knowledge that isshared for similar topics that can be effectively usedto port topic classifiers across languages.Previous methods for CLTC relied mainly on ma-chine translation, by translating the training data intothe language of the test data or vice versa, so thatboth training and test data belong to the same lan-guage.
Monolingual text classification algorithmscan then be applied on these translated data.
Al-though intuitive, these methods suffer from two ma-jor drawbacks.First, most off-the-shelf machine translation sys-tems typically generate only their best translation fora given text.
Since machine translation is knownto be a notoriously hard problem, applying mono-lingual text classification algorithms directly on theerroneous translation of training or test data mayseverely deteriorate the classification accuracy.Second, similar to domain adaptation in statisti-cal machine learning, due to the discrepancy of datadistribution between the training domain and test do-main, data distribution across languages may varybecause of the difference of culture, people?s inter-ests, linguistic expression in different language re-gions.
So even if the translation of training or testdata is perfectly correct, the cross language classi-fier may not perform as well as the monolingual onetrained and tested on the data from the same lan-guage.In this paper, we propose a new approach toCLTC, which trains a classification model in thesource language and ports the model to the targetlanguage, with the translation knowledge learned us-ing the EM algorithm.
Unlike previous methodsbased on machine translation (Fortuna and Shawe-Taylor, 2005), our method takes into account dif-1057ferent possible translations for model features.
Thetranslated model serves as an initial classifier for asemi-supervised process, by which the model is fur-ther adjusted to fit the distribution of the target lan-guage.
Our method does not require any labeleddata in the target language, nor a machine transla-tion system.
Instead, the only requirement is a rea-sonable amount of unlabeled data in the target lan-guage, which is often easy to obtain.In the following sections, we first review relatedwork.
In section 3, we introduce our method thattranslates the classification model with the trans-lation knowledge learned using the EM algorithm.Section 4 describes model adaptation by training thetranslated model with unlabeled documents in thetarget language.
Experiments and evaluations arepresented in section 5 and finally we conclude thepaper in section 6.2 Related WorkText classification has rightfully received a lot of at-tention from both the academic and industry com-munities, being one of the areas in natural languageprocessing that has a very large number of practi-cal applications.
Text classification techniques havebeen applied to many diverse problems, rangingfrom topic classification (Joachims, 1997), to genredetection (Argamon et al, 1998), opinion identifica-tion (Pang and Lee, 2004), spam detection (Sahamiet al, 1998), gender and age classification (Schler etal., 2006).Text classification is typically formulated as alearning task, where a classifier learns how to distin-guish between categories in a given set, using fea-tures automatically extracted from a collection ofdocuments.
In addition to the learning methodol-ogy itself, the accuracy of the text classifier also de-pends to a large extent upon the amount of trainingdata available at hand.
For instance, distinguish-ing between two categories for which thousands ofmanually annotated examples are already availableis expected to perform better than trying to separatecategories that have only a handful of labeled docu-ments.Some of the most successful approaches to datefor text classification involve the use of machinelearning methods, which assume that enough an-notated data is available such that a classificationmodel can be automatically learned.
These includealgorithms such as Naive Bayes (Joachims, 1997;McCallum and Nigam, 1998), Rocchio classifiers(Joachims, 1997; Moschitti, 2003), Maximum En-tropy (Nigam et al, 1999) or Support Vector Ma-chines (Vapnik, 1995; Joachims, 1998).
If onlya small amount of annotated data is available, thealternative is to use semi-supervised bootstrappingmethods such as co-training or self-training, whichcan also integrate raw unlabeled data into the learn-ing model (Blum and Mitchell, 1998; Nigam andGhani, 2000).Despite the attention that monolingual text clas-sification has received from the research commu-nity, there is only very little work that was doneon cross-lingual text classification.
The work thatis most closely related to ours is (Gliozzo and Strap-parava, 2006), where a multilingual domain kernel islearned from comparable corpora, and subsequentlyused for the cross-lingual classification of texts.
Inexperiments run on Italian and English, Gliozzo andStrapparava showed that the multilingual domainkernel exceeds by a large margin a bag-of-words ap-proach.
Moreover, they demonstrated that the useof a bilingual dictionary can drastically improve theperformance of the models learned from corpora.
(Fortuna and Shawe-Taylor, 2005; Olsson et al,2005) studied the use of machine translation toolsfor the purpose of cross language text classificationand mining.
These approaches typically translatethe training data or test data into the same language,followed by the application of a monolingual classi-fier.
The performance of such classifiers very muchdepends on the quality of the machine translationtools.
Unfortunately, the development of statisticalmachine translation systems (Brown et al, 1993) ishindered by the lack of availability of parallel cor-pora and the quality of their output is often erro-neous.
Several methods were proposed (Shi et al,2006; Nie et al, 1999) to automatically acquire alarge quantity of parallel sentences from the web,but such web data is however predominantly con-fined to a limited number of domains and languagepairs.
(Dai et al, 2007) experimented with the use oftransfer learning for text classification.
Although inthis method the transfer learning is performed across1058different domains in the same language, the under-lying principle is similar to CLTC in the sense thatdifferent domains or languages may share a signif-icant amount of knowledge in similar classificationtasks.
(Blum and Mitchell, 1998) employed semi-supervised learning for training text classifiers.
Thismethod bootstraps text classifiers with only unla-beled data or a small amount of labeled training data,which is close to our setting that tries to leverage la-beled data and unlabeled data in different languagesto build text classifiers.Finally, also closely related is the work carried outin the field of sentiment and subjectivity analysisfor cross-lingual classification of opinions.
For in-stance, (Mihalcea et al, 2007) use an English corpusannotated for subjectivity along with parallel text tobuild a subjectivity classifier for Romanian.
Sim-ilarly, (Banea et al, 2008) propose a method basedon machine translation to generate parallel texts, fol-lowed by a cross-lingual projection of subjectivitylabels, which are used to train subjectivity annota-tion tools for Romanian and Spanish.
A related, yetmore sophisticated technique is proposed in (Wan,2009), where a co-training approach is used to lever-age resources from both a source and a target lan-guage.
The technique is tested on the automatic sen-timent classification of product reviews in Chinese,and showed to successfully make use of both cross-language and within-language knowledge.3 Cross Language Model TranslationTo make the classifier applicable to documents ina foreign language, we introduce a method wheremodel features that are learned from the trainingdata are translated from the source language intothe target language.
Using this translation process,a feature associated with a word in the source lan-guage is transferred to a word in the target languageso that the feature is triggered when the word occursin the target language test document.In a typical translation process, the features wouldbe translated by making use of a bilingual dictio-nary.
However, this translation method has a majordrawback, due to the ambiguity usually associatedwith the entries in a bilingual dictionary: a word inone language can have multiple translations in an-other language, with possibly disparate meanings.If an incorrect translation is selected, it can distortthe classification accuracy, by introducing erroneousfeatures into the learning model.
Therefore, our goalis to minimize the distortion during the model trans-lation process, in order to maximize the classifica-tion accuracy in the target language.In this paper, we introduce a method that em-ploys the EM algorithm to automatically learn fea-ture translation probabilities from labeled text in thesource language and unlabeled text in the target lan-guage.
Using the feature translation probabilities,we can derive a classification model for the targetlanguage from a mixture model with feature transla-tions.3.1 Learning Feature Translation Probabilitieswith EM AlgorithmGiven a document d from the document collectionDin the target language, the probability of generatingthe document P (d) is the mixture of generating dwith different classes c ?
C:P (d) =?cP (d|c)P (c)In our cross-lingual setting, we view the generationof d given a class c as a two step process.
In thefirst step, a pseudo-document d?
is generated in thesource language, followed by a second step, whered?
is translated into the observed document d in thetarget language.
In this generative model, d?
is a la-tent variable that cannot be directly observed.
Sinced could have multiple translations d?
in the sourcelanguage, the probability of generating d can thenbe reformulated as a mixture of probabilities as inthe following equation.P (d) =?cP (c)?d?P (d|d?, c)P (d?|c)According to the bag-of-words assumption,the document translation probability P (d|d?, c) isthe product of the word translation probabilitiesP (wi|w?i, c) , where w?i in d?
is the source languageword that wi is translated from.
P (d?|c) is the prod-uct of P (w?i|c).
The formula is rewritten as:P (d) =?cP (c)?d?l?i=1P (wi|w?i, c)P (w?i|c)1059where wi is the ith word of the document d with lwords.
The prior probability P (c) and the proba-bility of the source language word w?
given class care estimated using the labeled training data in thesource language, so we use them as known parame-ters.
P (wi|w?i, c) is the probability of translating theword w?i in the source language to the word wi inthe target language given class c, and these are theparameters we want to learn from the corpus in thetarget language.Using the Maximum Likelihood Estimation(MLE) framework, we learn the model parameters ??
the translation probability P (wi|w?i, c) ?
by max-imizing the log likelihood of a collection of docu-ments in the target language:??
= argmax?m?j=1log(P (dj , ?
))= argmax?m?j=1log(?cP (c)?d?lj?i=1P (wi|w?i, c)P (w?i|c))where m is the number of documents in the corpusin the target language and lj is the number of wordsin the document dj .In order to estimate the optimal values of the pa-rameters, we use the EM algorithm (Dempster et al,1977).
At each iteration of EM we determine thosevalues by maximizing the expectation using the pa-rameters from the previous iteration and this itera-tive process stops when the change in the parametersis smaller than a given threshold.
We can repeat thefollowing two steps for the purpose above.?
E-stepP (w?c|w) ?
P (cw?w)P (w)= P (w|w?c)P (w?c)?c?w?
P (w|w?c)P (w?c)(1)?
M-stepP (w|w?c)?
f(w)P (w?c|w)?w?K f(w)P (w?c|w)(2)Algorithm 1 EM algorithm for learning translationprobabilitiesDl ?
labeled data in the source languageDu ?
unlabeled data in the target languageL?
bilingual lexicon1: Initialize P0(w|w?c) = 1nw?
, where (w,w?)
?
L,otherwise P0(w|w?c) = 0;2: Compute P (w?c) with Dl according to equa-tion 33: repeat4: Calculate Pt(w?c|w) with Du based onPt?1(w|w?c) according to equation 15: Calculate Pt(w|w?c) based on Pt?1(w?c|w)according to equation 26: until change of P (w|w?c) is smaller than thethreshold7: return P (w|w?c)Here f(w) is the occurrence frequency of the wordw in the corpus.
K is the set of translation candi-dates in the target language for the source languagewordw?
according to the bilingual lexicon.
P(w?c) isthe probability of occurrence of the source languageword w?
under the class c. It can be estimated fromthe labeled source language training data availableas follows and it is regarded as a known parameterof the model.P (w?c) = f(w?c)?w?
?V f(w?c)(3)where V is the vocabulary of the source language.Algorithm 1 illustrates the EM learning process,where nw?
denotes the number of translation candi-dates for w?
according to the bilingual lexicon.Our method requires no labeled training datain the target language.
Many statistical machinetranslation systems such as IBM models (Brownet al, 1993) learn word translation probabilitiesfrom millions of parallel sentences which are mu-tual translations.
However, large scale parallel cor-pora rarely exist for most language pairs.
(Koehnand Knight, 2000) proposed to use the EM algo-rithm to learn word translation probabilities fromnon-parallel monolingual corpora.
However, thismethod estimates only class independent transla-tion probabilities P (wi|w?i), while our approach isable to learn class specific translation probabilities1060P (wi|w?i, c) by leveraging available labeled trainingdata in the source language.
For example, the prob-ability of translating ?bush?
as ????
(small trees)is higher than translating as ????
(U.S. president)when the category of the text is ?botany.
?3.2 Model TranslationIn order to classify documents in the target language,a straightforward approach to transferring the classi-fication model learned from the labeled source lan-guage training data is to translate each feature fromthe bag-of-words model according to the bilinguallexicon.
However, because of the translation ambi-guity of each word, a model in the source languagecould be potentially translated into many differentmodels in the target language.
Thus, we think ofthe probability of the class of a target language doc-ument as the mixture of the probabilities by eachtranslated model from the source language model,weighed by their translation probabilities.P (c|d,mt) ?
?m?tP (m?t|ms, c)P (c|d,m?t)where mt is the target language classification modeland m?t is a candidate model translated from themodel ms trained on the labeled training data inthe source language.
This is a very generic rep-resentation for model translation and the model mcould be any type of text classification.
Specificallyin this paper, we take the Maximum Entropy (ME)model(Berger et al, 1996) as an example for themodel translation across languages, since the MEmodel is one of the most widely used text classifica-tion models.
The maximum entropy classifier takesthe formP (c|d) = 1Z(d)?w?Ve?wf(w,c)where: V is the vocabulary of the language; f(w, c)is the feature function associated with the word wand class c and its value is set to 1 when w occurs ind and the class is c or otherwise 0.
?w is the featureweight for f(wi, c) indicating the importance of thefeature in the model.
During model translation, thefeature weight for f(wi, c) is transferred to f(w?i, c)in the target language model, where w?i is the trans-lation of wi.
Z(d) is the normalization factor whichis invariant to c and hence we can omit it for classi-fication since our objective is to find the best c. Ac-cording to the formulation of the Maximum Entropymodel, the document can be classified as follows.c?
= argmaxc?C?m?tP (m?t|ms, c)v?i=1e?wisf(wit,c)The model translation probability P (m?t|ms, c) canbe modeled as the product of the translation proba-bilities of each of its individual bag-of-words fea-tures P (m?t|ms, c) ?
?li=1 P (wit|wis, c) and theclassification model can be further written asc?
= argmaxc?C?m?tv?i=1P (wit|wis, c)e?wisf(wit,c)where feature translation probabilities P (wit|wis, c)are estimated with the EM algorithm described inthe previous section.
Note that if the average numberof translations for a word w is n and v is the num-ber of words in the vocabulary there are nv possiblemodels m?t translated from ms.
However, we cando the following mathematical transformation on theequation which leads to a polynomial time complex-ity algorithm.
The idea is that instead of enumerat-ing the exponential number of different translationsof the entire model, we will instead handle one fea-ture at a time.
?m?tv?i=1P (wit|wis, c)e?wisf(wit,c) =n1?j=1P (w1jt |w1s , c)e?1f(w1jt ,c)?m2,vtv?i=2P (wit|wis, c)e?if(wit,c)Here w1 is the first word in the vocabulary of thesource language and w1j is a translation of w1 in thetarget language with n denoting the number its trans-lations according to the bilingual lexicon.
?m2,vtare all the target language models translated fromthe model consisting of the rest of the words w2 ...wv in the source language.
This process is recur-sive until the last word wvs of the vocabulary and thistransforms the equation into a polynomial form as1061follows.
?m?tv?i=1P (wit|wis, c)e?wisf(wit,c)=v?i=1ni?j=1P (wijt |wis, c)e?wisf(wijt ,c)Based on the above transformation, the class c?
forthe target language document d is then calculatedwith the following equation.c?
= argmaxc?Cv?i=1ni?j=1P (wijt |wis, c)e?wisf(wijt ,c)The time complexity of computing the above equa-tion is n?
v.4 Model Adaptation with Semi-Supervised LearningIn addition to translation ambiguity, another chal-lenge in building a classifier using training data ina foreign language is the discrepancy of data distri-bution in different languages.
Direct application of aclassifier translated from a foreign model may not fitwell the distribution of the current language.
For ex-ample, a text about ?sports?
in (American) Englishmay talk about ?American football,?
?baseball,?
and?basketball,?
whereas Chinese tend to discuss about?soccer?
or ?table tennis.
?To alleviate this problem, we employ semi-supervised learning in order to adapt the model tothe target language.
Specifically, we first start by us-ing the translated classifier from English as an initialclassifier to label a set of Chinese documents.
Theinitial classifier is able to correctly classify a num-ber of unlabeled Chinese documents with the knowl-edge transferred from English training data.
Forinstance, words like ?game(??),?
?score(??),??athlete(???),?
learned from English can still ef-fectively classify Chinese documents.
We then picka set of labeled Chinese documents with high con-fidence to train a new Chinese classifier.
The newclassifier can then learn new knowledge from theseChinese documents.
E.g.
it can discover that wordslike ?soccer(??)?
or ?badminton(???)?
occurfrequently in the Chinese ?sports?
documents, whilewords that are frequently occurring in English doc-uments such as ?superbowl(???)?
and ?NHL(?Algorithm 2 Semi-supervised learning for cross-lingual text classificationLs ?
labeled data in the source languageUt ?
unlabeled data in the target lan-guage1: Cs = train(Ls)2: Ct = translate(Cs)3: repeat4: Label(U,Ct)5: L?
select(confidence(U,Ct))6: Ct ?
train(L)7: until stopping criterion is met8: return Ct?????)?
do not occur as often.
Re-training theclassifier with the Chinese documents can adjust thefeature weights for these words so that the model fitsbetter the data distribution of Chinese documents,and thus it improves the classification accuracy.
Thenew classifier then re-labels the Chinese documentsand the process is repeated for several iterations.
Al-gorithm 2 illustrates this semi-supervised learningprocess.The confidence score associated with the docu-ments is calculated based on the probabilities of theclass.
For a binary classifier the confidence of clas-sifying the document d is calculated as:confidence(d) =???
?log(P (c|d)P (c|d))???
?An unlabeled document is selected as trainingdata for a new classifier when its confidence scoreis above a threshold.5 Experiments and EvaluationTo evaluate the effectiveness of our method, wecarry out several experiments.
First, we compare theperformance of our method on five different cate-gories, from five different domains, in order to seeits generality and applicability on different domains.We also run experiments with two different languagepairs - English-Chinese and English-French - to seeif the distance between language families influencesthe effectiveness of our method.To determine the performance of the method withrespect to other approaches, we compare the classi-fication accuracy with that of a machine translation1062approach that translates the training (test) data fromthe source language to the target language, as wellas with a classifier trained on monolingual trainingdata in the target language.Finally, we evaluate the performance of each ofthe two steps of our proposed method.
First, weevaluate the model translated with the parameterslearned with EM, and then the model after the semi-supervised learning for data distribution adaptationwith different parameters, including the number ofiterations and different amounts of unlabeled data.5.1 Data SetSince a standard evaluation benchmark for cross-lingual text classification is not available, we builtour own data set from Yahoo!
RSS news feeds.
Thenews feed contains news articles from October 1st2009 to December 31st 2009.
We collected a totalof 615731 news articles, categorized by their edi-tors into topics such as ?sports?
or ?business?.
Weselected five categories for our experiments, namely?sports?, ?health?, ?business?, ?entertainment?, ?ed-ucation?.
The Yahoo!
RSS news feed includesnews in many languages, including English, Chi-nese, French, Spanish, and others.We experimented on two language pairs, English-Chinese and English-French, selected for their diver-sity: English and Chinese are disparate languageswith very little common vocabulary and syntax,whereas English and French are regarded as moresimilar.
We expect to evaluate the impact of thedistance of languages on the effectiveness of ourmethod.
In both cases, English is regarded as thesource language, where training data are available,and Chinese and French are the target languagesfor which we want to build text classifiers.
Notethat regardless of the language, the documents areassigned with one of the five category labels men-tioned above.
Table 1 shows the distribution of doc-uments across categories and across languages.Category English Chinese Frenchsports 23764 14674 18398health 15627 11769 12745business 34619 23692 28740entertainment 26876 21470 23756education 16488 14353 15753Table 1: number of documents in each classBefore building the classification model, severalpreprocessing steps are applied an all the docu-ments.
First, the HTML tags are removed, and ad-vertisements and navigational information are alsoeliminated.
For the Chinese corpus, all the Chinesecharacters with BIG5 encoding are converted intoGB2312 and the Chinese texts are segmented intowords.
For the translation, we use the LDC bilin-gual dictionary1 for Chinese English and ?stardict?2 for Spanish English.5.2 Model TranslationTo transfer a model learned in one language to an-other, we can translate all the bag-of-word featuresaccording to a bilingual lexicon.
Due to the trans-lation ambiguity of each feature word, we com-pare three different ways of model translation.
Onemethod is to equally assign probabilities to all thetranslations for a given source language word, andto translate a word we randomly pick a translationfrom all of its translation candidates.
We denote thisas ?EQUAL?
and it is our baseline method.
Anotherway is to calculate the translation probability basedon the frequencies of the translation words in the tar-get language itself.
For instance, the English word?bush?
can be translated into ????
, ????
or ????
.
We can obtain the following unigram countsof these translation words in our Yahoo!
RSS newscorpus.count translation sense582 ??
Goerge W. Bush43 ??
small trees2 ??
canulaWe can estimate that P (?
?|bush) = 582/(582 +43+2) = 92.8% and so forth.
This method often al-lows us to estimate reasonable translation probabili-ties and we use ?UNIGRAM?
to denote this method.And finally the third model translation approach isto use the translation probability learned with theEM algorithm proposed in this paper.
The initialparameters of the EM algorithm are set to the prob-abilities calculated with the ?UNIGRAM?
methodand we use 4000 unlabeled documents in Chinese1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2002L272http://stardict.sourceforge.net/Dictionaries.php1063to learn translation probabilities with EM.
We firsttrain an English classification model for the topic of?sport?
and then translate the model into Chinese us-ing translation probabilities estimated by the abovethree different methods.
The three translated modelsare applied to Chinese test data and we measure theprecision, recall and F-score as shown in Table 2.Method P R FEQUAL 71.1 70.6 70.8UNIGRAM 79.5 77.8 78.6EM 83.1 84.7 83.9Table 2: Comparison of different methods for modeltranslationFrom this table we can see that the baseline methodhas lowest classification accuracy due to the fact thatit is unable to handle translation ambiguity sincepicking any one of the translation word is equallylikely.
?UNIGRAM?
shows significant improve-ment over ?EQUAL?
as the occurrence count of thetranslation words in the target language can helpdisambiguate the translations.
However occurrencecount in a monolingual corpus may not always bethe true translation probability.
For instance, theEnglish word ?work?
can be translated into ???(labor)?
and ???(factory)?
in Chinese.
How-ever, in our Chinese monolingual news corpus, thecount for ???(factory)?
is more than that of ???(labor)?
even though ???(labor)?
should be amore likely translation for ?work?.
The ?EM?
algo-rithm has the best performance as it is able to learntranslation probabilities by looking at documents inboth source language and target language instead ofjust a single language corpus.5.3 Cross Language Text ClassificationTo evaluate the effectiveness of our method on crosslanguage text classification, we implement severalmethods for comparison.
In each experiment, werun a separate classification for each class, using aone-versus-all binary classification.ML (Monolingual).
We build a monolingualtext classifier by training and testing the text classi-fication system on documents in the same language.This method plays the role of an upper-bound, sincethe best classification results are expected whenmonolingual training data is available.MT (Machine Translation).
We use the Sys-tran 5.0 machine translation system to translatethe documents from one language into the otherin two directions.
The first direction translates thetraining data from the source language into thetarget language, and then trains a model in the targetlanguage.
This direction is denoted as MTS.
Thesecond direction trains a classifier in the sourcelanguage and translates the test data into the sourcelanguage.
This direction is denoted as MTT.
Inour experiments, Systran generates the single besttranslation of the text as most off-the-shelf machinetranslation tools do.EM (Model Translation with EM).
This is thefirst step of our proposed method.
We used 4,000unlabeled documents to learn translation proba-bilities with the EM algorithm and the translationprobabilities are leveraged to translate the model.The rest of the unlabeled documents are used forother experimental purpose.SEMI (Adapted Model after Semi-SupervisedLearning).
This is our proposed method, after bothmodel translation and semi-supervised learning.In the semi-supervised learning, we use 6,000unlabeled target language documents with threetraining iterations.In each experiment, the data consists of 4,000 la-beled documents and 1,000 test documents (e.g., inthe cross-lingual experiments, we use 4,000 Englishannotated documents and 1,000 Chinese or Frenchtest documents).
For a given language, the same testdata is used across all experiments.Table 3 shows the performance of the variousclassification methods.
The ML (Monolingual)classifier has the best performance, as it is trainedon labeled data in the target language, so that thereis no information loss and no distribution discrep-ancy due to a model translation.
The MT (ma-chine translation) based approach scores the lowestaccuracy, probably because the machine translationsoftware produces only its best translation, whichis often error-prone, thus leading to poor classifi-cation accuracy.
In addition, the direct applicationof a classification model from one language to an-1064English?
ChineseCategory ML MTS MTT EM SEMIP R F P R F P R F P R F P R Fsports 96.1 94.3 95.2 80.6 81.7 81.2 81.7 83.8 82.7 83.1 84.7 83.9 92.1 91.8 91.9health 95.1 93.1 94.1 80.8 81.5 81.2 81.6 83.5 82.6 84.5 85.8 85.2 90.2 91.7 90.9business 91.6 93.1 92.4 81.3 81.9 81.6 80.7 81.0 80.9 81.6 82.0 81.8 87.3 89.3 88.3entertainment 88.1 88.3 88.2 76.1 78.8 77.5 75.3 78.9 77.1 76.8 79.7 78.2 83.2 83.8 83.5education 79.1 82.2 80.6 70.2 72.5 71.8 71.1 72.0 71.6 71.2 73.7 72.5 76.2 79.8 78.0English?
Frenchsports 95.8 95.0 95.4 82.8 83.6 83.2 82.1 83.0 82.5 85.3 87.1 86.2 92.5 92.1 92.3health 94.2 94.5 94.3 82.6 83.9 83.2 81.8 83.0 82.4 86.2 87.2 86.6 92.0 92.2 92.1business 90.1 92.2 91.1 81.4 82.1 81.7 81.3 81.8 81.8 84.4 84.3 84.4 88.3 89.2 88.8entertainment 87.4 87.2 87.3 76.6 79.1 77.8 76.0 78.8 77.4 78.9 81.0 80.0 84.3 85.5 84.9education 78.8 81.8 80.3 72.1 74.8 73.5 72.3 72.7 72.5 73.8 76.2 75.0 76.3 80.1 78.2Table 3: Comparison of different methods and different language pairsother does not adapt to the distribution of the sec-ond language, even if the documents belong to thesame domain.
Comparing the two MT alternatives,we can see that translating the training data (MTS)has better performance than translating the test data(MTT).
The reason is that when the model is trainedon the translated training data, the model parame-ters are learned over an entire collection of translateddocuments, which is less sensitive to translation er-rors than translating a test document on which theclassification is performed individually.Our EM method for translating model featuresoutperforms the machine translation approach, sinceit does not only rely on the best translation by themachine translation system, but instead takes intoaccount all possible translations with knowledgelearned specifically from the target language.
Ad-ditionally, the SEMI (semi-supervised) learning isshown to further improve the classification accuracy.The semi-supervised learning is able to not only helpadapt the translated model to fit the words distribu-tion in the target language, but it also compensatesthe distortion or information loss during the modeltranslation process as it can down-weigh the incor-rectly translated features.The improvement in performance for both theEM and the SEMI methods is consistent acrossthe five different domains, which indicates that themethods are robust and they are insensitive to thedomain of the data.The performance of the two language pairsEnglish-Chinese and English-French shows a dif-ference as initially hypothesized.
In both the EMand the SEMI models, the classification accuracyof English-French exceeds that of English-Chinese,which is probably explained by the fact that there isless translation ambiguity in similar languages, andthey have more similar distributions.
Note that themonolingual models in French and Chinese performcomparably, which means the difficulty of the testdata is similar between the two target languages.5.4 Model Adaptation with Semi-SupervisedLearningFinally, to gain further insights into our proposedadaptation method, we run several experiments withdifferent parameters for the semi-supervised learn-ing stage.
As these experiments are very time con-suming, we run them only on Chinese.For each of the five categories, we train a classi-fication model using the 4,000 training documentsin English and then translate the model into Chinesewith the translation parameters learned with EM on20,000 unlabeled Chinese documents.
Then we fur-ther train the translated model on a set of unlabeledChinese documents using a different number of it-erations and a different amount of unlabeled docu-ments.
Figures 1 and 2 show the results of theseevaluations.As the plots show, the use of unlabeled data inthe target language can improve the cross-languageclassification by learning new knowledge in thetarget language.
Larger amounts of unlabeleddata in general help, although the marginal bene-fit drops with increasing amounts of data.
Regard-ing the number of iterations, the best performance is10657075808590950  1000  2000  3000  4000  5000  6000ClassificationF-scoreSize of unlabeled datasportshealthbusinessentertainmenteducationFigure 1: Change in classification F-score for an increas-ing amount of unlabeled data in the target language7075808590950  1  2  3  4  5  6ClassificationF-scoreNumber of iterationssportshealthbusinessentertainmenteducationFigure 2: Change in classification F-score for a differentnumber of iterationsachieved after 3-4 iterations.6 ConclusionsIn this paper, we proposed a novel method for cross-lingual text classification.
Our method ports a clas-sification model trained in a source language to a tar-get language, with the translation knowledge beinglearned using the EM algorithm.
The model is fur-ther tuned to fit the distribution in the target languagevia semi-supervised learning.
Experiments on dif-ferent datasets covering different languages and dif-ferent domains show significant improvement overprevious methods that rely on machine translation.Moreover, the cross-lingual classification accuracyobtained with our method was found to be close tothe one achieved using monolingual text classifica-tion.AcknowledgmentsThe work of the second author has been partiallysupported by National Science Foundation awards#0917170 and #0747340.
Any opinions, findings,and conclusions or recommendations expressed inthis material are those of the authors and do notnecessarily reflect the views of the National ScienceFoundation.ReferencesS.
Argamon, M. Koppel, and G. Avneri.
1998.
Style-based text categorization: What newspaper am i read-ing?
In AAAI-98 Workshop on Learning for Text Cat-egorization, Madison.C.
Banea, R. Mihalcea, J. Wiebe, and S. Hassan.
2008.Multilingual subjectivity analysis using machine trans-lation.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP2008), Honolulu, Hawaii.A.
Berger, S. Della Pietra, and V. Della Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39?71.A.
Blum and T. Mitchell.
1998.
Combining labeled andunlabeled data with co-training.
In COLT: Proceed-ings of the Workshop on Computational Learning The-ory, Morgan Kaufmann Publishers, June.P.
Brown, S. della Pietra, V. della Pietra, and R. Mercer.1993.
The mathematics of statistical machine trans-lation: parameter estimation.
Computational Linguis-tics, 19(2).W.
Dai, G. Xue, Q. Yang, and Y. Yu.
2007.
Transfer-ring naive bayes classifiers for text classification.
In InProceedings of the 22nd AAAI Conference on ArtificialIntell igence, pages 540?545.A.P.
Dempster, N.M. Laird, and D.B.
Rubin.
1977.
Max-imum likelihood from incomplete data via the em al-gorithm.
Journal of the Royal Statistical Society.
Se-ries B (Methodological), 39(1).B.
Fortuna and J. Shawe-Taylor.
2005.
The use ofmachine translation tools for cross-lingual text min-ing.
In Learning With Multiple Views, Workshop atthe 22nd International Conference on Machine Learn-ing (ICML).A.
Gliozzo and C. Strapparava.
2006.
Exploiting com-parable corpora and bilingual dictionaries for cross-language text categorization.
In Proceedings of theConference of the Association for Computational Lin-guistics, Sydney, Australia.1066R.
Hwa, P. Resnik, and A. Weinberg.
2005.
Bootstrap-ping parsers via syntactic projection across paralleltexts.
Natural Language Engineering.
Special issueon Parallel Texts, editors R. Mihalcea and M. Simard.T.
Joachims.
1997.
A probabilistic analysis of the Roc-chio algorithm with TFIDF for text categorization.
InProceedings of ICML-97, 14th International Confer-ence on Machine Learning, Nashville, US.T.
Joachims.
1998.
Text categorization with SupportVector Machines: learning with mny relevant features.In Proceedings of the European Conference on Ma-chine Learning, pages 137?142.P.
Koehn and K. Knight.
2000.
Estimating word transla-tion probabilities from unrelated monolingua l corporausing the em algorithm.
In National Conference onArtificial Intelligence (AAAI 2000) Lang kilde, pages711?715.A.
McCallum and K. Nigam.
1998.
A comparison ofevent models for Naive Bayes text classification.
InProceedings of AAAI-98 Workshop on Learning forText Categorization.R.
Mihalcea, C. Banea, and J. Wiebe.
2007.
Learningmultilingual subjective language via cross-lingual pro-jections.
In Proceedings of the Association for Com-putational Linguistics, Prague, Czech Republic.C.
Monz and B.J.
Dorr.
2005.
Iterative translation dis-ambiguation for cross-language information retrieval.In Proceedings of the 28th Annual International ACMSIGIR Conference on Research and Development inInformation Retrieval, Salvador, Brazil.A.
Moschitti.
2003.
A study on optimal paramter tun-ing for Rocchio text classifier.
In Proceedings of theEuropean Conference on Information Retrieval, Italy.H.T.
Ng, B. Wang, and Y.S.
Chan.
2003.
Exploiting par-allel texts for word sense disambiguation: An empiri-cal study.
In Proceedings of the 41st Annual Meetingof the Association for Computational Linguistics (ACL2003), Sapporo, Japan, July.J.-Y.
Nie, M. Simard, P. Isabelle, and R. Durand.
1999.Cross-language information retrieval based on paralleltexts and automatic mining of parallel texts from theWeb.
In Proceedings of the 22nd annual internationalACM SIGIR conference on Research and developmentin information retrieval.K.
Nigam and R. Ghani.
2000.
Analyzing the effec-tiveness and applicability of co-training.
In Proceed-ings of the Conference on Information and KnowledgeManagement (CIKM 2000), McLean, VA, November.K.
Nigam, J. Lafferty, and A. McCallum.
1999.
Usingmaximum entropy for text classification.
In IJCAI-99Workshop on Machine Learning for Information Fil-tering.J.S.
Olsson, D. W. Oard, and J. Hajic.
2005.
Cross-language text classification.
In Proceedings of the 28thAnnual international ACM SIGIR Conference on Re-search and Development in information Retrieval.B.
Pang and L. Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In Proceedings of the 42ndMeeting of the Association for Computational Linguis-tics, Barcelona, Spain, July.M.
Sahami, S. Dumais, D. Heckerman, and E. Horvitz.1998.
A Bayesian approach to filtering junk e-mail.In AAAI-98 Workshop on Learning for Text Catego-rization, Madison.J.
Schler, M. Koppel, S. Argamon, and J. Pennebaker.2006.
Effects of age and gender on blogging.
In Pro-ceedings of 2006 AAAI Spring Symposium on Com-putational Approaches for Analyzing Weblogs, pages199?204, Stanford.L.
Shi, C. Niu, M. Zhou, and J. Gao.
2006.
A domtree alignment model for mining parallel data from theweb.
In Proceedings of the Annual Meeting of the As-sociation for Computational Lingusitics (ACL 2006),Sydney, Australia.V.
Vapnik.
1995.
The Nature of Statistical Learning The-ory.
Springer, New York.X.
Wan.
2009.
Co-training for cross-lingual sentimentclassification.
In Proceedings of the Joint Conferenceof the Association of Computational Linguistics andthe International Joint Conference on Natural Lan-guage Processing, Singapore, August.1067
