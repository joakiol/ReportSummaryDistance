Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 33?40,New York City, June 2006. c?2006 Association for Computational LinguisticsScaling Natural Language Understanding via User-driven OntologyLearningBerenike LoosEuropean Media Laboratory, GmbHSchloss-Wolfsbrunnenweg 33, 69118 Heidelberg, Germanyfirstname.lastname@eml-d.villa-bosch.deAbstractNon-statistical natural language under-standing components need world knowl-edge of the domain for which they are ap-plied in a machine-readable form.
Thisknowledge can be represented by manu-ally created ontologies.
However, as soonas new concepts, instances or relationsare involved in the domain, the manuallycreated ontology lacks necessary informa-tion, i.e.
it becomes obsolete and/or in-complete.
This means its ?world model?will be insufficient to understand the user.The scalability of a natural language un-derstanding system, therefore, essentiallydepends on its capability to be up todate.
The approach presented herein ap-plies the information provided by the userin a dialog system to acquire the knowl-edge needed to understand him or her ad-equately.
Furthermore, it takes the posi-tion that the type of incremental ontologylearning as proposed herein constitutes aviable approach to enhance the scalabilityof natural language systems.1 IntroductionTo let a computer system understand natural lan-guage one needs knowledge about objects and theirrelations in the real world.
As the manual modelingand maintenance of such knowledge structures, i.e.ontologies, are not only time and cost consuming,but also lead to not-scalable systems, there exists ademand to build and populate them automatically orat least semi automatically.
This is possible by an-alyzing unstructured, semi-structured or fully struc-tured data by various linguistic as well as statisticalmeans and by converting the results into an ontolog-ical form.In an open-domain scalable natural language un-derstanding (NLU) system the automatic learningof ontological concepts and corresponding relationsbetween them is essential, as a complete modelingof the world is neither practicable nor feasible, as thereal world and its objects, models and processes areconstantly changing along with their denotations.This paper assumes that a viable approach to thischallenging problem is to learn ontological conceptsand relations relevant to a certain user in a given con-text by the dialog system at the time of the user?sinquiry.
My central hypothesis is that the infor-mation about terms that lack any mapping to theemployed knowledge representation of the languageunderstanding component can only be found in top-ical corpora such as the Web.
With the help of thisinformation one can find the right node in the on-tology to append the concept corresponding to theunknown term in case it is a noun or to insert it as aninstance in case it is a proper noun or another namedentity.The goal of the ontology learning component is toextend the knowledge base of the NLU system andtherefore it will gradually adapt to the user?s needs.An example from the area of spoken dialog sys-tems would be that of a user walking through thecity of Heidelberg and asking: ?How do I get to33the Auerstein?.
This would lead to the detectionof Auerstein as being neither recognizable by thespeech recognizer nor mappable to the knowledgerepresentation of the system.
Therefore, the cor-responding hypernym of Auerstein has to be foundon the internet by recourse to additional informationabout the context of the user.
In this case, the ad-ditional information consists of the location of theuser, namely Heidelberg.
Once found, the hyper-nym is mapped to a corresponding concept, whichalready exists in the ontology.
If there is no suchcorresponding concept, the concept for the hyper-nym thereof has to be determined.
The formerly un-known term is mapped to a concept and is integratedinto the system?s ontology as a child of the conceptfor the found hypernym.
In case the unknown termis a proper noun, it is integrated as an instance of theconcept for the hypernym.
So far, the research un-dertaken is related to nouns and proper nouns, alsomore generally referred to as terms in this paper.In the following section, I will describe relatedwork undertaken to solve the task of ontology learn-ing, followed by some remarks of the distinctionbetween ontology learning and natural language inSection 3.
Thereafter, I will sketch out the minimalstages involved in the type of ontology learning pro-posed herein in Section 4.2 Related WorkThe capability to acquire knowledge exactly at thetime it is needed can be regarded as an importantstepping stone towards scalable natural language un-derstanding systems.
The necessity of scalabilityin NLU became more and more obvious in open-domain dialog systems, as the knowledge base in-tegrated into those can never be complete.
Beforethe emergence of open-domain systems, more orless complete ontologies were modeled manually forthe domain needed in the NLU system and weretherefore not scalable to additional domains, un-less modeled in advance in a manual fashion or bymeans of off-line ontology learning.
Nonetheless,numerous off-line ontology learning frameworks ex-ist, which alleviate the work of an ontology engineerto construct knowledge manually (Maedche, 2002),(Schutz and Buitelaar, 2005), (Cimiano et al, 2005).Most of these frameworks apply hybrid methods tooptimize their learning results.For example, the ontology population method On-toLearn (Navigli et al, 2004) is based on text min-ing and other machine learning techniques and startswith a generic ontology like WordNet and docu-ments in a given domain.
The result is a domainextended and trimmed version of the initial ontol-ogy.
For this, the system applies three phases tolearn concepts:?
First, a terminology extraction method, usingshallow techniques that range from stochas-tic methods to more sophisticated syntactic ap-proaches, is applied, which extracts a list of do-main terms (mostly nouns and proper nouns)from a set of documents representative for agiven domain.?
Second, a semantic interpretation takes placewhich makes use of a compositional interpreta-tion and structural semantic interconnections.?
After these two phases the extending and trim-ming of the initial ontology takes place.
Withthe help of the semantic interpretation of theterms they can be organized in sub-trees andappended under the appropriate node of the ini-tial ontology applying linguistic rules.The text understanding system SYNDICATE(SYNthesis of DIstributed Knowledge Acquiredfrom Texts) uses an integrated ontology learningmodule (Hahn and Marko, 2002).
In this approachnew concepts are learned with the help of text un-derstanding, which applies two different sources ofevidence, namely, the prior knowledge of the topicdomain of the texts and grammatical constructionsin which unknown lexical items occur in the texts.In an incremental process a given ontology is up-dated as new concepts are acquired from real-worldtexts.
The acquisition process is centered on the lin-guistic and conceptual ?quality?
of various forms ofevidence underlying the generation and refinementof concept hypotheses.
On the basis of the quality ofevidence, concept hypotheses are ranked accordingto credibility and the most credible ones are selectedfor assimilation into the domain knowledge base.The project Disciple (Stanescu et al, 2003) buildsagents which can be initially trained by a sub-ject matter expert and a knowledge engineer, in34a way similar to how an expert would teach anapprentice.
A Disciple agent applies two differ-ent methods for ontology learning, i.e.
exception-based and example-based ontology learning.
Theexception-based learning approach consists of fourmain phases:?
First, a candidate discovery takes place, inwhich the agent analyzes a rule together withits examples, exceptions and the ontology andfinds the most plausible types of extensions ofthe latter that may reduce or eliminate the rule?sexceptions.?
In the second phase the expert interacts with theagent to select one of the proposed candidates.?
Afterwards the agent elicits the ontology exten-sion knowledge from the expert and finally arule refinement takes place, in which the agentupdates the rule and eliminates its exceptionsbased on the performed ontology extension.?
When the subject matter expert has to specify afact involving a new instance or new feature inthe agent teaching process, the example-basedlearning method is invoked.
In this processthe agent tries to find example sentences ofthe words next to a new term through variousheuristics.
For instance, he finds out that X ismember of Y, and consequently can ask the ex-pert.
If he affirms, the new term can be memo-rized.All of the approaches described above exhibit the-oretical as well as practical (in the light of the taskundertaken herein) shortcomings.
The theoreticalproblems that have not been resolved in a satisfac-tory manner by the works described above (as wellas numerous others) are:?
a clear separation of the linguistic and ontolog-ical subtasks involved in the overall ontologylearning endeavor?
systematic ways and methods for evaluating theindividual learning results?
rigorously defined baselines against which toevaluate the ensuing learning approaches.In the following I will describe how these is-sues can be addressed within the user-drivenontology learning framework proposed herein.3 Natural Language versus OntologyLearningBefore describing the actual ontology learningprocess it is important to make a clear distinctionbetween the two fields involved: This is on the onehand natural language and on the other hand ontol-ogy learning.The corpora to extract knowledge from shouldcome from the internet as this source provides themost up-to-date information.
The natural languagetexts are rich in terms, which can be used as labelsof concepts in the ontology and rich in semantic re-lations, which can be used as ontological relations(aka properties).The connection between the two areas which areworking on similar topics but are using different ter-minology needs a distinction between the extractionof semantic information from natural language andthe final process of integrating this knowledge intoan ontology.Figure 1: Natural Language versus Ontology Learn-ingFigure 1 shows the process of ontology learningfrom natural language text.
On the left side relevantnatural language terms are extracted.
During a trans-formation process they are converted into labels ofconcepts and relations of an ontology.
Proper nounsare transfered into instance labels in the ontology1.1In our understanding the term ontology denotes both theinstance model as well as the ground ontology.354 Scaling NLU via User-driven OntologyLearningA user-driven ontology learning framework shouldbe able to acquire knowledge at the run time of theNLU system.
Therefore, terms which are not under-stood by the system have to be identified.
In dialogsystems this is true for all terms uttered or written bya user, which are not presently contained in the lex-icon or can be derived by means of derivational orflexional morphology.
In the following I will referto these terms as unknown terms2.When a user of an open-domain spoken dialogsystem makes an utterance, it happens regularly, thatthe term is not represented in the system?s lexicon.Since it is assumed, in this work, that the meaningof terms is represented by means of a formal on-tology, a user-driven ontology learning frameworkis needed to determine the corresponding conceptsfor these terms, e.g., via a search on topical corpora.For instance, a term such as Auerstein could be em-ployed to query a search engine.
By applying naturallanguage patterns, as proposed by Hearst (1992) andstatistical methods, as proposed by Faulhaber et al(2006) possible hypernyms or sets of hypernym can-didates of the term can be extracted.
For these a cor-responding concept (or set of possible concepts) inthe ontology employed by the dialog system need tobe found.
Last but not least the unknown term has tobe inserted into the ontology as either an instance ora subclass of that concept.
This process is describedin greater detail in Section 5.4).It is important to point out that terms often havemore than one meaning, which can only be deter-mined by recourse to the context in which it is ut-tered/found (Widdows, 2003), (Porzel et al, 2006).Therefore, information about this context needs tobe added in order to make searching for the righthypernym feasible3 as shown in Section 5.3.
For ex-ample, the term Lotus can refer to a flower, a specifictype of car or among copious other real world enti-ties to a restaurant in Heidelberg.
Therefore, a scal-able ontology learning framework in a dialog systemrequires at least the following ingredients:2This closely corresponds to what is termed out-of-vocabulary (OOV) words in the automatic speech recognitioncommunity.3Of course, even in the same context a term can have morethan one meaning as discussed in Section 5.7.?
A formal explicit model of a shared conceptual-ization of a specific domain of interest (Gruber,1993), i.e.
an ontology;?
processing methods which indicate the un-known terms;?
a corpus, as the starting point to retrieve hyper-nyms;?
methods for mapping hypernyms to concepts inthe ontology;?
an evaluation framework;Figure 2 shows the steps involved in on-demandontology learning from the text to the knowledgeside.Figure 2: From text to knowledge5 On-demand learningFrom the cognitive point of view learning makesonly sense when it happens on-demand.
On-demandmeans, that it occurs on purpose and that activityis involved rather than passivity.
As pointed out bySpitzer (2002) for human beings activity is neces-sary for learning.
We cannot learn by drummingdata into our brain through listening cassettes whensleeping or by similar fruitless techniques.
The rea-son for this is, that we need active ways of struc-turing the data input into our brain.
Furthermore, wetry only to learn what we need to learn and are there-fore quite economic with the ?storage space?
in ourbrain.36It makes not only for humans sense to simplylearn whatever they need and what is useful forthem.
Therefore, I propose that ontology learning,as any other learning, is only useful and, in the end,possible if it is situated and motivated by the givencontext and the user needs.
This can entail learningmissing concepts relevant to a domain or to learnnew concepts and instances which become neces-sary due to changes in a domain.However, the fundamental ontological commit-ments should be adhered to.
So, for example, thedecision between a revisionary and a descriptive on-tology should be kept in the hand of the knowledgeengineer, as well as the choice between a multiplica-tive and a reductionist modeling4.
As soon as thebasic structure is given new knowledge can be in-tegrated into this structure.
Thus, for a reduction-ist ontology a concept such as Hotel should be ap-pended only once, e.g.
to an ontological concept asPhysicalObject rather than NonPhysicalObject.In the following I will describe the various stepsand components involved in on-demand ontologylearning.5.1 Unknown terms in dialog systemsIn case the dialog system works with spoken lan-guage one can use the out-of-vocabulary (OOV)classification of the speech recognizer about allterms not found in the lexicon (Klakow et al,2004).
A solution for a phoneme-based recog-nition is the establishment of corresponding best-rated grapheme-chain hypotheses (Gallwitz, 2002).Those can be used for a search on the internet.
Incase the dialog system only works with written lan-guage it is easier to identify terms, which cannot bemapped to ontological concepts, at least if they arespelled correctly.
To evaluate the framework itselfadequately it is useful to apply only correctly writ-ten terms for a search.Later on in both cases - i.e.
in spoken and writtendialog systems - a ranking algorithm of the best, saythree, hypotheses should be selected to find the mostadequate term.
Here methods like the one of Google?Did you mean...?
for spelling errors could be used.4More information on these and other ontological choicescan be found summarized in (Cimiano et al, 2004)5.2 Language UnderstandingAll correctly recognized terms of the user utterancecan be mapped to concepts with the help of an analy-sis component.
Frequently, production systems(Engel, 2002), semantic chunkers (Bryant, 2004)or simple word-to-concept lexica (Gurevych et al,2003) are employed for this task.
Such lexica assigncorresponding natural language terms to all conceptsof an ontology.
This is especially important for alater semantic disambiguation of the unknown term(Loos and Porzel, 2004).
In case the information ofthe concepts of the other terms of the utterance canhelp to evaluate results: When there is more than oneconcept proposal for an instance (i.e.
on the linguis-tic side a proper noun like Auerstein) found in theword-to-concept lexicon, the semantic distance be-tween each proposed concept and the other conceptsof the user?s question can be calculated5 .5.3 Linguistic and Extra-linguistic ContextNot only linguistic but also extra linguistic contextplays an important role in dialog systems.
Thus, tounderstand the user in an open-domain dialog sys-tem it is important to know the extra-linguistic con-text of the utterances.
If there is a context moduleor component in the system it can give informationon the discourse domain, time and location of theuser.
This information can be used as a support for asearch on the internet.
E.g.
the location of the userwhen searching for, say Auerstein, is advantageous,as in the context of the city Heidelberg it has a dif-ferent meaning than in the context of another city(Bunt, 2000), (Porzel et al, 2006).Part of the context information can be representedby the ontology as well as patterns for grouping anumber of objects, processes and parameters for onedistinctive context (Loos and Porzel, 2005).5.4 Finding the appropriate hypernym on theinternetFor this, the unknown term as well as an appropri-ate context term (if available) needs to be appliedfor searching possible hypernyms on the Web.
Asmentioned before an example could be the unknownterm Auerstein and the context term Heidelberg.5E.g.
with the single-source shortest path algorithm of Dijk-stra (Cormen et al, 2001).37For searching the internet different encyclopediasand search engines can be used and the correspond-ing results can be compared.
After a distinction be-tween different types of unknown terms, the searchmethods are described.Global versus local unknown terms: In the caseof generally familiar proper nouns like stars, hotelchains or movies (so to say global unknown terms),a search on a topical encyclopedia can be quite suc-cessful.
In the case of proper nouns, only common ina certain country region, such as Auerstein (Restau-rant), Bierbrezel (Pub) and Lux (Cinema), which arelocal unknown terms, a search in an encyclopediais generally not fruitful.
Therefore, one can searchwith the help of a search engine.As one can not know the kind of unknown termsbeforehand, the encyclopedia search should be ex-ecuted before the one using the search engine.
Ifno results are produced, the latter will deliver them(hopefully).
In case results are retrieved by the for-mer, the latter can still be used to test those.Encyclopedia Search: The structure of Encyclo-pedia entries is generally pre-assigned.
That means,a program can know, where to find the most suit-able information beforehand.
In the case of findinghypernyms the first sentence in the encyclopedia de-scription is often found to be the most useful.
Togive an example from Wikipedia6 , here is the firstsentence for the search entry Michael Ballack:(1) Michael Ballack (born September 26, 1976in Grlitz, then East Germany) IS A Germanfootball player.With the help of lexico-syntactic patterns, the hy-pernym can be extracted.
These so-called Hearstpatterns (Hearst, 1992) can be expected to occur fre-quently in lexicons for describing a term.
In example1 the pattern X is a Y would be matched and the hy-pernym football player of the term Michael Ballackcould be extracted.Title Search: To search only in the titles of webpages might have the advantage, that results can be6Wikipedia is a free encyclopedia, which is editable on theinternet: http://www.wikipedia.org (last access: 26th January2006).generated relatively fast.
This is important as real-time performance is an important usability factor indialog systems.
When the titles contain the hyper-nym it still is to be expected that they might notconsist of full sentences, Hearst patterns (Hearst,1992) are, therefore, unlikely to be found.
Alter-natively, only the nouns in the title could be ex-tracted and their occurrences counted.
The nounmost frequently found in all the titles could then beregarded as the most semantically connected term.To aid such frequency-based approaches stemmingand clustering algorithms can be applied to groupsimilar terms.Page Search: For a page search Hearst patterns asin the encyclopedia search can almost certainly beapplied.
In contrast to encyclopedia entries the recallof those patterns is not so high in the texts from theweb pages.Figure 3: Tasks for the evaluation of ontology learn-ingThe text surrounding the unknown term issearched for nouns.
Equal to the title search the oc-currence of nouns can then be counted.
With thehelp of machine learning algorithms a text miningcan be done to ameliorate the results.5.5 Mapping text to knowledge by termnarrowing and wideningAs soon as an appropriate hypernym is found in atext the corresponding concept name should be de-termined.
For term narrowing, the term has to bestemmed to its most general form.
For the termwidening, this form is used to find synonyms.
Those38are, in turn, used for searching ontological conceptnames in the ontology integration phase.
If the hy-pernym found is in a language other than the oneused for the ontology, a translation of the terms hasto take place as well.5.6 Integration into an ontologyAfter the mapping phase newly learned concepts,instances or relations can be integrated into anydomain-independent or even foundational ontology.If no corresponding concept can be found the nextmore general concept has to be determined by thetechniques described above.5.7 EvaluationAn evaluation of such a system can be divided intotwo types: one for the performance of the algorithmsbefore the deployment of the system and one, whichcan be performed by a user during the run time ofthe system.Methodological evaluation Before integratingthe framework into a dialog system or any otherNLU system an evaluation of the methods and theirresults should take place.
Therefore, a representativebaseline has to be established and a gold-standard(Grefenstette, 1994) created, depending on the taskwhich is in the target of the evaluation.
The ensuingsteps in this type of evaluation are shown in Figure3 and described here in their order:1.
The extraction of hypernyms of unknownwords from text and the extraction of semanticrelations (other than is-a) between NLU terms.2.
The mapping of a linguistic term to an ontolog-ical concept.3.
The integration of ontological concepts, in-stances and relations into the system?s ontol-ogy.Depending on the three steps the most adequatebaseline method or algorithm for each of them hasto be identified.
In step 1 for the extraction of hyper-nyms a chance baseline as well as a majority classbaseline will not do the job, because their perfor-mance would be too poor.
Therefore, a well estab-lished algorithm which, for example applies a set ofstandard Hearst patterns (Hearst, 1992) would con-stitute a potential candidate.
For the mapping fromtext to knowledge (see step 2) the baseline could bea established by standard stemming combined withstring similarity metrics.
In case of different sourceand goal languages an additional machine transla-tion step would also become necessary.
For the base-line of ontology evaluation a task-based frameworkas proposed by (Porzel and Malaka, 2005) could beemployable.Evaluation by the user As soon as the frameworkis integrated into a dialog system the only way toevaluate it is by enabling the user to browse the on-tological additions at his or her leisure and to de-cide whether terms have been understood correctlyor not.
In case two or more hypernyms are scoredwith the same ?
or quite similar ?
weights, this ap-proach could also be quite helpful.
An obvious rea-son for this circumstance is, that the term in ques-tion has more than one meaning in the same context.Here, only a further inquiry to the user can help todisambiguate the unknown term.
In the Auersteinexample a question like ?Did you mean the hotelor the restaurant??
could be posed.
Even thoughthe system would show the user that it did not per-fectly understand him/her, the user might be morecontributory and less annoyed than with a questionlike ?What did you mean??.
The former questioncould also be posed by a person familiar with theplace, to disambiguate the question of someone insearch for Auerstein and would therefore mirror ahuman-human dialogs, which in turn would further-more lead to more natural human-computer dialogs.6 Concluding RemarksIn this paper I have shown, that the scalability ofnon-statistical natural language understanding sys-tems essentially depends on its capability to be up todate when it comes to understand language.
Fur-thermore, I took the position that ontology learn-ing is viable, when it happens incrementally and ina context-sensitive fashion.
Future work will focuson implementation and evaluation within a runningmulti-modal dialog system.
Additionally, a tight in-tegration with automatic lexicon and grammar learn-ing is of paramount importance.39ReferencesJohn Bryant.
2004.
Scalable construction-based parsingand semantic analysis.
In Proceedings of the 2nd In-ternational Workshop on Scalable Natural LanguageUnderstanding (ScaNaLU 2004) at HLT-NAACL 2004.Harry Bunt.
2000.
Dialogue pragmatics and con-text specification.
In H.C. Bunt and W.J.
Black, ed-itors, Computational Pragmatics, Abduction, Beliefand Context; Studies in Computational Pragmatics,pages 81?150.
John Benjamins, Amsterdam.Philipp Cimiano, Andreas Eberhart, Daniel Hitzler, Pas-cal Oberle, Steffen Staab, and Rudi Studer.
2004.
TheSmartWeb foundational ontology.
SmartWeb ProjectReport.Philipp Cimiano, Gu?nter Ladwig, and Steffen Staab.2005.
Gimme?
the context: Context-driven automaticsemantic annotation with C-PANKOW.
In Proceed-ings of the 14th World Wide Web Conference.
ACMPress.Thomas H. Cormen, Charles E. Leiserson, Ronald L.Rivest, and Clifford Stein.
2001.
Section 24.3: Dijk-stra?s algorithm.
In Introduction to Algorithms, Sec-ond Edition, pages 595?601.
MIT Press and McGraw-Hill.Ralf Engel.
2002.
SPIN: Language understanding forspoken dialogue systems using a production systemapproach.
In Proceedings of the International Confer-ence on Speech and Language Processing 2002, Den-ver, USA.Arndt Faulhaber, Berenike Loos, Robert Porzel, andRainer Malaka.
2006.
Open-class named entity clas-sification in multiple domains.
In Proceedings of theOntolex Workshop.
Genua, Italy.Florian Gallwitz.
2002.
Integrated Stochastic Models forSpontaneous Speech Recognition.
Logos, Berlin.Gregory Grefenstette.
1994.
Explorations in AutomaticThesaurus Discovery.
Kluwer Academic Publishers,USA.Thomas Gruber.
1993.
A translation approach toportable ontology specifications.
Knowledge Acqui-sition (5).Iryna Gurevych, Rainer Malaka, Robert Porzel, andHans-Peter Zorn.
2003.
Semantic coherence scoringusing an ontology.
In Proc.
of the HLT/NAACL 2003,page (in press), Edmonton, CN.Udo Hahn and Kornl G. Marko.
2002.
Ontology and lex-icon evolution by text understanding.
In Proceedingsof the ECAI 2002 Workshop on Machine Learning andNatural Language Processing for Ontology Engineer-ing (OLT?2002).
Lyon, France.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofCOLING 92, Nantes, France.Dietrich Klakow, Georg Rose, and Xavier Aubert.
2004.Oov-detection in a large vocabulary system using au-tomatically defined word-fragments as filler.
In Pro-ceedings of EUROSPEECH?99, Budapest, Hungary.Berenike Loos and Robert Porzel.
2004.
Resolution oflexical ambiguities in spoken dialogue systems.
InProceedings of the 5th Workshop on Diascourse andDialogue, Cambridge, Massachusetts, USA.Berenike Loos and Robert Porzel.
2005.
Towardsontology-based pragmatic analysis.
In Proceedings ofDIALOR?05, Nancy, France.Alexander Maedche.
2002.
Ontology Learning for theSemantic Web.
Kluwer Academic Publishers, USA.Roberto Navigli, Paola Velardi, Alessandro Cucchiarelli,and Francesca Neri.
2004.
Extending and enrichingWordNet with OntoLearn.
In Proceeedings of Inte-grated Approach for Web Ontology Learning and En-gineering.
IEEE Computer.Robert Porzel and Rainer Malaka.
2005.
A task-basedframework for ontology learning, population and eval-uation.
Ontology Learning from Text: Methods, Eval-uation and Applications Frontiers in Artificial Intelli-gence and Applications Series, 123.Robert Porzel, Iryna Gurevych, and Rainer Malaka.2006.
In context: Integrating domain- and situation-specific knowledge.
SmartKom Foundations of Mul-timodal Dialogue Systems, Springer, Cognitive Tech-nologies.Alexander Schutz and Paul Buitelaar.
2005.
RelExt:A tool for relation extraction in ontology extension.In Proceedings of the 4th International Semantic WebConference.
Galway, Ireland.Manfred Spitzer.
2002.
Lernen.
Spektrum Akademis-cher Verlag.Bogdan Stanescu, Cristina Boicu, Gabriel Balan, Mar-cel Barbulescu, Mihai Boicu, and Gheorghe Tecuci.2003.
Ontologies for learning agents: Problems, solu-tions and directions.
In Proceedings of the 2003 IEEEInternational Conference on Systems, Man and Cyber-netics, Volume: 3.
Washington D.C.Dominic Widdows.
2003.
A mathematical model forcontext and word-meaning.
In International and Inter-disciplinary Conference on Modeling and Using Con-text.
Stanford, California.40
