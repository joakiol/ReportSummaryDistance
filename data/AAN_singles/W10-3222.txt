Proceedings of the 8th Workshop on Asian Language Resources, pages 169?177,Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language ProcessingChained Machine Translation Using Morphemes as Pivot LanguageWen LiInstitute of IntelligentMachines, ChineseAcademy of Sciences,University of Scienceand Technology of Chinaxtliwen@mail.ustc.edu.cnLei ChenInstitute of IntelligentMachines, ChineseAcademy of Sciencesalan.cl@163.comWudabalaInstitute of IntelligentMachines, ChineseAcademy of Scienceshwdbl@126.comMiao LiInstitute of IntelligentMachines, ChineseAcademy of Sciencesmli@iim.ac.cnAbstractAs the smallest meaning-bearing ele-ments of the languages which have richmorphology information, morphemesare often integrated into state-of-the-artstatistical machine translation to improvetranslation quality.
The paper proposesan approach which novelly uses mor-phemes as pivot language in a chainedmachine translation system.
A machinetranslation based method is used thereinto find the mapping relations betweenmorphemes and words.
Experimentsshow the effectiveness of our approach,achieving 18.6 percent increase in BLEUscore over the baseline phrase-based ma-chine translation system.1 IntroductionRecently, most evaluations of machine transla-tion systems (Callison-Burch et al, 2009) indi-cate that the performance of corpus-based statis-tical machine translation (SMT) has come up tothe traditional rule-based method.
In the corpus-based SMT, it is difficult to exactly select thecorrect inflections (word-endings) if the targetlanguage is highly inflected.
This problem willbe more severe if the source language is an iso-lated language with non-morphology (eg.
Chi-nese) and the target language is an agglutinativelanguage with productive derivational and inflec-tional morphology (eg.
Mongolian: a minor-ity language of China).
In addition, the lack oflarge-scale parallel corpus may cause the sparsedata problem, which will be more severe if oneof the source language and the target languageis highly inflected.
As the smallest meaning-bearing elements of the languages which haverich morphology information, morphemes arethe compact representation of words.
Using mor-phemes as the semantic units in the parallel cor-pus can not only help choose the correct inflec-tions, but also alleviate the data sparseness prob-lem partially.Many strategies of integrating morphol-ogy information into state-of-the-art SMTsystems in different stages have been pro-posed.
(Ramanathan et al, 2009) proposeda preprocessing approach for incorporatingsyntactic and Morphological information withina phrase-based English-Hindi SMT system.
(Watanabe et al, 2006) proposed a methodwhich uses Porter stems and even 4-letter pre-fixes for word alignment.
(Koehn et al, 2007)proposed the factored translation models whichcombine feature functions to handle syntactic,morphological, and other linguistic informa-tion in a log-linear model during training.
(Minkov et al, 2007) made use of the infor-mation of morphological structure and sourcelanguage in postprocessing to improve SMTquality.
(de Gispert et al, 2009) adopted theMinimum Bayes Risk decoding strategy tocombine output from identical SMT system,which is trained on alternative morphologicaldecompositions of the source language.Meanwhile, the SMT-based methods arewidely used in the area of natural lan-guage processing.
(Quirk et al, 2004) ap-plied SMT to generate novel paraphrases.
(Riezler et al, 2007) adopted an SMT-based169method to query expansion in answer retrieval.
(Jiang and Zhou, 2008) used SMT to generatethe second sentence of the Chinese couplets.As opposed to the above strategies, the pa-per proposes an approach that uses morphemesas pivot language in a chained SMT system, fortranslating Chinese into Mongolian, which con-sists of two SMT systems.
First, Chinese sen-tences are translated into Mongolian morphemesinstead of Mongolian words in the Chinese-Morphemes SMT (SMT1).
Then Mongolianwords are generated from morphemes in theMorphemes-Mongolian SMT (SMT2).
The es-sential part of the chained SMT system is howto find the mapping relations between the mor-phemes and words, which is considered as a pro-cedure of machine translation in our approach.More concretely, the first challenge of this ap-proach is to investigate some effective strategiesto segment the Mongolian corpus in the Chinese-Mongolian parallel corpus.
And the second chal-lenge is how to efficiently generate Mongolianwords from morphemes.
Additionally, on theone hand Mongolian words may have multiplekinds of morphological segmentations.
On theother hand there is also the ambiguity of wordboundaries in the processing of generating Mon-golian words from morphemes.
In order to solvethese ambiguities, a SMT-based method is ap-plied in that word context and morphemes con-text can be taken into account in this method.The remainder of the paper is organized asfollows.
Section 2 introduces two methods ofmorphological segmentation.
Section 3 presentsthe details of chained SMT system.
Section 4describes the experiment results and evaluation.Section 5 gives concluding remarks.2 Morphological segmentationMongolian is a highly agglutinative languagewith a rich set of affixes.
Mongolian containsabout 30,000 stems, 297 distinct affixes.
A biggrowth in the number of possible word formsmay occur due to the inflectional and deriva-tional productions.
An inflectional suffix is aterminal affix that does not change the parts ofspeech of the root during concatenation, whichis added to maintain the syntactic environmentof the root.
For instance, the Mongolian word?YABVGSAN?
(walking) in the present con-tinuous tense syntactic environment consists ofthe root ?YABV?
(walk) and the suffix ?GSAN?(ing).
Whereas, when a verb root ?UILED?
(do)concatenates a noun derivational suffix ?BURI?,it changes to a noun ?UILEDBURI?
(factory).According to that whether linguistic lemmatiza-tion (the reduction to base form) is consideredor not, the paper proposes two methods of mor-phological segmentation.
The two methods aretested on the same training databases.The root lemmatization is concerned in thefirst method, which is called the SMT-basedmorphological segmentation (SMT-MS) in thispaper.
Given the Mongolian-morphemes par-allel corpus, this method trains a Mongolian-morphemes SMT to segment Mongolian words.The root lemmatization is considered in the orig-inal morphological pre-segmented training cor-pus.
So the SMT-based method can also dealwith root lemmatization when it segments aMongolian word.
For instance, the Mongo-lian word ?BAYIG A?
exhibits the change ofspelling during the concatenation of the mor-phemes ?BAI?
and ?G A?.
We also investi-gate whether it is effective if those roots areidentical to the original word forms.
In otherwords, the root lemmatization is ignored in thesecond method, which takes the gold standardmorphological segmentation corpus as a trainedmodel of Morfessor (Creutz and Lagus, 2007)and uses the Viterbi decoding algorithm to seg-ment new words.
Therefore, this method iscalled the Morfessor-based morphological seg-mentation (Mor-MS).
For instance, the word?BAYIG A?
will be segmented to ?BAYI?
and?G A?
instead of ?BAI?
and ?G A?.The mathematical description of SMT-MS isthe same as the traditional machine transla-tion system.
In the Mor-MS method, the mor-phological segmentation of a word can be re-garded as a flat tree (morphological segmenta-tion tree), where the root node corresponds tothe whole word and the leaves correspond tomorphemes of this word.
Figure 1 gives an ex-170ample.
First, the joint probabilistic distribution(Creutz and Lagus, 2007) of all morphemes inthe morphological segmentation tree are calcu-lated.
And then by using the Viterbi decodingalgorithm, the maximum probability segmenta-tion combination is selected.$0G0DB0RILAGDAHV-ACA$0G0DB0RILA GDA HV -ACAFigure 1: Morphological segmentation tree3 Chained SMT system3.1 OverviewIn order to improve the performance of Chinese-Mongolian machine translation, the paper pro-poses an approach which incorporates the mor-phology information within a chained SMT sys-tem.
More concretely, this system first translatesChinese into Mongolian morphemes instead ofMongolian words by the Chinese-MorphemesSMT.
And then it uses the Morphemes-Mongolian SMT to translate Mongolian mor-phemes into Mongolian words.
Namely, mor-phemes are regarded as pivot language in thissystem.The chained SMT system consists of a mor-phological segmentation system and two phrase-base machine translation systems, which aregiven as follows:?
Morphological segmentation: segment-ing Mongolian words (from the Chinese-Mongolian parallel corpus) into Mongo-lian morphemes and obtaining two paral-lel corpus: Chinese-Morphemes parallelcorpus and Morphemes-Mongolian parallelcorpus.?
SMT1: training the Chinese-MorphemesSMT on the Chinese-Morphemes parallelcorpus.?
SMT2: training the Morphemes-MongolianSMT on the Morphemes-Mongolian paral-lel corpus.Figure 2 illustrates the overview of chainedSMT system.3.2 Phrase-based SMTThe authors assume the reader to be famil-iar with current approaches to machine trans-lation, so that we briefly introduce the phrase-based statistical machine translation model(Koehn et al, 2003) here, which is the founda-tion of chained SMT system.In statistical machine translation, given asource language f , the aim is to seek a targetlanguage e, such that P (e|f) is maximized.
Thephrase-based translation model can be expressedby the following formula:e?
= argmaxeP (e|f) = argmaxe{P (f |e)P (e)}where e?
indicates the best result, P (e) is thelanguage model and P (f |e) is the translationmodel.
According to the standard log-linearmodel proposed by (Och and Ney, 2002), thebest result e?
that maximizes P (e|f) can be ex-pressed as follows:e?
= argmaxe{M?m=1?mhm(e, f)}where M is the number of feature functions,?m is the corresponding feature weight, eachhm(e, f) is a feature function.In our chained SMT system, SMT1, SMT2and the SMT for morphological segmentation(namely SMT-MS in Section 2) are all phrase-based SMTs.3.3 Features of Chained SMT systemAs shown in Figure 2, Chinese is translated intoMongolian morphemes in SMT1, which is thecore part of the chained SMT system.
Here mor-phemes are regarded as words.
Therefore, mor-phemes can play important roles in SMT1 as fol-lows: the roots present the meaning of the wordand the suffixes help select the correct grammat-ical environment.
The word alignments betweenChinese words and Mongolian morphemes arelearned automatically by GIZA++.
Figure 3gives an instance of word alignment in SMT1.171Mongolian (corpus)Chinese (corpus)Morphemes (corpus)SMT2: Morphemes-MongolianChinese (input)Mongolian (output)SMT1: Chinese-MorphemesMorphological segmentationFigure 2: Morphemes as pivot language in Chained SMT systemWe can see that the morphemes ?BI?,?TAN?
etc.are all regarded as words.0CI GAD -CV NEMERI-TAI ALAG_Ayiqi qu meiyou yidianni    bangzhuTANheBIwoFigure 3: Word alignments between Chinesewords and Mongolian morphemes in SMT1All the most commonly used features of stan-dard phrase-based SMT, including phrase trans-lation model, language model, distortion modeland word penalty, are selected in SMT1.
Thesecommonly used features determine the qualityof translation together.
The phrases of f ande are ensured to be good translations of eachother in the phrase translation model P (f |e).The fluent output is guaranteed in the languagemodel LM(e).
The reordering of the input sen-tence is allowed in the distortion model D(e, f).The translation is however more expensive withthe more reordering.
The translation results areguaranteed neither too long nor too short in theword penalty W (e).In SMT-MS and SMT2, the task is to findthe mapping relations between Mongolian mor-phemes and Mongolian words, which is consid-ered as the word-for-word translation.
There-fore, only phrase translation model and languagemodel are considered.
All the features weightsare uniform distribution by default.
Mongolianwords may have multiple kinds of morphologi-cal segmentations.
And there is the ambiguity ofword boundaries in the processing of generatingMongolian words from morphemes.
These am-biguities can be solved in SMT-MS and SMT2respectively, since the SMT-based method canendure mapping errors and solve mapping am-biguities by the multiple features which can con-sider the context of Mongolian words.4 Experiments4.1 Experimental setupIn the experiments, first we preprocess the cor-pus, such as converting Mongolian into LatinMongolian and filtering the apparent noisy seg-mentation of the gold standard morphologicalsegmentation corpus.
And then we evaluate theeffectiveness of the SMTs which find the map-ping relations between the morphemes and theircorresponding word forms.
Namely, SMT-MSand SMT2.
As mentioned above, SMT1 is thecore part of the chained SMT system, which de-cides the final quality of translation results.
Sothe evaluation of SMT1 can be reflected by theevaluation of translation results of whole chainedSMT system.
Finally, we evaluate and analyzethe performance of the chained SMT system byusing the automatic evaluation tools.The translation model consists of a stan-dard phrase-table with lexicalized reordering.Bidirectional word alignments obtained withGIZA++ are intersected using the grow-diag-final heuristic (Koehn et al, 2003).
Translationsof phrases of up to 7 words long are collectedand scored with translation probabilities and lex-ical weighting.
The language model of mor-phemes is a 5-gram model with Kneser-Ney172smoothing.
The language model of Mongo-lian word is 3-gram model with Kneser-Neysmoothing too.
All the language models arebuilt with the SRI language modeling toolkit(Stolcke, 2002).
The log-linear model featureweights are learned by using minimum error ratetraining (MERT) (Och, 2003) with BLEU score(Papineni et al, 2002) as the objective function.4.2 Corpus preprocessingThe Chinese-Mongolian parallel corpus andmonolingual sentences are obtain from the 5thChina Workshop on Machine Translation.
Inthe experiments, we first convert Mongoliancorpus into Latin Mongolian.
In morphologi-cal segmentation, the gold standard morpholog-ical segmentation corpus contains 38000 Mon-golian sentences, which are produced semi-automatically by using the morphological ana-lyzer Darhan (Nashunwukoutu, 1997) of InnerMongolia University.
Moreover, in order to ob-tain the higher quality corpus, most of the wrongsegmentation in the results of morphological an-alyzer are modified manually by the linguisticexperts.
However, there are still some wrongsegmentation in the gold standard corpus.
There-fore, we adopt a strategy to filter the apparentnoisy segmentation.
In this strategy, the sum ofthe lengths of all the morphemes is required tobe equivalent to the length of the original word.After filtering, there are still 37967 sentences re-mained.
In addition, the word alignment is vul-nerable to punctuation in SMT-MS.
So all punc-tuation of the gold standard morphological seg-mentation corpus are removed to eliminate somemistakes of the word alignment.Meanwhile, since the Chinese languagedoes not have explicit word boundaries, wealso need to do the segmentation of Chinesewords.
The word segmentation tool ICTCLAS(Zhang, 2008) is used in the experiments.4.3 Evaluation of SMT-MS and SMT2The tasks of SMT-MS and SMT2 are to findthe mapping relations between the morphemesand their corresponding word forms.
Morpho-logical segmentation is done by SMT-MS. Con-trarily, SMT2 is used to generate the wordsfrom morphemes.
To evaluate the effectivenessof SMT-MS and SMT2, we divide the filteredgold standard corpus into two sets for training(90%) and testing (10%) respectively.
The cor-rect morpheme boundaries are counted for SMT-MS evaluation, while the correct word bound-aries are counted for SMT2 evaluation.
We usethe two measures precision and recall on dis-covered word boundaries to evaluate the effec-tiveness of SMT-MS and SMT2, where precisionis the proportion of correctly discovered bound-aries among all discovered boundaries by the al-gorithm, and recall is the proportion of correctlydiscovered boundaries among all correct bound-aries.
A high precision indicates that a mor-pheme boundary is probably correct when it issuggested.
However the proportion of missedboundaries can not be obtained from it.
A highrecall indicates that most of the desired bound-aries were indeed discovered.
However it can notpoint out how many incorrect boundaries weresuggested either.
In order to get a comprehensiveidea, we also make use of the evaluation method:F-measure as a compromise.F-measure = 112(1precision+ 1recall )These measures assume values between zero and100%, where high values reflect good perfor-mance.
Therefore, we evaluate the SMT-basedmethods by incrementally evaluating the featuresused in our phrase-based SMT model.Table 1 gives the evaluation results, wherePTM denotes Phrase Translation Model, LW de-notes Lexical Weight, LM denotes LanguageModel, IPTM denotes Inverted PTM, ILW de-notes Inverted LW.
Table 1(a) and Table 1(b)are corresponding to the evaluations of SMT-MSand SMT2 respectively, where P , R and F de-note the three measures, namely precision, recalland F-measure.The results show that when we add more fea-tures incrementally, the precision, recall and F-measure are improved consistently.
These in-dicate that the features are helpful for findingthe mapping relations between morphemes andMongolian words.173Table 1: Evaluation of SMT-MS and SMT2(a) Evaluation of SMT-MSFeature P (%) R(%) F (%)(1): PTM+LW 73.35 72.45 72.90(2): (1)+LM 94.91 94.91 94.91(3): (2)+IPTM+ILW 94.95 94.95 94.95(b) Evaluation of SMT2Feature P (%) R(%) F (%)(1): PTM+LW 75.86 60.04 67.03(2): (1)+LM 95.13 89.92 92.45(3): (2)+IPTM+ILW 95.13 90.02 92.514.4 Evaluation of chained SMT systemWe use NIST score (Doddington, 2002) andBLEU score (Papineni et al, 2002) to evaluatechained SMT system.
The training set contains67288 Chinese-Mongolian parallel sentences.The test set contains 400 sentences, where eachsentence has four reference sentences which aretranslated by native experts.In the training phase, we convert Mongolianinto Latin Mongolian.
And while in the testphase, we convert the Latin Mongolian backinto the traditional Mongolian words.
We com-pare the chained SMT system with the standardphrase-based SMT.
Table 2 gives the evaluationof experiment result of each system, where Base-line is the standard phrase-based SMT, Chain1 isa chained SMT consisting of SMT-MS, SMT1and SMT2, Chain2 is also a chained SMT con-sisting of Mor-MS, SMT1 and SMT2.
In Table2(b), we use MERT to train the feature weightsof the baseline system and the feature weights ofSMT1 in Chain1 and Chain2.The experiment results show that both Chain1and Chain2 are much better than the baseline sys-tem.
The BLEU score is improved by 18.6 per-cent, from 20.71 (Baseline) to 24.57 (Chain2).In addition, Chain2 is better than Chain1.
Webelieve that it is essentially related to the dif-ferent morphemes corpus of Chain1 and Chain2.The morphemes corpus of Chain1 takes lemma-tization into account, while the morphemes cor-pus of Chain2 changes all morphemes to in-Table 2: Evaluation of systems(a) without MERTNIST BLEU (%)Baseline 5.3586 20.71Chain1 5.6471 23.91Chain2 5.6565 24.57(b) with MERTNIST BLEU (%)Baseline 5.6911 24.13Chain1 5.7439 24.70Chain2 5.8401 25.80flected forms which are identical to the originalword forms.
As the example in Section 2, theword ?BAYIG A?
is segmented into ?BAI+G A?in Chain1 and ?BAYI+G A?
in Chain2.
Mean-while, ?BAI?
is an independent Mongolian wordin the corpus.
So Chain1 can not discriminate theword ?BAI?
from the morpheme ?BAI?.As well known, the translation quality of SMTrelies on the performance of morphological seg-mentation.
We give the following example tointuitively show the quality of translation of thechained SMT system.Example 1 Table 3 gives four examples oftranslating Chinese into Mongolian.
In eachexample, four reference sentences translated bynative experts are also given.
These examplesindicate that the chained SMT system can helpchoose the correct inflections, and partly allevi-ate the data sparseness problem.In Table 3(a), the Mongolian word ?HAGAS?
(corresponding to the Chinese word ?yiban?
)has multiple inflectional forms as follows:Mongolian ChineseHAGAS-VN yi bandeHAGAS-IYAR yiban deHAGAS-TV zaibanHAGAS-I ba banFrom the above example, we can see thatthe baseline system translates the Chinese word?ban?
to the incorrect inflection ?HAGAS-TV,while Chain2 translates it to the correct inflec-tion ?HAGAS?
which is the morpheme of all theother inflections.174Table 3: Examples of translating Chinese into Mongolian(a) Lexicalization of morphemesChinese xianzai shi jiu dian ban .Baseline 0D0 B0L YISUN CAG HAGAS-TV.Chain1 0D0 B0L YISUN CAG HAGAS-TV.Chain2 0D0 B0L YISUN CAG HAGAS B0LJV BAYIN A.References0D0 YISUN CAG HAGAS B0LJV BAYIN A.0D0 YISUN CAG HAGAS.0D0 YISUN CAG HAGAS B0LBA.0D0 YISUN CAG HAGAS B0LJV BAYIN A.
(b) TenseChinese qunian zheshihou ni zai ganshenme ?Baseline NIDVNVN ENE HIRI CI YAGV HIJU BAYIHV BVI?Chain1 NIDVNVN ENE UYES CI YAGV HIJU BAYIHV BVI?Chain2 NIDVNVN ENE UY E-DU CI YAGV HIJU BAYIG A BVI?ReferencesNIDVNVN-V ENE UYE-DU TA YAGV HIJU BAYIG A BVI?NIDVNVN ENE UY E-DU TA YAGV HIJU BAYIBA?NIDVNVN JIL-VN ENE UYES TA YAGV HIJU BAYIBA?0D0 NIDVNVN-V ENE UYE-DU TA YAGV HIJU BAYIG A BVI?
(c) SyntaxChinese wo xiwang jinnian dong tian hui xiaxue .Baseline BI ENE JIL EBUL-UN EDUR-UN CASV 0R0JV B0L0N A.Chain1 BI ENE EBUL-UN EDUR CASV 0R0HV-YI HUSEJU BAYIN A.Chain2 BI ENE EBUL-UN EDUR CASV 0R0HV-YI HUSEJU BAYIN A.ReferencesBI ENE EBUL CAS 0R0HV-YI HUSEJU BAYIN A.ENE EBUL CASV 0R0HV-YI HUSEJU BAYIN A.BI ENE EBUL CASV 0R0HV-YI HUSEN E.BI ENE EBUL CAS 0R0HV-YI HUSEJU BAYIN A.
(d) Out-Of-Vocabulary wordsChinese wo guoqu chang yidazao chuqu sanbu .Baseline ... URGULJI yidazao GADAN A GARCV SELEGUCEN ALHVLABA.Chain1 ... URGULJI BODORIHU-BER GADAGVR ALHVLAN A.Chain2 ... URGULJI ORLOGE ERTE GARCV ALHVLAN A.References... URGULJI OROLGE ERTE GARCV AVHVDAG.... URGULJI ORLOGE ERTE GADAGVR ALHVLADAG.... YERU NI ORLOGE ERTE B0S0GAD GADAGVR ALHVLADAG.... URGULJI OROLGE ERTE GARCV AVHVDAG.In Table 3(b), the word ?BAYIN?
in the resultof the baseline system indicates the past tense en-vironment.
However, the correct environment isthe past continuous tense which is indicated bythe word ?BAYIN A?
appearing in the results ofchain1 and chain2.In Table 3(c), the baseline system translates?dongtian?
into ?EDUR-UN?
as an attribute,while the correct translation should be ?EDUR?as the subject of the object clause.175The statistical data-sets from word alignmentcorpus show that the vocabularies of the base-line system includes 376203 Chinese-Mongolianword pairs, while Chain1 and Chain2 contain326847 and 291957 Chinese-Morphemes pairsrespectively.
This indicates that the chained SMTsystem can partly alleviates the data sparsenessproblem.
As shown in Table 3(d), the baselinesystem can not translate the word ?yidazao?,while Chain1 and Chain2 can.5 Concluding remarksThe paper proposes the chained SMT system us-ing morphemes as pivot language for translat-ing an isolated language with non-morphologyinto an agglutinative language with productivederivational and inflectional morphology.
Theexperiment results show that the performance ofthe chained SMT system is encouraging.
Andthe SMT-based method is quite effective for find-ing mapping relations between morphemes andwords.
When adding more features, the preci-sion, recall and F-measure are all improved moreobviously.In the future, we will consider the confusionnetwork or lattice of N-best translation results in-stead of one best translation result in the chainedSMT system.
Meanwhile, the distortion of mor-pheme order in Mongolian is still obscure andneeds more investigation.
And comparing ourwork with other language pairs, such as English-to-French translation, English-to-Spanish trans-lation, and so on, is also concerned.AcknowledgmentsThe authors would like to thank the anonymousreviewers for their helpful reviews.
The work issupported by the National Key Technology R&DProgram of China under No.
2009BAH41B06and the Dean Foundation (2009) of Hefei Insti-tutes of Physical Science, Chinese Academy ofSciences.References[Callison-Burch et al2009] Callison-Burch, Chris,Philipp Koehn, Christof Monz, and JoshSchroeder.
2009.
Findings of the 2009 workshopon statistical machine translation.
In StatMT,pages 1?28.
[Creutz and Lagus2007] Creutz, Mathias and KristaLagus.
2007.
Unsupervised models for morphemesegmentation and morphology learning.
TSLP,4(1):1?34.
[de Gispert et al2009] de Gispert, Adria`, Sami Virpi-oja, Mikko Kurimo, and William Byrne.
2009.Minimum bayes risk combination of translationhypotheses from alternative morphological de-compositions.
In HLT, pages 73?76.
[Doddington2002] Doddington, George.
2002.
Auto-matic evaluation of machine translation quality us-ing n-gram co-occurrence statistics.
In HLT, pages128?132.
[Jiang and Zhou2008] Jiang, Long and Ming Zhou.2008.
Monolingual machine translation for para-phrase generation.
In COLING, pages 377?384.
[Koehn et al2003] Koehn, Philipp, Franz Josef Och,and Daniel Marcu.
2003.
Statistical phrase-basedtranslation.
In HLT-NAACL, pages 48?54.
[Koehn et al2007] Koehn, Philipp, Hieu Hoang,Alexandra Birch, Chris Callison-Burch, MarcelloFederico, Nicola Bertoldi, Brooke Cowan, WadeShen, Christine Moran, Richard Zens, Chris Dyer,Ondrej Bojar, Alexandra Constantin, and EvanHerbst.
2007.
Moses: Open source toolkit for sta-tistical machine translation.
In ACL, pages 177?180.
[Minkov et al2007] Minkov, Einat, KristinaToutanova, and Hisami Suzuki.
2007.
Generatingcomplex morphology for machine translation.
InACL, pages 128?135.
[Nashunwukoutu1997] Nashunwukoutu.
1997.
Anautomatic segmentation system for the root, stem,suffix of the mongolian.
Journal of Inner Mongo-lia University, 29(2):53?57.
[Och and Ney2002] Och, Franz Josef and HermannNey.
2002.
Discriminative training and maximumentropy models for statistical machine translation.In ACL, pages 295?302.
[Och2003] Och, Franz Josef.
2003.
Minimum errorrate training in statistical machine translation.
InACL, pages 160?167.
[Papineni et al2002] Papineni, Kishore, SalimRoukos, Todd Ward, and Wei-Jing Zhu.
2002.BLEU: a method for automatic evaluation ofmachine translation.
In ACL, pages 311?318.176[Quirk et al2004] Quirk, Chris, Chris Brockett, andWilliam B. Dolan.
2004.
Generating chinese cou-plets using a statistical MT approach.
In EMNLP,pages 142?149.
[Ramanathan et al2009] Ramanathan, Ananthakrish-nan, Hansraj Choudhary, Avishek Ghosh, andPushpak Bhattacharyya.
2009.
Case markers andmorphology: addressing the crux of the fluencyproblem in English-Hindi SMT.
In ACL-IJCNLP,pages 800?808.
[Riezler et al2007] Riezler, Stefan, AlexanderVasserman, Ioannis Tsochantaridis, Vibhu O.Mittal, and Yi Liu.
2007.
Statistical machinetranslation for query expansion in answer retrieval.In ACL, pages 464?471.
[Stolcke2002] Stolcke, Andreas.
2002.
SRILM - anextensible language modeling toolkit.
In Proc.Intl.
Conf.
on Spoken Language Processing, pages901?904.
[Watanabe et al2006] Watanabe, Taro, HajimeTsukada, and Hideki Isozaki.
2006.
Ntt systemdescription for the wmt2006 shared task.
In WMT,pages 122?125.
[Zhang2008] Zhang, Huaping.
2008.
ICTCLAS.http://ictclas.org/.177
