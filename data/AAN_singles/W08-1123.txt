Creation of a New Domain and Evaluation of Comparison Generation in aNatural Language Generation SystemMatthew MargeLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon Universitymrmarge@cs.cmu.eduAmy IsardICCS/HCRCSchool of InformaticsUniversity of EdinburghAmy.Isard@ed.ac.ukJohanna MooreICCS/HCRCSchool of InformaticsUniversity of EdinburghJ.Moore@ed.ac.ukAbstractWe describe the creation of a new domain forthe Methodius Natural Language GenerationSystem, and an evaluation of Methodius?
pa-rameterized comparison generation algorithm.The new domain was based around music andperformers, and texts about the domain weregenerated using Methodius.
Our evaluationshowed that test subjects learned more fromtexts that contained comparisons than fromthose that did not.
We also established that thecomparison generation algorithm could gener-alize to the music domain.1 IntroductionThere has been research into tailoring natural lan-guage to a user?s previous browsing history in a va-riety of domains such as medicine, museum col-lections, and animal descriptions (McKeown, 1985;Milosavljevic, 1997; Dale et al, 1998; O?Donnellet al, 2001).
Another domain in which this couldbe applied is automated disc jockeys (DJs) that ac-company a music stream such as Pandora1 and dis-cuss interesting trivia or facts about music tracks re-cently played to the user.
User modeling could makethese texts much more natural and less repetitive,and comparisons and contrasts between music artistsor tracks could also provide users with a novel wayto explore their music collection.The Methodius system (Isard, 2007) continuesin a line of research which began with ILEX(O?Donnell et al, 2001) and continued with M-PIRO (Isard et al, 2003) and now also NaturalOWL1http://www.pandora.com(Galanis and Androutsopoulos, 2007).
Like theseother systems, Methodius creates customizable de-scriptions of objects from an database, but it featuresa novel algorithm for generating comparisons be-tween a new object and objects that have previouslybeen encountered, which stands out from previousresearch in this area because it uses several explicitparameters to choose the most relevant and interest-ing comparisons given the context (Isard, 2007).There have been previous evaluations of some ofthese systems, including (Cox et al, 1999; Karasi-mos and Isard, 2004).
Karasimos and Isard con-ducted an evaluation of comparisons and aggrega-tion in the M-PIRO system.
The results showed thatparticipants learned more and perceived that theylearned more from texts that contained comparisonsand aggregations than they did from texts that didnot.
In this study, we investigate whether these re-sults generalize to our new domain, and we isolatethe effect of comparisons from that of aggregation.2 Knowledge Base Construction2.1 Corpus CollectionWe collected a small corpus to investigate the typeof facts disc jockeys tend to say about music.
We se-lected two genres where music descriptions betweenpieces were common, jazz and classical music.
Theprogrammes we used were broadcast on BBC Ra-dio Three2.
We transcribed sixty-four discussions;to maintain uniformity, we followed the LinguisticData Consortium?s transcription guidelines3.
This2http://www.bbc.co.uk/radio33http://projects.ldc.upenn.edu/Transcription/quick-trans169was not a thorough corpus collection; the purpose ofcollecting examples was to gain a sense of what discjockeys tend to discuss and compare.2.2 Ontology DesignBased on the transcribed examples, we selected andhand-wrote twelve database entries for music tracks,using the authoring tool developed by the M-PIROproject (Androutsopoulos et al, 2007).
We trans-formed the output of this tool into files suitable forMethodius using an ad-hoc collection of Perl andXSLT scripts, which also added the necessary infor-mation to the OpenCCG grammars (White, 2006)used by Methodius.
We discuss future plans in thisarea in Section 5.We created a single-inheritance ontology for aknowledge base of music pieces.
First, we listedthe high-level entity types in the music domain, suchas ?person?, ?instrument?, ?classical music period?,and ?jazz music period?.
We then added attributescommonly found in our disc jockey transcriptions.For each entity type, we defined a set of fields.
Forexample, the classical-period field must contain anentity which expresses a classical music piece?s timeperiod.
We also specified a microplanning expres-sion for each field, which provides detail on how thefield?s information should be generated at the sen-tence level.
We then added all the lexical items nec-essary for the music domain.2.3 Ontology PopulationWe populated our domain with six classical musicpieces and six jazz music pieces from the allmu-sic.com database4.
The songs were selected to yieldat least two interesting comparisons when placed ina specific order.
We also added entities linked to thetwelve songs, for example, each song?s album, per-former, and composer, and information about theseentities.
One challenge inherent in selecting theseentities from a publicly available database was toeliminate as much common knowledge as possi-ble about the music.
In order to decrease back-ground knowledge as a potential factor in our ex-periment, we selected songs that primarily did notcontain popular performers, composers, and con-ductors.
We were able to gauge the popularity of4http://www.allmusic.com"Avatar" was written by Gary Husband and it wasperformed by Billy Cobham, who was influencedby Miles Davis.
Billy Cobham originated fromPanama City, Panama and he played the drums; hewas active from the 1970s to the 1990s and heparticipated in the Mahavishnu Orchestra.
Hewas influenced by Miles Davis.
"Avatar" waswritten during the Fusion period.Figure 1: A generated description without comparisons.Unlike "Fracture" and "A Mystery in Town",which were written by Eddie "Lockjaw" Davis andwere performed by Fats Navarro, "Avatar" waswritten by Gary Husband and it was performed byBilly Cobham.
Cobham originated from PanamaCity, Panama and he played the drums; he wasactive from the 1970s to the 1990s and heparticipated in the Mahavishnu Orchestra.
Hewas influenced by Miles Davis.
"Avatar" waswritten during the Fusion period.Figure 2: A generated description with comparisons topreviously described songs.artists by their ?popularity rank?
in the allmusic.comdatabase.
However, we had to maintain a carefulbalance between obscure artists and the ability togenerate interesting comparisons.
Obscure artistshad less detailed information in the allmusic.comdatabase than popular music artists, so were forcedto select a few popular music artists for our exper-iment, as their music pieces had multiple possibleinteresting comparisons.3 ExperimentWe tried to maintain as many conditions from theprevious, similar study (Karasimos and Isard, 2004)as possible to allow us to directly compare our re-sults to theirs.
The previous study established thatpeople learned more and perceived that they learnedmore from text enriched with comparisons and ag-gregations of facts than from texts that containedneither.
Our experimental design was similar totheirs but all conditions of our experiment containedtext generated with aggregations of facts; our aimwas to isolate the effects of comparisons from thoseof sentence aggregation.For jazz texts, comparisons between songs involv-ing performers, albums, composers, and time peri-ods were possible.
Classical texts could produceall four of these types of comparisons.
In addi-tion, classical texts could also include comparisonsof conductors.
Although the potential similarities170for classical and jazz texts were not equal, we de-cided to include the conductor as a potential com-parison for classical music.
This is because acrossboth text types, we maintained the same number ofgenerated comparisons for each text type by limit-ing Methodius to generating only one comparisonor contrast per paragraph of text.
We present exam-ples of a paragraph of text generated by Methodiuswithout (Figure 1) and with (Figure 2) comparisons.In both cases, we assume that the user has alreadyseen texts about the songs ?Fracture?
and ?A Mys-tery in Town?, which expressed the facts about theseprevious songs which are used in the comparisons inFigure 2; the comparison text does not contain morenew information.3.1 Evaluation DesignFor our user study, we created a web interface usingWebExp2 Experiment Design software5 that con-tained text generated by Methodius from our musicfact knowledge base.
Forty fluent English speak-ers were recruited and directed to a web page thatgave detailed instructions.
After providing some ba-sic personal information including their name, age,gender, occupation and native languages, subjectsstarted with a test page, where they read a sampleparagraph and responded to one factual question, tomake sure that they had understood the interface,and they then proceeded to the main experiment.Participants read 6 paragraphs about either jazzor classical music, and answered 15 factual recallquestions.
They then read a further 6 paragraphsabout the other type of music, followed by 15 fac-tual recall questions on the second set of texts.
Fi-nally they completed a post-experimental survey of12 Likert Scale questions (Likert, 1932).
We useda within-subjects design, where each subject sawtwo sets of texts, one classical and one jazz, onewith and one without comparisons, and the orderin which text sets were presented was controlled.The multiple choice questions did not change giventhe condition; so every participant saw the sametwo sets of 15 multiple-choice questions in random-ized orders.
Seven multiple-choice questions of eachfifteen-question set dealt with facts that may be rein-forced by comparisons.
The remaining eight ques-5http://www.webexp.infoGroup Texts with com-parisonsTexts withoutcomparisonsA 4.15 (1.814) 3.35 (1.872)B 4.45 (1.638) 3.10 (1.651)All 4.30 (1.713) 3.23 (1.747)Table 1: Mean multiple choice scores with standard devi-ation in brackets.tions in each section served as a control for this ex-periment.On each page, the interface presented an image ofa paragraph of text generated by Methodius.
Theusers proceeded to the next paragraph when theywere ready by pressing the ?Next song?
or ?Nextpiece?
button, depending on whether the music typewas jazz or classical.
The texts were presented asimages for two reasons: so that the presentation ofstimuli would remain consistent across the differ-ent computers and to prevent the text from beingselected by the participant, thus discouraging themfrom copying the text and placing it into anotherwindow as a reference to answer the factual recallquestions asked later.4 ResultsA summary of the participants?
multiple choicescores are shown in Table 1.
Group A read classi-cal texts with comparisons and jazz texts without,and Group B read jazz texts with comparisons andclassical texts without.We performed a 2-way repeated measuresANOVA on our data and found that participants per-formed significantly better on questions about thetexts which had comparisons (F (1, 36) = 11.131,p < .01).
There were no ordering or groupingeffects?the performance of participants did not de-pend on which type of texts they saw first, or onwhich type of texts contained comparisons.In general, the Likert scores showed no signifi-cant differences between the texts which had com-parisons and those which did not.
Karasimos andIsard (2004) did find significant differences, but intheir case, texts had either comparisons and sen-tence aggregations, or neither.
In our study, all thetexts had sentence aggregations, so it may be thisfactor which contributed to their higher Likert re-171sults on questions such as ?I enjoyed reading aboutthese songs?
and the binary ?Which text (quality,fluency) did you like more?
question, for which wealso found no significant difference.
Details of re-sults and statistics can be found in (Marge, 2007).5 Conclusions and Future WorkWe have shown that the Methodius comparison gen-eration algorithm does generalize to new domains,and that it is possible to quickly author a new domainand generate fluent and readable text, using an ap-propriate authoring tool.
We have also confirmed thefindings of previous studies, and showed that the useof comparisons in texts does significantly improveparticipants?
recall of the facts which they have read.In future work, we would like to use the cur-rent text generation in an automatic DJ system withstreaming music, and perform further user studies inorder to make the texts as interesting and relevantas possible.
We would also like to perform a studyin which we compare the output of the comparisonalgorithm using different parameter settings, to seewhether users express a preference.Since this work was carried out, Methodius hasbeen adapted to accept ontologies and sentenceplans written in OWL/RDF.
These can be createdusing the Prote?ge?
editor6 with an NLG plugin de-veloped at the Athens University of Economics andBusiness as part of the NaturalOWL generation sys-tem (Galanis and Androutsopoulos, 2007), which isavailable as an open source package7.
A more prin-cipled method for the OpenCCG conversion processthan the one described in Section 2.2 is in develop-ment, and we hope to publish a paper on this subject.AcknowledgementsThe authors would like to acknowledge the helpand advice given by Colin Matheson, Ellen Bard,Keith Edwards, Ray Carrick, Frank Keller, and NeilMayo and the comments of the anonymous review-ers.
This work was funded in part by a grant fromthe Edinburgh-Stanford Link and by the Saint An-drew?s Society of the State of New York.
The musicdata in this study was used with the permission ofthe All Music Guide.6http://www.protege.stanford.edu7http://www.aueb.gr/users/ion/software/NaturalOWL.tar.gzReferencesI.
Androutsopoulos, J. Oberlander, and V. Karkaletsis.2007.
Source authoring for multilingual generationof personalised object descriptions.
Natural LanguageEngineering, 13:191?233.R.
Cox, M. O?Donnell, and J. Oberlander.
1999.
Dy-namic versus static hypermedia in museum education:an evaluation of ILEX, the intelligent labelling ex-plorer.
In Proceedings of the Artificial Intelligence inEducation conference, Le Mans.R.
Dale, J.
Green, M. Milosavljevic, C. Paris, C. Ver-spoor, and S. Williams.
1998.
The realities of gener-ating natural language from databases.
In Proceedingsof the 11th Australian Joint Conference on ArtificialIntelligence, Brisbane, Australia.D.
Galanis and I. Androutsopoulos.
2007.
Generatingmultilingual descriptions from linguistically annotatedOWL ontologies: the NaturalOWL system.
In Pro-ceedings of ENLG 2007.A.
Isard, J. Oberlander, I. Androutsopoulos, and C. Math-eson.
2003.
Speaking the users?
languages.
IEEE In-telligent Systems, 18(1):40?45.
Special Issue on Ad-vances in Natural Language Processing.A.
Isard.
2007.
Choosing the best comparison underthe circumstances.
In Proceedings of the InternationalWorkshop on Personalization Enhanced Access to Cul-tural Heritage, Corfu, Greece.A.
Karasimos and A. Isard.
2004.
Multi-lingual eval-uation of a natural language generation system.
InProceedings of the Fourth International Conference onLanguage Resources and Evaluation, Lisbon, Portu-gal.R.
Likert.
1932.
A technique for the measurement ofattitudes.
Archives of Psychology, 22(140):1?55.M.
Marge.
2007.
An evaluation of comparison genera-tion in the methodius natural language generation sys-tem.
Master?s thesis, University of Edinburgh.K.
McKeown.
1985.
Text Generation: Using DiscourseStrategies and Focus Constraints to Generate Natu-ral Language Text.
Cambridge University Press, NewYork, NY, USA.M.
Milosavljevic.
1997.
Content selection in compari-son generation.
In 6th European Workshop on NaturalLanguage Generation), Duisburg, Germany.M.
O?Donnell, C. Mellish, J. Oberlander, and A. Knott.2001.
ILEX: An architecture for a dynamic hypertextgeneration system.
Natural Language Engineering,7:225?250.M.White.
2006.
Efficient realization of coordinate struc-tures in combinatory categorial grammar.
Research onLanguage and Computation, 4(1):39?75.172
