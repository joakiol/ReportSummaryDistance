Part of Speech Tagging in ContextMichele BANKO and Robert C. MOOREMicrosoft ResearchOne Microsoft WayRedmond, WA 98052 USA{mbanko, bobmoore}@microsoft.comAbstractWe present a new HMM tagger that exploitscontext on both sides of a word to be tagged, andevaluate it in both the unsupervised and supervisedcase.
Along the way, we present the firstcomprehensive comparison of unsupervisedmethods for part-of-speech tagging, noting thatpublished results to date have not been comparableacross corpora or lexicons.
Observing that thequality of the lexicon greatly impacts the accuracythat can be achieved by the algorithms, we presenta method of HMM training that improves accuracywhen training of lexical probabilities is unstable.Finally, we show how this new tagger achievesstate-of-the-art results in a supervised, non-trainingintensive framework.1 IntroductionThe empiricist revolution in computationallinguistics has dramatically shifted the acceptedboundary between what kinds of knowledge arebest supplied by humans and what kinds are bestlearned from data, with much of the human-supplied knowledge now being in the form ofannotations of data.
As we look to the future, weexpect that relatively unsupervised methods willgrow in applicability, reducing the need forexpensive human annotation of data.With respect to part-of-speech tagging, webelieve that the way forward from the relativelysmall number of languages for which we cancurrently identify parts of speech in context withreasonable accuracy will make use of unsupervisedmethods that require only an untagged corpus anda lexicon of words and their possible parts ofspeech.
We believe this based on the fact that suchlexicons exist for many more languages (in theform of conventional dictionaries) than extensivehuman-tagged training corpora exist for.Unsupervised part-of-speech tagging, as definedabove, has been attempted using a variety oflearning algorithms (Brill 1995, Church, 1988,Cutting et.
al.
1992, Elworthy, 1994 Kupiec 1992,Merialdo 1991).
While this makes unsupervisedpart-of-speech tagging a relatively well-studiedproblem, published results to date have not beencomparable with respect to the training and testdata used, or the lexicons which have been madeavailable to the learners.In this paper, we provide the first comprehensivecomparison of methods for unsupervised part-of-speech tagging.
In addition, we explore two newideas for improving tagging accuracy.
First, weexplore an HMM approach to tagging that usescontext on both sides of the word to be tagged,inspired by previous work on buildingbidirectionality into graphical models (Lafferty et.al.
2001, Toutanova et.
al.
2003).
Second wedescribe a method for sequential unsupervisedtraining of tag sequence and lexical probabilities inan HMM, which we observe leads to improvedaccuracy over simultaneous training with certaintypes of models.In section 2, we provide a brief description ofthe methods we evaluate and review publishedresults.
Section 3 describes the contextualizedvariation on HMM tagging that we have explored.In Section 4 we provide a direct comparison ofseveral unsupervised part-of-speech taggers, whichis followed by Section 5, in which we present anew method for training with suboptimal lexicons.In section 6, we revisit our new approach to HMMtagging, this time, in the supervised framework.2 Previous WorkA common formulation of an unsupervised part-of-speech tagger takes the form of a hidden Markovmodel (HMM), where the states correspond topart-of-speech tags, ti, and words, wi, are emittedeach time a state is visited.
The training of HMM?based taggers involves estimating lexicalprobabilities, P(wi|ti), and tag sequenceprobabilities, P(ti | ti-1 ... ti-n).
The ultimate goal ofHMM training is to find the model that maximizesthe probability of a given training text, which canbe done easily using the forward-backward, orBaum-Welch algorithm (Baum et al1970, Bahl,Jelinek and Mercer, 1983).
These modelprobabilities are then used in conjunction with theViterbi algorithm (Viterbi, 1967) to find the mostprobable sequence of part-of-speech tags for agiven sentence.When estimating tag sequence probabilities, anHMM tagger, such as that described in Merialdo(1991), typically takes into account a historyconsisting of the previous two tags -- e.g.
wecompute  P(ti | ti-1, ti-2).
Kupiec (1992) describes amodified trigram HMM tagger in which hecomputes word classes for which lexicalprobabilities are then estimated, instead ofcomputing probabilities for individual words.Words contained within the same equivalenceclasses are those which possess the same set ofpossible parts of speech.Another highly-accurate method for part-of-speech tagging from unlabelled data is Brill?sunsupervised transformation-based learner (UTBL)(Brill, 1995).
Derived from his supervisedtransformation-based tagger (Brill, 1992), UTBLuses information from the distribution ofunambiguously tagged data to make informedlabeling decisions in ambiguous contexts.
Incontrast to the HMM taggers previously described,which make use of contextual information comingfrom the left side only, UTBL considers both leftand right contexts.Reported tagging accuracies for these methodsrange from 87% to 96%, but are not directlycomparable.
Kupiec?s HMM class-based tagger,when trained on a sample of 440,000 words of theoriginal Brown corpus, obtained a test set accuracyof 95.7%.
Brill assessed his UTBL tagger using350,000 words of the Brown corpus for training,and found that 96% of words in a separate200,000-word test set could be tagged correctly.Furthermore, he reported test set accuracy of95.1% for the UTBL tagger trained on 120,000words of Penn Treebank and tested on a separatetest set of 200,000 words taken from the samecorpus.
Finally, using 1 million words from theAssociated Press for training, Merialdo?s trigramtagger was reported to have an accuracy of 86.6%.This tagger was assessed using a tag set other thanthat which is employed by the Penn Treebank.Unfortunately none of these results can bedirectly compared to the others, as they have useddifferent, randomized and irreproducible splits oftraining and test data (Brill and Kupiec), differenttag sets (Merialdo) or different corpora altogether.The HMM taggers we have discussed so far aresimilar in that they use condition only on leftcontext when estimating probabilities of tagsequences.
Recently, Toutanova et al (2003)presented a supervised conditional Markov Modelpart-of-speech tagger (CMM) which exploitedinformation coming from both left and rightcontexts.
Accuracy on the Penn Treebank usingtwo tags to the left as features in addition to thecurrent tag was 96.10%.
When using tag to the leftand tag to the right as features in addition to thecurrent tag, accuracy improved to 96.55%.Lafferty et al (2001) also compared theaccuracies of several supervised part-of-speechtagging models, while examining the effect ofdirectionality in graphical models.
Using a 50%-50% train-test split of the Penn Treebank to assessHMMs, maximum entropy Markov models(MEMMs) and conditional random fields (CRFs),they found that CRFs, which make use ofobservation features from both the past and future,outperformed HMMs which in turn outperformedMEMMs.3 Building More Context into HMM TaggingIn a traditional HMM tagger, the probability oftransitioning into a state representing tag ti iscomputed based on the previous two tags ti-1 and ti-2, and the probability of a word wi is conditionedonly on the current tag ti.
This formulation ignoresdependencies that may exist between a word andthe part-of-speech tags of the words which precedeand follow it.
For example, verbs whichsubcategorize strongly for a particular part-of-speech but can also be tagged as nouns orpronouns (e.g.
?thinking that?)
may benefit frommodeling dependencies on future tags.To model this relationship, we now estimate theprobability of a word wi based on tags ti-1 and ti-+1.This change in structure, which we will call acontextualized HMM, is depicted in Figure 1.
Thistype of structure is analogous to context-dependentphone models used in acoustic modeling forspeech recognition (e.g.Young, 1999, Section 4.3).3.1 Model DefinitionIn order to build both left and right-context into anHMM part-of-speech tagger, we reformulate theFigure 1: Graphical Structure of TraditionalHMM Tagger (top) and Contextualized HMMTagger (bottom)trigram HMM model traditionally described as?=????
?=niiiiiiiiii twtwtpttwtwwpTWp1111111 )..|()...|(),(by replacing the approximation:)|()..|()|()...|(12111111?????
?==iiiiiiiiiiiiitttptwtwtptwptwtwwpwith the approximation:)|()..|()|()...|(1211111111????+??
?==iiiiiiiiiiiiiiitttptwtwtptttwptwtwwpGiven that we are using an increased context sizeduring the estimation of lexical probabilities, thusfragmenting the data, we have found it desirable tosmooth these estimates, for which we use astandard absolute discounting scheme (Ney, Essenand Knesser, 1994).4 Unsupervised Tagging: A Comparison4.1 Corpora and Lexicon ConstructionFor our comparison of unsupervised taggingmethods, we implemented the HMM taggersdescribed in Merialdo (1991) and Kupiec (1992),as well as the UTBL tagger described in Brill(1995).
We also implemented a version of thecontextualized HMM using the type of wordclasses utilized in the Kupiec model.
Thealgorithms were trained and tested using version 3of the Penn Treebank, using the training,development, and test split described in Collins(2002) and also employed by Toutanova et al(2003) in testing their supervised taggingalgorithm.
Specifically, we allocated sections 00-18 for training, 19-21 for development, and 22-24for testing.
To avoid the problem of unknownwords, each learner was provided with a lexiconconstructed from tagged versions of the fullTreebank.
We did not begin with any estimates ofthe likelihoods of tags for words, but only theknowledge of what tags are possible for each wordin the lexicon, i.e., something we could obtainfrom a manually-constructed dictionary.4.2 The Effect of Lexicon Construction onTagging AccuracyTo our surprise, we found initial tag accuracies ofall methods using the full lexicon extracted fromthe Penn Treebank to be significantly lower thanpreviously reported.
We discovered this was due toseveral factors.One issue we noticed which impacted taggingaccuracy was that of a frequently occurring word(a) The/VB Lyneses/NNP ,/, of/IN Powder/NNPSprings/NNP ,/, Ga./NNP ,/, have/VBPfiled/VBN suit/NN in/IN Georgia/NNPstate/NN court/NN against/IN Stuart/NNPJames/NNP ,/, *-1/-NONE- alleging/VBGfraud/NN ./.
(b) Last/JJ week/NN CBS/NNP Inc./NNPcancelled/VBD ``/`` The/NNP People/NNPNext/NNP Door/NNP ./.
''/''(c) a/SYM -/: Discounted/VBN rate/NN ./.Figure 2:  Manually-Tagged Examplesbeing mistagged during Treebank construction, asshown in the example in Figure 2a.
Since we arenot starting out with any known estimates forprobabilities of tags given a word, the learnerconsiders this tag to be just as likely as the word?sother, more probable, possibilities.
In another,more frequently occurring scenario, humanannotators have chosen to tag all words in multi-word names, such as titles, with the proper-nountag, NNP (Figure 2b).
This has the effect of addingnoise to the set of tags for many closed-classwords.Finally, we noticed that a certain number offrequently occurring words (e.g.
a, to, of) aresometimes labeled with infrequently occurring tags(e.g.
SYM, RB), as exemplified in Figure 2c.
In thecase of the HMM taggers, where we begin withuniform estimates of both the state transitionprobabilities and the lexical probabilities, thelearner finds it difficult to distinguish betweenmore and less probable tag assignments.We later discovered that previousimplementations of UTBL involved limiting whichpossible part of speech assignments were placedinto the lexicon1, which was not explicitly detailedin the published reports.
We then simulated, in asimilar fashion, the construction of higher qualitylexicons by using relative frequencies of tags foreach word from the tagged Treebank to limitallowable word-tag assignments.
That is, tags thatappeared the tag of a particular word less than X%of the time were omitted from the set of possibletags for that word.
We varied this threshold untilaccuracy did not significantly change on our set ofheldout data.
The effect of thresholding tags basedon relative frequency in the training set is shownfor our set of part-of-speech taggers in the curve inFigure 3.
As shown in Table 1, the elimination ofnoisy possible part-of-speech assignments raisedaccuracy back into the realm of previouslypublished results.
The best test set accuracies forthe learners in the class of HMM taggers are1Eric Brill, Personal Communication0.700.750.800.850.900.951.000 0.1 0.2 0.3ThresholdTagAccuracyMerialdo TrigramContextual TrigramKupiec TrigramUTBLFigure 3:  The effect of lexicon construction onunsupervised part-of-speech taggers0.600.650.700.750.800.850.900.951.000 1 2 3 4 5IterationTagAccuracyContextual TrigramKupiec TrigramMerialdo TrigramFigure 4: Test Accuracy of HMMs usingOptimzed Lexiconsplotted against the number of training iterations inFigure 4.5 Unsupervised Training With NoisyLexiconsWhile placing informed limitations on the tags thatcan be included in a lexicon can dramaticallyimprove results, it is dependent on some form ofsupervision ?
either from manually tagged data orby a human editor who post-filters anautomatically constructed list.
In the interest ofbeing as unsupervised as possible, we sought tofind a way to cope with the noisy aspects of theunfiltered lexicon described in the previoussection.We suspected that in order to better control thetraining of lexical probabilities, having a stablemodel of state transition probabilities would be ofhelp.
We stabilized this model in two ways.UnfilteredLexiconOptimizedLexiconMerialdo HMM 71.9 93.9ContextualizedHMM 76.9 94.0Kupiec HMM 77.1 95.9UTBL 77.2 95.9ContextualizedHMM with Classes 77.2 95.9Table 1: Tag Accuracy of Unsupervised POSTaggers5.1 Using Unambiguous Tag Sequences ToInitialize Contextual ProbabilitiesFirst, we used our unfiltered lexicon along with ourtagged corpus to extract non-ambiguous tagsequences.
Specifically, we looked for trigrams inwhich all words contained at most one possiblepart-of-speech tag.
We then used these n-gramsand their counts to bias the initial estimates of statetransitions in the HMM taggers.
This approach issimilar to that described in Ratnaparhki (1998),who used unambiguous phrasal attachments totrain an unsupervised prepositional phraseattachment model.5.2 HMM Model Training RevisedSecond, we revised the training paradigm forHMMs, in which lexical and transitionprobabilities are typically estimatedsimultaneously.
We decided to train the transitionmodel probabilities first, keeping the lexicalprobabilities constant and uniform.
Using theestimates initially biased by the method previouslymentioned, we train the transition model until itreaches convergence on a heldout set.
We then usethis model, keeping it fixed, to train the lexicalprobabilities, until they eventually converge onheldout data.5.3 ResultsWe implemented this technique for the Kupiec,Merialdo and Contextualized HMM taggers.
Fromour training data, we were able to extract data foron the order of 10,000 unique unambiguous tagsequences which were then be used for betterinitializing the state transition probabilities.
Asshown in Table 2, this method improved taggingaccuracy of the Merialdo and contextual taggersover traditional simultaneous HMM training,reducing error by 0.4 in the case of Merialdo and0.7 for the contextual HMM part-of-speech tagger.HMM TaggerSimultaneousModelTrainingSequentialModelTrainingMerialdo 93.9 94.3Contextualized 94.0 94.7Kupiec 95.9 95.9Table 2: Effects of HMM Training on TaggerAccuracyIn this paradigm, tagging accuracy of the KupiecHMM did not change.6 Contextualized Tagging with SupervisionAs one more way to assess the potential benefitfrom using left and right context in an HMMtagger, we tested our tagging model in thesupervised framework, using the same sections ofthe Treebank previously allocated for unsupervisedtraining, development and testing.
In addition tocomparing against a baseline tagger, which alwayschooses a word?s most frequent tag, weimplemented and trained a version of a standardHMM trigram tagger.
For further comparison, weevaluated these part of speech taggers againstToutanova et als supervised dependency-networkbased tagger, which currently achieves the highestaccuracy on this dataset to date.
The best result forthis tagger, at 97.24%, makes use of both lexicaland tag features coming from the left and rightsides of the target.
We also chose to examine thistagger?s results when using only <ti, t i-1, t i+1> asfeature templates, which represents the sameamount of context built into our contextualizedtagger.As shown in Table 3, incorporating morecontext into an HMM when estimating lexicalprobabilities improved accuracy from 95.87% to96.59%, relatively reducing error rate by 17.4%.With the contextualized tagger we witness a smallimprovement in accuracy over the current state ofthe art when using the same amount of context.
Itis important to note that this accuracy can beobtained without the intensive training required byToutanova et.
al?s log-linear models.
This resultfalls only slightly below the full-blown training-intensive dependency-based conditional model.7 ConclusionsWe have presented a comprehensive evaluation ofseveral methods for unsupervised part-of-speechtagging, comparing several variations of hiddenMarkov model taggers and unsupervisedtransformation-based learning using the samecorpus and same lexicons.
We discovered that theSupervised Tagger Test AccuracyBaseline 92.19Standard HMM 95.87Contextualized HMM 96.59DependencyUsing LR tag features 96.55DependencyBest Feature Set 97.24Table 3: Comparison of Supervised Taggersquality of the lexicon made available tounsupervised learner made the greatest differenceto tagging accuracy.
Filtering the possible part-of-speech assignments contained in a basic lexiconautomatically constructed from the commonly-used Penn Treebank improved results by as muchas 22%.
This finding highlights the importance ofthe need for clean dictionaries whether they areconstructed by hand or automatically when weseek to be fully unsupervised.In addition, we presented a variation on HMMmodel training in which the tag sequence andlexical probabilities are estimated in sequence.This helped stabilize training when estimation oflexical probabilities can be noisy.Finally, we experimented with using left andright context in the estimation of lexicalprobabilities, which we refer to as a contextualizedHMM.
Without supervision, this new HMMstructure improved results slightly compared to asimple trigram tagger as described in Merialdo,which takes into account only the current tag inpredicting the lexical item.
With supervision, thismodel achieves state of the art results without thelengthy training procedure involved in other high-performing models.
In the future, we will considermaking an increase the context-size, which helpedToutanova et al (2003).8 AcknowledgementsThe authors wish to thank Gideon Mann forperforming some initial experiments with apublicly available implementation of UTBL, andEric Brill for discussions regarding his work onunsupervised transformation based learning.ReferencesL.R.
Bahl, F. Jelinek, and R. Mercer.
1983.
Amaximum likelihood approach to continuousspeech recognition.
IEEE Transactions onPattern Analysis and Machine Intelligence,5(2):179--190.L.E.
Baum, T. Petrie, G. Soules, and N. Weiss.
Amaximization technique in the statistical analysisof probabilistic functions of Markov chains.Annals of Mathematical Statistics, 41:164-171.E.
Brill.
1992.
A simple rule-based part of speechtagger.
In Proceedings of the Third Conferenceon Applied Natural Language Processing, ACL.Trento, Italy.E.
Brill.
1995.
Unsupervised learning ofdisambiguation rules for part of speech tagging.In Proceedings of the Third Workshop on VeryLarge Corpora, Cambridge, MA.K.
Church.
1998.
A stochastic parts program andnoun phrase parser for unrestricted text.
InSecond Conference on Applied NaturalLanguage Processing, ACL.M.
Collins.
2002.
Discriminative training methodsfor hidden Markov models: theory andexperiments with perceptron algorithms.
InProceedings of the Conference on EmpiricalMethods in Natural Language Processing,Philadelphia, PA.D.
Cutting, J. Kupiec, J. Pedersen and P. Sibun.1992.
A practical part-of-speech tagger.
In ThirdConference on Applied Natural LanguageProcessing.
ACL.D.
Elworthy.
1994.
Does Baum-Welch re-estimation help taggers.
In Proceedings of theFourth Conference on Applied NaturalLanguage Processing, ACL.J.
Kupiec.
1992.
Robust part-of-speech taggingusing a hidden Markov model.
Computer Speechand Language 6.J.
Lafferty, A. McCallum, and F. Pereira.
2001.Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
InProceedings of ICML-01, pages 282-289.B.
Merialdo.
1991.
Tagging English text with aprobabilistic model.
In Proceedings of ICASSP.Toronto, pp.
809-812.H.
Ney, U. Essen and R. Kneser.
1994.
Onstructuring probabilistic dependencies instochastic language modeling.
Computer, Speechand Language, 8:1-38.A.
Ratnaparkhi.
1998.
Unsupervised statisticalmodels for prepositional phrase attachment.
InProceedings of the Seventeenth InternationalConference on Computational Linguistics.Montreal,  Canada.K.
Toutanova, D. Klein, C. Manning, and Y.Singer.
2003.
Feature-Rich Part-of-SpeechTagging with a Cyclic Dependency Network.
InProceedings of HLT-NAACL.
pp.
252-259.A.J.
Viterbi.
1967.
Error bounds for convolutionalcodes and an asymptotically optimal decodingalgorithm.
IEEE Transactions on InformationTheory, 13:260--269.S.
Young.
1999.
Acoustic modelling for largevocabulary continuous speech recognition.Computational Models of Speech PatternProcessing: Proc NATO Advance Study Institute.K.
Ponting, Springer-Verlag: 18-38.
