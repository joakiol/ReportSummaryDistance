Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 2?11,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsA Comparison of Approaches for Sentiment Classification on LithuanianInternet CommentsJurgita Kapoc?iu?te?-Dzikiene?Kaunas University of Tech-nology / K. Donelaic?io 73,LT-44249 Kaunas, Lithuaniajurgita.k.dz@gmail.comAlgis Krupavic?iusKaunas University of Tech-nology / K. Donelaic?io 73,LT-44249 Kaunas, Lithuaniapvai@ktu.ltTomas Krilavic?iusBaltic Institute of AdvancedTechnology / Saule?tekio 15,LT-10224 Vilnius, Lithuaniat.krilavicius@bpti.ltAbstractDespite many methods that effectivelysolve sentiment classification task for suchwidely used languages as English, thereis no clear answer which methods arethe most suitable for the languages thatare substantially different.
In this paperwe attempt to solve Internet commentssentiment classification task for Lithua-nian, using two classification approaches ?knowledge-based and supervised machinelearning.
We explore an influence of senti-ment word dictionaries based on the differ-ent parts-of-speech (adjectives, adverbs,nouns, and verbs) for knowledge-basedmethod; different feature types (bag-of-words, lemmas, word n-grams, charactern-grams) for machine learning methods;and pre-processing techniques (emoticonsreplacement with sentiment words, dia-critics replacement, etc.)
for both ap-proaches.
Despite that supervised ma-chine learning methods (Support Vec-tor Machine and Na?
?ve Bayes Multino-mial) significantly outperform proposedknowledge-based method all obtained re-sults are above baseline.
The best accu-racy 0.679 was achieved with Na?
?ve BayesMultinomial and token unigrams plus bi-grams, when pre-processing involved dia-critics replacement.1 IntroductionAn automatic extraction of opinions from a texthas become an area of growing interest in therecent years.
Due to the user-generated contentavailable on the Internet companies can measurethe feedback about their products or services; so-ciologists can look at people?s reaction about pub-lic events; psychologists can study general mind-state of communities with regard to various issues;etc.
Thus sentiment classification helps solvingmany various tasks, ranging from a very general tothe very specific, requiring special solutions.
Ma-jority of tasks consider the content in general byfocusing on the subjectivity vs. objectivity or se-mantic orientation (positive vs. negative) detectionof reviews, tweets, blogs, or Internet comments.Others are solving very specific tasks, e.g.
earlythreats detection (Bouma et al 2012), predictionof user?s potentiality to send out offensive content(Chen et al 2012), etc.But even adaptation to the task is not always ef-fective due to the variations and complexity of thelanguage.
Sentiments are not always expressedexplicitly, while for the meanings hidden in thecontext additional world knowledge is necessary.Moreover, sentiments may involve sarcasm and beinterpreted differently in various domains and con-texts.
Despite all the mentioned difficulties, senti-ment classification task is rather easy for us, hu-mans, but manual analysis is time consuming andrequires a lot of human-resources.
Due to this factautomatic sentiment classifiers are often selectedinstead.Various classification techniques effectivelysolve sentiment classification task for such widelyused languages as English, but there is no clear an-swer which method is the most suitable for Lithua-nian.
Our focus is at finding classification ap-proach yielding the best results on Lithuanian In-ternet comments by classifying them into positive,negative and neutral categories.2 Related WorkDue to the complexity of sentiment classificationtask, there is a vast variety of methods tryingto tackle this problem (for review see Pang andLee (2008)).All methods used to solve sentiment classifi-cation task fall into the three main categories:knowledge-based, machine learning and hybrid.2In knowledge-based approaches sentiment is seenas the function of keywords (usually based on theircount).
Thus the main task is the constructionof sentiment discriminatory-word lexicons withindicated class labels (positive or negative) andsometimes even with their intensiveness.
Lexi-cons are constructed either manually (Taboada etal., 2011) or semi-automatically making use ofsuch resources as WordNet (Hu and Liu, 2004);(Esuli and Sebastiani, 2006) or via word associa-tions based on the heuristics evaluating word?s oc-currence alongside with the ?seed?
words in thetext (Turney, 2002); (Turney and Littman, 2003).Adjectives (or adjectival phrases) are consid-ered as the most popular sentiment indicators, e.g.Benamara et al(2007) claim that adjectives andadverbs (chosen based on the proposed adverbscoring technique) give much better results thanadjectives alone; Taboada et al(2011) show thatsuch lexical items as nouns and verbs (not onlyadjectives and adverbs) can also carry importantsemantic polarity information.Ding and Liu (2007) argue that semantic orien-tation is content dependent task and words aloneare not sufficient sentiment indicators thus incor-porate them into the set of linguistic rules used inclassification; Choi and Cardie (2008) use heuris-tics based on the compositional semantics (consid-ering the effect of interactions among the words)and achieve better results over the methods notincorporating it; Taboada et al(2011) take intoaccount valence shifters (intensifiers, downtoners,negation and irrealis markers) that influence thepolarity of the neighboring words for English;Kuznetsova et al(2013) ?
for Russian.An alternative for the knowledge-based meth-ods is machine learning that in turn can be groupedinto supervised and clustering techniques.
Cluster-ing is rarely used due to the low accuracy, but thedrawback of supervised machine learning (that wewill further focus on) is that for model creation atraining dataset (with manually pre-assigned sen-timent class labels) is required.The main issue for supervised machine learningtechniques is proper selection of features.
Nev-ertheless, the most basic approach remains bag-of-words interpretation.
Pang et al(2002) showthat bag-of-words beat other feature types (basedon token bigrams, parts-of-speech information andword position in the text) with Support VectorMachine (SVM) method.
But on the contrary,Dave et al(2003) report that token n-grams (upto trigrams) can improve the performance com-pared with simple unigrams; Cui et al(2006) withhigher order token n-grams (n = 3, 4, 5, 6) andPassive Aggressive classifier outperform unigramsand bigrams; Pak and Parubek (2011) with tokenbigrams and Na?
?ve Bayes Multinomial methodoutperform both token unigrams and trigrams.Dave et al(2003) also report that stemming im-proves accuracy compared with the bag-of-wordsbaseline, but other linguistic features (negation,collocations of words, etc.)
on the contrary ?
hurtthe performance.
Raaijmakers and Kraaij (2008)use document-level character n-grams (n = 2, 3,4, 5, 6) with SVM (geodesic kernel); Hartmannet al(2011) claim that document-level charactern-grams used, namely, with Na?
?ve Bayes methodare even better choice than token n-grams (be-cause the probability of finding character n-gramis much higher and the relations between consec-utive words are still considered).Hybrid approaches combine both knowledge-based and machine learning methods thus achiev-ing superior performance.
As it is demonstratedby Mullen and Collier (2004) using SVM andcombined token unigram features with those basedon favorability measures (for phrases, adjectivesand even knowledge of topic).Sentiment classification results can be influ-enced by pre-processing as well.
E.g.
Kennedyand Inkpen (2006) claim that valence shifters andMukherjee and Bhattacharyya (2012) show thatdiscourse information incorporated into bag-of-words improve classification accuracy both forknowledge-based and SVM methods.
But oftenpre-processing techniques (such as emoticons re-placement, negation treatment and stop words re-moval) are selected without any considerations(e.g.
see in (Pak and Paroubek, 2011)).Both knowledge-based and supervised machinelearning methods are domain-dependent (whenclassifier trained in one domain can barely beatthe baseline in the other) and, moreover, domain-sensitive.
E.g.
Aue and Gamon (2005) withNa?
?ve Bayes and SVM classifiers show that differ-ent types of features work better across differentdomains; therefore usually methods are built forthe specific selected domain.
Sometimes domain-dependent problem is circumvented by extractingrelated content with manually created rules (Wanget al 2012) or via machine learning: i.e.
by3performing topicality classification at the firststep and sentiment afterwards (Hurst and Nigam,2004).
Read and Carroll (2009) solve domain-depended problem by using special methodologyto build the classifiers that are robust across thedifferent domains.Hence sentiment classification is domain andtask dependent problem.
Moreover, the perfor-mance of selected method can also depend on thelanguage.
E.g.
Boiy and Moens (2009) demon-strate that the best accuracy with token unigrams(augmented with linguistics features) is obtainedusing Na?
?ve Bayes Multinomial for English, SVMfor Dutch and Maximum Entropy for French lan-guage.
Besides, some solutions are proposed formultilingual texts as well, e.g.
Cheng and Zhu-lyn (2012) show that generalized bigram model(especially suitable for the languages with a flexi-ble word order) using Na?
?ve Bayes and logistic re-gression classifiers can achieve high accuracy ondifferent Germanic, Roman and East Asian lan-guages.We cannot provide any example of experimentsbased on sentiment classification for Lithuanian.Consequentially, this paper is the first attempt atfinding an accurate sentiment classification ap-proach (knowledge-based or machine learning) onLithuanian Internet comments.
Experiments willbe performed with different pre-processing tech-niques, lexicons, and feature types.3 The Lithuanian LanguageIn this section we discuss Lithuanian languageproperties focusing on those aspects (inflectionmorphology, word derivation system and word or-der in a sentence) that may be important in the sen-timent classification task.Lithuanian language has rich inflectional mor-phology, more complex than Latvian or Slavic lan-guages (Savickiene?
et al 2009).
Adjectives areinflected by 7 cases, 2 (+1) genders, 2 numbers,5 degrees of comparison, and have 2 pronomi-nal forms; adverbs ?
by 5 degrees of comparison;nouns ?
by 7 cases, 2 (+1) genders and 2 numbers;verbs ?
by 3 moods, 4 tenses, 2 numbers, and 3persons.
Besides, verbs can have non-conjugativeforms (participles, adverbial participles, verbal ad-verbs, and some forms of gerund) that can be in-flected by tense, case, gender, number, and have anactive or passive forms.
Various inflection formsin Lithuanian language are expressed by the dif-ferent endings (and suffixes), moreover, e.g.
nounshave 12 different inflection paradigms; adjectives?
9.Lithuanian language has rich word derivationsystem.
78 suffixes are used to derive diminutivesand hypocoristic words (Ulvydas, 1965), that areespecially frequent in spoken language; 25 pre-fixes are used for the nouns; 19 ?
for the verbs;and 3 (+4 in dialects) ?
for the adjectives andadjectival adverbs.
Suffixes and prefixes changethe meaning, e.g.
suffix ?-iaus-?
change ?geras?
(good) to ?geriausias?
(the best) (by the way, theending has to be adjusted to the new suffix, there-fore ?-as?
is replaced by ?-ias?
); prefix ?nu-?and reflexive participle ?-si-?
change ?s?neke?ti?
(totalk) to ?nusis?neke?ti?
(to blunder out).
Prefixes inLithuanian can also be used to derive phrasal verbs(e.g.
from ?eiti?
(to go) to ?i?eiti?
(to go in), ?is?eiti?
(to go out), etc.)
and negative words.The particle ?ne-?
(no, not) or ?nebe-?
(nolonger) giving to the words (adjectives, adjecti-val adverbs, adverbial adverbs, nouns, verbs andall their non-conjugative forms) an opposite mean-ing is attached to them as a prefix: ?geras?
(good)?
?negeras?
(not good); ?skaisc?iai?
(brightly) ??nebeskaisc?iai?
(no longer brightly); ?se?kme??
(afortune) ?
?nese?kme??
(a misfortune); ?be?gti?
(torun) ?
?nebebe?gti?
(no longer to run); etc.But if particle ?ne?, ?nebe?
or ?ne?ra?
(no, not)expresses contradiction, it is written separately(e.g.
in ?jis neblogas?
(he is not bad) ?ne?
goesas the prefix, but in ?jis ne blogas, o geras?
(he isnot bad, but good) ?ne?
goes separately.The difference between English and Lithuanianis that a negative idea in English is expressed byonly one negative word such as nothing, nobody,never, whereas in Lithuanian such sentence mustcontain two negated words, e.g.
?niekas gerainez?aidz?ia?
(nobody plays well) word-to-wordtranslation is (nobody well not plays); ?niekadanesakyk niekada?
(never say never) word-to-wordtranslation is (never not say never).The word order in Lithuanian sentences is free,but it performs notional function, i.e.
sentencesare grammatically correct regardless of the wordorder, but the meaning (things that are highlighted)can differ.
E.g.
whereas in ?tu esi labai geras?
(youare very good) intensifier ?labai?
(very) is high-lighted but in ?tu esi geras labai?
(you are verygood) adjective ?geras?
(good) is highlighted, thusthe first phrase gets higher positive intensiveness.44 Methodology4.1 DatasetThe dataset used in our sentiment classificationtask contains online Internet comments to articlescrawled from the largest Lithuanian daily newspa-per Lietuvos rytas (2013).
These comments reflectpeople?s opinions about the topical events in do-mestic and foreign politics, sport, etc.All Internet comments were manually labeledas positive, negative or neutral.
The decision aboutthe class label was based on a mutual agreementof two human-experts.
Efforts were made to fo-cus solely on each comment, but known topic andprevious posts could still influence experts?
deci-sion.
Ambiguous comments were discarded thusleaving only single-labeled ones.
Negative classstrongly dominated the others.
To maintain bal-anced class distribution the amount of comments(treated as instances in the classification process)belonging to the different classes was equalized bydiscarding redundant instances.
See statistics ofthe dataset in Table 1.ClasslabelNumberof in-stancesNumberof tokensNumberof distincttokensPositive 1,500 10,455 6,394Negative 1,500 15,000 7,827Neutral 1,500 13,165 4,039Total 4,500 38,621 15,008Table 1: Dataset statistics: the numbers were dis-carded; tokens (words) were transformed to lower-case.The dataset contains texts representing informalLithuanian language, i.e.
texts are full of slang,foreign language insertions, and barbarisms.
Be-sides, in the texts are a lot of typographical andgrammatical errors.
Moreover, Lithuanian lan-guage uses Latin script supplemented with diacrit-ics, but in informal texts, diacritics (a?, c?, e?, e?, i?,s?, u?, u?, z?)
are very often replaced with matchingLatin letters (a, c, e, e, i, s, u, u, z).4.2 Classification methodsSentiment classification task has never beensolved for Lithuanian; therefore it is unclear whichmethod could be the most suitable for the givendataset.
Consequentially, in this research we willcompare two different classification approaches ?knowledge-based and machine learning ?
apply-ing them on the informal texts.The keystone of our knowledge-based approachis the lexicon that is applied to recognize senti-ment words in the text.
In our experiments weused two lexicons (see Table 2): manually labeledand automatically augmented one.
Both lexiconsare composed of 4 dictionaries: for adjectives, ad-verbs, nouns and verbs, respectively.
Only lem-mas (main words?
forms containing ending andsuffices/prefixes) are stored in the dictionaries.The candidates for the first lexicon wereextracted from 1 million running wordstaken from Vytautas Magnus University Cor-pus (Marcinkevic?iene?, 2000).
These texts repre-sent standard Lithuanian and were taken from sixdomains: fiction, legal texts, national newspapers,parliamentary transcripts, local newspapers, andpopular periodicals.
Words were transformedinto their lemmas using Lithuanian part-of-speechtagger and lemmatizer Lemuoklis (Zinkevic?ius,2000); (Daudaravic?ius et al 2007) and trans-ferred to the dictionaries containing appropriateparts-of-speech.
Words in the first lexicon weremanually labeled with their polarity values (-3/3means that the word is strongly negative/positive;-2/2 ?
moderately negative/positive; -1/1 ?
weaklynegative/positive; 0 ?
neutral).
The decision wastaken by mutual agreement of two human-expertsthat made efforts not to bind to the specific usecases, but consider only the most common senseof each word.
The second lexicon was created byautomatically augmenting the first one with thesynonyms taken from Lithuanian WordNet (2013).Words from the manually labeled lexicon wereused as the pre-selected ?seeds?
to search for thesynonyms that automatically obtained the samepolarity value and were added to the appropriatedictionaries.Semantic orientation of each instance was de-termined by summing the polarity values of recog-nized sentiment words in the lemmatized texts.
Iftotal polarity value was positive (> 0), the instancewas classified as positive; if negative (< 0) ?
asnegative; if zero (= 0) ?
as neutral.
E.g.
?Filmaslabai puikus?
(The film is great) would be clas-sified as positive, because valueOf (?Filmas?
)=0and valueOf (?puikus?
)=3, thus 0 + 3 = 3 > 0.As the alternative for knowledge-based methodwe used two machine learning methods ?
i.e.
Sup-port Vector Machine (SVM), introduced by Cortesand Wapnik (1995) and Na?
?ve Bayes Multinomial(NBM), introduced by Lewis and Gale (1994).5Polari-ty valueAdjecti-vesAdverbs Verbs Nouns Total-3 115 71 236 275 697138 74 236 296 744-2 151 120 333 719 1,323175 122 337 775 1,409-1 243 95 732 1,854 2,924267 95 733 1,945 3,0400 4,035 1,296 10,001 12,367 27,6994,392 1,362 10,039 12,719 28,5121 145 117 344 856 1,462163 122 344 896 1,5252 130 114 112 195 551148 117 113 213 5913 117 61 72 54 304142 62 72 55 331Total 4,936 1,874 11,830 16,3205,425 1,954 11,874 16,899Table 2: Dictionaries statistics: the first value ineach cell represents the number of items in manu-ally labeled lexicon; the second ?
augmented withWordNet.SVM is one of the most popular techniques fortext classification, because it can cope with highdimensional feature spaces (e.g.
15,008 word fea-tures in our dataset); sparseness of feature vec-tors (e.g.
among 15,008, each instance would haveonly ?3.34 non-zero word feature values); and in-stances do not sharing any common features (com-mon for short texts, e.g.
average length of in-stance in our dataset is ?8.58 words).
BesidesSVM does not perform aggressive feature selec-tion which may result in a loss of information.NBM method is also often used for text clas-sification tasks (mostly due its simplicity): Na?
?veBayes assumption of feature independence allowsparameters of each feature to be learned sepa-rately.
It performs especially well when the num-ber of features is large.
Besides, it is reported(e.g.
by Pak and Parubek (2011)) that NBM caneven outperform popular SVM in sentiment clas-sification tasks.In our experiments we used SMO kernel forSVM and NBM implementations in WEKA (Hallet al 2009) machine learning toolkit, version 3.61.All parameters were set to their default values.4.3 Experimental setupBefore classification experiments tokens (i.e.words) in the dataset were pre-processed using dif-ferent techniques.
Knowledge-based method re-quired lemmatization, whereas for machine learn-1http://www.cs.waikato.ac.nz/ml/weka/.ing methods lemmatization was optional.
De-spite that lemmatizer can solve disambiguationproblems and achieve ?0.94 accuracy on norma-tive Lithuanian texts (Rimkute?
and Daudaravic?ius,2007); it could not recognize even ?0.25 of wordsin our dataset.Other optional pre-processing techniques in-volved emoticons replacement with appropriatesentiment words; Lithuanian diacritics replace-ments with appropriate Latin letters; and stopwords removal.Emoticons replacement demonstrated positiveeffect on English (Read, 2005) and triggered usto create such list for Lithuanian.
The list contains32 sentiment words (written in lemmas) with theirappropriate and commonly used emoticon equiv-alents2.
Thus, e.g.
?:-)?
would be replaced by?laimingas?
(happy).Words with replaced Lithuanian diacritics canneither be found in the dictionaries, nor recog-nized by the Lithuanian lemmatizer and thereforerequire special treatment.
Whereas tools able torestore Lithuanian diacritics are not yet available,we have chosen opposite way by replacing all dia-critics with matching Latin letters in the text, dic-tionaries and emoticons list and in such a way de-creasing the number of unrecognized words (forknowledge-based method) and the sparseness offeature vector (for machine learning methods).Stop words removal cannot affect the perfor-mance of knowledge-based method, but it candecrease the sparseness of the data for machinelearning techniques.
In our experiments we usedstop words list with excluded interjections, be-cause Spencer and Uchyigit (2012) showed thatinterjections are strong indicators of subjectivity.Compulsory pre-processing steps includedtransformation of letters into lower-case, digitsand punctuation removal.
Statistics demonstratingthe effect of different pre-processing techniqueson the dataset are presented in Table 3.Pre-processing was performed in such an or-der that previous steps could not harm followingones, thus lemmatization was performed beforediacritics replacement, punctuation removal wasperformed after emoticons replacement, etc.Knowledge-based method was evaluated usingdifferent combinations of dictionaries, whereasmachine learning method ?
different types of fea-tures: token unigrams (the most common case);2http://www.cool-smileys.com/text-emoticons.6token unigrams plus bigrams, i.e.
token unigramscomplemented with token bigrams (higher ordern-grams sometimes outperform token unigrams);token lemmas (strongly recommended for highly-inflective languages); document-level character4-grams (this type was reported as the bestfor Lithuanian topic classification by Kapoc?iu?te?-Dzikiene?
et al(2012)).ClasslabelTokensafterlemma-tizationTokenswithemoti-consTokenswithoutstop-wordsTokenswithoutdiacrit-icsPositive 10,386 10,664 8,982 10,4553,177 4,027 3,941 3,724Negative 14,928 15,107 11,945 15,0006,475 7,811 7,716 7,457Neutral 13,084 13,226 10,427 13,1655,134 6,391 6,276 6,058Total 38,398 38,997 31,354 38,62111,669 14,966 14,923 13,983Table 3: Pre-processed dataset statistics: the firstvalue in each cell represents the number of all to-kens, the second ?
distinct tokens.
See Table 1 forunprocessed dataset statistics.We expect the following statements to be con-firmed experimentally: 1) emoticons replacementshould increase the results since they usually re-flect emotional state of the person; 2) diacrit-ics replacement or lemmatization should improvethe results by decreasing data sparseness and thenumber of unrecognized words; 3) all dictionariesshould give better results for the knowledge-basedmethod because contain more sentiment informa-tion; 4) machine learning methods should out-perform knowledge-based approach because sen-timents can be expressed in more complex ways.5 ResultsAccuracies (the number of correctly classified in-stances divided by all instances) of previously de-scribed experiments are summarized in Figure 1 ?Figure 3.Figure 1 summarizes the results obtained withthe knowledge-based method.
Figure 2 summa-rizes the results obtained with SVM method, Fig-ure 3 ?
with NBM.
10-fold cross-validation wasused in all experiments with machine learningmethods.6 DiscussionSince the balanced class distribution is maintained(see Table 1), both majority (probability to belongonly to a major class) and random (the sum ofsquared probabilities of all classes) baselines areequal to 0.333.
Figure 1 ?
Figure 3 show that ob-tained classification results are above the baseline.The best results using knowledge-based methodare achieved with emoticons and diacritics re-placement, as expected (see Section 4.3), butemoticons replacement is more effective.Augmented lexicon slightly outperforms manu-ally labeled.
Besides, adjectives, nouns and verbsimprove the classification results for knowledge-based approach, but adverbs worsen it.
Bad per-formance of adverbs contradicts our expectations.Analysis of erroneous cases revealed that verystrong negative adverbs (used in slang) such as?baisiai?
(terribly), ?z?iauriai?
(brutally), etc.
fol-lowed by the positive adjectives such as ?geras?
(good), ?nuostabus?
(wonderful) become positiveintensifiers.
Moreover, very often adverbs arefound in the context does not expressing any senti-ment at all, e.g.
?gerai?
(well) in ?gerai pasakyta?
(well said) should not be treated as positive word.The results obtained with different machinelearning methods ?
SVM and NBM are very con-tradictory and not always correspond to our ex-pectations (see Section 4.3).
In general the bestfeature type for SVM is either token unigrams ortoken lemmas; for NBM ?
token unigrams plus bi-grams, but token lemmas is the second best result.Longer phrases (based on token bigrams) increasethe sparseness of the data that seems to be harm-ful for SVM method, which does not perform ag-gressive feature selection.
Whereas NBM is not assensitive to it, token unigrams plus bigrams (car-rying more sentiment information) give the bestaccuracy.For both machine learning methods token lem-mas are effective enough.
The main problem isthat Lithuanian lemmatizer could not recognizeeven a quarter of all words in the dataset, thus itcan be assumed that this feature type could giveeven better results if lemmatizer would cope withinformal Lithuanian language as well.Results obtained by machine learning meth-ods show that document-level character 4-grams(giving the best results for topic classification onLithuanian texts) are not effective for sentimentclassification.
Character n-grams not only in-crease the sparseness, but result in a loss of im-portant information about Lithuanian suffixes andprefixes.
E.g.
?gera?
(good) and ?negera?
(not7Figure 1: Accuracy of knowledge-based method, obtained using different lexicons and pre-processingtechniques: groups of columns represent different combinations of dictionaries; shades of columns rep-resent pre-processing techniques (?No Diacritics?
stands for diacritics replacement, ?With Diacritics?for no replacement, ?With Emoticons?
for emoticons replacement, ?No Emoticons?
for no replacement);the first column of the same shade represents results obtained using manually labeled lexicon, the second?
augmented with WordNet.Figure 2: Accuracy of SVM method, obtained using different feature types and pre-processing tech-niques: groups of columns represent different pre-processing techniques (?With Emoticons?
stands foremoticons replacement, ?No Stop Words?
for stop words removal, ?No Diacritics?
for diacritics replace-ment); shades of columns represent different feature types.8Figure 3: Accuracy of NBM, obtained using different feature types and pre-processing techniques.good) contain the same 4 characters ?gera?, butprefix ?ne-?
reverses the polarity.As presented in Figure 2 and Figure 3 emoti-cons and diacritics replacement positively affectclassification results, but the effect is much weakercompared to the knowledge-based approach.
Ingeneral, for SVM there is no single pre-processingtechnique that could significantly stand out fromthe rest, while for NBM diacritics replacementis the best one, stop words removal is the worst.It can be assumed that despite stop words seemunimportant; they still carry sentiment informa-tion, especially significant using token bigrams.As expected (see Section 4.3), machine learn-ing methods significantly outperform knowledge-based.
One of the main reasons is that the lexiconsare not adjusted to a specific domain.
Our goal wasnot to achieve as high accuracy as possible, but todetermine a real potential of such method on in-formal Lithuanian texts.
The analysis of erroneouscases revealed that adjectives, nouns and verbs arenot the only sentiment indicators, e.g.
interjection?valio!?
(hurray!)
in ?valio!
Auksas!?
(hurray!Gold!)
can express positive sentiment also.Besides, diacritics replacement is still a consid-erable problem: e.g.
whereas lexicon contains?s?aunus?
(cool, in masculine gender); the sameword with replaced diacritics in feminine gender?sauni?
will neither be recognized by lemmatizer,nor found in the lexicon with replaced diacritics.The best result with knowledge-based methodexceeds baseline by 0.156; with machine learning?
by 0.346, but they are still low compared to theresults obtained on English texts.
Analysis of er-roneous cases revealed that classifiers mostly faildue to the language variations when sentimentsare expressed implicitly and require special treat-ment considering informal Lithuanian languagespecifics.7 Conclusion and perspectivesIn this paper we are solving Internet commentssentiment classification task for Lithuanian, usingtwo different approaches: knowledge-based andmachine learning.Adjectives, nouns and verbs (excluding ad-verbs) are the most important sentiment indica-tors for the knowledge-based approach that wassignificantly outperformed by the machine learn-ing methods.
The best accuracy 0.679 is obtainedusing Na?
?ve Bayes Multinomial with token uni-grams plus bigrams as features and diacritics re-placement as pre-processing technique.In the future research we are planning to per-form detailed class-wise error analysis that couldhelp to find the solutions decreasing the number oferroneous cases.
Besides, it would be interestingto experiment with the implicitly expressed senti-ments.AcknowledgmentsThis research is funded by European Union Struc-tural Funds Project ?Postdoctoral Fellowship Im-plementation in Lithuania?
(VP1-3.1-S?MM-01).9ReferencesAnthony Aue and Michael Gamon.
2005.
Customiz-ing sentiment classifiers to new domains: A casestudy.
In Proceedings of the International Confer-ence on Recent Advances in Natural Language Pro-cessing (RANLP).Farah Benamara, Carmine Cesarano, Antonio Pi-cariello, Diego Reforgiato, and VS Subrahmanian.2007.
Sentiment analysis: Adjectives and adverbsare better than adjectives alone.
In Proceedingsof International Conference on Weblogs and SocialMedia (ICWSM).Erik Boiy and Marie-Francine Moens.
2009.
A Ma-chine Learning Approach to Sentiment Analysis inMultilingual Web Texts.
Information Retrieval,12(5):526?558.Henri Bouma, Olga Rajadell, Danie?l Worm, Corne?
Ver-sloot, and Harry Wedemeijer.
2012.
On the earlydetection of threats in the real world based on open-source information on the internet.
In Proceedingsof International Conference of Information Tech-nologies and Security.Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu.2012.
Detecting Offensive Language in Social Me-dia to Protect Adolescent Online Safety.
In Proceed-ings of the International Confernece on Social Com-puting (SocialCom 2012), pages 71?80.Alex Cheng and Oles Zhulyn.
2012.
A Systemfor Multilingual Sentiment Learning On Large DataSets.
In Proceedings of 24th International Confer-ence on Computational Linguistics (COLING 2012),pages 577?592.Yejin Choi and Claire Cardie.
2008.
Learning withcompositional semantics as structural inference forsubsentential sentiment analysis.
In Proceedings ofthe Conference on Empirical Methods in NaturalLanguage Processing, pages 793?801.Corinna Cortes and Vladimir Vapnik.
1995.
Support-vector networks.
Machine Learning, 20:273?297.Hang Cui, Vibhu Mittal, and Mayur Datar.
2006.Comparative experiments on sentiment classifica-tion for online product reviews.
In Proceedings ofthe Twenty First National Conference on ArtificialIntelligence (AAAI-2006), pages 1265?1270.Vidas Daudaravic?ius, Erika Rimkute?, and AndriusUtka.
2007.
Morphological annotation of theLithuanian corpus.
In Proceedings of the Work-shop on Balto-Slavonic Natural Language Process-ing: Information Extraction and Enabling Technolo-gies (ACL?07), pages 94?99.Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: opinion extractionand semantic classification of product reviews.
InProceedings of the 12th international conference onWorld Wide Web (WWW?03), pages 519?528.Xiaowen Ding and Bing Liu.
2007.
The utility oflinguistic rules in opinion mining.
In Proceedingsof the 30th International ACM SIGIR Conferenceon Research and Development in Information Re-trieval, pages 811?812.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-wordnet: A Publicly Available Lexical Resource forOpinion Mining.
In Proceedings of the 5th Confer-ence on Language Resources and Evaluation (LREC2006), pages 417?422.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA Data Mining Software: An Up-date.
SIGKDD Explorations, 11(1):10?18.Tino Hartmann, Sebastian Klenk, Andre Burkovski,and Gunther Heidemann.
2011.
Sentiment Detec-tion with Character n-Grams.
In Proceedings of theSeventh International Conference on Data Mining(DMIN?11).Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining (KDD?04), pages168?177.Matthew F. Hurst and Kamal Nigam.
2004.
Retriev-ing topical sentiments from online document collec-tions.
In Proceedings of Document Recognition andRetrieval, volume XI, pages 27?34.Jurgita Kapoc?iu?te?-Dzikiene?, Frederik Vaassen, WalterDaelemans, and Algis Krupavic?ius.
2012.
Im-proving Topic Classification for Highly InflectiveLanguages.
In Proceedings of 24th InternationalConference on Computational Linguistics (COLING2012), pages 1393?1410.Alistair Kennedy and Diana Inkpen.
2006.
Sentimentclassification of movie and product reviews usingcontextual valence shifters.
Computational Intelli-gence, 22(2):110?125.Ekaterina S. Kuznetsova, Natalia V. Loukachevitch,and Ilia I. Chetviorkin.
2013.
Testing rules for asentiment analysis system.
In Proceedings of Inter-national Conference Dialog, pages 71?80.David D. Lewis and William A. Gale.
1994.
A sequen-tial algorithm for training text classifiers.
In Pro-ceedings of Seventeenth Annual International ACM-SIGIR Conference on Research and Development inInformation Retrieval (SIGIR-94), pages 3?12.Ru?ta Marcinkevic?iene?.
2000.
Tekstynu?
lingvistika(teorija ir paktika) [Corpus linguistics (theory andpractice)].
Gudaitis, L.
(ed.)
Darbai ir dienos, 24:7?63.
(in Lithuanian).Subhabrata Mukherjee and Pushpak Bhattacharyya.2012.
Sentiment Analysis in Twitter with Light-weight Discourse Analysis.
In Proceedings of 24thInternational Conference on Computational Lin-guistics (COLING 2012), pages 1847?1864.10Tony Mullen and Nigel Collier.
2004.
Sentiment Anal-ysis using Support Vector Machines with DiverseInformation Sources.
In Proceedings of Empiri-cal Methods in Natural Language Processing, pages412?418.Alexander Pak and Patrick Paroubek.
2011.
Twitter forSentiment Analysis: When Language Resources areNot Available.
In Proceedings of Database and Ex-pert Systems Applications (DEXA 2011), pages 111?115.Bo Pang and Lillian Lee.
2008.
Opinion Mining andSentiment Analysis.
Foundation and Trends in In-formation Retrieval, 2(1-2):1?135.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification us-ing machine learning techniques.
In Proceedings ofConference on Empirical Methods in Natural Lan-guage Processing, EMNLP, pages 79?86.Stephan Raaijmakers and Wessel Kraaij.
2008.
Po-larity Classification of Blog TREC 2008 Data witha Geodesic Kernel.
In Proceedings of the Seven-teenth Text Retrieval Conference (TREC 2008), vol-ume 500?277.Jonathon Read and John Carroll.
2009.
Weakly su-pervised techniques for domain-independent senti-ment classification.
In Proceedings of the 1st inter-national CIKM workshop on Topic-sentiment analy-sis for mass opinion (TSA?09), pages 45?52.Jonathon Read.
2005.
Using Emoticons to Reduce De-pendency in Machine Learning Techniques for Sen-timent Classification.
In Proceedings of the 43thAnnual Meeting on Association for ComputationalLinguistics (ACL?05) (Student Research Workshop),pages 43?48.Erika Rimkute?
and Vidas Daudaravic?ius.
2007.
Mor-fologinis Dabartins lietuviu?
kalbos tekstyno anotavi-mas [Morphological annotation of the Lithuaniancorpus].
Kalbu?
studijos, 11:30?35.
(in Lithuanian).Lietuvos Rytas.
2013.
Lietuvos rytas.
Internetdaily newspaper, March.
[http://www.lrytas.lt/] (inLithuanian).Ineta Savickiene?, Vera Kempe, and Patricia J. Brooks.2009.
Acquisition of gender agreement in Lithua-nian: exploring the effect of diminutive usage in anelicited production task.
Journal of Child Language,36(3):477?494.James Spencer and Gulden Uchyigit.
2012.
Senti-mentor: Sentiment Analysis of Twitter Data.
InProceedings of European Conference on MachineLearning and Principles and Practice of KnowledgeDiscovery in Databases, pages 56?66.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-Based Methods for Sentiment Analysis.
Computa-tional Linguistics, 37(2):267?307.Peter D. Turney and Michael L. Littman.
2003.
Mea-suring praise and criticism: Inference of seman-tic orientation from association.
In Proceedings ofACM Transactions on Information and System Se-curity (TISSEC), pages 315?346.Peter D. Turney.
2002.
Thumbs up or thumbs down?
:semantic orientation applied to unsupervised classi-fication of reviews.
In Proceedings of the 40th An-nual Meeting on Association for Computational Lin-guistics (ACL?02), pages 417?424.Kazys Ulvydas, editor.
1965.
Fonetika ir morfologija(daiktavardis, bu?dvardis, skaitvardis, i?vardis) [Pho-netics and morphology (noun, adjective, numeral,pronoun)], volume 1.
Mintis, Vilnius, Lithuania.
(inLithuanian).Hao Wang, Dogan Can, Abe Kazemzadeh, Franc?oisBar, and Shrikanth Narayanan.
2012.
A systemfor Real-time Twitter Sentiment Analysis of 2012U.S.
Presidential Election Cycle.
In Proceedings ofthe 50th Annual Meeting on Association for Com-putational Linguistics (ACL?12)(System Demonstra-tions), pages 115?120.Lithuanian WordNet.
2013.
Lietuviu?
kalbos Word-Net, February.
[http://korpus.sk/ltskwn lt.html] (inLithuanian).Vytautas Zinkevic?ius.
2000.
Lemuoklis ?
mor-fologinei analizei [Morphological analysis withLemuoklis].
Gudaitis, L.
(ed.)
Darbai ir dienos,24:246?273.
(in Lithuanian).11
