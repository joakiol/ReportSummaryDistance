Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 488?498,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsPositive Unlabeled Learning for Deceptive Reviews DetectionYafeng Ren Donghong Ji Hongbin ZhangComputer SchoolWuhan UniversityWuhan 430072, China{renyafeng,dhji,zhanghongbin}@whu.edu.cnAbstractDeceptive reviews detection has attract-ed significant attention from both businessand research communities.
However, dueto the difficulty of human labeling need-ed for supervised learning, the problem re-mains to be highly challenging.
This pa-per proposed a novel angle to the prob-lem by modeling PU (positive unlabeled)learning.
A semi-supervised model, calledmixing population and individual proper-ty PU learning (MPIPUL), is proposed.Firstly, some reliable negative examplesare identified from the unlabeled dataset.Secondly, some representative positive ex-amples and negative examples are gener-ated based on LDA (Latent Dirichlet Al-location).
Thirdly, for the remaining un-labeled examples (we call them spy ex-amples), which can not be explicitly iden-tified as positive and negative, two simi-larity weights are assigned, by which theprobability of a spy example belonging tothe positive class and the negative classare displayed.
Finally, spy examples andtheir similarity weights are incorporatedinto SVM (Support Vector Machine) tobuild an accurate classifier.
Experimentson gold-standard dataset demonstrate theeffectiveness of MPIPUL which outper-forms the state-of-the-art baselines.1 IntroductionThe Web has dramatically changed the way peo-ple express themselves and interact with others,people frequently write reviews on e-commercesites, forums and blogs to achieve these purpos-es.
For NLP (Natural Language Processing), theseuser-generated contents are of great value in thatthey contain abundant information related to peo-ple?s opinions on certain topics.
Currently, on-line reviews on products and services are usedextensively by consumers and businesses to con-duct decisive purchase, product design and mar-keting strategies.
Hence, sentiment analysis andopinion mining based on product reviews havebecome a popular topic of NLP (Pang and Lee,2008; Liu, 2012).
However, since reviews infor-mation can guide people?s purchase behavior, pos-itive reviews can result in huge economic benefit-s and fame for organizations or individuals.
Thisleaves room for promoting the generation of re-view spams.
Through observations and studies ofthe predecessors (Jindal and Liu, 2008; Ott et al.,2011), review spams are divided into the followingtwo classes:?
Deceptive Reviews: Those deliberately mis-lead readers by giving undeserving positivereviews to some target objects in order to pro-mote the objects, or by giving unjust nega-tive reviews to some target objects in order todamage their reputation.?
Disruptive Reviews: Those are non-reviews,which mainly include advertisements andother irrelevant reviews containing no opin-ion.Disruptive reviews pose little threat to peo-ple, because human can easily identify and ignorethem.
In this paper, we focus on the more chal-lenging ones: deceptive reviews.
Generally, de-ceptive reviews detection is deemed to be a classi-fication problem (Ott et al., 2011; Li et al., 2011;Feng et al., 2012).
Based on the positive and neg-ative examples annotated by people, supervisedlearning is utilized to build a classifier, and then anunlabeled review can be predicted as deceptive re-view or truthful one.
But the work from Ott et al.
(2011) shows that human cannot identify decep-tive reviews from their prior knowledge, which in-dicates that human-annotated review datasets must488include some mislabeled examples.
These exam-ples will disturb the generation ability of the clas-sifiers.
So simple supervised learning is regardedas unsuitable for this task.It is difficult to come by human labeling need-ed for supervised learning and evaluation, we can-not obtain the datasets containing deceptive re-views.
However, we can get some truthful reviewswith high confidence by heuristic rules and priorknowledge.
Meanwhile, a lot of unlabeled reviewsare available.
The problem thus is this: based onsome truthful reviews and a lot of unlabeled re-views, can we build an accurate classifier to iden-tify deceptive reviews.PU (positive unlabeled) learning can be utilizedto deal with the above situation (Liu et al., 2002;Liu et al., 2003).
Different from traditional super-vised learning, PU learning can still build an ac-curate classifier even without the negative trainingexamples.
Several PU learning techniques havebeen applied successfully in document classifica-tion with promising results (Zhang, 2005; Elkanand Noto, 2008; Li et al., 2009; Xiao et al., 2011),while they have yet to be applied in detecting de-ceptive reviews.
Here, we will study how to designPU learning to detect deceptive reviews.An important challenge is how to deal withspy examples (easily mislabeled) of unlabeled re-views, which is not easily handled by the previousPU learning techniques.
In this paper, we proposea novel approach, mixing population and individ-ual property PU learning (MPIPUL), by assigningsimilarity weights and incorporating weights intoSVM learning phase.
This paper makes the fol-lowing contributions:?
For the first time, PU learning is defined inthe environment of identifying deceptive re-views.?
A novel PU learning is proposed based on L-DA and SVM.?
Experimental results demonstrate that ourproposed method outperforms the curren-t baselines.2 Related Work2.1 Deceptive Reviews DetectionSpam has historically been investigated in the con-texts of e-mail (Drucker et al., 1999; Gyongyi etal., 2004) and the Web (Ntoulas et al., 2006).
Inrecent years, researchers have started to look at de-ceptive reviews.Jindal and Liu (2008) found that opinion s-pam was widespread and different from e-mailand Web spam in essence (Jindal and Liu, 2008).They trained models using product review data,by defining features to distinguish duplicate opin-ion and non-duplicate based on the review tex-t, reviewers and product information.
Wu et al.
(2010) proposed an alternative strategy of popu-larity rankings (Wu et al., 2010).Ott et al.
(2011) developed the first dataset con-taining gold-standard deceptive reviews by crowd-sourcing (Ott et al., 2011), and presented three su-pervised learning methods to detect deceptive re-views by integrating knowledge from psycholin-guistics and computational linguistics.
This gold-standard dataset will be used in the paper.
Li et al.
(2011) manually built a review dataset from theircrawled reviews (Li et al., 2011), and exploitedsemi-supervised co-training algorithm to identifydeceptive reviews.Feng et al.
(2012) verified the connection be-tween the deceptive reviews and the abnormal dis-tributions (Feng et al., 2012a).
Later, they (Feng etal., 2012b) demonstrated that features driven fromCFG (Context Free Grammar) parsing trees con-sistently improve the detection performance.Mukherjee et al.
(2012) proposed detect-ing group spammers (a group of reviewers whowork collaboratively to write deceptive reviews) inproduct reviews (Mukherjee et al., 2012).
The pro-posed method first used frequent itemset miningto find a set of candidate groups.
Then GSRankwas presented which can consider relationships a-mong groups, individual reviewers and productsthey reviewed to detect spammer groups.
Later,they also proposed exploiting observed reviewingbehaviors to detect opinion spammers in an unsu-pervised Bayesian inference framework (Mukher-jee et al., 2013).Ren et al.
(2014) assumed that there must besome difference on language structure and sen-timent polarity between deceptive reviews andtruthful ones (Ren et al., 2014a), then they de-fined the features related to the review text andused genetic algorithm for feature selection, fi-nally they combined two unsupervised clusteringalgorithm to identify deceptive reviews.
Later,they (Ren et al., 2014b) present a new approach,from the viewpoint of correcting the mislabeled489examples, to find deceptive reviews.
Firstly, theypartition a dataset into several subsets.Then theyconstruct a classifier set for each subset and s-elect the best one to evaluate the whole dataset.Meanwhile, error variables are defined to computethe probability that the examples have been mis-labeled.
Finally, the mislabeled examples are cor-rected based on two threshold schemes, majorityand non-objection.Unlike previous studies, PU learning is imple-mented to identify deceptive reviews.2.2 Positive Unlabeled LearningAccording to the use of the unlabeled data, PUlearning can be divided into two classes.One family of methods built the final classifierby using positive examples dataset and some ex-amples of the unlabeled dataset (Liu et al., 2002;Liu et al., 2003).
The basic idea is to find a setof reliable negative examples from the unlabeleddata firstly, and then to learn a classifier using EM(Expectation Maximization) or SVM.
The perfor-mance is limited for neglecting the rest examplesof unlabeled dataset.Another family of methods learned the finalclassifier by using positive examples dataset andall examples of the unlabeled dataset.
Li et al.
(Li et al., 2009) studied PU learning in the datastream environment, they proposed a PU learn-ing LELC (PU Learning by Extracting Likelypositive and negative micro-Clusters) for docu-ment classification, they assume that the exam-ples close together shared the same labels.
Xi-ao et al.
(Xiao et al., 2011) proposed a method,called SPUL (similarity-based PU learning), thelocal similarity-based and global similarity-basedmechanisms are proposed to generate the similar-ity weights for the easily mislabeled examples,respectively.
Experimental results show globalSPUL generally performs better than local SPUL.In this paper, a novel PU learning (MPIPUL) isproposed to identify deceptive reviews.3 PreliminaryBefore we introduce the proposed method, webriefly review SVM, which has proven to be aneffective classification algorithm (Vapnik, 1998).Let T = {(x(1), y(1)), (x(2), y(2)), .
.
.
, (x(|T |), y(|T |))} be a training set, where x(i)?
Rdandy(i)?
{+1,?1}.
SVM aims to seek an optimalseparating hyperplane wTx(i)+ b = 0, the hyper-plane can be obtained by solving the followingoptimization problem:min F (w, b, ?i) =12||w||2+ C|T |?i=1?is.t.
y(i)(wTx(i)+ b) ?
1 ?
?i, i = 1, .
.
.
, |T |?i?
0, i = 1, .
.
.
, |T |(1)where wTrepresents the transpose of w, C is aparameter to balance the classification errors and?iare variables to relax the margin constraints.The optimal classifier can be achieved by usingthe Lagrange function.
For a test example x, ifwTx+b < 0, it is classified into the negative class;otherwise, it is positive.In the following, SVM is extended to incorpo-rate the spy examples and their weights, such thatthe spy examples can contribute differently to theclassifier construction.4 The Proposed MethodIn this section, we will introduce the proposed ap-proach in details.
In our PU learning (MPIPUL),truthful reviews are named positive examples, anddeceptive reviews are called negative examples.
Pis defined as a set which contains all positive ex-amples.
U is a set for all unlabeled examples.
PUlearning aims at building a classifier using P andU .
MPIPUL adopts the following four steps:?
Step 1: Extract the reliable negative exam-ples;?
Step 2: Compute the representative positiveand negative examples;?
Step 3: Generate the similarity weights forthe spy examples;?
Step 4: Build the final SVM classifier;4.1 Extracting Reliable Negative ExamplesConsidering only positive and unlabeled examplesare available in PU learning, some negative ex-amples need to be extracted firstly.
These exam-ples will influence the performance of the follow-ing three steps.
So high-quality negative examplesmust be guaranteed.
Previous works solved theproblem with the Spy technique (Liu et al., 2002)or the Rocchio technique (Liu et al., 2003), we in-tegrate them in order to get reliable negative ex-amples.
Let subsets NS1and NS2contain the490corresponding reliable negative examples extract-ed by the two techniques, respectively.
Examplesare considered to be a reliable negative only if bothtechniques agree that they are negative.
That is,NS = NS1?
NS2, where NS contains the reli-able negative examples.After reliable negative examples are extracted,there are still some unlabeled examples (we callspy examples) in set U , let subset US = U ?NS,which stores all the spy examples.
It is crucial todetermine how to deal with these spy examples.4.2 Computing Representative Positive andNegative ExamplesGenerally, a classifier can be constructed to pre-dict deceptive reviews based on the positive ex-amples set P and the reliable negative examplesset NS.
But the classifier is not accurate enoughfor lacking of making full use of unlabeled datasetU .
In order to utilize spy examples in subset US,some representative positive and negative exam-ples are calculated firstly.
Since the examples havedifferent styles in sentiment polarity and topic dis-tribution, for every class, computing one repre-sentative example is not suitable.
For the posi-tive class or the negative class, to ensure there isa big difference between the different representa-tive examples.
This paper proposes clustering re-liable negative examples into several groups basedon LDA (Latent Dirichlet Allocation) topic mod-el and K-means, and then multiple representativeexamples can be obtained.LDA topic model is known as a parametricBayesian clustering model (Blei et al., 2003), andassumes that each document can be representedas the distribution of several topics, each docu-ment is associated with common topics.
LDA canwell capture the relationship between internal doc-uments.In our experiments based on LDA model, wecan get the topic distribution for the reliable neg-ative examples, then some reliable negative exam-ples which are similar in topic distribution will beclustered into a group by K-means.
Finally, thesereliable negative examples can be clustered into nmicro-clusters (NS1, NS2, .
.
.
, NSn).
Here,n = 30 ?
|NS|/(|US| + |NS|) (2)Here, according to the suggestion of previouswork (Xiao et al., 2011), we examine the impactof the different parameter (from 10 to 60) on over-all performance, and select the best value 30.Based on the modified Rocchio formula (Buck-ley et al., 1999), n representative positive exam-ples (pk) and n negative ones (nk) can be obtainedusing the following formula:pk= ?1|P ||P |?i=1x(i)?
x(i)??
?1|NSk||NSk|?i=1x(i)?
x(i)?nk= ?1|NSk||NSk|?i=1x(i)?
x(i)??
?1|P ||P |?i=1x(i)?
x(i)?k = 1, .
.
.
, n(3)According to previous works (Buckley et al.,1994), where the value of ?
and ?
are set to 16and 4 respectively.
The research from Buckley etal.
demonstrate that this combination emphasizesoccurrences in the relevant documents as opposedto non-relevant documents.4.3 Generating Similarity WeightsFor a spy example x, since we do not know whichclass it should belong to, enforcing x to the posi-tive class or the negative class will lead to somemislabeled examples, which disturbs the perfor-mance of final classifier.
We represent a spy ex-ample x using the following probability model:{x, (p+(x), p?
(x))}, p+(x) + p?
(x) = 1 (4)Where p+(x) and p?
(x) are similarity weight-s which represent the probability of x belongingto the positive class and the negative class, re-spectively.
For example, {x, (1, 0)} means that xis positive, while {x, (0, 1)} indicates that x is i-dentified to be negative.
For {x, (p+(x), p?
(x))},where 0 < p+(x) < 1 and 0 < p?
(x) < 1, itimplies that the probability of x belonging to thepositive class and the negative class are both con-sidered.In this section, similarity weights are decided bymixing global information (population property)and local information (individual property).
Thenall spy examples and their similarity weights areincorporated into a SVM-based learning model.4.3.1 Population PropertyPopulation property means that the examples ineach micro-cluster share the similarity in sen-timent polarity and topic distribution, and theybelong to the same category with a high pos-sibility.
In our framework, in order to com-pare with the representative examples, all spy ex-amples are firstly clustered into n micro-clusters491(US1, US2, .
.
.
, USn) based on LDA and K-means.
Then, for every spy example x in onemicro-cluster USi, we tags with temporary labelby finding its most similar representative example.Finally, we can get the similarity weights for a spyexample x in micro-cluster USi, their probabilitypertaining to the positive class and negative classcan be represented by the following formula:p pop(x) =|positive||USi|n pop(x) =|negative||USi|(5)where |USi| represents the number of all examplesin micro-cluster USi, |positive| means the num-ber of the examples which is called temporary pos-itive in USi, and |negative| means the number ofthe examples which is called temporary negativein USi.For example, Figure 1 shows the part (C1, C2,C3, C4) of the clustering results for the spy exam-ples based on LDA and K-means, the examplesx in C4 are assigned with weights p pop(x) =49, n pop(x) =59, the examples x in C1 are as-signed with weights p pop(x) = 1, n pop(x) = 0.Figure 1: Illustration of population propertyThe advantage of population property lies in thefact that it considers the similar relationship be-tween the examples, from which the same micro-cluster are assigned the same similarity weight.However, it cannot distinguish the difference ofexamples in one micro-cluster.
In fact, the simi-larity weights of examples from the same micro-cluster can be different, since they are locatedphysically different.
For example, for the spy ex-ample y and z in micro-cluster C4, it is apparent-ly unreasonable that we assign the same similarityweights to them.
So we should join the local in-formation (individual property) when we are com-puting the similarity weights for a spy example.4.3.2 Individual PropertyIndividual property is taken into account to mea-sure the relationship between every spy exampleand all representative ones.
Specifically, for ex-ample x, we firstly compute its similarity to eachof the representative examples, and then the prob-ability of the example x belonging to the positiveclass and negative class can be calculated using thefollowing formula:p ind(x) =?nk=1sim(x, pk)?nk=1(sim(x, pk) + sim(x, nk))n ind(x) =?nk=1sim(x, nk)?nk=1(sim(x, pk) + sim(x, nk))(6)In the above formula,sim(x, y) =x ?
y||x|| ?
||y||4.3.3 Similarity WeightsA scheme mixing population and individual prop-erty is designed to generate the similarity weightsof spy examples.
Specifically, for spy example x,their similarity weights can be obtained by the fol-lowing formula:p+(x) = ?
?
p pop(x) + (1 ?
?)
?
p ind(x)p?
(x) = ?
?
n pop(x) + (1 ?
?)
?
n ind(x)(7)Where ?
is a parameter to balance the informa-tion from population property and individual prop-erty.
In the remaining section, we will examinethe impact of the parameter ?
on overall perfor-mance.
Meanwhile, it can be easily proved thatp+(x) + p?
(x) = 1.4.4 Constructing SVM ClassifierAfter performing the third step, each spy examplex is assigned two similarity weights: p+(x) andp?(x).
In this section, we will extend the formu-lation of SVM by incorporating the examples inpositive set P , reliable negative set NS, spy ex-amples set US and their similarity weights into aSVM-based learning model.4.4.1 Primal ProblemSince the similarity weights p+(x) and p?
(x) in-dicate the probability for a spy example x belong-ing to the positive class and the negative class, re-spectively.
The optimization formula (1) can be492rewritten as the following optimization problem:min F (w, b, ?)
=12||w||2+ C1|P |?i=1?i+ C2?|US|?j=1p+(x(j))?j+ C3|US|?m=1p?(x(m))?m+C4|NS|?n=1?ns.t.
y(i)(wTx(i)+ b) ?
1 ?
?i, x(i)?
Py(j)(wTx(j)+ b) ?
1 ?
?j, x(j)?
USy(m)(wTx(m)+ b) ?
1 ?
?m, x(m)?
USy(n)(wTx(n)+ b) ?
1 ?
?n, x(n)?
NS?i?
0, ?j?
0, ?m?
0, ?n?
0(8)Where C1, C2, C3and C4are penalty factors con-trolling the tradeoff between the hyperplane mar-gin and the errors, ?i, ?j, ?mand ?nare the errorterms.
p+(x(j))?jand p?
(x(m))?mcan be consid-ered as errors with different weights.
Note that,a bigger value of p+(x(j)) can increase the effectof parameter ?j, so that the corresponding examplex(j)becomes more significant towards the positiveclass.
In the following, we will find the dual formto address the above optimization problem.4.4.2 Dual ProblemAssume ?iand ?jare Lagrange multipliers.
Tosimplify the presentation, we redefine some nota-tions as follows:C+i={C1, x(i)?
PC2p+(x(j)), x(j)?
USC?j={C3p?
(x(m)), x(m)?
USC4, x(n)?
NSBased on the above definitions, we let T+=P ?
US, T?= US ?
NS and T?= T+?
T?.The Wolfe dual of primal formulation can be ob-tained as follows (Appendix A for the calculationprocess):max W (?)
=|T?|?i=1?i?12|T?|?i=1,j=1?i?jy(i)?y(j)< x(i), x(j)>s.t.
C+i?
?i?
0, x(i)?
T+C?j?
?j?
0, x(j)?
T?|T+|?i=1?i?|T?|?j=1?j= 0(9)where < x(i), x(j)> is the inner product of x(i)and x(j).
In order to get the better performance, wecan replace them by using kernel function ?
(x(i))and ?
(x(j)), respectively.
The kernel track canconvert the input space into a high-dimension fea-ture space.
It can solve the uneven distribution ofdataset and complex problem from heterogeneousdata sources, which allows data to get a better ex-pression in the new space (Lanckriet et al., 2004;Lee et al., 2007).After solving the above problem, w can be ob-tained, then b can also be obtained by using KKT(Karush-Kuhn-Tucker) conditions.
For a test ex-ample x, if wTx+ b > 0, it belongs to the positiveclass.
Otherwise, it is negative.5 ExperimentsWe aim to evaluate whether our proposed PUlearning can identify deceptive reviews properly.We firstly describe the gold-standard dataset, andthen introduce the way to generate the positiveexamples P and unlabeled examples U .
Finallywe present human performance in gold-standarddataset.5.1 DatasetsThere is very little progress in detection of de-ceptive reviews, one reason is the lack of stan-dard dataset for algorithm evaluation.
The gold-standard dataset is created based on crowdsourc-ing platform (Ott et al., 2011), which is also adopt-ed as the experimental dataset in this paper.5.1.1 Deceptive ReviewsCrowdsourcing services can carry out massive da-ta collection and annotation; it defines the task inthe network platform, and paid for online anony-mous workers to complete the task.493Humans cannot be precisely distinguish decep-tive ones from existing reviews, but they can createdeceptive reviews as one part of the dataset.
Ott etal.
(2011) accomplish this work by AMT (Ama-zon Mechanical Turk).
They set 400 tasks for 20hotels, in which each hotel gets 20 tasks.
Specif-ic task is: If you are a hotel market departmentemployee, for each positive review you wrote forthe benefit for hotel development, you may get onedollar.
They collect 400 deceptive reviews.5.1.2 Truthful ReviewsFor the collection of truthful reviews, they get6977 reviews from TripAdvisor1based on thesame 20 Chicago hotels, and remove some reviewson the basis of the following constraints:?
Delete all non-five star reviews;?
Delete all non-English reviews;?
Delete all reviews which are less than 75characters;?
Delete all reviews written by first-time au-thors;2124 reviews are gathered after filtering.
400 ofthem are chosen as truthful ones for balancing thenumber of deceptive reviews, as well as maintain-ing consistent with the distribution of the length ofdeceptive reviews.
800 reviews constitute wholegold-standard dataset at last.5.2 Experiment SetupWe conduct 10-fold cross-validation: the datasetis randomly split into ten folds, where nine fold-s are selected for training and the tenth fold fortest.
In training dataset, it contains 360 truthfulreviews and 360 deceptive ones.
This paper is in-tended to apply PU learning to identify deceptivereviews.
We specially make the following setting:take 20% of the truthful reviews in training set aspositive examples dataset P , all remaining truthfuland deceptive reviews in training set as the unla-beled dataset U .
Therefore, during one round ofthe algorithm, the training set contains 720 exam-ples including 72 positive examples (set P ) and648 unlabeled examples (set U ), and the test setcontains 80 examples including 40 positive and 40negative ones.
In order to verify the stability ofthe proposed method, we also experiment anoth-er two different settings, which account for 30%1http://www.tripadvisor.comand 40% of the truthful reviews in training set aspositive examples dataset P respectively.5.3 Human PerformanceHuman performance reflects the degree of difficul-ty to address this task.
The rationality of PU learn-ing is closely related to human performance.We solicit the help of three volunteer students,who were asked to make judgments on test sub-set (corresponding to the tenth fold of our cross-validation experiments, contains 40 deceptive re-views and 40 truthful reviews).
Additionally, totest the extent to which the individual humanjudges are biased, we evaluate the performance oftwo virtual meta-judges: one is the MAJORITYmeta-judge when at last two out of three humanjudge believe the review to be deceptive, and theother is the SKEPTIC when any human judge be-lieves the review to be deceptive.
It is apparentfrom the results that human judges are not par-ticularly effective at this task (Table 1).
Inter-annotator agreement among the three judges, com-puted using Fleiss?
kappa, is 0.09.
Landis andKoch (Landis and Koch, 1977) suggest that s-cores in the range (0.00, 0.20) correspond to ?s-light agreemen?
between annotators.
The largestpairwise Cohen?s kappa is 0.11 between JUDGE-1 and JUDGE-3, far below generally acceptedpairwise agreement levels.
We can infer that thedataset which are annotated by people will includea lot of mislabeled examples.
Identifying decep-tive reviews by simply using supervised learningmethods is not appropriate.
So we propose ad-dressing this issue by using PU learning.Table 1: Human performanceMethods Accuracy (%)HumanJUDGE-1 57.9JUDGE-2 55.4JUDGE-3 61.7METAMAJORITY 58.3SKEPTIC 62.46 Results and AnalysisIn order to verify the effectiveness of our proposedmethod, we perform two PU learning (LELC andSPUL) in the gold-standard dataset.4946.1 Experimental ResultsTable 2 shows that the experimental results com-pared with different PU learning techniques.
InTable 2, P (20%) means that we randomly select20 percentages of truthful reviews to form the pos-itive examples subset P .
In our MPIPUL frame-work, we set ?
= 0.3.
We can see that our pro-posed method can obtain 83.91%, 85.43% and86.69% in accuracy from different experimentalsettings, respectively.
Compared to the curren-t best method (SPUL-global), the accuracy can beimproved 2.06% on average.
MPUPUL can im-prove 3.21% on average than LELC.
The abovediscussion shows our proposed methods consis-tently outperform the other PU baselines.Table 2: Accuracy on the different PU learningBaselines P(20%) P(30%) P(40%)LELC 81.12 82.08 83.21SPUL-local 81.43 82.71 84.09SPUL-global 81.89 83.24 84.73MPIPUL (0.3) 83.91 85.43 86.69PU learning framework in this paper can obtainthe better performance.
Two factors contribute tothe improved performance.
Firstly, LDA can cap-ture the deeper information of the reviews in topicdistribution.
Secondly, strategies of mixing pop-ulation and individual property can generate thesimilarity weights for spy examples, and these ex-amples and their similarity weights are extendedinto SVM, which can build a more accurate clas-sifier.6.2 Parameter SensitivityFor the spy examples, the similarity weights aregenerated by population property and individualproperty.
Should we select the more populationinformation or individual information?
In MPIP-UL, parameter ?
is utilized to adjust this process.So we experiment with the different value of theparameter ?
on MPUPUL performance (Figure 2).As showed in Figure 2, for P (20%), if ?
< 0.3,the performance increases linearly, if ?
> 0.3,the performance will decrease linearly.
Mean-while, we can get the same trends for P (30%) andP (40%).
Based on the above discussion, MPIP-UL can get the best performance when ?
?
0.3.Figure 2: Algorithm performance on different pa-rameter7 Conclusions and Future WorkThis paper proposes a novel PU learning (MPIP-UL) technique to identify deceptive reviews basedon LDA and SVM.
Firstly, the spy examples areassigned similarity weights by integrating the in-formation from the population property and in-dividual property.
Then the spy examples andtheir similarity weights are incorporated into SVMlearning phase to build an accurate classifier.
Ex-perimental results on gold-standard dataset showthe effectiveness of our method.In future work, we will discuss the applicationof our proposed method in the massive dataset.AcknowledgmentsWe are grateful to the anonymous reviewer-s for their thoughtful comments.
This workis supported by the State Key Program ofNational Natural Science Foundation of China(Grant No.61133012), the National Natural Sci-ence Foundation of China (Grant No.61173062,61373108) and the National Philosophy SocialScience Major Bidding Project of China (GrantNo.
11&ZD189).ReferencesAlexandros Ntoulas, Marc Najork, Mark Manasse, andDennis Fetterly.
2006.
Detecting spam web pagesthrough content analysis.
In Proceedings of the 15thInternational Conference on World Wide Web, page83-92, Edinburgh, Scotland.Arjun Mukherjee, Abhinav Kumar, Bing Liu, JunhuiWang, Meichun Hsu, Malu Castellanos, and Riddhi-man Ghosh.
2013.
Spotting opinion spammers us-ing behavioral footprints.
In Proceeding of the 19th495ACM SIGKDD International Conference on Knowl-edge Discovery and Data Ming, page 632-640, Ly-on, France.Arjun Mukherjee, Bing Liu, and Natalie Glance.
2012.Spotting fake reviewer groups in consumer reviews.In Proceeding of the 21st International Conferenceon World Wide Web, page 191-200, New York, US-A.Bing Liu.
2012.
Sentiment analysis and opinion min-ing.
Morgan & Claypool Publishers.
San Rafael,USA.Bing Liu, Wee Sun Lee, Philip S. Yu, and Xiaoli Li.2002.
Partially supervised classification of text doc-uments.
In Proceedings of the 19th InternationalConference on Machine Learning, page 387-394,San Francisco, USA.Bing Liu, Yang Dai, Xiaoli Li, Wee Sun Lee, and PhilipS.
Yu.
2003.
Building text classifiers using positiveand unlabeled examples.
In Proceedings of the 3rdIEEE International Conference on Data Ming, page179-182, Washington, USA.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in In-formation Retrieval, 2(1-2):1-135.Charles Elkan and Keith Noto.
2008.
Learning clas-sifiers from only positive and unlabeled data.
InProceedings of the 14th ACM SIGKDD Internation-al Conference on Knowledge Discovery and DataMing, page 213-220, Las Vegas, USA.Chirs Buckley, Bgrard Salton, and James Allan.
1994.The effect of adding relevance information in a rele-vance feedback environment.
In Proceedings of the17th Annual International SIGIR Conference on Re-search and Development Retrieval, page 292-300,Dublin, Ireland.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet allocation.
Journal of Ma-chine Learning Research, 3:993-1022.Dell Zhang.
2005.
A simple probabilistic approachto learning from positive and unlabeled examples.In Proceedings of the 5th Annual UK Workshop onComputational Intelligence, page 83-87.Fangtao Li, Minlie Huang, Yi Yang, and XiaoyanZhu.
2011.
Learning to identify review spam.
InProceeding of the 22nd International Joint Confer-ence on Artificial Intelligence, page 2488-2493,Barcelona, Spain.Fang Wu and Bernardo A. Huberman.
2010.
Opinionformation under costly express.
ACM Transactionson Intelligence System Technology, 1(5):1-13.Gert R. G. Lanckeriet, Nello Cristianini, Peter Bartlet-t, Laurent EI Ghaoui, and Michael I.Jordan.
2004.Learning the kernel matrix with seim-difinit pro-gramming.
Journal of Machine Learning Research,5:27-72.Harris Drucker, Donghui Wu, and Vladimir N. Vap-nik.
1999.
Support vector machines for spam cate-gorization.
IEEE Transactions on Neural Networks,10(5):1048-1054.Kumar Ankita and Sminchisescu Cristian.
2006.
Sup-port kernel machines for object recognition.
In Pro-ceedings of the IEEE 11th International Conferenceon Computer Vision, page 1-8, Rio de Janeiro, Brza-il.Myle Ott, Yelin Choi, Claire Caridie, and Jeffrey T.Hancock.
2011.
Finding deceptive opinion spamby any stretch of the imagination.
In Proceedingof the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-noloies, page 309-319, Portland, USA.Nitin Jindal and Bing Liu.
2008.
Opinion spam andanalysis.
In Proceeding of the 1st ACM Interna-tional Conference on Web Search and Data Mining,page 137-142, California, USA.Richard Landis and Gary G. Koch.
1977.
The mea-surement of observer agreement for categorical data.Biometrics, 33(1):159-174.Song Feng, Longfei Xing, Anupam Gogar, and YejinChoi.
2012.
Distributional footprints of deceptiveproduct reviews.
In Proceeding of the 6th Inter-national AAAI Conference on WebBlogs and SocialMedia, page 98-105, Dublin, Ireland.Song Feng, Ritwik Banerjee, and Yejin Choi.
2012.Syntactic stylometry for deception detection.
InProceeding of the 50th Annual Meeting of the As-sociation for Computational Linguistics, page 171-175, Jeju Island, Korea.Vladimir N. Vapnik.
1998.
Statistical learning theory.Springer.
New York, USA.Wanjui Lee, Sergey Verzakov, and Robert P. Duin.2007.
Kernel combination versus classifier com-bination.
In Proceedings of the 7th InternationalWorkshop on Multiple Classifier Systems, page 22-31, Rrague, Czech Republic.Xiaoli Li, Philip S. Yu, Bing Liu, and See Kiong Ng.2009.
Positive unlabeled learning for data streamclassification.
In Proceedings of the SIAM Inter-national Conference on Data Ming, page 257-268,Nevada, USA.Yafeng Ren, Donghong Ji, Lan Yin, and HongbinZhang.
2014.
Finding deceptive opinion spam bycorrecting the mislabled instances.
Chinese Journalof Electronics, 23(4):702-707.Yafeng Ren, Lan Yin, and Donghong Ji.
2014.
De-ceptive reviews detection based on language struc-ture and sentiment polarity.
Journal of Frontiers ofComputer Science and Technology, 8(3):313-320.496Yanshan Xiao, Bing Liu, Jie Yin, Longbing Cao,Chengqi Zhang, and Zhifeng Hao.
2011.Similarity-based approach for positive and unla-beled learning.
In Proceeding of the 22nd Inter-national Joint Conference on Artifical Intelligence,page 1577-1582, Barcelona, Spain.Zoltan Gyongyi, Hector Garcia-Molina, and JanPedesen.
2004.
Combating web spam web withtrustrank.
In Proceedings of the 30th InternationalConference on Very Large Data Bases, page 576-587, Toronto, Canada.Appendix AThe optimization problem is as follows:min F (w, b, ?)
=12||w||2+ C1|P |?i=1?i+ C2?|US|?j=1p+(x(j))?j+ C3|US|?m=1p?(x(m))?m+C4|NS|?n=1?ns.t.
y(i)(wTx(i)+ b) ?
1 ?
?i, x(i)?
Py(j)(wTx(j)+ b) ?
1 ?
?j, x(j)?
USy(m)(wTx(m)+ b) ?
1 ?
?m, x(m)?
USy(n)(wTx(n)+ b) ?
1 ?
?n, x(n)?
NS?i?
0, ?j?
0, ?m?
0, ?n?
0(10)We construct the Lagrangian function for theabove optimization problem, we have:L(w, b, ?, ?, ?)
= F (w, b, ?)
+|P |?i=1?i[?y(i)?
(wTx(i)+ b) + 1 ?
?i] +|US|?j=1?j[?y(j)(wTx(j)+b) + 1 ?
?j] +|US|?m=1?m[?y(m)(wTx(m)+ b) + 1?
?m] +|NS|?n=1?n[?y(n)(wTx(n)+ b) + 1 ?
?n]?|P |?i=1?i?i?|US|?j=1?j?j?|US|?m=1?m?m?|NS|?n=1?n?n(11)Here, the ?
and ?
are Lagrange multipliers.
Tofind the dual form of the problem, we need to firstminimize L(w, b, ?, ?, ?)
with respect to w and b,we will do by setting the derivatives of L with re-spect to w and b to zero, we have:?L(w, b, ?, ?, ?
)?w= w ?|P |?i=1?iy(i)x(i)?|US|?j=1?jy(j)x(j)?|US|?m=1?my(m)x(m)?|NS|?n=1?ny(n)?x(n)= 0(12)This implies thatw =|P |?i=1?iy(i)x(i)+|US|?j=1?jy(j)x(j)+|US|?m=1?m?y(m)x(m)+|NS|?n=1?ny(n)x(n)(13)Here, to simplify the presentation, we redefinesome notations in the following:T+= P ?
US, T?= US ?NS, T?= T+?
T?C+i={C1, x(i)?
PC2p+x(j), x(j)?
USC?j={C3p?x(m), x(m)?
USC4, x(n)?
NSso we obtainw =|T?|?i=1?iy(i)x(i)(14)As for the derivative with respect to b, we obtain?L(w, b, ?, ?, ?
)?b= ?|P |?i=1?iy(i)?|US|?j=1?jy(j)?|US|?m=1?my(m)?|NS|?n=1?ny(n)= 0(15)We get:|T?|?i=1?iy(i)= 0 (16)497If we take Equation (14) and (16) back into theLagrangian function (Equation 11), and simplify,we getL(w, b, ?, ?, ?)
=|T?|?i=1?i?12|T?|?i,j=1y(i)y(j)?i?
?j< x(i), x(j)>(17)To the primal optimization formula (10), we canobtain the following dual optimization problem:max W (?)
=|T?|?i=1?i?12|T?|?i=1,j=1?i?jy(i)?y(j)< x(i), x(j)>s.t.
C+i?
?i?
0, x(i)?
T+C?j?
?j?
0, x(j)?
T?|T+|?i=1?i?|T?|?j=1?j= 0(18)where < x(i), x(j)> is the inner product of x(i)and x(j), we can replace them by using kernelfunction ?
(x(i)) and ?
(x(j)), respectively.498
