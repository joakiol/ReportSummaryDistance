Proceedings of the 8th International Conference on Computational Semantics, pages 351?354,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsIdentifying the Epistemic Value of DiscourseSegments in Biology TextsAnita de Waard(1)Paul Buitelaar(2)Thomas Eigner(3)(1) Elsevier & Universiteit Utrecht, the Netherlands (anita@cs.uu.nl)(2) DERI - NLP Unit, Galway, Ireland (paulb@deri.org)(3) DFKI, Saarbrcken, Germany (teigner@dfki.de)1 IntroductionTo manage the flood of information that threatens to engulf (life-)scientists,an abundance of computer-aided tools are being developed.
These tools aimto provide access to the knowledge conveyed within a collection of researchpapers, without actually having to read the papers.
Many of these toolsfocus on text mining, by looking for specific named-entities that have scien-tific meaning, and relationships between these.
An overview of the currentstate of the art is given in Rebholz-Schuhmann et al (2005) and Coutoet al (2003).
Typically, these tools identify a list of sentences containingrelationships between two specific named-entities that can be found usingrules or a thesaurus of synonyms.
These sentences represent an overview ofthe interactions that are known with a specific entity, thus precluding theneed for an exhaustive literature study.
For example, the following are afew sentences that have been found using a typical text mining tool for therelationship ?p53 activates *?:1.
The p53 tumor suppressor protein exerts most of its anti-tumorigenicactivity by transcriptionally activating several pro-apoptotic genes.2.
We found that p53 ... activates[,] the promoter of the myosin VI gene.However, in order to be able to use these statements and to draw conclu-sions about its subject (?Which entities does p53 activate??)
we still needto read the article that they appeared in, identify the experimental contextand the epistemic (?truth?)
value of each statement.
For instance, 1. doesnot seem to represent an experimental finding that is arrived at in the paper351that the sentence is taken from; instead, it seems to be a citation.
So, to beable to evaluate its epistemic value (?How true is this??)
we need to readthe paper that contained the sentence and paper(s) where the statementwas first experimentally motivated.
In the case of 2., a clear statement isgiven on what the authors of the paper have found.
But ?How did theyfind it?
?, ?What experimental setup and control experiments were used?
?,?What were their assumptions??
Biologists will need to check these andother issues before accepting 2. as a fact.
Our research therefore concernsthe classification of sentences in biology texts by ?epistemic segment type?,with the purpose of enabling a better way to summarize, mine and comparestatements within biology texts.
The current paper describes a first ventureinto doing this in a computational way.2 Epistemic Segment Types for Biology TextsAs motivated elsewhere we have identified seven epistemic segment types(De Waard, 2007):?
Fact: statement presumed to be accepted as true by the commu-nity, e.g.
Cellular transformation requires the expression of oncogenicRASV12.?
Hypothesis: possible explanation for a set of phenomena, e.g.
Thissuggests possible roles for APC in G1 and G0 phases of the cell cycle.?
Implication: interpretation of results, e.g.
These results indicate thatour procedure is sensitive enough to detect mild growth differences.?
Method: ways in which the experiment was performed, e.g.
Weinserted 500 bp fragments ... in a modified pMSCV-Blasticidin vector.?
Problem: discrepancies or unknown aspects of the known fact corpus,e.g.
The small number of miRNAs with a known function stressesthe need for a systematic screening approach to identify more miRNAfunctions.?
Goal: implicit hypothesis and problem, e.g.
identify miRNAs thatcan interfere with this process and ... contribute to the development oftumor cells?
Result: a summary of the results of measurements, e.g.
we observedan approximately 4-fold increase in miR-311 signal352For example, Fact segments are taken from another source of knowledge(explicitly referred to or presumed to be known) and therefore not experi-mentally ascertained in the article, whereas Result segments are obtainedby measurements discussed in the paper itself.
For the sentences in the pre-vious section, we therefore see that 1. is a Fact and 2. is a typical Resultsegment.
To classify the segments (manually first), we have used severallinguistic clues, as well as an understanding of the context of a segment.Important linguistic clues are the verb tense of the segment and specificmarkers used to identify a segment transition, e.g.
the transition between aResult and an Implication segment is usually indicated by a phrase such as?These results suggest that?.
The segment types and selected specific mark-ers that we used in our research here are as follows (using regular expressionsto shorten notation):?
Hypothesis: results indicate, suggest, suggesting that?
Implication: data?results demonstrate?suggest?indicate, data?resultsshow?
Method: by cloning?using, using additionally, we activated?constructed?
Goal: to examine?identify?investigate?mimic?shed light?start to?
Result: as expected?predicted, resulting in, shows that, this confirms3 Automatic Identification of Epistemic SegmentTypesTo investigate if we could use this set of markers for the automatic iden-tification of segment type, we applied them to an independently developeddata set of 1721 biomedical abstracts on ?mantle cell lymphoma?
that wedownloaded from PubMed.
We randomly selected 100 sentences, in whicha marker was identified, and to which one out of five segment types (Hy-pothesis, Implication, Method, Goal, Result) was assigned by a sim-ple automatic procedure, i.e.
we matched the markers to a part-of-speechenriched version of the PubMed corpus.
One or more segment types wereassigned in case of a match.
The resulting assignments were then evaluatedby the first author of this paper.
Results were encouraging as only 30 out of100 assignments were incorrect.
Most of these (12) were between Hypoth-esis, Implication, which is not surprising as their markers are overlapping353and therefore ambiguous.
Others that were somewhat frequent were: Hy-pothesis instead of Fact (3), Result instead of Fact (3), Result insteadof Method (2), Goal instead of Method (2), Goal instead of Problem(2).
Of these however, Fact and Problem were not covered by our set ofsegment specific markers and could therefore not be recognized.4 Conclusions and Future WorkAs a first conclusion, results are encouraging enough to merit further re-search.
We have identified several follow-up steps that can help improve ourresults.
First, we plan to segment the sentences into smaller discourse units.For instance, sentences such as the following are quite clearly divided intotwo parts: a Goal and a Method:?
Goal: To examine miRNA expression from the miR-Vec system,?
Method: a miR-24 minigene-containing virus was transduced intohuman cells.Such sentences are quite common, as are sentences containing Method,Result and Result, Implication segments; this clearly indicates that thismove order is logical and occurs often.
Secondly, there is a clear correlationbetween segment type and verb tense.
Method, Result are overwhelm-ingly stated in the past tense, whereas Fact, Implication are given in thepresent tense.
Using verb tense as a marker could further improve classi-fication scores.
Lastly, we are interested in applying our epistemic valuesto augment and improve bioinformatics tools, and investigating the value ofthese categories with users.
We are actively pursuing collaborations in thisarea.ReferencesRebholz-Schuhmann, D., H.Kirsch & F. Couto (2005) Facts from text - is textmining ready to deliver?
PLoS Biology 3(2).Couto, F., M.J. Silva & P. Coutinho (2003) Improving information extractionthrough biological correlation.
In Proc.
European Workshop on Data Miningand Text Mining, Dubrovnik.Waard, A. de (2007) The pragmatic research article.
In Proc.
2nd InternationalConference on the Pragmatic Web, Tilburg.354
