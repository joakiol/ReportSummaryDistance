Automatically Inducing a Part-of-Speech Taggerby Projecting from Multiple Source LanguagesAcross Aligned CorporaVictoria Fossum1 and Steven Abney21 Dept.
of EECS, University of Michigan, Ann Arbor MI 48105vfossum@umich.edu2 Dept.
of Linguistics, University of Michigan, Ann Arbor MI 48105abney@umich.eduAbstract.
We implement a variant of the algorithm described byYarowsky and Ngai in [21] to induce an HMM POS tagger for an ar-bitrary target language using only an existing POS tagger for a sourcelanguage and an unannotated parallel corpus between the source and tar-get languages.
We extend this work by projecting from multiple sourcelanguages onto a single target language.
We hypothesize that systematictransfer errors from differing source languages will cancel out, improvingthe quality of bootstrapped resources in the target language.
Our exper-iments confirm the hypothesis.
Each experiment compares three cases:(a) source data comes from a single language A, (b) source data comesfrom a single language B, and (c) source data comes from both A and B,but half as much from each.
Apart from the source language, other condi-tions are held constant in all three cases ?
including the total amount ofsource data used.
The null hypothesis is that performance in the mixedcase would be an average of performance in the single-language cases,but in fact, mixed-case performance always exceeds the maximum ofthe single-language cases.
We observed this effect in all six experimentswe ran, involving three different source-language pairs and two differenttarget languages.1 Introduction1.1 BackgroundStatistical NLP techniques typically require large amounts of annotated data.Labelling data by hand is time-consuming; a natural goal is therefore to generatetext analysis tools automatically, using minimal resources.
Yarowsky et al [22]present methods for automatically inducing various monolingual text analysistools for an arbitrary target language, using only the corresponding text analysistool for a source language and a parallel corpus between the source and targetlanguages.
Hwa et al [15] induce a parser for Chinese text via projection fromEnglish using a similar method to that of [22].
Cucerzan and Yarowsky [8] presenta method for bootstrapping a POS tagger for an arbitrary target language usingR.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
862?873, 2005.c?
Springer-Verlag Berlin Heidelberg 2005Automatically Inducing a Part-of-Speech Tagger 863only a bilingual dictionary between the source and target languages, a ?basiclibrary reference grammar?
for the target language, and an existing corpus inthe target language.While automatically induced text analysis tools use fewer resources, theiraccuracy lags behind that of more resource-intensive tools.
One solution to theproblem of error reduction on NLP tasks is to train multiple classifiers, thencompute a consensus classifier.
Combining multiple classifiers is an effective wayto reduce error if the errors made by each classifier are independently distributed.Such approaches have been successfully applied to a range of NLP tasks.
Brilland Wu [4], van Halteren et al [19], and Zavrel and Daelemans [23] investigatevarious methods for improving the performance of statistical POS taggers bycombining multiple such taggers.
Henderson and Brill [14] combine the Char-niak, Collins, and Ratnaparkhi parsers to achieve an accuracy surpassing thebest previous results on the WSJ.
Gollins and Sanderson [10] apply projec-tion via multiple source languages to reduce error in cross-linguistic informationretrieval.1.2 MotivationWe hypothesize that a large component of the error rate in the automatically in-duced text analysis tools generated by [22] is due to morphosyntactic differencesbetween the source and target languages that are specific to each source-targetlanguage pair.
Therefore, training POS taggers on additional source languagesshould result in multiple classifiers which produce independently distributed er-rors on the target language.Previous research in classifier combination for POS tagging has focused pri-marily on combining various statistical classifiers trained on data in the samelanguage.
Thus, our approach is novel in its exploitation of differences acrosslanguages, rather than differences across statistical methods, to improve per-formance on POS tagging.
Our method is general in that it does not rely onlanguage-specific information, and requires no annotated resources in the targetlanguage.Our method is easily extensible to new languages.
While it requires a parallelcorpus between each source language and the target language, the corpora usedto train each single-source tagger need not be translations of the same text.Furthermore, our algorithm is applicable even to target languages belonging todistinct language families from those of the source languages.1.3 Task OverviewUsing existing POS taggers for English, German, and Spanish, we generatesingle-source taggers for Czech and French via projection across parallel trans-lations of the Bible.
To obtain a theoretical upper bound on the performanceimprovement that is possible by combining multiple POS taggers, we measurethe complementarity between each pair of single-source taggers.
We examine864 V. Fossum and S. Abneyvarious ways to combine the output of these single-source taggers into a consen-sus tagger, and measure the resulting performance improvement.2 Methods2.1 Single-Source POS Tagger InductionWe implement a variant of the algorithm described in [21] for constructing asingle-source bigram-based HMM POS tagger for a target language.
First, weidentify a language (the ?source language?)
for which a POS tagger exists, anda sentence-aligned parallel corpus consisting of text in the source language andits translation in the target language.
We then align the parallel corpora atthe word-level using GIZA++ [1].
Next, we annotate the source text using anexisting POS tagger.
Finally, we project these annotations across the paralleltext from the source text to the target text, smooth these projections, and usethe projected annotations to train an HMM POS tagger for the target language.In more detail, we implement the following procedure, based on [21]:1.
Obtain a sentence-aligned parallel corpus in the source and target languages(see Section 2.4).2.
Align the parallel corpus at the word-level using GIZA++1.English: He(1) likes(2) cats(4).French: Il(1) aime(2) les(3) chats(4).3.
Tag the source portion of the parallel corpus using an existing POS tagger forthe source language2.
We use the Brill tagger3 for English [3], the TNT tagger4for German, and the SVMTool tagger5 for Spanish.English: He/PRP likes/VBP cats/NNS.Since the POS tagger for each source language uses its own distinct tagset, weconvert the output of each tagger to a ?generic?
tagset for comparison purposes.Additionally, we label each POS tag as belonging to one of several more general?core?
tagset categories (see Table 1).4.
Using the mapping induced by the word-level alignments, project the POStags from the source language onto the target language.French: Il/PRP aime/VB les/NULL chats/NNS.1 GIZA++ is a component of EGYPT, an open-source implementation of IBM?s sta-tistical machine translation system [1].2 For all existing POS taggers, we use the default models provided with the taggerfor training in the source language.
For taggers with variable parameter settings, weuse the default settings for all parameters.3 A transformation-based tagger [3].4 A bigram-based Markov tagger[2].5 An SVM-based tagger [9].Automatically Inducing a Part-of-Speech Tagger 865Note that tag projection is complicated by the occurrence of many-to-one wordalignments from source to target.
To handle such cases, we compute two esti-mates of tag probabilities, P (ti|wi): one using only 1-to-1 alignments, and theother using 1-to-n alignments.
We then linearly combine the two estimators.5.
Before computing the P (wi|ti) model, several steps must be taken to smooththe initial, noisy tag projections.
First, P (wi|ti) can be decomposed as follows:P (wi|ti) =P (ti|wi) ?
P (wi)P (ti)To smooth P (ti|wi), the simplifying assumption is made that in most naturallanguages, each word has at most two possible POS tags at the core tagsetgranularity.
We count the relative frequency of each tag that is assigned to thatFrench word by the tag projection from English, then discard all but the two mostfrequently assigned core tags.
We then recursively smooth the tag probabilitiesin favor of the two most probable subtags for each of the core tags, where thesubtags are members of the more finely grained ?generic?
tagset.
We computeP (ti) and P (wi) using corpus frequency.6.
We estimate the probability of unknown words using the probability of wordsappearing only once in the training corpus.
We replace all words occurring onlyonce in the training corpus by the ?UNK?
token.7.
Before computing the P (tj |ti) model, we filter the training data to removethose sentence pairs whose alignment score (as determined by GIZA++) fallsinto the lowest 25% of alignment scores.
To estimate the probability of unknownstate transitions, we perform Witten-Bell smoothing [20] on P (tj |ti) to assignnon-zero probabilities to state transitions not seen in the training data.8.
The resulting model defines an HMM bigram-based tagger in the target lan-guage.
We use the Viterbi algorithm to determine the most likely sequence oftags given a sentence in the target language [17].2.2 Multiple-Source POS Tagger InductionTo compute a multiple-source consensus tagger, we train n single-source taggersusing n parallel texts, each pairing one of the source languages with the targetlanguage.
We then apply each single-source tagger to the test sentences.
Foreach word in the test sentences, we record the probability distribution Pi(t|w)over possible tags that the ith single-source tagger produces.
We then computetwo consensus taggers, Majority Tag and Linear Combination, by combining theoutput from each of the n taggers, P1(t|w) .
.
.
Pn(t|w) as follows:Majority Tag: Each tagger outputs the most likely tagtbesti = argmaxt(Pi(t|w))for w. We select the tag from tbest1 , .
.
.
, tbestn that receives the greatest numberof votes from single-source taggers.
To break ties, we select the tag chosen withthe highest probability by the taggers that selected it.866 V. Fossum and S. AbneyLinear Combination: Each tagger outputs a vector of probabilities over pos-sible tags t given w. We take a linear combination of these vectors to computePlinear(T |w), then select the tag tlinear with the highest probability.Plinear(T |w) =n?i=1ki ?
(Pi(T |w))tlinear = argmaxt(Plinear(t|w))In our experiments, we set ki = 1n , so we effectively average the probabilitydistributions of each tagger over possible tags t for w.2.3 TagsetsTwo tagsets of different granularities are used in the experiments: the coarse-grained ?core?
and fine-grained ?generic?
tagsets (see Table 1).
While it can bedifficult to map fine-grained POS tags from one language directly onto anotheranother because of morphological differences between languages, languages tendto agree on tags at a coarse-grained level.2.4 Data SetsWe use two corpora in our experiments: the Bible (with translations in English,Czech, French, German, and Spanish), and the Hansards parallel corpus of Cana-dian parliamentary proceedings (with translations in English and French).
ForTable 1.
Generic and Core TagsetsPOS Generic CoreNoun NN NProper Noun NNP NVerb, Inf.
VB VVerb, Present VBP VVerb, Present Part.
VBG VVerb, Past Part.
VBN VVerb, Past VBD VDeterminer DT DWh-Determiner WDT DConjunction CC CNumber CD NUMAdverb RB RWh-Adverb WRB RAdjective JJ JPronoun PRP PPreposition IN IAutomatically Inducing a Part-of-Speech Tagger 867the Bible experiments, we use the entire 31,100-line text: training data con-sists of either one 31,000-line excerpt or two 15,500-line excerpts, while testingdata consists of a held-out 100-sentence excerpt.
For the Hansards experiments,training data consists of a 85,000-line excerpt; testing data consists of a held-out100-sentence excerpt.We perform the following pre-processing steps.
Each text is filtered to removepunctuation and converted to lower case; accents are preserved.
The English,French, German, and Spanish texts are tokenized to expand elisions.63 ResultsWe report percent agreement with the correct tags, determined by compari-son with the output of the Treetag tagger7 for French, and a hybrid rule-based/HMM-based tagger8 for Czech.
For French, agreement with the correctlytagged text is measured on the generic and core tagsets.
For Czech, agreementis measured on the core tagset only, since this is the POS tagset provided bythe tagger we use for evaluation purposes.
All experiments use 5-fold cross-validation.
For each iteration, the parallel corpus is divided randomly into train-ing and testing sets.
The accuracy of each single-source tagger is limited by theaccuracy of the tagger used to tag the source training text; the accuracy of theevaluation of each tagger?s performance on French and Czech text is limited bythe accuracy of the reference tagger against which it is compared (Table 2).Table 2.
Reported Accuracy of Existing POS Taggers used to Train Single-SourceTaggersTagger Language % Accuracy F-measure Test CorpusBrill English 96.6% ?- Penn Treebank (English)TNT German ?- ?- ?-SVMTool Spanish 96.89% ?- LEXESP (Spanish)TreeTag French 96.36% ?- Penn Treebank (English)Rules + HMM Czech ?- 95.38% PDT (Czech)3.1 Single-SourceFor each single-source tagger, we train on 31,000 lines of the parallel Bible be-tween the source and target languages and test on 100 held-out lines of the Biblein the target language.
We report the accuracy of the induced taggers on French(Tables 5 and 4) and Czech (Table 6).6 e.g.
?doesn?t?
?
?does not?, ?qu?il?
?
?que il?, ?zum?
?
?zu dem?, and ?del?
?
?de el?.
This tokenization represents the only step of our algorithm that requiresadditional language-specific knowledge beyond the resources already given.7 A decision-tree-based tagger [18].8 [13].868 V. Fossum and S. AbneyTo compare our baseline single-source tagger performance against that of [21],we conduct the following experiment, after the experimental procedure used by[21].
We train a single-source English-projected tagger for French on a 2,000,000-word (approximately 85,000-line) excerpt of the French-English Hansards cor-pus and test it on a 100-line excerpt of the same corpus.
We obtain accuraciesof 86.5% and 91.1% on the generic and core tagsets, respectively; [21] reportaccuracies of 91% and 94% on the ?English Equivalent?
and ?core?
tagsets,respectively.93.2 Multiple-SourceComplementarity: We compute the pairwise complementarity of each pair ofsingle-source taggers.
Brill and Wu [4] define the complementarity of a pair oftaggers i and j as the percentage of cases when tagger i is wrong that tagger jis correct (See Table 3):Comp(i, j) = (1 ?
errorsi ?
errorsjerrorsi) ?
100Table 3.
Complementarity (row,col) of Single-Source TaggersFrench Bible Czech BibleGeneric Tagset Core Tagset Core TagsetSource English German Spanish English German Spanish English German SpanishEnglish 0 38.95 32.87 0 32.75 37.13 0 22.08 18.71German 42.40 0 44.93 30.49 0 38.95 15.47 0 17.31Spanish 41.12 48.83 0 35.64 39.51 0 19.95 24.98 0PairwiseCombination: To determine whether tagger performance improves byusing training data from two different source languages, without increasing the to-tal amount of training data, we perform the following experiments.
For each possi-ble combination of two single-source taggers,wepartition theBible into two15,500-line training sets (the first, a parallel corpus between one source language and thetarget language; the second, a parallel corpus between the other source languageand the target language), and a 100-line held-out testing set.
We train the firstsingle-source tagger on one half, train the second single-source tagger on the sec-ond half, combine their output using the methods described in Section 2.2, and testthe resulting consensus tagger on a held-out 100-line excerpt of the French (Tables4 and 5) or Czech (Table 6) Bibles.
For each pairwise combination of taggers, wereport the percent error reduction of the combined tagger in comparison to theaverage accuracy of the constituent single-source taggers.9 Our ?generic?
and ?core?
tagsets correspond approximately to the ?English Equiva-lent?
and ?core?
tagsets used by [21].
Since we do not have access to the same testingset used by [21], we report results on a held-out excerpt of the Hansards corpus.Automatically Inducing a Part-of-Speech Tagger 869Table 4.
% Accuracy of Single-Source, Pairwise-Combined, and n-way Combined Tag-gers Using Generic Tagset on French BibleSources % Accuracy % Error Rate ReductionLinear MajorityEnglish 81.95 81.95 ?German 81.21 81.21 ?Spanish 79.76 79.76 ?Eng.
+ Ger.
84.52 84.30 15.96Eng.
+ Span.
84.42 84.48 18.91Ger.
+ Span.
83.89 84.09 18.45E.
+ G. + S. 85.80 85.61 25.38Table 5.
% Accuracy of Single-Source, Pairwise-Combined, and n-way Combined Tag-gers Using Core Tagset on French BibleSources % Accuracy % Error Rate ReductionLinear MajorityEnglish 85.67 85.67 ?German 86.66 86.66 ?Spanish 86.54 86.54 ?Eng.
+ Ger.
88.06 88.05 13.67Eng.
+ Span.
88.13 88.12 14.54Ger.
+ Span.
89.12 89.19 19.33E.
+ G. + S. 89.87 89.43 26.11n-Way Combination: To examine how much tagger performance can be im-proved by increasing the total amount of training data n-fold and training eachof n single-source taggers on the full 31,000 lines of the Bible, then computinga consensus tagger, we perform the following experiment.
We train each single-source tagger on 31,000 lines of the Bible, then compute the consensus output ofall 3 single-source taggers on a held-out 100-line excerpt of the French (Tables4 and 5) or Czech (Table 6) Bibles.
For each n-way combination of taggers, wereport the percent error reduction of the combined tagger in comparison to theaverage accuracy of the constituent single-source taggers.4 DiscussionAll multiple-source taggers outperform the corresponding single-source taggers?thus, incorporating multiple source languages improves performance, even whenthe total amount of training data is held constant (as in the pairwise combinationexperiments).4.1 Single-Source TaggersWe expect performance to be highest for those source-target language pairs thatare most similar to each other, linguistically.
At the generic tagset level, the870 V. Fossum and S. AbneyTable 6.
% Accuracy of Single-Source, Pairwise-Combined, and n-way Combined Tag-gers Using Core Tagset on Czech BibleSources % Accuracy % Error Rate ReductionLinear MajorityEnglish 62.53 62.53 ?German 65.27 65.27 ?Spanish 63.27 63.27 ?Eng.
+ Ger.
65.44 65.98 5.76Eng.
+ Span.
65.41 65.28 6.77Ger.
+ Span.
67.18 67.75 9.74E.
+ G. + S. 67.13 67.36 10.12poor performance of the Spanish-projected single-source tagger on French textis partially due to a discrepancy between the SVMTool tagset [9] and our generictagset10.
At the core tagset level, the distinction between verb tenses becomesirrelevant, and the performance of the Spanish-projected tagger matches that ofthe other single-source taggers more closely on French data; still, its performanceis lower than expected given the close morphosyntactic correspondence betweenSpanish and French.11For several reasons, we expect single-source tagger performance to be pooreron Czech (Table 6) than on French (Tables 5 and 4).
First, Czech is a ?highlyinflected?
language: the role of function words in the Germanic and Romancelanguages is typically filled by suffixes in Czech.
Second, Czech exhibits a ?rela-tively free word order?
[7].
Since a great deal of the POS information exploitedby an HMM tagger is contained in sequences of function words12, these featuresof Czech hinder the performance of an HMM POS tagger.13 Finally, Czech be-longs to the Slavic language family, and is therefore further removed than Frenchfrom the Germanic and Romance families of the source languages used to trainthe single-source taggers.Although our single-source taggers do not replicate the performance resultsreported by [21] (91% and 94% accuracy on generic and core tagsets, respec-tively), our primary concern is not their absolute performance but rather their10 e.g., SVMTool [9] does not make certain distinctions in verb tense that we make inour generic tagset.11 One likely explanation for this discrepancy is that we do not optimize the parametersof the Spanish POS tagger used to annotate the source corpus to suit the input formatof our data set, but instead use the default settings.
We estimate that optimizingthese parameters to match our data set could result in an increase of 1-2% accuracy inthe Spanish-projected source tagger for French and Czech; however, such an increasein performance of one of the baseline experiments would not change our conclusionin a significant way.12 e.g., a ?DT?
is likely to be followed by a ?NN?
in English.13 The Czech tagger we use for reference [13] combines a rule-based morphologicalanalyzer with an HMM POS tagger to combat these problems; our induced HMMPOS taggers, lacking any morphological analysis component, may not exploit thecorrect type of information for such languages.Automatically Inducing a Part-of-Speech Tagger 871performance relative to the multiple-source taggers.
We think it plausible thatthe improvements we observe would also be observed with Yarowsky?s single-source taggers, but it remains an open question.4.2 Multiple-Source TaggersComplementarity.
Pairwise complementarity among single-source taggers isrelatively high on French at both tagset granularities (Table 3).
The low pairwisecomplementarity of taggers on Czech may indicate the existence of a ceiling onthe performance of the single-source tagger induction algorithm, imposed by thelimited degree of similarity between any of the source languages with the targetlanguage.
Even under such circumstances, we still see improvement (thoughdiminished) by combining single-source taggers for Czech.One factor whose influence upon tagger complementarity must be acknowl-edged is the diversity of the statistical models underlying each of the POS taggersused to tag the source portion of the training text.
Since we use a different typeof tagger to tag each source language, we cannot separate the component ofcomplementarity that is caused by the difference in statistical models amongsources from the component caused by the difference in languages.Pairwise Combination.
All pairwise combined taggers outperform the cor-responding single-source taggers, though the total amount of training data isunchanged.
We observe this improvement on both French and Czech.
This sug-gests that our approach is likely to improve performance over single-source tag-gers on a wide range of target languages, and does not depend upon a closecorrespondence between any of the source and target languages.n-Way Combination.
As expected (given the n-fold increase in training data),all n-way combined taggers outperform the corresponding single-source taggers,suggesting that when parallel training data between a particular source-languagepair is limited, the performance of a POS tagger projected across that languagepair can be improved by the use of a parallel corpus between the target languageand a different source language.5 ConclusionProjection from multiple source languages significantly improves the perfor-mance of automatically induced POS taggers on a target language.
We observeperformance gains from incorporating multiple source taggers even when the to-tal amount of training data is held constant, indicating that multiple languagesprovide sources of information whose errors are independent and randomly dis-tributed to a large extent.
The approach presented here is general in that it doesnot depend on any language-specific resources in the target language beyondparallel corpora.
Our results suggest that the performance of text analysis toolsinduced using parallel corpora can benefit from the incorporation of resourcesin other languages, even in the case of source languages belonging to distinctlinguistic families from the target language.872 V. Fossum and S. Abney6 Future WorkTo further improve the accuracy of induced multiple-source taggers, we plan to in-vestigate othermethods for combining the output of single-sourcePOS taggers.Wehypothesize that combining the models constructed by each tagger before applyingeach tagger to the testing set would result in greater performance gains.References1.
Yasser Al-Onaizan , Jan Curin, Michael Jahr, Kevin Knight, John Lafferty, DanMelamed, Franz-Josef Och, David Purdy, Noah Smith and David Yarowsky: Sta-tistical machine translation.
Johns Hopkins University 1999 Summer Workshop onLanguage Engineering (1999)2.
Thorsten Brants: TnT ?
a statistical part-of-speech tagger.
In Proceedings of the6th Applied NLP Conference, ANLP-2000, April 29 ?
May 3, 2000, Seattle, WA.(2000)3.
Eric Brill: Transformation-Based Error-Driven Learning and Natural LanguageProcessing: A Case Study in Part-of-Speech Tagging.
Computational LinguisticsVol.
21 No.
4 (1995) 543-5654.
Eric Brill and Jun Wu: Classifier Combination for Improving Lexical Disambigua-tion.
Proceedings of the ACL (1998)5.
Peter F. Brown, John Cocke, Stephen Della Pietra, Vincent J. Della Pietra, Freder-ick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin: A StatisticalApproach to Machine Translation.
Computational Linguistics Vol.
16 No.
2 (1990)79?856.
S. Clark, J. Curran, and M. Osborne: Bootstrapping POS taggers using unlabelleddata.
In Walter Daelemans and Miles Osborne, editors, Proceedings of CoNLL-2003, Edmonton, Canada (2003) 49?557.
Michael Collins, Jan Hajic, Lance Ramshaw, and Christoph Tillmann: A StatisticalParser for Czech.
Proceedings of the 37th Annual Meeting of the ACL, CollegePark, Maryland (1999)8.
Silviu Cucerzan and David Yarowsky: Bootstrapping a Multilingual Part-of-speechTagger in One Person-day.
Proceedings of the Sixth Conference on Natural Lan-guage Learning (CoNLL) (2002)9.
Jesus Gimenez and Lluis Marquez: SVMTool: A general POS tagger generatorbased on Support Vector Machines.
Proceedings of the 4th International Confer-ence on Language Resources and Evaluation (LREC?04), Lisbon, Portugal (2004)10.
Tim Gollins and Mark Sanderson: Improving Cross Language Information Retrievalwith Triangulated Translation.
Proceedings of the 24th annual international ACMSIGIR conference 90?95 (2001)11.
French-English Hansards Corpus of Canadian Parliamentary Proceedings.12.
Jan Hajic and Barbora Hladka: Tagging Inflective Languages: Prediction of Mor-phological Categories for a Rich, Structured Tagset, COLING-ACL (1998) 483?49013.
Jan Hajic, Pavel Krbec, Pavel Kevton, Karel Oliva, and Vladimir Petkevic: SerialCombination of Rules and Statistics: A Case Study in Czech Tagging.
Proceedingsof the ACL (2001)14.
John C. Henderson and Eric Brill: Exploiting Diversity in Natural Language Pro-cessing: Combining Parsers.
Proceedings of the 1999 Joint SIGDAT Conferenceon Empirical Methods in Natural Language Processing and Very Large Corpora(1999) 187?194Automatically Inducing a Part-of-Speech Tagger 87315.
Rebecca Hwa, Philip Resnik, and Amy Weinberg: Breaking the Resource Bottle-neck for Multilingual Parsing.
Proceedings of the Workshop on Linguistic Knowl-edge Acquisition and Representation: Bootstrapping Annotated Language Data(2002)16.
Gideon Mann and David Yarowsky: Multipath translation lexicon induction viabridge languages.
In Proceedings of NAACL 2001: 2nd Meeting of the North Amer-ican Chapter of the Association for Computational Linguistics (2001) 151?15817.
Lawrence Rabiner: A tutorial on hidden Markov models and selected applicationsin speech recognition.
Proceedings of the IEEE Vol.
77 No.
2 (1989)18.
Helmut Schmid: Probabilistic Part-of-Speech Tagging Using Decision Trees.
Inter-national Conference on New Methods in Language Processing, Manchester, UK.(1994)19.
Hans van Halteren, Jakub Zavrel, and Walter Daelemans: Improving Data DrivenWordclass Tagging by System Combination.
Proceedings of the Thirty-Sixth An-nual Meeting of the Association for Computational Linguistics (1998) 491?49720.
Ian Witten and Timothy Bell: The zero-frequency problem: Estimating the prob-abilities of novel events in adaptive text compression.
IEEE Transactions in Infor-mation Theory, Vol.
37 No.
4 1085?1094 (1991)21.
David Yarowsky and Grace Ngai: Inducing Multilingual POS Taggers and NPBracketers via Robust Projection Across Aligned Corpora.
Proceedings of NAACL(2001) 200?20722.
David Yarowsky, Grace Ngai, and Richard Wicentowski: Inducing MultilingualText Analysis Tools via Robust Projection across Aligned Corpora.
Proceedings ofHLT (2001)23.
Jakub Zavrel and Walter Daelemans: Bootstrapping a Tagged Corpus throughCombination of Existing Heterogeneous Taggers.
Proceedings of LREC-2000,Athens (2000)
