Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP), pages 28?37,Dublin, Ireland, August 24 2014.A Rule-Based Approach to Aspect Extraction from Product ReviewsSoujanya PoriaDept of Computing Science & MathsUniversity of Stirlingsoujanya.poria@cs.stir.ac.ukErik CambriaSchool of Computer EngineeringNanyang Technological Universitycambria@ntu.edu.sgLun-Wei KuInstitute of Information ScienceAcademia Sinicalwku@iis.sinica.edu.twChen GuiSenticNetchen@sentic.netAlexander GelbukhCenter for Computing ResearchNational Polytechnic Institutegelbukh@cic.ipn.mxAbstractSentiment analysis is a rapidly growing research field that has attracted both academia and in-dustry because of the challenging research problems it poses and the potential benefits it canprovide in many real life applications.
Aspect-based opinion mining, in particular, is one of thefundamental challenges within this research field.
In this work, we aim to solve the problem ofaspect extraction from product reviews by proposing a novel rule-based approach that exploitscommon-sense knowledge and sentence dependency trees to detect both explicit and implicit as-pects.
Two popular review datasets were used for evaluating the system against state-of-the-artaspect extraction techniques, obtaining higher detection accuracy for both datasets.1 IntroductionIn opinion mining, different levels of granularity analysis have been proposed, each one having its ownadvantages and disadvantages.
Aspect-based opinion mining (Hu and Liu, 2004; Ding et al., 2008)focuses on the extraction of aspects (or product features) from opinionated text and on the inference ofpolarity values associated with these.
For example, a sentence like ?I love the touchscreen of my phonebut the battery life is so short?
contains two aspects or opinion targets, namely touchscreen and batterylife.
In this case, applying a sentence level polarity detection technique would mistakenly result in apolarity value close to neutral, since the two opinions expressed by the users are opposite.
Hence, aspectextraction is necessary to first deconstruct sentences into product features and then assign a separatepolarity value to each of these features.There are two types of aspects defined in aspect-based opinion mining: explicit and implicit.
Explicitaspects are concepts that explicitly denote targets in the opinionated sentence.
For instance, in the aboveexample, touchscreen and battery life are explicit aspects as they are explicitly mentioned in the sentence.On the other hand, an aspect can also be expressed indirectly through an implicit aspect clue (IAC), e.g.,in the sentence ?This camera is sleek and very affordable?, which implicitly provides a positive opinionabout the aspects appearance and price of the entity camera.Explicit aspect extraction has been widely researched and there exists several approaches for thistask.
Still, limited work has been done in extracting implicit aspects.
This task is very difficult yet veryimportant because the phenomenon of implicit aspects is present in nearly every opinionated document.For example, the following document extracted from the corpus (Hu and Liu, 2004) uses only implicitaspects:This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedingsfooter are added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.028This is the best phone one could have.
It has all the features one would need in a cellphone: Itis lightweight, sleek and attractive.
I found it very user-friendly and easy to manipulate; veryconvenient to scroll in menu etc.Here, the word ?lightweight?
refers to the weight of the phone; the words ?sleek?
and ?attractive?
toits appearance; the compound ?user-friendly?
to its interface; the phrase ?easy to manipulate?
to itsfunctionality; finally, the phrase ?to scroll in menu?
can be interpreted as a reference to the interfaceof the phone or its menu.
Even though the aspects appearance, weight and interface do not appearin the sentence, the context contains clues that permit us to infer them.
Namely, the words ?sleek,??lightweight,?
and ?user-friendly?
that do occur in the context suggest these aspects.In contrast to the task of identification of explicit aspects, the general scheme for identification ofimplicit aspects, a task called implicit aspect extraction, typically involves two steps:1.
Identify IACs (e.g., ?sleek?)
in the opinionated document.2.
Map them to the corresponding aspects (e.g., appearance).In this paper, we propose a novel approach to detect explicit aspects and IACs from opinionateddocuments.
We also map IACs to their respective aspect categories.
IACs are either single words,such as ?sleek,?
or multi-word expressions, such as ?easy to manipulate?
as in the above example.
EachIAC can be represented by a different part-of-speech (POS): in the example ?This MP3 player is reallyexpensive,?
the IAC ?expensive?
suggesting the aspect price is an adjective; in ?This camera looksgreat,?
the IAC ?look?
suggesting appearance is a verb; in ?I hate this phone.
It only lasted less than sixmonths!
?, the IAC ?lasted?
suggesting durability of the phone is a verb.
In the following examples, IACsare nouns or noun phrases: ?Even if I had paid full price I would have considered this phone a good deal,?
?Not to mention the sleekness of this phone?, ?The player keeps giving random errors?, ?This phone is apiece of crap.
?In different contexts, the same implicit aspect can be implied by different IACs, as shown below forthe implicit aspect price:?
This mp3 player is very affordable.?
This mp3 player also costs a lot less than the ipod.?
This mp3 player is quite cheap.?
This mp3 is inexpensive.?
I bought this mp3 for almost nothing!?
This mp3 player has been fairly innovative and reasonably priced.A common approach for IAC identification is to assume that sentiments or polarity words are goodcandidates for IACs: for example, in ?This MP3 player is really expensive,?
the word ?expensive?,which bears negative polarity, is also the IAC for the aspect price.
However, this is not always true.For example, in ?This camera looks great,?
the word ?looks?
implies the appearance of the phone,while polarity is conveyed through the word ?great.?
In ?I hate this phone.
It only lasted less than sixmonths!
?, the word ?lasted?
is the IAC for durability of the phone, while polarity is indicated by ?hate.
?Furthermore, the second sentence of this example could appear without the first one: ?This phone onlylasted less than six months?
and still constitute a negative opinion of the phone?s durability, but notexpressed by any specific word.This phenomenon is known in opinion mining as desirable fact: communicating fact that by common-sense are good or bad, which indirectly implies polarity.
For example, the objective fact ?The camera canhold lots of pictures?
does not contain any sentiment or polarity word yet gives a positive opinion aboutthe camera?s memory capacity (IAC ?hold?
), because it is desirable for a camera to hold many pictures.29In this paper, we present a rule-based approach that exploits common-sense knowledge and sentencedependency trees to detect both implicit and explicit aspects.
In particular, the approach draws lessonsfrom recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a)and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependencystructure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarityassociated with them.
The paper is organized as follows: Section 2 presents the literature in aspect ex-traction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposedmethodology; Section 5 describes in detail the aspect extraction approach and results of the experimentalevaluation; finally, Section 6 concludes the paper.2 Related WorkAspect extraction from opinionated text was first studied by Hu and Liu (Hu and Liu, 2004), who alsointroduced the distinction between explicit and implicit aspects.
However, the authors only dealt withexplicit aspects by adopting a set of rules based on statistical observations.
Hu and Liu?s method was im-proved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohnet al., 2008).
Popescu and Etzioni assumed the product class to be known as priori.
Their algorithmdetects whether a noun or noun phrase is a product feature or not by computing PMI between the nounphrase and the product class.
Scaffidi et al.
(Scaffidi et al., 2007) presented a method that uses a languagemodel to identify product features.
They assumed that product features are more frequent in product re-views than in general natural language text.
However, their method seems to be very inaccurate in termsof precision as the retrieved aspects extracted by their method were very noisy.Aspect extraction can be seen as a general information extraction problem, for which techniques basedon sequential labeling are generally used.
The most popular methods in this context, in particular, areHidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001).
Jin andHo (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicitaspects.
Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in acustom corpus with data of different domains.
Li et al.
(Li et al., 2010), Choi and Cardie (Choi andCardie, 2010) and Huang et al.
(Huang et al., 2012) also used CRF for extraction of explicit aspects.As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescuand Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarityclassification.
However, their system is not described in detail and is not publicly available.
To thebest of our knowledge, all existing methods for implicit aspect extraction are based on the use, in oneor another way, of what we term IAC.
Su (Su et al., 2008) proposed a clustering method to map IACs(which were assumed to be sentiment words) to their corresponding explicit aspects.
The method exploitsthe mutual reinforcement relationship between an explicit aspect and a sentiment word forming a co-occurring pair in a sentence.
Hai (Zhen et al., 2011) proposed a two-phase co-occurrence associationrule mining approach to match implicit aspects (which were also assumed to be sentiment words) withexplicit aspects.
Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extractexplicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicitfeature-word pairs.3 Method3.1 Corpus for aspect extractionIn order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu andLiu, 2004) and the Semeval 2014 dataset1(Table 1).
As for the implicit aspect extraction algorithm andlexicon, we use the corpus developed by Cruz-Garcia et al.
(Cruz-Garcia et al., 2014), who manuallylabeled each IAC and their corresponding aspects in a well-known corpus for opinion mining (Hu andLiu, 2004).
The corpus is publicly available for research purposes.21http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools2Available from www.gelbukh.com/resources/implicit-aspect-extraction-corpus, visited onMarch 19, 2014.30Table 1: Description of Semeval 2014 datasetSentences Containing n aspect termsDomain Name n = 0 n ?
1 n ?
2 total(n ?
0)Restaurants 1,732 2,212 881 3,944Laptops 1,883 2,065 456 3,9483.2 Pre-ProcessingPre-processing is a key step for aspect parsing.
The pre-processing module of the proposed frameworkconsists of two major steps: firstly, the sentence dependency tree is obtained through Stanford Depen-dency Parser3; secondly, dependency structure elements are processed by means of Stanford Lemmatizerfor each sentence.
It is important to build the dependency tree before lemmatization as swapping the twosteps results in several imprecisions caused by the lower grammatical accuracy of lemmatized sentences.3.3 Aspect Parser3.3.1 Implicit aspect lexiconWe use the implicit aspect corpus developed by Cruz-Garcia et al.
(Cruz-Garcia et al., 2014), whereIACs are indicated and manually labeled by their corresponding aspect categories.
For our task, weextracted the sentences having implicit aspects and then extracted IACs for each of them, along withtheir corresponding labeled categories.
For example, in ?The car is expensive?
the IAC is expensive andit is labeled by the category price.
Below is the list of the aspect categories extracted from the corpus:?
functionality?
weight?
price?
appearance?
behavior?
performance?
quality?
service?
sizeFor each IAC under every aspect category, synonyms and antonyms were obtained from WordNet (Fell-baum, 1998) and stored under the same aspect category.
For example, expensive and its antonym inex-pensive both have the same category price.
Semantics extracted from SenticNet (Cambria et al., 2014b)have also been exploited to enlarge the set of conceptually related IACs.
Thus, a lexicon of 1,128 IACscategorized into the above categories was built.3.3.2 Opinion LexiconWe use SenticNet 3 as a concept-level opinion lexicon.
The common-sense knowledge base contains30,000 multi-word expressions labeled by their polarity scores.
The proposed aspect parser is based ontwo general rules:?
Rules for the sentences having subject verb.?
Rules for the sentences which do not have subject verb.3http://nlp.stanford.edu:8080/parser31A dependency relation is a binary relation characterized by the following features:?
The type of the relation that specifies the nature of the (syntactic) link between the two elements inthe relation.?
The head of the relation: this is the element that is the pivot of the relation.
Core syntactic andsemantics properties (e.g., agreement) are inherited from the head.?
The dependent is the element that depends on the head and which usually inherits some of itscharacteristics (e.g., number, gender in the case of agreement).Most of the times, the active token is considered in a relation if it acts as the head of the relation, althoughthere are exceptions.
Once the active token has been identified as the trigger for a rule, there are severalways to compute its contribution, depending on how the dependency relation and the properties of thetokens match with the rules.
The preferred way is not to consider the contribution of the token alone,but in combination with the other elements in the dependency relation.
First of all, Stanford parser isused to obtain the dependency parse structure of each sentence.
Then, hand-crafted dependency rules areemployed on the parse trees to extract aspects.3.3.3 Subject Noun RuleTrigger: when the active token is found to be the syntactic subject of a token.
Behavior: if an activetoken h is in a subject noun relationship with a word t then:1. if t has any adverbial or adjective modifier and the modifier exists in SenticNet, then t is extractedas an aspect.2.
if the sentence does not have auxiliary verb, i.e., is, was, would, should, could, then:?
if the verb t is modified by an adjective or an adverb or it is in adverbial clause modifier relationwith another token, then both h and t are extracted as aspects.
In (1), battery is in a subjectrelation with lasts and lasts is modified by the adjective modifier little, hence both the aspectslast and battery are extracted.
(1) The battery lasts little.?
if t has any direct object relation with a token n and the POS of the token is Noun and n is notin SenticNet, then n is extracted as an aspect.
In (2), like is in direct object relation with lensso the aspect lens is extracted.
(2) I like the lens of this camera.?
if t has any direct object relation with a token n and the POS of the token n is Noun and n existsin SenticNet, then the token n extracted as aspect term.
In the dependency parse tree of thesentence, if another token n1is connected to n using any dependency relation and the POS ofn1is Noun, then n1is extracted as an aspect.
In (3), like is in direct object relation with beautywhich is connected to screen via a preposition relation.
So the aspects screen and beauty areextracted.
(3) I like the beauty of the screen.?
if t is in open clausal complement relation with a token t1, then the aspect t-t1is extracted if t-t1exists in the opinion lexicon.
If t1is connected with a token t2whose POS is Noun, then t2isextracted as an aspect.
In (4), like and comment is in clausal complement relation and commentis connected to camera using a preposition relation.
Here, the POS of camera is Noun and,hence, camera is extracted as an aspect.
(4) I would like to comment on the camera of this phone.323.
A copula is the relation between the complement of a copular verb and the copular verb.
If thetoken t is in copula relation with a copular verb and the copular verb exists in the implicit aspectlexicon, then t is extract as aspect term.
In (5), expensive is extracted as an aspect.
(5) The car is expensive.4.
If the token t is in copula relation with a copular verb and the POS of h is Noun, then h is extractedas an explicit aspect.
In (6), camera is extracted as an aspect.
(6) The camera is nice.5.
If the token t is in copula relation with a copular verb and the copular verb is connected to a tokent1using any dependency relation and t1is a verb, then both t1and t are extracted as implicit aspectterms, as long as they exist in the implicit aspect lexicon.
In (7), lightweight is in copula relationwith is and lightweight is connected to the word carry by open clausal complement relation.
Here,both lightweight and carry are extracted as aspects.
(7) The phone is very lightweight to carry.3.3.4 Sentences which do not have subject noun relation in their parse treeFor sentences that do not have noun subject relation in their parse trees, aspects are extracted using thefollowing rules:1. if an adjective or adverb h is in infinitival or open clausal complement relation with a token t and hexists in the implicit aspect lexicon, then h is extracted as an aspect.
In (8), big is extracted as anaspect as it is connected to hold using a clausal complement relation.
(8) Very big to hold.2.
if a token h is connected to a noun t using a prepositional relation, then both h and t are extracted asaspects.
In (9) sleekness is extracted as an aspect.
(9) Love the sleekness of the player.3.
if a token h is in a direct object relation with a token t, t is extracted as aspect.
In (10), mention is ina direct object relation with price, hence price is extracted as an aspect.
(10) Not to mention the price of the phone.3.3.5 Additional Rules?
For each aspect term extracted above, if an aspect term h is in co-ordination or conjunct relationwith another token t, then t is also extracted as an aspect.
In (11), amazing is firstly extracted as anaspect term.
As amazing is in conjunct relation with easy, then use is also extracted as an aspect.
(11) The camera is amazing and easy to use.?
A noun compound modifier of an NP is any noun that serves to modify the head noun.
If t isextracted as an aspect and t has noun compound modifier h, then the aspect h-t is extracted and tis removed from the aspect list.
In (12), as chicken and casserole are in noun compound modifierrelation, only chicken casserole is extracted as an aspect.
(12) We ordered the chicken casserole, but what we got were a few small pieces of chicken, alldark meat and on the bone.334 Novelty of the proposed workFirst of all, the proposed method is fully unsupervised and depends on the accuracy of the dependencyparser and the opinion lexicon, rather then a training corpus and supervised learning accuracy.
Only(Qiu et al., 2011) follow an unsupervised learning approach but the proposed method uses an enhancedset of rules and opinion lexicon.
The proposed method also outperforms (Qiu et al., 2011) on the samedataset they used.
Implicit aspects extracted through the proposed method differ from implicit aspectexpressions defined by Liu (Liu, 2012) as ?aspect expressions that are not nouns or noun phrases?
in thatimplicit aspects extracted by the proposed algorithm semantically refer to the values of the pre-definedaspects, irrespective of their own surface POS.
Below are listed some examples where the implicit aspectterms are either noun or noun phrases.In (13), the IAC deal is extracted.
(13) Even if I had paid full price I would have considered this phone a good deal.In (14), sleekness is extracted as an IAC.
(14) Not to mention the sleekness of this phone.In (15), the IAC errors is extracted by the algorithm.
(15) The player keeps giving random errors.In (16), piece of crap is a noun phrase and is extracted as an IAC by the proposed algorithm.
(16) This phone is a piece of crap.A demo of the developed aspect parser is freely available at http://sentic.net/demo.Table 2: Results on the DVD-player review dataset provided by (Hu and Liu, 2004)Algorithm Precision RecallHu and Liu 75.00% 82.00%Popescu and Etzioni 89.00% 80.00%Dependency propagation method 87.00% 81.00%Proposed approach 89.25% 91.25%Table 3: Results on the Canon G3 review dataset provided by (Hu and Liu, 2004)Algorithm Precision RecallHu and Liu 71.00% 79.00%Popescu and Etzioni 87.00% 74.00%Dependency propagation method 90.00% 81.00%Proposed approach 90.15% 92.25%Table 4: Results on the Jukebox review dataset provided by (Hu and Liu, 2004)Algorithm Precision RecallHu and Liu 72.00% 76.00%Popescu and Etzioni 89.00% 74.00%Dependency propagation method 90.00% 86.00%Proposed approach 92.25% 94.15%34Table 5: Results on the Nikon Coolpix review dataset provided by (Hu and Liu, 2004)Algorithm Precision RecallHu and Liu 69.00% 82.00%Popescu and Etzioni 86.00% 80.00%Dependency propagation method 81.00% 84.00%Proposed approach 82.15% 86.15%Table 6: Results on the Nokia-6610 review dataset provided by (Hu and Liu, 2004)Algorithm Precision RecallHu and Liu 74.00% 80.00%Popescu and Etzioni 90.00% 78.00%Dependency propagation method 92.00% 86.00%Proposed approach 93.25% 93.32%5 Experiments and Results5.1 Experiment on the dataset provided by (Hu and Liu, 2004)Experimental evaluation was carried out on the dataset derived from (Hu and Liu, 2004).
As discussedin Section 3, the proposed method is able to extract both explicit and implicit aspects.
To the best of ourknowledge, there is no state-of-the-art benchmark to evaluate implicit aspect extraction.We compare the proposed framework with those in Hu and Liu (Hu and Liu, 2004), Qiu et al.
(Qiu etal., 2011), and Popescu and Etzioni (Popescu and Etzioni, 2005) (which only carried out explicit aspectextraction).
Table 2, Table 3, Table 4, Table 5 and Table 6 show that the proposed framework outperformsall existing methods in terms of both precision and recall.6 ConclusionWe have illustrated a method for extracting both explicit and implicit aspects from opinionated text.The proposed framework only leverages on common-sense knowledge and on the dependency structureof sentences and, hence, is unsupervised.
As future work, we aim to discover more rules for aspectextraction.
Another key future effort is to combine existing rules for complex aspect extraction.
Toobtain the aspect categories of IACs, we have developed an aspect knowledge base using WordNet andSenticNet.
We will focus on extending the scalability of such knowledge base and on making it as muchnoise-free as possible.6.1 Experiment on Semeval 2014 datasetWe also carried out experiments on Semeval 2014 aspect based sentiment analysis data obtained fromhttp://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools.
Re-sults are shown in Table 7.
We cannot perform a comparative evaluation of such experimental results asthere is no state-of-art approach yet which used this dataset for the same kind of experiment.
Overall,results show high accuracy.Table 7: Results on the Semeval 2014 datasetDomain Precision RecallLaptop 82.15% 84.32%Restaurants 85.21% 88.15%35ReferencesSasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George A. Reis, and Jeff Reynar.
2008.Building a sentiment summarizer for local service reviews.
In Proceedings of WWW-2008 workshop on NLP inthe Information Explosion Era, page 14.Erik Cambria, Thomas Mazzocco, Amir Hussain, and Chris Eckl.
2011.
Sentic medoids: Organizing affectivecommon sense knowledge in a multi-dimensional vector space.
In D Liu, H Zhang, M Polycarpou, C Alippi,and H He, editors, Advances in Neural Networks, volume 6677 of Lecture Notes in Computer Science, pages601?610, Berlin.
Springer-Verlag.Erik Cambria, Paolo Gastaldo, Federica Bisio, and Rodolfo Zunino.
2014a.
An ELM-based model for affectiveanalogical reasoning.
Neurocomputing.Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal.
2014b.
SenticNet 3: A common and common-sense knowl-edge base for cognition-driven sentiment analysis.
AAAI, pages 1515?1521.Yejin Choi and Claire Cardie.
2010.
Hierarchical sequential learning for extracting opinions and their attributes.
InProceedings of Annual Meeting of the Association for Computational Linguistics (ACL-2010), pages 268?274.Ivan Cruz-Garcia, Alexander Gelbukh, and Grigori Sidorov.
2014.
Implicit aspect indicator extraction for aspect-based opinion mining.
submitted.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
A holistic lexicon-based approach to opinion mining.
InProceedings of First ACM International Conference on Web Search and Data Mining (WSDM-2008), pages231?240, Stanford University, Stanford, California, USA, Feb.Christiane Fellbaum.
1998.
WordNet: An Electronic Lexical Database (Language, Speech, and Communication).The MIT Press.Minqing Hu and Bing Liu.
2004.
Mining and summarizing customer reviews.
In Proceedings of the ACMSIGKDD International Conference on Knowledge Discovery & Data Mining, pages 168?177, Aug.Sheng Huang, Xinlan Liu, Xueping Peng, and Zhendong Niu.
2012.
Fine-grained product features extraction andcategorization in reviews opinion mining.
In Proceedings of the IEEE 12th International Conference on DataMining Workshops, pages 680?686.Wei Jin and Hung Hay Ho.
2009.
A novel lexicalized HMM-based learning framework for web opinion mining.In Proceedings of International Conference on Machine Learning (ICML-2009), pages 465?472.John Lafferty, Andrew McCallum, and Fernando C.N.
Pereira.
2001.
Conditional random fields: probabilisticmodels for segmenting and labeling sequence data.
In Proceedings of the 18th International Conference onMachine Learning, pages 282?289.
Morgan Kaufmann Publishers.Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, and Hao Yu.
2010.
Structure-awarereview mining and summarization.
In Proceedings of the 23rd International Conference on ComputationalLinguistics (COLING-2010), pages 653?661.Bing Liu.
2012.
Sentiment Analysis and Opinion Mining.
Morgan & Claypool Publishers.Jakob Niklas and Iryna Gurevych.
2010.
Extracting opinion targets in a single and cross-domain setting with con-ditional random fields.
In Proceedings of Conference on Empirical Methods in Natural Language Processing(EMNLP-2010), pages 1035?1045.Ana-Maria Popescu and Oren Etzioni.
2005.
Extracting product features and opinions from reviews.
In Proceed-ings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2005), pages 3?28.Soujanya Poria, Erik Cambria, Gregoire Winterstein, and Guang-Bin Huang.
2014.
Sentic patterns: Dependency-based rules for concept-level sentiment analysis.
Knowledge-Based Systems.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011.
Opinion word expansion and target extraction throughdouble propagation.
Computational linguistics, 37(1):9?27.Christopher Scaffidi, Kevin Bierhoff, Eric Chang, Mikhael Felker, Herman Ng, and Chun Jin.
2007.
Red opal:product-feature scoring from reviews.
In Proceedings of the 8th ACM conference on Electronic commerce,pages 182?191.
ACM.36Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su.
2008.
Hiddensentiment association in chinese web opinion mining.
In Proceedings of International Conference on WorldWide Web (WWW-2008), pages 959?968.Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cambria.
2013.
Feature ensemble plus sample selection: Acomprehensive approach to domain adaptation for sentiment classification.
IEEE Intelligent Systems, 28(3):10?18.Lingwei Zeng and Fang Li.
2013.
A classification-based approach for implicit feature identification.
In ChineseComputational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data.
12thChina National Conference, CCL 2013 and First International Symposium, NLP-NABD 2013, Suzhou, China,October 10?12, 2013, Proceedings, volume 8202 of Lecture Notes in Computer Science, pages 190?202.Hai Zhen, Kuiyu Chang, and Jung-jae Kim.
2011.
Implicit feature identification via co-occurrence association rulemining.
In Computational Linguistics and Intelligent Text Processing.
12th International Conference, CICLing2011, Tokyo, Japan, February 20?26, 2011.
Proceedings, Part I, volume 6608 of Lecture Notes in ComputerScience, pages 393?404.37
