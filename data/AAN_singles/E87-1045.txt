FRAGMENTATION AND PART OF SPEECH DISAMBIGUATION lJean-Louis BinotBTM.Kwikstraat, 4B3078 Everberg, BelgiumABSTRACTThat at least some syntax is necessary to support semantic process-ing is fairly obvious.
To know exactly how much syntax is needed,however, and how and when to apply it, is still an open and crucial,albeit old, question.
This paper discusses the solutions used in asemantic analyser of French called SABA, developed at the Uni-versity of Liege, Belgium.
Specifically, we shall argue in favor of theusefulness of two syntactic processes: fragmentation, which can heinterleaved with semantic processing, and part-of-speechdisambiguation, which can be performed as a preprocesslng step.1.
IntroductionThe role of syntax is one of these issues in natural anguage proc-essing which, albeit old and often (hotly) debated, have yet to re-ceive a definitive answer.
(Lytinen 86) distinguishes two approachesto NI, processing.
Followers of the "modular" approach believeusually in the autonomy of syntax and in the usefulness and cost-effectiveness of a purely syntactic stage of processing.
Results of thisapproach include the development of new grammatical formalisms(Weir et al 86) (Ristad 86), and of large syntactic grammars (Jensenet al 86).Followers of the "integrated" approach, on the contrary, believethat semantics hould be used as soon as possible in the parsingprocess.
An "integrated" system would have no discemable stagesof parsing, and would build directly a meaning representation with-out building an intermediate syntactic structure, tlow much syntaxis needed to support his semantic processing, however, and howshould the integration between syntax and semantics be done arestill open and crucial questions.
Some integrated systems, such asIPP (Schank et al 80) and Wilks" Preference Semantics ystem(Wilks 75), were trying to reduce the role of syntax as much aspossible.
Lytinen proposes a more moderate option in which sepa-rate syntactic and semantic rules are dynamically combined atparsing time.
Another kind of integration is used in (Boguraev 79),where an ATN is combined with Wilks' style semantic procedures.And, lastly, one might consider that unification-based grammars(Shieber 86) offer yet another approach where syntactic and se-mantic constraints can be specified simultaneously in functionalstructures and satisfied in parallel.The research presented in this paper was entirely performed while theauthor was working at the Computer Sciences department of Universityof Liege, Belgium.In this paper, we wish to present our arguments in favors of in-tegration, and then to discuss two specific technical proposals.
Ourgeneral position can be stated as follows:1.
That at least some form of syntax is necessary for natural an-guage processing should be by now fairly obvious and shouldneed no further argumentation.2.
Syntax, however, is not a goal per se.
The basic goal of NLP,at least from the point of view of AI, is to give a computer away to "understand" natural language input, and this dearlyrequires a semantic omponent.
The utility or necessity ofsyntax should only be evaluated in the light of the help it canprovide to this semantic omponent.3.
Grammaticality is not an essential issue, except in languagegeneration and in specific applications like CRITIQUE (Jensenet al 86), where the purpose is to correct he syntax and thestyle of a writer.
For the general task of understanding,achieving comprehension, even in the face of incorrect or unu-sual input, is more important than enforcing some grammaticalstandards.
And we believe that robustness is more easilyachieved in the context of a semantic system than in the pre-dictive paradigm of the grammatical pproach.If we want to avoid the use of a full male grammar, the syntacticprocesses necessary to support he semantic module must be im-plemented by special dedicated procedures.
This paper describe the.solutions used in a semantic analyser of French called SABA, de-veloped at the Computer Sciences department of University ofLiege, Belgium.
Specifically, we shall argue in favor of two syntacticprocesses: fragmentation, which can be interleaved with semanticprocessing, and part of speech disambiguation, which is usefullyperformed in a preprocessing step.
We shall start by a brief de-scription of the SABA system.2.
Overview of the SABA system.SABA ("Semantic Analyser, Backward Approach", (Binot, 1985),(Blnot et al, 1986)) is a robust and portable semantic parser ofwritten French sentences.
A prototype of this parser is running inMACLISP and in ZETAI.1SP; it has been tested successfully on acorpus of about 125 French sentences.
This system is not basedon a French grammar, but on semantic procedures which, withsome syntactic support, build directly a semantic dependency graphfrom the natural anguage input.
The following example is typicalof the level of complexity that can be handled by the system:(l) Le pont que le eonvoi a passe quand il a quitte New York ?ematin etait fort long.
(The bridge that the convoy crossed when it left New Yorkthis morning was very long.
)284To allow for portability, the SABA parser translates its naturallanguage input into an ~mtermediate" s mantic network formalismcalled SF (for "Sentence Formalism'), presented in details in (Binot,1984, 1985).
Before generating the SF output, SABA builds asimplified semantic graph expressing all the semantic dependenciesestablished between the meaningful terms of the sentence.
Thegraph established for sentence (1) is shown in figure (2).
(2)pont wLRque *.11BENEFICIARY VALUE INTENSITYQUAL long fortOBJECT AGENT0~ * convolMOMENT I passerAGENT OBJECTI~0~ *quitter New YorkMOMENT* mat inThese kinds of dependencies are established by using the ~dualframes" method described in (Binot and Ribbens 86).
Dual framesis a general method for establishing binary semantic dependenciesbetween all possible types of meaningfull terms.
This method sup-ports also a hierarchy of semantic lasses and an inheritance mech-anism allowing the designer to specify generic semantic frames at ageneral level.
However, we are not cone*reed here by the specificsof a particular semantic method, but by the kind of syntactic sup-port necessary to establish such dependencies (or, to put it anotherway, by the kind of syntactic support needed to identify accuratelythe arguments fdling the role slots of various meaningfull tenns).3.
Fragmentation3.1 General discussionConsider again sentence (1) and suppose that a purely semanticsystem were to understand it by establishing semantic dependenciesbetween words.
There would be no reason for such a system to re-frain from attempting to connect "was long" to "convoy', for ex-ample, And, if the attempt is made, no amount of semantic orpragmatic knowledge will be able to prevent he connection, whichis perfectly valid as such.
Note also that a simple proximity principlewould not work in this case.Thus, any natural language processing system must take intoaccount, in some way, the structure of a sentence, ttowever, wedon't necessarily need to build an intermediate syntactic structure,such as a parse tree, showing the detailed "phrase structure" of theinput.
The most crucial structural information eeded for an accu-rate semantic processing concerns "boundaries" across which se-mantic processing should not be allowed to relate words.
Theseboundaries can be identified by a fragmentation process which willcut a sentence into useful fragments by looking for specific types ofwords.Except maybe in Wilks" system fragmentation has not receivedthe attention it deserves as a faster alternative to full syntactic pars-ing.
Wilks" fragmentation process, however, was by his own ad-mission too simple.
In his system, fragmentation was performedonly once as a preprocessing step, and was designed around the sizeof his notion of "template'.
Both of these characteristics, we think,give rise to problems.Performing fragmentation asa single preprocessing step is obvi-ously insufficient for garden path sentences and for all the structuralambiguities that cannot be solved without the help of the semanticmodule.
Although Wilks said something about involving some se-mantic processing at the fragmentation stage, notably for handlingthe ambiguity about "that% he never presented, to our knowledge,a systematic procedure to integrate fragmentation and semantics.On the other hand, we believe that template sized fragments aremore troublesome and less us,full than clause sized fragments.
Evenin straightforward active declarative sentences, two distinct mech-anisms must be provided to establish semantic dependencies inWilks system: template matching, which identifies ~agent-action-object" triples, and paraplates, which are used to tie these templatestogether.
A prepositional phrase constitutes a separate template.One problem with that approach is that in sentences such as "Theold man / in the comer / left', fragmented by Wilks as shown by the.
/ ,  the agent ends up in a different fragment than the action andan additionnal step will be required to relate the two.
The sameproblem seems to arise in passive structures ('John is loved / byMary').
To avoid these kinds of problems, we decided to use clausesized fragments and to establish semantic dependencies directly atthe clause level.A third difference between the two approaches i that, whileWilks never provided a systematic method to solve part of speechambiguities, SABA makes use of a part of speech disambiguationpreprocessor, which will be described in the second part of this pa-per.
This module being applied before fragmentation, we shall as-sume in the following discussion of the fragmentation mechanismthat each word has a single part of speech.3.2 The fragmentation mechanism.We have implemented in the SABA system a fragmentation mech-anism which uses the clause as the fundamental fragmentation u itand which is repetitively applied and interleaved with the semanticprocessing.
We start by presenting the basic algorithm, then, in thenext sections, we shall discuss some more difficult problems andshow how the introduction of two additionnal mechanisms, ejectionand backtracking, can solve them.Fragmentation algorithm:Repeat he following until success or dead endI.
Fragment the sentence into clauses;2.
Select he innermost clause;3.
Process the selected clause, which includes:a.
The fragmentation f the clause into groups;b.
The establishement of semantic dcpendancies inside eachgroup;c. The establishement of semantic dcpendancies at the clauselevel;4.
If the processing is suecessfull, erase the text of the clau~ fromthe input and replace it by a special non terminal symbol.This algorithm follows a bottom-up strategy in which the in-nermost clause (the most dependent one) is always processed first.Ties are resolved by a left to right prefercnce rule.
The special sym-bols used in step 4 are PP CProposition Principal,") for a main'clause, PR for a relative clausc, PC for a conjunctive subordinateclause and PINF for an infinitive clause.
Participe clauses are proc-essed as special kinds of relatives, as we explain in section 4.2.Success in the above algorithm means that the input has beenreduced to the PP symbol or to a string of such symbols and con-junctions.
A dead end is reached if fragmentation can find no newclause or if the selected clause cannot be processed.
What happensthen will be discussed in the next sections.285As can be seen in the above algorithm, fragmentation i  SABAis in fact a two level process: sentences are fragmented into clausesand clauses into groups.
Fragmentation i to groups, wich gives farless problems than fragmentation i to clauses, will not be discussedat all in this paper.Fragmentation of a sentence into clauses proceeds by extendingto the left and to the right of each verb 2 and checking each en-countered word looking for clause delimiters.
The checks are per-formed by heuristic rules based on the part of speech of each word.Other rules will then look at the delimiters to fred the innermostclause.The rules checking if a given word is a delimiter are given below.The term "explicit clause boundaries" used in the rules denotes thefollowing kinds of words: relative or interrogative pronouns, rela-tive or interrogative adjectives, ubordinate conjunctions and coor-dinate conjunctions.
Coordinate conjunctions, which raise specialproblems, will not be discussed before section 3.5.Clause f ragmentat ion  rules.1.
Explicit clause boundaries other than coordinate conjunctionsare always clause delimiters; they are included in the clause onthe left and excluded on the right)2.
The special symbols PR, PC, PINF are never clause delimiters.3.
Sentence boundaries are always clause delimiters.4.
Another verb and the symbol PP are always clause delimiters,and are always excluded from the clause.5.
Negation particles ('ne', "n") are considered as (excluded)clause delimiters when expanding to the right of the verb of theclause.Rules 1 to 4 are rather immediate.
Rule 5 takes into account he factthat negation particles in French are always placed before the ne-gated verb.The basic clause selection rules (for choosing the innermostclause) are equally simple.
A clause is subordinate if its left boundis a relative or interrogative pronoun (or adjective), or a subordinaleconjunction, or if its verb is an infinitive.
A clause is said to be free(meaning that it is not qualified by other subordinate clauses whichshould be processed first) if its right bound is not one of these terms.The leftmost free and subordinate clause, or, if none, the leftmostfree clause will be chosen.Let us illustrate the effect of the above rules on example (1).
Thefigure (3) below shows the successive states of the input text.
Ineach state, the last fragmentation remit is indicated by underliningthe identified clauses.
The semantic l~'ocessing of the innermostclause selected at each step leads to the building of the correspond-ing part of the graph of figure (2).
(3) Le pont,que le convoi a passeoquand il a quitte INeW- York cematin~ etait fort long~Le pont,que le convoi a passelPCjetait fort long;iLe pont PR etait fort long iPPAs can be seen, a single fragmentation pass will often yieldimperfect results.
There will be holes (sentence fragments which arenot included in any clause, like ~Le pont" in the first two steps) andoverlappings (fragments which could be included in two clauses, like"New-York ce matin" in the first step).
This is where the repetitivenature of the fragmentation process comes into play.
Successive2Except auxiliaries that are part of a compound verbal form.aIf the lea clause bound is a relative pronoun preceeded by a preposi-tion.
the preposition will also be included in the clause.erasing of the innermost clauses from the input text, once they havebeen processed by the semantic module, will gradually cause theholes to disappear, and thus reveal the content of the main clause(s).Terms in overlapping areas will be automatically tried ftrst in theinnermost clause to which they could belong, in effect implementinga kind of deepest attachment preference.
What happens when thatftrst try is semantically inacceptable is discussed in the next section.Another interesting feature of the bottom-up algorithm is that thespecial symbol representing a processed subordinate clause will benaturally included, in later fragmentation steps, in the clause quali-fied by this subordinate, thus permitting to process correctly interclause dependencies.3.3 The ejection mechanism.A ftrst class of problems for which the above fragmentation algo-rithm is not sufficient concerns cases when the deepest attachmentpreference fails.
This problem occurs typically when a clause hasno explicit clause boundary on one side, as in the examples (4) and(5~, below:(4) rl'aime I'homme,~lue / presente a mon pere.~(I love the man whom I introduce to my father)(5) rle presente rhomrne, flue /'aline a mon pere.
I(I introduce the man wh'om 1 love to my father)In both eases the relative clause has no explicit fight boundary, andthe attachment problem concerns the group "a mon pete".
Thefragmentation result (shown by underlines) will in both cases in-elude this group in the relative clause, which is wrong for (5).
Insuch cases, the fragmentation will be automatically corrected, afterthe semantic processing of the relative clause, by a "right-ejection"mechanism:Right  ejection mechanismIf a group G on the right of the verb remains unconnectedafter the semantic processing of a clause, and if there is noother term on the right of G which has been connected to aterm on its left, then G and all terms on its right will be ex-cluded from the current clause.In the case of example (5), assuming reasonnably that no semanticdependency can be established between "aime" and "a mon pere",this last group will be ejected froin the relative clause, giving thesituation shown in (6):(6) iJe presente t homme que j'airae la mon pere.Since fragmentation is interleaved with the semantic processing, thenext fragmentation step will automatically pick up the discardedterm after the processing of the relative clause, and insert it at thecorrect level:(7) Je presente rhomrae PR a rnon pere,The same mechanism applies to overlapping cases, such as in ex-ample (8):.
,  , I (8) L'homrne ique I at rencontre sur la place rnla off err un care.
I(The man that I met in the square bought me a coffee)Here, two groups appear in the overlapping fragment.
The first one,"sur la place" ('on the squarer), can easily be connected to the rel-ative verb (as a location argument) and will remain in the relativeclause.
The second, "m" ("me") cannot be connected to "rencontre"('met"), the object slot of that verb being already fdled by the rela-tive pronoun "que".
~m" will thus be ejected from the relativeclause, and included correctly in the main clause during the nextfragmentation step.It is worth mentiorming that this mechanism involves no back-tracking and is extremely cheap in computational ressources.
Theonly processing required is the displacement of the right clauseboundary before erasing the text of the processed clause.2863.4.
Inf in i t ive clauses and  backtrack ing.Infinitive clauses without an explicit left boundary (such as a sub-ordinate conjunction) give rise to several interesting problems con-ceming both fragmentation itself and the selection of the innermostclause.
Consider the following examples:(9) ~J'irai 'ce soir a Parislvoir \[exposition'.
(I will go this evening to Paris to see the exposition)(I0) r/e n'ai \]amats" vu Jacquesjl travadler.
"(I never saw Jacques working)In both eases, there is an attachment problem for the terms in theoverlapping area.
In (9), all the terms in that area belong to therelative clause, while in (10) Jacques is the subject of the infinitiveclause.
One might want to define here a "left-ejection" mechanismsimilar to the one described in the last section; however it wouldalmost never work properly.
Indeed, if terms such as "this evening"or ~to Paris ~ are tried in the infinitive clause first, there would beno reason to reject them during the semantic processing of thatclause, and they will never be ejected.
Things work out better ifwe try first the terms in balance in the main clause.
This choice willbe wrong when one of these terms is in fact the subject of theinfinitive verb; but in that case, as we shall see, this term will conflictwith the infinitive verb for Idling the OBJECT slot of the main verb,and the system will have a reason to reject the wrong choice.
Ac-cordingly, we apply the following strategy:1, try first to place the terms of the overlapping area in the mainclause; in effect, this consists in preventing the infinitive clauseto extend to the let~ of its verb;2. if the choice made at point I fails, use a backtracking mech-anism that will restore the proper state of the analysis and tryto extend, one group at a time, the left bound of the infinitiveclause.With this strategy, (9) will be processed correctly at the frost ry.
(10)will lead to the following (erroneous) state of the analysis:(I1) iJe n'ai jamais vu Jacques PIN F. twhere "Jacques" and PINF compete for the object slot of the mainverb.
The term PINF will then be ejected by the mechanism of thelast section, giving the following state:(12) PP PINFThis is a dead end state, since the sentence is not reduced to a PPsymbol, and yet no further clause to process can be found.
Thebacktracking mechanism will then restore the state shown in (10)with the following fragmentation, which leads to a successfull anal-ysis:(13) t Je n'ai jamais vu tlacques travailler.jInfinitive clauses raise also problems concerning the selection of theinnermost clause.
Consider the following examples:(14) J" ai vu un homme, qui voulai~ (tormir sur le trottoir~(I saw a man who wanted to sleep on the street)(15) r\]" ai vu un hommet~qui avait bt~fdormir sur le trottoir.j(I saw a man who was drunk sleep on the street)In both cases, the selection rules will choose to process the infinitiveclause fu'st.
This choice is wrong for (15): if the relative relativeclause is not processed first, its presence will prevent he system tofred out that the group "un homme" is in fact the subject of theinfinitive clause.
Processing the infinitive fu'st, the system will reacha dead end after the following steps:(16) tl" ai vu un homme tqui avait bu PINF I (ejection of PINF)iJ'ai vu un homme PR PINFi(ejection of PINF)PP PINF (dead end)This problem is again handled by backtracking.
Let us note fu'st thatthe problem arises only when the subject of the infmitive verb isseparated from that verb by a relative clause.
In such a case, thesystem will try to process the infinitive ftrst, but will save the currentstate of the analysis o that it can later backtrack and process therelative first.
In the case of our example, backtracking to (15) fromthe dead end state in (16), and processing the relative clause first,we obtain a correct analysis, as shown in (17):(17) iJ'ai VUl Un homme PRidormir sur le trottoir.iJ'ai vu PINF I3.5 Coordinate conjunctionsFragmenting sentences with coordinate conjunctions requires tomake a decision regarding the scope of these conjunctions; specif-ically we need to distinguish between the conjunctions which coor-dinate clauses and the ones which coordinate groups inside a sameclause.
The following rules are used:Clause del imiter  rules fo r  coord inate  con junct ions1.
If the word to the right of the conjunction is a right de-limiter, or if next word in the current direction is thespecial symbol PP, the conjunction is taken as delimiter(excluded).2.
If the next clause delimiter in the current direction is anexplicit clause boundary or a sentence boundary, theconjunction is not taken as delimiter.3.
Otherwise choose to consider first the conjunction as adelimiter (excluded); this choice can be undone by back-tracking.Rule I is based on the fact that there must always be at least one?
conjunct o each side of a conjunction.
If a delimiter is found im-mediately to the right, then the conjunction must connect clauses.The same is true if the conjunction is adjacent to the PP symbol.The following example illustrates the use of this rule:(18) iJ'aime les ehien.~qui m'obeissent; etaui ne mordent pas r(I love the dogs which obey me and which do not bite)~'aime les chiens PR D et ~ui ne mordent pas!J'aime les chiens PR et PR;PPIf the next dellmitor is an explicit clause boundary, then there is noverb between the conjunction and this delimiter, and thus theconjuncts cannot be clauses.
This fact, captured by rule 2, can beillustrated by the following example:(19) ~ f q u e  les pommes et les poires etaient cheres.j(I learned that apples and pears were expensive)J" ai appris PCFinaly, if the next delimitor is a verb, the scope ambiguity cannotbe resolved at this stage.
The conjunction could be a clause delim-iter, as in (20), or not, as in (21):(20) Connors a vaincu Lendl et McEnroe a vaincu Connors.
(Connors defeated Lendl and McEnroe defeated Connors)287(21) Les hommes qui aiment les potatoes et les poires aiment aussiles oranges.
(People who like apples and pears like also oranges)In such cases, the system will choose to take the conjunction as adelimiter, and record the state of the analysis, so that the choice c,'mbe modified by backtracking.
The choice will be correct for sen-tence (20).
For sentence (2 l), the incorrect choice will lead to a deadend, as shown in (22), when the semantic module will try to coor-dinate ~hommes" and "poires" as agents of "aiment'.
Backtrackingto the choice point, followed by a new fragmentation, leads to thecorrect solution.
(22) Les hommes tqui aiment les pommesjet /es poires aiment att?siles oranges.iLes hommes PR et les poires aiment aussi les oranges;BACKTRACKINGLes horames ~lui aiment lies potatoes et les poiresj aiment aussiles oranges.
I?Les hommes PR aiment aussi les oranges.
IPP4.
Part of speech disambiguation4.1 General discussionMany lexically ambiguous words can have different parts of speech(hereafter POS).
The following table enumerates the main POSambiguities for example (1).Le (occurs twice): article or personal pronoun (the, him, it)que: subordinate conjunction, relative or interrogative pronoun,particle (that, which, what, than)quand: subordinate conjunction or adverb (when)feet: noun or adverb (castle, very).The ambiguity problem is further compounded by an accentuationproblem.
"Passe', third person of the present of the indicative ofthe verb "passer', is quite different in French from "passe", pastparticiple of the same verb?
Similarly, "a", indicative of avoir ("tohave'), has nothing to do with the preposition "a% llowever, for-getting an accent is one of the most common spelling mistakes.
Arobust system such as SABA must consider words such as "a","passe" and "quiRe" as ambiguous.
This would give at least 1024possible POS combinations for example (1)!Part of speech ambiguity is, of course, part of the more generalproblem of lexical ambiguity.
Thus, one could argue that it doesn'tneed an independent solution.
However, in the context of a frag-mentation system such as the one presented here, a POSdisambiguation preprocessor is necessary.
To give a simple example,the relative pronoun and subordinate conjunction senses of "que"are clause boundaries, while the (comparative or restrictive) particlesense is not.
Many other problems of semantic processing need aprior decision regarding the POS of the words involved.
Thus theFrench word "or ~ can be a noun ("gold'), and as such can fill a se-mantic role slot of some verb, or can be a coordinate conjunction("however'); qe" can be pronoun ( 'h im',  "it') and as such induce asearch for a pronoun reference, or can be a determiner ("the-).Many other examples could easily be found.Other works have already investigated the usefullness of a POS.disambiguation preprocessor, but for syntactic parsers.
(Klein andSimmons 63) presented very early a table based system for EnglishVerb mood ambiguities can usefully be considered at the same level asPOS ambiguities.where the emphasis was on the capability to classify "unknownwords', and thereby to reduce the size of the dictionnary.
Muchmore recently, (Merle 82) described a rule based POS disambiguatorfor French, its main objective being a gain of performance obtainedby the reduction of combinatorial explosion during syntatic parsing.Mede's rules, however, were rather unwieldy for two reasons:1. each rule must make a final decision regarding the POS of oneword; the designer must ensure himself the absence of contra-dictions between the rules.2.
The rules permitted only to test for fixed patterns in the input.In contrast o that, we have developped a method permitting theuse of cumulative rules and providing the possibility to test variablepatterns through the use of a search function.4.2.
The part of speech preprocessor for the SABAsystem.We have developped a part of speech disambiguation preprocessorfor French, which is used as the first stage of the SABA system.This preprocessor consists of heuristic rules which are applied toeach word in order to assign to every possible part of speech a cer-tainty factor.
The different combinations of possible parts ofspeechs are then tried in decreasing order of likeliness.The heuristic rules are based on the well known fact that it is notnecessary to scan the entire sentence to choose correctly the appro-priate part of speech for most words.
The local context" (i.e.
thefew surrounding words) proves often enough to provide an accurateindication.
Thus, if a word like "passe" is closely preceeded by anauxiliary, it is almost certainly a participe.
As another example,"fort", if closely preceeded by a determiner, is more likely to be anoun than an adverb.We have captured such insights into heuristic rules which assign toeach possible part of speech a certainty factor, according to the localcontext.
Two of these rules, relating to the examples justmentionned, are given in natural anguage form below:Rule 2If the current word can be a past participe and has otherpossible POS, then1.
If the current word is preceeded by a word that couldbe an auxiliary, and is only separated from that wordby words that could be adverbs, personal pronounsor particles, thenpast participle CF = 0.7; other possibles POSCF = 0.3;2.
Else:relative participe s CF = 0.7; other possible POSCF = 0.3.Rule 5If the current word can be a noun and has other possiblePOS, thenI.
If it is preceeded by a word that could be adeterminer, and is only separated from it by wordsthat could be adjectives or adverbs, thennoun CF = 0.9; other possible POS CF = 0.1;2. else:noun CF = 0.4; other possible POS CF = 0.6;We distinguish between a participe used in a complex verbal form anda participe clause, as in "1he man defeated by Connors was ill'.
In thelater case, the participe will receive a POS called PPAREL ('relativepartJcipe') because the participe clause is then processed exactly like arelative clause: in fact, when the POS PPAREL is assigned to aparticipe, a relative pronoun is inserted just before it.288These rules need several comments:I.
Each rule can be seen as a production rule with a condition andan action.
The condition is the clause starting with the first ~tf"of the rule; if it is not satisfied, this particular rule is not appliedto the current word.
The action is often itself a conditionnalstatement, each branch of which must include a certainty factorassigment s atement.2.
The certainty factors that we are using range from 0 (absoluteuncertainty) to 1 (absolute certainty).
They can be comparedto the belief actors used in the MYCIN system (Shortliffe 76).3.
The application of any rule must result in one assigrnent ofcertainty factors to all possible POS of the current word.llowever, a given word could possess other possible POS thanthose that need to be explicitly mentionned in a given rule.These are refered to by the formal expression "other possibleparts of speecht4.
The intermediate words tested by a rule can also have severalpossible parts of speech.
The expression ~ff such word couldbe of part of speech x" denotes a test bearing on all possibleparts of speech of that word.5.
We must be able to specify rules at varying levels of details.Sometimes, we will need to test if a word is a personal pro-noun; at another time, knowing that it is a pronoun of any kindis sufficient.
The system offers the possibility to specify a hier-archy of parts of speech, which is taken into account by therules.The part of speech disambignation preprocessor works in the fol-lowing way.
It processes successively all the words of the input.
Foreach word, it checks the conditions of all rules and fires all applica-ble rules.
If several rules are applied to a same word, certainty fac-tors are combined by the following formula:CF = I - ((I - CF I ) ' ( I  - CF2))where CFI and CF2 ate the certainty factors to be combined.
Vdhenthis is done, possible POS combinations are ordered by decreasingorder of likeliness.
Tile likeliness of a combination is simply definedas the product of the certainty factors of the parts of speech includedin that combination.Although each rule is considered for every word, the resultingprocess is very fast.
The ftrst reason for that is that there are very fewrules: 14 in the current implementation.
This is nothing comparedto the size of the rule base needed for a large grammar, and yet thesefew rules are sufficient to choose the correct POS at the ftrst try inmore than 80% of our test sentences.
The second reason is thateach rule is garded by a short, easy to check and very selectivecondition, so that most of the rules are immediately discarded for agiven word.4.3.
Implementation f the rules.The rules are implemented in a "semi-declarative" way: they can bespecified separately, each being described as a condition-action pair.However, both condition and action can be any evaluable LISPform.
in order to ease the task of rule specification, we have defmeda set of primitive operations.
The figure (23) gives the formalspecification of Rule 2.t lOMOGRAPH checks ff a word has more than one possible partsof speech.
POSSIBLE-STYPE checks ff the specified part ofspeech is one of the possible parts of speech of the word.DEFINE-PTYPELIST assigns to each part of speech of the worda specific certainty factor.
EXISTWORD, lastly, is a highly pa-rametered function performing searches in the input sentence.
Itsparameters are:1.
POSITION: the starting word for the search;2.
DIRECTION: the direction of the search (LEFT or RIGIIT);3.
LIMIT: the ending word, beyond which the search should bestopped;4.
GOAL-NAMES: admissible names for the target word5.
GOAL-TYPES: admissibles parts of speech for the targetword;6.
GOAL-CLASSES: admissible semantic lasses for the targetword;7.
BETWEEN-NAMES: admissible names for intermediatewolds8.
BETWEEN-TYPES: admissible parts of speech for intermedi-ate words;9.
BETWEEN-CLASSES: admissible semantic lasses for'inter-mediate words;10.
EXCLUDED-NAMES: excluded names for intermediatewords;11.
EXCLUDED-TYPES: excluded parts of speech for interme-diate words;12.
EXCLUDED-CLASSES: excluded semantic lasses for inter-mediate words.Parameters 3 through 12 are optional.
The default value for LIMITis the sentence boundary.
The default value for parameters 4through 9 is "(ALL)", denoting that all values are accepted.
Thedefault value for parameters 10 through 12 is NIL (no value is ex-cluded).5.
Results and conclusionsWe have presented two syntactic processes which offer useful andnecessary support for semantic processing, syntactic parser.
Bothare based on simple heuristic rules assisted by a backtrackingmechanism.
Both have been implemented in the SABA system andtested on a corpus of about 125 sentences.
Less than 5% of theserequired a backtracking of the fragmentation process.
Since we triedto characterize precisely the situations in which a backtracking couldarise, in most sentences there is not only no backtracking, but alsono bookkeeping of the intermediate steps.
(23)(ADD-SYNT-RULE R R2Condit ion(AND (POSSIBLE-STYPE WORD) 'PPA) (HOMOGRAPH WORD))Action(COND ((EXISI~/ORD posit ion (LEFT WORD)direct ion 'LEFTgoal-classes '(AUX)between-types '(PR ADV PT))(DEFINE-PTYPELIST WORD '((PPA .
.7)(OI~{ERS .
.3))))(T (DEFINE-PTYPELIST WORD '((PPAREL .
.7)(OTHERS .
.3))))))289As for the part of speech disambiguation preprocessor, the 14 rulesthat we implemented were sufficient o make the right choice inmore than 80% of the cases.
The very small size of this preprocessoris an important advantage if we think at the high human and com-putational costs involved in developing and using large size gram.mars .Although the specific rules that we implemented .were designed forFrench, we believe that the approach could be applied to otherlanguages as well.ACKNOWLEDGMENTSThanks are due to Professor D. Ribbens for his numerous helpfullcomments and for his active support.REFERENCES1.
Binot, J-L. 1984.
A Set-oriented semantic network formalismfor the representation f sentence meaning.
In Proc.
ECAI84,Pisa, September 1984.Binot, J-L. 1985.
SABA: vers un systeme portable d'analyse dufrancais ecrit.
Ph.D. dissertation, University of Liege, Belgium.Binot J-L. and Ribbens D. 1986.
Dual frames: a new tool forsemantic parsing.
In Proc.
AAAI86, Philadelphia, August 1986.Binot J-L, Gailly P-J.
and Ribbens D. 1986.
Elements d'uneinterface portable et robuste pour le francais ecrit.
In Proc.liuitiemes .lournees de glnformatique Francophone, Grenoble,January 1986.Boguraev B.K.
1979.
Automatic resolution of linguistic ambi-guities.
Ph.D. thesis, University of Cambridge, England, 1979.Jensen K., Heidom G.E., Richardson S. and ttaas N., PLNLP,PEG and CRITIQUE: three contributions to computing intheHumanities.
In Proc.
of the conf., on Computers and tiumani-ties, Toronto, April 1986.Klein S. and Simmons R.F.
A computational pproach togrammatical coding of English words.
Journal of the ACM.
10,March 1963.Lytinen S.L.
1986.
Dynamically combining syntax and seman-tics in natural language processing.
In Proc.
of AAAI86,Philadelphia, August 1986.Merle A.
1982.
Un analyseur presyntaxique pour la levee desambiguites darts des documents ecrits en langue naturelle: ap-plication a gindexation automatique".Ph.D, thesis, Institut Na-tional Polytechnique d  Grenoble.10.
Ristad E.. 1986.
Defining natural language grammars in GPSG.In Proc.
of the 24th meeting of the ACL, New-York, June 1986.I1.
Schank R.C., Leibowitz M. and Bimbaum L. 1980.
An inte-grated understander.
In Journal of the A CL, 6: I.12.
Shieber S. 1986.
An introduction to unification-bct?ed ap-proaches to grammar, University of Chicago Press.13.
Shortliffe E.H. 1976.
CorrqTuter-based medical consultation:M YCIN Elsevier.14.
Weir D.J., Vijay-Shanker K. and Joshi A.K.
1986.
"File re-lationship between Tree adjoining grammars and head gram-mars.
In Proc.
of the 24th meeting of the ACL, New-York, June1986.15.
Wilks Y.
1975.
An intelligent analyser and understander ofEnglish.
CACM 18:5, May 1975.2.3.4.5.6.7.8.9.290
