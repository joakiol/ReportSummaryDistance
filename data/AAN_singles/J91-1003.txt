met*: A Method for DiscriminatingMetonymy and Metaphor by ComputerDan Fass*Simon Fraser UniversityThe met* method istinguishes selected examples of metonymy from metaphor and from liter-alness and anomaly in short English sentences.
In the met* method, literalness is distinguishedbecause it satisfies contextual constraints that the nonliteral others all violate.
Metonymy isdiscriminated from metaphor and anomaly in a way that \[1\] supports Lakoff and Johnson's(1980) view that in metonymy one entity stands for another whereas in metaphor one en-tity is viewed as another, \[2\] permits chains of metonymies (Reddy 1979), and \[3\] allowsmetonymies toco-occur with instances of either literalness, metaphor, or anomaly.
Metaphor isdistinguished from anomaly because the former contains a relevant analogy, unlike the latter.The met* method is part of Collative Semantics, a semantics for natural language processing,and has been implemented in a computer program called meta5.
Some examples of meta5'sanalysis of metaphor and metonymy are given.
The met* method is compared with approachesfrom artificial intelligence, linguistics, philosophy, and psychology.1.
IntroductionMetaphor and metonymy are kinds of figurative language or tropes.
Other tropesinclude simile, irony, understatement (litotes), and overstatement (hyperbole).Example 1"My car drinks gasoline" (Wilks 1978, p. 199).Example 2"The ham sandwich is waiting for his check" (Lakoff and Johnson 1980, p. 35).Sentences (1) and (2) contain examples of metaphor and metonymy respectively.
Nei-ther sentence is literally true: cars do not literally drink nor do ham sandwiches literallywait.
Notice, though, that the two sentences are interpreted ifferently.
"My car" in(1) is commonly understood as resembling an animate drinker while in (2) "the hamsandwich" is generally interpreted as referring to the person who ordered the hamsandwich.Most of the considerable literature on metaphor and the smaller one on metonymy(see Van Noppen, De Knop and Jongen 1985; Shibles 1971) is from philosophy, lin-guistics, and psychology.
On the whole, the two phenomena remain vague, poorlydefined notions in that literature.
In artificial intelligence (AI), detailed treatments ofeither metaphor or metonymy are relatively scarce.
Moreover, most of those treatmentsare paper implementations that have not been coded up and run on a computer.
* Centre for Systems Science, Simon Fraser University, Burnaby, British Columbia, Canada V5A 1S6(~) 1991 Association for Computational LinguisticsComputational Linguistics Volume 17, Number 1The met* (pronounced "met star'0 method provides a means for recognizing se-lected examples of metonymy and metaphor, and also anomaly and literalness, inshort English sentences.
1 The method is part of Collative Semantics (hereafter CS),which is a semantics for natural language processing.
CS, and hence the met* method,has been implemented in a program called meta5 (so called because it does more thanmetaphor).
The meta5 program is, as far as I know, the first system to recognize xam-ples of metaphor and metonymy.
TO my knowledge, there is only one other workingprogram that might be said to recognize instances of metaphor (Martin 1988; 1990)and two systems that appear to recognize cases of metonymy, TEAM (Grosz et al1987) and TACITUS (Hobbs and Martin 1987).The rest of the paper is organized as follows.
Section 2 surveys general issuesand approaches in metaphor and metonymy, notably the distinctive characteristicsof metaphor and metonymy, the relationship between metaphor and metonymy, andthe relationship between literalness and nonliteralness.
Section 3 presents the met*method, concentrating on the basic topology of the met* method algorithm.
Section 4shows details of representations and processes used in CS.
Section 5 gives examplesof the meta5 program analyzing simple metaphors and metonymies.
Descriptions getprogressively more detailed from Section 2 through to Section 5.
Sections 6 and 7 de-scribe some extensions to metaphor interpretation in CS and compare the met* methodagainst other approaches to metaphor and metonymy, especially computational ones.A glossary of key terms is provided at the very end of the paper.2.
Survey of Metonymy and Metaphor ResearchMetonymy and metaphor are so poorly understood that widely divergent views existabout them and their relationship to each other.
This section reviews research onmetaphor (2.1), metonymy (2.2), the relationship between them (2.3), and the moregeneral relationship between literalness and nonliteralness (2.4).2.1 MetaphorFour views of metaphor are critically discussed: the comparison view, the interactiveview, the selection restriction violation view, and the conventional metaphor view.Computational examples of each kind are included by Gentner, Indurkhya, Hobbs,Wilks, and Martin.
Space does not permit discussion of other AI work on metaphorby, e.g., Russell (1976) and Weiner (1984; 1985).2.1.1 The Comparison View.
According to the comparison viewa metaphor isa comparison i  which one term (the tenor or subject of thecomparison) is asserted to bear a partial resemblance (the ground of thecomparison) to something else (the vehicle), the resemblance b ing insufficient tosustain a literal comparison.
As with any comparison, there is always omeresidual dissimilarity (the tension) between the terms involved in the comparison,but comparison theorists tend not to emphasize this dissimilarity (Tourangeauand Sternberg 1982, p. 205, their italics).What is crucial in the comparison approach, then, is finding the correct groundin a metaphor.
According to Tourangeau and Sternberg, Aristotle proposed the first1 The met* method takes its name from a remark made by Yorick Wilks.
He used met* to refercollectively tometonymy and metaphor: "*" is a match-anything symbol in the Unix operating system;hence, the token "met*" matches the two tokens "metonymy" and "metaphor.
"50Fass Discriminating Metonymycomparison theory and suggested several principles for finding the ground of a metaphor.Tourangeau and Sternberg reduce these principles to two basic ones: finding acategory to which the tenor and vehicle belong and constructing an analogy involvingthem.Gentner's (1983) Structure-Mapping Theory, which has been implemented in theStructure-Mapping Engine (Falkenhainer, Forbus and Gentner 1989), closely resemblesa comparison view of metaphor.
The theory addresses literal similarity, analogy, ab-straction, and anomaly, which Gentner refers to as four "kinds of comparison."
Analgorithm compares the semantic information from two concepts represented as setsof properties.
Properties are either "attributes," one-place predicates like LARGE(x),or "relations," two-place predicates such as COLLIDE(x,y).
The four kinds of compar-ison are distinguished by the relative proportions of attributes and relations that arematched, and the forms of mappings established between them.
Mappings betweenrelations are sought before those between attributes.
Pairs of relations are compared us-ing the "systematicity principle" that regular structural correspondences should existbetween terms occupying the same positions in those relations.
Mappings are purelystructural and independent of the content of the relations (i.e., the predicates).Tourangeau and Sternberg (1982) list some problems with the comparison view,including the following:(a) that everything has some feature or category that it shares with everythingelse, but we cannot combine just any two things in metaphor; (b) that the mostobvious hared features are often irrelevant to a reading of the metaphor; (c) thateven when the feature is relevant, it is often shared only metaphorically; ...and(e) that metaphors are novel and surprising is hard to reconcile with the ideathat they rely completely on extant similarities (ibid., pp.
226-227).Johnson (1980) also notes problem (a) with comparison theories, pointing out thatas a result they cannot account for the semantic tension between the two terms of ametaphor:the comparison theory ... tries to circumvent the experienced semantic strain byinterpreting metaphor as nothing but a way of comparing two things to see inwhat respects they are alike.
And since any two things are similar in somerespects, this kind of theory can never explain what is interesting and importantabout metaphor (ibid., p. 52).2.1.2 The Interaction View.
The interaction view focuses more upon the surprise andnovelty that metaphors create.
According to Tourangeau and Sternberg (1982, p. 212),proponents of the interaction view include Black (1962), Hesse (1966), Miles (1967),Richards (1936), and Wheelwright (1962).Interaction theorists argue that the vehicle of a metaphor is a template for seeingthe tenor in a new way.
This reorganization f the tenor is necessary, because thecharacteristics or features of the vehicle cannot be applied directly to the tenor;the features they 'share' are often only shared metaphorically.
As Black (1962)observes, the ground of a metaphor may itself be nonliteral.
'Men are wolves,' inBlack's example, in part because both are predators; but they are predators insharply different senses that may only strike us as similar when we interpret themetaphor.
In Black's reading of this metaphor, we see competition i socialrelations as corresponding topredacity in beasts (Tourangeau and Sternberg1982, pp.
212-213).51Computational Linguistics Volume 17, Number 1A problem with the interaction view is that theorists have not provided muchdetail about he processes involved, though Black (1962) does make some suggestions.According to Black, tenor and vehicle.., each have a 'system of commonplaces'associated with them.
These commonplaces are stereotypes, not necessarilydefinitional, not even necessarily true, just widely agreed upon.
In interpreting'man is a wolf,' we 'evoke the wolf-system of related commonplaces' and are ledby them 'to construct acorresponding system of implications about he principalsubject (Man)' (Black, 1962, p. 41).
In Black's view, then, interpretation i volvesnot so much comparing tenor and vehicle for existing similarities, as construingthem in a new way so as to create similarity between them (Tourangeau andSternberg 1982, p. 213).One might distinguish, then, two main differences between the interaction andcomparison views.
First, similarities are "created" in the interaction view (accountingfor the novelty and surprise in a metaphor) whereas only pre-existing similaritiesare found in the comparison view.
Second, a whole system of similarities are evokedbetween tenor and vehicle in the interactions view, whereas the comparisons view isbased upon finding a single similarity.One version of the interaction view is the domains-interaction view, set forth byTourangeau and Sternberg (1982), who take the view thatfeatures 'shared' by tenor and vehicle are often at best only analogous features,each limited in its application to one domain or another.
Of course, somefeatures or dimensions are quite general, applying across the board to a numberof domains (p. 218).Among comparison and interaction theorists, much attention had been paid toselecting the comparisons or interactions in a metaphor.
The importance of analogyor correspondence in metaphor has been stressed by Gentner (1983), Ortony (1979),Tourangeau and Sternberg (1982), and Wilks (1978), among others.
Various mecha-nisms have been advanced for highlighting certain comparisons or interactions, in-cluding relevance (e.g., Hobbs 1983b; Tversky 1977) and salience (Ortony et al 1985).Among computational approaches, Indurkhya's (1988) Constrained Semantic Trans-ference theory of metaphor can be viewed as a formalization of Black's interactiontheory (ibid., p. 129).
Source and target domains are viewed as "systems of relation-ships."
In metaphorical interpretation, an"implicative complex" of the source domainis imposed on the target domain, thereby shaping the features of the target domain,which in turn produces changes in the features of the source domain, hence the "in-teraction."
It is assumed that a structural analogy underlies every metaphor (ibid.,p.
129).A metaphor is identified with the formal notion of a T-MAP which is a pair / F,S /where F is a function that maps vocabulary of the source domain onto vocabularyof the target domain and S is a set of sentences from the source domain which areexpected to transfer to the target domain.
A metaphor is "coherent" if the transferredsentences S are logically consistent with the axioms of the target domain, and "stronglycoherent" if they already lie in the deductive closure of those axioms (cf.
Stallard 1987,p.
181).
S is thus the "implicative complex" of the source domain imposed on the targetdomain.
Every metaphorical interpretation f a given set of sentences i  associated witha T-MAP.
There may be several possible T-MAPs for a set of sentences.I would argue that Hobbs (1983a; 1983b) has also taken an interaction view ofmetaphor.
Hobbs' goal has been to develop a unified process of discourse interpre-tation based on the drawing of appropriate inferences from a large knowledge base,52Fass Discriminating Metonymywhich Hobbs sometimes calls "selective inferencing" (e.g., Hobbs 1980).
Selective in-ferencing is concerned with drawing or refraining from drawing certain inferences ina controlled fashion (cf.
Hobbs 1983a).
He argues that many problems have the sameor almost the same inferencing solutions.
These solutions are found via four separatesemantic operations that all draw inferences from text (e.g., Hobbs 1977).2.1.3 The Selection Restrictions Violations View.
The selection restriction violationview has also been called "the semantic deviance view" (Johnson 1980, p. 50) and "theanomaly view" (Tourangeau and Sternberg 1982, p. 211).
Johnson (1980) describes thisview as a common one among linguists; Tourangeau and Sternberg (1982) list thefollowing people as holders of this view: Beardsley (1962), Bickerton (1969), Campbell(1975), Guenther (1975), Percy (1954), Van Dijk (1975), and Wheelwright (1962).
To thislist one might add Levin (1977).
Johnson (1980, p. 50) describes this view as where:metaphor constitutes a violation of selection restriction rules within a givencontext, where the fact of this violation is supposed to explain the semantictension one experiences in comprehending any live metaphor.The theory of metaphor in Preference Semantics (Wilks 1975; 1978) consists of aselection restrictions view and a comparison view.
In the theory, information aboutword senses is contained in knowledge structures called "semantic formulas."
Analgorithm matches pairs of semantic formulas, seeking satisfied or violated preferencesbetween them.
A satisfied preference indicates a literal semantic relation; a violatedpreference indicates either a metaphorical or anomalous one.
This part of the theoryis implemented in a machine translation system (Wilks 1973).To distinguish metaphor from anomaly, a different knowledge structure and asecond algorithm are used.
The algorithm, called projection, operates on a knowl-edge structure, called a pseudo-text, that contains lists of templates (a further kind ofknowledge structure) linked by case ties.
A brief example of projection is given for (1).Example 3"My car drinks gasoline.
"Projection operates only on preference violations.
The best representation f (1) con-tains a preference violation, so projection is used.
The algorithm compares the templaterepresentation for the sentence\[my+car drink gasoline\]against emplates from the pseudo-text of 'car' seeking "the closest match," and selects\[ICengine (USE)#1iquid\].
(USE) is projected onto drink in the sentence representationwhich becomes\[my+car use gasoline\]Example 3"The rock is becoming brittle with age" (Reddy 1969, p. 242).53Computational Linguistics Volume 17, Number 1Example 4"Idi Amin is an animal" (Johnson 1980, p. 51).Example 5"People are not cattle" (Hobbs 1983b, p. 134).Example 6"No man is an Island" (John Donne, Meditations XVI I ) .The main problem with the selection restrictions view is that perfectly well-formedsentences exist that have a metaphorical interpretation and yet contain no selectionrestriction violations (Johnson 1980; Ortony 1980; Reddy 1969); for example, in (3),there is a literal interpretation when uttered about a stone and a metaphorical onewhen said about a decrepit professor emeritus.
Sentences (4), (5) and (6) also havetwin interpretations.The existence of such sentences suggests that a condition that occasionally holds(i.e., a selection restriction violation) has been elevated into a necessary conditionof metaphor (Johnson 1980).
Moreover, viewing metaphor only in terms of selectionrestriction violations ignores the influence of context:We seem to interpret an utterance metaphorically when to do so makes sense ofmore aspects of the total context than if the sentence is read literally.
Considerthe simple case of the sentence All men are animals as uttered by Professor X to anintroductory biology class and as uttered later by one of his female students toher roommate upon returning from a date.
In the latter instance the roommateunderstands the utterance as metaphorical (ibid., p. 51).In a similar way, Ortony (1980) suggests that metaphor should be thought of ascontextually anomalous.
This means that a literal interpretation f the expression,be it a word, phrase, sentence, or an even larger unit of text, fails to fit thecontext (p. 73, his italics),so whether or not a sentence is a metaphor depends upon the context in which itis used:if something is a metaphor then it will be contextually anomalous if interpretedliterally .... Insofar as the violation of selection restrictions can be interpreted interms of semantic incompatibilities at the lexical evel, such violations maysometimes be the basis of the contextual nomaly (ibid., p. 74).2.1.4 The Conventional Metaphor View.
Lakoff and Johnson (1980) have popular-ized the idea of conventional metaphors, also known as conceptual metaphors.
Theydistinguish three main kinds: orientational, ontological, and structural.
Orientationalmetaphors are mainly to do with kinds of spatial orientation like up-down, in-out,and deep-shallow.
Example metaphors include MORE IS UP and HAPPY IS UP.
Theyarise from human experience of spatial orientation and thus develop from the sort ofbodies we have and the way they function in our physical environment.Ontological metaphors arise from our basic human experiences with substancesand physical objects (especially our own bodies).
Some examples are TIME IS A SUB-STANCE, THE MIND IS AN ENTITY, and THE VISUAL FIELD IS A CONTAINER.54Fass Discriminating MetonymyStructural metaphors are elaborated orientational and ontological metaphors (cf.Lakoff and Johnson 1980) in which concepts that correspond to natural kinds of ex-perience, e.g., PHYSICAL ORIENTATIONS, SUBSTANCES, WAR, JOURNEYS, andBUILDINGS, are used to define other concepts, also natural kinds of experience,e.g., LOVE, TIME, IDEAS, UNDERSTANDING, and ARGUMENTS.
Some examplesof structural metaphors are ARGUMENT IS WAR and TIME IS MONEY.The ARGUMENT IS WAR metaphor forms a systematic way of talking about hebattling aspects of arguing .... Because the metaphorical concept is systematic,the language we use to talk about he concept is systematic (ibid., p. 5).What Lakoff and Johnson fail to discuss is how metaphors in general, let alneindividual metaphorical concepts, are recognized.
Martin's (1988; 1990) work has ad-dressed this issue.
He has pursued a conventional metaphor view using KODIAK(Wilensky 1984), a variant of Brachman's KLONE knowledge representation language.Within KODIAK, metaphorical relationships are represented using a primitive linktype called a "VIEW."
A VIEW "is used to assert that.., one concept may in cer-tain circumstances be considered as another " (Martin 1990, p. 59).
In Martin's work,"metaphor-maps," a kind of VIEW (ibid., p. 64), are used to represent conventionalmetaphors and the conceptual information they contain.2.2 MetonymyMetonymy involves "using one entity to refer to another that is related to it" (Lakoffand Johnson 1980, p. 35).Example 2"The ham sandwich is waiting for his check.
"For example, in (2) the metonymy is that the concept for ham sandwich is relatedto an aspect of another concept, for "the person who ordered the ham sandwich.
"Several attempts have been made to organize instances of metonymy into cat-egories (e.g., Lakoff and Johnson 1980; Stern 1931; Yamanashi 1987) or "metonymicconcepts," as Lakoff and Johnson call them.
A common metonymic oncept is PARTFOR WHOLE, otherwise known as synechdoche.Example 7"Dave drank the glasses" (= the liquid in the glasses).Example 8"The kettle is boiling" (= the liquid in the kettle) (Waldron 1967, p. 186; Yamanashi1987, p. 78).CONTAINER FOR CONTENTS, another metonymic concept, occurs in (7) between'drink' and the sense of 'glasses' meaning "containers," and also in (8).
In (7), 'drink'has an object preference for a potable liquid, but there is a preference violation becauseglasses are not potable liquids.
It is not glasses that are drunk, but the potable liquidsin them.
There is a relationship here between a CONTAINER (a glass) and its typicalCONTENTS (a liquid): this relationship is the metonymic oncept CONTAINER FOR55Computational Linguistics Volume 17, Number 1CONTENTS.
Below are examples of two further metonymic oncepts (from Lakoffand Johnson 1980, p. 38, italics in original).PRODUCER FOR PRODUCT"I'll have a L6wenbrau.
""He bought a Ford.
""He's got a Picasso in his den.
""I hate to read Heidegger.
"OBJECT USED FOR USER"The sax has the flu today.
""The BLT is a lousy tipper.
"*.2"The buses are on strike.
"Example 9"You'll find better ideas than that in the library" (Reddy 1979, p. 309).Reddy (1979) has observed that metonymies can occur in chains.
He suggests that(9) contains a chain of PART FOR WHOLE metonymies between 'ideas' and 'library':the ideas are expressed in words, words are printed on pages, pages are in books, andbooks are found in a library.Example 10"I found an old car on the road.
The steering wheel was broken" (Yamanashi 1987, p. 79).Example 11"We had a party in a mysterious room.
The walls were painted in psychedelic olor"(ibid.
).Example 12A: "I bought an interesting book."
B: "Who is the author?"
(ibid.
).Example 13"He happened to die of some disease, though I don't know what the cause was" (ibid.
).Yamanashi (1987) points out that basic metonymic relationships like part-wholeand cause-result often also link sentences.
According to him, the links in (10) and (11)are PART-WHOLE relations, the one in (12) is PRODUCT-PRODUCER, and the onein (13) is a CAUSE-RESULT relation.There has been some computational work on metonymy (Weischedel and Sond-heimer 1983; Grosz et al 1987; Hobbs and Martin 1987; Stallard 1987; Wilensky 1987).The TEAM project (Grosz et al 1987) handles metonymy, though metonymy is notmentioned by name but referred to instead as "coercion," which "occurs wheneversome property of an object is used to refer indirectly to the object" (ibid., p. 213).Coercion is handled by "coercion-relations;" for example, a coercion relation could beused to understand that 'Fords' means "cars whose CAR-MANUFACTURER is Ford"(in Lakoff and Johnson's terms, this is an example of a PRODUCER FOR PRODUCTmetonymic oncept).2 A BLT is a bacon, lettuce, and tomato sandwich.56Fass Discriminating MetonymyGrosz et al (1987) note a similarity between coercion (i.e., metonymy) and modifi-cation in noun-noun compounds, and use "modification relations" to decide whether,e.g., "U.S. ships" means "ships of U.S. registry" or "ships whose destination is the U.S."Hobbs and Martin (1987) and Stallard (1987) also discuss the relationship betweenmetonymy and nominal compounds.
Hobbs and Martin treat the two phenomenaas twin problems of reference resolution in their TACITUS system.
They argue thatresolving reference requires finding a knowledge base entity for an entity mentioned indiscourse (i.e., what that entity refers to), and suggest that the resolution of metonymyand nominal compounds both require discovering an implicit relation between twoentities referred to in discourse.
The example of metonymy they show is "after thealarm," which really means after the sounding of the alarm.Hobbs and Martin seem to assume a selection restrictions approach to metonymybecause metonymy is sought after a selection restrictions violation (ibid., p. 521).
Intheir approach, solving metonymy involves finding: \[1\] the referents for 'after' and'alarm' in the domain model, which are after(eo, a) and alarm(a); \[2\] an implicit entityz to which 'after' really refers, which is afier(eo, z); and \[3\] the implicit relation betweenthe implicit entity z and the referent of 'alarm,' q(z, a).Like Hobbs and Martin (1987), Stallard (1987) translates language into logical form.Stallard argues that with nominal compounds and metonymies "the problem is deter-mining the binary relation which has been 'elided' from the utterance" (ibid., p. 180)and suggests hifting the argument place of a predicate "by interposing an arbitrary,sortally compatible relation between an argument place of the predicate and the ac-tual argument" (ibid., p. 182).
Stallard notes that "in any usage of the metonomy (sic)operation there is a choice about which of two clashing elements to extend" (ibid.
).Stallard's work has not yet been implemented (ibid., p. 184).Stallard (1987) also briefly discusses anaphora resolution.
Brown (1990) is be-ginning research on metonymy and reference resolution, particularly pronouns.
Thisshould prove a promising line of investigation because metonymy and anaphora sharethe function of allowing one entity to refer to another entity.Example 2"The ham sandwich is waiting for his check" (= the male person who ordered theham sandwich).Example 14"He is waiting for his check" (= the male person).This similarity of function can be seen in comparing (2), which is metonymic, with(14), which is anaphoric.2.3 Relationship between Metonymy and MetaphorBoth metonymy and metaphor have been identified as central to the developmentof new word senses, and hence to language change (see, e.g., Stern 1931; Waldron1967).
Some of the best examples of the differences between the two phenomena comefrom data used in studies of metonymic and metaphorical effects on language change.Nevertheless, there are widely differing views on which phenomenon is the moreimportant.
Some argue that metaphor is a kind of metonymy, and others propose thatmetonymy is a kind of metaphor, while still others suggest that they are quite different(see Fass 1988c).57Computational Linguistics Volume 17, Number 1Among the third group, two differences between metonymy and metaphor arecommonly mentioned.
One difference is that metonymy is founded on contiguitywhereas metaphor is based on similarity (cf.
Jakobsen and Halle 1956; Ullmann 1962).Contiguity and similarity are two kinds of association.
Contiguity refers to a stateof being connected or touching whereas imilarity refers to a state of being alike inessentials or having characteristics in common (Mish 1986).A second difference, advanced by Lakoff and Johnson (1980) for example, is thatmetaphor is "principally a way of conceiving of one thing in terms of another, andits primary function is understanding" (ibid., pp.
36-37) whereas metonymy "hasprimarily a referential function, that is, it allows us to use one entity to stand foranother" (ibid., their italics), though it has a role in understanding because it focuseson certain aspects of what is being referred to.There is little computational work about the relationship between metonymy andmetaphor.
Stallard (1987) distinguishes separate roles for metonymy and metaphor inword sense extension.
According to him, metonymy shifts the argument place of apredicate, whereas metaphor shifts the whole predicate.
Hobbs (1983a; 1983b) writesabout metaphor, and he and Martin (1987) develop a theory of "local pragmatics" thatincludes metonymy, but Hobbs does not seem to have written about the relationshipbetween metaphor and metonymy.In knowledge representation, metonymic and metaphorical relations are both rep-resented in the knowledge representation language CycL (Lenat and Guha 1990).2.4 Literalness and NonliteralnessMuch of the preceding material assumes what Gibbs (1984) calls the "literal meaningshypothesis," which is thatsentences have well defined literal meanings and that computation of the literalmeaning is a necessary step on the path to understanding speakers' utterances(ibid., p. 275).There are a number of points here, which Gibbs expands upon in his paper.
Onepoint concerns the traditional notion of literal meaning, that all sentences have literalmeanings that are entirely determined by the meanings of their component words,and that the literal meaning of a sentence is its meaning independent of context.A second point concerns the traditional view of metaphor interpretation, thoughGibbs' criticism applies to metonymy interpretation also.
Using Searle's (1979) viewson metaphor as an example, he characterizes the typical model for detecting nonliteralmeaning as a three-stage process: \[1\] compute the literal meaning of a sentence, \[2\]decide if the literal meaning is defective, and if so, \[3\] seek an alternative meaning,i.e., a metaphorical one (though, presumably, a metonymic interpretation might alsobe sought at this stage).
Gibbs (1984, p. 275) concludes that the distinction betweenliteral and metaphoric meanings has "little psychological validity.
"Among AI researchers, Martin (1990) shares many of Gibbs's views in criticizingthe "literal meaning first approach" (ibid., p. 24).
Martin suggests a two-stage processfor interpreting sentences containing metaphors: \[1\] parse the sentence to producea syntactic parse tree plus primal (semantic) representation, and \[2\] apply inferenceprocesses of "concretion" and "metaphoric viewing" to produce the most detailedsemantic representation possible.The primal representation represents a level of semantic interpretation that isexplicitly in need of further processing.
Although it is obviously related to what58Fass Discriminating Metonymyhas traditionally been called a literal meaning, it should not be thought of as ameaning at all.
The primal representation should be simply considered as anintermediate stage in the interpretation process where only syntactic and lexicalinformation has been utilized (ibid., p. 90, his italics).However, Martin believes that at least some sentence meaning is independent ofcontext because the primal representation contains part of the primal content of anutterance and\[t\]he Primal Content represents he meaning of an utterance that is derivablefrom knowledge of the conventions ofa language, independent of context (ibid.
).2.5 Review SummaryThe metaphor literature contains many differing views, including the comparison,interaction, selection restrictions, and conventional metaphors views.
AI research onmetaphor includes all of these views.
Of the AI research, only Martin's work hasbeen implemented tomy knowledge.
Among the points raised are that metaphoricalsentences exist that do not contain selection restriction violations and that metaphorrequires interpretation i  context.
The much smaller metonymy literature stresses theselection restrictions view too.
The TEAM and TACITUS systems both seem to processmetonymics.The two main differences commonly noted between metonymy and metaphorare in their function (referential for metonymy and understanding with metaphor)and the kind of relationship established (contiguity in metonymy versus similarityin metaphor).
No one to my knowledge has a working system that discriminatesexamples of metaphor and metonymy.3.
met* MethodIn this section, the basic met* algorithm is outlined.
The met* method is based on theselection restriction, also known as the preference.
Metonymy, metaphor, literalness,and anomaly are recognized by evaluating preferences, which produces four kinds ofbasic "preference-based" relationship or semantic relation: literal, metonymic, metaphor-ical, and anomalous.
Within the method, the main difference between metonymy andmetaphor is that a metonymy is viewed as consisting of one or more semantic re-lationships like CONTAINER FOR CONTENTS and PART FOR WHOLE, whereas ametaphor is viewed as containing a relevant analogy.I agree with Ortony's remark that metaphor be viewed as contextual nomaly, butwould suggest wo modifications.
First, not just metaphor but all of the preference-based relations hould be understood in terms of the presence or absence of contextualconstraint violation.
Second, I prefer the term contextual constraint violation because\[1\] one of the phenomena detected by contextual violation is anomaly and \[2\] theselection restriction/preference (on which the met* method is based) is a kind oflexical contextual constraint.
The section starts with an explanation of some of thelinguistic background behind the met* method.3.1 Linguistic BackgroundI have argued elsewhere (Fass 1989a) that understanding atural language (or seman-tic interpretation) beviewed as the integration of constraints from language and fromcontext.
Some language constraints are syntactic, while others are semantic.
Some59Computational Linguistics Volume 17, Number 1language constraints are lexical constraints; that is, constraints possessed by lexicalitems (words and fixed phrases).
Lexical syntactic onstraints include those on wordorder, number, and tense.
This section describes three lexical semantic onstraints: pref-erences, assertions, and a lexical notion of relevance.Preferences (Wilks 1973), selection restrictions (Katz 1964), and expectations(Schank 1975) are the same (see Fass 1989c; Fass and Wilks 1983; Wilks and Fass inpress): all are restrictions possessed by senses of lexical items of certain parts of speechabout he semantic lasses of lexical items with which they co-occur.
Thus an adjectivesense has a preference for the semantic lass of nouns with which it co-occurs and averb sense has preferences for the semantic lasses of nouns that fill its case roles.
Forexample, the main sense of the verb 'drink' prefers an animal to fill its agent case role,i.e., it is animals that drink.The assertion of semantic information was noted by Lees (1960) in the formationof noun phrases and later developed by Katz (1964) as the process of "attribution.
"Assertions contain information that is possessed by senses of lexical items of certainparts of speech and that is imposed onto senses of lexical items of other parts of speech,e.g., the adjective 'female' contains information that any noun to which it applies isof the female sex.Lexical syntactic and semantic onstraints are enforced at certain places in sen-tences which !
call dependencies.
Within a dependency, the lexical item whose con-straints are enforced is called the source and the other lexical item is called the target(after Martin 1985).
Syntactic dependencies consist of pairs of lexical items of certainparts of speech in which the source, an item from one part of speech, applies one ormore syntactic onstraints o the target, another lexical item.
Examples of source-targetpairs include a determiner and a noun, an adjective and a noun, a noun and a verb,and an adverb and a verb.Example 15"The ship ploughed the waves.
"Semantic dependencies occur in the same places as syntactic dependencies.
The(metaphorical) sentence (15) contains four semantic dependencies: between the deter-miner 'the' and the noun 'ship,' between 'ship' and the verb stern 'plough,' between'the' and the noun 'waves,' and between 'waves' and 'plough.'
In each semantic de-pendency, one lexical item acts as the source and applies constraints upon the otherlexical item, which acts as the target.
In (15), 'the" and 'plough' both apply constraintsupon 'ship,' and 'the' and 'plough' apply constraints on 'waves.'
Semantic dependen-cies exist between ot just pairs of lexical items but also pairs of senses of lexical items.For example, the metaphorical reading of (15) is because 'waves' is understood asbeing the sense meaning "movement of water," not for example the sense meaning"movement of the hand.
"Semantic relations result from evaluating lexical semantic onstraints in sentences.Every semantic relation has a source (a lexical item whose semantic onstraints areapplied) and a target (a lexical item which receives those constraints).
Other termsused to refer to the source and target in a semantic relation include: vehicle and tenor(Richards 1936), subsidiary subject and principal subject (Black 1962), figurative termand literal term (Perrine 1971), referent and subject (Tversky 1977), secondary subjectand primary subject (Black 1979), source and destination (Winston 1980), old domainand new domain (Hobbs 1983a), and base and target (Gentner 1983).In CS, seven kinds of semantic relation are distinguished: literal, metonymic,metaphorical, anomalous, redundant, inconsistent, and novel relations (this list may60Fass Discriminating Metonymynot be exhaustive - -  there could be others).
Combinations of these seven semanticrelations are the basis of (at minimum) literalness, metonymy, metaphor, anomal)~ re-dundancy, contradiction, contrariness, and novelty.
Semantic relations belong to twoclasses, the preference-based and assertion-based classes of relations, depending on thekind of lexical semantic onstraint enforced.
The preference-based class of semanticrelations, which are the focus of this paper, contains literal, metonymic, metaphorical,and anomalous semantic relations.
The assertion-based class of relations are describedin greater length in Fass (1989a).Figure 1 shows the met* method laid out as a flow chart and illustrates how thepreference-based class of semantic relations is discriminated.
A satisfied preference(diamond 1) distinguishes literal relations from the remaining three relations, whichare all nonliteral.Example 16"The man drank beer.
"There is a literal relation between 'man' and 'drink' in (16) because 'drink' prefers ananimal as its agent and a man is a type of animal so the preference is satisfied.Example 7"Dave drank the glasses" (= potable liquid in the glasses --* CONTAINER FOR CON-TENTS).Example 17"Denise drank the bottle" (= potable liquid from the bottle -~ CONTAINER FOR CON-TENTS).\Figure 1The met* method61Computational Linguistics Volume 17, Number 1Example 18"Anne reads Steinbeck" (= writings of Steinbeck --, ARTIST FOR ART FORM).Example 19"Ted played Bach" (= music of Bach ~ ARTIST FOR ART FORM).Metonymy is viewed as a kind of domain-dependent inference.
The process offinding metonymies is called metonymic inferencing.
The metonymic concepts presentlyused are adapted from the metonymic concepts of Lakoff and Johnson (1980).
Two ofthe metonymic concepts used are CONTAINER FOR CONTENTS and ARTIST FORART FORM.
In (19), for example, Ted does not literally play the composer Bach - -  heplays music composed by him.As Figure 1 shows, a metonymy is recognized in the met* method if a metonymicinference (diamond 2) is found.
Conversely, if no successful inference is found then nometonymy is discovered and a metaphorical or anomalous semantic relation is thensought.
A successful inference stablishes a relationship between the original sourceor the target ("one entity'9 and a term ("another that is related to it'3 that refers toone of them.Like Stallard (1987), who noted that "in any usage of the metonomy (sic) operationthere is a choice about which of two clashing elements to extend" (ibid., p. 182), themet* method allows for metonymies that develop in different "directions."
A successfulinference is sometimes directed "forward" from the preference or "backward" fromthe target, depending on the metonyrnic oncept (more on this shortly).
It is thisdirection of inferencing that determines whether the source or target is substitutedin a successful metonymy.
The substitute source or target is used to discover anothersemantic relation that can be literal, metonymic again, metaphorical, or anomalous.In Figure 1, the presence of a relevant analogy (diamond 3) discriminates metaphor-ical relations from anomalous ones.
No one else (to my knowledge) has emphasizedthe role of relevance in the discovery of an analogy central to a metaphor though, asnoted in Section 2.2, the importance of relevance in recognizing metaphors and thecentrality of some analogy have both been discussed.Example 20"The car drank gasoline" (adapted from Wilks 1978).The form of relevance used is a lexical notion - -  i.e., the third kind of lexical semanticconstraint - -  that what is relevant in a sentence is given by the sense of the mainsentence verb being currently analyzed.
Thus, it is claimed that the semantic relationbetween 'car' and 'drink' in (20) is metaphorical because there is a preference violationand an underlying relevant analogy between 'car' and 'animal,' the preferred agent of'drink.'
A car is not a type of animal, hence the preference violation.
However, what isrelevant in (20) is drinking, and there is a relevant analogy that animals and cars bothuse up a liquid of some kind: animals drink potable liquids while cars use gasoline.Hence the metaphorical relation between 'car' and 'drink.
'Metaphor ecognition i  the met* method is related to all four views of metaphordescribed in Section 2.
Recognition is viewed as a two-part process consisting of \[1\]a contextual constraint violation and \[2\] a set of "correspondences" including a keycorrespondence, a relevant analogy.
The contextual constraint violation may be a pref-erence violation, as in the selection restrictions view of metaphor.
The set of "corre-spondences" is rather like the system of commonplaces between tenor and vehicle inthe interaction view.
The relevant analogy is related to the comparison and interaction62Fass Discriminating Metonymyviews, which emphasize a special comparison or an analogy as central to metaphor.Moreover, the relevant analogies eem to form groupings not unlike the conceptualmetaphors found in the conventional view.Example 21"The idea drank the heart.
"Anomalous relations have neither the semantic relationships of a metonymic rela-tion nor the relevant analogy of a metaphorical relation.
Hence the semantic relationbetween 'idea' and 'drink' is anomalous in (21) because 'idea' is not a preferred agentof 'drink' and no metonymic link or relevant analogy can be found between animals(the preferred agent) and ideas; that is, 'idea' in (21) does not use up a liquid like 'car'does in (20).
This is not to say that an anomalous relation is uninterpretable or thatno analogy can possibly be found in one.
In special circumstances (for example, in apoem), search for analogies might be expanded to permit weaker analogies, therebyallowing "ideas drinking" to be interpreted metaphorically.The topology of the flow chart in Figure 1 results from needing to satisfy a numberof observations about the preference-based phenomena, particularly metonymy:1. literalness is distinct from the others, which are all nonliteral;2. metonymies can occur in chains (Reddy 1979);3. metonymy always seems to occur with one of the other three; and4.
metaphor and anomaly are the hardest o tell apart (and thus require themost extended processing to distinguish).Hence a preference-based semantic relation can be either a single relation or amulti-relation.
A single relation consists of one literal, metaphorical, or anomalous re-lation.
A multi-relation contains one literal, metaphorical, or anomalous relation pluseither a single metonymy or a chain of metonymies.
All these combinations, but onlythese, are derivable from Figure 1.Note that in the met* method as presented in Figure 1, semantic relations aretried in a certain order: literal, metonymic, metaphorical, and finally anomalous.
Thisordering implies that a literal interpretation is sought before a nonliteral one (cf.
Harris1976).
The ordering results from thinking about discriminating the semantic relationsin serial processing terms rather than parallel processing terms, particularly the serialorder in which selection restrictions are evaluated and metonymic inference rules aretried: satisfied selection restrictions (indicating literalness) then metonymic inference(metonymy) then violated selection restrictions (metaphor or anomaly).Gibbs (1984) criticizes the idea that literal and nonliteral meaning can be discrimi-nated in ordered processing stages.
My response is that if the met* method is viewed inparallel processing terms then literal, metonymic, metaphorical, and anomalous inter-pretations are all sought at the same time and there is no ordering such that the literalmeaning of a sentence is computed first and then an alternative meaning sought ifthe literal meaning is defective.
Gibbs' other main criticism, concerning the traditionalanalysis of sentence meaning as composed from word meanings and independent ofcontext, will be discussed in Section 7.63Computational Linguistics Volume 17, Number 14.
CoUative SemanticsCS is a semantics for natural anguage processing that extends many of the mainideas behind Preference Semantics (Wilks 1973; 1975a; 1975b; 1978; see also Wilks andFass in press).
CS has four components: ense-frames, collation, semantic vectors, andscreening.
The met* method is part of the process of collation.
Fuller and more generaldescriptions of the four components appear in Fass (1988a; 1989b).Sense-frames are dictionary entries for individual word senses.
Sense-frames arecomposed of other word senses that have their own sense-frames, much like Quillian's(1967) planes.
Each sense-frame consists of two parts, an arcs section and a node section,that correspond to the genus and differentia commonly found in dictionary definitions(Amsler 1980).The arcs part of a sense-frame contains a labeled arc to its genus term (a wordsense with its own sense-flame).
Together, the arcs of all the sense-frames comprise adensely structured semantic network of word senses called the sense-network.
The nodepart of a sense-frame contains the differentia of the word sense defined by that sense-frame, i.e., information distinguishing that word sense from other word senses haringthe same genus.
The two lexical semantic onstraints mentioned earlier, preferencesand assertions, play a prominent part in sense-frame nodes.Sense-frame nodes for nouns (node-type 0) resemble Wilks' (1978) pseudo-texts.The nodes contain lists of two-element and three-element lists called cells.
Cells containword senses and have a syntax modeled on English.
Each cell expresses a piece offunctional or structural information and can be thought of as a complex semanticfeature or property of a noun.
Figure 2 shows sense-frames for two senses of the noun'crook.'
Crook1 is the sense meaning "thief" and crook2 is the shepherd's tool.All the terms in sense-frames are word senses with their own sense-frames orwords used in a particular sense that could be replaced by word senses.
It1 refersto the word sense being defined by the sense-frame so, for example, crook1 can besubstituted for it1 in \[it1, steal1, valuables1\].
Common dictionary practice is followedin that word senses are listed separately for each part of speech and numbered byfrequency of occurrence.
Hence in crook2, the cell \[shepherd1, use1, it1\] contains thenoun sense shepherd1 while the cell \[it1, shepherd1, sheep1\] contains the verb senseshepherd1 (in a three-element cell, the second position is always a verb, and the firstand third positions are always nouns).Sense-frame nodes for adjectives, adverbs and other modifiers (node-type 1) con-tain preferences and assertions but space does not permit a description of them here.Sense-frame nodes for verbs and prepositions (node-type 2) are case frames con-taining case subparts filled by case roles such as 'agent,' 'object,' and 'instrument.
'Case subparts contain preferences, and assertions if the verb describes a state change.sf(crookl, sf(crook2,\[\[arcs, \[\[arcs,\[\[supertype.
criminal1\]\]\], \[\[supertype, stick1\]\]\],\[nodeO, \[nodaO,\[\[it1, steal1, valuables1\]\]\]\]).
\[\[shepherd1, use1, it1\],\[it1, shepherd1, sheep1\]\]\]\]).Figure 2Sense-frames for crook1 and crook2 (noun senses)64Fass Discriminating Metonymysf(eatl, sf(clrinkl,\[(arcs, \[\[arcs,\[\[supertype, (ingest1, expenclt\]\]\]\], \[\[supertype, (ingest1, expendt\]\]\]\],(node2, \[node;t,\[\[agent, \[\[agent,\[preference, animalt\]\], \[preference, animal1\]\],\[object, \[object,\[preference, foocll\]\]\]} D. \[preference, drink1\]\]\]\]\]).Figure 3Sense-frames for eat1 and drink1 (verb senses)Figure 4The met* method (CS version)Figure 3 shows the sense-frames for the verb senses eat1 and drink1.
In both, the agentpreference is for an animal but the object preferences differ: the preference of eat1 isfor food1, i.e., an edible solid, while the preference of drink1 is for drink1 (the nounsense), i.e., a potable liquid.The second component of CS is the process of collation.
It is collation that con-tains the met* method in CS.
Collation matches the sense-frames of two word sensesand finds a system of multiple mappings between those sense-frames, thereby dis-criminating the semantic relations between the word senses.
Figure 4 shows the useof the met* method in CS.
Figure 4 is similar to the one in Figure 1 except hat thediamonds contain the processes used in CS to check for satisfied preferences (diamond1), metonymic inferences (diamond 2), and relevant analogies (diamond 3).The basic mappings in collation are paths found by a graph search algorithmthat operates over the sense-network.
Five types of network path are distinguished.Two types of path, called ancestor and same, denote kinds of "inclusion," e.g., that theclass of vehicles includes the class of cars (this is an ancestor relationship).
Satisfied65Computational Linguistics Volume 17, Number 1preferences are indicated by network paths denoting inclusion, also known as "inclu-sive" paths (see diamond 1 in Figure 4).
The other three types of network path, calledsister, descendant, and estranged, enote "exclusion," e.g., that the class of cars does notinclude the class of vehicles (this is a descendant relationship).
Violated preferencesare network paths denoting exclusion, also known as "exclusive" paths.These paths are used to build more complex mappings found by a frame-matchingalgorithm.
The frame-matching algorithm matches the sets of cells from two sense-frames.
The sets of cells, which need not be ordered, are inherited down the sense-network.
A series of structural constraints i olate pairs of cells that are matched usingthe graph search algorithm.
Network paths are then sought between terms occupyingidentical positions in those cells.
Seven kinds of cell match are distinguished, basedon the structural constraints and types of network path found.
Ancestor and same are"inclusive" cell matches, e.g.
\[composition1, metal1\] includes \[composition1, steel1\]because the class of metals includes the class of steels (another ancestor relationship).Sister, descendant, and estranged are types of "exclusive" cell matches, e.g.
\[composi-tion1, steel1\] and \[composition1, aluminiuml\] are exclusive because the class of steelsdoes not include the class of aluminiums ince both belong to the class of metals (thisis a sister relationship).
The remaining cell matches, distinctive source and distinctivetarget, account for cells that fail the previous five kinds of cell match.
For more detailon cell matches, see Fass (1988a).A kind of lexical relevance is found dynamically from the sentence context.
Thisnotion of relevance is used in finding the relevant analogies that distinguish metaphori-cal from anomalous relations; it is also used when finding CO-AGENT FOR ACTIVITYmetonymies.
Relevance divides the set of cells from the source sense-frame into twosubsets.
One cell is selected as relevant given the context; the remaining cells are termednonrelevant.
Collation matches both the source's relevant and nonrelevant cells againstthe cells from the target sense-frame.
A relevant analogy is indicated by a sister matchof the source's relevant cell (see diamond 3 in Figure 4).Five types of metonymic oncepts are currently distinguished.
Examples of twoof the metonymic oncepts, CONTAINER FOR CONTENTS and ARTIST FOR ARTFORM, have already been given.
The remaining three are PART FOR WHOLE, PROP-ERTY FOR WHOLE, and CO-AGENT FOR ACTIVITY.Example 22"Arthur Ashe is black" (= skin colored black ~ PART FOR WHOLE).Example 23"John McEnroe is white" (= skin colored white --+ PART FOR WHOLE).In (22) and (23), the skins of Arthur Ashe and John McEnroe, parts of their bodies,are colored black (white).Example 24"John McEnroe is yellow" (= limited in bravery --* PROPERTY FOR WHOLE).Example 25"Natalia Zvereva is green" (= limited in experience ~ PROPERTY FOR WHOLE).In (24), for example, John McEnroe is limited with respect to his bravery, apropertypossessed by humans and other animals.66Fass Discriminating MetonymyExample 26"Ashe played McEnroe" (= tennis with McEnroe --~ CO-AGENT FOR ACTIVITY).These concepts are encoded in metonymic nference rules in CS (see diamond 2 in Fig-ure 4).
The rules are ordered from most common (synecdoche) toleast.
The order usedis PART FOR WHOLE, PROPERTY FOR WHOLE, CONTAINER FOR CONTENTS,CO-AGENT FOR ACTIVITY, and ARTIST FOR ART FORM.The first two concepts, PART FOR WHOLE and PROPERTY FOR WHOLE, aresource-driven; the others are target-driven.
The difference in direction seems to bedependent on the epistemological structure of the knowledge being related by thedifferent inferences.
PART FOR WHOLE metonymies are source-driven, perhaps be-cause the epistemological nature of parts and wholes is that a part generally belongsto fewer wholes than wholes have parts, hence it makes sense to drive inferencingfrom a part (source) toward the whole (target) than vice versa.In CONTAINER FOR CONTENTS (target-driven), on the other hand, the episte-mological nature of containers and contents i that the containers generally mentionedin CONTAINER FOR CONTENTS metonymies are artifacts designed for the functionof containing - -  hence one can usually find quite specific information about the typ-ical contents of a certain container, for example, some glasses as in (7) - -  whereasthe contents do not generally have the function of being the contents of something.Hence it makes sense to drive inferencing from the container, and the function it per-forms, toward the contents than vice versa.
The same reasoning applies to ARTISTFOR ART FORM (target-driven).
An artist has the vocation of creating art: that ishis/her purpose.A further step in collation distinguishes metaphorical from anomalous semanticrelations.
Recall that a metaphorical relation contains a relevant analogy, as in (15)and (20), while an anomalous relation does not, as in (21).
A relevant analogy is foundby matching the relevant cell from the source sense-frame with one of the cells fromthe target sense-frame.
If the match of cells is composed of a set of sister networkpaths between corresponding word senses in those cells, then this is interpreted asanalogical and hence indicative of a metaphorical relation.
Any other match of ceils isinterpreted as not analogical and thus an anomalous semantic relation is recognized(see Fass 1986; 1987).The third component ofCS is the semantic vector which is a form of representation,like the sense-frame; but sense-frames represent lexical knowledge, whereas emanticvectors represent coherence.
Semantic vectors are therefore described as a kind of coher-ence representation.
A semantic vector is a data structure that contains nested labels andordered arrays structured by a simple dependency s ntax.
The labels form into sets.The outer sets of labels indicate the application of the three kinds of lexical semanticconstraints.
The outermost et of labels is 'preference' and 'assertion.'
The middle set is'relevant' and 'nonrelevant.'
The innermost set is the kind of mapping used: 'networkpath' and 'cell matches.'
The nesting of labels shows the order in which each source ofknowledge was introduced.
The ordered arrays represent the subkinds of each kindof mapping.
Five-column arrays are for the five network paths; seven-column arraysare for the seven types of cell match.
Each column contains a positive number thatshows the number of occurrences of a particular network path or cell match.The fourth component of CS is the process of screening.
During analysis of asentence constituent, a Semantic vector is created for every pairwise combination ofword senses.
These word sense combinations are called semantic readings or simply"readings."
Each reading has an associated semantic vector.
Screening chooses betweentwo semantic vectors and hence their attached semantic readings.
Rank orderings67Computational Linguistics Volume 17, Number 1among semantic relations are applied.
In the event of a tie, a measure of conceptualsimilarity is used.The ranking of semantic relations aims to achieve the most coherent possible in-terpretation of a reading.
The class of preference-based semantic relations takes prece-dence over the class of assertion-based semantic relations for lexical disambiguation.The rank order among preference-based semantic relations isliteral --* metaphorical ~ anomalous.If the semantic vectors are still tied then the measure of conceptual similarity isemployed.
This measure was initially developed to test a claim by Tourangeau andSternberg (1982) about the aptness of a metaphor.
They contend that aptness is afunction of the distance between the conceptual domains of the source and targetinvolved: the claim is that the more distant he domains, the better the metaphor.
Thisis discussed further in Section 5.
The conceptual similarity measure is also used forlexical ambiguity resolution (see Fass 1988c).5.
The Meta5 ProgramCS has been implemented in the meta5 natural language program.
The meta5 programis written in Quintus Prolog and consists of a lexicon holding the sense-frames of justover 500 word senses, a small grammar, and semantic routines that embody collationand screening, the two processes of CS.
The program is syntax-driven, a form ofcontrol carried over from the structure of earlier programs by Boguraev (1979) andHuang (1985), on which meta5 is based.
Meta5 analyzes entences, discriminates theseven kinds of semantic relation between pairs of word senses in those sentences (i.e.,the program recognizes metonymies, metaphors, and so on), and resolves any lexicalambiguity in those sentences.
Meta5 analyzes all the sentences given in Sections 3and 4, plus a couple more metaphorical sentences discussed in Section 7.Below are simplified versions of some of the metonymic inference rules used inmeta5.
The metonymic concepts used in CS contain three key elements: the conceptualrelationship involved, the direction of inference, and a replacement of the source ortarget.
The metonymic inference rules in meta5 contain all three key elements.
Therules, though written in a prolog-like format, assume no knowledge of Prolog on thepart of the reader and fit with the role of metonymy shown in Figures 1 and 4.Each metonymic nference rule has a left-hand side and a right-hand side.
The left-hand side is the topmost statement and is of the form metonymic_inference_rule(Source,Target).
The right-hand side consists of the remaining statements.
These statementsrepresent the conceptual relationship and the direction of inference, except for thebottom most one, which controls the substitution of the discovered metonym for eitherthe source or target: this statement is always a call to find a new sense-network path.Rule 1PROPERTY FOR WHOLE: source-driven.metonymic_inference_rule (Source, Target):-find_cell (Source, \[Whole, have1, it1\]), \[1\]find_sense_network_path (W ole, Target).
\[2\]This rule represents PROPERTY FOR WHOLE, which is source-driven.
State-ment \[1\] represents he conceptual relationship and direction of inference.
The concep-tual relationship is that the source is a property possessed by the whole in a property-whole relation.
The inference is driven from the source: find_cell searches through the68Fass Discriminating Metonymysource's list of cells for one referring to a "whole" of which the source is a "part.
"Statement \[2\] controls the substitution of the discovered metonym: the "whole" isthe substitute metonym that replaces the source, and the next sense-network path issought between the whole and the target.Rule 2CONTAINER FOR CONTENTS: target-driven.metonymic_inference_rule (Source, Target):-find_cell (Target, \[it1, contain1, Contents\]), \[1\]find~sense_network_path (Source, Contents).
\[2\]This metonymic concept is target-driven.
The target is the "container"in a container-contents relation (\[1\]).
The "contents" is the substitute metonym that replaces the tar-get.
The next sense-network path is sought between the source and the contents (\[2\]).Rule 3ARTIST FOR ART FORM: target-driven.metonymicJnference_rule (Source, Target):-find_genus (Target, Occupation), \[1\]find_cell (Occupation, lit1, Make, Art form\]), \[2\]confirm_type (create1, Make), \[3\]confirm_type (artdorml, Art form), \[4\]find~ense_network_path (Source, Art form).
\[5\]Again, the inference in ARTIST FOR ART FORM is from the target.
The targetis a person who is an "artist" in an artist-art form relation.
The occupation of theperson is found by searching up the sense-network (\[1\]).
The list of ceils associatedwith the occupation are searched for a cell describing the main activity involved inthe occupation (\[2\]), e.g., a cook cooks food and an artist makes art forms.
Checks aredone to confirm that any activity found is indeed making an art form, i.e., that the"making" involved is a type of creating (\[3\]) and that the "art form" is a type of artform1 (\[4\]).
The "art form" is the substitute metonym that replaces the target.
A newsense-network path is computed between the source and the art form (\[5\]).
I will nowdescribe how meta5 recognizes ome metonymies and metaphors.Example 19"Ted played Bach" (= the music of Bach).In (19), between 'Bach' and the twelfth sense of 'play' in meta5's lexicon (meaning "toplay music"), there is a chain of metonymies plus a literal relation.
The chain consistsof ARTIST FOR ART FORM and CONTAINER FOR CONTENTS metonymies.
Bothmetonymic oncepts are target-driven.
In ARTIST FOR ART FORM the inference isfrom the ARTIST (the target) to the ART FORM (the source), so the substitute metonymreplaces the target (the ARTIST) if the inference is successful.The sense-frames of the verb sense play12 and the noun senses music1 and jo-hann_sebastian_bach reshown in Figure 5.
The semantic relation results from match-ing the object preference of play12, which is for music, against the surface object,which is 'Bach,' short for 'Johann Sebastian Bach.'
The preference is the source andthe surface object is the target.We will follow what happens using the flow chart of Figure 4.
(Enter diamond 1of the chart.)
The sense-network path between the source (music1) and the target69Computational Linguistics Volume 17, Number 1sf(play12,\[\[arcs,\[\[supertype, per forrnl\]\] 1,\[node2,\[\[agent,\[preference, human_being1\]\],\[object,\[preference,music1\]\]\]\]\]).sf(musicl, sf (johann_sebastian_bach,\[\[arcs, \[\[arcs,\[\[supertype, \[sound1, art_fermi\]\]I\], \[\[supertype, composerl\]l \\[nodeO, \[nodeO,\[\[musician1, play12, itt\]\]\]\]).
\[\[animacyl, dead1\],\[sex1, male1\],\[bornt, 1685\],\[died1, 17501111).\]Figure 5Sense-frames for play12 (verb sense), music1 and johann_sebastian_bach (noun senses)(johann_sebastian_bach) is sought.
The path is not inclusive because johann_sebastian_bach is not a type of music1.
(Enter diamond 2 of the chart.)
Metonymic inference rules are applied.
The rulesfor PART FOR WHOLE, PROPERTY FOR WHOLE, CONTAINER FOR CONTENTS,CO-AGENT FOR ACTIVITY are tried in turn, but all fail.
The rule for ARTIST FORART FORM, however, succeeds.
The discovered metonymic inference is that johann_sebastian_bach (t e ARTIST) composes musical pieces (the ART FORM).
The metonymicinference is driven from the target (the ARTIST), which is johann_sebastian_bach.
Thesuccessful metonymic inference, using the ARTIST FOR ART FORM inference ruleabove, is as follows: \[1\] johann_sebastian_bach (the ARTIST) is a composer1, \[2\] com-posers compose1 musical pieces (the ART FORM).
Additional tests confirm \[2\], whichare that \[3\] composing is a type of creating, and \[4\] a musical_piece1 is a type ofart_form1.
(Enter the leftmost statement box - -  also step \[5\] of the ARTIST FOR ART FORMinference rule above.)
The original target (johann_sebastian_bach) is replaced by thesubstitute metonym (musical_piece1).
(Enter diamond 1 for a second time.)
The sense-network path between the source(music1) and the new target (musical_piece1) is sought.
The path is not inclusive.
(Enter diamond 2 for a second time.)
Metonymic inference rules are applied.
Therules for PART FOR WHOLE and PROPERTY FOR WHOLE fail, but the rule forCONTAINER FOR CONTENTS succeeds.
The successful inference, using the descrip-tion of the CONTAINER-CONTENTS inference rule given previously, is that \[1\] amusical_piece1 (the CONTAINER) contains music1 (the CONTENTS).
(Enter the leftmost statement box for a second time.)
The direction of inference inthe CONTAINER FOR CONTENTS metonymic oncept is from the target (the CON-TAINER) towards the source (the CONTENTS), so \[2\] the target (the CONTAINER) isreplaced by the substitute metonym when an inference is successful.
Hence in our ex-ample, the target (musical_piece1) is again replaced by a substitute metonym (music1).The source, which is music1, the object preference of play12, remains unchanged.
(Enter diamond 1 for a third time.)
The sense-network path between the source(music1) and the latest target (music1) is sought.
The path is inclusive, that music1 isa type of music1, so a literal relation is found.
(Exit the chart.)
The processing of the preference-based semantic relation(s) be-tween play12, and its preference for music1, and johann_sebastian_bach is completed.70Fass Discriminating MetonymyAfter an initial preference violation (Johann Sebastian Bach is not a kind of music), thesemantic relation found was an ARTIST FOR ART FORM metonymic relation (thatjohann_sebastian_bach composes musical pieces) followed by a CONTAINER FORCONTENTS metonymic relation (that musical pieces contain music) followed by aliteral relation (that music is music).Example 20"The car drank gasoline.
"There is a metaphorical relation between carl and the verb sense drink1 in (20).
Thesource is drink1, whose agent preference is animal1, and the target is carl (see Fig-ure 6).A metaphorical relation is sought after failing to find an inclusive network pathor a metonymic inference between animal1 and carl, hence the network path betweenanimal1 and carl must be exclusive.
The network path found is an estranged one.The second stage is the match between the relevant cell of animal1 and the cells ofcarl.
In the present example, drinkl is relevant.
The list of cells for animal1 is searchedfor one referring to drinking.
The relevant cell in the list is \[animal1, drink1, drink1\],which is matched against he inherited cells of carl (see Figure 7).
A sister match isfound between \[animal1, drink1, drink1\] and \[carl, use2, gasoline1\] from carl.The sister match is composed of two sister paths found in the sense-network.
Thefirst sister path is between the verb senses drink1 and use2, which are both typesof expending (Figure 8).
The second path is between the noun senses drink1 andgasoline1, which are both types of liquid (Figure 9).
The effect of the network paths is toestablish correspondences between the two cells such that an analogy is "discovered"that animals drink potable liquids as cars use gasoline.
Note that, like Gentner's (1983)systematicity principle, the correspondences found are structural and independent ofthe content of the word senses they connect.
Note also that the two cells have anunderlying similarity or "ground" (Richards 1936) in that both refer to the expenditureof liquids.
This second stage of finding a relevant analogy seems the crucial one inmetaphor recognition.Figure 10 shows the match of the nonrelevant cells from animal1 and carl.
The cell\[carl, use2, gasoline1\] has been removed.
There are three inclusive cell matches as an-imals and cars share physical objectlike properties of boundedness, three dimensions,sf(drinkl,\[\[arcs,\[\[supertype, \[ingest1, expendl\]\]J\],\[node2,\[\[agent,\[preference, anlrnall\] ,\[object,\[preference, drinkl\]\]\]\]\]).sf(animatl, sf(carl,\[\[arcs, \[\[arcs,\[\[supertype, organism1\]\]\], \[\[supertype, motor_vehicle1\]\]\],\[nodeO, \[nodeO, .\[\[biology1, animal1\], \[lit1, carry1, passenger1\]\]\]\]).lit1, drink1, drink1\],lit1, eat1, food1\]\]\]\]).Figure 6Sense-frames for drink1 (verb sense), animal1 and carl (noun senses)71Computational Linguistics Volume 17, Number 1Relevant cell of animal1(SOURCE)\[animal1, drink1, drink1\]Cetls of carl(TARGET)\[\[bounds1, distinct1\],\[extent1, three_dimensionatl\[behaviourl, solid1\],\[animacyl, nonliving1\],\[carl, roll1, \[on3, land1\]\],\[composition1, steel1\],\[driver1, drivel, carl\],\[carl, have1, \[4, wheel1\]\],\[carl, have1, engine1\],\[carl, use2, gasoline1\],\[caN, carry1, passenger1\]\]Figure 7Match of relevant cell from animal1 against cells of carl~ enter1 ~ contract1supertype supertype super~l~ertype~dr ink l  suP~I~ use2Figure 8Sister sense-network path between drink1 and use2 (verb senses)~ gy source1| supertype supertype supertype JIdrinkl ~J gasoline1 Ico .
l l  I |oodlFigure 9Sister sense-network path between gasoline1 and drink1 (noun senses)72Fass Discriminating MetonymyNon-relevant cells of animal1 Non-relevant c~lJ~ of carl Cell matches(SOURCE) (TARGET}\[\[bour=dsl, distinct1 \] \]\]bounds I distinct1 \] i sam\]extent1, three dimensional1|, \[extent , three d mens ona \],13 e\[behaviourt, sol id1| ,  \[behaviourt, sollidl\], ICell matcheslanimacyl, livingt\], \[animacyl, nonlivingl\], ~2 sister\]composition1, flesh1|, \]composition1, steel1|, ~ cell matches\]animal1, eat1, food1|, J2 distinctive\[biol0gyt, animalt\]\] I source celts(of animalt)\]carl, roHt, \]on3, land1||, |\]driver1, drivel, carl|, 15 distinctive\]carl, hayer, \[4. wheelt\]\], target cells\[cart, hayer, enginet\], (of carl)\[cart, carryt, passenger1||Figure 10Matches of non-relevant cells from animal1 and carl\ [pre ference,\[\[network~oath,\[0, 0, 0, 0, 1\]\],\ [ ce l lmatch ,\[\[relevant,\[0, 0, 1, 0, 0, 0, 10\]\],\]non_relevant,\[0, 3, 2, o, o, 2, 5\]\]\]\]\]\]I First array:preference violation(estranged sense-network path)I Second array:relevant analogy(sister match of relevant cell)I Third array:distance betw.
conceptual domains(matches of non-relevant cells)Figure 11Semantic vector for a metaphorical semantic relationand solidity.
Two cell matches are exclusive.
Animals are composed of flesh, whereascars are composed of steel.
Animals are living, whereas cars are nonliving.
There aretwo distinctive cells of animal1 and five distinctive cells of carl.
Tourangeau and Stern-berg's (1982) hypothesis predicts that the greater the distance between the conceptualdomains of the terms involved in a metaphor, the more apt the metaphor.
The pro-portion of similarities (inclusive cell matches) to differences (exclusive cell matches) is3 to 2, which is a middling distance suggesting, tentatively, an unimposing metaphor.All of these matches made by collation are recorded in the semantic vector shownin Figure 11.
The crucial elements of the metaphorical relation in (20) are the preferenceviolation and the relevant analogy.
In Figure 11, the preference violation has beenrecorded as the 1 in the first array and the relevant analogy is the 1 in the secondarray.
Information about the distance between conceptual domains is recorded in thethird array.The 'preference' label indicates that a preference has been matched (rather thanan assertion).
The five columns of the first array record the presence of ancestor,same, sister, descendant and estranged network paths respectively.
When a preferenceis evaluated, only one network path is found, hence the single 1 in the fifth column,which indicates that an estranged network path was found between animal1 and carl.Cell matches are recorded in the second and third arrays, which each contain sevencolumns.
Those columns record the presence of ancestor, same, sister, descendant,estranged, distinctive source, and distinctive target cell matches respectively.
The 1 inthe third column of the second array is the relevant analogy - -  a sister match of the73Computational Linguistics Volume 17, Number 1relevant cell \[animal1, drink1, drink1\] and the cell \[carl, use2, gasoline1\].
The 10 isthe ten distinctive cells of carl that did not match \[animal1, drink1, drink1\].
This isthe match of 12 cells, 1 from the source and 11 from the target (see Figure 7).
The sumof array columns is:( (0+0+1+0+0)  x2) 4-((0+10) x l )=(1  x2)+(10x1)=12.The 3 similarities, 2 differences, 2 distinctive cells of animal1 and 5 distinctive cellsof carl are the nonzero numbers of the final array.
The 3 similarities are all same cellmatches; the 2 differences are both sister cell matches.
A total of 17 cells are matched,7 from the source and 10 from the target (see Figure 10).
The total of array columns is:( (0+3+2+0+0)  x 2) + ((2+5) x 1) = (5 x 2) + (7 x 1) = 17.Example 15"The ship ploughed the waves.
"In (15), there is a metaphorical relation between a sense of the noun 'ship' and thesecond sense of the verb 'plough' :in meta5's lexicon.
Note that 'plough,' like 'drink,'belongs to several parts of speech.
Figure 12 shows the sense-frames for the verb senseplough2, the noun sense plough1, which is the instrument preference of plough2, andthe noun sense ship1.In (15), meta5 matches enses of 'ship' against senses of 'plough.'
When meta5pairs ship1 with plough2, it calls upon collation to match ship1 against the nounsense plough1, the instrument preference of plough2.First, the graph search algorithm searches the sense-network for a path betweenplough1 (which is the preference) and ship1 and finds an estranged network pathbetween them, i.e., a ship is not a kind of plough, so plough2's instrument preferenceis violated.Next, collation inherits down lists of cells for plough1 and ship1 from their super-ordinates in the sense-network.
What is relevant in the present context is the action ofploughing because (15) is about a ship ploughing waves.
Collation then runs throughthe list of inherited cells for the noun sense plough1 searching for a cell that refers tothe action of ploughing in the sense currently under examination by meta5, plough2.sf(plough2,\[\[arcs\[\[supertype, transfer1\]\]\],\[node2,\[\[instrument,\[preference, plough1\]\],\[object,\[preference, soil1\]\]\]\]\]).sf(ploughl, sf(shipl,\[\[arcs, \[\[arcs,\[\[supertype, tool1\]\]\], \[\[supertype, watercraft1\]\]\],\[nodeO, \[nodeO,\[\[farmer1, plough1, it1\], \[\[it1, carry1, shipment1\],\[it1, plough2, soil1\]\]\]\]).
\[it1, have1, engine1\]\]\]\]).Figure 12Sense-frames for plough2 (verb sense), plough1 and ship1 (noun senses)74Fass Discriminating MetonymyRelevant cell of DIouQhl(SOURCE)\ [p lough1,  p lough2,  soi l1\]Cells of shiol(TARGET)\ [ \ [bounds1, distinct1\],\ [extent1 ,  three d imens iona l1 \ ] ,\ [behav iour l ,  so l id1\ ] ,\ [an imacy l ,  non l iv ing1\ ] ,\ [ compos i t ion  1, meta l1 \ ] ,\ [ship1,  use2,  energy  source1\ ] ,\ [boatman1,  sa i l1 ,  sh ip1 \ ] ,\ [ sh ip1 ,  sa i l2 ,  water2 \ ] ,\ [sh ip1,  car ry1 ,  sh ipment1 \ ] ,\[ship1, have1,  enginel J \ ]Figure 13Match of relevant cell from plough1 against cells from ship1INon-relevant cells of olouahl Non-relevant cells of shin1 Cell matches(SOURCE) (TARGET)I 1 ancestor \[\[composition1, matter1\], \[\[composition1, metal1\], Icell match\[bounds1, distirtctl\], \[bounds1, distinct1\],\[extent1, three dimensional1\], lextentt, three_dimensionall\],14 same\[behaviourl, solid1\], \[behaviourl, solid1\], Icell matches\[animacyl, nonliving1\], \[animacyl, nonliving1\], |I 1 sister \[farmer1, plough1, plough1\]\] \[boatman1, sail1, ship1\], Icell matchuse2, energy_source1\], 13 distinctive \[ship1,\[ship1, carry1, shipment1\], Itarget cells|ship1, ha,/el, engine1\]\] I(of ship1)Figure 14Matches of non-relevant cells from plough1 and ship1Collation finds a relevant cell \[plough1, plough2, soil1\] and uses its frame-matchingalgorithm to seek a match for the cell against he list of inherited cells for ship1, shownin Figure 13 (for ease of reading, it1 has again been replaced by the word senses beingdefined).
The algorithm finds a match with \[ship1, sail2, water2\] (highlighted in Figure13), and hence collation "discovers" a relevant analogy that both ships and ploughsmove through a medium, i.e., that ploughs plough through soil as ships sail throughwater.Finally, collation employs the frame matching algorithm a second time to matchtogether the remaining nonrelevant cells of plough1 and ship1 (see Figure 14).
The cell\[ship1, sail2, water2\] is removed to prevent it from being used a second time.Figure 15 shows the semantic vector produced.
As with Figure 11, it shows ametaphorical relation.
There is a preference violation, an estranged network path in-dicated by the 1 in the fifth column of the first array.
There is also a relevant analogy,shown by the 1 in the third column of the second array: the analogical match of thecells \[plough1, plough2, soil1\] and \[ship1, sail2, water2\].
The second array shows that11 cells are matched, I from the source and 10 from the target (check against Figure 13).The sum of the array's columns is:((0 +0 + 1 +0+0)  x 2) + ( (0+9)  x 1) = (1 x 2) + (9 x 1) = 11.75Computational Linguistics Volume 17, Number 1\[preference,\[\[network oath,\[0, O, O, O, 1\]\],\[cell_match,\[\[relevant,\[o, o, 1, o, o, o, 9\]\],\[non_relevant,\[1,4, 1, O, O, O, 311\]\]11I First array:preference violation(estranged sense-network path)I Second array:relevant analogy(sister match of relevant cell)I Third array:distance betw.
conceptual domains(matches of non-relevant cells)Figure 15Semantic vector for another metaphorical semantic relationIn the third array, the match of nonrelevant cells, there is 1 ancestor match, 4 samematches, 1 sister match, and 3 distinctive cells of ship1.
Fifteen cells are matched, 6from the source and 9 from the target (see Figure 14).
The totals are:( (1+4+1+0+0)  x2)+( (0+3)x1)=(6x2)+(3x1)=15.Semantic vectors can represent all the semantic relations except metonymic ones.
Thereason is that metonymic relations, unlike the others, are not discriminated by CS interms of only five kinds of network path and seven kinds of cell matches.
Instead,they consist of combinations of network paths and specialized matches of cells thathave not fallen into a regular enough pattern to be represented systematically.6.
ExtensionsEven for those semantic dependencies investigated, the interpretation f semantic re-lations seems to require more complexity than has been described so far in this paper.Consider the differences between the following sentences:Example 20"The car drank gasoline.
"Example 27"The car drank coffee.
"Intuitively, sentence (20) is metaphorical while (27) is metaphorical/anomalous.In (20), the semantic relation between 'car' and 'drink' is thought o be metaphorical,and the isolated semantic relation between just 'drink' and 'gasoline' is anomalous,but the sentence as a whole is metaphorical because it is metaphorical that cars shoulduse up gasoline.In (27), the semantic relation between 'car' and 'drink' is metaphorical; the seman-tic relation between just 'drink' and 'coffee' is literal; yet the effect of (27) as a whole ismetaphorical/anomalous.
The object preference of 'drink' is for a drink, i.e., a potableliquid.
It seems that it is metaphorical for cars to "drink" a liquid commonly used upby cars, e.g., gasoline, but anomalous if the liquid has nothing to do with cars, e.g.,coffee, as in (27).The problem of understanding the differences between sentences (20) and (27)requires ome further observations about the nature of semantic relations, principally76Fass Discriminating Metonymythat the differences are caused by the combinations of semantic relations found in thesentences and the relationships between those relations.
Below is a suggestion as tohow deeper semantic processing might discriminate the differences between the twosentences.Before getting to the deeper processing, we need a better semantic vector notation.The better semantic vector notation, which developed from a discussion with AfzalBallim, is a modification of the notation shown in Section 5.
The key differences arereformulation by rewriting the five and seven column arrays in terms of the predicate-argument notation used in the rest of semantic vectors, and extension by adding thedomain knowledge connected by every network path and cell match.Figure 16 shows the semantic vector in Figure 11 reformulated and extended.
Theadvantage of vectors like the one in Figure 16 is that they record both how the sense-frames of two word senses are matched (i.e., as various kinds of network path and cellmatch) and what information in the sense-frames is matched (i.e., all the cells).
Forexample, the part of Figure 16 that begins "\[relevant, .
.
."
contains all the informationfound in Figure 7, the match of the relevant cell from animal1 against the cells of carl,both the types of cell matches and the cells matched.
The equivalent part of Figure 11only records the types of cell matches.
Recording the contents of the matched cells isuseful because it enables a deepened analysis of semantic relations.
Such an analysisis needed to detect he differences between (20) and (27).In the description of CS in Section 4, collation discriminates the one or moresemantic relations in each semantic dependency, but treats the semantic relations inone dependency asisolated from and unaffected by the semantic relations in anotherdependency.
What is needed is extra processing that interprets the semantic relation(s)in a later dependency with respect to the semantic relation(s) established in an earlier\[preference,\[\[network_path,\[estranged,\[1, \[animal1, carl\]I\]\],\[cell_match,\ [ \ [relevant,\ [ \ [ s i s ter ,\[1, \[\[\[animal1, drink1, drink1\], \[carl, use2, gasoline1\]\]\]\],\[distinctive_target,\[10, \[\[bounds1, distinct1\], \[extent1, three_dimensional1\],\[behaviourl, solid1\], \[composition1, metal1\],\[animacyl, nonliving1\], \[carl, rollf, \[on3, land1\]\],Idriverl, drivel, carl\], \[carl, hayer, \[4, wheel1\]\],\[carl, have1, engine1\], \[carl, caCryl, passenger1\]\]\]\]\]\],\[non_relevant,\[\[same,\[3, \[\[\[bounds1, distinct1\], \[boundst, distinct1\]\],\[\[extent 1, three dimensional1\], \[extentt, hree dimensional1 \]\],\[\[behaviourl, solid1\], \[behaviourl, solid1\]\]\]\],\[sister,\[2, \[\[\[composition1, flesh1\], \[composition1, rnetall\]\],\[\[animacyl, living1\], \[animacyl, nenlMngl\]\]\]J,\[distinctive_source,\[2, \[\[animal1, eat1, food1\], \[biology1, animal1\]\]\]\],\[distinctive_target,\[5, \[\[carl, roll1, \[on3, landt\]\], \[driver1, ddvel, cart\],\[carl, hayer, \[4, wheel1\]\], \[carl, have1, engine1\],\[carl, carry1, passenger1\]\]\]\]\]\]\]\]\]\]Figure 16Reformulated and extended version of Figure 1177Computational Linguistics Volume 17, Number 1\[preference,\[cell_match,\[relevant,\[sister,\[1, \[\[animal1, drink1, drink1\], \[carl, use2, gasoline1\]}\]\]\]\]\]Figure 17Vector statement ofmatch of relevant cell from animal1 against cells of carl\[preference,\[cellmatch,\[relevant,\[sister,\[1, \[\[animal1, drink1, drink1\], \[vehicle1, use2, gasoline1\]\]\]\]\]\]\]Figure 18Vector statement ofmatch of relevant cell from drink1 against cells of gasoline1 (noun senses)one.
This processing matches the domain knowledge in semantic vectors, i.e., thisprocessing is a comparison of coherence representations.In sentences such as (20) and (27) there are two key semantic dependencies.
Thefirst one is between the subject noun and the verb; the second is between the verband object noun.
In each dependency, the source is the verb (through its agent andobject preferences) and the targets are the nouns.
Semantic relations are found for eachdependency.
One way to detect he difference between metaphorical sentences suchas (20) and metaphorical/anomalous ones such as (27) is in each sentence to consultthe semantic vectors produced in its two main semantic dependencies and comparethe matches of the relevant cells that are found by collation.Let us go through such an analysis using CS, starting with the first semanticdependency between subject noun and verb.
In this semantic dependency in both (20)and (27), a relevant analogy is discovered as part of a metaphorical relation betweenthe target carl and animal1, the agent preference of the source drink1.
The semanticvector in Figure 16 records the two cells that figure in that relevant analogy.
Figure 17shows the same information from the semantic vector but written as a statement.When the second semantic dependency is analyzed in (20), the target is gasoline1and is matched against he noun sense drink1, the object preference of the sourcedrink1 (the verb sense).
A semantic vector is produced.
The relevant cell found inthe noun sense drink1 is \[animal1, drink1, drink1\].
Its match against \[vehicle1, use2,gasoline1\], a cell from gasoline1, is shown in the vector statement in Figure 18.
Thematch is a sister match, indicating a relevant analogy.Now this is peculiar because "drinking gasoline" is anomalous, yet a relevantanalogy has been found and this paper has argued that relevant analogies are specialto metaphorical relations.
One possible xplanation is that differences exist between therecognition of metaphorical relations that concern agents and metaphorical relationsthat concern objects and other case roles.
It may be that metaphorical relations areindicated by a relevant analogy, but only in selected circumstances.
This needs furtherinvestigation.78Fass Discriminating Metonymy\[preference,\[cell_match,\[relevant,\[ancestor,\[1, \[\[animal1, drink1, drink1\], \[human_being1, drink1, coffee1\]\]\]\]\]\]\]Figure 19Vector statement ofmatch of relevant cell from drink1 against cells from coffee1 (noun senses)To return to the analysis of (20), what appears to be important in determining that(20) is a metaphorical sentence is the comparison of the two pairs of matched relevantcells:\[\[animal1, drink1, drink1\], \[carl, use2, gasoline1\]\]\[\[animal1, drink1, drink1\], \[vehicle1, use2, gasoline1\]\]The two source cells are the same and the two target cells, \[carl, use2, gasoline1\]and \[vehicle1, use2, gasoline1\], are almost identical, indicating that the same basicanalogy runs through the whole of (20), hence the sentence as a whole is metaphorical.Now let us analyze the second semantic dependency in (27).
The target is coffee1and is again matched against drink1, the object preference of the verb sense drink1, thesource.
The relevant cell from the noun sense drink1 is again \[animal1, drink1, drink1\],which matches against \[human_being1, drink1, coffee1\] from the target coffee1.
Thistime, the match is an ancestor match and hence not a relevant analogy.
Figure 19shows this match of the relevant cell as a vector statement.
Let us compare the twopairs of matched relevant cells for (27):\[\[animal1, drink1, drink1\], \[carl, use2, gasoline1\]\]\[\[animal1, drink1, drink1\], \[human_being1, drink1, coffee1\]\]The two source cells are the same but the two target cells, \[carl, use2, gasoline1\]and \[human_being1, drink1, coffee1\], are very different.
The reason that the sentence asa whole is metaphorical/anomalous is because of the clash between these target cells.The basic analogy of a car ingesting aliquid does not carry over from the first semanticdependency into the second.
The anomalous flavor of (27) could not be detected bylooking at the semantic relations in the dependencies in isolation because one semanticrelation is metaphorical nd the other is literal.
Neither relation is anomalous - -  theanomaly comes from the interaction between the two relations.Figure 20 is a proposed representation for sentence (20).
The left side of Figure20 shows the knowledge representation part of the sentence representation: a simplecase-frame based representation f (20).
The right side of Figure 20, within the greypartition, is the coherence representation component of the sentence representation:abridged semantic vectors for the two main semantic dependencies in (20).
The uppersemantic vector is the match of the target carl against he source animal1.
The lowersemantic vector is the match of the target gasoline1 against he source drink1, thenoun sense.
The upper abridged semantic vector indicates a metaphorical relation.The lower semantic vector also indicates a metaphorical relation though, as was notedearlier, "drinking gasoline" when interpreted in isolation is surely anomalous.The underlines in Figure 20 denote pointers linking the semantic vectors to thecase frame.
The grey vertical arrows show that the two semantic vectors are also linked79Computational Linguistics Volume 17, Number 1~rlnkl,\ [a~t .
?ar~l.\[object,gasollnet \]\]I i  urce'\[\[explicit, ddnkl\],\[implicit, animal1\[\[\[,target, carl\[l,reference,network_path,\[estranged,\[1, \[anirnalt, car 1\]\]\]\],{cell_match,\[\[relevant,\[{sister,\[1, \[\[\[animall, drink1, drink1\[, \[carl, use2, gasolinet|\]\]\]\]\]\]\]\[\]\]\[\[\[source, l \[\[explicit, drink1\[,\[Implicit, drink1 \]\]\[,\[target, ~\]esollnel\]\],\[preference, 8,4\[\[network_path,\[dster,\[1, \[drink1, gasolinet \]\]\] ,(cell_match.\[{relevant,{{sister, '~\[1, \[\[\[animal1.
drink1, drink1\[, \[vehicle1.
use2, gasolinel\]\]\]\]\]\]\]\]\]\]\]Figure 20Sentence representation for "The car drank gasoline"I ~?\[\[\[sou roe,{I \[\[explicit, drink1\[,It \[implicit, ~11\]\] \] ,t~ \[age, carl\[l,/ \[p ref erenc'~'.| \[\[network path,I| \[estranged,,~ \[1, \[anirneH, carl\]\]\]\],II \[cell match, l~ \[\[relevant, \[drink1,{agent,c.~J \],\[object.coffee.
1\]\] \[\[\[source.
{{explicit, driNkl\],\[implicit, drinkt\]\]\],\[target, coffee.
1\]\],\[preference\[\[network_path.\[ancestor,\[1, \[drinkt, coffeet\]m,\[cell_match,\[\[relevant,\[\[ancestor,{(sister,\[1, \[\[\[animal1.
drink1, drink1\[.
\[carl, use2, gasolinel\]\]\]\]\]\]\]|\]\]\]\[1, \[{\[anirnall, drink1, drink1\[, \[human_being1, drink1, coffeel\]\]\]\[\]\]\]\]\]lFigure 21Sentence representation for "The car drank coffee"together via the matches of their relevant cells.
In those matches, the arrows are sense-network paths found between the elements of the two target cells.
The network pathsindicated in grey, that connect the two abridged semantic vectors, show processing ofcoherence representations.
The particular network paths found (indicated in italics), adescendant path and two same "paths," show that the same relevant analogy is usedin both semantic relations - -  that both semantic relations involve a match betweenanimals drinking potable liquids and vehicles (including cars) using gasoline - -  hencesentence (20) as a whole is metaphorical.
Figure 20 is therefore unlike any of thecoherence representations hown previously, because it shows a representation of ametaphorical sentence, not just two isolated metaphorical relations.80Fass Discriminating MetonymyCompare Figure 20 with Figure 21, a sentence representation for (27).
The uppersemantic vector again indicates a metaphorical relation between carl and drink1.
Thelower semantic vector indicates a literal relation between drink1 and coffee1.
What isimportant here is the match of relevant information discovered in the two semanticrelations, as indicated by the three network paths.
The paths found are two estrangedpaths and a. sister path, indicating that the relevant information found during the twosemantic relations is different: in one semantic relation, information about animalsdrinking potable liquids is matched against cars using gasoline; in the other, the sameinformation is matched against human beings drinking coffee; but cars using gasoline andhuman beings drinking coffee are quite different, hence sentence (27) is anomalousoverall.Note that in Figures 20 and 21, the coherence representation part of the sentencerepresentation is much larger than the knowledge representation part.
The detailed"world knowledge" about carl, the verb sense drink1, gasoline1, and coffee1 are all onthe right side.
It is interesting to contrast the figures with early Conceptual Dependency(CD) diagrams such as those in Schank (1973) because, rather than the large andseemingly unlimited amounts of world knowledge that appear in CD diagrams, thetwo figures present only the world knowledge needed to discriminate the semanticrelations in (20) and (27).7.
D iscuss ion  and Conc lus ionsThis section reviews the material on metonymy and metaphor in Section 2 in light ofthe explanation of the met* method given in Sections 3-6.
When compared with the AIwork described in Section 2, the met* method has three main advantages.
First, it con-tains a detailed treatment of metonymy.
Second, it shows the interrelationship betweenmetonymy, metaphor, literalness, and anomaly.
Third, it has been programmed.Preference Semantics addresses the recognition of literal, metaphorical, and anoma-lous relations, but does not have a treatment of metonymy.
In the case of PreferenceSemantics, the theory described in Wilks (1978) has not been implemented, thoughthe projection algorithm was implemented (Modiano 1986) using some parts of CS tosupply detail missing from Wilks' original specification.Gentner's (1983) Structure-Mapping Theory has no treatment of metonymy.
Thetheory has been implemented in the Structure-Mapping Engine (Falkenhainer, Forbusand Gentner 1989) and some examples analyzed by it but not, to my knowledge,examples of metaphor or anomaly.Indurkhya's (1988) Constrained Semantic Transference theory of metaphor has notreatment of metonymy, anomaly or literalness.
It has also not been implemented: seeIndurkhya (1987) for reasons why.Hobbs and Martin (1987) offer a relatively shallow treatment of metonymy with-out, for instance, acknowledgement that metonymies can be driven from either thesource or the target.
Hobbs' "selective inferencing" approach to text interpretation hasbeen applied to problems including lexical ambiguity (Hobbs 1977; 1982b; Hobbs andMartin 1987), metaphor (Hobbs 1977; 1983a; 1983b) and the "local pragmatics" phe-nomena of metonymy (Hobbs and Martin 1987), but not anomaly.
To my knowledge,Hobbs has yet to produce a unified description of selective inferencing that showsin detail how lexical ambiguity is resolved or how the differences between metaphor,metonymy, and so on can be recognized.
Hobbs" earlier papers include a series ofprograms - -  SATE, DIANA, and DIANA-2 - -  but the papers are not clear about whatthe programs can do.
It is not clear, for example, whether any of the programs actuallyanalyze any metaphors.81Computational Linguistics Volume 17, Number 1Martin's (1990) work is the only other computational pproach to metaphor thathas been implemented.
However, the work does not have a treatment of metonymy.Martin's metaphor-maps, which are used to represent conventional metaphors andthe conceptual information they contain, seem to complement semantic vectors ofthe extended kind described in Section 6.
In Section 6, I argued that vectors need torecord the conceptual information i volved when finding mappings between a sourceand target.
What metaphor-maps do is freeze (some of) the conceptual informationinvolved in particular metaphorical relations.
There is some theoretical convergencehere between our approaches; it would be interesting to explore this further.Moreover, the metaphors studied so far in CS seem linked to certain conventionalmetaphors because certain types of ground have recurred, types which resemble Lakoffand Johnson's (1980) structural metaphors.
Two types of ground have cropped up sofar.Example 28"Time flies.
"The first is a use-up-a-resource m taphor which occurs in (20) and in (28) whenviewed as noun-verb sentence.
Both sentences are analyzed by meta5.
Use-up-a-re-source resembles structural metaphors like TIME IS A RESOURCE and LABOR IS ARESOURCE which, according to Lakoff and Johnson (1980, p. 66), both employ thesimple ontological metaphors of TIME IS A SUBSTANCE and AN ACTIVITY IS ASUBSTANCE:These two substance metaphors permit labor and time to be quantified -- that is,measured, conceived of as being progressively "used up," and assignedmonetary values; they allow us to view time and labor as things that can be"used" for various ends.Example 29"The horse flew.
"The second type of ground is motion-through-a-medium, a type of ground dis-cussed by Russell (1976).
This appears in (15) and (29), again both analyzed by meta5.Incidentally, it is worth noting that structural metaphors have proven more amena-ble to the met* method than other kinds tried.
I assumed initially that orientational ndontological metaphors would be easier to analyze than structural metaphors becausethey were less complex.
However, structural metaphors have proved easier to analyze,probably because structural metaphors contain more specific oncepts uch as "drink"and "plough," which are more simple to represent in a network structure (like thesense-network of CS) so that analogies can be found between those concepts.7.1 Relationship between Literalness and NonliteralnessWe return here to Gibbs' point concerning the traditional notion of literal meaning that\[1\] all sentences have literal meanings that are entirely determined by the meaningsof their component words and that \[2\] the literal meaning of a sentence is its meaningindependent of context.
Although \[1\] and \[2\] are both presently true of CS, there aremeans by which context can be introduced more actively into sentence interpretation.At present, the meaning of a sentence in CS - -  whether literal or nonliteral - -is not derived entirely independently of context; however, the only context used is a82Fass Discriminating Metonymylimited notion of relevance which is generated by collation from within the sentencebeing analyzed: what is relevant is given by the sense of the main sentence verb.Nevertheless, because of this notion of relevance, contextual influence is present insemantic interpretation i  CS.
Moreover, the notion of relevance is recorded in semanticvectors (Figures 11 and 15) and the extended coherence representations discussed inSection 6.
Hence, the processes and representations of CS possess basic equipment forhandling further kinds of context.7.2 Relationship between Metonymy and MetaphorThe met* method is consistent with the view that metaphor is based on similarity,whereas metonymy is based on contiguity (cf.
Jakobsen and Halle 1956).
Contiguity,readers may recall, refers to being connected or touching whereas imilarity refers tobeing alike in essentials or having characteristics in common.
The difference comesfrom what and how the conceptual information is related.Example 1"My car drinks gasoline.
"Let us consider what is related first.
In metaphor, an aspect of one concept is similarto an aspect of another concept; e.g., in (1), an aspect of the concept for animal, thatanimals drink potable liquids, is similar to an aspect of another concept, that cars usegasoline.Example 2"The ham sandwich is waiting for his check.
"However, in metonymy, a whole concept is related to an aspect of another concept.For example, in (2) the metonymy is that the concept for ham sandwich is related toan aspect of another concept, for "the man who ate a ham sandwich.
"Regarding how that conceptual information is related: in the case of metaphor,the met* method assigns a central role to finding an analogy, and an analogy be-tween two terms is due to some underlying similarity between them (the ground),e.g., in the analogy that animals drinking potable liquids is like cars using gasoline,the underlying similarity is that both animals and cars ingest liquids.
In an analogy,the relationship between aspects of two concepts is purely structural.
In metonymies,however, the relationships are "knowledge-laden" connections, e.g., PART-WHOLEand CONTAINER-CONTENTS.So in summary, "similarity" in metaphor is understood to be based on struc-tural relationships between aspects of concepts, whereas "contiguity" in metonymyis based on knowledge-specific relationships between a concept and an aspect of an-other concept.
These observations, I would argue, support the view that metonymyhas primarily a referential function, allowing something to stand for something else - -a connection between a concept and an aspect of another concept.
The observationsalso support the view that metaphor's primary function is understanding, allowingsomething to be conceived of in terms of something else: the role of analogy is espe-cially crucial to this function.7.3 MetonymyThe treatment of metonymy permits chains of metonymies (Reddy 1979), and allowsmetonymies to co-occur with instances of either literalness, metaphor, or anomaly.83Computational Linguistics Volume 17, Number 1The kinds of inferences sought resemble the kinds of inferences that Yamanashi (1987)notes link sentences.
An obvious direction in which to extend the present work istoward across-sentence inferences.Example 30"John drank from the faucet" (Lehnert 1978, p. 221).Example 31"John filled his canteen at the spring" (Ibid.
).Metonymy seems closely related to the work on non-logical inferencing done bySchank (Schank 1973) and the Yale Group (Schank 1975; Schank and Abelson 1977;Schank and Riesbeck 1981).
For example, Lehnert (1978) observes that just one infer-ence is required for understanding both (30) and (31).
The inference, that water comesfrom the faucet in (30) and the spring in (31), is an instance of PRODUCER FORPRODUCT in which the faucet and spring are PRODUCERs and water is the PROD-UCT.
However, the inference is not a metonymy because it is from unused cases of theverbs 'drink' and 'fill' whereas metonymy only occurs in the presence of a violatedselection restriction, that neither (30) nor (31) contain.7,4 MetaphorMetaphor recognition in the met* method is related to all four views of metaphordescribed in Section 2, consisting of:1...4.a contextual constraint violation, such as a preference violation - -  as inthe selection restrictions view;a set of "correspondences"-- rather like the system of commonplaces inthe interaction view;a relevant analogy - -  cf.
the comparison and interaction views; withanalogies that fall into patterns not unlike conceptual metaphors foundin the conventional view.In CS, the presence of metaphor has been investigated in violations of preferences,a kind of lexical contextual constraint.
Though clearly this is a small part of the picture,it seems worth establishing an extensive picture of preference violation and metaphorbefore moving on to other contextual constraints.Collation and the met* method have certain similarities with the comparison viewof metaphor, especially in the cell matching process.
The relevant analogies discoveredin CS are indeed, to quote Tourangeau and Sternberg, "a comparison in which oneterm.., is asserted to bear a partial resemblance to something else.
"The collation process gives quite a clear picture of the ground and tension in ametaphor.
The ground is the most specific statement that subsumes both statementsthat figure in the analogy, e.g., \[it1, ingest1, liquid1\] is the ground for the analogyinvolving \[animal1, drink1, drink1\] and \[carl, use2, gasoline1\] (see Figures 8 and 9).Moreover, the details of the process match well Aristotle's two basic principles forfinding the ground of a metaphor in that both terms in a metaphorical relation belong84Fass Discriminating Metonymyto a common category (in the example above, the common categories are it1, ingest1,and liquid1) and an analogy is found between them.The collation process also takes care of many of the problems Tourangeau andSternberg (1980) note with the comparison view.
Regarding the problem that "every-thing shares ome feature or category.., with everything else," CS is in agreement: theonly significant combination of features in a metaphor are those involved in a relevantanalogy.
The problem that "the most obvious hared features are often irrelevant," i.e.,that the most obvious shared features are irrelevant to a metaphor, is borne out byexperience with CS - -  for example, animals and cars share some basic physical object-like properties, but these have a minor role in understanding cars drinking.
The met*method bears out another problem that, "even when a feature is relevant, it is oftenshared only metaphorically."
Finally, with the problem that novel metaphors cannotbe based on "extant similarities," - - the relevant analogies found in the met* methodare not "extant" but have to be actively discovered.In Section 2, two main differences were noted between the interaction and com-parison views: first, that similarities are "created" in the interaction view, whereas onlypre-existing similarities are found in the comparison view, and second, that a wholesystem of similarities are evoked in the interactions view, unlike the comparisons view,which focuses upon finding a single similarity.
Regarding the first difference, I wouldargue that the difference is a mistaken one and that interaction theorists are simply us-ing a sophisticated form of comparison.
This is quite evident when one examines, forexample, the methods Tourangeau and Sternberg propose for relating features acrossdomains in their theory.
The second of Aristotle's basic principles is finding an anal-ogy, yet Tourangeau and Sternberg (1982, p. 218) themselves say that, "in a sense, weare proposing that metaphors are analogies that include both tenor and vehicle andtheir different domains as terms.
"And, of course, finding an analogy is central to the met* method on CS.Regarding the second difference, I would agree that finding a system of common-places is distinctive.
However, the extensions to CS described in Section 6 move towardthe direction of finding a system of commonplaces in that the deeper semantic vec-tors, and sentence representations shown in Figures 20 and 21 contain the informationcrucial to finding a system of commonplaces.
Having identified the crucial analogy in(20), the deeper semantic vector contains the two pairs of matched relevant cells thatprovide the core analogy on which the metaphorical interpretation f (20) is built:\[\[animal1, drink1, drink1\], \[carl, use2, gasoline1\]\]\[\[animal1, drink1, drink1\], \[vehicle1, use2, gasoline1\]\]With this information at hand, the sense-frames for word senses in analogical corre-spondence - -  the verb senses drink1 and use2, the noun senses animal1 and carl,animal1 and vehicle1, and drink1 and gasoline1 - -  can be systematically expanded touncover deeper commonplaces between animals and cars.In conclusion, the view of metonymy and metaphor in the met* method is consis-tent with much of the literature on these phenomena.
The met* method is consistentwith the view that the primary function of metaphor is understanding while that ofmetonymy is referential, ike anaphora.
Nevertheless, metonymy and metaphor dohave much in common: both might be described as forms of "conceptual e lipsis," ashorthand way of expressing ideas.85Computational Linguistics Volume 17, Number 1The met* method in its present serial form recognizes literalness, metonymy,metaphor, and anomaly in the following order and by the following characteristics.?
Literalness - -  a satisfied preference.?
Metonymy - -  a successful conceptual inference.?
Metaphor - -  an underlying relevant analogy.?
Anomaly - -  none of the above.The above analysis also illustrates, I hope, why metonymy and metaphor are easilyconfused: both are nonliteral and are found through the discovery of some aspect (aproperty) shared by the source, a preference, and the target, in the above case a surfacenoun.
The differences are (a) how that aspect is selected, (b) the operations that follow,(c) the effect hose operations produce, and (d) subsequent processing.In the case of metonymy, (a) the selected aspect forms a regular semantic relation-ship with a property from the target; (b) there is substitution, i.e., replacement of oneconcept with another; (c) hence the apparent referential function of metonymy; and(d) is unclear at present.In the case of metaphor, (a) the selected aspect is relevant; (b) forms an analogywith another aspect from the target; and (c) the effect is of surprise discovery ofsimilarity between the two concepts; and (d) the discovered analogy is used to unearthfurther similarities between the two concepts (i.e, to deepen the analogy) and to guidesubsequent sentence interpretation.
Moreover, the view of metaphor in CS containselements of the selection restrictions view, the comparisons view, and the interactionsview of metaphor.It should be emphasized that the met* method has only been applied to a smallset of English sentences.
Metonymy interpretation has been investigated only foradjective-noun and subject-verb-object constructions; metaphor interpretation, only forthe latter.
The best avenue for progress with the met* method appears to be the exten-sions to metaphor interpretation described in Section 6.
In the meantime I am lookingfor sentences that contain semantic relations consisting of a metonymy (or chain ofmetonymies) followed by a metaphor.Example 32"America believes in democracy" (Hobbs 1983b, p. 134).On a related point, some sentences are interesting in this respect because theyhave either a metaphorical or metonymic interpretation.
In (32), for example, "Arewe viewing America metaphorically as something which can believe, or are we usingit metonymically to refer to the typical inhabitant, or the majority of inhabitants, ofAmerica?"
(Ibid., p. 135).Example 33"Prussia invaded France in 1870.
"Sentence (33), which was discussed in a group working on beliefs at the CRL (seeAcknowledgments), also has separate metonymic and metaphorical interpretations.The key semantic relation is between 'Prussia' and 'invade.'
The relation is nonliteralbecause 'army' is the expected agent of 'invade' and 'Prussia' is a country, not an army.What, then, is the semantic relation between 'Prussia' and 'army'?
One possibility is86Fass Discriminating Metonymythat a chain of metonymies i involved, that the army is controlled by the govern-ment which also controls Prussia.
A second possibility is that Prussia is understoodmetaphorically as being an animate thing that extends itself into France.AcknowledgmentsI would like to thank the many people atthe Cognitive Studies Centre, University ofEssex; the Computing Research Laboratory,New Mexico State University; and theCentre for Systems Science, Simon FraserUniversity, with whom I have had fruitfuldiscussions over the years, especially thosein the beliefs group at the CRL (AfzalBallim, John Barnden, Sylvia Candelaria deRam, and Yorick Wilks); others at the CRL(including Xiuming Huang, David Farwell,and Eric Dietrich); and colleagues in theCSS who made helpful comments on earlierdrafts of this paper (Chris Groeneboer, GaryHall, and Carl Vogel).
A special word ofthanks for the help given by Yorick Wilks,the director of the CRL, and Nick Cercone,the director of the CSS.
I also gratefullyacknowledge the financial support providedby SERC Project GR/C/68828 while atEssex, by the New Mexico State Legislaturewhile at NMSU, and by the AdvancedSystems Institute and the Centre forSystems Science while at SFU.ReferencesAmsler, Robert A.
(1980).
The structure of theMerriam- Webster Pocket Dictionary.Doctoral dissertation TR-164, Universityof Texas, Austin, Texas.Basso, K.H.
(1976). "
'Wise words' of theWestern Apache: metaphor and semantictheory."
In Meaning in anthropology, editedby K.H.
Basso and H. Selby, New MexicoPress.Beardsley, M. (1962).
"The metaphoricaltwist."
Philosophy and PhenomenologicalResearch, 22:293-307.Bickerton, Derek (1969).
"Prolegomena toalinguistic theory of metaphor.
"Foundations of Language, 5:36-51.Black, Max (1979).
"More about metaphor.
"In Metaphor and thought, edited byA.
Ortony, 19-43.
Cambridge UniversityPress.Black, Max (1962).
Models and Metaphors.Cornell University Press.Boguraev, Branimir K. (1979).
"Automaticresolution of linguistic ambiguities.
"Technical Report No.
11, University ofCambridge Computer Laboratory,Cambridge, England.Campbell, P. (1975).
"Metaphor andlinguistic theory."
Quarterly Journal ofSpeech, 61:1-12.Chomsky, Noam (1964).
"Degrees ofgrammaticalness."
In The Structure ofLanguage: Readings in the Philosophy ofLanguage, dited by J.A.
Fodor andJ.J.
Katz, 384-389, Prentice-Hall.Van Dijk, T. (1975).
"Formal semantics ofmetaphorical discourse."
Poetics,4:173-198.Dubois, J.; Edeline, E; Klinkenberg, J.-M.;Minguet, P.; Pire, E; and Trinon, H. (1970).Rhdtorique Gdndrale.
Larousse.
Publishedas: A General Rhetoric, translated byP.B.
Burrell and E.M. Slotkin, 1981, TheJohn Hopkins University Press.Falkenhainer, Brian; Forbus, Kenneth D.;and Gentner, Dedre (1986).
"Thestructure-mapping engine: algorithm andexamples."
Artificial Intelligence, 41:1-63.Fass, Dan C. (1986).
"Collative semantics: anapproach to coherence."
Technical ReportMCCS-86-56, Computing ResearchLaboratory, June 1986.Fass, Dan C. (1987).
"Semantic relations,metonymy, and lexical ambiguityresolution: a coherence-based account."
InProceedings, 9th Annual Cognitive ScienceSociety Conference, University ofWashington, Seattle, Washington: 575-586.Fass, Dan C. (1988a).
Collative semantics: asemantics for natural anguage processing.Doctoral dissertation, New Mexico StateUniversity, New Mexico.Fass, Dan C. (1988b).
"An account ofcoherence, semantic relations, metonymy,and lexical ambiguity resolution."
InLexical Ambiguity Resolution: Perspectivesfrom Psycholinguistics, Neuropsychology, andArtificial Intelligence, dited by StevenL.
Small, Garrison W. Cottrell, andMichael K. Tanenhaus, MorganKaufmann, 151-178.Fass, Dan C. (1988c).
"Metonymy andmetaphor: what's the difference?"
InProceedings, 12th International Conference onComputational Linguistics (COLING-88),Budapest, Hungary, 177-181.Fass, Dan C. (1988d).
"Collative semantics: astudy in the discrimination of meaning.
"Technical Report CSS/LCCR TR 88-24,Centre for Systems Science, Simon FraserUniversity.Fass, Dan C. (1989a).
"Lexical semanticconstraints."
Technical Report CSS/LCCRTR 89-11, Centre for Systems Science,Simon Fraser University.
(To appear in87Computational Linguistics Volume 17, Number 1Semantics and the Lexicon, edited by JamesPustejovsky.
Kluwer AcademicPublishers.
)Fass, Dan C. (1989b).
"Four generalrepresentations and processes for use inproblem solving."
In Knowledge BasedComputer Systems (Proceedings ofKBCS "89,Bombay, India), edited by S. Ramani,R.
Chandrasekar, and K.S.R.
Anjeyulu,Narosa Publishing House, 169-178.Genette, Gerard (1970).
"La rhetoriquerestreinte."
Communications, 16:158-171.Gentner, Dedre (1983).
"Structure mapping:a theoretical framework for analogy.
"Cognitive Science, 7:155-170.Gibbs, Raymond W. Jr. (1984).
"Literalmeaning and psychological theory.
"Cognitive Science, 8:275-304.Grosz, Barbara J.; Appelt, Douglas E.;Martin, Paul; and Pereira, Fernando C.N.(1987).
"TEAM: An experiment in thedesign of transportable natural-languageinterfaces."
Artificial Intelligence,32(2):173-243.Harris, R. (1976).
"Comprehension fmetaphor: a test of a two-stage processingmodel."
Bulletin of the Psychonomic Society,8:321-324.Hesse, M. (1966).
Models and Analogies inScience.
Notre Dame University Press.Hobbs, Jerry R. (1977).
"Coherence andinterpretation in English texts."
InProceedings, 5th International JointConference on Artificial Intelligence(IJCAI-77), Cambridge, Massachusetts,110-116.Hobbs, Jerry R. (1979).
"Coherence andcoreference."
Cognitive Science, 3:67-90.Hobbs, Jerry R. (1980).
"Selectiveinferencing."
In Proceedings, 3rd NationalConference ofthe Canadian Society forComputational Studies of Intelligence(CSCSI-3), Victoria, British Columbia,Canada, 101-114.Hobbs, Jerry R. (1982a).
"Towards anunderstanding of coherence in discourse.
"In Strategies for Natural LanguageProcessing, edited by Wendy G. Lehnertand Martin H. Ringle, ErlbaumAssociates, 223-243.Hobbs, Jerry R. (1982b).
"Representingambiguity."
In Proceedings, 1st West CoastConference on Formal Linguistics, Stanford,California, 15-28.Hobbs, Jerry R. (1983a).
"Metaphorinterpretation asselective inferencing:cognitive processes in understandingmetaphor (Part 1)."
Empirical Studies of theArts, 1:17-33.Hobbs, Jerry R. (1983b).
"Metaphorinterpretation asselective inferencing:cognitive processes in understandingmetaphor (Part 2)."
Empirical Studies of theArts, 1:125-141.Hobbs, Jerry R. (1985).
"On the coherenceand structure of discourse."
TechnicalReport No.
CSLI-85-37, Center for theStudy of Language and Information(CSLI), Stanford University.Hobbs, Jerry R. and Martin, Paul (1987).
"Local Pragmatics."
In Proceedings, lOthInternational Joint Conference on ArtificialIntelligence (IJCAI-87), Milan, Italy,520-523.Huang, Xiuming (1985).
"Machinetranslation i  the SDCG (SemanticDefinite Clause Grammars) formalism.
"In Proceedings, Conference on Theoretical ndMethodological Issues in Machine Translationof Natural Languages, Colgate University,New York, New York, 135-144.Indurkhya, Bipin (1985).
"A computationaltheory of metaphor comprehension a danalogical reasoning."
Technical Report#85/001, Boston University.Indurkhya, Bipin (1987).
"Approximatesemantic transference: a computationaltheory of metaphors and analogies.
"Cognitive Science, 11(4):445-480.Indurkhya, Bipin (1988).
"Constrainedsemantic transference: a formal theory ofmetaphors."
In Analogica: Proceedings ofthe First Workshop on Analogical Reasoning,edited by Armand Prieditis, MorganKaufmann (Pitman Research Notes inArtificial Intelligence), Los Altos,California, 129-157.Jacobs, Paul S. (1985).
"A knowledge-basedapproach to language production.
"Technical Report No.
UCB/CSD 86/254,Computer Science Division (EECS),University of California, Berkeley.Jakobsen, Roman and Halle, Morris (1956).Fundamentals ofLanguage.
Mouton.Johnson, Mark (1980).
"A philosophicalperspective on the problems ofmetaphor."
In Cognition and FigurativeLanguage, dited by Richard P. Honeckand Robert R. Hoffman, 47-68, ErlbaumAssociates.Katz, Jerrold J.
(1964).
"Analyticity andcontradiction i natural language."
In TheStructure of Language: Readings in the Phil-osophy of Language, dited by J.A.
Fodorand J.J. Katz, 519-543, Prentice-Hall.Lakoff, George and Johnson, Mark (1980).Metaphors We Live By.
Chicago UniversityPress.Lees, R.B.
(1960).
"The grammar of Englishnominalizations."
International Journal ofAmerican Linguistics, 26(3).88Fass Discriminating MetonymyLenat, Douglas B. and Guha, R. V. (1990).Building Large Knowledge-Based Systems:Representation a d Inference in the CYCProject.
Addison-Wesley.Levin, Samuel R. (1977).
The Semantics ofMetaphor.
John Hopkins University Press.Loewenberg, Ina (1975).
"Identifyingmetaphors."
Foundations of Language,12:315-338.Malgady, R. and Johnson, M.
(1976).
"Modifiers in metaphors: effects ofconstituent phrase similarity on theinterpretation f figurative sentences.
"Journal of Psycholinguistic Research, 5:43-52.Martin, James H. (1990).
A ComputationalModel of Metaphor Interpretation.
AcademicPress.Martin, James H. (1988).
"A computationaltheory of metaphor."
Technical ReportNo.
UCB/CSD 88/465, Computer ScienceDivision (EECS), University of California,Berkeley.Martin, James H. (1985).
"Knowledgeacquisition through natural languagedialogue."
In Proceedings, 2nd AnnualConference on Artificial IntelligenceApplications, Miami, Florida.Matthews, R. J.
(1971).
"Concerning a'linguistic theory' of metaphor.
"Foundations of Language, 7:413-425.Miles, J.
(1967).
Style and Proportion.
Little,Brown and Co.Mish, Frederick C. (1986).
Webster's NinthNew Collegiate Dictionary.
Merriam-Webster Inc.Modiano, Nicole (1986).
"Two proceduresfor sense projection."
Unpublished ms.,Computing Research Laboratory, NewMexico State University.Van Noppen, Jean-Pierre; De Knop, S.; andJongen, R. (1985).
Metaphor: A Bibliographyof post-1970 Publications.
AmsterdamStudies in the Theory and History ofLinguistic Science (Series V: Library andInformation Sources in Linguistics),Volume 17, John Benjamins PublishingCompany.Ortony, Andrew (1980).
"Somepsycholinguistic aspects of metaphor."
InCognition and Figurative Language, editedby Richard P. Honeck and RobertR.
Hoffman, 69-83, Erlbaum Associates.Ortony, Andrew (1979).
"Beyond literalsimilarity."
Psychological Review,86:161-180.Percy, Walker (1954).
The Message in theBottle.
Farrar, Strauss, and Giroux.Quillian, M. Ross (1968).
"Semanticmemory."
In Semantic InformationProcessing, edited by Marvin Minsky,216-270, MIT Press.Perrine, Lawrence (1971).
"Psychologicalforms of metaphor."
College English,33:125-138.Reddy, Michael J.
(1979).
"The conduitmetaphor - -  a case of frame conflict inour language about language."
InMetaphor and Thought, edited by AndrewOrtony, 284-324, Cambridge UniversityPress.Reddy, Michael J.
(1969).
"A semanticapproach to metaphor."
In ChicagoLinguistic Society Collected Papers, ChicagoUniversity Press, 240-251.Richards, Ivor A.
(1936).
The Philosophy ofRhetoric.
Oxford University Press.Russell, Sylvia Weber (1976).
"Computerunderstanding of metaphorically usedverbs."
American J~ournal of ComputationalLinguistics, Microfiche 44.Schank, Roger C. (1975).
"The structure ofepisodes in memory."
In Representationand Understanding, edited by DanielG.
Bobrow and Allan Collins, 237-272.Academic Press.Schank, Roger C. (1973).
"Identification ofconceptualizations underlying naturallanguage."
In Computer Models of Thoughtand Language, edited by Roger C. Schankand Kenneth M. Colby, 187-247.W.H.
Freeman.Shibles, Warren (1971).
Metaphor: AnAnnotated Bibliography and History.
TheLanguage Press.Stern, Gustaf (1968).
(first published inSweden 1931) Meaning and Changes ofMeaning.
Indiana University Press.Tourangeau, Roger and Sternberg, Robert J.(1982).
"Understanding and appreciatingmetaphors."
Cognition, 11:203-244.Tversky, Amos (1977).
"Features ofsimilarity."
Psychological Review,84:327-352.Ullmann, Stephen (1962).
Semantics: AnIntroduction to the Science of Meaning.
BasilBlackwell & Mott Ltd.Waldron, Ronald A.
(1967).
Sense and SenseDevelopment.
Andre Deutsch.Weiner, E. Judith (1985).
"Solving thecontainment problem for figurativelanguage."
International Journal ofMan-Machine Studies, 23:527-537.Weiner, E. Judith (1984).
"A knowledgerepresentation approach to understandingmetaphors."
American Journal ofComputational Linguistics, 10:1-14.Wheelwright, P. (1962).
Metaphor and Reality.Indiana University Press.Wilks, Yorick A.
(1978).
"Makingpreferences more active."
ArtificialIntelligence, 11:197-223.89Computational Linguistics Volume 17, Number 1Wilks, Yorick A.
(1975b).
"An intelligentanalyzer and understander for English.
"Communications of the ACM, 18:264-274.Wilks,Yorick A.
(1975a).
"A preferentialpattern-seeking semantics for naturallanguage inference."
Artificial Intelligence,6:53-74.Wilks, Yorick A.
(1973).
"An artificialintelligence approach to machinetranslation."
In Computer Models ofThought and Language, edited by RogerC.
Schank and Kenneth M. Colby,114-151, W.H.
Freeman.Wilks, Yorick A. and Fass, Dan C. (In press).
"The preference semantics family."
Toappear in Computers and Mathematics withApplications, Special Issue on SemanticNetworks in Artificial Intelligence.Winston, Patrick H. (1980).
"Learning bycreatifying transfer frames."
In ArtificialIntelligence: An MIT Perspective, Volume 1,edited by Patrick H. Winston and RichardH.
Brown, 347-376, MIT Press.Yamanashi, Masa-aki (1987).
"Metonymicinterpretation and associative processes innatural anguage."
In Language andArtificial Intelligence (Proceedings ofanInternational Symposium on Language andArtificial Intelligence held in Kyoto, Japan,16-21 March 1986), edited by MakotoNagao, 77-86, Elsevier Science Publishers.Glossary of Main TermsAnomalous relation: a semantic relationindicated by a violated preference and theabsence of a relevant analogy \[seeSection 3\].Assertion: a word sense-based contextualconstraint in which semantic information isimposed onto the local context of a wordsense \[Section 3\].Collation: a process that discriminates thesemantic relation(s) between two wordsenses by matching the sense-frames for theword senses \[Section 4\].Literal relation: a semantic relation indicatedby a satisfied preference \[Section 3\].Metaphor: a trope in which one entity isused to view another entity to which itbears a partial resemblance \[Sections 2-7\].Metaphorical relation: a semantic relationindicated by a violated preference and thepresence of a relevant analogy \[Section 3\].Metonymy: a trope in which one entity isused to refer to another that is related to it\[Sections 2-7\].Metonymic relation: a semantic relationindicated by failure to satisfy a preferenceand the presence of one or more conceptualrelationships like PART-WHOLE \[Section 3\].Preference: a word sense-based contextualconstraint in which semantic informationrestricts the local context of a word sense\[Section 3\].Screening: a process that resolves lexicalambiguity by choosing among semanticvectors on the basis of rank orderingsamong semantic relations and a measure ofconceptual similarity \[Section 4\].Semantic relation: the basis of literalness,metonymy, metaphor, etc.
; found byevaluating lexical semantic onstraints insentences \[Section 3\].Semantic vector: a data structure thatrepresents semantic relations by recordingthe matches produced by collation\[Section 4\].Sense-frame: a framelike data structure thatrepresents a word sense and is composed ofother word senses having their ownsense-frames \[Section 4\].Sense-network: a semantic network of wordsenses formed from information insense-frames \[Section 4\].Source: the lexical item in a semanticrelation whose contextual constraint(s) areenforced \[Section 3\].Target: the lexical item in a semantic relationon which contextual constraint(s) areapplied \[Section 3\].Trope: the technical term for a nonliteralfigure of speech, e.g., metaphor, metonymy,simile, understatement (li otes),overstatement (hyperbole), and irony\[Section 1\].90
