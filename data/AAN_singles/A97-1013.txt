Developing a hybrid NP  parserAtro Vouti lainenDepartment of General LinguisticsP.O.
Box 4FIN-00014 University of HelsinkiFinlandavout ila@ling, helsinki, fiLlufs Padr6Dept.
Llenguatges i Sistemes InformS, ticsUniversitat Polit~cnica de CatalunyaC/Grail Capit~ s/n.
08034 BarcelonaCataloniapadro@ls i ,  upc.
esAbstractWe describe the use of energy function op-timisation in very shallow syntactic pars-ing.
The approach can use linguisticrules and corpus-based statistics, so thestrengths of both linguistic and statisti-cal approaches to NLP can be combinedin a single framework.
The rules are con-textual constraints for resolving syntacticambiguities expressed as alternative tags,and the statistical language model consistsof corpus-based n-grams of syntactic tags.The success of the hybrid syntactic dis-ambiguator is evaluated against a held-outbenchmark corpus.
Also the contributionsof the linguistic and statistical languagemodels to the hybrid model are estimated.1 IntroductionThe language models used by natural anguage an-alyzers are traditionally based on two approaches.In the linguistic approach, the model is based onhand-crafted rules derived from the linguist's gen-eral and/or corpus-based knowledge about the ob-ject language.
In the data-driven approach, themodel is automatically generated from annotatedtext corpora, and the model can be represented e.g.as n-grams (Garside t al., 1987), local rules (Hindle,1989) or neural nets (Schmid, 1994).Most hybrid approaches combine statistical infor-mation with automatically extracted rule-based in-formation (Brill, 1995; Daelemans et al, 1996).
Rel-atively little attention has been paid to models wherethe statistical approach is combined with a truly lin-guistic model (i.e.
one generated by a linguist).
Thispaper reports one such approach: syntactic ruleswritten by a linguist are combined with statisticalinformation using the relaxation labelling algorithm.80Our application is very shallow parsing: identifi-cation of verbs, premodifiers, nominal and adverbialheads, and certain kinds of postmodifiers.
We callthis parser a noun phrase parser.The input is English text morphologically taggedwith a rule-based tagger called EngCG (Voutilainenet al, 1992; Karlsson et al, 1995).
Syntactic word-tags are added as alternatives (e.g.
each adjectivegets a premodifier tag, postmodifier tag and a nomi-nal head tag as alternatives).
The system should re-move contextually illegitimate tags and leave intacteach word's most appropriate tag.
In other words,the syntactic language model is applied by a disam-biguator.The parser has a recall of 100% if all words retainthe correct morphological nd syntactic reading; thesystem's precision is 100% if the output contains noillegitimate morphological or syntactic readings.
Inpractice, some correct readings are discarded, andsome ambiguities remain unresolved (i.e.
some wordsretain two or more alternative analyses).The system can use linguistic rules and corpus-based statistics.
Notable about the system is thatminimal human effort was needed for creating itslanguage models (the linguistic consisting of syn-tactic disambiguation rules based on the ConstraintGrammar framework (Karlsson, 1990; Karlsson etal., 1995); the corpus-based consisting of bigramsand trigrams):Only one day was spent on writing the 107 syn-tactic disambiguation rules used by the linguis-tic parser.No human annotators were needed for annotat-ing the training corpus (218,000 words of jour-nalese) used by the data-driven learning mod-ules of this system: the training corpus was an-notated by (i) tagging it with the EngCG mor-phological tagger, (ii) making the tagged textsyntactically ambiguous by adding the alterna-tive syntactic tags to the words, and (iii) re-solving most of these syntactic ambiguities byapplying the parser with the 107 disambigua-tion rules.The system was tested against a fresh sample of fivetexts (6,500 words).
The system's recall and pre-cision was measured by comparing its output to amanually disambiguated version of the text.
To in-crease the objectivity of the evaluation, system out-puts and the benchmark corpus are made publiclyaccessible (see Section 6).Also the relative contributions of the linguisticand statistical components are evaluated.
The lin-guistic rules seldom discard the correct ag, i.e.
theyhave a very high recall, but their problem is remain-ing ambiguity.
The problems of the statistical com-ponents are the opposite: their recall is considerablylower, but more (if not all) ambiguities are resolved.When these components are used in a balanced way,the system's overall recall is 97.2% - that is, 97.2%of all words get the correct analysis - and its preci-sion is 96.1% - that is, of the readings returned bythe system, 96.1% are correct.The system architecture is presented in Figure 1.Ambiguous \[ ~ I Partially"training co ~ - ; :, dis.~, biguatedHybrid language modelAmbiguous ~ Di.~mbig~t exltest c?rpus I ~ I test c?rpusFigure 1: Parser architecture.The structure of the paper is the following.
First,we describe our general framework, the relaxationlabelling algorithm.
Then we proceed to the appli-cation by outlining the grammatical representationused in our shallow syntax.
After this, the disam-biguation rules and their development are described.Next in turn is a description of how the data-drivenlanguage model was generated.
The evaluation of81the system is then presented: first the preparationof the benchmark corpus is described, then the re-sults of the tests are given.
The paper ends withsome concluding remarks.2 The Relaxation LabellingAlgorithmSince we are dealing with a set of constraints andwant to find a solution which optimally satisfiesthem M1, we can use a standard Constraint Satis-faction algorithm to solve that problem.Constraint Satisfaction Problems are naturallymodelled as Consistent Labeling Problems (Larrosaand Meseguer, 1995).
An algorithm that solvesCLPs is Relaxation Labelling.It has been applied to part-of-speech tagging(Padr6, 1996) showing that it can yield as good re-sults as a HMM tagger when using the same in-formation.
In addition, it can deal with any kindof constraints, thus the model can be improvedby adding any other constraints available, eitherstatistics, hand-written or automatically extracted(Mhrquez and Rodrfguez, 1995; Samuelsson et al,1996).Relaxation labelling is a generic name for a familyof iterative algorithms which perform function opti-misation, based on local information.
See (Torras,1989) for a summary.Given a set of variables, a set of possible labels foreach variable, and a set of compatibility constraintsbetween those labels, the algorithm finds a combina-tion of weights for the labels that maximises "globalconsistency" (see below).Let V = {vl, v2, .
.
.
,  v,~} be a set of variables.Let tl {til ti2, i = , .
.
.
, tmi  ) be the set of possiblelabels for variable vi.Let CS be a set of constraints between the labelsof the variables.
Each constraint C E CS  states a"compatibility value" Cr for a combination of pairsvariable-label.
Any number of variables may be in-volved in a constraint.The aim of the algorithm is to find a weightedlabelling I such that "global consistency" is max-imised.
Maximising "global consistency" is definedas maximising ~ j  p~.
x Sij , Vvi, where p~.
is theweight for label j in variable vi and Sij the supportreceived by the same combination.
The support forthe pair variable-label xpresses how compatible thatpair is with the labels of neighbouring variables, ac-cording to the constraint set.1A weighted labelling is a weight assignment for eachlabel of each variable such that the weights for the labelsof the same variable add up to one.The support is defined as the sum of the influenceof every constraint on a label.Sij = ~ Inf(r)rER~jwhere:R~j is the set of constraints on label j for variablei, i.e.
the constraints formed by any combination ofvariable--label pairs that includes the pair (vi, tj).r l  fd  Inf(r) = Cr x Pk,(m) x .
.
.
x Pkd(m), is the prod-uct of the current weights 2 for the labels appearingin the constraint except (vi,tj) (representing howapplicable the constraint is in the current context)multiplied by Cr which is the constraint compatibil-ity value (stating how compatible the pair is with thecontext).Briefly, what the algorithm does is:1.
Start with a random weight assignment.2.
Compute the support value for each label ofeach variable.
(How compatible it is with thecurrent weights for the labels of the other vari-ables.)3.
Increase the weights of the labels more compat-ible with the context (support greater than 0)and decrease those of the less compatible labels(support less than 0) 3 , using the updating func-tion:p~.
(rn) x (1 + Sij)pj(m + 1) =?
(1 + S,k)k=lwhere - l~S i j _~+l4.
If a stopping/convergence criterion 4 is satisfied,stop, otherwise go to to step 2.3 Grammat ica l  representat ionThe input of our parser is morphologically analyzedand disambiguated text enriched with alternativesyntactic tags, e.g.
"<others>""other" PRON N0M PL @>N @NH2p~(m) is the weight assigned to label k for variabler at time m.SNegative values for support indicate incompatibility.4The usual criterion is to stop when there are no morechanges, although more sophisticated heuristic proce-dures are also used to stop relaxation processes (Eklundhand Rosenfeld, 1978; Richards et al , 1981).
"<moved>""move" <SV> <SV0> V PAST VFIN @V"<away>""away" ADV ADVL @>A @AH"<from>""from" PREP @DUMMY"<tradit ional>""traditional" A ABS @>N @N< @NH"<jazz>""jazz" <-Indef> N NOM SG @>N @NH"<practice>""practice" N N0M SG @>N @NH"practice" <SV0> V PRES -SG3 VFIN @VEvery indented line represents a morphologicalreading; the sample shows that some morphologicalambiguities are not resolved by the rule-based mor-phological disambiguator, known as the EngCG tag-ger (Voutilainen et al, 1992; Karlsson et al, 1995).Our syntactic tags start with the "@" sign.
Aword is syntactically ambiguous if it has more thanone syntactic tags (e.g.
practice above has three al-ternative syntactic tags).
Syntactic tags are addedto the morphological nalysis with a simple lookupmodule.
The syntactic parser's main task is dis-ambiguating (rather than adding new informationto the input sentence): contextuMly illegitimate al-ternatives should be discarded, while legitimate tagsshould be retained (note that also morphological m-biguities may be resolved as a side effect).Next we describe the syntactic tags:?
@>N represents premodifiers and determiners.?
@N< represents a restricted range of postmod-ifiers and the determiner "enough" following itsnominal head.?
@NH represents nominal heads (nouns, adjec-tives, pronouns, numerals, ING-forms and non-finite ED-forms).?
@>A represents those adverbs that premodify(intensify) adjectives (including adjectival ING-forms and non-finite ED-forms), adverbs andvarious kinds of quantifiers (certain determin-ers, pronouns and numerals).?
@AH represents adverbs that function as headof an adverbial phrase.?
@A< represents the postmodifying adverb"enough".?
@V represents verbs and auxiliaries (incl.
theinfinitive marker "to").82?
@>CC represents words introducing a coordi-nation (" either", "neither", "both" ).?
@CC represents coordinating conjunctions.
* @CS represents subordinating conjunctions.. @DUMMY represents all prepositions, i.e.
theparser does not address the attachment ofprepositional phrases.4 Syntact i c  ru les4.1 Ru le  fo rmal i smThe rules follow the Constraint Grammar formal-ism, and they were applied using the recent parser-compiler CG-2 (Tapanainen, 1996).
The parserreads a sentence at a time and discards thoseambiguity-forming readings that are disallowed bya constraint.Next we describe some basic features of the ruleformalism.
The ruleR~.HOV~.
(?>hi)(,ic <<< OR (?V) OR (~CS) BARRIER (@NH));removes the premodifier tag @>N from an ambigu-ous reading if somewhere to the right (*1) there isan unambiguous (C) occurrence of a member of theset <<< (sentence boundary symbols) or the verbtag @V or the subordinating conjunction tag @CS,and there are no intervening tags for nominal heads(@NH).This is a partial rule about coordination:REMOVE (?>N)(NOT 0 (DET) OR (NUM) OR (A))( l c  (cc) )(2C (DET)) ;It removes the premodifier tag if all three context-conditions are satisfied:?
the word to be disambiguated (0) is not a de-terminer, numeral or adjective,?
the first word to the right (1) is an unambiguouscoordinating conjunction, and?
the second word to the right is an unambiguousdeterminer.In addition to REMOVing, also SELECTing a read-ing is possible: when all context-conditions are sat-isfied, all readings but the one the rule was expresslyabout are discarded.The rules can refer to words and tags directly orby means of predefined sets.
They can refer not onlyto any fixed context positions; also reference to con-textual patterns is possible.
The rules never discarda last reading, so every word retains at least oneanalysis.
On the other hand, an ambiguity remainsunresolved if there are no rules for that particulartype of ambiguity.4.2 Grammar  deve lopmentA day was spent on writing 107 constraints; about15,000 words of the parser's output were proofreadduring the process.
The routine was the following:1.
The current grammar (containing e.g.
2 rules)is applied to the ambiguous input in a 'trace'mode in which the parser also indicates, whichrule discarded which analysis,2.
The grammarian observes remaining ambigui-ties and proposes new rules for disambiguatingthem, and3.
He also tries to identify misanalyses (caseswhere the correct tag is discarded) and, usingthe trace information, corrects the faulty ruleThis routine is useful if the development time isvery restricted, and only the most common ambigu-ity types have to be resolved with reasonable suc-cess.
However, if the grammar should be of a veryhigh quality (extremely few mispredictions, high de-gree of ambiguity resolution), a large test corpus,formally similar to the input except for the manuallyadded extra information about the correct analysis,should be used.
This kind of test corpus would en-able the automatic identification of mispredictionsas well as counting of various performance statisticsfor the rules.
However, manually disambiguating atest corpus of a few hundred thousand words wouldprobably require a human effort of at least a month.4.3 Sample  outputThe following is genuine output of the linguistic(CG-2) parser using the 107 syntactic disambigua-tion rules.
The traces starting with "S:" indicatethe line on which the applied rule is in the grammarfile.
One syntactic (and morphological) ambiguityremains unresolved: until remains ambiguous due topreposition and subordinating conjunction readings.
"<aachen>"  S :46"aachen" <*> <Proper> hl hiOM SG ~1~"<remained>""remain" <SVC/N> <SVC/A> V PAST VFIN @V"<a>""a" <Indef> DET CENTRAL ART SG @>N"<free>" S:316, 4983"free" A ABS @>N"<imperial>" S:49, 57"imperial" A ABS @>N"<city>" S:46"city" N N0M SG @NH"<until>""until" PREP @DUMMY"until" <**CLB> CS @CS"<occupied>" S: 116, 345, 46"occupy" <SVO> PCP2 @V"<by>""by" PREP ~DUMMY"<france>" S :46"france" <*> <Proper> N N0M SG @NH"<in>""in" PREP @DUMMY"<1794>" S:121, 49"1794" <1900> NUM CARD @NH,,<$.>,,5 Hybrid language modelTo solve shallow parsing with the relaxation labellingalgorithm we model each word in the sentence as avariable, and each of its possible readings as a labelfor that variable.
We start with a uniform weightdistribution.We will use the algorithm to select the right syn-tactic tag for every word.
Each iteration will in-crease the weight for the tag which is currentlymost compatible with the context and decrease theweights for the others.Since constraints are used to decide how compat-ible a tag is with its context, they have to assessthe compatibil ity of a combination of readings.
Weadapt CG constraints described above.The REMOVE constraints express total incom-patibility 5 and SELECT constraints express totalcompatibil ity (actually, they express incompatibil ityof all other possibilities).The compatibil ity value for these should be atleast as strong as the strongest value for a statisti-cally obtained constraint (see below).
This producesa value of about -4-10.But because we want the linguistic part of themodel to be more important than the statistical partand because a given label will receive the influenceSWe model compatibility values using mutual infor-mation (Cover and Thomas, 1991), which enables usto use negative numbers to state incompatibility.
See(PadrS, 1996) for a performance comparison betweenM.I.
and other measures when applying relaxation la-belling to NLP.84of about two bigrams and three trigrams 6, a sin-gle linguistic constraint might have to override fivestatistical constraints.
So we will make the compat-ibility values six times stronger, that is, =h60.Since in our implementation of the CG parser(Tapanainen, 1996) constraints tend to be appliedin a certain order - e.g.
SELECT constraints areusually applied before REMOVE constraints - weadjust the compatibil ity values to get a similar ef-fect: if the value for SELECT constraints is +60,the value for REMOVE constraints will be lowerin absolute value, (i.e.
-50) .
With this we ensurethat two contradictory constraints (if there are any)do not cancel each other.
The SELECT constraintwill win, as if it had been applied before.This enables using any Constraint Grammar  withthis algorithm although we are applying it more flex-ibly: we do not decide whether a constraint is ap-plied or not.
It is always applied with an influence(perhaps zero) that depends on the weights of thelabels.I f  the algorithm should apply the constraints ina more strict way, we can introduce an influencethreshold under which a constraint does not haveenough influence, i.e.
is not applied.We can add more information to our model in theform of statistically derived constraints.
Here we usebigrams and trigrams as constraints.The 218,000-word corpus of journalese from whichthese constraints were extracted was analysed usingthe following modules:* EngCG morphological tagger?
Module for introducing syntactic ambiguities?
The NP disambiguator using the 107 rules writ-ten in a dayNo human effort was spent on creating this train-ing corpus.
The training corpus is partly ambigu-ous, so the bi / tr igram information acquired will beslightly noisy, but accurate nough to provide an al-most supervised statistical model.For instance, the following constraints have beenstatistically extracted from bi / t r igram occurrencesin the training corpus.-0.415371 (@Y)(1 (e>N))  ;6The algorithm tends to select one label per variable,so there is always a bi/trigram which is applied moresignificantly than the others.4.
28089 (?>A)(-1 (~>A))(1 (?AH)) ;The compatibility value is the mutual informa-tion, computed from the probabilities estimatedfrom a training corpus.
We do not need to assignthe compatibility values here, since we can estimatethem from the corpus.The compatibility values assigned to the hand-written constraints express the strength of these con-straints compared to the statistical ones.
Modifyingthose values means changing the relative weights ofthe linguistic and statistical parts of the model.6 P reparat ion  o f  the  benchmarkcorpusFor evaluating the systems, five roughly equal-sizedbenchmark corpora not used in the development ofour parsers and taggers were prepared.
The texts,totaling 6,500 words, were copied from the Guten-berg e-text archive, and they represent present-dayAmerican English.
One text is from an article aboutAIDS; another concerns brainwashing techniques;the third describes guerilla warfare tactics; thefourth addresses the assassination of J. F. Kennedy;the last is an extract from a speech by Noam Chom-sky.The texts were first analysed by a recent versionof the morphological analyser and rule-based dis-ambiguator EngCG, then the syntactic ambiguitieswere added with a simple lookup module.
The am-biguous text was then manually disambiguated.
Thedisambiguated texts were also proofread afterwards.Usually, this practice resulted in one analysis perword.
However, there were two types of exception:1.
The input did not contain the desired alterna-tive (due to a morphological disambiguation er-ror).
In these cases, no reading was markedas correct.
Two such words were found in thecorpora; they detract from the performance fig-ures.2.
The input contained more than one analyses allof which seemed equally legitimate, even whensemantic and textual criteria were consulted.In these cases, all the equal alternatives weremarked as correct.
The benchmark corpus con-tains 18 words (mainly ING-forms and nonfiniteED-forms) with two correct syntactic analyses.The number of multiple analyses could proba-bly be made even smaller by specifying the gram-matical representation (usage principles of the syn-85tactic tags) in more detail, in particular incorpo-rating some analysis conventions for certain appar-ent borderline cases (for a discussion of specify-ing a parser's linguistic task, see (Voutilainen andJ~rvinen, 1995)).To improve the objectivity of the evaluation, thebenchmark corpus (as well as parser outputs) havebeen made available from the following URLs:http://www.ling.helsinki.fi/-avoutila/anlp97.htmlhttp://www-lsi.upc.es/-l luisp/anlp97.html7 Exper iments  and  resu l tsWe tested linguistic, statistical and hybrid languagemodels, using the CG-2 parser (Tapanainen, 1996)and the relaxation labelling algorithm described inSection 2.The statistical models were obtained from a train-ing corpus of 218,000 words of journalese, syntac-tically annotated using the linguistic parser (seeabove).Although the linguistic CG-2 parser does not dis-ambiguate completely, it seems to have an almostperfect recall (cf.
Table 1 below), and the noise in-troduced by the remaining ambiguity is assumed tobe sufficiently lower than the signal, following theidea used in (Yarowsky, 1992).The collected statistics were bigram and trigramoccur rences .The algorithms and models were tested against ahand-disambiguated benchmark corpus of over 6,500words.We measure the performance of the different mod-els in terms of recall and precision.
Recall is thepercentage of words that get the correct tag amongthe tags proposed by the system.
Precision is thepercentage of tags proposed by the system that arecorrect.CCG-2  parser  Rel.
Labe l l ingprec.
- recal l  prec.
- recal l90 .8%-  99.7% 93.3%-  98.4%Table 1: Results obtained with the linguistic model.Rel.
Labe l l ingprec.
- recal lB 87.4% - 88.0%T 87.6% - 88.4%BT  88 .1%-  88.8%Table 2: Results obtained with statistical models.Rel.
Labellingprec.
- recal lBC  96.0%-  97.0%TC 95.9%-  97.0%BTC 96.1%-  97.2%Table 3: Results obtained with hybrid models.Precision and recall results (computed on allwords except punctuation marks, which are unam-biguous) are given in tables 1, 2 and 3.
Models arecoded as follows: B stands for bigrams, T for tri-grams and C for hand-written constraints.
All com-binations of information types are tested.
Since theCG-2 parser handles only Constraint Grammars, wecannot test this algorithm with statistical models.These results suggest he following conclusions:?
Using the same language model (107 rules), therelaxation algorithm disambiguates more thanthe CG-2 parser.
This is due to the weightedrule application, and results in more misanaly-ses and less remaining ambiguity.?
The statistical models are clearly worse than thelinguistic one.
This could be due to the noise inthe training corpus, but it is more likely causedby the difficulty of the task: we are dealing herewith shallow syntactic parsing, which is prob-ably more difficult to capture in a statisticalmodel than e.g.
POS tagging.?
The hybrid models produce less ambiguous re-sults than the other models.
The number oferrors is much lower than was the case with thestatistical models, and somewhat higher thanwas the case with the linguistic model.
The gainin precision seems to be enough to compensatefor the loss in recall 7.?
There does not seem to be much difference be-tween BC and TC hybrid models.
The reason isprobably that the job is mainly done by the lin-guistic part of the model - which has a higherrelative weight - and that the statistical partonly helps to disambiguate cases where the lin-guistic model doesn't make a prediction.
TheBTC hybrid model is slightly better than theother two.?
The small difference between the hybrid modelssuggest hat some reasonable statistics provideenough disambiguation, and that not very so-phisticated information is needed.7This obviously depends on the flexibility of one'srequirements.868 Discuss ionIn this paper we have presented a method for com-bining linguistic hand-crafted rules with statisticalinformation, and we applied it to a shallow parsingtask.Results show that adding statistical informationresults in an increase in the disambiguation ratio,getting a higher precision.
The price is a decreasein recall.
Nevertheless, the risk can be controlledsince more or less statistical information can be useddepending on the precision/recall tradeoff one wantsto achieve.We also used this technique to build a shallowparser with minimal human effort:?
107 disambiguation rules were written in a day.?
These rules were used to analyze a training cor-pus, with a very high recall and a reasonableprecision.?
This slightly ambiguous training corpus is usedfor collecting bigram and trigram occurrences.The noise introduced by the remaining ambigu-ity is assumed not to distort the resulting statis-tics too much.?
The hand-written constraints and the statisticsare combined using a relaxation algorithm toanalyze the test corpus, rising the precision to96.1% and lowering the recall only to 97.2%.Finally, a reservation must be made: what we havenot investigated in this paper is how much of theextra work done with the statistical module couldhave been done equally well or even better by spend-ing e.g.
another day writing a further collection ofheuristic rules.
As suggested e.g.
by Tapanainenand Voutilainen (1994) and Chanod and Tapanainen(1995), hand-coded heuristics may be a worthwhileaddition to 'strictly' grammar-based rules.AcknowledgementsWe wish to thank Timo J/irvinen, Pasi Tapanalnenand two ANLP'97 referees for useful comments onearlier versions of this paper.The first author benefited from the collaborationof Juha Heikkil~ in the development of the linguisticdescription used by the EngCG morphological tag-ger; the two-level compiler for morphological nMy-sis in EngCG was written by Kimmo Koskenniemi;the recent version of the Constraint Grammar parser(CG-2) was written by Pasi Tapanainen.
The Con-straint Grammar framework was originally proposedby Fred Karlsson.ReferencesE.
Brill.
1995.
Unsupervised Learning of Disam-biguation Rules for Part-of-speech Tagging.
InProceedings of 3rd Workshop on Very Large Cor-pora, Massachusetts.J.-P. Chanod and P. Tapanainen 1995.
TaggingFrench: comparing a statistical and a constraint-based method.
In Proc.
EACL'95.
ACL, Dublin.T.M.
Cover and J.A.
Thomas (Editors) 1991.
Ele-ments of information theory.
John Wiley & Sons.J.
Eklundh and A. Rosenfeld.
1978.
ConvergenceProperties of Relaxation Labelling.
Technical Re-port no.
701.
Computer Science Center.
Univer-sity of Maryland.W.
Daelemans, J. Zavrel, P. Berck and S. Gillis.1996.
MTB: A Memory-Based Part-of-SpeechTagger Generator.
In Proceedings of ~th Work-shop on Very Large Corpora.
Copenhagen, Den-mark.R.
Garside, G. Leech and G. Sampson (Editors)1987.
The Computational Analysis of English.London and New York: Longman.D.
Hindle.
1989.
Acquiring disambiguation rulesfrom text.
In Proc.
A CL'89.F.
Karlsson 1990.
Constraint Grammar as a Frame-work for Parsing Running Text.
In H.
Karlgren(ed.
), Papers presented to the 13th InternationalConference on Computational Linguistics, Vol.
3.Helsinki.
168-173.F.
Karlsson, A. Voutilainen, J. HeikkilK andA.
Anttila.
(Editors) 1995.
Constraint Grammar:A Language-Independent System for Parsing Un-restricted Text.
Mouton de Gruyter, Berlin andNew York.C.
Samuelsson, P. Tapanainen and A. Voutilainen.1996.
Inducing Constraint Grammars.
In Pro-ceedings of the 3rd International Colloquium onGrammatical Inference.H.
Schmid 1994.
Part-of-speech tagging with neu-ral networks.
In Proceedings of15th InternationalConference on Computational Linguistics, Kyoto,Japan.P.
Tapanainen 1996.
The Constraint GrammarParser CG-2.
Department ofGeneral Linguistics,University of Helsinki.P.
Tapanainen and A. Voutilainen 1994.
Taggingaccurately - Don't guess if you know.
In Pro-ceedings of the 4th Conference on Applied NaturalLanguage Processing, ACL.
Stuttgart.C.
Torras.
1989.
Relaxation and Neural Learning:Points of Convergence and Divergence.
Journal ofParallel and Distributed Computing, 6:217-244A.
Voutilainen, J. HeikkilK and A. Anttila 1992.Constraint Grammar of English.
A Performance-Oriented Introduction.
Publications 21, De-partment of General Linguistics, University ofHelsinki.A.
Voutilainen and T. JErvinen.
1995.
Specifyinga shallow grammatical representation for parsingpurposes.
In Proceedings ofthe 7th meeting of theEuropean Association for Computational Linguis-tics.
210-214.D.
Yarowsky.
1992.
Word-sense disambiguations us-ing statistical models of Roget's categories trainedon large corpora.
In Proceedings of 14th Interna-tional Conference on Computational Linguistics.Nantes, France.J.
Larrosa and P. Meseguer.
1995.
An Optimization-based Heuristic for Maximal Constraint Satisfac-tion.
In Proceedings of International Conferenceon Principles and Practice of Constraint Program-ming.L.
Mhrquez and H. Rodriguez.
1995.
TowardsLearning a Constraint Grammar from AnnotatedCorpora Using Decision Trees.
ESPRIT BRA-7315 Acquilex II, Working Paper.L.
Padr6.
1996.
POS Tagging Using RelaxationLabelling.
In Proceedings of 16th InternationalConference on Computational Linguistics, Copen-hagen, Denmark.J.
Richards, D. Landgrebe and P. Swain.
1981.
Onthe accuracy of pixel relaxation labelling.
In IEEETransactions on System, Man and Cybernetics.Vol.
SMC-1187
