Language Learning: Beyond ThunderdomeChristopher D. ManningComputer Science DepartmentStanford UniversityStanford, CA 94305-9040manning@cs.stanford.eduRemember: no matter where you go, there youare.The eight years from 1988 to 1996 saw the introduc-tion and soon widespread prevalence of probabilistic gen-erative models in NLP.
Probabilities were the answer tolearning, robustness and disambiguation, and we were allBayesians, if commonly in a fairly shallow way.
Theeight years from 1996 to 2004 saw the rise to preemi-nence of discriminative models.
Soon we were all eitherusing SVMs or (in a few cases like myself) arguing thatother discriminative techniques were equally as good: thesources of insight were margins and loss functions.What might the next eight years hold?
There willdoubtless be many more variants of SVMs deployed, butit seems much less likely to me that major progress willcome from new learning methods.
NLP pretty much al-ready uses what is known, and commonly the differencebetween one kernel or prior and another is small indeed.If we are waiting for better two class classifiers to pushthe performance of NLP systems into new realms, thenwe may be waiting a very long time.
What other oppor-tunities are there?One answer is to rely on more data, and this answerhas been rather fashionable lately.
Indeed, it has beenknown for a while now that ?There?s no data like moredata?.
One cannot argue with the efficacy of this solu-tion if you are dealing with surface visible properties of alanguage with ample online text, and dealing with a stan-dard problem over a stationary data set.
Or if you have somuch money that you can compensate for lacks from anyof those directions.
But I do not think this approach willwork for most of us.Something that has almost snuck up upon the field isthat with modern discriminative approaches and the cor-responding widely available software, anyone with mod-est training can deploy state of the art classification meth-ods.
What then determines the better systems?
The fea-tures that they use.
As a result, we need more linguistsback in the field (albeit ones with training in empirical,quantitative methods, who are still in short supply, espe-cially in North America).
This viewpoint is still some-what unfashionable, but I think it will increasingly beseen to be correct.
If you look through the results of re-cent competitive evaluations, such as the various CoNLLShared Task evaluations, many of the groups are usingsimilar or the same machine learning methods.
The of-ten substantial differences between the systems is mainlyin the features employed.
In the context of language,doing ?feature engineering?
is otherwise known as do-ing linguistics.
A distinctive aspect of language process-ing problems is that the space of interesting and usefulfeatures that one could extract is usually effectively un-bounded.
All one needs is enough linguistic insight andtime to build those features (and enough data to estimatethem effectively).A second direction of the field is a renewed intererstin the deeper problems of NLP: semantics, pragmatic in-terpretation, and discourse.
For both this issue and theprevious one, issues of representation become central.
Atdeeper levels of processing, there is less agreement onrepresentations, and less understanding of what are ef-fective representations for language learning.
Much ofour recent work in NLP has shown the importance andeffectiveness of good representations for both unsuper-vised and supervised natural language learning problems.Working with good representations will be even more im-portant for deeper NLP problems, and will see a revivalof rich linguistic representations like in the 1980s.Finally, a third direction (and perhaps the most pro-ductive area for new types of machine learning research)is to build systems that work effectively from less data.Whether trying to build a text classifier that can classifyemail into a folder based on only two examples, port-ing your work to a different Arabic dialect, or wantingto incorporate context into parsing and semantic interpre-tation, the challenge is how to build systems that learnfrom just a little data.
This is also the cognitive sciencechallenge of tackling the phenomenon of one-shot learn-ing, and it requires some different thinking from that ofrelying on large hand-labeled data sets.
