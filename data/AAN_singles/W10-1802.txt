Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 11?19,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsError-tagged Learner Corpus of CzechJirka HanaCharles UniversityPrague, Czech Republicfirst.last@gmail.comAlexandr RosenCharles UniversityPrague, Czech Republicalexandr.rosen@ff.cuni.czSvatava ?kodov?Technical UniversityLiberec, Czech Republicsvatava.skodova@tul.czBarbora ?tindlov?Technical UniversityLiberec, Czech Republicbarbora.stindlova@tul.czAbstractThe paper describes a learner corpus ofCzech, currently under development.
Thecorpus captures Czech as used by non-native speakers.
We discuss its structure,the layered annotation of errors and the an-notation process.1 IntroductionCorpora consisting of texts produced by non-native speakers are becoming an invaluable sourceof linguistic data, especially for foreign languageeducators.
In addition to morphosyntactic tag-ging and lemmatisation, common in other corpora,learner corpora can be annotated by informationrelevant to the specific nonstandard language ofthe learners.
Cases of deviant use can be identi-fied, emended and assigned a tag specifying thetype of the error, all of which helps to exploit therichness of linguistic data in the texts.
However,annotation of this kind is a challenging tasks, evenmore so for a language such as Czech, with itsrich inflection, derivation, agreement, and largelyinformation-structure-driven constituent order.
Atypical learner of Czech makes errors across alllinguistic levels, often targeting the same formseveral times.The proposed annotation scheme is an attemptto respond to the requirements of annotating a de-viant text in such a language, striking a compro-mise between the limitations of the annotation pro-cess and the demands of the corpus user.
Thethree-level format allows for successive emenda-tions, involving multiple forms in discontinuoussequences.
In many cases, the error type fol-lows from the comparison of the faulty and cor-rected forms and is assigned automatically, some-times using information present in morphosyntac-tic tags, assigned by a tagger.
In more complexcases, the scheme allows for representing relationsmaking phenomena such as the violation of agree-ment rules explicit.After an overview of issues related to learnercorpora in ?2 and a brief introduction to the projectof a learner corpus of Czech in ?3 we present theconcept of our annotation scheme in ?4, followedby a description of the annotation process in ?5.2 Learner corporaA learner corpus, also called interlanguage or L2corpus, is a computerised textual database of lan-guage as produced by second language (L2) learn-ers (Leech, 1998).
Such a database is a very pow-erful resource in research of second language ac-quisition.
It can be used to optimise the L2 learn-ing process, to assist authors of textbooks and dic-tionaries, and to tailor them to learners with a par-ticular native language (L1).More generally, a learner corpus ?
like othercorpora ?
serves as a repository of authentic dataabout a language (Granger, 1998).
In the do-main of L2 acquisition and teaching of foreign lan-guages, the language of the learners is called in-terlanguage (Selinker, 1983).1 An interlanguageincludes both correct and deviant forms.
The pos-sibility to examine learners?
errors on the back-ground of the correct language is the most impor-tant aspect of learner corpora (Granger, 1998).Investigating the interlanguage is easier whenthe deviant forms are annotated at least by theircorrect counterparts, or, even better, by tags mak-ing the nature of the error explicit.
Although1Interlanguage is distinguished by its highly individualand dynamic nature.
It is subject to constant changes asthe learner progresses through successive stages of acquiringmore competence, and can be seen as an individual and dy-namic continuum between one?s native and target languages.11learner corpora tagged this way exist, the twodecades of research in this field have shown thatdesigning a tagset for the annotation of errors is atask highly sensitive to the intended use of the cor-pus and the results are not easily transferable fromone language to another.Learner corpora can be classified according toseveral criteria:?
Target language (TL): Most learner corporacover the language of learners of English as asecond or foreign language (ESL or EFL).
Thenumber of learner corpora for other languagesis smaller but increasing.?
Medium: Learner corpora can capture writtenor spoken texts, the latter much harder to com-pile, thus less common.?
L1: The data can come from learners with thesame L1 or with various L1s.?
Proficiency in TL: Some corpora gather texts ofstudents at the same level, other include texts ofspeakers at various levels.
Most corpora focuson advanced students.?
Annotation: Many learner corpora contain onlyraw data, possibly with emendations, with-out linguistic annotation; some include part-of-speech (POS) tagging.
Several include er-ror tagging.
Despite the time-consuming man-ual effort involved, the number of error-taggedlearner corpora is growing.Error-tagged corpora use the following tax-onomies to classify the type of error:?
Taxonomies marking the source of error: Thelevel of granularity ranges from broad cate-gories (morphology, lexis, syntax) to more spe-cific ones (auxiliary, passive, etc.).?
Taxonomies based on formal types of alterna-tion of the source text: omission, addition, mis-formation, mis-ordering.?
Hierarchical taxonomies based on a combina-tion of various aspects: error domain (formal,grammatical, lexical, style errors), error cate-gory (agglutination, diacritics, derivation inflec-tion, auxiliaries, gender, mode, etc.
), word cat-egory (POS).?
Without error taxonomies, using only correctionas the implicit explanation for an error.In Table 1 we present a brief summary of ex-isting learner corpora tagged by POS and/or er-ror types, including the size of the corpus (in mil-lions of words or Chinese characters), the mothertongue of the learners, or ?
in case of learnerswith different linguistic backgrounds ?
the num-ber of mother tongues (L1), the TL and the learn-ers?
level of proficiency in TL.
For an extensiveoverview see, for example (Pravec, 2002; Nessel-hauf, 2004; Xiao, 2008).Size L1 TL TL proficiencyICLE ?
Internat?l Corpus of Learner English3M 21 English advancedCLC ?
Cambridge Learner Corpus30M 130 English all levelsPELCRA ?
Polish Learner English Corpus0.5M Polish English all levelsUSE ?
Uppsala Student English Corpus1.2M Swedish English advancedHKUST ?
Hong Kong University of Scienceand Technology Corpus of Learner English25M Chinese English advancedCLEC ?
Chinese Learner English Corpus1M Chinese English 5 levelsJEFLL ?
Japanese EFL Learner Corpus0.7M Japanese English advancedFALKO ?
Fehlerannotiertes Lernerkorpus1.2M various German advancedFRIDA ?
French Interlanguage Database0.2M various French intermediateCIC ?
Chinese Interlanguage Corpus2M 96 Chinese intermediateTable 1: Some currently available learner corpora3 A learner corpus of CzechIn many ways, building a learner corpus of Czechas a second/foreign language is a unique enter-prise.
To the best of our knowledge, the CzeSLcorpus (Czech as a Second/Foreign Language) isthe first learner corpus ever built for a highly in-flectional language, and one of the very few us-ing multi-layer annotation (together with FALKO?
see Table 1).
The corpus consists of 4 subcor-pora according to the learners?
L1:?
The Russian subcorpus represents an interlan-guage of learners with a Slavic L1.?
The Vietnamese subcorpus represents a numer-ous minority of learners with very few points ofcontact between L1 and Czech.?
The Romani subcorpus represents a linguisticminority with very specific traits in the Czechcultural context.?
The ?remnant?
subcorpus covers texts fromspeakers of various L1s.The whole extent of CzeSL will be two millionwords (in 2012).
Each subcorpus is again divided12into two subcorpora of written and spoken texts;2this division guarantees the representative charac-ter of the corpus data.
The corpus is based ontexts covering all language levels according to theCommon European Framework of Reference forLanguages, from real beginners (A1 level) to ad-vanced learners (level B2 and higher).
The textsare elicited during various situations in classes;they are not restricted to parts of written examina-tion.
This spectrum of various levels and situationsis unique in the context of other learner corpora.Each text is equipped with the necessary back-ground information, including sociological dataabout the learner (age, gender, L1, country, lan-guage level, other languages, etc.)
and the sit-uation (test, homework, school work without thepossibility to use a dictionary, etc.
).4 Annotation scheme4.1 The feasible and the desirableThe error tagging system for CzeSL is designed tomeet the requirements of Czech as an inflectionallanguage.
Therefore, the scheme is:?
Detailed but manageable for the annotators.?
Informative ?
the annotation is appropriate toCzech as a highly inflectional language.?
Open to future extensions ?
it allows for moredetailed taxonomy to be added in the future.The annotators are no experts in Czech as a for-eign language or in 2L learning and acquisition,and they are unaware of possible interferences be-tween languages the learner knows.
Thus theymay fail to recognise an interferential error.
Asentence such as Tokio je pe?kn?
hrad ?Tokio is anice castle?
is grammatically correct, but its au-thor, a native speaker of Russian, was misled by?false friends?
and assumed hrad ?castle?
as theCzech equivalent of Russian gorod ?town, city?.3Similarly in Je tam hodne?
sklepu?
?There are manycellars.?
The formally correct sentence may strikethe reader as implausible in the context, but it isimpossible to identify and emend the error with-out the knowledge that sklep in Russian means?grave?, not ?cellar?
(= sklep in Czech).For some types of errors, the problem is to de-fine the limits of interpretation.
The clause kdybycitila na tebe zlobna is grammatically incorrect,2Transcripts of the spoken parts will be integrated withthe rest of the corpus at a later stage of the project.3All examples are authentic.yet roughly understandable as ?if she felt angry atyou?.
In such cases the task of the annotator is in-terpretation rather than correction.
The clause canbe rewritten as kdyby se na tebe c?tila rozzloben?
?if she felt angry at you?, or kdyby se na tebe zlo-bila ?if she were angry at you?
; the former beingless natural but closer to the original, unlike thelatter.
It is difficult to provide clear guidelines.Errors in word order represent another specifictype.
Czech constituent order reflects informationstructure and it is sometimes difficult to decide(even in a context) whether an error is present.
Thesentence R?dio je taky na skr?
?ni ?A radio is also onthe wardrobe?
suggests that there are at least tworadios in the room, although the more likely inter-pretation is that among other things, there is also aradio, which happens to sit on the wardrobe.
Onlythe latter interpretation would require a differentword order: Taky je na skr?
?ni r?dio.
Similarlydifficult may be decisions about errors labelled aslexical and modality.The phenomenon of Czech diglossia is reflectedin the problem of annotating non-standard lan-guage, usually individual forms with colloquialmorphological endings.
The learners may not beaware of their status and/or an appropriate contextfor their use, and the present solution assumes thatcolloquial Czech is emended under the rationalethat the author expects the register of his text to beperceived as unmarked.On the other hand, there is the primary goal ofthe corpus: to serve the needs of the corpus users.The resulting error typology is a compromise be-tween the limitations of the annotation process andthe demands of research into learner corpora.The corpus can be used for comparisons amonglearner varieties of Czech, studied as national in-terlanguages (Russian, Vietnamese, Romani etc.
)using a matrix of statistic deviations.
Similarly in-teresting are the heterogeneous languages of learn-ers on different stages of acquisition.
From thepedagogical point of view, corpus-based analy-ses have led to a new inductive methodology ofdata-driven learning, based on the usage of con-cordances in exercises or to support students?
in-dependent learning activities.4.2 The frameworkAnnotated learner corpora sometimes use data for-mats and tools developed originally for annotatingspeech.
Such environments allow for an arbitrary13segmentation of the input and multilevel annota-tion of segments (Schmidt, 2009).
Typically, theannotator edits a table with columns correspond-ing to words and rows to levels of annotation.
Acell can be split or more cells merged to allow forannotating smaller or larger segments.
This way,phenomena such as agreement or word order canbe emended and tagged (L?deling et al, 2005).However, in the tabular format vertical corre-spondences between the original word form and itsemended equivalents or annotations at other levelsmay be lost.
It is difficult to keep track of linksbetween forms merged into a single cell, spanningmultiple columns, and the annotations of a format other levels (rows).
This may be a problem forsuccessive emendations involving a single form,starting from a typo up to an ungrammatical wordorder, but also for morphosyntactic tags assignedto forms, whenever a form is involved in a multi-word annotation and its equivalent or tag leavesthe column of the original form.While in the tabular format the correspondencesbetween elements at various levels are capturedonly implicitly, in our annotation scheme thesecorrespondences are explicitly encoded.
Our for-mat supports the option of preserving correspon-dences across levels, both between individualword forms and their annotations, while allowingfor arbitrary joining and splitting of any numberof non-contiguous segments.
The annotation lev-els are represented as a graph consisting of a setof parallel paths (annotation levels) with links be-tween them.
Nodes along the paths always standfor word tokens, correct or incorrect, and in a sen-tence with nothing to correct the correspondingword tokens in every pair of neighbouring pathsare linked 1:1.
Additionally, the nodes can be as-signed morphosyntactic tags, syntactic functionsor any other word-specific information.
Whenevera word form is emended, the type of error can bespecified as a label of the link connecting the in-correct form at level Si with its emended form atlevel Si+1.
In general, these labelled relations canlink an arbitrary number of elements at one levelwith an arbitrary number of elements at a neigh-bouring level.
The elements at one level partic-ipating in this relation need not form a contigu-ous sequence.
Multiple words at any level are thusidentified as a single segment, which is related to asegment at a neighbouring level, while any of theparticipating word forms can retain their 1:1 linkswith their counterparts at other levels.
This is use-ful for splitting and joining word forms, for chang-ing word order, and for any other corrections in-volving multiple words.
Nodes can also be addedor omitted at any level to correct missing or oddpunctuation signs or syntactic constituents.
SeeFigure 1 below for an example of this multi-levelannotation scheme.The option of relating multiple nodes as sin-gle segments across levels could also be used fortreating morphosyntactic errors in concord andgovernment.
However, in this case there is typ-ically one correct form involved, e.g., the sub-ject in subject-predicate agreement, the noun inadjective-noun agreement, the verb assigning caseto a complement, the antecedent in pronominalreference.
Rather than treating both the correctand the incorrect form as equals in a 2:2 relationbetween the levels, the incorrect form is emendedusing a 1:1 link with an option to refer to the cor-rect form.
Such references link pairs of forms atneighbouring levels rather than the forms them-selves to enable possible references from a multi-word unit (or) to another multi-word unit.
See Fig-ure 1 below again, where such references are rep-resented by arrows originating in labels val.A single error may result in multiple incorrectforms as shown in (1).
The adjective velk?
?big-NOM-SG-M(ASC)?
correctly agrees with the nounpes ?dog-NOM-SG-MASC?.
However, the case ofthe noun is incorrect ?
it should be in accusativerather than nominative.
When the noun?s case iscorrected, the case of the adjective has to be cor-rected as well.
Then multiple references are made:to the verb as the case assigner for the noun, andto the noun as the source of agreement for the ad-jective.
(1) a.
*Vide?lsawvelk?big-NOM-SG-Mpes.dog-NOM-SG-Mb.
Vide?lsawvelk?hobig-ACC-SG-Mpsa.dog-ACC-SG-M?He saw a big dog?Annotation of learners?
texts is often far fromstraightforward, and alternative interpretations areavailable even in a broader context.
The annota-tion format supports alternatives, but for the timebeing the annotation tool does not support localdisjunctions.
This may be a problem if the anno-tator has multiple target hypotheses in mind.144.3 Three levels of annotationA multi-level annotation scheme calls for somejustification, and once such a scheme is adopted,the question of the number of levels follows.After a careful examination of alternatives, wehave arrived at a two-stage annotation design,based on three levels.
A flat, single-stage, two-level annotation scheme would be appropriate ifwe were interested only in the original text andin the annotation at some specific level (fullyemended sentences, or some intermediate stage,such as emended word forms).
The flat designcould be used even if we insisted on registeringsome intermediate stages of the passage from theoriginal to a fully emended text, and decided tostore such information with the word-form nodes.However, such information might get lost in thecase of significant changes involving deletions oradditions (e.g., in Czech as a pro-drop language,the annotator may decide that a misspelled per-sonal pronoun in the subject position should bedeleted and the information about the spelling er-ror would lost).
The decision to use a multi-leveldesign was mainly due to our interest in annotat-ing errors in single forms as well as those spanning(potentially discontinuous) strings of words.Once we have a scheme of multiple levels avail-able, we can provide the levels with theoreticalsignificance and assign a linguistic interpretationto each of them.
In a world of unlimited re-sources of annotators?
time and experience, thiswould be the optimal solution.
The first annota-tion level would be concerned only with errors ingraphemics, followed by levels dedicated to mor-phemics, morphosyntax, syntax, lexical phenom-ena, semantics and pragmatics.
More realistically,there could be a level for errors in graphemics andmorphemics, another for errors in morphosyntax(agreement, government) and one more for every-thing else, including word order and phraseology.Our solution is a compromise between corpususers?
expected demands and limitations due tothe annotators?
time and experience.
The anno-tator has a choice of two levels of annotation, andthe distinction, based to a large extent on formalcriteria, is still linguistically relevant.At the level of transcribed input (Level 0), thenodes represent the original strings of graphemes.At the level of orthographical and morphologicalemendation (Level 1), only individual forms aretreated.
The result is a string consisting of cor-rect Czech forms, even though the sentence maynot be correct as a whole.
The rule of ?correctforms only?
has a few exceptions: a faulty formis retained if no correct form could be used in thecontext or if the annotator cannot decipher the au-thor?s intention.
On the other hand, a correct formmay be replaced by another correct form if the au-thor clearly misspelled the latter, creating an un-intended homograph with another form.
All othertypes of errors are emended at Level 2.4.4 Captured errorsA typical learner of Czech makes errors all alongthe hierarchy of theoretically motivated linguisticlevels, starting from the level of graphemics upto the level of pragmatics.
Our goal is to emendthe input conservatively, modifying incorrect andinappropriate forms and expressions to arrive ata coherent and well-formed result, without anyambition to produce a stylistically optimal solu-tion.
Emendation is possible only when the inputis comprehensible.
In cases where the input or itspart is not comprehensible, it is left with a partialor even no annotation.The taxonomy of errors is rather coarse-grained,a more detailed classification is previewed for alater stage and a smaller corpus sample.
It followsthe three-level distinction and is based on criteriaas straightforward as possible.
Whenever the er-ror type can be determined from the way the er-ror is emended, the type is supplied automaticallyby a post-processing module, together with mor-phosyntactic tags and lemmas for the correct oremended forms (see ?
5.3).Errors in individual word forms, treated at Level1, include misspellings (also diacritics and capi-talisation), misplaced word boundaries, missing ormisused punctuation, but also errors in inflectionaland derivational morphology and unknown stems.These types of errors are emended manually, butthe annotator is not expected label them by theirtype ?
the type of most errors at Level 1 is identi-fied automatically.
The only exception where theerror type must be assigned manually is when anunknown stem or derivation affix is used.Whenever the lexeme (its stem and/or suffix) isunknown and can be replaced by a suitable form, itis emended at Level 1.
If possible, the form shouldfit the syntactic context.
If no suitable form canbe found, the form is retained and marked as un-known.
When the form exists, but is not appro-15priate in context, it is emended at Level 2 ?
thereason may be the violation of a syntactic rule orsemantic incompatibility of the lexeme.Table 2 gives a list of error types emended atLevel 1.
Some types actually include subtypes:words can be incorrectly split or joined, punctu-ation, diacritics or character(s) can be missing,superfluous, misplaced or of a wrong kind.
TheLinks column gives the maximum number of po-sitions at Level 0, followed by the maximum num-ber of position at Level 1 that are related by linksfor this type of error.
The Id column says if theerror type is determined automatically or has to bespecified manually.Error type Links IdWord boundary m:n APunctuation 0:1, 1:0 ACapitalisation 1:1 ADiacritics 1:1 ACharacter(s) 1:1 AInflection 1:1 AUnknown lexeme 1:1 MTable 2: Types of errors at Level 1Emendations at Level 2 concern errors in agree-ment, valency and pronominal reference, negativeconcord, the choice of a lexical item or idiom,and in word order.
For the agreement, valencyand pronominal reference cases, there is typicallyan incorrect form, which reflects some properties(morphological categories, valency requirements)of a correct form (the agreement source, syntac-tic head, antecedent).
Table 3 gives a list of errortypes emended at Level 2.
The Ref column givesthe number of pointers linking the incorrect formwith the correct ?source?.Error type Links Ref IdAgreement 1:1 1 MValency 1:1 1 MPronominal reference 1:1 1 MComplex verb forms m:n 0,1 MNegation m:n 0,1 MMissing constituent 0:1 0 MOdd constituent 1:0 0 MModality 1:1 0 MWord order m:n 0 MLexis & phraseology m:n 0,1 MTable 3: Types of errors at Level 2The annotation scheme is illustrated in Figure 1,using an authentic sentence, split in two halves forspace reasons.
There are three parallel strings ofword forms, including punctuation signs, repre-senting the three levels, with links for correspond-ing forms.
Any emendation is labelled with an er-ror type.4 The first line is Level 0, imported fromthe transcribed original, with English glosses be-low (forms marked by asterisks are incorrect inany context, but they may be comprehensible ?
asis the case with all such forms in this example).Correct words are linked directly with their copiesat Level 1, for emended words the link is labelledwith an error type.
In the first half of the sentence,unk for unknown form, dia for an error in diacrit-ics, cap for an error in capitalisation.
According tothe rules of Czech orthography, the negative parti-cle ne is joined with the verb using an intermedi-ate node bnd.
A missing comma is introduced atLevel 1, labelled as a punctuation error.
All the er-ror labels above can be specified automatically inthe post-processing step.Staying with the first half of the sentence, mostforms at Level 1 are linked directly with theirequivalents at Level 2 without emendations.
Thereflexive particle se is misplaced as a second posi-tion clitic, and is put into the proper position usingthe link labelled wo for a word-order error.5 Thepronoun ona ?
?she?
in the nominative case ?
isgoverned by the form l?bit se, and should bear thedative case: j?.
The arrow to l?bit makes the rea-son for this emendation explicit.
The result couldstill be improved by positioning Praha after theclitics and before the finite verb nebude, resultingin a word order more in line with the underlyinginformation structure of the sentence, but our pol-icy is to refrain from more subtle phenomena andproduce a grammatical rather than a perfect result.In the second half of the sentence, there is onlyone Level 1 error in diacritics, but quite a few er-rors at Level 2.
Proto ?therefore?
is changed toproto?e ?because?
?
a lexical emendation.
Themain issue are the two finite verbs bylo and vad?.The most likely intention of the author is best ex-pressed by the conditional mood.
The two non-contiguous forms are replaced by the conditional4The labels for error types used here are simplified forreasons of space and mnemonics.5In word-order errors it may be difficult to identify a spe-cific word form violating a rule.
The annotation scheme al-lows for both se and j?
to be blamed.
However, here we pre-fer the simpler option and identify just one, more prominentword form.
Similarly with mi below.16auxiliary and the content verb participle in onestep using a 2:2 relation.
The intermediate nodeis labelled by cplx for complex verb forms.
Theprepositional phrase pro mne?
?for me?
is anothercomplex issue.
Its proper form is pro me?
(homony-mous with pro mne?, but with ?me?
bearing ac-cusative instead of dative), or pro mne.
The ac-cusative case is required by the preposition pro.However, the head verb requires that this comple-ment bears bare dative ?
mi.
Additionally, thisform is a second position clitic, following the con-ditional auxiliary (also a clitic) in the clitic cluster.The change from PP to the bare dative pronounand the reordering are both properly represented,including the pointer to the head verb.
What ismissing is an explicit annotation of the faulty caseof the prepositional complement, which is lostduring the Level 1 ?
Level 2 transition, the pricefor a simpler annotation scheme with fewer lev-els.
It might be possible to amend the PP at Level1, but it would go against the rule that only formswrong in isolation are emended at Level 1.Bojal jsem se ?e ona se ne bude libit prahu ,*feared AUX RFL that she RFL not will *like prague ,unk p bnd dia capB?l jsem se , ?e ona se nebude l?bit Prahu ,wo val valB?l jsem se , ?e se j?
nebude l?bit Praha ,I was afraid that she would not like Prague,proto to bylo velm?
vad?
pro mne?
.therefore it was *very resent for me .diaproto to bylo velmi vad?
pro mne?
.lex cplx val,woproto?e to by mi velmi vadilo .because I would be very unhappy about it.Figure 1: Annotation of a sample sentence4.5 Data FormatTo encode the layered annotation described above,we have developed an annotation schema in thePrague Markup Language (PML).6 PML is a6http://ufal.mff.cuni.cz/jazz/pml/index_en.html<?xml version="1.0" encoding="UTF-8"?><adata xmlns="http://utkl.cuni.cz/czesl/"><head><schema href="adata_schema.xml" /><references><reffile id="w" name="wdata" href="r049.w.xml" /></references></head><doc id="a-r049-d1" lowerdoc.rf="w#w-r049-d1">...<para id="a-r049-d1p2" lowerpara.rf="w#w-r049-d1p2">...<s id="a-r049-d1p2s5"><w id="a-r049-d1p2w50"><token>B?l</token></w><w id="a-r049-d1p2w51"><token>jsem</token></w><w id="a-r049-d1p2w52"><token>se</token></w>...</s>...<edge id="a-r049-d1p2e54"><from>w#w-r049-d1p2w46</from><to>a-r049-d1p2w50</to><error><tag>unk</tag></error></edge><edge id="a-r049-d1p2e55"><from>w#w-r049-d1p2w47</from><to>a-r049-d1p2w51</to></edge>...</para>...</doc></adata>Figure 2: Portion of the Level 1 of the sample sen-tence encoded in the PML data format.generic XML-based data format, designed for therepresentation of rich linguistic annotation organ-ised into levels.
In our schema, each of the higherlevels contains information about words on thatlevel, about the corrected errors and about rela-tions to the tokens on the lower levels.
Level 0does not contain any relations, only links to theneighbouring Level 1.
In Figure 2, we show a por-tion (first three words and first two relations) ofthe Level 1 of the sample sentence encoded in ourannotation schema.5 Annotation processThe whole annotation process proceeds as follows:?
A handwritten document is transcribed intohtml using off-the-shelf tools (e.g.
Open OfficeWriter or Microsoft Word).?
The information in the html document is used togenerate Level 0 and a default Level 1 encodedin the PML format.?
An annotator manually corrects the documentand provides some information about errors us-ing our annotation tool.?
Error information that can be inferred automat-ically is added.17Figure 3: Sample sentence in the annotation tool.5.1 TranscriptionThe original documents are hand-written, usuallythe only available option, given that their mostcommon source are language courses and exams.The avoidance of an electronic format is also dueto the concern about the use of automatic text-editing tools by the students, which may signifi-cantly distort the authentic interlanguage.Therefore, the texts must be transcribed, whichis very time consuming.
While we strive to cap-ture only the information present in the originalhand-written text, often some interpretation is un-avoidable.
For example, the transcribers have totake into account specifics of hand-writing of par-ticular groups of students and even of each indi-vidual student (the same glyph may be interpretedas l in the hand-writing of one student, e of an-other, and a of yet another).
When a text allowsmultiple interpretation, the transcribers may pro-vide all variants.
For example, the case of initialletters or word boundaries are often unclear.
Ob-viously, parts of some texts may be completely il-legible and are marked as such.Also captured are corrections made by the stu-dent (insertions, deletions, etc.
), useful for investi-gating the process of language acquisition.The transcripts are not spell-checked automati-cally.
In a highly inflectional language, deviationsin spelling very often do not only reflect wronggraphemics, but indicate an error in morphology.5.2 AnnotationThe manual portion of annotation is supported byan annotation tool we have developed.
The anno-tator corrects the text on appropriate levels, modi-fies relations between elements (by default all re-lations are 1:1) and annotates relations with errortags as needed.
The context of the annotated textis shown both as a transcribed html document andas a scan of the original document.
The tool iswritten in Java on top of the Netbeans platform.7Figure 3 shows the annotation of the sample sen-tence as displayed by the tool.5.3 PostprocessingManual annotation is followed by automatic post-processing, providing the corpus with additionalinformation:7http://platform.netbeans.org/18?
Level 1: lemma, POS and morphological cate-gories (this information can be ambiguous)?
Level 2: lemma, POS and morphological cate-gories (disambiguated)?
Level 1: type of error (by comparing the origi-nal and corrected strings), with the exception oflexical errors that involve lemma changes (e.g.
*kader?nic?ka ?
kader?nice ?hair-dresser?)?
Level 2: type of morphosyntactic errors causedby agreement or valency error (by comparingmorphosyntactic tags at Level 1 and 2)?
Formal error description: missing/extra expres-sion, erroneous expression, wrong order?
In the future, we plan to automatically tag errorsin verb prefixes, inflectional endings, spelling,palatalisation, metathesis, etc.6 ConclusionError annotation is a very resource-intensive task,but the return on investment is potentially enor-mous.
Depending on the annotation scheme, thecorpus user has access to detailed error statistics,which is difficult to obtain otherwise.
An error-tagged corpus is an invaluable tool to obtain a re-liable picture of the learners?
interlanguage and toadapt teaching methods and learning materials byidentifying the most frequent error categories inaccordance with the learner?s proficiency level orL1 background.We are expecting plentiful feedback from the er-ror annotation process, which is just starting.
Asthe goal of a sizable corpus requires a realisticsetup, we plan to experiment with more and lessdetailed sets of error types, measuring the time andinter-annotator agreement.
A substantially moreelaborate classification of errors is previewed for alimited subset of the corpus.At the same time, the feedback of the annotatorswill translate into the ongoing tuning of the an-notation guidelines, represented by a comprehen-sive error-tagging manual.
We hope in progress indealing with thorny issues such as the uncertaintyabout the author?s intended meaning, the inferenceerrors, the proper amount of interference with theoriginal, or the occurrence of colloquial language.In all of this, we need to make sure that annotatorshandle similar phenomena in the same way.However, the real test of the corpus will comewith its usage.
We are optimistic ?
some of thefuture users are a crucial part of our team and theirneeds and ideas are the driving force of the project.7 AcknowledgementsWe wish to thank other members of the projectteam, namely Milena Hn?tkov?, Tom??
Jel?nek,Vladim?r Petkevic?, and Hana Skoumalov?
for theirnumerous stimulating ideas, acute insight and im-portant feedback.
We are especially grateful toKarel ?ebesta, for all of the above and for initi-ating and guiding this enterprise.The work described in this paper is funded bythe European Social Fund and the government ofthe Czech Republic within the operational pro-gramme ?Education for Competitiveness?
as a partof the project ?Innovation in Education in theField of Czech as a Second Language?
(projectno.
CZ.1.07/2.2.00/07.0259).ReferencesSylviane Granger, editor.
1998.
Learner English onComputer.
Addison Wesley Longman, London andNew York.Geoffrey Leech.
1998.
Preface.
In Granger Sylviane,editor, Learner English on Computer, pages xiv?xx.Addison Wesley Longman, London and New York.Anke L?deling, Maik Walter, Emil Kroymann, and Pe-ter Adolphs.
2005.
Multi-level error annotation inlearner corpora.
In Proceedings of Corpus Linguis-tics 2005, Birmingham.Nadja Nesselhauf.
2004.
Learner corpora and their po-tential for language teaching.
In John McHardy Sin-clair, editor, How to use corpora in language teach-ing, Studies in corpus linguistics, pages 125?152.Benjamins, Amsterdam/Philadelphia.Norma A. Pravec.
2002.
Survery of learner corpora.ICAME Journal, 26:81?114.Thomas Schmidt.
2009.
Creating and working withspoken language corpora in EXMARaLDA.
InLULCL II: Lesser Used Languages & ComputerLinguistics II, pages 151?164.Larry Selinker.
1983.
Interlanguage.
In Betty W.Robinett and Jacquelyn Schachter, editors, SecondLanguage Learning: Contrastive analysis, erroranalysis, and related aspects, pages 173?196.
TheUniversity of Michigan Press, Ann Arbor, MI.Richard Xiao.
2008.
Well-known and influentialcorpora.
In Anke L?deling and Merja Kyt?, ed-itors, Corpus Linguistics.
An International Hand-book, volume 1 of Handbooks of Linguistics andCommunication Science [HSK] 29.1, pages 383?457.
Mouton de Gruyter, Berlin and New York.19
