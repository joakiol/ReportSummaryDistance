Proceedings of the 4th International Workshop on Computational Terminology, pages 11?21,Dublin, Ireland, August 23 2014.Assigning Terms to Domains by Document ClassificationRobert Gaizauskas, Emma Barker, Monica Lestari Paramita and Ahmet AkerDepartment of Computer Science, University of Sheffield, United Kingdom{r.gaizauskas,e.barker,m.paramita,ahmet.aker}@sheffield.ac.ukAbstractIn this paper we investigate a number of questions relating to the identification of the domainof a term by domain classification of the document in which the term occurs.
We propose andevaluate a straightforward method for domain classification of documents in 24 languages thatexploits a multilingual thesaurus and Wikipedia.
We investigate and provide quantitative resultsabout the extent to which humans agree about the domain classification of documents and termsalso the extent to which terms are likely to ?inherit?
the domain of their parent document.1 IntroductionIn an increasingly interconnected world, characterised by high international mobility and globalised tradepatterns, communication across languages is ever more important.
The demand for translation serviceshas never been higher and there is constant pressure for technological solutions, e.g., in the form of ma-chine translation (MT) and computer-assisted translation (CAT), to increase translation throughput andlower costs.
One requirement of these technologies is bilingual lexical resources, i.e.
dictionaries, partic-ularly in specialist subject areas or domains, such as biomedicine, information techology, or aerospace.While in theory statistical MT approaches need only parallel corpora to train their translation models,there is never enough parallel material in technical areas or for minority languages to support high qual-ity technical translation, so specialist bilingual terminological resources are very important.
Similarly,human translators using CAT systems need support in the form of bilingual terminological resources inspecialist areas about which they may know very little.The EU FP-7 TaaS project has created a cloud-based terminological service, which makes availablebilingual terminological resources for all EU languages.
These resources include both existing termi-nological resources and resources derived automatically from parallel and comparable corpora availableon the web.
Additionally, the service?s user community is able manually to supplement or correct theseresources.
Like many other terminology resources (e.g.
IATE1, Eurotermbank2), terms in TaaS have do-mains associated with them.
This is done for a number of reasons: (1) Computational Feasiblity: Whilein theory a translator faced with a translation task could provide the set of documents to be translated toa system that dynamically assembled a bespoke terminological resource specific to this task, this is notcomputationally feasible, at least not in a time-frame a user is likely to accept.
Much more feasible isto collect bilingual terminology off-line and store it within a term repository with an associated domainor domains.
Then, an on-line user, having identified the domain of the document(s) to be translated,searches for terms within that domain or may have terms from the domain into which his documents areautomatically classified made available to him.
(2) Sense Disambiguation: Term expressions, or theirtranslations, may have multiple senses, but these are likely to be in different domains.
By restrictingthe domain when looking up terms, sense confusions are less likely to occur.
(3) User Preference: OurThis work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footer areadded by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/1http://iate.europa.eu2http://www.eurotermbank.comTerminology questions in texts authored by patientsNoemie ElhadadDepartment of Biomedical InformaticsColumbia University, USAnoemie@dbmi.columbia.eduThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/Assigning Terms to Domains by Document ClassificationRobert Gaizauskas, Emma Barker, Monica Lestari Paramita and Ahmet AkerDepartment of Computer Science, University of Sheffield, United Kingdom{r.gaizauskas,e.barker,m.paramita,ahmet.aker}@sheffield.ac.ukAbstractIn this paper we investigate a number of questions relating to the identification of the domainof a term by domain classification of the document in which the term occurs.
We propose andevaluate a straightforward method for domain classification of documents in 24 languages thatexploits a multilingual thesaurus and Wikipedia.
We investigate and provide quantitative resultsabout the extent to which humans agree about the domain classification of documents and termsalso the extent to which terms are likely to ?inherit?
the domain of their parent document.1 IntroductionIn an increasingly interconnected world, characterised by high international mobility and globalised tradepatterns, communication across languages is ever more important.
The demand for translation serviceshas never been higher and there is constant pressure for technological solutions, e.g., in the form of ma-chine translation (MT) and computer-assisted translation (CAT), to increase translation throughput andlower costs.
One requirement of these technologies is bilingual lexical resources, i.e.
dictionaries, partic-ularly in specialist subject areas or domains, such as biomedicine, information techology, or aerospace.While in theory statistical MT approaches need only parallel corpora to train their translation models,there is never enough parallel material in technical areas or for minority languages to support high qual-ity technical translation, so specialist bilingual terminological resources are very important.
Similarly,human translators using CAT systems need support in the form of bilingual terminological resources inspecialist areas about which they may know very little.The EU FP-7 TaaS project has created a cloud-based terminological service, which makes availablebilingual terminological resources for all EU languages.
These resources include both existing termi-nological resources and resources derived automatically from parallel and comparable corpora availableon the web.
Additionally, the service?s user community is able manually to supplement or correct theseresources.
Like many other terminology resources (e.g.
IATE1, Eurotermbank2), terms in TaaS have do-mains associated with them.
This is done for a number of reasons: (1) Computational Feasiblity: Whilein theory a translator faced with a translation task could provide the set of documents to be translated toa system that dynamically assembled a bespoke terminological resource specific to this task, this is notcomputationally feasible, at least not in a time-frame a user is likely to accept.
Much more feasible isto collect bilingual terminology off-line and store it within a term repository with an associated domainor domains.
Then, an on-line user, having identified the domain of the document(s) to be translated,searches for terms within that domain or may have terms from the domain into which his documents areautomatically classified made available to him.
(2) Sense Disambiguation: Term expressions, or theirtranslations, may have multiple senses, but these are likely to be in different domains.
By restrictingthe domain when looking up terms, sense confusions are less likely to occur.
(3) User Preference: OurThis work is licensed under a Creative Commons Attribution 4.0 International Licen .
Page numbers and proceedings footer aredde by the organisers.
Licen d tails: http://creativecommons.org/licenses/ y/4.0/1http://i te.europa.eu2 www.eurotermbank.com11discussions with technical translators show they are used to and comfortable with the notion of domainsand prefer terminological resources structured by domain.Assuming, therefore, that term resources are to be structured into domains, the question arises as tohow this is to be done automatically for automatically acquired terms.
While the notion of domain isinherent in most definitions of ?term?3, most term extraction systems identify terms using grammaticalpatterns and/or statistical occurrence information applied to and gathered from corpora deemed to beeither in-domain or general/multi-domain.
I.e.
such tools do not have any inherent notion of domain, butinstead rely on the external provision of documents pre-selected by domain to determine the domain ofthe extracted terms.
But how valid is this procedure?In this paper we explore several questions related to the assignment of terms to domains.
These ques-tions were addressed within the evaluation of that component of the TaaS platform which automaticallycreates bilingual term resources (the Bilingual Term Extraction System, aka BiTES).
Specifically:1.
How well can a simple vector space classifier built from a multilingual thesaurus automatically clas-sify documents into domains prior to assigning these domains to the terms within the documents?2.
To what extent do humans agree about the assignment of terms to domains?3.
How accurate is the assumption that terms can be assigned to the domains of the documents inwhich they are found?The rest of the paper is structured as follows.
Section 2 gives a brief overview of the BiTES systemas a whole and the domain classification component in somewhat more detail.
In section 3 we describethe evaluation of those parts of BiTES relevant to the questions above, detailing the evaluation tasks,participants and data used and as well as the results of the evaluation.
Section 4 provides analysis anddiscussion of results.
Section 5 discusses related work.
We conclude in Section 6.2 System Components2.1 BiTES overviewThe Bilingual Term Extraction System (BiTES) uses different workflows, each comprising a set of toolsrun in sequence, to collect bilingual term pairs.
Each new bilingual term pair found by BiTES is fed intoa database for later retrieval.
The workflows consist of four different types of tools:1. tools for collecting Web resources, such as parallel and comparable corpora from which the bilingualterms are extracted;2. tools for performing document classification into pre-defined categories or domains;3. tools for extracting terms from or tagging terms in monolingual documents collected from the Web;4. tools for bilingual alignment of tagged terms in parallel or comparable document pairs collectedfrom the Web.Each workflow can be run in an offline and periodic manner and starts with document collection from theWeb followed by document classification.
The output of the document classifier is passed to the mono-lingual term extractor.
Term-tagged document pairs are fed to the bilingual term alignment processorto extract bilingual terms.
The main goal of BiTES within the TaaS platform is to automatically col-lect large numbers of bilingual term pairs off-line that are then stored in a database for later retrieval byusers.
This database of automatically collected terms is consulted when other pre-existing, and presumedhigher quality, manually gathered terminological resources, such as, EuroTermBank or IATE, which arealso available in the TaaS platform, do not contain translations for terms the user seeks.3For example Besse?
et al.
(1997) define term as ?a lexical unit consisting of one or more than one word which represents aconcept inside a domain?
; ISO 1087-1:2000 defines term as ?verbal designation of a general concept in a specific subject field?.12In this section we detail only the domain classification component of BiTES as it is the component thathas the most direct implications for the research questions addressed in the paper and as the underlyingmethods and performance of the other tools used in BiTES have been reported elsewhere (Aker et al.,2012; Pinnis et al., 2012; Su and Babych, 2012; Skadin?a et al., 2012; Aker et al., 2013; Aker et al.,2014b; Aker et al., 2014a).2.2 Domain Classification2.2.1 Domain classification schemeDespite the existence of various domain classification schemes, the TaaS project has created its own do-main classification for several reasons.
First, the TaaS platform requires a suitable classification systemwhich is easy to use, yet provides broad coverage of the topics that are of greatest interest to users work-ing in terminology management and machine translation.
The project conducted a user study to identifythe set of required domains.
Various classification systems were considered, including the Dewey Dec-imal Classification (DDC) and Universal Decimal Classification (UDC).
These schemes, however, aretoo complicated to be used by terminologists (the latter uses 10 level-1 domains and more than 60,000level-2 domains) yet still did not sufficiently cover relevant subject fields identified by our users, suchas IT, medicine and mechanical engineering.
The Internal Classification for Standards (ICS) schemewas considered next, as it covers technical subject fields, but it was lacking with respect to legal andhumanities domains.
Intially, therefore, the TaaS project decided to adopt the domain structuring usedin the EuroVoc thesaurus, which includes a broad range of domains.
However, with 21 level-1 domainsand 127 level-2 domains, it too is quite complex and focuses more on European Union domains than theindustry-related domains identified in our user study.
Therefore, various modifications to the EuroVocdomain scheme were performed to merge and delete various domains so as to increase the scheme?ssuitability for the project and also improve its practicality and ease of use.
This resulted in what we hererefer to as the TaaS domain classification scheme, which contains 11 level-1 domains and 66 level-2 do-mains4.
A mapping from EuroVoc level-1 and -2 domains to TaaS level-1 and -2 domains was manuallyestablished.2.2.2 Document classifierMany approaches to document classification have been proposed in the literature ?
see Agarwal et al.
(2014) for a survey.
Our domain classifier uses the well-explored vector space approach.
For eachlanguage, each domain is represented by one vector and each document to be classified by another vector.The cosine similarity measure (Salton and Lesk, 1968) is calculated between the vector representationof the input document and the vector representation of a domain and serves as a measure of the extentto which the document belongs to that domain.
The highest scoring domain may be chosen if hardclassification is required, or a vector of scores, one per domain, may be returned, if soft classificationis needed.
The advantage of this approach in our setting is that we can exploit an existing multilingual,domain-structured thesaurus to build our domain vector to deliver domain classifiers for 11 domains in24 languages, without the need for collecting training data.To create a vector representation for an input document, the document is first pre-processed and stopwords and punctuation are removed from it.
The TaaS project covers 23 of the 24 official EU languages5as well as Russian.
For each of these languages we took the entire dump of Wikipedia and weighted eachword in the articles using tf ?
idf (Manning et al., 2008).
Any word whose idf is below a predefinedthreshold is used as a stop word.
Using this method we collected stop word lists for all 24 languages.To identify punctuation we used simple rules covering the major punctuation symbols.
After filteringout stop words and punctuation, the remaining words in the input document are stemmed.
We adoptedLucene stemmers for all languages for which these resources are available in and implemented newstemmers for Latvian, Lithuanian and Estonian.
Finally, term frequency counts for the stems in the inputdocument are gathered, idf scores are taken from the Wikipedia dump and tf ?
idf weights are computedand stored to create the vector representation of the input document.4A full specification of the scheme is available at: https://demo.taas-project.eu/domains.5The omitted language is Irish, for which insufficient data was available for training our tools.13To create domain vectors we did the following: (1) For each domain and language, we manuallydownloaded the relevant EuroVoc term file from the EuroVoc website6.
(2) We used the EuroVoc-to-TaaS mapping described in Section 2.2.1 above to map all terms belonging to a specific EuroVoc domain(level-1 or -2) to the corresponding TaaS domain (level-1 or -2).
(3) For each TaaS domain (in eachlanguage) we built a domain-specific vector from the set of newly derived TaaS terms in the domain.Since our vector elements correspond to single words, we convert any multi-word term in the domaininto multiple single word representations.
To do this we process each multi-word by splitting it onwhitespace, removing any words that are stop words and finally stemming the remaining words.
For anysingle word terms we simply take their stems.
Finally, all the word stems so derived are stored in a vector.We use simple term frequency, measured across the bag of stemmed words derived from all terms in thedomain, as a weight for each stem.
In the experiment below we report results only for classification intothe 11 level-1 TaaS domains ?
see Table1.Level-1 Domain Level-2 DomainAgriculture and foodstuff Agriculture, forestry, fisheries, foodstuff, beverages and tobacco, and food technol-ogy.Arts Plastic arts, music, literature, and dance.Economics Business administration, national economics, finance and accounting, trade, mar-keting and public relations, and insurance.Energy Energy policy, coal and mining, oil and gas, nuclear energy, and wind, water andsolar energy.Environment Climate, and environmental protection.Industries and technology Information and communication technology, chemical industry, iron, steel and othermetal industries, mechanical engineering, electronics and electrical engineering,building and public works, wood industry, leather and textile industries, transporta-tion and aeronautics, and tourism.Law Civil law, criminal law, commercial law, public law, and international law and hu-man rights.Medicine and pharmacy Anatomy, ophthalmology, dentistry, otolaryngology, paediatrics, surgery, alterna-tive treatment methods, gynaecology, veterinary medicine, pharmacy, cosmetic, andmedical engineering.Natural sciences Astronomy, biology, chemistry, geology, geography, mathematics and physics.Politics and administration Administration, politics, international relations and defence, and European Union.Social sciences Education, history, communication and media, social affairs, culture and religion,linguistics, and sports.Table 1: TaaS Domains3 EvaluationTo evaluate the BiTES system we devised a set of four human assessment tasks focussed on differentaspects of the system.
These tasks were designed to assess the domain classifier, the extent to whichterms found in a document judged to be in a given domain were in the domain of their document, theaccuracy of the boundaries of extracted terms in context and the accuracy of system proposed bilingualterm alignments.
In this paper we focus on the first two of these tasks only.
As noted above the TaaSproject addressed 24 languages in total.
Evaluation of all these languages and language pairs was clearlyimpossible.
We chose to focus on six languages ?
English (EN), German (DE), Spanish (ES), Czech(CS), Lithuanian (LT) and Latvian (LV) ?
and five language pairs EN-DE, EN-ES, EN-CS, EN-LT andEN-LV.
This gave us exemplars from the Germanic, Romance, Slavic and Baltic language groups.3.1 Human assessment tasks3.1.1 Domain classification assessmentIn the domain classification assessment task we present participants with a document and the TaaS set ofdomain classes (see Table 1), and ask them to select the TaaS level-1 domain that in their judgement bestrepresents the document.
We provide a brief set of guidelines to help them carry out this task.6http://eurovoc.europa.eu14We encourage participants to select a primary domain wherever possible ?
i.e.
a single domain thatbest represents the document.
But we allow them to select multiple domains from the list provided, if theybelieve the text spans more than one domain and they are unable to decide upon a primary domain.
If theydo opt to select multiple domains we ask them to keep the number of selected domains to a minimum.For example, the Wikipedia article entitled ?Hydraulic Fracturing?
7 discusses a wide range of topics,including the process of hydraulic fracturing and its impacts in the geological, environmental, economicand political spheres.
For this document, which we use in our guidelines for the task, we recommendassessors choose ?Energy?
as a primary domain and possibly also ?Industries and Technology?, sincethese two domains best represent the overall document content, which is chiefly concerned with what isdescribed as a ?mechanical?
process in the ?industrial sector of mining?, the products being natural gasand oil.
But we would limit our selection to these two.The aim is for participants to select domains from the list we provide.
However, in the event that theyare unable to do so, we provide an option ?none of the above?, which they may select and then providea domain of their own.
In the guidelines we ask them to spend some time reviewing potential domaincandidates, and combinations of candidates, before opting to provide an as yet unspecified domain.I.e.
they should only select the option ?none of the above?
if they have genuinely exhausted all thepossibilities using one or more domains from our list.3.1.2 Term in domain assessmentFigure 1: Judging a Term Candidate in a DomainThis is the first of two tasks assessing the (monolingual) extraction of terms.
It assesses whether anautomatically extracted term candidate is a term in a proposed, automatically determined, domain.
As-suming the candidate is a term, a subsequent task assesses whether the boundaries of the term candidate,when taken in their original document context, are correct.In this task (see Figure 1) we present assessors with a term candidate and a domain and then ask themto judge if the candidate is a term in the given domain or if it is a term in a different domain.
If they judgethe term to be in a different domain we ask them to specify the alternate domain(s).
In this question thecandidate and the domain category are assessed together but we do not provide any specific context, suchas the source sentence or source document.
As with the previous task we provide a brief set of guidelinesto help assessors carry out the task.We ask assessors to base their judgement on the entire candidate string.
If the string contains a termbut also contains, additional words that are not part of the term then they should answer ?no?.
For7Aka ?fracking?, see http://en.wikipedia.org/wiki/Hydraulic_fracturing15example, consider the candidate ?excessive fuel emissions?
and the domain ?Industries and Technology?.Although most people would agree that ?fuel emissions?
is a term, Q1.1 and Q1.2 should be answered?no?
in this case since the candidate also contains noise, i.e.
the word ?excessive?.
Superfluous articles,determiners and other closed class words are also considered ?noise?
in this context.We encourage assessors to search the Internet, as translators and terminologists might do, to helpdetermine whether the entire candidate is indeed a term in the given domain.
Web searches can provideexamples of real world uses of a candidate in different domains.
We also allow assessors to consultexisting terminological or dictionary resources, online or otherwise, during the evaluation task.
However,participants are encouraged not to assume that such resources are complete or entirely correct and advisedthat such resources be used with some consideration and caution.Finally, if assessors have answered ?yes?
to one of Q1.1 or Q1.2, they will also be asked to indicatethe utility of the term candidate in Q1.3, however this aspect of the assessment is not of interest here andwill not be discussed further.3.2 ParticipantsWe recruited experienced translators to participate in the evaluation tasks.
For English and for eachlanguage pair, three assessors carried out each of the evaluation tasks.
In total our study involved 17assessors ?
one assessor took part in DE only, EN-DE and EN only tasks.
All assessors had an excellentbackground in translation in a wide variety of domains, with an average of 8.5 years translation experi-ence in the relevant language pairs.
All assessors who evaluated the English, Lithuanian and Latvian datawere native speakers.
For each of the remaining languages (Czech, German and Spanish), 2 were nativespeakers whilst 1 was a fluent speaker with over 54 years, 15 years and 12 years experience (respectively)in using these languages as a second language.3.3 Data3.3.1 Domain classificationFor the domain classification task, we selected a set of documents to be evaluated using the followingapproach.
First, we gathered all articles from the August 2013 Wikipedia dump in each of the assesmentlanguages and extracted the main text paragraphs, i.e.
tables, images, infoboxes and URLs were filteredout.
The number of articles ranged from 50,000 (for Latvian) to 4,000,000 (for English).
We then ranour domain classifier over each document in this dataset and assigned to each document the top domainproposed by the classifier, i.e.
the domain with the highest score according to our vector space approach(Section 2.2.2).
During processing we filtered out documents whose top domain scores were belowa previously set minimum threshold and those whose document length was below a minimum length.Finally, for each domain D, we sorted the documents classified into D based on their scores, divided thissequence into 10 equal-size bins and selected one document from each bin.
Since we were classifyingdocuments into one of the 11 level-1 TaaS domains, this resulted in 110 documents for each language8.3.3.2 Term extractionFor the term in domain assessment task, we narrowed the task to focus on two domains only ?
?Industriesand Technology?
and ?Politics and Administration?
?
since we could not hope to assess sufficient termsin all domains in all languages.
We extracted terms from all documents contained in the top bin of thedomain classifier, i.e.
the 10% of documents in the domain with the highest similarity score to the domainvector, using TWSC as the term extractor tool (Pinnis et al., 2012).
Next, we selected 200 terms fromboth domains, choosing terms of different word lengths: 50 of length 1, 70 of length 2, 50 of length 3and 30 of length 4.
This distribution was chosen in order to approximate roughly the distribution of termlengths one might expect in the data9.
This process was repeated for each of our six languages.8The Latvian set contains a slightly smaller set (i.e.
106 documents) due to a fewer number of documents found in one ofthe domains (i.e.
6 documents in the ?Energy?
domains).9This distribution was chosen after analysing term lengths in the EuroVoc thesaurus and in the term extractor results, whichindicated that terms length 2 are the most common, followed by terms length 1 and 3, and terms length 4 are found to be theleast common.
We boosted slightly the numbers of length 4 terms in our test to try to eliminate very small number effects.163.4 Results3.4.1 Domain classification assessmentA total of 656 documents (in 6 languages) were assessed and on average 1.2 domains were selected foreach document.
Regarding human-human agreement, at least 2 assessors fully agreed on their domainselections (including cases where more than one domain was selected) on 78% of the cases.
Whenconsidering cases where at least 2 assessors agreed on at least one domain, agreement increases to 98%.Regarding human-system agreement, since 3 assessors participated in each assessment, we producedtwo types of human judgments: majority (i.e.
any domains selected by at least two assessors) and union(i.e.
any domains selected by at least one assessor).
We computed the agreements between the classifierand both the majority and the union human judgments.
Results averaged over all domains and languagesshow the system?s proposed top domain agreed with the majority human judgment in 45% of cases andwith the union of human judgments in 58% of cases.
Broken down by language, agreement with themajority judgment ranged from a low of 35% (EN) to a high of over 53% (DE) while agreement with theunion of judgments ranged from a low of 48% (EN) to a high of over 64% (CS).
By domain, agreementwith majority judgment ranged from just over 12% (Agriculture and foodstuff) to 88% (Medicine andpharmacy) while agreement with the union of judgments ranged from 23% (Agriculture and foodstuff)to over 91% (Social sciences).Recall (Section 3.3.1) that our test data includes documents from different similarity score bins.
Thisenables us to analyse the agreement between the assessors and the classifier in more detail.
In generalwe see a monotonically increasing agreement with both the majority judgement and union of judgmentsas we move from the lowest to highest scoring bin.
The highest agreement is achieved in bin 10 whichrepresents the 10% of documents ?most confidently?
classified to a given domain, i.e.
those documentswith the highest similarity score to the domain vector.
Just under 80% of these documents (77.27%) areincluded in the union of assessors data and 63% are included in the majority.
I.e.
for approximately 77%of the documents most confidently classified to a domain by our classifier, at least one in three humanswill agree with the domain classification and for about 63% the majority of humans will agree.3.4.2 Term in domain assessmentTerm length Total Term in the Term in agiven domain different domainAll length 457 88% 12%1 144 88% 12%2 182 87% 13%3 84 92% 8%4 47 91% 9%Table 2: Terms with different term lengthLanguages Total Term in the Term in agiven domain different domainAll languages 457 88% 12%CS 103 86% 14%DE 79 82% 18%EN 80 88% 13%ES 54 80% 20%LT 47 98% 2%LV 94 97% 3%Table 3: Terms of different languagesA total of 1,200 candidate terms in 6 languages were assessed by 3 assessors and the majority judg-ments (i.e.
cases where at least two assessors agree) show that 38% terms were assessed to be candidateterms in the given domain, 5% terms were assessed to be candidate terms in a different domain, and therest (57%) were deemed not to be terms.This indicates that out of all candidate terms which were identified to be correct terms (43% of thedata), 88% were assessed to be in the same domain as the documents they were extracted from.
Furtheranalysis showed that the 57% of candidates judged not to be terms could be further broken down into33% which contain an overlap with a term, i.e.
term boundaries were incorrectly identified, and 24%which neither are nor overlap with a term.Of the 43% candidate terms that were judged to be terms, we examined the variation in extent towhich they were judged to be terms in the given domain across term lengths and across languages.
Thesefigures are shown in Tables 2 and 3.
We also examined variation in the extent to which these terms werejudged to be terms in the given domain across the two domains we were investigating: in ?Industries and17Technology?
92% of the terms were judged to be in the given domain and 8% in another domain, whilefor ?Politics and Administration?
these figures were 85% and 15% respectively.For the 43% of the term candidates that were identified as correct terms (457 terms), all three assessorsagreed about the domain of the term, i.e.
they either accepted the domain proposed by the system for theterm or they agreed on an alternative(s), in 45% of the cases.
In 54% of the cases there was not universalagreement but at least two assessors agreed on at least one domain they assigned to the term.
Only in 1%of the cases was there no overlap in judgment about term domain.4 Analysis and DiscussionLet us now return to the research questions we raised in Section 1.
Our first question was: How wellcan a simple vector space classifier built from a multilingual thesaurus automatically classify documentsinto domains prior to assigning these domains to the terms within the documents?
First, we have to viewsystem performance in the context of human performance.
Results in the last section show that 2 outof 3 humans agree 78% of the time on exact assignment of (possibly multiple) domains to documentsand 98% of the time if only one of the domains they assign to a document need to match.
Over alllanguages and domains our classifier achieves only 45% agreement with the majority judgment and58% with the union of judgments.
However, if we restrict ourselves to the highest confidence domainassigments, then the picture is much better: 63% agreement with the majority judgment and 77% withthe union of judgments.
This restriction reduces the number of documents from which terms could bemined from if accurate domain classification is important ?
but so long as there are lots of documentsto mine terms from this may not be important.
Furthermore note that our classifier could easily beused to select multiple domains, perhaps, e.g., when the differences in scores between highest scoringdomains is small.
This would make the comparison with the human figures fairer (now the system canonly propose one domain per document while the humans can propose several) and could only resultin higher system figures relative to human ones.
We conclude that the vector space classifier utilizingdomain representations derived from a pre-existing multingual thesaurus has much to recommend: it issimple, it needs no training data, it is straightforwardly applicable to multiple (24 in our case) differentlanguages and its performance is adequate if it is suitably constrained.Our second question was: To what extent do humans agree about the assignment of terms to domains?Our results show that in less than half the cases do all three human assessors agree with the assignmentof a term to a particular domain.
However, in 99% of the cases at least two of three assessors concur onat least one domain to which the term belongs.
This suggests that using overlap with two of three humanassessors is a good approach to measuring automatic domain assignment to terms.Our third question was: How accurate is the assumption that terms can be assigned to the domains ofthe documents in which they are found?
Tables 2 and 3 show that on average 88% of terms are judged tobe in the domain of the document in which they are found.
Furthermore there is relatively little variationin this figure ?
it ranges from a low of 80% (ES) to a high of 98% (LT) and a low of 87% for terms oflength 2 to a high of 92% for terms of length 3.
This suggests that assigning domains to terms basedon the domain of the document the term is found in is a relatively safe thing to do, but is by no meansperfect: just over 10% of terms will have their domains incorrectly assigned by making this assumption.5 Related WorkThere has been extensive work on the development of automated techniques to extract terminology fromdocument collections.
Such term extraction approaches can be grouped into three categories based onthe information used to extract terms: approaches using purely linguistic information, approaches usingpurely statistical information and those using combinations of both.
An analysis of different approachesis given by Pazienza et al.
(2005).
For the most part, however, such approaches make the assumptionthat domain-specific, and perhaps also non-domain-specific, collections of texts are available.
Justesonand Katz (1995), for example, assume that term frequency of a limited sort of noun phrases in domain-specific texts is sufficicent to indicate termhood.
Others such as Chung (2003) and Drouin (2004) lookat statistical contrasts between domain-specific and general comparison or reference corpus.
See also18(Kim et al., 2009; Marciniak and Mykowiecka, 2013; Kilgariff, 2014).
By contrast our approach doesnot presuppose the existence of documents pre-classified by domain (though we could benefit from this).Rather our approach starts by classifying a document into a domain and then extracting terms from it andassigning them the domain of the document.Utsuro et al.
(2006) and Kida et al.
(2007) extract terms from web-documents.
The domain spec-ification of a term is determined in two stage approach.
In the first stage for a term under inspectionweb-documents which mention the term are collected.
Then these documents are divided into two sets:domain relevant and domain-irrelevant documents.
A document whose content similarity to a domainspecific corpora is above a predefined threshold is regarded as relevant.
Any other document is regardedas irrelevant.
In the second stage a ratio of times the term occurs in the relevant and the irrelevant set iscomputed.
This ratio is used to determine whether the extracted term belongs to the domain in hand ornot.
Again, a domain-specific corpus is assumed for this approach to proceed.Benedictis et al.
(2013) use bootstrapping to collect domain specific terms.
They start with somemanually selected domain specific seed terms, perform web-search to obtain documents, extract furtherterms and re-start the process with the new terms.
The documents returned by the search engine areassumed to belong to the domain in hand and so are the extracted terms.
By contrast our approach doesnot require manually selected terms, but instead uses an existing domain structured multingual thesaurus.6 ConclusionIn this paper we have investigated a number of questions relating to the identification of the domain ofa term by domain classification of the document in which the term occurs.
We proposed and evaluateda straightforward method for domain classification of documents in 24 languages which uses a multilin-gual thesaurus to construct ?domain vectors?.
We investigated the extent to which humans agree aboutthe domain classification of documents and terms.
And, we investigated the extent to which terms arelikely to ?inherit?
the domain of their parent document.
Our results show that the domain classificationmethod has significant merit, that humans generally, but by no means universally, agree about domainclassification of documents and terms, and again that terms are generally, but certainly not universally,likely to be of the same domain as the document in which they occur.7 AcknowledgmentsThe authors would like to acknowledge funding from the European Union FP-7 programme for the TaaSproject, grant number: 296312.
We would also like to thank the human assessors without whose carefulwork the results reported here would not have been obtained.
Finally we thank our project partners in theTaaS project for user studies with translators and terminologists, contributions to the TaaS system, anddevelopment of the TaaS domain classication scheme and the EuroVoc-to-TaaS mapping.19ReferencesBasant Agarwal and Namita Mittal.
2014.
Text classification using machine learning methods-a survey.
InProceedings of the Second International Conference on Soft Computing for Problem Solving (SocProS 2012),December 28-30, 2012, pages 701?709.
Springer.Ahmet Aker, Evangelos Kanoulas, and Robert J Gaizauskas.
2012.
A light way to collect comparable corpora fromthe web.
In Proceedings of Eighth International Conference on Language Resources and Evalution (LREC),pages 15?20.Ahmet Aker, Monica Paramita, and Robert Gaizauskas.
2013.
Extracting bilingual terminologies from comparablecorpora.
In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL2013).Ahmet Aker, Monica Paramita, Emma Barker, and Robert Gaizauskas.
2014a.
Bootstraping Term Extractors forMultiple Languages.
In Proceedings of the International Conference on Language Resources and Evaluation(LREC).Ahmet Aker, Monica Paramita, Ma?rcis Pinnis, and Robert Gaizauskas.
2014b.
Bilingual dictionaries for all EUlanguages.
In Proceedings of the International Conference on Language Resources and Evaluation (LREC).Teresa Mihwa Chung.
2003.
A corpus comparison approach for terminology extraction.
Terminology, 9(2).Flavio De Benedictis, Stefano Faralli, Roberto Navigli, et al.
2013.
Glossboot: Bootstrapping multilingual domainglossaries from the web.
In Proceedings of the 51st Annual Meeting of the Association for ComputationalLinguistics, pages 528?538.Bruno de Besse?, Blaise Nkwenti-Azeh, and Juan C. Sager.
1997.
Glossary of terms used in terminology.
Termi-nology.
International Journal of Theoretical and Applied Issues in Specialized Communication, 4:117?156(39).Patrick Drouin.
2004.
Detection of domain specific terminology using corpora comparison.
In Proceedings of theFourth International Conference on Language Resources and Evaluation (LREC2004).John S. Justeson and Slava M. Katz.
1995.
Technical terminology: Some linguistic properties and an algorithmfor identification in text.
Natural Language Engineering, 1(1):9?27.Mitsuhiro Kida, Masatsugu Tonoike, Takehito Utsuro, and Satoshi Sato.
2007.
Domain classification of technicalterms using the web.
Systems and Computers in Japan, 38(14):11?19.Adam Kilgariff.
2014.
Finding terms in corpora for many languages with the Sketch Engine.
14th Conference ofthe European Chapter of the Association for Computational Linguistics.Su Nam Kim, Timothy Baldwin, and Min-Yen Kan. 2009.
An unsupervised approach to domain-specific termextraction.
In Australasian Language Technology Association Workshop 2009, page 94.Christopher D Manning, Prabhakar Raghavan, and Hinrich Schu?tze.
2008.
Introduction to information retrieval,volume 1.
Cambridge university press Cambridge.Ma?gorzata Marciniak and Agnieszka Mykowiecka.
2013.
Terminology extraction from domain texts in polish.In Intelligent Tools for Building a Scientific Information Platform, pages 171?185.
Springer.Maria Teresa Pazienza, Marco Pennacchiotti, and Fabio Massimo Zanzotto.
2005.
Terminology extraction: ananalysis of linguistic and statistical approaches.
In Knowledge Mining, pages 255?279.
Springer.Ma?rcis Pinnis, Nikola Ljubes?ic?, Dan S?tefa?nescu, Inguna Skadin?a, Marko Tadic?, and Tatiana Gornostay.
2012.Term extraction, tagging, and mapping tools for under-resourced languages.
In Proceedings of the 10th Confer-ence on Terminology and Knowledge Engineering (TKE 2012), June, pages 20?21.Gerard Salton and Michael E Lesk.
1968.
Computer evaluation of indexing and text processing.
Journal of theACM (JACM), 15(1):8?36.Inguna Skadin?a, Ahmet Aker, Nikos Mastropavlos, Fangzhong Su, Dan Tufis, Mateja Verlic, Andrejs Vasil?jevs,Bogdan Babych, Monica Paramita, Paul Clough, Robert Gaizauskas, and Nikos Glaros.
2012.
Collecting andusing comparable corpora for statistical machine translation.
In Proceedings of the 8th International Conferenceon Language Resources and Evaluation (LREC), Istanbul, Turkey.20Fangzhong Su and Bogdan Babych.
2012.
Measuring comparability of documents in non-parallel corpora forefficient extraction of (semi-) parallel translation equivalents.
In Proceedings of the Joint Workshop on Exploit-ing Synergies between Information Retrieval and Machine Translation (ESIRMT) and Hybrid Approaches toMachine Translation (HyTra), pages 10?19.
Association for Computational Linguistics.Takehito Utsuro, Mitsuhiro Kida, Masatsugu Tonoike, and Satoshi Sato.
2006.
Collecting novel technical termsfrom the web by estimating domain specificity of a term.
In Computer Processing of Oriental Languages.Beyond the Orient: The Research Challenges Ahead, pages 173?180.
Springer.21
