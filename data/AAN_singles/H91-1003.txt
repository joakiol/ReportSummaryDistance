THE ESPRIT PROJECT POLYGLOTLouis BovesDept.
of  Language and SpeechN i jmegen UniversityP.O.
Box 91036500 HD Ni jmegen,  The Nether landsABSTRACTThe ESPRIT project POLYGLOT aims at developing multi-lingualSpeech-to-Text and Text-to-Speech onversion and to integrate thistechnology in a number of commercially viable prototypeapplications.
Speech-to-Text conversion is mainly concerned withvery large vocabulary isolated word recognition.
It uses a statisticalknowledge based approach that was pioneered for Italian and is nowbeing extended to other languages.
Work on continuous peechrecognition has the character ofan in-depth feasibility study.
For Text-to-Speech conversion a new multi-level data structure is developed thatfacilitates rule writing by offering a semi-graphical ru e format.
Therecognition and synthesis technology is used to build a number ofgeneric prototype applications that mainly address office automation.INTRODUCTIONPolyglot is a 16.5 million ECU (i.e., approximately $23million) project hat is funded by the European Community aspart of the ESPRIT-2 program.
As is usual in ESPRIT, theEuropean Community covers 50% of the total costs; the otherhalf of the cost is paid by the partners in the PolyglotConsortium.
In terms of manpower the resources amount o atotal of some 133 man years.
The project started in August1989.
It was approved for a duration of three years.
Originally,a workplan spanning five years was submitted, so considerablecuts in the plans were necessary.
An attempt will be made toobtain new ESPRIT funding for a continuation project hat willprobably go under the name Polyglot-2.Polyglot builds partly on the results of a previous ESPRITproject that was titled "Linguistic Analysis of EuropeanLanguages" \[1\].
In that predecessor p oject the attention wasmainly focused on the acquisition of databases and statisticalknowledge about he seven European languages that are beinginvestigated in Polyglot.
In alphabetical order these languagesare British-English, Dutch, French, German, Greek, Italian andSpanish.
The data and knowledge acquired in that project werea.o.
used to build grapheme-to-phoneme and phoneme-to-grapheme conversion modules for the seven languages.
Ofcourse, the phoneme-to-grapheme conversion modules requiredthe development of language models; for that goal Markovmodels based on Part-of-Speech information were developed.Since it is necessary to have at least one partner in each ofthe seven language communities the Polyglot Consortium isnecessarily quite large; at this moment it consists of thefollowing partners (there have been some modifications in thepast):?
Olivetti Speech and Language Laboratory, Torino, Italy,acting as Contractor, i.e., as leader of the consortium?
Bull SA, Massy, France?
Philips Hamburg Research, now located in Aachen,Germany?
Siemens AG, Neurenberg, Germany?
Centre for Speech Technology Research, Edinburgh, U.K.?
LIMSI/CNRS, Orsay, France?
I.P.O., Eindhoven, The Netherlands?
Nijmegen University, The Netherlands?
Patras University, Greece?
Ruhr University, Bochum, Germany?
Universidad Polytecnica de Madrid, SpainThe work in Polyglot is structured in two ways.
First thereare five Work Packages (WP), one dealing with Isolated WordSpeech Recognition (IWSR), one with Continuous SpeechRecognition (CSR), one with Text-to-Speech Conversion(TTS), one with Applications (APP) and one with CommonTasks (COT).
Perpendicular to this structuring based ontechnologies there is another organizing principle, viz.
thedistinction between Language Dependent and LanguageIndependent work \[2\].
Polyglot aims ~ the development ofLanguage Independent frameworks in which LanguageDependent knowledge and data can be integrated in order tobuild homogeneously structured multi-lingual speech systems.In this paper the five Work Packages will be the organizingprinciple.P i lo t  LanguagesIn a consortium as large as Polyglot that, moreover,assembles partners from countries with widely divergingcultural and economic status and traditions it is impossible thatall partners have the same level of expertise in all aspects ofthe work.
That is reflected by the fact that some of the partnersavail of high quality speech recognition and/or speechsynthesis systems for their own language, whereas otherpartners are still in early stages of building such systems fortheir own language.
That is not necessarily due to a lack ofknowledge or expertise; it can also be the result of strategicdecisions of some partner to concentrate his efforts on othertopics in the past.
In such a situation it is only natural that theshort term goals for the languages are different.
This introducesthe concept of pilot languages, i.e., languages for which thework is ahead of the remaining languages.
The experiencegained in the work on the pilot languages i disseminated andused to speed up the work for the other languages.COMMON TASKSIn ESPRIT projects are set up as collaborative enterprises.Thus explicit efforts are made to ensure that all partnerscooperating in a Consortium use common, or at leastcompatible procedures.
Ideally, they should even use common7hardware.
In Polyglot he ideal of common hardware could notbe reached, since most of the partners already had acquired mostof the computers necessary for carrying out the research beforethe start of the project.
The budget available for the project didnot allow the purchase of completely new equipment for theproject.
This necessitated considerable ffort in specifyingstandards for hardware and software in order to obtain a commonplatform,One very important advantage of a collaborative project isthat the costs of software development can be kept to aminimum by distributing the development tasks over thepartners.
Obviously, this is one aspect where the distinctionbetween Language Independent frameworks and LanguageSpecific data plays a major role: the Language Independentsoftware needs to be written only once and made available to allpartners.
Since it is not yet feasible to produce completelysystem independent software it was specified that all softwarewritten as part of the project should be in 'C' and that, with fewexceptions, every program should be able to compile and runon a SUN station and on art MS-DOS PC.Another field where standardization is crucial is therecording of speech databases.
Since databases for sevendifferent languages are needed, it was not possible to do allrecordings at a single site.
In order to obtain compatiblerecordings from seven or so different sites in seven differentcountries, precise specifications of the recording conditionshad to be developed.
That process was complicated by the factthat several Work Packages had different requirements withrespect to recording quality and procedures.It has been the task of the WP Common Tasks to provide allstandards and specifications.
Moreover, this WP wasresponsible for the organization and the monitoring of theacquisition of all databases needed in the other WP's.
Finally,it was responsible for the production of the software forCOITIITtOn use .ISOLATED WORD SPEECH RECOGNITIONThe WP IWSR aims at the implementation of very largevocabulary, speaker adaptive, isolated word speech recognitionfor all seven languages of the consortium.
In practice, anattempt is made to extend an existing system for Italian to sixother languages \[3\].
That system was designed to offer fastspeaker enrollment, easy modification of the dictionary andflexible control.The systems run on an MS-DOS PC that uses one or twospecial-purpose plug-in boards.
After signal processing,resulting in vectors of 20 LPC Cepstrurn coefficients and twoenergy values for each 10 ms speech frame, each frame is giventhe label of the nearest phonemic template.
The string ofprototypes thus formed is then used for a fast lexical access thatretrieves the 100 or so most likely word candidates.
TheDynamic Programming string match used in this preselectionphase relies on knowledge about phoneme confusions,phoneme durations and phoneme and diphone frequencies in thelanguage.
Typically, some 25 templates are used duringpreselection.
Next, Fine Phonetic Analysis (FPA) is used tosort the word candidates produced uring preselection and retainonly the 1-5 best scoring candidates.
The objective function isbased on the distance from spectral prototypes (during FPA thenumber of prototypes is typically around 70), duration andthree features derived from energy.
A left-to-right beam searchis used to find the optimal alignment between the speech andthe phonetic representations of the words returned bypreselection.
Finally, a language model is used to select thebest scoring word among the output of FPA.
The languagemodel combines word frequencies, a bigram model and somedeterministic knowledge and the acoustic probability of eachcandidate in a single probabilistie score.Equipped with just the DSP board that performs the LPCanalysis the system runs in real-time with vocabularies of20,000 words.
In order to obtain real-time performance withmuch larger vocabularies (say between 60,000 and 100,000words) another special purpose board, built with four differentASIC's that speed up preselection has been designed.Speaker EnrollmentMost of the knowledge in the system is obtained fromprocessing large amounts of speech from a large number ofdifferent speakers.
Thus, only the prototypes used inpreselection are speaker independent.
Since the number ofprototypes used during that stage is typically very small, it isan easy task to acquire personal prototypes for a new speaker.Enrollment consists of speaking some 40 carefully chosenwords that are processed by automatic prototype xtractionsoftware.Modifying the VocabularyTools are provided for the maintenance of the dictionaries.When new words are added, the graphemic forms areautomatically converted to phonemic forms and rules areprovided for the generation of the most common pronunciationvariants.
Since lexical access during preselection and thescoring during FPA heavily rely on phonemic models, accuratemodeling of the pronunciation is mandatory.Flexible ControlFor many applications the performance of an IWSR systemcan be immensely improved if the size of the vocabulary can bedynamically adapted to the state of the dialogue.
In fact, verylarge vocabularies are only needed during free text dictation.The IWSR system developed for Italian, and in the process ofadaptation for the other languages, allows on-line selection ofsubsets of words from the base vocabulary.
Obviously, theability to make this selection is especially important inpreselection.State-of-the-ArtMost of the work needed to implement preselection for alllanguages is now ready.
Dictionaries comprisingrepresentations for use in preselection have been compiled forall languages.
Also, prototypes for a small number of speakersin each language have been built.
Preliminary tests run inJanuary 1991 have shown that acceptable preselection results(for at least 98% of the words spoken, the correct word is in thepreselection list) are obtained for all languages underconsideration.
Formal tests of preselection performance withlexica of 2000 words are planned for April 1991.
For the pilotlanguages English and Dutch much larger dictionaries areavailable (and will be tested).CONTINUOUS SPEECH RECOGNITIONUnlike IWSR, where concrete applications are aimed at, theWP Continuous Speech Recognition was set up to investigatethe feasibility of continuous peech recognition in situationsthat differ from the DARPA Resource Management task.
Inaddition, it is proposed to carry out an in-depth investigationof the viability of alternatives for the HMM approach.
Still,the DARPA RM task was chosen as a reference, in order to beable to relate the performance of the systems built in Polyglotto a generally accepted and well-understood standard.Originally it was planned to do a large number ofexperiments in which integrated search should be comparedwith bottom-up honeme based search.
Moreover, both searchstrategies hould be used with HMM, TDNN, and the framelabels produced by the Olivetti IWSR system described above.Finally, the approaches should be compared with respect oacoustic-phonetic decoding and word and sentence accuracy.Unfortunately, the limited resources available for this WPcombined with a host of practical problems forced a drasticreduction of these plans.
It is now intended to limit theinvestigation toTDNN and HMM in integrated search.
On theother hand, more emphasis will be put on work on languagemodels and on system integration aspects, especially withrespect o the possibility of using linguistic constraints toimprove phonetic decoding.
Apart from the DARPA speakerdependent RM task the systems will be tested on a corpus ofread newspaper text.
Such a corpus, limited to a vocabulary of5000 words, is available for British-English and German.Formal tests of the performance on the DARPA RM task will beavailable in August 1991.
Preliminary tests with theContinuous Mixtures Densities HMM system developed byPhilips Hamburg Research showed encouraging performance:using 46 monophones and 227 triphones a word error rate of23.3% was obtained in the no-grammar condition.
Thetriphones were selected by choosing only those that had afrequency of occurrence > 10 in the dictionary (data presentedby Herman Ney during the January 1991 Review Meeting).TEXT-TO-SPEECH CONVERSIONIn Polyglot, a relatively large part of the resources isdevoted to Text-to-Speech ('ITS) conversion.
This is becausewe believe that a high quality TTS system is essential for themajority of the applications in which speech technology is toprovide the major user interface.
Moreover, high quality TTSsystems are not yet available for most languages represented inPolyglot.
Last but not least, even if such systems would existfor some languages, they cannot be integrated into a singlesystem that has an architecture that is uniform for alllanguages.Advanced FeaturesAutomatic Language Identif ication.
The TTSsystem that is being developed in Polyglot will have a numberof unique features.
One is an automatic Language IdentificationModule (LIM) tIat is able to identify the language of eachsentence sent to the TTS system.
Since we will have a multi-lingual system with a uniform architecture for all languages theLIM will act as an intelligent switch that selects theappropriate language for each sentence.
LIM is implemented asa rule-based program that uses three knowledge sources:?
a list of very frequent words for all languages?
a list of letter combinations that can or cannot occur wordinitially and word finally in any of the languages?
a list of letter sequences that cannot occur word internallyin any of the languagesThese word-level knowledge sources are not sufficient odetermine the language for each word.
In fact, many words can,and do, occur in more than one language, Therefore, a sentencelevel scoring mechanism is added that selects the most likelylanguage for each complete sentence \[4\].
It has been shownthat LIM in its present form performs virtually without errors.Most problem cases that were found in a test on large textcorpora appeared to be due to errors of a very preliminaryversion of the sentence boundary detection algorithm and theinability of the LIM to recognize, e.g,, addresses in foreignlanguages.Syntax and Prosody.
Most existing TTS systemssuffer from inadequate prosody, due to the fact that syntacticprocessing is kept to a minimum.
However, the Polyglotsystem will do sufficient syntactic and prosodic processing tobe able to generate adequate intonation in most neutral texts.To that end it will use a medium sized lexicon (between 5,000and 10,000 most frequent full words for each language)containing phonemic forms and word class information, a setof 'morphological' rules that guess the word classes of thewords not found in the dictionary, a Markov grammar thatcomputes the optimal ordering of the possible classes of allwords and a Wild Card Parser (WPC), i.e., a deterministic parserbased on a Context Free Grammar.
The WPC attempts toaccount for the maximum number of words in an input sentenceusing the minimum number of major syntactic onstituents.Thus, it yields a partial parse each time a complete parse of theinput is not possible.
Partial parses may contain words that arenot part of a syntactic onstituent; these unaccounted words arecalled Wild Cards \[5\].
The output of the WPC is given to aprosodic processor that implements a form of the 'Focus-Accent' theory that predicts the relation between syntax andprosody as well as the words that should carry pitch accents\[6,7\].
Experiments for Dutch have shown that the approachyields excellent results.
Consultation with the partnersworking on other languages has confirmed that the sameapproach should work for all languages under consideration.Multi-level Data Structure.
In order to be able to takefull advantage of the syntactic and prosodic information it wasnecessary to design a multi-level data structure for the TTSsystem in which information on several levels can be stored insuch a way that levels can be linked with one another and eachrule can access all information on all levels that are relevant\[8\].
In order for this quite complicated ata structure to beaddressable by phonetic rule writers, a rule formalism had to bedesigned that allows expression of rules in the form of agraphical representation f the relevant levels of the datastructure.
It is expected that the prosodic information will notonly be helpful in generating high quality intonation contours,but that it will also enable us to improve the segmental rules,because it offers an easy way to account for interaction betweenprosodic and segmental phenomena.The  Arch i tec tureThe architecture of the Polyglot 'ITS system is highlymodular.
Thanks to the flexibility of the multi-layered datastructure and the access functions that come with it, it ispossible for each language to use exactly those modules that areneeded.
It is possible to add layers to the data structure, and thatcan be done in such a way that only those languages that use thenew layers will actually implement them.
Thus it is possiblefor each language to choose exactly those types of information(i.e., layers) that are necessary.
For instance, morphologicalanalysis is essential for English, but it may not be necessaryfor Italian.
If the Italian version of the 'ITS system does notneed the morphology layer, it simply does not use it.
Ofcourse, it is then not possible for rules in the Italian system torefer to morphological data.The Polyglot 'ITS system will use rule based synthesis.Segmental rules that produce highly intelligible speech areavailable for Italian, Spanish and Dutch.
For Dutch the rulebased system that is under development, partly in theframework of Polyglot, partly under the national Dutch SPINprogram, has been shown to equal the best competing diphonesystem in intelligibility both on the level of segments andparagraphs \[9\].
It is believed that rule based synthesis offersbetter opportunities to improve speech quality than diphonesystems.
The rules for the other languages will be obtained byadapting existing rules for other languages.
In order to supportthat conversion task a very flexible working environment hasbeen built that allows the rule developer to look at parametertracks and spectrograms of both natural and syntheticutterances, to listen to both natural and synthetic versions ofan utterance, and to change rules interactively.For all languages a prosody data base has been recorded, thatconsists of large numbers of sentences covering most syntacticand prosodic structures of interest as well as a number of shortprose passages.
All material has been read by two professionalspeakers, a female and a male.
The speech material istranscribed on the segmental nd the suprasegmental level andthe resulting information is stored in a data base that allowsone to access the data in many different ways.
It is intended tosegment and label the speech on the level of segments, o thatthe information can be used to develop and test duration rules.In addition, the suprasegmental transcriptions are used to deriveand test rules that predict pause locations and pitch contours.Most of the linguistic and phonetic rules are implemented insuch a way that they can be executed on a PC.
The conversionof phoneme target values to filter parameters and thecomputation of the eventual speech signal are done on aDSP32C board.APPL ICAT IONSESPRIT projects are mainly application driven.
Unlike thesituation in the DARPA community, one of the majorevaluation criteria for ESPRIT projects is the commercialinterest of the results and the commitment of the industrialpartners to commercialize those results.
Thus, it is only naturalthat a considerable amount of the resources in Polyglot arespent to the development of prototype applications.
Unlikemost groups working on speech technology the PolyglotConsortium is not exclusively aiming at applications thatinvolve information access via the public telephone network.Most of the applications that are under development areintended for use in the office or in the classroom.
Of course,many commercially viable applications will require thecombination, if not the integration of speech recognition andtext-to-speech conversion.
As can be seen below, this isreflected in some of the prototypical applications in Polyglot.Also, the applications that are at this moment limited to eitherspeech input or speech output can be easily extended to exploita combination of both technologies.Application Arch i tec tureIn Polyglot it was decided that the work on applicationsshould not be limited to the development of a number ofprototypes.
Instead, it was felt that the development of auniform Application Architecture that would enable applicationdevelopers to integrate speech technology in an easy way wasat least as important from the point of view of futureexploitation of the technology.
Therefore, one of the majortasks of the APP WP is the specification and implementation ofso called Application Programming Interfaces (API) that willallow almost every application program to interface with thePolyglot IWSR and 'ITS system.
The API's will be provided forMS-DOS and MS-WINDOWS; the desirability to provide APrsfor UNIX is still under investigation.Application PrototypesDictation.
Polyglot is working on a number of prototypeapplications.
Perhaps the most ambitious one is reportpreparation.
Although there are many domains where such asystem would be useful, the demonstration prototype will belimited to medical dictation.
The prototype will work in twomodes, viz.
interactive and free dictation.
In interactive modethe system will guide the user through a predefined protocol.The system will ask a number of questions, using the TTSsystem, and at each point in the dialogue the user is offered anumber of possible answers that he or she can speak.
Eachalternative will generate the appropriate passage in theeventual report.
In free dictation mode the dialogue will still bethe same, thus ensuring that the report will be complete underall circumstances, but now the user is offered an extraalternative after each question; if (s)he does not choose one ofthe fixed alternatives, but the added alternative free text, thesystem will go into dictation mode and the user can enterarbitrary text that will be copied to the report.
A laboratoryversion of the complete system is available for a Radiologyapplication i  Italian.
A fully developed prototype will followsoon.
For British-English a laboratory version of theinteractive mode is available for applications in Radiology andPathology.
Prototypes for the other languages are expected tobe ready by the end of 1991.Office Automation.
Bull SA already markets anapplication amed Mlc roname that offers access to a database of telephone numbers in a company.
At present, access isonly via a terminal, Ergonomic and marketing studies haveshown that there is a need for access by voice.
The speechversion of M lc roname will be offered integrated with aspeech-driven version of another product, called Micropost,that offers telephone access to Electronic Mail.
The user will10be offered the possibility of accessing his or her E-Mail systemvia the public telephone network, scan through the messagesand ask that one or more messages be read by the TTS system.Obviously, this is one of the applications where automaticidentification of the language of the message is essential.Teaching Aids.
In a multi-lingual community likeEurope there is an ever increasing need for language trainingand teaching.
One of the Polyglot applications addresses thisneed by offering flexible computer assisted instruction inlearning the meaning of words, in spoken languagecomprehension and in spelling proficiency.
Based on a CD-ROM containing a large number of multi-lingual dictionariesthe user will be able to enter any word in one of the languagesand see and hear the translation in another language.
Sincemost words will have several, if not many, translations, it willbe possible to view and to hear the words in sentence contextsthat help to make the correct choice.
In another applicationthe TTS system will read sentences or passages to the user inone of the languages.
The user is then asked questions that testcomprehension.
On request, the computer can check thespelling proficiency of by asking the user to type the sentencesthat were spoken and compare the user input with the text sentto the 'Iq'S system.CONCLUSIONThe ESPR1T project Polyglot concentrates on the extensionof existing technology to make it available in uniformarchitectures for large numbers of languages.
It is believed thatthis is extremely important for the successful launching ofmany applications in the multi-lingual community that the ECis now, and that it probably will remain for a long time tocome.
In addition to extending existing technology to evermore languages, the project should make substantialcontributions to to our knowledge about the structure of speechand spoken language.
These contributions will be mostapparent in the fields of text-to-speech conversion andcontinuous peech recognition.
With respect o isolated wordspeech recognition we believe that the attempt o extendexisting technology to many other, phonetically quitedifferent languages will also advance our understanding of thetechnology.REFERENCES1.
Boves, L., "A multi-lingual language model for largevocabulary speech recognit ion," Proceedings fromEUROSPEECH-89, Vol.
2:168-171, Paris, France, 1989.2.
Vittorelli, V., Adda, G., Billi, R., Boves, L., Jack, M,, andVivalda, E., "Esprit POLYGLOT Project: Multi Language/Speech Technology," Acoustics Bulletin:IT-20, October1990.3.
Billi, R., Arman, G., Cericola, D., MoUo, M.J., Tafini, F.,Varese, G., and Vittorelli, V., "A PC-based very largevocabulary isolated word speech recognition system,"Proceedings from EUROSPEECH-89, Vol.
2:157-160, Paris,France, 1989.4.
Henrich, P., "Language identification for automaticGrapheme-to-Phoneme conversion of foreign words in aGerman Text-to-Speech system," Proceedings fromEUROSPEECH-89:220-223, Paris, France, 1989.5.
Willemse, R., and Boves, L., "Context Free Wild CardParsing in a Text-to-Speech System," Proceedings fromICASSP-.91, Toronto, Canada, 1991.6.
Baart, J.L.G., Focus, Syntax, and Accent Placement: towardsa rule system for the derivation of pitch accent patterns inDutch as spoken by humans and machines, Ph.D. Dissertation,Leiden University, 1987.7.
Dirksen, A., and Terken, J., Specification of the proceduresfor prosodic marker assignment, Deliverable DEL-TT-11,Polyglot Project, 1991.8. van Lecuwen, H., and te Lindert, R., "Speech Maker: Text-to-Speech synthesis based on a multi-level, synchronized datastructure," Proceedings from ICASSP-91, Toronto, Canada,1991.9.
van Bezooijen, R., and Pols, L. C. W., "Evaluation ofallophone and diphone based Text-to-Speech conversion at theparagraph level," Proceedings from the Xllth Intern.
Congressof Phonetic Sciences, Aix en Provence, France, 1991.13.
