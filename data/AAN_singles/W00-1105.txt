Discriminative Power and Retrieval Effectiveness of PhrasalIndexing TermsSumio FujitaJust.system corporationBrainspark, Tokushima, J panEmail: Sumio Fuiita~iustsvstem.eo.it~AbstractIn spite of long controversy, effectiveness ofphrasal indexing is not yet clear.Recently, correlation between query length andeffect of phrasal indexing is reported.In this paper, terms extracted from the topic setof the NACSIS test collection 1are analyzedutilizing statistic tools in order to showdistribution characteristics of singleword/phrasal terms with regard to relevant/non-relevant documents.
Phrasal terms are found tobe very good discriminators in general but notall of them are effective as supplemental phrasalterms.
A distinction of informative / neutral /destructive phrasal terms is introduced.
Retrievaleffectiveness is examined utilizing query weightratio of these three categories of phrasal terms.IntroductionLonger queries are not necessarily better thanshorter queries in view of retrieval effectiveness,since longer queries may contain so-called noisyterms that hurt the performance.Given relevance judgements, we can say whichterms are noisy and which are not with regard toa certain topic description and a test collection.We can confwm that a term is good todiscriminate subject concepts if relevantdocuments contain such terms and non-relevantdocuments do not contain them and that a termis noisy if the situation is the opposite.The problem here is that not only noisy termsbut also good terms can harm the performance insome cases where term weighting is notadequate or terms are redundant.One example of such cases is complex termslike supplemental phrases or overlap bigramswhich violate term independence assumption.Phrasal terms are utilized either as replacementof single words or as supplemental units forsingle words, but according to our experience,phrasal terms as replacement of single words donot perform well.
Supplemental phrasal termsworks better in spite of the violation of termindependence assumption.Recent studies uncovered the correlationbetween phrase effectiveness and querylength(Fujita, 2000).In this paper, we will see the problem ofeffectiveness ofphrasal terms from two differentviewpoints utilizing a large test collection forJapanese text retrieval and statistical tools.NACSIS test collection I(NTCIR, 1999), whichconsists of a collection of abstracts of scientificpapers ( 330,000 records, 590MB in text ), twosets of topic description ( 30 topics for trainingand 53 topics for evaluation ) and relevancejudgement, provides us of a good opportunityfor this purpose.Topic description of NACSIS test collection 1contains four different fields, just like earlyversions of TREC topics, as follows:<title> fields consist of one ( typically simple )noun phrase.<description> fields consist of one ( typicallysimple ) sentence.<narrative> fields consist of 3 to 12 sentencesand contain detailed explanation of the topic,term definition, background knowledge, purposeof the search, preference in text types, criteria ofrelevance judgement and so on.<concepts> fields consist of lists of keywordscorresponding to principal concepts in theinformation need.Combining these four fields, different length ofquery sets for the same topics are prepared.47Topic field used A vg.Prec 1(Singlewordsonly)Avg.Prec2(sinoewords &Phrases)Avg.Prec2Avg.Precl<description> 0.3143 0.2846 .-0.0297<title> 0.2555 0.2265 -0.0290.3334 0.3079 -0.0255 <title>,<description><title>,<narrafive><narrative>0.30950.29850.31610.3210.36720.3640.3790.37020.3001 -0.00940.2895 -0.0090.3163 0.0002 <description>, <narrative><title>,<descripfion>,<narrative><description>,<coneepts><narrative>,<concepts>0.3233 0.00230.3786 0.01140.37610.39260.38440.01210.01360.01420.3681 0.3839 0.01580.371 0.3886 0.0176<title>,<description>,<concepts><title>,<narrafive>,<concepts><descripfion>,<narrative>,<concepts>qitle>,<description>,<narrafive>,<concepts><concepts>qitle>,<concepts>0.33160.3520.35040.3711Table 1: Performance comparison using 15 different versions of ?0.01880.0191Avg.
Avg.number numberof total of phrasalterms terms8.8 1.94.1 1.09.2 2.145.0 10.344.7 10.246.4 10.846.5 10.925.4 5.257.0 12.525.5 5.357.3 12.758.4 13.158.4 13.120.9 4.121.8 4.5ueries combining 4 fields1.
Phrasal IndexingFor the baseline run experiments, we utilized theengine of Coneeptbase S arch 1.2, a commercialbased search engine adopting vector spacemodel approach.1.1.
Linguistic Phrases as Indexing Unitsfor Japanese Text RetrievalFor automatic indexing of Japanese written text,once word boundary is detected bymorphological nalysis processing, word basedapproach normally adopted in English IR can beapplied.
Although computationally moreexpensive than in English, the accuracy ofJapanese morphological nalysis is quite highand sufficient for IR purpose.Our approach consists of utilizing noun phrasesextracted by linguistic processing assupplementary indexing terms in addition tosingle word terms contained in phrases.
Phrasesand constituent single word terms are U, eated inthe same way, both as independent terms, wherethe frequency of each term is countedindependently based on its occurrences.Linguistic phrases are normally contiguous kanjior katakana word sequences and internal phrasestructures are ignored.1.2.
Query Length and Effectiveness ofPhrasal IndexingAmong evaluation experiments of the NTCIR1workshop, correlation between query length andthe effect of phrasal indexing is reported in(Fujita, 1999).NTCIR topic description consists of four fieldsnamely <title>, <description>, <narrative> and<concepts> as shown in the previous chapter.The combination of these four fields makes 15different versions of queries for each topic.These 15 different versions of queries for 53topics are examined with phrasal terms and withonly single word terms.Table 1 shows the performance with 15 versionsof  queries, where we compared two types ofindexing language in question i.e.
single wordsvs.
single words + supplemental phrases.Performance is indicated as non-interpolatedaverage precision macro averaged for 53 topics.Since this experiment is designed to clarify theeffect of different length of queries, thefollowing settings are chosen:481) no pseudo feedback procedure isprocessed,2) no down-weighting coefficient is applied forphrasal terms,3) no field specific importance coefficient isapplied.Consequently, absolute performance is muchworse than our best performing runs.Out .of 15 versions of query sets, 10 timesphrasal indexing performs better than singleword only indexing, and 5 times vice versa.
Thisis exactly the situation described in literaturethat he effect of phrasal indexing is inconsistentand uncertain.We found out that there is clear correlationbetween the difference of average precision andnumber of terms contained in the query.Pearson's correlation coefficient between Avg.pree2 - Avg.precl and average number of terrnsaccounts for 0.57, while 0.52 between Avg.prec2 - Avg.precl and average number ofphrases.
Eliminating 8 query versions containing<concepts> field, correlation coefficientsbecome 0.96 and 0.95 respectively.<concepts> fields containing keywords that areessentially noun phrases, tend to favor phrasalindexing otherwise when using only one of thefields, single word runs perform better.The situation is different when more than twofields are combined.
Combining <title>,<description> and <narrative> fields, thesupplemental phrasal run performs better thanthe single word run.We can see that the length of query, which isnumber of features in the scoring function, isimportant factor as well as quality of phrasalterms extracted from topic description, in orderto evaluate phrasal indexing.Two aspects of characteristics of phrasal termsshould be considered:1) Are the phrasal terms good discriminator fsubject domain?2) Do the supplemental phrasal terms causesome undesirable influence to original wordbased queries?In the chapter 2, phrasal terms extracted fromthe topic set of the NACSIS test collection 1areexamined from the viewpoints of theirdiscriminative power.
In the chapter 3, we willsee another aspect of retrieval effectiveness.Df98561Term;/iJi~(research)83016 ~:~:(resul069911 364675 ~l~lt~(repon)63956 ~3-Pl~(charactefi~ics)61063 ~l~=(structure)58664 JY~-~(method)5841056807502465,,'.~  ~(system)~l~(analysis)MY(influence)47620 -~tti(evaluation)42130 gJ~(use)41584 ~-~/~(model)4123837567AS(process)~-?l~d~ (time)Table 2: High documentfrequency single word termsDf Term12817 ~f~ ~(effectiveness)6969 3 ~:~(3-dimension)5716 "~'~2~ 'rE(modeling)5183 ~ ~(efficient)4659 ~ 7 7" ~f /~(opt ic  fiber)2648 ~lJJ~J :~(user)1795 i~J\[~ ~(old people)1661 ~ '~ ~\]~(effecfive use)13471345(genetic algorithm)~ I~J(hierarohy)1038 a t m ~(ATM network)860799~/V- -~ ~7 =z= 7(groupware).K2E ~'d~(artifieial intelligence)777 ~' - -  ~ ~-~.~(data u' nsmission)672?
(distributional environment)Table 3: High document frequencyphrasal terms49~OO oa  .
.
.
.
?
, :o~ ~'"1  * .
?- p..,::--; -.o0.ZlL ?t !
?ot  C~$ O~ C~ 022 o~ G4?o  o, .
, : ;  .
.
,  ~ ?
.04 %?
S ?
* ~ o "":. o ~* :#.
I ? "
.
?o*  4 .
j  ~ .
, ?
.
~ ?oz  * ; ~ ?
.
.
j "  :~0,1~" ; i~ '  S::" " "-o I~-~-  .~" : - ,.
;:~ ~-.Ol o~15 0.2 o~ 03 o3~,Ji .oz .o ~i "O.1 ~15 02  O~ O~ O~Figure 1: p(occlrel ) as funct ion of  p(oce)Left above: short query single words, Right above: short query phrasesLeft below: long query single words, Right below: long query phrases2.
NTCIR  Data  AnalysisGreiff presented an analysis of TREC dataplotting each query terms in view ofdistributions in the whole document collectionand in relevant document sets(Greiff, 1998) andPickens et al applied this analysis for statisticalphrases(Pickens et al 2000)?Adopting their plotting approach, we will try toclarify distribution characteristics of  phrasalterms using mainly p(occlrel) and p(occ) whichare computed as document frequencies of theterm in relevant documents/the whole collectionrespectively divided by each number ofdocuments.2.1.
Occur rence  in Re levant  Documentsand in Non- re levant  DocumentsTable 2 and Table 3 shows high documentfrequency terms extracted from the short queryset of test topics.A short query refers to a query conslructed usingonly <description> field of topic description anda long query, all fields of  topic description.First, plotting of  p(occlnon-rel) as fimction ofp(occ) is not interesting since approximately therelation p(occlnon-rel)-'-p(occ) is observed.This is not surprising because number ofrelevant documents are generally very small andp(occ\[non-rel) can be approximated by p(occ).From Table 2 and Table 3, we can imagine thatthe distribution characteristics of  phrasal termsare almost same as single words i.e.
Zipfiandistribution but document frequencies of  phrasalterms are much smaller than single words.It seems difficult to get clear intuition aboutterm distribution characteristics from Figure 1,where p(occIrel) is plotted as fimction of p(occ).The same p(occ) value for some frequent ermsfound in plots indicates multiple occurrences ofa term in different queries.As Greiff suggests, a different visualization isdesirable for this graph.50i ,*o * .
.
.
.
l i  ,?
.
?
*~o , . '
"~.~"  ~ ~ ~.? "
. '
.
.
; - -  : , .
.~ .
.?
* .~f  ~.
?
kT i 'q~.
* ."
- . "
: .
.~ , '  :$ - i .Z  ., ?
.~?
?~1 .eo~?
#t?O O O O IO  ~ O ~ O Q OO Olt o?~m~ez-o~z~ee~B,m~aoca?
.
?m ?
t*?
o ?o-?"
.
',.-~ ,,"~ *.
'.i",,.,--~ ~'* I .- " ' - '  :~-'N'7.~!N!I4.~.
;;, ~, ; ; g,.
~: r ?~T:V  ~L ~| .
o*  ?
: ?
?
: * ' ?
-  ?
?
%%" .
: .
.? ""
L72~ .,.?~..'~...
.
.
?
.
.~ .
i "  ~* : ??
o ?
,  ,o?
?
?
".
.~ ~ -n 4 o * - tiFigure 2: Iog(p(occlrel)/p(occ)) as function of log(O(occ))Left above: short query single words, Right above: short query phrasesLeft below: long query single words, Right below: long query phrasesFirst p(occ) is replaced bylog(O(occ))=log(p(occ)/1-p(occ)), sincedistribution of p(oec) is too skewed?In Figure 1, if the dot representing a termlocated higher than the graph ofp(occ)=p(occlrel), the term can be a gooddiscriminator and should contribute to retrievalperformance given an adequate weightingscheme?
On the other hands, the terms plottedlower than the graph of p(occ)---p(occlrel) areby no means useful for retrieval performanceirrespective of weighting scheme.P(occirel) is replaced by log(p(occlrel)/p(occ)) inorder to illustrate this borderline.
In the case ofzero probability for p(occlrel), -6 is assigned forlog(p(occlrel)/p(oec)).This is equivalent to mutual informationMI(occ;rel) in information theory as follows:lod'P(?CC I rel) , ( p(occ, rel)Finally, Figure 2 illustrates distributioncharacteristics of terms much better than Figure1.The dots plotted above the y=0 line representuseful terms with respect to the query andShort queryLong querySingle words79.29%(291/367)Phrases66.34%(67/101)54.77%(13!
5/2401 ) 45 ?32%(315/695)Single words + phrases76.50%(358/468)52.65%(1630/3096)Table 4: Ratio of positive log(p(occlrel)/p(occ)) for query terms51Short queryLong querySingle words2.81Phrases4.381.65 2.92Table 5: Average of positive log(p(ocelrel)/p(occ)) value for query termsSingle words + phrase3.151.93relevance judgements.As this shows, single words and phrases are verysimilar distribution characteristics but documentfrequencies for phrases are much lower.
Averageof log(O(occ)) is -5.22 for single words while -8.64 for phrases in long queries.On the other hands, ratios of good terms, whoselog(p(occlrel)/p(occ)) is larger than 0, are shownin Table 4.From this observation, we can see limitedusefulness of phrasal terms with regards torelevance.
The ratio of positivelog(p(occlrel)/p(oce)) is lower than single words.This explains poor performance of pre-coordinated longer phrase based indexing thatutilizes phrases as replacements of single words.Phrasal terms tend to have high value oflog(p(occlrel)/p(oce)), but this does notnecessarily mean effectiveness of phrasal terms.As Figure 1 and Figure 2 illustrate, the termswith high log(p(ocelrel)/p(occ)) value tend tohave low log(O(oec)) that means extremelylower document frequency so that they are notso useful because of such lower frequency.2.2.
Measures for Phrasal TermEffectivenessTable 4 and Table 5 seem to supportsupplemental phrasal indexing, because fairlyhigh ratio of positive log(p(occlrel)/p(occ))terms, and higher average value oflog(p(oeclrel)/p(occ) ) are observed.
But for shortqueries, supplementing phrasal terms did notshow any positive effect as we have seen inTable 1.The following accounts are enumerated.1) Over-weighted phrasal terms may causetopic deviation from concepts represented bysingle words to concepts represented byphrasal terms.2) Supplemental phrasal terms are notalways informative because their constituentsingle words are already indexed.If the phrasal term AB has a high MI(AB,rel)value in contrast with MI(A, rel) and MI(B,rel),this is the ease where phrasal terms areeffective.Consider a supplemental phrasal term asinformative if and only if its MI(occ,rel) ispositive value and is higher than the sum ofMl(oce,rel) of constituent single words in viewof the query and relevance judgements.
A phrase"AB" is informative means that the occurrenceof a phrase "AB" gives more information aboutrelevance than occurrence of both single words"A" and "B".Table 6 shows the number and the ratio ofinformative phrasal terms.
-1 is assigned forMI(occ,rel) when p(oeclrel) is 0.Giving different values (-3 and -6) forMI(occlrel) when p(occlrel)=0 did not changethe results..{#phrasal termsl MI(AB,rel) >SUM( MI(A, rel), MI(B,rel))}Short query 31 (30.69%)Long query 146(21.01%)Table 6: Number of informative phrasal termsPositive MI(oec,rel)phrasal termsTotal phrasal terms67(66.34%) 101315(45.32%) 69552Category Phrasal termsInformative Jlij~.~ I / - -  b ~j~ll(transmission rate control),7 ~ - -  ~tJ,~fll (flow control),1/-- b ~tJ~l\] (rate control)Neutral -~/~ff" ~-Y .~ b ~j'f~(multicast communication),-~2~ ~ ~ ~ b(multieast),Destructive ~/J\]:~ l~J~(research trend);~l$.~r~ I~(partial),~_ ' l~(relatedness),~f~~llJl (sender side),~g~ "~'-- ~(multiple data),~2~-~" -~ Y, b ~:~(multicast environment),'~2~" ~ '.4 7" '~'~ ~' (multimedia data),~'f~ .
(receiver)Table 7 : Examples of phrasal terms in three categories from NACSIS topic 312.3.
Three Categories of Phrasal TermsThe following three categories of phrasal termsin view of possible contribution to retrievaleffectiveness are proposed from the previousdiscussion.1) Informative phrasal terms : MI(oce,rel) >MI(occ of constituent single words ,reD.2) Neutral phrasal terms :Z MI(occ of constituent single words ,rel) >MI(occ,rel) >= 0.3) Destructive phrasal terms : MI(occ,rel) < 0.For example, Table 7 shows phrasal termsextracted from all fields of topic 31 in NACSIStest collection 1,and classified accordingly.2.4.
Weight Ratio of Phrasal TermsRetrieval status values are computed as a linearcombination of each term weight, which is theproduct of the query weight and the documentweight of the term.
Using atn weighting in theSMART system for the same setting as the runsreported in Table 1, for each query term, thesums of weights of each query term arecomputed and for each query weight sum, ratioof informative phrasal terms and destructivephrasal terms are also computed.
Macro-averaged ratios of informative phrasal terms anddestructive phrasal terms are shown in Table 8.Still, short queries eem to contain better phrasesin the ratio despite the fact that no consistenteffectiveness for retrieval performance isobserved.2.5.
Correlation between phrasal termweight ratio and performancedifferenceFor each runs against he 53 test topic set bothwith short queries and long queries, correlationbetween query-by-query performance differenceand query-by-query weight ratio of bothinformative and destructive phrasal term weightratio are examined.
Performance difference ismeasured by non-interpolated average precisionand when the supplemental phrasal term runperforms better a positive value is given as wehave seen in Table 1.Table 9 shows the Pearson's correlationcoefficient between performance difference andeach weight ratio as well as and differencebetween weight ratios.Short queryLong queryAverage weightratio of informativephrases8.59% 256.47% 47Number of topicsContaininginformative phrasesAverage weightratio of destructivephrases10.40% 2616.14% 53Number of topicscontainingdestructive phrasesTable 8 : Weight ratio of phrasal terms ( macro-averaged for 53 topics )53Short queryLong queryInformative phrasalterm weight ratio(A)0.120.02Destructive phrasal termweight ratio(B)-0.05-0.05(A)-(B)0.110.04Table 9 : Pearson's correlation between performance difference and phrasal term weight ratioA positive correlation coefficient for informativephrasal terms and a negative correlationcoefficient for destructive phrasal terms areobserved as is expected, although the coefficientvalues are very small.Given a topic set, a document collection andrelevance judgements, we are able to knowwhich terms are good ( and possibly how goodthey are ) for retrieval performance but toexplain slight performance difference betweendifferent indexing strategies seems to be muchmore difficult.Short queries contain relatively better phrasalterms even though absolute number of suchterms is smaller than longer queries.
Bututilizing such phrasal terms does not always leadto performance improvement in macro-averagedprecision-recall basis evaluation.3.
Topic DeviationWhat we mean by topic deviation is aphenomenon that is similar to query drift causedby relevance feedback, but is incurred by someover-weighted supplemental phrasal terms.Terms representing some concepts in the topicare over-weighted consequently the searchresults are inclined to these concepts.We verified short queries where supplementalphrasal terms caused considerable degradation(difference in average precision is more than20%) and listed phrasal terms caused suchdegradation i  Table 10.As we can see, not only the neutral phrases intopics 50, 62 and 77, but also adding onlyinformative phrases caused degradation as intopic 76.<description> field of topic 76 is translated asfollows:"(I want to know about) methods forinterference detection between polyhedralrepresentations.
"This topic consists of two concepts namely"interference detection" and "polyhedralrepresentation" and the supplemented phrasaltom "~i~ifls: ra~\]"(between polyhedral) is part ofthe second concept.Retrieval effectiveness depends on a subtlebalance of weighting on each concept, especiallyin short queries, and redundant terms or over-weighted terms cause the scoring function toloose such balances.ConclusionsEffects of phrasal indexing in view of differentlength of queries are observed in theexperiments u ing NACSIS test collection 1, thefirst large scale test collection for Japaneseinformation retrieval.Our observations and conclusions are as follows:1) Distribution characteristics of phrasal termsas well as single word terms are examinedplotting each term's MI(oce,rel) as function oflog(O(occ)).2) Distribution characteristics of phrasal termsare similar to single word terms but theirfrequencies are much smaller than single words.3) Generally phrasal terms are comparably gooddiscriminators of relevant documents, if notsuperior, as single words are.4) In supplemental phrasal indexing, gooddiscriminator terms are not always effective forretrieval performance but only some phrasalterms are informative and possibly effective.5) Informative, neutral and destructive phrasalterms are defined by means of MI(oce,rel).6) Correlation between performance differenceand weight ratio of informative/destructive termsis examined and a very week correlation isobserved.54Topic34 i~  ~-~(improvement method)50 X I(artificial intelligence)60(educational issues)60 ~(occupation period)6o(educational situation)62 i ~\[~1~ - -~i (life-long learning)76(between polyhedral)77(braille transcription)78(mammals)(immortalize)Term p(occ) p(occ\]rel) p(oocl~rel) Iog(p(occ\[ Categorytel)/p(occ))0.000129 0 0.000129 -6 Destructive0.0023460.0000060.0000120.0000090.000440.3888890.2222220.2857140.0023050.0000060.0000060.0000090.0004355.11063-69.848081-66.475054NeutralDestructiveInformativeDestructiveNeutral0.000023 0.076923 0.000021 8.094061 Inform~ive0.000029 0.166667 0.000026 8.644108 Neutral0.000414 0 0.000414 -6 Destructive0.000065 0.666667 0.000053 9.241945 Inform~iveTable 10: Phrasal terms in degraded topics by supplemental phrases7) Explaining effectiveness of each query term isnot sufficient for explaining effectiveness ofphrasal indexing.
Even good discriminator termsmay hurt the retrieval effectiveness.This research is by no means conclusive but astarting point of a longer project hat hopefullyleads to a new weighting scheme to replacecurrent empirical down-weighting approach forsupplemental phrasal terms.AcknowledgementsThe author thanks NACSIS R&D department forproviding us of NACSIS test collection 1.
Weparticipated in the NTCIR workshop utilizingNACSIS test collection 1 (preliminary version)that is developed by NACSIS R&D department,thanks to understanding of academic societies(http://www.rd.nacsis.ae.ip/-nteadrrdthanks l-en.html) who provided the data.References\[1\] Fujita, S. (1999).
Notes on Phrasal Indexing:JSCB Evaluation Experiments at NTCIRAD HOC, NTCIR Workshop 1, Tokyo, 101-108.\[2\] Fujita, S. (2000).
Evaluation of JapanesePhrasal Indexing with a Large TestCollection, RIAO2000 Conferenceproceedings, Paris, 1089-1098.\[3\] Greiff, W.R. (1998).
A Theory of TermWeighting Based on Exploratory DataAnalysis, SIGIR '98, Melbourne, 11-19.\[4\] NTC1R.
(1999).http://www.rd,naesjs.ac.ip/-ntcadm/index-en.htmi.\[5\] Piekens, J.
Croft., W.B.
(2000) AnExploratory Analysis of Phrases in TextRetrieval, RIAO2000 Conferenceproceedings, Paris, 1179-1195.55
