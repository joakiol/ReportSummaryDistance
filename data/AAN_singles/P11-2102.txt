Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 581?586,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsIdentifying Sarcasm in Twitter: A Closer LookRoberto Gonz?lez-Ib?
?ez Smaranda Muresan Nina WacholderSchool of Communication & InformationRutgers, The State University of New Jersey4 Huntington St, New Brunswick, NJ 08901{rgonzal, smuresan, ninwac}@rutgers.eduAbstractSarcasm transforms the polarity of an ap-parently positive or negative utterance intoits opposite.
We report on a method forconstructing a corpus of sarcastic Twittermessages in which determination of thesarcasm of each message has been made byits author.
We use this reliable corpus tocompare sarcastic utterances in Twitter toutterances that express positive or negativeattitudes without sarcasm.
We investigatethe impact of lexical and pragmatic factorson machine learning effectiveness for iden-tifying sarcastic utterances and we comparethe performance of machine learning tech-niques and human judges on this task.
Per-haps unsurprisingly, neither the humanjudges nor the machine learning techniquesperform very well.1 IntroductionAutomatic detection of sarcasm is still in its infan-cy.
One reason for the lack of computational mod-els has been the absence of accurately-labelednaturally occurring utterances that can be used totrain machine learning systems.
Microbloggingplatforms such as Twitter, which allow users tocommunicate feelings, opinions and ideas in shortmessages and to assign labels to their own messag-es, have been recently exploited in sentiment andopinion analysis (Pak and Paroubek, 2010; Davi-dov et al, 2010).
In Twitter, messages can be an-notated with hashtags such as #bicycling, #happyand #sarcasm.
We use these hashtags to build alabeled corpus of naturally occurring sarcastic,positive and negative tweets.In this paper, we report on an empirical study onthe use of lexical and pragmatic factors to distin-guish sarcasm from positive and negative senti-ments expressed in Twitter messages.
Thecontributions of this paper include i) creation of acorpus that includes only sarcastic utterances thathave been explicitly identified as such by the com-poser of the message; ii) a report on the difficultyof distinguishing sarcastic tweets from tweets thatare straight-forwardly positive or negative.
Ourresults suggest that lexical features alone are notsufficient for identifying sarcasm and that pragmat-ic and contextual features merit further study.2 Related WorkSarcasm and irony are well-studied phenomena inlinguistics, psychology and cognitive science(Gibbs, 1986; Gibbs and Colston 2007; Kreuz andGlucksberg, 1989; Utsumi, 2002).
But in the textmining literature, automatic detection of sarcasm isconsidered a difficult problem (Nigam & Hurst,2006 and Pang & Lee, 2008 for an overview) andhas been addressed in only a few studies.
In thecontext of spoken dialogues, automatic detectionof sarcasm has relied primarily on speech-relatedcues such as laughter and prosody (Tepperman etal., 2006).
The work most closely related to ours isthat of Davidov et al (2010), whose objective wasto identify sarcastic and non-sarcastic utterances inTwitter and in Amazon product reviews.
In thispaper, we consider the somewhat harder problem581of distinguishing sarcastic tweets from non-sarcastic tweets that directly convey positive andnegative attitudes (we do not consider neutral ut-terances at all).Our approach of looking at lexical features foridentification of sarcasm was inspired by the workof Kreuz and Caucci (2007).
In addition, we alsolook at pragmatic features, such as establishingcommon ground between speaker and hearer(Clark and Gerring, 1984), and emoticons.3 DataIn Twitter, people (tweeters) post messages of upto 140 characters (tweets).
Apart from plain text, atweet can contain references to other users(@<user>), URLs, and hashtags (#hashtag) whichare tags assigned by the user to identify topic(#teaparty, #worldcup) or sentiment (#angry,#happy, #sarcasm).
An example of a tweet is:?
@UserName1 check out the twitter feed on@UserName2 for a few ideas :) http://xxxxxx.com#happy #hour?.To build our corpus of sarcastic (S), positive (P)and negative (N) tweets, we relied on the annota-tions that tweeters assign to their own tweets usinghashtags.
Our assumption is that the best judge ofwhether a tweet is intended to be sarcastic is theauthor of the tweet.
As shown in the following sec-tions, human judges other than the tweets?
authors,achieve low levels of accuracy when trying to clas-sify sarcastic tweets; we therefore argue that usingthe tweets labeled by their authors using hashtagproduces a better quality gold standard.
We used aTwitter API to collect tweets that include hashtagsthat express sarcasm (#sarcasm, #sarcastic), directpositive sentiment (e.g., #happy, #joy, #lucky), anddirect negative sentiment (e.g., #sadness, #angry,#frustrated), respectively.
We applied automaticfiltering to remove retweets, duplicates, quotes,spam, tweets written in languages other than Eng-lish, and tweets with URLs.To address the concern of Davidov et al(2010) that tweets with #hashtags are noisy, weautomatically filtered all tweets where the hashtagsof interest were not located at the very end of themessage.
We then performed a manual review ofthe filtered tweets to double check that the remain-ing end hashtags were not part of the message.
Wethus eliminated messages about sarcasm such as ?Ireally love #sarcasm?
and kept only messages thatexpress sarcasm, such as ?lol thanks.
I can alwayscount on you for comfort :) #sarcasm?.Our final corpus consists of 900 tweets in eachof the three categories, sarcastic, positive andnegative.
Examples of tweets in our corpus that arelabeled with the #sarcasm hashtag include the fol-lowing:1) @UserName That must suck.2) I can't express how much I love shoppingon black Friday.3) @UserName that's what I love about Mi-ami.
Attention to detail in preserving his-toric landmarks of the past.4) @UserName im just loving the positivevibes out of that!The sarcastic tweets are primarily negative (i.e.,messages that sound positive but are intended toconvey a negative attitude) as in Examples 2-4, butthere are also some positive messages (messagesthat sound negative but are apparently intended tobe understood as positive), as in Example 1.4 Lexical and Pragmatic FeaturesIn this section we address the question of whetherit is possible to empirically identify lexical andpragmatic factors that distinguish sarcastic, posi-tive and negative utterances.Lexical Factors.
We used two kinds of lexical fea-tures ?
unigrams and dictionary-based.
The dictio-nary-based features were derived from i)Pennebaker et al?s LIWC (2007) dictionary, whichconsists of a set of 64 word categories grouped intofour general classes: Linguistic Processes (LP)(e.g., adverbs, pronouns), Psychological Processes(PP) (e.g., positive and negative emotions), Per-sonal Concerns (PC) (e.g, work, achievement), andSpoken Categories (SC) (e.g., assent, non-fluencies); ii) WordNet Affect (WNA) (Strappara-va and Valitutti, 2004); and iii) list of interjections(e.g., ah, oh, yeah)1, and punctuations (e.g., !, ?
).The latter are inspired by results from Kreuz andCaucci (2007).
We merged all of the lists into asingle dictionary.
The token overlap between thewords in combined dictionary and the words in thetweets was 85%.
This demonstrates that lexicalcoverage is good, even though tweets are well1http://www.vidarholen.net/contents/interjections/582known to contain many words that do not appear instandard dictionaries.Pragmatic Factors.
We used three pragmatic fea-tures: i) positive emoticons such as smileys; ii)negative emoticons such as frowning faces; and iii)ToUser, which marks if a tweets is a reply toanother tweet (signaled by <@user> ).Feature Ranking.
To measure the impact of fea-tures on discriminating among the three categories,we used two standard measures: presence and fre-quency of the factors in each tweet.
We did a 3-way comparison of Sarcastic (S), Positive (P), andNegative (N) messages (S-P-N); as well as 2-waycomparisons of i) Sarcastic and Non-Sarcastic (S-NS);  ii) Sarcastic and Positive (S-P) and Sarcasticand Negative (S-N).
The NS tweets were obtainedby merging 450 randomly selected positive and450 negative tweets from our corpus.We ran a ?2 test to identify the features that weremost useful in discriminating categories.
Table 1shows the top 10 features based on presence of alldictionary-based lexical factors plus the pragmaticfactors.
We refer to this set of features as LIWC+.S-P-N S-NS S-N S-PNegemo(PP)Posemo(PP)Smiley(Pr)QuestionNegate(LP)Anger(PP)Present(LP)Joy(WNA)Swear(PP)AuxVb(LP)Posemo(PP)Present(LP)QuestionToUser(Pr)Affect(PP)Verbs(LP)AuxVb(LP)QuotationSocial(PP)Ingest(PP)Posemo(PP)Negemo(PP)Joy(WNA)Affect(PP)Anger(PP)Sad(PP)Swear(PP)Smiley(Pr)Body(PP)Frown(Pr)QuestionPresent(LP)ToUser(Pr)Smiley(Pr)AuxVb(LP)Ipron(LP)Negate(LP)Verbs(LP)Time(PP)Negemo(PP)Table 1: 10 most discriminating features in LIWC+for each taskIn all of the tasks, negative emotion (Negemo),positive emotion (Posemo), negation (Negate),emoticons (Smiley, Frown), auxiliary verbs(AuxVb), and punctuation marks are in the top 10features.
We also observe indications of a possibledependence among factors that could differentiatesarcasm from both positive and negative tweets:sarcastic tweets tend to have positive emotionwords like positive tweets do (Posemo is a signifi-cant feature in S-N but not in S-P), while they usemore negation words like  negative tweets do (Ne-gate is an important feature for S-P).
Table 1 alsoshows that the pragmatic factor ToUser is impor-tant in sarcasm detection.
This is an indication ofthe possible importance of features that indicatecommon ground in sarcasm identification.5 Classification ExperimentsIn this section we investigate the usefulness of lex-ical and pragmatic features in machine learning toclassify sarcastic, positive and negative Tweets.We used two standard classifiers often employedin sentiment classification: support vector machinewith sequential minimal optimization (SMO) andlogistic regression (LogR).
For features we used:1) unigrams; 2) presence of dictionary-based lexi-cal and pragmatic factors (LIWC+_P); and 3) fre-quency of dictionary-based lexical and pragmaticfactors (LIWC+_F).
We also trained our modelswith bigrams and trigrams; however, results usingthese features did not report better results than uni-grams and LICW+.
The classifiers were trained onbalanced datasets (900 instances per class) andtested through five-fold cross-validation.In Table 2, shaded cells indicate the best accura-cies for each class, while bolded values indicatethe best accuracies per row.
In the three-way clas-sification (S-P-N), SMO with unigrams as featuresoutperformed SMO with LIWC+_P and LIWC+_Fas features.
Overall SMO outperformed LogR.
Thebest accuracy of 57% is an indication of the diffi-culty of the task.We also performed several two-way classifica-tion experiments.
For the S-NS classification thebest results were again obtained using SMO withClass Features SMO LogRS-P-NUnigrams 57.22 49.00LIWC+_F 55.59 55.56LIWC+_P 55.67 55.59S-NSUnigrams 65.44 60.72LIWC+_F 61.22 59.83LIWC+_P 62.78 63.17S-PUnigrams 70.94 64.83LIWC+_F 66.39 67.44LIWC+_P 67.22 67.83S-NUnigrams 69.17 64.61LIWC+_F 68.56 67.83LIWC+_P 68.33 68.67P-NUnigrams 74.67 72.39LIWC+_F 74.94 75.89LIWC+_P 75.78 75.78Table 2: Classifiers accuracies using 5-fold cross-validation, in percent.583unigrams as features (65.44%).
For S-P and S-Nthe best accuracies were close to 70%.
Overall, ourbest result (75.89%) was achieved in the polarity-based classification P-N.
It is intriguing that themachine learning systems have roughly equal dif-ficulty in separating sarcastic tweets from positivetweets and from negative tweets.These results indicate that the lexical and prag-matic features considered in this paper do not pro-vide sufficient information to accuratelydifferentiate sarcastic from positive and negativetweets.
This may be due to the inherent difficultyof distinguishing short utterances in isolation,without use of contextual evidence.In the next section we explore the inherent diffi-culty of identifying sarcastic utterances by compar-ing human performance and classifierperformance.6 Comparison against Human Perfor-manceTo get a better sense of how difficult the task ofsarcasm identification really is, we conducted threestudies with human judges (not the authors of thispaper).
In the first study, we asked three judges toclassify 10% of our S-P-N dataset (90 randomlyselected tweets per category) into sarcastic, posi-tive and negative.
In addition, they were able toindicate if they were unsure to which categorytweets belonged and to add comments about thedifficulty of the task.In this study, overall agreement of 50% wasachieved among the three judges, with a Fleiss?Kappa value of 0.4788 (p<.05).
The mean accuracywas 62.59% (7.7) with 13.58% (13.44) uncertainty.When we considered only the 135 of 270 tweets onwhich all three judges agreed, the accuracy, com-puted over to the entire gold standard test set, fellto 43.33%2.
We used the accuracy when the judges2The accuracy on the set they agreed on (135  out of 270tweets) was 86.67%.agree (43.33%) and the average accuracy (62.59%)as a human baseline interval (HBI).We trained our SMO and LogR classifiers onthe other 90% of the S-P-N.
The models were thenevaluated on 10% of the S-P-N dataset that wasalso labeled by humans.
Classification accuracywas similar to results obtained in the previous sec-tion.
Our best result -- an accuracy of 57.41%--was achieved using SMO and LIWC+_P (Table 3:S-P-N).
The highest value in the established HBIachieved a slightly higher accuracy; however,when compared to the bottom value of the sameinterval, our best result significantly outperformedit.
It is intriguing that the difficulty of distinguish-ing sarcastic utterances from positive ones andfrom negative ones was quite similar.In the second study, we investigated how wellhuman judges performed on the two-way classifi-cation task of labeling sarcastic and non-sarcastictweets.
We asked three other judges to classify10% of our S-NS dataset (i.e, 180 tweets) into sar-castic and non-sarcastic.
Results showed anagreement of 71.67% among the three judges witha Fleiss?
Kappa value of 0.5861 (p<.05).
The aver-age accuracy rate was 66.85% (3.9) with 0.37%uncertainty (0.64).
When we considered only caseswhere all three judges agreed, the accuracy, againcomputed over the entire gold standard test set, fellto 59.44% 3 .
As shown in Table 3 (S-NS: 10%tweets), the HBI was outperformed by the automat-ic classification using unigrams (68.33%) andLIWC+_P (67.78%) as features.Based on recent results which show that non-linguistic cues such as emoticons are helpful ininterpreting non-literal meaning such as sarcasmand irony in user generated content (Derks et al,2008; Carvalho et al, 2009), we explored howmuch emoticons help humans to distinguish sarcas-tic from positive and negative tweets.
For this test,we created a new dataset using only tweets withemoticons.
This dataset consisted of 50 sarcastic3The accuracy  on the set they agreed on (129 out of 180tweets) was 82.95%.Ta sk S ?
N ?
P    (10% data set) S ?
NS (10% dataset) S ?
NS (100 tweets + emoticons)HBI [43.33%-62.59%] [59.44% - 66.85%] [70% - 73%]Test Features SMO LogR SMO LogR SMO Log R1 Unigrams 55.92 46.66 68.33 57.78 71.00 66.002 LIWC+_F 54.07 54.81 62.78 61.11 60.00 58.003 LIWC+_P 57.41 57.04 67.78 67.22 51.00 53.00Table 3: Classifiers accuracies against humans?
accuracies in three classification tasks.584tweets and 50 non-sarcastic tweets (25 P and 25N).
Two human judges classified the tweets usingthe same procedure as above.
For this task judgesachieved an overall agreement of 89% with Co-hen?s Kappa value of 0.74 (p<.001).
The resultsshow that emoticons play an important role inhelping people distinguish sarcastic from non-sarcastic tweets.
The overall accuracy for bothjudges was 73% (1.41) with uncertainty of 10%(1.4).
When all judges agreed, the accuracy was70% when computed relative the entire gold stan-dard set4Using our trained model for S-NS from the pre-vious section, we also tested our classifiers on thisnew dataset.
Table 3 (S-NS: 100 tweets) showsthat our best result (71%) was achieved by SMOusing unigrams as features.
This value is locatedbetween the extreme values of the established HBI.These three studies show that humans do notperform significantly better than the simple auto-matic classification methods discussed in this pa-per.
Some judges reported that the classificationtask was hard.
The main issues judges identifiedwere the lack of context and the brevity of themessages.
As one judge explained, sometimes itwas necessary to call on world knowledge such asrecent events in order to make judgments aboutsarcasm.
This suggests that accurate automaticidentification of sarcasm on Twitter requires in-formation about interaction between the tweeterssuch as common ground and world knowledge.7 ConclusionIn this paper we have taken a closer look at theproblem of automatically detecting sarcasm inTwitter messages.
We used a corpus annotated bythe tweeters themselves as our gold standard; werelied on the judgments of tweeters because of therelatively poor performance of human coders atthis task.
We semi-automatically cleaned the cor-pus to address concerns about corpus noisinessraised in previous work.
We explored the contribu-tion of linguistic and pragmatic features of tweetsto the automatic separation of sarcastic messagesfrom positive and negative ones; we found that thethree pragmatic features ?
ToUser, smiley andfrown ?
were among the ten most discriminatingfeatures in the classification tasks (Table 1).4The accuracy on the set they agreed on (83 out of 100tweets) was 83.13%.We also compared the performance of automaticand human classification in three different studies.We found that automatic classification can be asgood as human classification; however, the accura-cy is still low.
Our results demonstrate the difficul-ty of sarcasm classification for both humans andmachine learning methods.The length of tweets as well as the lack of expli-cit context makes this classification task quite dif-ficult.
In future work, we plan to investigate theimpact of contextual features such as commonground.Finally, the low performance of human coders inthe classification task of sarcastic tweets suggeststhat gold standards built by using labels given byhuman coders other than tweets?
authors may notbe reliable.
In this sense we believe that our ap-proach to create the gold standard of sarcastictweets is more suitable in the context of Twittermessages.AcknowledgmentsWe thank all those who participated as coders inour human classification task.
We also thank theanonymous reviewers for their insightful com-ments.ReferencesCarvalho, P., Sarmento, S., Silva, M. J., and de Oliveira,E.
2009.
Clues for detecting irony in user-generatedcontents: oh...!!
it's "so easy" ;-).
In Proceeding ofthe 1st international CIKM workshop on Topic-sentiment analysis for mass opinion (TSA '09).ACM, New York, NY, USA, 53-56.Clark, H. and Gerrig, R. 1984.
On the pretence theory ofirony.
Journal of Experimental Psychology: Gener-al, 113:121?126.
D.C.Davidov, D., Tsur, O., and Rappoport, A.
2010.
Semi-Supervised Recognition of Sarcastic Sentences inTwitter and Amazon, Dmitry Proceeding of Compu-tational Natural Language Learning (ACL-CoNLL).Derks, D., Bos, A. E. R., and Grumbkow, J. V. 2008.Emoticons and Online Message Interpretation.
Soc.Sci.
Comput.
Rev., 26(3), 379-388.Gibbs, R. 1986.
On the psycholinguistics of sarcasm.Journal of Experimental Psychology: General,105:3?15.Gibbs, R. W. and Colston H. L. eds.
2007.
Irony inLanguage and Thought.
Routledge (Taylor andFrancis), New York.585Kreuz, R. J. and Glucksberg, S. 1989.
How to be sarcas-tic: The echoic reminder theory of verbal irony.Journal of Experimental Psychology: General,118:374-386.Kreuz, R. J. and Caucci, G. M. 2007.
Lexical influenceson the perception of sarcasm.
In Proceedings of theWorkshop on Computational Approaches to Figura-tive Language (pp.
1-4).
Rochester, New York: As-sociation for Computational.LIWC Inc. 2007.
The LIWC application.
Retrieved May10, 2010, fromhttp://www.liwc.net/liwcdescription.php.Nigam, K. and Hurst, M. 2006.
Towards a Robust Me-tric of Polarity.
In Computing Attitude and Affect inText: Theory and Applications (pp.
265-279).
Re-trieved February 22, 2010, fromhttp://dx.doi.org/10.1007/1-4020-4102-0_20.Pak, A. and Paroubek, P. 2010.
Twitter as a Corpus forSentiment Analysis and Opinion Mining, in'Proceedings of the Seventh conference on Interna-tional Language Resources and Evaluation(LREC'10)' , European Language Resources Associ-ation (ELRA), Valletta, MaltaPang, B. and Lee, L. 2008.
Opinion Mining and Senti-ment Analysis.
Now Publishers Inc, July.Pennebaker, J.W., Francis, M.E., & Booth, R.J. (2001).Linguistic Inquiry and Word Count (LIWC):LIWC2001 (this includes the manual only).
Mah-wah, NJ: Erlbaum PublishersStrapparava, C. and Valitutti, A.
2004.
Wordnet-affect:an affective extension of wordnet.
In Proceedings ofthe 4th International Conference on Language Re-sources and Evaluation, Lisbon.Tepperman, J., Traum, D., and Narayanan, S. 2006.Yeah right: Sarcasm recognition for spoken dialoguesystems.
In InterSpeech ICSLP, Pittsburgh, PA.Utsumi, A.
2000.
Verbal irony as implicit display ofironic environment: Distinguishing ironic utterancesfrom nonirony.
Journal of Pragmatics, 32(12):1777?1806.586
