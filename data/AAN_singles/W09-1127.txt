Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 219?227,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsNew Features for FrameNet ?
WordNet MappingSara Tonelli and Daniele PighinFBK-Irst, Human Language TechnologiesVia di Sommarive, 18 I-38100 Povo (TN) Italy{satonelli,pighin}@fbk.euAbstractMany applications in the context of naturallanguage processing or information retrievalmay be largely improved if they were able tofully exploit the rich semantic information an-notated in high-quality, publicly available re-sources such as the FrameNet and the Word-Net databases.
Nevertheless, the practical useof similar resources is often biased by thelimited coverage of semantic phenomena thatthey provide.A natural solution to this problem would be toautomatically establish anchors between theseresources that would allow us 1) to jointly usethe encoded information, thus possibly over-coming limitations of the individual corpora,and 2) to extend each resource coverage by ex-ploiting the information encoded in the others.In this paper, we present a supervised learn-ing framework for the mapping of FrameNetlexical units onto WordNet synsets based ona reduced set of novel and semantically richfeatures.
The automatically learnt mapping,which we call MapNet, can be used 1) to ex-tend frame sets in the English FrameNet, 2)to populate frame sets in the Italian FrameNetvia MultiWordNet and 3) to add frame labelsto the MultiSemCor corpus.
Our evaluation onthese tasks shows that the proposed approachis viable and can result in accurate automaticannotations.1 IntroductionIn recent years, the integration of manually-builtlexical resources into NLP systems has receivedgrowing interest.
In particular, resources annotatedwith the surface realization of semantic roles, likeFrameNet (Baker et al, 1998) or PropBank (Palmeret al, 2005) have shown to convey an improve-ment in several NLP tasks, from question answer-ing (Shen and Lapata, 2007) to textual entailment(Burchardt et al, 2007) and shallow semantic pars-ing (Giuglea and Moschitti, 2006).
Nonetheless, themain limitation of such resources is their poor cov-erage, particularly as regards FrameNet.
Indeed, thelatest FrameNet release (v. 1.3) contains 10,195 lex-ical units (LUs), 3,380 of which are described onlyby a lexicographic definition without any examplesentence.
In order to cope with this lack of data, itwould be useful to map frame information onto otherlexical resources with a broader coverage.
We be-lieve that WordNet (Fellbaum, 1998), with 210,000entries in version 3.0, can represent a suitable re-source for this task.
In fact, both FrameNet andWordNet group together semantically similar words,and provide a hierarchical representation of the lex-ical knowledge (in WordNet the relations betweensynsets, in FrameNet between frames, see Ruppen-hofer et al (2006)).
On the other hand, WordNetprovides a more extensive coverage particularly foradjectives and nouns denoting artifacts and naturalkinds, that are mostly neglected in FrameNet.In this paper, we present an approach using Sup-port Vector Machines (SVM) to map FrameNet lex-ical units to WordNet synsets.
The proposed ap-proach addresses some of the limitations of previousworks on the same task (see for example De Caoet al (2008) and Johansson and Nugues (2007)).Most notably, as we do not train the SVM on a per-219frame basis, our model is able to cope also withthose frames that have little or no annotated sen-tences to support the frame description.
After learn-ing a very fast model on a small set of annotatedlexical unit-synset pairs, we can automatically es-tablish new mappings in never-seen-before pairs anduse them for our applications.
We will evaluate theeffect of the induced mappings on two tasks: the au-tomatic enrichment of lexical unit sets in the Englishand Italian FrameNet via MultiWordNet (Pianta etal., 2002), and the annotation of the MultiSemCorcorpus (Bentivogli and Pianta, 2005) with frame la-bels.The discussion is structured as follows: inSection 2 we review the main characteristics ofFrameNet and WordNet; in Section 3 we discussprevious attempts to establish a mapping betweenthem; in Section 4 we describe our supervised ap-proach to map lexical units onto synsets; Section 5details the dataset that we employed for our experi-ments; Section 6 describes the novel features that weused to characterize the mapping; Section 7 detailsthe results of our experiments; in Section 8 we ap-ply the mapping to three resource annotation tasks;finally, in Section 9 we draw our conclusions.2 FrameNet and WordNetThe FrameNet database (Baker et al (1998), Fill-more et al (2003)) is an English lexical resourcebased on the description of some prototypical sit-uations, the frames, and the frame-evoking wordsor expressions associated to them, the lexical units(LU).
Every frame corresponds to a scenario involv-ing a set of participants, the frame elements (FEs),that are typically the semantic arguments shared byall LUs in a frame.We report in Table 1 the information recordedin FrameNet for the CAUSE TO WAKE frame.
Inthe first row there is the frame definition with therelevant frame elements, namely AGENT, CAUSE,SLEEPER and SLEEP STATE.
Then there is the listof all lexical units evoking the frame and the corre-sponding part of speech.
Note that, differently fromWordNet synsets, a frame can contain LUs with dif-ferent PoS as well as antonymous words.
In thelast row, an example for each frame element is re-ported.
The lexical unit is underlined, while the con-Frame: CAUSE TO WAKEDef.
An AGENT or CAUSE causes a SLEEPER totransition from the SLEEP STATE to wakefulconsciousness.LUs awaken.v, get up.v, rouse.v, wake.v, wake up.vsinge.v, sizzle.v, stew.vFEs AGENT We tried to rouse Peter.CAUSE The rain woke the children.SLEEPER Neighbors were awakened by screams.SL STATE He woke Constance from her doze.Table 1: Frame CAUSE TO WAKEstituent bearing the FE label is written in italics.
TheFrameNet resource is corpus-based, i.e.
every lexi-cal unit should be instantiated by at least one ex-ample sentence.
Besides, every lexical unit comeswith a manual lexicographic definition.
The latestdatabase release contains 795 frame definitions and10,195 lexical units, instantiated through approxi-mately 140.000 example sentences.
Despite this, thedatabase shows coverage problems when exploitedfor NLP tasks, and is still being extended by theBerkeley group at ICSI.WordNet (Fellbaum, 1998) is a lexical resourcefor English based on psycholinguistics principlesand developed at Princeton University.
It has beenconceived as a computational resource aimed at im-proving some drawbacks of traditional dictionariessuch as the circularity of definitions and the ambigu-ity of sense references.
At present, it covers the ma-jority of nouns, verbs, adjectives and adverbs in theEnglish language, organized in synonym sets calledsynsets, which correspond to concepts.
WordNetalso includes a rich set of semantic relations acrossconcepts, such as hyponymy, entailment, antonymy,similar-to, etc.
Each synset is encoded as a set ofsynomyms having the same part of speech and de-scribed by a definition or gloss.
In some cases, oneor more example sentences may also be reported.The Princeton English WordNet has also been aug-mented with domain labels (Magnini and Cavaglia`,2000) that group synsets into homogeneous clustersin order to reduce polysemy in the database.We believe that mapping FrameNet LUs to Word-Net synsets would have at least three different ad-vantages: 1) for the English FrameNet, it would au-tomatically increase the number of LUs for frame by220importing all synonyms from the mapped synset(s),and would allow to exploit the semantic and lex-ical relations in WordNet to enrich the informa-tion encoded in FrameNet.
This would help cop-ing with coverage problems and disambiguating theLU senses.
2) For WordNet, it would be possibleto add a semantic layer between the synset leveland the domain level represented by frame rela-tions, and to enrich the synsets with a computa-tional description of the situation they refer to to-gether with the semantic roles involved.
3) Sinceframes are mostly defined at conceptual level, theFrameNet model is particularly suitable for cross-lingual induction (Boas, 2005).
In this framework,the FrameNet-WordNet mapping could help mod-elling frame-based resources for new languages us-ing minimal supervision.
In fact, the availability ofmultilingual resources like MultiWordNet (Pianta etal., 2002) and EuroWordNet (Vossen, 1998) allowsto easily populate frame sets for new languages withreduced human effort and near-manual quality byimporting all lemmas from the mapped synsets.3 Related workSeveral experiments have been carried out to de-velop a FrameNet-WordNet mapping and test itsapplications.
Shi and Mihalcea (2005) describeda semi-automatic approach to exploit VerbNet as abridge between FrameNet and WordNet for verbs,using synonym and hyponym relations and simi-larity between Levin?s verb classes and FrameNetframes.
Their mapping was used to develop a rule-based semantic parser (Shi and Mihalcea, 2004) aswell as to detect target words and assign frames forverbs in an open text (Honnibal and Hawker, 2005).Burchardt et al (2005) presented a rule-basedsystem for the assignment of FrameNet frames byway of a ?detour via WordNet?.
They applieda WordNet-based WSD system to annotate lexicalunits in unseen texts with their contextually de-termined WordNet synsets and then exploited syn-onyms and hypernyms information to assign the bestframe to the lexical units.
The system was inte-grated into the SALSA RTE system for textual en-tailment (Burchardt et al, 2007) to cope with sparse-data problems in the automatic assignment of framelabels.Johansson and Nugues (2007) created a featurerepresentation for every WordNet lemma and usedit to train an SVM classifier for each frame that tellswhether a lemma belongs to the frame or not.
Thebest-performing feature representation was built us-ing the sequence of unique identifiers for each synsetin its hypernym tree and weigthing the synsets ac-cording to their relative frequency in the SemCorcorpus.
They used the mapping in the Semeval-2007task on frame-semantic structure extraction (Bakeret al, 2007) in order to find target words in opentext and assign frames.Crespo and Buitelaar (2008) carried out an auto-matic mapping of medical-oriented frames to Word-Net synsets applying a Statistical Hypothesis Test-ing to select synsets attached to a lexical unit thatwere statistically significant using a given refer-ence corpus.
The mapping obtained was usedto expand Spanish FrameNet using EuroWordNet(Vossen, 1998) and evaluation was carried out on theSpanish lexical units obtained after mapping.Given a set of lexical units, De Cao et al (2008)propose a method to detect the set of suitable Word-Net senses able to evoke a frame by applying a simi-larity function that exploits different WordNet infor-mation, namely conceptual density for nouns, syn-onymy and co-hyponymy for verbs and synonymyfor adjectives.
The mapping approach was appliedalso to LU induction for the English FrameNet andfor Italian frames via MultiWordNet.4 Problem formulationOur objective is to be able to assign to every lex-ical unit l, belonging to a frame Fi defined in theFrameNet database, one or more WordNet sensesthat best express the meaning of l. More specifically,for every l ?
Fi, we consider the set of all WordNetsenses where l appears, CandSet, and then find thebest WordNet sense(s) bests ?
CandSet that expressthe meaning of l.For example, the lexical unit rouse.v belonging tothe CAUSE TO WAKE frame, is defined in FrameNetas ?bring out of sleep; awaken?.
Its CandSet com-prises 4 senses1: 1# bestir, rouse (become active);2# rout out, drive out, force out, rouse (force ordrive out); #3 agitate, rouse, turn on, charge, com-1The gloss is reported between parenthesis221move, excite, charge up (cause to be agitated, ex-cited or roused); #4 awaken, wake, waken, rouse,wake up, arouse (cause to become awake or con-scious).
In this example, bests = {#4} for rouse.vin CAUSE TO WAKE.We aim at creating a mapping system thatcan achieve a good accuracy also with poorly-documented lexical units and frames.
In fact, we be-lieve that under real-usage conditions, the automaticinduction of LUs is typically required for frameswith a smaller LU set, especially for those with onlyone element.
In the FrameNet database (v. 1.3), 33frames out of 720 are described only by one lex-ical unit, and 63 are described by two.
Further-more, more than 3,000 lexical units are character-ized only by the lexicographic definition and arenot provided with example sentences.
For this rea-son, we suggest an approach that makes also useof usually unexploited information in the FrameNetdatabase, namely the definition associated to everylexical unit, and disregards example sentences.This is the main point of difference betweenour and some previous works, e.g.
Johansson andNugues (2007) and De Cao et al (2008), where un-supervised approaches are proposed which stronglyrely either on the number of lexical units in a frameor on the example sentences available for l in theFrameNet corpus.
We claim that the relative shorttime necessary to annotate a small dataset of frame-synset pairs will result in a more reliable mappingsystem and, as a consequence, in consistent timesavings when we actually try to use the mappingsfor some tasks.
The ability to cope with differentcases while retaining a good accuracy will allow tobootstrap the mapping process in many cases whereother approaches would have failed due to lack oftraining data.To this end, we can train a binary classifierthat, given l and CandSet, for each pair ?l, s?,s ?
CandSet, delivers a positive answer if s ?bests, and a negative one otherwise.
To follow onthe previous example, for rouse.v we would have4 classifier examples, i.e.
the pairs ?rouse.v,#1?,?rouse.v,#2?, ?rouse.v,#3?
and ?rouse.v,#4?.
Ofthese, only the last would be considered a positiveinstance.
As a learning framework, we decided touse SVMs due to their classification accuracy androbustness to noisy data (Vapnik, 1998).5 Dataset descriptionIn order to train and test the classifier, we createda gold standard by manually annotating 2,158 LU-synset pairs as positive or negative examples.
Wedon?t have data about inter-annotator agreement be-cause the dataset was developed only by one annota-tor, but De Cao et al (2008) report 0.90 as Cohen?sKappa computed over 192 LU-synset pairs for thesame mapping task.
This confirms that senses andlexical units are highly correlated and that the map-ping is semantically motivated.The annotation process can be carried out in rea-sonable time.
It took approximately two work daysto an expert annotator to manually annotate the2,158 pairs that make up our gold standard.
The lexi-cal units were randomly selected from the FrameNetdatabase regardless of their part of speech or amountof annotated data in the FrameNet database.
Foreach lexical unit, we extracted from WordNet thesynsets where the LU appears, and for each of themwe assigned a positive label in case the LU-synsetpairs share the same meaning, and a negative labelotherwise.
Statistics about the dataset are reportedin Table 2.N.
of LU-synset pairs 2,158N.
of lexical units 617Verbal lexical units 39%Nominal lexical units 51%Adjectival lexical units 9%Adverbial lexical units <1%Targeted frames 386Pairs annotated as positive 32%Pairs annotated as negative 68%Average polysemy 3.49LUs with one candidate synset 204LUs with 10 or more cand.
synsets 32Table 2: Statistics on the datasetThe 386 frames that are present in the dataset rep-resent about one half of all lexicalized frames inthe FrameNet database.
This proves that, despitethe limited size of the dataset, it is well representa-tive of FrameNet characteristics.
This is confirmedby the distribution of the part of speech.
In fact,in the FrameNet database about 41% of the LUs222are nouns, 40% are verbs, 17% are adjectives and<1% are adverbs (the rest are prepositions, whichare not included in our experiment because they arenot present in WordNet).
In our dataset, the per-centage of nouns is higher, but the PoS ranking byfrequency is the same, with nouns being the mostfrequent PoS and adverbs the less represented.
Theaverage polysemy corresponds to the average num-ber of candidate synsets for every LU in the dataset.Note that the high number of lexical units with onlyone candidate does not imply a more straightforwardmapping, because in some cases the only candidaterepresents a negative example.
In fact, a LU couldbe encoded in a frame that does not correspond tothe sense expressed by the synset.6 Feature descriptionFor every LU-synset pair in the gold standard, weextracted a set of features that characterize differentaspects of the mapping.
In the remainder, we detailthe meaning as well as the feature extraction proce-dure of each of them.Stem overlap Both WordNet glosses and LU def-initions in FrameNet are manually written by lex-icographers.
We noticed that when they share thesame sense, they show high similarity, and some-times are even identical.
For example, the defini-tion of thicken in the Change of consistency frameis ?become thick or thicker?, which is identical tothe WordNet gloss of synset n. v#00300319.
Thethicken lemma occurs in three WordNet synsets, andin each of them it is the only lemma available, so noother information could be exploited for the sensedisambiguation.We believe that this information could help in thechoice of the best candidate synset, so we stemmedall the words in the synset gloss and in the lexicalunit definition and measured their overlap.
As fea-tures, we use the ratio between the number of over-lapping words and the number of words in the defi-nition, both for the gloss and the LU description.Prevalent Domain and Synset Since a frame rep-resents a prototypical situation evoked by the setof its lexical units, our intuition is that it shouldbe possible to assign it to a WordNet domain, thatgroups homogeneous clusters of semantically simi-lar synsets (see Section 2).Given the LU-synset pair ?l, s?, l ?
Fi, s ?CandSet, we extract all the lexical units in Fi andthen build a set AllCandSet of pairs ?sj , cj?, wheresj is a synset in which at least one li ?
Fi appears,and cj is the count of lexical units that are found insj .We exploit the information conveyed by AllCan-dSet in two ways: i) if there is a prevalent Word-Net domain that characterizes the majority of thesynsets in AllCandSet, and s ?
CandSet belongsto that same domain, we add a boolean feature tothe feature vector representing ?l, s?
; ii) if s is thesynset with the highest count in AllCandSet, i.e.
ifs = sj and cj > ci?
?sj , cj?
?
AllCandSet, i 6= j,then we add another boolean feature to encode thisinformation.Cross-lingual parallelism Our idea is that, if anEnglish lexical unit and its Italian translation belongto the same frame, they are likely to appear also inthe same MultiWordNet synset, and the latter wouldbe a good candidate for mapping.
In fact, in Multi-WordNet the Italian WordNet is strictly aligned withthe Princeton WordNet 1.6, with synsets having thesame id for both languages, and also semantic re-lations are preserved in the multilingual hierarchy.Since no Italian FrameNet is available yet, we ex-tended the parallel English-Italian corpus annotatedon both sides with frame information described inTonelli and Pianta (2008) by adding and annotating400 new parallel sentences.
The final corpus con-tains about 1,000 pairs of parallel sentences wherethe English and the Italian lexical unit belong to thesame frame.Given a pair ?l, s?, we check if l appears also inthe corpus with the frame label Fi and extract itsItalian translation lit.
If lit appears also in the Italianversion of synset s in MultiWordNet, we consider sas a good candidate for the mapping of l and encodethis information as a binary feature.Simple synset-frame overlap Intuitively, themore lemmas a frame and a synset have in common,the more semantically similar they are.
In order totake into account this similarity in our feature vec-tor, given the pair ?l, s?, l ?
Fi, we extract all lexicalunits in Fi and all lemmas in s and we compute thenumber of overlapping elements.
Then we divide223the value by the number of synsets where the sameoverlapping element(s) occur.As an example, the words tank and tank car inthe Vehicle frame, occur together only in the fourthsynset related to tank, which therefore will have ahigher value for this feature.Extended synset-frame overlap This feature is ageneralization of overlapping value described above.In fact, we noticed that the hypernym informationin WordNet can help disambiguating the synsets.Therefore, we take into account not only the over-laps according to the previous criterion, but also thenumber of overlapping words between the lexicalunits in a frame and the hypernyms of a synset.
Forexample, the party.n lexical unit in the AGGREGATEframe has 5 senses in WordNet.
According to theprevious criterion, there is no overlap between theLUs in the frame and the lemmas in any of the fivesynsets.
Instead, if we look at the direct hypernymrelation of party, we find that sense #3 is also de-scribed as set, circle, band, that are also lexical unitsof AGGREGATE.In those cases where the hypernym relation is notdefined, e.g.
adjectives, we used the similar-to rela-tion.7 Experimental setup and evaluationTo evaluate our methodology we carried out a 10-fold cross validation using the available data, split-ting them in 10 non-overlapping sets.
For each itera-tion, 70% of the data was used for training, 30% fortesting.
All the splits were generated so as to main-tain a balance between positive and negative exam-ples in the training and test sets.We used the SVM optimizer SVM-Light2 (Joachims, 1999), and applied polynomialkernels (poly) of different degrees (i.e.
1 through4) in order to select the configuration with the bestgeneralization capabilities.
The accuracy is mea-sured in terms of Precision, Recall and F1 measure,i.e.
the harmonic average between Precision andRecall.
For the sake of annotation, it is importantthat an automatic system be very precise, thus notproducing wrong annotations.
On the other hand,the higher the recall, the larger the amount of datathat the system will be able to annotate.2Available at http://svmlight.joachims.org/The macro-average of the classifier accuracy forthe different configurations is shown in Table 3.
Wereport results for linear kernel (i.e.
poly 1), maxi-mizing recall and f-measure, and for polynomial ker-nel of degree 2 (i.e.
poly 2), scoring the highest pre-cision.
In general , we notice that all our modelshave a higher precision than recall, but overall arequite balanced.
Different polynomial kernels (i.e.conjunction of features) do not produce very rele-vant differences in the results, suggesting that thefeatures that we employed encode significant infor-mation and have a relevance if considered indepen-dently.As a comparison, we also carried out the sameevaluation by setting a manual threshold and con-sidering a LU-synset pair as a positive example ifthe sum of the feature values was above the thresh-old.
We chose two different threshold values, thefirst (Row 1 in Table 3) selected so as to have com-parable precision with the most precise SVM model(i.e.
poly2), the second (Row 2) selected to haverecall comparable with poly1, i.e.
the SVM modelwith highest recall.
In the former case, the model hasa recall that is less than half than poly2, i.e.
0.214vs.
0.569, meaning that such model would establisha half of the mappings while making the same per-centage of mistakes.
In the latter, the precision ofthe SVM classifier is 0.114 points higher, i.e.
0.794vs.
0.680, meaning the SVM can retrieve as manymappings but making 15% less errors.In order to investigate the impact of different fea-tures on the classifier performance, we also consid-ered three different groups of features separately:the ones based on stem overlap, those computedfor prevalent domain and synset, and the featuresfor simple and extended frame ?
synset overlap.We did not take into account cross-lingual paral-lelism because it is one single feature whose cover-age strongly relies on the parallel corpus available.As a consequence, it is not possible to test the fea-ture in isolation due to data sparseness.Results are shown in Table 3, in the second groupof rows.
Also in this case, we carried out a 10-fold cross validation using a polynomial kernel ofdegree 2.
The stem overlap features, which to ourbest knowledge are an original contribution of ourapproach, score the highest recall among the threegroups.
This confirms our intuition that LU defini-224tions and WordNet glosses can help extending thenumber of mapped LUs, including those that arepoorly annotated.
For instance, if we consider theKNOT CREATION frame, having only tie.v as LU,the features about prevalent domain & synset andabout synset-frame overlap would hardly be infor-mative, while stem overlap generally achieves a con-sistent performance regardless of the LU set.
Infact, tie.v is correctly mapped to synset v#00095054based on their similar definition (respectively ?toform a knot?
and ?form a knot or bow in?).
Bestprecision was scored by the feature group consider-ing prevalent domain & synset, which are also newfeatures introduced by our approach.
The positiveeffect of combining all features is clearly shown bycomparing the results obtained with individual fea-ture groups against the figures in the row labeledpoly2.Prec.
Recall F1Man.
thresh.
(P) 0.789 0.214 0.337Man.
thresh.
(F1) 0.680 0.662 0.671Stem Overlap 0.679 0.487 0.567Prev.Dom.& Syn.
0.756 0.434 0.551Syn.- Frame Overlap 0.717 0.388 0.504poly1 0.761 0.613 0.679poly2 0.794 0.569 0.663Table 3: Mapping evaluation8 MapNet and its applicationsSince we aim at assigning at least one synset to ev-ery lexical unit in FrameNet, we considered all theframes and for every LU in the database we createda list of LU-synset pairs.
We re-trained the clas-sifier using the whole annotated gold standard andclassified all the candidate pairs.
The mapping pro-duced between the two resources, that we call Map-Net, comprises 5,162 pairs.
Statistics on MapNet arereported in table 4.About one thousand lexical units in FrameNethave no candidate synsets because the lemma is notpresent in WordNet.
The remaining LUs have 3.69candidate synsets each on average, similarly to theaverage polysemy reported for the gold standard (seeTable 2).
This confirms our hypothesis that the dataused for training are well representative of the char-N. of LUs in FrameNet 10,100N.
of LUs with at least one syn.cand.
9,120N.
of LU-synset candidate pairs 33,698N.
of mapped pairs 5,162Table 4: Statistics on the mappingacteristics of the whole resource.
We expect about80% of these mappings to be correct, i.e.
in linewith the precision of the classifier.8.1 Automatic FrameNet extensionMapNet can be easily exploited to automatically ex-tend FrameNet coverage, in particular to extend theset of lexical units for each frame.
In fact, we canassume that all lemmas in the mapped synsets havethe same meaning of the LUs in the correspondingframes.
We use MapNet to extract from WordNetthe lemmas in the mapped synsets and add them tothe frames.For English FrameNet, we can acquire 4,265 newlexical units for 521 frames.
In this way, we wouldextend FrameNet size by almost 42%.
In the ran-dom evaluation of 100 newly acquired LUs belong-ing to 100 different frames, we assessed a precisionof 78%.
For the Italian side, we extract 6,429 lexi-cal units for 561 frames.
Since no Italian FrameNethas been developed yet, this would represent a firstattempt to create this resource by automatically pop-ulating the frames.
We evaluate the content of 15complete frames containing 191 Italian LUs.
Theassigned LUs are correct in 88% of the consideredcases, which represent a promising result w.r.t.
theunsupervised creation of Italian FrameNet.The difference in the evaluation for the two lan-guages most likely lies in the smaller number ofsynsets on the Italian side of MultiWordNet if com-pared to the English, which results in less ambigu-ity.
Furthermore, we should consider that the taskfor Italian is easier than for English, since in the for-mer case we are building a resource from scratch,while in the latter we are extending an already exist-ing resource with lexical units which are most likelyperipheral with respect to those already present inthe database.2258.2 Frame annotation of MultiSemCorMultiSemCor (Bentivogli and Pianta, 2005) is anEnglish/Italian parallel corpus, aligned at wordlevel and annotated with PoS, lemma and Word-Net synsets.
The parallel corpus was created start-ing from the SemCor corpus, which is a subset ofthe English Brown corpus containing about 700,000running words.
The corpus was first manually trans-lated into Italian.
Then, the procedure of transferringword sense annotations from English to Italian wascarried out automatically.We apply MapNet to enrich the corpus with frameinformation.
We believe that this procedure wouldbe interesting from different point of views.
Notonly we would enrich the resource with a new anno-tation layer, but we would also automatically acquirea large set of English and Italian sentences having alexical unit with a frame label.
For the English side,it is a good solution to automatically extract a datasetwith frame information and train, for example, a ma-chine learning system for frame identification.
Forthe Italian side, it represents a good starting point forthe creation of a large annotated corpus with frameinformation, the base for a future Italian FrameNet.MultiSemCor contains 12,843 parallel sentences.If we apply MapNet to the corpus, we produce27,793 annotated instances in English and 23,872 inItalian, i.e.
about two lexical units per sentence.
Thedifferent amount of annotated sentences depends onthe fact that in MultiSemCor some synset annota-tions have not been transferred from English to Ital-ian.
From both sides of the resulting corpus, werandomly selected 200 sentences labeled with 200different frames, and evaluated the annotation qual-ity.
As for the English corpus, 75% of the sen-tences was annotated with the correct frame label,while on the Italian side they were 70%.
This re-sult is in line with the expectations, since Map-Net was developed with 0.79 precision.
Besides,synset annotation on the English side of MultiSem-Cor was carried out by hand, while annotation inItalian was automatically acquired by transferringthe information from the English corpus (precision0.86).
This explains why the resulting annotationfor English is slightly better than for Italian.
In somecases, the wrongly annotated frame was strictly con-nected to the right one, i.e.
APPLY HEAT insteadof COOKING CREATION and ATTACHING insteadof INCHOATIVE ATTACHING.9 ConclusionsWe proposed a new method to map FrameNet LUsto WordNet synsets using SVM with minimal super-vision effort.To our best knowledge, this is the only approachto the task that exploits features based on stem over-lap between LU definition and synset gloss andthat makes use of information about WordNet do-mains.
Differently from other models, the SVMis not trained on a per-frame basis and we do notrely on the number of the annotated sentences for aLU in the FrameNet corpus, thus our mapping al-gorithm performs well also with poorly-annotatedLUs.
After creating MapNet, the mapping be-tween FrameNet and WordNet, we applied it to threetasks: the automatic induction of new LUs for En-glish FrameNet, the population of frames for ItalianFrameNet and the annotation of the MultiSemCorcorpus with frame information.
A preliminary eval-uation shows that the mapping can significantly re-duce the manual effort for the development and theextension of FrameNet-like resources, both in thephase of corpus annotation and of frame population.In the future, we plan to improve the algorithmby introducing syntactic features for assessing simi-larity between LU definitions and WordNet glosses.We also want to merge all information extracted andcollected for Italian FrameNet and deliver a seedversion of the resource to be validated.
Finally, weplan to extend the mapping to all languages includedin MultiWordNet, i.e.
Spanish, Portuguese, Hebrewand Romanian.AcknowledgementsWe thank Roberto Basili and Diego De Cao for shar-ing with us their gold standard of frame ?
synsetmappings.226ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet Project.
In Proceed-ings of the 36th ACL Meeting and 17th ICCL Confer-ence.
Morgan Kaufmann.Collin F. Baker, Michael Ellsworth, and Katrin Erk.2007.
SemEval-2007 Task 10: Frame Semantic Struc-ture Extraction.
In Proceedings of the Fourth Interna-tional Workshop on Semantic Evaluations (SemEval-2007), pages 99?104, Prague, CZ, June.Luisa Bentivogli and Emanuele Pianta.
2005.
ExploitingParallel Texts in the Creation of Multilingual Seman-tically Annotated Resources: The MultiSemCor Cor-pus.
Natural Language Engineering, Special Issue onParallel Texts, 11(03):247?261, September.Hans C. Boas.
2005.
Semantic frames as interlingualrepresentations for multilingual lexical databases.
In-ternational Journal of Lexicography, 18(4):445?478.Aljoscha Burchardt, Katrin Erk, and Annette Frank.2005.
A WordNet detour to FrameNet.
In B. Fis-seni, H. Schmitz, B. Schro?der, and P. Wagner, editors,Sprachtechnologie, mobile Kommunikation und lingis-tische Resourcen, Frankfurt am Main, Germany.
PeterLang.Aljoscha Burchardt, Nils Reiter, Stefan Thater, and An-nette Frank.
2007.
A semantic approach to textualentailment: System evaluation and task analysis.
InProceedings of Pascal RTE-3 Challenge, Prague, CZ.Diego De Cao, Danilo Croce, Marco Pennacchiotti, andRoberto Basili.
2008.
Combining Word Sense andUsage for modeling Frame Semantics.
In Proceedingsof STEP 2008, Venice, Italy.Mario Crespo and Paul Buitelaar.
2008.
Domain-specificEnglish-to-Spanish Translation of FrameNet.
In Proc.of LREC 2008, Marrakech.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.C.J.
Fillmore, C.R.
Johnson, and M. R. L. Petruck.
2003.Background to FrameNet.
International Journal ofLexicography, 16:235?250, September.Ana-Maria Giuglea and Alessandro Moschitti.
2006.
Se-mantic role labeling via FrameNet, VerbNet and Prop-Bank.
In Proceedings of the 21st International Con-ference on Computational Linguistics and the 44th an-nual ACL meeting, pages 929?936, Morristown, NJ,US.
Association for Computational Linguistics.Matthew Honnibal and Tobias Hawker.
2005.
Identify-ing FrameNet frames for verbs from a real-text corpus.In Proceedings of Australasian Language TechnologyWorkshop 2005.Thorsten Joachims.
1999.
Making large-scale sup-port vector machine learning practical.
In BernhardScho?lkopf, Christopher J. C. Burges, and Alexander JSmola, editors, Advances in kernel methods: supportvector learning, pages 169?184.
MIT Press, Cam-bridge, MA, USA.R.
Johansson and P. Nugues.
2007.
Using WordNet toextend FrameNet coverage.
In Proc.
of the Workshopon Building Frame-semantic Resources for Scandina-vian and Baltic Languages, at NODALIDA, Tartu.Bernardo Magnini and Gabriela Cavaglia`.
2000.
Inte-grating Subject Field Codes into WordNet.
In Pro-ceedings of LREC 2000, pages 1413?1418, Athens,Greece.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An Annotated Corpusof Semantic Roles.
Computational Linguistics, 31.Emanuele Pianta, Luisa Bentivogli, and Christian Gi-rardi.
2002.
MultiWordNet: developing an alignedmultilingual database.
In First International Confer-ence on Global WordNet, pages 292?302, Mysore, In-dia.Josef Ruppenhofer, Michael Ellsworth, Miriam R.L.Petruck, Christopher R. Johnson, and JanScheffczyk.
2006.
FrameNet II: Ex-tended Theory and Practice.
Available athttp://framenet.icsi.berkeley.edu/book/book.html.Dan Shen and Mirella Lapata.
2007.
Using SemanticRoles to Improve Question Answering.
In Proceed-ings of EMNLP and CONLL, pages 12?21, Prague,CZ.Lei Shi and Rada Mihalcea.
2004.
Open Text SemanticParsing Using FrameNet and WordNet.
In Proceed-ings of HLT-NAACL 2004.Lei Shi and Rada Mihalcea.
2005.
Putting Pieces To-gether: Combining FrameNet, VerbNet and WordNetfor Robust Semantic Parsing.
In Proceedings of CI-CLing 2005, pages 100?111.
Springer.Sara Tonelli and Emanuele Pianta.
2008.
Frame Infor-mation Transfer from English to Italian.
In EuropeanLanguage Resources Association (ELRA), editor, Pro-ceedings of LREC 2008, Marrakech, Morocco.Vladimir N. Vapnik.
1998.
Statistical Learning Theory.Wiley-Interscience.Piek Vossen, editor.
1998.
EuroWordNet: A MultilingualDatabase with Lexical Semantic Networks.
Springer,October.227
