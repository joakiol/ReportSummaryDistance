Workshop on Monolingual Text-To-Text Generation, pages 10?19,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 10?19,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsWeb-based validation for contextual targeted paraphrasingHouda BouamorLIMSI-CNRSUniv.
Paris Sudhbouamor@limsi.frAure?lien MaxLIMSI-CNRSUniv.
Paris Sudamax@limsi.frGabriel IllouzLIMSI-CNRSUniv.
Paris Sudgabrieli@limsi.frAnne VilnatLIMSI-CNRSUniv.
Paris Sudanne@limsi.frAbstractIn this work, we present a scenario where con-textual targeted paraphrasing of sub-sententialphrases is performed automatically to supportthe task of text revision.
Candidate para-phrases are obtained from a preexisting reper-toire and validated in the context of the orig-inal sentence using information derived fromthe Web.
We report on experiments on French,where the original sentences to be rewrit-ten are taken from a rewriting memory au-tomatically extracted from the edit history ofWikipedia.1 IntroductionThere are many instances where it is reasonable toexpect machines to produce text automatically.
Tra-ditionally, this was tackled as a concept-to-text real-ization problem.
However, such needs apply some-times to cases where a new text should be derivedfrom some existing texts, an instance of text-to-textgeneration.
The general idea is not anymore to pro-duce a text from data, but to transform a text so as toensure that it has desirable properties appropriate forsome intended application (Zhao et al, 2009).
Forexample, one may want a text to be shorter (Cohnand Lapata, 2008), tailored to some reader pro-file (Zhu et al, 2010), compliant with some spe-cific norms (Max, 2004), or more adapted for sub-sequent machine processing tasks (Chandrasekar etal., 1996).
The generation process must producea text having a meaning which is compatible withthe definition of the task at hand (e.g.
strict para-phrasing for document normalization, relaxed para-phrasing for text simplification), while ensuring thatit remains grammatically correct.
Its complexity,compared with concept-to-text generation, mostlystems from the fact that the semantic relationshipbetween the original text and the new one is moredifficult to control, as the mapping from one text toanother is very dependent on the rewriting context.The wide variety of techniques for acquiring phrasalparaphrases, which can subsequently be used by textparaphrasing techniques (Madnani and Dorr, 2010),the inherent polysemy of such linguistic units andthe pragmatic constraints on their uses make it im-possible to ensure that potential paraphrase pairswill be substitutable in any context, an observationwhich was already made at a lexical level (Zhao etal., 2007).
Hence, automatic contextual validation ofcandidate rewritings is a fundamental issue for textparaphrasing with phrasal units.In this article, we tackle the problem of what wecall targeted paraphrasing, defined as the rewritingof a subpart of a sentence, as in e.g.
(Resnik et al,2010) where it is applied to making parts of sen-tences easier to translate automatically.
While thisproblem is simpler than full sentence rewriting, itsstudy is justified as it should be handled correctlyfor the more complex task to be successful.
More-over, being simpler, it offers evaluation scenarioswhich make the performance on the task easier toassess.
Our particular experiments here aim to as-sist a Wikipedia contributor in revising a text to im-prove its quality.
For this, we use a collection ofphrases that have been rewritten in Wikipedia, andtest the substitutability of paraphrases coming froma repertoire of sub-sentential paraphrases acquired10from different sources.
We thus consider that preex-isting repertoires of sub-sentential paraphrase pairsare available, and that each potential candidate has tobe tested in the specific context of the desired rewrit-ing.
Due to the large variety of potential phrasesand their associated known paraphrases, we do notrely on precomputed models of substitutability, butrather build them on-the-fly using information de-rived from web queries.1This article is organized as follows.
In section 2,we first describe the task of text revision, where asubpart of a sentence is rewritten, as an instanceof targeted paraphrasing.
Section 3 presents previ-ous works on the acquisition of sub-sentential para-phrases and describes the knowledge sources that wehave used in this work.
We then describe in section 4how we estimate models of phrase substitution incontext by exploiting information coming from theweb.
We present our experiments and their results insection 5, and finally discuss our current results andfuture work in section 6.2 Targeted paraphrasing for text revisionOne of the important processes of text revision isthe rewording of parts of sentences.
Some reword-ings are not intended to alter meaning significantly,but rather to make text more coherent and easier tocomprehend.
Those instances which express closemeanings are sub-sentential paraphrases: in theirsimpler form, they can involve synonym substitu-tion, but they can involve more complex deeperlexical-syntactic transformations.Such rephrasings are commonly found in record-ings of text revisions, which now exist in largequantities in the collaborative editing model ofWikipedia.
In fact, revision histories of the encyclo-pedia contain a significant amount of sub-sententialparaphrases, as shown by the study of (Dutrey et al,2011).
This study also reports that there is an impor-tant variety of rephrasing phenomena, as illustratedby the difficulty of reaching a good identificationcoverage using a rule-based term variant identifica-tion engine.1Note that using the web may not always be appropriate, orthat at least it should be used in a different way than what wepropose in this article, in particular in cases where the desiredproperties of the rewritten text are better described in controlledcorpora.The use of automatic targeted paraphrasing as anauthoring aid has been illustrated by the work ofMax and Zock (2008), in which writers are pre-sented with potential paraphrases of sub-sententialfragments that they wish to reword.
The automaticparaphrasing technique used is a contextual vari-ant of bilingual translation pivoting (Bannard andCallison-Burch, 2005).
It has also been proposedto externalize various text editing tasks, includingproofreading, by having crowdsourcing functions ontext directly from word processors (Bernstein et al,2010).Text improvements may also be more specifi-cally targeted for automatic applications.
In thework by Resnik et al (2010), rephrasings for spe-cific phrases are acquired through crowdsourcing.Difficult-to-translate phrases in the source text arefirst identified, and monolingual contributors areasked to provide rephrasings in context.
Collectedrephrasings can then be used as input for a Ma-chine Translation system, which can positively ex-ploit the increased variety in expression to pro-duce more confident translations for better estimatedsource units (Schroeder et al, 2009).2 For instance,the phrase in bold in the sentence The number ofpeople known to have died has now reached 358can be rewritten as 1) who died, 2) identified tohave died and 3) known to have passed away.
Allsuch rephrasings are grammatically correct, the firstone being significantly shorter, and they all conveya meaning which is reasonably close to the originalwording.The task of rewriting complete sentences has alsobeen addressed in various works (e.g.
(Barzilay andLee, 2003; Quirk et al, 2004; Zhao et al, 2010)).
Itposes, however, numerous other challenges, in par-ticular regarding how it could be correctly evalu-ated.
Human judgments of whole sentence trans-formations are complex and intra- and inter-judgecoherence is difficult to attain with hypotheses ofcomparable quality.
Using sentential paraphrasesto support a given task (e.g.
providing alternativereference translations for optimizing Statistical Ma-chine Translation systems (Madnani et al, 2008))2It is to be noted that, in the scenario presented in (Resnik etal., 2010), monolingual contributors cannot predict how usefultheir rewritings will be to the underlying Machine Translationengine used.11can be seen as a proxy for extrinsic evaluation ofthe quality of paraphrases, but it is not clear frompublished results that improvements on the task areclearly correlated with the quality of the producedparaphrases.
Lastly, automatic metrics have beenproposed for evaluating the grammaticality of sen-tences (e.g.
(Mutton et al, 2007)).
Automatic evalu-ation of sentential paraphrases has not produced anyconsensual results so far, as they do not integratetask-specific considerations and can be strongly bi-ased towards some paraphrasing techniques.In this work, we tackle the comparatively moremodest task of sub-sentential paraphrasing appliedto text revision.
In order to use an unbiasedtask, we use a corpus of naturally-occurring rewrit-ings from an authoring memory of Wikipedia ar-ticles.
We use the WICOPACO corpus (Max andWisniewski, 2010), a collection of local rephras-ings from the edit history of Wikipedia which con-tains instances of lexical, syntactical and semanticrephrasings (Dutrey et al, 2011), the latter type be-ing illustrated by the following example:Ce vers de Nuit rhe?nane d?Apollinaire [qui para?
?tpresque sans structure rythmique?
dont la ce?sureest comme masque?e].
.
.
3The appropriateness of this corpus for our workis twofold: first, the fact that it contains naturally-occurring rewritings provides us with an interest-ing source of text spans in context which have beenrewritten.
Moreover, for those instances where themeaning after rewriting was not significantly al-tered, it provides us with at least one candidaterewriting that should be considered as a correct para-phrase, which can be useful for training validationalgorithms.3 Automatic sub-sentential paraphraseacquisition and generationThe acquisition of paraphrases, and in particularof sub-sentential paraphrases and paraphrase pat-terns, has attracted a lot of works with the advent ofdata-intensive Natural Language Processing (Mad-nani and Dorr, 2010).
The techniques proposed havea strong relationship to the type of text corpus used3This verse from Apollinaire?s Nuit Rhe?nane [which seemsalmost without rhythmic structure ?
whose cesura is as ifhidden].
.
.for acquisition, mainly:?
pairs of sentential paraphrases (monolingualparallel corpora) allow for a good precisionbut evidently a low recall (e.g.
(Barzilay andMcKeown, 2001; Pang et al, 2003; Cohn etal., 2008; Bouamor et al, 2011))?
pairs of bilingual sentences (bilingual parallelcorpora) allow for a comparatively better re-call (e.g.
(Bannard and Callison-Burch, 2005;Kok and Brockett, 2010))?
pairs of related sentences (monolingual com-parable corpora) allow for even higher recallbut possibly lower precision (e.g.
(Barzilayand Lee, 2003; Li et al, 2005; Bhagat andRavichandran, 2008; Dele?ger and Zweigen-baum, 2009)Although the precision of such techniques can insome cases be formulated with regards to a prede-fined reference set (Cohn et al, 2008), it shouldmore generally be assessed in the specific contextof some use of the paraphrase pair.
This refers tothe problem of substituability in context (e.g.
(Con-nor and Roth, 2007; Zhao et al, 2007)), which is awell studied field at the lexical level and the object ofevaluation campains (McCarthy and Navigli, 2009).Contextual phrase substitution poses the additionalchallenge that phrases are rarer than words, so thatbuilding contextual and grammatical models to en-sure that the generated rephrasings are both seman-tically compatible and grammatical is more compli-cated (e.g.
(Callison-Burch, 2008)).The present work does not aim to present anyoriginal technique for paraphrase acquisition, butrather focusses on the task of sub-sentential para-phrase validation in context.
We thus resort to someexisting repertoire of phrasal paraphrase pairs.
Asexplained in section 2, we use the WICOPACO cor-pus as a source of sub-sentential paraphrases: thephrase after rewriting can thus be used as a potentialparaphrase in context.4 To obtain other candidatesof various quality, we used two knowledge sources.The first uses automatic pivot translation (Bannardand Callison-Burch, 2005), where a state-of-the-art4Note, however, that in our experiments we will ask our hu-man judges to assess anew its paraphrasing status in context.12general-purpose Statistical Machine Translation sys-tem is used in a two-way translation.
The seconduses manual acquisition of paraphrase candidates.Web-based acquisition of this type of knowledge hasalready been done before (Chklovski, 2005; Espan?aBonet et al, 2009), and could be done by crowd-sourcing, a technique growing in popularity in recentyears.
We have instead formulated manual acquisi-tion as a web-based game.
Players can take parts intwo parts of the game, illustrated on Figure 3.First, players propose sub-sentential paraphrasesin context for selected text spans in web documents(top of Figure 3), and then raters can take part in as-sessing paraphrases proposed by other players (bot-tom of Figure 3).
In order to avoid any bias, playerscannot evaluate games in which they played.
Eval-uation is sped up by using a compact word latticeview for eliciting human judgments, built using thesyntactic fusion algorithm of (Pang et al, 2003).Data acquisition was done in French to remain co-herent with our experiments on the French corpusof WICOPACO, and both players and raters werenative speakers.
An important point is that in ourexperiments the context of acquisition and of evalu-ation were different: players were asked to generateparaphrases in contexts that are different from thoseof the WICOPACO corpus used for evaluation.
Tothis end, web snippets were automatically retrievedfor the various phrases of our dataset without con-texts, so that sentences from the Web (but not fromWikipedia) were used for manual paraphrase acqui-sition.
This allows us to simulate the availability of apreexisting repertoire of (contextless) sub-sententialparaphrases, and to assess the performance of ourcontextual validation techniques on a possibly in-compatible context.4 Web-based contextual validationGiven a repertoire of potential phrasal paraphrasesand a context for a naturally-occurring rewriting, ourtask consists in deciding automatically which poten-tial paraphrases can be substituted with good confi-dence for the original phrase.
A concrete instantia-tion of it could correspond to the proposal of Maxand Zock (2008), where such candidate rephrasingscould be presented in order of decreasing suitabilityto a word processor user, possibly during the revi-sion of a Wikipedia article.The specific nature of the text units that we aredealing with calls for a careful treatment: in thegeneral scenario, it is unlikely that any supervisedcorpus would contain enough information for ap-propriate modeling of the substituability in contextdecision.
It is therefore tempting to consider usingthe Web as the largest available information source,in spite of several of its known limitations, includ-ing that data can be of varying quality.
It has how-ever been shown that a large range of NLP applica-tions can be improved by exploiting n-gram countsfrom the Web (using Web document counts as aproxy) (Lapata and Keller, 2005).Paraphrase identification has been addressed pre-viously, both using features computed from an of-fline corpus (Brockett and Dolan, 2005) and fea-tures computed from Web queries (Zhao et al,2007).
However, to our knowledge previous workexploiting information from the Web was limited tothe identification of lexical paraphrases.
Althoughthe probability of finding phrase occurrences sig-nificantly increases by considering the Web, somephrases are still very rare or not present in searchengine indexes.As in (Brockett and Dolan, 2005), we tackle ourparaphrase identification task as one of monolingualclassification.
More precisely, considering an orig-inal phrase p within the context of sentence s, weseek to determine whether a candidate paraphrase p?would be a grammatical paraphrase of p within thecontext of s. We make use of a Support Vector Ma-chine (SVM) classifier which exploits the featuresdescribed in the remainder of this section.Edit distance model score Surface similarity onphrase pairs can be a good indicator that they sharesemantic content.
In order to account for the costof transforming one string into the other, ratherthan simply counting common words, we use thescore produced by the Translation Edit Rate met-ric (Snover et al, 2010).
Furthermore, we performthis computation on strings of lemmas rather thansurface forms:55Note that because we computed the TER metric on Frenchstrings, stemming and semantic matching through WordNetwere not activated.13Figure 1: Interface of our web-based game for paraphrase acquisition and evaluation.
On the top, players reformulateall text spans highlighted by the game creator on any webpage (a Wikipedia article on the example).
On the bottom,raters evaluate paraphrases proposed by sets of players using a compact word-lattice view.
Note that in its standarddefinition, the game attributes higher scores to paraphrase candidates that are highly rated and rarer.hedit = TER(Lemorig, Lempara) (1)Note that this model is not derived from informa-tion from the Web, in contrast to all the models de-scribed next.Language model score The likelihood of a sen-tence can be a good indicator of its grammatical-ity (Mutton, 2006).
Language model probabilitiescan now be obtained from Web counts.
In our ex-periments, we used the Microsoft Web N-gram Ser-vice6 for research (Wang et al, 2010) to obtain loglikelihood scores for text units.7 However, this scoreis certainly not sufficient as it does not take the orig-inal wording into account.
We therefore used a ratioof the language model score of the paraphrased sen-tence with the language model score of the original6http://research.microsoft.com/en-us/collaboration/focus/cs/web-ngram.aspx7Note that in order to query on French text, we had to re-move all diacritics for the service to behave correctly, indepen-dently of encodings: careful examination of ranked hypothesesshowed that this trick allowed us to obtain results coherent withexpectations.sentence, after normalization by sentence length ofthe language model scores (Onishi et al, 2010):hLM ratio =LM(para)LM(orig)=lm(para)1/length(para)lm(orig)1/length(orig)(2)Contextless thematic model scores Cooccurringwords are used in distributional semantics to accountfor common meanings of words.
We build vectorrepresentations of cooccurrences for both the origi-nal phrase p and its paraphrase p?.
Our contextlessthematic model is built in the following fashion: wequery a search engine to retrieve the top N docu-ment snippets for phrase p. We then count frequen-cies for all content words in these snippets, and keepthe set W of words appearing more than a fractionof N .
We then build a vector T (thematic profile)of dimension |W | where values are computed by thefollowing formula:Tnocontorig [w] =count(p, w)count(p)(3)14where count(x) correspond to the number of docu-ments containing a given exact phrase or word ac-cording to the search engine used and count(x, y)correspond to the number of documents containingsimultaneously both.
We then compute the samethematic profile for the paraphrase p?, using only thesubset of words W :Tnocontpara [w] =count(p?, w)count(p)(4)Finally, we compute a similarity between the twoprofiles by taking the cosinus between their two vec-tors:hnocontthem =Tnocontorig ?
Tnocontpara||Tnocontorig || ?
||Tnocontpara ||(5)In all our experiments, we used the Yahoo!
SearchBOSS8 Web service for obtaining Web counts andretrieving snippets.
Assuming that the distributionof words in W is not biased by the result orderingof the search engine, our model measures some sim-ilarity between the most cooccurring content wordswith p and the same words with p?.Context-aware thematic model scores Ourcontext-aware thematic model takes into accountthe words of sentence s in which the substitutionof p with p?
is attempted.
We now consider the setof content words from s (s being the part of thesentence without phrase p) in lieu of the previousset of cooccurring words W , and compute thesame profile vectors and similarity between that ofthe original sentence and that of the paraphrasedsentence:hcontthem =T contorig ?
Tcontpara||T contorig || ?
||Tcontpara||(6)However, words from s might not be stronglycooccurring with p. In order to increase the likeli-hood of finding thematically related words, we alsobuild an extended context model, hextcontthem wherecontent words from s are supplemented with theirmost cooccurring words.
This is done using thesame procedure as that previously used for findingcontent words cooccurring with p.8http://developer.yahoo.com/search/boss/5 ExperimentsIn this section we report on experiments conductedto assess the performance of our proposed approachfor validating candidate sub-sentential paraphrasesusing information from the Web.5.1 Data usedWe randomly extracted 150 original sentences inFrench and their rewritings from the WICOPACOcorpus which were marked as paraphrases.
Of those,we kept 100 for our training corpus and the remain-ing 50 for testing.
The number of original phrases ofeach length is reported on Figure 2.phrase length 1 2 3 4 5 6 7 8original phrases 0 3 29 8 6 2 2 0paraphrases 39 64 74 36 21 10 5 1Figure 2: Distribution of number of phrases per phraselength in tokens for the test corpusFor each original sentence, we collected 5 candi-date paraphrases to simulate the fact that we had arepertoire of paraphrases with the required entries:9?
WICOPACO: the original paraphrase from theWICOPACO corpus;?
GAME: two candidate paraphrases from usersof our Web-based game;?
PIVOTES and PIVOTZH: two candidate para-phrases obtained by translation by pivot, usingthe Google Translate10 online SMT system andone language close to French as pivot (Span-ish), and another one more distant (Chinese).We then presented the original sentence and its 5paraphrases (in random order) to two judges.
Fournative speakers took part in our experiments: theyall took part in the data collection for one half ofthe sentences of the training and test corpora and tothe evaluation of paraphrases for the other half.
Forthe annotation with two classes (paraphrase vs. notparaphrase), we obtain as inter-judge agreement11 a9Note that, as a consequence, we did not carry any experi-ment related to the recall of any technique here.10http://translate.google.com11We used R (http://www.r-project.org) to com-pute this Cohen?s ?
value.15Figure 3: Example of an original sentence and its 5 associated candidate paraphrases.
The phrase in bold from theoriginal sentence (The brand is at the origin of many concepts that have revolutionized computing.)
is paraphrasedas est le promoteur (is the promoter), a popularise?
(popularized), origine (origin), est a` la source (is the source), andl?origine (the origin).value of ?
= 0.65, corresponding to a substantialagreement according to the literature.
An exampleof the interface used is provided in Figure 3.We considered that our technique could not pro-pose reliable results when web phrase counts weretoo low.
From the distribution of counts of phrasesand paraphrases from our training set (see Figure 4),we empirically chose a threshold of 10 for the min-imum count of any phrase.
Our corpus was conse-quently reduced from 750=150*5 to 434 examplesfor the training corpus, and from 250=50*5 to 215for the test corpus.<10 <100 <1000 <10000 <100000 <1000000 >10000000102030405060708090100 # of original phrases# of paraphrasesRange of number of countsFigure 4: Number of phrases and paraphrases per webcount rangeResults will be reported for three conditions:?
Possible: the gold standard for instances whereat least one of the judges indicated ?para-phrases?
records the pair as a paraphrase.
Inthis condition, the test set has 116 instances thatare paraphrases and 99 that are not.?
Sure: the gold standard for instances where notall judges indicated ?paraphrases?
records thepair as not paraphrase.
In this condition, thetest set has 76 instances that are paraphrasesand 139 that are not.?
Surer: only those instances where both judgesagree are recorded.
This reduces our trainingand test set to respectively 287 and 175 exam-ples.
Thus, results on this subcorpora will notbe directly comparable with the other results.In this condition, the test set has 76 instancesthat are paraphrases and 99 that are not.5.2 Baseline techniquesWeb-count based baselines We used two base-lines based on simple Web counts.
The first one,WEBLM, considers a candidate sentence a para-phrase of the original sentence whenever its Weblanguage model score is higher than that of the orig-inal phrase.
The second one, BOUNDLM, considersa sentence as a paraphrase whenever the counts forthe bigrams crossing the left and right boundary ofthe sub-sentential paraphrase is higher than 10.Syntactic dependency baseline When rewriting asubpart of a sentence, the fact that syntactic depen-dencies between the rewritten phrase and its con-text are the same than those of the original phraseand the same context can provide some information16about the grammatical and semantic substituabilityof the two phrases (Zhao et al, 2007; Max and Zock,2008).
We thus build syntactic dependencies forboth the original and rewritten sentence, using theFrench version (Candito et al, 2010) of the Berkeleyprobabilistic parser (Petrov and Klein, 2007), andconsider the subset of dependencies for the two sen-tences that exist between a word inside the phraseunder focus and a word outside it (Deporig andDeppara).
Our CONTDEP baseline considers a sen-tence as a paraphrase iff Deppara = Deporig.5.3 Evaluation resultsWe used the models described in Section 4 to builda SVM classifier using the LIBSVM package (Changand Lin, 2001).
Accuracy results are reported onFigure 5.WEBLM BOUNDLM CONTDEP CLASSIFIERPOSSIBLE 62.79 54.88 48.53 57.67SURE 68.37 36.27 51.90 70.69SURER 56.79 51.41 42.69 62.85Figure 5: Accuracy results for the three baselines and ourclassifier on the test set for the three conditions.
Note thatthe SURER condition cannot be directly compared withthe other two as the number of training and test examplesare not the same.The first notable observation is that our task is notsurprisingly a difficult one.
The best performanceachieved is an accuracy of 70.69 with our system inthe SURE condition.
There are, however, some im-portant variations across conditions, with a result aslow as 57.67 for our system in the POSSIBLE condi-tion (recall that in this condition candidates are con-sidered paraphrases when only one of the two judgesconsidered it a paraphrase, i.e.
when the two judgesdisagreed).Overall, the WEBLM baseline and our system ap-pear as stronger than the two other baselines.
Thetwo lower baselines, BOUNDLM and CONTDEP, at-tempt to model local grammatical constraints, whichare not surprisingly not sufficient for paraphraseidentification.
WEBLM is comparatively a muchmore competitive baseline, but its accuracy in theSURER condition is not very strong.
As this lattercondition considers only consensual judgements forthe two judges, we can hypothesize that the interpre-tation of its results is more reliable.
In this condi-WICOPACO GAMERS PIVOTES PIVOTZHPOSSIBLE 89.33 67.00 47.33 20.66SURE 64.00 44.50 31.33 10.66SURER 86.03 57.34 37.71 12.60Figure 6: Paraphrase accuracy of our different paraphraseacquisition methods for the three conditions.tion, our system obtains the best performance, witha +6.06 advantage over WEBLM.
As found in otherworks (e.g.
(Bannard and Callison-Burch, 2005)),using language models for paraphrase validation isnot sufficient as it cannot model meaning preserva-tion, and our results show that this is also true evenwhen counts are estimated from the Web.
Using aratio of normalized LM scores may have improvedthe situation a bit.12Lastly, we report in Figure 6 the paraphraseaccuracy of each individual acquisition technique(i.e.
source of paraphrases from the preexistingrepertoire).
The original rewritting from WICO-PACO obtains not surprisingly a very high para-phrase accuracy, in particular in the POSSIBLE andSURER conditions.
Paraphrases obtained throughour Web-based game have an acceptable accuracy:the numbers confirm that paraphrase pairs are highlycontext-dependent, because the pairs which werelikely to be paraphrases in the context of the gameare not necessarily so in a different context.
This,of course, may be due to a number of reasons thatwe will have to investigate.
Lastly, there is a signif-icant drop in accuracy for the automatic pivot para-phrasers, but pivoting through Spanish obtained, notsuprisingly again, a much better performance thanpivoting through Chinese.6 Discussion and future workWe have presented an approach to the task oftargeted paraphrasing in the context of text revi-sion, a scenario which was supported by naturally-occurring data from the rephrasing memory ofWikipedia.
Our framework takes a repertoire of ex-isting sub-sentential paraphrases, coming from pos-12A possible explanation for the relative good performance ofWEBLM may lie in the fact that our two automatic paraphrasersusing Google Translate as a pivot translation engine tend to pro-duce strings that are very likely according to the language mod-els used by the translation system, which we assume to be verycomparable to those that were used in our experiments.17sibly any source including manual acquisition, andvalidates all candidate paraphrases using informa-tion from the Web.
Our experiments have shownthat the current version of our classifier outperformsseveral baselines when considering paraphrases withconsensual judgements in the gold standard refer-ence.Although our initial experiments are positive, webelieve that they can be improved in a number ofways.
We intend to broaden our exploration of thevarious characteristics at play.
We will try more fea-tures, including e.g.
a model of syntactic depen-dencies derived from the Web, and extend our workto new languages.
We will also attempt to analyzemore precisely our results to identify problematiccases, some of which could turn to be almost im-possible to model without resorting to world knowl-edge, which was beyond our attempted modeling.Finally, we will also be interested in considering theapplicability of this approach as a framework for theevaluation of paraphrase acquisition techniques.AcknowledgmentsThis work was partly supported by ANR projectTrace (ANR-09-CORD-023).
The authors wouldlike to thank the anonymous reviewers for their help-ful questions and comments.ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of ACL, Ann Arbor, USA.Regina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: an unsupervised approach using multiple-sequence alignment.
In Proceedings of NAACL-HLT,Edmonton, Canada.Regina Barzilay and Kathleen McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In Proceedingsof ACL, Toulouse, France.Michael S. Bernstein, Greg Little, Robert C. Miller,Bjo?rn Hartmann, Mark S. Ackerman, David R. Karger,David Crowell, and Katrina Panovich.
2010.
Soylent:a word processor with a crowd inside.
In Proceedingsof the ACM symposium on User interface software andtechnology.Rahul Bhagat and Deepak Ravichandran.
2008.
Largescale acquisition of paraphrases for learning surfacepatterns.
In Proceedings of ACL-HLT, Columbus,USA.Houda Bouamor, Aure?lien Max, and Anne Vilnat.
2011.Monolingual alignment by edit rate computation onsentential paraphrase pairs.
In Proceedings of ACL,Short Papers session, Portland, USA.Chris Brockett and William B. Dolan.
2005.
Supportvector machines for paraphrase identification and cor-pus construction.
In Proceedings of The 3rd Inter-national Workshop on Paraphrasing IWP, Jeju Island,South Korea.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of EMNLP, Hawai, USA.Marie Candito, Beno?
?t Crabbe?, and Pascal Denis.
2010.Statistical french dependency parsing: treebank con-version and first results.
In Proceedings of LREC, Val-letta, Malta.R.
Chandrasekar, Christine Doran, and B. Srinivas.
1996.Motivations and methods for text simplification.
InProceedings of COLING, Copenhagen, Denmark.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIB-SVM: a library for support vector machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Timothy Chklovski.
2005.
Collecting paraphrase cor-pora from volunteer contributors.
In Proceedings ofKCAP 2005, Banff, Canada.Trevor Cohn and Mirella Lapata.
2008.
Sentence com-pression beyond word deletion.
In Proceedings ofCOLING, Manchester, UK.Trevor Cohn, Chris Callison-Burch, and Mirella Lapata.2008.
Constructing corpora for the development andevaluation of paraphrase systems.
Comput.
Linguist.,34(4):597?614.Michael Connor and Dan Roth.
2007.
Context sensitiveparaphrasing with a global unsupervised classifier.
InProceedings of ECML, Warsaw, Poland.Louise Dele?ger and Pierre Zweigenbaum.
2009.
Extract-ing lay paraphrases of specialized expressions frommonolingual comparable medical corpora.
In Pro-ceedings of the 2nd Workshop on Building and UsingComparable Corpora: from Parallel to Non-parallelCorpora, Singapore.Camille Dutrey, Houda Bouamor, Delphine Bernhard,and Aure?lien Max.
2011.
Local modifications andparaphrases in wikipedia?s revision history.
SEPLNjournal, 46:51?58.Cristina Espan?a Bonet, Marta Vila, M. Anto`nia Mart?
?,and Horacio Rodr??guez.
2009.
Coco, a web interfacefor corpora compilation.
SEPLN journal, 43.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time.
In Proceedings of NAACL-HLT, Los Angeles, USA.18Mirella Lapata and Frank Keller.
2005.
Web-based Mod-els for Natural Language Processing.
ACM Transac-tions on Speech and Language Processing, 2(1):1?31.Weigang Li, Ting Liu, Yu Zhang, Sheng Li, and WeiHe.
2005.
Automated generalization of phrasal para-phrases from the web.
In Proceedings of the IJCNLPWorkshop on Paraphrasing, Jeju Island, South Korea.Nitin Madnani and Bonnie J. Dorr.
2010.
Generatingphrasal and sentential paraphrases: A survey of data-driven methods.
Computational Linguistics, 36(3).Nitin Madnani, Philip Resnik, Bonnie J. Dorr, andRichard Schwartz.
2008.
Are multiple referencetranslations necessary?
investigating the value ofparaphrased reference translations in parameter opti-mization.
In Proceedings of AMTA, Waikiki, USA.Aure?lien Max and Guillaume Wisniewski.
2010.
Min-ing Naturally-occurring Corrections and Paraphrasesfrom Wikipedia?s Revision History.
In Proceedings ofLREC 2010, Valletta, Malta.Aure?lien Max and Michael Zock.
2008.
Looking upphrase rephrasings via a pivot language.
In Proceed-ings of the COLING Workshop on Cognitive Aspectsof the Lexicon, Manchester, United Kingdom.Aure?lien Max.
2004.
From controlled document au-thoring to interactive document normalization.
In Pro-ceedings of COLING, Geneva, Switzerland.Diana McCarthy and Roberto Navigli.
2009.
The en-glish lexical substitution task.
Language Resourcesand Evaluation, 43(2).Andrew Mutton, Mark Dras, Stephen Wan, and RobertDale.
2007.
Gleu: Automatic evaluation of sentence-level fluency.
In Proceedings of ACL, Prague, CzechRepublic.Andrew Mutton.
2006.
Evaluation of sentence grammat-icality using Parsers and a Support Vector Machine.Ph.D.
thesis, Macquarie University.Takashi Onishi, Masao Utiyama, and Eiichiro Sumita.2010.
Paraphrase Lattice for Statistical MachineTranslation.
In Proceedings of ACL, Short Papers ses-sion, Uppsala, Sweden.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignement of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of NAACL-HLT, Edmonton, Canada.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of NAACL-HLT, Rochester, USA.Chris Quirk, Chris Brockett, and William B. Dolan.2004.
Monolingual machine translation for paraphrasegeneration.
In Proceedings of EMNLP, Barcelona,Spain.Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kronrod,Alex Quinn, and Benjamin B. Bederson.
2010.
Im-proving translation via targeted paraphrasing.
In Pro-ceedings of EMNLP, Cambridge, MA.Josh Schroeder, Trevor Cohn, and Philipp Koehn.
2009.Word lattices for multi-source translation.
In Proceed-ings of EACL, Athens, Greece.Matthew Snover, Nitin Madnani, Bonnie J. Dorr, andRichard Schwartz.
2010.
TER-Plus: paraphrase, se-mantic, and alignment enhancements to TranslationEdit Rate.
Machine Translation, 23(2-3).Kuansan Wang, Chris Thrasher, Evelyne Viegas, Xiao-long Li, and Bo-june (Paul) Hsu.
2010.
An Overviewof Microsoft Web N-gram Corpus and Applications.In Proceedings of the NAACL-HLT DemonstrationSession, Los Angeles, USA.Shiqi Zhao, Ting Liu, Xincheng Yuan, Sheng Li, andYu Zhang.
2007.
Automatic acquisition of context-specific lexical paraphrases.
In Proceedings of IJCAI2007, Hyderabad, India.Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li.
2009.Application-driven statistical paraphrase generation.In Proceedings of the Joint ACL-IJCNLP, Singapore.Shiqi Zhao, Haifeng Wang, Ting Liu, , and Sheng Li.2010.
Leveraging multiple mt engines for paraphrasegeneration.
In Proceedings of COLING, Beijing,China.Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.2010.
A monolingual tree-based translation model forsentence simplification.
In Proceedings of COLING,Beijing, China.19
