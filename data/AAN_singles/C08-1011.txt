Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 81?88Manchester, August 2008A Concept-Centered Approach to Noun-Compound InterpretationCristina ButnariuSchool of Computer Science and InformaticsUniversity College DublinBelfield, Dublin 4Ioana.Butnariu@ucd.ieTony VealeSchool of Computer Science and InformaticsUniversity College DublinBelfield, Dublin 4Tony.Veale@ucd.ieAbstractA noun-compound is a compressedproposition that requires an audience torecover the implicit relationship betweentwo concepts that are expressed as nouns.Listeners recover this relationship byconsidering the most typical relationsafforded by each concept.
Theserelational possibilities are evident at alinguistic level in the syntagmaticpatterns that connect nouns to the verbalactions that act upon, or are facilitatedby, these nouns.
We present a model ofnoun-compound interpretation that firstlearns the relational possibilities forindividual nouns from corpora, andwhich then uses these to hypothesizeabout the most likely relationship thatunderpins a noun compound.1 IntroductionNoun compounds hide a remarkable depth ofconceptual machinery behind a simple syntacticform, Noun-Noun, and thus pose a considerableproblem for the computational processing oflanguage (Johnston and Busa, 1996).
It is not justthat compounds are commonplace in language,or that their interpretation requires a synthesis oflexical, semantic, and pragmatic informationsources (Finin, 1980); compounds provide ahighly compressed picture of the workings ofconcept combination, so there are as many waysof interpreting a noun compound as there areways of combining the underlying concepts(Gagn?, 2002).
Linguists have thus attempted to?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.understand noun-compounds as full propositionsin which a phrase with two nouns connected byan explicit relation ?
usually expressed as a verband a preposition ?
is compressed into a pair ofnouns (Levi, 1978).
Since these noun-pairs mustallow an audience to reconstruct thedecompressed proposition, there must be somesystematic means by which the missing relationcan easily be inferred.This framing of the problem as a search for amissing relation suggests two broad strategies forthe interpretation of compounds.
In the first, thetop-down strategy, we assume that there are onlyso many ways of combining two concepts; byenumerating these ways, we can view theproblem of interpretation as a problem ofclassification, in which compounds are placedinto separate classes that each correspond to asingle manner of concept connection (Kim andBaldwin, 2006), (Nastase and Szpakowicz,2003).
This strategy explicitly shaped theSemEval task on classifying semantic relationsbetween nominals (Girju et al, 2007) and so isemployed by all of the systems that participatedin that task.
In the second, the bottom-upstrategy, we assume that it is futile to try andenumerate the many ways in which concepts canrelationally combine, but look instead to largecorpora to discover the ways in which differentword combinations are explicitly framed bylanguage (Nakov, 2006), (Turney, 2006a).In this paper we describe an approach thatemploys the bottom-up strategy with an open-rather than closed-inventory of inter-conceptrelations.
These relations are acquired from theanalysis of large corpora, such as the Web ITcorpus of Google n-grams (Brants and Franz,2006).
We argue that an understanding of noun-compounds requires an understanding oflexicalized concept combination, which in turnrequires an understanding of how lexicalconcepts can be used and connected to others.
Assuch, we do not use corpora as a means of81characterizing noun-compounds themselves, butas a means of characterizing the actionpossibilities of the individual nouns that canparticipate in a compound.
In other words, weattempt to characterize those properties ofdifferent concepts denoted by nouns to helppredict how those nouns will combine withothers, and through which relations.
For instance,?diamonds?
can be used to cover and encrustjewelry or to provide a sharp tip for varioustools; we see the former usage in ?diamondbracelet?
and the latter in ?diamond saw?.Likewise, ?cheese?
is a solid substance whichcan be cut, as in ?cheese knife?, an ediblesubstance that can used as a filling, as in ?cheesesandwich?, and a substance that can be melted asa topping, as in ?cheese pizza?.
It follows that asandwich can be filled, a pizza can be topped,knives can cut and a bracelet can have a coveringof gems.
We use relational possibilities as ageneral term for what are sometimes called thequalia of a word (Pustejovsky, 1995), and learnthe linguistic relational possibilities of nouns byseeking out specific textual patterns in corpora.In section 2 we consider the most currentlyrelevant elements of the substantial body of pastwork in this area.
In section 3 we describe howcorpus analysis is used to identify the mostcommon lexico-semantic relational possibilitiesof nouns, while in section 4 we describe howthese relations are used, in conjunction with web-based validation, to interpret specific noun-compounds.
We present an evaluation of thisapproach in section 5 and conclude the paperwith some final remarks in section 6.2 Related WorkMachine-learning and example-based approachesto noun-compounds generally favor the top-downstrategy for defining relations, since it allowstraining data and exemplars/cases to be labeledusing a fixed inventory of relational classes.
Asnoted earlier, this strategy is characteristic of thesystems that participated in the SemEval task onclassifying semantic relations between nominals(Girju et al, 2007), such as Butnariu and Veale(2007).
Though the inventory is fixed in size, itcan be defined using varying levels ofabstraction; for instance, Nastase andSzpakowicz (2003) use an inventory of 35relations, 5 of which are top level relations withthe remaining 30 at the lower level.
The top-down strategy pre-dates these computationalapproaches, and is a key aspect of thefoundational work of Levi (1978) and ofsubsequent work by Gagn?
and Shoben (1997),both of whom posit a small set of semanticrelations as underpinning all noun compounds.More recently, Kim and Baldwin (2005) use afixed inventory of semantic relations to annotatea case-base of examples; new compounds areunderstood by determining their lexical similarityto the closest annotated compounds in the case-base.
Kim and Baldwin (2006) link theirrelations to specific seed verbs that linguisticallyconvey these relations, and then train a classifierto recognize which semantic relation is impliedby a pair of nouns connected by a givenintervening verb.
This approach appears to besensitive to the number of seed verbs; on a testinvolving 453 noun compounds, an accuracy of52.6% is achieved with 84 seed verbs, but just46.6% with 57 seed verbs.Verbs understandably play a key role in theinterpretation of compounds, since some kind ofpredicate must be recovered to link both nouns.For instance, Levi (1978) uses verbs to makeexplicit the implicit relation between the nounsof a compound, while Finin (1980) characterizesthe relation in a noun-noun compound using aninventory of all the possible verbs that can linkboth nouns; thus, e.g.
salt water is interpretedusing a relation like dissolved_in.
Nakov (2006)takes a similar approach, and uses verb-centredparaphrases to express the semantic relationsbetween the nouns of a compound.
He arguesthat the meaning of a compound is bestexpressed via a collection of appropriate verbsrather than via the abstract relations (such asCause, Location) that are used in moretraditional approaches, such as those of Levi(1978) and Gagn?
(2002).Nakov (2006) pursues a bottom-up strategy inwhich an open-ended inventory of relations isdiscovered using linguistic evidence.
Turney(2006a, 2006b) similarly pursues a bottom-up,data-driven approach, in which semanticrelations are expressed via representative lexico-syntactic patterns that are mined from large textcorpora.
Turney (2006a) sorts these relationalpatterns by pertinence, a measure that reflects thesimilarity of the noun pairs in the corpus inwhich each pattern is observed to occur.
Patternswhich are relatively unambiguous and whichserve to cluster noun pairs with similar meaningshave higher pertinence than those that do not.The approach described here is similarly corpus-based and verb-centric, but it is also noun-centricrather than pair-centric, which is to say, we use82corpus analysis to learn about the relationalbehavior of individual nouns rather than pairs ofnouns.
Like many other authors, from Finin(1980) to Nakov (2006), we see the problem ofcompound interpretation as a problem ofparaphrase generation, in which a suitable verb(with an optional preposition) is used tolinguistically re-frame the compound as acomplete proposition.
This linguistic frame is arelational possibilities of one of the nouns that isapt for the other.
Following Gagn?
and Shoben(1997), this relational possibilities is frequentlysuggested by the modifier noun, but as we nowdescribe, it may also be suggested by the head.3 Acquisition of Relational PossibilitiesThe meaning of a noun compound can beparaphrased in a variety of ways.
For instance,consider the compound ?headache pill?, whichmight be paraphrased as follows:P1: headache-inducing pillP2: headache prevention pillP3: pill for treating headachesP4: pill that causes headachesP5: pill that is prescribed forheadachesP6: pill that prevents headachesSome paraphrases are syntactic variants of others(e.g., P2 and P6), others employ lexical variation(e.g., P1 and P4) and others are co-descriptionsof the same event (e.g., P3 and P5 or P5 and P6).It thus seems unreasonable to try and reducethese meanings to a single semantic relation,since the compound can be used to mean severalof P1 ?
P6 simultaneously.
Rather than try toconstruct an inventory of logical relations, closedor otherwise, we shall instead treat linguisticframes like ?for treating X?, ?that prevents X?.etc.
as proxies for the relations themselves, whileretaining the capacity to treat syntactic variantsas proxies for the same relation.
Moreover, theselinguistic frames are relational possibilities ofspecific words, so that ?-inducing X?
is arelational possibility of ?headache?
while ?fortreating X?
is a relational possibility of ?pill?.Thus, a compound of the form ?headache X?might be re-framed as ?headache-inducing X?and a compound of the form ?X pill?
might bere-framed as ?pill that prevents X?, ?pill thatcauses X?
or ?pill for treating X?.The relational possibilities of individual wordscan be acquired from a large n-gram corpus likethat of Brants and Franz (2006), as derived fromGoogle?s web index.
Table 1 summarizes thelinguistic relational possibilities that can bederived from specific n-gram patterns.Google n-grampatternRelationalpossibilitiesLogical FormX ?
Verb+ing X Verb+ing Y verb(X, Y)X ?
Verb+ed X Verb+ed Y verb(X, Y)Verb+ed prep X Y Verb+ed prep X verb_prep(Y, X)X Verb+ed X Verb+ed prep Y verb_prep(X, Y)for Verb+ing X Y for Verb+ing X verb(Y, X)X for Verb+ing X for Verb+ing Y verb(X, Y)that Verb+s X Y that Verb+s X verb(Y, X)X that Verb+s X that Verb+s Y verb(X, Y)Table 1.
For an anchor noun X, the n-gram(left) suggests relational possibilities (middle) tolink to a generic noun Y; different linguisticrelational possibilities can have the same logicalform (right).For example, we extract the followinglinguistic relational possibilities for the noun?diamond?, where Google frequencies are givenin parentheses:accented_with_diamonds(4224),encrusted_with_diamonds(3990),decorated_with_diamonds(2616),based_on_diamond(2148),covered_with_diamonds(2018),filled_with_diamonds(1942),adorned_with_diamonds(1462),coated_with_diamond(1150),for_buying_diamonds(618),for_grading_diamonds(342),for_cutting_diamonds(430),dusted_in_diamond(168),bedecked_with_diamonds(140),tipped_with_diamond(108),crowned_with_diamonds(98),for_exporting_diamonds(98),embossed_with_diamond(90),edged_with_diamonds(82),drilled_with_diamond(86),that_sells_diamonds(44)?A hat may be crowned with diamonds, a watchdecorated with diamonds, a bracelet coveredwith diamonds, a throne encrusted withdiamonds and a king bedecked with diamonds ?each is an elaboration of a basic coveringrelation, but each adds nuances of its own thatwe do not want to lose in an interpretation that is83maximally specific to the nouns concerned.
Wetherefore take the view that relations should be asopen-ended and nuanced as the linguisticevidence suggests; if one needs to see twodifferent relations as broadly equivalent,resources like WordNet (Fellbaum, 1998) can beused to make the generalization.4 Interpreting Noun CompoundsWe see interpretation of a compound M-H as atwo-stage process of divergent generationfollowed by convergent validation.
Thegeneration process simply considers therelational possibilities associated either with themodifier M or the head H and generates aparaphrase from each.
Consider the compound?yeast bread?
where M = ?yeast?
and H =?bread?
; the relational possibilities for ?yeast?and ?bread?
and used to generate a set ofpotential paraphrases as shown in Table 2.
Forclarity, ?M?
and ?H?
denote the parts of eachparaphrase frame that will be filled with themodifier and head respectively.Relational possibilitiesfor MParaphrases for M-HH Verb+ed prep Me.g., H derived from yeastH Verb+ed prep Me.g., bread derivedfrom yeastH that Verb+s Me.g., H that contains yeastH that Verb+s Me.g., bread thatcontains yeastRelational possibilitiesfor HParaphrase for M-HH Verb+ed prep Me.g., bread prepared withMH Verb+ed prep Me.g., bread preparedwith yeastH that Verb+s Me.g., bread that has MH that Verb+s Me.g., bread that hasyeastTable 2.
Relational possibilities of the head (H)and modifier (M) nouns used for paraphrasing.The relational possibilities for the head noun?bread?
yield the following paraphrases, wherenumbers in parentheses are Google frequenciesfor the original n-grams on which eachparaphrase is based:?bread made from yeast?
(6335),?bread topped with yeast?
(6043), ?bread made with yeast?
(4726), ?bread stuffed withyeast?
(3871), ?bread baked inyeast?
(3341), bread made ofyeast?
(3064), ?bread servedwith yeast?
(3012), ?breadsoaked in yeast?
(2975), ?breaddipped in yeast?
(2873), ?breadfilled with yeast?
(2783), ...Similarly, the relational possibilities for themodifier noun ?yeast?
yield the followingparaphrases:?bread expressed in yeast?
(14058), ?bread leavened withyeast?
(10816), ?bread derivedfrom yeast?
(2562), ?breadbased on yeast?
(1200), ?breadfermented with yeast?
(842),?bread raised with yeast?
(736), ?bread induced in yeast?
(342) , ?bread infected withyeast?
(262), ?bread filledwith yeast?
(120), ?While these two sets of relational possibilitiescapture the most salient activities in which?yeast?
and  ?bread?
participate, many of theparaphrases listed here are inappropriate for?yeast bread?.
Candidate paraphrases for a nouncompound are useful only when one has a meansof determining the degree to which paraphrasesare meaningful and apt and of rejecting thosewhich are not.
This process typically assumesthat a meaningful paraphrase is one for whichevidence of prior usage can be found in a largecorpus (like the web); the greater this evidence,the more favored a given paraphrase should be.This assumption is central to Nakov (2006), whouses templates to find paraphrases for a nouncompound on the web.
These templates use theGoogle wildcard * to indicate the position of averb so that the specific verbs at the heart of aparaphrase can be mined from the snippets thatare returned.
Nakov (2007) uses the schematicpatterns ?N1 that * N2?,  ?N2 that * N1?,  ?N1 *N2?
and ?N2 * N1?, where the wildcard canstand for as many a eight contiguous words.Relational possibilities allow us, in the firstdivergent stage of interpretation, to generatefully-formed paraphrases that do not requirewildcards, so the second convergent stage ofinterpretation simply needs to validate theseparaphrases by finding one or more instances ofeach on the web.
Indeed, an especiallycompelling paraphrase may be found in theGoogle n-grams themselves, without recourse tothe web.
For instance, the paraphrase ?breadleavened with yeast?
has a frequency of 56 in thedatabase of Google 4-grams, while the84paraphrase ?bread based on yeast?
has such alow web frequency of 2 hits that it can bevalidated only by going to the web.But web-based validation has its limitations: itcannot account for novel and creativecompounds, nor can it account for conventionalcompounds whose meaning is not echoed in anexpanded paraphrase-form on the web.
Thus, wealso consider an alternate validation procedurefor those paraphrases that can  be generated bothfrom a modifier noun relational possibility andfrom a head noun relational possibility.
Forexample, ?bread filled with yeast?
can be derivedfrom the head relational possibility ?bread filledwith X?
which has a frequency of 2783, andfrom the modifier relational possibility ?X filledwith yeast?
which has a frequency of just 120.This dual basis for generation provides evidencethat the paraphrase is meaningful without theneed to actually find the paraphrase on the web.We refer to the validation of paraphrases in thisway as validation by matching relationalpossibilities of the modifier and head nouns.This matching relational possibilitiesprocedure does not require web validation, andso does not produce a web frequency for eachparaphrase.
We thus need to assign a score to aparaphrase based on the web frequencies of thematching relational possibilities that give rise toit.
For simplicity, we add the web frequency ofthe head relational possibility (e.g., 2783 from?bread filled with X?)
to the frequency of themodifier relational possibility (e.g., 120 from ?Xfilled with yeast?)
to obtain an inventedfrequency for the generated paraphrase (e.g.,2903 for ?bread filled with yeast?
).The third and more restricted validationprocedure we employ is a hybrid one, based onthe intersection of the two procedures above: werequire web-validation of paraphrases that arealready validated by virtue of arising frommatching head and modifier relationalpossibilities.
In this case, we rank theparaphrases by their actual web frequency.
Theset of paraphrases validated by the hybridapproach will be a subset of the paraphrasesvalidated by the other two validation methods;the size of this subset will be informative aboutthe relative utility of each procedure.5 Empirical EvaluationTo evaluate the relational possibility approach tonoun-noun interpretation, we perform twoexperiments: one to consider how well the set ofvalidated paraphrases can be mapped to theabstract relations used by (Nastase andSzpakowicz, 2003) to annotate their noun-nouncompounds, and one to consider how well theseparaphrases match the paraphrases offered byhumans for the same noun compounds.
Tounderstand the role of different validationstrategies, we use three variants of the model thatcorrespond to the three means of validatingparaphrases: model-1 uses the presence of therelational possibility on the web as the mark of avalid paraphrase; model-2 uses the matchingrelational possibilities procedure to validate aparaphrase (i.e., the paraphrase must arise fromboth an relational possibility of the modifier andof the head); a third model, model-3 intersectsboth validation procedures.
In each case,validated paraphrases are ranked by theirfrequency scores, as found explicitly on the webin the case of model-1 and model-3, or asinvented in model-2.5.1 Mapping compounds to abstract relationsIn the first experiment, we test the relationalpossibility model on a set of noun-nouncompounds from Nastase and Szpakowicz(2003), whose data is pre-classified into abstractclasses of semantic relations (i.e., Agent,Instrument, Location).
We perform a manualanalysis on the paraphrases that are generatedand validated for each noun pair, to measure howaccurately each paraphrase matches the pre-classified abstract semantic relation.
The Nastaseand Szpakowicz (2003) dataset comprises 600word pairs of the form adj-noun, adv-noun andnoun-noun; for this experiment we use only the329 noun-noun pairs, which are each pre-labeledwith one of 28 different semantic relations.We consider and quantify two eventualities here:those situations in which the relational possibilitymodel generates and validates a paraphrase thatclosely corresponds to the semantic relationassigned by Nastase and Szpakowicz (2003); andthose situations in which the relational possibilitymodel generates and validates an interpretationthat a human judge considers a plausible andsensible interpretation of a compound regardlessof Nastase and Szpakowicz (2003)?sinterpretation.
Table 3 presents validatedrelational possibilities for the compound ?oliveoil?, where those that match the pre-classifiedrelation are in bold, and those that are otherwiseplausible are italicized.85Paraphrases generated byweb-based validationParaphrases generated bymatching relational possibilitiesParaphrases generated byNakov (2007)extracted from (189), obtained from(132), mixed with (87), made from(75), produced from (38), pressedfrom (35), colored (25), infused (20),enriched with (16), made of (14),flavored (13), made with (12), derived(10), based (10), produced by (9),blended with (8), coloured (7), basedon (7), combined with (6), found in(6), dissolved in (6), served with (6),contained in (5), replaced by (4),flavoured (3), come from (3)?used in (25839), obtained from(15352), extracted from (14561),made from (11627), found in(11524), used for (9919), mixed with(9781), produced from (7794),produced by (6776), made with(5423), used as (4880),  are in (4577),contained in (4551), come from(4241), based on (4135), combinedwith (4029), added to (3848), made in(3608) ?come from (13), beobtained from (11), beextracted from (10), bemade from (9), beproduced from (7), bereleased from (4), tastelike (4), be beaten from(3), be produced with (3) ,emerge from (3)Table 3.
Validated paraphrases for ?olive oil?
; matches with Nastase and Szpakowicz are inbold; other sensible interpretations are italicized.We also consider the rank of the paraphrasesthat match the relations assigned by Nastase andSzpakowicz (2003) to this data set.
Figure 1graphs the F-measure for the relationalpossibilities approach when this relation is thetop-ranked validated paraphrase, when it is in thetop two validated paraphrases, and  moregenerally, when  it is in the top n validatedparaphrases, n <= 20.
Model-1 (web-basedvalidation) out-performs Model-2 (matchingrelational possibilities, with no web validation)when we consider just a small window of topranked paraphrases, but this situation reverses asthe window (whose size is given on the x-axis) isenlarged.F-measure (%) for top ranked paraphrases01020304050607080901 3 5 7 9 11 13 15 17 19Model 1Model 2Model 3Figure 1.
F-measure for target semanticrelations of top n ranked paraphrases generatedwith Model-1, Model-2 and Model-3.Model 3 (which requires both matchingrelational possibilities and web validation) showssimilar results to Model 2 (web validation only),which suggests that the matching relationalpossibilities criterion is strongly predictive ofweb-validation.
This further suggests thatmatching relational possibilities alone canreliably validate a paraphrase even when webevidence is lacking, as will be the case increative noun compounds.During this evaluation process, we observe atendency for specific paraphrases to co-occurwhen conveying a certain relation.
For instance,Y obtained from X typically co-occurs with Yproduced from X to indicate Nastase andSzpakowicz?s Source relation, while Y caused byX co-occurs with Y induced by X to convey theirEffect relation, and Y owned by X co-occur withY held by X to indicate their Possessor relation.This observation is similar to that of Nakov(2007), who performs a manual analysis ofparaphrases obtains from web-mining.
Theresults he reports are similar to those obtainedusing the relational possibilities approach, asshown in Table 3.5.2 Comparing human-generated paraphrasesIn the second experiment, we compared theparaphrases validated by the relationalpossibilities approach to human-generatedparaphrases reported by Nakov (2007) and to theparaphrases generated by Nakov?s own web-mining approach to this task.
Nakov (2007)collected human paraphrases for each noun-compound in his data-set (250 noun compoundslisted in the appendix of Levi, 1978) by askingsubjects to rephrase a noun-compound using arelative-clause centred around a single verb withan optional preposition.
This rephrasing elicitedhuman-generated paraphrases like the following:'neck vein is a vein that comesfrom the neck''neck vein is a vein that drainsthe neck'86Nakov then extracted normalized verbs andprepositions from these paraphrases to obtain areduced verb-based form for each, e.g., to obtainthe reduced forms come from and drain from theabove examples.
He used 174 subjects for thistask, to generate around 17,000 reduced forms,or 71 forms per compound.For each of his 250 noun pairs we constructedthree vectors h, w, and a, using human-generatedparaphrase verbs and their frequencies (h),Nakov's web-extracted verbs and theirfrequencies (w) and the verbs of the paraphrasesobtained using the relational possibilitiesapproach and their frequencies (a).
FollowingNakov (2007), we then calculated the cosinecorrelation between two frequency vectors usingthe formula:simcos(h,w) = ?hiwi   ?
?
?hi2 ??
wi2For ease of comparison, the a vector ispopulated with verbs and frequencies from justtwo patterns, Y Verb+ed Prep X and Y thatVerb+s X.
In Table 4 we report the averagecosine correlation across the vectors for all 250noun pairs, to compare for the three validationmodels the relational possibilities-based andNakov?s web-generated paraphrases and therelational possibilities -based and human-elicitedparaphrases.
Also shown, in the last row, is theaverage cosine correlation  between Nakov?sweb-mined paraphrases and human-elicitedparaphrases, as reported in Nakov (2007).Model 1 (web-validation)correlation to humans 26.8 %correlation to web-mined approach 27.1 %Model 2 (matching relational possibilities)correlation to humans 17 %correlation to web-mined approach 14.25 %Model 3 (intersection of Model-1 and Model-2)correlation to humans 27.9 %correlation to web-mined approach 28 %Web-mining (Nakov, 2007)correlation to humans 31.8%Table 4.
Average correlation between web-mined paraphrases and relational possibilities-based paraphrases with human elicitations.The results show the difference in quality ofthe paraphrases validated by each of our models.The matching-relational possibilities model(Model 2) yields the largest number ofparaphrases.
In the first experiment we showedthat this model outperforms the other two whenwe consider just top-ranked paraphrases, but hereit appears that this wider range of potentiallycreative interpretations diminishes the cosinecorrelation with human-elicited interpretations.But the most plausible paraphrases come to thefore in the hybrid model (Model 3), whoseparaphrases are a subset of those of Models 1 and2.
This hybrid approach also outperforms Model1 and compares well with the results obtained byweb mining.The difference in cosine correlation betweenhuman-elicited and relational possibitlies-basedparaphrases in Model-3 (27.9%) and Nakov?sweb-mined and human-elicited paraphrases(31.8%) can be justified both by the type ofpatterns used in the comparison, and by the typeof patterns used to validate paraphrases.
For one,we consider paraphrases generated using just twoforms of relational possibilities, Y Verb+ed PrepX and Y that Verb+s X, since these can bedirectly compared to the type of relative-clauseparaphrases used in this experiment.Furthermore, relational possibilities are derivedfrom Google n-grams where n < 6, we allow upto four words to intervene between the modifierand the head in a paraphrase, while the web-mining paraphrases benefit from a larger windowof intervening words (up to 8).
Nonetheless, in88 out of the 250 pairs, the correlation betweenrelational possibilities-based and human-elicitedparaphrases is larger than that observed for theweb-mining approach.6 ConclusionsSince the meaning of noun compounds arisesfrom a combination of individual noun meanings,it follows that the key input to the process ofcompound interpretation is detailed linguisticknowledge about how these nouns areconventionally used in language.
This point mayseem obvious, but a model of compounding canplace so much emphasis on the behavior of noun-pairs that the linguistic behavior of nouns inisolation is easily over-looked.We have presented a model of noun-compounding that places nouns and their specificlinguistic relational possibilities at the centre ofprocessing.
When one considers that linguisticrelational possibilities capture aspects of nounmeaning such as purpose, constitution andagency, their realization here can be viewed as a87generalized and lexicalized aspect of qualiastructure in the sense of Pustejovsky (1995) andJohnston and Busa (1996).
Indeed, the n-grampatterns used to extract these relationalpossibilities from corpora are not unlike thepatterns used by Cimiano and Wenderoth (2007)to harvest qualia structures from the web.We conclude from the empirical observationthat the hybrid model outperforms the web-basedmodel (albeit slimly) in experiment 2 while bothperform equally well in experiment 1, is that themodifier and head are of comparableperformance when paraphrasing theinterpretations of noun compounds.
Recall thatthe web-validation approach (Model-1) generatesinterpretations from either the modifier or thehead, while the matching-relational possibilitiesand hybrid models require both to contributeequally.Necessary extensions to the approach includethe acquisition of more relational possibilities ofgreater linguistic complexity, the ability toorganize relational possibilities hierarchicallyaccording to their underlying semantic meanings,and the ability to recognize an implicationstructure among different but related relationalpossibilities.AcknowledgementWe would like to thank Preslav Nakov forproviding us the data used in the secondexperiment.ReferencesBrants, T., and Franz, A.
2006.
Web 1t 5-gramversion 1, Linguistic Data Consortium.Butnariu, C., and Veale T. 2007.
A hybrid model fordetecting semantic relations between noun pairs intext.
In Proc.
of the Fourth International Workshopon Semantic Evaluations (SemEval-2007), Prague,.Association for Computational Linguistics.Cimiano, P., and Wenderoth, J.
2007.
AutomaticAcquisition of Ranked Qualia Structures from theWeb.
In Proc.
of the 45th Annual Meeting of theACL, pp 888-895.Fellbaum, C. 1998.
WordNet, an electronic lexicaldatabase.
Cambridge: MIT Press.Finin, T. 1980.
The semantic interpretation ofcompound nominals.
Urbana, Illinois: University ofIllinois dissertation.Gagn?, C. L., and Shoben, E. J.
1997.
Influence ofthematic relations on the comprehension ofmodifier-noun combinations.
Journal ofExperimental Psychology: Learning, Memory, andCognition, 23, 71?87Gagn?, C. L. 2002.
Lexical and Relational Influenceson the Processing of Novel Compounds.
Brain andLanguage 81(1-3), pp 723-735.Girju, R., Nakov, P. Nastase, V., Szpakowicz, S.,Turney, P., and Yuret, D. 2007.
Semeval-2007 task04: Classification of semantic relations betweennominals.
In Proc.
of the Fourth InternationalWorkshop on Semantic Evaluations (SemEval-2007), 13?18, Prague, Czech Republic.
ACL.Johnston, M., and Busa, F. 1996.
Qualia structure andthe compositional interpretation of compounds.
InProc.
of the ACL SIGLEX workshop on breadthand depth of semantic lexicons, Santa Cruz, CA.Kim, S. N., and Baldwin, T. 2006.
Interpretingsemantic relations in noun compounds via verbsemantics.
In Proc.
of the 21st InternationalConference on Computational Linguistics and the44th annual meeting of the ACL, pp 491?498, NJ,USA.Kim, S. N., and Baldwin, T. 2005.
Automaticinterpretation of noun compounds using WordNetsimilarity.
In Proc.
of the 2nd International JointConference On Natural Language Processing, pp945?956, Cheju, Korea.Levi, J.
1978.
The syntax and semantics of complexnominals.
NY: Academic Press.Nakov, P., and Hearst, M. A.
2006.
Using verbs tocharacterize noun-noun relations.
In AIMSA,Jerome Euzenat and John Domingue (eds.
), vol.4183 of Lecture Notes in Computer Science, pp233?244.
Springer.Nakov, P. 2007.
Using the Web as an ImplicitTraining Set: Application to Noun CompoundSyntax and Semantics.
Ph.D. Dissertation,University of California at Berkeley.Nastase, V., and Szpakowicz, S. 2003.
Exploringnoun-modifier semantic relations.
In Proc.
of the5th International Workshop on ComputationalSemantics (IWCS-5), pp 285?301, Tilburg, TheNetherlands.Pustejovsky, J.
1995.
The Generative Lexicon.
TheMIT Press, Cambridge, MA.Turney, P. 2006a.
Expressing implicit semanticrelations without supervision.
In Proc.
of the 21stInternational Conference on ComputationalLinguistics and the 44th annual meeting of theACL, pp 313?320, NJ, USA.Turney, P. D. 2006b.
Similarity of semantic relations.Computational Linguistics, 32, pp 379?416.88
