The LinGO Redwoods TreebankMotivation and Preliminary ApplicationsStephan Oepen, Kristina Toutanova, Stuart Shieber,Christopher Manning, Dan Flickinger, and Thorsten Brants{oe |kristina |manning |dan}@csli.stanford.edu,shieber@deas.harvard.edu, brants@parc.xerox.comAbstractThe LinGO Redwoods initiative is a seed activity in the de-sign and development of a new type of treebank.
While sev-eral medium- to large-scale treebanks exist for English (andfor other major languages), pre-existing publicly available re-sources exhibit the following limitations: (i) annotation ismono-stratal, either encoding topological (phrase structure) ortectogrammatical (dependency) information, (ii) the depth oflinguistic information recorded is comparatively shallow, (iii)the design and format of linguistic representation in the tree-bank hard-wires a small, predefined range of ways in whichinformation can be extracted from the treebank, and (iv) rep-resentations in existing treebanks are static and over the (oftenyear- or decade-long) evolution of a large-scale treebank tendto fall behind the development of the field.
LinGO Redwoodsaims at the development of a novel treebanking methodology,rich in nature and dynamic both in the ways linguistic data canbe retrieved from the treebank in varying granularity and in theconstant evolution and regular updating of the treebank itself.Since October 2001, the project is working to build the foun-dations for this new type of treebank, to develop a basic set oftools for treebank construction and maintenance, and to con-struct an initial set of 10,000 annotated trees to be distributedtogether with the tools under an open-source license.1 Why Another (Type of) Treebank?For the past decade or more, symbolic, linguistically ori-ented methods and statistical or machine learning ap-proaches to NLP have often been perceived as incompat-ible or even competing paradigms.
While shallow andprobabilistic processing techniques have produced use-ful results in many classes of applications, they have notmet the full range of needs for NLP, particularly whereprecise interpretation is important, or where the varietyof linguistic expression is large relative to the amountof training data available.
On the other hand, deepapproaches to NLP have only recently achieved broadenough grammatical coverage and sufficient processingefficiency to allow the use of precise linguistic grammarsin certain types of real-world applications.In particular, applications of broad-coverage analyti-cal grammars for parsing or generation require the use ofsophisticated statistical techniques for resolving ambigu-ities; the transfer of Head-Driven Phrase Structure Gram-mar (HPSG) systems into industry, for example, has am-plified the need for general parse ranking, disambigua-tion, and robust recovery techniques.
We observe generalconsensus on the necessity for bridging activities, com-bining symbolic and stochastic approaches to NLP.
Butalthough we find promising research in stochastic pars-ing in a number of frameworks, there is a lack of appro-priately rich and dynamic language corpora for HPSG.Likewise, stochastic parsing has so far been focussed oninformation-extraction-type applications and lacks anydepth of semantic interpretation.
The Redwoods initia-tive is designed to fill in this gap.In the next section, we present some of the motivationfor the LinGO Redwoods project as a treebank develop-ment process.
Although construction of the treebank isin its early stages, we present in Section 3 some prelim-inary results of using the treebank data already acquiredon concrete applications.
We show, for instance, thateven simple statistical models of parse ranking trainedon the Redwoods corpus built so far can disambiguateparses with close to 80% accuracy.2 A Rich and Dynamic TreebankThe Redwoods treebank is based on open-source HPSGresources developed by a broad consortium of re-search groups including researchers at Stanford (USA),Saarbru?cken (Germany), Cambridge, Edinburgh, andSussex (UK), and Tokyo (Japan).
Their wide distributionand common acceptance make the HPSG framework andresources an excellent anchor point for the Redwoodstreebanking initiative.The key innovative aspect of the Redwoods ap-proach to treebanking is the anchoring of all linguis-tic data captured in the treebank to the HPSG frame-work and a generally-available broad-coverage gram-mar of English, the LinGO English Resource Grammar(Flickinger, 2000) as implemented with the LKB gram-mar development environment (Copestake, 2002).
Un-like existing treebanks, there is no need to define a (new)form of grammatical representation specific to the tree-bank.
Instead, the treebank records complete syntacto-semantic analyses as defined by the LinGO ERG and pro-vide tools to extract different types of linguistic informa-tion at varying granularity.The treebanking environment, building on the [incrtsdb()] profiling environment (Oepen & Callmeier,2000), presents annotators, one sentence at a time, withthe full set of analyses produced by the grammar.
Usinga pre-existing tree comparison tool in the LKB (similarin kind to the SRI Cambridge TreeBanker; Carter, 1997),annotators can quickly navigate through the parse for-est and identify the correct or preferred analysis in thecurrent context (or, in rare cases, reject all analyses pro-posed by the grammar).
The tree selection tool presentsusers, who need little expert knowledge of the underly-ing grammar, with a range of basic properties that distin-guish competing analyses and that are relatively easy tojudge.
All disambiguating decisions made by annotatorsare recorded in the [incr tsdb()] database and thus becomeavailable for (i) later dynamic extraction from the anno-tated profile or (ii) dynamic propagation into a more re-cent profile obtained from re-running a newer version ofthe grammar on the same corpus.Important innovative research aspects in this approachto treebanking are (i) enabling users of the treebank toextract information of the type they need and to trans-form the available representation into a form suited totheir needs and (ii) the ability to update the treebank withan enhanced version of the grammar in an automatedfashion, viz.
by re-applying the disambiguating decisionson the corpus with an updated version of the grammar.Depth of Representation and Transformation of In-formation Internally, the [incr tsdb()] database recordsanalyses in three different formats, viz.
(i) as a deriva-tion tree composed of identifiers of lexical items and con-structions used to build the analysis, (ii) as a traditionalphrase structure tree labeled with an inventory of somefifty atomic labels (of the type ?S?, ?NP?, ?VP?
et al), and(iii) as an underspecified MRS (Copestake, Lascarides,& Flickinger, 2001) meaning representation.
While rep-resentation (ii) will in many cases be similar to the rep-resentation found in the Penn Treebank, representation(iii) subsumes the functor ?
argument (or tectogrammati-cal) structure advocated in the Prague Dependency Tree-bank or the German TiGer corpus.
Most importantly,however, representation (i) provides all the informationrequired to replay the full HPSG analysis (using the orig-inal grammar and one of the open-source HPSG process-ing environments, e.g., the LKB or PET, which alreadyhave been interfaced to [incr tsdb()]).
Using the latter ap-proach, users of the treebank are enabled to extract infor-mation in whatever representation they require, simplyby reconstructing full analyses and adapting the exist-ing mappings (e.g., the inventory of node labels used forphrase structure trees) to their needs.
Likewise, the ex-isting [incr tsdb()] facilities for comparing across compe-tence and performance profiles can be deployed to evalu-ate results of a (stochastic) parse disambiguation system,essentially using the preferences recorded in the treebankas a ?gold standard?
target for comparison.Automating Treebank Construction Although a pre-cise HPSG grammar like the LinGO ERG will typicallyassign a small number of analyses to a given sentence,choosing among a few or sometimes a few dozen read-ings is time-consuming and error-prone.
The project isexploring two approaches to automating the disambigua-tion task, (i) seeding lexical selection from a part-of-speech (POS) tagger and (ii) automated inter-annotatorcomparison and assisted resolution of conflicts.Treebank Maintenance and Evolution One of thechallenging research aspects of the Redwoods initiativeis about developing a methodology for automated up-dates of the treebank to reflect the continuous evolutionof the underlying linguistic framework and of the LinGOgrammar.
Again building on the notion of elementarylinguistic discriminators, we expect to explore the semi-automatic propagation of recorded disambiguating deci-sions into newer versions of the parsed corpus.
Whileit can be assumed that the basic phrase structure inven-tory and granularity of lexical distinctions have stabilizedto a certain degree, it is not guaranteed that one set ofdiscriminators will always fully disambiguate a more re-cent set of analyses for the same utterance (as the gram-mar may introduce new ambiguity), nor that re-playinga history of disambiguating decisions will necessarilyidentify the correct, preferred analysis for all sentences.A better understanding of the nature of discriminatorsand relations holding among them is expected to providethe foundations for an update procedure that, ultimately,should be mostly automated, with minimal manual in-spection, and which can become part of the regular re-gression test cycle for the grammar.Scope and Current State of Seeding Initiative Thefirst 10,000 trees to be hand-annotated as part of thekick-off initiative are taken from a domain for which theEnglish Resource Grammar is known to exhibit broadand accurate coverage, viz.
transcribed face-to-face dia-logues in an appointment scheduling and travel arrange-ment domain.1 For the follow-up phase of the project, itis expected to move into a second domain and text genre,presumably more formal, edited text taken from newspa-per text or another widely available on-line source.
Asof June 2002, the seeding initiative is well underway.The integrated treebanking environment, combining [incrtsdb()] and the LKB tree selection tool, has been estab-lished and has been deployed in a first iteration of anno-tating the VerbMobil utterances.
The approach to parseselection through minimal discriminators turned out tobe not hard to learn for a second-year Stanford under-graduate in linguistics, and allowed completion of thefirst iteration in less than ten weeks.
Table 1 summarizesthe current Redwoods status.1Corpora of some 50,000 such utterances are readily available fromthe VerbMobil project (Wahlster, 2000) and have already been studiedextensively among researchers world-wide.2Of the four data sets only VM32 has been double-checked byan expert grammarian and (almost) completely disambiguated to date;therefore it exhibits an interestingly higher degree of phrasal ambiguityin the ?active = 1?
subset.total active = 0 active = 1 active > 1 unannotatedcorpus ] ?
? ]
?
? ]
?
? ]
?
? ]
?
?VM6 2422 7?7 4?2 32?9 218 8?0 4?4 9?7 1910 7?0 4?0 7?5 80 10?0 4?8 23?8 214 14?9 4?3 287?5VM13 1984 8?5 4?0 37?9 175 8?5 4?1 9?9 1491 7?2 3?9 7?5 85 9?9 4?5 22?1 233 14?1 4?2 22?1VM31 1726 6?2 4?5 22?4 164 7?9 4?6 8?0 1360 6?6 4?5 5?9 61 10?1 4?2 14?5 141 13?5 4?7 201?5VM32 608 7?4 4?3 25?6 51 10?7 4?3 54?4 551 7?9 4?4 19?0 5 12?2 3?9 27?2 1 21?0 6?1 2220?0Table 1: Redwoods development status as of June 2002: four sets of transcribed and hand-segmented VerbMobil dialogues havebeen annotated.
The columns are, from left to right, the total number of sentences (excluding fragments) for which the LinGOgrammar has at least one analysis (?]?
), average length (???
), lexical and structural ambiguity (?
?
and ??
?, respectively), followedby the last four metrics broken down for the following subsets: sentences (i) for which the annotator rejected all analyses (no activetrees), (ii) where annotation resulted in exactly one preferred analysis (one active tree), (iii) those where full disambiguation wasnot accomplished through the first round of annotation (more than one active tree), and (iv) massively ambiguous sentences thathave yet to be annotated.23 Early Experimental ResultsDevelopment of the treebank has just started.
Nonethe-less, we have performed some preliminary experimentson concrete applications to motivate the utility of the re-source being developed.
In this section, we describe ex-periments using the Redwoods treebank to build and testsystems for parse disambiguation.
As a component, webuild a tagger for the HPSG lexical tags in the treebank,and report results on this application as well.Any linguistic system that allows multiple parsesof strings must address the problem of selecting fromamong the admitted parses the preferred one.
A varietyof approaches for building statistical models of parse se-lection are possible.
At the simplest end, we might lookonly at the lexical type sequence assigned to the wordsby each parse and rank the parse based on the likelihoodof that sequence.
These lexical types ?
the preterminalsin the derivation ?
are essentially part-of-speech tags, butencode considerably finer-grained information about thewords.
Well-understood statistical part-of-speech tag-ging technology is sufficient for this approach.In order to use more information about the parse,we might examine the entire derivation of the string.Most probabilistic parsing research ?
including, for ex-ample, work by by Collins (1997), and Charniak (1997)?
is based on branching process models (Harris, 1963).The HPSG derivations that the treebank makes availablecan be viewed as just such a branching process, anda stochastic model of the trees can be built as a prob-abilistic context-free grammar (PCFG) model.
Abney(1997) notes important problems with the soundness ofthe approach when a unification-based grammar is ac-tually determining the derivations, motivating the useof log-linear models (Agresti, 1990) for parse rankingthat Johnson and colleagues further developed (Johnson,Geman, Canon, Chi, & Riezler, 1999).
These modelscan deal with the many interacting dependencies andthe structural complexity found in constraint-based orunification-based theories of syntax.Nevertheless, the naive PCFG approach has the advan-tage of simplicity, so we pursue it and the tagging ap-proach to parse ranking in these proof-of-concept exper-iments (more recently, we have begun work on buildinglog-linear models over HPSG signs (Toutanova & Man-ning, 2002)).
The learned models were used to rankpossible parses of unseen test sentences according to theprobabilities they assign to them.
We report parse se-lection performance as percentage of test sentences forwhich the correct parse was highest ranked by the model.
(We restrict attention in the test corpus to sentences thatare ambiguous according to the grammar, that is, forwhich the parse selection task is nontrivial.)
We examinefour models: an HMM tagging model, a simple PCFG, aPCFG with grandparent annotation, and a hybrid modelthat combines predictions from the PCFG and the tagger.These models will be described in more detail presently.The tagger that we have implemented is a standard tri-gram HMM tagger, defining a joint probability distribu-tion over the preterminal sequences and yields of thesetrees.
Trigram probabilities are smoothed by linear in-terpolation with lower-order models.
For comparison,we present the performance of a unigram tagger and anupper-bound oracle tagger that knows the true tag se-quence and scores highest the parses that have the correctpreterminal sequence.The PCFG models define probability distributionsover the trees of derivational types corresponding to theHPSG analyses of sentences.
A PCFG model has parame-ters ?i, j for each rule Ai ?
?
j in the corresponding con-text free grammar.3 In our application, the nonterminalsin the PCFG Ai are rules of the HPSG grammar used tobuild the parses (such as HEAD-COMPL or HEAD-ADJ).We set the parameters to maximize the likelihood of theset of derivation trees for the preferred parses of the sen-tences in a training set.
As noted above, estimating prob-abilities from local tree counts in the treebank does notprovide a maximum likelihood estimate of the observeddata, as the grammar rules further constrain the possiblederivations.
Essentially, we are making an assumption ofcontext-freeness of rule application that does not hold inthe case of the HPSG grammar.
Nonetheless, we can stillbuild the model and use it to rank parses.3For an introduction to PCFG grammars see, for example, Manning& Schu?tze (1999).As previously noted by other researchers (Charniak &Caroll, 1994), extending a PCFG with grandparent an-notation improves the accuracy of the model.
We imple-mented an extended PCFG that conditions each node?sexpansion on its parent in the phrase structure tree.
Theextended PCFG (henceforth PCFG-GP) has parametersP(Ak Ai ?
?
j |Ak, Ai) .
The resulting grammar can beviewed as a PCFG whose nonterminals are pairs of thenonterminals of the original PCFG.The combined model scores possible parses usingprobabilities from the PCFG-GP model together with theprobability of the preterminal sequence of the parse treeaccording to a trigram tag sequence model.
More specif-ically, for a tree T ,Score(t) = log(PPCFG-GP(T )) + ?
log(PTRIG(tags(T ))where PTRIG(tags(T )) is the probability of the sequenceof preterminals t1 ?
?
?
tn in T according to a trigram tagmodel:PTRIG(t1 ?
?
?
tn) =?ni=1P(ti |ti?1, ti?2)with appropriate treatment of boundaries.
The trigramprobabilities are smoothed as for the HMM tagger.
Thecombined model is relatively insensitive to the relativeweights of the two component models, as specified by ?
;in any case, exact optimization of this parameter was notperformed.
We refer to this model as Combined.
TheCombined model is not a sound probabilistic model as itdoes not define a probability distribution over parse trees.It does however provide a crude way to combine ancestorand left context information.The second column in Table 2 shows the accuracyof parse selection using the models described above.For comparison, a baseline showing the expected perfor-mance of choosing parses randomly according to a uni-form distribution is included as the first row.
The accu-racy results are averaged over a ten-fold cross-validationon the data set summarized in Table 1.
The data we usedfor this experiment was the set of disambiguated sen-tences that have exactly one preferred parse (comprisinga total of 5312 sentences).
Often the stochastic modelswe are considering give the same score to several differ-ent parses.
When a model ranks a set of m parses highestwith equal scores and one of those parses is the preferredparse in the treebank, we compute the accuracy on thissentence as 1/m.Since our approach of defining the probability of anal-yses using derivation trees is different from the tradi-tional approach of learning PCFG grammars from phrasestructure trees, a comparison of the two is probably inorder.
We tested the model PCFG-GP defined over thecorresponding phrase structure trees and its average ac-curacy was 65.65% which is much lower than the accu-racy of the same model over derivation trees (71.73%).This result suggests that the information about grammarconstructions is very helpful for parse disambiguation.Method Tasktag sel.
parse sel.Random 90.13% 25.81%Tagger unigram 96.75% 44.15%trigram 97.87% 47.74%oracle 100.00% 54.59%PCFG simple 97.40% 66.26%grandparent 97.43% 71.73%combined 98.08% 74.03%Table 2: Performance of the HMM and PCFG models for thetag and parse selection tasks (accuracy).The results in Table 2 indicate that high disambigua-tion accuracy can be achieved using very simple statisti-cal models.
The performance of the perfect tagger showsthat, informally speaking, roughly half of the informationnecessary to disambiguate parses is available in the lexi-cal types alone.
About half of the remaining informationis recovered by our best method, Combined.An alternative (more primitive) task is the tagging taskitself.
It is interesting to know how much the taggingtask can be improved by perfecting parse disambigua-tion.
With the availability of a parser, we can examine theaccuracy of the tag sequence of the highest scoring parse,rather than trying to tag the word sequence directly.
Werefer to this problem as the tag selection problem, byanalogy with the relation between the parsing problemand the parse selection problem.
The first column of Ta-ble 2 presents the performance of the models on the tagselection problem.
The results are averaged accuraciesover 10 cross-validation splits of the same corpus as theprevious experiment, and show that parse disambigua-tion using information beyond the lexical type sequenceslightly improves tag selection performance.
Note thatin these experiments, the models are used to rank the tagsequences of the possible parses and not to find the mostprobable tag sequence.
Therefore tagging accuracy re-sults are higher than they would be in the latter case.Since our corpus has relatively short sentences and lowambiguity it is interesting to see how much the perfor-mance degrades as we move to longer and more highlyambiguous sentences.
For this purpose, we report in Ta-ble 3 the parse ranking accuracy of the Combined modelas a function of the number of possible analyses for sen-tences.
Each row corresponds to a set of sentences withnumber of possible analyses greater or equal to the boundshown in the first column.
For example, the first row con-tains information for the sentences with ambiguity ?
2,which is all ambiguous sentences.
The columns show thetotal number of sentences in the set, the expected accu-racy of guessing at random, and the accuracy of the Com-bined model.
We can see that the parse ranking accuracyis decreasing quickly and more powerful models will beneeded to achieve good accuracy for highly ambiguoussentences.Despite several differences in corpus size and compo-Analyses Sentences Random Combined?
2 3824 25.81% 74.03%?
5 1789 9.66% 59.64%?
10 1027 5.33% 51.61%?
20 525 3.03% 45.33%Table 3: Parse ranking accuracy by number of possible parses.sition, it is perhaps nevertheless useful to compare thiswork with other work on parse selection for unification-based grammars.
Johnson et al (1999) estimate aStochastic Unification Based Grammar (SUBG) using alog-linear model.
The features they include in the modelare not limited to production rule features but also ad-junct and argument and other linguistically motivatedfeatures.
On a dataset of 540 sentences (total trainingand test set) from a Verbmobil corpus they report parsedisambiguation accuracy of 58.7% given a baseline accu-racy for choosing at random of 9.7%.
The random base-line is much lower than ours for the full data set, but it iscomparable for the random baseline for sentences withmore than 5 analyses.
The accuracy of our Combinedmodel for these sentences is 59.64%, so the accuraciesof the two models seem fairly similar.4 Related WorkTo the best of our knowledge, no prior research hasbeen conducted exploring the linguistic depth, flexibil-ity in available information, and dynamic nature of tree-banks that we have proposed.
Earlier work on buildingcorpora of hand-selected analyses relative to an exist-ing broad-coverage grammar was carried out at XeroxPARC, SRI Cambridge, and Microsoft Research.
As allthese resources are tuned to proprietary grammars andanalysis engines, the resulting treebanks are not publiclyavailable, nor have reported research results been repro-ducible.
Yet, especially in light of the successful LinGOopen-source repository, it seems vital that both the tree-bank and associated processing schemes and stochasticmodels be available to the general (academic) public.
Anon-going initiative at Rijksuniversiteit Groningen (NL) isdeveloping a treebank of dependency structures (Mullen,Malouf, & Noord, 2001), derived from an HPSG-likegrammar of Dutch (Bouma, Noord, & Malouf, 2001).The general approach resembles the Redwoods initiative(specifically the discriminator-based method of tree se-lection; the LKB tree comparison tool was originally de-veloped by Malouf, after all), but it provides only a sin-gle stratum of representation, and has no provision forevolving analyses in tandem with the grammar.
Dipper(2000) presents the application of a broad-coverage LFGgrammar for German to constructing tectogrammaticalstructures for the TiGer corpus.
The approach is similarto the Groningen framework, and shares its limitations.ReferencesAbney, S. P. (1997).
Stochastic attribute-value grammars.Computational Linguistics, 23, 597 ?
618.Agresti, A.
(1990).
Categorical data analysis.
John Wiley &Sons.Bouma, G., Noord, G. van, & Malouf, R. (2001).Alpino.
Wide-coverage computational analysis of Dutch.
InW.
Daelemans, K. Sima-an, J. Veenstra, & J. Zavrel (Eds.
),Computational linguistics in the Netherlands (pp.
45 ?
59).Amsterdam, The Netherlands: Rodopi.Carter, D. (1997).
The TreeBanker.
A tool for supervisedtraining of parsed corpora.
In Proceedings of the Workshopon Computational Environments for Grammar Developmentand Linguistic Engineering.
Madrid, Spain.Charniak, E. (1997).
Statistical parsing with a context-freegrammar and word statistics.
In Proceedings of the Four-teenth National Conference on Artificial Intelligence (pp.598 ?
603).
Providence, RI.Charniak, E., & Caroll, G. (1994).
Context-sensitive statisticsfor improved grammatical language models.
In Proceedingsof the Twelth National Conference on Artificial Intelligence(pp.
742 ?
747).
Seattle, WA.Collins, M. J.
(1997).
Three generative, lexicalised models forstatistical parsing.
In Proceedings of the 35th Meeting ofthe Association for Computational Linguistics and the 7thConference of the European Chapter of the ACL (pp.
16 ?23).
Madrid, Spain.Copestake, A.
(2002).
Implementing typed feature structuregrammars.
Stanford, CA: CSLI Publications.Copestake, A., Lascarides, A., & Flickinger, D. (2001).
Analgebra for semantic construction in constraint-based gram-mars.
In Proceedings of the 39th Meeting of the Associationfor Computational Linguistics.
Toulouse, France.Dipper, S. (2000).
Grammar-based corpus annotation.
InWorkshop on linguistically interpreted corpora LINC-2000(pp.
56 ?
64).
Luxembourg.Flickinger, D. (2000).
On building a more efficient grammarby exploiting types.
Natural Language Engineering, 6 (1)(Special Issue on Efficient Processing with HPSG), 15 ?
28.Harris, T. E. (1963).
The theory of branching processes.Berlin, Germany: Springer.Johnson, M., Geman, S., Canon, S., Chi, Z., & Riezler, S.(1999).
Estimators for stochastic ?unification-based?
gram-mars.
In Proceedings of the 37th Meeting of the Associa-tion for Computational Linguistics (pp.
535 ?
541).
CollegePark, MD.Manning, C. D., & Schu?tze, H. (1999).
Foundations of statis-tical Natural Language Processing.
Cambridge, MA: MITPress.Mullen, T., Malouf, R., & Noord, G. van.
(2001).
Statisticalparsing of Dutch using Maximum Entropy models with fea-ture merging.
In Proceedings of the Natural Language Pro-cessing Pacific Rim Symposium.
Tokyo, Japan.Oepen, S., & Callmeier, U.
(2000).
Measure for mea-sure: Parser cross-fertilization.
Towards increased compo-nent comparability and exchange.
In Proceedings of the 6thInternational Workshop on Parsing Technologies (pp.
183 ?194).
Trento, Italy.Toutanova, K., & Manning, C. D. (2002).
Feature selectionfor a rich HPSG grammar using decision trees.
In Proceed-ings of the sixth conference on natural language learning(CoNLL-2002).
Taipei.Wahlster, W.
(Ed.).
(2000).
Verbmobil.
Foundations of speech-to-speech translation.
Berlin, Germany: Springer.
