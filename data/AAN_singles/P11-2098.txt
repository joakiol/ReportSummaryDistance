Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 558?563,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsA Probabilistic Modeling Framework for Lexical EntailmentEyal ShnarchComputer Science DepartmentBar-Ilan UniversityRamat-Gan, Israelshey@cs.biu.ac.ilJacob GoldbergerSchool of EngineeringBar-Ilan UniversityRamat-Gan, Israelgoldbej@eng.biu.ac.ilIdo DaganComputer Science DepartmentBar-Ilan UniversityRamat-Gan, Israeldagan@cs.biu.ac.ilAbstractRecognizing entailment at the lexical level isan important and commonly-addressed com-ponent in textual inference.
Yet, this task hasbeen mostly approached by simplified heuris-tic methods.
This paper proposes an initialprobabilistic modeling framework for lexicalentailment, with suitable EM-based parame-ter estimation.
Our model considers promi-nent entailment factors, including differencesin lexical-resources reliability and the impactsof transitivity and multiple evidence.
Evalu-ations show that the proposed model outper-forms most prior systems while pointing at re-quired future improvements.1 Introduction and BackgroundTextual Entailment was proposed as a genericparadigm for applied semantic inference (Dagan etal., 2006).
This task requires deciding whether a tex-tual statement (termed the hypothesis-H) can be in-ferred (entailed) from another text (termed the text-T ).
Since it was first introduced, the six roundsof the Recognizing Textual Entailment (RTE) chal-lenges1, currently organized under NIST, have be-come a standard benchmark for entailment systems.These systems tackle their complex task at vari-ous levels of inference, including logical represen-tation (Tatu and Moldovan, 2007; MacCartney andManning, 2007), semantic analysis (Burchardt et al,2007) and syntactic parsing (Bar-Haim et al, 2008;Wang et al, 2009).
Inference at these levels usually1http://www.nist.gov/tac/2010/RTE/index.htmlrequires substantial processing and resources (e.g.parsing) aiming at high performance.Nevertheless, simple entailment methods, per-forming at the lexical level, provide strong baselineswhich most systems did not outperform (Mirkinet al, 2009; Majumdar and Bhattacharyya, 2010).Within complex systems, lexical entailment model-ing is an important component.
Finally, there arecases in which a full system cannot be used (e.g.lacking a parser for a targeted language) and onemust resort to the simpler lexical approach.While lexical entailment methods are widelyused, most of them apply ad hoc heuristics which donot rely on a principled underlying framework.
Typ-ically, such methods quantify the degree of lexicalcoverage of the hypothesis terms by the text?s terms.Coverage is determined either by a direct match ofidentical terms in T and H or by utilizing lexi-cal semantic resources, such as WordNet (Fellbaum,1998), that capture lexical entailment relations (de-noted here as entailment rules).
Common heuristicsfor quantifying the degree of coverage are setting athreshold on the percentage coverage of H?s terms(Majumdar and Bhattacharyya, 2010), counting ab-solute number of uncovered terms (Clark and Har-rison, 2010), or applying an Information Retrieval-style vector space similarity score (MacKinlay andBaldwin, 2009).
Other works (Corley and Mihal-cea, 2005; Zanzotto and Moschitti, 2006) have ap-plied a heuristic formula to estimate the similaritybetween text fragments based on a similarity func-tion between their terms.These heuristics do not capture several importantaspects of entailment, such as varying reliability of558entailment resources and the impact of rule chainingand multiple evidence on entailment likelihood.
Anadditional observation from these and other systemsis that their performance improves only moderatelywhen utilizing lexical resources2.We believe that the textual entailment field wouldbenefit from more principled models for various en-tailment phenomena.
Inspired by the earlier stepsin the evolution of Statistical Machine Translationmethods (such as the initial IBM models (Brown etal., 1993)), we formulate a concrete generative prob-abilistic modeling framework that captures the basicaspects of lexical entailment.
Parameter estimationis addressed by an EM-based approach, which en-ables estimating the hidden lexical-level entailmentparameters from entailment annotations which areavailable only at the sentence-level.While heuristic methods are limited in their abil-ity to wisely integrate indications for entailment,probabilistic methods have the advantage of be-ing extendable and enabling the utilization of well-founded probabilistic methods such as the EM algo-rithm.We compared the performance of several modelvariations to previously published results on RTEdata sets, as well as to our own implementationof typical lexical baselines.
Results show thatboth the probabilistic model and our percentage-coverage baseline perform favorably relative to priorart.
These results support the viability of the proba-bilistic framework while pointing at certain model-ing aspects that need to be improved.2 Probabilistic ModelUnder the lexical entailment scope, our modelinggoal is obtaining a probabilistic score for the like-lihood that all H?s terms are entailed by T. To thatend, we model prominent aspects of lexical entail-ment, which were mostly neglected by previous lex-ical methods: (1) distinguishing different reliabil-ity levels of lexical resources; (2) allowing transi-tive chains of rule applications and considering theirlength when estimating their validity; and (3) con-sidering multiple entailments when entailing a term.2See ablation tests reports in http://aclweb.org/aclwiki/ in-dex.php?title=RTE Knowledge Resources#Ablation Testschaint 1t?Resource 2t nh 1h ih mt jText:Hypothesis:...Resource 1......MATCHResource 1...Resource 3Figure 1: The generative process of entailing terms of a hy-pothesis from a text.
Edges represent entailment rules.
Thereare 3 evidences for the entailment of hi: a rule from Resource1,another one from Resource3 both suggesting that tj entails it,and a chain from t1 through an intermediate term t?.2.1 Model DescriptionFor T to entail H it is usually a necessary, but notsufficient, that every term h ?
H would be en-tailed by at least one term t ?
T (Glickman et al,2006).
Figure 1 describes the process of entailinghypothesis terms.
The trivial case is when identicalterms, possibly at the stem or lemma level, appearin T and H (a direct match as tn and hm in Fig-ure 1).
Alternatively, we can establish entailmentbased on knowledge of entailing lexical-semanticrelations, such as synonyms, hypernyms and mor-phological derivations, available in lexical resources(e.g the rule inference?
reasoning from WordNet).We denote by R(r) the resource which provided therule r.Since entailment is a transitive relation, rules maycompose transitive chains that connect a term t ?
Tto a term h ?
H through intermediate terms.
Forinstance, from the rules infer?
inference and infer-ence ?
reasoning we can deduce the rule infer ?reasoning (were inference is the intermediate termas t?
in Figure 1).Multiple chains may connect t to h (as for tj andhi in Figure 1) or connect several terms in T to h(as t1 and tj are indicating the entailment of hi inFigure 1), thus providing multiple evidence for h?sentailment.
It is reasonable to expect that if a term tindeed entails a term h, it is likely to find evidencesfor this relation in several resources.Taking a probabilistic perspective, we assume a559parameter ?R for each resource R, denoting its re-liability, i.e.
the prior probability that applying arule from R corresponds to a valid entailment in-stance.
Direct matches are considered as a special?resource?, called MATCH, for which ?MATCH is ex-pected to be close to 1.We now present our probabilistic model.
For atext term t ?
T to entail a hypothesis term h by achain c, denoted by tc??
h, the application of everyr ?
c must be valid.
Note that a rule r in a chain cconnects two terms (its left-hand-side and its right-hand-side, denoted lhs ?
rhs).
The lhs of the firstrule in c is t ?
T and the rhs of the last rule in it ish ?
H .
We denote the event of a valid rule applica-tion by lhsr??
rhs.
Since a-priori a rule r is validwith probability ?R(r), and assuming independenceof all r ?
c, we obtain Eq.
1 to specify the prob-ability of the event tc??
h. Next, let C(h) denotethe set of chains which suggest the entailment of h.The probability that T does not entail h at all (byany chain), specified in Eq.
2, is the probability thatall these chains are not valid.
Finally, the probabil-ity that T entails all of H , assuming independenceof H?s terms, is the probability that every h ?
H isentailed, as given in Eq.
3.
Notice that there couldbe a term h which is not covered by any availablerule chain.
Under this formulation, we assume thateach such h is covered by a single rule coming froma special ?resource?
called UNCOVERED (expecting?UNCOVERED to be relatively small).p(tc??
h) =?r?cp(lhsr??
rhs) =?r?c?R(r)(1)p(T 9 h) =?c?C(h)[1?
p(tc??
h)] (2)p(T ?
H) =?h?Hp(T ?
h) (3)As can be seen, our model indeed distinguishesvarying resource reliability, decreases entailmentprobability as rule chains grow and increases it whenentailment of a term is supported by multiple chains.The above treatment of uncovered terms in H ,as captured in Eq.
3, assumes that their entailmentprobability is independent of the rest of the hypoth-esis.
However, when the number of covered hypoth-esis terms increases the probability that the remain-ing terms are actually entailed by T increases too(even though we do not have supporting knowledgefor their entailment).
Thus, an alternative model isto group all uncovered terms together and estimatethe overall probability of their joint entailment as afunction of the lexical coverage of the hypothesis.We denote Hc as the subset of H?s terms which arecovered by some rule chain and Huc as the remain-ing uncovered part.
Eq.
3a then provides a refinedentailment model for H , in which the second termspecifies the probability that Huc is entailed giventhat Hc is validly entailed and the correspondinglengths:p(T?H) = [?h?Hcp(T?h)]?p(T?Huc | |Hc|,|H|)(3a)2.2 Parameter EstimationThe difficulty in estimating the ?R values is thatthese are term-level parameters while the RTE-training entailment annotation is given for thesentence-level.
Therefore, we use EM-based esti-mation for the hidden parameters (Dempster et al,1977).
In the E step we use the current ?R valuesto compute all whcr(T,H) values for each trainingpair.
whcr(T,H) stands for the posterior probabilitythat application of the rule r in the chain c for h ?
His valid, given that either T entails H or not accord-ing to the training annotation (see Eq.
4).
Rememberthat a rule r provides an entailment relation betweenits left-hand-side (lhs) and its right-hand-side (rhs).Therefore Eq.
4 uses the notation lhsr??
rhs to des-ignate the application of the rule r (similar to Eq.
1).E :whcr(T,H) =?????????????????p(lhsr??
rhs|T ?
H) =p(T?H|lhsr?
?rhs)p(lhs r?
?rhs)p(T?H)if T ?
Hp(lhsr??
rhs|T 9 H) =p(T9H|lhsr?
?rhs)p(lhs r?
?rhs)p(T9H)if T 9 H(4)After applying Bayes?
rule we get a fraction withEq.
3 in its denominator and ?R(r) as the second termof the numerator.
The first numerator term is definedas in Eq.
3 except that for the corresponding rule ap-plication we substitute ?R(r) by 1 (per the condition-ing event).
The probabilistic model defined by Eq.1-3 is a loop-free directed acyclic graphical model560(aka a Bayesian network).
Hence the E-step proba-bilities can be efficiently calculated using the beliefpropagation algorithm (Pearl, 1988).The M step uses Eq.
5 to update the parameter set.For each resourceR we average thewhcr(T,H) val-ues for all its rule applications in the training, whosetotal number is denoted nR.M : ?R =1nR?T,H?h?H?c?C(h)?r?c|R(r)=Rwhcr(T,H)(5)For Eq.
3a we need to estimate also p(T?Huc ||Hc|,|H|).
This is done directly via maximum likeli-hood estimation over the training set, by calculatingthe proportion of entailing examples within the setof all examples of a given hypothesis length (|H|)and a given number of covered terms (|Hc|).
As|Hc| we take the number of identical terms in T andH (exact match) since in almost all cases terms inH which have an exact match in T are indeed en-tailed.
We also tried initializing the EM algorithmwith these direct estimations but did not obtain per-formance improvements.3 Evaluations and ResultsThe 5th Recognizing Textual Entailment challenge(RTE-5) introduced a new search task (Bentivogliet al, 2009) which became the main task in RTE-6 (Bentivogli et al, 2010).
In this task participantsshould find all sentences that entail a given hypothe-sis in a given document cluster.
This task?s data setsreflect a natural distribution of entailments in a cor-pus and demonstrate a more realistic scenario thanthe previous RTE challenges.In our system, sentences are tokenized andstripped of stop words and terms are lemmatized andtagged for part-of-speech.
As lexical resources weuse WordNet (WN) (Fellbaum, 1998), taking as en-tailment rules synonyms, derivations, hyponyms andmeronyms of the first senses of T and H terms, andthe CatVar (Categorial Variation) database (Habashand Dorr, 2003).
We allow rule chains of length upto 4 in WordNet (WN4).We compare our model to two types of baselines:(1) RTE published results: the average of the bestruns of all systems, the best and second best per-forming lexical systems and the best full system ofeach challenge; (2) our implementation of lexicalcoverage model, tuning the percentage-of-coveragethreshold for entailment on the training set.
Thismodel uses the same configuration as our probabilis-tic model.
We also implemented an Information Re-trieval style baseline3 (both with and without lex-ical expansions), but given its poorer performancewe omit its results here.Table 1 presents the results.
We can see thatboth our implemented models (probabilistic andcoverage) outperform all RTE lexical baselines onboth data sets, apart from (Majumdar and Bhat-tacharyya, 2010) which incorporates additional lex-ical resources, a named entity recognizer and aco-reference system.
On RTE-5, the probabilis-tic model is comparable in performance to the bestfull system, while the coverage model achieves con-siderably better results.
We notice that our imple-mented models successfully utilize resources to in-crease performance, as opposed to typical smalleror less consistent improvements in prior works (seeSection 1).ModelF1%RTE-5 RTE-6RTEavg.
of all systems 30.5 33.82nd best lexical system 40.31 44.02best lexical system 44.43 47.64best full system 45.63 48.05coverageno resource 39.5 44.8+ WN 45.8 45.1+ CatVar 47.2 45.5+ WN + CatVar 48.5 44.7+ WN4 46.3 43.1probabilistic no resource 41.8 42.1+ WN 45.0 45.3+ CatVar 42.0 45.9+ WN + CatVar 42.8 45.5+ WN4 45.8 42.6Table 1: Evaluation results on RTE-5 and RTE-6.
RTE systemsare: (1)(MacKinlay and Baldwin, 2009), (2)(Clark and Harri-son, 2010), (3)(Mirkin et al, 2009)(2 submitted runs), (4)(Ma-jumdar and Bhattacharyya, 2010) and (5)(Jia et al, 2010).While the probabilistic and coverage models arecomparable on RTE-6 (with non-significant advan-tage for the former), on RTE-5 the latter performs3Utilizing Lucene search engine (http://lucene.apache.org)561better, suggesting that the probabilistic model needsto be further improved.
In particular, WN4 performsbetter than the single-step WN only on RTE-5, sug-gesting the need to improve the modeling of chain-ing.
The fluctuations over the data sets and impactsof resources suggest the need for further investiga-tion over additional data sets and resources.
As forthe coverage model, under our configuration it posesa bigger challenge for RTE systems than perviouslyreported baselines.
It is thus proposed as an easy toimplement baseline for future entailment research.4 Conclusions and Future WorkThis paper presented, for the first time, a principledand relatively rich probabilistic model for lexical en-tailment, amenable for estimation of hidden lexical-level parameters from standard sentence-level an-notations.
The positive results of the probabilisticmodel compared to prior art and its ability to exploitlexical resources indicate its future potential.
Yet,further investigation is needed.
For example, analyz-ing current model?s limitations, we observed that themultiplicative nature of eqs.
1 and 3 (reflecting inde-pendence assumptions) is too restrictive, resemblinga logical AND.
Accordingly we plan to explore re-laxing this strict conjunctive behavior through mod-els such as noisy-AND (Pearl, 1988).
We also in-tend to explore the contribution of our model, andparticularly its estimated parameter values, within acomplex system that integrates multiple levels of in-ference.AcknowledgmentsThis work was partially supported by the NEGEVConsortium of the Israeli Ministry of Industry,Trade and Labor (www.negev-initiative.org), thePASCAL-2 Network of Excellence of the EuropeanCommunity FP7-ICT-2007-1-216886, the FIRB-Israel research project N. RBIN045PXH and by theIsrael Science Foundation grant 1112/08.ReferencesRoy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo Green-tal, Shachar Mirkin, Eyal Shnarch, and Idan Szpektor.2008.
Efficient semantic deduction and approximatematching over compact parse forests.
In Proceedingsof Text Analysis Conference (TAC).Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, DaniloGiampiccolo, and Bernardo Magnini.
2009.
The fifthPASCAL recognizing textual entailment challenge.
InProceedings of Text Analysis Conference (TAC).Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa TrangDang, and Danilo Giampiccolo.
2010.
The sixthPASCAL recognizing textual entailment challenge.
InProceedings of Text Analysis Conference (TAC).Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Computational Linguistics, 19(2):263?311,June.Aljoscha Burchardt, Nils Reiter, Stefan Thater, andAnette Frank.
2007.
A semantic approach to textualentailment: System evaluation and task analysis.
InProceedings of the ACL-PASCAL Workshop on TextualEntailment and Paraphrasing.Peter Clark and Phil Harrison.
2010.
BLUE-Lite: aknowledge-based lexical entailment system for RTE6.In Proceedings of Text Analysis Conference (TAC).Courtney Corley and Rada Mihalcea.
2005.
Measur-ing the semantic similarity of texts.
In Proceedings ofthe ACLWorkshop on Empirical Modeling of SemanticEquivalence and Entailment.Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.
The PASCAL recognising textual entailmentchallenge.
In Lecture Notes in Computer Science, vol-ume 3944, pages 177?190.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via the EMalgorithm.
Journal of the royal statistical society, se-ries [B], 39(1):1?38.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database (Language, Speech, and Com-munication).
The MIT Press.Oren Glickman, Eyal Shnarch, and Ido Dagan.
2006.Lexical reference: a semantic matching subtask.
InProceedings of the Conference on Empirical Methodsin Natural Language Processing, pages 172?179.
As-sociation for Computational Linguistics.Nizar Habash and Bonnie Dorr.
2003.
A categorial vari-ation database for english.
In Proceedings of the NorthAmerican Association for Computational Linguistics.Houping Jia, Xiaojiang Huang, Tengfei Ma, XiaojunWan, and Jianguo Xiao.
2010.
PKUTM participa-tion at TAC 2010 RTE and summarization track.
InProceedings of Text Analysis Conference (TAC).Bill MacCartney and Christopher D. Manning.
2007.Natural logic for textual inference.
In Proceedingsof the ACL-PASCAL Workshop on Textual Entailmentand Paraphrasing.562Andrew MacKinlay and Timothy Baldwin.
2009.
Abaseline approach to the RTE5 search pilot.
In Pro-ceedings of Text Analysis Conference (TAC).Debarghya Majumdar and Pushpak Bhattacharyya.2010.
Lexical based text entailment system for maintask of RTE6.
In Proceedings of Text Analysis Confer-ence (TAC).Shachar Mirkin, Roy Bar-Haim, Jonathan Berant, IdoDagan, Eyal Shnarch, Asher Stern, and Idan Szpektor.2009.
Addressing discourse and document structure inthe RTE search task.
In Proceedings of Text AnalysisConference (TAC).Judea Pearl.
1988.
Probabilistic reasoning in intelli-gent systems: networks of plausible inference.
MorganKaufmann.Marta Tatu and Dan Moldovan.
2007.
COGEX at RTE3.
In Proceedings of the ACL-PASCAL Workshop onTextual Entailment and Paraphrasing.Rui Wang, Yi Zhang, and Guenter Neumann.
2009.
Ajoint syntactic-semantic representation for recognizingtextual relatedness.
In Proceedings of Text AnalysisConference (TAC).Fabio Massimo Zanzotto and Alessandro Moschitti.2006.
Automatic learning of textual entailments withcross-pair similarities.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the Association for Com-putational Linguistics.563
