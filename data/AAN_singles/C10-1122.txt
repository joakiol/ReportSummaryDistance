Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1083?1091,Beijing, August 2010Chinese CCGbank:extracting CCG derivations from the Penn Chinese TreebankDaniel Tse and James R. CurranSchool of Information TechnologiesUniversity of Sydney{dtse6695,james}@it.usyd.edu.auAbstractAutomated conversion has allowed the de-velopment of wide-coverage corpora for avariety of grammar formalisms without theexpense of manual annotation.
Analysingnew languages also tests formalisms, ex-posing their strengths and weaknesses.We present Chinese CCGbank, a 760,000word corpus annotated with CombinatoryCategorial Grammar (CCG) derivations, in-duced automatically from the Penn Chi-nese Treebank (PCTB).
We design parsimo-nious CCG analyses for a range of Chinesesyntactic constructions, and transform thePCTB trees to produce them.
Our processyields a corpus of 27,759 derivations, cov-ering 98.1% of the PCTB.1 IntroductionAn annotated corpus is typically used to developstatistical parsers for a given formalism and lan-guage.
An alternative to the enormous cost  ofhand-annotating a corpus for a specific formalismis to convert from an existing corpus.The Penn Treebank (PTB; Marcus et al, 1994)has been converted to HPSG (Miyao et al, 2004),LFG (Cahill  et al,  2002), LTAG (Xia, 1999), andCCG (Hockenmaier, 2003).
Dependency corpora,e.g.
the German Tiger corpus, have also been con-verted (Hockenmaier, 2006).
The Penn ChineseTreebank (PCTB; Xue et al, 2005) provides analy-ses for 770,000 words of Chinese.
Existing PCTBconversions have targeted TAG (Chen et al, 2005)and LFG (Burke and Lam, 2004; Guo et al, 2007).We present Chinese CCGbank, a Chinese cor-pus of CCG derivations automatically induced fromthe PCTB.
Combinatory Categorial Grammar (CCG;Steedman, 2000) is a lexicalised grammar formal-ism offering a unified account of local and non-local dependencies.
We harness the facilities ofCCG to provide analyses of Chinese syntax includ-ing topicalisation, pro-drop, zero copula, extrac-tion, and the?
ba- and?
bei-constructions.Pushing the boundaries of formalisms by sub-jecting them to unfamiliar syntax also tests theiruniversality claims.
The freer word order of Turk-ish (Hoffman, 1996) and the complex morphologyof Korean (Cha et al, 2002) led to the developmentof extensions to the CCG formalism.We present our analysis of Chinese syntax un-der CCG, and provide an algorithm, modelled af-ter Hockenmaier and Steedman (2007), to incre-mentally transform PCTB trees into CCG derivations.The algorithm assigns CCG categories which di-rectly encode head and subcategorisation informa-tion.
Instances of Chinese syntax demanding spe-cial analysis, such as extraction, pro-drop or topi-calisation, are pin-pointed and given elegant anal-yses which exploit the expressivity of CCG.Our conversion yields CCG analyses for 27,759PCTB trees (98.1%).
Coverage on lexical items,evaluated by 10-fold cross-validation, is 94.46%(by token) and 73.38% (by type).We present  the  first CCG analysis  of  Chinesesyntax and obtain a wide-coverage CCG corpus ofChinese.
Highly efficient statistical parsing usinga CCGbank has recently been demonstrated forEnglish (Clark and Curran, 2007).
Our ChineseCCGbank will enable the development of similarlyefficient wide-coverage CCG parsers for Chinese.2 Combinatory Categorial GrammarCCG (Steedman,  2000) is  a  lexicalised grammarformalism, with a transparent syntax-semantics in-terface, a flexible view of constituency enablingconcise accounts of various phenomena, and a con-sistent account of local/non-local dependencies.It consists of categories, which encode the typeand number of arguments taken by lexical items,and combinators, which govern the possible inter-actions between categories.1083?
?
??
?
??
?
?
?that MW movie I already see EXP SFP(N/N)/M M N NP (S\NP)/(S\NP) (S[dcl]\NP)/NP (S\NP)\(S\NP) S\S> <B?N/N (S[dcl]\NP)/NP>N>T >BNP S/(S\NP) (S[dcl]\NP)/NPTtop>BS/(S/NP) S[dcl]/NP>S[dcl]<S[dcl]Figure 1: Chinese CCG derivation: ?That movie, I?ve already seen.
?A CCG grammar defines atomic categories, e.g.NP and S, which may be recursively constructedinto complex categories, e.g.
N/N and S\NP.1Figure 1 shows how combinators govern the inter-action of categories for lexical items, while slashesspecify argument directionality.The combinators allow us to reduce lexical am-biguity, by preserving a word?s canonical categoryeven when displaced from its canonical position.This facility is a strength of CCG, but elevates itsgenerative power to mild context-sensitivity.Some combinators may be disabled in a givenlanguage ?
the multi-modal CCG (Baldridge, 2002)allows these distinctions to be lexically specified.Introducing non-CCG rules decrease categorialambiguity at the expense of deviating from the for-malism.
Hockenmaier and Steedman (2002) showthat these greatly improve lexical coverage.
Theiranalysis of English employs non-CCG rules to co-erce a verb phrase headed by a participle (categoryS[ng]\NP) to a post-nominal modifier:S[ng]\NP??
NP\NP (1)This frees verbs from having to possess a dis-tinct category in each position, thus trading off lex-ical ambiguity for derivational ambiguity.
Honni-bal and Curran (2009) extended CCG with hat cat-egories, enabling the lexical specification of theseunary type-change rules.Hockenmaier and Steedman (2002, 2007) de-veloped CCGbank, the first wide-coverage EnglishCCG corpus, by converting 1.2 million words fromthe Wall Street Journal section of the PTB.
CCG-bank has made possible the development of wide-coverage statistical parsers for CCG in English, no-tably C&C (Clark and Curran, 2007).1Abbreviations in this paper: The directionless slash |stands for one of {/,\}.
We also use the verbal category ab-breviations VP?
S\NP and TV?
(S\NP)/NP.3 Penn Chinese TreebankXue  et al  (2005)  developed  the  Penn  ChineseTreebank (PCTB), the first syntactically annotatedcorpus for Chinese.
The corpus includes newswiretext, magazine articles, and transcribed speech.2Xue et al  establishes several principles for amore disciplined and consistent style of annota-tion compared to the original PTB.
These princi-ples include complement/adjunct marking: allow-ing the recovery of predicate-argument structure;limited semantic role marking: the annotation ofmodifier phrases with semantic roles; covert ar-gument marking: the retention of traces of argu-ments deleted through pro-drop; and NP internalstructure: bracketing of NP structure where the in-tended interpretation is clear.The one  relation  per  bracketing principleunambiguously  encodes  a  grammatical  relation(chiefly, predication, adjunction, or complementa-tion) through the configuration of a node and itschildren.
Xue et al developed this principle to as-sist conversions from the PTB, e.g.
Hockenmaier(2003), in resolving argument/adjunct distinctions.PCTB derivations  are  pre-segmented, pre-tokenised, and POS tagged.
Owing to the dearthof  morphology in  Chinese, the  concept  of partof speech is more fluid than that of English ?
theword ??
bijiao ?compare?
might  be  glossedas a verb, adjective, adverb, or noun dependingon  its  context.
Noun/verb  mis-taggings  are  afrequent error case for PCFG parsing on PCTB data,compounded in Chinese by the lack of functionwords  and  morphology  (Levy  and  Manning,2003).
This ambiguity is better handled by theadaptive multitagging approach used by Clark andCurran (2007) for CCG supertagging, in which eachlexical item is tagged with a set of CCG categories.We present our CCG analysis of Chinese syntaxbelow, followed by our conversion algorithm.2We use the Penn Chinese Treebank 6.0 (LDC2007T36).10844 The syntax of Chinese4.1 Basic clause structureChinese is typologically SVO, with some OV el-ements  (relative  clauses, adjunct  PPs  and nounmodifiers precede their heads).
Numbers and de-terminers may not modify nouns directly; a mea-sure word must intervene.The  category  structure  of  the  grammar  maybe inferred directly from headedness information.Heads subcategorise for the type, number and di-rectionality of their arguments, while adjuncts re-ceive modifier categories of the form X | X.
(2) ?INP?at(VP/VP)/NP??supermarketNP?buyVP/NP?PERFVP\VP?one(N/N)/M?box:MWM?
?eggsNI bought a box of eggs at the supermarket.4.2 TopicalisationIn topic-prominent languages, the topic refers toinformation which the speaker assumes is knownby the listener.
In Mandarin, topicalisation mani-fests as left-dislocation of the topic phrase (Li andThompson, 1989).
We distinguish gap and non-gap topicalisation depending on whether the topicis co-referent with a gap in the sentence.3For gapped topicalisation (cf.
Figure 1), weadopt the Steedman (1987) topicalisation analysis:T ?
S/(S/T ) for parametrically licensed T (3)For non-gap topicalisation (Example 5), we usea variation of the analysis described in Hocken-maier and Steedman (2005), which treats the topi-calised constituent as a sentential modifier.
Underthis analysis, the determiner in a topicalisedNP re-ceives (S/S)/N instead of its canonical categoryNP/N.
Instead, we propose a unary rule:T ?
S/S for topicalisation candidate T (4)This delays the coercion to sentential modifier type(i.e.
NP?
S/S) until after the NP has been con-solidated, allowing the words under the topicalisedNP to preserve their canonical categories.3Non-gap topicalisation is also known as the double sub-ject construction (Li and Thompson, 1989).
(5) (As for) trade, it has developed rapidly.??
??
?
?trade development very fastNP NP VP/VP VPT >T >S/S S/(S\NP) S\NP>S>STopicalisation  is  far  less  marked  in  Chinesethan in English, and the structure of topicalisedconstituents  is  potentially  quite  complex.
Theadditional  categorial  ambiguity  in  Hockenmaierand Steedman (2005) compounds the data sparsityproblem, leading us to prefer the unary rule.4.3 Pro-dropSince Chinese exhibits radical pro-drop (Neele-man and Szendro?i, 2007), in which the viability ofthe pro-drop is not conditioned on the verb, the cat-egorial ambiguity resulting from providing an ad-ditional argument-dropped category for every verbis prohibitive.Rather than engendering sparsity on verbal cate-gories, we prefer derivational ambiguity by choos-ing the unary rule analysis S[dcl] | NP?
S[dcl] tocapture Chinese pro-drop.4.4 Zero copulaAlthough the Chinese copula ?
shi is obligatorywhen equating NPs, it may be omitted when equat-ing an NP and a QP or PP (Tiee and Lance, 1986).4(6) ?NP3SG??VP/VPthis-year??
(S\NP)/M18?Myears-oldShe is 18 this year.A solution  involving  a  binary  ruleNP QP?
S[dcl] is  not  properly  headed, andthus  violates  the  Principle  of  Lexical  HeadGovernment  (Steedman,  2000).
Conversely, asolution  where, for  example, ??
?18?
wouldhave to receive the category (S[dcl]\NP)/M in-stead of its canonical category QP/M would leadto  both  data  sparsity  and  over-generation, withVP modifiers  becoming able  to  modify  the  QPdirectly.
Tentatively, we ignore the data sparsityconsequences, and  have ??
?18?
receive  thecategory (S[dcl]\NP)/M in this context.4The copula is ungrammatical in predication on an adjec-tival verb, such as??
?happy?.
However, we analyse suchwords as verbs proper, with category S[dcl]\NP.10854.5 ?
ba- and?
bei-constructions?
bei and?
ba introduce a family of passive-likeconstructions in Chinese.
Although superficiallysimilar, the resulting constructions exhibit distinctsyntax, as our CCG analysis reflects and clarifies.In the?
bei-construction, the patient argumentof a verb moves to subject position, while the agenteither becomes the complement of a particle?
bei(the long passive), or disappears (the short pas-sive; Yip and Rimmington, 1997).
Although thetwo constructions are superficially similar (appar-ently differing only by the deletion of the agentNP), they behave differently in more complex con-texts (Huang et al, 2008).The long passive occurs with or without an ob-ject gap (deleted by identity with the subject ofthe matrix verb).
We analyse this construction byassigning ?
bei a category which permutes thesurface positions of the agent and patient.
Co-indexation  of  heads  allows  us  to  express  long-distance dependencies.Bei receives ((S\NPy)/((S\NPx)/NPy))/NPxin  the  gapped  case  (cf.
Example 7)  and((S\NP)/(S\NPx))/NPxin the non-gapped case.
(7) Zhangsan was beaten by Lisi.??
?
??
??Z.
BEI L. beat-PERFNP (VP/TV )/NPyNP TV>(S\NPx)/((S\NPy)/NPx)>S\NPx<SShort  passives also occur with or  without  anobject gap, receiving (S\NPx)/((S\NP)/NPx) inthe gapped case and (S\NP)\(S\NP) in the non-gapped case.
Our analysis agrees with Huang et al(2008)?s observation that short-bei is isomorphicto English tough-movement: our short-bei cate-gory is the same as Hockenmaier and Steedman(2005)?s category for English tough-adjectives.In the ?
ba construction, a direct object be-comes the complement of the morpheme ?
ba,and  gains  semantics  related  to  ?being  affected,dealt with, or disposed of?
(Huang et al, 2008).
Asfor?
bei, we distinguish two variants dependingon whether the object is deleted under coreferencewith the complement of ?
ba.Ba receives ((S\NPy)/((S\NPy)/NPx))/NPxin  the  gapped  case  (cf.
Example 8), and((S\NPy)/(S\NPy))/NP in the non-gapped case.As Levy and Manning (2003) suggest, we re-shape the PCTB analysis of the ba-construction soTag Headedness ExampleVSB head-final ??
??
?plan [then] build?VRD right-adjunction ?
?
?cook done?VCP head-initial ??
?
?confirm as?VCD appositive ??
??
?invest [&] build-factory?VNV special ?
?
?
?go [or] not go?VPT special ?
?
?
?leave able away?Table 1: Verb compounds in PCTBthat ba subcategorises for its NP and VP, ratherthan subcategorising for an IP sibling, which al-lows the NP to undergo extraction.
(8) The criminals were arrested by the police.??
?
??
??
?police BA criminal arrest-PERFNP (VP/TV )/NP NP TV>(S\NPy)/((S\NPy)/NPx)<S\NPy<S4.6 Verbal compoundingVerbs resulting from compounding strategies aretagged and internally bracketed.
Table 1 lists thetypes distinguished by the PCTB, and the headed-ness we assign to compounds of each type.Modifier-head compounds (PCTB tag VSB) ex-hibit clear head-final semantics, with the first verbV1 causally or temporally precedingV2.
Verb coor-dination compounds (VCD) project multiple heads,like ordinary lexical coordination.In a resultative compound (VRD), the result ordirection ofV1 is indicated byV2, which we treat asa post-verbal modifier.
The V-not-V construction(VNV) forms a yes/no question where V1 = V2.
Inthe V-bu/de-V or potential verb construction (VPT),a disyllabic verbV =V1V2 receives the infix?
deor?
bu with the meaning can/cannot V .
In boththese cases, it is the infixed particle?
de or?
buwhich collects its arguments on either side.4.7 ExtractionIn the Chinese relative clause construction, the par-ticle ?
de links a sentence with a subject or ob-ject gap with a NP to which that gap co-refers,in an analysis similar to the English constructiondescribed by Hockenmaier and Steedman (2005),mediated by the relative pronoun that.As in the English object extraction case, forwardtype-raising on the subject argument, and forwardcomposition into the verbal category allows us toobtain the correct object gap category S/NP.10864.8 Right node raisingTwo coordinated verbs may share one or more con-tiguous arguments under right node raising.
Thisanalysis follows directly from the CCG definition ofcoordination, requiring no new lexical categories.
(9) Scholars have formulated and are releasingthe documents.??
??
?
??
?
?scholar formulate and release documentNP VP/NP con j VP/NP NP????
(VP/NP)[con j]????
?VP/NP>S\NP<S4.9 AppositionApposition is the juxtaposition of two phrases re-ferring to the same entity.
Unlike noun modifica-tion, no clear modification relationship holds be-tween the two phrases.
The direct juxtapositionrules out Hockenmaier?s (2003) analysis where adelimiting comma mediates the apposition.
Chi-nese also allows full sentence/NP apposition:(10) (??(users??waste?)Swater)S?
?NPincidentNPincidents of users wasting waterThis gives rise to the Chinese apposition binaryrules NP NP?
NP and S[dcl] NP?
NP.5 The translation pipeline5.1 TaggingEach PCTB internal node structurally encodes a con-figuration, which lets us distinguish head-initialand head-final complementation from adjunctionand predication (Xue et al, 2000).The tagging mechanism annotates the PCTB tagof each internal node with a marker, which pre-serves this headedness information, even after thenodes are re-structured in the binarisation phase.Hockenmaier?s  (2003)  conversion  algorithmuses the Magerman (1994) head-finding heuristics,a potential source of noise.
Fortunately, the PCTBencodes gold standard headedness data.The  tagging  algorithm  is  straightforward: ifa  node  and  its  children  unify  with  one  of  theschemata below, then the markers (e.g.
:l or :n)are attached to its children.
The markers l and rindicate complements left, or right of the head h;adjuncts are marked with a.Head-initial, -final complementationXPZP:r .
.
.YP:rX:hXPX:hZP:l. .
.
YP:lAdjunction, predicationXPXP:hZP:a. .
.
YP:aIPYP:hXP-SBJ:lTopicalisation (gap and non-gap)IPYP:rXP-SBJ:lZP-TPC(-i):T(t)CoordinationXPXP:c{CC,PU})+(XP:c({CC,PU})Others identify nodes with special syntax, suchas topicalisation (t/T), apposition (A) or coordina-tion (c), for special treatment in following phases.NP internal structureTo speed annotation, NP internal structure is oftenleft underspecified in PCTB (Xue et al, 2005), as inthe Penn Treebank.
As a result, 68% of non-traceNPs in PCTB have only a flat bracketing.We assume that the internal structure of flat NPsis right-branching and head-final (Li and Thomp-son, 1989), following Hockenmaier and Steedman(2005), who assume this structure for English.
Are-analysis of PCTB, like Vadas and Curran (2007)for the PTB, could restore this structure, and allowour conversion algorithm to yield the correct CCGanalysis with no further modifications.To obtain this default analysis, each node underNP internal structure receives the marker n, exceptthe the final node, the head, which receives N.5.2 BinarisationCCG combinators take at most two categories, in-ducing binary derivation trees.
As such, PCTB treesmust be re-shaped to accommodate a CCG analysis.Our markers control the shape of the binarisedstructure: head-initial complementation yields aleft-branching tree, while head-final complemen-tation, adjunction, predication, coordination, andNP internal  structure  all  yield  right-branchingtrees.
Following Hockenmaier (2003), sentence-final punctuation is attached high.Although  the  distinction  between  word-leveltags (such as NN, VA) and phrasal tags (such as NP,VP, LCP) enables the configurational encoding ofgrammatical relations, it leaves a large number of1087VP ?
VV,VE,VA,VRD ADJP ?
JJADVP ?
AD, CS CLP ?
MLCP ?
LC DP ?
DT, ODLST ?
OD INTJ ?
IJFLR ?
any node PP ?
PFigure 2: Pruned unary projectionsunary projections.
While an intransitive verb (e.g.??
?sleep?)
would carry the verbal PCTB tag VV,and a transitive verb combined with its object (e.g.????
?ate dinner?)
is annotated as VP, underCCG?s freer concept of constituency, both receivethe category S\NP.Pruning the unary projections in Fig.
2 preventsspurious category labellings in the next phase.5.3 LabellingWe label each node of the binarised tree with CCGcategories, respecting the headedness informationencoded in the markers.Atomic categoriesThe chosen mapping from PCTB tags to categoriesdefines the atomic category set for the grammar.The richer representation in CCG categories permitssome constituents to be expressed using a smallerset of atoms (e.g.
an adjective is simply a nounmodifier ?
N/N).
Despite their critical importancein controlling the degree of under-/over-generationin the corpus, little guidance exists as to the selec-tion of atomic categories in a CCG grammar.
Weobserved the following principles:Modifier proliferation: when  two  classes  ofwords can be modified by the same class of modi-fiers, they should receive a single category;Over-generation: the atom set should not over-generalise to accept ungrammatical examples;Efficiency: the representation may be motivatedby the needs of applications such as parsers.Table 2 shows the eight atomic categories cho-sen for our corpus.
Two of these categories: LCP(localisers) andM (measure words) have variouslybeen argued to  be  special  sub-classes  of  nouns(Huang et al, 2008).
However, based on our over-generation criterion, we decided to represent theseas atomic categories.We  adopt  the  bare/non-bare  noun  distinctionfrom Hockenmaier and Steedman (2007) on pars-ing efficiency grounds.
Although they roughlycorrespond to English PPs, the distributional dif-ferences between PPs, LCPs and QPs justify theirLCP Localiser phrase PP Prepositional phraseM Measure word QP Quantifier phraseN Bare noun S SentenceNP Noun phrase conj Conjunction wordTable 2: Chinese CCGbank atomic category setinclusion as atoms in Chinese.
Future work intraining a wide-coverage parser on Chinese CCG-bank will evaluate the impact of these choices.Labelling algorithmWe developed a recursive algorithm which appliesone of  several  labelling functions  based on themarkers on a node and its children.The algorithm proceeds top-down and assignsa CCG category to every node.
The markers on anode?s children are matched against the schemaof Table 3, applying the categories of the match-ing schema to the children.
The algorithm is thencalled recursively on each child.
If the algorithmis called on an unlabelled node, the mapping fromPCTB tags is used to assign a CCG category.PredicationCC\LLLeft  absorp-tionCCpAdjunctionCCC/C:aRightabsorptionCpCRightadjunctionCC\C:aC CoordinationCC[conj]C:cHead-initialCRC/R:hPartialcoordinationC[conj]C:cconjHead-finalCC\L:hL AppositionNPNPXP:ATable 3: Category labelling schemataLeft-  and  right-absorption  are  non-CCG ruleswhich functionally ignore punctuation, assumingthat they project no dependencies and combine toyield the same category as their non-punctuationsibling (Hockenmaier and Steedman, 2007).
In theschema, p represents a PCTB punctuation POS tag.NPs  receive  a  head-final  bracketing  (by  ourright-branching assumption), respecting NP inter-nal structure where provided by PCTB:NN??
struct.N??
org.N/NN/N??
bankN/N??
China(N/N)/(N/N)10886 Post-processingA number of cases remain which are either notcovered by the general translation algorithm, orotherwise could be improved in a post-processingstep.
The primary disharmony at this stage is thepresence of traces, the  empty categories  whichthe PCTB annotation style uses to mark the canoni-cal position of extraposed or deleted constituents.19,781 PCTB derivations (69.9%) contain a trace.Since CCG aims  to  provide  a  transparent  inter-face between surface string syntax and semantics,traces are expressly disallowed (Steedman, 2000).Hence, we eliminate traces from the annotation, bydevising alternate analyses in terms of categoriesand combinatory rules.Subject/object extraction8966 PCTB derivations (31.7%) contain a subjectextraction, while 3237 (11.4%) contain an objectextraction.
Figure 3 shows the canonical represen-tation of subject extraction in the PCTB annotationstyle.
The PCTB annotation follows the X?analysisof the relative clause construction as described byWu (2004), which we transform into an equivalent,trace-free CCG analysis.NP (N)?
?NP documentCP (N/N)CP (N/N)?DECIP (S[dcl])VP (S[dcl]\NP)?
?NP market?
?VV std.izeNP-SBJ (NP)*T*-iWHNP-i*OP*Figure 3: ?the document which standardises themarket?First, the Spec trace, WHNP-i, coindexed withthe extracted argument(s), is deleted.
Next, theextracted argument(s) with matching indices aredeleted, and category structure is adjusted to gen-erate the correct gap category.Modifier categoriesUnder our analysis, aspect particles such as ?
le(perfective) and ?
guo (experiential) are verbalpost-modifiers, corresponding to right adjunctionin Table 3.
Accordingly, an aspect particle fol-lowing a transitive verb VP/NP will receive themodifier category (VP/NP)\(VP/NP).
Under thisanalysis, every verbal category gives rise to onepossible modifier category for each aspect particle,leading to detrimental categorial ambiguity.However, the  generalised  backward  crossedcomposition  combinator  (Steedman,  2000)  letsaspect  particles  retain  their  canonical  category(S\NP)\(S\NP) regardless of the arity of the verbthey modify.TransformationsThe PCTB annotation style posits traces to accountfor  gapping, control/raising, argument  sharing,pro-drop and topicalisation.
To effect the parsimo-nious CCG analyses of Section 4, structural trans-formations on the original PCTB trees are necessaryto accommodate the new analyses.We  developed  a tgrep-like  language  whichidentifies instances of Chinese constructions, suchas right node raising and pro-drop, whose PCTB an-notation posits traces.
The local trees are then re-shaped to accommodate trace-free CCG analyses.7 EvaluationThis  section  explores  the  coverage  characteris-tics  of  Chinese  CCGbank, in  comparison  withthe English and German CCGbanks generated byHockenmaier.
Our analysis follows Hockenmaier(2006) in establishing coverage as the metric re-flecting how well the target corpus has accountedfor constructions in the source corpus.7.1 Corpus coverageThe Chinese CCGbank conversion algorithm com-pletes  for  28,227  of  the  28,295  (99.76%) PCTBtrees.
Annotation noise, and rare but legitimatesyntax, such as ellipsis, account for the coveragelost in this phase.
Following Hockenmaier andSteedman (2005), we adjust the PCTB annotationonly for systematic tagging errors that lead to cat-egory mis-assignments, maintaining as far as pos-sible the PCTB bracketing.269  derivations  (0.95%)  contain  unresolvedtraces, resulting from annotation noise and rareconstructions (such as ellipsis) not currently han-dled by our translation algorithm.
In 468 (1.66%)derivations, residues of PCTB tags not eliminated bythe translation algorithm generate malformed cate-gories outside the allowed set (Table 2).
Excludingthese cases, our conversion algorithm results in acorpus of 27,759 (98.1%) valid derivations.7.2 Category setThe Chinese CCGbank category set is comparedagainst existing CCG corpora derived from similarautomatic corpus conversions, to determine how1089well we have generalised over syntactic phenom-ena in the source corpus.A total of 1197 categories appear in the finalcorpus, of which 329 occur at least ten times, and478 are attested only once.
By comparison, En-glish CCGbank, contains 1286 categories, 425 ofwhich occur at least ten times, and 440 only once,while German CCGbank has a category inventoryof 2506 categories, with 1018 attested only once.57.3 Lexicon coverageLexical  item coverage  establishes  the  extent  towhich data sparsity due to unseen words is prob-lematic in the source corpus, and hence in any cor-pus derived from it.
Hockenmaier and Steedman(2001) showed that formalisms with rich tagsets,such as CCG, are particularly sensitive to this spar-sity ?
while a lexical item may be attested in thetraining data, it may lack the necessary category.We divided the  27,759 valid  derivations  intoten contiguous sections, performing ten-fold cross-validation  to  determine  the  coverage  of  lexicalitems and CCG categories in the resulting corpus.Average coverage on lexical items is 73.38%,while average coverage on categories is 88.13%.94.46% of token types from the held-out set arefound in the training set.
These figures compare to86.7% lexical coverage (by type) and 92% (by to-ken) in German CCGbank (Hockenmaier, 2006).Although lexical coverage by token is comparableto the German corpus, we observe a marked differ-ence in coverage by type.To explain this, we examine the most frequentPOS tags among the missing tokens.
These are NN(common nouns; 16,552 tokens), NR (proper noun;8458), VV (verb; 6879), CD (numeral; 1814) and JJ(adjective; 1257).
The 100 most frequent missingtokens across the ten folds comprise 48 NR tokens,46 NR, 3 NT (temporal nouns), 2 JJ (adjectives) andone VA (verbal adjective).
Personal names are alsonot tokenised into surnames and forenames in thePCTB, increasing unseen NR tokens.The  missing VVs  (verbs)  include  1342 four-character compounds, fossilised idiomatic expres-sions which are considered atomic verbs in thePCTB annotation.
Another  source  of  verb  spar-sity stems from the PCTB analysis of verbal infix-ation.
Given a polysyllabic verb (e.g.
??
leave-away ?leave?
), we  can  add  the  adverbial  infix5All German verbs having at least two categories to ac-count for German verbal syntax contributes to the greater sizeof the category set (Hockenmaier, 2006).?
not to form a potential verb???
leave-not-away ?unable to leave?.
In the PCTB annotation,however, this results in lexical items for the twocleaved parts, even though?
leave can no longerstand alone as a verb in modern Chinese.
In thiscase, a morphologically decomposed representa-tion which does not split the lexical item could mit-igate against this sparsity.
Alternatively, candidateverbs for this construction could have the first verbfragment subcategorise for the second.8 ConclusionWe have developed the first analysis of Chinesewith Combinatory Categorial Grammar, craftingnovel CCG analyses for a range of constructions in-cluding topicalisation, pro-drop, zero copula, verbcompounding, and the  long-range dependenciesresulting from the?
ba- and?
bei-constructions.We have presented an elegant and economicalaccount of Chinese syntax that exploits the powerof CCG combinatory rules, supporting Steedman?sclaim to its language-independence.We have designed a conversion algorithm to ex-tract this analysis from an existing treebank, avoid-ing the massive cost of hand re-annotation, creat-ing a corpus of 27,759 CCG derivations, covering98.1% of the PCTB.
The corpus will be publicly re-leased, together with the converter, providing thetools to create CCGbanks in new languages.At release, Chinese CCGbank will include gold-standard head co-indexation data, as required forthe training and evaluation of head-driven depen-dency parsers.
Co-indexation analyses, like thoseprovided for the ?
ba- and ?
bei-constructions,will be extended to all categories.Future refinements which could be brought tobear  on  Chinese  CCGbank include  the  integra-tion of PropBank data into CCGbank (Honnibaland Curran, 2007; Boxwell and White, 2008) us-ing Chinese PropBank (Xue, 2008).
The hat cat-egories of Honnibal and Curran (2009) may bet-ter  handle  form/function  discrepancies  such  asthe Chinese zero copula construction, leading tocleaner, more general analyses.We  have  presented  a  wide-coverage  Chinesecorpus which exploits the strengths of CCG to anal-yse a range of challenging Chinese constructions.We are now ready to develop rich NLP tools, includ-ing efficient, wide-coverage CCG parsers, to ad-dress the ever-increasing volumes of Chinese textnow available.1090AcknowledgementsJames Curran was  supported  by Australian  Re-search Council (ARC) Discovery grant DP1097291and  the  Capital  Markets  Cooperative  ResearchCentre.ReferencesJason Baldridge.
2002.
Lexically Specified Derivational Con-trol in Combinatory Categorial Grammar.
Ph.D. thesis,University of Edinburgh.Stephen Boxwell and Michael White.
2008.
Projecting Prop-bank roles onto the CCGbank.
Proceedings of LREC 2008.Michael Burke and Olivia Lam.
2004.
Treebank-based ac-quisition of a Chinese lexical-functional grammar.
In Pro-ceedings of the 18th Pacific Asia Conference on Language,Information and Computation, pages 161?172.Aoife Cahill, Mairead McCarthy, Josef van Genabith, andAndy  Way.
2002.
Automatic  annotation  of  the  PennTreebank with LFG F-structure information.
In LREC2002 Workshop on Linguistic Knowledge Acquisition andRepresentation-Bootstrapping Annotated Language Data,pages 8?15.Jeongwon Cha, Geunbae Lee, and Jonghyeok Lee.
2002.
Ko-rean combinatory categorial grammar and statistical pars-ing.
Computers and the Humanities, 36(4):431?453.John  Chen, Srinivas  Bangalore, and  K. Vijay-Shanker.2005.
Automated extraction of  Tree-Adjoining Gram-mars  from treebanks.
Natural  Language Engineering,12(03):251?299.Stephen Clark and James R. Curran.
2007.
Wide-CoverageEfficient  Statistical  Parsing  with  CCG and  Log-LinearModels.
In Computational Linguistics, volume 33, pages493?552.Yuqing Guo, Josef van Genabith, and Haifeng Wang.
2007.Treebank-based acquisition of LFG resources for Chinese.In Proceedings of LFG07 Conference, pages 214?232.Julia Hockenmaier.
2003.
Data and Models for StatisticalParsing with Combinatory Categorial Grammar.
Ph.D.thesis, University of Edinburgh.Julia Hockenmaier.
2006.
Creating a CCGbank and a wide-coverage CCG lexicon for German.
In Proceedings ofthe 21st International Conference on Computational Lin-guistics and the 44th annual meeting of the ACL, pages505?512.
Morristown, NJ, USA.Julia Hockenmaier and Mark Steedman.
2001.
Generativemodels for statistical  parsing with combinatory catego-rial grammar.
In ACL ?02: Proceedings of the 40th An-nual Meeting on Association for Computational Linguis-tics, pages 335?342.
Association for Computational Lin-guistics, Morristown, NJ, USA.Julia Hockenmaier and Mark Steedman.
2002.
Acquiringcompact lexicalized grammars from a cleaner treebank.
InProceedings of the Third International Conference on Lan-guage Resources and Evaluation, pages 1974?1981.Julia Hockenmaier and Mark Steedman.
2005.
CCGbank:Users?
manual.
Technical report, MS-CIS-05-09, Com-puter and Information Science, University of Pennsylva-nia.Julia Hockenmaier and Mark Steedman.
2007.
CCGbank: ACorpus of CCG Derivations and Dependency StructuresExtracted from the Penn Treebank.
Computational Lin-guistics, 33(3):355?396.Beryl Hoffman.
1996.
The computational analysis of the syn-tax and interpretation of free word order in Turkish.
Ph.D.thesis, University of Pennsylvania, Philadelphia, PA.Matthew Honnibal and James R. Curran.
2007.
Improvingthe complement/adjunct distinction in CCGbank.
In Pro-ceedings of the 10th Conference of the Pacific Associa-tion for Computational Linguistics (PACLING-07), pages210?217.Matthew Honnibal and James R. Curran.
2009.
Fully Lex-icalising CCGbank with Hat Categories.
In Proceedingsof the 2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 1212?1221.C.-T. James Huang, Y.-H. Audrey Li, and Yafei Li.
2008.
Thesyntax of Chinese.
Cambridge University Press.Roger Levy and Christopher Manning.
2003.
Is it harder toparse Chinese, or the Chinese Treebank?
In Annual Meet-ing of the Association for Computational Linguistics, vol-ume 1, pages 439?446.
Morristown, NJ, USA.Charles N. Li and Sandra A. Thompson.
1989.Mandarin Chi-nese: A functional reference grammar.
University of Cal-ifornia Press.David M. Magerman.
1994.
Natural language parsing as sta-tistical pattern recognition.
Ph.D. thesis, Stanford Univer-sity.Mitchell P.  Marcus, Beatrice  Santorini, and  Mary AnnMarcinkiewicz.
1994.
Building a Large Annotated Corpusof English: The Penn Treebank.
Computational Linguis-tics, 19(2):313?330.Yusuke Miyao, Takashi Ninomiya, and Jun?ichi Tsujii.
2004.Corpus-Oriented Grammar Development for Acquiring aHead-Driven Phrase Structure Grammar from the PennTreebank.
pages 684?693.Ad Neeleman and Kriszta Szendro?i.
2007.
Radical pro dropand  the  morphology  of  pronouns.
Linguistic  Inquiry,38(4):671?714.Mark Steedman.
1987.
Combinatory  grammars  and par-asitic  gaps.
Natural  Language  &  Linguistic  Theory,5(3):403?439.Mark Steedman.
2000.
The Syntactic Process.
MIT Press.Cambridge, MA, USA.Henry H.Y.
Tiee and Donald M. Lance.
1986.
A referencegrammar of Chinese sentences with exercises.
Universityof Arizona Press.David Vadas and James R. Curran.
2007.
Adding noun phrasestructure to the Penn Treebank.
In Association for Com-putational Linguistics, volume 45, page 240.Xiu-Zhi Zoe Wu.
2004.
Grammaticalization and languagechange in Chinese: A formal view.
Routledge.Fei  Xia.
1999.
Extracting tree adjoining grammars frombracketed corpora.
In Proceedings of Natural LanguageProcessing Pacific Rim Symposium ?99, pages 398?403.Nianwen Xue.
2008.
Labeling chinese predicates with seman-tic roles.
Computational Linguistics, 34(2):225?255.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer.2005.
The Penn Chinese TreeBank: Phrase structure an-notation of a large corpus.
Natural Language Engineering,11(02):207?238.Nianwen Xue, Fei Xia, Shizhe Huang, and Anthony Kroch.2000.
The Bracketing Guidelines for the Penn ChineseTreebank (3.0).
IRCS Report 00-08, University of Penn-sylvania.Po Ching Yip and Don Rimmington.
1997.
Chinese: An es-sential grammar.
Routledge.1091
