First Joint Conference on Lexical and Computational Semantics (*SEM), pages 275?281,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsUABCoRAL: A Preliminary study for Resolving the Scope of NegationBinod Gyawali, Thamar SolorioCoRAL LabDepartment of Computer and Information SciencesUniversity of Alabama at BirminghamBirmingham, Alabama, USA{bgyawali,solorio}@cis.uab.eduAbstractThis paper describes our participation in theclosed track of the *SEM 2012 Shared Taskof finding the scope of negation.
To performthe task, we propose a system that has threecomponents: negation cue detection, scope ofnegation detection, and negated event detec-tion.
In the first phase, the system creates alexicon of negation signals from the trainingdata and uses the lexicon to identify the nega-tion cues.
Then, it applies machine learningapproaches to detect the scope and negatedevent for each negation cue identified in thefirst phase.
Using a preliminary approach, oursystem achieves a reasonably good accuracyin identifying the scope of negation.1 IntroductionAll human language samples, either written or spo-ken, contain some information in negated form.
Intasks such as information retrieval, sometimes, weshould consider only the positive information of anevent and disregard its negation information, andvice versa.
For example, while searching for the pa-tients with diabetes, we should not include a patientwho has a clinical report saying No symptoms of di-abetes were observed.
Thus, finding the negationand its scope is important in tasks where the nega-tion and assertion information need to be treated dif-ferently.
However, most of the systems developedfor processing natural language data do not considernegations present in the sentences.
Although variousworks (Morante et al, 2008; Morante and Daele-mans, 2009; Li et al, 2010; Councill et al, 2010;Apostolova et al, 2011) have dealt with the identifi-cation of negations and their scope in sentences, thisis still a challenging task.The first task in *SEM 2012 SharedTask (Morante and Blanco, 2012) is concernedwith finding the scope of negation.
The taskincludes identifying: i) negation cues, ii) scope ofnegation, and iii) negated event for each negationpresent in the sentences.
Negation cue is a word,part of a word, or a combination of words thatcarries the negation information.
Scope of negationin a sentence is the longest group of words inthe sentence that is influenced by the negationcue.
Negated event is the shortest group of wordsthat is actually affected by the negation cue.
InExample (1) below, word no is a negation cue, thediscontinuous word sequences ?I gave him?
and?sign of my occupation?
are the scopes, and ?gave?is the negated event.
(1) I [gave] him no sign of my occupation.In this paper, we propose a system to detect thescope of negation for the closed track of *SEM 2012Shared Task.
Our system uses a combination ofa rule based approach, and a machine learning ap-proach.
We use a rule based approach to create alexicon of all the negation words present in the train-ing data.
Then we use this lexicon to detect thenegation cues present in the test data.
We do a pre-liminary analysis of finding the scope of negationand the negated events by applying a machine learn-ing approach, and using basic features created fromthe words, lemmas, and parts-of-speech (POS) tagsof words in the sentences.
The F-measure scores275achieved by our system are about 85% for negationcue detection, 65% in full scope identification, 48%in negated event detection, and 39% in identifyingfull negation.
Our error analysis shows that the useof lexicon is not very appropriate to detect the nega-tion cues.
We also describe the challenges in identi-fying the scope and the negated events.2 Problem DescriptionThe *SEM 2012 shared task competition providedthree data sets: training, development, and test dataset.
Each sentence in each data set is split intowords.
The dataset contains the information suchas lemma, part of speech, and other syntactic infor-mation of each word.
Each sentence of training anddevelopment data is annotated with negation cues,scopes and negated events.
Using the training andthe development data, the task is to identify negationcues, scopes and negated events in all unannotatedsentences of the test data.SentencetokensNegationcueScope NegatedeventI - I -am - am -not not - -sure - sure surewhether - whether -I - I -left - left -it - it -here - here -Table 1: An example of negation cue, scope and thenegated eventA sentence can contain more than one negationcue.
Negation cues in the data set can be i) a sin-gle word token such as n?t, nowhere, ii) a contin-uous sequence of two or more words, such as nomore, by no means or iii) two or more discontinu-ous words such as ..neither...nor... A negation cueis either a part or same as its corresponding nega-tion word.
This corresponding negation word is re-ferred as a negation signal in the remaining sectionsof the paper.
For example, for a negation signalunnecessary, the negation cue is un, and similarly,for a negation signal needless, the negation cue isless.Scope of a negation in a sentence can be a con-tinuous sequence of words or a discontinuous setof words in the sentence.
Scope of negation some-times includes the negation word.
A negation wordmay not have a negated event.
Presence of a negatedevent in a sentence depends upon the facts describedby the sentence.
Non-factual sentences such as in-terrogative, imperative, and conditional do not con-tain negated events.
Morante and Daelemans (2012)describe the details of the negation cue, scope, andnegated event, and the annotation guidelines.
An ex-ample of the task is shown in Table 1.3 System DescriptionWe decompose the system to identify the scope ofnegation into three tasks.
They are:1.
Finding the negation cue2.
Finding the scope of negation3.
Finding the negated eventThe scope detection and the negated event de-tection tasks are dependent on the task of findingthe negation cue.
But the scope detection and thenegated event detection tasks are independent ofeach other.We identify the negation cues present in the testdata based on a lexicon of negation signals thatare present in the training and the developmentdata.
The tasks of identifying scope of negation andnegated event are modeled as classification prob-lems.
To identify scope and negated event, we trainclassifiers with the instances created from the train-ing data provided.
We create test instances from thetest data annotated with negation cues predicted byour cue detection component.
Due to the use of testdata annotated by our cue detection component, thefalse negative rate in predicting the negation cues ispropagated to the scope detection as well as negatedevent detection components.
The details of all thethree components are described in the subsectionsbelow.3.1 Identifying the negation cueIn this task, we identify all the negation cues presentin the sentences.
We group the negation cues underthree types depending upon how they are present inthe data.
They are: single word cues, continuous276multiword cues, and discontinuous multiword cues.All the cues present in the training and developmentdatasets are shown in Table 2.Cue types CuesSingle wordcuesabsence, dis, except, fail, im, in, ir, less, n?t,neglected, neither, never, no, nobody, none,nor, not, nothing, nowhere, prevent, refused,save, un, withoutContinuousmultiwordcuesno more, rather than, by no means, nothingat all, on the contrary, not for the worldDiscontinuousmultiwordcuesneither nor, no nor, not notTable 2: Negation cues present in training and develop-ment dataIn the training and development data, multiwordnegation cues account for only 1.40% of the totalnegation cues.
At this stage, we decided to focuson identifying the single word negation cues.
Thesystem first creates a lexicon that contains the pairsof negation cues and their corresponding negationsignals for all the single word negation cues presentin the training and the development datasets.
In or-der to identify a negation cue in the test set, the sys-tem searches all the words in the sentences of thetest data that match the negation signals of the lexi-con.
For each word that matches, it assigns the cor-responding cue of the signal from the lexicon as itsnegation cue.3.2 Identifying the scope of negationWe apply a machine learning technique to identifythe scope of negation.
For each negation cue presentin a sentence, we create the problem instances as thetuple of the negation signal and each word presentin the same sentence.
To create the instances, weuse only those sentences having at least one nega-tion.
For training, we create instances from the train-ing data, but we consider only those words that arewithin a window of size 20 from the negation signaland within the sentence boundary.
We restricted thewords to be within the window in order to minimizethe problem of imbalanced data.
This window waschosen following our observation that only 1.26%of the scope tokens go beyond the 20 word win-dow from the negation signal.
Including the wordsbeyond this window causes a major increase in thenegative instances resulting in a highly imbalancedtraining set.
While creating test instances, we do notrestrict the words by window size.
This restriction isnot done in order to include all the words of the sen-tences in the test instances.
An instance is labeledas positive if the word used to create the instance isthe scope of the negation signal; else it is labeled asnegative.We extract 10 features to identify the scope ofnegation as follows:1.
Negation signal in the tuple2.
Lemma of the negation signal3.
POS tag of the negation signal4.
Word in the tuple5.
Lemma of the word in the tuple6.
POS tag of the word in the tuple7.
Distance between the negation signal and theword in terms of number of words8.
Position of the word from the negation signal(left, right)9.
Whether a punctuation character (?,?, ?:?,?;?)
ex-ists between the word and the negation signal10.
Sequence of POS tags in between the negationsignal and the wordAfter the classification, if an instance is predictedas positive, the word used to create the instance isconsidered as the scope of the negation signal.
If anegation signal has prefix such as ?dis?, ?un?, ?in?,?ir?, or ?im?, the scope of negation includes only thepart of word (signal) excluding the prefix.
Thus, foreach negation signal having these prefix, we removethe prefix from the signal and consider the remain-ing part of it as the scope, regardless of whether theclassifier classifies the instance pair as positive ornegative.2773.3 Identifying the negated eventThe task of identifying the negated event is simi-lar to the task of identifying the scope of negation.The process of creating the instances for this taskis almost the same to that of finding the scope ofnegation, except that, we limit the window size to4 words from the negation signal.
4.24% of thenegated events lie away from the 4 word window.Beyond this window, the events are very sparse anda small increment in the window size leads to abruptincrease in negative instances and creates an imbal-ance in the data.
The 4 word window size was se-lected based on the best result obtained among var-ious experiments performed with different windowsizes greater than and equal to 4.
The same ruleapplies while creating instances for training data aswell as test data.
We use only nine features in thisstep, excluding the 9th feature used in the scope de-tection.
We also apply the same rule of mapping thenegation signals starting with ?dis?, ?un?, ?in?, ?ir?,and ?im?
to the negated event as in the previous step.4 Experimental SettingsWe evaluated our system only on the test data of theshared task.
For the machine learning tasks, we usedthe SVM light classifier (Joachims, 1999) with 4thdegree polynomial kernel and other default param-eters.
The identification of cues, scopes, negatedevents, and full negation are evaluated on the basisof the F-measures.
We also use ?B?
variant for cues,scopes, negated events and the full negation for eval-uation.
The precision of ?B?
variant is calculated asthe ratio of true positives to the system count.
Iden-tification of cues and negated events are measuredindependent of any other steps.
But the identifica-tion of the scopes is measured depending upon thecorrect identification of cues in three different waysas follows:i) scopes (cue match): the cue has to be correctfor the scope to be correctii) scopes (no cue match): the system must iden-tify part of the cue for the scope to be correctiii) scope tokens (no cue match): a part of the sys-tem identified cue must overlap with the gold stan-dard cue for the scope tokens to be correctThe F1 score of the full negation detection wasused to rank the systems of the participants.
Thedetails about the evaluation measures can be foundin Morante and Blanco (2012).5 Results AnalysisThe results obtained by our system over the test dataare shown in Table 3.
The results obtained by eachcomponent, and their analysis are described in thesubsections below.5.1 Identifying the negation cuesThe system is able to achieve an 85.77% F1 score inthe task of identifying the negation cues using a sim-ple approach based on the lexicon of the negationsignals.
Because of the system?s inability to iden-tify multiword negation cues, it could not detect themultiword cues such as ..neither..nor.., ..absolutelynothing.., ..far from.., ..never more.., that account for3.5% of the total negation cues present in the testdata.The accuracy of the system is limited by the cov-erage of the lexicon.
Due to the low coverage of thelexicon, the system fails to identify signals such asceaseless, discoloured, incredulity, senseless,and unframed that are present only in the test data.These signals account for 4.5% of the total negationsignals present in the test data.
Some words suchas never, nothing, not, n?t, no, and without aremostly present as the negation signals in the data.But these words are not always the negation signals.The phrase no doubt is present nine times in the testdata, but the word no is a negation signal in onlyfour of them.
This accounts for 1.89% error in thenegation cue detection.
The word save is presentonce as a negation signal in the training data, but itis never a negation signal in the test data.
Therefore,our lexicon based system invariably predicts two oc-currences of save in the test data as negation signals.5.2 Identifying the scope of negationThe system achieves 63.46% F1 score in identifyingscopes with cue match, 64.76% F1 score in identify-ing scopes with no cue match, and 76.23% F1 scorein identifying scope tokens with no cue match.
Theresults show that our system has a higher precisionthan recall in identifying the scope.
As mentioned278gold system tp fp fn precision (%) recall (%) F1 (%)Cues 264 284 226 37 38 85.93 85.61 85.77Scopes (cue match) 249 239 132 35 117 79.04 53.01 63.46Scopes (no cue match) 249 239 132 35 113 79.53 54.62 64.76Scope tokens (no cue match) 1805 1456 1243 213 562 85.37 68.86 76.23Negated (no cue match) 173 104 65 35 104 65.00 38.46 48.33Full negation 264 284 73 37 191 66.36 27.65 39.04Cues B 264 284 226 37 38 79.58 85.61 82.48Scopes B (cue match) 249 239 132 35 117 55.23 53.01 54.10Scopes B (no cue match) 249 239 132 35 113 56.90 54.62 55.74Negated B (no cue match) 173 104 65 35 104 62.50 38.46 47.62Full negation B 264 284 73 37 191 25.70 27.65 26.64Total sentences: 1089Negation sentences: 235Negation sentences with errors: 172% Correct sentences: 81.73% Correct negation sentences: 26.81Table 3: Results of the systemearlier, the negation cues identified in the first taskare used to identify the scope of negation and thenegated events.
Using the test data with 15% errorin negation cues as the input to this component andsome of the wrong predictions of the scope by thiscomponent led to a low recall value in the scope de-tection.The results show that the system works well whena negation signal has fewer scope tokens and whenthe scope tokens are closer to the negation signal.There are some cases where the system could notidentify the scope tokens properly.
It is unable to de-tect the scope tokens that are farther in distance fromthe negation signals.
The system is not performingwell in predicting the discontinuous scopes.
Whena negation cue has discontinuous scope, mostly thesystem predicts one sequence of words correctly butcould not identify the next sequence.
In sentence(2) in the example below, the underlined word se-quences are the discontinuous scopes of the nega-tion cue not.
In the sentence, our system predictsonly the second sequence of scope, but not the firstsequence.
In some cases, our system does not have agood coverage of scope tokens.
In sentence (3), theunderlined word sequence is the scope of the signalno, but our system detects only at ninety was hard-ship as its scope.
These inabilities to detect the fullscope have led to have a higher accuracy in predict-ing the partial scope tokens (76.23%) than predictingthe full scope (64.76%).
(2) the box is a half pound box of honeydew to-bacco and does not help us in any way(3) ...a thermometer at ninety was no hardship(4) ...I cannot see anything save very vagueindicationsAnalyzing the results, we see that the error in pre-dicting the scope of the negation is high when thescope is distributed in two different phrases.
In theexample (2) above, does not help us in any way isa single verb phrase and all the scope within thephrase is correctly identified by our system.
Thebox being a separate phrase, it is unable to identifyit.
However, in some cases such as example (4), thesystem could not identify any scope tokens for nega-tion cue not.Some of the findings of previous works haveshown that the features related to syntactic path arehelpful in identifying the scope of negation.
Li etal.
(2010) used the syntactic path from the word tothe negation signal and showed that this helped toimprove the accuracy of scope detection.
Similarly,work by Councill et al (2010) showed that the ac-curacy of scope detection could be increased usingthe features from the dependency parse tree.
In ourexperiment, there was a good improvement in thescope detection rate when we included ?sequenceof POS tags?
between the negation signal and theword as a feature.
This improvement after includingthe sequence of POS tags feature and its consistency279with the previous works implies that adding path re-lated features might help to improve the accuracy inscope detection.5.3 Identifying the negated eventWe are able to achieve an F1 score of 48.33% in pre-dicting the negated events, which is the lowest scoreamong all three components.
As in the scope de-tection task, error in negation cue detection led tolower the recall rate of the negated event detectionsystem.
The accuracy of full negation is based onthe correct identification of the negation cues, scopeand the negated events of all the negations presentin the sentences.
The output shows that there aremany cases where negation cues and the scope arecorrectly identified but there is an error in identify-ing the negated events.
The higher error in predict-ing the negated events led to reduce the score of fullnegation and achieve an F1 score of 39.04%.Our system is unable to detect some negatedevents even though they are adjacent to the nega-tion signal.
This shows that the use of simple fea-tures extracted from words, lemmas, and POS tagsis not enough to predict the negated events properly.Adding features related to words in left and right ofthe negation signal and the path feature may help toimprove the detection of negated events.In order to analyze the impact of error in the nega-tion cue detection component upon the scope andnegated event detection components, we performedan experiment using the gold standard negation cuesto detect the scope and the negated events.
F1 scoresachieved by this system are 73.1% in full scope de-tection, 54.87% in negated event detection, 81.46%in scope tokens detection, and 49.57% in full nega-tion detection.
The result shows that there is al-most 10% increment in the F1 score in all the com-ponents.
Thus, having an improved cue detectioncomponent greatly helps to improve the accuracy ofscope and negated event detection components.6 Discussion and ConclusionIn this paper we outline a combination of a rulebased approach and a machine learning approach toidentify the negation cue, scope of negation, and thenegated event.
We show that applying a basic ap-proach of using a lexicon to predict the negation cuesachieves a considerable accuracy.
However, our sys-tem is unable to identify the negation cues such asnever, not, nothing, n?t, and save that can appearas a negation signal as well as in other non-negatedcontexts.
It also cannot cover the negation cues ofthe signals that are not present in the training data.Moreover, in order to improve the overall accuracyof the scope and negated event detection, we need anaccurate system to detect the negation cues since theerror in the negation cue detection propagates to thenext steps of identifying the scope and the negatedevent.
It is difficult to identify the scope of nega-tions that are farther in distance from the negationsignal.
Detecting the tokens of the scope that arediscontinuous is also challenging.As future work, we would like to extend our taskto use a machine learning approach instead of thelexicon of negation signals to better predict the nega-tion cues.
The system we presented here uses a pre-liminary approach without including any syntacticinformation to detect the scope and negated events.We would also incorporate syntactic information toidentify the scope and negated events in our futurework.
To improve the accuracy of identifying thescope and the negated events, adding other featuresrelated to the neighbor words of the negation signalmight be helpful.
In our tasks, we limit the scopeand negated event instances by the window size inorder to avoid imbalance data problem.
Another in-teresting work to achieve better accuracy could be touse other approaches of imbalanced dataset classifi-cation instead of limiting the training instances bythe window size.ReferencesEmilia Apostolova, Noriko Tomuro, and Dina Demner-Fushman.
2011.
Automatic extraction of lexico-syntactic patterns for detection of negation and spec-ulation scopes.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies: short papers -Volume 2, HLT ?11, pages 283?287, Stroudsburg, PA,USA.
Association for Computational Linguistics.Isaac G. Councill, Ryan McDonald, and Leonid Ve-likovich.
2010.
What?s great and what?s not: learn-ing to classify the scope of negation for improved sen-timent analysis.
In Proceedings of the Workshop onNegation and Speculation in Natural Language Pro-280cessing, NeSp-NLP ?10, pages 51?59, Stroudsburg,PA, USA.
Association for Computational Linguistics.Thorsten Joachims.
1999.
Making large-scale supportvector machine learning practical.
In Advances in ker-nel methods: support sector searning, pages 169?184.MIT Press, Cambridge, MA, USA.Junhui Li, Guodong Zhou, Hongling Wang, and Qiaom-ing Zhu.
2010.
Learning the scope of negation viashallow semantic parsing.
In Proceedings of the 23rdInternational Conference on Computational Linguis-tics, COLING ?10, pages 671?679, Stroudsburg, PA,USA.
Association for Computational Linguistics.Roser Morante and Eduardo Blanco.
2012.
*SEM 2012Shared Task: Resolving the Scope and Focus of Nega-tion.
In Proceedings of the First Joint Conference onLexical and Computational Semantics (*SEM 2012),Montreal, Canada.Roser Morante and Walter Daelemans.
2009.
A met-alearning approach to processing the scope of nega-tion.
In Proceedings of the Thirteenth Conference onComputational Natural Language Learning, CoNLL?09, pages 21?29, Stroudsburg, PA, USA.Roser Morante and Walter Daelemans.
2012.ConanDoyle-neg: Annotation of negation in ConanDoyle stories.
In Proceedings of the Eighth Interna-tional Conference on Language Resources and Evalu-ation (LREC), Istanbul.Roser Morante, Anthony Liekens, and Walter Daele-mans.
2008.
Learning the scope of negation inbiomedical texts.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?08, pages 715?724.
Association for Compu-tational Linguistics.281
