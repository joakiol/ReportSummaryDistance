Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 386?396,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsMulti-Resolution Language Grounding with Weak SupervisionR.
Koncel-Kedziorski, Hannaneh Hajishirzi, and Ali FarhadiUniversity of Washington{kedzior,hannaneh,farhadi}@washington.eduAbstractLanguage is given meaning through itscorrespondence with a world representa-tion.
This correspondence can be at mul-tiple levels of granularity or resolutions.In this paper, we introduce an approachto multi-resolution language grounding inthe extremely challenging domain of pro-fessional soccer commentaries.
We defineand optimize a factored objective functionthat allows us to leverage discourse struc-ture and the compositional nature of bothlanguage and game events.
We show thatfiner resolution grounding helps coarserresolution grounding, and vice versa.
Ourmethod results in an F1 improvement ofmore than 48% versus the previous stateof the art for fine-resolution grounding1.1 IntroductionLanguage is inextricable from its context.
A hu-man language user interprets an utterance in thecontext of, among other things, their perception ofthe world.
Grounded language acquisition algo-rithms imitate this setup: language is given mean-ing through its correspondence with a rich worldrepresentation.
A solution to the acquisition prob-lem must resolve several ambiguities: the seg-mentation of the text into meaningful units (spansof words that refer to events); determining whichevents are being referenced; and finding the properalignment of events to these units.Historically, language grounding was only pos-sible over simple controlled domains and rigidlystructured language.
Current research in grounded1Source code and data are available at http://ssli.ee.washington.edu/tial/projects/multires/Figure 1: An example of the multiple resolutions at whichsoccer commentaries refer to events: The utterance levelalignments are shown in the black dashed boxes.
The firstutterance can be further broken into the fragment-level align-ments shown; the second cannot be decomposed further.language acquisition is moving into real-world en-vironments (Yu and Siskind, 2013).
Groundingsports commentaries in game events is a specificinstance of this problem that has attracted attention(Liang et al., 2009; Snyder and Barzilay, 2007;Hajishirzi et al., 2012), in part because of the com-plexity of both the language and the world repre-sentation involved.The language employed in soccer commentariesis difficult to ground due to its dense informa-tion structure, novel vocabulary and word senses,and colorful, non-traditional syntax.
These chal-lenges conspire to foil most language processingtechniques including automated parsers and word-sense disambiguation systems.In addition to the structural problems presentedby the language of soccer commentaries, the prob-lem of reference is further complicated by the factthat for game events (and other real-world phe-nomena) there is no standardized meaningful lin-guistic unit.
Utterances ranging from a singleword to multiple sentences can be used to refer to asingle event.
For example, in Figure 1 the first fourwords of commentary (I) refer to a single event, asdoes the entirety of (II).386Figure 2: An example of the different levels of granularity present in the soccer data.
The dashed boxes on the left denote ut-terances made by the commentators.
Solid boxes denote fragments that cannot be decomposed into finer resolution alignments.The table on the right is a portion of the detailed listing of game events.Turning our attention to Figure 2, sometimes afragment refers to a combination of events and nofurther decomposition is available, such as the firstfragment of commentary (I).
Moreover, it is some-times desirable to construct a complex of eventsby determining all the events corresponding to aparticular collection of words.
For instance, wewould want to be able to align the whole of (I)with all the events in the corresponding dashedbox.
This suggests studying language groundingat multiple levels of granularity (resolutions).We use resolution to describe the continuum ofmeaningful units which exist in human language2.These resolutions interact in a complicated way,with clues from different resolutions sometimescombining to produce an effect and sometimesnegating one another.
With enough training data,one could hope to learn the details of the interac-tions of various resolutions.
However, the expenseof producing or obtaining supervised training dataat multiple resolutions is prohibitive.To address all these complications, we in-troduce weakly-supervised multi-resolution lan-guage grounding.
Our method makes use of afactorized objective function which allows us tomodel the complex interplay of resolutions.
Ourlanguage model takes advantage of the discoursestructure of the commentaries, making it robustenough to handle the unique language of the soc-cer domain.
Finally, our method relies only on2Though it is tempting to discritize meaning in text, Chafe(1988) shows that readers imbue text with meaningful intona-tional patterns drawn from the potentially continuous space ofauditory signals.loose temporal co-occurrence of events and utter-ances as supervision and does not require expen-sive annotated training data.To test our method we augment the Profes-sional Soccer Commentary Dataset (Hajishirzi etal., 2012) with fragment-level event alignment an-notations.
This dataset is composed of commen-taries for soccer matches paired with event logsproduced by Opta Sportsdata and includes humanannotated gold alignments3.
We achieve an F1 im-provement of over 48% on fragment-level align-ment versus a previous state-of-the-art.
We arealso able to leverage the interplay of fragment- andutterance- level alignments to improve the previ-ous state-of-the-art utterance-alignment system.2 ChallengesSyntactic Limitations: Syntax is used to struc-ture the information provided by an utterance, andso it seems intuitive that syntactic relations couldbe leveraged in this task.
For example, considerutterance (III) in Figure 2.
The multi-resolutiongrounding of (III) would provide a segmentationof the utterance ?
or a division of the utterance intothe fragments which refer to separate events.
In(III), there is an obvious syntactic correlate to thecorrect segmentation: each verb phrase within theconjunction headed by ?and?
identifies a separateevent.
Parsing (III) to an event-based semanticslike that of Davidson (1967), one could associateeach verb in an utterance with a game event andachieve the desired segmentation.3Our updated dataset is available at http://ssli.ee.washington.edu/tial/projects/multires/387Unfortunately, there is a preponderance of ex-amples such as (II) in Figure 2, where 4 verbsare used to describe a single ?miss?
event.
(II) il-lustrates just one of the many difficulties of usingsyntactic information ?
elsewhere, events are ref-erenced without an explicit verb whatsoever (suchas the use of the phrase ?into the books?
to refer toa foul event).
What is needed instead is a languagemodel that is powerful enough to proscribe somestructure yet robust enough to allow the world rep-resentation to determine which pieces of languageare referring to which referent or set of referents.Complex Interplay between Resolutions:Language refers at a variety of resolutions, andthe relationship between nested reference scopesis complex.
A single or few words can indicateentities or properties; full phrases are often neededto denote an action; complex events like a missedshot may take up to several phrases of narrationto properly describe.
A soccer commentatordoes not encode every detail necessary for properalignment and segmentation into their utterances,but rather only enough to make clear to anotherwith similar world knowledge what is meant.A language grounding method is at a severedisadvantage when faced with such implicitinformation.Instead, a successful method can make heavyuse of the limited lexical, phrasal, and discoursestructural cues provided in an utterance, as the dif-ferent resolutions rely on these different contex-tual clues to meaning.
At finer resolutions one canrely more on the lexical meanings of the words;at medium resolutions, compositionality can beleveraged; at coarser resolutions, discourse fea-tures come into play.
These cues interact in a com-plicated way, providing additional challenge.Consider again Figure 2.
In (III), the tempo-ral discourse marker ?and?
marks the division be-tween the fragments referring to each event.
In(I) the same word (used again as a temporal dis-course marker) is used to elaborate on the single?foul?
event being described in the second frag-ment.
A human (with sufficient understanding ofsoccer) knows that, despite being separated by thediscourse marker, the phrases ?bring him down?and ?set piece?
both refer to the foul.
A languagegrounding algorithm that can model the interac-tion between such word-level and utterance-levelcues can successfully segment both (I) and (III).Supervision: For language grounding generally,and multi-resolution grounding specifically, su-pervised training data is expensive to produce.Also, the various grounding domains of interestare highly independent of one another (Liang etal., 2009).
In the face of these issues, the idealcorrespondence between language and world rep-resentation would be learned with as little supervi-sion as possible.3 Problem DefinitionWe define the problem of multi-resolution lan-guage grounding as follows: Given a temporalevolution of a world state (a sequence of events)and an overlapping natural language text (a se-quence of utterances), we want to learn the bestcorrespondences between the language and theworld at different levels of granularity (Figure 2).To set up notations, for each utterance repre-sented as a set of words W = {w1, w2, .
.
.
, wn},we want a segmentation which expresses the re-lationship of the words to the events which theydescribe.Let S denote a set of all possible segmentationsof W .
Then S = {S|S is a segmentation of W}.A segmentation S is in turn a set of non-overlapping fragments (S = {si}), where eachfragment is a consecutive sequence of words fromthe utterance W .
For example, for utterance (III)from Figure 2, one possible (incorrect) segmenta-tion is S = {s1, s2, s3} for s1={Chamakh riseshighest}, s2={and aims a header}, and s3= {to-wards goal which is narrowly wide}.An alignment consists of a segmentation S anda mapping E from fragments of S to the set of allevents E. For example, the segmentation S couldbe mapped as E = {?s1, e2?, ?s2, e3?, ?s3, e1?
},with e1being an Aerial Challenge, e2being amissed attempt on goal, and e3being an out ofbounds penalty.
Let E = S ?
E denote the setof all possible alignments.As we show in Figure 2, events are composedof the various attributes Time, Type, Pass Events,Outcome, and Player.
For example, the aerialevent in Figure 2 has the attributes and valuestype:aerial, outcome:successful, pass events:headpass, and player:Chamakh.Finally, we denote the values for the attributesof each ejas eaj, where a ranges over the differentattributes of events as represented in the data.We define the multi-resolution grounding of W388into E as the best segmentation S and alignmentE that maximize the joint probability distribution:arg maxS?S,E?EP (S,E|W ) (1)This optimization4can be accomplishedthrough the use of supervised learning.
However,training data is expensive and tedious to producefor the grounding problem, especially at multipleresolutions.
Additionally, the complexity of thelanguage in this domain would result in verysparse associations.Yet if we knew some of the correct fine-resolution alignments, we could use that informa-tion to produce good coarse resolution alignments,and vice versa.
Therefore, we formulate a fac-torized form of the above objective which allowsus to learn features specific to aligning at the ut-terance, fragment, and attribute resolutions.
Ourmethod can be optimized with only weak super-vision (loose temporal alignments between utter-ances and a set of events occurring within a win-dow of the utterance time).We can evaluate such a correspondence in sev-eral ways.
For each utterance, can we predict thecorrect events to which this utterance refers?
Thisis the problem of utterance-level alignment.We can also evaluate based on events: for eachevent, can we identify the minimal text span(s)which refers to this event?
We want a tight corre-spondence because loose, overlapping alignmentsare not semantically satisfying.
However, we donot want to under associate: human languagemakes reference at a variety of levels (the wordlevel, the phrase level, the utterance level, and be-yond).
It is important to correctly identify all andonly the words which correspond to a given event.This is the fragment-level alignment problem.
Weshow that good fragment-level alignments will im-prove utterance-level alignment, and vice versa.Since events are composed of their attributes,we can imagine a very fine resolution grounding ofindividual words to individual attributes.
In fact,our solution involves producing such a groundingand composing the fragment- and utterance-levelalignments therefrom.WS?E?w1?
w2?
w3?
w4?
w5?Chamakh?
raises?
highest?
and?
aims???S1?
S2?
Sn?E1?
E2?
E3?
E4?{w3,w4,w5}?{w2}?{w1}?{w3,w4,w5}?{w1,w2}???{w4,w5}?{w1,w2,w3}?pass?
aerial?
miss?
out?Figure 3: Factor graph for P (S,E|W ).
Here the wiare thewords of utterance W , Sjare the possible segmentations ofW , and Ekare different events.4 Our MethodWe have formulated the grounding problem as anoptimization of the joint probability distributionP (S,E|W ), which returns the best segmentationand accompanying event alignments given an ut-terance W .
Optimizing this function in the do-main of real world language, however, is a diffi-cult problem.
Utterances are long here, and thereare many events which could be grounded to each.Furthermore, the cardinality of the set of possiblesegmentations is combinatorially large.Therefore we decompose Equation 1 using thefactor graph depicted in Figure 3.
We write thejoint probability distribution as a product of thefollowing two potential functions:P (S,E|W )def=1Z?s?S?align(E, s) ?
?seg(s,W )(2)where ?alignis a function for scoring the align-ment E for fragment s and ?segscores how gooda fragment s is for the utterance W , and Z is fornormalization.To optimize Equation 2 it is not practical tosearch the space of possible S,E combinations(this space is combinatorially large).
However, wecan optimize the factored form using dynamic pro-gramming.
We first describe how to find valuesfor each of the potentials in sections 4.1 and 4.2.In section 4.3 we describe the dynamic program-ming approach to optimization.4.1 Event Alignments Given SegmentationThe potential function ?align(E, s) takes as inputsa fragment s from segmentation S and a candidatealignment E for S and returns a score for E with4As this and future equations are conditioned on the setof all events E, we omit this variable from the equations fornotational simplicity.389regards to s. It is here that we produce the multi-resolution alignments; s can vary in size from asingle word to a whole utterance.
?aligndecom-poses as the following:?align(E, s) = ?prior(E) ?
?affinity(s, E) (3)where the priors (?prior) are confidence scores foran alignment E with the whole utterance as givenby Hajishirzi et al.
(2012), which fits an exemplarSVM to each utterance/event pair.
An exemplarSVM is an SVM fit with one positive and manynegative instances, allowing us to define an ex-ample by what it is not (Malisiewicz et al., 2011;Shrivastava et al., 2011).
?affinityscores the affinity between a fragments and the event ejto which it is aligned.
We usethe term affinity as a measure of the goodness ofan alignment.
Intuitively, a fragment s will havea higher affinity for an event ejif s describes thatevent well.
Formally, the affinity between s and ejamounts to a product of the affinity between eachword wi?
s and ej.
Since ejis defined by a col-lection of attributes, we can compose a score forwiwith ejfrom the affinity between wiand eachattribute a of ej.
?affinity(s, E) =?wi?s,ej?E?atr.
(wi, ej)=?wi?s,ej?Emaxa?
(wi, eaj) (4)where ejis the event to which s is aligned in align-mentE, ?atr.
(wi, ej) is the affinity betweenwiandevent ej, and ?
(wi, eaj) is the affinity between wiand attribute a of ej.In order to determine the affinity of a word andan event attribute, we create attribute:value clas-sifiers ?
one for each attribute:value pair that oc-curs in any event.
For example, for goals we createa type:goal classifier, and for unsuccessful eventswe create an outcome:unsuccessful classifier.For the categorical attributes Type, Outcome,and Pass Events, we fit a linear SVM (Fan et al.,2008) using the utterance-level alignments pro-vided by ?prior(the exemplar SVMs) to deter-mine the positive and negative examples.
For in-stance, we use all the utterances which are alignedwith an event whose type value is ?pass?
as posi-tive examples for our type:pass classifier, and allother utterances as negative examples.The weight assigned to each dimension in alinear SVM describes the relative importance ofthat dimension in the classification process.
Thedimensions of our attribute:value SVMs are thewords of the corpus, normalized for case and mi-nus punctuation and stop words.
Therefore, theaffinity of a word wiand the attribute:value eajisthe weight of the dimension corresponding to wiin the eajattribute:value classifier.
Following oth-ers (Liang et al., 2009; Kate and Mooney, 2007),we use string matches to determine the affinity be-tween a word and the Player attribute.In order to make comparisons between the im-portance of a word in the decision process for dif-ferent classifiers, we normalize the weight vectorsfor each.
These attribute:value classifiers produceour finest resolution alignments, allowing us to de-fine a correspondence between a single word anda single attribute of any event.By considering ejin terms of its attributes, weare able to compose a score for ejwith fragments.
This is a kind of double-sided compositionalsemantics, where both the meaningful signs (s)and their extensions (ej) are composed of finer-resolution atomic parts (wiand eaj, respectively).4.2 Segmentations Given UtterancesThe potential function ?seg(s,W ) from Equation2 returns a score for a fragment within an utter-ance.
A segmentation can be thought of as thecollection of bigrams ?wi, wi+1?
where wiis thelast word of a fragment which is being used to de-scribe one event and wi+1is the first word of afragment being used to describe a different event.We will refer to such bigrams as splitpoints.The function ?segshould favor fragments thatbegin and end at good splitpoint and whose inter-mediate bigrams are bad splitpoints.
We formalizethis as follows:?seg(s,W ) ??
(wk?1, wk) ?
?
(wk+m, wk+m+1)?m?1j=0?
(wk+j, wk+j+1)where fragment s is a span ofm consecutive words{wk, ..., wk+m} from W , and ?
is a score for howgood of a splitpoint ?wi, wi+1?
would make (ex-plained below).Ideally, ?
will be a classifier which can tellus if a given bigram is a good splitpoint for theutterance W .
However, ours being an attemptat weakly-supervised learning, we have no la-beled examples of correct splitpoints from which390to work.
Instead, we employ linguistic knowledgeto create a proxy of labels.
We will use this proxyto train a classifier to discover the features of goodsplitpoints which can be generalized and producea more robust system.The proxy labeling scheme we developed isbased on conservative components common to avariety of theories of discourse.
Discourse theo-ries aim to model the relationships which exist be-tween adjacent utterances in a coherent discourse.Since we consider a sports commentary to be a co-herent discourse, we can leverage results from dis-course theory in producing our proxy labels.Temporal Discourse: Events in a soccer matchoccur in a temporal sequence, and so it is reason-able to assume that the language used to describethem will employ temporal discourse relations todistinguish fragments describing separate events.Pitler et al.
(2008) have constructed a list of dis-course relations which can be easily automaticallyidentified, including temporal discourse relations.These are indicated by the presence of discoursemarkers ?
alternately known as cue phrases.
Wehypothesize that cue phrases can be used to iden-tify splitpoints and use them in our proxy labelingscheme.
This method is not restricted to tempo-rally related discourse: some contingency, expan-sion, and comparison relations are also analyzedas ?easily identifiable?.
As such, our segmentationprocess can also be used to ground language intoa world state where these relations would hold.Prosodic Discourse: We also make use ofprosodic discourse cues.
Pierrehumbert andHirschberg (1990) claim that intonational phrasesplay an important role in discourse segmentation.Therefore, we hypothesize that the edges of in-tonational phrases are very likely to correspondwith correct splitpoints.
Viewing the commen-tary transcriptions as a noisy channel of the ac-tual speech signal, we can identify the intona-tional phrase boundaries with the punctuation in-serted in the transcription process.
Chafe (1988)confirms that punctuation in written language hasa strong correspondence with intonational phraseboundaries, and an assumption like ours has beensuccessfully implemented in speech synthesis sys-tems (Black and Lenzo, 2000).
Thus, we includebigrams containing punctuation as splitpoints inour proxy labels.Feature Description for splitpoint classifierIs wi/wi+1a discourse marker?Is wi/wi+1punctuation?Is wi/wi+1a player name?Part of speech of wi/wi+1Is one of wi/wi+1a dependent of the other?Are wiand wi+1dependents of the same governor?Dependency relations that hold across splitpointHeight of wi/wi+1in the dependency treeDifference in height of wi/wi+1in dependency tree?
(wi, ej) of all words left versus right of splitpointSymmetric difference of best affinity scores for wi/wi+1Are best affinity scores from the same event?Table 1: Feature description for splitpoint classifierw1?
w2?
w3?Chamakh?
rises?
highest????
(w1,e1) ?
(w2,e1) ?(w3,e1)?
(w1,w2 )E1:?Unsuccessful?Cross?Pass?E2:?Successful??Aerial?Head?Pass?E3:?Missed??Head?Pass??1/?
(w1,w2 ) ?
(w3,e2 )?(w3,e3)?
(w2,e2 )?(w2,e3)?
(w1,e2 )?
(w1,e3) ?
(w1,w2 )Figure 4: We use a trellis to allow for dynamic programmingoptimization of the objective functionSplitpoint Classifier: All other bigrams besidesthose above are labeled as negative examples, anda linear SVM is fit to the data.
The features for theclassifier include structural, discourse, and statis-tical features.
We make use of dependency parseinformation from the Stanford dependency parser(De Marneffe and Manning, 2008).
The full fea-tures list is explained in Table 1.4.3 OptimizationWe want to maximize the function in Equation 1,and we have explained that we can approximatethis by maximizing the factored form in Equation2.
By the above methods, we can produce valuesfor the functions ?alignand ?seg.
What remains isto optimize Equation 2.We take advantage of the factorization by usinga dynamic programming approach to optimiza-tion.
Figure 4 illustrates the setup.
For each wordwiof the utterance, we create a column of nodesin our trellis, with one row for each event ej?
E.The nodes represent the affinity of a given wordwiwith event ej.
The weights on these nodes comefrom ?atr.
(wi, ej) described in section 4.2.The nodes in column wiare connected to thenodes in column wi+1by edges whose weights391Method Precision Recall F1Liang et al.
(2009) 0.513 0.393 0.445Our approach 0.603 0.481 0.535Table 2: Fragment-level alignments starting from goldutterance-level alignmentsMethod Precision Recall F1Liang et al.
(2009) 0.211 0.135 0.165Our approach 0.235 0.255 0.245Table 3: Fragment-level alignments starting from raw dataare drawn from the splitpoint classifier response?
(wi, wi+1).
We label the edges between adja-cent nodes corresponding to different events withthe responses from the splitpoint classifier, and theinverse of these responses for edges connectingnodes corresponding to the same event.We then use the Viterbi algorithm (Viterbi,1967) to find the maximum scoring path throughthis trellis.
The maximum scoring path optimizesEquation 2, and serves as our approximation of theoptimization of Equation 1.
We choose the top kdiverse paths through the trellis and use the associ-ations therein as our alignments.
See Figure 5 fora detailed example of how our Viterbi path coin-cides with the responses from the attribute:valueclassifiers.5 ExperimentsOne justification for multi-resolution languagegrounding would be if finer-resolution groundingimproves coarser-resolution grounding and viceversa.
If so, we expect that better utterance-levelalignments will improve fragment-level align-ments, and that in turn those fragment-level align-ments will improve utterance-level alignments.We evaluate both of these hypotheses.5.1 Experimental SetupDataset: We use the publicly available Profes-sional Soccer Commentary (PSC) dataset intro-duced in Hajishirzi et al.
(2012).
This dataset iscomposed of professional commentaries from the2010-2011 season of the English Premier League,along with a human-annotated data feed producedfor each game by Opta Sportsdata (Opta, 2012)which describes all events occurring around theball.
Events include passes, shots, misses, cards,Method Precision Recall F1Liang et al.
(2009) 0.327 0.418 0.367Hajishirzi et al.
(2012) 0.355 0.576 0.439Our approach 0.407 0.520 0.457Table 4: Utterance-level alignment resultstackles, and other relevant game details.
Eachevent category is defined precisely and the feedis annotated by professionals according to strictevent description guidelines.The PSC also provides ground truth alignmentof full utterances to events in the data feed, and forthis work we have augmented it with ground truthfragment-level annotations5.We use data from 7 games of the PSC.
Thesegames consist of 778 utterances totaling 13,692words.
There are 12,275 events.
This data is la-beled with ground truth utterance- and fragment-alignments.Metric: There are 1,295 correct utterance-to-event alignments.
For evaluation we use precision,recall, and F1 of our utterance-level alignments.The evaluation of fragment-level alignments isless straight forward.
This is due to the two fea-tures of a correct fragment alignment: pickingthe correct fragment boundaries and associatingthe fragment with the correct event.
We evaluatefragment-level alignment on a per word basis.
Weconsider precision in this task to be the number ofcorrect word to event alignments versus the totalnumber of alignments produced by a system.
Re-call is the number of correct word to event align-ments versus the total gold word to event align-ments, of which there are 18,147.Comparisons: We compare to two previousworks: Liang et al.
(2009), which producesboth segmentation and alignment results; and Ha-jishirzi et al.
(2012), which produces state-of-the-art alignments.
When evaluating segmentation,we compare how well the systems perform start-ing from the raw dataset, and starting from goldutterance-level alignments.
This allows us to iso-late the segmentation process from the overall sys-tem architectures.
It also gives us some insightinto the effect of event priors on the segmentationand alignment processes.5The full dataset is available at http://ssli.ee.washington.edu/tial/projects/multires/392Chamakh?
rises?
highest?
and?
aims?
a?
header?
towards?goal?
which?
is?
narrowly?wide?pass:head?pass?outcome:unsuccessful?type:out?pass:head?pass?outcome:successful?type:miss?pass:head?pass?outcome:successful?type:aerial?.01?
.02?0?
.05?
0?.23?
0?
.02?
.1?.33?
.02?.04?
0?0?
.03?0?
.01?
0?.04?
0?
.01?
.04?.33?
.01?.02?
0?.01?
.07?0?
0?
0?0?
0?
.03?
.28?.33?
.01?.01?
0?
.01?
.02?0?
.05?
0?.23?
0?
.02?
.1?.33?
.02?.04?
0?0?
.06?0?
0?
0?.03?
0?
.01?
.03?.33?
.01?.01?
0?.02?
.15?0?
.01?
0?.11?
0?
.06?
.50?.33?
.02?.07?
0?.01?
.02?0?
.05?
0?.23?
0?
.02?
.1?.33?
.02?.04?
0?0?
.06?0?
0?
0?.03?
0?
.01?
.03?.33?
.01?.02?
0?.04?
.02?0?
.05?
0?.1?
0?
.03?
.13?.33?
.03?.06?
0?Figure 5: A successful grounding at multiple resolutions.
Thin blue lines separatethe attribute:value pairs corresponding to the three events.
Values of ?
(wi, ej)are shown on each node.
The shaded bands indicate the gold fragment-level align-ments.
Thick line connecting the green nodes indicates the classifier responsesused in the Viterbi best path through our trellis.
The red dashed edge indicates ahigh response from the splitpoint classifier.
This figure is best viewed in color.Method Precision Recall F1Ours 0.235 0.255 0.245- ?affinity0.213 0.133 0.164- ?seg0.205 0.232 0.218Table 5: Ablation studies for fragment-levelalignments by removing ?affinityand ?segfrom our model by replacing them with uni-form function.Method Precision Recall F1Ours 0.407 0.520 0.457- ?affinity0.446 0.189 0.265- ?seg0.376 0.563 0.451Table 6: Ablation studies for utterance-levelalignments by removing ?affinityand ?segfrom our model by replacing them with uni-form function.5.2 ResultsWe evaluate our method on its alignments at thefragment-level and at the utterance-level.
The re-sults are as follows:Fragment-level: Our results for segmentation canbe seen in Tables 2 and 3.
Table 2 shows the resultsachieved on the fragment-level alignment task us-ing human-labeled utterance to event alignments.In this setting, all and only the correct events foreach utterance are present.
Still, there are sev-eral ambiguities in the data.
Some fragments arealigned in the gold data with multiple events, andsome are aligned to no event.
Our method out-performs the previous by a large margin in termsof both precision and recall.
We show below howthis is due to our system?s accommodation of dis-course structure when making segmentation deci-sions and the factored form of our optimization.Table 3 shows the results for fragment-levelalignment by applying each system starting fromthe raw data.
Here, in addition to the ambiguitiesmentioned above, the problem is further compli-cated by the fact that some correct events are miss-ing from the alignments produced by each systemand some incorrect events are included in thesealignments (see Error Analysis below for details).Still our method achieves a significant improve-ment, with a 48% increase in F1 versus prior work.Table 5 shows ablation results for the effect ofthe factors used in our optimization for fragment-level alignments.
These results demonstrate thevalue of each factor in the fragment-level align-ment process.
We cannot ascribe the benefit of thismethod to one factor or another alone ?
it is theirconcert that improves performance.Utterance-level: We have posited that good finer-resolution alignments will improve the coarser-resolution utterance to event alignments.
Our re-sults confirm this hypothesis.
Table 4 shows ourresults on these alignments.
We are able to im-prove F1 versus a state-of-the-art system whichis tuned to maximize its F1 score.
The major-ity of our improvement comes from the increasedprecision of our system, due to the influence ofthe finer-resolution fragment-level alignments onthese coarser, utterance-level alignments.
We pro-vide a detailed example of this below.
Ablationresults are shown in Table 6.5.3 Qualitative AnalysisA qualitative analysis of our system reveals thepower of our factored objective, double-sidedcompositional approach, and leveraging of dis-course structure.
Figure 5 shows the best paththrough the trellis of the example sentence usedin the introduction.
For explanatory purposes,we have split every event into its three compo-nent attributes.
This allows us to see how theattribute:value classifiers combine to produce analignment.Discourse Structure: The fragment-level align-ment we have produced for this utterance is per-fect: it correctly identifies the single splitpoint andcorrectly identifies each fragment with the associ-ated event.The identification of the splitpoint ?and?
comesfrom the fact that this word has, among other uses,a discourse connective meaning.
Thus, the edges393in our trellis between different events are weightedhigher than edges between the same event in theedges between the nodes for ?highest?
and ?and?,encouraging the Viterbi path to change events atthis point.Compositionality: We can see effect of the com-positional approach we have taken ?
composing?affinity(s, ej) from the attribute:value classifierscores of each ?
(wi, eaj) ?
by looking at how thebest path makes use of different attributes of thesame event.
For the ?miss?
event aligned withthe second part of the sentence, we can see thatthe best path makes use of both values from thetype:miss and pass event:head pass classifiers.Affinities: A few interesting associations areworth pointing out.
First, we note that the word?header?
has a stronger affinity for the type:missattribute than it does for the pass events:head passattribute.
On first blush, this seems like a mistakein our classifier.
However, we can see that evenin this single trellis all three events have the passevents:head pass attribute.
The utterance-levelalignment uses this association already, align-ing utterances containing the word ?header?
withevents that have a pass events:head pass attribute.At a finer-resolution, it is necessary to make adifferent distinction between events.
Our methodfinds that the presence of the word ?header?
is astronger indicator of an event with a type:miss at-tribute, and thus this association is made.Words that are better for the coarser-resolutionassociation with the pass events:head pass at-tribute are ?towards?
and ?goal?.
Out of the 10utterances containing the word ?towards?
in thedataset, 3 of these are aligned with at least 1 passevents:head pass event, making this strong asso-ciation a correct one.
The word ?goal?
also hasan affinity for the pass events:head pass attributedue to the fact that many events with this attributeare attempts on goal.
This correlates with domainknowledge about soccer, because, although theremay be other uses of their head by a player in thegame, shots on goal are events which will nearlyalways be commented upon by an announcer.Factorization: We have shown that finer-resolution fragment-level alignments can improveutterance-level alignments.
From the exemplarSVMs, we are given an utterance-level alignmentof the three events shown in the trellis with theutterance.
This alignment is incorrect: the goldutterance alignment only includes the bottom twoevents.
But by building an utterance-level align-ment from the results of our fragment level align-ment, we are left with only the two correct events.We prune the topmost event due to its failure toparticipate in a finer-resolution alignment.5.4 Error AnalysisThe majority of the errors made on our fragment-level alignments come in one of two flavors:Firstly, we sometimes erroneously identify a frag-ment as referring to an event when in truth it refersto no event.
Commentators often describe factsabout players or the weather or previous gameswhich have no extension in the current game.However, our system cannot distinguish such lan-guage from the language referring to this game.This is a good avenue for future exploration.The second set of errors we make in fragmen-tation are caused by bad event priors.
Our currentsetup cannot increase recall: we can only improvethe precision of the utterance-level alignments weare given.
Therefore, if an event is overlookedin the first-pass of utterance-level alignments, wecannot reintroduce it through a fragment align-ment.
This is a direction for future work as well.6 Related WorkEarly semantic parsing work made use of fully su-pervised training (Zettlemoyer and Collins, 2005;Ge and Mooney, 2006; Snyder and Barzilay,2007), but more recent work has focused on re-ducing the amount of supervision required (Artziand Zettlemoyer, 2013).
A few unsupervised ap-proaches exist (Poon and Domingos, 2009; Poon,2013), but these are specific to translating lan-guage into queries in highly structured databaseand cannot be applied to our more flexible domain.There are few datasets as detailed as the Profes-sional Soccer Commentary Dataset.
Early workin understanding soccer commentaries focused onRoboCup soccer (Chen and Mooney, 2008; Chenet al., 2010; Bordes et al., 2010; Hajishirzi etal., 2011) where simple language describes eachevent, and events are in a one-to-one correspon-dence with utterances.
Another dataset used forlanguage grounding is the Weather Report Dataset(Liang et al., 2009).
Here, again, however, wehave mostly single utterances paired with singleevents, and many alignments are made via nu-merical string matching rather than learning lex-394ical cues.
The NFL Recap dataset (Snyder andBarzilay, 2007) is also laden with numerical factmatching, and does not include the fragment-levelsegmentation annotation that the PSC dataset pro-vides.Impressive advances have been made groundinglanguage in instructions.
Branavan et al.
(2009)and Vogel and Jurafsky (2010) work in the do-main of computer technical support instructions,mapping language to actions using reinforcementlearning.
Matuszek et al.
(2012b) parses sim-ple language to robot control instructions.
Ourwork focuses on dealing with a richer space, bothin terms of the language used and the world-representation into which it is grounded, and lever-aging the multiple resolutions of reference.An exciting direction of research, closer to ourown, aims to ground natural language in visualperception systems.
Matuszek et al.
(2012a) at-tempts to learn a joint model of language and ob-ject characteristics of a workplace environment.Yu and Siskind (2013) grounds moderately richlanguage in automatically annotated video clips.Again, the contribution of our work versus theabove is in the complexity of the language withwhich we deal and our multi-resolution model.7 ConclusionThe problem of grounding complex natural hu-man language such as soccer commentaries isextremely difficult at all resolutions, and it ismost challenging at finer resolutions where data issparsest and small errors cannot be as easily nor-malized.
Our work will help open new avenues ofresearch into this difficult and exciting problem.This paper presents a new method for the multi-resolution grounding of complex natural languagein a detailed world representation.
Our factorgraph allows us to decompose the grounding prob-lem into the more tractable subproblems of seg-menting the language into fragments and aligningthe fragments with the world representation.
Inthe segmentation phase, we make use of linguis-tic theories of discourse to create a proxy of labelsfrom which we learn statistical and structural fea-tures of good splitpoints.
In the alignment phase,we bootstrap the learning of finer-grained corre-spondences between the language and the worldrepresentation with rough alignments from a state-of-the-art system.
We combine these phases in adynamic programming setup which allows us toefficiently optimize our objective.We have shown that factoring the acquisitionproblem into separate alignment and segmentationphases improves performance on several evalua-tion metrics.
We achieve considerable improve-ments over the previous state of the art on finer-resolution alignments in the domain of profes-sional soccer commentaries, and we show that wecan leverage groundings at one resolution to im-prove alignments in another.Several extensions of this work are possible.
Wewould like to annotate more games to improveour dataset.
We could improve our model by en-coding the dynamics of the environment.
We didnot attempt to learn this information in our pro-cess, but it is likely that modeling the event tran-sition probabilities could provide better results.
Alarger future work would extend the method out-lined herein to produce templates for automatedcommentary generation.AcknowledgmentsThis research was supported in part by a grantfrom the NSF (IIS-1352249), and the Royalty Re-search Fund (RRF) at the University of Washing-ton.
The authors also wish to thank Gina-AnneLevow, Yoav Artzi, Ben Hixon, and the anony-mous reviewers for their valuable feedback on thiswork.ReferencesYoav Artzi and Luke Zettlemoyer.
2013.
Weakly su-pervised learning of semantic parsers for mappinginstructions to actions.
Transactions of the Associa-tion for Computational Linguistics, 1(1):49?62.Alan Black and Kevin Lenzo.
2000.
Building voicesin the festival speech synthesis system.Antoine Bordes, Nicolas Usunier, and Jason Weston.2010.
Label ranking under ambiguous supervisionfor learning semantic correspondences.
In Proceed-ings of The 27th International Conference on Ma-chine Learning, pages 103?110.S.
R. K. Branavan, Harr Chen, Luke Zettlemoyer, andRegina Barzilay.
2009.
Reinforcement learning formapping instructions to actions.
In Proceedings ofthe Joint Conference of the 47th Annual Meeting ofthe Association for Computational Linguistics and4th International Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 82?90.Wallace Chafe.
1988.
Punctuation and the prosodyof written language.
Written communication,5(4):395?426.395David L. Chen and Raymond J. Mooney.
2008.
Learn-ing to sportscast: a test of grounded language ac-quisition.
In Proceedings of the 25th InternationalConference on Machine Learning, pages 128?135.David L. Chen, Joohyun Kim, and Raymond J.Mooney.
2010.
Training a multilingual sportscaster:Using perceptual context to learn language.
Journalof Artificial Intelligence Research (JAIR), 37:397?435.Donald Davidson.
1967.
The logical form of actionsentences.
The logic of Decision and Action.Marie-Catherine De Marneffe and Christopher D Man-ning.
2008.
Stanford typed dependencies manual.URL http://nlp.
stanford.
edu/software/dependenciesmanual.
pdf.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Ruifang Ge and Raymond J. Mooney.
2006.
Discrim-inative reranking for semantic parsing.
In Proceed-ings of the 44th Annual Meeting of the Associationfor Computational Linguistics.Hannaneh Hajishirzi, Julia Hockenmaier, Erik T.Mueller, and Eyal Amir.
2011.
Reasoning aboutrobocup soccer narratives.
In Proceedings of the27th conference on Uncertainty in Artificial Intelli-gence, pages 291?300.Hannaneh Hajishirzi, Mohammad Rastegari, AliFarhadi, and Jessica K Hodgins.
2012.
Semanticunderstanding of professional soccer commentaries.In Proceedings of the 28th conference on Uncer-tainty in Artificial Intelligence.Rohit J. Kate and Raymond J. Mooney.
2007.
Learn-ing language semantics from ambiguous supervi-sion.
In Proceedings of the Twenty-Second AAAIConference on Artificial Intelligence, pages 895?900.Percy Liang, Michael I. Jordan, and Dan Klein.
2009.Learning semantic correspondences with less super-vision.
In Proceedings of the Joint Conference of the47th Annual Meeting of the Association for Com-putational Linguistics and 4th International JointConference on Natural Language Processing of theAFNLP, pages 91?99.Tomasz Malisiewicz, Abhinav Gupta, and Alexei A.Efros.
2011.
Ensemble of exemplar-svms for objectdetection and beyond.
In Proceedings of the 13thInternational Conference on Computer Vision.Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-moyer, Liefeng Bo, and Dieter Fox.
2012a.
A JointModel of Language and Perception for GroundedAttribute Learning.
In Proc.
of the 2012 Interna-tional Conference on Machine Learning, Edinburgh,Scotland, June.Cynthia Matuszek, Evan Herbst, Luke Zettlemoyer,and Dieter Fox.
2012b.
Learning to parse naturallanguage commands to a robot control system.
InProc.
of the 13th International Symposium on Ex-perimental Robotics (ISER), June.Opta.
2012. http://www.optasports.com.Janet Pierrehumbert and Julia Hirschberg.
1990.
Themeaning of intonational contours in the interpreta-tion of discourse.
Intentions in Communication,271.Emily Pitler, Mridhula Raghupathy, Hena Mehta, AniNenkova, Alan Lee, and Aravind K Joshi.
2008.Easily identifiable discourse relations.
TechnicalReports (CIS), page 884.Hoifung Poon and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing, pages 1?10.Hoifung Poon.
2013.
Grounded unsupervised seman-tic parsing.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguis-tics.Abhinav Shrivastava, Tomasz Malisiewicz, AbhinavGupta, and Alexei A. Efros.
2011.
Data-drivenvisual similarity for cross-domain image matching.ACM Transaction of Graphics (TOG) (Proceedingsof ACM SIGGRAPH ASIA), 30(6).Benjamin Snyder and Regina Barzilay.
2007.Database-text alignment via structured multilabelclassification.
In Proceedings of the 20th Inter-national Joint Conference on Artificial Intelligence,pages 1713?1718.Andrew J Viterbi.
1967.
Error bounds for convolu-tional codes and an asymptotically optimum decod-ing algorithm.
Information Theory, IEEE Transac-tions on, 13(2):260?269.Adam Vogel and Daniel Jurafsky.
2010.
Learning tofollow navigational directions.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 806?814.Haonan Yu and Jeffrey Mark Siskind.
2013.
Groundedlanguage learning from video described with sen-tences.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguis-tics, volume 1, pages 53?63.Luke S. Zettlemoyer and Michael Collins.
2005.Learning to map sentences to logical form: Struc-tured classification with probabilistic categorialgrammars.
In Proceedings of the 21st Conferenceon Uncertainty in Artificial Intelligence, pages 658?666.396
