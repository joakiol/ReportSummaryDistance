Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 232?240, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsGETALP: Propagation of a Lesk Measure through an Ant Colony AlgorithmDidier Schwab, Andon Tchechmedjiev, J?r?me Goulian,Mohammad Nasiruddin, Gilles S?rasset, Herv?
BlanchonLIG-GETALPUniv.
Grenoble Alpeshttp://getalp.imag.fr/WSDfirstname.lastname@imag.frAbstractThis article presents the GETALP system forthe participation to SemEval-2013 Task 12,based on an adaptation of the Lesk measurepropagated through an Ant Colony Algorithm,that yielded good results on the corpus of Se-meval 2007 Task 7 (WordNet 2.1) as well asthe trial data for Task 12 SemEval 2013 (Ba-belNet 1.0).
We approach the parameter es-timation to our algorithm from two perspec-tives: edogenous estimation where we max-imised the sum the local Lesk scores; exoge-nous estimation where we maximised the F1score on trial data.
We proposed three runsof out system, exogenous estimation with Ba-belNet 1.1.1 synset id annotations, endoge-nous estimation with BabelNet 1.1.1 synset idannotations and endogenous estimation withWordNet 3.1 sense keys.
A bug in our imple-mentation led to incorrect results and here, wepresent an amended version thereof.
Our sys-tem arrived third on this task and a more finegrained analysis of our results reveals that thealgorithms performs best on general domaintexts with as little named entities as possible.The presence of many named entities leads theperformance of the system to plummet greatly.1 IntroductionOut team is mainly interested in Word Sense Disam-biguation (WSD) based on semantic similarity mea-sures.
This approach to WSD is based on a localalgorithm and a global algorithm.
The local algo-rithm corresponds to a semantic similarity measure(for example (Wu and Palmer, 1994), (Resnik, 1995)or (Lesk, 1986)), while the global algorithm propa-gates the values resulting from these measures at thelevel of a text, in order to disambiguate the wordsthat compose it.
For two years, now, our team hasfocussed on researching global algorithms.
The lo-cal algorithm we use, a variant of the Lesk algo-rithm that we have evaluated with several global al-gorithms (Simulated Annealing (SA), Genetic Al-gorithms (GA) and Ant Colony Algorithms (ACA))(Schwab et al 2012; Schwab et al 2013), hasshown its robustness with WordNet 3.0.
For thepresent campaign, we chose to work with an antcolony based global algorithms that has proven itsefficiency (Schwab et al 2012; Tchechmedjiev etal., 2012).Presently, for this SemEval 2013 Task 12 (Nav-igli et al 2013), the objective is to disambiguate aset of target words (nouns) in a corpus of 13 textsin 5 Languages (English, French, German, Italian,Spanish) by providing, for each sense the appropri-ate sense labels.
The evaluation of the answers isperformed by comparing them to a gold standardannotation of the corpus in all 5 languages usingthree possible sense inventories and thus sense tags:BabelNet 1.1.1 Synset ids (Navigli and Pozetto,2012), Wikipedia page names and Wordnet sensekeys (Miller, 1995).Our ant colony algorithm is a stochastic algorithmthat has several parameters that need to be selectedand tuned.
Choosing the values of the parametersbased on linguistic criteria remains an open and dif-ficult problem, which is why we wanted to autom-atize the parameter search process.
There are twoways to go about this process: exogenous estima-232tion, when the parameter values are selected so asto maximise the F-score on a small training anno-tated corpus and then used to disambiguate anothercorpus (weakly supervised); endogenous estimation,when the parameters are chosen so as to maximisethe global similarity score on a text or corpus (unsu-pervised).
Our first experiment and system run con-sists in tuning the parameters on the trial corpus ofthe campaign and running the system with the Ba-belNet sense inventory.
Our second and third exper-iments consist in endogenous parameter estimation,the first using BabelNet as a sense inventory and thesecond using WordNet.
Unfortunately, the presenceof an implementation issue prevented us from ob-taining scores up to par with the potential of our sys-tem and thus we will present indicative results of theperformance of the system after the implementationissue was fixed.2 The GETALP System: Propagation of aLesk Measure through an Ant ColonyAlgorithmIn this section we will first describe the local al-gorithm we used, followed by a quick overview ofglobal algorithms and our own Ant Colony Algo-rithm.2.1 The Local Algorithm: a Lesk MeasureOur local algorithm is a variant of the Lesk Algo-rithm (Lesk, 1986).
Proposed more than 25 yearsago, it is simple, only requires a dictionary and notraining.
The score given to a sense pair is the num-ber of common words (space separated strings) inthe definition of the senses, without taking into ac-count neither the word order in the definitions (bag-of-words approach), nor any syntactic or morpho-logical information.
Variants of this algorithm arestill today among the best on English-language texts(Ponzetto and Navigli, 2010).Our local algorithm exploits the links provided byWordNet: it considers not only the definition of asense but also the definitions of the linked senses(using all the semantic relations for WordNet, mostof them for BabelNet) following (Banerjee and Ped-ersen, 2002), henceforth referred asExtLesk1 Con-1All dictionaries and Java implementations of all algorithmsof our team can be found on our WSD pagetrarily to Banerjee, however, we do not considerthe sum of squared sub-string overlaps, but merelya bag-of-words overlap that allows us to generatea dictionary from WordNet, where each word con-tained in any of the word sense definitions is indexedby a unique integer and where each resulting defini-tion is sorted.
Thus we are able to lower the compu-tational complexity fromO(mn) toO(m), wheremand n are the respective length of two definitions andm ?
n. For example for the definition: "Some kindof evergreen tree", if we say that Some is indexed by123, kind by 14, evergreen by 34, and tree by 90,then the indexed representation is {14, 34, 90, 123}.2.2 Global Algorithm : Ant Colony AlgorithmWe will first review the principles pertaining toglobal algorithms and then a more detailed accountof our Ant Colony algorithm.2.2.1 Global algorithms, Global scores andConfigurationsA global algorithm is a method that allows topropagate a local measure to a whole text in or-der to assign a sense label to each word.
In thesimilarity-based WSD perspective, the algorithmsrequire some fitness measure to evaluate how gooda configuration is.
With this in mind, the scoreof the selected sense of a word can be expressedas the sum of the local scores between that senseand the selected senses of all the other words of acontext.
Hence, in order to obtain a fitness value(global score) for the whole configuration, it ispossible to simply sum the scores for all selectedsenses of the words of the context: Score(C) =?mi=1?mj=iExtLesk(wi,C[i], wj,C[j]).For a given text, the chosen configuration isthe one which maximizes the global score amongthe evaluated ones.
The simplest approach is theexhaustive evaluation of sense combinations (BF),used for example in (Banerjee and Pedersen, 2002),that assigns a score to each word sense combinationin a given context (window or whole text) and se-lects the one with the highest score.
The main is-sue with this approach is that it leads to a combi-http://getalp.imag.fr/WSD and more specifically forSemEval 2013 Task 12 on the following pagehttp://getalp.imag.fr/static/wsd/GETALP-WSD-ACA/233natorial explosion in the length of the context win-dow or text.
The number of combinations is indeed?|T |i=1(|s(wi)|), where s(wi) is the set of possiblesenses of word i of a text T .
For this reason it isvery difficult to use the BF approach on an analy-sis window larger than a few words.
In our work,we consider the whole text as context.
In this per-spective, we studied several methods to overcomethe combinatorial explosion problem.2.2.2 Complete and Incomplete ApproachesSeveral approximation methods can be used in or-der to overcome the combinatorial explosion issue.On the one hand, complete approaches try to reducedimensionality using pruning techniques and senseselection heuristics.
Some examples include: (Hirstand St-Onge, 1998), based on lexical chains that re-strict the possible sense combinations by imposingconstraints on the succession of relations in a taxon-omy (e.g.
WordNet); or (Gelbukh et al 2005) thatreview general pruning techniques for Lesk-basedalgorithms; or yet (Brody and Lapata, 2008) whoexploit distributional similarity measures extractedfrom corpora (information content).On the other hand, incomplete approaches gen-erally use stochastic sampling techniques to reach alocal maximum by exploring as little as necessaryof the search space.
Our present work focuses onsuch approaches.
Furthermore, we can distinguishtwo possible variants:?
local neighbourhood-based approaches (newconfigurations are created from existing con-figurations) among which are some approachesfrom artificial intelligence such as genetic al-gorithms or optimization methods such as sim-ulated annealing;?
constructive approaches (new configurationsare generated by iteratively adding new ele-ments of solutions to the configuration underconstruction), among which are for exampleant colony algorithms.2.2.3 Principle of our Ant Colony AlgorithmIn this section, we briefly describe out Ant ColonyAlgorithm so as to give a general idea of how it op-erates.
However, readers are strongly encouragedto read the detailed papers (Schwab et al 2012;Schwab et al 2013) for a more detailed descriptionof the system, including examples of how the graphis built, of how the algorithm operates step by stepas well all pseudo code listing.Ant colony algorithms (ACA) are inspired fromnature through observations of ant social behavior.Indeed, these insects have the ability to collectivelyfind the shortest path between their nest and a sourceof food (energy).
It has been demonstrated thatcooperation inside an ant colony is self-organisedand allows the colony to solve complex problems.The environment is usually represented by a graph,in which virtual ants exploit pheromone trails de-posited by others, or pseudo-randomly explore thegraph.
ACAs are a good alternative for the resolu-tion of optimization problems that can be encodedas graphs and allow for a fast and efficient explo-ration on par with other search heuristics.
The mainadvantage of ACAs lies in their high adaptivity todynamically changing environments.
Readers canrefer to (Dorigo and St?tzle, 2004) or (Monmarch?,2010) for a state of the art.In this article we use a simple hierarchical graph(text, sentence, word) that matches the structure ofthe text and that exploits no external linguistic infor-mation.
In this graph we distinguish two types ofnodes: nests and plain nodes.
Following (Schwab etal., 2012), each possible word sense is associated toa nest.
Nests produce ants that move in the graph inorder to find energy and bring it back to their mothernest: the more energy is brought back by ants, themore ants can be produced by the nest in turn.
Antscarry an odour (a vector) that contains the words ofthe definition of the sense of its mother nest.
Fromthe point of view of an ant, a node can be: (1) itsmother nest, where it was born; (2) an enemy nestthat corresponds to another sense of the same word;(3) a potential friend nest: any other nest; (4) a plainnode: any node that is not a nest.
Furthermore, toeach plain node is also associated an odour vector ofa fixed length that is initially empty.Ant movement is function of the scores given bythe local algorithm, of the presence of energy, of thepassage of other ants (when passing on an edge antsleave a pheromone trail that evaporates over time)and of the nodes?
odour vectors (ants deposit a partof their odour on the nodes they go through).
Whenan ant arrives onto the nest of another word (that cor-responds to a sense thereof), it can either continue its234exploration or, depending on the score between thisnest and its mother nest, decide to build a bridge be-tween them and to follow it home.
Bridges behavelike normal edges except that if at any given time theconcentration of pheromone reaches 0, the bridgecollapses.
Depending on the lexical informationpresent and the structure of the graph, ants will fa-vor following bridges between more closely relatedsenses.
Thus, the more closely related the senses ofthe nests are, the more bridges between them willcontribute to their mutual reinforcement and to thesharing of resources between them (thus formingmeta-nests); while the bridges between more dis-tant senses will tend to fade away.
We are thus ableto build interpretative paths (possible interpretationsof the text) through emergent behaviour and to sup-press the need to use a complete graph that includesall the links between the senses from the start (as isusually the case with classical graph-based optimi-sation approaches).Through the emergence of interpretative paths,sense pairs that are closer semantically benefit froman increased ant traffic and thus tend to capture mostof the energy of the system at a faster pace, thusfavouring a faster convergence over an algorithmthat uses a local neighbourhood graph (nodes aresenses interconnected so as to represent all sensecombinations in a context window) without sacrific-ing the quality of the results.The selected answers correspond, for each wordto the nest node with the highest energy value.
Thereason for this choice over using the pheromone con-centration is that empirically, the energy level bet-ter correlates with the actual F1 scores.
In turn, theglobal Lesk score of a selected sense combinationcorrelates even better with the F1 score, which iswhy, we keep the sense combinations resulting fromeach iteration of the algorithm (highest energy nestsat each iteration) and select the one with the highestglobal Lesk score as the final solution.2.3 ParametersThis version of our ant algorithm has seven param-eters (?, Ea, Emax, E0, ?v, ?, LV ) which have aninfluence on the emergent phenomena in the system:?
The maximum amount of energy an ant cancarry, Emax and Ea the amount of energy anant can take on a node, influences how muchan ant explores the environment.
Ants cannotgo back through an edge they just crossed andhave to make circuits to come back to their nest(if the ant does not die before that).
The sizeof the circuits depend on the moment the antsswitch to return mode, hence on Emax.?
The evaporation rate of the pheromone betweencycles (?)
is one of the memories of the sys-tem.
The higher the rate is, the least the trailsfrom previous ants are given importance andthe faster interpretative paths have to be con-firmed (passed on) by new ants in order not tobe forgotten by the system.?
The initial amount of energy per node (E0)and the ant life-span (?)
influence the numberof ants that can be produced and therefore theprobability of reinforcing less likely paths.?
The odour vector length (Lv) and the propor-tion of odour components deposited by an anton a plain node (?V ) are two dependent param-eters that influence the global system memory.The higher the length of the vector, the longerthe memory of the passage of an ant is kept.
Onthe other hand, the proportion of odour compo-nents deposited has the opposite effect.Given the lack of an analytical way of determin-ing the optimal parameters of the ant colony al-gorithm, they have to be estimated experimentally,which is detailed in the following section.3 Acquisition of Parameter ValuesThe algorithms we are interested in have a certainnumber of parameters that need tuning in order toobtain the best possible score on the evaluation cor-pus.
There are three possible approaches:?
Make an educated guess about the value rangesbased on a priori knowledge about the dynam-ics of the algorithm;?
Test manually (or semi-manually) several com-binations of parameters that appear promisingand determine the influence of making smalladjustments to the values ;?
Use a learning algorithm to automate acquisi-tion of parameters values.
We present that ap-proach in the following part.2353.1 Automated Parameter EstimationTwo methods can be used to automatically acquireparameters.
The first one consists in maximizingthe F-score on an sense-annotated corpus (weak ap-proach) while the second one consist in maximizingthe global Lesk score (unsupervised approach).3.1.1 GeneralitiesBoth approaches are based on the same principle(Tchechmedjiev et al 2012).
We use a simulatedannealing algorithm (Laarhoven and Aarts, 1987)combined with a non-parametric statistical (Mann-Whitney-U test (Mann and Whitney, 1947)) test witha p-value adapted for multiple comparisons throughFalse Discovery Rate control (FDR) (Benjamini andHochberg, 1995).
The estimation algorithm oper-ates on all the parameters of the ant colony algo-rithm described above and attempts to maximise theobjective function (Global score, F1).
The reasonwhy we need to use a statistical test and FDR ratherthan using the standard SA algorithm, is that theAnt Colony Algorithm is stochastic in nature andrequires tuning to be performed over the distribu-tion of possible answers for a given set of param-eter values.
Indeed, there is no guarantee that thevalue resulting from one execution is representativeat all of the distribution.
The exact nature of the dis-tribution of answers is unknown and thus we takea sampling of the distribution as precise as can beafforded.
Thus, we require the statistical test to as-certain the significance between the scores for twoparameter configurations.3.1.2 Exogenous parameter tuningIf we have a sense-annotated corpus at our dis-posal, it is possible to directly use the F1 value ob-tained by the system on this reference to tune theparameters of the systems so as to maximise said F1score.
The main issues that arise from such meth-ods are the fact that gold standards are expensive toproduce and that there is no guarantee on the gen-erality of the contents of the gold standard.
Thus,in languages with little resources we may be un-able to obtain a gold standard and in the case oneis available, there is a potentially strong risk of overfitting.
Furthermore due to the nature of the train-ing, taking training samples in a random order forcross-validation becomes tricky.
This is why we alsowant to test another method that can tune the pa-rameters without using labelled examples.
For theevaluation, we estimated parameters on the F1 scoreon the test corpus for English and French (the onlyones available).
We used the parameters estimatedfor English for our English results for our first sys-tem run GETALP-BN1 and the French parametersfor the results on French, German, Italian, Spanish.For English we found: ?
= 26, Ea =14, Emax = 3, E0 = 34, ?v = 0.9775, ?
=0.3577, LV = 25.For French: ?
= 19, Ea = 9, Emax = 3, E0 =32, ?v = 0.9775, ?
= 0.3577, LV = 25.3.1.3 Endogenous parameter tuningIn the context of the evaluation campaign, the ab-sence of an example gold standard on the same ver-sion of the resource (synset id mismatch betweenBabelNet 1.0 and 1.1.1 2) made dubious the prospectof using parameters estimated from a gold standard.Consequently, we set out to investigate the relationbetween the F1 score of the gold standard and theGlobal Lesk Score of successive solutions through-out the execution of the algorithm.We observed that the Lesk score is highly corre-lated to the F1 score and can be used as an estimatorthereof.
The main quality criterion being the dis-criminativeness of the Lesk score compared to theF1 score (average ratio between the number of pos-sible F1 score values for a single Lesk score value),for which the correlation is a possible indicator.
Wemake the hypothesis based on the correlation that fora given specific local measure, the global score willbe an adequate estimator of the F1 score.
Our sec-ond system run GETALP-WSD-BN2 is based on theendogenous parameter estimation.
We will not listall the parameters here, as there is a different set ofparameters for each text and each language.3.2 VotingIn previous experiment, as can be expected, we haveobserved a consistent rise the F1 score when apply-ing a majority vote method on the output of severalexecutions (Schwab et al 2012).
Consequently wefollowed the same process here, and for all the runsof our system we performed 100 executions and ap-plied a majority vote (For each word, our of all se-2http://lcl.uniroma1.it/babelnet/236lected senses, take the one that has been selected themost over all the executions) on all 100 answer files.The result of this process is a single answer file andcomes with the advantage of greatly reducing thevariability of the answers.
Say this voting processis repeated over and over again 100 times, then thestandard deviation of F1 scores around the mean ismuch smaller.
Thus, we also have a good solutionsto the problem of selecting the answer that yields thehighest score, without actually having access to thegold standard.4 Runs for SemEval 2013 task 12In this section we will describe the various runs weperformed in the context of Task 12.
We will firstpresent our methodologies relating to the BabelNettagged gold standard followed by the methodologiesrelating to the WordNet tagged gold standard.4.1 BabelNet Gold Standard EvaluationIn the context of the BabelNet gold standard evalu-ation, we need to tag the words of the corpus withBabelNet synset ids.
Due to the slow speed of re-trieving Babel synsets and extracting glosses, espe-cially in the context of our extended Lesk Approach,we pre-generate a dictionary for each language thatcontains entries for each word of the corpus and thenfor each possible sense (as per BabelNet).
In theshort time allotted for the competition, we restrictourselves to building dictionaries only for the wordsof the corpus, but the process described can be ap-plied to pre-generate a dictionary for the whole ofBabelNet.Each BabelNet synset for a word is considered asa possible sense in the dictionary.
For each synsetwe retrieve the Babel senses and retain the ones thatare in the appropriate language.
Then, we retrievethe Glosses corresponding to each selected senseand combine them in as the definition correspond-ing to that particular BabelNet synset.
Furthermore,we also retrieve certain of the related synsets andrepeat the same process so as to add the related def-initions to the BabelNet synset being considered.
Inour experiments on the test corpus, we determinedthat what worked best (i.e.
English and French)was to use only relations coming from WordNet, allthe while excluding the r, gdis, gmono relationadded by BabelNet.
We observed a similar increasein disambiguation quality with the Degree (Navigliand Lapata, 2010) algorithm implementation thatcomes with BabelNet.
The r relation correspond tothe relations in BabelNet extracted from Wikipedia,whereas gdis and gmono corresponds to relationcreated using a disambiguation algorithm (respec-tively for monosemous and polysemous words).4.2 WordNet Gold Standard EvaluationIn the context of the WordNet gold standard evalua-tion, we initially thought the purpose would be to an-notate the corpus in all five languages with WordNetsense keys through alignments extracted from Ba-belNet.
As a consequence, we exploited BabelNetas a resource, merely obtaining WordNet sense keysthrough the main senses expressed in BabelNet, thatcorrespond to WordNet synsets.
Although we wereable to produce annotations for all languages, as itturns out, the WordNet evaluation was merely aimedat evaluating monolingual systems that do not sup-port BabelNet at all.
For reference, we subsequentlygenerated a dictionary from WordNet only, to gaugethe performance of our system on the evaluation asintended by the organisers.5 ResultsWe will first present the general results pertainingto Task 12, followed by a more detailed analysis ona text by text basis, as well as the comparison withresults obtained on the Semeval 2007 WSD task interms of specific parts of speech.5.1 General Results for Semeval-2013 Task 12Important: implementation issue during theevaluation period During the evaluation period,we had an implementation issue, where a parameterthat limited the size of definition was not disabledproperly.
As a consequence, when we experimentedto determine the appropriate relations to considerfor the context expansion of the glosses, we arrivedat the experimental conclusion that using all rela-tions worked best.
However, since it was already thecase with WordNet (Schwab et al 2011), we read-ily accepted that our experimental conclusion wasindeed correct.
The issue was indirectly resolvedas an unforeseen side effect of another hot-fix ap-plied shortly before the start of the evaluation period.237Given that we were not aware of the presence of alimitation on the definition length before the hot-fix,we performed all the experiments under an incorrecthypothesis which led us to an incorrect conclusion,that itself led to the results we obtained for the cam-paign.
Indeed, with no restrictions on the size of thedefinition, our official results for this task were con-sistently inferior to the random baseline across theboard.
After a thorough analysis of our runs we ob-served that the sum of local measures (global leskscore) that correlated inversely with the gold stan-dard F1 score, the opposite of what it should havebeen.
We immediately located and corrected thisbug when we realized what had caused these badresults that did not correspond at all with what weobtained on the test corpus.
After the fix, we strictlyran the same experiment without exploiting the goldstandard, so as to obtain the results we would haveobtained had the bug not been present in the firstplace.Run Lang.
P R F1 MFSBN1 EN 58.3 58.3 58.3 65.6FR 48.3 48.2 48.3 50.1DE 52.3 52.3 52.3 68.6ES 57.6 57.6 57.6 64.4IT 52.6 52.5 52.6 57.2BN2 EN 56.8 56.8 56.8 65.6FR 48.3 48.2 48.3 50.1DE 51.9 51.9 51.9 68.6ES 57.8 57.8 57.8 64.4IT 52.8 52.8 52.8 57.2WN1 EN 51.4 51.4 51.4 63.0Table 1: Results after fixing the implementation is-sue for all three of our runs, compared to the MostFrequent Sense baseline (MFS).We can see in Table 1, that after the removal ofthe implementation issues, the scores become morecompetitive and meaningful compared to the othersystem, although we remain third of the evalua-tion campaign.
We can observe that there is nolarge difference between the exogenous results (us-ing a small annotated corpus) and endogenous re-sults.
Except for the English corpus where there isa 2% increase.
The endogenous estimation, since itis performed on a text by text basis is much slowerand resource consuming.
Given that the exogenousestimation offers slightly better results and that it re-quires very little annotated data, we can concludethat in most cases the exogenous estimation will bemuch faster to obtain.5.2 A more detailed analysisIn this section we will first make a more detailedanalysis for each text on the English corpus, by look-ing where our algorithm performed best.
We restrictourselves on one language for this analysis for thesake of brevity.
As we can see in Table 2, the re-sults can vary greatly depending on the text (withina twofold range).
The system consistently performsbetter on texts from the general domain (T 4, 6, 10),often beating the first sense baseline.
For more spe-cialized texts, however, (T 2, 7, 8, 11, 12, 13) thealgorithm performs notably lower than the baseline.The one instance where the algorithm truly fails, iswhen the text in question contains many ambigu-ous entities.
Indeed for text 7, which is about foot-ball, many of the instance words to disambiguate arethe names of players and of clubs.
Intuitively, thisbehaviour is understandable and can be mainly at-tributed to the local Lesk algorithm.
Since we useglosses from the resource, that mostly remain in thegeneral domain, a better performance in matchingtexts is likely.
As for named entities, the Lesk algo-rithm is mainly meant to capture the similarity be-tween concepts and it is much more difficult to dif-ferentiate two football players from a definition overconcepts (often more general).To further outline the strength of our approach, weneed to look back further at a setting with all partsof speech being considered, namely Task 7 from Se-mEval 2007.
As can be seen in Table 3, even thoughfor adjectives and adverbs the system is slightly be-low the MFS (respectively), it has a good perfor-mance compared to graph based WSD approachesthat would be hindered by the lack of taxonomicalrelations.
For verbs the performance is lower as isconsistently observed with WSD algorithms due tothe high degree of polysemy of verbs.
For example,in the case of Degree (Navigli and Pozetto, 2012),nouns are the part of speech for which the systemperforms the best, while the scores for other parts ofspeech are somewhat lower.
Thus, we can hypoth-238Text Descr.
Len.
F1 MFS Diff.1 Gen. Env.
228 61.4 68.9 -7.52 T. Polit.
84 51.2 66.7 -15.53 T. Econ.
84 52.4 56.0 - 3.64 News.
Gen. 119 58.8 58.0 0.85 T. Econ.
74 39.2 36.5 2.76 Web Gen. 210 67.1 64.3 2.87 T. Sport.
190 34.2 60.5 -26.38 Sci.
153 63.4 67.3 -3.99 Geo.
Econ.
190 63.2 74.2 -1110 Gen. Law.
160 61.9 61.9 011 T. Sport.
125 56.8 64.0 -7.212 T. Polit.
185 64.3 73.0 -8.713 T. Econ.
130 68.5 72.6 -4.1Table 2: Text by text F1 scores compared to theMFS baseline for the English corpus (T.= Trans-lated, Gen.= General, Env.= Environment, Polit.=Politics, Econ.= Economics, Web= Internet, Sport.=Sports, Geo.= Geopolitics, Sci.= Science).A P.O.S.
F1 MFS F1 Diff1108 Noun 79.42 77.4 +1.99591 Verb 74.78 75.3 -0.51362 Adj.
82.66 84.3 -1.59208 Adv.
86.95 87.5 -0.552269 All 79.42 78.9 +0.53Table 3: Detailed breakdown of F1 score per partof speech category for Semeval-2007 Task 7, overresults resulting from a vote over 100 executionsesise that using a different local measure dependingon the part of speech may constitute an interestingdevelopment while allowing a return to a more gen-eral all-words WSD task where all parts of speechare considered, even when the resource does not of-fer taxonomical relation for the said parts of speech.6 Conclusions & PerspectivesIn this paper, we present a method based on aLesk inspired local algorithm and a global algorithmbased on ant colony optimisation.
An endogenousversion (parameter estimation based on the maximi-sation of the F-score on an annotated corpus) andan exogenous version (parameter estimation basedon the maximisation of the global Lesk score onthe corpus) of the latter algorithm do not exhibit asignificant difference in terms of the F-score of theresult.
After a more detailed analysis on a text bytext basis, we found that the algorithm performs beston general domain texts with as little named enti-ties as possible (around or above the MFS baseline).For texts of more specialized domain the algorithmconsistently performs below the MFS baseline, andfor texts with many named entities, the performanceplummets greatly slightly above the level of a ran-dom selection.
We also show that with our Leskmeasure the system is best suited for WSD in a moregeneral setting with all parts of speech, however inthe context of just nouns, it is not the most suitablelocal measure.
As we have seen from the other sys-tems, graph based local measures may be the appro-priate answer to reach the level of the best systemson this task, however it is important not to dismissthe potential of other approaches.
The quality of theresults depend on the global algorithm, however theyare also strongly bounded by the local measure con-sidered.
Our team, is headed towards investigatinglocal semantic similarity measures and towards ex-ploiting multilingual features so as to improve thedisambiguation quality.7 AcknowledgementsThe work presented in this paper was conducted inthe context of the Formicae project funded by theUniversity Grenoble 2 (Universit?
Pierre Mend?sFrance) and the Videosense project, funded by theFrench National Research Agency (ANR) underits CONTINT 2009 programme (grant ANR-09-CORD-026).References[Banerjee and Pedersen2002] Satanjee Banerjee and TedPedersen.
2002.
An adapted lesk algorithm for wordsense disambiguation using wordnet.
In CICLing2002, Mexico City, February.
[Benjamini and Hochberg1995] Yoav Benjamini andYosef Hochberg.
1995.
Controlling the False Dis-covery Rate: A Practical and Powerful Approach toMultiple Testing.
Journal of the Royal StatisticalSociety.
Series B (Methodological), 57(1):289?300.
[Brody and Lapata2008] Samuel Brody and Mirella La-pata.
2008.
Good neighbors make good senses:Exploiting distributional similarity for unsupervised239WSD.
In Proceedings of the 22nd International Con-ference on Computational Linguistics (Coling 2008),pages 65?72, Manchester, UK.
[Dorigo and St?tzle2004] Dorigo and St?tzle.
2004.
AntColony Optimization.
MIT-Press.
[Gelbukh et al005] Alexander Gelbukh, GrigoriSidorov, and Sang-Yong Han.
2005.
On some opti-mization heuristics for Lesk-like WSD algorithms.
InInternational Conference on Applications of NaturalLanguage to Information Systems ?
NLDB?05, pages402?405, Alicante, Spain.
[Hirst and St-Onge1998] G. Hirst and David D. St-Onge.1998.
Lexical chains as representations of context forthe detection and correction of malapropisms.
Word-Net: An electronic Lexical Database.
C. Fellbaum.
Ed.MIT Press.
Cambridge.
MA, pages 305?332.
Ed.
MITPress.
[Laarhoven and Aarts1987] P.J.M.
Laarhoven and E.H.L.Aarts.
1987.
Simulated annealing: theory and appli-cations.
Mathematics and its applications.
D.
Reidel.
[Lesk1986] Michael Lesk.
1986.
Automatic sense dis-ambiguation using mrd: how to tell a pine cone froman ice cream cone.
In Proceedings of SIGDOC ?86,pages 24?26, New York, NY, USA.
ACM.
[Mann and Whitney1947] H. B. Mann and D. R. Whitney.1947.
On a Test of Whether one of Two Random Vari-ables is Stochastically Larger than the Other.
The An-nals of Mathematical Statistics, 18(1):50?60.
[Miller1995] George A. Miller.
1995.
Wordnet: A lexicaldatabase.
ACM, Vol.
38(No.
11):p.
1?41.
[Monmarch?2010] N. Monmarch?.
2010.
Artificial Ants.Iste Series.
John Wiley & Sons.
[Navigli and Lapata2010] Roberto Navigli and MirellaLapata.
2010.
An experimental study of graph con-nectivity for unsupervised word sense disambiguation.IEEE Trans.
Pattern Anal.
Mach.
Intell., 32:678?692,April.
[Navigli and Pozetto2012] Roberto Navigli and Si-mone Paolo Pozetto.
2012.
Babelnet: Theautomatic construction, evaluation and applica-tion of a wide-coverage multilingual semanticnetwork.
Artificial Intelligence, 193:217?250.http://dx.doi.org/10.1016/j.artint.2012.07.004.
[Navigli et al013] Roberto Navigli, David Jurgens, andDaniele Vannella.
2013.
Semeval-2013 task 12: Mul-tilingual word sense disambiguation.
In Proceedingsof the 7th International Workshop on Semantic Eval-uation (SemEval 2013), in conjunction with the Sec-ond Joint Conference on Lexical and ComputationalSemantics (*SEM 2013), Atlanta, Georgia, 14-15 June.
[Ponzetto and Navigli2010] Simone Paolo Ponzetto andRoberto Navigli.
2010.
Knowledge-rich word sensedisambiguation rivaling supervised systems.
In Pro-ceedings of the 48th Annual Meeting of the Associationfor Computational Linguistics, pages 1522?1531.
[Resnik1995] Philip Resnik.
1995.
Using informationcontent to evaluate semantic similarity in a taxonomy.In Proceedings of the 14th international joint confer-ence on Artificial intelligence - Volume 1, IJCAI?95,pages 448?453, San Francisco, CA, USA.
MorganKaufmann Publishers Inc.[Schwab et al011] Didier Schwab, J?r?me Goulian, andNathan Guillaume.
2011.
D?sambigu?sation lexicalepar propagation de mesures semantiques locales par al-gorithmes a colonies de fourmis.
In TALN, Montpel-lier (France), Juillet.
[Schwab et al012] Didier Schwab, J?r?me Goulian, An-don Tchechmedjiev, and Herv?
Blanchon.
2012.
Antcolony algorithm for the unsupervised word sense dis-ambiguation of texts: Comparison and evaluation.
InProceedings of COLING?2012, Mumbai (India), De-cember.
To be published.
[Schwab et al013] Didier Schwab, Jer?me Goulian, andAndon Tchechmedjiev.
2013.
Theoretical and empir-ical comparison of artificial intelligence methods forunsupervised word sense disambiguation.
Int.
J. ofWeb Engineering and Technology.
In Press.
[Tchechmedjiev et al012] Andon Tchechmedjiev,J?r?me Goulian, Didier Schwab, and Gilles S?rasset.2012.
Parameter estimation under uncertainty withsimulated annealing applied to an ant colony basedprobabilistic wsd algorithm.
In Proceedings ofthe First International Workshop on OptimizationTechniques for Human Language Technology, pages109?124, Mumbai, India, December.
The COLING2012 Organizing Committee.
[Wu and Palmer1994] Zhibiao Wu and Martha Palmer.1994.
Verbs semantics and lexical selection.
In Pro-ceedings of the 32nd annual meeting of Association forComputational Linguistics, ACL ?94, pages 133?138,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.240
