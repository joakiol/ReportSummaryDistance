Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 339?348,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsAspect Extraction through Semi-Supervised ModelingArjun Mukherjee Bing LiuDepartment of Computer Science Department of Computer ScienceUniversity of Illinois at Chicago University of Illinois at ChicagoChicago, IL 60607, USA Chicago, IL 60607, USAarjun4787@gmail.com liub@cs.uic.eduAbstractAspect extraction is a central problem insentiment analysis.
Current methods eitherextract aspects without categorizing them,or extract and categorize them usingunsupervised topic modeling.
Bycategorizing, we mean the synonymousaspects should be clustered into the samecategory.
In this paper, we solve theproblem in a different setting where theuser provides some seed words for a fewaspect categories and the model extractsand clusters aspect terms into categoriessimultaneously.
This setting is importantbecause categorizing aspects is a subjectivetask.
For different application purposes,different categorizations may be needed.Some form of user guidance is desired.
Inthis paper, we propose two statisticalmodels to solve this seeded problem, whichaim to discover exactly what the userwants.
Our experimental results show thatthe two proposed models are indeed able toperform the task effectively.1 IntroductionAspect-based sentiment analysis is one of the mainframeworks for sentiment analysis (Hu and Liu,2004; Pang and Lee, 2008; Liu, 2012).
A key taskof the framework is to extract aspects of entitiesthat have been commented in opinion documents.The task consists of two sub-tasks.
The first sub-task extracts aspect terms from an opinion corpus.The second sub-task clusters synonymous aspectterms into categories where each categoryrepresents a single aspect, which we call an aspectcategory.
Existing research has proposed manymethods for aspect extraction.
They largely fallinto two main types.
The first type only extractsaspect terms without grouping them into categories(although a subsequent step may be used for thegrouping, see Section 2).
The second type usesstatistical topic models to extract aspects and groupthem at the same time in an unsupervised manner.Both approaches are useful.
However, in practice,one also encounters another setting, wheregrouping is not straightforward because fordifferent applications the user may need differentgroupings to reflect the application needs.
Thisproblem was reported in (Zhai et al, 2010), whichgave the following example.
In car reviews,internal design and external design can be regardedas two separate aspects, but can also be regarded asone aspect, called ?design?, based on the level ofdetails that the user wants to study.
It is alsopossible that the same word may be put in differentcategories based on different needs.
However,(Zhai et al, 2010) did not extract aspect terms.
Itonly categorizes a set of given aspect terms.In this work, we propose two novel statisticalmodels to extract and categorize aspect termsautomatically given some seeds in the userinterested categories.
It is thus able to best meet theuser?s specific needs.
Our models also jointlymodel both aspects and aspect specific sentiments.The first model is called SAS and the secondmodel is called ME-SAS.
ME-SAS improves SASby using Maximum-Entropy (or Max-Ent for short)priors to help separate aspects and sentiment terms.However, to train Max-Ent, we do not needmanually labeled training data (see Section 4).339In practical applications, asking users to providesome seeds is easy as they are normally experts intheir trades and have a good knowledge what areimportant in their domains.Our models are related to topic models ingeneral (Blei et al, 2003) and joint models ofaspects and sentiments in sentiment analysis inspecific (e.g., Zhao et al, 2010).
However, thesecurrent models are typically unsupervised.
None ofthem can use seeds.
With seeds, our models arethus semi-supervised and need a differentformulation.
Our models are also related to the DF-LDA model in (Andrzejewski et al, 2009), whichallows the user to set must-link and cannot-linkconstraints.
A must-link means that two terms mustbe in the same topic (aspect category), and acannot-link means that two terms cannot be in thesame topic.
Seeds may be expressed with must-links and cannot-links constraints.
However, ourmodels are very different from DF-LDA.
First ofall, we jointly model aspect and sentiment, whileDF-LDA is only for topics/aspects.
Joint modelingensures clear separation of aspects from sentimentsproducing better results.
Second, our way oftreating seeds is also different from DF-LDA.
Wediscuss these and other related work in Section 2.The proposed models are evaluated using a largenumber of hotel reviews.
They are also comparedwith two state-of-the-art baselines.
Experimentalresults show that the proposed models outperformthe two baselines by large margins.2 Related WorkThere are many existing works on aspectextraction.
One approach is to find frequent nounterms and possibly with the help of dependencyrelations (Hu and Liu, 2004; Popescu and Etzioni,2005; Zhuang et al, 2006; Blair-Goldensohn et al,2008; Ku et al, 2006; Wu et al, 2009;Somasundaran and Wiebe, 2009; Qiu et al, 2011).Another approach is to use supervised sequencelabeling (Liu, Hu and Cheng 2005; Jin and Ho,2009; Jakob and Gurevych, 2010; Li et al, 2010;Choi and Cardie, 2010; Kobayashi et al, 2007; Yuet al, 2011).
Ma and Wan (2010) also exploitedcentering theory, and (Yi et al, 2003) usedlanguage models.
However, all these methods donot group extracted aspect terms into categories.Although there are works on grouping aspect terms(Carenini et al, 2005; Zhai et al, 2010; Zhai et al,2011; Guo et al, 2010), they all assume that aspectterms have been extracted beforehand.In recent years, topic models have been used toperform extraction and grouping at the same time.Existing works are based on two basic models,pLSA (Hofmann, 1999) and LDA (Blei et al,2003).
Some existing works include discoveringglobal and local aspects (Titov and McDonald,2008), extracting key phrases (Branavan et al,2008), rating multi-aspects (Wang et al, 2010;Moghaddam and Ester, 2011), summarizingaspects and sentiments (Lu et al, 2009), andmodeling attitudes (Sauper et al, 2011).
In (Lu andZhai, 2008), a semi-supervised model wasproposed.
However, their method is entirelydifferent from ours as they use expert reviews toguide the analysis of user reviews.Aspect and sentiment extraction using topicmodeling come in two flavors: discovering aspectwords sentiment wise (i.e., discovering positiveand negative aspect words and/or sentiments foreach aspect without separating aspect andsentiment terms) (Lin and He, 2009; Brody andElhadad, 2010, Jo and Oh, 2011) and separatelydiscovering both aspects and sentiments (e.g., Meiet al, 2007; Zhao et al, 2010).
Zhao et al (2010)used Maximum-Entropy to train a switch variableto separate aspect and sentiment words.
We adoptthis method as well but with no use of manuallylabeled data in training.
One problem with theseexisting models is that many discovered aspectsare not understandable/meaningful to users.
Changet al (2009) stated that one reason is that theobjective function of topic models does not alwayscorrelate well with human judgments.
Our seededmodels are designed to overcome this problem.Researchers have tried to generate ?meaningful?and ?specific?
topics/aspects.
Blei and McAuliffe(2007) and Ramage et al (2009) used documentlabel information in a supervised setting.
Hu et al(2011) relied on user feedback during Gibbssampling iterations.
Andrzejewski et al (2011)incorporated first-order logic with Markov LogicNetworks.
However, it has a practical limitationfor reasonably large corpora since the number ofnon-trivial groundings can grow to O(N2) where Nis the number of unique tokens in the corpus.Andrzejewski et al (2009) used another approach(DF-LDA) by introducing must-link and cannot-link constraints as Dirichlet Forest priors.
Zhai etal.
(2011) reported that the model does not scale up340when the number of cannot-links go beyond 1000because the number of maximal cliques Q(r) in aconnected component of size |r| in the cannot-linkgraph is exponential in r. Note that we could stillexperiment with DF-LDA as our problem size isnot so large.
We will show in Section 4 that theproposed models outperform it by a large margin.3 Proposed Seeded ModelsThe standard LDA and existing aspect andsentiment models (ASMs) are mostly governed bythe phenomenon called ?higher-order co-occurrence?
(Heinrich, 2009), i.e., based on howoften terms co-occur in different contexts1.
Thisunfortunately results in many ?non-specific?
termsbeing pulled and clustered.
We employ seed sets toaddress this issue by ?guiding?
the model to groupsemantically related terms in the same aspect thusmaking the aspect more specific and related to theseeds (which reflect the user needs).
For easypresentation, we will use aspect to mean aspectcategory from now on.
We replace the multinomialdistribution over words for each aspect (as inASMs) with a special two-level tree structureddistribution.
The generative process of ASMsassumes that each vocabulary word isindependently (i.e., not dependent upon otherword-aspect association) and equally probable tobe associated with any aspect.
Due to higher-orderco-occurrences, we find conceptually differentterms yet related in contexts (e.g., in hotel domainterms like stain, shower, walls in aspect1 w1 co-occurring with w2 which in turn co-occurs with w3 denotes asecond-order co-occurrence between w1 and w3.Maintenance; bed, linens, pillows in aspectCleanliness) equally probable of emission for anyaspect.
Figure 1(a) shows an example tree.
Uponadding the seed sets {bed, linens, pillows} and{staff, service}, the prior structure now changes tothe correlated distribution in Figure 1 (b).
Thus,each aspect has a top level distribution over non-seed words and seed sets.
Each seed set in eachaspect further has a second level distribution overseeds in that seed set.
The aspect term (word)emission now requires two steps: first sampling atlevel one to obtain a non-seed word or a seed set.
Ifa non-seed word is sampled we emit it else wefurther sample at the second seed set level and emita seed word.
This ensures that seed words togetherhave either all high or low aspect associations.Furthermore, seed sets preserve conjugacy betweenrelated concepts and also shape more specificaspects by clustering based on higher order co-occurrences with seeds rather than only withstandard one level multinomial distribution overwords (or terms) alone.3.1 SAS ModelWe now present the proposed Seeded Aspect andSentiment model (SAS).
Let ????
denote the entries in our vocabulary where ?
?is the number ofunique non-seed terms.
Let there be ?
seed sets??????
where each seed set ??
is a group of semantically related terms.
Let ???????
,????????
denote T aspect and aspect specific sentimentmodels.
Also let ??,?
denote the aspect specific distribution of seeds in the seed set ??.
Following the approach of (Zhao et al, 2010), we too assumethat a review sentence usually talks about oneFigure 1: Prior structure:  (a) Standard ASMs, (b) Two-level tree structured distribution.
Graphical models in platenotation: (c) SAS and (d) ME-SAS.a?
a?
a?Dawarau Nd, saz a?Sda?A a?OTC a?
a?ATa?Oa?
a?A a?OTC a?
a?ATa?Oa?a?a?a?Daza?Sdawarau Nd, s ax(a)(b) (d) (c)Seeds:{staff, service}{linens, bed, pillows}room stain bed staff linens service shower pillows walls friendly?Astaff service bed linens pillows?Astain walls            shower            friendly room ?
?341aspect.
A review document ????
comprises of ??
sentences and each sentence ?
?
??
has ??,?words.
Also, let ??????
denote the sentence ?
of document ?.
To distinguish between aspect and sentimentterms, we introduce an indicator (switch) variable??,?,?
?
?
?
?, ???
for the ??
?term of ??????,???,?,?.
Further, let ??,?
denote the distribution of aspects and sentiments in ??????.
The generative process of the SAS model (see Figure 1(c)) is given by:1.
For each aspect ??
?
?1, ?
, ??:i.
Draw    ????~????????
ii.
Draw a distribution over terms and seed sets ????~????????
a) For each seed set ?
?
??
?, ?
, ???
Draw a distribution over seeds ??,??~???????2.
For each (review) document ?
?
?1, ?
, ??:i.
Draw ???~???????
ii.
For each sentence ?
?
?1, ?
, ???
: a) Draw ??,??~????????
?b) Draw ??,??~???????
?c) For each term ??,?,??where???
?
?1, ?
, ??,??:I.
Draw ??,?,??~?????????????,?
?, ??,?,?
?
?
?
?, ???II.
if ??,?,?
?
?
??
// ??,?,?
is a sentimentEmit ??,?,??~?????????,??
?else // ??,?,?
?
?
??
?, ??,?,?
is an aspectA.
Draw ??,?,??~?????????,??
?B.
if ??,?,?
?
?
?
// non-seed termEmit ??,?,?
?
??
?,?,?else // ??,?,?
is some seed set index say ?
?,?,?Emit ??,?,??~????,??,?
?,?,?We employ collapsed Gibbs sampling (Griffithsand Steyvers, 2004) for posterior inference.
As ?and ?
are at different hierarchical levels, we derivetheir samplers separately as follows:????,?
?
?????
?,?, ??
?,?, ???,?
?, ???,??
?????,???
?
????
???,???
??,?
?
????????,???,??????????,???,???,??????
?
?????,?,???,?
????????,?,???,?
??,?????????
???,?????.??,?????,???????.??,????(1)????,?,?
?
?????
?,?, ??
?,?,?, ???,?,?
?, ??
?,?,?, ??,?
?
?, ??,?,?
?
??
???,??
??,?,??????,????
??,?,??|???
???
|???
??,????,?,??????,??
??,?,????????,??
??,?,????(2)????,?,?
?
???
?
?
??????????
??,?,??,???,?,?????,?,????,?
??,?,??|??|??
??,??
?????,????
????????
????,??
??,?,??????,??
??,?,????????,????,?,???????
; ???
?
????,??,???????,????,???????????
??,????,?,??????,??
??,?,????????,????,?,????
; ?
?, ?
?
??
(3)where ?????
?
??
????????????????????
??????????????
?is the multinomial Beta function.
??,??
is the number of times term ?
wasassigned to aspect ?
as an opinion/sentiment word.??,??,?
is the number of times non-seed term ?
?
??
was assigned to aspect ?
as an aspect.
??,?,??,?
is the number of times seed term ?
?
?
??
was assigned to aspect ?
as an aspect.
??,?????.
is the number of sentences in document ?
that were assigned toaspect ?.
??,??
and ??,??
denote the number of terms in ??????
that were assigned to aspects and opinions respectively.
??,??
is the number of times any term of seed set ??
was assigned to aspect ?.
Omission of a latter index denoted by [] in the above notationrepresents the corresponding row vector spanningover the latter index.
For example, ??,???,?
????,????,?
, ?
, ??,????,?
?
and (?)
denotes the marginalized sum over the latter index.
The subscript ?
?, ?denotes the counts excluding assignments of allterms in ??????.
?
?, ?, ?
denotes counts excluding?
?,?,?.We perform hierarchical sampling.
First, anaspect is sampled for each sentence ??,?
using Eq.
(1).
After sampling the aspect, we sample ?
?,?,?.The probability of ??,?,?
being an opinion orsentiment term, ????,?,?
?
???
is given by Eq.
(2).However, for ????,?,?
?
???
we have two cases: (a)the observed term ?
?
??,?,?
?
??
or (b) does not belong to any seed set, ?
?, ?
?
?
?, i.e., w is an non-seed term.
These cases are dealt in Eq.
(3).Asymmetric Beta priors: Hyper-parameters ?, ?O,?A are not very sensitive and the heuristic valuessuggested in (Griffiths and Steyvers, 2004) usuallyhold well in practice (Wallach et al 2009).However, the smoothing hyper-parameter ?
(Figure 1(c)) is crucial as it governs the aspect orsentiment switch.
Essentially, ??,?~?????????
is the probability of emitting an aspect term2 in ??????
with concentration parameter ?
and base measure??
?
??
?, ???.
Without any prior belief, uniform base measures ??
?
??
?
0.5 are used resulting in symmetric Beta priors.
However, aspects are oftenmore probable than sentiments in a sentence (e.g.,?The beds, sheets, and bedding were dirty.?).
Thus,it is more principled to employ asymmetric priors.Using a labeled set of sentences, ???????
?, where we know the per sentence probability of aspectemission (??,?
), we can employ the method of moments to estimate the smoothing hyper-parameter ?
?
??
?, ???:??
?
?
????????
?
1?
, ??
?
??
???
?
1?
; ??
?
????,?
?, ?
?
??????,??
(4)2 ??,?,?~?????????????,??.
??,?
, 1 ?
??,?
are the success and failureprobability of emitting an aspect/sentiment term.3423.2 ME-SAS ModelWe can further improve SAS by employingMaximum Entropy (Max-Ent) priors for aspect andsentiment switching.
We call this new model ME-SAS.
The motivation is that aspect and sentimentterms play different syntactic roles in a sentence.Aspect terms tend to be nouns or noun phraseswhile sentiment terms tend to be adjectives,adverbs, etc.
POS tag information can be elegantlyencoded by moving ??,?
to the term plate (see Figure 1(d)) and drawing it from a Max-Ent??,??,?
; ??
model.
Let???,?,???????????
?
??????,?,??
?, ?????,?,?
, ?????,?,??
?, ??,?,?
?
1, ?
?,?,?, ??,?,?
?1?
denote the feature vector associated with ??,?,??
encoding lexical and POS features of the previous,current and next term.
Using a training data set, wecan learn Max-Ent priors.
Note that unliketraditional Max-Ent training, we do not needmanually labeled data for training (see Section 4for details).
For ME-SAS, only the sampler for theswitch variable r changes as follows:????,?,?
?
?????
?,?, ??
?,?,?, ???,?,?
?, ??
?,?,?, ??,?
?
?, ??,?,?
?
??
???,??
??,?,??????,????
??,?,??|???
???
|???
?????
???????,?,?,???????
??
?????
???????,?,?,??????
??????,???
(5)????,?,?
?
???
?
?
????????
??,?,??,???,?,?????,?,????,?
??,?,??|??|??
??,??
?????,????
????????
???????
???????,?,?,???????
??
?????
???????,?,?,??????
??????,??????
; ???
?
????,??,???????,????,???????????
?????
???????,?,?,???????
??
?????
???????,?,?,??????
??????,???
; ?
?, ?
?
??
(6)where ????
are the parameters of the learned Max-Ent model corresponding to the ?
binary featurefunctions ????
of Max-Ent.4 ExperimentsThis section evaluates the proposed models.
Sincethe focus in this paper is to generate high qualityaspects using seeds, we will not evaluatesentiments although both SAS and ME-SAS canalso discover sentiments.
To compare theperformance with our models, we use two existingstate-of-the-art models, ME-LDA (Zhao et al2010) and DF-LDA (Andrzejewski et al, 2009).As discussed in Section 2, there are two mainflavors of aspect and sentiment models.
The firstflavor does not separate aspect and sentiment, andthe second flavor uses a switch to perform theseparation.
Since our models also perform aswitch, it is natural to compare with the latterflavor, which is also more advanced.
ME-LDA isthe representative model in this flavor.
DF-LDAadds constraints to LDA.
We use our seeds togenerate constraints for DF-LDA.
While ME-LDAcannot consider constraints, DF-LDA does notseparate sentiments and aspects.
Apart from othermodeling differences, our models can do both,which enable them to produce much better results.Dataset and Settings: We used hotel reviews fromtripadvisor.com.
Our corpus consisted of 101,234reviews and 692,783 sentences.
Punctuations, stopwords 3, and words appearing less than 5 times inthe corpus were removed.For all models, the posterior inference wasdrawn after 5000 Gibbs iterations with an initialburn-in of 1000 iterations.
For SAS and ME-SAS,we set ?
= 50/T, ?A = ?O = 0.1 as suggested in(Griffiths and Steyvers, 2004).
To make the seedsmore effective, we set the seed set word-distribution hyper-parameter ?
to be much largerthan ?A, the hyper-parameter for the distributionover seed sets and aspect terms.
This results inhigher weights to seeded words which in turnguide the sampler to cluster relevant terms better.A more theoretical approach would involveperforming hyper-parameter estimation (Wallachet al, 2009) which may reveal specific propertiesof the dataset like the estimate of ?
(indicating howdifferent documents are in terms of their latentsemantics), ?
(suggesting how large the groups offrequently appearing aspect and sentiment termsare) and ?
(giving a sense of which and how largegroupings of seeds are good).
These are interestingquestions and we defer it to our future work.
In thiswork, we found that the setting ?
= 250, a largervalue compared to ?A, produced good results.For SAS, the asymmetric Beta priors wereestimated using the method of moments (Section3.1).
We sampled 500 random sentences from thecorpus and for each sentence identified the aspects.We thus computed the per-sentence probability ofaspect emission (??,?)
and used Eq.
(4) to compute the final estimates, which give ?a = 2.35, ?b = 3.44.
To learn the Max-Ent parameters ?
of ME-SAS,we used the sentiment lexicon 4 of (Hu and Liu,2004) to automatically generate training data (nomanual labeling).
We randomly sampled 1000terms from the corpus which have appeared at least3 http://jmlr.csail.mit.edu/papers/volume5/lewis04a/a11-smart-stop-list/english.stop 4 http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar34320 times (to ensure that the training set isreasonably representative of the corpus).
Of those1000 terms if they appeared in the sentimentlexicon, they were treated as sentiment terms, elseaspect terms.
Clearly, labeling words not in thesentiment lexicon as aspect terms may not alwaysbe correct.
Even with this noisy automatically-labeled data, the proposed models can producegood results.
Since ME-LDA used manuallylabeled training data for Max-Ent, we againrandomly sampled 1000 terms from our corpusappearing at least 20 times and labeled them asaspect terms or sentiment terms, so this labeleddata clearly has less noise than our automaticallylabeled data.
For both ME-SAS and ME-LDA weused the corresponding feature vector of eachlabeled term (in the context of sentences where itoccurs) to train the Max-Ent model.
As DF-LDArequires must-link and cannot-link constraints, weused our seed sets to generate intra-seed set must-link and inter-seed set cannot-link constraints.
Forits hyper-parameters, we used the default values inthe package5 (Andrzejewski et al, 2009).Setting the number of topics/aspects in topicmodels is often tricky as it is difficult to know the5 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.htmlexact number of topics that a corpus has.
Whilenon-parametric Bayesian approaches (Teh et al,2006) do exist for estimating the number of topics,T, they strongly depend on the hyper-parameters(Heinrich, 2009).
As we use fixed hyper-parameters, we do not learn T from Bayesian non-parametrics.
We used 9 major aspects (T = 9)based on commonsense knowledge of what peopleusually talk about hotels and some experiments.These are Dining, Staff, Maintenance, Check In,Cleanliness, Comfort, Amenities, Location andValue for Money (VFM).
However, it is importantto note that the proposed models are flexible anddo not need to have seeds for every aspect/topic.Our experiments simulate the real-life situationwhere the user may not know all aspects or haveno seeds for some aspects.
Thus, we providedseeds only to the first 6 of the 9 aspects/topics.
Wewill see that without seeds for all aspects, ourmodels not only can improve the seeded aspectsbut also improve the non-seeded aspects.4.1 Qualitative ResultsThis section shows some qualitative results to givean intuitive feeling of the results from differentmodels.
Table 1 shows the aspect terms andsentiment terms discovered by the 4 models forAspect(seeds)ME-SAS SAS ME-LDA DF-LDAAspect Sentiment Aspect Sentiment Aspect Sentiment TopicStaff  (staff service waiter hospitality upkeep)attendantmanager waitress maintenance bartender waiters housekeepingreceptionist waitstaff janitorfriendly attentive polite niceclean pleasant slow courteous rude professionalattendantwaiter waitress manager maintenancehelpful waiters housekeepingreceptionistpolitefriendlynice dirty comfortableniceclean politeextremely courteous efficientstaffmaintenance room upkeeplinens room-service receptionistwait pillow waitersfriendly nice courteous extremely niceclean politelittle helpfulbetterstafffriendly helpful beds front room comfortable large receptionist housekeepingCleanliness(curtains restroom floor beds cleanliness)carpets hall towels bathtub couch mattress linens wardrobe spa pillowclean dirty comfortable fresh wet filthy extra stainfront wornhallcarpets towels pillow stain mattressfilthy linensinterior bathtubcleandirty fresh old nice goodenough newfront friendlycleanlinessfloor carpets bed lobby bathroomstaff closet spa d?corclean good dirtyhot large nicefresh thin new littlecleanpool beach carpets parking bed bathroom nice comfortable suiteComfort(comfort mattress furniture couch pillows)bedding bedcover sofa linens bedroom suites d?cor comforter blanket futoncomfortable clean soft nice uncomfortable spacious hard comfy dirty quietbedlinens sofa bedcoverhard bedroom privacy double comfy futonnicedirty comfortable large cleanbest spaciousonly bigextrabedmattress suites furniturelighting d?cor room bedroom hallway carpetgreat clean awesome dirty best comfortable soft nice only extrabedmattressnice stay lighting lobby comfort room dirty sofaTable 1: Top ranked aspect and sentiment words in three aspects (please see the explanation in Section 4.1).
?344three aspects.
Due to space limitations, we areunable to show all 6 aspects for which we haveseeds.
Since DF-LDA cannot separate aspects andsentiments, we only show its topics (aspects).
Red(bold) colored words show semantic clusteringerrors or inappropriate terms for different groups.It is important to note that we judge the resultsbased on how they are related to the user seeds(which represent the user need).
The judgment is tosome extent subjective.
What we reported here arebased on our judgments what are appropriate andwhat are not for each aspect.
For SAS, ME-SASand ME-LDA, we mark sentiment terms as errorswhen they are grouped under aspects as thesemodels are supposed to separate sentiments andaspects.
For DF-LDA, the situation is different as itis not meant to separate sentiment and aspectterms, we use red italic font to indicate thoseadjectives which are aspect specific adjectives (seemore discussion below).
Our judgment may beslightly unfair to ME-LDA and DF-LDA as theirresults may make sense in some other ways.However, that is precisely the purpose of thiswork, to produce results that suit the user?s needrather than something generic.We can see from Table 1 that ME-SAS performsthe best.
Next in order are SAS, ME-LDA, andDF-LDA.
We see that only providing a handful ofseeds (5) for the aspect Staff, ME-SAS candiscover highly specific words like manager,attendant, bartender, and janitor.
By specific, wemean they are highly related to the given seeds.While SAS also discovers specific wordsbenefiting from seeds, relying on Beta priors foraspect and sentiment switching was less effective.Next in performance is ME-LDA which althoughproduces reasonable results in general, severalaspect terms are far from what the user wantsbased on the seeds, e.g., room, linens, wait, pillow.Finally, we observe that DF-LDA does not performwell either.
One reason is that it is unable toseparate aspects and sentiments.
Althoughencoding the intra-seed set must-link and inter-seed set cannot-link constraints in DF-LDAdiscovers some specific words as ME-SAS, theyare much lower in the ranked order and hence donot show up in the top 10 words in Table 1.
AsDF-LDA is not meant to perform extraction and togroup both aspect and sentiment terms, we relaxthe errors of DF-LDA due to correct aspectspecific sentiments (e.g., friendly, helpful for Staffare correct aspect specific sentiments, but stillregard incorrect sentiments like front, comfortable,large as errors) placed in aspect models.
We callthis model DF-LDA-Relaxed.4.2 Quantitative ResultsTopic models are often evaluated quantitativelyusing perplexity and likelihood on held-out testdata (Blei et al, 2003).
However, perplexity doesnot reflect our purpose since our aim is not topredict whether an unseen document is likely to bea review of some particular aspect.
Nor are wetrying to evaluate how well the unseen review datafits our seeded models.
Instead our focus is toevaluate how well our learned aspects perform inclustering specific terms guided by seeds.
So wedirectly evaluate the discovered aspect terms.
Noteagain we do not evaluate sentiment terms as theyare not the focus of this paper 6.
Since aspectsproduced by the models are rankings and we donot know the number of correct aspect terms, anatural way to evaluate these rankings is to useprecision @ n (or p@n), where n is a rank position.Varying number of seeds: Instead of a fixednumber of seeds, we want to see the effect of thenumber of seeds on aspect discovery.
Table 2reports the average p@n vs. the number of seeds.The average is a two-way averaging.
The firstaverage was taken over all combinations of actualseeds selected for each aspect, e.g., when thenumber of seeds is 3, out of the 5 seeds in eachaspect, all ?53?
combinations of seeds were tried and the results averaged.
The results were furtheraveraged over p@n for 6 aspects with seeds.
Westart with 2 seeds and progressively increase themto 5.
Using only 1 seed per seed set (or per aspect)has practically no effect because the top leveldistribution ??
encodes which seed sets (and non-seed words) to include; the lower-level distribution?
constrains the probabilities of the seed words tobe correlated for each of the seed sets.
Thus,having only one seed per seed set will result insampling that single word whenever that seed set ischosen which will not have the effect of correlatingseed words so as to pull other words based on co-occurrence with constrained seed words.
FromTable 2, we can see that for all models p@nprogressively improves as the number of seedsincreases.
Again ME-SAS performs the bestfollowed by SAS and DF-LDA.6 A qualitative evaluation of sentiment extraction based on Table 1 yieldsthe following order: ME-SAS, SAS, ME-LDA.345Effect of seeds on non-seeded aspects: Here wecompare all models aspect wise and see the resultsof seeded models SAS and ME-SAS on non-seeded aspects (Table 3).
Shaded cells in Table 3give the p@n values for DF-LDA, DF-LDA-Relaxed, SAS, and ME-SAS on three non-seededaspects (Amenities, Location, and VFM)7.We see that across all the first 6 aspects with (5)seeds ME-SAS outperforms all other models bylarge margins in all top 3 ranked buckets p@10,p@20 and p@30.
Next in order are SAS, ME-LDAand DF-LDA.
For the last three aspects which didnot have any seed guidance, we find somethinginteresting.
Seeded models SAS and especiallyME-SAS result in improvements of non-seededaspects too.
This is because as seeds facilitateclustering specific and appropriate terms in seededaspects, which in turn improves precision on non-seeded aspects.
This phenomenon can be clearlyseen in Table 1.
In aspect Staff of ME-LDA, wefind pillow and linens being clustered.
This is not a?flaw?
of the model per se, but the point here ispillow and linens happen to co-occur many timeswith other words like maintenance, staff, andupkeep because ?room-service?
generally includesstaff members coming and replacing linens andpillow covers.
Although pillow and linens arerelated to Staff, strictly speaking they aresemantically incorrect because they do notrepresent the very concept ?Staff?
based on theseeds (which reflect the user need).
Presence of7 Note that Tables 2 and 3 are different runs of the model.
The variations in theresults are due to the random initialization of the Gibbs sampler.seed sets in SAS and ME-SAS result in pullingsuch words as linens and pillow (due to seeds likebeds and cleanliness in the aspect Cleanliness) andranking them higher in the aspect Cleanliness (seeTable 1) where they make more sense than Staff.Lastly, we also note that the improvements in non-seeded aspects are more pronounced for ME-SASthan SAS as SAS encounters more switching errorswhich counters the improvement gained by seeds.In summary, the averages over all aspects (Table3 last row) show that the proposed seeded modelsSAS and ME-SAS outperform ME-LDA, DF-LDAand even DF-LDA-Relaxed considerably.5 ConclusionThis paper studied the issue of using seeds todiscover aspects in an opinion corpus.
To ourknowledge, no existing work deals with thisproblem.
Yet, it is important because in practicethe user often has something in mind to find.
Theresults obtained in a completely unsupervisedmanner may not suit the user?s need.
To solve thisproblem, we proposed two models SAS and ME-SAS which take seeds reflecting the user needs todiscover specific aspects.
ME-SAS also does notneed any additional help from the user in its Max-Ent training.
Our results showed that both modelsoutperformed two state-of-the-art existing modelsME-LDA and DF-LDA by large margins.AcknowledgmentsThis work is supported in part by National ScienceFoundation (NSF) under grant no.
IIS-1111092.No.
of Seeds DF-LDA DF-LDA-Relaxed SAS ME-SAS P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@302 0.51 0.53 0.49 0.67 0.69 0.70 0.69 0.71 0.67 0.74 0.72 0.703 0.53 0.54 0.50 0.71 0.70 0.71 0.71 0.72 0.70 0.78 0.75 0.724 0.57 0.56 0.53 0.73 0.73 0.73 0.75 0.74 0.73 0.83 0.79 0.765 0.59 0.57 0.54 0.75 0.74 0.75 0.77 0.76 0.74 0.86 0.81 0.77Table 2: Average p@n of the seeded aspects with the no.
of seeds.Aspect ME-LDA DF-LDA DF-LDA-Relaxed SAS ME-SASP@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30Dining 0.70 0.65 0.67 0.50 0.60 0.63 0.70 0.70 0.70 0.80 0.75 0.73 0.90 0.85 0.80Staff 0.60 0.70 0.67 0.40 0.65 0.60 0.60 0.75 0.67 0.80 0.80 0.70 1.00 0.90 0.77Maintenance 0.80 0.75 0.73 0.40 0.55 0.56 0.60 0.70 0.73 0.70 0.75 0.76 0.90 0.85 0.80Check In 0.70 0.70 0.67 0.50 0.65 0.60 0.80 0.75 0.70 0.80 0.70 0.73 0.90 0.80 0.76Cleanliness 0.70 0.75 0.67 0.70 0.70 0.63 0.70 0.75 0.70 0.80 0.75 0.70 1.00 0.85 0.83Comfort 0.60 0.70 0.63 0.60 0.65 0.50 0.70 0.75 0.63 0.60 0.75 0.67 0.90 0.80 0.73Amenities 0.80 0.80 0.67 0.70 0.65 0.53 0.90 0.75 0.73 0.90 0.80 0.70 1.00 0.85 0.73Location 0.60 0.70 0.63 0.50 0.60 0.56 0.70 0.70 0.67 0.60 0.70 0.63 0.70 0.75 0.67VFM 0.50 0.55 0.50 0.40 0.50 0.46 0.60 0.60 0.60 0.50 0.50 0.50 0.60 0.55 0.53Avg.
0.67 0.70 0.65 0.52 0.62 0.56 0.70 0.72 0.68 0.72 0.72 0.68 0.88 0.80 0.74Table 3: Effect of performance on seeded and non-seeded aspects (5 seeds were used for the 6 seeded aspects).
?346ReferencesAndrzejewski, D., Zhu, X. and Craven, M. 2009.Incorporating domain knowledge into topic modelingvia Dirichlet forest priors.
Proceedings ofInternational Conference on Machine Learning(ICML).Andrzejewski, D., Zhu, X. and Craven, M. and Recht,B.
2011.
A framework for incorporating generaldomain knowledge into latent Dirichlet alocationusing first-order logic.
Proceedings of the 22ndInternational Joint Conferences on ArtificialIntelligence (IJCAI).Blair-Goldensohn, S., Hannan, K., McDonald, R.,Neylon, T., Reis, G. A. and Reynar, J.
2008.
Buildinga sentiment summarizer for local service reviews.Proceedings of WWW-2008 workshop on NLP in theInformation Explosion Era.Blei, D., Ng, A. and Jordan, M. 2003.
Latent dirichletallocation.
The Journal of Machine LearningResearch 3: 993-1022.Blei D. and McAuliffe, J.
2007.
Supervised topicmodels.
Neural Information Processing Systems(NIPS).Branavan, S., Chen, H., Eisenstein J. and Barzilay, R.2008.
Learning document-level semantic propertiesfrom free-text annotations.
Proceedings of theAnnual Meeting of the Association forComputational Linguistics (ACL).Brody, S. and Elhadad, S. 2010.
An UnsupervisedAspect-Sentiment Model for Online Reviews.Proceedings of The 2010 Annual Conference of theNorth American Chapter of the ACL (NAACL).Carenini, G., Ng, R. and Zwart, E. 2005.
Extractingknowledge from evaluative text.
Proceedings ofThird Intl.
Conf.
on Knowledge Capture (K-CAP-05).Chang, J., Boyd-Graber, J., Wang, C.  Gerrish, S. andBlei, D. 2009.
Reading tea leaves: How humansinterpret topic models.
In Neural InformationProcessing Systems (NIPS).Choi, Y. and Cardie, C. 2010.
Hierarchical sequentiallearning for extracting opinions and their attributes.Proceedings of Annual Meeting of the Associationfor Computational (ACL).Griffiths, T. and Steyvers, M. 2004.
Finding scientifictopics.
Proceedings of National Academy of Sciences(PNAS).Guo, H., Zhu, H., Guo, Z., Zhang, X. and Su, X.
2009.Product feature categorization with multilevel latentsemantic association.
Proceedings of ACMInternational Conference on Information andKnowledge Management (CIKM).Heinrich, G. 2009.
A Generic Approach to TopicModels.
Proceedings of the European Conference onMachine Learning and Principles and Practice ofKnowledge Discovery in Databases (ECML/PKDD).Hofmann, T. 1999.
Probabilistic latent semanticindexing.
Proceedings of Conference on Uncertaintyin Artificial Intelligence (UAI).Hu, Y., Boyd-Graber, J. and Satinoff, B.
2011.Interactive topic modeling.
Proceedings of AnnualMeeting of the Association for ComputationalLinguistics (ACL), 2011.Hu, M. and Liu, B.
2004.
Mining and summarizingcustomer reviews.
International Conference onKnowledge Discovery and Data Mining (ICDM).Jakob, N. and Gurevych, I.
2010.
Extracting OpinionTargets in a Single-and Cross-Domain Setting withConditional Random Fields.
Proceedings ofConference on Empirical Methods in NaturalLanguage Processing (EMNLP).Jin, W. and Ho, H. 2009.
A novel lexicalized HMM-based learning framework for web opinion mining.Proceedings of International Conference on MachineLearning (ICML).Jo, Y. and Oh, A.
2011.
Aspect and sentimentunification model for online review analysis.
ACMConference in Web Search and Data Mining(WSDM).Kobayashi, N., Inui, K. and Matsumoto, K. 2007.Extracting aspect-evaluation and aspect-of relationsin opinion mining.
Proceedings of the 2007 JointConference on Empirical Methods in NaturalLanguage Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL).Ku, L., Liang, Y. and Chen, H. 2006.
Opinionextraction, summarization and tracking in news andblog corpora.
Proceedings of AAAI Symposium onComputational Approaches to Analyzing Weblogs(AAAI-CAAW'06).Li, F., Han, C., Huang, M., Zhu, X. Xia, Y., Zhang, S.and Yu, H. 2010.
Structure-aware review mining andsummarization.
International Conference onComputational Linguistics (COLING).Lin, C. and He, Y.
2009.
Joint sentiment/topic model forsentiment analysis.
Proceedings of ACMInternational Conference on Information andKnowledge Management (CIKM).Liu, B.
2012.
Sentiment Analysis and Opinion Mining.347Morgan & Claypool publishers (to appear in June2012).Liu, B, M. Hu, and J. Cheng.
2005.
Opinion Observer:Analyzing and comparing opinions on the web.Proceedings of International Conference on WorldWide Web (WWW).Lu, Y., Zhai, C. and Sundaresan, N. 2009.
Rated aspectsummarization of short comments.
Proceedings ofInternational Conference on World Wide Web(WWW).Lu, Y. and Zhai, C. 2008.
Opinion Integration ThroughSemi-supervised Topic Modeling.
Proceedings of the17th International World Wide Web Conference(WWW).Ma, T. and Wan, X.
2010.
Opinion target extraction inChinese news comments.
Proceedings of Coling2010 Poster Volume (COLING).Mei, Q., Ling, X., Wondra, M., Su, H. and Zhai, C.2007.
Topic sentiment mixture: modeling facets andopinions in weblogs.
Proceedings of InternationalConference on World Wide Web (WWW).Moghaddam, S. and Ester, M. 2011.
ILDA:interdependent LDA model for learning latentaspects and their ratings from online product reviews.Proceedings of the Annual ACM SIGIR Internationalconference on Research and Development inInformation Retrieval (SIGIR).Pang, B. and Lee, L. 2008.
Opinion mining andsentiment analysis.
Foundations and Trends inInformation Retrieval.Popescu, A. and Etzioni, O.
2005.
Extracting productfeatures and opinions from reviews.
Proceedings ofConference on Empirical Methods in NaturalLanguage Processing (EMNLP).Qiu, G., Liu, B., Bu, J. and Chen, C. 2011.
OpinionWord Expansion and Target Extraction throughDouble Propagation.
Computational Linguistics.Ramage, D., Hall, D., Nallapati, R. and Manning, C.2009.
Labeled LDA: a supervised topic model forcredit attribution in multi-labeled corpora.Proceedings of the Conference on Empirical Methodsin Natural Language Processing (EMNLP).Sauper, C., Haghighi, A. and Barzilay, R. 2011.
Contentmodels with attitude.
Proceedings of the 49th AnnualMeeting of the Association for ComputationalLinguistics (ACL).Somasundaran, S. and Wiebe, J.
2009.
Recognizingstances in online debates, Proceedings of the 47thAnnual Meeting of the ACL and the 4th IJCNLP ofthe AFNLP.Teh, Y., Jordan, M., Beal, M. and Blei, D. 2006.Hierarchical Dirichlet Processes.
In Journal of theAmerican Statistical Association (JASA).Titov, I. and McDonald, R. 2008.
Modeling onlinereviews with multi-grain topic models.
Proceedingsof International Conference on World Wide Web(WWW).Wallach, H., Mimno, D. and McCallum, A.
2009.Rethinking LDA: Why priors matter.
In NeuralInformation Processing Systems (NIPS).Wang, H., Lu, Y. and Zhai, C. 2010.
Latent aspectrating analysis on review text data: a ratingregression approach.
Proceedings of ACM SIGKDDInternational Conference on Knowledge Discoveryand Data Mining (KDD).Wu, Y., Zhang, Q., Huang, X. and Wu, L. 2009.
Phrasedependency parsing for opinion mining.
Proceedingsof Conference on Empirical Methods in NaturalLanguage Processing (EMNLP).Yi, J., Nasukawa, T., Bunescu, R. and Niblack, W.2003.
Sentiment analyzer: Extracting sentimentsabout a given topic using natural language processingtechniques.
Proceedings of IEEE InternationalConference on Data Mining (ICDM).Yu, J., Zha, Z. J., Wang, M. and Chua, T. S. 2011.Aspect ranking: identifying important productaspects from online consumer reviews.
Proceedingsof the 49th Annual Meeting of the Association forComputational Linguistics, Association forComputational Linguistics (ACL).Zhai, Z., Liu, B. Xu, H. and Jia, P. 2010.
GroupingProduct Features Using Semi-Supervised Learningwith Soft-Constraints.
Proceedings of InternationalConference on Computational Linguistics(COLING).Zhai, Z., Liu, B. Xu, H. and Jia, P. 2011.
ConstrainedLDA for Grouping Product Features in OpinionMining.
Proceedings of Pacific-Asia Conference onKnowledge Discovery and Data Mining (PAKDD).Zhao, W., Jiang, J., Yan, Y. and Li, X.
2010.
Jointlymodeling aspects and opinions with a MaxEnt-LDAhybrid.
Proceedings of Conference on EmpiricalMethods in Natural Language Processing (EMNLP).Zhuang, L., Jing, F. and Zhu, X.
2006.
Movie reviewmining and summarization.
Proceedings ofInternational Conference on Information andKnowledge Management (CIKM).348
