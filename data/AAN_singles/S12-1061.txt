First Joint Conference on Lexical and Computational Semantics (*SEM), pages 449?453,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsSoft Cardinality: A Parameterized Similarity Function for Text ComparisonSergio JimenezUniversidad Nacionalde Colombia, Bogota,Ciudad Universitariaedificio 453, oficina 220sgjimenezv@unal.edu.coClaudia BecerraUniversidad Nacionalde Colombia, Bogotacjbecerrac@unal.edu.coAlexander GelbukhCIC-IPNAv.
Juan Dios B?tiz,Av.
Mendiz?bal, Col.Nueva Industrial Vallejo,CP 07738, DF, M?xicogelbukh@gelbukh.comAbstractWe present an approach for the construction of textsimilarity functions using a parameterized resem-blance coefficient in combination with a softenedcardinality function called soft cardinality.
Our ap-proach provides a consistent and recursive model,varying levels of granularity from sentences to char-acters.
Therefore, our model was used to comparesentences divided into words, and in turn, words di-vided into q-grams of characters.
Experimentally,we observed that a performance correlation func-tion in a space defined by all parameters was rel-atively smooth and had a single maximum achiev-able by ?hill climbing.?
Our approach used only sur-face text information, a stop-word remover, and astemmer to tackle the semantic text similarity task6 at SEMEVAL 2012.
The proposed method ranked3rd (average), 5th (normalized correlation), and 15th(aggregated correlation) among 89 systems submit-ted by 31 teams.1 IntroductionSimilarity is the intrinsic ability of humans and someanimals to balance commonalities and differences whencomparing objects that are not identical.
Although thereis no direct evidence of how this process works in liv-ing organisms, some models have been proposed fromthe cognitive perspective (Sj?berg, 1972; Tversky, 1977;Navarro and Lee, 2004).
On the other hand, several simi-larity models have been proposed in mathematics, statis-tics, and computer science among other fields.
Particu-larly in AI, similarity measures play an important role inthe construction of intelligent systems that are requiredto exhibit behavior similar to humans.
For instance, inthe field of natural language processing, text similarityfunctions provide estimates of the human similarity judg-ments related to language.
In this paper, we combine el-ements from the perspective of cognitive psychology andcomputer science to propose a model for building simi-larity functions suitable for the task of semantic text sim-ilarity.We identify four main families of text similarity func-tions: i) resemblance coefficients based on sets (e.g.
Jac-card?s (1901) and Dice?s (1945) coefficients) ii) functionsin metric spaces (e.g.
cosine tf-idf similarity (Salton etal., 1975)); iii) the edit distance family of measures (e.g.Levenstein (1966) distance, LCS (Hirschberg, 1977));and iv) hybrid approaches ((Monge and Elkan, 1996; Co-hen et al, 2003; Corley and Mihalcea, 2005; Jimenez etal., 2010)).
All of these measures use a subdivision ofthe texts in different granularity levels, such as q-gramsof words, words, q-grams of characters, syllables, andcharacters.
Among hybrid approaches, Monge-Elkan?smeasure and soft cardinality methods are recursive andcan be used to build similarity functions at any arbitraryrange of granularity.
For instance, it is possible to con-struct a similarity function to compare sentences basedon a function that compares words, which in turn can beconstructed based on a function that compares bigrams ofcharacters.
Furthermore, hybrid approaches can integratesimilarity functions that are not based on the representa-tion of the surface of text, such as semantic relatednessmeasures (Pedersen et al, 2004).Text similarity measures can be static or adaptivewhether they are binary functions using only surface in-formation of the two texts, or are functions that suitto a wider set of texts.
For instance, measures usingtf-idf weights adapt their results to the set of texts inwhich those weights were obtained.
Other approacheslearn parameters of the similarity function from a set oftexts to optimize a particular task.
For instance, Ris-tad and Yianilos (1998) and Bikenko and Mooney (2003)learned the costs of edit operations for all characters foran edit-distance function in a name-matching task.
Othermachine-learning approaches have also been proposed tobuild adaptive measures in name-matching (Bilenko and449Mooney, 2003) and textual-entailment tasks.However, those machine-learning-based methods foradaptive similarity suffer from sparseness and the ?curseof dimensionality?.
For example, the method of Ristadand Yianilos learns n2 + 2n parameters, where n is thesize of the character set.
Similarly, dimensionality in themethod of Bilenko and Mooney is the size of the dataset vocabulary.
This issue is addressed primarily throughmachine-learning algorithms, which reduce the dimen-sionality of the problem regularizating to achieve enoughgeneralization to get an acceptable performance differ-ence between training and test data.
Although machine-learning solutions have proven effective for many appli-cations, the principle of Occam?s razor suggests that itshould be preferable to have a model that explains thedata with a smaller number of significant parameters.
Inthis paper, we seek a simpler adaptive similarity modelwith few meaningful parameters.Our proposed similarity model starts with acardinality-based resemblance coefficient (i.e.
Dice?scoefficient 2|A?B|/|A|+|B|) and generalizes it to modelthe effect of asymmetric selection of the referent.
Thiseffect is a human factor discovered by Tversky (1977)that affects judgments of similarity, i.e.
humans tendsto select the more prominent stimulus as the referentand the less salient stimulus as the object.
Some ofTversky?s examples are ?the son resembles the father?rather than ?the father resembles the son?, ?an ellipse islike a circle?
not ?a circle is like an ellipse?, and ?NorthKorea is like Red China?
rather than ?Red China is likeNorth Korea?.
Generally speaking, ?the variant is moresimilar to the prototype than vice versa?.
In the previousexample, stimulus salience is associated with the promi-nence of the country; for text comparison we associateword salience with tf-idf weights.
At the text level, weassociate salience with a combination of word-salience,inter-word similarity, and text length provided by softcardinality.
Experimentally, we observed that this effectalso occurs when comparing texts, but not necessarilyin the same direction suggested by Tversky.
We usedthis effect to improve the performance of our similaritymodel.
In addition, we proposed a parameter that biasesthe function to generate greater or lower similarityscores.Finally, in our model we used a soft cardinality func-tion (Jimenez et al, 2010) instead of the classical set car-dinality.
Just as classical cardinality counts the numberof elements which are not identical in a set, soft cardi-nality uses an auxiliary inter-element similarity functionto make a soft count.
For instance, the soft cardinality ofa set with two very similar (but not identical) elementsshould be a real number closer to 1.0 instead of 2.0.The rest of the paper is organized as follows.
In Sec-tion 2 we briefly present soft cardinality.
In Section 3 theproposed parameterized similarity model is presented.
InSection 4 experimental validation is provided using 8 datasets annotated with human similarity judgments from the?Semantic-Text-Similarity?
task at SEMEVAL-2012.
Fi-nally, a brief discussion is provided in Section 5 and con-clusions are presented in Section 6.2 Soft CardinalityLet A ={a1, a2, .
.
.
, a|A|}and B ={b1, b2, .
.
.
, b|B|}be two sets being compared.
When each element of aior bj has an associated weight wai or wbj the problemof comparing those sets becomes a weighted similarityproblem.
This means that such model has to take intoaccount not only the commonalities and diferences, butalso their weights.
Also, if an (|A ?
B|) ?
(|A ?
B|)similarity matrix S is available, the problem becomes aweighted soft similarity problem because the common-ality between A and B has to be computed not onlywith identical elements, but also with elements with adegree of similarity.
The values of S can be obtainedfrom an auxiliary similarity function sim(a, b) that sat-isfies at least non-negativity (?a, b, sim(a, b) ?
0) andreflexivity (?a, sim(a, a) = 1).
Other postulates such assymmetry (?a, b, sim(a, b) = sim(b, a)) and triangle in-equality1 (?a, b, c, sim(a, c) ?
sim(a, b) + sim(b, c)?1) are not strictly necessary.Jimenez et al (2010) proposed a set-based weightedsoft-similarity model using resemblance coefficients andthe soft cardinality function instead of classical set car-dinality.
The idea of calculating the soft cardinality isto treat elements ai in set the A as sets themselves andto treat inter-element similarities as the intersections be-tween the elements sim(ai, aj) = |ai ?
aj |.
Therefore,the soft cardinality of set A becomes |A|?=????|A|i=1ai??
?.Since it is not feasible to calculate this union, they pro-posed the following weighted approximation using |ai| =wai :|A|?sim '|A|?iwai?
?|A|?jsim(ai, aj)p??
?1(1)Parameter p ?
0 in eq.1 controls the ?softeness?
ofthe cardinality, taking p = 1 its no-effect value and leav-ing element similarities unchanged for the calculation ofsoft cardinality.
When p is large, all sim(?, ?)
resultslower than 1 are transformed into a number approaching0.
As a result, the soft cardinality behaves like the clas-sical cardinality, returning the addition of all the weightsof the elements, i.e |A|?sim '?|A|i wai .
When p is closeto 0, all sim(?.?)
results are transformed approaching1triangle inequality postulate for similarity is derived from its coun-terpart for dissimilarity (distance) distance(a, b) = 1?
sim(a, b).450into a number approaching 1, making the soft cardinal-ity returns the average of the weights of the elements, i.e.|A|?sim '1|A|?|A|i wai .
Jimenez et al used p = 2 andidf weights in the same name-matching task proposed byCohen et al (Cohen et al, 2003).3 A Parameterized Similarity ModelAs we mentioned above, Tvesky proposed that humanstends to select more salient stimulus as referent and lesssalient stimulus as object when comparing two objects Aand B.
Based on the idea of Tvesrky, the similarity be-tween two objects can be measured as the ratio betweenthe salience of commonalities and the salience of the lesssalient object.
Drawing an analogy between objects assets and salience as the cardinality of a set, the salienceof commonalities is |A ?
B|, and the salience of the lesssalient object is min(|A|, |B|).
This ratio is known as theoverlap coefficient Overlap(A,B) = |A?B|min(|A|,|B|) .
How-ever, whether |A| < |B| or whether |A|  |B|, the sim-ilarity obtained by Overlap(A,B) is the same.
Hence,we propose to model the selecction of the referent usinga parameter ?
that makes a weighted average betweenmin(|A|, |B|) and max(|A|, |B|), controling the degreeto which the asymmetric referent-selection effect is con-sidered in the similarity measure.SIM(A,B) =|A ?B|+ bias?max (|A|, |B|) + (1?
?
)min (|A|, |B|)(2)The parameter ?
controls the degree to which theasymmetric referent-selection effect is considered in thesimilarity measure.
Its no-effect value is ?
= 0.5, sothe eq.2 becomes the Dice coefficient.
Moreover, when?
= 0 the eq.2 becomes the overlap coefficient, other-wise when ?
= 1 the opposite effect is modeled.In addition, we introduced a bias parameter in eq.
2that increases the commonalities of each object pair bythe same amount, and so it measures the degree to whichall of the objects have commonalities among each other.Clearly, the non-effect value for the bias parameter is 0.Besides, the bias parameter has the effect of biasingSIM(A,B) by considering any pair ?A,B?
more sim-ilar if bias > 0 and their cardinalities are small.
Con-versely, the similarity between pairs with large cardinal-ities is promoted if bias < 0.
However, as higher valuesof biasmay result in similarity scores outside the interval[0, 1], additional post-procesing to limit the similarities inthis interval may be required.The proposed parameterized text similarity measure isconstructed by combining the proposed resemblance co-efficient in eq.2 and the soft cardinality in eq.1.
Theresulting measure has three parameters: ?, bias, and p.Weights wai can be idf weights.
This measure takes two?
Asymetric referent selection at text levelbias Bias parameter at text levelp Soft cardinality exponent at word levelwai Element weights at word levelq1, q2 q1-grams or [q1 : q2]spectra word division?sim Asymetric referent selection at q-gram levelbiassim Bias parameter q-gram levelTable 1: Parameters of the proposed similarity modeltexts represented as sets of words and returns their simi-larity.
The auxiliary similarity function sim(a, b) neces-sary for calculating the soft cardinality is another param-eter of the model.
This auxiliary function is any functionthat can compare two words and return a similarity scorein [0, 1].To build this sim(a, b) function, we chose to reuse theeq.2 but representing words as sets of q-grams or rangesof q-grams of different sizes, i.e.
[q1 : q2] spectra.
Q-grams are consecutive overlapped substrings of size q.For instance, the word ?saturday?
divided into trigramsis {/sa, sat, atu, tur, urd, rda, day, ay.}.
The character?.?
is a padding character added to differenciate q-gramsat the begining or end of the string.
A [2 : 4]spectrais the combined representation of a word using ?in thisexample?
bigrams, trigrams and quadgrams (Jimenez andGelbukh, 2011).
The cardinality function for sim() wasthe classical set cardinality.
Clearly, the soft cardinal-ity could be used again if an auxiliary similarity func-tion for character comparison and a q-gram weightingmechanism are provided to allow another level of recur-sion.
Therefore, the parameters of sim(a, b) are: ?sim,biassim.
Finally, the entire set of parameters of the pro-posed similarity model is shown in Table 1.4 Experimental Setup and ResultsThe aim of these experiments is to observe the behaviorof the parameters of our similarity model and verify if thehypothesis that motivated these parameters can be con-firmed experimentally.
The experimental data are 8 datasets (3 for training and 5 for test) proposed in the ?Seman-tic Text Similarity?
task at SEMEVAL-2012.
Each dataset consist of a set of pairs of text annotated with human-similarity judgments on a scale of 0 to 5.
Each similarityjudgment is the average of the judgments provided by 5human judges.
For a comprehensible description of thetask see(Agirre et al, 2012).For the experiments, all data sets were pre-processedby converting to lowercase characters, English stop-words removal and stemming using Porter stemmer(Porter, 1980).
The performance measure used for all ex-periments was the Pearson correlation r.4514.1 Model ParametersIn order to make an initial exploration of the parame-ters in Table 1, we set q1 = 2 (i.e.
bigrams) and usedwai = idf(ai).
For other parameters, we started with allthe non-effect values, i.e.
?
= 0.5, bias = 0, p = 1,?sim = 0.5 and biassim = 0.
Plots in Figure 1 showthe Pearson correlation measured in each of the data sets.For each graph, the non-effect configuration was used andeach parameter varies in the range indicated in each hor-izontal axis.
For best viewing, the non-effect values oneach graph are represented by a vertical line.In this exploration of the parameters it was noted thateach parameter defines a function for the performancemeasure that is smooth and with an unique global maxi-mum.
Therefore, we assumed that the join performancefunction in the space defined by the 5 parameters alsohad the same properties.
The parameters for each data setshown in Table 2 were found using a simple hill-climbingalgorithm.
Different q-gram and spectra configurationswere tested manually.5 DiscussionIt is possible to observe from the results in Figure 1 andTable 2 that the behavior of the parameters is similar inpairs of data sets that have training and test parts.
Thisbehavior is evident in both MSRvid and MSRpar datasets, but it is less evident in SMTeuroparl.
Furthermore,the optimal parameters for training data sets MSRvid andMSRpar were similar to those of their test data sets.
Inconclusion, the proposed set of parameters provides a setof features that characterize a data set for the text similar-ity task.Regarding the effect of asymmetry in referent selecc-tion proposed by Tvesrky, it was observed that ?at textlevel?
the MSRvid data sets were the only ones that sup-ported this hypothesis (?
= 0.32, 0.42).
The remainingdata sets showed the opposite effect (?
> 0.5).
That is,annotators chose the most salient document (the longer)as the referent when a pair of texts is being compared.The Table 2 also shows that the optimal parametersfor all data sets were different from the no-effect valuescombination.
This result can also be seen in Figure 1,where curves crossed the vertical line of no-effect value?in most of the cases?
in values different to the optimum.Clearly, the proposed set of parameters is useful for ad-justing the similarity function for a particular data set andtask.6 ConclusionsWe have proposed a new parameterized similarity func-tion for text comparison and a method for finding the op-timal values of the parameter set when training data isavailable.
In addition, the parameter ?, which was moti-vated by the similarity model of Tversky, proved effectivein obtaining better performance, but we could not con-firm the Tvesky?s hypothesis that humans tends to selectthe object (text) with less stimulus salience (text length)as the referent.
This result might have occurred becauseeither the stimulus salience is not properly represented bythe length of the text, or Tversky?s hypothesis cannot beextended to text comparison.The proposed similarity function proved effective inthe task of ?Semantic Text Similarity?
in SEMEVAL2012.
Our method obtained the third best average cor-relation on the 5 test data sets.
This result is remarkablebecause our method only used data from the surface ofthe texts, a stop-word remover, and a stemmer, which canbe even be considered as a baseline method.AcknowledgmentsThis research was funded by the Systems and IndustrialEngineering Department, the Office of Student Welfareof the National University of Colombia, Bogot?, andthrought a grant from the Colombian Department forScience, Technology and Innovation Colciencias, proj.110152128465.
The second author recognizes the sup-port from Mexican Government (SNI, COFAA-IPN, SIP20113295, CONACYT 50206-H) and CONACYT?DSTIndia (proj.
?Answer Validation through Textual Entail-ment?
).ReferencesEneko Agirre, Daniel Cer, Mona Diab, and Gonzalez-AgirreAitor.
2012.
SemEval-2012 task 6: A pilot on semantictextual similarity.
In Proc.
of the 6th International Workshopon Semantic Evaluation (SemEval 2012), in conjunction withthe First Joint Conference on Lexical and Computational Se-mantics (*SEM 2012)., Montreal,Canada.Mikhail Bilenko and Raymond J. Mooney.
2003.
Adaptive du-plicate detection using learnable string similarity measures.In Proc.
of the ninth ACM SIGKDD international confer-ence on Knowledge discovery and data mining, pages 39?48,Washington, D.C. ACM.William W Cohen, Pradeep Ravikumar, and Stephen E Fien-berg.
2003.
A comparison of string distance metrics forName-Matching tasks.
In Proc.
of the IJCAI2003 Workshopon Information Integration on the Web II Web03.Courtney Corley and Rada Mihalcea.
2005.
Measuring the se-mantic similarity of texts.
In Proc.
of the ACL Workshopon Empirical Modeling of Semantic Equivalence and Entail-ment, Stroudsburg, PA.Lee R. Dice.
1945.
Measures of the amount of ecologic associ-ation between species.
Ecology, pages 297?302.Daniel S. Hirschberg.
1977.
Algorithms for the longest com-mon subsequence problem.
J. ACM, 24(4):664?675.4520.60.70.8correlationp0.30.40.50 1 2 3 4 5 6 7 8Pearsoncorrelation?0 0.5 1 1.5bias-15 -5 5 15?sim-0.5 0.5 1.5biassim-4 -2 0 2 4MSRvid(tr) MSRvid(te) MSRpar(tr) MSRpar(te) SMTeur(tr) SMTeur(te) OnWN SMTnews no effect-5 -3 -1 1 3 5Figure 1: Exploring similarity model parameters around their no-effect values (tr=training, te=test)Parameters correl.
Official ResultsData set [q1 : q2] ?
bias p ?sim biassim r SoftCard BestMSRpar.training [4] 0.62 1.14 0.77 -0.04 -0.38 0.6598 n/a n/aMSR.par.test [4] 0.60 1.02 0.9 -0.02 -0.4 0.6335 0.64051 0.7343MSRvid.training [1:4] 0.42 -0.80 2.28 0.18 0.08 0.8323 n/a n/aMSRvid.test [1:4] 0.32 -0.80 1.88 1.08 0.08 0.8579 0.8562 0.8803SMTeuroparl.training [2:4] 0.74 -0.06 0.91 1.88 2.90 0.6193 n/a n/aSMTeuroparl.test [2:4] 0.84 -0.16 0.71 1.78 3.00 0.5178 0.51522 0.5666OnWN.test [2:5] 0.88 -0.62 1.36 -0.02 -0.70 0.7202 0.71091 0.7273SMTnews.test [1:4] 0.88 0.88 1.57 0.80 3.21 0.5344 0.48331 0.60851Result obtained using Jaro-Winkler (Winkler, 1990) measure as sim(a, b) function between words.2Result obtained using generalized Monge-Elkan measure p = 4, no stop-words removal and no term weights(Jimenez et al, 2009).Table 2: Results with optimized parameters and official SEMEVAL 2012 resultsPaul Jaccard.
1901.
Etude comparative de la distribution floraredans une portion des alpes et des jura.
Bulletin de la Soci?t?Vaudoise des Sciences Naturelles, pages 547?579.Sergio Jimenez and Alexander Gelbukh.
2011.
SC spectra: alinear-time soft cardinality approximation for text compari-son.
In Proc.
of the 10th international conference on Artifi-cial Intelligence, MICAI?11, Puebla, Mexico.Sergio Jimenez, Claudia Becerra, Alexander Gelbukh, andFabio Gonzalez.
2009.
Generalized Monge-Elkan methodfor approximate text string comparison.
In ComputationalLinguistics and Intelligent Text Processing, volume 5449 ofLNCS, pages 559?570.Sergio Jimenez, Fabio Gonzalez, and Alexander Gelbukh.2010.
Text comparison using soft cardinality.
In String Pro-cessing and Information Retrieval, volume 6393 of LNCS,pages 297?302.Vladimir I. Levenshtein.
1966.
Binary codes capable of cor-recting deletions, insertions, and reversals.
Soviet PhysicsDoklady, 10(8):707?710.Alvaro E. Monge and Charles Elkan.
1996.
The field matchingproblem: Algorithms and applications.
In Proc.
KDD-96,pages 267?270, Portland, OR.Daniel Navarro and Michael D. Lee.
2004.
Common and dis-tinctive features in stimulis representation: A modified ver-sion of the contrast model.
Psychonomic Bulletin & Review,11:961?974.Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi.2004.
WordNet::Similarity: measuring the relatedness ofconcepts.
In Proc.
HLT-NAACL?Demonstration Papers,Stroudsburg, PA.Martin Porter.
1980.
An algorithm for suffix stripping.
Pro-gram, 3(14):130?137.Eric S. Ristad and Peter N. Yianilos.
1998.
Learning stringedit distance.
IEEE Transactions on Pattern Analysis andMachine Intelligence, 20(5):522?532.Gerard Salton, A. Wong, and C.S.
Yang.
1975.
A vector spacemodel for automatic indexing.
Com.
ACM, 18(11):613?620.L.
Sj?berg.
1972.
A cognitive theory of similarity.
G?teborgPsychological Reports.Amos Tversky.
1977.
Features of similarity.
PsychologicalReview, 84(4):327?352.William E. Winkler.
1990.
String comparator metrics and en-hanced decision rules in the Fellegi-Sunter model of recordlinkage.
In Proc.
of the Section on Survey Research Methods.453
