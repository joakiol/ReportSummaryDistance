Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 313?319,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsExploring Stylistic Variation with Age and Income on TwitterLucie Flekova?Ubiquitous Knowledge Processing LabDepartment of Computer ScienceTechnische Universit?at Darmstadtwww.ukp.tu-darmstadt.deLyle Ungar and Daniel Preot?iuc-PietroComputer & Information ScienceUniversity of Pennsylvaniaungar@cis.upenn.edudanielpr@sas.upenn.eduAbstractWriting style allows NLP tools to adjustto the traits of an author.
In this paper,we explore the relation between stylisticand syntactic features and authors?
age andincome.
We confirm our hypothesis thatfor numerous feature types writing styleis predictive of income even beyond age.We analyze the predictive power of writ-ing style features in a regression task ontwo data sets of around 5,000 Twitter userseach.
Additionally, we use our validatedfeatures to study daily variations in writingstyle of users from distinct income groups.Temporal stylistic patterns not only providenovel psychological insight into user behav-ior, but are useful for future research andapplications in social media.1 IntroductionThe widespread use of social media enables re-searchers to examine human behavior at a scalehardly imaginable before.
Research in text profil-ing has recently shown that a diverse set of usertraits is predictable from language use.
Examplesrange from demographics such as age (Rao et al,2010), gender (Burger et al, 2011; Bamman etal., 2014), popularity (Lampos et al, 2014), oc-cupation (Preot?iuc-Pietro et al, 2015a) and loca-tion (Eisenstein et al, 2010) to psychological traitssuch as personality (Schwartz et al, 2013) or men-tal illness (De Choudhury et al, 2013) and theirinterplay (Preotiuc-Pietro et al, 2015).
To a largeextent, the prominent differences captured by textare topical: adolescents post more about school, fe-males about relationships (Sap et al, 2014) andsport fans about their local team (Cheng et al,?Project carried out during a research stay at the Univer-sity of Pennsylvania2010).
Writing style and readability offer a dif-ferent insight into who the authors are.
This canhelp applications such as cross-lingual adaptationswithout direct translation, for text simplificationclosely matching the reader?s age, level of educa-tion and income or tailored to the specific momentthe document is presented.
Recently, Hovy andS?gaard (2015) have shown that the age of theauthors should be taken into account when build-ing and using part-of-speech taggers.
Likewise,socioeconomic factors have been found to influ-ence language use (Labov, 2006).
Understandingthese biases and their underlying factors in detailis important to develop NLP tools without socio-demographic bias.Writing style measures have initially been cre-ated to be applied at the document level, wherethey are often used to assess the quality of a docu-ment (Louis and Nenkova, 2013) or a summariza-tion (Louis and Nenkova, 2014) , or even to predictthe success of a novel (Ashok et al, 2013).
In con-trast to these document-level studies, we adopt auser-centric approach to measuring stylistic differ-ences.
We examine writing style of users on Twitterin relation to their age and income.
Both attributesshould be closely related to writing style: users ofolder age write on average more standard-conform(up to a certain point), and higher income is an indi-cator of education and conscientiousness (Judge etal., 1999), which determines writing style.
Indeed,many features that aim to measure the complexityof the language use have been developed in orderto study human cognitive abilities, e.g., cognitivedecline (Boy?e et al, 2014; Le et al, 2011).The relationship between age and language hasbeen extensively studied by psychologists, andmore recently by computational linguists in variouscorpora, including social media.
Pennebaker et al(2003) connect language use with style and per-sonality, while Schler et al (2006) automatically313classified blogs text into three classes based onself-reported age using part-of-speech features.
Jo-hannsen et al (2015) uncover some consistent agepatterns in part-of-speech usage across languages,while Rosenthal and McKeown (2011) studies theuse of Internet specific phenomena such as slang,acronyms and capitalisation patterns.
Preot?iuc-Pietro et al (2016) study differences in paraphrasechoice between older and younger Twitter usersas a measure of style.
Nguyen et al (2013) ana-lyzed the relationship between language use andage, modelled as a continuous variable.
They foundsimilar language usage trends for both genders,with increasing word and tweet length with age,and an increasing tendency to write more gram-matically correct, standardized text.
Such findingsencourage further research in the area of measuringreadability, which not only facilitates adjusting thetext to the reader (Danescu-Niculescu-Mizil et al,2011), but can also play an important role in iden-tifying authorial style (Pitler and Nenkova, 2008).Davenport and DeLine (2014) report negative cor-relation between tweet readability (i.e., simplicity)and the percentage of people with college degree inthe area.
Eisenstein et al (2011) employ languageuse as a socio-demographic predictor.In this paper we analyze two data sets of millionsof tweets produced by thousands of users annotatedwith their age and income.
We define a set of fea-tures ranging from readability and style to syntacticfeatures.
We use both linear and non-linear ma-chine learning regression methods to predict andanalyze user income and age.
We show that writingstyle measures give large correlations with bothage and income, and that writing style is predictiveof income even beyond age.
Finally, Twitter dataallows the unique possibility to study the variationin writing with time.
We explore the effects of timeof day in user behavior dependent in part on thesocio-demographic group.2 DataWe study two large data sets of tweets.
Each dataset consists of users and their historical record oftweet content, profile information and trait level fea-tures extracted with high precision from their pro-file information.
All data was tokenized using theTrendminer pipeline (Preot?iuc-Pietro et al, 2012),@-mentions and URL?s collapsed, automatically fil-tered for English using the langid.py tool (Lui andBaldwin, 2012) and part-of-speech tagged usingthe ArkTweet POS tagger (Gimpel et al, 2011).Income (D1) First, we use a large data set con-sisting of 5,191 Twitter users mapped to their in-come through their occupational class.
This dataset, introduced in (Preot?iuc-Pietro et al, 2015a;Preot?iuc-Pietro et al, 2015b), relies on a standard-ised job classification taxonomy (the UK StandardOccupational Classification) to extract job-relatedkeywords, search user profile fields for users hav-ing those jobs and map them to their mean UKincome, independently of user location.
The finaldata set consists of 10,796,836 tweets.Age (D2) The age data set consists of 4,279users mapped to their age from (Volkova andBachrach, 2015).
The final data set consists of574,095 tweets.3 FeaturesWe use a variety of features to capture the languagebehavior of a user.
We group these features into:Surface We measure the length of tweets inwords and characters, and the length of words.
Asshorter words are considered more readable (Gun-ning, 1969; Pitler and Nenkova, 2008), we alsomeasure the ratio of words longer than five letters.We further calculate the type-token ratio per user,which indicates the lexical density of text and isconsidered to be a readability predictor (Oaklandand Lane, 2004).
Additionally we capture the num-ber of positive and negative smileys in the tweetand the number of URLs.Readability After filtering tweets to containonly words, we use the most prominent readabil-ity measures per user: the Automatic Readabil-ity Index (Senter and Smith, 1967), the Flesch-Kincaid Grade Level (Kincaid et al, 1975), theColeman-Liau Index (Coleman and Liau, 1975),the Flesch Reading Ease (Flesch, 1948), the LIX In-dex (Anderson, 1983), the SMOG grade (McLaugh-lin, 1969) and the Gunning-Fog Index (Gunning,1969).
The majority of those are computed usingthe average word and sentence lengths and numberof syllables per sentence, combined with weights.Syntax Researchers argue about longer sen-tences not necessarily being more complex in termsof syntax (Feng et al, 2009; Pitler and Nenkova,2008).
However, advanced sentence parsing onTwitter remains a challenging task.
We thus limitourselves in this study to the part-of-speech (POS)314(a) ARI Readability Index.
(b) Pronouns.
(c) Interjections.
(d) Named Entities.Figure 1: Temporal patterns for groups of lowest (blue) and highest (orange) income users in our data set.X-axis shows the course of 24 hours in normalized time of day.
Y-axis shows a normalized difference ofthe hourly means from the overall mean feature value.
Width of a line shows the standard error.information.
In previous work on writing style(Pennebaker et al, 2003; Argamon et al, 2009;Rangel et al, 2014), a text with more nouns andarticles as opposed to pronouns and adverbs is con-sidered more formal.
We thus measure the ratio ofeach POS using the universal tagset (Petrov et al,2012).Style We implemented a contextuality measure,based on the work of Heylighen and Dewaele(2002), which assesses explicitness of the textbased on the POS used and serves as a proxy forformality.
Using Stanford Named Entity Recog-nizer (Finkel et al, 2005), we measure the propor-tion of named entities (3-classed) to words, as theirpresence potentially decreases readability (Bein-born et al, 2012), and netspeak aspects such as theproportion of elongations (wooow) and words withnumbers (good n8).
We quantify the number ofhedges (Hyland, 2005) and abstract words1used,and the ratio of standalone numbers stated per useras these are indicators of specificity (Pennebakeret al, 2003; Pitler and Nenkova, 2008).
We alsocapture the ratio of hapax legomena, and of su-perlatives and plurals using Stanford POS Tagger1www.englishbanana.com(Toutanova et al, 2003) using the Twitter model.4 Temporal Patterns in StyleSocial media data offers the opportunity to interpretthe features in a richer context, including time orspace.
In our income data set, a timestamp is avail-able for each message.
Golder and Macy (2011)showed user-level diurnal and seasonal patternsof mood across the world using Twitter data, sug-gesting that individuals awaken in a good moodthat deteriorates as the day progresses.
In thiswork we explore user-level daily temporal trends instyle for the 1500 highest- and 1500 lowest-incomeusers (mean income ?
?35,000 vs mean income?
?25,000).
In Figure 1 we present normalizedtemporal patterns for a selected set of features.While the difference between groups is moststriking, we also observe some consistent dailypatterns.
These display an increase in readabil-ity (Figure 1a) starting in the early hours of themorning, peaking at 10AM and then decreasingconstantly throughout the day, which is in accor-dance with the mood swings reported by Golderand Macy (2011).
The proportion of pronouns (Fig-ure 1b) and interjections (Figure 1c) follows the315exact opposite pattern, with a peak in frequencyduring nights.
This suggests that the language getsmore contextual (Heylighen and Dewaele, 2002)towards the end of the day.
Finally, named enti-ties (Figure 1d) display a very distinctive pattern,with a constant increase starting mornings, whichincreases throughout the day.
While the first threepatterns mirror the active parts of the day, coincid-ing with regular working hours, the latter patternis possibly associated with mentions of venues ornews.
An increase in usage of named entities inthe evening is steeper for low-income users - wehypothesize that this phenomenon could be rea-soned by a stronger association of named entitieswith leisure in this user group.
Overall, we noticea similarity between income groups, which, de-spite strongly separated, follow similar ?
perhapsuniversal ?
patterns.5 AnalysisWe view age and income as continuous variablesand model them in a regression setup.
This is incontrast to most previous studies on age as a cate-gorical variable (Rangel et al, 2014) to allow forfiner grained predictions useful for downstream ap-plications which use exact values of user traits, asopposed to being limited to broad classes such asyoung vs. old.
We apply linear regression withElastic Net regularization (Zou and Hastie, 2005)and support vector regression with an RBF kernel(as a non-linear counterpart) for comparison (Vap-nik, 1998).
We report Pearson correlation resultson 10-fold cross-validation.
We also study if ourfeatures are predictive of income above age, by con-trolling for age assigned by a state-of-the-art modeltrained on social media data (Sap et al, 2014).
Sim-ilar results have been obtained with log-scaling theincome variable.
Table 1 presents our prediction re-sults.
The strength of the correlation to the incomeand age, together with the sign of the correlationcoefficient, are visually displayed in Figure 2.As expected, all features correlate with age andincome in the same direction.
However, some fea-tures and groups are more predictive of one or theother (depicted above or below the principal di-agonal in Figure 2).
Most individual surface fea-tures correlate with age stronger than with income,with the exception of punctuation and, especially,words longer than 5 characters.
The correlationof each readability measure is remarkably strongerwith high income than with age, despite the factFeatures Income (D1) Age (D2) Income-Age (D1)Readability Lin RSVM Lin RSVM Lin RSVMARI .282 .311 .269 .318 .230 .263Flesch-Kincaid .285 .319 .263 .310 .234 .284Coleman-Liau .230 .197 .203 .265 .202 .289Flesch RE .277 .345 .186 .295 .239 .318FOG .291 .309 .222 .270 .238 .267SMOG .288 .339 .240 .263 .234 .301LIX .208 .286 .215 .268 .177 .245ALL .301 .380 .278 .329 .249 .354Syntax Lin RSVM Lin RSVM Lin RSVMNouns .155 .200 .278 .302 .078 .150Verbs .044 .071 (.046) .104 .093 .114Pronouns .264 .297 .148 .180 .114 .127Adverbs .115 .110 .077 .111 .135 .131Adjectives (.030) .149 .162 .200 (.046) .139Determiners (.040) .070 .135 .154 .103 .121Interjections .123 .188 .084 .122 .059 .139ALL .323 .258 .319 .229 .299 .267Style Lin RSVM Lin RSVM Lin RSVMNamed entities .241 .288 .282 .293 .255 .281Contextuality (.044) .204 .287 .310 (.030) .134Abstract words .108 .120 .141 .183 .125 .139Hedging (.019) .079 (.015) .000 .
(000) .083Specific (num) .093 .011 .072 .176 .059 .124Elongations .097 .160 .072 .073 .056 .114Hapax legom.
.056 .066 .160 .219 .064 .067ALL .279 .347 .306 .134 .296 .312Surface Lin RSVM Lin RSVM Lin RSVM# char.
/ token .085 .144 .104 .148 .051 .101# tokens / tweet .158 .159 .228 .237 .115 .116# char.
/ tweet .214 .261 .262 .278 .153 .169# words >5 char.
.139 .191 (.009) .087 .112 .163Type/token ratio .099 .132 .090 .180 .100 .126Punctuation .218 .123 .093 .086 .057 .084Smileys .064 .113 .146 .144 (.030) .090URLs .084 .128 .187 .194 (.040) .077ALL .379 .330 .294 .307 .352 .126Table 1: Predictive performance (Pearson corre-lation) for Income, Age and Income controlledfor predicted age using linear (Lin) and non-linear(RSVM) learning methods.
The last line of eachsub-table shows the results for all features fromthat block together, while individual rows displayindividual performance for the predictive features.Numbers in bold represent the highest correlationsfrom the specific block of features and data set.All correlations are significant on p < 0.001 levelexcept for those in brackets.these are to a large extent based on the surface fea-tures.
Notably, Flesch Reading Ease ?
previouslyreported to correlate with education levels at a com-munity level (Davenport and DeLine, 2014) andwith the usage of pronouns (?Stajner et al, 2012) ?is highly indicative for income.
On the syntacticlevel we observe that increased use of nouns, de-terminers and adjectives is correlated higher withage as opposed to income, while a high ratio ofpronouns and interjections is a good predictor oflower income but, only to a lesser extent, youngerage, with which it is traditionally associated (Schleret al, 2006).
From the stylistic features, the con-textuality measure stands out as being correlatedwith increase in age, in line with Heylighen and De-3160.3 0.2 0.1 0.0 0.1 0.2 0.3Income r0.30.20.10.00.10.20.3Ager# Char/Token# Tokens/Tweet# Chars/Tweet#words>5charType/token RatioPunctuationSmileysURLsARIF-KincaidColeman-LiauFlesch REFOGSMOGLIXNounsVerbsPronounsAdverbsAdjectivesDeterminersInterjectionsNamed entitiesContextualityAbstractHedgingSpecificElongationsHapax legom.SurfaceReadabilitySyntaxStyleFigure 2: Predictive performance (Pearson correla-tion) for Income and Age.
Individual points displayunivariate correlations (including sign) of the mostpredictive features.waele (2002), but is almost orthogonal to income.Similarly, the frequency of named entities is corre-lated with higher income, while elongations havestronger association with younger age.
Our resultsshow, that based on the desired application, onecan exploit these differences to tailor the style of adocument without altering the topic to suit eitherage or income individually.6 Conclusions and Future WorkUsing two large data sets from thousands of users,annotated with their age and income, we pre-sented the first study which analyzes these vari-ables jointly, in relation to writing style.
We haveshown that the stylistic measures not only obtainsignificant correlations with both age and income,but are predictive of income beyond age.
Moreover,we explored temporal patterns in user behavior onTwitter, discovering intriguing trends in writingstyle.
While the discovery of these patterns pro-vides useful psychosocial insight, it additionallyhints to future research and applications that piggy-back on author profiling in social media e.g., takingthe message timestamp into account for stylisticfeatures may yield improved results in user socio-demographic predictions.
Likewise, utilizing addi-tional proxies to control for income and educationmay lead to improvements in user age prediction.AcknowledgmentsThe authors acknowledge the support from Temple-ton Religion Trust, grant TRT-0048.
We also wishto thank Prof. Iryna Gurevych for supporting thecollaboration.ReferencesJonathan Anderson.
1983.
LIX and RIX: Variations ona Little-Known Readability Index.
Journal of Read-ing, pages 490?496.Shlomo Argamon, Moshe Koppel, James W. Pen-nebaker, and Jonathan Schler.
2009.
AutomaticallyProfiling the Author of an Anonymous Text.
Com-munications of the ACM, 52(2).Vikas Ganjigunte Ashok, Song Feng, and Yejin Choi.2013.
Success with style: Using writing style topredict the success of novels.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, EMNLP.David Bamman, Jacob Eisenstein, and Tyler Schnoe-belen.
2014.
Gender Identity and Lexical Varia-tion in Social Media.
Journal of Sociolinguistics,18(2):135?160.Lisa Beinborn, Torsten Zesch, and Iryna Gurevych.2012.
Towards Fine-Grained Readability Measuresfor Self-Directed Language Learning.
In Proceed-ings of the SLTC 2012 workshop on NLP for CALL.Mait?e Boy?e, Thi Mai Tran, and Natalia Grabar.
2014.Nlp-oriented contrastive study of linguistic pro-ductions of alzheimer and control people.
InLNCS 8686 Springer, Advances in Natural Lan-guage Processing, editor, POLTAL, pages 412?424.D.
John Burger, John Henderson, George Kim, andGuido Zarrella.
2011.
Discriminating Gender onTwitter.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing,EMNLP.Zhiyuan Cheng, James Caverlee, and Kyumin Lee.2010.
You are where you Tweet: A Content-basedApproach to Geo-locating Twitter Users.
In Pro-ceedings of the 19th ACM Conference on Informa-tion and Knowledge Management, CIKM.Meri Coleman and TL Liau.
1975.
A ComputerReadability Formula Designed for Machine Scoring.Journal of Applied Psychology, 60(2).Cristian Danescu-Niculescu-Mizil, Michael Gamon,and Susan Dumais.
2011.
Mark my Words!
: Lin-guistic Style Accommodation in Social Media.
InProceedings of the 20th International Conference onWorld Wide Web, WWW.317James RA Davenport and Robert DeLine.
2014.The Readability of Tweets and their GeographicCorrelation with Education.
arXiv preprintarXiv:1401.6058.Munmun De Choudhury, Michael Gamon, ScottCounts, and Eric Horvitz.
2013.
Predicting Depres-sion via Social Media.
In Proceedings of the SeventhInternational AAAI Conference on Weblogs and So-cial Media, ICWSM.Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2010.
A latent variable model forgeographic lexical variation.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, EMNLP.Jacob Eisenstein, Noah A Smith, and Eric P Xing.2011.
Discovering Sociolinguistic Associationswith Structured Sparsity.
In Proceedings of the49th annual meeting of the Association for Computa-tional Linguistics: Human Language Technologies,NAACL.Lijun Feng, No?emie Elhadad, and Matt Huenerfauth.2009.
Cognitively Motivated Features for Readabil-ity Assessment.
In Proceedings of the 12th Confer-ence of the European Chapter of the Association forComputational Linguistics, EACL.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating Non-Local Informa-tion into Information extraction Systems by GibbsSampling.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics,ACL.Rudolf Flesch.
1948.
A New Readability Yardstick.The Journal of Applied Psychology, 32(3).Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-Speech Taggingfor Twitter: Annotation, Features, and Experiments.In Proceedings of the 49th annual meeting of the As-sociation for Computational Linguistics, ACL.Scott A. Golder and Michael W. Macy.
2011.
Diur-nal and Seasonal Mood Vary with Work, Sleep, andDaylength Across Diverse Cultures.
Science, 333.Robert Gunning.
1969.
The Fog index after TwentyYears.
Journal of Business Communication, 6(2).Francis Heylighen and Jean-Marc Dewaele.
2002.Variation in the Contextuality of Language: An Em-pirical Measure.
Foundations of Science, 7(3).Dirk Hovy and Anders S?gaard.
2015.
Tagging Perfor-mance Correlates with Author Age.
In Proceedingsof the 53rd Annual Meeting of the Association forComputational Linguistics, ACL.Ken Hyland.
2005.
Stance and Engagement: A Modelof Interaction in Academic Discourse.
DiscourseStudies, 7(2):173?192.Anders Johannsen, Dirk Hovy, and Anders Sogaard.2015.
Cross-lingual syntactic variation over age andgender.
In CONNL.Timothy A.
Judge, Chad A. Higgins, Carl J. Thoresen,and Murray R. Barrick.
1999.
The big five personal-ity traits, general mental ability, and carreer successacross the life span.
Personnel Psychology, 52.J Peter Kincaid, Robert P Fishburne Jr, Richard LRogers, and Brad S Chissom.
1975.
Derivationof New Readability Formulas (Automated Readabil-ity Index, Fog Count and Flesch Reading Ease For-mula) for Navy Enlisted Personnel.
Technical re-port, Naval Technical Training Command Milling-ton TN Research Branch.William Labov.
2006.
The Social Stratification of En-glish in New York City.
Cambridge University Press.Vasileios Lampos, Nikolaos Aletras, Daniel Preot?iuc-Pietro, and Trevor Cohn.
2014.
Predicting and Char-acterising User Impact on Twitter.
In Proceedings ofthe 14th Conference of the European Chapter of theAssociation for Computational Linguistics, EACL,pages 405?413.Xuan Le, Ian Lancashire, Graeme Hirst, and ReginaJokel.
2011.
Longitudinal Detection of Dementiathrough Lexical and Syntactic Changes in Writing:A Case Study of Three British Novelists.
Literaryand Linguistic Computing, 26(4).Annie Louis and Ani Nenkova.
2013.
What makesWriting Great?
First Experiments on Article Qual-ity Prediction in the Science Journalism Domain.Transactions of the Association for ComputationalLinguistics.Annie Louis and Ani Nenkova.
2014.
Verbose,Laconic or Just Right: A Simple ComputationalModel of Content Appropriateness under LengthConstraints.
In Proceedings of the 14th Conferenceof the European Chapter of the Association for Com-putational Linguistics, EACL.Marco Lui and Timothy Baldwin.
2012. langid.py: AnOff-the-Shelf Language Identification Tool.
In Pro-ceedings of the 50th Annual Meeting of the Associa-tion for Computational Linguistics, ACL.G Harry McLaughlin.
1969.
SMOG Grading: A NewReadability Formula.
Journal of Reading, 12(8).Dong Nguyen, Rilana Gravel, Dolf Trieschnigg, andTheo Meder.
2013.
?How Old do you Think I am??
;A Study of Language and Age in Twitter.
In Pro-ceedings of the Seventh International AAAI Confer-ence on Weblogs and Social Media, ICWSM.Thomas Oakland and Holly B Lane.
2004.
Language,Reading, and Readability Formulas: Implicationsfor Developing and Adapting Tests.
InternationalJournal of Testing, 4(3):239?252.318J.W.
Pennebaker, Matthias R. Mehl, and K.G.
Nieder-hoffer.
2003.
Psychological Aspects of Natural Lan-guage Use: Our Words, Our Selves.
Annual Reviewof Psychology, 54(1).Slav Petrov, Dipanjan Das, and Ryan T. McDonald.2012.
A Universal Part-of-Speech Tagset.
In Pro-ceedings of the Eighth International Conference onLanguage Resources and Evaluation, LREC.Emily Pitler and Ani Nenkova.
2008.
Revisiting Read-ability: A Unified Framework for Predicting TextQuality.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP.Daniel Preot?iuc-Pietro, Sina Samangooei, Trevor Cohn,Nick Gibbins, and Mahesan Niranjan.
2012.
Trend-miner: An Architecture for Real Time Analysis ofSocial Media Text.
In Workshop on Real-Time Anal-ysis and Mining of Social Streams, ICWSM, pages38?42.Daniel Preot?iuc-Pietro, Vasileios Lampos, and Niko-laos Aletras.
2015a.
An Analysis of the User Occu-pational Class through Twitter Content.
In Proceed-ings of the 53rd Annual Meeting of the Associationfor Computational Linguistics, ACL.Daniel Preot?iuc-Pietro, Svitlana Volkova, VasileiosLampos, Yoram Bachrach, and Nikolaos Aletras.2015b.
Studying user income through language, be-haviour and affect in social media.
PLoS ONE.Daniel Preot?iuc-Pietro, Wei Xu, and Lyle Ungar.
2016.Discovering User Attribute Stylistic Differences viaParaphrasing.
In Proceedings of the Thirtieth AAAIConference on Artificial Intelligence, AAAI.Daniel Preotiuc-Pietro, Johannes Eichstaedt, GregoryPark, Maarten Sap, Laura Smith, Victoria Tobolsky,H Andrew Schwartz, and Lyle H Ungar.
2015.
TheRole of Personality, Age and Gender in Tweetingabout Mental Illnesses.
In Proceedings of the Work-shop on Computational Linguistics and Clinical Psy-chology: From Linguistic Signal to Clinical Reality,NAACL.Francisco Rangel, Paolo Rosso, Irina Chugur, MartinPotthast, Martin Trenkmann, Benno Stein, Ben Ver-hoeven, and Walter Daelemans.
2014.
Overviewof the 2nd Author Profiling Task at PAN 2014.
InProceedings of the Conference and Labs of the Eval-uation Forum (Working Notes), CLEF.Delip Rao, David Yarowsky, Abhishek Shreevats, andManaswi Gupta.
2010.
Classifying Latent User At-tributes in Twitter.
In Proceedings of the 2nd In-ternational Workshop on Search and Mining User-generated Contents, SMUC.Sara Rosenthal and Kathleen McKeown.
2011.
AgePrediction in Blogs: A Study of Style, Content, andOnline Behavior in Pre-and Post-Social Media Gen-erations.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguistics,ACL.Maarten Sap, Gregory Park, Johannes Eichstaedt, Mar-garet Kern, David Stillwell, Michal Kosinski, LyleUngar, and H Andrew Schwartz.
2014.
Develop-ing Age and Gender Predictive Lexica over SocialMedia.
In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Processing,EMNLP.Jonathan Schler, Moshe Koppel, Shlomo Argamon,and James Pennebaker.
2006.
Effects of Age andGender on Blogging.
In Proceedings of 2006 AAAISpring Symposium on Computational Approachesfor Analyzing Weblogs.H Andrew Schwartz, Johannes C Eichstaedt, Mar-garet L Kern, Lukasz Dziurzynski, Stephanie MRamones, Megha Agrawal, Achal Shah, MichalKosinski, David Stillwell, Martin EP Seligman, andLyle H Ungar.
2013.
Personality, Gender, andAge in the Language of Social Media: The Open-Vocabulary Approach.
PLoS ONE.R.J.
Senter and E.A.
Smith.
1967.
Automated Read-ability Index.
Aerospace Medical Research Labora-tories.Sanja?Stajner, Richard Evans, Constantin Orasan, andRuslan Mitkov.
2012.
What can readability mea-sures really tell us about text complexity.
In NLPfor Improving Textual Accessibility workshop, pages14?22.Kristina Toutanova, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-rich Part-of-Speech Tagging with a Cyclic Dependency Network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, NAACL.Vladimir N Vapnik.
1998.
Statistical learning theory.Wiley.Svitlana Volkova and Yoram Bachrach.
2015.
Onpredicting socio-demographic traits and emotionsin social networks and implications to online self-disclosure.
Cyberpsychology, behavior and socialnetworking, 18(12):726?736.Hui Zou and Trevor Hastie.
2005.
Regularization andVariable Selection via the Elastic Net.
Journal of theRoyal Statistical Society, Series B, 67.319
