Constructing Transliteration Lexicons from Web CorporaJin-Shea Kuo1, 2 Ying-Kuei Yang21Chung-Hwa TelecommunicationLaboratories, Taiwan, R. O. C., 3262E.
E.
Dept., National Taiwan University of Scienceand Technology, Taiwan, R.O.C., 106jskuo@cht.com.tw ykyang@mouse.ee.ntust.edu.twAbstractThis paper proposes a novel approach to automatingthe construction of transliterated-term lexicons.
Asimple syllable alignment algorithm is used toconstruct confusion matrices for cross-languagesyllable-phoneme conversion.
Each row in theconfusion matrix consists of a set of syllables in thesource language that are (correctly or erroneously)matched phonetically and statistically to a syllable inthe target language.
Two conversions usingphoneme-to-phoneme and text-to-phonemesyllabification algorithms are automatically deducedfrom a training corpus of paired terms and are usedto calculate the degree of similarity betweenphonemes for transliterated-term extraction.
In alarge-scale experiment using this automated learningprocess for conversions, more than 200,000transliterated-term pairs were successfully extractedby analyzing query results from Internet searchengines.
Experimental results indicate the proposedapproach shows promise in transliterated-termextraction.1 IntroductionMachine transliteration plays an important role inmachine translation.
The importance of termtransliteration can be realized from our analysis ofthe terms used in 200 qualifying sentences that wererandomly selected from English-Chinese mixed newspages.
Each qualifying sentence contained at leastone English word.
Analysis showed that 17.43% ofthe English terms were transliterated, and that mostof them were content words (words that carryessential meaning, as opposed to grammaticalfunction words such as conjunctions, prepositions,and auxiliary verbs).In general, a transliteration process starts by firstexamining a pre-compiled lexicon which containsmany transliterated-term pairs collected manually orautomatically.
If a term is not found in the lexicon,the transliteration system then deals with this out-of-vocabulary (OOV) term to try to generate atransliterated-term via a sequence of pipelinedconversions (Knight, 1998).
Before this issue can bedealt with, a large quantity of transliterated-termpairs are required to train conversion models.Preparing a lexicon composed of transliterated termpairs is time- and labor-intensive.
Constructing sucha lexicon automatically is the most important goal ofthis paper.
The problem is how to collecttransliterated-term pairs from text resources.Query logs recorded by Internet search enginesreveal users' intentions and contain much informationabout users' behaviors.
(Brill, 2001) proposed aninteractive process that used query logs for extractingEnglish-Japanese transliterated-terms.
Under thismethod, a large initial number of term pairs werecompiled manually.
It is time-consuming to preparesuch an initial training set, and the resource used isnot publicly accessible.The Internet is one of the largest distributeddatabases in the world.
It comprises various kinds ofdata and at the same time is growing rapidly.
Thoughthe World Wide Web is not systematically organized,much invaluable information can be obtained fromthis large text corpus.
Many researchers dealing withnatural language processing, machine translation,and information retrieval have focused on exploitingsuch non-parallel Web data (Al-Onaizan, 2002; Fung,1998;).
Also, online texts contain the latest terms thatmay not be found in existing dictionaries.
Regularlyexploring Web corpora is a good way to updatedictionaries.Transliterated-term extraction using non-parallelcorpora has also been conducted (Kuo, 2003).Automated speech recognition-generated confusionmatrices (AGCM) have been used successfully tobootstrap term extraction from Web pages collectedby a software spider.AGCM were used successfully not only to alleviatepronunciation variation, especially the sociolinguisticcauses, but also to construct a method for cross-language syllable-phoneme conversion (CLSPC).This is a mapping from a source-language syllableinto its target-language counterpart.
The problem ishow to produce such conversions if AGCM are notavailable for the targeted language pair.
To generateconfusion matrices from automated speechrecognition requires the effort of collecting manyspeech corpora for model training, costing time andlabor.
Automatically constructing a CLSPC withoutAGCM is the other main focus of this paper.Web pages, which are dynamically updated andpublicly accessible, are important to manyresearchers.
However, if many personally guidedspiders were simultaneously collecting Web pages,they might cause a network traffic jam.
Internetsearch engines, which update their data periodically,provide search services that are also publiclyaccessible.
A user can select only the pages ofinterest from Internet search engines; this mitigatesthe possibility that a network traffic jam will becaused by many personally guided spiders.Possibly aligned candidate strings in two languages,which may belong to two completely differentlanguage families, are selected using local contextanalysis from non-parallel corpora (Kuo, 2003).
Inorder to determine the degree of similarity betweenpossible candidate strings, a method for convertingsuch aligned terms cross-linguistically into the samerepresentation in syllables is needed.
A syllable is thebasic pronunciation unit used in this paper.
The tasksdiscussed in this paper are first to align syllablescross-linguistically, then to construct a cross-linguistic relation, and third to use the trainedrelation to extract transliterated-term pairs.The remainder of the paper is organized as follows:Section 2 describes how English-Chinesetransliterated-term pairs can be extractedautomatically.
Experimental results are presented inSection 3.
Section 4 analyzes on the performanceachieved by the extraction.
Conclusions are drawn inSection 5.2.
The Proposed ApproachAn algorithm based on minimizing the edit distancebetween words with the same representation hasbeen proposed (Brill, 2001).
However, the mappingbetween cross-linguistic phonemes is obtained onlyafter the cross-linguistic relation is constructed.
Sucha relation is not available at the very beginning.A simple and fast approach is proposed here toovercome this problem.
Initially, 200 verified correctEnglish-Chinese transliterated-term pairs arecollected manually.
One of the most importantattributes of these term pairs is that the numbers ofsyllables in the source-language term and the target-language term are equal.
The syllables of bothlanguages can also be decomposed further intophonemes.
The algorithm that adopts equal syllablenumbers to align syllables and phonemes cross-linguistically is called the simple syllable alignmentalgorithm (SSAA).
This algorithm generates syllableand phoneme mapping tables between the source andtarget languages.
These two mapping tables can beused to calculate similarity between candidate stringsin transliterated-term extraction.
With the mapping,the transliterated-term pairs can be extracted.
Theobtained term pairs can be selected according to thecriterion of equal syllable segments.
These qualifiedterm pairs can then be merged with the previous setto form a larger set of qualified term pairs.
The newset of qualified term pairs can be used again toconstruct a new cross-linguistic mapping for the nextterm extraction.
This process iterates until no morenew term pairs are produced or until other criteria aremet.
The conversions used in the last round of thetraining phase are then used to extract large-scaletransliterated-term pairs from query results.Two types of cross-linguistic relations, phoneme-to-phoneme (PP) and text-to-phoneme (TP), can beused depending on whether a source-language letter-to-sound system is available or not.2.1 Construction of a Relation Using Phoneme-to-Phoneme MappingIf a letter-to-phoneme system is available, aphoneme-based syllabification algorithm (PSA) isused for constructing a cross-linguistic relation, thena phoneme-to-phoneme (PP) mapping is selected.Each word in the located English string is convertedinto phonemes using MBRDICO (Pagel, 1998).
Inorder to compare English terms with Chinese termsin syllables, the generated English phonemes aresyllabified into consonant-vowel pairs.
Eachconsonant-vowel pair is then converted into aChinese syllable.
The PSA used here is basically thesame as the classical one (Jurafsky, 2000), but hassome minor modifications.
Traditionally, an Englishsyllable is composed of an initial consonant clusterfollowed by a vowel and then a final consonantcluster.
However, in order to convert Englishsyllables to Chinese ones, the final consonant clusteris appended only when it is a nasal.
The otherconsonants in the final consonant cluster are thensegmented into isolated consonants.
Such a syllablemay be viewed as the basic pronunciation unit intransliterated-term extraction.After English phonemes are grouped into syllables,the English syllables can be converted into Chineseones according to the results produced by usingSSAA.
The accuracy of the conversion can improveprogressively if the cross-linguistic relation isdeduced from a large quantity of transliterated-termpairs.Take the word ?polder?
as an example.
First, it isconverted into /pold?/ using the letter-to-phonemesystem, and then according to the phoneme-basedsyllabification algorithm (PSA), it is divided into /po/,/l/, and /d?/, where /l/ is an isolated consonant.Second, these English syllables are then convertedinto Chinese syllables using the trained cross-linguistic relation; for example, /po/, /l/, and /d?/ areconverted into /po/, /er/, and /de/ (in Pin-yin),respectively.
/l/ is a syllable with only an isolatedconsonant.
A final is appended to its convertedChinese syllable in order to make it completebecause not all Chinese initials are legal syllables.The other point worth noting is that /l/, a consonantin English, is converted into its Chinese equivalent,/er/, but, /er/ is a final (a kind of complex vowel) inChinese.2.2 Construction of a Relation Using Text-to-Phoneme MappingIf a source language letter-to-phoneme system isnot available, a simple text-based syllabificationalgorithm (TSA) is used and a text-to-phoneme (TP)mapping is selected.
An English word is frequentlycomposed of multiple syllables; whereas, everyChinese character is a monosyllable.
First, eachEnglish character in an English term is identified as aconsonant, a vowel or a nasal.
For example, thecharacters ?a?, ?b?
and ?n?
are viewed as a vowel, aconsonant and a nasal, respectively.
Second,consecutive characters of the same attribute form acluster.
However, some characters, such as ?ch?,?ng?
and ?ph?, always combine together to formcomplex consonants.
Such complex consonants arealso taken into account in the syllabification process.A Chinese syllable is composed of an initial and afinal.
An initial is similar to a consonant in English,and a final is analogous to a vowel or a combinationof a vowel and a nasal.
Using the proposed simplesyllable alignment algorithm, a conversion using TPmapping can be produced.
The conversion can alsobe used in transliterated-term extraction from non-parallel web corpora.The automated construction of a cross-linguisticmapping eliminates the dependency on AGCMreported in (Kuo, 2003) and makes transliterated-term extraction for other language pairs possible.
Thecross-linguistic relation constructed using TSA andTP is called CTP; on the other hand, the cross-linguistic relation using PSA and PP is called CPP.3 The Experimental Results3.1 Training Cross-language Syllable-phonemeConversionsAn English-Chinese text corpus of 500MB in15,822,984 pages, which was collected from theInternet using a web spider and was converted toplain text, was used as a training set.
This corpus iscalled SET1.
From SET1, 80,094 qualifyingsentences that occupied 5MB were extracted.
Aqualifying sentence was a sentence composed of atleast one English string.Two experiments were conducted using either CPPor CTP on SET1.
Figure 1 shows the progress ofextracting transliterated-term pairs achieved usingCPP mapping.
A noteworthy phenomenon was thatphoneme conversion produced more term pairs thansyllable conversion did at the very beginning oftraining.
This is because, initially, the quality of thesyllable combinations is not good enough.
Thephonemes exerted finer-grained control thansyllables did.
However, when the generated syllablecombinations improved in quality, the situationchanged.
Finally, extraction performed using syllableconversion outperformed that achieved usingphoneme conversion.
Note also that the resultsproduced by using phonemes quickly approached thesaturation state.
This is because the English phonemeset is small.
When phonemes were usedindependently to perform term extraction, fewerextracted term pairs were produced than wereproduced using syllables or a combination ofsyllables and phonemes.05001000150020002500300035004000450050005500600065007000Iter #1 Iter #2 Iter #3 Iter #4 Iter #5 Iter #6Syllable (S)Phoneme (P)S+PFigure 1.
The progress of extracting transliterated-term pairs using CPP conversionFigure 2 shows the progress of extractingtransliterated-term pairs using CTP.
The samesituation also occurred at the very beginning oftraining.
Comparing the results generated using CPPand CTP, CPP outperformed CTP in terms of thequantity of extracted term pairs because thecombinations obtained using TSA are larger thanthose obtained using PSA.
This is also revealed bythe results generated at iteration 1 and shown inFigures 1 and 2.050010001500200025003000350040004500500055006000Iter #1 Iter #2 Iter #3 Iter #4 Iter #5 Iter #6Syllable (S)Phoneme (P)S+PFigure 2.
The progress of extracting transliterated-term pairs using CTP conversion.3.2 Transliterated-term ExtractionThe Web is growing rapidly.
It is a rich informationsource for many researchers.
Internet search engineshave collected a huge number of Web pages forpublic searching (Brin, 1998).
Submitting queries tothese search engines and analyzing the results canhelp researchers to understand the usages oftransliterated-term pairs.Query results are text snippets shown in a pagereturned from an Internet search engine in responseto a query.
These text snippets may be composed oftexts that are extracted from the beginning of pagesor from the texts around the keywords matched in thepages.
Though a snippet presents only a portion ofthe full text, it provides an alternative way tosummarize the pages matched.Initially, 200 personal names were randomlyselected from the names in the 1990 censusconducted by the US Census Bureau1 as queries tobe submitted to Internet search engines.
CPP andCTP were obtained in the last round of the trainingphase.
The estimated numbers of distinct qualifyingterm pairs (EDQTP) obtained by analyzing queryresults and by using CPP and CTP mappings for 7days are shown in Table 1.
A qualifying term pairmeans a term pair that is verified manually to becorrect.
EDQTP are term pairs that are not verifiedmanually but are estimated according to the precisionachieved during the training phase.Finally, a text corpus called SET2 was obtained byiteratively submitting queries to search engines.SET2 occupies 3.17GB and is composed of 67,944pages in total.
The term pairs extracted using CTPwere much fewer in number than those extractedusing CPP.
This is because the TSA used in thisstudy, though effective, is very simple andrudimentary.
A finer-grained syllabificationalgorithm would improve performance.CPP CTPEDQTP 201,732 110,295Table 1.
The term pairs extracted from Internetsearch engines using PP and TP mappings.4 DiscussionComparing the performances achieved by CPP andCTP, the results obtained by using CPP were betterthan those with CTP.
The reason is that TSA is verysimple.
A better TSA would produce better results.Though TSA is simple, it is still effective inautomatically extracting a large quantity of term1http://www.census.gov/genealogy/names/pairs.
Also, TSA has an advantage over PSA is thatno letter-to-phoneme system is required.
It could behelpful when applying the proposed approach toother language pairs, where such a mapping may notbe available.5 ConclusionsAn approach to constructing transliterated-termlexicons has been presented in this paper.
A simplealignment algorithm has been used to automaticallyconstruct confusion matrices for cross-languagesyllable-phoneme conversion using phoneme-to-phoneme (PP) and text-to-phoneme (TP)syllabification algorithms.
The proposed approachnot only reduces the need for using automatedspeech recognition-generated confusion matrices, butalso eliminates the need for a letter-to-phonemesystem for source-language terms if TP is used toconstruct a cross-language syllable-phonemeconversion and to successfully extract transliterated-term pairs from query results returned by Internetsearch engines.
The performance achieved using PPand TP has been compared and discussed.
Theoverall experimental results show that this approachis very promising for transliterated-term extraction.ReferencesAl-Onaizan Y. and Knight K. 2002.
MachineTransliteration of Names in Arabic Text, In Proceedingsof ACL Workshop on Computational Approaches toSemitic Languages, pp.
34-46.Brill E., Kacmarcik G., Brockett C. 2001.
AutomaticallyHarvesting Katakana-English Term Pairs from SearchEngine Query Logs, In Proceedings of NaturalLanguage Processing Pacific Rim Symposium, pp.
393-399.Brin S. and Page L. 1998.
The Anatomy of a Large-scaleHypertextual Web Search Engine, In Proceedings of 7thInternational World Wide Web Conference, pp.
107-117.Fung P. and Yee L.-Y.
1998.
An IR Approach forTranslating New Words from Nonparallel, ComparableTexts.
In Proceedings of the 36th Annual Meeting of theAssociation for Computational Linguistics and 7thInternational Conference on Computational Linguistics,pp.
414-420.Jurafsky D. and Martin J. H. 2000.
Speech and LanguageProcessing, pp.
102-120, Prentice-Hall, New Jersey.Knight K. and Graehl J.
1998.
Machine Transliteration,Computational Linguistics, Vol.
24, No.
4, pp.599-612.Kuo J. S. and Yang Y. K. 2003.
Automatic Transliterated-term Extraction Using Confusion Matrix from Non-parallel Corpora, In Proceedings of ROCLING XVComputational Linguistics Conference, pp.17-32.Pagel V., Lenzo K., and Black A.
1998.
Letter to SoundRules for Accented Lexicon Compression, InProceedings of ICSLP, pp.
2015-2020.
