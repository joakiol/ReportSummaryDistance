Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 1?12,Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational LinguisticsRediscovering ACL Discoveries Through the Lens of ACL AnthologyNetwork Citing SentencesDragomir RadevEECS DepartmentUniversity of MichiganAnn Arbor, MI, USAradev@umich.eduAmjad Abu-JbaraEECS DepartmentUniversity of MichiganAnn Arbor, MI, USAamjbara@umich.eduAbstractThe ACL Anthology Network (AAN)1 is acomprehensive manually curated networkeddatabase of citations and collaborations in thefield of Computational Linguistics.
Each cita-tion edge in AAN is associated with one ormore citing sentences.
A citing sentence isone that appears in a scientific article and con-tains an explicit reference to another article.
Inthis paper, we shed the light on the usefulnessof AAN citing sentences for understanding re-search trends and summarizing previous dis-coveries and contributions.
We also proposeand motivate several different uses and appli-cations of citing sentences.1 IntroductionThe ACL Anthology2 is one of the most success-ful initiatives of the Association for ComputationalLinguistics (ACL).
It was initiated by Steven Birdin 2001 and is now maintained by Min-Yen Kan. Itincludes all papers published by ACL and related or-ganizations as well as the Computational Linguisticsjournal over a period of four decades.The ACL Anthology Network (AAN) is anothersuccessful initiative built on top of the ACL Anthol-ogy.
It was started in 2007 by our group (Radevet al, 2009) at the University of Michigan.
AANprovides citation and collaboration networks of thearticles included in the ACL Anthology (excludingbook reviews).
AAN also includes rankings of pa-pers and authors based on their centrality statistics1http://clair.si.umich.edu/anthology/2http://www.aclweb.org/anthology-new/in the citation and collaboration networks.
It alsoincludes the citing sentences associated with eachcitation link.
These sentences were extracted auto-matically using pattern matching and then cleanedmanually.
Table 1 shows some statistics of the cur-rent release of AAN.The text surrounding citations in scientific publi-cations has been studied and used in previous work.Nanba and Okumura (1999) used the term citingarea to refer to citing sentences.
They define the cit-ing area as the succession of sentences that appeararound the location of a given reference in a scien-tific paper and has connection to it.
They proposeda rule-based algorithm to identify the citing area ofa given reference.
In (Nanba et al, 2000) they usetheir citing area identification algorithm to identifythe purpose of citation (i.e.
the author?s reason forciting a given paper.
)Nakov et al (2004) use the term citances to referto citing sentences.
They explored several differentuses of citances including the creation of trainingand testing data for semantic analysis, synonym setcreation, database curation, summarization, and in-formation retrieval.Other previous studies have used citing sentencesin various applications such as: scientific papersummarization (Elkiss et al, 2008; Qazvinian andRadev, 2008; Mei and Zhai, 2008; Qazvinian et al,2010; Qazvinian and Radev, 2010; Abu-Jbara andRadev, 2011a), automatic survey generation (Nanbaet al, 2000; Mohammad et al, 2009), and citationfunction classification (Nanba et al, 2000; Teufelet al, 2006; Siddharthan and Teufel, 2007; Teufel,2007).1Number of papers 18,290Number of authors 14,799Number of venues 341Number of paper citations 84,237Citation network diameter 22Collaboration network diameter 15Number of citing sentences 77,753Table 1: Statistics of AAN 2011 releaseIn this paper, we focus on the usefulness of theciting sentences included in AAN.
We propose sev-eral uses of citing sentences such as analyzing thetrends of research, understanding the impact of re-search and how this impact changes over time, sum-marizing the contributions of a researcher, summa-rizing the discoveries in a certain research field,and providing high quality data for Natural Lan-guage Processing tasks.
In the rest of this paperwe present some of these ideas and provide exam-ples from AAN to demonstrate their applicability.Some of these ideas have been explored in previouswork, but we believe that they still need further ex-ploration.
However, most of the ideas are novel toour knowledge.
We present our ideas in the follow-ing sections.2 Temporal Analysis of CitationsThe interest in studying citations stems from the factthat bibliometric measures are commonly used to es-timate the impact of a researcher?s work (Borgmanand Furner, 2002; Luukkonen, 1992).
Several pre-vious studies have performed temporal analysis ofcitation links (Amblard et al, 2011; Mazloumian etal., 2011; Redner, 2005) to see how the impact ofresearch and the relations between research topicsevolve overtime.
These studies focused on observ-ing how the number of incoming citations to a givenarticle or a set of related articles change over time.However, the number of incoming citations is oftennot the only factor that changes with time.
We be-lieve that analyzing the text of citing sentences al-lows researchers to observe the change in other di-mensions such as the purpose of citation, the polarityof citations, and the research trends.
The followingsubsections discuss some of these dimensions.Comparison Contrast/Comparison in Results, Method, orGoalsBasis Author uses cited work as basis or starting pointUse Author uses tools, algorithms, data, or defini-tionsDescription Neutral description of cited workWeakness Limitation or weakness of cited workTable 2: Annotation scheme for citation purpose2.1 Temporal Analysis of Citation PurposeTeufel et al (2006) has shown that the purpose ofcitation can be determined by analyzing the text ofciting sentences.
We hypothesize that performinga temporal analysis of the purpose for citing a pa-per gives a better picture about its impact.
As aproof of concept, we annotated all the citing sen-tences in AAN that cite the top 10 cited papers fromthe 1980?s with citation purpose labels.
The labelswe used for annotation are based on Teufel et al?sannotation scheme and are described in Table 2.
Wecounted the number of times the paper was citedfor each purpose in each year since its publicationdate.
This analysis revealed interesting observationsabout the paper impacts.
We will discuss these ob-servations in Section 2.3.
Figure 1 shows the changein the ratio of each purpose with time for Shieber?s(1985) work on parsing.2.2 Temporal Analysis of Citation PolarityThe bibliometric measures that are used to estimatethe impact of research are often computed based onthe number of citations it received.
This number istaken as a proxy for the relevance and the quality ofthe published work.
It, however, ignores the fact thatcitations do not necessarily always represent posi-tive feedback.
Many of the citations that a publica-tion receives are neutral citations, and citations thatrepresent negative criticism are not uncommon.
Tovalidate this intuition, we annotated about 2000 cit-ing sentences from AAN for citation polarity.
Wefound that only 30% of citations are positive, 4.3%are negative, and the rest are neutral.
In another pub-lished study, Athar (2011) annotated 8736 citationsfrom AAN with their polarity and found that only10% of citations are positive, 3% are negative andthe rest were all neutral.
We believe that consider-ing the polarity of citations when conducting tem-poral analysis of citations gives more insight about2-10010203040506070801985-1987 1987-1989 1989-1991 1991-1993 1993-1995 1995-1997 1997-1999 1999-2001 2001-2003 2007-2009comparisonbasisusingweaknessdescriptiveFigure 1: Change in the citation purpose of Shieber (1985) paper020406080100120 NeutralPosivtiveNegativeFigure 2: Change in the polarity of the sentences citingChurch (1988) paperhow the way a published work is perceived by the re-search community over time.
As a proof of concept,we annotated the polarity of citing sentences for thetop 10 cited papers in AAN that were published inthe 1980?s.
We split the year range of citations intotwo-year slots and counted the number of positive,negative, and neutral citations that each paper re-ceived during that time slot.
We observed how theratios of each category changed overtime.
Figure 2shows the result of this analysis when applied to thework of Kenneth Church (1988) on part-of-speechtagging.2.3 Predict Emergence of New Techniques orDecline of Impact of Old Techniques.The ideas discussed in Sections 2.1 and 2.2 and theresults illustrated in Figures 1 and 2 suggest thatstudying the change in citation purpose and cita-tion polarity allow us to predict the emergence ofnew techniques or the decline in impact of old tech-niques.
For example, the analysis illustrated in Fig-ure 2 shows that the work of Ken Church (1988)on part-of-speech tagging received significant posi-tive feedback during the 1990s and until early 2000sbefore it started to receive more negative feedback.This probably can be explained by the emergenceof better statistical models for part-of-speech (POS)tagging (e.g.
Conditional Random Fields (Laffertyet al, 2001)) that outperformed Church?s approach.However, as indicated by the neutral citation curve,Church?s work continued to be cited as a classicalpioneering research on the POS tagging task, butnot as the state-of-the-art approach.
Similar anal-ysis can be applied to the change in citation purposeof Shieber (1985) as illustrated in Figure 12.4 Study the Dynamics of ResearchIn recent research, Gupta and Manning (2011) con-ducted a study that tries to understand the dynamicsof research in computational linguistics (CL).
Theyanalyzed the abstracts of CL papers included in theACL Anthology Reference Corpus.
They extractedthe contributions, the domain of application, and the3apply propose extend systemAbstracts 1368 2856 425 5065Citing Sentences 2534 3902 917 6633Table 3: Comparison of trigger word occurrences in ab-stracts vs citing sentences.techniques and tools used in each paper.
They com-bined this information with pre-calculated article-to-community assignments to study the influence of acommunity on others in terms of techniques bor-rowed and the maturing of some communities tosolve problems from other domains.
We hypothe-size that conducting such an analysis using the cit-ing sentences of papers instead of (or in combinationwith) abstracts leads to a more accurate picture ofresearch dynamics and the interaction between dif-ferent research communities.
There are several intu-itions that support this hypothesis.First, previous research (Elkiss et al, 2008) hasshown that the citing sentences that cite a paper aremore focused and more concise than the paper ab-stract, and that they consistently contain additionalinformation that does not appear in abstracts.
Thismeans that additional characteristics of a paper canbe extracted from citing sentences that cannot beextracted from abstracts.
To verify this, we com-pared abstracts vs citing sentences (within AAN)in terms of the number of occurrences of the trig-ger words that Gupta and Manning (2011) deemedto be indicative of paper characteristics (Table 3).All the abstracts and citing sentences included inthe 2011 release of AAN were used to get thesenumbers.
The numbers clearly show that the trig-ger words appear more frequently in the set of cit-ing sentences of papers than they do in the paperabstracts.
We also found many papers that none ofthe trigger words appeared in their abstracts, whilethey do appear in their citing sentences.
This sug-gests that more paper properties (contributions, tech-niques used, etc.)
could be extracted from citationsthan from abstracts.Second, while the contributions included in an ab-stract are the claims of the paper author(s), the con-tributions highlighted in citing sentences are collec-tively deemed to be important by peer researchers.This means that the contributions extracted from ci-Rankword 1980s 1990s 2000sgrammar 22 71 123model 75 72 26rules 77 89 148statistical - 69 74syntax 257 1018 683summarization - 880 359Table 4: Ranks of selected keywords in citing sentencesto papers published in 80s, 90s and 2000stations are more important from the viewpoint of thecommunity and are likely to reflect research trendsmore accurately.We performed another simple experiment thatdemonstrates the use of citing sentences to track thechanges in the focus of research.
We split the set ofciting sentences in AAN into three subsets: the setof citing sentences that cite papers from 1980s, theset of citing sentences that cite papers from 1990s,and the set of citing sentences that cite papers from2000s.
We counted the frequencies of words in eachof the three sets.
Then, we ranked the words in eachset by the decreasing order of their frequencies.
Weselected a number of keywords and compared theirranks in the three year ranges.
Some of these key-words are listed in Table 4.
This analysis shows, forexample, that there was more focus on ?grammar?
inthe computational linguistics research in the 1980sthen this focus declined with time as indicated by thelower rank of the keyword ?grammar?
in the 1990sand 2000s.
Similarly, rule based methods were pop-ular in the 1980s and 1990s but their popularity de-clined significantly in the 2000s.3 Scientific Literature SummarizationUsing Citing SentencesThe fact that citing sentences cover different aspectsof the cited paper and highlight its most importantcontributions motivates the idea of using citing sen-tences to summarize research.
The comparison thatElkiss et al (2008) performed between abstracts andciting sentences suggests that a summary generatedfrom citing sentences will be different and proba-bly more concise and informative than the paperabstract or a summary generated from the full textof the paper.
For example, Table 5 shows the ab-stract of Resnik (1999) and 5 selected sentences thatcite it in AAN.
We notice that citing sentences con-4tain additional facts that are not in the abstract, notonly ones that summarize the paper contributions,but also those that criticize it (e.g., the last citingsentence in the Table).Previous work has explored this research direc-tion.
Qazvinian and Radev (2008) proposed amethod for summarizing scientific articles by build-ing a similarity network of the sentences that citeit, and then applying network analysis techniques tofind a set of sentences that covers as much of thepaper facts as possible.
Qazvinian et al (2010) pro-posed another summarization method that first ex-tracts a number of important key phrases from theset of citing sentences, and then finds the best sub-set of sentences that covers as many key phrases aspossible.These works focused on analyzing the citing sen-tences and selecting a representative subset that cov-ers the different aspects of the summarized article.In recent work, Abu-Jbara and Radev (2011b) raisedthe issue of coherence and readability in summariesgenerated from citing sentences.
They added a pre-processing and postprocessing steps to the summa-rization pipeline.
In the preprocessing step, they usea supervised classification approach to rule out ir-relevant sentences or fragments of sentences.
In thepostprocessing step, they improve the summary co-herence and readability by reordering the sentences,removing extraneous text (e.g.
redundant mentionsof author names and publication year).Mohammed et al (2009) went beyond single pa-per summarization.
They investigated the useful-ness of directly summarizing citation texts in theautomatic creation of technical surveys.
They gen-erated surveys from a set of Question Answering(QA) and Dependency Parsing (DP) papers, their ab-stracts, and their citation texts.
The evaluation of thegenerated surveys shows that both citation texts andabstracts have unique survey-worthy information.
Itis worth noting that all the aforementioned researchon citation-based summarization used the ACL An-thology Network (AAN) for evaluation.4 Controversy IdentificationSome arguments and claims made by researchersmay get disputed by other researchers (Teufel,1999).
The following are examples of citingsentences that dispute previous work.
(1) Even though prior work (Teufel et al, 2006) argues that citationtext is unsuitable for summarization, we show that in the frameworkof multi-document survey creation, citation texts can play a crucial role.
(2) Mining the Web for bilingual text (Resnik, 1999) is notlikely to provide sufficient quantities of high quality data.In many cases, it is useful to know which ar-guments were confirmed and accepted by theresearch community and which ones where dis-puted or even rejected.
We believe that analyzingcitation text helps identify these contrasting viewsautomatically.5 Comparison of Different TechniquesCiting sentences that compare different tech-niques or compare the techniques proposed bythe author to previous work are common.
The fol-lowing sentences are examples of such comparisons.
(3) In (Zollmann et al, 2008), an interesting comparison be-tween phrase-based, hierarchical and syntax-augmented models iscarried out, concluding that hierarchical and syntax-based modelsslightly outperform phrase-based models under large data conditionsand for sufficiently non-monotonic language pairs.
(4) Brill?s results demonstrate that this approach can outper-form the Hidden Markov Model approaches that are frequently usedfor part-of-speech tagging (Jelinek, 1985; Church, 1988; DeRose,1988; Cutting et al, 1992; Weischedel et al, 1993), as well as showingpromise for other applications.
(5) Our highest scores of 90.8% LP and 90.5% LR outperformthe scores of the best previously published parser by Charniak (2000)who obtains 90.1% for both LP and LR.Extracting such comparisons from citations can beof great benefit to researchers.
It will allow themto quickly determine which technique works betterfor their tasks.
To verify that citation text couldbe a good source for extracting comparisons, wecreated a list of words and phrases that are usuallyused to express comparisons and counted theirfrequency in AAN citing sentences.
We found, forexample, that the word compare (at its variations)5Abstract STRAND (Resnik, 1998) is a language-independent system for automatic discovery of text in parallel translation on the WorldWide Web.
This paper extends the preliminary STRAND results by adding automatic language identification, scaling up by ordersof magnitude, and formally evaluating performance.
The most recent end-product is an automatically acquired parallel corpuscomprising 2491 English-French document pairs, approximately 1.5 million words per language.SelectedCitingSentencesMany research ideas have exploited the Web in unsupervised or weakly supervised algorithms for natural language processing(e.g.
, Resnik (1999))Resnik (1999) addressed the issue of language identification for finding Web pages in the languages of interest.In Resnik (1999), the Web is harvested in search of pages that are available in two languages, with the aim of building parallelcorpora for any pair of target languages.The STRAND system of (Resnik, 1999), uses structural markup information from the pages, without looking at their content, toattempt to align them.Mining the Web for bilingual text (Resnik, 1999) is not likely to provide sufficient quantities of high quality data.Table 5: Comparison of the abstract and a selected set of sentences that cite Resnik (1999) workappears in about 4000 sentences, and that the wordsoutperform and contrast each appears in about 1000citing sentences.6 Ontology CreationIt is useful for researchers to know which tasksand research problems are important, and whattechniques and tools are usually used with them.Citation text is a good source of such information.For example, sentence (6) below shows threedifferent techniques (underlined) that were used toextend tools and resources that were created forEnglish so that they work for other languages.
Foranother example, sentence (7) shows different tasksin which re-ranking has been successfully applied.These relations can be easily extracted from citingsentences and can be possibly used to build anontology of tasks, methods, tools, and the relationsbetween them.
(6) Another strain of research has sought to exploit resources and toolsin some languages (especially English) to construct similar resourcesand tools for other languages, through heuristic projection (Yarowskyand Ngai, 2001; Xi and Hwa, 2005) or constraints in learning (Burkettand Klein, 2008; Smith and Eisner, 2009; Das and Petrov, 2011;McDonald et al, 2011) or inference (Smith and Smith, 2004).
(7) (Re)rankers have been successfully applied to numerousNLP tasks, such as parse selection (Osborne and Baldridge, 2004;Toutanova et al, 2004), parse reranking (Collins and Duffy, 2002;Charniak and Johnson, 2005), question-answering (Ravichandran etal., 2003).7 Paraphrase ExtractionIt is common that multiple citing sentences high-light the same facts about a cited paper.
Since thesesentences were written by different authors, theyoften use different wording to describe the citedpaper facts.
This motivates the idea of using citingsentences to create data sets for paraphrase extrac-tion.
For example, sentences (8) and (9) below bothcite (Turney, 2002) and highlight the same aspectof Turney?s work using slightly different wordings.Therefore, sentences (8) and (9) can be consideredparaphrases of each other.
(8) In (Turney, 2002), an unsupervised learning algorithm wasproposed to classify reviews as recommended or not recommendedby averaging sentiment annotation of phrases in reviews that containadjectives or adverbs.
(9) For example, Turney (2002) proposes a method to classifyreviews as recommended/not recommended, based on the averagesemantic orientation of the review.The paraphrase annotation of citing sentencesconsists of manually labeling which sentenceconsists of what facts.
Then, if two citing sentencesconsist of the same set of facts, they are labeledas paraphrases of each other.
For example, if apaper has 50 sentences citing it, this gives us aparaphrasing data set that consists of 50*49 = 2450pairs.
As a proof of concept, we annotated 25 papersfrom AAN using the annotation method describedabove.
This data set consisted of 33,683 sentencepairs of which 8,704 are paraphrases.The idea of using citing sentences to create datasets for paraphrase extraction was initially suggested6by Nakov et al (2004) who proposed an algorithmthat extracts paraphrases from citing sentences us-ing rules based on automatic named entity annota-tion and the dependency paths between them.8 Scientific Article ClassificationAutomatic classification of scientific articles is oneof the important tasks for creating publicationdatabases.
A variety of machine learning algorithmshave been proposed for this task.
Many of thesemethods perform the classification based on the title,the abstract, or the full text of the article.
Some othermethods used citation links in addition to content tomake classification decisions.
Cao and Gao (2005)proposed a two-phase classification system.
Thesystem first applies a content-based statistical clas-sification method which is similar to general textclassification.
In the second phase, the system usesan iterative method to update the labels of classifiedinstances using citation links.
A similar approachis also proposed by Zhang et al (2006).
These ap-proaches use citation links only to improve classifi-cation decisions that were made based on content.We hypothesize that using the text of citing sen-tences in addition to citation structure and contentleads to more accurate classification than using thecontent and citation links only.9 Terminology TranslationCiting sentences can also be used to improvemachine translation systems by using citing sen-tences from different languages to build parallelcorpus of terms and their translations.
This canbe done by identifying articles written in differentlanguages that cite a common target paper, thenextracting the citing sentences from each paper.Word alignment techniques can then be applied tothe text surrounding the reference to the commontarget paper.
The aligned words from each sourcecan then be extracted and used as translations of thesame term.
Sentences (10) and (11) below illustratehow the application of this proposed method canidentify that the underlined terms in sentence 10(Spanish) and sentence 11 (English) are translationsof each other.
(10) Spanish: Se comprobo?
que la agrupacio?n por bloquesofrec?
?a mejores resultados que, la introduccio?n de vocabulario (Hearst,1997) o las cadenas le?xicas (Hearst, 1994) y, por tanto, es la que se hautilizado en la segunda fase del algoritmo.
(11) English: This can be done either by analyzing the numberof overlapping lexical chains (Hearst, 1994) or by building ashort-range and long-range language model (Beeferman et al, 1999).10 Other Uses of Citing SentencesNakov et al (2004) proposed several other uses ofciting sentences.
First, they suggested using them asa source for unannotated comparable corpora.
Suchcomparable corpora can be used in several applica-tions such as paraphrase extraction as we showedearlier.
They also noticed that the scientific liter-ature is rife with abbreviations and synonyms, andhence, citing sentences referring to the same articlemay allow synonyms to be identified and recorded.They also proposed using citing sentences to builda model of the different ways used to express a re-lationship between two entities.
They hypothesizedthat this model can help improve both relation ex-traction and named entity recognition systems.
Fi-nally, they proposed improving the indexing andranking of publications by considering, in additionto the content of the publication, the text of citingsentences that cite it and their contexts.11 Summarizing 30 years of ACLDiscoveries Using Citing SentencesThe ACL Anthology Corpus contains all the pro-ceedings of the Annual Meeting of the Associationof Computational Linguistics (ACL) since 1979.
Allthe ACL papers and their citation links and citingsentences are included in the ACL Anthology Net-work (ACL).
In this section, we show how citingsentences can be used to summarize the most im-portant contributions that have been published in theACL conference since 1979.
We selected the mostcited papers in each year and then manually picked aciting sentence that cites a top cited and describes itcontribution.
It should be noted here that the citationcounts we used for ranking papers reflect the numberof incoming citations the paper received only fromthe venues included in AAN.
To create the summary,we used citing sentences that has the reference to thecited paper in the beginning of the sentence.
This is71979 Carbonell (1979) discusses inferring the meaning of new words.1980 Weischedel and Black (1980) discuss techniques for interacting with the linguist/developer to identify insufficiencies in the gram-mar.1981 Moore (1981) observed that determiners rarely have a direct correlation with the existential and universal quantifiers of first-orderlogic.1982 Heidorn (1982) provides a good summary of early work in weight-based analysis, as well as a weight-oriented approach toattachment decisions based on syntactic considerations only.1983 Grosz et al (1983) proposed the centering model which is concerned with the interactions between the local coherence of discourseand the choices of referring expressions.1984 Karttunen (1984) provides examples of feature structures in which a negation operator might be useful.1985 Shieber (1985) proposes a more efficient approach to gaps in the PATR-II formalism, extending Earley?s algorithm by usingrestriction to do top-down filtering.1986 Kameyama (1986) proposed a fourth transition type, Center Establishment (EST), for utterances E.g., in Bruno was the bully ofthe neighborhood.1987 Brennan et al (1987) propose a default ordering on transitions which correlates with discourse coherence.1988 Whittaker and Stenton (1988) proposed rules for tracking initiative based on utterance types; for example, statements, proposals,and questions show initiative, while answers and acknowledgements do not.1989 Church and Hanks (1989) explored tile use of mutual information statistics in ranking co-occurrences within five-word windows.1990 Hindle (1990) classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs.1991 Gale and Church (1991) extract pairs of anchor words, such as numbers, proper nouns (organization, person, title), dates, andmonetary information.1992 Pereira and Schabes (1992) establish that evaluation according to the bracketing accuracy and evaluation according to perplexityor crossentropy are very different.1993 Pereira et al (1993) proposed a soft clustering scheme, in which membership of a word in a class is probabilistic.1994 Hearst (1994) presented two implemented segmentation algorithms based on term repetition, and compared the boundaries pro-duced to the boundaries marked by at least 3 of 7 subjects, using information retrieval metrics.1995 Yarowsky (1995) describes a ?semi-unsupervised?
approach to the problem of sense disambiguation of words, also using a set ofinitial seeds, in this case a few high quality sense annotations.1996 Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree.1997 Collins (1997)?s parser and its re-implementation and extension by Bikel (2002) have by now been applied to a variety of lan-guages: English (Collins, 1999), Czech (Collins et al , 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins,2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikels web page, Arabic.1998 Lin (1998) proposed a word similarity measure based on the distributional pattern of words which allows to construct a thesaurususing a parsed corpus.1999 Rapp (1999) proposed that in any language there is a correlation between the cooccurrences of words which are translations ofeach other.2000 Och and Ney (2000) introduce a NULL-alignment capability to HMM alignment models.2001 Yamada and Knight (2001) used a statistical parser trained using a Treebank in the source language to produce parse trees andproposed a tree to string model for alignment.2002 BLEU (Papineni et al, 2002) was devised to provide automatic evaluation of MT output.2003 Och (2003) developed a training procedure that incorporates various MT evaluation criteria in the training procedure of log-linearMT models.2004 Pang and Lee (2004) applied two different classifiers to perform sentiment annotation in two sequential steps: the first classifierseparated subjective (sentiment-laden) texts from objective (neutral) ones and then they used the second classifier to classify thesubjective texts into positive and negative.2005 Chiang (2005) introduces Hiero, a hierarchical phrase-based model for statistical machine translation.2006 Liu et al (2006) experimented with tree-to-string translation models that utilize source side parse trees.2007 Goldwater and Griffiths (2007) employ a Bayesian approach to POS tagging and use sparse Dirichlet priors to minimize modelsize.2008 Huang (2008) improves the re-ranking work of Charniak and Johnson (2005) by re-ranking on packed forest, which could poten-tially incorporate exponential number of k-best list.2009 Mintz et al (2009) uses Freebase to provide distant supervision for relation extraction.2010 Chiang (2010) proposes a method for learning to translate with both source and target syntax in the framework of a hierarchicalphrase-based system.Table 6: A citation-based summary of the important contributions published in ACL conference proceedings since1979.
The top cited paper in each year is found and one citation sentence is manually picked to represent it in thesummary.8because such citing sentences are often high-quality,concise summaries of the cited work.
Table 6 showsthe summary of the ACL conference contributionsthat we created using citing sentences.12 ConclusionWe motivated and discussed several different usesof citing sentences, the text surrounding citations.We showed that citing sentences can be used to an-alyze the dynamics of research and observe how ittrends.
We also gave examples on how analyzingthe text of citing sentences can give a better under-standing of the impact of a researcher?s work andhow this impact changes over time.
In addition, wepresented several different applications that can ben-efit from citing sentences such as scientific literaturesummarization, identifying controversial arguments,and identifying relations between techniques, toolsand tasks.
We also showed how citing sentences canprovide high-quality for NLP tasks such as informa-tion extraction, paraphrase extraction, and machinetranslation.
Finally, we used AAN citing sentencesto create a citation-based summary of the importantcontributions included in the ACL conference publi-cation in the past 30 years.ReferencesAmjad Abu-Jbara and Dragomir Radev.
2011a.
Coher-ent citation-based summarization of scientific papers.In Proceedings of the 49th Annual Meeting of the As-sociation for Computational Linguistics: Human Lan-guage Technologies, pages 500?509, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.Amjad Abu-Jbara and Dragomir Radev.
2011b.
Coher-ent citation-based summarization of scientific papers.In Proceedings of the 49th Annual Meeting of the As-sociation for Computational Linguistics: Human Lan-guage Technologies, pages 500?509, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.F.
Amblard, A. Casteigts, P. Flocchini, W. Quattrocioc-chi, and N. Santoro.
2011.
On the temporal analysisof scientific network evolution.
In Computational As-pects of Social Networks (CASoN), 2011 InternationalConference on, pages 169 ?174, oct.Awais Athar.
2011.
Sentiment analysis of citations us-ing sentence structure-based features.
In Proceedingsof the ACL 2011 Student Session, pages 81?87, Port-land, OR, USA, June.
Association for ComputationalLinguistics.Christine L. Borgman and Jonathan Furner.
2002.
Schol-arly communication and bibliometrics.
ANNUAL RE-VIEW OF INFORMATION SCIENCE AND TECH-NOLOGY, 36(1):2?72.Susan E. Brennan, Marilyn W. Friedman, and Carl J. Pol-lard.
1987.
A centering approach to pronouns.
InProceedings of the 25th Annual Meeting of the Associ-ation for Computational Linguistics, pages 155?162,Stanford, California, USA, July.
Association for Com-putational Linguistics.Minh Duc Cao and Xiaoying Gao.
2005.
Combin-ing contents and citations for scientific document clas-sification.
In Proceedings of the 18th AustralianJoint conference on Advances in Artificial Intelligence,AI?05, pages 143?152, Berlin, Heidelberg.
Springer-Verlag.Jaime G. Carbonell.
1979.
Towards a self-extendingparser.
In Proceedings of the 17th Annual Meeting ofthe Association for Computational Linguistics, pages3?7, La Jolla, California, USA, June.
Association forComputational Linguistics.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL?05), pages 263?270, AnnArbor, Michigan, June.
Association for ComputationalLinguistics.David Chiang.
2010.
Learning to translate with sourceand target syntax.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, pages 1443?1452, Uppsala, Sweden, July.
Asso-ciation for Computational Linguistics.Kenneth Ward Church and Patrick Hanks.
1989.
Wordassociation norms, mutual information, and lexicogra-phy.
In Proceedings of the 27th Annual Meeting of theAssociation for Computational Linguistics, pages 76?83, Vancouver, British Columbia, Canada, June.
Asso-ciation for Computational Linguistics.Kenneth Ward Church.
1988.
A stochastic parts programand noun phrase parser for unrestricted text.
In Pro-ceedings of the Second Conference on Applied NaturalLanguage Processing, pages 136?143, Austin, Texas,USA, February.
Association for Computational Lin-guistics.Michael John Collins.
1996.
A new statistical parserbased on bigram lexical dependencies.
In Proceed-ings of the 34th Annual Meeting of the Associationfor Computational Linguistics, pages 184?191, SantaCruz, California, USA, June.
Association for Compu-tational Linguistics.9Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proceedings of the35th Annual Meeting of the Association for Computa-tional Linguistics, pages 16?23, Madrid, Spain, July.Association for Computational Linguistics.Aaron Elkiss, Siwei Shen, Anthony Fader, Gu?nes?
Erkan,David States, and Dragomir Radev.
2008.
Blind menand elephants: What do citation summaries tell usabout a research article?
J.
Am.
Soc.
Inf.
Sci.
Tech-nol., 59(1):51?62.William A. Gale and Kenneth W. Church.
1991.
A pro-gram for aligning sentences in bilingual corpora.
InProceedings of the 29th Annual Meeting of the As-sociation for Computational Linguistics, pages 177?184, Berkeley, California, USA, June.
Association forComputational Linguistics.Sharon Goldwater and Tom Griffiths.
2007.
A fullybayesian approach to unsupervised part-of-speech tag-ging.
In Proceedings of the 45th Annual Meeting ofthe Association of Computational Linguistics, pages744?751, Prague, Czech Republic, June.
Associationfor Computational Linguistics.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1983.
Providing a unified account of definitenoun phrases in discourse.
In Proceedings of the 21stAnnual Meeting of the Association for ComputationalLinguistics, pages 44?50, Cambridge, Massachusetts,USA, June.
Association for Computational Linguis-tics.Sonal Gupta and Christopher Manning.
2011.
Analyz-ing the dynamics of research by extracting key as-pects of scientific papers.
In Proceedings of 5th Inter-national Joint Conference on Natural Language Pro-cessing, pages 1?9, Chiang Mai, Thailand, November.Asian Federation of Natural Language Processing.Marti A. Hearst.
1994.
Multi-paragraph segmentationexpository text.
In Proceedings of the 32nd AnnualMeeting of the Association for Computational Lin-guistics, pages 9?16, Las Cruces, New Mexico, USA,June.
Association for Computational Linguistics.George E. Heidorn.
1982.
Experience with an easilycomputed metric for ranking alternative parses.
InProceedings of the 20th Annual Meeting of the As-sociation for Computational Linguistics, pages 82?84,Toronto, Ontario, Canada, June.
Association for Com-putational Linguistics.Donald Hindle.
1990.
Noun classification frompredicate-argument structures.
In Proceedings of the28th Annual Meeting of the Association for Compu-tational Linguistics, pages 268?275, Pittsburgh, Penn-sylvania, USA, June.
Association for ComputationalLinguistics.Liang Huang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings ofACL-08: HLT, pages 586?594, Columbus, Ohio, June.Association for Computational Linguistics.Megumi Kameyama.
1986.
A property-sharing con-straint in centering.
In Proceedings of the 24th AnnualMeeting of the Association for Computational Linguis-tics, pages 200?206, New York, New York, USA, July.Association for Computational Linguistics.Lauri Karttunen.
1984.
Features and values.
In Proceed-ings of the 10th International Conference on Compu-tational Linguistics and 22nd Annual Meeting of theAssociation for Computational Linguistics, pages 28?33, Stanford, California, USA, July.
Association forComputational Linguistics.John D. Lafferty, Andrew McCallum, and Fernando C. N.Pereira.
2001.
Conditional random fields: Proba-bilistic models for segmenting and labeling sequencedata.
In Proceedings of the Eighteenth InternationalConference on Machine Learning, ICML ?01, pages282?289, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In Proceedings of the 36th AnnualMeeting of the Association for Computational Linguis-tics and 17th International Conference on Computa-tional Linguistics, Volume 2, pages 768?774, Mon-treal, Quebec, Canada, August.
Association for Com-putational Linguistics.Yang (1) Liu, Qun Liu, and Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machine trans-lation.
In Proceedings of the 21st International Con-ference on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguis-tics, pages 609?616, Sydney, Australia, July.
Associa-tion for Computational Linguistics.Terttu Luukkonen.
1992.
Is scientists?
publishing be-haviour rewardseeking?
Scientometrics, 24:297?319.10.1007/BF02017913.Amin Mazloumian, Young-Ho Eom, Dirk Helbing, SergiLozano, and Santo Fortunato.
2011.
How citationboosts promote scientific paradigm shifts and nobelprizes.
PLoS ONE, 6(5):e18975, 05.Qiaozhu Mei and ChengXiang Zhai.
2008.
Generatingimpact-based summaries for scientific literature.
InProceedings of ACL-08: HLT, pages 816?824, Colum-bus, Ohio, June.
Association for Computational Lin-guistics.Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-sky.
2009.
Distant supervision for relation extractionwithout labeled data.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 1003?1011,Suntec, Singapore, August.
Association for Computa-tional Linguistics.10Saif Mohammad, Bonnie Dorr, Melissa Egan, AhmedHassan, Pradeep Muthukrishan, Vahed Qazvinian,Dragomir Radev, and David Zajic.
2009.
Using ci-tations to generate surveys of scientific paradigms.
InProceedings of Human Language Technologies: The2009 Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 584?592, Boulder, Colorado, June.
Associationfor Computational Linguistics.Robert C. Moore.
1981.
Problems in logical form.
InProceedings of the 19th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 117?124,Stanford, California, USA, June.
Association for Com-putational Linguistics.Preslav I. Nakov, Ariel S. Schwartz, and Marti A. Hearst.2004.
Citances: Citation sentences for semantic anal-ysis of bioscience text.
In In Proceedings of the SI-GIR04 workshop on Search and Discovery in Bioin-formatics.Hidetsugu Nanba and Manabu Okumura.
1999.
To-wards multi-paper summarization using reference in-formation.
In IJCAI ?99: Proceedings of the Six-teenth International Joint Conference on Artificial In-telligence, pages 926?931, San Francisco, CA, USA.Morgan Kaufmann Publishers Inc.Hidetsugu Nanba, Noriko Kando, Manabu Okumura, andOf Information Science.
2000.
Classification of re-search papers using citation links and citation types:Towards automatic review article generation.Franz Josef Och and Hermann Ney.
2000.
Improved sta-tistical alignment models.
In Proceedings of the 38thAnnual Meeting of the Association for ComputationalLinguistics, pages 440?447, Hong Kong, October.
As-sociation for Computational Linguistics.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics, pages 160?167, Sapporo, Japan,July.
Association for Computational Linguistics.Bo Pang and Lillian Lee.
2004.
A sentimental edu-cation: Sentiment analysis using subjectivity summa-rization based on minimum cuts.
In Proceedings ofthe 42nd Meeting of the Association for ComputationalLinguistics (ACL?04), Main Volume, pages 271?278,Barcelona, Spain, July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings of 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 311?318, Philadelphia, Pennsylva-nia, USA, July.
Association for Computational Lin-guistics.Fernando Pereira and Yves Schabes.
1992.
Inside-outside reestimation from partially bracketed corpora.In Proceedings of the 30th Annual Meeting of the As-sociation for Computational Linguistics, pages 128?135, Newark, Delaware, USA, June.
Association forComputational Linguistics.Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.Distributional clustering of english words.
In Pro-ceedings of the 31st Annual Meeting of the Associ-ation for Computational Linguistics, pages 183?190,Columbus, Ohio, USA, June.
Association for Compu-tational Linguistics.Vahed Qazvinian and Dragomir R. Radev.
2008.
Scien-tific paper summarization using citation summary net-works.
In Proceedings of the 22nd International Con-ference on Computational Linguistics (Coling 2008),pages 689?696, Manchester, UK, August.
Coling 2008Organizing Committee.Vahed Qazvinian and Dragomir R. Radev.
2010.
Identi-fying non-explicit citing sentences for citation-basedsummarization.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, pages 555?564, Uppsala, Sweden, July.
Associa-tion for Computational Linguistics.Vahed Qazvinian, Dragomir R. Radev, and ArzucanOzgur.
2010.
Citation summarization throughkeyphrase extraction.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics(Coling 2010), pages 895?903, Beijing, China, Au-gust.
Coling 2010 Organizing Committee.Dragomir R. Radev, Pradeep Muthukrishnan, and VahedQazvinian.
2009.
The acl anthology network corpus.In NLPIR4DL ?09: Proceedings of the 2009 Workshopon Text and Citation Analysis for Scholarly Digital Li-braries, pages 54?61, Morristown, NJ, USA.
Associa-tion for Computational Linguistics.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated english and german cor-pora.
In Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics, pages519?526, College Park, Maryland, USA, June.
Asso-ciation for Computational Linguistics.Sidney Redner.
2005.
Citation statistics from 110 yearsof physical review.
Physics Today, 58(6):49?54.Philip Resnik.
1999.
Mining the web for bilingual text.In Proceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics, pages 527?534, College Park, Maryland, USA, June.
Associationfor Computational Linguistics.Stuart M. Shieber.
1985.
Using restriction to ex-tend parsing algorithms for complex-feature-basedformalisms.
In Proceedings of the 23rd Annual Meet-ing of the Association for Computational Linguistics,pages 145?152, Chicago, Illinois, USA, July.
Associ-ation for Computational Linguistics.11Advaith Siddharthan and Simone Teufel.
2007.
Whoseidea was this, and why does it matter?
attributingscientific work to citations.
In In Proceedings ofNAACL/HLT-07.Simone Teufel, Advaith Siddharthan, and Dan Tidhar.2006.
Automatic classification of citation function.
InIn Proc.
of EMNLP-06.Simone Teufel.
1999.
Argumentative zoning: Informa-tion extraction from scientific text.
Technical report.Simone Teufel.
2007.
Argumentative zoning for im-proved citation indexing.
computing attitude and affectin text.
In Theory and Applications, pages 159170.Ralph M. Weischedel and John E. Black.
1980.
If theparser fails.
In Proceedings of the 18th Annual Meet-ing of the Association for Computational Linguistics,pages 95?95, Philadelphia, Pennsylvania, USA, June.Association for Computational Linguistics.Steve Whittaker and Phil Stenton.
1988.
Cues and con-trol in expert-client dialogues.
In Proceedings of the26th Annual Meeting of the Association for Computa-tional Linguistics, pages 123?130, Buffalo, New York,USA, June.
Association for Computational Linguis-tics.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proceedings of 39thAnnual Meeting of the Association for ComputationalLinguistics, pages 523?530, Toulouse, France, July.Association for Computational Linguistics.David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In Pro-ceedings of the 33rd Annual Meeting of the Associ-ation for Computational Linguistics, pages 189?196,Cambridge, Massachusetts, USA, June.
Associationfor Computational Linguistics.M.
Zhang, X. Gao, M.D.
Cao, and Yuejin Ma.
2006.Neural networks for scientific paper classification.In Innovative Computing, Information and Control,2006.
ICICIC ?06.
First International Conference on,volume 2, pages 51 ?54, 30 2006-sept. 1.12
