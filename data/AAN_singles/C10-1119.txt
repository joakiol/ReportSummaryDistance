Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1056?1064,Beijing, August 2010Investigating the cross-linguistic potential of VerbNet -style classificationLin Sun and Anna KorhonenComputer LaboratoryUniversity of Cambridgels418,alk23@cl.cam.ac.ukThierry PoibeauLaTTiCe, UMR8094CNRS & ENSthierry.poibeau@ens.frCe?dric MessiantLIPN, UMR7030CNRS & U. Paris 13cedric.messiant@lipn.frAbstractVerb classes which integrate a wide rangeof linguistic properties (Levin, 1993) haveproved useful for natural language pro-cessing (NLP) applications.
However,the real-world use of these classes hasbeen limited because for most languages,no resources similar to VerbNet (Kipper-Schuler, 2005) are available.
We applya verb clustering approach developed forEnglish to French ?
a language for whichno such experiment has been conductedyet.
Our investigation shows that not onlythe general methodology but also the bestperforming features are transferable be-tween the languages, making it possibleto learn useful VerbNet style classes forFrench automatically without language-specific tuning.1 IntroductionA number of verb classifications have been built tosupport natural language processing (NLP) tasks(Grishman et al, 1994; Miller, 1995; Baker et al,1998; Palmer et al, 2005; Kipper-Schuler, 2005;Hovy et al, 2006).
These include both syntacticand semantic classifications, as well as ones whichintegrate aspects of both.
Classifications which in-tegrate a wide range of linguistic properties canbe particularly useful for NLP applications suffer-ing from data sparseness.
One such classificationis VerbNet (Kipper-Schuler, 2005).
Building onthe taxonomy of Levin (1993), VerbNet groupsverbs (e.g.
deliver, post, dispatch) into classes(e.g.
SEND) on the basis of their shared mean-ing components and syntactic behaviour, identi-fied in terms of meaning preserving diathesis al-ternations.
Such classes can be identified acrossthe entire lexicon, and they may also apply acrosslanguages, since their meaning components aresaid to be cross-linguistically applicable (Jack-endoff, 1990).Offering a powerful tool for generalization, ab-straction and prediction, VerbNet classes havebeen used to support many important NLPtasks, including e.g.
computational lexicography,parsing, word sense disambiguation, semanticrole labeling, information extraction, question-answering, and machine translation (Swier andStevenson, 2004; Dang, 2004; Shi and Mihalcea,2005; Abend et al, 2008).
However, to date theirexploitation has been limited because for mostlanguages, no Levin style classification is avail-able.Since manual classification is costly (Kipperet al, 2008) automatic approaches have been pro-posed recently which could be used to learn novelclassifications in a cost-effective manner (Joaniset al, 2008; Li and Brew, 2008; O?
Se?aghdhaand Copestake, 2008; Vlachos et al, 2009; Sunand Korhonen, 2009).
However, most work onLevin type classification has focussed on English.Large-scale research on other languages such asGerman (Schulte im Walde, 2006) and Japanese(Suzuki and Fukumoto, 2009) has focussed on se-mantic classification.
Although the two classifica-tion systems have shared properties, studies com-paring the overlap between VerbNet and WordNet(Miller, 1995) have reported that the mapping isonly partial and many to many due to fine-grainednature of classes based on synonymy (Shi and Mi-halcea, 2005; Abend et al, 2008).Only few studies have been conducted on Levinstyle classification for languages other than En-glish.
In their experiment involving 59 verbs andthree classes, Merlo et al (2002) applied a su-pervised approach developed for English to Ital-ian, obtaining high accuracy (86.3%).
In an-other experiment with 60 verbs and three classes,1056they showed that features extracted from Chinesetranslations of English verbs can improve Englishclassification.
These results are promising, butthose from a later experiment by Ferrer (2004)are not.
Ferrer applied a clustering approach de-veloped for English to Spanish, and evaluated itagainst the manual classification of Va?zquez et al(2000), constructed using criteria similar (but notidentical) to Levin?s.
This experiment involving514 verbs and 31 classes produced results onlyslightly better than the random baseline.In this paper, we investigate the cross-linguisticpotential of Levin style classification further.
Inpast years, verb classification techniques ?
in par-ticular unsupervised ones ?
have improved con-siderably, making investigations for a new lan-guage more feasible.
We take a recent verb clus-tering approach developed for English (Sun andKorhonen, 2009) and apply it to French ?
a ma-jor language for which no such experiment hasbeen conducted yet.
Basic NLP resources (cor-pora, taggers, parsers and subcategorization ac-quisition systems) are now sufficiently developedfor this language for the application of a state-of-the-art verb clustering approach to be realistic.Our investigation reveals similarities betweenthe English and French classifications, support-ing the linguistic hypothesis (Jackendoff, 1990)and the earlier result of Merlo et al (2002)that Levin classes have a strong cross-linguisticbasis.
Not only the general methodology butalso best performing features are transferable be-tween the languages, making it possible to learnuseful classes for French automatically withoutlanguage-specific tuning.2 French Gold StandardThe development of an automatic verb classifi-cation approach requires at least an initial goldstandard.
Some syntactic (Gross, 1975) and se-mantic (Vossen, 1998) verb classifications existfor French, along with ones which integrate as-pects of both (Saint-Dizier, 1998).
Since none ofthese resources offer classes similar to Levins?,we followed the idea of Merlo et al (2002) andtranslated a number of Levin classes from Englishto French.
As our aim was to to investigate thecross-linguistic applicability of classes, we tookan English gold standard which has been used toevaluate several recent clustering works ?
that ofSun et al (2008).
This resource includes 17 fine-grained Levin classes.
Each class has 12 memberverbs whose predominant sense in English (ac-cording to WordNet) belongs to that class.Member verbs were first translated to French.Where several relevant translations were identi-fied, each of them was considered.
For each can-didate verb, subcategorization frames (SCFs) wereidentified and diathesis alternations were consid-ered using the criteria of Levin (1993): alterna-tions must result in the same or extended verbsense.
Only verbs sharing diathesis alternationswere kept in the class.For example, the gold standard class 31.1AMUSE includes the following English verbs:stimulate, threaten, shock, confuse, upset, over-whelm, scare, disappoint, delight, exhaust, in-timidate and frighten.
Relevant French transla-tions were identified for all of them: abattre,accabler, briser, de?primer, consterner, ane?antir,e?puiser, exte?nuer, e?craser, ennuyer, e?reinter, inon-der.
The majority of these verbs take similar SCFsand diathesis alternations, e.g.
Cette affaire e?craseMarie (de chagrin), Marie est e?crase?e par le cha-grin, Le chagrin e?crase Marie.
However, stim-uler (stimulate) and menacer (threaten) do not,and they were therefore removed.40% of translations were discarded fromclasses because they did not share the same aler-nations.
The final version of the gold stan-dard (shown in table 1) includes 171 verbs in 16classes.
Each class is named according to theoriginal Levin class.
The smallest class (30.3) in-cludes 7 verbs and the largest (37.3) 16.
The aver-age number of verbs per class is 10.7.3 Verb ClusteringWe performed an experiment where we?
took a French corpus and a SCF lexicon au-tomatically extracted from that corpus,?
extracted from these resources a range of fea-tures (lexical, syntactic and semantic) ?
arepresentative sample of those employed inrecent English experiments,1057Class No Class Verbs9.1 PUT accrocher, de?poser, mettre, placer, re?partir, re?inte?grer, empiler, emporter, enfermer,inse?rer, installer10.1 REMOVE o?ter, enlever, retirer, supprimer, retrancher, de?barrasser, soustraire, de?compter, e?liminer11.1 SEND envoyer, lancer, transmettre, adresser, porter, expe?dier, transporter, jeter, renvoyer, livrer13.5.1 GET acheter, prendre, saisir, re?server, conserver, garder, pre?server, maintenir, retenir, louer,affre?ter18.1 HIT cogner, heurter, battre, frapper, fouetter, taper, rosser, brutaliser, e?reinter, maltraiter,corriger,22.2 AMALGAMATE incorporer, associer, re?unir, me?langer, me?ler, unir, assembler, combiner, lier, fusionner29.2 CHARACTERIZE appre?hender, concevoir, conside?rer, de?crire, de?finir, de?peindre, de?signer, envisager,identifier, montrer, percevoir, repre?senter, ressentir30.3 PEER regarder, e?couter, examiner, conside?rer, voir, scruter, de?visager31.1 AMUSE abattre, accabler, briser, de?primer, consterner, ane?antir, e?puiser, exte?nuer, e?craser, en-nuyer, e?reinter, inonder,36.1 CORRESPOND coope?rer, participer, collaborer, concourir, contribuer, prendre part, s?associer, travaille37.3 MANNER OFSPEAKINGra?ler, gronder, crier, ronchonner, grogner, bougonner, maugre?er, rouspe?ter, grommeler,larmoyer, ge?mir, geindre, hurler, gueuler, brailler, chuchoter37.7 SAY dire, re?ve?ler, de?clarer, signaler, indiquer, montrer, annoncer, re?pondre, affirmer, certifier,re?pliquer43.1 LIGHT EMIS-SIONbriller, e?tinceler, flamboyer, luire, resplendir, pe?tiller, rutiler, rayonner., scintiller45.4 CHANGE OFSTATEme?langer, fusionner, consolider, renforcer, fortifier, adoucir, polir, atte?nuer, tempe?rer,pe?trir, fac?onner, former47.3 MODES OF BE-INGtrembler, fre?mir, osciller, vaciller, vibrer, tressaillir, frissonner, palpiter, gre?siller, trem-bloter, palpiter51.3.2 RUN voyager, aller, se promener, errer, circuler, se de?placer, courir, bouger, naviguer, passerTable 1: A Levin style gold standard for French?
clustered the features using a method whichhas proved promising in both English andGerman experiments: spectral clustering,?
evaluated the clusters both quantitatively (us-ing the gold standard) and qualitatively,?
and compared the performance to that re-cently obtained for English in order to gaina better understanding of the cross-linguisticand language-specific properties of verb clas-sificationThis work is described in the subsequent sections.3.1 Data: the LexSchem LexiconWe extracted the features for clustering fromLexSchem (Messiant et al, 2008).
This large sub-categorization lexicon provides SCF frequency in-formation for 3,297 French verbs.
It was acquiredfully automatically from Le Monde newspapercorpus (200M words from years 1991-2000) us-ing ASSCI ?
a recent subcategorization acquisi-tion system for French (Messiant, 2008).
Systemssimilar to ASSCI have been used in recent verbclassification works e.g.
(Schulte im Walde, 2006;Li and Brew, 2008; Sun and Korhonen, 2009).Like these other systems, ASSCI takes raw corpusdata as input.
The data is first tagged and lemma-tized using the Tree-Tagger and then parsed us-ing Syntex (Bourigault et al, 2005).
Syntex isa shallow parser which employs a combinationof statistics and heuristics to identify grammati-cal relations (GRs) in sentences.
ASSCI considersGRs where the target verbs occur and constructsSCFs from nominal, prepositional and adjectivalphrases, and infinitival and subordinate clauses.When a verb has no dependency, its SCF is con-sidered as intransitive.
ASSCI assumes no pre-defined list of SCFs but almost any combinationof permitted constructions can appear as a candi-date SCF.
The number of automatically generatedSCF types in LexSchem is 336.Many candidate SCFs are noisy due to process-ing errors and the difficulty of argument-adjunctdistinction.
Most SCF systems assume that truearguments occur in argument positions more fre-quently than adjuncts.
Many systems also inte-grate filters for removing noise from system out-put.
When LexSchem was evaluated after filter-1058ing its F-measure was 69 ?
which is similar tothat of other current SCF systems (Messiant et al,2008) We used the unfiltered version of the lexi-con because English experiments have shown thatinformation about adjuncts can help verb cluster-ing (Sun et al, 2008).4 FeaturesLexical entries in LexSchem provide a variety ofmaterial for verb clustering.
Using this material,we constructed a range of features for experimen-tation.
The first three include basic informationabout SCFs:F1: SCFs and their relative frequencies with indi-vidual verbs.
SCFs abstract over particles andprepositions.F2: F1, with SCFs parameterized for the tense(the POS tag) of the verb.F3: F2, with SCFs parameterized for prepositions(PP).The following six features include informa-tion about the lexical context (co-occurrences)of verbs.
We adopt the best method of Li andBrew (2008) where collocations (COs) are ex-tracted from the window of words immediatelypreceding and following a lemmatized verb.
Stopwords are removed prior to extraction.F4, F6, F8: COs are extracted from the windowof 4, 6 and 8 words, respectively.
The relativeword position is ignored.F5, F7, F9: F4, F6 and F8 with the relative wordposition recorded.The next four features include informationabout lexical preferences (LP) of verbs in argu-ment head positions of specific GRs associatedwith the verb:F10: LP(PREP): the type and frequency of prepo-sitions in the preposition (PREP) relation.F11: LP(SUBJ): the type and frequency of nounsin the subject (SUBJ) relation.F12: LP(IOBJ): the type and frequency of nounsin the object (OBJ) and indirect object (IOBJ)relation.F13: LP(ALL): the combination of F10-F13.The final two features refine SCF features withLPs and semantic information about verb selec-tional preferences (SP):F14-F16: F1-F3 parameterized for LPs.F17: F3 refined with SPs.We adopt a fully unsupervised approach to SPacquisition using the method of Sun and Korho-nen (2009), with the difference that we determinethe optimal number of SP clusters automaticallyfollowing Zelnik-Manor and Perona (2004).
Themethod is introduced in the following section.
Theapproach involves (i) taking the GRs (SUBJ, OBJ,IOBJ) associated with verbs, (ii) extracting all theargument heads in these GRs, and (iii) clusteringthe resulting N most frequent argument heads intoM classes.
The empirically determined N 200was used.
The method produced 40 SP clusters.5 Clustering MethodsSpectral clustering (SPEC) has proved promisingin previous verb clustering experiments (Brewand Schulte im Walde, 2002; Sun and Korho-nen, 2009) and other similar NLP tasks involv-ing high dimensional feature space (Chen et al,2006).
Following Sun and Korhonen (2009) weused the MNCut spectral clustering (Meila andShi, 2001) which has a wide applicability anda clear probabilistic interpretation (von Luxburg,2007; Verma and Meila, 2005).
However, we ex-tended the method to determine the optimal num-ber of clusters automatically using the techniqueproposed by (Zelnik-Manor and Perona, 2004).Clustering groups a given set of verbs V ={vn}Nn=1 into a disjoint partition of K classes.SPEC takes a similarity matrix as input.
All ourfeatures can be viewed as probabilistic distribu-tions because the combination of different fea-tures is performed via parameterization.
Thus weuse the Jensen-Shannon divergence (JSD) to con-struct the similarity matrix.
The JSD between1059two feature vectors v and v?
is djsd(v, v?)
=12D(v||m)+ 12D(v?||m) where D is the Kullback-Leibler divergence, and m is the average of the vand v?.The similarity matrix W is constructed whereWij = exp(?djsd(v, v?)).
In SPEC, the simi-larities Wij are viewed as the connection weightij of a graph G over V .
The similarity matrixW is thus the adjacency matrix for G. The de-gree of a vertex i is di = ?Nj=1 wij .
A cut be-tween two partitions A and A?
is defined to beCut(A,A?)
=?m?A,n?A?
Wmn.The similarity matrix W is normalized into astochastic matrix P .P = D?1W (1)The degree matrix D is a diagonal matrix whereDii = di.It was shown by Meila and Shi (2001) that if Phas the K leading eigenvectors that are piecewiseconstant1 with respect to a partition I?
and theireigenvalues are not zero, then I?
minimizes themultiway normalized cut(MNCut):MNCut(I) = K ?
?Kk=1 Cut(Ik,Ik)Cut(Ik,I)Pmn can be interpreted as the transition proba-bility between vertices m,n.
The criterion canthus be expressed as MNCut(I) = ?Kk=1(1 ?P (Ik ?
Ik|Ik)) (Meila, 2001), which is the sumof transition probabilities across different clusters.This criterion finds the partition where the randomwalks are most likely to happen within the samecluster.
In practice, the leading eigenvectors of Pare not piecewise constant.
But we can extract thepartition by finding the approximately equal ele-ments in the eigenvectors using a clustering algo-rithm like K-Means.As the value of K is not known beforehand, weuse Zelnik-Manor and Perona (2004)?s method toestimate it.
This method finds the optimal valueby minimizing a cost function based on the eigen-vector structure of W .Like Brew and Schulte im Walde (2002), wecompare SPEC against a K-Means baseline.
Weused the Matlab implementation with euclideandistance as the distance measure.1The eigenvector v is piecewise constant with respect toI if v(i) = v(j)?i, j ?
Ik and k ?
1, 2...K6 Experimental Evaluation6.1 Data and Pre-processingThe SCF-based features (F1-F3 and F14-F17)were extracted directly from LexSchem.
The CO(F4-F9) and LP features (F10-F13) were extractedfrom the raw and parsed corpus sentences, respec-tively, which were used for creating the lexicon.Features that only appeared once were removed.Feature vectors were normalized by the sum of thefeature values before clustering.
Since our clus-tering algorithms have an element of randomness,we repeated clustering multiple times.
We reportthe results that minimize the distortion (the dis-tance to cluster centroid).6.2 Evaluation MeasuresWe employ the same measures for evaluation aspreviously employed e.g.
by O?
Se?aghdha andCopestake (2008) and Sun and Korhonen (2009).The first measure is modified purity (mPUR) ?a global measure which evaluates the mean preci-sion of clusters.
Each cluster is associated with itsprevalent class.
The number of verbs in a clusterK that take this class is denoted by nprevalent(K).Verbs that do not take it are considered as errors.Clusters where nprevalent(K) = 1 are disregardedas not to introduce a bias towards singletons:mPUR =?nprevalent(ki)>2nprevalent(ki)number of verbsThe second measure is weighted class accuracy(ACC): the proportion of members of dominantclusters DOM-CLUSTi within all classes ci.ACC =?Ci=1 verbs in DOM-CLUSTinumber of verbsmPUR and ACC can be seen as a measure of pre-cision(P) and recall(R) respectively.
We calculateF measure as the harmonic mean of P and R:F = 2 ?
mPUR ?
ACCmPUR + ACCThe random baseline (BL) is calculated as fol-lows: BL = 1/number of classes7 Evaluation7.1 Quantitative EvaluationIn our first experiment, we evaluated 116 verbs ?those which appeared in LexSchem the minimum1060of 150 times.
We did this because English exper-iments had shown that due to the Zipfian natureof SCF distributions, 150 corpus occurrences aretypically needed to obtain a sufficient number offrames for clustering (Sun et al, 2008).Table 2 shows F-measure results for all the fea-tures.
The 4th column of the table shows, for com-parison, the results of Sun and Korhonen (2009)obtained for English when they used the same fea-tures as us, clustered them using SPEC, and evalu-ated them against the English version of our goldstandard, also using F-measure2.As expected, SPEC (the 2nd column) outper-forms K-Means (the 3rd column).
Looking at thebasic SCF features F1-F3, we can see that they per-form significantly better than the BL method.
F3performs the best among the three features bothin French (50.6 F) and in English (63.3 F).
Wetherefore use F3 as the SCF feature in F14-F17(the same was done for English).In French, most CO features (F4-F9) outper-form SCF features.
The best result is obtainedwith F7: 55.1 F. This is clearly better than thebest SCF result 50.6 (F3).
This result is interestingsince SCFs correspond better than COs with fea-tures used in manual Levin classification.
Also,SCFs perform considerably better than COs in theEnglish experiment (we only have the result for F4available, but it is considerably lower than the re-sult for F3).
However, earlier English studies havereported contradictory results (e.g.
Li and Brew(2008) showed that CO performs better than SCFin supervised verb classification), indicating thatthe role of CO features in verb classification re-quires further investigation.Looking at the LP features, F13 produces thebest F (52.7) for French which is slightly betterthan the best SCF result for the language.
Alsoin English, F13 performs the best in this featuregroup and yields a higher result than the best SCF-based feature F3.Parameterizing the best SCF feature F3 with LPs(F14-16) and SPs (F17) yields better performance2Note that the results for the two languages are not mu-tually comparable due to differences in test sets, data sizes,and feature extraction systems (see Section 8 for discussion).The results for English are included so that we can comparethe relative performance of individual features in the two lan-guages in question.in French.
F15 and F17 have the F of 54.5 and54.6, respectively.
These results are so close tothe result of the best CO feature F7 (55.1 ?
whichis the highest result in this experiment) that thedifferences are not statistically significant.
In En-glish, the results of F14-F17 are similarly good;however, only F17 beats the already high perfor-mance of F13.On the basis of this experiment, it is difficult totell whether shallow CO features or more sophisti-cated SCF-based features are better for French.
Inthe English experiment sophisticated features per-formed better (the SCF-SP feature was the best).However, the English experiment employed amuch larger dataset.
These more sophisticatedfeatures may suffer from data sparseness in ourFrench experiment since although we required theminimum of 150 occurrences per verb, verb clus-tering performance tends to improve when moredata is available, and given the fine-grained natureof LexShem SCFs it is likely that more data is re-quired for optimal performance.We therefore performed another experimentwith French on the full set of 147 verbs, usingSPEC, where we investigated the effect of instancefiltering on the performance of the best featuresfrom each feature group: F3, F7, F13 and F17.The results shown in Table 3 reveal that the perfor-mance of the features remains fairly similar untilthe instance threshold of 1000.
When 2000 occur-rences per verb are used, the differences becomeclearer, until at the threshold of 4000, it is obviousthat the most sophisticated SCF-SP feature F17 isby far the best feature for French (65.4 F) and theSCF feature F3 the second best (60.5 F).
The CO-feature F7 and the LP feature F13 are not nearly asgood (53.4 and 51.0 F).Although the results at different thresholds arenot comparable due to the different number ofverbs and classes (see columns 2-3), the resultsfor features at the same threshold are.
Those re-sults suggest that when 2000 or more occurrencesper verb are used, most features perform like theyperformed for English in the experiment of Sunand Korhonen (2009), with CO being the least in-formative3 and SCF-SP being the most informa-3However, it is worth noting that CO is not a useless fea-ture.
As table 3 shows, when 150 or fewer occurrences are1061SPEC K Eng.BL 6.7 6.7 6.7F1 SCF 42.4 39.3 57.8F2 SCF(POS) 45.9 40.3 46.7F3 SCF(PP) 50.6 36.9 63.3F4 CO(4) 50.3 38.2 40.9F5 CO(4+loc) 48.8 26.3 -F6 CO(6) 52.7 29.2 -F7 CO(6+loc) 55.1 33.8 -F8 CO(8) 54.2 36.4 -F9 CO(8+loc) 54.6 37.2 -F10 LP(PREP) 35.5 32.8 49.0F11 LP(SUBJ) 33.7 23.6 -F12 LP(OBJ) 50.1 33.3 -F13 LP(ALL) 52.7 40.1 74.6F14 SCF+LP(SUBJ) 50.3 40.1 71.7F15 SCF+LP(OBJ) 54.5 35.6 74.0F16 SCF+LP(SUBJ+OBJ) 53.4 36.2 73.0F17 SCF+SP 54.6 39.8 80.4Table 2: Results for all the features for French(SPEC and K-means) and English (SPEC)THR Verbs Cls F3 F7 F13 F170 147 15 43.7 57.5 43.3 50.150 137 15 47.9 56.1 44.8 49.1100 125 15 49.2 54.3 44.8 49.5150 116 15 50.6 55.1 52.7 54.6200 110 15 54.9 52.9 49.7 52.5400 96 15 52.7 52.9 43.9 53.21000 71 15 51.4 54.0 44.8 54.52000 59 12 52.3 45.9 42.7 53.53000 51 12 55.7 49.0 46.8 59.24000 43 10 60.5 53.4 51.0 65.4Table 3: The effect of verb frequencytive feature.
The only exception is the LP featurewhich performed better than CO in English.7.2 Qualitative EvaluationWe conducted qualitative analysis of the clustersfor French: those created using SPEC with F17and F3.
Verbs in the gold standard classes 29.2,36.1, 37.3, 37.7 and 47.3 (Table 1) performedparticularly well, with the majority of memberverbs found in the same cluster.
These verbsare ideal for clustering because they have distinc-tive syntactic-semantic characteristics.
For exam-ple, verbs in 29.2 CHARACTERIZE class (e.g.
con-cevoir, conside?rer, de?peindre) not only have a veryspecific meaning but they also take high frequencySCFs involving the preposition comme (Eng.
as)available for a verb, CO outperforms all the other features inFrench, compensating for data sparseness.which is not typical to many other classes.
Inter-estingly, Levin classes 29.2, 36.1, 37.3, and 37.7were among the best performing classes also inthe supervised verb classification experiment ofSun et al (2008) because these classes have dis-tinctive characteristics also in English.The benefit of sophisticated features whichintegrate also semantic (SP) information (F17)is particularly evident for classes with non-distinctive syntactic characteristics.
For example,the intransitive verbs in 43.1 LIGHT EMISSIONclass (e.g.
briller, e?tinceler, flamboyer) are diffi-cult to cluster based on syntax only, but semanticfeatures work because the verbs pose strong SPson their subjects (entities capable of light emis-sion).
In the experiment of Sun et al (2008), 43.1was the worst performing class, possibly becauseno semantic features were used in the experiment.The most frequent source of error is syntac-tic idiosyncracy.
This is particularly evidentfor classes 10.1 REMOVE and 45.4 CHANGE OFSTATE.
Although verbs in these classes can takesimilar SCFs and alternations, only some of themare frequent in data.
For example, the SCF o?ter Xa` Y is frequent for verbs in 10.1, but not o?ter Xde Y.
Although class 10.1 did not suffer from thisproblem in the English experiment of Sun et al(2008), class 45.4 did.
Class 45.4 performs par-ticularly bad in French also because its memberverbs are low in frequency.Some errors are due to polysemy, caused partlyby the fact that the French version of the gold stan-dard was not controlled for this factor.
Some verbshave their predominant senses in classes which aremissing in the gold standard, e.g.
the most fre-quent sense of retenir is memorize, not keep as inthe gold standard class 13.5.1.
GET.Finally, some errors are not true errors butdemonstrate the capability of clustering to learnnovel information.
For example, the CHANGEOF STATE class 45.4 includes many antonyms(e.g.
weaken vs. strenghten).
Clustering (us-ing F17) separates these antonyms, so that verbsadoucir, atte?nuer and tempe?rer appear in one clus-ter and consolider and renforcer in another.
Al-though these verbs share the same alternations,their SPs are different.
The opposite effect can beobserved when clustering maps together classes1062which are semantically and syntactically related(e.g.
36.1 CORRESPOND and 37.7 SPEAK).
Suchclasses are distinct in Levin and VerbNet, al-though should ideally be related.
Cases such asthese show the potential of clustering in discover-ing novel valuable information in data.8 Discussion and ConclusionWhen sufficient corpus data is available, there isa strong correlation between the types of featureswhich perform the best in English and French.When the best features are used, many individ-ual Levin classes have similar performance in thetwo languages.
Due to differences in data setsdirect comparison of performance figures for En-glish and French is not possible.
When consid-ering the general level of performance, our bestperformance for French (65.4 F) is lower than thebest performance for English in the experiment ofSun and Korhonen (2009).
However, it does com-pare favourably to the performance of other state-of-the-art (even supervised) English systems (Joa-nis et al, 2008; Li and Brew, 2008; O?
Se?aghdhaand Copestake, 2008; Vlachos et al, 2009).
Thisis impressive considering that we experimentedwith a fully unsupervised approach originally de-veloped for another language.When aiming to improve performance further,employing larger data is critical.
Most recent ex-periments on English have employed bigger datasets, and unlike us, some of them have only con-sidered the predominant senses of medium-highfrequency verbs.
As seen in section 7.1, such dif-ferences in data can have significant impact onperformance.
However, parser and feature ex-traction performance can also play a big role inoverall accuracy, and should therefore be inves-tigated further (Sun and Korhonen, 2009).
Therelatively low performance of basic LP featuresin French suggests that at least some of the cur-rent errors are due to parsing.
Future researchshould investigate the source of error at differentstages of processing.
In addition, it would be in-teresting to investigate whether language-specifictuning (e.g.
using language specific features suchas auxiliary classes) can further improve perfor-mance on French.Earlier works most closely related to ours arethose of Merlo et al (2002) and Ferrer (2004).Our results contrast with those of Ferrer whoshowed that a clustering approach does not trans-fer well from English to Spanish.
However, sheused basic SCF and named entity features only,and a clustering algorithm less suitable for highdimensional data.
Like us, Merlo et al (2002) cre-ated a gold standard by translating Levin classesto another language (Italian).
They also applied amethod developed for English to Italian, and re-ported good overall performance using featuresdeveloped for English.
Although the experimentwas small (focussing on three classes and a fewfeatures only) and involved supervised classifica-tion, the results agree with ours.These experiments support the linguistic hy-pothesis that Levin style classification can becross-linguistically applicable.
A clustering tech-nique such as the one presented here could be usedas a tool for investigating whether classificationsare similar across a wider range of more diverselanguages.
From the NLP perspective, the fact thatan unsupervised technique developed for one lan-guage can be applied to another language with-out the need for substantial tuning means that au-tomatic techniques could be used to hypothesiseuseful Levin style classes for further languages.This, in turn, could facilitate the creation of mul-tilingual VerbNets in the future.9 AcknowledgementOur work was funded by the Royal Society Uni-versity Research Fellowship (AK), the DorothyHodgkin Postgraduate Award (LS), the EPSRCgrants EP/F030061/1 and EP/G051070/1 (UK)and the EU FP7 project ?PANACEA?.ReferencesOmri Abend, Roi Reichart, and Ari Rappoport.
Asupervised algorithm for verb disambiguation intoVerbNet classes.
In Proc.
of COLING, pages 9?16,2008.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.The Berkeley FrameNet Project.
In COLING-ACL,pages 86?90, 1998.Didier Bourigault, Marie-Paule Jacques, Ce?cile Fabre,Ce?cile Fre?rot, and Sylwia Ozdowska.
Syntex,analyseur syntaxique de corpus.
In Actes des106312e`mes journe?es sur le Traitement Automatique desLangues Naturelles, 2005.Chris Brew and Sabine Schulte im Walde.
Spectralclustering for German verbs.
In Proc.
of EMNLP,pages 117?124, 2002.Jinxiu Chen, Dong-Hong Ji, Chew Lim Tan, andZheng-Yu Niu.
Unsupervised relation disambigua-tion using spectral clustering.
In Proc.
of COL-ING/ACL, pages 89?96, 2006.Hoa Trang Dang.
Investigations into the Role of Lexi-cal Semantics in Word Sense Disambiguation.
PhDthesis, CIS, University of Pennsylvania, 2004.Eva Esteve Ferrer.
Towards a semantic classification ofSpanish verbs based on subcategorisation informa-tion.
In Proc.
of ACL Student Research Workshop,2004.Ralph Grishman, Catherine Macleod, and Adam Mey-ers.
Comlex syntax: building a computational lexi-con.
In Proc.
of COLING, pages 268?272, 1994.Maurice Gross.
Me?thodes en syntaxe.
Hermann, Paris,1975.Eduard Hovy, Mitch Marcus, Martha Palmer,L.
Ramshaw, and R. Weischedel.
Ontonotes: The90% solution.
In HLT/NAACL, 2006.Ray Jackendoff.
Semantic Structures.
The MIT Press,Cambridge, MA, 1990.Eric Joanis, Suzanne Stevenson, and David James.
Ageneral feature space for automatic verb classifica-tion.
Nat.
Lang.
Eng., 14(3):337?367, 2008.Karin Kipper, Anna Korhonen, Neville Ryant, andMartha Palmer.
A large-scale classification of En-glish verbs.
Language Resources and Evaluation,42:21?40, 2008.Karin Kipper-Schuler.
VerbNet: A broad-coverage,comprehensive verb lexicon.
University of Pennsyl-vania, PA, 2005.Beth.
Levin.
English verb classes and alternations: Apreliminary investigation.
Chicago, IL, 1993.Jianguo Li and Chris Brew.
Which Are the Best Fea-tures for Automatic Verb Classification.
In Proc.
ofACL, pages 434?442, 2008.Marina.
Meila.
The multicut lemma.
Technical report,University of Washington, 2001.Marina Meila and Jianbo Shi.
A random walks view ofspectral segmentation.
In AISTATS, 2001.Paola Merlo, Suzanne Stevenson, Vivian Tsang, andGianluca Allaria.
A multilingual paradigm for auto-matic verb classification.
In Proc.
of ACL, 2002.Ce?dric Messiant.
ASSCI : A subcategorization framesacquisition system for French.
In Proc.
of ACL Stu-dent Research Workshop, pages 55?60, 2008.Ce?dric Messiant, Thierry Poibeau, and Anna Korho-nen.
LexSchem: a Large Subcategorization Lexiconfor French Verbs.
In Proc.
of LREC, 2008.George A. Miller.
WordNet: a lexical database for En-glish.
Communications of the ACM, 1995.Diarmuid O?
Se?aghdha and Ann Copestake.
Semanticclassification with distributional kernels.
In Proc.
ofCOLING, pages 649?656, 2008.Martha Palmer, Daniel Gildea, and Paul Kingsbury.The proposition bank: An annotated corpus of se-mantic roles.
Computational Linguistics, 3(1):71?106, 2005.Patrick Saint-Dizier.
Verb Semantic Classes Based on?alternations?
and WordNet-like criteria .
In P. Saint-Dizier, editor, Predicative Forms in Natural lan-guage and lexical Knowledge Bases , pages 247?279.
Kluwer Academic, 1998.Sabine Schulte im Walde.
Experiments on the Auto-matic Induction of German Semantic Verb Classes.Computational Linguistics, 2006.Lei Shi and Rada Mihalcea.
Putting pieces together:Combining FrameNet, VerbNet and WordNet for ro-bust semantic parsing.
In Proc.
of CICLing, pages100?111, 2005.Lin Sun and Anna Korhonen.
Improving verb cluster-ing with automatically acquired selectional prefer-ences.
In Proc.
of EMNLP, pages 638?647, 2009.Lin Sun, Anna Korhonen, and Yuval Krymolowski.Verb class discovery from rich syntactic data.
LNCS,4919:16, 2008.Yoshimi Suzuki and Fumiyo Fukumoto.
Classify-ing Japanese Polysemous Verbs based on Fuzzy C-means Clustering.
In Proc.
of TextGraphs-4, pages32?40, 2009.Robert Swier and Suzanne Stevenson.
Unsupervisedsemantic role labelling.
In Proc.
of EMNLP, 2004.Gloria Va?zquez, Ana Ferna?ndez, Irene Castello?n, andM.
Antonia Mart??.
Clasificacio?n verbal: Alternan-cias de dia?tesis.
In Quaderns de Sintagma.
Univer-sitat de Lleida, 2000.Deepak Verma and Marina Meila.
A comparison ofspectral clustering algorithms.
Technical report, De-partment of CSE University of Washington Seattle,2005.Andreas Vlachos, Anna Korhonen, and ZoubinGhahramani.
Unsupervised and Constrained Dirich-let Process Mixture Models for Verb Clustering.
InProc.
of the Workshop on on GEMS, pages 74?82,2009.Ulrike von Luxburg.
A tutorial on spectral clustering.STAT COMPUT, 17:395 ?
416, 2007.Piek Vossen.
EuroWordNet: A Multilingual Databasewith Lexical Semantic Networks.
Kluwer AcademicPublishers, Dordrecht, 1998.Lihi Zelnik-Manor and Pietro Perona.
Self-tuningspectral clustering.
NIPS, 17(1601-1608):16, 2004.1064
