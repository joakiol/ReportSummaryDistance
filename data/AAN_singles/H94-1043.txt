SESSION 7: DEMONSTRATIONSVictor Abrash, ChairSRI  InternationalSpeech Research and Techno logy  Program333 Ravenswood AvenueMenlo  Park, CA,  94025This year, seven sites presented ten demos and one video, show-ing the continuing progress of speech and natural language tech-nology research and application.
Papers were optional for thissession.Jack Mostow, fzom CMU, began the evening by showing a pro-totype reading coach designed to help children read by listeningto them reading aloud.
The system follows along as the studentreads, detecting when words are not read correctly or when thereader gets stuck.
Reading disfluencies are evaluated by a rule-based pedagogical evaluation component, which chooses appro-priate interventions to help the reader.
These interventionsinclude asking the reader to re-read a word or a phrase, pro-nouncing adifficult word to the reader, ignoring the error, givingthe reader a chance to correct he mis-reading in the context of afluent reading of the initial part of the sentence, and reading thewhole phrase to the reader.
The system currently runs on a com-bination of DEC-Alpha and NeXT computers, with adult voicesreading and mis-reading children's tories.Alex Hauptmann, also from CMU, presented the latest demon-stration version of their ATIS system.
Based on the general pur-pose speech recognition system Sphinx-IL it ran completely insoftware on a DEC Alpha 3600 workstation.
CMU claims thattheir implementation f the ATIS task is unusually robust o thequirks of spontaneous speech.Lyn Bates of BBN demonstrated speech-driven database accessin a non-ATIS domain.
This application iUnstrated the ability toquickly port BBN's SLS technology to a domain completelyunrelated to ATIS.
The new domain consisted of a Sybase d~tA-base containing information about Air Force facilities, equip-ment, and their features and status.
Images as well as text wereshown in response to user queries.
This led to some discussionon useful tools to facilitate porting both the speech and languageunderstanding components of SLS systems.IBBN also showed a speech interface to the Navy's JOTS sys-tem, developed to demonstrate the use of ARPA speech recogni-tion technology in an operational military setting.
JOTS is anapplication that provides the ability to enter, update, and displaytracks of interesting objects, such as ships or aircraft.
This demoprovides a speech-recoguition upgrade to JOTS, specifically interms of entering and updating track position reports, the opera-tions which consume the largest fraction of the operator's work-load.
The system does not remove any keyboard or mousefunctionality, but simply adds the ability to set any field byspeaking the field name and value, using an active vocabulary ofa few hundred words.
This illustrated that speech can be used asa useful adjunct to an interface that operators already understand;BBN reports that it was well received by JOTS operators.Richard Schwartz demonstrated the BBN Wall Street Journaldictation system.
This year, BBN increased the size of theirvocabulary to over 40,000 words.
They also upgraded theirgrammar t aining by adding three more years of WSJ text (1990-1992), the spontaneous journalist raining data, and other wordscurrently in the news.
According to John Makhoul, these stepsgreatly reduced the frequency of out-of-vocabulary words, mak-ing it more likely that the language model would cover storiesabout rec~I events.
As in the past, their recognizer performs anapproximate fast match in the forward direction, followed by afast, accurate backwards pass.Patti Price of SRI demonstrated a spoken language translationsystem for English to Swedish translation i  the air travel plan-ning domain.
This demo, using a modular spoken languagetranslation architecture, was developed under sponsorship fromSwedish Telecom by a collaboration between SRI International,the Swedish Institute of Computer Science (SICS), and TeliaResearch.
This system produces a synthesized Swedish transla-tion of ATIS utterances, and consists of an English languagespeech recoguizer (SRI's DECIPHER ATIS system), a naturallanguage component which produces a language-independentintermediate form, and a translator to produce Swedish textwhich is sent o a text-to-speech synthesizer.
State-of-the-art per-formance was demonstrated after only modest developmenteffort.
Although current echnology does not provide for uncon-strained translation between languages, this demo indicates thatrecent advances allow us to envision realistic translation applica-tions in specific domains.Victor Zue and the MIT-LCS Spoken Language Systems Groupdemonstrated GALAXY, a system enabling users to access andmanipulate various ources of information using spoken input inorder to solve specific tasks.
GALAXY focused in general on thetravel domain, including air travel, local navigation, and weather,building on MIT's past experience in the ATIS, VOYAGER, andPEGASUS domains.
The demo made use of several real data-bases distributed on the information highway, including Ameri-can Airlines' EAASY SABRE, the NYNEX Yellow Pages, theUS Census Bureau's map database, and the National WeatherService database, and was designed to promote modularity, flexi-235bility, portability, and acalability.
MIT believes that heir strategyof integrating many different knowledge sources will allow themto uncover critical new technical issues, including new worddetection and learning, portability across domains, and dialoguemodeling, Furthermore, they believe that working on real appli-cations has the potential benefit of shortening the intervalbetween demonstration f a technology and its ultimate use, andthat real applications which help people solve problems will beused by real users, thus providing arich and continuing source ofuseful data.Bill Ogden and Fun Cowie, from New Mexico State University,presented Tabula Rass" an interactive design tool and code gen-erator for machine assisted human information extraction.Intended to put state-of-art TIPSTER technology into the handsof today's analysts, this tool allows them to define a new domainand to produce the matchin8 informatic~ extraction tool in min-utes.
It is an attempt to reduce two of the major bottlenecks ofinformation extraction: the definitions of the text extraction taskand the production of automatic extraction tools to aid the humananalyst in the production of structured ata.
In the demo, theyshowed how easily the system could be used to generate newinformation extraction tools incorporating good human factorswith existing automatic extraction capabilities.Carl Weir of Unisys demonstrated ASWIS, a system for mes-sage processing and data fusion.
This illustrated the use of mes-sage processing technology for monitoring the movements ofsubmarines, along with other types of naval platforms.
Normally,message traffic pertinent to an object being tracked is ignored inthe data fusion process, even though it could be a valuable sourceof informatic~t.
ASWIS demouslrates the use of a text under-standing (data extraction) sensor which detects references in themessage traffic to submarines arriving or departing from ports,providing afix on their locations.Suzanne Taylor, also from Unisys" presented IDUS, an intelli-gent doctunent tmdm'standing program.
Starting from the bit-mapped image of a document, IDUS creates the data for a textrelAeval application.
This demo employed many different ech-nologies, ranging from image understanding and optical charac-ter recognition (OCR), to document structural analysis and texttmderstanding, in a knowledge-based cooperative fashion.
TheIDUS system showed the power and utility of an integrated set ofdocument interpretation modules, all accessible via the standardX-Windows/Motif user interface.Finally, Xuedong Huang from Microsoft showed a video ofMicrosoft Whispers, their speech recognizer, running under W'm-dows on an lnte1486-based PC.
The video showed two separateapplications: a voice command-and-control system for a W'm-dows-based PC, and a speech recognition i terface to an intelli-gent agent system.
The first points out an important applicationwhich will undoubtedly help introduce the public at large tospeech recognition.
The intelligent agent interface, completewith an mmnated taming bird rendered in high-resolution com-puter graphics, combined speech synthesis, recognition, andunderstsnding toenable users to negotiate with the agent o askfor and play songs tored in a jukebox.236
