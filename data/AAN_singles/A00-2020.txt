Detecting Errors within a Corpus using Anomaly DetectionE leazar  Esk inDepartment of Computer ScienceColumbia Universityeeskin@cs.columbia.eduAbst ractWe present a method for automatically detect-ing errors in a manually marked corpus us-ing anomaly detection.
Anomaly detection isa method for determining which elements of alarge data set do not conform to the whole.This method fits a probability distribution overthe data and applies a statistical test to detectanomalous elements.
In the corpus error detec-tion problem, anomalous elements are typicallymarking errors.
We present he results of ap-plying this method to the tagged portion of thePenn Treebank corpus.1 In t roduct ionManually marking corpora is a time consumingand expensive process.
The process is subject ohuman error by the experts doing the marking.Unfortunately, many natural anguage process-ing methods are sensitive to these errors.
Inorder to ensure accuracy in a corpus, typicallyseveral experts pass over the corpus to ensureconsistency.
For large corpora this can be atremendous expense.In this paper, we propose a method for au-tomatically detecting errors in a marked cor-pus using an anomaly detection technique.
Thistechnique detects anomalies or elements whichdo not fit in with the rest of the corpus.
Whenapplied to marked corpora, the anomalies tendto be errors in the markings of the corpus.To detect he anomalies, we first compute aprobability distribution over the entire corpus.Then we apply a statistical test which identi-fies which elements are anomalies.
In this casethe anomalies are the elements with very lowlikelihood.
These elements are marked as errorsand are thrown out of the corpus.
The model isrecomputed on the remaining elements.
At con-clusion, we are left with two data sets: one thenormal elements and the second the detectedanomalous elements.We evaluate this method over the part ofspeech tagged portion of the Penn Treebank cor-pus (Marcus et al, 1993).
In one experiment,our method detected 1000 anomalies within adata set of 1.25 million tagged elements.
Humanjudges evaluated the results of the applicationof this method and verified that 69% of iden-tified anomalies are in fact tagging errors.
Inanother experiment, our method etected 4000anomalies of which 44% are tagging errors.1.1 Re lated  WorkThe tagged portion of the Penn Treebankhas been extensively utilized for constructionand evaluation of taggers.
This includestransformation-based tagging (Brill, 1994; Brilland Wu, 1998).
Weischedel t al.
(1993) appliedMarkov Models to tagging.
Abney et al (1999)applied boosting to part of speech tagging.
Ad-wait Ratnaparkhi (1996) estimates a probabil-ity distribution for tagging using a maximumentropy approach.Regarding error detection in corpora, Rat-naparkhi (1996) discusses inconsistencies inthe Penn Treebank and relates them to inter-annotator differences in tagging style.
Abney,Schapire and Singer (1999) discuss how to useboosting for cleaning data.Much related work to the anomaly detectionproblem stems from the field of statistics inthe study of outliers.
This work examines de-tecting and dealing with outliers in univariatedata, multivariate data, and structured atawhere the probability distribution over the datais given a priori.
Statistics gives a set of discor-dancy tests which can be applied to any givenelement in the dataset o determine whether itis an outlier.
A survey of outliers in statistics is148given in Barnett and Lewis (1994).Anomaly detection is extensively used withinthe field of computer security specifically in in-trusion detection (Denning, 1987).
Typicallyanomaly detection methods are applied to de-tect attacks by comparing the activity during anattack to the activity under normal use (Laneand Brodley, 1997; Warrender et al, 1999).
Themethod used in this paper is based on a methodfor anomaly detection which detects anomaliesin noisy data (Eskin, 2000).The sparse Markov transducer probabilitymodeling method is an extension of adaptivemixtures of probabilistic transducers (Singer,1997; Pereira and Singer, 1999).
Naive Bayeslearning, which is used to estimate probabilitiesin this paper, is described in (Mitchell, 1997).2 Anomaly  Detect ionMore formally, anomaly detection is the processof determining when an element of data is anoutlier.
Given a set of training data without aprobability distribution, we want to constructan automatic method for detecting anomalies.We are interested in detecting anomalies for twomain reasons.
One, we are interested in model-ing the data and the anomalies can contaminatethe model.
And two, the anomalies themselvescan be of interest as they may show rarely oc-curring events.
For the purposes of this work,we axe most interested in identifying mistaggedelements, i.e.
the second case.In order to motivate a method for detect-ing anomalies, we must first make assumptionsabout how the anomalies occur in the data.
Weuse a "mixture model" for explaining the pres-ence of anomalies, one of several popular modelsin statistics for explaining outliers (Barnett andLewis, 1994).
In the mixture model, there aretwo probability distributions which generate thedata.
An element xi is either generated from themajority distribution or with (small) probabil-ity A from an alternate (anomalous) distribu-tion.
Our distribution for the data, D, is then:D -- (1 - A)M + AA (I)where M is the majority distribution, and Ais the anomalous distribution.
The mixtureframework for explaining anomalies is indepen-dent of the properties of the distributions Mand A.
In other words, no assumptions about149the nature of the probability distributions arenecessary.
The specific probability distribu-tions, M and A, are chosen based on priorknowledge of the problem.
Typically M is astructured istribution which is estimated overthe data using a machine learning technique,while A is a uniform (random) distribution rep-resenting elements which do not fit into M.In the corpus error detection problem, we areassuming that for each tag in the corpus withprobability (1 - A) the human annotator markesthe corpus with the correct tag and with prob-ability A the human annotator makes an error.In the case of an error, we assume that the tagis chosen at random.2.1 Detect ion  of  Anomal iesDetecting anomalies, in this framework, isequivalent to determining which elements weregenerated by the distribution A and which ele-ments were generated by distribution M. Ele-ments generated by A are anomalies, while ele-ments generated by M are not.
In our case, wehave probability distributions associated withthe distributions M and A, PM and PA respec-tively.The algorithm partitions the data into twosets, the normal elements M and the anomaliesA.
For each element, we make a determinationof whether it is an anomaly and should be in-cluded in A or a majority element in which itshould be included in M. We measure the like-lihood of the distribution under both cases tomake this determination.The likelihood, L, of distribution D withprobability function P over elements Xl,...,XNis defined as follows:NL(D) = l'I PD(Xi) = (2)i-----1Since the product of small numbers is difficultto compute, we instead compute the log likeli-hood, LL.
The log likelihood for our case is:LL(D) = IMI log(1 - A) + ~\[\] log(PM(xi))xiEM+lAIlogA + ~ log(PA(xj)) (3)xj EAIn order to determine which elements areanomalies, we use a general principal for deter-mining outliers in multivariate data (Barnett,1979).
We measure how likely each element xi isan outlier by comparing the difference betweenthe log likelihood of the distribution if the ele-ment is removed from the majority distributionand included in the anomalous distribution.
Ifthis difference is sufficiently large, we declarethe element an anomaly.Specifically what this difference should be de-pends on the probability distributions and priorknowledge of the problem such as the rate of theanomalies, A.3 Methodo logy3.1 CorpusThe corpus we use is the Penn Treebank taggedcorpus.
The corpus contains approximately 1.25million manually tagged words from Wall StreetJournal articles.
For each word, a record is gen-erated containing the following elements:1.
The tag of the current word Ti.2.
The current word Wi.3.
The previous tag ~- I .4.
The next tag 7~+1.Over records containing these 4 elements, wecompute our probability distributions.3.2 Probability Modeling MethodsThe anomaly detection framework is indepen-dent of specific probability distributions.
Dif-ferent probability distributions have differentproperties.
Since the anomaly detection frame-work does not depend on a specific probabilitydistribution, we can choose the probability dis-tribution to best model the data based on ourintuitions about the problem.To illustrate this, we perform two sets of ex-periments, each using a different probability dis-tribution modeling method.
The first set ofexperiments uses sparse Markov transducers asthe probability modeling method, while the sec-ond uses a simple naive Bayes method.3.3 Sparse Markov TransducersSparse Markov transducers compute probabilis-tic mappings over sparse data.
A Markov trans-ducer is defined to be a probability distributionconditional on a finite set of inputs.
A Markovtransducer of order L is the conditional proba-bility distribution of the form:P(Yt\[XtXt_lXt_2Xt_3...Xt_(L_l) ) (4)where Xk are random variables over the in-put alphabet Ei,~ and Yk is a random variableover the output alphabet Eout.
This probabilitydistribution stochastically defines a mapping ofstrings over the input alphabet into the outputalphabet.
The mapping is conditional on the Lprevious input symbols.In the case of sparse data, the probabilitydistribution is conditioned on only some of theinputs.
We use sparse Markov transducers tomodel these type of distributions.
A sparseMarkov transducer is a conditional probabilityof the form:(5)where ?
represents a wild card symbol andti = t -  ~=ln J -  ( i -  1).
The goal of thesparse Markov transducer estimation algorithmis to estimate a conditional probability of thisform based upon a set of inputs and their cor-responding outputs.
However, the task is com-plicated due to the lack of knowledge a prioriof which inputs the probability distribution isconditional on.Intuitively, a fixed order Markov Chain of or-der L is equivalent o a n-gram with n = L.In a variable order Markov Chain, the value ofn changes depending on the context.
For ex-ample, some elements in the data may use abigram, while others may use a trigram.
Thesparse Markov transducer uses a weighted sumof n-grams for different values of n and theseweights depend on the context.
In addition theweighted sum is over not only n-grams, but alson-grams with wild cards such as a trigram whereonly the first and last element is conditioned on.In this case we are 'looking at the input se-quence of the current word, Wt, the previoustag, Tt-1, and the next tag, Tt+l.
The out-put is the set of all possible tags.
The modelsthat are in the weighted sum are the trigram,WtTt-lTt+l; the bigrams WtTt-1, WtTt+l andTt-lTt+l; and the unigrams Wt, Tt-1 and Tt+l.The specific weights of each model depends onthe context or the actual values of Wt, Tt-1, andTt+l.150Sparse Markov transducers depend on a set ofprior probabilities that incorporate prior knowl-edge about the importance of various elementsin the input sequence.
These prior probabilitiesare set based on the problem.
For this problem,we use the priors to encode the information thatthe current word, Wt, is very important in de-termining the part of speech.Each model in the weighted sum uses apseudo-count predictor.
This predictor com-putes the probability of an output (tag) by thenumber of times that a specific output was seenin a given context.
In order to avoid probabil-ities of 0, we assume that we have seen eachoutput at least once in every context.
In fact,these predictors can be any probability distri-bution which can also depend on what worksbest for the task.3.4 Naive BayesThe probability distribution for the tags wasalso estimated using a straight forward naiveBayes approach.We are interested in the probability of a tag,given the current word, the previous tag, andthe next tag, or the probability distributionP(TiIWi, T i - t ,  ~+1) which using Bayes Rule isequivalent to:P(Ti}Wi, T i - l ,  Ti+ l ) =P(Wi, Ti-I, Ti+zlTi) * P(Ti)P(Wi,  Ti - , ,T i+I)  (6)If we make the Naive Bayes independence as-sumption and we assume that the denominatoris constant for all values this reduces to:P(~IW~, ~-1,  Ti+,) =P(WiIT~) * P(T~-IIT~) * P(Ti+zlTi) * P(Ti) (7)Cwhere C is a normalization constant in order tohave the probabilities sum to 1.
Each of the val-ues on the right side of the equation can easilybe computed over the data estimating a proba-bility distribution.3.5 Comput ing  ProbabilityDistributionsEach probability distribution was trained overeach record giving a model over the entire data.The probability model is then used to deter-mine whether or not an element is an anomalyby applying the test in equation (3).
Typi-cally this can be done in an efficient mannerbecause the approach does not require reesti-mating the model over the entire data set.
If anelement is designated as an anomaly, we removeit from the set of normal elements andefficientlyreestimate he probability distribution to obtainmore anomalous elements.4 Results/EvaluationThe method was applied to the Penn Tree-bank corpus and a set of anomalies were gen-erated.
These anomalies were evaluated by hu-man judges to determine if they are in fact tag-ging errors in the corpus.
The human judgeswere natural language processing researchers(not the author) familiar with the Penn Tree-bank markings.In the experiments involving the sparseMarkov transducers, after applying the method,7055 anomalies were detected.
In the ex-periments involving the naive Bayes learningmethod, 6213 anomalies were detected.Sample output from the system is shown infigure 1.
The error is shown in the contextmarked with !!!.
The likelihood of the tag isalso given which is extremely low for the errors.The system also outputs a suggested tag andits likelihood which is the tag with the highestlikelihood for that context.
As we can see, theseerrors are clearly annotation errors.Since the anomalies detected from the twoprobability modeling methods differed onlyslightly, we performed human judge verificationof the errors over only the results of the sparseMarkov transducer experiments.The anomalies were ordered based on theirlikelihood.
Using this ranking, the set of anoma-lies were broken up into sets of 1000 records.
Weexamined the first 4000 elements by randomlyselecting 100 elements out of each 1000.Human judges were presented with the sys-tem output for four sets of 100 anomalies.
Thejudges were asked to choose among three op-tions for each example:1.
Corpus Error-  The tag in the corpus sen-tence is incorrect.2.
Unsure - The judge is unsure whether ornot the corpus tag is correct.151Error 0.000035: Its/PRP$ fast-food/NN restaurants/NNS -/ :  including/VBGDenny/NNP 's/eOS ,/, Hardee/N ie  's/POS ,/, Quincy/NNP 's/POS and/CCE1/NNP Pollo/NNP Loco/NNP (/( "/" !!!the/NN!!!
only/J J  significant/JJ fast-food/NNchain/NN to/TO specialize/VB in/IN char-broiled/JJ chicken/NN "/" )/) - / :  are/VBPstable/JJ ,/, recession-resistant/JJ and/CC growing/VBG ./.Suggested Tag: DT (0.998262)Error 0.019231: Not/RB even/RB Jack/NNP Lemmon/NNP 's/POSdoddering/JJ !!!makes/NNS!!!
this/DT trip/NN worth/NN taking/VBG ./.Suggested Tag: VBZ (0.724359)expert/JJError 0.014286: I t /PRP also/RB underscores/VBZ the/DT difficult/JJ task/NNahead/RB as/IN !!!Coors/NNS!!!
attempts/VBZ to/TO purchase/VB Stroh/NNP Brew-ery/NNP Co./NNP and/CC fight/VB off/RP increasingly/RB tough/J J  competition/NNfrom/IN Anheuser-Busch/NNP Cos/NNP ./.Suggested Tag: NNP (0.414286)Figure 1: Sample output of anomalies in Penn Treebank corpus.
The errors are marked with !!!.3.
System Error - The tag in the corpus sen-tence is correct and the system incorrectlymarked it as an error.The "unsure" choice was allowed because of theinherent subtleties in differentiating betweentypes of tags such as "VB vs. VBP" or "VBDvs.
VBN".Over the 400 examples evaluated, 158 werecorpus errors, 202 were system errors and thejudges were unsure in 40 of the cases.
The cor-pus error rate was computed by throwing outthe unsure cases and computing:Corpus error rate = (8)Corpus ErrorsSystem Errors + Corpus ErrorsThe total corpus error rate over the 400 manu-ally checked examples was was 44%.
As can beseen, many of the anomalies are in fact errorsin the corpus.For each error, we asked the human judge todetermine if the correct ag is the systems ug-gested tag.
Out of the total 158 corpus errors,the systems correct tag would have correctedthe error in 145 cases.Since the verified examples were random, wecan assume that 91% of corpus errors would beautomatically corrected if the system would re-place the suspect tag with the suggested tag.
Ig-noring the "unsure" elements for the purposesof this analysis, if we attempted to automati-cally correct he first 1000 examples where theerror rate was 69%, this method would have ledto a reduction of the total number of errors inthe corpus by 245.5 Conc lus ionThis paper presents a fully automatic methodfor detecting errors in corpora using anomalydetection techniques.
As shown, the anomaliesdetected in the Penn Treebank corpus tend tobe tagging errors.This method has some inherent limitationsbecause not all errors in the corpus would mani-fest themselves as anomalies.
In infrequent con-texts or ambiguous situations, the method maynot have enough information to detect an error.In addition, if there are inconsistencies betweenannotators, the method would not detect theerrors because the errors would be manifestedover a significant portion of the corpus.Although this paper presents a fully au-tomatic method for error detection in cor-pora, this method can also be used as a semi-automatic method for correcting errors.
Themethod can guide an annotator to the elementswhich are most likely errors.
The method cangreatly reduce the number of elements that anannotator needs to examine.Future work in this area involves modelingthe corpora with other probability distributions.152Anoma~ Rank Corpus Errors System Error Unsure Corpus Error Rate1-1000 63 28 9 69%1001-2000 36 54 i0 40%2001-3000 18 70 12 20%3001-4000 41 50 9 45%Totals 158 202 40 44%Table 1: Results of error detection experiments on the tagged portion of the Penn TreebankThe method is very sensitive to the effective-ness of the probability model in modeling thenormal elements.
Extensions to the probabil-ity distributions presented here such as addinginformation about endings of words or usingmore features could increase the accuracy of theprobability distribution and the overall perfor-mance of the anomaly detection system.
Otherfuture work involves applying this method toother marked corpora.Re ferencesSteve Abney, Robert E. Schapire, and YoramSinger.
1999.
Boosting applied to tag-ging and PP attachment.
In Proceedings ofthe Joint SIGDAT Conference on Empiri-cal Methods in Natural Language ProcessingConference and Very Large Corpora.V.
Barnett and T. Lewis.
1994.
Outliers in Sta-tistical Data.
John Wiley and Sons.V.
Barnett.
1979.
Some outlier tests for multi-variate samples.
5outh African Statist, 13:29-52.Eric Brill and Jun Wu.
1998.
Classifier com-bination for improved lexical disambiguation.In Proceedings of COLING-A CL.Eric Brill.
1994.
Some advances intransformation-based part of speech tagging.In Proceedings of the Twelfth NationalConference on Artificial Intelligence, pages722-727.D.E.
Denning.
1987.
An intrusion detectionmodel.
IEEE Transactions on Software En-gineering, SE-13:222-232.Eleazar Eskin.
2000.
Anomaly detection overnoisy data using learned probability distribu-tions.
In Proceedings of the Seventeenth In-ternational Conference on Machine Learning(ICML-2000) (to appear).T.
Lane and C. E. Brodley.
1997.
Sequencematching and learning in anomaly detectionfor computer security.
In AAAI Workshop:AI Approaches to Fraud Detection and RiskManagement, pages 43-49.
AAAI Press.Mitchell Marcus, Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Buildinga large annotated corpus of english: ThePenn Treebank.
Computational Linguistics,19(2):313-330.Tom Mitchell.
1997.
Machine Learning.
Mc-Graw Hill.Fernando Pereira and Yoram Singer.
1999.An efficient extension to mixture techniquesfor prediction and decision trees.
MachineLearning, 36(3):183-199.Adwait Ratnaparkhi.
1996.
A maximum en-tropy model part-of-speech tagger.
In Pro-ceedings of the Empirical Methods in NaturalLanguage Processing Conference.Yoram Singer.
1997.
Adaptive mixtures ofprobalistic transducers.
Neural Computation,9(8):1711-1733.Christina Warrender, Stephanie Forrest, andBarak Pearlmutter.
1999.
Detecting intru-sions using system calls: alternative datamodels.
In 1999 IEEE Symposium on Secu-rity and Privacy, pages 133-145.
IEEE Com-puter Society.Ralph Weischedel, Marie Meteer, RichardSchwartz, Lance Ramshaw, and Jeff Pal-mucci.
1993.
Coping with ambiguity and un-known words through probabilistic models.Computational Linguistics, 19(2):359-382.153
