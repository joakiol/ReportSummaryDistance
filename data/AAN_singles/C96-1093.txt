Analysis of Japanese Compound Nouns byDirect Text ScanningToru Hisamitsu and Yoshihiko NittaAdvanced Reseamh Laboratory,  Hitachi ,  Ltd.Hatoyama,  Saitama 350-03,  JAPAN{ h isamitu,  nitta } @ harl .hitachi .co.
jpAbstractThis paper aims to analyze word dependency structure incompound nouns appearing in Japanese newspaperarticles.
The analysis is a dil't:icult problem because suchcompound nouns can be quite long, have no wordboundaries between contained nouns, and often containnnregistered words such as abbreviations.
The non-segmentation property and unregistered words cause initialsegmentation errors which result in erroneous analysis.This paper presents acorpus-based approach which scans acorpus with a set of pattern matchers and gathers co-occurrence xamples to analyze compound nouns.
Itemploys boot-strapping search to cope with unregisteredwords: if an unregistered word is lound in the process ofsearching the examples, it is recorded and invokesadditional searches to gather the examples containing it.This makes it possible to correct initial over-segmentation errors, and leads to higher accuracy.
Theaccuracy of the method is evaluated using the compoundnouns of length 5, 6, 7, and 8.
A baseline is alsoinmxlueed and compared.1.
Background1.1 Compound Nouns in JapaneseNewspaper ArticlesThis paper analyzes the word dependency structure incompound nouns appearing in Japanese newspaperarticles.
Assume that you are given a large number ofarticles and a compound noun such as "~.~;?~J~-~" .This noun actually consists of three nouns "~JE"(revision), "~fL=~" and "~~,~-?"
(application), where ")~0_~~)~" is the abbreviation of "~d,~/~"(~- :large, d,3'~I~-~: retail shop, ~:  law).
However, it ishighly unlikely that such a word can be found in anordinary dictionary.
Newspaper articles are full of this kindof difficult compound nouns which can be infinitelygenerated, and such compound nouns often conveysubstantial information through which the articles can besummarized.In Japanese newspapers, compound nouns m~cespecially useful because they convey a lot of informationin a compact expression (even a single kanji, or Chinesecharacter, can represent complex meaning).
The number ofnouns torming a compound noun often exceeds three, andmay reach as much as ten.
This means that a compoundnoun can contain up to twenty kanji characters or more.Therefore, an analysis of noun compounds has to dealwith both segmentational and structural ambiguities.As for the example above, an initial morphologicalanalysis (segmentation + tagging) causes an over-segmentation error such as "~IE sn/~ adj/~ n/'lY, n/li~isn" because "~"(large), "~"(shop) and "~,"(law) are allmeaningful expressions by themselves.1.2 Existing Methods and ProblemsCompound noun analysis has been researched lbrmany years because it is important for understandingnatural anguage.
A concise review of this research areacan be found in, for instance, Lauer (1995), which datesback to Finin (1980).
When applying the existingmethods to Japanese compound nouns in newspaperarticles, however, aproblem arises:(1) All the methods are difficult to apply because they usetraining schemes uch as (partial)parsing of the wholecorpus and counting word occun'ence in word windows.As Lauer (1995) pointed out, using (partial) parsingof the text is too costly.
Thus, the word co-occurrenceapproach seems to be more appropriate.
However,counting the frequency of a given word is not an easy taskin a non-segmented Japanese text.
Ordinary patternmatching algorithms cannot count the number ofoccurrences of a word in non-segmented Japanese textbecause of the ambiguity in how sentences should besegmented.
Thus, whatever method one chooses, he isfirst confronted with the high cost of Japanesemorphological analysis and its inaccuracy caused byunregistered words.Thus, researchers of Japanese compound nounanalysis have been obliged to employ manually writtensyntactic rules for compound nouns (Miyazaki, 1984) orthe conceptual dependency model (Kobayashi et al, 1994)which employs a thesaurus and a limited co-occunencedata, li)r example, a collection of four kanji sequences(Tanaka, 1992) extracted from a corpus.Tim problems in existing methods arc:(2) It is costly to manually prepare the rules for theanalysis of compound nouns.
(3) Methods employing a conceptual dependency modelare brittle when unregistered words occur often.
One hasto properly allocate an unregistered word in lhe thesaurus,550which is another tough problem.For these reasons, the existing methods are noteffective for compound noun analysis in newspaperarticles.
A scheme for collecting coilocational information(1) must be practical for large amounts of Japanese mwtext, and also collect reliable data.
(2) should cope with unregistered words.1.3 Direct Text Scanning Methodqb satisfy the requirements mentioned above, we used adirect text scanning method which collects externalevidence (McDonald, 1993) of a modifier-modilcerelationship between two words using a set of simplepattern matchers.In this method, a Japanese morphological analyzer(JMA) first determines the most plausible segmentationfor a given compound noun by using an ordinarydictionary.
At this initial stage, the segmentation oftencontains an over-segmentation error.
That is, when theanalyzer encounters an unregistered word, it is likely tosegment the word into a sequence of registered words ofshort length (we empirically confirmed that wordboundary crossing type errors make up less than 5% of allerrors caused by unregistered words).
Our method correctsmany of over-segmentation errors automatically.Every word in the initial output of the JMA is usedas a key in pattern matching.
Twenty-three patternmatchers gather various types of word co-occurrence, andmany unregistered words can be detected in the process ofpattern matching.For example, in the searches for L={"~k_tl( .... )<" ")~""~ .... ~'~:"}, a pattern matcher finds evidence that "~)~~"  appears as a single word.
Then, " J .
, : )~" is registered,added into L, and invokes a search of word co-occurrencearound " ~ "  itself.
This bootstrapping search makes itpossible to conrect initial over-segmentation errors m~d toobtain the correct solution of morphological nalysis.A comparison of possible dependency structures isconducted by using mutual information and syntacticconstraints.
Lauer (1995) compared a dependency modelwith adjacency models, and found that the dependencymodel is better.
We used the dependency model as well.We did not use a conceptual dependency model.
Thisis because:(1) it is difficult to assign a proper position in a thesaurusto an unregistered word.
(2) we aimed to evaluate the perlommnce of the genuinedirect scanning approach, since no oue has lelX~tedwhether or not it works, or if it works, how large thecorpus should be.Finally we also intr~?luce a baseline that has yet notbeen introduced in the literature of Japanese compoundnoun analysis.
The baseline works fairly well, and thetext scanning method will turn out to .be much better thanthe baseline.Section 2 describes the algorithm of  text scanningmethod in detail, section 3 shows the results of ourexperiments and introduces the baseline.
Section 4discusses problems tbr future research.2.
Text Scann ing  Approach2.1 OverviewFigure 1 illustrates the processing I\]ow.
An inputcompound noun is first analyzed by JMA and segmentedinto a sequence of registered words.
The output is storedas an initial value in a list called WORDLIST  (WL).For every word in WL, a search for its collocationalpattern is conducted, and the results are stored in tileevidence data base (EDB).
It is important that there is afeedbackloop from EDB to WL through which newlytbund words can be a&ted to WL.
The search is continueduntil every wold in WL is used as a key.
This f~dbackenables tile bootstrapping acquisition of evidence.Figure 1Arch itecture of Direct Scanning Mct hodInput "4t d~Aa,ML,Yt~'P/ ~aqzer \[ ,17Result 0f Initial JMA?
gCll!
sW~ acl/I,; Wi)~ n(~l: sn" Newly Found Wordiulmtll ov~ D' word 'oo<" ,1 v,oen=II\[ Final WORD_UST Pattern II {(~l l - \ ]sn) , (~ adj), (Jtlln), MatchersI (fJ, n),(/j$,~?
~),(kJ,lif).
n)} ........
I - ::\] Result of FinahJMA \] 1 CorpIJs~t "~d~sWkl~ifJ.
n I .
.
.
.q \]~i sn' I Augumentedn i~ead A~/  CFG-Parser  ~w~ra IOutput --Attribute l\ ]Grammar \[np mod-pel:rv-no-rel, ~ ./ "" ~..  ~rera-rol '8fl ll Sllhead: i~iE head: )<hli f).~ t\]ead: ~f imed-rel:nil mocl~ret: nil modrol: dlAlter the searches, the input is re-analyzed usingnewly found words.
The final result of JMA is thenpassed to a CFG-parser which calculates the cost ofpossihlc structures and the attribute-values attached toeach node in a solution.
In the case that there isambiguity in the final morphological nalysis of a givencompound noun, the morphological nalyzer picks up thesolution with the least number of segmentations.The procedure of the cost calculation era  dcpendcncystructure is basically the same in Kobayashi et al (1994).The cost of the dependency between two nodes is given bynsing mulual information between the lexical heads of ihetaxies (fig.
2).551Here two kind of attributes are used; head, whichrecords the head of a node as a value, and nu, d-rel, whichrecords the kind of relationship found between two headsof children.In Japanese, if the two children are both contentwords, the value of the head attribute of the parent node isusually identical to the value of the hend attribute of theright daughter.Figure 2Depe nde ncy R epres ta~t ati on U singAttribute-Valu e Pai IsNP head: 7-r et:, .
.
.~ r~ma}NP NPhead:  a head:  f lmod-rel: {r ....... r,m,} m3d-rel:{r ....... r~}2.2 Basic CFG RulesThe category which the morphological nalyzer assigns toa word is one of the following: sn (stem of a sino-verb), n(noun), pn (proper noun), num (number), adj (stem of anadjective or an adjectival verb), prfx (nominal prefix), sfix(nominal suffix), num-prfx (numerical prefix), and num-sfix (numerical suffix).
CFG rules for compound nounconstruction use these categories as non-terminals.
Thefollowing two rules are the most basic: \[np -~ np np\] and\[np --~ n\].
These rules construct the basic framework ofthe dependency-structure of a compound noun.
We assumethat the structure of a compound noun can be representedin the framework of binary-tree grammar by usingattribute-wdue pairs.2.3 Co-occurrence Data Collection by DirectText ScanningThis subsection describes the most important part of ourmethod: the pattern matchers and heuristics onunregistered word treatment.
"Fable 1 shows the main part of the pattern matchers.We will describe the procedure for collecting evidence byusing the example mentioned previously, "~\]E.~)~t~tJ~)~The initial segmentation of the compound noun is"~k~ sn/~ adj/Y~ n/i-~ n/~'~T sn".
Thus the WL initiallycontains these five words.
The words are used as keys lotthe search.
As mentioned in the previous section, thissolution contains an over-segmentation error, which is themost likely error in the situation when unregistered wordsappear.
Therefore this example captures the typicalproblem laced in our task.In Table I, 'A' stands for a given key, 'B' stands for asequence of kanji characters (we only treat kanji-compound nouns in this paper), and 'D' stands for an"extended" delimiter: D is identical to a space, a symbol, akatakana or a hiragana except "?"
(no; o3').
Afterpreliminary experiments, we decided to eliminate "?
"from the delimiters because if it is used, a pattern such ~ts"A?B?C"(roughly C orB of A) could be picked up, andit may ~ erroneous evidence because of its ambiguity independency structure.TablePart of Pattern1.1D .AB.D DD 'BA 'D  DD1.~ D ?
A~B ?
D DD-Be)A  ?
D1.3 \ [D 'AV~B'DD,  A~'~cB - DD ?
BV~A ?
DD"  B~cA-  DD AT)~B-~7~ ?
D1., D A~B'9 ' -~  - D\ D A IZB~7~ ?
DD B;O:A-~ "7o ?
DD B~'A~7~ - DO B IZA~7~ .
D1MatchersA-~7~B ?
DAL, Y.:B ?
DA~ ~'~B ?
D 1.5D B'~Z~A ?
DD BL?cA ?
DD B~'LT~A ?
DD B~- / ' cA  ?
DD ?
A.~3 ~ i~'B ?
D ~D ?
AL  g - D 1.6D ?
B,t~ J: LFA ?
DD 'B~A'DD ?
A~Zo~'~cCo')B ?
D' 1.7D ?
A~,~-1~-9~ ~ B - D /D ?
B~:_o~,~Z'09A ?
DD.
B~Y-I~-~A ?
DPatterns ill 1.I collect evidence of inner-wordcollocation of A and B.
If the length of A is more than orequal to 2, The length of B is limited to less than or equ~dto 3.
If the length of A is !, the length of B is limited toless than or equal to 2.
Additional explanation will begiven later in this subsection.Patterns in 1.2 collect the evidence of particle-combined collocation of A and B.
A and B are combinedby a particle "?"
which is similar to "of' in English.Note that no part of a phrase such as "A?B?C" is pickedup so that erroneous evidence can be to avoided.
Thelength of B is limited to less than or equal to 3 (in 1.3,.... 1.7, the same condition on B is used).Patterns in 1.3 collect the evidence of an adjectivalmodifier-modifiee r lationship between an adjective (or anadjectival noun) and a noun.Patterns in 1.4 collect the evidence of a predicate-argument relation between a sino-verb and a noun.Particles "?j~" Q~a), "~ "(wo) and "l~-"(ni) roughly indicateAGENT, OBJECT and GOAL, respectively.Patterns in 1.5 collect the evidence of a modifier-modifiee relationship between a sino-verb and a noun, thesino-verb which appears at the tail of a noun modifierphrase and the noun which is modified by the phrase.Patterns in 1.6 collect the evidence of a coordinationrelationship between two words.Patterns in 1.7 collect phrases uch as "A about B"~md "B about A".Here we omit the others.
One can ,add any pattern as longas it supplies reliable evklence.In the following part of this subsection, we willillustrate the search procedure using the initial value ofWE {(?~k.d(sn), (~  adj), (/~ n), ('~}~ n), ()j~-~ sn)}.From the first item "~kll:Z', evidence shown in 3.1 offigure 3 is collected, and the result is stored in the form552shown in 3.1'.
Note that the number of occurrences ~uxtthe observed relationships are recorded.
At this stage, theunregistered word "Jql~'~J~" is already captured by using apattern marcher in 1.5.As for the second word, however, one has to becareful because a word with length 1 is very likely toappear through an over-segmentation error.
The patternmatchers gather evidence such as "AS~ ~:~{U' (~~o?
:big; ~(~: change), "J<~" (university), ")2~!!"
(large),"J<ldi'{):," (large retail-shop law) etc.
as given in 3.2.
Thisevidence contains not only correct examples (such as "ASL~ ~oc>~.
'\[~ '') but also registered words (such as "AS~", "~~")  and unregistered words (such as " J<h~").To classify the evidence, we developed the followingrules:R-(a)I f ( l )  the length of A is 1, and the length of B is l, ~md(2) there is no entry for the concatenated string AB (BA)in the dictionary used by JMA,then recognize the concatenated string as an unregisteredword, and apply R-(c).R-(b)If (1) the length of A is 1, and the length of B is 2, (2)there is no entry for the concatenatod string AB (BA) inthe dictionary, (3) the category of B is not 'sn' (thecondition for AB), and (4) the concatenated string AB(BA) cannot be segmented as a sequence of two registeredwords A'B'(B'A'), where A':#A,then recognize the concatenated string as an unregisteredword and apply R-(c).R-(c)If (1) the character string consisting of B is identical tothe concatenated string of the first or the first two wordsfollowing A in the initial solution (the condition for AB),or (2) the character string consisting of B is identical tothe concatenated string of the first previous or the firsttwo previous words preceding A in the initial solution(the condition for BA), then record AB in WL as anunregistered word, which will invoke pattern matchingusing AB as a key.R-(d)If (1) tile length of A is larger than or equal to 2, and(2) the concatenated string AB (BA) cannot be segmentedas a sequence of two registered words A'B'(B'A'), where A'A, then, record an evidence of inner-word co-occurrenceof A and B.We admit that the definition of a word might becontroversial.
However, we do not mention the argumentshere because of the lack o1' space.
We only say that thestandpoint we chose is simple and umchine-tractable, ~mdworks well lbr our purpose."~-~?
'~'\[~" is recorded as evidence of astraighttorward a jectival moditier-nlodifiee r lationshipbetween ".k" and "~C\[g".According to R-(a), "ASq:" and " )~"  are neglected.According to R-(b) and R-(c)-(l), ~)t~)2 is recorded asan unregistered word and stored in WD, which invokes asearch of the patterns around it.Having worked through all the elements in WD, theevidence given in 3.1', 3.2', 3.3', 3.4', 3.5' and finally3.6' is obtained.At this stage, \]MA re-analyzes the input compoundnoun by using newly found words.
Thus the con'cctsegmentation "~.~iE sn / .~ l~ n / )~,~l: sn" is obtained,and passed to the CFG-parser.Figure 3Exam pie o f Evi deuce Colle ct ion, .
.
.
l ldql q,~,3.1 " ..., 0,,lit o~ d( Jl .
.
.
.
""L: tk ~"~ i~<'t $ "'" 3.432  j~.
)<~?)
.
l~f f 'b i~t .
t : .
.
3.5' ...kthql4 ~... ...~:dq\[ 8 It Z :k I ,~L .
...Jl, khll//i~).. ..~'Gkt~i~(r~tll' l ~.. 3.6( ~/( 11 ,p " i~.wl~l t?I 2)?
"{l~(()t~hlitt!~l~Pl\[ : in~,:?.l tel 15)) | 3r  n':::: "~' '))1 3.vNe ~y', "', (t~i ,~td: I .
.
.
.
.
.
I z)\] 3,4'Wind " "  }~- ' -~  (,t:~;if~, ~Oii ~ 4) / J  - -3.6': } f l  Add iiio m I Sear d l2.4 Selection of Proper Analysis2.4.1 Cost Calculation and MutualIn format ionThe rest of the procedure is straightforward.
An augmentedbottom-up CFG parser chooses the minimum cost tree forthe given word sequence.
Let NP 3 be the parent of NP~and NP~ in a subtree.
Each node has three kinds ofattributes: head, mod-rel and accum-cost, head has thelexical head of the subtree under NP i as its value.
,u)d-relkeeps tile observed relationships captured by the pattenlmatchers between the two lexical heads of child nodes(this value is not actually used in the fi,llowingexperiments), accum-cost ci records the accumulated costof the subtree which has NP i as its root.
~ is calculatedas IMiows:c3 = cl+c~-log2( N(headl, head~)N( headl )N( head2)where N(headi) stands for the number of patternscontaining ha~ i, N(headl, head2) stands for the number ofthe patterns containing both heM~ and head 2.
The value ofaccum-cost of each leaf node is set to 0.2.4.2 Preference to Analysis ContainingObserved EvidenceThe corpus based approach inevitably encounters tile553sparseness problem.
Our approach also encounters thisproblem, although it turned out to be not serious, as willbe explained in section 3.3.
This subsection describes theheuristic that is employed when the evidence cannot coverany of the entire trees.Figure 4 shows two possible dependency structuresin a three-word compound noun.
For simplicity, thevalues of the head attribute are indicated instead of thenon-terminal symbols.
For three noun words, thefollowing rule is applied:If only the dependency between Hj and H 2 was observed,then 4-(a) is chosen, else if only the dependency betweenH l and H 3 was observed, then 4-(b) is chosen, else if onlythe dependency between H 2 and H 3 was observed, then 4-(b) is chosen.In general, priority is given to the solutioncontaining more subtrees which directly reflect theobserved evidence.In our experiments, the analysis which has multipleminimum cost solutions was considered to have failed.Figure 4Two Possible ParseH, H2 H~ H, ~ Hs4-(b) 4-(a)3.
Results3.1 Test DataWe used the articles contained in "Nikkei Shinbun" forJanuary and February in 1992 as the corpus for theexperiments.
The number of the articles is about 27,000,which contain about 7 million characters.Experiments were carried out using 400 compoundnouns: 100 for 5-kanji words, 100 for 6-kanji words, 100for 7-kanji words and 100 for 8-kanji words.
Thefrequency of these word lengths is about the same in thecorpus.
Alter randomly selecting the test samples, weconfirmed that they were all compound nouns.Numerical expressions appeared in 10% of the testsamples, and such expressions were pre-processed asfollows:"~ ' \ ] \ - I -~ ' "  --~ "~ pr-num/~\]\-\[- num/~ n"(?~: about; ~: hundred; A.: eight; W: ten; ~- :  dealer)3.2 BaselineBaselines have rarely been introduced in research onJapanese noun compounds.
This paper introduces abaseline to facilitate our evaluation of the effectiveness ofour method.The baseline we used is leftmost derivation.
This isan extension of left branchprefereture in Lauer (1995).The baseline is also a well-known heuristic method toanalyze Japanese noun phrases combined with "?)"
(suchas "A?B~C").
As shown below, this heuristic methodworks well especially when the length of a compoundnoun is relatively short.
Note that the baseline correctlyanalyzes " i~/E~\ ] j~ ,~-"  if "~)~"  is registered.However, the baseline actually fails because it cannotcapture the unregistered word.3.3 Results and ComparisonTable 2 shows the results of the proposed method.
Thefirst line indicates the number of samples for which thecorrect dependency structure was given as the singleminimum cost solution.
The second line indicates theaccumulated number of samples for which the col~rectdependency structure was given as one of the minimumcost solutions.
Table 3 shows the results of the baseline,and indicates the number of samples for which the correctdependency structure was given.Table 2word_l_length ~__Q5 a89 - - ~ 6  7~1 ~ 81 \] 76 \ ] ~The result of Direct ScanningTable 3word length I 5 6 ~ ~ ~ - ~1 83 ~63 1 41 \[ ~The result of baselineComparing the two tables reveals that the proposedmethod is more accurate than the baseline.
For longerword length, the difference is greater.Our result cannot be compared accurately with theexisting result (Kobayashi et a/., 1995) because we used adifferent test corpus, and only the results on 4-, 5- and 6-kanji compound nouns were reported.
However, theaccuracy of their results on 6-kanji compound nouns is53%, unless they combine their conceptual dependencymodel with a heuristic using the distance of modifier andmodifee.
After combining the model and the heuristic,accuracy improves to 70%, which is the same as ours.An 8-kanji compound noun usually contains fournouns.
The performance of our method (accuracy of 58%)is encouraging, since most of the errors were caused byproper nouns.
This problem can be solved using a pre-processor (explained below).3.4 Causes of ErrorsForty-two percent of the error was caused by propernouns, 16% by time expressions, and 15% by monetaryexpressions.
This means that proper nouns are a majorcause of the errors, as pointed out in previous research.There are several reasons for this:(1) an identical proper noun normally does not appear554many times in the corpus.
(2) proper nouns sometimes cause cross-boundary errors atthe initial morphological nalysis.We can be optimistic about eliminating these threetypes of errors.
If we use a preprocessor (for proper nouns,see Kitani et al, 1994), most of them can be eliminated.4.
Future DirectionsThis paper discussed performance of the direct textscanning method.
There remain several interestingproblems:(l) We did not employ the conceptual dependency model.A method for combining a conceptual dependency modelwith the proposed approach should be investigated and theresults analyzed.
(2) A proper noun pre-processing module should becombined with the proposed method.
(3) The effect of varying the corpus size should beinvestigated.
(4) The distance between a compound noun and itsevidence should be reflected in the cost calculation incomparing solutions.
(5) Parallel search should be employed to speed up theprocess.
(6) How to obtain an expanded expression from a givencompound noun should be investigated.
At the moment,the value of the nuM-rel attribute is not used.
Somecompound nouns can be rephrased with an ordinaryJapanese sentence.
Figure 5 shows an example ofexpansion.Fi?u re 5Analysis of Long Word andExpansion to Ordinary Japanese" ~  ~t~ ~ ~.~-~""no""an entelprise which aims at improving the area wheremany wooden apartments forrent stand close together".~  mokltzo; wooden ~:chhta i ;  renta{1"-~" juutaku; avartment ~:J~:mis,.,huu; crowd\]~ 1~: clfiku ;area ~:  seibi; improve, maintain~JI-~:: jigyou; enteq~ise5.
ConclusionA corpus-based approach for analyzing Japanesecompound nouns was proposed.
This method scans acorpus with a set of pattern marchers and gathers externalevidence to analyze compound nouns.
It employs a boot-strapping procedure to cope with unregistered words: if anunregistered word is found in the process of searching theco-occurrence examples, the newly tbund word is recordedand invokes additional searches, which enahle necessaryevidence to be gathered for the given compound noun.This also makes it possible to correct over-segmentationerrors in the initial segmentation, and leads to higheraccuracy.
The method is also very portable because itdepends little on a dictionary of a morphological nalyzerand treats registered words and unregistered words in thesame manner.
The accuracy of the method was evaluatedusing the compound nouns of length 5, 6, 7, and 8.
Abaseline, which takes leftmost derivation strategy, wasalso investigated for comparison with our method.
Theproposed method is much more accurate than the baselinein the experiments for words of four different lengths.AcknowledgementWe would like to express our gratitude to Professor YorickWilks (Sheffield) and Dr. Shojiro Asai (Hitachi, Ltd.),who gave the first author the opportunity to do thisresearch at the University of Sheffield as a visitingresearcher (from January to December, 1995).ReferencesFinin, Tim.
1980.
The Semantic Interpretation fCompound Nominals, PhD Thesis, Co-ordinatedScience Laboratory, University of Illinois, Urbana, ILLauer, Mark.
1995.
Corpus Statistics Meet the NounCompound: Some Empirical Results, in Proc.
of ACL,pp.47-54McDonald, David B.
1993.
Internal and External Evidencein the Identification attd Semantic Categorization fProper Names, in Proc.
of SIGLEX workshop onAcquisition of Lexical Knowledge from Text, pp.
32-43, Ohio, USAMiyazaki, Masahiro.
1984.
Automatic SegmentationMethod for Compound Words Using SemanticDependent Relationships between Words, in Trans.
ofIPSJ, Vol.
25, No.
6, pp.970-979Kitani, T. and Mitamura, T. 1994.
An AccurateMorphological Analysis and Proper Name Identificationfor Japanese Text Processing, in Trans.
of IPSJ, Vol.35, No.
3, pp.404-413Kobayashi, Y., Tokunaga, T. and Tanaka, H. 1994.Analysis of Japanese Compound Noun usingCollocational Information, in Proc.
of COIANG, pp.865-869Tanaka, Yasuhito.
1992.
Acquisition of knowledge fornatural language; the four kanji character sequence (inJapanese), in National Conference of InfommtionProcessing Society of Japan555
