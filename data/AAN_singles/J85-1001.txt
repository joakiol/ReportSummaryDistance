A SURVEY OF MACHINE TRANSLATION:ITS HISTORY, CURRENT STATUS,AND FUTURE PROSPECTSJonathan SloculnMicroelectronics and ComputerTechnology CorporationAustin, TexasElements of the history, state of the art, and probable future of Machine Translation (MT) arediscussed.
The treatment is largely tutorial, based on the assumption that this audience is, for the mostpart, ignorant of matters pertaining to translation in general, and MT in particular.
The paper coverssome of the major MT R&D groups, the general techniques they employ(ed), and the roles theyplay(ed) in the development of the field.
The conclusions concern the seeming permanence of thetranslation problem, and potential re-integration of MT with mainstream Computational Linguistics.INTRODUCTIONMachine Translation (MT) of natural human languages isnot a subject about which most scholars feel neutral.This field has had a long, colorful career, and boasts noshortage of vociferous detractors and proponents alike.During its first decade in the 1950s, interest and supportwas fueled by visions of high-speed high-quality trans-lation of arbitrary texts (especially those of interest o themilitary and intelligence communities, who funded MTprojects quite heavily).
During its second decade in the1960s, disillusionment crept in as the number and diffi-culty of the linguistic problems became increasingly obvi-ous, and as it was realized that the translation problemwas not nearly so amenable to automated solution as hadbeen thought.
The climax came with the delivery of theNational Academy of Sciences ALPAC report in 1966,condemning the field and, indirectly, its workers alike.The ALPAC report was criticized as narrow, biased, andshort-sighted, but its recommendations were adopted(with the important exception of increased expendituresfor long-term research in computational linguistics), andas a result MT projects were cancelled in the U.S. andelsewhere around the world.
By 1973, the early part ofthe third decade of MT, only three government-fundedprojects were left in the U.S., and by late 1975 there werenone.
Paradoxically, MT systems were still being used byvarious government agencies here and abroad, becausethere was simply no alternative means of gathering infor-mation from foreign \[Russian\] sources so quickly; inaddition, private companies were developing and sellingMT systems based on the mid-60s technology so roundlycastigated by ALPAC.
Nevertheless the general disreputeof MT resulted in a remarkably quiet third decade.We are now into the fourth decade of MT, and there isa resurgence of interest throughout he world - plus agrowing number of MT and MAT (Machine-aided Trans-lation) systems in use by governments, business andindustry: in 1984 approximately half a million pages oftext were translated by machine.
Industrial firms are alsobeginning to fund M(A)T R&D projects of their own; thusit can no longer be said that only government fundingkeeps the field alive (indeed, in the U.S. there is nogovernment funding, though the Japanese and Europeangovernments are heavily subsidizing MT R&D).
In partthis interest is due to more realistic expectations of whatis possible in MT, and realization that MT can be veryuseful though imperfect; but it is also true that the capa-bilities of the newer MT systems lie well beyond whatwas possible just one decade ago.In light of these events, it is worth reconsidering thepotential of, and prospects for, Machine Translation.Copyright1985 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted provided thatthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or specific permission.0362-613X/85/010001-17503.00Computational Linguistics, Volume 11, Number 1, January-March 1985 1Jonathan Slocum A Survey of Machine TranslationAfter opening with an explanation of how \[human\] trans-lation is done where it is taken seriously, we present abrief introduction to MT technology and a short historicalperspective before considering the ,present status aridstate of the art, and then moving on to a discussion of thefuture prospects.
For reasons of space and perspicuity,we shall concentrate on MT efforts in the U.S. and west-ern Europe, though some other MT projects and less-am-bitious approaches will receive attention.THE HUMAN TRANSLATION CONTEXTWhen evaluating the feasibility or desirability of MachineTranslation, one should consider the endeavor in light ofthe facts of human translation for like purposes.
In theU.S., it is common to conceive of translation as simplythat which a human translator does.
It is generallybelieved that a college degree \[or the equivalent\] in aforeign language qualifies one to be a translator for justabout any material whatsoever.
Native speakers offoreign languages are considered to be that much morequalified.
Thus, translation is not particularly respectedas a profession in the U.S., and the pay is poor.In Canada, in Europe, and generally around the world,this myopic attitude is not held.
Where translation is afact of life rather than an oddity, it is realized that anytranslator's competence is sharply restricted to a fewdomains (this is especially true of technical areas), andthat native fluency in a foreign language does not bestowon one the ability to serve as a translator.
Thus, thereare college-level and post-graduate schools that teach thetheory (translatology) as well as the practice of trans-lation; thus, a technical translator is trained in the fewareas in which he will be doing translation.Of special relevance to MT is the fact that essentiallyall translations for dissemination (export) are revised bymore highly qualified translators who necessarily referback to the original text when post-editing the trans-lation.
(This is not "pre-publication stylistic editing".
)Unrevised translations are always regarded as inferior inquality, or at least suspect, and for many if not mostpurposes they are simply not acceptable.
In the multi-na-tional f i rm Siemens, even internal communications thatare translated are post-edited.
Such news generally comesas a surprise, if not a shock, to most people in the U.S.It is easy to see, therefore, that the "fully-automatichigh-quality machine translation" standard, imagined bymost U.S. scholars to constitute minimum acceptability,must be radically redefined.
Indeed, the most famous MTcritic of all eventually recanted his strong opposition toMT, admitting that these terms could only be defined bythe users, according to their own standards, for each situ-ation (Bar-Hillel 1971).
So an MT system does not haveto print and bind the result of its translation in order toqualify as "fully automatic".
"High quality" does not atall rule out post-editing, since the proscription of humanrevision would "prove" the infeasibility of high-qualityHuman Translation.
Academic debates about whatconstitutes "high-quality" and "fully-automatic" areconsidered irrelevant by the users of Machine Translation(MT) and Machine-aided Translation (MAT) systems;what matters to them are two things: whether thesystems can produce output of sufficient quality for theintended use (e.g., revision), and whether the operationas a whole is cost-effective or, rarely, justifiable on othergrounds, like speed.MACHINE TRANSLATION TECHNOLOGYIn order to appreciate the differences among translationsystems (and their applications), it is necessary to under-stand,?
first, the broad categories into which they can be clas-sified;?
second, the different purposes '.
for which translations(however produced) are used;?
third, the intended appfications of these systems; and?
fourth, something about the linguistic techniques MTsystems employ in attacking the translation problem.CATEGORIES OF SYSTEMSThere are three broad categories of computerized trans-lation tools (the differences hinging on how ambitious thesystem is intended to be): Machine Translation (MT),Machine-aided Translation (MAT), and TerminologyData banks.MT systems are intended to perform translation with-out human intervention.
This does not rule out pre-pro-cessing (assuming this is not for the purpose of markingphrase boundaries and resolving part-of-speech and/orother ambiguities, etc.
), nor post-editing (since this isnormally done for human translations anyway).
Howev-er, an MT system is solely responsible for the completetranslation process from input of the source text tooutput Of the target ext without human assistance, usingspecial programs, comprehensive dictionaries, andcollections of linguistic rules (to the extent they exist,varying with the MT system).
MT occupies the top rangeof positions on the scale of computer translation ambi-tion.MAT systems fall into two subgroups: human-assistedmachine translation (HAMT) and machine-assistedhuman translation (MAHT).
These occupy successivelylower ranges on the scale of computer translation ambi-tion.
HAMT refers to a system wherein the computer isresponsible for producing the translation per se, but mayinteract with a human monitor at many stages along theway - for example, asking the human to disambiguate aword's part of speech or meaning, or to indicate where toattach a phrase, or to choose a translation for a word orphrase from among several candidates discovered in thesystem's dictionary.
MAHT refers to a system whereinthe human is responsible for producing the translationper se (on-line), but may interact with the system incertain prescribed situations - for example, requestingassistance in searching through a local dictionary or2 Computational Linguistics, Volume 11, Number 1, January-March 1985Jonathan Slocum A Survey of Machine Translationthesaurus, accessing a remote terminology data bank,retrieving examples of the use of a word or phrase, orperforming word processing functions like formatting.The existence of a pre-processing stage is unlikely in aMA(H)T system (the system does not need help, instead,it is making help available), but post-editing is frequentlyappropriate.Terminology Data banks (TD) are the least ambitioussystems because access frequently is not made during atranslation task (the translator may not be workingon-line), but usually is performed prior to human trans-lation.
Indeed the data bank may not be accessible (tothe translator) on-line at all, but may be limited to theproduction of printed subject-area glossaries.
A TDoffers access to technical terminology, but usually not tocommon words (the user already knows these).
Thechief advantage of a TD is not the fact that it is auto-mated (even with on-line access, words can be found justas quickly in a printed dictionary), but that it is up-to-date: technical terminology is constantly changing andpublished ictionaries are essentially obsolete by the timethey are available.
It is also possible for a TD to containmore entries because it can draw on a larger group ofactive contributors: its users.THE PURPOSES OF TRANSLATIONThe most immediate division of translation purposesinvolves information acquisition versus dissemination.The classic example of the former purpose is intelli-gence-gathering: with masses of data to sift through,there is no time, money, or incentive to carefully trans-late every document by normal (i.e., human) means.Scientists more generally are faced with this dilemma:there is already more to read than can be read in the timeavailable, and having to labor through texts written inforeign languages - when the probability is low that anygiven text is of real interest - is not worth the effort.
Inthe past, the lingua franca of science has been English;this is becoming less and less true for a variety ofreasons, including the rise of nationalism and the spreadof technology around the world.
As a result, scientistswho rely on English are having greater, difficulty keepingup with work in their fields.
If a very rapid and inexpen-sive means of translation were available, then - for textswithin the reader's areas of expertise - even a low-quali-ty translation might be sufficient for information acquisi-tion.
At worst, the reader could determine whether amore careful (and more expensive) translation effortmight be justified.
More likely, he could understand thecontent of the text well enough that a more careful trans-lation would not be necessary.The classic example of the latter purpose of translationis technology export: an industry in one country thatdesires to sell its products in another country must usual-ly provide documentation in the purchaser's chosenlanguage.
In the past, U.S. companies have escaped thisresponsibility by requiring that the purchasers learnEnglish; other exporters (German, for example) havenever had such luxury.
In the future, with the increase ofnationalism, it is less likely that English documentationwill be acceptable.
Translation is becoming increasinglycommon as more companies look to foreign markets.More to the point, texts for information dissemination(export) must be translated with a great deal of care: thetranslation must b?
"right" as well as clear.
Qualifiedhuman technical translators are hard to find, expensive,and slow (translating somewhere around 4 to 6 pages perday, on the average).
The information disseminationapplication is most responsible for the renewed interest inMT.INTENDED APPLICATIONS OF M(A)TAlthough literary translation is a case of informationdissemination, there is little or no demand for literarytranslation by machine: relative to technical translation,there is no shortage of human translators capable offulfilling this need, and in any case computers do not farewell at literary translation.
By contrast, the demand fortechnical translation is staggering in sheer volume; more-over, the acquisition, maintenance, and consistent use ofvalid technical terminology is an enormous problem.Worse, in many technical fields there is a distinct short-age of qualified human translators, and it is obvious thatthe problem will never be alleviated by measures uch asgreater incentives for translators, however laudable thatmay be.
The only hope for a solution to the technicaltranslation problem lies with increased human productiv-ity through computer technology: full-scale MT, lessambitious MAT, on-line terminology data banks, andword processing all have their place.
A serendipitoussituation involves style: in literary translation, emphasis isplaced on style, perhaps at~the xpense of absolute fideli-ty to content (especially for poetry).
~ In technical trans-lation, emphasis is properly placed on fidelity, even at theexpense of style.
M(A)T systems lack style but excel atterminology: they are best suited for technical trans-lation.LINGUISTIC TECHNIQUESThere are several perspectives from which one can viewMT techniques.
We will use the following: direct versusindirect; interlingua versus transfer; and local versusglobal scope.
(Not all eight combinations are realized inpractice.)
We shall characterize MT systems from theseperspectives, in our discussions.
In the past, "the use ofsemantics" was always used to distinguish MT systems;those which used semantics were labelled "good", andthose which did not were labelled "bad".
Now all MTsystems are claimed to make use of semantics, for obvi-ous reasons, so this is no longer a distinguishing charac-teristic.Direct translation is characteristic of a system (e.g.,GAT) designed from the start to translate out of onespecific language and into another.
Direct systems areComputational Linguistics, Volume 11, Number 1, January-March 1985 3Jonathan Slocum A Survey of Machine Translationlimited to the minimum work necessary to effect thattranslation; for example, disambiguation is performedonly to the extent necessary for translation into that onetarget language, irrespective of what might be requiredfor another language.
Indirect translation, on the otherhand, is characteristic of a system (e.g., EUROTRA)wherein the analysis of the source language and thesynthesis of the target language are totally independentprocesses; for example, disambiguation is performed tothe extent necessary to determine the "meaning"(however epresented) of the source language input, irre-spective of which target language(s) that input might beiranslated into.The interlingua pproach is characteristic of a system(e.g., CETA) in which the representation of the"meaning" of the source language input is intended to beindependent of any language, and this same represen-tation is used to synthesize the target language output.The linguistic universals earched for and debated aboutby linguists and philosophers i the notion that underliesan interlingua.
Thus, the representation f a given unit ofmeaning would be the same, no matter what language (orgrammatical structure) that unit might be expressed in.The transfer approach is characteristic of a system (e.g.,TAUM) in which the underlying representation of the"meaning" of a grammatical unit (e.g., sentence) differsdepending on the language from which it was derived orinto which it is to be generated; this implies the existenceof a third translation stage which maps one language-spe-cific meaning representation i to another: this stage iscalled Transfer.
Thus, the overall transfer transhttionprocess is Analysis followed by Transfer and thenSynthesis.
The transfer versus interlingua difference isnot applicable to all systems; in particular, direct MTsystems use neither the transfer nor the interlinguaapproach, since they do not attempt to represent"meaning".Local scope versus global scope is not so much a differ-ence of category as degree.
Local scope characterizes asystem (e.g., SYSTRAN) in which words are the essentialunit driving analysis, and in which that analysis is, ineffect, performed by separate procedures for each wordwhich try to determine - based on the words to the leftand/or  right - the part of speech, possible idiomaticusage, and "sense" of the word keying the procedure.
Insuch systems, for example, homographs (words thatdiffer in part of speech and/or derivational history \[thusmeaning\], but that are written alike) are a major prob-lem, because a unified analysis of the sentence per se isnot attempted.
Global scope characterizes a system(e.g., METAL) in which the meaning of a word is deter-mined by its context within a unified analysis of thesentence (or, rarely, paragraph).
In such systems, bycontrast, homographs do not typically constitute a signif-icant problem because the amount of context aken intoaccount is much greater than is the case with systems oflocal scope.HISTORICAL PERSPECTIVEThere are several comprehensive treatments of MTprojects (Bruderer 1977) and MT history (Hutchins1978) available in the open literature.
To illustrate somecontinuity in the field of MT, while remaining withinreasonable space limits, our brief historical overview isrestricted to defunct systems or projects that gave rise tofollow-on systems or projects of current interest.
Theseare:?
Georgetown's GAT,?
Grenoble's CETA,?
Texas's METAL,?
Montreal's TAUM, and?
Brigham Young University's ALP system.GAT: GEORGETOWN AUTOMATIC TRANSLATIONGeorgetown University was the site of one of the earliestMT projects.
Begun in 1952, and supported by the U.S.government, Georgetown's GAT system became opera-tional in 1964 with its delivery to the Atomic EnergyCommission at Oak Ridge National Laboratory, and toEurope's corresponding research facility EURATOM inIspra, Italy.
Both systems were used for many years totranslate Russian physics texts into "English".
Theoutput quality was quite poor, by comparison with humantranslations, but for the intended purpose of quicklyscanning documents to determine their content and inter-est, the GAT system was nevertheless uperior to the onlyalternatives: low and more expensive human translationor, worse, no translation at all.
GAT was not replaced atEURATOM until 1976; at ORNL, it seems to have beenused until at least 1979 (Jordan et al 1976, 1977) andpossibly later.The GAT strategy was direct and local: simple word-for-word replacement, followed by a limited amount oftransposition of words to result in something vaguelyresembling English.
Very soon, a "word" came to bedefined as a single word or a sequence of words formingan "idiom".
There was no true linguistic theory underly-ing the GAT design; and, given the state of the art incomputer science, there was no underlying computationaltheory either.
GAT was developed by being made towork for a given text; then being modified to account forthe next text, and so on.
The eventual result was amonolithic system of intractable complexity: after itsdelivery to ORNL and EURATOM, it underwent nosignificant modification.
The fact that it was used for solong is nothing short of remarkable - a lesson in whatcan be tolerated by users who desperately need trans-lation services for which there is no viable alternative toeven low-quality MT.The Georgetown MT project was terminated in themid-60s.
Peter Toma, one of the GAT workers, incorpo-rated LATSEC and developed the SYSTRAN system,which in 1970 replaced the IBM Mark II system at theUSAF Foreign Technology Division (FTD) at Wright4 Computational Linguistics, Volume 11, Number I, January-Marcb 1985Jonathan Slocum A Survey of Machine TranslationPatterson AFB, and in 1976 replaced GAT at EURATOM.SYSTRAN is still being used there to translate Russianinto English for information-acquisition purposes.
Weshall return to our discussion of SYSTRAN in the nextmajor section.CETA: CENTRE D'I~TUDES POUR LA TRADUCTION AUTOMA-TIQUEIn 1961 a project to translate Russian into French wasstarted at Grenoble University in France.
Unlike GAT,Grenoble began the CETA project with a clear linguistictheory - having had a number of years in which towitness and learn from the events transpiring at George-town and elsewhere.
In particular, it was resolved toachieve a dependency-structure analysis of everysentence (a global approach) rather than rely on intra-sentential heuristics to control limited word transposition(the local approach); with a unified analysis in hand, areasonable synthesis effort could be mounted.
Thetheoretical basis of CETA was interlingua (implying alanguage-independent, eutral meaning representation)at the grammatical evel, but transfer (implying amapping from one language-specific meaning represen-tation to another) at the lexical \[dictionary\] level.
Thestate of the art in computer science still being primitive,Grenoble was essentially forced to adopt IBM assemblylanguage as the software basis of CETA (Hutchins 1978).The CETA system was under development for tenyears; during 1967-71 it was used to translate 400,000words of Russian mathematics and physics texts intoFrench.
The major findings of this period were that theuse of an interlingua erases all clues about how to expressthe translation; also, that it results in extremely poor orno translations of sentences for which complete analysescannot be derived.
The CETA workers learned that it iscritically important in an operational system to retainsurface clues about how to formulate the translation(Indo-European languages, for example, have manystructural similarities, not to mention cognates, that onecan take advantage of), and to have "fail-soft" measuresdesigned into the system.
An interlingua does not allowthis easily, if at all, but the transfer approach does.A change in hardware (thus software) in 1971prompted the abandonment of the CETA system, imme-diately followed by the creation of a new project/systemcalled GETA, based entirely on a fail-soft transfer design.The software included significant amounts of assemblylanguage; this continued reliance on assembly languagewas soon to have deleterious effects, for reasons nowobvious to anyone.
We return to our discussion of GETAbelow.METAL: MECHANICAL TRANSLATION AND ANALYSISOF LANGUAGESHaving had the same opportunity for hindsight, theUniversity of Texas in 1961 used U.S. government fund-ing to establish the Linguistics Research Center, and withit the METAL project, to investigate MT - not fromRussian but from German into English.
(MT research atthe University actually began in 1956.)
The LRCadopted Chomsky's transformational paradigm, whichwas quickly gaining popularity in linguistics circles, andwithin that framework employed a syntactic interlinguabased on deep structures.
It was soon discovered thattransformational linguistics per se was not sufficientlywell developed to support an operational system, andcertain compromises were made.
The eventual result, in1974, was an 80,000-line, 14-overlay FORTRANprogram running on a dedicated CDC 6600.
Indirecttranslation was performed in 14 steps of global analysis,transfer, and synthesis - one for each of the 14 overlays- and required prodigious amounts of CPU time and I /Of rom/to massive data files.
U.S. government support forMT projects was winding down in any case, and theMETAL project was shortly terminated.Several years later, a small Government grant resur-rected the project.
The FORTRAN program was rewrit-ten in LISP to run on a DEC-10; in the process, it waspared down to just three major stages (analysis, transfer,and synthesis) comprising about 4,000 lines of codewhich could be accommodated in three overlays, and itscomputer resource requirements were reduced by afactor of ten.
Though U.S. government interest onceagain languished, the Sprachendienst (LanguageServices) department of Siemens AG in Munich hadbegun supporting the project, and in 1980 Siemens AGbecame the sole sponsor.TAUM: TRADUCTION AUTOMATIQUE DE L'UNIVERSITI~DE MONTRI~ALIn 1965 the University of Montreal established theTAUM project with Canadian government funding.
Thiswas probably the first MT project designed strictlyaround the transfer approach.
As the software basis ofthe project, TAUM chose the FORTRAN programminglanguage on the CDC 6600 (later, the CYBER" 173).
Afteran initial period of more-or-less open-ended research, theCanadian government began adopting specific goals forthe TAUM system.
A chance remark by a bored transla-tor in the Canadian Meteorological Center (CMC) hadled to a spin-off project: TAUM-METEO.
Weather fore-casters already adhered to a relatively consistent styleand vocabulary in their English reports.
Partly as a resultof this, translation into French was so monotonous a taskthat human translator turnover in the weather servicewas extraordinarily high - six months was the averagetenure.
TAUM was commissioned in 1975 to produce anoperational English-French MT system for weather fore-casts.
A prototype was demonstrated in 1976, and by1977 METEO was installed for production translation.METEO is discussed in the next major section.The next challenge was not long in coming: by a fixeddate, TAUM had to be usable for the translation of a 90million word set of aviation maintenance manuals fromEnglish into French (else the translation had to be startedby human means, since the result was needed quickly).Computational Linguistics, Volume 11, Number 1, January-March 1985 5Jonathan Slocum A Survey of Machine TranslationFrom this point on, TAUM concentrated on the aviationmanuals exclusively.
To alleviate problems with theirpredominantly syntactic analysis (especially consideringthe many multiple-noun compounds present in theaviation manuals), the group began in 1977 to incorpo-rate significant semantic analysis in theTAUM-AVIATION system.After a test in 1979, it became obvious thatTAUM-AVIATION was not going to be production-readyin time for its intended use.
The Canadian governmentorganized a series of tests and evaluations to assess thestatus of the system.
Among other things, it was discov-ered that the cost of writing each dictionary entry wasremarkably high (3.75 man-hours, costing $35-40 Cana-dian), and that the system's runtime translation cost wasalso high (6 cents per word) considering the cost ofhuman translation (8 cents per word), especially whenthe post-editing costs (10 cents per word for TAUMversus 4 cents per word for human translations) weretaken into account (Gervais 1980).
TAUM-AVIATIONwas not yet cost-effective.
Several other factors, espe-cially the bad Canadian economic situation, combinedwith this to cause the cancellation of the TAUM projectin 1981.
There are recent signs of renewed interest inMT in Canada.
State-of-the-art surveys have beencommissioned (Pierre Isabelle, formerly of TAUM,personal communication), but no successor project hasyet been established.ALP: AUTOMATED LANGUAGE PROCESSINGIn 1971 a project was established at Brigham YoungUniversity to translate Mormon ecclesiastical texts fromEnglish into multiple languages - starting with French,German, Portuguese and Spanish.
The original aim wasto produce a fully-automatic MT system based on Junc-tion Grammar (Lytle et al 1975), but in 1973 theemphasis shifted to Machine-aided Translation (MAT,where the system does not attempt o analyze sentenceson its own, according to pre-programmed linguistic rules,but instead relies heavily on interaction with a human toeffect the analysis if one is even attempted and completethe translation).
This Interactive Translation System(ITS) performed global analysis of sentences (with humanassistance), and then indirect ransfer (again, with humanassistance).The BYU project never produced an operationalsystem (hardware costs and the amount and difficulty ofhuman interaction prohibited cost-effectiveness), and theMormon Church, through the University, began todismantle the project.
In 1980, a group of BYU program-mers joined Weidner Communications Corporation, andhelped develop the fully-automatic, direct Weidner MTsystem.
At about the same time, most of the remainingBYU project members left to form Automated LanguageProcessing Systems (ALPS) and continue development ofITS.
Both of these systems are actively marketed today,and are discussed in the next section.
Some work contin-ues at BYU, but at a very much reduced level and degreeof aspiration (e.g., Melby 1982).CURRENT PRODUCTION SYSTEMSIn this section we consider the major M(A)T systemsbeing used and/or  marketed today.
Some of these origi-nate from the "failures" described above, but othersystems are essentially the result of successful (i.e.,continuing) MT R&D projects.
The full MT systemsdiscussed below are the following:?
SYSTRAN,?
LOGOS,?
METEO,?
Weidner, and?
SPANAM.We also discuss the MAT systems CULT and ALPS.
Mostof these systems have been installed for several custom-ers (METEO, SPANAM, and CULT are the exceptions,with only one obvious customer each).
The oldest activeinstallation dates from 1970.A "standard installation", if it can be said to exist,includes provision for pre-processing in some cases,translation (with much human intervention i  the case ofMAT systems), and some amount of post-editing.
To MTsystem users, acceptability is a function of the amount ofpre- and/or  post-editing that must be done (which is alsothe greatest determinant of cost).
Van Slype (1982)reports that "acceptability to the human translator .
.
.appears negotiable when the quality of the MT system issuch that the correction (i.e., post-editing) ratio is lowerthan 20% (1 correction every 5 words) and when thehuman translator can be associated with the upgrading ofthe MT system."
It is worth noting that editing time hasbeen observed to fall with practice: Pigott (1982) reportsthat " .
.
.
the more M.T.
output a translator handles, themore proficient he becomes in making the best use of thisnew tool.
In some cases he manages to double his outputwithin a few months as he begins to recognize typicalM.T.
errors and devise more efficient ways of correctingthem.
"It is also important o realize that, though none ofthese systems produces output mistakable for humantranslation \[at least not good human translation\], theirusers have found sufficient reason to continue usingthem.
Some users, indeed, are repeat customers.
Inshort, MT and MAT systems cannot be argued not towork, for they are in fact being bought and used, andthey save time and/or  money for their users.
Every userexpresses a desire for improved quality and reduced cost,to be sure, but then the same is said about human trans-lation.
Thus, in the only valid sense of the idiom, MT andMAT have already "arrived".
Future improvements inquality, and reductions in cost - both certain to takeplace - will serve to make M(A)T systems even moreattractive.6 Computational Linguistics, Volume 11, Number 1, January-March 1985Jonathan Sloeum A Survey of Machine TranslationSYSTRANSYSTRAN was one of the first MT systems to be market-ed; the first installation replaced the IBM Mark IIRussian-English system at the USAF FTD in 1970, and isstill operational.
NASA selected SYSTRAN in 1974 totranslate materials relating to the Apollo-Soyuz collab-oration, and EURATOM replaced GAT with SYSTRAN in1976.
Also by 1976, FTD was augmenting SYSTRANwith word-processing equipment to increase productivity(e.g., to eliminate the use of punched cards).
The systemhas continued to evolve, for example by the shift towarda more modular design and by the allowance of topicalglossaries (essentially, dictionaries pecific to the subjectarea of the text).
The system has been argued to be adhoc - particularly in the assignment of semantic features(Pigott 1979).
The USAF FTD dictionaries number overa million entries; Bostad (1982) reports that dictionaryupdating must be severely constrained, lest a change toone entry disrupt the activities of many others.
(A studyby Wilks (1978) reported an improvement/degradationratio \[after dictionary updates\] of 7:3, but Bostad impliesa much more stable situation after the introduction ofstringent quality-control measures.
)In 1976 the Commission of the European Communi-ties purchased an English-French version of SYSTRANfor evaluation and potential use.
Unlike the FTD, NASA,and EURATOM installations, where the goal was infor-mation acquisition, the intended use by CEC was forinformation dissemination - meaning that the output wasto be carefully edited before human consumption.
VanSlype (1982) reports that "the English-French standardvocabulary delivered by Prof. Toma to the Commissionwas found to be almost entirely useless for the Commis-sion environment."
Early evaluations were negative(e.g., Van Slype 1979), but the existing and projectedoverload on CEC human translators was such that inves-tigation continued in the hope that dictionary additionswould improve the system to the point of usability.Additional versions of SYSTRAN were purchased(French-English in 1978, and English-Italian in 1979).The dream of acceptable quality for post-editingpurposes was eventually realized: Pigott (1982) reportsthat " .
.
.
the enthusiasm demonstrated by \[a few trans-lators\] seems to mark something of a turning point in\[machine translation\]."
Currently, about 20 CEC trans-lators in Luxembourg are using SYSTRAN on a Siemens7740 computer for routine translation; one factoraccounting for success is that the English and Frenchdictionaries now consist of well over 100,000 entries inthe very few technical areas for which SYSTRAN is beingemployed.Also in 1976, General Motors of Canada acquiredSYSTRAN for translation of various manuals (for vehicleservice, diesel locomotives, and highway transit coaches)from English into French on an IBM mainframe.
GM'sEnglish-French dictionary had been expanded to over130,000 terms by 1981 (Sereda 1982).
Subseque~ly~GM purchased an English-Spanish version of SYSTRAN,and began to build the necessary \[very large\] dictionary.Sereda (1982) reports a speed-up of 3-4 times in theproductivity of his human translators (from about 1000words per day); he also reveals that developingSYSTRAN dictionary entries costs the company approxi-mately $4 per term (word- or idiom-pair).While other SYSTRAN users have applied the systemto unrestricted texts (in selected subject areas), Xeroxhas developed a restricted input language (MultinationalCustomized English) after consultation with LATSEC.That is, Xerox requires its English technical writers toadhere to a specialized vocabulary and a strict manual ofstyle.
SYSTRAN is then employed to translate the result-ing documents into French, Italian, Spanish, German,and Portuguese.
Ruffino (1982) reports "a five-to-onegain in translation time for most texts" with the range ofgains being 2-10 times.
This approach is not necessarilyfeasible for all organizations, but Xerox is willing toemploy it and claims it also enhances ource-text clarity.Currently, SYSTRAN is being used in the CEC for theroutine translation, followed by human post-editing, ofaround 1,000 pages of text per month in the couplesEnglish-French, French-English, and English-Italian(Wheeler 1983).
Given this relative success in the CECenvironment, he Commission has recently ordered anEnglish-German version as well as a French-Germanversion.
Judging by past experience, it will be quite sometime before these are ready for production use, but whenready they will probably save the CEC translation bureauvaluable time, if not real money as well.LOGOSDevelopment of the LOGOS system was begun in 1964.The first installation, in 1971, was used by the U.S. AirForce to translate English maintenance manuals for mili-tary equipment into Vietnamese.
Due to the terminationof U.S. involvement in that war, its use was ended aftertwo years.
(A report by Sinaiko and Klare (1973)disparaged LOGOS's cost-effectiveness, but this claimwas argued to be seriously flawed and was formallyprotested (Scott, personal communication).)
The linguis-tic foundations of LOGOS are not well advertised,presumably for reasons involving trade secrecy.
Thesystem developer states that "our linguistic approach .
.
.has evolved in ways analogous to case grammar/valencytheory .
.
.
mapping natural anguage into a semanto-syntactic abstraction language organized as a tree"(Scott, personal communication).LOGOS continued to attract customers.
In 1978,Siemens AG began funding the development of a LOGOSGerman-English system for telecommunications manuals.After three years LOGOS delivered a "production"system, but it was not found suitable for use (due in partto poor quality of the translations, and in part to theeconomic situation within Siemens which had resulted inff much-reduced demand for translation, hence no imme-Computational Linguistics, Volume 11, Number 1, January-March 1985 7Jonathan Slocum A Survey of Machine Translationdiate need for an MT system).
Eventually LOGOS forgedan agreement with the Wang computer company thatallowed the :implementation of the German-Englishsystem (formerly restricted to large IBM mainframes) onWang office computers.
This system reached thecommercial market, and has been purchased by severalmulti-national organizations (e.g., Nixdorf, Triumph-Adler, Hewlett-Packard); development of other languagepairs (e.g., English-French, English-German) is under-way (Scott, personal communication).METEOTAUM-METEO is the world's only example of a trulyfully-automatic MT system.
Developed as a spin-off ofthe TAUM technology, as discussed earlier, it was fullyintegrated into the Canadian Meteorological Center's(CMC's) nation-wide weather communications networkby 1977.
METEO scans the network traffic for Englishweather eports, translates them "directly" into French,and sends the translations back out over the communi-cations network automatically.
Rather than relying onpost-editors to discover and correct errors, METEOdetects its own errors and passes the offending input tohuman editors; output deemed "correct" by METEO isdispatched without human intervention, or even over-view.TAUM-METEO was probably also the first MT systemwhere translators were involved in all phases of thedesign/development/refinement; indeed, a CMC transla-tor instigated the entire project.
Since the restrictions oninput to METEO were already in place before the projectstarted (i.e., METEO imposed no new restrictions onweather forecasters), METEO cannot quite be classedwith the Xerox SYSTRAN system, which relies onrestrictions geared to the characteristics of SYSTRAN.But METEO is not extensible - though similar systemscould be built for equally restricted textual domains, ifthey exist.One of the more remarkable side effects of theMETEO installation is that the translator turnover ratewithin the CMC went from 6 months, prior to METEO, toseveral years, once the CMC translators began to trustMETEO's operational decisions and not review its output(Brian Harris, personal communication).
METEO's inputconstitutes over 24,000 words per day, or 8.5 millionwords per year.
Of this, it now correctly translates90-95%, shuttling the other ("more interesting") 5-10%to the human CMC translators.
Almost all of these"analysis failures" are attributable to communicationsnoise (the CMC network garbles some traffic),misspellings (METEO does not attempt corrections), orwords missing from the dictionary, though some failuresare due to the inability of the system to handle certainlinguistic constructions.
METEO's computational require-ments total about 15 CPU minutes per day on a CDC7600 (Thouin 1982).
By 1981, it appeared that the built-in limitations of METEO's theoretical basis had beenreached, and further improvement was not likely to becost-effective.WEIDNER COMMUNICATIONS CORPORATIONWeidner was established in 1977 by Bruce Weidner, whosoon hired some MT programmers from the fading BYUproject.
Weidner delivered a production English-Frenchsystem to Mitel in Canada in 1980, and a beta-test Engl-ish-Spanish system to the Siemens Corporation (USA) inthe same year.
In 1981 Mitel took delivery on Weidner'sEnglish-Spanish and English-German systems, and Brav-ice (a translation service bureau in Japan) purchased theWeidner English-Spanish and Spanish-English systems.To date, there are 22 or more installations of the Weid-ner MT system around the world.
The Weidner system,though "fully automatic" during translation, is marketedas a "machine aid" to translation (perhaps to avoid thestigma usually attached to MT).
It is highly interactivefor other purposes (the lexical pre-analysis of texts, theconstruction of dictionaries, etc.
), and integrates word-processing software with external devices (e.g., theXerox 9700 laser printer at Mitel) for enhanced overalldocument production.
Thus, the Weidner system acceptsa formatted source document (actually, one containingformatting or typesetting codes) and produces a format-ted translation.
This is an important feature to users,since almost everyone is interested in producing format-ted translations from formatted source texts.Given the way this system is tightly integrated withmodern word-processing technology, it is difficult toassess the degree to which the translation componentitself enhances translator productivity, versus the degreeto which simple automation of formerly manual (or poor-ly automated) processes accounts for the productivitygains.
The direct translation component itself is notparticularly sophisticated.
For example, analysis is local,usually confined to the noun phrase or verb phrase level(except for Japanese) - so that context available only athigher levels cannot be taken into account.Translation is performed in four independent stages:homograph disambiguation, idiom search, structural anal-ysis, and transfer.
These stages do not interact with eachother, which creates more problems; for example, homo-graphs are resolved once and for all very early on, with-out any higher-level context (it is not available untillater) that would make this process much more sensitive.As another example, Hundt (1982) comments that"idioms are an extremely important part of the trans-lation procedure .
.
.
.
machine assisted translation is forthe most part word replacement .
.
.
.  "
Then, "It is notworthwhile discussing the various problems of the \[Weid-ner\] system in great depth because in the first place theyare much too numerous .
.
.
.  "
Yet even though theWeidner translations are of low quality, users neverthe-less report economic satisfaction with the results.
Hundtcontinues, " .
.
.
\[T\]he Weidner system indeed works asan aid .
.
. "
and, "800 words an hour as a final figure8 Computational Linguistics, Volume 11, Number 1, January-March 1985Jonathan Slocum A Survey of Machine Translation\[for translation throughput\] is not unrealistic."
This levelof performance was not attainable with previous \[human\]methods, and some users report the use of Weidner to becost-effective, aswell as faster, in their environments.In 1982, Weidner delivered English-German andGerman-English systems to ITT in Great Britain; butthere were some financial problems (a third of theemployees were laid off that year) until 1983, when acontrolling interest was purchased by a Japanese compa-ny: Bravice, one of Weidner's customers, owned by agroup of Japanese investors.
Weidner continues tomarket MT systems, and is presently working to developJapanese MT systems.
A commercial Japanese-Englishsystem has recently been announced by Bravice, andwork continues on an English-Japanese system.
In addi-tipn, Weidner has implemented its system on the IBMPersonal Computer, in order to reduce its dependence onthe PDP-11 in particular, and on any one machine ingeneral.
The system is written in FORTRAN, with someassembly code support, but there are plans to reimple-ment the software in another language to increase itsflexibility.SPANAMFollowing a promising feasibility study, the Pan Ameri-can Health Organization in Washington, D.C. decided in1975 to undertake work on a machine translation system,utilizing some of the same techniques developed for GAT.Consultants were hired from nearby Georgetown Univer-sity, the home of GAT.
The official PAHO languages areEnglish, French, Portuguese, and Spanish; Spanish-Engl-ish was chosen as the initial language pair, due to thebelief that "This combination requires fewer parsing stra-tegies in order to produce manageable output \[and otherreasons relating to expending effort on software ratherthan linguistic rules\]" (Vasconcellos 1983).
Actual workstarted in 1976, and the first prototype was running in1979, using punched card input on an IBM mainframe.With the subsequent integration of a word-processingsystem, production use could be seriously considered.After further upgrading, an in-house translationservice based on SPANAM was created in 1980.
Laterthat year, in its first major test, SPANAM reducedmanpower equirements for a test translation effort by45%, resulting in a monetary savings of 61% (Vascon-cellos 1983).
(Because these SPANAM translation andon-line post-editing figures appear to be contrastedagainst he purely manual, hardcopy translation traditionat PAHO, the gains from using SPANAM per se may behopelessly confounded with the gains of working on-line;thus, it is difficult or impossible to say how much increasein productivity is accounted for by SPANAM alone.
)Since 1980, SPANAM has been used to translate wellover a million words of text, averaging about 4,000words per day per post-editor.
The post-editors haveamassed "a bag of tricks" for speeding the revision work,and special string functions have also been built into theword processor for handling SPANAM's English output.Concerning the early status of SPANAM, sketchydetails implied that the linguistic technology underlying itwas essentially that of GAT; the grammar rules seemed tobe built into the programs, in the GAT tradition.
Thesoftware technology was updated in that the programsare modular.
The system is not sophisticated: it adoptsthe direct translation strategy, and settles for local analy-sis of phrases and some clauses via a sequence of primi-tive, independent processing stages (e.g., homographresolution) - again, in the Georgetown tradition.SPANAM is currently used by three PAHO translators intheir routine work.A follow-on project to develop ENGSPAN (for Engl-ish-Spanish), underway since 1981, has also delivered aproduction system - this one characterized by a moreadvanced esign (e.g., an ATN parser), some features ofwhich may find their way into SPANAM.
(SPANAM iscurrently "undergoing a major overhaul" (Vasconcellos,personal communication).)
Four PAHO translatorsalready employ ENGSPAN in their daily work.
Based onthe successes of these two systems, development ofENGPORT (with Portuguese as the Target Language) hasbegun.
In the future, "all translators \[in the LanguageServices bureau of PAHO will be\] expected to use MT atleast part of the time, and the corresponding duties areincluded in the post descriptions".
(Vasconcellos,personal communication).CULT: CHINESE UNIVERSITY LANGUAGE TRANSLATORCULT is possibly the most successful of the Machine-aid-ed Translation systems, Development began at theChinese University of Hong Kong around 1968.
CULTtranslates Chinese mathematics and physics journals(published in Beijing) into English through a highly-inter-active process \[or, at least, with a lot of human inter-vention\].
The goal was to eliminate post-editing of theresults by allowing a large amount of pre-editing of theinput, and a certain \[unknown\] degree of human inter-vention during translation.
Although published details(Loh 1976, 1978, 1979) are not unambiguous, it is clearthat humans intervene by marking sentence and phraseboundaries in the input, and by indicating word senseswhere necessary, among other things.
(What is not clearis whether this is strictly a pre-editing task, or an interac-tive task.)
CULT runs on the ICL 1904A computer.Beginning in 1975, the CULT system was applied tothe task of translating the Acta Mathematica Sinica intoEnglish; in 1976, this was joined by the Acta PhysicaSini6a.
Originally the Chinese character transcriptionproblem was solved by use of the standard telegraphcodes invented a century ago, and the input data waspunched on cards.
But in 1978 the system was updatedby the addition of word-processing equipment for on-linedata entry and pre- or post-editing.Computational Linguistics, Volume 11, Number 1, January-March 1985 9Jonathan Slocum A Survey of Machine TranslationIt is not cleat' how general the techniques behindCULT are - whether, for example, it could be applied tothe translation of other texts - nor how cost-effective itis in operation.
Other factors may justify its continueduse.
It is also unclear whether R&D is continuing, orwhether CULT, like METEO, is unsuited to design modifi-cation beyond a certain point already reached.
In theabsence of answers to these questions, and perhapsdespite them, CULT does appear to be an MAT successstory: the amount of post-editing said to be required istrivial - limited to the re-introduction of certain untrans-latable formulas, figures, etc., into the translated output.At some point, other translator intervention is required,but it seems to be limited to the manual inflection ofverbs and nouns for tense and number, and perhaps theintroduction of a few function words such as determiners.ALPS: AUTOMATED LANGUAGE PROCESSING SYSTEMSALPS was incorporated by a group of five BrighamYoung University ITS developers in 1980; this groupseems to have been composed of linguists interested inproducing machine aids for human translators (dictionarylook-up and substitution, etc.)
and later grew to includevirtually all of the major figures from the ITS staff(Melby and Tenney, personal communication).
Thus thenew ALPS system is interactive in all respects, and doesnot seriously pretend to perform translation; rather,ALPS provides the translator with a set of software toolsto automate many of the tasks encountered in everydaytranslation experience.
ALPS adopted the language pairsthat the BYU ITS system had supported: English intoFrench, German, Portuguese, and Spanish.
Since then,other languages (e.g., Arabic) have been announced, buttheir commercial status is unclear.
In addition to sellingMAT systems, ALPS now includes its own translationservice bureau.The new ALPS system is intended to work on any ofthree "levels" - providing capabilities from multilingualword processing and dictionary lookup, through word-for-word (actually, term-for-term) translation, to highly-automated (though human-assisted) sentence-leveltranslation; ~the latter mode of operation, judging byALPS demonstrations and the reports of users, is seldomif ever employed.
The central tool provided by ALPS isthus a menu-driven word-processing system coupled tothe on-line dictionary.
One of the first ALPS customersseems to have been Agnew TechTran - a commercialtranslation bureau which acquired the ALPS system forin-house use.
Other customers include Xerox, Compu-terVision, Control Data (in France), IBM (in Italy) andHewlett-Packard (in Mexico).
Recently, another shake-up at Weidner Communication Corporation (the ProvoR&D group was disbanded) has allowed ALPS to hire alarge group of former Weidner workers: ALPS mightitself be intending to enter the fully-automatic MT arena.CURRENT RESEARCH AND DEVELOPMENTIn addition to the organizations marketing or using exist-ing M(A)T systems, there are several groups engaged inon-going R&D in this area.
Operational (i.e., marketed orused) systems have not yet resulted from these efforts,but deliveries are foreseen at various times in the future.We discuss the major Japanese MT efforts briefly (as ifthey were unified, in a sense, though for the most partthey are actually separate), and then the major U.S. andEuropean MT systems at greater length.MT R & D IN JAPANIn 1982 Japan electrified the technological world bywidely publicizing its new Fifth Generation project andestablishing the Institute for New Generation ComputerTechnology (ICOT) as its base.
Its goal is to leapfrogWestern technology and place Japan at the forefront ofthe digital electronics world in the 1990's.
MITI (Japan'sMinistry of International Trade and Industry) is the moti-vating force behind this project, and intends that the goalbe achieved through the development and application ofhighly innovative techniques in both computer architec-ture and Artificial Intelligence.Of the application areas considered as an applicationscandidate by the ICOT scientists and engineers, MachineTranslation played a prominent role (Moto-oka 1982).Among the western Artificial Intelligentsia, the inclusionof MT seems out of place: AI researchers have beentrying (successfully) to ignore all MT work in the twodecades ince the ALPAC debacle, and almost universallybelieve that success is impossible in the foreseeablefuture - in ignorance of the successful, cost-effectiveapplications already in place.
To the Japanese leader-ship, however, the inclusion of MT is no accident.Foreign language training aside, translation into Japaneseis still one of the primary means by which Japaneseresearchers acquire information about what their West-ern competitors are doing, and how they are doing it.Translation out of Japanese is necessary before Japancan export products to its foreign markets, because thecustomers demand that the manuals and other documen-tation not be written only in Japanese, and in generaltranslation is seen as a way to "diffuse the Japanesescientific and technological information to outer world"(Nagao, personal communication).
The Japanesecorrectly view translation as necessary to their technolog-ical survival, but have found it extremely difficult - andexpensive - to accomplish by human means: the trans-lation budgets of Japanese companies, when totalled, areestimated to exceed 1 trinion yen, and most of thisinvolves the export trade (Philippi 1985).
Accordingly,the Japanese government and industry have sponsoredMT research for several decades.
There has been no riftbetween AI and MT researchers in Japan, as there hasbeen in the West - especially in the U.S.10 Computational Linguistics, Volume 11, Number 1, January-March 1985Jonathan Slocum A Survey of Machine TranslationNomura (1982) numbers the MT R&D groups in Japanat more than 18.
(By contrast, there might be a dozensignificant MT groups in all of the U.S. and Europe,including commercial vendors.)
Several of the Japaneseprojects are quite large.
(By contrast, only one MTproject in the western world (EUROTRA) even appearsas large, but most of the 80 individuals involved work onEUROTRA only a fraction of their time.)
Most of theJapanese projects are engaged in research as much asdevelopment.
(Most Western projects are engaged inpure development.)
Japanese progress in MT has notcome fast: until a few years ago, their hardware technol-ogy was inferior; so was their software competence, butthis situation has been changing rapidly.
Another obsta-cle has been the great differences between Japanese andWestern languages - especially English, which is ofgreatest interest o them - and the relative paucity ofknowledge about these differences.
The Japanese areworking to eliminate this ignorance: progress has beenmade, and production-quality s stems already exist forsome applications.
None of the Japanese MT systems aredirect, and all engage in global analysis; most are basedon a transfer approach, but a few groups are pursuing theinterlingua pproach.MT research as been pursued at Kyoto Universitysince 1964.
There were once two MT projects at Kyoto(one for long-term research, one for near-term applica-tion).
The former project, recently abandoned, wasworking on an English-Japanese translation system basedon formal semantics (Cresswell's implified version ofMontague Grammar (Nishida et al 1982, 1983)).
Thelatter has developed a practical system for translatingEnglish titles of scientific and technical papers into Japa-nese (Nagao 1980, 1982), and is working on other appli-cations of English-Japanese (Tsujii 1982) as well asJapanese-English (Nagao 1981).
This effort, funded bythe Agency of Science and Technology and headed byProf.
Nagao, "consists of more than 20 people \[atKyoto\], with three other organizations involved \[compris-ing another 20 workers\]" (Nagao personal communi-cation).
The goal of this four-year, $2.7 million (U.S.)project is to create a practical system for translating tech-nical and scientific documents from Japanese intoEnglish and vice versa (Philippi 1985).
Kyushu Universi-ty has been the home of MT research since 1955, withprojects by Tamachi and Shudo (1974).
The Universityof Osaka Prefecture and Fukuoka University also hostMT projects.However, most Japanese MT research (like otherresearch) is performed in the industrial laboratories.Fujitsu (Sawai et al 1982), Hitachi, Toshiba (Amano1982), and NEC (Muraki & Ichiyama 1982), amongothers, support large projects generally concentrating onthe translation of computer manuals.
Nippon Telegraphand Telephone is working on a system to translate scien-tific and technical articles from Japanese into English andvice versa (Nomura et al 1982), and is looking into thefuture as far as simultaneous machine translation of tele-phone conversations (Nomura, personal communication).Recently a joint venture by Hitachi and Quick hasresulted in a English-Japanese ystem which will be usedto offer Japanese readers news from Europe and the U.S.on the economy, stock market, and commodities; eventu-ally, this service will be offered via Quick's on-linemarket information service (AAT 1984).
In addition,Fujitsu has announced its bi-directional Atlas Japanese-English system for translating technical texts; this systemis now available for lease (AAT 1984).
NEC and IBMJapan have also recently announced evelopment ofsystems intended for near-term commercial introduction(Philippi 1985).Japanese industrialists are not confining their attentionto work at home.
Several AI groups in the U.S.
(e.g., SRIInternational) have been approached by Japanesecompanies desiring to fund MT R&D projects, and theLinguistics Research Center of the University of Texas iscurrently engaged in MT-related research funded byHitachi.
More than that, some U.S. MT vendors(SYSTRAN and Weidner, at least) have recently soldpartial interests to Japanese investors, and deliveredproduction MT systems.
Various Japanese corporations(e.g., NTT and Hitachi) and trade groups (e.g., JEIDA(Japan Electronic Industry Development Association))have sent teams to visit MT projects around the worldand assess the state of the art.
University researchershave been given sabbaticals to work at Western MTcenters (Prof. Shudo at Texas, Prof. Tsujii at Grenoble).Other representatives have indicated Japan's desire toestablish close working communications with the CEC'sEUROTRA project (King and Nagao, personal communi-cation).
Japan evidences a long-term, growing commit-ment to acquire and develop MT technology.
TheJapanese leadership is convinced that success in MT isvital to their future.METALOne of the major MT R&D groups around the world, theMETAL project at the Linguistics Research Center of theUniversity of Texas, has recently delivered a commer-cial-grade system.
The METAL German-English systempassed tests in a production-style s tting in late 1982,mid-1983, and twice in 1984, and the system was theninstalled at the sponsor's ite in Germany for further test-ing and final development of a translator interface.Renamed LITRAS, it was introduced for sale at theHanover Fair in Germany in April 1985.
The METALdictionaries are now being expanded for maximum possi-ble coverage of selected technical areas, and work onother language pairs has begun in earnest.One of the particular strengths of the METAL systemis its accommodation of a variety of linguistictheories/strategies.
The German analysis component isbased on a context-free phrase-structure grammar,augmented by procedures with facilities for, among otherComputational Linguistics, Volume 11, Number 1, January-March 1985 11Jonathan Slocum A Survey of Machine Translationthings, arbitrary transformations.
The English analysiscomponent, on tile other hand, employs a modified GPSGapproach and makes no use of transformations.
Analysisis completely separated from transfer, and the system ismultilingual in that a given constituent structure analysiscan be used for transfer and synthesis into multiple targetlanguages.
(Translation from German into Chinese andSpanish, as well as from English into German, has tran-spired on an experimental basis.
)The transfer component of METAL includes twotransformation packages, one used by transfer grammarrules and the other by transfer dictionary entries; thesecooperate during transfer, which is effected during atop-down exploration of the (highest-scoring) treeproduced in the analysis phase.
The strategy for thetop-down pass is controlled by the linguist who writes thetransfer ules.
These are most often paired 1-1 with thegrammar ules used to perform the original analysis, sothat there is no need to search through a general transfergrammar to find applicable rules (potentially allowingapplication of the wrong ones); however, the option ofemploying a more general transfer grammar is available,and is in fact used for the translation of clauses.
Asimplied above, structural and lexical transfer areperformed in the same pass, so that each may influencethe operation of the other; in particular, transfer diction-ary entries may specify the syntactic and/or semanticcontexts in which they are valid.
If no analysis isachieved for a given input, the longest phrases whichtogether span that input are selected for independenttransfer and synthesis, o that every input (a sentence, orperhaps a phrase) results in some translation.In addition to producing a translation system per se,the Texas group has developed software packages fortext processing (so as to format the output translationslike the original input documents), data base manage-ment (of dictionary entries and grammar rules), rule vali-dation (to eliminate most errors in dictionary entries andgrammar rules), dictionary construction (to enhancehuman efficiency in coding lexical entries), etc.
Asidefrom the word-processing front-end (developed by theproject sponsor), the METAL group has developed acomplete system, rather than a basic machine translationengine that leaves much drudgery for its humandevelopers/users.
Lehmann et al (1981), Bennett(1982), and Slocum (1983, 1984, 1985) present moredetails about the METAL system.GETAAs discussed earlier, the Groupe d'Etudes pour laTraduction Automatique was formed when Grenobleabandoned the CETA system.
In reaction to the failuresof the interlingua pproach, GETA adopted the transferapproach.
In addition, the former software design waslargely discarded, and a new software package supportinga new style of processing was substituted.
The core ofthe GETA translation system (ARIANE-78) is composedof three types of programs: one converts strings intotrees (for, e.g., word analysis), one converts trees intotrees (for, e.g., syntactic analysis and transfer), and thethird converts trees into strings (for, e.g., word synthe-sis).
(A fourth type exists, but may be viewed as aspecialized instance of one of the others.)
The overalltranslation process is composed of a sequence of stages,wherein each stage employs one of these programs.Other modules in ARIANE-78 support editing and systemmaintenance functions.One of the features of ARIANE-78 that sets it apartfrom other MT systems is the insistence on the part of thedesigners that no stage be more powerful than is mini-mally necessary for its proper function.
Thus, ratherthan supplying the linguist with programming tools capa-ble of performing any operation whatever (e.g., the arbi-trarily powerful Q-systems of TAUM), ARIANE-78supplies at each stage only the minimum capability neces-sary to effect the desired linguistic operation, and nomore.
This reduces the likelihood that the linguist willbecome overly ambitious and create unnecessary prob-lems, and also enabled the programmers to produce soft-ware that runs more rapidly than would be possible witha more general scheme.A "grammar" in the ROBRA subsystem is actually anetwork of subgrammars; that is, a grammar is a graphspecifying alternative sequences of applications of thesubgramrnars and optional choices of which subgrammarsare to be applied (at all).
The top-level grammar istherefore a "control graph" over the subgrammars thatactually effect the linguistic operations - analysis, trans-fer, etc.
ARIANE-78 is sufficiently general to allowimplementation f any linguistic theory, or even multipletheories at once (in separate subgrammars) if such isdesired.
Thus, in principle, it is completely open-endedand could accommodate arbitrary semantic processingand reference to "world models" of any description.In practice, however, the story is more complicated.In order to increase the computational flexibility, as isrequired to take advantage of substantially new linguistictheories, especially "world models", the underlying soft-ware would have to be changed in many various ways.Unfortunately, the underlying software is rigid (written inlow-level languages), making modification extremelydifficult.
As a result, the GETA group has been unable toexperiment with any radically new computational strate-gies.
Back-up, for example, is a known problem (Tsujii,personal communication): if the GETA system "pursues awrong path" through the control graph of subgrammars,it can undo some of its work by backing up past wholegraphs, discarding the results produced by entiresubgrammars; but within a subgrammar, there is nopossibility of backing up and reversing the effects of indi-vidual rule applications.
Until GETA receives enoughfunding that programmers can be hired to rewrite thesoftware in a high-level language (LISP/PROLOG is beingevaluated), facilitating present and future redesign, the12 Computational Linguistics, Volume 11, Number 1, January-March 1985Jonathan Slocum A Survey of Machine TranslationGETA group is "stuck" with the current software - nowshowing clear signs of age, to say nothing of non-trans-portability (to other than IBM machines).GETA seems not to have been required to produce afull-fledged application early on, and the staff was rela-tively free to pursue research interests.
Unless the GETAsoftware basis can be updated, however, it may not longremain a viable system.
(The GETA staff are activelyseeking funding for such a project.)
Meanwhile, theFrench government has launched a major applicationeffort - Projet Nationale -: to commercialize the GETAsystem, in which the implementation language is LISP(Peccoud, personal communication).SUSY: SAARBR~CKER ~BERSETZUNGSSYSTEMThe University of the Saar at Saarbrttcken, West Germa-ny, hosts one of the larger MT projects in Europe, estab-lished in the late 1960s.
After the failure of a projectintended to modify GAT for Russian-Germad trans-lation, a new system was designed along somewhat simi-lar lines to translate Russian into German after "global"sentence analysis into dependency tree structures, usingthe transfer approach.
Unlike most other MT projects,the Saarbr0cken group was left relatively free to pursueresearch interests, rather than forced to produce applica-tions, and was also funded at a level sufficient o permitsignificant on-going experimentation and modification.As a result, SUSY tended to track external developmentsin MT and AI more closely ,than other projects.
Forexample, Saarbriicken helped establish the co-operativeMT group LEIBNIZ (along with Grenoble and others) in1974.
Until 1975, SUSY was based on a strict transferapproach; since 1976, however, it has evolved, becomingmore abstract as linguistic problems mandating "deeper"analysis have forced the transfer representations toassume some of the generality of an interlingua.
Also asa result of such research freedom, there was apparentlyno sustained attempt to develop coverage for specificend-user applications.Developed as a multilingual system involving English,French, German, Russian, and Esperanto, work on SUSYhas tended to concentrate on translation into Germanfrom Russian and, recently, English.
The strongest limit-ing factor in the further development of SUSY seems tobe related to the initial inspiration behind the project:SUSY adopted a primitive approach in which the linguis-tic rules were organized into strictly independent strataand, where efficiency seemed to dictate, incorporateddirectly into the software (Maas 1984).
As a conse-quence, the rules were virtually unreadable, and theirinteractions, eventually, became almost impossible tomanage.
In terms of application potential, therefore,SUSY seems to have failed, even though it is used (withinUniversity projects) for the translation of patentdescriptions and other materials.
A second-generationproject, SUSY-II, begun in 1981, may fare better.EUROTRAEUROTRA is the largest MT project in the Westernworld.
It is the first serious attempt o produce a truemultilingual system, in this case intended for all sevenEuropean Economic Community languages.
The justi-fication for the project is simple, inescapable conomics:over a third of the entire administrative budget of theEEC for 1982 was needed to pay the translation division(average individual cost: $43,000 per year), which stillcould not keep up with the demands placed on it; techni-cal translation costs the EEC $0.20 per word for each ofsix translations (from the seventh original anguage), anddoubles the cost of the technology documented; with theaddition of Spain and Portugal, the translation staffwould have to double for the current demand level(unless highly productive machine aids were already inplace) (Perusse 1983).
The high cost of writingSYSTRAN dictionary entries is presently justifiable forreasons of speed in translation, but this situation is notviable in the long term.
The EEC must have superiorquality MT at lower cost for dictionary work.
Humantranslation alone will never suffice.EUROTRA is a true multi-national developmentproject.
There is no central aboratory where the workwill take place, but instead designated University repre-sentatives of each member country will produce the anal-ysis and synthesis modules for their native language; onlythe transfer modules will be built by a "central" group -and the transfer modules are designed to be as small aspossible, consisting of little more than lexical substitution(King 1982).
Software development will be almostentirely separated from the linguistic rule development;indeed, the production software, though designed by theEUROTRA members, will be written by whichevercommercial software house wins the contract in biddingcompetition.
Several co-ordinating committees are work-ing with the various language and emphasis groups toensure co-operation.The theoretical linguistic basis of EUROTRA is notnovel.
The basic structures for representing "meaning"are dependency trees, marked with feature-value pairspartly at the discretion of the language groups writing thegrammars (anything a group wants, it can add), and part-ly controlled by mutual agreement among the languagegroups (a certain set of feature-value combinations hasbeen agreed to constitute minimum information; all areconstrained to produce this set when analyzing sentencesin their language, and all may expect it to be presentwhen synthesizing sentences in their language) (King1981, 1982).
This is not to say that no new linguisticknowledge is being gained for, aside from the test oftheory that EUROTRA is about to perform, there is thevery substantial matter of the background contrastivelinguistic investigation that has been going on since about1978.Computational Linguistics, Volume 11, Number 1, January-March 1985 13Jonathan S|ocum A Survey of Machine TranslationIn one sense, the software basis of EUROTRA will notbe novel either.
The basic rule interpreter will be "ageneral re-write system with a control language overgrammars/processes" (King, personal communication).As with ARIANE-78, the linguistic rules can be bundledinto packets of subgrammars, and the linguists will beprovided with a means of controlling which packets ofrules are applied, and when; the individual rules will benon-destructive r -write rules, so that the application ofany given rule may create new structure, but will nevererase any old information.In another sense, however, the software basis ofEUROTRA is quite remarkably different from othersystems that have preceded it.
The analysis, transfer, andsynthesis trategies will not be incorporated into algo-rithms that the programmers implement; rather, they willbe formulated by linguists and represented in a specialcontrol anguage (not the rule-writing language, which isalgorithm-independent).
This formulation of the dynam-ic control strategies will be compiled into a program thatwill then interpret the "static" rules describing thelinguistic facts.This is a bold step.
There are, of course, pitfalls toany such action.
Aside from the usual risk of unforeseenproblems, there are two rather obvious unresolved issues.First, it remains to be seen whether linguists, trainedmostly in the static, "descriptive" framework of linguis-tics (modern or otherwise), can accommodate hemselvesto the expression of dynamic algorithms - a mode ofthinking that programmers (including almost all computa-tional linguists) are far more adept at.
Second, it alsoremains to be seen whether the system can be designedsufficiently flexibly to adjust to the wide range of exper-imental strategies that is sure to come when the staff isgiven such a large degree of freedom (remembering thatthe software implementation is seen as an essentiallyone-shot process to be performed on'contract basis),while at the same time retaining sufficient speed toensure that the computing requirements are affordable.Affordability is not merely an issue belonging to theeventual production system!
On the contrary, it is crit-ically important hat a development group be able toconduct experiments hat produce results in a reasonableamount of time.
After too long a delay, the differencebecomes one of category rather than degree, andprogress is substantially - perhaps fatally - impeded.The EUROTRA charter requires delivery of a smallrepresentative prototype system by late 1987, and aprototype covering one technical area by late 1988.
Thesystem must translate among the official languages of allmember countries that sign a "contract of association";thus, not all seven EEC languages will necessarily berepresented, but by law at least four languages must berepresented if the project is to continue.
It appears thatthe requisite number of member states have committed tojoin.
It will be interesting to see whether this, the mostambitious of all MT projects, succeeds; either way, theconsequences promise to be noteworthy.THE STATE OF THE ARTHuman languages are, by nature, different.
So much sothat the illusory goal of abstract perfection in translation- once and still imagined by some to be achievable - canbe comfortably ruled out of the realm of possible exist-ence, whether attempted by machine or man.
Even theabstract notion of "quality" is undefinable, hence immea-surable.
In its place, we must substitute the notion ofevaluation of translation according to its purpose, judgedby the consumer.
One must therefore accept the truththat the notion of quality is inherently subjective.Certainly there will be translations hailed by most if notall as "good", and correspondingly there will be trans-lations almost universally labelled "bad".
Most trans-lations, however, will surely fall in between theseextremes, and each user must render his own judgementaccording to his needs.In corporate circles, however, there is and has alwaysbeen an operational definition of "good" versus "bad"translation: a good translation is what senior translatorsare willing to expose to outside scrutiny (not that theyare fully satisfied, for they never are); and a bad one iswhat they are not willing to release.
These experiencedtranslators - usually post-editors - impose a judgementthe corporate body is willing to accept at face value: afterall, such judgement is the very purpose for having seniortranslators.
It is arrived at subjectively, based on thepurpose for which the translation is intended, but comesas close to being an objective assessment as the world islikely to see.
In a post-editing context, a "good" originaltranslation is one worth revising - i.e., one the editor willendeavor to change, rather than reject or replace with hisown original translation.Therefore, any rational position on the state of the artin MT and MAT must respect he operational decisionsabout the quality of MT and MAT as judged by the pres-ent users.
These systems are all, of course, based on oldtechnology ("ancient", by the standards of AI research-ers); but by the time systems employing today's AI tech-nology hit the market, they too will be "antiquated" bythe research laboratory standards of their time.
Such isthe nature of technology.
We therefore distinguish, inour assessment, between what is available and/or  usednow ("old", yet operationally current, technology), andwhat is around the next corner (techniques working inresearch labs today), and what is farther down the road(experimental pproaches).PRODUCTION SYSTEMSProduction M(A)T systems are based on old technology;some, for example, still (or until very recently did)employ punched cards and print(ed) out translations inall upper case.
Few if any attempt a comprehensiveglobal analysis at the sentence level (trade secrets make14 Computational Linguistics, Volume 11, Number 1, January-March 1985Jonathan Slocum A Survey of Machine Translationthis hard to discern), and none go beyond that to theparagraph level.
None use a significant amount ofsemantic information (though all claim to use some).Most if not all perform as "'idiots savants'~ making use ofenormous amounts of very unsophisticated pragmaticinformation and brute-force computation to determinethe proper word-for-word or idiom-for-idiom translationfollowed by local rearrangement of word order - leavingthe translation chaotic, even if understandable.But they work!
Some of them do, anyway - wellenough that their customers find reason to invest enor-mous amounts of time and capital developing the neces-sary massive dictionaries pecialized to their applications.Translation time is certainly reduced.
Translator frus-tration is increased or decreased, as the case may be (itseems that personality differences, among other things,have a large bearing on this).
Some translators resisttheir introduction - there are those who still resist theintroduction of typewriters, to say nothing of wordprocessors - with varying degrees of success.
But mostare thinking about accepting the place of computers intranslation, and a few actually look forward to relief frommuch of the drudgery they now face.
Current MTsystems eem to take some getting used to, and furtherproductivity increases are realized as time goes by; theyare usually accepted, eventually, as a boon to the boredtranslator.
New products embodying old technology areconstantly introduced; most are found not viable, andquickly disappear from the market.
But those that havebeen around for years must be economically justifiable totheir users - else, presumably, they would no longerexist.DEVELOPMENT SYSTEMSSystems being developed for near-term introductionemploy Computational Linguistics (CL) techniques of thelate 1970s, if not the 1980s.
Essentially all are full MT,not MAT, systems.
As Hutchins (1982) notes, " .
.
.there is now considerable agreement on the basic strate-gy, i.e.
a transfer system with some semantic analysis andsome interlingual features in order to simplify transfercomponents."
These systems employ one of a variety ofsophisticated parsing/transducing techniques, typicallybased on charts, whether the grammar is expressed viaphrase-structure rules (e.g., METAL) or (strings of) trees(e.g., GETA, EUROTRA); they operate at the sentencelevel, or higher, and make significant use of semanticfeatures.
Proper linguistic theories, whether elegant ornot quite, and heuristic software strategies take the placeof simple word substitution and brute-force program-ming.
If the analysis attempt succeeds, the translationstands a fair chance of being acceptable to the revisor; ifanalysis fails, then fail-soft measures are likely toproduce something equivalent o the output of a currentproduction MT system.These systems work well enough in experimentalsettings to give their sponsors and waiting customers (tosay nothing of their implementers) reason to hope fornear-term success in application.
Their technology isbased on some of the latest techniques that appear to beworkable in immediate large-scale application.
Most"pure AI" techniques do not fall in this category; thus,serious AI researchers look down on these developmentsystems (to say nothing of production systems) as old,uninteresting - and probably useless.
Some likely are.But others, though "old", will soon find an applicationniche, and will begin displacing any of the currentproduction systems that try to compete.
(Since the pres-ent crop of development systems all seem to be aimed atthe "information dissemination" application, the currentproduction systems aimed at the "informationacquisition" market may survive for some time.)
Themajor hurdle is time: time to write and debug the gram-mars (a very hard task), and time to develop lexiconswith roughly ten thousand general Vocabulary items, andthe few tens of thousands of technical terms required persubject area.
Some development projects have investedthe necessary time, and stand ready to deliver commer-cial applications (e.g., GETA) or have just recently doneso (e.g., METAL, under the market name LITRAS).RESEARCH SYSTEMSThe biggest problem associated with MT researchsystems is their scarcity (nonexistence, in.the U.S.).
Ifcurrent CL and AI researchers were seriously interestedin foreign languages - even if not for translation per se -this would not necessarily be a bad situation.
But in theU.S.
very few are so interested, and in Europe CL and AIresearch has not yet reached the level achieved in theU.S.
Western business and industry are more concernedwith near-term payoff, and some track developmentsystems; very few support MT development directly, andnone yet support pure MT research at a significant level.
(The Dutch firm Philips may, indeed, have the only long-term research project in the West.)
Some Europeangovernments fund significant R&D projects (e.g., Germa-ny and France), but Japan is making by far the world'slargest investment in MT research.
The U:S. government,which otherwise supports the best overall AI and(English) CL research in the world, is not involved.Where pure MT research projects do exist, they tendto concentrate on the problems of deep meaning repre-sentations - striving to pursue the goal of a true AIsystem, which would presumably include language-inde-pendent meaning representations of great depth andcomplexity.
Translation here is seen as just one applica-tion o fsuch  a system: the system "understands" naturallanguage input, then "generates" natural languageoutput; if the languages happen to be different, thentranslation has been performed via paraphrase.
Trans-lation could thus be viewed as one of the ultimate tests ofan Artificial Intelligence: if a system "translatescorrectly", then to some extent it can be argued to have"understood correctly", and in any case will tell us muchComputational Linguistics, Volume 11, Number 1, January-March 1985 15Jonathan Slocum A Survey of Machine Translationabout what translation is all about.
In this role, MTresearch holds out its greatest promise as a once-againscientifically respectable discipline.
The first require-ment, however, is the existence of research groups inter-ested in, and funded for, the study of multiple languagesand.translatiort among them within the framework of AIresearch.
At the present ime only Japan, and to a some-what lesser extent western Europe, can boast suchgroups.FUTURE PROSPECTSThe world has changed in the two decades ince ALPAC.The need and demand for technical translation hasincreased ramatically, and the supply of qualified humantechnical translators has not kept pace.
(Indeed, it isdebatable whether there existed a sufficient supply ofqualified technical translators even in 1966, contrary toALPAC's claims.)
The classic "law of supply anddemand" has not worked in this instance, for whateverreasons: the shortage is real, all over the world; nothingis yet serving to stem this worsening situation; and noth-ing seems capable of doing so outside of dramaticproductivity increases via computer automation.
In theEEC, for example, the already overwhelming need fortechnical translation is projected to rise sixfold withinfive years.The future promises greater acceptance by translatorsof the role of machine aids - running the gamut fromword processing systems and on-line term banks to MTsystems - in technical translation.
Correspondingly,M(A)T systems will experience greater success in themarketplace.
As these systems continue to drive downthe cost of translation, the demand and capacity fortranslation will grow even more than it would otherwise:many "new" needs for translation, not presentlyeconomically justifiable, will surface.
If MT systems areto continue to improve so as to further reduce the burdenon human translators, there will be a greater need anddemand for continuing MT R&D efforts.CONCLUSIONSThe translation problem will not go away, and humansolutions (short of full automation) do not now, andnever will, suffice.
MT systems have already scoredsuccesses among the user community, and the trend canhardly fail to continue as users demand further improve-ments and greater speed, and MT system vendorsrespond.
The half-million pages of text translated bymachine in 1984 is but a drop in the bucket of translationdemand.
Of course, the need for research is great, butsome current and future applications will continue tosucceed on economic grounds alone - and to the usercommunity, this is virtually the only measure of successor failure.It is important o note that translation systems are notgoing to "fall out" of AI efforts not seriously contendingwith multiple languages from the start.
There are tworeasons for this.
First, English is not a representativelanguage.
Relatively speaking, it is not even a very hardlanguage from the standpoint of Computational Linguis-tics: Japanese, Chinese, Russian, and even German, forexample, seem more difficult to deal with using existingCL techniques - surely in part due to the nearly totalconcentration of CL workers on English, and their conse-quent development of tools specifically for English (and,accidentally, for English-like languages).
Developingtranslation ability will require similar concentration byCL workers on other languages; nothing less will suffice.Second, it would seem that translation is not by anymeans a simple matter of understanding the source text,then reproducing it in the target language - even thoughmany translators (and virtually every layman) will saythis is so.
On the one hand, there is the serious questionof whether, in for example the case of an article on front-line research in semiconductor switching theory, or parti-cle physics, a translator eally does "fully comprehend"the content of the article he is translating.
One wouldsuspect not.
(Johnson (1983) makes a point of claimingthat he has produced translations, judged good byinformed peers, in technical areas where his expertise isdeficient, and his understanding, incomplete.)
On theother hand, it is also true that translation schools expendconsiderable ffort teaching techniques for low-level exi-cal and syntactic manipulation - a curious fact tocontrast with the usual "full comprehension" claim.
Inany event, every qualified translator will agree that thereis much more to translation than simpleanalysis/synthesis (an almost prime facie proof of thenecessity for Transfer).What this means is that the development of translationas an application of Computational Linguistics willrequire substantial research in its own right in addition tothe work necessary in order to provide the basic multilin-gual analysis and synthesis tools.
Translators must beconsulted, for they are the experts in translation.
Noneof this will happen by accident; it must result fromdesign.REFERENCESAAT 1984 Fujitsu has 2-way Translator System.
AAT Report 66.Advanced American Technology, Inc., Los Angeles: 8.AAT 1984 Hitachi Develops English-to-Japanese TranslatingMachine.
AAT Report 66.
Advanced American TechnoFogy, Inc.,Los Angeles: 8.Amano, S. 1982 Machine Translation Project at Toshiba Corporation.Technical note.
R&D Center, Information Systems Laboratory,Toshiba Corporation, Kawasaki, Japan.Bar-Hillel, Y.
1971 Some Reflections on the Present Outlook forHigh-Quality Machine Translation.
In Lehman, W.P.
and Stachow-itz, R., Eds., Feasibility Study on Fully Automatic High QualityTranslation.
Final technical report RADC-TR-71-295.
LinguisticsResearch Center, University of Texas at Austin.Bennett, W.S.
1982 The Linguistic Component ofMETAL.
Workingpaper LRC-82-2.
Linguistics Research Center, University of Texasat Austin.Bostad, D.A.
1982 Quality Control Procedures in Modification of theAir Force Russian-English MT System.
In Lawson 1982: 129-133.16 Computational Linguistics, Volume I 1, Number 1, January-March 1985Jonathan Slocum A Survey of Machine TranslationBruderer, H.E.
1977 The Present State of Machine and Machine-As-sisted Translation.
Commission of the European Communities, ThirdEuropean Congress on Information Systems and Networks: Overcom-ing the Language Barrier.
vol.
1.
Verlag Dokumentation, Munich:529-556.Gervais, A.
1980 et DG de la Planification, de l'Evaluation et de laVerification.
Rapport final d'evaluation du systeme pilote detraduction automatique TAUM-AVIATION.
Secretariat d'Etat,Canada.Hundt, M.G.
1982 Working with the Weidner Machine-Aided Trans-lation System.
In Lawson 1982: 45-51.Hutchins, W.J.
1978 Progress in Documentation: Machine Translationand Machine-Aided Translation.
Journal of Documentation 34(2):119-159.Hutchins, W.J.
1981 The Evolution of Machine Translation Systems.In Lawson 1982: 21-37.Johnson, R.L.
1983 Parsing- an MT Perspective.
In Jones, K.S.
andWilks, Y., Eds., Automatic Natural Language Parsing.
Ellis Horwood,Ltd., Chichester, Great Britain.Jordan, S.R.
; Brown, A.F.R.
; and Hutton, F.C.
1976 ComputerizedRussian Translation at ORNL.
Proceedings of the ASIS AnnualMeeting, San Francisco: 163.
Also 1977 in ASIS Journal 28(1):26-33.King, M. 1981 Design Characteristics of a Machine TranslationSystem.
Proceedings of the Seventh IJCAL Vol.
1, Vancouver, B.C.,Canada: 43-46.King, M. 1982 EUROTRA: An Attempt o Achieve Multilingual MT.In Lawson 1982: 139-147.Lawson V. 1982 Practical Experience of Machine Translation.
North-Holland, Amsterdam.Lehmann, W.P.
; Bennet, W.S.
; Slocum J.; Smith, H.; Fluger, S.M.V.
;and Eveland, S.A. 1981 The Metal System.
Final technical repor tRADC-TR-80-374.
Linguistics Research Center, University ofTexas at Austin.
NTIS report AO-97896.Loh, S.-C. 1976 Machine Translation: Past, Present, and Future.ALLC Bulletin 4(2): 105-114.Lob, S.-C.; Kong, L.; and Hung, H.-S. 1978 Machine Translation ofChinese Mathematical Articles.
ALLC Bulletin 6(2): 111-120.Loh, S.-C. and Kong, L. 1979 An Interactive On-Line MachineTranslation System (Chinese into English).
In Snell, B.M., Ed.,Translating and the Computer.
North-Holland, Amsterdam: 135-148.Lytle, E.G.
; Packard, D.; Gibb, D; Melby, A.K.
; and Billings, F.H.1975 Junction Grammar as a Base for Natural Language Processing.AJCL 3 (microfiche 26): 1-77.Maas, H.-D. 1984 The MT System SUSY.
Presented at the ISSCOTutorial on Machine Translation, Lugano, Switzerland.Melby, A.K.
1982 Multi-level Translation Aids in a DistributedSystem.
Proceedings of the Ninth ICCL (COLING 82), Prague,Czechoslovakia: 215-220.Moto-oka, T. 1982 Challenge for Knowledge Information ProcessingSystems (Preliminary Report on Fifth Generation ComputerSystems).
In Moto-oka, T., Ed., Fifth Generation Computer Systems(Proceedings of the International Conference on Fifth-GenerationComputer Systems, Tokyo).
North Holland, Amsterdam.Muraki, K. and Ichiyama, S. 1982 An Overview of Machine Trans-lation Project at NEC Corporation.
Technical note.
C & C SystemsResearch Laboratories, NEC Corporation,Nagao, M.; Tsujii, J.; Mitamura, K.; Hirakawa, H.; and Kume, M.1980 A Machine Translation System from Japanese into English:Another Perspective of MT Systems.
Proceedings of the EighthICCL (COLING 80), Tokyo: 414-423.Nagao, M. et al 1981 On English Generation for a Japanese-EnglishTranslation System.
Technical Report on Natural Language Proc-essing 25.
Information Processing of Japan.Nagao, M.; Tsujii, J.; Yada, K.; and Kakimoto, T. 1982 An EnglishJapanese Machine Translation System of the Titles of Scientific andEngineering Papers.
Proceedings of the Ninth ICCL (COLING 82),Prague, Czechoslovakia: 245-252.Nagao, M. 1984,1985 personal communication.Nishida, F. and Takamatsu, S. 1982 Japanese-English TranslationThrough Internal Expressions.
Proceedings of the Ninth ICCL(COLING 82), Prague, Czechoslovakia: 271-276.Nishida, T. and Doshita, S. 1982 An English-Japanese MachineTranslation System Based on Formal Semantics of NaturalLanguage.
Proceedings of the Ninth 1CCL (COLING 82), Prague,Czechoslovakia: 277-282.Nishida, T. and Doshita, S. 1983 An Application of Montague Gram-mar to English-Japanese Machine Translation.
Proceedings of theACL-NRL Conference on Applied Natural Language Processing, SantaMonica, California: 156-165.Nomura, H. and Shimazu, A.
1982 Machine Translation in Japan.Technical note.
Musashino Electrical Communication Laboratory,Nippon Telegraph and Telephone Public Corporation, Tokyo.Nomura, H.; Shimazu, A.; lida, H.; Katagiri, Y.; Saito, Y.; Naito, S.;Ogura, K.; Yokoo, A.; and Mikami, M. 1982 Introduction to LUTE(Language Understander, Translator & Editor).
Technical note.Musashino Electrical Communication Laboratory, Research Divi-sion, Nippon Telegraph and Telephone Public Corporation, Tokyo.Peccoud, F. 1985 Personal communication.Perusse, D. 1985 Machine Translation.
ATA Chronicle 12(8): 6-8.Philippi, D.L.
1985 Machine Translation in Japan - a Survey.
JapanIntelligence 1(4).Pigott, I.M.
1979 Theoretical Options and Practical Limitations ofUsing Semantics to Solve Problems of Natural Language Analysisand Machine Translation.
In MacCafferty, M. and Gray, K., Eds.The Analysis of Meaning: lnformatics 5.
ASLIB, London: 239-268.Pigott, I.M.
1982 The Importance of Feedback from Translators in theDevelopment of High-Quality Machine Translation.
In Lawson1982: 61-73.Ruffino, J.R. 1982 Coping with Machine Translation.
In Lawson1982: 57-60.Sawai, S.; Fukushima, H.; Sugimoto, M.; and Ukai, N. 1982 Know-ledge Representation a d Machine Translation.
Proceedings of theNinth ICCL (COLING 82), Prague, Czechoslovakia: 351-356.Scott, B.E.
1984 Personal communication.Sereda, S.P.
1982 Practical Experience of Machine Translation.
InLawson 1982:119-123.Shudo, K. 1974 On Machine Translation from Japanese into Englishfor a Technical Field.
Information Processing in Japan 14: 44-50.Sinaiko, H.W.
and Klare, G.R.
1973 Further Experiments in LanguageTranslation: A Second Evaluation of the Readability of ComputerTranslations.
ITL 19: 29-52.Slocum, J.
1983 A Status Report on the LRC Machine TranslationSystem.
Proceedings of the ACL-NRL Conference on Applied NaturalLanguage Processing, Santa Moniea, California: 166-173.Sloeum, J.
1984 Metal: The LRC Machine Translation System.Presented at ISSCO Tutorial on Machine Translation, Lugano, Swit-zerland.Sloeum, J.; Bennett, W.S.
; Whiffin, L.; and Norcross, E. 1985 AnEvaluation of METAL: the LRC Machine Translation System.Presented at the Second Annual Conference of the European Chap-ter of the Association for Computational Linguistics, University ofGeneva, Switzerland.Thouin, B.
1982 The METEO System.
In Lawson 1982: 39-44.Tsujii, J.
1982 The Transfer Phase in an English- Japanese TranslationSystem.
Proceedings of the Ninth ICCL (COLING 82), Prague,Czechoslovakia: 383-390.Van Slype, G. 1979 Evaluation du systeme de traduction automatiqueSYSTRAN anglais-francais, version 1978, de la Commission descommunautes Europeennes.
Babel 25(3): 157-162.Van Slype, G. 1982 Economic Aspects of Machine Translation.
InLawson 1982: 79-93.Vasconeellos, M. 1983 Management of the Machine Translation Envi-ronment.
Proceedings of the ASLIB Conference on Translating andthe Computer, London.Vasconcellos, M. 1985 Personal communication.Wheeler, P. 1983 The Errant Avocado (Approaches to Ambiguity inSYSTRAN Translation).
Newsletter 13, Natural Language Trans-lations Specialist Group, BCS.Wilks, Y. and LATSEC, Inc, 1978 Comparative Translation QualityAnalysis.
Final report on contract F-33657-77-C-0695.Computational Linguistics, Volume 11, Number 1, January-March 1985 17
