Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1453?1458,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsFinancial Keyword Expansion viaContinuous Word Vector RepresentationsMing-Feng TsaiDepartment of Computer Science &Program in Digital Content and TechnologyNational Chengchi UniversityTaipei 116, Taiwanmftsai@nccu.edu.twChuan-Ju WangDepartment of Computer ScienceUniversity of TaipeiTaipei 100, Taiwancjwang@utaipei.edu.twAbstractThis paper proposes to apply the contin-uous vector representations of words fordiscovering keywords from a financial sen-timent lexicon.
In order to capture morekeywords, we also incorporate syntacticinformation into the Continuous Bag-of-Words (CBOW) model.
Experimental re-sults on a task of financial risk predictionusing the discovered keywords demonstratethat the proposed approach is good at pre-dicting financial risk.1 IntroductionIn the present environment with a great deal ofinformation, how to discover useful insights fordecision making is becoming increasingly impor-tant.
In finance, there are typically two kinds ofinformation (Petersen, 2004): soft information usu-ally refers to text, including opinions, ideas, andmarket commentary, whereas hard information isrecorded as numbers, such as financial measuresand historical prices.
Most financial studies relatedto risk analysis are based on hard information, es-pecially on time series modeling (Christoffersenand Diebold, 2000; Lee and Tong, 2011; Wu et al.,2014; Y?uml?u et al., 2005).
Despite of using onlyhard information, some literature incorporates softtextual information to predict financial risk (Ko-gan et al., 2009; Leidner and Schilder, 2010; Tsaiand Wang, 2013).
Moreover, sentiment analysis, atechnique to make an assessment of the sentimentsexpressed in various information, has also beenapplied to analyze the soft textual information infinancial news, reports, and social media data (De-vitt and Ahmad, 2007; Loughran and McDonald,2011; Wang et al., 2013).Continuous vector space models (Bengio etal., 2003; Schwenk, 2007; Mikolov et al., 2010)are neural network language models, in whichwords are represented as high dimensional real val-ued vectors.
These representations have recentlydemonstrated promising results across variety oftasks (Schwenk, 2007; Collobert and Weston, 2008;Glorot et al., 2011; Socher et al., 2011; Weston etal., 2011), because of their superiority of capturingsyntactic and semantic regularities in language.
Inthis paper, we apply the Continuous Bag-of-Words(CBOW) model (Mikolov et al., 2013) on the softtextual information in financial reports for discov-ering keywords via financial sentiments.
In spe-cific, we use the continuous vector representationsof words to find out similar terms based on theircontexts.
Additionally, we propose a straightfor-ward approach to incorporate syntactic informationinto the CBOW model for better locating similarlymeaningful or highly correlated words.
To the bestof our knowledge, this is the first work to incorpo-rate more syntactic information by adding Part-Of-Speech (POS) tags to the words before training theCBOW model.In our experiments, the corpora are the annualSEC1-mandated financial reports, and there are3,911 financial sentiment keywords for expansion.In order to verify the effectiveness of the expandedkeywords, we then conduct two prediction tasks,including regression and ranking.
Observed fromour experimental results, for the regression andranking tasks, the models trained on the expandedkeywords are consistently better than those trainedthe original sentiment keywords only.
In addition,for comparison, we conduct experiments with ran-dom keyword expansion as baselines.
Accordingto the experimental results, the expansion eitherwith or without syntactic information outperformsthe baselines.
The results suggest that the CBOWmodel is effective at expanding keywords for finan-cial risk prediction.1Securities and Exchange Commission14532 Keyword Expansion via FinancialSentiment Lexicon2.1 Financial Sentiment LexiconA sentiment lexicon is the most important resourcefor sentiment analysis.
Loughran and McDon-ald (2011) states that a general purpose sentimentlexicon (e.g., the Harvard Psychosociological Dic-tionary) might misclassify common words in fi-nancial texts.
Therefore, in this paper, we use afinance-specific lexicon that consists of the 6 wordlists provided by (Loughran and McDonald, 2011)as seeds to expand keywords.
The six lists are nega-tive (Fin-Neg), positive (Fin-Pos), uncertainty (Fin-Unc), litigious (Fin-Lit), strong modal words (MW-Strong), and weak modal words (MW-Weak).22.2 Simple Keyword ExpansionWith the financial sentiment lexicon, we first use acollection of financial reports as the training textsto learn continuous vector representations of words.Then, each word in the sentiment lexicon is used asa seed to obtain the words with the highest n cosinedistances (called the top-n words for the word) viathe learned word vector representations.
Finally,we construct an expanded keyword list from thetop-n words for each word.2.3 Keyword Expansion with SyntacticInformationFor the expansion considering syntactic informa-tion, we attach the POS tag to each word in thetraining texts first.
Then, the words in the senti-ment lexicon with 4 major POS tags (i.e., JJ, NN,VB, RB) are used as seeds to expand.
The rest ofsteps is similar to that in Section 2.2.The reason of considering POS tags for expan-sion is that, in general, a word with different POStags may result in different lists of top-n words.
Ta-ble 1 shows the top-5 words for the word ?default?with different POS tags (noun and adjective).
Notethat none of the words in the two lists overlaps.3 Financial Risk Prediction3.1 The Risk Measure: VolatilityVolatility is a measure for variation of prices of astock over a period of time.
Let Stbe the priceof a stock at time t. Holding the stock from timet?
1 to time t would lead to a simple return: Rt=2http://www.nd.edu/?mcdonald/Word_Lists.html.default (NN) default (JJ)Cosine CosineWord Distance Word Distancedefault (v.) 0.63665 nonconform (v.) 0.63462unwaiv (v.) 0.63466 subprim (v.) 0.62404uncur (v.) 0.62285 chattel (n.) 0.61510trigger (n.) 0.60080 foreclos (adj.)
0.61397unmatur (v.) 0.58208 unguarante (v.) 0.60559Table 1: Top-5 Words for the word ?default.?St/St?1?
1 (Tsay, 2005).
The volatility of returnsfor a stock from time t?
n to t can thus be definedas follows:v[t?n,t]=??ti=t?n(Ri?
?R)2n, (1)where?R =?ti=t?nRi/(n + 1).3.2 Regression TaskGiven a collection of financial reports D ={d1,d2, .
.
.
,dn}, in which each di?
Rpand isassociated with a company ci, we aim to predict thefuture risk of each company ci(which is character-ized by its volatility vi).
This prediction problemcan be defined as follows:v?i= f(di;w).
(2)The goal is to learn a p-dimensional vector w fromthe training data T = {(di, vi)|di?
Rp, vi?
R}.In this paper, we adopt the Support Vector Regres-sion (SVR) (Drucker et al., 1997) for training sucha regression model.
More details about SVR canbe found in (Sch?olkopf and Smola, 2001).3.3 Ranking TaskInstead of predicting the volatility of each companyin the regression task, the ranking task aims to rankcompanies according to their risk via the textualinformation in their financial reports.
We first splitthe volatilities of company stock returns within ayear into different risk levels by the mechanismprovided in (Tsai and Wang, 2013).
The risk levelscan be considered as the relative difference of riskamong the companies.After obtaining the relative risk levels of thecompanies, the ranking task can be defined as fol-lows: Given a collection of financial reports D,we aim to rank the companies via a ranking modelf : Rp?
R such that the rank order of the set ofcompanies is specified by the real value that the1454model f takes.
Specifically, f(di) > f(dj) meansthat the model asserts that cicj, where cicjmeans that ciis ranked higher than cj; that is, thecompany ciis more risky than cj.
For this task, thispaper adopts Ranking SVM (Joachims, 2006).4 Experiments4.1 Dataset and PreprocessingsIn the experiments, we use the 10-K corpus (Ko-gan et al., 2009) to conduct our financial risk pre-diction tasks.
All documents and the 6 financialsentiment word lists are stemmed by the Porterstemmer (Porter, 1980), and some stop words arealso removed.For financial risk prediction, the ground truth,the twelve months after the report volatility foreach company, v+(12), (which measures the futurerisk for each company) can be calculated by Equa-tion (1), where the stock prices can be obtainedfrom the Center for Research in Security Prices(CRSP) US Stocks Database.
In addition, to ob-tain the relative risks among companies used in theranking task, we follow (Tsai and Wang, 2013) tosplit the companies of each year into 5 risk levels.4.2 Keyword ExpansionIn our experiments, Section 7 (Management Dis-cussion and Analysis) in 10-K corpus is used astraining texts for the tool (word2vec3) to learn thecontinuous vector representations of words.For the simple expansion (denoted as EXP-SIMhereafter), we use the total 1,667 stemmed senti-ment words as seeds to obtain the expanded key-words via the learned word vector representations.For the expansion considering syntactic informa-tion (denoted as EXP-SYN), NLTK4is applied toattach the POS tag5to each word in the trainingtexts; we attach the POS tag to a word with an un-derscore notation (e.g., default VB).
For simplicity,we combine some POS tags to one tag via the tagreplacement; for example, the tags JJR (adjective,comparative) and JJS (adjective, superlative) arereplaced to JJ (adjective).
The detailed replace-ment rules are tabulated in Table 2.
Words fromthe sentiment lexicon with the four types of POStags (i.e., JJ, NN, VB, RB) are consider as the seedsto expand the keywords.
For both EXP-SIM and3https://code.google.com/p/word2vec/4http://www.nltk.org/5The most common POS tag scheme, the Penn TreebankPOS Tags, is adopt in the paper.After Replacement Before ReplacementJJ JJ, JJR, JJSNN NN, NNS, NNP, NNPSPRP PRP, PRP$RB RB, RBR, RBSVB VB, VBD, VBG, VBN, VBP, VBZWP WP, WP$Table 2: Tag Replacement Rules.Word Cosine Distance Word Cosine Distanceuncur 0.569498 event 0.466834indentur 0.565450 lender 0.459995waiv 0.563656 forbear 0.456556trigger 0.559936 represent 0.450631cure 0.539999 breach 0.446851nonpay 0.538445 noncompli 0.431490unmatur 0.525251 gecc 0.430712unwaiv 0.510359 customari 0.424447insolv 0.488534 waiver 0.419338occurr 0.471123 prepay 0.418969Table 3: Top-20 (Stemmed) Words for the Word?default.
?EXP-SYN, we use the top-20 expanded words foreach word (e.g., Table 3) to construct expanded key-word lists.
In total, for EXP-SIM, the expandedlist contains 9,282 unique words and for EXP-SYN,the list has 13,534 unique words.4.3 Word FeaturesIn the experiments, the bag-of-words model isadopted and three word features are used to repre-sent the 10-K reports in the experiments.
Given adocument d, three word features (i.e., TF, TFIDFand LOG1P) are calculated as follows:?
TF(t,d) = TC(t,d)/|d|,?
TFIDF(t,d) = TF(t,d) ?
IDF(t,d) =TC(t,d)/|d| ?
log(|D|/|d ?
D : t ?
d|),?
LOG1P = log(1 + TC(t,d)),where TC(t,d) denotes the term count of t in d,|d| is the length of document d, and D denotes theset of all documents in each year.4.4 Experimental ResultsTables 4 and 5 tabulate the experimental results ofregression and ranking, respectively, in which thetraining data is composed of the financial reportsin a five-year period, and the following year is thetest data.
For example, the reports from year 1996to 2000 constitute a training data, and the learnedmodel is tested on the reports of year 2001.1455[TFIDF] (Baseline) (Baseline)Year SEN EXP-RAN EXP-SIM EXP-SYN SEN EXP-RAN EXP-SIM EXP-SYNKendall?s Tau (Kendall, 1938).
Spearman?s Rho (Myers et al., 2003)2001 0.4384 0.4574 0.4952 0.5049 0.4701 0.4889 0.5266 0.53752002 0.4421 0.4706 0.4881 0.4944 0.4719 0.5007 0.5187 0.52562003 0.4414 0.4706 0.5105 0.5006 0.4716 0.5015 0.5418 0.53182004 0.4051 0.4551 0.4750 0.4961 0.4335 0.4842 0.5043 0.52552005 0.3856 0.4482 0.5126 0.5294 0.4117 0.4757 0.5418 0.55792006 0.3784 0.4385 0.4588 0.4867 0.4029 0.4641 0.4847 0.5129Table 5: Performance of Ranking.
[LOGP] (Baseline)Year SEN EXP-RAN EXP-SIM EXP-SYNMean Squared Error2001 0.2526 0.2360 0.2195 0.21482002 0.2858 0.2649 0.2433 0.23812003 0.2667 0.2512 0.2320 0.23502004 0.2345 0.2140 0.1902 0.18722005 0.2241 0.2014 0.1754 0.16822006 0.2256 0.2072 0.1889 0.1825Table 4: Performance of RegressionIn the tables, SEN denotes the experimentstrained on the words from the original financial sen-timent lexicon.
Despite of the experiments trainedon EXP-SIM and EXP-SYN, we also conduct ex-periments with random keyword expansion (calledEXP-RAN); for the comparison purpose, we keepthe number of words in the randomly expandedword list the same as that in EXP-SYN.
Note thatthe randomly expanded list contains all sentimentwords and the rest of words are randomly chosenfrom the vocabulary of the dataset.
The columnswith label EXP-RAN denote the results averagedfrom 20 randomly expanded word lists.
The boldface numbers denote the best performance amongthe four word lists.As shown in Tables 4 and 5, for both regressionand ranking tasks, the models trained on expandedkeywords (i.e., EXP-*) are consistently better thanthose trained on the original sentiment keywordsonly.6Additionally, we treat the experiments withrandomly expanded word list (EXP-RAN) as thebaselines.7From the two tables, we observe thatthe expansion either with or without syntactic in-formation outperforms the baselines.
Note that, forthe EXP-SIM, the number of words used for train-6Due to the page limits, only the results trained on featuresLOGP for regression and TFIDF for ranking are reported, butthe performance for models trained on features TF, TFIFG,and LOGP is very consistent.7The results for EXP-SYN are all significant better thanthe baseline with p < 0.05.ing the regression and ranking models is even lessthan that of EXP-RAN.
The results suggest that theCBOW model is effective at expanding keywordsfor financial risk prediction.
Furthermore, incorpo-rating syntactic information into the CBOW modelcan even enhance the performance for the tasks offinancial risk prediction.4.5 DiscussionsBelow we provide the original texts from 10-K re-ports that contain the top 1 expanded word, ?uncur?
(stemmed), for ?default?
in Table 3.
Two piecesof sentences are listed as follows (the companyInvestment Technology Group, 1997):?
?
?
terminate the agreement upon cer-tain events of bankruptcy or insolvencyor upon an uncured breach by the Com-pany of certain covenants ?
?
??
?
?
any termination of the license agree-ment resulting from an uncured defaultwould have a material adverse effect onthe Company?s results of operations.From the above examples, the expanded word ?un-cur?
has similar meaning to ?default,?
which con-firms the capability of our method of capturingsimilarly meaningful or highly correlated words.5 ConclusionsThis paper applies the continuous bag-of-wordsmodel on the textual information in financial re-ports for expanding keywords from a financial sen-timent lexicon.
Additionally, we propose a simplebut novel approach to incorporate syntactic infor-mation into the continuous bag-of-words model forcapturing more similarly meaningful or highly cor-related keywords.
The experimental results for therisk prediction problem show that the expansioneither with or without syntactic information out-performs the baselines.
As a direction for further1456research, it is interesting and important to providemore analysis on the expanded words via the con-tinuous vector representations of words.AcknowledgmentsThis research was partially supported by the Na-tional Science Council of Taiwan under the grantsNSC 102-2420-H-004-052-MY2, 102-2221-E-004-006, and 102-2221-E-845-002-MY3.ReferencesYoshua Bengio, R?ejean Ducharme, Pascal Vincent, andChristian Janvin.
2003.
A neural probabilistic lan-guage model.
Journal of Machine Learning Re-search, 3:1137?1155.Peter F Christoffersen and Francis X Diebold.
2000.How relevant is volatility forecasting for financialrisk management?
Review of Economics and Statis-tics, 82(1):12?22.Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: Deepneural networks with multitask learning.
In Pro-ceedings of the 25th international conference on Ma-chine learning, IMCL ?08, pages 160?167.Ann Devitt and Khurshid Ahmad.
2007.
Sentimentpolarity identification in financial news: A cohesion-based approach.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Lin-guistics, ACL ?07, pages 984?991.Harris Drucker, Chris JC Burges, Linda Kaufman, AlexSmola, and Vladimir Vapnik.
1997.
Support vectorregression machines.
Advances in Neural Informa-tion Processing Systems, 9:155?161.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Domain adaptation for large-scale sentimentclassification: A deep learning approach.
In Pro-ceedings of the 28th International Conference onMachine Learning, ICML ?11, pages 513?520.Thorsten Joachims.
2006.
Training linear svms in lin-ear time.
In Proceedings of the 12th ACM SIGKDDinternational conference on Knowledge discoveryand data mining, KDD ?06, pages 217?226.Maurice G Kendall.
1938.
A new measure of rankcorrelation.
Biometrika, 30:81?93.Shimon Kogan, Dimitry Levin, Bryan R Routledge,Jacob S Sagi, and Noah A Smith.
2009.
Pre-dicting risk from financial reports with regression.In Proceedings of Human Language Technologies:The 2009 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, NAACL ?09, pages 272?280.Yi-Shian Lee and Lee-Ing Tong.
2011.
Forecastingtime series using a methodology based on autore-gressive integrated moving average and genetic pro-gramming.
Knowledge-Based Systems, 24(1):66?72.Jochen L. Leidner and Frank Schilder.
2010.
Huntingfor the black swan: risk mining from text.
In Pro-ceedings of the ACL 2010 System Demonstrations,ACLDemos ?10, pages 54?59.Tim Loughran and Bill McDonald.
2011.
When is aliability not a liability?
textual analysis, dictionaries,and 10-ks.
The Journal of Finance, 66(1):35?65.Tomas Mikolov, Martin Karafi?at, Lukas Burget, JanCernock`y, and Sanjeev Khudanpur.
2010.
Recur-rent neural network based language model.
In Pro-ceedings of Interspeech, pages 1045?1048.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013.
Efficient estimation of word represen-tations in vector space.
CoRR, abs/1301.3781.Jerome L Myers, Arnold D Well, and Robert F Lorch Jr.2003.
Research design and statistical analysis.Routledge.Mitchell A Petersen.
2004.
Information: Hard and soft.Technical report, Northwestern University.Martin F Porter.
1980.
An algorithm for suffix strip-ping.
Program: electronic library and informationsystems, 14(3):130?137.Bernhard Sch?olkopf and Alexander J Smola.
2001.Learning with kernels: Support vector machines,regularization, optimization, and beyond.
MITpress.Holger Schwenk.
2007.
Continuous space languagemodels.
Computer Speech & Language, 21(3):492?518.Richard Socher, Cliff C Lin, Chris Manning, and An-drew Y Ng.
2011.
Parsing natural scenes and nat-ural language with recursive neural networks.
InProceedings of the 28th International Conference onMachine Learning, ICML ?11, pages 129?136.Ming-Feng Tsai and Chuan-Ju Wang.
2013.
Risk rank-ing from financial reports.
In Advances in Informa-tion Retrieval, pages 804?807.
Springer.Ruey S Tsay.
2005.
Analysis of financial time series.Wiley.Chuan-Ju Wang, Ming-Feng Tsai, Tse Liu, and Chin-Ting Chang.
2013.
Financial sentiment analysis forrisk prediction.
In Proceedings of the Sixth Interna-tional Joint Conference on Natural Language Pro-cessing, IJCNLP ?13, pages 802?808.Jason Weston, Samy Bengio, and Nicolas Usunier.2011.
Wsabie: Scaling up to large vocabularyimage annotation.
In Proceedings of the Twenty-Second international joint conference on Artificial1457Intelligence-Volume Volume Three, pages 2764?2770.Desheng Dash Wu, Shu-Heng Chen, and David L Ol-son.
2014. Business intelligence in risk manage-ment: Some recent progresses.
Information Sci-ences, 256:1?7.Serdar Y?uml?u, Fikret S G?urgen, and Nesrin Okay.2005.
A comparison of global, recurrent andsmoothed-piecewise neural models for istanbulstock exchange (ise) prediction.
Pattern Recogni-tion Letters, 26(13):2093?2103.1458
