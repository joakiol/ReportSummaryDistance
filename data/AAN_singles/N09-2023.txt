Proceedings of NAACL HLT 2009: Short Papers, pages 89?92,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsAutomatic Agenda Graph Construction from Human-Human Dialogsusing Clustering MethodCheongjae Lee, Sangkeun Jung, Kyungduk Kim, Gary Geunbae LeeDepartment of Computer Science and EngineeringPohang University of Science and TechnologyPohang, South Korea{lcj80,hugman,getta,gblee}@postech.ac.krAbstractVarious knowledge sources are used for spo-ken dialog systems such as task model, do-main model, and agenda.
An agenda graph isone of the knowledge sources for a dialogmanagement to reflect a discourse structure.This paper proposes a clustering and linkingmethod to automatically construct an agendagraph from human-human dialogs.
Prelimi-nary evaluation shows our approach would behelpful to reduce human efforts in designingprior knowledge.1 IntroductionData-driven approaches have been long applied for spo-ken language technologies.
Although a data-driven ap-proach requires time-consuming data annotation, thetraining is done automatically and requires little humansupervision.
These advantages have motivated the de-velopment of data-driven dialog modelings (Williamsand Young, 2007, Lee et al, 2009).
In general, the data-driven approaches are more robust and portable thantraditional knowledge-based approaches.
However, var-ious knowledge sources are still used in many spokendialog systems that have been developed recently.
Theseknowledge sources contain task model, domain model,and agenda which are powerful representation to reflectthe hierarchy of natural dialog control.
In the spokendialog systems, these are manually designed for variouspurposes including dialog modeling (Bohus and Rud-nicky, 2003, Lee et al, 2008), search space reduction(Young et al, 2007), domain knowledge (Roy and Sub-ramaniam, 2006), and user simulation (Schatzmann etal., 2007).We have proposed an example-based dialog modeling(EBDM) framework using an agenda graph as priorknowledge (Lee et al, 2008).
This is one of the data-driven dialog modeling techniques and the next systemaction is determined by selecting the most similar dialogexamples in dialog example database.
In the EBDMframework for task-oriented dialogs, agenda graph ismanually designed to address two aspects of a dialogmanagement: (1) Keeping track of the dialog state witha view to ensuring steady progress towards task comple-tion, and (2) Supporting n-best recognition hypothesesto improve the robustness of dialog manager.
However,manually building such graphs for various applicationsmay be labor intensive and time consuming.
Thus, wehave tried to investigate how to build this graph auto-matically.
Consequently, we sought to solve the prob-lem by automatically building the agenda graph usingclustering method from an annotated dialog corpus.2 Related WorkClustering techniques have been widely used to buildprior knowledge for spoken dialog systems.
One ofthem is automatic construction of domain model (ortopic structure) which is one of the important resourcesto handle user?s queries in call centers.
Traditional ap-proach to building domain models is that the analystsmanually generate a domain model through inspectionof the call records.
However, it has recently been pro-posed to use an unsupervised technique to generate do-main models automatically from call transcriptions (Royand Subramaniam, 2006).
In addition, there has beenresearch on how to automatically learn models of task-oriented discourse structure using dialog act and taskinformation (Bangalore et al, 2006).
Discourse struc-ture is necessary for dialog state-specific speech recog-nition and language understanding to improve theperformance by predicting the next possible dialogstates.
In addition, the discourse structure is essential todetermine whether the current utterance in the dialog ispart of the current subtask or starts a new task.89More recently, it has been proposed stochastic dialogmanagement such as the framework of a partially ob-servable Markov decision process (POMDP).
Thisframework is statistically data-driven and theoreticallyprincipled dialog modeling.
However, detailed dialogstates in the master space should be clustered into gen-eral dialog states in summary space to scale upPOMDP-based dialog management for practical appli-cations (Williams and Young, 2007).
To address thisproblem, an unsupervised automatic clustering of dialogstates has been introduced and investigated in POMDP-based dialog manager (Lefevre and Mori, 2007).In this paper, we are also interested in exploring me-thods that would automatically construct the agendagraph as prior knowledge for the EBDM framework.3 Agenda GraphIn this section, we begin with a brief overview ofEBDM framework and agenda graph.
The basic idea ofthe EBDM is that the next system action is predicted byfinding semantically similar user utterance in the dialogstate space.
The agenda graph was adapted to take intoaccount the robustness problem for practical applica-tions.
Agenda graph G is a simply a way of encodingthe domain-specific dialog control to complete the task.G is represented by a directed acyclic graph (DAG)(Figure 1).
An agenda is one of the subtask flows, whichis a possible path from root node to terminal node.
G iscomposed of nodes (v) which correspond to possibleintermediate steps in the process of completing the spe-cified task, and edges (e) which connect nodes.
In otherwords, v corresponds to dialog state to achieve domain-specific subtask in its expected agenda.
Each node in-cludes three different components: (1) A preconditionthat must be true before the subtask is executed; (2) Adescription of the node that includes its label and iden-tifier; and (3) Links to nodes that will be executed at thesubsequent turn.
In this system, this graph is used torescore n-best ASR hypotheses and to interpret the dis-course state such as new task, next task, and new sub-task based on topological position on the graph.
In theagenda graph G, each node holds a set of relevant dialogexamples which may appear in the corresponding dialogstates when a precondition of the node is true.
To de-termine the next system action, the dialog manager firstgenerates possible candidate nodes with n-best hypo-theses by using a discourse interpretation algorithmbased on the agenda graph, and then selects the focusnode which is the most likely dialog state given the pre-vious dialog state.
Finally the best example in the focusnode is selected to determine appropriate system action.Human efforts are required to manually design theagenda graph to integrate it into the EBDM framework.However, it is difficult to define all possible precondi-tion rules and to assign the transition probabilities toeach link based only on the discretion of the systemdeveloper.
To solve these problems, we tried to con-struct the agenda graph from the annotated dialog cor-pus using clustering technique.4 Clustering and Linking4.1 Node ClusteringEach precondition has been manually defined to maprelevant dialog examples into each node.
To avoid this,the dialog examples are automatically grouped into theclosest cluster (or node) by a node clustering.
In thissection, we explain a feature extraction and clusteringmethod for constructing the agenda graph.4.1.1 Feature ExtractionEach dialog example should be converted into a featurevector for a node clustering.
To represent the featurevectors, we first extract all n-grams which occur morefrequently than a threshold and do not contain any stopword as word-level features.
We also extract utterance-level and discourse-level features from the annotateddialog corpus to reflect semantic and contextual infor-mation because a dialog state can be characterized usingsemantic and contextual information derivable from theannotations.
The utterance is thus characterized by theset of various features as shown in Table 1.Figure 1: Example of an agenda graph for buildingguidance domainFeature Types Features #SizeWord-levelfeaturesunigram 175bigram 573trigram 1034Utterance-levelfeaturesdialog act (DA) 9main goal (MG) 16slot filling status 8system act (SA) 26Discourse-levelfeaturesprevious DA 10previous MG 17previous SA 27Table 1: List of feature sets90For a set of N dialog examples X={xi|i=1,..,N}, thebinary feature vectors are represented by using a set offeatures from the dialog corpus.
To calculate the dis-tance of two feature vectors, we used a cosine measureas a binary vector distance measure:jijiji xxxxxxd ????
)(1),(where xi and xj denoted two feature vectors.
However,each feature vector contains small number of non-zeroterms (<20 features) compared to the feature space(>2000 features).
Therefore, most pairs of utterancesshare no common feature, and their distance is close to1.0.
To address this sparseness problem, the distancebetween two utterances can be computed by checkingonly the non-zero terms of corresponding feature vec-tors (Liu, 2005).4.1.2 ClusteringAfter extracting feature vectors from the dialog corpus,we used K-means clustering algorithm which is the sim-plest and most commonly used algorithm employing asquared error criterion.
At the initialization step, onecluster mean is randomly selected in the data set and k-1means are iteratively assigned by selecting the farthestpoint from pre-selected centers as the following equa-tion:?
????????
???
?11,maxarg kiiXxkuxduwhere each cluster ck is represented as a mean vector uk.At the assignment step, each example is assigned to thenearest clustertc?
by minimizing the distance of clustermean uk and dialog example xt.?
??
?tkKkt xudc ,minarg?
1 ??
?The responsibilities rkt of each cluster ck are calcu-lated for each example xt as the following rule:?
??
??
??
??
??
???
l tl tkkt xudxudr ,exp,exp?
?where ?
is the stiffness and usually assigned to 1.During the update step, the means are recomputed us-ing the current cluster membership by reflecting theirresponsibilities:??
?t ktt tktk rxru4.2 Node LinkingFrom the node clustering step, node vk for cluster ck isobtained from the dialog corpus and each node containssimilar dialog examples by the node clustering algo-rithm.
Next, at the node linking step, each node shouldbe connected with an appropriate transition probabilityto build the agenda graph which is a DAG (Figure 2).This linking information can come from the dialog cor-pus because the task-oriented dialogs consist of sequen-tial utterances to complete the tasks.
Using sequences ofdialog examples obtained with the dialog corpus, rela-tive frequencies of all outgoing edges are calculated toweight directed edges:)()(),(ijiji vxnvvxnvvf ???
?where ?
?ivxn ?
represents the number of dialog exam-ples in vi and ?
?ji vvxn ??
denotes the number of di-alog examples having directed edge from vi to vj.
Nextsome edges are pruned when the weight falls below apre-defined threshold ?, and the cycle paths are removedby deleting minimal edge in cycle paths through adepth-first traversal.
Finally the transition probabilitycan be estimated by normalizing relative frequencieswith the remained edges.??
l li jiij vvfvvfvvp ),(),()|(5 Experiment & ResultA spoken dialog system for intelligent robot was devel-oped to provide information about building (e.g., roomnumber, room name, room type) and people (e.g., name,phone number, e-mail address).
If the user selects aspecific room to visit, then the robot takes the user tothe desired room.
For this system, we collect a human-human dialog corpus of about 880 user utterances from214 dialogs which were based on a set of pre-defined 10subjects relating to building guidance task.
Then, wedesigned an agenda graph and integrated it into theEBDM framework.
In addition, a simulated environ-ment with a user simulator and an ASR channel (Jung etFigure 2: Node Linking Algorithm91al., 2008) was developed to evaluate our approach bysimulating a realistic scenario.First we measured the clustering performance to veri-fy our approach for constructing the agenda graph.
Weused the manually clustered examples by a set of pre-condition rules as the reference clusters.
Table 2 showserror rates when different feature sets are used for K-means clustering in which K is equal to 10 because ahand-crafted graph included 10 nodes.
The error ratewas significantly reduced when using all feature sets.We also evaluated the dialog system performancewith the agenda graphs which are manually (HC-AG) orautomatically designed (AC-AG).
We also used 10-bestrecognition hypotheses with 20% word error rate(WER) for a dialog management and 1000 simulateddialogs for an automatic evaluation.
In this result, al-though the system with HC-AG slightly outperforms thesystem with AC-AG, we believe that AC-AG can behelpful to manage task-oriented dialogs with less humancosts for designing the hand-crafted agenda graph.6 Conclusion & DiscussionIn this paper, we address the problem of automaticknowledge acquisition of agenda graph to structuretask-oriented dialogs.
We view this problem as a firststep in clustering the dialog states, and then in linkingbetween each cluster based on the dialog corpus.
Theexperiment results show that our approach can be appli-cable to easily build the agenda graph for prior know-ledge.There are several possible subjects for further re-search on our approach.
We can improve the clusteringperformance by using a distance metric learning algo-rithm to consider the correlation between features.
Wecan also discover hidden links in the graph by exploringnew dialog flows with random walks.AcknowledgementThis research was supported by the MKE (Ministry ofKnowledge Economy), Korea, under the ITRC (Infor-mation Technology Research Center) support programsupervised by the IITA (Institute for Information Tech-nology Advancement) (IITA-2009-C1090-0902-0045).ReferencesBangalore, S., Fabbrizio, G.D. and Stent, A.
2006.
Learningthe structure of task-driven human-human dialogs.
Proc.
ofthe Association for Computational Linguistics, 201-208.Bohus, B. and Rudnicky, A.
2003.
RavenClaw: Dialog Man-agement Using Hierarchical Task Decomposition and anExpectation Agenda.
Proc.
of the European Conference onSpeech, Communication and Technology, 597-600.Jung, S., Lee, C., Kim, K. and Lee, G.G.
2008.
An IntegratedDialog Simulation Technique for Evaluating Spoken DialogSystems.
Proc.
of Workshop on Speech Processing for Safe-ty Critical Translation and Pervasive Applications, Interna-tional Conference on Computational Linguistics, 9-16.Lee, C., Jung, S. and Lee, G.G.
2008.
Robust Dialog Man-agement with N-best Hypotheses using Dialog Examplesand Agenda.
Proc.
of the Association for ComputationalLinguistics, 630-637.Lee, C., Jung, S., Kim, S. and Lee, G.G.
2009.
Example-basedDialog Modeling for Practical Multi-domain Dialog System.Speech Communication, 51(5):466-484.Lefevre, F. and Mori, R.D.
2007.
Unsupervised State Cluster-ing for Stochastic Dialog Management.
Proc.
of the IEEEWorkshop on Automatic Speech Recognition and Under-standing, 550-555.Liu, Z.
2005.
An Efficient Algorithm for Clustering ShortSpoken Utterances.
Proc.
of the IEEE International Confe-rence on Acoustics, Speech and Signal Processing, 593-596.Roy, S. and Subramaniam, L.V.
2006.
Automatic generationof domain models for call centers from noisy transcriptions.Proc.
of the Association for Computational Linguistics, 737-744.Schatzmann, J., Thomson, B., Weilhammer, K., Ye, H. andYoung, S. 2007.
Agenda-based User Simulation for Boot-strapping a POMDP Dialogue System.
Proc.
of the HumanLanguage Technology/North American Chapter of the Asso-ciation for Computational Linguistics, 149-152.Williams, J.D.
and Young, S. 2007.
Partially observable Mar-kov decision processes for spoken dialog systems.
Comput-er Speech and Language, 21:393-422.Young, S., Schatzmann, J., Weilhammer, K. and Ye, H. 2007.The Hidden Information State Approach to Dialog Man-agement.
Proc.
of the IEEE International Conference onAcoustics, Speech and Signal Processing, 149-152.System TCR (%) AvgUserTurnUsing HC-AG 92.96 4.41Using AC-AG 89.95 4.39Table 3: Task completion rate (TCR) and averageuser turn (AvgUserTurn) (WER=20%)Feature sets Error rate (%)Word-level features 46.51+Utterance-level features 34.63+Discourse-level features 31.20Table 2: Error rates for node clustering (K=10)92
