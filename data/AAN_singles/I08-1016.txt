Entity-driven Rewrite for Multi-document SummarizationAni NenkovaUniversity of PennsylvaniaDepartment of Computer and Information Sciencenenkova@seas.upenn.eduAbstractIn this paper we explore the benefits fromand shortcomings of entity-driven nounphrase rewriting for multi-document sum-marization of news.
The approach leads to20% to 50% different content in the sum-mary in comparison to an extractive sum-mary produced using the same underlyingapproach, showing the promise the tech-nique has to offer.
In addition, summariesproduced using entity-driven rewrite havehigher linguistic quality than a comparisonnon-extractive system.
Some improvementis also seen in content selection over extrac-tive summarization as measured by pyramidmethod evaluation.1 IntroductionTwo of the key components of effective summariza-tions are the ability to identify important points inthe text and to adequately reword the original textin order to convey these points.
Automatic textsummarization approaches have offered reasonablywell-performing approximations for identifiying im-portant sentences (Lin and Hovy, 2002; Schiffman etal., 2002; Erkan and Radev, 2004; Mihalcea and Ta-rau, 2004; Daume?
III and Marcu, 2006) but, not sur-prisingly, text (re)generation has been a major chal-lange despite some work on sub-sentential modifica-tion (Jing and McKeown, 2000; Knight and Marcu,2000; Barzilay and McKeown, 2005).
An addi-tional drawback of extractive approaches is that es-timates for the importance of larger text units suchas sentences depend on the length of the sentence(Nenkova et al, 2006).Sentence simplification or compaction algorithmsare driven mainly by grammaticality considerations.Whether approaches for estimating importance canbe applied to units smaller than sentences and usedin text rewrite in the summary production is a ques-tion that remains unanswered.
The option to operateon smaller units, which can be mixed and matchedfrom the input to give novel combinations in thesummary, offers several possible advantages.Improve content Sometimes sentences in the in-put can contain both information that is very appro-priate to include in a summary and information thatshould not appear in a summary.
Being able to re-move unnecessary parts can free up space for bettercontent.
Similarly, a sentence might be good over-all, but could be further improved if more detailsabout an entity or event are added in.
Overall, a sum-marizer capable of operating on subsentential unitswould in principle be better at content selection.Improve readability Linguistic quality evalua-tion of automatic summaries in the Document Un-derstanding Conference reveals that summarizersperform rather poorly on several readability aspects,including referential clarity.
The gap between hu-man and automatic performance is much larger forlinguistic quality aspects than for content selection.In more than half of the automatic summaries therewere entities for which it was not clear what/whothey were and how they were related to the story.The ability to add in descriptions for entities in thesummaries could improve the referential clarity ofsummaries and can be achieved through text rewrite118of subsentential units.IP issues Another very practical reason to be in-terested in altering the original wording of sentencesin summaries in a news browsing system involves in-tellectual property issues.
Newspapers are not will-ing to allow verbatim usage of long passages oftheir articles on commercial websites.
Being able tochange the original wording can thus allow compa-nies to include longer than one sentence summaries,which would increase user satisfaction (McKeownet al, 2005).These considerations serve as direct motivationfor exploring how a simple but effective summarizerframework can accommodate noun phrase rewrite inmulti-document summarization of news.
The ideais for each sentence in a summary to automaticallyexamine the noun phrases in it and decide if a dif-ferent noun phrase is more informative and shouldbe included in the sentence in place of the original.Consider the following example:Sentence 1 The arrest caused an international con-troversy.Sentence 2 The arrest in London of former Chileandictator Augusto Pinochet caused an interna-tional controversy.Now, consider the situation where we need to ex-press in a summary that the arrest was controversialand this is the first sentence in the summary, and sen-tence 1 is available in the input (?The arrest causedan international controversy?
), as well as an unre-lated sentence such as ?The arrest in London of for-mer Chilean dictator Augusto Pinochet was widelydiscussed in the British press?.
NP rewrite can allowus to form the rewritten sentence 2, which would bea much more informative first sentence for the sum-mary: ?The arrest in London of former Chilean dic-tator Augusto Pinochet caused an international con-troversy?.
Similarly, if sentence 2 is available inthe input and it is selected in the summary after asentence that expresses the fact that the arrest tookplace, it will be more appropriate to rewrite sentence2 into sentence 1 for inclusion in the summary.This example shows the potential power of nounphrase rewrite.
It also suggests that context will playa role in the rewrite process, since different nounphrase realizations will be most appropriate depend-ing on what has been said in the summary up to thepoint at which rewrite takes place.2 NP-rewrite enhanced frequencysummarizerFrequency and frequency-related measures of im-portance have been traditionally used in text sum-marization as indicators of importance (Luhn, 1958;Lin and Hovy, 2000; Conroy et al, 2006).
No-tably, a greedy frequency-driven approach leads tovery good results in content selection (Nenkova etal., 2006).
In this approach sentence importance ismeasured as a function of the frequency in the in-put of the content words in that sentence.
The mostimportant sentence is selected, the weight of wordsin it are adjusted, and sentence weights are recom-puted for the new weights beofre selecting the nextsentence.This conceptually simple summarization ap-proach can readily be extended to include NP rewriteand allow us to examine the effect of rewrite capa-bilities on overall content selection and readability.The specific algorithm for frequency-driven summa-rization and rewrite is as follows:Step 1 Estimate the importance of each contentword wi based on its frequency in the input ni,p(wi) = niN .Step 2 For each sentence Sj in the input, estimateits importance based on the words in the sen-tence wi ?
Sj : the weight of the sentence isequal to the average weight of content wordsappearing in it.Weight(Sj) =?wi?Sjp(wi)|wi?Sj |Step 3 Select the sentence with the highest weight.Step 4 For each maximum noun phrase NPk in theselected sentence4.1 For each coreferring noun phrase NPi,such that NPi ?
NPk from allinput documents, compute a weightWeight(NPi) = FRW (wr ?
NPi).4.2 Select the noun phrase with the highestweight and insert it in the sentence in119place of the original NP.
In case of ties,select the shorter noun phrase.Step 5 For each content word in the rewritten sen-tence, update its weight by setting it to 0.Step 6 If the desired summary length has not beenreached, go to step 2.Step 4 is the NP rewriting step.
The functionFRW is the rewrite composition function that as-signs weights to noun phrases based on the impor-tance of words that appear in the noun phrase.
Thetwo options that we explore here are FRW ?
Avrand FRW ?
Sum; the weight of an NP equalsthe average weight or sum of weights of contentwords in the NP respectively.
The two selectionslead to different behavior in rewrite.
FRW ?
Avrwill generally prefer the shorter noun phrases, typ-ically consisting of just the noun phrase head andit will overall tend to reduce the selected sentence.FRW ?
Sum will behave quite differently: it willinsert relevant information that has not been con-veyed by the summary so far (add a longer nounphrase) and will reduce the NP if the words in italready appear in the summary.
This means thatFRW ?
Sum will have the behavior close to whatwe expect for entity-centric rewrite: inluding moredescriptive information at the first mention of the en-tity, and using shorter references at subsequent men-tions.Maximum noun phrases are the unit on whichNP rewrite operates.
They are defined in a depen-dency parse tree as the subtree that has as a roota noun such that there is no other noun on thepath between it and the root of the tree.
For ex-ample , there are two maximum NPs, with heads?police?
and ?Augusto Pinochet?
in the sentence?British police arrested former Chilean dictator Au-gusto Pinochet?.
The noun phrase ?former chileandictator?
is not a maximum NP, since there is a noun(augusto pinochet) on the path in the dependencytree between the noun ?dictator?
and the root of thetree.
By definition a maximum NP includes all nom-inal and adjectival premodifiers of the head, as wellas postmodifiers such as prepositional phrases, ap-positions, and relative clauses.
This means that max-imum NPs can be rather complex, covering a widerange of production rules in a context-free grammar.The dependency tree definition of maximum nounphrase makes it easy to see why these are a goodunit for subsentential rewrite: the subtree that hasthe head of the NP as a root contains only modifiersof the head, and by rewriting the noun phrase, theamount of information expressed about the head en-tity can be varied.In our implementation, a context free grammarprobabilistic parser (Charniak, 2000) was used toparse the input.
The maximum noun phrases wereidentified by finding sequences of <np>...</np>tags in the parse such that the number of opening andclosing tags is equal.
Each NP identified by such tagspans was considered as a candidate for rewrite.Coreference classes A coreference class CRm isthe class of all maximum noun phrases in the inputthat refer to the same entity Em.
The general prob-lem of coreference resolution is hard, and is evenmore complicated for the multi-document summa-rization case, in which cross-document resolutionneeds to be performed.
Here we make a simplify-ing assumption, stating that all noun phrases thathave the same noun as a head belong to the samecoreference class.
While we expected that this as-sumption would lead to some wrong decisions, wealso suspected that in most common summarizationscenarios, even if there are more than one entities ex-pressed with the same noun, only one of them wouldbe the main focus for the news story and will ap-pear more often across input sentences.
Referencesto such main entities will be likely to be picked ina sentence for inclusion in the summary by chancemore often than other competeing entities.
We thusused the head noun equivalance to form the classes.A post-evaluation inspection of the summaries con-firmed that our assumption was correct and therewere only a small number of errors in the rewrit-ten summaries that were due to coreference errors,which were greatly outnumbered by parsing errorsfor example.
In a future evaluation, we will evalu-ate the rewrite module assuming perfect coreferenceand parsing, in order to see the impact of the coreNP-rewrite approach itself.3 NP rewrite evaluationThe NP rewrite summarization algorithm was ap-plied to the 50 test sets for generic multi-document120summarization from the 2004 Document Under-standing Conference.
Two examples of its operationwith FRW ?
Avr are shown below.Original.1 While the British government defendedthe arrest, it took no stand on extradition of Pinochetto Spain.NP-Rewite.1 While the British government de-fended the arrest in London of former Chilean dicta-tor Augusto Pinochet, it took no stand on extraditionof Pinochet to Spain.Original.2 Duisenberg has said growth in the euroarea countries next year will be about 2.5 percent,lower than the 3 percent predicted earlier.NP-Rewrite.2 Wim Duisenberg, the head of the newEuropean Central Bank, has said growth in the euroarea will be about 2.5 percent, lower than just 1 per-cent in the euro-zone unemployment predicted ear-lier.We can see that in both cases, the NP rewritepasted into the sentence important additional infor-mation.
But in the second example we also see anerror that was caused by the simplifying assumptionfor the creation of the coreference classes accord-ing to which the percentage of unemployment andgrowth have been put in the same class.In order to estimate how much the summary ischanged because of the use of the NP rewrite, wecomputed the unigram overlap between the originalextractive summary and the NP-rewrite summary.As expected, FFW ?
Sum leads to bigger changesand on average the rewritten summaries containedonly 54% of the unigrams from the extractive sum-maries; for FRW ?
Avr, there was a smaller changebetween the extractive and the rewritten summary,with 79% of the unigrams being the same betweenthe two summaries.3.1 Linguistic quality evaluationNoun phrase rewrite has the potential to improvethe referential clarity of summaries, by inserting inthe sentences more information about entities whensuch is available.
It is of interest to see how therewrite version of the summarizer would compareto the extractive version, as well as how its linguis-tic quality compares to that of other summarizersthat participated in DUC.
Four summarizers wereevaluated: peer 117, which was a system that usedgeneration techniques to produce the summary andSYSTEM Q1Q2Q3Q4Q5SUMId 4.06 4.12 3.80 3.80 3.20SUMAvr 3.40 3.90 3.36 3.52 2.80SUMSum 2.96 3.34 3.30 3.48 2.80peer 117 2.06 3.08 2.42 3.12 2.10Table 1: Linguistic quality evaluation.
Peer 117 wasthe only non-extractive system entry in DUC 2004;SUMId is the frequency summarizer with no NPrewrite; and the two versions of rewrite with sumand average as combination functions.was the only real non-extractive summarizer partic-ipant at DUC 2004 (Vanderwende et al, 2004); theextractive frequency summarizer, and the two ver-sions of the rewrite algorithm (Sum and Avr).
Theevaluated rewritten summaries had potential errorscoming from different sources, such as coreferenceresolution, parsing errors, sentence splitting errors,as well as errors coming directly from rewrite, inwhich an unsuitable NP is chosen to be included inthe summary.
Improvements in parsing for exam-ple could lead to better overall rewrite results, butwe evaluated the output as is, in order to see whatis the performance that can be expected in a realisticsetting for fully automatic rewrite.The evaluation was done by five native Englishspeakers, using the five DUC linguistic quality ques-tions on grammaticality (Q1), repetition (Q2), refer-ential clarity (Q3), focus (Q4) and coherence (Q5).Five evaluators were used so that possible idiosyn-cratic preference of a single evaluator could beavoided.
Each evaluator evaluated all five sum-maries for each test set, presented in a random order.The results are shown in table 3.1.
Each summarywas evaluated for each of the properties on a scalefrom 1 to 5, with 5 being very good with respect tothe quality and 1, very bad.Comparing NP rewrite to extraction Here wewould be interested in comparing the extractive fre-quency summarizer (SUMId), and the two version ofsystems that rewrite noun phrases: SUMAvr (whichchanges about 20% of the text) and SUMSum (whichchanges about 50% of the text).
The general trendthat we see for all five dimensions of linguistic qual-ity is that the more the text is automatically altered,the worse the linguistic quality of the summary121gets.
In particular, the grammaticality of the sum-maries drops significantly for the rewrite systems.The increase of repetition is also significant betweenSUMId and SUMSum.
Error analysis showed thatsometimes increased repetition occurred in the pro-cess of rewrite for the following reason: the contextweight update for words is done only after each nounphrase in the sentence has been rewritten.
Occasion-ally, this led to a situation in which a noun phrasewas augmented with information that was expressedlater in the original sentence.
The referential clar-ity of rewritten summaries also drops significantly,which is a rather disappointing result, since one ofthe motivations for doing noun phrase rewrite wasthe desire to improve referential clarity by adding in-formation where such is necessary.
One of the prob-lems here is that it is almost impossible for humanevaluators to ignore grammatical errors when judg-ing referential clarity.
Grammatical errors decreasethe overall readability and a summary that is givena lower grammaticality score tends to also receivelower referential clarity score.
This fact of qualityperception is a real challenge for summarizerationsystems that move towards abstraction and alter theoriginal wording of sentences since certainly auto-matic approaches are likely to introduce ingrammat-icalities.Comparing SUMSum and peer 117 We now turnto the comparison of between SUMSum and the gen-eration based system 117.
This system is uniqueamong the DUC 2004 systems, and the only onethat year that experimented with generation tech-niques for summarization.
System 117 is verb-driven: it analizes the input in terms of predicate-argument triples and identifies the most importanttriples.
These are then verbalized by a generationsystem originally developed as a realization compo-nent in a machine translation engine.
As a result,peer 117 possibly made even more changes to theoriginal text then the NP-rewrite system.
The resultsof the comparison are consistent with the observa-tion that the more changes are made to the originalsentences, the more the readability of summaries de-creases.
SUMSum is significantly better than peer117 on all five readability aspects, with notable dif-ference in the grammaticality and referential quality,for which SUMSum outperforms peer 117 by a fullpoint.
This indicates that NPs are a good candidategranularity for sentence changes and it can lead tosubstantial altering of the text while preserving sig-nificantly better overall readability.3.2 Content selection evaluationWe now examine the question of how the content inthe summaries changed due to the NP-rewrite, sinceimproving content selection was the other motiva-tion for exploring rewrite.
In particular, we are in-terested in the change in content selection betweenSUMSum and SUMId (the extractive version of thesummarizer).
We use SUMSum for the compari-son because it led to bigger changes in the sum-mary text compared to the purely extractive version.We used the pyramid evaluation method: four hu-man summaries for each input were manually ana-lyzed to identify shared content units.
The weight ofeach content unit is equal to the number of modelsummaries that express it.
The pyramid score ofan automatic summary is equal to the weight of thecontent units expressed in the summary divided bythe weight of an ideally informative summary of thesame length (the content unit identification is againdone manually by an annotator).Of the 50 test sets, there were 22 sets in whichthe NP-rewritten version had lower pyramid scoresthan the extractive version of the summary, 23 setsin which the rewritten summaries had better scores,and 5 sets in which the rewritten and extractive sum-maries had exactly the same scores.
So we see thatin half of the cases the NP-rewrite actually improvedthe content of the summary.
The summarizer versionthat uses NP-rewrite has overall better content selec-tion performance than the purely extractive system.The original pyramid score increased from 0.4039 to0.4169 for the version with rewrite.
This improve-ment is not significant, but shows a trend in the ex-pected direction of improvement.The lack of significance in the improvement is dueto large variation in performance: when np rewriteworked as expected, content selection improved.But on occasions when errors occurred, both read-ability and content selection were noticeably com-promised.
Here is an example of summaries forthe same input in which the NP-rewritten versionhad better content.
After each summary, we list thecontent units from the pyramid content analysis thatwere expressed in the summary.
The weight of each122content unit is given in brackets before the label ofthe unit and content units that differ between the ex-tractive and rewritten version are displayed in italic.The rewritten version conveys high weight contentunits that do not appear in the extractive version,with weights 4 (maximum weight here) and 3 re-spectively.Extractive summary Italy?s Communist Re-founding Party rejected Prime Minister Prodi?s pro-posed 1999 budget.
By one vote, Premier RomanoProdi?s center-left coalition lost a confidence votein the Chamber of Deputies Friday, and he went tothe presidential palace to rsign.
Three days after thecollapse of Premier Romano Prodi?s center-left gov-ernment, Italy?s president began calling in politicalleaders Monday to try to reach a consensus on a newgovernment.
Prodi has said he would call a confi-dence vote if he lost the Communists?
support.?
Ihave always acted with coherence,?
Prodi said be-fore a morning meeting with President Oscar Luigi.
(4) Prodi lost a confidence vote(4) The Refounding Party is Italy?s CommunistParty(4) The Refounding Party rejected the govern-ment?s budget(3) The dispute is over the 1999 budget(2) Prodi?s coalition was center-left coalition(2) The confidence vote was lost by only 1 vote(1) Prodi is the Italian Prime Minister(1) Prodi wants a confidence vote from ParliamentNP-rewrite version Communist Refounding, afringe group of hard-line leftists who broke with theminstream Communists after they overhauled theparty following the collapse of Communism in East-ern Europe rejected Prime Minister Prodi?s proposed1999 budget.
By only one vote, the center-left primeminister of Italy, Romano Prodi, lost The vote in thelower chamber of Parliament 313 against the con-fidence motion brought by the government to 312in favor in Parliament Friday and was toppled frompower.
President Oscar Luigi Scalfaro, who askedhim to stay on as caretaker premier while the headof state decides whether to call elections.
(4) Prodi lost a confidence vote(4) Prodi will stay as caretaker until a new gov-ernment is formed(4) The Refounding Party is Italy?s CommunistParty(4) The Refounding Party rejected the govern-ment?s budget(3) Scalfaro must decide whether to hold newelections(3) The dispute is over the 1999 budget(2) Prodi?s coalition was center-left coalition(2) The confidence vote was lost by only 1 vote(1) Prodi is the Italian Prime MinisterBelow is another example, showing the worse de-terioration of the rewritten summary compared tothe extractive one, both in terms of grammatical-ity and content.
Here, the problem with repetitionduring rewrite arises: the same person is mentionedtwice in the sentence and at both places the sameoverly long description is selected during rewrie,rendering the sentence practically unreadable.Extractive summary Police said Henderson andMcKinney lured Shepard from the bar by sayingthey too were gay and one of their girlfriends saidShepard had embarrassed one of the men by mak-ing a pass at him.
1,000 people mourned MatthewShepherd, the gay University of Wyoming studentwho was severely beaten and left to die tied to afence.
With passersby spontaneously joining theprotest group, two women held another sign thatread,?
No Hate Crimes in Wyoming.?
Two candle-light vigils were held Sunday night.
Russell An-derson, 21, and Aaron McKinney, 21, were chargedwith attempted murder.
(4) The victim was a student at the University ofWyoming(4) The victim was brutally beaten(4) The victim was openly gay(3) The crime was widely denounced(3) The nearly lifeless body was tied to a fence(3) The victim died(3) The victim was left to die(2) The men were arrested on charges of kidnap-ping and attempted first degree murder123(2) There were candlelight vigils in support forthe victim(1) Russell Henderson and Aaron McKinney arethe names of the people responsible for the deathNP-rewrite version Police said Henderson andMcKinney lured the The slight, soft-spoken 21-year-old Shepard, a freshman at the University ofWyoming, who became an overnight symbol of anti-gay violence after he was found dangling from thefence by a passerby from a bar by saying they toowere gay and one of their girlfriends said the Theslight, soft-spoken 21-year-old Shepard, a fresh-man at the University of Wyoming, who became anovernight symbol of anti-gay violence after he wasfound dangling from the fence by a passerby hadembarrassed one of the new ads in that supposedlyhate-free crusade.
(4) The victim was a student at the University ofWyoming(3)The nearly lifeless body was tied to a fence (1)A passerby found the victim(1) Russell Henderson and Aaron McKinney arethe names of the people responsible for the death(1) The victim was 22-year oldEven from this unsuccessful attempt for rewritewe can see how changes of the original text can bedesirable, since some of the newly introduced infor-mation is in fact suitable for the summary.4 ConclusionsWe have demonstrated that an entity-driven ap-proach to rewrite in multi-document summarizationcan lead to considerably different summary, in termsof content, compared to the extractive version ofthe same system.
Indeed, the difference leads tosome improvement measurable in terms of pyramidmethod evaluation.
The approach also significantlyoutperforms in linguistic quality a non-extractiveevent-centric system.Results also show that in terms of linguistic qual-ity, extractive systems will be curently superior tosystems that alter the original wording from the in-put.
Sadly, extractive and abstractive systems areevaluated together and compared against each other,putting pressure on system developers and prevent-ing them from fully exploring the strengths of gen-eration techniques.
It seems that if researchersin the field are to explore non-extractive methods,they would need to compare their systems sepa-rately from extractive systems, at least in the begin-ning exploration stages.
The development of non-extractive approaches in absolutely necessary if au-tomatic summarization were to achieve levels of per-formance close to human, given the highly abstrac-tive form of summaries written by people.Results also indicate that both extractive and non-extractive systems perform rather poorly in terms ofthe focus and coherence of the summaries that theyproduce, identifying macro content planning as animportant area for summarization.ReferencesRegina Barzilay and Kathleen McKeown.
2005.
Sen-tence fusion for multidocument news summarization.Computational Linguistics, 31(3).Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In NAACL-2000.John Conroy, Judith Schlesinger, and Dianne O?Leary.2006.
Topic-focused multi-document summarizationusing an approximate oracle score.
In Proceedings ofACL, companion volume.Hal Daume?
III and Daniel Marcu.
2006.
Bayesian query-focused summarization.
In Proceedings of the Confer-ence of the Association for Computational Linguistics(ACL), Sydney, Australia.Gunes Erkan and Dragomir Radev.
2004.
Lexrank:Graph-based centrality as salience in text summa-rization.
Journal of Artificial Intelligence Research(JAIR).Hongyan Jing and Kathleen McKeown.
2000.
Cutand paste based text summarization.
In Proceedingsof the 1st Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL?00).Kevin Knight and Daniel Marcu.
2000.
Statistics-basedsummarization ?
step one: Sentence compression.
InProceeding of The American Association for ArtificialIntelligence Conference (AAAI-2000), pages 703?710.Chin-Yew Lin and Eduard Hovy.
2000.
The automatedacquisition of topic signatures for text summarization.In Proceedings of the 18th conference on Computa-tional linguistics, pages 495?501.124Chin-Yew Lin and Eduard Hovy.
2002.
Automatedmulti-document summarization in neats.
In Proceed-ings of the Human Language Technology Conference(HLT2002 ).H.
P. Luhn.
1958.
The automatic creation of literatureabstracts.
IBM Journal of Research and Development,2(2):159?165.K.
McKeown, R. Passonneau, D. Elson, A. Nenkova,and J. Hirschberg.
2005.
Do summaries help?
atask-based evaluation of multi-document summariza-tion.
In SIGIR.R.
Mihalcea and P. Tarau.
2004.
Textrank: Bringing or-der into texts.
In Proceedings of EMNLP 2004, pages404?411.Ani Nenkova, Lucy Vanderwende, and Kathleen McKe-own.
2006.
A compositional context sensitive multi-document summarizer: exploring the factors that influ-ence summarization.
In Proceedings of SIGIR.Barry Schiffman, Ani Nenkova, and Kathleen McKeown.2002.
Experiments in multidocument summarization.In Proceedings of the Human Language TechnologyConference.Lucy Vanderwende, Michele Banko, and Arul Menezes.2004.
Event-centric summary generation.
In Pro-ceedings of the Document Understanding Conference(DUC?04).125
