Coling 2010: Poster Volume, pages 860?868,Beijing, August 2010A Vector Space Model for Subjectivity Classification in Urduaided by Co-TrainingSmruthi MukundCEDARUniversity at Buffalosmukund@buffalo.eduRohini K. SrihariCEDARUniversity at Buffalorohini@cedar.buffalo.eduAbstractThe goal of this work is to produce aclassifier that can distinguish subjectivesentences from objective sentences forthe Urdu language.
The amount of la-beled data required for training automaticclassifiers can be highly imbalanced es-pecially in the multilingual paradigm asgenerating annotations is an expensivetask.
In this work, we propose a co-training approach for subjectivity analy-sis in the Urdu language that augmentsthe positive set (subjective set) and gene-rates a negative set (objective set) devoidof all samples close to the positive ones.Using the data set thus generated fortraining, we conduct experiments basedon SVM and VSM algorithms, and showthat our modified VSM based approachworks remarkably well as a sentence lev-el subjectivity classifier.1 IntroductionSubjectivity tagging involves distinguishingsentences that express opinions from sentencesthat present factual information (Banfield 1982;Wiebe, 1994).
A wide variety of affectivenuances can be used while delivering a messagepertaining to an event.
Although the factualcontent remains the same, lexical selections andgrammatical choices can considerably influencethe affective nature of the text.
Recognizingsentences that exhibit affective behavior willrequire, at the least, recognizing the structure ofthe sentence and the emotion bearing words.To date, much of the research in this area isfocused on English.
A variety of reliableresources that facilitate effective sentimentanalysis and opinion mining, such as polaritylexicons (Senti-WordNet 1 ) and contextualvalence shifters (Kennedy and Inkpen, 2005) areavailable for English.
The MPQA corpus of10,000 sentences (Wiebe et al, 2005) providesdetailed annotations for sources of opinions,targets, speech events and fragments that indicateattitudes for the English newswire data.
TheIMDB corpus contains 10,000 sentencescategorized as subjective and objective in themovie review domain.
Clearly, English is wellsupported with resources.
There are other widelyspoken resource poor languages that are not asprivileged.
When we consider social media,limiting our analysis to a language like English,however universal, will lead to loss ofinformation.
With the advent of virtualkeyboards and extended Unicode support, theinternet is rapidly getting flooded by users whouse their native language in textualcommunication.
There is a pressing need toperform non-topical text analysis in themultilingual paradigm.Subjectivity analysis is a precursor tonumerous applications performing non-topicaltext analysis like sentiment analysis, emotiondetection, and opinion extraction (Liu et al,2005; Ku et al, 2006; Titov and McDonald,2008).
Creating the state-of-the-art subjectivityclassifier using machine learning techniquesrequire access to large amounts of annotateddata.
For less commonly taught languages like1 http://swn.isti.cnr.it/download_1.0/860Urdu, Hindi, Bengali, Spanish and Romanian,the resources required to automate subjectivityanalysis are either very sparse or unavailable.Generating annotated corpus for subjectivitydetection is laborious and time consuming.However, several innovative techniques havebeen proposed by researchers in the past togenerate annotated data and lexical resources forsubjectivity analysis in resource poor languages.Mihalcea et al, (2007) and Banea et al, (2008)used machine translation technique to leverageEnglish resources for analysis in Romanian andSpanish languages.
Wan (2009) proposed a co-training technique that leveraged an availableEnglish corpus for Chinese sentimentclassification.
Wan (2008) focused on improvingChinese sentiment analysis by using bothChinese and English lexicons.Unfortunately, not much work has been donein the area of subjectivity analysis for the Urdulanguage.
This language lacks annotatedresources required to generate even the basicNLP tools (POS tagger, NE tagger etc.)
neededfor text analysis.
In order to facilitate subjectivityanalysis in Urdu language, we annotated a smallset of Urdu newswire articles for emotions (?2).The sentence level annotations provided in thisdataset follow the annotation guidelinesproposed by Wiebe et al, (2003).
Althoughtremendous effort was put into generating thiscorpus, the data set is not very comprehensiveand contains only about 500 sentences markedsubjective.
This is definitely insufficient to traina suitable subjectivity classifier.1.1 Issue with unbalanced data setA subjectivity classifier is a binary classifier.A traditional binary classifier is trained usinguniversal representative sets for positive andnegative categories.
But in subjectivity analysis,especially for languages like Urdu that have noannotated data, generating universalrepresentative sets is extremely difficult andalmost an impossible task.
Assimilating thenegative set is especially a delicate task as the setshould be carefully pruned of all the positivesamples.
Also, detecting subjectivity in asentence is highly personalized.
Annotators aresometimes prejudiced while marking samples.This bias, however small, produces errors withsome true positive samples being unintentionallymissed and categorized as negative.Traditionally, research in machine learning hasassumed the class distribution in the training datato be reasonably balanced.
However, when thetraining data is highly imbalanced, i.e., thenumber of positive examples is very small, theperformance of text classification algorithmssuch as linear support vector machine (SVM)(Brank and Grobelnik, 2003), na?ve Bayes anddecision trees (Kubat and Matwin, 1997) areadversely affected.In order to achieve a balanced training set,Japkowicz (2000) duplicates positive examples(oversampling) and discards negative ones(downsizing).
Kubat and Matwin (1997) discardall samples that are close to the positive set toavoid misclassification.
Chan and Stalfo (1998)have trained several classifiers on different ba-lanced data subsets, each constructed to includeall positive training samples and a set of negativesamples of comparable size.
The predictions arecombined through stacking.For the task of subjectivity analysis, especiallyin the multilingual paradigm where the data set ishighly unbalanced, using one of the techniquesproposed above will yield benefit.
To the best ofour knowledge, co-training technique has notbeen applied before for the subjectivity detectiontask, in particular, for the Urdu language.1.2 ContributionOur first contribution is inspired by the workof Luo et al, (2008).
We propose a similar co-training technique that helps to create a likelynegative set (objective sentences) and a filteredpositive set (subjective sentences)simultaneously from the unlabeled set.
We usetwo learning models trained using the linearSVM algorithm iteratively.
In every iteration ofco-training, the likely positive samples arefiltered.
The iterative process terminates when nomore positive samples are found.
The finalnegative set is the likely negative set, consideredas the universal representative set for the non-subjective category.
The likely positive sampleset is appended to the already existing positiveset (annotated set).
The SVM models are trainedusing part of speech, unigrams and emotionbearing words, as features.The second contribution of this work includestraining a state-of-the-art Vector Space Model861(VSM) for Urdu newswire data using the datasets generated by the co-training method.Experiments that use the SVM classifier are alsoperformed.
The results show that theperformance of the proposed VSM basedapproach helps to achieve state-of-the-artsentence level subjectivity classifier.
The F-Measure of the VSM subjectivity classifier is82.72% with 78.7% F-measure for the subjectiveclass and 86.7% F-Measure for the objectiveclass.2 Data SetThe data set used to generate a subjectivityclassifier for Urdu newswire articles is obtainedfrom BBC Urdu2.
The annotating efforts are di-rected towards achieving the final goal- emotiondetection in Urdu newswire data and the annota-tion guidelines are based on the MPQA standardsset for English.The repository of articles provided by BBC ishuge and needs to be filtered intelligently.
Twolevels of filters are applied.
?
date and keywordsearch.
The date filter is applied to retrieve ar-ticles of three years, starting year 2003.
The key-word based filter consists of a set of seed wordsthat are commonly used to express emotions inUrdu -ghussa (~anger), pyar (~love) etc.
Clearly,this list will not cover all possible linguistic ex-pressions that express emotion and opinion.
Butit is definitely a representative of a wide range ofphenomena that naturally occurs in text express-ing emotions.The data retrieved is parsed using an in-houseHTML parser to produce clean data.
To date, wehave 500 articles, consisting of 700 sentencesannotated for emotions.
There are nearly 6000sentences that do not contain any emotions mak-ing it highly unbalanced.
This data set is dividedinto testing and training sets with 30% and 70%of the data respectively.
Co-training is performedonly on the 70% training set that consists of 470subjective sentences and about 4000 objectivesentences.
The purpose of co-training here is toremove samples that are close to subjective fromthe objective set and create a likely negative set.The samples removed are the likely positive set.This set of 4000 objective sentences can be con-sidered as the un-annotated set.2 http://www.bbc.co.uk/urdu/3 Co-TrainingIdentifying sentences that express emotions inUrdu newswire data is not trivial.
Subjective sen-tences do not always contain individual expres-sions that indicate subjectivity.
Analysis is high-ly dependent on the contextual information.Wiebe et al, (2001) reported that nearly 44% ofsentences in the MPQA corpus (English news-wire data) are subjective.
In newswire data,though most facts are reported objectively, thereare cases when the tone of the sentence is veryintense indicating the existence of emotion.
Con-sider Example 1.Example 1:Political news headline??????
??
?????
?
???????
?????????
??
???????
??
?????????
????
??
??????
????
[bhart ka pakstan kE sath jame mZakrat sE ankar,bharty lykcr snnE kE Kwaha" nhy"][India refuses to have a dialog with Pakistan, In-dians are not willing to listen to the lecture]Common Urdu?????
??
?????
??
???
??
???
?????
???????
??
?????
[India refuses to talk to Pakistan]Clearly, the news headline is extremely in-tense and strongly expresses the opinion of Indiaon Pakistan.
However, the statement in commonUrdu is not as affective.Example 2:??
????
????
????
???
????
????
???
??
????
???
?????????
???
???
[anSary nE kha ?myry ray^E my" eamr shyl aykbd dmaG awr Zdy XKS hy"?
][Ansari said, ?according to me Aamir Sohail is onecrazy and stubborn man?
]Statements in quotes that express emotions aresubjective as shown in example 2.Consider example 3.
Here, identifying thewords that indicate subjectivity is not straightforward.
The phrase, ?found it very difficult tohide his smile?
is indicative of the emotion expe-rienced by ?Habib Miya?.Example 3:???
???
???????
??
??
?????
??
??
????
????
??
?????
??
????
???????
????
????
[rqm ky as wSwly pr yh Hbyb mya" kE ly^E bhtmXkl t|ha kh wh apny mskrahT c|hpa sky"][At this event of money collection, Habib Miyanfound it very difficult to hide his smile.
]862There are also several false positives thatmake subjective detection hard task.
Example 4is an objective sentence despite the usage ofword ?pyar?
~ love, an emotion bearing word.Example 4:??
???
????
???
????????
??
???
????
[n|Zmam ka nya pyar ka nam anzy pRa hE][The new nickname for Inzaman is Inzi]Expressive elements in Urdu sentences weremarked with an inter-annotator agreement of 0.8kappa score.
Though high, there still exists a biasthat can influence classification especially whenthe number of sentences in the positive set is rel-atively less.
In order to obtain a reliable positiveand negative set for training a learning algorithm,we adopt a semi-supervised learning technique ofco-training.
Co-training (Blum and Mitchell,1998) is similar to self-training in that it increas-es the amount of labeled data by automaticallyannotating unlabeled data.
The intuition here isthat if the conditional independence assumptionholds, then on an average each selected docu-ment will be as informative as a random docu-ment, and the learning will progress.
Co-trainingdiffers from self-training as it uses multiplelearners to do the annotation.
Each learner offersits own perspective that when combined givesmore information.
This technique is especiallyeffective when the feature space of a particulartype of problem can be divided into distinctgroups and each group contains sufficient infor-mation to perform the annotation.
In other words,co-training algorithm involves training two dif-ferent learning algorithms on two different fea-ture spaces.
The learning of one becomes condi-tionally independent of the other and the predic-tion made by each classifier is used on the unla-beled data set to augment the training data of theother.A traditional co-training classifier is trainedand later applied on the same unlabeled data set.Theoretically such classifiers are not likely toassign confident labels.
In this work, the pro-posed co-training method differs from the tradi-tional co-training method in that the two classifi-ers are based not on two different feature spacesbut on two different training data sets with thesame feature space.Figure 1: Co-Training modelFigure 1 explains the overall working of themodel.
The negative set (which can also be theunlabeled set) is split into two equal parts N1 andN2.
S represents the positive annotated set.
Twolinear SVM classifiers are trained iteratively topurify the negative data set.
SVM1 is trained us-ing S+N1i and SVM2 is trained using S+N2i datasets.
In every iteration i, N1i data set is evaluatedusing SVM2 model and N2i data set is evaluatedusing SVM1 model.
The samples that are classi-fied as positive in a given iteration i are binnedinto sets P1i and P2i respectively.
These samplesare removed from N1i and N2i data sets to createnew N1i+1 and N2i+1 sets that are used for trainingin the next iteration i+1.
The iterations continueuntil no positive samples are marked by bothSVM1 and SVM2 models.
The final set of likelynegatives is S = N1k + N2k sets, where N1k andN2k are sets created in the last k iteration of thealgorithm.
In order to obtain the likely positiveset, the final P1 = {P11 + P12 + ?.
+ P1k} and P2 ={P21 + P22 + ?.
+ P2k} sets are combined andtested using the SVMs modeled in the last k ite-ration of the co-training algorithm.
Similar to thetraditional co-training method the samples thatare marked positive by both classifiers (P1o = P2o)are considered to be the likely positive set L.Several features are used to train the SVMlearning models used for co-training.
The bestperformance is obtained when word unigrams,parts of speech and likely emotion words areused as features.This technique of co-training provides us witha relatively huge set of likely positive samples863(close to 400 sentences).
Sentences in this setwere examined by the annotators and nearly 60%of the sentences were subjective or near subjec-tive in nature (Example 5 and 6).Labels R % P % IF % AF %Unigram 52.631 18.64 74.57 29.83-1 95.4 62.35 75.44Unigram+Bigram 50.251 14.40 85 24.63-1 98.19 61.82 75.87Table 1: Performance of the model usingun-balanced data set3Labels R % P % IF % AF %Annotated positive + likely positive + likelynegative62.951 39 70 50.09-1 87.28 67.34 79.9Annotated positive + likely negative 55.421 30 61.2 40.26-1 86.1 64.23 73.57Table 2 ?
Performance of the model afterco-training methodTable 1 shows the performance of the SVMmodel using the unbalanced data set for training.Table 2 shows the performance of the samemodel using data generated after co-training.Example 5:???
????
???????
?
??????
?
?????
??
???
??
???
??????
????
?
?????
??
?????
?????
???
??????
?
????
????
[pwtn nE kha kh lwg dwsrw" ky Ank|h my" tnkadyk|h lytE hy" lykn apny Ank|h my" pRa Xhtyr an-hy" n|zr nhy" Ata .
][Potan said people who see dust in others eyesnever realize that it is their eyes that are filled withdirt.
]The above example is a metaphor indicatingextreme anger.Example 6:??????
??
?
????
????
??
??
????
????
??
???
??????
??????
????
?????
????
?????
????
???
??
?????
??
??
??
[e|ta& alrHmn XyK ka khna hE kh barh agst kw an-hy" an kE byTw" kE samnE mkml |twr pr brhnh krkE pryD kray^y gy^y][etlaalrahman said that on 12th Aug they made himparade naked in front of his children.
]3 Convention used across tables -  Label 1: subjective sen-tences Label -1: objective sentences R: Recall P: PrecisionIF: Individual F-Measure AF: Average F-Measure.Example 6 indicates extreme sad emotion.
Suchexamples were found in the likely positive set.4 FeaturesFeatures that are commonly used to train asubjectivity classifier for English are word uni-grams, emotion keywords, part of speech infor-mation and noun patterns (Pang et al, 2002).Due to difference in syntactic structure, vocabu-lary and style, features that work for English maynot work for Urdu.
Also, Urdu is handicapped bythe lack of resources required to perform basicNLP analysis.
However, it is worth exploring theEnglish feature set as subjectivity is more a se-mantic phenomenon.
Efforts to generate likelyemotion word lexicons and subjectivity patternsfor the Urdu language are underway.
The sec-tions that follow summarize the experimentedfeatures.4.1 Word UnigramsUnigram word features are very informative.Three different approaches are tried for selectingthe unigrams.
The first method involves selectingonly those words that occur more than twice inthe dataset.
This eliminates proper nouns (lowfrequency named entities do not generally con-tribute towards subjectivity detection) and spel-ling errors (Pang et al, 2002).
In the second me-thod, only words that are adjectives and verbsalong with the surrounding case markers are ac-counted for as features.
This has the advantage ofdrastically reducing the feature set.
The third me-thod involves including the nouns as well to thefeature set.
A simple list of stop words (commonUrdu words ?
pronouns such as ?us?, ?is?, ?aap?,?un?, salutations like ?shabba khair?, ?aadab?
andhonorifics along with punctuations and specialsymbols) are eliminated.
The features arerepresented as Boolean features for the SVMmodel.
The value is 1 if the feature word appearsin the sentence to be classified and 0 otherwise.The best performance is obtained for the firstmethod that considers all words with frequencygreater than 2.
This conforms to what is shownby Pang et al, (2002) for classification of Eng-lish movie reviews.4.2 Part of Speech (POS) InformationThe work done by Mukund and Srihari (2009)provides suitable POS and NE tagger for Urdu.864This POS tagger is used to generate parts ofspeech tags on the acquired data set (?3).
ThePOS tags associated with adjectives, verbs,common nouns and auxiliary words are consi-dered and used as Boolean features for the SVMmodel.
The proper noun words are normalized toone common word ?nnp?
and are assigned thecommon noun tag.
For the English language,when building a subjectivity classifier for reviewclassification, the use of POS information did notbenefit the system (Kennedy and Inkpen, 2006).However, for Urdu, the performance of the co-training model with POS information showed1.2% improvement (table 3).4.3 Likely Emotion LexiconIn order to facilitate simple keyword baseddetection of subjectivity, access to a lexicon con-sisting of likely emotion words is needed.
Unfor-tunately, no such lexicon is available off theshelf for Urdu.
In this work, an Urdu specificemotion list is generated that contains transla-tions from the English emotion list released bySemEval (2007) ?Word"et affect Emotion List?.Words for each emotion category - sadness (sad),fear, joy (happy), surprise, anger and disgust areobtained for Urdu by using an Urdu-English dic-tionary.
The list is pruned manually and cor-rected to remove errors.
Simple keyword lookupon the Urdu annotated corpus has an emotiondetection rate of 29.27%.
This shows that al-though the contribution of the emotion lexiconfor subjectivity classification is not significant, itcontains information which when used alongwith other features aid subjectivity detection.4.4 PatternsExtracting syntactic patterns contribute to-wards the affective orientation of a sentence (Ri-loff et al, 2003).
The Apriori algorithm (Agar-wal and Srikant, 1994) for learning associationrules is used here to mine the syntactic word pat-terns commonly used in the positive and negativedata set.
The length of the candidate item set k =4.
Starting from a small set of seed words (likelyemotion words) and the associated POS tags,POS sequential patterns like ?adverb verbverbtransitive sentencemarker?, ?noun noun ca-semarker verbtransitive?, etc., that are mostcommonly found in subjectivity set are extracted.23 patterns that strongly indicate subjectivitywere found by this method and included as fea-tures to train the SVM learning algorithm.4.5 Confidence WordsThe confidence word list positively aids theVSM classifier (?5).
The words in the likelyemotion list are not the only ones that contributetowards the emotion orientation of a sentenceand also, not all of these words contribute effec-tively.
There are several stop words (eliminatedwhile accounting for unigrams) (esp.
case mark-ers) that contribute significantly for categoriza-tion.
In order to identify all the keywords thatactually contribute to subjectivity categorization,a technique proposed by Soucy and Mineau(2004) is used.The confidence weight of a given word w,based on the number of documents it is asso-ciated with under each category, is measured us-ing the Wilson Proportion Estimate (Wilson,1927).
In order to compute the confidence of wfor a specific category, the number of positiveand negative documents associated with w has tobe determined.
A document is positive if it be-longs to that category and negative otherwise.Thus, two kinds of word confidence metrics arecomputed, CPOS:w and C"EG:w as given below.???
(Eq.
1)???
(Eq.
2)where n is the total number of positive and nega-tive documents,  is the ratio of the num-ber of positive documents which contain w to thetotal number of documents, and  is theratio of the number of negative documents whichcontain w to the total number of documents.
Thenormal distribution is used when n > 30.Note that equations 1 and 2 give a range ofvalues for CPOS:w and C"EG:w. If the lower boundof CPOS:w is greater than the upper bound ofC"EG:w, we say that w is likely to be a word inthat category.
Now, we compute the strength of aword Sw in a particular category as( )( )nznnzppznzpCwPOSwPOSzwPOSwPOS 22/22/::2/2/:: 1]4?1?[2?????+????????
+?
?+=( )( )nznnzppznzpCw"EGw"EGzw"EGw"EG 22/22/::2/2/:: 1]4?1?[2?????+????????
+?
?+=wPOSp :?
( )???
?= >                            ;                    0;2logotherwise)w:NEGub(C  )w:POSlb(C ifmPRFSw"EG:w p ?865???
(Eq.
3)where mPRF is given by???
(Eq.
4)and lb(?)
and ub(?)
are the lower and upperbounds of their arguments, respectively.Equations 1 through 4 generated a very good setof keywords that are used as category word fea-tures in the SVM learning model.
For VSM, thestrength value is used as a boost factor alongwith the tf-idf weight when calculating the simi-larity score (table 3).5 Final Subjectivity ClassifierWiebe et al, (2005) and Pang et al, (2002)have shown that an SVM based approach workswell for subjectivity classification.
Riloff et al,(2003) have conducted experiments that use Bag-Of-Words (BoW) as features to generate a Na?veBayes subjectivity classifier for the MPQA cor-pus in English.
This method has an accuracy of73.3%.
Su and Markert (2008) use BoW featurestermed as lexical features on the IMDB corpus togenerate an accuracy of 60.5%.
Das and Ban-dyopadhyay (2009) use a CRF based approach togenerate a subjectivity classifier for Bengali datawith a precision of 72.16% for news and 74.6%for blogs domain.
The same approach has a pre-cision of 76.08% and 79.9% on the two domainsrespectively.
Impressive results for emotion de-tection are obtained by Danisman and Alpkocak,(2007) who use a VSM based approach.
Theyshow that their approach works much better thana traditional SVM based approach commonlyused for emotion detection.In this work, we conduct subjectivity classifi-cation experiments using two different learningalgorithms ?
linear SVM and VSM.
The bestperformance is obtained using the VSM model asshown in table 4.
All experiments are conductedon the data set obtained after applying the co-training technique.5.1 VSM algorithmThe final subjectivity classifier is based on theVSM approach.
Inspired by the work done in?Feeler?
(Danisman and Alpkocak, 2007), a sim-ilar technique is used to train the final subjectivi-ty classifier for Urdu.
The algorithm is explainedin table 3.
The similarity metric is modified toinclude the confidence score for each word(pt.5).
In VSM, documents and queries arerepresented as vectors, and the cosine angle be-tween them indicates the similarity.1.
di = <w1i, w2i, ?.
wni> where wki is the weight ofthe kth term in document i , di is the documentvector.
wki is computed using tf-idf weightingscheme.2.
Mj={d1,d2,?,dc} where Mj is each class (subjec-tive and objective)3.
Model vector for an arbitrary class Ej is createdby taking the mean of dj vectors?
?=||1 jjiMMdijj dMEwhere |Mj| represents number of documents in Mj.4.
The whole system is represented with a set ofmodel vectors, D={E1,E2,...,Es} where s representsthe number of distinct classes to be recognized.5.
The normalized similarity between a given querytext Q, and a class, Ej, is defined as follows:kjnkkqj EconfwEQsim *)(),(1?=+=conf is the confidence factor applied for lexicalterms found in the word list.6.
classification result is,)),(max(arg)( jEQsimQVSM =Table 3: VSM Algorithm for subjectivityClassificationLabels R % P % IF % AF %Before Co-Training (all data) 62.951 65.85 70.85 67.4-1 85.58 83.33 84.44After Co-Training (pruned data) 86.731 72.88 85.57 78.72-1 91.29 82.60 86.73Table 4: VSM approach, using all training data andusing pruned training data (L+S+true)The confidence metric (strength) for each termis calculated using the Wilson proportion esti-mate (?4.4) and added to the term score as theboost factor.
Q is the test set.
Model vectors areobtained using the data set that consists of trueset (annotated positive samples), likely positiveset L and likely negative set N. Sets L and N areobtained from the co-training method.
The re-sults are shown in table 4.The power of SVM cannot be ignored.
Pang etal., (2002) use SVM to generate a subjectivity(polarity) classifier for English.
Our second setof experiments is conducted to measure the per-formance of a linear SVM classifier for subjec-tivity analysis on the Urdu newswire data.
Thedata set used for training is the pruned data set)ub(C )lb(C)lb(Cw:NEGw:POSw:POS+=mPRF866obtained after applying the co-training technique.The features used and the performance of themodel with each feature is documented in table 6.Labels R % P % IF % AF %Unigrams + POS 64.21 40.67 71.1 51.75-1 88.29 67.74 76.67Unigrams + POS + Patterns 65.681 43.22 72.34 54.11-1 88.29 68.69 77.26Unigrams + POS + Patterns + emotion words  67.311 48.31 70.81 57.43-1 85.88 70.09 77.19Table 6: SVM classifier on Urdu newswire dataIn order to provide a better understanding ofthe power of the VSM technique, we applied thismodel on the IMDB data set.
The training dataconsists of 4000 positive (subjective) and 4000negative (objective) samples.
Since the data set isalready balanced, we skip the co-training method.Our aim here is to test the working of VSM clas-sifier.
The test set consists of 1000 positive and1000 negative samples.
The classification resulton this data set is shown in table 5.
The resultsare comparable to the state-of-the-art perfor-mance of English subjectivity classifier that usesSVM (Wiebe et al, 2005).Labels R % P % IF % AF %Balanced training 78.011 64 90.57 75-1 93.18 71.68 81.03Table 5: VSM approach on IMDB data set6 Analysis of resultsIn this work, experiments were conducted us-ing two different classification approaches; 1.VSM based 2.
SVM based.
Results in table 4indicate that the VSM technique when combinedwith the modified boost factor (confidencemeasure) can be a very powerful technique forsentence level classification tasks.
When modelvectors were constructed using the entire trainingset (highly unbalanced), the performance was at62% F-Measure with the subjectivity detectionrate of 70.85%.
Post co-training, using the mod-ified model vectors obtained from the pruneddata set generated better scores.
The increase inthe recall of negative class and the increase in theoverall F-Measure can be attributed to (i) in-crease in the positive samples (~likely positiveset), and (ii) cleaner negative set (no near posi-tive samples).The results in table 6 for the SVM classifieralso indicate the benefits of co-training.
The sub-jectivity classification performance show posi-tive improvement.
Although the performance ofthe SVM model is not as good as the VSM mod-el, addition of each feature shows an improve-ment in the subjectivity recognition rate.
Thisperformance indicates that the feature sets ex-plored definitely contain positive informationnecessary for accurate detection.The poor performance of SVM (over VSM)can be attributed to 1. lack of balanced data fortraining a traditional SVM model and, 2. smallnumber of positive samples.
In VSM the problemof unbalanced data set in a way is overcome byusing the confidence score at the time of calcu-lating similarity.
If these factors are compensated,the performance of the SVM model will signifi-cantly improve.7 ConclusionThis research provides interesting insights inmodeling a subjectivity classifier for Urdunewswire data.
We show that despite Urdu beinga resource poor language, techniques like co-training and statistical techniques based on tf-idfand word unigrams coupled with confidencemeasures help model the state-of-the-art subjec-tivity classifier.
We demonstrate the power of theco-training technique in generating likely nega-tive and positive sets.
The number of near sub-jective samples in the likely positive set suggeststhat this method can be used as an adaptivelearning technique to enable the annotators pro-duce more samples.
For a task like emotion de-tection, that requires fine grained analysis, sen-tences need to be analyzed at the semantic leveland this goes beyond simple keyword based ap-proach.
Our efforts are now concentrated in thisdirection.ReferencesAgrawal R, Srikant R. 1994.
Fast Algorithms for MiningAssociation Rules.
In Proc.
Of the Intl.
Conf on VeryLarge databases.
Santiago, Chile.
Sept. Pp.
478-499.Banea, C., Mihalcea, R., Wiebe, J., and Hassan, S. 2008.Multilingual subjectivity analysis using machine transla-tion.
In Proceedings of EM"LP-2008.Banfield, A.
1982.
Unspeakable Sentences.
Routledge andKegan Paul, Boston.867Blum, A. and Mitchell, T. 1998.
Combining labeled andunlabeled data with co-training.
Proceedings of the ele-venth annual conference on Computational learningtheory, ACM.
p. 100.Brank, J., Grobelnik, M., Milic-Frayling, N., and Mladenic,D.
2003.
Training text classifiers with SVM on very fewpositive examples.
Technical Report MSR-TR-2003-34,Microsoft Corp.Chan, Philip K. and Stolfo J. Salvatore.
1998.
Toward Scal-able Learning with Non-Uniform Class and Cost Distri-butions: A Case Study in Credit Card Fraud Detection.Proc.
4th Int.
Conf.
on Knowledge Discovery and DataMining (KDD-98), August 27?31, 1998, New York City,New York, USA, pp.
164?168.
AAAI Press.Danisman, T., and Alpkocak, A.
2008.
Feeler: EmotionClassification of Text Using Vector Space Model.
AISB2008 Convention Communication, Interaction and SocialIntelligence, p. 53.Das, A., and Bandyopadhyay, S. 2009.
Subjectivity Detec-tion in English and Bengali: A CRF-based Approach.
Se-venth International Conference on "atural LanguageProcessing (ICON 2009), December.
Hyderabad, India.Japkowicz Nathalie.
2000.
Learning from Imbalanced DataSets: A Comparison of Various Strategies.
In "athalieJapkowicz (ed.
), Learning from Imbalanced Data Sets:Papers from the AAAI Workshop (Austin, Texas, Mon-day, July 31, 2000), AAAI Press, Technical Report WS-00-05, pp.
10?15.Kennedy, A, & Inkpen, D. 2005.
Sentiment classification ofmovie and product reviews using contextual valence shif-ters.
In Workshop on the analysis of informal and formalinformation exchange during negotiations (FINEXIN2005)Ku, L. W., Liang, Y. T., and Chen, H. H. 2006.
Opinionextraction, summarization and tracking in news and blogcorpora.
In Proceedings of AAAI-2006.Kubat, Miroslav and Matwin Stan.
1997.
Addressing thecurse of imbalanced training sets: one-sided selection.Proc.
14th ICML, Nashville, Tennessee, USA, July 8?12,1997, pp.
179?186.Liu, B., Hu, M., and Cheng, J.
2005.
Opinion observer:Analyzing and comparing opinions on the web.
In Pro-ceedings of WWW-2005.Luo, N., Yuan, F., and Zuo, W. 2008.
Using CoTraining andSemantic Feature Extraction for Positive and UnlabeledText Classification.
International Seminar on Future In-formation Technology and Management Engineering.Mihalcea, R., Banea, C., and Wiebe, J.
2007.
Learning mul-tilingual subjective language via cross-lingual projec-tions.
In Proceedings of ACL-2007.Mukund, S., and Srihari, R.K., 2009.
NE Tagging for Urdubased on Bootstrap POS Learning.
Third InternationalWorkshop on Cross Lingual Information Access: Ad-dressing the Information Need of Multilingual Societies(CLIAWS3), NAACL - 2009, Boulder, CO.Pang, B., Lee, L., and Vaithyanathan, S. 2002.
Thumbs up?Sentiment classification using machine learning tech-niques.
In Proceedings of the Conference on EM"LP,pages 79?86.Riloff, E., Wiebe, J., and Wilson, T. 2003.
Learning subjec-tive nouns using extraction pattern bootstrapping.
Pro-ceedings of the seventh conference on "atural languagelearning at HLT-"AACL 2003 - Volume 4,  Edmonton,Canada: Association for Computational Linguistics, pp.25-32.Soucy, P., and Mineau, G. W. 2005.
Beyond tfidf weightingfor text categorization in the vector space model.
Interna-tional Joint Conference on Artificial Intelligence, Cite-seer, p. 1130.Su, F., and Markert.
K. 2008.
From words to senses: a casestudy of subjectivity recognition.
Proceedings of the 22ndInternational Conference on Computational Linguistics-Volume 1, ACL, pp.
825-832.Titov, I., and McDonald, R. 2008.
A joint model of text andaspect ratings for sentiment summarization.
In Proceed-ings of ACL-08:HLT.Wan, X.
2008.
Using bilingual knowledge and ensembletechniques for unsupervised Chinese sentiment analysis.In Proceedings of EM"LP-2008.Wan, X.
2009.
Co-Training for Cross-Lingual SentimentClassification.
In Proceedings of the Joint Conference ofthe 47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on "atural Language Processingof the AF"LP, Association for Computational Linguis-tics, pp.
235-243.Wiebe, J.
1994.
Tracking point of view in narrative.
Com-putational Linguistics, 20(2):233-287.Weibe, J., Bruce, R., and O?Hara, T. 1999.
Developmentand use of a gold standard data set for subjectivity classi-fications.
In Proc.
37th Annual Meeting of the Assoc.
forComputational Linguistics (ACL-99).Wiebe, J., and Riloff, E. 2005.
Creating Subjective andObjective Sentence Classifiers from Unannotated Texts.Proceedings of the 6th International Conference on Intel-ligent Text Processing and Computational Linguistics.Wiebe, J., Wilson, T., and Cardie, C. 2005.
Annotatingexpressions of opinions and emotions in language.
Lan-guage Resources and Evaluation, volume 39, issue 2-3,pp.
165-210.Wilson, B. Edward.
1927.
Probable Inference, the Law ofSuccession, and Statistical Inference.
Journal of theAmerican Statistical Association, Vol.
22, No.
158 (Jun.,1927), pp.
209-212.868
