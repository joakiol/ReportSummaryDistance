Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 375?383,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsN-best Reranking by Multitask LearningKevin Duh Katsuhito Sudoh Hajime Tsukada Hideki Isozaki Masaaki NagataNTT Communication Science Laboratories2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan{kevinduh,sudoh,tsukada,isozaki}@cslab.kecl.ntt.co.jpnagata.masaaki@lab.ntt.co.jpAbstractWe propose a new framework for N-bestreranking on sparse feature sets.
The ideais to reformulate the reranking problem asa Multitask Learning problem, where eachN-best list corresponds to a distinct task.This is motivated by the observation thatN-best lists often show significant differ-ences in feature distributions.
Training asingle reranker directly on this heteroge-nous data can be difficult.Our proposed meta-algorithm solves thischallenge by using multitask learning(such as ?1/?2 regularization) to discovercommon feature representations across N-best lists.
This meta-algorithm is simple toimplement, and its modular approach al-lows one to plug-in different learning algo-rithms from existing literature.
As a proofof concept, we show statistically signifi-cant improvements on a machine transla-tion system involving millions of features.1 IntroductionMany natural language processing applications,such as machine translation (MT), parsing, andlanguage modeling, benefit from the N-bestreranking framework (Shen et al, 2004; Collinsand Koo, 2005; Roark et al, 2007).
The advan-tage of N-best reranking is that it abstracts awaythe complexities of first-pass decoding, allowingthe researcher to try new features and learning al-gorithms with fast experimental turnover.In the N-best reranking scenario, the trainingdata consists of sets of hypotheses (i.e.
N-bestlists) generated by a first-pass system, along withtheir labels.
Given a new N-best list, the goal isto rerank it such that the best hypothesis appearsnear the top of the list.
Existing research have fo-cused on training a single reranker directly on theentire data.
This approach is reasonable if the datais homogenous, but it fails when features vary sig-nificantly across different N-best lists.
In partic-ular, when one employs sparse feature sets, oneseldom finds features that are simultaneously ac-tive on multiple N-best lists.In this case, we believe it is more advantageousto view the N-best reranking problem as a multi-task learning problem, where each N-best list cor-responds to a distinct task.
Multitask learning, asubfield of machine learning, focuses on how toeffectively train on a set of different but relateddatasets (tasks).
Our heterogenous N-best list datafits nicely with this assumption.The contribution of this work is three-fold:1.
We introduce the idea of viewing N-bestreranking as a multitask learning problem.This view is particularly apt to any generalreranking problem with sparse feature sets.2.
We propose a simple meta-algorithm thatfirst discovers common feature representa-tions across N-bests (via multitask learning)before training a conventional reranker.
Thusit is easily applicable to existing systems.3.
We demonstrate that our proposed methodoutperforms the conventional reranking ap-proach on a English-Japanese biomedicalmachine translation task involving millionsof features.The paper is organized as follows: Section 2 de-scribes the feature sparsity problem and Section 3presents our multitask solution.
The effectivenessof our proposed approach is validated by experi-ments demonstrated in Section 4.
Finally, Sections5 and 6 discuss related work and conclusions.2 The Problem of Sparse Feature SetsFor concreteness, we will describe N-best rerank-ing in terms of machine translation (MT), though375our approach is agnostic to the application.
In MTreranking, the goal is to translate a foreign lan-guage sentence f into an English sentence e bypicking from a set of likely translations.
A stan-dard approach is to use a linear model:e?
= argmaxe?N(f)wT ?
h(e, f) (1)where h(e, f) is a D-dimensional feature vector,w is the weight vector to be trained, and N(f) isthe set of likely translations of f , i.e.
the N-bestlist.
The feature h(e, f) can be any quantity de-fined in terms of the sentence pair, such as transla-tion model and language model probabilities.Here we are interested in situations where thefeature definitions can be quite sparse.
A com-mon methodology in reranking is to first designfeature templates based on linguistic intuition anddomain knowledge.
Then, numerous features areinstantiated based on the training data seen.
Forexample, the work of (Watanabe et al, 2007) de-fines feature templates based on bilingual wordalignments, which lead to extraction of heavily-lexicalized features of the form:h(e, f) =??????
?1 if foreign word ?Monsieur?and English word ?Mr.
?co-occur in e,f0 otherwise(2)One can imagine that such features are sparsebecause it may only fire for input sentences thatcontain the word ?Monsieur?.
For all other inputsentences, it is an useless, inactive feature.Another common feature involves word ngramtemplates, for example:h(e, f) =??
?1 if English trigram?Mr.
Smith said?
occurs in e0 otherwise(3)In this case, all possible trigrams seen in the N-best list are extracted as features.
One can seethat this kind of feature can be very sensitive tothe first-pass decoder: if the decoder has loose re-ordering constraints, then we may extract expo-nentially many nonsense ngram features such as?Smith said Mr.?
and ?said Smith Mr.?.
Granted,the reranker training algorithm may learn thatthese nonsense ngrams are indicative of poor hy-potheses, but it is unlikely that the exact same non-sense ngrams will appear given a different test sen-tence.In summary, the following issues compound tocreate extremely sparse feature sets:1.
Feature templates are heavily-lexicalized,which causes the number of features to growunbounded as the the amount of data in-creases.2.
The input (f ) has high variability (e.g.
largevocabulary size), so that features for differentinputs are rarely shared.3.
The N-best list output also exhibits high vari-ability (e.g.
many different word reorder-ings).
Larger N may improve reranking per-formance, but may also increase feature spar-sity.When the number of features is too large, evenpopular reranking algorithms such as SVM (Shenet al, 2004) and MIRA (Watanabe et al, 2007;Chiang et al, 2009) may fail.
Our goal here is toaddress this situation.3 Proposed Reranking FrameworkIn the following, we first give an intuitive com-parison between single vs. multiple task learning(Section 3.1), before presenting the general meta-algorithm (Section 3.2) and particular instantia-tions (Section 3.3).3.1 Single vs.
Multiple TasksGiven a set of I input sentences {f i}, the trainingdata for reranking consists of a set of I N-best lists{(Hi,yi)}i=1,...,I , where Hi are features and yiare labels.To clarify the notation:1 for an input sentencef i, there is a N-best list N(f i).
For a N-best listN(f i), there are N feature vectors correspondingto the N hypotheses, each with dimension D. Thecollection of feature vectors for N(f i) is repre-sented by Hi, which can be seen as a D ?
Nmatrix.
Finally, the N -dimensional vector of la-bels yi indicates the translation quality of each hy-pothesis in N(f i).
The purpose of the rerankertraining algorithm is to find good parameters from{(Hi,yi)}.1Generally we use bold font h to represent a vector, bold-capital font H to represent a matrix.
Script h and h(?)
maybe scalar, function, or sentence (depends on context).376The conventional method of training a singlereranker (single task formulation) involves opti-mizing a generic objective such as:argminwI?i=1L(w,Hi,yi) + ??
(w) (4)where w ?
RD is the reranker trained on all lists,and L(?)
is some loss function.
?
(w) is an op-tional regularizer, whose effect is traded-off by theconstant ?.
For example, the SVM reranker forMT (Shen et al, 2004) defines L(?)
to be somefunction of sentence-level BLEU score, and ?
(w)to be the large margin regularizer.2On the other hand, multitask learning involvessolving for multiple weights, w1,w2, .
.
.
,wI ,one for each N-best list.
One class of multitasklearning algorithms, Joint Regularization, solvesthe following objective:arg minw1,..,wII?i=1L(wi,Hi,yi) + ??
(w1, ..,wI )(5)The loss decomposes by task but the joint regu-larizer ?
(w1, ..,wI) couples together the differentweight parameters.
The key is to note that multi-ple weights allow the algorithm to fit the heteroge-nous data better, compared to a single weight vec-tor.
Yet these weights are still tied together so thatsome information can be shared across N-best lists(tasks).One instantiation of Eq.
5 is ?1/?2 regular-ization: ?
(w1, ..,wI) , ||W||1,2, where W =[w1|w2| .
.
.
|wI ]T is a I-by-D matrix of stackedweight vectors.
The norm is computed by first tak-ing the 2-norm on columns of W, then taking a1-norm on the resulting D-length vector.
This en-courages the optimizer to choose a small subset offeatures that are useful across all tasks.For example, suppose two different sets ofweight vectors Wa and Wb for a 2 lists, 4 fea-tures reranking problem.
The ?1/?2 norm for Wais 14; the ?1/?2 norm for Wb is 12.
If both havethe same loss L(?)
in Eq.
5, the multitask opti-mizer would prefer Wb since more features areshared:Wa :?4 0 0 30 4 3 0?Wb :?4 3 0 00 4 3 0?4 4 3 3 ?
14 4 5 3 0 ?
122In MT, evaluation metrics like BLEU do not exactly de-compose across sentences, so for some training algorithmsthis loss is an approximation.3.2 Proposed Meta-algorithmWe are now ready to present our general rerankingmeta-algorithm (see Algorithm 1), termed Rerank-ing by Multitask Learning (RML).Algorithm 1 Reranking by Multitask LearningInput: N-best data {(Hi,yi)}i=1,...,IOutput: Common feature representation hc(e, f)and weight vector wc1: [optional] RandomHashing({Hi})2: W = MultitaskLearn({(Hi ,yi)})3: hc = ExtractCommonFeature(W)4: {Hic} = RemapFeature({Hi}, hc)5: wc = ConventionalReranker({(Hic ,yi)})The first step, random hashing, is optional.
Ran-dom hashing is an effective trick for reducing thedimension of sparse feature sets without suffer-ing losses in fidelity (Weinberger et al, 2009;Ganchev and Dredze, 2008).
It works by collaps-ing random subsets of features.
This step can beperformed to speed-up multitask learning later.
Insome cases, the original feature dimension may beso large that hashed representations may be neces-sary.The next two steps are key.
A multitask learn-ing algorithm is run on the N-best lists, and a com-mon feature space shared by all lists is extracted.For example, if one uses the multitask objectiveof Eq.
5, the result of step 2 is a set of weightsW.
ExtractCommonFeature(W) then returns thefeature id?s (either from original or hashed repre-sentation) that receive nonzero weight in any ofW.3 The new features hc(e, f) are expected tohave lower dimension than the original featuresh(e, f).
Section 3.3 describes in detail differentmultitask methods that can be plugged-in to thisstep.The final two steps involve a conventionalreranker.
In step 4, we remap the N-best listdata according to the new feature representationshc(e, f).
In step 5, we train a conventionalreranker on this common representation, which bynow should have overcome sparsity issues.
Us-ing a conventional reranker at the end allows usto exploit existing rerankers designed for specificNLP applications.
In a sense, our meta-algorithmsimply involves a change of representation forthe conventional reranking scenario, where the3For example in Wb, features 1-3 have nonzero weightsand are extracted.
Feature 4 is discarded.377new representation is found by multitask methodswhich are well-suited to heterogenous data.3.3 Multitask Objective FunctionsHere, we describe various multitask methods thatcan be plugged in Step 2 of Algorithm 1.
Ourgoal is to demonstrate that a wide range of existingmethods from the multitask learning literature canbe brought to our problem.
We categorize multi-task methods into two major approaches:1.
Joint Regularization: Eq.
5 is an exam-ple of joint regularization, with ?1/?2 norm beinga particular regularizer.
The idea is to use the reg-ularizer to ensure that the learned functions of re-lated tasks are close to each other.
The popular?1/?2 objective can be optimized by various meth-ods, such as boosting (Obozinski et al, 2009) andconvex programming (Argyriou et al, 2008).
Yetanother regularizer is the ?1/??
norm (Quattoni etal., 2009), which replaces the 2-norm with a max.One could also define a regularizer to ensurethat each task-specific wi is close to some averageparameter, e.g.
?i ||wi ?
wavg||2.
If we inter-pret wavg as a prior, we begin to see links to Hier-archical Bayesian methods for multitask learning(Finkel and Manning, 2009; Daume, 2009).2.
Shared Subspace: This approach assumesthat there is an underlying feature subspace thatis common to all tasks.
Early works on multi-task learning implement this by neural networks,where different tasks have different output layersbut share the same hidden layer (Caruana, 1997).Another method is to write the weight vectoras two parts w = [u;v] and let the task-specificfunction be uT ?
h(e, f) + vT ?
?
?
h(e, f) (Andoand Zhang, 2005).
?
is a D?
?D matrix that mapsthe original features to a subspace common to alltasks.
The new feature representation is computedby the projection hc(e, f) , ?
?
h(e, f).Multitask learning is a vast field and relates toareas like collaborative filtering (Yu and Tresp,2005) and domain adaptation.
Most methods as-sume some common representation and is thus ap-plicable to our framework.
The reader is urged torefer to citations in, e.g.
(Argyriou et al, 2008) fora survey.4 Experiments and ResultsAs a proof of concept, we perform experimentson a MT system with millions of features.
Weuse a hierarchical phrase-based system (Chiang,100 101 102 103 10410?710?610?510?410?310?210?1100P(feature occursinxlists)xFigure 1: This log-log plot shows that there aremany rare features and few common features.
Theprobability that a feature occurs in x number of N-best lists behaves according to the power-law x?
?,where ?
= 2.28.2007) to generate N-best lists (N=100).
Sparsefeatures used in reranking are extracted accordingto (Watanabe et al, 2007).
Specifically, the major-ity are lexical features involving joint occurrencesof words within the N-best lists and source sen-tences.It is worth noting that the fact that the first passsystem is a hierarchical system is not essential tothe feature extraction step; similar features can beextracted with other systems as first-pass, e.g.
aphrase-based system.
That said, the extent of thefeature sparsity problem may depend on the per-formance of the first-pass system.We experiment with medical domain MT, wherelarge numbers of technical vocabulary cause spar-sity challenges.
Our corpora consists of Englishabstracts from PubMed4 with their Japanese trans-lations.
The first-pass system is built on hierarchi-cal phrases extracted from 17k sentence pairs andtarget (Japanese) language models trained on 800kmedical-domain sentences.
For our reranking ex-periments, we used 500 lists as the training set5,500 lists as held-out, and another 500 for test.4.1 Data CharacteristicsWe present some statistics to illustrate the featuresparsity problem: From 500 N-best lists, we ex-tracted a total of 2.4 million distinct features.
Bytype, 75% of these features occur in only one N-best list in the dataset.
Less than 3% of features4A database of the U.S. National Library of Medicine.5In MT, training data for reranking is sometimes referredto as ?dev set?
to distinguish from the data used in first-pass.Also, while the 17k bitext may seem small compared to otherMT work, we note that 1st pass translation quality (around 28BLEU) is high enough to evaluate reranking methods.378occur in ten or more lists.
The distribution of fea-ture occurrence is clearly Zipfian, as seen in thepower-law plot in Figure 1.We can also observe the feature growth rate (Ta-ble 1).
This is the number of new features intro-duced when an additional N-best list is seen.
It isimportant to note that on average, 2599 new fea-tures are added everytime a new N-best list is seen.This is as much as 2599/4188 = 62% of the ac-tive features.
Imagine an online training algorithm(e.g.
MIRA or perceptron) on this kind of data:whenever a loss occurs and we update the weightvector, less than half of the weight vector updateapplies to data we have seen thus far.
Herein liesthe potential for overfitting.From observing the feature grow rate, one mayhypothesize that adding large numbers of N-bestlists to the training set (500 in the experimentshere) may not necessarily improve results.
Whileadding data potentially improves the estimationprocess, it also increases the feature space dramat-ically.
Thus we see the need for a feature extrac-tion procedure.
(Watanabe et al, 2007) also reports the possibil-ity of overfitting in their dataset (Arabic-Englishnewswire translation), especially when domaindifferences are present.
Here we observe this ten-dency already on the same domain, which is likelydue to the highly-specialized vocabulary and thecomplex sentence structures common in researchpaper abstracts.4.2 MT ResultsOur goal is to compare different feature represen-tations in reranking: The baseline reranker usesthe original sparse feature representation.
This iscompared to feature representations discovered bythree different multitask learning methods:?
Joint Regularization (Obozinski et al, 2009)?
Shared Subspace (Ando and Zhang, 2005)?
Unsupervised Multitask Feature Selection(Abernethy et al, 2007).6We use existing implementations of the abovemethods.7 The conventional reranker (Step 5, Al-6This is not a standard multitask algorithm since mostmultitask algorithms are supervised.
We include it to seeif unsupervised or semi-supervised multitask algorithms ispromising.
Intuitively, the method tries to select subsets offeatures that are correlated across multiple tasks using ran-dom sampling (MCMC).
Features that co-occur in differenttasks form a high probability path.7Available at http://multitask.cs.berkeley.eduNbest id #NewFt #SoFar #Active1 3900 3900 39002 7535 11435 79133 6078 17513 70874 3868 21381 47475 1896 23277 26456 3542 26819 4747....100 2440 289118 4299101 1639 290757 2390102 3468 294225 4755103 2350 296575 3824Average 2599 ?
4188Table 1: Feature growth rate: For N-best list i inthe table, we have (#NewFt = number of new fea-tures introduced since N-best i ?
1) ; (#SoFar =Total number of features defined so far); and (#Ac-tive = number of active features for N-best i).
E.g.,we extracted 7535 new features from N-best 2;combined with the 3900 from N-best 1, the totalfeatures so far is 11435.gorithm 1) used in all cases is SVMrank.8 Ourinitial experiments show that the SVM baselineperformance is comparable to MIRA training, sowe use SVM throughout.
The labels for the SVMare derived as in (Shen et al, 2004), where top10% of hypotheses by smoothed sentence-BLEUis ranked before the bottom 90%.
All multitasklearning methods work on hashed features of di-mension 4000 (Step 1, Algorithm 1).
This speedsup the training process.All hyperparameters of the multitask methodare tuned on the held-out set.
In particular, themost important is the number of common featuresto extract, which we pick from {250, 500, 1000}.Table 2 shows the results by BLEU (Papineniet al, 2002) and PER.
The Oracle results are ob-tained by choosing the best hypothesis per N-bestlist by sentence-level BLEU, which achieved 36.9BLEU in both Train and Test.
A summary of ourobservations is:1.
The baseline (All sparse features) overfits.
Itachieves the oracle BLEU score on the trainset (36.9) but performs poorly on the test(28.6).2.
Similar overfitting occurs when traditional ?1regularization is used to select features on8Available at http://svmlight.joachims.org379the sparse feature representation9 .
?1 reg-ularization is a good method of handlingsparse features for classification problems,but in reranking the lack of tying betweenlists makes this regularizer inappropriate.
Asmall set of around 1200 features are chosen:they perform well independently on each taskin the training data, but there is little sharingwith the test data.3.
All three multitask methods obtained featuresthat outperformed the baseline.
The BLEUscores are 28.8, 28.9, 29.1 for UnsupervisedFeature Selection, Joint Regularization, andShared Subspace, respectively, which all out-perform the 28.6 baseline.
All improvementsare statistically significant by bootstrap sam-pling test (1000 samples, p < 0.05) (Zhanget al, 2004).4.
Shared Subspace performed the best.
Weconjecture this is because its feature projec-tion can create new feature combinations thatis more expressive than the feature selectionused by the two other methods.5.
PER results are qualitatively similar to BLEUresults.6.
As a further analysis, we are interested in see-ing whether multitask learning extracts novelfeatures, especially those that have low fre-quency.
Thus, we tried an additional featurerepresentation (feature threshold) which onlykeeps features that occur in more than x N-bests, and concatenate these high-frequencyfeatures to the multitask features.
The fea-ture threshold alone achieves nice BLEU re-sults (29.0 for x > 10), but the combinationoutperforms it by statistically significant mar-gins (29.3-29.6).
This implies that multitasklearning is extracting features that comple-ment well with high frequency features.For the multitask features, improvements of 0.2to 1.0 BLEU are modest but consistent.
Figure2 shows the BLEU of bootstrap samples obtainedas part of the statistical significance test.
We seethat multitask almost never underperform base-line in any random sampling of the data.
This im-plies that the proposed meta-algorithm is very sta-9Optimized by the Vowpal Wabbit toolkit:http://hunch.net/vw/ble, i.e.
it is not a method that sometimes improvesand sometimes degrades.Finally, a potential question to ask is: whatkinds of features are being selected by themultitask learning algorithms?
We found thatthat two kinds of features are usually selected:one is general features that are not lexicalized,such as ?count of phrases?, ?count of dele-tions/insertions?, ?number of punctuation marks?.The other kind is lexicalized features, such asthose in Equations 2 and 3, but involving functionswords (like the Japanese characters ?wa?, ?ga?,?ni?, ?de?)
or special characters (such as numeralsymbol and punctuation).
These are features thatcan be expected to be widely applicable, and it ispromising that multitask learning is able to recoverthese from the millions of potential features.
10?0.2 0 0.2 0.4 0.6 0.8 1 1.2050100150200250300BLEU(shared subspace)?BLEU(baseline sparse feature)BootstrapsamplesFigure 2: BLEU difference of 1000 bootstrap sam-ples.
95% confidence interval is [.15, .90] Theproposed approach therefore seems to be a stablemethod.5 Related Work in NLPPrevious reranking work in NLP can be classifiedinto two different research focuses:1.
Engineering better features: In MT, (Ochand others, 2004) investigates features extractedfrom a wide variety of syntactic representations,such as parse tree probability on the outputs.
Al-though their results show that the proposed syntac-tic features gave little improvements, they point tosome potential reasons, such as domain mismatchfor the parser and overfitting by the reranking10Note: In order to do this analysis, we needed to run JointRegularization on the original feature representation, sincethe hashed representations are less interpretable.
This turnsout to be computationally prohibitive in the time being so weonly ran on a smaller data set of 50 lists.
Recently new op-timization methods that are orders of magnitude faster havebeen developed (Liu et al, 2009), which makes larger-scaleexperiments possible.380Train Test TestFeature Representation #Feature BLEU BLEU PER(baselines)First pass 20 29.5 28.5 38.3All sparse features (Main baseline) 2.4M 36.9 28.6 38.2All sparse features w/ ?1 regularization 1200 36.5 28.5 38.6Random hash representation 4000 33.0 28.5 38.2(multitask learning)Unsupervised FeatureSelect 500 32.0 28.8 37.7Joint Regularization 250 31.8 28.9 37.5Shared Subspace 1000 32.9 29.1 37.3(combination w/ high-frequency features)(a) Feature threshold x > 100 3k 31.7 27.9 38.2(b) Feature threshold x > 10 60k 35.8 29.0 37.9Unsupervised FeatureSelect + (b) 60.5k 36.2 29.3 37.6Joint Regularization + (b) 60.25k 36.1 29.4 37.5Shared Subspace + (b) 61k 36.2 29.6 37.3Oracle (best possible) ?
36.9 36.9 33.1Table 2: Results for different feature sets, with corresponding feature size and train/test BLEU/PER.
Allmultitask features give statistically significant improvements over the baselines (boldfaced), e.g.
SharedSubspace: 29.1 BLEU vs Baseline: 28.6 BLEU.
Combinations of multitask features with high frequencyfeatures also give significant improvements over the high frequency features alone.method.
Recent work by (Chiang et al, 2009) de-scribes new features for hierarchical phrase-basedMT, while (Collins and Koo, 2005) describesfeatures for parsing.
Evaluation campaigns likeWMT (Callison-Burch et al, 2009) and IWSLT(Paul, 2009) also contains a wealth of informationfor feature engineering in various MT tasks.2.
Designing better training algorithms: N-best reranking can be seen as a subproblem ofstructured prediction, so many general structuredprediction algorithms (c.f.
(Bakir et al, 2007))can be applied.
In fact, some structured predic-tion algorithms, such as the MIRA algorithm usedin dependency parsing (McDonald et al, 2005)and MT (Watanabe et al, 2007) uses iterativesets of N-best lists in its training process.
Othertraining algorithms include perceptron-style algo-rithms (Liang et al, 2006), MaxEnt (Charniak andJohnson, 2005), and boosting variants (Kudo et al,2005).The division into two research focuses is conve-nient, but may be suboptimal if the training algo-rithm and features do not match well together.
Ourwork can be seen as re-connecting the two focuses,where the training algorithm is explicitly used tohelp discover better features.Multitask learning is currently an active subfieldwithin machine learning.
There has already beensome applications in NLP: For example, (Col-lobert and Weston, 2008) uses a deep neural net-work architecture for multitask learning on part-of-speech tagging, chunking, semantic role label-ing, etc.
They showed that jointly learning theserelated tasks lead to overall improvements.
(De-selaers et al, 2009) applies similar methods formachine transliteration.
In information extraction,learning different relation types can be naturallycast as a multitask problem (Jiang, 2009; Carlsonet al, 2009).
Our work can be seen as followingthe same philosophy, but applied to N-best lists.In other areas, (Reichart et al, 2008) introducedan active learning strategy for annotating multitasklinguistic data.
(Blitzer et al, 2006) applies themultitask algorithm of (Ando and Zhang, 2005)to domain adaptation problems in NLP.
We expectthat more novel applications of multitask learningwill appear in NLP as the techniques become scal-able and standard.6 Discussion and ConclusionN-best reranking is a beneficial framework for ex-perimenting with large feature sets, but unfortu-nately feature sparsity leads to overfitting.
We ad-dressed this by re-casting N-best lists as multitask381learning data.
Our MT experiments show consis-tent statistically significant improvements.From the Bayesian view, multitask formulationof N-best lists is actually very natural: Each N-best is generated by a different data-generatingdistribution since the input sentences are different,i.e.
p(e|f1) 6= p(e|f2).
Yet these N-bests are re-lated since the general p(e|f) distribution dependson the same first-pass models.The multitask learning perspective opens upinteresting new possibilities for future work, e.g.:?
Different ways to partition data into tasks,e.g.
clustering lists by document structure, orhierarchical clustering of data?
Multitask learning on lattices or N-best listswith larger N. It is possible that a larger hy-pothesis space may improve the estimation oftask-specific weights.?
Comparing multitask learning to sparse on-line learning of batch data, e.g.
(Tsuruoka etal., 2009).?
Modifying the multitask objective to incorpo-rate application-specific loss/decoding, suchas Minimum Bayes Risk (Kumar and Byrne,2004)?
Using multitask learning to aid large-scalefeature engineering and visualization.AcknowledgmentsWe have received numerous helpful commentsthroughout the course of this work.
In partic-ular, we would like to thank Albert Au Yeung,Jun Suzuki, Shinji Watanabe, and the three anony-mous reviewers for their valuable suggestions.ReferencesJacob Abernethy, Peter Bartlett, and AlexanderRakhlin.
2007.
Multitask learning with expert ad-vice.
In COLT.Rie Ando and Tong Zhang.
2005.
A framework forlearning predictive structures from multiple tasksand unlabeled data.
JMLR.Andreas Argyriou, Theodoros Evgeniou, and Massim-iliano Pontil.
2008.
Convex multitask feature learn-ing.
Machine Learning, 73(3).G.
Bakir, T. Hofmann, B. Scholkopf, A. Smola,B.
Taskar, and S. V. N. Vishwanathan, editors.
2007.Predicting structured data.
MIT Press.J.
Blitzer, R. McDonald, and F. Pereira.
2006.
Domainadaptation with structural correspondence learning.In EMNLP.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Josh Schroeder.
2009.
Findings of the 2009workshop on statistical machine translation.
InWMT.Andrew Carlson, Justin Betteridge, Estevam Hruschka,and Tom Mitchell.
2009.
Coupling semi-supervisedlearning of categories and relations.
In NAACLWorkshop on Semi-supervised learning for NLP(SSLNLP).Rich Caruana.
1997.
Multitask learning.
MachineLearning, 28.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In ACL.David Chiang, Wei Wang, and Kevin Knight.
2009.11,001 new features for statistical machine transla-tion.
In NAACL.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33(2).Michael Collins and Terry Koo.
2005.
Discriminativereranking for natural langauge parsing.
Computa-tional Linguistics, 31(1).Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: deepneural networks with multitask learning.
In ICML.Hal Daume.
2009.
Bayesian multitask learning withlatent hierarchies.
In UAI.Thomas Deselaers, Sasa Hasan, Oliver Bender, andHermann Ney.
2009.
A deep learning approach tomachine transliteration.
In WMT.Jenny Rose Finkel and Chris Manning.
2009.
Hier-archical Bayesian domain adaptation.
In NAACL-HLT.Kuzman Ganchev and Mark Dredze.
2008.
Small sta-tistical models by random feature mixing.
In ACL-2008 Workshop on Mobile Language Processing.Jing Jiang.
2009.
Multitask transfer learning forweakly-supervised relation extraction.
In ACL.Taku Kudo, Jun Suzuki, and Hideki Isozaki.
2005.Boosting-based parse reranking with subtree fea-tures.
In ACL.Shankar Kumar and William Byrne.
2004.
Minimumbayes-risk decoding for statistical machine transla-tion.
In HLT-NAACL.P.
Liang, A. Bouchard-Cote, D. Klein, and B. Taskar.2006.
An end-to-end discriminative approach to ma-chine translation.
In ACL.382J.
Liu, S. Ji, and J. Ye.
2009.
Multi-task feature learn-ing via efficient l2,1-norm minimization.
In UAI.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005.
Online large margin training of de-pendency parsers.
In ACL.Guillaume Obozinski, Ben Taskar, and Michael Jor-dan.
2009.
Joint covariate selection and joint sub-space selection for multiple classification problems.Statistics and Computing.F.J.
Och et al 2004.
A smorgasbord of features forstatistical machine translation.
In HLT/NAACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automaticevaluation of machine translation.
In ACL.Michael Paul.
2009.
Overview of the iwslt 2009 eval-uation campaign.
In IWSLT.Ariadna Quattoni, Xavier Carreras, Michael Collins,and Trevor Darrell.
2009.
An efficient projectionfor L1-Linfinity regularization.
In ICML.Roi Reichart, Katrin Tomanek, Udo Hahn, and AriRappoport.
2008.
Multi-task active learning for lin-guistic annotations.
In ACL.Brian Roark, Murat Saraclar, and Michael Collins.2007.
Discriminative n-gram language modeling.Computer Speech and Language, 21(2).Libin Shen, Anoop Sarkar, and Franz Och.
2004.
Dis-criminative reranking for machine translation.
InHLT-NAACL.Yoshimasa Tsuruoka, Jun?ichi Tsujii, and Sophia Ana-niadou.
2009.
Stochastic gradient descent trainingfor l1-regularized log-linear models with cumulativepenalty.
In ACL-IJCNLP.Taro Watanabe, Jun Suzuki, Hajime Tsukada, andHideki Isozaki.
2007.
Online large-margin train-ing for statistical machine translation.
In EMNLP-CoNLL.Kilian Weinberger, Anirban Dasgupta, John Langford,Alex Smola, and Josh Attenberg.
2009.
Featurehashing for large scale multitask learning.
In ICML.Kai Yu and Volker Tresp.
2005.
Learning to learn andcollaborative filtering.
In NIPS-2005 Workshop onInductive Transfer.Ying Zhang, Stephan Vogel, and Alex Waibel.
2004.Interpreting BLEU/NIST scores: How much im-provement do we need to have a better system?
InLREC.383
