TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 17?24,Rochester, April 2007 c?2007 Association for Computational LinguisticsExtractive Automatic Summarization: Does more linguistic knowledgemake a difference?Daniel S. Leite1, Lucia H. M. Rino1, Thiago A. S. Pardo2, Maria das Gra?as V. Nunes2N?cleo Interinstitucional de Ling?
?stica Computacional (NILC)http://www.nilc.icmc.usp.br1Departamento de Computa?
?o, UFSCarCP 676, 13565-905 S?o Carlos - SP, Brazil2Instituto de Ci?ncias Matem?ticas e de Computa?
?o, Universidade de S?o PauloCP 668, 13560-970 S?o Carlos - SP, Brazil{daniel_leite; lucia}@dc.ufscar.br , {taspardo,gracan}@icmc.usp.brAbstractIn this article we address the usefulness oflinguistic-independent methods in extrac-tive Automatic Summarization, arguingthat linguistic knowledge is not only useful,but may be necessary to improve the in-formativeness of automatic extracts.
An as-sessment of four diverse AS methods onBrazilian Portuguese texts is presented tosupport our claim.
One of them is Mihal-cea?s TextRank; other two are modifiedversions of the former through the inclusionof varied linguistic features.
Finally, thefourth method employs machine learningtechniques, tackling more profound andlanguage-dependent knowledge.1 IntroductionUsually, automatic summarization involves produc-ing a condensed version of a source text throughselecting or generalizing its relevant content.
As aresult, either an extract or an abstract will be pro-duced.
An extract is produced by copying text seg-ments and pasting them into the final text preservingthe original order.
An abstract instead is producedby selecting and restructuring information from thesource text.
The resulting structure is thus linguisti-cally realized independently of the surface choicesof the source text.
This comprises, thus, a rewritingtask.This article focuses solely on extracts of sourcetexts written in Brazilian Portuguese.
For extrac-tive Automatic Summarization (AS), several meth-ods have been suggested that are based uponstatistics or data readily available in the sourcetext.
Word frequency (Luhn, 1958) and sentenceposition (Edmundson, 1969) methods are classicexamples of that.
Usually, extractive AS does nottake into account linguistic and semantic knowl-edge in order to be portable to distinct domains orlanguages (Mihalcea, 2005).
Graph-based methodsaim at the same and have been gaining a lot of in-terest because they usually do not rely on any lin-guistic resource and run pretty fast.
Exemplars ofthose are LexRank (Erkan and Radev, 2004) andTextRank (Mihalcea and Tarau, 2004).
In spite oftheir potentialities, we claim that there is a com-promise in pursuing a language-free setting: how-ever portable a system may be, it may also produceextracts that lack the degree of informativenessneeded for use.
Informativeness, in the currentcontext, refers to the ability of an automatic sum-marizer to produce summaries that convey mostinformation of reference, or ideal, summaries.
Ourassessment thus aimed at verifying if parsimonioususe of linguistic knowledge could improve extrac-tive AS.We argue that the lack of linguistic knowledgein extractive AS can be the reason for weak per-formance regarding informativeness.
This argu-ment follows from acknowledging thatimprovements on the scores usually obtained inthat field have not been expressive lately.
The mostcommon metrics used to date, precision and recall,signal average results, suggesting that it is notenough to pursue completely language-free sys-tems, no matter the current demands for portabilityin the global communication scenario.
We focushere on TextRank, which can be used for summa-17rizing Brazilian Portuguese texts due to its lan-guage independence.
To show that linguisticknowledge does make a difference in extractiveAS, we compared four automatic summarizers:TextRank itself, two other modified versions ofthat, and SuPor-2 (Leite and Rino, 2006).TextRank works in a completely unsupervisedway.
Our two variations, although stillunsupervised, include diverse linguistic knowledgein the preprocessing phase.
SuPor-2 is the onlymachine learning-based system amongst the fourones, and it was built to summarize texts inBrazilian Portuguese, although it may becustomized to other languages.
Unlike the others, itembeds more sophisticated decision features thatrely on varied linguistic resources.
Some of themcorrespond to full summarization methods bythemselves: Lexical Chaining (Barzilay andElhadad, 1997), Relationship Mapping (Salton etal., 1997), and Importance of Topics (Larocca Netoet al, 2000).
This is its unique and distinguishingcharacteristic.In what follows we first review the different lev-els of processing in extractive AS (Section 2), thenwe describe TextRank and its implementation tosummarize Brazilian Portuguese texts (Section 3).Our suggested modifications of TextRank are pre-sented in Section 4, whilst SuPor-2 is described inSection 5.
Finally, we compare the results of thefour automatic summarizers when running on Bra-zilian Portuguese texts (Section 6), and make someremarks on linguistic independence for extractiveAS in Section 7.2 A Review of Automatic SummarizationMani (2001) classifies AS methods based uponthree levels of linguistic processing to summarize atext, namely:?
Shallow level.
At this level only features at thesurface of the text are explored.
For example,location (Edmunson, 1969), sentence lengthand presence of signaling phrases (e.g., Kupiecet al, 1995).
Combined, such features mayyield a salience function that drives selectionof sentences of the source text to include in asummary.?
Entity level.
The aim here is to build an inter-nal representation of the source text that con-veys its entities and correspondingrelationships.
These amount to the informationthat allows identifying important text seg-ments.
Examples of such relations are wordcooccurrence (e.g., Salton et al, 1997), syno-nyms and antonyms (e.g., Barzilay and Elha-dad, 1997), logical relations, such asconcordance or contradiction, and syntacticrelations.?
Discourse level.
At this level the whole struc-ture of the source text is modeled, providedthat its communicative goals can be graspedfrom the source text.
The discourse structure isintended to help retrieving, e.g., the main top-ics of the document (e.g, Barzilay and Elha-dad, 1997; Larocca Neto et al, 2000) or itsrhetorical structure (e.g., Marcu, 1999), in or-der to provide the means for AS.In this work we mainly focus on the entity level.Special entities and their relations thus provide themeans to identify important sentences for buildingan extract.
In turn, there is a loss of independencefrom linguistic knowledge, when compared to shal-lower approaches.
Actually, apart from TextRank,the other systems described in this paper target en-tity level methods, as we shall see shortly.3 The TextRank MethodThe unsupervised TextRank method (Mihalcea andTarau, 2004) takes after Google?s PageRank (Brinand Page, 1998), a graph-based system that helpsjudge the relevance of a webpage through incomingand outgoing links.
PageRank directed graphs repre-sent webpages as nodes and their linking to otherwebpages as edges.
A random walk model is thusapplied to build a path between the nodes, in orderto grade the importance of a webpage in the graph.Similarly to grading webpages through travers-ing a graph, TextRank attempts to weight sentencesof a text by building an undirected graph.
Nodes arenow sentences, and edges express their similaritydegrees to other sentences in the text.
Actually, thedegree of similarity is based upon content overlap.As such, similarity degrees help assess the overallcohesive structure of a text.
The more content over-lap a sentence has with other sentences, the moreimportant it is and more likely it is to be included inthe extract.. Similarity is calculated through equa-tion [1] (Mihalcea and Tarau, 2004), where Si and Sjare sentences and wk is a common token between18them.
The numerator is the sum of common wordsbetween Si and Sj.
To reduce bias, normalization ofthe involved sentences length takes place, as showsthe denominator.|)log(||)log(||}|{|),(jijkikkji SSSwSwwSSSim +??
?=  [1]Once the graph and all similarity degrees areproduced, sentence importance is calculated by therandom walk algorithm shown in equation [2].TR(Vi) signals sentence importance, d is an arbitraryparameter in the interval [0,1], and N is the numberof sentences in the text.
Parameter d integrates theprobability of jumping from one vertex to anotherrandomly chosen.
Thus, it is responsible for randomwalking.
This parameter is normally set to 0.85 (thisvalue is also used in TextRank).?
?-= -=?????????????
?+-=1010),(),()()1()(NjNkkjjijiSSSimSSSimVTRddVTR  [2]Initial TR similarity values are randomly set inthe [0,1] interval.
After successive calculations,those values converge to the targeted importancevalue.
After calculating the importance of the verti-ces, the sentences are sorted in reverse order and thetop ones are selected to compose the extract.
Asusual, the number of sentences of the extract is de-pendent upon a given compression rate.Clearly, TextRank is not language dependent.For this reason Mihalcea (2005) could use it toevaluate AS on texts in Brazilian Portuguese, be-sides reporting results on texts in English.
She alsoexplored distinct means of representing a text with-out considering linguistic knowledge, emphasizingTextRank language and domain independence.
Shevaries, e.g., the ways the graphs could be traversedusing both directed and undirected graphs.
Once asentence is chosen to compose an extract, havingundirected graphs makes possible, to look forward ?from the sentence to its outgoing edges (i.e., focus-ing on the set of its following sentences in the text)?
or to look backward, considering that sentenceincoming edges and, thus, the set of its precedingsentences in the text.Another variation proposed by Mihalcea is toreplace the PageRank algorithm (Equation [2]) byHITS (Kleinberg, 1999).
This works quite simi-larly to PageRank.
However, instead of aggregat-ing the scores for both incoming and outgoinglinks of a node in just one final score, it producestwo independent scores.
These are correspondinglynamed ?authority?
and ?hub?
scores.4 Improving TextRank through varia-tions on linguistic informationTo improve the similarity scores between sen-tences in TextRank we fed it with more linguisticknowledge, yielding its two modified versions.
Thefirst variation focused just upon basic preprocess-ing; the second one, on the use of a thesaurus tocalculate semantic similarity to promote AS deci-sions.
However, we did not modify the main ex-tractive algorithm of TextRank: we kept the graphundirected and used PageRank as the score deter-miner.
Actually, we modified only the method ofcomputing the edges weights.4.1 Using Basic Preprocessing MethodsIn applying Equation 1 for similarity scores, onlyexact matches between two words are allowed.Since in Brazilian Portuguese there are many mor-phological and inflexional endings for most words,this process becomes troublesome: importantmatches may be ignored.
To overcome that, we useda stemmer for Brazilian Portuguese (Caldas Jr.
etal., 2001) based upon Porter?s algorithm (1980).
Wealso removed stopwords from the source text, be-cause they are not useful in determining similarity.The resulting version of TextRank is named hereaf-ter ?TextRank+Stem+StopwordsRem?.4.2 Using a ThesaurusOur second TextRank variation involved plugginginto the system a Brazilian Portuguese thesaurus(Dias-da-Silva et al, 2003).
Our hypothesis here isthat semantic similarity of the involved words isalso important to improve the informativeness ofthe extracts under production.
Thus, an extractivesummarizer should consider not only word repeti-tion in the source text, but also synonymy and an-tonymy.Although plugging the thesaurus into theautomatic summarizer did not imply changing itsmain method of calculating similarity, there weresome obstacles to overcome concerning the follow-ing:19Figure 1.
SuPor-2 training phaseFigure 2.
SuPor-2 extraction phasea) Should we consider only synonyms or bothsynonyms and antonyms in addition to termrepetition (reiteration)?b) How to acknowledge, and disentangle, se-mantic similarity, when polissemy, for ex-ample, is present?c) Once the proper relations have beendetermined, how should they be weighted?Just considering all thesaural relations to beequally important might not be the best ap-proach.Concerning (a), synonyms, antonyms, and termrepetition were all considered, as suggested by oth-ers (e.g., Barzilay and Elhadad, 1997).
We did nottackle (b) to choose the right sense of a word be-cause of the lack of an effective disambiguationprocedure for Brazilian Portuguese.
Finally, intackling (c) and, thus, grading the importance ofthe relations for sentence similarity, we adoptedthe same weights proposed by Barzilay and Elha-dad (1997) in their lexical chaining method, whichis discussed in more detail below.
For both reitera-tion and synonymy, they assume a score of 10 forthe considered lexical chain; for antonymy, theysuggest a score of 7.
The resulting version of Tex-tRank is named here ?TextRank+Thesaurus?.5 The SuPor-2 SystemSuPor-2 is an extractive summarizer built fromscratch for Brazilian Portuguese.
It embeds differ-ent features in order to identify and extract relevantsentences of a source text.
To configure SuPor-2for an adequate combination of such features weemploy a machine learning approach.
Figures 1and 2 depict the training and extraction phases,respectively.For training, machine learning is carried out by aNa?ve-Bayes classifier that employs Kernel meth-ods for numeric feature handling, known as Flexi-ble Bayes (John and Langley, 1995).
Thisenvironment is provided by WEKA1 (Witten andFrank, 2005), which is used within SuPor-2 itself.The training corpus comprises both source textsand corresponding reference extracts.
Every sen-tence from a source text is represented in the train-1 Waikato Environment for Knowledge Analysis.
Available athttp://www.cs.waikato.ac.nz/ml/weka/ (December, 2006)20ing dataset as a tuple of the considered features.Each tuple is labeled with its class, which signals ifthe sentence appears in a reference extract.
Theclass label will be true if the sentence under focusmatches a sentence of the reference extract andfalse otherwise.Once produced, the training dataset is used bythe Bayesian classifier to depict the sentences thatare candidates to compose the extract (Figure 2).
Inother words, the probability for the ?true?
class iscomputed and the top-ranked sentences are se-lected, until reaching the intended compressionrate.When computing features, three full methods(M) and four corpus-based parameters (P) are con-sidered.
Both methods and parameters are mappedonto the feature space and are defined as follows:(M) Lexical Chaining (Barzilay and Elhadad,1997).
This method computes the connectednessbetween words aiming at determining lexicalchains in the source text.
The stronger a lexicalchain, the more important it is considered for ex-traction.
Both an ontological resource and Word-Net (Miller et al, 1990) are used to identifydifferent relations, such as synonymy or antonym,hypernymy or hyponymy, that intervene to com-pute connectedness.
The lexical chains are thenused to produce three sets of sentences.
To identifyand extract sentences from those sets, three heuris-tics are  made available, namely: (H1) selectingevery sentence s of the source text based on eachmember m of every strong lexical chain of the text.In this case, s is the sentence that contains the firstoccurrence of m; (H2) this heuristics is similar tothe former one, but instead of considering all themembers of a strong lexical chain, it uses only therepresentative ones.
A representative member isone whose frequency is greater than the averagefrequency of all words in the chain; (H3) a sen-tence s is chosen by focusing only on representa-tive lexical chains of every topic of the source text.In SuPor-2, the mapping of this method onto anominal feature is accomplished by signalingwhich heuristics have recommended the sentence.Thus, features in the domain may range over thevalues {?None?, ?H1?, ?H2?, ?H3?, ?H1H2?,?H1H3?, ?H2H3?, ?H1H2H3?}.
(M) Relationship Mapping (Salton et al,1997).
This method performs similarly to the pre-vious one and also to TextRank in that it builds upa graph interconnecting text segments.
However, itconsiders paragraphs instead of sentences as verti-ces.
Hence, graph edges signal the connectivenessof the paragraphs of the source text.
Similarityscores between two paragraphs are thus related tothe degree of connectivity of the nodes.
Similarlyto Lexical Chaining, Salton et al also suggest threedifferent ways of producing extracts.
However,they now depend on the way the graph is traversed.The so-called dense or bushy path (P1), deep path(P2), and segmented path (P3) aim at tackling dis-tinct textual problems that may damage the qualityof the resulting extracts.
The dense path considersthat paragraphs are totally independent from eachother, focusing on the top-ranked ones (i.e., theones that are denser).
As a result, it does not guar-antee that an extract will be cohesive.
The deeppath is intended to overcome the former problemby choosing paragraphs that may be semanticallyinter-related.
Its drawback is that only one topic,even one that is irrelevant, may be conveyed in theextract.
Thus, it may lack proper coverage of thesource text.
Finally, the segmented path aims atovercoming the limitations of the former ones, ad-dressing all the topics at once.
Similarly to LexicalChaining, features in the Relationship methodrange over the set {?None?,?P1?,?P2?,?P3?, ?P1P2?,?P1P3?, ?P2P3?, ?P1P2P3?}.
(M) Importance of Topics (Larocca Neto etal., 2000).
This method also aims at identifying themain topics of the source text, however through theTextTiling algorithm (Hearst, 1993).
Once the top-ics of the source text have been determined, thefirst step is to select sentences that better expressthe importance of each topic.
The amount of sen-tences, in this case, is proportional to the topic im-portance.
The second step is to determine thesentences that will actually be included in the ex-tract.
This is carried out by measuring their simi-larity to their respective topic centroids (LaroccaNeto et al, 2000).
The method thus signals howrelevant a sentence is to a given topic.
In SuPor-2this method yields a numeric feature whose valueconveys the harmonic mean between the sentencesimilarity to the centroid of the topic in which itappears and the importance of that topic.
(P) Sentence Length (Kupiec et al, 1995).This parameter just signals the normalized count ofwords of a sentence.21(P) Sentence Location (Edmundson, 1969).This parameter takes into account the position of asentence in the text.
It is valued, thus, in{?II?,?IM?,?IF?,?MI?,?MM?,?MF?,?FI?,?FM?,?FF?
}.In this set the first letter of each label signals theposition of the sentence within a paragraph (Initial,Medium, or Final).
Similarly, the second letter sig-nals the position of the paragraph within the text.
(P) Occurrence of proper nouns (e.g., Kupiecet al, 1995).
This parameter accounts for the num-ber of proper nouns in a sentence.
(P) Word Frequency (Luhn, 1958).
This pa-rameter mirrors the normalized sum of the wordfrequency in a sentence.SuPor-2 provides a flexible way of combininglinguistic and non-linguistic features for extraction.There are profound differences from TextRank.First, it is clearly language-dependent.
Also, itsgraph-based methods do not assign weights to theirvertices in order to select sentences for extraction.Instead, they traverse a graph in very specific  andvaried ways that mirror both linguistic interde-pendencies and important connections between thenodes.6 Assessing the Four SystemsTo assess the degree of informativeness of the sys-tems previously described, we adopt ROUGE2 (Linand Hovy, 2003), whose recall rate mirrors the in-formativeness degree of automatically generatedextracts by correlating automatic summaries withideal ones.The two modified versions of TextRank requirelinguistic knowledge but at a low cost.
This is cer-tainly due to varying only preprocessing, while themain decision procedure is kept unchanged andlanguage-independent.
Those three systems do notneed training, one of the main arguments in favorof TextRank (Mihalcea and Tarau, 2004).
In con-trast, SuPor-2 relies on training and this is certainlyone of its main bottlenecks.
It also employs lin-guistic knowledge for both preprocessing and ex-traction, which TextRank purposefully avoids.However, using WEKA has made its adjustmentsless demanding and more consistent, indicatingthat scaling up the system is feasible.2 Recall-Oriented Understudy for Gisting Evaluation.
Avail-able at http://haydn.isi.edu/ROUGE/ (January, 2007).In our assessment, the same single-documentsummarization scenario posed by Mihalcea (2005)was adopted, namely: (a) we considered the Brazil-ian Portuguese TeM?rio corpus (Pardo and Rino,2003); (b) we used the same baseline, which se-lects top-first sentences to include in the extract;(c) we adopted a 70-75% compression rate, makingit compatible with the compression rate of the ref-erence summaries; and (d) ROUGE was used forevaluation in its Ngram(1,1) 95% confidence ratesetting, without stopwords removal.
TeM?rio com-prises 100 newspaper articles from online Braziliannewswire.
A set of corresponding manual summa-ries produced by an expert in Brazilian Portugueseis also included in TeM?rio.
These are our refer-ence summaries.For training and testing SuPor-2, we avoidedbuilding an additional training corpus by using a10-fold cross-validation procedure.
Finally, weproduced three sets of extracts using ?TextRank +Stem + StopwordsRem?, ?TextRank + Thesaurus?,and SuPor-2 on the TeM?rio source texts.
Resultsfor informativeness are shown in Table 1.
SinceMihalcea?s setting was kept unchanged, we justincluded in that table the same results presented in(Mihalcea, 2005), i.e., we did not run her systemsall over again.
We also reproduced for comparisonthe TextRank variations reported by Mihalcea, es-pecially regarding graph-based walks by PageRankand HITS.
Shaded lines correspond to our sug-gested methods presented in Sections 4 and 5,which involve differing degrees of dependence onlinguistic knowledge.It can be seen that ?TextRank+Thesaurus?
and?TextRank+Stem+StopwordsRem?
considerablyoutperformed all other versions of TextRank.Compared with Mihalcea's best version, i.e., with'TextRank (PageRank - backward)', those twomethods represented a 6% and 9% improvement,respectively.
We can conclude that neither the waythe graph is built nor the choice of the graph-basedranking algorithm affects the results as signifi-cantly as do the linguistic-based methods.
Clearly,both variations proposed in this paper signal thatlinguistic knowledge, even if only used at the pre-processing stage, provides more informative ex-tracts than those produced when no linguisticknowledge at all is considered.
Moreover, at thatstage little modeling and computational effort isdemanded, since lexicons, stoplists, and thesauri22are quite widely available nowadays for severalRomance languages.Even the baseline outperformed most versionsof TextRank, showing that linguistic independencein a random walk model for extractive AS shouldbe reconsidered.
Actually, this shows that linguis-tic knowledge does make a difference, at least forsummarizing newswire texts in Brazilian Portu-guese.In addition, SuPor-2 performance exceeds thebest version of TextRank that uses no linguisticknowledge ?
?TextRank (PageRank - backward)?
?by about 14%.System ROUGE NGram(1,1)SuPor-2 0,5839TextRank+Thesaurus 0,5603TextRank+Stem+StopwordsRem 0,5426TextRank (PageRank - backward) 0,5121TextRank (HIT hub - forward) 0,5002TextRank (HITS authority - backward) 0,5002Baseline 0,4963TextRank (PageRank - undirected) 0,4939TextRank (HITS authority - forward) 0,4834TextRank (HIT hub - backward) 0,4834TextRank (HITS authority - undirected) 0,4814TextRank (HIT hub - undirected) 0,4814TextRank (PageRank - forward) 0,4574Table 1.
Informativeness comparison between ex-tractive summarizers7 Final RemarksA critical issue in the comparison presented aboveis the contrast between having an unsupervised orsupervised summarizer, which is related to the is-sue on having linguistic-independent extractivesummarizers.
Perhaps the question that we shouldpose here is how interesting and useful an extrac-tive automatic summarizer that is totally independ-ent from linguistic knowledge can actually be.
Toour view, the more non-informative an extract, theless useful it may be.
So, summarizers that do notreach a minimum threshold concerning informa-tiveness are deemed to failure nowadays.
Clearly,SuPor-2 requires language-dependent resources,but its main extraction procedure is still generalenough to make it portable and adaptable to newdomains and languages.
Hence, SuPor-2 assess-ment suggests that it may be interesting to scale upSuPor-2.Considering that SuPor-2 is one of the best ex-tractive summarizers for Brazilian Portuguese texts(Leite and Rino, 2006) and ?TextRank+Thesaurus?performed only 4% below it, we can also argue  infavor of providing even simple linguistic proce-dures for extractive AS.
The latter system showsthat TextRank can yield extracts nearly as informa-tive as those produced by the former, when em-bedding stemming and stopwords removal.
It canalso perform AS with little computational effortand no training, when compared to the supervisedSuPor-2.
As a conclusion, we see that some lin-guistic knowledge may boost TextRank perform-ance without too much effort, since language-dependent resources for preprocessing texts innatural language are usually available and easy tohandle, concerning our addressed approach.There are many experiments that may be derivedfrom our discussion in this paper (1) Although thereported results suggest that linguistic knowledgedoes make a difference when embedded in lan-guage-free extractive summarizers, the perform-ance of the top systems assessed through ROUGEshould be more comprehensively licensed throughadditional assessment tasks.
(2) These could alsoincorporate other graph-based algorithms thanTextRank, such as the LexRank one, aiming at re-assuring our claim and scaling up graph-based ap-proaches.
(3) Since we addressed language-independence (thus portability) versus language-dependence for informativeness, it would also beinteresting to explore other domains or languagesto support our claim or, at least, to look for otherfindings to confirm if linguistic knowledge indeedmakes a difference.
(4) Other TextRank variationscould also be explored, to see if adding more fea-tures would make TextRank closer to SuPor-2.AcknowledgementsThis work has been supported by the Brazilian re-search funding agencies CNPq, CAPES andFAPESP.23ReferencesB.
C. Dias-da-Silva, M. F. Oliveira, H. R. Moraes, C.Paschoalino, R. Hasegawa, D. Amorin and A. C.Nascimento.
2000.
Constru?
?o de um Thesaurus Ele-tr?nico para o Portugu?s do Brasil.
In Proceedings ofthe V Encontro para o Processamento Computacio-nal da L?ngua Portuguesa Escrita e Falada(PROPOR 2000), S?o Carlos, Brasil , 1-11.C.
Lin and E. H. Hovy.
2003.
Automatic Evaluation ofSummaries Using N-gram Co-occurrence Statistics.In Proceedings of Language Technology Conference(HLT-NAACL 2003), Edmonton, Canada.D.
Marcu.
1999.
Discourse Trees Are Good Indicatorsof Importance in Text.
In Mani, I., Maybury, M.
T.(Eds.).
1999.
Advances in Automatic Text Summari-zation.
MIT Press.D.
S. Leite and L. H. M. Rino.
2006.
Selecting a FeatureSet to Summarize Texts in Brazilian Portuguese.
In J.S.
Sichman et al (eds.
): Proceedings of 18th.
Brazil-ian Symposium on Artificial Intelligence (SBIA'06)and 10th.
Ibero-American Artificial Intelligence Con-ference (IBERAMIA'06).
Lecture Notes on ArtificialIntelligence, No.
4140, Springer-Verlag, 462-471.G.
Erkan and D R. Radev.
2004.
LexRank: Graph-basedLexical Centrality as Salience in Text Summariza-tion.
Journal of Artificial Intelligence Research22:457-479G.
A. Miller, R. Beckwith, C. Fellbaum, D. Gross andK.
Miller.
1990.
Introduction to WordNet: An On-line Lexical Database.
International Journal of Lexi-cography 3(4):235-244G.
Salton, and C. Buckley.
1988.
Term-weighting ap-proaches in automatic text retrieval.
InformationProcessing & Management 24 : 513-523.. Reprintedin: K. Sparck-Jones and P. Willet (eds.).
1997.
Read-ings in Information Retrieval, Morgan Kaufmann,323-328.H.
Luhn.
1958.
The automatic creation of literature ab-stracts.
IBM Journal of Research and Development2:159-165H.
P. Edmundson.
1969.
New methods in automaticextracting.
Journal of the Association for ComputingMachinery 16:264-285.I.
Witten and E. Frank.
2005.
Data Mining: Practicalmachine learning tools and techniques, 2nd ed.
Mor-gan Kaufmann, San Francisco.I.
Mani.
2001.
Automatic Summarization.
John Benja-min?s Publishing Company.I.
Mani and M. T. Maybury.
1999.
Advances in Auto-matic Text Summarization.
MIT Press.J.
Caldas Junior, C. Y. M. Imamura and S. O.
Rezende.Avalia?
?o de um Algoritmo de Stemming para aL?ngua Portuguesa.
In Proceedings of the 2nd Con-gress of Logic Applied to Technology(LABTEC?2001), vol.
II.
Faculdade SENAC de Ci?n-cias Exatas e Tecnologia, S?o Paulo, Brasil (2001),267-274.J.
M. Kleinberg.
1999.
Authoritative sources in hyper-linked environment.
Journal of the ACM, 46(5):604-632.J.
Kupiec, J. Pedersen and F. Chen.
1995.
A trainabledocument summarizer.
In Proceedings of the 18thACM-SIGIR Conference on Research & Develop-ment in Information Retrieval, 68-73.J.
Larocca Neto, A. D. Santos, C. A.
A. Kaestner and A.A. Freitas.
2000.
Generating Text Summariesthrough the Relative Importance of Topics.
LectureNotes in Artificial Intelligence, No.
1952.
Springer-Verlag, 200-309M.
A. Hearst.
1993.
TextTiling: A Quantitative Ap-proach to Discourse Segmentation.
Technical Report93/24.
University of California, Berkeley.M.
F. Porter.
1980.
An Algorithm for Suffix Stripping.Program, 14 (3) : 130-137R.
Mihalcea and P. Tarau.
2004.
TextRank: BringingOrder into Texts.
In  Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP 2004), Barcelona, Spain, July.R.
Mihalcea.
2005.
Language Independent ExtractiveSummarization.
In Proceedings of the 43th AnnualMeeting of the Association for Computational Lin-guistics, Companion Volume (ACL2005), Ann Ar-bor, MI, June.R.
Barzilay and M. Elhadad.
1997.
Using lexical chainsfor text summarization.
In Proceedings of the Intelli-gent Scalable Text Summarization Workshop(ISTS'97), ACL, Madrid, Spain.S.
Brin and L. Page.
1998.
The anatomy of a large-scalehypertextual Web search engine.
Computer Networksand ISDN Systems 30:1-7.T.
A. S. Pardo and L.H.M.
Rino.
2003.
TeM?rio: A cor-pus for automatic text summarization (in Portu-guese).
NILC Tech.
Report NILC-TR-03-0924
