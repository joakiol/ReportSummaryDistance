Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 63?72,Atlanta, Georgia, June 13 2013. c?2013 Association for Computational LinguisticsRole of Morpho-Syntactic Features in Estonian Proficiency ClassificationSowmya VajjalaSeminar fu?r SprachwissenschaftUniversita?t Tu?bingensowmya@sfs.uni-tuebingen.deKaidi Lo?oSeminar fu?r SprachwissenschaftUniversita?t Tu?bingenkaidi.loo@student.uni-tuebingen.deAbstractWe developed an approach to predict the pro-ficiency level of Estonian language learnersbased on the CEFR guidelines.
We performedlearner classification by studying morpho-syntactic variation and lexical richness in textsproduced by learners of Estonian as a sec-ond language.
We show that our featureswhich exploit the rich morphology of Esto-nian by focusing on the nominal case and ver-bal mood are useful predictors for this task.We also show that re-formulating the classifi-cation problem as a multi-stage cascaded clas-sification improves the classification accuracy.Finally, we also studied the effect of trainingdata size on classification accuracy and foundthat more training data is beneficial in onlysome of the cases.1 Introduction and MotivationEvery year, language learners across the world learnvarious languages and take tests that measure theirproficiency level.
The Estonian language profi-ciency examination1 in particular is usually takenby the immigrant population for citizenship and/oremployment needs in Estonia.
Assessing learnertexts to classify them into relevant proficiency lev-els is usually done by human evaluators and is of-ten a time consuming process.
An approach to au-tomate this process would complement the humanannotators and reduce the overall effort in evaluat-ing learner texts for their proficiency.
Investigat-ing features that follow any sort of trend across the1http://www.ekk.edu.ee/various proficiency levels among learners is a firststep in building such automatic proficiency classifi-cation systems.
This is the main motivation for ourresearch.Several factors might play a role in determining alearner?s proficiency in a given language.
Since westudy the learner corpus of Estonian, a morphologi-cally complex language with an elaborate declensionand conjugation system, we hypothesized that study-ing the role of morpho-syntactic features would be agood starting point to perform proficiency classifi-cation.
We used the Estonian Interlanguage Corpus(EIC)2, a publicly accessible corpus of written textsproduced by learners of Estonian as a second lan-guage, for this purpose.
All the texts were annotatedwith a proficiency level that is based on the Com-mon European Framework of Reference for Lan-guages Council of Europe (CEFR).
We constructedvarious proficiency classification models based onthis corpus by using features motivated primarily bythe morphological complexity of Estonian and foundthat true to our hypothesis, they turn out to be goodpredictors of the proficiency level.We also studied the effect of breaking up themain classification task into sub-tasks and cascad-ing them.
We show that this approach increases theoverall accuracy of proficiency classification.
In ad-dition, we studied the effect of training data size andfound that it does not have a significant impact inmost of the classification tasks we performed.
Tosummarize, we studied the task of proficiency clas-sification for Estonian by studying both the aspectsfeature engineering and model construction.2http://evkk.tlu.ee/wwwdata/what_is_evk63The rest of this paper is organized as follows: Sec-tion 2 briefly surveys related work and explains thecontext of our research.
Section 3 describes our cor-pus and the experimental setup.
Section 4 describesour feature set.
Section 5 describes our experimentsand results.
Section 6 concludes the paper with adiscussion on results and directions for future work.2 Related WorkWith the availability of computer based learner cor-pora, research focusing on studying the criterial fea-tures that correlate with proficiency levels began toemerge.
A wide body of research exists on studyingthe syntactic complexity of texts produced by learn-ers across different proficiency levels, their lexicalrichness and the errors they make (e.g., Lu, 2012;Vyatkina, 2012; Tono, 2000) .
Learner data fromboth longitudinal and cross sectional studies was an-alyzed to understand the linguistic patterns amonglearners of different proficiency levels, in SecondLanguage Acquisition (SLA) research.Automatic proficiency assessment of learner textsis another active area of related research, whichplays an important role in language testing.
Auto-mated systems are now being used both for evalua-tion of language learners and for offering feedbackon their language proficiency (e.g., Williamson,2009; Burstein et al 2003 ).
Forms of text used forassessment include mathematical responses, shortanswers, essays and spoken responses among oth-ers (Williamson et al 2010).
Standardized tests likeGRE and GMAT too use such systems to comple-ment human scorers while evaluating student essaysautomatically (Burstein, 2003; Rudner et al 2005).Zhang (2008) discusses proficiency classification forthe Examination for the Certificate of Proficiencyin English (ECPE) in detail, by comparing proce-dures based on four types of measurement models.The problem of automatic student classification i.e.,making inferences about a student?s skill level by us-ing some form of data about them is an active areaof research in Educational data mining (e.g., Des-marais and Baker, 2012; Baker 2010).But, automatic approaches for classifying lan-guage learners into standardized proficiency levels(e.g., the European CEFR levels3, Common Core3http://www.coe.int/t/dg4/linguistic/Standards4) is a relatively new area of interest.Supnithi et al(2003) used a dataset consisting ofaudio transcripts by Japanese learners of English tobuild a proficiency classification model with a fea-ture set that modeled vocabulary, grammatical accu-racy and fluency.
This dataset had 10 levels of pro-ficiency.
Hasan and Khaing (2008) performed profi-ciency classification with the same dataset using er-ror rate and fluency features.
Dickinson et al(2012)developed a system for classifying Hebrew learnersinto five proficiency levels, using features that focuson the nature of errors in a corpus of scrambled sen-tence exercise questions.Proficiency Classification so far has been predom-inantly focused on the correlation of error-rate withproficiency.
Although error-rate is a strong indicatorof a learner?s proficiency in a language, consider-ing other factors like lexical indices or syntactic andmorphological complexity would help in providingmultiple views about the same data.
Providing anon-error driven model, Crossley et al(2011) stud-ied the impact of various lexical indices in predictingthe learner proficiency level.
Using a corpus of 100writing samples by L2 learners of English classifiedin to three levels (beginner, intermediate, advanced),they built a classification system that analyses lan-guage proficiency using the Coh-metrix5 lexical in-dices.Most of the research about the distinguishing fac-tors among learners of various proficiency levels hasfocused on English.
However, issues like morpho-logical variation, which may not be strong predic-tors of learner proficiency in English, could be use-ful in proficiency classification of other languages.Hence, in this paper, we study the texts produced bythe learners of a morphologically rich and complexlanguage, Estonian and show that morphology canbe a good predictor for learner proficiency classifi-cation.We build our classification models using the Es-tonian Interlanguage Corpus (EIC), which containstexts produced by learners of Estonian as a secondlanguage.
We modeled our approach based on thefeatures motivated by the morphological complex-ity of Estonian.
To our knowledge, this is the firstCadre1_en.asp4http://www.corestandards.org/5http://cohmetrix.memphis.edu64work that studies the role of morphology based fea-tures for proficiency classification in general and inEstonian in particular.3 Corpus and Experimental Setup3.1 CorpusThe Estonian Interlanguage Corpus (EIC)6 was cre-ated by the Talinn University.
It is a collection ofwritten texts produced by learners of Estonian as asecond language.
Most of the learners were nativespeakers of Russian.
The corpus consists mainly ofshort essays, answers to questions, translations andpersonal letters.
The texts are annotated with errortypes and incorrect forms.
The corpus also providesinformation about the learner?s age, gender, educa-tion and about other languages known to the learner.Descriptive statistics about the corpus are availableon their website7.
The corpus contains around 8000documents (two million words), most of which aretexts from the Estonian language proficiency exam-ination.
The length of the texts varies in general be-tween 50 and 1000 words (Eslon, 2007).Information about the learner?s level of compe-tence is based on the CEFR guidelines8 and is de-cided by human annotator judgement.
Until late2008, Estonian language proficiency was tested byconducting proficiency exams at three levels - thelowest level A, the medium level B and the highestlevel C. Later, the CEFR standards were adapted, di-viding the development of language proficiency intosix levels (A1, A2, B1, B2, C1, C2).
A1 indicates abasic proficiency and C2 indicates a mastery.For our current work, we use a sub-corpus con-sisting of 2000 texts that can be accessibly throughthe EIC.
These texts are spread across three broadlevels A, B, C instead of the more fine grained sixlevels and contain all kinds of texts including shortanswers.
Although these texts also have an an-notated version containing information about error-types and corrections, since our aim in this paper isto study the effect of morpho-syntactic features, weconsidered the raw texts produced by the learners as6http://evkk.tlu.ee/7http://evkk.tlu.ee/statistics.html8http://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languagesthey were, without looking at the error annotations.Table 1 shows a summary of the entire corpus thatwas made available.We prepared a test set consisting of 50 documentsfrom each category, picked randomly.
This test setwas not used to train any of the classifiers we usedin this paper.
Further, to avoid a training bias to-wards any class, we used equal number of instancesfrom all classes during all our binary and three-classtraining processes.Proficiency Level #Docs Avg.
#tokensA-level 807 182.9B-level 876 260.3C-level 307 431.8Table 1: The EIC Corpus3.2 Pre-processingAll the texts in our corpus were POS-tagged with theTreeTagger9 and the tagged output was then usedto extract the required features.
The TreeTagger(Schmid, 1994) is a probabilistic part of speech tag-ger, which contains parameter files to tag Estoniandata.
The tag set was derived from the Tartu Mor-phologically Disambiguated Corpus tag set10.
Asmentioned earlier, we do not use the error annotationinformation for these learner texts, in this paper.4 FeaturesOur choice of features were primarily motivated bythe nature of the morphology of Estonian.4.1 The Estonian LanguageThe Estonian language has about one million nativespeakers.
It belongs to the Finnic branch of Uraliclanguages and is known for it?s complex morphol-ogy.
It is both an agglutinative and a flectional (fu-sional) language.
Some of the prominent features ofEstonian language include:?
14 productive nominal cases9http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/10http://www.cl.ut.ee/korpused/morfkorpus/65?
no grammatical gender (either of nouns or per-sonal pronouns) and no articles (either definiteor indefinite)?
the verbal system lacks a morphological futuretense (the present tense is used instead)?
relatively free word order (relations betweenwords are expressed by case endings)?
extensive compound word formation?
impersonal voice (specific to the Finnic lan-guages and similar to passive voice.
The verbis conjugated in ?fourth person?, who is nevermentioned)?
Most of the inflected words in Estonian havetwo distinctive parts: the stem and the forma-tive.
For example, raamatutele (book, plural,allative) consists of the stem raamatu and theformative tele, which in turn consists of pluralmarker te and allative case marker le (Erelt etal., 2007, p.
203).?
Unlike most of other Finnic languages, Esto-nian also has flective features, i.e., the samemorpheme may have different shapes in differ-ent word forms.
For example, the stem jalg(?foot?, singular, nominative) may appear asjala (singular, genitive) or jalga (singular, par-titive) and plural marker may appear as d, de,te or i or merged with the stem as in jalad(plural, nominative), jalgade (plural, genitive)and jalgu (plural, partitive) (Erelt et al 2007,p.
203).As many of these characteristics are morpholog-ical in nature, we hypothesized that this morpho-logical complexity of Estonian may play a role inthe process of language learning and hence maybe a useful predictor for proficiency classification.Hence, we built our feature set primarily focusingon the morphological properties of the learner texts.Apart from these features, we also included otherfeatures based on the Parts of Speech and lexicalvariation.4.2 Morphological FeaturesIn Estonian, as in other Finnic languages, nomi-nals (nouns, adjectives, numerals and pronouns) andverbs are inflected for number and case.
Estoniannominals are inflected in 14 different cases.
Three ofthe nominal cases are grammatical cases, i.e., nom-inative, genitive and partitive.
They fulfill mainlya syntactic purpose and have a very general gram-matical meaning.
All the other cases are semanticcases, and they have a more concrete meaning thangrammatical cases, which often can be explained bymeans of adverbs or adpositions (Erelt et al 2007,p.
241).
We considered the proportion of nouns andadjectives tagged with various cases per documentand included them as our declension features.
Thecases we considered in this paper are: nominative,genitive, partitive, illative, inessive, elative, allative,adessive, ablative, translative, terminative, essive,abessive, comitative and short singular illative, i.e.,aditive case.The verb in Estonian has finite forms that occuras predicates and auxiliary components of complexpredicates and non-finite forms.
Finite forms are in-flected for mood, tense, voice, aspect, person andnumber.
The verb has altogether five moods: the in-dicative, conditional, imperative, quotative and jus-sive.
It has two simple tenses: the present and thepast, two voices: personal and impersonal, affirma-tion and negation.
Non-finite forms behave differ-ently.
Participles are inflected for voice and tense,present participles also for case and number, andsupines for voice and case.
There is one infinitiveand one gerund, which can be explained as the ines-sive case form of the infinitve (Erelt, 2003, p. 52).
Inthis paper, we considered the proportion of verbs be-longing to various tense, mood, voice, number andperson categories as our features.11.4.3 POS featuresWe included the various degrees of comparison ofadjectives and the proportion of words belonging tovarious parts of speech among our features.
Thisgroup of features also included the proportion of ad-positions (=prepositions+postpositions) along withthe proportion of prepositions and postpositions sep-arately.
We also included the proportion of co-ordinating conjunctions and subordinating conjunc-tions along with that of all conjunctions.11Examples of various forms of declension and conjugationcan be found in the Estonian morphology guide at: http://lpcs.math.msu.su/?pentus/etmorf.htm664.4 Lexical Variation featuresLexical variation, also called lexical range indicatesthe range of vocabulary displayed in a learner?s lan-guage use.
We implemented the measures of lexicalvariation that are used in the English SLA researchto measure the lexical richness of the learners of En-glish as a second language (Lu, 2012).
These in-cluded the noun variation, verb variation, adjectivevariation and verb variation which indicated the ra-tio of the words with the respective parts of speechto the total number of lexical words (instead of allwords).4.5 Text Length FeatureSince text length is one of the most commonly usedmeasures of learner proficiency and also because ofthe variation in average text length across the pro-ficiency levels (Table1), we included the number ofword tokens per document as a feature.4.6 Most Predictive FeaturesApart from these individual feature groups, we alsoperformed a feature selection, to identify the mostpredictive ones among all our features.
We used theCorrelation based Feature Subset (CFS) selectionmethod in WEKA for this purpose.
CFS choosesa feature subset considering the correlation and thedegree of redundancy between the features.
Table 2consists of a list of the most predictive and non-redundant features after ranking all the selected fea-tures based on their Information Gain.
This list con-sisted of five verb morphology based features fol-lowed by three nominal declension features.Feature GroupNominative case NounMorphImpersonal VerbMorphPersonal VerbMorphNum.
words TextLengthPresent tense VerbMorph2nd person verbs VerbMorphPrepositions POSAllative case NounMorphImperatives VerbMorphTranslative case NounMorphTable 2: 10 Most Predictive, Non-redundant FeaturesIt is interesting to note that several characteris-tics that are prominent in Estonian (cf.
Section 4.1)figured among this list of most predictive features.Nominative being the top predictor can be explaineddue to the difference in (the number of) cases be-tween Estonian and other languages.
For example(Eslon, 2011) found in her corpus study based on thesame corpus that the learners frequently use nom-inative case instead of genitive and partitive case.So, it is to be expected that the usage of the nom-inative case changes as the proficiency increases.Impersonal and personal voice are distinctive fea-tures in Estonian and other Finnic languages, asthey are different from the active and passive voicethat typically exist in other languages (Erelt, 2003).This may make them difficult to master for languagelearners, making them one of the top predictors forproficiency.
Further, Estonian has more postposi-tions than prepositions.
Hence, one could that theuse of prepositions will be replaced by postposi-tions as the language acquisition progresses (Ehala,1994).5 Experiments and ResultsWe first studied the effect of the individual featuregroups as well as their combination for a three classclassification of Estonian learners into A, B and Cclasses.
We also studied the impact of a stackingensemble on the overall classification accuracy andfound out that it did not result in a significant im-provement on the test set.
Hence, we further investi-gated the problem as a collection of multi-stage two-class cascades instead of a single stage three classclassification.
For all our classification experiments,we used the WEKA (Hall et al 2009) toolkit.
Wereport the overall classification accuracy as our eval-uation metric.5.1 Three Class-ClassificationWe first considered the learner classification as a sin-gle step, three class classification problem.
Since50 documents from each category were separated asa held-out test set (cf.
Section 3.1), we built ourthree-class models with 250 texts per category as ourtraining set to ensure that there is a balanced distri-bution between classes.
We trained multiple clas-sification models considering the individual feature67groups and the most predictive feature group.
Ta-ble 3 shows the classification accuracy of variousfeature groups, reported using the Sequential Mini-mal Optimization (SMO) implementation in WEKA(Platt, 1998).Features 10-Fold CV Test setRandom baseline 33.33% 33.33%Noun Morph.
56.64% 52%Verb Morph 57.55% 58%POS 52.99% 47.33%Lex.
Variation 43.36% 47.33%Text Length 33.72% 34%All Features 62.45% 59.33%Noun+Verb Morph 61.45% 58%Top10 features (Table 2) 57.34% 56.58%Table 3: Estonian Learner Proficiency Classification withvarious Feature groupsAlthough the classification accuracies overall arenot very high, it can be seen from the results that themorphological variation does play a key role in pro-ficiency classification of Estonian.
While the verbalmorphology features performed best as an individ-ual feature sub group, the addition of lexical varia-tion and POS features to the morphological featuresadded very little to the overall classification accu-racy.Text length turned out to be the most predictivesingle feature among the top features.
It can be seenfrom Table 3 that this feature alone resulted in a clas-sification accuracy of 34%, which is just above therandom baseline (33.33%).
But the fact that the Clevel in general contained a higher number of es-says and translations compared to other categoriesof text like letters and short answers (than the A andB levels), thereby resulting in longer texts in gen-eral, may have resulted text length being the singlemost predictive feature.
The Top-10 features alsoperformed on par with the individual morphologicalfeature subgroups.5.1.1 Ensemble ModelSince ensemble models are known to obtain a bet-ter performance than their constituent models, wecompared the performance of a stacking ensembleagainst its individual constituent models.
We trainedthree classification models on the entire feature set,using the same train-test sets as explained before andtrained an ensemble model with three classifiers.
Weused the StackingC implementation of WEKA (See-wald, 2002) to combine the models, with a linear re-gression model as our meta classifier.
Table 4 showsthe classification accuracies for the individual clas-sifiers as well as the ensemble on a 10-fold CV ofthe training set and on the held out test set.
Theensemble did not result in any significant improve-ment (<1%) compared to the best model amongstthe three of its individual components (SMO).
Theensemble?s performance on the test set was poorcompared to the best classification model.Classifier 10-Fold CV Test setSMO 62.45% 59.33%Logistic Regression 59.37% 52%Decision Tree 57.29% 52.33%Stacked Ensemble 63.28% 57.33%Table 4: Proficiency Classification With an Ensemble5.2 Classification Through Two-Class CascadesSince combining the classifiers as a stacking ensem-ble did not work, we turned to reformulating ourproblem as a cascade of two-class classifiers.
Cas-cade generalization is the process of sequentiallyusing a set of small classifiers to perform an over-all classification task.
Gama and Brazdil (2000)showed that a cascade can outperform other ensem-ble methods like stacking or boosting.
Kaynak andAlpaydin (2000) proposed a method to sequentiallycascade classifiers and showed that this improves theaccuracy without increasing the computational com-plexity and cost.
Although the creation of our clas-sifier cascades in this paper is not the same as anyof the above mentioned research, their conclusionthat cascading subsets of classifiers to build an over-all classifier can possibly result in a better accuracywas the main motivation for this experiment.The SMO implementation in WEKA also con-siders multi-class classification as a combination ofpairwise binary classifications.
But, in our subse-quent experiments, we combine our two-class clas-sifiers as a multi-stage cascade rather than a multi-expert stacking ensemble.
For these experiments,68we first built the various binary classifiers that werelater used to construct the cascades.
We chose ourcombinations both by using a One vs All (OvA) aswell as a One vs One (OvO) strategy.
Thus, six bi-nary classifiers were created, namely:?
(A, B) classifier?
(B, C) classifier?
(C, A) classifier?
(A and Not A) classifier?
(B and Not B) classifier?
(C and Not C) classifierIn all the cases, our training data consisted ofequal number of instances per class.
In the cases ofthe last three classifiers, the training data for NotA,NotB and NotC categories consisted of instancesfrom both the classes that were included in the re-spective ?Not-?
classes.
The data from the held-out test set was not included in any of these binaryclassification experiments.
The training data size foreach classifier has a different size depending on theclasses involved.
In all cases, the number of train-ing samples per category is equal to the number ofdocuments belonging to the category with the leastnumber of documents.
Hence, in cases involvingthe C-class (ABC, AC, BC, CnotC), we trained theclassifiers with 250 documents per category.
In allthe other cases (AB, AnotA, BnotB), we trained theclassifiers with 750 documents per category.
Table 5summarizes the training data size and the classifica-tion accuracies using 10-fold cross validation.
Allthe models were trained using the SMO algorithm.Classifer Training data size AccuracyA,B 750 per cat 70.8%B,C 250 per cat 74.59%A,C 250 per cat 85.93%A,NotA 750 per cat 74.20%B,NotB 750 per cat 60.04%C,NotC 250 per cat 79.69%Table 5: Binary Classifications of Estonian LearnersThis binary classification shows that there is aclear trend among the features across the proficiencylevels.
In the case of a pair-wise classification be-tween classes, the highest classification accuracywas achieved for the binary classifier that consideredthe A and C classes.
Although the classification ac-curacies of the binary classifiers (A,B) and (B,C) areconsiderably higher than the overall three class clas-sification accuracy (Table 3), they are very low com-pared to that of the binary classifier (A,C).
The con-fusion between the three classes is the highest whenit involves the middle class, B.
This confirmed theordinal nature of proficiency classification.
In thesecond set of binary classifiers, again, the classifierwith a poor performance turned out to be (B,NotB).To take advantage of the fact that the two-classclassification is much more accurate than the three-class classification, we studied three class classifica-tion by building multi-stage classifier cascades us-ing the above binary classifiers.
Based on the outputof the first stage (which is the most accurate classi-fier), we feed the test instance to one of the remain-ing classifiers to get the final prediction.5.2.1 Cascade-1For the first cascade, we considered the pairwisebinary classifiers that used a One vs One (OvO)strategy from Table 5.
We constructed a classifiercascade as follows: For each test instance,?
Classify the instance using the classifier (A,C).?
If A, re-classify the instance using the classifier(A,B).?
if C, re-classify the instance using the classifier(B,C).5.2.2 Cascade-2For the second cascade, we considered the sec-ond set of binary classifiers from Table 5, which usea One vs All (OvA) strategy.
The cascade is con-structed as follows: For each test instance,?
Classify the instance using the classifier(C,NotC).?
If C, classify the instance as C.?
Else, re-classify the instance using the classifier(A,notA).69The choice of these particular combinations ofcascades was motivated by two factors:?
To understand the performance of OvO andOvA binary classifier cascades independently?
To start with the classifier that has the highestaccuracy as the first stage.Table 6 compares the performance on the test setof the cascaded classifiers against the normal 3-classclassifier and a classifier ensemble.
Compared to anormal three-class classifier, the cascaded approachshowed more than 5% improvement in the classifica-tion accuracy using both the cascades.
Compared toCascade-1, Cascade-2 performed even better with a66.66% classification accuracy on the test set.
Sincebinary classification for certain pairs seemed to bepossible with higher accuracy than the three-classclassification, reformulating three class classifica-tion as a cascade of binary classifications may resultin a better classification accuracy.
This was the ini-tial motivation for the choice of cascade classifica-tion.
Our results clearly showed that it was a fruitfulexperiment.Classifer AccuracyCascade-1 64.66%Cascade-2 66.66%3-class,without cascade 59.33%3-class ensemble 57.33%Table 6: Comparison of Cascade classificationThe cascades need more exploration though.Also, although the morphological features turnedout to be useful predictors of proficiency classifica-tion, the classification accuracies are still not veryhigh.
Two possible explanations could be that ourfeatures are good but not sufficient or that the train-ing data was insufficient.It is clear from our various classification experi-ments that the morphological features are good pre-dictors of proficiency levels.
But, surely, there ismuch more to language proficiency than morpholog-ical complexity.
So, exploring more features will bethe natural next step to improve the overall classi-fication accuracy.
However, to gain some more in-sights at this level, we studied the effect of trainingdata sizes on the various classification tasks we per-formed.5.3 Effect of Training Sample SizeWe took all the seven different classification mod-els we used in the earlier experiments and studiedthe impact of gradually increasing the training datasize on classification accuracy.
For this purpose,wetrained all the classifiers with the complete featureset using the SMO algorithm.
The classifiers studiedinclude the three class ABC classifier and the binaryclassifiers AB, BC, AC, AnotA, BnotB and CnotC.Table 7 summarizes the effect of splitting the respec-tive training sets into various train-test splits, on theclassification accuracies.classifier 50-50 60-40 70-30 80-20ABC 56.73% 60.05% 61.76% 62.76%AB 71.07% 71.3% 71.2% 72.04%BC 71.33% 72.35% 71.73% 74.86%AC 86.31% 84.95% 84.15% 85.55%AnotA 75.39% 75.20% 76.65% 75.82%BnotB 59.05% 57.95% 56.91% 58.08%CnotC 77.34% 77.56% 77.27% 76.52%Table 7: Effect of training size on classification accuracyAs the table shows, training data size had an im-pact only on some of the classification tasks.
Forthe three class classification, training set size had aclear effect.
Although our corpus had a large num-ber of texts from A and B compared to C (Table1), since we used balanced training sets to train allmodels, the three-class model had relatively fewernumber of documents per category (250) comparedto, say, the AB classifier (750 per category).
Re-duction of this small training set further by 50% de-creased the three class classification accuracy from62.76% (when 80% of the data was used for train-ing) to 56.73%.
So, in this case, training data sizehad an effect.However, an interesting observation is that thissmall training sample size (250 documents per cat-egory) did not have any impact on the classificationperformance of the classifier (A,C).
This classifierconsistently performed at a higher level compared toall the other classifiers even when the training datawas only 50% (125 documents per category).
Al-70though it is possible that the length of the documentplayed a role here, there was little difference in theperformance (< 1%) even after removing the textlength feature.
This indicates a strong differentiationbetween the texts of the language learners of levelsA and C, in terms of the features we used.In case of the other classification tasks, only the(B,C) classifier showed some effect of the trainingdata on its overall classification accuracy.
Whilethere might be other reasons that we did not no-tice yet, it is possible that the inter class overlapbetween (A,B) is more compared to the overlap be-tween (B,C) at least in terms of the features we con-sidered.
Also, the fact that the B-level lies in be-tween A and C could also have contributed to thefact that more training data has little effect on clas-sifiers involving data from all the three classes (An-otA, BnotB, CnotC).6 Conclusion and DiscussionIn this paper, we discussed the task of classify-ing learner texts into standardized proficiency lev-els based on the texts produced by learners of Es-tonian as a second language.
We used the publiclyaccessible Estonian Interlanguage Corpus (EIC) andmodeled our classifiers by considering the morpho-syntactic variation as our primary feature group.
Wehypothesized that the morphology may play an im-portant role in detecting the proficiency levels as Es-tonian is a morphologically rich and complex lan-guage.For building our classifiers, we experimented withvarious methods such as three class classifiers, anensemble model and multi-stage cascades.
Our ex-periments showed that the multi-stage cascades im-proved the classification accuracy compared to theother approaches.
Our experiments also showed aclear trend across the proficiency levels.
There waslittle classification overlap between the beginner (A)and the advanced (C) level texts but a strong overlapof both these levels with the intermediate (B) level.We can conclude from our experiments that themorphological features can indeed play an impor-tant role in the proficiency classification of Estonian.Although the classification accuracies we achieved(60-65%) have a long way to go in terms of a real-world grading application, we believe that this is agood starting point to explore the role of morphol-ogy in proficiency classification of Estonian in par-ticular and other morphologically rich languages ingeneral.As a part of our future work, we intend to investi-gate the role of morphology in Estonian proficiencyclassification further.
We also want to compare theproficiency levels across various genres of texts inthe corpus (e.g, essays, personal and official letters,translations etc.).
Another interesting dimension wewant to explore further is the distribution of specifickinds of morphological phenomena (e.g., case mark-ers) that exist in Estonian but not in the learner?s na-tive language, across the different proficiency levels.It would also be interesting to apply insights fromthe theories of second language acquisition researchand study their utility for proficiency classification.Apart from morphology, we also intend to study theimpact of other features such as lexical sophistica-tion, error rate, syntactic complexity and discoursecoherence.
Finally, on the model construction side,we plan to investigate and understand the workingof cascaded classifiers better in this context.AcknowledgmentsWe thank Dr Pille Eslon from the Talinn Universityfor sharing the corpus with us.
We also thank SerhiyBykh, Dr Detmar Meurers and the three anonymousreviewers for their feedback on the paper.
This re-search is partially funded by the European Commis-sion?s 7th Framework Program under grant agree-ment number 238405 (CLARA)12ReferencesR.S.J.d.
Baker.
2010.
Mining data for student models.
InAdvances in Intelligent Tutoring Systems, pages 323?338.
Springer.Jill Burstein, Martin Chodorow, and Claudia Leacock.2003.
Criterion: Online essay evaluation: An appli-cation for automated evaluation of student essays.
InProceedings of the Fifteenth Annual Conference on In-novative Applications of Artificial Intelligence (IAAI-03), pages 3?10, Acapulco, Mexico, August.Jill Burstein, 2003.
The e-rater Scoring Engine: Auto-mated Essay Scoring with Natural Language Process-ing, chapter 7, pages 107?115.
Lawrence Erlbaum As-sociates, Inc.12http://clara.uib.no71Scott A. Crossley, Tom Salsbury, and Danielle S. Mc-Namara.
2011.
Predicting the proficiency level oflanguage learners using lexical indices.
In LanguageTesting.M.C.
Desmarais and R.S.J.d.
Baker.
2012.
A review ofrecent advances in learner and skill modeling in intel-ligent learning environments.
In User Modeling andUser-Adapted Interaction, 22(1-2).Markus Dickinson, Sandra Ku?bler, and Anthony Meyer.2012.
Predicting learner levels for online exercisesof Hebrew.
In Proceedings of the Seventh Workshopon Building Educational Applications Using NLP,pages 95?104, Montre?al, Canada, June.
Associationfor Computational Linguistics.Martin Ehala.
1994.
Russian influence and the change inprogress in the Estonian adpositional system.
In Lin-guistica Uralica, 3, pages 177?193.M.
Erelt, T. Erelt, and K. Ross.
2007.
Eesti keeleka?siraamat.
Eesti Keele Sihtasutus.M.
Erelt.
2003.
Estonian language.
Linguistica Uralica.Estonian Academy Publishers.Pille Eslon.
2007.
O?ppijakeelekorpused ja keeleo?p.In Tallinna U?likooli keelekorpuste optimaalsus,to?o?tlemine ja kasutamine, pages 87?120.Pille Eslon.
2011.
Millest ra?a?givad eesti keeleka?a?ndeadendused?
la?hivo?rdlusi.
In La?hivertailuja, 21,pages 45?64.Joao Gama and Pavel Brazdil.
2000.
Cascade general-ization.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: An update.In The SIGKDD Explorations, volume 11, pages 10?18.Md Maruf Hasan and Hnin Oo Khaing.
2008.
Learnercorpus and its application to automatic level checkingusing machine learning algorithms.
In Proceedings ofECTI-CON.C.
Kaynak and E. Alpaydin.
2000.
Multistage cascad-ing of multiple classifiers: One mans noise is anotherman?s data.
In Proceedings of the 17th InternationalConference on Machine Learning (ICML).Xiaofei Lu.
2012.
The relationship of lexical richness tothe quality of esl learners?
oral narratives.
The ModernLanguages Journal.John C. Platt.
1998.
Sequential minimal optimiza-tion: A fast algorithm for training support vector ma-chines.
Technical Report MSR-TR-98-14, MicrosoftResearch.Lawrence Rudner, Veronica Garcia, and CatherineWelch.
2005.
An evaluation of intellimetricTM essayscoring system using responses to gmat awa prompts.Technical report, Graduate Management AdmissionCouncil (GMAC).Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In Proceedings of the In-ternational Conference on New Methods in LanguageProcessing, pages 44?49, Manchester, UK.A.K.
Seewald.
2002.
How to make stacking better andfaster while also taking care of an unknown weakness.In In the proceedings of the Nineteenth InternationalConference on Machine Learning, pages 554?561.Thepchai Supnithi, Kiyotaka Uchimoto, Toyomi Saiga,Emi Izumi, Sornlertlamvanich Virach, and Hitoshi Isa-hara.
2003.
Automatic proficiency level checkingbased on sst corpus.
In In Proceedings of RANLP.Yukio Tono.
2000.
A corpus-based analysis of interlan-guage development: analysing pos tag sequences ofEFL learner corpora.
In PALC?99: Practical Applica-tions in Language Corpora, pages 323?340.Nina Vyatkina.
2012.
The development of second lan-guage writing complexity in groups and individuals:A longitudinal learner corpus study.
The Modern Lan-guage Journal.
to appear.David M. Williamson, Randy Elliot Bennett, StephenLazer, Jared Bernstein, Peter W. Foltz, Thomas K.Landauer, David P. Rubin, Walter D. Way, and KevinSweeney.
2010.
Automated scoring for the assess-ment of common core standards.
White Paper.David M. Williamson.
2009.
A framework for im-plementing automated scoring.
In The annual meet-ing of the American Educational Research Association(AERA) and the National Council on Measurement inEducation (NCME).Bo Zhang.
2008.
Investigating proficiency classificationfor the examination for the certificate of proficiencyin english (ecpe).
In Spaan Fellow Working Papers inSecond or Foreign Language Assessment.72
