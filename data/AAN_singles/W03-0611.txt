Learning the Meaning and Usage of Time Phrases from a Parallel Text-DataCorpusEhud ReiterDepartment of Computing ScienceUniversity of Aberdeenereiter@csd.abdn.ac.ukSomayajulu SripadaDepartment of Computing ScienceUniversity of Aberdeenssripada@csd.abdn.ac.ukAbstractWe present an empirical corpus study of themeaning and usage of time phrases in weatherforecasts; this is based on a novel corpus anal-ysis technique where we align phrases fromthe forecast text with data extracted from a nu-merical weather simulation.
Previous papershave summarised this analysis and discussedthe substantial variations we discovered amongindividual writers, which was perhaps our mostsurprising finding.
In this paper we describeour analysis procedure and results in consid-erably more detail, and also discuss our cur-rent work on using parallel text-data corpora tolearn the meanings of other types of words.1 IntroductionNLP systems that interact with the world often need mod-els of what words mean in terms of the non-linguisticworld.
In this paper, we describe how we have deter-mined the meaning of time phrases in weather forecastsby analysing a parallel corpus of (A) manually-writtenweather forecast texts and (B) the numerical data (from aweather simulation) that the human forecasters examinedwhen writing the textual forecasts.
The analysis proce-dure first aligns (associates) text fragments with data seg-ments, and then infers the meaning of each time phrase bystatistically analysing the time of data segments that arealigned to textual phrases that contain this time phrase.This is broadly similar in concept to the use of parallelmultilingual corpora in machine translation (Brown et al,1990), except that our parallel corpus consists of texts andunderlying numeric data, not texts and their translations.In other words, we are trying to learn what words meanin terms of non-linguistic data, not the best translationsof words in another language.Probably the biggest surprise in our analysis was thesubstantial variation we saw between individuals.
Forexample, by evening apparently meant 1800 to some peo-ple, but 0000 to others.
Although the possibility of suchvariation in individual idiolects has been acknowledgedin the past (for example, (Nunberg, 1978; Parikh, 1994)),it seems to be ignored by most recent work on lexical se-mantics.We have published other papers that have summarisedour key findings, notably variation between individu-als (Reiter and Sripada, 2002a; Reiter and Sripada,2002b); and also described the corpus itself (Sripada etal., 2003b).
The purpose of this paper is to describeour analysis procedure (including alignment) and resultsin detail, and to also discuss our current work on usingparallel text-data corpora to learn the meanings of othertypes of words.2 Previous ResearchLinguists and lexicographers have used a number of dif-ferent techniques to determine the meanings of words.These include asking native-speaker informants to judgethe acceptability and oddness of test sentences (Cruse,1986); defining word senses via lexicographic analysisof citations and corpora (Landau, 1984); and asking sub-jects to respond to ?fill in the blank?
questions (Cassidyand Hall, 1996).
These techniques have focused purelyon texts, and have not analysed how texts and words re-late to non-linguistic representations of the meanings ofa text, which is our focus.Psychologists interested in categorisation have doneformal experiments to determine which objects humansubjects consider to be in a mental category (Rosch,1978; Malt et al, 1999).
If we assume that the mean-ing of a word is one or more mental categories, then thisresearch has shed considerable light on what words mean.However, like all psychological research, it has examinedlanguage usage in an artificial experimental context, notnaturally occurring language.In the NLP community, models of word meanings aretypically either entered by a user or developer (for exam-ple in Microsoft?s English Query natural-language inter-day hour wind dir wind speed25-10-00 0 SSW 1225-10-00 3 SSE 1125-10-00 6 ESE 1825-10-00 9 ESE 1625-10-00 12 E 1525-10-00 15 ENE 1525-10-00 18 ENE 1825-10-00 21 NNE 2026-10-00 0 NNW 26Table 1: Wind (at 10m) extract from 24-Oct-00 data fileface) or derived from a hand-built knowledge base (eg,(Reiter, 1991)).
There is growing interest in trying tolearn word meanings from parallel text-data corpora, forexample (Siskind, 2001; Barzilay and Lee, 2002; Roy,2002).
We believe our work is unusual because we areusing naturally occurring texts and data.
Siskind (2001),in contrast, used data which was explicitly created for hisexperiments; Barzilay and Lee (2002) used texts whichsubjects had written for a previous experiment; and Roy(2002) used both data and texts that were created for hisexperiments.3 SumTime Project and CorporaThe SUMTIME project is investigating better technologyfor building software systems that automatically gener-ate textual summaries of time-series data.
One of thedomains SUMTIME is working in is weather forecasts,and in this domain we acquired a corpus of 1119 weatherforecasts (for off-shore oil rigs) written by five profes-sional meteorologists (Sripada et al, 2002; Sripada et al,2003b).
The reports were primarily based on the outputof a numerical weather simulation, and our corpus con-tains this information as well as the forecast texts.
Eachforecast is roughly 400 words long, giving a total corpussize of about 400,000 words.
The forecasts are split intoan initial section which gives an overview of the weather,and then additional sections which give detailed forecastsfor different periods of time.
Figure 1 shows an exampleextract from a forecast text; this is the detailed descrip-tion of predicted weather on 25 Oct 2000, from a forecastissued at 3AM on 24 Oct 2000.Much of our analysis has focused on statements de-scribing predicted wind speed and direction at 10 metersaltitude during the first 72 hours after the forecast was is-sued.
In other words, the WIND(10M) field from the de-tailed weather descriptions up to 3 days after the forecastwas issued.
One reason for focusing on wind statementsis that they are based fairly directly on two fields fromthe data files, predicted wind direction and speed; the re-lationship between some of the other statements (such asweather) and the data files is more complex.
The pre-dicted wind (at 10m) speed and direction on 25 Oct 2000,from the 24 Oct 2000 data file, is shown in Table 1.
Thisis the primary information that the meteorologists lookedat when writing the wind statement in Figure 1, althoughthey also have access to other information sources, suchas satellite weather photographs.Each forecast contains 3 such wind statements, with anaverage length of approximately 10 words; hence thereare about 30,000 words in our wind-statement subcorpus.This of course is very small compared to many text-onlycorpora such as the British National Corpus (BNC), butwe believe that our weather forecast corpus is one of thelargest parallel text-data corpora in existence.4 Analysis Procedure for Time PhrasesOne of SUMTIME?s research goals is to learn the meaningof time phrases; in other words, what a forecaster meantwhen he used a time phrase such as by evening or af-ter midnight.
We also wished to learn which time phraseshould be included in a computer-generated weather fore-cast text to indicate a time; for example, which timephrase should be used to indicate a change in the weatherat 1200.
Note that it is rare for weather forecasts to ex-plicitly mention numerical times such as 1200, and alsothat although there are standard terminologies for somemeteorological phenomena such as cloud cover and pre-cipitation, we are not aware of any standard terminologiesfor the use of time phrases in weather forecasts.We performed this analysis as follows.
First we ex-tracted the wind at 10 meters statements for the next 72hours from all forecasts in our corpus, and parsed thesetexts with a simple parser tuned to the linguistic structureof these texts.
The parser essentially broke sentences upinto individual phrases, and then recorded the speed, di-rection, and time phrase mentioned in each such phrase,along with other information (such as verb) which wasnot used in the analysis described here.
For example theWIND (10M) statement from Figure 1 was broken up bythe parser into four wind phrases:1.
SSW 12-16(speed:12-16, direction:SSW, timephrase: none)2.
BACKING ESE 16-20 IN THE MORNING,(speed:16-20, direction:ESE, timephrase: IN THEMORNING)3.
BACKING NE EARLY AFTERNOON(speed:(16-20), direction:NE, timephrase: EARLYAFTERNOON)4.
THEN NNW 24-28 LATE EVENING(speed:24-28, direction:NNW, timephrase: LATEEVENING)FORECAST 00-24 GMT, WEDNESDAY, 25-Oct 2000WIND(10M): SSW 12-16 BACKING ESE 16-20 IN THE MORNING, BACKINGNE EARLY AFTERNOON THEN NNW 24-28 LATE EVENING(50M): SSW 15-20 BACKING ESE 20-25 IN THE MORNING, BACKINGNE EARLY AFTERNOON THEN NNW 30-35 LATE EVENINGSIG WAVE: 2.0-2.5 RISING 3.0-3.5 BY AFTERNOONMAX WAVE: 3.0-4.0 RISING 5.0-5.5 BY AFTERNOONWEATHER: RAIN SOON, CLEARING TO SHOWERS IN THE EVENINGVIS: GOOD BECOMING MODERATE IN RAINFigure 1: Extract from 5-day forecast issued on 24-Oct-00If a wind phrase did not specify speed or direction, theparser assumed that this was unchanged from the pre-vious wind phrase; such elision is common in weatherforecast texts.
Thus, for example, the speed recorded forBACKING NE EARLY AFTERNOON is 16-20, whichis the speed from the previous phrase (BACKING ESE16-20 IN THE MORNING).
Our parser successfullyparsed 3225 of the 3357 WIND(10M) statements; 132(4%) of the statements could not be parsed.
The parserproduced 8198 wind phrases in total.From these 8198 wind phrases we selected thosephrases which (a) included a time phrase, (b) did notuse a qualifier such as mainly or occasionally, (c) did notspecify that wind speed or direction was variable, (d) forwhich we had the corresponding data files, and (e) forwhich we knew the forecast author.
There were 3654such phrases.
The majority (4014 phrases) of the elim-inated phrases did not specify a time phrase, such as thefirst phrase (SSW 12-16) in the above example.We next associated each wind phrase with an entry inthe corresponding data file.
In other words, we alignedthe textual wind phrases with the numeric data file en-tries.
As in other uses of parallel corpora, good alignmentis essential in order for the results to be meaningful (Ochand Ney, 2000).To associate data file entries with wind phrases, wefirst searched the data file for entries which matched thewind phrase.
An entry matched if its speed was within therange defined in the phrase, and if its direction was within12 degrees of the direction mentioned in the phrase.
In343 cases, no data file entry matched the wind phrase.
Webelieve that such cases were mostly due to (a) forecastersnot literally reporting the data file, but instead adjustingwhat they said based on their meteorological expertiseand on information not available to the numerical weathersimulation (such as satellite weather images); (b) fore-casters reporting a simultaneous change in wind speedand direction, when in fact speed and direction changedat different times (this may be due to forecasters trying towrite texts quickly, so that they can use the most up-to-date data (Reiter et al, 2003)); and (c) forecaster errors.For example, the third phrase in our example, BACK-ING NE EARLY AFTERNOON, does not match any ofthe data file entries shown in Table 1.
This could be be-cause the forecaster decided that the numerical forecastwas underestimating the speed at which the wind wasshifting, and hence he believed that the wind would beNE at 12 or 15, even though the data file predicted E andENE for these times.
It could also be that the forecastermade a mistake, and perhaps was intending to write ENEbut wrote NE instead because he was writing under timepressure.
In any case, wind phrases which did not matchany data file entries were dropped from our analysis.Out of the 3311 matched wind phrases, 1434 (43%)were unambiguous and only matched one data file en-try.
For example, the fourth wind phrase in our example,THEN NNW 24-28 LATE EVENING, matches only onedata file entry, the one for 0000 on 26 Oct 2000.1877 (57%) of the matched wind phrases were ambigu-ous and matched more than one data file entry.
Typicallythis happened when the wind was changing slowly andhence two or more adjacent data file entries matched thewind phrase.
In such cases we checked if one data fileentry had a speed which was was closer than the otherdata files entries to the middle of the speed range in thetextual wind phrase.
This heuristic produced a preferredmatch for 1105 (33%) of the matched wind phrases, andleft 772 (23%) phrases as ambiguous and unmatched.For example, the second wind phrase in our example,BACKING ESE 16-20 IN THE MORNING, matches twodata file entries: 0600 (direction ESE, speed 18) and 0900(direction ESE, speed 16).
The midpoint of the 16-20speed range reported in the forecast is 18, so our speedheuristic matches this wind phrase to the 0600 data fileentry, since its speed is closer to the speed range midpoint(indeed, it matches the midpoint).We evaluated our alignment process by applying it tothe subset of wind phrases which used a time phrasewhich we thought had a clear and unambiguous inter-pretation, namely an absolute time (such as by 0600), bytime F1 F2 F3 F4 F5 total0000 2 9 80 5 14 1100300 1 10600 1 10900 01200 1 11500 2 1 1 2 61800 30 5 2 27 13 772100 13 6 8 2 11 40total 37 22 91 34 42 236Significance of differences: p   0.001Table 2: Usage of by evening, by forecaster (mode inbold)time F1 F2 F3 F4 F5 total0000 2 1 30300 1 10600 1 10900 3 1 7 2 131200 23 71 86 11 1911500 7 1 9 5 2 241800 2 2 1 52100 1 1total 34 1 85 103 16 239Significance of differences: p  0.1Table 3: Usage of by midday, by forecaster (mode inbold)midday (which means 1200), by midnight (which means0000), and by end of period (which means either 0000 or0600, depending on the forecast section).
The matchingprocess was fairly accurate; in 86% of cases it producedthe expected meaning (such as 0000 for by midnight).Clearly we would benefit from better matching andalignment techniques, and we wonder if perhaps some ofthe alignment techniques used for parallel multi-lingualcorpora (Och and Ney, 2000) could be adapted to helpalign our text-data corpora.
This is a topic we plan toinvestigate in future research.This matching/alignment procedure is different in de-tail from the preliminary analysis procedure reported in(Reiter and Sripada, 2002b).
The procedure used in ourearlier paper aligned fewer phrases (1382 vs. 2539) andhad a higher error rate (22% vs. 14%), so it was inferior.5 ResultsWe examined the association between time phrase andtime in the 2539 aligned (wind phrase, data file entry)pairs.
In this analysis, we regarded time phrases as dif-ferent if they involved different head nouns (for example,time F1 F2 F3 F4 F5 total0000 215 9 15 2390300 1 10600 00900 01200 1 11500 01800 02100 3 3 2 8total 0 0 219 12 18 249Significance of differences p   0.001 (ANOVA: p = 0.06)Table 4: Usage of by late evening, by forecaster (mode inbold)by evening and by afternoon), different prepositions (forexample, midday and by midday) and/or different adjec-tives (for example, by afternoon and by late afternoon).However, we ignored determiners (for example, by thisevening was regarded as the same phrase as by evening).Tables 2, 3, and 4 gives details of the usage of the threemost common non-contextual time phrases: by evening,by midday, and by late evening.
This tables also showsthe statistical significance of differences between fore-casters, calculated with a a chi-square test (which treatstime as a categorical variable).
As some colleagueshave expressed an interest in a one-way ANOVA analysis(which compares mean time), we show this as well whereit gives a substantially different value from the chi-squareanalysis.
This data suggests that by evening means different things to different peo-ple; for example, F1 and F4 primarily use this phraseto mean 1800, while F3 primarily uses this phrase tomean 0000. by midday was used in a very similar way by all fore-casters (ignoring F2, who only used the term once). by late evening was used by all forecasters (whoused this term) primarily to mean 0000.
However,the usages of the different forecasters was still sig-nificantly different.
This reflects a difference in thedistribution of usage; in particular, F3 almost always(98% of cases) used this phrase to mean 0000, whileF4 and F5 used this phrase to mean 0000 in about80% of cases.These patterns are replicated across the corpus: somephrases (such as by midday and by morning) are used inthe same way by all forecasters; some phrases (such asby evening and by late morning) are used in very differ-ent ways by the forecasters; and some phrases (such as bylate evening and by midnight) have the same core mean-ing (eg, 0000) but different distributions around the core.We have, incidentally, looked for seasonal variations inmeaning (for example, by evening meaning one thing inthe winter and another in the summer), but we have foundno evidence of such variation.Roy (2002) has also noted variation in the meaningsthat individuals assign to words, in his parallel text-datastudy of object descriptions.
For example, one objectmight be described as having the colour pink by one sub-ject, but other subjects might have problems identifyingthe object when it was described as pink, because they didnot consider it to have this colour.Table 5 presents the most common time-phrase usedby each forecaster for each time, including context-dependent phrases such as later.
This highlights ma-jor ?stylistic?
differences between forecasters in terms ofwhich time phrases they prefer to use.
For example, F1and F2 make heavy use of contextual time phrases suchas later and soon, while F5 (and to a lesser extent F4)seem to prefer to avoid such terms.
It is also interest-ing that contextual time phrases are especially commonlyused to refer to the time 0300.
We wonder if this couldreflect a ?lexical gap?
in English; there are no commonlyused time phrases in English for times around 0300, andperhaps this encourages the forecasters to use contextualtime phrases to refer to 0300.Table 6 presents the most common (mode) meaningof non-contextual time phrases, for each forecaster.
Per-haps not surprisingly, the greatest variability occurs whena time phrase denoting a time period (morning, afternoon,or evening) occurs without being modified by an adjec-tive (early, mid, or late).
The data also suggests that theforecasters may disagree about the meaning of morning,with F4 in particular considering morning to be the period0300-0900, while F5 considers morning to be the period0600-1200.6 Current and Future Work6.1 Verb ChoiceWe would like to use our corpus to learn choice rulesfor verbs which are near-synonyms (Edmonds and Hirst,2002).
We are currently attempting to learn rules whichpredict which of three possible verbs ?
decreasing, eas-ing, and falling ?
are used when the wind speed de-creases.We have conducted two experiments.
The first was asemantic analysis, where we attempted to learn a choicerule based on features extracted from the numerical data.To do this, we used our aligned corpus to extract seman-tic features which we thought could be relevant to thisdecision (such as the amount by which the wind speedhas decreased), and then analysed this with Ripper (Co-hen, 1995).
This gave the rules shown in Figure 2; theseagain show substantial variation between individual fore-verb F1 F2 F3 F4 F5 totaldecreasing 0 0 3 2 0 5easing 1 19 0 0 0 20falling 4 0 61 0 0 65Table 7: Choice of wind decrease verb when subsequentword is variable, by forecaster (mode in bold)casters.
These rules are mildly effective; 10-fold crossvalidation error is 25%, compared to a baseline error rateof 33% from always choosing the most common verb(easing).
These rules suggest that at least for some fore-casters, decreasing suggests a larger change in the windspeed than easing; this is the sort of near-synonym con-notational difference that we expected to find.
More sur-prisingly (at least to us), the presence of forecast date insome of the rules suggests that forecasters change howthey write over time.
Perhaps in retrospect this shouldnot have been a surprise, because we have also observedchanges over time in how people write in a previousproject (Reiter et al, 2000).We also analysed collocation effects, that is whetherwe could predict verb choice based purely on the wordsimmediately preceding and following the verb (and henceignoring the numerical prediction data).
This was doneon the complete corpus (not just verbs that were part ofsuccessfully aligned phrases).
It is difficult to directlycompare the collocation analysis with the semantic onedue to differences in the corpora texts used, but in gen-eral terms the reduction in baseline error rate seems com-parable to the semantic analysis.
Some of the collocationeffects were both strong and forecaster-dependent.
Forexample, Table 7 shows the choice of wind decrease verbwhen the word following the verb was variable (indicat-ing wind direction was variable).
In this context, fore-casters F1 and F3 usually used falling; F2 always usedeasing; and F4 always used decreasing (F5 never usedvariable in his forecasts).
Similar individual differenceswere observed in other collocations.
For example, whenthe word preceding the verb was gradually, F3, F4, andF5 preferred decreasing, but F2 always used easing (F1never used gradually in his forecasts).In summary, it seems that the choice between the nearsynonyms decreasing, easing, and falling depends on semantics: how much the actual wind speed haschanged;collocation: immediately preceding and followingwords in the sentence;author: which forecaster wrote this particular text; date: when the text was written.time F1 F2 F3 F4 F5 all0000 later later by late evening by midnight in evening later0300 later soon soon soon tonight soon0600 later overnight soon by morning later in period later0900 soon soon soon by midday in morning soon1200 by midday soon by midday by midday in morning by middayby by mid by mid early by mid1500 afternoon soon afternoon afternoon afternoon afternoon1800 by evening by evening by late afternoon by evening by evening by eveningin evening/ later/2100 later later by evening later by evening by eveningbold font means this phrases was at least twice as common as the second-most common term.X/Y means X and Y were equally commonTable 5: Most common time-phrases for each time, by forecasterChoose decreasing ifForecaster ruleF1 neverF2 neverF3 speed change    10 knots AND time interval    15 hoursF4 speed change    9 knots OR forecast date    2-November-2001F5 forecast date    30 March 2001Otherwise choose easingFigure 2: Verb choice rule based on data featuresAll of these factors are important, and in particular thekind of semantic differences investigated by (Edmondsand Hirst, 2002) are only one factor among many, and donot dominate the choice decision.
We plan to continueworking on this and other analyses of near-synonyms,and obtain a better idea of how these factors interact.6.2 Other corporaIn addition to the weather corpus, the SUMTIME projectalso has access to a parallel text-data corpus of doc-tors describing signal data from a neonatal intensive careunit (Alberdi et al, 2001).
We would like to analysethis corpus to determine the meanings of words such assteady and oscillations.
However, a preliminary analy-sis has suggested to us that we cannot conduct such ananalysis until we remove non-physiological events fromthe data (Sripada et al, 2003a).
For example, a doctormay describe a signal as steady even when it contains alarge spike, if the doctor believes the spike is due to anon-physiological event (such as a sensor falling off thebaby and then being replaced by a nurse).
Hence non-physiological events (known in this domain as ?artifacts?
)must be removed from the data before it is possible toanalyse word meaning.
We are currently working on ar-tifact removal, and once this is complete we will start ouranalysis of word meanings.SUMTIME is also working on generating textual sum-maries of gas turbine sensor data (Yu et al, 2003).
Un-fortunately in this domain, as in many other NLG appli-cations (Reiter et al, 2003), there is no existing corpusof manually written texts describing the input data.
Wehave explicitly asked two experts to write descriptionsof 38 signal fragments.
This very small corpus showedthat once again there were major differences between in-dividuals (Reiter and Sripada, 2002a), but the corpus istoo small to allow meaningful statistical analysis of wordmeanings.7 ConclusionTo conclude, we believe that parallel text-data corporaare a valuable resource for investigating lexical seman-tic and pragmatic issues, and can help shed valuable lighton the fundamental question of how words relate to thenon-linguistic world.
We have described in detail how wehave used such a corpus to analyse the meaning and usageof time phrases in weather forecasts, and also sketchedour current work on other analyses of text-data corpora.We hope that other researchers interested in semanticsand pragmatics will find our techniques interesting, andconsider whether they might be useful in exploring othersemantic and pragmatic questions about word meaningusage.phrase F1 F2 F3 F4 F5 combinedafter midnight 0600 0600afternoon * 1630 1630around midday * * * 1200by 0600 0600 0600by afternoon 1500 1200 1200 1200 1200by early afternoon * * * 1330 1330by early evening 1800 * 1800by early morning 0300 0300by evening 1800 0000 0000 1800 0000 0000by late afternoon 1800 * 1800by late evening 0000 0000 0000 0000by late morning * 0900 1200 1030by mid afternoon 1500 1500 * 1500by mid evening * 2100 * 2100by mid morning * * * 0900by midday 1200 * 1200 1200 1200 1200by midnight 0000 0000 0000 0000by morning 0600 0600 * 0600during afternoon * * 1500during evening 0000 0000 0000 0000during morning * 1030 * 0900 0900early afternoon * * * 1500 1500early evening * 1800 1800evening 1612 2100 0000 0000from midday 1200 1200in afternoon * * 1800 1800in evening 0000 0000 0000in morning 1200 1200late evening * 0000 0000 0000later in evening 0000 0000later in night 0600 0600mid morning * * * 0900overnight 0600 0600 * 0600tonight * 0000 0000* means phrase was used fewer than five times by this forecaster.Phrases used less than 5 times by all forecasters combined are omitted.Contextual phrases (such as later) are also omitted.If 2 or more times are equally common, their average is shown.Table 6: Most common (mode) usage of time phrases, by forecasterAcknowledgementsOur thanks to the many individuals who have discussedthis work with us, of which there are too many to listhere.
Special thanks to our industrial collaborators atWNI/Oceanroutes, without whom this work would havebeen impossible.
This work was supported by the UK En-gineering and Physical Sciences Research Council (EP-SRC), under grant GR/M76881.ReferencesEugenio Alberdi, Julie-Clare Becher, Ken Gilhooly, JimHunter, Robert Logie, Andy Lyon, Neil McIntosh, andJan Reiss.
2001.
Expertise and the interpretation ofcomputerized physiological data: implications for thedesign of computerized monitoring in neonatal inten-sive care.
International Journal of Human-ComputerStudies, 55:191?216.Regina Barzilay and Lillian Lee.
2002.
Bootstrap-ping lexical choice via multiple sequence alignment.In Proceedings of the 2002 Conference on EmpiricalMethods in Natural Language Processing (EMNLP-2002).Peter F. Brown, John Cocke, Stephen Della Pietra, Vin-cent J. Della Pietra, Frederick Jelinek, John D. Laf-ferty, Robert L. Mercer, and Paul S. Roossin.
1990.
Astatistical approach to machine translation.
Computa-tional Linguistics, 16(2):79?85.Frederick Cassidy and Joan Hall, editors.
1996.
Dictio-nary of American Regional English.
Belknap.William Cohen.
1995.
Fast effective rule induction.In Proc.
12th International Conference on MachineLearning, pages 115?123.
Morgan Kaufmann.D.
Cruse.
1986.
Lexical Semantics.
Cambridge Univer-sity Press.Philip Edmonds and Graeme Hirst.
2002.
Near-synonymy and lexical choice.
Computational Linguis-tics, pages 105?144.Sidney Landau.
1984.
Dictionaries: the art and craft oflexicography.
Scribner.Barbara Malt, Steven Sloman, Silvia Gennari, Meiyi Shi,and Yuan Wang.
1999.
Knowing versus naming:Similarity and the linguistic categorization of artifacts.Journal of Memory and Language, 40:230?262.Geoffrey Nunberg.
1978.
The Pragmatics of Reference.University of Indiana Linguistics Club, Bloomington,Indiana.Franz Och and Herman Ney.
2000.
A comparison ofalignment models for statistical machine translation.In Proceedings of the 18th International Conferenceon Computational Linguistics (COLING-2000), pages1086?1090.Rohit Parikh.
1994.
Vagueness and utility: The seman-tics of common nouns.
Linguistics and Philosophy,17:521?535.Ehud Reiter and Somayajulu Sripada.
2002a.
Humanvariation and lexical choice.
Computational Linguis-tics, 28:545?553.Ehud Reiter and Somayajulu Sripada.
2002b.
Shouldcorpora texts be gold standards for NLG?
In Proceed-ings of the Second International Conference on Natu-ral Language Generation, pages 97?104.Ehud Reiter, Roma Robertson, and Liesl Osman.
2000.Knowledge acquisition for natural language genera-tion.
In Proceedings of the First International Con-ference on Natural Language Generation, pages 217?215.Ehud Reiter, Somayajulu Sripada, and Roma Robertson.2003.
Acquiring correct knowledge for natural lan-guage generation.
Journal of Artificial Intelligence Re-search.
Forthcoming.Ehud Reiter.
1991.
A new model of lexical choice fornouns.
Computational Intelligence, 7(4):240?251.Eleanor Rosch.
1978.
Principles of categorization.
InE.
Rosch and B. Lloyd, editors, Cognition and Catego-rization, pages 27?48.
Lawrence Erlbaum, Hillsdale,NJ.Deb Roy.
2002.
Learning visually grounded words andsyntax for a scene description task.
Computer Speechand Language, 16:353?385.Jeffrey Siskind.
2001.
Grounding the lexical semanticsof verbs in visual perspection using force dynamicsand event logic.
Journal of Artificial Intelligence Re-search, 15:31?90.Somayajulu Sripada, Ehud Reiter, Jim Hunter, and JinYu.
2002.
SUMTIME-METEO: Parallel corpus ofnaturally occurring forecast texts and weather data.Technical Report AUCS/TR0201, Computing ScienceDept, Univ of Aberdeen, Aberdeen AB24 3UE, UK.Somayajulu Sripada, Ehud Reiter, Jim Hunter, and JinYu.
2003a.
Exploiting a parallel text-data corpus.In Proceedings of Corpus Linguistics 2003.
UCREL,Lancaster University, UK.Somayajulu Sripada, Ehud Reiter, Jim Hunter, and JinYu.
2003b.
Summarising neonatal time-series data.
InProceedings of EACL-2003.
Forthcoming.Jin Yu, Ehud Reiter, Jim Hunter, and Somayajulu Sri-pada.
2003.
Sumtime-turbine: A knowledge-basedsystem to communicate gas turbine time-series data.In Proceedings of IEA/AIE-2003.
