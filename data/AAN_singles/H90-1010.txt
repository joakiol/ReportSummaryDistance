Two Recent Developments in Tree Adjoining Grammars:Semantics and Efficient ProcessingYves SchabesAravind K. JoshiDepartment of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104ABSTRACTDuring the past year there have been two very significant de-velopments in the area of Tree Adjoining Grammars (TAGs).The first development is a variant of TAGs, called syn-chronous TAGs, which allows TAG to be used beyond theconfines of syntax by characterizing correspondences be-tween languages.
The formalism's intended usage is to relateexpressions of natural anguages to their associated seman-tics represented by a logical form language in TAG, or totheir translates in another natural anguage.
The formalismis incremental nd inherently nondirectional.
We will showby detailed examples the working of synchronous TAGs andsome of its applications, for example in generation and inmachine translation.The second development is the design of LR-style parsersfor TAGs.
LR parsing strategies evolved out of the orig-inal work of Knuth.
Even though they are not powerfulenough for NLP, they have found use in natural anguageprocessing 0VLP) by solving by pseudo-parallelism conflictsbetween multiple choices.
This gives rise to a class of pow-erful yet efficient parsers for natural anguage.
In order toextend the LR techniques to TAGs it is necessary to findbottom-up automaton that is exactly equivalent o TAGs.This is precisely what has been achieved by the discovery ofthe Bottom-up Embedded Push Down Automaton (BEPDA).Using BEPDA, deterministic left to fight parsers for the TreeAdjoining Languages have been developed.Using TAGs beyond their Role in Syn-taxThe unique properties of tree-adjoining rammars (TAG)present a challenge for the application of TAGs beyond thelimited confines of syntax, for instance, to the task of se-mantic interpretation or automatic translation of natural an-guage.
A variant of TAGs, called synchronous TAGs, hasbeen developed (Shieber and Schabes \[1990(a)\]).
It is used*This research is partiaUy supported by Darpa grant N0014-85-K0018,ARO grant DAAL03-89-C-0031PRI and NSF grant-IR184-10413 A02.Parts of this work are results of coUaborafion with Stuart Shieber (HarvardUniversity), K. Vijay-Shanker (University of Delaware) and Anne Abei116(University of Paris-7).
The specifics of the collaboration are stated in thebody of the paper.
We are also grateful to Bernard Lang and David Weirfor their valuable suggestions onLR-style parsing of TAGs which playedan instrumental ro e in the definition of BEPDA, for example r striction onthe moves allowed.to relate expressions of natural languages to their associ-ated semantics represented in a logical form language orto their translates in another natural anguage (the work onSynchronous TAG and its applications to language interpre-tation and generation has been done in collaboration withStuart Shieber).Language in terpretat ion  and  generat ion  w i thTAGsThe key idea for semantic interpretation is that the logicalform language itself can be described by a TAG.
The twoTAGs (one for the natural anguage and one for the logicalform language) work synchronously, in the sense that thecertain correspondences (links) are stated initially betweenthe elementary trees of the two TAGs and then compositionoperations (such as substitution and adjoining) are carriedout synchronously on the linked nodes of the two TAGs.The fact that both the natural anguage and the logical formlanguage can be described by TAGs is a direct consequenceof the extended omain of locality of TAGs as compared toLFG or GPSG.A sample synchronous TAG is given in Figure 1.
Eachelement of the synchronous TAG is a pair consisting of twoelementary trees, one from the source language (English)and one from the target (logical form \[LF\]).
Nodes, one fromeach tree, may be linked; such links are depicted graphicallyas thick lines.
If  we project the pairs onto their first or sec-ond components (ignoring the cross links), the projectionsare TAGs for an English fragment and an LF fragment, re-spectively.
These grammars are themselves written in a par-ticular variant of TAGs; the choice of this base formalism,as we will call it, is free.
In the case at hand, we havechosen single-component lexicalized TAGs with adjunctionand substitution (Schabes, Abeill6 and Joshi \[1988\]).
Otherbases (as Multiple Component TAGs) are needed for morecomplex phenomena.The elementary operation in a synchronous TAG is super-venient on the elementary operations in the base formalism.A derivation step from a pair of trees (oq, o~2) proceeds asfollows:1.
Nondeterministically choose a link in the pair connect-ing two nodes (say, nl in cq and n~ in c~2).48S F/ l f-T, T A\ Y \ hates / .
(o T)I IGeorge george'(  bro~oli~br?~Tc?lit\ violently violently" IN ~ T  \I P N,  I~ T, /ooked cooked" IFigure 1: A sample synchronous TAG.2.
Nondeterministically choose a pair of trees (#x, f12) inthe grammar.3.
Form the resultant pair (fll(Otl, nl), fl2(ol2, n2)) where~(o~, n) is the result of performing a primitive operationin the base formalism on o~ at node n using ~/ (e.g.,adjoining or substituting B into ot at n).
1Synchronous TAG derivation then proceeds by choosinga pair of initial trees (oq, o~2) that is an element of the gram-mar, and repeatedly applying derivation steps as above.As an example, suppose we start with the tree pair o~ inFigure 1.
2 We choose the link from the subject NP to Tand the tree pair ~ to apply to its nodes.
The resultant, bysynchronous substitution, is the tree pair:S F/ Ny R T T , \\George  i -P'I" ~a...',.'r,.
'll_X hates ~ - - J /Note that the links from ~ are pres-d!l'!ltrtll"d~the resultant pairc~l except for the chosen link, which has no counterpart inthe result.Using tree pair 7 on the remaining link from NP to T inoq yields1 The definition allows for the operations performed on the first andsecond trees to differ, one being a substitution a d the other an adjunction,for example.2We use standard TAG notation, marking foot nodes in auxiliary treeswith '*' and nodes where substitution is to occur with '~'.
The nonterminalnames in the logical form grammar e mnemonic for Formula, Relation(or function) symbol, Term, and Quantifier.ot 2 I NP VP ~ R T ~ T/ I  I I 1"Ik Ge?rge y ?
hate'ge?rgeTbr?cc?li"This pairing manifests the correspondence b tween thesentence "George hates broccoli" and its logical formhates'(george', broccoli ~) (as written in a more traditionalnotation).
Here we see that the links in the operator trees(those in 7) are preserved in the resultant pair, accountingfor the sole remaining link.
The trees in 7 are linked in thisway so that other tree pairs can modify the N.We can continue the derivation, using 8 and e to generatethe pair given in Figure 2 thereby associating the meaningviolently' ( hates' (george', cooked' (broccoli') ) )with the sentence "George hates cooked broccoli violently.
"The arguments for factoring recursion and dependenciesas TAGs do for the syntax of natural anguage have theircounterparts in the semantics.
The structure of TAGs allowssyntactic dependencies--agreement, subcategorization, a dso forth--to be localized in the primitives of a grammar, theelementary trees.
This is most dramatically evident in thecase of long-distance dependencies, such as that between awh-phrase and its associated gap.
Similarly, using TAGs toconstruct logical forms allows the localization of semanticdependencies in the logical forms of natural language xpres-sions, dependencies such as the signature requirements (ar-gument type and arity) of function and relation symbols, andeven the long-distance d pendencies between a wh-quantifierand its associated bound variable.
With other methods of se-mantics, these dependencies cannot be localized; the seman-tic aspects of filler-gap dependencies must be passed amongthe features of various nodes in a parse tree or otherwisedistributed over the entire derivation.The use of the synchronous TAG augmentation allowsan even more radical reduction in the role of features in aTAG grammar.
Because of the extended omain of localitythat TAGs possess, the role of features and unification isreduced from its role in context-free based systems.
Onlyfinite-valued features are needed, with the possible xceptionof a feature whose value encodes an expression's logicalform.
In removing the construction of logical forms fromthe duties delegated to features, we can maintain a strictlyfinite-valued---and therefore formally dispensable--featuresystem for TAGs.ApplicationsSynchronous TAGs suggest elegant solutions to the seman-tics of idioms, quantifier scoping (Shieber and Schabes,\[1990a\]) and provide an elegant framework for generation(Shieber and Schabes, \[1990b\]) and machine translation(Abeill6, Schabes and Joshi \[1990\]).49S FI ~ I .-----'~"""----.-...George~ AI~VP violently" ~ T Tgeorge / lOT  NP violentlybroccoli" hateI Icooked broccoliFigure 2: Derived tree pair for "George hates cooked broccoli violently.
"Semantics IdiomsAll of the arguments for the TAG analysis of idioms and lightverb constructions (Abeill6 and Schabes, 1989) can then bemaintained in a formalism that allows for semantics for themas well.
In particular, discontinuous syntactic onstituentscan be semantically localized nonstandard long-distance d -pendencies are statable without resort to reanalysis, bothfrozen and flexible idioms can be easily characterized.For example, the idiomatic onstruction "kick the bucket"cashes out as the following tree pair, under its idiomaticinterpretation:/ s REx \~a d!e' J"whereas the literal usage of "kick" is associated with a treepair similar to that of "hates" in Figure 1.QuantifiersIn order to characterize quantifier scoping possibilities,multi-component TAGs (as defined by Joshi, 1987) is usedas the base formalism for synchronous TAG (see Shieberand Schabes \[1990(a)\] for more details on quantifiers scop-ing with Synchronous TAG).
In particular, an NP will belinked both to a formula in the semantics (the quantifier'sscope) and a term (the position bound by the quantifier).Generat ionThe nondirectionaly of Synchronous TAGs enables us to useit for semantic interpretation aswell as for generation (seeShieber and Schabes \[1990b\]).Mach ine  Trans lat ionThe transfer between two languages, uch as French and En-glish, can be done by putting directly into correspondencelarge elementary units without going through some interlin-gual representation a d without major changes to the sourceand target grammars (Abeill6, Schabes and Joshi \[1990\]).The underlying formalism for the transfer is SynchronousTree Adjoining Grammars.
Transfer ules are stated as cor-respondences between nodes of trees of large domain oflocality which are associated with words.
We can thus de-fine lexical transfer ules that avoid the defects of a mereword-to-word approach but still benefit from the simplicityand elegance of a lexical approach (this work has been donein collaboration with Anne Abeill6).As an example, consider the fragment of the transfer lex-icon given in Figure 3.
(x3'(TJohn JohnNPI$ y ~ /misses~-manq ue ~1 ~qP1 $ //apparemment \[Figure 3: Fragment of the English-French transfer lexiconFor example, suppose we start with the pair 3' and weoperate the pair a on the link from the English node NPoto the French node NP1.
This operation yields the derivedpair a4.500/4\] S ~ Srip xLP{ John V NP 15 V PP,\ I I / x\m isses  manque ~1 7~t JohnThen, ff the pair fl operates on the NP1-NPo in 0/4, thefollowing pair 0/5 is generated.0/5I /N  Iohn~ 7 Mary ~r ,~missesMary manque ~l 7JohnFinally, when the pak ~ operates on the S-S link in 0/5,the pair 0/6 is generated.0/6Adv S Adv S/ apparc~atly NP VP hiP VP apparemmcntI /N  \ Jo~V ~ ~vNPmanque ~1 jolh ntThe fragment of the transfer lexicon given in Figure 3therefore nables us to translate:Apparently, John misses MaryApparemment, Mary manque ~ JohnIn most cases, translation can be performed incrementallyas the input string is being parsed.By virtue of their extended omain of locality, Tree Ad-joining Grammars allow regular correspondences betweenlarger structures to be stated without amediating interlingualrepresentation.
The mapping of derivation trees from sourceto target languages, using the formalism of synchronousTAGs, makes possible to state such direct correspondences.By doing so, we are able to match linguistic units with quitedifferent internal structures.
Furthermore, the fact that thegrammars are lexicalized enables capturing some idiosyn-crasies of each language.The simplicity and effectiveness of the transfer ules inthis approach shows that lexicalized TAGs, with their ex-tended omain of locality, are very well adapted to machinetranslation.Efficient Processing of TAGsThe second development is the design of LR-style parsersfor TAGs.
LR parsing strategies evolved out of the originalwork of Knuth.
LR(k) parsers for Context Free Grammars(Knuth, 1965) consist of a finite state control (constructedgiven a CFG) that drives deterministically with k lookaheadsymbols a push down stack, while scanning the input fromleft to right.
It has been shown that they recognize xactlythe set of languages recognized by deterministic push downautomata.
LR(k) parsers for CFGs have been proven usefulfor compilers as well as recently for natural language pro-cessing.
For natural anguage processing, although LR(k)parsers are not powerful enough, conflicts between multi-ple choices are solved by pseudo-parallelism (Lang, 1974,Tomita, 1987).
This gives rise to a class of powerful yet ef-ficient parsers for natural languages.
It is in this context thatdeterministic (LR(k)-style) parsing of TAGs is studied (thiswork has been done in collaboration with Vijay-Shanker).The set of Tree Adjoining Languages i  a strict superset ofthe set of Context Free Languages (CFLs).
For example, thecross serial dependency onstruction i Dutch can be gener-ated by a TAG.
Walters (1970), R6v6sz (1971), Turnbull andLee (1979) investigated deterministic parsing of the class ofcontext-sensitive languages.
However they used Turing ma-chines which recognize languages much more powerful thanTree Adjoining Languages.
So far no deterministic bottom-up parser has been proposed for any member of the class ofthe so-called "mildly context sensitive" formalisms (Joshi,1985) in which Tree Adjoining Grammars fall.
3 Since theset of Tree Adjoining Languages (TALs) is a strict super-set of the set of Context Free Languages, in order to defineLR-type parsers for TAGs, we need to use a more powerfulconfiguration then a finite state automaton driving a pushdown stack.
The design of deterministic left to right bottomup parsers for TAGs in which a finite state control drives themoves of a Bottom-up Embedded Push Down Stack has beeninvestigated.
The class of corresponding non-deterministicautomata recognizes exactly the set of TALs.Due to the lack of space, we focus our attention on thebottom-up embedded pushdown automaton.
The moves ofthe parser are sequences of moves of the automaton.
Thecomplete construction of LR-style parser for TAGs can befound in Schabes and Vijay-Shanker (1990).Automata Models of TagsBefore we discuss the Bottom-up Embedded Pushdown Au-tomaton (BEPDA) which is used by parser, we will explainthe Embedded Pushdown Automaton (EPDA).
An EPDAis similar to a pushdown automaton (IDA) except hat thestorage of an EPDA is a sequence of pushdown stores.
Amove of an EPDA (see Figure 5) allows for the introduc-tion of bounded pushdowns above and below the current oppushdown.
Informally, this move can be thought of as corre-sponding to the adjoining operation move in TAGs with the3Tree Adjoining Grammars, Modified Head Grammars, Linear IndexedGrammars and Categofial Grammars (all of which generate the same sub-class of context-sensitive languages) fall in the class of the so-called ~mildlycontext sensitive" formalisms.
The Embedded Push Down Automaton rec-ognizes exactly this set of languages (Vijay-Shanker 1987).51read only inp~ tat, estack of stacksBEPDABou dn e, f lof stacks I I  ,o:bou, sizeBounded number ~ ....o/stack elements ~J ~ ,Unbounded number f lof stack elements ~ ~Bounded stacks I B~of bounded size L~UNW~PEPDAmorseUNWRAP move!
E \[\]PUSH moveFigure 4: Bottom-up Embedded Pushdown Automatonpushdowns introduced above and below the current push-down reflecting the tree structure to the left and right of thefoot node of an auxiliary being adjoined.
The spine (pathfrom root to foot node) is left on the previous tack.I   .,,~left of foot of 13pme ~.~spine of \[3H ~'~right ?f f?
?t ?f13Figure 5: Embedded Pushdown AutomatonThe generalization f a PDA to an EPDA whose storage isa sequence of pushdowns captures the generalization of thenature of the derived trees of a CFG to the nature of derivedtrees of a TAG.
From Thatcher (1971), we can observe thatthe path set of a CFG (i.e.
the set of all paths from root toleaves in trees derived by a CFG) is a regular set.
On theother hand, the path set of a TAG is a CFL.
This followsfrom the nature of the adjoining operation of TAGs, whichsuggests tacking along the path from root to a leaf.
Forexample, as we traverse down a path in a tree "r (in Figure 5),if adjunction, say by/3, occurs then the spine of/3 has to betraversed before we can resume the path in "r.Bottom-up Embedded Pushdown AutomatonFor any TAG G, an EPDA can be designed such that itsmoves correspond to a top-down parse of a string generatedby G (EPDA characterizes xactly the set of Tree AdjoiningLanguages, Vijay- Shanker, 1987).
If we wish to designa bottom-up arser, say by adopting a shift reduce parsingstrategy, we have to consider the nature of a reduce moveof such a parser (i.e.
using EPDA storage).
This reducemove, for example applied after completely considering anauxiliary tree, must be allowed to 'remove' some boundedpushdowns above and below some (not necessarily bounded)pushdown.
Thus (see Figure 4), the reduce move is like thedual of the wrapping move performed by an EPDA.Therefore, the Bottom-up Embedded Pushdown Automa-ton (BEPDA), whose moves are dual of an EPDA, has beenintroduced.
The two moves of a BEPDA are the unwrapmove depicted in Figure 4 - which is an inverse of the wrapmove of an EPDA - and the introduction of new pushdownson top of the previous pushdown (push move).
In an EPDA,when the top pushdown is emptied, the next pushdown au-tomatically becomes the new top pushdown.
The inverse ofthis step is to allow for the introduction of new pushdownsabove the previous top pushdown.
These are the two movesallowed in a BEPDA, the various steps in our parsers aresequences of one or more such moves.Due to space constraints, we do not show the equiva-lence between BEPDA and EPDA apart from noting thatthe moves of the two machines are dual of each other.Using the BEPDA, the parser ecognizes the derived treeinside out: it extracts recursively the innermost auxiliary treethat has no adjunction performed in it.
Schabes and Vijay-Shanker (1990) give a complete xplanation of the parsermoves and its construction.
The accuracy of the parsingtable can also be improved by computing lookaheads forTAGs.Similar to the work of Lang (1974) and Tomita (1987)extending LR parsers for arbitrary CFGs, the LR parsers forTAGs can be extended to solve by pseudo-parallelism theconflicts of moves.52ConclusionDuring the past year there have been two very significant de-velopments inthe area of Tree Adjoining Grammars (TAGs):synchronous TAGs and efficient processing of TAGs.A variant of TAGs called Synchronous TAGs has beendeveloped, which is used to relate expressions of natural lan-guages to their associated semantics represented in a logicalform language.
The key idea is that the logical form lan-guage itself can be described by a TAG.
The two TAGs worksynchronously, in the sense that he certain correspondences(links) are stated initially between the elementary trees of thetwo TAGs and then universal composition operations (suchas substitution and adjoining) are carried out synchronouslyon the linked nodes of the two TAGs.
Synchronous TAGsare used for language interpretation, generation and machinetranslation.The second evelopment is the design of LR-style parsersfor TAGs.
The existence of the push down automata forcontext-free grammars is crucial for the development ofthese techniques for the parsing of context-free languages.In order to extend the LR techniques to TAGs it is neces-sary to find bottom-up automaton that is exactly equivalentto TAGs.
This is precisely what has been achieved by thediscovery of the Bottom-up Embedded Push Down Automa-ton (BPDA).
Using BPDA the first deterministic left to rightparsers for the Tree Adjoining Languages were developed.ReferencesAbei116, Anne and Schabes, Yves, 1989.
Parsing Idioms inTree Adjoining Grammars.
In Fourth Conference of theEuropean Chapter of the Association for ComputationalLinguistics (EA CL ' 89 ).
Manchester.Abeill6, Anne, Schabes, Yves, and Joshi, Aravind K., 1990.Using Lexicalized Tree Adjoining Grammars for MachineTranslation.
In Proceedings of the 13 th InternationalConference on Computational Linguistics (COLING'90).Helsinki.Joshi, Aravind K., 1985.
How Much Context-Sensitivityis Necessary for Characterizing Structural Descriptions--Tree Adjoining Grammars.
In Dowty, D., Karttunen, L.,and Zwicky, A.
(editors), Natural Language Processing---Theoretical, Computational nd Psychological Perspec-tives.
Cambridge University Press, New York.
Originallypresented in a Workshop on Natural Language Parsing atOhio State University, Columbus, Ohio, May 1983.Joshi, Aravind K., 1987.
An Introduction to Tree AdjoiningGrammars.
In Manaster-Ramer, A.
(editor), Mathematicsof Language.
John Benjamins, Amsterdam.Knuth, D. E., 1965.
On the translation of languages fromleft to righL Inf.
Control 8:607--639.Lang, Bernard, 1974.
Deterministic Techniques for EfficientNon-Deterministic Parsers.
In Loeckx, Jacques (editor),Automata, Languages and Programming, 2nd Colloquium,University of Saarbrficken.
Lecture Notes in ComputerScience, Springer Verlag.R6v6sz, G., 1971.
Unilateral context sensitive grammars andleft to right parsing.
J. Comput.
System Sci.
5:337-352.Schabes, Yves and Vijay-Shanker, K., 1990.
DeterministicLeft to Right Parsing of Tree Adjoining Languages.
In28 th Meeting of the Association for Computational Lin-guistics (ACL'90).
Pittsburgh.Schabes, Yves, Abeill6, Anne, and Joshi, Aravind K., Au-gust 1988.
Parsing Strategies with 'Lexicalized' Gram-mars: Application to Tree Adjoining Grammars.
In Pro-ceedings of the 12 th International Conference on Compu-tational Linguistics (COLING'88).
Budapest, Hungary.Shieber, Stuart and Schabes, Yves, 1990 (a).
SynchronousTree Adjoining Grammars.
In Proceedings of the 13 thInternational Conference on Computational Linguistics(COLING'90).
Helsinki.Shieber, Stuart and Schabes, Yves, 1990 (b).
Generation andSynchronous Tree Adjoining Grammars.
In Proceedingsof the fifth International Workshop on Natural LanguageGeneration.
Pittsburgh.Thatcher, J. W., 1971.
Characterizing Derivations Trees ofContext Free Grammars through aGeneralization fFiniteAutomata Theory.
J. Comput.
Syst.
Sci.
5:365-396.Tomita, Masaru, 1987.
An Efficient Augmented-Context-Free Parsing Algorithm.
Computational Linguistics13:31--46.Turnbull, C. J. M. and Lee, E. S., 1979.
Generalized Deter-ministic Left to Right Parsing.
Acta lnformatica 12:187-207.Vijay-Shanker, K., 1987.
A Study of Tree Adjoining Gram-mars.
PhD thesis, Department of Computer and Informa-tion Science, University of Pennsylvania.Walters, D.A., 1970.
Deterministic Context-Sensitive Lan-guages.
Inf.
Control 17:14-40.53
