Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 23?32,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsInferring Logical Forms From DenotationsPanupong PasupatComputer Science DepartmentStanford Universityppasupat@cs.stanford.eduPercy LiangComputer Science DepartmentStanford Universitypliang@cs.stanford.eduAbstractA core problem in learning semanticparsers from denotations is picking outconsistent logical forms?those that yieldthe correct denotation?from a combina-torially large space.
To control the searchspace, previous work relied on restrictedset of rules, which limits expressivity.
Inthis paper, we consider a much more ex-pressive class of logical forms, and showhow to use dynamic programming to effi-ciently represent the complete set of con-sistent logical forms.
Expressivity alsointroduces many more spurious logicalforms which are consistent with the cor-rect denotation but do not represent themeaning of the utterance.
To addressthis, we generate fictitious worlds and usecrowdsourced denotations on these worldsto filter out spurious logical forms.
Onthe WIKITABLEQUESTIONS dataset, weincrease the coverage of answerable ques-tions from 53.5% to 76%, and the ad-ditional crowdsourced supervision lets usrule out 92.1% of spurious logical forms.1 IntroductionConsider the task of learning to answer com-plex natural language questions (e.g., ?Where didthe last 1st place finish occur??)
using onlyquestion-answer pairs as supervision (Clarke etal., 2010; Liang et al, 2011; Berant et al,2013; Artzi and Zettlemoyer, 2013).
Seman-tic parsers map the question into a logical form(e.g., R[Venue].argmax(Position.1st, Index))that can be executed on a knowledge source to ob-tain the answer (denotation).
Logical forms arevery expressive since they can be recursively com-posed, but this very expressivity makes it moredifficult to search over the space of logical forms.Previous work sidesteps this obstacle by restrict-ing the set of possible logical form compositions,but this is limiting.
For instance, for the systemin Pasupat and Liang (2015), in only 53.5% of theexamples was the correct logical form even in theset of generated logical forms.The goal of this paper is to solve two main chal-lenges that prevent us from generating more ex-pressive logical forms.
The first challenge is com-putational: the number of logical forms grows ex-ponentially as their size increases.
Directly enu-merating over all logical forms becomes infeasi-ble, and pruning techniques such as beam searchcan inadvertently prune out correct logical forms.The second challenge is the large increase inspurious logical forms?those that do not reflectthe semantics of the question but coincidentallyexecute to the correct denotation.
For example,while logical forms z1, .
.
.
, z5in Figure 1 are allconsistent (they execute to the correct answer y),the logical forms z4and z5are spurious and wouldgive incorrect answers if the table were to change.We address these two challenges by solving twointerconnected tasks.
The first task, which ad-dresses the computational challenge, is to enumer-ate the set Z of all consistent logical forms givena question x, a knowledge source w (?world?
),and the target denotation y (Section 4).
Observ-ing that the space of possible denotations growsmuch more slowly than the space of logical forms,we perform dynamic programming on denotations(DPD) to make search feasible.
Our method isguaranteed to find all consistent logical forms upto some bounded size.Given the set Z of consistent logical forms, thesecond task is to filter out spurious logical formsfrom Z (Section 5).
Using the property that spuri-ous logical forms ultimately give a wrong answerwhen the data in the world w changes, we create23Year Venue Position Event Time2001 Hungary 2nd 400m 47.122003 Finland 1st 400m 46.692005 Germany 11th 400m 46.622007 Thailand 1st relay 182.052008 China 7th relay 180.32x: ?Where did the last 1st place finish occur?
?y: ThailandConsistentCorrectz1: R[Venue].argmax(Position.1st, Index)Among rows with Position = 1st, pick the one withmaximum index, then return the Venue of that row.z2: R[Venue].Index.max(R[Index].Position.1st)Find the maximum index of rows with Position =1st, then return the Venue of the row with that index.z3: R[Venue].argmax(Position.Number.1,R[?x.R[Date].R[Year].x])Among rows with Position number 1, pick one withlatest date in the Year column and return the Venue.Spuriousz4: R[Venue].argmax(Position.Number.1,R[?x.R[Number].R[Time].x])Among rows with Position number 1, pick the onewith maximum Time number.
Return the Venue.z5: R[Venue].Year.Number.
(R[Number].R[Year].argmax(Type.Row, Index)?1)Subtract 1 from the Year in the last row, then returnthe Venue of the row with that Year.Inconsistentz?
: R[Venue].argmin(Position.1st, Index)Among rows with Position = 1st, pick the one withminimum index, then return the Venue.
(= Finland)Figure 1: Six logical forms generated from thequestion x.
The first five are consistent: they ex-ecute to the correct answer y.
Of those, correctlogical forms z1, z2, and z3are different ways torepresent the semantics of x, while spurious logi-cal forms z4and z5get the right answer y for thewrong reasons.fictitious worlds to test the denotations of the logi-cal forms in Z.
We use crowdsourcing to annotatethe correct denotations on a subset of the gener-ated worlds.
To reduce the amount of annotationneeded, we choose the subset that maximizes theexpected information gain.
The pruned set of log-ical forms would provide a stronger supervisionsignal for training a semantic parser.We test our methods on the WIKITABLEQUES-TIONS dataset of complex questions on Wikipediatables.
We define a simple, general set of deduc-tion rules (Section 3), and use DPD to confirmthat the rules generate a correct logical form in...r1 ?
?
?1 Finland 1str2 ?
?
?2 Germany 11thr3 ?
?
?3 Thailand 1st...1111NextNextNextNextIndexIndexIndexVenue PositionVenue PositionVenue PositionNumberNumberNumberz1 = R[Venue].
argmax( Position.
1st , Index)Figure 2: The table in Figure 1 is converted into agraph.
The recursive execution of logical form z1is shown via the different colors and styles.76% of the examples, up from the 53.5% in Pa-supat and Liang (2015).
Moreover, unlike beamsearch, DPD is guaranteed to find all consistentlogical forms up to a bounded size.
Finally, by us-ing annotated data on fictitious worlds, we are ableto prune out 92.1% of the spurious logical forms.2 SetupThe overarching motivation of this work is allow-ing people to ask questions involving computa-tion on semi-structured knowledge sources suchas tables from the Web.
This section introduceshow the knowledge source is represented, how thecomputation is carried out using logical forms, andour task of inferring correct logical forms.Worlds.
We use the term world to refer to a col-lection of entities and relations between entities.One way to represent a world w is as a directedgraph with nodes for entities and directed edgesfor relations.
(For example, a world about geog-raphy would contain a node Europe with an edgeContains to another node Germany.
)In this paper, we use data tables from the Webas knowledge sources, such as the one in Figure 1.We follow the construction in Pasupat and Liang(2015) for converting a table into a directed graph(see Figure 2).
Rows and cells become nodes (e.g.,r0= first row and Finland) while columns be-come labeled directed edges between them (e.g.,Venue maps r1to Finland).
The graph is aug-mented with additional edges Next (from each24row to the next) and Index (from each row to itsindex number).
In addition, we add normaliza-tion edges to cell nodes, including Number (fromthe cell to the first number in the cell), Num2 (thesecond number), Date (interpretation as a date),and Part (each list item if the cell represents alist).
For example, a cell with content ?3-4?
hasa Number edge to the integer 3, a Num2 edge to 4,and a Date edge to XX-03-04.Logical forms.
We can perform computation ona world w using a logical form z, a small programthat can be executed on the world, resulting in adenotation JzKw.We use lambda DCS (Liang, 2013) as the lan-guage of logical forms.
As a demonstration, wewill use z1in Figure 2 as an example.
The small-est units of lambda DCS are entities (e.g., 1st) andrelations (e.g., Position).
Larger logical formscan be constructed using logical operations, andthe denotation of the new logical form can be com-puted from denotations of its constituents.
For ex-ample, applying the join operation on Positionand 1st gives Position.1st, whose denotationis the set of entities with relation Position point-ing to 1st.
With the world in Figure 2, the denota-tion is JPosition.1stKw= {r1, r3}, which cor-responds to the 2nd and 4th rows in the table.
Thepartial logical form Position.1st is then usedto construct argmax(Position.1st, Index), thedenotation of which can be computed by mappingthe entities in JPosition.1stKw= {r1, r3} us-ing the relation Index ({r0: 0, r1: 1, .
.
.
}), andthen picking the one with the largest mapped value(r3, which is mapped to 3).
The resulting logicalform is finally combined with R[Venue] with an-other join operation.
The relation R[Venue] is thereverse of Venue, which corresponds to traversingVenue edges in the reverse direction.Semantic parsing.
A semantic parser maps anatural language utterance x (e.g., ?Where did thelast 1st place finish occur??)
into a logical form z.With denotations as supervision, a semantic parseris trained to put high probability on z?s that areconsistent?logical forms that execute to the cor-rect denotation y (e.g., Thailand).
When the spaceof logical forms is large, searching for consistentlogical forms z can become a challenge.As illustrated in Figure 1, consistent logicalforms can be divided into two groups: correct log-ical forms represent valid ways for computing theanswer, while spurious logical forms accidentallyget the right answer for the wrong reasons (e.g., z4picks the row with the maximum time but gets thecorrect answer anyway).Tasks.
Denote by Z and Zcthe sets of all con-sistent and correct logical forms, respectively.
Thefirst task is to efficiently compute Z given an ut-terance x, a world w, and the correct denotation y(Section 4).
With the set Z, the second task is toinfer Zcby pruning spurious logical forms from Z(Section 5).3 Deduction rulesThe space of logical forms given an utterance xand a world w is defined recursively by a set of de-duction rules (Table 1).
In this setting, each con-structed logical form belongs to a category (Set,Rel, or Map).
These categories are used for typechecking in a similar fashion to categories in syn-tactic parsing.
Each deduction rule specifies thecategories of the arguments, category of the re-sulting logical form, and how the logical form isconstructed from the arguments.Deduction rules are divided into base rules andcompositional rules.
A base rule follows one ofthe following templates:TokenSpan[span]?
c [f(span)] (1)?
?
c [f()] (2)A rule of Template 1 is triggered by a span oftokens from x (e.g., to construct z1in Figure 2from x in Figure 1, Rule B1 from Table 1 con-structs 1st of category Set from the phrase ?1st?
).Meanwhile, a rule of Template 2 generates a log-ical form without any trigger (e.g., Rule B5 gen-erates Position of category Rel from the graphedge Position without a specific trigger in x).Compositional rules then construct larger logi-cal forms from smaller ones:c1[z1] + c2[z2]?
c [g(z1, z2)] (3)c1[z1]?
c [g(z1)] (4)A rule of Template 3 combines partial logicalforms z1and z2of categories c1and c2intog(z1, z2) of category c (e.g., Rule C1 uses 1st ofcategory Set and Position of category Rel to con-struct Position.1st of category Set).
Template 4works similarly.Most rules construct logical forms without re-quiring a trigger from the utterance x.
This is25Rule SemanticsBase RulesB1 TokenSpan?
Set fuzzymatch(span)(entity fuzzily matching the text: ?chinese??
China)B2 TokenSpan?
Set val(span)(interpreted value: ?march 2015??
2015-03-XX)B3 ?
?
Set Type.Row(the set of all rows)B4 ?
?
Set c ?
ClosedClass(any entity from a column with few unique entities)(e.g., 400m or relay from the Event column)B5 ?
?
Rel r ?
GraphEdges(any relation in the graph: Venue, Next, Num2, .
.
.
)B6 ?
?
Rel != | < | <= | > | >=Compositional RulesC1 Set + Rel?
Set z2.z1| R[z2].z1(R[z] is the reverse of z; i.e., flip the arrow direction)C2 Set?
Set a(z1)(a ?
{count, max, min, sum, avg})C3 Set + Set?
Set z1u z2| z1unionsq z2| z1?
z2(subtraction is only allowed on numbers)Compositional Rules with MapsInitializationM1 Set?
Map (z1, x) (identity map)Operations on MapM2 Map + Rel?
Map (u1, z2.b1) | (u1,R[z2].b1)M3 Map?
Map (u1, a(b1))(a ?
{count, max, min, sum, avg})M4 Map + Set?
Map (u1, b1u z2) | .
.
.M5 Map + Map?
Map (u1, b1u b2) | .
.
.
(Allowed only when u1= u2)(Rules M4 and M5 are repeated for unionsq and ?
)FinalizationM6 Map?
Set argmin(u1,R[?x.b1])| argmax(u1,R[?x.b1])Table 1: Deduction rules define the space of logi-cal forms by specifying how partial logical formsare constructed.
The logical form of the i-th argu-ment is denoted by zi(or (ui, bi) if the argumentis a Map).
The set of final logical forms containsany logical form with category Set.crucial for generating implicit relations (e.g., gen-erating Year from ?what?s the venue in 2000?
?without a trigger ?year?
), and generating opera-tions without a lexicon (e.g., generating argmaxfrom ?where?s the longest competition?).
How-ever, the downside is that the space of possiblelogical forms becomes very large.The Map category.
The technique in this paperrequires execution of partial logical forms.
Thisposes a challenge for argmin and argmax oper-ations, which take a set and a binary relation asarguments.
The binary could be a complex func-tion (e.g., in z3from Figure 1).
While it is possibleto build the binary independently from the set, ex-ecuting a complex binary is sometimes impossible(e.g., the denotation of ?x.count(x) is impossibleto write explicitly without knowledge of x).We address this challenge with the Map cat-egory.
A Map is a pair (u, b) of a finite setu (unary) and a binary relation b.
The deno-tation of (u, b) is (JuKw, JbK?w) where the binaryJbK?wis JbKwwith the domain restricted to the setJuKw.
For example, consider the construction ofargmax(Position.1st, Index).
After construct-ing Position.1st with denotation {r1, r3}, RuleM1 initializes (Position.1st, x) with denotation({r1, r3}, {r1: {r1}, r3: {r3}}).
Rule M2 is thenapplied to generate (Position.1st,R[Index].x)with denotation ({r1, r3}, {r1: {1}, r3: {3}}).Finally, Rule M6 converts the Map into the desiredargmax logical form with denotation {r3}.Generality of deduction rules.
Using domainknowledge, previous work restricted the space oflogical forms by manually defining the categoriesc or the semantic functions f and g to fit the do-main.
For example, the category Set might be di-vided into Records, Values, and Atomic when theknowledge source is a table (Pasupat and Liang,2015).
Another example is when a compositionalrule g (e.g., sum(z1)) must be triggered by somephrase in a lexicon (e.g., words like ?total?
thatalign to sum in the training data).
Such restrictionsmake search more tractable but greatly limit thescope of questions that can be answered.Here, we have increased the coverage of logi-cal forms by making the deduction rules simpleand general, essentially following the syntax oflambda DCS.
The base rules only generates en-tities that approximately match the utterance, butall possible relations, and all possible further com-binations.Beam search.
Given the deduction rules, an ut-terance x and a worldw, we would like to generateall derived logical forms Z.
We first present thefloating parser (Pasupat and Liang, 2015), whichuses beam search to generate Zb?
Z, a usuallyincomplete subset.
Intuitively, the algorithm firstconstructs base logical forms based on spans ofthe utterance, and then builds larger logical formsof increasing size in a ?floating?
fashion?withoutrequiring a trigger from the utterance.Formally, partial logical forms with category cand size s are stored in a cell (c, s).
The algorithmfirst generates base logical forms from base deduc-tion rules and store them in cells (c, 0) (e.g., thecell (Set, 0) contains 1st, Type.Row, and so on).Then for each size s = 1, .
.
.
, smax, we populate26?
?
??
?
??
?
??
?
??
?
??
?
??
?
?
(Set , 7,{Thailand})(Set , 7,{Finland})Figure 3: The first pass of DPD constructs cells(c, s, d) (square nodes) using denotationally in-variant semantic functions (circle nodes).
The sec-ond pass enumerates all logical forms along pathsthat lead to the correct denotation y (solid lines).the cells (c, s) by applying compositional rules onpartial logical forms with size less than s. For in-stance, when s = 2, we can apply Rule C1 onlogical forms Number.1 from cell (Set, s1= 1)and Position from cell (Rel, s2= 0) to createPosition.Number.1 in cell (Set, s0+s1+1 = 2).After populating each cell (c, s), the list of logi-cal forms in the cell is pruned based on the modelscores to a fixed beam size in order to control thesearch space.
Finally, the set Zbis formed bycollecting logical forms from all cells (Set, s) fors = 1, .
.
.
, smax.Due to the generality of our deduction rules, thenumber of logical forms grows quickly as the sizes increases.
As such, partial logical forms thatare essential for building the desired logical formsmight fall off the beam early on.
In the next sec-tion, we present a new search method that com-presses the search space using denotations.4 Dynamic programming on denotationsOur first step toward finding all correct logicalforms is to represent all consistent logical forms(those that execute to the correct denotation).
For-mally, given x, w, and y, we wish to generate theset Z of all logical forms z such that JzKw= y.As mentioned in the previous section, beamsearch does not recover the full set Z due to prun-ing.
Our key observation is that while the numberof logical forms explodes, the number of distinctdenotations of those logical forms is much morecontrolled, as multiple logical forms can share thesame denotation.
So instead of directly enumerat-ing logical forms, we use dynamic programmingon denotations (DPD), which is inspired by sim-ilar methods from program induction (Lau et al,2003; Liang et al, 2010; Gulwani, 2011).The main idea of DPD is to collapse logicalforms with the same denotation together.
Insteadof using cells (c, s) as in beam search, we per-form dynamic programming using cells (c, s, d)where d is a denotation.
For instance, the logi-cal form Position.Number.1 will now be storedin cell (Set, 2, {r1, r3}).For DPD to work, each deduction rule musthave a denotationally invariant semantic functiong, meaning that the denotation of the resulting log-ical form g(z1, z2) only depends on the denota-tions of z1and z2:Jz1Kw= Jz?1Kw?
Jz2Kw= Jz?2Kw?
Jg(z1, z2)Kw= Jg(z?1, z?2)KwAll of our deduction rules in Table 1 are de-notationally invariant, but a rule that, for in-stance, returns the argument with the larger log-ical form size would not be.
Applying a de-notationally invariant deduction rule on any pairof logical forms from (c1, s1, d1) and (c2, s2, d2)always results in a logical form with the samedenotation d in the same cell (c, s1+ s2+1, d).1(For example, the cell (Set, 4, {r3}) con-tains z1:= argmax(Position.1st, Index) andz?1:= argmin(Event.Relay, Index).
Combin-ing each of these with Venue using Rule C1 givesR[Venue].z1and R[Venue].z?1, which belong tothe same cell (Set, 5, {Thailand})).Algorithm.
DPD proceeds in two forwardpasses.
The first pass finds the possible combi-nations of cells (c, s, d) that lead to the correct de-notation y, while the second pass enumerates thelogical forms in the cells found in the first pass.Figure 3 illustrates the DPD algorithm.In the first pass, we are only concerned aboutfinding relevant cell combinations and not the ac-tual logical forms.
Therefore, any logical formthat belongs to a cell could be used as an argu-ment of a deduction rule to generate further logicalforms.
Thus, we keep at most one logical form percell; subsequent logical forms that are generatedfor that cell are discarded.After populating all cells up to size smax, welist all cells (Set, s, y) with the correct denotationy, and then note all possible rule combinations(cell1, rule) or (cell1, cell2, rule) that lead to those1Semantic functions f with one argument work similarly.27final cells, including the combinations that yieldeddiscarded logical forms.The second pass retrieves the actual logicalforms that yield the correct denotation.
To do this,we simply populate the cells (c, s, d) with all log-ical forms, using only rule combinations that leadto final cells.
This elimination of irrelevant rulecombinations effectively reduces the search space.
(In Section 6.2, we empirically show that the num-ber of cells considered is reduced by 98.7%.
)The parsing chart is represented as a hyper-graph as in Figure 3.
After eliminating unusedrule combinations, each of the remaining hyper-paths from base predicates to the target denotationcorresponds to a single logical form.
making theremaining parsing chart a compact implicit repre-sentation of all consistent logical forms.
This rep-resentation is guaranteed to cover all possible log-ical forms under the size limit smaxthat can beconstructed by the deduction rules.In our experiments, we apply DPD on the de-duction rules in Table 1 and explicitly enumeratethe logical forms produced by the second pass.
Forefficiency, we prune logical forms that are clearlyredundant (e.g., applying max on a set of size 1).We also restrict a few rules that might otherwisecreate too many denotations.
For example, we re-stricted the union operation (unionsq) except unions oftwo entities (e.g., we allow Germany unionsq Finlandbut not Venue.Hungary unionsq .
.
.
), subtraction whenbuilding a Map, and count on a set of size 1.25 Fictitious worldsAfter finding the set Z of all consistent logicalforms, we want to filter out spurious logical forms.To do so, we observe that semantically correct log-ical forms should also give the correct denotationin worlds w?other than than w. In contrast, spu-rious logical forms will fail to produce the correctdenotation on some other world.Generating fictitious worlds.
With the ob-servation above, we generate fictitious worldsw1, w2, .
.
.
, where each world wiis a slight alter-ation of w. As we will be executing logical formsz ?
Z on wi, we should ensure that all entities andrelations in z ?
Z appear in the fictitious world wi(e.g., z1in Figure 1 would be meaningless if theentity 1st does not appear in wi).
To this end, we2While we technically can apply count on sets of size 1,the number of spurious logical forms explodes as there aretoo many sets of size 1 generated.Year Venue Position Event Time2001 Finland 7th relay 46.622003 Germany 1st 400m 180.322005 China 1st relay 47.122007 Hungary 7th relay 182.05Figure 4: From the example in Figure 1, we gen-erate a table for the fictitious world w1.w w1w2?
?
?z1Thailand China Finland ?
?
?
}q1z2Thailand China Finland ?
?
?z3Thailand China Finland ?
?
?z4Thailand Germany China ?
?
? }
q2z5Thailand China China ?
?
?
}q3z6Thailand China China ?
?
?............Figure 5: We execute consistent logical formszi?
Z on fictitious worlds to get denotation tu-ples.
Logical forms with the same denotation tupleare grouped into the same equivalence class qj.impose that all predicates present in the originalworld w should also be present in wias well.In our case where the world w comes from adata table t, we construct wifrom a new table tiasfollows: we go through each column of t and re-sample the cells in that column.
The cells are sam-pled using random draws without replacement ifthe original cells are all distinct, and with replace-ment otherwise.
Sorted columns are kept sorted.To ensure that predicates in w exist in wi, we usethe same set of table columns and enforce that anyentity fuzzily matching a span in the question xmust be present in ti(e.g., for the example in Fig-ure 1, the generated timust contain ?1st?).
Fig-ure 4 shows an example fictitious table generatedfrom the table in Figure 1.Fictitious worlds are similar to test suites forcomputer programs.
However, unlike manuallydesigned test suites, we do not yet know the cor-rect answer for each fictitious world or whether aworld is helpful for filtering out spurious logicalforms.
The next subsections introduce our methodfor choosing a subset of useful fictitious worlds tobe annotated.Equivalence classes.
Let W = (w1, .
.
.
, wk) bethe list of all possible fictitious worlds.
For eachz ?
Z, we define the denotation tuple JzKW=(JzKw1, .
.
.
, JzKwk).
We observe that some logi-cal forms produce the same denotation across all28fictitious worlds.
This may be due to an algebraicequivalence in logical forms (e.g., z1and z2in Fig-ure 1) or due to the constraints in the constructionof fictitious worlds (e.g., z1and z3in Figure 1 areequivalent as long as the Year column is sorted).We group logical forms into equivalence classesbased on their denotation tuples, as illustrated inFigure 5.
When the question is unambiguous, weexpect at most one equivalence class to containcorrect logical forms.Annotation.
To pin down the correct equiva-lence class, we acquire the correct answers to thequestion x on some subset W?= (w?1, .
.
.
, w?`) ?W of ` fictitious worlds, as it is impractical to ob-tain annotations on all fictitious worlds in W .
Wecompile equivalence classes that agree with the an-notations into a set Zcof correct logical forms.We want to choose W?that gives us the mostinformation about the correct equivalence class aspossible.
This is analogous to standard practicesin active learning (Settles, 2010).3Let Q be theset of all equivalence classes q, and let JqKW?bethe denotation tuple computed by executing an ar-bitrary z ?
q on W?.
The subset W?divides Qinto partitions Ft= {q ?
Q : JqKW?= t} basedon the denotation tuples t (e.g., from Figure 5, ifW?contains just w2, then q2and q3will be in thesame partition F(China)).
The annotation t?, whichis also a denotation tuple, will mark one of thesepartitions Ft?as correct.
Thus, to prune out manyspurious equivalence classes, the partitions shouldbe as numerous and as small as possible.More formally, we choose a subset W?thatmaximizes the expected information gain (orequivalently, the reduction in entropy) aboutthe correct equivalence class given the annota-tion.
With random variables Q ?
Q represent-ing the correct equivalence class and T?W?forthe annotation on worlds W?, we seek to findargminW?H(Q | T?W?).
Assuming a uniformprior on Q (p(q) = 1/|Q|) and accurate annota-tion (p(t?| q) = I[q ?
Ft?
]):H(Q | T?W?)
=?q,tp(q, t) logp(t)p(q, t)=1|Q|?t|Ft| log |Ft|.
(*)3The difference is that we are obtaining partial informa-tion about an individual example rather than partial informa-tion about the parameters.We exhaustively search for W?that minimizes(*).
The objective value follows our intuition since?t|Ft| log |Ft| is small when the terms |Ft| aresmall and numerous.In our experiments, we approximate the fullset W of fictitious worlds by generating k =30 worlds to compute equivalence classes.
Wechoose a subset of ` = 5 worlds to be annotated.6 ExperimentsFor the experiments, we use the training portionof the WIKITABLEQUESTIONS dataset (Pasupatand Liang, 2015), which consists of 14,152 ques-tions on 1,679 Wikipedia tables gathered by crowdworkers.
Answering these complex questions re-quires different types of operations.
The sameoperation can be phrased in different ways (e.g.,?best?, ?top ranking?, or ?lowest ranking num-ber?)
and the interpretation of some phrases de-pend on the context (e.g., ?number of ?
could bea table lookup or a count operation).
The lexicalcontent of the questions is also quite diverse: evenexcluding numbers and symbols, the 14,152 train-ing examples contain 9,671 unique words, only10% of which appear more than 10 times.We attempted to manually annotate the first 300examples with lambda DCS logical forms.
Wesuccessfully constructed correct logical forms for84% of these examples, which is a good numberconsidering the questions were created by humanswho could use the table however they wanted.
Theremaining 16% reflect limitations in our setup?for example, non-canonical table layouts, answersappearing in running text or images, and com-mon sense reasoning (e.g., knowing that ?Quarter-final?
is better than ?Round of 16?
).6.1 Generality of deduction rulesWe compare our set of deduction rules with theone given in Pasupat and Liang (2015) (hence-forth PL15).
PL15 reported generating the anno-tated logical form in 53.5% of the first 200 exam-ples.
With our more general deduction rules, weuse DPD to verify that the rules are able to gener-ate the annotated logical form in 76% of the first300 examples, within the logical form size limitsmaxof 7.
This is 90.5% of the examples that weresuccessfully annotated.
Figure 6 shows some ex-amples of logical forms we cover that PL15 couldnot.
Since DPD is guaranteed to find all consis-tent logical forms, we can be sure that the logical29?which opponent has the most wins?z = argmax(R[Opponent].Type.Row,R[?x.count(Opponent.x u Result.Lost])?how long did ian armstrong serve?
?z = R[Num2].R[Term].Member.IanArmstrong?R[Number].R[Term].Member.IanArmstrong?which players came in a place before lukas bauer?
?z = R[Name].Index.<.R[Index].Name.LukasBauer?which players played the same position as ardo kreek?
?z = R[Player].Position.R[Position].Player.Ardou !=.ArdoFigure 6: Several example logical forms our sys-tem can generated that are not covered by the de-duction rules from the previous work PL15.forms not covered are due to limitations of the de-duction rules.
Indeed, the remaining examples ei-ther have logical forms with size larger than 7 orrequire other operations such as addition, union ofarbitrary sets, etc.6.2 Dynamic programming on denotationsSearch space.
To demonstrate the savingsgained by collapsing logical forms with the samedenotation, we track the growth of the number ofunique logical forms and denotations as the log-ical form size increases.
The plot in Figure 7shows that the space of logical forms explodesmuch more quickly than the space of denotations.The use of denotations also saves us from con-sidering a significant amount of irrelevant partiallogical forms.
On average over 14,152 trainingexamples, DPD generates approximately 25,000consistent logical forms.
The first pass of DPDgenerates ?
153,000 cells (c, s, d), while the sec-ond pass generates only ?
2,000 cells resultingfrom ?
8,000 rule combinations, resulting in a98.7% reduction in the number of cells that haveto be considered.Comparison with beam search.
We compareDPD to beam search on the ability to generate (butnot rank) the annotated logical forms.
We considertwo settings: when the beam search parametersare uninitialized (i.e., the beams are pruned ran-domly), and when the parameters are trained usingthe system from PL15 (i.e., the beams are prunedbased on model scores).
The plot in Figure 8shows that DPD generates more annotated logicalforms (76%) compared to beam search (53.7%),even when beam search is guided heuristically bylearned parameters.
Note that DPD is an exact al-gorithm and does not require a heuristic.0 1 2 3 4 5 6 7logical form size00.2K0.4K0.6K0.8K1.0Kcount logical formsdenotationsFigure 7: The median of the number of logicalforms (dashed) and denotations (solid) as the for-mula size increases.
The space of logical formsgrows much faster than the space of denotations.0 5000 10000 15000 20000 25000number of final LFs produced0.00.20.40.60.8annotatedLFscoverage ?Figure 8: The number of annotated logical formsthat can be generated by beam search, both unini-tialized (dashed) and initialized (solid), increaseswith the number of candidates generated (con-trolled by beam size), but lacks behind DPD (star).6.3 Fictitious worldsWe now explore how fictitious worlds divide theset of logical forms into equivalence classes, andhow the annotated denotations on the chosenworlds help us prune spurious logical forms.Equivalence classes.
Using 30 fictitious worldsper example, we produce an average of 1,237equivalence classes.
One possible concern withusing a limited number of fictitious worlds is thatwe may fail to distinguish some pairs of non-equivalent logical forms.
We verify the equiva-lence classes against the ones computed using 300fictitious worlds.
We found that only 5% of thelogical forms are split from the original equiva-lence classes.Ideal Annotation.
After computing equivalenceclasses, we choose a subset W?of 5 fictitiousworlds to be annotated based on the information-theoretic objective.
For each of the 252 exam-ples with an annotated logical form z?, we usethe denotation tuple t?= Jz?KW?as the annotatedanswers on the chosen fictitious worlds.
We areable to rule out 98.7% of the spurious equivalenceclasses and 98.3% of spurious logical forms.
Fur-thermore, we are able to filter down to just oneequivalence class in 32.7% of the examples, and30at most three equivalence classes in 51.3% of theexamples.
If we choose 5 fictitious worlds ran-domly instead of maximizing information gain,then the above statistics are 22.6% and 36.5%,respectively.
When more than one equivalenceclasses remain, usually only one class is a dom-inant class with many equivalent logical forms,while other classes are small and contain logicalforms with unusual patterns (e.g., z5in Figure 1).The average size of the correct equivalenceclass is ?
3,000 with the standard deviation of?
8,000.
Because we have an expressive logicallanguage, there are fundamentally many equiva-lent ways of computing the same quantity.Crowdsourced Annotation.
Data from crowd-sourcing is more susceptible to errors.
From the252 annotated examples, we use 177 exampleswhere at least two crowd workers agree on the an-swer of the original world w. When the crowd-sourced data is used to rule out spurious logicalforms, the entire set Z of consistent logical formsis pruned out in 11.3% of the examples, and thecorrect equivalent class is removed in 9% of theexamples.
These issues are due to annotation er-rors, inconsistent data (e.g., having date of deathbefore birth date), and different interpretations ofthe question on the fictitious worlds.
For the re-maining examples, we are able to prune out 92.1%of spurious logical forms (or 92.6% of spuriousequivalence classes).To prevent the entire Z from being pruned, wecan relax our assumption and keep logical formsz that disagree with the annotation in at most 1fictitious world.
The number of times Z is prunedout is reduced to 3%, but the number of spuriouslogical forms pruned also decreases to 78%.7 Related Work and DiscussionThis work evolved from a long tradition of learn-ing executable semantic parsers, initially from an-notated logical forms (Zelle and Mooney, 1996;Kate et al, 2005; Zettlemoyer and Collins, 2005;Zettlemoyer and Collins, 2007; Kwiatkowski etal., 2010), but more recently from denotations(Clarke et al, 2010; Liang et al, 2011; Berantet al, 2013; Kwiatkowski et al, 2013; Pasupatand Liang, 2015).
A central challenge in learn-ing from denotations is finding consistent logicalforms (those that execute to a given denotation).As Kwiatkowski et al (2013) and Berantand Liang (2014) both noted, a chief difficultywith executable semantic parsing is the ?schemamismatch?
?words in the utterance do not mapcleanly onto the predicates in the logical form.This mismatch is especially pronounced in theWIKITABLEQUESTIONS of Pasupat and Liang(2015).
In the second example of Figure 6, ?howlong?
is realized by a logical form that computesa difference between two dates.
The ramificationof this mismatch is that finding consistent logi-cal forms cannot solely proceed from the languageside.
This paper is about using annotated denota-tions to drive the search over logical forms.This takes us into the realm of program in-duction, where the goal is to infer a program(logical form) from input-output pairs (for us,world-denotation pairs).
Here, previous workhas also leveraged the idea of dynamic program-ming on denotations (Lau et al, 2003; Liang etal., 2010; Gulwani, 2011), though for more con-strained spaces of programs.
Continuing the pro-gram analogy, generating fictitious worlds is simi-lar in spirit to fuzz testing for generating new testcases (Miller et al, 1990), but the goal there iscoverage in a single program rather than identi-fying the correct (equivalence class of) programs.This connection can potentially improve the flowof ideas between the two fields.Finally, the effectiveness of dynamic program-ming on denotations relies on having a manage-able set of denotations.
For more complex logi-cal forms and larger knowledge graphs, there aremany possible angles worth exploring: performingabstract interpretation to collapse denotations intoequivalence classes (Cousot and Cousot, 1977),relaxing the notion of getting the correct denota-tion (Steinhardt and Liang, 2015), or working in acontinuous space and relying on gradient descent(Guu et al, 2015; Neelakantan et al, 2016; Yin etal., 2016; Reed and de Freitas, 2016).
This paper,by virtue of exact dynamic programming, sets thestandard.Acknowledgments.
We gratefully acknowledgethe support of the Google Natural Language Un-derstanding Focused Program.
In addition, wewould like to thank anonymous reviewers for theirhelpful comments.Reproducibility.
Code and experiments forthis paper are available on the CodaLab platformat https://worksheets.codalab.org/worksheets/0x47cc64d9c8ba4a878807c7c35bb22a42/.31ReferencesY.
Artzi and L. Zettlemoyer.
2013.
UW SPF: The Uni-versity of Washington semantic parsing framework.arXiv preprint arXiv:1311.3011.J.
Berant and P. Liang.
2014.
Semantic parsing viaparaphrasing.
In Association for ComputationalLinguistics (ACL).J.
Berant, A. Chou, R. Frostig, and P. Liang.
2013.Semantic parsing on Freebase from question-answerpairs.
In Empirical Methods in Natural LanguageProcessing (EMNLP).J.
Clarke, D. Goldwasser, M. Chang, and D. Roth.2010.
Driving semantic parsing from the world?s re-sponse.
In Computational Natural Language Learn-ing (CoNLL), pages 18?27.P.
Cousot and R. Cousot.
1977.
Abstract interpreta-tion: a unified lattice model for static analysis ofprograms by construction or approximation of fix-points.
In Principles of Programming Languages(POPL), pages 238?252.S.
Gulwani.
2011.
Automating string processing inspreadsheets using input-output examples.
ACMSIGPLAN Notices, 46(1):317?330.K.
Guu, J. Miller, and P. Liang.
2015.
Travers-ing knowledge graphs in vector space.
In Em-pirical Methods in Natural Language Processing(EMNLP).R.
J. Kate, Y. W. Wong, and R. J. Mooney.
2005.Learning to transform natural to formal languages.In Association for the Advancement of Artificial In-telligence (AAAI), pages 1062?1068.T.
Kwiatkowski, L. Zettlemoyer, S. Goldwater, andM.
Steedman.
2010.
Inducing probabilistic CCGgrammars from logical form with higher-order uni-fication.
In Empirical Methods in Natural LanguageProcessing (EMNLP), pages 1223?1233.T.
Kwiatkowski, E. Choi, Y. Artzi, and L. Zettlemoyer.2013.
Scaling semantic parsers with on-the-fly on-tology matching.
In Empirical Methods in NaturalLanguage Processing (EMNLP).T.
Lau, S. Wolfman, P. Domingos, and D. S. Weld.2003.
Programming by demonstration using versionspace algebra.
Machine Learning, 53:111?156.P.
Liang, M. I. Jordan, and D. Klein.
2010.
Learn-ing programs: A hierarchical Bayesian approach.In International Conference on Machine Learning(ICML), pages 639?646.P.
Liang, M. I. Jordan, and D. Klein.
2011.
Learn-ing dependency-based compositional semantics.
InAssociation for Computational Linguistics (ACL),pages 590?599.P.
Liang.
2013.
Lambda dependency-based composi-tional semantics.
arXiv.B.
P. Miller, L. Fredriksen, and B.
So.
1990.
An empir-ical study of the reliability of UNIX utilities.
Com-munications of the ACM, 33(12):32?44.A.
Neelakantan, Q. V. Le, and I. Sutskever.
2016.Neural programmer: Inducing latent programs withgradient descent.
In International Conference onLearning Representations (ICLR).P.
Pasupat and P. Liang.
2015.
Compositional semanticparsing on semi-structured tables.
In Association forComputational Linguistics (ACL).S.
Reed and N. de Freitas.
2016.
Neural programmer-interpreters.
In International Conference on Learn-ing Representations (ICLR).B.
Settles.
2010.
Active learning literature survey.Technical report, University of Wisconsin, Madison.J.
Steinhardt and P. Liang.
2015.
Learning with re-laxed supervision.
In Advances in Neural Informa-tion Processing Systems (NIPS).P.
Yin, Z. Lu, H. Li, and B. Kao.
2016.
Neural en-quirer: Learning to query tables with natural lan-guage.
arXiv.M.
Zelle and R. J. Mooney.
1996.
Learning toparse database queries using inductive logic pro-gramming.
In Association for the Advancement ofArtificial Intelligence (AAAI), pages 1050?1055.L.
S. Zettlemoyer and M. Collins.
2005.
Learning tomap sentences to logical form: Structured classifica-tion with probabilistic categorial grammars.
In Un-certainty in Artificial Intelligence (UAI), pages 658?666.L.
S. Zettlemoyer and M. Collins.
2007.
Online learn-ing of relaxed CCG grammars for parsing to log-ical form.
In Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP/CoNLL), pages 678?687.32
