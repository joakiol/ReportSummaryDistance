Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 49?54,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsThe Voice and Eye Gaze Behavior of an Imposter: AutomatedInterviewing and Detection for Rapid Screening at the BorderAaron C. Elkins Douglas C. DerrickUniversity of Arizona University of Nebraska at Omahaaelkins@cmi.arizona.edu   dcderrick@mail.unomaha.eduMonica GariupFrontex, Research and Development Unitmonica.gariup@frontex.europa.euAbstractContextual differences present significantchallenges when developing computationalmethods for detecting deception.
Weconducted a field experiment with borderguards from the European Union in order todemonstrate that deception detection can bedone robustly using context specificcomputational models.
In the study, some ofthe participants were given a ?fraudulent?document with incorrect data and asked topass through a checkpoint.
An automatedsystem used an embodied conversationalagent (ECA) to conduct interviews.
Basedon the participants?
vocalic and ocularbehavior our specific model classified 100%of the imposters while limiting false positiveerrors.
The overall accuracy was 94.47%.1 IntroductionUnlike Pinocchio, liars do not exhibit universalbehavior or physiological signals in all situations.Deception is often inappropriately reduced toeither simply telling the truth or lying.
However,there are many strategies for lying (e.g.,omission, imposters, equivocation, hedging);situations where lying occurs (e.g., rapidscreening, imposter, interrogation, conversation);varying consequences and power dynamics (e.g.,parents, friends, boss, border guard, lawenforcement); and interviewing styles (e.g.,behavioral analysis interviewer, informal chat,guilty knowledge test, short answer format).
Allof these factors contribute to the type ofbehaviors and physiological responses that areexhibited and are theoretically expected.
Thesecontextual differences present significantchallenges when trying to develop computationalmethods for detecting deception.
In order todevelop systems that can be used for reliabledeception detection, we must constrain thecomplex problem of deception and manage thefactors described above.We conducted a field experiment with borderguards from the European Union in order todemonstrate that by controlling some of theabove factors and by developing context specificcomputational models, deception detection canbe achieved robustly.
In the experiment, some ofthe participants were given a ?fraudulent?document with incorrect data and asked to passthrough a checkpoint.
An automated system usedan embodied conversational agent (ECA) toconduct interviews.
The system was equippedwith vocal and ocular sensors, as well as anelectronic passport reader.
Based on theparticipants?
vocal and eye gaze behavior acomputational classification model wasdeveloped to identify imposters while limitingthe number of false positives.2 Embodied Conversational AgentTo account for the complex interplay betweenliars and the deceived, Buller and Burgoon(1996) introduced Interpersonal DeceptionTheory (IDT).
This theory expanded andconceptualized deception as a strategicinteraction between a sender and receiver.
Liarsmust simultaneously manage information, theirbehavior, and appearance during the interaction.Moreover, liars will use different strategiesdepending on their skill, relationship with theinteraction partner, preparation, motivation, andtime.49Lying is undeniably a social act.
One majorchallenge to computational deception detection isaccounting for the variability introduced byhuman interviewers.
Every interviewer has theirown style (e.g., aggressive, friendly),inconsistently asks questions, and gets tired.
Thebehavior and approach of the interviewerstrongly influences the behavior and reactions ofthe interviewee.
For example, if the intervieweris angry, the interviewee will be affected by thisand artificially display reciprocal anger or evendistress.
Perhaps after a lunch break theinterviewer is fresh and in better spirits andreturns to a more friendly interaction.
Anydeception detection system that relies onconsistent behavioral cues will have to accountfor the diverse range of human interviewervariability.To address this challenge, we developed anECA-based deception detection system that asksthe same questions, in the same order, and in thesame way each time.
Additionally, this systemcan speak the native language of everyinterviewee.Figure 1.
ECA Interviewer3 SensorsThe ECA depicted above (Figure 1) conducts thestructured border-screening interview andintegrated into this system were three sensors fordetecting imposters: microphone (vocalicmeasures), near infrared camera (ocularbehavior), and an electronic passport reader(document input).3.1 Vocalic MeasuresA unidirectional microphone was integrated intothe system to capture spoken responses to theECA?s questions.
Vocal features were extractedfrom each of these responses near real-time (i.e.,seconds).
Previous research has found that anincrease in the fundamental frequency or pitch isrelated to stress or arousal (Bachorowski &Owren, 1995; Elkins & Stone, 2011; Streeter,Krauss, Geller, Olson, & Apple, 1977).
Pitch isa function of the speed of vibration of the vocalfolds during speech production (Titze & Martin,1998).
Females have smaller vocal folds thanmen, requiring their vocal chords to vibrate fasterand leading to their higher pitch.
When we arearoused our muscles tense and tighten.
When thevocal muscles become tenser, they vibrate at ahigher frequency, leading to a higher pitch.Similarly, previous research has found that whenaroused or excited, our pitch also exhibits morevariation and higher intensities (Juslin & Laukka,2003).Deceptive speech is also predicted to be morecognitively taxing, leading to non-strategic orleakage cues (Buller & Burgoon, 1996;Rockwell, Buller, & Judee K. Burgoon, 1997;Zuckerman, DePaulo, & Rosenthal, 1981).
Thesecues, specific to cognitive effort, can bemeasured vocally.
Cognitively taxed speakerstake longer to respond (response latency) andincorporate more disfluencies (e.g., ?um?
?uh?,speech errors).
Moreover, the harmonics-to-noise ratio serves as an indicator of voice quality(Boersma, 1993).
Originally intended tomeasure speech pathology (Yumoto, Gould, &Baer, 1982), liars have been found to speak witha lower harmonic-to-noise ratio than truth-tellers(Nunamaker, Derrick, Elkins, Burgoon, &Patton, 2011).
The quality of the voice isaffected by increased cognitive effort andheightened stress/emotion.3.2 Ocular BehaviorThis system was designed to be used in a rapidscreening environment and to assess eyebehavior during an interview typical at a port ofentry.
All participants were shown an image ofhis or her issued visa during the interview andasked if the information was correct.
All of the50information was correct on the visa for allparticipants except the imposters where the dateof birth was inaccurate.
This test design is basedon orienting theory and predicts that measurablephysiology accompanies an orienting reflex tofamiliar stimulus.
Pavlov originally studied theorienting reflex during his classical conditioningexperiments.
This reflex orients attention tonovel and familiar stimuli and is consideredadaptive to the environment.
In order to capturethe eye behavior responses, we used the EyeTechDigital Systems VT2 infrared eye tracker (seefigure 2) mounted directly below a computermonitor.Figure 2.
EyeTech Eye TrackerThe VT2 has two infrared light sources and anintegrated infrared camera.
It connects via USBto a Windows computer and captures the eyegaze location (x, y coordinates) at each instanceat a rate of approximately 33-34 frames persecond.
During the interaction with theinterviewing system, participants?
eye behaviorwas monitored while they spoke to the ECA(e.g., for eye contact) and when they observedthe image of their visa.
Based on prior research(Derrick, Jenkins, & Nunamaker, 2011), weanticipated that the imposter would orient onareas of the image that contained falseinformation about their identity.
A sample of thedocument used by all participants is shown inFigure 3.3.3 Electronic Passport ReaderTo provide the system with additionalinformation about each participant, a 3M AT-9000 e-passport reader was integrated into thesystem.
Each participant placed their visadocument on the scanner prior to the interview.The information from the document was readinto the system using the Machine ReadableZone (MRZ) and an image of the visa wascaptured for use during interview.Figure 3.
Visa Issued to Participants4 Final SystemThe final system used during the fieldexperiment is depicted below in Figure 4.
TheECA conducted the screening interview in thelanguage of each participant?s choice (English,French, German, Polish, or Spanish).
The eyegaze and vocal behavior were recorded andprocessed during the interaction in near real-time.
Immediately to the right of the monitor is apassport reader used to scan the entireparticipant?s visas to read the information andimage.Figure 4.
ECA System Screening Participants5 Method5.1 Participants37 border guards from the following EuropeanUnion (EU) member states participated: Austria,Belgium, Denmark, Estonia, Finland, Germany,Hungary, Italy, Latvia, Lithuania, Malta, theNetherlands, Norway, Poland, Romania,Slovakia, Spain, Sweden and the UnitedKingdom.
In addition, two representatives fromthe U.S. Customs and Border Protection and theCanadian Border Services Agency also51participated.
The simulation was part of aworkshop on decision support for screening andrisk assessment at passport control.
Of the 37,four (two men from the Netherlands andRomania and two women from Sweden andDenmark respectively) were selected to beimposters with incorrect dates of birth on theirvisa.
The selection was based on the results of anearlier survey that asked participants about theirconfidence in his or her ability to lie and remainundetected.
Participants with the highestconfidence scores were selected.5.2 ProcedureAll participants were given the visa document attheir registration to use as their travel documentduring the simulated border check.
Thedocument consisted of personal data: name,surname, date of birth, place of birth, andnationality.
For the sake of the simulation, alldocuments were assumed to be genuine (notcounterfeited/falsified).
The imposters weregiven basic instructions on the scenario and theirrole.
They had acquired genuine documents of aperson with a name identical to theirs who alsolooked like them (based on the photo of theirown passport).The goal of the imposter was to pass the bordercheck undetected, meet with their fellowaccomplices (the other imposters), and place abomb at a reception.
The imposters wereexplicitly instructed the day before thesimulation to check his or her visa document andnote that the date and location of their birth wasfalse (not coincident with their real one).The imposters were asked to lie and answeraffirmatively when the ECA asked him or herwhether the document belonged to them and ifthe data were correct.
In order to reinforce theimposters in their role, on the day before thesimulation, they were invited to meet in secret inthe reception room and discuss how they wouldset up a bomb scare.The other participants were simply told to behavenormally.
All other participants, andexperimental staff were blind to the identity ofthe imposters.Upon arrival to the in participants scanned theirdocument in the e-passport reader and selectedthe language for the ECA to use for the interview(English, Polish, Spanish, French, or German).The ECA then asked the following questions:1.
What is your full name?2.
Where were you born?3.
Do have anything to declare?4.
What is the purpose of your visit?5.
Please carefully examine the followingdocumenta.
Scanned document shown (15 seconds)6.
Are the data on this document correct?a.
Scanned document shown (15 seconds)7.
Is this your document?During each of the responses, the sensorsmonitored the vocal and ocular behavior of theparticipants and descriptive measures werecalculated and presented to an experimenter andother participating border guard.6 Results6.1 Vocal BehaviorTo assess the relationship between the voice andthe participant?s interview responses a multilevelmodel was specified with vocal quality as theresponse variable (N=189) regressed oncondition (Guilty/Innocent) and question number(time).
To reflect the repeated measureexperimental design of multiple questions, bothtime and the Intercept of vocal quality weremodeled to vary within Subject (N=38) asrandom effects.
To calibrate each speaker eachmeasurement of voice quality was subtracted bytheir starting value to reflect the deviance from aneutral starting point (Question One).Table 1 below lists the fixed effects from thisanalysis.
The imposters had a significantly largerdrop in voice quality during the interview thaninnocent participants, b=-2.18, p<.01.
Innocentparticipants and imposters both dropped theirvoice quality over time, likely because of thestress of the interview in contrast to the benignstarting question.Table 1.
Vocal Behavior Fixed Effects (N=189,38 Subjects)Fixed Effects ?Intercept -0.136Imposter -2.180**Time (Question) -0.134**p<.05; **p<.01; Fit by Maximum Likelihood Estimation.The imposters spoke with much lower vocalquality when answering questions related to theiridentity (questions 5, 6, and 7 above).
Figure 5below illustrates the difference in vocal qualitybetween innocent and guilty participants.52Figure 5.
Lower Vocal Quality of Imposters6.2 Eye BehaviorEye contact with the ECA was not predictive ofdeception.
However, a Between SubjectsANOVA revealed that when participants wereasked to examine the image of their visa,imposters spent much more time fixating on theincorrect date of birth information, F(1,36)=5.18,p=.028, ?2=.14.
Imposters spent 2.12 times moretime fixating on the incorrect date of birth fieldson their visa (Imposter M=29.73, SD=35.63;Innocent M=13.99, SD=8.45).Figure 6.
Eye Fixation Time on DOB Field7 Summary of PredictorsTo summarize the predictive potential of each ofthe collected vocal and eye gaze behaviormeasurements, each were submitted to BetweenSubjects ANOVA.
Table 2 details the results foreach measurement as a predictor of an imposterwhen answering question six.Table 2.
Vocal and Eye Gaze Behavior ANOVASummaryPredictor df F pVocal Pitch Mean 36 0.05 .83Vocal Pitch SD 36 0.30 .58Vocal Quality Mean 36 8.78 <.01**Vocal Quality SD 36 0.29 .59Vocal Intensity Mean 36 1.65 .21Vocal Intensity SD 36 0.82 .37DOB Eye Fixation 36 5.18 .03*Pupil Dilation 36 0.04 .83*p<.05; **p<.01; DOB is Date of Birth field on visa document; Allvocal measurements were speaker calibrated8 Classifying ImpostersVocal quality and date of birth fixation weresubmitted to a recursive partitioningclassification algorithm (Clark & Pregibon,1992; R Development Core Team, 2011).
Thistype of classification algorithm has the advantageof being very easy to interpret and resulted in thedecision rule detailed in Figure 7 below.Figure 7.
Imposter Classification ModelThis final model had 94.47% accuracy, correctlyidentified all imposters, and misclassified twoother participants of being imposters.
When theclassification model did not include the eye gazebehavior, the Voice Quality cut-off was muchless conservative and resulted in many more falsepositives.
However, after including the EyeFixation variable, the system was calibrated tonot over-rely on the voice.This classification model illustrated theimportance of additional sensors for improvingoverall accuracy of prediction, not just focusingentirely on true positives, or identifyingimposters.
Falsely accusing too many peoplewould make the system infeasible in a highthroughput, operational scenario.
Given thediverse nature of the participants it should benoted that that gender, language, and potentialcultural differences did not affect the results, butno support or conclusions can be drawn given therelatively small size of the various populations.9 ConclusionWe conducted a field experiment with borderguards from the European Union in order todemonstrate that by controlling some of theabove factors and by developing context specificcomputational models, deception detection canbe done robustly.
We demonstrated that usingboth vocalic and ocular measurements we couldcorrectly classify 100% of imposters in a limitedscenario while limiting false positives.
Futureexperimentation needs to be conducted tounderstand how the system compares to human53judgment and if synergies exist between humanand automated screening.ReferencesBachorowski, J.
A., & Owren, M. J.
1995.
Vocalexpression of emotion: Acoustic properties ofspeech are associated with emotional intensity andcontext.
Psychological Science, 219?224.Boersma, P. 1993.
Accurate short-term analysis of thefundamental frequency and the harmonics-to-noiseratio of a sampled sound.
Proceedings of theInstitute of Phonetic Sciences (Vol.
17, pp.
97-110).Buller, D. B., & Burgoon, J. K. 1996.
Interpersonaldeception theory.
Communication Theory, 6, 203-242.Clark, L. A., & Pregibon, D. 1992.
Tree-basedmodels.
Statistical models in S, 377?419.Derrick, D. C., Jenkins, J., & Nunamaker, J. F.(2011).
Design Principles for Special Purpose,Embodied, Conversational Intelligence withEnvironmental Sensors (SPECIES) Agents.
AISTransactions on Human-Computer Interaction,3(2), 62-81.Elkins, A. C., & Stone, J.
2011.
The Effect ofCognitive Dissonance on Argument Language andVocalics.
Forty-Fourth Annual HawaiiInternational Conference on System Sciences.Koloa, Kauai, Hawaii.Juslin, P. N., & Laukka, P. 2003.
Communication ofemotions in vocal expression and musicperformance: Different channels, same code?Psychological Bulletin, 129(5), 770-814.Nunamaker, J. F., Derrick, D. C., Elkins, A. C.,Burgoon, J. K., & Patton, M. W. 2011.
EmbodiedConversational Agent-Based Kiosk for AutomatedInterviewing.
Journal of Management InformationSystems, 28(1), 17?48.
doi:10.2753/MIS0742-1222280102R Development Core Team.
2011.
R: A Language andEnvironment for Statistical Computing.
Vienna,Austria.
Retrieved from http://www.R-project.org/Rockwell, P., Buller, D. B., & Judee K. Burgoon.1997.
Measurement of deceptive voices:Comparing acoustic and perceptual data.
AppliedPsycholinguistics, 18(04), 471-484.Streeter, L. A., Krauss, R. M., Geller, V., Olson, C., &Apple, W. 1977.
Pitch changes during attempteddeception.
Journal of Personality and SocialPsychology, 35(5), 345?350.Titze, I. R., & Martin, D. W. 1998.
Principles of voiceproduction.
Acoustical Society of AmericaJournal, 104, 1148.Yumoto, E., Gould, W. J., & Baer, T. 1982.Harmonics-to-noise ratio as an index of the degreeof hoarseness.
Journal of the Acoustical Society ofAmerica, 71(6), 1544-1550.Zuckerman, M., DePaulo, B. M., & Rosenthal, R.1981.
Verbal and nonverbal communication ofdeception.
Advances in experimental socialpsychology, 14(1), 59.54
