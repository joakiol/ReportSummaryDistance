Summarizing Encyclopedic Term Descriptions on the WebAtsushi Fujii and Tetsuya IshikawaGraduate School of Library, Information and Media StudiesUniversity of Tsukuba1-2 Kasuga, Tsukuba, 305-8550, Japan{fujii,ishikawa}@slis.tsukuba.ac.jpAbstractWe are developing an automatic method tocompile an encyclopedic corpus from theWeb.
In our previous work, paragraph-styledescriptions for a term are extracted fromWeb pages and organized based on domains.However, these descriptions are independentand do not comprise a condensed text asin hand-crafted encyclopedias.
To resolvethis problem, we propose a summarizationmethod, which produces a single text frommultiple descriptions.
The resultant sum-mary concisely describes a term from dif-ferent viewpoints.
We also show the effec-tiveness of our method by means of experi-ments.1 IntroductionTerm descriptions, which have been carefully orga-nized in hand-crafted encyclopedias, are valuablelinguistic knowledge for human usage and compu-tational linguistics research.
However, due to thelimitation of manual compilation, existing encyclo-pedias often lack new terms and new definitions forexisting terms.The World Wide Web (the Web), which containsan enormous volume of up-to-date information, is apromising source to obtain new term descriptions.It has become fairly common to consult the Web fordescriptions of a specific term.
However, the use ofexisting search engines is associated with the follow-ing problems:(a) search engines often retrieve extraneous pagesnot describing a submitted term,(b) even if desired pages are retrieved, a user has toidentify page fragments describing the term,(c) word senses are not distinguished for polyse-mous terms, such as ?hub (device and center)?,(d) descriptions in multiple pages are independentand do not comprise a condensed and coherenttext as in existing encyclopedias.The authors of this paper have been resolvingthese problems progressively.
For problems (a) and(b), Fujii and Ishikawa (2000) proposed an auto-matic method to extract term descriptions from theWeb.
For problem (c), Fujii and Ishikawa (2001)improved the previous method, so that the multipledescriptions extracted for a single term are catego-rized into domains and consequently word senses aredistinguished.Using these methods, we have compiled an ency-clopedic corpus for approximately 600,000 Japaneseterms.
We have also built a Web site called ?Cy-clone?1 to utilize this corpus, in which one or moreparagraph-style descriptions extracted from differ-ent pages can be retrieved in response to a userinput.
In Figure 1, three paragraphs describing?XML?
are presented with the titles of their sourcepages.However, the above-mentioned problem (d) re-mains unresolved and this is exactly what we intendto address in this paper.In hand-crafted encyclopedias, a single term is de-scribed concisely from different ?viewpoints?, suchas the definition, exemplification, and purpose.
Incontrast, if the first paragraph in Figure 1 is notdescribed from a sufficient number of viewpointsfor XML, a user has to read remaining paragraphs.However, this is inefficient, because the descriptionsare extracted from independent pages and usuallyinclude redundant contents.To resolve this problem, we propose a summariza-tion method that produces a concise and condensedterm description from multiple paragraphs.
As a re-sult, a user can obtain sufficient information about aterm with a minimal cost.
Additionally, by reducingthe size of descriptions, Cyclone can be used withmobile devices, such as PDAs.However, while Cyclone includes various typesof terms, such as technical terms, events, and an-imals, the required set of viewpoints can vary de-pending the type of target terms.
For example, thedefinition and exemplification are necessary for tech-nical terms, but the family and habitat are necessaryfor animals.
In this paper, we target Japanese tech-nical terms in the computer domain.Section 2 outlines Cyclone.
Sections 3 and 4 ex-plain our summarization method and its evaluation,respectively.
In Section 5, we discuss related workand the scalability of our method.1http://cyclone.slis.tsukuba.ac.jp/Figure 1: Example descriptions for ?XML?.2 Overview of CycloneFigure 2 depicts the overall design of Cyclone,which produces an encyclopedic corpus by means offive modules: ?term recognition?, ?extraction?, ?re-trieval?, ?organization?, and ?related term extrac-tion?.
While Cyclone produces a corpus off-line,users search the resultant corpus for specific descrip-tions on-line.It should be noted that the summarizationmethod proposed in this paper is not included inFigure 2 and that the concept of viewpoint has notbeen used in the modules in Figure 2.In the off-line process, the input terms can be ei-ther submitted manually or collected by the termrecognition module automatically.
The term recog-nition module periodically searches the Web for mor-pheme sequences not included in the corpus, whichare used as input terms.The retrieval module exhaustively searches theWeb for pages including an input term, as performedin existing Web search engines.The extraction module analyzes the layout (i.e.,the structure of HTML tags) of each retrieved pageand identifies the paragraphs that potentially de-scribe the target term.
While promising descrip-tions can be extracted from pages resembling on-linedictionaries, descriptions can also be extracted fromgeneral pages.The organization module classifies the multipleparagraphs for a single term into predefined domains(e.g., computers, medicine, and sports) and sortsthem according to the score.
The score is computedby the reliability determined by hyper-links as inGoogle2 and the linguistic validity determined by alanguage model produced from an existing machine-readable encyclopedia.
Thus, different word senses,which are often associated with different domains,can be distinguished and high-quality descriptionscan be selected for each domain.Finally, the related term extraction modulesearches top-ranked descriptions for terms stronglyrelated to the target term (e.g., ?cable?
and ?LAN?for ?hub?).
Existing encyclopedias often provide re-lated terms for each headword, which are effectiveto understand the headword.
In Cyclone, relatedterms can also be used as feedback terms to nar-row down the user focus.
However, this module isbeyond the scope of this paper.3 Summarization Method3.1 OverviewGiven a set of paragraph-style descriptions for a sin-gle term in a specific domain (e.g., descriptions for?hub?
in the computer domain), our summarization2http://www.google.com/Weborganizationretrievalextractionterm(s)encyclopediccorpusterm recognitionrelated term extractiondescriptions related termsFigure 2: Overall design of Cyclone.method produces a concise text describing the termfrom different viewpoints.These descriptions are obtained by the organiza-tion module in Figure 2.
Thus, the related termextraction module is independent of our summariza-tion method.Our method is multi-document summarization(MDS) (Mani, 2001).
Because a set of input docu-ments (in our case, the paragraphs for a single term)were written by different authors and/or differenttime, the redundancy and divergence of the topics inthe input are greater than that for single documentsummarization.
Thus, the recognition of similarityand difference among multiple contents is crucial.The following two questions have to be answered:?
by which language unit (e.g., words, phrases, orsentences) should two contents be compared??
by which criterion should two contents be re-garded as ?similar?
or ?different?
?The answers for these questions can be different de-pending on the application and the type of inputdocuments.Our purpose is to include as many viewpoints aspossible in a concise description.
Thus, we com-pare two contents on a viewpoint-by-viewpoint basis.In addition, if two contents are associated with thesame viewpoint, we determine that those contentsare similar and that they should not be repeated inthe summary.Our viewpoint-based summarization (VBS)method consists of the following four steps:1. identification, which recognizes the languageunit associated with a viewpoint,2.
classification, which merges the identified unitsassociated with the same viewpoint into a singlegroup,3.
selection, which determines one or more repre-sentative units for each group,4.
presentation, which produces a summary in aspecific format.The model is similar to those in existing MDS meth-ods.
However, the implementation of each stepvaries depending on the application.
We elaborateon the four steps in Sections 3.2-3.5, respectively.3.2 IdentificationThe identification module recognizes the languageunits, each of which describes a target term from aspecific viewpoint.
However, a compound or com-plex sentence is often associated with multiple view-points.
The following example is an English trans-lation of a Japanese compound sentence in a Webpage.XML is an abbreviation for eXtensibleMarkup Language, and is a markup lan-guage.The first and second clauses describe XML from theabbreviation and definition viewpoints, respectively.It should be noted that because ?XML?
and ?eX-tensible Markup Language?
are spelled out by theRoman alphabet in the original sentence, the firstclause does not provide Japanese readers with thedefinition of XML.To extract the language units on a viewpoint-by-viewpoint basis, we segment Japanese sentences intosimple sentences.
However, sentence segmentationremains a difficult problem and the accuracy is not100%.
First, we analyze the syntactic dependencystructure of an input sentence by CaboCha3.
Sec-ond, we use hand-crafted rules to extract simple sen-tences using the dependency structure.The simple sentences excepting the first clause of-ten lack the subject.
To resolve this problem, zeropronoun detection and anaphora resolution can beused.
However, due to the rudimentary nature ofexisting methods, we use hand-crafted rules to com-plement simple sentences with the subject.As a result, we can obtain the following two simplesentences from the above-mentioned input sentence,in which the complement subject is in parentheses.?
XML is an abbreviation for eXtensibleMarkup Language.?
(XML) is a markup language.3.3 ClassificationThe classification module merges the simple sen-tences related to the same viewpoint into a singlegroup.
An existing encyclopedia for technical termsuses approximately 30 obligatory and optional view-points.
We selected the following 12 viewpoints forwhich typical expressions can be coded manually:3http://cl.aist-nara.ac.jp/?taku-ku/software/cabocha/definition, abbreviation, exemplification,purpose, synonym, reference, product, ad-vantage, drawback, history, component,function.We manually produced 36 linguistic patterns usedto describe terms from a specific viewpoint.
Thesepatterns are regular expressions, in which specificmorphemes are generalized into parts-of-speech orthe special symbol representing the target term.We use a two-stage classification method.
First,the simple sentences that match with a patternare classified into the associated viewpoint group.A simple sentence that matches with patterns formultiple viewpoints is classified into every possiblegroup.However, the pattern-based method fails to clas-sify the sentences that do not match with any prede-fined patterns.
Thus, second we classify the remain-ing sentences into the group in which the most simi-lar sentence has already been classified.
In practice,we compute the similarity between an unclassifiedsentence and each of the classified sentences.
Thesimilarity between two sentences is determined bythe Dice coefficient, i.e., the ratio of content wordscommonly included in those sentences.
The sen-tences unclassified through the above method areclassified into the ?miscellaneous?
group.In summary, our two-stage method uses prede-fined linguistic patterns and statistics of words.The following examples are English translationsof Japanese sentences extracted in the identificationmodule.
These sentences can be classified into a spe-cific group on the ground of the underlined expres-sions, excepting sentence (e).
However, in the secondstage, sentence (e) can be classified into the historygroup, because sentence (e) is most similar to sen-tence (c).
(a) XML is an extensible markup language.?
definition(b) an abbreviation for eXtensible Markup Lan-guage?
abbreviation(c) was advised as a standard by W3C in 1998?
history(d) XML is an abbreviation for Extensible MarkupLanguage?
abbreviation(e) the standard of XML was advised by W3C?
???
?
history3.4 SelectionThe selection module determines one or more rep-resentative sentences for each viewpoint group.
Thenumber of sentences selected from each group canvary depending on the desired size of the resultantsummary.We consider the following factors to compute thescore for each sentence and select sentences withgreater scores in each group.?
the number of common words included (W)The representative sentences should containmany words that are common in the group.
Wecollect the frequencies of words for each group,and sentences including frequent words are pre-ferred.?
the rank in Cyclone (R)As depicted in Figure 2, Cyclone sorts the re-trieved paragraphs according to the plausibilityas the description.
Sentences in highly-rankedparagraphs are preferred.?
the number of characters included (C)To minimize the size of a summary, short sen-tences are preferred.Because these factors are different in terms ofthe dimension, range, and polarity, we normalizeeach factor in [0,1] and compute the final score as aweighed average of the three factors.
The weight ofeach factor was determined by a preliminary study.In brief, the relative importance among the threefactors is W>R>C.However, because the miscellaneous group in-cludes various viewpoints, we use a different methodfrom that for the regular groups.
First, we select rep-resentative sentences from the regular groups.
Sec-ond, from the miscellaneous group, we select the sen-tence that is most dissimilar to the sentences alreadyselected as representatives.
We use the Dice-basedsimilarity used in Section 3.3 to measure the dis-similarity between two sentences.
If we select morethan one sentence from the miscellaneous group, thesecond process is repeated recursively.3.5 PresentationThe presentation module lists the selected sentenceswithout any post-editing.
Ideally, natural languagegeneration is required to produce a coherent text by,for example, complementing conjunctions and gen-erating anaphoric expressions.
However, a simplelist of sentences is also useful to obtain knowledgeabout a target term.Figure 3 depicts an example summary producedfrom the top 50 paragraphs for the term ?XML?.
Inthis figure, six viewpoint groups and the miscella-neous group were formed and only one sentence wasselected from each group.
The order of sentencespresented was determined by the score computed inthe selection module.While the source paragraphs consist of 11,224characters, the summary consists of 397 characters,which is almost the same length as an abstract for atechnical paper.The following is an English translation of the sen-tences in Figure 3.
Here, the words spelled out bythe Roman alphabet in the original sentences are initalics.Figure 3: Example summary for ?XML?.?
definition: XML is an extensible markup lan-guage (eXtensible Markup Language).?
abbreviation: an abbreviation for ExtensibleMarkup Language (an extensible markup lan-guage).?
purpose: Because XML is a standard specifi-cation for data representation, the data definedby XML can be reusable, irrespective of the up-per application.?
advantage: XML is advantageous to develop-ers of the file maker Pro, which needs to receivedata from the client.?
history: was advised as a standard by W3C(World Wide Web Consortium: a group stan-dardizing WWW technologies) in 1998,?
reference: This book is an introduction forXML, which has recently been paid much at-tention as the next generation Internet standardformat, and related technologies.?
miscellaneous: In XML, the tags are enclosedin ?<?
and ?>?.Each viewpoint label or sentence is hyper-linked tothe associated group or the source paragraph, re-spectively, so that a user can easily obtain more in-formation on a specific viewpoint.
For example, bythe reference sentence, a catalogue page of the bookin question can be retrieved.Although the resultant summary describes XMLfrom multiple viewpoints, there is a room for im-provement.
For example, the sentences classifiedinto the definition and abbreviation viewpoints in-clude almost the same content.4 Evaluation4.1 MethodologyExisting methods for evaluating summarizationtechniques can be classified into intrinsic and extrin-sic approaches.In the intrinsic approach, the content of a sum-mary is evaluated with respect to the quality of atext (e.g., coherence) and the informativeness (i.e.,the extent to which important contents are in thesummary).
In the extrinsic approach, the evaluationmeasure is the extent to which a summary improvesthe efficiency of a specific task (e.g., relevance judg-ment in text retrieval).In DUC4 and NTCIR5, both approaches havebeen used to evaluate summarization methods tar-geting newspaper articles.
However, because therewas no public test collections targeting term descrip-tions in Web pages, we produced our test collection.4http://duc.nist.gov/5http://research.nii.ac.jp/ntcir/index-en.htmlAs the first step of our summarization research, weaddressed only the intrinsic evaluation.In this paper, we focused on including as manyviewpoints (i.e., contents) as possible in a summary,but did not address the text coherence.
Thus, weused the informativeness of a summary as the evalu-ation criterion.
We used the following two measures,which are in the trade-off relation.?
compression ratio#characters in summary#characters in Cyclone result?
coverage#viewpoints in summary#viewpoints in Cyclone resultHere, ?#viewpoints?
denotes the number of view-point types.
Even if a summary contains multiplesentences related to the same viewpoint, the numer-ator is increased by 1.We used 15 Japanese term in an existing computerdictionary as test inputs.
English translations of thetest inputs are as follows:10BASE-T, ASCII, SQL, XML, accumu-lator, assembler, binary number, crossingcable, data warehouse, macro virus, mainmemory unit, parallel processing, resolu-tion, search time, thesaurus.To calculate the coverage, the simple sentencesin the Cyclone results have to be associated withviewpoints.
To reduce the subjectivity in the evalu-ation, for each of the 15 terms, we asked two collegestudents (excluding the authors of this paper) to an-notate each simple sentence in the top 50 paragraphswith one or more viewpoints.
The two annotatorsperformed the annotation task independently.
Thedenominators of the compression ratio and coveragewere calculated by the top 50 paragraphs.During a preliminary study, the authors and anno-tators defined 28 viewpoints, including the 12 view-points targeted in our method.
We also defined thefollowing three categories, which were not consideredas a viewpoint:?
non-description, which were also used to anno-tate non-sentence fragments caused by errors inthe identification module,?
description for a word sense independent of thecomputer domain (e.g., ?hub?
as a center, in-stead of a network device),?
miscellaneous.It may be argued that an existing hand-craftedencyclopedia can be used as the standard sum-mary.
However, paragraphs in Cyclone often con-tain viewpoints not described in existing encyclope-dias.
Thus, we did not use existing encyclopedias inour experiments.4.2 ResultsTable 1 shows the compression ratio and coverage fordifferent methods, in which ?#Reps?
and ?#Chars?denote the number of representative sentences se-lected from each viewpoint group and the numberof characters in a summary, respectively.
We alwaysselected five sentences from the miscellaneous group.The third column denotes the compression ratio.The remaining columns denote the coverage ona annotator-by-annotator basis.
The columns ?12Viewpoints?
and ?28 Viewpoints?
denote the casein which we focused only on the 12 viewpoints tar-geted in our method and the case in which all the28 viewpoints were considered, respectively.The columns ?VBS?
and ?Lead?
denote the cover-age obtained with our viewpoint-based summariza-tion method and the lead method.
The lead method,which has often been used as a baseline method inpast literature, systematically extracted the top Ncharacters from the Cyclone result.
Here, N is thesame number in the second column.In other words, the compression ratio of the VBSand lead methods was standardized, and we com-pared the coverage of both methods.
The compres-sion ratio and coverage were averaged over the 15test terms.Suggestions which can be derived from Table 1 areas follows.First, in the case of ?#Reps=1?, the averagesize of a summary was 616 characters, which ismarginally longer than an abstract for a techni-cal paper.
In the case of ?#Reps=3?, the averagesummary size was 1309 characters, which is almostthe maximum size for a single description in hand-crafted encyclopedias.
A summary obtained withfour sentences in each group is perhaps too long asterm descriptions.Second, the compression ratio was roughly 10%,which is fairly good performance.
It may be arguedthat the compression ratio is exaggerated.
That is,although paragraphs ranked higher than 50 can po-tentially provide the sufficient viewpoints, the top 50paragraphs were always used to calculate the domi-nator of the compression ratio.We found that the top 38 paragraphs, on average,contained all viewpoint types in the top 50 para-graphs.
Thus, the remaining 12 paragraphs did notprovide additional information.
However, it is dif-ficult for a user to determine when to stop readinga retrieval result.
In existing evaluation workshops,such as NTCIR, the compression ratio is also calcu-lated using the total size of the input documents.Third, the VBS method outperformed the leadmethod in terms of the coverage, excepting the caseof ?#Reps=1?
focusing on the 12 viewpoints by an-notator B.
However, in general the VBS method pro-duced more informative summaries than the leadmethod, irrespective of the compression ratio andthe annotator.It should be noted that although the VBS methodTable 1: Results of summarization experiments.Coverage by annotator A (%) Coverage by annotator B (%)Compression 12 Viewpoints 28 Viewpoints 12 Viewpoints 28 Viewpoints#Reps #Chars ratio (%) VBS Lead VBS Lead VBS Lead VBS Lead1 616 5.97 56.62 52.84 49.49 44.84 50.00 53.61 49.49 47.562 998 9.61 73.43 57.23 59.26 53.70 64.50 62.96 60.75 57.373 1309 12.61 76.04 59.29 63.13 56.44 67.83 64.81 65.22 60.84targets 12 viewpoints, the sentences selected fromthe miscellaneous group can be related to the re-maining 16 viewpoints.
Thus, even if we focus onthe 28 viewpoints, the coverage of the VBS methodcan potentially increase.It should also be noted that all viewpoints are notequally important.
For example, in an existing en-cyclopedia (Nagao and others, 1990) the definition,exemplification, and synonym are regarded as theobligatory viewpoints, and the remaining viewpointsare optional.We investigated the coverage for the three obliga-tory viewpoints.
We found that while the coveragefor the definition and exemplification ranged from60% to 90%, the coverage for the synonym was 50%or less.A low coverage for the synonym is partially dueto the fact that synonyms are often described withparentheses.
However, because parentheses are usedfor various purposes, it is difficult to identify onlysynonyms expressed with parentheses.
This problemneeds to be further explored.5 DiscussionThe goal of our research is to automatically compilea high-quality large encyclopedic corpus using theWeb.
Hand-crafted encyclopedias lack new termsand new definitions for existing terms, and thus thequantity problem is crucial.
The Web contains un-reliable and unorganized information and thus thequality problem is crucial.
We intend to alleviateboth problems.
To the best of our knowledge, noattempt has been made to intend similar purposes.Our research is related to question answering(QA).
For example, in TREC QA track, definitionquestions are intended to provide a user with the def-inition of a target item or person (Voorhees, 2003).However, while the expected answer for a TRECquestion is short definition sentences as in a dic-tionary, we intend to produce an encyclopedic textdescribing a target term from multiple viewpoints.The summarization method proposed in this pa-per is related to multi-document summarization(MDS) (Mani, 2001; Radev and McKeown, 1998;Schiffman et al, 2001).
The novelty of our researchis that we applied MDS to producing a condensedterm description from unorganized Web pages, whileexisting MDS methods used newspaper articles toproduce an outline of an event and a biography ofa specific person.
We also proposed the concept ofviewpoint for MDS purposes.While we targeted Japanese technical terms in thecomputer domain, our method can also be applied toother types of terms in different languages, withoutmodifying the model.
However, a set of viewpointsand patterns typically used to describe each view-point need to be modified or replaced depending theapplication.
Given annotated data, such as thoseused in our experiments, machine learning methodscan potentially be used to produce a set of view-points and patterns for a specific application.6 ConclusionTo compile encyclopedic term descriptions from theWeb, we introduced a summarization method to ourprevious work.
Future work includes generating acoherent text instead of a simple list of sentencesand performing extensive experiments including anextrinsic evaluation method.ReferencesAtsushi Fujii and Tetsuya Ishikawa.
2000.
Utilizingthe World Wide Web as an encyclopedia: Extract-ing term descriptions from semi-structured texts.In Proceedings of the 38th Annual Meeting of theAssociation for Computational Linguistics, pages488?495.Atsushi Fujii and Tetsuya Ishikawa.
2001.
Organiz-ing encyclopedic knowledge based on the Web andits application to question answering.
In Proceed-ings of the 39th Annual Meeting of the Associationfor Computational Linguistics, pages 196?203.Inderjeet Mani, 2001.
Automatic Summarization,chapter 7, pages 169?208.
John Benjamins.Makoto Nagao et al, editors.
1990.
Encyclope-dic Dictoinary of Computer Science.
IwanamiShoten.
(In Japanese).Dragomir R. Radev and Kathleen R. McKeown.1998.
Generating natural language summariesfrom multiple on-line sources.
Computational Lin-guistics, 24(3):469?500.Barry Schiffman, Inderjeet Mani, and Kristian J.Concepcion.
2001.
Producing biographical sum-maries: Combining linguistic knowledge with cor-pus statistics.
In Proceedings of the 39th An-nual Meeting of the Association for Computa-tional Linguistics, pages 450?457.Ellen M. Voorhees.
2003.
Evaluating answers to def-inition questions.
In Companion Volume of theProceedings of HLT-NAACL 2003, pages 109?111.
