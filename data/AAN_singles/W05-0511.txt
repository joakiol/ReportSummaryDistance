Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 91?99,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsSteps Toward Deep Lexical AcquisitionSourabh NiyogiMassachusetts Institute of Technologyniyogi@mit.eduAbstractI describe steps toward ?deep lexical ac-quisition?
based on naive theories, moti-vated by modern results of developmentalpsychology.
I argue that today?s machinelearning paradigm is inappropriate to takethese steps.
Instead we must develop com-putational accounts of naive theory repre-sentations, mechanisms of theory acquisi-tion, and the mapping of naive theories tolexicalizable concepts.
This will enableour theories to describe the flexibility ofthe human conceptual apparatus.1 Where We Are NowThe present Machine Learning ParadigmMuch of computational linguistics has convergedonto a machine learning paradigm that provides ussoothing clarity.
The machine learning approach de-fines a problem as a mapping problem ?
map someacoustic stream onto a list of word tokens, map a listof word tokens onto a parse tree, map a parse treeonto a set of semantic roles or ?logical form?, mapeach word in a tree onto its best sense, and so on.We then develop a learning algorithm to accomplishthe desired mapping.
Multiple groups describe howwell their algorithm maps various test sets given var-ious training sets, and describe a ?result?
to improveupon.
The clarity provided by this paradigm is sosoothing, one gets the sense we can turn a crank,and indeed, in many cases, progress has been madeproceeding precisely along these lines.Turning the crank on deep lexical acquisition,however, we might feel something is missing.
Whatis it?
Underlying any model of deep lexical acquisi-tion is a theory of the human conceptual apparatus.Unlike our handle on acoustic streams, word lists,and parse trees, our handle on a suitable ?output?for the space of word meanings is remarkably poor.Somehow, via experience (of some kind or another),children acquire a mapping from a space of vocabu-lary items to a space of lexicalizable concepts ?
thelexicon; our task as modelers is to figure out howthis mapping can occur.
Many models for the spaceof lexicalizable concepts exist: concepts are pointsin Rn, concepts are Jackendoff?s lexical concep-tual structures, concepts are FrameNet?s frame ele-ments, concepts are Schankian script activators, con-cepts are distributions over syntactic frames, con-cepts are grounded in sensorimotor statistics, or allof the above.
Almost everyone nowadays reportshow their algorithm accomplished some mapping toone or more of these models of concepts.
They haveto, because today?s de facto idea of what constitutesa ?result?
according the machine learning paradigmtoday is to do exactly this.The Golden Oldies formed our concept modelsOur models of conceptual spaces did not origi-nate from computational linguists following the ma-chine learning paradigm.
They were proposed fromlinguists, psychologists and philosophers back inearlier eras - what we will call Golden Oldies ?when the idea of a ?result?
was somewhat differ-ent.
There are too many to recall: Quine (1960)argued that the linguist watching the natives utter-ing Gavagai!
in the context of a rabbit would nec-91essarily require far more constraints than met theeye.
Brown (1957) showed that children used syn-tactic cues to disambiguate between possible mean-ings; Landau and Gleitman (1985) followed on theseinsights, showing just how deep it could be, thateven blind children could learn look and see, basingtheir mapping on syntactic constraints.
Chomsky?s(1965) notion of ?deep structure?
?
proposed to ac-count for commonplace syntactic phenomena ?
mo-tivated many insights explored in Gruber (1965)?sthesis, Fillmore (1968)?s classical thematic roles,and Jackendoff (1983)?s Lexical conceptual struc-tures.
Hale and Keyser and many linguists laboredunder the MIT Lexicon project in the 1980s to deter-mine the fundamental features of the lexicon; manyof these hard-earned observations appear in Levin(1993).
Schank (1972)?s Conceptual dependencytheory, Minsky (1975)?s Frames were proposed forthe broader goals of capturing commonsense knowl-edge.
Quillian?s (1968) and Miller et al(1990)?sWordNet were not intended for models of lexical ac-quisition or databases to be used in computationallinguistics but as models of human semantic mem-ory.
Many other Golden Oldies exist, and our debtto them is quite large.
Ask what motivates our col-lection of subcategorization statistics or what drivesthe quest for semantic roles, and the roots are foundin the science questions of the Golden Oldies.The present Myopic Learning ParadigmIt would have been extremely myopic to take anyone of these classical results and accuse their authorsof not demonstrating a learning algorithm, not evalu-ating them on large corpora, and not getting togetherin workshops to share the results on test sets.
Thestandard for what constituted a result back then con-sisted of none of these things, because today?s ma-chine learning paradigm was just not present then.The questions were:?
Question (1): What is a lexicalizable concept??
Question (2): How can a word-concept map-ping be learned from evidence?But for reasons that no one really talks about,somehow, the standard of what constitutes a resultchanged from some balance of Question (1) and (2)to a machine learning paradigm essentially focusedon Question (2).
The dependency between Ques-tion (1) and (2) is quite well-understood, but do wehave an adequate answer to (1)?
We tell ourselves:We?ve gotta build better parsers, speech recognizers,search engines, machine translation systems, so...let?s take shortcuts on Question (1) so as to makeprogress on Question (2).
For many, that shortcutconsists of semantic role labels and learning fromframe distributions.
These shortcuts don?t answerQuestion (1), unfortunately.2 Where We Need to GoWhile the Golden Oldies were used as the founda-tions of today?s lexical acquisition, psychology be-gan to sing a new tune, still balancing Questions (1)and (2).Children have naive theoriesDevelopmental psychology after the GoldenOldies has shown just how deep our ?deep lexicalacquisition?
theories have to be.
On this view, wordmeanings are couched in changing naive theories ofhow the world works.
The model of the child is thatthe child possesses a naive theory T ?
changing statefrom T1 to T2, and that there is a space of conceptsaccessible from T1 that substantively different fromthe space of concepts accessible from T2.
A learnerundergoes radical conceptual change.
Developmen-tal psychology has not been explicit about the pre-cise form of T ?, nor have they characterized how T ?relates to lexicalizable concepts.
But their contribu-tions inform us about the fundamental ingredientsof concepts (Question (1)) and inform us what deeplexical acquisition must consist of (Question (2)).A few examples must suffice in place of a review(c.f.
Gopnik and Meltzoff (1997)).
Keil (1989)?stransformation studies illustrate theory change in thedomain of biology.
First, children are shown a pic-ture of a skunk; then, are told a story ?
that the an-imal received either (A) surgery or (B) a shot in in-fancy ?
and then are shown a picture of a raccoon.Young preschool children judge that the animal isa raccoon, as if they base their judgements on su-perficial features.
Children between 7 and 9 (T2)on the other hand, judge that the raccoon-lookingfigure in (A) is still a skunk.
Adults (T3) judgethat the raccoon-looking figure in both conditions isstill a skunk.
Apparently, preschoolers?
theory T192lacks the belief that an animal?s kind is determinedat birth, but this becomes part of the adult?s T3.Similarly, preschool children at T1 have conceptof death involving a belief in a continued existencein an alternate location (like sleep); When askedwhether dead people dream, eat, defecate, and move,4 to 6 year olds will say that dead people do all ofthese, except move (Slaughter et al 2001).
Missingin T1 are the causes of death (a total breakdown ofbodily functions) and that death is an irreversible, in-evitable end.
Between 4 and 6, children become su-perficially aware of the general function of variousbody parts (e.g ?You need a heart to live?).
Otherphenomena serve the same point: the child at T1thinks uncle means friendly middle-aged man, andat T2 thinks it means parent?s brother.
The child atT1 thinks island means a beachy territory and at T2thinks it means body of land surrounded by water(Keil 1989).
And, ?theory of mind?
concepts/wordssuch as belief, desire, wonder, pretend (Wellmanand Bartsch 1995, Leslie 2000) are similarly situ-ated.How ?theory-like?
T1 and T2 are is subject toconsiderable debate (diSessa 1993, Leslie 2000).disessa (1993) describes a large number of causal?p-prims?
that are highly context specific and con-siderably larger in number than what Carey (1985)describes; these are shown to apply to everydayphysical phenomena ?
?force as mover?, ?vaccu-ums impel?, ?overcoming?, ?springiness?, ?biggermeans lower pitch (or slower)?, to name a few.
Eachof these have a FrameNet-like causal syntax, ofsome unknown mapping to vocabulary items.
Sim-ilarly, Rozenblit and Keil (2003) show that non-expert adults have a remarkably superficial notionof how common mechanisms work ?
such as how ahelicopter changes from hovering to forward flight.Theories may be suspiciously weak.Students have alternative frameworksEducational psychologists have characterized T ?by asking a different, more practical question: whyis it difficult for science students to learn certain sci-entific concepts (weight, density, force, heat, .
.
.
)when they come to class?
The broad insight is this:students come to class not as blank slates but withalternative pre-conceptions that must be understood.Data on their pre-conceptions yields clues as to con-tents of T ?, well before they walk into science class.Again, a few examples illustrate the point.Many studies on physics misconceptions have ob-served deeply held views on the motion of pro-jectiles (McCloskey 1983, Halloun and Hestenes1985).
Ask students to predict what happens whena projectile is thrown upward at an angle, and theiranswers will typically be consistent with one of (a-c)These answers are consistent with an ?impetus?
the-ory of motion, where an object?s motion is exclu-sively dominated by whatever ?impetus?
the throwerprovides it.
Medieval scientists such as Buridanalso held similar beliefs; Newtonian mechanics, ofcourse, shows that the answer is a parabola.
disessa(1993) report a wider array of these types of physicsmisconceptions in a theoretical framework.Likewise, ask students for their knowledge of howtheir eyes work, and they reveal an ?extramission?belief: something somehow shoots out from the eyeand reaches the objects (Winer et al2002); they alsosay that eye is the sole organ in the body responsi-ble for vision.
Plato and da Vinci shared these samebeliefs.
Systematic catalogues of these sorts of ob-servations have been compiled for just about everydomain ?
e.g.
megaphones create sounds, heat is asubstance, eggs are not alive, the moon and sun arethe same size, and so forth (AAAS 1993).3 What Steps We Must TakeConsider this fascinating phenomena from the Bestof Today and the comfort of the grammar-generates-sentence relation will be replaced by queasiness: theterms theory, concept, and change are most unclear,as many developmental psychologists freely admit.But computational linguists may contribute signifi-cantly to rendering new clarity: If the Golden Oldiesdrove the efforts on today?s shallow lexical acquisi-tion, the Best of Today?s Psychology may drive theresults of tomorrow?s progress in deep lexical acqui-sition.93(a)primitives // ConceptGenerator G// space of lexicalizableconcepts//VocabularyAcquisitionDevice// lexiconexperienceOO(b)space of possibletheories//TheoryAcquisitionDevice// Theory T ?
//ConceptGeneratorG//space of lexicalizableconcepts G(T ?
)//VocabularyAcquisitionDevice// theory-basedlexicon LexperienceOOexperienceOOFigure 1: (a) The Model of Concepts from the Golden Oldies: used in the present Machine Learning Paradigm; (b) The UniversalTheory Model of Concepts: necessary for deep lexical acquisitionThe new framework: Universal TheoryWe have much progress to make: We can de-scribe naive theories precisely; we can describe howtheory acquisition occurs; we can describe the mapfrom naive theories to a set of lexicalizable concepts.We can describe how vocabulary acquisition occurs.Figure 1(a) shows the Golden Oldies model of con-cepts that we must abandon: a Vocabulary Acquisi-tion Device receives a fixed hypothesis space of pos-sible concepts completely determined by a fixed setof primitives; Figure 1(b) shows the Universal The-ory Model of Concepts that we must take steps to-wards: A Theory Acquisition Device (TAD) outputsa state T ?
that describes a learners?s naive theory; AConcept Generator G maps T ?
to a set of lexical-izable concepts G(T ?).
A Vocabulary AcquisitionDevice (VAD) uses G(T ?)
to learn a lexicon.
Thetheory of the TAD states is Universal Theory (UT);a UT metalanguage enables an abstract characteriza-tion of possible theories ?
each possible theory de-scribes a system of kinds, attributes, relations, part-whole relations, and causal mechanisms.
Within thisUniversal Theory Model of Concepts, we can beginto answer the following core questions:1. what is the initial state of the TAD?2.
what are possible final states of the TAD?3.
how can the TAD change state?4.
how can the TAD use T ?
to parse experience?5.
how does the concept generator G map T ?
ontoa set of lexicalizable concepts G(T ?)?6.
how can the VAD use G(T ?
)?We have made progress on these core questionsMany of these questions have been addressed al-ready in computational models where a candidateUT metalanguage and theory T ?
is latent.
diSessa(1993) catalogs sets of p-prims in naive physics.Atran (1995) describes a theory of family struc-ture.
Gopnik et al(2004) uses Bayesian networks tomodel preschooler?s causal reasoning about blickets.McClelland and Rogers (2004) describe connection-ist models of some of Carey (1985)?s classic results.In my own work, I have been situating the ele-ments of the Universal Theory Model of Concepts ina microgenesis study, where adult subjects undergoa T1 to T2 transition (Niyogi 2005).
The transitioncan be understood with a minimal UT metalanguageneeded to characterize a set of possible theories: T ?is characterized by a interrelated sets of kinds, at-tributes, relations, and causal laws.
T1 and T2 aredescribed in that UT metalanguage, and the simplestconcept generator G is described that mechanicallymaps T1 and T2 onto G(T1) and G(T2).
Sub-jects undergo theory change in a Blocksworld uni-verse (see Figure 2(a)) while learning 3 verbs (gorp,pilk, seb) that refer to the causal mechanisms gov-erning the universe.
Subjects interact with a set of29 blocks, some of which activate other blocks oncontact.
On activation, subjects are shown a transi-tive verb frame (?Z is gorping L, ?U is sebbing F?,?D is pilking Y?)
in a Word Cue Area.
Unbeknownstto subjects, each block belongs to 1 of 4 kinds (A, B,C or D) and 3 activation mechanisms exist betweenthem: lawab: As activate Bs, lawc?
: Cs activate Cs,and lawd: Ds activate Ds; each of the 3 verbs refersto one the 3 mechanisms.
Subjects are probed forthe naming conditions on each of the 3 verbs.Subjects?
responses indicate that their TAD statechanges from T ?
= T1 (there is 1 kind of blockgoverned by 1 causal mechanism lawq) to T ?
= T294(a) (b)Figure 2: (a) Subjects try to learn the laws and word meanings in a ?Causal Blocksworld?
computer application by dragging anddropping blocks onto each other.
Cues to the meaning of 3 verbs (gorp, pilk and seb) are given in a Word Cue Area.
Shown is howtwo kinds of subjects ?
T2 Subjects and T1 Subjects ?
clustered the blocks; the clusters for the kinds A, B, C and D (boxed) areclear for T2 Subjects but no such differentiation is apparent for T1 subjects; (b) When T ?
= T1, all 3 verbs can only be mappedto a single concept in G(T1) = {Q} (dashed arrows); When T ?
= T2, gorp, pilk and seb can be mapped to 3 new concepts AB, C?and D in G(T2) (solid arrows).
(there are 4 kinds of blocks governed by 3 distinctcausal mechanisms, lawab, lawc?
and lawd).
Butthis is not true for all subjects: some remain ?T1subjects?
while others move onto become ?T2 sub-jects?.
Critically, when T ?
= T1, the verbs can onlybe mapped to a single concept in G(T1) = {Q};When T ?
= T2, the verbs can be mapped to 3 dis-tinct concepts in G(T2) = {AB, C?, D} (See Figure2(b)).
Once T ?
= T2, subjects can ?parse?
the ac-tivation and infer the hidden kind and causal mech-anism involved.
Critically, subjects cannot learn todistinguish the 3 verbs until T ?
= T2, when the3 new concepts emerge in G(T ?).
Then gorp, pilkand jeb may be mapped onto those 3 new concepts.These verbs are thus theory-laden in the same wayas death, uncle and island.This UT architecture concretely dissolves thePuzzle of Concept Acquisition (Laurence and Mar-golis 2002): how can a person ever acquire a ?new?concept, when a fixed set of primitives exhaustivelyspan the space of possible concepts?
Taking theviewpoint of the learner?s VAD at a specific momentin time with a specific T ?, it has access to just thoseconcepts in G(T ?)
?
acquisition of a new conceptis possible if T ?
changes.
Taking the viewpoint ofthe learner?s species across all possible times, thespecies has access to the union of G(T ?)
over allpossible TAD states ?
thus a ?new?
concept for thespecies is impossible.
Which viewpoint one takes isa matter of perspective.
Critically, the Golden Oldiesmodel of concepts does not expose the TAD state re-vealed in the UT model of concepts (Fig.
1a,b).Universal Theory and the Linguistic AnalogyComputational linguists can progress on thesequestions, because naive theories are like gram-mars.
Just as a grammar generates a set of possiblesentences, a theory T ?
generates a set of possibleworlds.
Just as the space of possible grammars is re-stricted, so is the space of possible theories.
Just aslearning a grammar consists of picking a point froma space of possible grammars, learning a theory con-sists of picking a point from the space of possibletheories.
The task of writing a naive theory is likewriting a grammar.
The task of characterizing thespace of possible theories requires a theory meta-language just as characterizing the space of possiblegrammars requires a grammar metalanguage.Moreover, research into naive theories does notproceed separately from the program of research ingrammar.
The two programs are bridged by the con-cept generator G: T ?
generates G(T ?
), a set of lexi-calizable concepts.
An adequate account of G wouldgenerate concepts present in a particular language,for every language, and for every possible T ?.Miller et al(1990) distinguish between a con-structive and a differential lexicon.
In a differentialtheory of the lexicon, meanings can be representedby any symbols that enable a theorist to distinguishamong them; In a constructive theory of the lexi-con, the representation should ?contain sufficient in-formation to support an accurate construction of theconcept (by either a person or a machine)?.95The conceptual analyst who desires to produce aconstructive theory of the lexicon has four kinds ofaccounts to provide: (see Niyogi 2005)?
an explanatory account of the space of possibletheories, for all persons P?
an explanatory account of the space of possi-ble concepts, for all persons P, for all possibletheories?
a descriptive account of a specific theory T ?held by a representative person P (e.g.
of a 3-year old or of a 10-year old)?
a descriptive account of a specific lexicon Lheld by a representative person P (e.g.
a 3-year old Chinese speaker, 3-year old Englishspeaker, 10-year old Chinese speaker, 10-yearold Chinese speaker)We may envision a ?theory-based lexicon?
thatwould capture the two key state variables in Figure1(b), the two descriptive accounts above: (1) T ?
foran idealized human; (2) a set of vocabulary itemsmapped to points in G(T ?).
Very limited instancesof a theory-based lexicon can be constructed alreadyfor subjects at the end of the experiment ?
such atheory-based lexicon has (1) T2 in the UT metalan-guage; (2) the mapping in L to G(T2): gorp = AB,pilk = C?, seb = D. This constructive theory-basedlexicon would be in stark contrast to differential lex-icons such as WordNet and FrameNet.Grounding language in perception is insufficientMany have proposed deep lexical acquisition by?grounding language in perception?
(Siskind 1996,Regier 1996, Roy and Pentland 2002, Yu and Bal-lard 2004), constructing systems that can learn to ut-ter, e.g.
red, banana, hit and triangle in contextswhere there are, e.g., three triangles hitting red ba-nanas.
Such systems also propose a space of possi-ble concepts exhausted by a fixed set of primitives,as in the Golden Oldies model.
The initial state ofthe TAD (T ?
(t = 0)) can explicitly incorporate allthese attributes and relations (contact, luminance,.
.
.
); but then, the TAD can further change stateto yield new kinds, attributes, relations, and causalmechanisms not present in the initial state, but mo-tivated by the data (see Gopnik and Meltzoff 1997).As such, vague appeal to grounding is insufficient;associative processes that may work on red, hit, ba-nana, eye, three are extremely challenging to gen-eralize to color, kind, wonder, pilk, seb, telescope,maybe and uninvented groobles that cannot be per-ceived.
Again, developmental psychology providessome insight on what theoretical innovations wouldbe required for a suitable interface to sensorimotorapparatus (c.f.
Mandler 2004).Commonsense AI gives UT foundationsPrimitives well beyond the sensory apparatushave been developed to describe physical systemsqualitatively (Regier 1975, Forbus 1984).
Theyshow us some of the possibilities of what T ?
andcandidate UT metalanguages may look like (quan-tity spaces, kinds, attributes, relations, part-wholerelations, and causal mechanisms that interrelatethese sets).
Regier (1975)?s description of a toi-let appears particularly close to Rozenblit and Keil(2003)?s helicopter.
Later qualitative AI frameworksof Forbus (1984) and Kuipers (1994) may be ap-plied to McCloskey (1982)?s intuitive physics anddisessa?s (1993) p-prims.
Except for the work ofHobbs, Pustejovsky and their colleagues, few havemapped commonsense theories onto the lexicon.Similar domain-general elements of naive math andcausality are present in the workds of Hobbs et al(1987), Kennedy and McNally (2002)?s degree rep-resentations for gradable predicates, Talmy (1988)?sforce dynamics, and the quantity spaces of Kuipers(1994) and Forbus (1984).
These disparate frame-works provide foundational elements for a UT met-alanguage.Shortcuts on UT foundations will not workWe must resist the urge to take shortcuts onthese foundations.
Simply creating slots for foun-dational phenomena will impede progress.
Puste-jovsky (1995)?s observations for co-compositionhave clearly illustrated how much flexibility our in-terpretation systems must have, e.g.
in He enjoyedthe beer/movie.
But specifying the telic role of beerand movie to be drink and watch does not consti-tute an adequate theory ?
we require constraints thatrelate to the state space of the human conceptual ap-paratus.
Pustejovsky (1995)?s telic, formal, constitu-tive, agentive roles may be mapped onto T ?
?s char-acterization of artifacts, materials, and so on.
Werequire nothing less than absolute conceptual trans-parency.96We must bridge UT to analogyLakoff and Johnson (1980) and subsequent cog-nitive linguistics work have catalogued a stunninglevel of metaphoric usage of language.
Lexical ex-tension of items such as illuminate in, e.g.
Analo-gies illuminate us on theory acquisition are couchedin terms of conceptual metaphors such as ?ideas arelight?.
Significant steps have been taken to modelanalogical mapping (c.f.
Falkenhainer et al1989,Bailey et al1997) and conceptual blending (Faucon-nier and Turner 1998).
These processes may moti-vate TAD state changes.
In most cases, the the un-derlying predicates in the source and target domainsare ad hocly constructed; a natural source of thesepredicates may be the sets internal to T ?
(kinds, at-tributes, relations, causal mechanisms); similaritybetween domains may be determined by the struc-tural properties of the UT metalanguage and G. IfT ?
incorporates the common causal mechanisms be-hind ideas and light transmission, for example, thenone may strive for a shorter lexicon where the vo-cabulary item illuminate happens to be used in bothdomains with ?one?
core entry.
An adequate theoryof this process would obviously reduce the numberof so called ?senses?
in word sense disambiguation.4 What We Assumed WrongModern computational linguistics appears to havemade a set of assumptions that deserve reanalysis,given the availability of other options.Assumption: A fixed alphabet of meaning com-ponents exists, and we know what it isA key assumption dating to the Golden Oldies isthat the meaning of a sentence is adequately cap-tured by a ?logical form?
(LF) characterized by afixed alphabet of meaning components (e.g.
the-matic roles, lexical semantic primitives, conceptualdependency primitives).
Today?s computational lin-guistics program uses this assumption to demon-strate systems that answer ?who did what to whom,where, why, .
.
.?
questions, given sentences like:John saw the man with the telescope.John hit the man with the umbrella.Is the computational linguist is expected to be sat-isfied when systems can answer Who saw the manwith the telescope?
or Who did John hit with the um-brella?
This year?s CoNLL Shared Task, mappingsentences onto semantic roles, assumes the above.But try these: Does John have eyes?
Were they everopen when he was looking through the telescope?Could John know whether the man was wearing un-derwear?
Did the umbrella move?
Did John move?Did the man feel anything when he was hit?
WasJohn alive?
Was the man alive?
Why would Johnneed a telescope to see the man, when he has eyes?Why would John use an umbrella when his handswould do?
Something is missing in these systems.We should be more accountable.
Developmen-tal psychology showed that theory change and con-ceptual change is possible, proving this assumptionis wrong: the alphabet behind sentence meaningis a varying set of lexicalizable concepts G(T ?
).Missing in today?s systems attaching AGENT (orFrameNet?s Perceiver passive, or Impactor) to Johnand INSTRUMENT to umbrella and telescope is T ?,and a mapping of the lexical items to G(T ?).
WhatT ?
must contain, in some as yet unknown form, isa T of physics described by McCloskey and disessa(1993), a T of vision studied by Landau and Gleit-man (1985) and Winer et al(2002), a T of bodystudied by Carey (1985), a T of materials and arti-facts studied by Hobbs et al(1987) and Pustejovsky(1995).
This T ?, when mapped via G, forms the al-phabet of the above 2 sentences.Assumption: The machine learning paradigmcan treat deep lexical acquisition.If we reject the assumption that there is some?meaning?
of a sentence spanned by a set of mean-ing primitives, the soothing clarity of the machinelearning paradigm is no longer available.
We cannotmap parse trees onto sentence meanings.
The pos-sibility of ?Putting Meaning in Your Trees?
(Palmer2004) completely disappears.
We may still use themachine learning paradigm to parse, disambiguateand recognize speech.
But these results are of lit-tle use to model theory, concept and lexical acquisi-tion, because there is no output representation wherea suitable training set could be collected.
The humanconceptual apparatus is not that simple: the VAD re-quires G(T ?)
(which changes, as T ?
changes), andfor that we need explanatory accounts of UT and G,and must recognize the diverse ways the TAD maychange state.97Assumption: Paths from shallow to deep lexicalacquisition existThe Golden Oldies Models of concepts (Figure1a) and the Universal Theory models of concepts(Figure 1b) are incommensurable.
The path fromthe shallow to the deep cannot be declared to existby fiat.
Wishful thinking is inappropriate, becauseone architecture is more powerful than the other: theGolden Oldies model did not expose the TAD statespace.
Instead, lexical semantics results obtainedunder the Golden Oldies model require translationinto the UT model: the privileged position syntacticpositions that motivated thematic roles and lexicalsemantics primitives, the bi-partite event structurerevealed through adverbial modification, and so on.This translation is mediated in G, and will not yielda notational variant of what we started with.Assumption: Verb classes determine meaningsWe must distinguish between a representation ofverb meanings determined by the distribution ofsubcategorization frames and cued by these frames.Landau and Gleitman (1990) showed that verb?s par-ticipation in some frames but not others are cuesthat a child uses to constrain verb meaning.
Levinand Rappaport-Hovav (1998) explicitly distinguishstructural and idiosyncratic components of mean-ing.
But neither claim that verb classes or statisticaldistributions of subcategorization frames determineverb meaning.
Yet VerbNet maps verbs to predicatesin precisely this way: (Kingsbury et al2002).cure, rob, .
.
.
: Verbs of Inalienable Possessioncause(Agent,E) location(start(E),Theme,Source)marry, divorce, .
.
.
: Verbs of Social Interactionsocial interaction(.
.
.
)The distinction between cure and rob, or betweenmarry and divorce is not astonishing to the Englishspeaker.
Causal mechanisms behind disease, pos-session, and the marital practices that were labeledidiosyncratic by the lexical semanticist must be cap-tured in T ?.Assumption: Language is separate from generalsystems of knowledge and beliefThis ?defining?
assumption helped for the GoldenOldies, but innovations in developmental psychol-ogy motivate dropping this assumption.
The bridgeis provided by the concept generator G: it maps anaive theory T ?
(general systems of knowledge andbelief) to G(T ?
), used by the VAD (language).Assumption: Real-world knowledge is BadThe absence of the soothing clarity of the machinelearning paradigm and presence of real world knowl-edge in T ?
brings forth 2 associations:Early Schank/Cyc = Much Knowledge = UT research = BadStatistics = Little Knowledge = shallow semantics = GoodThe associations lead to the inference that UniversalTheory research will suffer a similar fate as the 70sSchankian program and the Cyc program (Schank1972, Lenat and Guha 1990).
However, this infer-ence is incorrect.
The 70s Schankian program andCyc efforts did not carefully consider the constraintsof syntactic phenomena or developmental psychol-ogy.
Schank and his colleagues stimulated researchin qualitative physics and explanation-based learn-ing that addressed many of these deficiencies, butthere is much work to be done to bridge today?s ef-forts in deep lexical acquisition to this.Assumption: Others will provide us the answersLexical semanticists now rely on cognitive expla-nations far more heavily than ever before.
Jack-endoff (2002) concludes: ?someone has to studyall these subtle frameworks of meaning - so whynot linguists??
Levin and Rappaport-Hovav (2003),addressing denominal verbs such as mop and but-ter, now freely point to ?general cognitive prin-ciples?
rather than situate knowledge in the lexi-con.
Rather than consume lexical semantics of theGolden Oldies, we can draw upon our toolbox toagain answer Question (1): ?what is a lexicalizableconcept?
?5 We Must Change Our ConceptsStop working with models of concepts from theGolden Oldies.
Start questioning whether resultsunder the machine learning paradigm are really re-sults.
Change your concept of a result.
Learn howchildren do theory, concept and vocabulary acqui-sition.
Expose the fundamental ingredients of con-cepts.
Change your concept of deep.
Change yourconcept of computational linguistics.
Radical con-ceptual change is possible.
Write some new songs,and sing some new tunes.
We can have some GreatGolden Oldies of Tomorrow.98ReferencesS.
Atran.
Classifying nature across cultures.
In E. Smith and D. Osherson, edi-tors, Thinking: An invitation to cognitive science, Cambridge, MA, 1995.
MITPress.D.
Bailey, J. Feldman, S. Narayanan, and G. Lakoff.
Modeling embodied lexicaldevelopment.
In Proceedings of the Annual Cognitive Science Society, 1997.K.
Bartsch and H. Wellman.
Children Talk about the Mind.
Oxford UniversityPress, New York, 1995.R.
Brown.
Linguistic determinism and the part of speech.
Journal of Abnormaland Social Psychology, 1957.S.
Carey.
Conceptual Change in Childhood.
MIT Press, Cambridge, MA, 1985.N.
Chomsky.
Aspects of the Theory of Syntax.
MIT Press, Cambridge, MA, 1965.A.
M. Collins and M. R. Quillian.
Retrieval time from semantic memory.
Journalof Verbal Learning and Verbal Behavior, 8:240?247, 1969.B.
Falkenhainer, K. Forbus, and D. Gentner.
The structure-mapping engine: Al-gorithm and examples.
Artificial Intelligence, 41:1?63, 1989.G.
Fauconnier and M. Turner.
Conceptual integration networks.
Cognitive Sci-ence, 22(2):133?187, 1998.C.
Fillmore.
The case for case.
In E. Bach and R. Harms, editors, Universals inLinguistic Theory, pages 1?90, New York, 1968.
Holt, Rinehart and Winston.C.
Fillmore, C. Wooters, and C. Baker.
Building a large lexical databank whichprovides deep semantics.
In Proceedings of the Pacific Asian Conference onLanguage, Information and Computation, Hong Kong, 2001.K.
Forbus.
Qualitative process theory.
Artificial Intelligence, 24:85?168, 1984.D.
Gentner.
Why we?re so smart.
In D. Gentner and S. Goldin-Meadow, editors,Language in mind: Advances in the study of language and thought, pages195?235, Cambridge, MA, 2003.
MIT Press.A.
Gopnik, C. Glymour, D. Sobel, L. Schultz, and T. Kushnir.
Theory formationand causal learning in children: Causal maps and bayes nets.
PsychologicalReview, in press.A.
Gopnik and A. Meltzoff.
Words, thoughts and theories.
MIT Press, Cam-bridge, MA, 1997.J.
Hobbs, W. Croft, T. Davies, D. Edwards, and K. Law.
Commonsense meta-physics and lexical semantics.
Computational Linguistics, 13:241?250, 1987.R.
S. Jackendoff.
Semantics and Cognition.
MIT Press, Cambridge, MA, 1983.R.
S. Jackendoff.
Foundations of Language.
Oxford University Press, Oxford,2002.F.
Keil.
Semantic and Conceptual Development: An Ontological Perspective.Harvard University Press, Cambridge, MA, 1979.C.
Kennedy and L. McNally.
Scale structure and the semantic typology of grad-able predicates.
Language, 2002.P.
Kingsbury, M. Palmer, and M. Marcus.
Adding semantic annotation to the penntreebank.
In Proceedings of Human Language Technology Conference, 2002.B.
Kuipers.
Qualitative Reasoning.
MIT Press., Cambridge, MA, 1994.B.
Landau and L. R. Gleitman.
Language and experience: Evidence from theblind child.
Harvard University Press, Cambridge, MA, 1985.S.
Laurence and E. Margolis.
Radical concept nativism.
Cognition, 86:22?55,2002.D.
Lenat and D. Guha.
Building large knowledge-based systems: Representationand Inference in the Cyc Project.
Addison-Wesley, Reading, MA, 1990.A.
Leslie.
How to acquire a representational theory of mind.
In D. Sperber,editor, Metarepresentations: An Multidisciplinary perspective., pages 197?223, Oxford, 2000.
Oxford Press.B.
Levin.
English Verb Classes and Alternations: A Preliminary Investigation.University of Chicago Press, Chicago, IL, 1993.B.
Levin and M. Rappaport-Hovav.
Objecthood and object alternations.
ms, 2003.J.
Mandler.
Foundations of Mind: Origins of Conceptual Thought.
Oxford Uni-versity Press, New York, 2004.M.
McCloskey.
Intuitive physics.
Scientific American, 248:122?130, 1983.G.
Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. Miller.
Five papers onwordnet.
International Journal of Lexicology, 3(4), 1990.M.
Minsky.
A framework for representing knowledge.
In P. Winston, editor, Thepsychology of Computer Vision., pages 211?277, New York, 1975.
McGraw-Hill.N.
Nersessian.
Comparing historical and intuitive explanations of motion: Doesnaive physics have a structure?
In Proceedings of the Eleventh Annual Con-ference of the Cognitive Science Society, pages 412?420, 1989.S.
Niyogi.
Aspects of the logical structure of conceptual analysis.
Proceedings ofthe 27th Annual Meeting of the Cognitive Science Society, 2005.S.
Niyogi.
The universal theory model of concepts and the dissolution of thepuzzle of concept acquisition.
Proceedings of the 27th Annual Meeting of theCognitive Science Society, 2005.M.
Palmer.
Putting meaning in your trees.
In CoNLL-2004, 2004.J.
Pustejovsky.
The Generative Lexicon.
MIT Press, Cambridge, MA, 1995.W.
Quine.
Word and Object.
MIT Press, Cambridge, MA, 1960.T.
Regier.
The Human Semantic Potential.
MIT Press, Cambridge, MA, 1996.T.
Rogers and J. McClelland.
Semantic Cognition: A parallel distributed Pro-cessing approach.
MIT Press, Cambridge, MA, 2004.D.
Roy and Pentland.
Learning words from sights and sounds: A computationalmodel.
Cognitive Science, 26:113?146, 2002.L.
Rozenblit and F. Keil.
The misunderstood limits of folk science: an illusion ofexplanatory depth.
Cognitive Science, 26:521?562, 2002.R.
Schank.
Conceptual dependency theory.
Cognitive Psychology, 3:552?631,1972.J.
Siskind.
A computational study of cross-situational techniques for learningword-to-meaning mappings.
Cognition, 61:39?91, 1996.V.
Slaughter, R. Jaakola, and S. Carey.
Constructing a coherent theory: children?sbiological understanding of life and death.
In M. Siegel and C. Peterson,editors, Children?s understanding of biology and health, Cambridge, 1999.Cambridge University.V.
Slaughter, R. Jaakola, and S. Carey.
Constructing a coherent theory: children?sbiological understanding of life and death.
In M. Siegel and C. Peterson,editors, Children?s understanding of biology and health, Cambridge, 1999.Cambridge University.C.
Yu and Dana H. Ballard (2004) A Unified Model of Early Word Learning:Integrating Statistical and Social Cues.
Proceedings of the 3rd InternationalConference on Development and Learning, 2004.99
