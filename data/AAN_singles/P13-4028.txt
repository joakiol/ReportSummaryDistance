Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 163?168,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsSEMILAR: The Semantic Similarity ToolkitVasile Rus, Mihai Lintean, Rajendra Banjade, Nobal Niraula, and Dan StefanescuDepartment of Computer ScienceThe University of MemphisMemphis, TN 38152{vrus,rbanjade,mclinten,nbnraula,dstfnscu}@memphis.eduAbstractWe present in this paper SEMILAR, the SE-Mantic simILARity toolkit.
SEMILAR im-plements a number of algorithms for assessingthe semantic similarity between two texts.
It isavailable as a Java library and as a Javastandalone ap-plication offering GUI-basedaccess to the implemented semantic similaritymethods.
Furthermore, it offers facilities formanual se-mantic similarity annotation by ex-perts through its component SEMILAT (aSEMantic simILarity Annotation Tool).1 IntroductionWe present in this paper the design and im-plementation of SEMILAR, the SEManticsimILARity toolkit.
SEMILAR(www.semanticsimilarity.org) includes im-plementations of a number of algorithms pro-posed over the last decade or so to addressvarious instances of the general problem oftext-to-text semantic similarity.
Semantic sim-ilarity is an approach to language understand-ing that is widely used in real applications.
Itis a practical alternative to the true under-standing approach, which is intractable as itrequires world knowledge, a yet to-be-solvedproblem in Artificial Intelligence.Text A: York had no problem with MTA?s in-sisting the decision to shift funds had been withinits legal rights.Text B: York had no problem with MTA?s say-ing the decision to shift funds was within itspowers.Given such two texts, the paraphrase identifi-cation task is about automatically assessingwhether Text A is a paraphrase of, i.e.
has thesame meaning as, Text B.
The example above isa positive instance, meaning that Text A is a par-aphrase of Text B and vice versa.The importance of semantic similarity in Nat-ural Language Processing (NLP) is highlightedby the diversity of datasets and shared task eval-uation campaigns (STECs) that have been pro-posed over the last decade (Dolan, Quirk, andBrockett, 2004; McCarthy & McNamara, 2008;Agirre et al 2012).
These datasets include in-stances from various applications.
Indeed, thereis a need to identify and quantify semantic rela-tions between texts in many applications.
Forinstance, paraphrase identification, an instance ofthe semantic similarity problem, is an importantstep in a number of applications including Natu-ral Language Generation, Question Answering,and dialogue-based Intelligent Tutoring Systems.In Natural Language Generation, paraphrases area method to increase diversity of generated text(Iordanskaja et al1991).
In Question Answer-ing, multiple answers that are paraphrases ofeach other could be considered as evidence forthe correctness of the answer (Ibrahim et al2003).
In Intelligent Tutoring Sys-tems (Rus etal., 2009; Lintean et al 2010; Lintean, 2011),paraphrase identification is useful to assesswhether students?
articulated answers to deepquestions (e.g.
conceptual physics questions) aresimilar-to/paraphrases-of ideal answers.Generally, the problem of semantic similaritybetween two texts, denoted text A and text B, isdefined as quantifying and identifying the pres-ence of semantic relations between the two texts,e.g.
to what extent text A has the same meaningas or is a paraphrase of text B (paraphrase rela-tion; Dolan, Quirk, and Brockett, 2004).
Othersemantic relations that have been investigatedsystematically in the recent past are entailment,i.e.
to what extent text A entails or logically in-fers text B (Dagan, Glickman, & Magnini, 2004),and elaboration, i.e.
is text B is an elaboration oftext A?
(McCarthy & McNamara, 2008).163Semantic similarity can be broadly construedbetween texts of any size.
Depending on thegranularity of the texts, we can talk about thefollowing fundamental text-to-text similarityproblems: word-to-word similarity, phrase-to-phrase similarity, sentence-to-sentence similari-ty, paragraph-to-paragraph similarity, or docu-ment-to-document similarity.
Mixed combina-tions are also possible such as assessing the simi-larity of a word to a sentence or a sentence to aparagraph.
For instance, in summarization itmight be useful to assess how well a sentencesummarizes an entire paragraph.2 MotivationThe problem of word-to-word similarity has beenextensively studied over the past decades and aword-to-word similarity library (WordNet Simi-larity) has been developed by Pedersen and col-leagues (Pedersen, Patwardhan, & Michelizzi,2004).Methods to assess the semantic similarity oflarger texts, in particular sentences, have beenproposed over the last decade (Corley andMihalcea, 2005; Fernando & Stevenson, 2008;Rus, Lintean, Graesser, & McNamara 2009).Androutsopoulos & Malakasiotis (2010) com-piled a survey of methods for paraphrasing andentailment semantic relation identification at sen-tence level.
Despite all the proposed methods toassess semantic similarity between two texts, nosemantic similarity library or toolkit, similar tothe WordNet library for word-to-word similarity,exists for larger texts.
Given the importance ofsemantic similarity, there is an acute need forsuch a library and toolkit.
The developed SEMI-LAR library and toolkit presented here fulfill thisneed.In particular, the development of the semanticsimilarity toolkit SEMILAR has been motivatedby the need for an integrated environment thatwould provide:?
easy access to implementations of varioussemantic similarity approaches from thesame user-friendly interface and/or library.?
easy access to semantic similarity methodsthat work at different levels of text granulari-ty: word-to-word, sentence-to-sentence, par-agraph-to-paragraph, document-to-document, or a combination (SEMILAR in-tegrates word-to-word similarity measures).?
authoring methods for semantic similarity.?
a common environment for that allows sys-tematic and fair comparison of semantic sim-ilarity methods.?
facilities to manually annotate texts with se-mantic similarity relations using a graphicaluser interface that make such annotationseasier for experts (this component is calledSEMILAT component - a SEMantic similari-ty Annotation Tool).SEMILAR is thus a one-stop-shop for investi-gating, annotating, and authoring methods for thesemantic similarity of texts of any level of granu-larity.3 SEMILAR: The Semantic SimilarityToolkitThe authors of the SEMILAR toolkit (see Figure1) have been involved in assessing the semanticFigure 1.
Snapshot of SEMILAR.
The Data View tab is shown.164similarity of texts for more than a decade.
Duringthis time, they have conducted a careful require-ments analysis for an integrated software toolkitthat would integrate various methods for seman-tic similarity assessment.
The result of this effortis the prototype presented here.
We briefly pre-sent the components of SEMILAR next and thendescribe in more detail the core component ofSEMILAR, i.e.
the set of semantic similaritymethods that are currently available.
It should benoted that we are continuously adding new se-mantic similarity methods and features to SEMI-LAR.The SEMILAR toolkit includes the followingcomponents: project management; data view-browsing-visualization; preprocessing (e.g., col-location identification, part-of-speech tagging,phrase or dependency parsing, etc.
), semanticsimilarity methods (word-level and sentence-level), classification components for qualitativedecision making with respect to textual semanticrelations (na?ve Bayes, Decision Trees, SupportVector Machines, and Neural Network), kernel-based methods (sequence kernels, word sequencekernels, and tree kernels; as of this writing, weare still implementing several other tree kernelmethods); debugging and testing facilities formodel selection; and annotation components (al-lows domain expert to manually annotate textswith semantic relations using GUI-based facili-ties; Rus et al 2012).
For space reasons, we onlydetail next the main algorithms in the core com-ponent, i.e.
the major text-to-text similarity algo-rithms currently available in SEMILAR.4 The Semantic Similarity MethodsAvailable in SEMILARThe core component of SEMILAR is a set oftext-to-text semantic similarity methods.
Wehave implemented methods that handle both uni-directional similarity measures as well as bidirec-tional similarity measures.
For instance, the se-mantic relation of entailment between two textsis unidirectional (a text T logically entails a hy-pothesis text H but H does not entail T) while theparaphrase relation is bidirectional (text A hassame meaning as text B and vice versa).Lexical Overlap.
Given two texts, the sim-plest method to assess their semantic similarity isto compute lexical overlap, i.e.
how many wordsthey have in common.
There are many lexicaloverlap variations.
Indeed, a closer look at lexi-cal overlap reveals a number of parameters thatturns the simple lexical overlap problem into alarge space of possibilities.
The parameters in-clude preprocessing options (collocation detec-tion, punctuation, stopword removal, etc.
), filter-ing options (all words, content words, etc.
),weighting schemes (global vs. local weighting,binary weighting, etc.
), and normalization factors(largest text, weighted average, etc.).
A total of3,456 variants of lexical overlap can be generat-ed by different parameter settings in SEMILAR.Lintean (2011) has shown that performance onlexical overlap methods on the tasks of para-phrase identification and textual entailment taskscan vary significantly depending on the selectedparameters.
Some lexical overlap variations leadto performance results rivaling more sophisticat-ed, state-of-the-art methods.It should be noted that the overlap category ofmethods can be extended to include N-gramoverlap methods (see the N-gram overlap meth-ods proposed by the Machine Translation com-munity such as BLEU and METEOR).
SEMI-LAR offers bigram and unigram overlap methodsincluding the BLEU and METEOR scores.A natural approach to text-to-text similaritymethods is to rely on word-to-word similaritymeasures.
Many of the methods presented nextcompute the similarity of larger texts using indi-vidual word similarities.Mihalcea, Corley, & Strappavara (2006;MCS) proposed a greedy method based on word-to-word similarity measures.
For each word intext A (or B) the maximum similarity score toany word in the other text B (or A) is used.
Anidf-weighted average is then computed as shownin the equation below.)}2{)(}2{)}(*)1,(max{}1{)(}1{)}(*)2,(max{(21)2,1(?????????
?TwwidfTwwidfTwSimTwwidfTwwidfTwSimTTsimThe word-to-word similarity function sim(w,T) in the equation above can be instantiated toany word-to-word similarity measure (e.g.WordNet similarities or Latent Semantic Analy-sis).
The vast majority of word-to-word similari-ty measures that rely on WordNet are concept-to-concept measures and to be able to use them onemust map words in the input texts onto conceptsin WordNet, i.e.
word sense disambiguation(WSD) is needed.
As of this writing, SEMILARaddresses the issue in two simple ways: (1) se-165lecting the most frequent sense for each word,which is sense #1 in WordNet, and (2) using allthe senses for each word and then take the max-imum (or average) of the relatedness scores foreach pair of word senses.
We label the formermethod as ONE (sense one), whereas the latter islabeled as ALL-MAX or ALL-AVG (all sensesmaximum score or all senses average score, re-spectively).
Furthermore, most WordNet-basedmeasures only work within a part-of-speech cat-egory, e.g.
only between nouns.Other types of word-to-word measures, suchas those based on Latent Semantic Analysis orLatent Dirichlet Allocation, do not have a word-sense disambiguation challenge.Rus and Lintean (2012; Rus-Lintean-Optimal Matching or ROM) proposed an opti-mal solution for text-to-text similarity based onword-to-word similarity measures.
The optimallexical matching is based on the optimal assign-ment problem, a fundamental combinatorial op-timization problem which consists of finding amaximum weight matching in a weighted bipar-tite graph.Given a weighted complete bipartite graph, where edge  has weight, the optimal assignment problem is tofind a matching M from X to Y with maximumweight.A typical application is about assigning agroup of workers, e.g.
words in text A in ourcase, to a set of jobs (words in text B in our case)based on the expertise level, measured by, of each worker at each job.
By addingdummy workers or jobs we may assume that Xand Y have the same size, n, and can be viewedas   and Y = .In the semantic similarity case, the weightis the word-to-word similarity between a word xin text A and a word y in text B.The assignment problem can also be stated asfinding a permutation  of {1, 2, 3, ?
, n} forwhich  is maximum.
Such anassignment is called optimum assignment.
TheKuhn-Munkres algorithm (Kuhn, 1955) can finda solution to the optimum assignment problem inpolynomial time.Rus and colleagues (Rus et al 2009; Rus &Graesser, 2006; Rus-Syntax-Negation or RSN)used a lexical overlap component combined withsyntactic overlap and negation handling to com-pute an unidirectional subsumption score be-tween two sentences, T (Text) and H (Hypothe-sis), in entailment recognition and student inputassessment in Intelligent Tutoring Systems.
Eachtext is regarded as a graph with words asnodes/vertices and syntactic dependencies asedges.
The subsumption score reflects how mucha text is subsumed or contained by another.
Theequation below provides the overall subsumptionscore, which can be averaged both ways to com-pute a similarity score, as opposed to just thesubsumption score, between the two texts.2)_#)1(1()||),(max||),(max(),(relneghEeHhEtEhEmatcheTtEhVvHhVtVhVmatchvTtVHTsubsump??????????????
?The lexical component can be used by itself(given a weight of 1 with the syntactic compo-nent given a weight of 0) in which case the simi-larity between the two texts is just a composi-tional extension of word-to-word similaritymeasures.
The match function in the equationcan be any word-to-word similarity measure in-cluding simple word match, WordNet similaritymeasures, LSA, or LDA-based similaritymeasures.Fernando and Stevenson (FST; 2008) pro-posed a method in which similarities among allpairs of words are taken into account for compu-ting the similarity of two texts.
Each text is rep-resented as a binary vector (1 ?
the word occursin the text; 0 ?
the word does not occur in thetext).
They use a similarity matrix operator Wthat contains word-to-word similarities betweenany two words.||||),( ??????
?baTbWabasimEach element wij represents the word-levelsemantic similarity between word ai in text Aand word bj in text B.
Any word-to-word seman-tic similarity measure can be used.Lintean and Rus (2010; weighted-LSA orwLSA) extensively studied methods for semanticsimilarity based on Latent Semantic Analysis(LSA; Landauer et al 2006).
LSA representswords as vectors in a 300-500 dimensional LSAspace.
An LSA vector for larger texts can be de-rived by vector algebra, e.g.
by summing up theindividual words?
vectors.
The similarity of twotexts A and B can be computed using the cosine(normalized dot product) of their LSA vectors.Alternatively, the individual word vectors can be166combined through weighted sums.
Lintean andRus (2010) experimented with a combination of3 local weights and 3 global weights.
All theseversions of LSA-based text-to-text similaritymeasures are available in SEMILAR.SEMILAR also includes a set of similaritymeasures based on the unsupervised method La-tent Dirichlet Allocation (LDA; Blei, Ng, &Jordnan, 2003; Rus, Banjade, & Niraula,2013).
LDA is a probabilistic generative modelin which documents are viewed as distributionsover a set of topics (?d - text d?s distribution overtopics) and topics are distributions over words (?t?
topic t?s distribution over words).
That is, eachword in a document is generated from a distribu-tion over words that is specific to each topic.A first LDA-based semantic similarity meas-ure among words would then be defined as a dot-product between the corresponding vectors rep-resenting the contributions of each word to a top-ic (?t(w) ?
represents the probability of word win topic t).
It should be noted that the contribu-tions of each word to the topics does not consti-tute a distribution, i.e.
the sum of contributions isnot 1.
Assuming the number of topics T, then asimple word-to-word measure is defined by theformula below.More global text-to-text similarity measures couldbe defined in several ways as detailed next.Because in LDA a document is a distributionover topics, the similarity of two texts needs tobe computed in terms of similarity of distribu-tions.
The Kullback-Leibler (KL) divergencedefines a distance, or how dissimilar, two distri-butions p and q are as in the formula below.If we replace p with ?d (text/document d?s dis-tribution over topics) and q with ?c(text/document c?s distribution over topics) weobtain the KL distance between two documents(documents d and c in our example).
The KLdistance has two major problems.
In case qi iszero KL is not defined.
Then, KL is not symmet-ric.
The Information Radius measure (IR) solvesthese problems by considering the average of piand qi as below.
Also, the IR can be transformedinto a symmetric similarity measure as in the fol-lowing (Dagan, Lee, & Pereira, 1997):The Hellinger and Manhattan distances be-tween two distributions are two other optionsthat avoid the shortcomings of the KL distance.Both are options are implemented in SEMILAR.LDA similarity measures between two docu-ments or texts c and d can also include similarityof topics.
That is, the text-to-text similarity isobtained multiplying the similarities between thedistribution over topics (?d and ?c) and distribu-tion over words (?t1 and ?t2).
The similarity oftopics can be computed using the same methodsillustrated above as the topics are distributionsover words (for all the details see Rus, Banjade,& Niraula, 2013).The last semantic similarity method presentedin this paper is based on the Quadratic Assign-ment Problem (QAP).
The QAP method aims atfinding an optimal assignment from words in textA to words in text B, based on individual word-to-word similarity measures, while simultaneous-ly maximizing the match between the syntacticdependencies of the words.The Koopmans-Beckmann (1957) formulationof the QAP problem best fits this purpose.
Thegoal of the original QAP formulation, in the do-main of economic activity, was to minimize theobjective function QAP shown below where ma-trix F describes the flow between any two facili-ties, matrix D indicates the distances betweenlocations, and matrix B provides the cost of lo-cating facilities to specific locations.
F, D, and Bare symmetric and non-negative.??
?????
?nini iibnj jidjifBDFQAP 1 1 )(,1 )()(,),,(min ??
?The fi,j term denotes the flow between facili-ties i and j which are placed at locations ?
(i) and?
(j), respectively.
The distance between theselocations is d?(i)?(j).
In our case, F and D describedependencies between words in one sentencewhile B captures the word-to-word similaritybetween words in opposite sentences.
Also, wehave weighted each term in the above formula-tion and instead of minimizing the sum we aremaximizing it resulting in the formulation below.??
??????
?nini iibnj jidjifBDFQAP 1 1 )(,)1(1 )()(,),,(max ?????????
Tttt vwvwwwLDA1)()(),(2 ??
),(10),( dcIRqpSIM ??????
Ti iii qppqpKL1log),(1675 Discussion and ConclusionsThe above methods were experimented with onvarious datasets for paraphrase, entailment, andelaboration.
For paraphrase identification, theQAP method provides best accuracy results(=77.6%) on the test subset of the Microsoft Re-search Paraphrase corpus, one of the largest par-aphrase datasets.Due to space constraints, we have not de-scribed all the features available in SEMILAR.For a complete list of features, latest news, refer-ences, and updates of the SEMILAR toolkitalong with downloadable resources includingsoftware and data files, the reader can visit thislink: www.semanticsimilarity.org.AcknowledgmentsThis research was supported in part by Institutefor Education Sciences under awardR305A100875.
Any opinions, findings, and con-clusions or recommendations expressed in thismaterial are solely the authors?
and do not neces-sarily reflect the views of the sponsoring agency.ReferencesAndroutsopoulos, I.
& Malakasiotis, P. 2010.
A sur-vey of paraphrasing and textual entailment meth-ods.
Journal of Artificial Intelligence Research,38:135-187.Agirre, E., Cer, D., Diab, M., & Gonzalez-Agirre, A.(2012).
SemEval-2012 Task 6: A Pilot on SemanticTextual Similarity, First Joint Conference on Lexi-cal and Computational Semantics (*SEM), Mon-treal, Canada, June 7-8, 2012.Blei, D.M., Ng, A.Y., & Jordan, M.I.
2003.
Latentdirichlet alcation, The Journal of Machine Learn-ing Research 3, 993-1022.Corley, C., & Mihalcea, R. (2005).
Measuring theSemantic Similarity of Texts.
In Proceedings of theACL Workshop on Empirical Modeling of Seman-tic Equivalence and Entailment.
Ann Arbor, MI.Dagan, I., Glickman, O., & Magnini, B.
(2004).
ThePASCAL Recognising textual entailment Chal-lenge.
In Quinorero-Candela, J.; Dagan, I.; Magni-ni, B.; d'Alche-Buc, F.
(Eds.
), Machine LearningChallenges.
Lecture Notes in Computer Science,Vol.
3944, pp.
177-190, Springer, 2006.Dolan, B., Quirk, C., & Brockett, C. (2004).
Unsuper-vised construction of large paraphrase corpora: Ex-ploiting massively parallel news sources.
In Pro-ceedings of the 20th International Conference onComputational Linguistics (COLING-2004), Gene-va, Switzerland.Fernando, S. & Stevenson, M. (2008).
A semanticsimilarity approach to paraphrase detec-tion, Computational Linguistics UK (CLUK 2008)11th Annual Research Colloquium.Lintean, M., Moldovan, C., Rus, V., & McNamara D.(2010).
The Role of Local and Global Weighting inAssessing the Semantic Similarity of Texts UsingLatent Semantic Analysis.
Proceedings of the 23rdInternational Florida Artificial Intelligence Re-search Society Conference.
Daytona Beach, FL.Lintean, M. (2011).
Measuring Semantic Similarity:Representations and Methods, PhD Thesis, De-partment of Computer Science, The University ofMemphis, 2011.Ibrahim, A., Katz, B., & Lin, J.
(2003).
Extractingstructural paraphrases from aligned monolingualcorpora In Proceedings of the Second InternationalWorkshop on Paraphrasing, (ACL 2003).Iordanskaja, L., Kittredge, R., & Polgere, A.
(1991).Natural Language Generation in Artificial Intelli-gence and Computational Linguistics.
Lexical se-lection and paraphrase in a meaning-text genera-tion model, Kluwer Academic.McCarthy, P.M. & McNamara, D.S.
(2008).
User-Language Paraphrase Corpus Challengehttps://umdrive.memphis.edu/pmmccrth/public/ParaphraseCorpus/Paraphrase site.htm.
Retrieved2/20/2010 online, 2009.Pedersen, T., Patwardhan, S., & Michelizzi, J.
(2004).WordNet::Similarity - Measuring the Relatednessof Concepts, In the Proceedings of the NineteenthNational Conference on Artificial Intelligence(AAAI-04), pp.
1024-1025, July 25-29, 2004, SanJose, CA (Intelligent Systems Demonstration).Rus, V., Lintean M., Graesser, A.C., & McNamara,D.S.
(2009).
Assessing Student Paraphrases UsingLexical Semantics and Word Weighting.
In Pro-ceedings of the 14th International Conference onArtificial Intelligence in Education, Brighton, UK.Rus, V., Lintean, M., Moldovan, C., Baggett, W.,Niraula, N., Morgan, B.
(2012).
The SIMILARCorpus: A Resource to Foster the Qualitative Un-derstanding of Semantic Similarity of Texts, InSemantic Relations II: Enhancing Resources andApplications, The 8th Language Resources andEvaluation Conference (LREC 2012), May 23-25,Instanbul, Turkey.Rus, V., Banjade, R., & Niraula, N. (2013).
SimilarityMeasures based on Latent Dirichlet Allocation,The 14th International Conference on IntelligentText Procesing and Computational Linguistics,March 24-30, 2013, Samos, Greece.168
