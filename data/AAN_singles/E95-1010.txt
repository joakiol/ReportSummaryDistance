Text Alignment in the Real World: Improving Alignments of NoisyTranslations Using Common Lexical Features, String Matching Strategiesand N-Gram Comparisons ~Mark W. Davis, Ted E. Dunning and William C. OgdenComputing Research LaboratoryNew Mexico State UniversityBox 30001/3CRLLas Cruces, New MexicoUSA{ madavis,ted,ogden } @crl.nmsu.eduAbstractAlignment methods based on byte-lengthcomparisons of alignment blocks have beenremarkably successful for aligning goodtranslations from legislative transcriptions.For noisy translations in which the paralleltext of a document has significant structuraldifferences, byte-alignment methods oftendo not perform well.
The Pan AmericanHealth Organization (PAHO) corpus is aseries of articles that were first translated bymachine methods and then improved by pro-fessional translators.
Many of the SpanishPAHO texts do not share formatting conven-tions with the corresponding English docu-ments, refer to tables in stylistically differentways and contain extraneous information.
Amethod based on a dynamic programmingframework, but using a decision criterionderived from a combination of byte-lengthratio measures, hard matching of numbers,string comparisons and n-gram co-occur-rence matching substantially improves theperformance of the alignment process.1 IntroductionGiven texts in two languages that are to some degreetranslations of one another, an alignment of the textsassociates entences, paragraphs or phrases in onedocument with their translations in the other.
Success-ful approaches to alignment can be divided into twoprimary types: those that use comparisons of lexicalelements between the documents (Wu, 1994; Chen1993; Catizone, Russell and Warwick, 1989), andIThis research was funded under DoD Contract#MDA 904-94-C-E086those that use a statistical decision process derivedfrom byte-length ratios between alignment blocks(Wu, 1994; Church, 1993; Gale and Church, 1991).Methods vary for the former approach, hut in the lat-ter approach, a dynamic programming framework isused to sequentially align blocks as the alignment pro-cess proceeds.
Under this model, blocks are comparedonly with nearby blocks as the alignment proceeds,substantially reducing the computational overhead\[O(n 2) ~ O(n!
)\] of the alignment process.In the primary literature on alignment, he texts aretypically well-behaved.
In byte-length ratioapproaches, the presence of long stretches of blocksthat have roughly similar lengths can be problematic,and some improvement can be achieved by augment-ing the byte-length measure by scores derived fromlexical feature matching (Wu, 1994).
When combinedwith radical formatting departures between docu-ments that often arise in text translations, the difficul-ties of producing ood alignments are exacerbated bythe presence of untranslated segments, textual rear-rangements and other problematic text features.
Thedynamic programming framework makes long runs ofsegments that have no translation i  their parallel textdifficult to ignore because the limited window sizeprevents passing over those segments to reach appro-priate areas of the document further downstream.Taken together, these difficulties can be catastrophicto the alignment process.
Our experience shows thatthe fraction of correct alignments can drop to less than5%.Noisy translations of this sort do reflect humanerror and the preferences of translators, and they areprobably much more prevalent than alignment workon legislative transcriptions has indicated.
The pur-pose of this research was to ascertain what types ofinformation contained in a document could be used toimprove the alignment process, while not makinggross assumptions about the source text format con-67ventions and peculiarities.
The Pan American HealthOrganization (PAHO) corpus was used as a test cor-pus for evaluating the performance of the modifiedalignment algorithm.
The PAHO texts are a series ofdocuments on Latin American health issues and ourtest segment consisted of 180 documents that rangedfrom 20 to 3825 lines in length.
From these docu-ments, several of the more problematic texts werehand aligned for analysis and comparison with theresults of automatic alignment methods.2 A General ApproachThe byte-length ratio methods are very general in thatthey rely only upon a heuristic segmentation proce-dure to divide a text into sentence-level chunks.Although determining sentence boundaries can beproblematic across languages, simple assumptionsappear to work well even for comparisons betweenEuropean and Oriental anguages, primarily becausethe segmentation heuristic is uniformly applied toeach document and therefore an "undersegmented"section can combine together to match with singleblocks in the opposite language as necessary.Less general would be a method that relied on deepanalysis of the source texts to determine appropriateboundaries for alignment blocks.
A model thataccounted for all of the formatting discrepancies,comparative r scalings of sentence or phrase lengthdue to the economy of the language xpression, andother properties that may define a corpus, will notnecessarily be appropriate to other corpora or to textin general.We chose to remain as general as possible with ourinvestigations of alignment methods.
In particular, theheuristics for text segmentation regarded periods fol-lowed by a space, a newline (paragraph boundaries)or a tab as a sentence boundary for both English andSpanish texts (Figure 1).
Multiple periods separatedby spaces were ignored for alignment segmentation toXXXV MeetingWashington, D,C,?
XLIIt Meetingl/the.
- - ,  .
.
.
?
.It describes the situation of malaria inRegion in 1990, summarizing the information obtainedfrom theGovernments in response to the questionnaire sent to themannually.INTRODUCCIONEl presente documento es el XXXIX lnforme sobre laSituaei6nLa situaci6n de la malaria en el mundo se refiere a 1989,Yha sido tomada de publieaciones dela Organizaei6n Mun-dial de laSalud,~ S1TUACIN DE LA MALARIA EN EL MUNDOPoblaei6nen fiesgoMils de140% de la poblaci6n mundial, o sea, mils de2,000millones de personas, pemmncccn expuestas  diversos gra-dos deriesgo do malaria en unos 100 paises o territorios (Mapa 1).Figure 1: Sample English and Spanish texts with contiguous grey areas indicating alignmentblocks.68allow for ellipsis.
This approach did not, therefore,regard many abbreviations a a unique class of tex-tual event.
The end result was an extremely simplis-tic segmentation.3 The PAHO Corpus: Noisy,Problematic TextsThe PAHO texts serve as an important counter-part to our translator's workstation, Norm (Ogden,1993).
During the translation process, translatorscan access many different resources including avariety of on-line dictionaries, reference works andparallel texts.
The parallel texts include examplesof translations that different ranslators have com-piled in the past and serve as a series of examples ofhow to translate words and phrases for a particularcontext.
The PAHO texts also serve as a basis forour multi-lingual information retrieval system(Davis and Dunning, 1995; Dunning and Davis,1993a, 1993b).
The need for robust strategies toprocess and align large parallel corpora automati-cally is therefore a critical component of our ongo-ing research.In the PAHO corpus, many of the texts are well-behaved, with similar tokenization at the bound-aries delineating paragraphs.
But some areextremely noisy, with added text in the English orSpanish document hat lacks a counterpart in theparallel document.
Formatting conventions differ inmany cases, with multiple periods delimiting con-tents listings in one, while spaces serve a similarrole in the other, or tables and reference formats dif-fering between the two texts.
Another formattingproblem is the addition of significant runs ofwhitespace and newlines that simply do not occurin the parallel text.
The document pair shown inFigure 1 is representative of the quality of thePAHO texts.4 Features and AlignmentOne of the most striking features of English-Span-ish translations i the fact that native English speak-ers with little knowledge of Spanish appear able toidentify parallel texts with remarkable accuracy.The reason appears to be the large number of cog-nate terms that Spanish and English translationsshare, especially technical terms, and other lexicalfeatures such as numbers and proper names thatmay appear with similar placement and frequencyacross two parallel texts.
The work by Simard, Fos-ter and Isabelle (1993) as well as Church (1993)demonstrated that cognate-matching strategies canbe highly effective in aligning text.
Native Englishspeakers with limited Spanish appear to be capable ofaligning even noisy texts like many of the PAHO doc-uments, with difficulty causing a decrease in speed ofalignment, rather than decreased accuracy of thealignment.
From these observations, we examinedfive different sources of information for alignmentdiscrimination:?
Byte-length ratios?
Unordered character n-gram comparisons?
Simple ordered string-matching?
Number matching?
Bilingual-dictionary translationsThe analyses of each of these information sources arepresented in sections 5.1 through 5.5.For each method, a hand-aligned ocument fromPAHO corpus that was problematic for byte-ratiomethods was used for evaluation, first for comparingthe method's score distribution between randomblocks and the hand-aligned set, then for performingrealignments of the documents.
The document wasquite long for the PAHO set, containing about 1400lines of text and 360 alignment blocks in the Englishdocument and 1000 lines and 297 blocks in the Span-ish text.
In these particular documents, the Englishtext had nearly 400 lines of extraneous data abutted tothe end of it that was not in the Spanish document,increasing the error potential for byte-length methods.5 Improving AlignmentsWe used a modified and extended version of Gale andChurch's byte-ratio algorithm (199l) as a basis for animproved alignment algorithm.
The standard algo-rithm derives a penalty from a ratio of the byte lengthsof two potential aligned blocks and augments the pen-alty with a factor based on the frequency of matchesbetween blocks in one language that equate to a blockor blocks in the second language.
The byte-ratio pen-alty is the measurement-conditioned or a posterioriprobability of a match while the frequency of blockmatches gives the a priori  probability of the samematch.
Our version of the basic algorithm differs inthe mechanics of memory management (we use skip-lists to improve performance of the dynamic program-ming, for example), includes both positive and nega-tive information about the probability of a givenmatch and fuses multiple sources of information forevaluating alignment probabilities.For two documents, Dl and D 2 , consisting ofn andm alignment blocks, respectively, a i < n and by ~ m' analignment, A, is a set consisting ofai '"  "ai + l ~-4 b j .
.
.b j  +p pairs.
For compactness, we willwrite this as cti, l *~ flj, p.69p(AIDvD2) = 1-'I p(ai, t~-->f3j, plSp82 ..... 8k)(0ti.i ?,-> 13j,~) ~ AP (ai, l <'-> Dj, plSv 82 ..... 8k) = p(51 ' 52 .
.
.
.
.
5k )(Eq 1)(Eq2)P(a i ,  l<'-'>~j, pl51, 5 2 .
.
.
.
.
5k)P (5,, 5 2 ..... 5,l~i, t ~ f3j, p) p (~i,l ~ ~j,p)(Eq 3)P (51 , 5 2 .
.
.
.
.
5klO~i, 1 ~--> \[~j,p) P (o~i, 1 <--) \[~j,p) + P (51 , 5 2 .
.
.
.
.
5kl---~ ( o~i, l <--> \[~j,p)  P (-.-1 (o~i, 1 ?
?-.-> \[~j,p)(Eq 4)01 = logP(Sk\[Oti, l ~ ~j,p)0 2 = log\[P(Sk\]ai, l<--->\[~j,p) e(o~i,l<--->~j.p)+P(Skl~(ai, l~->~j,p))P(~(ai, t~--~j,p))\]03 = logP(a/ ,  l ~ ~j,p)argmaxe(AIDpD2) = ~ ~-01  +02-03A (a,.,~fb.
.)
cA k(Eq 5)(Eq 6)(Eq 7)(Eq 8)Figure 2.
Equations.Following the Gale and Church approach, wechoose an alignment that maximizes the probabilityover all possible alignments:arg r~ax \[P(A IDv D2)\]If we assume that the probabilities of individuallyaligned block pairs in an alignment are independent,the above equation becomes:p(AIDI, D2 ) = I-I e(eti, t~\[ij, plOpO2)(ai.t <'-> ~j,p) ~ AFurther assuming that the individual probabilities ofaligning two blocks, e(ai, t~-~fJj, pIDvD2), aredependent on features in the text described by a seriesof feature scores, 8 k, the above equations expandsinto Equation 1 in figure 2.Now, for each of the feature scoring functions, the aposteriori probabilities can be calculated from Bayes'Rule as shown in Equation 2, Figure 2 which, givenan approximation of the joint a posteriori probabili-ties by assuming independence, produces Equation 3,Figure 2.Note that the term in the denominator fEquation 3reflects both the statistics of the positive and negativeinformation for the alignment.
In Gale and Church'soriginal work, the denominator term was assumed tobe a constant over the range of 8, and therefore couldbe safely ignored during the maximization of proba-bilities over the alignment set.
In reality, this assump-tion is true only in the case of a uniform distributionof P (Sk\]~ (0~ i l ~ \[~j p) ) ' and is perhaps not even truein that Case due to ti{e scaling properties of the loga-rithm when the maximization problem above is con-verted to a minimization problem (below).In any case, the probability of a given value of fioccurring is not merely dependent on the probabilityof that score in the hand-aligned set, but is dependenton the comparative probabilities of the score for thehand aligned set and a set of randomly chosen align-ment blocks.
Clearly, if a value of 5 is equally likelyfor both the hand aligned and random sets, then themeasurement cannot contribute to the decision pro-cess.
Equation3 presents a very general approach tothe fusion of multiple sources of information aboutalignment probabilities.
Each of the sources contrib-utes to the overall probability of an alignment, but isin turn scaled by the total probability of a given scoreoccurring over the entire set of possible alignments.We can convert he maximization of probabilitiesinto a minimization of penalties taking the negativelogarithm of Equation 2 and substituting Equation 3,70where 01 , 0 2 and 03 are as given in figure 2, Equa-tions 5, 6 and 7.
Equation 8 in the same figure is theresult.The feature functions, 5 k , are derived from esti-mates of the probability of byte length differences,number matching score probabilities and string matchscore probabilities in our approach.The Bayesian prior, P(O~i,l<--.->~j,p), can  be esti-mated as per Gale and Church (1991) by assumingthat it is equal to the frequency of distinct n-mmatches in the training set.5.1 Byte-length Ratios, 5 IThe probability of an alignment based on byte-lengthratios is P(51 Ctl t ~-~ 13j p) = P(Sl(l(ct I t) l(~j p))),I .
", ', ~ ,where l ( ) is the byte-length function.
The distribu-tion is assumed to be a Gaussian random variablederived from the block length differences in the handaligned set.
Following Gale and Church (1991), theslope of the average of the length differencesdescribes the average number of Spanish charactersgenerated per English character.
Assuming that thedistribution is approximately Gaussian, we can nor-malize it to mean 0 and variance 1, resulting in:~il(/(?~i, t), l(pj p)) = l(pj, p) - l(txi, t)c' ~/(~i, t) 02where c = E(I(~j, p)/l(o~i, l) ) = 0.99 and 02 ~ O.
16 is theobserved variance.
The histogram in Figure 3a showsthe actual distribution of the hand-aligned ata set.The shape of the histogram is approximately Gauss-ian.
The distribution of the corresponding randomsegments in shown in Figure 3b.
Note that the distri-bution of the random set has significantly higher stan-dard deviation than the corresponding hand alignedset.
This diagram, as well as Figure 4 for the n-gramapproach on the following page, indicate the statisti-cal quality of the information provided by the scores.Good sources of information would produce amarkeddifference between the two distributions.
For compar-atively poor sources of information, the distributionswould show little or no differences.5.2 4-gram Matching, 5 2Cognates in English and Spanish often have shortruns of letters in common.
A measure that counts thenumber of matching n-grams in two strings is anunordered comparison of similarities within thestrings.
In this way, runs of letters in commonbetween cognate terms are measured.
We used an effi-cient n-gram matching algorithm that requires a sin-gle scan of each string, followed by two sorts and alinear-time list comparison to count matches.
Theresulting score was normalized by the total number ofn-grams between the strings.
Formally, for two stringselee....e p and sls2...s q, the n-gram match count, K n, isgiven by:Kn = 1 ~, ~<qm(eiei+ 1 n,~+l.. .Sj+n) p-q i<p j ""el+where mO is the matching function.
The function,m(), is equal to 1 only for equivalent n-grams, else itis 0.We chose to use 4-gram scores for the alignmentalgorithm, 52 = K 4 .
The distributions of the 4-gramDis t r ibut ion  o f  Byte - length  Rat io  Scores  fo r  the  Hand A l igned  Set70,0O65 ,0060 ,0055,O050,0045.00,IO,OO~:~ 35,0030,0025,0O2O.OO15.00IO.OO_~.00-40 .00  -20 .00  0 .008 1110.00100.009O.OO80.OO70.OO~ 6O.0O~ 5o .oo4o .oo30 .oo2o .oolo .ooo .ooDis t r ibut ion  o f  Byte - length  Rat ios  fo r  the  Randomly  A l igned  Set0.oo  500.008 t(a) (b)Figure 3.
Distribution of 51 for (a) hand aligned and (b) randomly aligned blocks71Dis t r ibut ion  of  4 -Gram Match  Scores  fo r  Hand A l igned  Set55.00  .
.
.
.
.
.
.
.
.
~' .
.
.
.
.
.
.
.
.
-: .
.
.
.
.
.
.
.
.
.
:- .
.
.
.5O.0045 .0O40 .0035 ,O030 .0025 .002O.0015 ,OO10 .OO5 .000 .00  50 .00  IOO.00  150.OO82x 1~ 3Dis t r ibut ion  o f  d -Gram Match  Scores  fo r  the  Random Set9O.O080 .OO7o .oo60 .0oo?o5o .oo~ 4o .o030 .0020 .o010 .00o .ooiiiiiiiiiiiiiiio .oo  20 .00  40 .oo82x l~ 3(a) (b)Figure 4.
4-gram matching score distributions, 8 2 , for (a) hand aligned and (b) randomly alignedblocks.counts were computed for both the hand-aligned andrandom alignment blocks.
Figure 4 shows the result-ing distributions.
The results suggest hat, on thewhole, the use of n-gram methods hould be consid-ered for improving alignments that contain lexicallysimilar cognates.
Being unordered comparisons, how-ever, they cannot exploit any intrinsic sequencing oflexical elements.5.3 Ordered String Comparisons, 8 3The value of unordered comparisons like the n-grammatching may be enhanced by ordered comparisons.An ordered comparison can reduce the noise associ-ated with matching unrelated n-grams at oppositeends of parallel alignment blocks.
We chose to evalu-ate a simple string-matching scheme as a possiblemethod for improving alignment performance.
Thescheme compares the two alignment blocks character-by-character, skipping over sections in one block thatdo not match in the opposite, thus primarily penaliz-ing the inclusion of dissimilar text segments in eitherblock.
The resulting sum of the matches is scaled bythe sum of the lengths of the two blocks.
In compari-son with the random block scoring, the distribution ofthe hand aligned data set had a greater number ofmatches with high string-match scores.5.4 Number Matching, 8 4The PAHO texts are distinguished by a number of tex-tual features, especially the fact that they are all insome way related to Latin American health issues.The preponderance of the documents are technicalreports on epidemiology, proceedings from meetingsand conferences, and compendiums of resources andcitations.
Within these documents, numbers occurregularly.
The string-matching technique suggestedthat if a class of lexical distinction could be matcheddirectly, the alignments might be significantlyimproved.
Numbers are sufficiently general that wefelt we were not violating the spirit of the restrictionon generality by using a number-matching scheme.For each alignment block pair, the number match-ing algorithm extracted all numbers.
The total numberof exact matches between the number sets from eachalignment block was then normalized by the sizes ofboth sets of numbers.
This approach as several draw-backs, such as the differences in the format of num-bers between Spanish and English.
In Spanish, forexample, commas are used instead of decimal points.These distinctions were ignored, however, to preservethe generality of the algorithm.
This generality willpotentially extend to other languages, including Asi-atic languages, which tend to use Arabic numerals torepresent numbers.
The distributions of both the handand random block scoring both showed a substantialmass of very low scores.It should be noted that numbers are simply a specialcase of cognates and certainly contribute to the n-gram scores.
Adding in number matching strategiestherefore only enhances the n-gram results.5.5 Translation ResiduesDespite the fact that non-Spanish speakers can oftenachieve success at aligning English documents withSpanish texts, the added knowledge of someone withboth Spanish and English language understanding isan added benefit and should facilitate alignment.
Toevaluate the role of translation-based alignment scor-72Table 1.
Performance comparisons between byte-length ratio methods and the improved algorithm.Document 1Document 2Byte-length Ratio Method#HAND #FOUND #CORRECT281 196 65787 440 3Improved Method#HAND #FOUND #CORRECT281 222 138787 614 553ing, the Collins Spanish-English and English-Spanishbilingual dictionaries were used to produce a scoreequal to the residue from a translation attempt of theterms in potential aligning blocks.Given a set of English terms, e i, Spanish terms, sj,from two blocks, the translation operation, T(I), gen-erates aset of terms in the opposite language by stem-ming each term and retrieving the terms that thestemmed word translates to in Collins.
The residue, R,is then a penalty equal to the (normalized) number ofterms in each translation set that do not have a matchin the opposite translation set:R =1 EkllZ?lPc tgllZUT(lk) UlkUIn comparison test, the distributions of scoresbetween random Spanish blocks and English blocks,and between the hand-aligned sets, were surprisinglysimilar, making a statistical discrimination of properalignments difficult.
We believe that dictionary-baseddiscrimination performs poorly primarily due to thenoisy nature of the dictionary we used.
It was initiallythought hat subsenses and usage patterns for eachterm would be an aid to discrimination by providing astronger basis for matches between true parallelblocks.
The added terms beyond the critical primarysense in the dictionary had high hit rates with usageterms throughout the dictionary.
The result was anoisy translation set that robbed the residue measureof discriminatory power.
The results discouraged usfrom including the R measure in the error function forthe dynamic programming system, although we sus-pect that improved dictionaries may ultimately pro-vide better discrimination.
It may also be possible toapply a kill list to the dictionary to reduce the numberof high frequency terms in each definition, increasingthe relevancy of the overall residue measure.6 ImplementationThe fact that our formulation of the alignment proba-bility for two blocks is dependent on both the positiveand negative information about the alignment proba-bility means that the probability density functions canbe used directly in the algorithm.
Specifically, the dis-tributions hown in Figures 3 and 4, as well as the dis-tributions for ordered string comparisons and numbercomparisons, were loaded into the algorithm as histo-grams.
During the dynamic programming operation,probability scores were determined by direct look-upof the 8 scores in the appropriate histogram, withsome weighted averaging performed for valuesbetween the boundaries of the histogram bars forsmoothing.
This approach eliminated the necessity ofestimating a distribution function for the rather non-Gaussian functions that are assumed to underlay theexperimental data.
Using this approach, the byte-length ratios could be simplified by not assuming aGaussian-like distribution and directly using the his-tograms of byte-length probabilities.
For comparison,however, we chose to use the Gale and Church deriva-tion without modifying 81 .7 PerformanceTable 1 shows the performance of the original align-ment algorithm compared to the improved algorithm.The results are for two documents.
#HAND is thenumber of alignment blocks found in the hand alignedset.
#FOUND is the number of alignment blocksfound by the algorithms.
Values of #FOUND lowerthan the value of #HAND indicates that alignmentblocks that contain multiple segments have beenfound by the algorithm (e.g., a 3-3 match has sup-planted three 1-1 matches).
#CORRECT is the num-ber of the found blocks which exactly match blocks inthe hand aligned set.
Note that the number of exactmatches is a conservative estimate of the number of73acceptable alignments, as different ranslators may,for example, differ about whether a 2-2 match cantake the place of two 1-1 matches and still be consid-ered aligned.In general, the performance of the improved align-ment algorithm was very good, improving the hitrates from 23% to 49% on Document 1 and from0.00381% to 70% on Document 2.
The abysmal per-formance of the byte-length method on Document 2can be attributed to the massive amounts of headerinformation, significant added whitespace and incon-sistent able and list formats that occurred in one doc-ument but not the other.
The algorithm encounteredonly 1 hit (the document start) in the first quarter ofthe document.
The training texts for these runs werethe texts themselves, and therefore the results must bereviewed with care.
The statistics of just two docu-ments, applied directly to those two documents forevaluation does not necessarily provide a direct esti-mate of the same statistics to a broader spectrum ofdocuments.8 ConclusionsIn the real world, poor-quality translations are com-mon due to the preferences of individual translators,lack of formal format guidelines for translations andoutright mistakes.
Our method combines four featurescores into a simple measure of the probability of twotextual segments aligning.
The algorithm is fairlygeneral in that all of the feature scores used are moreor less applicable to a wide range of Spanish andEnglish translations and are also applicable to adegree to other European languages.
It is furtherlikely that the methods we used can improve align-ments between many non-European languages byexploiting the increasingly common English phrasesand Arabic number occurrences in professional andpublic communications throughout the world.Our alignment algorithm presents a new formula-tion of Bayesian methods combined with a directapproach to data fusion for multiple sources of infor-mation.
This approach should work well with a widerange of data sources, including direct comparisons ofco-occurrence probabilities for specific lasses of lex-ical elements.ReferencesCATIZONE, ROBERTA, GRAHAM RUSSELL &SUSAN WARWICK.
1989.
Deriving Translation Datafrom Bilingual Texts.
In Proceedings of the FirstInternational Acquisition Workshop, Detroit, MI.CHEN, STANLEY F. 1993.
Aligning Sentences inBilingual Corpora Using Lexical Information.
In Pro-ceedings of the 31st Annual Conference of the Associ-ation of Computational Linguistics, 9-16, Columbus,OH.CHURCH, KENNETH W. 1993.
Char-align: A Pro-gram for Aligning Parallel Texts at the CharacterLevel.
In Proceedings of the 31st Annual Conferenceof the Association of Computational Linguistics, 1-8,Columbus, OH.DAVIS, MARK W. & TED E. DUNNING.
1995.Query TransLation using Evolutionary Programmingfor Multi-lingual Information Retrieval.
To appear inProceedings of the Fourth Annual Conference onEvolutionary Programming, San Diego, CA.DUNNING, TED E. & MARK W. DAVIS.
1993a.
ASingle Language Evaluation of a Multi-Lingual TextRetrieval System.
NIST Special Publication 500-207.
"The First Text Retrieval Conference (TREC-1), D.K.Harman, Ed., Computer Systems Laboratory, NIST.DUNNING, TED E. & MARK W. DAVIS.
1993b.Multi-Lingual Information Retrieval.
Memoranda inComputer and Cognitive Science, MCCS-93-252,Computing Research Laboratory, New Mexico StateUniversity.GALE, WILLIAM m. & KENNETH W. CHURCH.1991.
A Program for Aligning Sentences in BilingualCorpora.
In Proceedings of the 29th Annual Confer-ence of the Association of Computational Linguistics,177-184, Berkeley, CA.OGDEN, WILLIAM C. 1993.
Norm - A System forTranslators.
Demonstration at ARPA Workshop onHuman Language Technology, Merill-Lynch Confer-ence Center, Plainsboro, NJ.SIMARD, M., G. FOSTER & P. ISABELLE.
1992.Using Cognates to Align Sentences in Bilingual Cor-pora.
Fourth International Conference on Theoreticaland Methodological Issues in Machine Translation.Montreal Canada.WU, DEKAI.
1994.
Aligning a Parallel English-Chi-nese Corpus Statistically with Lexical Criteria.
InProceedings of the 32nd Annual Conference of theAssociation for Computational Linguistics, 80-87,Las Cruces, NM.74
