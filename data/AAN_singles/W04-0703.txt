Event Clustering on Streaming NewsUsing Co-Reference Chains and Event WordsJune-Jei KuoDepartment of Computer Science andInformation EngineeringNational Taiwan University, Taipei, Taiwanjjkuo@nlg.csie.ntu.edu.twHsin-Hsi ChenDepartment of Computer Science andInformation EngineeringNational Taiwan University, Taipei, Taiwanhh_chen@csie.ntu.edu.twAbstractEvent clustering on streaming news aims togroup documents by events automatically.This paper employs co-reference chains toextract the most representative sentences, andthen uses them to select the most informativefeatures for clustering.
Due to the long spanof events, a fixed threshold approach prohibitsthe latter documents to be clustered and thusdecreases the performance.
A dynamicthreshold using time decay function andspanning window is proposed.
Besides thenoun phrases in co-reference chains, eventwords in each sentence are also introduced toimprove the related performance.
Two modelsare proposed.
The experimental results showthat both event words and co-reference chainsare useful on event clustering.1 IntroductionNews, which is an important information source,is reported anytime and anywhere, and isdisseminated across geographic barriers throughInternet.
Detecting the occurrences of new eventsand tracking the processes of the events (Allan,Carbonell, and Yamron, 2002) are useful fordecision-making in this fast-changing network era.Event clustering automatically groups documentsby events that are specified in the documents in atemporal order.
The research issues behind eventclustering include: how many features can be usedto determine event clusters, which cue patterns canbe employed to relate news stories in the sameevent, how the clustering strategies affect theclustering performance using retrospective data oron-line data, how the time factor affects clusteringperformance, and how multilingual data isclustered.Chen and Ku (2002) considered named entities,other nouns and verbs as cue patterns to relatenews stories describing the same event.
Acentroid-based approach with a two-thresholdscheme determines relevance (irrelevance)between a news story and a topic cluster.
A least-recently-used removal strategy models the timefactor in such a way that older and unimportantterms will have no effect on clustering.
Chen, Kuoand Su (2003) touched on event clustering inmultilingual multi-document summarization.
Theyshowed that translation after clustering is betterthan translation before clustering, and translationdeferred to sentence clustering, which reduces thepropagation of translation errors, is most promising.Fukumoto and Suzuki (2000) proposed conceptsof topic words and event words for event tracking.They introduced more semantic approach forfeature selection than the approach of parts ofspeech.
Wong, Kuo and Chen (2001) employedthese concepts to select informative words forheadline generation, and to rank the extractedsentences in multi-document summarization (Kuo,Wong, Lin, and Chen, 2002).Bagga and Baldwin (1998) proposed entity-based cross-document co-referencing which usesco-reference chains of each document to generateits summary and then use the summary rather thanthe whole article to select informative words to bethe features of the document.
Azzam, Humphreys,and Gaizauskas (1999) proposed a primitive modelfor text summarization using co-reference chainsas well.
Silber and McCoy (2002) proposed a textsummarization model using lexical chains andshowed that proper nouns and anaphora resolutionis indispensable.The two semantics-based feature selectionapproaches, i.e., co-reference chains and eventwords, are complementary in some sense.
Theformer denotes equivalence classes of nounphrases, and the latter considers both nominal andverbal features, which appear across paragraphs.This paper will employ both co-reference chainsand event words for temporal event clustering.
Anevent clustering system using co-reference chainsis described in Section 2.
The evaluation methodand the related experimental results are describedin Section 3.
The event words are introduced anddiscussed in Section 4.
Section 5 proposes asummation model and a two-level model,respectively for event clustering using both co-reference chains and event words.
Section 6concludes the remarks.2 Event Clustering using Co-ReferenceChainsA co-reference chain in a document denotes anequivalence class of noun phrases.
(Cardie andWagstaff, 1999)  A co-reference resolutionprocedure is first to find all the possible NPcandidates.
It includes word segmentation, namedentity extraction, part of speech tagging, and nounphrase chunking.
Then the candidates arepartitioned into equivalence classes using theattributes such as word/phrase itself, parts ofspeech of head nouns, named entities, positions ina document, numbers (singular, plural, orunknown), pronouns, gender (female, male, orunknown), and semantics of head nouns.
As thebest F-measure of automatic co-referenceresolution in English documents in MUC-7 was61.8% (MUC, 1998), a corpus hand-tagged withnamed entities, and co-reference chains areprepared and employed to examine the real effectsof co-reference chains in event clustering r.Headlines of a news story can be regarded as itsshort summary.
That is, the words in the headlinerepresent the content of a document in some sense.The co-reference chains that are initiated by thewords in the headlines are assumed to have higherweights.
A sentence which contains any words ina given co-reference chain is said to ?cover?
thatchain.
Those sentences which cover more co-reference chains contain more information, and areselected to represent a document.
Each sentence ina document is ranked according to the number ofco-reference chains that it covers.
Five scoresshown below are computed.
Sentences are sortedby the five scores in sequence and the sentences ofthe highest score are selected.
The selectionprocedure is repeated until the designated numberof sentences, e.g., 4 in this paper, is obtained.
(1) For each sentence that is not selected, countthe number of noun co-reference chains fromthe headline, which are covered by thissentence and have not been covered by thepreviously selected sentences.
(2) For each sentence that is not selected, countthe number of noun co-reference chains fromthe headline, which are covered by thissentence, and add the count to the number ofverbal terms in this sentence which also appearin the headline.
(3) For each sentence that is not selected, countthe number of noun co-reference chains, whichare covered by this sentence and have not beencovered by the previously selected sentences.
(4) For each sentence that is not selected, countthe number of noun co-reference chains, whichare covered by this sentence, and add the countto the number of verbal terms in this sentencewhich also appear in the headline.
(5) The position of a sentenceScore 1 only considers nominal features.Comparatively, Score 2 considers both nominaland verbal features together.
Both scores areinitiated by headlines.
Scores 3 and 4 consider allthe co-reference chains no matter whether thesechains are initiated by headlines or not.
These twoscores ranks those sentences of the same scores 1and 2.
Besides, they can assign scores to newsstories without headlines.
Scores 1 and 3 arerecomputed in the iteration.
Finally, since newsstories tend to contain more information in theleading paragraphs, Score 5 determines whichsentence will be selected according to position ofsentences, when sentences are of the same scores(1)-(4).
The smaller the position number of asentence is, the more it will be preferred.The sentences extracted from a document form asummary for this document.
It is in terms of aterm vector with weights defined below.
It is anormalized TF-IDF.22221loginiijijijsssdfNtfw +??
?++?=   (1)where tfij is frequency of term tj in summary i, Nis total number of summaries in thecollection being examined, dfj is numberof summaries that term tj occurs, and sijdenotes the TF-IDF value of term tj insummary i.A single-pass complete link clustering algorithmincrementally divides the documents into severalevent clusters.
We compute the similarities of thesummary of an incoming news story with eachsummary in a cluster.
Let V1 and V2 be the vectorsfor the two summaries extracted from documentsD1 and D2.
The similarity between V1 and V2 iscomputed as follows.??
?==?=mj jnj jcommonjjwwwwVVSim122121t term2121j),(  (2)If all the similarities are larger than a fixedthreshold, the news story is assigned to the cluster.Otherwise, it forms a new cluster itself.
Life spanis a typical phenomenon for an event.
It may bevery long.
Figure 1 shows the life span of an aircrash event is more than 100 days.
To tackle thelong life span of an event, a dynamic threshold(d_th) shown below is introduced, where th is aninitial threshold.
In other words, the earlier thedocuments are put in a cluster, the smaller theirthresholds are.
Assume the published day ofdocument D2 is later than that of document D1.th)/w_sizedist(D)/w_sizedist(DDDthd ?++=11),(_2121  (3)where dist (day distance) denotes the number ofdays away from the day at which theevent happens, and w_size (window size)keeps the threshold unchanged within thesame window.Moreover, we use square root function toprevent the dynamic threshold from downgradingtoo fast.3 Test CollectionIn our experiment, we used the knowledge baseprovided by the United Daily News(http://udndata.com/), which has collected6,270,000 Chinese news articles from 6 Taiwanlocal newspaper companies since 1975/1/1.
Toprepare a test corpus, we first set the topic to be??????
(Air Accident of China Airlines),and the range of searching date from 2002/5/26 to2002/9/4 (stopping all rescue activities).
Total 964related news articles, which have published date,news source, headline and content, respectively,are returned from search engine.
All are in SGMLformat.
After reading those news articles, wedeleted 5 news articles which have headlines butwithout any content.
The average length of a newsarticle is 15.6 sentences.
Figure 1 depicts thedistribution of the document number within theevent life span, where the x-axis denotes the dayfrom the start of the year.
For example, ?146?denotes the day of ?2002/5/26?, which is the 146thday of year 2002.Then, we identify thirteen focus events, e.g.,rescue status.
Meanwhile, two annotators areasked to read all the 959 news articles and classifythese articles into 13 events.
If a news article cannot be classified, the article is marked as ?other?type.
A news article which reports more than oneevent may be classified into more than one eventcluster.
We compare the classification results ofannotators and consider those consistent results asour answer set.
Table 1 shows the distribution ofthe 13 focus events.Event Name Number ofDocumentsFly right negotiation betweenTaiwan and Hong Kong20Cause of air accident 57Confirmation of air accident 6Influence on stock market 27Influence on insurance fee 11Influence on China Airline 8Influence on Peng-Huarchipelagoes26Punishment for persons in charge 10News reporting 18Wreckage found 28Remains found 57Rescue status 65Solatium 34Other 664Table 1: Focus EventsWe adopt the metric used in Topic Detectionand Tracking (Fiscus and Doddington, 2002).
Theevaluation is based on miss and false alarm rates.Both miss and false alarm are penalties.
They can020406080100120140160145 155 165 175 185 195 205 215 225 235 245Daynumberofdocs/ dayFigure 1.
Event Evolution of China Airlines Air Accident (2002/5/26 ~ 2002/9/4)measure more accurately the behavior of users whotry to retrieve news stories.
If miss or false alarmis too high, users will not be satisfied with theclustering results.
The performance ischaracterized by a detection cost, , in terms ofthe probability of miss and false alarm:detCettnonFAFAettMissMissDet PPCPPCC argarg ???+?
?= (4)where  and  are costs of a miss and afalse alarm, respectively,  andare the conditional probabilities of a missand a false alarm, and  andMissC FACMissP FAPettP arg( )ettettnon PP argarg 1?=?
are the prior targetprobabilities.Manmatha, Feng and Allan (2002) indicated thatthe standard TDT cost function used for allevaluations in TDT is C ,when CFAMiss PP 098.002.0det +=Miss, CFA and Ptarget are set to 1, 0.1 and 0.02,respectively.
The less the detection cost is, thehigher the performance is.For comparison, the centroid-based approachand single pass clustering is regarded as a baselinemodel.
Conventional TF-IDF scheme selects 20features for each incoming news articles and eachcluster uses 30 features to be its centroid.Whenever an article is assigned to a cluster, the 30words of the higher TF-IDFs are regarded as thenew centroid of that cluster.
The experimentalresults with various thresholds are shown in Table2.
The best result is 0.012990 when the thresholdis set to 0.05.Fixed Threshold Cdet0.01 0.0246440.05 0.0129900.10 0.0137360.15 0.0143310.20 0.0154800.25 0.015962Table 2: Detection Costs Using Centroid ApproachKuo, Wong, Lin and Chen (2002) indicated thatnear 26% of compression rate is suitable for anormal reader in multi-document summarization.Recall that the average length of a news story is15.6 sentences.
Following their postulation, total 4sentences, i.e., 16/4, are selected using co-reference chains.
Table 3 shows the detection costwith various threshold settings.
We found that thebest result could be obtained using threshold 0.05,however, it was lower than the result of baseline(i.e., 0.013137 > 0.012990).Next, we study the effects of dynamic thresholds.Three dynamic threshold functions areexperimented under the window size 1.
A lineardecay approach removes the square root functionin Formula (3).
A slow decay approach adds aconstant (0.05) to Formula (3) to keep theminimum threshold to be 0.05 and degrades thethreshold slowly.
Table 4 shows that Formula (3)obtained the best result, and the dynamic thresholdapproach is better than the baseline model.Fixed Threshold Cdet0.01 0.0159600.05 0.0131370.10 0.0153090.15 0.0165070.20 0.0167360.25 0.017360Table 3.
Detection Costs Using Co-ReferenceChainsFunctionTypeLineardecayingFormula(3)SlowDecayingCdet 0.013196 0.012657 0.016344Table 4.
Detection Costs with Various DynamicThreshold Functions (Initial Threshold = 0.05)Additionally, we evaluate the effect of thewindow size.
Table 5 shows the results usingvarious window sizes in Formula (3).
The bestdetection cost, i.e., 0.012647, is achieved underwindow size 2.
It also shows the efficiency ofdynamic threshold and window size.Windowsize1 2 3 4Cdet 0.012657 0.012647 0.012809 0.012942Table 5.
Detection Costs with Various WindowSizes Using Formula (3) (Initial Threshold = 0.05)4 Event Clustering Using Event WordsThe co-reference chains in the above approachconsidered those features, such as person name,organization name, location, temporal expressionand number expression.
However, the importantwords ?black box?
or ?rescue?
in an air crash eventare never shown in any co-reference chain.
Thissection introduces the concepts of event words.Topic and event words were applied to topictracking successfully (Fukumoto and Suzuki,2000).
The basic hypothesis is that an event wordassociated with a news article appears acrossparagraphs, but a topic word does not.
In contrast,a topic word frequently appears across all newsdocuments.
Because the goal of event clustering isto extract all the events associated with a topic,those documents belonging to the same topic, e.g.,China Airlines Air Accident, always have thesimilar topic words like ?China Airlines?, ?flight611?, ?air accident?, ?Pen-Hu?, ?Taiwan strait?,?rescue boats?, etc.
Topic words seem to have nohelp in event clustering.
Comparatively, eachnews article has different event words, e.g.,?emergency command center?, ?set up?,?17:10PM?, ?CKS airport?, ?Commander Lin?,?stock market?, ?body recovery?, and so on.Extracting such keywords is useful to understandthe events, and distinguish one document fromanother.The postulation by Fukumoto and Suzuki (2002)is that the domain dependency among words is akey clue to distinguish a topic and an event.
Thiscan be captured by dispersion value and deviationvalue.
The former tells if a word appears acrossparagraphs (documents), and the latter tells if aword appears frequently.
Event words areextracted by using these two values.
Formula (5)defines a weight of term t in the i-th story.tijjitit NsNTFsMaxTFsWs log)(?=    (5)where TFsit denotes term frequency of term t inthe i-th story, N is total number of stories,and Nst is the number of stories whereterm t occurs.Besides term weight in story level, Wpit definesa weight of term t in the i-th paragraph.
Formulas(6) and (7) define dispersion value and deviationvalue, respectively.mmeanWsDispSmi titt?= ?= 1 2)(    (6)??
+?
?=ttitit DispSmeanWsDevS )(    (7)Where, meant is average weight of term t instory level.
Similarly, DispPt and DevPjt aredefined in the paragraph level.
The dispersionvalue of term t in the story level denotes howfrequently term t appears across m stories.
Thedeviation value of term t in the i-th story denoteshow frequently it appears in a particular story.Coefficients ?
and ?
are used to adjust the numberof event words.
In our experiments, 20 eventwords are extracted for each document.
In such acase, (?, ?)
is set to (10, 50) in story level and setto (10, 25) in paragraph level, respectively.Formula (8) shows that term t frequently appearsacross paragraphs rather than stories.
Formula (9)shows that term t frequently appears in the i-thstory rather than paragraph Pj.
An event word isextracted if it satisfies both formulas (8) and (9).tt DispSDispP <    (8)ijj S Psuch that  P allfor                   ?< itjt DevSDevP  (9)Below shows the event clustering using eventwords only.
At first, we extract the event words ofeach news article using the whole news collection.For each sentence, we then compute the number ofevent words in it.
After sorting all sentences, thedesignated number of sentences are extractedaccording to their number of event words.
In theexperiments, we use different window sizes tostudy the change of detection cost after introducingevent words.
Table 6 shows the experimentalresults under the same threshold (0.005) and testcollection mentioned in Section 3.Windowsize1 2 3 4Cdet 0.011918 0.011842 0.011747 0.011923Table 6.
Detection Costs with Event Words andVarious Window SizesThe results in Table 6 are much better than thosein Table 5, because inclusion of event wordsselects more informative or representativesentences or paragraphs.
The more informativefeature words documents have, the moreeffectively documents of one event can bedistinguished from those of another.
In otherwords, the similarities of documents amongdifferent events become smaller, so that thedocuments cannot be assigned to the same clustereasily under the higher threshold, and the bestperformance is shifted from window size 2 towindow size 3.5 Event Clustering Using Both Co-referenceChains and Event WordsAccording to the above experimental results, it isevident that either co-reference chains or eventwords are useful for event clustering on streamingnews.
As co-reference chains and event words arecomplementary in some sense, we further examinethe effect on event clustering using both of them.Thus, two models called summation model andtwo-level model, respectively, are proposed.
Thesummation model is used to observe thesummation effect using both the co-referencechains and the event words on event clustering.On the other hand, the two-level model is used toobserve the interaction between co-referencechains and event words.5.1 Summation ModelIn summation model, we simply add the scoresfor both co-reference chains and event words,which are described above respectively to be thescore for each sentence in the news document.
Atfirst, we extract the event words of each newsarticle using the whole news collection describedin Section 3.
For each sentence, we then computethe number of event words in it, and add this countto the number of co-reference chains it covers.
Theiterative procedure specified in Section 2 extractsthe designated number of sentences according tothe number of event words and co-reference chains.Table 7 summarizes the experimental resultsunder the same test collection mentioned inSection 3.
The experiments of summation modelshow that the best detection cost is 0.011603.Comparing the best result with those in Tables 5and 6, the detection costs are decreased 9% and 2%,respectively.Windowsize1 2 3 4Cdet 0.112233 0.011603 0.013109 0.013109Table 7.
Detection Costs Using Summation Model5.2 Two-level modelBy comparing the experimental results describedin Section 3 and 4, we noticed that the event wordfactor seems more important than the co-referencefactor on event clustering of news document.Moreover, from the summation model we onlyknow that both factors are useful on eventclustering.
In order to make clear which factor ismore important during event clustering of newsdocuments, a two-level model is designed in such away that the co-reference chains or the event wordsare used separately rather than simultaneously.
Forexample, we use the score function and thesentence selection algorithm described in Section 3first, when there is a tie during sentence selection.Then we use the score function described inSection 4 to decide which sentence is selected fromthose candidate sentences, and vice versa.
Thus,two alternatives are considered.
Type 1 modeluses the event words sentence selection algorithmdescribed in Section 4 to select the representativesentences from each document, the co-referencechains are used to solve the tie issue.
In contrast,type 2 model uses the co-reference chains sentenceselection algorithm described in Section 3 to selectthe representative sentences for each documentsand use event words to solve the tie issue.
Table 8shows the experimental result under the same testcollection as described in previous sections.Windowsize2 3 4 5Type 1 0.012116 0.011987 0.011662 0.012266Type 2 0.012789 0.012674 0.012854 0.012941Table 8.
Detection Costs Using Two level ModelsThe performance of type 1 outperforms that oftype 2.
This result conforms to those shown inTable 5 and Table 6.
We can say that the effect ofevent words is better than the co-reference chainsin event clustering.
Furthermore, the best score oftype 1 is also better than the best score of Table 6.Thus, the introduction of co-reference chains canreally improve the performance of event clusteringusing event words.
On the other hand, theintroduction of event words in type 2 does not havesuch an effect.
Moreover, to further examine theuse of co-reference chain information and theevent words in event clustering, a more elaboratecombination, e.g., using mutual information orentropy, of the two approaches is needed.6 Concluding RemarksThis paper presented an approach for eventclustering on streaming news based on both co-reference chains and event words.
Theexperimental results using event words onlyoutperform the results using the co-referencechains only.
Nevertheless, as to the combinationof co-reference chains and event words in eventclustering, the experimental results show that theintroduction of co-reference chains can improvethe performance of event clustering using eventwords much.
To model the temporal behavior ofevent clustering of streaming news, a dynamicthreshold setting using time decay function andspanning window size is proposed.
Theexperimental results, using TDT?s evaluationmetric ?
say, detection cost, show that the dynamicthreshold is useful.
.We believe that the improvement of multi-document co-reference resolution will have greatimpact on temporal event clustering.
In order tofurther improve our performance in even clusteringon streaming news, there are still future worksneeded to be studied:(1) In order to verify the significance of theexperimental results, statistical test is needed.
(2) Instead of hand-tagging method, we willintroduce automatic co-reference resolutiontools to create large scale test corpus andconduct large scale experiments.
(3) When the length of document is variable, thefixed number of representative sentences maylose many important sentences to degrade theperformance of event clustering.
The dynamicnumber of representative sentences for eachdocument according to its length is introduced.
(4) As the news stories are reported incrementallyinstead of being given totally in the on-lineevent clustering, the computation of eventwords is an important issue.
(5) Apply the extracted sentences for eachdocument to generate event-based shortsummary.ReferencesAllan, James; Carbonell, Jaime; and Yamron,Jonathan (Eds) (2002) Topic Detection andTracking: Event-Based Information Organization,Kluwer.Azzam, S.; Humphreys, K; and Gaizauskas, R.(1999) ?Using Coreference Chains for TextSummarization,?
Proceedings of the ACLWorkshop on Coreference and Its Applications,Maryland.Bagga, A. and Baldwin, B.
(1998) ?Entity-BasedCross-Document Coreferencing Using theVector Space Model,?
Proceedings of the 36thAnnual Meeting of ACL and the 17thInternational Conference on ComputationalLinguistics.Cardie, Claire and Wagstaff, Kiri (1999) ?NounPhrase Co-reference as Clustering,?
Proceedingof the Joint Coreference on EMNLP and VLCChen, Hsin-Hsi and Ku, Lun-Wei (2002) ?An NLP& IR Approach to Topic Detection,?
TopicDetection and Tracking: Event-BasedInformation Organization, James Allan, JaimeCarbonell, and Jonathan Yamron (Editors),Kluwer, pp.
243-264.Chen, Hsin-Hsi; Kuo, June-Jei and Su, Tsei-Chun(2003) ?Clustering and Visualization in a Multi-Lingual Multi-Document SummarizationSystem,?
Proceedings of 25th EuropeanConference on Information Retrieval Research,Lecture Notes in Computer Science, LNCS 2633,pp.
266-280.Fiscus, Jonathan G. and Doddington, George R.(2002) ?Topic Detection and TrackingEvaluation Overview,?
Topic Detection andTracking: Event-Based Information Organization,James Allan, Jaime Carbonell, and JonathanYamron (Eds), Kluwer, pp.
17-32.Fukumoto, F. and Suzuki, Y.
(2000) ?EventTracking based on Domain Dependency,?Proceedings of the 23rd ACM SIGIR 2000Conference, pp.
57-64Kuo, June-Jei; Wong, Hung-Chia; Lin, Chuan-Jieand Chen, Hsin-Hsi (2002) ?Multi-DocumentSummarization Using Informative Words and ItsEvaluation with a QA System,?
Proceedings ofThe Third International Conference onIntelligent Text Processing and ComputationalLinguistics, Lecture Notes in Computer Science,LNCS 2276, pp.
391-401.Manmatha, R.; Feng, A. and Allan, James (2002)?A Critical Examination of TDT?s CostFunction,?
Proceedings of the 25th ACM SIGIRConference, pp.
403-404.MUC (1998) Proceedings of 7th MessageUnderstanding Conference, Fairfax, VA, 29April - 1 May, 1998,http://www.itl.nist.gov/iaui/894.02/related_projects/muc/ index.html.Silber, H. Gregory and McCoy, Kathleen F. (2002)?Eficiently Computed Lexical Chains As anIntermediate Representation for Automatic TextSummarization.?
Journal of Association forComputational Linguistics, Vol.28, No.4, pp.487-496.Wong, Hong-Jia; Kuo, June-Jei and Chen, Hsin-Hsi (2001) ?Headline Generation for Summariesfrom Multiple Online Sources.?
Proceedings of6th Natural Language Processing Pacific RimSymposium, November 27-29 2001, Tokyo,Japan, pp.
653-660.
