Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 189?192,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsMapping between Compositional Semantic Representations and LexicalSemantic Resources: Towards Accurate Deep Semantic ParsingSergio Roa?
?, Valia Kordoni?
and Yi Zhang?Dept.
of Computational Linguistics, Saarland University, Germany?German Research Center for Artificial Intelligence (DFKI GmbH)?Dept.
of Computer Science, University of Freiburg, Germany?
{sergior,kordoni,yzhang}@coli.uni-sb.deAbstractThis paper introduces a machine learningmethod based on bayesian networks whichis applied to the mapping between deep se-mantic representations and lexical semanticresources.
A probabilistic model comprisingMinimal Recursion Semantics (MRS) struc-tures and lexicalist oriented semantic featuresis acquired.
Lexical semantic roles enrich-ing the MRS structures are inferred, which areuseful to improve the accuracy of deep seman-tic parsing.
Verb classes inference was alsoinvestigated, which, together with lexical se-mantic information provided by VerbNet andPropBank resources, can be substantially ben-eficial to the parse disambiguation task.1 IntroductionRecent studies of natural language parsing haveshown a clear and steady shift of focus from puresyntactic analyses to more semantically informedstructures.
As a result, we have seen an emerginginterest in parser evaluation based on more theory-neutral and semantically informed representations,such as dependency structures.
Some approacheshave even tried to acquire semantic representationswithout full syntactic analyses.
The so-called shal-low semantic parsers build basic predicate-argumentstructures or label semantic roles that reveal the par-tial meaning of sentences (Carreras and Ma`rquez,2005).
Manually annotated lexical semantic re-sources like PropBank (Palmer et al, 2005), Verb-Net (Kipper-Schuler, 2005), or FrameNet (Baker etal., 1998) are usually used as gold standards fortraining and evaluation of such systems.
In themeantime, various existing parsing systems are alsoadapted to provide semantic information in their out-puts.
The obvious advantage in such an approachis that one can derive more fine-grained represen-tations which are not typically available from shal-low semantic parsers (e.g., modality and negation,quantifiers and scopes, etc.).
To this effect, var-ious semantic representations have been proposedand used in different parsing systems.
Generallyspeaking, such semantic representations should becapable of embedding shallow semantic information(i.e., predicate-argument or semantic roles).
How-ever, it is non-trivial to map even the basic predicate-arguments between different representations.
Thisbecomes a barrier to both sides, making the cross-fertilization of systems and resources using differentsemantic representations very difficult.In this paper, we present a machine learning ap-proach towards mapping between deep and shallowsemantic representations.
More specifically, we useBayesian networks to acquire a statistical model thatenriches the Minimal Recursion Semantics struc-tures produced by the English Resource Grammar(ERG) (Flickinger, 2002) with VerbNet-like seman-tic roles.
Evaluation results show that the mappingfrom MRS to semantic roles is reliable and benefi-cial to deep parsing.2 Minimal Recursion SemanticsThe semantic representation we are interested inin this paper is the Minimal Recursion Semantics(MRS).
Because of its underspecifiability, it hasbeen widely used in many deep and shallow pro-cessing systems.
The main assumption behind MRSis that the interesting linguistic units for compu-tational semantics are the elementary predications(EPs), which are single relations with associated ar-guments (Copestake et al, 2006).
In this paper,the MRS structures are created with the English Re-source Grammar (ERG), a HPSG-based broad cov-erage precision grammar for English.
The seman-189tic predicates and their linguistic behaviour (includ-ing the set of semantic roles, indication of optionalarguments, and their possible value constraints arespecified by the grammar as its semantic interface(SEM-I) (Flickinger et al, 2005).3 Relating MRS structures to lexicalsemantic resources3.1 Feature extraction from linguistic resourcesThe first set of features used to find correspondinglexical semantic roles for the MRS predicate argu-ments are taken from Robust MRS (RMRS) struc-tures (Copestake, 2006).
The general idea of theprocess is to traverse the bag of elementary predi-cations looking for the verbs in the parsed sentence.When a verb is found, then its arguments are takenfrom the rarg tags and alternatively from the in-gconjunctions related to the verb.
So, given the sen-tence:(1) Yields on money-market mutual funds contin-ued to slide, amid signs that portfolio managersexpect further declines in interest rates.the obtained features for expect are shown in Table1.SEM-I roles Features WordsARG1 manager n of managersARG2 propositional m rel further declinesTable 1: RMRS features for the verb expectThe SEM-I role labels are based mainly on syn-tactic characteristics of the verb.
We employedthe data provided by the PropBank and VerbNetprojects to extract lexical semantic information.
ForPropBank, the argument labels are named ARG1,...,ARGN and additionally ARGM for adjuncts.
In thecase of VerbNet, 31 different thematic roles are pro-vided, e.g.
Actor, Agent, Patient, Proposition, Predi-cate, Theme, Topic.
A treebank of RMRS structuresand derivations was generated by using the Prop-Bank corpus.
The process of RMRS feature extrac-tion was applied and a new verb dependency treesdataset was created.To obtain a correspondence between the SEM-Irole labels and the PropBank (or VerbNet) role la-bels, a procedure which maps these labellings foreach utterance and verb found in the corpus was im-plemented.
Due to the possible semantic roles thatsubjects and objects in a sentence could bear, themapping between SEM-I roles and VerbNet role la-bels is not one-to-one.
The general idea of this align-ment process is to use the words in a given utterancewhich are selected by a given role label, both a SEM-I and a PropBank one.
With these words, a naive as-sumption was applied that allows a reasonable com-parison and alignment of these two sources of infor-mation.
The naive assumption considers that if allthe words selected by some SEM-I label are found ina given PropBank (VerbNet) role label, then we candeduce that these labels can be aligned.
An impor-tant constraint is that all the SEM-I labels must beexhausted.
An additional constraint is that ARG1,ARG2 or ARG3 SEM-I labels cannot be mapped toARGM PropBank labels.
When an alignment be-tween a SEM-I role and a corresponding lexical se-mantic role is found, no more mappings for theselabels are allowed.
For instance, given the examplein Table 1, with the following Propbank (VerbNet)labelling:(2) [Arg0(Experiencer) Portfolio managers] expect[Arg1(Theme) further declines in interest rates.
]the alignment shown in Table 2 is obtained.SEM-I roles Mapped roles FeaturesARG1 Experiencer manager n ofARG2 Theme propositional m relTable 2: Alignment instance obtained for the verb expectSince the use of fine-grained features can makethe learning process very complex, the WordNetsemantic network (Fellbaum, 1998) was also em-ployed to obtain generalisations of nouns.
The al-gorithm described in (Pedersen et al, 2004) wasused to disambiguate the sense, given the headsof the verb arguments and the verb itself (by us-ing the mapping from VerbNet senses to WordNetverb senses (Kipper-Schuler, 2005)).
Alternatively,a naive model has also been proposed, in whichthese features are simply generalized as nouns.
Forprepositions, the ontology provided by the SEM-Iwas used.
Other words like adjectives or verbs inarguments were simply generalised as their corre-sponding type (e.g., adjectival rel or verbal rel).1903.2 Inference of semantic roles with BayesianNetworksThe inference of semantic roles is based on train-ing of BNs by presenting instances of the featuresextracted, during the learning process.
Thus, a train-ing example corresponding to the features shown inTable 2 might be represented as Figure 1 shows, us-ing a first-order approach.
After training, the net-work can infer a proper PropBank (VerbNet) seman-tic role, given some RMRS role corresponding tosome verb.
The use of some of these features canbe relaxed to test different alternatives.VerbNet classwish?62ARG1 ARG3ARG2propositional_m_relRMRS FeaturesARGMExperiencer nullThemepropositional_m_relPropBank/VerbNet Featuresnullthing_nliving_living_thing_nFigure 1: A priori structure of the BN for lexical semanticroles inference.Two algorithms are used to train the BNs.
TheMaximum Likelihood (ML) estimation procedure isused when the structure of the model is known.
Inour experiments, the a priori structure shown in Fig-ure 1 was employed.
In the case of the Structural Ex-pectation Maximization (SEM) Algorithm, the ini-tial structure assumed for the ML algorithm servesas an initial state for the network and then the learn-ing phase is executed in order to learn other con-ditional dependencies and parameters as well.
Thetraining procedure is described in Figure 2.procedure Train (Model)1: for all Verbs do2: for all Sentences and Parsings which include the current verbdo3: Initialize vertices of the network with SEM-I labels and fea-tures.4: Initialize optionally vertices with the corresponding VerbNetclass.5: Initialize edges connecting corresponding features.6: Append the current features as evidence for the network.7: end for8: Start Training Model for the current Verb, where Model is MLor SEM.9: end forFigure 2: Algorithm for training Bayesian Networks forinference of lexical semantic rolesAfter the training phase, a testing procedure usingthe Markov Chain Monte Carlo (MCMC) inferenceengine can be used to infer role labels.
Since it isreasonable to think that in some cases the VerbNetclass is not known, the presentation of this feature asevidence can be left as optional.
Thus, after present-ing as evidence the SEM-I related features, a rolelabel with highest probability is obtained after usingthe MCMC with the current evidence.4 Experimental resultsThe experiment uses 10370 sentences from thePropBank corpus which have a mapping to Verb-Net (Loper et al, 2007) and are successfully parsedby the ERG (December 2006 version).
Up to 10best parses are recorded for each sentence.
The to-tal number of instances, considering that each sen-tence contains zero or more verbs, is 13589.
Thealgorithm described in section 3.1 managed to findat least one mapping for 10960 of these instances(1020 different verb lexemes).
If the number of pars-ing results is increased to 25 the results are improved(1460 different verb lexemes were found).
In thesecond experiment, the sentences without VerbNetmappings were also included.The results for the probabilistic models for in-fering lexical semantic roles are shown in Table 3,where the term naive means that no WordNet fea-tures were included in the training of the models, butonly simple features like noun rel for nouns.
On thecontrary, when mode is complete, WordNet hyper-nyms up to the 5th level in the hierarchy were used.In this set of experiments the VerbNet class was alsoincluded (in the marked cases) during the learningand inference phases.Corpus Nr.
iter.
Mode Model Verb Accuracy %MCMC classesPropBank with 1000 ML naive 78.41VerbNet labels 10000 ML naive 84.4810000 ML naive ?
87.921000 ML complete 84.7410000 ML complete 86.7910000 ML complete ?
87.761000 SEM naive 84.251000 SEM complete 87.26PropBank with 1000 ML naive 87.46PropBank labels 1000 SEM naive 90.27Table 3: Results of role mapping with probabilistic modelIn Table 3, the errors are due to the problems in-troduced by the alternation behaviour of the verbs,which are not encoded in the SEM-I labelling and191also some contradictory annotations in the mappingbetween PropBank and VerbNet.
Furthermore, theuse of the WordNet features may also generate amore complex model or problems derived from thedisambiguation process and hence produce errors inthe inference phase.
In addition, it is reasonableto use the VerbNet class information in the learn-ing and inference phases, which in fact improvesslightly the results.
The outcomes also show thatthe use of the SEM algorithm improves accuracyslightly, meaning that the conditional dependencyassumptions were reasonable, but still not perfect.The model can be slightly modified for verb classinference, by adding conditional dependencies be-tween the VerbNet class and SEM-I features, whichcan potentially improve the parse disambiguationtask, in a similar way of thinking to (Fujita et al,2007).
For instance, for the following sentence, wederive an incorrect mapping for the verb stay to theVerbNet class EXIST-47.1-1 with the (falsely) fa-vored parse where the PP ?in one place?
is treated asan adjunct/modifier.
For the correct reading wherethe PP is a complement to stay, the mapping to thecorrect VerbNet class LODGE-46 is derived, and thecorrect LOCATION role is identified for the PP.
(3) Regardless of whether [Theme you] hike fromlodge to lodge or stayLODGE-46 [Location in oneplace] and take day trips, there are plenty ofchoices.5 Conclusions and Future WorkIn this paper, we have presented a study of mappingbetween the HPSG parser semantic outputs in formof MRS structures and lexical semantic resources.The experiment result shows that the Bayesian net-work reliably maps MRS predicate-argument struc-tures to semantic roles.
The automatic mapping en-ables us to enrich the deep parser output with seman-tic role information.
Preliminary experiments havealso shown that verb class inference can potentiallyimprove the parse disambiguation task.
Althoughwe have been focusing on improving the deep pars-ing system with the mapping to annotated semanticresources, it is important to realise that the mappingalso enables us to enrich the shallow semantic an-notations with more fine-grained analyses from thedeep grammars.
Such analyses can eventually behelpful for applications like question answering, forinstance, and will be investigated in the future.ReferencesCollin Baker, Charles Fillmore, and John Lowe.
1998.The Berkeley FrameNet project.
In Proceedings ofthe 36th Annual Meeting of the ACL and 17th In-ternational Conference on Computational Linguistics,pages 86?90, San Francisco, CA.Xavier Carreras and Llu?
?s Ma`rquez.
2005.
Introduc-tion to the CoNLL-2005 shared task: Semantic rolelabeling.
In Proceedings of the Ninth Conference onComputational Natural Language Learning (CoNLL-2005), pages 152?164, Ann Arbor, Michigan.Ann Copestake, Dan P. Flickinger, and Ivan A. Sag.2006.
Minimal recursion semantics: An introduction.Research on Language and Computation, 3(4):281?332.Ann Copestake.
2006.
Robust minimal recursion seman-tics.
Working Paper.Christiane D. Fellbaum.
1998.
WordNet ?
An ElectronicLexical Database.
MIT Press.Dan Flickinger, Jan T. L?nning, Helge Dyvik, StephanOepen, and Francis Bond.
2005.
SEM-I rational MT.Enriching deep grammars with a semantic interface forscalable machine translation.
In Proceedings of the10th Machine Translation Summit, pages 165 ?
172,Phuket, Thailand.Dan Flickinger.
2002.
On building a more efficientgrammar by exploiting types.
In Stephan Oepen, DanFlickinger, Jun?ichi Tsujii, and Hans Uszkoreit, edi-tors, Collaborative Language Engineering, pages 1?17.
CSLI Publications.Sanae Fujita, Francis Bond, Stephan Oepen, and TakaakiTanaka.
2007.
Exploiting semantic information forhpsg parse selection.
In ACL 2007 Workshop on DeepLinguistic Processing, pages 25?32, Prague, CzechRepublic.Karin Kipper-Schuler.
2005.
VerbNet: A broad-coverage, comprehensive verb lexicon.
Ph.D. thesis,University of Pennsylvania.Edward Loper, Szu ting Yi, and Martha Palmer.
2007.Combining lexical resources: Mapping between Prop-bank and Verbnet.
In Proceedings of the 7th In-ternational Workshop on Computational Linguistics,Tilburg, the Netherlands.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An Annotated Cor-pus of Semantic Roles.
Computational Linguistics,31(1):71?106.Ted Pedersen, Siddharth Patwardhan, and Jason Miche-lizzi.
2004.
WordNet::Similarity - Measuring the Re-latedness of Concepts.
In Proceedings of the Nine-teenth National Conference on Artificial Intelligence(AAAI-04).192
