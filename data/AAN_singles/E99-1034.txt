Proceedings of EACL '99Finding content-bearing terms using term similaritiesJ us t in  P icardIns t i tu t  In ter facu l ta i re  d ' In fo rmat iqueUnivers i ty  o f  Neucht te lSWITZERLANDjust in .p icard@seco.un ine.chAbst ractThis paper explores the issue of using dif-ferent co-occurrence similarities betweenterms for separating query terms that areuseful for retrieval from those that areharmful.
The hypothesis under examina-tion is that useful terms tend to be moresimilar to each other than to other queryterms.
Preliminary experiments withsimilarities computed using first-orderand second-order co-occurrence s em toconfirm the hypothesis.
Term similari-ties could then be used for determiningwhich query terms are useful and bestreflect the user's information eed.
Apossible application would be to use thissource of evidence for tuning the weightsof the query terms.1 I n t roduct ionCo-occurrence information, whether it is used forexpanding automatically the original query (Qiuand Frei, 1993), for providing a list of candi-date terms to the user in interactive query ex-pansion, or for relaxing the independence as-sumption between query terms (van Rijsbergen,1977), has been widely used in information re-trieval.
Nevertheless, the use of this informationhas often resulted in reduction of retrieval effec-tiveness (Smeaton and van Rijsbergen, 1983), afact sometimes explained by the poor discriminat-ing power of the relationships (Peat and Willet,1991).
It was not until recently that a more elabo-rated use of this information resulted in consistentimprovement of retrieval effectiveness.
Improve-ments came from a different computation of therelationships named "second-order co-occurrence"(Schutze and Pedersen, 1997), from an adequatecombination with other sources of evidence suchas relevance feedback (Xu and Croft, 1996), orfrom a more careful use of the similarities for ex-panding the query (Qiu and Frei, 1993).Indeed, interesting patterns relying in co-occurrence information may be discovered and,if used carefully, may enhance retrieval effective-ness.
This paper explores the use of co-occurrencesimilarities between query terms for determiningthe subset of query terms which are good descrip-tors of the user's information eed.
Query termscan be divided into those that are useful for re-trieval and those that are harmful, which will benamed respectively "content" terms and "noisy"terms.
The hypothesis under examination is thattwo content terms tend to be more similar toeach other than would be two noisy terms, or anoisy and a content erm.
Intuitively, the queryterms which reflect he user's information eed aremore likely to be found in relevant documents andshould concern similar topic areas.
Consequently,they should be found in similar contexts in thecorpus.
A similarity measures the degree to whichtwo terms can be found in the same context, andshould be higher for two content erms.We name this hypothesis the "Cluster Hypoth-esis for query terms", due to its correspondencewith the Cluster Hypothesis of information re-trieval which assumes that relevant documents"are more like one another than they are like non-relevant documents" (van Rijsbergen and Sparck-Jones, 1973, p.252).
Our middle-term objectiveis to verify experimentally the hypothesis for dif-ferent types of co-occurrences, different measuresof similarity and different collections.
If a highersimilarity between content terms is indeed ob-served, this pattern could be used for tuning theweights of query terms in the absence of relevancefeedback information, by increasing the weights ofthe terms which appear to be content erms, andinversely for noisy terms.
Next section is aboutthe verification of the hypothesis on the CACMcollection (3204 documents, 50 queries).241Proceedings of EACL '992 Verifying the Cluster Hypothesisfor query terms2.1 The  C lus ter  Hypothes is  for queryte rmsThe hypothesis that similarities between queryterms is an indicator of the relevance of each termto the user's information eed is based on an in-tuition.
This intuition can be illustrated by thefollowing request:Document will provide totals orspecific data on changes to the provenreserve figures for any oil or naturalgas producer.It appears that the only terms which appear inone or more relevant documents are oil,reserveand gas, which obviously concern similar topic ar-eas, and are good descriptors of the informationneed 1.
All the other terms retrieve only non-relevant documents, and consequently reduce re-trieval effectiveness.
Taken individually, they donot seem to specifically concern the user's infor-mation need.
Our hypothesis can be formulatedthis way:?
Content erms which are representative of theinformation eed (like oil, reserve, and gas)concern similar topics and are more likely tobe found in relevant documents;?
Terms which concern similar topics should befound in similar contexts of the corpus (doc-uments, sentences, neighboring words...);* Terms found in similar contexts have a highsimilarity value.
Consequently, content ermstend to be similar to each other.2.2 Determin ing  content  te rms and noisyte rmsUntil now, we have talked of "content" or "noisy"terms, as terms which are useful or harmful for re-trieval.
How can we determine this?
First, termswhich do not occur in any relevant document canonly be harmful (at best, they have no impact onretrieval) and can directly be classified as "noisy".For terms which occur in one or more relevantdocuments, the usefulness depends on the totalnumber of relevant documents and on the num-ber of occurrences of the term in the collection.We use the X2 test of independence between theoccurrence of the term and the relevance of a doc-ument to determine if the term is a content or a1 Remark that we do not consider here phrases uchas 'natural gas', but the argument can be extended tophrases.noisy term.
For terms which fail the test at the95% confidence level, the hypothesis of indepen-dence is rejected, and they are considered con-tent terms.
Otherwise, they are considered noisyterms.Another way of verifying if a term is useful forretrieval would be to compare the retrieval effi-ciency of the query with and without the term.This method is appealing since our final objectiveis better etrieval efficiency.
But it has some draw-backs: (1) there are several measures of retrievaleffectiveness, and (2) the classification of a termwill depend in part on the retrieval system itselfiA point deserves discussion: terms which do notappear in any relevant documents and which areclassified noisy may sometimes be significant ofthe content of the query.
This may happen forexample if the number of relevant documents issmall and if the vocabularies used in the requestand in the relevant documents are different.
Any-way, this does not change the fact that the termis harmful to retrieval.
It could still be used forfinding expansion terms, but this is another prob-lem.
In any case, a rough classification of termsbetween "content" and "noisy" can always be dis-cussed, the same way that a binary classificationof documents between relevant and non-relevantis a major controversy in the field of informationretrieval.2.3 P re l iminary  exper imentsOnce terms are classified as either content ornoisy, three types of term pairs are considered:content-content, content-noisy, and noisy-noisy.For each pair of query terms, different measuresof similarity can be computed, depending on thetype of co-occurrence, the association measure,and so on.
Each of the three classes of term pairshas an a-priori probability to appear.
We are in-terested in verifying if the similarity has an influ-ence on this probability.One problem with first-order co-occurrence isthat the majority of terms never co-occur, becausethey occur too infrequently.
We decided to se-lect terms which occur more than ten times in thecorpus.
The same term pairs were used for firstand second-order co-occurrence.
Term pairs comefrom selected terms of the same query.
For ex-ample, take a query with 10 terms of which 5 areclassified content.
Then for this query, there areI0.
(i0--I) 2 = 45 term pairs, of which 5"(5-1)2 = 10are content-content, 10 are noisy-noisy, and theother 25 are noisy-content.On the 50 queries used for experiments, thereare 7544 term pairs, of which 1340 (17.76%) are242Proceedings of EACL '99of class content-content, 3426 (45.41%) of classcontent-noisy, and 2778 (36.82%) of class noisy-noisy.
40.47% of the terms are content terms.Obviously, a term can be classified content in aquery and noisy in another.
In the following sub-sections, we present our preliminary experimentson the CACM collection.2.3 .1  F i r s t -o rder  co -occur renceFirst-order co-occurrence measures the degreeto which two terms appear together in thesame context.
If the vectors of weights of tiand tj in documents d~ to dn are respectively(wil, wi2,..., w,~) T and (wjz, wj2, ..., win) T, thecosine similarity is:n 2 /x - '~  n 2 Wik V~,k=l  WjkThe weight wij was set to 1 if ti occured indj, and to 0 otherwise, and within document fre-quency and document size were not exploited.Figure 1 shows the probability to find each of theclasses vs similarity.
The probabilities are com-puted from the raw data binned in intervals ofsimilarity of 0.05, and for the 0 similarity value.The values associated on the graph are 0 for the0 similarity value, 0.025 for interval \]0,0.05\], 0.075for \]0.05,0.1\], etc.
The similarities after 0.325 arenot plotted because there are very few of them.There is a neat increase of probability of theclass 'content-content' with increasing similarity.It is interesting to remark that if high values ofsimilarities are evidence that the terms are con-tent terms, small values can be taken as nega-tive evidence for the same conclusion.
By usingsmaller and more reliable contexts such as sen-tences, paragraphs or windows, it is expected thatthe measures of similarity should be more reliable,and the observed pattern should be stronger.2.3 .2  Second-Order  co -occur renceSecond-order co-occurrence measures the de-gree to which two terms occur with similarterms.
Terms are represented by vectors of co-occurrences where the dimensions correspond toeach of the m terms in the collection.
The valueattributed to dimension k of term ti is the numberof times that ti occurs with tk.
More elaboratedmeasures take into account a weight for each di-mension, which represent the discriminating valueof the corresponding term.
Term ti is representedhere by (wil, wi2, ..., wire) T, where wij is the num-ber of time that ti and tj occur in the same con-text.0.80.7 ?
- -  content--content?
- - content-noisy0,60.5~ 0.40.30,20.10 0.05 0'.1 0.;5 0:2 0.15 013SJr~tar~yFigure 1: Probability of term pairs classes vsFirst-order similarityWe used again Equation 1 for computing simi-larities between query terms.
The similarity val-ues were in general higher than for first-order co-occurrence.
Remark that the same data (termpairs) were taken for first and second-order co-occurrence.
For the computation of probabil-ities, data were binned in intervals of 0.1, onthe range \[0, 0.925\] (not enough similarities higherthan 0.925).
Figure 2 represents the probabilitiesof the class vs similarity.Again, the probability of having the classcontent-content i creases with similarity, but to alesser degree than with first-order similarity.
Moreexperiments are needed to see if first-order co-occurrence is in general stronger evidence of thequality of a term than second-order co-occurrence.However, a second-order similarity can be com-puted for nearly all query terms, while first-ordersimilarities can only be computed for frequentenough terms.0.7_- : I : ' ,Z : ;  o10.f ......... ~sy-r~isy 0 a.
0.30.20.IO0 0'.I 012 0'.3 0'.4 0'.5 0'.0 0'.7 0'.0 0'.9S~mitar~tyFigure 2: Probability of term pairs classes vsSecond-order similarity243Proceedings of EACL '993 DiscussionIn this paper, we have formulated the hypothe-sis that query terms which are good descriptorsof the information need tend to be more simi-lar to each other.
We have proposed a methodto verify if the hypothesis holds in practice, andpresented some preliminary investigations on theCACM collection which seem to confirm the hy-pothesis.
But many other investigations have tobe done on bigger collections, involving more elab-orate measures of similarity using weights, differ-ent contexts (paragraphs, entences), and not onlysingle words but also phrases.
Experiments areongoing on a subset of the TREC collection (200Mb), and preliminary results seem to confirm thehypothesis.
Our hope is that investigations onthis large test collection should yield better re-sults, since the computed similarities are statis-tically more reliable when they are computed onlarger data sets.In a way, this work can be related to word sensedisambiguation.
This problem has already beenaddressed in the field of the information retrieval,but it has been shown that the impact of wordsense disambiguation is of limited utility (Krovetzand Croft, 1992).
Here the problem is not the de-termination of the correct sense of a word, butrather the determination of the usefulness of aquery term for retrieval.
However, it would beinteresting to see if techniques developed for wordsense disambiguation such as (Yarowsky, 1992)could be adapted to determine the usefulness ofa query term for retrieval.From our preliminary investigations, it seemsthat similarities can be used as positive and asnegative vidence that a term should be useful forretrieval.
The other part of our work is to deter-mine a technique for using this pattern in orderto improve term weighting, and at the end im-prove retrieval effectiveness.
While simple tech-niques might work and will be tried (e.g.
cluster-ing), we seriously doubt about it because veryrelationship between query terms should be takeninto account, and this leads to very complex in-teractions.
We are presently developing a modelwhere the probability of the state (content/noisy)of a term is determined by uncertain inference,using a technique for representing and handlinguncertainty named Probabilistic ArgumentationSystems (Kohlas and Haenni, 1996).
In the nextfuture, this model will be implemented and testedagainst simpler models.
If the model allows to pre-dict reasonably well the state of each query term,this information can be used to refine the weight-ing of query terms and lead to better informationretrieval.AcknowledgementsThe author wishes to thank Warren Greiff forcomments on an earlier draft of this paper.
Thisresearch was supported by the SNSF (Swiss Na-tional Scientific Foundation) under grants 21-49427.95.ReferencesJ.
Kohlas and R. Haenni.
1996.
Assumption-based reasoning and probabilistic argumenta-tion systems.
In J. Kohlas and S. Moral,editors, Defensible Reasoning and UncertaintyManagement Systems: Algorithms.
Oxford Uni-versity Press.R.
Krovetz and W.B.
Croft.
1992.
Lexical ambi-guity and information retrieval.
ACM Transac-tions on Information Systems, 10(2):115-141.H.J.
Peat and P. Willet.
1991.
The limita-tions of term co-occurence data for query ex-pansion in document retrieval systems.
Journalof the American Society for Information Sci-ence, pages 378-383, June.Y.
Qiu and H.P.
Frei.
1993.
Concept based queryexpansion.
In Proc.
of the Int.
A CM-SIGIRConf., pages 160-169.H.
Schutze and J.O.
Pedersen.
1997.
Acooccurrence-based thesaurus and two applica-tions to information retrieval.
Information Pro-cessing eJ Management, 33(3):307-318.A.F.
Smeaton and C.J.
van Rijsbergen.
1983.
Theretrieval effects of query expansion on a feed-back document retrieval system.
The ComputerJournal, 26(3):239-246.C.J.
van Rijsbergen and K. Sparck-Jones.
1973.A test for the separation of relevant andnon-relevant documents in experimental re-trieval collections.
Journal of Documentation,29(3):251-257, September.C.J.
van Rijsbergen.
1977.
A theoretical basis forthe use of co-occurrence data in information re-trieval.
Journal of Documentation, 33(2):106-119.J.
Xu and W.B.
Croft.
1996.
Query expansionusing local and global document analysis.
InProc.
of the Int.
ACM-SIGIR Conf., pages 4-11.D.
Yarowsky.
1992.
Word-sense disambiguationusing statistical models of Roget's categoriestrained on large corpora.
In COLING-92, pages454-460.244
