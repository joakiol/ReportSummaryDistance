Automating the Acquisition of Bilingual TerminologyP im van der  E i j kDigital  Equ ipment  Corporat ionKabe lweg 211014 BA AmsterdamThe  Nether landseijk~cecehv.enet.dec.comAbst rac tAs the acquisition problem of bilingual listsof terminological expressions i formidable,it is worthwhile to investigate methods tocompile such lists as automatically as pos-sible.
In this paper we discuss experimen-tal results for a number of methods, whichoperate on corpora of previously translatedtexts.Keywords :  parallel corpora, tagging, ter-minology acquisition.1 In t roduct ionIn the past several years, many researchers havestarted looking at bilingual corpora, as they im-plicitly contain much information eeded for vari-ous purposes that would otherwise have to be com-piled manually.
Some applications using informationextracted from bilingual corpora are statistical MT(\[Brown et al, 1990\]), bilingual exicography (\[Cati-zone el al., 1989\]), word sense disambiguation (\[Galeet al, 1992\]), and multilingual information retrieval(\[Landauer and Littmann, 1990\]).The goal of the research discussed in this paper isto automate as much as possible the generation ofbilingual term lists from previously translated texts.These lists are used by terminologists and transla-tors, e.g.
in documentation departments.
Manualcompilation of bilingual term lists is an expensiveand laborious effort, hence the relative rarity of spe-cialized, up-to-date, and manageable t rminologicaldata collections.
However, organizations interestedin terminology and translation are likely to havearchives of previously translated ocuments, whichrepresent a considerable investment.
Automatic orsemi-automatic extraction of the information con-tained in these documents would then be an attrac-tive perspective.A bilingual term list is a list associating sourcelanguage terms with a ranked list of target languageterms.
The methods to extract bilingual terminol-ogy from parallel texts were developed and evaluatedexperimentally using a bilingual, Dutch-English cor-pus.
There are two phases in the process:1.
Process the texts to extract terms.
The defini-tion of the notion 'term' will be an importantissue of this paper, as it is necessary to adopt adefinition that facilitates comparison of terms inthe source and target language.
Section 4 willshow some flaws of methods that define terms aswords or nouns.
Terminologists commonly usefull noun phrases 1 as terms to express (domain-specific) concepts.
The NP level is shown to bea better level to compare Dutch and English insections 5.1 and 5.2.This phase acts as a linguistic front end to thesecond phase.
The various techniques used toprocess the corpus are described in section 2.2.
Apply statistic techniques to determine corres-pondences between source and target language.In section 3 we will introduce a simple algorithmto select and order potential translations for agiven term.
This method will subsequently becompared to two other methods discussed in theliterature.The usual benefits of modularity apply because thetwo phases are highly independent.1To some extent, a particular domain will also havetextual elements specific to the domain that are not NPs.We will ignore these, but essentially the same methodscould be used to create bilingual ists of e.g.
verbs.113This paper is structured as follows.
Section 2 in-troduces the operations carried out on the evaluationcorpus.
Section 3 describes the translation selectionmethod used.
Section 4 discusses initial experimentswhich use words, resp.
only nouns, as terms: Section5 contains an evaluation of a larger experiment inwhich NPs are used as terms.
Related research isdis-cussed in \[Gaussier et al, 1992\], \[Gale and Church,1991a\] and \[Landauer and Littmann, 1990\].
Section6 compares our method with these approaches.
Sec-tion 7 summarizes the paper, and compares our ap-proach to related research.2 Text  p reprocess ingA number of experiments were carried out on a sam-ple bilingual corpus, viz.
Dutch and English ver-sions of the official announcement of he ESPRIT pro-gramme by the European Commission, the Dutchversion of which contains ome 25,000 words.
Thetexts have been preprocessed in several ways.Lexical Analysis Word and sentence boundarieswere marked up in SGML.
This involved taking intoaccount issues like abbreviations, numerical expres-sions, character normalization.
No morphologicalanalysis (stemming or lemmatization) was applied.Al ignment The experiments were carried out onparallel texts aligned at the sentence level, i.e.
thetexts have been converted to corresponding segmentsof one, or a few, sentences.
Reliable sentence align-ment algorithms are discussed in \[Brown et hi., 1991\]and \[Gale and Church, 1991b\].
For our experimentswe used the Gale-Church method, which is imple-mented by Amy Winarske, ISSCO, Geneva.
Figure1 is a display of two aligned segments.Figure 1: Aligned text segmentsEen hardnekkige weerzin ~ A persisting aversion totegen vroegtijdige start- earlydaardisatie verhindert standardisation preventseen wisselwerking tussen an inter-working ofprod-produkten netsTagging In order to investigate the role of syn-tactic information, the texts have been tagged.
Atagged version of the English text was supplied byUmist, Manchester.
The Dutch version was taggedautomatically using a tagger inspired on the En-glish tagger described in \[Church, 1988\].
This tag-ger uses as contextual information a trigram modelconstructed using a previously tagged corpus, viz.the "Eindhovense corpus".
The system furthermoreuses as lexical information a dictionary derived froma subset of the Celex lexical database, which con-tains information about the possible categories andrelative frequencies of about 50,000 inflected Dutchword forms.Figure 2 shows the tagged aligned segments.Figure 2: Tagged aligned text segments?
'.
Fend haxdnekkige~ ~-* Ad persisting~ aversion,,weerzinn tegenp top .vroegtijdigea standaax- eaxlya strmdaxdisation.disatie, verhindertr eena preventsu and inter-wisselwerking, tussenp working, of v productsnprodukten.?
Parsing On the basis of previous tagging, the textsare superficially parsed by simple pattern matching,where the objective is to extract a list of term nounphrases.
The following grammer rule, where "w" isa marked up word, expresses that English term NPsconsist of zero or more words tagged as adjectivesfollowed by a one or more words tagged as nouns.
* w + np --~ w aThe grammar rule doesn't ake postnominal com-plements and modifiers into account, because the lex-icon lacks information to disambiguate PP attach-ment.
We will later see (section 5.3) that this causesproblems in relating Dutch and English NPs.
Figure3 shows the result of parsing, with recognized NPs inbold face.
Texts can be parsed in linear time usingfinite state techniques.Figure 3: Parsed aligned text segmentsEen hardnekklge ~-~ A persist ing aversionweerz in tegen vroeg- to earlyti jdige standaardisa- standardisat ion pre-tie verhin- vents an inter-workingdeft een wisselwerking of productstussen produkten3 Trans la t ion  se lec t ionA number of variants of bilingual term acquisitionalgorithms have been implemented that operate onparallel texts.
These methods use the output ofthe operations in section 2, then build a databaseof "translational co-occurrences", determine and or-der target language terms for each source languageterm, (optionally) apply filtering using threshold val-ues, and write a report.The selection and ordering technique used is simi-lar to another well-known ranking method, viz.
mu-tual information.
We will compare xperimental re-suits based on our method and on mutual informa-tion in section 6.1.Co-occur rence  In conducting our experiments, asimple statistic measure was used to rank the prob-ability that a target language term is the translationof a source language item.
This measure is based on114the intuition that the translation of a term is likelyto be more frequent in the subset of target 2 text seg-ments aligned to source text segments containing thesource language term than in the entire target lan-guage text.The method consists in building a "global" fre-quency table for all target language terms.
Further-more, for each source language term, a "sub-corpus"of target text segments aligned to source languagesegments containing that source language term iscreated.
A separate, "local" frequency table of tar-get language terms is built for each source languageterm.
Candidate translation terms l/for a source lan-guage term sl are ranked by dividing the "local" fre-quency by their "global" frequency, and select thosepairs for which the result > 1.freqloeat (tllsl)freqalobat (tl)Thresho ld  An important drawback of this defini-tion is that very low-frequent target language terms,which just happen to occur in an aligned segment willget unrealistically high scores.
To eliminate these, weimposed a threshold by removing from the list thosetarget language terms whose local frequency was be-low a certain threshold.
The threshold is defined interms of the global frequency of the source languageterm.freqto,at (tllsl) > thresholdfreqalobat (sl) --The default threshold used was 50%.
However,this restriction does not improve results for thosesource language terms that are infrequent hem-selves.
The effects of variation of this thresholdon precision and recall are discussed in section 5.2,where it will be shown that the threshold, as a pa-rameter of the program, can be modified by the userto give a higher priority to precision or to recall.Similar filters could be established by defining athreshold in terms of the global frequency of the tar-get language term.
One could also require minimalabsolute values 3.Pos l t ion-sens i t iv i ty  An option to the selectionmethod is to calculate the "expected" position ofthe translation of a term (using the size 4 of sourceand target fragments and the position of the sourceterm in the source segment).
For the target languageterms, the score is decreased proportionally to the~It should be noted that we are comparing two trans-lationally related texts; there need not be an actual di-rectional source ---* target relation between the texts.3For example, \[Gaussier et al, 1992\] selected sourcelanguage terms co-occurring more than six times withtarget language terms.4 Size and distance are measured in terms of the num-ber of words (or nouns, NPs) in the segments.distance from the expected position, normalized bythe size of the target segment 5.4 Word and noun-based methods4.1 Exper imentIn the word and noun-based methods, a test suiteof 100 Dutch words which were tagged as a nounwas selected at random.
In the word-based method,the frequencies being compared are the frequenciesof the word forms.
In the noun-based method, onlyfrequencies of nouns are compared.
Figure 4 showsthe result of some experiments.
The quality of themethods can be measured in recall -whether or nota translation of a term is found- and precision.
Wedefine precision as the ability of the program to as-sign the translation, given that this translation hasbeen found, the highest relevance score.Figure 4: Word and noun-based methods\[ Term \[ Pos i t ionword noword yesnoun nonoun yesRecal l  \[ P rec is ion52% 33%52% 77%48% 49%43% 77%The experiments demonstrate that position-sensitivity results in a major improvement of pre-cision.
The size of the segments of the aligned pro-gram is still fairly large (on average, over 24 wordsper segment in the test corpus), therefore there willin general be a lot of candidate translations for agiven term.
Especially in the ease of a small corpussuch as ours, this results in a tendency to return anumber of terms as ex aequo highest scoring items.Apparently, there is little distortion in the order ofterms in the corpus.Another conclusion that can be drawn from theexamples is that use of categorial information alonedoes not improve precision, even though the num-ber of candidate translations is great ly reduced.Position-sensitivity is a much more effective way toachieve improved precision.
One factor explainingthis lack of succes is the error rate introduced bytext tagging, which the word-based method does notsuffer from.
As expected, there is an inherent reduc-tion in recall because nouns do not always translateto nouns.Figure 5 shows an example of the output of theposition-sensitive, word-based system.
The word in-dustry occurs 88 times globally (fourth output col-umn) in the corpus, twice locally, in segments aligned5This option introduces a complication in that localscores are no longer simple co-occurrence ounts, whereasglobal scores till are.
This is partly responsible for lowerrecall in figures 4 and 9.115to segments containing industrietak.
This local fre-quency is adapted to 1.8315.. (the third output col-umn), because of position-sensitivity.Figure 5: Example outputFound 2matchesfor industrietakin 912 segments13.073232323232324 industry 1.8315151515151515 883.5176684881602913 is 1.376969696969697 2442.331223628691983 in 1.7727272727272727 4744.2 Eva luat ionThe real concern raised by the results of the fourmethods discussed is the very low recall.
There arevarious categories of errors common to all methods,which will be discussed in more detail in the evalua-tion of a much larger experiment in section 5.3.However, a more fundamental problem specific tothe word and noun-based methods is the inabilityto extract ranslational information between higher-level units such as noun phrases or compounds.
TheEnglish compound programme management is re-lated to a single Dutch word, viz.
programmabeheer,and even more complex sequences such as high speeddata processing capability are translations of snellegegevensverwerkingscapaciteit, where high speed ismapped to the adjective snel and data processing ca-pability to gegevensverwerkingscapaciteit.
The com-pound problem alone represents 65% of the errors,and is a general problem which comes up in com-paring languages like German or Dutch to languageslike French or English.Although the compound problem can also be ad-dressed by morphological decomposition of com-pounds, there are two other advantages to com-pare the languages at the phrasal rather than at the(tagged) lexical level.Sometimes, an ambiguous noun is disambiguatedby an adjective, e.g.
financial statement, where theadjective imposes a particular eading on the headnoun.
A phrasal method is then based on less am-biguous terms, and will therefore yield more refinedtranslations.Furthermore, the method implicitly lexicalizestranslation of collocational effects between adjectivesand head nouns.5 Phrase-based  methods5.1 Eva luat ion  of  phase-based methodsInitial experiments with a phrase-based methodshowed a small quality increase.
However, in order toevaluate the performance of the phrase-based meth-ods in more detail, a much larger and representativecollection of NPs was selected.
This collection con-sisted of 1100 Dutch NPs, which is 17% of the totalnumber of NPs in the Dutch text.A list associating these terms to their correcttranslations was compiled semi-automatically, b  us-ing some of the methods described in this paper andchecking and correcting the results manually.
61 NPswere removed from the collection because the trans-lation of some occurrences of these terms turned outto be incorrect, very indirect, simply missing fromthe text, or because they suffered from low-level for-matting errors or typing errors.
Also, a program toautomate the evaluation process was implemented.The remaining set was divided in two groups.1.
One group contained 706 pairs of NPs whichthe extraction algorithms should be able extractfrom the text, because they occur in correctlyaligned segments, and are tagged and parsedcorrectly.2.
The other group consists of 334 NPs which itwould not be able to extract because of one or acombination of errors in one of the preprocessingsteps.
Section 5.3 contains a detailed analysis ofthese errors.It is important o note that due to these errors,the extraction algorithms will not be able to achieverecall beyond 68%.
Nevertheless, the acquisition al-gorithms, when operating on NPs instead of wordsor nouns, perform markedly better, cf.
figure 6.
Therecall of both methods is 64%, which is much betterthan word and noun-based methods.
When only tak-ing into account he group of 706 items which didn'thave any preprocessing errors, recall is even 94%.
Fi-nally, precision again improves considerably by ap-plying position-sensitivity.
Section 5.4 discusses at-tempts to further improve precision.Figure 6: Phrase-based methodsI p?s i t i ?n  I Recal l  I P ree is i ?n  Iyes 64% (94%) 68%5.2 Tunab i l i tyThe threshold is defined in terms of the source lan-guage term frequency.
As can be expected, a highthreshold results in relatively higher precision andrelatively lower recall.
Figure 7 shows some fig-ures of varying thresholds with the position-sensitivemethod.
As in figure 6, the score in parentheses ithe recall score when attention is restricted to the setof 706 NPs.
The 50% threshold is the default for theexperiments discussed in this paper, cf.
the secondrow of table 6.The threshold value of our method is a parameterthat can be changed, so that an appropriate thresh-old can be selected, depending on the desired priorityof precision and recall.116Figure 7: Effects of variation of threshold value100%95%90%75%50%25%lo%Recal l15% (23%)31% (45%)42% (62%)54% (79%)64% (94%)66% (97%)6ti% (97%)100%96%88%76%68%64%59%5.3 Analys is  o f  e r rors  af fect ing recal lThe errors can be classified and quantified as follows.There are four classes of technical problems causedby the various preprocessing phases, and two classesof fundamental counter-examples.
These are the fourclasses of errors due to preprocessing.1.
Incorrect alignment of text segments accountsfor 6% of the errors.2.
In 15% of the errors part of a term is taggedincorrectly.
This is often due to lexicon errors.An incompatibility between lexical classificationschemes accounts for another 7% of the errors.The Dutch tagger also has no facility to dealwith occasional use of English in Dutch text(4%).3.
The tagger (and its dictionary) currently doesn'trecognize multi word units, hence e.g.
with res-pect to wrongly yields the term respect (6%).4.
In many cases the syntactic structures of theterms in the two languages do not match.
Thisis the main source of errors (47%).
The patternmatcher ignores postnominal PP arguments andmodifiers in both languages.
However, a Dutchpostnominal PP argument often maps to thefirst part of an English noun-noun compound,as in the following example, where markt mapsto market and versplintering to fragmentation.versplinteringn vanp ,--+ market,,ded marktn fragmentationnThe majority of errors (85%) is therefore due to er-rors in text preprocessing, where there are still manypossible improvements.
The remaining two classesare fundamental counter-examples.1.
In a number of cases (15%), NPs do not trans-late to NPs, e.g.
the following Dutch sentencecontains the equivalent of careful management.sneliea maaxe ~ needsvzorgvuldige~ leidingr, tOrn be~ rapida buttvraagt~ carefullyadvmanaged~2.
In two cases (1%), the solution of a genuine.
ambiguity by the tagger did not correspond tothe interpretation imposed by the translation.In the following example, the deverbal mean-ing of vervaardiging imposes the interpretationof manufacturing as a gerund.hoofdaccent,, opp ded ~ rnaina emphasis,~ onpvervaardigingn vanp manufacturingn/v:elementenn elementsnHowever, these two classes affect only 5% of allterms.
The theoretically maximal recall, assumingthat the alignment program, tagger and NP parserall perform fully correctly, is 95%.
Since the parser iscurrently extremely simplistic, we expect hat majorimprovements can be readily achieved s.5.4  Improv ing  prec is ionThe results in figure 6 and 7 show an important im-provement in recall.
One factor impeding better pre-cision is the small size of the corpus.
In our corpus,71% of the Dutch NPs is unique in the corpus, andprecision suffers from sparsity of data.
Still, it isuseful to investigate ways to improve precision.One obvious option we explored was to exploitcompositionality in translation.
The Dutch terms infigure 8 all contain the 'subterm' schakelingen, theEnglish terms the subterm circuits.
This evidentregularity is not exploited by any of the discussedmethods.
We experimented with an approach whereco-occurrence tables are built of terms as well as ofheads of terms 7and where this information is used inthe selection and ordering of translations.
Surpris-ingly, this improved results for non-positional meth-ods, but not for positional methods.
We do expectthese regularities to emerge with much larger cor-pora.There are some other possibilities which could beexplored.
The terms could lemmatized, so that infor-mation about inflectional variants can be combined.There may also be a correlation in length of termsand their translations.
Finally, the alignment pro-gram provides a measure of the quality of alignment,which is not yet used by the program.6 Re la ted  ResearchIn this section we compare our work with two othermethods reported on in the literature.
In section 6.1we compare our work to work discussed in \[Gaussieret al, 1992\], which is based on mutual informa-tion.
Section 6.2 discusses \[Gale and Church, 1991a\],which is based on the ?2 statistic.
?It is conceivable to partly automate the acquisition ofthe necessary lexical knowledge, viz.
determining whichnouns are likely to take PP complements, but our corpusis too small for this type of knowledge acquisition.7In fact, it turned out to be better to use final sub-strings (e.g.
six or seven characters) of the head noun ofthe NP instead of the head itself to avoid the compoundproblem discussed in section 4.2.117Figure 8: Terms containing circuitsgeintegreerde opto- 4-+ integrated optoelectricelectronische schakelin- circuitsgensnelle logische schake- +-~ high speed logic circuitsl ingengeintegreerde ~ integrated circuitsschakelingenA third method to extract bilingual terminologyis the use of latent semantic indexing, cf.
\[Landauerand Littmann, 1990\].
Latent semantic indexing isa vector model, where a term-document matrix istransformed toa space of much less dimensions usinga technique called singular value decomposition.
Inthe resulting matrix, distributionally similar terms,such as synonyms, are represented by similar vec-tors.
When applied to a collection of documents andtheir translations, terms will be represented by vec-tors similar to the representations of their transla-tions.
We have not yet compared our method to thisapproach.6.1 Mutua l  in fo rmat ionThe selection and ranking method is not based onthe concept of mutual information (cf.
\[Church andHanks, 1989\]), though the technique is quite similar.The mutual information score compares the prob-ability of observing two items together (in alignedsegments) to the product of their individual proba-bilities.P(st, t0I(sl, tl) = log 2 P(s l )P(t l )The difference is that in our method the globalfrequency of the source language term is only usedin the threshold, and is not used for computingthe translational relevance score.
Mutual informa-tion is used for translation selection and ranking in\[Gaussier et al, 1992\].
For comparison, the evalu-ation was repeated using mutual information as se-lection and ordering criterium.
The first two rows infigure 9 show mutual information achieves improvedrecall when compared to figure 6, but at the expenseof reduced precision s.In \[Gaussier d al., 1992\] a filter is used which elim-inates all candidate target language terms that donot provide more information on any other sourcelanguage term.
The last two rows in figure 9 showresults from our implementation f that technique.sit is possible to select only pairs with a mutual infor-mation score greater than some minimum value, whichreduces recall and improves precision.
However, reduc-ing recall to the level in figure 6 still leaves precision ata level much below the precision level given there.In both cases, the threshold results in a huge im-provement of precision, at the expense of recall.
Theposition-sensitive r sult is comparable to the 90%row in table 7.
'Figure 9: Phrase-based methods using muthal infor-mationPosit ion \[ F i l ter  I Recal lno no 66% (98%) 25%yes no 66% (98%) 58%no yes 55% (82%) 38%yes yes 40% (59%) 89%Precision6.2 The  ?2 methodIn \[Gale and Church, 1991a\], another associationmeasure is used, viz.
?2, a X2-1ike statistic.
In thefollowing formula, assume a is the co-occurrence fre-quency of a source language term sl and a targetlanguage term tl, b the frequency of sl minus a, c thefrequency of tl minus a, and d the number of regionscontaining neither sl, nor tl.
?2 = (ad - be) 2(a + b) (a + c) (b + d) (c + d)As in the other methods, the co-occurrence fre-quency can be modified to reflect position-sensitivity.We incorporated this measure into our system andevaluated the performance.
This result is similar tothe 25% threshold in figure 7.Figure 10: Results using e2-statisticPosit ion Recal l  P rec is ionno 66% (97%) 37%yes 66% (97%) 64%7 DiscussionIn this paper a number of methods to extract bilin-gual terminology from aligned corpora were dis-cussed.
The methods consist of a linguistic termextraction phase and a statistic translation selectionphase.The best term extraction method (in terms of re-call) turned out to be a method that defines termsas NPs.
NPs are extracted from text using part ofspeech tagging and pattern matching.
Both taggingand NP-extraction can still be improved consider-ably.
Precision is improved by preferring terms at'similar' positions in target language segments.The translation selection method selects and or-ders translations of a term by comparing lobal and118local frequencies of the target language terms, sub-ject to a threshold condition defined in terms of thefrequency of the source language term.
The thresh-old is a parameter which can be used to give priorityto precision or recall.The re-implementation f the algorithms discussedin \[Gaussier el al., 1992\] and \[Gale and Church,1991a\] results in precision/recall figures comparableto our method.
It should be noted that these studiesestablish correspondences between words rather thanphrases.
We have shown a phrasal approach yieldsimproved recall in the Dutch-English language pair.These studies dealt with an English-French corpus.To some extent, the mismatch due to compoundingmay be less problematic for this language pair, butthe example of the translation of the English expres-sion House of Commons to Chambre des Communes 9shows this language pair would also benefit from aphrasal approach.
These are lexicalized phrases andare described as such in dictionaries 1?.Another difference is that position-sensitivity inranking potential translations i not taken advantageof in the earlier proposals.
Tables 9 and 10 showthese methods also benefit from this extension.
Bothproposals also have no direct analog to our thresholdparameter, which allows for prioritizing precision orrecall (cf.
section 5.2).One aspect not covered at all in our proposal isthe technical problem of memory requirements whichwill emerge when using very large corpora.
This is-sue is discussed in \[Gale and Church, 1991a\].
Futureexperiments should definitely concentrate on experi-ments with much larger corpora, because these wouldallow us to carry out realistic experiments with tech-niques such as mentioned in section 5.4.
We also ex-pect precision to improve in larger corpora, becausemost NPs are unique in the small corpus we used sofar.AcknowledgementsThe research reported was supported by the Euro-pean Commission, through the Eurotra project andcarried out at the Research Institute for Languageand Speech, Utrecht University.
Some experimentsand revisions were carried out at Digital Equipment'sCEC in Amsterdam.
I thank Danny Jones at Umist,Manchester, for the tagged version of the Englishcorpus; Amy Winarske at ISSCO Geneva, for thealignment program mentioned in section 2; and Jean-Marc Lang~ and Bill Gale for help in preparing sec-tion 6.Re ferences\[Brown et al, 1990\] P.F.
Brown, J. Cocke, S.A. Del-laPietra, V.J.
DellaPietra, F. Jelinek, J.D.
Laf-ferty, R.L.
Mercer, and P.S.
Roossin.
A statisticalapproach to machine translation.
ComputationalLinguistics, 16:85-97, 1990.\[Brown et al, 1991\] P. Brown, J. Lai, and R. Mer-cer.
Aligning sentences in parallel corpora.
In 29lhAnnual Meeting of the Association for Computa-tional Linguistics, pages 169-176, 1991.\[Catizone t aL, 1989\] R. Catizone, G. Russel, andS.
Warwick.
Deriving translation data from bilin-gual texts.
In Uri Zernik, editor, Proc.
of the FirstInt.
Lexicai Acquisition Workshop, Detroit, 1989.\[Church and Hanks, 1989\] K. Church and P. Hanks.Word association orms, mutual information, andlexicography.
In 27th Annual Meeting of the As-sociation for Computational Linguistics, pages 76-83, 1989.\[Church, 1988\] K. Church.
A stochastic parts pro-gram and noun phrase parser for unrestricted text.In 2nd Conference on Applied Natural LanguageProcessing (ACL), 1988.\[Gale and Church, 1991a\] W. Gale and K. Church.Identifying word correspondences in parallel texts.In gth Darpa Workshop on Speech and NaturalLanguage, pages 152-157, 1991.\[Gale and Church, 1991b\] W. Gale and K. Church.A program for aligning sentences in bilingual cor-pora.
In 29th Annual Meeting of the Associa-tion for Computational Linguistics, pages 177-184, 1991.\[Gale et al, 1992\] W. Gale, K. Church, andD.
Yarowsky.
Using bilingual materials to developword sense disambiguation methods.
In Fourth In-ternational Conference on theoretical and method-ological issues in machine translation, pages 101-112, Montreal, 1992.\[Gaussier et aL, 1992\] E. Gaussier, J-M Lang,, andF.
Meunier.
Toward bilingual terminology.. InJoint ALLC/ACH Conference, Oxford, 1992.\[Landauer and Littmann, 1990\] T. Landauer andM.
Littmann.
Fully automatic ross-language doc-ument retrieval using latent semantic indexing.
InProceedings of the 6th Conference of the UW Cen-tre for the New Oxford English Dictionary andTest Research, pages 31-38, 1990.9Discussed in \[Landauer and Littmann, 1990, page 34\]and \[Gale and Church, 1991a, page 154\].1?This example again pinpoints the need for improvedNP-recognition, because the PP of Commons would notbe attached to the NP by the NP rule in section 2.119
