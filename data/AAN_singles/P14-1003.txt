Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 25?35,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsText-level Discourse Dependency ParsingSujian Li1 Liang Wang1 Ziqiang Cao1 Wenjie Li21 Key Laboratory of Computational Linguistics, Peking University, MOE, China2 Department of Computing, The Hong Kong Polytechnic University, HongKong{lisujian,intfloat,ziqiangyeah}@pku.edu.cncswjli@comp.polyu.edu.hkAbstractPrevious researches on Text-level discourseparsing mainly made use of constituencystructure to parse the whole document intoone discourse tree.
In this paper, we presentthe limitations of constituency based dis-course parsing and first propose to use de-pendency structure to directly represent therelations between elementary discourseunits (EDUs).
The state-of-the-art depend-ency parsing techniques, the Eisner algo-rithm and maximum spanning tree (MST)algorithm, are adopted to parse an optimaldiscourse dependency tree based on the arc-factored model and the large-margin learn-ing techniques.
Experiments show that ourdiscourse dependency parsers achieve acompetitive performance on text-level dis-course parsing.1 IntroductionIt is widely agreed that no units of the text can beunderstood in isolation, but in relation to theircontext.
Researches in discourse parsing aim toacquire such relations in text, which is funda-mental to many natural language processing ap-plications such as question answering, automaticsummarization and so on.One important issue behind discourse parsingis the representation of discourse structure.
Rhe-torical Structure Theory (RST) (Mann andThompson, 1988), one of the most influentialdiscourse theories, posits a hierarchical genera-tive tree representation, as illustrated in Figure 1.The leaves of a tree correspond to contiguoustext spans called Elementary Discourse Units(EDUs)1.
The adjacent EDUs are combined into1 EDU segmentation is a relatively trivial step in discourseparsing.
Since our work focus here is not EDU segmenta-tion but discourse parsing.
We assume EDUs are alreadyknown.the larger text spans by rhetorical relations (e.g.,Contrast and Elaboration) and the larger textspans continue to be combined until the wholetext constitutes a parse tree.
The text spanslinked by rhetorical relations are annotated aseither nucleus or satellite depending on how sali-ent they are for interpretation.
It is attractive andchallenging to parse the whole text into one tree.Since such a hierarchical discourse tree isanalogous to a constituency based syntactic treeexcept that the constituents in the discourse treesare text spans, previous researches have exploreddifferent constituency based syntactic parsingtechniques (eg.
CKY and chart parsing) and var-ious features (eg.
length, position et al) for dis-course parsing (Soricut and Marcu, 2003; Joty etal., 2012; Reitter, 2003; LeThanh et al, 2004;Baldridge and Lascarides, 2005; Subba and DiEugenio, 2009; Sagae, 2009; Hernault et al,2010b; Feng and Hirst, 2012).
However, the ex-isting approaches suffer from at least one of thefollowing three problems.
First, it is difficult todesign a set of production rules as in syntacticparsing, since there are no determinate genera-tive rules for the interior text spans.
Second, thedifferent levels of discourse units (e.g.
EDUs orlarger text spans) occurring in the generativeprocess are better represented with different fea-tures, and thus a uniform framework for dis-course analysis is hard to develop.
Third, toreduce the time complexity of the state-of-the-artconstituency based parsing techniques, the ap-proximate parsing approaches are prone to trapin local maximum.In this paper, we propose to adopt the depend-ency structure in discourse representation toovercome the limitations mentioned above.
Hereis the basic idea: the discourse structure consistsof EDUs which are linked by the binary, asym-metrical relations called dependency relations.
Adependency relation holds between a subordinateEDU called the dependent, and another EDU on25which it depends called the head, as illustrated inFigure 2.
Each EDU has one head.
So, the de-pendency structure can be seen as a set of head-dependent links, which are labeled by functionalrelations.
Now, we can analyze the relations be-tween EDUs directly, without worrying aboutany interior text spans.
Since dependency treescontain much fewer nodes and on average theyare simpler than constituency based trees, thecurrent dependency parsers can have a relativelylow computational complexity.
Moreover, con-cerning linearization, it is well known that de-pendency structures can deal with non-projectiverelations, while constituency-based models needthe addition of complex mechanisms like trans-formations, movements and so on.
In our work,we adopt the graph based dependency parsingtechniques learned from large sets of annotateddependency trees.
The Eisner (1996) algorithmand maximum spanning tree (MST) algorithmare used respectively to parse the optimal projec-tive and non-projective dependency trees withthe large-margin learning technique (Crammerand Singer, 2003).
To the best of our knowledge,we are the first to apply the dependency structureand introduce the dependency parsing techniquesinto discourse analysis.The rest of this paper is organized as follows.Section 2 formally defines discourse dependencystructure and introduces how to build a discoursedependency treebank from the existing RST cor-pus.
Section 3 presents the discourse parsing ap-proach based on the Eisner and MST algorithms.Section 4 elaborates on the large-margin learningtechnique as well as the features we use.
Section5 discusses the experimental results.
Section 6introduces the related work and Section 7 con-cludes the paper.1e2e1-e2*e3e1- 2*-e3e1 e2e1-e2*e3e1-e2-e3*e1 e2e1*-e2e3e1-e2-e3*e1e2e1*-e2e3e1*-e2-e3e1 e2e2*-e3e3e1-e2*-e3e1 e2e3 e1 e2e3e1*-e2-e3e2*-e3 e2-e3*e1*-e2-e31 2 3 45 6 7 8e1e2 e3e1- 2- 3*e2-e3*Figure 1: Headed Constituency based Discourse Tree Structure (e1,e2 and e3 denote three EDUs,and * denotes the NUCLEUS constituent)e1 e2 e3 e1 e2 e3 e1 e2 e3 e1 e2 e3e1 e2 e3e1 e2 e3 e1 e2 e3e1 e2 e31' 2' 3' 4'5' 6' 7' 8' 9'e1 e2 e3e0e0 e0 e0e0 e0 e0 e0 e0Figure 2: Discourse Dependency Tree Structures (e1,e2 and e3 denote three EDUS, and the directedarcs  denote one dependency relations.
The artificial e0 is also displayed here.
)2 Discourse Dependency Structure andTree Bank2.1 Discourse Dependency StructureSimilar to the syntactic dependency structuredefined by McDonald (2005a, 2005b), we insertan artificial EDU e0 in the beginning for eachdocument and label the dependency relation link-ing from e0 as ROOT.
This treatment will sim-plify both formal definitions and computationalimplementations.
Normally, we assume that eachEDU should have one and only one head exceptfor e0.
A labeled directed arc is used to representthe dependency relation from one head to its de-pendent.
Then, discourse dependency structurecan be formalized as the labeled directed graph,where nodes correspond to EDUs and labeledarcs correspond to labeled dependency relations.26We assume that the text2  T is composed ofn+1 EDUs including the artificial e0.
That isT=e0 e1 e2 ?
en.
Let R={r1,r2, ?
,rm} denote afinite set of functional relations that hold be-tween two EDUs.
Then a discourse dependencygraph can be denoted by G=<V, A> where V de-notes a set of nodes and A denotes a set of la-beled directed arcs, such that for the text T=e0 e1e2 ?
en and the label set R the following holds:(1) V = { e0, e1, e2, ?
en }(2) A ?
V?
R ?
V, where <ei, r, ej>?A representsan arc from the head ei to the dependent ejlabeled with the relation r.(3) If <ei, r, ej>?A then <ek, r?, ej>?A for all k?i(4) If <ei, r, ej>?A then <ei, r?, ej>?A for all r?
?rThe third condition assures that each EDU hasone and only one head and the fourth tells thatonly one kind of dependency relation holds be-tween two EDUs.
According to the definition,we illustrate all the 9 possible unlabeled depend-ency trees for a text containing three EDUs inFigure 2.
The dependency trees 1?
to 7?
are pro-jective while 8?
and 9?
are non-projective withcrossing arcs.2.2 Our Discourse Dependency TreebankTo automatically conduct discourse dependencyparsing, constructing a discourse dependencytreebank is fundamental.
It is costly to manuallyconstruct such a treebank from scratch.
Fortu-nately, RST Discourse Treebank (RST-DT)(Carlson et al, 2001) is an available resource tohelp with.A RST tree constitutes a hierarchical structurefor one document through rhetorical relations.
Atotal of 110 fine-grained relations (e.g.
Elabora-tion-part-whole and List) were used for taggingRST-DT.
They can be categorized into 18 classes(e.g.
Elaboration and Joint).
All these relationscan be hypotactic (?mononuclear?)
or paratactic(?multi-nuclear?).
A hypotactic relation holdsbetween a nucleus span and an adjacent satellitespan, while a paratactic relation connects two ormore equally important adjacent nucleus spans.For convenience of computation, we convert then-ary (n>2) RST trees3 to binary trees throughadding a new node for the latter n-1 nodes andassume each relation is connected to only onenucleus4.
This departure from the original theory2 The two terms ?text?
and ?document?
are used inter-changeably and represent the same meaning.3 According to our statistics, there are totally 381 n-ary rela-tions in RST-DT.4 We set the first nucleus as the only nucleus.is not such a major step as it may appear, sinceany nucleus is known to contribute to the essen-tial meaning.
Now, each RST tree can be seen asa headed constituency based binary tree wherethe nuclei are heads and the children of eachnode are linearly ordered.
Given three EDUs5,Figure 1 shows the possible 8 headed constituen-cy based trees where the superscript * denotesthe heads (nuclei).
We use dependency trees tosimulate the headed constituency based trees.Contrasting Figure 1 with Figure 2, we usedependency tree 1?
to simulate binary trees 1 and8, and dependency tress 2?- 7?
to simulate binarytrees 2-7 correspondingly.
The rhetorical rela-tions in RST trees are kept as the functional rela-tions which link the two EDUs in dependencytrees.
With this kind of conversion, we can getour discourse dependency treebank.
It is worthnoting that the non-projective trees like 8?
and 9?do not exist in our dependency treebank, thoughthey are eligible according to the definition ofdiscourse dependency graph.3 Discourse Dependency Parsing3.1 System OverviewAs stated above, T=e0 e1 ?en represents an inputtext (document) where ei denotes the ith EDU ofT.
We use V to denote all the EDU nodes andV?R?V-0 (V-0 =V-{e0}) denote all the possiblediscourse dependency arcs.
The goal of discoursedependency parsing is to parse an optimal span-ning tree from V?R?V-0.
Here we follow the arcfactored method and define the score of a de-pendency tree as the sum of the scores of all thearcs in the tree.
Thus, the optimal dependencytree for T is a spanning tree with the highestscore and obtained through the function DT(T,w):000, ,, ,( , )( , )( , , )( , , )fTTi j TTi j TG V R VG V R V i je r e GG V R V i je r e GTDT T argmaxargmax e r eargmax e rs ore T Gec?????
?
??
?
??
???
?
??
?????
??
?wwwhere GT means a possible spanning tree with( , )Tscore T G  and ?
(       ) denotes the score ofthe arc <ei, r, ej> which is calculated according toits feature representation f(ei,r,ej) and a weightvector w.Next, two basic problems need to be solved:how to find the dependency tree with the highest5 We can easily get al possible headed binary trees for onemore complex text containing more than three EDUs, byextending the 8 possible situations for three EDUs.27score for T given all the arc scores (i.e.
a parsingproblem), and how to learn and compute thescores of arcs according to a set of arc features(i.e.
a learning problem).The following of this section addresses thefirst problem.
Given the text T, we first reducethe multi-digraph composed of all possible arcsto the digraph.
The digraph keeps only one arc<ei, r, ej> between two nodes which satisfies?
(       )                  .
Thus, we canproceed with a reduction from labeled parsing tounlabeled parsing.
Next, two algorithms, i.e.
theEisner algorithm and MST algorithm, are pre-sented to parse the projective and non-projectiveunlabeled dependency trees respectively.3.2 Eisner AlgorithmIt is well known that projective dependency pars-ing can be handled with the Eisner algorithm(1996) which is based on the bottom-up dynamicprogramming techniques with the time complexi-ty of O(n3).
The basic idea of the Eisner algo-rithm is to parse the left and right dependents ofan EDU independently and combine them at alater stage.
This reduces the overhead of index-ing heads.
Only two binary variables, i.e.
c and d,are required to specify whether the heads occurleftmost or rightmost and whether an item iscomplete.Eisner(T,  ?
)Input: Text T=e0 e1?
en; Arc scores ?
(ei,ej)1   Instantiate E[i, i, d, c]=0.0 for all i, d, c2   For m := 1 to n3       For i := 1 to n4          j = i + m5          if j> n then break;6          # Create subgraphs with c=0 by adding arcs7         E[i, j, 0, 0]=maxi?q?j (E[i,q,1,1]+E[q+1,j,0,1]+?
(ej,ei))8         E[i, j, 1, 0]=maxi?q?j (E[i,q,1,1]+E[q+1,j,0,1]+?
(ei,ej))9          # Add corresponding left/right subgraphs10        E[i, j, 0, 1]=maxi?q?j (E[i,q,0,1]+E[q,j,0,0]11        E[i, j, 1, 1]=maxi?q?j (E[i,q,1,0]+E[q,j,1,1])Figure 3: Eisner AlgorithmFigure 3 shows the pseudo-code of the Eisneralgorithm.
A dynamic programming tableE[i,j,d,c] is used to represent the highest scoredsubtree spanning ei to ej.
d indicates whether ei isthe head (d=1) or ej is head (d=0).
c indicateswhether the subtree will not take any more de-pendents (c=1) or it needs to be completed (c=0).The algorithm begins by initializing all length-one subtrees to a score of 0.0.
In the inner loop,the first two steps (Lines 7 and 8) are to constructthe new dependency arcs by taking the maximumover all the internal indices (i?q?j) in the span,and calculating the value of merging the two sub-trees and adding one new arc.
The last two steps(Lines 10 and 11) attempt to achieve an optimalleft/right subtree in the span by adding the corre-sponding left/right subtree to the arcs that havebeen added previously.
This algorithm considersall the possible subtrees.
We can then get theoptimal dependency tree with the scoreE[0,n,1,1] .3.3 Maximum Spanning Tree AlgorithmAs the bottom-up Eisner Algorithm must main-tain the nested structural constraint, it cannotparse the non-projective dependency trees like 8?and 9?
in Figure 2.
However, the non-projectivedependency does exist in real discourse.
For ex-ample, the earlier text mainly talks about the top-ic A with mentioning the topic B, while the lattertext gives a supplementary explanation for thetopic B.
This example can constitute a non-projective tree and its pictorial diagram is exhib-ited in Figure 4.
Following the work of McDon-ald (2005b), we formalize discourse dependencyparsing as searching for a maximum spanningtree (MST) in a directed graph.... ...A A AB B...Figure 4: Pictorial Diagram of Non-projectiveTreesChu and Liu (1965) and Edmonds (1967) in-dependently proposed the virtually identical al-gorithm named the Chu-Liu/Edmonds algorithm,for finding MSTs on directed graphs (McDonaldet al 2005b).
Figure 5 shows the details of theChu-Liu/Edmonds algorithm for discourse pars-ing.
Each node in the graph greedily selects theincoming arc with the highest score.
If one treeresults, the algorithm ends.
Otherwise, theremust exist a cycle.
The algorithm contracts theidentified cycle into a single node and recalcu-lates the scores of the arcs which go in and out ofthe cycle.
Next, the algorithm recursively callitself on the contracted graph.
Finally, those arcswhich go in or out of one cycle will recoverthemselves to connect with the original nodes inV.
Like McDonald et al (2005b), we adopt anefficient implementation of the Chu-Liu/Edmonds algorithm that is proposed by Tar-jan (1997) with O(n2) time complexity.28Chu-Liu-Edmonds(G, ?
)Input: Text T=e0 e1?
en; Arc scores ?
(ei,ej)1      A?
= {<ei, ej>| ei = argmax ?
(ei,ej); 1?j?|V|}2      G?
= (V, A?
)3      If G?
has no cycles, then return G?4      Find an arc set AC that is a cycle in G?5      <GC, ep> = contract(G, AC, ?
)6      G = (V, A)=Chu-Liu-Edmonds(GC, ?
)7      For the arc <ei,eC> where ep(ei,eC)=ej:8              A=A?AC?
{<ei,ej)}-{<ei,eC>, <a(ej),ej>}9      For the arc <eC, ei> where ep(eC ,ei)=ej:10            A=A?
{<ej,ei>}-{<eC,ei>}11    V = V12    Return GContract(G=(V,A), AC, ?
)1   Let GC be the subgraph of G excluding nodes in C2   Add a node eC to GC denoting the cycle C3   For ej ?V-C : ?ei?C <ei,ej>?A4        Add arc <eC,ej> to GC withep(eC,ej)=          ?
(ei,ej)5        ?
(eC,ej) = ?
(ep(eC,ej),ej)6    For ei ?V-C: ?ej?C   (ei,ej)?A7         Add arc <ei,eC> to GC withep(ei,eC)= =           [?(ei,ej)-?
(a(ei),ej)]8         ?
(ei,eC) =?(ei,ej)-?
(a(ei),ej)+score(C)9   Return <GC, ep>Figure 5: Chu-Liu/Edmonds MST Algorithm4 LearningIn Section 3, we assume that the arc scores areavailable.
In fact, the score of each arc is calcu-lated as a linear combination of feature weights.Thus, we need to determine the features for arcrepresentation first.
With referring to McDonaldet al (2005a; 2005b), we use the Margin InfusedRelaxed Algorithm (MIRA) to learn the featureweights based on a training set of documentsannotated with dependency structures ?
??
?
1, Ni iT ?iywhere yi denotes the correct dependency tree forthe text Ti.4.1 FeaturesFollowing (Feng and Hirst, 2012; Lin et al, 2009;Hernault et al, 2010b), we explore the following6 feature types combined with relations to repre-sent each labeled arc <ei, r, ej> .
(1) WORD: The first one word, the last oneword, and the first bigrams in each EDU, the pairof the two first words and the pair of the two lastwords in the two EDUs are extracted as features.
(2) POS: The first one and two POS tags in eachEDU, and the pair of the two first POS tags inthe two EDUs are extracted as features.
(3) Position: These features concern whether thetwo EDUs are included in the same sentence, andthe positions where the two EDUs are located inone sentence, one paragraph, or one document.
(4) Length: The length of each EDU.
(5) Syntactic:  POS tags of the dominating nodesas defined in Soricut and Marcu (2003) are ex-tracted as features.
We use the syntactic treesfrom the Penn Treebank to find the dominatingnodes,.
(6) Semantic similarity: We compute the se-mantic relatedness between the two EDUs basedon WordNet.
The word pairs are extracted from(ei, ej) and their similarity is calculated.
Then, wecan get a weighted complete bipartite graphwhere words are deemed as nodes and similarityas weights.
From this bipartite graph, we get themaximum weighted matching and use the aver-aged weight of the matches as the similarity be-tween ei and ej.
In particular, we usepath_similarity, wup_similarity, res_similarity,jcn_similarity and lin_similarity provided by thenltk.wordnet.similarity (Bird et.
al., 2009) pack-age for calculating word similarity.As for relations, we experiment two sets ofrelation labels from RST-DT.
One is composedof 19 coarse-grained relations and the other 111fine-grained relations6.4.2 MIRA based LearningMargin Infused Relaxed Algorithm (MIRA) is anonline algorithm for multiclass classification andis extended by Taskar et al (2003) to cope withstructured classification.MIRA   Input: a training set ?
??
?
1, Ni iT ?iy1      w0 = 0; v = 0; j = 02      For iter := 1 to K3            For i := 1 to N4                   update w according to ?
?,iT iy :1min j j?
?w ws.t.
( , ) ( , ') ( , ')where  ' ( , )i i i i i iji is T s T LDT T?
?
?y y y yy w5                      v = v + wj ;6                      j = j+17       w = v/(K*N)Figure 6: MIRA based LearningFigure 6 gives the pseudo-code of the MIRAalgorithm (McDonld et al, 2005b).
This algo-rithm is designed to update the parameters w us-ing a single training instance ?
?,iT iy  in eachiteration.
On each update, MIRA attempts tokeep the norm of the change to the weight vector6 19 relations include the original 18 relation in RST-DTplus one artificial ROOT relation.
The 111 relations alsoinclude the ROOT relation.29as small as possible, which is subject to con-structing the correct dependency tree under con-sideration with a margin at least as large as theloss of the incorrect dependency trees.
We definethe loss of a discourse dependency tree 'iy  (de-noted by ( , ')i iL y y  ) as the number of the EDUsthat have incorrect heads.
Since there are expo-nentially many possible incorrect dependencytrees and thus exponentially many margin con-straints, here we relax the optimization and staywith a single best dependency tree' ( , )ji iDT T?y w  which is parsed under the weightvector wj.
In this algorithm, the successive up-dated values of w are accumulated and averagedto avoid overfitting.5 Experiments5.1 PreparationWe test our methods experimentally using thediscourse dependency treebank which is built asin Section 2.
The training part of the corpus iscomposed of 342 documents and contains 18,765EDUs, while the test part consists of 38 docu-ments and 2,346 EDUs.
The number of EDUs ineach document ranges between 2 and 304.
Twosets of relations are adopted.
One is composed of19 relations and Table 1 shows the number ofeach relation in the training and test corpus.
Theother is composed of 111 relations.
Due to spacelimitation, Table 2 only lists the 10 highest-distributed relations with regard to their frequen-cy in the training corpus.The following experiments are conducted: (1)to measure the parsing performance with differ-ent relation sets and different feature types; (2) tocompare our parsing methods with the state-of-the-art discourse parsing methods.Relations Train Test Relations Train TestElaboration 6879 796 Temporal 426 73Attribution 2641 343 ROOT 342 38Joint 1711 212 Compari.
273 29Same-unit 1230 127 Condition 258 48Contrast 944 146 Manner.
191 27Explanation 849 110 Summary 188 32Background 786 111 Topic-Cha.
187 13Cause 785 82 Textual 147 9Evaluation 502 80 TopicCom.
126 24Enablement 500 46 Total 18765 2346Table 1: Coarse-grained Relation DistributionRelations Train TestElaboration-additional 2912 312Attribution 2474 329Elaboration-object-attribute-e 2274 250List 1690 206Same-unit 1230 127Elaboration-additional-e 747 69Circumstance 545 80Explanation-argumentative 524 70Purpose 430 43Contrast 358 64Table 2: 10 Highest Distributed Fine-grainedRelations5.2 Feature Influence on Two Relation SetsSo far, researches on discourse parsing avoidadopting too fine-grained relations and the rela-tion sets containing around 20 labels are widelyused.
In our experiments, we observe that adopt-ing a fine-grained relation set can even be helpfulto building the discourse trees.
Here, we conductexperiments on two relation sets that contain 19and 111 labels respectively.
At the same time,different feature types are tested their effects ondiscourse parsing.Method Features UnlabeledAcc.LabeledAcc.Eisner 1+2 0.3602 0.26511+2+3 0.7310 0.48551+2+3+4 0.7370 0.48681+2+3+4+5 0.7447 0.49571+2+3+4+5+6 0.7455 0.4983MST 1+2 0.1957 0.14791+2+3 0.7246 0.47831+2+3+4 0.7280 0.47951+2+3+4+5 0.7340 0.49151+2+3+4+5+6 0.7331 0.4851Table 3: Performance Using Coarse-grained Re-lations.Method Feature types UnlabeledAcc.LabeledAcc.Eisner 1+2 0.3743 0.24211+2+3 0.7451 0.40791+2+3+4 0.7472 0.40411+2+3+4+5 0.7506 0.42541+2+3+4+5+6 0.7485 0.4288MST 1+2 0.2080 0.13001+2+3 0.7366 0.40541+2+3+4 0.7468 0.40711+2+3+4+5 0.7494 0.42881+2+3+4+5+6 0.7460 0.4309Table 4: Performance Using Fine-grained Rela-tions.Based on the MIRA leaning algorithm, theEisner algorithm and MST algorithm are used toparse the test documents respectively.
Referringto the evaluation of syntactic dependency parsing,30we use unlabeled accuracy to calculate the ratioof EDUs that correctly identify their heads, la-beled accuracy the ratio of EDUs that have bothcorrect heads and correct relations.
Table 3 andTable 4 show the performance on two relationsets.
The numbers (1-6) represent the corre-sponding feature types described in Section 4.1.From Table 3 and Table 4, we can see that theaddition of more feature types, except the 6th fea-ture type (semantic similarity), can promote theperformance of relation labeling, whether usingthe coarse-grained 19 relations and the fine-grained 111 relations.
As expected, the first andsecond types of features (WORD and POS) arethe ones which play an important role in buildingand labeling the discourse dependency trees.These two types of features attain similar per-formance on two relation sets.
The Eisner algo-rithm can achieve unlabeled accuracy around0.36 and labeled accuracy around 0.26, whileMST algorithm achieves unlabeled accuracyaround 0.20 and labeled accuracy around 0.14.The third feature type (Position) is also veryhelpful to discourse parsing.
With the addition ofthis feature type, both unlabeled accuracy andlabeled accuracy exhibit a marked increase.
Es-pecially, when applying MST algorithm on dis-course parsing, unlabeled accuracy rises fromaround 0.20 to around 0.73.
This result is con-sistent with Hernault?s work (2010b) whose ex-periments have exhibited the usefulness of thoseposition-related features.
The other two types offeatures which are related to length and syntacticparsing, only promote the performance slightly.As we employed the MIRA learning algorithm,it is possible to identify which specific featuresare useful, by looking at the weights learned toeach feature using the training data.
Table 5 se-lects 10 features with the highest weights in ab-solute value for the parser which uses the coarse-grained relations, while Table 6 selects the top10 features for the parser using the fine-grainedrelations.
Each row denotes one feature: the leftpart before the symbol ?&?
is from one of the 6feature types and the right part denotes a specificrelation.
From Table 5 and Table 6, we can seethat some features are reasonable.
For example,The sixth feature in Table 5 represents that thedependency relation is preferred to be labeledExplanation with the fact that ?because?
is thefirst word of the dependent EDU.
From thesetwo tables, we also observe that most of theheavily weighted features are usually related tothose highly distributed relations.
When usingthe coarse-grained relations, the popular relations(eg.
Elaboration, Attribution and Joint) are al-ways preferred to be labeled.
When using thefine-grained relations, the large relations includ-ing List and Elaboration-object-attribute-e aregiven the precedence of labeling.
This phenome-non is mainly caused by the sparseness of thetraining corpus and the imbalance of relations.To solve this problem, the augment of trainingcorpus is necessary.Feature description Weight1Last two words in dependent EDU are?appeals court?
& Joint0.4752First word in dependent EDU is ?racked?& Elaboration0.4453First two words in head EDU are ?I ?d?& Attribution0.3244Last word in dependent EDU is ?in?& Elaboration-0.3235The res_similarity between two EDUs is 0& Elaboration0.3226First word in dependent EDU is ?because?& Explanation0.3067 First POS in head EDU is ?DT?
& Joint -0.2998First two words in dependent EDU are ?thatrequired?
& Elaboration0.2879First two words in dependent EDU are ?thatthe?
& Elaboration0.27710First word in dependent EDU is ?because?& Cause0.265Table 5: Top 10 Feature Weights for Coarse-grained Relation Labeling (Eisner Algorithm)Features Weight1 Last two words in dependent EDU are ?ap-peals court?
& List0.5762 First two words in head EDU are ?I ?d?& Attribution0.3853 First two words in dependent EDU is ?thatthe?
& Elaboration-object-attribute-e0.3484 First POS in head EDU is ?DT?
& List -0.3235 Last word in dependent EDU is ?in?
& List -0.2866 First word in dependent EDU is ?racked?
&Elaboration-object-attribute-e0.4457 First two word pairs are <?In an?,?Buteven?>  & List-0.2528 Dependent EDU has a dominating nodetagged ?CD?& Elaboration-object-attribute-e-0.2449 First two words in dependent EDU are ?pa-tents disputes?
& Purpose0.23110 First word in dependent EDU is ?to?& Purpose0.230Table 6: Top 10 Feature Weights for Coarse-grained Relation Labeling (Eisner Algorithm)Unlike previous discourse parsing approaches,our methods combine tree building and relationlabeling into a uniform framework naturally.This means that relations play a role in buildingthe dependency tree structure.
From Table 3 andTable 4, we can see that fine-grained relationsare more helpful to building unlabeled discourse31trees more than the coarse-grained relations.
Thebest result of unlabeled accuracy using 111 rela-tions is 0.7506, better than the best performance(0.7447) using 19 relations.
We can also see thatthe labeled accuracy using the fine-grained rela-tions can achieve 0.4309, only 0.06 lower thanthe best labeled accuracy (0.4915) using thecoarse-grained relations.In addition, comparing the MST algorithmwith the Eisner algorithm, Table 3 and Table 4show that their performances are not significant-ly different from each other.
But we think thatMST algorithm has more potential in discoursedependency parsing, because our converted dis-course dependency treebank contains only pro-jective trees and somewhat suppresses the MSTalgorithm to exhibit its advantage of parsing non-projective trees.
In fact, we observe that somenon-projective dependencies produced by theMST algorithm are even reasonable than whatthey are in the dependency treebank.
Thus, it isimportant to build a manually labeled discoursedependency treebank, which will be our futurework.5.3 Comparison with Other SystemsThe state-of-the-art discourse parsing methodsnormally produce the constituency based dis-course trees.
To comprehensively evaluate theperformance of a labeled constituency tree, theblank tree structure (?S?
), the tree structure withnuclearity indication (?N?
), and the tree structurewith rhetorical relation indication but no nuclear-ity indication (?R?)
are evaluated respectivelyusing the F measure (Marcu 2000).To compare our discourse parsers with others,we adopt MIRA and Eisner algorithm to conductdiscourse parsing with all the 6 types of featuresand then convert the produced projective de-pendency trees to constituency based treesthrough their correspondence as stated in Section2.
Our parsers using two relation sets are namedOur-coarse and Our-fine respectively.
The in-putted EDUs of our parsers are from the standardsegmentation of RST-DT.
Other text-level dis-course parsing methods include: (1) Percep-coarse: we replace MIRA with the averaged per-ceptron learning algorithm and the other settingsare the same with Our-coarse; (2) HILDA-manual and HILDA-seg are from Hernault(2010b)?s work, and their inputted EDUs arefrom RST-DT and their own EDU segmenterrespectively; (3) LeThanh indicates the resultsgiven by LeThanh el al.
(2004), which built amulti-level rule based parser and used 14 rela-tions evaluated on 21 documents from RST-DT;(4) Marcu denotes the results given by Mar-cu(2000)?s decision-tree based parser which used15 relations evaluated on unspecified documents.Table 7 shows the performance comparisonfor all the parsers mentioned above.
Human de-notes the manual agreement between two humanannotators.
From this table, we can see that bothour parsers perform better than all the otherparsers as a whole, though our parsers are notdeveloped directly for constituency based trees.Our parsers do not exhibit obvious advantagethan HILDA-manual on labeling the blank treestructure, because our parsers and HILDA-manual all perform over 94% of Human and thisperformance level somewhat reaches a bottle-neck to promote more.
However, our parsersoutperform the other parsers on both nuclearityand relation labeling.
Our-coarse achieves 94.2%and 91.8% of the human F-scores, on labelingnuclearity and relation respectively, while Our-fine achieves 95.2% and 87.6%.
We can also seethat the averaged perceptron learning algorithm,though simple, can achieve a comparable per-formance, better than HILDA-manual.
Theparsers HILDA-seg, LeThanh and Marcu usetheir own automatic EDU segmenters and exhibita relatively low performance.
This means thatEDU segmentation is important to a practicaldiscourse parser and worth further investigation.S N ROur-coarse 82.9 73.0 60.6Our-fine 83.4 73.8 57.8Percep-coarse 82.3 72.6 59.4HILDA-manual 83.0 68.4 55.3HILDA-seg 72.3 59.1 47.8LeThanh 53.7 47.1 39.9Marcu 44.8 30.9 18.8Human 88.1 77.5 66.0Table 7: Full Parser EvaluationMAFS WAFS AccOur-coarse 0.454 0.643 66.84Percep-coarse 0.438 0.633 65.37Feng 0.440 0.607 65.30HILDA-manual 0.428 0.604 64.18Baseline - - 35.82Table 8: Relation Labeling PerformanceTo further compare the performance of rela-tion labeling, we follow Hernault el al.
(2010a)and use Macro-averaged F-score (MAFS) toevaluate each relation.
Due to space limitation,we do not list the F scores for each relation.Macro-averaged F-score is not influenced by thenumber of instances that are contained in each32relation.
Weight-averaged F-score (WAFS)weights the performance of each relation by thenumber of its existing instances.
Table 8 com-pares our parser Our-coarse with other parsersHILDA-manual, Feng (Feng and Hirst, 2012)and Baseline.
Feng (Feng and Hirst, 2012) canbe seen as a strengthened version of HILDAwhich adopts more features and conducts featureselection.
Baseline always picks the most fre-quent relation (i.e.
Elaboration).
From the results,we find that Our-coarse consistently providessuperior performance for most relations overother parsers, and therefore results in higherMAFS and WAFS.6 Related WorkSo far, the existing discourse parsing techniquesare mainly based on two well-known treebanks.One is the Penn Discourse TreeBank (PDTB)(Prasad et al, 2007) and the other is RST-DT.PDTB adopts the predicate-arguments repre-sentation by taking an implicit/explicit connec-tive as a predication of two adjacent sentences(arguments).
Then the discourse relation betweeneach pair of sentences is annotated independentlyto characterize its predication.
A majority of re-searches regard discourse parsing as a classifica-tion task and mainly focus on exploiting variouslinguistic features and classifiers when usingPDTB (Wellner et al, 2006; Pitler et al, 2009;Wang et al, 2010).
However, the predicate-arguments annotation scheme itself has such alimitation that one can only obtain the local dis-course relations without knowing the rich context.In contrast, RST and its treebank enable peo-ple to derive a complete representation of thewhole discourse.
Researches have begun to in-vestigate how to construct a RST tree for thegiven text.
Since the RST tree is similar to theconstituency based syntactic tree except that theconstituent nodes are different, the syntacticparsing techniques have been borrowed for dis-course parsing (Soricut and Marcu, 2003;Baldridge and Lascarides, 2005; Sagae, 2009;Hernault et al, 2010b; Feng and Hirst, 2012).Soricut and Marcu (2003) use a standard bottom-up chart parsing algorithm to determine the dis-course structure of sentences.
Baldridge and Las-carides (2005) model the process of discourseparsing with the probabilistic head driven parsingtechniques.
Sagae (2009) apply a transition basedconstituent parsing approach to construct a RSTtree for a document.
Hernault et al (2010b) de-velop a greedy bottom-up tree building strategyfor discourse parsing.
The two adjacent textspans with the closest relations are combined ineach iteration.
As the extension of Hernault?swork, Feng and Hirst (2012) further explore var-ious features aiming to achieve better perfor-mance.
However, as analyzed in Section 1, thereexist three limitations with the constituencybased discourse representation and parsing.
Weinnovatively adopt the dependency structure,which can be benefited from the existing RST-DT, to represent the discourse.
To the best of ourknowledge, this work is the first to apply de-pendency structure and dependency parsingtechniques in discourse analysis.7 ConclusionsIn this paper, we present the benefits and feasi-bility of applying dependency structure in text-level discourse parsing.
Through the correspond-ence between constituency-based trees and de-pendency trees, we build a discourse dependencytreebank by converting the existing RST-DT.Based on dependency structure, we are able todirectly analyze the relations between the EDUswithout worrying about the additional interiortext spans, and apply the existing state-of-the-artdependency parsing techniques which have arelatively low time complexity.
In our work, weuse the graph based dependency parsing tech-niques learned from the annotated dependencytrees.
The Eisner algorithm and the MST algo-rithm are applied to parse the optimal projectiveand non-projective dependency trees respectivelybased on the arc-factored model.
To calculate thescore for each arc, six types of features are ex-plored to represent the arcs and the featureweights are learned based on the MIRA learningtechnique.
Experimental results exhibit the effec-tiveness of the proposed approaches.
In the fu-ture, we will focus on non-projective discoursedependency parsing and explore more effectivefeatures.AcknowledgmentsThis work was partially supported by NationalHigh Technology Research and DevelopmentProgram of China (No.
2012AA011101), Na-tional Key Basic Research Program of China (No.2014CB340504), National Natural ScienceFoundation of China (No.
61273278), and Na-tional Key Technology R&D Program (No:2011BAH10B04-03).
We also thank the threeanonymous reviewers for their helpful comments.33ReferencesJason Baldridge and Alex Lascarides.
2005.
Probabil-istic Head-driven Parsing for Discourse Structure.In Proceedings of the Ninth Conference on Com-putational Natural Language Learning, pages 96?103.Steven Bird, Ewan Klein, and Edward Loper.
2009.Natural Language Processing with Python ?
Ana-lyzing Text with the Natural Language Toolkit.O?Reilly.Lynn Carlson, Daniel Marcu, and Mary E. Okurowski.2001.
Building a Discourse-tagged Corpus in theFramework of Rhetorical Structure Theory.
Pro-ceedings of the Second SIGdial Workshop on Dis-course and Dialogue-Volume 16, pages 1?10.Yoeng-Jin Chu and Tseng-Hong Liu.
1965.
On theShortest Arborescence of a Directed Graph, Sci-ence Sinica, v.14, pp.1396-1400.Koby Crammer and Yoram Singer.
2003.
Ultracon-servative Online Algorithms for Multiclass Prob-lems.
JMLR.Jack Edmonds.
1967.
Optimum Branchings, J. Re-search of the National Bureau of Standards, 71B,pp.233-240.Jason Eisner.
1996.
Three New Probabilistic Modelsfor Dependency Parsing: An Exploration.
In Proc.COLING.Vanessa Wei Feng and Graeme Hirst.
Text-level Dis-course Parsing with Rich Linguistic Features, Pro-ceedings of the 50th Annual Meeting of theAssociation for Computational Linguistics, pages60?68, Jeju, Republic of Korea, 8-14 July 2012.Hugo Hernault, Danushka Bollegala, and MitsuruIshizuka.
2010a.
A Semi-supervised Approach toImprove Classification of Infrequent Discourse Re-lations Using Feature Vector Extension.
In Pro-ceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, pages399?409, Cambridge, MA, October.
Associationfor Computational Linguistics.Hugo Hernault, Helmut Prendinger, David A. duVerle,and Mitsuru Ishizuka.
2010b.
HILDA: A DiscourseParser Using Support Vector Machine Classifica-tion.
Dialogue and Discourse, 1(3):1?33.Shafiq Joty, Giuseppe Carenini and Raymond T. Ng.A Novel Discriminative Framework for Sentence-level Discourse Analysis.
EMNLP-CoNLL '12Proceedings of the 2012 Joint Conference on Em-pirical Methods in Natural Language Processingand Computational Natural Language LearningStroudsburg, PA, USA.Huong LeThanh, Geetha Abeysinghe, and ChristianHuyck.
2004.
Generating Discourse Structures forWritten Texts.
In Proceedings of the 20th Interna-tional Conference on Computational Linguistics,pages 329?
335.Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng.
2009.Recognizing Implicit Discourse Relations in thePenn Discourse Treebank.
In Proceedings of the2009 Conference on Empirical Method in NaturalLanguage Processing, Vol.
1, EMNLP?09, pages343-351.William Mann and Sandra Thompson.
1988.
Rhetori-cal Structure Theory: Toward a Functional Theoryof Text Organization.
Text, 8(3):243?281.Daniel Marcu.
2000.
The Theory and Practice of Dis-course Parsing and Summarization.
MIT Press,Cambridge, MA, USA.Ryan McDonald, Koby Crammer, and Fernando Pe-reira.
2005a.
Online Large-Margin Training of De-pendency Parsers, 43rd Annual Meeting of theAssociation for Computational Linguistics (ACL2005) .Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005b.
Non-projective DependencyParsing using Spanning Tree Algorithms, Proceed-ings of HLT/EMNLP 2005.Emily Pitler, Annie Louis, and Ani Nenkova.
2009.Automatic Sense Prediction for Implicit DiscourseRelations in Text, In Proc.
of the 47th ACL.
pages683-691.Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, AlanLee, Aravind Joshi, Livio Robaldo, and BonnieWebber.
2007.
The Penn Discourse Treebank 2.0Annotation Manual.
The PDTB Research Group,December.David Reitter.
2003.
Simple Signals for ComplexRhetorics: On Rhetorical Analysis with Rich-feature Support Vector Models.
LDV Forum,18(1/2):38?52.Kenji Sagae.
2009.
Analysis of discourse structurewith syntactic dependencies and data-driven shift-reduce parsing.
In Proceedings of the 11th Interna-tional Conference on Parsing Technologies, pages81-84.Radu Soricut and Daniel Marcu.
2003.
Sentence leveldiscourse parsing using syntactic and lexical in-formation.
In Proceedings of the 2003 Conference34of the North American Chapter of the Associationfor Computational Linguistics on Human Lan-guage Technology, Volume 1, pages 149?156.Rajen Subba and Barbara Di Eugenio.
2009.
An effec-tive discourse parser that uses rich linguistic in-formation.
In Proceedings of Human LanguageTechnologies: The 2009 Annual Conference of theNorth American Chapter of the Association forComputational Linguistics, pages 566?574.Robert Endre Tarjan, 1977.
Finding OptimumBranchings, Networks, v.7, pp.25-35.Ben Taskar, Carlos Guestrin and Daphne Koller.
2003.Max-margin Markov Networks.
In Proc.
NIPS.Bonnie Webber.
2004.
D-LTAG: Extending Lexical-ized TAG to Discourse.
Cognitive Science,28(5):751?779.Wen Ting Wang, Jian Su and Chew Lim Tan.
2010.Kernel based Discourse Relation Recognition withTemporal Ordering Information, In Proc.
ofACL?10.
pages 710-719.Ben Wellner, James Pustejovsky, Catherine Havasi,Anna Rumshisky and Roser Sauri.
2006.
Classifi-cation of Discourse Coherence Relations: an Ex-ploratory Study Using Multiple KnowledgeSources.
In Proc.of the 7th SIGDIAL Workshop onDiscourse and Dialogue.
pages 117-125.35
