INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 146?149,Utica, May 2012. c?2012 Association for Computational LinguisticsContent Selection From Semantic Web DataNadjet Bouayad-Agha1Gerard Casamayor1Leo Wanner1,21DTIC, University Pompeu Fabra2Institucio?
Catalana de Recerca i Estudis Avanc?atsBarcelona, Spainfirstname.lastname@upf.eduChris MellishComputing ScienceUniversity of AberdeenAberdeen AB24 3UE, UKc.mellish@abdn.ac.ukAbstractSo far, there has been little success in NaturalLanguage Generation in coming up with gen-eral models of the content selection process.Nonetheless, there has been some work oncontent selection that employ Machine learn-ing or heuristic search.
On the other side, thereis a clear tendency in NLG towards the use ofresources encoded in standard Semantic Webrepresentation formats.
For these reasons, webelieve that time has come to propose an initialchallenge on content selection from SemanticWeb data.
In this paper, we briefly outline theidea and plan for the execution of this task.1 MotivationSo far, there has been little success in Natural Lan-guage Generation in coming up with general mod-els of the content selection process.
Most of theresearchers in the field agree that this lack of suc-cess is because the knowledge and context (commu-nicative goals, user profile, discourse history, query,etc) needed for this task depend on the applicationdomain.
This often led in the past to template-or graph-based combined content selection and dis-course structuring approaches operating on idiosyn-cratically encoded small sets of input data.
Fur-thermore, in many NLG-applications, target textsand sometimes even empirical data are not avail-able, which makes it difficult to employ empiricalapproaches to knowledge elicitation.
Nonetheless,during the last decade, there has been a steady flowof new work on content selection that employed Ma-chine learning (Barzilay and Lapata, 2005; Duboueand McKeown, 2003; Jordan and Walker, 2005;Kelly et al, 2009), heuristic search (O?Donnell etal., 2001; Demir et al, 2010; Mellish and Pan,2008), or a combination thereof (Bouayad-Agha etal., 2011).
All of these strategies can deal with largevolumes of data.On the other side, there is a clear tendency in NLGtowards the use of resources encoded in terms ofstandard Semantic Web representation formats suchas OWL and RDF, e.g., (Wilcock and Jokinen, 2003;Bontcheva and Wilks, 2004; Mellish and Pan, 2008;Power and Third, 2010; Bouayad-Agha et al, 2011;Dannells et al, 2012), to name but a few.
However,although most of these works make a good attemptat realisation, the problem of content determinationfrom Semantic Web data is relatively untouched.For these reasons, we believe that the time hascome to bring together researchers working on (orinterested in working on) content selection to par-ticipate in a challenge for this task using standardfreely available web data as input.
The availabilityof open modular multi-domain multi-billion tripledata and of open ontological resources (Bizer et al,2009) presented in a standard knowledge represen-tation formalism make semantic web data a naturalchoice for such a challenge.As will be presented below, this initial challengepresents a relatively simple content selection taskwith no user model and a straightforward commu-nicative goal so that people are encouraged to takepart and motivated to stay on for later challenges, inwhich the task will be successively enhanced fromgained experience.A content determination challenge would be achance to (i) directly compare the performance of146different types of content selection strategies; (ii)contribute towards developing a standard ?off-the-shelf?
content selection module; and (iii) contributetowards a standard interface between text planningand linguistic generation.To get the widest reception possible, the challengewill be open to any approach, be it template-, rule-or heuristic-based, or empirical.
Furthermore, it willbe advertised in the Semantic Web Community toget contributors from other horizons, see, e.g., (Daiet al, 2010).In what follows, we briefly outline the idea andplan for the execution of the challenge.
In Section 2,we outline a description of the task.
In Section 3,the data and domain that will be used are presented.Section 4 describes how this data is to be preparedfor the task, and Section 5 how it will be released tothe participants.
In Section 6, we sketch the eval-uation including the preparation of the evaluationdataset.
Section 7 gives a proposed schedule foreach of the tasks involved in organizing the chal-lenge.
Finally, in Section 8, we provide short bi-ographies of the members of the organization team,focusing on their experience in the proposed task.2 Task DescriptionThe core of the task to be addressed can be formu-lated as follows:Build a system which, given a set of RDFtriples containing facts about a celebrityand a target text (for instance, a wikipedia-style article about that person), selectsthose triples that are reflected in the targettext.The participants are also free to consider the se-mantics defined by the data sources in their ap-proach, rely on additional resources like ontologiesfrom other sources, or disregard the semantics com-pletely.The implemented system should output its resultsin a predefined standard format that can be used forautomatic evaluation.It could be that the RDF data does not contain ev-erything that would ideally be included in such anarticle, but that is ignored here.
The task consists inselecting content that is communicated in the targettext.3 The dataThe domain will be constituted by short biographiesof famous people.
This is an interesting domain forthe challenge because Semantic Web data and corre-sponding texts for this domain are available in largequantities (e.g., DBPedia or Freebase for the dataand many other sources for biography texts, amongthem Wikipedia).The data will consist, for each famous person, ofa pair of RDF-triple set and associated text(s).
Foreach pair, the RDF data will include both informa-tion communicated and excluded from the text.
Thetext may convey information not present in the RDF-triples, but this will be kept to a minimum, alwayssubject to using naturally-occurring texts.
All pairsshould contain enough RDF-triples and text to makethe pair interesting for the content selection task.When choosing data for the challenge, we willprefer semantic contents classified under consistentontologies over plain Linked Data with no explicitsemantics.
The semantics of the RDF data (vocab-ularies, ontologies) will be provided, preferably en-coded in Semantic Web standards (e.g., in RDFS orOWL).4 Data PreparationThe task of data preparation consists in 1) data gath-ering and preparation, which is to be carried out bythe organizers, and 2) working dataset selection andannotation, which is to be carried out by both theorganizers and participants.4.1 Data gathering and preparationThis preparatory stage consists in choosing therepository sources, downloading the relevant on-tologies (to the extent those will be provided), anddownloading and pairing the data and associatedtexts (= the paired corpus).4.2 Working Dataset selection and annotationThe participants will be asked to participate in a pre-liminary task consisting in marking which triples areincluded in the text given a subset of the paired cor-pus (the size of the subset still has to be decided).This task could be supported by some automaticanchoring techniques such as used in (Duboue andMcKeown, 2003; Barzilay and Lapata, 2005).
The147objectives of the task are threefold: (1) to provide allparticipants with a common set of ?correct answers?to be exploited in their approach, (2) to familiarizethe participants with the nature of the contents, theirsemantics and the texts, and (3) to provide the taskwith a ceiling for the evaluation, i.e.
inter-annotatoragreement.Annotation guidelines will be needed to ensurethat all participants follow the same procedure whenannotating texts.
For this purpose, an early docu-ment will be produced detailing the procedure to-gether with examples and descriptions of relevantproblems such as ambiguities in the annotation.
Theguidelines will be improved in multiple stages of an-notation and revision with the goal of maximizinginter-annotator agreement.5 Data releaseThe participants in the challenge will be given ac-cess to the set of all correct answers and a largeportion of the non-marked paired corpus, as well astheir semantics (i.e., ontologies and the like).
Theremaining unseen, non-marked set will be kept forevaluation.6 EvaluationThe evaluation consists of 1) a preparatory stage forselecting and annotating the evaluation dataset, and2) an evaluation stage.6.1 Evaluation dataset selection and annotationOnce all participants have submitted their exe-cutable to solve the task, the evaluation set will beprocessed.
If timing is tight, however, this could bedone whilst the participants are still working on thetask or extra effort (for instance, from the organiz-ers) could be brought in.
A subset of the data israndomly selected and annotated with the selectedtriples by the participants.
This two-stage approachto triple selection annotation is proposed in order toavoid any bias on the evaluation data.6.2 EvaluationEach executable is run against the test corpus and theselected triples evaluated against the gold triple se-lection set.
Since this is formally a relatively simpletask of selecting a subset of a given set, we will usefor evaluation standard precision, recall and F mea-sures.
In addition, other appropriate metrics will beexplored?for instance, certain metrics for extrac-tive summarisation (which is to some extent a simi-lar task).The organizers will explore whether it will be fea-sible to select and annotate some test examples froma different corpus and have the systems evaluated onthese as a separate task.7 ScheduleTable 1 presents the different tasks, protagonists andthe schedule involved in the organization of the chal-lenge.
The challenge proper will take place betweenNovember 2012 and May/June 2013.8 OrganizersNadjet Bouayad-Agha has been a lecturer and re-searcher at DTIC, UPF, since 2002.
She obtainedher PhD on Text Planning in 2001 from the Univer-sity of Brighton and has been working ever since herpostgraduate studies at the University of Paris VII inNLG, more specifically on Text Planning.
In recentyears her focus has been on how to exploit semanticweb representations and technologies for Text Plan-ning in general and content selection in particular.Gerard Casamayor is a PhD student at DTIC,UPF, working on text planning from general-purpose semantic data.
His main interests are ma-chine learning and interactive, collaborative textplanning.
As part of his thesis, he is developing atext planning approach that can be trained directlyby domain experts, minimizing the need of encodingor annotating prior knowledge about how to solvethe task.Chris Mellish has been a professor at the Univer-sity of Aberdeen since 2003, when he moved from asimilar position at the University of Edinburgh.
Hehas been doing research in NLG since 1984 and or-ganised the second European NLG workshop.
Hiswork on content selection includes the opportunis-tic planning approach used by the ILEX system anda rule-based approach to content selection from se-mantic web data presented in ENLG 2011.Leo Wanner has been ICREA Research Profes-sor at DTIC, UPF, since 2005.
Before, he was148What?
Who?
When?Data gathering and preparation Organizers Summer 2012Working dataset selection and annotation Organizers and Participants Sept/Oct 2012Data Release Organizers November 2012Evaluation dataset selection and annotation Organizers and Participants May 2013Evaluation Organizers June 2013Publication@INLG Organizers August 2013Table 1: Content Selection Challenge Organization Scheduleaffiliated as Assistant Professor with the Univer-sity of Stuttgart.
Wanner is involved in researchon multilingual text generation since the late 80ies.Among his research foci are user-oriented con-tent selection and the interface between language-independent ontology-based and linguistic represen-tations in text generation.ReferencesRegina Barzilay and Mirella Lapata.
2005.
Collec-tive Content Selection for Concept-to-Text Genera-tion.
Proceedings of the Joint Human Language Tech-nology and Empirical Methods in Natural LanguageProcessing Conferences (HLT/EMNLP-2005) Van-couver, Canada.Christian Bizer, Tom Heath and Tim Berners-Lee 2009.Linked Data - The Story So Far.
International Journalon Semantic Web and Information Systems 5(3) 1?22Kalina Bontcheva and Yorick Wilks 2004.
AutomaticReport Generation from Ontologies: the MIAKT ap-proach Nineth International Conference on Appli-cations of Natural Language to Information Systems(NLDB?2004) 324?335.Nadjet Bouayad-Agha, Gerard Casamayor and Leo Wan-ner.
2011.
Content selection from an ontology-basedknowledge base for the generation of football sum-maries Proceedings of the 13th European Workshopon Natural Language Generation (ENLG?2011) 72?81 Nancy, France.Yintang Dai, Shiyong Zhang, Jidong Chen, TianyuanChen and Wei Zhang.
2010 Semantic Network Lan-guage Generation based on a Semantic Networks Seri-alization Grammar World Wide Web 13:307341Dana Danne?lls, Mariana Damova, Ramona Enache andMilen Chechev.
2012 Multilingual Online Genera-tion from Semantic Web Ontologies Proceedings ofthe 21st International Conference on World Wide Web(WWW?12) 239?242Seniz Demir, Sandra Carberry and Kathleen F. McCoy.2010.
A Discourse-Aware Graph-Based Content-Selection Framework.
Proceedings of the Interna-tional Language Generation Conference.
Sweden.Pablo A. Duboue and Kathleen R. McKeown.
2003.
Sta-tistical Acquisition of Content Selection Rules for Nat-ural Language Generation.
Proceedings of the 2003conference on Empirical Methods in Natural Lan-guage Processing (EMNLP).
Sapporo, Japan.Dimitrios Galanis and Ion Androutsopoulos.
2007.
Gen-erating Multilingual Personalized Descriptions fromOWL Ontologies on the Semantic Web: the Natu-ralOWL System.
Proceedings of the Eleventh Eu-ropean Workshop on Natural Language Generation(ENLG07)Pamela W. Jordan and Marilyn A. Walker 2005 Learningcontent selection rules for generating object descrip-tions in dialogue Journal of Artificial Intelligence Re-search 24, 157?194.Colin Kelly, Ann Copestake, and Nikiforos Karamanis.2009 Investigating content selection for language gen-eration using machine learning.
Proceedings of the12th European Workshop on Natural Language Gen-eration.. 130?137.Chris Mellish and Jeff Z. Pan.
2008 Language Di-rected Inference from Ontologies.
Artificial Intelli-gence.
172(10):1285-1315.Mick ODonnell, Chris Mellish, Jon Oberlander, and Alis-tair Knott.
2001.
ILEX: an architecture for a dynamichypertext generation system.
Natural Language Engi-neering.
7(3):225?250.Richard Power and Allan Third 2010 Expressing OWLaxioms by English sentences: dubious in theory, fea-sible in practice Proceedings of the 23rd Interna-tional Conference on Computational Linguistics (CI-CLING?01).
1006?1013.Graham Wilcok and Kristiina Jokinen 2003 Generat-ing Responses and Explanations from RDF/XML andDAML+OIL.
IJCAI03 Workshop on Knowledge andReasoning in Practical Dialogue Systems.
58?63.149
