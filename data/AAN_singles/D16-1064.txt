Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 669?679,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsExploring Semantic Representation in Brain ActivityUsing Word EmbeddingsYu-Ping Ruan1, Zhen-Hua Ling1 and Yu Hu1,21National Engineering Laboratory for Speech and Language Information ProcessingUniversity of Science and Technology of China, Hefei, China2iFLYTEK Research, Hefei, Chinaypruan@mail.ustc.edu.cn, zhling@ustc.edu.cn, yuhu@iflytek.comAbstractIn this paper, we utilize distributed word rep-resentations (i.e., word embeddings) to anal-yse the representation of semantics in brainactivity.
The brain activity data were recordedusing functional magnetic resonance imaging(fMRI) when subjects were viewing words.First, we analysed the functional selectivity ofdifferent cortex areas by calculating the corre-lations between neural responses and severaltypes of word representations, including skip-gram word embeddings, visual semantic vec-tors, and primary visual features.
The resultsdemonstrated consistency with existing neu-roscientific knowledge.
Second, we utilizedbehavioural data as the semantic ground truthto measure their relevance with brain activity.A method to estimate word embeddings underthe constraints of brain activity similarities isfurther proposed based on the semantic wordembedding (SWE) model.
The experimentalresults show that the brain activity data are sig-nificantly correlated with the behavioural dataof human judgements on semantic similarity.The correlations between the estimated wordembeddings and the semantic ground truthcan be effectively improved after integratingthe brain activity data for learning, whichimplies that semantic patterns in neural rep-resentations may exist that have not been fullycaptured by state-of-the-art word embeddingsderived from text corpora.1 IntroductionRecently, the topic of exploring semantic represen-tation in human brain has attracted the attention ofresearchers from both neuroscience and computa-tional linguistics fields.
In these studies, conceptsare represented in terms of neural activation patternsin the brain that can be recorded by functionalmagnetic resonance imaging (fMRI) (Haxby et al,2001).
It has been found that the semantic spaceshared among different individuals is distributedcontinuously across the cortex (Huth et al, 2012).A recent study proposed an efficient way to measureand visualize the semantic selectivity of differentcortex areas (Huth et al, 2016).Similar to the distributed semantic representationin the brain, describing the meaning of a wordusing a dense low-dimensional and continuous vec-tor (i.e., word embedding) is currently a popularapproach in computational linguistics (Hinton etal., 1986; Turney et al, 2010).
Word embeddingsare commonly estimated from large text corporautilizing statistics concerning the co-occurrencesof words (Mikolov et al, 2013a; Mikolov et al,2013b; Pennington et al, 2014).
To investigatethe correlation between word embeddings and thebrain activity involved in viewing words, Mitchellet al (2008) designed a computational model topredict brain responses using hand-tailored wordembeddings as input.
Further, Fyshe et al (2014)proposed a joint non-negative sparse embedding(JNNSE) method to combine fMRI data and textualdata to estimate word embeddings.
This workimproved the correlation between word embeddingsand human behavioural data, which lends supportto the view that fMRI data can provide additionalsemantic information that may not exist in textualdata.669The factors that can influence the activities ofcortex areas are diverse.
Recent studies show that vi-sual semantic features such as bag-of-visual-words(BoVW) are significantly correlated with the fMRIdata captured when viewing words (Anderson et al,2013).
The primary visual features derived usingGabor wavelets can be used to determine the imagespresented to the subjects from their recorded brainactivity (Kay et al, 2008; Naselaris et al, 2009).Some other research work also indicates that visualexperiences (Nishimoto et al, 2011) and speechinformation (Ryali et al, 2010) can affect neuralresponses in cortex areas.In this paper, we first study the semantic repre-sentation of words in brain activity by correlationanalysis (Anderson et al, 2013; Carlson et al,2014).
Then, we calculate the correlations betweensubjects?
neural responses when viewing words andthree types of word representations: skip-gram wordembeddings, primary visual features, and visualsemantic vectors.
The goal of doing this is to in-vestigate whether these representations can accountfor the brain data and the functional selectivity ofdifferent cortex areas.
Then, we utilize behaviouraldata as the semantic ground truth to measure thesemantic relevance of brain activity.
A method ofestimating word embeddings within the constraintsof similar brain activities is proposed.
This methodis based on the semantic word embedding (SWE)model (Liu et al, 2015) which develops from theskip-gram model.
It aims at verifying whether textu-al data and brain activity data can be complementaryto derive word embeddings that are more consistentwith human judgement.The contributions of this study are twofold.
First,this study involved a comprehensive correlationanalysis on brain activity data and state-of-the-artskip-gram word embeddings at both whole-brainand brain lobe levels.
Primary visual featuresand visual semantic vectors are also introducedas auxiliary representations to better understandthe functional selectivity across the cortex.
Someresults of this analysis are interpretable usingexisting neuroscience knowledge.
Second, to ourknowledge, this study marks the first attempt tointegrate brain activity data into the skip-grammodel for estimating word embeddings.
Theexperimental results show that the correlationbetween the estimated word embeddings and thebehavioural measure of semantics can be effectivelyimproved after integrating brain activity data forlearning.2 Related workThe correlation between brain data and word vectorshas been studied in previous work.
The experimentsin Carlson et al (2014) adopted brain activity datafor correlation analysis from only the ventral tempo-ral pathway, not from the whole brain.
Anderson etal.
(2013) performed correlation analysis using thevoxels of the whole brain and compared the HAL-based textual semantic model (Lund and Burgess,1996) with the BoVW-based visual semantic model(Sivic and Zisserman, 2003; Csurka et al, 2004) interms of these two model?s ability to account forthe patterns found in the neural data.
However,the experiments in Anderson et al (2013) failed todetect differential interactions of semantic modelswith brain areas.
In this paper, considering thepopularity of word embedding estimation approach-es based on neural networks in recent years, weadopt skip-gram word embeddings (Mikolov et al,2013a) for correlation analysis.
To our knowledge,this is the first time that the association betweenskip-gram word embeddings and brain activity datahave been studied.
Furthermore, our work improveson the voxel selection strategy used in Andersonet al (2013), leading to more interpretable resultswhen demonstrating the functional selectivity ofbrain areas.To our knowledge, the first and only attemptto integrate brain activity data into the acquisitionof textual word embedding is the JNNSE method(Fyshe et al, 2014).
In this method, word em-beddings were estimated as latent representationsusing matrix factorization.
The objective functionscontained additional constraints for reconstructingbrain activity data.
In this paper, we adopt theSWE model (Liu et al, 2015) to incorporate brainactivity knowledge into word embedding estimation.The SWE model was developed from the skip-grammodel.
In SWE, semantically related knowledgeis converted into inequality constraints for learningword embeddings.
The experimental results showthat our proposed method using SWE can improve670the semantic consistency between word embeddingsand human judgements.3 From Skip-Gram to SWE3.1 Skip-gram modelThe skip-gram model (Mikolov et al, 2013b) adoptsa neural network structure to derive the distributedrepresentation of words from textual corpus.
Theword vectors are learned based on the distribution-al hypothesis (Harris, 1954; Miller and Charles,1991), which assumes that words with similar con-texts tend to have similar semantic meanings.
Fora sequence of training data of T words, denotedas {w1, w2, w3, ?
?
?
, wT }, the skip-gram model istrained to maximize the following objective functionQ = 1TT?t=1?
?c?j?c,j 6=0log p(wt+j |wt), (1)where wt and ww+j are the central word and neigh-bouring words in a context window respectively, andc denotes the size of the context window.
The condi-tional probability p(wt+j |wt) in Eq.
(1) is calculatedasp(wt+j |wt) =exp(w(2)t+j ?
w(1)t )?Vk=1 exp(w(2)k ?
w(1)t ), (2)where w(1)t and w(2)k denote row vectors in thematrices W(1) and W(2) respectively, and V isthe vocabulary size of the corpus.
The matrixW(1) stores the word vectors of input central words,and the matrix W(2) stores the word vectors ofpredicted neighbouring words.
The optimization ofthe objective function Q is solved by the stochasticgradient descent (SGD) method (Mikolov et al,2013b).
Finally, the learned matrix W(1) is used asthe estimated word embeddings of all words in thevocabulary.3.2 Semantic word embedding (SWE)The skip-gram model learns word embeddingsbased on the distributional hypothesis; however, thishypothesis still has some limitations.
For example,antonyms often appear in similar contexts althoughthey have opposite meanings.
The semantic wordembedding (SWE) model (Liu et al, 2015) hasbeen proposed to address this issue by incorporatingexternal semantic knowledge into the text-basedlearning process for word embeddings.In this method, semantic knowledge is repre-sented as a set of ranking inequalities.
Each in-equality contains a triplet (i, j, k) of three words{wi, wj , wk} with a similarity relationsimilarity(wi, wj) > similarity(wi, wk), (3)which can be notated in simplified form as sij > sik.Then, the learning method of SWE is defined as thefollowing constrained optimization problem{W(1),W(2)} = arg maxW(1),W(2)Q(W(1),W(2)),s.t.
sij > sik,?
(i, j, k) ?
S, (4)where function Q is defined in Eq.
(1) and Sdenotes the inequality set.
Then, the constrainedoptimization problem in Eq.
(4) is simplified intoan unconstrained problem by introducing a penaltyterm into the objective function of the skip-grammodel.
The penalty term is defined asD =?
(i,j,k)?Sf(i, j, k), (5)where f(i, j, k) = max(0, sik ?
sij) is a Hingeloss function.
Finally, the object function to bemaximized in SWE can be written as follows:Q?
= Q?
?
?D, (6)where ?
is a parameter to control the contributionof the penalty term.
Similar to the skip-gram model,theQ?
function in the SWE model is optimized usingSGD to estimate word embeddings.
The detailedformulae can be found in Liu et al (2015).3.3 Integrating brain activity into SWEIn the implementation of the SWE model in Liu et al(2015), the ranking inequalities were collected us-ing hypernym-hyponym and synonym-antonym re-lationships extracted from WordNet (Fellbaum andothers, 1998).
In this paper, the SWE model isutilized as a tool to explore the semantic relevance ofbrain activity by examining the performance of theestimated word embeddings after integrating brain-activity-related knowledge.
Therefore, we construct671the ranking inequalities in Eq.
(3) using brainactivity data.
When a subject is viewing a word,the neural response in the cortex is captured usingfMRI and further stored as a vector.
After collectingthe fMRI data for a set of words, the inequalitiesin Eq.
(3) can be constructed by using a similaritymeasure on the neural response vectors of wordpairs.
Here, we adopt Pearson correlation as thesimilarity measure.
The details will be introducedin Section 5.1.4 Data4.1 Brain dataThe fMRI data used in our experiments was record-ed and preprocessed by Mitchell et al (2008).
Itincludes the recorded data of 9 subjects.
To recordthe data, each of 60 concrete nouns was presentedvisually to each subject with a textual label and asimple line drawing.
The subjects were asked tothink about the properties of the objects indicatedby the words during fMRI scanning.
This procedurerepeated 6 times, and the stimuli of the 60 nounswere presented in a random order in each run.
Moredetails about the data acquisition and preprocessingprocedures can be found in Mitchell et al (2008)and its supplement materials.
Finally, an fMRIvector measuring the neural response at all voxelsacross the cortex was created for each word and eachsubject.4.2 Behavioural dataThe behavioural data collects human judgements onthe semantic similarity between word pairs.
Theapproach to behavioural data collection in our exper-iment is similar to the one used in the WordSim-353dataset (Finkelstein et al, 2001).
For the 60 concretenouns used in Section 4.1, we obtained C260 =1, 770 word pairs.
Then, we asked 15 participantsto score the semantic similarity of each word pairon a scale from 0 to 10, in which ?0?
signifiedthat the two words were totally unrelated and ?10?signified that the two words were highly related orhad identical meanings.
This collection procedurewas conducted on the Amazon Mechanical Turk1crowdsourcing platform.
We tested the averageSpearman correlation coefficient among the scores1http://www.mturk.com/given by different annotators and found that it wasapproximately 0.4873 with a p-value of 1.1e-02.After gathering the scores for all the word pairs,the highest and lowest scores for each word pairwere discarded, and the average of the remaining 13scores was calculated as the similarity score for eachword pair2.To verify the reliability of the above data col-lection process, we also added 15 word pairs fromthe WordSim-353 dataset into our 1,770 word pairsduring score collection.
Then, we calculated thesimilarity scores of these 15 word pairs using thecollected scores and compared them with the scoresin the WordSim-353 dataset using Spearman cor-relation analysis.
The correlation coefficient was0.8451 with a p-value of 2.7e ?
04.
This highcorrelation verifies the reliability of our behaviouraldata collection.5 Experiments5.1 Correlations between brain activity andword vectorsWe calculated the correlations between the fMRIvectors and the different types of word represen-tations to investigate whether these representationscan account for the brain activity and the functionalselectivity of different cortex areas.
We adoptedthe method of representational similarity analysis(Kriegeskorte et al, 2008) in our experiments.
Fora specific word representation, we calculated thecosine similarity for each word pair in a set of nwords, resulting in a similarity vector with a totallength of C2n.
For the fMRI data3, we constructeda similarity vector for each subject using the Pear-son correlation coefficients between pairs of fMRIvectors (Anderson et al, 2013).
Then, the 9 vectorsof the 9 subjects were averaged to obtain an overallsimilarity vector in the fMRI space (Anderson etal., 2013).
Finally, the Spearman rank correlationcoefficient between the similarity vectors given bythe fMRI data and each word representation wascalculated together with a p-value for significance2The behavioural data are available at http://home.ustc.edu.cn/?ypruan/work/emnlp2016/behaviour_data/3Before using the fMRI data, we first regularized its meanvalue to 0 and variance to 1.672analysis.
The p-value was calculated using a per-mutation test under a positive hypothesis with theword pair labels randomly shuffled 10,000 times.Empirically, two similarity vectors are consideredto be correlated when p < 0.05, and they areconsidered significantly correlated when p < 0.01.5.1.1 Word vectorsThree types of word representations, i.e., skip-gram word embeddings, visual semantic vectors,and primary visual features, were used in thecorrelation analysis.
Some details about theacquisitions of these three word representations willbe introduced in the following paragraphs.Skip-gram word embeddings The Wikipediatext corpus4, containing 130 million words, wasadopted to train our skip-gram word embeddings,and the hierarchical softmax scheme was followed.The dimension of word embedding was 200.
Thewindow size, learning rate, and negative samplingnumber were set to 8, 0.05, and 8, respectively.
Themodel was trained for one iteration using a singleexecution thread.Visual semantic vectors On one hand, distributedword representations are usually learnt from textcorpora.
On the other hand, visual perception alsocontributes to semantic cognition according tosome neuroscience research (Louwerse, 2011), andit has been utilized to complement the semanticrepresentation learned from texts (Bruni et al,2012).
One approach to constructing visualsemantic vectors is to first extract the low-levelvisual features from images and then convert theminto higher-level semantic representations using thebag-of-visual-words (BoVW) (Grauman and Leibe,2011) model.
In our experiments, we built theBoVW representations from ImageNet (Deng et al,2009) using the VSEM5 toolkit.
Due to coveragelimitations, only 57 of the 60 concrete nounsin the fMRI data could be found in ImageNet6and each noun has approximately 1000 imagesamples.
Similar to Anderson et al (2013), weadopted the Scale Invariant Feature Transform4http://mattmahoney.net/dc/enwik9.zip5http://clic.cimec.unitn.it/vsem/6The three missing words are arm, eye and saw.
(SIFT) (Lowe, 2004) to extract lower-level visualfeatures; however, we did not use the ?object?box to discriminate ?object?
and ?context?
areasduring the extraction.
Then, we clustered the SIFTfeatures into 1000 classes to construct the visualvocabulary, and each image was divided into 8regions.
Thus, the BoVW representation of animage was a vector of 8000 dimensions.
The BoVWvectors of all images in ImageNet corresponding tothe same word were averaged to obtain the BoVWrepresentation of that word.
Finally, we transformedthe BoVW representation matrix of the 57 nouns tononnegative point-wise mutual information (PMI)association scores (Church and Hanks, 1990) toobtain the final visual semantic vectors.Primary visual features As introduced inSection 4.1, a line drawing of each word waspresented to subjects together with the textuallabel when collecting the fMRI data (Mitchellet al, 2008).
This presentation led to neuralresponses in visual cortices that may be irrelevantto semantic representation.
Because the receptivefields of simple cells in the primary visual cortexof mammalian brains can be modelled by Gaborfunctions (Marc?elja, 1980; Daugman, 1985), weadopted Gabor wavelets to extract the primary visualfeatures from the line drawings of the 60 nounsand further analysed their correlations with fMRIdata.
The original resolution of the image stimuliused in Mitchell et al (2008) was 500 x 500 pixels.These images were converted to 64 x 64 pixels aftertrimming the black borders and downsampling.The Gabor wavelet filter bank was designed usingan open source tool (Haghighat et al, 2015).
Thenumber of scales and orientations were set to 5 and8, respectively.
Thus, we represented the primaryvisual features of each noun as a vector of 163,840dimensions.
The singular value decomposition(SVD) technique was employed to reduce thedimension of each vector to 60.5.1.2 Correlation analysis at the whole-brainlevelThe fMRI recording measures the neural respons-es of more than 20,000 voxels across the cortex.
Toperform dimensionality reduction, we selected 500voxels from all voxels for each subject according to673word representation rho (p-value)skip-gram 0.0065 (4.0e-01)BoVW 0.3515 (0.0e-00)Gabor 0.3924 (0.0e-00)Table 1: Spearman?s rank correlation coefficients(rho) between different word representations andwhole-brain fMRI data for 57 nouns and theircorresponding p-values.Lobe Proportion (%)frontal 5.89temporal 6.96parietal 10.13occipital 58.40other 18.62Table 2: The proportions of the regional distribu-tions of the 500 selected voxels.the stability of the voxel responses across 6 runs offMRI recordings.
This selection strategy was thesame as the one used in Mitchell et al (2008) andAnderson et al (2013).
The correlation analysisfollowed the method described at the beginning ofSection 5.1.
Table 1 shows the results, where skip-gram, BoVW, and Gabor denote the skip-gram wordembeddings, visual semantic vectors, and primaryvisual features introduced above, respectively.As Table 1 shows, the visual semantic vectors andprimary visual features are significantly correlatedwith the fMRI vectors at the whole-brain level;however, the skip-gram word embeddings are notcorrelated with the fMRI data.
To investigate thereason for this lack of correlation, we analysed thedistribution of the 500 selected voxels across thefour brain lobes (i.e., frontal, temporal, parietal andoccipital) using the automated anatomical labelingscheme (Tzourio-Mazoyer et al, 2002).
From theresults shown in Table 2, we can find that most ofthe selected voxels are located in the occipital lobealthough it is the smallest of the four main lobesin the human brain.
The occipital lobe occupiesmost of the anatomical area of the visual cortex andis considered to be the visual processing centre ofthe mammalian brain.
This unbalanced distributionled to the conclusion that the semantic informationrelated to skip-gram word embeddings is not wellrepresented by the 500 selected voxels.
Thus, an al-ternative strategy to select stable voxels at the brainlobe level for correlation analysis was necessary.5.1.3 Correlation analysis at the brain lobelevelAs an alternative approach, rather than selectingthe 500 most stable voxels from the whole-braindata as in (Mitchell et al, 2008; Anderson et al,2013), we selected the 100 most stable voxels ateach of the four main brain lobes independently forthis experiment.
Then, the correlations between thefMRI vectors measuring different lobes and wordrepresentations were calculated and are shown inTable 3.From this table, we can observe the associationdifferences of different word representations withbrain lobe level activities.
First, the primary visualfeatures (Gabor) are highly correlated with the oc-cipital fMRI data and are uncorrelated with the otherthree lobes.
This is reasonable considering that theprimary visual cortex (V1) is located in the occipitallobe.
Second, the skip-gram word embeddings aresignificantly correlated with the fMRI data of allbrain lobes except the occipital lobe.
Previousneuroscience research has revealed that the frontal,temporal, and parietal lobes all play important rolesin semantic cognition, including high-level and ab-stract knowledge processing (Miller et al, 2002),integration of lexical information (Hagoort, 2005),speech comprehension (Hickok and Poeppel, 2007),and knowledge retrieval (Binder et al, 2009).
Thisindicates that the skip-gram word embeddings canpartly account for the semantic processing in thecortex and contain little visual information aboutwords.
Third, the visual sematic vectors (BoVW)are significantly correlated with all four brain lobes.It has been found that the temporal lobe plays akey role in both the formation of long-term visualmemories (Smith and Kosslyn, 2007) and in therecognition of visual stimuli and objects (Chao etal., 1999; Kanwisher and Yovel, 2006).
The parietallobe is relevant to high-level vision and is partof the dorsal visual stream correlated with spatialcognition (Sack, 2009; Vannini et al, 2004).
Thisindicates that the visual sematic vectors used in ourexperiment may contain not only low-level but alsohigh-level and semantically related visual informa-tion.674Frontal Temporal Parietal OccipitalSkip-gram 0.1450 (0.0e+00) 0.1483 (0.0e+00) 0.2317 (0.0e+00) -0.0385 (9.4e-01)BoVW 0.0601 (8.2e-03) 0.2053 (0.0e+00) 0.2750 (0.0e+00) 0.3120 (0.0e+00)Gabor -0.0823 (1.0e+00) -0.0879 (1.0e+00) 0.0111 (3.4e-01) 0.5116 (0.0e+00)Table 3: Spearman?s rank correlation coefficients (rho) between different word representations and the fMRIdata at four main brain lobes and their corresponding p-values.fMRI data rho (p-value)whole brain 0.1266 (0.0e+00)frontal lobe 0.0160 (2.5e-01)temporal lobe 0.0694 (1.7e-03)parietal lobe 0.0698 (1.6e-03)occipital lobe 0.0814 (4.0e-04)Table 4: Spearman?s rank correlation coefficients(rho) between the behaviour data and the fMRI dataof different brain lobes.5.2 Correlations between brain activity andbehavioural dataAfter analysing the correlation between brain activi-ty and the three types of word vectors in the previousexperiments, we further examined the correlationsbetween brain activity and the behavioural dataintroduced in Section 4.2.
Here, the behavioural datawere used as the semantic ground truth to evaluatethe semantic relevance of the brain activity and wordembeddings.
The results are shown in Table 4.
Inthis subsection, the fMRI data at the whole-brainand brain lobe levels adopted the voxel selectionstrategies introduced in Sections 5.1.2 and 5.1.3,respectively.
As Table 4 shows, the behavioural dataare significantly correlated with the fMRI data of thewhole brain and the occipital lobe, and they are alsocorrelated with the fMRI data of the temporal andparietal lobes.Furthermore, we utilized the SWE model in-troduced in Section 3.2 to explore the semanticrelevance of brain activity by examining the per-formance of the estimated word embeddings afterintegrating brain activity related knowledge.
Theinequality set used in Eq.
(3) was created using thefMRI data, where the similarity score sij was calcu-lated as the Pearson correlation coefficient betweenthe fMRI vectors of the i-th and the j-th words.
Forthe 60 nouns (a total of 12 categories with 5 wordsin each category), we produced 12?
3?
C35 = 360Figure 1: Spearman?s rank correlation coefficientsbetween the estimated word embeddings withdifferent ?
values and the behavioural data of twodatasets.intra-category inequalities and 3?C312 = 660 inter-category inequalities.
To collect the inter-categoryinequalities, we first used the label words of eachcategory and averaged the fMRI vectors of the 5words belonging to each category to obtain the fMRIdata for these label words.
Then, the inter-categoryinequalities were produced from the triplets of theselabel words.
The text corpus and parameter settingswe used to train SWE were the same as thoseused for training the skip-gram word embeddings asdescribed in Section 5.1.1.
The penalty term ?
inEq.
(6) was tuned through experiments.We evaluated the word embeddings estimatedwith brain activity constraints using the collectedbehavioural data for the 60 nouns and the WordSim-353 dataset.
WordSim-353 is a behavioural datasetcontaining semantic similarity scores for 353 word-pairs (Finkelstein et al, 2001).
We checked toensure these word-pairs have no overlap with the60 nouns used in our experiments.
The purposeof using the WordSim-353 dataset is to explore theeffects of utilizing the brain data of the 60 nouns onother words for which we had no brain data.67560 nouns WordSim353skip-gram 0.2232 0.6876SWE (whole brain) 0.3814 0.6878SWE (frontal) 0.3173 0.6822SWE (temporal) 0.3613 0.6890SWE (parietal) 0.3516 0.6706SWE (occipital) 0.3348 0.6803JNNSE 0.3006 0.1795Table 5: Spearman?s rank correlation coefficientsbetween different word embeddings and the be-havioural data of the two datasets.The performance of the word embeddings esti-mated using the SWE model and the whole-brainfMRI data are shown in Figure 1.
In this figure,the SWE model becomes a conventional skip-grammodel when ?
= 0.
The correlation coefficientbetween the skip-gram word embeddings and thebehavioural data of the 60 nouns was 0.2232.
As ?was increased, this correlation coefficient increasedsignificantly.
The maximum correlation efficientwas 0.3814 when ?
= 2.8.
This result impliesthat textual data and brain activity data can beused in a complementary fashion to derive wordembeddings that are more consistent with humanjudgements.
On one hand, semantic patterns mayexist in neural representations that have not beenfully captured by state-of-the-art word embeddingsderived from text corpora.
On the other hand, we cansee that the variation of the correlation coefficientsfor the WordSim-353 dataset with different ?
valuesis small.
This indicates that our SWE training did-n?t negatively affect the word embeddings withoutfMRI observations.Furthermore, we produced ranking inequalitiesusing the fMRI data measuring each brain lobe toestimate word embeddings under the SWE frame-work.
The correlations between the learned wordembeddings and the behavioural data of the twodatasets were calculated and are shown in Table 5.For each SWE model in this table, the value of ?was tuned to obtain the highest correlation on the60 nouns.
Comparing the correlation coefficients ofthe different models on the 60 nouns, we can seethat the fMRI data at all brain lobes can contributeto learning more semantically related word embed-dings using the SWE model.
The improvement fromusing the fMRI data of the temporal lobe is the mostsignificant among the four lobes, but the highestcorrelation coefficient is achieved when utilizing thefMRI data of whole brain.Finally, we compared the performance of ourSWE models with the JNNSE model proposedby Fyshe et al (2014) on the two datasets.
Theword embeddings estimated by the JNNSE modelutilized either fMRI or magnetoencephalography(MEG) measures of the 60 nouns.
We adoptedthe best JNNSE word embeddings reported by theauthors7 for these comparisons, and the resultsare shown in the last row of Table 58.
As Table5 shows, the performance of the JNNSE wordembeddings on the WordSim-353 dataset is not asgood as those of the skip-gram and SWE results.Examining the correlation coefficients on the 60nouns with brain activity data, we can see that theJNNSE model achieves better performance thanthe skip-gram model, but is still below that of theSWE models.
It should be noted that it is unfair todirectly compare the SWE models and the JNNSEmodel because they used different training corporaand word embedding dimensions.
Moreover, the ?values of the SWE models were tuned to achievethe best performance on these 60 nouns.
Here, themotivation behind introducing the JNNSE model asa reference is to help readers better understand theeffects of integrating brain data into SWE training.These experimental results demonstrate that theSWE model is an effective model structure forintegrating external knowledge into the estimationof word embeddings.6 ConclusionThis study utilized word embeddings to investigatethe semantic representations in brain activity asmeasured by fMRI.
First, the functional selectivityof different cortex areas is explored by calculatingthe correlations between neural responses and threetypes of word vectors: skip-gram word embeddings,visual semantic vectors, and primary visual features.7http://www.cs.cmu.edu/?afyshe/papers/acl2014/8Because there were 32 word-pairs in the WordSim-353dataset that were not covered by the vocabulary of the JNNSEword embeddings, the value 0.1795 in the last row of Table 5was calculated using only 321 word-pairs.676Experimental results demonstrate the differencesbetween the associations of different word vectorswith brain-lobe-level brain activities.
The skip-gram word embeddings are significantly correlatedwith the fMRI data of all brain lobes except theoccipital lobe.
Furthermore, we utilized behaviouraldata as the semantic ground truth to measure itsrelevance to brain activity.
The SWE model wasemployed to explore the semantic relevance of brainactivity by examining the performances of wordembeddings after integrating brain-activity-relatedknowledge into their estimations.
Experimentalresults show that whole-brain fMRI data are sig-nificantly correlated with human judgement withrespect to semantic similarity.
The correlationsbetween the estimated word embeddings and thehuman-assigned similarity scores are effectively im-proved after integrating brain activity data into SWEtraining.The experiments in this paper provide informationabout how semantic features correlate with brain ac-tivities, laying foundations for further investigationsof higher-level semantic processing in the humanbrain.
Furthermore, our experiments with SWEmodelling show the potential of applying fMRIdata to obtain better word embeddings.
Althoughthis approach is still far from being a practicalengineering application due to issues such as thehigh costs and low signal-to-noise ratio of fMRIrecordings and the diversity among individuals, itprovides us with an alternative method for verifyingthe semantic relevance of brain activities and withevidence for recognizing the limitations of estimat-ing word embeddings using only text corpora.AcknowledgementsThis work was supported in part by the Scienceand Technology Development of Anhui Province,China (Grant No.
2014z02006), the FundamentalResearch Funds for the Central Universities (GrantNo.
WK2350000001) and the CAS Strategic Prior-ity Research Program (Grant No.
XDB02070006).The authors also want to thank Quan Liu for his helpand wonderful suggestions during the experiments.References[Anderson et al2013] Andrew J Anderson, Elia Bruni,Ulisse Bordignon, Massimo Poesio, and MarcoBaroni.
2013.
Of words, eyes and brains: Correlatingimage-based distributional semantic models withneural representations of concepts.
In EMNLP, pages1960?1970.
[Binder et al2009] Jeffrey R Binder, Rutvik H Desai,William W Graves, and Lisa L Conant.
2009.Where is the semantic system?
a critical review andmeta-analysis of 120 functional neuroimaging studies.Cerebral Cortex, 19(12):2767?2796.
[Bruni et al2012] Elia Bruni, Jasper Uijlings, MarcoBaroni, and Nicu Sebe.
2012.
Distributionalsemantics with eyes: Using image analysis to improvecomputational representations of word meaning.
InProceedings of the 20th ACM international conferenceon Multimedia, pages 1219?1228.
ACM.
[Carlson et al2014] Thomas A Carlson, Ryan A Sim-mons, Nikolaus Kriegeskorte, and L Robert Slevc.2014.
The emergence of semantic meaning in theventral temporal pathway.
Journal of cognitiveneuroscience, 26(1):120?131.
[Chao et al1999] Linda L Chao, James V Haxby, andAlex Martin.
1999.
Attribute-based neural substratesin temporal cortex for perceiving and knowing aboutobjects.
Nature neuroscience, 2(10):913?919.
[Church and Hanks1990] Kenneth Ward Church andPatrick Hanks.
1990.
Word association norms,mutual information, and lexicography.
Computationallinguistics, 16(1):22?29.
[Csurka et al2004] Gabriella Csurka, Christopher Dance,Lixin Fan, Jutta Willamowski, and Ce?dric Bray.
2004.Visual categorization with bags of keypoints.
InWorkshop on statistical learning in computer vision,ECCV, pages 1?2.
Prague.
[Daugman1985] John G Daugman.
1985.
Uncertaintyrelation for resolution in space, spatial frequency,and orientation optimized by two-dimensional visualcortical filters.
JOSA A, 2(7):1160?1169.
[Deng et al2009] Jia Deng, Wei Dong, Richard Socher,Li-Jia Li, Kai Li, and Li Fei-Fei.
2009.
Imagenet: Alarge-scale hierarchical image database.
In ComputerVision and Pattern Recognition, 2009.
CVPR 2009.IEEE Conference on, pages 248?255.
IEEE.
[Fellbaum and others1998] Christiane Fellbaum et al1998.
Wordnet: An electronic lexical database mitpress.
Cambridge MA.
[Finkelstein et al2001] Lev Finkelstein, EvgeniyGabrilovich, Yossi Matias, Ehud Rivlin, ZachSolan, Gadi Wolfman, and Eytan Ruppin.
2001.Placing search in context: The concept revisited.
In677Proceedings of the 10th international conference onWorld Wide Web, pages 406?414.
ACM.
[Fyshe et al2014] Alona Fyshe, Partha P Talukdar, BrianMurphy, and Tom M Mitchell.
2014.
Interpretablesemantic vectors from a joint model of brain-and text-based meaning.
In Proceedings of the conference.Association for Computational Linguistics.
Meeting,volume 2014, page 489.
NIH Public Access.
[Grauman and Leibe2011] Kristen Grauman and BastianLeibe.
2011.
Visual object recognition.
Synthesis lec-tures on artificial intelligence and machine learning,5(2):1?181.
[Haghighat et al2015] Mohammad Haghighat, SamanZonouz, and Mohamed Abdel-Mottaleb.
2015.
Clou-did: Trustworthy cloud-based and cross-enterprisebiometric identification.
Expert Systems with Appli-cations, 42(21):7905?7916.
[Hagoort2005] Peter Hagoort.
2005.
On broca, brain,and binding: a new framework.
Trends in cognitivesciences, 9(9):416?423.
[Harris1954] Zellig S Harris.
1954.
Distributionalstructure.
Word, 10(2-3):146?162.
[Haxby et al2001] James V Haxby, M Ida Gobbini,Maura L Furey, Alumit Ishai, Jennifer L Schouten,and Pietro Pietrini.
2001.
Distributed and overlappingrepresentations of faces and objects in ventral temporalcortex.
Science, 293(5539):2425?2430.
[Hickok and Poeppel2007] Gregory Hickok and DavidPoeppel.
2007.
The cortical organization of speechprocessing.
Nature Reviews Neuroscience, 8(5):393?402.
[Hinton et al1986] Geoffrey E Hinton, James L Mcclel-land, and David E Rumelhart.
1986.
Distributedrepresentations, parallel distributed processing: ex-plorations in the microstructure of cognition, vol.
1:foundations.
[Huth et al2012] Alexander G Huth, Shinji Nishimoto,An T Vu, and Jack L Gallant.
2012.
A continuoussemantic space describes the representation of thou-sands of object and action categories across the humanbrain.
Neuron, 76(6):1210?1224.
[Huth et al2016] Alexander G Huth, Wendy A de Heer,Thomas L Griffiths, Fre?de?ric E Theunissen, andJack L Gallant.
2016.
Natural speech reveals thesemantic maps that tile human cerebral cortex.
Nature,532(7600):453?458.
[Kanwisher and Yovel2006] Nancy Kanwisher and GalitYovel.
2006.
The fusiform face area: a cortical regionspecialized for the perception of faces.
PhilosophicalTransactions of the Royal Society of London B:Biological Sciences, 361(1476):2109?2128.
[Kay et al2008] Kendrick N Kay, Thomas Naselaris,Ryan J Prenger, and Jack L Gallant.
2008.
Identifyingnatural images from human brain activity.
Nature,452(7185):352?355.
[Kriegeskorte et al2008] Nikolaus Kriegeskorte, MariekeMur, and Peter A Bandettini.
2008.
Representationalsimilarity analysis-connecting the branches of systemsneuroscience.
Frontiers in systems neuroscience, 2:4.
[Liu et al2015] Quan Liu, Hui Jiang, Si Wei, Zhen-HuaLing, and Yu Hu.
2015.
Learning semantic wordembeddings based on ordinal knowledge constraints.Proceedings of ACL, Beijing, China.
[Louwerse2011] Max M Louwerse.
2011.
Symbolinterdependency in symbolic and embodied cognition.Topics in Cognitive Science, 3(2):273?302.
[Lowe2004] David G Lowe.
2004.
Distinctive imagefeatures from scale-invariant keypoints.
Internationaljournal of computer vision, 60(2):91?110.
[Lund and Burgess1996] Kevin Lund and Curt Burgess.1996.
Producing high-dimensional semantic spacesfrom lexical co-occurrence.
Behavior ResearchMethods, Instruments, & Computers, 28(2):203?208.
[Marc?elja1980] S Marc?elja.
1980.
Mathematicaldescription of the responses of simple cortical cells*.JOSA, 70(11):1297?1300.
[Mikolov et al2013a] Tomas Mikolov, Kai Chen, GregCorrado, and Jeffrey Dean.
2013a.
Efficientestimation of word representations in vector space.arXiv preprint arXiv:1301.3781.
[Mikolov et al2013b] Tomas Mikolov, Ilya Sutskever,Kai Chen, Greg S Corrado, and Jeff Dean.
2013b.Distributed representations of words and phrasesand their compositionality.
In Advances in neuralinformation processing systems, pages 3111?3119.
[Miller and Charles1991] George A Miller and Walter GCharles.
1991.
Contextual correlates of semanticsimilarity.
Language and cognitive processes, 6(1):1?28.
[Miller et al2002] Earl K Miller, David J Freedman, andJonathan D Wallis.
2002.
The prefrontal cortex:categories, concepts and cognition.
PhilosophicalTransactions of the Royal Society of London B:Biological Sciences, 357(1424):1123?1136.
[Mitchell et al2008] Tom M Mitchell, Svetlana VShinkareva, Andrew Carlson, Kai-Min Chang,Vicente L Malave, Robert A Mason, and Marcel AdamJust.
2008.
Predicting human brain activityassociated with the meanings of nouns.
science,320(5880):1191?1195.
[Naselaris et al2009] Thomas Naselaris, Ryan J Prenger,Kendrick N Kay, Michael Oliver, and Jack L Gallant.2009.
Bayesian reconstruction of natural images fromhuman brain activity.
Neuron, 63(6):902?915.
[Nishimoto et al2011] Shinji Nishimoto, An T Vu,Thomas Naselaris, Yuval Benjamini, Bin Yu, and678Jack L Gallant.
2011.
Reconstructing visualexperiences from brain activity evoked by naturalmovies.
Current Biology, 21(19):1641?1646.
[Pennington et al2014] Jeffrey Pennington, RichardSocher, and Christopher D Manning.
2014.
Glove:Global vectors for word representation.
In EMNLP,volume 14, pages 1532?1543.
[Ryali et al2010] Srikanth Ryali, Kaustubh Supekar,Daniel A Abrams, and Vinod Menon.
2010.
Sparselogistic regression for whole-brain classification offMRI data.
NeuroImage, 51(2):752?764.
[Sack2009] Alexander T Sack.
2009.
Parietal cortexand spatial cognition.
Behavioural brain research,202(2):153?161.
[Sivic and Zisserman2003] Josef Sivic and Andrew Zis-serman.
2003.
Video google: A text retrievalapproach to object matching in videos.
In ComputerVision, 2003.
Proceedings.
Ninth IEEE InternationalConference on, pages 1470?1477.
IEEE.
[Smith and Kosslyn2007] EE Smith and SM Kosslyn.2007.
Cognitive Psychology: Mind and Brain.Pearson Prentice Hall, Upper Saddle River, NJ.
[Turney et al2010] Peter D Turney, Patrick Pantel, et al2010.
From frequency to meaning: Vector spacemodels of semantics.
Journal of artificial intelligenceresearch, 37(1):141?188.
[Tzourio-Mazoyer et al2002] Nathalie Tzourio-Mazoyer,Brigitte Landeau, Dimitri Papathanassiou, FabriceCrivello, Olivier Etard, Nicolas Delcroix, BernardMazoyer, and Marc Joliot.
2002.
Automatedanatomical labeling of activations in SPM using amacroscopic anatomical parcellation of the mni mrisingle-subject brain.
Neuroimage, 15(1):273?289.
[Vannini et al2004] Patrizia Vannini, Ove Almkvist, An-ders Franck, Tomas Jonsson, Umberto Volpe, Mari-a Kristoffersen Wiberg, Lars-Olof Wahlund, andThomas Dierks.
2004.
Task demand modulationsof visuospatial processing measured with functionalmagnetic resonance imaging.
Neuroimage, 21(1):58?68.679
