A Twin-Candidate Model of CoreferenceResolution with Non-AnaphorIdentification CapabilityXiaofeng Yang1,2, Jian Su1, and Chew Lim Tan21 Institute for Infocomm Research,21, Heng Mui Keng Terrace, Singapore, 119613{xiaofengy, sujian}@i2r.a-star.edu.sg2 Department of Computer Science,National University of Singapore, Singapore, 117543{yangxiao, tancl}@comp.nus.edu.sgAbstract.
Although effective for antecedent determination, the tradi-tional twin-candidate model can not prevent the invalid resolution ofnon-anaphors without additional measures.
In this paper we propose amodified learning framework for the twin-candidate model.
In the newframework, we make use of non-anaphors to create a special class oftraining instances, which leads to a classifier capable of identifying thecases of non-anaphors during resolution.
In this way, the twin-candidatemodel itself could avoid the resolution of non-anaphors, and thus couldbe directly deployed to coreference resolution.
The evaluation done onnewswire domain shows that the twin-candidate based system with ourmodified framework achieves better and more reliable performance thanthose with other solutions.1 IntroductionIn recent years supervised learning approaches have been widely used in corefer-ence resolution task and achieved considerable success [1,2,3,4,5].
Most of theseapproaches adopt the single-candidate learning model, in which coreference rela-tion is determined between a possible anaphor and one individual candidate at atime [1,3,4].
However, it has been claimed that the reference between an anaphorand its candidate is often subject to the other competing candidates [5].
Suchinformation is nevertheless difficult to be captured in the single-candidate model.As an alternative, several researchers proposed a twin-candidate model [2,5,6].Instead of directly determining coreference relations, this model would judge thepreference between candidates and then select the most preferred one as the an-tecedent.
The previous work has reported that such a model can effectively helpantecedent determination for anaphors [5,6].However, one problem exits with the twin-candidate model.
For every encoun-tered NP during resolution, the model would always pick out a ?best?
candidateas the antecedent, even if the current NP is not an anaphor.
The twin-candidateR.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
719?730, 2005.c?
Springer-Verlag Berlin Heidelberg 2005720 X. Yang, J. Su, and C.L.
Tanmodel itself could not identify and block such invalid resolution of non-anaphors.Therefore, to apply such a model to coreference resolution, some additional ef-forts have to be required, e.g., using an anaphoricity determination module toeliminate non-anaphors in advance [5], or using threshold to prevent the selectionof a candidate if the confidence it wins other competitors is low [6].In this paper, we explore how to effectively apply the twin-candidate modelto the coreference resolution task.
We propose a modified learning frameworkwith the capability of processing non-anaphors.
In the framework, we make use ofnon-anaphors to create training instances.
This special class of instances wouldenable the learned classifier to identify the test instances formed by non-anaphorsduring resolution.
Thus, the resulting model could avoid resolving a non-anaphorto a non-existent antecedent by itself, without specifying a threshold or using anadditional anaphoricity determination module.
Our experiments on MUC dataset systematically evaluated effectiveness of our modified learning framework.We found that with this new framework, the twin-candidate based system couldnot only outperform the single-candidate based one, but also achieve better andmore reliable results than those twin-candidate based systems using the twomentioned solutions.The rest of the paper is organized as follows.
Section 2 describes the originalframework of the twin-candidate model.
Section 3 presents in details the modifiedframework, including the training and resolution procedures.
Section 4 reportsand discusses the experimental results and finally Section 6 gives the conclusions.2 The Original Framework of the Twin-Candidate ModelThe basic idea of the twin-candidate model is to learn a binary classifier whichcould judge the preference between candidates of an anaphor.
In this section wewill describe a general framework of such a model.2.1 Instance RepresentationIn the twin-candidate model, an instance takes a form like i{C1, C2, M }, whereM is a possible anaphor and C1 and C2 are two of its antecedent candidates.We stipulate that C2 should be closer to M than C1 in distance.
An instance islabelled as ?10?
if C1 is preferred to C2 to be the antecedent, or ?01?
if otherwise.A feature vector would be specified for an instance.
The features may describethe lexical, syntactic, semantic and positional relationships between M and eachone of the candidates, C1 or C2.
In addition, inter-candidate features couldbe used to represent the relationships between the pair of candidates, e.g.
thedistance between C1 and C2 in position.2.2 Training ProcedureFor each anaphor Mana in a given training text, its closet antecedent, Cante,would be selected as the anchor candidate to compare with other candidates.A Twin-Candidate Model of Coreference Resolution 721A set of ?10?
instances, i{Cante, Cp, Mana}, is generated by pairing Mana andCante, as well as each of the interning candidates Cp.
Also a set of ?01?
instances,i{Ca, Cante, Mana}, is created by pairing Cante and each non-antecedental can-didate Ca before Cante.Table 1.
An example text[1 Globalstar] still needs to raise [2 $600 million], and [3Schwartz] said [4 that company] would try to raise [5 the money]in [6 the debt market] .Consider the example in Table 1.
In the text segment, [4 that company] and[5 the money] are two anaphors with [1 Globalstar] and [2 $600 million] beingtheir antecedents respectively.
Thus the training instances to be created for thistext would be:i{[1 Globalstar], [2 $600 million], [4 that company]} : 10i{[1 Globalstar], [3 Schwartz], [4 that company]} : 10i{[1 Globalstar], [2 $600 million], [5 the money]} : 01i{[2 $600 million], [3 Schwartz], [5 the money]} : 10i{[2 $600 million], [4 that company], [5 the money]} : 10Based on the training instances, a classifier is trained using a certain machinelearning algorithm.
Given the feature vector of a test instance, the classifierwould return ?10?
or ?01?
indicating which one of the two candidates underconsideration is preferred.2.3 ResolutionAfter the classifier is ready, it could be employed to select the antecedent foran encountered anaphor.
The resolution algorithm is shown in Figure 1.
In thealgorithm, a round-robin model is employed, in which each candidate is comparedwith every other candidate and the final winner is determined by the won-lostrecords.
The round-robin model would be fair for each competitor and the resultis reliable to represent the rank of the candidates.As described in the algorithm, after each match between two candidates,the record of the winning candidate (i.e., the one judged as preferred by theclassifier) will increase and that of the loser will decrease.
The algorithm simplyuses a unit of one as the increment and decrement.
Therefore, the final record ofa candidate is its won-lost difference in the round-robin matches.
Alternatively,we can use the confidence value returned by the classifier as the in(de)crement,while we found no much performance difference between these two recordingstrategies in experiments.722 X. Yang, J. Su, and C.L.
Tanalgorithm ANTE-SELinput:M : the anaphor to be resolvedcandidate set: the set of antecedent candidates of M,{C1, C2, .
.
.
, Ck}for i = 1 to KScore[ i ] = 0;for j = K downto 2for i = j - 1 downto 1/*CR returns the classification result*/if CR(i{Ci, Cj, M}) ) = = 10 thenScore[ i ]++;Score[ j ]??
;if CR(i{Ci, Cj, M}) ) = = 01 thenScore[ i ]??
;Score[ j ]++;SelectedIdx = argimaxCi?candidate setScore[i];return CSelectedIdxFig.
1.
The original antecedent selection algorithm3 Modified Framework for Coreference Resolution Task3.1 Non-anaphor ProcessingIn the task of coreference resolution, it is often that an encountered NP is non-anaphoric, that is, no antecedent exists among its possible candidates.
However,the resolution algorithm described in the previous section would always try topick out a ?best?
candidate as the antecedent for each given NP, and thus couldnot be applied for coreference resolution directly.One natural solution to this is to use an anaphoricity determination (AD)module to identify the non-anaphoric NPs in advance (e.g.
[5]).
If an NP is judgedas anaphoric, then we deploy the resolution algorithm to find its antecedent.Otherwise we just leave the NP unresolved.
This solution, however, would heavilyrely on the performance of the AD module.
Unfortunately, the accuracy thatmost state-of-the-art AD systems could provide is still not high enough (around80% as reported in [7]) for our coreference resolution task.Another possible solution is to set a threshold to avoid selecting a candidatethat wins with low confidence (e.g.
[6]).
Specifically, for two candidates in amatch, we update their match records only if the confidence returned from theclassifier is above the specified threshold.
If no candidate has a positive record inthe end, we deem the NP in question as non-anaphoric and leave it unresolved.In other words, a NP would be resolved to a candidate only if the candidate wonat least one competitor with confidence above the threshold.The assumption under this solution is that the classifier would return low con-fidence for the test instances formed by non-anaphors.
Although it may be true,A Twin-Candidate Model of Coreference Resolution 723there exist other cases for which the classifier would also assign low confidencevalues, for example, when the two candidates of an anaphoric NP both havestrong or weak preference.
The solution of using threshold could not discrimi-nate these different cases and thus may not be reliable for coreference resolution.In fact, the above problem could be addressed if we could teach the classi-fier to explicitly identify the cases of non-anaphors, instead of using thresholdimplicitly.
To do this, we need to provide a special set of instances formed bythe non-anaphors to train the classifier.
Given a test instance formed by a non-anaphor, the newly learned classifier is supposed to give a class label differentfrom the instances formed by anaphors.
This special label would indicate thatthe current NP is a non-anaphor, and no preference relationship is held be-tween the two candidates under consideration.
In this way, the twin-candidatemodel could do the anaphoricity determination by itself, without any additionalpre-possessing module.
We will describe the modified training and resolutionprocedures in the subsequent subsections.3.2 TrainingIn the modified learning framework, an instance also takes a form like i{C1,C2, M }.
During training, for an encountered anaphor, we create ?01?
or ?10?training instances in the same way as in the original learning framework, whilefor a non-anaphor Mnon ana, we?
From the candidate set, randomly select a candidate Crand as the anchorcandidate.?
Create an instance by pairing Mnon ana, Crand, and each of the candidatesother than Crand.The above instances formed by non-anaphors would be labelled as ?00?.
Note thatan instance may have a form like i{Ca, Crand, Mnon ana} if candidate Ca is pre-ceding Crand, or like i{Crand, Cp, Mnon ana} if candidate Cp is following Crand.Consider the text in Table 1 again.
For the non-anaphors [3 Schwartz] and[6 the debt market], supposing the selected anchor candidates are [1 Globalstar]and [2 $600 million], respectively.
The ?00?
instances generated for the text are:i{[1 Globalstar], [2 $600 million], [3 Schwartz]} : 00i{[1 Globalstar], [2 $600 million], [6 the debt market]} : 00i{[2 $600 million], [3 Schwartz], [6 the debt market]} : 00i{[2 $600 million], [4 that company], [6 the debt market]} : 00i{[2 $600 million], [5 the money], [6 the debt market]} : 003.3 ResolutionThe ?00?
training instances are used together with the ?01?
and ?10?
ones totrain a classifier.
The resolution procedure is described in Figure 2.
Like in theoriginal algorithm, each candidate is compared with every other candidate.
The724 X. Yang, J. Su, and C.L.
Tandifference is that, if two candidates are judged as ?00?
in a match, both candi-dates would receive a penalty of ?1 in their respective record; If no candidatehas a positive final score, then the NP would be deemed as non-anaphoric andleft unresolved.
Otherwise, it would be resolved to the candidate with highestscore as usual.
In the case when an NP has only one antecedent candidate, apseudo-instance is created by paring the candidate with itself.
The NP would beresolved to the candidate if the return label is not ?00?.Note that in the algorithm a threshold could still be used, for example, toupdate the match record only if the classification confidence is high enough.algorithm ANTE-SELinput:M : the new NP to be resolvedcandidate set: the candidates set of M, {C1, C2, .
.
.
, Ck}for i = 1 to KScore[ i ] = 0;for j = K downto 2for i = j - 1 downto 1if CR(i{Ci, Cj, M}) ) = = 10 thenScore[ i ]++;Score[ j ]??
;if CR(i{Ci, Cj, M}) ) = = 01 thenScore[ i ]??
;Score[ j ]++;if CR(i{Ci, Cj, M}) ) = = 00 thenScore[ i ]??
;Score[ j ]??
;SelectedIdx = argimaxCi?candidate setScore[i];if (Score[SelectedIdx] <= 0)return nil;return CSelectedIdx;Fig.
2.
The new antecedent selection algorithm4 Evaluation and Discussion4.1 Experiment SetupThe experiments were done on the newswire domain, using MUC coreferencedata set (Wall Street Journal articles).
For MUC-6 [8] and MUC-7 [9], 30 ?dry-run?
documents were used for training as well as 20-30 documents for testing.In addition, another 100 annotated documents from MUC-6 corpus were alsoprepared for the purpose of deeper system analysis.
Throughout the experiments,C5 was used as the learning algorithm [10].
The recall and precision rates ofthe coreference resolution systems were calculated based on the scoring schemeproposed by Vilain et al [11].A Twin-Candidate Model of Coreference Resolution 725Table 2.
Features for coreference resolution using the twin-candidate modelFeatures describing the new markable M :1.
M DefNP 1 if M is a definite NP; else 02.
M IndefNP 1 if M is an indefinite NP; else 03.
M ProperNP 1 if M is a proper noun; else 04.
M Pronoun 1 if M is a pronoun; else 0Features describing the candidate, C1 or C2, of M5.
candi DefNp 1(2) 1 if C1 (C2) is a definite NP; else 06. candi IndefNp 1(2) 1 if C1 (C2) is an indefinite NP; else 07. candi ProperNp 1(2) 1 if C1 (C2) is a proper noun; else 08. candi Pronoun 1(2) 1 if C1 (C2) is a pronoun; else 0Features describing the relationships between C1(C2) and M :9.
Appositive 1(2) 1 if C1 (C2) and M are in an appositive structure; else 010.
NameAlias 1(2) 1 if C1 (C2) and M are in an alias of the other; else 011.
GenderAgree 1(2) 1 if C1 (C2) and M agree in gender; else 0 if disagree; -1if unknown12.
NumAgree 1(2) 1 if C1 (C2) and M agree in number; else 0 if disagree;-1 if unknown13.
SentDist 1(2) Distance between C1 (C2) in sentences14.
HeadStrMatch 1(2) 1 if C1 (C2) and M match in head string; else 015.
NPStrMatch 1(2) 1 if C1 (C2) and M match in full strings; else 016.
StrSim 1(2) The ratio of the common strings between C1 (C2) andM , over the strings of C1 (C2)17.
SemSim 1(2) The semantic agreement of C1 (C2) against M in Word-NetFeatures describing the relationships between C1 and C218.
inter SentDist Distance between C1 and C2 in sentences19.
inter StrSim 0, 1, 2 if StrSim 1(C1, M) is equal to, larger or less thanStrSim 1(C2, M)20. inter SemSim 0, 1, 2 if SemSim 1(C1, M) is equal to, larger or less thanSemSim 1(C2, M)The candidates of a markable to be resolved were selected as follows.
Duringtraining, for each encountered markable, the preceding markables in the currentand previous four sentences were taken as the candidates.
During resolution, fora non-pronoun, all the preceding markables were included into the candidateset, while for a pronoun, only the markables in the previous four sentences wereused, as the antecedent of a pronoun usually occurs in a short distance.For MUC-6 and MUC-7, our modified framework generated 207k trainingtraining instances, three times larger than the single-candidate based systemby Soon et al[3].
Among them, the ratio of ?00?,?01?
and ?10?
instances wasaround 8:2:1.
The distribution of the class labels was more balanced than in Soonet al?s system, where only 5% training instances were positive while others wereall negative.In our study we only considered domain-independent features that could beobtained with low computational cost but with high reliability.
Table 2 summa-rizes the features with their respective possible values.
Features f1-f17 record726 X. Yang, J. Su, and C.L.
Tanthe properties of a new markable and its two candidates, as well as their relation-ships.
Most of these features could be found in previous systems on coreferenceresolution (e.g.
[3], [4]).
In addition, three inter-candidate features, f18-f20,mark the relationship between the two candidates.
The first one, inter SentDist,records the distance between the two candidates in sentences, while the lattertwo, inter StrSim and inter SemSim compare the similarity scores of the twocandidates, in string-matching and semantics respectively.To provide necessary information of feature computation, an input raw textwas preprocessed automatically by a pipeline of NLP components.
Among them,the chunking component was trained and tested for the shared task for CoNLL-2000 and achieved 92% F-score.
The HMM based NE recognition componentwas capable of recognizing the MUC-style NEs with F-scores of 96.9% (MUC-6)and 94.3% (MUC-7).4.2 Results and DiscussionIn the experiment we compared four systems:SC.
The system based on the single-candidate model.
It was a duplicate of thesystem by Soon et al [3].
The feature set used in the baseline system wassimilar to those listed in Table 2, except that no inter-candidate featurewould be used and only one set of features related to the single candidatewas required.TC AD.
The system based on the twin-candidate mode with the original learn-ing framework, in which non-anaphors were eliminated by an anaphoricitydetermination module in advance.
We built a supervised learning based ADmodule similar to the system proposed by Ng and Cardie [7].
We trainedthe AD classifier on the additional 100 MUC-6 documents.
By adjusting themisclassification cost parameter of C5, we obtained a set of classifiers capableof identifying ?positive?
anaphors with variant recall and precision rates.TC THRESH.
The system based on the twin-candidate mode with the origi-nal learning framework, using threshold to discard the low-confidenced com-parison results between candidates.TC NEW.
The system based on the twin-candidate mode, with our modifiedlearning framework.The results of the four systems on MUC-6 and MUC-7 are summarized inTable 3.
In these experiments, five-fold cross-evaluation was performed on thetraining data to select the resolution parameters, for example, the threshold forsystems TC THRESH and TC NEW, and final AD classifier for TC AD.As shown in the table, the baseline system SC achieves 66.1% and 65.9%F-measure for MUC-6 and MUC-7 data sets.
This performance is better thanthat reported by Soon et al [3], and is comparable to that of the state-of-the-artsystems on the same data sets.From the table we could find system TC AD achieves a comparatively high pre-cision but a low recall, resulting in a F-measure worse than that of SC.
The analysisA Twin-Candidate Model of Coreference Resolution 727Table 3.
The performance of different coreference resolution systems30 Docs 100 DocsMUC-6 MUC-7 MUC-6 MUC-7Experiments R P F R P F R P F R P FSC 70.4 62.4 66.1 69.8 62.5 65.9 67.9 62.1 64.9 69.8 62.5 65.9TC AD 62.6 66.4 64.4 60.8 64.7 62.7 61.6 65.4 63.4 60.8 64.6 62.7TC THRESH 70.7 59.1 64.4 70.0 61.7 65.6 71.0 60.7 65.4 70.6 60.9 65.4TC NEW 64.8 70.1 67.3 66.0 68.6 67.2 67.0 70.2 68.5 67.0 69.2 68.1of the AD classifier reveals that it successfully identifies 79.3% anaphors (79.48%precision) for MUC-6, and 70.9% anaphors (76.3% precision) for MUC-6.
Thatmeans, although the pre-processing AD module could partly avoid the wrong res-olution of a non-anaphor, it eliminates many anaphors at the same, which leads tothe low recall for coreference resolution.
Although in resolution different AD clas-sifiers could be applied, we only observe the tradeoff between recall and precision,with no effective resolution improvement in F-measure.In contrast to TC AD, system TC THRESH yields large gains in recall.
Therecall, up to above 70%, is higher than all the other three systems.
However, theprecision at the same time is unfortunately the lowest.
Such a pattern of highrecall and low precision indicates that using threshold could reduce, to somedegree, the risk of eliminating true anaphors, but it would be too lenient toeffectively block the resolution of non-anaphors.Compared with TC AD and TC THRESH, TC NEW produces large gains inthe precision rates, which rank the highest among all the four systems.
Althoughthe recall also drops at the same time, the increase in the precision could compen-sate it well; we observe a F-measure of 67.3% for MUC-6 and 67.2% for MUC-7,significantly better (p ?
0.05, by a sign test) than the other twin-candidatebased systems.
These results suggest that with our modified framework, thetwin-candidate model could effectively identify non-anaphors and block their in-valid resolution, without affecting the accuracy of the antecedent determinationfor anaphors.In our experiment we were interested to evaluate the resolution performanceof TC NEW under different sizes of training data.
For this purpose, we used theadditional 100 annotated documents for training, and plotted the learning curvein Figure 3.
The curve indicates that the system could perform well with a smallnumber of training data, while the performance would get further improved withmore training data (the best performance is obtained on 90 documents).In Table 3, we also summarized the results of different systems trained on 100documents.
In contrast to TC NEW, we find for system SC, there is no muchperformance difference between using 30 and 100 training documents.
This isconsistent with the report by Soon et al [3] that the single-candidate modelwould achieve the peak performance with a moderate size of data.
In the tablewe could also find that the performance improvement of TC NEW against theother three systems is apparently larger on 100 training documents than on30 documents.728 X. Yang, J. Su, and C.L.
Tan0 10 20 30 40 50 60 70 80 90 1006061626364656667686970Number of Documents Trained OnF?measureFig.
3.
Learning curve of system TC NEW on MUC-740 50 60 70 80 90 1003035404550556065707580RecallPrecisionTC_THRESHTC_ADTC_NEWFig.
4.
Recall and precision results for the twin-candidate based systemsIn Figure 4, we plotted the variant recall and precision scores that the threetwin-candidate based systems were capable of producing when trained on 100documents.
(Here we only showed the results for MUC-7.
Similar results couldbe obtained for MUC-6).
In line with the results in Table 3, system TC ADtends to obtain a high precision but low recall, while system TC THRESHtends to obtain a high recall but low precision.
Comparatively, system TC NEWproduces even recall and precision.
For the range of recall within which thethree systems coincide, TC NEW yields higher precision than the other twosystems.
This figure further proves the effectiveness of our modifiedlearning framework.As mentioned, in systems TC THRESH and TC NEW the threshold pa-rameter could be adjusted.
It would be interesting to evaluate the influence ofdifferent thresholds on the resolution performance.
In Figure 5 we compared therecall and precision of two systems, with thresholds ranging from 65 to 100.In TC THRESH, when the threshold is low, the recall is almost 100% whilethe precision is quite low.
In such a case, all the markables, regardless anaphors orA Twin-Candidate Model of Coreference Resolution 72965 70 75 80 85 90 95 10030405060708090100ThresholdResultsTC_THRESHRecallPrecision65 70 75 80 85 90 95 1000102030405060708090ThresholdResultsTC_NEWRecallPrecisionFig.
5.
Performance of TC THRESH and TC NEW under different thresholdsnon-anaphors, will be resolved.
As a consequence, all the occurring markables in adocument tends to be linked together.
In fact, the effective range of the thresholdthat leads to an acceptable performance is quite short.
The threshold would onlywork when it is considerably high (above 95).
Before that, the precision remainsvery low (less than 40%) while the recall keeps going down with the increase ofthe threshold.By contrast, in TC NEW, both the recall and precision vary little unless thethreshold is extremely high.
That means, the threshold would not impose muchinfluence on the resolution performance of TC NEW.
This should be because inthe modified framework, the cases of non-anaphors are determined by the specialclass label ?00?, instead of the threshold as in TC THRESH.
The purpose ofusing threshold in TC NEW is not to identify the non-anaphors, but to improvethe accuracy of class labelling.
Indeed, we could obtain a good result withoutusing any threshold in TC NEW.
These further confirm our claims that themodified learning framework could perform more reliably than the solution ofusing threshold.5 ConclusionsIn this paper we aimed to find an effective way to apply the twin-candidate modelinto coreference resolution task.
We proposed a modified learning framework inwhich non-anaphors were utilized to create a special class of training instances.With such instances, the resulting classifier could avoid the invalid resolution ofnon-anaphors, which enables the twin-candidate model to be directly deployed tocoreference resolution, without using an additional anaphoricity determinationmodule or using a pre-defined threshold.In the paper we evaluated the effectiveness of our modified framework onthe MUC data set.
The results show that the system with the new frameworkoutperforms the single-candidate based system, as well as the twin-candidate730 X. Yang, J. Su, and C.L.
Tanbased systems using other solutions.
Especially, the analysis of the results indi-cates that our modified framework could lead to more reliable performance thanthe solution of using threshold.
All these suggest that the twin-candidate modelwith the new framework is effective for coreference resolution.References1.
McCarthy, J., Lehnert, Q.: Using decision trees for coreference resolution.
In:Proceedings of the 14th International Conference on Artificial Intelligences.
(1995)1050?10552.
Connolly, D., Burger, J., Day, D. New Methods in Language Processing.
In: Amachine learning approach to anaphoric reference.
(1997) 133?1443.
Soon, W., Ng, H., Lim, D.: A machine learning approach to coreference resolutionof noun phrases.
Computational Linguistics 27 (2001) 521?5444.
Ng, V., Cardie, C.: Improving machine learning approaches to coreference resolu-tion.
In: Proceedings of the 40th Annual Meeting of the Association for Compu-tational Linguistics, Philadelphia (2002) 104?1115.
Yang, X., Zhou, G., Su, J., Tan, C.: Coreference resolution using competitionlearning approach.
In: Proceedings of the 41st Annual Meeting of the Associationfor Computational Linguistics, Japan (2003)6.
Iida, R., Inui, K., Takamura, H., Matsumoto, Y.: Incorporating contextual cues intrainable models for coreference resolution.
In: Proceedings of the 10th Conferenceof EACL, Workshop ?The Computational Treatment of Anaphora?.
(2003)7.
Ng, V., Cardie, C.: Identifying anaphoric and non-anaphoric noun phrases to im-prove coreference resolution.
In: Proceedings of the 19th International Conferenceon Computational Linguistics (COLING02).
(2002)8.
MUC-6: Proceedings of the Sixth Message Understanding Conference.
MorganKaufmann Publishers, San Francisco, CA (1995)9.
MUC-7: Proceedings of the Seventh Message Understanding Conference.
MorganKaufmann Publishers, San Francisco, CA (1998)10.
Quinlan, J.R.: C4.5: Programs for machine learning.
Morgan Kaufmann Publishers,San Francisco, CA (1993)11.
Vilain, M., Burger, J., Aberdeen, J., Connolly, D., Hirschman, L.: A model-theoretic coreference scoring scheme.
In: Proceedings of the Sixth Message under-standing Conference (MUC-6), San Francisco, CA, Morgan Kaufmann Publishers(1995) 45?52
