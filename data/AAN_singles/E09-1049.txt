Proceedings of the 12th Conference of the European Chapter of the ACL, pages 424?432,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsN-gram-based Statistical Machine Translation versus Syntax AugmentedMachine Translation: comparison and system combinationMaxim Khalilov and Jos?
A.R.
FonollosaUniversitat Polit?cnica de CatalunyaCampus Nord UPC, 08034Barcelona, Spain{khalilov,adrian}@talp.upc.eduAbstractIn this paper we compare and contrasttwo approaches to Machine Translation(MT): the CMU-UKA Syntax AugmentedMachine Translation system (SAMT) andUPC-TALP N-gram-based Statistical Ma-chine Translation (SMT).
SAMT is a hier-archical syntax-driven translation systemunderlain by a phrase-based model and atarget part parse tree.
In N-gram-basedSMT, the translation process is based onbilingual units related to word-to-wordalignment and statistical modeling of thebilingual context following a maximum-entropy framework.
We provide a step-by-step comparison of the systems and re-port results in terms of automatic evalu-ation metrics and required computationalresources for a smaller Arabic-to-Englishtranslation task (1.5M tokens in the train-ing corpus).
Human error analysis clari-fies advantages and disadvantages of thesystems under consideration.
Finally, wecombine the output of both systems toyield significant improvements in transla-tion quality.1 IntroductionThere is an ongoing controversy regardingwhether or not information about the syntax oflanguage can benefit MT or contribute to a hybridsystem.Classical IBM word-based models were re-cently augmented with a phrase translation ca-pability, as shown in Koehn et al (2003), or inmore recent implementation, the MOSES MT sys-tem1 (Koehn et al, 2007).
In parallel to the phrase-based approach, the N -gram-based approach ap-peared (Mari?o et al, 2006).
It stemms from1www.statmt.org/moses/the Finite-State Transducers paradigm, and is ex-tended to the log-linear modeling framework, asshown in (Mari?o et al, 2006).
A system follow-ing this approach deals with bilingual units, calledtuples, which are composed of one or more wordsfrom the source language and zero or more wordsfrom the target one.
The N -gram-based systemsallow for linguistically motivated word reorderingby implementing word order monotonization.Prior to the SMT revolution, a major partof MT systems was developed using rule-basedalgorithms; however, starting from the 1990?s,syntax-driven systems based on phrase hierar-chy have gained popularity.
A representativesample of modern syntax-based systems includesmodels based on bilingual synchronous grammar(Melamed, 2004), parse tree-to-string translationmodels (Yamada and Knight, 2001) and non-isomorphic tree-to-tree mappings (Eisner, 2003).The orthodox phrase-based model was en-hanced in Chiang (2005), where a hierarchicalphrase model allowing for multiple generaliza-tions within each phrase was introduced.
Theopen-source toolkit SAMT2 (Zollmann and Venu-gopal, 2006) is a further evolution of this ap-proach, in which syntactic categories extractedfrom the target side parse tree are directly assignedto the hierarchically structured phrases.Several publications discovering similaritiesand differences between distinct translation mod-els have been written over the last few years.
InCrego et al (2005b), the N -gram-based systemis contrasted with a state-of-the-art phrase-basedframework, while in DeNeefe et al (2007), theauthors seek to estimate the advantages, weak-est points and possible overlap between syntax-based MT and phrase-based SMT.
In Zollmann etal.
(2008) the comparison of phrase-based , "Chi-ang?s style" hirearchical system and SAMT is pro-2www.cs.cmu.edu/?zollmann/samt424vided.In this study, we intend to compare the differ-ences and similarities of the statistical N -gram-based SMT approach and the SAMT system.
Thecomparison is performed on a small Arabic-to-English translation task from the news domain.2 SAMT systemA criticism of phrase-based models is data sparse-ness.
This problem is even more serious when thesource, the target, or both languages are inflec-tional and rich in morphology.
Moreover, phrase-based models are unable to cope with global re-ordering because the distortion model is basedon movement distance, which may face computa-tional resource limitations (Och and Ney, 2004).This problem was successfully addressed whenthe MT system based on generalized hierarchi-cally structured phrases was introduced and dis-cussed in Chiang (2005).
It operates with only twomarkers (a substantial phrase category and "a gluemarker").
Moreover, a recent work (Zollmann andVenugopal, 2006) reports significant improvementin terms of translation quality if complete or par-tial syntactic categories (derived from the targetside parse tree) are assigned to the phrases.2.1 ModelingA formalism for Syntax Augmented Translationis probabilistic synchronous context-free grammar(PSynCFG), which is defined in terms of sourceand target terminal sets and a set of non-terminals:X ??
?
?, ?,?, ?
?where X is a non-terminal, ?
is a sequence ofsource-side terminals and non-terminals, ?
is a se-quence of target-side terminals and non-terminals,?
is a one-to-one mapping from non-terminal to-kens space in ?
to non-terminal space in ?, and ?is a non-negative weight assigned to the rule.The non-terminal set is generated from the syn-tactic categories corresponding to the target-sidePenn Treebank set, a set of glue rules and a spe-cial marker representing the "Chiang-style" rules,which do not span the parse tree.
Consequently, alllexical mapping rules are covered by the phrasesmapping table.2.2 Rules annotation, generalization andpruningThe SAMT system is based on a purely lexi-cal phrase table, which is identified as shown inKoehn et al (2003), and word alignment, which isgenerated by the grow-diag-final-and method (ex-panding the alignment by adding directly neigh-boring alignment points and alignment points inthe diagonal neighborhood) (Och and Ney, 2003).Meanwhile, the target of the training corpus isparsed with Charniak?s parser (Charniak, 2000),and each phrase is annotated with the constituentthat spans the target side of the rules.
The set ofnon-terminals is extended by means of conditionaland additive categories according to CombinatoryCategorical Grammar (CCG) (Steedman, 1999).Under this approach, new rules can be formed.
Forexample, RB+VB, can represent an additive con-stituent consisting of two synthetically generatedadjacent categories 3, i.e., an adverb and a verb.Furthermore, DT\NP can indicate an incompletenoun phrase with a missing determiner to the left.The rule recursive generalization procedure co-incides with the one proposed in Chiang (2005),but violates the restrictions introduced for single-category grammar; for example, rules that containadjacent generalized elements are not discarded.Thus, each ruleN ??
f1 .
.
.
fm/e1 .
.
.
encan be extended by another existing ruleM ??
fi .
.
.
fu/ej .
.
.
evwhere 1 ?
i < u ?
m and 1 ?
j < v ?
n, toobtain a new ruleN ??
f1 .
.
.
fi?1Mkfu+1 .
.
.
fm/e1 .
.
.
ej?1Mkev+1 .
.
.
enwhere k is an index for the non-terminal M that in-dicates a one-to-one correspondence between thenew M tokens on the two sides.Figure 1 shows an example of initial rules ex-traction, which can be further extended using thehierarchical model, as shown in Figure 2 (conse-quently involving more general elements in ruledescription).Rules pruning is necessary because the set ofgeneralized rules can be huge.
Pruning is per-formed according to the relative frequency andthe nature of the rules: non-lexical rules thathave been seen only once are discarded; source-conditioned rules with a relative frequency of ap-pearance below a threshold are also eliminated.3Adjacent generalized elements are not allowed in Chi-ang?s work because of over-generation.
However, over-generation is not an issue within the SAMT framework dueto restrictions introduced by target-side syntax425Rules that do not contain non-terminals are notpruned.2.3 Decoding and feature functionsThe decoding process is accomplished using a top-down log-linear model.
The source sentence is de-coded and enriched with the PSynCFG in such away that translation quality is represented by a setof feature functions for each rule, i.e.:?
rule conditional probabilities, given a source,a target or a left-hand-side category;?
lexical weights features, as described inKoehn et al (2003);?
counters of target words and rule applica-tions;?
binary features reflecting rule context (purelylexical and purely abstract, among others);?
rule rareness and unbalancedness penalties.The decoding process can be represented asa search through the space of neg log probabil-ity of the target language terminals.
The set offeature functions is combined with a finite-statetarget-side n-gram language model (LM), whichis used to derive the target language sequence dur-ing a parsing decoding.
The feature weights areoptimized according to the highest BLEU score.For more details refer to Zollmann and Venu-gopal (2006).3 UPC n-gram SMT systemA description of the UPC-TALP N -gram transla-tion system can be found in Mari?o et al (2006).SMT is based on the principle of translating asource sentence (f ) into a sentence in the targetlanguage (e).
The problem is formulated in termsof source and target languages; it is defined ac-cording to equation (1) and can be reformulated asselecting a translation with the highest probabilityfrom a set of target sentences (2):Figure 1: Example of SAMT and N-gram elements extraction.Figure 2: Example of SAMT generalized rules.426e?I1 = argmaxeI1{p(eI1 | fJ1 )}= (1)= argmaxeI1{p(fJ1 | eI1) ?
p(eI1)}(2)where I and J represent the number of words inthe target and source languages, respectively.Modern state-of-the-art SMT systems operatewith the bilingual units extracted from the parallelcorpus based on word-to-word alignment.
Theyare enhanced by the maximum entropy approachand the posterior probability is calculated as a log-linear combination of a set of feature functions(Och and Ney, 2002).
Using this technique, theadditional models are combined to determine thetranslation hypothesis, as shown in (3):e?I1 = argmaxeI1{ M?m=1?mhm(eI1, fJ1 )}(3)where the feature functions hm refer to the systemmodels and the set of ?m refers to the weights cor-responding to these models.3.1 N-gram-based translation systemThe N -gram approach to SMT is considered tobe an alternative to the phrase-based translation,where a given source word sequence is decom-posed into monolingual phrases that are then trans-lated one by one (Marcu and Wong, 2002).The N -gram-based approach regards transla-tion as a stochastic process that maximizes thejoint probability p(f, e), leading to a decomposi-tion based on bilingual n-grams.
The core part ofthe system constructed in this way is a translationmodel (TM), which is based on bilingual units,called tuples, that are extracted from a word align-ment (performed with GIZA++ tool4) according tocertain constraints.
A bilingual TM actually con-stitutes an n-gram LM of tuples, which approxi-mates the joint probability between the languagesunder consideration and can be seen here as a LM,where the language is composed of tuples.3.2 Additional featuresThe N -gram translation system implements a log-linear combination of five additional models:?
an n-gram target LM;4http://code.google.com/p/giza-pp/?
a target LM of Part-of-Speech tags;?
a word penalty model that is used to compen-sate for the system?s preference for short out-put sentences;?
source-to-target and target-to-source lexiconmodels as shown in Och and Ney (2004)).3.3 Extended word reorderingAn extended monotone distortion model basedon the automatically learned reordering rules wasimplemented as described in Crego and Mari?o(2006).
Based on the word-to-word alignment, tu-ples were extracted by an unfolding technique.
Asa result, the tuples were broken into smaller tuples,and these were sequenced in the order of the targetwords.
An example of unfolding tuple extraction,contrasted with the SAMT chunk-based rules con-struction, is presented in Figure 1.The reordering strategy is additionally sup-ported by a 4-gram LM of reordered source POStags.
In training, POS tags are reordered accordingto the extracted reordering patterns and word-to-word links.
The resulting sequence of source POStags is used to train the n-gram LM.3.4 Decoding and optimizationThe open-source MARIE5 decoder was used as asearch engine for the translation system.
Detailscan be found in Crego et al (2005a).
The de-coder implements a beam-search algorithm withpruning capabilities.
All the additional fea-ture models were taken into account during thedecoding process.
Given the development setand references, the log-linear combination ofweights was adjusted using a simplex optimizationmethod and an n-best re-ranking as described inhttp://www.statmt.org/jhuws/.4 Experiments4.1 Evaluation frameworkAs training corpus, we used the 50K first-lines ex-traction from the Arabic-English corpus that wasprovided to the NIST?086 evaluation campaignand belongs to the news domain.
The corpusstatistics can be found in Table 1.
The develop-ment and test sets were provided with 4 referencetranslations, belong to the same domain and con-tain 663 and 500 sentences, respectively.5http://gps-tsc.upc.es/veu/soft/soft/marie/6www.nist.gov/speech/tests/mt/2008/427Arabic EnglishSentences 50 K 50 KWords 1.41 M 1.57 KAverage sentence length 28.15 31.22Vocabulary 51.10 K 31.51 KTable 1: Basic statistics of the training corpus.Evaluation conditions were case-insensitive andsensitive to tokenization.
The word alignment isautomatically computed by using GIZA++ (Ochand Ney, 2004) in both directions, which are madesymmetric by using the grow-diag-final-and oper-ation.The experiments were done on a dual-processorPentium IV Intel Xeon Quad Core X5355 2.66GHz machine with 24 G of RAM.
All computa-tional times and memory size results are approxi-mated.4.2 Arabic data preprocessingArabic is a VSO (SVO in some cases) pro-drop language with rich templatic morphology,where words are made up of roots and affixesand clitics agglutinate to words.
For prepro-cessing, a similar approach to that shown inHabash and Sadat (2006) was employed, and theMADA+TOKAN system for disambiguation andtokenization was used.
For disambiguation, onlydiacritic unigram statistics were employed.
For to-kenization, the D3 scheme with -TAGBIES optionwas used.
The scheme splits the following set ofclitics: w+, f+, b+, k+, l+, Al+ and pronominal cl-itics.
The -TAGBIES option produces Bies POStags on all taggable tokens.4.3 SAMT experimentsThe SAMT guideline was used to performthe experiments and is available on-line:http://www.cs.cmu.edu/?zollmann/samt/.Moses MT script was used to create thegrow ?
diag ?
final word alignment andextract purely lexical phrases, which are then usedto induce the SAMT grammar.
The target side(English) of the training corpus was parsed withthe Charniak?s parser (Charniak, 2000).Rule extraction and filtering procedures wererestricted to the concatenation of the developmentand test sets, allowing for rules with a maximallength of 12 elements in the source side and with azero minimum occurrence criterion for both non-lexical and purely lexical rules.Moses-style phrases extracted with a phrase-based system were 4.8M , while a number of gen-eralized rules representing the hierarchical modelgrew dramatically to 22.9M .
10.8M of them werepruned out on the filtering step.The vocabulary of the English Penn Treebankelementary non-terminals is 72, while a number ofgeneralized elements, including additive and trun-cated categories, is 35.7K.The FastTranslateChart beam-search de-coder was used as an engine of MER training aim-ing to tune the feature weight coefficients and pro-duce final n-best and 1-best translations by com-bining the intensive search with a standard 4-gramLM as shown in Venugopal et al (2007).
The it-eration limit was set to 10 with 1000-best list andthe highest BLEU score as optimization criteria.We did not use completely abstract rules (with-out any source-side lexical utterance), since theserules significantly slow down the decoding process(noAllowAbstractRules option).Table 2 shows a summary of computational timeand RAM needed at each step of the translation.Step Time MemoryParsing 1.5h 80MbRules extraction 10h 3.5GbFiltering&merging 3h 4.0GbWeights tuning 40h 3GbTesting 2h 3GbTable 2: SAMT: Computational resources.Evaluation scores including results of systemcombination (see subsection 4.6) are reported inTable 3.4.4 N-gram system experimentsThe core model of the N -gram-based system is a4-gram LM of bilingual units containing: 184.3451-grams7, 552.838 2-grams, 179.466 3-grams and176.221 4-grams.Along with this model, an N -gram SMT sys-tem implements a log-linear combination of a 5-gram target LM estimated on the English portionof the parallel corpus, as well as supporting 4-gram source and target models of POS tags.
Bies7This number also corresponds to the bilingual model vo-cabulary.428BLEU NIST mPER mWER METEORSAMT 43.20 9.26 36.89 49.45 58.50N-gram-based SMT 46.39 10.06 32.98 48.47 62.36System combination 48.00 10.15 33.20 47.54 62.27MOSES Factored System 44.73 9.62 33.92 47.23 59.84Oracle 61.90 11.41 28.84 41.52 66.19Table 3: Test set evaluation resultsPOS tags were used for the Arabic portion, asshown in subsection 4.2; a TnT tool was used forEnglish POS tagging (Brants, 2000).The number of non-unique initially extractedtuples is 1.1M , which were pruned according tothe maximum number of translation options pertuple on the source side (30).
Tuples with a NULLon the source side were attached to either the pre-vious or the next unit (Mari?o et al, 2006).
Thefeature models weights were optimized accordingto the same optimization criteria as in the SAMTexperiments (the highest BLEU score).Stage-by-stage RAM and time requirements arepresented in Table 4, while translation qualityevaluation results can be found in Table 3.Step Time MemoryModels estimation 0.2h 1.9GbReordering 1h ?Weights tuning 15h 120MbTesting 2h 120MbTable 4: Tuple-based SMT: Computational re-sources.4.5 Statistical significanceA statistical significance test based on a bootstrapresampling method, as shown in Koehn (2004),was performed.
For the 98% confidence intervaland 1000 set resamples, translations generated bySAMT and N -gram system are significantly dif-ferent according to BLEU (43.20?1.69 for SAMTvs.
46.42?
1.61 for tuple-based system).4.6 System combinationMany MT systems generate very different trans-lations of similar quality, even if the modelsinvolved into translation process are analogous.Thus, the outputs of syntax-driven and purely sta-tistical MT systems were combined at the sentencelevel using 1000-best lists of the most probabletranslations produced by the both systems.For system combination, we followed a Mini-mum Bayes-risk algorithm, as introduced in Ku-mar and Byrne (2004).
Table 3 shows the resultsof the system combination experiments on the testset, which are contrasted with the oracle transla-tion results, performed as a selection of the transla-tions with the highest BLEU score from the unionof two 1000-best lists generated by SAMT and N -gram SMT.We also analyzed the percentage contribution ofeach system to the system combination: 55-60%of best translations come from the tuples-basedsystem 1000-best list, both for system combina-tion and oracle experiments on the test set.4.7 Phrase-based reference systemIn order to understand the obtained results com-pared to the state-of-the-art SMT, a referencephrase-based factored SMT system was trainedand tested on the same data using the MOSEStoolkit.
Surface forms of words (factor ?0?
), POS(factor ?1?)
and canonical forms of the words(lemmata) (factor ?2?)
were used as English fac-tors, and surface forms and POS were the Arabicfactors.Word alignment was performed according tothe grow-diag-final algorithm with the GIZA++tool, a msd-bidirectional-fe conditional reorderingmodel was trained; the system had access to thetarget-side 4-gram LMs of words and POS.
The 0-0,1+0-1,2+0-1 scheme was used on the translationstep and 1,2-0,1+1-0,1 to create generation tables.A detailed description of the model training canbe found on the MOSES tutorial web-page8.
Theresults may be seen in Table 3.5 Error analysisTo understand the strong and weak points of bothsystems under consideration, a human analysis of8http://www.statmt.org/moses/429the typical translation errors generated by eachsystem was performed following the frameworkproposed in Vilar et al (2006) and contrasting thesystems output with four reference translations.Human evaluation of translation output is a time-consuming process, thus a set of 100 randomlychosen sentences was picked out from the corre-sponding system output and was considered as arepresentative sample of the automatically gener-ated translation of the test corpus.
According tothe proposed error topology, some classes of errorscan overlap (for example, an unknown word canlead to a reordering problem), but it allows findingthe most prominent source of errors in a reliableway (Vilar et al, 2006; Povovic et al, 2006).
Ta-ble 5 presents the comparative statistics of errorsgenerated by the SAMT and the N -gram-basedSMT systems.
The average length of the generatedtranslations is 32.09 words for the SAMT transla-tion and 35.30 for the N -gram-based system.Apart from unknown words, the most importantsources of errors of the SAMT system are missingcontent words and extra words generated by thetranslation system, causing 17.22 % and 10.60 %of errors, respectively.
A high number of missingcontent words is a serious problem affecting thetranslation accuracy.
In some cases, the systemis able to construct a grammatically correcttranslation, but omitting an important contentword leads to a significant reduction in translationaccuracy:SAMT translation: the ministers of arabenvironment for the closure of the Israeli dymwnpreactor .Ref 1: arab environment ministers demand theclosure of the Israeli daemona nuclear reactor .Ref 2: arab environment ministers demand theclosure of Israeli dimona reactor .Ref 3: arab environment ministers call for Israelinuclear reactor at dimona to be shut down .Ref 4: arab environmental ministers call for theshutdown of the Israeli dimona reactor .Extra words embedded into the correctly trans-lated phrases are a well-known problem of MTsystems based on hierarchical models operating onthe small corpora.
For example, in many casesthe Arabic expression AlbHr Almyt is trans-lated into English as dead sea side and notas dead sea, since the bilingual instances con-tain only the whole English phrase, like following:AlbHr Almyt#the dead sea side#@NPThe N -gram-based system handles miss-ing words more correctly ?
only 9.40 % ofthe errors come from the missing contentType Sub-type SAMT N-gramMissing words 152 (25.17 %) 92 (15.44 %)Content words 104 (17.22 %) 56 (9.40 %)Filler words 48 (7.95 %) 36 (6.04 %)Word order 96 (15.89 %) 140 (23.49 %)Local word order 20 (3.31 %) 68 (11.41 %)Local phrase order 20 (3.31 %) 20 (3.36 %)Long range word order 32 (5.30 %) 48 (8.05 %)Long range phrase order 24 (3.97 %) 4 (0.67 %)Incorrect words 164 (27.15 %) 204 (34.23 %)Sense: wrong lexical choice 24 (3.97 %) 60 (10.07 %)Sense: incorrect disambiguation 16 (2.65 %) 8 (1.34 %)Incorrect form 24 (3.97 %) 56 (9.40 %)Extra words 64 (10.60 %) 56 (9.40 %)Style 28 (4.64 %) 20 (3.36 %)Idioms 4 (0.07 %) 4 (0.67 %)Unknown words 132 (21.85 %) 104 (17.45 %)Punctuation 60 (9.93 %) 56 (9.40 %)Total 604 596Table 5: Human made error statistics for a representative test set.430words; however, it does not handle local andlong-term reordering, thus the main problemis phrase reordering (11.41 % and 8.05 %of errors).
In the example below, the un-derlined block (Circumstantial Complement:from local officials in the tour-ism sector) is embedded between the verband the direct object, while in correct translationit must be placed in the end of the sentence.N-gram translation: the winner receivedfrom local officials in the tourism sector threegold medals .Ref 1: the winner received three gold medalsfrom local officials from the tourism sector .Ref 2: the winner received three gold medalsfrom the local tourism officials .Ref 3: the winner received his prize of 3 goldmedals from local officials in the tourist industry .Ref 4: the winner received three gold medalsfrom local officials in the tourist sector .Along with inserting extra words and wronglexical choice, another prominent source ofincorrect translation, generated by the N -gram system, is an erroneous grammaticalform selection, i.e., a situation when the sys-tem is able to find the correct translation butcannot choose the correct form.
For example,arab environment minister call forclosing dymwnp Israeli reactor,where the verb-preposition combinationcall for was correctly translated on thestem level, but the system was not able to generatea third person conjugation calls for.
In spiteof the fact that English is a language with nearlyno inflection, 9.40 % of errors stem from poorword form modeling.
This is an example of theweakest point of the SMT systems having accessto a small training material; the decoder does notuse syntactic information about the subject ofthe sentence (singular) and makes a choice onlyconcerning the tuple probability.The difference in total number of errors is neg-ligible, however a subjective evaluation of the sys-tems output shows that the translation generatedby the N -gram system is more understandablethan the SAMT one, since more content words aretranslated correctly and the meaning of the sen-tence is still preserved.6 Discussion and conclusionsIn this study two systems are compared: the UPC-TALP N -gram-based and the CMU-UKA SAMTsystems, originating from the ideas of Finite-StateTransducers and hierarchical phrase translation,respectively.
The comparison was created to be asfair as possible, using the same training materialand the same tools on the preprocessing, word-to-word alignment and language modeling steps.The obtained results were also contrasted with thestate-of-the-art phrase-based SMT.Analyzing the automatic evaluation scores, theN -gram-based approach shows good performancefor the small Arabic-to-English task and signifi-cantly outperforms the SAMT system.
The resultsshown by the modern phrase-based SMT (factoredMOSES) lie between the two systems under con-sideration.
Considering memory size and compu-tational time, the tuple-based system has obtainedsignificantly better results than SAMT, primarilybecause of its smaller search space.Interesting results were obtained for the PERand WER metrics: according to the PER,the UPC-TALP system outperforms the SAMTby 10%, while the WER improvement hardlyachieves a 2% difference.
The N -gram-basedSMT can translate the context better, but pro-duces more reordering errors than SAMT.
Thismay be explained by the fact that Arabic and En-glish are languages with high disparity in wordorder, and the N -gram system deals worse withlong-distance reordering because it attempts to useshorter units.
However, by means of introducingthe word context into the TM, short-distance bilin-gual dependencies can be captured effectively.The main conclusion that can be made fromthe human evaluation analysis is that the systemscommit a comparable number of errors, but theyare distributed dissimilarly.
In case of the SAMTsystem, the frequent errors are caused by missingor incorrectly inserted extra words, while the N -gram-based system suffers from reordering prob-lems and wrong words/word form choiceSignificant improvement in translation qualitywas achieved by combining the outputs of the twosystems based on different translating principles.7 AcknowledgmentsThis work has been funded by the Spanish Gov-ernment under grant TEC2006-13964-C03 (AVI-VAVOZ project).431ReferencesT.
Brants.
2000.
TnT ?
a statistical part-of-speech tag-ger.
In Proceedings of the 6th Applied Natural Lan-guage Processing (ANLP-2000).E.
Charniak.
2000.
A maximum entropy-inspiredparser.
In Proceedings of NAACL 2000, pages 132?139.D.
Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofACL 2005, pages 263?270.J.
M. Crego and J.
B. Mari?o.
2006.
Improving statis-tical MT by coupling reordering and decoding.
Ma-chine Translation, 20(3):199?215.J.
M. Crego, J. Mari?o, and A. de Gispert.
2005a.
AnNgram-based Statistical Machine Translation De-coder.
In Proceedings of INTERSPEECH05, pages3185?3188.J.M.
Crego, M.R.
Costa-juss?, J.B. Mari?o, and J.A.R.Fonollosa.
2005b.
Ngram-based versus phrase-based statistical machine translation.
In Proc.
of theIWSLT 2005, pages 177?184.S.
DeNeefe, K. Knight, W. Wang, and D. Marcu.
2007.What can syntax-based MT learn from phrase-basedMT?
In Proceedings of EMNLP-CoNLL 2007,pages 755?763.J.
Eisner.
2003.
Learning non-isomorphic tree map-pings for machine translation.
In Proceedings ofACL 2003 (companion volume), pages 205?208.N.
Habash and F. Sadat.
2006.
Arabic preprocessingschemes for statistical machine translation.
In Pro-ceedings of HLT/NAACL 2006, pages 49?52.Ph.
Koehn, F.J. Och, and D. Marcu.
2003.
Statisticalphrase-based machine translation.
In Proceedings ofHLT-NAACL 2003, pages 48?54.Ph.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: open-source toolkitfor statistical machine translation.
In Proceedingsof ACL 2007, pages 177?180.P.
Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP 2004, pages 388?395.S.
Kumar and W. Byrne.
2004.
Minimum bayes-riskdecoding for statistical machine translation.
In Pro-ceedings of HLT/NAACL 2004.D.
Marcu and W. Wong.
2002.
A Phrase-based, JointProbability Model for Statistical Machine Transla-tion.
In Proceedings of EMNLP02, pages 133?139.J.
B. Mari?o, R. E. Banchs, J. M. Crego, A. de Gispert,P.
Lambert, J.
A. R. Fonollosa, and M. R. Costa-juss?.
2006.
N-gram based machine translation.Computational Linguistics, 32(4):527?549, Decem-ber.I.D.
Melamed.
2004.
Statistical machine translation byparsing.
In Proceedings of ACL 2004, pages 111?114.F.
J. Och and H. Ney.
2002.
Discriminative Train-ing and Maximum Entropy Models for StatisticalMachine Translation.
In Proceedings of ACL 2002,pages 295?302.F.
Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.F.
Och and H. Ney.
2004.
The alignment templateapproach to statistical machine translation.
Compu-tational Linguistics, 30(4):417?449.M.
Povovic, A. de Gispert, D. Gupta, P. Lambert, J.B.Mari?o, M. Federico, H. Ney, and R. Banchs.
2006.Morpho-syntactic information for automatic erroranalysis of statistic machine translation output.
InIn Proceeding of the HLT-NAACL Workshop on Sta-tistical Machine Translation, pages 1?6.M.
Steedman.
1999.
Alternative quantifier scope inccg.
In Proceedings of ACL 1999, pages 301?308.A.
Venugopal, A. Zollmann, and S. Vogel.
2007.An Efficient Two-Pass Approach to Synchronous-CFG Driven Statistical MT.
In Proceedings ofHLT/NAACL 2007, pages 500?507.D.
Vilar, J. Xu, L. F. D?Haro, and H. Ney.
2006.
ErrorAnalysis of Machine Translation Output.
In Pro-ceedings of LREC?06, pages 697?702.K.
Yamada and K. Knight.
2001.
A syntax-based sta-tistical translation model.
In Proceedings of ACL2001, pages 523?530.A.
Zollmann and A. Venugopal.
2006.
Syntax aug-mented machine translation via chart parsing.
InProceedings of NAACL 2006.A.
Zollmann, A. Venugopal, F. Och, and J. Ponte.2008.
Systematic comparison of Phrase-based, Hi-erarchical and Syntax-Augmented Statistical mt.
InProceedings of Coling 2008, pages 1145?1152.432
