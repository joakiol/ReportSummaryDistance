Enhancing Performance of Protein Name Recognizers Using CollocationWen-Juan HouDepartment of Computer Scienceand Information EngineeringNational Taiwan UniversityTaipei, Taiwanwjhou@nlg.csie.ntu.edu.twHsin-Hsi ChenDepartment of Computer Scienceand Information EngineeringNational Taiwan UniversityTaipei, Taiwanhh_chen@csie.ntu.edu.twAbstractNamed entity recognition is a fundamental task inbiological relationship mining.
This paperemploys protein collocates extracted from abiological corpus to enhance the performance ofprotein name recognizers.
Yapex and KeX aretaken as examples.
The precision of Yapex isincreased from 70.90% to 81.94% at the lowexpense of recall rate (i.e., only decrease 2.39%)when collocates are incorporated.
We alsointegrate the results proposed by Yapex and KeX,and employs collocates to filter the merged results.Because the candidates suggested by these twosystems may be inconsistent, i.e., overlap in partial,one of them is considered as a basis.
Theexperiments show that Yapex-based integration isbetter than KeX-based integration.1 IntroductionNamed entities are basic constituents in adocument.
Recognizing named entities is afundamental step for document understanding.
Ina famous message understanding competitionMUC (Darpa, 1998), named entities extraction,including organizations, people, and locations,along with date/time expressions and monetary andpercentage expressions, is one of the evaluationtasks.
Several approaches have been proposed tocapture these types of terms.
For example,corpus-based methods are employed to extractChinese personal names, and rule-based methodsare used to extract Chinese date/time expressionsand monetary and percentage expressions (Chenand Lee, 1996; Chen, et al, 1998).
Corpus-basedapproach is adopted because a large personal namedatabase is available for training.
In contrast,rules which have good coverage exist for date/timeexpressions, so the rule-based approach is adopted.In the past, named entities extraction mainlyfocuses on general domains.
Recently, largeamount of scientific documents has been published,in particular for biomedical domains.
Severalattempts have been made to mine knowledge frombiomedical documents (Hirschman, et al, 2002).One of their goals is to construct a knowledge baseautomatically and to find new informationembedded in documents (Craven and Kumlien,1999).
Similar information extraction works havebeen explored on this domain.
Named entitieslike protein names, gene names, drug names,disease names, and so on, were recognized (Collier,et al, 2000; Fukuda, et al, 1998; Olsson, et al,2002; Rindflesch, et al, 2000).
Besides, therelationships among these entities, e.g.,protein-protein, protein-gene, drug-gene,drug-disease, etc., were extracted (Blaschke, et al,1999; Frideman, et al, 2001; Hou and Chen, 2002;Marcotte, et al, 2001; Ng and Wong, 1999; Park,et al, 2001; Rindflesch, et al, 2000; Thomas, et al,2000; Wong, 2001).Collocation denotes two or more words havingstrong relationships (Manning and Schutze, 1999).The related technologies have been applied toterminological extraction, natural languagegeneration, parsing, and so on.
This paper dealswith a special collocation in biological domain ?say, protein collocation.
We will find out thosekeywords that co-occur with protein names byusing statistical methods.
Such terms, which arecalled collocates of proteins hereafter, will beconsidered as restrictions in protein nameextraction.
To improve the precision rate at thelow expense of recall rate is the main theme of thisapproach.The rest of the paper is organized as follows.The protein name recognizers used in this study areintroduced in Section 2.
The collocation methodwe adopted is shown in Section 3.
The filteringand integration strategies are explained in Sections4 and 5, respectively.
Finally, Section 6concludes the remarks and lists some future works.23Protein Name RecognizersThe detection of protein names presents achallenging task because of their variant structuralcharacteristics, their resemblance to regular nounphrases and their similarity with other kinds ofbiological substances.
Previous approaches onbiological named entities extraction can beclassified into two types ?
say, rule-based (Fukuda,et al, 1998; Humphreys, et al, 2000; Olsson, et al,2002) and corpus-based (Collier, et al, 2000).KeX developed by Fukuda, et al (1998) andYapex developed by Olsson, et al (2002) werebased on handcrafted rules for extracting proteinnames.
Collier, et al (2000) trained a HiddenMarkov Model with a small corpus of 100MEDLINE abstracts to extract names of gene andgene products.Different taggers have their specific features.KeX was evaluated by using 30 abstracts on SH3domain and 50 abstracts on signal transduction,and achieved 94.70% precision and 98.84% recall.Yapex was applied to a test corpus of 101 abstracts.Of these, 48 documents were queried from proteinbinding and interaction, and 53 documents wererandomly chosen from GENIA corpus.
Theperformance of tagging protein names is 67.8%precision and 66.4% recall.
While the same testcorpus was applied to KeX, it got 40.4% precisionand 41.1% recall.
It reveals that each tagger hasits own characteristics.
Changing the domainmay result in the variant performance.Consequently, how to select the correct molecularentities proposed from the existing taggers is aninteresting issue.Statistical Methods for CollocationThe overall flow of our method is shown in Figure1.
To extract protein collocates, we need a corpusin which protein names have been tagged.
Thus,we prepare a tagged biological corpus by lookingup the protein lexicon in the first step.
Then,common stop words are removed and thestemming procedure is applied to gather and groupmore informative words.
Next, the collocationvalues of proteins and their surrounding words arecalculated.
Finally, we use these values to tellwhich neighbouring words are the desiredcollocates.
The major modules are specified indetail in the following subsections.ProteinlexiconTag the raw materialPreprocessing1.
Remove stopwords2.
StemStop wordlistCalculate collocation valueExtract significant proteincollocatesFigure 1.
Flow of Mining Protein Collocates3.1 Step 1: Tagging the CorpusOn the one hand, to calculate the collocationvalues of words with proteins from a corpus, it isnecessary to recognize protein names at first.
Onthe other hand, the goal of this paper deals withperformance issue of protein name tagging.Hence, preparing a protein name tagged corpus anddeveloping a high performance protein nametagger seem to be a chicken-egg problem.Because the corpus developed in the first step isused to extract the contextual information ofproteins, a completely tagged corpus is notnecessary at the first step.
Dictionary-basedapproach for name tagging, i.e., full patternmatching between the dictionary entries and thewords in the corpus, is simple.
The majorargument is its coverage.
Those protein nameswhich are not listed in the dictionary, but appear inthe corpus will not be recognized.
Thus thisapproach only produces a partial-tagged corpus,but it is enough to acquire contextual informationfor latter use.3.2 Step 2: Preprocessing3.2.1 Step 2.1: Exclusion of StopwordsStopwords are common English words (such aspreposition ?in?
and article ?the?)
that frequentlyappear in the text but are not helpful indiscriminating special classes.
Because they aredistributed largely in the corpus, they should befiltered out.
The stopword list in this study wascollected with reference to the stoplists of Fox(1992), but the words also appearing in the proteinlexicon are removed.
For example, ?of?
is aconstituent of the protein name ?capsid of thelumazine?, so that ?of?
is excluded from thestoplist.
Finally, 387 stopwords were used.3.2.2 Step 2.2: StemmingStemming is a procedure of transforming aninflected form to its root form.
For example,?inhibited?
and ?inhibition?
will be mapped intothe root form ?inhibit?
after stemming.Stemming can group the same word semantics andreflect more information around the proteins.3.3 Step 3: Computing Collocation StatisticsThe collocates of proteins are those terms thatoften co-occur with protein names in the corpus.In this step, we calculate three collocation statisticsto find the significant terms around proteins.FrequencyThe collocates are selected by frequency.
Inorder to gather more flexible relationships, here wedefine a collocation window that has five words oneach side of protein names.
And then collocationbigrams at a distance are captured.
In general,more occurrences in the collocation windows arepreferred, but the standard criteria for frequenciesare not acknowledged.
Hence, other collocationmodels are also considered.Mean and VarianceThe mean value of collocations can indicate howfar collocates are typically located from proteinnames.
Furthermore, variance shows thedeviation from the mean.
The standard deviationof value zero indicates that the collocates and theprotein names always occur at exactly the samedistance equal to the mean value.
If the standarddeviation is low, two words usually occur at aboutthe same distance, i.e., near the mean value.
Ifthe standard deviation is high, then the collocatesand the protein names occur at random distance.t-test ModelWhen the values of mean and variance have beencomputed, it is necessary to know if two words donot co-occur by chance.
Moreover, we also haveto know if the standard deviation is low enough.In other words, we have to set a threshold in theabove approach.
To get the statistical confidencethat two words have a collocation relationship,t-test hypothesis testing is adopted.The t-value for each word i is formulated asfollows:Nsuxtiiii/2?=WhereN = 4n - 15,Ncountnx ii _= ,)1(2 iii pps ?
?= ,ncountnp ii /_= ,iproteini ppu ?= , andproteinp  is the probability of protein.When ?
(confidence level) is equal to 0.005, thevalue of t is 2.576.
In the t-test model, if thet-value is larger than 2.576, the word is regarded asa good collocate of protein with 99.5% confidence.3.4 Step 4: Extraction of CollocatesWe applied the above procedure to a corpusdownloaded from the PASTA website in SheffieldUniversity with 1,514 MEDLINE abstracts[http://www.dcs.shef.ac.uk/nlp/pasta].
Of the4,782 different stemmed words appearing in thecollocation windows, there are 541 collocationsgenerated in Step 3.
The collocates are nottagged with parts of speech, so that the output maycontain nouns, prepositions, numbers, verbs, etc.The collocates extracted in a corpus cannot onlyserve as conditions of protein names, but alsofacilitate the relationship discovery betweenproteins.
From the past papers on the extractionof the biological information, such as Blaschke, etal.
(1999), Ng, et al (1999), and Ono, et al (2001)etc., verbs are the major targets.
This is becausemany of the subjects and the objects related tothese verbs are names of genes or proteins.
Toassure that the collocates selected in Step 3 areverbs, we assign parts of speech to these words.Appendix A lists the collocates and theirvariations.4 Filtering StrategiesFor protein name recognition, rule-based systemsand dictionary-based systems are usuallycomplementary.
Rule-based systems canrecognize those protein names not listed in adictionary, but some false entities may also pass atthe same time.
Dictionary-based systems canrecognize those proteins in a dictionary, but thecoverage is its major deficiency.
In this section,we will employ collocates of proteins mined earlierto help identify the molecular entities.
Yapexsystem (Olsson et al, 2002) is adopted to proposecandidates, and collocates are served as restrictionsto filter out less possible protein names.The following filtering strategies are proposed.Assume the candidate set M0 is the outputgenerated by Yapex.z M1: For each candidate in M0, check if acollocate is found in its collocation window.If yes, tag the candidate as a protein name.Otherwise, discard it.z M2: Some of the collocates may besubstrings of protein names.
We relax therestriction in M1 as follows.
If acollocate appears in the candidate or in thecollocation window of the candidate, thentag the candidate as a protein name;otherwise, discard it.z M3: Some protein names may appear morethan once in a document.
They may notalways co-occur with some collocate ineach occurrence.
In other words, theprotein candidate and some collocates mayco-occur in the first occurrence, the secondoccurrence, or even the last occurrence.We revise M1 and M2 as follows tocapture this phenomenon.
Duringchecking if there exists a collocateco-occurring with a protein candidate, thecandidate without any collocate is keptundecidable instead of definite no.
Afterall the protein names are examined, thoseundecidable candidates may be consideredas protein names when one of theirco-occurrences containing any collocate.In other words, as long as a candidate hasbeen confirmed once, it is assumed to be aprotein throughout.
In this way, there aretwo filtering alternatives M31 and M32from M1 and M2, respectively.To get more objective evaluation, we utilizedanother corpus of 101 abstracts used by Yapex[http://www.sics.se/humle/projects/prothalt].Using the test corpus and answer keys supported inYapex project, the evaluation results on filteringstrategies are listed in Table 1.Table 1.
Evaluation on Filtering StrategiesPrecision Recall F-scoreM0 70.90% 69.53% 70.22%M1 79.18% 56.10% 67.64%M2 79.29% 56.66% 67.98%M31 81.97% 66.84% 74.41%M32 81.94% 67.14% 74.54%Compared with the baseline model M0, theprecision rates of all the four models usingcollocates were improved more than 8%.
Therecall rates of M1 and M2 decreased about 13%.Thus, the overall F-scores of M1 and M2decreased about 2% compared to M0.
In contrast,if the decision of tagging was deferred until all theinformation were considered, then the recall ratedecreased only 2% and the overall F-scores of M31and M32 increased 4% relative to M0.
The bestone, M32, improved the precision rate from70.90% to 81.94%, and the F-score from 70.22%to 74.54%.
That meets our expectation, i.e., toenhance the precision rate, but not to reduce thesignificant recall rate.5 Integration StrategiesNow we consider how to improve the recall rates.Integration strategies based on a hybrid concept areintroduced.
The basic idea is that differentprotein name taggers have their own specificfeatures such that they can recognize some taggingobjects according to their rules or recognitionmethods.
Among the proposed protein names bydifferent recognizers, there may exist someoverlaps and some differences.
In other words, aprotein name recognizer may tag a protein namethat another recognizer cannot identify, or both ofthem may accept certain common proteins.
Theintegration strategies are used to select correctprotein names proposed by multiple recognizers.In this study, we made experiments on Yapex andKeX because they are freely available on the web.Because protein candidates are proposed by twonamed entity extractors independently, they maybe totally separated, totally overlap, overlapped inbetween, overlapped in the beginning, andoverlapped in the end.
Figure 2 demonstratesthese five cases.The integration strategies shown as followscombine the results from two sources.z When the protein names produced fromtwo recognizers are totally separated (i.e.,type A), retain them as the proteincandidates.
This integration strategypostulates that one protein namerecognizer may extract some proteins thatanother one cannot identify.z When the protein names produced fromtwo recognizers are exactly the same (i.e.,type B), retain them as the proteincandidates.
Because both taggers acceptthe same protein names, there must existsome special features that fit proteinnames.z When the protein names tagged by twotaggers have partial overlap (i.e., types C,D and E), two additional integrationstrategies are employed, i.e., Yapex-basedand KeX-based strategies.
In the formerstrategy, we adopt protein names taggedby Yapex as candidates and discard theones produced by KeX.
In contrast, thenames tagged by KeX are kept in the latterstrategy.
The integration strategy ismade because each recognizer has its owncharacteristics, and we do not know whichone is performed better in advance.Type A: totally separatedThe above integration strategies put together allthe possible protein candidates except theambiguous cases (i.e., types C, D and E).
Thattends to increase the recall rate.
To avoiddecreasing the precision rate, we also employ thecollocates mentioned in Section 3 to filter out theless possible protein candidates.
Furthermore, toobjectively evaluate the performance of theproposed collocates, we employ the samestrategies to the same test corpus with some termssuggested by human experts.
Total 48 verbalkeywords which were used to find the pathway ofproteins are used and listed in Appendix B.Type B: totally overlapType C: overlapped in betweenType D: overlapped in the beginningFour sets of experiments were designed asfollows for Yapex- and KeX-based integrationstrategies, respectively.Type E: overlapped in the end(1)YA and KA: Use the collocates automaticallyextracted in Section 3 to filter out the candidates asdescribed in Section 4.
(2)YB and KB: Use the terms suggested byhuman experts for the filtering strategies.Figure 2.
Candidates Proposed by Two Systems(3)YA-C and KA-C: If Yapex and KeXrecommend the same protein names (i.e., type B),regard them as protein names withoutconsideration of collocates.
Otherwise, use thecollocates proposed in this study to make filtering.
(4)YB-C and KB-C: Similar to (3) except thatthe collocates are replaced by the terms suggestedby human experts.The experimental results are listed in Tables 2and 3.
The tendency M32>M31>M2>M1 is stillkept in the new experiments.
The strategy ofdelaying the decision until clear evidence is foundis workable.
The performances of YA, YA-C, KA,and KA-C are better than the performances of thecorresponding models (i.e., YB, YB-C, KB, andTable 2.
Evaluation Results on Yapex-basedIntegration StrategyYA Precision Recall F-scoreM0 61.98% 77.52% 69.75%M1 64.97% 62.82% 63.90%M2 65.02% 63.53% 64.28%M31 65.94% 74.26% 70.10%M32 65.90% 74.62% 70.26%YBM1 66.79% 44.30% 55.55%M2 66.79% 44.81% 55.80%M31 70.20% 65.06% 67.63%M32 70.19% 65.51% 67.85%YA-CM1 65.76% 69.18% 67.47%M2 65.88% 69.84% 67.86%M31 65.39% 75.43% 70.41%M32 65.38% 75.69% 70.54%YB-CM1 68.92% 58.09% 63.51%M2 68.78% 58.49% 63.64%M31 69.07% 69.08% 69.13%M32 69.07% 69.63% 69.35%Table 3.
Evaluation Results on KeX-basedIntegration StrategyKA Precision Recall F-scoreM0 60.43% 70.60% 65.52%M1 63.82% 56.61% 60.22%M2 63.52% 57.22% 60.37%M31 64.39% 65.56% 64.98%M32 64.03% 65.92% 64.98%KBM1 67.56% 41.20% 54.38%M2 66.99% 41.71% 54.35%M31 69.57% 55.70% 61.64%M32 69.25% 56.26% 62.76%KA-CM1 64.72% 63.17% 63.95%M2 64.44% 63.68% 64.06%M31 63.83% 66.79% 65.31%M32 63.49% 67.04% 65.27%KB-CM1 69.57% 55.60% 62.59%M2 69.15% 56.10% 64.06%M31 68.36% 60.22% 64.29%M32 68.09% 60.78% 64.44%KB-C).
It shows that the set of collocatesproposed by our system is more complete than theset of terms suggested by human experts.Compared with the recall rate of M0 in Table 1(i.e., 69.53%), the recall rates of both Yapex- andKeX-based integration are increased, i.e., 77.52%and 70.60%, respectively.
That matches ourexpectation.
However, the precision rates aredecreased more than the increase of recall rates.In particular, the F-score of KeX-based integrationstrategy is 4.70% worse than that of the baselineM0.
It shows that KeX performed not well in thistest set, so it cannot recommend good candidates inthe integration stage.
Moreover, the F-scores ofM31 and M32 of YA and YA-C are better than thatof M0 in Table 1.
It reveals that Yapexperformed better in this test corpus, so that we canenhance the performance by both the filtering andintegration strategies.
Nevertheless, the modelsin Tables 2 and 3 still cannot compete to M32 inTable 1.
The reason may be some heuristic rulesused in Yapex are modified from KeX (Olsson etal., 2002).6 Concluding RemarksThis paper shows a fully automatic way of miningcollocates from scientific text in the proteindomain, and employs them to improve theperformance of protein name recognitionsuccessfully.
The same approach can be extendedto other domains like gene, DNA, RNA, drugs, andso on.
The collocates extracted from a domaincorpus are also important keywords for pathwaydiscovery, so that a systematic way from basicnamed entities finding to complex relationshipsdiscovery can be established.Applying filtering strategy only demonstratesbetter performance than applying both filtering andintegration strategies together in this paper.
Oneof the possible reasons is that the adopted systemsare similar, i.e., both systems are rule-based, andsome heuristic steps used in one system areinherited from another.
The effects of combiningdifferent types of protein name taggers, e.g.,rule-based and corpus-based, will be investigatedin the future.AcknowledgementsPart of research results was supported by NationalScience Council under the contractNSC-91-2213-E-002-088.
We also thank Dr.George Demetriou in the Department of theComputer Science of the University of Sheffield,who kindly supported the resources in this work.ReferencesBlaschke, C., Andrade, M.A., Ouzounis, C. andValencia, A.
(1999) ?Automatic Extraction ofBiological Information from Scientific Text:Protein-Protein Interactions,?
Proceedings of 7thInternational Conference on Intelligent Systems forMolecular Biology, pp.
60-67.Chen, H.H.
and Lee, J.C. (1996) ?Identification andClassification of Proper Nouns in Chinese Texts,?Proceedings of 16th International Conference onComputational Linguistics, pp.
222-229.Chen, H.H.
; Ding, Y.W.
and Tsai, S.C. (1998) ?NamedEntity Extraction for Information Retrieval,?Computer Processing of Oriental Languages,Special Issue on Information Retrieval on OrientalLanguages, 12(1), 1998, pp.
75-85.Collier, N., Park, H.S., Ogata, N., Tateishi, Y., Nobata,C.
and Ohta, T. (1999) ?The GENIA project:Corpus-based Knowledge Acquisition andInformation Extraction from Genome ResearchPapers,?
Proceedings of the Annual Meeting of theEuropean Chapter of the Association forComputational Linguistics (EACL?99), June.Collier, N., Nobata, C. and Tsujii J.I.
(2000) ?Extractingthe Names of Genes and Gene Products with aHidden Markov Model,?
Proceedings of 18thInternational Conference on ComputationalLinguistics, pp.
201-207.Craven, M. and Kumlien, J.
(1999) ?ConstructingBiological Knowledge Bases by ExtractingInformation from Text Sources, Proceedings of 7thInternational Conference on Intelligent Systems forMolecular Biology, pp.
77-86.DARPA (1998) Proceedings of 7th MessageUnderstanding Conference.Fox, C. Lexical Analysis and Stoplists.
In InformationRetrieval: Data Structures and Algorithms, Frakes,W.
B. and Baeza-Yates, R., ed., Prentice Hall,102-130, 1992.Friedman, C., Kra, P., Yu, H., Krauthammer, M. andRzhetsky, A.
(2001) ?GENIES: A Natural LanguageProcessing System for the Extraction of MolecularPathways from Journal Articles,?
Bioinformatics,17(S1), pp.
74-82.Fukuda, K., Tsunoda, T., Tamura, A., and Takagi, T.(1998) ?Toward Information Extraction: IdentifyingProtein Names from Biological Papers,?Proceedings of Pacific Symposium on Biocomputing,pp.
707-718.Hirschman, L., Park, J.C., Tsujii, J., Wong, L. and Wu,C.H.
(2002) ?Accomplishments and Challenges inLiterature Data mining for Biology,?
Bioinformatics,18(12), pp.
1553-1561.Hou, W.J.
and Chen, H.H.
(2002) ?Extracting BiologicalKeywords from Scientific Text,?
Proceedings of 13thInternational Conference on Genome Informatics,pp.
571-573.Humphreys, K., Demetriou, G. and Gaizauskas, R.(2000) ?Two Applications of Information Extractionto Biological Science Journal Articles: EnzymeInteractions and Protein Structures,?
Proceedings ofPacific Symposium on Biocomputing, 5, pp.502-513.Manning, C.D.
and Schutze, H. (1999) Foundations ofStatistical Natural Language Processing, The MITPress.Marcotte, E.M., Xenarios, I. and Eisenberd, D. (2001)?Mining Literature for Protein-protein Interactions,?Bioinformatics, 17(4), pp.
359-363.Ng, S.-K. and Wong, M. (1999) ?Toward RoutineAutomatic Pathway Discovery from On-lineScientific Text Abstracts,?
Proceedings of 10thInternational Conference on Genome Informatics,pp.
104-112.Olsson, F., Eriksson, G., Franzen, K., Asker, L. andLiden P. (2002) ?Notions of Correctness whenEvaluating Protein Name Taggers,?
Proceedings ofthe 19th International Conference on ComputationalLinguistics, pp.
765-771.Ono, T., Hishigaki, H., Tanigami, A., and Takagi, T.?Automated Extraction of Information onProtein-Protein Interactions from the BiologicalLiterature,?
Bioinformatics, 17(2), pp.155-161.Park, J.C., Kim, H.S., and Kim, J.J. (2001)?Bidirectional Incremental Parsing for AutomaticPathway Identification with Combinatory CategorialGrammar,?
Proceedings of Pacific Symposium onBiocomputing, 6, pp.
396-407.Rindflesch, T.C., Tanabe, L., Weinstein, J.N.
and Hunter,L.
(2000) ?EDGAR: Extraction of Drugs, Genes,and Relations from Biomedical Literature,?Proceedings of Pacific Symposium on Biocomputing,5, pp.
517-528.Thomas, J., Milward, D., Ouzounis, C., Pulman, S., andCarroll, M. (2000) ?Automatic Extraction of ProteinInteractions from Scientific Abstracts,?
Proceedingsof Pacific Symposium on Biocomputing, 5, pp.538-549.Wong, L. (2001) ?PIES, a Protein Interaction ExtractionSystem,?
Proceedings of Pacific Symposium onBiocomputing, 6, pp.
520-531.Appendix A. Collocates mined from corpusact (-, -ed, -ing, -ion, -ive, -ivities, -ivity, -s),activat (-e, -ed, -es, -ing, -ion, -or) , adopt (-,ed, -s),affect (-, -ed, -ing, -s), allow (-, -ed, -s), analy (-sed,-ses, -sis, -zed, -zing), appear (-, -s), arrange (-d,-ment), assembl (-ing, -y), associat (-e, -ed, -ion),bas (-e, -ed, -is), belong (-, -ing, -s), bind (-, -ing,-s) / bound, bond (-, -ed, -ing, -s), bridge (-, -d, -s),calculat (-ed, -ion), called, carr (-ied, -ier, -ies),cataly (-sed, -ses, -stic, -ze, -zed, -zes, -zing), cause(-, -d, -s), center (-, -ed) / centre (-, -s), chang (-e,-ed, -es, -ing), characteriz (-ation, -e, -ed, -es, -ing),charg (-e, -ed), class (-, -es, -ified, -ifying), cleav(-e, -ed, -es, -ing), clos (-e, -ed, -ing), coil (-, -ed),compar (-e, -ed, -ing, -ison, -isons), complex (-, -ed,-es), composed, compris (-es, -ing), conclu (-de,-ded, -sion, -sions), conserved, consist (-, -ed, -ent,-ing, -s), constitut (-e, -ed, -es), contact (-, -s),contain (-, -ed, -ing, -s), coordinat (-e, -ed, -es,-ion), correlat (-e, -ed), correspond (-, -ing), crystal(-, -lize, -lized, -lizes, -s), cycl (-e, -es, -ing), define(-d, -s), demonstrat (-e, -ed, -es, -ing), depend (-,-ent, -ing), derived, describe (-, -d), design (-, -ed,-ing), detail (-, -ed, -s), determin (-ation, -ations, -e,-ed, -es, -ing), differ (-ence, -ences, -s), diffract(-ing, -ion), digest (-ed, -s), dimer (-, -ic, -ization,-ize), direct (-, -ed, -s), discuss (-, -ed), display (-,-s), disrupt (-, -ed, -ing, -s), effect (-, -s), encod (-e,-ed, -ing), enhanc (-e, -ed, -er, -es, -ing), exhibit (-,-ed, -s), exist (-, -s), explain (-, -ed, -ing, -s),express (-ed, -ing), extend (-, -ed), facilitat (-e, -es,-ing), finding / found, fold (-, -ed, -ing, -s), form (-,-ed, -ing, -s), function (-, -al, -ing, -s), groove (-,-s), hydroly (-sis, -zed, -zes), identif (-ied, -ies, -y),implicat (-e, -ed, -ions), inactiv (-ated, -ates, -e),includ (-ed, -es, -ing), indicat (-e, -ed, -es, -ing),induc (-e, -ed, -es, -ing), inhibit (-, -ed, -ing, -ion,-or, -ors, -s), initiat (-ed, -es), insert (-, -ed, -ing),interact (-, -ing, -ion, -ions, -s), involv (-e, -ed, -es,-ing), isolated, lack (-, -s), lead (-, -ing, -s), ligand(-, -ed, -s), like, link (-, -ed, -ing), located, loop (-,-ing, -s), mediat (-e, -ed, -es, -ing), model (-, -ed,-ing, -s), modul (-ate, -ates, -ating, -e, -es), mutat(-ed, -ions), observ (-e, -ed), obtain (-, -ed), occup(-ied, -ies), occur (-, -red, -s), organiz (-ation, -ed),oxidiz (-ed, -ing), phosphorylate (-d, -s), play (-,-s), position (-, -ed, -ing, -s), predict (-, -ed, -ing),presen (-ce, -ted, -ting), produc (-e, -ed, -es, -ing),promot (-e, -er, -es, -ing), proposed, proton (-,-ated, -s), provid (-e, -ed, -es, -ing), purif (-ied, -y),react (-, -ion, -tive, -s), recogni (-tion, -zed, -zes,-ing), reduc (-ed, -es, -ing, -tase, -tion), refined,regulat (-e, -ed, -es, -ing, -ion, -ory), relat (-ed, -es,-ive), repeat (-, -ed, -s), replaced, report (-, -ed),represent (-, -ed, -ing, -s), requir (-e, -ed, -es, -ing),resembl (-e, -ed, -es, -ing), resol (-ution, -ve),result (-, -ed, -ing, -s), reveal (-, -ed, -s), select (-ed,-ive, -ively), sequence (-, -d, -s), serve (-, -s), shape(-, -d), share (-, -d, -s), show (-, -n, -s), signal (-,-ing, , -ling, -s), sol (-ution, -ved), stabili (sed, -ty,-ze, -zed, -zes, -zing), stimulat (-e, -ed, -es, -ion,-ory), strain (-, -s), strand (-, -ed, -s), structur (-al,-ally, -e, -ed, -es), stud (-ied, -ies, -y, -ying),substitut (-e, -es, -ion, -ions), substrate (-, -s),suggest (-, -ed, -ing, -ion, -s), support (-, -ing, -s),switch (-, -es), synthesi (-s, -ze, -zed), target (-, -ed,-ing, -s), transfer (-, -red), transport (-, -s),understand (-, -ing) / understood, unexpected, us(-e, -ing)Appendix B.
Terms suggested by an expertaccompan (-ied, -ies, -y, -ying), activat (-e, -ed, -es,-ing, -ion, -or, -ors, -ory), affect (-, -ed, -ing, -s),aggregat (-e, -ed, -es, -ing, -ion), assembl (-e, -ed,-es, -ing, -y), associat (-e, -ed, -es, -ing, -ion),attract (-, -ed, -ing, -ion, -s), bind (-, -ing, -s) /bound, catalys (-e, -ed, -es, -ing, -tic), catalyz (-e,-ed, -es, -ing), cluster (-, -ed, -ing, -s), communicat(-e, -ed, -es, -ing, -ion), complex (-, -ed, -es, -ing),construct (-, -ed, -ing, -ion, -s), control (-, -ed, -ing,-led, -ling, -s), cooperat (-e, -ed, -es, -ing, -ion, -or,-ors), correlat (-e, -ed, -es, -ing, -ion), coupl (-e,-ed, -es, -ing), crosslink (-, -ed, -ing, -s),deglycosylat (-e, -ed, -es, -ing, -ion, -ory),demethylat (-e, -ed, -es, -ing, -ion, -ory),dephosphorylat (-e, -ed, -es, -ing, -ion, -ory), effect(-, -ed, -ing, -s), eliminat (-e, -ed, -es, -ing, -ion),enabl (-e, -ed, -es, -ing), enhanc (-e, -ed, -er, -es,-ing), glycosylat (-e, -ed, -es, -ing, -ion, -ory),group (-, -ed, -ing, -s), help (-, -ed, -ing, -s), hinder(-, -ed, -ing, -s), inactivat (-e, -ed, -es, -ing, -ion,-or, -ors, -ory), inhibit (-, -ed, -ing, -ion, -or, -ors,-ory, -s), integrat (-e, -ed, -es, -ing, -ion), interact (-,-ed, -ing, -ion, -s), link (-, -ed, -ing, -s), methylat(-e, -ed, -es, -ing, -ion), obstacl (-e, -ed, -es, -ing),participat (-e, -ed, -es, -ing, -ion), phosphorylat (-e,-ed, -es, -ing, -ion, -ory), prim (-e, -ed, -es, -ing),process (-, -ed, -es, -ing), react (-, -ed, -ing, -ion,-or, -ors, -ory, s), regulat (-e, -ed, -es, -ing,-ion, ,-or, -ory), relat (-e, -ed, -es, -ing, -ion), signal(-, -ed, -ing, , -led, -ling, -s), stimulat (-e, -ed, -es,-ing, -ion, ,-or, -ory), suppress (-, -ed, -es, -ing,-ion), transduc (-e, -ed, -es, -ing, -tion, ,-tor, -tory),trigger (-, -ed, -ing, -s)
