Generic Text Processing:A Progress ReportPaul S. Jacobs, George R. Krupka, Susan W. McRoyLisa F. Rau, Norman K. Sondheimer and Uri ZernikArtificial Intelligence ProgramGE Research and Development CenterSchenectady, NY 12301IntroductionA generic natural language system, without modifica-tion, can effectively analyze an arbitrary input at leastto the level of word sense tagging.
Considerable re-search has addressed the transportability of natural an-guage systems, but not generic text processing capabil-ities.
For example, previous DARPA-sponsored work\[1, 2\] produced transportable interfaces to database sys-tems.
Each new application of these interfaces generallyrequired modifications to lexicons, new semantic knowl-edge bases, and other specialized features.
The mostthat natural language text processing systems have ac-complished has been the parsing of arbitrary text, with-out any real semantic analysis.Our text processing work at GE, like the earlier ef-forts in interfaces, has emphasized transportability.
Wehave applied the same core of natural language tools,including the grammar, lexicon, parser, and semanticinterpreter (collectively known as the NLToolset \[3\]), todomains ranging from personnel directories to aircraftengine service reports.
Some other applications of theNLToolset are the SCISOR news story reader \[4\] and theGE effort in the MUCK-II evaluation \[5\].
These proto-types process texts at a rate of several hundred para-graphs per hour, synthesize a structured representationfor each text, and answer English questions about thecontents.This transportable t xt processing effort has providedsuccessful proof-of-concept demonstrations for applica-tions with only a few person-months of effort, often withonly minor assistance from the NLToolset developers.Unfortunately, even this anaount of customization is fartoo much for most potential text processing applications,which continue to use more robust but far more superfi-cial methods, such as keyword indexing, pattern match-ing, and statistical retrieval.Our effort at GE currently aims at developing enerictext processing capabilities.
Building on the techniquespreviously used for a wide variety of applications, we areextending our methods to the semantic analysis of unre-stricted text.
This has placed the greatest stress on en-hanced lexical processing.
Most importantly, the systemmust now apply lexical information that is rich enoughto cover the content words of arbitrary text, while pro-viding enough information about words in context tocontrol ambiguity and produce "preferred" interpreta-tions.
In the near term, we expect at least to reduce fu-ture customization efforts while experimenting with theeffects of "text coding" or word sense-tagging withoutcustomization.We will report on some preliminary results in generictext processing, including the development of a 10,000-root core sense-disambiguated l xicon, the use of textpreprocessing (including tagging and bracketing) to helpcontrol parsing, and the design of a module for collect-ing sense preferences from different, knowledge sources intext analysis.
The program currently discriminates wordsenses (albeit somewhat, roughly) in arbitrary text.
Wewill report on the current state of this effort and describethe key unresolved issues.Lexical inadequacyMost problems in natural language processing--including information retrieval, database generation,and machine translation--hinge on relating words toother words that are similar in mneaning.
Because of theextreme difficulty of producing any accurate deep-levelanalysis of text, many of these strategies are inherentlyword-based.
In the case of information retrieval, currentmethods match words in a query with words in docu-ments, with the degree of match weighted according tothe frequency of words in the texts.
In database gen-eration, programns map individual words into names offrames or database records.
In language translation, sys-tems use mappings between words in a "source" languageand words in a "target" language to guide lexical choice(word choice).
In all these applications, current methodsare limited in their accuracy by the fact that many wordshave multiple senses, although different words often havesimilar meanings.We will refer to this as the problem of lexical inade-quacy, including the issue of genuinely ambiguous wordsas well as vague tern~s and derivative words (words thathave a common root but vary slightly in meaning).
Pre-vious approaches to the problem of lexical inadequacyfall into two basic categories-word-based approaches anddeep-level approaches.
Word-based approaches have ad-359dressed the problem in several general ways, includingusing co-occurrence and other contextual information asan indicator of text content to try to filter out inac-curacies, using word roots rather thau words by strip-ping affixes, and using a thesaurus or synonym list thatmatches words to other words.
Deep-level approachesuse a knowledge representation, or interlingua, to reflecttext content, thereby separating text representation fromthe individual words.
Deep-level approaches caJ~ be moreaccurate than word-based approaches, but have not beensufficiently robust to perform any practical text process-ing task.
This lack of robustness i generally due to thedifficulty in building knowledge bases that are sufficientfor broad-scale processing.Text  cod ingOur approach tries to take advantage of the main ben-efit of word-based analysis, i.e.
the explicit recogni-tion in text representation of the relationship betweenwords that derive from a common root, while overcom-ing the main limitation, i.e.
the loss of information be-tween complete text and word roots.
The idea is thatthe first step in text processing should be to develop a"recoding" or sense-tagging of the source text that cap-tures word-level knowledge as well as any deeper infor-mation the system is able to produce.
In theory, thisapproach would lead to capabilities that are no worse,with zero customization, than word-based methods forinformation retrieval, but allow for easy improvementusing more knowledge-intensive methods.
This theoryis still untested, although there is some preliminary evi-dence that word sense tagging could improve informationretrieval system performance \[6\].As an example of the input and output of the sys-tem, the following is an arbitrary segment of Wall Street,Journal text with the resulting coding.
Each word istagged with its part of speech and sense code (a. numbersuffix), along with a parent concept.
For example, thetag \[changing verb_3 (c-replacing)\] shows that theinput word is "changing", the preferred sense is number3 of the verb, and that this sense falls under the conceptc - rep lac ing  in the hierarchy.
The program producesthis output by analyzing the text in several stages, fromstochastic tagging through semantic interpretation, andcollecting results in a matrix of word senses and prefer-ence scores.The network also is changing its halftimeshow to include viewer participation, in an at-tempt to hold on to its audience through half-time and into the second halves of games.
Oneshow will ask viewers to vote on their favoriteall-time players through telephone polls.\[changing verb_3 (c-replacing) \]\ [ i ts  ppnoun_l (c-obj) \]\[halftime noun_l (c-ent ity)  \]\[show c-act-of-verb_show1 (c-manifesting) \]\[to *infl* \]\[include verb_2 (c-grouping) \]\[viewer c-verb_view2-er (c-entity) \]\[participation c-r esult- of-being-verb_part ic ipat e i(c-causal-state) \]\[*comma* *ptmct* \]\[in prep_27 (c-group-part) \]\[an det_l (c-def inite-qual)  \]\[attempt c-act-of-verb_attemptl (c-attempting) \]\[to *infl* \]\[hold verb_4 (c-positioning) \]\[on adv_l (c-range-qual c-continuity-qual) \]\[to prep_l (c-destination-rel) \]\[its ppnoun_l (c-obj) \]\[audience noun_l (c-human-group) \]\[through prep_l (c-course-rel)  \]\[halftime noun_l (c-entity) \]\[and coordconj_l (c-conjunction) \]\[into prep_5 (c-engage-in) \]\[the det_l (c-definite-qual) \]\[second c-numword_twol-th (c-order-qual) \]\[halves noun_1 (c-portion-part) \]\[of prep_8 (c-stateobject-rel) \]\[games noun_l (c-recreation-obj) \]\[*period* *punct* \]\[one noun_l (c-ent i ty)  \]\[show c-act-of-verb_showl (c-manifesting) \]\[will *aux* \]\[ask verb_2 (c-asking) \]\[viewers c-verb_view2-er (c-entity) \]\[to *infl* \]\[vote verb 1 (c-selecting) \]\[on prep_4 (c-temporal-proximity-rel) \]\[their ppnoun_l (c-obj) \]\[favorite adj_1 (c-importance-qualc-superiority-qual) \]\[all det_l (c-quantifier) \]\[*hyphen* *punct* \]\[time noun_l (c-indef-time-period) \]\[players c-verb_playl-er (c-entity) \]\[through prep_l (c-course-rel) \]\[telephone noun_l (c-machine) \]\[polls c-act-of-verb_polll (c-asking) \]\[*period* *punct* \]Naturally, this text recoding assumes a representationscheme for the enhanced text, a large lexicon includingword senses and knowledge for discriminating them, anda robust parser and semantic interpreter.
The rest of thispaper will give a progress report on the development ofthese resources o far.\[the det_l (c-definite-qual) \]\[network noun_2 (c-entertainment-objc-business-org c-system) \]\[also adv_l (a-numeric-qual) \]\ [ i s  *aux* \]The core  lex iconGE's core lexicon development followed an exper-iment with a moderate-sized (10,000-unique root),commercially-available lexicon, which demonstrated360many substantive problems in applying lexical resourcesto  text processing.
The lexicon had good morpl~ologicaland gran~n~atical coverage, as well as a thesam-us-basedsemantic representation of word meanings.
However, itwas inadequate for producing semantic representationsof text because it did not provide reasonable informa-tion for discriminating word senses.
Building from thiseffort, we designed and constructed a lexicon of roughlythe same size that included much more word-sense infor-mation, as well as constraining the number of senses ofeach entry t,o avoid spurious semantic interpretations.The main features of the new lexicon are a hierarchy of1,000 parent concepts for encoding semantic preferencesand restrictions, sense-based morphology and subcate-gorization, a distinction bet,ween primary and secondarysenses and senses that require particular "triggers" orappear only in specific contexts, and a broad range ofcolloca.tiona1 information.
For example, the followingare the lexical entries for the word "issue":( issue:POS noun:SENSES( (  issue1:EXAMPLE (address important issues):TYPE p:PAR (c-concern):ASSOC (subject) )( issue2:EXAMPLE (is that the october issue?
):TYPE s:PAR (c-published-document):ASSOC (edition) ) ) )( issue:POS verb:G-DERIV nil: SENSESssueiSYNTAX (one-obj io-rec)EXAMPLE (the stockroom issues supplies)TYPE pPAR (c-giving)ASSOC (supply)S-DERIV ((-able adj tr-ability)(-ance noun tr-act)(-er noun tr-actor)) )( issue2:SYNTAX (one-obj io-rec):EXAMPLE (I issued instructions):TYPE p:PAR (c-informing):ASSOC (produce):S-DERIV ((-ance noun tr-act))ssue3SYNTAX (one-obj no-obj)EXAMPLE (good smells issue from the cake)TYPE sPAR (c-passive-moving) ) ) )The lexicon, by design, includes only the coarsest dis-tinctions anlong word senses; thus the financial sense of"issue" (e. g., a new securit,y) falls under the same coresense as the latest "issue" of a, ma,gazine.
This meansthat,  for a task like data.base genera.tion, task-specificprocessing or inference must augment the core lexicalknowledge, but avoids many of the problems with consid-ering many nuances of meaning or low-frequency senses.For example, the "progeny" sense of issue, as well as the"exit" sense, are omrnitted from our lexicon.
The ideais to preserve in the core lexicon the common, coarsestdistinctions among senses.Each entry has a part of speech :POS and a set of setof core :SENSES.
Each core sense has a :TYPE field thatindicates p for all primary senses and s for secondarysenses.
While we are in the process of enriching the in-formation cont,ained in this field, the general rule is thatthe semantic interpreter should not consider secondarysenses without specific contextual information.
For ex-ample, the word "yard" can mean an enclosed area, aworkplace, or a unit, of measure, but only the enclosedarea sense is considered in the zero-context.The :PAR field links each word sense to its immediateparent in t,he semantic hierarchy.
Without going throughthe entire hierarchy, it is difficult to convey the seman-tics of each sense, but the parents and siblings of the twosenses of the noun "issue" can give an idea of the cover-age of the lexicon.
In the output below, word senses aregiven by a root followed by a sense number, with concep-tual categories designated by any atom beginning withc-.
Explicit derivations a.re shown by roots followed byendings and additional type specifiers:NOUN-ISSUE1:PARENT CHAIN: c-concern c-mental-obj c-objc-entity somethingSIBLINGS: (all nouns) regardl realm2puzzle1 province2 premonition1 pity1pet2 parameter1 ground3 goodwill1feeling2 enigma1 dr aw 2 department2concern1 cause2 care1 business3baby2 apprehend-ion-xNOUN-ISSUE2:parent chain: c-published-document c-documentc-phys-obj c-obj c-entity somethingSIBLINGS: (all nouns): week-ly-xtranscript1 tragedy2 tome1supplement2 strip4 source2serial1 scripture1 romance2profile2 digest1 bible1paper3 paper2 pamphlet 1obituary1 novel1 notice2memoir1 map 1 manual 1library1 journal1 handbook1guide 1 grammar1 gazette1feature4 facsimile1 epic1fiction1 column1 book1volume1thesaurus1sof twarelpublicat ion2paperback1omnibus1month-ly-xmagazine 1anthology1dissertation1encyclopedia1period-ic-al-xdirectorylcomiclcalendarlarticlelcopy2 atlasl dictionarylcolumn2 blurb1 cataloguelbulletinl brochurel biographylbibliographyl constitute-ion-xlThe basic semantic hierarchy acts as a sense-disambiguated thesaurus \[7\], under the assumption thatin the absence of more specific knowledge word senseswill tend to share semantic constraints with the mostclosely related words.
Note that derivative lexical en-tries, such as week- ly -x  above, do "double duty" inthe lexicon, so that an application program can use thederivation as well as the semantics of the derivative form.The :ASSOC field, not currently used in processing,includes the lexicographer's choice of synonym or closelyrelated words for each sense.The :SYNTAX field encodes syntactic constraints andsubcategorizations for each sense.
Where senses shareconstraints (not the case in this example), these can beencoded at the level of the word entry.
When the syntac-tic constraints (such as io - rec ,  one-ob j ,  and no-obj)influence semantic preferences, these are attached to thesense entry.
For example, in this case "issue" used asan intransitive verb would favor "passive moving" eventhough it is a secondary sense, while the io - rec  subcat-egorization in the first two senses means that the ditran-strive form will fill the recipient conceptual role.
Thegrammatical knowledge base of the system relates thesesubcategories to semantic roles.The :G-DEKIV and :S-DEKIV fields mark morphologi-cal derivations.
G-DERIV (NIL in this case to indicate noderivations) encodes these derivations at the word rootlevel, while S-DEItIV encodes derivations at the sensepreference l vel.
We have been gradually moving more ofthe derivations to the sense level on the basis of corpusanalysis.
For example, the S-DERIV constraint allows"issuance" to derive from either of the first two sensesof the verb, with "issuer" and "issuable" deriving onlyfrom the "giving" sense.The derivation triples (such as ( -e r  noun t r _actor ) )encode the form of each affix, the resulting syntacticcategory (usually redundant), and the "semantic trans-formation" that applies between the core sense and theresulting sense.
For example, the "issuer" in this casewould play the actor role of sense one of the verb issue.Because derivations often apply to multiple senses andoften result in different semantic transformations (for ex-ample, the ending - ion  can indicate the act of perform-ing some action, the object of the action, or the resultof the action), the lexicon often contains strongly "pre-ferred" interpretations, to help control the ambiguity.The lexicon currently contains 8,775 roots (with nounand verb roots separated) and 13,415 senses.
In addition,there are about 10,000 explicit derivations.In applying the lexicon, the most obvious errors arisefrom collocational expressions, so the lexicon now in-cludes a substantial number of (currently several hun-dred) common collocations, such as verb-particles andverb-complement combinations.
These expressions areoften semantically productive, but the representation fcommon expressions helps the semantic interpreter toapply preferences.
For example, the following is one setof entries for expressions with take:( take:POS verb: SPECIAL(( takeS0: S-COMPOUNDS((Vc (or (member c-verb_advise2-objc-act-of-verb_blamelc-act-of-verb_losel noun_prof it2)c-giving) ) ):EXAMPLE (take delivery):PAR (c-receiving) )( take51:S-COMPOUNDS ((vc (or (member noun effortl)c-temporal-obj c-energy))):EXAMPLE (the job takes up time)):PAR (c-require-tel) )( take52:S-COMPOUNDS ((vc (member noun_news1noun_burdenl noun_load2 noun_pressure3noun_pressure2 noun_stressl noun_stress2c- act-of-verb_strainl) ) ):PAR (c-managing) )( take58:S-COMPOUNDS ((vc (or (member noun_office2noun_advant age i noun_chargelc-act-of-verb_controll noun_command2noun_r espons ibilit yl ) c-structure-telc-shape-rel) ) ):PAR (c-contracting) )( take59:S-COMPOUNDS ((vc (member noun e f fec t1) ) ):PAR (c-transpire) )( take60:S-COMPOUNDS ((vc (or c-task))):PAR (c-deciding) ))The above entries contain only the verb-complement(vc) relations for "take".
Whether these expressions areproductive or not, the lexicon can include explicit wordsense pairings (such as take52 with noun_pressureS),in which case the collocation helps to discriminate thesenses of both verb and complement, or a pairing witha conceptuM category (such as take51 with c-temporai-obj), in which case the pairing is more likely to conflictwith another but will cover a much broader class of ex-pressions (from take one's time to take years).The descriptions above cover most of the central com-ponents of the GE lexicon, especially those that allowfor general sense preferences in text.
The natural ques-tion is how to make use of all this knowledge in semanticinterpretation.
The next section describes the generalproblem of applying lexical knowledge.A little knowledge:a dangerous thingSuccess with the new" lexicon came quickly in retrofittingthe knowledge base to domain-specific database genera-362tion systems.
By allowing systems to specify key por-tions of the knowledge base for certain domains (about300 word senses for MUCK-II), we derived a benefit fromthe core lexicon (i. e. reducing lexicon-building effort)without introducing many spurious enses.
However, themain goal of the effort was to achieve some sort of usefulsemantic results without any customization.
The samealgorithms applying the core lexicon to arbitrary sam-ples of the Wall Street Journal, not surprisingly, causedsome serious problems.
After three "easy" sentences, theprogram encountered the following typical input:A form of asbestos once used to make Kentcigarette filters has caused a high percentageof cancer deaths among a group of workers ex-posed to it more than 30 years ago, researchersreported.While producing over 100 parses for the above sentence,the program did quite poorly at first in determiningthe "preferred" sense of each word and even at distin-guishing noun forms from verb forms without any "do-main" knowledge.
This seemed to be a practical exam-ple of the "I see a cow" problem (i.e.
a large dictio-nary greatly increases the degree of ambiguity by intro-ducing low-frequency possibilities).
After analyzing theprogram's performance on many examples of this type,we found that we had already reached diminishing re-turns in adding words and word senses to the lexicon,and that most of the problems with the sense taggingtask broke down into three categories: (1) local syntac-tic preferences, such as that "make" is a verb (as opposedto "a make of car") and "filters" is a noun, (2) simple at-tachment preferences ( uch as minimal attachment), and(3) recognition of "senseless" parsing distinctions, suchas the multiple attachments of "once used", "among agroup...", and "exposed to it" (e. g. whether "amonga group" modifies "deaths", "percentage", or "caused"does not affect semantic preferences).Word sense preferences are only loosely coupled to"traditional" syntactic and semantic preferences.
Be-cause many preferences depend on local constraints andlexical relations, we chose to handle some of these is-sues by using text pre-processing to limit parsing andlexical ambiguity.
The next section briefly describes thedivision of effort between pre-processing and traditionalparsing.applying semantic onstraints as selectional restrictionsand pruning off paths with low semantic "scores".The motivation for pre-processing, of course, is thatambiguity at the word level is such a problem.
Evenwith our moderate-size l xicon, almost any English con-tent word has more than one part of speech.
"Obvi-ous" nouns such as table and case can appear as verbs,and almost all verbs can appear as nouns.
Tagging hasemerged as an essential component in corpus-processingsystems, removing or reducing this part-of-speech am-biguity.
Our effort uses a tagger to perform dynamicpart-of-speech tagging based on lexical and morpholog-ical analysis.
The tagger is in some ways similar toChurch's method \[9\], but is lexicon-dependent (Church'ssystem does not use morphology) and combines tatis-tics with heuristics (such as knowing that words follow-ing determiners are nouns, rather than relying only onspecific rules).
The tagger tags only content words, andprocesses input at a rate of 500,000 words per hour.While the tagger uses a simple lexical ookup, we foundit useful to use another pre-processing procedure to cor-rect some grammar-specific tagging problems as well asto fetch collocations from the lexicon before parsing.
In afew cases, this post-tagging procedure re-introduces am-biguity where the tagger gives a specific choice.
Whilethe accuracy of the tagger is highest when it is heavilybiased toward nouns, the accuracy of the parser dependson having some verbs.After pre-processing, the TRUMP parser and semanticinterpreter \[8\] go to work on the tagged text, collectingrelations (such as modification and verb-complement) athe level of each clause.
The sense preference mecha-nism assigns a total score to each relation to help withattachment, as well as maintaining a weighted vector ofpreference information that determines the final sensetagging of the text.
The final sense tag thus does notdepend on having a single final correct parse.The following list describes the vector of five prefer-ence scores for each word sense, along with the five con-tributing preferences for each role filler:Sense preferences:- frequency preference (zero-context)- morphological pref.
(primary or secondary)- cluster preference (based on topic, etc.
)- collocation (phrase) preference- syntactic preference of senseProcess ing  and  pre -process ingThe current style of processing separates both syntac-tic and semantic analysis into two stages.
The pre-processing stage performs a morphological nalysis andquick lexical lookup of the text, followed by taggingand bracketing (including stochastic tagging with cor-rection) and col\]ocational nalysis.
The result of thispre-processing is a pre-filtered version of the text, withsome of the lexical amnbiguity eliminated as well as base-line semantic preferences.
In the second stage, a morecomplete analysis parses the text in a chart style \[8\],Roel-filler preferences:- preference for filer, independent of attachment- role pref.
(how well filler fills role)- rel pref.
(how well frame "likes" role)- base preference (how well role likes frame)- syntactic preference of fillerSince each word sense can have roles, the relations be-tween head and filler reflect he interactions among sensepreferences in the text.
The final choice of sense tagsthus indirectly reflects correct attachment and syntacticanalysis.363Certainly, the bulk of work that remains is in "fillingout" these sparse preference vectors.
The next sectioncomments on the results produced using the still-sparsepreference information.system to sense tagging of arbitrary text.
We expect oevaluate these results on tasks in information retrieval,and, later, machine translation, to determine the like-lihood of achieving substantive improvements hroughsense-based semantic analysis.Current status and interim resultsIt is still difficult to evaluate the results of this sort of ef-fort.
The new lexicon and sense preference mechanism atleast shows strong evidence of improved transportability,since the task of customizing the lexicon to a limited do-main now takes no more than a day or two.
The systemalso shows excellent lexical and morphological coverage,with well over 90% of non-proper-noun word occurrencescovered.
When tested on the Wall Street Journal texts(for which there has been no adaptation or customizationaside from a company-name r cognizer), it rarely pro-duces a single correct parse; however, the partial parsesproduced generally cover most of the text at the clauselevel.The examples of sense-coded text shown earlier areproduced by combining clause-level fragments producedby the analyzer.
Since most semantic preferences appearat this level (and those that do not, do not depend onsyntactic analysis), the results of this sense-coding areencouraging.
At least, we have never before been ableto produce any partial semantic results from processingarbitrary text.We made an unsuccessful attempt at evaluating theaccuracy of sense-tagging over a corpus.
First, we dis-covered that a human "expert" had great difficulty iden-tifying each sense, and that this task was far more te-dious than manual part-of-speech tagging or bracketing.Second, we questioned what we would learn from theevaluation of these partial results, and have since turnedour attention back to task-oriented evaluation.Our next step is to evaluate the effect of text cod-ing on an information retrieval task, by applying tradi-tional term-weighted statistical retrieval methods to therecoded text.
One intriguing aspect of this approachis that errors in distinguishing sense preferences shouldnot be too costly in this task, so long as the program isfairly consistent in its disambiguation of terms in boththe source texts and the input queries.
At the sametime, we will be applying the system to much broaderdatabase generation projects than those of SCISOR andMUCK-II.ConclusionWe have developed a substantial knowledge base for textprocessing, especially a word-sense-based lexicon, andapplying this new lexicon to semantic interpretation anddatabase generation.
In database generation, the newknowledge base has proven successful in reducing theamount of lexicon engineering required, although cur-rent database generation tasks are still too small for thiseffect o be more than marginal.
In generic text process-ing, there are some encouraging results from applying theReferences\[1\] B. Grosz, D. Appelt, P. Martin, and F. Pereira.TEAM: An experiment in the design of transportablenatural language interfaces.
Technical Report 356,SRI International, 1985.\[2\] Madeleine Bates and Robert J. Bobrow.
A trans-portable natural language interface for informationretrieval.
In Proceedings of the 6th Annual Interna-tional ACM SIGIR Conference, ACM Special Inter-est Group on Information Retrieval and AmericanSociety for Information Science, Washington, D.C.,1983.\[3\] Paul S. Jacobs and Lisa F. Rau.
The GE NLToolset:A software foundation for intelligent ext processing.In Proceedings of the Thirteenth International Con-ference on Computational Linguistics, Helsinki, Fin-land, 1990.\[4\] Lisa F. Rau and Paul S. Jacobs.
Integrating top-down and bottom-up strategies in a text processingsystem.
In Proceedings of Second Conference on Ap-plied Natural Language Processing, pages 129-135,Morristown, NJ, Feb 1988.
ACL.\[5\] Beth Sundheim.
Second message understanding con-ference (MUCK-II) test report.
Technical Report1328, Naval Ocean Systems Center, San Diego, CA,1990.\[6\] R. Krovetz.
Lexical acquisition and information re-trieval.
In U. Zernik, editor, First International Lex-ical Acquisition Workshop.
1989.\[7\] E. Fox, J. Nutter, T. Ahlswede, M. Evens, andJ.
Markowitz.
Building a large thesaurus for informa-tion retrieval.
In Proceedings of Second Conferenceon Applied Natural Language Processing.
Associationfor Computational Linguistics, February 1988.\[8\] P. Jacobs.
TRUMP: A transportable language un-derstanding program.
Technical Report CRD89/181,General Electric Corporate Research and Develop-ment, Schenectady, NY, 1989.\[9\] K. Church, W. Gale, P. Hanks, and D. Hindle.
Pars-ing, word associations, and predicate-argument rela-tions.
In Proceedings of the International Workshopon Parsing Technologies, Carnegie Mellon University,1989.364
