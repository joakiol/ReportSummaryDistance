Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 807?811,Dublin, Ireland, August 23-24, 2014.UTU: Disease Mention Recognition and Normalization with CRFs andVector Space RepresentationsSuwisa Kaewphan1,2,3?, Kai Hakaka1?, Filip Ginter11Dept.
of Information Technology, University of Turku, Finland2Turku Centre for Computer Science (TUCS), Turku, Finland3The University of Turku Graduate School (UTUGS), University of Turku, Finlandsukaew@utu.fi, kahaka@utu.fi, ginter@cs.utu.fiAbstractIn this paper we present our system par-ticipating in the SemEval-2014 Task 7in both subtasks A and B, aiming atrecognizing and normalizing disease andsymptom mentions from electronic medi-cal records respectively.
In subtask A, weused an existing NER system, NERsuite,with our own feature set tailored for thistask.
For subtask B, we combined wordvector representations and supervised ma-chine learning to map the recognized men-tions to the corresponding UMLS con-cepts.
Our system was placed 2nd and 5thout of 21 participants on subtasks A and Brespectively showing competitive perfor-mance.1 IntroductionThe SemEval 2014 task 7 aims to advance the de-velopment of tools for analyzing clinical text.
Thetask is organized by providing the researchers an-notated clinical records to develop systems thatcan detect the mentions of diseases and symptomsin medical records.
In particular, the SemEval task7 comprises two subtasks, recognizing the men-tions of diseases and symptoms (task A) and map-ping the mentions to unique concept identifiersthat belong to the semantic group of disorders inthe Unified Medical Language System (UMLS).Our team participated in both of these sub-tasks.
In subtask A, we used an existing namedentity recognition (NER) system, NERsuite, sup-plemented with UMLS dictionary and normaliza-tion similarity features.
In subtask B, we com-bined compositional word vector representations?These authors contributed equally.This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/with supervised machine learning to map the rec-ognized mentions from task A to the UMLS con-cepts.
Our best systems, evaluated on strict match-ing criteria, achieved F-score of 76.6% for the sub-task A and accuracy of 60.1% for the subtask B,showing competitive performance in both tasks.2 Task A: Named Entity Recognitionwith NERSuiteThe ML approach based on conditional randomfields (CRFs) has shown to have state-of-the-artperformance in recognizing the biological entities.We thus performed task A by using NERsuite,an existing NER toolkit with competitive perfor-mance on biological entity recognition (Camposet al., 2013).NERsuite is a NER system that is built ontop of the CRFsuite (Okazaki, 2007).
It con-sists of three language processing modules: a to-kenizer, a modified version of the GENIA taggerand a named entity recognizer.
NERsuite allowsuser-implemented features in addition to dictio-nary matching and features shown to benefit thesystems such as raw token, lemma, part-of-speech(POS) and text chunk.Prior to detecting the disease mentions by therecognizer module of NERsuite, the clinical textis split into sentences by using GENIA SentenceSplitter, a supervised ML system that is known tobe well optimized for biomedical texts (S?tre etal., 2007).
The sentences are subsequently tok-enized and POS tagged.To represent the positive entities, the ?BIO?model was used in our system.
The first tokensof positive mentions are labeled with ?B?
and therest with ?I?.
Negative examples, non-entities, arethus labeled with ?O?.
This model was used forboth contiguous and discontiguous entities.The features include the normalization similar-ity (see Section 3.3), types of medical records (dis-charge, echo, radiology and ecg), and UMLS dic-807Trained Model Precision Recall F-scoretrain + positive samples 77.3% 72.4% 74.8%train + development 76.7 % 76.5% 76.6%Table 1: The results of our different NERsuitemodels, announced by the organizers.tionary matching in addition to NERsuite?s ownfeature generation.The UMLS dictionary is prepared by extract-ing the UMLS database for the semantic types de-manded by the task.
In addition to those 11 seman-tic types, ?Finding?
was also included in our dic-tionary since, according to its definition, the con-cept is also deemed relevant for the task.
Due tothe common use of acronyms, which are not ex-tensively provided by UMLS, we also extendedthe coverage of our prepared UMLS dictionaryby extracting medical acronyms from the UMLSdatabase using regular expression.We assessed the effect of dictionary matchingby training the models with and without the com-piled UMLS dictionary and evaluating against thedevelopment set.
The model trained with dictio-nary features outperformed the one without.
Thebest model was obtained by training the NERsuitewith UMLS dictionary in case-number-symbolnormalization mode.
In this mode, all letters,numbers and symbols are converted to lower case,zero (0) and underscore ( ) respectively.The regularization parameter (C2) was selectedby using development set to evaluate the bestmodel.
The default parameter (C2 = 1.0) gavethe best performing system and thus was usedthroughout the work.Finally, for the NER task, we submitted twomodels.
The first model was trained with the orig-inal training data and duplicates of sentences withat least one entity mention.
The second modelwas trained by using the combination of the firstmodel?s training data and development set.2.1 Results and DiscussionsOur NER system from both submissions benefitedfrom the increased number of training exampleswhile the more diverse training data set gave a bet-ter performance.
The official results are shown intable 1.The analysis of our best performing NER sys-tem is not possible since the gold standard of thetest data is not publicly available.
We thus simplyanalyze our second NER system based on the eval-uation on the development data.
The F-score of thesystem was 75.1% and 88.0% for the strict and re-laxed evaluation criteria respectively.
Among allthe mistakes made by the system, the discontigu-ous entities were the most challenging ones for theNERsuite.
In development data, the discontiguousentities contribute about 10% of all entities, how-ever, only 2% were recognized correctly.
On thecontrary, the system did well for the other types as73% were correctly recognized under strict crite-ria.
This demonstrates that the ?BIO?
model haslimitations in representing the discontiguous enti-ties.
Improving the model to better represent thediscontiguous entities can possibly boost the per-formance of the NER system significantly.3 Task B: Normalization withCompositional Vector RepresentationsOur normalization approach is based on con-tinuous distributed word vector representations,namely the state-of-the-art method word2vec(Mikolov et al., 2013a).
Our word2vec modelwas trained on a subset of abstracts and full ar-ticles from the PubMed and PubMed Central re-sources.
This data was used as it was readilyavailable to us from the EVEX resource (Van Lan-deghem et al., 2013).
Before training, all non-alphanumeric characters were removed and all to-kens were lower-cased.
Even though a set of unan-notated clinical reports was provided in the taskto support unsupervised learning methods, our ex-periments on the development set showed betterperformance with the model trained with PubMedarticles.
This might be due to the size of the cor-pora, as the PubMed data included billions of to-kens whereas the provided clinical reports totaledin over 200 million tokens.The dimensionality of the word vectors was setto 300 and we used the continuous skip-gram ap-proach.
For other word2vec parameters defaultvalues were used.One interesting feature demonstrated byMikolov et al.
(2013b; 2013c) is that the vectorsconserve some of the semantic characteristics inelement-wise addition and subtraction.
In this taskwe used the same approach of simply summingthe word-level vectors to create compositionalvectors for multi-word entities and concepts, i.e.we looked up the vectors for every token appear-ing in a concept name or entity and summed themto form a vector to represent the whole phrase.808We then formed a lexicon including all preferredterms and synonyms of all the concepts in thesubset of UMLS defined in the task guidelines.This lexicon is a mapping from the compositionalvector representations of the concept names intothe corresponding UMLS identifiers.
To select thebest concept for a recognized entity we calculatedcosine similarity between the vector representa-tion of the given entity and all the concept vectorsin the lexicon and the concept with the highestsimilarity was chosen.Word2vec is generally able to relate differentforms of the same word to each other, but we no-ticed a small improvement in accuracy when pos-sessive suffixes were removed and all tokens werelemmatized.3.1 Detecting CUI-less MentionsAs some of the mentions in the training data do nothave corresponding concepts in the semantic cat-egories listed in the task guidelines, they are an-notated as ?CUI-less?.
However, our normaliza-tion approach will always find the nearest match-ing concept, thus getting penalized for wrong pre-dictions in the official evaluation.
To overcomethis problem, we implemented three separate stepsfor detecting the ?CUI-less?
mentions.
As thesimplest approach we set a fixed cosine similaritythreshold and if the maximal similarity falls belowit, the mention is normalized to ?CUI-less?.
Thethreshold value was selected using a grid search tooptimize the performance on the official develop-ment set.
Although this method resulted in decentperformance, it is not capable of coping with caseswhere the mention has very high similarity or evenexact match with a concept name.
For instanceour system normalized ?aspiration?
mentions intoUMLS concept ?Pulmonary aspiration?
which hasa synonym ?Aspiration?, thus resulting in an exactmatch.
To resolve this kind of cases, we used sim-ilar approach as in the DNorm system (Leaman etal., 2013b), where the ?CUI-less?
mentions occur-ring several times in the training data were addedto the concept lexicon with concept ID ?CUI-less?.As the final step we trained a binary SVM classi-fier to distinguish the ?CUI-less?
mentions.
Theclassifier utilized bag-of-word features as well asthe compositional vectors.
The performance im-provement provided by each of these steps is pre-sented in table 2.
This evaluation shows that eachstep increases the performance considerably, butMethod Strict accuracyB 43.6T 48.4T + L 53.5T + L + C 55.4O 59.3Table 2: Evaluation of the different approachesto detect CUI-less entities on the official develop-ment set compared to a baseline without CUI-lessdetection and an oracle method with perfect de-tection.
This evaluation was done with the entitiesrecognized by our NER system instead of the goldstandard entities.
B = baseline without CUI-lessdetection, T = similarity threshold, L = Lexicon-based method, C = classifier, O = Oracle.the overall performance is still 3.9pp below per-fect detection.3.2 Acronym ResolutionAbbreviations, especially acronyms, form a con-siderable portion of the entity mentions in clini-cal reports.
One of the problems in normalizingthe acronyms is disambiguation as one acronymcan be associated with multiple diseases.
Previ-ous normalization systems (Leaman et al., 2013b)handle this by selecting the matching concept withmost occurrences in the training data.
However,this approach does not resolve the problem ofnon-standard acronyms, i.e.
acronyms that are notknown in the UMLS vocabulary or in other medi-cal acronym dictionaries.
Our goal was to resolveboth of these problems by looking at the other enti-ties found in the same document instead of match-ing the acronym against the concept lexicon.
Withthis approach for instance entity mention ?CP?was on multiple occasions correctly normalizedinto the concept ?Chest Pain?, even though UMLSis not aware of this acronym for the given conceptand in fact associates it with several other con-cepts such as ?Chronic Pancreatitis?
and ?CerebralPalsy?.
However, the overall gain in accuracy ob-tained from this method was only minor.3.3 Normalization Feedback to NamedEntity RecognitionWhile basic exact match dictionary features pro-vide usually a large improvement in NER perfor-mance, they are prone to bias the system to highprecision and low recall.
As both noun and ad-jective forms of medical concepts, e.g.
?atrium?and ?atrial?, are commonly used in clinical texts,809the entities may not have exact dictionary matches.Moreover the different forms of medical termsmay not share a common morphological root dis-covered by simple stemming methods, thus com-plicating approximate matching.
In this task wetried to boost the recall of our entity recognition byfeeding back the normalization similarity informa-tion as features.
These features included the max-imum similarity between the token and the UMLSconcepts as a numerical value as well as a booleanfeature describing whether the similarity exceededa certain threshold.In addition we experimented by calculating thesimilarities for bigrams and trigrams in a slid-ing window around the tokens, but these featuresdid not provide any further performance improve-ments.3.4 Other Directions ExploredThe DNorm system utilizes TF-IDF vectors to rep-resent the entities and concepts but instead of cal-culating cosine similarity, the system trains a rank-ing algorithm to measure the maximal similarity(Leaman et al., 2013a).
Their evaluation, carriedout on the NCBI disease corpus (Do?gan et al.,2014), showed a notable improvement in perfor-mance compared to cosine similarity.
In our anal-ysis we noticed that in 39% of the false predic-tions made by our normalization system, the cor-rect concept was in the top 10 most similar con-cepts.
This strongly suggested that a similar rank-ing method might be beneficial with our system aswell.
To test this we trained a linear SVM to rerankthe top 10 concepts with highest cosine similarity,but we were not able to increase the overall per-formance of the system.
However, due to the stricttime constraints of the task, we cannot concludewhether this approach is feasible or not.As our compositional vectors are formed bysumming the word vectors, each word has an equalweight in the sum.
Due to this our system madevarious errors where the entity was a single wordmatching closely to several concepts with longernames.
For instance entity ?hypertensive?
wasfalsely normalized to concept ?Hypertensive car-diopathy?
whereas the correct concept was ?Hy-pertensive disorder?.
These mistakes could havebeen prevented to some extent if the more impor-tant words had had a larger weight in the sum, e.g.word ?disorder?
is of low significance when try-ing to distinguish different disorders.
However,Team Strict accuracy Relaxed accuracyUTH CCB 74.1 87.3UWM 66.0 90.9RelAgent 63.9 91.2IxaMed 60.4 86.2UTU 60.1 78.3Table 3: Official evaluation results for the top 5teams in the normalization task.weighting the word vectors with their IDF values,document in this case being an UMLS concept, didnot improve the performance.3.5 ResultsThe official results for the normalization task areshown in table 3.
Our system achieved accuracyof 60.1% when evaluated with the official strictevaluation metric.
This result suggests that com-positional vector representations are a competitiveapproach for entity normalization.
However, thebest performing team surpassed our performanceby 14.0pp, showing that there is plenty of room forother teams to improve.
It is worth noting thoughthat their recall in the NER task tops ours by 8.2ppthus drastically influencing the normalization re-sults as well.
To evaluate the normalization sys-tems in isolation from the NER task, a separateevaluation set with gold standard entities shouldbe provided.4 ConclusionsOverall, our NER system can perform well withthe same default settings of NERsuite for genename recognition.
The performance improveswhen relevant features, such as UMLS dictionarymatching and word2vec similarity are added.
Wespeculated that representing the nature of the datawith more suitable model can improve the systemperformance further.
As a part of a combined sys-tem, the improvement on NER system can resultin the increased performance of normalization sys-tem.Our normalization system showed competitiveresults as well, indicating that word2vec-basedvector representations are a feasible way of solv-ing the normalization task.
As future work wewould like to explore different methods for cre-ating the compositional vectors and reassess theapplicability of the reranking approach describedin section 3.4.810AcknowledgementsComputational resources were provided by CSC?
IT Center for Science Ltd, Espoo, Finland.
Thiswork was supported by the Academy of Finland.ReferencesDavid Campos, S?ergio Matos, and Jos?e Lu?
?s Oliveira.2013.
Gimli: open source and high-performancebiomedical name recognition.
BMC bioinformatics,14(1):54.Rezarta Islamaj Do?gan, Robert Leaman, and ZhiyongLu.
2014.
NCBI disease corpus: a resource for dis-ease name recognition and concept normalization.Journal of Biomedical Informatics, 47:1?10, Feb.Robert Leaman, Rezarta Islamaj Do?gan, and ZhiyongLu.
2013a.
DNorm: disease name normaliza-tion with pairwise learning to rank.
Bioinformatics,29(22):2909?2917.Robert Leaman, Ritu Khare, and Zhiyong Lu.2013b.
NCBI at 2013 ShARe/CLEF eHealth SharedTask: Disorder normalization in clinical notes withDNorm.
In Proceedings of the Conference and Labsof the Evaluation Forum.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013a.
Efficient estimation of word represen-tations in vector space.
In ICLR Workshop.Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.Corrado, and Jeffrey Dean.
2013b.
Distributed rep-resentations of words and phrases and their compo-sitionality.
In NIPS, pages 3111?3119.Tomas Mikolov, Wen tau Yih, and Geoffrey Zweig.2013c.
Linguistic regularities in continuous spaceword representations.
In HLT-NAACL, pages 746?751.Naoaki Okazaki.
2007.
CRFsuite: a fast im-plementation of conditional random fields (CRFs).http://www.chokkan.org/software/crfsuite/.Rune S?tre, Kazuhiro Yoshida, Akane Yakushiji,Yusuke Miyao, Y Matsubyashi, and Tomoko Ohta.2007.
AKANE system: protein-protein interactionpairs in BioCreAtIvE2 challenge, PPI-IPS subtask.In Proceedings of the BioCreative II, pages 209?212.Sofie Van Landeghem, Jari Bj?orne, Chih-Hsuan Wei,Kai Hakala, Sampo Pyysalo, Sophia Ananiadou,Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, YvesVan de Peer, and Filip Ginter.
2013.
Large-scale event extraction from literature with multi-level gene normalization.
PLoS ONE, 8(4):e55814.811
