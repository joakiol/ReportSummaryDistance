Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 24?36, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsBilingual Lexicon Extraction from Comparable Corpora Using LabelPropagationAkihiro Tamura and Taro Watanabe and Eiichiro SumitaMultilingual Translation Laboratory, MASTAR ProjectNational Institute of Information and Communications Technology3-5 Hikaridai, Keihanna Science City, Kyoto, 619-0289, JAPAN{akihiro.tamura,taro.watanabe,eiichiro.sumita}@nict.go.jpAbstractThis paper proposes a novel method for lex-icon extraction that extracts translation pairsfrom comparable corpora by using graph-based label propagation.
In previous work,it was established that performance drasti-cally decreases when the coverage of a seedlexicon is small.
We resolve this problemby utilizing indirect relations with the bilin-gual seeds together with direct relations, inwhich each word is represented by a distri-bution of translated seeds.
The seed distri-butions are propagated over a graph repre-senting relations among words, and transla-tion pairs are extracted by identifying wordpairs with a high similarity in the seed dis-tributions.
We propose two types of thegraphs: a co-occurrence graph, representingco-occurrence relations between words, anda similarity graph, representing context sim-ilarities between words.
Evaluations usingEnglish and Japanese patent comparable cor-pora show that our proposed graph propaga-tion method outperforms conventional meth-ods.
Further, the similarity graph achieved im-proved performance by clustering synonymsinto the same translation.1 IntroductionBilingual lexicons are important resources for bilin-gual tasks such as machine translation (MT) andcross-language information retrieval (CLIR).
There-fore, the automatic building of bilingual lexiconsfrom corpora is one of the issues that have attractedmany researchers.
As a solution, a number of pre-vious works proposed extracting bilingual lexiconsfrom comparable corpora, in which documents werenot direct translations but shared a topic or domain1.The use of comparable corpora is motivated by thefact that large parallel corpora are only available fora few language pairs and for limited domains.Most of the previous methods are based on as-sumption (I), that a word and its translation tend toappear in similar contexts across languages (Rapp,1999).
Based on this assumption, many methodscalculate word similarity using context and then ex-tract word translation pairs with a high-context sim-ilarity.
We call these methods context-similarity-based methods.
The context similarities are usu-ally computed using a seed bilingual lexicon (e.g.a general bilingual dictionary) by mapping contextsexpressed in two different languages into the samespace.
In the mapping, information not representedby the seed lexicon is discarded.
Therefore, thecontext-similarity-based methods could not find ac-curate translation pairs if using a small seed lexicon.Some of the previous methods tried to alleviatethe problem of the limited seed lexicon size (Koehnand Knight, 2002; Morin and Prochasson, 2011;Hazem et al2011), while others did not require anyseed lexicon (Rapp, 1995; Fung, 1995; Haghighi etal., 2008; Ismail and Manandhar, 2010; Daume?
IIIand Jagarlamudi, 2011).
However, they suffer theproblems of high computational cost (Rapp, 1995),sensitivity to parameters (Hazem et al2011),low accuracy (Fung, 1995; Ismail and Manandhar,2010), and ineffectiveness for language pairs with1Although Vulic?
et al2011) regarded document-alignedtexts such as texts on Wikipedia as comparable corpora, we donot limit comparable corpora to these kinds of texts.24different types of characters (Koehn and Knight,2002; Haghighi et al2008; Daume?
III and Jagar-lamudi, 2011).In face of the above problems, we propose a novelmethod that uses a graph-based label propagationtechnique (Zhu and Ghahramani, 2002).
The pro-posed method is based on assumption (II), which isderived by recursively applying assumption (I) to the?contexts?
: a word and its translation tend to havesimilar co-occurrence (direct and indirect) relationswith all bilingual seeds across languages.Based on assumption (II), we propose a three-step approach: (1) constructing a graph for eachlanguage with each edge indicating a direct co-occurrence relation, (2) representing every word as aseed translation distribution by iteratively propagat-ing translated seeds in each graph, (3) finding twowords in different languages with a high similaritywith respect to the seed distributions.
By propagat-ing all the seeds on the graph, indirect co-occurrencerelations are also considered when computing bilin-gual relations, which have been neglected in previ-ous methods.
In addition to the co-occurrence-basedgraph construction, we propose a similarity graph,which also takes into account context similarities be-tween words.The main contributions of this paper are as fol-lows:?
We propose a bilingual lexicon extractionmethod that captures co-occurrence relationswith all the seeds, including indirect rela-tions, using graph-based label propagation.In our experiments, we confirm that theproposed method outperforms conventionalcontext-similarity-based methods (Rapp, 1999;Andrade et al2010), and works well even ifthe coverage of a seed lexicon is low.?
We propose a similarity graph which representscontext similarities between words.
In our ex-periments, we confirm that a similarity graphis more effective than a co-occurrence-basedgraph.2 Context-Similarity-based ExtractionMethodThe bilingual lexicon extraction from comparablecorpora was pioneered in (Rapp, 1995; Fung, 1995).The popular similarity-based methods consist of thefollowing steps: modeling contexts, calculating con-text similarities, and finding translation pairs.Step 1.
Modeling contexts: The context of eachword is generally modeled by a vector where eachdimension corresponds to a context word and eachdimension has a value indicating occurrence cor-relation.
Various definitions for the context havebeen used: distance-based context (e.g.
in a sen-tence (Laroche and Langlais, 2010), in a para-graph (Fung and McKeown, 1997), in a predefinedwindow (Rapp, 1999; Andrade et al2010)), andsyntactic-based context (e.g.
predecessors and suc-cessors in dependency trees (Garera et al2009),certain dependency position (Otero and Campos,2008)).
Some treated context words equally re-gardless of their positions (Fung and Yee, 1998),while others treated the words separately for eachposition (Rapp, 1999).
Various correlation mea-sures have been used: log-likelihood ratio (Rapp,1999; Chiao and Zweigenbaum, 2002), tf-idf (Fungand Yee, 1998), pointwise mutual information(PMI) (Andrade et al2010), context heterogene-ity (Fung, 1995), etc.Shao and Ng (2004) represented contexts usinglanguage models.
Andrade et al2010) used aset of words with a positive association as a con-text.
Andrade et al2011a) used dependency re-lations instead of context words.
Ismail and Man-andhar (2010) used only in-domain words in con-texts.
Pekar et al2006) constructed smoothed con-text vectors for rare words.
Laws et al2010) usedgraphs in which vertices correspond to words andedges indicate three types of syntactic relations suchas adjectival modification.Step 2.
Calculating context similarities: The con-texts which are expressed in two different languagesare mapped into the same space.
Previous methodsgenerally use a seed bilingual lexicon for this map-ping.
After that, similarities are calculated basedon the mapped context vectors using various mea-sures: city-block metric (Rapp, 1999), cosine sim-ilarity (Fung and Yee, 1998), weighted jaccard in-dex (Hazem et al2011), Jensen-Shannon diver-gence (Pekar et al2006), the number of overlap-ping context words (Andrade et al2010), Sim-Rank (Laws et al2010), euclidean distance (Fung,1995), etc.25Japanese English0.80.60.50.8????
?
????
(piranha)   (Amazon)????
?
?????
(piranha)    (jungle)????
?
??
(piranha)   (freshwater)??
?
?
(freshwater)  (fish)AssociationQuery ?
Context Word0.80.60.50.80.60.8piranha   ?
Amazonpiranha   ?
junglepiranha   ?
freshwateranaconda ?
Amazonanaconda ?
junglefreshwater ?
fishAssociationQuery ?
Context WordSeed Lexicon (Japanese ?
English) :????
?
Amazon, ?????
?
jungle, ?
?
fishAmazon   jungle????
( 0.8 , 0.6 ) Amazon  junglepiranha    ( 0.8 , 0.6 )anaconda ( 0.8 , 0.6 )similarity????
?
piranha    1.0????
?
anaconda 1.0Japanese English0.50.80.60.80.80.60.8 0.60.50.8?(fish)?????(jungle)????(Amazon)junglefish????
?????
?0.5   ,    0.3   ,     0.2Amazon  jungle  fish0.55  ,   0.4   ,  0.05Amazon jungle  fish0.5 ,      0.3  ,   0.2Proposed MethodContext-similarity-based Method????(piranha)??
(freshwater)freshwaterpiranhaanacondaAmazonFigure 1: An Example of a Previous Method and our Pro-posed MethodAndrade et al2011b) performed a linear trans-formation of context vectors in accordance with thenotion that importance varies by context positions.Gaussier et al2004) mapped context vectors vialatent classes to capture synonymy and polysemy ina seed lexicon.
Fis?er et al2011) and Kaji (2005)calculated 2-way similarities.Step 3.
Finding translation pairs: A pair of wordsis treated as a translation pair when their contextsimilarity is high.
Various clues have been con-sidered when computing the similarities: conceptclass information obtained from a multilingual the-saurus (De?jean et al2002), co-occurrence modelsgenerated from aligned documents (Prochasson andFung, 2011), and transliteration information (Shaoand Ng, 2004).2.1 Problems from Previous WorksMost of previous methods used a seed bilingual lex-icon for mapping modeled contexts in two differentlanguages into the same space.
The mapping heav-ily relies on the entries in a given bilingual lexicon.Therefore, if the coverage of the seed lexicon is low,the context vectors become sparser and its discrim-inative capability becomes lower, leading to extrac-tion of incorrect translation equivalents.Consider the example in Figure 1, where acontext-similarity-based method and our proposedmethod find translation equivalents of the Japaneseword ?????
(piranha)?.
There are three con-text words for the query.
However, the informa-tion on co-occurrence with ???
(freshwater)?
dis-appears after the context vector is mapped, becausethe seed lexicon does not include ???
(freshwa-ter)?.
The same thing happens with the English word?piranha?.
As a result, the pair of ?????
(pi-ranha)?
and ?anaconda?
could be wrongly identifiedas a translation pair.Some previous work focused on the problemof seed lexicon limitation.
Morin and Prochas-son (2011) complemented the seed lexicon withbilingual lexicon extracted from parallel sentences.Koehn and Knight (2002) used identically-spelledwords in two languages as a seed lexicon.
However,the method is not applicable for language pairs withdifferent types of characters such as English andJapanese.
Hazem et al2011) exploited k-nearestwords for a query, which is very sensitive to the pa-rameter k.Some previous work did not require any seed lex-icon.
Rapp (1995) proposed a computationally de-manding matrix permutation method which maxi-mizes a similarity between co-occurrence matricesin two languages.
Ismail and Manandhar (2010) in-troduced a similarity measure between two words indifferent languages without requiring any seed lex-icon.
Fung (1995) used context heterogeneity vec-tors where each dimension is independent on lan-guage types.
However, their performances are worsethan those of conventional methods using a smallseed lexicon.
Haghighi et al2008) and Daume?III and Jagarlamudi (2011) proposed a generativemodel based on probabilistic canonical correlationanalysis, where words are represented by contextfeatures and orthographic features2.
However, theirexperiments showed that orthographic features to beimportant for effectiveness, which means low per-2In Haghighi et al2008) and Daume?
III and Jagarla-mudi (2011), indirect relations with seeds are considered topo-logically, but our method utilizes degrees of indirect correla-tions with seeds.26formance for language pairs with different charactertypes.3 Lexicon Extraction Based on LabelPropagationAs described in Section 2, the performance of previ-ous work is significantly degraded when used with asmall seed lexicon.
This problem could be resolvedby incorporating indirect relations with all the seedswhen identifying translation pairs.
For example, inFigure 1, ?????
(piranha)?
has some degree ofassociation with the seed ??
- fish?
through ???(freshwater)?
in both the Japanese side and the En-glish side, although ?????
(piranha)?
and ??(fish)?
do not co-occur in the same contexts.
More-over, ?anaconda?
has very little association with theseed ??
- fish?
in the English side.
Therefore,the indirect relation with the seed ??
- fish?
helpsto discriminate from between ?piranha?
and ?ana-conda?
and could be an important clue for identify-ing a correct translation pair.To utilize indirect relations, we introduce assump-tion (II): a word and its translation tend to have simi-lar co-occurrence (direct and indirect) relations withall bilingual seeds across languages3.
Based on as-sumption (II), we propose to identify a word pair asa translation pair when its co-occurrence (direct andindirect) relations with all the seeds are similar.To obtain co-occurrence relations with all theseeds, including indirect relations, we focus on agraph-based label propagation (LP) technique (Zhuand Ghahramani, 2002).
LP transfers labels fromlabeled data points to unlabeled data points.
In theprocess, all vertices have soft labels that can be inter-preted as label distributions.
We apply LP to bilin-gual lexicon extraction by representing each word asa vertex in a graph with each edge encoding a directco-occurrence relation.
Translated seeds are propa-gated as labels, and seed distributions are obtainedfor each word.
From the seed distributions, we iden-tify translation pairs.In summary, our proposed method consists ofthree steps (see Algorithm 1): (1) graph construc-3Assumption (I) indicates direct co-occurrence relations be-tween a word and its context words are preserved across differ-ent languages.
Therefore, assumption (II) is derived by recur-sively applying assumption (I) to the ?context words?.Algorithm 1 Bilingual Lexicon ExtractionRequire: comparable corpora De and Df ,a seed lexicon S consists of Se and SfEnsure: Output translation pairs T1-1: Ge = {Ee, V e,W e} ?
construct-graph(De)1-2: Gf = {Ef , V f ,W f} ?
construct-graph(Df )2-1: G?e = {Ee, V e,W e, Qe} ?
propagate-seed (Ge, Se)2-2: G?f = {Ef , V f ,W f , Qf} ?
propagate-seed (Gf , Sf )3: T ?
extract-translation (Qe, Qf , S)tion for each language, (2) seed propagation in eachgraph, (3) translation pair extraction.3.1 Graph ConstructionWe construct a graph representing the associationbetween words for each language.
Each graph is anundirected graph because the association does nothave direction.
The graphs are constructed as fol-lows:Step 1.
Vertex assignment extracts words fromeach corpus, and assigns a vertex to each of the ex-tracted words.
Let V = {v1, ?
?
?
, vn} be a set ofvertices.Step 2.
Edge weight calculation calculates associ-ation strength between two words as the weights ofedges.
Let E and W be a set of edges and that ofthe weights respectively, and eij ?
E links vi andvj , and wij ?
W is the weight of eij .
Note that|E| = |W |.Step 3.
Edge pruning excludes edges whoseweights are lower than threshold, in order to reducethe computational cost during seed propagations.We propose two types of graphs that differ in theassociation measure used in Step 2: a co-occurrencegraph and a similarity graph4.3.1.1 Co-occurrence GraphA co-occurrence graph directly encodes assump-tion (II).
Each edge in the graph indicates correlationstrength between occurrences of two linked words.An example is shown in Figure 1.In edge weight calculation, the co-occurrencefrequencies are first computed for each word pair inthe same context, and then the correlation strength isestimated.
There are various definitions of a contextor correlation measures that can be used (e.g.
the4We can combine the association measures used in a co-occurrence graph and a similarity graph.
We will leave thiscombination approach for future work.27approaches used for modeling contexts in context-similarity-based methods).
In this paper, we usewords in a predefined window (window size is 10in our experiments) as the context and PMI as thecorrelation measure:wij = PMI(vi, vj) = logp(vi, vj)p(vi) ?
p(vj),where p(vi) (or p(vj)) is the probability that vi (orvj) occurs in a context, and p(vi, vj) is the probabil-ity that vi and vj co-occur within the same context.We estimate PMI(vi, vj) by the Bayesian methodproposed by Andrade et al010).
Then, edgeswith a negative association, PMI(vi, vj) ?
0, arepruned in edge pruning.3.1.2 Similarity GraphCo-occurrence graphs are very sensitive to ac-cidental relation caused by lower frequent co-occurrence.
Thus, we propose a similarity graphwhere context similarities are employed as weightsof edges instead of simple co-occurrence-based cor-relations.
Since the context similarities are com-puted by the global correlation among words whichco-occur, a similarity graph is less subject to acci-dental co-occurrence.
The use of a similarity graphis inspired by assumption (III): a word and its trans-lation tend to have similar context similarities withall bilingual seeds across languages5.In edge weight calculation, we first construct acorrelation vector representing co-occurrence rela-tions for each word.
The correlation vectors are con-structed in the same way as the context vectors usedin context-similarity-based methods (see Section 2),where context words are words in a predefined win-dow (window size is 4 in our experiment), the as-sociation measure is PMI, and context words aretreated separately for each position.
A correlationvector for each position is computed separately, thenconcatenated into a single vector within the window.Secondly, we calculate similarities between correla-tion vectors.
There are various similarity measuresthat can be used, and cosine similarity is used in this5This assumption is justified because context similarities arebased on co-occurrence relations that are preserved across dif-ferent languages.paper:wij = Cos(f?i, f?j) =f?i ?
f?j?f?i?
?f?j?,where f?i (or f?j) is the correlation vector of vi (orvj).
Then, in edge pruning, we preserve the edgeswith top 100 weight for each vertex.3.2 Seed PropagationLP is a graph-based technique which transfers thelabels from labeled data to unlabeled data in or-der to infer labels for unlabeled data.
This is pri-marily used when there is scarce labeled data butabundant unlabeled data.
LP has been success-fully applied in common natural language process-ing tasks such as word sense disambiguation (Niuet al2005; Alexandrescu and Kirchhoff, 2007),multi-class lexicon acquisition (Alexandrescu andKirchhoff, 2007), and part-of-speech tagging (Dasand Petrov, 2011).
LP iteratively propagates la-bel information from any vertex to nearby verticesthrough weighted edges, and then a label distribu-tion for each vertex is generated where the weightsof all labels add up to 1.We adopt LP to obtain relations with all bilingualseeds including indirect relations by treating eachseed as a label.
First, each translated seed is assignedto a label, and then the labels are propagated in thegraph described in Section 3.1.The seed distribution for each word is initializedas follows:q0i (z) =??
?1 if vi ?
Vs and z = vi0 if vi ?
Vs and z ?= viu(z) otherwise,where Vs is the set of vertices corresponding totranslated seeds, u is a uniform distribution, qki (i =1 ?
?
?
|V |) is the seed distribution for vi after k prop-agation, and qki (z) is the weight of a label (i.e., atranslated seed) z in qki .After initialization, we iteratively propagate theseeds through weighted edges.
In each propagation,seeds are probabilistically propagated from linkedvertices under the condition that larger edge weightsallow seeds to travel through easier.
Thus, the closervertices are, the more likely they have similar seeddistributions.
In Figure 1, the balloons attached to28vertices in the graphs show examples of the seed dis-tributions generated by propagations.
For example,the English word ?piranha?
has the seed distributionwhere the weights of the seeds ?Amazon?, ?jungle?,and ?fish?
are 0.5, 0.3, and 0.2, respectively.
Specif-ically, each of seed distributions is updated as fol-lows:qmi (z) =??
?q0i (z) if vi ?
Vs?vj?N(vi) wij ?
qm?1j (z)?vj?N(vi) wijotherwise ,where N(vi) is the set of vertices linking to vi.
Weran this procedure for 10 iterations in our experi-ments.3.3 Translation Pair ExtractionAfter label propagations, we treat a pair of words indifferent languages with similar seed distributions asa translation pair.
Seed distribution can be regardedas a vector where each dimension corresponds toeach translated seed and each dimension has up-dated weight through label propagations.
A sim-ilarity between seed distributions can therefore becalculated in the same way as a context-similarity-based method.
In this paper, we use the cosine sim-ilarity defined by the following:Cos(qfx , qey) =?si?S qfx(vfi ) ?
qey(vei )?
?si?S(qfx(vfi ))2?
?si?S(qey(vei ))2,where qfx (or qey) is the seed distribution for a word x(or y) in the source language (or target language), Sis the seed lexicon whose i-th entry si is a pairing ofa translated seed in the source language vfi and onein the target language vei .4 Experiment4.1 Experiment DataWe used English and Japanese patent documentspublished between 1993 and 2005 by the US Patent& Trademark Office and the Japanese Patent Of-fice respectively, which were a part of the data usedin the NTCIR-8 patent translation task (Fujii et al2010).
Note that these documents are not aligned.There are over three million English-Japaneseparallel sentences (e.g.
training data, test data, andPair Japanese Word English WordLexS 2,742 2,566 2,326LexL 28,053 18,587 12,893Table 1: Size of Seed Lexiconsdevelopment data used in the NTCIR-8 patent trans-lation task, which is called NTCIR parallel datahereafter) in the patent data.
However, a preliminaryexamination showed that the NTCIR parallel datacovers less than 3% of all words because there area number of technical terms and neologisms.
There-fore, the patent translation task is a task that requiresbilingual lexicon extraction from non-parallel data.We selected documents belonging to the physicsdomain from each monolingual corpus based on In-ternational Patent Classification (IPC) code6, andthen used them as a comparable corpus in our ex-periments.
As a result, we used 1,479,831 Japanesedocuments and 438,227 English documents.
Thereason for selecting the physics domain is that thisdomain contains the most documents of all the do-mains.The Japanese texts were segmented and part-of-speech tagged by ChaSen7, and the English textswere tokenized and part-of-speech tagged by Tree-Tagger (Schmid, 1994).
Next, function words wereremoved since function words with little seman-tic information spuriously co-occurred with manywords.
As a result, the number of distinct wordsin Japanese corpus and English corpus amounted to1,111,302 and 4,099,8258, respectively.We employed seed lexicons from two sources:(1) EDR bilingual dictionary (EDR, 1990), (2)automatic word alignments generated by runningGIZA++ (Och and Ney, 2003) with the NTCIR par-allel data consisting of 3,190,654 parallel sentences.From each source, we extracted pairs of nouns ap-pearing in our corpus.
From (2), we excluded wordpairs where the average of 2-way translation proba-6SECTION G of IPC code indicates the physics domain.7http://chasen-legacy.sourceforge.jp/8The English words contain words in tables or mathematicalformula but the Japanese words do not because the data formatdiffers between English and Japanese.
This is why the numberof English words is larger than that of Japanese words, eventhough the number of English documents is smaller than that ofJapanese documents.29bilities was lower than 0.5.
The pairs from (1) and(2) amounted to 27,353 and 2,853 respectively, andthe two sets were not exclusive.
In order to mea-sure the impact of seed lexicon size, we preparedtwo seed lexicons: LexL, a large seed lexicon that isa union of all the extracted word pairs, and LexS , asmall seed lexicon that is a union of a random sam-pling one-tenth of the pairs from (1) and one-tenthof the pairs from (2).
Table 1 shows the size of eachseed lexicon.
Note that our seed lexicons includeone-to-many or many-to-one translation pairs.We randomly selected 1,000 Japanese words asour test data which were identified as either a nounor an unknown by ChaSen and were not covered ei-ther by the EDR bilingual dictionary or by the NT-CIR parallel data.
This is because the purpose of ourmethod is to complement existing bilingual dictio-naries or parallel data.
Note that the Japanese wordsin our test data may not have translation equivalentsin the English side.4.2 Competing MethodsWe evaluated two types of our label propagationbased methods against two baselines.
Cooc em-ploys co-occurrence graphs and Sim uses similaritygraphs when constructing graphs for label propaga-tion as described in Section 3.Rapp is a typical context-similarity-basedmethod described in Section 2 (Rapp, 1999).Context words are words in a window (window sizeis 10) and are treated separately for each position.Associations with context words are computedusing the log-likelihood ratio (Dunning, 1993).
Thesimilarity measure between context vectors is thecity-block metric.Andrade is a sophisticated method in context-similarity-based methods (Andrade et al2010).Context is a set of words with a positive associationin a window (window size is 10).
The associationis calculated using the PMI estimated by a Bayesianmethod, and a similarity between contexts is esti-mated based on the number of overlapping words(see the original paper for details).4.3 Experiment ResultsTable 2 shows the performance of each method us-ing LexS or LexL.
Hereafter, Method(L) (orMethod(S)) denotes the Method using LexL (orLexS LexLAcc1 Acc20 Acc1 Acc20Rapp 1.5% 3.8% 4.8% 17.6%Andrade 1.9% 4.2% 5.6% 17.6%Cooc 3.2% 8.6% 9.2% 28.3%Sim 4.1% 11.5% 10.8% 30.6%Table 2: Performance on Bilingual Lexicon ExtractionLexS).
We measure the performance on bilinguallexicon extraction as Top N accuracy (AccN ), whichis the number of test words whose top N translationcandidates contain a correct translation equivalentover the total number of test words (=1,000).
Table2 shows Top 1 and Top 20 accuracy.
We manually9evaluated whether translation candidates contained acorrect translation equivalent.
We did not use recallbecause we do not know if the translation equiva-lents of a test word appear in the corpus.Table 2 shows that the proposed methods outper-form the baselines both when using LexS and usingLexL.
The improvements are statistically significantin the sign-test with 1% significance-level.
The re-sults show that capturing the relations with all theseeds including indirect relations is effective.The accuracies of the baselines in Table 2 areworse than the previous reports: 14% Acc1 and 46%Acc10 (Andrade et al2010), and 72% Acc1 (Rapp,1999).
This is because previous works evalu-ated only the queries whose translation equivalentsexisted in the experiment data, which is not al-ways true in our experiments.
Moreover, previousworks evaluated only high-frequency words: com-mon nouns (Rapp, 1999) and words with a docu-ment frequency of at least 50 (Andrade et al2010).Our test data, on the other hand, includes many low-frequency words.
It is generally true that translationof high-frequency words is much easier than that oflow frequency words.
We discuss the impact of testword frequencies in detail in Section 5.3.Table 2 also shows that Sim outperforms Coocboth when using LexS and using LexL.
The im-provements of Acc20 are statistically significant inthe sign-test with 5% significance-level.9We could not evaluate using existing dictionaries becausemost of the test data are technical terms and neologisms notincluded in the dictionaries.30Sim(L) (2) Cooc(L) (5) Andrade(L) (181)1 psychosis polynephropathy disease2 manic-depression neuroleptic bowel3 epilepsy iridocyclitis disorder4 insomnia Tic symptom5 dementia manic-depression sclerosisSim(S) (974) Cooc(S) (1652) Andrade(S) (1747)1 ulceration dyslinesia bulimia2 ulcer encephalomyelopathy spasticity3 naphthol ganglionic Parkinson4 dementia corticobasal Asymmetric5 gastritis praecox anorexiaTable 3: Translation Candidates for ???
(manic-depression)??
?Cooc(L) Andrade(L) Cooc(S) Andrade(S)1 ???
(0.12) ???
(7.6) ??
(0.016) ??
(5.0)narcotic narcotic dementia posteriori2 ???
(0.11) ??
(6.3) ??
(0.014) ??
(3.7)psychosis old alien,stepchild dementia3 ???
(0.08) ???
(6.3) ??
(0.012) ??
(3.2)neurosis psychosis posteriori ulcer4 ????
(0.05) ????
(5.6) ??
(0.012) ????
(2.9)hormone bronchitis electropositivity period5 ???
(0.04) ??
(5.0) ??
(0.011) ??
(2.5)insomnia posteriori ulcer seriousnessmanic-depressionCooc(L) Andrade(L) Cooc(S) Andrade(S)1 illness illness ganja galop(0.15) (8.6) (0.012) (7.0)2 neurosis psychotherapeutics carbanilide madness(0.11) (7.0) (0.011) (5.4)3 seizure galop paludism libido(0.07) (7.0) (0.011) (5.2)4 psychosis psychosis resignation vitiligo(0.06) (6.8) (0.010) (4.6)5 insomnia somnambulism galop dementia(0.04) (6.7) (0.009) (4.3)Table 4: Seeds with the Highest Weight5 Discussion5.1 Effect of Indirect Relations with SeedsTable 3 shows a list of the top 5 translation can-didates for the Japanese word ????
(manic-depression)?
for each method, where the ranks of thecorrect translations are shown in parentheses next tomethod names.
Table 4 shows the top 5 translatedseeds which characterize the query, where the val-ues in parentheses indicate weight.
Table 3 showsthat Cooc(L) can find the correct translation equiv-alent but Andrade(L) cannot.
Table 4 shows thatCooc(L) can utilize more seeds closely tied to thequery (e.g.
????
(neurosis)?, ????
(insom-nia)?
), which did not occur in the context of thequery in the experiment data.
The result shows thatindirectly-related seeds are also important clues, andour proposed method can utilize these.5.2 Impact of Seed Lexicon SizeTable 2 shows that a reduction of seed lexicon sizedegrades performance.
This is natural for the base-line methods because LexS cannot translate most ofcontext words, which are necessary for word charac-terization.
Consider Andrade(L) and Andrade(S)in the example in Section 5.1.
Table 4 shows thatAndrade(S) uses less relevant seeds with the query,and has to express the query by seeds with less as-sociation.
For example, ????
(psychosis)?
can-not be used in Andrade(S) because LexS does nothave the seed.
Therefore, it is more difficult forAndrade(S) to find correct translation pairs.The proposed methods also share the same ten-dency, although each word is expressed by all theseeds in the seed lexicon.
Consider Cooc(L) andCooc(S) in the above example.
Table 4 shows thatCooc(S) expresses the query by a smooth seed dis-tribution, which is difficult to discriminate from oth-ers.
This is because LexS does not have relevantseeds for the query.
This is why Cooc(S) cannotfind the correct translation equivalent.
On the otherhand, Cooc(L) characterizes ?????
and ?manic-depression?
by strongly relevant seeds (e.g.
????
(psychosis)?,????
(neurosis)?
), and then findsthe correct translation equivalent.To examine the robustness-to-seed lexicon size,we calculated the reduction rate of Acc20 with thefollowing expression: (Acc20 with LexL ?
Acc20with LexS) / Acc20 with LexL.
The reduction ratesof Rapp, Andrade, Cooc, and Sim are 78.4%,76.1%, 69.6%, and 62.4% respectively.
Moreover,the difference between degradation in Cooc and thatin Andrade is statistically significant in the sign-testwith 1% significance-level.
These results indicatethat the proposed methods are more robust to seedlexicon size than the baselines.
This is because theproposed methods can utilize seeds with indirect re-lations while the baselines utilize only seeds in thecontext.To verify our claim, we examined the numberof test words which occurred with no seeds in thecontext.
There were 570 such words in Rapp(S),387 in Rapp(L), 572 in Andrade(S), and 388 inAndrade(L).
The baselines cannot find their trans-31Low Freq.
High Freq.Acc1 Acc20 Acc1 Acc20Rapp(L) 0.5% 2.4% 7.2% 25.6%Andrade(L) 0.3% 1.8% 8.6% 26.3%Cooc(L) 0.8% 4.3% 13.9% 40.7%Sim(L) 2.2% 6.7% 15.0% 42.0%Table 5: Comparison between Performance for High andLow Frequency Wordslation equivalents.
Words such as this occur even ifusing LexL, and that number increases when LexSis used.
On the other hand, the proposed methodsare able to utilize all the seeds in order to find equiv-alents for words such as these.
Therefore, the pro-posed methods work well even if the coverage of aseed lexicon is low.5.3 Impact of Word FrequenciesOur test data includes many low-frequency wordswhich are not covered by the EDR bilingual dic-tionary or the NTCIR parallel data.
624 words ap-pear in the corpus less than 50 times.
Table 5 showsAccN using LexL for 624 low-frequency words and376 high-frequency words.
Table 5 shows that per-formance for low-frequency words is much worsethan that for high-frequency words.
This is becausetranslation of high-frequency words utilizes abun-dant and reliable context information, while the con-text information for low-frequency words is statis-tically unreliable.
In the proposed methods, edgeslinking rare words are sometimes generated basedon accidental co-occurrences, and then unrelatedseed information is transferred through the edges.Therefore, even our label propagation based meth-ods, especially for Cooc, could not identify the cor-rect translation equivalents for rare words.
Sim al-leviated the problem by using a similarity graph inwhich edges are generated based on global correla-tion among words, as indicated by Table 5.
Table5 also suggests that top 20 translation candidates forhigh-frequency words have potential to contribute tobilingual tasks such as MT and CLIR although theoverall performance is still low.5.4 Effect of Similarity GraphsWe examined AccN for synonyms of translatedseeds in Japanese.
The Acc1 and Acc20 of Sim(L)are 15.6% and 56.3%, respectively, and those ofCooc(L) are 9.4% and 37.5%, respectively.
Theresults show that similarity graphs are effective forclustering synonyms into the same translation equiv-alents.
For example, Sim(L) extracted the correcttranslation pair of the English word ?iodine?
andthe Japanese word ??????
?, a synonym of thetranslated seed ????
(iodine)?
in Japanese.
Thisis because synonyms tend to be linked in the similar-ity graph and have similar seed distributions.
On theother hand, in the co-occurrence graph, synonymstend to be indirectly linked through mutual contextwords, so the seed distributions of the two could befar away from each other.There are in particular many loanwords in patentdocuments, which are spelled in different ways fromperson to person.
For example, the loan word for theEnglish word ?user?
is often written as ????
?,but it is sometimes written as ?????
?, with anadditional prolonged sound mark.
Therefore, Simis particularly effective for the experiment data.5.5 Error AnalysisWe discuss errors of the proposed methods exceptthe errors for low-frequency words (see Section5.3).
Our test data includes words whose transla-tion equivalents inherently cannot be found.
Thefirst of these types are words whose equivalent doesnot exist in the English corpus.
This is an unavoid-able problem for methods based on comparable cor-pora.
The second one are words whose Englishequivalents are compound words.
The Japanesemorphological analyzer tends to group a compoundword into a single word, while the English text an-alyzer does not perform a collocation of words di-vided by the delimiter space.
For example, the sin-gle Japanese word ????
is equivalent to ?palmpattern?
or ?palm print?, which is composed oftwo words.
This case was counted as an erroreven though the proposed methods found the word?palm?
as a equivalent of ???
?.A main reason of errors other than those aboveis word sense ambiguity, which is different in ev-ery language.
For example, the Japanese word ??
?32means ?right?
and ?conservatism?
in English.
Theproposed methods merge different senses by prop-agating seeds through these polysemous words inonly one language side.
This is why translation pairscould have wrong seed distributions and then theproposed methods could not identify correct trans-lation pairs.
We will leave this word sense disam-biguation problem for future work.6 Related WorkBesides the comparable corpora approach discussedin Section 2, many alternatives have been proposedfor bilingual lexicon extraction.
The first is a methodthat finds translation pairs in parallel corpora (Wuand Xia, 1994; Fung and Church, 1994; Och andNey, 2003).
However, large parallel corpora are onlyavailable for a few language pairs and for limiteddomains.
Moreover, even the large parallel corporaare relatively smaller than comparable corpora.The second is a method that exploits the Web.
Luet al2004) extracted translation pairs by miningweb anchor texts and link structures.
As an alter-native, mixed-language web pages are exploited byfirst retrieving texts including both source and tar-get languages from the web by using a search en-gine or simple rules, and then extracting transla-tion pairs from the mixed-language texts utilizingvarious clues: Zhang and Vines (2004) used co-occurrence statistics, Cheng et al2004) used co-occurrences and context similarity information, andHuang et al2005) used phonetic, semantic andfrequency-distance features.
Lin et al2008) pro-posed a method for extracting parenthetically trans-lated terms, where a word alignment algorithm isused for establishing the correspondences betweenin-parenthesis and pre-parenthesis words.
However,those methods cannot find translation pairs whenthey are not connected with each other through linkstructures, or when they do not co-occur in the sametext.Transliteration is a completely different way forbilingual lexicon acquisition, in which a word inone language is converted into another language us-ing phonetic equivalence (Knight and Graehl, 1998;Karimi et al2011).
Although machine transliter-ation works particularly well for proper names andloan words, it cannot be employed for phoneticallydissimilar translations.All the methods mentioned above may poten-tially extract translation pairs more precisely thanour comparable corpora approach when their under-lying assumptions are satisfied.
We might improvethe performance of our method by augmenting aseed lexicon with translation pairs extracted usingthe above methods, as experimented with in Section4, in which additional lexical entries are includedfrom parallel data.7 ConclusionWe proposed a novel bilingual lexicon extractionmethod using label propagation for alleviating thelimited seed lexicon size problem.
The proposedmethod captures relations with all the seeds in-cluding indirect relations by propagating seed in-formation.
Moreover, we proposed using similar-ity graphs in propagation process in addition to co-occurrence graphs.
Our experiments showed that theproposed method outperforms conventional context-similarity-based methods (Rapp, 1999; Andrade etal., 2010), and the similarity graphs improve theperformance by clustering synonyms into the sametranslation.We are planning to investigate the following openproblems in future work: word sense disambigua-tion and translation of compound words as describedin (Daille and Morin, 2005; Morin et al2007).In addition, indirect relations have also been usedin other tasks, such as paraphrase acquisition frombilingual parallel corpora (Kok and Brockett, 2010).We will utilize their random walk approach or othergraph-based techniques such as modified adsorp-tion (Talukdar and Crammer, 2009) for generatingseed distributions.
We are also planning an end-to-end evaluation, for instance, by employing the ex-tracted bilingual lexicon into an MT system.AcknowledgmentsWe thank anonymous reviewers of EMNLP-CoNLL2012 for helpful suggestions and comments on a firstversion of this paper.
We also thank anonymous re-viewers of First Workshop on Multilingual Model-ing (MM-2012) for useful comments on this work.33ReferencesAndrei Alexandrescu and Katrin Kirchhoff.
2007.Data-Driven Graph Construction for Semi-SupervisedGraph-Based Learning in NLP.
In Human LanguageTechnologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics; Proceedings of the Main Confer-ence, pages 204?211.Daniel Andrade, Tetsuya Nasukawa, and Junichi Tsu-jii.
2010.
Robust Measurement and Comparisonof Context Similarity for Finding Translation Pairs.In Proceedings of the 23rd International Conferenceon Computational Linguistics (COLING 2010), pages19?27.Daniel Andrade, Takuya Matsuzaki, and Junichi Tsu-jii.
2011a.
Effective Use of Dependency Structurefor Bilingual Lexicon Creation.
In Proceedings ofthe 12th International Conference on ComputationalLinguistics and Intelligent Text Processing (CICLing2011) - Volume Part II, pages 80?92.Daniel Andrade, Takuya Matsuzaki, and Junichi Tsujii.2011b.
Learning the Optimal Use of Dependency-parsing Information for Finding Translations withComparable Corpora.
In Proceedings of the 4th Work-shop on Building and Using Comparable Corpora,pages 10?18.Pu-Jen Cheng, Jei-Wen Teng, Ruei-Cheng Chen, Jenq-Haur Wang, Wen-Hsiang Lu, and Lee-Feng Chien.2004.
Translating Unknown Queries with Web Cor-pora for Cross-Language Information Retrieval.
InProceedings of the 27th Annual International ACM SI-GIR Conference on Research and Development in In-formation Retrieval, pages 146?153.Yun-Chuang Chiao and Pierre Zweigenbaum.
2002.Looking for candidate translational equivalents in spe-cialized, comparable corpora.
In Proceedings of the19th International Conference on Computational Lin-guistics (COLING 2002), pages 1?5.Be?atrice Daille and Emmanuel Morin.
2005.
French-English Terminology Extraction from ComparableCorpora.
In Proceedings of 2nd International JointConference on Natural Language Processing (IJCNLP2005), pages 707?718.Dipanjan Das and Slav Petrov.
2011.
Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Pro-jections.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Hu-man Language Technologies (ACL-HLT 2011), pages600?609.Hal Daume?
III and Jagadeesh Jagarlamudi.
2011.
Do-main Adaptation for Machine Translation by MiningUnseen Words.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies (ACL-HLT2011),pages 407?412.Herve?
De?jean, ?Eric Gaussier, and Fatia Sadat.
2002.An approach based on multilingual thesauri and modelcombination for bilingual lexicon extraction.
In Pro-ceedings of the 19th International Conference onComputational linguistics (COLING 2002), pages 1?7.Ted Dunning.
1993.
Accurate Methods for the Statis-tics of Surprise and Coincidence.
COMPUTATIONALLINGUISTICS, 19(1):61?74.EDR.
1990.
Bilingual Dictionary.
In Technical ReportTR-029.
Japan Electronic Dictionary Research Insti-tute, Tokyo.Darja Fis?er, Nikola Ljubes?ic?, ?Spela Vintar, and Senja Pol-lak.
2011.
Building and using comparable corpora fordomain-specific bilingual lexicon extraction.
In Pro-ceedings of the 4th Workshop on Building and UsingComparable Corpora, pages 19?26.Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Take-hito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, andSayori Shimohata.
2010.
Overview of the PatentTranslation Task at the NTCIR-8 Workshop.
In Pro-ceedings of the 8th NTCIR Workshop, pages 371?376.Pascale Fung and Kenneth Ward Church.
1994.
K-vec: A New Approach for Aligning Parallel Texts.In Proceedings of the 15th International Conferenceon Computational Linguistics (COLING 1994), pages1096?1102.Pascale Fung and Kathleen McKeown.
1997.
FindingTerminology Translations from Non-parallel Corpora.In Proceedings of the 5th Annual Workshop on VeryLarge Corpora, pages 192?202.Pascale Fung and Lo Yuen Yee.
1998.
An IR Approachfor Translating New Words from Nonparallel, Compa-rable Texts.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguisticsand 17th International Conference on ComputationalLinguistics, Volume 1, pages 414?420.Pascale Fung.
1995.
Compiling Bilingual LexiconEntries from a Non-Parallel English-Chinese Corpus.In Proceedings of the 3rd Annual Workshop on VeryLarge Corpora, pages 173?183.Nikesh Garera, Chris Callison-Burch, and DavidYarowsky.
2009.
Improving Translation Lexicon In-duction from Monolingual Corpora via DependencyContexts and Part-of-Speech Equivalences.
In Pro-ceedings of the 13th Conference on ComputationalNatural Language Learning (CoNLL 2009), pages129?137.Eric Gaussier, Jean-Michel Renders, Irina Matveeva,Cyril Goutte, and Herve De?jean.
2004.
A Geomet-34ric View on Bilingual Lexicon Extraction from Com-parable Corpora.
In Proceedings of the 42nd AnnualMeeting on Association for Computational Linguistics(ACL 2004), pages 526?533.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning Bilingual Lexiconsfrom Monolingual Corpora.
In Proceedings of the46th Annual Meeting of the Association for Computa-tional Linguistics (ACL 2008): the Human LanguageTechnology Conference (HLT), pages 771?779.Amir Hazem, Emmanuel Morin, and Sebastian Pen?a Sal-darriaga.
2011.
Bilingual Lexicon Extraction fromComparable Corpora as Metasearch.
In Proceedingsof the 4th Workshop on Building and Using Compara-ble Corpora, pages 35?43.Fei Huang, Ying Zhang, and Stephan Vogel.
2005.
Min-ing Key Phrase Translations from Web Corpora.
InProceedings of Human Language Technology Confer-ence and Conference on Empirical Methods in Natu-ral Language Processing (HLT-EMNLP 2005), pages483?490.Azniah Ismail and Suresh Manandhar.
2010.
Bilin-gual lexicon extraction from comparable corpora us-ing in-domain terms.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics(COLING 2010), pages 481?489.Hiroyuki Kaji.
2005.
Extracting Translation Equivalentsfrom Bilingual Comparable Corpora.
IEICE - Trans.Inf.
Syst., E88-D:313?323.Sarvnaz Karimi, Falk Scholer, and Andrew Turpin.
2011.Machine Transliteration Survey.
ACM ComputingSurveys, 43(3):1?46.Kevin Knight and Jonathan Graehl.
1998.
MachineTransliteration.
Computational Linguistics, 24:599?612.Philipp Koehn and Kevin Knight.
2002.
Learning aTranslation Lexicon from Monolingual Corpora.
InProceedings of ACL Workshop on Unsupervised Lexi-cal Acquisition, pages 9?16.Stanley Kok and Chris Brockett.
2010.
Hitting the RightParaphrases in Good Time.
In Proceedings of HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics (HLT-NAACL 2010), pages145?153.Audrey Laroche and Philippe Langlais.
2010.
Re-visiting Context-based Projection Methods for Term-Translation Spotting in Comparable Corpora.
In Pro-ceedings of the 23rd International Conference onComputational Linguistics (COLING 2010), pages617?625.Florian Laws, Lukas Michelbacher, Beate Dorow, Chris-tian Scheible, Ulrich Heid, and Hinrich Schu?tze.
2010.A Linguistically Grounded Graph Model for BilingualLexicon Extraction.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics(COLING 2010), pages 614?622.Dekang Lin, Shaojun Zhao, Benjamin Van Durme, andMarius Pasca.
2008.
Mining Parenthetical Transla-tions from the Web by Word Alignment.
In Proceed-ings of the 46th Annual Meeting of the Association forComputational Linguistics (ACL 2008): the HumanLanguage Technology Conference (HLT), pages 994?1002.Wen-Hsiang Lu, Lee-Feng Chien, and Hsi-Jian Lee.2004.
Anchor Text Mining for Translation of WebQueries: A Transitive Translation Approach.
ACMTransactions on Information Systems, 22(2):242?269.Emmanuel Morin and Emmanuel Prochasson.
2011.Bilingual Lexicon Extraction from Comparable Cor-pora Enhanced with Parallel Corpora.
In Proceedingsof the 4th Workshop on Building and Using Compara-ble Corpora, pages 27?34.Emmanuel Morin, Be?atrice Daille, Koichi Takeuchi, andKyo Kageura.
2007.
Bilingual Terminology Mining -Using Brain, not brawn comparable corpora.
In Pro-ceedings of the 45th Annual Meeting of the Associa-tion of Computational Linguistics (ACL 2007), pages664?671.Zheng-Yu Niu, Dong-Hong Ji, and Chew Lim Tan.
2005.Word Sense Disambiguation Using Label PropagationBased Semi-Supervised Learning.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL 2005), pages 395?402.Franz Josef Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, 29:19?51.Pablo Gamallo Otero and Jose?
Ramom Pichel Campos.2008.
Learning Spanish-Galician Translation Equiva-lents Using a Comparable Corpus and a Bilingual Dic-tionary.
In Proceedings of the 9th International Con-ference on Computational Linguistics and IntelligentText Processing (CICLing 2008), pages 423?433.Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and An-drea Mulloni.
2006.
Finding Translations for Low-Frequency Words in Comparable Corpora.
MachineTranslation, 20:247?266.Emmanuel Prochasson and Pascale Fung.
2011.
RareWord Translation Extraction from Aligned Compara-ble Documents.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies (ACL-HLT2011),pages 1327?1335.Reinhard Rapp.
1995.
Identifying Word Translations inNon-Parallel Texts.
In Proceedings of the 33rd AnnualMeeting of the Association for Computational Linguis-tics (ACL 1995), pages 320?322.35Reinhard Rapp.
1999.
Automatic Identification of WordTranslations from Unrelated English and German Cor-pora.
In Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics (ACL1999), pages 519?526.Helmut Schmid.
1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
In Proceedings of the In-ternational Conference on New Methods in LanguageProcessing, pages 44?49.Li Shao and Hwee Tou Ng.
2004.
Mining New WordTranslations from Comparable Corpora.
In Proceed-ings of the 20th International Conference on Compu-tational Linguistics (COLING 2004), pages 618?624.Partha Pratim Talukdar and Koby Crammer.
2009.
NewRegularized Algorithms for Transductive Learning.
InProceedings of the European Conference on MachineLearning and Principles and Practice of KnowledgeDiscovery in Databases (ECML-PKDD 2009), pages442?457.Ivan Vulic?, Wim De Smet, and Marie-Francine Moens.2011.
Identifying Word Translations from Compara-ble Corpora Using Latent Topic Models.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies (ACL-HLT 2011), pages 479?484.Dekai Wu and Xuanyin Xia.
1994.
Learning an English-Chinese Lexicon from a Parallel Corpus.
In Proceed-ings of the First Conference of the Association for Ma-chine Translation in the Americas (AMTA 1994), pages206?213.Ying Zhang and Phil Vines.
2004.
Using the Web forAutomated Translation Extraction in Cross-LanguageInformation Retrieval.
In Proceedings of the 27thAnnual International ACM SIGIR Conference on Re-search and Development in Information Retrieval,pages 162?169.Xiaojin Zhu and Zoubin Ghahramani.
2002.
Learningfrom Labeled and Unlabeled Data with Label Propa-gation.
Technical report, CMU-CALD-02-107.36
