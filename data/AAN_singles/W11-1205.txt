Bilingual Lexicon Extraction from Comparable Corpora Enhanced withParallel CorporaEmmanuel Morin and Emmanuel ProchassonUniversite?
de Nantes, LINA - UMR CNRS 62412 rue de la Houssinie`re, BP 9220844322 Nantes Cedex 03{emmanuel.morin,emmanuel.prochasson}@univ-nantes.frAbstractIn this article, we present a simple and ef-fective approach for extracting bilingual lex-icon from comparable corpora enhanced withparallel corpora.
We make use of structuralcharacteristics of the documents comprisingthe comparable corpus to extract parallel sen-tences with a high degree of quality.
We thenuse state-of-the-art techniques to build a spe-cialized bilingual lexicon from these sentencesand evaluate the contribution of this lexiconwhen added to the comparable corpus-basedalignment technique.
Finally, the value of thisapproach is demonstrated by the improvementof translation accuracy for medical words.1 IntroductionBilingual lexicons are important resources of manyapplications of natural language processing suchas cross-language information retrieval or machinetranslation.
These lexicons are traditionally ex-tracted from bilingual corpora.In this area, the main work involves parallel cor-pora, i.e.
a corpus that contains source texts and theirtranslations.
From sentence-to-sentence aligned cor-pora, symbolic (Carl and Langlais, 2002), statistical(Daille et al, 1994), or hybrid techniques (Gaussierand Lange?, 1995) are used for word and expressionalignments.
However, despite good results in thecompilation of bilingual lexicons, parallel corporaare rather scarce resources, especially for technicaldomains and for language pairs not involving En-glish.
For instance, current resources of parallel cor-pora are built from the proceedings of internationalinstitutions such as the European Union (11 lan-guages) or the United Nations (6 languages), bilin-gual countries such as Canada (English and Frenchlanguages), or bilingual regions such as Hong Kong(Chinese and English languages).For these reasons, research in bilingual lexiconextraction is focused on another kind of bilingualcorpora.
These corpora, known as comparable cor-pora, are comprised of texts sharing common fea-tures such as domain, genre, register, sampling pe-riod, etc.
without having a source text-target textrelationship.
Although the building of comparablecorpora is easier than the building of parallel cor-pora, the results obtained thus far on comparablecorpora are contrasted.
For instance, good resultsare obtained from large corpora ?
several millionwords ?
for which the accuracy of the proposedtranslation is between 76% (Fung, 1998) and 89%(Rapp, 1999) for the first 20 candidates.
(Cao andLi, 2002) have achieved 91% accuracy for the topthree candidates using the Web as a comparable cor-pus.
But for technical domains, for which largecorpora are not available, the results obtained, eventhough encouraging, are not completely satisfactoryyet.
For instance, (De?jean et al, 2002) obtained aprecision of 44% and 57% for the first 10 and 20candidates in a 100,000-word medical corpus, and35% and 42% in a multi-domain 8 million-wordcorpus.
For French/English single words, (Chiaoand Zweigenbaum, 2002) using a medical corpusof 1.2 million words, obtained a precision of about50% and 60% for the top 10 and top 20 candidates.
(Morin et al, 2007) obtained a precision of 51%and 60% for the top 10 and 20 candidates in a 1.527Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 27?34,49th Annual Meeting of the Association for Computational Linguistics,Portland, Oregon, 24 June 2011. c?2011 Association for Computational Linguisticsmillion-word French-Japanese diabetes corpus.The above work in bilingual lexicon extractionfrom comparable corpora relies on the assumptionthat words which have the same meaning in differentlanguages tend to appear in the same lexical contexts(Fung, 1998; Rapp, 1999).
Based on this assump-tion, a standard approach consists of building con-text vectors for each word of the source and targetlanguages.
The candidate translations for a partic-ular word are obtained by comparing the translatedsource context vector with all target context vectors.In this approach, the translation of the words of thesource context vectors depends on the coverage ofthe bilingual dictionary vis-a`-vis the corpus.
Thisaspect can be a potential problem if too few corpuswords are found in the bilingual dictionary (Chiaoand Zweigenbaum, 2003; De?jean et al, 2002).In this article, we want to show how this prob-lem can be partially circumvented by combining ageneral bilingual dictionary with a specialized bilin-gual dictionary based on a parallel corpus extractedthrough mining of the comparable corpus.
In thesame way that recent works in Statistical MachineTranslation (SMT) mines comparable corpora to dis-cover parallel sentences (Resnik and Smith, 2003;Yang and Li, 2003; Munteanu and Marcu, 2005;Abdul-Rauf and Schwenk, 2009, among others),this work contributes to the bridging of the gap be-tween comparable and parallel corpora by offeringa framework for bilingual lexicon extraction fromcomparable corpus with the help of parallel corpus-based pairs of terms.The remainder of this article is organized as fol-lows.
In Section 2, we first present the method forbilingual lexicon extraction from comparable cor-pora enhanced with parallel corpora and the associ-ated system architecture.
We then quantify and anal-yse in Section 3 the performance improvement ofour method on a medical comparable corpora whenused to extract specialized bilingual lexicon.
Fi-nally, in Section 4, we discuss the present study andpresent our conclusions.2 System ArchitectureThe overall architecture of the system for lexicalalignment is shown in Figure 1 and comprises par-allel corpus- and comparable corpus-based align-ments.
Starting from a comparable corpus harvestedfrom the web, we first propose to extract parallelsentences based on the structural characteristics ofthe documents harvested.
These parallel sentencesare then used to build a bilingual lexicon througha tool dedicated to bilingual lexicon extraction.
Fi-nally, this bilingual lexicon is used to perform thecomparable corpus-based alignment.
For a word tobe translated, the output of the system is a rankedlist of candidate translations.2.1 Extracting Parallel Sentences fromComparable CorporaParallel sentence extraction from comparable cor-pora has been studied by a number of researchers(Ma and Liberman, 1999; Chen and Nie, 2000;Resnik and Smith, 2003; Yang and Li, 2003; Fungand Cheung, 2004; Munteanu and Marcu, 2005;Abdul-Rauf and Schwenk, 2009, among others) andseveral systems have been developed such as BITS(Bilingual Internet Test Search) (Ma and Liberman,1999), PTMiner (Parallel Text Miner) (Chen andNie, 2000), and STRAND (Structural TranslationRecognition for Acquiring Natural Data) (Resnikand Smith, 2003).
Their work relies on the observa-tion that a collection of texts in different languagescomposed independently and based on sharing com-mon features such as content, domain, genre, regis-ter, sampling period, etc.
contains probably somesentences with a source text-target text relation-ship.
Based on this observation, dynamic program-ming (Yang and Li, 2003), similarity measures suchas Cosine (Fung and Cheung, 2004) or word andtranslation error ratios (Abdul-Rauf and Schwenk,2009), or maximum entropy classifier (Munteanuand Marcu, 2005) are used for discovering parallelsentences.Although our purpose is similar to these works,the amount of data required by these techniquesmakes them ineffective when applied to specializedcomparable corpora used to discover parallel sen-tences.
In addition, the focus of this paper is not topropose a new technique for this task but to studyhow parallel sentences extracted from a compara-ble corpus can improve the quality of the candidatetranslations.
For theses reasons, we propose to makeuse of structural characteristics of the documentscomprising the comparable corpus to extract auto-28bilingualextractionparallel sentencessource documents  target documentscandidatetranslationsterms to bedocumentsharverstingThe Webextractionlexical alignmentdictionarybilinguallexiconprocessextractionlexical contexts lexical contextsextractionbilingual lexiconsparallel corpus?based alignmentcomparable corpus?based alignmenttranslatedFigure 1: Overview of the system for lexical alignmentmatically parallel sentences.In fact, specialized comparable corpora are gener-ally constructed via the consultation of specializedWeb portals.
For instance, (Chiao and Zweigen-baum, 2002) use CISMeF1 for building the Frenchpart of their comparable corpora and CliniWeb2 forthe English part, and (De?jean and Gaussier, 2002)use documents extracted from MEDLINE3 to build aGerman/English comparable corpus.
Consequently,the documents collected through these portals areoften scientific papers.
Moreover, when the lan-guage of these papers is not the English, the paperusually comprises an abstract, keywords and title inthe native language and their translations in the En-glish language.
These characteristics of scientificpaper is useful for the efficient extraction of parallelsentences or word translations from the documentsforming a specialized comparable corpus for whichone part will inevitably be in English.In this study, the documents comprising theFrench/English specialized comparable corpus were1http://www.chu-rouen.fr/cismef/2http://www.ohsu.edu/cliniweb/3http://www.ncbi.nlm.nih.gov/PubMedtaken from the medical domain within the sub-domain of ?breast cancer?.
These documents havebeen automatically selected from the Elsevier web-site4 among the articles published between 2001 and2008 for which the title or the keywords of the arti-cles contain the multi-word term ?cancer du sein?
inFrench and ?breast cancer?
in English.
We thus col-lected 130 documents in French and 118 in Englishand about 530,000 words for each language.
Sincethe 130 French documents previously collected arescientific papers, each document contains a Frenchabstract which is accompanied by its English trans-lation.
We exploit this structural characteristic of theFrench documents in order to build a small special-ized parallel corpus directly correlated to the sub-domain of ?breast cancer?
involved in the compara-ble corpus.2.2 Parallel Corpus-Based AlignmentWe use the Uplug5 collection of tools for alignment(Tiedemann, 2003) to extract translations from our4http://www.elsevier.com5http://stp.ling.uu.se/cgi-bin/joerg/Uplug29specialized parallel corpus.
The output of such a toolis a list of aligned parts of sentences, that has to bepost-process and filtered in our case.
We clean thealignment with a simple yet efficient method in orderto obtain only word translations.
We associate everysource word from a source sequence with every tar-get word from the target sequence.
As an example,uplug efficiently aligns the English word breast can-cer with the French word cancer du sein (the dataare described in Section 3.1).
We obtain the follow-ing lexical alignment:?
cancer (fr) ?
(en) breast, cancer?
du (fr) ?
(en) breast, cancer?
sein (fr) ?
(en) breast, cancerWith more occurrences of the French word can-cer, we are able to align it with the English words{breast, cancer, cancer, cancer, the, of, breast, can-cer}.
We can then filter such a list by counting thetranslation candidates.
In the previous example, weobtain: cancer (fr) ?
breast/2, the /1, of/1, can-cer/4.
The English word cancer is here the bestmatch for the French word cancer.
In many cases,only one alignment is obtained.
For example, thereis only one occurrence of the French word chromo-some, aligned with the English word chromosome.In order to filter translation candidates, we keep1:1 candidates if their frequencies are comparablein the original corpus.
We keep the most frequenttranslation candidates (in the previous example, can-cer) if their frequencies in the corpus are also com-parable.
This in-corpus frequency constraint is use-ful for discarding candidates that appear in manyalignments (such as functional words).
The criterionfor frequency acceptability is:min(f1, f2)/max(f1, f2) > 2/3with f1 and f2 the frequency of words to be alignedin the parallel corpus.By this way, we build a French/English special-ized bilingual lexicon from the parallel corpus.
Thislexicon, called breast cancer dictionary (BC dictio-nary) in the remainder of this article, is composed of549 French/English single words.2.3 Comparable Corpus-Based AlignmentThe comparable corpus-based alignment relies onthe simple observation that a word and its translationtend to appear in the same lexical contexts.
Basedon this observation, the alignment method, known asthe standard approach, builds context vectors in thesource and the target languages where each vectorelement represents a word which occurs within thewindow of the word to be translated (for instance aseven-word window approximates syntactic depen-dencies).
In order to emphasize significant wordsin the context vector and to reduce word-frequencyeffects, the context vectors are normalized accord-ing to association measures.
Then, the translation isobtained by comparing the source context vector toeach translation candidate vector after having trans-lated each element of the source vector with a gen-eral dictionary.The implementation of this approach can be car-ried out by applying the four following steps (Fung,1998; Rapp, 1999):1.
We collect all the lexical units in the context ofeach lexical unit i and count their occurrencefrequency in a window of n words around i.For each lexical unit i of the source and thetarget languages, we obtain a context vector viwhich gathers the set of co-occurrence units jassociated with the number of times that j andi occur together occ(i, j).
In order to iden-tify specific words in the lexical context and toreduce word-frequency effects, we normalizecontext vectors using an association score suchas Mutual Information (MI) or Log-likelihood,as shown in equations 1 and 2 and in Table 1(where N = a + b + c + d).2.
Using a bilingual dictionary, we translate thelexical units of the source context vector.
If thebilingual dictionary provides several transla-tions for a lexical unit, we consider all of thembut weight the different translations accordingto their frequency in the target language.3.
For a lexical unit to be translated, we com-pute the similarity between the translated con-text vector and all target vectors through vectordistance measures such as Cosine or Weighted30Jaccard (WJ) (see equations 3 and 4 whereassocij stands for ?association score?).4.
The candidate translations of a lexical unit arethe target lexical units ranked following thesimilarity score.j ?ji a = occ(i, j) b = occ(i,?j)?i c = occ(?i, j) d = occ(?i,?j)Table 1: Contingency tableMI(i, j) = log a(a + b)(a + c) (1)?
(i, j) = a log(a) + b log(b) + c log(c)+d log(d) + (N) log(N)?
(a + b) log(a + b)?
(a + c) log(a + c)?
(b + d) log(b + d)?
(c + d) log(c + d)(2)Cosinevkvl =?t assoclt assockt?
?t assoclt2?
?t assockt2(3)WJvkvl =?t min(assoclt, assockt )?t max(assoclt, assockt )(4)This approach is sensitive to the choice of param-eters such as the size of the context, the choice ofthe association and similarity measures.
The mostcomplete study about the influence of these param-eters on the quality of bilingual alignment has beencarried out by Laroche and Langlais (2010).3 Experiments and ResultsIn the previous section, we have introduced our com-parable corpus and described the method dedicatedto bilingual lexicon extraction from comparable cor-pora enhanced with parallel corpora.
In this sec-tion, we then quantify and analyse the performanceimprovement of our method on a medical compara-ble corpus when used to extract specialized bilinguallexicon.3.1 Experimental Test bedThe documents comprising the French/English spe-cialized comparable corpus have been normalisedthrough the following linguistic pre-processingsteps: tokenisation, part-of-speech tagging, and lem-matisation.
Next, the function words were removedand the words occurring less than twice in theFrench and the English parts were discarded.
Fi-nally, the comparable corpus comprised about 7,400distinct words in French and 8,200 in English.In this study, we used four types of bilingual dic-tionary: i) the Wiktionary6 free-content multilin-gual dictionary, ii) the ELRA-M00337 professionalFrench/English bilingual dictionary, iii) the MeSH8metha-thesaurus, and iv) the BC dictionary (see Sec-tion 2.2).
Table 2 shows the main features of the dic-tionaries, namely: the number of distinct French sin-gle words in the dictionary (# SWs dico.
), the num-ber of distinct French single words in the dictionaryafter projection on the French part of the compara-ble corpus (# SWs corpus), and the number of trans-lations per entry in the dictionary (# TPE).
For in-stance, 42% of the French context vectors could betranslated with the Wiktionary (3,099/7,400).Table 2: Main features of the French/English dictionariesName # SWs # SWs # TPEdict.
corpusWiktionary 20,317 3,099 1.8ELRA 50,330 4,567 2.8MeSH 18,972 833 1.6BC 549 549 1.0In bilingual terminology extraction from special-ized comparable corpora, the terminology refer-ence list required to evaluate the performance ofthe alignment programs are often composed of 100single-word terms (SWTs) (180 SWTs in (De?jeanand Gaussier, 2002), 95 SWTs in (Chiao andZweigenbaum, 2002), and 100 SWTs in (Daille andMorin, 2005)).
To build our reference list, we se-lected 400 French/English SWTs from the UMLS96http://www.wiktionary.org/7http://www.elra.info/8http://www.ncbi.nlm.nih.gov/mesh9http://www.nlm.nih.gov/research/umls31meta-thesaurus and the Grand dictionnaire termi-nologique10.
We kept only the French/English pairof SWTs which occur more than five times in eachpart of the comparable corpus.
As a result of filter-ing, 122 French/English SWTs were extracted.3.2 Experimental ResultsIn order to evaluate the influence of the parallelcorpus-based bilingual lexicon induced from thecomparable corpus on the quality of comparable cor-pus based-bilingual terminology extraction, four ex-periments were carried out.
For each experiment,we change the bilingual dictionary required for thetranslation phase of the standard approach (see Sec-tion 2.3):1.
The first experiment uses only the Wiktionary.Since the coverage of the Wiktionary from thecomparable corpus is small (see Table 2), theresults obtained with this dictionary yield alower boundary.2.
The second experiment uses the Wiktionaryadded to the BC dictionary.
This experimentattempts to verify the hypothesis of this study.3.
The third experiment uses the Wiktionaryadded to the MeSH thesaurus.
This experimentattempts to determine whether a specialiseddictionary (in this case the MeSH) would bemore suitable than a specialized bilingual dic-tionary (in this case the BC dictionary) directlyextracted from the corpus.4.
The last experiment uses only the ELRA dic-tionary.
Since the coverage of the ELRA dic-tionary from the comparable corpus is the best(see Table 2), the results obtained with this oneyield a higher boundary.Table 3 shows the coverage of the four bilin-gual lexical resources involved in the previous ex-periments in the comparable corpus.
The first col-umn indicates the number of single words belong-ing to a dictionary found in the comparable cor-pus (# SWs corpus).
The other column indicatesthe coverage of each dictionary in the ELRA dic-tionary (Coverage ELRA).
Here, 98.9% of the sin-gle words belonging to the Wiktionary are included10http://www.granddictionnaire.com/in the ELRA dictionary whereas less than 95% ofthe single words belonging to the Wiktionary+BCand Wiktionary+MeSH dictionaries are included inthe ELRA dictionary.
Moreover, the MeSH and BCdictionaries are two rather distinct specialized re-sources since they have only 117 single words incommon.Table 3: Coverage of the bilingual lexical resources in thecomparable corpusName # SWs Coveragecorpus ELRAWiktionary 3,099 98.8%Wiktionary + BC 3,326 94.8%Wiktionary + MeSH 3,465 94.9%ELRA 4,567 100%In the experiments reported here, the size of thecontext window n was set to 3 (i.e.
a seven-wordwindow), the association measure was the MutualInformation and the distance measure the Cosine(see Section 2.3).
Other combinations of parameterswere assessed but the previous parameters turned outto give the best performance.Figure 2 summarises the results obtained for thefour experiments for the terms belonging to the ref-erence list according to the French to English direc-tion.
As one could expect, the precision of the re-sult obtained with the ELRA dictionary is the bestand the precision obtained with the Wiktionary is thelowest.
For instance, the ELRA dictionary improvesthe precision of the Wiktionary by about 14 pointsfor the Top 10 and 9 points for the top 20.
Theseresults confirm that the coverage of the dictionary isan important factor in the quality of the results ob-tained.
Now, when you add the BC dictionary tothe Wiktionary, the results obtained are also muchbetter than those obtained with the Wiktionary aloneand very similar to those obtained with the ELRAdictionary alone (without taking into account the top5).
This result suggests that a standard general lan-guage dictionary enriched with a small specializeddictionary can replace a large general language dic-tionary.Furthermore, this combination is more interestingthan the combination of the MeSH dictionary with32the Wiktionary.
Since the BC dictionary is inducedfrom the corpus, this dictionary is directly correlatedto the theme of breast cancer involved in the cor-pus.
Consequently the BC dictionary is more suit-able than the MeSH dictionary i) even if the MeSHdictionary specializes in the medical domain and ii)even if more words in the comparable corpus arefound in the MeSH dictionary than in the BC dic-tionary.This last observation should make us relativize theclaim: the greater the number of context vector el-ements that are translated, the more discriminatingthe context vector will be for selecting translationsin the target language.
We must also take into ac-count the specificity of the context vector elementsin accordance with the thematic of the documentsmaking up the corpus studied in order to improvebilingual lexicon extraction from specialized com-parable corpora.5 10 15 201020304050607080TopP????
?bcbcbcbcbcutututututrsrsrsrsrsWiktionary ?ELRA rsWiktionary + BC utWiktionary + MeSH bcFigure 2: Precision of translations found according to therank4 Conclusion and DiscussionIn this article, we have shown how the quality ofbilingual lexicon extraction from comparable cor-pora could be improved with a small specializedbilingual lexicon induced through parallel sentencesincluded in the comparable corpus.
We have eval-uated the performance improvement of our methodon a French/English comparable corpus within thesub-domain of breast cancer in the medical domain.Our experimental results show that this simple bilin-gual lexicon, when combined with a general dic-tionary, helps improve the accuracy of single wordalignments by about 14 points for the Top 10 and 9points for the top 20.
Even though we focus hereon one structural characteristic (i.e.
the abstracts)of the documents comprising the comparable corpusto discover parallel sentences and induced bilinguallexicon, the method could be easily applied to othercomparable corpora for which a bilingual dictionarycan be extracted by using other characteristics suchas the presence of parallel segments or paraphrasesin the documents making up the comparable corpus.AcknowledgmentsThe research leading to these results has re-ceived funding from the European CommunitysSeventh Framework Programme (FP7/2007-2013)under Grant Agreement no 248005.ReferencesSadaf Abdul-Rauf and Holger Schwenk.
2009.
On theuse of comparable corpora to improve SMT perfor-mance.
In Proceedings of the 12th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics (EACL?09), pages 16?23, Athens,Greece.Yunbo Cao and Hang Li.
2002.
Base Noun Phrase Trans-lation Using Web Data and the EM Algorithm.
InProceedings of the 19th International Conference onComputational Linguistics (COLING?02), pages 127?133, Tapei, Taiwan.Michael Carl and Philippe Langlais.
2002.
An IntelligentTerminology Database as a Pre-processor for Statisti-cal Machine Translation.
In L.-F. Chien, B. Daille,K.
Kageura, and H. Nakagawa, editors, Proceed-ings of the 2nd International Workshop on Computa-tional Terminology (COMPUTERM?02), pages 15?21,Tapei, Taiwan.Jiang Chen and Jian-Yun Nie.
2000.
Parallel Web TextMining for Cross-Language Information Retrieval.
InProceedings of Recherche d?Information Assiste?e parOrdinateur (RIAO?00), pages 62?77, Paris, France.33Yun-Chuang Chiao and Pierre Zweigenbaum.
2002.Looking for candidate translational equivalents in spe-cialized, comparable corpora.
In Proceedings of the19th International Conference on Computational Lin-guistics (COLING?02), pages 1208?1212, Tapei, Tai-wan.Yun-Chuang Chiao and Pierre Zweigenbaum.
2003.
Theeffect of a general lexicon in corpus-based identifica-tion of French-English medical word translations.
InR.
Baud, M. Fieschi, P. Le Beux, and P. Ruch, editors,The New Navigators: from Professionals to Patients,Actes Medical Informatics Europe, volume 95 of Stud-ies in Health Technology and Informatics, pages 397?402.Be?atrice Daille and Emmanuel Morin.
2005.
French-English Terminology Extraction from ComparableCorpora.
In Proceedings of the 2nd InternationalJoint Conference on Natural Language Processing (IJ-CLNP?05), pages 707?718, Jeju Island, Korea.Be?atrice Daille, ?Eric Gaussier, and Jean-Marc Lange?.1994.
Towards Automatic Extraction of Monolingualand Bilingual Terminology.
In Proceedings of the 15thInternational Conference on Computational Linguis-tics (COLING?94), volume I, pages 515?521, Kyoto,Japan.Herve?
De?jean and ?Eric Gaussier.
2002.
Une nouvelle ap-proche a` l?extraction de lexiques bilingues a` partir decorpus comparables.
Lexicometrica, Alignement lexi-cal dans les corpus multilingues, pages 1?22.Herve?
De?jean, Fatia Sadat, and ?Eric Gaussier.
2002.An approach based on multilingual thesauri and modelcombination for bilingual lexicon extraction.
In Pro-ceedings of the 19th International Conference onComputational Linguistics (COLING?02), pages 218?224, Tapei, Taiwan.Pascale Fung and Percy Cheung.
2004.
Mining Very-Non-Parallel Corpora: Parallel Sentence and LexiconExtraction via Bootstrapping and EM.
In D. Lin andD.
Wu, editors, Proceedings of Empirical Methodson Natural Language Processing (EMNLP?04), pages57?63, Barcelona, Spain.Pascale Fung.
1998.
A Statistical View on Bilin-gual Lexicon Extraction: From Parallel Corpora toNon-parallel Corpora.
In D. Farwell, L. Gerber, andE.
Hovy, editors, Proceedings of the 3rd Conference ofthe Association for Machine Translation in the Ameri-cas (AMTA?98), pages 1?16, Langhorne, PA, USA.
?Eric Gaussier and Jean-Marc Lange?.
1995.
Mode`lesstatistiques pour l?extraction de lexiques bilingues.Traitement Automatique des Langues (TAL), 36(1?2):133?155.Audrey Laroche and Philippe Langlais.
2010.
Re-visiting Context-based Projection Methods for Term-Translation Spotting in Comparable Corpora.
InProceedings of the 23rd International Conference onComputational Linguistics (COLING?10), pages 617?625, Beijing, China.Xiaoyi Ma and Mark Y. Liberman.
1999.
Bits: AMethod for Bilingual Text Search over the Web.
InProceedings of Machine Translation Summit VII, KentRidge Digital Labs, National University of Singapore.Emmanuel Morin, Be?atrice Daille, Koichi Takeuchi, andKyo Kageura.
2007.
Bilingual Terminology Mining ?Using Brain, not brawn comparable corpora.
In Pro-ceedings of the 45th Annual Meeting of the Associationfor Computational Linguistics (ACL?07), pages 664?671, Prague, Czech Republic.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving Machine Translation Performance by Exploit-ing Non-Parallel Corpora.
Computational Linguistics,31(4):477?504.Reinhard Rapp.
1999.
Automatic Identification of WordTranslations from Unrelated English and German Cor-pora.
In Proceedings of the 37th Annual Meeting of theAssociation for Computational Linguistics (ACL?99),pages 519?526, College Park, MD, USA.Philip Resnik and Noah A. Smith.
2003.
The Webas a parallel corpus.
Computational Linguistics,29(3):349?380.J.
Tiedemann.
2003.
Recycling Translations - Extractionof Lexical Data from Parallel Corpora and their Appli-cation in Natural Language Processing.
Ph.D. thesis,Studia Linguistica Upsaliensia 1.Christopher C. Yang and Kar Wing Li.
2003.
Au-tomatic construction of English/Chinese parallel cor-pora.
Journal of the American Society for InformationScience and Technology, 54(8):730?742.34
