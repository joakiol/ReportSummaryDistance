Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 129?134,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsRepresentation of Morphosyntactic Units and Coordination Structuresin the Turkish Dependency TreebankUmut Sulubacak Gu?ls?en Eryig?itDepartment of Computer EngineeringIstanbul Technical UniversityIstanbul, 34469, Turkey{sulubacak, gulsen.cebiroglu}@itu.edu.trAbstractThis paper presents our preliminary conclu-sions as part of an ongoing effort to construct anew dependency representation framework forTurkish.
We aim for this new framework to ac-commodate the highly agglutinative morphol-ogy of Turkish as well as to allow the annota-tion of unedited web data, and shape our deci-sions around these considerations.
In this pa-per, we firstly describe a novel syntactic repre-sentation for morphosyntactic sub-word units(namely inflectional groups (IGs) in Turkish)which allows inter-IG relations to be discernedwith perfect accuracy without having to hidelexical information.
Secondly, we investigatealternative annotation schemes for coordina-tion structures and present a better scheme(nearly 11% increase in recall scores) than theone in Turkish Treebank (Oflazer et al 2003)for both parsing accuracies and compatibilityfor colloquial language.1 IntroductionIn recent years, dependency parsing has globallyseen great deal of attention, and has constitutedthe underlying framework for the syntactic pars-ing of many multilingual studies.
Even thoughconstituency parsing and grammars are still thepreferred formalism for some well-researched lan-guages, others may have certain traits that put con-stituency parsing in an unfavorable position againstdependency parsing, such as flexible constituent or-dering, which is typical of several prominent lan-guages including Turkish.
Although Turkish is de-cidedly more workable over the dependency for-malism, it has invariably fallen short of usual pars-ing accuracies compared to other languages, as seenclearly in some recent works such as (McDonald andNivre, 2011).There are more parameters to parsing than the for-malism alone, among which the correctness of thecorpora used in learning procedures and the annota-tion schemes of syntactic relations are held in con-sideration as part of this work.
Between the two,the emphasis is on the annotation scheme, whichis proven to significantly affect the parsing per-formance (Bosco et al 2010; Boyd and Meurers,2008).
Our motivation for this research is that thesefactors must also contribute to some extent to theperformance deficiency in parsing Turkish, besidesthe inherent difficulty of parsing the language.
Ouraim is to investigate these points and suggest im-provements where applicable.2 Parsing Framework and Data SetAs our parsing framework, we use MaltParser (Nivreet al 2007) which is a data-driven dependencyparser with an underlying SVM learner based onLIBSVM (Chang and Lin, 2001).
MaltParser iswidely used and has shown high performancesacross various languages (Nivre et al 2006a).
Werun MaltParser with Nivre?s Arc-Standard parsingalgorithm (Nivre, 2003) and use the same optimizedparameters as in (Eryig?it et al 2008).
We also usethe learning features from the last cited work as ourbaseline feature set and an updated version from(Eryig?it et al 2011) of the same data set (Oflazer,2003).
The only difference from the configurationof (Eryig?it et al 2011) is that our baseline parserdoes not exclude non-projective sentences from thecorpus for training, which explains the baseline ac-129Figure 1: The original and the novel IG representations for the word sag?lamlas?t?r?lmas?n?n, which respectively comesto mean strong, to become strong, to strengthen, to be strengthened and of the strengthening of after each derivation.The new morphological tags introduced after each derivation pertain to the relevant IG, and common morphologicalfeatures for the IGs of a single word such as the agreement are given under the final IG.
Model I is the originalrepresentation, while Model II is the new representation we propose.curacy differences (e.g.
67.4% against our 65.0% inlabelled attachment score).3 Proposed Annotation Schemes3.1 IGsWithin the context of data-driven parsing, the mostapparent problem of languages with productivederivational morphology is that words can poten-tially yield a very large morphological tag set, whichcauses severe sparsity in the morphological featuresof words.
To alleviate this problem, words aresplit into morphosyntactic parts called inflectionalgroups (IGs), taking intermediate derivational af-fixes as boundaries.
It is a known fact that analyz-ing sentences as being composed of IGs rather thansurface word forms yields better results in majorNLP problems such as morphological disambigua-tion (Hakkani-Tu?r et al 2002) and syntactic parsing(Eryig?it et al 2008).Within the domain of dependency parsing, IGsas syntactic tokens are not as free as independentwords, since the IGs of each word must be con-nected to each other with an exclusive dependencyrelation named DERIV.
However, other tokens arefree to be connected to an arbitrary IG of a word,with the added benefit of more compact morpholog-ical feature sets to help make the distinction.Other languages with productive derivation, suchas Uralic or Ugric languages, or those orthographi-cally differing from the well-studied European lan-guages, such as Semitic languages, can also benefitfrom using non-word-based morphosyntactic pars-ing tokens, as evidenced for instance by the recentconsiderations of splitting up tokens based on mor-phemes for Hebrew (Tsarfaty and Goldberg, 2008).3.1.1 Current IG RepresentationSince MaltParser accepts input in the standarddata format of the CoNLL-X Shared Task (Buch-holz and Marsi, 2006), the ways in which IGs canbe represented for the parser are limited.
The stan-dard method for annotating IGs using the CoNLL-Xdata fields, as described in (Eryig?it et al 2008), in-volves marking up the FORM and LEMMA fields withunderscores rather than with lexical data as shown inFigure 1.
At first, this method is convenient, as cur-rent feature vectors readily take lexical informationinto account, and as such, a linear transition-basedparser would easily learn to connect adjacent wordsas IGs of the same word as long as the head wordhas an underscore for a stem.
However, an obviousdrawback is that the actual lexical information getslost in favor of marking IGs, preventing the potentialusage of that information in deciding on inter-worddependencies.3.1.2 Proposed IG RepresentationAs an improvement over the original IG repre-sentation described in Section 3.1.1, we propose aslightly different annotation scheme which does notlock out the lexical data columns, by making use of130a new column named IG.
This new column takes aboolean value that is true for non-final IGs of multi-IG words much like the original FORM column, ef-fectively marking the dependents that must be con-nected to the next token in line with the dependencyrelation DERIV.
Once this representation gets inte-grated, lexical information may be assigned to theFORM and LEMMA columns, of which the formergets surface lexical forms of the current stage ofderivation, and the latter gets the FORM data of theprevious IG.3.2 Coordination StructuresAmong the most controversial annotation schemesare those of coordination structures (CS), which aregroups of two or more tokens that are in coordina-tion with each other, usually joined with conjunc-tions or punctuation, such as an ?and?
relation.
Theelements in coordination are the conjuncts of the CS,all of which are semantically linked to a single ex-ternal head.
A large variety of annotation methodsare employed by different corpora, as thoroughlyexplained in (Popel et al 2013).
We chose threeschemes to compare for our parser, which are il-lustrated in Figure 2.
There does not seem to be astandard annotation rising as the best scheme, whichis convenient because different schemes would haveadvantages and disadvantages against different for-malisms and algorithms.Figure 2: I) The original annotation scheme in the Turk-ish Treebank.
II) Swedish Style, an alternative scheme inthe manner of Talbanken (Nivre et al 2006b).
III) Stan-ford Style, another alternative scheme in the manner ofthe Stanford dependencies (De Marneffe and Manning,2008), all with a head-right configuration as per (Popel etal., 2013), as would be appropriate for the predominantlyhead-final Turkish.3.2.1 Current Coordination RepresentationIn the original Turkish Treebank, CSs are anno-tated as shown in scheme I in Figure 2, which ap-pears to be problematic in several ways.
This struc-ture requires a prior conjunct to be connected to anintermediate conjunction, which in turn would beconnected to a posterior conjunct, completing thecoordination.
The CS is then represented by theposterior conjunct, and the dependency relation be-tween the prior conjunct and the conjunction mustbe identical to the dependency relation between theposterior conjunct and the external head, even if itwould not semantically make sense.Considering the tokens are processed incremen-tally from left to right during parsing, one difficultywith this method lies in correctly guessing the de-pendency relation between the prior argument andthe conjunction before the posterior argument andthe external head are even encountered, and unsur-prisingly, directional parsers fail at this task moreoften than usual, resulting in added recall error formany dependency relations not necessarily related tocoordinations.
Another problem is that the schemerequires an intermediate conjunction or punctuationto work, which cannot be relied on even for editedtexts, and would fare much worse if applied on webdata.
One final drawback of this method is that it isarguably more confusing for human annotators com-pared to a straightforward method in which the argu-ments in coordination are directly connected.3.3 Proposed Coordination RepresentationThe drawbacks we have identified in the original CSannotation scheme encourage us to explore alterna-tive approaches to coordinations.
After investigatingmany annotation methods, we expect that the repre-sentation shown as the Swedish Style in Figure 2 willhave the best performance in alleviating the issuesdescribed in Section 3.2.1.Evaluating the Swedish Style representation, weobserve that the CS does not depend on correctlyplaced conjunctions between the arguments, whichincreases compatibility in the absence of well-formatted sentences.
Additionally, the dependencyrelation between the CS and the external head isnot duplicated with this method, which should con-tribute to the reduction of recall error for many de-pendency types.
Finally, we believe this scheme iseasier for human annotators to understand and apply,131and decreases the risk of annotation errors, whichare very common in the Turkish Treebank.4 ExperimentsIn order to practically evaluate our proposed IG andcoordination representations, we first took our ini-tial data set as our baseline, and then applied certainmanual and automatic transformations to the data inorder to create the experimental data sets.
Since allof our data were based on a training corpus withoutan exclusive validation set, we decided to apply 10-fold cross-validation on all of our models to betterevaluate the results.For our tests on IG representations, we attemptedto automatically transform our baseline corpus bypopulating the new IG column with boolean dataderived from the IG relations in the gold-standard,and then automatically fill out the null lexical fieldsby an automatic morphological synthesis procedureusing our morphological tool (Oflazer, 1994).
Thesynthesis procedure, albeit a non-trivial implemen-tation, successfully covered the majority (over 95%)of the lexical data, and we were able to manually an-notate the remaining unrecognized tokens.
To allowMaltParser to recognize the new fields, the CoNLL-X sentence format has been slightly adjusted andsubmitted as a custom input data format, and thebaseline feature vector has been augmented with twoextra features for the IG column information fromthe tokens on top of the Stack and Input pipes.
Thefinal model is named the LexedIG model.On the other hand, we needed to perform a com-plete selective manual review of the corpus and cor-rect numerous annotation errors in CSs before ahealthy conversion could be made.
Afterwards, weran automatic conversion routines to map all CSsto the aforementioned Swedish Style and the com-monly used Stanford Style in order to compare theirspecific performances.
Since a sizeable amount ofmanual corrections were made before the conver-sions, we took the manually reviewed version as anintermediate model in order to distinguish the contri-bution of the automatic conversions from the manualreview.4.1 MetricsFor every model we evaluated via cross-validation,we made specific accuracy analyses and report theprecision (P ), recall (R) and F scores per depen-Baseline LexedIGP R F P R FABLAT 61, 46% 77, 44% 0, 69 61, 50% 76, 67% 0, 68APPOS 66, 67% 12, 87% 0, 22 58, 97% 11, 39% 0, 19CLASS 72, 98% 71, 80% 0, 72 72, 57% 71, 61% 0, 72COORD 83, 95% 53, 70% 0, 66 83, 57% 54, 87% 0, 66DATIV 60, 69% 71, 57% 0, 66 61, 08% 70, 68% 0, 66DERIV 100,00% 100,00% 1,00 100,00% 100,00% 1,00DETER 91, 18% 93, 70% 0, 92 91, 23% 93, 80% 0, 92INSTR 44, 64% 38, 38% 0, 41 45, 87% 40, 96% 0, 43INTEN 87, 99% 81, 95% 0, 85 87, 35% 81, 84% 0, 85LOCAT 73, 40% 79, 25% 0, 76 73, 90% 79, 60% 0, 77MODIF 86, 04% 81, 58% 0, 84 86, 33% 81, 74% 0, 84MWE 71, 72% 58, 72% 0, 65 71, 50% 59, 42% 0, 65NEGAT 92, 56% 70, 00% 0, 80 92, 86% 73, 13% 0, 82OBJEC 77, 90% 71, 36% 0, 74 78, 32% 71, 92% 0, 75POSSE 87, 44% 80, 80% 0, 84 86, 58% 81, 27% 0, 84QUEST 86, 10% 77, 16% 0, 81 85, 77% 77, 16% 0, 81RELAT 70, 00% 49, 41% 0, 58 70, 49% 50, 59% 0, 59ROOT 68, 83% 99, 77% 0, 81 69, 63% 99, 77% 0, 82S.MOD 54, 25% 50, 25% 0, 52 54, 29% 50, 92% 0, 53SENTE 93, 25% 89, 63% 0, 91 93, 20% 89, 68% 0, 91SUBJE 69, 54% 68, 94% 0, 69 69, 87% 69, 65% 0, 70VOCAT 69, 61% 29, 46% 0, 41 69, 23% 29, 88% 0, 42Table 1: Specific accuracies per dependency relation forthe IG-related models.dency relation.
Furthermore, we also calculated gen-eral accuracies as micro-averages from the cross-validation sets, for which we used two metrics,namely the labelled attachment score ASL and theunlabelled attachment score ASU , which are bothaccuracy metrics that compute the percentage of cor-rectly parsed dependencies over all tokens, wherethe unlabelled metric only requires a match with thecorrect head, and the labelled metric additionally re-quires the correct dependency relation to be chosen.4.2 Results and DiscussionOur test results with the LexedIG model suggestthat our proposed IG representation works perfectlywell, as the perfect precision and recall scores of theoriginal model for DERIV relations are preservedin the new model.
Besides this, the reconstructedlexical information that we had populated the newmodel with caused only slight changes in overall ac-curacy that are not statistically significant, which islikely due to the sparsity of lexical data.
Regardless,a model with lexical information for all tokens is es-sentially superior to a similarly performing modelwithout such information.
We foresee that beingable to see lexical forms in the data would increaseboth the speed and the accuracy of human annota-tion.
Additionally, as these experiments were donein preparation for the parsing of web data, we be-lieve that in the near future, with the ability to un-supervisedly parse large amounts of data found on132Baseline Corrected Swedish Style Stanford StyleP R F P R F P R F P R FABLAT 61, 46% 77, 44% 0, 69 61, 70% 79, 46% 0, 69 61, 25% 79, 19% 0, 69 61, 84% 80, 20% 0, 70APPOS 66, 67% 12, 87% 0, 22 62, 86% 9, 78% 0, 17 65, 79% 12, 82% 0, 21 67, 57% 12, 82% 0, 22CLASS 72, 98% 71, 80% 0, 72 72, 54% 71, 76% 0, 72 72, 33% 74, 52% 0, 73 72, 78% 74, 22% 0, 73CONJU N/A N/A N/A N/A N/A N/A 79, 78% 72, 38% 0, 76 76, 99% 60, 85% 0, 68COORD 83, 95% 53,70% 0, 66 83, 88% 54,23% 0, 66 79, 15% 64,64% 0, 71 73, 82% 58,68% 0, 65DATIV 60, 69% 71, 57% 0, 66 61, 57% 71, 77% 0, 66 60, 62% 72, 83% 0, 66 61, 36% 73, 81% 0, 67DERIV 100, 00% 100, 00% 1, 00 100, 00% 100, 00% 1, 00 100, 00% 100, 00% 1, 00 100, 00% 100, 00% 1, 00DETER 91, 18% 93, 70% 0, 92 91, 08% 93, 74% 0, 92 91, 14% 94, 28% 0, 93 91, 15% 93, 97% 0, 93INSTR 44, 64% 38, 38% 0, 41 46, 72% 39, 48% 0, 43 46, 05% 41, 08% 0, 43 45, 25% 41, 49% 0, 43INTEN 87, 99% 81, 95% 0, 85 87, 30% 82, 71% 0, 85 87, 46% 82, 47% 0, 85 87, 83% 82, 26% 0, 85LOCAT 73, 40% 79, 25% 0, 76 73, 92% 79, 35% 0, 77 72, 33% 78, 91% 0, 75 72, 42% 79, 73% 0, 76MODIF 86, 04% 81, 58% 0, 84 85, 80% 81, 47% 0, 84 85, 80% 81, 84% 0, 84 85, 83% 81, 06% 0, 83MWE 71, 72% 58, 72% 0, 65 72, 46% 59, 09% 0, 65 74, 11% 58, 87% 0, 66 72, 55% 60, 18% 0, 66NEGAT 92, 56% 70, 00% 0, 80 92, 68% 66, 28% 0, 77 92, 91% 73, 29% 0, 82 92, 00% 71, 43% 0, 80OBJEC 77, 90% 71, 36% 0, 74 77, 61% 71, 54% 0, 74 78, 42% 72, 12% 0, 75 78, 67% 72, 08% 0, 75POSSE 87, 44% 80, 80% 0, 84 87, 03% 80, 68% 0, 84 87, 69% 83, 37% 0, 85 87, 25% 82, 89% 0, 85QUEST 86, 10% 77, 16% 0, 81 86, 15% 77, 78% 0, 82 86, 15% 78, 05% 0, 82 86, 15% 78, 05% 0, 82RELAT 70, 00% 49, 41% 0, 58 71, 67% 49, 43% 0, 59 72, 13% 50, 57% 0, 59 69, 35% 49, 43% 0, 58ROOT 68, 83% 99, 77% 0, 81 68, 84% 99, 49% 0, 81 70, 41% 99, 79% 0, 83 66, 28% 99, 81% 0, 80S.MOD 54, 25% 50, 25% 0, 52 51, 31% 49, 28% 0, 50 53, 55% 50, 09% 0, 52 53, 88% 49, 91% 0, 52SENTE 93, 25% 89, 63% 0, 91 92, 74% 89, 02% 0, 91 93, 50% 88, 80% 0, 91 93, 36% 88, 90% 0, 91SUBJE 69, 54% 68, 94% 0, 69 69, 61% 68, 14% 0, 69 69, 89% 69, 70% 0, 70 69, 75% 69, 60% 0, 70VOCAT 69, 61% 29, 46% 0, 41 67, 86% 24, 78% 0, 36 61, 05% 25, 66% 0, 36 69, 62% 24, 34% 0, 36Table 2: Specific accuracies per dependency relation for the coordination-related models.the web, sparse data will no longer be a significantproblem, and lexical data will gain further value.A comparison of the alternative CS models withthe baseline suggests that, while the manual cor-rection itself did not cause a noticeable change,the automatic conversion procedures that it madepossible resulted in significant improvements.
TheSwedish Style and Stanford Style models faredslightly better in the accuracy of some dependencytypes commonly joined in CSs such as SUBJECT,OBJECT, and DATIVE, INSTRUMENTAL andABLATIVE.ADJUNCTs, but not always enough towarrant statistical significance.
Apart from those,the largest improvement is in the COORDINATIONrelation itself, which had a slight drop in precisionfor both final models (likely due to the increased av-erage dependency distances) but at the great benefitof the recall increasing from 53.70% to 58.68% forthe Stanford Style and 64.64% for the Swedish Style.5 ConclusionIn this paper, we proposed novel annotation schemesfor Turkish morphosyntactic sub-word units and co-ordination structures that are superior to the Turk-ish Treebank representations in terms of ease of use,parsing performance and/or compatibility with sen-ASU ASLBaseline 74.5%?
0.2 65.0%?
0.2LexedIG 74.6%?
0.1 65.1%?
0.2Baseline 74.5%?
0.2 65.0%?
0.2Corrected 74.5%?
0.1 65.0%?
0.2Swedish Style 74.5%?
0.2 65.6%?
0.2Stanford Style 73.2%?
0.2 64.1%?
0.2Table 3: General parsing accuracies for all models, in-cluding standard error.tences that are not well-formed.
Our findings sub-stantiate our thesis that annotation schemes haveboth room for improvement and a high impact po-tential on parsing performance.
In the light of ourresults, we intend to sustain our research and drawbetter annotation schemes for other syntactic struc-tures such as copulae and modifier sub-types to servenot only Turkish, but also other languages with richmorphology.AcknowledgmentsThe authors would like to acknowledge that thiswork is part of a research project supported by ICTCOST Action IC1207 and TU?BI?TAK 1001 (GrantNumber 112E276).133ReferencesCristina Bosco, Simonetta Montemagni, AlessandroMazzei, Vincenzo Lombardo, Felice dell?Orletta,Alessandro Lenci, Leonardo Lesmo, Giuseppe Attardi,Maria Simi, Alberto Lavelli, et al2010.
Comparingthe influence of different treebank annotations on de-pendency parsing.
In LREC.Adriane Boyd and Detmar Meurers.
2008.
Revisiting theimpact of different annotation schemes on pcfg pars-ing: A grammatical dependency evaluation.
In Pro-ceedings of the Workshop on Parsing German, pages24?32.
Association for Computational Linguistics.Sabine Buchholz and Erwin Marsi.
2006.
Conll-x sharedtask on multilingual dependency parsing.
In Proceed-ings of the Tenth Conference on Computational Nat-ural Language Learning, pages 149?164.
Associationfor Computational Linguistics.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIBSVM: ALibrary for Support Vector Machines.
Software avail-able at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Marie-Catherine De Marneffe and Christopher D Man-ning.
2008.
The stanford typed dependencies repre-sentation.
In Coling 2008: Proceedings of the work-shop on Cross-Framework and Cross-Domain ParserEvaluation, pages 1?8.
Association for ComputationalLinguistics.Gu?ls?en Eryig?it, Tugay Ilbay, and Ozan Arkan Can.
2011.Multiword expressions in statistical dependency pars-ing.
In Proceedings of the Second Workshop on Sta-tistical Parsing of Morphologically Rich Languages(IWPT), pages 45?55, Dublin, Ireland, October.
As-sociation for Computational Linguistics.Gu?ls?en Eryig?it, Joakim Nivre, and Kemal Oflazer.
2008.Dependency parsing of Turkish.
Computational Lin-guistics, 34(3):357?389.Dilek Hakkani-Tu?r, Kemal Oflazer, and Go?khan Tu?r.2002.
Statistical morphological disambiguation foragglutinative languages.
Journal of Computers andHumanities, 36(4):381?410.Ryan McDonald and Joakim Nivre.
2011.
Analyzingand integrating dependency parsers.
ComputationalLinguistics, 37(1):197?230.Joakim Nivre, Johan Hall, Jens Nilsson, Gu?ls?en Eryig?it,and Stetoslav Marinov.
2006a.
Labeled pseudo-projective dependency parsing with support vectormachines.
In Proceedings of the 10th Conferenceon Computational Natural Language Learning, pages221?225, New York, NY.Joakim Nivre, Jens Nilsson, and Johan Hall.
2006b.
Tal-banken05: A swedish treebank with phrase structureand dependency annotation.
In Proceedings of the fifthInternational Conference on Language Resources andEvaluation (LREC), pages 1392?1395.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,Gu?ls?en Eryig?it, Sandra Ku?bler, Stetoslav Mari-nov, and Erwin Marsi.
2007.
Maltparser: Alanguage-independent system for data-driven depen-dency parsing.
Natural Language Engineering Jour-nal, 13(2):99?135.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of the 8th In-ternational Workshop on Parsing Technologies, pages149?160, Nancy.Kemal Oflazer, Bilge Say, Dilek Z. Hakkani-Tu?r, andGo?khan Tu?r.
2003.
Building a Turkish treebank.
In A.Abeille?, editor, Treebanks: Building and Using ParsedCorpora, pages 261?277.
Kluwer, London.Kemal Oflazer.
1994.
Two-level description of Turk-ish morphology.
Literary and Linguistic Computing,9(2):137?148.Kemal Oflazer.
2003.
Dependency parsing with an ex-tended finite-state approach.
Computational Linguis-tics, 29(4):515?544.Martin Popel, David Marec?ek, Jan S?te?pa?nek, Daniel Ze-man, and Zde?ne?k Z?abokrtsky?.
2013.
Coordinationstructures in dependency treebanks.
In Proceedingsof the 51st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 517?527, Sofia, Bulgaria, August.
Associationfor Computational Linguistics.Reut Tsarfaty and Yoav Goldberg.
2008.
Word-basedor morpheme-based?
annotation strategies for mod-ern hebrew clitics.
In Nicoletta Calzolari (Con-ference Chair), Khalid Choukri, Bente Maegaard,Joseph Mariani, Jan Odijk, Stelios Piperidis, andDaniel Tapias, editors, Proceedings of the Sixth In-ternational Conference on Language Resources andEvaluation (LREC?08), Marrakech, Morocco, may.European Language Resources Association (ELRA).http://www.lrec-conf.org/proceedings/lrec2008/.134
