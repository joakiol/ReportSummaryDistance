Exploring English Lexicon Knowledge for Chinese Sentiment AnalysisYulan He Harith AlaniKnowledge Media InstituteThe Open UniversityMilton Keynes MK6 6AA, UK{y.he, h.alani}@open.ac.ukDeyu ZhouSchool of Computer Science and EngineeringSoutheast UniversityNanjing, Chinad.zhou@seu.edu.cnAbstractThis paper presents a weakly-supervisedmethod for Chinese sentiment analysisby incorporating lexical prior knowledgeobtained from English sentiment lexi-cons through machine translation.
Amechanism is introduced to incorpo-rate the prior information about polarity-bearing words obtained from existingsentiment lexicons into latent Dirichletallocation (LDA) where sentiment labelsare considered as topics.
Experimentson Chinese product reviews on mobilephones, digital cameras, MP3 players,and monitors demonstrate the feasibil-ity and effectiveness of the proposed ap-proach and show that the weakly su-pervised LDA model performs as wellas supervised classifiers such as NaiveBayes and Support vector Machines withan average of 83% accuracy achievedover a total of 5484 review documents.Moreover, the LDA model is able toextract highly domain-salient polaritywords from text.1 IntroductionSentiment analysis aims to understand subjec-tive information such as opinions, attitudes, andfeelings expressed in text.
It has become a hottopic in recent years because of the explosion inavailability of people?s attitudes and opinions ex-pressed in social media including blogs, discus-sion forums, tweets, etc.
Research in sentimentanalysis has mainly focused on the English lan-guage.
There have been few studies in sentimentanalysis in other languages due to the lack of re-sources, such as subjectivity lexicons consistingof a list of words marked with their respectivepolarity (positive, negative or neutral) and manu-ally labeled subjectivity corpora with documentslabeled with their polarity.Pilot studies on cross-lingual sentiment anal-ysis utilize machine translation to perform senti-ment analysis on the English translation of for-eign language text (Banea et al, 2008; Bautinet al, 2008; Wan, 2009).
The major problemis that they cannot be generalized well whenthere is a domain mismatch between the sourceand target languages.
There have also been in-creasing interests in exploiting bootstrapping-style approaches for weakly-supervised senti-ment classification in languages other than En-glish (Zagibalov and Carroll, 2008b; Zagibalovand Carroll, 2008a; Qiu et al, 2009).
Otherapproaches use ensemble techniques by eithercombining lexicon-based and corpus-based algo-rithms (Tan et al, 2008) or combining sentimentclassification outputs from different experimen-tal settings (Wan, 2008).
Nevertheless, all theseapproaches are either complex or require carefultuning of domain and data specific parameters.This paper proposes a weakly-supervised ap-proach for Chinese sentiment classification byincorporating language-specific lexical knowl-edge obtained from available English senti-ment lexicons through machine translation.
Un-like other cross-lingual sentiment classificationmethods which often require labeled corpora fortraining and therefore hinder their applicabilityfor cross-domain sentiment analysis, the pro-posed approach does not require labeled docu-ments.
Moreover, as opposed to existing weakly-supervised sentiment classification approacheswhich are rather complex, slow, and require care-ful parameter tuning, the proposed approach issimple and computationally efficient; renderingmore suitable for online and real-time sentimentclassification from the Web.Our experimental results on the Chinese re-views of four different product types show thatthe LDA model performs as well as the super-vised classifiers such as Naive Bayes and Sup-port Vector Machines trained from labeled cor-pora.
Although this paper primarily studies sen-timent analysis in Chinese, the proposed ap-proach is applicable to any other language solong as a machine translation engine is availablebetween the selected language and English.The remainder of the paper is organized asfollows.
Related work on cross-lingual senti-ment classification and weakly-supervised sen-timent classification in languages other than En-glish are discussed in Section 2.
The proposedmechanism of incorporating prior word polarityknowledge into the LDA model is introduced inSection 3.
The experimental setup and results ofsentiment classification on the Chinese reviewsof four different products are presented in Sec-tion 4 and 5 respectively.
Finally, Section 6 con-cludes the paper.2 Related WorkPilot studies on cross-lingual sentiment analysisrely on English corpora for subjectivity classifi-cation in other languages.
For example, Mihal-cea et al (2007) make use of a bilingual lexiconand a manually translated parallel text to gener-ate the resources to build subjectivity classifiersbased on Support Vector Machines (SVMs) andNaive Bayes (NB) in a new language; Banea etal.
(2008) use machine translation to produce acorpus in a new language and train SVMs andNB for subjectivity classification in the new lan-guage.
Bautin et al (2008) also utilize machinetranslation to perform sentiment analysis on theEnglish translation of a foreign language text.More recently, Wan (2009) proposed a co-training approach to tackle the problem of cross-lingual sentiment classification by leveraging anavailable English corpus for Chinese sentimentclassification.
Similar to the approach proposedin (Banea et al, 2008), Wan?s method also usesmachine translation to produced a labeled Chi-nese review corpus from the available labeledEnglish review data.
However, in order to allevi-ate the language gap problem that the underlyingdistributions between the source and target lan-guage are different, Wan builds two SVM classi-fiers, one based on English features and the otherbased on Chinese features, and uses a bootstrap-ping method based on co-training to iterativelyimprove classifiers until convergence.The major problem of the aforementionedcross-lingual sentiment analysis algorithms isthat they all utilize supervised learning to trainsentiment classifiers from annotated English cor-pora (or the translated target language corporagenerated by machine translation).
As such, theycannot be generalized well when there is a do-main mismatch between the source and targetlanguage.
For example, For example, the word?compact?
might express positive polarity whenused to describe a digital camera, but it couldhave negative orientation if it is used to describea hotel room.
Thus, classifiers trained on onedomain often fail to produce satisfactory resultswhen shifting to another domain.Recent efforts have also been made forweakly-supervised sentiment classification inChinese.
Zagibalov and Carroll (2008b) startswith a one-word sentiment seed vocabulary anduse iterative retraining to gradually enlarge theseed vocabulary by adding more sentiment-bearing lexical items based on their relative fre-quency in both the positive and negative partsof the current training data.
Sentiment directionof a document is then determined by the sumof sentiment scores of all the sentiment-bearinglexical items found in the document.
The prob-lem with this approach is that there is no princi-pal way to set the optimal number of iterations.They then suggested an iteration control methodin (Zagibalov and Carroll, 2008a) where itera-tive training stops when there is no change to theclassification of any document over the previoustwo iterations.
However, this does not necessar-ily correlate to the best classification accuracy.Similar to (Zagibalov and Carroll, 2008b),Qiu et al (2009) also uses a lexicon-based iter-ative process as the first phase to iteratively en-large an initial sentiment dictionary.
But insteadof using a one-word seed dictionary as in (Za-gibalov and Carroll, 2008b), they started with amuch larger HowNet Chinese sentiment dictio-nary1 as the initial lexicon.
Documents classifiedby the first phase are taken as the training set totrain the SVMs which are subsequently used torevise the results produced by the first phase.Other researchers investigated ensemble tech-niques for weakly-supervised sentiment classifi-cation.
Tan et al (2008) proposed a combinationof lexicon-based and corpus-based approachesthat first labels some examples from a give do-main using a sentiment lexicon and then trainsa supervised classifier based on the labeled onesfrom the first stage.
Wan (2008) combined sen-timent scores calculated from Chinese productreviews using the Chinese HowNet sentimentdictionary and from the English translation ofChinese reviews using the English MPQA sub-jectivity lexicon2.
Various weighting strategieswere explored to combine sentiment classifica-tion outputs from different experimental settingsin order to improve classification accuracy.Nevertheless, all these weakly-supervisedsentiment classification approaches are rathercomplex and require either iterative training orcareful tuning of domain and data specific pa-rameters, and hence unsuitable for online andreal-time sentiment analysis in practical applica-tions.3 Incorporating Prior Word PolarityKnowledge into LDAUnlike existing approaches, we view sentimentclassification as a generative problem that whenan author writes a review document, he/she firstdecides on the overall sentiment or polarity (pos-itive, negative, or neutral) of a document, thenfor each sentiment, decides on the words to beused.
We use LDA to model a mixture of onlythree topics or sentiment labels, i.e.
positive,negative and neutral.Assuming that we have a total number of Ssentiment labels; a corpus with a collection of D1http://www.keenage.com/download/sentiment.rar2http://www.cs.pitt.edu/mpqa/documents is denoted by C = {d1, d2, ..., dD};each document in the corpus is a sequence of Ndwords denoted by d = (w1, w2, ..., wNd), andeach word in the document is an item from a vo-cabulary index with V distinct terms denoted by{1, 2, ..., V }.
The generative process is as fol-lows:?
Choose distributions ?
?
Dir(?).?
For each document d ?
[1, D], choose dis-tributions pid ?
Dir(?).?
For each of the Nd word posi-tion wt, choose a sentiment labellt ?
Multinomial(pid), and then choose aword wt ?Multinomial(?lt).The joint probability of words and sentimentlabel assignment in LDA can be factored intotwo terms:P (w, l) = P (w|l)P (l|d).
(1)Letting the superscript ?t denote a quantity thatexcludes data from the tth position, the condi-tional posterior for lt by marginalizing out therandom variables ?
and pi isP (lt = k|w, l?t, ?,?)
?N?twt,k + ?N?tk + V ?
?N?tk,d + ?kN?td +?k ?k, (2)where Nwt,k is the number of times word wt hasassociated with sentiment label k; Nk is the thenumber of times words in the corpus assigned tosentiment label k; Nk,d is the number of timessentiment label k has been assigned to someword tokens in document d; Nd is the total num-ber of words in the document collection.Each words in documents can either bear pos-itive polarity (lt = 1), or negative polarity (lt =2), or is neutral (lt = 0).
We now show howto incorporate polarized words in sentiment lex-icons as prior information in the Gibbs samplingprocess.
LetQt,k =N?twt,k + ?N?tk + V ?
?N?tk,d + ?kN?td +?k ?k(3)We can then modify the Gibbs sampling equa-tion as follows:P (lt = k|w, l?t, ?,?)
?
{1I(k = S(wt))?Qt,k if S(wt) is definedQt,k otherwise(4)where the function S(wt) returns the prior senti-ment label of wt in a sentiment lexicon and it isdefined if word wt is found in the sentiment lex-icon.
1I(k = S(wt)) is an indicator function thattakes on value 1 if k = S(wt) and 0 otherwise.Equation 4 in fact applies a hard constraintthat when a word is found in a sentiment lexi-con, its sampled sentiment label is restricted tobe the same as its prior sentiment label definedin the lexicon.
This constraint can be relaxed byintroducing a parameter to control the strength ofthe constraint such that when wordwt is found inthe sentiment lexicon, Equation 4 becomesP (lt = k|w, l?t, ?,?)
?(1?
?
)?Qt,k + ??
1I(k = S(wt))?Qt,k(5)where 0 ?
?
?
1.
When ?
= 1, the hard con-straint will be applied; when ?
= 0, Equation 5is reduced to the original unconstrained Gibbssampling as defined in Equation 2.While sentiment prior information is incor-porated by modifying conditional probabilitiesused in Gibbs sampling here, it is also possible toexplore other mechanisms to define expectationor posterior constraints, for example, using thegeneralized expectation criteria (McCallum etal., 2007) to express preferences on expectationsof sentiment labels of those lexicon words.
Weleave the exploitation of other mechanisms of in-corporating prior knowledge into model trainingas future work.The document sentiment is classified based onP (l|d), the probability of sentiment label givendocument, which can be directly obtained fromthe document-sentiment distribution.
We de-fine that a document d is classified as positiveif P (lpos|d) > P (lneg|d), and vice versa.Table 2: Data statistics of the four Chinese prod-uct reviews corpora.No.
of Reviews VocabCorpus positive Negative SizeMobile 1159 1158 8945DigiCam 853 852 5716MP3 390 389 4324Monitor 341 342 47124 Experimental SetupWe conducted experiments on the four corpora3which were derived from product reviews har-vested from the website IT1684 with each cor-responding to different types of product reviewsincluding mobile phones, digital cameras, MP3players, and monitors.
All the reviews weretagged by their authors as either positive or neg-ative overall.
The statistics of the four corporaare shown in Table 2.We explored three widely used English sen-timent lexicons in our experiments, namely theMPQA subjectivity lexicon, the appraisal lexi-con5, and the SentiWordNet6 (Esuli and Sebas-tiani, 2006).
For all these lexicons, we only ex-tracted words bearing positive or negative polar-ities and discarded words bearing neutral polar-ity.
For SentiWordNet, as it consists of wordsmarked with positive and negative orientationscores ranging from 0 to 1, we extracted a subsetof 8,780 opinionated words, by selecting thosewhose orientation strength is above a thresholdof 0.6.We used Google translator toolkit7 to translatethese three English lexicons into Chinese.
Aftertranslation, duplicate entries, words that failed totranslate, and words with contradictory polaritieswere removed.
For comparison, we also tested aChinese sentiment lexicon, NTU Sentiment Dic-tionary (NTUSD)8 (Ku and Chen, 2007) which3http://www.informatics.sussex.ac.uk/users/tz21/dataZH.tar.gz4http://product.it168.com5http://lingcog.iit.edu/arc/appraisal_lexicon_2007b.tar.gz6http://sentiwordnet.isti.cnr.it/7http://translate.google.com8http://nlg18.csie.ntu.edu.tw:Table 1: Matched polarity words statistics (positive/negative).LexiconChinese EnglishMobile DigiCam MP3 Monitors Mobile DigiCam MP3 Monitors(a)MPQA 261/253 183/174 162/135 169/147 293/331 220/241 201/153 210/174(b)Appraisal 279/165 206/127 180/104 198/105 392/271 330/206 304/153 324/157(c)SentiWN 304/365 222/276 202/213 222/236 394/497 306/397 276/310 313/331(d)NTUSD 338/319 263/242 239/167 277/241 ?
(a)+(c) 425/465 307/337 274/268 296/289 516/607 400/468 356/345 396/381(a)+(b)+(c) 495/481 364/353 312/280 344/302 624/634 496/482 447/356 494/389(a)+(c)+(d) 586/608 429/452 382/336 421/410 ?was automatically generated by enlarging an ini-tial manually created seed vocabulary by con-sulting two thesauri, tong2yi4ci2ci2lin2 and theAcademia Sinica Bilingual Ontological Word-Net 3.Chinese word segmentation was performed onthe four corpora using the conditional randomfields based Chinese Word Segmenter9.
The to-tal numbers of matched polarity words in eachcorpus using different lexicon are shown in Ta-ble 1 with the left half showing the statisticsagainst the Chinese lexicons (the original En-glish lexicons have been translated into Chinese)and the right half listing the statistics against theEnglish lexicons.
We did not translate the Chi-nese lexicon NTUSD into English since we fo-cused on Chinese sentiment classification here.It can be easily seen from the table that in gen-eral the matched positive words outnumbered thematched negative words using any single lexi-con except SentiWordNet.
But the combinationof the lexicons results in more matched polaritywords and thus gives more balanced number ofpositive and negative words.
We also observedthe increasing number of the matched polaritywords on the translated English corpora com-pared to their original Chinese corpora.
How-ever, as will be discussed in Section 5.2 that theincreasing number of the matched polarity wordsdoes not necessarily lead to the improvement ofthe sentiment classification accuracy.We modified GibbsLDA++ package10 for themodel implementation and only used hard con-8080/opinion/pub1.html9http://nlp.stanford.edu/software/stanford-chinese-segmenter-2008-05-21.tar.gz10http://gibbslda.sourceforge.net/straints as defined in Equation 4 in our experi-ments.
The word prior polarity information wasalso utilized during the initialization stage thatif a word can be found in a sentiment lexicon,the word token is assigned with its correspond-ing sentiment label.
Otherwise, a sentiment labelis randomly sampled for the word.
SymmetricDirichlet prior ?
was used for sentiment-worddistribution and was set to 0.01, while asym-metric Dirichlet prior ?
was used for document-sentiment distribution and was set to 0.01 forpositive and neutral sentiment labels, and 0.05for negative sentiment label.5 Experimental ResultsThis section presents the experimental resultsobtained under two different settings: LDAmodel with translated English lexicons tested onthe original Chinese product review corpora; andLDA model with original English lexicons testedon the translated product review corpora.5.1 Results with Different SentimentLexiconsTable 3 gives the classification accuracy resultsusing the LDA model with prior sentiment la-bel information provided by different sentimentlexicons.
Since we did not use any labeled in-formation, the accuracies were averaged over 5runs and on the whole corpora.
For comparisonpurposes, we have also implemented a baselinemodel which simply assigns a score +1 and -1to any matched positive and negative word re-spectively based on a sentiment lexicon.
A re-view document is then classified as either posi-tive or negative according to the aggregated sen-timent scores.
The baseline results were shownin brackets in Table 3 .Table 3: Sentiment classification accuracy (%) by LDA, numbers in brackets are baseline results.Lexicon Mobile DigiCam MP3 Monitors Average(a)MPQA 82.00 (63.53) 80.93 (67.59) 78.31 (68.42) 81.41 (64.86) 80.66 (66.10)(b)Appraisal 71.95 (56.28) 80.46 (60.54) 77.28 (61.36) 80.67 (57.98) 77.59 (59.04)(c)SentiWN 81.10 (62.45) 78.52 (57.13) 79.08 (64.57) 75.55 (55.34) 78.56 (59.87)(d)NTUSD 82.61 (71.21) 78.70 (68.23) 78.69 (75.87) 84.63 (74.96) 81.16 (72.57)(a)+(c) 81.18 (65.95) 78.70 (65.18) 83.83 (67.52) 80.53 (62.08) 81.06 (65.18)(a)+(b)+(c) 81.48 (62.84) 80.22 (65.88) 80.23 (65.60) 78.62 (61.35) 80.14 (63.92)(a)+(c)+(d) 82.48 (69.96) 84.33 (69.58) 83.70 (71.12) 82.72 (65.59) 83.31 (69.06)Naive Bayes 86.52 82.27 82.64 86.21 84.41SVMs 84.49 82.04 79.43 83.87 82.46It can be observed from Table 3 that theLDA model performs significantly better thanthe baseline model.
The improvement ranges be-tween 9% and 19% and this roughly correspondsto how much the model learned from the data.We can thus speculate that LDA is indeed able tolearn the sentiment-word distributions from data.Translated English sentiment lexicons per-form comparably with the Chinese sentimentlexicon NTUSD.
As for the individual lexicon,using MPQA subjectivity lexicon gives the bestresult among all the English lexicons on all thecorpora except the MP3 corpus where MPQAperforms slightly worse than SentiWordNet.
Thecombination of MPQA and SentiWordNet per-forms significantly better than other lexicons onthe MP3 corpus, with almost 5% improvementcompared to the second best result.
We alsonotice that the combination of all the three En-glish lexicons does not lead to the improvementof classification accuracy which implies that thequality of a sentiment lexicon is indeed impor-tant to sentiment classification.
The above re-sults suggest that in the absence of any Chinesesentiment lexicon, MPQA subjectivity lexiconappears to be the best candidate to be used toprovide sentiment prior information to the LDAmodel for Chinese sentiment classification.We also conducted experiments by includ-ing the Chinese sentiment lexicon NTUSD andfound that the combination of MPQA, Senti-WordNet, and NTUSD gives the best overallclassification accuracy with 83.31% achieved.For comparison purposes, we list the 10-foldcross validation results obtained using the super-vised classifiers, Naive Bayes and SVMs, trainedon the labeled corpora as previously reported in(Zagibalov and Carroll, 2008a).
It can be ob-served that using only English lexicons (the com-bination of MPQA and SentiWordNet), we ob-tain better results than both NB and SVMs onthe MP3 corpus.
With an additional inclusionof NTUSD, LDA outperforms NB and SVMson both DigiCam and MP3.
Furthermore, LDAgives a better overall accuracy when comparedto SVMs.
Thus, we may conclude that the un-supervised LDA model performs as well as thesupervised classifiers such as NB and SVMs onthe Chinese product review corpora.5.2 Results with Translated CorporaWe ran a second set of experiments on the trans-lated Chinese product review corpora using theoriginal English sentiment lexicons.
Both thetranslated corpora and the sentiment lexiconshave gone through stopword removal and stem-ming in order to reduce the vocabulary size andthereby alleviate data sparseness problem.
It canbe observed from Figure 1 that in general senti-ment classification on the original Chinese cor-pora using the translated English sentiment lex-icons gives better results than classifying on thetranslated review corpora using the original En-glish lexicons on both the Mobile and Digicamcorpora.
However, reversed results are observedon the Monitor corpus that classifying on thetranslated review corpus using the English sen-timent lexicons outperforms classifying on the85Mobile8085y?(%)Mobile70758085AccuracMobile6570758085()MPQA(b)Ail()SiWN()()()(b)()Mobile6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MobileChineseCorporaEnglishCorpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MobileChinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MobileChinese?CorporaEnglish?Corpora85DigiCam8085y?(%)DigiCam70758085AccuracDigiCam6570758085(a)MPQA(b)Appraisal(c)SentiWN(a)+(c)(a)+(b)+(c)DigiCam6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)DigiCamChinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)DigiCamChinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)DigiCamChinese?CorporaEnglish?Corpora85MP38085y?(%)MP370758085AccuracMP36570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MP36570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MP3Chinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MP3Chinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MP3Chinese?CorporaEnglish?Corpora85Monitor8085y?
(%)Monitor70758085AccuracMonitor6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)Monitor6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MonitorChinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MonitorChinese?CorporaEnglish?Corpora6570758085(a)?MPQA(b)?Appraisal(c)?SentiWN(a)+(c)(a)+(b)+(c)MonitorChinese?CorporaEnglish?CorporaFigure 1: Comparison of the performance on the Chinese corpora and their translated corpora inEnglish.original Chinese review corpus using the trans-lated sentiment lexicons.
In particular, the com-bination of the MPQA subjectivity lexicon andSentiWordNet gives the best result of 84% onthe Monitor corpus.
As for the MP3 corpus,classifying on the original Chinese reviews or onthe translated reviews does not differ much ex-cept that a better result is obtained on the Chi-nese corpus when using the combination of theMPQA subjectivity lexicon and SentiWordNet.The above results can be partially explained bythe ambiguities and changes of meanings intro-duced in the translation.
The Mobile and Digi-Cam corpora are relatively larger than the MP3and Monitors corpora and we therefore expectmore ambiguities being introduced which mightresult in the change of document polarities.5.3 Extracted Polarity-Bearing WordsLDA is able to extract polarity-bearing words.Table 4 lists some of the polarity words identi-fied by the LDA model which are not found inthe original sentiment lexicons.
We can see thatLDA is indeed able to recognize domain-specificpositive or negative words, for example, ?Y(bluetooth) for mobile phones, ?
(compact)for digital cameras,?^ (metallic) for MP3,?s (flat screen) and?b (deformation) for mon-itors.The iterative approach proposed in (Zagibalovand Carroll, 2008a) can also automatically ac-quire polarity words from data.
However, it ap-pears that only positive words were identifiedby their approach.
Our proposed LDA modelcan extract both positive and negative words andmost of them are highly domain-salient as can beseen from Table 4.6 ConclusionsThis paper has proposed a mechanism to incor-porate prior information about polarity wordsfrom English sentiment lexicons into LDAmodel learning for weakly-supervised Chinesesentiment classification.
Experimental results ofsentiment classification on Chinese product re-views show that in the absence of a language-specific sentiment lexicon, the translated En-glish lexicons can still produce satisfactory re-sults with the sentiment classification accuracyof 81% achieved averaging over four differenttypes of product reviews.
With the incorpora-tion of the Chinese sentiment lexicon NTUSD,the classification accuracy is further improved to83%.
Compared to the existing approaches tocross-lingual sentiment classification which ei-ther rely on labeled corpora for classifier learn-ing or iterative training for performance gains,the proposed approach is simple and readily toTable 4: Extracted example polarity words by LDA.Corpus Positive NegativeMobile ?
(advantage), ' (large), }( (easy touse),?
(fast),(comfortable),?Y (blue-tooth),?
(new),? (easy)O (bad), ?
(poor), b (slow), ?
(no;not), ?
(difficult;hard), (less),?/ (but),?
(repair)DigiCam  ?
(advantage),  ?
(compact), :(strong;strength), & (telephoto), ? (dy-namic), h (comprehensive),  (profes-sional),K (get started)?
(regret),O (bad),?
(poor),b (slow),?
(dark),5 (expensive),?
(difficult;hard),5(consume much electricity), Q?
(plastic), ?
(repair)MP3 ?
(compact),?
(fast),: (strong;strength),?
(even), ( (textual), h (comprehensive),?^ (metallic),A (very)(no;not),?
(poor),O (bad),	?
(rather),9, (simply),!
(substandard),{: (crash),?
(no),F/ (but)Monitors ? (easy), ?
(new), ?s (flat screen), (comfortable), >?
(looks bright), )(sharp),?
(bright),??
(automatic)?b (deformation), Or (color cast bad), O(bad), ?
(poor), ?
(no;not), I (leakage oflight), ?O (black screen),   (refund;return),?
(dark),??
(jitter)be used for online and real-time sentiment clas-sification from the Web.One issue relating to the proposed approachis that it still depends on the quality of ma-chine translation and the performance of senti-ment classification is thus affected by the lan-guage gap between the source and target lan-guage.
A possible way to alleviate this problemis to construct a language-specific sentiment lex-icon automatically from data and use it as theprior information source to be incorporated intothe LDA model learning.ReferencesBanea, C., R. Mihalcea, J. Wiebe, and S. Hassan.2008.
Multilingual subjectivity analysis using ma-chine translation.
In Proceedings of the EMNLP,pages 127?135.Bautin, M., L. Vijayarenu, and S. Skiena.
2008.
In-ternational sentiment analysis for news and blogs.In Proceedings of the International Conference onWeblogs and Social Media (ICWSM).Esuli, A. and F. Sebastiani.
2006.
SentiWordNet:A publicly available lexical resource for opinionmining.
In Proceedings of LREC, volume 6.Ku, L.W.
and H.H.
Chen.
2007.
Mining opinionsfrom the Web: Beyond relevance retrieval.
Jour-nal of the American Society for Information Sci-ence and Technology, 58(12):1838?1850.McCallum, A., G. Mann, and G. Druck.
2007.
Gen-eralized expectation criteria.
Technical Report2007-60, University of Massachusetts Amherst.Mihalcea, R., C. Banea, and J. Wiebe.
2007.
Learn-ing multilingual subjective language via cross-lingual projections.
In Proceedings of the ACL,pages 976?983.Qiu, L., W. Zhang, C. Hu, and K. Zhao.
2009.
Selc: aself-supervised model for sentiment classification.In Proceeding of the CIKM, pages 929?936.Tan, S., Y. Wang, and X. Cheng.
2008.
Combininglearn-based and lexicon-based techniques for sen-timent detection without using labeled examples.In Proceedings of the SIGIR, pages 743?744.Tseng, H., P. Chang, G. Andrew, D. Jurafsky, andC.
Manning.
2005.
A conditional random fieldword segmenter.
In Fourth SIGHAN Workshop onChinese Language Processing, volume 37.Wan, X.
2008.
Using bilingual knowledge and en-semble techniques for unsupervised Chinese sen-timent analysis.
In Proceedings of the EMNLP,pages 553?561.Wan, X.
2009.
Co-training for cross-lingual senti-ment classification.
In Proceedings of the ACL,pages 235?243.Zagibalov, T. and J. Carroll.
2008a.
Automatic seedword selection for unsupervised sentiment classifi-cation of Chinese text.
In Proceedings of the COL-ING, pages 1073?1080.Zagibalov, T. and J. Carroll.
2008b.
Unsupervisedclassification of sentiment and objectivity in chi-nese text.
In Proceedings of the IJCNLP, pages304?311.
