Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 203?206,Prague, June 2007. c?2007 Association for Computational LinguisticsJU-SKNSB: Extended WordNet Based WSD on the English All-WordsTask at SemEval-1Sudip Kumar NaskarComputer Sc.
& Engg.
Dept.,Jadavpur University,Kolkata, Indiasudip.naskar@gmail.comSivaji BandyopadhyayComputer Sc.
& Engg.
Dept.,Jadavpur University,Kolkata, Indiasivaji_cse_ju@yahoo.comAbstractThis paper presents an Extended WordNetbased word sense disambiguation systemusing a major modification to the Lesk al-gorithm.
The algorithm tries to disambigu-ate nouns, verbs and adjectives.
The algo-rithm relies on the POS-sense tagged syn-set glosses provided by the ExtendedWordNet.
The basic unit of disambiguationof our algorithm is the entire sentence un-der consideration.
It takes a global ap-proach where all the words in the targetsentence are simultaneously disambigu-ated.
The context includes previous andnext sentence.
The system assigns the de-fault WordNet first sense to a word whenthe algorithm fails to predict the sense ofthe word.
The system produces a precisionand recall of .402 on the SemEval-2007English All-Words test data.1 IntroductionIn Senseval 1, most of the systems disambiguatingEnglish words, were outperformed by a Lesk vari-ant serving as baseline(Kilgariff & Rosenzweig,2000).
On the other hand, during Senseval 2 andSenseval 3, Lesk baselines were outperformed bymost of the systems in the lexical sample track(Edmonds, 2002).In this paper, we explore variants of the Lesk al-gorithm on the English All Words SemEval 2007test data (465 instances), as well as on the first 10Semcor 2.0 files (9642 instances).
The proposedWSD algorithm is POS-sense-tagged gloss (fromExtended WordNet) based and is a major modifi-cation of the original Lesk algorithm.2 Extended WordNetThe eXtended WordNet (Harabagiu et al, 1999)project aims to transform the WordNet glosses intoa format that allows the derivation of additionalsemantic and logic relations.
It intends to syntacti-cally parse the glosses, transform glosses into logi-cal forms and tag semantically the nouns, verbs,adjectives and adverbs of the glosses automati-cally.
The last release of the Extended WordNet isbased on WordNet 2.0 and has three stages: POStagging and parsing, logic form transformation,and semantic disambiguation.3 Related WorksBanerjee and Pedersen (2002) reports an adapta-tion of Lesk?s dictionary-based WSD algorithmwhich makes use of WordNet glosses and tests onEnglish lexical sample from SENSEVAL-2.
They de-fine overlap as the longest sequence of one or moreconsecutive content words that occurs in bothglosses.
Each overlap contributes a score equal tothe square of the number of words in the overlap.A version of Lesk algorithm in combinationwith WordNet has been reported for achievinggood results in (Ramakrishnan et al, 2004).Vasilescu et al (2004) carried on a series of ex-periments on the Lesk algorithm, adapted toWordNet, and on some variants.
They studied theeffect of varying the number of words in the con-texts, centered around the target word.But till now no work has been reported whichmakes use of Extended WordNet for Lesk-likegloss-oriented approach.2034 Proposed Sense Disambiguation Algo-rithmThe proposed sense disambiguation algorithm is amajor modification of the Lesk algorithm (Lesk,1986).
WordNet and Extended WordNet are themain resources.4.1 Modifications to the Lesk AlgorithmWe modify the Lesk algorithm (Lesk, 1986) inseveral ways to create our baseline algorithm.
TheLesk algorithm relies on glosses found in tradi-tional dictionaries which often do not have enoughwords for the algorithm to work well.
We choosethe lexical database WordNet, to take advantage ofthe highly inter?connected set of relations amongdifferent words that WordNet offers, and ExtendedWordNet to capitalize on its (POS and sense)tagged glosses.The Lesk algorithm takes a local approach forsense disambiguation.
The disambiguation of thevarious words in a sentence is a series of inde-pendent problems and has no effect on each other.We propose a global approach where all the words(we mean by word, an open-class lemma) in thecontext window are simultaneously disambiguatedin a bid to get the best combination of senses forall the words in the window instead of only thetarget word.
The process can be thought of as sensedisambiguation of the whole context, instead of aword.The Lesk algorithm disambiguates words in shortphrases.
But, the basic unit of disambiguation ofour algorithm is the entire sentence under consid-eration.
We later modify the context to include theprevious and next sentence.Another major change is that the dictionarydefinition or gloss of each of its senses is com-pared to the glosses of every other word in the con-text by the Lesk algorithm.
But in the presentwork, the words themselves are compared with theglosses of every other word in the context.4.2 Choice of Which Glosses to UseWhile Lesk?s algorithm restricts its comparisons tothe dictionary meanings of the words being disam-biguated, our choice of dictionary allows us to alsocompare the meanings (i.e., glosses) of the words,as well as the words that are related to themthrough various relationships defined in WordNet.For each POS we choose a relation if links of itskind form at least 5% of the total number of linksfor that part of speech, with two exceptions.
Weuse the attribute relation although there are notmany links of its kind.
But this relation links adjec-tives, which are not well developed in WordNet, tonouns which have a lot of data about them.
Thispotential to tap into the rich noun data prompted usto use this relation.
Another exception is the an-tonymy relationship.
Although there are sufficientantonymy links for adjectives and adverbs, wehave not utilized these relations.Noun Verb AdjectiveHypernymHyponymHolonymMeronymAttributeHyponymTroponymAlso seeAttributeAlso seeSimilar toPertainym ofTable 1.
WordNet relations chosen for the disam-biguation algorithm4.3 The AlgorithmThe gloss bag is constructed for every sense ofevery word in the sentence.
The gloss-bag is con-structed from the POS and sense tagged glosses ofsynsets, obtained from the Extended WordNet.
Forany synset, the words forming the synset and thegloss definition contribute to the gloss-bag.
Thenon-content words are left out.
Example sentencesdo not contribute to the gloss bag since they are not(POS and sense) tagged.
Each word along with itsPOS and sense-tag are stored in the gloss bag.
Forwords with different POS, different relations aretaken into account (according to Table 1) for build-ing the corresponding gloss-bag.This gloss-bag creation process can be per-formed offline or online.
It can be performed dy-namically on a as-when-needed basis.
Or, gloss-bags can be created for all WordNet entries onlyonce and stored in a data file in prior.
The issue istime versus space.Once, this gloss-bag creation process is over, thecomparison process starts.
Each word (say Wi) inthe context is compared with each word in thegloss-bag for every sense (say Sk) of every otherword (say Wj) in the context.
If a match is found,they are checked further for part-of-speech match.If the words match in part-of-speech as well, ascore is assigned to both the words: the word beingmatched (Wi) and the word whose gloss-bag con-tains the match (Wj).
This matching event indicates204mutual confidence towards each other, so bothwords are rewarded for this event.
Two two-dimensional (one for word index and the other forsense index) vectors are maintained: sense_vote forthe word in context, and sense_score for the wordin gloss-bag.
Say, for example, the context word(Wi # noun) matches with gloss word (Wn # noun #m) (i.e., Wi = Wn) in the gloss bag for kth sense ofWj.
Then, a score of 1/(gloss bag size of (Wjk)) isassigned to both sense_vote[i][m] andsense_score[j][k].
Scores are normalized beforeassigning because of huge discrepancy in gloss-bagsizes.
This process continues until each contextword is matched against all gloss-bag words foreach sense of every other context words.Once all the comparisons have been made, we addsense_vote value with the sense_score linearlyvalue for each sense of every word to arrive at thecombination score for this word-sense pair.The algorithm assigns a word the nth sense forwhich the corresponding sense_vote andsense_score produces the maximum sum, and itdoes not assign a word any sense when the corre-sponding sense_vote and sense_score values are 0,even if the word has only one sense.
In the event ofa tie, we choose the one that is more frequent, asspecified by WordNet.Assuming that there are N words in the windowof context (i.e.
the sentence), and that, on an aver-age there are S senses per word, and G number ofgloss words in each gloss bag per sense, N * Sgloss bags need to be constructed, giving rise to atotal of N * S * G gloss words.
Now these manygloss words are compared against each of the Ncontext words.
Thus, N2 * S * G pairs of wordcomparisons need to be performed.
Both, S and Gvary heavily.5 Variants of the AlgorithmThe algorithm discussed thus far is our baselinealgorithm.
We made some changes, as described inthe following two subsections, to investigatewhether the performance of the algorithm can beimproved.5.1 Increasing the Context SizeThe poor performance of the algorithm perhapssuggests that sentential context is not enough forthis algorithm to work.
So we went for a largercontext: a context window containing the currentsentence under consideration (target sentence), itspreceding sentence and the succeeding sentence.This increment in context size indeed performedbetter than the baseline algorithm.5.2 Assigning Different ScoresWhen constructing the gloss-bags for a word-sensepair, some words may appear in more than onegloss (by gloss we mean to say synonyms as wellas gloss).
So, we added another parameter withevery (word#pos#sense) in a gloss bag: noc - thenumber of occurrence of this (word#pos#sense)combination in this gloss-bag.And, in case of a match of context word (say Wi)with a gloss-bag word (of say kth sense of wordWj), we scored the words in four ways to see if thisphenomenon has any effect on the sense disam-biguation process.
Say, for example, the contextword (Wi # noun) matches with gloss word (Wn #noun # m # noc) in the gloss bag for kth sense of Wj(i.e., the particular word appears noc times in thesaid gloss-bag) and the gloss bag size is gbs.
Then,we reward Wi and Wj for this event in four waysgiven below.1.
Assign 1/gbs tosense_vote[i][m] and 1/gbsto sense_score[j][k].2.
Assign 1/gbs tosense_vote[i][m] and noc/gbsto sense_score[j][k].3.
Assign noc/gbs  tosense_vote[i][m] and 1/gbsto sense_score[j][k].4.
Assign noc/gbs tosense_vote[i][m] and noc/gbsto sense_score[j][k].The results of this four-way scoring proved thatthis indeed has influence on the disambiguationprocess.The WSD system is based on Extended Word-Net version 2.0-1.1 (the latest release), which is inturn based on WordNet version 2.0.
So, the systemreturns WordNet 2.0 sense indexes.
These Word-Net sense indexes are then mapped to WordNet 2.1sense indexes using sensemap 2.0 to 2.1.6 EvaluationsThe system has been evaluated on the SemEval-2007 English All-Words Tasks (465 test in-205stances), as well as on the first 10 Semcor 2.0files, which are manually disambiguated textcorpora using WordNet senses.We compute F-Score as 2*P*R / (P+R).
Ta-ble 2 shows the performance of the four variants ofthe system (with a context size of 3 sentences)on the first 10 Semcor 2.0 files.
From table 2, itis clearly evident that model C produces the bestresult (precision - .621, recall - .533) among the 4scoring schemes.
POS-wise evaluation results formodel C on Semcor 2.0 data is given in table 3.ModelA B C DPrecision .618 .602 .621 .604Recall .531 .517 .533 .519F-Score .571 .556 .574 .558Table 2.
Evaluation of the four models on Sem-cor DataNoun Verb Adj OverallPrecision .6977 .4272 .6694 .6211Recall .6179 .3947 .4602 .5335F-Score .6554 .4103 .5454 .574Table 3.
POS-wise Evaluation for model C onSemcor DataModel C produced a precision of .393 and a re-call of .359 on the SemEval-2007 English All-Words test data (465 test instances).
Table 4shows POS-wise evaluation results for this testdata.Noun Verb OverallPrecision .507 .331 .393Recall .472 .299 .359F-Score .489 .314 .375Table 3.
POS-wise Evaluation on SemEval-2007English All-Words test dataWhen default WordNet first senses were as-signed to the (40) words for which the algorithmfailed to predict senses, both the precision and re-call values went up to .402 (this result has beensubmitted in SemEval-2007).
The WSD systemstood 10th in the SemEval-2007 English All-Words task.7 DiscussionsWe believe that this somewhat poor showing canbe partially attributed to the brevity of definitionsin WordNet in particular and dictionaries in gen-eral.
The Lesk algorithm is crucially dependent onthe lengths of glosses.
However lexicographersaim to create short and precise definitions which,though a desirable quality in dictionaries, is disad-vantageous to this algorithm.
Nouns have the long-est average glosses in WordNet, and indeed thehighest recall obtained is on nouns.
The character-istics of the gloss bags need to be further investi-gated.
Again many of the sense tagged gloss wordsin Extended WordNet, which are determinant fac-tors in this algorithm, are of  ?silver?
or ?normal?quality.
And finally, since the system returnsWordNet 2.0 sense indexes which are mapped toWordNet 2.1 indexes with certain amount of con-fidence using sensemap 2.0 to 2.1, there may besome loss of information during this mappingprocess.ReferencesA.
Kilgarriff, and J. Rosenzweig.
2000.
Framework andResults for English SENSEVAL.
Computers and theHumanities, 34, 15-48.Florentina Vasilescu, Philippe Langlais, and Guy La-palme.
2004.
Evaluating Variants of the Lesk Ap-proach for Disambiguating Words.
LREC, Portugal.G.
Ramakrishnan, B. Prithviraj, and P. Bhattacharyya.2004.
A Gloss Centered Algorithm for Word SenseDisambiguation.
Proceedings of the ACL SEN-SEVAL 2004, Barcelona, Spain, 217-221.M.
Lesk.
1986.
Automatic sense disambiguation usingmachine readable dictionaries: How to tell a pinecone from a ice cream cone.
Proceedings of SIGDOC?86.P.
Edmonds.
2002.
SENSEVAL : The Evaluation ofWord Sense Disambiguation Systems, ELRA News-letter, Vol.
7, No.
3.S.
Banerjee.
2002.
Adapting the Lesk Algorithm forWord Sense Disambiguation to WordNet.
MS Thesis,University of Minnesota.S.
Banerjee, and T. Pedersen.
2002.
An Adapted LeskAlgorithm for Word Sense Disambiguation UsingWordNet.
CICLing, Mexico.S.
Harabagiu, G. Miller, and D. Moldovan.
1999.WordNet2 - a morphologically and semantically en-hanced resource.
Proceedings of SIGLEX-99, Univ ofMariland.
1-8.206
