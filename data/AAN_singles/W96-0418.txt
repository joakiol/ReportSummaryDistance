Matchmaking: dialogue modelling and speech generation meet*Brigitte GroteFAW UlmGermanyE-mail: grote@faw.uni-ulm.deEli HagenGMD/IPSI, Darmstadt andTechnical University of DarmstadtGermanyE-mail: hagen@darmstadt.gmd.deElke TeichUniversity of tile SaarlandDepartment of Applied Linguistics, Translation and InterpretationGermanyE-mail: teich@darmstadt.gmd.deKeywords :  Speech generation, intonationAbstractThis article is concerned with determiningthe constraints on the selection of appropriateintonation in speech generation in human-machine information seeking dialogues.
Thetwo pillars of our system--a state-of-the-art computational dialogue model and astate-of-the-art NL generator--are presented.Based on this, we determine the kinds oflinguistic and pragmatic knowledge neededto sufficiently constrain choice in the intona-tional resources of the system.
We take intoconsideration factors uch as dialogue history,speaker's attitudes, heater's expectations,and semantic speech functions.1 Introduct ionTask independent computational dialogue modelling(see e.g., \[5, l0 t 35\]) seldom makes contact with naturallanguage generation (exceptions being, e.g., \[7, 9, 22\]),and much less so with speech generation/synthesis.Conversely, speech synthesis, being predominantly con-cerned with rendering text to speech, rarely considersactual full scale generation.In this article we introduce an approach under de-velopment in a joint collaborative project betweenthe Technical Universities of Darmstadt and Budapest('SPEAK!')
that combines the dialogue modellingparadigm with NL generation and speech synthesisin an information retrieval system.
The novelty ofthe approach pursued lies in the move away fromtext-to-speech and concept-to-speech generation towardscommunicative-context-to-speech g neration (see Sec-tion 2) and the integration of dialogue representation,NL generation, and speech synthesis.
Our principalconcern is selection of appropriate intonation.
Morespecifically, from our representation f communicative"Authors appear in alphabetical order.
This workwas partially funded by Copernicus, Project No.
10393('SPEAK!
').171context, we derive constraints on interpersonal mean-ing, which are then expressed through intonation con-tour (or tone contour or simply tone).We have taken two existing systems, the COR dialoguemodel (\[31\]) and the K'OMET-PENMAN multilingual textgenerator \[33\] to build the backbone of an integrateddialogue-based interface to an information system.
Thelinguistic generation resources of German have been en-hanced by a systemic functionally \[14, 15, 24\] motivatedgrammar of speech that includes knowledge about in-tonational patterns \[12, 34\].
Section 3 presents ourdialogue model and the intonational resources.In Section 4 we first apply an bottom-up approach; wewill determine the kinds of knowledge the generatorneeds to make intonational choices, and based on thiswe develop a stratified model with three strata: gram-mar, semantics, and extra-linguistic context.
Secondwe apply a top-down approach; we determine how thisknowledge can be obtained from tile dialogue modeland dialogue history, i.e., from the extra-linguistic con-text, and thereby verify the applicability of our over-all model.
Section 5 concludes the paper with a sum-mary and a number of questions that have been leftuntouched.2 State of the art in speech generat ionIn this section we give a survey of existing speech gen-eration systems for German, arguing that their syntax-based approach does not suffice to generate "natural"speech in dialogue systems.In information-seeking dialogues that use spoken lan-guage for interaction, intonation is often the onlymeans to distinguish between different dialogue acts,thus making the selection of the appropriate intonationcrucial to the success of the information-seeking pro-cess (see e.g., \[26\] for English).
To illustrate this point,imagine an information-seeking dialogue where the userwants to know a specific train connection.
At somepoint in the interaction, the system produces a sen-tence like Sie fahren um drei Uhr von Darmstadt nachHeidelberg ("You travel at three o'clock from Darm-stadt to Heidelbei'g.").
There are several interpreta-tions of this utterance, the most obvious being thatthe system presents ome kind of information to thereader.
However, the same sentence--employing a dif-ferent intonation--could be part of a clarification dia-logue, where the system wants to reassure that it gotthe user's request right.
In this case, the user wouldbe expected to react, i.e., either confirm or rebuke thisstatement.
Only by means of intonation can the userinterpret he system's expectation correctly and reactaccordingly.Even though current speech synthesizers can supportsophisticated variation of intonation, no existing text-to-speech or concept-to-speech system for German isavailable that provides the semantic or pragmatic guid-ance necessary for selecting intonations appropriately.The major shortcoming is that traditional text-to-speech systems (e.g., \[16, 18, 23\]) and concept-to-speech systems \[6\] alike use purely syntactic informa-tion in order to control prosodic features.
Moreover,with text-to-speech systems, where the syntactic struc-ture has to be reconstructed from the written text bymeans of a syntactic analysis, the resulting data is sel-dom complete nor unambiguous.
Concept-to-speechsystems avoid the latter problem by generating spokenoutput from a pre-linguistic onceptual structure.
Yet,most of the current implementations of the concept-to-speech approach use the conceptual representationonly to avoid syntactic ambiguities with the assignmentof intonational features till based on the written text(see \[6\]).A common feature of all these systems is that theyare often too expressive in that too many words arestressed, mainly due to the lack of discourse informa-tion, for instance on focus domain or the given/newdistinction.
A number of discourse-model based speechgeneration systems have been proposed that addressexactly this problem, for example NewSpeak \[17, 26\].However, the problem with these systems is that theystill start from a given text, and are hence restrictedto those kinds of discourse information that can be re-constructed from that text.
Moreover, since they as-sume a one-to-one mapping between syntactic struc-ture and intonational features, they cannot account forthose phenomena frequent o our domain, where thesame syntactic structure can be realized with differingintonations (see example above).Assuming that intonation is more than the mere reflec-tion of the surface linguistic form (see \[14, 30, 19, 24\]),and further, that intonation is selected to express par-ticular communicative goals and intentions, an effectivecontrol of intonation requires ynthesizing from mean-ings rather than word sequences as the discussed sys-tems do.This fact is acknowledged by \[1\], whose SYNPHONICSsystem ~ is based on the assumption that prosodic fea-tThe SYNPHONICS system (\[I\]) covers the incremen-172tures have a function independent of syntax.
\[1\] re-place the idea of syntax-dependent prosody--which isimplicit to all the approaches discussed so far--withthe notion of the linguistic function of prosodic fea-tures including intonation.
Thus, this approach allowsprosodic features to be controlled by various factorsother than syntax, e.g., by the information structuresuch as focus-background or topic-comment s ructure.However, the function of intonation is still restrictedto what is called grammatical function, more specif-ically the textual function of intonation, without con-sidering aspects like communicative goals and speaker'sattitude, i.e., the interpersonal function of intonation(\[14\]).
2 Yet, in the context of generating speech ininformation-seeking dialogues where intonational fea-tures are often the only means to signal a dialogue act,these aspects have to be taken into account.Furthermore, in a dialogue situation as given in our ap-proach, it is not sufficient o look at isolated sentences;instead one has to look at the utterance in its context,as part of a larger interaction.
Intonation is not onlyused to mark sentence-internal information structures,but additionally it can be employed in the managementof the communicative demands of interaction partners.Therefore, we also have to consider the function of in-tonation with respect o the whole conversational in-teraction, taking into account he discourse (dialogue)history (see also \[7\]).
Intonation as realization of in-teractional features thus draws on discourse and usermodel as the source of constraints.An approach to speech generation that starts fromcommunication context and maps this to intonationalfeatures is the only approach that provides the intona-tional control needed in dialogue systems to producespeech that human hearers would find acceptable.3 Ava i lab le  resourcesThe overall system architecture for SPEAK!
is shownin Figure 1.
The text generation system (KOMET-PENMAN) receives input from a dialogue module (colt,dialogue history) and perhaps several other informa-tion sources (e.g., confidence measure from a speechrecognition unit), which will be made more precise be-low (see Section 4).
Together the information fromthese input sources controls the traversal of the gram-mar (see Section 3.2).
The KOMET-PENMAN grammarcan generate two types of output: A plain text, whichcan be embedded into, for instance, a dialogue box ina graphical user interface and a text that is markedup with intonational features (see Section 3.2 for anexample), which is passed on to the MULTIVOX text-to-speech system \[23\] and presented acoustically to theuser.In this article we develop a model of how the dialoguemodule can control the traversal of those regions of thetal generation of utterances from pre-linguistic conceptualstructures to the formation of syntactic and phonologicalstructures, with an interface to a speech synthesis modulefor German.2See \[7\] for an exception.DialogueF igure  1: System architecture.grammar concerned with intonation.
As a basis fordiscussion, we introduce our dialogue model and therelevant parts of the grammar in detail.3.1 The  d ia logue mode lA dialogue model guides the interaction between a userand an information retrieval system, i.e., it calculatesa subset of possible dialogue acts that the user action(spoken or deictic) could correspond to, and on thesystem side it calculates those dialogue acts that wouldprovide appropriate responses to a given user action.
Inthe work presented here, we assume that a componentexists that can choose one of the dialogue acts fromthese subsets (see e.g., \[13, 28\].
)In the 'SPEAK!'
project we have chosen to employa modified version of the Conversational Roles model(COR) as our dialogue model (see \[31\]).
COR is a taskindependent model based on Searle's peech act theory\[29\].
It has been modified within the 'SPEAK!'
frame-work in order to include naturally occuring data thatthe original model failed to account for, but the overallspeech act framework remains the same.In the model, a dialogue is represented as a sequenceof dialogue moves (e.g., Request, Inform, Withdraw re-quest), which are further decomposed into sequences ofatomic acts, dialogue moves, and sub-dialogues.
Thisrecursive representation of a dialogue enables COR toaccount for mixed initiative dialogues, where both in-formation seeker and informa\[ion knower can employ,for instance, retraction, correction, and clarificationtactics.Below we present a simplified rewrite rule version of thedialogue model.
In this version we only present he re-quest, inform, and assert moves in detail, since the othermoves are cast in the same format as the request, andone only has to insert new move names (e.g., Promise---+ promise(K), (Dialogue(S)), etc.).
Moves in paren-theses are optional.
The parameters indicate whichparticipant can perform a given move, S=informationseeker, K=information knower.
Moves begin with up-per case and acts with lower case.
The first two rulesencode the course that the dialogue is expected to take,while the other dialogue rules encode exceptions.
(Fora more detailed account see \[31\]).Dialogue(S) --> (Request (S)) , (Promise(K)) ,Inform(K), (Evaluate (S)), (Dialogue (_))Dialogue(S) --> (Offer(K)), (Accept(S)),Inform(K) , (Evaluate(S)), (Dialogue(_))173Dialogue(S) --> 0fret(K), (Accept(S)),WithdrawOffer (K) , (Dialogue (_))Dialogue(S) --> 0fret(K), Accept(S),WithdrawAccept (S), (Dialogue (_))Dialogue(S) --> Request (S), (Promise(K)),WithdrawRequest (S), (Dialogue (_))Dialogue(S) --> Request (S) , Promise(K),WithdrawPromise (K), (Dialogue (_))Dialogue(S) --> 0fret(K), WithdrawOffer(K),(Dialogue (_))Dialogue(S) --> 0ffer(K), Reject0ffer(S),(Dialogue(_))Dialogue(S) --> Request(S), Withdrawftequest(S) ,(Dialogue (_))Dialogue(S) --> Request (S) , RejectRequest (K) ,(Dialogue (_))Dialogue(S) --> Withdraw(_)Request (S) --> request (S), (Dialogue(K))Request(S) --> request(S), (Assert(S))Request(S) --> Dialogue(K)Request (S) --> Assert (S) , (request (S))Request(S) --> Assert(S) , (Dialogue(S))Inform(K) --> inform(K), (Dialogue(S))Assert (_) --> assert (_) , (Dialogue (_))Based on the dialogue model, the system builds up atree-like dialogue history of the ongoing dialogue (seeSection 4).
Two central themes in our current workare to identify the relevant partial structures of suchtrees and to determine their semantics uch that, forinstance, the text generation system can search thedialogue history and interpret what it finds in orderto guide the choice of intonation for the system utter-ances.3.2 The  in tonat iona l  resources  of  theKOMET grammarIn this section, we describe the syste m networks thathave been introduced to the German grammar of theKOMET-PENMAN text generation component as to in-clude specifications of appropriate intonation selectionsin its output (\[12\]).
The KOMET grammar of Ger-man (\[32, 11\]) is a computational NIGEL-style systemic-functional grammar, based on the notion of choice.
Thesystemic-functional framework provides us with repre-sentational means for describing available choices andfor mapping (even though indirectly) communicativegoals to intonational features.According to systemic-functional linguistics (SFL) (see\[15, 21, 7\]), intonation is just one means amongothers--such as syntax and lexis--to realize choices inthe grammar.
3 This implies that choices underlyingthe realization of intonation may be organized in ex-actly the same way as other choices in the grammar(see \[14, 7\].
Hence, the intonational control requiredfor speech generation in a dialogue system has beenbuilt into the existing KOMET grammar.
The addeddiscriminations are constraints on the specification ofan appropriate intonation rather than constraints onthe structural form.T reatment  of  in tonat ion in SFL The three dis-tinct kinds of phonological categories, i.e., tone group,tonic syllable and tone, contribute to the intonationa\[2, 30, 4, 8\] consider intonation part of phonology.specification of a clause (see for instance \[4, 30, 24\]).They signal three different kinds of relation betweengrammar and intonation (and thus, indirectly, con-*ext), and hence realize different meanings?
A choicefrom the available alternatives has to be made for eachof the phonological categories in order to realize sen-tence intonation.
The three sets of choices accordingto \[14\] are:would generate a neutral statement choosing tone lato accompany the presentation, as in / / la  die ergeb-nisse sind unten dargestellt//z ("The results are givenbelow").
If, however, the results had so far been pre-sented at a different position on the screen, the sys-tem would generate tone lb  in order to place specialemphasis on the statement: / / lb  die ergebmsse sinaUNTEN dargestellt//.?
Tonal i ty:  The distribution into tone groups, i.e.,the number of tone groups allocated by the speakerto a given stretch of language.?
Tonic i ty:  The placing of the tonic syllable, i.e.,its position within the tone group.?
Tone:  The choice of a tone for each tone group;the tone is associated with the tonic.Choices in the systems of tonality and tonic i ty leadto an information constituent structure independent ofthe grammatical constituency, whereas choices in toneresult in the assignment of a tone contour for each iden-tified tone group in an utterance.
From these systems,only the choices in the tone systems realize an interper-sonal function 4, that of indicating a speech function orthe speaker's attitude (e.g., \[14\])?
This interpersonalfunction is our present concern.
Next, we want to in-vestigate the tone more closely before turning to theactual system networks in the KOMET grammar?Following \[24\], we assume five tones, s the primarytones, plus a number of so-called secondary tones thatare necessary for the description of German intonationcontours.
These tones are: ~all (tonel), rise (tone2),progredient (tone3),/all-rise (tone4), rise-/all (toneS),where the first four can be further differentiated intosecondary a and b tones.
8 The primary tones are theundifferentiated variants, whereas the secondary tonesare interpreted as realizing additional meaning.
Theyare intepreted as follows:la = neutrallb = emphatic2a = neutral2b = negative3a = weak contrast3b = strong contrast4a = neutral4b = negative5 = assertive/clarifyingConsider the following example taken from one of theinformation seeking dialogues: The computer has re-trieved an answer to a query, and this answer is pre-sented graphically to the user.
As a default, the system4Tone moreover realizes the logical metafunction, how-ever, we will ignore this fact for the present argument.~Other approaches tointonation suggest adifferent num-ber of tones, ranging from four to six.
\[8\] even goes one stepfurther in arguing that it is not sufficient o describe tonesby a combination of fall and rise, instead, much finer dis-tinctions have to be made (see \[8\]).8The criteria for the distinction of primary tones is thetype of the tone movement, for instance rising or falling tonecontour, whereas the degree of the movement, i.e., whetherit is strong or weak in expression, is considered to be avariation within a given tone contour?174dcclnuvcI ~i~ivcF- cxd~aivc raL.
ncgaivc+Wh ~L pe~i~vc-dc~yi~gaas~,,~mnl~-to-c~dlsl~.ing \ [ '~  noo.cxpn:ssivcr~ e.mphaO.c cxpn:~'cr~q~vcF igure 2: KEY systems in declarative clauses (simpli-fied)Intonational choices in the KOMET grammarModelling intonation in the KOMET grammar involvesthe introduction of more delicate systems in those ar-eas on the lexicogrammatical level, where intonationaldistinctions exist, thus specifying the relation betweenintonation features and competing linguistic resources(like lexis and syntax).
Here, we will restrict ourselvesto the description of the system networks reflecting thechoices in tone.
The networks are primarily based onthe descriptive work by \[24\].The interpersonal part of the grammar provides thespeaker with resources for interacting with the listener,for exchanging information, goods and services, etc.
(see \[15, 20\]).
On the lexicogrammatical stratum, theMOOD systems are the central resource for expressingthese speech functions.
More delicate speech functionaldistinctions--specific to spoken German--are realizedby means of tone.
The (primary) tone selection in atone group serves to realize a number of speech func-tional distinctions?
For instance, depending on the tonecontour selected, the system output l is le wollen umf~nfzehn uhr fahren//("You want to leave at 3 pm.
")can be either interpreted as a question (tone 2a) or astatement (tone la).More important is the conditioning of the (secondary)tone by attitudinal options such as the speaker's atti-Tin this paper, the following notational conventions hold:/ /marks tone group boundaries, CAPITAL LETTERS areused to mark the tonic element of a tone group.
Numbersfollowing the / /  at the beginning of a tone group indicatethe type of tone contour.tude towards the proposition being expressed (surprise,reservation ...), what answer is being expected, empha-sis on the proposition etc., referred to as KEY features.If one defines KEY as the part of speech functional dis-tinctions expressed' by means of tone rather than moodalone, one can integrate the MOOD and KEY systemsinto the grammar by positioning KEY systems as de-pendent on the various MOOO systems,ropuve - -mmn-seekmgrevolved__  S l roeS-* t~tn '~ lF igure  3: KEY systems, interrog, clauses (simplified)Figures 2 and 3 give the system networks of the KOMETgrammar for the declarative and interrogative sentencemood.
The networks now include more delicate gram-matical distinctions in order to realize the variationsthat have intonational consequences.
The networksare restricted in that they omit some of the incongru-ent mood codings.
The added discriminations to theKOMET grammar impose constraints on the specifica-tion of an appropriate intonation contour.3.3 In tegrat ing  COl t  and  KOMET-PENMANAs illustrated in Section 3.2 the relation between dia-logue moves and tone is many-to-many, hence the ap-propriate tone selection must be further constrained.The dialogue model provides general information aboutthe structure of an information retrieval dialogue,hence we consider it a representation of genre.
TheKOMET grammar provides linguistic resources includ-ing intonational options.
In the following section, wedetermine the kinds of information that are needed inaddition to what these resources provide and suggesta method of integrating the additional resources in theoverall system,4 Const ra in ts  on  cho ice  in in tonat ionIn information-seeking, human-machine dialogue it iscrucial to signal to the user as unambiguously as pos-sible at which stage in the dialogue she is and what ac-tion (verbal or non-verbal) she is supposed to take (sees\[14\], \[7\] and \[21\] have described this for English, \[24\]adapted Halliday's approach for German.175Section 2).
When spoken mode is envisaged as output,the intonation contour is the major means to conveythis information.
The relation between dialogue movesand tone types is however not trivial.
For instance, adialogue move REQUEST--depending on the context inwhich it occurs--may be realized intonationally by us-ing tone 1, tone 2 or tone 4.
Hence, the selection of anappropriate tone is conditioned by factors other thanjust individual coR dialogue moves.
When we thinkabout the problem from the perspective of intonation,the picture becomes clearer.
It is generally acknowl-edged in descriptive linguistics that the kind of toneattributed to an information unit encodes a basic se-mantic speech act or speech function \[27, 25\], such ascommand, question, statement and offer, even thoughthis relation is not one-to-one.
Also, it is uncontro-versial to maintain that intonation potentially reflectsa speaker's attitude towards the message she verbalizes(see e.g., \[24\]).
When looking at dialogue--rather thanmonologue--other factors coming into play are the his-tory off the dialogue taking place and the expectationson the part off the hearer that are evoked at particularstages in the course of the dialogue.In this section, we will discuss how these factors re-late to the selection of tone.
Our goal is to deter-mine more precisely what is comprised by them andto arrive at a refinement of the general architecture wehave presented in Section 3.
More concretely, it willbe shown that the factors just pointed out are logi-cally independent parameters that in different combi-nations constrain the selection of a particular tone.
Wewill then propose an organization of these different pa-rameters in terms of stratification that allows for thenecessary flexibility and brigdes the gap between thedialogue model and the generator.
Discussing a sam-ple dialogue (Section 4.2), we will then apply the modeldeveloped.We start from the stratum of grammar and move to theother linguistic and pragmatic resources relevant o thepresent problem.
As the starting point for discussionwe take the grammatical systems of MOOD and KEY, forthey grammatically encode semantic speech functionand speaker's attitudes and lead directly to selectionsin tone.4.1 The  mean ings  of  toneOne of the primary grammatical choices relevant for theselection of tone is the choice of mood, such as declar-ative, interrogative and imperative.
9 The relation be-tween mood and tone is potentially many-to-many withone exception:imperative s always realized by tone 1.However, the choice of mood is crucial since it leads toa whole variety of options that are eventually realizedin different ones (these are the KEY systems).How is choice in the basic mood options constrained?9We assume here that the information unit is the clauseand that tonality is unmarked, i.e., that there is one tone-group only.
We are aware, however, that generally thereis no one-to-one correspondence b tween information unitand clause.Mood is in the first instance tim grammatical real-ization of semantic speech function.
Speech functionscomprise command, offer, statement and question.
Sys-temically, they are derived from the SPEECH FUNC-TION network (see e.g., \[20\] and Figure 4).
Again,the relation between speech function and mood is po-tentially many-to-many:All of imperative, declaraLiveand interrogative may for instance ncode a command.For example Schliefl das Fenster!
(Close the window!
),W~rdest Du das Fenster schlieflen, bitte?
( Would youclose the window, please?
), Du sollst das Fenster nichtbffnen!
(You're not supposed to open the window O.How can the mapping between speech function andmood be constrained then?
A major constraint onthe mapping between speech function and mood isthe kind of discourse or genre, and the type of dis-course stage the message is produced in.
For instance,the genre of information-seeking, human-machine dia-logues is characterized by certain genre-specific stagesor dialogue moves (see Section 3.1).
A typical move inthis genre is the REQUEST move.
In terms of speechfunction, a REQUEST is typically a question, i.e., \[de-manding:information\], m The REQUEST-question corre-lation in the kind of dialogue we are dealing with hereconstrains the choice of mood to interrogative or declar-ative, e.g., (1) Wohin mSchten Sie fahren?
(Where doyou want to go?)
(interrogative)-- (2) Sie wollen umdrei Uhr fahren?
(You want to go at three o'clock?)(declarative).
So, in information-seeking dialogues, thetype of move largely constrains the selection of speechfunction, but it only partially constrains the mappingof speech time,ion and mood.Deciding between declarative and interrogative as real-ization of a move REQUEST requires information aboutthe immediate context of the utterance, i.e., about thedialogue history.
It is in the area of combinations ofdialogue moves that we find reflections of speaker's at-titudes and intentions and hearer's expectations as de-termined by the context.
The area in the grammarencoding this is key.The KEY systems are subsystems of the basicMOOD options (see Section 3.2).
In terms ofkey, example (1) would be \[interrogative:wh-type:wh-nontonic:neutral-involvement\], thus leading to an into-national realization as tone 1, example (2) would be\[ declarative:answering:answer-to-question:strong\] lead-ing to an intonational realization as tone 2.
Con-sider the contexts in which (1) or (2) would be ap-propriate: (1) would typically be used as an initiat-ing move of an exchange, where there is no immedi-ately preceding context--the speaker's attitude is es-sentially neutral.
(2) would typically be used in anexchange as the realization of a responding to move;in terms of the coa  model, (2) would be a possiblerealization of a REQUEST within an INFORM or withina REQUEST- - the speaker wants to make sure she hasunderstood correctly.
Only in the REQUEST or IN-raThe notation \[x:y:z\] gives a path through a systemnetwork.176rank fcallingI il.t, tolldizlg ?
E ~ru,~ting~ tz?N?t'i~tt'iHN "~'Er(';u:t.ilz~n~tV.,oti~Ltiol~ l E initi;tt, iuN ~xc:h+ulKin~~-~ Z't~.~p?
)lldil Ig t.oI '  I-- d i .~ l l l ;U ld i l lg  ~ s ta tement  /F good g,~ scPrvl(~,+ C,.,,~,,,~-- command /L I l l g l J l ' l l l a t l ( ) l l  quest ionF igure  4: Speech functions--the semantic stratum.FORM contexts of a REQUEST does it become possi-ble to map the dialogue move/speech function corre-lation of REQUEST-question to the mood and key fea-tures \[ declarative:answering:answer-to-question:strong\](see also Section 4.2).For the representation f constraints between dialoguemoves on the dialogue side and speech function on theside of interpersonal semantics and mood and key onthe part of the grammar, this means that a good can-didate for the ultimate constraint on tone selection isthe type of move in context (or: the dialogue history).Given that all of the parameters (dialogue move type,dialogue history, speech function, mood and key) arelogically independent and that different combinationsof them go together with different selections of tone, anorganization of these parameters in terms of stratifica-tion suggests itself, for it provides the required flexibil-ity in mapping the different categories.
Such an orga-nization is for instance proposed in systemic functionalwork on interaction and dialogue \[3, 20, 36\].1In the systemic functional model, the strata assumedare context (extra-linguistic), semantics and grammar(linguistic).
On the semantic stratum, general knowl-edge about interactions i located, described in terms ofthe NEGOTIATION network (cf.
Figure 4).
A pass (orpasses, since NEGOTIATION is recursive) through thenetwork results in a syntagmatic structure of an inter-action called exchange structure.
An exchange struc-ture consists of moves which are the units for whichthe SPEECH FUNCTION network holds.
NEGOTIATIONand SPEECH FUNCTION are the two ranks of the stra-tum of interpersonal semantics (see Figure 4).
TheMOOD and KEY systems represent the grammatical re-alization of a move (given that a move is realized asa clause).
The ultimate constraint on the selectionof features in the interpersonal semantics and gram-mar is the information located at the stratum of con-text.
This is knowledge about the type of discourse orgenre.
In the present scenario, this contextual knowl-edge is provided by the dialogue model, reflecting thegenre of information-seeking, human-machine dialogue.Since the stratum of context is extra-linguistic, locat-ing the dialogue model--which as originally not beendesigned to be a model of linguistic dialogue, but ofretrieval dialogue in general--here is a straightforwardstep.
For a graphical overview of the stratified archi-tecture we just described briefly see Figure 5.
"7 xX Oo~9D IALOGUE MODEL --t- D IALOGUE H ISTORYD->R,P , I ,ED -> R, RRR-> r, Dnegotiation --Espeech functionmood "'" ~ keyF igure  5: The stratified model.4.2 A top-down perspectiveIn this section, we discuss our proposal of bridging thegap between the dialogue model and the text generatorKOMET-PENMAN from a top-down perspective.
We de-velop concrete mappings between the extra-linguisticand semantic strata.
Further, we show how competentchoices at the semantic stratum guide the selection offeatures in the MOOD and KEY systems, which finallyresult in the assignment of a tone.
We base our deriva-tion of mappings between the strata on the followingsample dialogue and its COR analysis ll from the do-main of giving out train information.
In the following,we will discuss the different system utterances one byone.
This discussion is summarized in Table 1 .A) usrB) systC) usrD) systE) usrF ) systG) usrH) syst<Calls the train information>Wo mhchten Sie hin?Heidelberg (HD) um 3Uhr.Sic wollen nach Heidelberg?Ja.W/ire 14:52 heute Nachmittag OK?Ja.Eine einfache Fahrt kostet 6DM.English translation:A) usr <Calls the train information>B) syst Where do you want to travel?C) usr Heidelberg (HD) at 3 o'clock.D) syst You said Heidelberg?E) usr Yes.F) syst Is 14:52 this afternoon OK?G) usr Yes.H) syst A one-way ticket costs 6DMn(,,) / D(,,} ~ ~  I(s)r D(s) iphm'D~ n(s )  I01) ~ ODM~,m / i / ~ D(.)to?
S n 'e loe l?
II I Ir iI i \[HD7 Ym 14:627I ( .
)IiI y~In i t ia l  requests  Utterance B) results from a realinformation eed on the system part.
In order to dollIn the analysis: D=(sub-)Dialogue, R/r=R/request,I/i=\[/inform.
177anything at all, the system must know where the userwants to travel.
Unless the user volunteers the des-tination, it must request his information from her.
12The user did not say where she wanted to travel, hencethe system initiated the exchange, this is representedby the following path through the NEGOTIATIONha net-work: \[negotiation:negotiating:exchanging/initiating\].In terms of speech function, we realize this request asa question (\[demanding/in/ormation\]).
Other possiblerealizations of a request would be command, offer andstatement, hough none of them applies in the givencontext.
The scenario itself excludes the command andthe statement option, since the system is in need forinformation.
Finally, since the system is incapable ofhanding over, say, a ticket, this request cannot be re-alized as an offer ("Let me give you a ticket to yourdestination" ).Knowing that we have to realize a question, we havethree MOOD options available: \[declarative\], [yes/no-question\], and \[wh-question\].
Keeping in mind that wewant our system to be user friendly, we do not wantit to realize this request as a yes/no question ("Do youwant to go to Heidelberg?
"), or a statement ("You wantto travel to Heidelberg?
"), since it would then exhaus-tively have to search through its knowledge base in or-der to find the right destination to include in its ut-terance.
Hence we conclude that requests that are notin response to a user utterance should be realized as awh-question.In terms of KEY, we do not want our system to be overly\[involved\] in the conversation or \[surprised\] by the factthat it has to request some information and there isnothing to \[clarify\], hence the only accessible KEY fea-ture is \[neutral-involvement\], which implies that utter-ance B)--an initiating, neutral, wh-question--shouldbe realized as tone 1.Respond ing  requests  Utterance D) is a request inresponse to the destination that the user informed.
Interms of semantic hoices it is \[initiating\] a new embed-ded exchange, while it is \[responding to\] a user movein the embedding exchange.
The speech function isquestion since the system wants to initiate a response.We suggest hat the linguistic realization of this ques-tion depends on how confident the system is about whatthe user informed, hence in order to choose appropriateMOOD and KEY features, we argue that we need accessto an additional resource--a confidence measure.13 Forthe current example, we suggest he following alterna-tives:12We assume that the system has an abstract internalspecification of its information eeds and that it keeps arecord of the information it has already received.laTbis is highly relevant if the input channel is spoken,since speech recognizers cannot achieve a 100% recognitionrate.
Technically, the confidence measure would come fromthe speech recognition unit.I t lGH"You said Heidelberg?"
?9Z .~ "Did you say Heidelberg?"~.
"Could you repeat hat, please?
"zo "Where do you want to travel?"
C.9LOWIf the system is confident hat it has understood whatthe user said, it would ask only to confirm what itbelieves to know, hence it would choose a declarativewith tone 2 (\[answering:positive/answering-to-question:strong\]).
If the confidence is somewhat lower,there are two ways of realizing a yes/no-question:tone 2a (\[interrogative:yes/no-type:information-seeking:unmarked:neutral-assessment\]) or tone 2(\[interrogative:yes/no:request\]).
Finally, if the systemhas not at all understood what the user said, it couldindicate this by using a clarifying wh-question withtone 4 (\[interrogative:wh-type:wh-tonic:clarifying\]).Utterance F) is also in response to a user inform, butwhat makes this situation different from the responseabove is that here, there is a mismatch between whatthe user wanted and what the system can offer (Userwanted 3 o'clock, while system can only offer 14.52).Hence the system must offer the user an alternativeand the linguistic form of this utterance might differwith the "closeness" of the alternative to the originaldemand.If the alternative is reasonably close (In our exam-ple, there is a time difference of 8 minutes, which, forthis scenario, might be considered a good alternative),we find it appropriate to generate a yes/no-questionwith tone 2b (\[interrogative:yes/no-type:information-seeking:unmarked:strong-assessment\]).
The lack ofgood alternatives, however, might condition a wh-question ("What is your next preferred departuretime?")
with tone 1 (\[interrogative:wh-type:wh-nontonic :neutral- involvement \] ).I n fo rm The system answers the user's question,i.e., it is \[giving/information\], and hence the speechfunction is statement.
Statements of this type donot need any particular intonational marking, sinceat this point they are expected, hence we choose thefeatures \[ declarative:stating:neutral:n?nemphatic:n?n-contrastive\], i.e., tone la.
E.g., ("Eine einfache Fahrtkostet 6DM" (="The ticket costs 6DM.
").P romise  The information knower can utter a pro-mise when she wants to signal the information seekerthat she is considering the request.
For instance, "IchDURCHSUCHE die datenbank."
(= "I am search-ing").
A promise move is always in response to a requestmove and the relevant partial structure is:D(s)R(u) P(s)!
/r P As(s)The speech function is statement since the systemtures we choose \[declaratwe:stating:neutral:nonempha-tic:non-contrastive\], hence tone la.As indicated in the partial structure above, an assertmove can follow a promise act.
This is additional infor-mation that the system volunteers the user, which oftentake the form of a polite command, e.g., "Bitte warrenSie.
"(= "Please wait.").
Linguistically~ commands arerealized as imperatives and hence tone 1.Request  in Wi thdraw A request in the context ofany of the unexpected ialogue moves (e.g., withdraw-request) mostly serves as confirmation question similarto the responding requests in inform that we discussedabove.
This is, however, an unexpected move on thepart of the user, hence we suggest hat these requests,again mapping to question on the speech functionallevel, are realized as yes/no-question (as opposed todeclarative with tone 2, see above) i.e., "Do you wantto quit?"
vs. "You want to quit?".
Which tone onechooses for this type of question depends on how in-volved one wants the system to appear.
Tone 4a indi-cates neutral involvement, while tone 4b signals stronginvolvement.
The partial structure of this type of re-quests is as follows:D(s)a(u)  Vn(u)' D()  r wr sR(u)Offer In an information retrieval system, the systemoften offers the user a list of alternatives from whichshe has to choose one.
If we consider the appearanceof a list on the screen a metaphor for actually hand-ing over an object, this situation corresponds to \[de-manding/goods ~4 services\], i.e., the speech function iscommand, hence we suggest hat offers are realized asimperatives with tone 1.
E.g., "Bitte wS~hlen Sie eins.
"(="Please choose one.
")Summary  The above discussion is summarized inTable 1.
Further, from the data that we have collectedso far we observe:?
The dialogue move guides the selection of speechfunction, e.g., request corresponds to speech func-tion question, whereas offer maps to command.?
The dialogue history, or context, guides the se-lection of semantic choices, i.e., pure initiat-ing moves (e.g., request) correspond to \[exchang-ing/initiating\], while responding initiating moves(e.g., inform(request)) correspond to \[exchang-ing/responding\] in a first grammar traversal and\[exchanging/initiating\] in a second.?
Choices in MOOD and KEY systems can often notbe made unless we have access to additional knowl-edge sources as, for instance, a confidence measure.is \[giving/information\], and as MOOD and KEY fea- Future empirical studies will determine whether these178 generalizations hold.Genre Exchangelevel moveB) requestD) inform(re-quest)D) inform(re-quest)D) inform(re-quest)F)H)I exch/init\] exch/resp\] exch/init\]Speech Moodf Tonefunction Keyquestion WH 1question A 2question Y/N 2bquestion WH 4inform(re- exch/resp\] question Y/N 2aquest) exch/init\]inform exch/resp\] statement S lapromise exch/resp\] statement S 1promise(as- exch/resp\] command I 1sert)withdraw( \[exch/resp\] question Y/N 4a/brequest) \[exch/init 1offer \[exch/init\] command I 1reject re- \[exch/resp\] statement A 2questTable 1: Notation: ' / '  and ' / / '  indicate choices in par-alell systems, ':' indicate refinement of the previouschoice.
WH = wh-question, Y/N = yes/no question,A = answering, S = stating, I = imperative.5 ConclusionsIn this article we have developed a model for guid-ing the selection of intonation in a system supportinghuman-machine interaction in retrieval dialogues withspoken output.
We have concentrated on the choice \[1\]of tone as a major signal of interpersonal semanticfeatures, such as speech acts and speaker's attitudes.To express these appropriately is crucial especially inhuman-machine dialogue, since they contribute to the \[2\]success of the interaction in a major way.As a starting point we have taken two existing \[3\]systems--the COR dialogue model and the KOMET-PENMAN generation system.
On this basis, we havedetermined a number of factors that contribute to theselection of appropriate tones, such as speech func- \[4\]tion, speaker's attitudes and hearer's expectations, andtypes of dialogue moves in context.
Finally, we haveproposed a stratified model that includes all of the rele-vant kinds of information to guide the selection of tone.
\[5\]Even though our dialogue model was originally not de-signed for language, we have shown that this relatively \[6\]simple model provides useful information for intonationselection.
A linguistically based discourse model wouldbe able to provide more information, but in the contextof an interactive conversational system in which there \[7\]are practical imits on how tong it can take to producea response, we believe that a full fledged discourse anal-ysis system would be too slow.We are aware that we have left untouched a number of \[8\]problems that are involved in the generation of appro-priate intonations.
These include: \[9\]?
accounting for the textual meaning of intonationencoded in information structure and thematic179development/progression (realized in tonicity; seeSection 2);We handle only situations in which there is a one-to-one corresponds between tone group and clause.We can only make predictions about completeclauses, hence the grammar prevents the genera-tion of utterances with ellipses.
This is relevant forgeographical clarification question, e.g., "WollenSie nach Frankfurt am Main oder Frankfurt ander Oder?".
In many contexts it is more natu-ral to use just a phrase "Frankfurt am Main oderan der Oder?
"Similarly it is unnatural to generate the evaluatemoves as complete clauses.
It suffices to generatesimple phrases like "Thanks" or "OK".Also, the method we have applied here to develop ourmodel has been solely qualitative.
For a proper vali-dation we need to analyse larger quantities of dialoguein order to have an empirically sound foundation.
Thesame is true for the classification of intonation whichwas developed by Pheby in the late sixties.
Here, thecollaborative work with speech synthesis will provideus with empirical data that can then be used to refinethe classification.REFERENCESB.
Abb, C. Giinther, M. Herweg, C. Maienborn, andA.
Schopp.
Incremental syntactic and phonological en-coding - an outline of the synphonics formulator.
InProceedings of the Fourth European Workshop on Nat-ural Language Generation, pages 19-29, 1993.H.
Altmann, editor.
Zur Intonation yon Modus undFokus im Deutschen.
Tiibingen: Niemeyer, 1989.M.
Berry.
Systemic linguistics and discourse analysis:a multi-layered approach to exchange structure.
InMalcolm Coulthard and Michael Montgomery, editors,Studies in Discourse Analysis.
Routledge and KeganPaul, London, 1981.M.
Bierwisch.
Regeln ffir die Intonation deutscherSatze.
In Studia Grammatica VII: Untersuchungen5ber Akzent und Intonation im Deutschen, pages 99-201.
Berlin: Akademie Verlag, 1973.E.
Bilange.
A task independent oral dialogue model.In Proc.
of the European Chapter of the ACL, pages83-87, 1991.G.
Dorffner, E. Buchberger, and M. Kommenda.
Inte-grating stress and intonation into a concept-to-speechsystem.
In Proc.
of the l~th Intl.
Conf.
on Computa-tional Linguistics (COLING'90), pages 89-94, 1990.R.P.
Fawcett, A. van der Mije, and C. van Wissen.
To-wards a systemic flowchart model for discourse.
In R.P.Fawcett and D. Young, editors, New Developments inSystemic Linguistics, volume 2, pages 116-143.
Pinter,London, 1988.C.
Fery.
German Intonational Patterns.
Tiibingen:Niemeyer, 1993.M.
Fischer, E. Maier, and A. Stein.
Generating coop-erative system responses in information retrieval dia-logues.
In Proceedings of the International Workshopon Natural Language Generation, pages 207-216, Ken-nebunkport, Maine, 1994.\[10\] D. Frohlich and P. Luff.
Applying the technology ofconversation to the technology for conversation.
InP.
Luff, N. Gilbert, and D. Frohlich, editors.
Comput-ers and Conversation, pages 187-220.
Academic Press,1990.\[11\] B. Grote.
Grammatical revision of the germanprepositional phrase in KOMET.
Technical Report,GMD/Institut fiir integrierte Publikations- und Infor-mationssysteme, Darmstadt, 1994.\[12\] B. Grote.
Specifications of grammar/semantic exten-sions for inclusion of intonation within the KOMETgrammar of german.
COPERNICUS '93 Project No.10393.
Deliverable R2.1.1, 1995.\[13\] E. Hagen and A. Stein.
Automatic generation of a com-plex dialogue history.
In Proc.
11th Canadian Confer-ence on Artificial Intelligence (AI96), page forthcom-ing.
Canadian Society for Computational Studies ofIntelligence, 1996.\[14\] M.A.K.
Halliday.
Intonation and Grammar in BritishEnglish.
The Hague: Mouto, 1967.\[15\] M.A.K.
HaUiday.
An Introduction to Functional Gram-mar.
Edward Arnold, London, 1985.\[16\] J.P. Hemert, U. Adriaens-Porzig, and L.M.
Adriaens.Speech synthesis in the spicos project.
In H.G.
Till-mann and G. Willee, editors, Analyse und Synthesegesprochener Sprache.
Jahrestagung der GLDV, pages34-39.
Hildesheim: Georg Olms, 1987.\[17\] J. Hirschberg.
Using discourse context o guide pitchaccent decisions in synthetic speech.
In G. Bailly andC.
Benoit, editors, Talking machines: Theory, Modelsand Design, pages 367-376.
Amsterdam: North Hol-land, 1992.\[18\] K. Huber, H. Hunker, B. Pfister, T. Russi, and C.Traber.
Sprachsynthese ab Text.
In H.G.
Tillmann andG.
Willee, editors, Analyse und Synthese gesprochenerSprache.
Jahrestagung der GLDV, 1987, pages 26-33.Hildesheim: Georg Olms, 1987.\[19\] K.J.
Kohler.
Einf~hrung in die Phonetik desDeutschen.
Berlin, 1977.\[20\] J.R. Martin.
English text; System and structure, chap-ter 7, pages 493-573.
John Benjamins Publishing Com-pany, Philadelphia/Amsterdam, 1992.\[21\] C. Matthiessen.
Lexicogrammatical rtography: En-glish systems.
Technical Report, University of Sydney,Linguistics Department, 1993.\[22\] M. O'Donnell.
A dynamic model of exchange.
Word,41(3):293-327, 1990.\[23\] G. Olaszy, G. Gordos, and G. Nemeth.
The multivoxmultilingual text-to-speech onverter.
In G. Bailly andC.
Benoit, editors, Talking machines: Theory, Modelsand Design, pages 385-411.
Amsterdam: North Hol-land, 1992.\[24\] J. Pheby.
Intonation und Grammatik im Deutschen.Akademie-Verlag, Berlin, 1969.
(2nd.
edition, 1980).\[25\] J. Pheby.
Intonation.
In K.E.
Heidolph, W. Fl~imig,and W. Motsch, editors, Grundz~ge einer deutschenGrammatik, pages 839 - 897.
Akademie-Verlag, Berlin,1980.\[26\] S. Prevost and M. Steedman.
Specifying intonationfrom context for speech synthesis.
Speech Communi-cation, to appear.\[27\] R. Quirk, S. Greenbaum, G. Leech, and J. Svartik.
Acomprehensive grammar of the English language.
Long-man, London, 1985.\[28\] N. Reithinger, E. Maier, and J. Alexandersson.
Treat-ment of incomplete dialogues in a speech-to-speechtranslation system.
In Proc.
ESCA Workshop onSpoken Dialogue Systems; Theories and Applications,pages 33-36.
ESCA and Center for PersonKommunika-tion, Aalborg University, Denmark, 1995.\[29\] J.R. Searle.
A Taxonomy of Illocutionary Acts.
In:Searle, J.R.
Expression and Meaning.
Studies in theTheory of Speech Acts., pages 1-29.
Cambridge Uni-versity Press, Cambridge, MA, 1979.\[30\] M. Selting.
Phonologie der Intonation: Problemebisheriger Modelle und Konsequenzen.
Zeitschrift fiirSprachwissenschaft, 11(1):1993, 99-138.\[31\] S. Sitter and A. Stein.
Modelling the illocutionaryaspects of information-seeking dialogues.
InformationProcessing and Management, 8(2):165-180, 1992.\[32\] E. Teich.
Komet: Grammar documentation.
Techni-cal Report, GMD/Institut ffir integrierte Publikations-und Informationssysteme, Darmstadt, 1992.\[33\] E. Teich, J.A.
Bateman, and L. Degand.
Multilingualtextuality: Experiences from multilingual text genera-tion.
In Zock M. and G. Adorni, editors, Selected Pa-pers from the Fourth European Workshop on NaturalLanguage Generation, Pisa, Italy, 28-30 April 1993.Springer, Berlin, New York, forthcoming.\[34\] E. Teich, A. Stein, E. Hagen, and J.A.
Bateman.Meta-dialogues implementation.
Technical report,GMD/IPSI, Technical Universities of Darmstadt andBudapest, 1995.
Speech Generation in MultimodalInformation Systems, Copernicus Project No.
10393,SPEAK!
deliverable P3.2.3.\[35\] D. Traum and E. Hinkelman.
Conversation acts intask-oriented spoken dialogue.
Computational Intelli-gence, 8(3):575-599, 192.\[36\] E. Ventola.
The Structure of Social Interaction: A Sys-temic Approach to the Semiotics of Service Encounters.Frances Pinter (publishers), London, 1987.180
