Toward the "At-a-glance" Summary:Phrase-representation Summarization MethodYoshihiroUEDA, MamikoOKA, TakahiroKOYAMA and TadanobuMIYAUCHlIndustry Solutions Company, Fuji Xerox~ Co., Ltd.430 Sakai, Nakai-machi, Kanagawa 259-0157, JAPAN{Ueda.goshihiro, oka.mamiko, Koyama.Takahiro, Miyauchi.Tadanobu}@fujixerox.co.jpAbstractWe have developed a summarization method that creates a snmmary suitable for tim p,'ocess ofsifting information retrieval results.
Unlike conventional methods that extract ilnportant sen-tences, this method constructs short phrases to reduce the burden of reading long sentences.
Wehave developed a prototype summarization system tbr Japanese.
Through a rather large-scale task~based experiment, he sumnmry this system creates proved to be effective to sift IR results.
Thissummarization method is also applicable to other languages such as English.IntroductionSulnmaries are used to select relevant informationfrom information retrieval results.
The goal ofsunmmrization for such "indicative" use is toprovide fast and accurate judgement.Most automatic summarization systems adoptthe "sentence selection" metho& which gives ascore to eve~ sentence on the basis of its charac-.teristics, such as word frequency, the position inwhich it appears, etc.
and selects sentences withhigh scores.Tim sentences collected in such a way tend tobe so long and complex that the reader mustreconstruct im structure while reading them.Reading such sentences involves some annoy-ante .Our aim is to reduce this burden by provklingan "at-a-glance" summary.Phrase-representation summarization is amethod to create the "at-a-glance" summary forthe Japanese language, t tere we present theconcept, the algorithm, and ewihiation of theefficacy of the summary produced by a prototypebased on this method.
Extension to English isalso discussed.1 The ConceptExamples of an "'at-a-glance'" summary are theheadlines of news articles.
The headlineprovides intbrmation tbr judging whether thearticle is to be read or not an& in this sense, it isreally ??indicative."
The characteristics are:?
Brevity (short in length)?
Simplicity (less embedded sentences)We use "'pllrases" to represent he simplicitycharacteristic I and set our goal to create phrase-represented summaries, which provide the readerwith an outline of  the document, avoiding readingstress by enumerating short phrases containing theimportant words and concepts composed fromthese words.The lnethod we adopted to achieve this goal isto construct such phrases from the relationsbetween words rather than extracting importantsentences fl'om the original document.2 Summarization Method2.1 Outline of the AlgorithmHere we give a short description of the ot,tline oftiffs method using the example shown in Fig.
1.
2i The word "'phrase" used here is not of tile linguisticsense but an expression tbr "'short" and "sinaple."
InJapanese, there is no rigid distinction between "phrase"and "'clause.
"-~ In tiffs paper, Japanese words are represented inEnglish as much as possible.
The words left inJapanese arc shown in italics, such as -~a" (a particlefor AGENT),  "jidai'" ("era"), etc.
Each relation nameis constructed from a Japanese pailicle and its function(shown as a case name or an equivalent l-;nglish878(a) original \[ "(9:.r~gl j sl~ t rans lat ion)  At the Green Fair  held on 24th, a venture company PICORP ap.nounced it l i censes  its env i ronment  pro tect ion  techno logy  to B_MICO, theU.S.
top compa:!v.
P ICORP's  CEO Ken Ono said that..
.
(b) analysis graph & (1) analysis of relations....... ~ ~ - - ~  (;,',,enF~,ir } (2) selection of.
/ ,  ?
.
.
.
.
.
.
.
"nioite"-AT ~ core relationm -FQ \[ - "1 "'ha'-IHEM\[= ~ ' ~  \]venture ~'\[ PICORP j' - -  I. .
.
.
.
.
e    ro m--71ent 4, I, , "no -ur  !
protection I / ' -  . '
... " - " - I ,  , , , ~t" -~\ ]  license \[ , .- larmouncedl\[ t_ecnnomgy I".,o"-OBJ' ~ ' ' - I, I I  ~ (3) Addition of relations.
.
.
.
.
.
.
ni '-DAT(c) obtained phrase.~  (4) generationPICORP l icenses env i ronment  pro tect ion  techno logy  to AMICO IFig.
1 : Outline of phrase-representation summarizationThe method consists of the Efllowing tbur majorsteps:(1) Syntactic analysis to extract he relationsbetween words(2) Selection of the core relation(3) Adding relations necessa D' for the unityof the phrase's meaning(4)Generating the surface phrase from theconstructed graphFirst, the sentences in the given document areanalyzed to produce directed acyclic graphs(DAGs) constructed fi'om relation units, each ofwhich consists of  two nodes (words) and an arc(relation between tim words).
Each node is notonly a single word but also can be a wordsequence (noun group).Then an important relation is selected as a"core" relation.
In F'ig.
l, the arc connecting thetwo shaded nodes is selected as the "core.
"The core relation alone carries insufficientinformation to convey the content of the originaldocunaent.
Additional arcs (represented bypreposition).double lines) are attached to narrow the infornm-.tion the phrase supplies.The tbllowing short phrase can be generatedfi'om the selected nodes and arcs in the graph:P ICORP l i censes  (its) env i ronmentpro tect ion  techno logy  to AMICO.
3Phrase-representation summarization enutner-ates such short phrases to give the readers enoughinfornmtion to grasp the outline of a document.This algorithm is explained in the next section.2.2  Fur ther  descr ip t ion  o f  each  s tepThe steps shown in the previous section consistsof  a cycle that produces a single phrase.
Thecycles are repeated until the generated phrasessatisfy a predefined condition (e.g.
the length ofthe summary).
The scores of the words used inthe cycle are reduced by a predefined cut-down; This short sentence can be expressed as a phrase intt~e linguistic sense in \[.
;nglish:I~IC()RI)'s licensing (its) environment protectiontechnology to AMIC().879ratio to avoid fi'equent use of the same words inthe summaiT.The basic algorithm is shown in El,, "~Relation AnM|,.~'isSyntactic analysis is applied to each sentence illthe document to produce a DAG of the relationsof words.
We use a simple parser based onpattern matching (Miyauchi, et al 1995), one ofwhose rules always judges each case dependenton its nea,'est verb.
Some of the misanalysis willbe hidden by "ambiguity packing" ill the "addi-tional relation attachment" step.Relation ScoringAll importance score is provided for each relationunit (two nodes and an arc connecting them).First, every word is scored by its importance.This score is calculated based on tile tf*IDF wdue(Salton, 1989) 4.Then, the relation score is calculated as fol-lows:Score = Srel * (Wl*S1 + W2"S2)Here, SI and $2 are tile scores of the two wordsconnected by relations.
The score of  a wordsequence is calculated by decreasing the sum ofthe scores of its constituent words according totile length of the word sequence.Wl and W2 are the weights given to each word.Currently, all words are equally treated (WI ---W2 = 1).Srel is the importance factor of  tile relation.The relations that play central roles ill themeaning, such as verb cases, are given highscores, and the surrounding relations, such as"'AND" relations, are scored low.
Tile relationscores for modifier-modified relations such asadverbs are set to 0 to avoid selecting them as thecore relations.Core relation selectionThe relation unit with tile highest score among allrelations is selected as the "core relation.
"Additional relation attachmentThe inlbrmation that the core relation carries isusually insufficient.
Additional relations arcattached to make the information tile phrase?
~ ll)F is calculated from I million WW~,V documcntsgathered by a Web search engine.Doctlnlent_ _ .
~ InputRelation Analysis 1Relation Scoring \]I \[ Core relation1 \[ selection \[ Relation\[\[ Generation of I\[_.surface ~hrases IOutput\[ Snlnnlary \]Fig.2 Basic flow of the algorithmsupplies rnore specific and to give the readersufficient information to infer the content of theoriginal doculnent.
"File following relations are apart of the relations to be attached.
@ Mandatory casesRelations that correspond to mandatory casesare attached to verbs.
Mandatory case listsare defined for verbs except for those thatshare tile common mandatory case list, whichincludes ?
'ga'-AGENT, %vo"-OBJ and "ni"-DATIVE.
"Ha"- ' f t fEME, "mo'-.ALSO, andnull-marker elations are also treated as man-datory, because they can appear in place ofthe mandatory relations.Ex.)
AMICe "ga"-AGENT release-+ AMICe "ga'-AGENTPDA "wo'-OBJ release(AMICe releases PDA.
)@ Noun modified by a verbIn Japanese, the "verb - noun" structure repre-.sents an embedded sentence, and the nounusually fills some gap in the embedded sen-tence, l('the verb in the core relation (noun-- verb) consists ot'sucll a verb -noun relation,the modified noun is also assumed to carryimportant information, even if it does not t511the mandatory case (fllough the case is not880arialyzed in tlic ctlrrent algorithm)?
Tim.<; theverb - llOtlll relation is attached to tile core.Ex.)
PDA "wo".-OBJ releasePDA "wo"-OBJ release0-THAT 5 AMICe(AMICe that releases I:>DA)PI)A "wo"-OBJ release-~ PDA"wo"-OBJ release0.-Tt4AT pDs!
(a plan to release PDA)@ Anlbiguity packingThe analysi.s trees often contain error.<; be--cause the pattern-base parser doesn't resolveambiguities.
For exarnple, the strtlCttlreV 0-.TI-IAT N1 "no'-OV N2 (Ving Nl's N2)i,q ambiguous in Japanese (V can rnodil~,/either N1 or N2 but the parser always aim-.lyzes N2 as modified)?
lf'the V-.NI rehltioniv; selected as the cole, the N1-N2 rehition isalways attached to the core to include the pos-.sible V-N2 relation.il Modifiers of generic llOUllSTile concepts brought by generic rloun,; suchas <~momf" (thing), +~koto" (<~that"' of that-clause), ~baai" (case), ~Tidai" (era) are not sospecific that they usually acconlpany lnodifi-.ers to be infbrmative, tlere such modifiersare attached to make them intbrmatiw e.l';x.)
era "ni".TIME emerge' ~ U ~  "no"-.OF era"ni".-TIME emerge(emerged irl the era of confi,isiorl)77,rmimgtian comlitio~,Judges whether tim surnnlarics created so far arcsufi-icient.
Curreritly the termination coriditiori sdefined by either the number of produced phrasesor the total summary length.Re-scoring ojrelationuI f  the condition is not fll lfi l led, thes;e steps fromselection of the core relation Must I.
)e repeated tocreate another phrase, t}efi)re selecting a newcore, the scores of  the words used in this cycle arereduced to increase the possibility for other wordsto be used in the next phrase.
Score reduction isachieved by multiplying tile predefined Ctll-dowllratio R (0 < It < 1) by the scores of the wordsused.
l,>,ehition scores are re-calculated usin.~, thenov, word scores.Generation o.f sur~we phrasesTiffs process produces I)AGs each of ~laichconsists of one core relation and several attachediclations.
In ,latmnesc, the surface phrases canbe ea.,;il) obtained by connecthlg the still'acestring of the nodes in their original order.
SeeChapter 5 for the generatioil method for \]\[:,nglish.3 The  Pro to typeWc developed a prototype of the summarizationsystem based on this algorithm.
The developmentlanguage is Java and the system is working onWindows 95/c)8/NT and Solaris 2.6 a.The time consumed by summarization processis in proportion to the text length and it takesabout 700 rnsec to generate a surnmal T for an Adsized document (2000 Japanese characters) usinga PC with a Celeron processor (500 Mtlz).
Over95% of the time is consumed in the relationanalysis tep.4 Eva luat ionWe have conducted an experiment to evahiate thesystem.
This section is a short sumrna W of theexpei+iment reported iri (()ka and Uedar, 2000).The aim of a phrase--represented summary is togive fast and accurate sifting of lit results.
Toevahiate whether the aim was achieved?
weadopted a task-based evahlation (Jing, et al 1998,Mani, et al 1998).
One of the problems of thoseexperiments using human subjects as assessors isinaccuracy caused by the diversity of assessment.To reduce the diversity, first we assign 10sub.iects (experiment participants) fbr eachsulnnlary sample.
The nunlber o f  subjects wasjust I or 2 in the previous task-based experiments.Second, we gave the subjects a detailed instruc--tion including the situation that led them to searchthe WWW.4,1 Exper iment  MethodThe outline of the evahiation is as follows:5 '0'" shows that there ~ll'e i1() particle~; ur any other\~,ol'ds Collnccting two ;~,old:-;.
,lapttrics;e dticSll'trequire anything like relative pi+onoun+<~' .lava and Solaris are the tra(temarks of SunMicrosvstems.
Windows and Ccleron tll'O themldcmark!
; of Microsoft and lntel, respedively.881?
Assume an inlbrmation need and make aqueIw for the information eed?
Prepare simulated WWW search resultswith different ypes of summaries: (A) first80 characters, (B) important sentence se-lection (Zechner, 1996), (C) phrase-represented summary, (I)) keyword enu-meration.
The documents in the simulatedsearch result set are selected so that the setincludes an appropriate number of relevantdocuments and irrelevant documents.?
Have subjects judge from the summariesthe relevance between the search resultsand the given int'ormation need.
Thejudgement is expressed in t'our levels (fromhigher to lower: L3, L2, LI, and L0, whichis judged to be irrelevant).?
Compare the relevance with the one that weassumed.The documents the user judges to be relevantcompose a subset of the IR results and it shouldbe more relevant o the information eed than theIR results themselves.
Because we haveintroduced three relevance levels, we can assumethree kinds of the subsets; L3 only, L3+L2, andL3+L2+LI.
The subset composed only from thedocuments with L3 judgement should have a highprecision score and the subset including L1documents should get a high recall score.4.2 ResultBecause recall and precision are in a trade~offrelation, here we show the result using f-measure,the balanced score of the two indexes.2 * precision* recallf - -  meaX l l l ' e  =precision + recallThe fmeasure averages of the experimentresult of three different asks are shown in Fig.
3.It shows that the phrase-represented summaries(C) are more suitable tbr sifting search resultsthan any other summaries in all cases.4.3 DiscussionThe result can be explained using the number ofsummaries that contain clues to the informationneed.
Summaries consistin,, of short units(phrases (C) and keywoMs (D)) are gathered fromthe wide range of the original text and accord-in,.zlv have many chances to include the clues.The actual average numbers of summaries thatphrase-represented Stltl lnlal-~E1A FIB EIC l iD,?
:::Ji f )t'ui:11Eut.0.80.70.60.50.40.30.20.10TOnly L3 L2 L3 L1 L2 + L3Fig.3 Experiment resultcontain the clues are 2.0, 4.3 and 4.7 for (B)sentence, (C) phrases and (D) keywords, respecotively, in spite that (D) keywords include moreclues than any other samples, they don't get agood t-score.
The reason is considered to be dueto the lack of information about the relationsamong keywords.5 Applicability to Other LanguagesAlthough this algoritlun was first developed forthe Japanese language, the concept of phrase~representation stmunarization is also applicable toother languages.
Here we show the directiontoward its extension to t'nglish.English has a clear concept of ~'phrase," andsimply connected words do not produce well-formed phrases.
I'his requires emantic analysisand generation from the semantic structure.We will consider the following example again.Ex.)
A venture company PICORP announcedto license their environment protection tech-nology to AMICO, a U.S. top company.l f"PICORP" and "license" must be included inthe summary and "announce" is not so important,"PlCORP license(s)" is the core of the desiredphrase.
Generating it requires ub.iect resolutiono\[" "license" and thus semantic level analysis isrequired.
Moreover, predicate-argument struc-tures arc preferable to syntactic trees because thesub.iect and the object are represented in the samelevel, thlification gramtnar flameworks uch asI,FG (Kaplan and P, restmn.
1082) and tlPSG(Pollard and Sag, t994) fulfill these requirements.Fig.
4 is a part of the analysis rcsuh represented inI.FG.882PREDSUBJVCOMP'announce( 1" SUB J) ( ?
VCOMP)'\[1\]\[PRED "PICORP"\]PRED 'license(i" SUB J) ( \[ OBJ) ( t  TO OBJ)'SUBJ \[11OBJ \[PRED 'environment protection technology'\]TO E PP TO 1 OBJ \[PRED 'AMICO' \]2$SUBJ \[PRED "PICORP"\]OBJ \[PRED 'environment protection technology'\]TO ~ PP 10 7\]OBJ \[PRED 'AMICO' \]PICORP licenses erlvironment protection technology to AMICe.PICORP's licensing of environment protection technology to AMICe.PICORP to license environment protection technology to AMICe (headline style)Fig.
4: Analysis and generation of summaryA score is calculated for each feature structureand the core feature structure will be selected byits score instead of  selecting a core relation andattaching malldatory relations.
In the corel~mture structure, index \[1\] is replaced by %I, JBJ ofthe top l\]eature structure.(}eneratin<,.
> phrases t'rOlll the t\:ature structurerequires templates ?.
Several pattern,<; c, an beselected io generate phrases:V- ing (gerund) tbrmARGI'  s PRED--Ang ARG2 'co ARG3notin |'ormARGI ' s  noun (PRF, D) o?
ARG2 to  ARG3to--infinitive l~}l-nlFor  ARGI  to  PRED ARG2 to  ARG3In this case, tile herin fOFlll ~" lqC()RP 's  licensec,f the protection technology to AMIC()" isavoided because tile noun "qicense" lacks themeaning of "action" or "'event. '"
()tiler rulesspecific to headlines such as ~'to-infinitiverepresents |'uture" Call alSO be hltroduced.6 Re lated WorkbllOSt sumnmrization studies ( inc luding Zcchnero1996) arc based on inq3oitant sentence selectionand seek belier selection methods.
We have+' Generation el" articles is h.'ft to be considered.pointed out that sumnmries made by this methodtend to be btndensome to read, and have proposedphrase-representation summarization as analternative.
The following studies bear somerelation to our study.The summarization method by Boguraev andKctmedy (1997) adopts ~phrasal expression"rather than sentences or paragraphs.
However, itbegins to create a phrase not from a core relationbut a core word (in their words, "'topic stamp")and produces multipk; phrases containing thesame core word; it is therefore not suitable forsummaries for sifting IR results.
In addition,because it does not consider the roles andimportance of thc attaching arcs when enrichingthe core, less important words are often attachedto the core.
They aimed at supporting fastreading rather than sifting IR restllts.Some studies are similar to ours in that theymake sentences short.
Wakao, et al (1998) andMikami, ct al.
(1998) aim to create closedcaptioning fl-om an announcer's manuscript byparaf~hrasing and renlovhlg nlodifiers.
Thismethod doesnh ronlove \[he "'{l'tlllk ~" o1" theanalxsis tree and the sunlll~aries canilot be madeas short as in phrase-representation.Na{~ao, el al.
(1998) also proposed a ineti~od tocreate summarization based on the i'ehlthms883between words.
They utilize GDA (GlobalDocument Annotation), a tag set that the docu-ment author inserts into the document and thatcontains linguistic information such as sentencestructures and reference infimnation.
Althot@athis method is similar to ours in some points, thestlmmaw consists of sentences and thus does nothave "at-a-glalme" capability.
Most of  all, theexpectation that every doctmlent is taggedlinguistically will not be fulfilled until specialeditors with automatic linguistic tagging becontepopular.ConclusionWe introduced the concept of  "at-a-glance"summary and showed an algorithm of phrase-representation SUlnmarization as a realization ofthe concept.
An experiment shows that thesummaries are effective for sifting IR results.We continue to fine-trine the prototype fortimber efficacy.AcknowledgementWe would like to thank our laboratory memberswho give us valuable suggestions and participatedin the experiment.ReferencesBougraev, t3.
and Kennedy, C. (1997): "Salience-basedContent Characterisation f Text Documents," Proc.Intelligent Scalable Text Summarization, pp.
2-9.Jing, H., Barzilay, R., McKeown, K. and Elhadad, M.(1998): "Summarization Evaluation Methods:Experiments and Analysis."
In Intelligent TextSummarization.
pp.
51-59.
AAAI Press.Kaplan, R. M. and Bresnan, J.
(1982): "'Lexical-Functional Grammar: A Forlnal System for Gram-matical Representation," in Bresnan, J.
(ed.)
TheMental Representation oJ" Gramnzatical Relalions,MIT Press.Mani, 1., House, D., Klein, G., ttirschman, L., Obrst,L., Firmin, T., Chizanowski, M., and Sundheim, B.
(1998): "'The 77PSTER SL/MM:tC T~:vt Summariza-tion Evaluation."
Technical P, eport MTR98W0000138, MITRE Technical Report.Mikami, M., Yamazaki, K., Masuyama, S. andNakagawa, S. (1998): "Summarization of NewsSentences for Closed Caption Generation," t'roc.llq>rksh~q) l)rogram The 4th Anmzal Meeting (71 Tim.-l.s'xociation .
/br Natural Language l)roce.ssiny, pp.14-21 (in Japanese).Miyauchi, T., Ol<a, M. and Ueda.
Y.
(1995):-Key-relation technology for text rett+ieval. ""
/'roe.
theSDAIR '95, pp.
469-483.Nagao, K. and tlasida, K. (1998): "Autotnatic TextSununarization P, ased on the Global DoctnnentAnnotation," Proc.
COLING-g& pp.
917-92 I.Oka, M. and Ueda, Y.
(2000): "'Evaluation of Phrase-representation Summarization based on InformationRetrieval Task," Proc.
ANLP, NAACL 2000 Work-shop o,'z ,4zzlomatic Sumnzarization, pp.
59 -- 68.Pollard, C. and Sag, 1.
A.
(1994): ttead-Driven t'hraseStrltctm'e Grammar, The University of ChicagoPress.Salton, G. (1989): :tulomalic 7Z, x/ l'rocessing: The7)'an.~/brmation, A alysis, and Retrieval of InJbrma-tion by Compttter, Addison-Wesley.Wakao, "F., Ehara, T. and Shirai, K. (1998): "Auto?matic Summarization for Closed Caption for TVNews," Proc.
Workshop Program The 4t\]l AnnualMeeting (?/ The Association for Natural La~NuageProcessing, 7-13 (in Japanese).Zechner, K. (1996): "'Fast Generation of Abstractsfrom General Domain Text Corpora by ExtractingRelevant Sentences."
l'roc.
COLING-96, pp.
986.,,989.884
