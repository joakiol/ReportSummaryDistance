Rea l -T ime Spoken Language Translat ionUsing Assoc iat ive  ProcessorsKozo Oi, Eiichiro Sumita, Osamu Furuse, Hitoshi Iida and Tetsuya Higuchi~ATR Interpreting Telecommunications Research Laboratories2-2 Hikaridai, Seika, Souraku, Kyoto 619-02, JAPAN{ o i, sumit a, furus e, i ida} @it i. atr.
co. j p~Electrotechnical L boratory1-1-4 Umezono, Tsukuba, Ibaraki 305, Japanhiguchi?et i. go.
jpAbstractThis paper proposes a model using associativeprocessors (APs) for real-time spoken languagetranslation.
Spoken language translation re-quires (1) an accurate translation and (2) a real-time response.
We have already proposed amodel, TDMT (Transfer-Driven Machine Trans-lation), that translates a sentence utilizing ex-amples effectively and performs accurate struc-tural disambiguation and target word selection.This paper will concentrate on the second re-quirement.
In TDMT, example-retrieval (ER),i.e., retrieving examples most similar to an in-put expression, is the most dominant part of thetotal processing time.
Our study has concludedthat we only need to implement the ER for ex-pressions including a frequent word on APs.
Ex-perimental results how that the ER can be dras-tically speeded up.
Moreover, a study on com-munications between APs demonstrates the scal-ability against vocabulary size by extrapolation.Thus, our model, TDMT on APs, meets the vitalrequirements of spoken language translation.1 IntroductionResearch on speech translation that began in themid-1980s has been challenging.
Such research asresulted in several prototype systems (Morimoto etal., 1993; Kitano, 1991; Waibel et al, 1991).
Speechtranslation consists of a sequence of processes, i.e.,speech recognition, spoken language translation andspeech synthesis.
Each process must be acceleratedin order to achieve real-time response.
This pa-per focuses on the second process, spoken languagetranslation, which requires (1) an accurate trans-lation and (2) a real-time response.
We have al-ready proposed a model that utilizes examples andtranslates a sentence by combining pieces of trans-fer knowledge, i.e., target language xpressions thatcorrespond to source language xpressions that coverthe sentence jointly.
The model is called Transfer-Driven Machine Translation (TDMT) (Furuse andIida, 1992; Furuse et al, 1994) (see subsection 2.1 fordetails).
A prototype system of TDMT which trans-lates a Japanese spoken sentence into English, hasperformed accurate structural disambiguation andtarget word selection 1.This paper will focus on the second requirement.First, we will outline TDMT and analyze its com-putational cost.
Second, we will describe the con-figuration, experimental results and scalability ofTDMT on associative processors (APs).
Finally, wewill touch on related works and conclude.2 TDMT and its Cost Analysis2.1 Out l ine of  TDMTIn TDMT, transfer knowledge is the primary knowl-edge, which is described by an example-based frame-work (Nagao, 1984).
A piece of transfer knowledgedescribes the correspondence between source lan-guage expressions (SEs) and target language xpres-sions (TEs) as follows, to preserve the translationalequivalence:SE => TEl (Era, E12,...),:TE, (E,1, E,2,...)Eij indicates the j-th example of TEi.
For exam-ple, the transfer knowledge for source expression "Xno Y" is described as follows~:XnoY =>Y' o fX '  ((ronbun\[paper\],daimoku\[title\]),...),Y' for X'  ((hoteru\[hotel\],yoyaku\[reservation\]),...),Y' in X' ((Kyouto\[Kyoto\],kaigi\[conference\]),...),1The t rans la t ion  success  ra te  for 825 sentences  used aslearning data in a conference registration task, is about98%.
The translation success rate for 1,056 sentences,amassed through arbitary inputs in the same domain, isabout 71~.
The translation success rate increases as thenumber of examples increases.2X and Y are variables for Japanese words and X Iand Y~ are the English translations ofX and Y, respec-tively; "no" is an adnomina\] particle that corresponds tosuch English prepositions as "of," "for," "in," and so on.101TDMT utilizes the semantic distance calculationproposed by Sumita and Iida (Sumita and Iida,1992).
Let us suppose that an input, I, and eachexample, Eij, consist o f t  words as follows:I = ( I1 , ' " , I~)E~ = (E~I , .
.
.
,E~, )Then, the distance between I and Eij is calculatedas follows:d(I, Eij) = d((Xl , .
.
.
, I , ) , (E i j l , .
.
.
,E i j , ) )t= Z ?k=lThe semantic distance d(Ik, Eijk) between wordsis reduced to the distance between concepts in a the-saurus (see subsection 3.2 for details).
The weightWk is the degree to which the word influences theselection of the translation 3.The flow of selecting the most plausible TE is asfollows:(1) The distance from the input is calculated for allexamples.
(2) The example with the minimum distance fromthe input is chosen.
(3) The corresponding TE of the chosen example isextracted.Processes (1) and (2) are called ER (Example-Retrieval) hereafter.Now, we can explain the top-level TDMT algo-rithm:(a) Apply the transfer knowledge to an input sen-tence and produce possible source structures inwhich SEs of the transfer knowledge are com-bined.
(b) Transfer all SEs of the source structures to themost appropriate TEs by the processes (1)-(3)above, to produce the target structures.
(c) Select the most appropriate target structurefrom among all target structures on the basisof the total semantic distance.For example, the source structure of the followingJapanese sentence is represented by a combinationof SEs with forms such as (X no Y), (X ni Y), (Xde Y), (X ga Y) and so on:dainihan no annaisyo n|{ second version, particle, announcement, particle,kaigi de happyou-sareru ronbunconference, particle, be presented, paper,no daimoku ga notte-orimasuparticle, title, particle, be written }2.2 The  Analys is  of  Computat iona l  CostHere, we briefly investigate the TDMT processingtime on sequential machines.For 746 test sentences (average sentence length:about 10 words) comprising representative Japanese3In the TDMT prototype, Wk is 1/t.1--Rate(%)Other\ [ \ ]  processingtimeExample-, re t r ieva ltime0-2 2~4 4~6 6~88~1010 ~Translation time Iseconds~in sequential TDMT "Figure 1: Rates for ER time in sequential TDMTsentences 4 in a conference registration task, the av-erage translation time per sentence is about 3.53seconds in the TDMT prototype on a sequentialmachine (SPARCstation2).
ER is embedded as asubroutine call and is called many times during thetranslation of one sentence.
The average number ofER calls per sentence is about 9.5.
Figure 1 showsrates for the ER time and other processing time.The longer the total processing time, the higher therate for the ER time; the rate rises from about 43%to about 85%.
The average rate is 71%.
Thus, ER isthe most dominant part of the total processing time.In the ATR dialogue database (Ehara et al, 1990),which contains about 13,000 sentences for a confer-ence registration task, the average sentence length isabout 14 words.
We therefore assume in the remain-der of this subsection and subsection 3.5 that the av-erage sentence length of a Japanese spoken sentenceis 14 words, and use statistics for 14-word sentenceswhen calculating the times of a large-vocabularyTDMT system.
The expected translation time ofeach 14-word sentence is about 5.95 seconds, whichis much larger than the utterance time.
The ex-pected number of ER calls for each 14-word sen-tence is about 15.
The expected time and rate forER of the 14-word sentence are about 4.32 secondsand about 73%, respectively.Here, we will consider whether a large-vocabularyTDMT system can attain a real-time response.In the TDMT prototype, the vocabulary size andthe number of examples, N, are about 1,500 and12,500, respectively.
N depends on the vocab-ulary size.
The vocabulary size of the averagecommercially-available machine translation systemis about 100,000.
Thus, in the large-vocabulary s s-4We have 825 test sentences as described in footnote 1in section 1.
These sentences cover basic expressions thatare used in Japanese ability tests conducted by the gov-ernment and Japanese ducation courses used by manyschools for foreigners (Uratani et al, 1992).
The sen-tences were reviewed by Japanese linguists.
In the ex-periments in this paper, we used 746 sentences xcludingsentences translated by exact-match.102tern, N is about 830,000 (-~ 12,500 ?
100,000/1,500)in direct proportion to the vocabulary size.
For thesake of convenience, we assume N = 1,000,000.The ER time is nearly proportional to N due toprocess (1) described in subsection 2.1.
Therefore,the expected translation time of a 14-word sentencein the large-vocabulary s stem using a SPARCsta-tion2 (28.5 MIPS) is about 347.2 (=\[ER time\]+\[otherprocessing timeS\]=\[4.32 x 1,000,000/12,500\]+\[5.95 -4.32\]=345.6+1.63) seconds.
ER consumes 99.5% ofthe translation time.A 4,000 MIPS sequential machine will be avail-able in 10 years, since MIPS is increasing at a rateof about 35 % per year; we already have a 200MIPS machine (i.e.
DEC alpha/7000).
The trans-lation time of the large-vocabulary s stem with the4,000 MIPS machine is expected to be about 2.474(~_ 347.2 x 28.5/4,000) seconds.
Of the time, 2.462(_~ 345.6 x 28.5/4,000) seconds will be for ER.
There-fore, although the 1500-word TDMT prototype willrun quickly on the 4,000 MIPS machine, sequentialimplementation will not be scalable, in other words,the translation time will still be insufficient for real-time application.
Therefore, we have decided to uti-lize the parallelism of associative processors.Careful analysis of the computational cost in thesequential TDMT prototype has revealed that theER for the top 10 SEs (source language xpressions)accounts for nearly 96% of the entire ER time.
Theexpected number of ER calls for the top 10 SEs ofeach 14-word sentence is about 6.
Table 1 showsrates of the ER time against each SE in the trans-fer knowledge.
Function words, such as "wa", "no","o", "ni" and "ga", in the SEs are often used inJapanese sentences.
They are polysemous, thus,their translations are complicated.
For that rea-son, the number of examples associated with theseSEs is very large.
In sum, the computational costof retrieving examples including function words isproportional to the square of the frequency of thefunction words.
In an English-to-Japanese v rsionof TDMT, the number of examples associated withthe SEs, which include function words such as "by","to" and "of", is very large as well.With this rationale, we decided to parallelize ERfor the top 10 SEs of the Japanese-to-English trans-fer knowledge.Table 1: Rates of ER time against each SESEX wa YX no YX o YX ni Yx g.a YRate(%)25.2020.6019.6111.138.90Accumulative(%)25.2045.8065.4176.5485.445This time does not depend on N.3 TDMT Using Associat iveProcessors3.1 ER on Associative Processors (APs)As described in the previous ubsection, parallelizingER is inevitable but promising.
Preliminary experi-ments of ER on a massively parallel associative pro-cessor IXM2 (Higuchi et al, 1991a; Higuchi et al,1991b) have been successful (Sumita et al, 1993).The IXM2 is the first massively parallel associativeprocessor that clearly demonstrates the computingpower of a large Associative Memory (AM).
The AMnot only features torage operations but also logicaloperations uch as retrieving by content.
Parallelsearch and parallel write are particularly importantoperations.
The IXM2 consists of associative pro-cessors (APs) and communication processors.
EachAP has an AM of 4K words of 40 bits, plus an IMST801 Transputer (25 Mttz).3.2 Semant ic  D is tance  Ca lcu lat ion  on APsAs described in subsection 2.1, the semantic distancebetween words is reduced to the distance betweenconcepts in a thesaurus.
The distance between con-cepts is determined according to their positions inthe thesaurus hierarchy.
The distance varies from 0to 1.
When the thesaurus i (n + 1) layered, (k/n)is connected to the classes in the k-th layer from thebottom (0 _< k _~ n).
In Figure 2, n is 3, k is from0 to 3, and the distance d is 0/3 (--0), 1/3, 2/3 and3/3 (=1) from the bottom.The semantic distance is calculated based on thethesaurus code, which clearly represents the the-saurus hierarchy, as in Table 2, instead of travers-ing the hierarchy.
Our n is 3 and the width of eachlayer is 10.
Thus, each word is assigned a three-digit decimal code of the concept to which the wordcorresponds.Here, we briefly introduce the semantic distancecalculation on an AM (Associative Memory) refer-ring to Figure 3.
The input data is 344 which is theS"Wl " "W2" "W3" "W4""thesaurus rootFigure 2: Thesaurus (portion) and distance103Table 2: Semantic distance by thesaurus code.The input code and example code are CI =CI1CI2CI3, CE = CE1CE2CE3.Condition ExampleCIICI2CI3 = CEICE2CE3 347 , 347CI1CI2 = CEaCE2,CI3 # CE3 347 , 346CI1 = CEI, CA # CE2 347,337CI1 # CE~ 347, 247Dist.01/32/31Thesaurus codeI .
.
.
.
.
.
.
.
I (~ ' t~:  , \] Input dataddressuchiawasc\[ meeting \]i Markteisha / v\[ stopping \ ] / J  .
.
.
.
.
.
.
.
.
3 1 6kaigi / .
3 4 4 0 2 \[ conferen~ .
.
.
.
.
.
.
.
.
........ i i iJ i iAssociative MemoryFigure 3: Semantic distance calculation on an Asso-ciative Memorythesaurus code of the word "uchiawase\[meeting\]".Each code (316, 344) of the examples such as"teisha\[stopping\]", "kaigi\[conference\]", and so on isstored in each word of the AM.
The algorithm forsearching for examples whose distance from the in-put is 0, is as follows6:(I) Give a command that searches for the wordswhose three-digit code matches the input.
(Thesearch is performed on all words simultaneouslyand matched words are marked.
)(II) Get the addresses of the matched words one byone and add the distance, 0, to the variable thatcorresponds to each address.The search in process (I) is done only by the AMand causes the acceleration of ER.
Process (II) isdone by a transputer and is a sequential process.3.3 Conf igurat ion  of TDMT Using APsAccording to the performance analysis in subsection2.2, we have implemented the ER of the top 10 SEs.Figure 4 shows a TDMT configuration using APsin which the ER of the top 10 SEs are imple-mented.
The 10 APs (AP1,AP2," .
,AP10) andthe transputer (TP) directly connected to the hostmachine (SPARCstation2) are connected in a treeconfiguration 7.SAn algorithm that searches for examples whose dis-tance from the input is 1/3, 2/3 or 3/3, is similar.7The tree is 3-array because the transputer has fourconnectors.
The TDMT main program is described withLisp language and is executed on the host machine.
TheER routine is programmed with Occam2 language, whichis called by the main program and runs on the TP andTransputer~(TP) JFigure 4: Configuration of TDMT using 10 APsThe algorithm for ER in the TDMT using APs isas follows:(i) Get input data and send the input data fromthe host to TP.
(ii) Distribute the input data to all APs.
(iii) Each AP carries out ER, and gets the minimumdistance and the example number whose dis-tance is minimum.
(iv) Each AP and the TP receive the data from thelower APs (if they exist), merge them and theirown result, and send the merged result upward.With the configuration shown in Figure 4, westudied two different methods of storing examples.The two methods of storing examples are as follows:Homo- load ing  (HM)  Examples associated withone SE are stored in one AP.
That is, each APis loaded with examples of the same SE.Hetero- load ing (HT)  Examples associated withone SE are divided equally and stored in 10APs.
That is, each AP is loaded with exam-ples of 10 different SEs.3.4 Exper imenta l  Resul tsFigure 5 plots the speedup of ER for TDMT usingAPs over sequential TDMT, with the two methods.It can be seen that the speedup for the HT methodis greater than that for the HM method, partly be-cause the sequential part of ER is proportional to theexample number in question.
With the HT method,30 I I I | I I25-  HT \[\]20 ~m lO50 I I I I I I0-2 2-4 4-6 6-8 8-10 10-Translation time in sequential TDMT (seconds)Figure 5: Speedup of ER in TDMT using APs oversequential TDMTon transputers in the APs.104the average speedup is about 16.4 (=\[the average timeper sentence in the sequential TDMT\]/\[the average timeper sentence in the HT method\]~ 2489.7/152.2(msec.
)).For the 14-word sentences, the average speedup isabout 20.8 (2 4324.7/208.0(msec.))
and the ER timefor the top 10 SEs is about 85.4 milliseconds out ofthe total 208.0 milliseconds.Figure 6 shows a screen giving a comparison be-tween TDMT using APs and sequential TDMT.FIle(F) Translate(T) Display(D)Sentence Number \]....8 .......Input Sentence : :~ J~"~'~$ ~ U '~T~ ~,Trat~lation Result P ~ ~ .
~  th the ~.!.strat!gn.
for~~ r a l JSentence ~mber i 20Input Sentence \ [~: : !~ 'C '~ '~ ......................................................................................................................... ii'iiiii"iiiiiiii"Translation Resu l t~ .
.
.
.
.
.
.Figure 6: A comparison of TDMT using APs and se-quential TDMT - -  This is a snapshot of a race betweentwo machines.
The sentence numbers and run times cor-respond to sentences that have been translated.
Theaverage times cover all sentences that have been trans-lated.3.5 Sealabi l i tyIn this subsection, we consider the scalability ofTDMT using APs in the HT method.
Here, wewill estimate the ER time using 1,000,000 exampleswhich are necessary for a large-vocabulary TDMTsystem (see subsection 2.2).Assuming that the number of examples in eachAP is the same as that in the experiment, 800 (=1,000,000/12,500) APs are needed to store 1,000,000examples.
Figure 7 shows 800 APs in a tree struc-ture (~L=I 3 ~ _> 800; L(minimum)=6 layers).
In theremainder of this subsection, we will use the statis-tics (time, etc.)
for the 14-word s sentences.The translation time is divided into the ER timeon APs and the processing time on the host machine.The former is divided into the computing time oneach AP and the communication time between APs.The ER time on APs in the experiment is about85.4 milliseconds as described in subsection 3.4.
Thecomputing time per sentence on each AP is the sameas that in the experiment and is approximately 84.1milliseconds out of the 85.4 milliseconds.
The com-munication time between APs is vital and increasesSThis is the average sentence l ngth in the ATR dia-logue database.
See subsection 2.2.Transputer] ~machinel ~ 0 : APJ I ~_ (Associative ~ ~ ~"~rocessor)/iViV P'../iVi Vi"../i Vi",.Figure 7: Configuration of large-vocabulary TDMTusing 800 APsas the number of APs increases.
There are two kindsof communication processes: distribution of inputdata 9 and collection of the resulting data of ER 1?.The input data distribution time is the sum ofdistribution times TP--* AP1, AP1 --* AP2, .
. '
,AP4--~AP5 and APs--*AP6, that is, 6 multiplied bythe distribution time between two APs that are di-rectly connected (see Figure 7), because a transputercan send the data to the other transputers directlyconnected in parallel (e.g., APs--*APs, AP~AP7,APs--+APs).
The average number of ER calls isabout 6 and the average distribution time betweendirectly-connected APs is about 0.05 milliseconds.Therefore, the total input data distribution time persentence in the configuration of Figure 7 is nearly 1.8(= 0.05 x 6 ?
6) milliseconds.The time required to collect the resulting datais the sum of the processing times in process (iv),which is explained in subsection 3.3, at the TP,APt, "- .
,AP4 and APs, illustrated in Figure 7.
Ittakes about 0.04 milliseconds, on average, for eachAP to receive the resulting data from the lowerAPs and it takes about 0.02 milliseconds, on av-erage, for the AP to merge the minimum distanceand the example numbers.
Therefore, it is ex-pected that the total collection time is about 2.2(= (0.04 + 0.02) ?
6 ?
6) milliseconds.Thus, the total communication time is about 4.0(= 1.8 + 2.2) milliseconds.
Consequently, the pro-cessing time on APs is about 88.1 (= 84.1 +4.0) mil-liseconds.
This is 3,920 (2 345.6/0.0881) times fasterthan the SPARCstation2 n.  It is clear then that thecommunication has little impact on the scalabilitybecause it is controlled by the tree depth and smallcoefficient.Therefore, the TDMT using APs becomes morescalable as the number of examples increases andcan attain a real-time response.9Process (ii) described in subsection 3.3.1?Process (iv) described in subsection 3.3.//See the data described in subsection 2.2.1054 Re la ted  worksUp to now, some systems using a massively par-allel machine in the field of natural anguage pro-cessing, such as a parsing system (Kitano andHiguchi, 1991b) and translation systems, e.g., Dm-SNAP (Kitano et al, 1991), ASTRAL (Kitano andHiguchi, 1991a), MBT3n (Sato, 1993), have beenproposed.
They have demonstrated good perfor-mance; nonetheless, they differ from our proposal.For the first three systems, their domain is muchsmaller than our domain and they do not performstructural disambiguation or target word selectionbased on the semantic distance between an inputexpression and each example.
For the last system,it translates technical terms i.e.
noun phrases, butnot sentences.5 Conc lus ionThis paper has proposed TDMT (Transfer-DrivenMachine Translation) on APs (Associative Proces-sors) for real-time spoken language translation.
InTDMT, a sentence is translated by combining piecesof transfer knowledge that are associated with ex-amples, i.e., source word sequences.
We showed thatthe ER (example-retrieval) for source xpressions in-cluding a frequent word, such as a function word,are predominant and are drastically speeded up us-ing APs.
That the TDMT using APs is scalableagainst vocabulary size has also been confirmed byextrapolation, i.e., a 10-AP sustained performanceto an 800-AP expected performance, through analy-sis on communications between APs.
Consequently,the TDMT can achieve real-time performance evenwith a large-vocabulary system.
In addition, as ourprevious papers have shown, the TDMT achievesaccurate structural disambiguation a d target wordselection.
Thus, our model, TDMT on APs, meetsthe vital requirements for real-time spoken languagetranslation.ReferencesTerumasa Ehara, Kentaro Ogura, and Tsuyoshi Mo-rimoto.
1990.
ATR Dialogue Database.
In Proc.of ICSLP'90, pages 1093-1096, November.Osamu Furuse and Hitoshi Iida.
1992.
CooperationBetween Transfer and Analysis in Example-BasedFramework.
In Proc.
of COLING'92, pages 645-651, July.Osamu Furuse, Eiichiro Sumita, and tIitoshi Iida.1994.
Transfer Driven Machine Translation Uti-lizing Empirical Knowledge.
Transactions of In-formation Processing Society of Japan, 35(3):414-425, March.Tetsuya Higuchi, Tatsumi Furuya, Kenichi Handa,Naoto Takahashi, I-Iiroyasu Nishiyama, and AkioKokubu.
1991a.
IXM2 : A Parallel AssociativeProcessor.
In Proc.
of the 18th International Sym-posium on Computer Architecture, May.Tetsuya Higuchi, Hiroaki Kitano, Tatsumi Furuya,Ken-ichi I-Ianda, Naoto Takahashi, and AkioKokubu.
1991b.
IXM2 : A Parallel AssociativeProcessor for Knowledge Processing.
In Proc.
ofAAAI'91, pages 296-303, July.ttiroaki Kitano and Tetsuya Higuchi.
1991a.
HighPerformance Memory-Based Translation on IXM2Massively Parallel Associative Memory Processor.In Proc.
of AAAI'91, pages 149-154, July.Hiroaki Kitano and Tetsuya Higuchi.
1991b.
Mas-sively Parallel Memory-Based Parsing.
In Proc.of IJCAI'91, pages 918-924.Hiroaki Kitano, Dan Moldovan, and Seungho Cha.1991.
High Performance Natural Language Pro-cessing on Semantic Network Array Processor.
InProc.
of IJCAl'91, pages 911-917.Hiroaki Kitano.
1991.
?DM-Dialog: An Experi-mental Speech-to-Speech Dialog Translation Sys-tem.
IEEE Computer, 24(6):36-50, June.Tsuyoshi Morimoto, Toshiyuki Takezawa, Fumi-hiro Yato, Shigeki Sagayama, Toshihisa Tashiro,Masaaki Nagata, and Akira Kurematsu.
1993.ATR's Speech Translation System: ASURA.
InProc.
of EUROSPEECH'93, pages 1291-1294,September.Makoto Nagao.
1984.
A Framework of a Mechani-cal Translation between Japanese and English byAnalogy Principle.
In A. Elithorn and R. Banerji,editors, Artificial and Human Intelligence, pages173-180.
North-Holland.Satoshi Sato.
1993.
MIMD Implementation ofMBT3.
In Proc.
of the Second InternationalWorkshop on Parallel Processing for Artificial In-telligence, pages 28-35.
IJCAI'93, August.Eiichiro Sumita and Hitoshi Iida.
1992.
Example-Based Transfer of Japanese Adnominal Particlesinto English.
IEICE TRANS.
INF.
8J SYST.,E75-D(4):585-594, April.Eiichiro Sumita, Kozo Oi, Osamu Furuse, HitoshiIida, Tetsuya Higuchi, Naoto Takahashi, and I-Ii-roaki Kitano.
1993.
Example-Based MachineTranslation on Massively Parallel Processors.
InProc.
of IJCAI'93, pages 1283-1288, August.Noriyoshi Uratani, Masami Suzuki, Masaaki Na-gata, Tsuyoshi Morimoto, Yukinori Takubo,Toshiyuki Sadanobu, and Hajime Narita.
1992.
AFunction Evaluation Method for Analysis Systemof Goal-Directed Dialogue.
In IEICE TechnicalReport, NLC92-10, July.Alex Waibel, Ajay N. Jain, Arthur E. McNair, Hi-roaki Saito, Alexander G. Hauptmann, and JoeTebelskis.
1991.
JANUS: A Speech-to-speechTranslation Using Connectionist and SymbolicProcessing Strategies.
In Proc.
of ICASSP'91,pages 793-796, May.106
