Facilitating Treebank Annotation Using a Statistical ParserFu-Dong Chiou, David Chiang, and Martha PalmerDept of Computer and Information ScienceUniversity of Pennsylvania200 S 33rd Street, Philadelphia, PA 19104-6389{chioufd,dchiang,mpalmer}@linc.cis.upenn.edu1.
INTRODUCTIONCorpora of phrase-structure-annotated text, or treebanks, are use-ful for supervised training of statistical models for natural languageprocessing, as well as for corpus linguistics.
Their primary draw-back, however, is that they are very time-consuming to produce.
Toalleviate this problem, the standard approach is to make two passesover the text: first, parse the text automatically, then correct theparser output by hand.In this paper we explore three questions:?
How much does an automatic first pass speed up annotation??
Does this automatic first pass affect the reliability of the finalproduct??
What kind of parser is best suited for such an automatic firstpass?We investigate these questions by an experiment to augment thePenn Chinese Treebank [15] using a statistical parser developedby Chiang [3] for English.
This experiment differs from previousefforts in two ways: first, we quantify the increase in annotationspeed provided by the automatic first pass (70?100%); second, weuse a parser developed on one language to augment a corpus in anunrelated language.2.
THE PARSERThe parsing model described by Chiang [3] is based on stochas-tic TAG [13, 14].
In this model a parse tree is built up out of treefragments (called elementary trees), each of which contains exactlyone lexical item (its anchor).In the variant of TAG used here, there are three kinds of el-ementary trees: initial, (predicative) auxiliary, and modifier, andthree corresponding composition operations: substitution, adjunc-tion, and sister-adjunction.
Figure 1 illustrates all three of these op-erations.
The first two come from standard TAG [8]; the third isborrowed from D-tree grammar [11].In a stochastic TAG derivation, each elementary tree is gener-ated with a certain probability which depends on the elementarytree itself as well as the node it gets attached to.
Since every tree is.lexicalized, each of these probabilities involves a bilexical depen-dency, as in many recent statistical parsing models [9, 2, 4].Since the number of parameters of a stochastic TAG is quite high,we do two things to make parameter estimation easier.
First, wegenerate an elementary tree in two steps: the unlexicalized tree,then a lexical anchor.
Second, we smooth the probability estimatesof these two steps by backing off to reduced contexts.When trained on about 80,000 words of the Penn Chinese Tree-bank and tested on about 10,000 words of unseen text, this modelobtains 73.9% labeled precision and 72.2% labeled recall [1].3.
METHODOLOGYFor the present experiment the parsing model was trained onthe entire treebank (99,720 words).
We then prepared a new setof 20,202 segmented, POS-tagged words of Xinhua newswire text,which was blindly divided into 3 sets of equal size (?10 words).Each set was then annotated in two or three passes, as summa-rized by the following table:Set Pass 1 Pass 2 Pass 31 ?
Annotator A Annotators A&B2 parser Annotator A Annotators A&B3 revised parser Annotator A Annotators A&BHere ?Annotators A&B?
means that Annotator B checked thework of Annotator A, then for each point of disagreement, both an-notators worked together to arrive at a consensus structure.
?Parser?is Chiang?s parser, adapted to parse Chinese text as described byBikel and Chiang [1].
?Revised parser?
is the same parser with additional modificationssuggested by Annotator A after correcting Set 2.
These revisionsprimarily resulted from a difference between the artificial evalua-tion metric used by Bikel and Chiang [1] and this real-world task.The metric used earlier, following common practice, did not takepunctuation or empty elements into account, whereas the presenttask ideally requires that they be present and correctly placed.
Thusfollowing changes were made:?
The parser was originally trained on data with the punctua-tion marks moved, and did not bother to move the punctua-tion marks back.
For Set 3 we simply removed the prepro-cessing phase which moved the punctuation marks.?
Similarly, the parser was trained on data which had all emptyelements removed.
In this case we simply applied a rule-based postprocessor which inserted null relative pronouns.?
Finally, the parser often produced an NP (or VP) which dom-inated only a single NP (respectively, VP), whereas such aNPNNPJohnSNP?
VPVBleaveVPMDshouldVP?NPNNtomorrow(1)(2)() (?
)?2112?2,1derivation treeSNPNNPJohnVPMDshouldVPVBleaveNPNNtomorrowderived treeFigure 1: Grammar and derivation for ?John should leave tomorrow.
?1and2are initial trees,  is a (predicative) auxiliary tree,?
is a modifier tree.structure is not specified by the bracketing guidelines.
There-fore we applied another rule-based postprocessor to removethese nodes.
(This modification would have helped the orig-inal evaluation as well.
)In short, none of the modifications required major changes to theparser, but they did improve annotation speed significantly, as wewill see below.4.
RESULTSThe annotation times and rates for Pass 2 are as follows:Set Pass 1 Time (Pass 2) Rate (Pass 2)(hours:min) (words/hour)1 ?
28:01 2402 parser 16:21 4123 revised parser 14:06 478The rate increase for Set 2 over Set 1 was about 70%; for Set 3 overSet 1, about double.
Thus the time saved by the use of an automaticfirst pass is substantial.Assessing the reliability of the final product is somewhat trickier.Set Pass 1 Accuracy (Pass 1) Accuracy (Pass 2)LP LR LP LR1 ?
?
?
99.84 99.762 parser 76.73 75.36 99.76 99.653 revised parser 82.87 81.42 99.81 99.26where LP stands for labeled precision and LR stands for labeledrecall.
The third column reports the accuracy of Pass 1 (the parser)using the results of Pass 2 (Annotator A) as a gold standard.
Thefourth column reports the accuracy of Pass 2 (Annotator A) usingthe results of Pass 3 (Annotators A&B) as a gold standard.We note several points:?
There is no indication that the addition of an automatic firstpass affected the accuracy of Pass 2.
On the other hand, thenear-perfect reported accuracy of Pass 2 suggests that in facteach pass biased subsequent passes substantially.
We needa more objective measure of reliability, which we leave forfuture experiments.?
The parser revisions significantly improved the accuracy ofthe parser with respect to the present metric (which is sensi-tive to punctuation and empty elements).
On Set 2 the revisedparser obtained 78.98/77.39% labeled precision/recall, an er-ror reduction of about 9%.?
Not surprisingly, errors due to large-scale structural ambi-guities were the most time-consuming to correct by hand.
Totake an extreme example, one parse produced by the parser isshown in Figure 2.
It often matches the correct parse (shownin Figure 3) at the lowest levels but the large-scale errors re-quire the annotator to make many corrections.5.
DISCUSSIONIn summary, although Chiang?s parser was not specifically de-signed for Chinese, and trained on a moderate amount of data (lessthan 100,000 words), the parses it provided were reliable enoughthat the annotation rate was effectively doubled.Now we turn to our third question: what kind of parser is mostsuitable for an automatic first pass?
Marcus et al [10] describe theuse of the deterministic parser Fidditch [6] as an automatic firstpass for the Penn (English) Treebank.
They cite two features of thisparser as strengths:1.
It only produces a single parse per sentence, so that the an-notator does not have to search through many parses.2.
It produces reliable partial parses, and leaves uncertain struc-tures unspecified.The Penn-Helsinki Parsed Corpus of Middle English was con-structed using a statistical parser developed by Collins [4] as anautomatic first pass.
This parser, as well as Chiang?s, retains thefirst advantage but not the second.
However, we suggest two waysa statistical parser might be used to speed annotation further:First, the parser can be made more useful to the annotator.
Astatistical parser typically produces a single parse, but can also(with little additional computation) produce multiple parses.
Rat-naparkhi [12] has found that choosing (by oracle) the best parse outof the 20 highest-ranked parses boosts labeled recall and precision(IP (NP (DP (DTYJ)) these(NP (NN?))) businesses(VP (VP (ADVP (AD?))
also(VP (BA?)
BA(IP (NP (QP (CD?
?y) 36,000(CLP (M1))) item(CP (WHNP (-NONE- *OP*))(CP (IP (VP (VVp?)
possess(NP (NN?)
to be one?s own master(NN#) knowledge(NN?Y)))) property rights(DEC{))) DE(NP (NNb))) technologies(VP (PP (P5) toward(NP (DP (DT ??))
other(NP (NN ?) businesses(PU)(NN ??))))
organizations(VP (VV?#)))))) transfer(CCZ) and(VP (VVj?)
spread(IP (VP (PU?
)(VP (VV) create(NP (NNB?))
income(QP (CD???
?7) 4.43 billion(CLP (M?))))))))
RMB(PU ))Figure 2: Parser output.
Translation: ?These businesses also transfer and spread the intellectual property rights of 36,000 technolo-gies to other businesses and organizations, creating an income of 4.43 billion RMB.?
(IP (NP-SBJ (DP (DTYJ)) these(NP (NN?))) businesses(VP (ADVP (AD ?))
also(VP (VP (BA?)
BA(IP-OBJ (NP-SBJ (QP (CD?
?y) 36,000(CLP (M1))) item(CP (WHNP-1 (-NONE- *OP*))(CP (IP (NP-SBJ (-NONE- *T*-1))(VP (VVp?)
possess(NP-OBJ (NN ?)
to be one?s own master(NN #) knowledge(NN ?Y)))) property rights(DEC{))) DE(NP (NNb))) technologies(VP (PP-DIR (P5) toward(NP (DP (DT??))
other(NP (NN?) businesses(PU)(NN??))))
organizations(VP (VP (VV ?#)) transfer(CC Z) and(VP (VV j?))))))
spread(PU?
)(VP (VV) create(NP-OBJ (NN B?))
income(QP-EXT (CD???
?7) 4.43 billion(CLP (M?))))))
RMB(PU ))Figure 3: Corrected parse for sentence of Figure 2.from about 87% to about 93%.
This suggests that if the annotatorhad access to several of the highest-ranked parses, he or she couldsave time by choosing the parse with the best gross structure andmaking small-scale corrections.Would such a change defeat the first advantage above by forcingthe annotator to search through multiple parses?
No, because theparses produced by a statistical parser are ranked.
The additionallower-ranked parses can only be of benefit to the annotator.
Indeed,because the chart contains information about the certainty of eachsubparse, a statistical parser might regain the second advantage aswell, provided this information can be suitably presented.Second, the annotator can be made more useful to the parser bymeans of active learning or sample selection [5, 7].
(We are as-suming now that the parser and annotator will take turns in a train-parse-correct cycle, as opposed to a simple two-pass scheme.)
Theidea behind sample selection is that some sentences are more in-formative for training a statistical model than others; therefore, ifwe have some way of automatically guessing which sentences aremore informative, these sentences are the ones we should hand-correct first.
Thus the parser?s accuracy will increase more quickly,potentially requiring the annotator to make fewer corrections over-all.6.
ACKNOWLEDGMENTSWe would like to thank Fei Xia, Mitch Marcus, Aravind Joshi,Mary Ellen Okurowski and John Kovarik for their helpful com-ments on the design of the evaluation, Beth Randall for her postpro-cessing and error-checking code, and Nianwen Xue for serving as?Annotator B.?
This research was funded by DARPA N66001-00-1-8915, DOD MDA904-97-C-0307, and NSF SBR-89-20230-15.7.
REFERENCES[1] Daniel M. Bikel and David Chiang.
Two statistical parsingmodels applied to the Chinese Treebank.
In Proceedings ofthe Second Chinese Language Processing Workshop, pages1?6, 2000.
[2] Eugene Charniak.
Statistical parsing with a context-freegrammar and word statistics.
In Proceedings of theFourteenth National Conference on Artificial Intelligence(AAAI-97), pages 598?603.
AAAI Press/MIT Press, 1997.
[3] David Chiang.
Statistical parsing with anautomatically-extracted tree adjoining grammar.
InProceedings of the 38th Annual Meeting of the Assocationfor Computational Linguistics, pages 456?463, Hong Kong,2000.
[4] Michael Collins.
Three generative lexicalised models forstatistical parsing.
In Proceedings of the 35th AnnualMeeting of the Assocation for Computational Linguistics(ACL-EACL ?97), pages 16?23, Madrid, 1997.
[5] Ido Dagan and Sean P. Engelson.
Committee-based samplingfor training probabilistic classifiers.
In Proceedings of theTwelfth International Conference on Machine Learning,pages 150?157.
Morgan Kaufmann, 1995.
[6] Donald Hindle.
Acquiring disambiguation rules from text.
InProceedings of the 27th Annual Meeting of the Associationfor Computational Linguistics, 1989.
[7] Rebecca Hwa.
Sample selection for statistical grammarinduction.
In Proceedings of EMNLP/VLC-2000, pages45?52, Hong Kong, 2000.
[8] Aravind K. Joshi and Yves Schabes.
Tree-adjoininggrammars.
In Grzegorz Rosenberg and Arto Salomaa,editors, Handbook of Formal Languages and Automata,volume 3, pages 69?124.
Springer-Verlag, Heidelberg, 1997.
[9] David M. Magerman.
Statistical decision-tree models forparsing.
In Proceedings of the 33rd Annual Meeting of theAssocation for Computational Linguistics, pages 276?283,Cambridge, MA, 1995.
[10] Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
Building a large annotated corpus ofEnglish: the Penn Treebank.
Computational Linguistics,19:313?330, 1993.
[11] Owen Rambow, K. Vijay-Shanker, and David Weir.
D-treegrammars.
In Proceedings of the 33rd Annual Meeting of theAssocation for Computational Linguistics, pages 151?158,Cambridge, MA, 1995.
[12] Adwait Ratnaparkhi.
Maximum entropy models for naturallanguage ambiguity resolution.
PhD thesis, University ofPennsylvania, 1998.
[13] Philip Resnik.
Probabilistic tree-adjoining grammar as aframework for statistical natural language processing.
InProceedings of the Fourteenth International Conference onComputational Linguistics (COLING-92), pages 418?424,Nantes, 1992.
[14] Yves Schabes.
Stochastic lexicalized tree-adjoininggrammars.
In Proceedings of the Fourteenth InternationalConference on Computational Linguistics (COLING-92),pages 426?432, Nantes, 1992.
[15] Fei Xia, Martha Palmer, Nianwen Xue, Mary EllenOkurowski, John Kovarik, Fu-Dong Chiou, Shizhe Huang,Tony Kroch, and Mitch Marcus.
Developing guidelines andensuring consistency for Chinese text annotation.
InProceedings of the Second International Conference onLanguage Resources and Evaluation (LREC-2000), Athens,Greece, 2000.
