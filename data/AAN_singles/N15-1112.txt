Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1055?1065,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsSocially-Informed Timeline Generation for Complex EventsLu Wang Claire Cardie Galen MarchettiDepartment of Computer ScienceCornell UniversityIthaca, NY 14853{luwang, cardie}@cs.cornell.edu gjm97@cornell.eduAbstractExisting timeline generation systems for com-plex events consider only information fromtraditional media, ignoring the rich social con-text provided by user-generated content thatreveals representative public interests or in-sightful opinions.
We instead aim to gen-erate socially-informed timelines that con-tain both news article summaries and selecteduser comments.
We present an optimizationframework designed to balance topical cohe-sion between the article and comment sum-maries along with their informativeness andcoverage of the event.
Automatic evaluationson real-world datasets that cover four com-plex events show that our system producesmore informative timelines than state-of-the-art systems.
In human evaluation, the asso-ciated comment summaries are furthermorerated more insightful than editor?s picks andcomments ranked highly by users.1 IntroductionSocial media sites on the Internet provide increas-ingly more, and increasingly popular, means forpeople to voice their opinions on trending events.Traditional news media ?
the New York Times andCNN, for example ?
now provide online mecha-nisms that allow and encourage readers to share re-actions, opinions, and personal experiences relevantto a news story.
For complex emerging events, inparticular, user comments can provide relevant, in-teresting and insightful information beyond the factsreported in the news.
But their large volume andtremendous variation in quality make it impossible* Comment A: The ?Crimean Parliament?, headed by an ethnicRussian separatist who waselected leader of parliamentAFTER pro-Russian armed forcesoccupied the parliamentary chambers, has voted for Crimea tobe annexed into Russia?
* Comment B: Does the West andUS have a policy at all?
The Obama administration haswarned of ?increasingly harshsanctions?, but it is unlikely thatEurope will comply?
* Comment C: Sanctions areeffective and if done in unisonwith the EU?- Crimeans vote in a referendum to rejoin Russia or return to its status under the 1992constitution.March 16th, 2014- The Crimean parliament officially declared independence and requested fullaccession to the Russian Federation.- Obama declared sanctions on Russianofficials considered responsible for the crisis.- The leader of the pro-Russian organization ?Youth Unity?
was arrested.- President Obama warned Vladimir Putin that further provocations by Russia couldisolate and diminish its influence.- One pro-Russian soldier was killed in theSimferopol incident.March 17th, 2014March 18th, 2014?
summaries for other dates ?Figure 1: A snippet of the event timeline on Ukraine Cri-sis is displayed on the left.
On the right, we display a setof representative comments addressing the article sum-mary of March 17th.
Comment A (underlined) brings aperspective on ?Crimean parliament passes declaration ofindependence?
(the article sentence is also underlined onthe left).
Comments B and C focus on Obama?s sanctionson Ukrainian and Russian officials.
Sentences linked byedges belong to the same event thread, which is centeredon the entities with the same color.for readers to efficiently digest the user-generatedcontent, much less integrate it with reported factsfrom the dozens or hundreds of news reports pro-duced on the event each day.In this work, we present a socially-informed time-line generation system that jointly generates a newsarticle summary and a user comment summary foreach day of an ongoing complex event.
A sample(gold standard) timeline snippet for Ukraine Crisisis shown in Figure 1.
The event timeline is on theleft; the comment summary for March 17this on theright.1055While generating timelines from news articles andsummarizing user comments have been studied asseparate problems (Yan et al, 2011; Ma et al, 2012),their joint summarization for timeline generationraises new challenges.
Firstly, there should be a tightconnection between the article and comment por-tion of the timeline.
By definition, users commenton socially relevant events.
So the important part ofarticles and insightful comments should both coverthese events.
Moreover, good reading experience re-quires that the article summary and comment sum-mary demonstrate evident connectivity.
For exam-ple, Comment C in Figure 1 (?Sanctions are effec-tive and if done in unison with the EU?)
is obscurewithout knowing the context that ?sanctions are im-posed by U.S?.
Simply combining the outputs froma timeline generation system and a comment sum-marization system may lead to timelines that lackcohesion.
On the other hand, articles and commentsare from intrinsically different genres of text: arti-cles emphasize facts and are written in a professionalstyle; comments reflect opinions in a less formalway.
Thus, it could be difficult to recognize the con-nections between articles and comments.
Finally, itis also challenging to enforce continuity in timelineswith many entities and events.To address the challenges mentioned above, weformulate the timeline generation task as an opti-mization problem, where we maximize topic cohe-sion between the article and comment summarieswhile preserving their ability to reflect importantconcepts and subevents, adequate coverage of men-tioned topics, and continuity of the timeline as it isupdated with new material each day.
We design anovel alternating optimizing algorithm that allowsthe generation of a high quality article summary andcomment summary via mutual reinforcement.
Wedemonstrate the effectiveness of our algorithm onfour disparate complex event datasets collected overmonths from the New York Times, CNN, and BBC.Automatic evaluation using ROUGE (Lin and Hovy,2003) and gold standard timelines indicates that oursystem can effectively leverage user comments tooutperform state-of-the-art approaches on timelinegeneration.
In a human evaluation via Amazon Me-chanical Turk, the comment summaries generatedby our method were selected as the best in termsof informativeness and insightfulness in 66.7% and51.7% of the evaluations (vs. 26.7% and 30.0% forrandomly selected editor?s-picks).Especially, our optimization framework relies ontwo scoring functions that estimate the importanceof including individual article sentences and usercomments in the timeline.
Based on the observa-tion that entities or events frequently discussed inthe user comments can help with identify summary-worthy content, we show that the scoring functionscan be learned jointly by utilizing graph-based reg-ularization.
Experiments show that our joint learn-ing model outperforms state-of-the-art ranking algo-rithms and other joint learning based methods whenevaluated on sentence ranking and comment rank-ing.
For example, we achieve an NDCG@3 of0.88 on the Ukraine crisis dataset, compared to 0.77from Yang et al (2011) which also conducts jointlearning between articles and social context usingfactor graphs.Finally, to encourage continuity in the gener-ated timeline, we propose an entity-centered eventthreading algorithm.
Human evaluation demon-strates that users who read timelines with eventthreads write more informative answers than userswho do not see the threads while answering the samequestions.
This implies that our system constructedthreads can help users better navigate the timelinesand collect relevant information in a short time.For the rest of the paper, we first describe datacollection (Section 2).
We then introduce thejoint learning model for importance prediction (Sec-tion 3).
The full timeline generation system is pre-sented in Section 4, which is followed by evaluations(Section 5).
Related work and conclusion are in Sec-tions 6 and 7.2 Data Collection and PreprocessingWe crawled news articles from New York Times(NYT), CNN, and BBC on four trending events: themissing Malaysia Airlines Flight MH370 (MH370),the political unrest in Ukraine (Ukraine), the Israel-Gaza conflict (Israel-Gaza), and the NSA surveil-lance leaks (NSA).
For each event, we select a setof key words (usually entities?
name), which areused to filter out irrelevant articles.
We collect com-ments for NYT articles through NYT communityAPI, and comments for CNN articles via Disqus1056API.1NYT comments come with information onwhether a comment is an editor?s-pick.
The statis-tics on the four datasets are displayed in Table 1.2Time Span # Articles # CommentsMH370 03/08 - 06/30 955 406,646Ukraine 03/08 - 06/30 3,779 646,961Israel-Gaza 07/20 - 09/30 909 322,244NSA 03/23 - 06/30 145 60,481Table 1: Statistics on the four event datasets.We extract parse trees, dependency trees, andcoreference resolution results of articles and com-ments with Stanford CoreNLP (Manning et al,2014).
Sentences in articles are labeled with times-tamps using SUTime (Chang and Manning, 2012).We also collect all articles with comments fromNYT in 2013 (henceforth NYT2013) to form atraining set for learning importance scoring func-tions on articles sentences and comments (see Sec-tion 3).
NYT2013 contains 3, 863 articles and833, 032 comments.3 Joint Learning for Importance ScoringWe first introduce a joint learning method that usesgraph-based regularization to simultaneously learntwo functions ?
a SENTENCE scorer and a COM-MENT scorer ?
that predict the importance of in-cluding an individual news article sentence or a par-ticular user comment in the timeline.We train the model on the aforementionedNYT2013 dataset, where 20% of the articles andtheir comments are reserved for parameter tuning.Formally, the training data consists of a set of ar-ticles D = {di}|D|?1i=0.
Each article dicontains aset of sentences xsdi= {xsdi,j}|sdi|?1j=0and a set ofassociated comments xcdi= {xcdi,k}|cdi|?1k=0, where|sdi| and |cdi| are the numbers of sentences and com-ments for di.
For simplicity, we use xsor xcto de-note a sentence or a comment wherever there is noambiguity.In addition, each article has a human-written ab-stract.
We use the ROUGE-2 (Lin and Hovy, 2003)score of each sentence computed against the associ-ated abstract as its gold-standard importance score.1BBC comment volume is low, so we do not collect it.2The datasets are available at http://www.cs.cornell.edu/?luwang/data.html.Each comment is assigned a gold-standard value of1.0 if it is an editor?s pick, or 0.0 otherwise.The SENTENCE and COMMENT scorers rely ontwo classifiers, each designed to handle the specialcharacteristics of news and user comments, respec-tively; and a graph-based regularizing constraint thatencourages similarity between selected sentencesand comments.
We describe each component below.Article SENTENCE Importance.
Each sentencexsin a news article is represented as a k-dimensionalfeature vector xs?
Rk, with a gold-standard labelys.
We denote the training set as a feature matrix?Xs, with a label vector?Ys.
To produce the SEN-TENCE scoring function fs(xs) = xs?
ws, we useridge regression to learn a vector wsthat minimizes||?Xsws?
?Ys||22+ ?s?
||ws||22.
Features used in themodel are listed in Table 2.
We also impose thefollowing position-based regularizing constraint toencode the fact that the first sentence in a news arti-cle usually conveys the most essential information:?s?
?di?xsdi,j,j 6=0||(xsdi,0?
xsdi,j) ?ws?
(ysdi,0?ysdi,j)||22, where xsdi,jis the j-th sentence in doc-ument di.
Term (xsdi,0?
xsdi,j) ?
wsmeasures thedifference in predicted scores between the first sen-tence and any other sentence.
This value is expectedbe close to the true difference.
We further construct?X?sto contain all difference vectors (xsdi,0?
xsdi,j),with?Y?sas label difference vector.
The objectivefunction to minimize becomesJs(ws) =||?Xsws?
?Ys||22+ ?s?
||?X?sws?
?Y?s||22+ ?s?
||ws||22(1)User COMMENT Importance.
Similarly, eachcomment xcis represented as an l?dimensional fea-ture vector xc?
Rl, with label yc.
Comments in thetraining data are denoted with a feature matrix?Xcwith a label vector?Yc.
Likewise, we learn fc(xc) =xc?wcby minimizing ||?Xcwc?
?Yc||22+ ?c?
||wc||22.Features are listed in Table 3.
We apply a pairwisepreference-based regularizing constraint (Joachims,2002) to incorporate a bias toward editor?s picks:?c?
?di?xcdi,j?Edi,xcdi,k/?Edi||(xcdi,j?xcdi,k) ?wc?1||22, where Ediare the editor?s picks for di.
Term(xcdi,j?
xcdi,k) ?
wcenforces the separation of ed-itor?s picks from regular comments.
We furtherconstruct?X?cto contain all the pairwise differences1057(xcdi,j?
xcdi,k).
?Y?cis a vector of same size as?X?cwith each element as 1.
Thus, the objective functionto minimize is:Jc(wc) =||?Xcwc?
?Yc||22+ ?c?
||?X?cwc?
?Y?c||22+ ?c?
||wc||22(2)Graph-Based Regularization.
The regularizingconstraint is based on two mutually reinforcing hy-potheses: (1) the importance of a sentence dependspartially on the availability of sufficient insightfulcomments that touch on topics in the sentence; (2)the importance of a comment depends partially onwhether it addresses notable events reported in thesentences.
For example, we want our model to biaswsto predict a high score for a sentence with highsimilarity to numerous insightful comments.We first create a bipartite graph from sentencesand comments on the same articles, where edgeweights are based on the content similarity betweena sentence and a comment (TF-IDF similarity isused).
Let?R be an N ?M adjacency matrix, whereN and M are the numbers of sentences and com-ments.
Rscis the similarity between sentence xsandcomment xc.
We normalize?R by?Q =?D?12?R?D?
?12,where?D and?D?are diagonal matrices:?D ?
RN?N,Di,i=?Mj=1Ri,j;?D??
RM?M, D?j,j=?Ni=1Ri,j.The interplay between the two types of data is en-coded in the following regularizing constraint:Js,c(ws,wc) =?sc??di?xs?xsdi,xc?xcdiQxs,xc?
(xs?ws?
xc?wc)2(3)Full Objective Function.
Thus, the full objectivefunction consists of the three parts discussed above:J(ws,wc) = Js(ws) + Jc(wc) + Js,c(ws,wc)(4)Furthermore, using the following notation,?X =[?Xs00?Xc]?Y =[?Ys?Yc]?X?=[?X?s00?X?c]?Y?=[?Y?s?Y?c]??
=[?sIk00 ?cIl]??
=[?sI|X?s|00 ?cI|X?c|]?L =[?scI|Xs|??sc?Q?
?sc?QT?scI|Xc|]w =[wswc]we can show a closed form solution to Equation 4as follows:?w =(?XT?L?X +?XT?X +?X?T???X?+??
)?1(?XT?Y +?X?T???Y?
)(5)Basic Features Social Features- num of words - avg/sum frequency of- absolute/relative position words appearing in comment- overlaps with headline - avg/sum frequency of- avg/sum TF-IDF scores dependency relations- num of NEs appearing in commentTable 2: Features used for sentence importance scoring.Basic Features Readability Features- num of words - Flesch-Kincaid Readability- num of sentences - Gunning-Fog Readability- avg num of words Discourse Featuresper sentence - num/proportion of connectives- num of NEs - num/proportion of hedge words- num/proportion of Article Featurescapitalized words - TF/TF-IDF simi with article- avg/sum TF-IDF - TF/TF-IDF simi with comments- contains URL - JS/KL divergence (div) with article- user rating (pos/neg) - JS/KL div with commentsSentiment Features- num /proportion of positive/negative/neutral words (MPQA(Wilson et al, 2005), General Inquirer (Stone et al, 1966))- num /proportion of sentiment wordsTable 3: Features used for comment importance scoring.4 Timeline GenerationNow we present an optimization framework fortimeline generation.
Formally, for each day, our sys-tem takes as input a set of sentences Vsand a set ofcomments Vcto be summarized, and the (automati-cally generated) timeline T (represented as threads)for days prior to the current day.
It then identifiesa subset S ?
Vsas the article summary and a subsetC ?
Vcas the comment summary by maximizing thefollowing function:Z(S,C; T ) = Squal(S; T )+Cqual(C)+?X (S,C) (6)where Squal(S; T ) measures the quality of the articlesummary S in the context of the historical timelinerepresented as event threads T ; Cqual(C) computesthe quality of the comment summary C; and X (S,C)estimates the connectivity between S and C.We solve this maximization problem using an al-ternating optimization algorithm which is outlined1058in Section 4.4.
In general, we alternately searchfor a better article summary S with hill climbingsearch and a better comment summary C with Ford-Fulkerson algorithm until convergence.In the rest of this section, we first describe anentity-centered event threading algorithm to con-struct event threads T which are used to boost articletimeline continuity.
Then we explain how to com-pute Squal(S; T ) and Cqual(C) in Section 4.2, fol-lowed by X (S,C) in Section 4.3.4.1 Entity-Centered Event ThreadingWe present an event threading process where eachthread connects sequential events centered on aset of relevant entities.
For instance, the followingthread connects events about Obama?s actiontowards the annexation of Crimea by Russia:Day 1: Obama declared sanctions on Russian officials.Day 2: President Obama warned Russian.Day 3: Obama urges Russian to move back its troops.Day 4: Obama condemns Russian aggression in Ukraine.We first collect relation extractions as (entity, re-lation, entity) triples from OLLIE (Mausam et al,2012), a dependency relation based open informa-tion extraction system.
We retain extractions withconfidence scores higher than 0.5.
We further de-sign syntactic patterns based on Fader et al (2011)to identify relations expressed as a combination of averb and nouns.
Each relation contains at least oneevent-related word (Ritter et al, 2012).The entity-centered event threading algorithmworks as follows: on the first day, each sentence inthe summary becomes an individual cluster; there-after, each sentence in the current day?s article sum-mary either gets attached to an existing thread orstarts a new thread.
The updated threads then be-come the input to next day?s summary generationprocess.
On day n, we have a set of threads T = {?
:s1, s2, ?
?
?
, sn?1} constructed from previous n ?
1days, where sirepresents the set of sentences at-tached to thread ?
from day i.
The cohesion betweena new sentence s ?
S and a thread ?
is denoted ascohn(s, ?).
s is attached to ??
if there exists ??
=max?
?Tcohn(s, ?)
and cohn(s, ??)
> 0.0.
Otherwise,s becomes a new thread.
We define cohn(s, ?)
=minsi?
?,si6=?tfsimi(si, s), where tfsimi(si, s) mea-sures the TF similarity between siand s. We con-sider unigrams/bigrams/trigrams generated from theentities of our event extractions.4.2 Summary Quality MeasurementRecall that we learned two separate importance scor-ing functions for sentences and comments, whichwill be denoted here as imps(s) and impc(c).
Withan article summary S and threads T = {?i}, the ar-ticle summary quality function Squal(S; T ) has thefollowing form:Squal(S; T ) =?s?Simp(s)+?cov?s?
?Vsmin(?s?Stfidf(s, s?
), ??s?
?Vstfidf(s?, s?
))+ ?cont??
?Tmaxsk?Scohn(sk, ?
)tfidf(?, ?)
is the TF-IDF similarity function.Squal(S; T ) captures three desired qualities of an ar-ticle summary: importance (first item), coverage(second item), and the continuity of the current sum-mary to previously generated summaries.
The cov-erage function has been used to encourage summarydiversity and reduce redundancy (Lin and Bilmes,2011; Wang et al, 2014).
The continuity functionconsiders how well article summary S can be at-tached to each event thread, thus favors summariesthat can be connected to multiple threads.Parameters ?covand ?
are tuned on multi-document summarization dataset DUC 2003 (Overand Yen, 2003).
Experiments show that system per-formance peaks and is stable for ?cont?
[1.0, 5.0].We thus fix ?contto 1.0.
We discard sentences withmore than 80% of content words covered by histor-ical summaries.
We use BASIC to denote a systemthat only optimizes on importance and coverage (i.e.first two items in Squal(S; T )).
The system optimiz-ing Squal(S; T ) is henceforth called THREAD.The comment summary quality function simplytakes the form Cqual(C) =?c?Cimpc(c).4.3 Connectivity MeasurementWe encode two objectives in the connectivity func-tion X (S,C): (1) encouraging topical cohesion (i.e.connectivity) between article summary and com-ment summary; and (2) favoring comments thatcover diversified events.Let conn(s, c) measure content similarity betweena sentence s ?
S and a comment c ?
C. Connectivitybetween article summary S and comment summaryC is computed as follows.
We build a bipartite graphG between S and C with edge weight as conn(s, c).1059We then find an edge setM, the best matching of G.X (S,C) is defined as the sum over edge weights inM, i.e.
X (S,C) =?e?Mweight(e).
An example isillustrated in Figure 2.C0: The ?Crimean Parliament?, headed by an ethnic Russianseparatist, has voted for Crimea tobe annexed into Russia?S0: The Crimean parliament officiallydeclared independenceand requested fullaccession to theRussian Federation.Article Summary Comment SummaryC1: The Obama administration has warned of "increasingly harshsanctions", but it is unlikely thatEurope will comply?C2: Sanctions are effective and if done in unison with the EU?S1: Obama declared sanctions on Russianofficials consideredresponsible for the crisis.0.80.10.10.3 0.80.5Figure 2: An example on computing the connectivitybetween an article summary (left) and a comment sum-mary (right) via best matching in bipartite graph.
Num-ber on each edge indicates the content similarity betweena sentence and a comment.
Solid lines are edges in thebest matching graph.
For this example, the connectivityX (S,C) is 0.8 + 0.8 = 1.6.We consider two options for conn(s, c).
One islexical similarity which is based on TF-IDF vec-tors.
Another is semantic similarity.
Let Rs={(as, rs, bs)} and Rc= {(ac, rc, bc)} be the sets ofdependency relations in s and c. conn(s, c) is calcu-lated as:?
(as,rs,bs)?Rsmax(ac,rc,bc)?Rcrs=rcsimi(as, ac)?
simi(bs, bc)where simi(?, ?)
is a word similarity function.We experiment with shortest path based similar-ity defined on WordNet (Miller, 1995) and Co-sine similarity with word vectors trained on Googlenews (Mikolov et al, 2013).
Systems using the threemetrics that optimize Z(S,C; T ) are henceforthcalled THREAD+OPTTFIDF, THREAD+OPTWordNetand THREAD+OPTWordVec.4.4 An Alternating Optimization AlgorithmTo maximize the full objective function Z(S,C; T ),we design a novel alternating optimization algorithm(Alg.
1) where we alternately find better S and C.We initialize S0by a greedy algorithm (Lin andBilmes, 2011) with respect to Squal(S; T ).
Noticethat Squal(S; T ) is a submodular function, so thatthe greedy solution is a 1 ?
1/e approximation tothe optimal solution of Squal(S; T ).
Fixing S0, wemodel the problem of finding C0that maximizesCqual(C) + ?X (S0, C) as a maximum-weight bipar-tite graph matching problem.
This problem can bereduced to a maximum network flow problem, andthen be solved by Ford-Fulkerson algorithm (de-tails are discussed in (Kleinberg and Tardos, 2005)).Thereafter, for each iteration, we alternately find abetter Stwith regard to Squal(S; T ) + ?X (S,Ct?1)using hill climbing, and an exact solution CttoCqual(C)+?X (St, C) with Ford-Fulkerson algorithm.Iteration stops when the increase of Z(S,C) is belowthreshold  (set to 0.01).
System performance is sta-ble when we vary ?
?
[1.0, 10.0], so we set ?
= 1.0.Input : sentences Vs, comments Vc, threads T , ?,threshold , functions Z(S,C; T ),Squal(S; T ), Cqual(C), X (S,C)Output: article summary S, comment summary C/*Initialize S and C by greedy algorithmand Ford-Fulkerson algorithm*/S0?maxSSqual(S; T );C0?
maxCCqual(C) + ?X (S0, C);t?
1;?Z ??
;while ?Z >  do/*Step 1: Hill climbing algorithm*/St?
maxSSqual(S; T ) + ?X (S,Ct?1);/*Step 2: Ford-Fulkerson algorithm*/Ct?
maxCCqual(C) + ?X (St, C);?Z = Z(St, Ct; T )?Z(St?1, Ct?1; T );t?
t+ 1;endAlgorithm 1: Generate article summary and com-ment summary for a given day via alternating opti-mization .Algorithm 1 is guaranteed to find a solution atleast as good as S0and C0.
It progresses only if Step1 finds Stthat improves upon Z(St?1, Ct?1; T ), andStep 2 finds Ctwhere Z(St, Ct; T ) ?
Z(St, Ct?1; T ).5 Experimental Results5.1 Evaluation of SENTENCE and COMMENTImportance ScorersWe test importance scorers (Section 3) on singledocument sentence ranking and comment ranking.For both tasks, we compare with two previ-ous systems on joint ranking and summarization ofnews articles and tweets.
Yang et al (2011) em-ploy supervised learning based on factor graphs tomodel content similarity between the two types ofdata.
We use the same features for this model.Gao et al (2012) summarize by including thecomplementary information between articles and1060tweets, which is estimated by an unsupervised topicmodel.3We also consider two state-of-the-artrankers: RankBoost (Freund et al, 2003) and Lamb-daMART (Burges, 2010).
Finally, we use a positionbaseline that ranks sentences based on their positionin the article, and a rating baseline that ranks com-ments based on positive user ratings.We evaluate using normalized discounted cumu-lative gain at top 3 returned results (NDCG@3).Sentences are considered relevant if they haveROUGE-2 scores larger than 0.0 (computed againsthuman abstracts), and comments are considered rel-evant if they are editor?s picks.4Figure 3 demon-strates that our joint learning model uniformly out-performs all the other comparisons for both rank-ing tasks.
In general, supervised learning based ap-proaches (e.g.
our method, Yang et al (2011), Rank-Boost, and LambdaMART) produce better resultsthan unsupervised method (e.g.
Gao et al (2012)).5Figure 3: Evaluation of sentence and comment rankingon the four datasets by using normalized discounted cu-mulative gain at top 3 returned results (NDCG@3).
Ourjoint learning based approach uniformly outperforms allthe other comparisons.5.2 Leveraging User CommentsIn this section, we test if our system can leveragecomments to produce better article-based summariesfor event timelines.
We collect gold-standard time-lines for each of the four events from the corre-sponding Wikipedia page(s), NYT topic page, orBBC news page.We consider two existing timeline creation sys-tems that only utilize news articles, and a timelinegenerated from single-article human abstracts: (1)CHIEU AND LEE (2004) select sentences with high3We thank Zi Yang and Peng Li for providing the code.4We experiment with all articles for sentence ranking, andNYT comments (with editor?s picks) for comment ranking.5Similar results are obtained with mean reciprocal rank.?interestingness?
and ?burstiness?
using a likelihoodratio test to compare word distributions of sentenceswith articles in neighboring days.
(2) YAN ET AL.
(2011) design an evolutionary summarization sys-tem that selects sentences based on on coverage, co-herence, and diversity.
(3) We construct a timelinefrom the human ABSTRACTs provided with each ar-ticle: we sort them chronologically according to arti-cle timestamps and add abstract sentences into eachdaily summary until reaching the word limit.We test on five variations of our system.
Thefirst two systems generate article summarieswith no comment information by optimizingSqual(S; T ) using a greedy algorithm: BASIC ignoresevent threading; THREAD considers the threads.THREAD+OPTTFIDF, THREAD+OPTWordNetandTHREAD+OPTWordVec(see Section 4.3) leverageuser comments to generate article summaries aswell as comment summaries based on alternatingoptimization of Equation 3.
Although commentsummaries are generated, they are not used in theevaluation.For all systems, we generate daily article sum-maries of at most 100 words, and select 5 com-ments for the corresponding comment summary.
Weemploy ROUGE (Lin and Hovy, 2003) to automat-ically evaluate the content coverage (in terms ofngrams) of the article-based timelines vs. gold-standard timelines.
ROUGE-2 (measures bigramoverlap) and ROUGE-SU4 (measures unigram andskip-bigrams separated by up to four words) scoresare reported in Table 4.
As can be seen, under the al-ternating optimization framework, our systems, em-ploying both articles and comments, consistentlyyield better ROUGE scores than the three baselinesystems and our systems that do not leverage com-ments.
Though constructed from single-article ab-stracts, baseline ABSTRACT is found to contain re-dundant information and thus limited in content cov-erage.
This is due to the fact that different mediatend to report on the same important events.5.3 Evaluating Socially-Informed TimelinesWe evaluate the full article+comment-based time-lines on Amazon Mechanical Turk.
Turkers arepresented with a timeline consisting of five con-secutive days?
article summaries and four vari-ations of the accompanying comment summary:1061MH370 Ukraine Israel-Gaza NSAR-2 R-SU4 R-2 R-SU4 R-2 R-SU4 R-2 R-SU4CHIEU AND LEE 6.43 10.89 4.64 8.87 3.38 7.32 6.14 9.73YAN ET AL.
6.37 10.35 4.57 8.67 2.39 5.78 3.99 7.73ABSTRACT 6.16 10.62 3.85 8.40 2.21 5.42 7.03 8.65- Greedy AlgorithmBASIC 6.59 9.80 5.31 9.23 3.15 6.20 3.81 7.58THREAD 6.55 10.86 5.73 9.75 3.16 6.16 6.29 10.09- Alternating Optimization (leveraging comments)THREAD+OPTTFIDF8.74 11.63 9.10 12.59 3.78 6.45 8.07 10.31THREAD+OPTWordNet8.73 11.87 8.67 12.10 4.11 6.64 8.63 11.12THREAD+OPTWordVec9.29 11.63 9.16 12.72 3.75 6.38 8.29 10.36Table 4: ROUGE-2 (R-2) and ROUGE-SU4 (R-SU4)scores (multiplied by 100) for different timeline gener-ation approaches on four event datasets.
Systems thatstatistically significantly outperform the three baselines(p < 0.05, paired t?test) are in italics.
Numbers in boldare the highest score for each column.RANDOMly selected comments, USER?S-PICKS(ranked by positive user ratings), randomly selectedEDITOR?S-PICKS and timelines produced by theTHREAD+OPTWordVecversion of OUR SYSTEM.
Wealso include one noisy comment summary (i.e.
irrel-evant to the question) to avoid spam.
We display twocomments per day for each system.6Turkers are asked to rank the comment summaryvariations according to informativeness and insight-fulness.
For informativeness, we ask the Turkersto judge based only on knowledge displayed in thetimeline, and to rate each comment summary basedon how much relevant information they learn from it.For insightfulness, Turkers are required to focus oninsights and valuable opinions.
They are requestedto leave a short explanation of their ranking.15 five-day periods are randomly selected.
We so-licit four distinct Turkers located in the U.S. to eval-uate each set of timelines.
An inter-rater agreementof Krippendorff?s ?
of 0.63 is achieved for infor-mativeness ranking and ?
is 0.50 for insightfulnessranking.Table 5 shows the percentage of times a partic-ular method is selected as producing the best com-ment portion of the timeline, as well as the micro-average rank of each method, for both informative-ness and insightfulness.
Our system is selected asthe best in 66.7% of the evaluations for informative-ness and 51.7% for insightfulness.
In both cases, westatistically significantly outperform (p < 0.05 us-ing a Wilcoxon signed-rank test) the editor?s-picks6For our system, we select the two comments with highestimportance scores from the comment summary.Informativeness Insightfulness% Best Avg Rank % Best Avg RankRandom 1.7% 3.67 3.3% 3.58User?s-picks 5.0% 2.83 15.0% 2.55Editor?s-picks 26.7% 2.05 30.0% 2.22Our system 66.7% 1.45 51.7% 1.65Table 5: Human evaluation results on the comment por-tion of socially-informed timelines.
Boldface indicatesstatistical significance vs. other results in the same col-umn using a Wilcoxon signed-rank test (p < 0.05).
Onaverage, the output from our system is ranked higher thanall other alternatives.and user?s-picks.
Turkers?
explanations indicate thatthey prefer our comment summaries mainly becausethey are ?very informative and insightful to whatwas happening?, and ?show the sharpness of thecommenter?.
Turkers sometimes think the sum-maries randomly selected from editor?s-picks ?lackconnection?, and characterize user?s-picks as ?theinformation was somewhat limited?.Figure 4 shows part of the timeline generated byour system for the Ukraine crisis.Article Summary Comment Summary2014-03-17 Obama administra-tion froze the U.S. assets of sevenRussian officials, while similarsanctions were imposed on fourUkrainian officials.
.
.
.Theodore Roosevelt said that theworst possible thing you can do indiplomacy is ?soft hitting?.
Thatis what the US and the EU aredoing in these timid ?sanctions?against people without any over-seas accounts.
.
.2014-03-18 Ukraine does not rec-ognize a treaty signed in Moscowon Tuesday making its Crimeanpeninsula a part of Russia.
.
.Though there were many inCrimea who supported annexa-tion, there were certainly somewho did not.
what about thosepeople?.
.
.2014-03-19 The head of NATOwarned on Wednesday that Rus-sian President Vladimir Putinmay not stop with the annexationof Crimea .
.
.If you look at a real map , Crimeais an island and has always beenmore connected to Russia than toUkraine.
.
.2014-03-20 The United States onThursday expanded its sanctionson Russians.
.
.The US and EU should follow upeconomic sanctions with concretesteps to strengthen NATO.
.
.Figure 4: A snippet of timeline generated by our sys-tem THREAD+OPTWordVecfor the Ukraine crisis.
Due tospace limitations, we only display partial summaries.5.4 Human Evaluation of Event ThreadingHere we evaluate on the utility of event threads forhigh-level information access guidance: can eventthreads allow users to easily locate and absorb in-formation with a specific interest in mind?We first sample a 10-day timeline for each datasetfrom those produced by the THREAD+OPTWordVec1062variation of our system.
We designed one ques-tion for each timeline.
Sample questions are: ?de-scribe the activities for searching for the missingflight MH370?, and ?describe the attitude and actionof Russian Government on Eastern Ukraine?.
We re-cruited 10 undergraduate and graduate students whoare native speakers of English.
Each student firstread one question and its corresponding timeline for5 minutes.
The timeline was then removed, and thestudent wrote down an answer for the question.
Weasked each student to answer the question for eachof four timelines (one for each event dataset).
Twotimelines are displayed with threads, and two with-out threads.
We presented threads by adding a threadnumber in front of each sentence.We then used Amazon Mechanical Turk to evalu-ate the informativeness of students?
answers.
Turk-ers were asked to read all 10 answers for the samequestion, with five answers based on timelines withthreads and five others based on timelines withoutthreads.
After that, they rated each answer with aninformativeness score on a 1-to-5 rating scale (1 as?not relevant to the query?, and 5 as ?very informa-tive?).
We also added two quality control questions.Table 6 shows that the average rating for answerswritten after reading timelines with threads is 3.29(43% are rated?
4), higher than the 2.58 for the time-lines with no thread exhibited (30% are rated ?
4).Answer Type Avg ?
STD Rated 5 (%) Rated 4 (%)No Thread 2.58 ?
1.20 7% 23%With Threads 3.29 ?
1.28 17% 26%Table 6: Human evaluation on the informativeness ofanswers written after reading timelines with threads vs.with no thread.
Answers written with access to threadsare rated higher (3.29) than the ones with no thread(2.58).6 Related WorkThere is a growing interest in generating articlesummaries informed by social context.
Existingwork focuses on learning users?
interests from com-ments and incorporates the learned information intoa news article summarization system (Hu et al,2008).
Zhao et al (2013) instead estimate word dis-tributions from tweets, and bias a Page Rank algo-rithm to give higher restart probability to sentenceswith similar distributions.
Generating tweet+articlesummaries has been recently investigated in Yang etal.
(2011).
They propose a factor graph to allow sen-tences and tweets to mutually reinforce each other.Gao et al (2012) exploit a co-ranking model to iden-tify sentence-tweet pairs with complementary infor-mation estimated from a topic model.
These effortshandle a small number of documents and tweets,while we target a larger scale of data.In terms of timeline summarization, the Chieuand Lee (2004) system ranks sentences accordingto ?burstiness?
and ?interestingness?
estimated by alikelihood ratio test.
Yan et al (2011) explore an op-timization framework that maximizes the relevance,coverage, diversity, and coherence of the timeline.Neither system has leveraged the social context.
Ourevent threading algorithm is also inspired by workon topic detection and tracking (TDT) (Allan et al,1998), where efforts are made for document-levellink detection and topic tracking.
Similarly, Nalla-pati et al (2004) investigate event threading for ar-ticles, where they predict linkage based on causaland temporal dependencies.
Shahaf et al (2012) in-stead seek for connecting articles into one coherentgraph.
To the best of our knowledge, we are the firstto study sentence-level event threading.7 ConclusionWe presented a socially-informed timeline gener-ation system, which constructs timelines consist-ing of article summaries and comment summaries.An alternating optimization algorithm is designedto maximize the connectivity between the two setsof summaries as well as their importance and infor-mation coverage.
Automatic and human evaluationsshowed that our system produced more informativetimelines than state-of-the-art systems.
Our com-ment summaries were also rated as very insightful.AcknowledgmentsWe thank John Hessel, Lillian Lee, Moontae Lee,David Lutz, Karthik Raman, Vikram Rao, YiyeRuan, Xanda Schofield, Adith Swaminathan, Chen-hao Tan, Bishan Yang, other members of CornellNLP group, and the NAACL reviewers for valuablesuggestions and advice on various aspects of thiswork.
This work was supported in part by DARPADEFT Grant FA8750-13-2-0015.1063ReferencesJ.
Allan, J. Carbonell, G. Doddington, J. Yamron, andY.
Yang.
1998.
Topic detection and tracking pi-lot study: Final report.
In Proceedings of theDARPA Broadcast News Transcription and Under-standing Workshop, pages 194?218, Lansdowne, VA,USA, February.
007.Christopher J. C. Burges.
2010.
From RankNet to Lamb-daRank to LambdaMART: An Overview.
Technicalreport, Microsoft Research.Angel X. Chang and Christopher Manning.
2012.Sutime: A library for recognizing and normaliz-ing time expressions.
In Nicoletta Calzolari (Con-ference Chair), Khalid Choukri, Thierry Declerck,Mehmet Uur Doan, Bente Maegaard, Joseph Mar-iani, Asuncion Moreno, Jan Odijk, and SteliosPiperidis, editors, Proceedings of the Eight Interna-tional Conference on Language Resources and Eval-uation (LREC?12), Istanbul, Turkey, may.
EuropeanLanguage Resources Association (ELRA).Hai Leong Chieu and Yoong Keok Lee.
2004.
Querybased event extraction along a timeline.
In Proceed-ings of the 27th Annual International ACM SIGIRConference on Research and Development in Informa-tion Retrieval, SIGIR ?04, pages 425?432, New York,NY, USA.
ACM.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open informationextraction.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?11, pages 1535?1545, Stroudsburg, PA,USA.
Association for Computational Linguistics.Yoav Freund, Raj Iyer, Robert E. Schapire, and YoramSinger.
2003.
An efficient boosting algorithm forcombining preferences.
J. Mach.
Learn.
Res., 4:933?969, December.Wei Gao, Peng Li, and Kareem Darwish.
2012.
Jointtopic modeling for event summarization across newsand social media streams.
In Proceedings of the21st ACM International Conference on Informationand Knowledge Management, CIKM ?12, pages 1173?1182, New York, NY, USA.
ACM.Meishan Hu, Aixin Sun, and Ee-Peng Lim.
2008.Comments-oriented document summarization: Under-standing documents with readers?
feedback.
In Pro-ceedings of the 31st Annual International ACM SIGIRConference on Research and Development in Informa-tion Retrieval, SIGIR ?08, pages 291?298, New York,NY, USA.
ACM.Thorsten Joachims.
2002.
Optimizing search engines us-ing clickthrough data.
In Proceedings of the EighthACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, KDD ?02, pages133?142, New York, NY, USA.
ACM.Jon Kleinberg and Eva Tardos.
2005.
Algorithm De-sign.
Addison-Wesley Longman Publishing Co., Inc.,Boston, MA, USA.Hui Lin and Jeff Bilmes.
2011.
A class of submodu-lar functions for document summarization.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies - Volume 1, HLT ?11, pages 510?520,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Chin-Yew Lin and Eduard Hovy.
2003.
Automatic evalu-ation of summaries using n-gram co-occurrence statis-tics.
In Proceedings of the 2003 Conference of theNorth American Chapter of the Association for Com-putational Linguistics on Human Language Technol-ogy - Volume 1, pages 71?78.Zongyang Ma, Aixin Sun, Quan Yuan, and Gao Cong.2012.
Topic-driven reader comments summarization.In Proceedings of the 21st ACM International Con-ference on Information and Knowledge Management,CIKM ?12, pages 265?274, New York, NY, USA.ACM.Christopher Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven Bethard, and David McClosky.2014.
The stanford corenlp natural language process-ing toolkit.
In Proceedings of 52nd Annual Meeting ofthe Association for Computational Linguistics: SystemDemonstrations, pages 55?60, Baltimore, Maryland.Association for Computational Linguistics.Mausam, Michael Schmitz, Robert Bart, Stephen Soder-land, and Oren Etzioni.
2012.
Open language learn-ing for information extraction.
In Proceedings of the2012 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning, EMNLP-CoNLL ?12, pages 523?534, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013.
Efficient estimation of word represen-tations in vector space.
CoRR, abs/1301.3781.George A. Miller.
1995.
Wordnet: A lexical database forenglish.
Commun.
ACM, 38(11):39?41, November.Ramesh Nallapati, Ao Feng, Fuchun Peng, and James Al-lan.
2004.
Event threading within news topics.
InProceedings of the Thirteenth ACM International Con-ference on Information and Knowledge Management,CIKM ?04, pages 446?453, New York, NY, USA.ACM.P.
Over and J.
Yen.
2003.
An introduction to DUC 2003:Intrinsic evaluation of generic news text summariza-tion systems.1064Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.2012.
Open domain event extraction from twitter.In Proceedings of the 18th ACM SIGKDD Interna-tional Conference on Knowledge Discovery and DataMining, KDD ?12, pages 1104?1112, New York, NY,USA.
ACM.Dafna Shahaf, Carlos Guestrin, and Eric Horvitz.
2012.Trains of thought: Generating information maps.
InProceedings of the 21st International Conference onWorld Wide Web, WWW ?12, pages 899?908, NewYork, NY, USA.
ACM.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,and Daniel M. Ogilvie.
1966.
The General Inquirer:A Computer Approach to Content Analysis.
MITPress, Cambridge, MA.Lu Wang, Hema Raghavan, Claire Cardie, and VittorioCastelli.
2014.
Query-focused opinion summarizationfor user-generated content.
In Proceedings of COL-ING 2014, the 25th International Conference on Com-putational Linguistics: Technical Papers, pages 1660?1669, Dublin, Ireland, August.
Dublin City Universityand Association for Computational Linguistics.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of the Confer-ence on Human Language Technology and EmpiricalMethods in Natural Language Processing, HLT ?05,pages 347?354, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,Xiaoming Li, and Yan Zhang.
2011.
Evolution-ary timeline summarization: A balanced optimizationframework via iterative substitution.
In Proceedings ofthe 34th International ACM SIGIR Conference on Re-search and Development in Information Retrieval, SI-GIR ?11, pages 745?754, New York, NY, USA.
ACM.Zi Yang, Keke Cai, Jie Tang, Li Zhang, Zhong Su, andJuanzi Li.
2011.
Social context summarization.
InProceedings of the 34th International ACM SIGIRConference on Research and Development in Informa-tion Retrieval, SIGIR ?11, pages 255?264, New York,NY, USA.
ACM.Xin Wayne Zhao, Yanwei Guo, Rui Yan, Yulan He, andXiaoming Li.
2013.
Timeline generation with so-cial attention.
In Proceedings of the 36th Interna-tional ACM SIGIR Conference on Research and De-velopment in Information Retrieval, SIGIR ?13, pages1061?1064, New York, NY, USA.
ACM.1065
