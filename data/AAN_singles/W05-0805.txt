Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 33?40,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Revealing Phonological Similarities between Related Languagesfrom Automatically Generated Parallel CorporaKarin Mu?llerInformatics InstituteUniversity of AmsterdamKruislaan 4031098 SJ Amsterdam, The Netherlandskmueller@science.uva.nlAbstractIn this paper, we present an approachto automatically revealing phonologicalcorrespondences within historically re-lated languages.
We create two bilingualpronunciation dictionaries for the lan-guage pairs German-Dutch and German-English.
The data is used for automat-ically learning phonological similaritiesbetween the two language pairs via EM-based clustering.
We apply our modelsto predict from a phonological Germanword the phonemes of a Dutch and anEnglish cognate.
The similarity scoresshow that German and Dutch phonemesare more similar than German and En-glish phonemes, which supplies statisticalevidence of the common knowledge thatGerman is more closely related to Dutchthan to English.
We assess our approachqualitatively, finding meaningful classescaused by historical sound changes.
Theclasses can be used for language learning.1 IntroductionGerman and Dutch are languages that exhibit a widerange of similarities.
Beside similar syntactic fea-tures like word order and verb subcategorizationframes, the languages share phonological featureswhich are due to historical sound changes.
Thesesimilarities are one reason why it is easier to learn aclosely historically related language than languagesfrom other language families: the learner?s nativelanguage provides a valuable resource which can beused in learning the new language.
Although En-glish also belongs to the West Germanic languages,German and Dutch share more lexical entries with acommon root than German and English.The knowledge about language similarities on thelexical level is exploited in various fields.
In ma-chine translation, some approaches search for sim-ilar words (cognates) which are used to align par-allel texts (e.g., Simard et al (1992)).
The wordtriple Text-tekst-text ([tEkst] in German, Dutchand English) can be easily recognized as a cog-nate; recognizing Pfeffer-peper-pepper ([pfE][f@r]-[pe:][p@r])-[pE][p@r*]), however, requires moreknowledge about sound changes within the lan-guages.
The algorithms developed for machinetranslation search for similarities on the ortho-graphic level, whereas some approaches to com-parative and synchronic linguistics put their fo-cus on similarities of phonological sequences.Covington (1996), for instance, suggests differentalgorithms to align the phonetic representation ofwords of historical languages.
Kondrak (2000)presents an algorithm to align phonetic sequencesby computing the similarities of these words.Nerbonne and Heeringa (1997) use phonetic tran-scriptions to measure the phonetic distance betweendifferent dialects.
The above mentioned approachespresuppose either parallel texts of different lan-guages for machine translation or manually com-piled lists of transcribed cognates/words for analyz-ing synchronic or diachronic word pairs.
Unfortu-nately, transcribed bilingual data are scarce and it33is labor-intensive to collect these kind of corpora.Thus, we aim at exploiting electronic pronunciationdictionaries to overcome the lack of data.In our approach, we automatically generate dataas input to an unsupervised training regime andwith the aim of automatically learning similar struc-tures from these data using Expectation Maximiza-tion (EM) based clustering.
Although the generationof our data introduces some noise, we expect thatour method is able to automatically learn meaningfulsound correspondences from a large amount of data.Our main assumption is that certain German/Dutchand German/English phoneme pairs from relatedstems occur more often and hence will appear in thesame class with a higher probability than pairs not inrelated stems.
We assume that the historical soundchanges are hidden information in the classes.The paper is organized as follows: Section 2presents related research.
In Section 3, we describethe creation of our bilingual pronunciation dictionar-ies.
The outcome is used as input to the algorithmfor automatically deriving phonological classes de-scribed in Section 4.
In Section 5, we apply ourclasses to a transcribed cognate list and measure thesimilarity between the two language pairs.
A quali-tative evaluation is presented in Section 6, where weinterpret our best models.
In Sections 7 and 8, wediscuss our results and draw some final conclusions.2 Previous ResearchSome approaches to revealing sound correspon-dences require clean data whereas other methods candeal with noisy input.
Cahill and Tiberius (2002)use a manually compiled cognate list of Dutch,English and German cognates and extract cross-linguistic phoneme correspondences.
The results1contain the counts of a certain German phonemeand their possible English and Dutch counterparts.The method presented in Kondrak (2003), however,can deal with noisy bilingual word lists.
He gener-ates sound correspondences of various Algonquianlanguages.
His algorithm considers them as possi-ble candidates if their likelihood scores lie above acertain minimum-strength threshold.
The candidatesare evaluated against manually compiled sound cor-respondences.
The algorithm is able to judge1http://www.itri.brighton.ac.uk/projects/metaphon/whether a bilingual phoneme pair is a possible soundcorrespondence.
Another interesting generativemodel can be found in Knight and Graehl (1998).They train weighted finite-state transducers with theEM algorithm which are applied to automaticallytransliterating Japanese words - originated from En-glish - back to English.
In our approach, we aim atdiscovering similar correspondences between bilin-gual data represented in the classes.
The classes canbe used to assess how likely a bilingual sound corre-spondence is.3 Generation of two parallel CorporaIn this section, we describe the resources used forour clustering algorithm.
We take advantage of twoon-line bilingual orthographic dictionaries2 and themonolingual pronunciation dictionaries (Baayen etal., 1993) in CELEX to automatically build two bilin-gual pronunciation dictionaries.In a first step, we extract from the German-Dutchorthographic dictionary 72,037 word pairs and fromthe German-English dictionary 155,317.
Figures 1and 2 (1st table) display a fragment of the extractedorthographic word pairs.
Note that we only allowone possible translation, namely the first one.In a next step, we automatically look up the pro-nunciation of the German, Dutch and English wordsin the monolingual part of CELEX.
A word pair isconsidered for further analysis if the pronunciationof both words is found in CELEX.
For instance, thefirst half of the word pair Hausflur-huisgang (cor-ridor) does occur in the German part of CELEX butthe second half is not contained within the Dutchpart.
Thus, this word pair is discarded.
However, thewords Haus-huis-house are found in all three mono-lingual pronunciation dictionaries and are used forfurther analysis.
Note that the transcription and syl-labification of the words are defined in CELEX.The result is a list of 44,415 transcribed German-Dutch word pairs and a list of 63,297 transcribedGerman-English word pairs.
Figures 1 and 2 (2ndtable) show the result of the look-up procedure.For instance, [?haus]3-[?hUIs] is the transcription ofHaus-huis in the German-Dutch dictionary, while2http://deatch.de/niederlande/buch.htmhttp://branchenportal-deutschland.aus-stade.de/englisch-deutsch.html3A syllable is transcribed within brackets ([syllable]).34Orthographic lexicon Transcribed lexicon Bilingual pronunciation dictionary Onsets Nuclei Codas....................................Ha?user huizen [?hOy][z@r] [hUI][z@] [?hOy][z@r] [hUI][z@] h h Oy UI NOP NOPHaus huis [?haus] [?hUIs] [?haus] [?hUIs] z z @ @ r NOPHausflur huisgang ?
[?haus][flu:r] huisgang ?
- - ?
h h au UI s sHaut huid [?haut] [?hUIt] [?haut] [?hUIt] h h au UI t tHautarzt huidarts [haut][?a:rtst] [hUId][Arts] [haut][?a:rtst] [hUId][Arts] h h au UI t dNOP NOP a: A rtst rts....................................Figure 1: Creation of the German-Dutch input: from the orthographic lexicon - the automatically tran-scribed lexicon - the bilingual dictionary - to the final bilingual onset, nucleus and coda lists ( left to right)Orthographic lexicon Transcribed lexicon Bilingual pronunciation dictionary Onsets Nuclei Codas....................................Ha?user houses [?hOy][z@r] [?haU][zIz] [?hOy][z@r] [?haU][zIz] h h Oy aU NOP NOPHaus house [?haus] [haUs] [?haus] [haUs] z z @ I r zHausflur corridor ?
[?haus][flu:r] [?kO][rI][dO:r?]
?
- - ?
h h au aU s sHaut skin [?haut] [skIn] [?haut] [skIn] h sk au I t nHautarzt dermatologist [haut][?a:rtst] [d3:][m@][?tO]--[l@][dZIst] - -....................................Figure 2: Creation of the German-English input: from the orthographic lexicon - the automatically tran-scribed lexicon - the bilingual dictionary - to the final bilingual onset, nucleus and coda lists ( left to right)[?haus]-[haUs] is the transcription of Haus-house inthe German-English part.We aim at revealing phonological relationshipsbetween German-Dutch and German-English wordpairs on the phonemic level, hence, we need some-thing similar to an alignment procedure on the syl-lable level.
Thus, we first extract only those wordpairs which contain the same number of syllables.The underlying assumption is that words with a his-torically related stem often preserve their syllablestructure.
The only exception is that we do not useall inflectional paradigms of verbs to gain more databecause they are often a reason for uneven syllablenumbers (e.g., the past tense German suffix /tete/is in Dutch /te/ or /de/).
Hautarzt-huidarts wouldbe chosen both made up of two syllables; how-ever, Hautarzt-dermatologist will be dismissed asthe German word consists of two syllables whereasthe English word comprises five syllables.
Figures 1and 2 (3rd table) show the remaining items after thisfiltering process.
We split each syllable within thebilingual word lists into onset, nucleus and coda.All consonants to the left of the vowel are consid-ered the onset.
The consonants to the right of thevowel represent the coda.
Empty onsets and codasare replaced by the word [NOP].
After this process-ing step, each word pair consists of the same numberof onsets, nuclei and codas.The final step is to extract a list of German-Dutchand German-English phoneme pairs.
It is easy to ex-tract the bilingual onset, nucleus and coda pairs fromthe transcribed word pairs (fourth table of Figures 1and 2).
For instance, we extract the onset pair [h]-[h], the nucleus pair [au]-[UI] and the coda pair [s]-[s]from the German-Dutch word pair [?haus]-[?hUIs].With the described method, we obtain from the re-maining 21,212 German-Dutch and 13,067 German-English words, 59,819 German-Dutch and 35,847German-English onset, nucleus and coda pairs.4 Phonological ClusteringIn this section, we describe the unsupervised clus-tering method used for clustering of phonologicalunits.
Three- and five-dimensional EM-based clus-tering has been applied to monolingual phonologi-cal data (Mu?ller et al, 2000) and two-dimensionalclustering to syntax (Rooth et al, 1999).
In ourapproach, we apply two-dimensional clustering toreveal classes of bilingual sound correspondences.The method is well-known but the application ofprobabilistic clustering to bilingual phonologicaldata allows a new view on bilingual phonological35processes.
We choose EM-based clustering as weneed a technique which provides probabilities todeal with noise in the training data.
The two mainparts of EM-based clustering are (i) the inductionof a smooth probability model over the data, and (ii)the automatic discovery of class structure in the data.We aim to derive a probability distribution p(y) onbilingual phonological units y from a large sample(p(c) denotes the class probability, p(ysource|c) isthe probability of a phoneme of the source languagegiven class c, and p(ytarget|c) is the probability of aphoneme of the target language given class c).p(y) =?c?Cp(c) ?
p(ysource|c) ?
p(ytarget|c)The re-estimation formulas are given in (Rooth etal., 1999) and our training regime dealing with thefree parameters (e.g.
the number of |c| of classes)is described in Sections 4.1 and 4.2.
The output ofour clustering algorithm are classes with their classnumber, class probability and a list of class memberswith their probabilities.class 2 0.069t 0.633ts 0.144s 0.055t 0.764d 0.128The above table comes from our German-Dutch ex-periments and shows Class # 2 with its probability of6.9%, the German onsets in the left column (e.g., [t]appears in this class with the probability of 63.3%,[ts] with 14.4% and [s] with 5.5%) and the Dutchonsets in the right column ([t] appears in this classwith the probability of 76.4% and [d] with 12.8%).The examples presented in this paper are fragmentsof the full classes showing only those units with thehighest probabilities.4.1 Experiments with German-Dutch dataWe use the 59,819 onset, nucleus and coda pairsas training material for our unsupervised training.Unsupervised methods require the variation of allfree parameters to search for the optimal model.There are three different parameters which have tobe varied: the initial start parameters, the numberof classes and the number of re-estimation steps.Thus, we experiment with 10 different start param-eters, 6 different numbers of classes (5, 10, 15, 20,25 and 304) and 20 steps of re-estimation.
Our train-ing regime yields 1,200 onset, 1,200 coda and 1,000nucleus models.4.2 Experiments with German-English dataOur training material is slightly smaller for German-English than for German-Dutch.
We derive 35,847onset, nucleus and coda pairs for training.
The re-duced training set is due to the structure of wordswhich is less similar for German-English words thanfor German-Dutch words leading to words with un-equal syllable numbers.
We used the same trainingregime as in Section 4.1, yielding the same numberof models.5 Similarity scores of the syllable partsWe apply our models to a translation task.
The mainidea is to take a German phoneme and to predict themost probable Dutch and English counterpart.Hence, we extract 808 German-Dutch and 738German-English cognate pairs from a cognatedatabase5, consisting of 836 entries.
As for the train-ing data, we extract those pairs that consist of thesame number of syllables because our current mod-els are restricted to sound correspondences and donot allow the deletion of syllables.
We split our cor-pus into two parts by putting the words with an evenline number in the development database and thewords with an uneven line number in the gold stan-dard database.
The development set and the goldstandard corpus consist of 404 transcribed words forthe German to Dutch translation task and of 369transcribed words for the German to English trans-lation task.The task is then to predict the translation of Ger-man onsets to Dutch onsets taken from German-Dutch cognate pairs, e.g.
the models should predictfrom the German word durch ([dUrx]) (through), theDutch word door ([do:r]).
If the phoneme correspon-dence, [d]:[d], is predicted, the similarity score of theonset model increases.
The nucleus score increasesif the nucleus model predicts [U]:[o:] and the codascore increases if the coda model predicts [rx]:[r].We assess all our onset, nucleus and coda models4We did not experiment with 30 classes for nucleus pairs asthere are fewer nucleus types than onset or coda types5http://www.itri.brighton.ac.uk/projects/metaphon/36German to Dutch German to EnglishOnset Nucleus Coda Onset Nucleus Coda80.7% 50.7 % 52.2 % 69.6% 17.1% 28.7%Table 1: Similarity scores for syllable parts of cog-nates indicating that German is closer related toDutch than to English.by measuring the most probable phoneme transla-tions of the cognates from our development set.
Wechoose the models with the highest onset, nucleusand coda scores.
Only the models with the highestscores (for onset, nucleus and coda prediction) areapplied to the gold standard to avoid tuning to thedevelopment set.
Using this procedure shows howour models perform on new data.
We apply our scor-ing procedure to both language pairs.Table 1 shows the results of our best models bymeasuring the onset, nucleus and coda translationscores on our gold standard.
The results point outthat the prediction of the onset is easier than predict-ing the nucleus or the coda.
We achieve an onsetsimilarity score of 80.7% for the German to Dutchtask and 69.6% for the German to English task.
Al-though the set of possible nuclei is smaller than theset of onsets and codas, the prediction of the nucleiis much harder.
The nucleus similarity score de-creases to 50.7% and to 17.1% for German-Englishrespectively.
Codas seem to be slightly easier to pre-dict than nuclei leading to a coda similarity score of52.2% for German-Dutch and to 28.7% for German-English.The comparison of the similarity scores from thetranslation tasks of the two language pairs indicatesthat predicting the phonological correspondencesfrom German to Dutch is much easier than fromGerman to English.
These results supply statisticalevidence that German is historically more closely re-lated to Dutch than to English.
We do not believethat the difference in the similarity scores are due tothe different size of the training corpora but ratherto their closer relatedness.
Revealing phonologicalrelationships between languages is possible simplybecause the noisy training data comprise enough re-lated words to learn from them the similar structureof the languages on the syllable-part level.Proto Germanic...West GermanicHHHHHHHOld Dutchbefore ?
1150Middle Dutch1150 ?
1500Modern Dutch1500 - presentOld English450 ?
1100Middle English1066 ?
1500Early/Modern English1500 ?
17001700 - presentOld High Germanbefore 1050Middle High German1050 ?
1350Early/Modern German1350 ?
16501650 - presentFigure 3: Family tree of West Germanic languages6 Evaluation: Interpretation of the ClassesIn this section, we interpret our classes by manu-ally identifying classes that show typical similari-ties between the two language pairs.
Sometimes, theclasses reflect sound changes in historically relatedstems.
Our data is synchronic, and thus it is not pos-sible to directly identify in our classes which soundchanges took place (Modern German (G), ModernEnglish (E) and Modern Dutch (NL) did not de-velop from each other but from a common ances-tor).
However, we will try to connect the data to an-cient languages such as Old High German (OHG),Middle High German (MHG), Old English (OE),Middle Dutch (MNL), Old Dutch (ONL), Proto orWest Germanic (PG, WG).
Naturally, we can onlygo back in history as far as it is possible accordingto the information provided by the following litera-ture: For Dutch, we use de Vries (1997) and the on-line version of Philippa et al (2004), for English, anetymological dictionary (Harper, 2001) and for Ger-man, Burch et al (1998).
We find that certain his-toric sound changes took place regularly, and thus,the results of these changes can be rediscovered inour synchronic classes.
Figure 3 shows the historicrelationship between the three languages.
A poten-tial learner of a related language does not have tobe aware of the historic links between languages buthe/she can implicitly exploit the similarities such asthe ones discovered in the classes.The relationship of words from different lan-guages can be caused by different processes: somewords are simply borrowed from another languageand adapted to a new language.
Papagei-papegaai37(parrot) is borrowed from Arabic and adapted toGerman and Dutch phonetics, where the /g/ is pro-nounced in German as a voiced velar plosive and inDutch as an unvoiced velar fricative.Other language changes are due to phonology;e.g., the Old English word [mus] (PG: muHs) wassubject to diphthongization and changed to mouse([maUs]) in Modern English.
A similar processtook place in German and Dutch, where the sameword changed to the German word Maus (MHG:mu?s) and to the Dutch word muis (MNL: muus).On the synchronic level, we find [au] and [aU] inthe same class of a German-English model and [au]and [UI] in a German-Dutch model.
There are alsoother phonological processes which apply to the nu-clei, such as monophthongization, raising, lower-ing, backing and fronting.
Other phonological pro-cesses can be observed in conjunction with conso-nants, such as assimilation, dissimilation, deletionand insertion.
Some of the above mentioned phono-logical processes are the underlying processes of thesubsequent described classes.6.1 German-Dutch classesAccording to our similarity scores presented in Sec-tion 5, the best onset model comprises 30 classes,the nucleus model 25 classes and the coda model 30classes.
We manually search for classes, which showinteresting sound correspondences.6.1.1 Onset classesclass 20 0.016p 0.747pf 0.094r 0.027x 0.025f 0.021p 0.902x 0.022The German part of class # 20 reflects Grimm?s firstlaw which states that a West Germanic [p] is oftenrealized as a [pf] in German.
The underlying phono-logical process is that sounds are inserted in a cer-tain context.
The onsets of the Middle High Ger-man words phat (E: path) and phert (E: horse, L:paravere?redus) became the affricate [pf] in ModernGerman.
In contrast to German, Dutch preservedthe simple onsets from the original word form, asin paard (E: horse, MNL: peert) and pad (E: path,MNL: pat).class 25 0.012S 0.339Sr 0.172ts 0.130tr 0.122z 0.090sx 0.189sxr 0.162s 0.135tr 0.087st 0.058Class # 25 represents a class where the Dutch onsetsare more complex than the onsets in German.
Fromthe Old High German word sca?f (E: sheep) the onset/sc/ is assimilated in Modern German to [S] whereasthe Dutch onset [sx] preserves the complex conso-nant cluster from the West Germanic word sk?pan(E: sheep, MNL: scaep).6.1.2 Nucleus classesclass 4 0.054U 0.449O 0.260Y 0.079au 0.072O 0.721U 0.112o: 0.101857We find in Class # 4 a lowering process.
The Ger-man short high back vowel /U/ can be often trans-formed to the Dutch low back vowel /O/.
The un-derlying processes are that the Dutch vowel is some-times lowered from /i/ to /O/; e.g., the Dutch wordgezond (E: healthy, MNL: ghesont, WG: gezwind)comes from the West Germanic word gezwind.
InModern German, the same word changed to gesund(OHG: gisunt).6.1.3 Coda classesclass 14 0.027m 0.534n 0.187NOP 0.054mt 0.042mst 0.042m 0.555NOP 0.136x 0.064k 0.06mt 0.055Class # 14 represents codas where plural and infini-tive suffixes /en/, as in Menschen-mensen (E: hu-mans) or laufen-lopen (E: to run), are reduced to aSchwa [@] in Dutch and thus appear in this classwith an empty coda [NOP].
It also shows that cer-tain German codas are assimilated by the alveolarsounds /d/ and /s/ from the original bilabial [m] to anapico-alveolar [n], as in Boden (E: ground, MHG:bodem) or in Besen (E: broom, MHG: be?sem, OHG:pe?samo).
In Dutch, the words bodem (E: ground,MNL: bo?dem, Greek: puthme?n), and bezem (E:broom, MNL: be?sem, WG: besman) kept the /m/.class 23 0.010rt 0.476tst 0.0782rts 0.068rst 0.067Nst 0.047t 0.023rtst 0.022kt 0.021rt 0.521t 0.159Nt 0.049lt 0.029tst 0.022rd 0.022st 0.022rts 0.021xt 0.02138Class # 23 comprises complex German codas whichare less complex in Dutch.
In the German wordArzt (E: doctor, MHG: arza?t), the complex coda [tst]emerges.
However in Modern Dutch, arts camefrom MNL arst or arsate (Latin: archia?ter).
We canalso find the rule that German codas [Nst] of a 2ndperson singular form of a verb are reduced to [Nt] inDutch as in bringst-brengt (E: bring).6.2 German-English classesThe best German-English models contain 30 onsetclasses, 20 nucleus classes, and 10 coda classes.Our German-English models are noisier than theGerman-Dutch ones, which again points at thecloser relation between the German and Dutch lex-icon.
However, when we analyze the 30 on-set classes, we find meaningful processes as forGerman-Dutch.6.2.1 Onset classesclass 23 0.016f 0.720Sp 0.105z 0.044S 0.012v 0.011...Spr 0.005sp 0.003f 0.648sp 0.131v 0.059Class # 23 shows that a complex German onset [Spr]preserves the consonant cluster, as in sprechen (E:to speak, OHG: sprehhan, PG: sprekanan).
ModernEnglish, however, deleted the /r/ to [sp], as in speak(OE: sprecan).
Another regularity can be found: thepalato-alveolar [S] in the German onset [Sp] is re-alized in English as the alveolar [s] in [sp].
Boththe German word spinnen and the English word spincome from spinnan (OHG, OE).class 3 0.051z 0.489ts 0.170s 0.087s 0.617z 0.143Class # 3 displays the rule that in many loan words,the onset /c/ is realized in German as [ts] and in En-glish as [s] in Akzent-accent (Latin: accentus).6.2.2 Nucleus classesclass 8 0.044o: 0.449y: 0.123ai 0.055@U 0.425@ 0.201O 0.115u: 0.048In some loan words, we find that an original /u/ or /o/becomes in German the long vowel [o:] and in En-glish the diphthong [@U], as in Sofa-sofa (Arabic:suffah) or in Foto-photo (Latin: Phosphorus).
Thediphthongization in English usually applies to opensyllables with the nucleus /o/, as shown in class # 8.6.2.3 Coda classesClass # 6 displays the present participle suffix /end/,which is realized in English as /ing/ (OE: -ende), asin backend-baking.class 6 0.056nt 0.707N 0.075lnt 0.058NOP 0.049rnt 0.047N 0.846NOP 0.072nt 0.041v 0.009s 0.0087 DiscussionWe automatically generated two bilingual phono-logical corpora.
The data is classified by usingan EM-based clustering algorithm which is new inthat respect that this method is applied to bilin-gual onset, nucleus and coda corpora.
The methodprovides a probability model over bilingual sylla-ble parts which is exploited to measure the similar-ity between the language pairs German-Dutch andGerman-English.
The method is able to generalizefrom the data and reduces the noise introduced bythe automatic generation process.
Highly probablesound correspondences appear in very likely classeswith a high probability whereas unlikely sound cor-respondences receive lower probabilities.Our approach differs from other approaches eitherin the method used or in the different linguistic task.Cahill and Tiberius (2002) is based on mere countsof phoneme correspondences; Kondrak (2003) gen-erates Algonquian phoneme correspondences whichare possible according to his translation models;Kondrak (2004) measures if two words are possi-ble cognates; and Knight and Graehl (1998) focuson the back-transliteration of Japanese words to En-glish.
Thus, we regard our approach as a thematiccomplement and not as an overlap to former ap-proaches.The presented approach depends on the availableresources.
That means that we can only learn thosephoneme correspondences which are represented inthe bilingual data.
Thus, metathesis which applies toonsets and codas can not be directly observed as thesyllable parts are modeled separately.
In the Dutchword borst (ONL: bructe), the /r/ shifted from theonset to the coda whereas in English and German(breast-Brust), it remained in the onset.
We are also39dependent on the CELEX builders, who followed dif-ferent transcription strategies for the German andDutch parts.
For instance, elisions occur in theDutch lexicon but not in the German part.
The codaconsonant /t/ in lucht (air) disappears in the Dutchword luchtdruk (E: air pressure), [?lUG][drUk], butnot in the German word Luftdruck, [lUft][drUk].We assume that the similarity scores of the sylla-ble parts might be sharpened by increasing the sizeof the databases.
A first possibility is to take thefirst transcribed translation and not the first transla-tion in general.
As often the first translation is notcontained in the pronunciation dictionary.Our current data generation process also in-troduces unrelated word pairs such as Haut-skin([haut]-[skIn]).
However, it is very unlikely that re-lated words do not include similar phonemes.
Thus,this word pair should be excluded.
Exploiting thisknowledge could lead to cleaner input data.8 Conclusions and Future WorkWe presented a method to automatically build bilin-gual pronunciation dictionaries that can be used toreveal phonological similarities between related lan-guages.
In general, our similarity scores show thatthe lexicons of German and Dutch are closer relatedthan German and English.
Beside the findings aboutthe relatedness between the two language pairs, wethink that the classes might be useful for languagelearning.
An interesting point for future work is toapply the methods developed for the identificationof cognates to our bilingual word-lists.
Beyond theincrease in data, a great challenge is to develop mod-els that can express sound changes on the diachroniclevel adumbrated in Section 6.
We also believe thata slightly modified version of our method can be ap-plied to other related language pairs by using thetranscription of morphemes.9 AcknowledgmentsThis research was supported by the Netherlands Or-ganization for Scientific Research under project nr.220-80-001.
I am especially endebted to B. Mo?biusand G. Dogil for their support and comments duringa research visit in Stuttgart, as well as to D. Ahn, D.Prescher and E. Tjong Kim Sang for comments.ReferencesHarald R. Baayen, Richard Piepenbrock, and H. van Rijn.1993.
The CELEX lexical database?Dutch, English,German.
(Release 1)[CD-ROM].
Philadelphia, PA:Linguistic Data Consortium, Univ.
Pennsylvania.Thomas Burch, Johannes Fournier, and Kurt Ga?rtner.1998.
Mittelhochdeutsche Wo?rterbu?cher auf CD-ROM und im Internet .
Akademie-Journal, 2:17?24.
?http://www.mwv.uni-trier.de/index.html?.Lynne Cahill and Carole Tiberius.
2002.
Cross-linguisticphoneme correspondences.
In Proceedings of ACL2002, Taipai, Taiwan.Michael A. Covington.
1996.
An Algorithm to AlignWords for Historical Comparison.
Computational Lin-guistics, 22(4):481?496.Jan de Vries.
1997.
Nederlands Etymologisch Woorden-boek.
Brill, Leiden.Daniel Harper.
2001.
Online Etymology Dictionary.
?http://www.etymonline.com?.Kevin Knight and Jonathan Graehl.
1998.
Machinetransliteration.
Computational Linguistics, 24(4):599?612.Grzegorz Kondrak.
2000.
A New Algorithm for theAlignment of Phonetic Sequences.
In Proceedings ofNAACL 2000, Seattle, WA.Grzegorz Kondrak.
2003.
Identifying Complex SoundCorrespondences in Bilingual Wordlists.
In Proceed-ings of CICLING 2003, Mexico City.Grzegorz Kondrak.
2004.
Combining evidence in cog-nate identification.
In Proceedings of Canadian AI2004, pages 44?59.Karin Mu?ller, Bernd Mo?bius, and Detlef Prescher.
2000.Inducing Probabilistic Syllable Classes Using Multi-variate Clustering.
In Proc.
38th Annual Meeting ofthe ACL, Hongkong, China.John Nerbonne and Wilbert Heeringa.
1997.
MeasuringDialect Distance Phonetically.
In Proceedings of thethird meeting of the SIGPHON at ACL, pages 11?18.Marlies Philippa, Frans Debrabandere, and Arend Quak.2004.
Etymologisch Woordenboek van het Nederlandsdeel 1: A t/m E, volume 1.
Amsterdam UniversityPress, Amsterdam.
?http://www.etymologie.nl/?.Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Car-roll, and Franz Beil.
1999.
Inducing a SemanticallyAnnotated Lexicon via EM-Based Clustering.
In Proc.37th Annual Meeting of the ACL, College Park, MD.Michel Simard, George F. Foster, and Pierre Isabelle.1992.
Using cognates to align sentences in bilingualcorpora.
In Proceedings of TMI-92, Montreal Canada.40
