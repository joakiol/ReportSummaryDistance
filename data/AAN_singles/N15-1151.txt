Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1351?1356,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsMultilingual Open Relation ExtractionUsing Cross-lingual ProjectionManaal FaruquiCarnegie Mellon UniversityPittsburgh, PA 15213mfaruqui@cs.cmu.eduShankar KumarGoogle Inc.New York, NY 10011shankarkumar@google.comAbstractOpen domain relation extraction systems iden-tify relation and argument phrases in a sen-tence without relying on any underlyingschema.
However, current state-of-the-art re-lation extraction systems are available onlyfor English because of their heavy relianceon linguistic tools such as part-of-speech tag-gers and dependency parsers.
We present across-lingual annotation projection method forlanguage independent relation extraction.
Weevaluate our method on a manually annotatedtest set and present results on three typolog-ically different languages.
We release thesemanual annotations and extracted relations inten languages from Wikipedia.1 IntroductionRelation extraction (RE) is the task of assigning asemantic relationship between a pair of arguments.The two major types of RE are closed domain andopen domain RE.
While closed-domain RE systems(Bunescu and Mooney, 2005; Bunescu, 2007; Mintzet al, 2009; Yao and Van Durme, 2014; Berantand Liang, 2014) consider only a closed set of re-lationships between two arguments, open domainsystems (Yates et al, 2007; Carlson et al, 2010;Fader et al, 2011; Mausam et al, 2012) use an ar-bitrary phrase to specify a relationship.
In this pa-per, we focus on open-domain RE for multiple lan-guages.
Although there are advantages to closeddomain RE (Banko and Etzioni, 2008), it is expen-sive to construct a closed set of relation types whichwould be meaningful across multiple languages.Open RE systems extract patterns from sentencesin a given language to identify relations.
For learn-ing these patterns, the sentences are analyzed using apart of speech tagger, a dependency parser and pos-sibly a named-entity recognizer.
In languages otherthan English, these tools are either unavailable or notaccurate enough to be used.
In comparison, it is eas-ier to obtain parallel bilingual corpora which can beused to build machine translation systems (Resnikand Smith, 2003; Smith et al, 2013).In this paper, we present a system that performsRE on a sentence in a source language by first trans-lating the sentence to English, performing RE in En-glish, and finally projecting the relation phrase backto the source language sentence.
Our system as-sumes the availability of a machine translation sys-tem from a source language to English and an openRE system in English but no any other analysis toolin the source language.
The main contributions ofthis work are:?
A pipeline to develop relation extraction sys-tem for any source language.?
Extracted open relations in ten languages basedon Wikipedia corpus.?
Manual judgements for the projected relationsin three languages.We first describe our methodology for languageindependent cross-lingual projection of extracted re-lations (?2) followed by the relation annotation pro-cedure and the results (?3).
The manually anno-tated relations in 3 languages and the automati-cally extracted relations in 10 languages are avail-able at: http://cs.cmu.edu/?mfaruqui/soft.html.1351Figure 1: RE in a Spanish sentence using the cross-lingual relation extraction pipeline.2 Multilingual Relation ExtractionOur method of RE for a sentence s = ?s1, s2, .
.
.
sN?in a non-English language consists of three steps: (1)Translation of s into English, that generates a sen-tence t = ?t1, t2, .
.
.
tM?
with word alignments arelative to s, (2) Open RE on t, and (3) Relation pro-jection from t to s. Figure 1 shows an example of REin Spanish using our proposed pipeline.
We employOLLIE1(Mausam et al, 2012) for RE in English andGOOGLE TRANSLATE2API for translation from thesource language to English, although in principle,we could use any translation system to translate thelanguage to English.
We next describe each of thesecomponents.2.1 Relation Extraction in EnglishSuppose t = ?t1, t2, .
.
.
, tM?
is a tokenized Englishsentence.
Open relation extraction computes triplesof non-overlapping phrases (arg1; rel; arg2) fromthe sentence t. The two arguments arg1 and arg2are connected by the relation phrase rel.We utilized OLLIE (Mausam et al, 2012) to ex-tract the relation tuples for every English sentence.We chose OLLIE because it has been shown togive a higher yield at comparable precision rela-tive to other open RE systems such as REVERBand WOEparse(Mausam et al, 2012).
OLLIE wastrained by extracting dependency path patterns onannotated training data.
This training data was boot-strapped from a set of high precision seed tuples ex-tracted from a simpler RE system REVERB (Faderet al, 2011).
In Godse killed Gandhi, the ex-1http://knowitall.github.io/ollie/2https://developers.google.com/translate/Data: s, t, a, ptResult: psP ?
PhraseExtract(s, t, a)ps= ?, score = ?
?, overlap = 0for (phrs, phrt) ?
P doif BLEU(phrt, pt) > score thenif phrt?
pt6= ?
thenpt?
phrtscore?
BLEU(phrt, pt)overlap?
phrt?
ptif overlap 6= 0 thenlength =?for (phrs, pt) ?
P doif len(phrs) < length thenlength?
len(phrs)ps?
phrs;elseps?WordAlignmentProj(s, t, a, pt);Algorithm 1: Cross-lingual projection of phrase ptfrom a target sentence t to a source sentence s usingword alignments a and parallel phrases P .tracted relation (Godse; killed; Gandhi) can be ex-pressed by the dependency pattern: arg1 ?
nsubj ?rel:postag=VBD ?
dobj ?
arg2.3OLLIE also nor-malizes the relation phrase for some of the phrases,for example is president of is normalized to be pres-ident of.42.2 Cross-lingual Relation ProjectionWe next describe an algorithm to project the ex-tracted relation tuples in English back to the sourcelanguage sentence.
Given a source sentence, theGOOGLE TRANSLATE API provides us its transla-tion along with the word-to-word alignments rela-tive to the source.
If s = sN1and t = tM1denotethe source and its English translation, then the align-ment a = {aij: 1 ?
i ?
N ; 1 ?
j ?
M} where,aij= 1 if siis aligned to tj, and is 0 otherwise.
A3Example borrowed from Mausam et al (2012)4For sentences where the veracity of a relation depends ona clause, OLLIE also outputs the clause.
For example, in Earlyastronomers believed that Earth is the center of the universe,the relation (Earth; be center of; universe) is supplemented byan (AttributedTo: believe; Early astronomers) clause.
We ignorethis clausal information.1352naive word-alignment based projection would mapevery word from a phrase extracted in English to thesource sentence.
This algorithm has two drawbacks:first, since the word alignments are many-to-many,each English word can be possibly mapped to morethan one source word which leads to ambiguity in itsprojection; second, a word level mapping can pro-duce non-contiguous phrases in the source sentence,which are hard to interpret semantically.To tackle these problems, we introduce a novelalgorithm that incorporates a BLEU score (Papineniet al, 2002) based phrase similarity metric to per-form cross-lingual projection of relations.
Givena source sentence, its translation, and the word-to-word alignment, we first extract phrase-pairs Pusing the phrase-extract algorithm (Och and Ney,2004).
In each extracted phrase pair (phrs, phrt) ?P , phrsand phrtare contiguous word sequences ins and t respectively.
We next determine the trans-lations of arg1, rel and arg2 from the extractedphrase-pairs.For each English phrase p ?
{arg1, rel, arg2}, wefirst obtain the phrase-pair (phrs, phrt) ?
P suchthat phrthas the highest BLEU score relative top subject to the condition that p ?
phrt6= ?
i.e,there is at least one word overlap between the twophrases.
This condition is necessary since we useBLEU score with smoothing and may obtain a non-zero BLEU score even with zero word overlap.
Ifthere are multiple phrase-pairs in P that correspondto the same target phrase phrt, we select the shortestsource phrase (phrs).
However, if there is no wordoverlap between the target phrase p and any of thetarget phrases in P , we project the phrase using theword-alignment based projection.
The cross-lingualprojection method is presented in Algorithm 1.3 ExperimentsEvaluation for open relations is a difficult task withno standard evaluation datasets.
We first describe theconstruction of our multilingual relation extractiondataset and then present the experiments.Annotation.
The current approach to evaluationfor open relations (Fader et al, 2011; Mausam etal., 2012) is to extract relations from a sentenceand manually annotate each relation as either valid(1) or invalid (0) for the sentence.
For exam-ple, in the sentence: ?Michelle Obama, wife ofBarack Obama was born in Chicago?, the follow-ing are possible annotations: a) (Michelle Obama;born in; Chicago): 1, b) (Barack Obama; born in;Chicago): 0.
Such binary annotations are not avail-able for languages apart from English.
Further-more, a binary 1/0 label is a coarse annotation thatcould unfairly penalize an extracted relation whichhas the correct semantics but is slightly ungrammat-ical.
This could occur either when prepositions aredropped from the relation phrase or when there is anambiguity in the boundary of the relation phrase.Therefore to evaluate our multilingual relation ex-traction framework, we obtained annotations fromprofessional linguists for three typologically differ-ent languages: French, Hindi, and Russian.
The an-notation task is as follows: Given a sentence anda pair of arguments (extracted automatically fromthe sentence), the annotator identifies the most rel-evant contiguous relation phrase from the sentencethat establishes a plausible connection between thetwo arguments.
If there is no meaningful contigu-ous relation phrase between the two arguments, thearguments are considered invalid and hence, the ex-tracted relation tuple from the sentence is consideredincorrect.Given the human annotated relation phrase andthe automatically extracted relation phrase, we canmeasure the similarity between the two, thus alle-viating the problem of coarse annotation in binaryjudgments.
For evaluation, we first report the per-centage of valid arguments.
Then for sentences withvalid arguments, we use smoothed sentence-levelBLEU score (max n-gram order = 3) to measure thesimilarity of the automatically extracted relation rel-ative to the human annotated relation.5Results.
We extracted relations from the entireWikipedia6corpus in Russian, French and Hindifrom all sentences whose lengths are in the rangeof 10 ?
30 words.
We randomly selected 1, 000relations for each of these languages and annotatedthem.
The results are shown in table 1.
The percent-age of valid extractions is highest in French (81.6%)5We obtained two annotations for ?
300 Russian sentences.Between the two annotations, the perfect agreement rate was74.5% and the average BLEU score was 0.85.6www.wikipedia.org1353Language Argument 1 Relation phrase Argument 2FrenchIl fut enr?ol?e de force au RADHe was conscripted to RADHindibahut se log aaye cailiforniaMany people came to CaliforniaRussian??????????????
?????????
?????????
?Crash occured MontenegroTable 3: Examples of extracted relations in different languages with English translations (Hindi is transliterated).Language % valid BLEURelation lengthGold AutoFrench 81.6% 0.47 3.6 2.5Hindi 64.9% 0.38 4.1 2.8Russian 63.5% 0.62 1.8 1.7Table 1: % of valid relations and BLEU score of the ex-tracted relations across languages with the average rela-tion phrase length (in words).
[0-0.1) [0.1-0.2)[0.2-0.4)[0.4-0.6)[0.6-0.8) [0.8-1) [1]Binned BLEU Score050100150200250300350400NumberofRelationsFrenchHindiRussianFigure 2: Number of automatically extracted relationsbinned by their BLEU scores computed relative to themanually annotated relations.followed by Hindi and Russian (64.0%).
Surpris-ingly, Russian obtains the lowest percentage of validrelations but has the highest BLEU score betweenthe automatic and the human extracted relations.This could be attributed to the fact that the averagerelation length (in number of words) is the shortestfor Russian.
From table 1, we observe that the lengthof the relation phrase is inversely correlated with theBLEU score.Figure 2 shows the distribution of the numberof extracted relations across bins of similar BLEUscores.
Interestingly, the highest BLEU score bin(1) contains the maximum number of relations inLanguage Size Language SizeFrench 6,743 Georgian 497Hindi 367 Latvian 491Russian 7,532 Tagalog 102Chinese 2,876 Swahili 114Arabic 707 Indonesian 1,876Table 2: Number of extracted relations (in thousands)from Wikipedia in multiple languages.all three languages.
This is an encouraging resultsince it implies that the majority of the extracted re-lation phrases are identical to the manually anno-tated relations.
Table 2 lists the sizes of automat-ically extracted relations on 10 different languagesfrom Wikipedia that we are going to make publiclyavailable.
These were selected to include a mix-ture of high-resource, low-resource, and typologi-cally different languages.
Table 3 shows examplesof randomly selected relations in different languagesalong with their English translations.4 Related WorkCross-lingual projection has been used for transferof syntactic (Yarowsky and Ngai, 2001; Hwa et al,2005) and semantic information (Riloff et al, 2002;Pad?o and Lapata, 2009).
There has been a grow-ing interest in RE for languages other than English.Gamallo et al (2012) present a dependency-parserbased open RE system for Spanish, Portuguese andGalician.
RE systems for Korean have been de-veloped for both open-domain (Kim et al, 2011)and closed-domain (Kim and Lee, 2012; Kim etal., 2014) using annotation projection.
These ap-proaches use a Korean-English parallel corpus toproject relations extracted in English to Korean.
Fol-lowing projection, a Korean POS-tagger and a de-pendency parser are employed to learn a RE systemfor Korean.1354Tseng et al (2014) describe an open RE for Chi-nese that employs word segmentation, POS-tagging,dependency parsing.
Lewis and Steedman (2013)learn clusters of semantically equivalent relationsacross French and English by creating a semanticsignature of relations by entity-typing.
These rela-tions are extracted using CCG parsing in Englishand dependency parsing in French.
Blessing andSch?utze (2012) use inter-wiki links to map relationsfrom a relation database in a pivot language to thetarget language and use these instances for learn-ing in a distant supervision setting.
Gerber andNgomo (2012) describe a multilingual pattern ex-traction system for RDF predicates that uses pre-existing knowledge bases for different languages.5 ConclusionWe have presented a language independent open do-main relation extraction pipeline and have evalu-ated its performance on three typologically differ-ent languages: French, Hindi and Russian.
Ourcross-lingual projection method utilizes OLLIE andGOOGLE TRANSLATE to extract relations in thelanguage of interest.
Our approach does not relyon the availability of linguistic resources such asPOS-taggers or dependency parsers in the target lan-guage and can thus be extended to multiple lan-guages supported by a machine translation system.We are releasing the manually annotated judgementsfor open relations in the three languages and theopen relations extracted over the entire Wikipediacorpus in ten languages.
The resources are avail-able at: http://cs.cmu.edu/?mfaruqui/soft.html.AcknowledgmentThis work was performed when the first author wasan intern at Google.
We thank Richard Sproat forproviding comments on an earlier draft of this pa-per.
We thank Hao Zhang for helping us with the re-lation extraction framework, and Richard Zens andKishore Papineni for their feedback on this work.We are grateful to Bruno Cartoni, Vitaly Nikolaevand their teams for providing us annotations of mul-tilingual relations.ReferencesMichele Banko and Oren Etzioni.
2008.
The tradeoffsbetween open and traditional relation extraction.
InProceedings of ACL.J.
Berant and P. Liang.
2014.
Semantic parsing via para-phrasing.
In Proceedings of ACL.Andre Blessing and Hinrich Sch?utze.
2012.
Crosslingualdistant supervision for extracting relations of differentcomplexity.
In Proceedings of CIKM.Razvan C. Bunescu and Raymond J. Mooney.
2005.
Ashortest path dependency kernel for relation extrac-tion.
In Proceedings of EMNLP.Razvan C. Bunescu.
2007.
Learning to extract relationsfrom the web using minimal supervision.
In Proceed-ings of ACL.Andrew Carlson, Justin Betteridge, Bryan Kisiel, BurrSettles, Estevam R. Hruschka Jr., and Tom M.Mitchell.
2010.
Toward an architecture for never-ending language learning.
In Proceedings of AAAI.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open information ex-traction.
In Proceedings of EMNLP.Pablo Gamallo, Marcos Garcia, and Santiago Fern?andez-Lanza.
2012.
Dependency-based open informationextraction.
In Proceedings of ROBUS-UNSUP.Daniel Gerber and Axel-Cyrille Ngonga Ngomo.
2012.Extracting multilingual natural-language patterns forrdf predicates.
In Proceedings of the 18th Inter-national Conference on Knowledge Engineering andKnowledge Management.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Natural Language Engineering, 11:11?311.Seokhwan Kim and Gary Geunbae Lee.
2012.
A graph-based cross-lingual projection approach for weakly su-pervised relation extraction.
In Proceedings of ACL.Seokhwan Kim, Minwoo Jeong, Jonghoon Lee, andGary Geunbae Lee.
2011.
A cross-lingual anno-tation projection-based self-supervision approach foropen information extraction.
In Proceedings of IJC-NLP.Seokhwan Kim, Minwoo Jeong, Jonghoon Lee, andGary Geunbae Lee.
2014.
Cross-lingual annotationprojection for weakly-supervised relation extraction.ACM Trans.
Asian Lang.
Inf.
Process., pages 3?3.Mike Lewis and Mark Steedman.
2013.
Unsupervisedinduction of cross-lingual semantic relations.
In Pro-ceedings of EMNLP.Mausam, Michael Schmitz, Robert Bart, Stephen Soder-land, and Oren Etzioni.
2012.
Open language learningfor information extraction.
In Proceedings of EMNLP-CoNLL.1355Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of ACL.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Comput.
Linguist., pages 417?449.Sebastian Pad?o and Mirella Lapata.
2009.
Cross-lingualannotation projection of semantic roles.
Journal of Ar-tificial Intelligence Research, 36:307?340.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic evalu-ation of machine translation.
In Proceedings of ACL.Philip Resnik and Noah A. Smith.
2003.
The web as aparallel corpus.
Computational Linguistics.Ellen Riloff, Charles Schafer, and David Yarowsky.2002.
Inducing information extraction systems fornew languages via cross-language projection.
In Pro-ceedings of COLING.Jason R. Smith, Herve Saint-Amand, Magdalena Pla-mada, Philipp Koehn, Chris Callison-Burch, andAdam Lopez.
2013.
Dirt cheap web-scale parallel textfrom the common crawl.
In Proceedings of ACL.Yuen-Hsien Tseng, Lung-Hao Lee, Shu-Yen Lin, Bo-Shun Liao, Mei-Jun Liu, Hsin-Hsi Chen, Oren Etzioni,and Anthony Fader.
2014.
Chinese open relation ex-traction for knowledge acquisition.
In Proceedings ofEACL.Xuchen Yao and Benjamin Van Durme.
2014.
Informa-tion extraction over structured data: Question answer-ing with freebase.
In Proceedings of ACL.David Yarowsky and Grace Ngai.
2001.
Inducing multi-lingual pos taggers and np bracketers via robust pro-jection across aligned corpora.
In Proceedings ofNAACL.Alexander Yates, Michael Cafarella, Michele Banko,Oren Etzioni, Matthew Broadhead, and StephenSoderland.
2007.
Textrunner: Open informationextraction on the web.
In Proceedings of NAACL:Demonstrations.1356
