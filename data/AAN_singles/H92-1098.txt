ROBUSTNESS, PORTABILITY, AND SCALABILITYLANGUAGE SYSTEMSRalph WeischedelBBN Systems and Technologies10 Moulton St.Cambridge, MA 02138OF NATURALOBJECTIVEIn the DoD, every unit, from the smallest o the largest,communicates through messages.
Messages arefundamental in command and control, in intelligenceanalysis, and in planning and replanning.
Our objective isto create algorithms that will1) robustly process open source text,identifying relevant messages, and updating adata base based on the relevant messages;b) reduce the effort required in porting naturallanguage (NL) message processing softwareto a new domain from months to weeks; andc) be scalable to broad domains withvocabularies of tens of thousands of words.APPROACHOur approach is to apply probabilistic language models andtraining over large corpora in all phases of natural anguageprocessing.
This new approach will enable systems toadapt o both new task domains and linguistic expressionsnot seen before by semi-automatically acquiring 1) adomain model, 2) facts required for semantic processing, 3)grammar ules, 4) information about new words, 5)probability models on frequency of occurrence, and 6) rulesfor mapping from semantic representation to applicationstructure.For instance, a statistical model of categories of words willenable systems to predict the most likely category of aword never encountered by the system before and to focuson its most likely interpretation i context, rather thanskipping the word or considering all possibleinterpretations.
Markov modelling techniques will be usedfor this problem.In an analogous way, statistical models of language will bedeveloped and applied at the level of syntax (form), at thelevel of semantics (content), and at the contextual level(meaning and impact).RECENT RESULTSAchieved performance l vels in MUC-3 of identification ofover 40% of the data present ("recall") with an accuracyabove 50% ("precision").
(Only one quarter of the systemsin MUC-3 achieved comparable performance; we achievedthis performance with half a person-year of effort to moveto this domain, much less than the labor invested by theother top performing roups.
)Distributed POST, our software for statistically labellingwords in text, to several other DARPA contractors (NewYork University, Syracuse University, and the Universityof Chicago).Ported our PLUM message processing system to a class oflong range air messages inonly seven person-weeks.PLANS FOR THE COMING YEARCreate automated procedures for the syntactic training ofNL systems, both to improve system performance and toreduce human effort in porting the NL system to a newdomain.Create automated procedures for semantic training.Develop strategies for automatically inferring a domainmodel from a corpus, a task which is highly labor-intensive in today's technology.Create a probabilistic model for predicting the most likely(partial) interpretations of a novel form or errorful input,both of which are significant challenges to currenttechnology.465
