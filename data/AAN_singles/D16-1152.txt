Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1452?1461,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsToward Socially-Infused Information Extraction:Embedding Authors, Mentions, and EntitiesYi YangGeorgia Institute of TechnologyAtlanta, GA 30308, USAyiyang@gatech.eduMing-Wei ChangMicrosoft ResearchRedmond, WA 98052, USAminchang@microsoft.comJacob EisensteinGeorgia Institute of TechnologyAtlanta, GA 30308, USAjacobe@gatech.eduAbstractEntity linking is the task of identifying men-tions of entities in text, and linking them toentries in a knowledge base.
This task is espe-cially difficult in microblogs, as there is littleadditional text to provide disambiguating con-text; rather, authors rely on an implicit com-mon ground of shared knowledge with theirreaders.
In this paper, we attempt to cap-ture some of this implicit context by exploit-ing the social network structure in microblogs.We build on the theory of homophily, whichimplies that socially linked individuals shareinterests, and are therefore likely to mentionthe same sorts of entities.
We implement thisidea by encoding authors, mentions, and en-tities in a continuous vector space, which isconstructed so that socially-connected authorshave similar vector representations.
Thesevectors are incorporated into a neural struc-tured prediction model, which captures struc-tural constraints that are inherent in the entitylinking task.
Together, these design decisionsyield F1 improvements of 1%-5% on bench-mark datasets, as compared to the previousstate-of-the-art.1 IntroductionEntity linking on short texts (e.g., Twitter messages)is of increasing interest, as it is an essential step formany downstream applications, such as market re-search (Asur and Huberman, 2010), topic detectionand tracking (Mathioudakis and Koudas, 2010), andquestion answering (Yih et al, 2015).
Tweet entitylinking is a particularly difficult problem, becauseFigure 1: Illustration on leveraging social relations for entitydisambiguation.
Socially connected users u1 and u2 tend totalk about similar entities (baseball in the example).the short context around an entity mention is ofteninsufficient for entity disambiguation.
For example,as shown in Figure 1, the entity mention ?Giants?in tweet t1 can refer to the NFL football team NewYork Giants or the MLB baseball team San Fran-cisco Giants.
In this example, it is impossible todisambiguate between these entities solely based onthe individual text message.We propose to overcome the difficulty and im-prove the entity disambiguation capability of theentity linking system by employing social networkstructures.
The sociological theory of homophilyasserts that socially connected individuals are morelikely to have similar behaviors or share similar in-terests (McPherson et al, 2001).
This property hasbeen used to improve many natural language pro-cessing tasks such as sentiment analysis (Tan et al,2011; Yang and Eisenstein, 2015), topic classifica-tion (Hovy, 2015) and user attribute inference (Li etal., 2015).
We assume Twitter users will have simi-lar interests in real world entities to their near neigh-bors ?
an assumption of entity homophily ?
which1452is demonstrated in Figure 1.
The social relation be-tween users u1 and u2 may lead to more coherenttopics in tweets t1 and t2.
Therefore, by success-fully linking the less ambiguous mention ?Red Sox?in tweet t2 to the Boston Red Sox baseball team, thetweet entity linking system will be more confidenton linking ?Giants?
to the San Francisco Giants foot-ball team in tweet t1.To exploit social information, we adopt the recentadvance on embedding information networks (Tanget al, 2015), which induces low-dimensional rep-resentations for author nodes based on the networkstructure.
By learning the semantic interactions be-tween the author embeddings and the pre-trainedFreebase entity embeddings, the entity linking sys-tem can incorporate more disambiguating contextfrom the social network.
We also consider low-dimensional representations of mentions, anothersource of related information for entity linking, withthe intuition that semantically related mentions canrefer to similar entities.
Previously proposed ap-proaches (Guo et al, 2013a; Yang and Chang, 2015)are based on hand-crafted features and off-the-shelfmachine learning algorithms.
Our preliminary studysuggests that simply augmenting the traditional sur-face features with the distributed representationsbarely improves the performance of these entitylinking systems.
Therefore, we propose NTEL, aNeural model for Tweet Entity Linking, to leveragethe distributed representations of authors, mentions,and entities.
NTEL can not only make efficient useof statistical surface features built from a knowledgebase, but also learn the interactions between thesedistributed representations.Our contributions are summarized as follows:?
We present a novel model for entity linking thatexploits distributed representations of users,mentions, and entities.?
We combine this distributed model with a feed-forward neural network that learns non-linearcombinations of surface features.?
We perform message-level inference using adynamic program to avoid overlapping men-tions.
The architecture is trained with loss-augmented decoding, a large margin learningtechnique for structured prediction.Data # Tweet # Entity DateNEEL-train 2,340 2,202 Jul.
- Aug. 2011NEEL-test 1,164 687 Jul.
- Aug. 2011TACL 500 300 Dec. 2012Table 1: Statistics of data sets.?
The complete system, NTEL, outperforms theprevious state-of-the-art (Yang and Chang,2015) by 3% average F1 on two benchmarkdatasets.2 DataTwo publicly available datasets for tweet entity link-ing are adopted in the work.
NEEL is originally col-lected and annotated for the Named Entity Extrac-tion & Linking Challenge (Cano et al, 2014), andTACL is first used and released by Fang and Chang(2014).
The datasets are then cleaned and unifiedby Yang and Chang (2015).
The statistics of thedatasets are presented in Table 1.3 Testing Entity HomophilyThe hypothesis of entity homophily, as presented inthe introduction, is that socially connected individ-uals are more likely to mention similar entities thandisconnected individuals.
We now test the hypoth-esis on real data before we start building our entitylinking systems.Twitter social networks We test the assumptionon the users in the NEEL-train dataset.
We con-struct three author social networks based on thefollower, mention and retweet relations betweenthe 1,317 authors in the NEEL-train dataset, whichwe refer as FOLLOWER, MENTION and RETWEET.Specifically, we use the Twitter API to crawl thefriends of the NEEL users (individuals that theyfollow) and the mention/retweet links are inducedfrom their most recent 3,200 tweets.1 We exploitbi-directed links to create the undirected networks,as bi-directed links result in stronger social networkties than directed links (Kwak et al, 2010; Wu etal., 2011).
The numbers of social relations for thenetworks are 1,604, 379 and 342 respectively.1We are able to obtain at most 3,200 tweets for each Twitteruser, due to the Twitter API limits.1453Network sim(i?
j) sim(i?/ j)FOLLOWER 0.128 0.025MENTION 0.121 0.025RETWEET 0.173 0.025Table 2: The average entity-driven similarity results for the net-works.Metrics We propose to use the entity-driven sim-ilarity between authors to test the hypothesis of en-tity homophily.
For a user ui, we employ a Twit-ter NER system (Ritter et al, 2011) to detect entitymentions in the timeline, which we use to constructa user entity vector u(ent)i , so that u(ent)i,j = 1 iffuser i has mentioned entity j.2 The entity-drivensimilarity between two users ui and uj is definedas the cosine similarity score between the vectorsu(ent)i and u(ent)j .
We evaluate the three networksby calculating the average entity-driven similarityof the connected user pairs and that of the discon-nected user pairs, which we name as sim(i ?
j)and sim(i?/ j).Results The entity-driven similarity results ofthese networks are presented in Table 2.
As shown,sim(i?
j) is substantially higher than sim(i?/ j)on all three social networks, indicating that sociallyconnected individuals clearly tend to mention moresimilar entities than disconnected individuals.
Notethat sim(i?/ j) is approximately equal to the samebase rate defined by the average entity-driven simi-larity of all pairs of users, because the vast major-ity of user pairs are disconnected, no matter howto define the network.
Among the three networks,RETWEET offers slightly higher sim(i ?
j) thanFOLLOWER and MENTION.
The results verify ourhypothesis of entity homophily, which forms the ba-sis for this research.
Note that all social relation datawas acquired in March 2016; by this time, the au-thorship information of 22.1% of the tweets in theNEEL-train dataset was no longer available, becausethe tweets or user accounts had been deleted.4 MethodIn this section, we present, NTEL, a novel neuralbased tweet entity linking framework that is able to2We assume each name corresponds to a single entity forthis metric, so this metric only approximates entity homophily.Figure 2: Illustration of the non-overlapping structure for thetask of tweet entity linking.
In order to link ?Red Sox?
to a realentity, ?Red?
and ?Sox?
should be linked to Nil.leverage social information.
We first formally de-fine the task of tweet entity linking.
Assume we aregiven an entity database (e.g., Wikipedia or Free-base), and a lexicon that maps a surface form intoa set of entity candidates.
For each input tweet, weconsider any n-grams of the tweet that match thelexicon as mention candidates.3 The entity linkingsystem maps every mention candidate (e.g., ?RedSox?)
in the message to an entity (e.g., Boston RedSox) or to Nil (i.e., not an entity).
There are twomain challenges in the problem.
First, a mentioncandidate can often potentially link to multiple en-tities according to the lexicon.
Second, as shownin Figure 2, many mention candidates overlap witheach other.
Therefore, the entity linking system isrequired to disambiguate entities and produce non-overlapping entity assignments with respect to themention candidates in the tweet.We formalize this task as a structured learningproblem.
Let x be the tweet, u be the author, andy = {yt}Tt=1 be the entity assignments of the Tmention candidates in the tweet.
The overall scoringfunction s(x,y, u) can be decomposed as follows,s(x,y, u) =T?t=1g(x, yt, u, t), (1)where g(x, yt, u, t) is the scoring function for the t-th mention candidate choosing entity yt.
Note thatthe system needs to produce non-overlapping entityassignments, which will be resolved in the inferencealgorithm.The overview of NTEL is illustrated in Figure 3.We further break down g(x, yt, u, t) into two scoring3We adopted the same entity database and lexicon as thoseused by Yang and Chang (2015).1454Figure 3: The proposed neural network approach for tweet entity linking.
A composition model based on bilinear functions is usedto learn the semantic interactions of user, mention, and entity.functions:g(x, yt, u, t; ?1,?2) =g1(x, yt, t; ?1) + g2(x, yt, u, t; ?2), (2)where g1 is the scoring function for our basic sur-face features, and g2 is the scoring function for mod-eling user, mention, entity representations and theircompositions.
?1 and ?2 are model parameters thatwill be detailed below.
We choose to use a mul-tilayer perceptron (MLP) to model g1(x, yt, t; ?1),and we employ simple yet efficient bilinear func-tions to learn the compositions of user, mention,and entity representations g2(x, yt, u, t; ?2).
Fi-nally, we present a training algorithm based on loss-augmented decoding and a non-overlapping infer-ence algorithm.4.1 Modeling Surface FeaturesWe include the 37 features used by Yang and Chang(2015) as our surface feature set.
These features areextracted from various sources, including a namedentity recognizer, an entity type recognizer, andsome statistics of the Wikipedia pages.We exploit a multilayer perceptron (MLP) totransform the surface features to a real-valued score.The output of the MLP is formalized as follows,g1(x, yt, t; ?1) =?>h + bh =tanh(W?
(x, yt, t) + b), (3)where ?
(x, yt, t) is the feature function, W is anM ?
D matrix, the weights b are bias terms, andh is the output of the hidden layer of the MLP.
?is an M dimensional vector of weights for the out-put score, and b is the bias term.
The parameters ofthe MLP are ?1 = {W,b,?, b}.
Yang and Chang(2015) argue that non-linearity is the key for obtain-ing good results on the task, as linear models arenot expressive enough to capture the high-order rela-tionships between the dense features.
They proposea tree-based non-linear model for the task.
The MLPforms simple non-linear mappings between the inputfeatures and the output score, whose parameters willbe jointly learnt with other components in NTEL.4.2 Modeling User, Mention, and EntityTo leverage the social network structure, we firsttrain low-dimensional embeddings for the authorsusing the social relations.
The mention and entityrepresentations are given by word embeddings learntwith a large Twitter corpus and pre-trained Freebaseentity embeddings respectively.
We will denote theuser, word, entity embedding matrices as:E(u) = {v(u)u } E(w) = {v(w)w } E(e) = {v(e)e },where E(u),E(w),E(e) are V (u) ?
D(u), V (w) ?D(w), V (e) ?
D(e) matrices, and v(u)u , v(w)w , v(e)eare D(u), D(w), D(e) dimensional embedding vec-tors respectively.
V (u), V (w), V (e) are the vocabu-lary sizes for users, words, and entities.
Finally, wepresent a composition model for learning semanticinteractions between user, mention, and entity.User embeddings We obtain low-dimensionalTwitter author embeddings E(u) using LINE ?
therecently proposed model for embedding informationnetworks (Tang et al, 2015).
Specifically, we trainLINE with the second-order proximity, which as-sumes that Twitter users sharing many neighbors are1455close to each other in the embedding space.
Accord-ing to the original paper, the second-order proxim-ity yields slightly better performances than the first-order proximity, which assumes connecting usersare close to each other, on a variety of downstreamtasks.Mention embeddings The representation of amention is the average of embeddings of words itcontains.
As each mention is typically one to threewords, the simple representations often perform sur-prisingly well (Socher et al, 2013).
We adopt thestructured skip-gram model (Ling et al, 2015) tolearn the word embeddings E(w) on a Twitter corpuswith 52 million tweets (Owoputi et al, 2013).
Themention vector of the t-th mention candidate can bewritten as:v(m)t =1|x(w)t |?w?x(w)tv(w)w , (4)where x(w)t is the set of words in the mention.Entity embeddings We use the pre-trained Free-base entity embeddings released by Google to rep-resent entity candidates, which we refer as E(e).4The embeddings are trained with the skip-grammodel (Mikolov et al, 2013) on 100 billion wordsfrom various news articles.
The entity embeddingscan also be learnt from Wikipedia hyperlinks orFreebase entity relations, which we leave as futurework.Compositions of user, mention, and entity Thedistributed representations of users, mentions, andentities offer additional information that is useful forimproving entity disambiguation capability.
In par-ticular, we explore the information by making twoassumptions: socially connected users are interestedin similar entities (entity homophily), and semanti-cally related mentions are likely to be linked to sim-ilar entities.We utilize a simple composition model that takesthe form of the summation of two bilinear scoringfunctions, each of which explicitly leverages one ofthe assumptions.
Given the author representationv(u)u , the mention representation v(m)t , and the en-tity representation v(e)yt , the output of the model can4Available at https://code.google.com/archive/p/word2vec/be written as:g2(x, yt, u, t; ?2) =v(u)u>W(u,e)v(e)yt+ v(m)t>W(m,e)v(e)yt , (5)where W(u,e) and W(m,e) are D(u) ?
D(e) andD(w) ?D(e) bilinear transformation matrices.
Sim-ilar bilinear formulation has been used in the lit-erature of knowledge base completion and infer-ence (Socher et al, 2013; Yang et al, 2014).
Theparameters of the composition model are ?2 ={W(u,e),W(m,e),E(u),E(w),E(e)}.4.3 Non-overlapping InferenceThe non-overlapping constraint for entity assign-ments requires inference method that is differentfrom the standard Viterbi algorithm for a linearchain.
We now present a variant of the Viterbi al-gorithm for the non-overlapping structure.
Giventhe overall scoring function g(x, yt, u, t) for the t-thmention candidate choosing an entity yt, we sort themention candidates by their end indices and definethe Viterbi recursion byy?t = arg maxyt?Yxt ,yt 6=Nilg(x, yt, u, t) (6)a(1) = max(g(x,Nil, u, 1), g(x, y?1, u, 1)) (7)a(t) = max (?t(Nil), ?t(y?t)) (8)?t(Nil) =g(x,Nil, u, t) + a(t?
1) (9)?t(y?t) =g(x, y?t, u, t) +?prev(t)<t?<tg(x,Nil, u, t?
)+ a(prev(t)) (10)where Yxt is set of entity candidates for the t-thmention candidate, and prev(t) is a function thatpoints out the previous non-overlapping mentioncandidate for the t-th mention candidate.
We ex-clude any second-order features between entities.Therefore, for each mention candidate, we only needto decide whether it can take the highest scored en-tity candidate y?t or the special Nil entity based onwhether it is overlapped with other mention candi-dates.14564.4 Loss-augmented TrainingThe parameters need to be learnt during training are?
= [?1, {W(u,e),W(m,e)}].5 We train NTEL byminimizing the following loss function for eachtraining tweet:L(?)
= maxy?Yx(?(y,y?)
+ s(x,y, u))?
s(x,y?, u),(11)where y?
is the gold structure, Yx represents theset of valid output structures for x, and ?(y,y?
)is the weighted hamming distance between the goldstructure y?
and the valid structure y.
The ham-ming loss is decomposable on the mention candi-dates, which enables efficient inferences.
We setthe hamming loss weight to 0.2 after a preliminarysearch.
Note that the number of parameters in ourcomposition model is large.
Thus, we include anL2 regularizer on these parameters, which is omit-ted from Equation 11 for brevity.
The evaluation ofthe loss function corresponds to the loss-augmentedinference problem:y?
= arg maxy?Yx(?(y,y?)
+ s(x,y, u)), (12)which can be solved by the above non-overlappinginference algorithm.
We employ vanilla SGD algo-rithm to optimize all the parameters.
The numbersof training epochs are determined by early stopping(at most 1000 epochs).
Training takes 6-8 hours on4 threads.5 ExperimentsIn this section, we evaluate NTEL on the NEEL andTACL datasets as described in ?
2, focusing on in-vestigating whether social information can improvethe task.
We also compare NTEL with the previousstate-of-the-art system.5.1 Social Network ExpansionWe utilize Twitter follower, mention, and retweet so-cial networks to train user embeddings.
We wereable to identify 2,312 authors for the tweets of thetwo datasets in March 2016.
We then used the Twit-ter API to crawl their friend links and timelines,from which we can induce the networks.
We find the5We fixed the pre-trained embedding matrices during loss-augmented training.Network # Author # RelationFOLLOWER+ 8,772 286,800MENTION+ 6,119 57,045RETWEET+ 7,404 59,313Table 3: Statistics of author social networks used for traininguser embeddings.numbers of social connections (bidirectional links)between these users are relatively small.
In orderto learn better user embeddings, we expand the setof author nodes by including nodes that will do themost to densify the author networks.
For the fol-lower network, we add additional individuals whoare followed by at least twenty authors in the orig-inal set.
For the mention or retweet networks, weadd all users who have mentioned or retweeted by atleast ten authors in the original set.
The statistics ofthe resulting networks are presented in Table 3.5.2 Experimental SettingsFollowing Yang and Chang (2015), we train allthe models with the NEEL-train dataset and evalu-ate different systems on the NEEL-test and TACLdatasets.
In addition, 800 tweets from the NEEL-train dataset are sampled as our development setto perform parameter tuning.
Note that Yang andChang (2015) also attempt to optimize F1 scores bybalancing precision and recall scores on the devel-opment set; we do not fine tune our F1 in this way,so that we can apply a single trained system acrossdifferent test sets.Metrics We follow prior work (Guo et al, 2013a;Yang and Chang, 2015) and perform the standardevaluation for an end-to-end entity linking system,computing precision, recall, and F1 score accordingto the entity references and the system outputs.
Anoutput entity is considered as correct if it matchesthe gold entity and the mention boundary overlapswith the gold mention boundary.
More details aboutthe metrics are described by Carmel et al (2014).Competitive systems Our first baseline system,NTEL-nonstruct, ignores the structure informationand makes the entity assignment decision for eachmention candidate individually.
For NTEL, westart with a baseline system using the surface fea-tures, and then incorporate the two bilinear functions1457(user-entity and mention-entity) described in Equa-tion 5 incrementally.
Our main evaluation uses theRETWEET+ network, since the retweet network hadthe greatest entity homophily; an additional evalua-tion compares across network types.Parameter tuning We tune all the hyper-parameters on the development set, and then re-trainthe models on the full training data with the bestparameters.
We choose the number of hiddenunits for the MLP from {20, 30, 40, 50}, and theregularization penalty for our composition modelfrom {0.001, 0.005, 0.01, 0.05, 0.1}.
The sizes ofuser embeddings and word embeddings are selectedfrom {50, 100} and {200, 400, 600} respectively.The pre-trained Freebase entity embedding size is1000.
The learning rate for the SGD algorithm is setas 0.01.
During training, we check the performanceon the development set regularly to perform earlystopping.5.3 ResultsTable 4 summarizes the empirical findings for ourapproach and S-MART (Yang and Chang, 2015)on the tweet entity linking task.
For the systemswith user-entity bilinear function, we report resultsobtained from embeddings trained on RETWEET+in Table 4, and other results are available in Table 5.The best hyper-parameters are: the number of hid-den units for the MLP is 40, the L2 regularizationpenalty for the composition parameters is 0.005, andthe user embedding size is 100.
For the word embed-ding size, we find 600 offers marginal improvementsover 400 but requires longer training time.
Thus, wechoose 400 as the size of word embeddings.As presented in Table 4, NTEL-nonstruct per-forms 2.7% F1 worse than the NTEL baseline on thetwo test sets, which indicates the non-overlappinginference improves system performance on the task.With structured inference but without embeddings,NTEL performs roughly the same as S-MART,showing that a feedforward neural network offerssimilar expressivity to the regression trees employedby Yang and Chang (2015).Performance improves substantially with the in-corporation of low-dimensional author, mention,and entity representations.
As shown in Table 4, bylearning the interactions between mention and entityrepresentations, NTEL with mention-entity bilinearfunction outperforms the NTEL baseline system by1.8% F1 on average.
Specifically, the bilinear func-tion results in considerable performance gains in re-calls, with small compromise in precisions on thedatasets.Social information helps to increase about 1% F1on top of both the NTEL baseline system and theNTEL system with mention-entity bilinear compo-sition.
In contrast to the mention-entity compo-sition model, which mainly focuses on improvingthe baseline system on recall scores, the user-entitycomposition model increases around 2.5% recalls,without much sacrifice in precisions.Our best system achieves the state-of-the-art re-sults on the NEEL-test dataset and the TACLdataset, outperforming S-MART by 0.9% and 5.4%F1 scores respectively.
To establish the statisticalsignificance of the results, we obtain 100 bootstrapsamples for each test set, and compute the F1 scoreon each sample for each algorithm.
Two-tail pairedt-test is then applied to determine if the F1 scores oftwo algorithms are significantly different.
NTEL sig-nificantly outperforms S-MART on the NEEL-testdataset and the TACL dataset under p < 0.01 level,with t-statistics equal to 11.5 and 33.6 respectively.As shown in Table 5, MENTION+ andRETWEET+ perform slightly better than FOL-LOWER+.
Puniyani et al (2010) show that themention network has stronger linguistic propertiesthan the follower network, as it gives better correla-tions on each author?s distribution over latent topicsas induced by latent Dirichlet alocation (Blei et al,2003).
Our results suggest that the properties holdwith respect to the authors?
interests on real worldentities.5.4 Error Analysis & DiscussionWe examine the outputs of different systems, fo-cusing on investigating what errors are corrected bythe two bilinear functions.
The results reveal thatthe mention-entity composition improves the sys-tem ability to tackle mentions that are abbreviationssuch as ?WSJ?
(The Wall Street Journal) and ?SJSU?
(San Jose State University), which leads to higherrecall scores.
The mention-entity model also helpsto eliminate errors that incorrectly link non-entitiesto popular entities.
For example, the NTEL baseline1458System user-entitymention-entityNEEL-test TACL Avg.
F1P R F1 P R F1Our approachNTEL-nonstruct 80.0 68.0 73.5 64.7 62.3 63.5 68.5NTEL 82.8 69.3 75.4 68.0 66.0 67.0 71.2NTEL X 82.3 71.8 76.7 66.9 68.7 67.8 72.2NTEL X 80.2 75.8 77.9 66.9 69.3 68.1 73.0NTEL X X 81.9 75.6 78.6 69.0 69.0 69.0 73.8Best published resultsS-MART 80.2 75.4 77.7 60.1 67.7 63.6 70.7Table 4: Evaluation results on the NEEL-test and TACL datasets for different systems.
The best results are in bold.Network NEEL-test TACLP R F1 P R F1FOLLOWER+ 82.2 75.1 78.5 67.8 68.7 68.2MENTION+ 82.5 76.0 79.1 67.5 69.3 68.4RETWEET+ 81.9 75.6 78.6 69.0 69.0 69.0Table 5: Comparison of different social networks with our fullmodel.
The best results are in bold.system links ?sec?
in the tweet ?I?m a be in Miamifor sec to hit da radio!?
to Southeastern Conference,which is corrected by the mention-entity composi-tion model.
The word semantic information encodedin the mention representations alleviates the biasedentity information given by the surface features.The user-entity composition model is good at han-dling highly ambiguous mentions.
For example,our full model successfully disambiguates entitiesfor mentions such as ?Sox?
(Boston Red Sox vs.Chicago White Sox), ?Sanders?
(Bernie Sanders vs.Barry Sanders), and ?Memphis?
(Memphis Grizzliesvs.
Memphis, Tennessee), which are mistakenlylinked to the other entities or Nil by the mention-entity model.
Another example is that the socialnetwork information helps the system correctly link?Kim?
to Lil?
Kim instead of Kim Kardashian, de-spite that the latter entity?s wikipedia page is con-siderably more popular.6 Related WorkTweet entity linking Previous work on en-tity linking mainly focuses on well-written docu-ments (Bunescu and Pasca, 2006; Cucerzan, 2007;Milne and Witten, 2008), where entity disambigua-tion is usually performed by maximizing the globaltopical coherence between entities.
However, theseapproaches often yield unsatisfactory performanceon Twitter messages, due to the short and noisy na-ture of the tweets.
To tackle this problem, collec-tive tweet entity linking methods that leverage en-riched context and metadata information have beenproposed (Huang et al, 2014).
Guo et al (2013b)search for textually similar tweets for a target tweet,and encourage these Twitter messages to containsimilar entities through label propagation.
Shen etal.
(2013) employ Twitter user account informationto improve entity linking, based on the intuition thatall tweets posted by the same user share an under-lying topic distribution.
Fang and Chang (2014)demonstrate that spatial and temporal signals arecritical for the task, and they advance the perfor-mance by associating entity prior distributions withdifferent timestamps and locations.
Our work over-comes the difficulty by leveraging social relations ?socially connected individuals are assumed to sharesimilar interests on entities.
As the Twitter post in-formation is often sparse for some users, our as-sumption enables the utilization of more relevant in-formation that helps to improve the task.NLP with social relations Most previous work onincorporating social relations for NLP problems fo-cuses on Twitter sentiment analysis, where the ex-istence of social relations between users is consid-ered as a clue that the sentiment polarities of mes-sages from the users should be similar.
Speriosu etal.
(2011) construct a heterogeneous network withtweets, users, and n-grams as nodes, and the sen-timent label distributions associated with the nodes1459are refined by performing label propagation over so-cial relations.
Tan et al (2011) and Hu et al (2013)leverage social relations for sentiment analysis byexploiting a factor graph model and the graph Lapla-cian technique respectively, so that the tweets be-longing to social connected users share similar labeldistributions.
We work on entity linking in Twit-ter messages, where the label space is much largerthan that of sentiment classification.
The social re-lations can be more relevant in our problem, as it ischallenging to obtain the entity prior distribution foreach individual.7 ConclusionWe present a neural based structured learning archi-tecture for tweet entity linking, leveraging the ten-dency of socially linked individuals to share simi-lar interests on named entities ?
the phenomenonof entity homophily.
By modeling the compositionsof vector representations of author, entity, and men-tion, our approach is able to exploit the social net-work as a source of contextual information.
Thisvector-compositional model is combined with non-linear feature combinations of surface features, viaa feedforward neural network.
To avoid predictingoverlapping entity mentions, we employ a structuredprediction algorithm, and train the system with loss-augmented decoding.Social networks arise in other settings besides mi-croblogs, such as webpages and academic researcharticles; exploiting these networks is a possible di-rection for future work.
We would also like to in-vestigate other metadata attributes that are relevantto the task, such as spatial and temporal signals.Acknowledgments We thank the EMNLP review-ers for their constructive feedback.
This researchwas supported by the National Science Foundationunder awards IIS-1111142 and RI-1452443, by theNational Institutes of Health under award numberR01-GM112697-01, and by the Air Force Office ofScientific Research.ReferencesSitaram Asur and Bernardo A Huberman.
2010.
Pre-dicting the future with social media.
In Web Intel-ligence and Intelligent Agent Technology (WI-IAT),pages 492?499.David M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent dirichlet alocation.
the Journal of ma-chine Learning research, 3:993?1022.R.
C Bunescu and M. Pasca.
2006.
Using encyclopedicknowledge for named entity disambiguation.
In Pro-ceedings of the European Chapter of the Associationfor Computational Linguistics (EACL).Amparo E Cano, Giuseppe Rizzo, Andrea Varga,Matthew Rowe, Milan Stankovic, and Aba-SahDadzie.
2014.
Making sense of microposts (# microp-osts2014) named entity extraction & linking challenge.Making Sense of Microposts (# Microposts2014).David Carmel, Ming-Wei Chang, Evgeniy Gabrilovich,Bo-June Paul Hsu, and Kuansan Wang.
2014.
Erd?14:entity recognition and disambiguation challenge.
InACM SIGIR Forum, pages 63?77.Silviu Cucerzan.
2007.
Large-scale named entity disam-biguation based on wikipedia data.
In Proceedings ofEmpirical Methods for Natural Language Processing(EMNLP).Yuan Fang and Ming-Wei Chang.
2014.
Entity link-ing on microblogs with spatial and temporal signals.Transactions of the Association for ComputationalLinguistics (ACL).Stephen Guo, Ming-Wei Chang, and Emre Kiciman.2013a.
To link or not to link?
a study on end-to-end tweet entity linking.
In Proceedings of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (NAACL), Atlanta, GA.Yuhang Guo, Bing Qin, Ting Liu, and Sheng Li.
2013b.Microblog entity linking by leveraging extra posts.
InProceedings of Empirical Methods for Natural Lan-guage Processing (EMNLP), Seattle, WA.Dirk Hovy.
2015.
Demographic factors improve classifi-cation performance.
In Proceedings of the Associationfor Computational Linguistics (ACL), pages 752?762,Beijing, China.Xia Hu, Lei Tang, Jiliang Tang, and Huan Liu.
2013.
Ex-ploiting social relations for sentiment analysis in mi-croblogging.
In Proceedings of the sixth ACM inter-national conference on Web search and data mining(WSDM), pages 537?546.Hongzhao Huang, Yunbo Cao, Xiaojiang Huang, HengJi, and Chin-Yew Lin.
2014.
Collective tweet wikifi-cation based on semi-supervised graph regularization.In Proceedings of the Association for ComputationalLinguistics (ACL), Baltimore, MD.Haewoon Kwak, Changhyun Lee, Hosung Park, and SueMoon.
2010.
What is Twitter, a social network or anews media?
In Proceedings of the Conference onWorld-Wide Web (WWW), pages 591?600, New York.ACM.1460Jiwei Li, Alan Ritter, and Dan Jurafsky.
2015.
Learn-ing multi-faceted representations of individuals fromheterogeneous evidence using neural networks.
arXivpreprint arXiv:1510.05198.Wang Ling, Chris Dyer, Alan Black, and Isabel Trancoso.2015.
Two/too simple adaptations of word2vec forsyntax problems.
In Proceedings of the North Ameri-can Chapter of the Association for Computational Lin-guistics (NAACL), Denver, CO.Michael Mathioudakis and Nick Koudas.
2010.
Twit-termonitor: trend detection over the twitter stream.In Proceedings of the ACM SIGMOD InternationalConference on Management of data (SIGMOD), pages1155?1158.Miller McPherson, Lynn Smith-Lovin, and James MCook.
2001.
Birds of a feather: Homophily in socialnetworks.
Annual review of sociology, pages 415?444.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013.
Distributed representationsof words and phrases and their compositionality.
InNeural Information Processing Systems (NIPS), pages3111?3119, Lake Tahoe.D.
Milne and I. H. Witten.
2008.
Learning to link withWikipedia.
In Proceedings of the International Con-ference on Information and Knowledge Management(CIKM).Olutobi Owoputi, Brendan O?Connor, Chris Dyer, KevinGimpel, Nathan Schneider, and Noah A. Smith.
2013.Improved part-of-speech tagging for online conversa-tional text with word clusters.
In Proceedings of theNorth American Chapter of the Association for Com-putational Linguistics (NAACL), pages 380?390, At-lanta, GA.Kriti Puniyani, Jacob Eisenstein, Shay Cohen, and Eric P.Xing.
2010.
Social links from latent topics in mi-croblogs.
In Proceedings of NAACL Workshop on So-cial Media, Los Angeles.Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.2011.
Named entity recognition in tweets: an exper-imental study.
In Proceedings of Empirical Methodsfor Natural Language Processing (EMNLP).Wei Shen, Jianyong Wang, Ping Luo, and Min Wang.2013.
Linking named entities in tweets with knowl-edge base via user interest modeling.
In Proceedingsof Knowledge Discovery and Data Mining (KDD).Richard Socher, Danqi Chen, Christopher D. Manning,and Andrew Y. Ng.
2013.
Reasoning With NeuralTensor Networks For Knowledge Base Completion.
InNeural Information Processing Systems (NIPS), LakeTahoe.Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Ja-son Baldridge.
2011.
Twitter polarity classificationwith label propagation over lexical links and the fol-lower graph.
In Proceedings of Empirical Methods forNatural Language Processing (EMNLP), pages 53?63.Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, MingZhou, and Ping Li.
2011.
User-level sentiment anal-ysis incorporating social networks.
In Proceedings ofKnowledge Discovery and Data Mining (KDD).Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, JunYan, and Qiaozhu Mei.
2015.
Line: Large-scale in-formation network embedding.
In Proceedings of theConference on World-Wide Web (WWW).Shaomei Wu, Jake M Hofman, Winter A Mason, andDuncan J Watts.
2011. Who says what to whom ontwitter.
In Proceedings of the Conference on World-Wide Web (WWW), pages 705?714.Yi Yang and Ming-Wei Chang.
2015.
S-mart: Noveltree-based structured learning algorithms applied totweet entity linking.
In Proceedings of the Associationfor Computational Linguistics (ACL), Beijing, China.Yi Yang and Jacob Eisenstein.
2015.
Puttingthings in context: Community-specific embeddingprojections for sentiment analysis.
arXiv preprintarXiv:1511.06052.Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao,and Li Deng.
2014.
Embedding entities and relationsfor learning and inference in knowledge bases.
arXivpreprint arXiv:1412.6575.Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jian-feng Gao.
2015.
Semantic parsing via staged querygraph generation: Question answering with knowl-edge base.
In Proceedings of the Association for Com-putational Linguistics (ACL), Beijing, China.1461
