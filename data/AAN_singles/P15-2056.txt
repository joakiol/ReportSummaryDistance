Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 341?345,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsLearning to Mine Query Subtopics from Query LogZhenzhong Zhang, Le Sun, Xianpei HanInstitute of Software, Chinese Academy of Sciences, Beijing, China{zhenzhong, sunle, xianpei}@nfs.iscas.ac.cnAbstractMany queries in web search are ambiguous ormultifaceted.
Identifying the major senses orfacets of queries is very important for websearch.
In this paper, we represent the majorsenses or facets of queries as subtopics and re-fer to indentifying senses or facets of queriesas query subtopic mining, where query subtop-ic are represented as a number of clusters ofqueries.
Then the challenges of query subtopicmining are how to measure the similarity be-tween queries and group them semantically.This paper proposes an approach for miningsubtopics from query log, which jointly learnsa similarity measure and groups queries byexplicitly modeling the structure among them.Compared with previous approaches usingmanually defined similarity measures, our ap-proach produces more desirable query subtop-ics by learning a similarity measure.
Experi-mental results on real queries collected from asearch engine log confirm the effectiveness ofthe proposed approach in mining query sub-topics.1 IntroductionUnderstanding the search intents of queries isessential for satisfying users?
information needsand is very important for many search tasks suchas personalized search, query suggestion, andsearch result presentation.
However, it is not atrivial task because the underlying intents of thesame query may be different for different users.Two well-known types of such queries are am-biguous queries and multifaceted queries.
Forexample, the ambiguous query ?michael jordon?may refer to a basketball player or a professor ofstatistics in Berkeley.
The multifaceted query?harry potter?
may refer to different search in-tents such as films, books, or games and so on.Many approaches have been proposed to identi-fy the search intents of a query which are repre-sented by search goals, topics, or subtopics.
Forexample, Broder (2002) classified query intentsinto three search goals: informational, naviga-tional, and transactional.
Broder et al (2007) andLi et al (2005) represented query intents by top-ics.
Clarke et al (2009) represented query intentsby subtopics which denote different senses ormultiple facets of queries.Previous work on query subtopic mining ismostly based on clustering framework by manu-ally defining a similarity measure with few fac-tors.
Hu et al (2012) employed an agglomerativeclustering algorithm with a similarity measurecombining string similarities, click similarities,and keyword similarities linearly.
Wang et al(2013) applied affinity propagation algorithm(Frey and Dueck, 2009) with a sense-based simi-larity.
Tsukuda et al (2013) used a hierarchicalclustering algorithm with the similarity measurebased on search results.In this paper, we argue that the similarity be-tween queries is affected by many different fac-tors and it could produce more desirable querysubtopics by learning a similarity measure.
Tolearn a similarity measure for query subtopicmining, a natural approach is to use a binaryclassifier, that is, the classifier targets pairs ofqueries and makes predictions about whetherthey belong to the same subtopic.
However, be-cause such pairwise classifiers assume that pairsare independent, they might make inconsistentpredictions: e.g., predicting queries qi and qj, qjand qk to belong to the same subtopic, but qi andqk to belong to different subtopics.
For example,given three queries, ?luxury car?, ?sport car?
and?XJ sport?, for the query ?jaguar?, a lexicon-similarity-based classifier is easy to learn that?luxury car?
and ?sport car?, and ?sport car?
and?XJ sport?
belong to the same subtopic; but diffi-cult to learn that ?luxury car?
and ?XJ sport?
be-long to the same subtopic.
From this example,we can see that a learner should exploit thesetransitive dependencies among queries to learn amore effective similarity measure.
Hence, in thispaper, our first contribution is that we learn asimilarity measure by explicitly modeling thedependencies among queries in the same subtop-ic.
The second contribution is that we analyze theperformance of the proposed approach with dif-ferent dependencies among queries.
The thirdcontribution is that we conduct experiments on341real-world data and the experimental results con-firm the effectiveness of the proposed approachin mining query subtopics.2 Learning to Mine Query SubtopicsIn this section, we present our approach in details.First, we collect queries as subtopic candidatesfrom query log using a heuristic method.
Then,we learn a similarity measure to mine query sub-topics from these candidates.2.1 Collecting Subtopic Candidates fromQuery LogIn web search, users usually add additionalwords to clarify the underlying intents of a query(Hu et al, 2012).
For example, if the ambiguousquery ?jaguar?
does not satisfy a user?s infor-mation need, he/she may submit ?jaguar sportcar?
as an expanded query to specify the subtopic.Therefore, for a given query q, we collect its re-formulations with additional words from querylog as query subtopic candidates, e.g., we collect{?jaguar sports car?, ?jaguar XJ sport?, ?jaguardiet?, ?}
for query ?jaguar?.
We say query q?
is asubtopic candidate of q if (1) q?
is superset of q(e.g.
q?= ?jaguar sports car?
and q = ?jaguar?
), and(2) q?
occurred at least five times in query log.
Inthis way, we collect a series of subtopic candi-dates for each query.
Many subtopic candidates,however, belong to the same subtopic, e.g., ?jag-uar sports car?
and ?jaguar XJ sport?.
Thus, toobtain the subtopics of a query, we need to groupits subtopic candidates into clusters, each ofwhich corresponds to an individual subtopic.2.2 Mining Query SubtopicsAs we described above, we need to group thesubtopic candidates of a query into clusters toobtain its subtopics.
The key to producing desir-able subtopics is how to measure the similaritybetween subtopic candidates.
In this paper, welearn a similarity measure by exploiting the de-pendencies among subtopic candidates in thesame subtopic.We represent each pair of subtopic candidatesqi and qj as a feature vector ?
(qi, qj), each dimen-sion of which describes a factor.
The similaritymeasure Simw parameterized by w is defined asSimw(qi, qj) = wT??
(qi, qj), which maps pairs ofsubtopic candidates to a real number indicatinghow similar the pair is: positive for similar andnegative for dissimilar.
As argued in the intro-duction, the dependencies among subtopic can-didates within the same subtopic are useful forlearning an effective similarity measure.
We de-note the dependencies among subtopic candi-dates as a graph h, whose vertices are subtopiccandidates and edges connect two vertices be-longing to the same subtopic.
In this paper, weemploy two different graphs.
The first one is theall-connection structure, where all subtopic can-didates belonging to the same subtopic associatewith each other.
Figure 1 gives an example of theall-connection structure.
The second one is thestrong-connection structure, where each subtopiccandidate only associates with its ?most similar?subtopic candidate within the same subtopic.Figure 2 gives an example.17352460.10.3 0.20.5 0.30.2 -0.10.10.2Figure 1.
An example of the all-connection struc-ture.
The dashed circles denote the subtopics.The subtopic candidates (small solid circles) inthe same dashed circle belong to the same sub-topic.
The weights indicate how similar the pairof two vertices is.17352460.3 0.20.5 0.30.2Figure 2.
An example of the strong-connectionstructure.Formally, we denote the set of subtopic candi-dates for a given query q as S = {q1, q2, ?, qN}.The label y is a partition of the N subtopic candi-dates into subtopic clusters.
h is the correspond-ing graph that is consistent with y. h is consistentwith a clustering y if every cluster in y is a con-nected component in h, and there are no edges inh that connect two distinct clusters in y.
Given S,our approach makes predictions by maximizingthe sum of similarities for subtopic candidatepairs that are adjacent in h, that is,Tw i j i j( , ) ( , )(i, j) (i,j)arg max ( , ) arg max w ( , )y h Y H y h Y Hh hSim q q q q?
?
?
??
??
???
?where Y and H are the sets of possible y and hrespectively.
(i, j) ?h denotes qi and qj are di-rectly connected in h.(1)342To predict a partition y with the all-connectionstructure, we use the algorithm in (Bansal et al,2002) with the objective function Eq (1).
To pre-dict a partition y with the strong-connectionstructure, we run Kruskal?s algorithm on h andeach tree corresponds to a subtopic, as shown inAlgorithm 1.Algorithm 1: Mining Query Subtopic with Strong-connection StructureInput: the set of query subtopic candidates S = {q1,q2, ?, qN}, feature vectors ?
(qi, qj) (1?i, j?N,i?j) and the weight wOutput: the partition y//search for the strong-connection structure h, MST-KRUSKAL(G) denotes the Minimum Spanning Treealgorithm- Kruskal?s algorithmfor i = 1?N-1 dofor j = i+1?N dosim = wT?
?
(qi, qj);G(i, j)=?sim;endendh?= MST-KRUSKAL(G);for i = 1?N-1 dofor j = i+1?N doif h?
(i, j)<0 thenh(i, j) = 1;endendend// construct the partition yt = 0;y(1)=0;for i = 2?N doj = 1;while j ?
i-1 doif h(j, i) = 1 theny(i)= y(j);break;endj = j+1;endif j ?
i thent = t + 1;y(i) = t;endendreturn y2.3 Solving the Proposed ApproachFor a given set of subtopic candidates with anno-tated subtopics, {(Sn, yn)} (1?n?N), we need toestimate the optimal weight w. Empirically, theoptimal weight w should minimize the error be-tween the predicted partition y?
and the true parti-tion y, and it should also have a good generaliza-tion capability.
Therefore, it is learnt by solvingthe following optimization problem (Yu and Joa-chims, 2009):' ''N2nw,n 1Ti j(i,j)T ' 'i j( , )(i,j)1min || w ||2s.t.
, max ( , )max [ ( , ) ( , , )]h Hhn ny h Y HhCn w q qw q q y y h?????
???
??
?
?
??
?
?
?
????
?where ?
(yn, y?, h?)
indicates a loss between a truepartition yn and the predicted partition y?
speci-fied by h?, ?n (1?n?N) is a set of slack variablesto allow errors in the training data, and C con-trols the trade-off between empirical loss andmodel complexity.Intuitively, the loss function ?
(yn, y?, h?)
shouldsatisfy that ?
(yn, y?, h?)
= 0 if yn = y?, and rises asyn and y?
become more dissimilar.
Because theall-connection structure is observable in thetraining data while the strong-connection struc-ture is hidden, we define different loss functionsfor them.
For the all-connection structure, wedefine the loss function as,' 'n( , , ) 10 Dy y h T?
?where T is the total number of pairs of subtopiccandidates in the set partitioned by yn and y?, andD is the total number of pairs where yn and y?disagree about their cluster membership.Since the strong-connection structure hn for ynis hidden in the training data, we cannot measurethe loss between (yn, hn) and (y?, h?).
According to(Yu and Joachims, 2009), we define the lossfunction based on the inferred structure h?
as,'' 'n n n n(i, j)( , , ) ( ) ( ) ( , (i, j))hy y h n y k y l y??
?
?
?
?where n(yn) and k(yn) are the number of subtopiccandidates and the number of clusters in the cor-rect clustering yn.
l(yn, (i, j) ) = 1 if qi and qj are inthe same cluster in yn, otherwise  l(yn, (i, j) ) = ?1.Then the optimization problem introduced in Eq.
(2) can be solved by the Concave-Convex Proce-dure (CCCP) (Yuille and Rangarajan, 2003).2.4 Pairwise Similarity FeaturesThe proposed approach requires a set of featuresto measure the similarity between two subtopiccandidates.
Table 1 lists the features employed inour approach.
These features are categorized intotwo types: lexicon-based similarity and URL-based similarity.
The lexicon-based similarityfeatures are employed to measure the string simi-larity between two subtopic candidates.
And theURL-based similarity features are used to meas-ure the semantic similarity between two subtopiccandidates.
The basic idea is that if two queriesshare many clicked URLs, they have similarsearch intent to each other (Li et al, 2008).
To(2)(3)(4)343make the features comparable with each other,we normalize them into range of [0, 1] accord-ingly.Feature DescriptionCOS cosine similarity between qi and qjEUC Euclidean distance between qi and qjJAC Jaccard coeff between qi and qjEDIT norm edit distance between qi and qjLEN |length(qi)-length(qj)|SUBSET whether one is a subset of the otherUCOS cosine similarity between the clickedURL sets of qi and qjUJAC Jaccard coeff between the clicked URLsets of qi and qjTable 1: pairwise similarity features employed inour approach3 Experiments3.1 Data SetTo illustrate the effectiveness of our approach,we use 100 ambiguous/multifaceted queries pro-vided by the NTCIR-9 intent task as originalqueries and collect their subtopic candidatesfrom SogouQ dataset (http://www.sogou.com)using the method mentioned in section 2.1.
Forthe 100 queries, we totally collect 2,280 querysubtopic candidates.
Three annotators manuallylabel these candidates with their subtopics ac-cording to the content words of these candidatesand their clicked web pages (if there are clickedURLs for the candidate in query log).
A candi-date belongs to a specific subtopic if at least twoannotators agree with it.
At last we obtain 1,086subtopics.
We randomly split the original queriesinto two parts: half used for training and the restfor testing.3.2 Evaluation Metrics and BaselinesTo evaluate the performance of our approach, weemploy the measures in (Luo, 2005), which arecomputed as follows,' ' ' '' '( , ( )) ( , ( )), ( , ))( , )i i i ii ij ji i jiR g R R g Rp r R RR R?
??
?
???
?
?where R?
is the predicted partition and R is theground-truth partition; ?
(A, B) is a similaritymeasure between set A and B, which is Jaccardcoefficient in this paper; and g(.)
is the optimalmapping between R?
and R. Based on p and r, f-measure can be calculated as,2 p rf measure p r?
??
?
?The higher the f-measure score is, the better per-formance an approach achieves.We used the following approaches as baselines:?
K-means: we perform the standard k-meansclustering algorithm with different manuallydefined similarity measures to mine query sub-topics.
COS, JAC, EUC, EDIT refer to cosinesimilarity, Jaccard similarity, Euclidean dis-tance, and edit distance, respectively.?
Binary Classification Cluster with the all-connection structure (BCC-AC): BCC-AC usesa SVM classifier to learn the weight w andclusters with correlation clustering method.?
Binary Classification Cluster with the strong-connection structure (BCC-SC): BCC-SC usesa SVM classifier to learn the weight w andclusters with the method presented in Algo-rithm 1.For the proposed methods, we denote themethod with the all-connection structure as ACand the method with the strong-connection struc-ture as SC.
The parameter C in Eq.
(2) is pickedfrom10-2 to 104 using a 10-fold cross validationprocedure.3.3 Experimental ResultsMethods p r f-measureK-Means-COS 0.6885 0.6589 0.6734K-Means-JAC 0.6872 0.6616 0.6742K-Means-EUC 0.6899 0.6652 0.6774K-Means-EDIT 0.6325 0.6275 0.6300BCC-AC 0.7347 0.7263 0.7305BCC-SC 0.7406 0.7258 0.7331AC 0.8027 0.7911 0.7968SC 0.8213* 0.8187* 0.8200*Table2: the performance of all methods.
?*?
in-dicates significant difference at 0.05 level using apaired t-test.Table 2 presents the experimental results.
Com-pared with K-Means methods with differentmanually defined similarity measures, SCachieves at least 13.14% precision improvement,15.35% recall improvement, and 14.26% F-Measure improvement.
And AC achieves at least11.28% precision improvement, 12.59% recallimprovement, and 11.94% F-Measure improve-ment.
These results confirm that the similaritybetween two subtopic candidates is affected bymany factors and our methods can achieve moredesirable query subtopics by learning a similaritymeasure.Compared with BCC-AC and BCC-SC, SCachieves at least 8.07% precision improvement,9.29% recall improvement, and 8.69% F-Measure improvement.
And AC achieves at least6.21% precision improvement, 6.53% recall im-344provement, and 6.37% F-Measure improvement.These results confirm that the dependenciesamong the subtopic candidates within the samesubtopic are useful for learning a similaritymeasure for query subtopic mining.Compared with AC, SC achieves 1.86% preci-sion improvement, 2.76% recall improvement,and 2.32% F-Measure improvement.
These re-sults confirm that a subtopic candidate belongingto a given query subtopic does not need to simi-lar with all subtopic candidates within the givensubtopic.In order to understand which pairwise similari-ty feature is important for the problem of querysubtopic mining, we list the features and theirweights learned by SC, AC, and BCC (BinaryClassification Cluster) in Table 3.SC AC BCCCOS 0.08 0.04 0.19EUC ?1.74 ?1.07 ?0.73JAC 4.44 4.73 4.90EDIT ?1.60 ?1.01 ?0.48LEN ?1.34 ?0.91 ?1.07SUBSET 0.21 0.11 ?0.05UCOS 0.01 0.01 0.04UJAC 0.06 0.07 0.09Table 3: the features and their weights learned bythe different methods.As can be seen in Table 3, JAC has the largestimportance weight for mining query subtopics inthe three methods.
The URL-based features(UCOS and UJAC) have small importanceweight.
The reason is that clicked URLs aresparse in our query log and many long-tail sub-topic candidates in the same subtopic do notshare any common URLs.4 ConclusionsIn this paper, we propose an approach for miningquery subtopics from query log.
Compared withprevious approaches, our approach learns a simi-larity measure by explicitly modeling the de-pendencies among subtopic candidates within thesame subtopic.
Experimental results on real que-ries collected from a search engine log confirmour approach produces more desirable query sub-topics by using the learned similarity measure.AcknowledgmentsThe work is supported by the National NaturalScience Foundation of China under Grants no.61433015 and 61272324, and the National HighTechnology Development 863 Program of Chinaunder Grants no.
2015AA015405.
Moreover, wesincerely thank the reviewers for their valuablecomments.ReferencesN.
Bansal, A. Blum, and S. Chawla.
2002.
Correlationclustering.
In Machine Learning, 56, 89-113.A.
Z. Broder.
A taxonomy of web search.
2002.
InSigir Forum, 36:3-10.A.
Z. Broder, M. Fontoura, E. Gabrilovich, A. Joshi,V.
Josifovski, and T. Zhang.
2007.
Robust classifi-cation of rare queries using web knowledge.
InSIGIR, pp.
231-238.C.
L. A. Clarke, N. Craswell, and I. Soboroff.
2009.Overview of the trec 2009 web track.
In TREC?09,pp.
1-9.Y.
Hu, Y. Qian, H. Li, D. Jiang, J.Pei, and Q. Zheng.2012.
Ming query subtopics from search log data.In SIGIR?12, pp.
305-314.T.
Finley and T. Joachims.
2005.
Supervised cluster-ing with support vector machines.
In ICML, pp.217-224.B.
J. Frey and D. Dueck.
2007.
Clustering by passingmessages between data points.
In science,315(5814):972-976.Y.
Li, Z. Zheng, and H. K. Dai.
2005.
Kdd cup-2005report: facing a great challenge.
In SIGKDD Explor.Newsl., 7:91-99.L.
Li, Z. Yang, L. Liu, and M. Kitsuregawa.
2008.Query-url bipartite based approach to personalizedquery recommendation.
In AAAI?08, pp.
1189-1194.X.
Luo.
2005.
On Coreference resolution performancemetrics.
In HLT&EMNLP, pp.
25-32.F.
Radlinski, M. Szummer, and N. Craswell.
2010.Inferring Query Intent from Reformulations andClicks.
In WWW, pp.
1171-1172.R.
Song et, al.
2011.
Overview of the ntcir-9 intenttask, In NTCIR-9, pp.82-105.K.
Tsukuda, Z. Dou, and T. Sakai.
2013.
Microsoftresearch asia at the ntcir-10 intent task.
In NTCIR-10, pp.
152-158.J.
Wang, G. Tang, Y. Xia, Q. Hu, S. Na, Y. Huang, Q.Zhou, and F. Zheng.
2013.
Understanding the que-ry: THCIB and THUIS at ntcir-10 intent task.
InNTCIR-10, pp.
132-139.C.
J. Yu and T. Joachims.
2009.
Learning StructuralSVMs with Latent Variables.
In ICML, pp.
1169-1176A.
Yuille, and A. Rangarajan.
2003.
The concave-convex procedure.
In Neural Computation, 15, 915.MethodFeature345
