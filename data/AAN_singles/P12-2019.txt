Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 95?99,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsAutomatically Learning Measures of Child Language DevelopmentSam SahakianUniversity of Wisconsin - Madisonsahakian@cs.wisc.eduBenjamin SnyderUniversity of Wisconsin - Madisonbsnyder@cs.wisc.eduAbstractWe propose a new approach for the creation ofchild language development metrics.
A set oflinguistic features is computed on child speechsamples and used as input in two age predic-tion experiments.
In the first experiment, welearn a child-specific metric and predicts theages at which speech samples were produced.We then learn a more general developmen-tal index by applying our method across chil-dren, predicting relative temporal orderings ofspeech samples.
In both cases we compareour results with established measures of lan-guage development, showing improvements inage prediction performance.1 IntroductionThe rapid childhood development from a seem-ingly blank slate to language mastery is a puzzlethat linguists and psychologists continue to ponder.While the precise mechanism of language learningremains poorly understood, researchers have devel-oped measures of developmental language progressusing child speech patterns.
These metrics pro-vide a means of diagnosing early language disor-ders.
Besides this practical benefit, precisely mea-suring grammatical development is a step towardsunderstanding the underlying language learning pro-cess.Previous NLP work has sought to automate thecalculation of handcrafted developmental metricsproposed by psychologists and linguists.
In this pa-per, we investigate a more fundamental question:Can we use machine learning techniques to createa more robust developmental measure itself?
If so,how well would such a measure generalize acrosschildren?
This last question touches on an underly-ing assumption made in much of the child languageliterature?
that while children progress grammati-cally at different rates, they follow fixed stages intheir development.
If a developmental index auto-matically learned from one set of children could beaccurately applied to others, it would vindicate thisassumption of shared developmental paths.Several metrics of language development havebeen set forth in the psycholinguistics literature.Standard measures include Mean Length of Utter-ance (MLU) (Brown, 1973)?
the average length inmorphemes of conversational turns, Index of Pro-ductive Syntax (IPSYN) (Scarborough, 1990)?
amulti-tiered scoring process where over 60 individ-ual features are counted by hand and combined intotiered scores, and D-Level (Rosenberg et al, 1987;Covington et al, 2006)?
a score for individual sen-tences based on the observed presence of key syn-tactic structures.
Today, these hand-crafted metricspersist as measurements of child language develop-ment, each taking a slightly different angle to assessthe same question: Exactly how much grammaticalknowledge does a young learner possess?NLP technology has been applied to help au-tomate the otherwise tedious calculation of thesemeasures.
Computerized Profiling (CP) (Long andChannell, 2001) is a software package that producessemi-automated language assessments, using part-of-speech tagging and human supervision.
In re-sponse to its limited depth of analysis and the neces-sity for human supervision in CP, there have since95D-LevelArticleCount?Be?CountFn./ContentPrep.CountWordFreq.DepthMLUAdam 0.798 0.532 0.817 0.302 0.399 0.371 0.847 0.855Abe 0.633 0.479 0.591 0.144 0.269 0.413 0.534 0.625Ross 0.252 0.153 -0.061 0.125 0.314 0.209 0.134 0.165Peter 0.371 0.429 0.781 0.562 0.638 0.657 0.524 0.638Naomi 0.812 0.746 0.540 0.652 0.504 0.609 0.710 0.710Sarah 0.829 0.550 0.733 0.382 0.654 0.570 0.731 0.808Nina 0.824 0.758 0.780 0.560 0.451 0.429 0.780 0.890Mean: 0.646 0.521 0.597 0.390 0.461 0.465 0.609 0.670Table 1: ?
of each feature versus time, for each individualchild.
In this and all following tables, traditional devel-opmental metrics are shaded.been implementations of completely automated as-sessments of IPSYN (Sagae et al, 2005) and D-Level (Lu, 2009) which take advantage of automaticparsing and achieve results comparable to manualassessments.
Likewise, in the ESL domain, Chenand Zechner (2011) automate the evaluation of syn-tactic complexity of non-native speech.Thus, it has been demonstrated that NLP tech-niques can compute existing scores of language pro-ficiency.
However, the definition of first-languagedevelopmental metrics has as yet been left up to hu-man reasoning.
In this paper, we consider the au-tomatic induction of more accurate developmentalmetrics using child language data.
We extract fea-tures from longitudinal child language data and con-duct two sets of experiments.
For individual chil-dren, we use least-squares regression over our fea-tures to predict the age of a held-out language sam-ple.
We find that on average, existing single met-rics of development are outperformed by a weightedcombination of our features.In our second set of experiments, we investigatewhether metrics can be learned across children.
Todo so, we consider a speech sample ordering task.We use optimization techniques to learn weight-ings over features that allow generalization acrosschildren.
Although traditional measures like MLUand D-level perform well on this task, we find thata learned combination of features outperforms anysingle pre-defined developmental score.2 DataTo identify trends in child language learning weneed a corpus of child speech samples, which we02,2504,5006,7509,00014 21 28 35 42 49 56 63 70 77UtterancesAge (months)AdamAbeRossPeterNaomiSarahNinaFigure 1: Number of utterances across ages ofeach child in our corpus.
Sources: Nina (Suppes,1974), Sarah (Brown, 1973), Naomi (Sachs, 1983),Peter (Bloom et al, 1974; Bloom et al, 1975),Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) andAdam (Brown, 1973)take from the CHILDES database (MacWhinney,2000).
CHILDES is a collection of corpora frommany studies of child language based on episodicspeech data.
Since we are interested in developmentover time, our corpus consists of seven longitudinalstudies of individual children.
Data for each childis grouped and sorted by the child?s age in months,so that we have a single data point for each monthin which a child was observed.
The size of our dataset, broken down by child, is shown in Figure 1.We take advantage of automatic dependencyparses bundled with the CHILDES transcripts(Sagae et al, 2007) and harvest features that shouldbe informative and complementary in assessinggrammatical knowledge.
We first note three stan-dard measures of language development: (i) MLU,a measure of utterance length, (ii) mean depth of de-pendency parse trees, a measure of syntactic com-plexity similar to that of Yngve (1960), and (iii) D-level, a measure of linguistic competence based onobservations of syntactic constructions.Beyond the three traditional developmental met-rics, we record five additional features.
We counttwo of Brown?s (1973) obligatory morphemes ?
ar-ticles and contracted auxiliary ?be?
verbs ?
as wellas occurrences of any preposition.
These countedfeatures are normalized by a child?s total numberof utterances at a given age.
Finally, we includetwo vocabulary-centric features: Average word fre-96D-Level Depth MLU All FeaturesAdam 14.037 14.149 11.128 14.175Abe 34.69 44.701 34.509 39.931Ross 329.64 336.612 345.046 244.071Peter 23.58 13.045 8.245 24.128Naomi 24.458 28.426 34.956 45.036Sarah 12.503 20.878 13.905 6.989Nina 7.654 6.477 4.255 3.96Mean 63.795 66.327 64.578 54.041Table 2: Mean squared error from 10-fold cross valida-tion of linear regression on individual children.
The low-est error for each child is shown in bold.quency (i.e.
how often a word is used in a stan-dard corpus) as indicated by CELEX (Baayen et al,1995), and the child?s ratio of function words (deter-miners, pronouns, prepositions, auxiliaries and con-junctions) to content words.To validate a developmental measure, we rely onthe assumption that a perfect metric should increasemonotonically over time.
We therefore calculateKendall?s Tau coefficient (? )
between an ordering ofeach child?s speech samples by age, and an order-ing by the given scoring metric.
The ?
coefficientis a measure of rank correlation where two identicalorderings receive a ?
of 1, complete opposite order-ings receive a ?
of -1, and independent orderings areexpected to receive a ?
of zero.
The ?
coefficientsfor each of our 8 features individually applied to the7 children are shown in Table 1.We note that the pre-defined indices of languagedevelopment ?
MLU, tree depth and D-Level ?perform the ordering task most accurately.
To illus-trate the degree of variance between children andfeatures, we also include plots of each child?s D-Level and contracted auxiliary ?be?
usage in Figure2.3 ExperimentsLearning Individual ChildMetrics Our first taskis to predict the age at which a held-out speech sam-ple was produced, given a set of age-stamped sam-ples from the same child.
We perform a least squaresregression on each child, treating age as the depen-dent variable, and our features as independent vari-ables.
Each data set is split into 10 random folds of90% training and 10% test data.
Mean squared erroris reported in Table 2.
On average, our regressionMLU All Features MLU & Fn.
/ Content0.7456 0.7457 0.7780Table 3: Average ?
of orderings produced by MLU (thebest traditional index) and our learned metric, versus truechronological order.
Highest ?
is shown in bold.achieves lower error than any individual feature byitself.Learning General Metrics Across Children Toproduce a universal metric of language developmentlike MLU or D-Level, we train on data pooled acrossmany children.
For each of 7 folds, a single child?sdata is separated as a test set while the remainingchildren are used for training.
Since Ross is the onlychild with samples beyond 62 months, we do not at-tempt to learn a general measure of language devel-opment at these ages, but rather remove these datapoints.Unlike the individual-child case, we do not pre-dict absolute ages based on speech samples, as eachchild is expected to learn at a different rate.
Instead,we learn an ordering model which attempts to placeeach sample in its relative place in time.
The modelcomputes a score from a weighted quadratic combi-nation of our features and orders the samples basedon their computed scores.
To learn the parametersof the model, we seek to maximize the Kendall ?between true and predicted orderings, summed overthe training children.
We pass this objective functionto Nelder-Mead (Nelder and Mead, 1965), a stan-dard gradient-free optimization algorithm.
Nelder-Mead constructs a simplex at its initial guess of pa-rameter values and iteratively makes small shifts inthe simplex to satisfy a descent condition until a lo-cal maximum is reached.We report the average Kendall ?
achieved by thisalgorithm over several feature combinations in Ta-ble 3.
Because we modify our data set in this ex-periment, for comparison we also show the averageKendall ?
achieved by MLU on the truncated data.4 DiscussionOur first set of experiments verified that we canachieve a decrease in mean squared error over ex-isting metrics in a child-specific age prediction task.However, the results of this experiment are skewed970 1 2020406080100 Adam0 1 2020406080100 Abe0 1 2020406080100 Ross0 1 2020406080100 Peter0 1 2020406080100 Naomi0 1 2020406080100 Sarah0 1 2020406080100 Nina0 0.1 0.20204060801000 0.1 0.20204060801000 0.1 0.20204060801000 0.1 0.20204060801000 0.1 0.20204060801000 0.1 0.20204060801000 0.1 0.2020406080100Figure 2: Child age plotted against D-Level (top) and counts of contracted auxiliary ?be?
(bottom) with best fit lines.Since our regression predicts child age, age in months is plotted on the y-axis.in favor of the learned metric by the apparent diffi-culty of predicting Ross?s age.
As demonstrated inFigure 2, Ross?s data exhibits major variance, andalso includes data from later ages than that of theother children.
It is well known that MLU?s per-formance as a measure of linguistic ability quicklydrops off with age.During our first experiment, we also attempted tocapture more nuanced learning curves than the lin-ear case.
Specifically, we anticipated that learningover time should follow an S-shaped curve.
Thisfollows from observations of a ?fast mapping?
spurtin child word learning (Woodward et al, 1994), andthe idea that learning must eventually level off asmastery is attained.
To allow our model to capturenon-linear learning rates, we fit logit and quadraticfunctions to the data.
Despite the increased free-dom, only Nina?s predictions benefited from thesemore complex models.
With every other child, thesefunctions fit the data to a linear section of the curveand yielded much larger errors than simple linearregression.
The preference towards linearity maybe due to the limited time span of our data.
Withhigher ages, the leveling off of linguistic perfor-mance would need to be modeled.In our second set of experiments, we attemptedto learn a general metric across children.
Here wealso achieved positive results with simple methods,just edging out established measures of language de-velopment.
The generality of our learned metricsupports the hypothesis that children follow simi-lar paths of language development.
Although ourlearned solution is slightly more favorable than pre-existing metrics, it performs very little learning.
Us-ing all features, learned parameter weights remain ator extremely close to the starting point of 1.Through trial and error, we discovered we couldimprove performance by omitting certain features.In Table 3, we report the best discovered featurecombination including only two relatively uncorre-lated features, MLU and function/content word ra-tio.
If downweighting some features yields a betterresult, we would expect to discover that with our op-timization algorithm, but this evidently not the case,perhaps due to our limited sample of 7 children.The fact that weights move so little suggests thatour best result is stuck in a local maximum.
Toinvestigate this, we also experimented with Differ-ential Evolution (Storn and Price, 1997) and SVM-ranking (Joachims, 2002), the former a global op-timization technique, and the latter a method de-veloped specifically to learn orderings.
Althoughthese algorithms are more willing to adjust param-eter weights and theoretically should not get stuckin local maxima, they are still edged out in perfor-mance by Nelder-Mead.
It may be that the earlystopping of Nelder-Mead serves as a sort of smooth-ing in this very small data-set of 7 children.Our improvements over hand-crafted measuresof language development show promise.
In thecase of individual children, we outperform existingmeasures of development, especially past the earlystages of development when MLU ceases to corre-late with age.
Our attempts to learn a metric acrosschildren met with more limited success.
However,when we restricted our regression to two of the leastcorrelated features, MLU and the function/contentword ratio, we were able to beat manually createdmetrics.
These results suggest that more sophisti-cated models and techniques combined with moredata could lead to more accurate metrics as well asinsights into the language learning process.98ReferencesR.H.
Baayen, R. Piepenbrock, and L. Gulikers.
1995.The CELEX lexical database (release 2)[cd-rom].Philadelphia, PA: Linguistic Data Consortium, Uni-versity of Pennsylvania [Distributor].L.
Bloom, L. Hood, and P. Lightbown.
1974.
Imitation inlanguage development: If, when, and why.
CognitivePsychology, 6(3):380?420.L.
Bloom, P. Lightbown, L. Hood, M. Bowerman,M.
Maratsos, and M.P.
Maratsos.
1975.
Structure andvariation in child language.
Monographs of the Soci-ety for Research in Child Development, pages 1?97.R.
Brown.
1973.
A First Language: The Early Stages.Harvard U. Press.M.
Chen and K. Zechner.
2011.
Computing and evaluat-ing syntactic complexity features for automated scor-ing of spontaneous non-native speech.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics, pages 722?731.M.A.
Covington, C. He, C. Brown, L. Naci, and J. Brown.2006.
How complex is that sentence?
a proposed re-vision of the Rosenberg and Abbeduto D-level scale.Research Report, AI Center, University of Georgia.T.
Joachims.
2002.
Optimizing search engines us-ing clickthrough data.
In Proceedings of the EighthACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 133?142.ACM.S.A.
Kuczaj.
1977.
The acquisition of regular and irreg-ular past tense forms.
Journal of Verbal Learning andVerbal Behavior, 16(5):589?600.S.H.
Long and R.W.
Channell.
2001.
Accuracy offour language analysis procedures performed automat-ically.
American Journal of Speech-Language Pathol-ogy, 10(2):180.X.
Lu.
2009.
Automatic measurement of syntactic com-plexity in child language acquisition.
InternationalJournal of Corpus Linguistics, 14(1):3?28.B.
MacWhinney.
2000.
The CHILDES project: Tools foranalyzing talk, volume 2.
Psychology Press.J.A.
Nelder and R. Mead.
1965.
A simplex methodfor function minimization.
The Computer Journal,7(4):308?313.S.
Rosenberg, L. Abbeduto, et al 1987.
Indicators oflinguistic competence in the peer group conversationalbehavior of mildly retarded adults.
Applied Psycholin-guistics, 8(1):19?32.J.
Sachs.
1983.
Talking about the there and then: Theemergence of displaced reference in parent-child dis-course.
Childrens Language, 4.K.
Sagae, A. Lavie, and B. MacWhinney.
2005.
Auto-matic measurement of syntactic development in childlanguage.
In Proceedings of the 43rd Annual Meetingon Association for Computational Linguistics, pages197?204.
Association for Computational Linguistics.K.
Sagae, E. Davis, A. Lavie, B. MacWhinney, andS.
Wintner.
2007.
High-accuracy annotation andparsing of CHILDES transcripts.
In Proceedings ofthe Workshop on Cognitive Aspects of ComputationalLanguage Acquisition, pages 25?32.
Association forComputational Linguistics.H.S.
Scarborough.
1990.
Index of productive syntax.Applied Psycholinguistics, 11(1):1?22.R.
Storn and K. Price.
1997.
Differential evolution?asimple and efficient heuristic for global optimizationover continuous spaces.
Journal of Global Optimiza-tion, 11(4):341?359.P.
Suppes.
1974.
The semantics of children?s language.American Psychologist, 29(2):103.A.L.
Woodward, E.M. Markman, and C.M.
Fitzsimmons.1994.
Rapid word learning in 13-and 18-month-olds.Developmental Psychology, 30(4):553.V.H.
Yngve.
1960.
A model and an hypothesis for lan-guage structure.
Proceedings of the American Philo-sophical Society, 104(5):444?466.99
