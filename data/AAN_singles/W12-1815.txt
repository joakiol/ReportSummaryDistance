NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 33?36,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsA Simulation-based Framework for Spoken Language Understanding and Action Selection in Situated Interaction  David Cohen Ian Lane Carnegie Mellon University Carnegie Mellon University Nasa Research Park Nasa Research Park Moffett Field, CA Moffett Field, CA david.cohen@sv.cmu.edu  lane@cs.cmu.edu  AbstractThis paper introduces a simulation-based framework for performing action selection and understanding for interactive agents.
By simulating the objects and actions relevant to an interaction, an agent can semantically ground natural language and interact consid-erately and on its own initiative in situated environments.
The framework proposed in this paper leverages models of the environ-ment, user and system to predict possible fu-ture world states via simulation.
It leverages understanding of spoken language and multi-modal input to estimate the state of the ongo-ing interaction and select actions based on the utility of future outcomes in the simulated world.
In this paper we introduce this frame-work and demonstrate its effectiveness for in-car navigation.
1 Introduction Speech and multimodal interactive systems have many challenges to overcome before they can ef-fectively interact with users in the real world.
The-se challenges include semantically grounding vague and ambiguous natural language utterances, understanding the user?s knowledge and capabili-ties, and acting on their own initiative to plan and take appropriate actions in complex environments.
To overcome these challenges, interactive agents require more than just models of the environment, user goals, and attention, they need the ability to infer the consequences of both their and the users?
actions ?
a capability which simulation provides.
For each given task, an agent must plan the best way to carry it out.
In many cases, a simple set of context-dependent behavior templates will not be sufficient.
For example, if an in-car navigation as-sistant is trying to direct a driver to his destination,it should probably not give directions within the driver?s own neighborhood, with which he is al-ready familiar.
However, it should inform the driv-er if there is road construction in the area of which he/she is unaware.
Alternatively, if the driver is having an important conversation and the cost of the detour is outweighed by the cost of interrupting the conversation, perhaps the system should re-main quiet.
Understanding all the contexts that af-fect interaction is difficult and defining a set of heuristics to choose the appropriate behavior will quickly become unmanageable.
An agent in the real world will be faced with complicated situa-tions that will require planning and an understand-ing of the effects its actions will have.
To capture the full context necessary to perform understanding and planning in situated interaction, this paper argues for a unified model of the envi-ronment, the user?s knowledge, attention and goals, and the simulated consequences of different courses of action.
2 Related Work Early work in deep natural language understand-ing (Schank and Abelson, 1977; Wilensky, 1983) formed cognitive theories and developed software to reinforce the idea that understanding an agent?s words requires an understanding of that agent?s plans, goals, and planning mechanisms.
Other work (Allen and Perrault, 1980) focused on identi-fying these plans and goals from the partial infor-mation available; interpreting speech acts as primitive actions in a STRIPS planner (Fikes and Nilsson, 1971), and using heuristics to determine an agent?s plan based on their speech acts.
Traum (1994) adopted a similar definition of speech acts, and developed a computational theory of ground-ing whereby multiple agents come to understand each other?s plans and meaning.33Figure 1: Overview of the proposed simulation-based understanding and action selection framework.
Previous work on considerate mixed-initiative systems has placed an emphasis on modeling the user?s mental state, particularly attention and cog-nitive loading.
Horvitz et al (2003) treat attention as critical to reasoning about the value of taking action and potentially disrupting users.
Multiple modalities such as speech and gesture recognition, as well as mouse and keyboard behavior all con-tribute to their models of attention.
Their work also stressed the importance of attention cues in effec-tive collaborative communication.
Other work from the same author (Horvitz, 1999) probabilisti-cally tracked a belief in the user?s goal based on attentional cues, specifically trying to determine if a behavior from the system was desired.
This work all reinforces the idea that close attention to the user?s mental state must be paid to act considerate-ly with mixed initiative, but never attempts to en-dow a system with the ability to reason about the consequences of its actions.
There are several existing paradigms for spoken dialogue systems.
RavenClaw (Bohus and Rud-nicky, 2009) uses a human-engineered task tree to guide the logic of an interaction, which allows for well-understood behavior, but does not permit the flexibility of planning needed for complex, dynam-ic interaction.
The collaborative agent framework, COLLAGEN (Rich and Sidner, 1996), specifies the data structures for recipes and attention models based off the SharedPlan collaborative discourse framework.
The framework proposed by Allen and et al (2002) is built on a collaborative discourse framework similar to SharedPlan, and is similar to our work in its situation theoretic world model and focus on user goal and plan modeling.
However, to the best of our knowledge, these frameworks have never been successfully applied to a situated agent in a dynamic environment with many interacting objects and a wealth of multi-modal input as isavailable within an in-car assistant environment.
It is in these situations that we believe our framework will demonstrate its applicability compared to prior approaches.
3 A Simulation-based Framework for Un-derstanding Situated Interaction1 In this paper, we propose a framework in which an interactive agent leverages a model of the ongo-ing situated interaction and simulations of possible future scenarios to perform understanding and de-cision-making (Figure 1).
The model supports complex inference about natural language as well as other modalities of input, and provides a suita-ble environment for the system to evaluate possible courses of action.
As an example, we evaluated the effectiveness of this framework for planning and interacting in an in-car navigation assistant.
Simulated Interaction and Environment The system models its environment in terms of an object-oriented probabilistic model that allows for multiple simultaneous actions.
It is assumed that the model is an incomplete view of the world, and there are objects that the model is unaware of.
In-cluded in this model is the set of primitive actions all the objects in the world can take, defined by their pre-conditions and post-conditions.
Through simulation, the system can project the current world state forward in time in an attempt to predict possible futures.
Within each simulated scenario, the system, user, and any number of other actors will interact.
At each time step, every object selects a primitive action, which is applied to the world if its pre-conditions have been met.
1 An initial version of the simulator used in the work can be download from: http://speech.sv.cmu.edu/SimInteraction34Programs for Modeling High-Level Actions In order to make inferences about the long-term behavior of objects in the simulator, plans and high-level actions need a representation within the simulator.
To do this, programs are defined for several realistic behaviors for each actor.
These programs are a specific form of options (Sutton et al, 1999), which in the context of a Markov Deci-sion Process are closed-loop policies for choosing action over an extended period of time.
In the current implementation, programs are fi-nite state machines, which are resumed at each time interval, changing state based on the actor?s internal state until a primitive action is selected.
Modeling User Knowledge and Awareness An actor carrying out a program will choose a dif-ferent sequence of actions depending on their in-ternal mental state.
That is why the world model must contain this information to make accurate predictions.
In particular, a user?s knowledge and attention play critical roles in their decision-making, and thus must be modeled.
Tracking and Parsing The tracker maintains the current world model in-cluding the set of objects that are relevant for simulation and estimated distributions over uncer-tain variables such as the user?s mental state and the programs being run by all relevant objects.
The tracker is responsible for initiating simulations to project the situation model into the future.
The tracker also manages and interfaces to a set of mini-parsers which interpret input across multiple modalities in various ways.
In the proposed framework, the tracker also uses information from the parsers to add new objects to the world model, and modify the parameters of the objects already in the model.
Additional parsers can be spawned based on simulation results.
For example, if a simulated scenario predicts the car running out of gas, the tracker might spawn a new parser to interpret the driver?s awareness of their gas level based on gaze.
Utility Estimation and Action Selection The desirability of every simulated scenario is de-termined by a utility score, defined by the system designer to maximize the system?s usefulness.
The system includes itself and its own possible pro-grams in each simulation it runs, and picks theTable 1: Description of three evaluation tasks.
TaskID Task Description 1 Destination is a business in downtown area, mostly a straight path as a warm-up task.
2 Destination is a residence in Palo Alto, in-sufficient gas to get to destination.
3 Destination is a residence in Mountain View, retrace much of the path from Task 2.
Table 2: Average number of system turns for base-line and the proposed system.
System turns include questions, notifications, and instructions.
TaskID Novice Intermediate Expert 1 7.0 7.0 3.0 2 13.0 15.8 9.0 3 12.0 12.8 9.0   program that gives the best expected utility.
4 Demonstration Example We demonstrate the effectiveness of the pro-posed framework for an in-car navigation assistant.
We tested this demonstration with ten test subjects each navigating through three the tasks listed in Table 1.
The subjects navigated through Mountain View and Palo Alto, California in Google EarthTM while a supervisor observed their progress, entered it into the system and relayed messages between the subject and system.
Some subjects had been in the area only a few times and some were current residents of Mountain View and neighboring cities.
Based off the subjects?
initial self-assessment, the system was given one of three different starting familiarity map estimates - novice, medium, and expert.
These initial estimates reflected our intui-tive assessment of the likelihood that a driver would know major streets and neighborhoods.
For users with different levels of familiarity we counted the number of system turns, which include questions, notifications, and instructions required to complete the task.
These counts are shown in Table 2 show a decrease in the number of system turns across all tasks for users who were more fa-miliar with the area.
This is a direct result of the system?s ability to direct these users to waypoints they were familiar with along the route, saving un-necessary directions.
Example interactions ob-tained from the experiments are shown in Figure 1.35Figure 2: Sample interactions from subjects with different starting familiarity estimates.
5 Conclusions This paper introduces a simulation-based frame-work for performing action selection and under-standing in an interactive agent.
The framework uses a simulator to predict possible future world states incorporating and updating models of the environment, user and system based on observed input.
Understanding of spoken language and mul-timodal input is performed leveraging the past, current and future world states in the simulator.
Action selection is performed based on the utility of future world states and the expected user goal.
In this paper we introduce this framework and demonstrate its effectiveness for in-car navigation.References  James Allen, Nate Blaylock, George Ferguson 2002.
A Problem Solving Model for Collaborative Agents.
Proc.
AAMAS.
James F. Allen and C. Raymond Perrault.
1980.
Analyz-ing Intention in Utterances.
Artificial Intelligence.
Dan Bohus and Eric Horvitz.
2011.
Multiparty Turn Taking in Situated Dialog: Study, Lessons, Direc-tions Proc.
SIGdial.Dan Bohus and Alexander I. Rudnicky.
2009.
The RavenClaw Dialog Management Framework: Archi-tecture and Systems.
Computer Speech and Lan-guage.
Richard E. Fikes and Nils J. Nilsson 1971.
STRIPS: A New Approach to the Application of Theorem Prov-ing to Problem Solving.
IJCAI.
Eric Horvitz.
1999.
Principles of Mixed-Initiative User Interfaces Proc.
SIGCHI.
Eric Horvitz, Carl Kadie, Tim Paek, David Hovel.
2003.
Models of Attention in Computing and Communica-tion: From Principles to Applications.
Communica-tions of ACM.
Charles Rich and Candace L. Sidner 1996.
COLLAGEN: When Agents Collaborate with Peo-ple.
Mitsubishi Electric Research Laboratories Inc. Roger Schank and Robert Abelson.
1977.
Scripts Plans Goals and Understanding: an Inquiry into Human Knowledge Structures.
Lawrence Erlbaum Associ-ates, Inc., Publishers.
Richard S. Sutton, Doina Precup, Satinder Singh.
1999.
Between MDPs and semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning.
Artificial Intelligence.
David R. Traum.
1994.
A Computational Theory of Grounding in Natural Language Conversation Ph.D. Thesis Robert Wilensky.
1983.
Planning and Understanding: A Computational Approach to Human Reasoning.
The Addison-Wesley series in artificial intelligence.36
