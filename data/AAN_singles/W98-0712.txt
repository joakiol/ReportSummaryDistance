IIIIIIIIIIIIIIIAugmenting WordNet-like lexical resources with distributional evidence.An application-oriented perspective"Simonetta Montemagni, Vito PirrelliIstituto di Linguistica Computazionale, CNRVia della Faggiola 32, Pisa, ITALYe-mail: {simo,vito} @ilc.pi.cnr.itAbstractThe paper deals with the issue of how and to what extentWordNet-like resources provide the necessary informationfor an assessment of semantic similarity which is useful forpractical applications.
The general point is made thattaxonomical information should be complemented withdistributional evidence.
The claim is substantiated throughexperimental ~t8 and an illustration of a word sensedisambiguation system (SENSE) capable of usingcontextually-relevant semantic similarity.1.
IntroductionAssessment of semantic similarity has proved to be beessential for a variety of Natural Language Processing(NLP) tasks, including syntactic disambiguation (eitherstructural or functional), word sense disambiguation,selection of appropriate translation equivalent,assessment of lexical cohesion in texts for automaticsummarisation, query expansion and documentindexing in Information Retrieval.Typically, the semantic similarity between wordsis computed on the basis of taxonomical relationshipssuch as hyperonymy.
Given two word senses W a andW:, their similarity is captured as a function of theirbelonging to more general semantic classes.
Theapproach presupposes prior availability of independenthierarchically-structured repositories of lexico-semantic information such as WordNet.
An interestingissue here is to evaluate how nsefi~l this type ofresource is in capm.,-mg semantic similarity at thedesirable level of granularity, given the requirements ofthe abovelisted applications.As a general comment, he taxonomical pproachto semantic similarity tends to neglect the role oflinguistic context as a perspectivising factor affectingthe perception of a semantic similarity between any twowords considered.
There is substantial experimentalevidence supporting the view that human similarityjudgements are affected by the pressure of contextualfactors (see, among others, Goldstone et al 1997):intuitively, while candle and barbecue would scorepoorly on semantic proximity if consideredindependently of their use in context, their occurence inexpressions such as light a candle, light a barbecuewould immediately throw in relief a (possibly weak,but nonetheless contextually relevant) semanticassociation between the two, established by theirconnection with the process of burning.
This?
The work reported in this paper was joindy carriedout by the authors within the SPARKLE project (LE-2111).
For the specific concerns of the Italian Academyonly, S. Montemagni is responsible for sections I, 2,3.2, 3.3, and V. Pirrelli for 3.1, 4 and 5.association is relevant insofar as it plays a role incarving out the set of plausible objects of the verb light.Taxonomies are not in principle incapable of capturingcross-classifications like those based on relational orrole properties uch as "being a product" or "being atypical object of event/process".
There are allowancesin the latest Wordnet version (1.6) for defining pointersfrom each concept o = say = nouns representing itsparts, or from nouns to verbs to represent functionsetc., although the latter are not actually implementedyet.
Nonetheless, it is not obvious how many of thesecross-classificatory dimensions should be overlaid on ataxonomy to attain the desirable level of context=sensitivity required by real applications.
From anapplication-oriented perspective, there is the furtherproblem of how it is possible to regiment their role andrelevance as a function of context variation.As a somewhat radical alternative to taxonomicalrelationships, other ways of measuring semanticsimilarity based on distributional evidence have beenput forward in the literature (see, among others, Brownet al 1991, Gale et al 1992, Pereira and Tishby 1992),which emphasise the role played by context in thisgame.
These approaches compute the semanticsimilarity between W z and W, on the basis of the extentto which W,/W,'s average contexts of use overlap.Here, the context is generally defined as an n-wordwindow centred on Wl/W:.
The method rests on theassumption that words entering into the samesyntagmatic relation with other words are perceived assemantically similar.
The method has a potential forcapturing word similarities grounded on contextualeffects of the sort sketched out above, although it mayoften happen that, given two instances of the sameword W in a text and their corresponding contextwindows, very few token words are found in bothwindows.
Strategies to alleviate this sparse dataproblem have been described for word sensedisambiguation (e.g.
Schiitze 1992): they def'me thecontext no longer in terms of the immediateneighbouring words, but rather as the set of words thatneighbourmg words normally consort with.
Aninteresting issue here is whether "context cascades" ofthis sort are still constrained enough to be able tocapture effects of context=sensitive similarity.
Theamount of data that this method requires is also anissue.Be that as it may, it is still to be shownconclusively that any of the NLP tasks listed at theoutset really requires uch a f'me grained measure ofcontext-sensitive semantic similarity.
In this paper, wetend that an ideal lexical resource aimed at beingas a yardstick for measuring word sense similarityIIiIIIIIIIIIIIIIat the level of granularity required by most NLPapplications hould strive to complement the lexico-semantic knowledge typically embedded ina WordNet-like resource with distributional evidence of some kind.This is argued on grounds that: i) contextual factorsplay an important role in assessing the semanticsimilarity between words and ii) this is what mostapplications require.
Both points will be dealt with insome detail in the context of the problem of classifyingthe typical complements lexically selected by a givenverb sense.
We will show that verbs' selectionalpreferences cannot always be neatly expressed in termsof taxonomy nodes/classes, but rather cut across thetaxonomy in a seemingly erratic way, straggling forseveral relatively unrelated nodes.
Close examinationof real data shows that different verb senses selectdifferent classes of complements according to differentdimensions of semantic similarity, to such an extentthat it soon becomes impossible to provide an effectiveaccount of these dimensions independently of the verbsense in question.2.
Taxonomy-based semantic similarity: generalbackgroundDifferent methods have been put forward in theliterature to assess emantic similarity in relation to ahierarchically structured lexical resource such asWordNet.
In most of them (see among others Rada etal.
1989 and Lee et al 1993), assessment of semanticsimilarity is carried out on the basis of hyperonymy(IS-A) links.
More concretely, semantic similarity isevaluated by measuring the distance between thetaxonomical nodes corresponding to the items beingcompared: the shorter the path from one node toanother, the more similar the corresponding items.Given multiple paths, the shortest path is taken as theone involving the stronger similarity.A number of criticisms have been levelled at thisapproach.
Some scholars pointed out that IS-A links aresimply not sufficient.
Nagao (1992), for instance, usesboth hyperonymy and synonymy links to computesemantic similarity, and assigns higher similarityscores to synonymy relationships.
Other scholars haveattempted tofurther widen the range of relationships onthe basis of which semantic similarity is computed; see,among others, Niremburg et al (1993) who also usemorphological information and antonyms.A more technical problem faced by the path-length similarity method has to do with the underlyingassumption that links in a taxonomy represent uniformdistances between odes.
As often pointed out, this isnot always the case: in real taxonomies, the "distance"covered by individual taxonomic links is variable, sincecertain sub-taxonomies can be much denser thanothers.
To overcome the problem of varying linkdistances, Agirre and Rigau (1996) propose a semanticsimilarity measure (referred to as "conceptual density")which is sensitive to i) the length of the path, ii) thedepth of the nodes in the hierarchy (deeper nodes areranked closer) and iii) the density of nodes in the sub-hierarchies (concepts involved in a denser subhierarchyare ranked closer than those in a more sparse region).In a similar vein, Resnik (1995) defines a taxonomicsimilarity measure which dispenses with the pathlength approach and is based on the notion ofinformation content- Under his view, semanticsimilarity between two words is represented by the -log P(C) value of  the most informative concept Csubsuming both words in a semantic taxonomy, whereP(C) is a maximum likelyhood estimate of C'sprobability of occurrence ina reference corpus.Despite their differences, all these methodsaddress the issue of how lexico-semantic hierarchieslike WordNet should best be exploited, but do notquestion their suitability for measuring word semanticproximity.
This issue will he dealt with in some detailin the following section.3.
Taxonomy-based semantic similarity at work: anillustrative exampleIn this section, the problem is tackled of how and towhat extent a WordNet-like lexical resource canprovide the information eeded to assess semanticsimilarity of words in context, in connection with thetask of of semantically characterising the class oftypical collocates of a given verb sense.
In section 3.
I ataxonomy-based account of selectional preferences ofdifferent senses of the same verb is illustrated.
This iscomplemented with a comparative study of intersectingsets of typical collocates of different verb senses(section 3.2).3.1 A taxonomy-based account of selectionalpreferences of verbsThis section illustrates the modelling of the selectionalpreferences ofdifferent senses of a verb according to ataxonomy-based view.
To exemplify, we consider herethe different senses of the Italian verb accenderetogether with the sets of their typical object collocates.These typical objects are projected onto a semantichierarchy to evaluate whether and to what extent heverb's selectional preferences are captured throughtaxonomical generalizations of some kind.According to the Collins Italian-Englishdictionary (1985), the Italian verb accendere has, in itstransitive reading, the following four senses, eachaccompanied by an illustrative set of its typical objects:1) light when it takes as a direct object nouns like fiammifero,candela, sigaretta, caraino (respectively, 'match, candle,cigarette, fireplace')2) mrn on.
switch on, when the object is a device such as radio,luce, lampada, gas, motore (respectively, "radio.
light, lamp, gascooker, engine')88II1IIiIIIIIIIIIIIII3) raise, if the object is some kind of feeling such as speranza,desiderio ('hope, desire')4) open, if the object is a bank-related entity such as conto, debito,ipoteca 'bank account, debt, mortgage'Given the source of lexical information consideredhere, each sense is characterised in terms of itsappropriate English translation equivalent.
The tree-like structure reported below illustrates the result ofprojecting Collins' typical object collocates of each setonto WordNet.I ' |Figure I Objects of accendere: semantic hierarchyShadowed boxes (typically but not necessarily treeleaves) represent he actually occurring collocates,which are accompanied byan indication of the sense ofaccendere with which they are associated in thedictionary.
Dotted lines in the tree show that the linkbetween the connected nodes is not direct, i.e.
that thetaxonomical path includes intermediate nodes.The fast thing to note in this context is thatcollocates of different senses exhibit a differentpropensity to cluster together in the semantic hierarchy.The selectional preferences of senses 3 ('raise') and 4('open') nicely fall into distinct branches of thetaxonomy.
The class of typical objects of sense 3 canappropriately be described as a <feeling>, while<possession> being a suitable hyperonym of all andonly objects of sense 4.
Yet, the same taxonomy fails topart the selectional preferences ofsense 1 ('light') fromthose of sense 2 ('switch on').
In the latter case, objectcollocates of both senses are categorised as an<artifact>, a notion which is far too general to tell thecollocates of sense 1 of accendere from those of itssense 2, as illustrated by the internal structure of thesub-hierarchy of artifact objects of accenderediagrammed in Figure 2 below.
For senses 1 and 2 ofaccendere, the clustering of nodes in the subtaxonomyof 'artifacts' does not help to identify the semantic"glue" that keeps together the object collocates for eachrelevant sense.Although we are working on Italian examples, we willuse hereafter, for illustrative purposes, WordNet 1.5 asa reference taxonomical resource, due to itscompleteness, the Italian WordNet being still underdevelopment in the framework of the EuroWordNetproject (LE2-4003).
This decision is not arbitrary,since, for the words considered in this paper, the ItalianWordNet shows a similar taxonomical organization asWor&~qet 1.5.?| ,.NFigure 2 Hierarchy of 'artifact' objects of accendereSense 1 of accendere selects for artifact objects whichcan bum; sense 2 basically selects for devices whichare activated through making electric contact.The problem here is not simply that it isimpossible to identify one single upper node covering -say - all and only burning artifacts as opposed todevices making electric contact.
The classicalassumption that one scrnantic class should be made tocontain all and only the collocates of one sense isclearly too strong in this context, if it is a workablecognitive hypothesis at all.
One could nonetheless fallback to the weaker assumption that a class of collocatesbe expressed in terms of a disjunction of thetaxonomy's nodes/subclasses, provided that each suchnode/subclass defines a proper subset of the typicalobjects of the verb sense in question.
In fact, ourdiagram above shows that even this weakercharacterization is not viable in all cases.
Consider thetaxonomy chain formed by luce-larapada-candelacorresponding tothe class of objects having to do with<light, source of illumination>.
Whereas luce 'light'and its hyponym larapada 'lamp' both point to the'switch on' sense (sense 2), candela 'candle' (theterminal node of this chain) is associated with the'light' sense (sense 1), due to its being a typicallyburning object.
Here the same taxonomy chain includesobjects related to different senses of the verb.
This istantamount to saying that the dimension of semanticsimilarity captured through the taxonomical structure isnot appropriate but rather misleading if one wants tounambiguously characterise the different senses of theverb through thei~ selectional preferences.
The propertyof burning, on which the preference is based, cannotpossibly be percolated from higher to lower nodesthrough the taxonomy chain.
Rather, it represents aproperty peculiar of some nodes only, eitherintermediate or terminal ones.
Hence, given thetaxonomy illustrated above, one can do little more thandisjunctively listing all nodes corresponding to thecollocates in question, with the further stipulation thatthe property of being a collocate does not necessarilypercolate further down in the taxonomy chain.
This isfine, but it boils down to saying that the taxonomy inquestion can do very little to generalize over theselectional preference classes.89IIIIIIIIIIII,IIITo sum up, this simple example shows thattaxonomy-based semantic similarity is not alwayssufficient o justify the belonging of a given lexicalitem to a specific selectional preference class.
Verygranular distinctions may be needed to characterise anysuch class.
Moreover, some of the distinctions requiredare orthogonal to the distinctions conveyed by ataxonomical organisation ofthe lexicon.3.2 Comparing overlapping seleetional preferencesof different verbsSo far, we focussed on the difficulty of neatlycharacterising verb selectional preferences in terms oftaxonomical classes.
It turns out that the semantic gluepasting together the object collocates of senses 1 and 2of the verb accendere isgiven by distinctions which arenot directly reflected in the semantic taxonomy.Taxonomical relationships seem to capture only someof the various dimensions on which semantic similarityis grounded.
This is not accidental, we believe, sincetaxonomical dimensions are typically def'med i)independently of context, and ii) once and for all.
It isthus not surprising that hey may fail, in some cases, toreflect the similarity dimension appropriate in aspecific ontext.
In this section, this issue is explored inmore detail by comparing the selectional preferences ofdifferent verbs exhibiting a non empty intersection ofthe sets of their typical collocates.Among the typical collocates of sense 1 ofaccendere 'light' there is sigaretta 'cigarette' which, inWordNet 1.5, is the terminal node of the followingtaxonomical path:sigarctla 'cigarette'=> roll of tobacco=> tobacco, baccy=> narcotic=> drug=> artifact, artefact=> object, inanimate object, physical object=> entityLet us look now at some of the typical verbs withwhich sigaretta occurs, together with other possiblecollocates of these verbs, as they are attested in theCollins Italian-English Dictionary (1985), in bothexample sentences and the semantic indicators field.
Inthese examples, the sequences "/S" (short for"Subject") and "/O" (short for "Object") specify thegrammatical relation of the noun relative to the verb:?
ACCENDERF..$0_I/V {SIGARETTA./O CAMINO/OCANDELMO FIAMMIFERO/O}light {cigarette/O, fireplace/O, candle/O, match/O}?
ARROTOLARE$O l/V {SIGARETTPdO CARTAJOSTOFFA/O}roll up {cigarette/O paper/O fabric/O}?
FUMARES0_I/V {SIGARETTMO PIPA/O}smoke {cigarette/O pipe/OI?
OFFRIRES0_I/V {SIGARETrA/O AIUTO/O LAVORO/OM ERCE/O PREGHIERAiO}offer {cigarette/O help/O job/O goods/O prayer/O }?
RIACCENDERE$0 I/V {SIGARETTA/O FUOCO/O GAS/O\[NTERESSE/O LUCE/O RADIO/O SENTIMENTO/O}light/switch on/revive {cigarerte/O fire/O gas/O interest/Olight/O radio/O feeling/O}?
SPEGNERE$0 I/V {SIGARETTA/O APPARECCHIO/ODEBITO/O l~tJOCO/O GAS/O LUCE/O PASSIONE/OS UO NO/O }extinguisWswitch off7stifle/rnufl\]e {cigarette/O device/O debt/Ofire/O gas/O light/O passion/O sound/O}?
SPEGNERSI$O 2./V {SIGARETTA/S APPARECCHIO/SFUOCO/S LUC-E/S PASSIONE/S RICORIX)/S SUONO/S}be extinguished/stop/fade way {cigarette/S deviceJS fire/Slight/S passion/S memory/S sound/S}Careful consideration of these examples hows thatdifferent types of semantic glue are at work in differenteases.
With the verb accendere (sense 1) the glue is, aswe saw, the property of burning.
A similar analogy is atwork in the case of riaccendere, spegnere andspegnersi, with the main difference that this case alsoincludes figurative usages.
As to the verb arrotolare,the semantic similarity of its object collocates isgrounded on their being made of material whosetexture makes them rollable.
The relevant similaritywhich links pipes and cigarettes relative to the contextoffumare rather hinges on their telic role, their bothbeing typically smoked objects.
Finally, thecollocational set of offrire includes words denotingtypical human needs and/or desires ranging fromcigarettes and goods to more abstract hings such ashelp and prayers.These examples confirm the difficulty ofassessing the semantic similarity of words when theyare considered outside their actual contexts of use,difficulty which already emerged in relation to acharacterization f the selectional preferences of theverb accendere.
By projecting these collocational setsonto WordNet, appropriate generalisations can hardlybe found.
A general semantic lass subsuming some orall members of each set may exist, but often it is notspecific enough to avoid undesired intersection ofclasses, as in the case of senses 1 and 2 of accendere.On the other hand, semantic features such as"lightability", "enjoyability", "smokability" or"rollability" seem to be at work here: they strike us ashardly amenable to a global consistent taxonomicalrendering.3.3 ImplicationsIn the previous ections, we discussed whether and towhat extent taxonomical relationships as actuallyimplemented in WordNet-like lexical resources can beused to measure the semantic similarity of typicalcollocates associated with a given verb sense.
Weshowed that one can hardly fred a unique taxonomynode subsuming all and only the collocates bearing thesame grammatical relation to a given verb sense.
Aweaker but more realistic hypothesis was alsoconsidered, namely that a class of verb collocates beg0IlIIIIIIIIIIIIIIIexpressed in terms of a disjunction of taxonomy'snodes, provided that each such node defines a propersubset of the typical collocates of the verb sense inquestion.
It turned out that even this weakercharacterization f selectional preferences is not alwaysviable since it is often the case that selectionalpreference information is not disjunctively distributedover taxonomy nodes.
When this is the case, ataxonomy provides virtually no means of generalisingover the set of typical collocates of a given verb sense.In our view of things, such an inadequacy oftaxonomical information cannot be got around byletting finer grained distinctions slip in the semantictype model.
Rather, it bears upon one inherent propertyof most taxonomies as they arc currently built up:monodimensionality.
In fact, taxonomies are oftenanchored to a fixed classificatory dimension (e.g.perceptual features as opposed to functional ones).
Bycontrast, real data suggest hat different verb sensesselect different classes of complements according todifferent dimensions of semantic similarity.
This is thereason why taxonomies do not always capture locallysalient common features, which are needed toappropriately account for the semantic similarity ofverb complements.Our examples showed that multidimensionalclassifications are indeed required to dynamicallycapture locally salient features.
Although in WorNet1.6 provision is made for concepts to be cross-classified with respect o different dimensions, it is notclear how many and what dimensions should be addedto the original WordNet structure to comply with realNLP application requirements.
These considerationsare, in our view, compelling enough to prompt theinvestigation of different and more workable ways tocomplement the taxonomical structure of WordNet-likeresources.
A simple but effective source of knowledgewhich can nicely complement WordNet for capturinglocally salient semantic similarity is represented bydistributional information about words, under theassumption that words which bear the same syntacticrelation to the same word sense form a somehowsemantically coherent class.In the following section, we illustrate this pointby describing a measure of semantic similarity basedon distributional evidence and we show how helpfulthis is in capturing locally salient semantic similarity.4.
Distributionally-based semantic similarityA semantic similarity measure computed on the basisof distributional evidence is at work in SENSE, anexample-based word sense disambiguation (WSD)system carrying out the task on the basis of arepresentative setof typical patterns of use (Federici etal.
1997).
In particular, SENSE presupposes prioravailability of verb-noun pairs where the contextuallyrelevant sense of the verb token is assigned.
At thesame time, the accompanying oun is provided with itsgrammatical function.
This set of verb-noun pairsconstitutes the knowledge base of examples (orexample base for short) on the basis of which SENSE isable to draw its inferences.Given an Input Pair IP to be disambiguatedwhere the grammatical relation of the noun relative tothe verb is specified, SENSE searches its example baselooking for the set of examples which are most similarto IP.
If an identical pair is found in the example base,then the usual assumption is made that the verb tokenin IP is used in the same reading of the verb in theknown example) The key notion used by SENSE tocompute similarity between non identical pairs isproportional nalogy.
To illustrate, if the verb sense inthe pair accendere-pipa/O 'light-pipe' has to beinferred, this can be done through the followingproportion, involving three disambiguated verb-objectpairs attested in the example base plus the input pairaccendere.pipa/O as the fourth term:fumare l- : ~umare l- = accendere_l- : accendere~-sigarettatO p ipa lO  sigaretta/O pipalO' smoke-  : ' smoke-  = " l ight-  : ' l ight -ci~arette/O' pipedO' ci~arettc/O' pile-dO' _Intuitively, the proportion says that the sense ofaccendere in accendere-pipa "light-pipe' is likely to bethe same as in  accendere-sigaretta 'light-cigarette'since both pipa and sigaretta can typically be smoked,or - in more linguistic terms - since they ate bothtypical objects of sense 1 of fumare 'smoke'(fumare l).It is important to point out here that thisinferential strategy is "local" in two senses: i) relativeto the example base, and ii) relative to the input pair.First, it neither presupposes nor relies on a preliminaryclassification of all known examples.
In this respect,the system simply memorizes all examples, with noattempt to generalize over them in any optimal globalway.
Generalizations are only made to interpret newunknown evidence.
Hence, the resulting classificationdoes not reflect general properties of the example baseas such, but only associations which are triggered bythe specific input pair in question.
In this sense thehypothesis search space is constructed on the fly, everytime the system is confronted with a new unknownpair.The second notion of "locality" we intend toemphasize here is related to the issue of whatconstitutes a relevant analogy, given the input pair IPconsidered.
The similarity between an IP and someknown examples is not simply based on a a-priori2 In fact, SENSE is also able to go beyond the evidenceprovided by an attested example as illustrated inFederici et al 1997.91IIIIIIII!
!liIglobal similarity of some.
of its constituent elements(i.e.
the verb and the noun), which, as we just saw, isnot available.
An analogical proportion enforces amuch more constraining relation.
The interpretation'light-pipe' of accendere-pipa is not simply based onthe piecemeal nalogy with accendere-sigaretta (whereaccendere is found in common, and pipe and cigaretteare sufficiently similar).
The conclusive lement of theanalogy is that both fumare and accendere in theirrespective senses of 'tight' and 'smoke' aresystematically related in the example base through a setof shared objects, and that pipa occurs with fumare inthe required sense.
This is exactly what the proportionis able to capture.We contend that, for the notion of context-sensitive word sense similarity to adequately bemodeled, both notions of locality play an importantrole.The example base used so far for testing theeffectiveness of the distributionally-based semanticsimilarity measure for WSD purposes wasautomatically acquired from both semantic indicatorsand example sentences of the Collins Italian-EnglishDictionary (Montemagni 1995).
Each acquired verb-noun pair can thus be said to represent a typical patternof use of a given sense of a verb.
The choice of abilingual dictionary was also motivated by the practicalinterest hat the resulting sense subdivisions have forpurposes of Machine Translation.The derived example base contains 8,153 verb-noun pairs (either verb-subject or verb-object patterns)which exemplify 3,359 different verb senses.
All pairsare acquired from verbentries, and thus provide senseinformation only about the verb; each accompanyingnoun, ifpolysemous, i  not disambiguated.
On average,a verb sense is illustrated through 2.42 patterns.
Senseswhich are attested in ten or more patterns are anegligible part of the training set, whereas most verbsare illustrated through a number of patterns rangingbetween 2 and 5.
Finally, a considerable group of verbsenses is attested only once.
Note that the lattercircumstance does not stop SENSE from recognising?
hapax senses in novel unknown contexts.SENSE performance was tested on a corpus of150 IPs randomly extracted from unrestricted texts.Since the test was intended to evaluate the reliability ofdistributionally-based inferences, the test corpus didnot contain any pattern already present in the examplebase.
Only verbs were disambiguated.
The results ofthis experiment are reported in the table below:Overall PolysemousRECALL 79.3% 66.3%PRECISION 89,9% 80.4%Figures in the first column refer to both polysemousand monosemic verbs.
In the second column, recall andprecision are relative to polysemous verbs only.
Thesefigures are very significant if one considers i) thecomparatively small size of the lexical database usedfor training, ii) the distribution of patterns per verbsense, and iii) the fact that only some of its attestedwords (namely verbs) are semantically disambiguated.The results reported above were computed on thebasis of distributional evidence only.
On closeranalysis, it turned out that some of the input contextswhich were lefr ambiguous by SENSE could have beensuccessfully disambiguated if also taxonomicalinformation was taken into account.
Consider thefollowing three cases:verb sense objectinput abbattere ?
piantacontext 'cut down' 'plant'known abbattere 1 alberoexample 'cut down' '~'ee'hyponym:alberoinput abbassarecontext 'hang'known abbassareexample 'hanl\['input accarez=arecontext 'stroke'known acearezzareexample 'stroke'?
capo synonym:'head' testa1 testa'head'9 barba hyperonym:'beard' pelo 'hair'1 capello hypcronym:'hair' pelo 'hair'In the first case, the object in the target context is theWordNet hyperonym of the object in the knownexample, as shown in the rightmost column of  thetable.
In the second case, the objects of both input andknown pairs are synonyms.
Finally, the last caseillustrates a typical instance of hyperonym sharing.This indicates that distributionally-based andtaxonomy-based inferences can nicely becomplemented.
In practice, this can be done in morethan one way.
In some experiments of syntacticdisambiguation (subject/object assignment in Italian,Montemagni 1995, Montemagni et al 1996), we triedto combine both taxonomical and distributionalmeasures in such a way that the system retied ontaxonomical information first, to turn to distributionalevidence only when the first step was not conclusive.This strategy, however, did not seem to be successful,as the system was frequently led astray by irrelevantsimilarities.
Our experience seems to suggest hat amore promising way to integrate distnbutionally-basedand taxonomy-based information is arguably to usedistributional evidence fast, so as to exploit thecontext-sensitivity (or locality) of proportional nalogyas a filter of irrelevant similarities.
Taxonomicalinformation is to be relied on only at a second stage, asa fall back solution to outstanding ambiguities.5.
ConclusionsSemantic similarity is not simply a relation betweentwo words in isolation, but rather a relation betweentwo words in their context.
This context-sensitive vi wof semantic sLrnJlarity makes its identification moreproblematic.
In principle, semantic similarity of words92can be captured in a number of different ways, rangingfrom their taxonomical relationships to their actualdistribution in a corpus.
It would be very difficult toargue that one such a way is more plausible thananother; nonetheless, it should be observed that theirpractical utility in well-known interesting NLPapplications can vary considerably.We noted that taxonomy-based measures ofsemantic similarity are to an extent inadequate, as theycapture only some of the classificatory dimensionswhich play a relevant role in NIP applications.
Weshowed that relevant similarities need to be groundedon the specific context to be processed (e.g.disambiguated, retrieved or summarised) and thatdifferent contexts call for different classificatorydimensions.
Distributional evidence can be used tomodel this sort of context-sensitive multidimensionalclassification, so as to induce semantic associationsbetween words that nonetheless belong to differentplaces in a taxonomy.
We also showed thatdistributionally-based semantic similarity has aconsiderable impact on crucial NLP tasks such as wordsense disambiguation.
All this provides evidence thatWordNet-like lexical resources should strive tointegrate taxonomical and distributional information,by combining both paradigmatic and syntagmaticdimensions.As already mentioned, Word,Net has a potentialfor doing that, through extended implementation f so-called pointers from nouns to verbs and from verbs tonouns, to represent functions, typical semanticpreferences tc.
Within the EuroWordNet project (LE2-4003), some steps in this direction have already beentaken in developing multilingual WordNets for Dutch,Italian and Spanish.
Among the additions to theoriginal set of relations borrowed from WordNet 1.5,syntagmatic relations feature prominently: e.g., onefinds verb-to-noun relations denoting the typicalentities involved in a given event, or noun-to-verbrelations referring to the typical events in which a givenentity play a role (Alonge et al forthcoming).This certainly provides the information eeded tocapture context-sensitive semantic similarities.
We alsoshowed that local inferential engines such as SENSEcan demonstrably tap this type of information with thedegree of flexibility, noise-tolerance and input-relevance required, among others, by WSD.ReferencesAlongc A., N. Calzolari, P. Vosscn, L. Bloksma, \[.Castellon, A. Marti, W. Peters, forthcoming, 'TheLinguistic Design of the EuroWordNet Database', inComputers and the Humanities: Special Issue onEuro WordNet.Agirre E., G. Rigau, 1996, 'Word SenseDisambiguation using Conceptual Density', inProceedings of COLING-96, Copenhagen, pp.
16-22.Brown P.F., S.A.D.
Pietra, V.J.D.
Pietza, R.L.
Mercer,1991, 'Word Sense Disambiguation Using StasticalMethods', in Proceedings of A CL-1991, pp.
264-270.Collins Giunti Mamocco, 1985, English-Italian Italian-English Dictionary, London Firenze.Federici S., S. Montemagni, V. Pirrelli, 1997,'Inferring semantic similarity from DistributionalEvidence: an Analogy-based Approach to WordSense Disambiguation', in Proceedings of theACL/EACL Workshop "'Automatic InformationExtraction and Building of Lexical SemanticResources for NLP Applications'; Madrid, Spain.Gale W.A., K.W.
Church, D. Jarowsky, 1992, 'AMethod for Disambiguationg Word Senses in LargeCorpora', Computers and the Humanities.Goldstone R.L., Medin D.L., Halberstadt J., 1997,'Similarity in context', Memory and Cognition, 25(2),pp.
237-255.Lee J.H., M.H.
Kim, Y.I.
Lee, 1993, 'InformationRetrieval based on conceptual distance in IS-Ahierarchies', Journal of Documentation, 49(2), June1993, pp.
188-207.Montemagni S., 1995, Subject and Object in ItalianSentence Processing, PhD Dissertation, UMIST,Manchester, UK.Montemagnl S., S. Federici, V. Pirrelli, 1996, 'Resolvingsyntactic ambiguities with lexico-semantic patterns: ananalogy-based approach', in Proceedings of COLING-96, Copenhagen, August 1996, pp.
376-381.Nagao M., 1992, 'Some Rationales and Methodologiesfor Example-Based Approach', in Proceedings of"International Workshop on Fundamental Researchfor the Future Generation of Natural LanguageProcessing", 30-31 July 1992, Manchester, pp.
82-94.Nirenburg S., C. Domashnev, D.I.
Grannes, 1993,'Two Approaches to Matching in Example-BasedMachine Translation', in Proceedings of TMI-93, pp.47-57.Pereira F., N. Tishby, 1992, 'Distributional Similarity,Phase Transitions and Hierarchical Clustering',Working Notes, Fall Symposium Series, AAAI, pp.108-112.Rada IL, M. Hafedh, E. Bicknell, M. Blettner, 1989,'Development and application of a metric onsemantic nets', IEEE Transactions on System, Man,and Cybernetics, 19(I), pp.
17-30.Resnik P., 1995, 'Using Information Content toEvaluate Semantic Similarity in a Taxonomy', inProceedings of IJCAI-95.Schiitze, H., 1992, 'Word Sense Disambiguation withSublexical Representations', Workshop Notes,Statistically-based NLP Techniques, AAAI, 109-113.93
