Proceedings of the SIGDIAL 2014 Conference, pages 12?21,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsOut-of-Domain Spoken Dialogs in the Car: A WoZ StudySven Reichel, Jasmin Sohn,Ute Ehrlich, Andr?e BertonSpeech Dialogue SystemsDaimler AG, Ulm, Germanysven.reichel@daimler.comMichael WeberInstitute of Media InformaticsUlm UniversityGermanymichael.weber@uni-ulm.deAbstractMobile Internet access via smartphonesputs demands on in-car infotainment sys-tems, as more and more drivers like to ac-cess the Internet while driving.
Spokendialog systems (SDS) distract drivers lessthan visual/haptic-based dialog systems.However, in conversational SDSs driversmight speak utterances which are not inthe domain of the SDS and thus cannotbe understood.
In a Wizard of Oz study,we evaluate the effects of out-of-domainutterances on cognitive load, driving per-formance, and usability.
The results showthat an SDS which reacts as expected bythe driver, is a good approach to control in-car infotainment systems, whereas unex-pected SDS reactions might cause severeaccidents.
We evaluate how a dialog initia-tive switch, which guides the user and en-ables him to reach his task goal, performs.1 IntroductionThe acceptance of smartphones is a success story.These devices allow people to access the Internetnearly anywhere at anytime.
While driving, usinga smartphone is prohibited in many countries as itdistracts the driver.
Regardless of this prohibition,people use their smartphone and cause severe in-juries (National Highway Traffic Safety Adminis-tration (NHTSA), 2013).
In order to reduce driverdistraction, it is necessary to integrate the smart-phones functionality safely into in-car infotain-ment systems.
Since hands and eyes are involvedin driving, a natural and intuitive speech-based in-terface increases road safety (Maciej and Vollrath,2009).
There are already infotainment systemswith Internet applications like e.g.
weather, musicstreaming, gas prices, news, and restaurant search.However, conversational spoken dialog sys-tems (SDS) to control all these applications andthe car?s functionality, are still missing.
Cur-rent SDSs operate mostly in specific domains andthey understand user utterances which are relatedto these domains.
While using natural language,users are not restricted to specific domains.
Thusone crucial problem for them is to know which ut-terances the system is able to understand.
Peo-ple use different approaches to solve this prob-lem, for example by reading the manual, using on-screen help, or relying on their mental model ofthe SDS.
In multi-domain SDSs, utterances can bequite complex and remembering all of them or dis-playing them on screen would not be possible.
Asa result, as long as conversational SDSs are notable to operate in much wider domains, sooneror later the user will speak an utterance which isin his mental model of the SDS, but cannot beprocessed.
Such utterances can be divided intoout-of-domain and out-of-application-scope (Bo-hus and Rudnicky, 2005).
We induce errors indomain switches and not within one domain, thusonly out-of-domain utterances are considered.In this paper, we present results from a Wizardof Oz (WoZ) study on multi-domain interactionwith an in-car SDS to evaluate the effects of out-of-domain utterances on driver performance.
Weconsidered four different system reactions: suc-cessful domain switch, misunderstanding, non-understanding, and a dialog initiative switch.
Byanalyzing them concerning driver distraction andusability, we are able to evaluate whether a dia-log initiative switch is an appropriate response toan out-of-domain utterance or not.
The results of-fer valuable clues for the development of multi-domain in-car SDSs.The remainder is structured as follows: Section2 provides an overview of studies in this context.Section 3 describes the domain of the study whichis shown in Section 4.
Data analysis methods aredefined in Section 5.
We present and discuss theresults in Section 6 and conclude in Section 7.122 Related WorkDriver distractions, due to secondary tasks, areevaluated in many studies (a good overview pro-vides Ei-Wen Lo and Green (2013)).
The driver?sperformance is generally better when using speechinterfaces than manual or visual interfaces, how-ever, interacting with an SDS is often worse thanjust driving (Bar?on and Green, 2006).
Most stud-ies consider specific domains and do not evalu-ate how to handle domain switches.
Kun et al.
(2013) evaluated multi-threaded dialogs betweenhumans while driving.
By interrupting a dialog,they observed an increase of cognitive load, whichaffected the driving performance negatively.
Theparticipants were prepared that an interruption willbe initiated at some time.
This means they mightbe surprised, however, it won?t be as unexpected assystem reactions in response to out-of-domain ut-terances.
In this work, we evaluate a dialog initia-tive switch, as a possible reaction to out-of-domainutterances.In a driving simulator study, Kun et al.
(2007)showed that low SDS recognition accuracy affectsthe steering wheel angle variance negatively.
Thisis first evidence that in-car SDSs need to han-dle speech recognition or language understand-ing errors intelligently.
In preliminary work tothis study, we analyzed a dataset containing dia-log errors in relation to driving performance, mea-sured by the lane change task (Mattes, 2003).
Thisshowed slight evidence that dialog errors, such asresponses to out-of-domain utterances, have an in-fluence on driving performance.
However, the lanechange task is not the right driving task for sucha fine granular analysis, as drivers are only occu-pied during a lane change and thus not constantlyat the same level.
Therefore, we analyze drivingperformance with the Continuous Tracking andReaction (ConTRe) task (Mahr et al., 2012).3 User TasksIn a user experiment it is crucial to set real tasksfor users, since artificial tasks will be hard to re-member and can reduce their attention.
We ana-lyzed current in-car infotainment systems with In-ternet access and derived eight multi-domain tasksfrom their functionality (see Table 1).
Since onlyfew natural use cases involve more than three do-mains, every user task is a story of three subtasks.In task number 5 for example, a user has to starta subtask, which navigates him to Berlin.
Thenhe would like to search an Italian restaurant at thedestination.
Finally, he adds the selected restau-rant to his address book.No Domain 1 Domain 2 Domain 31 POI Search Restaurant Call2 Knowledge Ski Weather Navigation3 Weather Hotel Search Address book4 Play Artist News Search Forward by eMail5 Navigation Restaurant Save Address6 News Search Play Artist Share on Facebook7 News Search Knowledge Convert Currency8 Navigation Gas Prices Status Gas TankTable 1: Multi-domain user tasks.At the beginning of a task and during a sub-task, the SDS always reacts as it is expected bythe users, which means it answers their requests.This increases the stress when the system suddenlystarts to react unexpectedly.
After presenting thefinal answer of a subtask, the user has to initiatea domain switch.
In response to domain switch-ing utterances four different system reactions wereused (see Section 4.2.2).4 User ExperimentDeveloping an SDS includes specifying a gram-mar or training statistical language models forspeech recognition.
These steps precede any realuser test.
In system-initiated dialogs, with a fewpossible utterances, specifying a grammar is fea-sible.
However, in strictly user-initiative dialogscovering multiple domains, this is rather compli-cated.
A WoZ study does not require to developspeech recognition and language understanding asthis is performed by a human (Fraser and Gilbert,1991).
In addition, the system reaction is con-trolled and not influenced by recognition errors.Our study requires such a controlled environment,as an unexpected system reaction, due to a recog-nition error, would influence the results negatively.Driver distraction and usability ratings varyamong people and depend on age, personality, ex-perience, context, and many more.
Therefore, itis essential to conduct a user study with peoplewho might use the SDS later on.
A study bythe NHTSA (National Highway Traffic Safety Ad-ministration (NHTSA), 2013) showed that 73% ofthe drivers involved in fatal crashes due to cellphone use in 2011, were less than 40 years old.
Forthis reason, our study considers drivers between18 and 40 years who are technically affine and arelikely to buy a car equipped with an infotainmentsystem with Internet access.134.1 Set-Up of the ExperimentWhen designing a user interaction experiment, it isimportant that it takes place in a real environment.As driving on a real road is dangerous, we useda fixed-base driving simulator in a laboratory.
Ascreen in front of the car covers the driver?s fieldof view (see Figure 1).
Steering and pedal signalsare picked from the car?s CAN bus.It is important that the user assumes he is in-teracting with a computer as ?human-human in-teractions are not the same as human-computer in-teractions?
(Fraser and Gilbert, 1991).
The wiz-ard, a person in charge of the experiment, was lo-cated behind the car and mouse clicks or any otherinteraction of the wizard was not audible in thecar.
To ensure a consistent behavior of the wiz-ard, we used SUEDE (Klemmer et al., 2000) todefine the dialog, which also provides an interfacefor the wizard.
SUEDE defines a dialog in a statemachine, in which the system prompts are statesand user inputs are edges between them.
The con-tent of system prompts was synthesized with NU-ANCE Vocalizer Expressive1version 1.2.1 (Voice:anna.full).
During the experiment, the wizardclicks the corresponding edge after each user in-put and SUEDE plays the next prompt.Figure 1: Set-up of the experiment4.2 Design of the ExperimentDriving a car requires the driver to focus on theroad and react appropriately to sudden events.However, if drivers are occupied with a secondarytask, such as controlling an infotainment system,their attention to the road might suffer.
This is dueto the fact that the human?s performance is reducedwhen human resources overlap (Wickens, 2008).In this experiment, a dual task scenario is used bydriving in a simulator and interacting with an SDSat the same time.
There is no visual display in1http://www.nuance.com/for-business/mobile-solutions/vocalizer-expressive/index.htmthe car, as this would require additional human re-sources and it would increase the driver distraction(Young and Regan, 2007).4.2.1 Primary Task: Driving SimulatorOne major requirement for the driving simulator isto ensure a controlled and comparable driver dis-traction measure over all interaction variants andparticipants.
The open-source driving simulatorOpenDS provides a driving environment and ex-tensive logging facilities (Math et al., 2012).
Asexplained in Section 2, it is essential to keep thedriver occupied at a constant level all the time.Therefore, we used the ConTRe task (Mahr et al.,2012), which consists of a continuous steering taskand a reaction task.Figure 2 shows the ConTRe task with steeringcylinders and a traffic light.
The yellow steeringcylinder moves unpredictably right and left at aconstant distance from the driver.
The driver hasto steer the blue cylinder to superpose it with themiddle section of the yellow one.
This is similarto driving on a curved road.
Sometimes a driverneeds to react to sudden events to prevent an acci-dent.
A traffic light shows randomly red and greenand requires the driver to push the throttle or brakepedal.
As the car drives constantly at 50km/h, thepedals are only pushed in response to the trafficlight.
The movement of the yellow cylinder andthe appearance of the traffic light can be controlledby manipulating OpenDS?
control variables.
Weused the ?hard driving?
condition as described byMahr et al.
(2012).Figure 2: Continuous tracking and reaction task4.2.2 Secondary Task: Responses to DomainSwitching RequestsA task in our experiment consists of three subtasksand each subtask requires two to four semanticconcepts.
For a user it is possible to insert mul-tiple concepts at once:U: ?Search an Italian restaurant at my destination?14or as single utterances in a dialog:U: ?Search an Italian restaurant?S: ?Where do you search an Italian restaurant?
?U: ?At my destination?Prompts were created for all possible combina-tions.
SUEDE provides a GUI for the wizard toselect which semantic concepts a user input con-tains.
Depending on the selection, either anotherconcept is requested or the answer is provided.Within one subtask, the system always reacts asexpected by the user.
An answer for the presentedexample might look like:S: ?There is one Italian restaurant: Pizzeria San Marco.
?After this, the user has to initiate a domainswitch to save the pizzeria?s address into hispersonal address book.
Such user-initiated do-main switches challenge current SDSs as lan-guage models increase and thus speech recogni-tion as well as language understanding is errorprone (Carstensen et al., 2010).
Furthermore, theuser could request a functionality which is not sup-ported by the system.
In case of such a request,SDSs react differently and could apply error re-covery strategies if the error is recognized.
To an-alyze the impact of error recovery strategies in thecar, we use four different kinds of responses to do-main switching requests.Figure 3 shows the study?s conditions.
Detaileddialogs that corresponds to them can be foundin the Appendix.
First of all, we consider theExpected Reaction (ER) condition, in which theSDS reacts as expected by the user and switchesthe domain.
As the speech is recognized by a wiz-ard, this is an optimal system without any errors.Miscommunication can be distinguished be-tween misunderstanding and non-understanding(Skantze, 2007).
In the MisUnderstanding (MU)condition, the SDS does not recognize the do-main switch request and it responses in contextof the current domain.
On the contrary, in theNon-Understanding (NU) condition, it recognizesan out-of-domain utterance and refuses the ac-tion by apologizing and encouraging the user torephrase his utterance (a combination of Bohusand Rudnicky (2005)?s Notify and AskRephraseerror handling strategies).
The only way to pro-ceed with a MU or NU task in our experiment is touse an explicit domain switching command, suchas ?start radio application?.
As we have shownin Reichel et al.
(2014), participants do not usesuch commands naturally in a speech-only info-tainment system and only use them after tryingnumerous unsuccessful utterances.
Another ap-proach is a Dialog Initiative Switch (DIS) to guidethe user after recognizing an out-of-domain utter-ance (Notify and YouCanSay strategy (Bohus andRudnicky, 2005)).
Therefore, the SDS proposes achoice of four possible domains to interact with.Users have to select the first option which was fol-lowed by four possible actions within this domain.By selecting the desired action, the SDS reads outfour examples of possible utterances.
After that,the dialog initiative is given back to the user.Action(e.g.
?add restaurant?
)Execute RefuseExpectedReaction (ER)Misunder-standing (MU)Non-Under-standing (NU)Dialog InitiativeSwitch (DIS)MiscommunicationFigure 3: Domain switching response conditions4.3 Procedure of the experimentThe experiment starts with an initial questionnaireto create a profile of the participant, concerningage, experience with smartphones, infotainmentsystems and SDSs.
Then participants are intro-duced to the driving task and they have time topractice till being experienced.
After completinga baseline drive, they start to use the SDS.
Foreach spoken dialog task users get a story describ-ing in prose what they like to achieve.
To mini-mize priming effects, they have to remember theirtask and are not allowed to keep the descriptionduring the interaction.
There is no explanationor example of the SDS, apart from a start com-mand for activation.
After the start command, thesystem plays a beep and the user can say what-ever he likes to achieve his task.
The explorationphase consists of four tasks, in which the systemreacts as it is expected by the user.
This enablesthe user to get used to the SDS while driving.
Inthe second part of the experiment, one task foreach condition was completed (ER, MU, NU, andDIS).
The conditions were assigned randomly toa task and each one was rated by a SubjectiveAssessment of Speech System Interfaces (SASSI)(Hone and Graham, 2000) and Driver ActivityLoad Index (DALI) (Pauzi?e et al., 2007) question-naire.
At end of the experiment, each participantcompleted a second baseline drive without usingthe SDS to analyze whether the driving perfor-mance changed to the first baseline drive or not.15After that, the four conditions were compared in aquestionnaire.5 Evaluation Metrics and HypothesesThe goal of this study is to evaluate four SDSresponse conditions concerning driver distractionand usability.
Therefore, we used four kindsof measurements (see Table 2): objective driv-ing performance logged by OpenDS, subjectivedriver distraction with DALI questionnaires, us-ability scores measured by SASSI questionnaires,and dialog performance.
The steering deviationvalue measures the driver?s performance to keepthe blue cylinder superposed to the yellow one inthe ConTRe task.
Reaction times between the ap-pearance of a traffic light and the pedal press arelogged as well as wrong and missed pedal presses.The DALI questionnaire consists of 7 questionswhich are assigned to 7 domains to evaluate thedriver?s cognitive load.
We did not ask for visualor haptic demand, as the system does not have vi-sual output or haptic input.
A 7-point Likert scalewas used: low cognitive load (-3) to high cognitiveload (+3).
SASSI is widely used to measure theusability of an SDS covering 6 dimensions with34 questions.
We used a 7-point Likert scale fromstrong disagree (-3) to strong agree (+3).
Highvalues mean good usability, except for annoyanceand cognitive demand ratings, which are opposed.objective driving steering deviationperformance reaction time(OpenDS) missed reactionwrong reactioncognitive load global attention(DALI) auditory demandinterferencetemporal demandusability (SASSI) system response accuracy (SRA)likeability (Like)cognitive demand (Cog Dem)annoyance (Ann)habitability (Hab)speeddialog performance task successuser response delaysystem turn durationuser turn durationTable 2: Evaluation metricsObviously, we expect that drivers perform bestduring the baseline drives without controlling theSDS.
As ER does not stress or frustrate drivers andthey do not need much cognitive power to thinkwhat to say, there won?t be huge differences be-tween ER and baseline drives.
On the contrary,if the system does not react as expected (MU andNU), we expect a worse driving performance andpoor usability ratings.
NU should be rated bet-ter than MU, as the SDS explains the problem.The interesting part is how a DIS will perform asan error handling strategy to out-of-domain utter-ances.
We assume that it is rated better than MUand NU and worse than ER.
As the help dialogs inDIS are long, DIS might tend towards MU and NUin terms of driver distraction.
However, it will berated better in terms of usability because the tasksuccess is expected to be higher.-3-2-10123SRA Like Cog Dem Ann Hab SpeedERMU_NUDISFigure 4: Usability ratings, all of them are significant(p<.001) except of: speed between DIS and MU NU6 ResultsIn the following, evaluation results of the four do-main switching responses are shown.
We analyzeddata from 30 participants (16m/14f), with averageage of 26.65 (SD: 3.32).
Their experience withSDS is little (6-Likert Scale, avg: 3.06, SD: 1.48)as well as the usage of SDSs (5-Likert Scale, avg:2.04, SD: 1.16).
We asked them how they usu-ally approach a new system to learn its interactionschema and scope of operation.
All 30 of themtry a new application on their smartphone withoutinforming themselves how it is used.
Concerninginfotainment systems, trying is also the most usedlearning approach, even while driving (26 people).This means, people do not read a manual, but thesystem has to be naturally usable.
In terms of driv-ing experience, all participants have a driver li-cense for average 8.6 (SD: 3.5) years and most ofthem use their car daily.
Considering the objectivedriving performances of the two baseline drives,there are no significant differences, which meansthe participants performed at a constant level overthe entire experiment.
Figure 4, 5 and 6 show adetailed overview of the evaluation results, whichwill be explained in this Section.160,177  0,1710,188  0,178  0,160,180,20,220,24ER Baseline MU_NU DISSteeringDeviation * *1,0380,8401,060  1,0420,80,911,11,21,3ER Baseline MU_NU DISReaction Time[sec]* * *   * * *0,43  0,20  1,47  1,03  0123456ER Baseline MU_NU DISMissed Pedals* ***0,57  0,352,34  1,800123456ER Baseline MU_NU DISWrongPedals* * ** **Figure 5: Objective driving performance (OpenDS), significance levels: p<.05(*), p<.01(**), p<.001(***)-3-2-10123Attention Auditory Stress Interference TemporalDriver Activity Load IndexERBaselineMU_NUDIS***********************************************Figure 6: Cognitive load: driver activity load index (DALI), significance levels: p<.05(*), p<.01(**), p<.001(***)6.1 SDS which Reacts as Expected (ER)First of all, results of an optimal SDS (ER), whichreacts as expected and does not make any mis-takes, are presented.
The objective driver perfor-mance (see Figure 5) is slightly worse than thebaseline drives in terms of steering and pressingthe right pedals, but not significantly.
However,reaction times are worse than without interactingwith an SDS.
This corresponds to the results fromPatten et al.
(2004), who observed an increase inreaction times when drivers talk to someone on thephone.
The cognitive load (see Figure 6) causedby an optimal SDS is negative in all dimensions,which means an optimal SDS does not put highdemands on the driver.
In general, ER was ratedvery good in terms of usability (see Figure 4) andwould most likely be accepted by young drivers.6.2 Mis- and Non-Understanding (MU, NU)The results of MU and NU do not show signifi-cant differences in any dimension.
Therefore, themean value of MU and NU is used.
As shown inFigure 6, the driver?s cognitive load is high in alldimensions for MU NU.
In terms of stress and at-tention, it is significantly higher than during base-line drives (other DALI dimensions are not as-sessed for baseline drives).
Due to the increasedcognitive load, the driver?s performance (see Fig-ure 5) concerning steering, reaction times, andpedal presses decreases significantly compared tobaseline drives.
Especially the number of times17drivers do not react to external events at all (missedpedal), or they do not react appropriately (wrongpedal), increases strongly.
The usability ratingsprovide evidence how users rate an SDS which isnot usable.As expected, ER performs better than MU NU.An unexpected system reaction causes higher cog-nitive load in all dimensions.
However, in contrastto what one might expect, the driver?s steering per-formance and reaction times are not better than forER (psteering=.083 and preaction=.215).6.3 Dialog Initiative Switch as an Out-Of-Domain Handling Strategy (DIS)Previous Sections have shown that it is impor-tant to minimize misunderstandings and non-understandings in a safe and usable in-car infotain-ment system.
Comparing DIS with an optimal anda worst-case SDS shows whether it is a reason-able approach to handle out-of-domain utterancesor not.
We use a single factor variance analysis(ANOVA) with repeated measurements to identifythe best (Helmert contrast) and worst (differencecontrast) condition out of ER, DIS, and MU NU.If DIS lays between ER and MU NU, we analyzewhether DIS tends towards ER or MU NU.
There-fore, we compare the differences of ER-DIS withMU NU-DIS and use a one sample t-test.6.3.1 Driving PerformanceThe ANOVA did not show any significant differ-ences in drivers?
steering performances or reactiontimes (see Figure 5).
Using a Helmert contrast todetermine the best response, the ANOVA identi-fied ER as the condition with significantly fewestmissed and wrong reactions.
There is no differ-ence between DIS and MU NU, thus DIS tends interms of objective driver distraction more towardsMU NU than to ER.6.3.2 Cognitive LoadAnalyzing the cognitive load of ER, DIS, andMU NU (see Figure 6), the ANOVA identifies ERas the significant best condition (p<.002).
Thesignificant worst one in terms of attention, stress,and interference is MU NU, which means DISlays in between for these dimensions.
However,no evidence is found for stress or interferencewhether DIS tends towards ER or MU NU.
Inglobal attention, DIS tends slightly (p<.031) to-wards MU NU.
Furthermore, the long prompts inDIS put high auditive demands on the driver.6.3.3 UsabilityAs task success of MU NU dialogs is poor (seeSection 6.4), it is obvious that ER is the best(p<.001) and MU NU is the worst condition(p<.001) in terms of usability (see Figure 4).
AllDIS ratings, except of speed, are between ER andMU NU (p<.001).
Speed is basically identicalto the MU NU rating, which is due to the longprompts.
There is a slight tendency of DIS towardsER in system response accuracy (p<.051) and inhabitability (p<.077), however, this is not signif-icant.
In annoyance DIS tends towards MU NU(p<.002), which might be due to the three stephelp dialog.
For cognitive demand and likability,DIS lays exactly between ER and MU NU.6.4 Dialog PerformanceThe task success is pretty low in MU (29.03%) andNU (19.35%) as the task was aborted by the wiz-ard, if drivers did not use explicit domain switch-ing commands after multiple attempts.
On thecontrary, the task success for ER (96.8%) and DIS(93.6%) is good, however, 3 tasks were aborted byusers.
Figure 7 shows the average user responsedelay, system turn duration, and user turn dura-tion.
The rectangular bars drawn in line patternsshow successful interactions during a subtask andthe ones drawn in checked pattern dialogs betweentwo subtasks.When the system responds as expected, usersneed between 2 and 3 seconds to respond.
If thesystem does not react as expected (between twosubtasks), drivers need significantly more time torespond, as they need to think what to say.
In DIS,they only need to repeat the proposed term, thusthey respond faster.
In MU NU, the system turnsin dialogs between subtasks are shorter, wherebythe user turns are longer (user turn duration doesnot include the user?s response time).
So eitherdrivers speak slower or provide longer sentences,if the SDS does not react as expected.
Due to thefour proposed utterances in DIS, system turn du-rations are longer in dialogs between subtasks.6.5 Summary and DiscussionIn general, if an SDS reacts as expected by theuser, it will be a good approach to control the in-car infotainment system.
Except for the driver?sreaction time, an optimal SDS does not influencethe driving performance.
However, a delayed re-action of 200ms might be better than glancing at a1802468ER MU_NU DISUserResponse Delay [sec]***   ***02468ER MU_NU DISSystem Turn Duration [sec]**   ***0246ER MU_NU DISUser Turn Duration[sec]*   ***Figure 7: Dialog performance (light color: interaction during subtasks, dark color: dialog between two subtasks), significancelevels: p<.05(*), p<.01(**), p<.001(***)display.
For example, the Driver Focus-TelematicsWorking Group (2006) states in their guidelines tovisual distraction: ?single glance durations gener-ally should not exceed 2 seconds?.As long as conversational SDSs are not able tooperate in much wider domains, sooner or later theuser will provide an utterance the system is notable to respond to.
Comparing the MU and NUconditions shows that an out-of-domain recogni-tion with a simple rephrase error recovery strategydoes not work.
This is understandable, as bothconditions increase the cognitive load, which in-fluences the driving performance negatively.
Es-pecially the reaction to external events, such astraffic lights, suffers.
In our experiment, the traf-fic light was in the middle of the screen.
Accord-ing to Victor et al.
(2005), drivers concentrate theirgaze on the road center at the expense of periph-eral glances during auditory or complex drivingtasks.
Thus we would expect even worse resultsif the traffic light occurs in the driver?s peripheralvision.
This means an intelligent handling strat-egy for out-of-domain utterances needs to be es-tablished, which informs drivers of the system?scapabilities.We evaluated a dialog initiative switch as a re-sponse to out-of-domain utterances.
Mostly, thisstrategy performed somewhere between the opti-mal and worst-case SDS.
Due to long narrativesystem prompts, the auditive demand is rated highby drivers and thus the driving performance tendstowards the worst-case SDS.
The dialog initiativeswitch was rated as usable, but different variantsneed to be developed and evaluated in the future.After the experiment, the participants rated thefour conditions with two questions from ITU-TP.851 (ITU, 2003) on a 7-point Likert scale fromstrong disagree (-3) to strong agree (+3):Q1: ?Would you have expected more help from the sys-tem?
?Q2: ?You feel adequately informed about the system?s pos-sibilities?
?ER (SD) MU (SD) NU (SD) DIS (SD)Q1 -1.73(1.78) 1.47(1.81) 2.1(1.32) -1.1(1.58)Q2 0.43(2.13) -1.53(1.36) -1.7(1.49) 0.73(1.66)Table 3: Adequate system helpTable 3 shows the results, whereby DIS tendstowards ER in Q1 (p<.004) and is even better thanER in Q2.
This means the drivers felt informedadequately of the SDS, however, further researchis necessary to evaluate how to present this infor-mation.
Shorter helping prompts might be better.Furthermore, multimodal aspects needs to be con-sidered.
For example, head-up displays are able topresent information, such as possible utterances,right in the driver?s view.
This might reduce theauditive demand.7 ConclusionsIn this paper, we showed results from a WoZstudy on user-initiated multi-domain SDSs in thecar.
If an in-car SDS cannot fulfill a user?s re-quest due to, for example, missing functionality,the driver?s cognitive load and distraction will in-crease.
Therefore, out-of-domain utterances needto be identified and handled adequately by in-carSDSs.
Switching the dialog initiative is a good ap-proach to guide users to the task goal and reducetheir cognitive load.
However, if drivers need toprocess any information, some mental activity willbe required.
Therefore, the design and implemen-tation of a dialog initiative switch strategy needfurther efforts to minimize the driver?s distractionand to make it enjoyable for the user.
Other modal-ities than speech-only SDSs, such as head-up dis-plays, need to be evaluated in future studies.AcknowledgmentsThe work presented here was funded by GetH-omeSafe (EU 7th Framework STREP 288667).19ReferencesAdriana Bar?on and Paul Green.
2006.
Safety and us-ability of speech interfaces for in-vehicle tasks whiledriving: A brief literature review.
Technical report,University of Michigan Transportation Research In-stitute.Dan Bohus and Alexander I. Rudnicky.
2005.Sorry, i didnt catch that!
an investigation of non-understanding errors and recovery strategies.
InProceedings of SIGdial, Lisbon, Portugal.Kai-Uwe Carstensen, Christian Ebert, Cornelia Ebert,Susanne Jekat, Ralf Klabunde, and Hagen Langer.2010.
Computerlinguistik und Sprachtechnologie.Spektrum, Akad.
Verl.Driver Focus-Telematics Working Group.
2006.
State-ment of principles, criteria and verification pro-cedures on driver interactions with advanced in-vehicle information and communication systems.Victor Ei-Wen Lo and Paul A.
Green.
2013.
Devel-opment and evaluation of automotive speech inter-faces: Useful information from the human factorsand the related literature.
Int.
Journal of VehicularTechnology, 2013:13.Norman M. Fraser and G.Nigel Gilbert.
1991.
Sim-ulating speech systems.
Computer Speech & Lan-guage, 5(1):81 ?
99.Kate S Hone and Robert Graham.
2000.
Towards atool for the subjective assessment of speech systeminterfaces (sassi).
Natural Language Engineering,6(3&4):287?303.International Telecommunication Union (ITU).
2003.Subjective quality evaluation of telephone servicesbased on spoken dialogue systems (itu-t rec.
p.851).Scott R. Klemmer, Anoop K. Sinha, Jack Chen,James A. Landay, Nadeem Aboobaker, and AnnieWang.
2000.
Suede: a wizard of oz prototypingtool for speech user interfaces.
In Proc.
of the 13thannual ACM symposium on User interface softwareand technology, New York.
ACM.Andrew L. Kun, Tim Paek, and Zeljko Medenica.2007.
The effect of speech interface accuracy ondriving performance.
In INTERSPEECH, pages1326?1329, Antwerp, Belgium.Andrew L. Kun, Alexander Shyrokov, and PeterA.Heeman.
2013.
Interactions between humanhumanmulti-threaded dialogues and driving.
Personal andUbiquitous Computing, 17(5):825?834.Jannette Maciej and Mark Vollrath.
2009.
Compari-son of manual vs. speech-based interaction with in-vehicle information systems.
Accident Analysis andPrevention, 41(5):924 ?
930.Angela Mahr, Michael Feld, Mohammad MehdiMoniri, and Rafael Math.
2012.
The contre (con-tinuous tracking and reaction) task: A flexible ap-proach for assessing driver cognitive workload withhigh sensitivity.
In Adjunct Proceedings of the 4thAutomotiveUI, Portsmouth.
ACM.Rafael Math, Angela Mahr, Mohammad M Moniri, andChristian M?uller.
2012.
Opends: A new open-source driving simulator for research.
Adjunct Pro-ceedings of the 4th AutomotiveUI.Stefan Mattes.
2003.
The lane-change-task as a toolfor driver distraction.
In Proceedings of IGfA, Dear-born.National Highway Traffic Safety Administra-tion (NHTSA).
2013.
Distracted driving 2011.Technical report.Christopher J.D Patten, Albert Kircher, Joakim stlund,and Lena Nilsson.
2004.
Using mobile telephones:cognitive workload and attention resource alloca-tion.
Accident Analysis & Prevention, 36(3):341 ?350.Annie Pauzi?e, J Manzan, and Nicolas Dapzol.
2007.Driver?s behavior and workload assessment for newin-vehicle technologies design.
In Proceedings ofthe 4th International Driving Symposium on HumanFactors in Driver Assessment, Training, and VehicleDesign., Stevenson, Washington.Sven Reichel, Ute Ehrlich, Andr?e Berton, and MichaelWeber.
2014.
In-car multi-domain spoken dialogs:A wizard of oz study.
In EACL Workshop Dialog inMotion, Gothenburg, Sweden.Gabriel Skantze.
2007.
Error Handling in Spoken Di-alogue Systems.
Ph.D. thesis, KTH Computer Sci-ence and Communication.Trent W. Victor, Joanne L. Harbluk, and Johan A. En-gstrm.
2005.
Sensitivity of eye-movement mea-sures to in-vehicle task difficulty.
TransportationResearch Part F: Traffic Psychology and Behaviour,8(2):167 ?
190.
The relationship between distrac-tion and driving performance: towards a test regimefor in-vehicle information systems In-vehicle infor-mation systems.Christopher D Wickens.
2008.
Multiple resources andmental workload.
In Human factors, volume 50,pages 449?55.
USA.Kristie Young and Michael Regan.
2007.
Driver dis-traction: A review of the literature.
Distracted Driv-ing.20AppendixMU:U: Navigation to Berlin, Brandenburger TorS: Brandenburger Tor in Berlin was set as yourdestination.U: Italian restaurant at the destinationS: Italian restaurant could not be set as adestinationU: Navigate to a restaurant in BerlinS: The address restaurant in Berlin was notfoundU: I would like  to search a restaurantS: Sorry?U: Start restaurant applicationS: Restaurant search, what do you want?U: An Italian restaurant in BerlinS: There is one Italian restaurant in Berlin:Pizzeria San MarcoU: Add the address to my address bookS: The address of Pizzeria San Marco isMainstreet 1, BerlinU: Save that to my address bookS: Sorry?U: Save Pizzeria  San MarcoS: Pizzeria San Marco is famous for its deliciousItalian dishesU: Address bookS: Address book, what do you want?U: Save the address of San MarcoS: Alright, the address was addedNU:U: Drive me to the Brandenburger Tor in BerlinS: Brandenburger Tor in Berlin was set as yourdestination.U: Is there an Italian restaurant nearBrandenburger Tor?S: Action unknown, please say something elseU: Give me an Italian restaurant along therouteS: Action unknown, please say something elseU: Italian restaurantS: Action unknown, please say something elseU: Restaurant in BerlinS: Action unknown, please say something elseU: I?d like to search a restaurantS: Action unknown, please say something else<aborted by the wizard>ER:U: NavigationS: Navigation, what do you want?U: City BerlinS: To what address or place of interest do youwant?U: Brandenburger TorS: Brandenburger Tor in Berlin was set as yourdestinationU: Italian restaurant near Brandenburger Tor?S: There is one Italian restaurant in Berlin:Pizzeria San MarcoU: Save the addressS: Alright, the address was addedDIS:U: I would like to go to the Brandenburger Torin BerlinS: Brandenburger Tor in Berlin was set as yourdestination.U: Italian restaurant nearby?S: Action unknown, you can say: restaurant,navigation, hotel, or radioU: RestaurantS: You can: search a restaurant, order a table,rate a restaurant, request opening timesU: Search a restaurantS: Say for example: Search a restaurant at thedestination, I search a Chinese restaurant, ?DieKrone?
in Stuttgart, or Mexican restaurantU: I search an Italian restaurantS: Where do you search an Italian restaurantU: Near Brandenburger Tor in BerlinS: There is one Italian restaurant in Berlin:Pizzeria San MarcoU: Save the addressS: Action unknown, you can say: address book,restaurant, navigation, or hotelU: address bookS: You can: add a contact, remove a contact,access contact details, or delete address bookU: Add a contactS: Say for example: I?d like to add a contact,add an address, add Paul to my address book,save the number 0165332U: Add San Marco to my address bookS: Alright, the address was addedAppendix 1: Detailed dialog examples of the four response conditions.
Translated from German and based on real experimentdata.
Red rectangles identify the domain switching dialogs between two subtasks.21
