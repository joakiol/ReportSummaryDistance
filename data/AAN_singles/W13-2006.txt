Proceedings of the BioNLP Shared Task 2013 Workshop, pages 45?49,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsBiomedical Event Extractionby Multi-class Classification of Pairs of Text EntitiesXiao Liu Antoine Bordes Yves GrandvaletUniversit?
de Technologie de Compi?gne & CNRSHeudiasyc UMR 7253, Rue Roger Couttolenc, CS 6031960203 Compi?gne Cedex, FRANCEfirstname.lastname@hds.utc.frAbstractThis paper describes the HDS4NLP en-try to the BioNLP 2013 shared task onbiomedical event extraction.
This systemis based on a pairwise model that trans-forms trigger classification in a simplemulti-class problem in place of the usualmulti-label problem.
This model facili-tates inference compared to global modelswhile relying on richer information com-pared to usual pipeline approaches.
TheHDS4NLP system ranked 6th on the Ge-nia task (43.03% f-score), and after fix-ing a bug discovered after the final submis-sion, it outperforms the winner of this task(with a f-score of 51.15%).1 IntroductionHuge amounts of electronic biomedical docu-ments, such as molecular biology reports or ge-nomic papers are generated daily.
Automaticallyorganizing their content in dedicated databases en-ables advanced search and ease information re-trieval for practitioners and researchers in biology,medicine or other related fields.
Nowadays, thesedata sources are mostly in the form of unstruc-tured free text, which is complex to incorporateinto databases.
Hence, many research events areorganized around the issue of automatically ex-tracting information from biomedical text.
Effortsdedicated to biomedical text are necessary becausestandard Natural Language Processing tools can-not be readily applied to extract biomedical eventssince they involve highly domain-specific jargonand dependencies (Kim et al 2011).This paper describes the HDS4NLP entry to oneof these challenges, the Genia task (GE) of theBioNLP 2013 shared task.
The HDS4NLP sys-tem is based on a novel model designed to directlyextract events having a pairwise structure (trigger,Figure 1: Part of a sentence and corresponding events for theBioNLP 2013 GE task.argument), in contrast to standard pipeline modelswhich first extract the trigger and then search forthe argument.
Combining these two steps enablesto use more sophisticated event features whilelargely avoiding error propagation.
The model us-age is also simple, in the sense that it does not relyon any complex and costly inference process asrequired by joint global systems based on IntegerLinear Programming.The official HDS4NLP entry was only ranked6th on the GE task (with 43.03% f-score).
How-ever, after fixing a bug discovered after the finalsubmission, the HDS4NLP system outperformedthe winner of the GE task, with a f-score 51.15%to be compared to the 50.97% of EVEX.2 BioNLP Genia TaskBioNLP Genia task aims at extracting event for-mulas from text sentences, which are defined assequences of tokens (words, numbers, or sym-bols).
Events are constituted of two elements: anevent trigger and one or several arguments.
Theevent trigger is a sequence of tokens that indicatesan event is mentioned in the text.
The argumentsof an event are participants, which can be pro-teins, genes or other biomedical events.
Figure 1illustrates the GE task: given 3 proteins ?Tax?,?CBP?
and ?p300?, one must detect ?recruit?
asan event trigger and then extract two formulas:( ?recruit?, Theme:?Tax?, Theme2:?CBP?)
and(?recruit?, Theme:?Tax?, Theme2:?p300?
), bothwith event type Binding.In our work, we process tokens differently de-pending on whether they are marked as proteins inthe annotation or not; the latter are termed candi-date tokens.
A key part of the task is to detect the45trigger tokens among the candidates.
The BioNLP2013 GE task considers 13 types of events, but weonly dealt with the 9 types already existing in the2011 GE task, because there was not enough dataon the newly defined event types for proper train-ing or model selection.Table 1 lists these events and their properties.The 9 event types may be merged into three maingroups: the first 5 have a single argument, aTheme; the Binding event can accept up to twoarguments (2 Themes); the last 3 types also ac-cept up to two arguments, a Theme and an optionalCause.
In the following, we refer to the first 6types as non-regulation events and to the remain-ing 3 as regulation ones.Event type Principal arg Optional argGene_expression Theme (P)Transcription Theme (P)Protein_catabolism Theme (P)Phosphorylation Theme (P)Localization Theme (P)Binding Theme (P) Theme2 (P)Regulation Theme (E/P) Cause (E/P)Positive_regulation Theme (E/P) Cause (E/P)Negative_regulation Theme (E/P) Cause (E/P)Table 1: Main types of events with their arguments (P standsfor Protein, E for Event).3 Previous WorkThe preceding approaches falls into two main cat-egories: pipeline incremental models and jointglobal methods.Pipeline approaches (S?tre et al 2009; Co-hen et al 2009; Bj?rne et al 2009) are the sim-plest way to tackle the problem of event extrac-tion.
A sequence of classifiers are ran on the text tosuccessively (1) detect non-regulation event trig-gers, (2) assign them arguments, (3) detect regula-tion event triggers and (4) assign them arguments.Such systems are relatively easy to set up but suf-fer from error cascading.
Besides, they detect trig-gers using classifiers solely taking tokens as in-put, or involve dependency parse information bytree depth other than a concrete potential argument(Bj?rne et al 2009).In the corpuses used in 2009 and 2011 for theGE task, some tokens belong to several events ofdifferent types; their classification thus requires tosolve a multi-label problem.
We believe that de-tecting triggers in isolation breaks the structuredproblem down to excessively fine-grained sub-tasks, with contextual information loss that leadsto ill-posed problems.Global approaches (Riedel et al 2009; Mc-Closky et al 2011) aim at solving the whole taskat once, so as to resolve the drawbacks of pipelinemodels.
In (McClosky et al 2011), event an-notations are converted into pseudo-syntactic rep-resentations and the task is solved as a syntacticextraction problem by traditional parsing meth-ods.
(Riedel et al 2009; Riedel and McCallum,2011a; Riedel et al 2011; Riedel and McCallum,2011b) encode the event annotations as latent bi-nary variables indicating the type of each tokenand the relation between each pair of them (pro-tein or candidate) in a sentence.
The state of thesevariables is predicted by maximizing the globallikelihood of an Integer Linear Program.This jointmodel achieves good performance (winner of the2011 GE task), but might be overly complicated,as it considers all possible combinations of tokens,even unlikely ones, as potential events together.4 Pairwise ModelOur new pairwise approach operates at the sen-tence level.
We denote CS = {ei}i the set of can-didate tokens, AS = {aj}j the set of candidatearguments in a given sentence S, and the set ofevent types (augmented by None) is denoted Y .The first step of a pipeline model assigns labelsto candidate tokens ei ?
CS .
Instead, our pair-wise model addresses the problem of classifyingcandidate-argument pairs (ei, aj) ?
CS?AS .
De-noting fk the binary classifier predicting the eventtype k ?
Y , event extraction is performed by:?
(ei, aj) ?
CS ?AS , y?ij = argmaxk?Yfk(ei, aj) .Variable y?ij encodes the event type of the pairmade of the candidate token ei and the argumentaj , an event being actually extracted when y?ij 6=None.
For the fk classifiers, we use Support Vec-tor Machines (SVMs) (using implementation fromscikit-learn.org) in a one-vs-rest setting.We used procedures from (Duan et al 2003; Platt,1999; Tax and Duin, 2002) to combine the outputsof these binary classifiers in order to predict a sin-gle class from Y for each pair (ei, aj).This simple formulation is powerful becauseclassifying a pair (ei, aj) as not-None jointly de-tects the event trigger ei and its argument aj .
Forall event types with a single argument, predictingy?
variables directly solves the task.
Working onpairs (ei, aj) also allows to take into account in-teractions, in particular through dedicated features46describing the connection between the trigger andits argument (see Section 6).
Finally, classifyingpairs (ei, aj) is conceptually simpler than classi-fying ei: the task is a standard classification prob-lem instead of a multi-label problem.
Note thatentity ei may still be assigned to several categoriesthrough the allocation of different labels to pairs(ei, aj) and (ei, ak).Though being rather minimalist, the pairwisestructure captures a great deal of trigger-argumentinteractions, and the simplicity of the structureleads to a straightforward inference procedure.Compared to pipeline models, the main drawbackof the pairwise model is to multiply the number ofexamples to classify by a card(AS) factor.
How-ever, SVMs can scale to large numbers of exam-ples and card(AS) is usually low (less than 10).5 Application to BioNLP Genia TaskFor any given sentence, our system sequentiallysolves a set of 4 pairwise relation extraction prob-lems in the following order:1.
Trigger-Theme pair extraction (T-T),2.
Binding-Theme fusion (B-T),3.
Regulation-Theme pair extraction (R-T),4.
Regulation-Cause assignment (R-C).Steps T-T and R-T are the main event extrac-tion steps because they detect the triggers and oneargument.
Since some events can accept multi-ple arguments, we supplement T-T and R-T withsteps B-T and R-C, designed to potentially add ar-guments to events.
All steps are detailed below.Steps T-T & R-T Both steps rely on our pair-wise model to jointly extract event triggers, deter-mine their types and corresponding themes.
How-ever, they detect different triggers with differentpotential argument sets: for step T-T, AS con-tains only proteins and Y = {Gene_expression,Transcription, Protein_catabolism, Phosphoryla-tion, Localization, Binding, None}.
For step R-T, AS contains proteins and all predicted trig-gers, Y = {Regulation, Positive_regulation, Neg-ative_regulation, None}.Steps B-T & R-C These steps attempt to assignoptional arguments to Binding or regulation eventsdetected by T-T or R-T respectively.
They proceedsimilarly.
Given an extracted event (ei, aj) and acandidate argument set AS = {ak}, all combina-tions {(ei, aj , ak)|k 6= j} are classified by a bi-nary SVM.
For B-T, AS contains all the proteinsType FeaturesSurface features StemString after ?-?String while pruning ?-?
and/or ?/?Prefix of tokenSemantic features Lemma from WordNetPart-of-speech (POS) tagToken annotated as proteinTable 2: Word features.of the sentence S that were extracted as argumentof a Binding event by T-T. For R-C, AS containsall proteins and triggers detected by T-T.
In bothcases, a post-processing step is used to select thelongest combination.6 FeaturesWe present here our features and preprocessing.Candidate set For each sentence S, the set CSis built using a trigger gazetteer: candidates arerecursively added by searching first the longest to-kens sequences from the gazetteer.
For candidateswith several tokens, a head token is selected usingan heuristic based on the dependency parse.Candidate tokens Three types of features areused, either related to the head token, a word win-dow around it, or its parent and child nodes in thedependency tree.
Table 2 lists word features.Proteins The protein name is a useless feature,so the word features of the head token were re-moved for proteins.
Word features of the neigh-boring tokens and of the parent node in the de-pendency tree were still included.
Proteins arealso described using features extracted from theUniprot knowledge base (uniprot.org).Pairwise relations Our pairwise method is aptto make use of features that code interactions be-tween candidate triggers and arguments.
Thesepatterns are defined from the path linking two to-kens in the dependency parse tree of the sentence.Special care was taken to perform tokenizationand sentence splitting because this has an impor-tant impact on the quality of the dependency parsetrees.
Data was split in sentences using both thenltk toolkit (nltk.org) and the support anal-ysis provided for the BioNLP 2013 GE task.
To-kenization was carried out using a slightly mod-ified version of the tokenizer from the Stanfordevent parser (McClosky et al 2011).
The de-pendency parse trees were finally obtained usingphrase structure parser (McClosky et al 2010)47combined with post-processing using the Stanfordcorenlp package (De Marneffe et al 2006).Incorporating dependency information into thepairwise model relies on the process encoding thepath into feature vectors.
Many formatting meth-ods have been proposed in previous works, suchas E-walks, that format the path into triplets (dep,word, dep), V-walks that use triplets (word, dep,word) or simply N-grams of words, following thedependency parse: words are usually encoded viastem and POS tags, and dep by the dependencylabels (Miwa et al 2010).
All these imperfectrepresentations lose a lot of information and caneven add noise, especially when the path is long.Hence dependency parse features are processedonly for pairs for which the candidate-argumentpath length is below a threshold whose value is ahyper-parameter.7 Experimental ResultsThe hyper-parameters of our system have been op-timized on the BioNLP 2013 GE task developmentset, after training on the corresponding trainingset.
Using these hyper-parameter values, the fi-nal model submitted for test evaluation on the GEtask server has been trained on all documents fromtraining and development sets of BioNLP 2011and 2013 GE tasks.Table 3 lists the test results of our official sub-mission.
Our system achieved the best score forSIMPLE ALL and second best for PROT-MODALL, but it suffered from a rather poor perfor-mance on REGULATION ALL, causing a lowoverall score relegating the submission to the 6thplace in the competition.Event Class recall prec.
f-scoreSIMPLE ALL 75.27 83.27 79.07Binding 41.74 33.74 37.32PROT-MOD ALL 70.68 75.84 73.17REGULATION ALL 16.67 30.86 21.64EVENT ALL 37.11 51.19 43.03Table 3: Official test evaluation results.After the test results were disclosed, we sus-pected that our poor results on REGULATIONALL were due to a bug, which was eventually dis-covered in the post-processing step of R-C. Were-trained our system after having fixed the bugon the latest revision of the training set (our of-ficial entry used revision 2 of the training set in-stead of revision 3, which resulted in slightly dif-ferent annotations for Binding events).
This ledEvent Class recall prec.
f-scoreBinding 43.24 34.37 38.30REGULATION ALL 31.43 47.70 37.89EVENT ALL 45.96 57.66 51.15Table 4: Test evaluation results after bug fix.to the results displayed in Table 4 (we only showresults that differ from Table 3).
Our system ac-tually achieves a EVENT ALL f-score of 51.15%,instead of 43.03%: this rating is higher than thebest score of the BioNLP 2013 GE task (50.97%).To compare to previous models, we also trainedour system on BioNLP2011 GE task training setand evaluated it on development set.
Our ap-proach reaches a EVENT ALL f-score of 51.28%,which is lower than that of this challenge?s winner,the FAUST system (Riedel et al 2011) (55.9%).However, FAUST is a combination of several dif-ferent models, compared to the UMass model(Riedel and McCallum, 2011a), which is the mainconstituent of FAUST, we achieve a higher EVTscore (74.93% vs 74.7%) but a lower overall score(51.28% vs 54.8%).
Our system is outperformedon Binding and Regulation events; this indicatesthe directions in which it should be improved.8 ConclusionThis paper introduced a pairwise model designedfor biomedical event extraction, which, after bugfix, outperforms the best performance of theBioNLP 2013 GE task.
This system decomposesthe overall task into the multi-class problem ofclassifying (trigger, argument) pairs.
Relying ofthis pairwise structure for input examples allowsto use joint (trigger, argument) features, to avoidcostly global inference procedures over sentencesand to solve a simple multi-class problem insteadof a multi-label multi-class one.Still, some issues remain.
We currently cannotextract regulation events whose arguments are an-other regulation event.
We are also subject to somecascading error between steps T-T and R-T.
In fu-ture works, we intend to improve our system byturning it into a dynamic online process that willperform recursive event extraction.AcknowledgmentsThis work was carried out in the framework ofthe Labex MS2T (ANR-11-IDEX-0004-02), andfunded by the French National Agency for Re-search (EVEREST-12-JS02-005-01).48ReferencesJari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Ex-tracting complex biological events with rich graph-based feature sets.
In Proceedings of the BioNLP2009 Workshop Companion Volume for Shared Task,pages 10?18, Boulder, Colorado, June.
Associationfor Computational Linguistics.K.
Bretonnel Cohen, Karin Verspoor, Helen John-son, Chris Roeder, Philip Ogren, William Baumgart-ner, Elizabeth White, and Lawrence Hunter.
2009.High-precision biological event extraction with aconcept recognizer.
In Proceedings of the BioNLP2009 Workshop Companion Volume for Shared Task,pages 50?58, Boulder, Colorado, June.
Associationfor Computational Linguistics.Marie-Catherine De Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of LREC, volume 6, pages 449?454.Kaibo Duan, S. Sathiya Keerthi, Wei Chu, Shirish Kr-ishnaj Shevade, and Aun Neow Poo.
2003.
Multi-category classification by soft-max combination ofbinary classifiers.
In In 4th International Workshopon Multiple Classifier Systems.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, Ngan Nguyen, and Jun?ichi Tsujii.
2011.Overview of BioNLP shared task 2011.
In Proceed-ings of BioNLP Shared Task 2011 Workshop, pages1?6, Portland, Oregon, USA, June.
Association forComputational Linguistics.David McClosky, Eugene Charniak, and Mark John-son.
2010.
Automatic domain adaptation for pars-ing.
In Human Language Technologies: The 2010Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,HLT ?10, pages 28?36, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.David McClosky, Mihai Surdeanu, and Christopher D.Manning.
2011.
Event extraction as dependencyparsing.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies - Volume 1,HLT ?11, pages 1626?1635, Stroudsburg, PA, USA.Association for Computational Linguistics.Makoto Miwa, Rune S?tre, Jin-Dong Kim, andJun?ichi Tsujii.
2010.
Event extraction withcomplex event classification using rich features.J.
Bioinformatics and Computational Biology,8(1):131?146.John C. Platt.
1999.
Probabilistic outputs for sup-port vector machines and comparisons to regularizedlikelihood methods.
In Advances in Large MarginClassifiers, pages 61?74.
MIT Press.Sebastian Riedel and Andrew McCallum.
2011a.
Fastand robust joint models for biomedical event extrac-tion.
In Proceedings of the 2011 Conference on Em-pirical Methods in Natural Language Processing,pages 1?12, Edinburgh, Scotland, UK., July.
Asso-ciation for Computational Linguistics.Sebastian Riedel and Andrew McCallum.
2011b.
Ro-bust biomedical event extraction with dual decom-position and minimal domain adaptation.
In Pro-ceedings of BioNLP Shared Task 2011 Workshop,pages 46?50, Portland, Oregon, USA, June.
Asso-ciation for Computational Linguistics.Sebastian Riedel, Hong-Woo Chun, Toshihisa Takagi,and Jun?ichi Tsujii.
2009.
A Markov logic approachto bio-molecular event extraction.
In Proceedings ofthe BioNLP 2009 Workshop Companion Volume forShared Task, pages 41?49, Boulder, Colorado, June.Association for Computational Linguistics.Sebastian Riedel, David McClosky, Mihai Surdeanu,Andrew McCallum, and Christopher D. Manning.2011.
Model combination for event extraction inBioNLP 2011.
In Proceedings of BioNLP SharedTask 2011 Workshop, pages 51?55, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.Rune S?tre, Makoto Miwa, Kazuhiro Yoshida, andJun?ichi Tsujii.
2009.
From protein-protein interac-tion to molecular event extraction.
In Proceedingsof the BioNLP 2009 Workshop Companion Volumefor Shared Task, pages 103?106, Boulder, Colorado,June.
Association for Computational Linguistics.D.
M. J.
Tax and R. P. W. Duin.
2002.
Using two-classclassifiers for multiclass classification.
In Proceed-ings of the 16th International Conference on PatternRecognition, volume 2, pages 124?127 vol.2.49
