Learning to identify animate referencesConstantin Ora?sanSchool of Humanities, Languagesand Social SciencesUniversity of WolverhamptonC.Orasan@wlv.ac.ukRichard EvansSchool of Humanities, Languagesand Social SciencesUniversity of WolverhamptonR.J.Evans@wlv.ac.ukAbstractInformation about the animacy ofnouns is important for a wide range oftasks in NLP.
In this paper, we presenta method for determining the animacyof English nouns using WordNet andmachine learning techniques.
Ourmethod firstly categorises the sensesfrom WordNet using an annotatedcorpus and then uses this informationin order to classify nouns for whichthe sense is not known.
Our evaluationresults show that the accuracy of theclassification of a noun is around 97%and that animate entities are moredifficult to identify than inanimateones.1 IntroductionInformation on the gender of noun phrase (NP)referents can be exploited in a range of NLPtasks including anaphora resolution and theapplications that can benefit from it such ascoreference resolution, information retrieval,information extraction, machine translation,etc.
The gender of NP referents is explicitlyrealised morphologically in languages such asRomanian, French, Russian, etc.
in which thehead of the NP or the NP?s determiner undergoespredictable morphological transformation oraffixation to reflect its referent?s gender.
In theEnglish language, the gender of NPs?
referents isnot predictable from the surface morphology.Moreover, in (Evans and Ora?san, 2000) it wasargued that it is not always desirable to obtaininformation concerning the specific gender ofa NP?s referent in English.
Instead, it is moreeffective to obtain the animacy of each NP.
Wedefine animacy as the property of a NP wherebyits referent, in singular rather than plural number,can be referred to using a pronoun in the setfhe, him, his, himself, she, her, hers, herselfg.During the course of this paper, we will discussanimate and inanimate senses of nouns and verbs.We use these expressions to denote the sensesof nouns that are the heads of NPs referring toanimate/inanimate entities and the senses of verbswhose agents are typically animate/inanimateentities.In our previous work, we investigated the useof WordNet in order to determine the animacy ofentities in discourse.
There, we used the fact thateach noun and verb sense is derived from uniqueclasses called unique beginners.
We classifiedeach unique beginner as being a hypernym of aset of senses that were for the most part eitheranimate or inanimate (in the case of nouns) orindicative of animacy/inanimacy in their subjects(in the case of verbs).
In classifying a noun, thenumber of its senses that belong to an animateclass is compared with the number belongingto an inanimate class, and this information isused to make the final classification.
In addition,if the noun is the head of a subject, the sameinformation is computed for the verb.
Ourassumption was that a noun with many animatesenses is likely to be used to refer to an animateentity.
For subjects, the information from themain verb was used to take into consideration thecontext of the sentence.
That system, referredto in this paper as the previous system also useda proper name gazetteer and some simple ruleswhich mainly assisted in the classification ofnamed entities.
For reasons explained in Section4.2, these additions to the basic algorithm wereignored in the comparative evaluation describedthere.Experiments with that algorithm showed it tobe useful.
Applied to a system for automaticpronominal anaphora resolution, it led to asubstantial improvement in the ratio of suitableand unsuitable candidates in the sets consideredby the anaphora resolver (Evans and Ora?san,2000).However, the previous system has two mainweaknesses.
The first one comes from the factthat the classes used to determine the numberof animate/inanimate senses are too general, andin most cases they do not reliably indicate theanimacy of each sense in the class.
The secondweakness is due to the naive nature of the rulesthat decide if a NP is animate or not.
Theirapplication is simple and involves a comparisonof values obtained for a NP with threshold valuesthat were determined on the basis of a relativelysmall number of experiments.In this paper, we present a new method foranimacy identification which uses WordNet andmachine learning techniques.
The remainderof the paper is structured as follows.
Section2 briefly describes some concepts concerningWordNet that are used in this paper.
In Section 3,our two step method is described.
An evaluationof the method and discussion of the results ispresented in Section 4.
We end the paper byreviewing previous related work and drawingsome conclusions.2 Background informationAs previously mentioned, in this researchWordNet (Fellbaum, 1998) is used to identifythe animacy of a noun.
In this section severalimportant concepts from WordNet are explained.WordNet is an electronic lexical resourceorganized hierarchically by relations betweensets of synonyms or near-synonyms calledsynsets.
Each of the four primary classes ofcontent-words, nouns, verbs, adjectives andadverbs are arranged under a small set of so-called unique beginners.
In the case of nounsand verbs, which are the concern of the presentpaper, the unique beginners are the most generalconcepts under which the entire set of entries isorganized on the basis of hyponymy/hypernymyrelations.
Hypernymy is the relation that holdsbetween such word senses as vehicle1-ship1orhuman1-politician1, in which the first itemsin the pairs are more general than the second.Conversely, the second items are more specificthan the first, and are their hyponyms.It is usual to regard hypernymy as a verticallyarranged relationship, with general sensespositioned higher than more specific ones in anontology.
In WordNet, the top-most senses arecalled unique beginners.
Senses at the samevertical level in the ontology are also clusteredhorizontally through the synonymy relation insynsets.
In this paper, the term node is usedinterchangeably with synset.As explained in Section 3.1, our methodrequires that the nodes in WordNet are classifiedaccording to their animacy.
Given the size ofWordNet, this task cannot be done manually anda corpus where words are annotated with theirsenses was necessary.
A corpus that meets theserequirements is SEMCOR (Landes et al, 1998),a subset of the Brown Corpus in which the nounsand the verbs have been manually annotated withtheir senses from WordNet.3 The methodIn this section a two step method used to classifywords according to their animacy is presented.
InSection 3.1, we present an automatic method fordetermining the animacy of senses from WordNeton the basis of an annotated corpus.
Once thesenses from WordNet have been classified, aclassical machine learning technique uses thisinformation to determine the animacy of a nounfor which the sense is not known.
This techniqueis presented in Section 3.2.3.1 The classification of the sensesAs previously mentioned, the unique beginnersare too general to be satisfactorily classified asanimate or inanimate.
However, this does not2664HYPERNYManih= aniiinanih= inanii37752664Sense1ani1inani137752664Sense2ani2inani237752664Sense3ani3inani33775  2664Sensenanininanin3775Figure 1: Example of hypernymy relation between senses in WordNetSense1Sense2Sense3... SensenObserved ani1ani2ani3... aninExpected ani1+ inani1ani2+ inani2ani3+ inani3... anin+ inaninTable 1: Contingency table for testing if a hypernym is animatemean that it is not possible to uniquely classifymore specific senses as animate or inanimate.
Inthis section, we present a corpus-based methodwhich classifies the synsets from WordNetaccording to their animacy.The NPs in a 52 file subset of the SEMCORcorpus were manually annotated with animacyinformation and then used by an automatic systemto classify the nodes.
These 52 files contain 2512animate entities and 17514 inanimate entities.The system attempts to classify the sensesfrom WordNet that explicitly appear in thecorpus directly, on the basis of their frequency.1However, our goal is to design a procedure whichis also able to classify senses that are not foundin the corpus.
To this end, we decided to use abottom up procedure which starts by classifyingthe terminal nodes and then continues with moregeneral nodes.
The terminal nodes are classifiedusing the information straight from the annotatedfiles.
When classifying a more general node,the following hypothesis is used: ?if all the1Due to linguistic ambiguities and tagging errors, not allthe senses at this level can be classified adequately in thisway.hyponyms of a sense are animate, then the senseitself is animate?.
However, this does not alwayshold because of annotation errors or rare uses ofa sense and instead, a statistical measure must beused to test the animacy of a more general node.Several measures were considered and the mostappropriate one seemed to be chi-square.Chi-square is a non-parametric test which canbe used for estimating whether or not there isany difference between the frequencies of itemsin frequency tables (Oakes, 1998).
The formulaused to calculate chi-square is:2=X(O  E)2E(1)where O is the observed number of cases and Ethe expected number of cases.
If 2 is less thanor equal to a critical level, we may conclude thatthe observed and expected values do not differsignificantly.Each time that a more general node is to beclassified, its hyponyms are considered.
If all thehyponyms observed in the corpus2 are annotatedas either animate or inanimate (but not both), the2Either directly or indirectly via the hyponymy relations.Generalisation rejected.... for hypernym Def:(any living entity)Ani 16 Inani 3 person (sense 1)++++Def: (a human being; "there was too much for one person to do")Ani 0 Inani 11 animal (sense 1)++++Def: (a living organism characterized by voluntary movement)Figure 2: Example of generalisation rejectedGeneralisation accepted .... for hypernym Def:(the continuum ofexperience in which events pass from the future through thepresent to the past)Ani 0 Inani 9 past (sense 1)++++Def: (the time that has elapsed; "forget the past")Ani 0 Inani 6 future (sense 1)++++Def: (the time yet to come)Figure 3: Example of generalisation acceptedmore general node is classified as its hyponymsare.
However, for the aforementioned reasons,this rule does not apply in all cases.
In theremaining cases the chi-square test is applied.For each more general node which is about tobe classified, two hypotheses are tested: the firstone considers the node animate and the secondone inanimate.
The system classifies the nodeaccording to which test is passed.
If neither arepassed, it means that the node is too general andit and all its hypernyms can equally refer to bothanimate and inanimate entities.For example, a more general node can haveseveral hyponyms as shown in Figure 1.
In thatcase, the hypernym has n hyponyms.
We considereach sense to have two attributes: the numberof times it has been annotated as animate (anii)and the number of times it has been annotatedas inanimate (inanii).
For more general nodes,these attributes are the sum of the number ofanimate/inanimate instances of its hyponyms.When the node is tested to determine whether ornot it is animate, a contingency table like Table1 is built.
Given that we are testing to see if themore general node is animate or not, for each ofits hyponyms, the total number of occurrences ofa sense in the annotated corpus is the expectedvalue (meaning that all the instances should beanimate) and the number of times the hyponym isannotated as referring to an animate entity is theobserved value.
Formula 1 is used to computechi-square, and the result is compared with thecritical level obtained for n-1 degrees of freedomand a significance level of .05.
If the test ispassed, the more general node is classified asanimate.
In a similar way, more general nodesare tested for inanimacy.
Figures 2 and 3 showtwo small examples in which the generalisationis rejected and accepted, respectively.In order to be a valid test of significance, chi-square usually requires expected frequencies to be5 or more.
If the contingency table is larger thantwo-by-two, some few exceptions are allowed aslong as no expected frequency is less than one andno more than 20% of the expected frequencies areless than 5 (Sirkin, 1995).
In our case it is notpossible to have expected frequencies less thanone because this would entail no presence in thecorpus.
If, when the test is applied, more than20% of the senses have an expected frequencyless than 5, the two similar senses with the lowestfrequency are merged and the test is repeated.3 Ifno senses can be merged and still more than 20%of the expected frequencies are less than 5, thetest is rejected.3.2 The classification of a wordThe classification described in the previoussection is useful for determining the animacy of asense, even for those which were not previouslyfound in the annotated corpus, but which arehyponyms of a node that has been classified.However, nouns whose sense is unknown cannotbe classified directly and therefore an additionallevel of processing is necessary.
In this section,we show how TiMBL (Daelemans et al, 2000)3Two senses are considered similar if they both have thesame attribute equal to zero.was used to determine the animacy of nouns.TiMBL is a program which implements severalmachine learning techniques.
After trying thealgorithms available in TiMBL with differentconfigurations, the best results were obtainedusing instance-based learning with gain ratio asthe weighting measure (Quinlan, 1993; Mitchell,1997).
In this type of learning, all the instancesare stored without trying to infer anything fromthem.
At the classification stage, the algorithmcompares a previously unseen instance withall the data stored at the training stage.
Themost frequent class in the k nearest neighboursis assigned as the class to which that instancebelongs.
After experimentation, it was noticedthat the best results were obtained when k=3.In our case the instances used in trainingand classification consist of the followinginformation: The lemma of the noun which is to beclassified. The number of animate and inanimate sensesof the word.
As we mentioned before, inthe cases where the animacy of a sense isnot known, it is inferred from its hypernyms.If this information cannot be found for anyof a word?s hypernyms, information on theunique beginners for the word?s sense isused, in a manner similar to that used in(Evans and Ora?san, 2000). If the word is the head of a subject, thenumber of animate/inanimate senses ofits verb.
For those senses for which theclassification is not known, an algorithmsimilar to the one described for nouns isemployed.
These values are 0 for heads ofnon-subjects. The ratio of the number of animate singularpronouns (e.g he or she) to inanimatesingular pronouns (e.g.
it) in the whole text.The output of this stage is a list of nounsclassified according to their animacy.4 Evaluation and discussionIn this section we examine the performanceof the system, particularly with respect to theclassification of nouns; investigate sources oferrors; and highlight directions for future researchand improvements to the system.4.1 The performance of the systemThe system was evaluated with respect to twocorpora.
The first one consists of the files selectedfrom the SEMCOR corpus stripped of the senseannotation.
The second one is a selection oftexts from Amnesty International (AI) used in ourprevious research.
These texts have been selectedbecause they include a relatively large number ofreferences to animate entities.
By including thetexts from the second corpus we could comparethe results of our previous system with thoseobtained here.
In addition, we can assess theresults of the algorithm on data which was notused to determine the animacy of the senses.
Thecharacteristics of the two corpora are presented inTable 2.In this research three measures were usedto assess the performance of the algorithm:accuracy, precision and recall.
The accuracy isthe ratio between the number of items correctlyclassified and the total number of items to beclassified.
This measure assesses the performanceof the classification algorithm, but can be slightlymisleading because of the greater number ofinanimate entities in texts.
In order to alleviatethis problem, we computed the precision andrecall for each type of classification.
Theprecision with which the method classifiesanimate entities is defined as the ratio betweenthe number of entities it correctly classifiesas animate and the total number of entities itclassifies as animate (including the ones wronglyassigned to this class).
The method?s recallover this task is defined as the ratio between thenumber of entities correctly classified as animateby the method and the total number of animateentities to be classified.
The precision and recallfor inanimate entities is defined in a similarmanner.We consider that by using recall and precisionfor each type of entity we can better assess theperformance of the algorithms.
This is mainlybecause the large number of inanimate entities areconsidered separately from the smaller number ofanimate entities.
In addition to this, by separatingCorpus No of words No.
of animate entities No of inanimate entitiesSEMCOR 104612 2512 17514AI 15767 537 2585Table 2: The characteristics of the two corpora usedAnimacy InanimacyExperiment Accuracy Precision Recall Precision RecallBaseline on SEMCOR 37.62% 8.40% 74.44% 88.41% 31.64%Baseline on AI 31.01% 18.07% 76.48% 79.27% 20.60%Previous system on AI 64.87% 93.88% 36.09% 81.00 % 99.14%New System on SEMCOR 97.51% 88.93% 91.03% 98.74% 98.41%New System on AI 97.69% 94.28% 92.17% 98.38% 98.83%Table 3: The results of the evaluationthe evaluation of the classification of animateentities from the one for inanimate entities we canassess the difficulty of each classification.Table 3 presents the results of the method onthe two data sets.
For the experiment with theSEMCOR corpus, we evaluated it using five-foldcross-validation.
We randomly split the wholecorpus into five disjoint parts, using four parts fortraining and one for evaluation.
We repeated thetraining-evaluation cycle five times, making surethat the whole corpus was used.
Note that foreach iteration of the cross-validation, the learningprocess begins from scratch.
The results reportedwere obtained by averaging the error rates fromeach of the 5 runs.
In the second experiment, all52 files from the SEMCOR corpus were used fortraining and the texts from Amnesty Internationalfor testing.In addition to the results of the methodpresented in this paper, Table 3 presents theresults of a baseline method and of the methodpreviously proposed in (Evans and Ora?san, 2000).In the baseline method, the probability that anentity is classified as animate is proportionalto the number of animate third person singularpronouns in the text.As can be seen in Table 3 the accuracy of thebaseline is very low.
The results of our previousmethod are considerably higher, but still poorin the case of animate entities with many ofthese being classified as inanimate.4 This can4Due to time constraints and the large amount of effortbe explained by the fact that most of the uniquebeginners were classified as inanimate, andtherefore there is a tendency to classify entitiesas inanimate.
The best results were obtainedby the new method over both corpora, the mainimprovement being noticed in the classificationof animate entities.Throughout this section we referred to theclassification of ambiguous nouns without tryingto assess how successful the classification of thesynsets in WordNet was.
Such an assessmentwould be interesting, but would require manualclassification of the nodes in WordNet, andtherefore would be somewhat time consuming.Even though this evaluation was not carried out,the high accuracy of the system suggests that thecurrent classification is useful.4.2 Comments and error analysisDuring the training phase of TiMBL, the programcomputes the importance of each feature forthe classification.
The most important featureaccording to the gain ratio is the number ofanimate senses of a noun followed by the numberof inanimate senses of the noun.
This wasexpected given that our method is based on theidea that in most of the cases the number ofanimate and inanimate senses determines theanimacy of a noun.
However, this would meanthat the same noun will be classified in the samerequired to transform the input data into a format usableby the previous method, it was not possible to assess itsperformance with respect to the SEMCOR corpus.way regardless of the text.
Therefore, three textdependent features were introduced.
They are thenumber of animate and inanimate senses of thepredicate of the sentence if the noun is a subject,and the ratio between the number of animatethird-person singular pronouns and inanimatethird-person singular pronouns in the text.
Interms of importance, gain ratio ranks them fourth,fifth and sixth, respectively, after the lemma ofthe noun.
The lemma of the noun was includedbecause it was noticed that this improves theaccuracy of the method.During the early stages of the evaluation, theclassification of personal names proved to be aconstant source of errors.
Further investigationshowed that the system performed poorly on alltypes of named entities.
For the named entitiesreferring to companies, products, etc.
this canbe explained by the fact that in many cases theyare not found in WordNet.
However, in mostcases the system correctly classified them asinanimate, having learned that most unknownwords belong to this class.
Entities denoted bypersonal names were constantly misclassifiedeither because the names were not in WordNet orelse they appeared with a substantial number ofinanimate senses (e.g.
the names Bob and Mariado not have any senses in WordNet which couldrelate them to animate entities).
In light of theseerrors we decided not to present our system withnamed entities.
With no access to more accuratetechniques, we considered non-sentence-initialcapitalised words as named entities and removedthem from the evaluation data.
Even when thiscrude filtering was applied, we still presenteda significant number of proper names to oursystem.
This partially explains its lower accuracywith respect to the classification of animateentities.By attempting to filter proper names, wecould not compare the new system with the onereferred to as the extended algorithm in (Evansand Ora?san, 2000).
In future, we plan to addressthe problem of named entities by using gazetteersor, alternatively, developing more sophisticatednamed entity recognition methods.Another source of errors is the unusual usageof senses.
For example someone can refer to theirpet with he or she, and therefore according toour definition they should be considered animate.However, given the way the algorithm is designedthere is no way to take these special uses intoconsideration.5Another problem with the method is the factthat all the senses have the same weight.
Thismeans that a word like pupil, which has twoanimate senses and one inanimate, is highlyunlikely to be classified as inanimate, even ifit used to refer to a specific part of the eye.6The ideal solution to this problem would be todisambiguate the words, but this would require anaccurate disambiguation method.
An alternativesolution is to weight the senses with respect tothe text.
In this way, if a sense is more likely tobe used in a text, its animacy/inanimacy will havegreater influence on the classification process.
Atpresent, we are trying to integrate the word sensedisambiguation method proposed in (Resnik,1995) into our system.
We hope that this willparticularly improve the classification of animateentities.5 Related workMost of the work on animacy/gender recognitionhas been done in the field of anaphora resolution.The automatic recognition of NP gender onthe basis of statistical information has beenattempted before (Hale and Charniak, 1998).That method operates by counting the frequencywith which a NP is identified as the antecedent ofa gender-marked pronoun by a simplistic pronounresolution system.
It is reported that by usingthe syntactic Hobbs algorithm (Hobbs, 1976)for pronoun resolution, the method was able toassign the correct gender to proper nouns in atext with 68.15% precision, though the methodwas not evaluated with respect to the recognitionof gender in common NPs.
The method hastwo main drawbacks.
Firstly, it is likely to beineffective over small texts.
Secondly, it seems5However, it is possible to reclassify the nodes fromWordNet using an annotated corpus where the pets areanimate, but this would make the system consider all theanimals which can be pets animate.6Actually the only way this word would be classified asinanimate is if it is in the subject position, and most of thesenses of its main verb are inanimate.
This is explained bythe way the senses are weighted by the machine learningalgorithm.that the approach makes the assumption thatanaphora resolution is already effective, eventhough, in general, anaphora resolution systemsrely on gender filtering.In (Denber, 1998), WordNet was used todetermine the animacy of nouns and associatethem with gender-marked pronouns.
The detailspresented are sparse and no evaluation is given.Cardie and Wagstaff (1999) combined the use ofWordNet with proper name gazetteers in orderto obtain information on the compatibility ofcoreferential NPs in their clustering algorithm.Again, no evaluation was presented with respectto the accuracy of this animacy classificationtask.6 Conclusions and future workIn this paper, a two step method for animacyrecognition was proposed.
In the first step, ittries to determine the animacy of senses fromWordNet on the basis of an annotated corpus.
Inthe second step, this information is used by aninstance based learning algorithm to determinethe animacy of a noun.
This area has beenrelatively neglected by researchers, therefore acomparison with other methods is difficult tomake.
The accuracy obtained is around 97%,more than 30% higher than that obtained by ourprevious system.Investigation of the results showed that inorder to obtain accuracy close to 100%, severalresources have to be used.
As we point out inSection 4.2, a method which is able to weightthe senses of a noun according to the text,and a named entity recogniser are necessary.The requirement for such components helps toemphasise the problematic nature of NP animacyrecognition.
We believe that such an investmentshould be made in order to go forward with thisuseful enterprise.ReferencesClaire Cardie and Kiri Wagstaff.
1999.
Nounphrase coreference as clustering.
In Proceedings ofthe 1999 Joint SIGDAT conference on EmphiricalMethods in NLP and Very Large Corpora (ACL?99),pages 82 ?
89, University of Maryland, USA.Walter Daelemans, Jakub Zavarel, Ko van der Sloot,and Antal van den Bosch.
2000.
Timbl: Tilburgmemory based learner, version 3.0, reference guide,ilk technical report 00-01.
ILK 00-01, TilburgUniversity.Michael Denber.
1998.
Automatic resolution ofanaphora in english.
Technical report, EastmanKodak Co, Imaging Science Division.Richard Evans and Constantin Ora?san.
2000.Improving anaphora resolution by identifyinganimate entities in texts.
In Proceedings ofthe Discourse Anaphora and Reference ResolutionConference (DAARC2000), pages 154 ?
162,Lancaster, UK, 16 ?
18 November.Christiane Fellbaum, editor.
1998.
WordNet: AnEletronic Lexical Database.
The MIT Press.John Hale and Eugene Charniak.
1998.
Getting usefulgender statistics from english textx.
TechnicalReport CS-98-06, Brown University.Jerry Hobbs.
1976.
Pronoun resolution.
Researchreport 76-1, City College, City University of NewYork.Shari Landes, Claudia Leacock, and Randee I. Tengi.1998.
Building semantic concordances.
InFellbaum (Fellbaum, 1998), pages 199 ?
216.Tom M. Mitchell.
1997.
Machine learning.
McGraw-Hill.Michael P. Oakes.
1998.
Statistics for CorpusLinguistics.
Edinburgh Textbooks in EmpiricalLinguistics.
Edinburgh University Press.J.
Ross Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann.Philip Resnik.
1995.
Disambiguating noun groupingswith respect to Wordnet senses.
In David Yarovskyand Kenneth Church, editors, Proceedings of theThird Workshop on Very Large Corpora, pages54?68, Somerset, New Jersey.
Association forComputational Linguistics.R.
Mark Sirkin.
1995.
Statistics for the socialsciences.
SAGE Publications.
