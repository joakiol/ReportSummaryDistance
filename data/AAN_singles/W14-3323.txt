Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 201?206,Baltimore, Maryland USA, June 26?27, 2014.c?2014 Association for Computational LinguisticsManawi: Using Multi-Word Expressions and Named Entities to ImproveMachine TranslationLiling Tan and Santanu PalApplied Linguistics, Translation and Interpretation DepartmentUniversit?at des Saarlandesliling.tan@uni-saarland.desantanu.pal@uni-saarland.deAbstractWe describe the Manawi1(mAnEv) sys-tem submitted to the 2014 WMT transla-tion shared task.
We participated in theEnglish-Hindi (EN-HI) and Hindi-English(HI-EN) language pair and achieved 0.792for the Translation Error Rate (TER)score2for EN-HI, the lowest among thecompeting systems.
Our main innova-tions are (i) the usage of outputs fromNLP tools, viz.
billingual multi-word ex-pression extractor and named-entity rec-ognizer to improve SMT quality and (ii)the introduction of a novel filter methodbased on sentence-alignment features.
TheManawi system showed the potential ofimproving translation quality by incorpo-rating multiple NLP tools within the MTpipeline.1 IntroductionIn this paper, we present Saarland University(USAAR) submission to Workshop for MachineTranslation 2014 (WMT 2014) using the ManawiMT system.
We participated in the generic trans-lation shared task for the English-Hindi (EN-HI)and Hindi-English (HI-EN) language pairs.Our Manawi system showcased the incorpora-tion of NLP tools output within the MT pipeline; abilingual MWE extractor and a bilingual NE rec-ognizer for English and Hindi were implemented.The output from these NLP tools was appended tothe training corpus prior to the SMT model train-ing with the MOSES toolkit (Koehn et al., 2007).The resulting system achieves the lowest Transla-tion Error Rate (TER) among competing systemsfor the English-Hindi language pair.1Multi-word expression And Named-entity AndWikipedia titles (Manawi)2Lower TER often results in better translationThe rest of the paper is structured as follow:Section 2 describes the implementation of the NLPtools; Section 3 outlines the corpus pre-processingbefore the MT training process; Section 4 de-scribes the MT system setup; Section 5 describesa simple post-processing component to handleOut-Of-Vocabulary words; Section 6 presents theWMT shared task results for the Manawi systemand Section 6 concludes the paper.2 NLP Tools Implementation2.1 Bilingual MWE in MTMulti-Word Expressions (MWE) are defined as?idiosyncratic interpretations that cross wordboundaries?
(Sag et al., 2002).
MWE can be madeup of collocations (e.g.
seem ridiculous : behudadikhai), frozen expressions (e.g.
exception han-dling : apavada sancalaka) or name entities (e.g.Johnny Cash : Johni Kesh).
Jackendoff (1997)claims that the frequency of MWE and the fre-quency of single words in a speaker?s lexicon arealmost equivalent.Bilingual MWE has shown to be useful fora variety of NLP applications such as multilin-gual information retrieval (Vechtomova, 2005)and Crosslingual/Multilingual Word Sense Dis-ambiguation (Tan and Bond, 2013; Finlayson andKulkarni, 2011).
For machine translation, vari-ous studies had introduced bilingual MWE to im-prove MT system performance.
Lambert (2005)introduced bilingual MWE by grouping them asa single token before training alignment modelsand they showed that it improved alignment andtranslation quality.
Ren et al.
(2009) integratedan in-domain bilingual MWE using log likelihoodratio based hierarchical reducing algorithm andgained +0.61 BLEU score.
Similarly, Santanu etal.
(2010) single tokenized MWE before training aphrase-based SMT model and achieved 50% im-provement in BLEU score.201In order to improve the word alignment quality,Venkatapathy and Joshi (2006) reported a discrim-inative approach to use the compositionality infor-mation of verb-based multi-word expressions.
Palet al.
(2011) discussed the effects of incorporatingprior alignment of MWE and NEs directly or indi-rectly into Phrase-based SMT systems.2.2 Bilingual MWE ExtractionMonolingual MWE extraction revolves aroundthree approaches (i) rule-based methods relyingon morphosyntactic patterns, (ii) statistical meth-ods which use association/frequency measures todetermine ngrams as MWE and (iii) hybrid ap-proaches that combine the rule-based and statis-tical methods.However, where bilingual MWE extractiontechniques are concerned, they operate aroundtwo main modus operandi (i) extracting mono-lingual MWE separately and aligning them atword/phrasal level afterwards or (ii) aligning par-allel text at word/phrasal level and then extractingMWE.We implemented a language independent bilin-gual MWE extractor, (Muwee), that produces aparallel dictionary of MWE without the need forany word/phrasal-level alignment.
Muwee makesuse of the fact that the number of highly collocatedMWE should be the same for each sentences pair.Muwee first extracts MWE separately from thesource and target sentences; the MWE are ex-tracted based on bigrams that reports a Point-wise Mutual Information (PMI) score of above10.
Then for each parallel sentence, if the numberof MWE are equivalent for the source and target,the bigrams are joint together as a string and con-tiguous duplicate words are deleted.
The removalof contiguous duplicate words is grounded on thefact that linguistically motivated MWE that formsgrammatical phrases had shown to improve SMTperformances (Pal et al., 2013).
Figure 1 presentsan example of the MWE extraction process.Figure 1: Muwee Extraction Process2.3 Named-entity RecognitionNamed-Entity (NE) recognition is the task of iden-tifying entities such as names of people, organi-zations and locations.
Given a perfect MWE ex-traction system, NEs would have been captured byMWE extraction.
However, the state-of-art MWEextractors have yet been perfected.To compliment the MWE extracted by Muwee,we implemented a bilingual NE extractor bycombining outputs from the (i) Stanford EnglishNE Recognizer (NER)3and (ii) a Do-It-Yourself(DIY) Hindi NER using CRF++ toolkit4with an-notated data from NER-SSEA 2008 shared task(Rajeev Sangal and Singh, 2008).
We trained aConditional Random Field classifier for the HindiNER using unigram features, bigram features anda context window of two words to the left and tothe right.
And we used the DIY Hindi NER andStanford NER tool to monolingually annotate theNEs from training corpus for the EN-HI / HI-ENlanguage pair.Similar to the Muwee bilingual extraction cri-teria, if the number of NEs are the same on thesource and target language, the NEs were joint to-gether as a string.
We note that sometimes thebilingual NER output contains more than one NEper sentence.
For example, our bilingual NER ex-tractor outputs ?Kalpna Chawla Gurdeep Pand-her?, which contains two NEs ?Kalpna Chawla?and ?Gurdeep Pandher?.
Although the resultingbilingual NE does not provide a perfect NE dic-tionary, it filters out NEs from the sentence andimproves word alignments at the start of the MTpipeline.3 Corpus PreprocessingThe performance of any data driven SMT dependson the quality of training data.
Previous stud-ies had shown that filtering out low quality sen-tence pairs improves the quality of machine trans-lation.
For instance, the Moore-Lewis filter re-moves sentence pairs based on source-side cross-entropy differences (Moore and Lewis, 2010) andthe Edinburgh?s MT system used the ModifiedMoore-Lewis filtering (Axelrod et al., 2011) inWMT 2013 shared task (Durrani et al., 2013).CNGL-DCU system extended the Moore-Lewisfilter by incorporating lemmas and named enti-3http://nlp.stanford.edu/software/CRF-NER.shtml4http://crfpp.googlecode.com202ties in their definition of perplexity5(Rubino et al.,2013; Toral, 2013).The RWTH Aachen system filtered the Com-mon Crawl Corpus by keeping only sentence pairsthat contains at least 70% of the word from aknown vocabulary dataset extracted from the othercorpora in the WMT 2013 shared task (Peitz etal., 2013).
The Docent system from Uppsala Uni-versity also performed data cleaning on the Com-mon Crawl dataset prior to SMT but they wereusing more aggressive conditions by (i) remov-ing documents that were identified correctly us-ing a language identification module and (ii) re-moving documents that falls below a thresholdvalue of alignment points and sentence length ra-tio (Stymne et al., 2013).
Our approach to datacleaning is similar to the Uppsala?s system but in-stead of capitalizing on word-alignments features,we were cleaning the data based on sentence align-ment features.3.1 GaCha Filtering: Filter by CharacterMean RatioStymne et al.
(2013) improved translation qual-ity by cleaning the Common Crawl corpus duringthe WMT 2013 shared task.
They filtered out doc-uments exceeding 60 words and cleaned the re-mainder of the corpus by exploiting the numberof alignment points in word alignments betweensentence pairs.
Their hypothesis was that sentencepairs with very few alignment points in the inter-section would mostly likely not be parallel.
Thisis based on the fact that when using GIZA++ (Ochand Ney, 2003), the intersection of alignments ismore sparse than the standard SMT symmetriza-tion heuristics like grow-diag-final-and (Koehn,2005).Different from Stymne et al., our hypothesis fornon-parallelness adheres to sentence level align-ment criteria as defined in the Gale-Church algo-rithm (Gale and Church, 1993).
If a sentence pairis parallel, the ratio of the number of characters inthe source and target sentence should be coherentto the global ratio of the number of source-targetcharacters in a fully parallel corpus.
The Gale-Church algorithm had its parameters tuned to suitEuropean languages and Tan (2013) had demon-strated that sentence-level alignments can be im-proved by using corpus specific parameters.
When5The exponent of cross-entropy may be regarded as per-plexityusing variable parameters to the Gale-Church al-gorithm, Tan showed that instead of the defaultparameters set in the original Gale-Church algo-rithm, using mean ratio of the noisy corpus canalso improve sentence level alignments althoughthe ratio from a clean corpus would achieve evenbetter alignments.Given the premises of the sentence level align-ment hypothesis, we clean the training corpus byfirst calculating the global mean ratio of the num-ber of characters of source sentence to target sen-tence and then filter out sentence pairs that exceedsor fall below 20% of the global ratio.
We call thismethod, GaCha filtering; this cleaning method ismore aggressive than cleaning methods describedby Stymne et al.
but it filters out noisy sen-tence level alignments created by non-languagespecific parameters used by sentence aligners suchas Gale-Church algorithm.3.2 Filtering Noise in HindEnCorpAfter manual inspection 100 random sentencepairs from the HindEnCorp (Bojar et al., 2014),we found that documents were often misalignedat sentence level or contains HTML special char-acters.
To further reduce the noise in the Hin-dEnCorp, the Manawi system was only traineda subset of the HindEnCorp from the follow-ing sources (i) DanielPipes, (ii) TIDES and (iii)EILMT.
Lastly, we filtered the training data on al-lowing a maximum of 100 tokens per language persentence.Finally, the cleaned data contained 87,692 sen-tences, only ?36% of the original HindEnCorptraining data.4 System SetupData: To train the baseline translation model,we have used the cleaned subset of the data asdescribed in Section 3.
For the Manawi model,we added the NLP outputs from the MWE andNE extractors presented in Section 2.
To train themonolingual language model, we used the Hindisentences from the HindEnCorp.System: We used the standard log-linearPhrase based SMT model provided from theMOSES toolkit.Configuration: We experimented with variousmaximum phrase length for the translation and n-203Manawi Submissions (EN-HI) BLEU BLEU TER(cased)PB-SMT + MWE + NE 9.9 7.1 0.869PB-SMT + MWE + NE + Wiki (Manawi) 7.7 7.6 0.864Manawi + GaCha Filter 8.9 8.9 0.818Manawi + GaCha Filter + Handle OOV 8.8 8.8 0.800Manawi + GaCha Filter + Remove OOV 8,9 8.8 0.792Table 1: Manawi System Submissions @ WMT 2014 Translation Shared Task for English-HindiManawi Submissions (HI-EN) BLEU BLEU TER(cased)PB-SMT + MWE + NE + Wiki (Manawi) 7.7 7.6 0.864Manawi + GaCha Filter 8.9 8.9 0.818Table 2: Manawi System Submissions @ WMT 2014 Translation Shared Task for Hindi-Englishgram settings for the language model.
And wefound that using a maximum phrase length of 5and 4-gram language model produced best resultin terms of BLEU and TER for our baseline model(i.e.
without the incorporation of outputs from theNLP tools).
The other experimental settings were:?
GIZA++ implementation of IBM word align-ment model 4 with grow-diagonal-final-andheuristics for performing word alignment andphrase-extraction (Koehn et al., 2003)?
Minimum Error Rate Training (MERT) (Och,2003) on a held-out development set, targetlanguage model with Kneser-Ney smoothing(Kneser and Ney, 1995) using language mod-els trained with SRILM (Stolcke, 2002)?
Reordering model6was trained on bidirec-tional (i.e.
using both forward and back-ward models) and conditioned on both sourceand target language.
The reordering modelis built by calculating the probabilities of thephrase pair being associated with the givenorientation.Innovation: We demonstrated the incorporationof multiple NLP tools outputs in the SMT piplineby simply using automatically extracted bilingualMWE and NEs as additional parallel data to thecleaned data and ran the translation and statisticalmodel as per the baseline configurations.6For reordering we used lexicalized reordering model,which consists of three different types of reordering byconditioning the orientation of previous and next phrases-monotone (m), swap (s) and discontinuous (d).5 Post-processingThe MOSES decoder produces translations withOut-Of-Vocabulary (OOV) words that were nottranslated from the source language.
The Manawisystem post-processed the decoder output by (i)handling OOV words by replacing each OOVword with the most probable translation using thelexical files generated by GIZA++ and (ii) remov-ing OOV words from the decoded outputs.6 ResultsTable 1 summarizes the Manawi system sub-missions for the English-Hindi language pair forWMT 2014 generic translation shared task.
Thebasic Manawi system is a Phrase-based SMT(PB-SMT) setup using extracted MWE and NEsand Wikipedia titles as additional parallel data (i.e.PB-SMT+MWE+NE+Wiki in Table 1).
The ba-sic Manawi system achieved 7.7 BLEU score and0.864 TER.After filtering the data before training the trans-lation model, the Manawi system performed bet-ter at 8.9 BLEU and 0.818 TER.
By adding thepost-processing component, we achieved the low-est TER score among competing team at 0.792.7 ConclusionThe Manawi system showed how simple yet ef-fective pre-processing and integration of outputfrom NLP tools improves the performance of MTsystems.
Using GaCha filtering to remove noisydata and using automatically extracted MWE andNEs as additional parallel data improve word andphrasal alignments at the start of the MT pipeline204which eventually improves the quality of machinetranslation.
The best setup for the Manawi systemachieved the best TER score among the competingsystem.Also, the incremental improvements made bystep-wise implementation of (i) filtering, (ii) in-corporating outputs from NLP tools and (iii) post-processing showed that individual components ofthe Manawi can be integrated into other MT sys-tems without detrimental effects.AcknowledgmentsThe research leading to these results has receivedfunding from the People Programme (MarieCurie Actions) of the European Union?s SeventhFramework Programme FP7/2007-2013/ underREA grant agreement n?317471.The authors of this paper also thank our col-leagues J?org Knappen and Jos?e M.M.
Mart?
?nezfor their help in setting up the server that made theManawi system possible.ReferencesAmittai Axelrod, Xiaodong He, and Jianfeng Gao.2011.
Domain adaptation via pseudo in-domain dataselection.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,pages 355?362.
Association for Computational Lin-guistics.Ond?rej Bojar, Vojt?ech Diatka, Pavel Rychl?y, PavelStra?n?ak, Ale?s Tamchyna, and Dan Zeman.
2014.Hindi-English and Hindi-only Corpus for MachineTranslation.
In Proceedings of the Ninth Interna-tional Language Resources and Evaluation Confer-ence (LREC?14), Reykjavik, Iceland, may.
ELRA,European Language Resources Association.
in prep.Nadir Durrani, Barry Haddow, Kenneth Heafield, andPhilipp Koehn.
2013.
Edinburghs machine transla-tion systems for european language pairs.
In Pro-ceedings of the Eighth Workshop on Statistical Ma-chine Translation, pages 112?119.Mark Alan Finlayson and Nidhi Kulkarni.
2011.
De-tecting multi-word expressions improves word sensedisambiguation.
In Proceedings of the Workshop onMultiword Expressions: From Parsing and Gener-ation to the Real World, MWE ?11, pages 20?24,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.William A Gale and Kenneth W Church.
1993.
Aprogram for aligning sentences in bilingual corpora.Computational linguistics, 19(1):75?102.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, et al.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Pro-ceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,pages 177?180.
Association for Computational Lin-guistics.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
MT summit, 5:79?86.Patrik Lambert.
2005.
Data inferred multi-word ex-pressions for statistical machine translation.
In InMT Summit X.Robert C Moore and William Lewis.
2010.
Intelligentselection of language model training data.
In Pro-ceedings of the ACL 2010 Conference Short Papers,pages 220?224.
Association for Computational Lin-guistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational linguistics, 29(1):19?51.Santanu Pal, Tanmoy Chakraborty, and Sivaji Bandy-opadhyay.
2011.
Handling multiword expressionsin phrase-based statistical machine translation.
In InProceedings of the 13th Machine Translation Sum-mit, pages 215?224.
MT Summit 2011.Santanu Pal, Mahammed Hasanuzzaman, Sudip Ku-mar Naskar, and Sivaji Bandyopadhyay.2013.
Impact of linguistically motivatedshallow phrases in pb-smt.
In ICON 2013http://sivajibandyopadhyay.com/publications/Icon-v1.3-camera.pdf.
ICON 2013.Stephan Peitz, Jan-Thorsten Peter Saab Mansour,Christoph Schmidt, Joern Wuebker, Matthias Huck,Markus Freitag, and Hermann Ney.
2013.
The rwthaachen machine translation system for wmt 2013.
InProceedings of the Eighth Workshop on StatisticalMachine Translation, pages 191?197.Dipti Misra Sharma Rajeev Sangal and Anil KumarSingh, editors.
2008.
Proceedings of the IJCNLP-08 Workshop on Named Entity Recognition for Southand South East Asian Languages.
Asian Federationof Natural Language Processing, Hyderabad, India,January.Zhixiang Ren, Yajuan L?u, Jie Cao, Qun Liu, and YunHuang.
2009.
Improving statistical machine trans-lation using domain bilingual multiword expres-sions.
In Proceedings of the Workshop on MultiwordExpressions: Identification, Interpretation, Disam-biguation and Applications, MWE ?09, pages 47?54, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.205Raphael Rubino, Antonio Toral, S Cort?es Va?llo, JunXie, Xiaofeng Wu, Stephen Doherty, and Qun Liu.2013.
The cngl-dcu-prompsit translation systemsfor wmt13.
In Proceedings of the Eighth Workshopon Statistical Machine Translation, pages 211?216.Ivan A Sag, Timothy Baldwin, Francis Bond, AnnCopestake, and Dan Flickinger.
2002.
Multiwordexpressions: A pain in the neck for nlp.
In Compu-tational Linguistics and Intelligent Text Processing,pages 1?15.
Springer Berlin Heidelberg.Pal Santanu, Sudip Kumar Naskar, Pavel Pecina, SivajiBandyopadhyay, and Andy Way.
2010.
Handlingnamed entities and compound verbs in phrase-basedstatistical machine translation.
In 23rd InternationalConference of Computational Linguistics (Coling2010), Beijing, Chaina, pages 46?54.Sara Stymne, Christian Hardmeier, J?org Tiedemann,and Joakim Nivre.
2013.
Tunable distortion lim-its and corpus cleaning for smt.
In Proceedings ofthe Eighth Workshop on Statistical Machine Trans-lation, pages 225?231.Liling Tan and Francis Bond.
2013.
Xling: Match-ing query sentences to a parallel corpus using topicmodels for word sense disambiguation.Liling Tan.
2013.
Gachalign: Gale-church sentence-level alignments with variable parameters [soft-ware].
Retrieved from https://db.tt/LLrul4zP andhttps://code.google.com/p/gachalign/.Antonio Toral.
2013.
Hybrid selection of languagemodel training data using linguistic information andperplexity.
ACL 2013, page 8.Olga Vechtomova.
2005.
The role of multi-word unitsin interactive information retrieval.
In ECIR, pages403?420.Sriram Venkatapathy and Aravind K Joshi.
2006.
Us-ing information about multi-word expressions forthe word-alignment task.
In Proceedings of theWorkshop on Multiword Expressions: Identifyingand Exploiting Underlying Properties, pages 20?27.Association for Computational Linguistics.206
