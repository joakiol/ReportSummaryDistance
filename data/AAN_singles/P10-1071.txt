Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 688?697,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsModels of Metaphor in NLPEkaterina ShutovaComputer LaboratoryUniversity of Cambridge15 JJ Thomson AvenueCambridge CB3 0FD, UKEkaterina.Shutova@cl.cam.ac.ukAbstractAutomatic processing of metaphor canbe clearly divided into two subtasks:metaphor recognition (distinguishing be-tween literal and metaphorical language ina text) and metaphor interpretation (iden-tifying the intended literal meaning of ametaphorical expression).
Both of themhave been repeatedly addressed in NLP.This paper is the first comprehensive andsystematic review of the existing compu-tational models of metaphor, the issues ofmetaphor annotation in corpora and theavailable resources.1 IntroductionOur production and comprehension of languageis a multi-layered computational process.
Hu-mans carry out high-level semantic tasks effort-lessly by subconsciously employing a vast inven-tory of complex linguistic devices, while simulta-neously integrating their background knowledge,to reason about reality.
An ideal model of lan-guage understanding would also be capable of per-forming such high-level semantic tasks.However, a great deal of NLP research to datefocuses on processing lower-level linguistic infor-mation, such as e.g.
part-of-speech tagging, dis-covering syntactic structure of a sentence (pars-ing), coreference resolution, named entity recog-nition and many others.
Another cohort of re-searchers set the goal of improving application-based statistical inference (e.g.
for recognizingtextual entailment or automatic summarization).In contrast, there have been fewer attempts tobring the state-of-the-art NLP technologies to-gether to model the way humans use language toframe high-level reasoning processes, such as forexample, creative thought.The majority of computational approaches tofigurative language still exploit the ideas articu-lated three decades ago (Wilks, 1978; Lakoff andJohnson, 1980; Fass, 1991) and often rely on task-specific hand-coded knowledge.
However, recentwork on lexical semantics and lexical acquisitiontechniques opens many new avenues for creationof fully automated models for recognition and in-terpretation of figurative language.
In this pa-per I will focus on the phenomenon of metaphorand describe the most prominent computationalapproaches to metaphor, as well the issues of re-source creation and metaphor annotation.Metaphors arise when one concept is viewedin terms of the properties of the other.
In otherwords it is based on similarity between the con-cepts.
Similarity is a kind of association implyingthe presence of characteristics in common.
Hereare some examples of metaphor.
(1) Hillary brushed aside the accusations.
(2) How can I kill a process?
(Martin, 1988)(3) I invested myself fully in this relationship.
(4) And then my heart with pleasure fills,And dances with the daffodils.1In metaphorical expressions seemingly unrelatedfeatures of one concept are associated with an-other concept.
In the example (2) the computa-tional process is viewed as something alive and,therefore, its forced termination is associated withthe act of killing.Metaphorical expressions represent a great vari-ety, ranging from conventional metaphors, whichwe reproduce and comprehend every day, e.g.those in (2) and (3), to poetic and largely novelones, such as (4).
The use of metaphor is ubiq-uitous in natural language text and it is a seri-ous bottleneck in automatic text understanding.1?I wandered lonely as a cloud?, William Wordsworth,1804.688In order to estimate the frequency of the phe-nomenon, Shutova (2010) conducted a corpusstudy on a subset of the British National Corpus(BNC) (Burnard, 2007) representing various gen-res.
They manually annotated metaphorical ex-pressions in this data and found that 241 out of761 sentences contained a metaphor.
Due to sucha high frequency of their use, a system capable ofrecognizing and interpreting metaphorical expres-sions in unrestricted text would become an invalu-able component of any semantics-oriented NLPapplication.Automatic processing of metaphor can beclearly divided into two subtasks: metaphorrecognition (distinguishing between literal andmetaphorical language in text) and metaphor in-terpretation (identifying the intended literal mean-ing of a metaphorical expression).
Both of themhave been repeatedly addressed in NLP.2 Theoretical BackgroundFour different views on metaphor have beenbroadly discussed in linguistics and philosophy:the comparison view (Gentner, 1983), the inter-action view (Black, 1962), (Hesse, 1966), the se-lectional restrictions violation view (Wilks, 1975;Wilks, 1978) and the conceptual metaphor view(Lakoff and Johnson, 1980)2.
All of these ap-proaches share the idea of an interconceptual map-ping that underlies the production of metaphoricalexpressions.
In other words, metaphor always in-volves two concepts or conceptual domains: thetarget (also called topic or tenor in the linguisticsliterature) and the source (or vehicle).
Considerthe examples in (5) and (6).
(5) He shot down all of my arguments.
(Lakoffand Johnson, 1980)(6) He attacked every weak point in my argu-ment.
(Lakoff and Johnson, 1980)According to Lakoff and Johnson (1980), amapping of a concept of argument to that of waris employed here.
The argument, which is the tar-get concept, is viewed in terms of a battle (or awar), the source concept.
The existence of sucha link allows us to talk about arguments using thewar terminology, thus giving rise to a number ofmetaphors.2A detailed overview and criticism of these four views canbe found in (Tourangeau and Sternberg, 1982).However, Lakoff and Johnson do not discusshow metaphors can be recognized in the linguis-tic data, which is the primary task in the auto-matic processing of metaphor.
Although humansare highly capable of producing and comprehend-ing metaphorical expressions, the task of distin-guishing between literal and non-literal meaningsand, therefore, identifying metaphor in text ap-pears to be challenging.
This is due to the vari-ation in its use and external form, as well as anot clear-cut semantic distinction.
Gibbs (1984)suggests that literal and figurative meanings aresituated at the ends of a single continuum, alongwhich metaphoricity and idiomaticity are spread.This makes demarcation of metaphorical and lit-eral language fuzzy.So far, the most influential account of metaphorrecognition is that of Wilks (1978).
According toWilks, metaphors represent a violation of selec-tional restrictions in a given context.
Selectionalrestrictions are the semantic constraints that a verbplaces onto its arguments.
Consider the followingexample.
(7) My car drinks gasoline.
(Wilks, 1978)The verb drink normally takes an animate subjectand a liquid object.
Therefore, drink taking a caras a subject is an anomaly, which may in turn in-dicate the metaphorical use of drink.3 Automatic Metaphor RecognitionOne of the first attempts to identify and inter-pret metaphorical expressions in text automati-cally is the approach of Fass (1991).
It originatesin the work of Wilks (1978) and utilizes hand-coded knowledge.
Fass (1991) developed a systemcalled met*, capable of discriminating betweenliteralness, metonymy, metaphor and anomaly.It does this in three stages.
First, literalnessis distinguished from non-literalness using selec-tional preference violation as an indicator.
In thecase that non-literalness is detected, the respectivephrase is tested for being a metonymic relation us-ing hand-coded patterns (such as CONTAINER-for-CONTENT).
If the system fails to recognizemetonymy, it proceeds to search the knowledgebase for a relevant analogy in order to discriminatemetaphorical relations from anomalous ones.
E.g.,the sentence in (7) would be represented in thisframework as (car,drink,gasoline), which does notsatisfy the preference (animal,drink,liquid), as car689is not a hyponym of animal.
met* then searches itsknowledge base for a triple containing a hypernymof both the actual argument and the desired argu-ment and finds (thing,use,energy source), whichrepresents the metaphorical interpretation.However, Fass himself indicated a problem withthe selectional preference violation approach ap-plied to metaphor recognition.
The approach de-tects any kind of non-literalness or anomaly inlanguage (metaphors, metonymies and others),and not only metaphors, i.e., it overgenerates.The methods met* uses to differentiate betweenthose are mainly based on hand-coded knowledge,which implies a number of limitations.Another problem with this approach arises fromthe high conventionality of metaphor in language.This means that some metaphorical senses arevery common.
As a result the system would ex-tract selectional preference distributions skewedtowards such conventional metaphorical senses ofthe verb or one of its arguments.
Therefore, al-though some expressions may be fully metaphor-ical in nature, no selectional preference violationcan be detected in their use.
Another counterar-gument is bound to the fact that interpretation isalways context dependent, e.g.
the phrase all menare animals can be used metaphorically, however,without any violation of selectional restrictions.Goatly (1997) addresses the phenomenon ofmetaphor by identifying a set of linguistic cuesindicating it.
He gives examples of lexical pat-terns indicating the presence of a metaphorical ex-pression, such as metaphorically speaking, utterly,completely, so to speak and, surprisingly, liter-ally.
Such cues would probably not be enough formetaphor extraction on their own, but could con-tribute to a more complex system.The work of Peters and Peters (2000) concen-trates on detecting figurative language in lexicalresources.
They mine WordNet (Fellbaum, 1998)for the examples of systematic polysemy, whichallows to capture metonymic and metaphorical re-lations.
The authors search for nodes that are rel-atively high up in the WordNet hierarchy and thatshare a set of common word forms among their de-scendants.
Peters and Peters found that such nodesoften happen to be in metonymic (e.g.
publica-tion ?
publisher) or metaphorical (e.g.
supportingstructure ?
theory) relation.The CorMet system discussed in (Mason, 2004)is the first attempt to discover source-target do-main mappings automatically.
This is done by?finding systematic variations in domain-specificselectional preferences, which are inferred fromlarge, dynamically mined Internet corpora?.
Forexample, Mason collects texts from the LAB do-main and the FINANCE domain, in both of whichpour would be a characteristic verb.
In the LABdomain pour has a strong selectional preferencefor objects of type liquid, whereas in the FI-NANCE domain it selects for money.
From thisMason?s system infers the domain mapping FI-NANCE ?
LAB and the concept mapping money?
liquid.
He compares the output of his systemagainst the Master Metaphor List (Lakoff et al,1991) containing hand-crafted metaphorical map-pings between concepts.
Mason reports an accu-racy of 77%, although it should be noted that asany evaluation that is done by hand it contains anelement of subjectivity.Birke and Sarkar (2006) present a sentence clus-tering approach for non-literal language recog-nition implemented in the TroFi system (TropeFinder).
This idea originates from a similarity-based word sense disambiguation method devel-oped by Karov and Edelman (1998).
The methodemploys a set of seed sentences, where the sensesare annotated; computes similarity between thesentence containing the word to be disambiguatedand all of the seed sentences and selects the sensecorresponding to the annotation in the most simi-lar seed sentences.
Birke and Sarkar (2006) adaptthis algorithm to perform a two-way classification:literal vs. non-literal, and they do not clearly de-fine the kinds of tropes they aim to discover.
Theyattain a performance of 53.8% in terms of f-score.The method of Gedigan et al (2006) discrimi-nates between literal and metaphorical use.
Theytrained a maximum entropy classifier for this pur-pose.
They obtained their data by extracting thelexical items whose frames are related to MO-TION and CURE from FrameNet (Fillmore etal., 2003).
Then they searched the PropBankWall Street Journal corpus (Kingsbury and Palmer,2002) for sentences containing such lexical itemsand annotated them with respect to metaphoric-ity.
They used PropBank annotation (argumentsand their semantic types) as features to train theclassifier and report an accuracy of 95.12%.
Thisresult is, however, only a little higher than the per-formance of the naive baseline assigning major-ity class to all instances (92.90%).
These numbers690can be explained by the fact that 92.00% of theverbs of MOTION and CURE in the Wall StreetJournal corpus are used metaphorically, thus mak-ing the dataset unbalanced with respect to the tar-get categories and the task notably easier.Both Birke and Sarkar (2006) and Gedigan etal.
(2006) focus only on metaphors expressed bya verb.
As opposed to that the approach of Kr-ishnakumaran and Zhu (2007) deals with verbs,nouns and adjectives as parts of speech.
Theyuse hyponymy relation in WordNet and word bi-gram counts to predict metaphors at a sentencelevel.
Given an IS-A metaphor (e.g.
The worldis a stage3) they verify if the two nouns involvedare in hyponymy relation in WordNet, and ifthey are not then this sentence is tagged as con-taining a metaphor.
Along with this they con-sider expressions containing a verb or an adjec-tive used metaphorically (e.g.
He planted goodideas in their minds or He has a fertile imagi-nation).
Hereby they calculate bigram probabil-ities of verb-noun and adjective-noun pairs (in-cluding the hyponyms/hypernyms of the noun inquestion).
If the combination is not observed inthe data with sufficient frequency, the system tagsthe sentence containing it as metaphorical.
Thisidea is a modification of the selectional prefer-ence view of Wilks.
However, by using bigramcounts over verb-noun pairs Krishnakumaran andZhu (2007) loose a great deal of information com-pared to a system extracting verb-object relationsfrom parsed text.
The authors evaluated their sys-tem on a set of example sentences compiled fromthe Master Metaphor List (Lakoff et al, 1991),whereby highly conventionalized metaphors (theycall them dead metaphors) are taken to be negativeexamples.
Thus they do not deal with literal exam-ples as such: essentially, the distinction they aremaking is between the senses included in Word-Net, even if they are conventional metaphors, andthose not included in WordNet.4 Automatic Metaphor InterpretationAlmost simultaneously with the work of Fass(1991), Martin (1990) presents a Metaphor In-terpretation, Denotation and Acquisition System(MIDAS).
In this work Martin captures hierarchi-cal organisation of conventional metaphors.
Theidea behind this is that the more specific conven-tional metaphors descend from the general ones.3William ShakespeareGiven an example of a metaphorical expression,MIDAS searches its database for a correspondingmetaphor that would explain the anomaly.
If itdoes not find any, it abstracts from the example tomore general concepts and repeats the search.
If itfinds a suitable general metaphor, it creates a map-ping for its descendant, a more specific metaphor,based on this example.
This is also how novelmetaphors are acquired.
MIDAS has been inte-grated with the Unix Consultant (UC), the sys-tem that answers users questions about Unix.
TheUC first tries to find a literal answer to the ques-tion.
If it is not able to, it calls MIDAS whichdetects metaphorical expressions via selectionalpreference violation and searches its database for ametaphor explaining the anomaly in the question.Another cohort of approaches relies on per-forming inferences about entities and events inthe source and target domains for metaphor in-terpretation.
These include the KARMA sys-tem (Narayanan, 1997; Narayanan, 1999; Feld-man and Narayanan, 2004) and the ATT-Metaproject (Barnden and Lee, 2002; Agerri et al,2007).
Within both systems the authors developeda metaphor-based reasoning framework in accor-dance with the theory of conceptual metaphor.The reasoning process relies on manually codedknowledge about the world and operates mainly inthe source domain.
The results are then projectedonto the target domain using the conceptual map-ping representation.
The ATT-Meta project con-cerns metaphorical and metonymic description ofmental states and reasoning about mental statesusing first order logic.
Their system, however,does not take natural language sentences as input,but logical expressions that are representations ofsmall discourse fragments.
KARMA in turn dealswith a broad range of abstract actions and eventsand takes parsed text as input.Veale and Hao (2008) derive a ?fluid knowl-edge representation for metaphor interpretationand generation?, called Talking Points.
Talk-ing Points are a set of characteristics of conceptsbelonging to source and target domains and re-lated facts about the world which the authors ac-quire automatically from WordNet and from theweb.
Talking Points are then organized in Slip-net, a framework that allows for a number ofinsertions, deletions and substitutions in defini-tions of such characteristics in order to establisha connection between the target and the source691concepts.
This work builds on the idea of slip-page in knowledge representation for understand-ing analogies in abstract domains (Hofstadter andMitchell, 1994; Hofstadter, 1995).
Below is anexample demonstrating how slippage operates toexplain the metaphor Make-up is a Western burqa.Make-up =>?
typically worn by women?
expected to be worn by women?
must be worn by women?
must be worn by Muslim womenBurqa <=By doing insertions and substitutions the sys-tem arrives from the definition typically worn bywomen to that of must be worn by Muslim women,and thus establishes a link between the conceptsof make-up and burqa.
Veale and Hao (2008),however, did not evaluate to which extent theirknowledge base of Talking Points and the asso-ciated reasoning framework are useful to interpretmetaphorical expressions occurring in text.Shutova (2010) defines metaphor interpretationas a paraphrasing task and presents a method forderiving literal paraphrases for metaphorical ex-pressions from the BNC.
For example, for themetaphors in ?All of this stirred an unfathomableexcitement in her?
or ?a carelessly leaked report?their system produces interpretations ?All of thisprovoked an unfathomable excitement in her?
and?a carelessly disclosed report?
respectively.
Theyfirst apply a probabilistic model to rank all pos-sible paraphrases for the metaphorical expressiongiven the context; and then use automatically in-duced selectional preferences to discriminate be-tween figurative and literal paraphrases.
The se-lectional preference distribution is defined in termsof selectional association measure introduced byResnik (1993) over the noun classes automaticallyproduced by Sun and Korhonen (2009).
Shutova(2010) tested their system only on metaphors ex-pressed by a verb and report a paraphrasing accu-racy of 0.81.5 Metaphor ResourcesMetaphor is a knowledge-hungry phenomenon.Hence there is a need for either an exten-sive manually-created knowledge-base or a robustknowledge acquisition system for interpretation ofmetaphorical expressions.
The latter being a hardtask, a great deal of metaphor research resorted tothe first option.
Although hand-coded knowledgeproved useful for metaphor interpretation (Fass,1991; Martin, 1990), it should be noted that thesystems utilizing it have a very limited coverage.One of the first attempts to create a multi-purpose knowledge base of source?target domainmappings is the Master Metaphor List (Lakoff etal., 1991).
It includes a classification of metaphor-ical mappings (mainly those related to mind, feel-ings and emotions) with the corresponding exam-ples of language use.
This resource has been criti-cized for the lack of clear structuring principles ofthe mapping ontology (Lo?nneker-Rodman, 2008).The taxonomical levels are often confused, and thesame classes are referred to by different class la-bels.
This fact and the chosen data representationin the Master Metaphor List make it not suitablefor computational use.
However, both the idea ofthe list and its actual mappings ontology inspiredthe creation of other metaphor resources.The most prominent of them are MetaBank(Martin, 1994) and the Mental Metaphor Data-bank4 created in the framework of the ATT-metaproject (Barnden and Lee, 2002; Agerri et al,2007).
The MetaBank is a knowledge-base of En-glish metaphorical conventions, represented in theform of metaphor maps (Martin, 1988) contain-ing detailed information about source-target con-cept mappings backed by empirical evidence.
TheATT-meta project databank contains a large num-ber of examples of metaphors of mind classifiedby source?target domain mappings taken from theMaster Metaphor List.Along with this it is worth mentioning metaphorresources in languages other than English.
Therehas been a wealth of research on metaphorin Spanish, Chinese, Russian, German, Frenchand Italian.
The Hamburg Metaphor Database(Lo?nneker, 2004; Reining and Lo?nneker-Rodman,2007) contains examples of metaphorical expres-sions in German and French, which are mappedto senses from EuroWordNet5 and annotated withsource?target domain mappings taken from theMaster Metaphor List.Alonge and Castelli (2003) discuss howmetaphors can be represented in ItalWordNet for4http://www.cs.bham.ac.uk/?jab/ATT-Meta/Databank/5EuroWordNet is a multilingual database with wordnetsfor several European languages (Dutch, Italian, Spanish, Ger-man, French, Czech and Estonian).
The wordnets are struc-tured in the same way as the Princeton WordNet for English.URL: http://www.illc.uva.nl/EuroWordNet/692Italian and motivate this by linguistic evidence.Encoding metaphorical information in general-domain lexical resources for English, e.g.
Word-Net (Lo?nneker and Eilts, 2004), would undoubt-edly provide a new platform for experiments andenable researchers to directly compare their re-sults.6 Metaphor Annotation in CorporaTo reflect two distinct aspects of the phenomenon,metaphor annotation can be split into two stages:identifying metaphorical senses in text (akin wordsense disambiguation) and annotating source ?
tar-get domain mappings underlying the production ofmetaphorical expressions.
Traditional approachesto metaphor annotation include manual searchfor lexical items used metaphorically (PragglejazGroup, 2007), for source and target domain vocab-ulary (Deignan, 2006; Koivisto-Alanko and Tis-sari, 2006; Martin, 2006) or for linguistic mark-ers of metaphor (Goatly, 1997).
Although thereis a consensus in the research community thatthe phenomenon of metaphor is not restricted tosimilarity-based extensions of meanings of iso-lated words, but rather involves reconceptualiza-tion of a whole area of experience in terms of an-other, there still has been surprisingly little inter-est in annotation of cross-domain mappings.
How-ever, a corpus annotated for conceptual mappingscould provide a new starting point for both linguis-tic and cognitive experiments.6.1 Metaphor and PolysemyThe theorists of metaphor distinguish between twokinds of metaphorical language: novel (or poetic)metaphors, that surprise our imagination, and con-ventionalized metaphors, that become a part of anordinary discourse.
?Metaphors begin their livesas novel poetic creations with marked rhetoricaleffects, whose comprehension requires a specialimaginative leap.
As time goes by, they becomea part of general usage, their comprehension be-comes more automatic, and their rhetorical effectis dulled?
(Nunberg, 1987).
Following Orwell(1946) Nunberg calls such metaphors ?dead?
andclaims that they are not psychologically distinctfrom literally-used terms.This scheme demonstrates how metaphoricalassociations capture some generalisations govern-ing polysemy: over time some of the aspects ofthe target domain are added to the meaning of aterm in a source domain, resulting in a (metaphor-ical) sense extension of this term.
Copestakeand Briscoe (1995) discuss sense extension mainlybased on metonymic examples and model the phe-nomenon using lexical rules encoding metonymicpatterns.
Along with this they suggest that similarmechanisms can be used to account for metaphoricprocesses, and the conceptual mappings encodedin the sense extension rules would define the lim-its to the possible shifts in meaning.However, it is often unclear if a metaphoricalinstance is a case of broadening of the sense incontext due to general vagueness in language, or itmanifests a formation of a new distinct metaphor-ical sense.
Consider the following examples.
(8) a.
As soon as I entered the room I noticedthe difference.b.
How can I enter Emacs?
(9) a.
My tea is cold.b.
He is such a cold person.Enter in (8a) is defined as ?to go or come intoa place, building, room, etc.
; to pass within theboundaries of a country, region, portion of space,medium, etc.
?6 In (8b) this sense stretches todescribe dealing with software, whereby COM-PUTER PROGRAMS are viewed as PHYSICALSPACES.
However, this extended sense of enterdoes not appear to be sufficiently distinct or con-ventional to be included into the dictionary, al-though this could happen over time.The sentence (9a) exemplifies the basic senseof cold ?
?of a temperature sensibly lower thanthat of the living human body?, whereas cold in(9b) should be interpreted metaphorically as ?voidof ardour, warmth, or intensity of feeling; lackingenthusiasm, heartiness, or zeal; indifferent, apa-thetic?.
These two senses are clearly linked viathe metaphoric mapping between EMOTIONALSTATES and TEMPERATURES.A number of metaphorical senses are includedin WordNet, however without any accompanyingsemantic annotation.6.2 Metaphor Identification6.2.1 Pragglejaz ProcedurePragglejaz Group (2007) proposes a metaphoridentification procedure (MIP) within the frame-6Sense definitions are taken from the Oxford English Dic-tionary.693work of the Metaphor in Discourse project (Steen,2007).
The procedure involves metaphor annota-tion at the word level as opposed to identifyingmetaphorical relations (between words) or source?target domain mappings (between concepts or do-mains).
In order to discriminate between the verbsused metaphorically and literally the annotatorsare asked to follow the guidelines:1.
For each verb establish its meaning in contextand try to imagine a more basic meaning ofthis verb on other contexts.
Basic meaningsnormally are: (1) more concrete; (2) relatedto bodily action; (3) more precise (as opposedto vague); (4) historically older.2.
If you can establish the basic meaning thatis distinct from the meaning of the verb inthis context, the verb is likely to be usedmetaphorically.Such annotation can be viewed as a form ofword sense disambiguation with an emphasis onmetaphoricity.6.2.2 Source ?
Target Domain VocabularyAnother popular method that has been used to ex-tract metaphors is searching for sentences contain-ing lexical items from the source domain, the tar-get domain, or both (Stefanowitsch, 2006).
Thismethod requires exhaustive lists of source and tar-get domain vocabulary.Martin (2006) conducted a corpus study inorder to confirm that metaphorical expressionsoccur in text in contexts containing such lex-ical items.
He performed his analysis on thedata from the Wall Street Journal (WSJ) cor-pus and focused on four conceptual metaphorsthat occur with considerable regularity in thecorpus.
These include NUMERICAL VALUEAS LOCATION, COMMERCIAL ACTIVITYAS CONTAINER, COMMERCIAL ACTIVITYAS PATH FOLLOWING and COMMERCIALACTIVITY AS WAR.
Martin manually compiledthe lists of terms characteristic for each domainby examining sampled metaphors of these typesand then augmented them through the use ofthesaurus.
He then searched the WSJ for sen-tences containing vocabulary from these listsand checked whether they contain metaphors ofthe above types.
The goal of this study was toevaluate predictive ability of contexts containingvocabulary from (1) source domain and (2) targetdomain, as well as (3) estimating the likelihoodof a metaphorical expression following anothermetaphorical expression described by the samemapping.
He obtained the most positive results formetaphors of the type NUMERICAL-VALUE-AS-LOCATION (P (Metaphor|Source) =0.069, P (Metaphor|Target) = 0.677,P (Metaphor|Metaphor) = 0.703).6.3 Annotating Source and Target DomainsWallington et al (2003) carried out a metaphor an-notation experiment in the framework of the ATT-Meta project.
They employed two teams of an-notators.
Team A was asked to annotate ?inter-esting stretches?, whereby a phrase was consid-ered interesting if (1) its significance in the doc-ument was non-physical, (2) it could have a phys-ical significance in another context with a similarsyntactic frame, (3) this physical significance wasrelated to the abstract one.
Team B had to anno-tate phrases according to their own intuitive defi-nition of metaphor.
Besides metaphorical expres-sions Wallington et al (2003) attempted to anno-tate the involved source ?
target domain mappings.The annotators were given a set of mappings fromthe Master Metaphor List and were asked to assignthe most suitable ones to the examples.
However,the authors do not report the level of interannota-tor agreement nor the coverage of the mappings inthe Master Metaphor List on their data.Shutova and Teufel (2010) adopt a different ap-proach to the annotation of source ?
target do-main mappings.
They do not rely on prede-fined mappings, but instead derive independentsets of most common source and target categories.They propose a two stage procedure, whereby themetaphorical expressions are first identified usingMIP, and then the source domain (where the ba-sic sense comes from) and the target domain (thegiven context) are selected from the lists of cate-gories.
Shutova and Teufel (2010) report interan-notator agreement of 0.61 (?
).7 Conclusion and Future DirectionsThe eighties and nineties provided us with awealth of ideas on the structure and mechanismsof the phenomenon of metaphor.
The approachesformulated back then are still highly influential,although their use of hand-coded knowledge isbecoming increasingly less convincing.
The lastdecade witnessed a high technological leap in694natural language computation, whereby manuallycrafted rules gradually give way to more robustcorpus-based statistical methods.
This is also thecase for metaphor research.
The latest develop-ments in the lexical acquisition technology willin the near future enable fully automated corpus-based processing of metaphor.However, there is still a clear need in a uni-fied metaphor annotation procedure and creationof a large publicly available metaphor corpus.Given such a resource the computational work onmetaphor is likely to proceed along the followinglines: (1) automatic acquisition of an extensive setof valid metaphorical associations from linguis-tic data via statistical pattern matching; (2) usingthe knowledge of these associations for metaphorrecognition in the unseen unrestricted text and, fi-nally, (3) interpretation of the identified metaphor-ical expressions by deriving the closest literalparaphrase (a representation that can be directlyembedded in other NLP applications to enhancetheir performance).Besides making our thoughts more vivid andfilling our communication with richer imagery,metaphors also play an important structural rolein our cognition.
Thus, one of the long term goalsof metaphor research in NLP and AI would be tobuild a computational intelligence model account-ing for the way metaphors organize our conceptualsystem, in terms of which we think and act.AcknowledgmentsI would like to thank Anna Korhonen and my re-viewers for their most helpful feedback on this pa-per.
The support of Cambridge Overseas Trust,who fully funds my studies, is gratefully acknowl-edged.ReferencesR.
Agerri, J.A.
Barnden, M.G.
Lee, and A.M. Walling-ton.
2007.
Metaphor, inference and domain-independent mappings.
In Proceedings of RANLP-2007, pages 17?23, Borovets, Bulgaria.A.
Alonge and M. Castelli.
2003.
Encoding informa-tion on metaphoric expressions in WordNet-like re-sources.
In Proceedings of the ACL 2003 Workshopon Lexicon and Figurative Language, pages 10?17.J.A.
Barnden and M.G.
Lee.
2002.
An artificial intelli-gence approach to metaphor understanding.
Theoriaet Historia Scientiarum, 6(1):399?412.J.
Birke and A. Sarkar.
2006.
A clustering approachfor the nearly unsupervised recognition of nonlit-eral language.
In In Proceedings of EACL-06, pages329?336.M.
Black.
1962.
Models and Metaphors.
Cornell Uni-versity Press.L.
Burnard.
2007.
Reference Guide for the British Na-tional Corpus (XML Edition).A.
Copestake and T. Briscoe.
1995.
Semi-productivepolysemy and sense extension.
Journal of Seman-tics, 12:15?67.A.
Deignan.
2006.
The grammar of linguisticmetaphors.
In A. Stefanowitsch and S. T. Gries,editors, Corpus-Based Approaches to Metaphor andMetonymy, Berlin.
Mouton de Gruyter.D.
Fass.
1991. met*: A method for discriminatingmetonymy and metaphor by computer.
Computa-tional Linguistics, 17(1):49?90.J.
Feldman and S. Narayanan.
2004.
Embodied mean-ing in a neural theory of language.
Brain and Lan-guage, 89(2):385?392.C.
Fellbaum, editor.
1998.
WordNet: An ElectronicLexical Database (ISBN: 0-262-06197-X).
MITPress, first edition.C.
J. Fillmore, C. R. Johnson, and M. R. L. Petruck.2003.
Background to FrameNet.
InternationalJournal of Lexicography, 16(3):235?250.M.
Gedigan, J. Bryant, S. Narayanan, and B. Ciric.2006.
Catching metaphors.
In In Proceedings of the3rd Workshop on Scalable Natural Language Un-derstanding, pages 41?48, New York.D.
Gentner.
1983.
Structure mapping: A theoreticalframework for analogy.
Cognitive Science, 7:155?170.R.
Gibbs.
1984.
Literal meaning and psychologicaltheory.
Cognitive Science, 8:275?304.A.
Goatly.
1997.
The Language of Metaphors.
Rout-ledge, London.M.
Hesse.
1966.
Models and Analogies in Science.Notre Dame University Press.D.
Hofstadter and M. Mitchell.
1994.
The CopycatProject: A model of mental fluidity and analogy-making.
In K.J.
Holyoak and J.
A. Barnden, editors,Advances in Connectionist and Neural ComputationTheory, Ablex, New Jersey.D.
Hofstadter.
1995.
Fluid Concepts and CreativeAnalogies: Computer Models of the FundamentalMechanisms of Thought.
HarperCollins Publishers.Y.
Karov and S. Edelman.
1998.
Similarity-basedword sense disambiguation.
Computational Lin-guistics, 24(1):41?59.695P.
Kingsbury and M. Palmer.
2002.
From TreeBankto PropBank.
In Proceedings of LREC-2002, GranCanaria, Canary Islands, Spain.P.
Koivisto-Alanko and H. Tissari.
2006.
Senseand sensibility: Rational thought versus emotionin metaphorical language.
In A. Stefanowitschand S. T. Gries, editors, Corpus-Based Approachesto Metaphor and Metonymy, Berlin.
Mouton deGruyter.S.
Krishnakumaran and X. Zhu.
2007.
Hunting elusivemetaphors using lexical resources.
In Proceedingsof the Workshop on Computational Approaches toFigurative Language, pages 13?20, Rochester, NY.G.
Lakoff and M. Johnson.
1980.
Metaphors We LiveBy.
University of Chicago Press, Chicago.G.
Lakoff, J. Espenson, and A. Schwartz.
1991.
Themaster metaphor list.
Technical report, Universityof California at Berkeley.B.
Lo?nneker and C. Eilts.
2004.
A Current Re-source and Future Perspectives for Enriching Word-Nets with Metaphor Information.
In Proceedingsof the Second International WordNet Conference?GWC 2004, pages 157?162, Brno, Czech Republic.B.
Lo?nneker-Rodman.
2008.
The hamburg metaphordatabase project: issues in resource creation.
Lan-guage Resources and Evaluation, 42(3):293?318.B.
Lo?nneker.
2004.
Lexical databases as resourcesfor linguistic creativity: Focus on metaphor.
In Pro-ceedings of the LREC 2004 Workshop on LanguageResources for Linguistic Creativity, pages 9?16, Lis-bon, Portugal.J.
H. Martin.
1988.
Representing regularities in themetaphoric lexicon.
In Proceedings of the 12th con-ference on Computational linguistics, pages 396?401.J.
H. Martin.
1990.
A Computational Model ofMetaphor Interpretation.
Academic Press Profes-sional, Inc., San Diego, CA, USA.J.
H. Martin.
1994.
Metabank: A knowledge-base ofmetaphoric language conventions.
ComputationalIntelligence, 10:134?149.J.
H. Martin.
2006.
A corpus-based analysis of con-text effects on metaphor comprehension.
In A. Ste-fanowitsch and S. T. Gries, editors, Corpus-BasedApproaches to Metaphor and Metonymy, Berlin.Mouton de Gruyter.Z.
J. Mason.
2004.
Cormet: a computational,corpus-based conventional metaphor extraction sys-tem.
Computational Linguistics, 30(1):23?44.S.
Narayanan.
1997.
Knowledge-based action repre-sentations for metaphor and aspect (karma.
Tech-nical report, PhD thesis, University of California atBerkeley.S.
Narayanan.
1999.
Moving right along: A computa-tional model of metaphoric reasoning about events.In Proceedings of AAAI 99), pages 121?128, Or-lando, Florida.G.
Nunberg.
1987.
Poetic and prosaic metaphors.
InProceedings of the 1987 workshop on Theoreticalissues in natural language processing, pages 198?201.G.
Orwell.
1946.
Politics and the english language.Horizon.W.
Peters and I. Peters.
2000.
Lexicalised system-atic polysemy in wordnet.
In Proceedings of LREC2000, Athens.Pragglejaz Group.
2007.
MIP: A method for iden-tifying metaphorically used words in discourse.Metaphor and Symbol, 22:1?39.A.
Reining and B.
Lo?nneker-Rodman.
2007.
Corpus-driven metaphor harvesting.
In Proceedings ofthe HLT/NAACL-07 Workshop on ComputationalApproaches to Figurative Language, pages 5?12,Rochester, New York.P.
Resnik.
1993.
Selection and Information: A Class-based Approach to Lexical Relationships.
Ph.D. the-sis, Philadelphia, PA, USA.E.
Shutova and S. Teufel.
2010.
Metaphor corpus an-notated for source - target domain mappings.
In Pro-ceedings of LREC 2010, Malta.E.
Shutova.
2010.
Automatic metaphor interpretationas a paraphrasing task.
In Proceedings of NAACL2010, Los Angeles, USA.G.
J. Steen.
2007.
Finding metaphor in discourse:Pragglejaz and beyond.
Cultura, Lenguaje y Rep-resentacion / Culture, Language and Representation(CLR), Revista de Estudios Culturales de la Univer-sitat Jaume I, 5:9?26.A.
Stefanowitsch.
2006.
Corpus-based approachesto metaphor and metonymy.
In A. Stefanowitschand S. T. Gries, editors, Corpus-Based Approachesto Metaphor and Metonymy, Berlin.
Mouton deGruyter.L.
Sun and A. Korhonen.
2009.
Improving verb clus-tering with automatically acquired selectional pref-erences.
In Proceedings of EMNLP 2009, pages638?647, Singapore, August.R.
Tourangeau and R. Sternberg.
1982.
Understand-ing and appreciating metaphors.
Cognition, 11:203?244.T.
Veale and Y. Hao.
2008.
A fluid knowledge repre-sentation for understanding and generating creativemetaphors.
In Proceedings of COLING 2008, pages945?952, Manchester, UK.696A.M.Wallington, J.
A. Barnden, P. Buchlovsky, L. Fel-lows, and S. R. Glasbey.
2003.
Metaphor annota-tion: A systematic study.
Technical report, Schoolof Computer Science, The University of Birming-ham.Y.
Wilks.
1975.
A preferential pattern-seeking seman-tics for natural language inference.
Artificial Intelli-gence, 6:53?74.Y.
Wilks.
1978.
Making preferences more active.
Ar-tificial Intelligence, 11(3):197?223.697
