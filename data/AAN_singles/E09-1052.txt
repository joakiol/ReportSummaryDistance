Proceedings of the 12th Conference of the European Chapter of the ACL, pages 451?459,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsA Logic of Semantic Representations for Shallow ParsingAlexander KollerSaarland UniversitySaarbru?cken, Germanykoller@mmci.uni-saarland.deAlex LascaridesUniversity of EdinburghEdinburgh, UKalex@inf.ed.ac.ukAbstractOne way to construct semantic represen-tations in a robust manner is to enhanceshallow language processors with seman-tic components.
Here, we provide a modeltheory for a semantic formalism that is de-signed for this, namely Robust MinimalRecursion Semantics (RMRS).
We showthat RMRS supports a notion of entailmentthat allows it to form the basis for compar-ing the semantic output of different parsesof varying depth.1 IntroductionRepresenting semantics as a logical form that sup-ports automated inference and model construc-tion is vital for deeper language engineering tasks,such as dialogue systems.
Logical forms can beobtained from hand-crafted deep grammars (Buttet al, 1999; Copestake and Flickinger, 2000) butthis lacks robustness: not all words and con-structions are covered and by design ill-formedphrases fail to parse.
There has thus been a trendrecently towards robust wide-coverage semanticconstruction (e.g., (Bos et al, 2004; Zettlemoyerand Collins, 2007)).
But there are certain seman-tic phenomena that these robust approaches don?tcapture reliably, including quantifier scope, op-tional arguments, and long-distance dependencies(for instance, Clark et al (2004) report that theparser used by Bos et al (2004) yields 63% ac-curacy on object extraction; e.g., the man that Imet.
.
.
).
Forcing a robust parser to make a de-cision about these phenomena can therefore beerror-prone.
Depending on the application, it maybe preferable to give the parser the option to leavea semantic decision open when it?s not sufficientlyinformed?i.e., to compute a partial semantic rep-resentation and to complete it later, using informa-tion extraneous to the parser.In this paper, we focus on an approach to se-mantic representation that supports this strategy:Robust Minimal Recursion Semantics (RMRS,Copestake (2007a)).
RMRS is designed to supportunderspecification of lexical information, scope,and predicate-argument structure.
It is an emerg-ing standard for representing partial semantics,and has been applied in several implemented sys-tems.
For instance, Copestake (2003) and Frank(2004) use it to specify semantic components toshallow parsers ranging in depth from POS tag-gers to chunk parsers and intermediate parserssuch as RASP (Briscoe et al, 2006).
MRS anal-yses (Copestake et al, 2005) derived from deepgrammars, such as the English Resource Grammar(ERG, (Copestake and Flickinger, 2000)) are spe-cial cases of RMRS.
But RMRS, unlike MRS and re-lated formalisms like dominance constraints (Egget al, 2001), is able to express semantic infor-mation in the absence of full predicate argumentstructure and lexical subcategorisation.The key contribution we make is to cast RMRS,for the first time, as a logic with a well-definedmodel theory.
Previously, no such model theoryexisted, and so RMRS had to be used in a some-what ad-hoc manner that left open exactly whatany given RMRS representation actually means.This has hindered practical progress, both in termsof understanding the relationship of RMRS to otherframeworks such as MRS and predicate logic andin terms of the development of efficient algo-rithms.
As one application of our formalisation,we use entailment to propose a novel way of char-acterising consistency of RMRS analyses acrossdifferent parsers.Section 2 introduces RMRS informally and illus-trates why it is necessary and useful for represent-ing semantic information across deep and shallowlanguage processors.
Section 3 defines the syntaxand model-theory of RMRS.
We finish in Section 4by pointing out some avenues for future research.4512 Deep and shallow semanticconstructionConsider the following (toy) sentence:(1) Every fat cat chased some dog.It exhibits several kinds of ambiguity, includ-ing a quantifier scope ambiguity and lexicalambiguities?e.g., the nouns ?cat?
and ?dog?
have8 and 7 WordNet senses respectively.
Simplifyingslightly by ignoring tense information, two of itsreadings are shown as logical forms below; thesecan be represented as trees as shown in Fig.
1.
(2) every q 1(x, fat j 1(e?, x) ?
cat n 1(x),some q 1(y, dog n 1(y),chase v 1(e, x, y)))(3) some q 1(y, dog n 2(y),every q 1(x, fat j 1(e?, x) ?
cat n 2(x),chase v 1(e, x, y)))Now imagine trying to extract semantic infor-mation from the output of a part-of-speech (POS)tagger by using the word lemmas as lexical pred-icate symbols.
Such a semantic representationis highly partial.
It will use predicate symbolssuch as cat n, which might resolve to the pred-icate symbols cat n 1 or cat n 2 in the com-plete semantic representation.
(Notice the dif-ferent fonts for the ambiguous and unambiguouspredicate symbols.)
But most underspecificationformalisms (e.g., MRS (Copestake et al, 2005) andCLLS (Egg et al, 2001)) are unable to represent se-mantic information that is as partial as what we getfrom a POS tagger because they cannot underspec-ify predicate-argument structure.
RMRS (Copes-take, 2007a) is designed to address this problem.In RMRS, the information we get from the POS tag-ger is as follows:(4) l1 : a1 : every q(x1),l41 : a41 : fat j(e?
),l42 : a42 : cat n(x3)l5 : a5 : chase v(e),l6 : a6 : some q(x6),l9 : a9 : dog n(x7)This RMRS expresses only that certain predica-tions are present in the semantic representation?it doesn?t say anything about semantic scope,about most arguments of the predicates (e.g.,chase v(e) doesn?t say who chases whom), orabout the coindexation of variables ( every q_every_q_1x?_fat_j_1e' x_cat_n_1x_some_q_1y _dog_n_1y_chase_v_1e x y_every_q_1x?_fat_j_1e' x_cat_n_2x_some_q_1y _dog_n_2y_chase_v_1e x yFigure 1: Semantic representations (2) and (3) astrees.binds the variable x1, whereas cat n speaks aboutx3), and it maintains the lexical ambiguities.
Tech-nically, it consists of six elementary predications(EPs), one for each word lemma in the sentence;each of them is prefixed by a label and an anchor,which are essentially variables that refer to nodesin the trees in Fig.
1.
We can say that the two treessatisfy this RMRS because it is possible to map thelabels and anchors in (4) into nodes in each treeand variable names like x1 and x3 into variablenames in the tree in such a way that the predica-tions of the nodes that labels and anchors denoteare consistent with those in the EPs of (4)?e.g., l1and a1 can map to the root of the first tree in Fig.
1,x1 to x, and the root label every q 1 is consistentwith the EP predicate every q.There are of course many other trees (and thus,fully specific semantic representations such as (2))that are described equally well by the RMRS (4);this is not surprising, given that the semantic out-put from the POS tagger is so incomplete.
If wehave information about subjects and objects froma chunk parser like Cass (Abney, 1996), we canrepresent it in a more detailed RMRS:(5) l1 : a1 : every q(x1),l41 : a41 : fat j(e?
),l42 : a42 : cat n(x3)l5 : a5 : chase v(e),ARG1(a5, x4),ARG2(a5, x5)l6 : a6 : some q(x6),l9 : a9 : dog n(x7)x3 = x4, x5 = x7This introduces two new types of atoms.
x3 =x4 means that x3 and x4 map to the same variablein any fully specific logical form; e.g., both to thevariable x in Fig.
1.
ARGi(a, z) (and ARGi(a, h))452express that the i-th child (counting from 0) of thenode to which the anchor a refers is the variablename that z denotes (or the node that the hole hdenotes).
So unlike earlier underspecification for-malisms, RMRS can specify the predicate of anatom separately from its arguments; this is nec-essary for supporting parsers where informationabout lexical subcategorisation is absent.
If wealso allow atoms of the form ARG{2,3}(a, x) to ex-press uncertainty as to whether x is the second orthird child of the anchor a, then RMRS can evenspecify the arguments to a predicate while under-specifying their position.
This is useful for speci-fying arguments to give v when a parser doesn?thandle unbounded dependencies and is faced withWhich bone did you give the dog?
vs. To whichdog did you give the bone?Finally, the RMRS (6) is a notational variant ofthe MRS derived by the ERG, a wide-coverage deepgrammar:(6) l1 : a1: every q 1(x1),RSTR(a1, h2),BODY(a1, h3)l41 : a41: fat j 1(e?
),ARG1(a41, x2)l42 : a42: cat n 1(x3)l5 : a5: chase v 1(e),ARG1(a5, x4),ARG2(a5, x5)l6 : a6: some q 1(x6),RSTR(a6, h7),BODY(a6, h8)l9 : a9: dog n 1(x7)h2 =q l42, l41 = l42, h7 =q l9x1 = x2, x2 = x3, x3 = x4,x5 = x6, x5 = x7RSTR and BODY are conventional names forthe ARG1 and ARG2 of a quantifier predicate sym-bol.
Atoms like h2 =q l42 (?qeq?)
specify a cer-tain kind of ?outscopes?
relationship between thehole and the label, and are used here to underspec-ify the scope of the two quantifiers.
Notice that thelabels of the EPs for ?fat?
and ?cat?
are stipulatedto be equal in (6), whereas the anchors are not.
Inthe tree, it is the anchors that are mapped to thenodes with the labels fat j 1 and cat n 1; the la-bel is mapped to the conjunction node just abovethem.
In other words, the role of the anchor in anEP is to connect a predicate to its arguments, whilethe role of the label is to connect the EP to the sur-rounding formula.
Representing conjunction withlabel sharing stems from MRS and provides com-pact representations.Finally, (6) uses predicate symbols likedog n 1 that are meant to be more specific thansymbols like dog n which the earlier RMRSsused.
This reflects the fact that the deep gram-mar performs some lexical disambiguation that thechunker and POS tagger don?t.
The fact that theformer symbol should be more specific than thelatter can be represented using SPEC atoms likedog n 1 " dog n. Note that even a deep gram-mar will not fully disambiguate to semantic pred-icate symbols, such as WordNet senses, and sodog n 1 can still be consistent with multiple sym-bols like dog n 1 and dog n 2 in the semanticrepresentation.
However, unlike the output of aPOS tagger, an RMRS symbol that?s output by adeep grammar is consistent with symbols that allhave the same arity, because a deep grammar fullydetermines lexical subcategorisation.In summary, RMRS allows us to represent in auniform way the (partial) semantics that can beextracted from a wide range of NLP tools.
Thisis useful for hybrid systems which exploit shal-lower analyses when deeper parsing fails, or whichtry to match deeply parsed queries against shal-low parses of large corpora; and in fact, RMRS isgaining popularity as a practical interchange for-mat for exactly these purposes (Copestake, 2003).However, RMRS is still relatively ad-hoc in that itsformal semantics is not defined; we don?t know,formally, what an RMRS means in terms of seman-tic representations like (2) and (3), and this hin-ders our ability to design efficient algorithms forprocessing RMRS.
The purpose of this paper is tolay the groundwork for fixing this problem.3 Robust Minimal Recursion SemanticsWe will now make the basic ideas from Section2 precise.
We will first define the syntax of theRMRS language; this is a notational variant of ear-lier definitions in the literature.
We will then de-fine a model theory for our version of RMRS, andconclude this section by carrying over the notionof solved forms from CLLS (Egg et al, 2001).3.1 RMRS SyntaxWe define RMRS syntax in the style of CLLS (Egget al, 2001).
We assume an infinite set of nodevariables NVar = {X,Y,X1, .
.
.
}, used as labels,anchors, and holes; the distinction between thesewill come from their position in the formulas.
Wealso assume an infinite set of base variables BVar,consisting of individual variables {x, x1, y, .
.
.
}and event variables {e1, .
.
.
}, and a vocabulary of453predicate symbols Pred = {P,Q, P1, .
.
.}.
RMRSformulas are defined as follows.Definition 1.
An RMRS is a finite set ?
of atomsof one of the following forms; S ?
N is a set ofnumbers that is either finite orN itself (throughoutthe paper, we assume 0 ?
N).A ::= X:Y :P| ARGS(X, v)| ARGS(X,Y )| X !?
Y| v1 = v2 | v1 %= v2| X = Y | X %= Y| P " QA node variable X is called a label iff ?
con-tains an atom of the form X:Y :P or Y !?
X; itis an anchor iff ?
contains an atom of the formY :X:P or ARGS(X, i); and it is a hole iff ?
con-tains an atom of the form ARGS(Y,X) or X!
?Y .Def.
1 combines similarities to earlier presen-tations of RMRS (Copestake, 2003; Copestake,2007b) and to CLLS/dominance constraints (Egget al, 2001).
For the most part, our syntaxgeneralises that of older versions of RMRS: Weuse ARG{i} (with a singleton set S) instead ofARGi and ARGN instead of ARGn, and the EPl:a:P (v) (as in Section 2) is an abbreviation of{l:a:P,ARG{0}(a, v)}.
Similarly, we don?t as-sume that labels, anchors, and holes are syntacti-cally different objects; they receive their functionfrom their positions in the formula.
One major dif-ference is that we use dominance (!?)
rather thanqeq; see Section 3.4 for a discussion.
Comparedto dominance constraints, the primary differenceis that we now have a mechanism for representinglexical ambiguity, and we can specify a predicateand its arguments separately.3.2 Model TheoryThe model theory formalises the relationship be-tween an RMRS and the fully specific, alternativelogical forms that it describes, expressed in thebase language.
We represent such a logical formas a tree ?
, such as the ones in Fig.
1, and we canthen define satisfaction of formulas in the usualway, by taking the tree as a model structure thatinterprets all predicate symbols specified above.In this paper, we assume for simplicity that thebase language is as in MRS; essentially, ?
becomesthe structure tree of a formula of predicate logic.We assume that ?
is a ranked signature consist-ing of the symbols of predicate logic: a unary con-structor ?
and binary constructors ?,?, etc.
; a setof 3-place quantifier symbols such as every q 1and some q 1 (with the children being the boundvariable, the restrictor, and the scope); and con-structors of various arities for the predicate sym-bols; e.g., chase v 1 is of arity 3.
Other base lan-guages may require a different signature ?
and/ora different mapping between formulas and trees;the only strict requirement we make is that thesignature contains a binary constructor ?
to rep-resent conjunction.
We write ?i and ?
?i for theset of all constructors in ?
with arity i and at leasti, respectively.
We will follow the typographicalconvention that non-logical symbols in ?
are writ-ten in sans-serif, as opposed to the RMRS predicatesymbols like cat n and cat n 1.The models of RMRS are then defined to be fi-nite constructor trees (see also (Egg et al, 2001)):Definition 2.
A finite constructor tree ?
is a func-tion ?
: D ?
?
such that D is a tree domain (i.e.,a subset ofN?
which is closed under prefix and leftsibling) and the number of children of each nodeu ?
D is equal to the arity of ?
(u).We write D(?)
for the tree domain of a con-structor tree ?
, and further define the following re-lations between nodes in a finite constructor tree:Definition 3. u !?
v (dominance) iff u is a prefixof v, i.e.
the node u is equal to or above the nodev in the tree.
u!??
v iff u!?
v, and all symbols onthe path from u to v (not including v) are ?.The satisfaction relation between an RMRS ?and a finite constructor tree ?
is defined in termsof several assignment functions.
First, a nodevariable assignment function ?
: NVar ?
D(?
)maps the node variables in an RMRS to the nodesof ?
.
Second, a base language assignment func-tion g : BVar ?
?0 maps the base variables tonullary constructors representing variables in thebase language.
Finally, a function ?
from Pred tothe power set of ?
?1 maps each RMRS predicatesymbol to a set of constructors from ?.
As we?llsee shortly, this function allows an RMRS to under-specify lexical ambiguities.Definition 4.
Satisfaction of atoms is defined as454follows:?,?, g,?
|= X:Y :P iff?(?
(Y )) ?
?
(P ) and ?(X)!??
?
(Y )?,?, g,?
|= ARGS(X, a) iff exists i ?
S s.t.?
(X) ?
i ?
D(?)
and ?(?
(X) ?
i) = g(a)?,?, g,?
|= ARGS(X,Y ) iff exists i ?
S s.t.?
(X) ?
i ?
D(?),?
(X) ?
i = ?
(Y )?,?, g,?
|= X !?
Y iff ?(X)!?
?
(Y )?,?, g,?
|= X =/%= Y iff ?
(X) =/%= ?
(Y )?,?, g,?
|= v1 =/%= v2 iff g(v1) =/%= g(v2)?,?, g,?
|= P " Q iff ?
(P ) ?
?
(Q)A 4-tuple ?,?, g,?
satisfies an RMRS ?
(written?,?, g,?
|= ?)
iff it satisfies all of its elements.Notice that one RMRS may be satisfied by mul-tiple trees; we can take the RMRS to be a par-tial description of each of these trees.
In partic-ular, RMRSs may represent semantic scope ambi-guities and/or missing information about seman-tic dependencies, lexical subcategorisation andlexical senses.
For j = {1, 2}, suppose that?j ,?j , gj ,?
|= ?.
Then ?
exhibits a semanticscope ambiguity if there are variables Y, Y ?
?NVar such that ?1(Y ) !?
?1(Y ?)
and ?2(Y ?)
!?
?2(Y ).
It exhibits missing information about se-mantic dependencies if there are base-languagevariables v, v?
?
BVar such that g1(v) = g1(v?
)and g2(v) %= g2(v?).
It exhibits missing lex-ical subcategorisation information if there is aY ?
NVar such that ?1(?1(Y )) is a construc-tor of a different type from ?2(?2(Y )) (i.e., theconstructors are of a different arity or they dif-fer in whether their arguments are scopal vs. non-scopal).
And it exhibits missing lexical sense in-formation if ?1(?1(Y )) and ?2(?2(Y )) are differ-ent base-language constructors, but of the sametype.Let?s look again at the RMRS (4).
This is sat-isfied by the trees in Fig.
1 (among others) to-gether with some particular ?, g, and ?.
For in-stance, consider the left-hand side tree in Fig.
1.The RMRS (4) satisfies this tree with an assign-ment function ?
that maps the variables l1 and a1to the root node, l41 and l42 to its second child(labeled with ???
), a41 to the first child of thatnode (i.e.
the node 21, labelled with ?fat?)
anda42 to the node 22, and so forth.
g will map x1and x3 to x, and x6 and x7 to y, and so on.
And?
will map each RMRS predicate symbol (whichrepresents a word) to the set of its fully resolvedmeanings, e.g.
cat n to a set containing cat n 1_every_q_1x?_fat_j_1e' x_cat_n_1x_some_q_1y _dog_n_1y_chase_v_1e x y?
?_sleep_v_1e''x_run_v_1e''' yFigure 2: Another tree which satisfies (6).and possibly others.
It is then easy to verifythat every single atom in the RMRS is satisfied?most interestingly, the EPs l41:a41: fat j(e?)
andl42:a42: cat n(x3) are satisfied because ?(l41)!???
(a41) and ?(l42)!??
?
(a42).Truth, validity and entailment can now be de-fined in terms of satisfiability in the usual way:Definition 5. truth: ?
|= ?
iff ?
?, g,?
such that?,?, g,?
|= ?validity: |= ?
iff ??
, ?
|= ?.entailment: ?
|= ??
iff ??
, if ?
|= ?
then ?
|= ?
?.3.3 Solved FormsOne aspect in which our definition of RMRS is likedominance constraints and unlike MRS is that anysatisfiable RMRS has an infinite number of mod-els which only differ in the areas that the RMRSdidn?t ?talk about?.
Reading (6) as an MRS or asan RMRS of the previous literature, this formulais an instruction to build a semantic representa-tion out of the pieces for ?every fat cat?, ?somedog?, and ?chased?
; a semantic representation asin Fig.
2 would not be taken as described by thisRMRS.
However, under the semantics we proposedabove, this tree is a correct model of (6) becauseall atoms are still satisfied; the RMRS didn?t sayanything about ?sleep?
or ?run?, but it couldn?t en-force that the tree shouldn?t contain those subfor-mulas either.In the context of robust semantic processing,this is a desirable feature, because it means thatwhen we enrich an RMRS obtained from a shal-low processor with more semantic information?such as the relation symbols introduced by syntac-tic constructions such as appositives, noun-nouncompounds and free adjuncts?we don?t changethe set of models; we only restrict the set of mod-els further and further towards the semantic rep-resentation we are trying to reconstruct.
Further-more, it has been shown in the literature that adominance-constraint style semantics for under-specified representations gives us more room to455manoeuvre when developing efficient solvers thanan MRS-style semantics (Althaus et al, 2003).However, enumerating an infinite number ofmodels is of course infeasible.
For this reason,we will now transfer the concept of solved formsfrom dominance constraints to RMRS.
An RMRSin solved form is guaranteed to be satisfiable, andthus each solved form represents an infinite classof models.
However, each satisfiable RMRS hasonly a finite number of solved forms which parti-tion the space of possible models into classes suchthat models within a class differ only in ?irrele-vant?
details.
A solver can then enumerate thesolved forms rather than all models.Intuitively, an RMRS in solved form is fullyspecified with respect to the predicate-argumentstructure, all variable equalities and inequalitiesand scope ambiguities have been resolved, andonly lexical sense ambiguities remain.
This ismade precise below.Definition 6.
An RMRS ?
is in solved form iff:1. every variable in ?
is either a hole, a label oran anchor (but not two of these);2. ?
doesn?t contain equality, inequality, andSPEC (") atoms;3. if ARGS(Y, i) is in ?, then |S| = 1;4. for any label Y and index set S, there are notwo atomsARGS(Y, i) andARGS(Y, i?)
in?;5.
if Y is an anchor in some EP X:Y :Pand k is the maximum number such thatARG{k}(X, i) is in ?
for any i, then there is aconstructor p ?
?
(P ) whose arity is at leastk;6. no label occurs on the right-hand side of twodifferent !?
atoms.Because solved forms are so restricted, we can?read off?
at least one model from each solvedform:Proposition 1.
Every RMRS in solved form is sat-isfiable.Proof (sketch; see also (Duchier and Niehren, 2000)).For each EP, we choose to label the anchor withthe constructor p of sufficiently high arity whoseexistence we assumed; we determine the edgesbetween an anchor and its children from theuniquely determined ARG atoms; plugging labelsinto holes is straightforward because no label isdominated by more than one hole; and spacesbetween the labels and anchors are filled withconjunctions.We can now define the solved forms of an RMRS?
; these finitely many RMRSs in solved form parti-tion the space of models of ?
into classes of mod-els with trivial differences.Definition 7.
The syntactic dominance relationD(?)
in an RMRS ?
is the reflexive, transitive clo-sure of the binary relation{(X,Y ) | ?
contains X !?
Y orARGS(X,Y ) for some S}An RMRS ??
is a solved form of the RMRS ?
iff??
is in solved form and there is a substitution sthat maps the node and base variables of ?
to thenode and base variables of ??
such that1.
??
contains the EP X ?
:Y ?
:P iff there are vari-ables X,Y such that X:Y :P is in ?, X ?
=s(X), and Y ?
= s(Y );2. for every atom ARGS(X, i) in ?, there isexactly one atom ARGS?
(X ?, i?)
in ??
withX ?
= s(X), i?
= s(i), and S?
?
S;3.
D(??)
?
s(D(?
)).Proposition 2.
For every tuple (?,?, g,?)
thatsatisfies some RMRS ?, there is a solved form ?
?of ?
such that (?,?, g,?)
also satisfies ??.Proof.
We construct the substitution s from ?
andg.
Then we add all dominance atoms that are satis-fied by ?
and restrict the ARG atoms to those childindices that are actually used in ?
.
The result is insolved form because ?
is a tree; it is a solved formof ?
by construction.Proposition 3.
Every RMRS ?
has only a finitenumber of solved forms, up to renaming of vari-ables.Proof.
Up to renaming of variables, there is only afinite number of substitutions on the node and basevariables of ?.
Let s be such a substitution.
Thisfixes the set of EPs of any solved form of ?
that isbased on s uniquely.
There is only a finite set ofchoices for the subsets S?
in condition 2 of Def.
7,and there is only a finite set of choices of new dom-inance atoms that satisfy condition 3.
Therefore,the set of solved forms of ?
is finite.456Let?s look at an example for all these defini-tions.
All the RMRSs presented in Section 2 (re-placing =q by !?)
are in solved form; this is leastobvious for (6), but becomes clear once we noticethat no label is on the right-hand side of two dom-inance atoms.
However, the model constructed inthe proof of Prop.
1 looks a bit like Fig.
2; bothmodels are problematic in several ways and in par-ticular contain an unbound variable y even thoughthey also contains a quantifier that binds y.
If werestrict the class of models to those in which suchvariables are bound (as Copestake et al (2005)do), we can enforce that the quantifiers outscopetheir bound variables without changing models ofthe RMRS further?i.e., we add the atoms h3!?
l5and h8!?
l5.
Fig.
2 is no longer a model for the ex-tended RMRS, which in turn is no longer in solvedform because the label l5 is on the right-hand sideof two dominance atoms.
Instead, it has the fol-lowing two solved forms:(7) l1:a1: every q 1(x1),RSTR(a1, h2), BODY(a1, h3),l41:a41: fat j 1(e?
),ARG1(a41, x1),l41:a42: cat n 1(x1),l6:a6: some q 1(x6),RSTR(a6, h7), BODY(a6, h8),l9:a9: dog n 1(x6),l5:a5: chase v 1(e),ARG1(a5, x1), ARG2(a5, x6),h2 !?
l41, h3 !?
l6, h7 !?
l9, h8 !?
l5(8) l1:a1: every q 1(x1),RSTR(a1, h2), BODY(a1, h3),l41:a41: fat j 1(e?
),ARG1(a41, x1),l41:a42: cat n 1(x1),l6:a6: some q 1(x6),RSTR(a6, h7), BODY(a6, h8),l9:a9: dog n 1(x6),l5:a5: chase v 1(e),ARG1(a5, x1), ARG2(a5, x6),h2 !?
l41, h3 !?
l5, h7 !?
l9, h8 !?
l1Notice that we have eliminated all equalities byunifying the variable names, and we have fixed therelative scope of the two quantifiers.
Each of thesesolved forms now stands for a separate class ofmodels; for instance, the first model in Fig.
1 isa model of (7), whereas the second is a model of(8).3.4 ExtensionsSo far we have based the syntax and semantics ofRMRS on the dominance relation from Egg et al(2001) rather than the qeq relation from Copestakeet al (2005).
This is partly because dominance isthe weaker relation: If a dependency parser links adeterminer to a noun and this noun to a verb, thenwe can use dominance but not qeq to represent thatthe predicate introduced by the verb is outscopedby the quantifier introduced by the determiner (seeearlier discussion).
However, it is very straightfor-ward to extend the syntax and semantics of the lan-guage to include the qeq relation.
This extensionadds a new atom X =q Y to Def.
1, and ?,?, g,?will satisfy X =q Y iff ?(X)!??
(Y ), each nodeon the path is a quantifier, and each step in the pathgoes to the rightmost child.
All the above proposi-tions about solved forms still hold if ?dominance?is replaced with ?qeq?.Furthermore, grammar developers such as thosein the DELPH-IN community typically adopt con-ventions that restrict them to a fragment of the lan-guage from Def.
1 (once qeq is added to it), or theyrestrict attention to only a subset of the models(e.g., ones with correctly bound variables, or oneswhich don?t contain extra material like Fig.
2).Our formalism provides a general framework intowhich all these various fragments fit, and it?s amatter of future work to explore these fragmentsfurther.Another feature of the existing RMRS literatureis that each term of an RMRS is equipped with asort.
In particular, individual variables x, eventvariables e and holes h are arranged together withtheir subsorts (e.g., epast) and supersorts (e.g.,sort i abstracts over x and e) into a sort hierar-chy S. For simplicity we defined RMRS withoutsorts, but it is straightforward to add them.
Forthis, one assumes that the signature?
is sorted, i.e.assigns a sort s1 ?
.
.
.
sn ?
s to each constructor,where n is the constructor?s arity (possibly zero)and s, s1, .
.
.
, sn ?
S are atomic sorts.
We restrictthe models of RMRS to trees that are well-sorted inthe usual sense, i.e.
those in which we can infer asort for each subtree, and require that the variableassignment functions likewise respect the sorts.
Ifwe then modify Def.
6 such that the constructor pof sufficiently high arity is also consistent with thesorts of the known arguments?i.e., if p has sorts1?
.
.
.?
sn ?
s and the RMRS contains an atomARG{k}(Y, i) and i is of sort s?, then s?
is a sub-sort of sk?all the above propositions about solvedforms remain true.4574 Future workThe above definitions serve an important theoret-ical purpose: they formally underpin the use ofRMRS in practical systems.
Next to the peace ofmind that comes with the use of a well-understoodformalism, we hope that the work reported herewill serve as a starting point for future research.One direction to pursue from this paper is thedevelopment of efficient solvers for RMRS.
As afirst step, it would be interesting to define a practi-cally useful fragment of RMRS with polynomial-time satisfiability.
Our definition is sufficientlyclose to that of dominance constraints that we ex-pect that it should be feasible to carry over the def-inition of normal dominance constraints (Althauset al, 2003) to RMRS; neither the lexical ambigu-ity of the node labels nor the separate specificationof predicates and arguments should make satisfia-bility harder.Furthermore, the above definition of RMRS pro-vides new concepts which can help us phrase ques-tions of practical grammar engineering in well-defined formal terms.
For instance, one crucial is-sue in developing a hybrid system that combinesor compares the outputs of deep and shallow pro-cessors is to determine whether the RMRSs pro-duced by the two systems are compatible.
In thenew formal terms, we can characterise compati-bility of a more detailed RMRS ?
(perhaps from adeep grammar) and a less detailed RMRS ??
sim-ply as entailment ?
|= ??.
If entailment holds,this tells us that all claims that ??
makes about thesemantic content of a sentence are consistent withthe claims that ?
makes.At this point, we cannot provide an efficient al-gorithm for testing entailment of RMRS.
However,we propose the following novel syntactic charac-terisation as a starting point for research alongthose lines.
We call an RMRS ??
an extension ofthe RMRS ?
if ??
contains all the EPs of ?
andD(??)
?
D(?
).Proposition 4.
Let ?,??
be two RMRSs.
Then?
|= ??
iff for every solved form S of ?, there is asolved form S?
of ??
such that S is an extension ofS?.Proof (sketch).
???
follows from Props.
1 and 2.???
: We construct a solved form for ??
bychoosing a solved form for ?
and appropriate sub-stitutions for mapping the variables of ?
and ?
?onto each other, and removing all atoms usingvariables that don?t occur in ??
.
The hard partis the proof that the result is a solved form of ??
;this step involves proving that if ?
|= ??
with thesame variable assignments, then all EPs in ??
alsooccur in ?.5 ConclusionIn this paper, we motivated and defined RMRS?asemantic framework that has been used to repre-sent, compare, and combine semantic informationcomputed from deep and shallow parsers.
RMRSis designed to be maximally flexible on the typeof semantic information that can be left under-specified, so that the semantic output of a shallowparser needn?t over-determine or under-determinethe semantics that can be extracted from the shal-low syntactic analysis.
Our key contribution wasto lay the formal foundations for a formalism thatis emerging as a standard in robust semantic pro-cessing.Although we have not directly provided newtools for modelling or processing language, webelieve that a cleanly defined model theory forRMRS is a crucial prerequisite for the future de-velopment of such tools; this strategy was highlysuccessful for dominance constraints (Althaus etal., 2003).
We hope that future research will buildupon this paper to develop efficient algorithms andimplementations for solving RMRSs, performinginferences that enrich RMRSs from shallow analy-ses with deeper information, and checking consis-tency of RMRSs that were obtained from differentparsers.Acknowledgments.
We thank Ann Copestake,Dan Flickinger, and Stefan Thater for extremelyfruitful discussions and the reviewers for theircomments.
The work of Alexander Koller wasfunded by a DFG Research Fellowship and theCluster of Excellence ?Multimodal Computingand Interaction?.ReferencesS.
Abney.
1996.
Partial parsing via finite-state cas-cades.
In John Carroll, editor, Workshop on RobustParsing (ESSLLI-96), pages 8?15, Prague.E.
Althaus, D. Duchier, A. Koller, K. Mehlhorn,J.
Niehren, and S. Thiel.
2003.
An efficient graphalgorithm for dominance constraints.
J. Algorithms,48:194?219.458J.
Bos, S. Clark, M. Steedman, J. Curran, and J. Hock-enmaier.
2004.
Wide coverage semantic representa-tions from a CCG parser.
In Proceedings of the Inter-national Conference on Computational Linguistics(COLING 2004), Geneva, Switzerland.E.J.
Briscoe, J. Carroll, and R. Watson.
2006.
Thesecond release of the rasp system.
In Proceedingsof the COLING/ACL 2006 Interaction PresentationSessions, Sydney, Australia.M.
Butt, T. Holloway King, M. Nin?o, and F. Segond.1999.
A Grammar Writer?s Cookbook.
CSLI Publi-cations.S.
Clark, M. Steedman, and J. Curran.
2004.
Objectextraction and question parsing using CCG.
In Pro-ceedings from the Conference on Empirical Methodsin Natural Language Processing (EMNLP), pages111?118, Barcelona.A.
Copestake and D. Flickinger.
2000.
An open-source grammar development environment and en-glish grammar using HPSG.
In Proceedings ofthe Second Conference on Language Resources andEvaluation (LREC 2000), pages 591?600, Athens.A.
Copestake, D. Flickinger, I.
Sag, and C. Pollard.2005.
Minimal recursion semantics: An introduc-tion.
Research on Language and Computation, 3(2?3):281?332.A.
Copestake.
2003.
Report on the design of RMRS.Technical Report EU Deliverable for Project num-ber IST-2001-37836, WP1a, Computer Laboratory,University of Cambridge.A.
Copestake.
2007a.
Applying robust semantics.In Proceedings of the 10th Conference of the Pa-cific Assocation for Computational Linguistics (PA-CLING), pages 1?12, Melbourne.
Invited talk.A.
Copestake.
2007b.
Semantic composition with(robust) minimal recursion semantics.
In ACL-07workshop on Deep Linguistic Processing, pages 73?80, Prague.D.
Duchier and J. Niehren.
2000.
Dominance con-straints with set operators.
In In Proceedings of theFirst International Conference on ComputationalLogic (CL2000), LNCS, pages 326?341.
Springer.M.
Egg, A. Koller, and J. Niehren.
2001.
The con-straint language for lambda structures.
Journal ofLogic, Language, and Information, 10:457?485.A.
Frank.
2004.
Constraint-based RMRS construc-tion from shallow grammars.
In Proceedings of theInternational Conference in Computational Linguis-tics (COLING 2004), Geneva, Switzerland.L.
Zettlemoyer and M. Collins.
2007.
Online learn-ing of relaxed CCG grammars for parsing to log-ical form.
In Proceedings of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning (EMNLP-CoNLL), pages 678?687.459
