Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 98?102,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsEliminating Redundancy by Spectral Relaxation for Multi-DocumentSummarizationFumiyo Fukumoto Akina Sakai Yoshimi SuzukiInterdisciplinary Graduate School of Medicine and EngineeringUniversity of Yamanashi{fukumoto, t05kg014, ysuzuki}@yamanashi.ac.jpAbstractThis paper focuses on redundancy, over-lapping information in multi-documents,and presents a method for detectingsalient, key sentences from documentsthat discuss the same event.
To elimi-nate redundancy, we used spectral clus-tering and classified each sentence intogroups, each of which consists of seman-tically related sentences.
Then, we ap-plied link analysis, the Markov RandomWalk (MRW) Model to deciding the im-portance of a sentence within documents.The method was tested on the NTCIRevaluation data, and the result shows theeffectiveness of the method.1 IntroductionWith the exponential growth of information on theInternet, it is becoming increasingly difficult for auser to read and understand all the materials froma series of large-scale document streams that is po-tentially of interest.
Multi-document summariza-tion is an issue to attack the problem.
It differsfrom single document summarization in that it isimportant to identify differences and similaritiesacross documents.
Graph-based ranking methods,such as PageRank (Page et al, 1998) and HITS(Kleinberg, 1999) have recently applied and beensuccessfully used for multi-document summariza-tion (Erkan and Radev, 2004; Mihalcea and Tarau,2005).
Given a set of documents, the model con-structs graph consisting vertices and edges wherevertices are sentences and edges reflect the rela-tionships between sentences.
The model then ap-plies a graph-based ranking method to obtain therank scores for the sentences.
Finally, the sen-tences with large rank scores are chosen into thesummary.
However, when they are strung to-gether, the resulting summary still contains muchoverlapping information.
Because all the sen-tences are ranked based on a sentence as unit ofinformation.
Therefore, for example, semanti-cally related two sentences with ?high recommen-dation?
are ranked with high score, and thus areregarded as a summary sentence.
To attack theproblem, Wan et al proposed two models, i.e., theCluster-based conditional Markov Random Walkmodel and the Cluster-based HITS model, bothmake use of the theme clusters in the document set(Wan and Yang, 2008).
Their model first groupsdocuments into theme clusters by using a simpleclustering method, k-means.
Next, the model con-structs a directed or undirected graph to reflect therelationships between sentences and clusters byusing link analysis.
They reported that the resultson the DUC2001 and DUC2002 datasets showedthe effectiveness of their models.
However, oneof the problems using multivariate clustering suchas k-means is that it is something of a black artwhen applied to high-dimensional data.
The avail-able techniques for searching this large space donot offer guarantees of global optimality, thus theresulting summary still contains much overlappinginformation, especially for a large amount of doc-uments.This paper focuses extractive summarization,and present a method for detecting key sentencesfrom documents that discuss the same event.
LikeWan et al?s approach, we applied link analysis,the Markov Random Walk (MRW) model (Bre-maud, 1999) to a graph consisting sentences andclusters.
To attack the problem dealing with thehigh dimensional spaces, we applied spectral clus-tering technique (Ng et al, 2002) to the sentencesfrom a document set.
Spectral clustering is a trans-formation of the original sentences into a set of or-thogonal eigenvectors.
We worked in the space de-fined by the first few eigenvectors, using standardclustering techniques in the transformed space.982 Spectral ClusteringSimilar to other clustering algorithms, the spec-tral clustering takes as input a matrix formed froma pairwise similarity function over a set of datapoints.
Given a set of points S = {s1, ?
?
?
, sn}in a high dimensional space, the algorithm is asfollows:1.
Form a distance matrix D ?
R2.
We usedcosine similarity as a distance measure.2.
D is transformed to an affinity matrix Aij.Aij={exp(?D2ij?2), if i 6= j0, otherwise.
?2 is a parameter and controls the rate atwhich affinity drops off with distance.3.
The matrix L = D?1/2AD?1/2 is created.
Dis a diagonal matrix whose (i,i) element is thesum of A?s i-th row.4.
The eigenvectors and eigenvalues of L arecomputed, and a new matrix is created fromthe vectors associated with the number of llargest eigenvalues.5.
Each item now has a vector of l coordinatesin the transformed space.
These vectors arenormalized to unit length.6.
K-means is applied to S in the l-dimensionalspace.3 Cluster-based Link AnalysisThe link analysis we used is an approach presentedby Wan et.
al (Wan and Yang, 2008).
The modelcalled ?Cluster-based Conditional Markov Ran-dom Walk Model?
incorporates the cluster-levelinformation into the process of sentence rank-ing.
The model is summarized as follows: Let?
(clus(si)) ?
[0, 1] be the importance of clus-ter clus(si) in the whole document set D. Letalso ?
(si, clus(si)) ?
[0, 1] denote the strength ofthe correlation between sentence siand its clusterclus(si).
clus(si) refers to the cluster containingsentence si.
The transition probability from sitosjis defined by formula (1).p(i?j|clus(si), clus(sj))=8>><>>:f(i?j|clus(si), clus(sj))|S|Xk=1f(i?k|clus(si), clus(sk)), if ?f 6= 00 , otherwise.
(1)f(i ?
j | clus(si), clus(sj)) in formula (1) refersto the weight between two sentences siand sj,conditioned on the two clusters containing the twosentences, and defined by formula (2).f(i?j|clus(si), clus(sj))= f(i?j)?{???(clus(si))??
(clus(si))+(1 ?
?)??(clus(sj))??
(clus(sj))} (2)?
?
[0, 1] in formula (2) is the combinationweight controlling the relative contributions fromthe source cluster and the destination cluster.?
(clus(si)) denotes the value indicating the im-portance of the cluster clus(si) in the documentset D. Similarly, ?
(si, clus(si)) refers to the sim-ilarity value between the sentence siand its clusterclus(si).
These values are obtained by using thecosine similarity.
The new row-normalized matrixM is defined by formula (3).Mij = p(i ?
j | clus(si), clus(sj)) (3)The saliency scores for the sentences are com-puted based on formula (3) by using the iterativeform in formula (4).Score(si) = ?Xallj 6=iScore(sj) ?
Mji +(1 ?
?
)| S |(4)?
in formula (4) is the damping factor, which weset to 0.85.
The above process can be consideredas a Markov chain by taking the sentences as thestates and the final transition matrix is given byformula (5), and each score of the sentences is ob-tained by the principle eigenvector of the new tran-sition matrix A.A = ?MT+(1 ?
?
)| V |~e~eT (5)~e in formula (5) is a column vector with all ele-ments equal to 1.
We selected a certain numberof sentences according to rank score into the sum-mary.994 ExperimentsWe had an experiment by using the NTCIR-31SUMM to evaluate our approach.
NTCIR-3 hastwo tasks, single, and multi-document summariza-tion.
The data is collected from two years(1998-1999) Mainichi Japanese Newspaper articles.
Weused multi-document summarization task.
Thereare two types of gold standard data provided tohuman judges, FBFREE DryRun and FormalRun,each of which consists of 30 topics.
There are twotypes of correct summary according to the charac-ter length, i.e., ?long?
and ?short?.
All documentswere tagged by a morphological analysis, ChaSen(Matsumoto et al, 1997) and noun words are ex-tracted.We used FormalRun consisting of 30 topics as atest data.
Similarly, we randomly chose 10 topicsfrom the FBFREEDryRun data to tuning a param-eter ?
in Spectral Clustering, and the number of lin the l-dimensional space obtained by the Spec-tral Clustering.
?
is searched in steps of 0.01 from1.0 to 5.0. l in the l-dimensional space is searchedin steps 10% from 0 to 80% against the total num-ber of words in the training data.
The size that op-timized the average F-score of 10 topics was cho-sen.
Here, F-score is the standard measure usedin the clustering algorithm, and it combines recalland precision with an equal weight.
Precision is aratio of the number of correct pair of sentences ob-tained by the k-means divided by the total numberof pairs obtained by the k-means.
Recall indicatesa ratio of the number of correct pair of sentencesobtained by the k-means divided by the total num-ber of correct pairs.
As a result, ?
and l are set to4.5 and 80%, respectively.It is difficult to predict the actual cluster numberk in a given input sentences to produce optimalresults.
The usual drawback in many clusteringalgorithms is that they cannot give a valid criterionfor measuring class structure.
Therefore, similarto Wan et.
al?s method (Wan and Yang, 2008), wetypically set the number of k of expected clustersas?N where N is the number of all sentencesin the document set.
We used these values of theparameters and evaluated by using test data.We used two evaluation measures.
One is co-sine similarity between the generated summary bythe system and the human generated summary.Another is ROUGE score used in DUC (Liu andHovy, 2003).1http://research.nii.ac.jp/ntcir/ROUGE =Xs?CandXngram?sCountmatch(ngram)Xs?CandXngram?sCount(ngram)(6)We used a word instead of n-gram sequence informula (6).
The results are shown in Table 1.
?#of doc?
and ?# of sent?
refer to the average numberof documents and sentences, respectively.
?# ofsum?
denotes to the average number of summarysentences provided by NTCIR3 SUMM.
?cos?
and?ROUGE?
refer to the results evaluated by usingcosine, and ROUGE score, respectively.
?MRW?indicates the results obtained by directly applyingMRW model to the input sentences.We can see from Table 1 that our approach(Spectral) outperforms the baselines, ?MRW?and ?k-means?, regardless of the types of sum-mary (long/short) and evaluation measures (co-sine/ROUGE).
The results obtained by three ap-proaches show that ?short?
was better than ?long?.This indicates that the rank score of correct sen-tences within the candidate sentences obtainedby the MRW model works well.
Comparingthe results evaluated by ?ROUGE?
were worsethan those of ?cos?
at any approaches.
One rea-son is that the difference of summarization tech-nique, i.e., our work is extractive summarization,while the gold standard data provided by NTCIR-3 SUMM is the abstracts written by human pro-fessionals.
As a result, a large number of wordsin a candidate summary are extracted by our ap-proaches.
For future work, it is necessary to ex-tend our method to involve paraphrasing for ex-tracted key sentences to reduce the gap betweenautomatically generated summaries and human-written abstracts (Barzilay et al, 1993; Careniniand Cheung, 2008).It is interesting to note how our approach affectsfor the number of sentences as an input.
Figure1 illustrates the results of summary ?long?
withevaluated ROUGE score.
We can see from Figure1 that our approach is more robust than k-meansand the MRW model, even for a large number ofinput data.
We have seen the same observationsfrom other three results, i.e., the results of shortand long with evaluated cos and short with evalu-ated ROUGE.We recall that the cluster number k is set to thesquare root of the sentence number.
We tested dif-ferent number of k to see how the cluster number100Table 1: Results against 30 topics# of doc # of sent # of sum cos ROUGEMRW k-means Spectral MRW k-means SpectralShort 7.5 83.0 11.9 0.431 0.575 0.632 0.330 0.334 0.360Long 20.4 0.371 0.408 0.477 0.180 0.186 0.2090.050.10.150.20.250.30.350.40  50  100  150  200  250  300  350ROUGE# of sentencesk-meansSpectralMRWFigure 1: Long with ROUGE vs. # of sentencesaffects the summarization performance.
In the ex-periment, we set k = r?
| N | where r is a pa-rameter ranged from 0 to 1 (Wan and Yang, 2008).Because of space is limited, we report only the re-sult with summary ?long?
and ROUGE score.
Theresult is shown in Figure 2.Overall the results obtained by our approachand k-means outperformed the results obtainedby directly applying MRW model, while the re-sults by k-means was worse than the results byMRW model when the ratio of the number of sen-tences was larger than 0.8.
This shows that cluster-based summarization is effective reduce redun-dancy, overlapping information.
Figure 2 alsoshows that our approach always outperforms, re-gardless of how many number of sentences wereused.
This indicates that the MRW model withspectral clustering is more robust than that withthe baseline, k-means, with respect to the differ-ent number of clusters.5 ConclusionWe have developed an approach to detect salientsentences from documents that discuss the same0.1750.180.1850.190.1950.20.2050.210.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9Avg.
ROUGEratio of the # of kMRWk-meansSpectralFigure 2: Long with ROUGE score measure vs. #of kevent.
The results showed the effectiveness of themethod.
Future work will include: (i) compar-ing other approaches that uses link analysis to re-duce redundancy, such as (Zhu et al, 2007), (ii)applying the method to the DUC evaluation datafor quantitative evaluation, and (iii) extending themethod to classify sentences into more than oneclasses by using soft-clustering techniques such asEM (Dempster et al, 1977) and fuzzy c-means al-gorithms (Zhang and Wang, 2007).ReferencesR.
Barzilay, K. R. McKeown, and M. Elhadad.1993.
Information Fusion in the Context of Multi-document Summarization.
In Proc.
of the 37th An-nual Meeting of the Association for ComputationalLinguistics, pages 550?557.P.
Bremaud.
1999.
Markov Chains: Gibbs Fields,Monte Carlo Simulation, and Queues.
Springer-Verlag.G.
Carenini and J. C. K. Cheung.
2008.
Extractivevs.
NLG-based Abstractive Summarization of Eval-uative Text: The Effect of Corpus Controversiality.101In Proc.
of the 5th International Natural LanguageGeneration Conference, pages 33?41.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.MaximumLikelihood from Incomplete Data Via theEM Algorithm.
Royal Statistical Society, 39(B):1?38.G.
Erkan and D. Radev.
2004.
LexPageRank: Prestigein Multi-document Text Summarization.
In Proc.
ofthe 2004 Conference on Empirical Methods in Nat-ural Language Processing, pages 365?371.J.
M. Kleinberg.
1999.
Authoritative Sources in a Hy-perlinked Environment.
ACM, 46(5):604?632.C-Y.
Liu and E. H. Hovy.
2003.
Automatic Evalu-ation of Summaries Using N-gram Co-occurrenceStatistics.
In Proc.
of Human Language Technolo-gies: The Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, pages 71?78.Y.
Matsumoto, A. Kitauchi, T. Yamashita, Y. Haruno,O.
Imaichi, and T. Imamura.
1997.
Japanese Mor-phological Analysis System Chasen Mannual.R.
Mihalcea and P. Tarau.
2005.
Language Indepen-dent Extractive Summarization.
In In Proc.
of the43nd Annual Meeting of the Association for Compu-tational Linguistics, pages 49?52.A.
Y. Ng, M. I. Jordan, and Y. Weiss.
2002.
On Spec-tral Clustering: Analysis and an Algorithm, vol-ume 14.
MIT Press.L.
Page, S. Brin, R. Motwani, and T. Winograd.
1998.The Pagerank Citation Ranking: Bringing Order tothe Web.
In Technical report, Stanford Digital Li-braries.X.
Wan and J. Yang.
2008.
Multi-document Sum-marization Using Cluster-based Link Analysis.
InProc.
of the 31st Annual International ACM SIGIRConference on Research and Development in Infor-mation Retrieval, pages 299?306.Z.
Zhang and R. Wang.
2007.
Identification ofOverlapping Community Structure in Complex Net-works using Fuzzy C-means Clustering.
PHYSICA,A(374):483?490.X.
Zhu, A. Goldberg, J. V. Gael, and D. Andrzejew-ski.
2007.
Improving Diversity in Ranking usingAbsorbing Random Walks.
In In Human Languagetechnologies: The Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 97?104.102
