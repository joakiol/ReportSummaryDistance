Proceedings of the SIGDIAL 2013 Conference, pages 457?461,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsDialog State Tracking using Conditional Random FieldsHang Ren, Weiqun Xu, Yan Zhang,Yonghong YanThe Key Laboratory of Speech Acoustics and Content UnderstandingInstitute of Acoustics, Chinese Academy of Sciences21 North 4th Ring West Road, Beijing, China, 100190{renhang, xuweiqun, zhangyan, yanyonghong}@hccl.ioa.ac.cnAbstractThis paper presents our approach to dialogstate tracking for the Dialog State Track-ing Challenge task.
In our approach weuse discriminative general structured con-ditional random fields, instead of tradi-tional generative directed graphic models,to incorporate arbitrary overlapping fea-tures.
Our approach outperforms the sim-ple 1-best tracking approach.1 IntroductionSpoken dialog systems have been widely devel-oped in recent years.
However, when dialogs areconducted in noisy environments or the utteranceitself is noisy, it is difficult for machines to cor-rectly recognize or understand user utterances.
Inthis paper we present a novel dialog state track-ing method, which directly models the joint prob-ability of hypotheses onN -best lists.
Experimentsare then conducted on the DSTC shared corpus,which provides a common dataset and an evalua-tion frameworkThe remainder of this paper is organized as fol-lows.
Section 2 reviews relevant studies in dia-log state tracking.
Section 3 introduces our newapproach and presents the model and features weused in detail.
Section 4 describes experiment set-tings and gives the result.
Section 5 concludes thispaper with a discussion for possible future direc-tions.2 Previous WorkFor the task of dialog state tracking, previousresearch focused on dynamic Bayesian models(DBN)(Young et al 2013).
User goal, dialog his-tory and other variables are modeled in a graphi-cal model.
Usually, Markov assumptions are madeand in each turn the dialog state is dependent onthe ASR outputs and the dialog state of the pre-vious turn.
Dependency on other features, suchas system action, dialog history could be assumedas long as their likelihood is modeled.
For aPOMDP-based dialog model, the state update ruleis as follows:bt+1(st+1) = ?P (ot+1|st+1, at)?stP (st+1|st, at)bt(st) (1)where bt(st) is the belief state at time t, ot+1 is theobservation at time t+ 1, at is the machine action.Thus the dialog states are estimated incrementallyturn by turn.Since each node has hundreds, or even thou-sands, of possible assignments, approximation isnecessary to make efficient computation possible.In POMDP-based dialog systems, two commonapproaches are adopted (Young et al 2013), i.e.,N -best approximation and domain factorization.In theN -best approach, the probability distribu-tion of user goals are approximated using N -bestlist.
The hidden information state (HIS) model(Young et al 2010) makes a further simplificationthat similar user goals are grouped into a singleentity called partition, inside which all user goalsare assigned the same probabilities.
The Bayesianupdate of dialog state (BUDS) model (Thomsonand Young, 2010) is a representative of the secondapproach and adopts a different approximationstrategy, where each node is further divided intosub-nodes for different domain concepts and in-dependence assumptions of sub-nodes across con-cepts are made.
Recent studies have suggestedthat a discriminative model may yield better per-formance than a generative one (Bohus and Rud-nicky, 2006).
In a discriminative model, the emis-sion part of the state update rule is modeled dis-criminatively.
Possible flawed assumptions in acompletely generative models could be mitigated457in this way, such as the approximation of obser-vation probability using SLU scores (Williams,2012a; Williams, 2012b).3 Proposed Method3.1 Discriminative State Tracking ModelMost previous methods model the distribution ofuser goals for each turn explicitly, which can leadto high computation cost.
In our work, the jointprobability of all items on the N -best lists fromSLU is modeled directly and the state tracking re-sult is generated at a post-processing stage.
Thusthe state tracking problem is converted into a la-beling task as is shown in equation 2, which in-volves modeling the joint probability of the N -best hypotheses.bt(st) = P (H1,1, H1,2, ...,Ht,m?1, Ht,m) (2)where Ht,m is a binary variable indicating thetruthfulness of the m-th hypothesis at turn t.For each turn, the model takes into account allthe slots on theN -best lists from the first turn up tothe current one, and those slots predicted to be trueare added to the dialog state.
The graphical modelis illustrated in figure 1.
To predict dialog state atturn t, the N -best items from turn 1 to t are allconsidered.
Hypotheses assigned true labels areincluded in the dialog state.
Compared to the DBNapproach, the dialog states are built ?jointly?.
Thisapproach is reasonable because what the trackergenerates is just some combinations of all N -bestlists in a session, and there is no point guessing be-yond SLU outputs.
We leverage general structuredConditional Random Fields (CRFs) to model theprobabilities of the N -best items, where factorsare used to strengthen local dependency.
SinceCRF is a discriminative model, arbitrary overlap-ping features can be added, which is commonlyconsidered as an advantage over generative mod-els.3.2 Conditional Random FieldsCRF is first introduced to address the problemof label bias in sequence prediction (Lafferty etal., 2001).
Linear-chain CRFs are widely used tosolve common sequence labeling problem in nat-ural language processing.
General structured CRFhas also been reported to be successful in varioustasks (Sutton and McCallum, 2012).In general structured CRF, factor templates areutilized to specify both model structure and pa-...Hyp1Hyp2HypNTurn tSlot1=...Slot2=......Turn t-1Figure 1: Dialog state update using CRFs, wherethe 8 rectangles above denote N -best hypothe-ses for each turn, and the box below representsthe dialog state up to the current turn.
Con-nections between rectangles denote ?Label-Label?factors.
?Label-Observation?
factors are not shownfor simplicity.rameter tying (Sutton and McCallum, 2012).
Fac-tors are partitioned into a series of templates, andfactors inside each template share the same param-eters.p(y|x) = 1Z(x)?Cp?C?
?c?Cp?c(xc,yc; ?p), (3)where C is the set of factor templates and x,y areinputs and labels respectively.
Template factorsare written as?c(xc,yc; ?p) = expK(p)?k=1?pkfpk (xc,yc) (4)and Z(x) is the normalizing functionZ(x) =?y?Cp?C?
?c?Cp?c(xc,yc; ?p) (5)In the experiment we use Factorie1 to define andtrain the model.3.3 Model Structure and FeaturesIn the model, slots in every N -best item upto the current turn are represented as binaryvariables.
For simplification of data structure,each slot in a single N -best item is extractedand represented using different label vari-ables, with the same rank indicating their1Available from https://github.com/factorie/factorie.458original places in the N -best list.
For exam-ple, the item slots: [from: Pittsburgh,data: Tuesday], score: 0.85, rank: 2,is converted to two slots: slots: [from:Pittsburgh], score: 0.85, rank: 2 andslots: [date: Tuesday], score: 0.85,rank: 2.
Label-label connections are specifiedusing factor templates between slot pairs, andLabel-observation templates are used to addslot-wise features.
Without label-label connectionthe model is reduced to a maximum entropymodel, and with more connections added, thegraph tends to have loopy structures.Two classes of feature sets (templates) in the ex-periment are defined as follows.
(1) Label-Label factor templates are used tostrengthen the bond between certain slots.Pairwise-slots of the same rank This template isbuilt for pairs of slots in a turn with the samerank to bind their boolean assignment.
Toavoid creating too many loops and make in-ference efficient, the factors are added in suchan order that the slots involved in a single turnare linked in a linear way.Pairwise-slots with identical value Slots withidentical value may appear in the N -bestlist for multiple times.
Besides, user canmention the same slot in different turns,making these slots more reliable.
Similarordering mechanism is utilized to avoidredundant loops.
(2) Label-observation templates are used to addfeatures for the identification of the truthfulness ofslots.SLU score and rank of slot The score generatedby the ASR and SLU components is a directindicator of the correctness degree of slots.However, a slot?s true reliability is not neces-sarily linear with its score.
The relationship isquite different for various ASR and SLU al-gorithms, and scores produced by some ASRare not valid probabilities.
As we adopt adata-driven approach, we are able to learnthis relationship from data.
In addition to theSLU score, the slot rank is also added to thefeature set.Dialog history (grounding information) Inmost spoken dialog systems, explicit andimplicit groundings are adapted to indicatethe correctness of the system belief.
Thisinformation is useful to determine thecorrectness of slots.
The grounding infor-mation includes grounding type (implicitor explicit grounding), user reply (negationor confirmation) and corresponding SLUscores.Count of slots with identical value As previ-ously mentioned, slots with identical valuescan appear several times and slots with morefrequent occurrences are more likely to becorrect.Domain-specific features Slots for some domainconcepts often have values with specificforms.
For example, in the DSTC data sets,the route slots are usually filled with valueslike ?61d?, ?35b?, and SLU often generatesnoisy outputs like ?6d?, ?3d?.
Thus the lexi-cal form is a very useful feature.Baseline Tracker The simple and fast 1-besttracking algorithm is used as the baselinetracker and exhibits a satisfying performance.Thus the tracking result is added as an addi-tional feature.
This indicates the possibilityof combining tracking outputs from differ-ent algorithms in this discriminative model,which may improve the overall tracking per-formance.4 Experiment4.1 Task and DataThe Dialog State Tracking Challenge (DSTC)2aims at evaluating dialog state tracking algorithmson shared real-user dialog corpus.
In each dia-log session, ASR and SLU results are annotated,making it possible to conduct direct comparisonamong various algorithms.
For further details,please refer to the DSTC handbook (Williams etal., 2013b).4.2 Corpus PreprocessingThe ASR and SLU components can generate manynoisy hypotheses which are completely wrong,rendering the dialog corpus seriously imbalancedat the level of slots (there are more wrong slotsthan true slots).
We use resampling to prevent2http://research.microsoft.com/en-us/events/dstc/459the model from biasing towards making negativejudgements.
Before training, the total number ofcorrect slots in a set is counted, and equal num-ber of wrong slots are sampled from the subset ofall the wrong slots.
These chosen negative slotsplus all the positive slots together constitute theeffective slot set for model training, with remain-ing slots fixed to their true value and regarded asobserved variables.
To make full use of the dia-log corpus, this process is repeated for eight times,producing a bigger and balanced corpus.4.3 Model TrainingIn the training phase, the log-likelihood functionis optimized using the LBFGS method with L2-regularization.
Loopy belief propagation is usedas the inference routine.
It can be shown that forfactor graphs without loops, the marginal proba-bilities produced by loopy belief propagation areexact.
Model selection is done according to thelog-likelihood on the development set.4.4 Predicting and TrackingFor each dialog session, the predicted slot labelsare mapped to tracking results.
To produce a N -best list of tracking results, the top N configura-tions of slots and corresponding probability scoresare generated.
Gibbs sampling is adopted.
Thesampling is repeated for 1000 times in each cor-pus, after each sampling the configuration of slotsis mapped to certain tracking state.
More efficientinference routines, such as M-best belief propaga-tion (Yanover and Weiss, 2004), could be utilized,which would be suitable for practical real-time ap-plication.4.5 ResultsAfter tracker outputs are generated based on thesampling results, they are scored using evaluationtools provided by the DSTC organizers.
Severalmetrics are evaluated, including precisions, ROCperformance, etc.
Individual and joint slots arescored respectively.
And different schedules areused, which indicats the turns included for evalu-ation.
Partial results are shown in table 1.
A sys-tematic analysis by the organizers is in the DSTCoverview paper (Williams et al 2013a).
The com-plete challenge results can be found on DSTCwebsite.
On the test sets of test1, test2 and test3,the CRF-based model achieves better performancethan the simple baseline in most metrics.
How-ever, on test4, the performance degrades seriouslywhen there is a mismatch between training dataand test data, since test4 is produced by a differentgroup and does not match the training set.
It showsthat the CRF-based model is very flexible and isable to learn the properties of ASR and SLU, thusadapting to a specific system.
But it has a tendencyof overfitting .Test1 Test4Metric CRF BASE CRF BASEACC 0.987 0.983 0.960 0.986L2 0.020 0.021 0.046 0.017MRR 0.990 0.988 0.980 0.990CA05 0.987 0.983 0.960 0.986EER 0.015 0.983 0.021 0.012Table 1: Results of slot ?Date?
on Test1 and Test4(schedule1 is used).
The tracker used on Test4 istrained on Test3.
Details of the metrics can befound in DSTC handbook(Williams et al 2013b)5 Conclusions and Future DirectionsWe proposed a CRF-based discriminative ap-proach for dialog state tracking.
Preliminary re-sults show that it achieves better performance thanthe 1-best baseline tracker in most metrics whenthe training set and testing set match.
This indi-cates the feasibility of our approach which directlymodels joint probabilities of the N -best items.In the future, we will focus on the followingpossible directions to improve the performance.Firstly, we will enrich the feature set and add moredomain-related features.
Secondly, interactions ofslots between dialog turns are not well modeledcurrently.
This problem can be alleviated by tun-ing graph structures, which deservers further stud-ies.
Moreover, it is challenging to use online train-ing methods, so that the performance could be im-proved incrementally when more training samplesare available.6 AcknowledgmentsThis work is partially supported by the Na-tional Natural Science Foundation of China (Nos.10925419, 90920302, 61072124, 11074275,11161140319, 91120001), the Strategic Prior-ity Research Program of the Chinese Academyof Sciences (Grant Nos.
XDA06030100,XDA06030500), the National 863 Program (No.2012AA012503) and the CAS Priority Deploy-ment Project (No.
KGZD-EW-103-2).460ReferencesDan Bohus and Alex Rudnicky.
2006.
A ?k hypotheses+ other?
belief updating model.
In Proceedings ofthe 2006 AAAI Workshop on Statistical and Empiri-cal Approaches for Spoken Dialogue Systems, pages13?18, Menlo Park, California.
The AAAI Press.John Lafferty, Andrew Mccallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proc.
18th International Conf.
onMachine Learning, pages 282?289.
Morgan Kauf-mann, San Francisco, CA.Charles A. Sutton and Andrew McCallum.
2012.
Anintroduction to conditional random fields.
Founda-tions and Trends in Machine Learning, 4(4):267?373.Blaise Thomson and Steve Young.
2010.
Bayesianupdate of dialogue state: A POMDP framework forspoken dialogue systems.
Computer Speech andLanguage, 24(4):562?588.Jason D. Williams, Antoine Raux, Deepak Ramachan-dran, and Alan Black.
2013a.
The dialog state track-ing challenge.
In Proceedings of the 14th SIGdialworkshop on Discourse and Dialogue.Jason D. Williams, Antoine Raux, Deepak Ra-machandran, and Alan Black.
2013b.
Dia-log state tracking challenge handbook.
Avail-able from http://research.microsoft.com/apps/pubs/?id=169024.Jason D. Williams.
2012a.
Challenges and opportu-nities for state tracking in statistical spoken dialogsystems: Results from two public deployments.
Se-lected Topics in Signal Processing, IEEE Journal of,6(8):959 ?970.Jason D. Williams.
2012b.
A critical analysis of twostatistical spoken dialog systems in public use.
InSLT, pages 55?60.
IEEE.Chen Yanover and Yair Weiss.
2004.
Finding them most probable configurations using loopy beliefpropagation.
Advances in Neural Information Pro-cessing Systems, 16:289?296.Steve Young, Milica Gas?ic?, Simon Keizer, Franc?oisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2010.
The hidden information state model:A practical framework for POMDP-based spoken di-alogue management.
Computer Speech and Lan-guage, 24(2):150?174.Steve Young, Milica Gas?ic?, Blaise Thomson, and Ja-son D. Williams.
2013.
POMDP-based statisticalspoken dialog systems: A review.
Proceedings ofthe IEEE, 101(5):1160?1179.461
