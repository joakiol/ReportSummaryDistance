I ncorporat ing  "Unconsc ious  Reana lys i s "  into  an Incrementa l ,Monoton ic  ParserPatrick Sturt*Centre for Cognitive ScienceEdinburghUKsturt@cogsci.ed.ac.ukAbstractThis paper describes the author's imple-mentation of a parser aimed at repro-ducing, in a computationally explicit sys-tem, the constraints of a particular psy-cholinguistic model (Gorrell in press).
InGorrell's model, "unconscious" gardenpaths may be processed via the additionof structural relations to a monotone in-creasing set at the point of disambigua-tion, but there is no discussion as to howthe parser decides which relations to add.We model this decision as a search for anode in the tree at which an explicitlydefined parsing operation, tree-loweringmay be applied.
With reference to En-glish and Japanese processing data, weshow the importance of this search forempirical adequacy of the psycholinguis-tic model.1 Conscious and UnconsciousGarden PathsCertain researchers in the psycholinguistic com-munity (Pritchett (1992), Gorrell (in press)), haveargued for a binary distinction between two dis-tinct types of garden path sentences.
Consciousgarden paths, such as (1) below, are locally am-biguous sentences which give rise to reanalysisthat is both experimentally detectable and causesa conscious ensation of difficulty or "surprise ef-fect".
Unconscious garden paths, on the otherhand, such as (2), cause reanalysis which is exper-imentally detectable, but which is generally not"noticed" by the speaker or hearer.
*The work reported here was done very much in acollaborative spirit with my supervisor, Dr. MatthewCrocker, and thanks are due to him for innumerablesuggestions and ideas.
I would also like to thank thepeople who have offered insightful comments on thiswork, in particular, David Milward and Martin Pick-ering.
The research was supported by ESRC grantR00429334338(1) While John was eating the ice cream mel ted .
(2) John knows the truth hurts .This binary distinction has often been used to mo-tivate a two-level architecture in the human syn-tactic processing system, where what we will callthe "core parser" performs tandard attachment,as well as being able to reanalyse in the easy cases(such as on reaching hurts in (2)), but where theassistance of a higher level resolver(to use Abney'sterminology (1987, 1989)), is required to solvethe difficult cases, (such as on reaching melted in(1)).
This "core parser" has been the subject ofa number of computational implementations, in-cluding Marcus's deterministic parser (1980), De-scription theory (henceforth, D-theory) (Marcuset al(1983)), and Abney's licensing based model(1987, 1989).
It has also been the subject of anumber of psycholinguistic studies on a more the-oretical level (Pritchett (1992), Gorrell (in press)).The implementation described in this paper isbased on the most recent model, that of (Gorrell(in press)).
This model is interesting in that itdoes not allow the parser to employ delay tactics,such as using a lookahead buffer (Marcus (1980),Marcus et al(1983)), or waiting for the head ofa phrase to appear in the input before construct-ing that phrase (Abney (1987, 1989), Pritehett(1992)).
Instead, processing is guided by the prin-ciple of Incremental Licensing, which states that"the parser attempts incrementally to satisfy theprinciples of grammar".
For the purposes of thisimplementation, I have interpreted this to meanthat each word must be attached into a fully-connected phrase marker as it is found in theinput.
1 The psychological desirability of such a1In fact, GorreU conjectures that, where there isinsufficient grammatical information to postulate astructural relation between two constituents, uch asin a sequence of two non-case marked NPs in an En-glish centre-embedded construction, the parser mayhold these constituents unstructured in its memory(in press, p.212).
However, for the purposes of thisimplementation, we have taken the most constrainedposition.
Note that, since we do not deal with such291Full Attachment model has been argued for, es-pecially with regard to the processing of head-final languages, where evidence has been foundof pre-head structuring (Inoue & Fodor (1991),Frazier (1987)).
Such models have also been ex-plored computationally (Milward (1995), Crocker(1991)).2 D-theory and Gorrell 's ModelGorrell employs the D-theoretic device of buildingup a set of dominance and precedence relations 2between nodes, where the set is intended tobe constrained by informational monotonicity, inthat once asserted to the set, no relation may bedeleted or overridden.
Gorrell restricts this con-straint to Primary structural relations (i.e.
domi-nance and precedence), while secondary relations(e.g.
thematic and case dependencies) are not soconstrained.
Recall (2), repeated below:(2) John knows the truth hurts.At the point where John knows the truth has beenprocessed, a complete clause will have been built:(3) Is \[NP1 John\] \[vP Iv knows\] \[NP2 the truth\]\]The description will include the information thatthe verb knows precedes ~IP2, and that the VP dora- .inates NP2.
{...,prec(V,NP2), dom(VP, NP2), ...}However, on the subsequent input of hurts, thestructure can be reanalysed by asserting an extraclausal node (call it S~) dominating NP2 (whichwill then become the embedded subject), butwhich is in turn dominated by the matrix VP.
Thiscan be achieved by adding the following struc-tural relations to the tree description {prec(V,S2),dom(VP,S2), dom(S2,NP2)}(4).
Is \[NP, John\] \[vP Iv knows\] \[s~ \[Ni% thetruth\] \[vP~ hurts\]\]\]\]Since the description before the processing of thedisambiguating word hurts is a subset of the finaltree description, the monotonicity requirement issatisfied.
Note in particular, that, because domi-nance is a transitive relation, and because of theinheritance condition on trees (a node inheritsthe precedence relations of its ancestors3), thetwo statements dom(VP, NP2) and prec (V, lips) re-main true after reanalysis.
4constructions, none of the arguments presented herehinge on whether or not the parser may buffer mate-rial in this way.2The original D-theory model did not computeprecedence relations, except between terminal nodes.3See Partee et al(1993) for a description of theconditions on trees, with which all tree descriptionsmust comply.q t  will be noticed that the reanalysis here involvesNote also that the model will correctly fail to re-analyse for sentence (1) above, since the reanalysiswill require the retraction of the domination rela-tion between the VP of the adverbial clause andthe NP the ice cream.3 Implementat ionAlthough Gorrell proposes a general principle toguide initial attachment decisions (Simplicity: Novacuous structure building), and specifies the con-ditions under which "unconscious reanalysis" mayoccur, the model leaves unspecified the problemof how the-system ay be implemented.
Of par-ticular interest is the problem of how the parserdecides which relations to add to the set at eachpoint in time, especially at disambiguating points.3.1 Lexical  Representat ionThe basic framework on which the implementa-tion is built is similar to Tree Adjoining Gram-mar (Joshi et al1975).
Each lexical category isassociated with a set of structural relations, whichdetermine its lexical subtree.
We call this set thesubtree projection of that lexical category.
For ex-ample, the subtree projection for verbs in the En-glish grammar is as follows, where Lex is a variablewhich will be instantiated to the actual verb foundin the input.
{dom(S,NP), dom(S,VP), dom(VP,V),dom(V,Lex), prec(NP,VP) }Lexical categories are also associated with lists ofleft and right attachment sites.
In the above case,NP, (which will correspond to the subject of theverb), will be unified with the left attachment site.If a transitive verb is found in the input, then theparser consults the verb's argument structure andcreates a new right attachment site for an NP,asserting also that this new NP is dominated byVP and preceded by V.3.2 At tachmentSimple attachment can be performed in two ways,which are defined below, where the term currenttree description is intended to denote the the setof structural relations built up to that point inprocessing:Intuitively, left attachment may be thought of interms of attaching the current ree description tothe left corner of the projection of the new word,while right attachment corresponds to attachingthe projection of the new word to the right cornera realignment of thematic and, on GB assumptions,case dependencies.
These are examples of what Gor-rell calls secondary relations, which are not subject othe monotonicity requirement.292of the current tree description.
They are equiva-lent to Abney's Attach-L and Attach respectively.DEFINITION Left  A t tachment :Let D be the current tree description, with rootnode R. Let S be the subtree projection of thenew word, whose left-most attachment site, A isof identical syntactic ategory as R. The updatedtree description is S LJ D, where A is unified withR.DEFINITION R ight  At tachment :Let D be the current tree description, with thefirst right attachment site A.
Let S be the sub-tree projection of the new word, whose root R isof identical syntactic ategory as A.
The updatedtree description is S tA D, where A is unified withR.3.3 T ree  Lower ingIt should be clear that, while simple left and rightattachment will suffice for attaching argumentswithout reanalysis, it will not allow us to de-rive the reanalysis required in example (2).
Forthis, we intuitively require some means of insert-ing one tree description inside another.
Schemat~ically, what we require is illustrated below, where\[1\] is intended to represent the current tree de-scription built up after John knows the truth hasbeen parsed, and \[2\] is intended to represent thesubtree description of the new word hurts.\[i\] \[2\]S/ \NP VP/ \V NP/ kD NS+ / \ ==>NP VPr33s/ \NP VP/ \V S/ \NP VP/ \D NWe will call this operation "tree-lowering".
In-tuitively, the operation finds a node on the cur-rent trec description which matches the left at-tachment site of the projection of the new word,and attaches it, while inserting the root of the newprojection in its place.
The result is that the nodechosen is "lowered" or "subordinated".In order to maintain structural coherence, the newword attached via tree-lowering must be precededby all other words previously attached into thedescription.
We can guarantee this by requiringthe lowered node to dominate the last word to beattached.
We also need to ensure that, to avoidcrossing branches, the lowered node does not dom-inate any unsaturated attachment sites (or "dan-gling nodes") We therefore define accessibility fortree-lowering as follows:DEFINITION Accessibility:Let N be a node in the current tree description.Let W be the last word to be attached into thetree.N is accessible iff N dominates W, and N does notdominate any unsaturated attachment sites.DEFINITION Tree- lower ing:Let D be the current tree description.
Let S bethe subtree projection of the new word.
The leftattachment site A of Smust match a node N acces-sible in D. The root node R of S must be licensedby the grammar in the position occupied by N.Let L be the set of local relations in which N par-ticipates.
Let M be the result of substituting allinstances of N in L with R. The attachment nodeA is unified with AT.The updated tree-description is D U S U M sIt will be noticed that tree-lowering is similar inspirit to the adjunction operation of Tree Adjoin-ing Grammars (Joshi et al 1975).
The differenceis that the foot and root nodes of an auxiliary treein TAG, (corresponding to the "lowered" node andthe node that replaces it respectively) must be ofthe same syntactic ategory, whereas, as we haveseen in this example, in the model proposed here,the two nodes may be of different categories, solong as the resulting structure is licensed by thegrammar.In the case of example (2), at the point where thetruth has been processed, the parser must find anaccessible node which matches the category of theleft attachment site of hurts (i.e.
an NP).
Theonly choice is NP~:(3) \[s \[NP1 John\] \[vv \[v knows\] \[NP~ the truth\]\]NOw, all the local relations in which NP2 partici-pates are found:{dora(VP,NP2), prec(V,NP~) }and NP2 is substituted with the root of the newprojection, $2 to derive two new relations:{dom(VP, $2), prec(V, $2)}These relations are found to be licensed, becausethe verb which V dominates ("knows") may sub-categorise for a clause, so these new relations areadded to the set 6.
Now, adding the subtree pro-jection of hurts to the set, and unifying its leftSNote that Abney's STEAL operation (1987, 1989)is more powerful than tree-lowering, since it maychange domination relations, and thus will allow sen-tences such as (1), though it excludes reduced rela-tive garden paths, such as The horse raced past thebarn fell.
The original D-theory model (Marcus et al(1983)) is also more powerful, because it allows theright-most daughter of a node to be lowered under asibling node.eNote that the relations defining the original posi-tion of NP2, (i.e.
dom(l/P,NP2) and prec(V,NP2)) arenot subtracted from the set.293attachment site with NP2 results in the derivedstructure with NP~ "subordinated" into the lowerclause.Is \[NP~ John\] \[vp Iv knows\] Is2 \[gP2 the truth\]\[vP~ hurts\]\]\]\]With the tree-lowering operation so defined, theproblem of finding which relations to add to theset at a disambiguating point reduces to a searchfor an accessible node at which to apply this oper-ation.
However, this implies that, if more than onesuch node exists, the parser must be given a pref-erence for making the requisite decision.
Considerthe following sentence fragment, for example:(5) I know \[NP1 the man who believes \[NP2 thecountess\]\]...If the input subsequently continues with a verb,then we have a choice of two nodes for lower-ing, i.e.
NP1 and l~P2.
Though no experimentalwork has been done on this type of sentence, thereseems to be an intuitive preference for the lowerattachment site, NP2.
In (6), binding constraintsforce lowering to be applied at NP2, while in (7), itmust be applied at NP1.
Of the two, most nativeEnglish speakers report (6) to be easier.
(6) I know the man who believes the countesskilled herself.
(7) I know the man who believes the countesskilled himself.Note also, that, on standard X-bar assumptions,the attachment of post-modifiers may be derivedvia lowering at an X I node.
In this case, the low-ered node and its replacement will be of the samesyntactic ategory (like the root and foot node ofa TAG auxiliary tree).
Researchers have noteda general preference for low attachment of post-modifiers (this is accounted for by the principleof late closure (Frazier and Rayner, 1982)).
Thiswould suggest hat a reasonable search strategyfor English would be to search the set of accessi-ble node in a bottom-up direction for English.The algorithm is constructed in such a way thatlowering is only attempted in cases where sim-ple attachment fails.
This means that arguments(which are incorporated via simple attachment)will be attached preferentially to adjuncts (whichare incorporated via lowering).
This captures thegeneral preference for argument over adjunct at-tachment, which is accounted for by the princi-ple of Minimal attachment in Frazier and Rayner(1982), and by the principle of simplicity in Got-tell (in press).4 Processing Japanese4.1 Ma in /subord lnate  clause ambiguityJapanese presents a challenge for any incrementalparsing model because, typically, it is not possibleto determine where an embedded clause begins.Consider the following example:(8) John ga \[Oi ronbun wo kaita\] seitoi wo hometa.John NOM essay ACC wrote student ACC praised"John praised the student who wrote the essay"Up to the first verb kaiia ("wrote"), the stringis interpretable as a full clause (without a gap),meaning '~John wrote an essay", and the incre-mental parser builds the requisite structure.
How-ever, the appearance of the head noun seito (stu-dent) means that at least part of the precedingclause must be reinterpreted as a relative clauseincluding agap (note that there is no overt relativepronoun in Japanese).
One way of looking at whatis happening here is to see the subject NP Johnga as being dissociated from the clause in whichit is originally attached, and reattached into themain clause.
But looking at it from a differentperspective, as Gorrell has noted (in press), onecan see the subject NP as remaining in the mainclause, and the constituent bracketed in (8), (ton-bun wo kaita ("wrote an essay")) as being loweredinto the relative clause.
If this is possible, then wewould expect examples like (8) to be unconsciousgarden paths, and this does indeed seem to be re-flected in the intuitive data (see Mazuka and Itoh(in press)).
However, if we are to allow our parserto handle such examples, we must expand the def-inition of tree-lowering, since, in order to build arelative clause, we have to assert extra material(including the empty subject and the new S node),which is not justified solely by the lexical require-ments of the disambiguating word, the head nounseito.
This involves reconstructing all the clausalstructure dominating the lowering site (includingasserting empty argument positions), with refer-ence to the verb's case frame, and attempting toattach the result as a relative clause to the headnoun.4.2 M in ima l  Expuls ionInoue (1991), describes a "minimal expulsionstrategy", which predicts a preference, on reanal-ysis, towards expelling the minimum amount ofmaterial from the clause.
In our terms, this meansthat (assuming a binary right-branching clausestructure, with the verb in its right corner) thenode selected for lowering must be as high aspossible.
This means that the bottom-up searchwhich we use for English will wrongly predicta Maximal expulsion strategy.
In cases such as(8), assuming the bottom-up search, when a post-clausal noun has been reached in the input, the294parser starts its search from the node immediatelydominating the last word to be incorporated, (i.e.the verb of what will become the relative clause).This means that, in cases such as (8), the firstpreference will be to lower the verb (and therefore"expel" both subject and object), whereas the hu-man preference, (to lower the object and verb, andtherefore xpel only the subject) is the parser'ssecond choice on the bottom-up search strategy.Mazuka and Itoh (in press) note that exampleswhere both subject and object must be expelledfrom the relative clause, as would be the firstchoice in a bottom-up search, often cause a con-scious garden path effect.
An example, adaptedfrom Mazuka and Itoh is the following:(9) Yamasita ga yuuzin wo \[O Oi houmonsita\]kaisyai de mikaketa.Yamasita NOM friend ACC visited companyLOC saw"Yamasita saw his friend at the company he vis-ited.
"In order to capture the minimal expulsion strat-egy in this class of Japanese examples, therefore,search for the lowering node should be conductedtop-down.
We are currently investigating the con-sequences of changing the search strategy in thisway.5 The  Prob lem o f  Ret rospect iveReana lys i sHaving formulated the constraints of Gorrell'smodel in terms of the accessibility of a node for~ree-lowering, we can see that the model can befalsified if we can find a case where the relevantdisambiguating information comes at a point inprocessing where the node which is required tobe lowered is no longer accessible.
Consider thefollowing pair of sentences:(10) I saw the man with the moustache.
(11) I saw the man with the telescope.It is familiar from the psycholinguistic literaturethat there is a preference for attaching the withphrase as an instrumental argument of the verb(as in (11), on the reading where the telescopeis the instrument of seeing).
On the assumptionthat saw selects for a PP instrumental rgument,we can derive this preference in the present modelvia the preference to attach as an argument as op-posed to an adjunct.
However, since we are con-strained by incrementality, we will have to makean attachment decision for the PP as soon as thepreposition with is encountered, and it will be at-tached in the preferred reading as a sister of theverb.
This means that, in cases such as (10),where, on the globally acceptable reading, the PPis an adjunct of the NP the man, this attachmentwill have to be revised, and the PP retrospectivelyadjoined into the relevant N t node.
However, oncethe preposition with has been attached, the re-quired N' node will no longer be accessible, anda conscious garden path effect will be predicted,which, intuitively, does not occur.
Note that thereis no garden path effect even if the preposition isseparated from the disambiguating head noun by aseries of adjectives: ("I saw the man with the neat,quaint, old-fashioned moustache/telescope").The same result obtains if we abstract away fromthe particular implementational details of tree-lowering, and return to the abstract level at whichGorrell states his model.
Once the PP has beenattached as an argument of the verb, it can neverbe reanalysed as the adjunct of the preceding NP,because the NP will precede the PP before re-analysis, and dominate it after reanalysis, whichis against he "exclusivity condition" on trees (i.e.no two nodes may stand in both a dominance anda precedence r lation).
7A similar problem concerns examples uch as thefollowing, from Gibson et al(1993):(12) the lamps near the\[that was damaged in the(13) the lamps near thepaintings of the houseflood\].painting of the houses\[that was damaged in the flood\].
(14) the lamp near the paintings of the houses\[that was damaged in the flood\].in the above, Gibson et alhave manipulated num-ber agreement to force low (12), middle (13) andhigh (14) attachment of the bracketed relativeclause.
The results of their on- and off-line ex-periments how clearly that the low attachment(corresponding to 12) is easiest, but the middleattachment (corresponding to (13)) is most diffi-cult.
This behaviour cannot be captured whetherwe adopt a bottom-up or a top-down search fortree-lowering.
However, even if we can incorpo-rate the required preferences into the parser, theconstraint of incrementality will force us to makethe decision on encountering that.
This meansthat, assuming we decide initially to attach low,but number agreement on was subsequently forceshigh attachment, as in (14), then a conscious gar-den path effect will be predicted, as lowering can-not derive the reanalysis.
This is true on the ab-stract level as well, since there will be nodes inthe description which precede the original ow po-sition of the relative clause, but are dominated bythe subsequent high position of the relative clause.ZNote that in Marcus et al(1983), since precedencerelations were not computed for non-terminals, lower-ing into a predecessor was possible, thus (11) wouldcause no processing difficulty.
However, presumably,their parser would overgenerate on examples uch asthe horse raced past the barn fell.295However, intuitively, of the above sentences, it isonly (13) which causes the conscious garden patheffect.S6 Conc lus ionThe current implementation shows that the suc-cess of an abstract model such as Gorrell's de-pends crucially on the computational details ofthe processing algorithm used.
The search for thelowering site is of particular importance.
In thefinal section we have seen that the combination ofinformational monotonicity with the assumptionof strict incrementality results in a system whichis too constrained to capture all the processingdata.
Future research will be aimed at determin-ing, firstly, how we can enrich the information towhich the search strategy is sensitive in order toprovide a better match with human preferences,and secondly, which constraints should be relaxedin order to avoid the problem of undergeneration.Re ferencesAbney, S. P. (1987): Licensing'and Parsing.
Pro-ceedings of NELS 17 p.l-15, University of Mas-sachusetts, AmherstAbney, S. P. (1989): A computational model ofhuman parsing.
Journal of Psycholinguistic Re-search 18 p.129-144Crocker, M. W. (1991): A Logical Model of Com-petence and Performance in the Human SentenceProcessor.
PhD thesis, Dept.
of Artificial Intelli-gence, University of Edinburgh, Edinburgh, U.K.Frazier, L. (1987): Syntactic processing: Evidencefrom Dutch.
In Natural Language and LinguisticTheory 5.4 p.519-559Frazier, L. and K. Rayner, (1982): Making andcorrecting errors during sentence comprehension:Eye movements in the anMysis of structurallyambiguous entences.
Cognitive Psychology 14p.178-210Spreliminary findings suggest hat a similar pref-erence rating is employed in (written) production aswell as (reading) comprehension for these examples.This can be seen in Gibson et als (1994) study.
Thisshows a the LOW> HIGH > MID ordering in the at-tachment of the final PP in NPs of the following formfound in the Brown corpus:NP1 Prep NP2 Prep NP3 PPOf 105 unambiguous PP adjunct attachments, 68%were low-attached, 26% high attached and 10% mid-attached.
However, the question of whether the syn-tactic structures people preferentially use in produc-tion should correspond to the syntactic structurespeople preferentially assign to strings during compre-hension is still very much an open issue, though seeMitchell and Cuetos (1991) for a view that the expe-rience of previous input influences parsing decisions.Gibson, E., N. Pearlmutter, E. Canesco-Gonzalezand Greg Hickok (1993): Cross-linguistic Attach-ment Preferences: Evidence from English andSpanish.
(ms. submitted to Cognition)Gibson, E. and N. Pearlmutter, E. (1994): Acorpus-based account of Psycholinguistic Con-straints on Prepositional Phrase Attachment (inC. Clifton, L. Frazier and K. Rayner (eds)Perspectives on Sentence Processing New York:Lawrence ErlbaumGorrell, P. (in press): Syntax and Perception.
tobe published by Cambridge University PressInoue, A.
(1991): A comparative study of parsingin English and Japanese.
PhD thesis, Universityof Conneticut.Inoue, A. and J.D.
Fodor (in press): Information-paced parsing of Japanese.
(to appear in Mazuka~; Nagai (eds))Joshi, A.K., L.S.
Levy, and M. Takahashi, (1975):Tree Adjunct grammars.
Journal of Computerand System Sciences 10, p.136-163Marcus, M. (1980): A Theory of Syntactic Recog-nition for Natural Language Cambridge, MA:MIT PressMarcus, M., D. Hindle, and M. Fleck (1983): D-theory: Talking about talking about trees.
As-sociation for Computational Linguistics 21 p.129-136Mazuka, R. and K. Itoh (in press): Can Japanesebe led down the garden path?
(to appear inMazuka and Nagai)Mazuka, R., and Nagai (eds) ( to  appear):Japanese Syntactic Processing Hillsdale, NJ:Lawrence EarlbaumMilward, D. (1995): Incremental Interpretationof Categorial Grammar.
in Proceedings of EA CL(this volume)Mitchell, D.C. & Cuetos, F. (1991): The origins ofparsing strategies.
Conference proceedings: Cur-rent issues in natural anguage processing Univer-sity of Texas at Austin, TXPartee, B., A. ter Meulen and R. E. Wall (1993):Mathematical methods in Linguistics Dordrecht:Kluwer Academic PublishersPritchett, B. L. (1992): Grammatical Competenceand Parsing Performance.
Chicago, IL: Univer-sity of Chicago Press296.
