Distributing and Porting General Linguistic ToolsDamien Genthial, Jacques Courtin and Jacques Men6zoTRILAN-CLIPS, IMAG-Campus, BP 53F-38040 GRENOBLE Cedex, FRANCE{ Damien.Genthial J cques.Courtin Jacques.Menezo }@imag.frAbstractOur main motivation is to build generaland adaptable linguistic tools and wehave faced the problem of theirportability.
We first make a quick de-scription of the linguistic tools we haveat hand and we explain why linguistictools, unlike other software tools, presentpmticular portability problems.
We thendiscuss code portability and also dataportability and we describe the methodwe have used for a French lexicon,showing that portability leads to a more"natural" computational lexicon.
Wethen propose the use of a commandlanguage to interface the tools with morecomplex applications and we show thatthis technique facilitates integration oftools from various sources, entails abetter exploitation of linguistic resourcesand makes easier the distribution of toolson several machines.1.
IntroductionOur main motivation is to build general andadaptable linguistic tools and we have filcedthe problem of portability of these tools.
Theproblem has raised sharply when we decided toimplement a distributed version of the tools.The idea is to have bricks to build complexlinguistic systems and to make possible, andeasy, communication between bricks.
We havethree points in mind:?
integration of tools lYom various sources:the linguistic system must not know thedetails of the interred architecture of thetools it uses, so it should be easier tosubstitute one tool by another (for exampleyou can easily change the morphologicalparser);?
better exploitation of linguistic resources byembedding them in very general tools;?
possibility of a distribution on severalmachines of a net, allowing tools to beshared by several users (and thus the costcan also be shared).After a quick description of the tools weimve at hand, we will explain why linguistictools, unlike other software tools, presentparticular portability problems.
We will thendiscuss the user interface portability and wewill propose a simple method which, makingthis portability easier, is also a good waytowards distr ibuted tools and easycommunication between them.2.
Linguistic tools at hand andmotivationWe have a complete morphological systembased on a general finite state transducer.
Itsmain characteristics are its reversibility (thesame data are used for parsing and generating)and its adaptability (the system includes editorswhich permit easy and interactive modificationof the data).
This system is operational on PCand Macintosh architecture with a real sizeFrench lexicon, but switching from onearchitecture to the other is a painful process,mainly because switching the system alsoimplies switching the lexicon (see next:section).We also have three lexical correctors: onebased on similarity keys, another on phoneticsand a third, more original, which correctflexional errors in French.
All these tools areoperational on PC architecture only.Finally, we have two syntactic parsers whichbuild dependency structures.
One is based onthe notion of dependency relations and is veryfast but has a limited power of expression.
Theother uses typed-feature structures to increasethis power but pay the bill with slower parses.Both works on PC and Macintosh.The interesting point comes when we de-cided to make all these tools available on Unixsystems.
The goal is to gain flexibility andpower by a distribution of the linguistic toolsin a client/server architecture.
With such anarchitecture, tools are more easy to use and aresharable among applications.
For example, asproposed by (Genthial ,  1994) aphonetic/graphic transducer which implementsa lexical correction, can also be used in asyntactic corrector to determine the mostprobable correction.
Tools can also bedispatched on difl)rent machines, such thatone can, for example, write on his PC or Macand use the linguistic tools of a Unix server.So the problem to solve looks like a soft-ware engineering one: we have a lot of code,1053written in different programming languages ontwo different machines, and we want toimplement it on a new architecture.
But wehave add a more heavy constraint: we want thatcode and data obtained on the new architecture(Unix) can easily - -  by easily we mean in onlya few minutes - -  be put back on the other ones(Mac and PC).3.
Code and data portabilityCode portability is not specific to computa-tional linguistics, it is a well known problem inthe software engineering domain, but im-plementing a linguistic application means alsoimplementing an important amount of dataand thus raise the problem of data portability.Considering morphological level for example,implies coding a lexicon including words withtheir  category,  their morpho log ica lproperties ....
Categories and properties aresymbols chosen by the linguist and he can?
always choose symbols which can be expressedin the same way on different machines, andthus be portable.
But words are characterstrings, coded with the character set of themachine used and so the portability of theword list rely upon the portability of thischaracter set.
The ASCII character set, which isthe basic set on almost every machine, is fullyportable but it does not contain every characterof every natural anguage: using the Frenchor a~ or q implies the use of an extendedcharacter set which is not portable.After a small discussion on code portability,we will present a method to achieve dataportability.3.1.
CodeCode portability is heavily tied with theprogramming language used for writing pro-grams: the more portable is the language, themore portable is the code.
That is the reasonwhy we had chosen the Pascal programminglanguage in the early 70's : the language waswell defined and we used only the standardfeatures.
But the language has evolved and theevolution leads to incompatibility betweenversions.On the contrary, the C language has beenstandardised in 1989 by the ANSI and we cannow speak of a real portability of code fromone architecture to another.
We have thenchosen to use C and the biggest part ofrewriting Pascal units to C modules has beenachieved by a Pascal to C translator.But one problem remains: we want to putback the C translation on the original machinewith minimal work, and the original codeincludes a user interface with pull-down menusand dialogues which are impossible to translateas is.
So we have made an effort to cut the Cversion in two parts:?
the user interface, which is heavily un-portable and must be rewritten on everymachine (see section 4 for a discussion oninterface portability);?
the tool kemels, written in strict ANSI-C.Thanks to the language standard, thekernels (about 8000 lines of code) have beencompiled, without changing even a comma, onMacintosh, PC and two different Unixmachines.3.2.
DataTwo kinds of data may be used in linguisticapplications: textual data and binary data.Most of them are textual because they caneasily be printed, displayed and modified withthe standard tools of the host system.
Butsometimes you need to compile data to gainefficiency: the application becomes faster anduse less disk space.Binary data in linguistic applications are forexample integers, bit vectors coding properties,floating-point numbers coding statistics and soon.
Their portability is not a real problembecause one can easily translate them in textualform on the original machine, put this form onthe target machine, and compile them back.As said before, portability of textual datarely upon portability of the character set, sousing ASCII set ensures a great portability butforbids writing special characters.
Such specialcharacters are all French accented letters (d, 4,~, d, ~ .... ) which can be coded (and typed) onevery machine but the codes are different fromone machine to another.
Moreover, all specialcharacter codes are above the ASCII maximalcode and this entails a disturbing side effect:when sorting words of a lexicon you get alwords starting with an accented letter at the endof the list (see example on Figure 1).errerouioutreoui"event6rudit8terFigure 1 : Sorted accented strings on a PCWhen the lexicon is big enough, the word~rudit is far from errer, which is computa-tionally sounded but unacceptable for thecommon user.We have then defined an internal code forspecial characters based on the ASCIIcharacter set.
The code is a reduced version ofone defined by GETA in (Boitet, 1982) anaccented letter is coded with the letter without1054accent, a vertical bar, and a number cor-responding to the accent (see examples onFigure 2) I.---> a12a---> a136--> ell--~ el2---> el3Figure 2 ?
Examples of the code for accentedcharactersAll textual data are then completelyportable provided that source and targetmachines use ASCII.
But there are twodrawbacks: you can not ask the user to learnthis code and .you can not use the standardstring comparing functions.
For the firstproblem, we simply write two procedures: onefor reading strings and one for writing.
Theirpurpose is to translate from one representationto the other such that the user has no need toknow the internal code: he can type specialletters as usual on his keyboard.
For thesecond, the solution is to write our owncomparing function, which is not so difficultand have an advantage: we can implement a"natural" order on words (the order used inpaper dictionaries).
We then obtain a humansounded order which can also have acomputat ional  advantage in correct ionsystems.
Consider for example the four Frenchwords cote, cote, cotd and cOtO: their proximityin the lexicon is a guarantee for a corrector tofind the correction if one is used for the other,guarantee that you cannot have with thepreceding order (765 root words between theroots cote and cOt6 in our French rootdictionary, which contains a total of 35 000roots).With this code, we get textual portability ofdata and a natural dictionary order which ispreserved on all machines where the dictionaryis implemented.4.
Dr iv ing tools with acommand languageOnce you have achieved the portability ofyour software kernels, you are faced theportability of the user interfaces.
Here youhave two choices:1. write portable interfaces by using verysimple textual interactions with the user sothat you can write the code in ANSI-C;I The code defined by the Text Encoding Initiative(Sperberg, 1994), derived from SGML, is usable forelectronical transfer, but a little cumbersome for alexicon which might contains as much as 200 or 300thousands words2.
write a modem interface, heavily tied withthe graphical interface of the host machine,and partially or completely rewrite it eachtime you want to implement it on a newarchitecture.We have chosen to proceed in two steps:?
first make the first choice even if we get avery poor user interface, not acceptable onmodem graphic computers; such interfacesare very easy to write and permit at least todebug the tools.?
then make the second choice, try tominimise the rewriting cost and, moreover,to make the kernels completely in-dependent of the interface.To minimise the rewriting cost, we use agraphical ibrary which is freely available andportable from one machine to another.To make the kernels completely indepen-dent of the interface, we propose to have a userinterface which is str ict ly l imited tocommunications with the user.
The architec-ture is a client/server one, where the user in-terface (the client) calls the kernels (theservers) for linguistic treatments (see Figure 3).CLI: Command Language InterfaceUserinterfaceMorphologicalParserSimilarity Key \]CorrectionMorphologicalGeneratorPhonetic/GraphicTransducerEditorsFigure 3 : Distributed Architecture withseparated user interfaceYou can imagine as much clients as youneed, for example:?
one for a lemmatiser which calls only themorphological parser and generator;?
one, more complex,  for a detec-tion/correction system, which uses all toolsto produce correction of lexical errors;1055?
one, with pull-down menus and windows,devoted only to the editors (modification ofthe lexicons, of the linguistic data,...).Of course, all interfaces are sharing thetools with the others and it must be easy to adda new tool to an interface (for example a newcorrection method) or to substitute a given toolby an other (one can change thephonetic/graphic transducer to get an im-proved version).To obtain this flexibility and to make pos-sible the distribution of tools (on the samemachines or on all a net), we propose, as(Boitet, 1994) in the white-board architecture,to add a manager on each module.
Ourmanager take the form of a textual commandlanguage which is used to drive the module(Antworth, 1990) has used such a commandlanguage interface in PC-KIMMO.The general form of a command would be thefollowing:verb(arg I => paraml;arg 2 => param2;,..)where verb  is the command and where arg iand param i are respectively the names andthe values of its parameters.Parameter values could be integers, lloatingpoint numbers, booleans, objects (denoted withthe same syntax as a command), or a list of thepreceding.Examples:Parse (string => "to_be_parsed")Generate (word => "aimer";f i lter => filter(category => "verb";variables => \["present","singular","3 rd_person" \] )List (dictionnary => "dict name")Add d ict ionnary(word => "to_add";like => "paradigm")Each tool must be build on the same frame:it reads only from one input stream (itsstandard input) and write to only one outputstream (its standard output) and the mainalgorithm is an interprcter.Using such a command language interfaceentails 4 main advantages:?
it can be used as the only (but rough) in-terface for a given tool;?
you can write programs in this languageand thus automate the use of the tool;the interpreter does not use machinespecific feature so the entire tool can bewritten in strict ANSI-C and thus be heavilyportable (without changing a comma);connecting the tool to a more sophisticatedinterface program is very easy: it requiresonly the ability of passing text from oneapplication to the other.
You can forexample put a morphological parser on amachine such that it can be called byelectronic mail: you send the string to beparsed in a mail and the answer contains thewords, with their category and properties.5.
ConclusionWe have used the portability frame presentedin this paper for the main tools of our system:a morphological parser and a morphologicalgenerator, which use a root and endingslexicon to parse or generate about 250 000French forms.
The lexicon must be un-compiled and compiled back when portingfrom Mac to PC but the whole process doesnot take more than a dozen minutes.
On thecontrary, thanks to the similarity in theirarchitectures, the same lexicon can be used onMac and on Unix machines.Concerning the code, we have now portableversions of the tools mentioned above, plus alexical desambiguer and a lexical correcterusing similarity keys.
We are able to deliverlibraries for these tools (and their data forFrench) on Mac, PC and Unix.ReferencesE.L.
Antworth (1990).
PC-KIMMO : A Two-level Processor lor Morphological Analysis,Summer Institute of Linguistics, Dallas,Texas.Christian Boitet (1982).
Le point sur ARIANE-78.
Rapport ADI 81/423, GETA-Champollion et CAP SOGETI France,Grenoble.Christian Boitet and Marc Seligman (1994).The "white-board" architecture: a way tointegrate heterogeneous components ofNLP systems.
CoLing'94, Kyoto, Japan,August 94, Vol.
1, pp 426-430.Damien Genthial and Jacques Courtin (1994).Towards a More User-Friendly Correction.CoLing'94, Kyoto, Japan, August 94, pp1083-1088.C.M.
Sperberg-McQueen and L. Burnard(1994).
Guidelines for Electronic TextEncoding and Interchange.
in press,Chicago and Oxford.1056
