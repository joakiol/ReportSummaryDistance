Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 929?936,Sydney, July 2006. c?2006 Association for Computational LinguisticsSemantic Role Labeling via FrameNet, VerbNet and PropBankAna-Maria Giuglea and Alessandro MoschittiDepartment of Computer ScienceUniversity of Rome ?Tor Vergata?Rome, Italyagiuglea@gmail.commoschitti@info.uniroma2.itAbstractThis article describes a robust seman-tic parser that uses a broad knowledgebase created by interconnecting three ma-jor resources: FrameNet, VerbNet andPropBank.
The FrameNet corpus con-tains the examples annotated with seman-tic roles whereas the VerbNet lexicon pro-vides the knowledge about the syntac-tic behavior of the verbs.
We connectVerbNet and FrameNet by mapping theFrameNet frames to the VerbNet Intersec-tive Levin classes.
The PropBank corpus,which is tightly connected to the VerbNetlexicon, is used to increase the verb cov-erage and also to test the effectiveness ofour approach.
The results indicate that ourmodel is an interesting step towards thedesign of more robust semantic parsers.1 IntroductionDuring the last years a noticeable effort has beendevoted to the design of lexical resources thatcan provide the training ground for automatic se-mantic role labelers.
Unfortunately, most of thesystems developed until now are confined to thescope of the resource used for training.
A veryrecent example in this sense was provided by theCONLL 2005 shared task (Carreras and Ma`rquez,2005) on PropBank (PB) (Kingsbury and Palmer,2002) role labeling.
The systems that participatedin the task were trained on the Wall Street Jour-nal corpus (WSJ) and tested on portions of WSJand Brown corpora.
While the best F-measurerecorded on WSJ was 80%, on the Brown cor-pus, the F-measure dropped below 70%.
Themost significant causes for this performance decaywere highly ambiguous and unseen predicates (i.e.predicates that do not have training examples).The same problem was again highlighted by theresults obtained with and without the frame infor-mation in the Senseval-3 competition (Litkowski,2004) of FrameNet (Johnson et al, 2003) role la-beling task.
When such information is not usedby the systems, the performance decreases by 10percent points.
This is quite intuitive as the se-mantics of many roles strongly depends on the fo-cused frame.
Thus, we cannot expect a good per-formance on new domains in which this informa-tion is not available.A solution to this problem is the automaticframe detection.
Unfortunately, our preliminaryexperiments showed that given a FrameNet (FN)predicate-argument structure, the task of identify-ing the associated frame can be performed withvery good results when the verb predicates haveenough training examples, but becomes very chal-lenging otherwise.
The predicates belonging tonew application domains (i.e.
not yet included inFN) are especially problematic since there is notraining data available.Therefore, we should rely on a semantic contextalternative to the frame (Giuglea and Moschitti,2004).
Such context should have a wide coverageand should be easily derivable from FN data.
Avery good candidate seems to be the IntersectiveLevin class (ILC) (Dang et al, 1998) that can befound as well in other predicate resources like PBand VerbNet (VN) (Kipper et al, 2000).In this paper we have investigated the aboveclaim by designing a semi-automatic algorithmthat assigns ILCs to FN verb predicates and bycarrying out several semantic role labeling (SRL)experiments in which we replace the frame withthe ILC information.
We used support vector ma-929chines (Vapnik, 1995) with (a) polynomial ker-nels to learn the semantic role classification and(b) Tree Kernels (Moschitti, 2004) for learningboth frame and ILC classification.
Tree kernelswere applied to the syntactic trees that encode thesubcategorization structures of verbs.
This meansthat, although FN contains three types of predi-cates (nouns, adjectives and verbs), we only con-centrated on the verb predicates and their roles.The results show that: (1) ILC can be derivedwith high accuracy for both FN and Probank and(2) ILC can replace the frame feature with almostno loss in the accuracy of the SRL systems.
At thesame time, ILC provides better predicate coverageas it can also be learned from other corpora (e.g.PB).In the remainder of this paper, Section 2 sum-marizes previous work done on FN automatic roledetection.
It also explains in more detail why mod-els based exclusively on this corpus are not suit-able for free-text parsing.
Section 3 focuses on VNand PB and how they can enhance the robustnessof our semantic parser.
Section 4 describes themapping between frames and ILCs whereas Sec-tion 5 presents the experiments that support ourthesis.
Finally, Section 6 summarizes the conclu-sions.2 Automatic Semantic Role LabelingOne of the goals of the FN project is to design alinguistic ontology that can be used for the auto-matic processing of semantic information.
The as-sociated hierarchy contains an extensive semanticanalysis of verbs, nouns, adjectives and situationsin which they are used, called frames.
The basicassumption on which the frames are built is thateach word evokes a particular situation with spe-cific participants (Fillmore, 1968).
The word thatevokes a particular frame is called target word orpredicate and can be an adjective, noun or verb.The participant entities are defined using semanticroles and they are called frame elements.Several models have been developed for theautomatic detection of the frame elements basedon the FN corpus (Gildea and Jurafsky, 2002;Thompson et al, 2003; Litkowski, 2004).
Whilethe algorithms used vary, almost all the previousstudies divide the task into: 1) the identification ofthe verb arguments to be labeled and 2) the tag-ging of each argument with a role.
Also, mostof the models agree on the core features as be-ing: Predicate, Headword, Phrase Type, Govern-ing Category, Position, Voice and Path.
These arethe initial features adopted by Gildea and Jurafsky(2002) (henceforth G&J) for both frame elementidentification and role classification.One difference among previous machine-learning models is whether they used the frame in-formation or not.
The impact of the frame featureover unseen predicates and words is particularlyinteresting for us.
The results obtained by G&Jprovide some interesting insights in this direction.In one of their experiments, they used the frame togeneralize from predicates seen in the training datato unseen predicates, which belonged to the sameframe.
The overall performance increased show-ing that when no training data is available for atarget word we can use data from the same frame.Other studies suggest that the frame is cru-cial when trying to eliminate the major sourcesof errors.
In their error analysis, (Thompson etal., 2003) pinpoints that the verb arguments withheadwords that are rare in a particular frame butnot rare over the whole corpus are especially hardto classify.
For these cases the frame is very im-portant because it provides the context informa-tion needed to distinguish between different wordsenses.Overall, the experiments presented in G&J?sstudy correlated with the results obtained in theSenseval-3 competition show that the frame fea-ture increases the performance and decreases theamount of annotated examples needed in training(i.e.
frame usage improves the generalization abil-ity of the learning algorithm).
On the other hand,the results obtained without the frame informationare very poor.These results show that having broader framecoverage is very important for robust semanticparsing.
Unfortunately, the 321 frames that con-tain at least one verb predicate cover only a smallfraction of the English verb lexicon and of thepossible domains.
Also from these 321 framesonly 100 were considered to have enough trainingdata and were used in Senseval-3 (see (Litkowski,2004) for more details).Our approach for solving such problems in-volves the usage of a frame-like feature, namelythe Intersective Levin class (ILC).
We show thatthe ILC can replace the frame with almost no lossin performance.
At the same time, ILC providesbetter coverage as it can be learned also from other930corpora (e.g.
PB).The next section provides the theoretical sup-port for the unified usage of FN, VN and PB, ex-plaining why and how it is possible to link them.3 Linking FrameNet to VerbNet andPropBankIn general, predicates belonging to the same FNframe have a coherent syntactic behavior that isalso different from predicates pertaining to otherframes (G&J).
This finding is consistent with the-ories of linking that claim that the syntactic behav-ior of a verb can be predicted from its semantics(Levin, 1993).
This insight justifies the attempt touse ILCs instead of the frame feature when clas-sifying FN semantic roles (Giuglea and Moschitti,2004).The main advantage of using Levin classescomes from the fact that other resources like PBand the VN lexicon contain this kind of informa-tion.
Thus, we can train an ILC classifier also onthe PB corpus, considerably increasing the verbknowledge base at our disposal.
Another advan-tage derives from the syntactic criteria that wereapplied in defining the Levin?s clusters.
As shownlater in this article, the syntactic nature of theseclasses makes them easier to classify than frameswhen using only syntactic and lexical features.More precisely, Levin?s clusters are formed ac-cording to diathesis alternation criteria which arevariations in the way verbal arguments are gram-matically expressed when a specific semantic phe-nomenon arises.
For example, two different typesof diathesis alternations are the following:(a) Middle Alternation[Subject, Agent The butcher] cuts [DirectObject, Patient the meat].
[Subject, Patient The meat] cuts easily.
(b) Causative/inchoative Alternation[Subject, Agent Janet] broke [Direct Object,Patient the cup].
[Subject, Patient The cup] broke.In both cases, what is alternating is the grammati-cal function that the Patient role takes when chang-ing from the transitive use of the verb to the intran-sitive one.
The semantic phenomenon accompa-nying these types of alternations is the change offocus from the entity performing the action to thetheme of the event.Levin documented 79 alternations which con-stitute the building blocks for the verb classes.Although alternations are chosen as the primarymeans for identifying the classes, additional prop-erties related to subcategorization, morphologyand extended meanings of verbs are taken into ac-count as well.
Thus, from a syntactic point ofview, the verbs in one Levin class have a regu-lar behavior, different from the verbs pertaining toother classes.
Also, the classes are semanticallycoherent and all verbs belonging to one class sharethe same participant roles.This constraint of having the same semanticroles is further ensured inside the VN lexiconwhich is constructed based on a more refined ver-sion of the Levin?s classification, called Intersec-tive Levin classes (ILCs) (Dang et al, 1998).
Thelexicon provides a regular association between thesyntactic and semantic properties of each of thedescribed classes.
It also provides informationabout the syntactic frames (alternations) in whichthe verbs participate and the set of possible seman-tic roles.One corpus associated with the VN lexicon isPB.
The annotation scheme of PB ensures thatthe verbs belonging to the same Levin class sharesimilarly labeled arguments.
Inside one ILC, toone argument corresponds one semantic role num-bered sequentially from ARG0 to ARG5.
The ad-junct roles are labeled ARGM.Levin classes were constructed based on regu-larities exhibited at grammatical level and the re-sulting clusters were shown to be semantically co-herent.
As opposed, the FN frames were built onsemantic bases, by putting together verbs, nounsand adjectives that evoke the same situations.
Al-though different in conception, the FN verb clus-ters and VN verb clusters have common proper-ties1:1.
Different syntactic properties between dis-tinct verb clusters (as proven by the experi-ments in G&J)2.
A shared set of possible semantic roles for allverbs pertaining to the same cluster.Having these insights, we have assigned a corre-spondent VN class not to each verb predicate butrather to each frame.
In doing this we have ap-plied the simplifying assumption that a frame has a1See section 4.4 for more details931unique corresponding Levin class.
Thus, we havecreated a one-to-many mapping between the ILCsand the frames.
In order to create a pair ?FN frame,VN class?, our mapping algorithm checks both thesyntactic and semantic consistency by comparingthe role frequency distributions on different syn-tactic positions for the two candidates.
The algo-rithm is described in detail in the next section.4 Mapping FrameNet frames to VerbNetclassesThe mapping algorithm consists of three steps: (a)we link the frames and ILCs that have the largestnumber of verbs in common and we create a set ofpairs ?FN frame, VN class?
(see Table 1); (b) werefine the pairs obtained in the previous step basedon diathesis alternation criteria, i.e.
the verbs per-taining to the FN frame have to undergo the samediathesis alternation that characterize the corre-sponding VN class (see Table 2) and (c) we man-ually check the resulting mapping.4.1 The mapping algorithmGiven a frame, F , we choose as candidate for themapping the ILC, C, that has the largest number ofverbs in common with it (see Table 1, line (I)).
Ifthe number is greater or equal than three we forma pair ?F , C?
that will be tested in the second stepof the algorithm.
Only the frames that have morethan 3 verb lexical units are candidates for this step(frames with less than 3 members cannot pass con-dition (II)).
This excludes a number of 60 framesthat will be subsequently manually mapped.In order to assign a VN class to a frame, wehave to verify that the verbs belonging to the FNframe participate in the same diathesis alternationcriteria used to define the VN class.
Thus, thepairs ?F,C?
formed in step 1 of the mapping al-gorithm have to undergo a validation step that ver-ifies the similarity between the enclosed FN frameand VN class.
This validation process has severalsub-steps:First, we make use of the property (2) of theLevin classes and FN frames presented in the pre-vious section.
According to this property, all verbspertaining to one frame or ILC have the same par-ticipant roles.
Thus, a first test of compatibilitybetween a frame and a Levin class is that theyshare the same participant roles.
As FN is anno-tated with frame-specific semantic roles, we man-ually mapped these roles into the VN set of the-INPUTV N = {C|C is a V erbNet class}V N Class C = {v|c is a verb of C}FN = {F |F is a FrameNet frame}FN frame F = {v|v is a verb of F}OUTPUTPairs = {?F, C?
|F ?
FN,C ?
V N : F maps to C }COMPUTE PAIRS:Let Pairs = ?for each F ?
FN(I) compute C?
= argmaxC?V N |F ?
C|(II) if |F ?
C?| ?
3 then Pairs = Pairs ?
?F,C?
?Table 1: Linking FrameNet frames and VerbNetclasses.TR = {?i : ?i is the i?
th theta role of VerbNet }for each ?F, C?
?
Pairs?
?AF = ?o1, .., on?, oi = #?
?i, F, pos =adjacent??
?DF = ?o1, .., on?, oi = #?
?i, F, pos =distant??
?AC = ?o1, .., on?, oi = #?
?i, C, pos =adjacent??
?DC = ?o1, .., on?, oi = #?
?i, C, pos =distant?ScoreF,C = 23 ??
?AF ???AC????????AF???????????????AC?????
?+ 13 ??
?DF ???DC????????DF???????????????DC?????
?Table 2: Mapping algorithm - refining step.matic roles.
Given a frame, we assigned thematicroles to all frame elements that are associated withverbal predicates.
For example the Speaker, Ad-dressee, Message and Topic roles from the Tellingframe were respectively mapped into the Agent,Recipient, Theme and Topic theta roles.Second, we build a frequency distribution ofVN thematic roles on different syntactic positions.Based on our observation and previous studies(Merlo and Stevenson, 2001), we assume that eachILC has a distinct frequency distribution of roleson different grammatical slots.
As we do not havematching grammatical functions in FN and VN,we approximate that subjects and direct objectsare more likely to appear on positions adjacentto the predicate, while indirect objects appear onmore distant positions.
The same intuition is suc-cessfully used by G&J to design the Position fea-ture.For each thematic role ?i we acquired from VNand FN data the frequencies with which ?i appearson an adjacent A or distant D positions in a givenframe or VN class (i.e.
#?
?i , class, position?
).Therefore, for each frame and class, we obtain twovectors with thematic role frequencies correspond-ing respectively to the adjacent and distant posi-tions (see Table 2).
We compute a score for each932Score No.
of FramesNotmapped CorrectOverallCorrect[0,0.5] 118 48.3% 82.5%(0.5,0.75] 69 0 84%(0.75,1] 72 0 100%89.6%Table 3: Results of the mapping algorithm.pair ?F,C?
using the normalized scalar product.The core arguments, which tend to occupy adja-cent positions, show a minor syntactic variabilityand are more reliable than adjunct roles.
To ac-count for this in the overall score, we multiply theadjacent and the distant scores by 2/3 and 1/3, re-spectively.
This limits the impact of adjunct roleslike Temporal and Location.The above frequency vectors are computed forFN directly from the corpus of predicate-argumentstructure examples associated with each frame.The examples associated with the VN lexicon areextracted from the PB corpus.
In order to do thiswe apply a preprocessing step in which each la-bel Arg0..5 is replaced with its corresponding the-matic role given the ILC of the predicate.
Weassign the same roles to the adjuncts all over PBas they are general for all verb classes.
The onlyexception is ARGM-DIR that can correspond toSource, Goal or Path.
We assign different roles tothis adjunct based on the prepositions.
We ignoresome adjuncts like ARGM-ADV or ARGM-DISbecause they cannot bear a thematic role.4.2 Mapping ResultsWe found that only 133 VN classes have corre-spondents among FN frames.
Moreover, from theframes mapped with an automatic score smallerthan 0.5 almost a half did not match any of theexisting VN classes2.
A summary of the resultsis depicted in Table 3.
The first column containsthe automatic score provided by the mapping al-gorithm when comparing frames with ILCs.
Thesecond column contains the number of frames foreach score interval.
The third column contains thepercentage of frames that did not have a corre-sponding VN class and finally the fourth and fifthcolumns contain the accuracy of the mapping al-gorithm for each interval score and for the wholetask, respectively.We mention that there are 3,672 distinct verbsenses in PB and 2,351 distinct verb senses in2The automatic mapping is improved by manually assign-ing the FN frames of the pairs that receive a score lower than0.5.FN.
Only 501 verb senses are in common betweenthe two corpora which means 13.64% of PB and21.31% of FN.
Thus, by training an ILC classifieron both PB and FN we extend the number of avail-able verb senses to 5,522.4.3 DiscussionIn the literature, other studies compared the Levinclasses with the FN frames, e.g.
(Baker and Rup-penhofer, 2002; Giuglea and Moschitti, 2004; Shiand Mihalcea, 2005).
Their findings suggest thatalthough the two set of clusters are roughly equiv-alent there are also several types of mismatches:1.
Levin classes that are narrower than the cor-responding frames,2.
Levin classes that are broader that the corre-sponding frames and3.
Overlapping groups.For our task, point 2 does not pose a problem.Points 1 and 3 however suggest that there are casesin which to one FN frame corresponds more thanone Levin class.
By investigating such cases, wenoted that the mapping algorithm consistently as-signs scores below 75% to cases that match prob-lem 1 (two Levin classes inside one frame) andbelow 50% to cases that match problem 3 (morethan two Levin classes inside one frame).
Thus,to increase the accuracy of our results, a first stepshould be to assign independently an ILC to eachof the verbs pertaining to frames with score lowerthan 0.75%.Nevertheless the current results are encourag-ing as they show that the algorithm is achieving itspurpose by successfully detecting syntactic inco-herences that can be subsequently corrected man-ually.
Also, in the next section we will show thatour current mapping achieves very good results,giving evidence for the effectiveness of the Levinclass feature.5 ExperimentsIn the previous sections we have presented thealgorithm for annotating the verb predicates ofFrameNet (FN) with Intersective Levin classes(ILCs).
In order to show the effectiveness of thisannotation and of the ILCs in general we have per-formed several experiments.First, we trained (1) an ILC multiclassifier fromFN, (2) an ILC multiclassifier from PB and (3) a933Run51.3.2Cooking45.3Characterize29.2Other_cos45.4Say37.7Correspond36.1 MulticlassifierPB #Train InstancesPB #Test Instances2625652,9451342,2071499,7076082592052,1722,742PB Results 75 33.33 96.3 97.24 100 88.89 92.96FN #Train InstancesFN #Test Instances5,3811,34313835765407211841,8601,34355711146,73411,650FN Results 96.36 72.73 95.73 92.43 94.43 78.23 92.63Table 4: F1s of some individual ILC classifiers and the overall multiclassifier accuracy (180 classes onPB and 133 on FN).Body_part Crime Degree Agent MulticlassifierFN #Train InstancesFN #Test Instances1,5113563957651876,4411,643102,72425,615LF+Gold Frame 90.91 88.89 70.51 93.87 90.8LF+Gold ILC 90.80 88.89 71.52 92.01 88.23LF+Automatic Frame 84.87 88.89 70.10 87.73 85.64LF+Automatic ILC 85.08 88.89 69.62 87.74 84.45LF 79.76 75.00 64.17 80.82 80.99Table 5: F1s of some individual FN role classifiers and the overall multiclassifier accuracy (454 roles).frame multiclassifier from FN.
We compared theresults obtained when trying to classify the VNclass with the results obtained when classifyingframe.
We show that ILCs are easier to detect thanFN frames.Our second set of experiments regards the auto-matic labeling of FN semantic roles on FN corpuswhen using as features: gold frame, gold ILC, au-tomatically detected frame and automatically de-tected ILC.
We show that in all situations in whichthe VN class feature is used, the accuracy loss,compared to the usage of the frame feature, is neg-ligible.
This suggests that the ILC can success-fully replace the frame feature for the task of se-mantic role labeling.Another set of experiments regards the gener-alization property of the ILC.
We show the impactof this feature when very few training data is avail-able and its evolution when adding more and moretraining examples.
We again perform the exper-iments for: gold frame, gold ILC, automaticallydetected frame and automatically detected ILC.Finally, we simulate the difficulty of free textby annotating PB with FN semantic roles.
Weused PB because it covers a different set of ver-bal predicates and also because it is very differentfrom FN at the level of vocabulary and sometimeseven syntax.
These characteristics make PB a dif-ficult testbed for the semantic role models trainedon FN.In the following section we present the resultsobtained for each of the experiments mentionedabove.5.1 Experimental setupThe corpora available for the experiments were PBand FN.
PB contains about 54,900 predicates andgold parse trees.
We used sections from 02 to 22(52,172 predicates) to train the ILC classifiers andSection 23 (2,742 predicates) for testing purposes.The number of ILCs is 180 in PB and 133 on FN,i.e.
the classes that we were able to map.For the experiments on FN corpus, we extracted58,384 sentences from the 319 frames that containat least one verb annotation.
There are 128,339argument instances of 454 semantic roles.
In ourevaluation we use only verbal predicates.
More-over, as there is no fixed split between training andtesting, we randomly selected 20% of sentencesfor testing and 80% for training.
The sentenceswere processed using Charniak?s parser (Char-niak, 2000) to generate parse trees automatically.The classification models were implemented bymeans of the SVM-light-TK software available athttp://ai-nlp.info.uniroma2.it/moschittiwhich encodes tree kernels in the SVM-lightsoftware (Joachims, 1999).
We used the defaultparameters.
The classification performance wasevaluated using the F1 measure for the individualrole and ILC classifiers and the accuracy for themulticlassifiers.9345.2 Automatic VerbNet class vs. automaticFrameNet frame detectionIn these experiments, we classify ILCs on PB andframes on FN.
For the training stage we use SVMswith Tree Kernels.The main idea of tree kernels is the modelingof a KT (T1,T2) function which computes the num-ber of common substructures between two trees T1and T2.
Thus, we can train SVMs with structuresdrawn directly from the syntactic parse tree of thesentence.
The kernel that we employed in our ex-periments is based on the SCF structure devisedin (Moschitti, 2004).
We slightly modified SCFby adding the headwords of the arguments, usefulfor representing the selectional preferences (moredetails are given in (Giuglea and Moschitti, 2006).For frame detection on FN, we trained our clas-sifier on 46,734 training instances and tested on11,650 testing instances, obtaining an accuracy of91.11%.
For ILC detection the results are depictedin Table 4.
The first six columns report the F1measure of some verb class classifiers whereas thelast column shows the global multiclassifier accu-racy.
We note that ILC detection is more accuratethan the frame detection on both FN and PB.
Ad-ditionally, the ILC results on PB are similar withthose obtained for the ILCs on FN.
This suggeststhat the training corpus does not have a major in-fluence.
Also, the SCF-based tree kernel seems tobe robust in what concerns the quality of the parsetrees.
The performance decay is very small on FNthat uses automatic parse trees with respect to PBthat contains gold parse trees.5.3 Automatic semantic role labeling onFrameNetIn the experiments involving semantic role label-ing, we used SVMs with polynomial kernels.
Weadopted the standard features developed for se-mantic role detection by Gildea and Jurafsky (seeSection 2).
Also, we considered some of the fea-tures designed by (Pradhan et al, 2005): First andLast Word/POS in Constituent, Subcategorization,Head Word of Prepositional Phrases and the Syn-tactic Frame feature from (Xue and Palmer, 2004).For the rest of the paper, we will refer to these fea-tures as being literature features (LF).
The resultsobtained when using the literature features aloneor in conjunction with the gold frame feature, goldILC, automatically detected frame feature and au-tomatically detected ILC are depicted in Table 5.3040506070809010 20 30 40 50 60 70 80 90 100% Training DataAccuracyLF+ILCLFLF+Automatic ILC Trained on PBLF+Automatic ILC Trained on FNFigure 1: Semantic role learning curve.The first four columns report the F1 measureof some role classifiers whereas the last columnshows the global multiclassifier accuracy.
The firstrow contains the number of training and testing in-stances and each of the other rows contains theperformance obtained for different feature com-binations.
The results are reported for the label-ing task as the argument-boundary detection taskis not affected by the frame-like features (G&J).We note that automatic frame produces an accu-racy very close to the one obtained with automaticILC suggesting that this is a very good candidatefor replacing the frame feature.
Also, both auto-matic features are very effective and they decreasethe error rate by 20%.To test the impact of ILC on SRL with differentamount of training data, we additionally draw thelearning curves with respect to different features:LF, LF+ (gold) ILC, LF+automatic ILC trained onPB and LF+automatic ILC trained on FN.
As canbe noted, the automatic ILC information providedby the ILC classifiers (trained on FN or PB) per-forms almost as good as the gold ILC.5.4 Annotating PB with FN semantic rolesTo show that our approach can be suitable forsemantic role free-text annotation, we have au-tomatically classified PB sentences3 with the FNsemantic-role classifiers.
In order to measurethe quality of the annotation, we randomly se-lected 100 sentences and manually verified them.We measured the performance obtained with andwithout the automatic ILC feature.
The sentencescontained 189 arguments from which 35 were in-correct when ILC was used compared to 72 incor-rect in the absence of this feature, i.e.
an accu-racy of 81% with ILC versus 62% without it.
Thisdemonstrates the importance of the ILC feature3The results reported are only for role classification.935outside the scope of FN where the frame featureis not available.6 ConclusionsIn this paper we have shown that the ILC featurecan successfully replace the FN frame feature.
Bydoing that we could interconnect FN to VN andPB obtaining better verb coverage and a more ro-bust semantic parser.
Our good results show thatwe have defined an effective framework which isa promising step toward the design of more robustsemantic parsers.In the future, we intend to measure the effec-tiveness of our system by testing FN SRL on alarger portion of PB or on other corpora containinga larger verb set.ReferencesCollin Baker and Josef Ruppenhofer.
2002.
Framenetsframes vs. levins verb classes.
In 28th Annual Meet-ing of the Berkeley Linguistics Society.Xavier Carreras and Llu?
?s Ma`rquez.
2005.
Introduc-tion to the CoNLL-2005 shared task: Semantic rolelabeling.
In Proceedings of CoNLL-2005.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.
In Proceedings of NACL00, Seattle,Washington.Hoa Trang Dang, Karin Kipper, Martha Palmer, andJoseph Rosenzweig.
1998.
Investigating regularsense extensions based on intersective levin classes.In Coling-ACL98.Charles J. Fillmore.
1968.
The case for case.
In Uni-versals in Linguistic Theory.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tic.Ana-Maria Giuglea and Alessandro Moschitti.
2004.Knowledge discovering using FrameNet, VerbNetand PropBank.
In Proceedings of Workshop on On-tology and Knowledge Discovering at ECML 2004,Pisa, Italy.Ana-Maria Giuglea and Alessandro Moschitti.
2006.Shallow semantic parsing based on FrameNet, Verb-Net and PropBank.
In Proceedings of the 17th Euro-pean Conference on Artificial Intelligence, Riva delGarda, Italy.T.
Joachims.
1999.
Making large-scale SVM learningpractical.
In B. Scho?lkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods - Support Vec-tor Learning.Christopher Johnson, Miriam Petruck, Collin Baker,Michael Ellsworth, Josef Ruppenhofer, and CharlesFillmore.
2003.
Framenet: Theory and practice.Berkeley, California.Paul Kingsbury and Martha Palmer.
2002.
From Tree-bank to PropBank.
In LREC02).Karin Kipper, Hoa Trang Dang, and Martha Palmer.2000.
Class-based construction of a verb lexicon.In AAAI00.Beth Levin.
1993.
English Verb Classes and Alterna-tions A Preliminary Investigation.
Chicago: Univer-sity of Chicago Press.Kenneth Litkowski.
2004.
Senseval-3 task automaticlabeling of semantic roles.
In Senseval-3.Paola Merlo and Suzanne Stevenson.
2001.
Automaticverb classification based on statistical distribution ofargument structure.
CL Journal.Alessandro Moschitti.
2004.
A study on convolutionkernels for shallow semantic parsing.
In ACL04,Barcelona, Spain.Sameer Pradhan, Kadri Hacioglu, Valeri Krugler,Wayne Ward, James H. Martin, and Daniel Jurafsky.2005.
Support vector learning for semantic argu-ment classification.
Machine Learning Journal.Lei Shi and Rada Mihalcea.
2005.
Putting pieces to-gether: Combining FrameNet, VerbNet and Word-Net for robust semantic parsing.
In Proceedings ofCicling 2005, Mexico.Cynthia A. Thompson, Roger Levy, and ChristopherManning.
2003.
A generative model for semanticrole labeling.
In 14th European Conference on Ma-chine Learning.V.
Vapnik.
1995.
The Nature of Statistical LearningTheory.
Springer.Nianwen Xue and Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Proceedingsof EMNLP 2004, Barcelona, Spain.
Association forComputational Linguistics.936
