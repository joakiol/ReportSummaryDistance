Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,pages 15?19, Dublin, Ireland, August 23-29 2014.Creating Custom Taggers by Integrating Web Page Annotation andMachine LearningSrikrishna Raamadhurai?Oskar Kohonen?Teemu Ruokolainen??
?Aalto University, Department of Information and Computer Science, Finland?
?Aalto University, Department of Signal Processing and Acoustics, Finlandfirstname.lastname@aalto.fiAbstractWe present an on-going work on a software package that integrates discriminative machine learn-ing with the open source WebAnnotator system of Tannier (2012).
The WebAnnotator systemallows users to annotate web pages within their browser with custom tag sets.
Meanwhile, weintegrate the WebAnnotator system with a machine learning package which enables automatictagging of new web pages.
We hope the software evolves into a useful information extractiontool for motivated hobbyists who have domain expertise on their task of interest but lack machinelearning or programming knowledge.
This paper presents the system architecture, including theWebAnnotator-based front-end and the machine learning component.
The system is availableunder an open source license.1 IntroductionA typical development cycle of a natural language processing (NLP) tool involves several different ex-perts whose time is often limited as well as expensive.
In particular, rule-based systems need experts toconstruct the rules, while data-driven systems require domain experts to produce annotated training dataand machine learning experts to train the systems.
Because of the required investment, tasks which lackcommercial or academic interest are often left completely without applicable tools.
Nevertheless, webelieve that there exist many relatively simple tasks where necessary annotation for a machine learningsystem could be produced by motivated hobbyists who possess domain expertise but lack machine learn-ing or programming knowledge.
For example, consider identifying fields in classified ads such as productname, dimensions and price, or segmenting individual posts in a web forum.
To this end, we present asoftware package that integrates discriminative machine learning with the open source WebAnnotatorsystem (Tannier, 2012).The combination of an annotation tool and machine learning is, of course, not a new idea, as it goesback at least to the Alembic system (Day et al., 1997), which was developed to accelerate the processof tailoring NLP tools to new domains, languages, and tasks, by attempting to reduce the work load ofhuman annotators by employing pre-taggers learned from previously annotated data.
Despite these ideasbeing around for a long time, they do not seem to have been integrated into a web-browser previously.Since a large amount of information is consumed using the web-browser, it is desirable to be able to trainand apply automatic analysis tools directly within that context.The paper is organized as follows.
In Section 2, we review how the system is used, its general archi-tecture and details related to how the machine learning is implemented.
Section 4 provides discussionand conclusions on the work.2 SystemIn this section we present in some detail the system that integrates discriminative machine learningwith the open source WebAnnotator (Tannier, 2012).
We review the usage of the system, its softwarearchitecture, the central aspects related to how machine learning is applied: the employed ConditionalThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/15Random Fields-method, indexing and pre-processing web-pages, how training sets are constructed, andthe applied feature extraction.
Finally, we review how the trained system is applied to new web-pages.The latest version of the software can be found at https://github.com/okohonen/semantify.2.1 Overview of UsageThe system is installed as an add-on to the Firefox browser.
Subsequently, it can be activated for anyweb page.
The user can train several different models by indicating which model a particular annotationbelongs to.
The user can also define the tag set used for annotation.
To annotate, the user highlightsparts of the page with the mouse and selects the desired tag from the shown menu.
Assigned annotationsare denoted by colors.
This process is presented in Figure 1 (a).
When the user is done, she stores theannotated page as shown in Figure 1 (b).
The system then stores the annotated page in its page index.Meanwhile, in the background, the system automatically produces a training set that contains all thepages annotated so far and learns a tagger.
The user can ask the system to tag a new page as shown inFigure 1 (c), in which case the system pre-processes and tags the current page using the latest trainedmodel.
The system then adds the annotations matching the output of the machine learning model to theviewed web page.
The automatically assigned tags are visually distinct from the manually annotatedones (lighter color scheme).
The automatic taggings can then be corrected manually and added to thetraining set.
An example of an automatically annotated page is shown in figure 1 (d).2.2 Overview of ArchitectureThe system architecture consists of two main components, namely, 1) an add-on to the Firefox-browserthat allows annotation of web pages directly in the browser window, and 2) a machine learning compo-nent for annotating new pages.
The browser add-on extends the WebAnnotator system (Tannier, 2012)by integrating it with the machine learning component and with functionality to show and edit the tagsproduced by the trained taggers.
The machine learning component indexes the annotated web pages, pre-processes them to produce training sets of sentences, and trains models that can then be applied to newdata.
The Firefox add-on is implemented in Javascript and XUL while the machine learning componentis implemented in Python.
To bridge the language gap they communicate using XMLHTTPRequest.The machine learning component implements the well-known conditional random field (CRF) method,a discriminative modeling framework for sequence labeling (Lafferty et al., 2001).2.3 Conditional Random FieldsOur system implements the linear-chain CRF model (Lafferty et al., 2001) which can inherently accom-modate the arbitrary, overlapping features described below in Section 2.7.
The CRF model is estimatedbased on the available training set of exemplar input-output sequence pairs.
Test instances are decodedusing the standard Viterbi search (Lafferty et al., 2001).CRF parameter estimation is most commonly associated with the maximum likelihood approach em-ployed by Lafferty et al.(2001).
However, in our system, we rely on the averaged perceptron algorithmfollowing Collins (2002a).
(Note that the CRFs correspond to discriminatively trained hidden Markovmodels, and Collins (2002a) employs the latter terminology.)
We apply the averaged perceptron learningapproach for its simplicity and competitive performance (Zhang and Clark, 2011).2.4 Web Page IndexThe web page index in the machine learning component stores the annotated pages using the internalformat of WebAnnotator, which is simply the original HTML-page augmented with <span>-tags toencode and visualize the annotations.
Apart from annotated pages, it is also possible to index unannotatedpages if one has a particular set of pages that are to be tagged by the model.16Figure 1: Sample screenshots of the tool depicting typical scenarios.2.5 Pre-processingWe parse the HTML using the Beautiful Soup-library1, extracting the visible text parts.
Subsequently, wetokenize the text by splitting at white space and at non-alphanumeric characters.
The token sequence isgrouped into sentences based on punctuation and HTML-tags.
We consider that if an HTML-tag definesa new block then it also starts a new sentence (e.g.
<div> starts a block, while <span> does not).
Foreach token position we apply feature functions that are described in detail in Section 2.7.The user?s annotations are stored as span-tags that are identified by their class attributes.
Thespan-tags are parsed so that the label information is extracted, but they are ignored when calculatingthe feature functions which should be identical regardless of how the page is annotated.
If the user hasnot assigned any label we assume a default Outside class.2.6 Building the Training SetsThe CRF parameter estimation requires training and development sets which must be drawn from an-notated web pages in the page index.
A special characteristic of the data set is that the label distribu-tion is typically very skewed towards many Outside taggings and few non-Outside taggings.
Toensure that the development set gets sufficiently many non-Outside taggings, we use use a modulus-based scheme that assigns 10% of the sentences to the development set while making sure that there areenough sentences containing taggings from each class.
The training set and development set are formedby concatenating the preprocessed files for each individual page.2.7 Feature ExtractionIn addition to standard first-order state transition features, the CRF model includes feature functionswhich operate on the token sequence of the sentence and the HTML-tree of the page.
We use ortho-graphic features and HTML-features which consider the token string and HTML-tree, respectively.
Fororthographic features, we use the word in lower case, and generalized character-based following Collins(2002b).
We extract features based on the following properties of the current node in the HTML-tree:parent nodes and the class-attribute.
For the parent nodes we calculate both individual features for im-1http://www.crummy.com/software/BeautifulSoup/17mediate parents as well as very specific features that concatenates all parents up to the body-tag.
Forthe class-attribute we provide it both as it is and apply the same generalization functions as in the or-thographic feature set.
One could also extract features from other attributes than class.
However, wesuspect that they are less informative for the tagging task compared to the class-attribute which is oftenused to indicate structural properties of the page content.
We also window the features to consider theprevious and next positions in the input.2.8 Annotating New Pages AutomaticallyWhen the user asks the system to tag a new page, the current page is sent to the machine learningcomponent for preprocessing.
The latest trained CRF is applied to the preprocessed page and each tokenis assigned a tag.
We produce <span>-tags similar to the internal format used by WebAnnotator, butwith distinct attributes so the browser extension can distinguish manual and automatic annotation.
Toproduce the modified HTML-page, we need to know the position in the HTML-string for each token inthe preproessed file.
In order to achieve this, we create an index of the HTML-string during preprocessingthat maps every token to its original position in the string.3 DiscussionFor a software tool of the presented kind, the key performance measures are: accuracy on the task athand, as a function of the number of annotations; and training time.
As both measures are specific to taskand implementation, addressing them both experimentally would require a large number of experimentswhich is not feasible in the allowed space.
However, for illustration purposes, we will present a simpleexample application.In general, for the proposed system to yield high accuracy, it needs to learn the desired categories froma few annotated examples.
This requires input features that predict the desired target category well.
Thekey benefit of the discriminative training employed is the ability to use a large set of rich and overlappingfeatures.
This allows the construction of feature sets that yield good performance on several differenttasks, reducing the need for task-specific feature engineering which requires domain and programmingexpertise.
Future work includes identifying additional features that yield good performance in a numberof different tasks.For training time, it would be ideal if the system could be trained in real time, that is, once the userhas submitted an annotated web page to the system, the training would be completed when the userwants to apply the model to a new web page.
This would require training times on the order of a fewseconds.
Training time depends mostly on the employed classifier, training algorithm, and the number ofsequences and tokens in the training set.
We had assumed that training time would not be an issue, evenfor a naive implementation, because a typical user would only gather small data sets.
However, it turnedout that while the annotation may be small in the number of annotated web pages, typical web pageswere larger in terms of token counts than we had anticipated and more advanced training techniques maybe needed to reach real-time performance.To illustrate the properties related to tagging web pages using the current implementation, we presenta simple example application of the system to the task of extracting fields from the Internet MovieDatabase (IMDB).2We annotated 50 web pages from IMDB, each describing a different movie.
Thefollowing fields were annotated: director, genre, title, rating, theme, writer, and release year.
It shouldbe noted that this task is from the easier end of the spectrum, as the fields can be extracted with a highaccuracy using the markup structure alone.
For experimental purposes, we performed cross-validationwith training, development, and test sets constructed from 36, 4, and 10 web pages respectively.
Thesystem yielded the following token F-scores by category, director: 73%, genre: 99%, title: 86%, rating:100%, theme: 100%, writer: 80%, and release year: 100%.
This level of performance is promising,as several fields were extracted with perfect, or near perfect accuracy.
The training times for the 36-page training sets varied between 1.5 and 3.5 minutes on a standard desktop computer (Intel i5-2500with 16Gb RAM).
The variance in training time is explained by the employed stopping criterion which2http://www.imdb.com18terminates training based on the performance on the development set, resulting in varying numbers ofpasses over the training data.
In the above example task, the training set sizes were on average: 22Ksequences, 133K tokens, and 30K features.The empirical training times are longer than what could be considered real-time performance.
Thegoal of the current implementation has been accuracy rather than execution time, and for the latter, thereis certainly room for improvement.
However, for real-time performance, the improvement needed islarge enough that a different training procedure may be necessary.
A promising approach, that suits thesetting well, is using online training, such that one would only train on the latest submitted web-page.Furthermore, it is usually the case, that the non-Outside annotation is concentrated on a fairly smallsubpart of the web page.
This structure could be utilized to reduce computational cost.
These approacheswill be evaluated in future work.4 ConclusionsWe presented on-going work on a software package that integrates discriminative machine learning withthe open source WebAnnotator system of Tannier (2012).
The system allows users to annotate webpages directly within their web browser and train a machine learning tagger applicable for annotatingnew web pages.
We hope the software evolves into a useful information extraction tool for motivatedhobbyists who have domain expertise on their task of interest but lack machine learning or programmingknowledge.In future work, we plan to investigate the following aspects of the system.
The utility of the systemshould be evaluated in real-life tasks and for the target user group.
The machine learning componentcould then be improved further based on user experience.
Perhaps most importantly, the extracted fea-tures can be improved using both generic and task-specific features.
Also, while the system currentlyapplies only supervised learning, it would be a natural setting to apply semi-supervised learning.AcknowledgementsThe work was funded by an Exploratory Research Project grant from Aalto Science Institute, theAcademy of Finland research project on Multimodal Language Technology, Langnet (Finnish doctoralprogramme in language studies), and the Academy of Finland under the Finnish Centre of ExcellenceProgram 2012?2017 (grant no.
251170).ReferencesMichael Collins.
2002a.
Discriminative training methods for hidden Markov models: Theory and experimentswith perceptron algorithms.
In Proceedings of the ACL-02 conference on Empirical methods in natural lan-guage processing, volume 10, pages 1?8.Michael Collins.
2002b.
Ranking algorithms for named-entity extraction: Boosting and the voted perceptron.In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 489?496.Association for Computational Linguistics.David Day, John Aberdeen, Lynette Hirschman, Robyn Kozierok, Patricia Robinson, and Marc Vilain.
1997.Mixed-initiative development of language processing systems.
In Proceedings of the Fifth Conference on Ap-plied Natural Language Processing, ANLC ?97, pages 348?355, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.John Lafferty, Andrew McCallum, and Fernando C.N.
Pereira.
2001.
Conditional random fields: Probabilisticmodels for segmenting and labeling sequence data.
In Proceedings of the Eighteenth International Conferenceon Machine Learning, pages 282?289.Xavier Tannier.
2012.
WebAnnotator, an Annotation Tool for Web Pages.
In Proceedings of the 8th InternationalConference on Language Resources and Evaluation (LREC 2012), Istanbul, Turkey, May.Yue Zhang and Stephen Clark.
2011.
Syntactic processing using the generalized perceptron and beam search.Computational Linguistics, 37(1):105?151.19
