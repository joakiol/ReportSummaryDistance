Coling 2010: Poster Volume, pages 445?453,Beijing, August 2010Morphological analysis can improve a CCG parser for EnglishMatthew Honnibal, Jonathan K. Kummerfeld and James R. CurranSchool of Information TechnologiesUniversity of Sydney{mhonn,jono,james}@it.usyd.edu.auAbstractBecause English is a low morphology lan-guage, current statistical parsers tend toignore morphology and accept some levelof redundancy.
This paper investigateshow costly such redundancy is for a lex-icalised grammar such as CCG.We use morphological analysis to splitverb inflectional suffixes into separate to-kens, so that they can receive their ownlexical categories.
We find that this im-proves accuracy when the splits are basedon correct POS tags, but that errors in goldstandard or automatically assigned POStags are costly for the system.
This showsthat the parser can benefit from morpho-logical analysis, so long as the analysis iscorrect.1 IntroductionEnglish is a configurational language, so gram-matical functions are mostly expressed throughword order and function words, rather than withinflectional morphology.
Most English verbs havefour forms, and none have more than five.
Most ofthe world?s languages have far richer inflectionalmorphology, some with millions of possible in-flection combinations.There has been much work on addressing thesparse data problems rich morphology creates, butmorphology has received little attention in the En-glish statistical parsing literature.
We suggest thatEnglish morphology may prove to be an under-utilised aspect of linguistic structure that can im-prove the performance of an English parser.
En-glish also has a rich set of resources available, soan experiment that is difficult to perform with an-other language may be easier to conduct in En-glish, and a technique that makes good use of En-glish morphology may transfer well to a morpho-logically rich language.
under-exploited in En-glish natural languageIn this paper, we show how morphologicalinformation can improve an English statisticalparser based on a lexicalised formalism, Com-binatory Categorial Grammar (CCG, Steedman,2000), using a technique suggested for Turkish(Bozsahin, 2002) and Korean (Cha et al, 2002).They describe how a morphologically rich lan-guage can be analysed efficiently with CCG bysplitting off inflectional affixes as morphologicaltokens.
This allows the affix to receive a cate-gory that performs the feature coercion.
For in-stance, sleeping would ordinarily be assigned thecategory S [ng ]\NP : a sentence with the [ng ] fea-ture requiring a leftward NP argument.
We splitthe word into two tokens:sleep -ingS [b]\NP (S [ng ]\NP)\(S [b]\NP)The additional token creates a separate spacefor inflectional information, factoring it awayfrom the argument structure information.Even with only 5 verb forms in English, wefound that accurate morphological analysis im-proved parser accuracy.
However, the system hadtrouble recovering from analysis errors caused byincorrect POS tags.We then tested how inflection categories in-teracted with hat categories, a linguistically-motivated extension to the formalism, proposedby Honnibal and Curran (2009), that introducessome sparse data problems but improves parsereffiency.
The parser?s accuracy improved by 0.8%when gold standard POS tags were used, but notwith automatic POS tags.
Our method addressesproblems caused by even low morphology, andfuture work will make the system more robust toPOS tagging errors.4452 Combinatory Categorial GrammarCombinatory Categorial Grammar (CCG, Steed-man, 2000) is a lexicalised grammar, which meansthat each word in the sentence is associated witha category that specifies its argument structureand the type and features of the constituent thatit heads.
For instance, in might head a PP -typedconstituent with one NP -typed argument, writtenas PP/NP .
The / operator denotes an argumentto the right; \ denotes an argument to the left.For example, a transitive verb is a function froma rightward NP to and a leftward NP to a sen-tence, (S\NP)/NP .
The grammar consists of afew schematic rules to combine the categories:X /Y Y ?> XY X \Y ?< XX /Y Y /Z ?>B X /ZY \Z X \Y ?<B X \ZY /Z X \Y ?<B?
X /ZCCGbank (Hockenmaier and Steedman, 2007)extends this grammar with a set of type-changingrules, designed to strike a better balance betweensparsity in the category set and ambiguity in thegrammar.
We mark such productions TC.In wide-coverage descriptions, categories aregenerally modelled as typed feature structures(Shieber, 1986), rather than atomic symbols.
Thisallows the grammar to include head indices, andto unify under-specified features.
In our nota-tion features are annotated in square-brackets, e.g.S [dcl ].
Head-finding indices are annotated oncategories as subscripts, e.g.
(NPy\NPy)/NPz .We occasionally abbreviate S\NP as VP , andS [adj ]\NP as ADJ .2.1 Statistical CCG parsing and morphologyIn CCGbank, there are five features that arelargely governed by the inflection of the verb:writes/wrote (S [dcl ]\NP)/NP(was) written (S [pss]\NP)/NP(has) written (S [pt ]\NP)/NP(is) writing (S [ng ]\NP)/NP(to) write (S [b]\NP)/NPThe features are necessary for satisfactory anal-yses.
Without inflectional features, there is noway to block over-generation like has running orwas ran.
However, the inflectional features alsocreate a level of redundancy if the different in-flected forms are treated as individual lexical en-tries.
The different inflected forms of a verb willall share the same set of potential argument struc-tures, so some way of grouping the entries to-gether is desirable.Systems like the PET HPSG parser (Oepen et al,2004) and the XLE LFG parser (Butt et al, 2006)use a set of lexical rules that match morphologi-cal operations with transformations on the lexicalcategories.
For example, a lexical rule is used toensure that an intransitive verb like sleeping re-ceives the same argument structure as the baseform sleep, but with the appropriate inflectionalfeature.
This scheme works well for rule-basedparsers, but it is less well suited for statisticalparsers, as the rules propose categories but do nothelp the model estimate their likelihood or assignthem feature weights.Statistical parsers for lexicalised formalismssuch as CCG are very sensitive to the number ofcategories in the lexicon and the complexity ofthe mapping between words and categories.
Thesub-task of assigning lexical categories, supertag-ging (Bangalore and Joshi, 1999), is most of theparsing task.
Supertaggers mitigate sparse dataproblems by using a label frequency threshold toprune rare categories from the search space.
Clarkand Curran (2007) employ a tag dictionary that re-stricts the model to assigning word/category pairsseen in the training data for frequent words.The tag dictionary causes some level of under-generation, because not all valid word/categorypairs will occur in the limited training data avail-able.
The morphological tokens we introduce helpto mitigate this, by bringing together what weredistinct verbs and argument structures, using lem-matisation and factoring inflection away from ar-gument structures.
The tag dictionaries for the in-flectional morphemes will have very high cover-age, because there are only a few inflectional cat-egories and a few inflectional types.3 Inflectional CategoriesWe implement the morphemic categories thathave been discussed in the CCG literature446be ?ing good and do ?ing good(S [b]\NP)/ADJ (S [ng ]\NP)\(S [b]\NP) ADJ conj (S [b]\NP)/NP (S [ng ]\NP)\(S [b]\NP) NP<B?
<B?
(S [ng ]\NP)/ADJ (S [ng ]\NP)/NP> >S [ng ]\NP S [ng ]\NP<?>(S [ng ]\NP)\(S [ng ]\NP)<S [ng ]\NPFigure 1: A single inflection category (in bold) can serve many different argument structures.
(Bozsahin, 2002; Cha et al, 2002).
The inflectedform is broken into two morphemes, and each isassigned a category.
The category for the inflec-tional suffix is a function from a category with thebare-form feature [b] to a category that has an in-flectional feature.
This prevents verbal categoriesfrom having to express their inflectional featuresdirectly.
Instead, their categories only have to ex-press their argument structure.The CCG combinators allow multiple argumentstructures to share a single inflectional category.For instance, the (S [ng ]\NP)\(S [b]\NP) cate-gory can supply the [ng ] feature to all categoriesthat have one leftward NP argument and anynumber of rightward arguments, via the gener-alised backward composition combinator.
Fig-ure 1 shows this category transforming two dif-ferent argument structures, using the backwardcrossed composition rule (<B?
).Table 1 shows the most frequent inflection cat-egories we introduce.
The majority of inflectedverbs in the corpus have a subject and some num-ber of rightward arguments, so we can almostassign one category per feature.
The most fre-quent exceptions are participles that function aspre-nominal modifiers and verbs of speech.Table 2 shows the inflectional token types weintroduce and which features they correspond to.Our scheme largely follows the Penn Treebanktag set (Bies et al, 1995), except we avoided dis-tinguishing past participles from past tense (-envs -ed), because this distinction was a significantsource of errors for our morphological analysisprocess, which relies on the part-of-speech tag.3.1 Creating Training DataWe prepared a version of CCGbank (Hocken-maier and Steedman, 2007) with inflectional to-kens.
This involved the following steps:Correcting POS tags: Our morphological anal-Freq.
Category Example32.964 (S [dcl ]\NP)\(S [b]\NP) He ran11,431 (S [pss]\NP)\(S [b]\NP) He was run down11,324 (S [ng ]\NP)\(S [b]\NP) He was running4,343 (S [pt ]\NP)\(S [b]\NP) He has run3,457 (N /N )\(S [b]\NP) the running man2,011 S [dcl ]\S ?..
?, he says1,604 (S [dcl ]\S)\(S [b]\S) ?..
?, said the boy169 (S [dcl ]\ADJ )\(S [b]\ADJ ) Here ?s the deal55 (S [dcl ]\PP)\(S [b]\PP) On it was a beeTable 1: The inflectional categories introduced.Token POS Feat Example-es VBZ dcl He write -es letters-e VBP dcl They write -e letters-ed VBD dcl They write -ed letters-ed VBN pt They have write -ed letters-ed VBN pss Letters were write -ed-ing VBG ng They are write -ing lettersTable 2: The inflectional token types introduced.ysis relies on the part-of-speech tags providedwith CCGbank.
We identified and correctedwords whose POS tags were inconsistent with theirlexical category, as discussed in Section 3.2.Lemmatising verbs and removing features:We used the morphy WordNet lemmatiser imple-mented in NLTK1 to recover the lemma of the in-flected verbs, identified by their POS tag (VBP,VBG, VBN or VBZ).
The verb?s categories wereupdated by switching their features to [b].Deriving inflectional categories: The gener-alised backward composition rules allow a func-tor to generalise over some sequence of ar-gument categories, so long as they all sharethe same directionality.
For instance, a func-tor (S\NP)\(S\NP) could backward cross-compose into a category ((S\NP)/NP)/PP toits left, generalising over the two rightward ar-guments that were not specified by the functor?sargument.
It could not, however, compose intoa category like ((S\NP)\NP)/PP , because thetwo arguments (NP and PP ) have differing direc-1http://www.nltk.org447Freq.
From To Examples1056 VBG IN including, according, following379 VBN JJ involved, related, concerned351 VBN IN compared, based, given274 VBG NN trading, spending, restructuring140 VBZ NN is, ?s, has102 VB VBP sell, let, have53 VBZ MD does, is, has45 VBG JJ pending, missing, misleading41 VBP MD do, are, have40 VBD MD did, were, was334 All others2,815 TotalTable 3: The most frequent POS tag conversions.tionalities (leftward and rightward).Without this restriction, we would only requireone inflection category per feature, using inflec-tional categories like S [ng ]\S [b].
Instead, our in-flectional categories must subcategorise for everyargument except the outermost directionally con-sistent sequence.
We discard this outermost con-sistent sequence, remove all features, and use theresulting category as the argument and result.
Wethen restore the result?s feature, and set the argu-ment?s feature to [b].Inserting inflectional tokens: Finally, the in-flectional token is inserted after the verb, with anew node introduced to preserve binarisation.3.2 POS tag correctionsHockenmaier and Steedman (2007) corrected sev-eral classes of POS tag errors in the Penn Treebankwhen creating CCGbank.
We follow Clark andCurran (2007) in using their corrected POS labels,but found that there were still some words with in-consistent POS tags and lexical categories, such asbuilding|NN|(S[dcl]\NP)/NP.In order to make our morphological anal-ysis more consistent, we identify and correctsuch POS tagging errors as follows.
Weuse two regular expressions to identify ver-bal lexical categories and verbal POS tags:?\(*S\[(dcl|pss|ng|pt|b)\] andAUX|MD|V.. respectively.
If a word has averbal lexical category and non-verbal POS, wecorrect its POS tag with reference to its suffix andits category?s inflectional feature.
If a word has averbal POS tag and a non-verbal lexical category,we select the POS tag that occurs most frequentlywith its lexical category.The only exception are verbs functioning asnominal modifiers, such as running in the runningman, which are generally POS tagged VBG but re-ceive a lexical category of N /N .
We leave thesePOS tagged as verbs, and instead analyse theirsuffixes as performing a form-function transfor-mation that turns them from S [b]\NP verbs intoN /N adjectives ?
(N /N )\(S [b]\NP).Table 3 lists the most common before-and-after POS tag pairs from our corrections, and thewords that most frequently exemplified the pair.When compiling the table some clear errors cameto light, such as the ?correction?
of is|VBZ tois|NN.
These errors may explain why the POStagger?s accuracy drops by 0.1% on the correctedset, and suggest that the problem of aligning POStags and supertags is non-trivial.In light of these errors, we experimentedwith an alternate strategy.
Instead of cor-recting the POS tags, we introduced nullinflectional categories that compensatedfor bad morphological tokenisation such asaccord|VBG|(S/S)/PP -ing|VIG|-.The null inflectional category does not interactwith the rest of the derivation, much like a punc-tuation symbol.
This performed little better thanthe baseline, showing that the POS tag correctionsmade an important contribution, despite theproblems with our technique.3.3 Impact on CCGbank LexiconVerbal categories in CCGbank (Hockenmaier andSteedman, 2007) record both the valency and theinflectional morphology of the verb they are as-signed to.
This means v ?
i categories are re-quired, where v and i are the number of distinct ar-gument structures and inflectional features in thegrammar respectively.The inflectional tokens we propose allow in-flectional morphology to be largely factored awayfrom the argument structure, so that roughly v+ iverbal categories are required.
A smaller categoryset leads to lower category ambiguity, making theassignment decision easier.Table 4 summarises the effects of inflection cat-egories on the lexicon extracted from CCGbank.Clark and Curran (2007) extract a set of 425 cate-gories from the training data (Sections 02-21) that448consists of all categories that occur at least 10times.
The frequency cut off is used because themodel will not have sufficient evidence to assignthe other 861 categories that occur at least once,and their distribution is heavy tailed: together,they only occur 1,426 times.
We refer to the fre-quency filtered set as the lexicon.
The parser can-not assign a category outside its lexicon, so gapsin it cause under-generation.The CCGbank lexicon includes 159 verbal cat-egories.
There are 74 distinct argument structuresand 5 distinct features among these verbal cate-gories.
The grammar Clark and Curran (2007)learn therefore under-generates, because 211 ofthe 370 (5 ?
74) argument structure and featurecombinations are rare or unattested in the trainingdata.
For instance, there is a (S [dcl ]\NP)/PPcategory, but no corresponding (S [b]\NP)/PP ,making it impossible for the grammar to generatea sentence like I want to talk to you, as the cor-rect category for talk in this context is missing.
Itwould be trivial to add the missing categories tothe lexicon, but a statistical model would be un-able to reproduce them.
There are 8 occurrencesof such missing categories in Section 00, the de-velopment data.The reduction in data sparsity brought by the in-flection categories causes 22 additional argumentstructures to cross the frequency threshold intothe lexicon.
A grammar induced from this cor-pus is thus able to generate 480 (96?5) argumentstructure and feature combinations, three times asmany as could be generated before.We introduce 15 inflectional categories in thecorpus.
The ten most frequent are shown in Table1.
The combinatory rules allow these 15 inflectioncategories to serve 96 argument structures, reduc-ing the number of verbal categories in the lexiconfrom 159 to 89 (74 + 15).The statistics at frequency 1 are less reliable,because many of the categories may be linguisti-cally spurious: they may be artefacts caused byannotation noise in the Penn Treebank, or theconversion heuristics used by Hockenmaier andSteedman (2007).?
CCGbank +InflectInflection categories 10 0 15Argument structures 10 74 96Verb categories generated 10 159 480All categories 10 425 375Inflection categories 1 0 31Argument structures 1 283 283Verbs categories generated 1 498 1415All categories 1 1285 1120Table 4: Effect of inflection tokens on the category set forcategories with frequency ?
10 and ?
13.4 Configuration of parsing experimentsWe conducted two sets of parsing experiments,comparing the impact of inflectional tokens onCCGbank (Hockenmaier and Steedman, 2007)and hat CCGbank (Honnibal and Curran, 2009).The experiments allow us to gauge the impact ofinflectional tokens on versions of CCGbank withdiffering numbers of verbal categories.We used revision 1319 of the C&C parser2(Clark and Curran, 2007), using the best-performing configuration they describe, whichused the hybrid dependency model.
The mostimportant hyper-parameters in their configurationare the ?
and K values, which control the work-flow between the supertagger and parser.
We usethe Honnibal and Curran (2009) values of theseparameters in our hat category experiments, de-scribed in Section 5.Accuracy was evaluated using labelled depen-dency F -scores (LF ).
CCG dependencies are la-belled by the head?s lexical category and the ar-gument slot that the dependency fills.
We evalu-ated the baseline and inflection parsers on the un-modified dependencies, to allow direct compari-son.
For the inflection parsers, we pre-processedthe POS-tagged input to introduce inflection to-kens, and post-processed it to remove them.We follow Clark and Curran (2007) in notevaluating accuracy over sentences for which theparser returned no analysis.
The percentage ofsentences analysed is described as the parser?scoverage (C).
Speed (S) figures refer to sentencesparsed per second (including failures) on a dual-CPU Pentium 4 Xeon with 4GB of RAM.2http://trac.ask.it.usyd.edu.au/candc4494 Parsing Results on CCGbankTable 5 compares the performance of the parseron Sections 00 and 23 with and without inflectiontokens.
Section 00 was used for development ex-periments to test different approaches, and Section23 is the test data.
Similar effects were observedon both evaluation sections.The inflection tokens had no significant impacton speed or coverage, but did improve accuracyby 0.49% F -measure when gold standard POStags were used, compared to the baseline.
How-ever, some of the accuracy improvement can beattributed to the POS tag corrections described inSection 3.2, so the improvement from the inflec-tion tokens alone was 0.39%.The POS tag corrections caused a large drop inperformance when automatic POS tags were used.We attribute this to the imperfections in our cor-rection strategy.
The inflection tokens improvedthe accuracy by 0.39%, but this was not largeenough to correct for the drop in accuracy causedby the POS changes.Another possibility is that our morphologicalanalysis makes POS tagger errors harder to re-cover from.
Instead of an incorrect feature value,POS tag errors can now induce poor morphologi-cal splits such as starl|VBG -ing|VIG.
POStagging errors are already problematic for the C&Cparser, because only the highest ranked tag isforwarded to the supertagger as a feature.
Ourmorphological analysis strategy seems to exacer-bate this error propagation problem.
Curran et al(2006) showed that using a beam of POS tags asfeatures in the supertagger and parser mitigatedthe loss of accuracy from POS tagging errors.
Un-fortunately, with our morphological analysis strat-egy, POS tag variations change the tokenisationof a sentence, making parsing more complicated.Perhaps the best solution would be to address thetagging errors in the treebank more thoroughly,and reform the annotation scheme to deal withparticularly persistant error cases.
This might im-prove POS tag accuracy to a level where errors arerare enough to be unproblematic.Despite the limited morphology in English, theinflectional tokens improved the parser?s accuracywhen gold standard POS tags were supplied.
WeGold POS Auto POSLF S C LF S CBaseline 00 87.19 22 99.22 85.28 24 99.11+POS 00 87.46 24 99.16 85.04 23 99.05+Inflect 00 87.81 24 99.11 85.33 23 98.95Baseline 23 87.69 36 99.63 85.50 36 99.58+POS 23 87.79 36 99.63 85.06 36 99.50+Inflect 23 88.18 36 99.58 85.42 33 99.34Table 5: Effect of POS changes and inflection tokens onaccuracy (LF ), speed (S) and coverage (C) on 00 and 23.attribute the increase in accuracy to the more ef-ficient word-to-category mapping caused by re-placing inflected forms with lemmas, and feature-bearing verb categories with ones that only refer tothe argument structure.
We examined this hypoth-esis by performing a further experiment, to inves-tigate how inflection tokens interact with hat cat-egories, which introduce additional verbal cate-gories that represent form-function discrepancies.5 Inflection Tokens and Hat CategoriesHonnibal and Curran (2009) introduce an exten-sion to the CCG formalism, hat categories, as analternative way to solve the modifier category pro-liferation (MCP) problem.
MCP is caused whena modifier is itself modified by another modi-fier.
For instance, in the sentence he was in-jured running with scissors, with modifies run-ning, which modifies injured.
This produces thecategory ((VP\VP)\(VP\VP))/NP for with, arare category that is sensitive to too much of thesentence?s structure.Hockenmaier and Steedman (2007) addressMCP by adding type-changing rules to CCGbank.These type-changing rules transform specific cat-egories.
They are specific to the analyses in thecorpus, unlike the standard combinators, whichare schematic and language universal.
Honnibaland Curran?s (2009) contribution is to extend theformalism to allow these type-changing rules tobe lexically specified, restoring universality to thegrammar ?
but at the cost of sparse data problemsin the lexicon.
Figure 2 shows how a reduced rel-ative clause is analysed using hat categories.
Thehat category (S [pss]\NP)NP\NP is subject to theunhat rule, which unarily replaces it with its hat,NP\NP , allowing it to function as a modifier.Hat categories have a practical advantage for aparser that uses a supertagging phase (Bangalore450The company bought by Google last year is profitableNP/N N (S [pss]\NP)NP\NP (VP\VP)/NP NP NPVP\VP/N N (S [dcl ]\NP)/ADJ ADJ> > > >NP VP\VP NPVP\VP S [dcl ]\NP<(S [pss]\NP)NP\NP<(S [pss]\NP)NP\NPHNP\NP<NP<S [dcl ]Figure 2: CCG derivation showing hat categories and the unhat rule.The company buy ?ed by Google last yearNP/N N S [b]\NP (S [pss]\NP)NP\NP\(S [b]\NP) (VP\VP)/NP NP NPVP\VP/N N> < > >NP (S [pss]\NP)NP\NP VP\VP NPVP\VP< H(S [pss]\NP)NP\NP VP\VP<(S [pss]\NP)NP\NPHNP\NP<NPFigure 3: CCG derivation showing how inflectional tokens interact with hat categories.and Joshi, 1999), such as the C&C system (Clarkand Curran, 2007).
By replacing type-changingrules with additional lexical categories, more ofthe work is shifted to the supertagger.
The su-pertagging phase is much more efficient than thechart parsing stage, so redistribution of labourmakes the parser considerably faster.Honnibal and Curran (2009) found that theparser was 37% faster on the test set, at a costof 0.5% accuracy.
They attribute the drop in ac-curacy to sparse data problems for the supertag-ger, due to the increase in the number of lexicalcategories.
We hypothesised that inflectional cate-gories could address this problem, as the two anal-yses interact well.5.1 Analyses with inflectional hat categoriesUsing hat categories to lexicalise type-changingrules offers attractive formal properties, and somepractical advantages.
However, it also missessome generalisations.
A type-changing operationsuch as S [ng ]\NP ?
NP\NP must be avail-able to any VP.
If we encounter a new word, Thecompany is blagging its employees, we can gen-eralise to the reduced relative form, She works forthat company blagging its employees with no ad-ditional information.This property could be preserved with someform of lexical rule, but a novel word-categorypair is difficult for a statistical model to assign.Inflection tokens offer an attractive solution to thisproblem, as shown in Figure 3.
Assigning the hatcategory to the suffix makes it available to anyverb the suffix follows ?
it is just another func-tion the inflectional suffix can perform.
This gen-erality also makes it much easier to learn, becauseit does not matter whether the training data hap-pens to contain examples of a given verb perfom-ing that grammatical function.We prepared a version of the Honnibal andCurran (2009) hat CCGbank, moving hats on toinflectional categories wherever possible.
Thehat CCGbank?s lexicon contained 105 hat cate-gories, of which 77 were assigned to inflectedverbs.
We introduced 33 inflection hat cate-gories in their place, reducing the number ofhat categories by 27.9%.
Fewer hat categorieswere required because different argument struc-tures could be served by the same inflection cat-egory.
For instance, the (S [ng ]\NP)NP\NP and(S [ng ]\NP)NP\NP/NP categories were both re-placed by the (S [ng ]\NP)NP\NP\(S [b]\NP)category.
Table 6 lists the most frequent inflectionhat categories we introduce.451Freq.
Category3332 (S [pss]\NP)NP\NP\(S [b]\NP)1518 (S [ng ]\NP)NP\NP\(S [b]\NP)1231 (S [ng ]\NP)(S\NP)\(S\NP)\(S [b]\NP)360 ((S [dcl ]\NP)/NP)NP\NP\((S [b]\NP)/NP)316 (S [ng ]\NP)NP\(S [b]\NP)234 ((S [dcl ]\NP)/S)S/S\((S [b]\NP)/S)209 (S [ng ]\NP)S/S\(S [b]\NP)162 (S [dcl ]NP\NP\NP)\(S [b]\NP)157 ((S [dcl ]\NP)/S)VP/VP\((S [b]\NP)/S)128 (S [pss]\NP)S/S\(S [b]\NP)Table 6: The most frequent inflection hat categories.5.2 Parsing resultsTable 7 shows the hat parser?s performance withand without inflectional categories.
We used thevalues for the ?
and K hyper-parameters de-scribed by Honnibal and Curran (2009).
Thesehyper-parameters were tuned on Section 00, andsome over-fitting seems apparent.
We also fol-lowed their dependency conversion procedure, toallow evaluation over the original CCGbank de-pendencies and thus direct comparison with Table5.
We also merged the parser changes they de-scribed into the development version of the C&Cparser we are using, for parse speed comparison.Interestingly, incorporating the hat changes intothe current version has increased the advantageof the hat categories.
Honnibal and Curran re-port a 37% improvement in speed for the hybridmodel (which we are using) on Section 23, usinggold standard POS tags.
With our version of theparser, the improvement is 86% (36 vs. 67 sen-tences parsed per second).With gold standard POS tags, the inflection to-kens improved the hat parser?s accuracy by 0.8%,but decreased its speed by 24%.
We attributethe decrease in speed to the increase in sentencelength coupled with the new uncertainty on theinflectional tokens.
Coverage increased slightlywith gold standard POS tags, but decreased withautomatic POS tags.
We attribute this to the factthat POS tagging errors lead to morphologicalanalysis errors.The accuracy improvement on the hat corpuswas more robust to POS tagging errors than theCCGbank results, however.
This may be be-cause POS tagging errors are already quite prob-lematic for the hat category parser.
POS tag fea-Gold POS Auto POSLF S C LF S CHat baseline 00 87.08 32 99.53 84.67 34 99.32Hat inflect 00 87.85 37 99.63 84.99 30 98.95Hat baseline 23 87.26 67 99.50 84.93 53 99.58Hat inflect 23 88.06 54 99.63 85.25 43 99.38Table 7: Effect of inflection tokens on accuracy (LF ),speed (S) and coverage (C) on Sections 00 and 23.tures are more important for the supertagger thanthe parser, and the supertagger performs more ofthe work for the hat parser.6 ConclusionLexicalised formalisms like CCG (Steedman,2000) and HPSG (Pollard and Sag, 1994) haveled to high-performance statistical parsers of En-glish, such as the C&C CCG parser (Clark andCurran, 2007) and the ENJU HPSG (Miyao andTsuji, 2008) parser.
The performance of theseparsers can be partially attributed to their theoret-ical foundations.
This is particularly true of theC&C parser, which exploits CCG?s lexicalisationto divide the parsing task between two integratedmodels (Clark and Curran, 2004).We have followed this formalism-driven ap-proach by exploiting morphology for English syn-tactic parsing, using a strategy designed for mor-phologically rich languages.
Combining our tech-nique with hat categories leads to a 20% improve-ment in efficiency, with a 0.25% loss of accuracy.If the POS tag error problem were addressed, thetwo strategies combined would improve efficiencyby 50%, and improve accuracy by 0.37%.
Theseresults illustrate that linguistically motivated solu-tions can produce substantial practical advantagesfor language technologies.AcknowledgmentsWe would like to thank the anonymous reviewersfor their feedback, and the members of the CCG-technicians mailing list for discussion about someof our analyses.
Matthew Honnibal was supportedby Australian Research Council (ARC) DiscoveryGrant DP0665973.
James Curran was supportedby ARC Discovery grant DP1097291 and the Cap-ital Markets Cooperative Research Centre.452ReferencesSrinivas Bangalore and Aravind Joshi.
1999.
Su-pertagging: An approach to almost parsing.Computational Linguistics, 25(2):237?265.Ann Bies, Mark Ferguson, Karen Katz, andRobert MacIntyre.
1995.
Bracketing guidelinesfor Treebank II style Penn Treebank project.Technical report, MS-CIS-95-06, University ofPennsylvania, Philadelphia, PA, USA.Cem Bozsahin.
2002.
The combinatory mor-phemic lexicon.
Computational Linguistics,28(2):145?186.Miriam Butt, Mary Dalrymple, and Tracy H.King, editors.
2006.
CSLI Publications, Stan-ford, CA.Jeongwon Cha, Geunbae Lee, and JonghyeokLee.
2002.
Korean Combinatory CategorialGrammar and statistical parsing.
Computersand the Humanities, 36(4):431?453.Stephen Clark and James R. Curran.
2004.
Theimportance of supertagging for wide-coverageCCG parsing.
In Proceedings of 20th Interna-tional Conference on Computational Linguis-tics, pages 282?288.
Geneva, Switzerland.Stephen Clark and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCGand log-linear models.
Computational Linguis-tics, 33(4):493?552.James R. Curran, Stephen Clark, and DavidVadas.
2006.
Multi-tagging for lexicalized-grammar parsing.
In Proceedings of the JointConference of the International Committee onComputational Linguistics and the Associationfor Computational Linguistics, pages 697?704.Sydney, Austrailia.Julia Hockenmaier and Mark Steedman.
2007.CCGbank: a corpus of CCG derivationsand dependency structures extracted from thePenn Treebank.
Computational Linguistics,33(3):355?396.Matthew Honnibal and James R. Curran.
2009.Fully lexicalising CCGbank with hat cate-gories.
In Proceedings of the 2009 Conferenceon Empirical Methods in Natural LanguageProcessing, pages 1212?1221.
Singapore.Yusuke Miyao and Jun?ichi Tsuji.
2008.
Featureforest models for probabilistic HPSG parsing.Computational Linguistics, 34(1):35?80.Stepan Oepen, Daniel Flickenger, KristinaToutanova, and Christopher D. Manning.
2004.LinGO Redwoods.
a rich and dynamic treebankfor HPSG.
Research on Language and Compu-tation, 2(4):575?596.Carl Pollard and Ivan Sag.
1994.
Head-DrivenPhrase Structure Grammar.
The University ofChicago Press, Chicago.Stuart M. Shieber.
1986.
An Introduction toUnification-Based Approaches to Grammar,volume 4 of CSLI Lecture Notes.
CSLI Pub-lications, Stanford, CA.Mark Steedman.
2000.
The Syntactic Process.The MIT Press, Cambridge, MA, USA.453
