Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 97?102,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsPLIS: a Probabilistic Lexical Inference SystemEyal Shnarch1, Erel Segal-haLevi1, Jacob Goldberger2, Ido Dagan11Computer Science Department, Bar-Ilan University, Israel2Faculty of Engineering, Bar-Ilan University, Israel{shey,erelsgl,dagan}@cs.biu.ac.ilgoldbej@eng.biu.ac.ilAbstractThis paper presents PLIS, an open sourceProbabilistic Lexical Inference Systemwhich combines two functionalities: (i)a tool for integrating lexical inferenceknowledge from diverse resources, and (ii)a framework for scoring textual inferencesbased on the integrated knowledge.
Weprovide PLIS with two probabilistic im-plementation of this framework.
PLIS isavailable for download and developers oftext processing applications can use it asan off-the-shelf component for injectinglexical knowledge into their applications.PLIS is easily configurable, componentscan be extended or replaced with user gen-erated ones to enable system customiza-tion and further research.
PLIS includesan online interactive viewer, which is apowerful tool for investigating lexical in-ference processes.1 Introduction and backgroundSemantic Inference is the process by which ma-chines perform reasoning over natural languagetexts.
A semantic inference system is expected tobe able to infer the meaning of one text from themeaning of another, identify parts of texts whichconvey a target meaning, and manipulate text unitsin order to deduce new meanings.Semantic inference is needed for many NaturalLanguage Processing (NLP) applications.
For in-stance, a Question Answering (QA) system mayencounter the following question and candidateanswer (Example 1):Q: which explorer discovered the New World?A: Christopher Columbus revealed America.As there are no overlapping words between thetwo sentences, to identify that A holds an answerfor Q, background world knowledge is neededto link Christopher Columbus with explorer andAmerica with New World.
Linguistic knowledgeis also needed to identify that reveal and discoverrefer to the same concept.Knowledge is needed in order to bridge the gapbetween text fragments, which may be dissimilaron their surface form but share a common mean-ing.
For the purpose of semantic inference, suchknowledge can be derived from various resources(e.g.
WordNet (Fellbaum, 1998) and others, de-tailed in Section 2.1) in a form which we denote asinference links (often called inference/entailmentrules), each is an ordered pair of elements in whichthe first implies the meaning of the second.
For in-stance, the link ship?vessel can be derived fromthe hypernym relation of WordNet.Other applications can benefit from utilizing in-ference links to identify similarity between lan-guage expressions.
In Information Retrieval, theuser?s information need may be expressed in rele-vant documents differently than it is expressed inthe query.
Summarization systems should identifytext snippets which convey the same meaning.Our work addresses a generic, application in-dependent, setting of lexical inference.
We there-fore adopt the terminology of Textual Entailment(Dagan et al 2006), a generic paradigm for ap-plied semantic inference which captures inferenceneeds of many NLP applications in a common un-derlying task: given two textual fragments, termedhypothesis (H) and text (T ), the task is to recog-nize whether T implies the meaning of H , denotedT?H.
For instance, in a QA application, H rep-resents the question, and T a candidate answer.
Inthis setting, T is likely to hold an answer for thequestion if it entails the question.It is challenging to properly extract the neededinference knowledge from available resources,and to effectively utilize it within the inferenceprocess.
The integration of resources, each has itsown format, is technically complex and the quality97?Lexical InferenceLexical Integrator?
?
?
?WordNetWikipediaVerbOceanTextHypothesis ?1 ?2 ?3 ?4?1 ?3?(?
?
?3)?2??LexicalResources?
(?3 ?
?2)Figure 1: PLIS schema - a text-hypothesis pair is processedby the Lexical Integrator which uses a set of lexical resourcesto extract inference chains which connect the two.
The Lexi-cal Inference component provides probability estimations forthe validity of each level of the process.of the resulting inference links is often unknown inadvance and varies considerably.
For coping withthis challenge we developed PLIS, a Probabilis-tic Lexical Inference System1.
PLIS, illustrated inFig 1, has two main modules: the Lexical Integra-tor (Section 2) accepts a set of lexical resourcesand a text-hypothesis pair, and finds all the lex-ical inference relations between any pair of textterm ti and hypothesis term hj , based on the avail-able lexical relations found in the resources (andtheir combination).
The Lexical Inference module(Section 3) provides validity scores for these rela-tions.
These term-level scores are used to estimatethe sentence-level likelihood that the meaning ofthe hypothesis can be inferred from the text, thusmaking PLIS a complete lexical inference system.Lexical inference systems do not look into thestructure of texts but rather consider them as bagof terms (words or multi-word expressions).
Thesesystems are easy to implement, fast to run, practi-cal across different genres and languages, whilemaintaining a competitive level of performance.PLIS can be used as a stand-alone efficient in-ference system or as the lexical component of anyNLP application.
PLIS is a flexible system, al-lowing users to choose the set of knowledge re-sources as well as the model by which inference1The complete software package is available at http://www.cs.biu.ac.il/nlp/downloads/PLIS.html and an online in-teractive viewer is available for examination at http://irsrv2.cs.biu.ac.il/nlp-net/PLIS.html.is done.
PLIS can be easily extended with newknowledge resources and new inference models.
Itcomes with a set of ready-to-use plug-ins for manycommon lexical resources (Section 2.1) as wellas two implementation of the scoring framework.These implementations, described in (Shnarch etal., 2011; Shnarch et al 2012), provide probabil-ity estimations for inference.
PLIS has an inter-active online viewer (Section 4) which provides avisualization of the entire inference process, and isvery helpful for analysing lexical inference mod-els and lexical resources usability.2 Lexical integratorThe input for the lexical integrator is a set of lex-ical resources and a pair of text T and hypothe-sis H .
The lexical integrator extracts lexical in-ference links from the various lexical resources toconnect each text term ti?T with each hypothesisterm hj ?H2.
A lexical inference link indicates asemantic relation between two terms.
It could bea directional relation (Columbus?navigator) or abidirectional one (car??
automobile).Since knowledge resources vary in their rep-resentation methods, the lexical integrator wrapseach lexical resource in a common plug-in inter-face which encapsulates resource?s inner repre-sentation method and exposes its knowledge as alist of inference links.
The implemented plug-insthat come with PLIS are described in Section 2.1.Adding a new lexical resource and integrating itwith the others only demands the implementationof the plug-in interface.As the knowledge needed to connect a pair ofterms, ti and hj , may be scattered across few re-sources, the lexical integrator combines inferencelinks into lexical inference chains to deduce newpieces of knowledge, such as Columbus resource1??????
?navigator resource2???????
explorer.
Therefore, the onlyassumption the lexical integrator makes, regardingits input lexical resources, is that the inferentiallexical relations they provide are transitive.The lexical integrator generates lexical infer-ence chains by expanding the text and hypothesisterms with inference links.
These links lead to newterms (e.g.
navigator in the above chain exampleand t?
in Fig 1) which can be further expanded,as all inference links are transitive.
A transitivity2Where i and j run from 1 to the length of the text andhypothesis respectively.98limit is set by the user to determine the maximallength for inference chains.The lexical integrator uses a graph-based rep-resentation for the inference chains, as illustratesin Fig 1.
A node holds the lemma, part-of-speechand sense of a single term.
The sense is the ordi-nal number of WordNet sense.
Whenever we donot know the sense of a term we implement themost frequent sense heuristic.3 An edge representsan inference link and is labeled with the semanticrelation of this link (e.g.
cytokine?protein is la-beled with the WordNet relation hypernym).2.1 Available plug-ins for lexical resourcesWe have implemented plug-ins for the follow-ing resources: the English lexicon WordNet(Fellbaum, 1998)(based on either JWI, JWNLor extJWNL java APIs4), CatVar (Habash andDorr, 2003), a categorial variations database,Wikipedia-based resource (Shnarch et al 2009),which applies several extraction methods to de-rive inference links from the text and structureof Wikipedia, VerbOcean (Chklovski and Pantel,2004), a knowledge base of fine-grained semanticrelations between verbs, Lin?s distributional simi-larity thesaurus (Lin, 1998), and DIRECT (Kotler-man et al 2010), a directional distributional simi-larity thesaurus geared for lexical inference.To summarize, the lexical integrator finds allpossible inference chains (of a predefined length),resulting from any combination of inference linksextracted from lexical resources, which link anyt, h pair of a given text-hypothesis.
Developerscan use this tool to save the hassle of interfac-ing with the different lexical knowledge resources,and spare the labor of combining their knowledgevia inference chains.The lexical inference model, described next,provides a mean to decide whether a given hypoth-esis is inferred from a given text, based on weigh-ing the lexical inference chains extracted by thelexical integrator.3 Lexical inferenceThere are many ways to implement an infer-ence model which identifies inference relationsbetween texts.
A simple model may consider the3This disambiguation policy was better than consideringall senses of an ambiguous term in preliminary experiments.However, it is a matter of changing a variable in the configu-ration of PLIS to switch between these two policies.4http://wordnet.princeton.edu/wordnet/related-projects/number of hypothesis terms for which inferencechains, originated from text terms, were found.
InPLIS, the inference model is a plug-in, similar tothe lexical knowledge resources, and can be easilyreplaced to change the inference logic.We provide PLIS with two implemented base-line lexical inference models which are mathemat-ically based.
These are two Probabilistic LexicalModels (PLMs), HN-PLM and M-PLM which aredescribed in (Shnarch et al 2011; Shnarch et al2012) respectively.A PLM provides probability estimations for thethree parts of the inference process (as shown inFig 1): the validity probability of each inferencechain (i.e.
the probability for a valid inference re-lation between its endpoint terms) P (ti ?
hj), theprobability of each hypothesis term to be inferredby the entire text P (T ?
hj) (term-level proba-bility), and the probability of the entire hypothesisto be inferred by the text P (T ?
H) (sentence-level probability).HN-PLM describes a generative process bywhich the hypothesis is generated from the text.Its parameters are the reliability level of each ofthe resources it utilizes (that is, the prior proba-bility that applying an arbitrary inference link de-rived from each resource corresponds to a valid in-ference).
For learning these parameters HN-PLMapplies a schema of the EM algorithm (Demp-ster et al 1977).
Its performance on the recog-nizing textual entailment task, RTE (Bentivogli etal., 2009; Bentivogli et al 2010), are in line withthe state of the art inference systems, includingcomplex systems which perform syntactic analy-sis.
This model is improved by M-PLM, which de-duces sentence-level probability from term-levelprobabilities by a Markovian process.
PLIS withthis model was used for a passage retrieval for aquestion answering task (Wang et al 2007), andoutperformed state of the art inference systems.Both PLMs model the following prominent as-pects of the lexical inference phenomenon: (i)considering the different reliability levels of theinput knowledge resources, (ii) reducing inferencechain probability as its length increases, and (iii)increasing term-level probability as we have moreinference chains which suggest that the hypothesisterm is inferred by the text.
Both PLMs only needsentence-level annotations from which they deriveterm-level inference probabilities.To summarize, the lexical inference module99?(?
?
?)?(???
??)?(?
?
??
)configuration1234Figure 2: PLIS interactive viewer with Example 1 demonstrates knowledge integration of multiple inference chains andresource combination (additional explanations, which are not part of the demo, are provided in orange).provides the setting for interfacing with the lexi-cal integrator.
Additionally, the module providesthe framework for probabilistic inference modelswhich estimate term-level probabilities and inte-grate them into a sentence-level inference deci-sion, while implementing prominent aspects oflexical inference.
The user can choose to applyanother inference logic, not necessarily probabilis-tic, by plugging a different lexical inference modelinto the provided inference infrastructure.4 The PLIS interactive systemPLIS comes with an online interactive viewer5 inwhich the user sets the parameters of PLIS, insertsa text-hypothesis pair and gets a visualization ofthe entire inference process.
This is a powerfultool for investigating knowledge integration andlexical inference models.Fig 2 presents a screenshot of the processing ofExample 1.
On the right side, the user configuresthe system by selecting knowledge resources, ad-justing their configuration, setting the transitivitylimit, and choosing the lexical inference model tobe applied by PLIS.After inserting a text and a hypothesis to theappropriate text boxes, the user clicks on the in-fer button and PLIS generates all lexical inferencechains, of length up to the transitivity limit, thatconnect text terms with hypothesis terms, as avail-able from the combination of the selected input re-5http://irsrv2.cs.biu.ac.il/nlp-net/PLIS.htmlsources.
Each inference chain is presented in a linebetween the text and hypothesis.PLIS also displays the probability estimationsfor all inference levels; the probability of eachchain is presented at the end of its line.
For eachhypothesis term, term-level probability, whichweighs all inference chains found for it, is givenbelow the dashed line.
The overall sentence-levelprobability integrates the probabilities of all hy-pothesis terms and is displayed in the box at thebottom right corner.Next, we detail the inference process of Exam-ple 1, as presented in Fig 2.
In this QA example,the probability of the candidate answer (set as thetext) to be relevant for the given question (the hy-pothesis) is estimated.
When utilizing only twoknowledge resources (WordNet and Wikipedia),PLIS is able to recognize that explorer is inferredby Christopher Columbus and that New World isinferred by America.
Each one of these pairs hastwo independent inference chains, numbered 1?4,as evidence for its inference relation.Both inference chains 1 and 3 include a singleinference link, each derived from a different rela-tion of the Wikipedia-based resource.
The infer-ence model assigns a higher probability for chain1 since the BeComp relation is much more reliablethan the Link relation.
This comparison illustratesthe ability of the inference model to learn how todiffer knowledge resources by their reliability.Comparing the probability assigned by the in-100ference model for inference chain 2 with the prob-abilities assigned for chains 1 and 3, reveals thesophisticated way by which the inference modelintegrates lexical knowledge.
Inference chain 2is longer than chain 1, therefore its probability islower.
However, the inference model assigns chain2 a higher probability than chain 3, even thoughthe latter is shorter, since the model is sensitiveenough to consider the difference in reliability lev-els between the two highly reliable hypernym re-lations (from WordNet) of chain 2 and the less re-liable Link relation (from Wikipedia) of chain 3.Another aspect of knowledge integration is ex-emplified in Fig 2 by the three circled probabili-ties.
The inference model takes into considerationthe multiple pieces of evidence for the inferenceof New World (inference chains 3 and 4, whoseprobabilities are circled).
This results in a term-level probability estimation for New World (thethird circled probability) which is higher than theprobabilities of each chain separately.The third term of the hypothesis, discover, re-mains uncovered by the text as no inference chainwas found for it.
Therefore, the sentence-levelinference probability is very low, 37%.
In orderto identify that the hypothesis is indeed inferredfrom the text, the inference model should be pro-vided with indications for the inference of dis-cover.
To that end, the user may increase the tran-sitivity limit in hope that longer inference chainsprovide the needed information.
In addition, theuser can examine other knowledge resources insearch for the missing inference link.
In this ex-ample, it is enough to add VerbOcean to the in-put of PLIS to expose two inference chains whichconnect reveal with discover by combining an in-ference link from WordNet and another one fromVerbOcean.
With this additional information, thesentence-level probability increases to 76%.
Thisis a typical scenario of utilizing PLIS, either viathe interactive system or via the software, for ana-lyzing the usability of the different knowledge re-sources and their combination.A feature of the interactive system, which isuseful for lexical resources analysis, is that eachterm in a chain is clickable and links to anotherscreen which presents all the terms that are in-ferred from it and those from which it is inferred.Additionally, the interactive system communi-cates with a server which runs PLIS, in a full-duplex WebSocket connection6.
This mode of op-eration is publicly available and provides a methodfor utilizing PLIS, without having to install it orthe lexical resources it uses.Finally, since PLIS is a lexical system it caneasily be adjusted to other languages.
One onlyneeds to replace the basic lexical text processingtools and plug in knowledge resources in the tar-get language.
If PLIS is provided with bilingualresources,7 it can operate also as a cross-lingualinference system (Negri et al 2012).
For instance,the text in Fig 3 is given in English, while the hy-pothesis is written in Spanish (given as a list oflemma:part-of-speech).
The left side of the figuredepicts a cross-lingual inference process in whichthe only lexical knowledge resource used is a man-ually built English-Spanish dictionary.
As can beseen, two Spanish terms, jugador and casa remainuncovered since the dictionary alone cannot con-nect them to any of the English terms in the text.As illustrated in the right side of Fig 3,PLIS enables the combination of the bilingualdictionary with monolingual resources to pro-duce cross-lingual inference chains, such as foot-baller hypernym??????
?player manual??????jugador.
Such in-ference chains have the capability to overcomemonolingual language variability (the first linkin this chain) as well as to provide cross-lingualtranslation (the second link).5 ConclusionsTo utilize PLIS one should gather lexical re-sources, obtain sentence-level annotations andtrain the inference model.
Annotations are avail-able in common data sets for task such as QA,Information Retrieval (queries are hypotheses andsnippets are texts) and Student Response Analysis(reference answers are the hypotheses that shouldbe inferred by the student answers).For developers of NLP applications, PLIS of-fers a ready-to-use lexical knowledge integratorwhich can interface with many common lexicalknowledge resources and constructs lexical in-ference chains which combine the knowledge inthem.
A developer who wants to overcome lex-ical language variability, or to incorporate back-ground knowledge, can utilize PLIS to inject lex-6We used the socket.io implementation.7A bilingual resource holds inference links which connectterms in different languages (e.g.
an English-Spanish dictio-nary can provide the inference link explorer?explorador).101Figure 3: PLIS as a cross-lingual inference system.
Left: the process with a single manual bilingual resource.
Right: PLIScomposes cross-lingual inference chains to increase hypothesis coverage and increase sentence-level inference probability.ical knowledge into any text understanding appli-cation.
PLIS can be used as a lightweight infer-ence system or as the lexical component of larger,more complex inference systems.Additionally, PLIS provides scores for infer-ence chains and determines the way to combinethem in order to recognize sentence-level infer-ence.
PLIS comes with two probabilistic lexicalinference models which achieved competitive per-formance levels in the tasks of recognizing textualentailment and passage retrieval for QA.All aspects of PLIS are configurable.
The usercan easily switch between the built-in lexical re-sources, inference models and even languages, orextend the system with additional lexical resourcesand new inference models.AcknowledgmentsThe authors thank Eden Erez for his help withthe interactive viewer and Miquel Espla` Gomisfor the bilingual dictionaries.
This work was par-tially supported by the European Community?s7th Framework Programme (FP7/2007-2013) un-der grant agreement no.
287923 (EXCITEMENT)and the Israel Science Foundation grant 880/12.ReferencesLuisa Bentivogli, Ido Dagan, Hoa Trang Dang, DaniloGiampiccolo, and Bernardo Magnini.
2009.
Thefifth PASCAL recognizing textual entailment chal-lenge.
In Proc.
of TAC.Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa TrangDang, and Danilo Giampiccolo.
2010.
The sixthPASCAL recognizing textual entailment challenge.In Proc.
of TAC.Timothy Chklovski and Patrick Pantel.
2004.
VerbO-cean: Mining the web for fine-grained semantic verbrelations.
In Proc.
of EMNLP.Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.
The PASCAL recognising textual entailmentchallenge.
In Lecture Notes in Computer Science,volume 3944, pages 177?190.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via theEM algorithm.
Journal of the royal statistical soci-ety, series [B], 39(1):1?38.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,Massachusetts.Nizar Habash and Bonnie Dorr.
2003.
A categorialvariation database for English.
In Proc.
of NAACL.Lili Kotlerman, Ido Dagan, Idan Szpektor, and MaayanZhitomirsky-Geffet.
2010.
Directional distribu-tional similarity for lexical inference.
Natural Lan-guage Engineering, 16(4):359?389.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In Proc.
of COLOING-ACL.Matteo Negri, Alessandro Marchetti, Yashar Mehdad,Luisa Bentivogli, and Danilo Giampiccolo.
2012.Semeval-2012 task 8: Cross-lingual textual entail-ment for content synchronization.
In Proc.
of Se-mEval.Eyal Shnarch, Libby Barak, and Ido Dagan.
2009.
Ex-tracting lexical reference rules from Wikipedia.
InProc.
of ACL.Eyal Shnarch, Jacob Goldberger, and Ido Dagan.
2011.Towards a probabilistic model for lexical entailment.In Proc.
of the TextInfer Workshop.Eyal Shnarch, Ido Dagan, and Jacob Goldberger.
2012.A probabilistic lexical model for ranking textual in-ferences.
In Proc.
of *SEM.Mengqiu Wang, Noah A. Smith, and Teruko Mita-mura.
2007.
What is the Jeopardy model?
A quasi-synchronous grammar for QA.
In Proc.
of EMNLP.102
