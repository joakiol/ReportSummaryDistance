Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 964?972,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsPredicting and Eliciting Addressee?s Emotion in Online DialogueTakayuki Hasegawa?GREE Inc.Minato-ku, Tokyo 106-6101, Japantakayuki.hasegawa@gree.netNobuhiro Kaji and Naoki YoshinagaInstitute of Industrial Science,the University of TokyoMeguro-ku, Tokyo 153-8505, Japan{kaji,ynaga}@tkl.iis.u-tokyo.ac.jpMasashi ToyodaInstitute of Industrial Science,the University of TokyoMeguro-ku, Tokyo 153-8505, Japantoyoda@tkl.iis.u-tokyo.ac.jpAbstractWhile there have been many attempts toestimate the emotion of an addresser fromher/his utterance, few studies have ex-plored how her/his utterance affects theemotion of the addressee.
This has mo-tivated us to investigate two novel tasks:predicting the emotion of the addresseeand generating a response that elicits aspecific emotion in the addressee?s mind.We target Japanese Twitter posts as asource of dialogue data and automaticallybuild training data for learning the pre-dictors and generators.
The feasibility ofour approaches is assessed by using 1099utterance-response pairs that are built byfive human workers.1 IntroductionWhen we have a conversation, we usually careabout the emotion of the person to whom wespeak.
For example, we try to cheer her/him upif we find out s/he feels down, or we avoid sayingthings that would trouble her/him.To date, the modeling of emotion in a dialoguehas extensively been studied in NLP as well as re-lated areas (Forbes-Riley and Litman, 2004; Ayadiet al, 2011).
However, the past attempts are vir-tually restricted to estimating the emotion of anaddresser1 from her/his utterance.
In contrast, fewstudies have explored how the emotion of the ad-dressee is affected by the utterance.
We considerthe insufficiency of such research to be fatal for?This work was conducted while the first author was agraduate student at the University of Tokyo.1We use the terms addresser/addressee rather than aspeaker/listener, because we target not spoken but online di-alogue.I have had a high fever for 3 days.JOYI hope you feel better soon.I have had a high fever for 3 days.SADNESSSorry, but you can?t join us today.Figure 1: Two example pairs of utterances and re-sponses.
Those responses elicit certain emotions,JOY or SADNESS, in the addressee?s mind.
The ad-dressee in this example refers to the left-hand user,who receives the response.computers to support human-human communica-tions or to provide a communicative man-machineinterface.With this motivation in mind, the paper inves-tigates two novel tasks: (1) prediction of the ad-dressee?s emotion and (2) generation of the re-sponse that elicits a prespecified emotion in the ad-dressee?s mind.2 In the prediction task, the systemis provided with a dialogue history.
For simplic-ity, we consider, as a history, an utterance and aresponse to it (Figure 1).
Given the history, thesystem predicts the addressee?s emotion that willbe caused by the response.
For example, the sys-tem outputs JOY when the response is I hope youfeel better soon, while it outputs SADNESS whenthe response is Sorry, but you can?t join us today2We adopt Plutchik (1980)?s eight emotional categories inboth tasks.964(Figure 1).In the generation task, on the other hand, thesystem is provided with an utterance and an emo-tional category such as JOY or SADNESS, which isreferred to as goal emotion.
Then the system gen-erates the response that elicits the goal emotion inthe addressee?s mind.
For example, I hope you feelbetter soon is generated as a response to I have hada high fever for 3 days when the goal emotion isspecified as JOY, while Sorry, but you can?t join ustoday is generated for SADNESS (Figure 1).Systems that can perform the two tasks not onlyserve as crucial components of dialogue systemsbut also have interesting applications of their own.Predicting the emotion of an addressee is use-ful for filtering flames or infelicitous expressionsfrom online messages (Spertus, 1997).
The re-sponse generator that is aware of the emotion ofan addressee is also useful for text completion inonline conversation (Hasselgren et al, 2003; Pangand Ravi, 2012).This paper explores a data-driven approach toperforming the two tasks.
With the recent emer-gence of social media, especially microblogs, theamount of dialogue data available is rapidly in-creasing.
Therefore, we are taking this opportu-nity to building large-scale training data from mi-croblog posts automatically.
This approach allowsus to perform the two tasks in a large-scale withlittle human effort.We employ standard classifiers for predictingthe emotion of an addressee.
Our contribution hereis to investigate the effectiveness of new featuresthat cannot be used in ordinary emotion recog-nition, the task of estimating the emotion of aspeaker (or writer) from her/his utterance (or writ-ing) (Ayadi et al, 2011; Bandyopadhyay and Oku-mura, 2011; Balahur et al, 2011; Balahur et al,2012).
We specifically extract features from theaddressee?s last utterance (e.g., I have had a highfever for 3 days in Figure 1) and explore the effec-tiveness of using such features.
Such informationis characteristic of a dialogue situation.To perform the generation task, we build a sta-tistical response generator by following (Ritter etal., 2011).
To improve on the previous study, weinvestigate a method for controlling the contentsof the response for, in our case, eliciting the goalemotion.
We achieve this by using a technique in-spired by domain adaptation.
We learn multiplemodels, each of which is adapted for eliciting onespecific emotion.
Also, we perform model inter-polation for addressing data sparseness.In our experiment, we automatically build train-ing data consisting of over 640 million dialoguesfrom Japanese Twitter posts.
Using this data set,we train the classifiers that predict the emotionof an addressee, and the response generators thatelicit the goal emotion.
We evaluate our methodson the test data that are built by five human work-ers, and confirm the feasibility of the proposed ap-proaches.2 Emotion-tagged Dialogue CorpusThe key in making a supervised approach to pre-dicting and eliciting addressee?s emotion success-ful is to obtain large-scale, reliable training dataeffectually.
We thus automatically build a large-scale emotion-tagged dialogue corpus from mi-croblog posts, and use it as the training data in theprediction and generation tasks.This section describes a method for construct-ing the emotion-tagged dialogue corpus.
We firstdescribe how to extract dialogues from posts inTwitter, a popular microblogging service.
We thenexplain how to automatically annotate utterancesin the extracted dialogues with the addressers?emotions by using emotional expressions as clues.2.1 Mining dialogues from TwitterWe have first crawled utterances (posts) fromTwitter by using the Twitter REST API.3 Thecrawled data consist of 5.5 billion utterances inJapanese tweeted by 770 thousand users fromMarch 2011 to December 2012.
We next cleanedup the crawled utterances by handling Twitter-specific expressions; we replaced all URL stringsto ?URL?, excluded utterances with the symbolsthat indicate the re-posting (RT) or quoting (QT)of others?
tweets, and erased @user name ap-pearing at the head and tail of the utterances, sincethey are usually added to make a reply.
We ex-cluded utterances given by any user whose nameincluded ?bot.
?We then extracted dialogues from the resultingutterances, assuming that a series of utterancesinterchangeably made by two users form a dia-logue.
We here exploited ?in reply to status id?field of each utterance provided by Twitter RESTAPI to link to the other, if any, utterance to whichit replied.3https://dev.twitter.com/docs/api/965# users 672,937# dialogues 311,541,839# unique utterances 1,007,403,858ave.
# dialogues / user 463.0ave.
# utterances / user 1497.0ave.
# utterances / dialogue 3.2Table 1: Statistics of dialogues extracted fromTwitter.2,000,00040,000,00060,000,00080,000,000100,000,000120,000,000140,000,000160,000,000180,000,0000 2 3 4 5 6 7 8 9 10 11+#DialoguesDialogue length (# utterances in dialogue)Figure 2: The number of dialogues plotted againstthe dialogue length.Utterance EmotionA: Would you like to go for dinner with me?B: Sorry, I can?t.
I have a fever of 38 degrees.A: Oh dear.
I hope you feel better soon.
SURPRISEB: Thanks.
I?m happy to hear you say that.
JOYTable 2: An illustration of an emotion-tagged dia-logue: The first column shows a dialogue (a seriesof utterances interchangeably made by two users),while the second column shows the addresser?semotion estimated from the utterance.Table 1 lists the statistics of the extracted di-alogues, while Figure 2 plots the number of di-alogues plotted against the dialogue length (thenumber of utterances in dialogue).
Most dialogues(98.2%) consist of at most 10 utterances, althoughthe longest dialogue includes 1745 utterances andspans more than six weeks.2.2 Tagging utterances with addressers?emotionsWe then automatically labeled utterances in theobtained dialogues with the addressers?
emotionsby using emotional expressions as clues (Table 2).In this study, we have adopted Plutchik (1980)?seight emotional categories (ANGER, ANTICIPA-TION, DISGUST, FEAR, JOY, SADNESS, SUR-PRISE, and TRUST) as the targets to label, andmanually tailored around ten emotional expres-sions for each emotional category.
Table 3 listsexamples of the emotional expressions, while theEmotion Emotional expressionsANGER frustrating, irritating, nonsenseANTICIPATION exciting, expecting, looking forwardDISGUST disgusting, unpleasant, hateFEAR afraid, anxious, scaryJOY glad, happy, delightedSADNESS sad, lonely, unhappySURPRISE surprised, oh dear, wowTRUST relieved, reliable, solidTable 3: Example of clue emotional expressions.Emotion # utterances PrecisionWorker A Worker BANGER 190,555 0.95 0.95ANTICIPATION 2,548,706 0.99 0.99DISGUST 475,711 0.93 0.93FEAR 2,671,222 0.96 0.96JOY 2,725,235 0.94 0.96SADNESS 712,273 0.97 0.97SURPRISE 975,433 0.97 0.97TRUST 359,482 0.97 0.98Table 4: Size and precision of utterances labeledwith the addressers?
emotions.rest are mostly their spelling variations.4Because precise annotation is critical in the su-pervised learning scenario, we annotate utteranceswith the addressers?
emotions only when the emo-tional expressions do not:1. modify content words.2.
accompany an expression of negation, condi-tional, imperative, interrogative, concession,or indirect speech in the same sentence.For example, I saw a frustrated teacher is re-jected by the first condition, while I?ll be happyif it rains is rejected by the second condition.
Thesecond condition was judged by checking whetherthe sentence includes trigger expressions such as???
(not/never)?, ???
(if-clause)?, ??
?, ???
((al)though)?, and ??
(that-clause)?.Table 4 lists the size and precision of the utter-ances labeled with the addressers?
emotions.
Twohuman workers measured the precision of the an-notation by examining 100 labeled utterances ran-domly sampled for each emotional category.
Theinter-rater agreement was ?
= 0.85, indicating al-most perfect agreement.
The precision of the an-notation exceeded 0.95 for most of the emotionalcategories.4Note that the clue emotional expressions are language-specific but can be easily tailored for other languages.
Here,Japanese emotional expressions are translated into English towiden the potential readership of the paper.9663 Predicting Addressee?s EmotionThis section describes a method for predictingemotion elicited in an addressee when s/he re-ceives a response to her/his utterance.
The inputto this task is a pair of an utterance and a responseto it, e.g., the two utterances in Figure 1, whilethe output is the addressee?s emotion among theemotional categories of Plutchik (1980) (JOY andSADNESS for the top and bottom dialogues in Fig-ure 1, respectively).Although a response could elicit multiple emo-tions in the addressee, in this paper we focus onpredicting the most salient emotion elicited in theaddressee and cast the prediction as a single-labelmulti-class classification problem.5 We then con-struct a one-versus-the-rest classifier6 by combin-ing eight binary classifiers, each of which predictswhether the response elicits each emotional cate-gory.
We use online passive-aggressive algorithmto train the eight binary classifiers.We exploit the emotion-tagged dialogue corpusconstructed in Section 2 to collect training exam-ples for the prediction task.
For each emotion-tagged utterance in the corpus, we assume that thetagged emotion is elicited by the (last) response.We thereby extract the pair of utterances preced-ing the emotion-tagged utterance and the taggedemotion as one training example.
Taking the di-alogue in Table 2 as an example, we obtain onetraining example from the first two utterances andSURPRISE as the emotion elicited in user A.We extract all the n-grams (n ?
3) in the re-sponse to induce (binary) n-gram features.
Theextracted n-grams could indicate a certain actionthat elicits a specific emotion (e.g., ?have a fever?in Table 2), or a style or tone of speaking (e.g.,?Sorry?).
Likewise, we extract word n-grams fromthe addressee?s utterance.
The extracted n-gramsactivate another set of binary n-gram features.Because word n-grams themselves are likely tobe sparse, we estimate the addressers?
emotionsfrom their utterances and exploit them to induceemotion features.
The addresser?s emotion hasbeen reported to influence the addressee?s emotion5Because microblog posts are short, we expect emotionselicited by a response post not to be very diverse and a multi-class classification to be able to capture the essential crux ofthe prediction task.6We should note that a one-versus-the-rest classifier canbe used in the multi-label classification scenario, just by al-lowing the classifier to output more than one emotional cate-gory (Ghamrawi and McCallum, 2005).strongly (Kim et al, 2012), while the addressee?semotion just before receiving a response can be areference to predict her/his emotion in question af-ter receiving the response.To induce emotion features, we exploit the rule-based approach used in Section 2.2 to estimatethe addresser?s emotion.
Since the rule-based ap-proach annotates utterances with emotions onlywhen they contain emotional expressions, we in-dependently train for each emotional categorya binary classifier that estimates the addresser?semotion from her/his utterance and apply it to theunlabeled utterances.
The training data for theseclassifiers are the emotion-tagged utterances ob-tained in Section 2, while the features are n-grams(n ?
3)7 in the utterance.We should emphasize that the features inducedfrom the addressee?s utterance are unique to thistask and are hardly available in the related tasksthat predicted the emotion of a reader of news ar-ticles (Lin and Hsin-Yihn, 2008) or personal sto-ries (Socher et al, 2011).
We will later confirm theimpact of these features on the prediction accuracyin the experiments.4 Eliciting Addressee?s EmotionThis section presents a method for generating a re-sponse that elicits the goal emotion, which is oneof the emotional categories of Plutchik (1980), inthe addressee.
In section 4.1, we describe a statis-tical framework for response generation proposedby (Ritter et al, 2011).
In section 4.2, we presenthow to adapt the model in order to generate aresponse that elicits the goal emotion in the ad-dressee.4.1 Statistical response generationFollowing (Ritter et al, 2011), we apply the sta-tistical machine translation model for generating aresponse to a given utterance.
In this framework,a response is viewed as a translation of the inpututterance.
Similar to ordinary machine translationsystems, the model is learned from pairs of an ut-terance and a response by using off-the-shelf toolsfor machine translation.We use GIZA++8 and SRILM9 for learningtranslation model and 5-gram language model, re-7We have excluded n-grams that matched the emotionalexpressions used in Section 2 to avoid overfitting.8http://code.google.com/p/giza-pp/9http://www.speech.sri.com/projects/srilm/967spectively.
As post-processing, some phrase pairsare filtered out from the translation table as fol-lows.
When GIZA++ is directly applied to di-alogue data, it frequently finds paraphrase pairs,learning to parrot back the input (Ritter et al,2011).
To avoid using such pairs for response gen-eration, a phrase pair is removed if one phrase isthe substring of the other.We use Moses decoder10 to search for the bestresponse to a given utterance.
Unlike machinetranslation, we do not use reordering models, be-cause the positions of phrases are not consideredto correlate strongly with the appropriateness ofresponses (Ritter et al, 2011).
In addition, we donot use any discriminative training methods suchas MERT for optimizing the feature weights (Och,2003).
They are set as default values provided byMoses (Ritter et al, 2011).4.2 Model adaptationThe above framework allows us to generate appro-priate responses to arbitrary input utterances.
Ontop of this framework, we have developed a re-sponse generator that elicits a specific emotion.We use the emotion-tagged dialogue corpus tolearn eight translation models and language mod-els, each of which is specialized in generatingthe response that elicits one of the eight emo-tions (Plutchik, 1980).
Specifically, the modelsare learned from utterances preceding ones that aretagged with emotional category.
As an example,let us examine to learn models for eliciting SUR-PRISE from the dialogue in Table 2.
In this case,the first two utterances are used to learn the trans-lation model, while only the second utterance isused to learn the language model.However, this simple approach is prone to suf-fer from the data sparseness problem.
Becausenot all the utterances are tagged with the emotionin emotion-tagged dialogue corpus, only a smallfraction of utterances can be used for learning theadapted models.We perform model interpolation for addressingthis problem.
In addition to the adapted mod-els described above, we also use a general model,which is learned from the entire corpus.
The twomodels are then merged as the weighted linear in-terpolation.Specifically, we use tmcombine.py scriptprovided by Moses for the interpolation of trans-10http://www.statmt.org/moses/lation models (Sennrich, 2012).
For all the fourfeatures (i.e., two phrase translation probabilitiesand two lexical weights) derived from transla-tion model, the weights of the adapted model areequally set as ?
(0 ?
?
?
1.0).
On the otherhand, we use SRILM for the interpolation of lan-guage models.
The weight of the adapted model isset as ?
(0 ?
?
?
1.0).The parameters ?
and ?
control the strength ofthe adapted models.
Only adapted models are usedwhen ?
(or ?
)= 1.0, while the adapted models arenot at all used when ?
(or ?)
= 0.
When both ?and ?
are specified as 0, the model becomes equiv-alent to the original one described in section 4.1.5 Experiments5.1 Test dataTo evaluate the proposed method, we built, as testdata, sets of an utterance paired with responsesthat elicit a certain goal emotion (Table 5).
Notethat they were used for evaluation in both of thetwo tasks.
Each utterance in the test data hasmore than one responses that elicit the same goalemotion, because they are used to compute BLEUscore (see section 5.3).The data set was built in the following manner.We first asked five human worker to produce re-sponses to 80 utterances (10 utterances for eachgoal emotion).
Note that the 80 utterances do nothave overlap between workers and that the workerproduced only one response to each utterance.To alleviate the burden on the workers, we ac-tually provided each worker with the utterancesin the emotion-tagged corpus.
Then we askedeach worker to select 80 utterances to which s/hethought s/he could easily respond.
The selectedutterances were removed from the corpus duringtraining.As a result, we obtained 400 utterance-responsepairs (= 80 utterance-response pairs ?
5 work-ers).
For each of those 400 utterances, two ad-ditional responses are produced.
We did not al-low the same worker to produce more than oneresponse to the same utterance.
In this way, weobtained 1200 responses for the 400 utterances intotal.Finally, we assessed the data quality to removeresponses that were unlikely to elicit the goal emo-tion.
For each utterance-response pair, we askedtwo workers to judge whether the response elicitedthe goal emotion.
If both workers regarded the968Goal emotion: JOYU: 16????????????????????????
(I?m turning 16.
Hope to get alng with you aswell as ever!)R1:??????????????
(Happy birthday!)R2:?????????????????????(Congratulations!
I?ll give you a birthday present.)R3:???????????????(Congratulations!
I hope you have a happy year!
)Table 5: Example of the test data.
English transla-tions are attached in the parenthesis.Emotion # utterance pairsANGER 119,881ANTICIPATION 1,416,847DISGUST 333,972FEAR 1,662,998JOY 1,724,198SADNESS 436,668SURPRISE 589,790TRUST 228,974GENERAL 646,429,405Table 6: The number of utterance pairs usedfor training classifiers in emotion prediction andlearning the translation models and language mod-els in response generation.response as inappropriate, it was removed fromthe data.
The resulting test data consist of 1099utterance-response pairs for 396 utterances.This data set is submitted as supplementary ma-terial to support the reproducibility of our experi-mental results.5.2 Prediction taskWe first report experimental results on predictingthe addressee?s emotion within a dialogue.
Table 6lists the number of utterance-response pairs usedto train eight binary classifiers for individual emo-tional categories, which form a one-versus-the restclassifier for the prediction task.
We used opal11as an implementation of online passive-aggressivealgorithm to train the individual classifiers.To investigate the impact of the features that areuniquely available in a dialogue data, we com-pared classifiers trained with the following twosets of features in terms of precision, recall, andF1 for each emotional category.RESPONSE The n-gram and emotion features in-duced from the response.11http://www.tkl.iis.u-tokyo.ac.jp/?ynaga/opal/.Emotion RESPONSE RESPONSE/UTTER.PREC REC F1 PREC REC F1ANGER 0.455 0.476 0.465 0.600 0.548 0.573ANTICIPA.
0.518 0.526 0.522 0.614 0.637 0.625DISGUST 0.275 0.519 0.359 0.378 0.511 0.435FEAR 0.484 0.727 0.581 0.459 0.706 0.556JOY 0.690 0.417 0.519 0.720 0.590 0.649SADNESS 0.711 0.467 0.564 0.670 0.562 0.611SURPRISE 0.511 0.348 0.414 0.584 0.437 0.500TRUST 0.695 0.452 0.548 0.682 0.514 0.586average 0.542 0.492 0.497 0.588 0.563 0.567Table 7: Predicting addressee?s emotion: Results.PREDICTED EMOTIONANGERANTICIPA.DISGUSTFEARJOYSADNESSSURPRISETRUSTtotalANGER 69 0 26 20 0 8 2 1 126ANTICIPA.
1 86 11 7 13 0 6 11 135DISGUST 25 1 68 18 2 8 7 4 133FEAR 3 0 22 101 1 5 9 2 143JOY 1 28 9 4 85 1 7 9 144SADNESS 6 3 25 14 5 77 5 2 137SURPRISE 7 10 9 32 5 7 59 6 135TRUST 3 12 10 24 7 9 6 75 146CORRECTEMOTIONtotal 115 140 180 220 118 115 101 110 1099Table 8: Confusion matrix of predicting ad-dressee?s emotion, with mostly predicted emo-tions bold-faced and mostly confused emotionsunderlined for each emotional category.RESPONSE/UTTER.
The n-gram and emotionfeatures induced from the response and theaddressee?s utterance.Table 7 lists prediction results.
We can see thatthe features induced from the addressee?s utter-ance significantly improved the prediction perfor-mance, F1, for emotions other than FEAR.
FEAR iselicited instantly by the response, and the featuresinduced from the addressee?s utterance therebyconfused the classifier.Table 8 shows a confusion matrix of the classi-fier using all the features, with mostly predictedemotions bold-faced and mostly confused emo-tions underlined for each emotional category.
Wecan find some typical confusing pairs of emotionsfrom this matrix.
The classifier confuses DISGUSTwith ANGER and vice versa, while it confuses JOYwith ANTICIPATION.
These confusions conformto our expectation, since they are actually similaremotions.
The classifier was less likely to confusepositive emotions (JOY and ANTICIPATION) withnegative emotion (ANGER, DISGUST, FEAR, andSADNESS) vice versa.969Goal emotion: ANGER (predicted as SADNESS)U:????????????????
(You have phone calls every day, I envy you.)R:????????????????????????
(I envy you have a lot of time ?cause no one calls you.
)Goal emotion: SURPRISE (predicted as FEAR)U:????????????
(Is it true that dark-haired girls are popular with boys?)R:???????????????????
(About 80% of boys seem to prefer dark-haired girls.
)Table 9: Examples of utterance-response pairs towhich the system predicted wrong emotions.We have briefly examined the confusions andfound the two major types of errors, each of whichis exemplified in Table 9.
The first (top) one is sar-casm or irony, which has been reported to be diffi-cult to capture by lexical features alone (Gonza?lez-Iba?n?ez et al, 2011).
The other (bottom) one is dueto lack of information.
In this example, only if theaddressee does not know the fact provided by theresponse, s/he will surprise at it.5.3 Generation taskWe next demonstrate the experimental results foreliciting the emotion of the addressee.We use the utterance pairs summarized in Ta-ble 6 to learn the translation models and languagemodels for eliciting each emotional category.
Wealso use the 640 million utterances pairs in theentire emotion-tagged corpus for learning generalmodels.
However, for learning the general transla-tion models, we currently use 4 millions of utter-ance pairs sampled from the 640 millions of pairsdue to the computational limitation.Automatic evaluationWe first use BLEU score (Papineni et al, 2002)to perform automatic evaluation (Ritter et al,2011).
In this evaluation, the system is pro-vided with the utterance and the goal emotionin the test data and the generated responses areevaluated through BLEU score.
Specifically, weconducted two-fold cross-validation to optimizethe weights of our method.
We tried ?
and?
in {0.0, 0.2, 0.4, 0.6, 0.8, 1.0} and selected theweights that achieved the best BLEU score.
Notethat we adopted different values of the weights fordifferent emotional categories.Table 10 compares BLEU scores of three meth-ods including the proposed one.
The first rowrepresents a method that does not perform modeladaptation at all.
It corresponds to the special caseSystem BLEUNO ADAPTATION 0.64PROPOSED 1.05OPTIMAL 1.57Table 10: Comparison of BLEU scores.
(i.e., ?
= ?
= 0.0) of the proposed method.
Thesecond row represents our method, while the lastrow represents the result of our method when theweights are set as optimal, i.e., those achieving thebest BLEU on the test data.
This result can be con-sidered as an upper bound on BLEU score.The results demonstrate that model adaptationis useful for generating the responses that elicitthe goal emotion.
We can clearly observe the im-provement in the BLEU from 0.64 to 1.05.On the other hand, there still remains a gap be-tween the last two rows (i.e., proposed and opti-mal).
We think this is partly because the currenttest data is too small to reliably tune parameters.Human evaluationWe next asked two human workers to manuallyevaluate the generation results.In this evaluation, the baseline (no adaptationin Table 10) and proposed method generated a re-sponse for each of the 396 utterances in the testdata.
For the resulting 792 utterance-responsepairs, the two workers manually assessed the ap-propriateness of the response.
Each response wasjudged whether it is grammatical and meaningful.If the response was regarded as so by either of theworkers, it was further judged whether it elicits thegoal emotion or not.
To make the comparison fair,we did not expose to the workers which systemgenerated the response.
In addition, the responsesgenerated by the two systems were presented in arandom order.As the result, 147 and 157 responses of thebaseline and proposed method were regarded asappropriate, i.e., ecliting the goal emotion, by ei-ther of the workers; 74 and 92 responses wereregarded as appropirate by both of the workers.These results suggest the effectiveness of the pro-posed method.
Especially, we can confirm thatthe proposed method can generate responses thatelicit addresee?s emotion more clearly.
We inves-tigated the agreement between the two workers inthis evaluation.
We found that the ?
coefficient is0.59, which indicates moderate agreement.
Thissupports the reliability of our evaluation.970Goal emotion: JOYInput: ???????????????????2?
7?????
(I wooooon the outstanding award at the photo competition!
The ceremony is on Feb.
7!
)NO ADAPTATION: ??????????????
(Sorry to say, only the first day.
)PROPOSED: ????????????????????
(Congratulations on winning the gold prize!!!
Congrats.
)Goal emotion: TRUSTInput: ????????????
(Do you get desperate?
)NO ADAPTATION: ????
(I?m looking forward to it!
)PROPOSED: ????????
(Maybe still OK.)Goal emotion: ANTICIPATIONInput: ?????????????ww(Huh!
It?s gonna be all right!
lol)??????????????????????????????????
(???
)(I gotta buy the goods, so I?ll be glad if you can take the time :-))NO ADAPTATION: ?????????????????
(Since I?ve not bought it, I feel worried.
)PROPOSED: ????????????????
(Good!
I?ll buy it too!!!
)Table 11: Examples of the responses generated by the two systems, NO ADAPTATION and PROPOSED.ExamplesTable 11 illustrates examples of the responses gen-erated by the no adaptation baseline and proposedmethod.
In the first two examples, the proposedmethod successfully generates responses that elicitthe goal emotions: JOY and TRUST.
From theseexamples, we can consider that the adapted modelassigns large probability to phrases such as con-gratulations or OK.
In the last example, the sys-tem also succeeded in eliciting the goal emotion:ANTICIPATION.
For this example, we can interpretthat the speaker of the response (i.e., the system)feels anticipation, and consequently the emotionof the addressee is affected by the emotion of thespeaker (i.e., the system).
Interestingly, a similarphenomenon is also observed in real conversation(Kim et al, 2012).6 Related WorkThere have been a tremendous amount of stud-ies on predicting the emotion from text or speechdata (Ayadi et al, 2011; Bandyopadhyay and Oku-mura, 2011; Balahur et al, 2011; Balahur et al,2012).
Unlike our prediction task, most of themhave exclusively focused on estimating the emo-tion of a speaker (or writer) from her/his utterance(or writing).Analogous to our prediction task, Lin and Hsin-Yihn (2008) and Socher et al (2011) investigatedpredicting the emotion of a reader from the textthat s/he reads.
Our work differs from them in thatwe focus on dialogue data, and we exploit fea-tures that are not available within their task set-tings, e.g., the addressee?s previous utterance.Tokuhisa et al (2008) proposed a method forextracting pairs of an event (e.g., It rained sud-denly when I went to see the cherry blossoms) andan emotion elicited by it (e.g., SADNESS) from theWeb text.
The extracted data are used for emotionclassification.
A similar technique would be use-ful for prediction the emotion of an addressee aswell.Response generation has a long research history(Weizenbaum, 1966), although it is only very re-cently that a fully statistical approach was intro-duced in this field (Ritter et al, 2011).
At this mo-ment, we are unaware of any statistical responsegenerators that model the emotion of the user.Some researchers have explored generatingjokes or humorous text (Dybala et al, 2010;Labtov and Lipson, 2012).
Those attempts aresimilar to our work in that they also aim at elic-iting a certain emotion in the addressee.
They are,however, restricted to elicit a specific emotion.The linear interpolation of translation and/orlanguage models is a widely-used technique foradapting machine translation systems to new do-mains (Sennrich, 2012).
However, it has not beentouched in the context of response generation.7 Conclusion and Future WorkIn this paper, we have explored predicting andeliciting the emotion of an addressee by using alarge amount of dialogue data obtained from mi-croblog posts.
In the first attempt to model theemotion of an addressee in the field of NLP, wedemonstrated that the response of the dialoguepartner and the previous utterance of the addresseeare useful for predicting the emotion.
In the gen-eration task, on the other hand, we showed that the971model adaptation approach successfully generatesthe responses that elicit the goal emotion.For future work, we want to use longer dialoguehistory in both tasks.
While we considered onlytwo utterances as a history, a longer history wouldbe helpful.
We also plan to personalize the pro-posed methods, exploiting microblog posts madeby users of a certain age, gender, occupation, oreven character to perform model adaptation.AcknowledgmentThis work was supported by the FIRST program ofJSPS.
The authors thank the anonymous review-ers for their valuable comments.
The authors alsothank the student annotators for their hard work.ReferencesMoataz El Ayadi, Mohamed S. Kamel, and Fakhri Kar-ray.
2011.
Survey on speech emotion recognition:Features, classification schemes, and databases.Pattern Recognition, 44:572?587.Alexandra Balahur, Ester Boldrini, Andres Montoyo,and Patricio Martinez-Barco, editors.
2011.
Pro-ceedings of the 2nd Workshop on ComputationalApproaches to Subjectivity and Sentiment Analysis.Association for Computational Linguistics.Alexandra Balahur, Andres Montoyo, Patricio Mar-tinez Barco, and Ester Boldrini, editors.
2012.
Pro-ceedings of the 3rd Workshop on ComputationalApproaches to Subjectivity and Sentiment Analysis.Association for Computational Linguistics.Sivaji Bandyopadhyay and Manabu Okumura, editors.2011.
Proceedings of the Workshop on SentimentAnalysis where AI meets Psychology.
Asian Federa-tion of Natural Language Processing.Pawel Dybala, Michal Ptaszynski, Jacek Maciejewski,Mizuki Takahashi, Rafal Rzepka, and Kenji Araki.2010.
Multiagent system for joke generation: Hu-mor and emotions combined in human-agent conver-sation.
Journal of Ambient Intelligence and SmartEnvironments, 2(1):31?48.Kate Forbes-Riley and Diane J. Litman.
2004.
Pre-dicting emotion in spoken dialogue from multipleknowledge sources.
In Proceedings of NAACL,pages 201?208.Nadia Ghamrawi and Andrew McCallum.
2005.
Col-lective multi-label classification.
In Proceedings ofCIKM, pages 195?200.Roberto Gonza?lez-Iba?n?ez, Smaranda Muresan, andNina Wacholder.
2011.
Identifying sarcasm in twit-ter: a closer look.
In Proceedings of ACL, pages581?586.Jon Hasselgren, Erik Montnemery, Pierre Nugues, andMarkus Svensson.
2003.
HMS: A predictive textentry method using bigrams.
In Proceedings ofEACL Workshop on Language Modeling for Text En-try Methods, pages 43?50.Suin Kim, JinYeong Bak, and Alice Haeyun Oh.
2012.Do you feel what I feel?
social aspects of emotionsin Twitter conversations.
In Proceedings of ICWSM,pages 495?498.Igor Labtov and Hod Lipson.
2012.
Humor as circuitsin semantic networks.
In Proceedings of ACL (ShortPapers), pages 150?155.Kevin Lin and Hsin-Hsi Hsin-Yihn.
2008.
Rankingreader emotions using pairwise loss minimizationand emotional distribution regression.
In Proceed-ings of EMNLP, pages 136?144.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofACL, pages 160?167.Bo Pang and Sujith Ravi.
2012.
Revisiting the pre-dictability of language: Response completion in so-cial media.
In Proceedings of EMNLP, pages 1489?1499.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automaticevaluation of machine translation.
In Proceedingsof ACL, pages 311?318.Robert Plutchik.
1980.
A general psychoevolutionarytheory of emotion.
In Emotion: Theory, research,and experience: Vol.
1.
Theories of emotion, pages3?33.
New York: Academic.Alan Ritter, Colin Cherry, andWilliam B. Dolan.
2011.Data-driven response generation in social media.
InProceedings of EMNLP, pages 583?593.Rico Sennrich.
2012.
Perplexity minimization fortranslation model domain adaptation in statisticalmachine translation.
In Proceedings of EACL, pages539?549.Richard Socher, Jeffrey Pennington, Eric H. Huang,Andrew Y. Ng, and Christopher D. Manning.
2011.Semi-supervised recursive autoencoders for predict-ing sentiment distributions.
In Proceedings ofEMNLP, pages 151?161.Ellen Spertus.
1997.
Smokey: Automatic recognitionof hostile messages.
In Proceedings of IAAI, pages1058?1065.Ryoko Tokuhisa, Kentaro Inui, and Yuji Matsumoto.2008.
Emotion classification using massive exam-ples extracted from the Web.
In Proceedings ofCOLING, pages 881?888.JosephWeizenbaum.
1966.
ELIZA?
a computer pro-gram for the study of natural language communica-tion between man and machine.
Communications ofthe ACM, 9(1):36?45.972
