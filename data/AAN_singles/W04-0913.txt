Text Understanding with GETARUNS for Q/A and SummarizationRodolfo DelmonteDepartment of Language SciencesUniversit?
Ca?
FoscariCa?
Garzoni-Moro - San Marco 3417 - 30124 VENEZIAe-mail: delmont@unive.it website - http://project.cgm.unive.itAbstractSummarization and Question Answering needprecise linguistic information with a much highercoverage than what is being offered by currentlyavailable statistically based systems.
We assumethat the starting point of any interesting applicationin these fields must necessarily be a good syntactic-semantic parser.
In this paper we present thesystem for text understanding called GETARUNS,General Text and Reference Understanding System(Delmonte, 2003a).
The heart of the system is arule-based top-down DCG-style parser, which usesan LFG oriented grammar organization.
The parserproduces an f-structure as a DAG which is thenused to create a Logical Form, the basis for allfurther semantic representation.
GETARUNS, hasa highly sophisticated linguistically based semanticmodule which is used to build up the DiscourseModel.
Semantic processing is stronglymodularized and distributed amongst a number ofdifferent submodules which take care of Spatio-Temporal Reasoning, Discourse Level AnaphoraResolution.1.
IntroductionGETARUNS, the system for text understandingdeveloped at the University of Venice, is equippedwith three main modules: a lower module forparsing where sentence strategies are implemented;a middle module for semantic interpretation anddiscourse model construction which is cast intoSituation Semantics; and a higher module wherereasoning and generation takes place (Delmont &Bianchi, 2002) .The system is based on LFG theoreticalframework (Bresnan, 2001) and has a highlyinterconnected modular structure.
It is a top-downdepth-first DCG-based parser written in Prologwhich uses a strong deterministic policy by meansof a lookahead mechanism with a WFST to helprecovery when failure is unavoidable due to strongattachment ambiguity.It is divided up into a pipeline of sequential butindependent modules which realize the subdivisionof a parsing scheme as proposed in LFG theorywhere a c-structure is built before the f-structurecan be projected by unification into a DAG.
In thissense we try to apply in a given sequence phrase-structure rules as they are ordered in the grammar:whenever a syntactic constituent is successfullybuilt, it is checked for semantic consistency, bothinternally for head-spec agreement, and externally,in case of a non-substantial head like a prepositiondominating the lower NP constituent.
Otherimportant local semantic consistency checks areperformed with modifiers like attributive andpredicative adjuncts.
In case the governingpredicate expects obligatory arguments to belexically realized they will be searched andchecked for uniqueness and coherence as LFGgrammaticality principles require (Delmonte,2002).
In other words, syntactic and semanticinformation is accessed and used as soon aspossible: in particular, both categorial andsubcategorization information attached topredicates  in the lexicon is extracted  as soon asthe main predicate is processed, be it adjective,noun or verb, and is used to subsequently restrictthe number of possible structures to be built.Adjuncts are computed by semantic crosscompatibility tests on the basis of selectionalrestrictions of main predicates and adjuncts heads.As far as parsing is concerned, we purport the viewthat the implementation of sound parsing algorithmmust go hand in hand with sound grammarconstruction.
Extragrammaticalities can be bettercoped with within a solid linguistic frameworkrather than without it.
Our parser is a rule-baseddeterministic parser in the sense that it uses alookahead and a Well-Formed Substring Table toreduce backtracking.
It also implements FiniteState Automata in the task of tag disambiguation,and produces multiwords whenever lexicalinformation allows it.
In our parser we use anumber of parsing strategies and graceful recoveryprocedures which follow a strictly parameterizedapproach to their definition and implementation.Recovery procedures are also used to cope withelliptical structures and uncommon orthographicand punctuation patterns.
A shallow or partialparser, in the sense of (Abney, 1996), is alsoimplemented and always activated before thecomplete parse takes place, in order to produce thedefault baseline output to be used by furthercomputation in case of total failure.
In that casepartial semantic mapping will take place where noLogical Form is being built and only referringexpressions are asserted in the Discourse Model ?but see below.1.2 The Binding ModuleThe output of grammatical modules is then fedonto the Binding Module(BM) which activates analgorithm for anaphoric binding in LFG termsusing f-structures as domains and grammaticalfunctions as entry points into the structure.Pronominals are internally decomposed into afeature matrix which is made visible to the BindingAlgorithm(BA) and allows for the activation ofdifferent search strategies into f-structure domains.Antecedents for pronouns are ranked according togrammatical function, semantic role, inherentfeatures and their position at f-structure.
Specialdevices are required for empty pronouns containedin a subordinate clause which have an ambiguouscontext, i.e.
there are two possible antecedentsavailable in the main clause.
Also split antecedentstrigger special search strategies in order to evaluatethe set of possible antecedents in the appropriate f-structure domain.
Eventually, this information isadded into the original f-structure graph and thenpassed on to the Discourse Module(DM).
We showhere below the architecture of the parser.Fig.1 GETARUNS?
LFG-Based Parser1.3 Lexical InformationThe grammar is equipped with a lexiconcontaining a list of fully specified inflected wordforms where each entry is followed by its lemmaand a list of morphological features, organized inthe form of attribute-value pairs.
However,morphological analysis for English has also beenimplemented and used for OOV words.
The systemuses a core fully specified lexicon, which containsapproximately 10,000 most frequent entries ofEnglish.
In addition to that, there are all lexicalforms provided by a fully revised version ofCOMLEX.
In order to take into account phrasaland adverbial verbal compound forms, we also uselexical entries made available by UPenn and TAGencoding.
Their grammatical verbal syntactic codeshave then been adapted to our formalism and isused to generate an approximate subcategorizationscheme with an approximate aspectual andsemantic class associated to it.
Semantic inherentfeatures for Out of Vocabulary words , be theynouns, verbs, adjectives or adverbs, are providedby a fully revised version of WordNet ?
270,000lexical entries - in which we used 75 semanticclasses similar to those provided by CoreLex.Our training corpus which is made up 200,000words and is organized by a number of texts takenfrom different genres, portions of the UPenn WSJcorpus, test-suits for grammatical relations, andsentences taken from COMLEX manual.To test the parser performance we used the?Greval Corpus?
made available by John Carrolland Ted Briscoe which allows us to measure theprecision and recall against data published in(Preis, 2003).
The results obtained are a 90% F-measure which is by far the best result obtained onthat corpus by other system, ranging around 75%.Overall almost the whole text - 98% - is turned intosemantically consistent structures which havealready undergone Pronominal Binding at sentencelevel in their DAG structural representation.
Thebasic difference between the complete and thepartial parser is the ability of the first to ensurepropositional level semantic consistency in almostevery parse, which is not the case with the second.2.
The Upper ModuleGETARUNS, has a highly sophisticatedlinguistically based semantic module which is usedto build up the Discourse Model.
Semanticprocessing is strongly modularized and distributedamongst a number of different submodules whichtake care of Spatio-Temporal Reasoning, DiscourseLevel Anaphora Resolution, and other subsidiaryprocesses like Topic Hierarchy which will impingeon Relevance Scoring when creating semanticindividuals.
These are then asserted in theDiscourse Model (hence the DM), which is thenused to solve nominal coreference together withWordNet.
The system uses two resolutionsubmodules which work in sequence: theyconstitute independent modules and allow nobacktracking.
The first one is fired whenever a freesentence external pronoun is spotted; the secondone takes the results of the first submodule andchecks for nominal anaphora.
They have access toall data structures contemporarily and pass theresolved pair, anaphor-antecedent to the followingmodules.
Semantic Mapping is performed in twosteps: at first a Logical Form is produced which is astructural mapping from DAGs onto of unscopedwell-formed formulas.
These are then turned intosituational semantics informational units, infonswhich may become facts or sits.
Each unit has arelation, a list of arguments which in our casereceive their semantic roles from lower processing?
a polarity, a temporal and a spatial locationindex.2.1 Logical Form Creation and SemanticMappingIn order to produce a semantic interpretationfrom the output of the parser we adopt a uniformmeaning representation which is a structuredLogical Form(LF).
In other words we map our f-structures into a linear formalism that can capturethe basic meaning of the structural units ofgrammatical representation.
We assume thatparsing has made explicit predicate-argumentrelations as well as subordination and adjunction inf-structure representation: no ambiguity has beenleft to decide in the semantics, seen that allconstituents have been assigned a preferentialreading.LF representations are used to generate asemantic analysis for an utterance: in this sense,they represents its interpretation in context andalso its truth conditions.
In fact, the systemgenerates a situation semantics mapping directlyfrom LF, and that is used to update the DiscourseModel with new discourse entities or newproperties of already existing entities.LF is basically a flat version of f-structure,where the main verb predicate is raised at thehigher node, and arguments and adjuncts arestripped off of useless information w.r.t.
semanticmapping.
In order to produce a semanticinterpretation of each utterance we proceed asfollows:A. we start from DAGs(Direct Acyclic Graphs)available for each utterance, i.e.
f-structures, andperform pronominal binding and anaphoraresolution at discourse level.
Our f-structures areenriched with Semantic Roles which are derivedfrom our augmented Lexical Forms by a matchwith the head Noun inherent features andselectional restrictions.
Semantic match is alsoperformed for Adjuncts, which require anintermediate Preposition and Verb semanticconsistency check for all PP adjuncts.
SemanticRoles may undergo a transformation in thesemantic mapping from LF to Infons in case ofidiomatic expressions, and in case of unexpressedObligatory Arguments;B. each CLAUSE in a DAG is turned into a well-formed-formula with restricted unscopedquantification, positive literals, no variables exceptfor those introduced at a syntactic level.
The LFtransducer looks for the starting node which is thepropositional node, where mood and tense areavailable.
All arguments are searched first, bytraversing the DAG looking for grammaticalfunctions; only semantically referential argumentsare considered, non referential ones are erased(notice that f-structures containing semantic roleForm (corresponding to ?there?
existential subject,or pleonastic ?it?)
are excluded from LF;C. after argument f-structures are mapped inappropriate logical terms, i.e.
by computinginternal adjuncts and/or arguments, the algorithmlooks for sentence level adjuncts.
In LFG, botharguments and adjuncts may be computed in twodifferent ways: open or predicative, closed or non-predicative.
These two syntactic constructionsreceive a different treatment in the semantics: inparticular, closed adjuncts have only a modifyingimport on the Event variable associate to the mainpredicate.
On the contrary, open adjuncts haveboth an Event variable and an argument variablewhich they modify: this information is representedin f-structure by the presence of an internal Subjectvariable functionally controlled by the governinghead NP.
An example will be reported below anddiscussed in details;D. each wff is an expression of logical form whichis made up of a predicate and a number ofarguments, "p(arg1, ..., argn), where 'p' is a constantand 'arg' may be a complex term.
A term is madeup of a quantifier, a variable and a restriction,"term(quant,var,restr)" where the quantifier may bea real natural language quantifier existing in a NPor a time operator like "time"; the variable is asyntactic index assigned to the phrase in the f-structure representation by the parser; therestriction is the structure on which thequantifier/operator takes scope which mightcoincide with the phrase or clause of f-structurerepresentation or may be a logical expression builtfor that aim at logical form level, as happens fortime formulas.
In order to reach an adequaterepresentation for our discourse model we generatea generic "situation" predicate for each tensedclause we compute, and we build a complex termfor time-aspect representation.E.
In LF representation we use syntactic indicesderived directly from f-structure.
The mappingonto semantic representation has two effects:syntactic indices are substituted by semantic ones,where they already exist ?
and this is the case ofanaphora resolution.
In case of new entities, newsemantic indices are generated.F.
Each term is enriched with Semantic Roleinformation.
As said above, Semantic Roles mayundergo a transformation in the semantic mappingfrom LF to Infons in case of idiomatic expressions,and in case of unexpressed Obligatory Arguments.In the former case semantically empty argumentsare assembled together to produce a noncompositional meaning representation (seeTHERE_BE, as opposed to the BE predicate).
Thelatter case regards both agentless passives and theReceiver or Goal of ditransitive verbs.The following is the LF for the first utterance:John went into a restaurant.wff(situation, [wff(go, [term(definite, sn2, wff(isa, [sn2, john])),term(definite, sn5, wff(isa, [sn5, restaurant])),term(event, f5, wff(and, [wff(isa, [f5, ev]),wff(time, [f5, term(definite, t1,wff(and, [wff(isa, [t1, tloc]),wff(past, [t1])]))])])) 'term-event'])])Generic 'isa' relations are introduced into wffsfor NP's and the quantifier is represented by thetranslation of the content of the NP's specifier.Indefinite NP are turned into 'definite' operators incase no scope ambiguity in the clause may arisedue to the absence of ambiguity inducingquantifiers.
Tense specifications are transformedinto complex terms with a semantic operator thattranslates the contents of aspect after thecomputations that have transformed the lexicalstatic value of aspect into its correspondingdynamic propositional import.
We use threedifferent operators: event, process, state.
Theseoperators then have a complex restriction,represented by a conjoined number of wffs, wherewe indicate both the location in time - tloc - and itsspecificity.This LF representation is then converted into asituational semantic representation where syntacticidentifiers are turned into semantic identifiers andall logical predicates are omitted except for theconjunction 'and'.
Semantic identifiers might bederived from the discourse model in case thelinguistic form represents an entity already existingor known to the world of the DM.
Situationsemantics builds infons for each unit ofinformation constituting the situation denoted bythe proposition being represented in the formula.In addition, for each individual or set entity werecord the semantic role already assigned at f-structure level by the grammar.
A generic 'arg' isassociated to arguments of time predicate.
Noticethen that a polarity argument has been added at theend of each expression.sit(event, id4, go,[ind(definite, id3,and([infon(att, infon8, isa, [id3, john], [], 1)]), agent),ind(indefinite, id2,and([infon(att, infon9, isa,[id2, restaurant], [], 1)]), locat)],and([infon(att, infon10, isa, [id4, ev], [], 1),infon(att, infon13, time, [id4,ind(definite, id5,and([infon(att, infon11, isa, [id5, tloc], [], 1),infon(att, infon12, past, [id5], [], 1)]), arg)], [], 1)]), 1)Finally the content of this representation isasserted in the DM as a set of 'facts' or 'sits' in casethey are not already present.
Factuality forsituational types - events, processes and states - iscomputed from propositional level informationaland semantic features.
Semantic roles inheritedfrom f-structure representation make explicit, in adeclarative way, semantic relations which are notcomputed in the LF.The final translation in the DM introduces theobjects of our ontology which, as we said aboveare made up of the following literals: fact, sit, loc,ind, set, card, in, class.
The structure of eachsituation semantic expression is differentaccording to their semantic role: loc, locations hasno polarity and no spatiotemporal location indices;ind, in, card, set, class are type denotators and haveno internal structure.
Fact and sit have an internalstructure which is made up of the followingarguments:- an infon ranked number; a relational typespecifier; a list of argument expressed as a featurerole:identifier; a polarity, spatiotemporal indices.Facts and sits corresponding to main propositionalrelations have no infon: in its place they have asemantic unique identifier.Fig.2 GETARUNS?
Discourse Level Modules2.2 Building the Discourse ModelIn Situation Semantics where reality isrepresented in Situations which are collections ofFacts: in turn facts are made up of Infons whichinformation units characterised as follows:Infon(Index, Relation(Property),List of Arguments - with Semantic Roles,Polarity - 1 affirmative, 0 negation,Temporal Location Index,Spatial Location Index)In addition Arguments have each a semanticidentifier which is unique in the Discourse Modeland is used to individuate the entity uniquely.
Alsopropositional facts have semantic identifiersassigned thus constituting second level ontologicalobjects.
They may be ?quantified?
over bytemporal representations but also by discourse leveloperators, like subordinating conjunctions.Negation on the contrary is expressed in each fact.All entities and their properties are asserted in theDM with the relations in which they are involved;in turn the relations may have modifiers - sentencelevel adjuncts and entities may also have modifiersor attributes.
Each entity has a polarity and acouple of spatiotemporal indices which are linkedto main temporal and spatial locations if any exists;else they are linked to presumed time referencederived from tense and aspect computation.Entities are mapped into semantic individual withthe following ontology: on first occurrence of areferring expression it is asserted as an INDividualif it is a definite or indefinite expression; it isasserted as a CLASS if it is quantified (dependingon quantifier type) or has no determiner.
Specialindividuals are ENTs which are associated todiscourse level anaphora which bind relations andtheir arguments.
Finally, we have LOCs for mainlocations, both spatial and temporal.
If it has acardinality determined by a number, it is plural or itis quantified (depending on quantifier type) it isasserted as a SET and the cardinality is simplyinferred in case of naked plural, i.e.
in case ofcollective nominal expression it is set to 100,otherwise to 5.
On second occurrence of the samenominal head the semantic index is recovered fromthe history list and the system checks whether it isthe same referring expression:- in case it is definite or indefinite with apredicative role and no attributes nor modifiersnothing is done;- in case it has different number - singular and theone present in the DM is a set or a class nothinghappens;- in case it has attributes and modifiers which aredifferent and the one present in the DM has none,nothing happens;- in case it is quantified expression and has nocardinality, and the one present in the DM is a setor a class, again nothing happens.In all other cases a new entity is asserted in the DMwhich however is also computed as being includedin (a superset of) or by (a subset of) the previousentity.2.3 GETARUNS at workAs said at the beginning, this paper is concernedwith an hybrid approach to text understandingwhich is based on the concurrent use of completeNLP techniques with shallow and partial ones inheavily linguistically demanding tasks such as theone posed by summarization and questionanswering.
This approach should be taken as aproposal in line with current NLP research inunrestricted texts that assumes that partialprocessing can be more suitable and useful forbetter satisfaction of certain requirements.
Inparticular, morphological analysis is a prerequisitein order to better cope with Out of VocabularyWords(OOW) by means of guessing techniquesbased on morphological rules; statistical processing?
or finite state automata as is the case with oursystem - is assumed to be essential for taggingdisambiguation.
As to syntactic parsing, robustapproaches should be adopted in order to allow forstructure building in the case of local failures.Eventually, whenever required, partial semanticinterpretation has to be carried out in order toexecute anaphora resolution and a Discourse Modelis built with a limited number of relations andproperties.
Partial semantic interpretation meansthat not all semantic relations will be detected andencoded appropriately in a sense better specifiedbelow.
Nonetheless, what is captured by partialanalysis can still be useful to carry out suchimportant tasks as anaphora resolution at discourselevel and a rough evaluation of entity relevance inorder to better grasp what topic has been the mostrelevant one.Consider now a simple sentence like thefollowing:1.
John went into a restaurantThis might be represented by Ternary Expressions(Katz, 1997) as follows:<John go restaurant><GO <SUBJ John>, <OBL restaurant>>GETARUNS represents the same sentence indifferent manners according to whether it isoperating in Complete or in Partial modality.
Inturn the operating modality is determined by itsability to compute the current text: in case offailure the system will switch automatically fromComplete to Partial modality.The system will produce the followingrepresentations:loc(infon2, id1, [arg:main_tloc, arg:tr(f1_r01)])loc(infon3, id2, [arg:main_sloc, arg:restaurant])ind(infon4, id3)fact(infon5, inst_of, [ind:id3, class:man], 1, univ, univ)fact(infon6, name, [john, id3], 1, univ, univ)ind(infon7, id4)fact(infon8, isa, [ind:id4, class:restaurant], 1, id1, id2)fact(infon9, inst_of, [ind:id4, class:place], 1, univ, univ)fact(id5, go, [agent:id3, locat:id4], 1, tes(f1_r01), id2)fact(infon12, isa, [arg:id5, arg:ev], 1, tes(f1_r01), id2)fact(infon13, isa, [arg:id6, arg:tloc], 1, tes(f1_r01), id2)fact(infon14, past, [arg:id6], 1, tes(f1_r01), id2)fact(infon15, time, [arg:id5, arg:id6], 1, tes(f1_r01), id2)So in case of failure at the Complete level, thesystem will switch to Partial and the representationwill be deprived of its temporal and spatial locationinformation as follows:ind(infon4, id3)fact(infon5, inst_of, [ind:id3, class:man], 1, univ, univ)fact(infon6, name, [john, id3], 1, univ, univ)ind(infon7, id4)fact(infon8, isa, [ind:id4, class:restaurant], 1, id1, id2)fact(infon9, inst_of, [ind:id4, class:place], 1, univ, univ)fact(id5, go, [agent:id3, locat:id4], 1, univ, id2)In order to test the performance of the system intext understanding we refer to such applicationfields as Question/Answering and Summarization.They are by far the best benchmark for any systemthat aims at showing how good the semanticmapping has been.We will show how GETARUNS computes theDM by presenting the output of the system for the?Maple Syrup?
text made available by Mitre for theANLP2000 Workshop(see Hirschmann et al1999).
Here below is the original text which isfollowed by the DM only relatively to the linguisticmaterial needed to answer the five questions,though.How Maple Syrup is MadeMaple syrup comes from sugar maple trees.
At onetime, maple syrup was used to make sugar.
This is whythe tree is called a "sugar" maple tree.Sugar maple trees make sap.
Farmers collect the sap.The best time to collect sap is in February and March.The nights must be cold and the days warm.The farmer drills a few small holes in each tree.
Heputs a spout in each hole.
Then he hangs a bucket on theend of each spout.
The bucket has a cover to keep rainand snow out.
The sap drips into the bucket.
About 10gallons of sap come from each hole.Discourse Model for sentences 6 and 76.
Farmers collect the sapclass(infon100, id28)fact(infon101, inst_of, [ind:id28, class:man], 1, univ, univ)fact(infon102, isa, [ind:id28, class:farmer], 1, univ, id8)fact(id29, collect, [agent:id28, theme_aff:id24], 1, tes(f1_es6), id8)fact(infon105, isa, [arg:id29, arg:ev], 1, tes(f1_es6), id8)fact(infon106, isa, [arg:id30, arg:tloc], 1, tes(f1_es6), id8)fact(infon107, pres, [arg:id30], 1, tes(f1_es6), id8)during(tes(f1_es6), tes(f1_es5))includes(tr(f1_es6), univ)7.
The best time to collect sap is in February and Marchind(infon112, id31)fact(infon113, inst_of, [ind:id31, class:substance], 1, univ, univ)fact(infon114, isa, [ind:id31, class:sap], 1, univ, id8)in(infon115, id31, id24)ind(infon116, id32)fact(infon117, best, [ind:id32], 1, univ, id8)fact(infon118, inst_of, [ind:id32, class:time], 1, univ, univ)fact(infon119, isa, [ind:id32, class:time], 1, univ, id8)set(infon120, id33)card(infon121, 2)fact(infon122, inst_of, [ind:id33, class:time], 1, univ, univ)fact(infon123, isa, [ind:id33, class:[march, February]], 1, univ, id8)fact(id35, collect, [agent:id28, theme_aff:id31], 1, tes(finf1_es7),id8)fact(infon126, isa, [arg:id35, arg:ev], 1, tes(finf1_es7), id8)fact(infon127, isa, [arg:id36, arg:tloc], 1, tes(finf1_es7), id8)fact(infon128, nil, [arg:id36], 1, tes(finf1_es7), id8)fact(infon130, [march, February], [arg:id32], 1, univ, id8)fact(id37, be, [prop:id35, prop:infon130], 1, tes(f1_es7), id8)fact(infon131, isa, [arg:id37, arg:st], 1, tes(f1_es7), id8)fact(infon132, isa, [arg:id38, arg:tloc], 1, tes(f1_es7), id8)fact(infon133, pres, [arg:id38], 1, tes(f1_es7), id8)during(tes(f1_es7), tes(f1_es6))includes(tr(f1_es7), univ)3.
Question-AnsweringComing now to Question Answering, the systemaccesses the DM looking for relations at first thenfor entities : entities are searched according to theform of the focussed element in the User DataBaseof Question-Facts as shown below with the QDMfor the first question:User Question-Facts Discourse Modelq_loc(infon3, id1, [arg:main_tloc, arg:tr(f1_free_a)])q_ent(infon4, id2)q_fact(infon5, isa, [ind:id2, class:who], 1, id1, univ)q_fact(infon6, inst_of, [ind:id2, class:man], 1, univ, univ)q_class(infon7, id3)q_fact(infon8, inst_of, [ind:id3, class:coll], 1, univ, univ)q_fact(infon9, isa, [ind:id3, class:sap], 1, id1, univ)q_fact(infon10, focus, [arg:id2], 1, id1, univ)q_fact(id4, collect, [agent:id2, theme_aff:id3], 1, tes(f1_free_a),univ)q_fact(infon13, isa, [arg:id4, arg:pr], 1, tes(f1_free_a), univ)q_fact(infon14, isa, [arg:id5, arg:tloc], 1, tes(f1_free_a), univ)q_fact(infon15, pres, [arg:id5], 1, tes(f1_free_a), univ)The system knows that the ?
focus ?
argument is?
who ?
with semantic id, id2, and is an entitybelonging to the semantic class of ?
man ?, thislatter informantion being derived from thesyntactic structure of the corresponding sentencewhere the interrogative pronoun has bound anempty category in the SUBJect of the verb?
COLLECT ?
of the main clause : this in turn hasallowed the parser to pass the selectionalrestrictions associated in the lexicon with thecorresponding lexical frame for the verb?
COLLECT ?.
Search of the answer is performedby looking into the DM for the best Infon thatmatches the question: at first, the system looks forthe same relation ?
collect ?, then it looks for theentity corresponding to the semantic role of theFocus in the question, the Agent.
If the first actiondoesn?t succeed, the well-known ?
semanticbottleneck ?
will cause the system to search forsynonyms in the WordNet synset at first, then in amore generic dictionary (2 million correlations forsome 30,000 entries) of quasi-synonyms orconcepts belonging to the same semantic field.Then, the system tries to pick up the entity that isthe Agent, which in our case is id28 (as shown inthe DM for sentence 6), by searching the entityontological identifiers ?
set, ind, ent.
When thecorresponding fact is found, the predicate(FARMER) is passed to the Generator that buildsthe reply sentence.As to the current text, it replies correctly to allquestions.
As to question 4, at first the systemtakes ?
come from ?
to be answered exhaustivelyby sentence 14 ; however, seen that ?
hole ?
is notcomputed with a ?
location ?
semantic role, itsearches the DM for a better answer which is therelation linguistically expressed in sentence 9,where ?
holes ?
are drilled ?
in each tree ?.
The?
tree ?
is the Main Location of the whole storyand ?
hole ?
in sentence 9 is inferentially linked to?
hole ?
in sentence 14, by a chain of inferentialinclusions.
In fact, come_from does not figure inWordNet even though it does in our genericdictionary of synonyms.
As to the fifth question,the system replies correctly.1.
Who collects maple sap?
(Farmers)2.
What does the farmer hang from a spout?
(A bucket)3.
When is sap collected?
(February and March)4.
Where does the maple sap come from?
(Sugar mapletrees)5.
Why is the bucket covered?
(to keep rain and snow out)Another possible ?
Why ?
question could havebeen the following : ?
why is the tree called a"sugar" maple tree ?, which would have receivedthe appropriate answer seen that the correspondingsentence has received an appropriate grammaticaland semantic analysis.
In particular, the discoursedeictic pronoun ?
This ?
has been bound to theprevious main relation ?
use ?
and its arguments,so that they can be used to answer the ?
Why ?question appropriately.There is not enough space here to comment indetail the parse and the semantics (but seeDelmonte 2000d); however, as far as anaphoraresolution is concerned, the Higher Modulecomputes the appropriate antecedent for the bigPro, i.e.
the empty SUBject of the infinitive insentence n. 7, where the collecting action wouldhave been left without an agent.
This resolution ofanaphora is triggered by the parser decision to treatthe big Pro as an arbitrary pronominal and thisinformation is stored at lexical level in thesubcategorization frame for the name ?
time ?.With question n.4 the text only makes availableinformation related to ?
maple syrup ?.
As saidabove, we start looking for relations, and the?
come from ?
relation has a different linguisticdescription as SUBJect/ Theme_Unaffectedargument ?
i.e.
?
SAP ?
-, what we do is to try andsee whether there is some inferential link between?
sap ?
and ?
syrup ?
in WordNet.
This fails, seenthat WordNet does not link the two conceptsexplicitly.
However both are classified as?
substance ?
thus allowing the required inferenceto be fired ?
both are also taken as synonyms in ourgeneric dictionary.
The final question does notconstitute a problem seen that the relation ?cover?has become a semantic relation and is no longer anoun or a verb.
Also worth noting is the fact thatthe question is not a real passive, but a quasi-passive or an ergative construction, so no agentshould be searched for.
Our conclusion is that theheart of a Q/A system should be a stronglyrestrictive pipeline of linguistically based moduleswhich alone can ensure the adequate informationfor the knowledge representation and the reasoningprocesses required to answer natural languagequeries.3.1 Answering Generic QuestionAn important issue in QA is answering genericquestions on the ?aboutness?
of the text, questionswhich may be answered by producing appropriateheadlines or just a title.
In our system, given theconcomitant work of anaphora resolution modulesand the semantic mapping into predicate-argumentstructures, this can be made as follows.
The systemcollapses all entities and their properties, relationsand attributes, after the text has been fullyanalysed, by collecting them for each ontologicaltype under each semantic identifier.
At the sametime, each semantic id receives a score fortopichood thus allowing a ranking of the entities.Here below we list the most relevant entities of thetext reported above:entity(set,id8,30,facts([card(infon23, id8, 5),fact(infon24, sugar_maple, [ind:id8], 1, T, P),fact(infon25, inst_of, [ind:id8, class:plant_life], 1, T, P),fact(infon26, isa, [ind:id8, class:tree], 1, T, P),fact(id11, come, [actor:id2, locat:id8], 1, T, P),fact(id25, make, [agent:id8, theme_aff:id23, patient:id24], 1, T,P)])).entity(class,id30,77,facts([fact(infon114, inst_of, [ind:id30, class:man], 1, T, P),fact(infon115, isa, [ind:id30, class:farmer], 1, T, P),fact(id39, drill, [agent:id30, theme_aff:id38], 1, T, P),fact(id42, put, [agent:id30, theme_aff:id41, locat:id38], 1, T, P),fact(id48, hang, [agent:id30, theme_aff:id44], 1, T, P)])).entity(ind,id13,10,facts([in(infon48, id13, id9),fact(infon46, inst_of, [ind:id13, class:substance], 1, T, P),fact(infon47, isa, [ind:id13, class:sugar], 1, T, P),fact(id14, make, [agente:id2, tema_aff:id13], 1, T, P),fact(*, inst_of, [ind:id13, class:maple], 1, T, P),fact(*, isa, [ind:id13, class:maple], 1, T, P),fact(*, isa, [ind:id13, class:sugar_maple], 1, T, P),fact(*, of, [arg:id10, specif:id13], 1, T, P)])).Where starred facts are inherited by the inclusionrelation specified by the ?in?
semantic predicate.For instance, the fact constituted by a ?specifying?relation between ?sugar?
and ?maple?
asfact(infon34, of, [arg:id10, specif:id9], 1, univ,univ)becomes a starred fact inherited by id13 in force ofthe inclusion relation,in(infon48, id13, id9)In this way, an appropriate answer to thequestion ?What is the text about?
can be generateddirectly from the entity list by picking up relationsand properties of the most relevant individuals,setsand classes (Delmonte, 2000).4.
The ExperimentWe downloaded the only freely available corpusannotated with anaphoric relations, i.e.Wolverhampton?s Manual Corpus made availableby Prof. Ruslan Mitkov on his website.
The corpuscontains text from Manuals at the followingaddress,http://clg.wlv.ac.uk/resources/corpus.htmlTo compare our results with the SGMLdocuments we created a Perl script that extractedall referring expressions and wrote the output intoa separate file.
The new representation of theSGML files looked now like a list of records eachone denoted by an index a dash and the text of thereferring expression.
In case of complex referringexpressions we had more than one index availableand so we translated the complex referringexpression into a couple or a triple of records eachone denoted by its index.
The final results were75% F-measure - complete results are published in(Delmonte, 2003b).5.
ConclusionsResults reported in the experiment above havebeen aimed to show the ability of the system tocope with what has always been regarded as thetoughest task for an NLP system to cope with, thatof reference resolution which is paramount in anysystem of Q/A.
We have not addressed the problemof summarization for lack of space: however hintshave been addressed by the issue of answeringGeneric Questions.We are currently experimenting with automaticontology building from the DM into a Proteg?database which is then used to answer queries fromthe web (Delmonte, 2003b).
By weaving naturallanguage into the basic fabric of the Semantic Web,we can begin to create an enormous network ofknowledge easily accessible by both machines andhumans alike.
Furthermore, we believe that naturallanguage querying capabilities will be a keycomponent of any future Semantic Web system.
Byproviding ?natural?
means for creating andaccessing information on the Semantic Web, wecan dramatically lower the barrier of entry to theSemantic Web.
Natural language support givesusers a whole new way of interacting with anyinformation system, and from a knowledgeengineering point of view, natural languagetechnology divorces the majority of users from theneed to understand formal ontologies.
As we havetried to show in the paper, this calls for better NLPtools where a lot of effort has to be put in order toallow for complete and shallow techniques tocoalesce smoothly into one single system.GETARUNS represents such a hybrid system andits performance is steadily improving.6.
ReferencesAbney, A.
1996.
Part-of-Speech Tagging andPartial Parsing, in Ken Church et al, eds.Corpus-Based Methods in Language andSpeech, Kluwer Academic Publishers,Dordrecht.Bresnan, Joan.
2001.
Lexical-Functional Syntax.Blackwells.Delmonte R., 2003a.
Getaruns: a hybrid systemfor summarization and question answering, inProc.
Workshop "NLP for Question Answering"in EACL, Budapest, 21-28.Delmonte R., D. Bianchi.
2002.
From Deep toPartial Understanding with GETARUNS, Proc.ROMAND 2002, Universit?
Roma2, Roma, 57-71.Delmonte R. 2002.
GETARUN PARSER - Aparser equipped with Quantifier Raising andAnaphoric Binding based on LFG, Proc.LFG2002 Conference, Athens, 130-153, athttp://cslipublications.stanford.edu/hand/miscpubsonline.html.Delmonte R. 2000.
Generating from a DiscourseModel, Proc.
MT-2000, BCS, Exeter, 25-1/10.Delmonte R., 2003b.
The Semantic Web NeedsAnaphora Resolution, Proc.Workshop ARQAS,2003 International Symposium on ReferenceResolution and Its Applications to Q/A andSummarization, Venice, Ca' Foscari University,25-32.Preis J., 2003.
Using Grammatical Relations toCompare Parsers, in Proc., EACL, Budapest,291-298.Hirschman, L. Marc Light, Eric Breck, & J. D.Buger.
1999.
Deep Read: A readingcomprehension system.
In Proc.
A CL'99.University of Maryland.Katz, B.
1997.
Annotating the World Wide Webusing natural language.
In RIAO ?97.
