A Bootstrapping Method for Extracting Bilingual Text PairsHiroshi Masuiehil Raymond Flournoy**Fuii Xerox Co., Ltd.Corporate Research Center430 Sakai, Nakai-machi, Ashigarakami-gun,Kanagawa 259-0157, Japan{ masuichi, flournoy, kauflnann,Stefan Kaufmann * Stanley Peters *?
Center for the Study of Language and InformationStanford University210 Panama Street, Stanford,CA 94305-4115, U.S.A.peters} @csli.stanford.eduAbstractThis paper proposes a method for extractingbilingual text pairs from a comparable cor-pus.
The basic idea of the method is to ap-ply bootstrapping to an existing corpus-based cross-language information retrieval(CLIR) approach.
We conducted prelimi-nary tests with English and Japanese bilin-gual corpora.
The bootstrapping methodled to much better esults for the task of ex-tracting translation pairs compared with acorpus-based CLIR method without boot-strapping, and the extracted translation pairscould be useftfl training data for improvingresults of the corpus-based CLIR method.1 IntroductionA parallel corpus is an important resource forcorpus-based approaches to CLIR.
Theseapproaches use parallel corpora as statisticaltraining data and then retrieve documents writ-ten in a language different from that of the query.One disadvantage of these approaches i lack ofresources.
Parallel corpora are not alwaysreadily available and those that are availabletend to be relatively small or to cover only asmall number of subjects.A bilingual comparable corpus is a set of textsin two different languages from the same do-main or on the same topic.
Unlike a parallelcorpus it is composed independently in the re-spective language text sets.
It can be morereadily obtained from the Internet or CD-ROMresources than parallel corpora.
Zanettin(1998) introduced several available bilingualcomparable corpora such as news paper articlesselected by dates and subject codes, medicalarticles from journals and textbooks, and articlesfor tourists from brochures and guides.
Zanet-tin (1994) also reported that it is highly likelythat much relevant information can be foundacross languages in a topic-related bilingualcomparable corpus.
In this paper, we propose amethod for extracting bilingual text pairs whichshare the same information fiom a bilingualcolnparable corpus, and show the possibility thatthe resulting bilingual text pairs can be usefulfor corpus-based CLIR approaches when we usethem as training data instead of a parallel corpus.Sheridan (1998) also proposed an approach tobuilding lnultilingual test collection from com-parable corpora consisting of news articles.The idea is to reduce the work of manual rele-vance judgements by restricting news articles tobe examined to a couple of days.
Disadvan-tages to this approach are that it relies on time-sensitive texts, texts obtained by this approachare constrained to referencing specific events,and nontrivial work by hulnans is still necessm'y.On the other hand, our goal is to extract bilin-gual text pairs automatically from any kind ofbilingual comparable corpora.This paper is organized as follows: Section2 introduces the basic idea for extractingrelevant ext pairs from a bilingual comparablecorpus.
Our method is based on a corpus-basedCLIR method, so we overview previous corpus-based CLIR approaches in Section 3.
Section 4describes an experimental procedure, the resultsit produced, and an analysis of the results.
Theconclusion is given in Section 5.2 The Basic IdeaAs we will describe in Section 3, several CLIRapproaches that rely on parallel corpora havebeen proposed and lead to successful retrievalresults.
In those approaches, a parallel corpusused as training data should be large enough toobtain good retrieval results.
Although we usea CLIR method which relies on a parallel corpus,we begin with a very small parallel corpus.
Weretrieve bilingual text pairs from a bilingualcomparable corpus using the small parallel cor-pus as training data.
Then we concatenate thetext pairs to the initial small parallel corpus andgrow the parallel corpus by iterating the retrievaland concatenation processes (Figure 1).1066I comparable COlptlS IFigure 1: The bootstrapping methodThis kind of bootstrapping method has aproblem, however: It is highly sensitive to theaccuracy of the text pairs obtained in the earlystages of the iterations.
In order to solve thisproblem, we concatenate only a small number ofthe most "reliable" text pairs to the initial paral-lel corpus in the early stages, then graduallyincrease the number of the text pairs which areconcatenated to the initial parallel corpus.
Wewill describe the details of the method in Section4.3 Corpus-based CLIR approaches3.1 Previous ResearchesAs we mentioned in Section 2, we use a CLIRmethod which relies on a parallel corpus in ourbootstrapping method.
One approach to cor-pus-based CLIR is to use the Latent SemanticIndexing technique proposed by Fumas et al(1988) on a parallel corpus to construct a lan-guage illdependent representation el'queries anddocuments (Landauer and Lfltman, 1990).Another approach that relies on a parallel corpushas been suggested by l)unning and l)avis(1993).
Their method is based on the vectorspace model and involves the linear trausforula-tion of the representation f a query.
A parallelcorpus can also be used to enhance existingknowledge-based resources.
The resources arkused to translate the query and then classical IRmatching techniques are applied to compute thesimilarity between the trauslated query anddocuments (Hull and Grel'enstette, 1996).3.2 hfforlnation Mapping for CLIRFor our bootstrapping method, we adopted aCLIR method which is based on the hfforma-tion Mapping approach (Masuichi et al,1999).
Information Mapping is basically awlriant of the vector space model, and is basedon an approach first proposed by Schtitze(1995).
The approach is closely related toLatent Semantic Indexing, and the dilTerencebetween these two is discussed in Schfitze andPedersen (1997).
Note that our bootstrappingmethod does not depend on any particuhu"properties o1' the Information Mapping ap-proach, so it could employ other corpus-basedCLIR methods such as Latent Semantic in-dexing.Information Mapping begins with a largeword-by-word matrix.
A list of n content-bearing words and m w)cabulary words corre-spond to the columns and the rows of thematrix.
The most fiequently appearing nwords in a training corpus are selected ascontent-bearing words and the most frequentlyappearing m words as vocabulary words.Each cell of the matrix holds the nmnber oftotal cooccurrences between a content-bearingword and a vocabulary word in the trainingcorpus.
In this way, an n-dimensional vectorwhich represents the word's distributionalbehavior is produced t'or each vocabularyword.
Then the original n-dimensional vec-tor space is converted into a condensed, lower-dilnensional, real-valued matrix using SingularValue l)ecomposition (SVD) (Berry, 1992).The lower-dimensional vector space is calledword space.
A document vector and a queryvector are calculated by summing the vectorscorresponding to the vocabulary words in thedocument or the query, and the proximitybetween the two vectors is del'ined as the cosi-ne of the angle between them.To apply this method to CL1R, we regardeach translation pair in a training parallelcorpus of language LI and L2 as a singleCOlnpotmd document and create a word-by-word matrix and then a word space.
Theword space represents a hmguage independentvector space for vocabulary words in both 1,1and L2, and therefore query and documentvectors in both LI and L2 can be calculatedand compmed in the salne word space.4 Experimental tests and Results4.1 Tests with complete-pair corporaWe used an English-Japanese bilingual patenttext corpus for our experilnental tests.
Forour first test, we prepared I000 English-Japanese patent text pairs as a pseudo bilin-gual comparable corpus.
For each Japanesepatent text in the corpus, its English transla-tion by humans exists j, so this corpus could beregarded as an ideal bilingual comparablecorpus.
We also prepared 100 pairs as aninitial parallel corpus (a training corpus) tocreate an initial word space.
All the patentsThe quality of the translations wtrics greatly fromword-for-word translations to short sunnnaries.1067in the two corpora were randomly selectedfrom the Japanese patents issued in 1991, andthe two corpora shared no patent.
We usedonly the title and abstract exts and removedall other information, such as author, patent IDand issue date.
Table 1 shows an example ofan English-Japanese pair in the corpora.
Allcharacters in the English texts are l-byte char-acters and all characters, including alphabeti-cal and numerical characters, in the Japanesetexts are 2-byte, so there is no word which isshared by both English and Japanese texts.We used all words which appeared in a train-ing corpus as vocabulary words, and the mostfrequently appearing 3000 English words ascontent-bearing words and then reduced thedimension of the vectors from 3000 to 200 bySVD.llose liar 'l'ransl~zrring Fertilizer from Fcflilizer Tmlki of Mobile \["arm Machine Abslracl:PROlll ,I~M TO l ie  .SOI.VI.~D: To provide a mechanism To arrange a ferlilizer Imnsli~r bosefrom a ferlilizer lallk wilhoul catlsing hindrance Io lhe olher mcchaniSlllS, t}lc.
SOI.UTION:A fertilizer Irans fer hose 38 Io deliver a f?~lilizer rllll| il fcriilizer lank 31 placed al ~1 side ofa mobile machine l~dy I Io lhe downslream side of a ferlilizing par128 is laid along theoilier circulllli?rellCe of a passage 23 placed ~l\[Ollg die back and a side o1" a drivcl's seal 8 andexlending \[ioln Ihe driver's eal 8 Io a working inacbille I I.1 ~l l :~  I-/'6.~tzltE~t')x-'ga 1 h',6 ll~llEt~t128 T ~'~IV'IIE~/I~.J~'C'~IIB,I~,--7,.a 8-'2,Table 1 : An example of an English-Japanese patent pairWe began with a word space created fromthe 100 English-Japanese translation pairs (theinitial parallel corpus).
Then using the wordspace, we calculated 1000 English patentvectors and 1000 Japanese patent vectorswhich correspond to the patent texts in thepseudo comparable corpus.
Next we extract-ed English-Japanese patent pairs which satis-fied the simple condition that the Englishpatent vector in the pair has the highest prox-imity (the biggest cosine) with the Japanesepatent vector in the pair among the 1000 Ja-panese patent vectors, and vice versa (hereaf-ter we call these pairs mutual-proximity pairs).Note that mutual-proximity pairs are, ofcourse, not always correct translation pairs.Then we selected the 10 most "reliable" mu-tual-proximity pairs, assuming that the higherthe proximity between the two vectors of amutual-proximity pair, the more reliable themutual-proximity pair is.
Finally we con-catenated the 10 mutual-proximity pairs to theinitial 100 translation pairs.
This is the firststage of our bootstrapping method.In the second stage, we created a new wordspace regarding the 110 English-Japanesepairs obtained in the first stage as a trainingcorpus.
Then we selected the 20 most reli-able mutual-proximity pairs and concatenatedthem to the initial 100 patent ranslation pairs.At the Nth stage, we selected the N* 10 mostreliable lnutual-proximity pairs.
If the num-ber of the nmtual-proximity pairs obtained inthe stage is less than N*I0, all of the mutual-proximity pairs were concatenated to the ini-tial 100 patent ranslation pairs.We repeated this procedure up to the 100thstage.
At the 100th stage, we obtained 727mutual-proximity pairs and 721 pairs out ofthe 727 pairs were correct translation pairs.Therefore the recall of the obtained pairs was72.1% (721/1000) and the precision was99.2% (721/727) (see the column of Testl andthe row of the "bootstrapping method" ofTable 2).
On the other hand, we obtained341 mutual-proximity pairs and 258 pairs outof the 341 pairs were correct ranslation pairsin the case of the normal Information Mappingmethod which corresponds to the first stage ofour bootstrapping method.
In this case, therecall was 25.8% and the precision was 75.7%(see the column of Testl and the row of the"normal method" of Table 2).I 0C,8(26(:,I(i2(~ s i / m  (e~)~ recall ( ~ ), I .
I , I , I ,20 40 6(1 80 100Figure 2: The change of precision and recallwith complete-pair corpusFigure 2 shows the change of the precisionand the recall through the 100 stages.
Theprecision was kept over 93.3% and the recallwent up gradually.
We could successfullygrow the bilingual text pairs using bootstrap-ping.l l o rmalmethodboot-strappingmethodPrec 75.7Rec 25.8Prec 99.2Rec 72.175.6 76.626.6 26.999.1 99.774.0 73.078.2 72.825.4 27.198.9 98.771.0 70.6Table 2: Results of extracting tests withcomplete-pair corpus1068We prepared 4 more different sets of 1000pairs 1'or pseudo comparable corpora and dif-ferent sets of 100 pairs for initial parallelcorpora, and repeated the same test 4 moretimes.
Table 2 shows results of the 5 tests ofthe bootstrapping method and the normalInformation Mapping method.
In each case thebootstrapping method could drastically im-prove both the precision and the recall.We also conducted tests to see if the result-ing text pairs obtained at the 100th stage in theprevious tests are useful for the normal In fermarion Mapping method.
We prepared an-other 1000 English-Japanese patent ranslationpairs for each of the 5 previous tests asevaluation corpora.
No same patents wereshared between any two of all the corpora.We extracted mutual-proximity pairs froln thenew 1000 English-Japanese pair with the nor-mal Information Mapping method, using (1)the initial parallel corpus in the previous test,(2) the initial parallel corpus + the mutual-proximity pairs obtained in the previous test,(3) the initial parallel corpus + the 1000 Eng-lish-Japanese correct translation pairs in thepseudo comparable corpus of the previous test,as a training corpus respectively.
For exam-ple, in Test 1, the number of pairs in therefining corpus is 100 for (1), 827 with 6 errorpairs for (2) and 1100 for (3).the Introduction, it is highly likely that a realbilingual comparable corpus includes bilingualpairs which share the same information, but italso includes a lot of irrelevant texts.
Tosimulate this, we replaced half of the Japanesepatent exts in the pseudo comparable corporaof the previous tests with different Japanesepatent texts which were randomly selected.Therefore the corpus included 500 English-Japanese translation pairs, and 500 Englishpatents and 500 Japanese patents which weretotally irrelevant to each other.100806040200I I I I~f~f l  ~ I , I rcc dll(%) ,20 40 60 80 100Figure 3: The change of precision and recallwith 50%-error-pair corpuslh'cC initialpairs Rccinilail + Prccboot-stmppingpmrs Recinitail + Preccompletepmrs Rcc 77.5 79.3 79.0 77.4Table 3: Results of ewduat\]oncomplete-pair corpus77.5 77.323.8 29.398.9 98.774.5 75.099.0 99.173.326.198.875.1 75.099.6 98.775.6 75.425.1 25.899.
I 99.273.598.778.6tests forTable 3 shows the results.
The results of(3) can be considered as the ceilings of theprecision aud the recall, because we used allthe correct translation pairs in the pseudocomparable corpus.
In each case, both theprecision and the recall of (2) is very close tothe ceilings, so we think the bilingual textpairs obtained by our bootstrapping method isuseful as a training corpus for the normalInformation Mapping method.4.2 Tests with incomplete-pair corporaIn the tests described above, we used the idealpseudo COlnparable corpus.
As described innolill~|\]mclhodboorstral~pingmethodPrcc 55.3Rcc 28.4l'rcc 82.1P, cc 69.850.0 52.826.8 28,081.4 83.870.8 67.446.6 53,525.
(} 29.481.0 80,767.4 69.2Table 4: Results of extracting testswith 50%-error-pair corpusl'rec 77.5 77.3 73.3 75.6 initialpairs Rec 23.8 29.3 26.
I 25.
Iinitail + l'rec 96.2 95.7 93.4 93.3boot-strappingpairs Rec 61.
I 61.9 59.8 57.4initail + Prec 98.4 98.7 97.9 98,0completepan's Roe 66.1 70.7 68.6 69.0 71.1Table 5: Results of evaluation testsfor 50%-error-pair corpus75.425.895.960.598.9Results are shown in Figure 3, Table 4 andTable5, which correspond to Figure 2, Table 2and Table 3 respectively.1069I(~) I I I I806040200+ recall (%)?20 40 60 80 100Figure 4: The change of precision and recallwith 80%-error-pair corpusllOrlllalmethodboot-strappingmethodl'rcc 23.4Rec 27.5Prec 52.5Rec 58.017.8 20.720.0 24.555.2 50.953.0 55.O21.1 27.023.5 30.053.2 53.453.5 50.2Table 6: Results of extracting testswith 80%-error-pair corpusinitialpairsinilail +boot-strappingpawsinitail +completepailSTable 7: Results of evaluation tests(5, for 80 N-error-pair corpusPrecRccPrccRccPrccRcc77.523.882.937.996.154.777.3 73,329.3 26.185.5 81.136.3 35.396.4 96.058.7 55.075.625.
I83.533.594.055.375.425.885.433.495.753.4Figure 4, Table 6 and Table 7 show results inthe case that we replaced 80% of Japanese pat-ent texts with irrelevant Japanese patent exts.The results of these tests are not as good asthe results of tests with the ideal pseudo compa-rable corpora.
Figure 4 and 6 show, however,the bootstrapping method iml?roved both theprecision and recall of the extracted text pairs ascompared to the normal method.
Figure 5 and7 also show that the bilingual text pairs obtainedby the bootstrapping method are still useful as atraining corpus for the normal method.5 ConclusionWe proposed a lnethod of extracting bilingualtext pairs from a comparable corpus.
Themethod is based on an existing corpus-basedCLIR method and uses bootstrapping.
Alt-hough our research is in the preliminary stage ofdevelopment and tested with artificial corporaconsisting of English and Japanese patent exts,the bootstrapping led to nmch better results forthe task of extracting translation pairs than theresults produced by a normal CLIR method, andthe extracted translation pairs could be useful forimproving the results of the normal CLIR whenwe used them as a training corpus.ReferencesBerry, M. W. (1992) Large Scale Singular VahteComputations.
International Journal of Supercom-puter Applications, 6/1, pp.
13-49.Dunning T. E. and Davis M. W. (1993) Multi-lingualinformation retrieval.
Computational Memorandairi Co~aitive and Computer Science MCCS-93-252,New-Mexico State University, Computing Re-search Laboratory.Furnas, G. W., Dcerwester, S., Dumais, S. T., Lan-daucr, T. K., H~rshlnan, R. A., Streeter, L. A. andLochbaum, K. E. (1988) lnfbrmation retrieval us-ing a singular value decomj)osition model of latel!tsemantic structure.
In proceedings of die l l thACM International Conference on Research andDevelopment in hfformation Retrieval, pp.
465-480.Hull, D. and Grefenstette, G. (1996) Quelying acrosslanguages."
A dictionaty-bas'ed apRroach to mul-tilinettal infomtation retrieval.
In Proceedings ofSIGIR'96, \[~p.
49-57.Landauer, T. K. and Littman, L. M. (1990) Fullyautomatic ross-language document retrieval usinglatettt semantic indexittg.
In Proceedintzs of lhe 6lliConference of Univcrsi.ly ol' Wterloo Centre for theNew Oxford English Dictionary and Text Research,pp.
31-38.Masuichi, H., Flournoy, R., Kaufinann, S. and Peters,S.
(1999) Query, Translation Method for CrossLanguage h!forthation Retrieval.
In Proc'eedinjg8 ofthe "Worksh6p on Machine Translation lor CrossLantzua~ze Inlormation Retrieval, MT Summit VII,pp.
30-S4.Schfitze, H. (1995) Ambiguity Resohttion in Lcm-guage Learning: Computa'tional atzd Cognitive9 ) Z Models.
\[ hD tlicsis, Stanford University, l)cpart-mcnt of Linguistics.Schi.itze, H. and Pederscn, J.
(1997)A coocur-retlce-based thesaurus attd two al~lglications to in-.folT~lation retrieval.
Informatmn Processing &management, 33/3, pp.
307-318.Sheridan, P., Ballerini, J. P. and Schfinble, P. (1998)Building a large multilingual test,, collection fromconqmrable news documents.
In 'Cross-Lanfam~cInformation Retrieval", Kluwer Academic PuNis'fi-ers, pp.
137-150.Zanettin, F. (1994) Parallel Words: Designing aBilingual Database lk~r Translation Actiwties.
In"Corpora in Language Education and Research: aSelection of Papers fi'om TALC 94", LancasterUniversity, UK, pp.
99-111.Zanettin, F. (1998) Bilingual comp(Irable con)eraand the training of translators.
In META, XLIII,4, Special Issue.
The corpus-based ap.proach: a newparadigm in translation s'tudics", pp.
616-630.1070
