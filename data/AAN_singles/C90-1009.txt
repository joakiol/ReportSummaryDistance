Japanese-to-English ProjectPROTRAN & TWINTRANJelinek, J.~, Wilcock, G?, Nishida, 0.2, Yoshimi, T."Bos, M. J. W. 3, Tamura, N. a, Murakan~fi, H. 31.
Center for Japanese Studies, The University of Sheffield, S102tn, U.K.2.
SHARP Corporation, 492 Minosho-cho, Yamatokouriyama, Nara, Japan3.
Faculty of Engineering, Kobe University, Rokkodai, Nada, Kobe 657, Japan1 BackgroundI.D.S.
stands for Integrated Dictionary Systems.Its distinguishing feature is the integration ofthe bulk of grammar (= morphology, instruc-tions for syntactic analysis, transfer and gener-ation) !into the dictionary.Research on these lines, Mined at :Japanese-to-English Machine ~h:a.nslation, started in theearly 60's and found practical application as atool for teaching monolinguM English speakersto decode Japanese.
Applications of this methodto other language pairs have also taken place.The fDS approach to Japanese-to-English MTfound sponsorship from the British Governmentand ICL from 1984 as part of ALVEY (IKBSproject no.25, carried out at the University ofSheffield, England in cooperation with ICL andKobe University, Japan).
When the Japanese toEnglish part of the ALVEY project was success-fully concluded in 1987, resulting in the creationof AIDTRANS, SHARP Corporation (Japan)concluded an agreement with the hitherto part-ners and took over further sponsorship of thisresearch.
This note is about the work carriedout after that.We have since achieved a working prototypeof the sentence-for-sentence component knownas PROTRAN and work now continues at KobeUniversity, under SHARP sponsorship, on thedevelopment of a textwide component (TWIN-TRAN) which could run on top of the existingmodel.2 Sentence-for-Sentence Com-ponent: PROTRAN2.1 Linguistic Rules and the Process-ing SystemOur mMn task in the last year of research asbeen to reformulate the sentence-for-sentenceJapanese-to-English ystem in such a way asto make the complete linguistic information ex-plicit, which are executed by a processing systemseparate from these rules.
The processing sys-tem is all programmed in Prolog and executesthe linguistic rules by applying a function toeach type of ~ule.
This task has largely beenachieved by now.The linguistic information resides in tlhe fol-lowing sets of rules:1) Japanese-to-English Automatic Dictionary(at present 32000 entries), held in a rela-tional database with seven fields for eachentry (combined key comprises the fieldsEntry_~ord, Translat ion,  ~lord._class,Entry_code and Continuation; outsidekey are the fields P r io r i ty  and Semantic_category).2) Prioritised list of permitted juxtapositionallinksMorpholexical analysis is executed by alinear chart parser utilising the fieldsEntry_~ord, Entry_code, Continuationand Pr io r i ty  from the dictionaxy databaseand the prioritised list of permitted links.This yields a set of morphological word class50 1strings, each of which maps the input sen-tence, evaluated for their juxtapositionalsuitability and their morpholexical suitabil-ity as the best of all obtainable dictionarymappings of the input sentence.
This eval-uation takes place in two tiers, first utilisingthe prioritised list of permitted links (to ob-tain morphological optimum) and then onthe basis of the field "priority" of each en-try (to obtain lexicM optinrum).
Only theoverall optimum mappings are passed on forfurther processing.3) Morpholexical Grammar Rules (which arelinear rewrite rules)A set of linear grammar rules is appliedto produce strings of syntactic word classesout of the original strings of morphologicalword classes.4) Syntactic Analysis Rules (allowing parsinginto trees)A version of Bottom-Up Parser \[4\] is thenused to execute the linguistic rules for Syn-tactic Analysis, resulting in a set of all a.1-lowable Japanese trees for the Japanese in-put sentence.
We now have a prioritisedversion of these rules, designed to avoidcarrying out the complete search in favourof proceeding with tire best option onlyand coming back only if this option failsin further processing.
Work is in progressat present, to be incorporated in TWIN-TRAN, to implement this stage in the fornrof demand-driven prioritised chart parser(whereby the chart parser is cmttrolled byan A* al.gorith.m).5) Sentence Pattern Transfer Rules (specifyingcase-type word order transfer)A set of functions applies the rules ofSentence Pattern Transfer (which are de-fined as Production Rules), moving verb-dependent case groups to their appropri-ate English word order positions, supply-ing default prepositions for each case groupand creating default Subjects and/or Ob-jects where necessary.
Unlike all the previ-ous stages, which, are all largely divergent,6)this process contains little divergence andprioritisation has not yet been introduced.Substitution Rules (which deal with all re-maiming word order transfer, which at thisstage is Entry-Specific)Substitution is a set of functions executingrules which finalise the English word orderdown to the lowest level of trees, but theoutput remMns in the form of trees.
Thisprocess tends to output fewer alternativesthan have been input, as some trees are li-able to be eliminated.Generation Rules (which produce Englishword forms)Generation produces actual English sen-tences by scanning all tree node labels inpost-order, activating Generation rules bynode labels.
It still preserves multiple userchoices not only from amongst differentsentence-level renderings of the input sen-tence but also from within sets of local al-ternatives within each version of the sen-tence.2.2 Po in ts  o f  ConvergenceIt is common knowledge that.
the kind of exercisedescribed above is bound to entail combinatorialexplosion at several points from (1) to (4) if nomeasures are taken to prevent it.
An inseparablepart of our method is the reliance on the so-called Points of Convergence to overcome thisproblem.A point of convergence is a point at which allalternatives so far listed have the same chance ofsuccess vis-~-vis what ma.y folk)w. A selection ofthe best alternative(s), or a ranking of these al-ternatives as to their relative '(goodness", maytherefore be carried out i~t each poi~t of con-vergence, i.e.
severM times before the end ofsentence is reached.Points of convergence may be total (whenall available a.lternatives a.t that point stand anequal chance of success) or partial (as betweenonly some available alternatives).
These pointsare found not only at the stage of linear grain-mar but also on the trees produced in syntactic2 51analysis.At each point of convergence the quantity ofinformation passed on to the next process can besignificantly reduced.
The information left be-hind can either be dropped altogether (as is thecase with less than optimum morphological rep-resentations) or be graded into ranks and waitin a queue on a demand-driven basis.3 Textwide  GrammarA random sequence of sentences does not makea valid text, anymore than a random sequence ofwords makes a valid sentence (even though bothphenomena may occur by accident).
This is notprimarily because such random sequences wouldnot make a coherent sense; that would only putthem in the same category as numerous prop-erly formed and perfectly official texts, whichjust happen to talk nonsense.
Natural languageis able to express nonsense, on purpose or other-wise.
Nonsense can be grammatical and can betranslated.
Random sequences fall down mainlybecause they tend to be formally incoherent, andformal coherence is another word for grammar.There are formal rules determining text coher-ence and most of these rules have to do with theformal aspect of correferentiality.
Certain struc-tures are formally able to refer again to someitems (assertions, events, facts, objects or per-sons) that have previously been mentioned inthe same text.
Unless this "referring again", orcorreferentiality, happens quite often and suIfi-ciently thoroughly, the text cannot be under-stood as one coherent linguistic entity and mayend up looking like a random sequence of sen-tences.The rules of grammar governing correferen-tiality are based on the theory of depredication\[2\] \[3\].
We have formulated these rules for thespecific process of translating from Japanese toEnglish.
Their implementation also requires afairly simple but robust semantic network, basedentirely on only one type of semantic relationknown as subsumption.We believe that TWINTI?AN will be able todemonstrate the functioning of textwide gram-mar in time for this conference.A processing stage which would come up withonly one definite %ptimum" alternative at thevery end is not yet implemented.
Since themain prospective user is meant o be a monolin-gual Japanese, we envisage the need \[or interac-tive disambiguation based on reformulating theJapanese sentence in alternative Japanese ren-derings.AcknowledgementWe wish to express our gratitude to Prof. StevenL.
Tanimoto of University of Washington andMr.
Mikio Osaki, Mr. Shinobu Shiotani and Mr.ttitoshi Suzuki of SHARP Corporation.References\[1\]\[2\]\[3\]Knowles, F. E.; Jelinek, J. and Wood, M.McG.
: The ALVEY Japanese and EnglishMachine Translation Project, Proceedingsof Machine Translation Sunrmit Confer-ence, Tokyo 1987.Jelinek, Jiri : A Linguistic Aspect of Trans-formation Rules, in Acta Universitatis Car-olinae - Philologica, I (Slavica Pragensia,VII), Prague 1965.Jelinek, Jiri : Construct Classes, PragueStudies in Mathematical Linguistics 2,1966.\[4\] Matsumoto, Y. : BUP : A Bottom-UpParser Embedded in Prolog, New Genera-tion Computing, Vol.
1, No.
2, pp.145-158,1983.52 3
