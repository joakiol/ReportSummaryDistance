Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 526?536,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsInvestigating the Sources of Linguistic Alignment in ConversationGabriel DoyleDepartment of PsychologyStanford UniversityStanford, CA 94305gdoyle@stanford.eduMichael C. FrankDepartment of PsychologyStanford UniversityStanford, CA 94305mcfrank@stanford.eduAbstractIn conversation, speakers tend to ?ac-commodate?
or ?align?
to their partners,changing the style and substance of theircommunications to be more similar totheir partners?
utterances.
We focus hereon ?linguistic alignment,?
changes in wordchoice based on others?
choices.
Althoughlinguistic alignment is observed acrossmany different contexts and its degree cor-relates with important social factors suchas power and likability, its sources are stilluncertain.
We build on a recent probabilis-tic model of alignment, using it to separateout alignment attributable to words ver-sus word categories.
We model alignmentin two contexts: telephone conversationsand microblog replies.
Our results showevidence of alignment, but it is primarilylexical rather than categorical.
Further-more, we find that discourse acts modu-late alignment substantially.
This evidencesupports the view that alignment is shapedby strategic communicative processes re-lated to the ongoing discourse.1 IntroductionIn conversation, people tend to adapt to one an-other across a broad range of behaviors.
Thisadaptation behavior is collectively known as?communication accommodation?
(Giles et al,1991).
Linguistic alignment, the use of sim-ilar words to a conversational partner, is oneprominent form of accommodation.
Alignment isfound robustly across many settings, including in-person, computer-mediated, and web-based con-versation (Danescu-Niculescu-Mizil et al, 2012;Giles et al, 1979; Niederhoffer and Pennebaker,2002).
In addition, the strength of alignment toconversational partners varies with relevant socio-logical factors, such as the power of the partners,their social network centrality, and their likability.Potentially, this alignment could be used to inferthese factors in situations where they are difficultto observe directly.Although linguistic alignment appears to reflectimportant social dynamics, the mechanisms un-derlying alignment are still not well-understood.One particular question is whether alignment issupported by relatively automatic priming mecha-nisms, or higher-level, discourse and communica-tive strategies.
The Interactive Alignment Modelproposes that conversational partners prime eachother, causing alignment via the primed reuse ofstructures ranging from individual lexical itemsto syntactic abstractions (Pickering and Garrod,2004).
In contrast, Accommodation Theory em-phasizes the relatively more communicative andstrategic nature of alignment (Giles et al, 1991).Relative to this theoretical landscape, a numberof questions have emerged.
First, does alignmentoccur at structural levels?
If alignment is driven byinteractive priming of structures, effects of align-ment should be expected not only at the lexicallevel but also for structural elements or categoriesas well.
In contrast, if alignment is primarily com-municative, then alignment strength might differand be greater for specific words that serve par-ticular conversational or discourse functions in aparticular situation.Second, does alignment vary with conversa-tional goals?
If alignment is driven primarily bypriming, it should be relatively consistent acrossdifferent aspects of a discourse.
In contrast, froma strategic or communicative perspective, align-ment ?
in which preceding words and conceptsare reused ?
must be balanced against a needto move the conversation forward by introducingnew words and concepts.
Thus, on a communica-526tive account, alignment should be modulated bythe speaker?s discourse act, reflecting whether thebalance of the concern is convergence on a currentfocus or conveyal of new information.Our goal in the current work is to investigatethese questions.
We make use of a recent prob-abilistic model of linguistic alignment, modify-ing it to operate robustly over corpora with highlyvarying distributional structures and to considerboth lexical and category-based alignment.
Weuse two corpora of spontaneous conversations, theSwitchboard Corpus and a corpus of Twitter con-versations, to perform two experiments.
First, inboth datasets we measure alignment across dif-ferent levels of representation and find very lim-ited evidence for category-level alignment.
Sec-ond, we make use of annotations in Switchboard tomeasure alignment across different discourse acts,finding that the level of alignment depends on thediscourse actions that are included in the analy-sis.
Taken together, these findings are consistentwith the idea that alignment arises from discourse-level, strategic processes that operate primarilyover lexical items.2 Previous Work2.1 Why does alignment matter?Linguistic alignment, like other kinds of accom-modation, can be a critical part of achieving so-cial goals.
Performance in cooperative decision-making tasks is positively related to the par-ticipants?
linguistic convergence (Fusaroli et al,2012; Kacewicz et al, 2013).
Romantically,match-making in speed dating and stability in es-tablished relationships have both been linked toincreased alignment (Ireland et al, 2011).
Align-ment can also improve perceived persuasiveness,encouraging listeners to follow good health prac-tices (Kline and Ceropski, 1984) or to leave largertips (van Baaren et al, 2003).Alignment is also important as an indicatorof implicit sociological variables.
Less power-ful conversants generally accommodate to moreto powerful conversants.
Prominent examples in-clude interviews and jury trials (Willemyns et al,1997; Gnisci, 2005; Danescu-Niculescu-Mizil etal., 2012).
A similar effect is found for networkstructure: speakers align more to more network-central speakers (Noble and Fern?andez, 2015).Additionally, factors such as gender, likability, re-spect, and attraction all interact with the magni-tude of accommodation (Bilous and Krauss, 1988;Natale, 1975).2.2 Sources of linguistic alignmentDespite the important outcomes associated withalignment, its sources are not clear.
The mostprominent strand of work on alignment has fo-cused on the level of word categories, looking athow interlocutors change their frequency of us-ing, for instance, pronouns or quantitative words(Danescu-Niculescu-Mizil et al, 2012; Ireland etal., 2011).
These results show alignment effectsat the category level, but it is in principle possi-ble that these effects arose purely from alignmenton individual words (and that conclusion wouldnot be inconsistent with the interpretation of thatwork).Syntactic alignment is one area in which the-oretical predictions have been tested, though re-sults have been somewhat equivocal.
The Interac-tive Alignment Model has generally been taken tosuggest that there should be cross-person primingof syntactic categories and structures (Pickeringand Garrod, 2004).
But while some studies havefound support for syntactic priming (Gries, 2005;Dubey et al, 2005), others have found negative ornull alignment (Healey et al, 2014; Reitter et al,2006).
In one particularly thorough study, Healeyet al (2014) found across two corpora that speak-ers syntactically diverged from their interlocutorsonce lexical alignment was accounted for.Furthermore, positive alignment is generally re-garded as a good conversational tactic, but thereis clearly a limit to its virtues, at least when itcomes to content words.
Alignment is inher-ently backward-looking, while the general goalof a conversation is to exchange information thatis not already known by both parties, an inher-ently forward-looking goal.
Perhaps because ofthis, some recent work finding positive alignmenthas limited itself to ?non-topical?
word categories,which are less contentful (Danescu-Niculescu-Mizil et al, 2011; Doyle et al, 2016).
And sug-gestively, alignment within a task-relevant syntac-tic category was a better predictor of decision-making performance than overall lexical align-ment (Fusaroli et al, 2012).In sum, although individual studies do bear onthe sources of alignment, the picture is still notclear.
Because most work on alignment has beendone either on categories of words or aggregating527across the lexicon, we do not have a good sense ofwhether there are systematic differences in align-ment at different levels of representation.
A fur-ther complication is that there is no standard mea-sure of alignment; we turn to this issue next.2.3 Measures of alignmentThe metrics used in previous work fall into twobasic categories: distributional and conditional.Distributional methods such as Linguistic StyleMatching (LSM) (Niederhoffer and Pennebaker,2002; Ireland et al, 2011) or the Zelig Quotient(Jones et al, 2014) calculate the similarity be-tween the conversation participants over their fre-quencies of word or word category use in all utter-ances within the conversation.
In contrast, condi-tional metrics, such as Local Linguistic Alignment(LLA) (Fusaroli et al, 2012; Wang et al, 2014)and the metric used by Danescu-Nicolescu-Mizilet al (2011), look at how a message conditions itsreply, with alignment indicated by elevated worduse in the reply when that word was in the preced-ing message.While distributional methods have been popu-lar, a major weakness of such methods is that theydo not necessarily show true alignment, only sim-ilarity.
A high level of distributional similaritydoes not imply that two conversational partnershave aligned to one another, because they mightinstead have been similar to begin with.
In con-trast, conditional measures allow for stronger in-ferences about the temporal sequence of alignment(even though they cannot guarantee any causal in-terpretation).
Thus, we focus here on conditionalmeasures exclusively.By-message conditional methods Several ex-isting conditional methods have started from thesimplified representation that messages either door do not contain particular words (?markers?
),irrespective of message length or marker count.
(Danescu-Niculescu-Mizil et al, 2012; Doyle etal., 2016).
We refer to these as ?by-message?methods.
Consider the following example of con-ditional alignment, using pronouns as the marker:Bob aligns to Alice if his replies are more likely tocontain a pronoun when in response to a messagefrom Alice that contains a pronoun.Bob?s replyAlice?s message has pronoun no pronounhas pronoun 8 2no pronoun 5 5Here, Alice sends 10 messages that contain atleast one pronoun, and 8 of Bob?s replies containat least one pronoun.
But Alice also sends 10 mes-sages that don?t contain any pronouns, and only 5of Bob?s replies to these contain pronouns.
Thisincreased likelihood of a pronoun-containing re-ply to a pronoun-containing message is the condi-tional alignment.Different models quantify this conditionalalignment slightly differently.
Danescu-Niculescu-Mizil et al (2011) proposed asubtractive conditional probability model,where alignment is the difference between thelikelihood of a pronoun-containing reply Bto a pronoun-containing message A and theprobability of a pronoun-containing reply to anymessage:alignSCP= p(B|A)?
p(B) (1)Doyle et al (2016) showed that this measurecan be affected by the overall frequency of thecategory being aligned on, though.
To correctthis issue, they proposed a Hierarchical AlignmentModel (HAM), which defines alignment as a lin-ear effect on the log-odds of a reply containing therelevant marker (e.g., a pronoun), similar to a lin-ear predictor in a logistic regression.1(2)alignHAM?
logit?1(p(B|A))?logit?1(p(B|?A))These binary conditional methods depend onthe assumption that all messages have similar, andsmall, numbers of words, however.
The prob-ability that a message contains at least one ofany marker of interest is dependent on the mes-sage?s length, so if messages vary substantially intheir length, these alignment values can be at leastnoisy, if not biased.
They are also not robust asmessages increase in length, since the likelihoodthat a message contains any marker approaches 1as message length increases.By-word conditional methods A solution to theproblem of variable message lengths is simply toshift from binarized data to count data.
Insteadof counting how many times Bob?s replies con-tain at least one pronoun, we can count what pro-portion of his replies?
word tokens are pronouns.1Because the HAM estimated this quantity via Bayesianinference, the inferred alignment value depends on the priorand number of messages observed, so unlike the other mea-sures, this equality is only approximate.528Some existing measures use a related quantity, theproportion of the preceding message that appearsin its reply, to estimate alignment, notably LocalLinguistic Alignment (LLA) (Fusaroli et al, 2012;Wang et al, 2014) and the lexical similarity (LS)measure of Healey et al (2014).
LLA is defined asthe number of word tokens (wi) that appear in boththe message (Ma) and the reply (Mb), divided bythe product of the total number of word tokens inthe message and reply:alignLLA=?wi?Mb?
(wi?Ma)length(Ma)length(Mb)(3)These measures have an aspect of conditional-ity, as they only count words that appear in boththe message and the reply.
But they neverthelessfail to control for the baseline frequency of the ini-tial marker, and hence may be biased in measure-ments across words or categories of different fre-quencies (Doyle et al, 2016).
They also can beaffected by reply length, as the maximum align-ment estimate is only possible when the reply isshorter than the message.All of these by-word conditional models treatthe reply as a bag of words, without order informa-tion.
The by-word models, including the WHAMmodel we propose, are agnostic about reply lengtheffects, correcting for the artifactual length effectsof by-message models, but assuming that all mes-sages have similar alignment strengths indepen-dent of length.
This is in contrast to models thatexplicitly model priming effects as decaying overtime (Reitter et al, 2006; Reitter, 2008), whichpredict higher alignment in shorter replies.
Futureby-word alignment models could infer a discount-ing for words that occur later in the reply, simi-lar to the beta value on the log-distance from theprime proposed in Reitter et al (2006).Our goal in this work is to create a model thatcombines the benefits of the existing by-messageconditional models with the length-robustness of aby-word conditional method.
We present WHAM,a modification of the HAM model that satisfiesthis goal.3 The Word-Based HierarchicalAlignment Model (WHAM)We propose the Word-Based Hierarchical Align-ment Model (WHAM).
Like HAM, WHAM as-sumes that word use in replies is shaped bywhether the preceding message contained themarker of interest.
But WHAM uses marker to-ken frequencies within replies, so that a 40-wordreply with two instances of the marker is repre-sented differently from a 3-word reply containingone instance.For each marker, WHAM treats each reply as aseries of token-by-token independent draws froma binomial distribution.
The binomial probabil-ity ?
is dependent on whether the preceding mes-sage did (?align) or did not (?base) contain themarker, and the inferred alignment value is thedifference between these probabilities in log-oddsspace (?align).
The graphical model is shown inFigure 1.For a set of message-reply pairs between aspeaker-replier dyad (a, b), we first separate thereplies into two sets based on whether the preced-ing message contained the marker m (the ?align-ment?
set) or not (the ?baseline?
set).
All replieswithin a set are then aggregated in a single bag-of-words representation, with marker token countsCalignm,a,band Cbasem,a,b, and total token counts Nbasem,a,band Nbasem,a,b, the observed variables on the far rightof the model.
Moving from right to left, thesecounts are assumed to come from binomial drawswith probability ?alignm,a,bor ?basem,a,b.
The ?
valuesare generated from ?
values in log-odds space byan inverse-logit transform, similar to linear predic-tors in logistic regression.The ?basevariables are representations of thebaseline frequency of a marker in log-odds space,and ?baseis simply a conversion of ?baseto proba-bility space, the equivalent of an intercept term ina logistic regression.
?alignis an additive value,with ?align= logit?1(?base+ ?align), the equiv-alent of a binary feature coefficient in a logisticregression.
Alignment is then the change in log-odds of the replier using m above baseline usage,given that the initial message uses m.The remainder of the model is a hierarchy ofnormal distributions that allow social and wordcategory structure to be integrated into the anal-ysis.
In the present work, we have three levelsin the hierarchy: category level, marker level,2and conversational dyad level.
All of these nor-mal distributions have identical standard devia-tions ?2= .25.3A Cauchy(0, 2.5) distribution2In the lexical and category-not-word alignment models,these markers are words within a category.
The categoryalignment model does not include this level, since all wordsin a category are treated identically.3This value was chosen as a good balance between rea-529CN?bases?basem?basem,a,b?basem,a,bCbasem,a,b?aligns?alignm?alignm,a,b?alignm,a,bCalignm,a,bCategoryMarkerDyadN Nlogit?1BinomN Nlogit?1BinomNbasem,a,bNalignm,a,b(a, b) ?
Dm ?
ss ?
SFigure 1: The Word-Based Hierarchical Alignment Model (WHAM).
A chain of normal distributionsgenerates a linear predictor ?, which is converted into a probability ?
for binomial draws of the words ineach reply.gives a relatively uninformative prior for the base-line marker frequency (Gelman et al, 2008).
Thealignment hierarchy is headed by a normal distri-bution centered at 0, biasing the model equally infavor of positive and negative alignments.For our marker set, we adopt the Linguistic In-quiry and Word Count (LIWC) system to catego-rize words (Pennebaker et al, 2007).
We use aset of 11 categories that have shown alignment ef-fects in previous work (Danescu-Niculescu-Mizilet al, 2011).
These can be loosely grouped intoa set of five syntactic categories (articles, con-junctions, prepositions, pronouns, and quantifiers)and six conceptual categories (certainty, discrep-ancy, exclusion, inclusion, negation, and tenta-tive).
Categories and example elements are shownin Table 1.
We manually lemmatized all words ineach category.
We implemented WHAM in RStan(Carpenter, 2015), with code available at http://github.com/langcog/disc_align.3.1 Validating WHAMA major goal of our by-word alignment model,WHAM, is to fix the length issues discussed inSection 2.3.
We test WHAM and the by-messageHAM model on simulated data, using a methodsimilar to Simulation 2 in Doyle et al (2016), tosonable parameter convergence (improved by smaller ?2) andgood model log-probability (improved by larger ?2).Swbd TwitCategory Examples Size Prob ProbArticle a, the 2 .053 .047Certainty always, never 17 .014 .015Conjunction but, and, though 18 .077 .051Discrepancy should, would 21 .015 .019Exclusive without, exclude 77 .038 .028Inclusive with, include 57 .057 .028Negation not, never 12 .020 .023Preposition to, in, by, from 97 .097 .091Pronoun it, you 55 .17 .16Quantifier few, many 23 .028 .025Tentative maybe, perhaps 28 .033 .025Table 1: Marker categories for linguistic align-ment, with examples, number of distinct wordlemmas, and token probability of in a reply inSwitchboard and Twitter.see how robust they are to different reply lengths.We generate 500 speaker-replier dyads, each ex-changing an average of 5 message pairs (drawnfrom a geometric distribution).
Each message pairconsists of a message whose length in words isdrawn from a uniform distribution [1, 25], and areply of length L. Because our goal is to test theeffect of length on the models?
performances, wecreate separate simulated datasets for different val-ues of L, and see whether the model correctly es-timates the alignment value ?align.
Three inde-pendent simulations were run for each alignment-length pair.
We present data here for a simulated530llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll llllllllllllllllllllllllllllllllllllllllllllllllll?1.0?0.50.00.5?1012WHAMHAM?1.0 ?0.5 0.0 0.5 1.0true alignmentestimated alignment  replylengthlllll15102550Figure 2: Actual versus estimated alignment onsimulated data.
Lines are loess-fit curves; colorsrepresent the reply length in the simulation run.WHAM estimates alignment accurately regardlessof reply length; HAM is highly affected by length.word category with a baseline frequency of 0.1,around the middle of the attested category fre-quency range (see Table 1).Figure 2 plots the true alignment value in thesimulations against the model-estimated align-ment values.
Different colors represent differentreply lengths L, ranging from single-word replies(light yellow) to 50-word replies (dark orange).The WHAM model shows consistently accuratealignment estimates over the range of simulatedalignment values and reply lengths.
The HAMmodel estimates the alignment far less accurately,and the reply length biases its estimates.4 DataMoving on to real data, we use two corpora for ourexperiments.
The first is a collection of Twitterconversations collected by Doyle & Frank (2015)to examine information density in conversation.This corpus focuses on conversations within a setof 14 mostly distinct sub-communities on Twitter,and contains 63,673 conversation threads, cover-ing 228,923 total tweets.
We divide these con-versations into message pairs, also called conver-sational turns, which are two consecutive tweetswithin a conversation thread.
The second tweet isalways in reply to the first (according to the TwitterAPI), although this does not necessarily mean thatthe content of the reply is a response to the preced-ing tweet.
Retweets (including explicit retweetsand some common manual retweet methods) wereremoved automatically.
This processing leaves uswith 122,693 message pairs, spanning 2,815 users.The tweets were parsed into word tokens using theTwokenizer (Owoputi et al, 2013).The second corpus is the SwDA version of theSwitchboard corpus (Godfrey et al, 1992; Juraf-sky et al, 1997).4This corpus is a collection oftranscribed telephone conversations, with each ut-terance labeled with the discourse act it is per-forming (e.g., statement of opinion, signal of non-understanding).
It contains 221,616 total utter-ances in 1,155 conversations.
We combine con-secutive utterances by the same speaker withoutinterruption from the listener into a single messageand treat consecutive pairs of messages from dif-ferent speakers as conversation turns, resulting in110,615 message pairs.5 Experiment 1: Lexical- andCategory-Level AlignmentOur first experiment examines how alignment dif-fers across the lexical and categorical levels.
Weuse the WHAM framework to infer alignment onword and category counts, and also introduce ameasure to estimate the influence of one word in acategory on other words in its category, ?category-not-word?
alignment.
We include this last type ofalignment because it is possible that the categoryalignment effects in previous work are the resultof lexical alignment on the individual words inthe category, without any influence across wordsin the category.
If categorical alignment is areal effect over and above lexical alignment, asan interactive-priming source for alignment wouldsuggest, then the presence of a word in a messageshould not only increase the chance of seeing thatword in the reply, but also other words in its cate-gory.5.1 Category-not-word-alignment modelAssessing the amount of alignment triggeredacross words in a category (which we call?category-not-word alignment?
or CNW) is nottrivial, as there are a variety of interactions be-tween lexical items within a category that cancause the lexical alignment to actually be less than4Available courtesy of Christopher Potts at http://compprag.christopherpotts.net/swda.html.531ReplyMessage ?
he she?
25 25 25he 20 50 10she 20 10 50Table 2: A theoretical case where lexical align-ment surpasses categorical alignment due to nega-tive CNW between the words.the category alignment.
Table 2 illustrates thiswith a theoretical distribution over the pronounshe and she; one use of the pronoun he makes an-other use more likely (A: Did he like the movie?B: Yeah, he loved it.)
while also reducing the like-lihood of she, since the topic of conversation isnow a male, and vice versa for she.
For both heand she, the lexical alignment is approximatelylogit?1(p(B|A) ?
p(B|?A)) = logit?1(5080?2575) ?
1.2, but categorical alignment is approx-imately logit?1(120160?5075) ?
0.4.
On the otherhand, the pronouns you and I might trigger eachother more than themselves (A: Did you like themovie?
B: Yeah, I loved it.
).The differences between lexical, categorical,and CNW alignment are also relevant to discus-sions of ?lexical boosts?
in the syntactic primingliterature, an increased priming effect at the cate-gorical level when there is lexical repetition.
Lex-icalist residual activation accounts (Pickering andBranigan, 1998) predict such a boost, while im-plicit learning accounts do not (Bock and Griffin,2000; Chang et al, 2006).
In the context of thisexperiment, such a lexical boost could make lexi-cal and categorical alignment appear elevated andcloser together, but would not have a substantialeffect on CNW alignment.5To investigate CNW alignment, we look at asubset of the data: for each word w, exclude allmessages that contain a word from that category(S) that is not w. This limits the category align-ment influence on the reply to the single word w.Then, instead of looking at how oftenw appears inthe reply, we look at how often all other words incategory S appear in the reply.
The model then in-fers the influence of w on the other words in thecategory independent of their lexical alignment.5The categories being investigated in our work containmostly non-topical, closed-class words, which have not ex-hibited lexical boosts in past research (Bock, 1989; Pickeringand Branigan, 1998; Hartsuiker et al, 2008), but such boost-ing may be detectable in estimates on topical categories.Within the WHAM model, we change the countvariablesC?andN?so thatCalignis the number oftokens of {S ?w} in replies to messages contain-ing w but not {S ?
w}.
Cbaseis then the numberin replies to messages not containing any wordsin S. Similarly, Nalignis the total token countsover replies containing w but not any other wordsin S, and Nbasethe total token counts over repliescontaining no words in S.5.2 MethodsWe conducted three sets of simulations, fitting themodel with marker categories, individual words,and with the CNW scheme described above.
Ineach, the model was fit with two chains of 200 it-erations of the sampler for each dataset.
We thenextracted alignment estimates from each of the fi-nal 100 samples, and we report 95% highest pos-terior density intervals on ?alignS.5.3 ResultsFigure 3 shows the alignment on each markercategory in the Twitter and Switchboard corpora.There were substantial differences in the overallrate of alignment between the corpora: Mean cat-egory alignment on Twitter was .19, while Switch-board category alignment was ?.051.
These dif-ferences may reflect the nature of the two dis-course contexts: Replies on Twitter are composedwhile looking at the preceding message, encour-aging the replier to take more account of the othertweeter?s words, and a replier can draft and edittheir reply to make it better fit the conversation.Messages on Switchboard, on the other hand, areevanescent, so a replier must compose a replywithout looking back at the message, without edit-ing, and in real-time.
Differences in the discoursestructure of these corpora may also be contribut-ing, an effect we will consider in Experiment 2.Despite the difference in reply construction inthe two corpora, the results across levels of align-ment were similar.
Alignment was found primar-ily at the lexical ?
rather than the category ?
level.Lexical and category alignment were not signifi-cantly different from each other, but the strengthof lexical alignment was significantly larger thanthe CNW alignment, according to a t-test over cat-egories (Twitter: t(10) = .21, p < .001; Swbd:t(10) = .12, p = .003).
CNW alignment wassignificantly negative on Switchboard (t(10) =?.11, p = .01) and not significantly different fromzero on Twitter (t(10) = .009, p = .79).532Syntactic Conceptual?????????
????????????
??????
??????
??????
???
???
?????????
?????????
???
?0.50.00.51.0?0.50.00.51.0TwitterSwitchboardarticleconjunctionprepositionpronounsquantifiercertaintydiscrepancyexclusioninclusionnegationtentativeestimated alignment (logodds)?
?
?Category Lexical CNWFigure 3: Categorical (red), lexical (blue), and CNW (green) alignments plotted by category, on theTwitter (left) and Switchboard (right) datasets.
95% HPD intervals from WHAM shown.WHAM ?
unlike other previous measures ?provides estimates of alignment that are unbiasedby either marker frequency or message length,but we still observed modest alignment on Twit-ter, replicating previous work (Doyle et al, 2016;Danescu-Niculescu-Mizil et al, 2011).
Alignmentwas smaller in Switchboard, and in both casesthere were no category effects.
Thus, the categor-ical alignment results may result primarily fromlexical alignment, inconsistent with the predic-tions of interactive priming accounts of alignment.6 Experiment 2: Discourse Acts andAlignmentMessages within a discourse can serve a very widerange of purposes.
This variety has effects for bothlinguistic structure and the relationship to neigh-boring messages.
For example, a simple yes/noquestion is likely to receive a short, constrained re-ply, while a statement of an opinion is more likelyto yield a longer reply.
In addition, different typesof messages can either introduce new informationto the conversation (e.g., statements, questions, of-fers) or look back at existing information (e.g., ac-knowledgments, reformulations, yes/no answers).We hypothesize that alignment will be substan-tially different depending on the discourse act, asspeakers?
conversational goals vary.
Thus, oursecond experiment examines how alignment dif-fers depending on discourse act.We focus on a particular kind of discourse act,the backchannel (Yngve, 1970).
Backchannels areextremely common in Switchboard, accountingfor almost 20% of utterances, and include utter-ances such as single words signaling understand-ing or misunderstanding (yeah, uh-huh, no) orsimple messages expressing empathy without try-ing to take a full conversational turn (It must havebeen tough).
Backchannels are a particularly inter-esting case because their short and constrained na-ture makes it difficult to align on some categories(e.g., backchannels rarely contain quantifiers orprepositions), while the purpose of giving feed-back to the speaker makes it important to align onothers (e.g., matching the positive/negative tone orcertainty of a speaker).
In addition, backchannelsare primarily restricted to spoken corpora.
Twitterconversations contain far fewer backchannels thanSwitchboard, which may account for some of theiralignment differences?especially as the results ofthis experiment suggest that backchannels reduceoverall alignment.6.1 MethodsWe use the discourse-annotated Switchboard cor-pus to compare alignment in conversations con-taining backchannels with those whose backchan-nels have been removed.
We make this compari-son by creating a second corpus, removing everyutterance classified as a backchannel from the cor-pus prior to parsing the utterances into conversa-tion turns as before.533syntactic conceptuallll lll lll lll lll llllll lll llllll lll?0.50.00.51.0articleconjunctionprepositionpronouns quantifiercertaintydiscrepancyexclusioninclusionnegationtentativemarker categoryestimatedalignmentalignment type l l lcategory lexical CNWSwitchboard alignments (w/o backchannels)Figure 4: Categorical (red), lexical (blue), andCNW (green) alignments on the Switchboarddataset with backchannels removed.
95% HPD in-tervals from WHAM shown.6.2 ResultsAlignment values for the Switchboard corpuswithout backchannels are shown in Figure 4.
Asexpected, alignment is on average higher withoutthe backchannels (p = .09 for category, p < .05for lexical and CNW), reflecting the constrainednature of backchannels.
Lexical alignment is sig-nificantly higher than category alignment (t(10) =?.08, p = .03), consistent with the findings of Ex-periment 1.
The mean category alignment withoutbackchannels is .029.Figure 5 compares the category alignments forthe full Switchboard corpus (green) and Switch-board without backchannels (orange).
Alignmenton the full corpus is lower for all but two cat-egories, exhibiting the reduced opportunity foralignment provided by backchannels.
Syntac-tic category alignment is especially affected bybackchannels, whose constrained forms providevery little ability to align syntactically.Interestingly, the two categories that do showgreater alignment when backchannels are includedare certainty and negation.
These categoriesare both important for backchannels; a negativebackchannel is generally inappropriate in reply toa non-negative message, and similarly a confidentbackchannel would often be out of place in replyto an uncertain message.
These influences of dis-course acts on alignment are more consistent witha discourse-strategic origin for alignment than apriming-based account.syntactic conceptualllll ll ll ll llllllllllll?0.4?0.20.00.20.4articleconjunctionprepositionpronouns quantifiercertaintydiscrepancyexclusioninclusionnegationtentativemarker categoryestimatedalignmentcorpus l lSwbd Swbd w/o backchannelsCategory alignment and backchannelsFigure 5: Comparing categorical alignment on theSwitchboard dataset with and without backchan-nels.
95% HPD intervals from WHAM shown.7 DiscussionLinguistic alignment is a prominent type of com-municative accommodation, but its sources are un-clear.
We presented WHAM, a length-robust ex-tension of a probabilistic alignment model.
Usingthis model, we find evidence that linguistic align-ment is primarily lexical, and that it is strongly af-fected by at least some aspects of the discoursegoal of a message.This combination of a primarily-lexical originfor linguistic alignment and its variation by wordcategory and discourse act suggest that alignmentis primarily a higher-level discourse strategy ratherthan a low-level priming-based mechanism.
Thisset of results is consistent with both Accommo-dation Theory and the set of findings, reviewedabove, that sociological factors affect the level ofobserved alignment.
The effect of discourse actson alignment further suggests that alignment isnot a completely automatic process but rather oneof many discourse strategies that speakers use toachieve their conversational goals.AcknowledgmentsWe wish to thank Dan Yurovsky, Aaron Chuey,and Jake Prasad for their work on and discus-sion of earlier versions of the model, Herb Clarkfor discussions of potential effects of messagelength, and, of course, the reviewers.
The authorswere funded by NSF BCS 1528526, NSF BCS1456077, and a grant from the Stanford Data Sci-ence Initiative.534ReferencesFrances R. Bilous and Robert M. Krauss.
1988.
Domi-nance and accommodation in the conversational be-haviours of same-and mixed-gender dyads.
Lan-guage & Communication.Kay Bock and Zenzi M. Griffin.
2000.
The persis-tence of structural priming: Transient activation orimplicit learning.
Journal of Experimental Psychol-ogy: General, 129:177?192.Kay Bock.
1989.
Closed-class immanence in sentenceproduction.
Cognition, 31:163?186.Bob Carpenter.
2015.
Stan: A Probabilistic Program-ming Language.
Journal of Statistical Software.Franklin Chang, Gary S. Dell, and Kay Bock.2006.
Becoming syntactic.
Psychological Review,113:234?272.Cristian Danescu-Niculescu-Mizil, Michael Gamon,and Susan Dumais.
2011.
Mark my words!
: lin-guistic style accommodation in social media.
InProceedings of the 20th international conference onWorld Wide Web - WWW ?11, page 745, New York,New York, USA.
ACM Press.Cristian Danescu-Niculescu-Mizil, Lillian Lee,Bo Pang, and Jon Kleinberg.
2012.
Echoes ofpower: Language effects and power differencesin social interaction.
In Proceedings of the 21stinternational conference on World Wide Web -WWW ?12, page 699.Gabriel Doyle and Michael C. Frank.
2015.
Audi-ence size and contextual effects on information den-sity in Twitter conversations.
In Proceedings ofthe Workshop on Cognitive Modeling and Compu-tational Linguistics.Gabriel Doyle, Dan Yurovsky, and Michael C. Frank.2016.
A robust framework for estimating linguisticalignment in Twitter conversations.
In WWW 2016.Amit Dubey, Patrick Sturt, and Frank Keller.
2005.Parallelism in coordination as an instance of syntac-tic priming: Evidence from corpus-based modeling.In Proceedings of the conference on Human Lan-guage Technology and Empirical Methods in Nat-ural Language Processing, pages 827?834.
Associ-ation for Computational Linguistics.Riccardo Fusaroli, Bahador Bahrami, Karsten Olsen,Andreas Roepstorff, Geraint Rees, Chris Frith, andKristian Tyl?en.
2012.
Coming to Terms: Quantify-ing the Benefits of Linguistic Coordination.
Psycho-logical Science, 23(8):931?939.Andrew Gelman, Aleks Jakulin, Maria Grazia Pittau,and Yu-Sung Su.
2008.
A weakly informative de-fault prior distribution for logistic and other regres-sion models.
The Annals of Applied Statistics.Howard Giles, Klaus R. Scherer, and Donald M. Tay-lor.
1979.
Speech markers in social interaction.
InKlaus R. Scherer and Howard Giles, editors, Socialmarkers in speech, pages 343?81.
Cambridge Uni-versity Press, Cambridge.Howard Giles, Nikolas Coupland, and Justine Coup-land.
1991.
Accommodation theory: Communica-tion, context, and consequences.
In Howard Giles,Justine Coupland, and Nikolas Coupland, editors,Contexts of accommodation: Developments in ap-plied sociolinguistics.
Cambridge University Press,Cambridge.Augusto Gnisci.
2005.
Sequential strategies of ac-commodation: A new method in courtroom.
BritishJournal of Social Psychology, 44(4):621?643.John J. Godfrey, Edward C. Holliman, and Jane Mc-Daniel.
1992.
Switchboard: Telephone speech cor-pus for research and development.
In 1992 IEEEInternational Conference on Acoustics, Speech, andSignal Processing., volume 1, pages 517?520.
IEEE.Stefan Th Gries.
2005.
Syntactic priming: A corpus-based approach.
Journal of psycholinguistic re-search, 34(4):365?399.Robert J. Hartsuiker, Sarah Bernolet, SofieSchoonbaert, Sara Speybroeck, and Dieter Van-derelst.
2008.
Syntactic priming persists whilethe lexical boost decays: Evidence from writtenand spoken dialogue.
Journal of Memory andLanguage, 58:214?238.Patrick G. T. Healey, Matthew Purver, and ChristineHowes.
2014.
Divergence in dialogue.
PloS one,9(6):e98598.Molly E. Ireland, Richard B. Slatcher, Paul W. East-wick, Lauren E. Scissors, Eli J. Finkel, and James W.Pennebaker.
2011.
Language style matching pre-dicts relationship initiation and stability.
Psycholog-ical Science, 22:39?44.Simon Jones, Rachel Cotterill, Nigel Dewdney, KateMuir, and Adam Joinson.
2014.
Finding Zeligin text: A measure for normalising linguistic ac-commodation.
In Proceedings of COLING 2014,the 25th International Conference on ComputationalLinguistics, pages 455?465.Dan Jurafsky, Elizabeth Shriberg, and Debra Biasca.1997.
Switchboard swbd-damsl shallow-discourse-function annotation coders manual.
Institute of Cog-nitive Science Technical Report, pages 97?102.Ewa Kacewicz, James W. Pennebaker, Matthew Davis,Moongee Jeon, and Arthur C. Graesser.
2013.Pronoun use reflects standings in social hierar-chies.
Journal of Language and Social Psychology,33(2):125?143.Susan L. Kline and Janet M. Ceropski.
1984.
Person-centered communication in medical practice.
In Hu-man Decision-Making, pages 120?141.
SIU Press,Carbondale.535Michael Natale.
1975.
Convergence of mean vocalintensity in dyadic communication as a function ofsocial desirability.
Journal of Personality and SocialPsychology, 32(5):790?804.Kate G. Niederhoffer and James W. Pennebaker.
2002.Linguistic style matching in social interaction.
Jour-nal of Language and Social Psychology, 21(4):337?360.Bill Noble and Raquel Fern?andez.
2015.
Centre Stage:How Social Network Position Shapes Linguistic Co-ordination.
In Proceedings of the Workshop on Cog-nitive Modeling and Computational Linguistics.Olutobi Owoputi, Brendan O?Connor, Chris Dyer,Kevin Gimpel, Nathan Schneider, and Noah Smith.2013.
Improved Part-of-Speech Tagging for On-line Conversational Text with Word Clusters.
InProceedings of the Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies, pages380?391.James W. Pennebaker, Roger J. Booth, and Martha E.Francis.
2007.
Linguistic Inquiry and Word Count:LIWC.Martin J. Pickering and H. P. Branigan.
1998.
The rep-resentation of verbs: Evidence from syntactic prim-ing in language production.
Journal of Memory andLanguage, 39:633?651.Martin J. Pickering and Simon Garrod.
2004.
Towarda mechanistic psychology of dialogue.
Behavioraland brain sciences, 27(2):169?190.David Reitter, Johanna D. Moore, and Frank Keller.2006.
Priming of syntactic rules in task-oriented di-alogue and spontaneous conversation.
In Proceed-ings of the 28th Annual Conference of the CognitiveScience Society.David Reitter.
2008.
Context Effects in Language Pro-duction: Models of Syntactic Priming in DialogueCorpora.
Ph.D. thesis, U. of Edinburgh.Rick B. van Baaren, Rob W. Holland, Bregje Steenaert,and Ad van Knippenberg.
2003.
Mimicryfor money: Behavioral consequences of imita-tion.
Journal of Experimental Social Psychology,39(4):393?398.Yafei Wang, David Reitter, and John Yen.
2014.
Lin-guistic Adaptation in Conversation Threads: Ana-lyzing Alignment in Online Health Communities.
InProceedings of the Annual Meeting of the Associa-tion for Computational Linguistics.Michael Willemyns, Cynthia Gallois, Victor Callan,and Jeffrey Pittam.
1997.
Accent accommodationin the employment interview.
Journal of Languageand Social Psychology, 15(1):3?22.Victor Yngve.
1970.
On getting a word in edgewise.In Papers from the Sixth Regional Meeting of theChicago Linguistics Society, pages 567?577.536
