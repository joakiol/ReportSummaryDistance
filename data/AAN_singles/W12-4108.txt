Proceedings of the TextGraphs-7 Workshop at ACL, pages 44?54,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsBringing the Associative Ability to Social Tag RecommendationMiao Fan,?
?Yingnan Xiao?and Qiang Zhou?
?Department of Computer Science and Technology, Tsinghua University?School of Software Engineering, Beijing University of Posts and Telecommunications{fanmiao.cslt.thu,lxyxynt}@gmail.com,zq-lxd@mail.tsinghua.edu.cnAbstractSocial tagging systems, which allow users tofreely annotate online resources with tags,become popular in the Web 2.0 era.
In order toease the annotation process, research on socialtag recommendation has drawn much attentionin recent years.
Modeling the social taggingbehavior could better reflect the nature of thisissue and improve the result of recommendation.In this paper, we proposed a novel approach forbringing the associative ability to model thesocial tagging behavior and then to enhance theperformance of automatic tag recommendation.To simulate human tagging process, ourapproach ranks the candidate tags on aweighted digraph built by the semanticrelationships among meaningful words in thesummary and the corresponding tags for agiven resource.
The semantic relationships arelearnt via a word alignment model in statisticalmachine translation on large datasets.Experiments on real world datasets demonstratethat our method is effective, robust andlanguage-independent compared with the state-of-the-art methods.1 IntroductionSocial tagging systems, like Flickr 1 , Last.fm 2 ,Delicious 3  and Douban 4 , have recently becomemajor infrastructures on the Web, as they allowusers to freely annotate online resources withpersonal tags and share them with others.
Becauseof the no vocabulary restrictions, there are differentkinds of tags, such as tags like keywords, categorynames or even named entities.
However, we can1 http://www.flickr.com2 http://www.lastfm.com3 http://delicious.com4 http://www.douban.comstill find the inner relationship between the tagsand the resource that they describe.
Figure 1 showsa snapshot of a social tagging example, where thefamous artist, Michael Jackson was annotated withmultiple social tags by users in Last.fm2.
Actually,Figure 1 can be divided into three parts, which arethe title, the summary and the tags respectively.Figure 1: A music artist entry from website Last.fm2We can easily find out that social tags conciselyindicate the main content of the given onlineresource and some of them even reflect userinterests.
For this reason, social tagging has beenwidely studied and applied in recommendersystems (Eck et al, 2007; Musto et al, 2009; Zhouet al, 2010), advertising (Mirizzi et al, 2010), etc.For the sake of easing the process of userannotation and providing a better effect of human-computer interaction, researchers expected to build44automatic social tagging recommender systems,which could automatically suggest proper tags fora user when he/she wants to annotate an onlineresource.
By observing huge amount of onlineresources, researchers found out that most of themcontain summaries, which could play an importantrole in briefly introducing the correspondingresources, such as the artist entry about MichaelJackson in Figure 1.
Thus some of them proposedto automatically suggest tags based on resourcesummaries, which are collectively known as thecontent-based approach (F. Ricci et al, 2011).The basic idea of content-based approach inrecommender systems is to select important wordsfrom summaries as tags.
However, this is far fromadequate as not all tags are statistically significantin the summaries.
Some of them even do notappear in the corresponding summaries.
Forexample, in Figure 1, the popular tag dance doesnot appear in the summary, but why most of userschoose it as a proper tag to describe MichaelJackson.
This ?out-of-summary?
phenomenonreflects a fact that users usually exploit their ownknowledge and associative ability to annotateonline resources.
When a summary comes, theyassociate the important words in the summary withother semantic-related tags based on theirknowledge.
To improve the automatic tagrecommendation, a social computing issue (Wanget al, 2007), modeling the social tagging behavioris the straightforward way.
Namely, how toanalyze the human tagging process and propose asuitable approach that can help the computer tosimulate the process are what we will explore inthis paper.The novel idea of our approach is to rank thecandidate tags on a weighted digraph built by thesemantic relationships among meaningful words inthe summary and the corresponding tags for agiven resource.
The semantic relationships arelearnt via a word alignment model in statisticalmachine translation.
Our approach could bring theassociative ability to social tag recommendationand naturally simulate the whole process of humansocial tagging behavior and then to enhance theperformance of automatic tag recommendation.
So,we name this approach for Associative TagRecommendation (ATR).The remainder of the paper is organized asfollows.
Section 2 analyzes the process of humantagging behavior.
Section 3 describes our novelapproach to simulate the process of human taggingbehavior for social tag recommendation.
Section 4compares our approach with the state-of-the-artand baseline methods and analyzes the parameterinfluences.
Section 5 surveys some related work insocial tag recommendation.
Section 6 concludeswith our major contributions and proposes someopen problems for future work.2 Human Tagging Behavior AnalysisHere, we will analyze the human tagging processto discover the secret why some of the tags arewidely annotated while are not statisticallysignificant or even do not appear in the summaries.In most cases, the information in summaries istoo deficient for users to tag resources or to reflectpersonalities.
Users thus exploit their ownknowledge, which may be partly learnt from otherresource entries containing both summaries andtags in Table 1.
Then when they want to tag anonline resource, they will freely associatemeaningful words in the summary with othersemantic related words learnt from former readingexperiences.
However, the result of this associationbehavior will be explosive.
Users should judge andweigh these candidate tags in brain, usually viaforming a semantic related word network andfinally decide the tags that they choose to annotatethe given resource.For example, after browsing plentiful ofsummary-tag pairs, we could naturally acquire thesemantic relationships between the words, such as?singer?, ?pop?, in the summary and the tag,?dance?.
If we tag the artist entry in Figure 1, thetag ?dance?
is more likely associated by the wordslike ?pop?, ?artist?, ?Rock & Roll?
et al Whilereading the summary of artist Michael Jackson inFigure 1, we may construct an abstract tag-networkin Figure 2 with the important words (king, pop,artist et al) in the summary, the associated tags(dance, 80s, pop et al and their semanticrelationships.Summary: David Lindgren (born April 28, 1982in Skelleftea, Sweden) is a Swedish singer andmusical artist?Tags: swedish, pop, dance, musical, davidlindgrenSummary: Wanessa God?i Camargo (born on45December 28, 1982), known simply as Wanessa, isa Brazilian pop singer?Tags: pop, dance, female vocalists, electronic,electropop ?Table 1: Examples of artist entries from Last.fm2Figure 2: A part of the abstract associative tag-networkin human brains.3 Associative Tag RecommendationWe describe our ATR approach as a three-stageprocedure by simulating the human annotationprocess analyzed in Section 2.
Figure 3 shows theoverall structure of our approach.Figure 3: The overview of ATR approach.Stage 1: Summary-tag pairs sampling.
Givena large collection of tagged resources, we need topre-process the dataset.
Generally, the pre-processing contains tokenizing the summaries,extracting the meaningful words and balancing thelength ratio between the summaries and tags.Stage 2: Associative ability acquiring.
Weregard a summary-tag pair as a parallel text.
Theyare really suitable to acquire the semantic relationknowledge by using word alignment model (In thispaper, we adopt IBM Model-1) from the largeamount of summary-tag pairs prepared by Stage 1.After gaining the translation probabilities betweenthe meaningful words in summaries and tags, oursocial tagging recommender system initially hasthe capability of association, namely from oneword to many semantic related tags.Stage 3: TagRank algorithm forrecommendation.
Stage 2 just helps ourrecommender system acquire the ability ofassociating one word with many semantic relatedtags.
However, when the system faces a givenresource with a long summary, the associationresults may be massive.
Thus, we propose aTagRank algorithm to order the candidate tags onthe weighted Tag-digraph, which is built by themeaningful words in the summary and theirsemantic related words.Before introducing the approach in details, wedefine some general notations, while the otherspecific ones will be introduced in thecorresponding stage.
In our approach, a resource isdenoted as    , where   is the set of allresources.
Each resource contains a summary and aset of tags.
The summary    of resource is simplyregarded as a bag of meaningful words, where     is the count ofmeaningful word    and    is the number of theunique meaningful words in  .
The tag set(annotations)    of resource   is represented as, where     is the count of tagand   is the number of the unique tags for  .3.1 Summary-Tag Pairs SamplingWe consider that the nouns and tags that appear inthe corresponding summary are meaningful for ourtagging recommendation approach.46It is not difficult for language, such as English,French et al As for Chinese, Thai and Japanese,we still need to do word segmentation (D.
D.Palmer., 2010).
Here, to improve the segmentationresults of these language texts, we collect all theunique tags in resource   as the user dictionary tosolve the out-of-vocabulary issue.
This idea isinspired by M. Sun (2011) and we will discuss itseffort on the performance improvement of oursystem in Section 4.3.After the meaningful words have been extractedfrom the summaries, we regard the summary andthe set of tags as two bags of the sampled wordswithout position information for a given resource.The IBM Model-1(Brown et al, 1993) wasadopted for training to gain the translationprobabilities between the meaningful words insummary and the tags.
Och and Ney (2003)proposed that the performance of word alignmentmodels would suffer great loss if the length ofsentence pairs in the parallel training data set isunbalanced.
Moreover, some popular onlineresources may be annotated by hundreds of peoplewith thousands of tags while the correspondingsummaries may limit to hundreds of words.
So, itis necessary to propose a sampling method forbalanced length of summary-tag pairs.One intuitional way is to assign each meaningfulword in summaries and tags with a term-frequency(TF) weight, namely     and    .
For eachextracted meaningful word   in a given summary,?and the same tag set(annotations)    ,?.
Here, we bring aparameter   in this stage, which denotes the lengthratio between the sampled summary and tag set,namely,3.2 Associative Ability AcquiringIBM Model-1 could help our social taggingrecommender system to learn the lexicaltranslation probability between the meaningfulwords in summaries and tags based on the datasetprovided by stage 1.
We adjust the model to ourapproach, which can be concisely described as,?For each resource  , the relationship between thesampled summary   =and the sampledtagsis connected via a hiddenvariable.
For example,indicates word    in  at position   is aligned totag    in   at position  .For more detail description on mathematics, thejoint likelihood of   and an alignment   givenis?
(   |in which                and  (   |      is calledthe translation probability of    given    .
Thealignment is determined by specifying the valuesof    for   from 1 to  , each of which can take anyvalue from 0 to  .
Therefore,??
?
(   |The goal is to adjust the translation probabilitiesso as to maximize           subject to theconstraints that for each  ,?IBM Model-1 can be trained using Expectation-Maximization (EM) algorithm (Dempster et al,1977) in an unsupervised fashion.
At last, weobtain the translation probabilities betweensummaries and tags, i.e.,        and        forour recommender system acquiring associativeability.From Eq.
(4), we know that IBM Model-1 willproduce one-to-many alignments from onelanguage to another language, and the trainedmodel is thus asymmetric.
Sometimes, there are afew translation pairs appear in both two direction,i.e., summary?
tag (     ) and tag?
summary(    ).
For this reason, Liu et al (2011) proposed aharmonic means to combine the two models.47()3.3 TagRank Algorithm for RecommendationBy the time we have generated the ?harmonic?translation probability list between meaningfulwords in summaries and tags, our recommendersystem could acquire the capability of associationlike human beings.
For instance, it could ?trigger?a large amount of semantic related tags from agiven word: Novel (Figure 4).
However, if wecollected all the ?triggered?
tags associated byeach meaningful word in a given summary, thescale would be explosive.
Thus we need to explorean efficient way that can not only rank thesecandidate tags but also simulate the human taggingbehavior as much as possible.Figure 4: The association results from the word ?Novel?via our social tagging recommender system.Inspired by the PageRank algorithm (S. Brin andL.
Page., 1998), we find out that the idea could bebrought into our approach with a certain degreeimprovement as the human tagging rankingprocess is on a weighted Tag-digraph  .
We regardthe association relationship as one wordrecommending the corresponding candidate tagsand the degree of preference could be quantified bythe translation probabilities.For a given summary, we firstly sample it viathe method described in stage 1 to obtain all themeaningful words, which are added to the graph asa set of seed vertices denoted as   .
Thenaccording to stage 2, we could obtain a set ofsemantic related vertices associated by these seedsdenoted as   .
We union the    and     to get theset of all candidate tags  .
For a directed edgefrom    to   , the weight  (   )  equals thetranslation probability from    to   , namely(  |   .
So the weighted Tag-digraph could beformulized as,{{   }{(     )         }(   )    (  |The original TextRank algorithm (Mihalcea etal., 2004) just considered the words recommendingthe nearest ones, and assumed that therecommending strengths were same.
As all thewords had the equal chance to recommend, it wasthe fact that all the edges in the graph gained nodirection information.
So this method brought littleimprovement on ranking results.
In the Eq.
(7) theyused,        represents the set of all the verticesthat direct to    and         denotes the set of allthe vertices that direct from   .
The factor   isusually set to 0.85.?|   (  )|(  )We improve the TextRank model and propose aTagRank algorithm (Eq.
8) that is suitable to ourapproach.
For each   ,(   )?
(   )      (  )representsthe proportion of trigger ability from    to   .
Thisproportion multiplying the own score of    reflectthe the degree of recommend contribution to   .After we sum up all the vertices willing to?recommend?
, namely          , We cancalculate the score of    in one step.Some conceptual words could trigger hundredsof tags, so that our recommender system will suffera rather high computation complexity.
Thus, weadd a parameter   which stands for the maximumout-degree of the graph  .
That means for eachvertex in the graph  , it can at most trigger top-candidate tags with the    highest translationprobabilities.48?
(   )?
(   )      (  )(  )Starting from vertex initial values assigned tothe seed nodes (  ) in the graph, the computationiterates until convergence below a given thresholdis achieved.
After running the algorithm, a score isassigned to each vertex.
Finally, our system canrecommend best   tags with high score for theresource.4 Experiments4.1 Datasets and Evaluation MetricsDatasets: We prepare two real world datasets withdiverse properties to test the performance of oursystem in different language environment.
Table 2lists the statistical information of the English andChinese datasets.Dataset P Vs Vt Ns NtBOOK 29464 68996 40401 31.5 7.8ARTIST 14000 35972 4775 19.0 5.0Table 2: Statistical information of two datasets.
P , Vs ,Vt , Ns, and Nt represent the number of parallel texts, thevocabulary of summaries, the vocabulary of tags, theaverage number of unique words in each summary andthe average number of unique tags in each resourcerespectively.The first dataset, BOOK, was crawled from apopular Chinese book review online communityDouban4, which contains the summaries of booksand the tags annotated by users.
The second dataset,ARTIST, was freely obtained via the Last.fm2 API.It contains the descriptions of musical artists andthe tags annotated by users.
By comparing thecharacteristics of these two datasets, we find outthat they differ in language, data size and thelength ratio (Figure 5).
The reason of preparingtwo datasets with diverse characteristics is that wewould like to demonstrate that our approach iseffective, robust and language-independentcompared with others.Evaluation Metrics: We use precision, recall andF-measure to evaluate the performance of our ATRapproach.
Given a resource set  , we regard the setof original tags as   , the automatic recommendedtag set as   .
The correctly recommended set oftags can be denoted as        .
Thus, precision,recall and F-measure are defined as5The final precision and recall of each method iscomputed by performing 7-fold cross validation onboth two datasets.Figure 5: The length ratio distributions of BOOK andARTIST datasets.4.2 Methods ComparisonBaseline Methods: In this section, we compare theperformance of our associative taggingrecommendation (ATR) with three other relativemethods, the state-of-the-art WTM (Liu et al,2011), TextRank (Mihalcea et al, 2004) and thetraditional TFIDF (C. D. Manning et al, 2008; R.Baeza-Yates et al, 2011).5 The reason why we do not calculate the precision, recall andF-measure alone is that we cannot guarantee thatrecommending at least one correct tag for each resource.49The reasons we choose those methods tocompare were as follows.?
WTM can reflect the state-of-the-artperformance on content-based social tagrecommendation.?
TextRank can be regarded as a baselinemethod on graph-based social tagrecommendation.?
TFIDF, as a traditional method, represents thebaseline performance and can validate the?out-of-summary?
phenomenon.For the TFIDF value of each word in a givensummary, it can be calculated by multiplying termfrequency?
(lognormalization) by inverted documentfrequency|?
|(inversefrequency smooth), where |?
| indicatesthe number of resources whose summaries containword  .TextRank method regarded the word and itsforward and backward nearest words as itsrecommendation.
Thus, each word in a givensummary is recommended by its neighborhoodwith no weight.
Simply, we use Eq.
(7) to calculatethe final value of each word in a given summary.Liu et al (2011) proposed a state of the artmethod which summed up the product the weightof a word and its translation probabilities to eachsemantic related tag as the final value of each tagin a given resource (Eq.
10).
?Experiment Results: Figure 6 illustrates theprecision-recall curves of ATR, WTM, TextRankand TFIDF on two datasets.
Each point of aprecision-recall curve stands for different numberof recommended tags from     (upper left) to(bottom right).
From the Figure 6, we canobserve that:?
ATR out-performs WTM, TextRank andTFIDF on both datasets.
This indicates thatATR is a language-independent approach forsocial tag recommendation.?
ATR shows consistently better performancewhen recommending different number of tags,which implies that our approach is efficientand robust (Figure 7).Figure 6: Performance comparison among ATR, WTM,TextRank and TFIDF on BOOK and ARTIST datasetswhen      ,     and vertex initial values areassigned to one.50Figure 7: F-measure of ATR, WTM, TextRank andTFIDF versus the number of recommended tags ( ) onthe BOOK and ARTIST datasets when       ,and vertex initial values are assigned to one.4.3 Sampling Methods DiscussionSection 3.1 proposed an idea on summary-tag pairssampling, which collected all the unique tags as theuser dictionary to enhance performance of thesummary segmentation, especially for the Chinese,Thai, and Japanese et al Though M. Sun (2011)put forward a more general paradigm, few studieshave verified his proposal.
Here, we will discussthe efficiency of our sampling method.
Figure 8shows the comparison of performance between theunsampled ATR and (sampled) ATR.Figure 8: Performance comparison between unsampledATR and (sampled) ATR on BOOK datasets when,     and vertex initial values are assigned tooneExperiments on the Chinese dataset BOOKdemonstrates that our (sampled) ATR approachachieves average 19.2% improvement onperformance compared with the unsampled ATR.4.4 Parameter AnalysisIn Section 3, we brought several parameters intoour approach, namely the harmonic factor  whichcontrols the proportion between model      and, the maximum out-degree   which specifiesthe computation complexity of the weighted tag-digraph and the vertex initial values which mayaffect the final score of some vertices if theweighted tag-digraph is not connected.We take the BOOK dataset as an example andexplore their influences to ATR by usingcontrolling variables method, which means weadjust the focused parameter with the other onesstable to observe the results.Harmonic factor: In Figure 9, we investigate theinfluence of harmonic factor via the curves of F-measure of ATR versus the number ofrecommended tags on the BOOK dataset.Experiments showed that the performance isslightly better when      .
As   controls theproportion between model      and     ,means model      contributes more onperformance.Figure 9: F-measure of ATR versus the number ofrecommended tags on the BOOK dataset whenharmonic factor   ranges from 0.0 to 1.0, whenand vertex initial values are assigned to one.Maximum out-degree: Actually, during theexperiments, we have found out that somemeaningful words could trigger hundreds ofcandidate tags.
If we bring all these tags to ourTag-Network, the computation complexity will bedramatically increased, especially in large datasets.To decrease the computation complexity with littleimpact on performance, we need to explore thesuitable maximum out-degree.
Figure 10 illustrateshow the complexities of tag-digraph will influentthe performance.
We discover that ATR gainsslight improvement when   is added from 5 to 9except the ?leap?
from 1 to 5.
It means thatwill be a suitable maximum out-degree, whichbalances the performance and the computationcomplexity.51Figure 10: F-measure of ATR versus the number ofrecommended tags on the BOOK dataset, when1           and vertex initial values are assignedto one.Vertex initial values: The seeds (meaningfulwords in the summaries) may not be semanticrelated, especially when the maximum out-degreeis low.
As a result, the graph   may bedisconnected, so that the final score of each vertexafter iteration may relate to the vertex initial values.In Figure 11, we compare three different vertexinitial values, namely value-one, value of TF (localconsideration) and value of TFIDF (globalconsideration) to check the influence.
However,the results show that there is almost no differencein F-measure when the maximum out-degreeranges from 1 to 9.Figure 11: F-measure of ATR versus maximum out-degree on BOOK dataset when the vertex initial valuesequal to Value-One, TF, TFIDF separately withand number of recommended tags   = 5.5 Related WorkThere are two main stream methods to build asocial tag recommender system.
They arecollaboration-based method (Herlocker et al, 2004)and the content-based approach (Cantador et al,2010).FolkRank (Jaschke et at., 2008) and MatrixFactorization (Rendle et al, 2009) arerepresentative collaboration-based methods forsocial tag recommendation.
Suggestions of thesetechniques are based on the tagging history of thegiven resource and user, without considering theresource summaries.
Thus most of these methodssuffer from the cold-start problem, which meansthey cannot perform effective suggestions forresources that no one has annotated.To remedy the defect of cold-start problem,researchers proposed content-based methodsexploiting the descriptive information on resources,such as summaries.
Some of them consideredsocial tag recommendation as a classificationproblem by regarding each tag as a category label.Various classifiers such as kNN (Fujimura et al,2007), SVM (Cao et al, 2009) have been discussed.But two issues exposed from these methods.?
Classification-based methods are highlyconstrained in the quality of annotation, whichare usually noisy.?
The training and classification cost are oftenin proportion to the number of classificationlabels, so that these methods may not beefficient for real-world social tagging system,where thousands of unique tags may belong toa resource.With the widespread of latent topic models,researchers began to pay close attention onmodeling tags using Latent Dirichlet Allocation(LDA) (Blei et al, 2003).
Recent studies (Krestelet al, 2009; Si and Sun, 2009) assume that bothtags and words in summary are generated from thesame set of latent topics.
However, most latenttopic models have to pre-specify the number oftopic before training.
Even though we can usecross validation to determine the optimal numberof topics (Blei et al, 2010), the solution isobviously computationally complicated.The state of the art research on social taggingrecommendation (Z. Liu, X. Chen and M. Sun,2011) regarded social tagging recommendationproblem as a task of selecting appropriate tagsfrom a controlled tag vocabulary for the givenresource and bridged the vocabulary gap betweenthe summaries and tags using word alignmentmodels in statistical machine translation.
But theysimply adopted the weighted sum of the score of52candidate tags, named word trigger method(WTM), which cannot reflect the whole process ofhuman annotation.6 Conclusion and Future WorkIn this paper, we propose a new approach for socialtagging recommendation via analyzing andmodeling human associative annotation behaviors.Experiments demonstrate that our approach iseffective, robust and language-independentcompared with the state of the art and baselinemethods.The major contributions of our work are asfollows.?
The essential process of human taggingprocess is discovered as the guideline to helpus build simulating models.?
A suitable model is proposed to assist oursocial tagging recommender system to learnthe semantic relationship between themeaningful words in summaries andcorresponding tags.?
Based on the semantic relationship betweenthe meaningful words in the summaries andcorresponding tags, a weighted Tag-digraph isconstructed.
Then a TagRank algorithm isproposed to re-organize and rank the tags.Our new approach is also suitable in the tasksof keyword extraction, query expansion et alwhere the human associative behavior exists.
Thus,we list several open problems that we will explorein the future:?
Our approach can be expanded from lexicallevel to sentence level to bring the associativeability into semantic-related sentencesextraction.?
We will explore the effects on other researchareas, such as keyword extraction, queryexpansion, where human associative behaviorexists as well.AcknowledgementsThe work was supported by the research projectsof National Science Foundation of China (GrantNo.
60873173) and National 863 High-Tech researchprojects (Grant No.
2007AA01Z173).
The authorswould like to thank Yi Luo for his insightfulsuggestions.ReferencesR.
Baeza-Yates and B. Ribeiro-Neto.
2011.
Moderninformation retrieval: the concepts and technologybehind search, 2nd edition.
ACM Press.D.
M. Blei, A. Y. Ng, and M. I. Jordan.
2003.
Latentdirichlet alocation.
JMLR, 3:993-1022.S.
Brin and L. Page.
1998.
The anatomy of a large-scalehypertextual  web search engine.
Computer networksand ISDN systems, 30 (1-7): 107-117.P.
F. Brown, V. J. D. Pietra, S. A. D. Pietra, and R. L.Mercer.
1993.
The mathematics of statistical machinetranslation: Parameter estimation.
Computationallinguistics, 19(2):263-311.I.
Cantador, A. Bellog?n, D. Vallet.
2010.
Content-basedrecommendation in social tagging systems.
InProceedings of ACM RecSys, pages 237-240.H.
Cao, M. Xie, L. Xue, C. Liu, F. Teng, and Y. Huang.2009.
Social tag predication base on supervisedranking model.
In Proceeding of ECML/PKDD 2009Discovery Challenge Workshop, pages 35-48.A.
P. Dempster, N. M. Laird, D. B. Rubin, et al 1977.Maximum likelihood from incomplete data via theem algorithm.
Journal of the Royal Statistical Society.Series B (Methodological), 39 (1): 1-38.D.
Eck, P. Lamere, T. Bertin-Mahieux, and S. Green.2007.
Automatic generation of social tags for musicrecommendation.
In Proceedings of NIPS, pages385-392.S.
Fujimura, KO Fujimura, and H. Okuda.
2007.Blogosonomy: Autotagging any text using bloggers?knowledge.
In Proceedings of WI, pages 205-212.J.
L. Herlocker, J.
A. Konstan, L. G. Terveen, and J. T.Riedl.
2004.
Evaluating collaborative filteringrecommender systems.
ACM Transactions onInformation Systems, 22(1):5-53.R.
Jaschke, L. Marinho, A. hotho, L. Schmidt-Thieme,and G. Stumme.
2008.
Tag recommendations insocial bookmarking systems.
AI Communications,21(4):231-247.R.
Krestel, P. Fankharser, and W. Nejdl.
2009.
Latentdirichlet alocation for tag recommendation.
InProceedings of ACM RecSys, pages 61-68.Z.
Liu, X. Chen, M. Sun.
2011.
A simple word triggermethod for social tag suggestion.
In Proceedings ofEMNLP, pages 1577-1588.C.
D. Manning.
P. Raghavan, and H. Schtze.
2008.Introduction to information retrieval.
CambridgeUniversity Press, NY, USA.53R.
Mihalcea and P. Tarau.
2004.
TextRank: Bringingorder into texts.
In Proceedings of EMNLP, pages404-411.
Poster.R.
Mirizzi, A. Ragone, T. Di Noia, and E. Di Sciascio.2010.
Semantic tags generation and retrieval foronline advertising.
In Proceedings of CIKM, pages1089-1098.C.
Musto, F. Narducci, M. de Gemmis, P. Lops, and G.Semeraro.
2009.
STaR: a social tag recommendersystem.
In Proceeding of ECML/PKDD 2009Discovery Challenge Workshop, pages 215-227.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
Computationallinguistics, 29(1): 19-51.D.
D. Palmer.
2010.
Text preprocessing.
Handbook ofnatural language processing 2nd edition, chapter 2.CRC Press.S.
Rendle, L. Balby Marinho, A. Nanopoulos, and L.Schmidt-Thieme.
2009.
Learning optimal rankingwith ensor factorization for tag recommendation.
InProceedings of KDD, pages 727-726.F.
Ricci, L. Rokach, B. Shapira and P. B. Kantor.
2011.Recommender Systems Handbook.
Springer Press.X.
Si and M. Sun.
2009.
Tag-LDA for scalable real-timetag recommendation.
Journal of ComputationalInformation Systems, 6(1): 23-31.M.
Sun.
2011.
Natural language processing based onnaturally annotated web resources.
Journal ofChinese Information Processing, 25(6): 26-32T.
C. Zhou, H. Ma, M. R. Lyu, and I.
King.
2010.UserRec: A user recommendation approach in socialtagging systems.
In Proceedings of AAAI, pages1486-1491.54
