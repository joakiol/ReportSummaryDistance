Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 414?423,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsA Knowledge-based Representationfor Cross-Language Document Retrieval and CategorizationMarc Franco-Salvador1,2, Paolo Rosso2and Roberto Navigli11Department of Computer ScienceSapienza Universit`a di Roma, Italy{francosalvador,navigli}@di.uniroma1.it2Natural Language Engineering Lab - PRHLT Research CenterUniversitat Polit`ecnica de Val`encia, Spain{mfranco,prosso}@dsic.upv.esAbstractCurrent approaches to cross-language doc-ument retrieval and categorization arebased on discriminative methods whichrepresent documents in a low-dimensionalvector space.
In this paper we pro-pose a shift from the supervised to theknowledge-based paradigm and provide adocument similarity measure which drawson BabelNet, a large multilingual knowl-edge resource.
Our experiments showstate-of-the-art results in cross-lingualdocument retrieval and categorization.1 IntroductionThe huge amount of text that is available on-line is becoming ever increasingly multilingual,providing an additional wealth of useful informa-tion.
Most of this information, however, is not eas-ily accessible to the majority of users because oflanguage barriers which hamper the cross-lingualsearch and retrieval of knowledge.Today?s search engines would benefit greatlyfrom effective techniques for the cross-lingual re-trieval of valuable information that can satisfya user?s needs by not only providing (Landauerand Littman, 1994) and translating (Munteanu andMarcu, 2005) relevant results into different lan-guages, but also by reranking the results in a lan-guage of interest on the basis of the importance ofsearch results in other languages.Vector-based models are typically used in theliterature for representing documents both inmonolingual and cross-lingual settings (Manninget al., 2008).
However, because of the large sizeof the vocabulary, having each term as a compo-nent of the vector makes the document represen-tation very sparse.
To address this issue severalapproaches to dimensionality reduction have beenproposed, such as Principal Component Analysis(Jolliffe, 1986), Latent Semantic Indexing (Hull,1994), Latent Dirichlet Allocation (LDA) (Blei etal., 2003) and variants thereof, which project thesevectors into a lower-dimensional vector space.
Inorder to enable multilinguality, the vectors of com-parable documents written in different languagesare concatenated, making up the document ma-trix which is then reduced using linear projection(Platt et al., 2010; Yih et al., 2011).
However, todo so, comparable documents are needed as train-ing.
Additionally, the lower dimensional represen-tations are not of easy interpretation.The availability of wide-coverage lexicalknowledge resources extracted automaticallyfrom Wikipedia, such as DBPedia (Bizer et al.,2009), YAGO (Hoffart et al., 2013) and BabelNet(Navigli and Ponzetto, 2012a), has considerablyboosted research in several areas, especially wheremultilinguality is a concern (Hovy et al., 2013).Among these latter are cross-language plagiarismdetection (Potthast et al., 2011; Franco-Salvadoret al., 2013), multilingual semantic relatedness(Navigli and Ponzetto, 2012b; Nastase andStrube, 2013) and semantic alignment (Navigliand Ponzetto, 2012a; Matuschek and Gurevych,2013).
One main advantage of knowledge-basedmethods is that they provide a human-readable,semantically interconnected, representation ofthe textual item at hand (be it a sentence or adocument).Following this trend, in this paper we providea knowledge-based representation of documentswhich goes beyond the lexical surface of text,while at the same time avoiding the need for train-ing in a cross-language setting.
To achieve thiswe leverage a multilingual semantic network, i.e.,BabelNet, to obtain language-independent repre-sentations, which contain concepts together withsemantic relations between them, and also includesemantic knowledge which is just implied by theinput text.
The integration of our multilingualgraph model with a vector representation enablesus to obtain state-of-the-art results in comparable414document retrieval and cross-language text cate-gorization.2 Related WorkThe mainstream representation of documentsfor monolingual and cross-lingual document re-trieval is vector-based.
A document vector, whosecomponents quantify the relevance of each term inthe document, is usually highly dimensional, be-cause of the variety of terms used in a documentcollection.
As a consequence, the resulting docu-ment matrices are very sparse.
To address the datasparsity issue, several approaches to the reduc-tion of dimensionality of document vectors havebeen proposed in the literature.
A popular class ofmethods is based on linear projection, which pro-vides a low-dimensional mapping from a high di-mensional vector space.
A historical approach tolinear projection is Principal Component Analysis(PCA) (Jolliffe, 1986), which performs a singularvalue decomposition (SVD) on a document matrixD of size n?m, where each row in D is the termvector representation of a document.
PCA usesan orthogonal transformation to convert a set ofobservations of possibly correlated variables intoa set of values of linearly uncorrelated variablescalled principal components, which make up thelow-dimensional vector.
Latent Semantic Analy-sis (LSA) (Deerwester et al., 1990) is very simi-lar to PCA but performs the SVD using the cor-relation matrix instead of the covariance matrix,which implies a lower computational cost.
LSApreserves the amount of variance in an eigenvector~v by maximizing its Rayleigh ratio:~vTC~v~vT~v, whereC = DTD is the correlation matrix of D.A generalization of PCA, called Oriented Prin-cipal Component Analysis (OPCA) (Diamantarasand Kung, 1996), is based on a noise covari-ance matrix to project the similar components ofD closely.
Other projection models such as La-tent Dirichlet Allocation (LDA) (Blei et al., 2003)are based on the extraction of generative modelsfrom documents.
Another approach, named Ex-plicit Semantic Analysis (ESA) (Gabrilovich andMarkovitch, 2007), represents each document byits similarities to a document collection.
Using alow domain specificity document collection suchas Wikipedia, the model has proven to obtain com-petitive results.Not only have these methods proven to be suc-cessful in a monolingual scenario (Deerwesteret al., 1990; Hull, 1994), but they have alsobeen adapted to perform well in tasks at a cross-language level (Potthast et al., 2008; Platt et al.,2010; Yih et al., 2011).
Cross-language Latent Se-mantic Indexing (CL-LSI) (Dumais et al., 1997)was the first linear projection approach used incross-lingual tasks.
CL-LSI provides a cross-lingual representation for documents by reducingthe dimensionality of a matrix D whose rows areobtained by concatenating comparable documentsfrom different languages.
Similarly, PCA andOPCA can be adapted to a multilingual setting.LDA was also adapted to perform in a multilingualscenario with models such as Polylingual TopicModels (Mimno et al., 2009), Joint ProbabilisticLSA and Coupled Probabilistic LSA (Platt et al.,2010), which, however, are constrained to usingword counts, instead of better weighting strate-gies, such as log(tf)-idf, known to perform bet-ter with large vocabularies (Salton and McGill,1986).
Another variant, named Canonical Cor-relation Analysis (CCA) (Thompson, 2005), usesa cross-covariance matrix of the low-dimensionalvectors to find the projections.
Cross-languageExplicit Semantic Analysis (CL-ESA) (Potthast etal., 2008; Cimiano et al., 2009; Potthast et al.,2011), instead, adapts ESA to be used at cross-language level by exploiting the comparable doc-uments across languages from Wikipedia.
CL-ESA represents each document written in a lan-guage L by its similarities with a document collec-tion in the same language L. Using a multilingualdocument collection with comparable documentsacross languages, the resulting vectors from dif-ferent languages can be compared directly.An alternative unsupervised approach, Cross-language Character n-Grams (CL-CNG) (Mc-namee and Mayfield, 2004), does not draw uponlinear projections and represents documents asvectors of character n-grams.
It has proven to ob-tain good results in cross-language document re-trieval (Potthast et al., 2011) between languageswith lexical and syntactic similarities.Recently, a novel supervised linear projec-tion model based on Siamese Neural Networks(S2Net) (Yih et al., 2011) achieved state-of-the-art performance in comparable document retrieval.S2Net performs a linear combination of the termsof a document vector~d to obtain a reduced vector~r, which is the output layer of a neural network.Each element in ~r has a weight which is a linearcombination of the original weights of~d, and cap-tures relationships between the original terms.However, linear projection approaches need ahigh number of training documents to achievestate-of-the-art performance (Platt et al., 2010;Yih et al., 2011).
Moreover, although they aregood at identifying a few principal components,415the representations produced are opaque, in thatthey cannot explicitly model the semantic contentof documents with a human-interpretable repre-sentation, thereby making the data analysis diffi-cult.
In this paper, instead, we propose a language-independent knowledge graph representation fordocuments which is obtained from a large multi-lingual semantic network, without using any train-ing information.
Our knowledge graph represen-tation explicitly models the semantics of the docu-ment in terms of the concepts and relations evokedby its co-occurring terms.3 A Knowledge-based DocumentRepresentationWe propose a knowledge-based document rep-resentation aimed at expanding the terms in a doc-ument?s bag of words by means of a knowledgegraph which provides concepts and semantic rela-tions between them.
Key to our approach is theuse of a graph representation which does not de-pend on any given language, but, indeed, is multi-lingual.
To build knowledge graphs of this kind weutilize BabelNet, a multilingual semantic networkthat we present in Section 3.1.
Then, in Section3.2, we describe the five steps needed to obtain ourgraph-based multilingual representation of docu-ments.
Finally, we introduce our knowledge graphsimilarity measure in Section 3.3.3.1 BabelNetBabelNet (Navigli and Ponzetto, 2012a) is amultilingual semantic network whose conceptsand relations are obtained from the largest avail-able semantic lexicon of English, WordNet (Fell-baum, 1998), and the largest wide-coveragecollaboratively-edited encyclopedia, Wikipedia,by means of an automatic mapping algorithm.
Ba-belNet is therefore a multilingual ?encyclopedicdictionary?
that combines lexicographic informa-tion with wide-coverage encyclopedic knowledge.Concepts in BabelNet are represented similarly toWordNet, i.e., by grouping sets of synonyms inthe different languages into multilingual synsets.Multilingual synsets contain lexicalizations fromWordNet synsets, the corresponding Wikipediapages and additional translations output by a sta-tistical machine translation system.
The relationsbetween synsets are collected from WordNet andfrom Wikipedia?s hyperlinks between pages.We note that, in principle, we could use anymultilingual network providing a similar kind ofinformation, e.g., EuroWordNet (Vossen, 2004).However, in our work we chose BabelNet be-cause of its larger size, its coverage of both lex-icographic and encyclopedic knowledge, and itsfree availability.1In our work we used BabelNet1.0, which encodes knowledge for six languages,namely: Catalan, English, French, German, Italianand Spanish.3.2 From Document to Knowledge GraphWe now introduce our five-step method for repre-senting a given document d from a collection D ofdocuments written in language L as a language-independent knowledge graph.Building a Basic Vector Representation Ini-tially we transform a document d into a traditionalvector representation.
To do this, we score eachterm ti?
d with a weight wi.
This weight is usu-ally a function of term and document frequency.Following the literature, one method that workswell is the log tf-idf weighting (Salton et al., 1983;Salton and McGill, 1986):wi= log2(fi+ 1)log2(n/ni).
(1)where fiis the number of times term i occurs indocument d, n is the total number of documents inthe collection and niis the number of documentsthat contain ti.
We then create a weighted termvector ~v = (w1, ..., wn), where wiis the weightcorresponding to term ti.
We exclude stopwordsfrom the vector.Selecting the Relevant Document Terms Wethen create the set T of base forms, i.e., lemmas2,of the terms in the document d. In order to keeponly the most relevant terms, we sort the terms Taccording to their weight in vector ~v and retain amaximum number of K terms, obtaining a set ofterms TK.3The value of K is calculated as a func-tion of the vector size, as follows:K = (log2(1 + |~v|))2, (2)The rationale is that K must be high enough toensure a good conceptual representation but nottoo high, so as to avoid as much noise as possi-ble in the set TK.Populating the Graph with Initial ConceptsNext, we create an initially-empty knowledgegraph G = (V,E), i.e., such that V = E = ?.We populate the vertex set V with the set SKofall the synsets in BabelNet which contain any termin TKin the document language L, that is:1http://babelnet.org2Following the setup of (Platt et al., 2010), our initial datais represented using term vectors.
For this reason we lemma-tize in this step.3Since the vector ~v provides weights for all the wordforms, and not only lemmas, occurring in d, we take the bestweight among those word forms of the considered lemma.416Figure 1: (a) initial graph from TK= {?European?, ?apple?, ?tree?, ?Malus?, ?species?, ?America?
}; (b)knowledge graph obtained by retrieving all paths from BabelNet.
Gray nodes are the original concepts.SK=?t?TKSynsetsL(t), (3)where SynsetsL(t) is the set of synsets in Ba-belNet which contain a term t in the languageof interest L. For example, in Figure 1(a) weshow the initial graph obtained from the set TK={?European?, ?apple?, ?tree?, ?Malus?, ?species?,?America?}.
Note, however, that each retrievedsynset is multilingual, i.e., it contains lexicaliza-tions for the same concept in other languages too.Therefore, the nodes of our knowledge graph pro-vide a language-independent representation of thedocument?s content.Creating the Knowledge Graph Similarly toNavigli and Lapata (2010), we create the knowl-edge graph by searching BabelNet for paths con-necting pairs of synsets in V .
Formally, for eachpair v, v??
V such that v and v?do not share anylexicalization4in TK, for each path in BabelNetv ?
v1?
.
.
.
?
vn?
v?, we set: V := V ?
{v1, .
.
.
, vn} and E := E?
{(v, v1), .
.
.
, (vn, v?
)},that is, we add all the path vertices and edges toG.
After prototyping, the path length is limitedto maximum length 3, so as to avoid an excessivesemantic drift.As a result of populating the graph with inter-mediate edges and vertices, we obtain a knowl-edge graph which models the semantic context ofdocument d. We point out that our knowledgegraph might have different isolated components.We view each component as a different interpreta-tion of document d. To select the main interpre-tation, we keep only the largest component, i.e.,the one with the highest number of vertices, whichwe consider as the most likely semantic represen-tation of the document content.Figure 1(b) shows the knowledge graph ob-tained for our example term set.
Note that ourapproach retains, and therefore weights, only thesubgraph focused on the ?apple fruit?
meaning.4This prevents different senses of the same term from be-ing connected via a path in the resulting knowledge graph.Knowledge Graph Weighting The final stepconsists of weighting all the concepts and se-mantic relations of the knowledge graph G. Forweighting relations we use the original weightsfrom BabelNet, which provide the degree of re-latedness between the synset end points of eachedge (Navigli and Ponzetto, 2012a).
As for con-cepts, we weight them on the basis of the origi-nal weights of the terms in the vector ~v.
In or-der to score each concept in our knowledge graphG, we applied the topic-sensitive PageRank al-gorithm (Haveliwala et al., 2003) to G. Whilethe well-known PageRank algorithm (Page et al.,1998) calculates the global importance of verticesin a graph, topic-sensitive PageRank is a variantin which the importance of vertices is biased us-ing a set of representative ?topics?.
Formally, thetopic-sensitive PageRank vector ~p is calculated bymeans of an iterative process until convergence asfollows: ~p = cM~p+(1?c)~u, where c is the damp-ing factor (conventionally set to 0.85), 1?
c repre-sents the probability of a surfer randomly jumpingto any node in the graph, M is the transition proba-bility matrix of graph G, with Mji= degree(i)?1if an edge from i to j exists, 0 otherwise, ~u isthe random-jumping transition probability vector,where each uirepresents the probability of jump-ing randomly to the node i, and ~p is the resultingPageRank vector which scores the nodes of G. Incontrast to vanilla PageRank, the ?topic-sensitive?variant gives more probability mass to some nodesin G and less to others.
In our case we perturbate~u by concentrating the probability mass to the ver-tices in SK, which are the synsets correspondingto the document terms TK(cf.
Formula 3).3.3 Similarity between Knowledge GraphsWe can now determine the similarity between twodocuments d, d??
D in terms of the similarity oftheir knowledge graph representations G and G?.Following the literature (Montes y G?omez etal., 2001) we calculate the similarity between thevertex sets in the two graphs using Dice?s coeffi-cient (Jackson et al., 1989):417Figure 2: Knowledge graph examples from two comparable documents in different languages.Sc(G,G?)
=2 ?
?c?V (G)?V (G?
)w(c)?c?V (G)w(c) +?c?V (G?
)w(c), (4)where w(c) is the weight of a concept c (see Sec-tion 3.2).
Likewise, we calculate the similarity be-tween the two edge sets as:Sr(G,G?)
=2 ??r?E(G)?E(G?
)w(r)?r?E(G)w(r) +?r?E(G?
)w(r), (5)where w(r) is the weight of a semantic relationedge r.We combine the two above measures of concep-tual (Sc) and relational (Sr) similarity to obtain anintegrated measure Sg(G,G?)
between knowledgegraphs:Sg(G,G?)
=Sc(G,G?)
+ Sr(G,G?)2.
(6)Notably, since we are working with a language-independent representation of documents, thissimilarity measure can be applied to the knowl-edge graphs built from documents written in anylanguage.
In Figure 2 we show two knowledgegraphs for comparable documents written in dif-ferent languages (for clarity, labels are in Englishin both graphs).
As expected, the graphs share sev-eral key concepts and relations.4 A Multilingual Vector Representation4.1 From Document to Multilingual VectorSince our knowledge graphs will only cover themost central concepts of a document, we comple-ment this core representation with a more tradi-tional vector-based representation.
However, aswe are interested in the cross-language compari-son of documents, we translate our monolingualvector ~vLof a document d written in language Linto its corresponding vector ~vL?in language L?Algorithm 1 Dictionary-based term-vector translation.Input: a weighted document vector ~vL= (w1, .
.
.
, wn), asource language L and a target language L?Output: a translated vector ~vL?1: ~vL??
(0, .
.
.
, 0) of length n2: for i = 1 to n3: if wi= 0 continue4: // let tibe the term corresponding to wiin ~vL5: SL?
SynsetsL(ti)6: for each synset s ?
SL7: T ?
getTranslations(s, L?
)8: if T 6= ?
then9: for each tr ?
T10: wnew= wi?
confidence(tr, ti)11: // let index(tr) be the index of tr in ~vL12: if ?
index(tr) then13: vL?
(index(tr)) = wnew14: return ~vL?using BabelNet as our multilingual dictionary.
Wedetail the document-vector translation process inAlgorithm 1.The translated vector ~vL?is obtained as follows:for each term tiwith non-zero weight in vLweobtain all the possible meanings of tiin BabelNet(see line 5) and, for each of these, we retrieve allthe translations (line 7), i.e., lexicalizations of theconcept, in language L?available in the synset.
Weset a non-zero value in the translation vector ~vL?,5in correspondence with each such translation tr,proportional to the weight of tiin the original vec-tor and the confidence of the translation (line 10),as provided by the BabelNet semantic network.6In order to increase the amount of informationavailable in the vector and counterbalance possiblewrong translations, we avoid translating all vec-tors to one language.
Instead, in the present workwe create a multilingual vector representation of a5To make the translation possible, while at the same timekeeping the same number of dimensions in our vector repre-sentation, we use a shared vocabulary which covers both lan-guages.
See Section 6 for details on the experimental setup.6Non-English lexicalizations in BabelNet have confi-dence 1 if originating from Wikipedia inter-language linksand ?
1 if obtained by means of statistical machine transla-tion (Navigli and Ponzetto, 2012a).418document d written in language L by concatenat-ing the corresponding vector ~vLwith the translatedvector ~vL?of d for language L?.
As a result, weobtain a multilingual vector ~vLL?, which containslexicalizations in both languages.4.2 Similarity between Multilingual VectorsFollowing common practice for document similar-ity in the literature (Manning et al., 2008), we usethe cosine similarity as the similarity measure be-tween multilingual vectors:Sv(~vLL?, ~v?LL?)
=~vLL??
~v?LL?||~vLL?|| ||~v?LL?||.
(7)5 Knowledge-based Document SimilarityGiven a source document d and a target docu-ment d?, we calculate the similarities between therespective knowledge-graph and multilingual vec-tor representations, and combine them to obtain aknowledge-based similarity as follows:KBSim(d, d?)
= c(G)Sg(G,G?)
+ (1?
c(G))Sv(~vLL?, ~v?LL?
),(8)where c(G) is an interpolation factor calculated asthe edge density of knowledge graph G:c(G) =|E(G)||V (G)|(|V (G)| ?
1).
(9)Note that, using the factor c(G) to interpolatethe two similarities in Eq.
8, we determine the rel-evance for the knowledge graphs and the multi-lingual vectors in a dynamic way.
Indeed, c(G)makes the contribution of graph similarity dependon the richness of the knowledge graph.6 EvaluationIn this section we compare our knowledge-based document similarity measure, KBSim,against state-of-the-art models on two differenttasks: comparable document retrieval and cross-lingual text categorization.6.1 Comparable Document RetrievalIn our first experiment we determine the effective-ness of our knowledge-based approach in a com-parable document retrieval task.
Given a docu-ment d written in language L and a collection DL?of documents written in another language L?, thetask of comparable document retrieval consists offinding the document in DL?which is most simi-lar to d, under the assumption that there exists onedocument d??
DL?which is comparable with d.6.1.1 Corpus and Task SettingDataset We followed the experimental settingdescribed in (Platt et al., 2010; Yih et al., 2011)and evaluated KBSim on the Wikipedia datasetmade available by the authors of those papers.The dataset is composed of Wikipedia compara-ble encyclopedic entries in English and Spanish.For each document in English there exists a ?real?pair in Spanish which was defined as a compara-ble entry by the Wikipedia user community.
Thedataset of each language was split into three parts:43,380 training, 8,675 development and 8,675 testdocuments.
The documents were tokenized, with-out stemming, and represented as vectors using alog(tf)-idf weighting (Salton and Buckley, 1988).The vocabulary of the corpus was restricted to20,000 terms, which were the most frequent termsin the two languages after removing the top 50terms.Methodology To evaluate the models we com-pared each English document against the Spanishdataset and vice versa.
Following the original set-ting, the results are given as the average perfor-mance between these two experiments.
For eval-uation we employed the averaged top-1 accuracyand Mean Reciprocal Rank (MMR) at finding thereal comparable document in the other language.We compared KBSim against the state-of-the-artsupervised models S2Net, OPCA, CCA, and CL-LSI (cf.
Section 2).
In contrast to these models,KBSim does not need a training step, so we ap-plied it directly to the testing partition.In addition we also included the results ofCL-ESA7, CL-C3G8and two simple vector-basedmodels which translate all documents into Englishon a word-by-word basis and compared them us-ing cosine similarity: the first model (CosSimE)uses a statistical dictionary trained with Europarlusing Wavelet-Domain Hidden Markov Models(He, 2007), a model similar to IBM Model 4;the second model (CosSimBN) instead uses Algo-rithm 1 to translate the vectors with BabelNet.6.1.2 ResultsAs we can see from Table 1,9the CosSimBNmodel, which uses BabelNet to translate the docu-ment vectors, achieves better results than CCA andCL-LSI.
We hypothesize that this is due to theselinear projection models losing information duringthe projection.
CosSimEyields results similar toCosSimBN, showing that BabelNet is a good al-ternative statistical dictionary.
In contrast to CCA7Document collections with sizes higher than 105providehigh performance (Potthast et al., 2008).
Here we used 15kdocuments from the training set to index the test documents.8CL-C3G is CL-CNG using character 3-grams, which hasproven to be the best length (Mcnamee and Mayfield, 2004).9In this work, statistically significant results according toa ?2test are highlighted in bold.419Model Dimension Accuracy MMRS2Net 2000 0.7447 0.7973KBSim N/A 0.7342 0.7750OPCA 2000 0.7255 0.7734CosSimEN/A 0.7033 0.7467CosSimBNN/A 0.7029 0.7550CCA 1500 0.6894 0.7378CL-LSI 5000 0.5302 0.6130CL-ESA 15000 0.2660 0.3305CL-C3G N/A 0.2511 0.3025Table 1: Test results for comparable document re-trieval in Wikipedia.
S2Net, OPCA, CosSimE,CCA and CL-LSI are from (Yih et al., 2011).and CL-LSI, OPCA performs better thanks to itsimproved projection method using a noise covari-ance matrix, which enables it to obtain the maincomponents in a low-dimensional space.CL-C3G and CL-ESA obtain the lowest results.Considering that English and Spanish do not havemany lexical similarities, the low performance ofCL-C3G is justified because these languages donot share many character n-grams.
The reason be-hind the low results of CL-ESA can be explainedby the low number of intersecting concepts be-tween Spanish and English in Wikipedia, as con-firmed by Potthast et al.
(2008).
Despite both us-ing Wikipedia in some way, KBSim obtains muchhigher performance than CL-ESA thanks to theuse of our multilingual knowledge graph repre-sentation of documents, which makes it possibleto expand and semantically relate its original con-cepts.
As a result, in contrast to CL-ESA, KB-Sim can integrate conceptual and relational simi-larity functions which provide more accurate per-formance.
Interestingly, KBSim also outperformsOPCA which, in contrast to our system, is super-vised, and in terms of accuracy is only 1 point be-low S2Net, the supervised state-of-the-art modelusing neural networks.6.2 Cross-language Text CategorizationThe second task in which we tested the differ-ent models was cross-language text categorization.The task is defined as follows: given a documentdLin a language L and a corpus D?L?with docu-ments in a different language L?, and C possiblecategories, a system has to classify dLinto one ofthe categories C using the labeled collection D?L?.6.2.1 Corpus and Task SettingDataset To perform this task we used the Mul-tilingual Reuters Collection (Amini et al., 2009),which is composed of five datasets of news fromfive different languages (English, French, German,Spanish and Italian) and classified into six possi-Model Dim.
EN News ES NewsAccuracy AccuracyKBSim N/A 0.8189 0.6997Full MT 50 0.8483 0.6484CosSimBNN/A 0.8023 0.6737OPCA 100 0.8412 0.5954CCA 150 0.8388 0.5323CL-LSI 5000 0.8401 0.5105CosSimEN/A 0.8046 0.4481Table 2: Test results for cross-language text cat-egorization.
Full MT, OPCA, CCA, CL-LSI andCosSimEare from (Platt et al., 2010).ble categories.
In addition, each dataset of newsis translated into the other four languages usingthe Portage translation system (Sadat et al., 2005).As a result, we have five different multilingualdatasets, each containing source news documentsin one language and four sets of translated doc-uments in the other languages.
Each of the lan-guages has an independent vocabulary.
Documentvectors in the collection are created using TFIDF-based weighting.Methodology To evaluate our approach we usedthe English and Spanish news datasets.
Fromthe English news dataset we randomly selected13,131 news as training and 1,875 as test docu-ments.
From the Spanish news dataset we selectedall 12,342 news as test documents.
To classifyboth test sets we used the English news trainingset.
We performed the experiment at cross-linguallevel using Spanish and English languages avail-able for both Spanish and English news datasets,therefore we classified each test set selecting thedocuments in English and using the Spanish doc-uments in the training dataset, and vice versa.
Wefollowed Platt et al.
(2010) and averaged the val-ues obtained from the two comparisons for eachtest set to obtain the final result.
To categorizethe documents we applied k-NN to the rankedlist of documents according to the similarity mea-sure employed for each model.
We evaluated eachmodel by estimating its accuracy in the classifica-tion of the English and Spanish test sets.We compared our approach against the state-of-the-art supervised models in this task: OPCA,CCA and CL-LSI (Platt et al., 2010).
In addi-tion, we include the results of the CosSimBNandCosSimEmodels that we introduced in Section6.1.1, as well as the results of a full statistical ma-chine translation system trained with Europarl andpost-processed by LSA (Full MT), as reported byPlatt et al.
(2010).4206.2.2 ResultsTable 2 shows the cross-language text categoriza-tion accuracy.
CosSimEobtained the lowest re-sults.
This is because there is a significant numberof untranslated terms in the translation process thatthe statistical dictionary cannot cover.
This is notthe case in the CosSimBNmodel which achieveshigher results using BabelNet as a statistical dic-tionary, especially on the Spanish news corpus.On the other hand, however, the linear projec-tion methods as well as Full MT obtained the high-est results on the English corpus.
The differencesbetween the linear projection methods are evidentwhen looking at the Spanish corpus results; OPCAperformed best with a considerable improvement,which indicates again that it is one of the most ef-fective linear projection methods.
Finally, our ap-proach, KBSim, obtained competitive results onthe English corpus, performing best among the un-supervised systems, and the highest results on theSpanish news, surpassing all alternatives.Since KBSim does not need any training fordocument comparison, and because it based,moreover, on a multilingual lexical resource, weperformed an additional experiment to demon-strate its ability to carry out the same text cate-gorization task in many languages.
To do this, weused the Multilingual Reuters Collection to cre-ate a 3,000 document test dataset and 9,000 train-ing dataset10for five languages: English, German,Spanish, French and Italian.
Then we calculatedthe classification accuracy on each test set usingeach training set.
Results are shown in Table 3.The best results for each language were ob-tained when working at the monolingual level,which suggests that KBSim might be a gooduntrained alternative in monolingual tasks, too.In general, cross-language comparisons producedsimilar results, demonstrating the general applica-bility of KBSim to arbitrary language pairs in mul-tilingual text categorization.
However, we notethat German, Italian and Spanish training parti-tions produced low results compared to the oth-ers.
After analyzing the length of the documentsin the different datasets we discovered that theyhave different average lengths in words: 79 (EN),76 (FR), 75 (DE), 60 (ES) and 55 (IT).
German,Spanish and especially Italian documents have thelowest average length, which makes it more diffi-cult to build a representative knowledge graph ofthe content of each document when it is perform-ing at cross-language level.10Note that training is needed for the k-NN classifier, butnot for document comparison.Testing Training datasetsdatasets DE EN ES FR ITDE 0.8053 0.6872 0.5373 0.6417 0.5920EN 0.5827 0.8463 0.5540 0.6530 0.5820ES 0.5883 0.6153 0.8707 0.6237 0.7010FR 0.6867 0.7103 0.6667 0.8227 0.6887IT 0.5973 0.5487 0.6263 0.5973 0.8317Table 3: KBSim accuracy in a multilingual setup.7 ConclusionsIn this paper we introduced a knowledge-basedapproach to represent and compare documentswritten in different languages.
The two maincontributions of this work are: i) a new graph-based model for the language-independent rep-resentation of documents based on the Babel-Net multilingual semantic network; ii) KBSim, aknowledge-based cross-language similarity mea-sure between documents, which integrates ourmultilingual graph-based model with a traditionalvector representation.In two different cross-lingual tasks, i.e., compa-rable document retrieval and cross-language textcategorization, KBSim has proven to perform ona par or better than the supervised state-of-the-artmodels which make use of linear projections toobtain the main components of the term vectors.We remark that, in contrast to the best systems inthe literature, KBSim does not need any parametertuning phase nor does it use any training informa-tion.
Moreover, when scaling to many languages,supervised systems need to be trained on each pair,which can be very costly.The gist of our approach is in the knowl-edge graph representation of documents, which re-lates the original terms using expanded conceptsand relations from BabelNet.
The knowledgegraphs also have the nice feature of being human-interpretable, a feature that we want to exploit infuture work.
We will also explore the integrationof linear projection models, such as OPCA andS2Net, into our multilingual vector-based similar-ity measure.
Also, to ensure a level playing field,following the competing models, in this work wedid not use multi-word expressions as vector com-ponents.
We will study their impact on KBSim infuture work.AcknowledgmentsThe authors gratefully acknowledge the supportof the ERC Starting Grant MultiJEDI No.
259234,EC WIQ-EI IRSES (Grant No.
269180) andMICINN DIANA-Applications (TIN2012-38603-C02-01).
Thanks go to Yih et al.
for their supportand Jim McManus for his comments.421ReferencesMassih-Reza Amini, Nicolas Usunier, and CyrilGoutte.
2009.
Learning from multiple partially ob-served views - an application to multilingual textcategorization.
In Advances in Neural InformationProcessing Systems 22 (NIPS 2009), pages 28?36.Christian Bizer, Jens Lehmann, Georgi Kobilarov,S?oren Auer, Christian Becker, Richard Cyganiak,and Sebastian Hellmann.
2009.
Dbpedia - a crys-tallization point for the web of data.
J.
Web Sem.,7(3):154?165.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet allocation.
the Journal of ma-chine Learning research, 3:993?1022.Philipp Cimiano, Antje Schultz, Sergej Sizov, PhilippSorg, and Steffen Staab.
2009.
Explicit versus la-tent concept models for cross-language informationretrieval.
In Proceedings of the International JointConference on Artificial Intelligence (IJCAI), vol-ume 9, pages 1513?1518.Scott Deerwester, Susan T. Dumais, George W. Fur-nas, Thomas K. Landauer, and Richard Harshman.1990.
Indexing by latent semantic analysis.
Jour-nal of the American society for information science,41(6):391?407.Konstantinos I. Diamantaras and Sun Y. Kung.
1996.Principal component neural networks.
Wiley NewYork.Susan T. Dumais, Todd A. Letsche, Michael L.Littman, and Thomas K. Landauer.
1997.
Auto-matic cross-language retrieval using latent seman-tic indexing.
In Proc.
of AAAI Spring Symposiumon Cross-language Text and Speech Retrieval, pages18?24.Christiane Fellbaum.
1998.
WordNet: An electroniclexical database.
Bradford Books.Marc Franco-Salvador, Parth Gupta, and Paolo Rosso.2013.
Cross-language plagiarism detection usinga multilingual semantic network.
In Proc.
of the35th European Conference on Information Retrieval(ECIR?13), volume LNCS(7814), pages 710?713.Springer-Verlag.Evgeniy Gabrilovich and Shaul Markovitch.
2007.Computing semantic relatedness using wikipedia-based explicit semantic analysis.
In Proc.
of the 20thInternational Joint Conference on Artifical Intelli-gence (IJCAI), pages 1606?1611.Taher Haveliwala, Sepandar Kamvar, and Glen Jeh.2003.
An analytical comparison of approaches topersonalizing pagerank.
Technical Report 2003-35,Stanford InfoLab, June.Xiaodong He.
2007.
Using word dependent transitionmodels in hmm based word alignment for statisticalmachine translation.
In Proceedings of the SecondWorkshop on Statistical Machine Translation, pages80?87.
Association for Computational Linguistics.Johannes Hoffart, Fabian M. Suchanek, KlausBerberich, and Gerhard Weikum.
2013.
Yago2: Aspatially and temporally enhanced knowledge basefrom wikipedia.
Artificial Intelligence, 194:28?61.Eduard H. Hovy, Roberto Navigli, and Simone PaoloPonzetto.
2013.
Collaboratively built semi-structured content and Artificial Intelligence: Thestory so far.
Artificial Intelligence, 194:2?27.David Hull.
1994.
Improving text retrieval for therouting problem using latent semantic indexing.
InProceedings of the 17th Annual International ACMSIGIR Conference on Research and Developmentin Information Retrieval (SIGIR), pages 282?291.Springer.Donald A. Jackson, Keith M. Somers, and Harold H.Harvey.
1989.
Similarity coefficients: measures ofco-occurrence and association or simply measures ofoccurrence?
American Naturalist, pages 436?453.Ian T. Jolliffe.
1986.
Principal component analysis,volume 487.
Springer-Verlag New York.Thomas K. Landauer and Michael L. Littman.
1994.Computerized cross-language document retrievalusing latent semantic indexing, April 5.
US Patent5,301,109.Christopher D. Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to InformationRetrieval.
Cambridge University Press, New York,NY, USA.Michael Matuschek and Iryna Gurevych.
2013.Dijkstra-WSA: A graph-based approach to wordsense alignment.
Transactions of the Association forComputational Linguistics (TACL), 1:151?164.Paul Mcnamee and James Mayfield.
2004.
Charac-ter n-gram tokenization for european language textretrieval.
Information Retrieval, 7(1-2):73?97.David Mimno, Hanna M. Wallach, Jason Naradowsky,David A. Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing: Volume 2-Volume 2, pages880?889.
Association for Computational Linguis-tics.Manuel Montes y G?omez, Alexander F. Gelbukh, Au-relio L?opez-L?opez, and Ricardo A. Baeza-Yates.2001.
Flexible comparison of conceptual graphs.In Proc.
of the 12th International Conference onDatabase and Expert Systems Applications (DEXA),pages 102?111.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving machine translation performance by exploit-ing non-parallel corpora.
Computational Linguis-tics, 31(4):477?504.422Vivi Nastase and Michael Strube.
2013.
Transform-ing wikipedia into a large scale multilingual conceptnetwork.
Artificial Intelligence, 194:62?85.Roberto Navigli and Mirella Lapata.
2010.
An ex-perimental study of graph connectivity for unsuper-vised word sense disambiguation.
IEEE Transac-tions on Pattern Analysis and Machine Intelligence,32(4):678?692.Roberto Navigli and Simone Paolo Ponzetto.
2012a.BabelNet: The automatic construction, evaluationand application of a wide-coverage multilingual se-mantic network.
Artificial Intelligence, 193:217?250.Roberto Navigli and Simone Paolo Ponzetto.
2012b.BabelRelate!
a joint multilingual approach to com-puting semantic relatedness.
In Proceedings of theTwenty-Sixth AAAI Conference on Artificial Intelli-gence (AAAI-12), pages 108?114, Toronto, Canada.Lawrence Page, Sergey Brin, Rajeev Motwani, andTerry Winograd.
1998.
The PageRank CitationRanking: Bringing Order to the Web.
Technical re-port, Stanford Digital Library Technologies Project.John C. Platt, Kristina Toutanova, and Wen-tau Yih.2010.
Translingual document representations fromdiscriminative projections.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 251?261.Martin Potthast, Benno Stein, and Maik Anderka.2008.
A wikipedia-based multilingual retrievalmodel.
In Advances in Information Retrieval, pages522?530.
Springer.Martin Potthast, Alberto Barr?on-Cede?no, Benno Stein,and Paolo Rosso.
2011.
Cross-language plagia-rism detection.
Language Resources and Evalua-tion, 45(1):45?62.Fatiha Sadat, Howard Johnson, Akakpo Agbago,George Foster, Joel Martin, and Aaron Tikuisis.2005.
Portage: A phrase-based machine translationsystem.
In Proceedings of the ACL Workshop onBuilding and Using Parallel Texts, Ann Arbor, USA.Gerard Salton and Christopher Buckley.
1988.
Term-weighting approaches in automatic text retrieval.
In-formation processing & management, 24(5):513?523.Gerard Salton and Michael J. McGill.
1986.
Intro-duction to Modern Information Retrieval.
McGraw-Hill, Inc., New York, NY, USA.Gerard Salton, Edward A.
Fox, and Harry Wu.
1983.Extended boolean information retrieval.
Communi-cations of the ACM, 26(11):1022?1036.Bruce Thompson.
2005.
Canonical correlation analy-sis.
Encyclopedia of statistics in behavioral science.Piek Vossen.
2004.
EuroWordNet: A multilin-gual database of autonomous and language-specificwordnets connected via an inter-lingual index.
In-ternational Journal of Lexicography, 17(2):161?173.Wen-tau Yih, Kristina Toutanova, John C. Platt, andChristopher Meek.
2011.
Learning discriminativeprojections for text similarity measures.
In Proceed-ings of the Fifteenth Conference on ComputationalNatural Language Learning, pages 247?256.423
