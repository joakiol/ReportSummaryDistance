An Efficient A* Stack Decoder Algor i thm for ContinuousSpeech Recognit ion with a Stochastic Language Model*Douglas B. PaulLincoln Laboratory, MITLexington, Ma.
02173ABSTRACTThe stack decoder is an attractive algorithm for controllingthe acoustic and language model matching in a continuousspeech recognizer.
A previous paper described anear-optimaladmissible Viterbi A* search algorithm for use with non-cross-word acoustic models and no-grammar language models\[16\].
This paper extends this algorithm to include unigramlanguage models and describes a modified version of the algo-rithm which includes the full (forward) decoder, cross-wordacoustic models and longer-span language models.
The resul-tant algorithm is not admissible, but has been demonstratedto have a low probability of search error and to be very effi-cient.INTRODUCTIONSpeech recognition may be treated as a tree networksearch problem.
As one proceeds from the root towardthe leaves, the branches leaving each junction representthe set of words which may be appended to the currentpartial sentence.
Each of the branches leaving a junc-tion has a probability and each word has a likelihoodof being produced by the observed acoustic data.
Therecognition problem is to identify the most likely path(word sequence, W*) from the root (beginning of thesentence) to a leaf (end of the sentence) taking into ac-count the junction probabilities (the stochastic languagemodel, p(W)) and the acoustic match (including timealignment, p(OIW)) given that path \[2\]:W* =argmax p( OIW)p (W) (1)(w}where O is the acoustic observation sequence and W isa word sequence.This paper is concerned with the network search prob-lem and therefore correct recognition is defined as out-putting the most likely sentence W* given the languagemodel, the acoustic models, and the observed acousticdata.
If  the most likely sentence is not the one spoken,it is a modeling error- -not a search error.
This paper*This work was sponsored by the Defense Advanced ResearchProjects Agency.
The views expressed are those of the author anddo not reflect he official policy or position of the U.S. Government.will assume for simplicity that an isolated sentence is theobject to be recognized.
(The algorithm extends triviallyto recognize continuous input.
)THE BAS IC  STACK DECODERThe stack decoder \[8\], as used in speech, is an implemen-tation of a best-first ree search.
The basic operation ofa sentence decoder is as follows \[2,5\]:1.
Initialize the stack with a null theory.2.
Pop the best (highest scoring) theory off the stack.3.
if(end-of-sentence) output the sentence and termi-nate.4.
Perform acoustic and language-model fast matchesto obtain a short list of candidate word extensionsof the theory.5.
For each word on the candidate list:(a) Perform acoustic and language-model detailedmatches to compute the new theory output log-likelihood.i.
if(not end-of-sentence) insert into thestack.ii.
if(end-of-sentence) insert into the stackwith end-of-sentence flag = TRUE.6.
Go to 2.The fast matches \[4,5,7\] are computationally cheapmethods for reducing the number of word extensionswhich must be checked by the more accurate, but com-putationally expensive detailed matches.
1 (The fastmatches may also be considered a predictive compo-nent for the detailed matches.)
Top-N (N-best) modeis achieved by delaying termination until N sentenceshave been output.1 The following discussion concerns the basic stack decoder andtherefore it will be assumed that the correct word will always be onthe fast match list.
This can be guaranteed bythe scheme outlinedin reference \[5\].405The stack itself is just a sorted list which supports thefollowing operations: pop the best entry and insert newentries according to their scores.
The following itemsmust be contained in the ith stack entry:1. a stack score: StSci2.
a reference time: t_refl3.
a word history i: (path or theory identification)4. an output log-likelihood istribution: Li(t)5. an end-of-sentence flagTHE A* STACK CRITERIONA key issue in the stack decoder is deciding which theoryshould be popped from the stack to be extended.
This isdecided by the stack score and the reference time.
(Allscores used here are log-likelihoods or log-probabilities.
)The near-optimal A* criterion \[11\] used here is the dif-ference between the actual og-likelihood of reaching apoint in time on a path and a least upper bound on thelog-likelihood of any path reaching that point in time:Ai(t)  = Li(t) -lubL(t) (2)where Ai(t) is the A* scoring function, Li(t) is the outputlog-likelihood, t denotes time, i denotes the path (treebranch or left sentence fragment) and lubL(f) is the leastupper bound on Li(f).
(This criterion is derived in theappendix.)
In order to sort the stack entries, it is nec-essary to reduce the Ai(t) to a single number (the stackscore):StSci =max Ai(f).
(3),It is also convenient at this point to define the minimumtime which satisfies equation 3:t_mini =argmin (StSci = Ai(t)).
(4)tIt is also possible to estimate the most likely theory exittime ast_ezifi =argmax Li (f) - at (5)for an appropriately chosen value for a.A STACK DECODER FOR CSR WITHA UNIGRAM LANGUAGE MODELIt is not possible to compute the exact least upper boundon the theory likelihoods without first performing therecognition.
It is, however, possible to compute the least-upper-bound-so-far (lubsf) on the likelihoods that havealready been computed, which requires negligible com-putation and is sufficient to perform the near-optimal A*search.
This creates two difficulties:1.
Since lubL(f) = lubsfL(t) can change as the theoriesare evaluated, the stack order can also change.2.
A degeneracy in determining the best path by SfScalone can occur since lubsfL(t) can equal Li(t) formore than one i (path) at different imes.Problem 1 is easily cured by reevaluating the stack scoresStSc every time lubsfL(t) is updated and reorganizingthe stack.
This is easily accomplished if the stack isstored as a heap \[10\].Problem 2 occurs because different heories may domi-nate different parts of the current upper bound.
Thusall of these theories will have a score of zero.
The cureis to extend the shortest theory (minimum t_min) whichhas a stack score equal to the best.
If f_refi = f-mini,this can be accomplished by performing a major sort onthe stack score StSc and a minor sort on the referencetime f_re f .This guarantees that lubsfL(t) = lubL(f) for t < t_refp(where p denotes the theory which is about to bepopped) and therefore the relevant part of the least-upper-bound has been computed by the time that it isneeded.
Since the bound, at the time that it is needed,is the least-upper-bound, the search is admissible andnear-optimal.
Furthermore, when the first sentence isoutput, the least-upper-bound-so-far will be the exactleast-upper-bound.A stack pruning threshold can be used to limit the stacksize \[16\].
Any theory whose SfSc falls below the thresh-old can be deleted from the stack.
This can be appliedon stack insertions and any time the stack is reorganized.This stack pruning threshold has little effect on the com-putational requirements and can therefore be set veryconservatively to essentially eliminate any chance thatthe correct heory will be pruned.In a time-synchronous (TS) no-grammar/unigram l n-guage model Viterbi decoder, all word output likelihoodsare compared and only the maximum is passed on asinput to the word models.
Thus by comparison, onlytheories that dominate the lubsf need be retained onthe stack and the stack pruning threshold can be set tozero for top-1 recognition.
Since all stack scores, StSc,of all theories popped from the stack will be zero untilthe first sentence is output, all theories popped from thestack will be in reference time t_min order.
(Of course,the stack pruning threshold must be non-zero if a top-Nlist of sentences i desired.)
For top-N recognition, thisalgorithm adaptively raises the effective computationalpruning threshold (which equals the current best StSc)by the minimum required to produce N output sentences,406subject o the limit placed by the stack pruning thresh-old.This algorithm is near-optimal nd admissible only fora Viterbi decode using non-cross word acoustic modelsand a no-grammar o unigram language model.recognition.
(While this algorithm can also perform top-N recognition with or without a language model, it can-not be made equivalent to the no-grammar/unigram l n-guage model version for top-N. Its pruning threshold isfixed and it will only output heories whose relative like-lihoods do not fall below the threshold.
)A STACK DECODER FOR CSR WITHA LONG-SPAN LANGUAGE MODELThe above algorithm fails with a long span languagemodel because the overall best theory can have a less-than-best intermediate score.
This less-than-best inter-mediate score can be locally "shadowed" by the bestscore and thus will not be popped from the stack \[6\].An efficient stack decoder algorithm which can be usedwith cross-word acoustic models, the full (forward) de-coder, and longer-span (> 2) language models can beproduced by two simple changes:1. change the stack ordering to be a major sort on thereference time t_ref (favoring the lesser times) anda minor sort on the stack score StSe and2.
use a non-zero stack pruning threshold.The reference time t_ref may also be changed from theminimum time which satisfies equation 3used in the no-grammar/unigram language-model version to t_exit asdefined in equation 5.
(Either will work and both re-quired similar amounts of computation i tests.)
Thisalgorithm appears to be a simplification of one devel-oped at IBM \[3\].This algorithm is not admissible because the correcttheory can be pruned from the stack.
The stack-pruning threshold now becomes the computational prun-ing threshold which controls the trade-off between theamount of computation and the probability of prun-ing the the correct theory by controlling the likelihood"depth" that will be searched.
Unlike the previous algo-rithm, an (unpruned) theory cannot be shadowed be-cause it will be extended when its reference time isreached.
This algorithm is quasi-time-synchronous be-cause it, in effect, moves atime bound forward and when-ever this time bound becomes equal to the reference timeof a theory, the theory is expanded.Note that the stack pruning threshold can also be setto zero for no-grammar/unigram l nguage model top-1recognition with this algorithm.
With a zero stack prun-ing threshold and t_refl = t_minl, it becomes equivalentto the near-optimal, admissible no-grammar/unigramlanguage model algorithm described above for top-1DISCUSSION AND CONCLUSIONSThe above stack-search algorithms have been imple-mented in a prototype implementation which uses realspeech input, but does not yet have all of the featuresof the Lincoln TS CSR \[13,14,15\].
(The primary missingfeature is cross-word phonetic modeling.)
The proto-type runs faster than does the TS system on the cor-responding recognition task, frequently by a significantfactor.
(In fairness, the TS system does not include a fastmatch.)
Current experience using the DARPA ResourceManagement Database \[17\] shows the required numberof stack pops and the stack size to be surprisingly small.In addition, the prototype includes a proposed CSR-NLinterface \[12\] and has been run with unigram, word-pair,bigram, and trigram language models accessed throughthe interface without difficulty.
(It has also been runusing a no-grammar language model, which, of course,does not require the interface.)
This prototype imple-mentation has also been tested with vocabulary sizes upto 64K words.
The CSR computation, which is dom-inated by the fast match, scales approximately as thesquare root of the vocabulary size.Methods for joining the acoustic matching of separatetheories and caching of acoustic omputations to reducethe acoustic match computation were described in ref-erence \[16\].
These algorithms were tested in a stack-decoder simulator (real stack decoder with simulated in-put data).
The path join accelerator is used in the pro-totype stack decoder to remove copies of theories whichare identical except for non-grammatical items such asoptional intermediate silences.A* search using the scoring function described by Nils-son \[11\] (equation 6) requires computing the likelihoodof the future data (h*(t) in equation 7).
The optimalA* decoder equires exact evaluation of h*(t) which re-quires solving the top-1 recognition problem by someother means, such as a reverse direction TS decoder\[19\], before the A* search can begin.
The alternativedescribed here substitutes a near-optimal scoring func-tion which is derived from the A* search and requiresnegligible additional computation over that required bythe search itselfl Since, as noted above, the Lincolntop-1 TS decoder takes more CPU time than does thenear-optimal stack decoder, the near-optimal stack de-coder algorithm appears to be the most efficient of the407three approaches for top-1 recognition.
In addition, thelong-span language model version of the stack decodercan very easily integrate long-span language models intothe search.
However, if top-N recognition is the goal,the optimal A* search may be preferred because, oncethe price is paid for computing h*(t), the A* search canfind the additional N-1 sentences very efficiently for no-grammar/unigram language models \[19\].Recently, several other algorithms have been proposedfor top-N recognition using A* search \[9,19,22\] whichuse the Nilsson formulation of the scoring function.
Allof these approaches use a reverse direction TS decoderto compute h*(t).
(A reverse direction top-1 stack de-coder could also be used to compute h*(t).)
(There arealso some proposed non-A* methods for recognizing thetop-N sentences \[1,18,21\].
In general, the bidirectionalapproaches appear to be more efficient han the unidi-rectional approaches.)
These bidirectional A* methodsmust wait for the end of data (or a pseudo-end-of-data\[9\]) to begin the A* (or the reverse direction) pass.
Incontrast, because they do not need data beyond that nec-essary to extend the current theory (this includes dataup to t_ref required to choose the current theory), thetwo stack decoder formulations proposed here can pro-ceed totally left-to-right as the input data becomes avail-able from the front end.
The long-span language-modelversion of the stack search will output all top-N theorieswith minimal delay following the end-of-data because alltheories are pursued in quasi-parallel or, in top-1 mode,it can output he partial sentence as soon as all unprunedtheories have a common partial history (initial word se-quence).
(A similar technique for continuous output af-ter a short delay from continuous input exists for TSdecoders \[20\].
)One of the motivations for some of these other A* (andtop-N) algorithms is as a method for using weaker andcheaper initial acoustic and language models to producea top-N sentence list for later refinement by more de-tailed and expensive acoustic and/or language models,which now need only consider a few theories.
In con-trast the algorithm proposed here integrates both thedetailed acoustic and language models directly in thestack search and therefore need only produce a top-1output.
It attempts to minimize the computation by ap-plying all available information to constrain the search.
(The stack decoder as described here can, of course, alsobe used with weak and cheap acoustic and/or languagemodels to produce a top-N list for later processing.)
Theultimate choice between the two methods may be deter-mined by the number of sentences required by the top-Napproaches and the relative computational costs of thevarious modules in each system.
The architectural sim-plicity of each system may also have some bearing.The stack decoder has long shown promise for integrat-ing long-span language models and acoustic models intoa single effective search which applies information fromboth sources into controlling the search.
It has not beenused at many sites, primarily due to the difficulty ofmaking the search efficient.
The algorithms describedabove will hopefully remove this barrier.APPENDIX:  DERIVAT ION OFTHE A* CR ITERION USED INEQUATION 2Nilsson \[11\] states the optimal A* criterion (slightlyrewritten to match the speech recognition problem) asf i(t) = gi(t) + h*(t) (6)where f i(t) is the log-likelihood of a sentence with thepartial theory i ending at time t, gi(t) is the log-likelihood of partial theory i, and h*(t) is the log-likelihood of the best extension of any theory from timet to the end of the data.
(Nilsson uses costs which areinterpreted here as negative log-likelihoods.
All descrip-tions here will use sign conventions appropriate for log-likelihoods to be consistent with the rest of the paper.
)The theory argmax (mtax fi(t)) is chosen as the next toibe popped from the stack and expanded.Equation 6 requires that the computation of the totallikelihood of a sentence must be separable into a begin-ning part and an end part separated by a single time,which disallows this derivation for the full (forward) de-coder because the full decoder does not have a uniquetransition time between two words.
Thus, the deriva-tion is limited to a decoder which is Viterbi betweenwords.
It also limits the derivation to non-cross-wordacoustic models and no-grammar or unigram languagemodel recognition tasks.Definef*(t) = g*(t) + h*(t).
(7)for the best theory with a word transition at time t.The function f* (t) is slowly varying with global maximaat the word transition points of the correct theory, atwhich points it equals the likelihood of the correct heory.Specifically, it is maximum at t = 0 and t = T. (T is theend of data.)
Since gi(t) is an exact value (rather thana bound or estimate) for a tree search, g*(t) = lubgi(t)and since h*(t) is not a function of i, f*(t) = lubfi(t).Subtract equation 7 from equation 6 and define \]i(t)\]i(t) = fi(t) -- f*(t) = gi(t) -- g'(t).
(8)408This is just equation 2 in a different notation: gi(t) =Li (t) and g* (t) = ubL(t) (specifically lubL(t)) and there-fore \]i(t) = Ai(t).
Thus, if f*(t) were a constant, \]i(t)would just be an offset from fi(t) and the search would beoptimum because argmax (n~ax \]i(t)) would always beiequal to argTax (n ax fi(t)) As noted earlier, f*(t) hasmaxima at word transition times of the correct theory.Thus \]i(t) is zero at word transition times on the correcttheory and < 0 for all other i and t. Thus the searchis admissible because it can never block the correct he-ory by giving a better score to an incorrect heory, butsub-optimal because it can cause incorrect heories tobe popped from the stack and be evaluated.
The eval-uation function "error" f* (t) - f* (0) is slowly varyingand small, therefore the search is near-optimal.Since the stack decoder treats each theory and all pointson the likelihood distribution Li(t)) as a unit, each the-ory is evaluated at its optimum point: the max Ai(t) astdefined in equation 3, to give it its "best" chance andthen, for efficiency, the likelihood of all points on thedistribution Li(t) are extended in one operation.The fact that all StSci are zero until the first sentence isoutput and the tie is broken by choosing the theory withthe minimum reference time t_min, insures that all can-didate theories which might alter lubsfLi(t <_ t_minpop)have already been computed.
Thus the lubsfL(t) =lubL(t) for t _< t_minpop.This derivation shows the stack criterion max StSciwith a minimum t_minl tie-breaker to be adequate toperform a near-optimal admissible A*-search Viterbi-recognition with non-cross word acoustic models anda no-grammar/unigram language-model using the stackdecoder algorithm.REFERENCES1.
S. Austin, R. Schwartz, and P. Placeway "The Forward-Backward Search Algorithm," ICASSP 91, Toronto,May 1991.2.
L. R. Bahl, F. Jelinek, and R. L. Mercer, "A Maxi-mum Likelihood Approach to Continuous Speech Recog-nition," IEEE Trans.
Pattern Analysis and Machine In-telligence, PAMI-5, March 1983.3.
L. R. Bahl and F. Jelinek, "Apparatus and Method forDetermining a Likely Word Sequence from Labels Gen-erated by an Acoustic Processor," US Patent 4,748,670,May 31, 1988.4.
L. Bahl, S. V. De Gennaro, P. S. Gopalakrishnam, R. L.Mercer, "A Fast Approximate Acoustic Match for LargeVocabulary Speech Recognition," submitted to ASSP.5.
L. Bahl, P. S. Gopalakrishnam, D. Kanevsky, D. Na-hamoo, "Matrix Fast Match: A Fast Method for Iden-tifying a Short List of Candidate Words for Decoding,"ICASSP 89, Glasgow, May 1989.6.
J. K. Baker, personal communication, June 1990.7.
L. S. Gillick and R. Roth, "A Rapid Match Algorithmfor Continuous Speech Recognition," Proceedings June1990 Speech and Natural Language Workshop, MorganKaufmann Publishers, June, 1990.8.
F. Jelinek, "A Fast Sequential Decoding Algorithm Us-ing a Stack," IBM J. Res.
Develop., vol.
13, November1969.9.
P. Kenny, R. Hollan, V. Gupta, M. Lennig, P. Mermel-stein, and D. O'Shaughnessy, "A* - Admissible Heuris-tics for Rapid Lexical Access," ICASSP 91, Toronto,May 1991.10.
D. E. Knuth, "The Art of Computer Programming:Sorting and Searching,", Vol.
3., Addison-Wesly, MenloPark, California, 1973.11.
N. J. Nilsson, "Problem-Solving Methods of ArtificialIntelligence," McGraw-Hill, New York, 1971.12.
D. B. Paul, "A CSR-NL Interface Specification," Pro-ceedings October, 1989 DARPA Speech and NaturalLanguage Workshop, Morgan Kanfmann Publishers,October, 1989.13.
D. B. Paul, "Speech Recognition using Hidden MarkovModels," Lincoln Laboratory Journal, Vol.
3, no.
1,Spring 1990.14.
D.B.
Paul, "New Results with the Lincoln Tied-MixtureHMM CSR System," Proceedings Fourth DARPASpeech and Natural Language Workshop, Morgan Kauf-mann Publishers, February, 1991.15.
D. B. Paul, "The Lincoln Tied-Mixture HMM Contin-uous Speech Recognizer," ICASSP 91, Toronto, May1991.16.
D. B. Paul, "Algorithms for an Optimal A* Search andLinearizing the Search in the Stack Decoder," ICASSP91, Toronto, May 1991.alsoD.
B. Paul, "Algorithms for an Optimal A* Search andLinearizing the Search in the Stack Decoder," Proceed-ings June 1990 Speech and Natural Language Workshop,Morgan Kaufmann Publishers, June, 1990.17.
P. Price, W. Fisher, J. Bernstein, and D. Pallett, "TheDARPA 1000-Word Resource Management Databasefor Continuous Speech Recognition," ICASSP 88, NewYork, April 1988.18.
R. Schwartz and S. Austin, "A Comparison of SeveralApproximate Algorithms for Finding Multiple (N-Best)Sentence Hypotheses," ICASSP 91, Toronto, May 1991.19.
F. K. Soong and E. F. Huang, "A Tree-Trellis FastSearch for Finding the N Best Sentence Hypotheses inContinuous Speech Recognition," ICASSP 91, Toronto,May 1991.20.
J. C. Spohrer, P. F. Brown, P. H. Hochschild, and J. K.Baker, "Partial Backtrace in Continuous Speech Recog-nition," Proc.
Int.
Conf.
on Systems, Man, and Cyber-netics, 1980.21.
V. Steinbiss, "Sentence-Hypothesis Generation i a Con-tinuous Speech Recognition System," EUROSPEECtt89, Paris, Sept 1989.22.
V. Zue, J.
Glass, D. Goodine, H. Leung, M. Phillips, J.Polifroni, and S. Seneff, "Integration of Speech Recogni-tion and Natural Language Processing in the MIT Voy-ager System," ICASSP 91, Toronto, May 1991.409
