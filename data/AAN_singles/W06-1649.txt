Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 415?422,Sydney, July 2006. c?2006 Association for Computational LinguisticsPartially Supervised Sense Disambiguation by Learning Sense Numberfrom Tagged and Untagged CorporaZheng-Yu Niu, Dong-Hong JiInstitute for Infocomm Research21 Heng Mui Keng Terrace119613 Singapore{zniu, dhji}@i2r.a-star.edu.sgChew Lim TanDepartment of Computer ScienceNational University of Singapore3 Science Drive 2117543 Singaporetancl@comp.nus.edu.sgAbstractSupervised and semi-supervised sense dis-ambiguation methods will mis-tag the in-stances of a target word if the senses ofthese instances are not defined in sense in-ventories or there are no tagged instancesfor these senses in training data.
Here weused a model order identification methodto avoid the misclassification of the in-stances with undefined senses by discov-ering new senses from mixed data (taggedand untagged corpora).
This algorithmtries to obtain a natural partition of themixed data by maximizing a stability cri-terion defined on the classification resultfrom an extended label propagation al-gorithm over all the possible values ofthe number of senses (or sense number,model order).
Experimental results onSENSEVAL-3 data indicate that it outper-forms SVM, a one-class partially super-vised classification algorithm, and a clus-tering based model order identification al-gorithm when the tagged data is incom-plete.1 IntroductionIn this paper, we address the problem of partiallysupervised word sense disambiguation, which isto disambiguate the senses of occurrences of a tar-get word in untagged texts when given incompletetagged corpus 1.Word sense disambiguation can be defined asassociating a target word in a text or discourse1?incomplete tagged corpus?
means that tagged corpusdoes not include the instances of some senses for the targetword, while these senses may occur in untagged texts.with a definition or meaning.
Many corpus basedmethods have been proposed to deal with the sensedisambiguation problem when given definition foreach possible sense of a target word or a taggedcorpus with the instances of each possible sense,e.g., supervised sense disambiguation (Leacock etal., 1998), and semi-supervised sense disambigua-tion (Yarowsky, 1995).Supervised methods usually rely on the infor-mation from previously sense tagged corpora todetermine the senses of words in unseen texts.Semi-supervised methods for WSD are charac-terized in terms of exploiting unlabeled data inthe learning procedure with the need of prede-fined sense inventories for target words.
The in-formation for semi-supervised sense disambigua-tion is usually obtained from bilingual corpora(e.g.
parallel corpora or untagged monolingualcorpora in two languages) (Brown et al, 1991; Da-gan and Itai, 1994), or sense-tagged seed examples(Yarowsky, 1995).Some observations can be made on the previoussupervised and semi-supervised methods.
Theyalways rely on hand-crafted lexicons (e.g., Word-Net) as sense inventories.
But these resources maymiss domain-specific senses, which leads to in-complete sense tagged corpus.
Therefore, sensetaggers trained on the incomplete tagged corpuswill misclassify some instances if the senses ofthese instances are not defined in sense invento-ries.
For example, one performs WSD in informa-tion technology related texts using WordNet 2 assense inventory.
When disambiguating the word?boot?
in the phrase ?boot sector?, the sense tag-ger will assign this instance with one of the sensesof ?boot?
listed in WordNet.
But the correct sense2Online version of WordNet is available athttp://wordnet.princeton.edu/cgi-bin/webwn2.0415?loading operating system into memory?
is not in-cluded in WordNet.
Therefore, this instance willbe associated with an incorrect sense.So, in this work, we would like to study theproblem of partially supervised sense disambigua-tion with an incomplete sense tagged corpus.Specifically, given an incomplete sense-taggedcorpus and a large amount of untagged examplesfor a target word 3, we are interested in (1) label-ing the instances in the untagged corpus with sensetags occurring in the tagged corpus; (2) trying tofind undefined senses (or new senses) of the targetword 4 from the untagged corpus, which will berepresented by instances from the untagged cor-pus.We propose an automatic method to estimatethe number of senses (or sense number, model or-der) of a target word in mixed data (tagged cor-pus+untagged corpus) by maximizing a stabilitycriterion defined on classification result over allthe possible values of sense number.
At the sametime, we can obtain a classification of the mixeddata with the optimal number of groups.
If the es-timated sense number in the mixed data is equalto the sense number of the target word in taggedcorpus, then there is no new sense in untaggedcorpus.
Otherwise new senses will be representedby groups in which there is no instance from thetagged corpus.This partially supervised sense disambiguationalgorithm may help enriching manually compiledlexicons by inducing new senses from untaggedcorpora.This paper is organized as follows.
First, amodel order identification algorithm will be pre-sented for partially supervised sense disambigua-tion in section 2.
Section 3 will provide experi-mental results of this algorithm for sense disam-biguation on SENSEVAL-3 data.
Then relatedwork on partially supervised classification will besummarized in section 4.
Finally we will concludeour work and suggest possible improvements insection 5.2 Partially Supervised Word SenseDisambiguationThe partially supervised sense disambiguationproblem can be generalized as a model order iden-3Untagged data usually includes the occurrences of all thepossible senses of the target word4?undefined senses?
are the senses that do not appear intagged corpus.tification problem.
We try to estimate the sensenumber of a target word in mixed data (tagged cor-pus+untagged corpus) by maximizing a stabilitycriterion defined on classification results over allthe possible values of sense number.
If the esti-mated sense number in the mixed data is equal tothe sense number in the tagged corpus, then thereis no new sense in the untagged corpus.
Other-wise new senses will be represented by clusters inwhich there is no instance from the tagged corpus.The stability criterion assesses the agreement be-tween classification results on full mixed data andsampled mixed data.
A partially supervised clas-sification algorithm is used to classify the full orsampled mixed data into a given number of classesbefore the stability assessment, which will be pre-sented in section 2.1.
Then we will provide thedetails of the model order identification procedurein section 2.2.2.1 An Extended Label PropagationAlgorithmTable 1: Extended label propagation algorithm.Function: ELP(DL, DU , k, Y 0DL+DU )Input: labeled examples DL, unlabeledexamples DU , model order k, initiallabeling matrix Y 0DL+DU ;Output: the labeling matrix YDU on DU ;1 If k < kXL thenYDU =NULL;2 Else if k = kXL thenRun plain label propagation algorithmon DU with YDU as output;3 Else then3.1 Estimate the size of tagged data setof new classes;3.2 Generate tagged examples from DUfor (kXL + 1)-th to k-th new classes;3.3 Run plain label propagation algorithmon DU with augmented tagged datasetas labeled data;3.4 YDU is the output from plain labelpropagation algorithm;End if4 Return YDU ;Let XL+U = {xi}ni=1 be a set of contexts ofoccurrences of an ambiguous word w, where xirepresents the context of the i-th occurrence, and nis the total number of this word?s occurrences.
Let416SL = {sj}cj=1 denote the sense tag set of w in XL,where XL denotes the first l examples xg(1 ?
g ?l) that are labeled as yg (yg ?
SL).
Let XU denoteother u (l + u = n) examples xh(l + 1 ?
h ?
n)that are unlabeled.Let Y 0XL+U ?
N |XL+U |?|SL| represent initialsoft labels attached to tagged instances, whereY 0XL+U ,ij = 1 if yi is sj and 0 otherwise.
Let Y 0XLbe the top l rows of Y 0XL+U and Y 0XU be the remain-ing u rows.
Y 0XL is consistent with the labeling inlabeled data, and the initialization of Y 0XU can bearbitrary.Let k denote the possible value of the numberof senses in mixed data XL+U , and kXL be thenumber of senses in initial tagged data XL.
Notethat kXL = |SL|, and k ?
kXL .The classification algorithm in the order identi-fication process should be able to accept labeleddata DL 5, unlabeled data DU 6 and model order kas input, and assign a class label or a cluster indexto each instance in DU as output.
Previous super-vised or semi-supervised algorithms (e.g.
SVM,label propagation algorithm (Zhu and Ghahra-mani, 2002)) cannot classify the examples in DUinto k groups if k > kXL .
The semi-supervised k-means clustering algorithm (Wagstaff et al, 2001)may be used to perform clustering analysis onmixed data, but its efficiency is a problem for clus-tering analysis on a very large dataset since multi-ple restarts are usually required to avoid local op-tima and multiple iterations will be run in eachclustering process for optimizing a clustering so-lution.In this work, we propose an alternative method,an extended label propagation algorithm (ELP),which can classify the examples in DU into kgroups.
If the value of k is equal to kXL , thenELP is identical with the plain label propagationalgorithm (LP) (Zhu and Ghahramani, 2002).
Oth-erwise, if the value of k is greater than kXL , weperform classification by the following steps:(1) estimate the dataset size of each new class assizenew class by identifying the examples of newclasses using the ?Spy?
technique 7 and assuming5DL may be the dataset XL or a subset sampled from XL.6DU may be the dataset XU or a subset sampled fromXU .7The ?Spy?
technique was proposed in (Liu et al, 2003).Our re-implementation of this technique consists of threesteps: (1) sample a small subset DsL with the size 15%?|DL|from DL; (2) train a classifier with tagged data DL ?
DsL;(3) classify DU and DsL, and then select some examples fromDU as the dataset of new classes, which have the classifica-that new classes are equally distributed;(2) D?L = DL, D?U = DU ;(3) remove tagged examples of the m-th newclass (kXL + 1 ?
m ?
k) from D?L 8 and train aclassifier on this labeled dataset without the m-thclass;(4) the classifier is then used to classify the ex-amples in D?U ;(5) the least confidently unlabeled pointxclass m ?
D?U , together with its label m, is addedto the labeled data D?L = D?L + xclass m, andD?U = D?U ?
xclass m;(6) steps (3) to (5) are repeated for each newclass till the augmented tagged data set is largeenough (here we try to select sizenew class/4 ex-amples with their sense tags as tagged data foreach new class);(7) use plain LP algorithm to classify remainingunlabeled data D?U with D?L as labeled data.Table 1 shows this extended label propagationalgorithm.Next we will provide the details of the plain la-bel propagation algorithm.Define Wij = exp(?d2ij?2 ) if i 6= j and Wii = 0(1 ?
i, j ?
|DL + DU |), where dij is the distance(e.g., Euclidean distance) between the example xiand xj , and ?
is used to control the weight Wij .Define |DL + DU | ?
|DL + DU | probabilitytransition matrix Tij = P (j ?
i) = Wij?nk=1 Wkj,where Tij is the probability to jump from examplexj to example xi.Compute the row-normalized matrix T byT ij = Tij/?nk=1 Tik.The classification solution is obtained byYDU = (I ?
T uu)?1T ulY 0DL .
I is |DU | ?
|DU |identity matrix.
T uu and T ul are acquired by split-ting matrix T after the |DL|-th row and the |DL|-thcolumn into 4 sub-matrices.2.2 Model Order Identification ProcedureFor achieving the model order identification (orsense number estimation) ability, we use a clus-ter validation based criterion (Levine and Domany,2001) to infer the optimal number of senses of win XL+U .tion confidence less than the average of that in DsL.
Classifi-cation confidence of the example xi is defined as the absolutevalue of the difference between two maximum values fromthe i-th row in labeling matrix.8Initially there are no tagged examples for the m-th classin D?L.
Therefore we do not need to remove tagged examplesfor this new class, and then directly train a classifier with D?L.417Table 2: Model order evaluation algorithm.Function: CV(XL+U , k, q, Y 0XL+U )Input: data set XL+U , model order k,and sampling frequency q;Output: the score of the merit of k;1 Run the extended label propagationalgorithm with XL, XU , k and Y 0XL+U ;2 Construct connectivity matrix Ck basedon above classification solution on XU ;3 Use a random predictor ?k to assignuniformly drawn labels to each vectorin XU ;4 Construct connectivity matrix C?k usingabove classification solution on XU ;5 For ?
= 1 to q do5.1 Randomly sample a subset X?L+U withthe size ?|XL+U | from XL+U , 0 < ?
< 1;5.2 Run the extended label propagationalgorithm with X?L, X?U , k and Y 0?
;5.3 Construct connectivity matrix C?k usingabove classification solution on X?U ;5.4 Use ?k to assign uniformly drawn labelsto each vector in X?U ;5.5 Construct connectivity matrix C?
?k usingabove classification solution on X?U ;Endfor6 Evaluate the merit of k using followingformula:Mk = 1q??
(M(C?k , Ck) ?
M(C?
?k , C?k)),where M(C?, C) is given by equation (2);7 Return Mk;Then this model order identification procedurecan be formulated as:k?XL+U = argmaxKmin?k?Kmax{CV (XL+U , k, q, Y 0XL+U )}.
(1)k?XL+U is the estimated sense number in XL+U ,Kmin (or Kmax) is the minimum (or maximum)value of sense number, and k is the possible valueof sense number in XL+U .
Note that k ?
kXL .Then we set Kmin = kXL .
Kmax may be set as avalue greater than the possible ground-truth value.CV is a cluster validation based evaluation func-tion.
Table 2 shows the details of this function.We set q, the resampling frequency for estimationof stability score, as 20. ?
is set as 0.90.
The ran-dom predictor assigns uniformly distributed classlabels to each instance in a given dataset.
Werun this CV procedure for each value of k. Thevalue of k that maximizes this function will be se-lected as the estimation of sense number.
At thesame time, we can obtain a partition of XL+U withk?XL+U groups.The function M(C?, C) in Table 2 is given by(Levine and Domany, 2001):M(C?, C) =?i,j 1{C?i,j = Ci,j = 1, xi, xj ?
X?U}?i,j 1{Ci,j = 1, xi, xj ?
X?U},(2)where X?U is the untagged data in X?L+U , X?L+Uis a subset with the size ?|XL+U | (0 < ?
< 1)sampled from XL+U , C or C?
is |XU | ?
|XU | or|X?U | ?
|X?U | connectivity matrix based on classi-fication solutions computed on XU or X?U respec-tively.
The connectivity matrix C is defined as:Ci,j = 1 if xi and xj belong to the same cluster,otherwise Ci,j = 0.
C?
is calculated in the sameway.M(C?, C) measures the proportion of examplepairs in each group computed on XU that are alsoassigned into the same group by the classificationsolution on X?U .
Clearly, 0 ?
M ?
1.
Intu-itively, if the value of k is identical with the truevalue of sense number, then classification resultson the different subsets generated by samplingshould be similar with that on the full dataset.
Inthe other words, the classification solution with thetrue model order as parameter is robust against re-sampling, which gives rise to a local optimum ofM(C?, C).In this algorithm, we normalize M(C?k , Ck) bythe equation in step 6 of Table 2, which makesour objective function different from the figure ofmerit (equation ( 2)) proposed in (Levine and Do-many, 2001).
The reason to normalize M(C?k , Ck)is that M(C?k , Ck) tends to decrease when increas-ing the value of k (Lange et al, 2002).
Thereforefor avoiding the bias that the smaller value of kis to be selected as the model order, we use thecluster validity of a random predictor to normalizeM(C?k , Ck).If k?XL+U is equal to kXL , then there is no newsense in XU .
Otherwise (k?XL+U > kXL) newsenses of w may be represented by the groups inwhich there is no instance from XL.3 Experiments and Results3.1 Experiment DesignWe evaluated the ELP based model order iden-tification algorithm on the data in English lexi-cal sample task of SENSEVAL-3 (including all418Table 3: Description of The percentage of officialtraining data used as tagged data when instanceswith different sense sets are removed from officialtraining data.The percentage of officialtraining data used as tagged dataSsubset = {s1} 42.8%Ssubset = {s2} 76.7%Ssubset = {s3} 89.1%Ssubset = {s1, s2} 19.6%Ssubset = {s1, s3} 32.0%Ssubset = {s2, s3} 65.9%the 57 English words ) 9, and further empiricallycompared it with other state of the art classifi-cation methods, including SVM 10 (the state ofthe art method for supervised word sense disam-biguation (Mihalcea et al, 2004)), a one-class par-tially supervised classification algorithm (Liu etal., 2003) 11, and a semi-supervised k-means clus-tering based model order identification algorithm.The data for English lexical samples task inSENSEVAL-3 consists of 7860 examples as offi-cial training data, and 3944 examples as officialtest data for 57 English words.
The number ofsenses of each English word varies from 3 to 11.We evaluated these four algorithms with differ-ent sizes of incomplete tagged data.
Given offi-cial training data of the word w, we constructedincomplete tagged data XL by removing the allthe tagged instances from official training data thathave sense tags from Ssubset, where Ssubset is asubset of the ground-truth sense set S for w, and Sconsists of the sense tags in official training set forw.
The removed training data and official test dataof w were used as XU .
Note that SL = S?Ssubset.Then we ran these four algorithm for each targetword w with XL as tagged data and XU as un-tagged data, and evaluated their performance us-ing the accuracy on official test data of all the 57words.
We conducted six experiments for each tar-get word w by setting Ssubset as {s1}, {s2}, {s3},{s1, s2}, {s1, s3}, or {s2, s3}, where si is the i-thmost frequent sense of w. Ssubset cannot be set as{s4} since some words have only three senses.
Ta-ble 3 lists the percentage of official training dataused as tagged data (the number of examples in in-9Available at http://www.senseval.org/senseval310we used a linear SV M light, available athttp://svmlight.joachims.org/.11Available at http://www.cs.uic.edu/?liub/LPU/LPU-download.htmlcomplete tagged data divided by the number of ex-amples in official training data) when we removedthe instances with sense tags from Ssubset for allthe 57 words.
If Ssubset = {s3}, then most ofsense tagged examples are still included in taggeddata.
If Ssubset = {s1, s2}, then there are very fewtagged examples in tagged data.
If no instances areremoved from official training data, then the valueof percentage is 100%.Given an incomplete tagged corpus for a targetword, SVM does not have the ability to find thenew senses from untagged corpus.
Therefore it la-bels all the instances in the untagged corpus withsense tags from SL.Given a set of positive examples for a class anda set of unlabeled examples, the one-class partiallysupervised classification algorithm, LPU (Learn-ing from Positive and Unlabeled examples) (Liuet al, 2003), learns a classifier in four steps:Step 1: Identify a small set of reliable negativeexamples from unlabeled examples by the use of aclassifier.Step 2: Build a classifier using positive ex-amples and automatically selected negative exam-ples.Step 3: Iteratively run previous two steps untilno unlabeled examples are classified as negativeones or the unlabeled set is null.Step 4: Select a good classifier from the set ofclassifiers constructed above.For comparison, LPU 12 was run to performclassification on XU for each class in XL.
Thelabel of each instance in XU was determined bymaximizing the classification score from LPU out-put for each class.
If the maximum score of aninstance is negative, then this instance will be la-beled as a new class.
Note that LPU classifiesXL+U into kXL + 1 groups in most of cases.The clustering based partially supervised sensedisambiguation algorithm was implemented by re-placing ELP with a semi-supervised k-means clus-tering algorithm (Wagstaff et al, 2001) in themodel order identification procedure.
The labelinformation in labeled data was used to guide thesemi-supervised clustering on XL+U .
Firstly, thelabeled data may be used to determine initial clus-ter centroids.
If the cluster number is greater12The three parameters in LPU were set as follows: ?-s1spy -s2 svm -c 1?.
It means that we used the spy technique forstep 1 in LPU, the SVM algorithm for step 2, and selected thefirst or the last classifier as the final classifier.
It is identicalwith the algorithm ?Spy+SVM IS?
in Liu et al (2003).419than kXL , the initial centroids of clusters for newclasses will be assigned as randomly selected in-stances.
Secondly, in the clustering process, theinstances with the same class label will stay inthe same cluster, while the instances with differentclass labels will belong to different clusters.
Forbetter clustering solution, this clustering processwill be restarted three times.
Clustering processwill be terminated when clustering solution con-verges or the number of iteration steps is more than30.
Kmin = kXL = |SL|, Kmax = Kmin + m. mis set as 4.We used Jensen-Shannon (JS) divergence (Lin,1991) as distance measure for semi-supervisedclustering and ELP, since plain LP with JS diver-gence achieves better performance than that withcosine similarity on SENSEVAL-3 data (Niu et al,2005).For the LP process in ELP algorithm, we con-structed connected graphs as follows: two in-stances u, v will be connected by an edge if u isamong v?s 10 nearest neighbors, or if v is amongu?s 10 nearest neighbors as measured by cosine orJS distance measure (following (Zhu and Ghahra-mani, 2002)).We used three types of features to capture theinformation in all the contextual sentences of tar-get words in SENSEVAL-3 data for all the fouralgorithms: part-of-speech of neighboring wordswith position information, words in topical con-text without position information (after removingstop words), and local collocations (as same as thefeature set used in (Lee and Ng, 2002) except thatwe did not use syntactic relations).
We removedthe features with occurrence frequency (countedin both training set and test set) less than 3 times.If the estimated sense number is more than thesense number in the initial tagged corpus XL, thenthe results from order identification based meth-ods will consist of the instances from clusters ofunknown classes.
When assessing the agreementbetween these classification results and the knownresults on official test set, we will encounter theproblem that there is no sense tag for each instancein unknown classes.
Slonim and Tishby (2000)proposed to assign documents in each cluster withthe most dominant class label in that cluster, andthen conducted evaluation on these labeled docu-ments.
Here we will follow their method for as-signing sense tags to unknown classes from LPU,clustering based order identification process, andELP based order identification process.
We as-signed the instances from unknown classes withthe dominant sense tag in that cluster.
The resultfrom LPU always includes only one cluster of theunknown class.
We also assigned the instancesfrom the unknown class with the dominant sensetag in that cluster.
When all instances have theirsense tags, we evaluated the their results using theaccuracy on official test set.3.2 Results on Sense DisambiguationTable 4 summarizes the accuracy of SVM, LPU,the semi-supervised k-means clustering algorithmwith correct sense number |S| or estimated sensenumber k?XL+U as input, and the ELP algorithmwith correct sense number |S| or estimated sensenumber k?XL+U as input using various incompletetagged data.
The last row in Table 4 lists the av-erage accuracy of each algorithm over the six ex-perimental settings.
Using |S| as input means thatwe do not perform order identification procedure,while using k?XL+U as input is to perform orderidentification and obtain the classification resultson XU at the same time.We can see that ELP based method outperformsclustering based method in terms of average accu-racy under the same experiment setting, and thesetwo methods outperforms SVM and LPU.
More-over, using the correct sense number as input helpsto improve the overall performance of both clus-tering based method and ELP based method.Comparing the performance of the same sys-tem with different sizes of tagged data (from thefirst experiment to the third experiment, and fromthe fourth experiment to the sixth experiment), wecan see that the performance was improved whengiven more labeled data.
Furthermore, ELP basedmethod outperforms other methods in terms of ac-curacy when rare senses (e.g.
s3) are missing inthe tagged data.
It seems that ELP based methodhas the ability to find rare senses with the use oftagged and untagged corpora.LPU algorithm can deal with only one-classclassification problem.
Therefore the labeled dataof other classes cannot be used when determiningthe positive labeled data for current class.
ELPcan use the labeled data of all the known classes todetermine the seeds of unknown classes.
It mayexplain why LPU?s performance is worse thanELP based sense disambiguation although LPUcan correctly estimate the sense number in XL+U420Table 4: This table summarizes the accuracy of SVM, LPU, the semi-supervised k-means clustering al-gorithm with correct sense number |S| or estimated sense number k?XL+U as input, and the ELP algorithmwith correct sense number |S| or estimated sense number k?XL+U as input on the official test data of ELStask in SENSEVAL-3 when given various incomplete tagged corpora.Clustering algorithm ELP algorithm Clustering algorithm ELP algorithmSVM LPU with |S| as input with |S| as input with k?XL+U as input with k?XL+U as inputSsubset ={s1} 30.6% 22.3% 43.9% 47.8% 40.0% 38.7%Ssubset ={s2} 59.7% 54.6% 44.0% 62.4% 48.5% 62.6%Ssubset ={s3} 67.0% 53.4% 48.7% 67.2% 52.4% 69.1%Ssubset ={s1, s2} 14.6% 13.1% 44.4% 40.2% 35.6% 33.0%Ssubset ={s1, s3} 25.7% 21.1% 48.5% 37.9% 39.8% 31.0%Ssubset ={s2, s3} 56.2% 53.1% 47.3% 59.4% 46.6% 58.7%Average accuracy 42.3% 36.3% 46.1% 52.5% 43.8% 48.9%Table 5: These two tables provide the mean andstandard deviation of absolute values of the differ-ence between ground-truth results |S| and sensenumbers estimated by clustering or ELP based or-der identification procedure respectively.Clustering based method ELP based methodSsubset ={s1} 1.3?1.1 2.2?1.1Ssubset ={s2} 2.4?0.9 2.4?0.9Ssubset ={s3} 2.6?0.7 2.6?0.7Ssubset ={s1, s2} 1.2?0.6 1.6?0.5Ssubset ={s1, s3} 1.4?0.6 1.8?0.4Ssubset ={s2, s3} 1.8?0.5 1.8?0.5when only one sense is missing in XL.When very few labeled examples are avail-able, the noise in labeled data makes it difficultto learn the classification score (each entry inYDU ).
Therefore using the classification confi-dence criterion may lead to poor performance ofseed selection for unknown classes if the classifi-cation score is not accurate.
It may explain whyELP based method does not outperform cluster-ing based method with small labeled data (e.g.,Ssubset = {s1}).3.3 Results on Sense Number EstimationTable 5 provides the mean and standard devia-tion of absolute difference values between ground-truth results |S| and sense numbers estimated byclustering or ELP based order identification pro-cedures respectively.
For example, if the groundtruth sense number of the word w is kw, and the es-timated value is k?w, then the absolute value of thedifference between these two values is |kw ?
k?w|.Therefore we can have this value for each word.Then we calculated the mean and deviation on thisarray of absolute values.
LPU does not have theorder identification capability since it always as-sumes that there is at least one new class in un-labeled data, and does not further differentiate theinstances from these new classes.
Therefore we donot provide the order identification results of LPU.From the results in Table 5, we can see that esti-mated sense numbers are closer to ground truth re-sults when given less labeled data for clustering orELP based methods.
Moreover, clustering basedmethod performs better than ELP based method interms of order identification when given less la-beled data (e.g., Ssubset = {s1}).
It seems thatELP is not robust to the noise in small labeled data,compared with the semi-supervised k-means clus-tering algorithm.4 Related WorkThe work closest to ours is partially supervisedclassification or building classifiers using positiveexamples and unlabeled examples, which has beenstudied in machine learning community (Denis etal., 2002; Liu et al, 2003; Manevitz and Yousef,2001; Yu et al, 2002).
However, they cannot421group negative examples into meaningful clusters.In contrast, our algorithm can find the occurrenceof negative examples and further group these neg-ative examples into a ?natural?
number of clusters.Semi-supervised clustering (Wagstaff et al, 2001)may be used to perform classification by the useof labeled and unlabeled examples, but it encoun-ters the same problem of partially supervised clas-sification that model order cannot be automaticallyestimated.Levine and Domany (2001) and Lange et al(2002) proposed cluster validation based criteriafor cluster number estimation.
However, theyshowed the application of the cluster validationmethod only for unsupervised learning.
Our workcan be considered as an extension of their methodsin the setting of partially supervised learning.In natural language processing community, thework that is closely related to ours is word sensediscrimination which can induce senses by group-ing occurrences of a word into clusters (Schu?tze,1998).
If it is considered as unsupervised meth-ods to solve sense disambiguation problem, thenour method employs partially supervised learningtechnique to deal with sense disambiguation prob-lem by use of tagged and untagged texts.5 ConclusionsIn this paper, we present an order identificationbased partially supervised classification algorithmand investigate its application to partially super-vised word sense disambiguation problem.
Exper-imental results on SENSEVAL-3 data indicate thatour ELP based model order identification algo-rithm achieves better performance than other stateof the art classification algorithms, e.g., SVM,a one-class partially supervised algorithm (LPU),and a semi-supervised k-means clustering basedmodel order identification algorithm.ReferencesBrown P., Stephen, D.P., Vincent, D.P., & Robert, Mer-cer.. 1991.
Word Sense Disambiguation Using Sta-tistical Methods.
Proceedings of ACL.Dagan, I.
& Itai A.. 1994.
Word Sense Disambigua-tion Using A Second Language Monolingual Cor-pus.
Computational Linguistics, Vol.
20(4), pp.
563-596.Denis, F., Gilleron, R., & Tommasi, M.. 2002.
TextClassification from Positive and Unlabeled Exam-ples.
Proceedings of the 9th International Confer-ence on Information Processing and Management ofUncertainty in Knowledge-Based Systems.Lange, T., Braun, M., Roth, V., & Buhmann, J. M.2002.
Stability-Based Model Selection.
NIPS 15.Leacock, C., Miller, G.A.
& Chodorow, M.. 1998.Using Corpus Statistics and WordNet Relations forSense Identification.
Computational Linguistics,24:1, 147?165.Lee, Y.K.
& Ng, H.T.. 2002.
An Empirical Eval-uation of Knowledge Sources and Learning Algo-rithms for Word Sense Disambiguation.
Proceed-ings of EMNLP, (pp.
41-48).Levine, E., & Domany, E. 2001.
Resampling Methodfor Unsupervised Estimation of Cluster Validity.Neural Computation, Vol.
13, 2573?2593.Lin, J.
1991.
Divergence Measures Based on theShannon Entropy.
IEEE Transactions on Informa-tion Theory, 37:1, 145?150.Liu, B., Dai, Y., Li, X., Lee, W.S., & Yu, P.. 2003.Building Text Classifiers Using Positive and Unla-beled Examples.
Proceedings of IEEE ICDM.Manevitz, L.M., & Yousef, M.. 2001.
One ClassSVMs for Document Classification.
Journal of Ma-chine Learning, 2, 139-154.Mihalcea R., Chklovski, T., & Kilgariff, A.. 2004.The SENSEVAL-3 English Lexical Sample Task.SENSEVAL-2004.Niu, Z.Y., Ji, D.H., & Tan, C.L.. 2005.
Word SenseDisambiguation Using Label Propagation BasedSemi-Supervised Learning.
Proceedings of ACL.Schu?tze, H.. 1998.
Automatic Word Sense Discrimi-nation.
Computational Linguistics, 24:1, 97?123.Wagstaff, K., Cardie, C., Rogers, S., & Schroedl, S..2001.
Constrained K-Means Clustering with Back-ground Knowledge.
Proceedings of ICML.Yarowsky, D.. 1995.
Unsupervised Word Sense Dis-ambiguation Rivaling Supervised Methods.
Pro-ceedings of ACL.Yu, H., Han, J., & Chang, K. C.-C.. 2002.
PEBL: Pos-itive example based learning for web page classifi-cation using SVM.
Proceedings of ACM SIGKDD.Zhu, X.
& Ghahramani, Z.. 2002.
Learning from La-beled and Unlabeled Data with Label Propagation.CMU CALD tech report CMU-CALD-02-107.422
