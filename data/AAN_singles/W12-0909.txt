Proceedings of the EACL 2012 Workshop on Computational Models of Language Acquisition and Loss, pages 33?37,Avignon, France, April 24 2012. c?2012 Association for Computational LinguisticsPHACTS about activation-based word similarity effectsBasilio CalderoneCLLE-ERSS (UMR 5263) CNRS &Universit?
de Toulouse-Le Mirail31058 Toulouse Cedex 9, Francebasilio.calderone@univ-tlse2.frChiara CelataScuola Normale SuperioreLaboratorio di Linguistica56126 Pisa, Italyc.celata@sns.itAbstractEnglish phonotactic learning is modeled bymeans of the PHACTS algorithm, a topo-logical neuronal receptive field implement-ing a phonotactic activation function aimedat capturing both local (i.e., phonemic) andglobal (i.e., word-level) similarities amongstrings.
Limits and merits of the model arepresented.1 IntroductionCategorical rules and probabilistic constraints ofphonotactic grammar affect speakers?
intuitionsabout the acceptability of word-level units in anumber of experimental tasks, including con-tinuous speech segmentation and word similar-ity judgment.
Several sources of informationcontribute to phonotactic generalization, includ-ing sub-segmental properties, segment transitionprobabilities, lexical neighborhood effects; allthese factors have been independently or jointlymodeled in several recent accounts of phonotac-tics and phonotactic learning (Coady and Aslin,2004; Vitevitch, 2003; Vitevitch and Luce, 2005;Hayes and Wilson, 2008; Albright, 2009; Coet-zee, 2009).In this study, we explore the word level phono-tactics in terms of a function of ?phonotactic ac-tivation?
within a PHACTS environment (Celataet al, 2011).
PHACTS is a topological neu-ronal receptive field implementing an n-gramsampling estimate of the frequency distribution ofphonemes and a sub- lexical chunking of recur-rent sequences of phonemes.
Once this phono-tactic knowledge has been developed, the modelgeneralizes it to novel stimuli to derive activation-based representations of full lexical forms, thusmirroring the contribution of lexical neighbor-hood effects.
Then the similarity values for pairsof words and non-words can be calculated.2 PHACTS: the modelPHACTS (for PHonotactic ACTivation System) isbased on the principles of a Self-Organizing Map(SOM) (Kohonen, 2000), an associative memoryalgorithm which realizes low-dimensional (gener-ally, bi-dimensional) representations of a multidi-mensional input space.PHACTS simulates the formation of phonotacticknowledge in the mind of a speaker, who is ex-posed to a stream of phonological words and grad-ually develops a mental representation of the sta-tistical regularities shaping the phonotactics of agiven language.
The model also performs lexi-cal generalizations on the basis of the phonotacticknowledge developed in the training phase.The physical structure of PHACTS is definedby a set S (with finite cardinality) of neurons njkwith 1 ?
j ?
J and 1 ?
k ?
K arranged ina bi-dimensional grid of S = {n11, n12, .
.
.
n},?S?
= JK.
Each neuron in the grid correspondsto a vector (the so-called prototype vector) whosedimension is equal to the dimension of the inputdata vector.
At the beginning of the learning pro-cess, the prototype vectors assume random valueswhile, as learning progresses, they change theirvalues to fit the input data.PHACTS works according to the two follow-ing phases: i) the training phase, where language-specific phonotactic knowledge is acquired; ii) thelexical generalization phase.332.1 Training phase: the acquisition ofphonotactic knowledgeAt the beginning, each input word iteratively hitsthe system.
For any iteration, the algorithmsearches for the best matching unit (BMU), thatis, the neuron which is topologically the closest tothe input vector i and which is a good candidateto represent the input data through the prototypevector.
The search for the BMU is given by maxi-mizing the dot product of i and ujk in the t-th stepof the iteration:BMU((i)t) = arg maxjk(i(t) ?
ujk) (1)In other terms, the BMU((i)t) is the best alignedprototype vector with respect to the input i. Af-ter the BMU is selected for each i at time t,PHACTS adapts the prototype vector ujk to thecurrent input according to the topological adapta-tion equation given in (2):?ujk(t) = ?(t)?(t)[i(t)?
ujk(t?
1)] (2)where ?
(t) is a learning rate and ?
(t) is the so-called neighborhood function.
The neighborhoodfunction is a function of time and distance be-tween the BMU and each of its neighbors on thebi-dimensional map.
It defines a set of neuronsaround the that would receive training, while neu-rons outside this set would not be changed.
In ourmodel the neighborhood function is defined as aGaussian function.The ?
parameter controls for the elasticity ofthe network, and ?
roughly controls for the areaaround each best matching where the neurons aremodified.
The initial value of both parameters isset heuristically and in general decreases as longas the learning progresses.
In order to facilitate atraining convergence, we set ?
?
0 and ?
?
0as t ?
0.
PHACTS performs a vector map-ping of the data space in input to the output spacedefined by the prototype vectors ujk on the bi-dimensional grid of neurons S.2.1.1 The data: Type and token frequency inPHACTSFor the present simulations, PHACTS wastrained on a portion of the CELEX Englishdatabase (Baayen et al, 1995), and specificallyon 8266 English word types phonologically tran-scribed and provided with their frequency of oc-currence (only the words with token frequency> 100 were selected).
Each phoneme was phono-logically encoded according to a binary vectorspecifying place, manner of articulation and voic-ing for consonants, roundedness, height and ante-riority for vowels.
The bi-dimensional map was25 X 35 neurons, and thus S = 875.
Input wordswere sampled according to i for PHACTS is con-stituted by the input training words with a n-gramsampling window (with n spanning up the lengthof the longest word).During the training phase, the map takes intoaccount the global distribution of the n-gramsin order to realize the topological activationsof the phonotactic patterns (?phonotactic activa-tion?).
Both token frequency (i.e., the numberof occurrences of specific n-grams) and type fre-quency (i.e., the number of all members of ann-gram type as defined by phonological featuresshared; for instance, /tan/ and /dim/ are two re-alizations of the trigram type stop+vowel+nasal)play a key role in phonotactic activation.
Byvirtue of being repeatedly inputted to the map, ahigh token frequency n-gram will exhibit high ac-tivation state in the map.
Low token frequencyn-grams, however, will exhibit activation on theSOM only if they share phonological material(namely, phonemes or features) with high tokenfrequency n-grams.
Type frequency generatesentrenchment effects in the map; high type fre-quency n-grams will occupy adjacent positionson the bi-dimensional map, thus defining clearphonotactic clusters.
For these reasons, PHACTSdiffer sharply from current models of phonotac-tic learning, where only type frequencies are as-sumed to play a role in phonotactic generalization(and formalized accordingly).
(Albright, 2009)2.2 N-gram generalization and lexicalgeneralizationsOnce PHACTS has been exposed to an input ofphonologically-encoded n-grams , an activation-based representation of unseen words can bederived.
This phase implements a linear thresh-olded function d in which each neuron T?firesT?as a function of its activation with respect tothe (unseen) n-grams.
In this sense each neuronacts as a ?transfer function?T?
of an activationweight depending on the alignment betweenthe unseen n-gram vector and the best alignedn-gram prototype vector.34Lexical generalization in PHACTS is thereforea word-level transfer process whereby the activa-tion values of each word n-gram are summed ac-cording to equation [4]:FPHACTS(x) =?jk?
(x) (3)The cumulative action of n-gram activations re-alizes a distributed representation of the word inwhich both phonological similarity (at the stringlevel), and token frequency effects for phonotac-tic patterns are taken into account.Being based on an associative memory learn-ing of phonological words inputted by a n-gramsampling window, PHACTS develops topolog-ical cumulative memory traces of the learnedwords in which phonotactic activations emergeas the results of repeated mnemonic superim-positions of n-grams.
This aspect is crucialfor a distributional analysis of the morphotacticsalience in a given language.
In this direction,PHACTS was successfully implemented in themodeling of the micro- and macro-phonotacticsin Italian (Calderone and Celata, 2010).
Bymicro-phonotactics we mean sequential informa-tion among segments (e.g., the fact that, in thespecific language, a phonological sequence, suchas /ato/, differs from similar sequences, such as/uto/, /rto/, and /atu/ ).
By macro-phonotactics wemean positional information within the word, i.e.,sub-lexical (or chunk) effects (e.g., the fact thatword-initial /#ato/ is different from word-medial/-ato-/, as well as from word-final /ato#/ ).
In En-glish language as well, PHACTS seems to distri-butionally distinguish a positional relevance forhighly attested phonological sequences such as/ing/.
Figure 1 reports the phonotactic activationstates outputted for the sequence /ing/ in initialand final word position (training corpus and pa-rameters described in 2.1.1).3 The experimentsAccording to the literature, the speakers in judg-ing the wordlikeness of isolated non-words relymainly on a grammar-based phonotactic knowl-edge and enhance the correspondence amongtypes of strings (e.g., segmental features and onsetand coda constituency).
In doing so, they estab-lish connections between each non-word and the#ing--ing#Figure 1: Phonotactic activation states for the se-quence #ing- (initial word position) and -ing# (finalword position)neighborhood of all attested and unattested (butphonotactically legal, i.e., potentially attested)strings of their language.
This must be a com-putationally hard task to accomplish even whenno time restrictions are imposed, as in traditionalwordlikeness experiments (since (Scholes, 1966)onward).
In this experiment, we want to verifywhether such task can be modeled in PHACTSand whether the vector representation of wordsoutputted by PHACTS may represent a solid basisfor this type of phonotactic evaluation.
To evalu-ate PHACTS?s ability to reproduce the typicalitypatterns produced by the speakers in judging the?Englishness?
of isolated strings, we had to derivea similarity value among each string and somecounterpart in the English lexicon, as explainedwith more details below.
We used 150 non-words,which were randomly selected from the list of272 non-words of Bailey and Hahn (2001, B &H henceforth).In that study, pronounceable non-words werecreated, either 4- or 5-phoneme long, differingfrom their nearest real word neighbor by eitherone or two phonemes (in terms of substitution,addition or subtraction).
In the former case theywere called near misses, in the latter case theywere called isolates.
22 isolates and 250 nearmisses around the isolates were used in the B& H?s study; 24 English speakers were askedto judge the ?Englishness?
of the non-words thatwere individually presented in their orthographicand auditory form.
The 150 non-words used inthe present experiment were selected from amongthe near misses only.
PHACTS was asked to de-rive the cosine value between the vector represen-tations of each non- word and the correspondingreal English words composing its neighbor fam-ily (according to the lists provided in B & H).The total number of string pairs was 1650 (theaverage number of neighbors for each non-word35being 11).
Then, an average cosine value wascalculated for each of the 150 non-words.
Theaverage cosine value was assumed to reflect thephonotactic acceptability of each non-word withrespect to their real word neighbors and therefore,to approximate the speakers?
typicality judgmentof isolated non-words.
An edit distance calcula-tion (normalized by the length of the two strings)was performed for the same 1650 pairs of non-words.
Since the neighbors were all selected byadding, subtracting or modifying one phonemefrom their reference non-words, the edit distancevalues were expected not to vary to a large ex-tent.
In the edit distance algorithm, values rangefrom 0 to 1 according to the degree of the sim-ilarity between the two strings As expected, thedistribution of the edit distance values was notuniform and the 1650 string pairs elicited a verysmall range of edit distance values.
In total, 96%of cases elicited only four different edit distancevalues (namely, 0.83, 0.87, 0.93 and 0.97); the re-maining 4% elicited three different values whichwere all higher than 0.7.The cosine values outputted by PHACTS forthe same string pairs were evaluated with respectto the calculated edit distances.
As in the caseof the edit distance algorithm, cosine values closeto 1 indicate high similarity while values closeto 0 indicate low similarity.
As in the case ofthe edit distances, the cosine values were asym-metrically distributed, highly skewed to the right(for high similarity values).
The global range ofthe distribution of values was similar for the twoalgorithms (spanning from 0.7 to 0.99).
How-ever, compared to the sharpness of the edit dis-tance results (see Figure 2), PHACTS?s outputincluded subtler variations across comparisons,with fine distinctions distributed over a continu-ous range of values.
The edit distance and thecosine values turned out to be correlated withr = 0.465.
Although the nature of the differ-ence between PHACTS?s output and the edit dis-tance algorithm should be better evaluated withrespect to a more varied data set, also includingpairs of very dissimilar strings, we could prelimi-narily conclude that the cosine value calculated byPHACTS for pairs of activation-based string rep-resentations did not correspond to an edit distancecalculation.We further verified whether PHACTS cosinevalues could approximate the perceived phonotac-0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 10.650.70.750.80.850.90.951PHACTS(NORMALIZED) EDIT DISTANCE0.840.860.880.90.920.940.960.9811.02 0204060801001201401600.70.750.80.850.90.9510100200300400500600Figure 2: Correlation scatterplot and distribution his-tograms of the edit distance and PHACTS values forthe B & H?s materialstic distance between two strings, as it is calculatedby the speaker when (s)he is asked to judge thephonotactic acceptability of an isolated non-word.To test this hypothesis, the average cosine valueof each non-word was correlated with the corre-sponding acceptability rating produced by the En-glish subjects in the B & H?s work.
The Spear-man?s rank correlation between speakers?
ratingsand the (exp-transformed) cosine values was ?
=.216, p < .01.
Although statistically significant,the correlation coefficient was rather low and re-vealed that the observed and simulated behaviorsoverlapped only to a limited extent.
In particu-lar, PHACTS did not reach a span of phonotacticacceptability as large as the speakers appeared toproduce (with ratings comprised between 2.1 and6.5).In conclusion, PHACTS-based word similar-ity calculation appeared not to produce a reliableranking of strings according to their phonotacticwellformedness.
On the other hand, it did pro-duce a fine-grained distributed representation ofword in which both phonological similarity andtoken frequency effects for full forms seemed todefine phonotactic activations of highly attestedphonological sequences.
This kind of representa-tion differed from raw calculations of the numberof operations required to transform a string intoanother.Experimental protocols for modeling word simi-larity in PHACTS are currently under investiga-tion.36ReferencesAdam Albright.
2009.
Feature-based generalisationas a source of gradient acceptability.
Phonology,26(1):9?41.Harald R. Baayen, Richard Piepenbrock, and LeonGulikers.
1995.
The celex lexical database.
release2 (cd-rom).
Philadelphia: Linguistic Data Consor-tium, University of Philadelphia: Linguistic DataConsortium, University of Pennsylvania.Basilio Calderone and Chiara Celata.
2010.The morphological impact of micro- and macro-phonotactics.
computational and behavioral analy-sis (talk given).
In 14th International MorphologyMeeting, Budapest, 13-16 May.Chiara Celata, Basilio Calderone, and Fabio Mon-termini.
2011.
Enriched sublexical representa-tions to access morphological structures.
a psycho-computational account.
TAL-Traitement Automa-tique du Langage, 2(52):123?149.Jeffry A. Coady and Richard N. Aslin.
2004.
Youngchildren?s sensitivity to probabilistic phonotacticsin the developing lexicon.
Journal of Experimen-tal Child Psychology, 89:183?213.Andries W. Coetzee.
2009.
Grammar is both categor-ical and gradient.
In S. Parker, editor, Phonologi-cal Argumentation: Essays on Evidence and Moti-vation.
Equinox.Bruce Hayes and Colin Wilson.
2008.
A maxi-mum entropy model of phonotactics and phonotac-tic learning.
Linguistic Inquiry, 39(3):379?440.Teuvo Kohonen.
2000.
Self-Organizing Maps.Springer, Heidelberg.Robert J. Scholes.
1966.
Phonotactic Grammatical-ity.
Mouton.Michael S. Vitevitch and Paul A. Luce.
2005.
In-creases in phonotactic probability facilitate spokennonword repetition.
Journal of Memory and Lan-guage, 52(2):193?204.Michael S. Vitevitch.
2003.
The influence of sub-lexical and lexical representations on the processingof spoken words in english.
Clinical Linguistics &Phonetics, 17:487?499.37
