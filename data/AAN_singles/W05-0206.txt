Proceedings of the 2nd Workshop on Building Educational Applications Using NLP,pages 29?36, Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Automatic Essay Grading with Probabilistic Latent Semantic AnalysisTuomo Kakkonen, Niko Myller, Jari Timonen, and Erkki SutinenDepartment of Computer Science, University of JoensuuP.O.
Box 111, FI-80101 Joensuu, FINLANDfirstname.lastname@cs.joensuu.fiAbstractProbabilistic Latent Semantic Analysis(PLSA) is an information retrieval tech-nique proposed to improve the problemsfound in Latent Semantic Analysis (LSA).We have applied both LSA and PLSA inour system for grading essays written inFinnish, called Automatic Essay Assessor(AEA).
We report the results comparingPLSA and LSA with three essay sets fromvarious subjects.
The methods were foundto be almost equal in the accuracy mea-sured by Spearman correlation betweenthe grades given by the system and a hu-man.
Furthermore, we propose methodsfor improving the usage of PLSA in essaygrading.1 IntroductionThe main motivations behind developing automatedessay assessment systems are to decrease the time inwhich students get feedback for their writings, andto reduce the costs of grading.
The assumption inmost of the systems is that the grades given by thehuman assessors describe the true quality of an es-say.
Thus, the aim of the systems is to ?simulate?the grading process of a human grader and a sys-tem is usable only if it is able to perform the grad-ing as accurately as human raters.
An automated as-sessment system is not affected by errors caused bylack of consistency, fatigue or bias, thus it can helpachieving better accuracy and objectivity of assess-ment (Page and Petersen, 1995).There has been research on automatic essay grad-ing since the 1960s.
The earliest systems, such asPEG (Page and Petersen, 1995), based their grad-ing on the surface information from the essay.
Forexample, the number of words and commas werecounted in order to determine the quality of the es-says (Page, 1966).
Although these kinds of sys-tems performed considerably well, they also re-ceived heavy criticism (Page and Petersen, 1995).Some researchers consider the use of natural lan-guage as a feature for human intelligence (Hearstet al, 2000) and writing as a method to expressthe intelligence.
Based on that assumption, tak-ing the surface information into account and ignor-ing the meanings of the content is insufficient.
Re-cent systems and studies, such as e-rater (Burstein,2003) and approaches based on LSA (Landauer etal., 1998), have focused on developing the methodswhich determine the quality of the essays with moreanalytic measures such as syntactic and semanticstructure of the essays.
At the same time in the1990s, the progress of natural language processingand information retrieval techniques have given theopportunity to take also the meanings into account.LSA has produced promising results in contentanalysis of essays (Landauer et al, 1997; Foltz etal., 1999b).
Intelligent Essay Assessor (Foltz etal., 1999b) and Select-a-Kibitzer (Wiemer-Hastingsand Graesser, 2000) apply LSA for assessing essayswritten in English.
In Apex (Lemaire and Dessus,2001), LSA is applied to essays written in French.
Inaddition to the essay assessment, LSA is applied toother educational applications.
An intelligent tutor-ing system for providing help for students (Wiemer-29Hastings et al, 1999) and Summary Street (Stein-hart, 2000), which is a system for assessing sum-maries, are some examples of other applications ofLSA.
To our knowledge, there is no system utilizingPLSA (Hofmann, 2001) for automated essay assess-ment or related tasks.We have developed an essay grading system, Au-tomatic Essay Assessor (AEA), to be used to ana-lyze essay answers written in Finnish, although thesystem is designed in a way that it is not limited toonly one language.
It applies both course materials,such as passages from lecture notes and course text-books covering the assignment-specific knowledge,and essays graded by humans to build the model forassessment.
In this study, we employ both LSA andPLSA methods to determine the similarities betweenthe essays and the comparison materials in order todetermine the grades.
We compare the accuracy ofthese methods by using the Spearman correlation be-tween computer and human assigned grades.The paper is organized as follows.
Section 2 ex-plains the architecture of AEA and the used gradingmethods.
The experiment and results are discussedin Section 3.
Conclusions and future work based onthe experiment are presented in Section 4.2 AEA SystemWe have developed a system for automated assess-ment of essays (Kakkonen et al, 2004; Kakkonenand Sutinen, 2004).
In this section, we explain thebasic architecture of the system and describe themethods used to analyze essays.2.1 Architecture of AEAThere are two approaches commonly used in the es-say grading systems to determine the grade for theessay:1.
The essay to be graded is compared to thehuman-graded essays and the grade is based onthe most similar essays?
grades; or2.
The essay to be graded is compared to the essaytopic related materials (e.g.
textbook or modelessays) and the grade is given based on the sim-ilarity to these materials.In our system, AEA (Kakkonen and Sutinen, 2004),we have combined these two approaches.
The rel-evant parts of the learning materials, such as chap-ters of a textbook, are used to train the system withassignment-specific knowledge.
The approachesbased on the comparison between the essays to begraded and the textbook have been introduced in(Landauer et al, 1997; Foltz et al, 1999a; Lemaireand Dessus, 2001; Hearst et al, 2000), but have beenusually found less accurate than the methods basedon comparison to prescored essays.
Our methodattempts to overcome this by combining the useof course content and prescored essays.
The es-says to be graded are not directly compared to theprescored essays with for instance k-nearest neigh-bors method, but prescored essays are used to deter-mine the similarity threshold values for grade cat-egories as discussed below.
Prescored essays canalso be used to determine the optimal dimension forthe reduced matrix in LSA as discussed in Kakko-nen et al (2005).Figure 1: The grading process of AEA.Figure 1 illustrates the grading process of our sys-tem.
The texts to be analyzed are added into word-by-context matrix (WCM), representing the numberof occurrences of each unique word in each of thecontexts (e.g.
documents, paragraphs or sentences).In WCM M , cell Mij contains the count of the wordi occurrences in the context j.
As the first step in an-alyzing the essays and course materials, the lemmaof each word form occurring in the texts must befound.
We have so far applied AEA only to essayswritten in Finnish.
Finnish is morphologically morecomplex than English, and word forms are formedby adding suffixes into base forms.
Because of that,30base forms have to be used instead of inflectionalforms when building the WCM, especially if a rel-atively small corpus is utilized.
Furthermore, sev-eral words can become synonyms when suffixes areadded to them, thus making the word sense disam-biguation necessary.
Hence, instead of just strippingsuffixes, we apply a more sophisticated method,a morphological parser and disambiguator, namelyConstraint Grammar parser for Finnish (FINCG) toproduce the lemmas for each word (Lingsoft, 2005).In addition, the most commonly occurring words(stopwords) are not included in the matrix, and onlythe words that appear in at least two contexts areadded into the WCM (Landauer et al, 1998).
Wealso apply entropy-based term weighting in order togive higher values to words that are more importantfor the content and lower values to words with lessimportance.First, the comparison materials based on the rel-evant textbook passages or other course materialsare modified into machine readable form with themethod described in the previous paragraph.
Thevector for each context in the comparison materialsis marked with Yi.
This WCM is used to create themodel with LSA, PLSA or another information re-trieval method.
To compare the similarity of an es-say to the course materials, a query vector Xj of thesame form as the vectors in the WCM is constructed.The query vector Xj representing an essay is addedor folded in into the model build with WCM with themethod specific way discussed later.
This folded-in query X?j is then compared to the model of eachtext passage Y?i in the comparison material by using asimilarity measure to determine the similarity value.We have used the cosine of the angle between (X?j ,Y?i), to measure the similarity of two documents.
Thesimilarity score for an essay is calculated as the sumof the similarities between the essay and each of thetextbook passages.The document vectors of manually graded es-says are compared to the textbook passages, inorder to determine the similarity scores betweenthe essays and the course materials.
Based onthese measures, threshold values for the grade cat-egories are defined as follows: the grade categories,g1, g2, .
.
.
, gC , are associated with similarity valuelimits, l1, l2, .
.
.
, lC+1, where C is the number ofgrades, and lC+1 = ?
and normally l1 = 0 or??.
Other category limits li, 2 ?
i ?
C, are de-fined as weighted averages of the similarity scoresfor essays belonging to grade categories gi and gi?1.Other kinds of formulas to define the grade categorylimits can be also used.The grade for each essay to be graded is then de-termined by calculating the similarity score betweenthe essay and the textbook passages and comparingthe similarity score to the threshold values defined inthe previous phase.
The similarity score Si of an es-say di is matched to the grade categories accordingto their limits in order to determine the correct gradecategory as follows: For each i, 1 ?
i ?
C,if li < Si ?
li+1 then di ?
gi and break.2.2 Latent Semantic AnalysisLatent Semantic Analysis (LSA) (Landauer et al,1998) is a corpus-based method used in informa-tion retrieval with vector space models.
It providesa means of comparing the semantic similarity be-tween the source and target texts.
LSA has beensuccessfully applied to automate giving grades andfeedback on free-text responses in several systemsas discussed in Section 1.
The basic assumptionbehind LSA is that there is a close relationship be-tween the meaning of a text and the words in thattext.
The power of LSA lies in the fact that it is ableto map the essays with similar wordings closer toeach other in the vector space.
The LSA method isable to strengthen the similarity between two textseven when they do not contain common words.
Wedescribe briefly the technical details of the method.The essence of LSA is dimension reduction basedon the singular value decomposition (SVD), an al-gebraic technique.
SVD is a form of factor analy-sis, which reduces the dimensionality of the origi-nal WCM and thereby increases the dependency be-tween contexts and words (Landauer et al, 1998).SVD is defined as X = T0S0D0T , where X is thepreprocessed WCM and T0 and D0 are orthonormalmatrices representing the words and the contexts.
S0is a diagonal matrix with singular values.
In the di-mension reduction, the k highest singular values inS0 are selected and the rest are ignored.
With thisoperation, an approximation matrix X?
of the origi-nal matrix X is acquired.
The aim of the dimensionreduction is to reduce ?noise?
or unimportant detailsand to allow the underlying semantic structure to be-31come evident (Deerwester et al, 1990).In information retrieval and essay grading, thequeries or essays have to be folded in into the modelin order to calculate the similarities between the doc-uments in the model and the query.
In LSA, the fold-ing in can be achieved with a simple matrix multipli-cation: X?q = XTq T0S?10 , where Xq is the term vec-tor constructed from the query document with pre-processing, and T0 and S0 are the matrices from theSVD of the model after dimension reduction.
Theresulting vector X?q is in the same format as the doc-uments in the model.The features that make LSA suitable for auto-mated grading of essays can be summarized as fol-lows.
First, the method focuses on the content ofthe essay, not on the surface features or keyword-based content analysis.
The second advantage is thatLSA-based scoring can be performed with relativelylow amount of human graded essays.
Other meth-ods, such as PEG and e-rater typically need severalhundred essays to be able to form an assignment-specific model (Shermis et al, 2001; Burstein andMarcu, 2000) whereas LSA-based IEA system hassometimes been calibrated with as few as 20 essays,though it typically needs more essays (Hearst et al,2000).Although LSA has been successfully applied ininformation retrieval and related fields, it has also re-ceived criticism (Hofmann, 2001; Blei et al, 2003).The objective function determining the optimal de-composition in LSA is the Frobenius norm.
Thiscorresponds to an implicit additive Gaussian noiseassumption on the counts and may be inadequate.This seems to be acceptable with small documentcollections but with large document collections itmight have a negative effect.
LSA does not definea properly normalized probability distribution and,even worse, the approximation matrix may containnegative entries meaning that a document containsnegative number of certain words after the dimen-sion reduction.
Hence, it is impossible to treat LSAas a generative language model and moreover, theuse of different similarity measures is limited.
Fur-thermore, there is no obvious interpretation of thedirections in the latent semantic space.
This mighthave an effect if also feedback is given.
Choosingthe number of dimensions in LSA is typically basedon an ad hoc heuristics.
However, there is researchdone aiming to resolve the problem of dimension se-lection in LSA, especially in the essay grading do-main (Kakkonen et al, 2005).2.3 Probabilistic Latent Semantic AnalysisProbabilistic Latent Semantic Analysis (PLSA)(Hofmann, 2001) is based on a statistical modelwhich has been called the aspect model.
The aspectmodel is a latent variable model for co-occurrencedata, which associates unobserved class variableszk, k ?
{1, 2, .
.
.
, K} with each observation.
In oursettings, the observation is an occurrence of a wordwj , j ?
{1, 2, .
.
.
, M}, in a particular context di,i ?
{1, 2, .
.
.
, N}.
The probabilities related to thismodel are defined as follows:?
P (di) denotes the probability that a word oc-currence will be observed in a particular con-text di;?
P (wj |zk) denotes the class-conditional proba-bility of a specific word conditioned on the un-observed class variable zk; and?
P (zk|di) denotes a context specific probabilitydistribution over the latent variable space.When using PLSA in essay grading or informationretrieval, the first goal is to build up the model.
Inother words, approximate the probability mass func-tions with machine learning from the training data,in our case the comparison material consisting of as-signment specific texts.Expectation Maximization (EM) algorithm can beused in the model building with maximum likeli-hood formulation of the learning task (Dempster etal., 1977).
In EM, the algorithm alternates betweentwo steps: (i) an expectation (E) step where posteriorprobabilities are computed for the latent variables,based on the current estimates of the parameters, (ii)a maximization (M) step, where parameters are up-dated based on the loglikelihood which depends onthe posterior probabilities computed in the E-step.The standard E-step is defined in equation (1).P (zk|di, wj) =P (wj |zk)P (zk|di)?Kl=1 P (wj |zl)P (zl|di)(1)The M-step is formulated in equations (2) and (3)as derived by Hofmann (2001).
These two steps32are alternated until a termination condition is met,in this case, when the maximum likelihood functionhas converged.P (wj |zk) =?Ni=1 n(di, wj)P (zk|di, wj)?Mm=1?Ni=1 n(di, wm)P (zk|di, wm)(2)P (zk|di) =?Mj=1 n(di, wj)P (zk|di, wj)?Mm=1 n(di, wm)(3)Although standard EM algorithm can lead to goodresults, it may also overfit the model to the train-ing data and perform poorly with unseen data.
Fur-thermore, the algorithm is iterative and convergesslowly, which can increase the runtime seriously.Hence, Hofmann (2001) proposes another approachcalled Tempered EM (TEM), which is a derivation ofstandard EM algorithm.
In TEM, the M-step is thesame as in EM, but a dampening parameter is intro-duced into the E-step as shown in equation (4).
Theparameter ?
will dampen the posterior probabilitiescloser to uniform distribution, when ?
< 1 and formthe standard E-step when ?
= 1.P (zk|di, wj) =(P (wj |zk)P (zk|di))?
(?Kl=1 P (wj |zl)P (zl|di))?
(4)Hofmann (2001) defines the TEM algorithm asfollows:1.
Set ?
:= 1 and perform the standard EM withearly stopping.2.
Set ?
:= ??
(with ?
< 1).3.
Repeat the E- and M-steps until the perfor-mance on hold-out data deteriorates, otherwisego to step 2.4.
Stop the iteration when decreasing ?
does notimprove performance on hold-out data.Early stopping means that the optimization is notdone until the model converges, but the iteration isstopped already once the performance on hold-outdata degenerates.
Hofmann (2001) proposes to usethe perplexity to measure the generalization perfor-mance of the model and the stopping condition forthe early stopping.
The perplexity is defined as thelog-averaged inverse probability on unseen data cal-culated as in equation (5).P = exp(?
?i,j n?
(di, wj) log P (wj |di)?i,j n?
(di, wj)), (5)where n?
(di, wj) is the count on hold-out or trainingdata.In PLSA, the folding in is done by using TEMas well.
The only difference when folding in a newdocument or query q outside the model is that justthe probabilities P (zk|q) are updated during the M-step and the P (wj |zk) are kept as they are.
The sim-ilarities between a document di in the model and aquery q folded in to the model can be calculated withthe cosine of the angle between the vectors contain-ing the probability distributions (P (zk|q))Kk=1 and(P (zk|di))Kk=1 (Hofmann, 2001).PLSA, unlike LSA, defines proper probabilitydistributions to the documents and has its basis inStatistics.
It belongs to a framework called LatentDirichlet Allocations (Girolami and Kaba?n, 2003;Blei et al, 2003), which gives a better grounding forthis method.
For instance, several probabilistic sim-ilarity measures can be used.
PLSA is interpretablewith its generative model, latent classes and illus-trations in N -dimensional space (Hofmann, 2001).The latent classes or topics can be used to determinewhich part of the comparison materials the studenthas answered and which ones not.In empirical research conducted by Hof-mann (2001), PLSA yielded equal or better resultscompared to LSA in the contexts of informationretrieval.
It was also shown that the accuracy ofPLSA can increase when the number of latentvariables is increased.
Furthermore, the combina-tion of several similarity scores (e.g.
cosines ofangles between two documents) from models withdifferent number of latent variables also increasesthe overall accuracy.
Therefore, the selection of thedimension is not as crucial as in LSA.
The problemwith PLSA is that the algorithm used to computatethe model, EM or its variant, is probabilistic and canconverge to a local maximum.
However, accordingto Hofmann (2001), this is not a problem since thedifferences between separate runs are small.
Flawsin the generative model and the overfitting problem33Set Field Training Test Grading Course Comp.
mat.
No.
No.No.
essays essays scale materials division type Passages Words1 Education 70 73 0?6 Textbook Paragraphs 26 23972 Education 70 73 0?6 Textbook Sentences 147 23973 Communications 42 45 0?4 Textbook Paragraphs 45 15834 Communications 42 45 0?4 Textbook Sentences 139 15835 Soft.
Eng.
26 27 0?10 *) Paragraphs 27 9656 Soft.
Eng.
26 27 0?10 *) Sentences 105 965Table 1: The essay sets used in the experiment.
*) Comparison materials were constructed from the coursehandout with teacher?s comments included and transparencies represented to the students.have been discussed in Blei et al (2003).3 Experiment3.1 Procedure and MaterialsTo analyze the performance of LSA and PLSA inthe essay assessment, we performed an experimentusing three essay sets collected from courses on edu-cation, marketing and software engineering.
The in-formation about the essay collections is shown in Ta-ble 1.
Comparison materials were taken either fromthe course book or other course materials and se-lected by the lecturer of the course.
Furthermore, thecomparison materials used in each of these sets weredivided with two methods, either into paragraphs orsentences.
Thus, we run the experiment in total withsix different configurations of materials.We used our implementations of LSA and PLSAmethods as described in Section 2.
With LSA, allthe possible dimensions (i.e.
from two to the num-ber of passages in the comparison materials) weresearched in order to find the dimension achievingthe highest accuracy of scoring, measured as thecorrelation between the grades given by the systemand the human assessor.
There is no upper limitfor the number of latent variables in PLSA mod-els as there is for the dimensions in LSA.
Thus,we applied the same range for the best dimensionsearch to be fair in the comparison.
Furthermore, alinear combination of similarity values from PLSAmodels (PLSA-C) with predefined numbers of la-tent variables K ?
{16, 32, 48, 64, 80, 96, 112, 128}was used just to analyze the proposed potential ofthe method as discussed in Section 2.3 and in (Hof-mann, 2001).
When building up all the PLSA mod-els with TEM, we used 20 essays from the trainingset of the essay collections to determine the earlystopping condition with perplexity of the model onunseen data as proposed by Hofmann (2001).3.2 Results and DiscussionThe results of the experiment for all the three meth-ods, LSA, PLSA and PLSA-C are shown in Table 2.It contains the most accurate dimension (columndim.)
measured by machine-human correlation ingrading, the percentage of the same (same) and adja-cent grades (adj.)
compared to the human grader andthe Spearman correlation (cor.)
between the gradesgiven by the human assessor and the system.The results indicate that LSA outperforms bothmethods using PLSA.
This is opposite to the re-sults obtained by Hofmann (2001) in informationretrieval.
We believe this is due to the size of thedocument collection used to build up the model.
Inthe experiments of Hofmann (2001), it was muchlarger, 1000 to 3000 documents, while in our casethe number of documents was between 25 and 150.However, the differences are quite small when usingthe comparison materials divided into sentences.
Al-though all methods seem to be more accurate whenthe comparison materials are divided into sentences,PLSA based methods seem to gain more than LSA.In most cases, PLSA with the most accuratedimension and PLSA-C perform almost equally.This is also in contrast with the findings of Hof-mann (2001) because in his experiments PLSA-Cperformed better than PLSA.
This is probably alsodue to the small document sets used.
Neverthe-less, this means that finding the most accurate di-mension is unnecessary, but it is enough to com-34Set LSA LSA LSA LSA PLSA PLSA PLSA PLSA PLSA-C PLSA-C PLSA-CNo.
dim.
same adj.
cor.
dim.
same adj.
cor.
same adj.
cor.1 14 39.7 43.9 0.78 9 31.5 32.9 0.66 34.2 35.6 0.702 124 35.6 49.3 0.80 83 37.0 37.0 0.76 35.6 41.1 0.733 8 31.1 28.9 0.54 38 24.4 35.6 0.41 17.7 24.4 0.124 5 24.4 42.3 0.57 92 35.6 31.1 0.59 22.2 35.6 0.475 6 29.6 48.2 0.88 16 18.5 18.5 0.78 11.1 40.1 0.686 6 44.4 37.1 0.90 55 33.3 44.4 0.88 14.8 40.7 0.79Table 2: The results of the grading process with different methods.bine several dimensions?
similarity values.
In ourcase, it seems that linear combination of the simi-larity values is not the best option because the sim-ilarity values between essays and comparison mate-rials decrease when the number of latent variablesincreases.
A topic for a further study would be toanalyze techniques to combine the similarity valuesin PLSA-C to obtain higher accuracy in essay grad-ing.
Furthermore, it seems that the best combina-tion of dimensions in PLSA-C depends on the fea-tures of the document collection (e.g.
number ofpassages in comparison materials or number of es-says) used.
Another topic of further research is howthe combination of dimensions can be optimized foreach essay set by using the collection specific fea-tures without the validation procedure proposed inKakkonen et al (2005).Currently, we have not implemented a version ofLSA that combines scores from several models butwe will analyze the possibilities for that in futureresearch.
Nevertheless, LSA representations for dif-ferent dimensions form a nested sequence becauseof the number of singular values taken to approxi-mate the original matrix.
This will make the modelcombination less effective with LSA.
This is not truefor statistical models, such as PLSA, because theycan capture a larger variety of the possible decom-positions and thus several models can actually com-plement each other (Hofmann, 2001).4 Future Work and ConclusionWe have implemented a system to assess essayswritten in Finnish.
In this paper, we report a newextension to the system for analyzing the essayswith PLSA method.
We have compared LSA andPLSA as methods for essay grading.
When our re-sults are compared to the correlations between hu-man and system grades reported in literature, wehave achieved promising results with all methods.LSA was slightly better when compared to PLSA-based methods.
As future research, we are going toanalyze if there are better methods to combine thesimilarity scores from several models in the contextof essay grading to increase the accuracy (Hofmann,2001).
Another interesting topic is to combine LSAand PLSA to compliment each other.We used the cosine of the angle between the prob-ability vectors as a measure of similarity in LSA andPLSA.
Other methods are proposed to determine thesimilarities between probability distributions pro-duced by PLSA (Girolami and Kaba?n, 2003; Bleiet al, 2003).
The effects of using these techniqueswill be compared in the future experiments.If the PLSA models with different numbers oflatent variables are not highly dependent on eachother, this would allow us to analyze the reliabilityof the grades given by the system.
This is not pos-sible with LSA based methods as they are normallyhighly dependent on each other.
However, this willneed further work to examine all the potentials.Our future aim is to develop a semi-automaticessay assessment system (Kakkonen et al, 2004).For determining the grades or giving feedback tothe student, the system needs a method for compar-ing similarities between the texts.
LSA and PLSAoffer a feasible solution for the purpose.
In orderto achieve even more accurate grading, we can usesome of the results and techniques developed forLSA and develop them further for both methods.
Weare currently working with an extension to our LSAmodel that uses standard validation methods for re-ducing automatically the irrelevant content informa-35tion in LSA-based essay grading (Kakkonen et al,2005).
In addition, we plan to continue the workwith PLSA, since it, being a probabilistic model, in-troduces new possibilities, for instance, in similaritycomparison and feedback giving.ReferencesD.
M. Blei, A. Y. Ng, and M. I. Jordan.
2003.
La-tent Dirichlet Allocation.
J. of Machine Learning Re-search, 3:993?1022.J.
Burstein and D. Marcu.
2000.
Benefits of modularityin an automated scoring system.
In Proc.
of the Work-shop on Using Toolsets and Architectures to Build NLPSystems, 18th Int?l Conference on Computational Lin-guistics, Luxembourg.J.
Burstein.
2003.
The e-rater scoring engine: Auto-mated essay scoring with natural language process-ing.
In M. D. Shermis and J. Burstein, editors, Auto-mated essay scoring: A cross-disciplinary perspective.Lawrence Erlbaum Associates, Hillsdale, NJ.S.
Deerwester, S. T. Dumais, G. W. Furnas, T. K. Lan-dauer, and R. Harshman.
1990.
Indexing By LatentSemantic Analysis.
J. of the American Society for In-formation Science, 41:391?407.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via the emalgorithm.
J. of the Royal Statistical Society, 39:1?38.P.
W. Foltz, D. Laham, and T. K. Landauer.
1999a.
Au-tomated Essay Scoring: Applications to EducationalTechnology.
In Proc.
of Wolrd Conf.
Educational Mul-timedia, Hypermedia & Telecommunications, Seattle,USA.P.
W. Foltz, D. Laham, and T. K. Landauer.
1999b.The Intelligent Essay Assessor: Applications toEducational Technology.
Interactive Multime-dia Electronic J. of Computer-Enhanced Learning,1.
http://imej.wfu.edu/articles/1999/2/04/index.asp (Accessed 3.4.2005).M.
Girolami and A. Kaba?n.
2003.
On an Equivalence be-tween PLSI and LDA.
In Proc.
of the 26th Annual Int?lACM SIGIR Conf.
on Research and Development in In-formaion Retrieval, pages 433?434, Toronto, Canada.ACM Press.M.
Hearst, K. Kukich, M. Light, L. Hirschman, J. Burger,E.
Breck, L. Ferro, T. K. Landauer, D. Laham, P. W.Foltz, and R. Calfee.
2000.
The Debate on AutomatedEssay Grading.
IEEE Intelligent Systems, 15:22?37.T.
Hofmann.
2001.
Unsupervised Learning by Proba-bilistic Latent Semantic Analysis.
Machine Learning,42:177?196.T.
Kakkonen and E. Sutinen.
2004.
Automatic As-sessment of the Content of Essays Based on CourseMaterials.
In Proc.
of the Int?l Conf.
on InformationTechnology: Research and Education, pages 126?130,London, UK.T.
Kakkonen, N. Myller, and E. Sutinen.
2004.
Semi-Automatic Evaluation Features in Computer-AssistedEssay Assessment.
In Proc.
of the 7th IASTED Int?lConf.
on Computers and Advanced Technology in Ed-ucation, pages 456?461, Kauai, Hawaii, USA.T.
Kakkonen, N. Myller, E. Sutinen, and J. Timonen.2005.
Comparison of Dimension Reduction Methodsfor Automated Essay Grading.
Submitted.T.
K. Landauer, D. Laham, B. Rehder, and M. E.Schreiner.
1997.
How well can passage meaning bederived without using word order?
A comparison ofLatent Semantic Analysis and humans.
In Proc.
of the19th Annual Meeting of the Cognitive Science Society,Mawhwah, NJ.
Erlbaum.T.
K. Landauer, P. W. Foltz, and D. Laham.
1998.
In-troduction to latent semantic analysis.
Discourse Pro-cesses, 25:259?284.B.
Lemaire and P. Dessus.
2001.
A System to Assess theSemantic Content of Student Essays.
J. of EducationalComputing Research, 24:305?320.Lingsoft.
2005. http://www.lingsoft.fi/ (Ac-cessed 3.4.2005).E.
B.
Page and N. S. Petersen.
1995.
The computermoves into essay grading.
Phi Delta Kappan, 76:561?565.E.
B.
Page.
1966.
The imminence of grading essays bycomputer.
Phi Delta Kappan, 47:238?243.M.
D. Shermis, H. R. Mzumara, J. Olson, and S. Harring-ton.
2001.
On-line Grading of Student Essays: PEGgoes on the World Wide Web.
Assessment & Evalua-tion in Higher Education, 26:247.D.
Steinhart.
2000.
Summary Street: an LSA Based Intel-ligent Tutoring System for Writing and Revising Sum-maries.
Ph.D. thesis, University of Colorado, Boulder,Colorado.P.
Wiemer-Hastings and A. Graesser.
2000.
Select-a-Kibitzer: A computer tool that gives meaningful feed-back on student compositions.
Interactive LearningEnvironments, 8:149?169.P.
Wiemer-Hastings, K. Wiemer-Hastings, andA.
Graesser.
1999.
Approximate natural lan-guage understanding for an intelligent tutor.
InProc.
of the 12th Int?l Artificial Intelligence ResearchSymposium, pages 172?176, Menlo Park, CA, USA.36
