R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
804 ?
814, 2005.?
Springer-Verlag Berlin Heidelberg 2005Semantic Role Tagging for Chinese at the Lexical LevelOi Yee Kwong and Benjamin K. TsouLanguage Information Sciences Research Centre, City University of Hong Kong,Tat Chee Avenue, Kowloon, Hong Kong{rlolivia, rlbtsou}@cityu.edu.hkAbstract.
This paper reports on a study of semantic role tagging in Chinese, inthe absence of a parser.
We investigated the effect of using only lexical infor-mation in statistical training; and proposed to identify the relevant headwords ina sentence as a first step to partially locate the corresponding constituents to belabelled.
Experiments were done on a textbook corpus and a news corpus, rep-resenting simple data and complex data respectively.
Results suggested that inChinese, simple lexical features are useful enough when constituent boundariesare known, while parse information might be more important for complicatedsentences than simple ones.
Several ways to improve the headword identifica-tion results were suggested, and we also plan to explore some class-based tech-niques for the task, with reference to existing semantic lexicons.1   IntroductionAs the development of language resources progresses from POS-tagged corpora tosyntactically annotated treebanks, the inclusion of semantic information such aspredicate-argument relations is becoming indispensable.
The expansion of the PennTreebank into a Proposition Bank [11] is a typical move in this direction.
Lexicalresources also need to be enhanced with semantic information (e.g.
[5]).
In fact theability to identify semantic role relations correctly is essential to many applicationssuch as information extraction and machine translation; and making available re-sources with this kind of information would in turn facilitate the development of suchapplications.Large-scale production of annotated resources is often labour-intensive, and thusneeds automatic labelling to streamline the work.
The task can essentially be per-ceived as a two-phase process, namely to recognise the constituents bearing somesemantic relationship to the target verb in a sentence, and then to label them with thecorresponding semantic roles.In their seminal proposal, Gildea and Jurafsky approached the task using variousfeatures such as headword, phrase type, and parse tree path [6].
Such features haveremained the basic and essential features in subsequent research, irrespective of thevariation in the actual learning components.
In addition, parsed sentences are oftenrequired, for extracting the path features during training and providing the argumentboundaries during testing.
The parse information is deemed important for the per-formance of role labelling [7, 8].More precisely, in semantic role labelling, parse information is rather more criticalfor the identification of boundaries for candidate constituents than for the extractionSemantic Role Tagging for Chinese at the Lexical Level 805of training data.
Its limited function in training, for instance, is reflected in the lowcoverage reported (e.g.
[21]).
However, given the imperfection of existing automaticparsers, which are far from producing gold standard parses, many thus resort to shal-low syntactic information from simple chunking, though results often turn out to beless satisfactory than with full parses.This limitation is even more pertinent for the application of semantic role labellingto languages which do not have sophisticated parsing resources.
In the case of Chi-nese, for example, there is considerable variability in its syntax-semantics interface;and when one has more nested and complex sentences such as those from news arti-cles, it becomes more difficult to capture the sentence structures by typical examples.It is therefore worthwhile to investigate alternatives to the role labelling task forChinese under the parsing bottleneck, both in terms of the features used and the short-cut or compromise to at least partially pin down the relevant constituents.
A series ofrelated questions deserve consideration here:1. how much could we achieve with only parse-independent features in the role la-belling process;2. with constituent boundaries unknown in the absence of parse information, couldwe at least identify the headwords in the relevant constituents to be tagged; and3.
whether the unknown boundary problem varies with the nature of the dataset,e.g., will the degradation in performance from known boundaries to unknownboundaries be more serious for complicated sentences than for simplesentences.So in the current study we experiment on the use of parse-independent features forsemantic role labelling in Chinese, for locating the headwords of the constituentscorresponding to arguments to be labelled.
We will also compare the results on twotraining and testing datasets.In Section 2, related work will be reviewed.
In Section 3, the data used in the cur-rent study will be introduced.
Our proposed method will be explained in Section 4,and the experiment reported in Section 5.
Results and future work will be discussedin Section 6, followed by conclusions in Section 7.2   Related WorkThe definition of semantic roles falls on a continuum from abstract ones to very spe-cific ones.
Gildea and Jurafsky [6], for instance, used a set of roles defined accordingto the FrameNet model [2], thus corresponding to the frame elements in individualframes under a particular domain to which a given verb belongs.
Lexical entries (infact not limited to verbs, in the case of FrameNet) falling under the same frame willshare the same set of roles.
Gildea and Palmer [7] defined roles with respect to indi-vidual predicates in the PropBank, without explicit naming.
To date PropBank andFrameNet are the two main resources in English for training semantic role labellingsystems.The theoretical treatment of semantic roles is also varied in Chinese.
In practice,for example, the semantic roles in the Sinica Treebank mark not only verbal argu-ments but also modifier-head relations within individual constituents, following a806 O.Y.
Kwong and B.K.
Tsouhead-driven principle [4].
In our present study, we use a set of more abstract semanticroles, which are generalisable to most Chinese verbs and are not dependent on par-ticular predicates.
They will be further introduced in Section 3.The major concerns in automatic semantic role labelling include the handling of al-ternations (as in ?the window broke?
and ?John broke the window?, where in bothcases ?the window?
should be tagged as ?patient?
despite its appearance in differentpositions in the sentences), and generalisation to unseen constituents and predicates.For the latter, clustering and semantic lexicons or hierarchies have been used (e.g.
[6]), or similar argument structures are assumed for near-synonyms and verbs underthe same frame (e.g.
[11]).Approaches in automatic semantic role labelling are mostly statistical, typicallymaking use of a number of features extracted from parsed training sentences.
InGildea and Jurafsky [6], the features studied include phrase type (pt), governing cate-gory (gov), parse tree path (path), position of constituent with respect to the targetpredicate (position), voice (voice), and headword (h).
The labelling of a constituentthen depends on its likelihood to fill each possible role r given the features and thetarget predicate t, as in the following, for example:),,,,,|( tvoicepositiongovpthrPSubsequent studies exploited a variety of implementation of the learning compo-nent, including Maximum Entropy (e.g.
[1, 12]), Support Vector Machines (e.g.
[9,16]), etc.
Transformation-based approaches were also used (e.g.
[10, 19]).
Swier andStevenson [17] innovated with an unsupervised approach to the problem, using abootstrapping algorithm, and achieved 87% accuracy.While the estimation of the probabilities could be relatively straightforward, thekey often lies in locating the candidate constituents to be labelled.
A parser of somekind is needed.
Gildea and Hockenmaier [8] compared the effects of CombinatoryCategorial Grammar (CCG) derivations and traditional Treebank parsing, and foundthat the former performed better on core arguments, probably due to its ability tocapture long range dependencies, but comparable for all arguments.
Gildea andPalmer [7] compared the effects of full parsing and shallow chunking; and found thatwhen constituent boundaries are known, both automatic parses and gold standardparses resulted in about 80% accuracy for subsequent automatic role tagging, butwhen boundaries are unknown, results with automatic parses dropped to 57% preci-sion and 50% recall.
With chunking only, performance further degraded to below30%.
Problems mostly arise from arguments which correspond to more than onechunk, and the misplacement of core arguments.A couple of evaluation exercises for semantic role labelling were organized re-cently, such as the shared task in CoNLL-2004 using PropBank data [3], and the onein SENSEVAL-3 using the FrameNet dataset [15].
Most systems in SENSEVAL-3used a parser to obtain full syntactic parses for the sentences, whereas systems par-ticipating in the CoNLL task were restricted to using only shallow syntactic informa-tion.
Results reported in the former tend to be higher.
Although the dataset may be afactor affecting the labelling performance, it nevertheless reinforces the usefulness offull syntactic information.Semantic Role Tagging for Chinese at the Lexical Level 807According to Carreras and M?rquez [3], for English, the state-of-the-art resultsreach an F1 measure of slightly over 83 using gold standard parse trees and about 77with real parsing results.
Those based on shallow syntactic information is about 60.The usefulness of parse information for semantic role labelling would be especiallyinteresting in the case of Chinese, given the flexibility in its syntax-semantics interface(e.g.
the object after ?
?eat?
could refer to the Patient as in ???
?eat apple?, Loca-tion as in ???
?eat canteen?, Duration as in ???
?eat three years?, etc.).
In theabsence of sophisticated parsing resources, however, we attempt to investigate howwell one could simply use a set of parse-independent features and backward guess thelikelihood of headwords to partially locate the candidate constituents to be labelled.3   The Data3.1   MaterialsAs mentioned in the introduction, we attempted to investigate the difference betweenlabelling simple sentences and complex ones.
For this purpose, sentences from pri-mary school textbooks were taken as examples for simple data, while sentences froma large corpus of newspaper texts were taken as complex examples.Two sets of primary school Chinese textbooks popularly used in Hong Kong weretaken for reference.
The two publishers were Keys Press [22] and Modern EducationResearch Society Ltd [23].
Texts for Primary One to Six were digitised, segmentedinto words, and annotated with parts-of-speech (POS).
The two sets of textbooksamount to a text collection of about 165K character tokens and upon segmentationabout 109K word tokens (about 15K word types).
There were about 2,500 transitiveverb types, with frequency ranging from 1 to 926.The complex examples were taken from a subset of the LIVAC synchronous cor-pus1 [13, 18].
The subcorpus consists of newspaper texts from Hong Kong, includinglocal news, international news, financial news, sports news, and entertainment news,collected in 1997-98.
The texts were segmented into words and POS-tagged, amount-ing to about 1.8M character tokens and upon segmentation about 1M word tokens(about 47K word types).
There were about 7,400 transitive verb types, with fre-quency ranging from 1 to just over 6,300.3.2   Training and Testing DataFor the current study, a set of 41 transitive verbs common to the two corpora (hereaf-ter referred to as textbook corpus and news corpus), with frequency over 10 and over50 respectively, was sampled.Sentences in the corpora containing the sampled verbs were extracted.
Constituentscorresponding to semantic roles with respect to the target verbs were annotated by atrained annotator, whose annotation was verified by another.
In this study, we workedwith a set of 11 predicate-independent abstract semantic roles.
According to the Dic-tionary of Verbs in Contemporary Chinese (Xiandai Hanyu Dongci Dacidian, ?????????)
[14], our semantic roles include the necessary arguments for most1http://www.livac.org808 O.Y.
Kwong and B.K.
Tsouverbs such as Agent and Patient, or Goal and Location in some cases; and some op-tional arguments realised by adjuncts, such as Quantity, Instrument, and Source.
Someexamples of semantic roles with respect to a given predicate are shown in Fig.
1.Fig.
1.
Examples of semantic roles with respect to a given predicateAltogether 980 sentences covering 41 verb types in the textbook corpus were anno-tated, resulting in 1,974 marked semantic roles (constituents); and 2,122 sentencescovering 41 verb types in the news corpus were annotated, resulting in 4,933 markedconstituents2.The role labelling system was trained on 90% of the sample sentences from thetextbook corpus and the news corpus separately; and tested on the remaining 10% ofthe respective corpora.4   Automatic Role LabellingThe automatic labelling was based on the statistical approach in Gildea and Jurafsky[6].
In Section 4.1, we will briefly mention the features employed in the trainingprocess.
Then in Sections 4.2 and 4.3, we will explain our approach for locatingheadwords in candidate constituents associated with semantic roles, in the absence ofparse information.4.1   TrainingIn this study, our probability model was based mostly on parse-independent featuresextracted from the training sentences, namely:2These figures only refer to the samples used in the current study.
In fact over 35,000 sen-tences in the LIVAC corpus have been semantically annotated, covering about 1,500 verbtypes and about 80,000 constituents were marked.?
??
??
??
?
??
?
?Next week school hold tell story contestTime Agent Target PatientExample: (Next week, the school will hold a story-telling contest.)??
?
???????
?
(-pl) write essay always feel not anythingExperiencer Target ThemeExample: (Students always feel there is nothing to write about for their essays.)??time??
?canTimeStudent writeSemantic Role Tagging for Chinese at the Lexical Level 809Headword (head): The headword from each constituent marked with a semantic rolewas identified.
For example, in the second sentence in Fig.
1, ??
(school) is theheadword in the constituent corresponding to the Agent of the verb ??
(hold), and??
(contest) is the headword of the noun phrase corresponding to the Patient.Position (posit): This feature shows whether the constituent being labelled appearsbefore or after the target verb.
In the first example in Fig.
1, the Experiencer andTime appear on the left of the target, while the Theme is on its right.POS of headword (HPos): Without features provided by the parse, such as phrasetype or parse tree path, the POS of the headword of the labelled constituent couldprovide limited syntactic information.Preposition (prep): Certain semantic roles like Time and Location are often realisedby prepositional phrases, so the preposition introducing the relevant constituentswould be an informative feature.Hence for automatic labelling, given the target verb t, the candidate constituent,and the above features, the role r which has the highest probability for P(r | head,posit, HPos, prep, t) will be assigned to that constituent.
In this study, however, weare also testing with the unknown boundary condition where candidate constituentsare not available in advance, hence we attempt to partially locate them by identifyingtheir headwords to start with.
Our approach is explained in the following sections.4.2   Locating Candidate HeadwordsIn the absence of parse information, and with constituent boundaries unknown, weattempt to partially locate the candidate constituents by trying to identify their corre-sponding headwords first.
Sentences in our test data were segmented into words andPOS-tagged.
We thus divide the recognition process into two steps, locating theheadword of a candidate constituent first, and then expanding from the headword todetermine its boundaries.Basically, if we consider every word in the same sentence as the target verb (bothto its left and to its right) a potential headword for a candidate constituent, what weneed to do is to find out the most probable words in the sentence to match againstindividual semantic roles.
We start with a feature set with more specific distributions,and back off to feature sets with less specific distributions.
Hence in each round welook for)|(maxarg setfeaturerPrfor every candidate word.
Ties are resolved by giving priority to the word nearest tothe target verb in the sentence.Fig.
2 shows an example illustrating the procedures for locating candidate head-words.
The target verb is ??
(discover).
In the first round, using features head,posit, HPos, and t, ??
(time) and ??
(problem) were identified as Time and Pa-tient respectively.
In the fourth subsequent round, backing off with features posit andHPos, ??
(we) was identified as a possible Agent.
In this round a few other wordswere identified as potential Patients.
However, since Patient was already located in810 O.Y.
Kwong and B.K.
Tsouthe previous round, those come up in this round are not considered.
So in the end theheadwords identified for the test sentence are ??
(we) for Agent, ??
(problem)for Patient and ??
(time) for Time.Fig.
2.
Example illustrating the procedures for locating candidate headwords4.3   Constituent BoundaryUpon the identification of headwords for potential constituents, the next step is toexpand from these headwords for constituent boundaries.
Although we are not doingthis step in the current study, it can potentially be done via some finite state tech-niques, or better still, with shallow syntactic processing like simple chunking ifavailable.5   The Experiment5.1   TestingThe system was trained and tested on the textbook corpus and the news corpusrespectively.
The testing was done under the ?known constituent?
and ?unknownconstituent?
conditions.
The former essentially corresponds to the known-boundarycondition in related studies; whereas in the unknown-constituent condition, which wewill call ?headword location?
condition hereafter, we tested our method of locatingcandidate headwords as explained above in Section 4.2.
In this study, every noun,verb, adjective, pronoun, classifier, and number within the test sentence containingthe target verb was considered a potential headword for a candidate constituentSentence:?????????????????????????????????????
?During revision, we discover a lot of problems which we have not thought of or cannot besolved, then we go and ask father.Candidate  Round 1 ?
Round 4  Final ResultHeadwords??
(revision)    Patient??
(time)  Time     ----       Time??
(we)    Agent       Agent??
(normally)??
(think)    Patient?
(can)??
(solve)    Patient??
(problem)  Patient     ----       Patient?
(go)     Patient?
(ask)    Patient??
(father)    PatientSemantic Role Tagging for Chinese at the Lexical Level 811corresponding to some semantic role.
The performance was measured in terms of theprecision (defined as the percentage of correct outputs among all outputs), recall (de-fined as the percentage of correct outputs among expected outputs), and F1 scorewhich is the harmonic mean of precision and recall.5.2   ResultsThe results are shown in Table 1, for testing on both the textbook corpus and the newscorpus under the known constituent condition and the headword location condition.Table 1.
Results on two datasets for known constituents and headword locationTextbook Data News DataPrecision Recall F1 Precision Recall F1Known Constituent 93.85 87.50 90.56 90.49 87.70 89.07Headword Location 46.12 61.98 52.89 38.52 52.25 44.35Under the known constituent condition, the results were good on both datasets,with an F1 score of about 90.
This is comparable or even better to the results reportedin related studies for known boundary condition.
The difference is that we did not useany parse information in the training, not even phrase type.
Our results thus suggestthat for Chinese, even without more complicated syntactic information, simple lexicalinformation might already be useful in semantic role tagging.Comparison of the known constituent condition with the headword location condi-tion shows that performance for the latter has expectedly dropped.
However, thedegradation was less serious with simple sentences than with complex ones, as is seenfrom the higher precision and recall for textbook data than for news data under theheadword location condition.
What is noteworthy here is that recall apparently dete-riorated less seriously than precision.
In the case of news data, for instance, we wereable to maintain over 50% recall but only obtained about 39% precision.
The surpris-ingly low precision is attributed to a technical inadequacy in the way we break ties.In this study we only make an effort to eliminate multiple tagging of the same role tothe same target verb in a sentence on either side of the target verb, but not if theyappear on both sides of the target verb.
This should certainly be dealt with in futureexperiments.
The differential degradation of performance between textbook data andnews data also suggests the varied importance of constituent boundaries to simplesentences and complex ones, and hence possibly their varied requirements for fullparse information for the semantic labelling task.6   DiscussionAccording to Carreras and M?rquez [3], the state-of-the-art results for semantic rolelabelling systems based on shallow syntactic information is about 15 lower thanthose with access to gold standard parse trees, i.e., around 60.
Our experimentalresults for the headword location condition, with no syntactic information available812 O.Y.
Kwong and B.K.
Tsouat all, give an F1 score of 52.89 and 44.35 respectively for textbook data and newsdata.
This further degradation in performance is nevertheless within expectation,but whether this is also a result of the difference between English and Chineseremains to be seen.In response to the questions raised in the introduction, firstly, the results for theknown constituent condition (F1 of 90.56 and 89.07 for textbook data and news datarespectively) have shown that even if we do not use parse-dependent features such asgoverning category and parse tree path, results are not particularly affected.
In otherwords, lexical features are already very useful as long as the constituent boundariesare given.
Secondly, in the absence of parse information, the results of identifying therelevant headwords in order to partially locate candidate constituents were not assatisfactory as one would like to see.
One possible way to improve the results, assuggested above, would be to improve the handling of ties.
Other possibilities includ-ing a class-based method could also be used, as will be discussed below.
Thirdly,results for news data degraded more seriously than textbook data from the knownconstituent condition to the headword location condition.
This suggests that complexsentences in Chinese are more affected by the availability of full parse information.To a certain extent, this might be related to the relative flexibility in the syntax-semantics interface of Chinese; hence when a sentence gets more complicated, theremight be more intervening constituents and the parse information would be useful tohelp identify the relevant ones in semantic role labelling.In terms of future development, apart from improving the handling of ties in ourmethod, as mentioned in the previous section, we plan to expand our work in severalrespects, the major part of which is on the generalization to unseen headwords andunseen predicates.
As is with other related studies, the examples available for trainingfor each target verb are very limited; and the availability of training data is also insuf-ficient in the sense that we cannot expect them to cover all target verb types.
Hence itis very important to be able to generalize the process to unseen words and predicates.To this end, we will experiment with a semantic lexicon like Tongyici Cilin (????
?, a Chinese thesaurus) in both training and testing, which we expect to improvethe overall performance.Another area of interest is to look at the behaviour of near-synonymous predicatesin the tagging process.
Many predicates may be unseen in the training data, but whilethe probability estimation could be generalized from near-synonyms as suggested by asemantic lexicon, whether the similarity and subtle differences between near-synonyms with respect to the argument structure and the corresponding syntacticrealisation could be distinguished would also be worth studying.
Related to this is thepossibility of augmenting the feature set with semantic features.
Xue and Palmer[20], for instance, looked into new features such as syntactic frame, lexicalized con-stituent type, etc., and found that enriching the feature set improved the labellingperformance.Another direction of future work is on the location of constituent boundaries uponthe identification of the headword.
As mentioned earlier on, this could probably betackled by some finite state techniques or with the help of simple chunkers.Semantic Role Tagging for Chinese at the Lexical Level 8137   ConclusionThe study reported in this paper has thus tackled the unknown constituent boundarycondition in semantic role labelling for Chinese, by attempting to locate the corre-sponding headwords first.
We experimented with both simple and complex data.Using only parse-independent features, our results on known boundary condition arecomparable to those reported in related studies.
Although the results for headwordlocation condition were not as good as state-of-the-art performance with shallowsyntactic information, we have nevertheless suggested some possible ways to improvethe results.
We have further observed that the influence of full syntactic informationis more serious for complex data than simple data, which might be a consequence ofthe characteristic syntax-semantics interface of Chinese.
As a next step, we plan toexplore some class-based techniques for the task, with reference to existingsemantic lexicons.AcknowledgementsThis work is supported by Competitive Earmarked Research Grants (CERG) of theResearch Grants Council of Hong Kong under grant Nos.
CityU1233/01H andCityU1317/03H.References1.
Baldewein, U., Erk, K., Pad?, S. and Prescher, D. (2004)  Semantic Role Labelling WithChunk Sequences.
In Proceedings of the Eighth Conference on Computational NaturalLanguage Learning (CoNLL-2004), Boston, Massachusetts, pp.98-101.2.
Baker, C.F., Fillmore, C.J.
and Lowe, J.B. (1998)  The Berkeley FrameNet Project.
InProceedings of the 36th Annual Meeting of the Association for Computational Linguisticsand the 17th International Conference on Computational Linguistics (COLING-ACL ?98),Montreal, Quebec, Canada, pp.86-90.3.
Carreras, X. and M?rquez, L. (2004)  Introduction to the CoNLL-2004 Shared Task: Se-mantic Role Labeling.
In Proceedings of the Eighth Conference on Computational Natu-ral Language Learning (CoNLL-2004), Boston, Massachusetts, pp.89-97.4.
Chen, F-Y., Tsai, P-F., Chen, K-J.
and Huang, C-R. (1999)  Sinica Treebank (????????????).
Computational Linguistics and Chinese Language Processing, 4(2):87-104.5.
Fellbaum, C., Palmer, M., Dang, H.T., Delfs, L. and Wolf, S. (2001)  Manual and Auto-matic Semantic Annotation with WordNet.
In Proceedings of the NAACL-01 SIGLEXWorkshop on WordNet and Other Lexical Resources, Invited Talk, Pittsburg, PA.6.
Gildea, D. and Jurafsky, D. (2002)  Automatic Labeling of Semantic Roles.
Computa-tional Linguistics, 28(3): 245-288.7.
Gildea, D. and Palmer, M. (2002)  The Necessity of Parsing for Predicate Argument Rec-ognition.
In Proceedings of the 40th Meeting of the Association for Computational Lin-guistics (ACL-02), Philadelphia, PA.8.
Gildea, D. and Hockenmaier, J.
(2003)  Identifying Semantic Roles Using CombinatoryCategorial Grammar.
In Proceedings of the 2003 Conference on Empirical Methods inNatural Language Processing, Sapporo, Japan.814 O.Y.
Kwong and B.K.
Tsou9.
Hacioglu, K., Pradhan, S., Ward, W., Martin, J.H.
and Jurafsky, D. (2004)  Semantic RoleLabeling by Tagging Syntactic Chunks.
In Proceedings of the Eighth Conference onComputational Natural Language Learning (CoNLL-2004), Boston, Massachusetts,pp.110-113.10.
Higgins, D. (2004)  A transformation-based approach to argument labeling.
In Proceed-ings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004), Boston, Massachusetts, pp.114-117.11.
Kingsbury, P. and Palmer, M. (2002)  From TreeBank to PropBank.
In Proceedings of theThird Conference on Language Resources and Evaluation (LREC-02), Las Palmas, Ca-nary Islands, Spain.12.
Kwon, N., Fleischman, M. and Hovy, E. (2004)  SENSEVAL Automatic Labeling of Se-mantic Roles using Maximum Entropy Models.
In Proceedings of the Third InternationalWorkshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3),Barcelona, Spain, pp.129-132.13.
Kwong, O.Y.
and Tsou, B.K.
(2003) Categorial Fluidity in Chinese and its Implicationsfor Part-of-speech Tagging.
In Proceedings of the Research Note Session of the 10th Con-ference of the European Chapter of the Association for Computational Linguistics, Buda-pest, Hungary, pp.115-118.14.
Lin, X., Wang, L. and Sun, D. (1994)  Dictionary of Verbs in Contemporary Chinese.Beijing Language and Culture University Press.15.
Litkowski, K.C.
(2004) SENSEVAL-3 Task: Automatic Labeling of Semantic Roles.
InProceedings of the Third International Workshop on the Evaluation of Systems for the Se-mantic Analysis of Text (SENSEVAL-3), Barcelona, Spain, pp.9-12.16.
Moldovan, D., Girju, R., Olteanu, M. and Fortu, O.
(2004)  SVM Classification of Frame-Net Semantic Roles.
In Proceedings of the Third International Workshop on the Evalua-tion of Systems for the Semantic Analysis of Text (SENSEVAL-3), Barcelona, Spain,pp.167-170.17.
Swier, R.S.
and Stevenson, S. (2004)  Unsupervised Semantic Role Labelling.
In Pro-ceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,Barcelona, Spain, pp.95-102.18.
Tsou, B.K., Tsoi, W.F., Lai, T.B.Y., Hu, J. and Chan, S.W.K.
(2000)  LIVAC, A ChineseSynchronous Corpus, and Some Applications.
In Proceedings of the ICCLC InternationalConference on Chinese Language Computing, Chicago, pp.
233-238.19.
Williams, K., Dozier, C. and McCulloh, A.
(2004)  Learning Transformation Rules forSemantic Role Labeling.
In Proceedings of the Eighth Conference on ComputationalNatural Language Learning (CoNLL-2004), Boston, Massachusetts, pp.134-137.20.
Xue, N. and Palmer, M. (2004)  Calibrating Features for Semantic Role Labeling.
In Pro-ceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,Barcelona, Spain, pp.88-94.21.
You, J-M. and Chen, K-J.
(2004)  Automatic Semantic Role Assignment for a Tree Struc-ture.
In Proceedings of the 3rd SigHAN Workshop on Chinese Language Processing,ACL-04, Barcelona, pp.109-115.22.
??????
Qisi Zhongguo Yuwen.
Primary 1-6, 24 volumes, 2004.
Hong Kong: KeysPress.23.
??????
Xiandai Zhongguo Yuwen.
Primary 1-6, 24 volumes, 2004.
Hong Kong:Modern Education Research Society Ltd.
