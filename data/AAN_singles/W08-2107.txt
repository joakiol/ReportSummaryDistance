CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 49?56Manchester, August 2008Picking them up and Figuring them out:Verb-Particle Constructions, Noise and IdiomaticityCarlos Ramisch?
?, Aline Villavicencio?
?, Leonardo Moura?and Marco Idiart?
?Institute of Informatics, Federal University of Rio Grande do Sul (Brazil)?GETALP Laboratory, Joseph Fourier University - Grenoble INP (France)?Department of Computer Sciences, Bath University (UK)?Institute of Physics, Federal University of Rio Grande do Sul (Brazil){ceramisch,avillavicencio,lfsmoura}@inf.ufrgs.br, idiart@if.ufrgs.brAbstractThis paper investigates, in a first stage,some methods for the automatic acquisi-tion of verb-particle constructions (VPCs)taking into account their statistical prop-erties and some regular patterns found inproductive combinations of verbs and par-ticles.
Given the limited coverage pro-vided by lexical resources, such as dictio-naries, and the constantly growing numberof VPCs, possible ways of automaticallyidentifying them are crucial for any NLPtask that requires some degree of semanticinterpretation.
In a second stage we alsostudy whether the combination of statis-tical and linguistic properties can providesome indication of the degree of idiomatic-ity of a given VPC.
The results obtainedshow that such combination can success-fully be used to detect VPCs and distin-guish idiomatic from compositional cases.1 IntroductionConsiderable investigative effort has focused onthe automatic identification of Multiword Expres-sions (MWEs), like compound nouns (science fic-tion) and phrasal verbs (carry out) (e.g.
Pearce(2002), Evert and Krenn (2005) and Zhang etal.
(2006)).
Some of them employ languageand/or type dependent linguistic knowledge forthe task, while others employ independent statis-tical methods, such as Mutual Information andLog-likelihood (e.g.
Pearce (2002) and, Zhang etal.
(2006)), or even a combination of them (e.g.c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.Baldwin (2005) and Sharoff (2004)), as basis forhelping to determine whether a given sequenceof words is in fact an MWE.
Although some re-search aims at developing methods for dealingwith MWEs in general (e.g.
Zhang et al (2006),Ramisch et al (2008)), there is also some work thatdeals with specific types of MWEs (e.g.
Pearce(2002) on collocations and Villavicencio (2005)on verb-particle constructions (VPCs)) as each ofthese MWE types has distinct distributional andlinguistic characteristics.VPCs are combinations of verbs and particles,such as take off in Our plane took off late, that dueto their complex characteristics and flexible na-ture, provide a real challenge for NLP.
In particu-lar, there is a lack of adequate resources to identifyand treat them, and those that are available provideonly limited coverage, in face of the huge numberof combinations in use.
For tasks like parsing andgeneration, it is essential to know whether a givenVPC is possible or not, to avoid for example us-ing combinations that sound unnatural or ungram-matical to native speakers (e.g.
give/lend/?grantout for the conveying of something to someone orsome place - (Fraser, 1976)).1Thus, the knowl-edge of which combinations are possible is cru-cial for precision grammar engineering.
In ad-dition, as the semantics of VPCs varies from theidiomatic to the more compositional cases, meth-ods for the automatic detection and handling of id-iomaticity are very important for any NLP task thatinvolves some degree of semantic interpretationsuch as Machine Translation (in this case avoidingthe problem of producing an unrelated translationfor a source sentence).
Automatic methods for theidentification of idiomaticity in MWEs have been1See Baldwin et al (2004) for a discussion of the effects ofmultiword expressions like VPCs on a parser?s performance.49proposed using a variety of approaches such asstatistical, substitutional, distributional, etc.
(e.g.McCarthy et al (2003), Bannard (2005) and Fa-zly and Stevenson (2006)).
In particular, Fazlyand Stevenson (2006) look at the correlation be-tween syntactic fixedness (in terms of e.g.
pas-sivisation, choice of determiner type and pluralisa-tion) and non-compositionality of verb-noun com-pounds such as shoot the breeze.In this work we investigate the automatic extrac-tion of VPCs, looking into a variety of methods,combining linguistic with statistical information,ranging from frequencies to association measures:Mutual Information (MI), ?2and Entropy.
We alsoinvestigate the determination of compositionalityof VPCs verifying whether the degree of semanticflexibility of a VPC combined with some statisti-cal information can be used to determine if it isidiomatic or compositional.This paper starts with a brief description ofVPCs, research on their automatic identificationand determination of their semantics (?
2).
We thenexplain the research questions and the assumptionsthat serve as the basis for the application of statis-tical measures (?
3) on the dataset (?
4).
Our meth-ods and experiments are then detailed (?
5), andthe results obtained are analysed (?
6).
We con-clude with a discussion of the contributions thatthis work brings to the research on verb-particleconstructions (?
7).2 Verb-Particle Constructions in Theoryand PracticeParticles in VPCs are characterised by containingfeatures of motion-through-location and of com-pletion or result in their core meaning (Bolinger,1971).
VPCs can range from idiosyncratic or semi-idiosyncratic combinations, such as get on (in e.g.Bill got on well with his new colleagues), to moreregular ones, such as tear up (e.g.
in In a rage shetore up the letter Jack gave her).
A three way clas-sification is adopted by (Deh?e, 2002) and (Jack-endoff, 2002), where a VPC can be classified ascompositional, idiomatic or aspectual, dependingon its sense.
In compositional VPCs the meaningof the construction is determined by the literal in-terpretations of the particle and the verb.
TheseVPCs usually involve particles with directional orspatial meaning, and these can often be replacedby the appropriate directional PPs (e.g.
carry inin Sheila carried the bags in/into the house Deh?e(2002)).
Idiomatic VPCs, on the other hand, can-not have their meaning determined by interpretingtheir components literally (e.g.
get on, meaning tobe on friendly terms with someone).
The third classis that of aspectual VPCs, which have the parti-cle providing the verb with an endpoint, suggestingthat the action described by the verb is performedcompletely, thoroughly or continuously (e.g.
tearup meaning to tear something into a lot of smallpieces).From a syntactic point of view, a given combi-nation can occur in several different subcategorisa-tion frames.
For example, give up can occur as anintransitive VPC (e.g.
in I give up!
Tell me the an-swer), where no other complement is required, orit may occur as a transitive VPC which requires afurther NP complement (e.g.
in She gave up alco-hol while she was pregnant ).
Since in English par-ticles tend to be homographs with prepositions (up,out, in), a verb followed by a preposition/particleand an NP can be ambiguous between a transitiveVPC and a prepositional verb (e.g.
rely on, in Herelies on his wife for everything).
Some criteriathat characterise VPCs are discussed by Bolinger(1971):2C1 In a transitive VPC the particle may come ei-ther before or after the NP (e.g.
He backedup the team vs.
He backed the team up).However, whether a particle can be separatedor not from the verb may depend on the de-gree of bonding between them, the size of theNP, and the kind of NP.
This is considered bymany to be sufficient condition for diagnos-ing a VPC, as prepositions can only appear ina position contiguous to the verb (e.g.
*Hegot the bus off ).C2 Unstressed personal pronouns must precedethe particle (e.g.
They ate it up but not *Theyate up it).C3 If the particle precedes a simple definite NP,the particle does not take the NP as its object(e.g.
in He brought along his girlfriend) un-like with PP complements or modifiers (e.g.in He slept in the hotel).
This means that inthe first example the NP is not a complementof the particle along, while in the second it is.2The distinction between a VPC and a prepositional verbmay be quite subtle, and as pointed out by Bolinger, manyof the criteria proposed for diagnosing VPCs give differentresults for the same combination, frequently including un-wanted combinations and excluding genuine VPCs.50In this paper we use the first two criteria, thereforethe candidates may contain noise (in the form ofprepositional verbs and related constructions).VPCs have been the subject of a considerableamount of interest, and some analysis has beendone on the subject of productive VPCs.
In manycases the particle seems to be compositionallyadding a specific meaning to the construction andfollowing a productive pattern (e.g.
in tear up,cut up and split up, where the verbs are seman-tically related and up adds a sense of completionto the action of these verbs).
Fraser (1976) pointsout that semantic properties of verbs can affecttheir ability to combine with particles: for exam-ple, bolt/cement/clamp/glue/paste/nail are seman-tically similar verbs where the objects representedby the verbs are used to join material, and they canall combine with down.
There is clearly a com-mon semantic thread running through this list, sothat a new verb that is semantically similar to themcan also be reasonably assumed to combine withdown.
Indeed, frequently new VPCs are formed byanalogy with existing ones, where often the verb isvaried and the particle remains (e.g.
hang on, holdon and wait on).
Similarly, particles from a givensemantic class can be replaced by other particlesfrom the same class in compositional combina-tions: send up/in/back/away (Wurmbrand, 2000).By identifying classes of verbs that follow patternssuch as these in VPCs, we can help in the identi-fication of a new unknown candidate combination,using the degree of productivity of a class to whichthe verb belongs as a back-off strategy.In terms of methods for automatic identifica-tion of VPCs from corpora, Baldwin (2005) pro-poses the extraction of VPCs with valence infor-mation from raw text, exploring a range of tech-niques (using (a) a POS tagger, (b) a chunker, (c) achunk grammar, (d) a dependency parser, and (e) acombination of all methods).
Villavicencio (2005)uses the Web as a corpus and productive patternsof combination to generate and validate candidateVPCs.
The identification of compositionality inVPCs is addressed by McCarthy et al (2003) whoexamine the overlap of similar words in an auto-matically acquired distributional thesaurus for verband VPCs, and by Bannard (2005) who uses adistributional approach to determine when and towhat extent the components of a VPC contributetheir simplex meanings to the interpretation of theVPC.
Both report a correlation between some ofthe measures and compositionality judgements.3 The Underlying HypothesesThe problem of the automatic detection and classi-fication of VPCs can be summarised as, for a givenVPC candidate, to answer to the questions:Q1 Is it a real VPC or some free combinationof verb and preposition/adverb or a preposi-tional verb?Q2 If it is a true VPC, is it idiomatic or composi-tional?In order to answer the first question, we use twoassumptions.
Firstly, we consider that the elementsof a true VPC co-occur above chance.
The greaterthe correlation between the verb and the particlethe greater the chance that the candidate is a trueVPC.
Secondly, based on criterion C1 we also as-sume that VPCs have more flexible syntax and aremore productive than non-VPCs.
This second as-sumption goes against what is usually adopted forgeneral MWEs, since it is the prepositional verbsthat allow less syntactic configurations than VPCsand are therefore more rigid (?
2).
To further dis-tinguish VPCs from prepositional verbs and otherrelated constructions we also verify the possibil-ity of the particle to be immediately followed byan indirect prepositional complement (like in Theplane took off from London), which is a good in-dicator/delimiter of a VPC since in non-VPC con-structions like prepositional verbs the prepositionneeds to have an NP complement.
Therefore, wewill assume that a true VPC occurs in the followingconfigurations, according to Villavicencio (2005)and Ramisch et al (2008):S1 VERB + PARTICLE + DELIMITER, for intran-sitive VPCs;S2 VERB + NP + PARTICLE + DELIMITER, fortransitive split VPCs and;S3 VERB + PARTICLE + NP + DELIMITER, fortransitive joint VPCs.In order to answer Q2, we look at the link be-tween productivity and compositionality and as-sume that a compositional VPC accepts the sub-stitution of one of its members by a semanticallyrelated term.
This is in accordance to Fraser(1976), who shows that semantic properties of51verbs can affect their ability to combine with par-ticles: for example verbs of hunting combiningwith the resultative down (hunt/track/trail/followdown) and verbs of cooking with the aspectual up(bake/cook/fry/broil up), forming essentially pro-ductive VPCs.
Idiomatic VPCs, however, willnot accept the substitution of one of its membersby a related term (e.g.
get and its synonyms inget/*obtain/*receive over), even if at first glancethis could seem natural.
In our experiments, wewill consider that a VPC is compositional if it ac-cepts: the replacement of the verb by a synonym,or of the preposition by another preposition.
Sum-marising our hypothesis, we get:?
For Q1: Is the candidate syntactically flexi-ble, i.e.
does it allow the configurations S1through S3??
NO: non-VPC?
YES: VPC?
For Q2: Is the candidate semantically flexi-ble, allowing the substitution of a member bya related word??
NO: idiomatic VPC?
YES: compositional VPC4 Data SourcesTo generate a gold standard, we used the Bald-win VPC candidates dataset (henceforth BaldwinCD)3, which contains 3,078 English VPC candi-dates annotated with information about idiomatic-ity (14.5% are considered idiomatic).
We fur-ther annotated this dataset with information aboutwhether each candidate is a genuine VPC or not,where a candidate is consider genuine if it be-longs to at least one of a set of machine-readabledictionaries: the Alvey Natural Language Tools(ANLT) lexicon (Carroll and Grover, 1989), theComlex lexicon (Macleod and Grishman, 1998),and the LinGO English Resource Grammar (ERG)(Copestake and Flickinger, 2000)4.
With this crite-rion 81.8% of them are considered genuine VPCs.To gather information about the candidates inthis work we employ both a fragment of 1.8Msentences from the British National Corpus (BNCBurnard (2000)) and the Web as corpora.
TheBNC fragment is used to calculate the correlation3This dataset was provided by Timothy Baldwin for theMWE2008 Workshop.4Version of November 2001.measures since they require a corpus with knownsize.
The Web is used to generate frequenciesfor the entropy measures, as discussed in ?
5.2.Web frequencies are approximated by the numberof pages containing a candidate and indexed byYahoo Search API.
In order to keep the searchesas simple and self-sufficient as possible, no addi-tional sources of information are used (Villavicen-cio, 2005).
Therefore, the frequencies are quiteconservative in the sense that by employing in-flected forms of verbs, potentially much more evi-dence could be gathered.For the generation of semantic variational pat-terns, we use both Wordnet 3.0 (Fellbaum, 1998)and Levin?s English Verb Classes and Alternations(Levin, 1993).
Wordnet is organised as a graph ofconcepts, called synsets, linked by relations of syn-onymy, hyponymy, etc.
Each synset contains a listof words that represent the concept.
The verbs ina synset and its synonym synsets are used to gen-erate variations of a VPC candidate.
Likewise weuse Levin?s classes, which define 190 fine-grainedclasses for English verbs, based on their syntacticand semantic features.It is important to highlight that the generationof the semantic variations strongly relies on theseresources.
Therefore, cross-language extensionwould depend on the availability of similar toolsfor the target language.5 Carrying out the experimentsOur experiments are composed of two stages, eachone consisting of three steps (corresponding to thenext three sections).
The first stage filters out ev-ery candidate that is evaluated as not being a VPC,while the second one intends to identify the id-iomatic VPCs among the remaining candidates ofthe previous stage.5.1 Generating candidatesFor each of the 3,078 items in the Baldwin CD wegenerated 2 sets of variations, syntactic and seman-tic, and we will refer to these as alternative formsor variations of a candidate.The syntactic variations are generated using thepatterns S1 to S3 described in section 3.
Followingthe work of Villavicencio (2005) 3 frequently usedprepositions for, from and with are used as delim-iters and we search for NPs in the form of pronounslike this and definite NPs like the boy.
The use ofalternative search patterns also helps to give an in-52dication about the syntactic distribution of a can-didate VPC, and consequently if it has a preferredsyntactic realisation.
For instance, for eat up andthe delimiter with, we propose a list of Web searchqueries for its respective variations vi, shown withtheir corresponding Web frequencies in table 1.5Variation (vi) Frequency (nY ahoo(vi))eat up with 49200eat the * up with 2240eat this up with 1120eat up the * with 3110Table 1: Distribution of syntactic variations for thecandidate eat up.For the semantic variations, in order to capturethe idiomaticity of VPCs we generate the alterna-tive forms by replacing the verb by its synonymverbs as follows:WNS Wordnet Strict variations.
When using Word-net, we consider any verb that belongs to thesame synset of the candidate as a synonym.WNL Wordnet Loose variations.
This is an indi-rect synonymy relation capturing any verbin Wordnet that belongs either to the samesynset or to a synset that is synonym of thesynset in which the candidate verb is con-tained.Levin These include all verbs in the same Levinclass as the candidate.Multiword synonyms are ignored in this step toavoid noisy search patterns, (e.g.
*eat up up).
Theexamples for these variations are shown in table 2for the candidate act in.Wordnet and Levin are considered ambiguousresources because one verb is potentially containedin several synsets or classes.
However, as WordSense Disambiguation is not within the scope ofthis work we employ some heuristics to select agiven sense for the candidate verb.
In order to testthe effect of frequency, the first heuristic adopts thefirst synset in the list, as Wordnet organises synsetsin descending order of frequency (denoted as first).To study the influence of the number of synonyms,the second and third heuristics use respectively thebiggest (max) and smallest (min) synsets.
The last5The Yahoo wildcard used in these searches matches anyword occurring in that particular position.Variation (vi) Source nY ahoo(vi)act in ?
2690playact in WNS 0play in WNS 167000behave in WNL 98do in WNL 24600pose in Levin 1610qualify in Levin 358rank in Levin 706rate in Levin 16700serve in Levin 2240Table 2: Distribution of syntactic variations for thecandidate eat up.heuristic is the union of all synonyms (all).
Theseheuristics are indicated using a subscript notation,where e.g.
WNSallsymbolizes the WNS varia-tions set using the union of all synsets as disam-biguation heuristic.
Finally, we generated twoadditional sets of candidates by replacing the par-ticle by one of the 48 prepositions listed in theANLT dictionary (prep) and also by one of 9 cho-sen locative prepositions (loc-prep).
It is impor-tant to also verify possible variations of the prepo-sition because compositional VPCs combine pro-ductively with one or more groups of particles, e.g.locatives, and present consequently a wider prob-ability distribution among the variations, while anidiomatic VPC presents a higher frequency for achosen preposition.5.2 Working the statistical measures outThe classifications of the candidate VPCs are doneusing a set of measures: the frequencies of theVPC candidates and of their individual words,their Mutual Information (MI), ?2and Entropies.We calculate the MI and ?2indices of a candidateformed by a verb and a particle based on their in-dividual frequencies and on their co-occurrence inthe BNC fragment.The Entropy measure is given byH(V ) = ?n?i=1p(vi) ln [ p(vi) ]wherep(vi) =n(vi)??
vj?Vn(vj)is the probability of the variation vito occuramong the set of all possible variations V =53H(V ) ?
0.001081nBNC(p) ?
51611nY ahoo(vtransitive) ?
1nY ahoo(v) ?
2020000000 : yesnY ahoo(v) > 2020000000?2?
25.99?
?
?Figure 1: Fragment of the decision tree that filtersout non-VPCs.
{v1, v2, .
.
.
, vn}, and n(vi) is the Web frequencyfor the variation vi.The entropy of a probability distribution givesus some clues about its shape.
A very low en-tropy is a sign of a heterogeneous distribution thatcontains a peak.
On the other hand, a distributionthat presents uniformity will lead to a high entropyvalue.The interest of H(V ) for the detection of VPCsis in that true instances are more likely to not prefera canonical form, more widely distributing proba-bilities over all alternative syntactic frames (S1 toS3), while non-VPCs are more likely to choose oneframe and present low frequencies for the proposedvariations.For the semantic variations, the entropy is cal-culated from a set V of variations generated by theWordnet synset, Levin class and preposition sub-stitutions described in ?
5.1.
The interpretation ofthe entropy at this point is that high entropy indi-cates compositionality while low entropy indicatesidiomaticity, since compositional VPCs are moreproductive and distribute well over a class of verbsor a class of prepositions and idiomatic VPCs pre-fer a specific verb or preposition.5.3 Bringing estimations togetherOnce we got a set of measures to predictVPCs and another to predict their idiomatic-ity/compositionality, we would like to know whichmeasures are useful.
Therefore, we combine ourmeasures automatically by building a decision treewith the J48 algorithm, a version of the traditionalentropy-based C4.5 algorithm implemented in theWeka package.66 Weighting the results upThe first stage of our experiments applied to the3,078 VPC candidates generated a decision tree us-6http://www.cs.waikato.ac.nz/ml/weka/ing 10-fold cross validation that is partially repro-duced in figure 1.
From these, 2,848 candidateswere considered genuine VPCs, with 2,419 truepositives, 100 false negatives and 429 false posi-tives.
This leads to a recall of 96% of the VPCsbeing kept in the list with a precision of 84.9%,and an f-measure of 90.1%.
We interpret this as avery positive result since although some false neg-atives have been filtered out, the remaining candi-dates are now less noisy.Figure 1 shows that the entropy of the variationsis the best predictor since it is at the root of thetree.
We can also see that there are several typesof raw frequencies being used before a correlationmeasure appears (?2).
We can conclude that thefrequency of each transitive, intransitive and splitconfigurations are also good predictors to detectfalse from true VPCs.
At this point, MI does notseem to contribute to the classification task.For our second stage, we generated Wordnetsynonym, Levin class and preposition variationsfor a list of the 2,867 VPC candidates classifiedas genuine cases.
We also took into account theproportion of synonyms that are MWEs (vpc-syn)and the proportion of synonyms that contain thecandidate itself (self-syn).In order to know what kind of contribution eachmeasure gives to the construction of the decisiontree, we used a simple iterative algorithm that con-structs the set U of useful attributes.
It first ini-tialises U with all attributes, then calculates theprecision for each class (yes and no)7on a crossvalidation using all attributes in U .
For each at-tribute a ?
U , it ignores a and recalculates preci-sions.
If both precisions decrease, the contributionof a is positive, if both increase then a is negative,else its contribution remains unknown.
All fea-tures that contribute negatively are removed fromU , and the algorithm is repeated until there is nonegative attribute left.The step-by-step execution of the algorithmcan be observed in table 3, where the inconclu-sive steps are hidden.
We found out that theoptimal features are U?= {self-syn, H(prep),H(Levinfirst), H(WNSfirst), H(WNSmin),H(Levinmax), H(Levinmin).}
The self-syn in-formation seems to be very important, as withoutit precisions of both classes decrease considerably7We use the precision as a quality estimator since it givesa good idea of the amount of work that a grammar engineeror lexicographer must perform in order to clear the list fromfalse positives.54Precision# Ignored No Yes +/?1stiteration0 ?
86.6% 54.9%1 vpc-syn 86.7% 56.6% ?2 self-syn 85.2% 28.7% +4 H(loc-prep) 86.7% 56.1% ?6 H(WNSmax) 87.5% 57.4% ?9 H(WNLfirst) 86.7% 57.9% ?10 H(WNLmax) 86.7% 57.8% ?11 H(WNLmin) 86.9% 57.6% ?16 H(Levinall) 86.7% 55.1% ?2nditeration17 ?
87.7% 60.3%18 H(prep) 87.6% 59.2% +21 H(WNSall) 87.8% 61.6% ?22 H(WNLall) 87.8% 61.0% ?23 H(Levinfirst) 87.5% 60.2% +3rditeration26 ?
87.8% 61.9%27 H(WNSfirst) 87.8% 61.9% ?28 H(WNSmin) 87.7% 61.1% +29 H(Levinmax) 87.8% 61.6 ?30 H(Levinmin) 87.7% 61.5% +Table 3: Iterative attributes selection process.
Pre-cision in each class is used as quality estimator.
(experiment #2).All entropies of the WNL heuristics are of littleor no utility.
This could probably be explained byeither the choice of simple WSD heuristics for se-lecting synsets, or because the indirect synonymyinformation is too far related to the original verb tobe used in variational patterns.
Inspecting the gen-erated variations, we notice that most of the syn-onym synsets are related to secondary senses orvery specific uses of a verb and are thus not cor-rectly disambiguated.In what concerns the WNS sets, only the small-est and first synset were kept, suggesting again thatit may not be a good idea to maximise the syn-onyms set and for future work, we intent to es-tablish a threshold for a synset to be taken intoaccount.
In addition, we can also infer a posi-tive contribution of the frequency of a sense withthe choice of the first synset returned by Word-net resulting in a reasonable WSD heuristic (whichis compatible with the results by McCarthy et al(2004)).On the other hand, the algorithm selected thefirst, the smallest and the biggest of the Levin?ssets.
This probably happens because the major-ity of these verbs belongs only to one or two, butnever to a great number of classes.
Since the gran-ularity of the classes is coarser than for synsets,the heuristics often offer four equal or very closeentropies and thus redundant information.
As anoverall result, the last iteration shown in table 3indicates a precision of 61.9% for the classifier indetecting idiomatic VPCs, that is to say that we au-tomatically retrieved 176 VPCs where 67 are falsepositives and 109 are truly idiomatic.
This value isa quality estimator for the resulting VPCs that willpotentially be used in the construction of a lexi-con.
Recall of idiomatic VPCs goes from 16.7%to 24.9%.7 ConclusionsOne of the important challenges for robust natu-ral language processing systems is to be able tosuccessfully deal with Multiword Expressions andrelated constructions.
We investigated the identifi-cation of VPCs using a combination of statisticalmethods and linguistic information, and whetherthere is a correlation between the productivity ofVPCs and their semantics that could help us detectif a VPC is idiomatic or compositional.The results confirm that the use of statisticaland linguistic information to automatically iden-tify verb-particle constructions presents a reason-able way of improving coverage of existing lexi-cal resources in a very simple and straightforwardmanner.
In terms of grammar engineering, the in-formation about compositional candidates belong-ing to productive classes provides us with the ba-sis for constructing a family of fine-grained redun-dancy rules for these classes.
These rules are ap-plied in a constrained way to verbs already in thelexicon, according to their semantic classes.
TheVPCs identified as idiomatic, on the other hand,need to be explicitly added to the lexicon, aftertheir semantic is determined.
This study can alsobe complemented with the results of investigationsinto the semantics of VPCs, as discussed by bothBannard (2005) and McCarthy et al (2003).In addition, the use of clustering methods is aninteresting possibility for automatically identify-ing clusters of productive classes of both verbs andof particles that combine well together.55AcknowledgmentsThis research was partly supported by the CNPqresearch project Recuperac?
?ao de Informac??oesMultil?
?ng?ues (CNPq Universal 484585/2007-0).ReferencesBaldwin, Timothy, Emily M. Bender, Dan Flickinger, AraKim, and Stephan Oepen.
2004.
Road-testing the EnglishResource Grammar over the British National Corpus.
InFourth International Conference on Language Resourcesand Evaluation (LREC 2004), Lisbon, Portugal.Baldwin, Timothy.
2005.
Deep lexical acquisition of verb-particle constructions.
Computer Speech and Language,19(4):398?414.Bannard, Colin J.
2005.
Learning about the meaning of verb-particle constructions from corpora.
Computer Speech andLanguage, 19(4):467?478.Bolinger, Dwight.
1971.
The phrasal verb in English.
Har-vard University Press, Harvard, USA.Burnard, Lou.
2000.
User reference guide for the British Na-tional Corpus.
Technical report, Oxford University Com-puting Services.Carroll, John and Claire Grover.
1989.
The derivation of alarge computational lexicon of English from LDOCE.
InBoguraev, B. and E. Briscoe, editors, Computational Lexi-cography for Natural Language Processing.
Longman.Copestake, Ann and Dan Flickinger.
2000.
An open-sourcegrammar development environment and broad-coverageEnglish grammar using HPSG.
In Proceedings of the2nd International Conference on Language Resources andEvaluation (LREC 2000).Deh?e, Nicole.
2002.
Particle verbs in English: syntax, in-formation structure and intonation.
John Benjamins, Am-sterdam/Philadelphia.Evert, Stefan and Brigitte Krenn.
2005.
Using small randomsamples for the manual evaluation of statistical associationmeasures.
Computer Speech and Language, 19(4):450?466.Fazly, Afsaneh and Suzanne Stevenson.
2006.
Automaticallyconstructing a lexicon of verb phrase idiomatic combina-tions.
In EACL.
The Association for Computer Linguis-tics.Fellbaum, Christiane, editor.
1998.
WordNet: An ElectronicLexical Database (Language, Speech, and Communica-tion).
The MIT Press, May.Fraser, Bruce.
1976.
The Verb-Particle Combination in En-glish.
Academic Press, New York, USA.Jackendoff, Ray.
2002.
English particle constructions, thelexicon, and the autonomy of syntax.
In N. Deh?e, R. Jack-endoff, A. McIntyre and S. Urban, editors, Verb-ParticleExplorations.
Berlin: Mouton de Gruyter.Levin, Beth.
1993.
English Verb Classes and Alternations:a preliminary investigation.
University of Chicago Press,Chicago and London.Macleod, Catherine and Ralph Grishman.
1998.
Comlex syn-tax reference manual, Proteus Project.McCarthy, Diana, Bill Keller, and John Carroll.
2003.
De-tecting a continuum of compositionality in phrasal verbs.In Proceedings of the ACL 2003 workshop on Multiwordexpressions, pages 73?80, Morristown, NJ, USA.
Associ-ation for Computational Linguistics.McCarthy, Diana, Rob Koeling, Julie Weeds, and John Car-roll.
2004.
Finding predominant word senses in untaggedtext.
In Proceedings of the 42nd Annual Meeting on Asso-ciation for Computational Linguistics, page 279.
Associa-tion for Computational Linguistics.Pearce, Darren.
2002.
A comparative evaluation of colloca-tion extraction techniques.
In Third International Confer-ence on Language Resources and Evaluation, Las Palmas,Canary Islands, Spain.Ramisch, Carlos, Paulo Schreiner, Marco Idiart, and AlineVillavicencio.
2008.
An evaluation of methods for the ex-traction of multiword expressions.
In Proceedings of theLREC Workshop - Towards a Shared Task for MultiwordExpressions (MWE 2008), pages 50?53, Marrakech, Mo-rocco, June.Sharoff, Serge.
2004.
What is at stake: a case study of rus-sian expressions starting with a preposition.
pages 17?23,Barcelona, Spain.Villavicencio, Aline.
2005.
The availability of verb-particleconstructions in lexical resources: How much is enough?Journal of Computer Speech and Language Processing,19(4):415?432.Wurmbrand, S. 2000.
The structure(s) of particle verbs.
Ms.,McGill University.Zhang, Yi, Valia Kordoni, Aline Villavicencio, and MarcoIdiart.
2006.
Automated multiword expression predictionfor grammar engineering.
In Proceedings of the Workshopon Multiword Expressions: Identifying and Exploiting Un-derlying Properties, pages 36?44, Sydney, Australia.
As-sociation for Computational Linguistics.56
