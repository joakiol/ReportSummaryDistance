Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 257?262,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsDisfluency Detection with a Semi-Markov Model and Prosodic FeaturesJames Ferguson, Greg Durrett and Dan KleinComputer Science DivisionUniversity of California, Berkeley{jferguson,gdurrett,klein}@berkeley.eduAbstractWe present a discriminative model for de-tecting disfluencies in spoken language tran-scripts.
Structurally, our model is a semi-Markov conditional random field with featurestargeting characteristics unique to speech re-pairs.
This gives a significant performanceimprovement over standard chain-structuredCRFs that have been employed in past work.We then incorporate prosodic features oversilences and relative word duration into oursemi-CRF model, resulting in further perfor-mance gains; moreover, these features are noteasily replaced by discrete prosodic indica-tors such as ToBI breaks.
Our final sys-tem, the semi-CRF with prosodic information,achieves an F-score of 85.4, which is 1.3 F1better than the best prior reported F-score onthis dataset.1 IntroductionSpoken language is fundamentally different fromwritten language in that it contains frequent disflu-encies, or parts of an utterance that are correctedby the speaker.
Removing these disfluencies is de-sirable in order to clean the input for use in down-stream NLP tasks.
However, automatically identify-ing disfluencies is challenging for a number of rea-sons.
First, disfluencies are a syntactic phenomenon,but defy standard context-free parsing models dueto their parallel substructures (Johnson and Char-niak, 2004), causing researchers to employ otherapproaches such as pipelines of sequence models(Qian and Liu, 2013) or incremental syntactic sys-tems (Honnibal and Johnson, 2014).
Second, hu-man processing of spoken language is complex andmixes acoustic and syntactic indicators (Cutler et al,1997), so an automatic system must employ fea-tures targeting all levels of the perceptual stack toin  the    upper     school                          upper  four   gradesFluent Fluent DisfluentReparandum  RepairFigure 1: Example of a disfluency where the speakercorrected upper school.
Our model considers both tran-scribed text and the acoustic signal and predicts disfluen-cies as complete chunks using a semi-Markov conditionalrandom field.achieve high performance.
In spite of this, the pri-mary thread of work in the NLP community has fo-cused on identifying disfluencies based only on lex-icosyntactic cues (Heeman and Allen, 1994; Char-niak and Johnson, 2001; Snover et al, 2004; Ra-sooli and Tetreault, 2013).
A separate line of workhas therefore attempted to build systems that lever-age prosody as well as lexical information (Shriberget al, 1997; Liu et al, 2003; Kim et al, 2004; Liu etal., 2006), though often with mixed success.In this work, we present a model for disfluencydetection that improves upon model structures usedin past work and leverages additional prosodic in-formation.
Our model is a semi-Markov conditionalrandom field that distinguishes disfluent chunks (tobe deleted) from fluent chunks (everything else), asshown in Figure 1.
By making chunk-level predic-tions, we can incorporate not only standard token-level features but also features that can consider theentire reparandum and the start of the repair, en-abling our model to easily capture parallelism be-tween these two parts of the utterance.1This frame-1The reparandum and repair are important concepts that wewill refer to in this paper, but the model does not distinguish therepair from other fluent text which follows.257work also enables novel prosodic features that com-pute pauses and word duration based on alignmentsto the speech signal itself, allowing the model to cap-ture acoustic cues like pauses and hesitations thathave proven useful for disfluency detection in ear-lier work (Shriberg et al, 1997).
Such informa-tion has been exploited by NLP systems in the pastvia ToBI break indices (Silverman et al, 1992), amid-level prosodic abstraction that might be indica-tive of disfluencies.
These have been incorporatedinto syntactic parsers with some success (Kahn etal., 2005; Dreyer and Shafran, 2007; Huang andHarper, 2010), but we find that using features onpredicted breaks is ineffective compared to directlyusing acoustic indicators.Our implementation of a baseline CRF model al-ready achieves results comparable to those of a high-performance system based on pipelined inference(Qian and Liu, 2013).
Our semi-CRF with span fea-tures improves on this, and adding prosodic indica-tors gives additional gains.
Our final system gets anF-score of 85.4, which is 1.3 F1better than the bestprior reported F-score on this dataset (Honnibal andJohnson, 2014).2 Experimental SetupThroughout this work, we make use of the Switch-board corpus using the train/test splits specified byJohnson and Charniak (2004) and used in otherwork.
We use the provided transcripts and goldalignments between the text and the speech signal.We follow the same preprocessing regimen as pastwork: we remove partial words, punctuation, andcapitalization to make the input more realistic.2Fi-nally, we use predicted POS tags from the Berkeleyparser (Petrov et al, 2006) trained on Switchboard.3 ModelPast work on disfluency detection has employedCRFs to predict disfluencies using a IOBES tag set(Qian and Liu, 2013).
An example of this is shownin Figure 2.
One major shortcoming of this model isthat beginning and ending of a disfluency are not de-cided jointly: because features in the CRF are local2As described in Honnibal and Johnson (2014), we com-puted features over sentences with filler words (um and uh) andthe phrases I mean and you know removed.to emissions and transitions, features in this modelcannot recognize that a proposed disfluency beginswith upper and ends before another occurrence ofupper (see Figure 1).
Identifying instances of thisparallelism is key to accurately predicting disflu-encies.
Past work has captured information aboutrepeats using token-level features (Qian and Liu,2013), but these still apply to either the beginningor ending of a disfluency in isolation.
Such featuresare naturally less effective on longer disfluencies aswell, and roughly 15% of tokens occurring in disflu-encies are in disfluencies of length 5 or greater.
Thepresence of these longer disfluencies suggests usinga more powerful semi-CRF model as we describe inthe next section.3.1 Semi-CRF ModelThe model that we propose in this work is a semi-Markov conditional random field (Sarawagi and Co-hen, 2004).
Given a sentence x = (x1, .
.
.
, xn)the model considers sequences of labeled spanss?
= ((`1, b1, e1), (`2, b2, e2), .
.
.
, (`k, bk, ek)),where `i?
{Fluent,Disfluent} is a label for eachspan and bi, ei?
{0, 1 .
.
.
n} are fenceposts for eachspan such that bi< eiand ei= bi+1.
The modelplaces distributions over these sequences given thesentence as follows:p?
(s?|x) ?
exp(?>k?i=1f(x, (`i, bi, ei)))(1)where f is a feature function that computes featuresfor a span given the input sentence.
In our model weconstrain the transitions so that fluent spans can onlybe followed by disfluent spans.
For this task, thespans we are predicting correspond directly to thereparanda of disfluencies, since these are the partsof the input sentences that should be removed.
Notethat our feature function can jointly inspect both thebeginning and ending of the disfluency; we will de-scribe the features of this form more specifically inSection 3.2.2.To train our model, we maximize conditionallog likelihood of the training data augmented witha loss function via softmax-margin (Gimpel andSmith, 2010).
Specifically, during training, we max-imize L(?)
=?di=1log p??
(s?|x), where p??
(s?|x) =p?
(s?|x) exp (`(s?, s??)).
We take the loss function258to determine  how  you address  how  you weigh?TO       VB       WRB  PRP    VBP     WRB  PRP  VBPO        O           B       I        E         O     O      OUnigrams: determine, how, youBigrams: (determine, how), (how, you)POS Unigrams: VB, WRB, PRPPOS Bigrams: (VB, WRB), (WRB, PRP)Distance: 3Word+Distance: (3, how)POS Bigram: (WRB, PRP)DuplicateFigure 2: Token features for CRF and semi-CRF models.` to be token-level asymmetric Hamming distance(where the output is viewed as binary edited/non-edited).
We optimize with the AdaGrad algorithmof Duchi et al (2011) with L2regularization.3.2 FeaturesFeatures in our semi-CRF factor over spans, whichcover the reparandum of a proposed disfluency,and thus generally end at the beginning of the re-pair.
This means that they can look at informationthroughout the reparandum as well as the repair bylooking at content following the span.
Many of ourfeatures are inspired by those in Qian and Liu (2013)and Honnibal and Johnson (2014).
We use a combi-nation of features that are fired for each token withina span, and features that consider properties of thespan as a whole.3.2.1 Token FeaturesFigure 2 depicts the token-level word featureswe employ in both our basic CRF and our semi-CRF models.
Similar to standard sequence model-ing tasks, we fire word and predicted part-of-speechunigrams and bigrams in a window around the cur-rent token.
In addition, we fire features on repeatedwords and part-of-speech tags in order to capture thefact that the repair is typically a partial copy of thereparandum, with possibly a word or two switchedout.
Specifically, we fire features on the distanceto any duplicate words or parts-of-speech in a win-dow around the current token, conjoined with theFluent                    Disfluent                        Fluentto determine how you address  how you weigh?Surrounding POS: (VB, WRB)?
?Ending POS: (VBP, WRB)?
?Beginning POS: (VB, WRB)?
?Word duplicate length: 2POS duplicate length: 3TO       VB      WRB PRP   VBP     WRB PRP  VBPFigure 3: Span features for semi-CRF model.word identity itself or its POS tag (see the Dupli-cate box in Figure 2).
We also fire similar featuresfor POS tags since substituted words in the repairfrequently have the same tag (compare address andweigh).
Finally, we include a duplicate bigram fea-ture that fires if the bigram formed from the currentand next words is repeated later on.
When this hap-pens, we fire an indicator for the POS tags of thebigram.
In Figure 2, this feature is fired for the wordhow because how you is repeated later on, and con-tains the POS tag bigram (WRB, PRP).Table 1 shows the results for using these featuresin a CRF model run on the development set.33.2.2 Span FeaturesIn addition to features that fire for each individualtoken, the semi-CRF model allows for the inclusionof features that look at characteristics of the pro-posed span as a whole, allowing us to consider therepair directly by firing features targeting the wordsfollowing the span.
These are shown in Figure 3.Critically, repeated sequences of words and parts-of-speech are now featurized in a coordinated way,making it less likely that spurious repeated contentwill cause the model to falsely posit a disfluency.We first fire an indicator of whether or not the en-tire proposed span is later repeated, conjoined withthe length of the span.
Because many disfluencies3We created our development set by randomly samplingdocuments from the training set.
Compared to the developmentset of Johnson and Charniak (2004), this more closely matchesthe disfluency distribution of the corpus: their development sethas 0.53 disfluent tokens per sentence, while our set has 0.38per sentence, and the training set has 0.37 per sentence.259Prec.
Rec.
F1CRF 84.0 82.1 83.0Semi-CRF 88.6 81.7 85.0Semi-CRF + Prosody 89.5 82.7 86.0Table 1: Disfluency results on the development set.Adding span features on top of a CRF baseline im-proves performance, and including raw acoustic informa-tion gives further performance gains.are just repeated phrases, and longer phrases aregenerally not repeated verbatim in fluent language,this feature is a strong indicator of disfluencies whenit fires on longer spans.
For similar reasons, we firefeatures for the length of the longest repeated se-quences of words and POS tags (the bottom box inFigure 3).
In addition to general repeated words, wefire a separate feature for the number of uncommonwords (appearing less than 50 times in the trainingdata) contained in the span that are repeated later inthe sentence; consider upper from Figure 1, whichwould be unlikely to be repeated on its own as com-pared to stopwords.
Lastly, we include features onthe POS tag bigrams surrounding each span bound-ary (top of Figure 3), as well as the bigram formedfrom the POS tags immediately before and after thespan.
These features aim to capture the idea thata disfluency is a mistake with a disjuncture beforethe repair, so the ending bigram will generally notbe a commonly seen fluent pair, and the POS tagssurrounding the reparandum should be fluent if thereparandum were removed.Table 1 shows that the additional features enabledby the CRF significantly improve performance ontop of the basic CRF model.4 Exploiting Acoustic InformationSection 3 discussed a primarily structural improve-ment to disfluency detection.
Henceforth, we willuse the semi-CRF model exclusively and discusstwo methods of incorporating acoustic duration in-formation that might be predictive of disfluencies.Our results will show that features targeting rawacoustic properties of the signal (Section 4.1) arequite effective, while using ToBI breaks as a discreteindicator to import the same information does notgive benefits (Section 4.2)Pause: 1313msLong; 2.5x average duration for ofthat   kind  of                                     to   me      it    is     moreFigure 4: Raw acoustic features.
The combination of along pause and considerably longer than average durationfor of is a strong indicator of a disfluency.4.1 Raw Acoustic FeaturesThe first way we implemented this information wasin the form of raw prosodic features related to pausesbetween words and word duration.
To computethese features, we make use of the alignment be-tween the speech signal and the raw text.
Pauses arethen simply identified by looking for pairs of wordswhose alignments are not flush.
The specific fea-tures used are indicators of the existence of a pauseimmediately before or after a span, and the totalnumber of pauses contained within a span.
Wordduration is computed based on the deviation of aword?s length from its average length averaged overall occurrences in the corpus.4We fire duration fea-tures similar to the pause features, namely indicatorsof whether the duration of the first and last words ina span deviate beyond some threshold from the aver-age, and the total number of such deviations withina span.
As displayed in Table 1, adding these rawfeatures results in improved performance on top ofthe gains from the semi-CRF model.4.2 ToBI FeaturesIn addition to the raw acoustic features, we alsotried utilizing discrete indicators of acoustic infor-mation, specifically ToBI break indices (Silvermanet al, 1992).
Previous work has shown perfor-mance improvements resulting from the use of suchdiscrete information in other tasks, such as pars-ing (Kahn et al, 2005; Dreyer and Shafran, 2007;Huang and Harper, 2010).
We chose to focus specif-ically on ToBI breaks rather than on ToBI tones be-cause tonal information has appeared relatively less4Note that this averages over multiple speakers as well.260DisfluencyPrec.
Rec.
F1Baseline 88.61 81.69 85.01AuToBI 3, 4 88.46 81.92 85.06CRF ToBI 88.42 81.96 85.07Raw acoustic 89.53 82.74 86.00Table 2: Disfluency results with predicted ToBI fea-tures on the development set.
We compare our baselinesemi-CRF system (Baseline) with systems that incorpo-rate prosody via predictions from the AuToBI system ofRosenberg (2010) and from our CRF ToBI predictor, aswell as the full system using raw acoustic features.useful for this task (Shriberg et al, 1997).
More-over, the ToBI break specification (Hirschberg andBeckman, 1992) stipulates a category for strong dis-juncture with a pause (2) as well as a pause marker(p), both of which correlate well with disfluencieson gold-annotated ToBI data.To investigate whether this correlation translatesinto a performance improvement for a disfluency de-tection system like ours, we add features targetingToBI annotations as follows: for each word in a pro-posed disfluent span, we fire a feature indicating thebreak index on the fencepost following that word,conjoined with where that word is in the span (be-ginning, middle, or end).We try two different ways of generating the breakindices used by these features.
The first is usingthe AuToBI system of Rosenberg (2010), a state-of-the-art automatic ToBI prediction systems based onacoustic information which focuses particularly ondetecting occurrences of 3 and 4.
Second, we usethe subset of Switchboard labeled with ToBI breaks(Taylor et al, 2003) to train a CRF-based ToBI pre-dictor.
This model employs both acoustic and lexi-cal features, which are both useful for ToBI predic-tion despite breaks being a seemingly more acousticphenomenon (Rosenberg, 2010).
The acoustic indi-cators that we use are similar to the ones describedin Section 4 and our lexical features consist of a setof standard surface features similar to those used inSection 3.2.1.In Table 2 we see that neither source of predictedToBI breaks does much to improve performance.
Inparticular, the gains from using raw acoustic featuresare substantially greater despite the fact that the pre-Prec.
Rec.
F1Johnson and Charniak (2004) ?
?
79.7Qian and Liu (2013) ?
?
83.7Honnibal and Johnson (2014) ?
?
84.1CRF 88.7 78.8 83.4Semi-CRF 90.1 80.0 84.8Semi-CRF + Prosody 90.0 81.2 85.4Table 3: Disfluency prediction results on the test set; ourbase system outperforms that of Honnibal and Johnson(2014), a state-of-the-art system on this dataset, and in-corporating prosody further improves performance.dictions were made in part using similar raw acous-tic features.
This is somewhat surprising, since in-tuitively, ToBI should be capturing information verysimilar to what pauses and word durations capture,particularly when it is predicted based partially onthese phenomena.
However, our learned ToBI pre-dictor only gets roughly 50 F1on break prediction,so ToBI prediction is clearly a hard task even withsophisticated features.
The fact that ToBI cannotbe derived from acoustic features also indicates thatit may draw on information posterior to signal pro-cessing, such as syntactic and semantic cues.
Fi-nally, pauses are also simply more prevalent in thedata than ToBI markers of interest: there are roughly40,000 pauses on the ToBI-annotated subset of thedataset, yet there are fewer than 10,000 2 or p breakindices.
The ToBI predictor is therefore trained toignore information that may be relevant for disflu-ency detection.5 Results and ConclusionTable 3 shows results on the Switchboard test set.Our final system substantially outperforms the re-sults of prior work, and we see that this is a resultof both incorporating span features via a semi-CRFas well as incorporating prosodic indicators.AcknowledgmentsThis work was partially supported by BBN underDARPA contract HR0011-12-C-0014 and by a Face-book Fellowship for the second author.
Thanksto the anonymous reviewers for their helpful com-ments.261ReferencesEugene Charniak and Mark Johnson.
2001.
Edit Detec-tion and Parsing for Transcribed Speech.
In Proceed-ings of the North American Chapter of the Associationfor Computational Linguistics.Anne Cutler, Delphine Dahan, and Wilma van Donselaar.1997.
Prosody in the Comprehension of Spoken Lan-guage: A Literature Review.
Language and Speech,40(2):141?201.Markus Dreyer and Izhak Shafran.
2007.
ExploitingProsody for PCFGs with Latent Annotations.
In Pro-ceedings of Interspeech.John Duchi, Elad Hazan, and Yoram Singer.
2011.Adaptive Subgradient Methods for Online Learningand Stochastic Optimization.
Journal of MachineLearning Research, 12:2121?2159, July.Kevin Gimpel and Noah A. Smith.
2010.
Softmax-Margin CRFs: Training Log-Linear Models with CostFunctions.
In Proceedings of the North AmericanChapter for the Association for Computational Lin-guistics.Peter Heeman and James Allen.
1994.
Detecting andCorrecting Speech Repairs.
In Proceedings of the As-sociation for Computational Linguistics.Julia Hirschberg and Mary E. Beckman.
1992.The tobi annotation conventions.
Online athttp://www.cs.columbia.edu/ julia/files/conv.pdf.Matthew Honnibal and Mark Johnson.
2014.
Joint Incre-mental Disfluency Detection and Dependency Parsing.Transactions of the Association of Computational Lin-guistics ?
Volume 2, Issue 1, pages 131?142.Zhongqiang Huang and Mary Harper.
2010.
Appropri-ately Handled Prosodic Breaks Help PCFG Parsing.In Proceedings of the North American Chapter of theAssociation for Computational Linguistics.Mark Johnson and Eugene Charniak.
2004.
A TAG-based Noisy-channel Model of Speech Repairs.
InProceedings of the Association for Computational Lin-guistics.Jeremy G. Kahn, Matthew Lease, Eugene Charniak,Mark Johnson, and Mari Ostendorf.
2005.
EffectiveUse of Prosody in Parsing Conversational Speech.
InProceedings of the Conference on Empirical Methodsin Natural Language Processing.Joungbum Kim, Sarah E Schwarm, and Mari Ostendorf.2004.
Detecting Structural Metadata with DecisionTrees and Transformation-Based Learning.
In Pro-ceedings of the North American Chapter of the Asso-ciation for Computational Linguistics.Yang Liu, Elizabeth Shriberg, and Andreas Stolcke.2003.
Automatic Disfluency Identification in Conver-sational Speech Using Multiple Knowledge Sources.In Proceedings of Eurospeech.Yang Liu, E. Shriberg, A. Stolcke, D. Hillard, M. Osten-dorf, and M. Harper.
2006.
Enriching Speech Recog-nition with Automatic Detection of Sentence Bound-aries and Disfluencies.
Transactions of Audio, Speechand Language Processing, 14(5):1526?1540, Septem-ber.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning Accurate, Compact, and Inter-pretable Tree Annotation.
In Proceedings of the Con-ference on Computational Linguistics and the Associ-ation for Computational Linguistics.Xian Qian and Yang Liu.
2013.
Disfluency DetectionUsing Multi-step Stacked Learning.
In Proceedingsof the North American Chapter of the Association forComputational Linguistics.Mohammad Sadegh Rasooli and Joel Tetreault.
2013.Joint Parsing and Disfluency Detection in Linear Time.In Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing.Andrew Rosenberg.
2010.
AuToBI - A Tool for Au-tomatic ToBI Annotation.
In Proceedings of Inter-speech.Sunita Sarawagi and William W. Cohen.
2004.
Semi-Markov Conditional Random Fields for InformationExtraction.
In Proceedings of Advances in Neural In-formation Processing Systems.Elizabeth Shriberg, Rebecca Bates, and Andreas Stolcke.1997.
A Prosody-only Decision-tree Model for Dis-fluency Detection.
In Proceedings of Eurospeech.Kim Silverman, Mary Beckman, John Pitrelli, Mari Os-tendorf, Colin Wightman, Patti Price, Janet Pierrehum-bert, and Julia Hirschberg.
1992.
ToBI: A Standardfor Labeling English Prosody.
In Proceedings of theInternational Conference on Spoken Language Pro-cessing.Matthew Snover, Bonnie Dorr, and Richard Schwartz.2004.
A Lexically-Driven Algorithm for DisfluencyDetection.
In Proceedings of the North AmericanChapter of the Association for Computational Linguis-tics.Ann Taylor, Mitchell Marcus, and Beatrice Santorini.2003.
The penn treebank: An overview.262
