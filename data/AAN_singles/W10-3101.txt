Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 1?4,Uppsala, July 2010.Zones of conceptualisation in scientific papers: a window to negative andspeculative statementsMaria LiakataDepartment of Computing Science, Aberystwyth UniversityEuropean Bioinformatics Institute, Cambridgeliakata@ebi.ac.ukAbstractIn view of the increasing need to facilitateprocessing the content of scientific papers,we present an annotation scheme for anno-tating full papers with zones of conceptu-alisation, reflecting the information struc-ture and knowledge types which constitutea scientific investigation.
The latter are theCore Scientific Concepts (CoreSCs) andinclude Hypothesis, Motivation, Goal, Ob-ject, Background, Method, Experiment,Model, Observation, Result and Conclu-sion.
The CoreSC scheme has been usedto annotate a corpus of 265 full papers inphysical chemistry and biochemistry andwe are currently automating the recogni-tion of CoreSCs in papers.
We discusshow the CoreSC scheme relates to otherviews of scientific papers and indeed howthe former could be used to help identifynegation and speculation in scientific texts.1 IntroductionThe recent surge in the numbers of papers pro-duced, especially in the biosciences, has high-lighted the need for automatic processing meth-ods.
Work by [Lin (2009)] has shown that methodssuch as information retrieval are more effective ifzones of interest are specified within the papers.Various corpora and annotation schemes havebeen proposed for designating a variety of linguis-tic phenomena permeating scientific papers, in-cluding negation, hedges, dependencies and se-mantic relations [Vincze et al (2008); Pyysaloet al (2007); Medlock and Briscoe (2007); McIn-tosh and Curran (2009)].
Other schemes followthe argumentation and citation flow within pa-pers [Teufel et al (2009); Teufel and Siddharthan(2007)] or indeed a combination of some of theabove along multiple dimensions [Shatkay et al(2008)].In the following we present the CoreSC anno-tation scheme and a corpus with CoreSC anno-tations.
The CoreSC scheme is used at the sen-tence level to identify the core components thatconstitute a scientific investigation.
We discusshow the CoreSC scheme relates to other annota-tion schemes representing alternate views of sci-entific papers and how CoreSCs could be used toguide the identification of negation and specula-tion.2 The CoreSC schemeThe CoreSC annotation scheme adopts the viewthat a scientific paper is the human-readable repre-sentation of a scientific investigation and thereforeseeks to mark the components of a scientificinvestigation as expressed in the text.
CoreSCis ontology-motivated and originates from theCISP meta-data [Soldatova and Liakata (2007)],a subset of classes from EXPO [Soldatova andKing (2006)], an ontology for the description ofscientific investigations.
CISP consists of the con-cepts: Motivation, Goal, Object, Method,Experiment, Observation, Result andConclusion, which were validated using anon-line survey as constituting the indispensableset of concepts necessary for the description ofa scientific investigation.
CoreSC implementsthese as well as Hypothesis, Model andBackground, as a sentence-based annotationscheme for 3-layered annotation.
The first layerpertains to the previously mentioned 11 cate-gories, the second layer is for the annotation ofproperties of the concepts (e.g.
?New?, ?Old?
)and the third layer caters for identifiers (concep-tID), which link together instances of the sameconcept, e.g.
all the sentences pertaining to thesame method will be linked together with thesame conceptID (e.g.
?Met1?
).If we combine the layers of annotation so as to1Table 1: The CoreSC Annotation schemeCategory DescriptionHypothesis A statement not yet confirmed rather than a factual statementMotivation The reasons behind an investigationBackground Generally accepted background knowledge and previous workGoal A target state of the investigation where intended discoveries are madeObject-New An entity which is a product or main theme of the investigationObject-New-Advantage Advantage of an objectObject-New-Disadvantage Disadvantage of an objectMethod-New Means by which authors seek to achieve a goal of the investigationMethod-New-Advantage Advantage of a MethodMethod-New-Disadvantage Disadvantage of a MethodMethod-Old A method mentioned pertaining to previous workMethod-Old-Advantage Advantage of a MethodMethod-Old-Disadvantage Disadvantage of a MethodExperiment An experimental methodModel A statement about a theoretical model or frameworkObservation the data/phenomena recorded in an investigationResult factual statements about the outputs of an investigationConclusion statements inferred from observations & results relating to research hypothesisgive flat labels, we cater for the categories in table1.The CoreSC scheme was accompanied by a set of45 page guidelines which contain a decision tree,detailed description of the semantics of the cate-gories, 6 rules for pairwise distinction and exam-ples from chemistry papers.
These guidelines areavailable from http://ie-repository.jisc.ac.uk/88/.3 The CoreSC corpusWe used the CoreSC annotation scheme and thesemantic annotation tool SAPIENT [Liakata et al(2009)] to construct a corpus of 265 annotated pa-pers [Liakata and Soldatova (2009)] from physi-cal chemistry and biochemistry.
The CoreSC cor-pus was developed in two different phases.
Dur-ing phase I, fifteen Chemistry experts were splitinto five groups of three, each of which anno-tated eight different papers; A 16th expert anno-tated across groups as a consistency check.
Thisresulted in a total of 41 papers being annotated,all of which received multiple annotations.
Weranked annotators according to median success interms of inter-annotator agreement (as measuredby Cohen?s kappa) both within their groups andfor a paper common across groups.
In phase II,the 9 best annotators of phase I each annotated 25papers, amounting to a total of 225 papers.The CoreSC corpus is now being used to traina classifier for the automation of Core Scientificconcepts in papers.4 Correlating CoreSCs to other zones ofinterestGiven the plethora of annotation schemes, it is in-teresting to investigate the correlation between dif-ferent views of scientific papers and how differentschemes map to each other.
We recently lookedat the correlation between the CoreSC scheme,which views papers as the humanly readable rep-resentation of scientific investigations and seeksto recover the investigation components within thepaper, and AZ-II [Teufel et al (2009)], which as-sumes a paper is the attempt of claiming owner-ship for a new piece of knowledge and aims torecover the rhetorical structure and the relevantstages in the argumentation.By definition, the two schemes focus on differ-ent aspects of the papers, with CoreSCs provid-ing more detail with respect to different types ofmethods and results and AZ-II looking mostly atthe appropriation of knowledge claims.
Based ona set of 36 papers annotated with both schemes,we were able to confirm that the two schemesare indeed complementary [Liakata et al (2010)].CoreSC categories provide a greater level of gran-ularity when it comes to the content-related cate-gories whereas AZ-II categories cover aspects ofthe knowledge claims that permeate across differ-ent CoreSC concepts.In [Guo et al (2010)] we followed a simi-lar methodology for annotating abstracts withCoreSCs and an independently produced annota-tion scheme for abstract sections [Hirohata et al(2008)].
We found a subsumption relation be-tween the schemes, with CoreSCs providing the2finer granularity.To obtain the mapping between annotationschemes, which allows annotation schemes to bedefined in a wider context, we ideally require an-notations from different schemes to be made avail-able for the same set of papers.
However, a firstinterpretation of the relation between schemes canbe made by mapping between annotation guide-lines.5 Thoughts on using CoreSCs forNegation and SpeculationCurrent work of ours involves automating therecognition of CoreSCs and we plan to use themto produce extractive summaries for papers.
Weare also in the process of evaluating the usefulnessof CoreSCs for Cancer Risk Assessment (CRA).An important aspect of the latter is being ableto distinguish between positive and negative re-sults and assess the confidence in any conclusionsdrawn.
This naturally leads us to the need for ex-ploring negation and speculation, both of whichare prominent in scientific papers, as well as howthese two phenomena correlate to CoreSCs.While it seems that negation can be identifiedby means of certain linguistic patterns [Morante(2010)], different types of negation can appearthroughout the paper, some pertaining to back-ground work, problems serving as the motivationof the paper, others referring to intermediate re-sults or conclusions.
It is interesting to look atthese different types of negation in the context ofeach of the different CoreSCs, the type of linguis-tic patterns used to express it and their distributionacross CoreSCs.
This can provide a more target-ted approach to negation, while at the same time itcan be used in combination with a CoreSC to inferthe type of knowledge obtained (e.g.
a positive ornegative result).
We plan to use automatic meth-ods for recognising negation patterns in CoreSCsand relate them to specific CoreSC categories.There is a consensus that identifying specula-tion is a harder task than identifying negation.Part of the problem is that ?speculative assertionsare to be identified on the basis of the judge-ments about the author?s intended meaning, ratherthan on the presence of certain designated hedgeterms?
[Medlock and Briscoe (2007); Light et al(2004)].
When annotating papers with CoreSCs,annotators are required to understand the papercontent rather than base category assignments en-tirely on linguistic patterns.
This is why we havechosen experts as annotators for the creation ofthe CoreSC corpus.
So both speculation andCoreSC annotation appear to be higher level an-notation tasks requiring comprehension of the in-tended meaning.
Looking at the annotation guide-lines for hedges [Medlock and Briscoe (2007)],it would seem that cases of hedge type 1 corre-spond to to CoreSC Conclusion, hedge type2 pertains to Background, hedge type 3 wouldmainly be cases of Motivation, hedge type 4maps to Motivation or Hypothesis, hedgetype 5 maps to Goal and hedge type 6 maps toConclusion.
One can look at speculation in thezones/windows identified by the previously men-tioned CoreSCs.
Indeed, two of the categories,Hypothesis and Motivation are speculativeby definition.
We intend to port the issue of iden-tifying speculation in our papers to that of identi-fying the corresponding CoreSCs.
We also plan toannotate the hedge classification data of [Medlockand Briscoe (2007)] with CoreSCs to confirm themapping between the two schemes.ReferencesY.
Guo, A. Korhonen, M. Liakata, I Silins, L. LiSun,and U. Stenius.
Identifying the information struc-ture of scientific abstracts: An investigation of threedifferent schemes.
In Proceedings of BioNLP 2010.To appear., Uppsala, Sweden, 2010.K.
Hirohata, N. Okazaki, S. Ananiadou, andM.
Ishizuka.
Identifying sections in scientific ab-stracts using conditional random fields.
In Proc.
ofthe IJCNLP 2008, 2008.M.
Liakata and L.N.
Soldatova.
The art cor-pus.
Technical report, Aberystwyth University,2009.
URL http://www.aber.ac.uk/en/cs/research/cb/projects/art/art-corpus/.M.
Liakata, Claire Q, and S. Soldatova.
Semantic anno-tation of papers: Interface & enrichment tool (sapi-ent).
In Proceedings of BioNLP-09, pages 193?200,Boulder, Colorado, 2009.M.
Liakata, S. Teufel, A. Siddharthan, and C. Batche-lor.
Corpora for the conceptualisation and zoning ofscientific papers.
2010.M.
Light, X.Y.
Qiu, and P. Srinivasan.
The languageof bioscience: Facts, speculations and statements inbetween.
In Proceedings of BioLink 2004 Work-shop on Linking Biological Literature, Ontologiesand Databases: Tools for Users, Boston, 2004.J.
Lin.
Is searching full text more effective than search-ing abstracts?
BMC Bioinformatics, 10:46, 2009.T.
McIntosh and J.R. Curran.
Challenges for automati-cally extracting molecular interactions from full-textarticles.
BMC Bioinformatics, 10(311), 2009.3B.
Medlock and T. Briscoe.
Weakly supervised learn-ing for hedge classification in scientific literature.In 45th Annual Meeting of the ACL, pages 23?30,Prague, Czech Republic, 2007.R.
Morante.
Descriptive analysis of negation cuesin biomedical texts.
In Proceedings of the Sev-enth International Language Resources and Evalu-ation (LREC?10), pages 1429?1436, Valletta, Malta,2010.S.
Pyysalo, F. Ginter, J. Heimonen, J. Bjorne,J.
Boberg, J. Jarvinen, and T. Salakoski.
Bioinfer:a corpus for information extraction in the biomedi-cal domain.
BMC Bioinformatics, 8(1), 2007.H.
Shatkay, F. Pan, A. Rzhetsky, and W.J.
Wilbur.Multi-dimensional classification of biomedical text:Toward automated, practical provision of high-utility text to diverse users.
Journal of Bioinformat-ics, 24:18:2086?2093, 2008.L.N.
Soldatova and R.D.
King.
An ontology of scien-tific experiments.
Journal of the Royal Society In-terface, 3:795?803, 2006.L.N.
Soldatova and M. Liakata.
An ontology method-ology and cisp-the proposed core information aboutscientific papers.
Technical Report JISC Project Re-port, Aberystwyth University, 2007.
URL http://ie-repository.jisc.ac.uk/137/.S.
Teufel and A. Siddharthan.
Whose idea was this,and why does it matter?
attributing sicentific work tocitations.
In Proceedings of NAACL-HLT-07, 2007.Simone Teufel, Advaith Siddharthan, and Colin Batch-elor.
Towards discipline-independent argumenta-tive zoning: Evidence from chemistry and compu-tational linguistics.
In Proceedings of EMNLP-09,Singapore, 2009.V.
Vincze, G. Szarvas, R. Farkas, G. Mra, and J. Csirik.The bioscope corpus: biomedical texts annotated foruncertainty, negation and their scopes.
BMC Bioin-formatics, 9(Suppl 11):S9, 2008.4
