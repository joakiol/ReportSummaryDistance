Proceedings of NAACL HLT 2007, pages 380?387,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsAnalysis of Morph-Based Speech Recognition and the Modeling ofOut-of-Vocabulary Words Across LanguagesMathias Creutz?, Teemu Hirsima?ki?, Mikko Kurimo?, Antti Puurula?, Janne Pylkko?nen?,Vesa Siivola?, Matti Varjokallio?, Ebru Ar?soy?, Murat Sarac?lar?, and Andreas Stolcke??
Helsinki University of Technology, <firstname>.<lastname>@tkk.fi,?
Bog?azic?i University, arisoyeb@boun.edu.tr, murat.saraclar@boun.edu.tr,?
SRI International / International Computer Science Institute, stolcke@speech.sri.comAbstractWe analyze subword-based languagemodels (LMs) in large-vocabularycontinuous speech recognition acrossfour ?morphologically rich?
languages:Finnish, Estonian, Turkish, and EgyptianColloquial Arabic.
By estimating n-gramLMs over sequences of morphs insteadof words, better vocabulary coverageand reduced data sparsity is obtained.Standard word LMs suffer from highout-of-vocabulary (OOV) rates, whereasthe morph LMs can recognize previouslyunseen word forms by concatenatingmorphs.
We show that the morph LMsgenerally outperform the word LMs andthat they perform fairly well on OOVswithout compromising the accuracyobtained for in-vocabulary words.1 IntroductionAs automatic speech recognition systems are beingdeveloped for an increasing number of languages,there is growing interest in language modeling ap-proaches that are suitable for so-called ?morpholog-ically rich?
languages.
In these languages, the num-ber of possible word forms is very large becauseof many productive morphological processes; wordsare formed through extensive use of, e.g., inflection,derivation and compounding (such as the Englishwords ?rooms?, ?roomy?, ?bedroom?, which all stemfrom the noun ?room?
).For some languages, language modeling based onsurface forms of words has proven successful, or atleast satisfactory.
The most studied language, En-glish, is not characterized by a multitude of wordforms.
Thus, the recognition vocabulary can sim-ply consist of a list of words observed in the trainingtext, and n-gram language models (LMs) are esti-mated over word sequences.
The applicability of theword-based approach to morphologically richer lan-guages has been questioned.
In highly compoundinglanguages, such as the Germanic languages German,Dutch and Swedish, decomposition of compoundwords can be carried out to reduce the vocabularysize.
Highly inflecting languages are found, e.g.,among the Slavic, Romance, Turkic, and Semiticlanguage families.
LMs incorporating morphologi-cal knowledge about these languages can be applied.A further challenging category comprises languagesthat are both highly inflecting and compounding,such as the Finno-Ugric languages Finnish and Es-tonian.Morphology modeling aims to reduce the out-of-vocabulary (OOV) rate as well as data sparsity,thereby producing more effective language mod-els.
However, obtaining considerable improvementsin speech recognition accuracy seems hard, as isdemonstrated by the fairly meager improvements(1?4 % relative) over standard word-based modelsaccomplished by, e.g., Berton et al (1996), Ordel-man et al (2003), Kirchhoff et al (2006), Whit-taker and Woodland (2000), Kwon and Park (2003),and Shafran and Hall (2006) for Dutch, Arabic, En-glish, Korean, and Czech, or even the worse perfor-mance reported by Larson et al (2000) for Germanand Byrne et al (2001) for Czech.
Nevertheless,clear improvements over a word baseline have beenachieved for Serbo-Croatian (Geutner et al, 1998),Finnish, Estonian (Kurimo et al, 2006b) and Turk-ish (Kurimo et al, 2006a).In this paper, subword language models in therecognition of speech of four languages are ana-380lyzed: Finnish, Estonian, Turkish, and the dialectof Arabic spoken in Egypt, Egyptian ColloquialArabic (ECA).
All these languages are considered?morphologically rich?, but the benefits of usingsubword-based LMs differ across languages.
We at-tempt to discover explanations for these differences.In particular, the focus is on the analysis of OOVs:A perceived strength of subword models, when con-trasted with word models, is that subword modelscan generalize to previously unseen word forms byrecognizing them as sequences of shorter familiarword fragments.2 MorfessorMorfessor is an unsupervised, data-driven, methodfor the segmentation of words into morpheme-likeunits.
The general idea is to discover as com-pact a description of the input text corpus as possi-ble.
Substrings occurring frequently enough in sev-eral different word forms are proposed as morphs,and the words in the corpus are then representedas a concatenation of morphs, e.g., ?hand, hand+s,left+hand+ed, hand+ful?.
Through maximum a pos-teriori optimization (MAP), an optimal balance issought between the compactness of the inventory ofmorphs, i.e., the morph lexicon, versus the compact-ness of the representation of the corpus.Among others, de Marcken (1996), Brent (1999),Goldsmith (2001), Creutz and Lagus (2002), andCreutz (2006) have shown that models based onthe above approach produce segmentations that re-semble linguistic morpheme segmentations, whenformulated mathematically in a probabilistic frame-work or equivalently using the Minimum Descrip-tion Length (MDL) principle (Rissanen, 1989).Similarly, Goldwater et al (2006) use a hierarchicalDirichlet model in combination with morph bigramprobabilities.The Morfessor model has been developed overthe years, and different model versions exist.
Themodel used in the speech recognition experiments ofthe current paper is the original, so-called Morfes-sor Baseline algorithm, which is publicly availablefor download.1.
The mathematics of the MorfessorBaseline model is briefly outlined in the following;consult Creutz (2006) for details.1http://www.cis.hut.fi/projects/morpho/2.1 MAP Optimization CriterionIn slightly simplified form, the optimization crite-rion utilized in the model corresponds to the maxi-mization of the following posterior probability:P (lexicon | corpus) ?P (lexicon) ?
P (corpus | lexicon) =?letters ?P (?)
?
?morphs ?P (?).
(1)The lexicon consists of all distinct morphs spelledout; this forms a long string of letters ?, in whicheach morph is separated from the next morph usinga morph boundary character.
The probability of thelexicon is the product of the probability of each let-ter in this string.
Analogously, the corpus is repre-sented as a sequence of morphs, which correspondsto a particular segmentation of the words in the cor-pus.
The probability of this segmentation equals theproduct of the probability of each morph token ?.Letter and morph probabilities are maximum likeli-hood estimates (empirical Bayes).2.2 From Morphs to n-GramsAs a result of the probabilistic (or MDL) approach,the morph inventory discovered by the MorfessorBaseline algorithm is larger the more training datathere is.
In some speech recognition experiments,however, it has been desirable to restrict the size ofthe morph inventory.
This has been achieved by set-ting a frequency threshold on the words on whichMorfessor is trained, such that the rarest words willnot affect the learning process.
Nonetheless, therarest words can be split into morphs in accordancewith the model learned, by using the Viterbi algo-rithm to select the most likely segmentation.
Theprocess is depicted in Figure 1.2.3 Grapheme-to-Phoneme MappingThe mapping between graphemes (letters) andphonemes is straightforward in the languages stud-ied in the current paper.
More or less, there isa one-to-one correspondence between letters andphonemes.
That is, the spelling of a word indicatesthe pronunciation of the word, and when splitting theword into parts, the pronunciation of the parts in iso-lation does not differ much from the pronunciationof the parts in context.
However, a few exceptions381Morphinventory+ probsn?gramsTraincut?offFrequencyViterbisegm.Text with wordssegmented intoLMmorphsMorfessorExtractwordsText corpusFigure 1: How to train a segmentation model usingthe Morfessor Baseline algorithm, and how to fur-ther train an n-gram model based on morphs.have been treated more rigorously in the Arabic ex-periments: e.g., in some contexts the same (spelled)morph can have multiple possible pronunciations.3 Experiments and AnalysisThe goal of the conducted experiments is to com-pare n-gram language models based on morphs tostandard word n-gram models in automatic speechrecognition across languages.3.1 Data Sets and Recognition SystemsThe results from eight different tests have been an-alyzed.
Some central properties of the test config-urations are shown in Table 1.
The Finnish, Esto-nian, and Turkish test configurations are slight vari-ations of experiments reported earlier in Hirsima?kiet al (2006) (Fin1: ?News task?, Fin2: ?Book task?
),Kurimo et al (2006a) (Fin3, Tur1), and Kurimo etal.
(2006b) (Fin4, Est, Tur2).Three different recognition platforms have beenused, all of which are state-of-the-art large vocab-ulary continuous speech recognition (LVCSR) sys-tems.
The Finnish and Estonian experiments havebeen run on the HUT speech recognition system de-veloped at Helsinki University of Technology.The Turkish tests were performed using theAT&T decoder (Mohri and Riley, 2002); the acous-tic features were produced using the HTK front end(Young et al, 2002).
The experiments on EgyptianColloquial Arabic (ECA) were carried out using theSRI DecipherTM speech recognition system.3.1.1 Speech Data and Acoustic ModelsThe type and amount of speech data vary fromone language to another.
The Finnish data con-sists of news broadcasts read by one single femalespeaker (Fin1), as well as an audio book read by an-other female speaker (Fin2, Fin3, Fin4).
The Finnishacoustic models are speaker dependent (SD).
Mono-phones (mon) were used in the earlier experiments(Fin1, Fin2), but these were later replaced by cross-context triphones (tri).The Estonian speech data has been collected froma large number of speakers and consists of sen-tences from newspapers as well as names and dig-its read aloud.
The acoustic models are speaker-independent triphones (SI tri) adapted online usingCepstral Mean Subtraction and Constrained Maxi-mum Likelihood Linear Regression.
Also the Turk-ish acoustic training data contains speech from hun-dreds of speakers.
The test set is composed of news-paper text read by one female speaker.
Speaker-independent triphones are used as acoustic models.The Finnish, Estonian, and Turkish data sets con-tain planned speech, i.e., written text read aloud.By contrast, the Arabic data consists of transcribedspontaneous telephone conversations,2 which arecharacterized by disfluencies and by the presenceof ?non-speech?, such as laugh and cough sounds.There are multiple speakers in the Arabic data, andonline speaker adaptation has been performed.3.1.2 Text Data and Language ModelsThe n-gram language models are trained usingthe SRILM toolkit (Stolcke, 2002) (Fin1, Fin2,Tur1, Tur2, ECA) or similar software developedat HUT (Siivola and Pellom, 2005) (Fin3, Fin4,Est).
All models utilize the Modified InterpolatedKneser-Ney smoothing technique (Chen and Good-man, 1999).
The Arabic LM is trained on thesame corpus that is used for acoustic training.
Thisdata set is regrettably small (160 000 words), but itmatches the test set well in style, as it consists oftranscribed spontaneous speech.
The LM trainingcorpora used for the other languages contain fairlylarge amounts of mainly news and book texts andconceivably match the style of the test data well.In the morph-based models, words are split intomorphs using Morfessor, and statistics are collectedfor morph n-grams.
As the desired output of the2LDC CallHome corpus of Egyptian Colloquial Ara-bic: http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC97S45382Table 1: Test configurationsFin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECARecognizer HUT HUT HUT HUT HUT AT&T AT&T SRISpeech dataType of speech read read read read read read read spont.Training set [kwords] 20 49 49 49 790 230 110 160Speakers in training set 1 1 1 1 1300 550 250 310Test set [kwords] 4.3 1.9 1.9 1.9 3.7 7.0 7.0 16Speakers in test set 1 1 1 1 50 1 1 57Text dataLM training set [Mwords] 36 36 32 150 53 17 27 0.16ModelsAcoustic models SD mon SD mon SD tri SD tri SI tri SI tri SI tri SI triMorph lexicon [kmorphs] 66 66 120 25 37 52 34 6.1Word lexicon [kwords] 410 410 410 ?
60 120 50 18Out-of-vocabulary wordsOOV LM training set [%] 5.0 5.0 5.9 ?
14 5.3 9.6 0.61OOV test set [%] 5.0 7.2 7.3 ?
19 5.5 12 9.9New words in test set [%] 2.7 3.0 3.1 1.5 3.4 1.6 1.5 9.8speech recognizer is a sequence of words rather thanmorphs, the LM explicitly models word breaks asspecial symbols occurring in the morph sequence.For comparison, word n-gram models have beentested.
The vocabulary cannot typically include ev-ery word form occurring in the training set (becauseof the large number of different words), so the mostfrequent words are given priority; the actual lexiconsizes used in each experiment are shown in Table 1.Any word not contained in the lexicon is replaced bya special out-of-vocabulary symbol.As words and morphs are units of different length,their optimal performance may occur at different or-ders of the n-gram.
The best order of the n-gramhas been optimized on development test sets in thefollowing cases: Fin1, Fin2, Tur1, ECA (4-gramsfor both morphs and words) and Tur2 (5-grams formorphs, 3-grams for words).
The models have ad-ditionally been pruned using entropy-based pruning(Tur1, Tur2, ECA) (Stolcke, 1998).
In the otherexperiments (Fin3, Fin4, Est), no fixed maximumvalue of n was selected.
n-Gram growing was per-formed (Siivola and Pellom, 2005), such that thosen-grams that maximize the training set likelihoodare gradually added to the model.
The unrestrictedgrowth of the model is counterbalanced by an MDL-type complexity term.
The highest order of n-gramsaccepted was 7 for Finnish and 8 for Estonian.Note that the optimization procedure is neutralwith respect to morphs vs. words.
Roughly thesame number of parameters are allowed in the result-ing LMs, but typically the morph n-gram LMs aresmaller than the corresponding word n-gram LMs.3.1.3 Out-of-Vocabulary WordsTable 1 further shows statistics on out-of-vocabulary rates in the data sets.
This is relevantfor the assessment of the word models, as the OOVrates define the limits of these models.The OOV rate for the LM training set correspondsto the proportion of words replaced by the OOVsymbol in the LM training data, i.e., words that werenot included in the recognition vocabulary.
The highOOV rates for Estonian (14 %) and Tur2 (9.6 %) in-dicate that the word lexicons have poor coverage ofthese sets.
By contrast, the ECA word lexicon cov-ers virtually the entire training set vocabulary.Correspondingly, the test set OOV rate is the pro-portion of words that occur in the data sets usedfor running the speech recognition tests, but that aremissing from the recognition lexicons.
This valueis thus the minimum error that can be obtained bythe word models, or put differently, the recognizeris guaranteed to get at least this proportion of wordswrong.
Again, the values are very high for Estonian(19 %) and Tur2 (12 %), but also for Arabic (9.9 %)because of the insufficient amount of training data.Finally, the figures labeled ?new words in test set?denote the proportion of words in the test set that donot occur in the LM training set.
Thus, these valuesindicate the minimum error achievable by any wordmodel trained on the training sets available.383Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA010203040506070809010076.671.979.167.889.882.292.866.751.968.667.466.761.240.141.8Wordaccuracy[%]MorphsWordsFigure 2: Word accuracies for the different speechrecognition test configurations.3.2 Results and AnalysisThe morph-based and word-based results of the con-ducted speech recognition experiments are shown inFigure 2 (for Fin4, no comparable word experimenthas been carried out).
The evaluation measure usedis word accuracy (WAC): the number of correctlyrecognized words minus the number of incorrectlyinserted words divided by the number of words inthe reference transcript.
(Another frequently usedmeasure is the word error rate, WER, which relatesto word accuracy as WER = 100 % ?
WAC.
)Figure 2 shows that the morph models performbetter than the word models, with the exceptionof the Arabic experiment (ECA), where the wordmodel outperforms the morph model.
The statisti-cal significance of these differences is confirmed byone-tailed paired Wilcoxon signed-rank tests at thesignificance level of 0.05.Overall, the best performance is observed for theFinnish data sets, which is explained by the speaker-dependent acoustic models and clean noise condi-tions.
The Arabic setup suffers from the insufficientamount of LM training data.3.2.1 In-Vocabulary WordsFor a further investigation of the outcome of theexperiments, the test sets have been partitioned intoregions based on the types of words they contain.The recognition output is aligned with the refer-ence transcript, and the regions aligned with in-vocabulary (IV) reference words (words containedin the vocabulary of the word model) are put inone partition and the remaining words (OOVs) areput in another partition.
Word accuracies are thencomputed separately for the two partitions.
Insertedwords, i.e., words that are not aligned with any wordin the reference, are put in the IV partition, unlessthey are adjacent to an OOV region, in which casethey are put in the OOV partition.Figure 3a shows word accuracies for the in-vocabulary words.
Without exception, the accuracyfor the IVs is higher than that of the entire test set vo-cabulary.
One could imagine that the word modelswould do better than the morph models on the IVs,since the word models are totally focused on thesewords, whereas the morph models reserve modelingcapacity for a much larger set of words.
The wordaccuracies in Fig.
3a also partly seem to support thisview.
However, Wilcoxon signed-rank tests (level0.05) show that the superiority of the word model isstatistically significant only for Arabic and for Fin3.With few exceptions, it is thus possible to drawthe conclusion that morph models are capable ofmodeling a much larger set of words than wordmodels without, however, compromising the perfor-mance on the limited vocabulary covered by theword models in a statistically significant way.3.2.2 Out-of-Vocabulary WordsSince the word model and morph model performequally well on the subset of words that are includedin the lexicon of the word model, the overall supe-riority of the morph model needs to come from itssuccessful coping with out-of-vocabulary words.In Figure 3b, word accuracies have been plot-ted for the out-of-vocabulary words contained in thetest set.
It is clear that the recognition accuracy forthe OOVs is much lower than the overall accuracy.Also, negative accuracy values are observed.
Thishappens when the number of insertions exceeds thenumber of correctly recognized units.In Figure 3b, if speaker-dependent and speaker-independent setups are considered separately (andArabic is left out), there is a tendency for the morphmodels to recognize the OOVs more accurately, thehigher the OOV rate is.
One could say that a morphmodel has a double advantage over a correspond-ing word model: the larger the proportion of OOVs384Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA010203040506070809010079.979.781.977.992.594.673.374.771.872.671.771.945.648.1Wordaccuracyfor in?vocabularywords[%]MorphsWords(a)Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA?100?80?60?40?2002040608010076.671.979.167.889.882.292.866.751.968.667.466.761.240.141.815.1?74.843.2?62.655.1?76.138.0?47.713.2?21.829.2?19.4?10.1?14.6Wordaccuracyfor OOVs[%]MorphsWords(b)Figure 3: Word accuracies computed separately for those words in the test sets that are (a) included in and(b) excluded from the vocabularies of the word vocabulary; cf.
figures listed on the row ?OOV test set?
inTable 1.
Together these two partitions make up the entire test set vocabulary.
For comparison, the results forthe entire sets are shown using gray-shaded bars (also displayed in Figure 2).in the word model is, the larger the proportion ofwords that the morph model can recognize but theword model cannot, a priori.
In addition, the largerthe proportion of OOVs, the more frequent and more?easily modelable?
words are left out of the wordmodel, and the more successfully these words areindeed learned by the morph model.3.2.3 New Words in the Test SetAll words present in the training data (some ofwhich are OOVs in the word models) ?leave sometrace?
in the morph models, in the n-gram statisticsthat are collected for morph sequences.
How, then,about new words that occur only in the test set, butnot in the training set?
In order to recognize suchwords correctly, the model must combine morphs inways it has not observed before.Figure 4 demonstrates that the new unseen wordsare very challenging.
Now, also the morph mod-els mostly obtain negative word accuracies, whichmeans that the number of insertions adjacent to newwords exceeds the number of correctly recognizednew words.
The best results are obtained in cleanacoustic conditions (Fin2, Fin3, Fin4) with only fewforeign names, which are difficult to get right usingtypical Finnish phoneme-to-grapheme mappings (asthe negative accuracy of Fin1 suggests).3.3 Vocabulary Growth and ArabicFigure 5 shows the development of the size ofthe vocabulary (unique word forms) for growingamounts of text in different corpora.
The corporaused for Finnish, Estonian, and Turkish (plannedspeech/text), as well as Arabic (spontaneous speech)are the LM training sets used in the experiments.Additional sources have been provided for Arabicand English: Arabic text (planned) from the FBIScorpus of Modern Standard Arabic (a collectionof transcribed radio newscasts from various radiostations in the Arabic speaking world), as well astext from the New York Times magazine (Englishplanned) and spontaneous transcribed English tele-phone conversations from the Fisher corpus.The figure illustrates two points: (1) The fasterthe vocabulary growth is, the larger the potential ad-vantage of morph models is in comparison to stan-dard word models, because of OOV and data spar-sity problems.
The obtained speech recognition re-sults seem to support this hypothesis; the appliedmorph LMs are clearly beneficial for Finnish andEstonian, mostly beneficial for Turkish, and slightlydetrimental for ECA.
(2) A more slowly growingvocabulary is used in spontaneous speech than inplanned speech (or written text).
Moreover, theArabic ?spontaneous?
curve is located fairly close385Fin1 Fin2 Fin3 Fin4 Est Tur1 Tur2 ECA?100?80?60?40?2002040608010076.671.979.167.889.882.292.866.751.968.667.466.761.240.141.8?8.7?93.020.7?75.931.0?81.017.9?32.3?64.6?6.1?24.6?5.9?24.5?10.1?14.6Wordaccuracyfor unseenwords[%]MorphsWordsFigure 4: Word accuracies computed for the wordsin the test sets that do not occur at all in the train-ing sets; cf.
figures listed on the row ?new wordsin test set?
in Table 1.
For comparison, the gray-shaded bars show the corresponding results for theentire test sets (also displayed in Figure 2).to the English ?planned?
curve and much belowthe Finnish, Estonian, and Turkish curves.
Thus,even though Arabic is considered a ?morphologi-cally rich?
language, this is not manifested througha considerable vocabulary growth (and high OOVrate) in the Egyptian Colloquial Arabic data used inthe current speech recognition experiments.
Conse-quently, it may not be that surprising that the morphmodel did not work particularly well for Arabic.Arabic words consist of a stem surrounded by pre-fixes and suffixes, which are fairly successfully seg-mented out by Morfessor.
However, Arabic alsohas templatic morphology, i.e., the stem is formedthrough the insertion of a vowel pattern into a ?con-sonantal skeleton?.Additional experiments have been performed us-ing the ECA data and Factored Language Models(FLMs) (Kirchhoff et al, 2006).
The FLM is apowerful model that makes use of several sourcesof information, in particular a morphological lexi-con of ECA.
The FLM incorporates mechanisms forhandling templatic morphology, but despite its so-phistication, it barely outperforms the standard wordmodel: The word accuracy of the FLM is 42.3 % andthat of the word model is 41.8 %.
The speech recog-nition implementation of both the FLM and the word0 20 40 60 80 100 120 140 160 18005101520253035404550Corpus size [1000 words]Uniquewords[1000 words]Finnish(planned)Estonian (planned)Turkish (planned)Arabic(spontaneous)Arabic (planned)English (planned)English (spontaneous)Figure 5: Vocabulary growth curves for the differ-ent corpora of spontaneous and planned speech (orwritten text).
For growing amounts of text (wordtokens) the number of unique different word forms(word types) occurring in the corpus are plotted.model is based on whole words (although subwordunits are used for assigning probabilities to wordforms in the FLM).
This contrasts these models withthe morph model, which splits words into subwordunits also in the speech recognition implementation.It seems that the splitting is a source of errors in thisexperimental setup with very little data available.4 DiscussionAlternative morph-based and word-based ap-proaches exist.
We have tried some, but none ofthem has outperformed the described morph modelsfor Finnish, Estonian, and Turkish, or the word andFLM models for Egyptian Arabic (in a statisticallysignificant way).
The tested models comprisemore linguistically accurate morph segmentationsobtained using later Morfessor versions (Categories-ML and Categories-MAP) (Creutz, 2006), as wellas analyses obtained from morphological parsers.Hybrids, i.e., word models augmented withphonemes or other subword units have been pro-posed (Bazzi and Glass, 2000; Galescu, 2003;Bisani and Ney, 2005).
In our experiments, suchmodels have outperformed the standard word mod-els, but not the morph models.Simply growing the word vocabulary to cover the386entire vocabulary of large training corpora could beone (fairly ?brute-force?)
approach, but this is hardlyfeasible for languages such as Finnish.
The en-tire Finnish LM training data of 150 million words(used in Fin4) contains more than 4 million uniqueword forms, a value ten times the size of the ratherlarge word lexicon currently used.
And even if a 4-million-word lexicon were to be used, the OOV rateof the test set would still be relatively high: 1.5 %.Judging by the Arabic experiments, there seemsto be some potential in Factored Language Models.The FLMs might work well also for the other lan-guages, and in fact, to do justice to the more ad-vanced morph models from later versions of Mor-fessor, FLMs or some other refined techniques maybe necessary as a complement to the currently usedstandard n-grams.AcknowledgmentsWe are most grateful to Katrin Kirchhoff and Dimitra Vergyrifor their valuable help on issues related to Arabic, and to the EUAMI training program for funding part of this work.
The workwas also partly funded by DARPA under contract No.
HR0011-06-C-0023 (approved for public release, distribution is unlim-ited).
The views herein are those of the authors and do not nec-essarily reflect the views of the funding agencies.ReferencesI.
Bazzi and J. R. Glass.
2000.
Modeling out-of-vocabularywords for robust speech recognition.
In Proc.
ICSLP, Bei-jing, China.A.
Berton, P. Fetter, and P. Regel-Brietzmann.
1996.
Com-pound words in large-vocabulary German speech recognitionsystems.
In Proc.
ICSLP, pp.
1165?1168, Philadelphia, PA,USA.M.
Bisani and H. Ney.
2005.
Open vocabulary speech recog-nition with flat hybrid models.
In Proc.
Interspeech, Lisbon,Portugal.M.
R. Brent.
1999.
An efficient, probabilistically sound algo-rithm for segmentation and word discovery.
Machine Learn-ing, 34:71?105.W.
Byrne, J.
Hajic?, P. Ircing, F. Jelinek, S. Khudanpur, P. Kr-bec, and J. Psutka.
2001.
On large vocabulary continuousspeech recognition of highly inflectional language ?
Czech.In Proc.
Eurospeech, pp.
487?489, Aalborg, Denmark.S.
F. Chen and J. Goodman.
1999.
An empirical study ofsmoothing techniques for language modeling.
ComputerSpeech and Language, 13:359?394.M.
Creutz and K. Lagus.
2002.
Unsupervised discovery ofmorphemes.
In Proc.
ACL SIGPHON, pp.
21?30, Philadel-phia, PA, USA.M.
Creutz.
2006.
Induction of the Morphology of NaturalLanguage: Unsupervised Morpheme Segmentation with Ap-plication to Automatic Speech Recognition.
Ph.D. thesis,Helsinki University of Technology.
http://lib.tkk.fi/Diss/2006/isbn9512282119/.C.
G. de Marcken.
1996.
Unsupervised Language Acquisition.Ph.D.
thesis, MIT.L.
Galescu.
2003.
Recognition of out-of-vocabulary wordswith sub-lexical language models.
In Proc.
Eurospeech, pp.249?252, Geneva, Switzerland.P.
Geutner, M. Finke, and P. Scheytt.
1998.
Adaptive vocabu-laries for transcribing multilingual broadcast news.
In Proc.ICASSP, pp.
925?928, Seattle, WA, USA.J.
Goldsmith.
2001.
Unsupervised learning of the mor-phology of a natural language.
Computational Linguistics,27(2):153?198.S.
Goldwater, T. L. Griffiths, and M. Johnson.
2006.
Contex-tual dependencies in unsupervised word segmentation.
InProc.
Coling/ACL, pp.
673?680, Sydney, Australia.T.
Hirsima?ki, M. Creutz, V. Siivola, M. Kurimo, S. Virpioja, andJ.
Pylkko?nen.
2006.
Unlimited vocabulary speech recogni-tion with morph language models applied to Finnish.
Com-puter Speech and Language, 20(4):515?541.K.
Kirchhoff, D. Vergyri, J. Bilmes, K. Duh, and A. Stol-cke.
2006.
Morphology-based language modeling for Ara-bic speech recognition.
Computer Speech and Language,20(4):589?608.M.
Kurimo, M. Creutz, M. Varjokallio, E. Ar?soy, andM.
Sarac?lar.
2006a.
Unsupervised segmentation of wordsinto morphemes ?
Morpho Challenge 2005, Application toautomatic speech recognition.
In Proc.
Interspeech, Pitts-burgh, PA, USA.M.
Kurimo, A. Puurula, E. Ar?soy, V. Siivola, T. Hirsima?ki,J.
Pylkko?nen, T. Aluma?e, and M. Sarac?lar.
2006b.
Un-limited vocabulary speech recognition for agglutinative lan-guages.
In Proc.
NAACL-HLT, New York, USA.O.-W. Kwon and J.
Park.
2003.
Korean large vocabulary con-tinuous speech recognition with morpheme-based recogni-tion units.
Speech Communication, 39(3?4):287?300.M.
Larson, D. Willett, J. Koehler, and G. Rigoll.
2000.
Com-pound splitting and lexical unit recombination for improvedperformance of a speech recognition system for German par-liamentary speeches.
In Proc.
ICSLP.M.
Mohri and M. D. Riley.
2002.
DCD library, Speechrecognition decoder library.
AT&T Labs Research.
http://www.research.att.com/sw/tools/dcd/.R.
Ordelman, A. van Hessen, and F. de Jong.
2003.
Compounddecomposition in Dutch large vocabulary speech recogni-tion.
In Proc.
Eurospeech, pp.
225?228, Geneva, Switzer-land.J.
Rissanen.
1989.
Stochastic complexity in statistical inquiry.World Scientific Series in Computer Science, 15:79?93.I.
Shafran and K. Hall.
2006.
Corrective models for speechrecognition of inflected languages.
In Proc.
EMNLP, Syd-ney, Australia.V.
Siivola and B. Pellom.
2005.
Growing an n-gram model.
InProc.
Interspeech, pp.
1309?1312, Lisbon, Portugal.A.
Stolcke.
1998.
Entropy-based pruning of backoff languagemodels.
In Proc.
DARPA BNTU Workshop, pp.
270?274,Lansdowne, VA, USA.A.
Stolcke.
2002.
SRILM ?
an extensible language modelingtoolkit.
In Proc.
ICSLP, pp.
901?904.
http://www.speech.sri.com/projects/srilm/.E.
W. D. Whittaker and P. C. Woodland.
2000.
Particle-basedlanguage modelling.
In Proc.
ICSLP, pp.
170?173, Beijing,China.S.
Young, D. Ollason, V. Valtchev, and P. Woodland.
2002.The HTK book (for version 3.2 of HTK).
University of Cam-bridge.387
