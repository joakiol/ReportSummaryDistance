In: Proceedings of CoNLL-2000 and LLL-2000, pages 154-156, Lisbon, Portugal, 2000.Chunking with WPDV ModelsHans  van  Ha l te renDept.
of Language and Speech, Univ.
of NijmegenP.O.
Box 9103, 6500 HD NijmegenThe Netherlandshvh@let ,  kun .
n l1 In t roduct ionIn this paper I describe the application of theWPDV algorithm to the CoNLL-2000 sharedtask, the identification ofbase chunks in Englishtext (Tjong Kim Sang and Buchholz, 2000).
Forthis task, I use a three-stage architecture: Ifirst run five different base chunkers, then com-bine them and finally try to correct some recur-ring errors.
Except for one base chunker, whichuses the memory-based machine learning sys-tern TiMBL, 1 all modules are based on WPDVmodels (van Halteren, 2000a).2 Arch i tec ture  componentsThe first stage of the chunking architecture con-sists of five different base chunkers:1) As a baseline, I use a stacked TiMBLmodel.
For the first level, following Daelemanset al (1999), I use as features all words andtags in a window ranging from five tokens tothe left to three tokens to the right.
For thesecond level (cf.
Tjong Kim Sang (2000)), I usea smaller window, four left and two right, butadd the IOB suggestions made by the first levelfor one token left and right (but not the focus).2) The basic WPDV model uses as featuresthe words in a window ranging from one left toone right, the tags in a window ranging fromthree left to three right, and the IOB sugges-tions for the previous two tokens?3) In the reverse WPDV model, the directionof chunking is reversed, i.e.
it chunks from theend of each utterance towards the beginning.4) In the R&M WPDV model, Ramshaw andMarcus's type of IOB-tags are used, i.e.
startsof chunks are tagged with a B-tag only if the1Cf.
ht tp : / / i l k .
kub.
nl/ .2For unseen data, i.e.
while being applied, the IOBsuggestions used are of course those suggested by themodel itself, not the true ones.preceding chunk is of the same type, and withan I-tag otherwise.5) In the LOB WPDV model, the Penn word-class tags (as produced by the Brill tagger)are replaced by the output of a WPDV taggertrained on 90% of the LOB corpus (van Hal-teren, 2000b).For all WPDV models, the number of fea-tures is too high to be handled comfortably bythe current WPDV implementation.
For thisreason, I use a maximum feature subset size offour and a threshold frequency of two.
3The second stage consists of a combinat ion ofthe outputs of the five base chunkers, using an-other WPDV model.
Each chunker contributesa feature containing the IOB suggestions for theprevious, current and next token.
In addition,there is a feature for the word and a featurecombining the (Penn-style) wordclass tags ofthe previous, current and next token.
For thecombination model, I use no feature restrictions,and the default hill-climbing procedure.In the final stage, I apply correct ive mea-sures to systematic errors which are observedin the output of leave-one-out experiments onthe training data.
For now, I focus on the mostfrequent phrase type, the NP, and especially onone weak point: determination f the start po-sition of NPs.
I use separate WPDV models foreach of the following cases:1) Shou ld  a token  now marked  I -NP  start a~Cf.
van Halteren (2000a).
Also, the difference be-tween training and running (correct IOB-tags vs modelsuggestions) leads to a low expected generalization qual-ity of hill-climbing.
I therefore stop climbing after asingle effective step, but using an alternative climbingprocedure, in which not only the single best multiplica-tions/division is applied per step, but which during ev-ery step applies all multiplications/divisions that yieldedimprovements while the opposite operation did not.154PhrasetypeADJPADVPCONJPINTJLSTNPPPPRTSBARVPNumber intest set4388669251242248111065354658TiMBL WPDVbasic reverse R&M LOB64.99 71.14 76.18 70.52 69.83 74.5575.03 78.96 79.83 78.16 78.50 80.0936.36 45.45 18.18 20.69 58.82 42.1166.67 66.67 66.67 66.67 0.00 66.670.00 0.00 0.00 0.00 0.00 0.0091.85 92.65 92.56 92.00 92.35 93.7295.66 96.53 96.85 96.06 96.65 97.0963.10 73.63 68.60 74.07 73.45 74.3176.50 82.27 85.54 84.18 84.77 85.4192.11 92.80 92.84 92.37 91.45 93.61NO OtN NOt A'7 O1 T ?)
N1 ONCombination Correctivemeasures74.5279.8642.1166.670.0093.8497.1074.3185.4193.65O~ OE Qq q'~Table 1: FZ=i measurements for all systems (as described in the text).
In addition we list thenumber of occurrences of each phrase type in the test set.new NP?
4 Features used: the wordclass tag se-quence within the NP up to the current oken,the wordclass equence within the NP from thecurrent token, and the current, previous andnext word within the NP.2) Should a token now marked B-NP con-tinue a preceding NP?
Features used: type andstructure (in terms of wordclass tags) of the cur-rent and the preceding two chunks, and the finalword of the current and the preceding chunk.3) Should (part of) a chunk now precedingan NP be part of the NP?
Features used: typeand structure (in wordclass tags) of the current,preceding and next chunk (the latter being theNP), and the final word of the current and nextchunk.For all three models, the number of differentfeatures i large.
Normally, this would force theuse of feature restrictions.
The training sets arevery small, however, so that the need for featurerestrictions disappears and the full model canbe used.
On the other hand, the limited sizeof the training sets has as a disadvantage thathill-climbing becomes practically useless.
Forthis reason, I do not use hill-climbing but simplytake the initial first order weight factors.Each token is subjected to the appropriatemodel, or, if not in any of the listed situations,left untouched.
To remove (some) resulting in-consistencies, I let an AWK script then changethe IOB-tag of all comma's and coordinatorsthat now end an NP into O.4This cannot already be the first token of an NP,as I-tags following a different ype of chunk are alwaysimmediately transformed to B-tags.3 Resul tsThe Ff~=l scores for all systems are listed in Ta-ble 1.
They vary greatly per phrase type, partlybecause of the relative difficulty of the tasks butalso because of the variation in the number ofrelevant raining and test cases: the most fre-quent phrase types (NP, PP and VP) also showthe best results.
Note that three of the phrasetypes (CONJP, INTJ and LST) are too infre-quent o yield statistically sensible information.The TiMBL results are worse than the onesreported by Buchholz et al (1999), 5 but the lat-ter were based on training on WSJ sections 00-19 and testing on 20-24.
When comparing withthe NP scores of Daelemans et al (1999), we seea comparable accuracy (actually slightly higherbecause of the second level classification).The WPDV accuracies are almost all muchhigher.
For NP, the basic and reverse modelproduce accuracies which can compete withthe highest published non-combination accura-cies so far.
Interestingly, the reverse mode lyields the best overall score.
This can be ex-plained by the observation that many choices,e.g.
PP/PRT and especially ADJP/part of NP,are based mostly on the right context, aboutwhich more information becomes available whenthe text is handled from right to left.
TheR&M-type IOB-tags are generally less usefulthan the standard ones, but still show excep-tional quality for some phrase types, e.g.
PRT.The results for the LOB model are disappoint-ing, given the overall quality of the tagger used~FADJP----66.7, FADVP----77.9 FNp=92.3, Fpp=96.8,Fvp----91.8155test data precision (97.82% on the held-out 10% of LOB).
I hypoth-esize this to be due to: a) differences in texttype between LOB and WSJ, b) partial incom-patibility between the LOB tags and the WSJchunks and c) insufficiency of chunker trainingset size for the more varied LOB tags.Combination, as in other tasks (e.g.
van Hal-teren et al (To appear)), leads to an impressiveaccuracy increase, especially for the three mostfrequent phrase types, where there is a suffi-cient number of cases to train the combinationmodel on.
There are only two phrase types,ADVP and SBAR, where a base chunker (re-verse WPDV) manages to outperform the com-bination.
In both cases the four normal direc-tion base chunkers outvote the better-informedreverse chunker, probably because the combina-tion system has insufficient training material torecognize the higher information value of the re-verse model (for these two phrase types).
Eventhough the results are already quite good, I ex-pect that even more effective combination ispossible, with an increase in training set sizeand the inclusion of more base chunkers, espe-cially ones which differ substantially from thecurrent, still rather homogeneous, set.The corrective measures yield further im-provement, although less impressive.
Unsur-prisingly, the increase is found mostly for theNP.
The next most affected phrase type is theADJP, which can often be joined with or re-moved from the NP.
There is an increase in re-call for ADJP (71.23% to 71.46%), but a de-crease in precision (78.20% to 77.86%), leav-ing the FZ=I value practically unchanged.
ForADVP, there is a loss of accuracy, most likelycaused by the one-shot correction procedure.This loss will probably disappear when a proce-dure is used which is iterative and also targetsother phrase types than the NP.
For VP, on theother hand, there is an accuracy increase, prob-ably due to a corrected inclusion/exclusion fparticiples into/from NPs.
The overall scoresshow an increase, especially due to the per-typeincreases for the very frequent NP and VP.All scores for the chunking system as a whole,including precision and recall percentages, arelisted in Table 2.
For all phrase types, thesystem yields substantially better results thanany previously published.
I attribute the im-provements primarily to the combination archi-ADJPADVPCONJPINTJLSTNPPPPRTSBARVP77.86%80.52%40.00%100.00%O.00%93.55%96.43%72.32%87.77%93.36%all 93.13% 93.51%recall Ff~=l71.46% 74.5279.21% 79.8644.44% 42.1150.00% 66.670.00% 0.0094.13% 93.8497.78% 97.1076.42% 74.3183.18% 85.4193.95% 93.6593.32Table 2: Final results per chunk type, i.e.
af-ter applying corrective measures to base chun-ker combination.tecture, with a smaller but yet valuable contri-bution by the corrective measures.
The choicefor WPDV proves a good one, as the WPDValgorithm is able to cope well with all the mod-eling tasks in the system.
Whether it is the bestchoice can only be determined by future experi-ments, using other machine learning techniquesin the same architecture.Re ferencesSabine Buchholz, Jorn Veenstra, and Walter Daele-mans.
1999.
Cascaded grammatical relation as-signment.
In Proceedings of EMNLP/VLC-99.Association for Computational Linguistics.W.
Daelemans, S. Buchholz and J. Veenstra.
1999.Memory-based shallow parsing.
In Proceedings ofCoNLL, Bergen, Norway.H.
van Halteren.
2000a.
A default first order familyweight determination procedure for WPDV mod-els.
In Proceedings of the CoNLL-2000.
Associa-tion for Computational Linguistics.H.
van Halteren.
2000b.
The detection of inconsis-tency in manually tagged text.
In Proceedings ofLINC2000.H.
van Halteren, J. Zavrel, and W. Daelemans.
Toappear.
Improving accuracy in wordclass taggingthrough combination ofmachine l arning systems.Computational Linguistics.E.
F. Tjong Kim Sang.
2000.
Noun phrase recogni-tion by system combination.
In Proceedings o\] theANLP-NAACL 2000.
Seattle, Washington, USA.Morgan Kaufman Publishers.E.
F. Tjong Kim Sang and S. Buchholz.
2000.
Intro-duction to the CoNLL-2000 shared task: Chunk-ing.
In Proceedings ofthe CoNLL-2000.
Associa-tion for Computational Linguistics.156
