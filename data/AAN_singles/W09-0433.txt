Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 190?196,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsChinese Syntactic Reordering for Adequate Generation of KoreanVerbal Phrases in Chinese-to-Korean SMTJin-Ji Li, Jungi Kim, Dong-Il Kim*, and Jong-Hyeok LeeDepartment of Computer Science and Engineering,Electrical and Computer Engineering Division,Pohang University of Science and Technology (POSTECH),San 31 Hyoja Dong, Pohang, 790-784, R. of KoreaE-mail: {ljj, yangpa, jhlee}@postech.ac.kr*Language Engineering Institute,Department of Computer, Electron and Telecommunication Engineering,Yanbian University of Science and Technology (YUST),Yanji, Jilin, 133-000, P.R.
of ChinaE-mail: {dongil}@ybust.edu.cnAbstractChinese and Korean belong to different lan-guage families in terms of word-order andmorphological typology.
Chinese is an SVOand morphologically poor language while Ko-rean is an SOV and morphologically rich one.In Chinese-to-Korean SMT systems, systemat-ic differences between the verbal systems ofthe two languages make the generation of Ko-rean verbal phrases difficult.
To resolve thedifficulties, we address two issues in this paper.The first issue is that the verb position is dif-ferent from the viewpoint of word-order ty-pology.
The second is the difficulty of com-plex morphology generation of Korean verbsfrom the viewpoint of morphological typology.We propose a Chinese syntactic reorderingthat is better at generating Korean verbalphrases in Chinese-to-Korean SMT.
Specifi-cally, we consider reordering rules targetingChinese verb phrases (VPs), prepositionphrases (PPs), and modality-bearing wordsthat are closely related to Korean verbal phras-es.
We verify our system with two corpora ofdifferent domains.
Our proposed approachsignificantly improves the performance of oursystem over a baseline phrased-based SMTsystem.
The relative improvements in the twocorpora are +9.32% and +5.43%, respectively.1 IntroductionRecently, there has been a lot of research on en-coding syntactic information into statistical ma-chine translation (SMT) systems in various formsand in different stages of translation processes.During preprocessing source language sen-tences undergo reordering and morpho-syntacticreconstruction phases to generate more targetlanguage-like sentences.
Also, fixing erroneouswords, generating complex morphology, and re-ranking translation results in post-processingphases may utilize syntactic information of bothsource and target languages.
A syntax-basedSMT system encodes the syntactic information inits translation model of the decoding step.A number of researchers have proposed syn-tactic reordering as a preprocessing step (Xia andMcCord, 2004; Collins et al, 2005; Wang et al,2007).
In these syntactic reordering approaches,source sentences are first parsed and a series ofreordering rules are applied to the parsed trees toreorder the source sentences into target language-like word orders.
Such an approach is an effec-tive method for a phrase-based SMT system thatemploys a relatively simple distortion model inthe decoding phase.This paper concentrates upon reorderingsource sentences in the preprocessing step of aChinese-to-Korean phrase-based SMT systemusing syntactic information.
Chinese-to-KoreanSMT has more difficulties than the languagepairs studied in previous research (French-English, German-English, and Chinese-English).From the viewpoint of language typology, theselanguage pairs are all SVO languages and theyhave relatively simpler morphological inflections.On the other hand, Korean is an SOV and agglu-tinative language with relatively free word orderand with complex and rich inflections.For the Chinese-to-Korean SMT, these syste-matic differences of the two languages make thegeneration of Korean verbal phrases very diffi-cult.
Firstly, the difference in the verb position ofthe two languages may not be reflected in thesimple distortion model of a phrase-based SMTsystem.
Secondly, Morphology generation of190Korean verbs is difficult because of its complexi-ty and the translation direction from a low-inflection language to a high-inflection language.In the following sections, we describe the cha-racteristics of Korean verbal phrases and theircorresponding Chinese verbal phrases, andpresent a set of hand-written syntactic reorderingrules including Chinese verb phrases (VPs), pre-position phrases (PPs), and modality-bearingwords.
In the latter sections, we empirically veri-fy that our reordering rules effectively repositionsource words to target language-like order andimprove the translation results.2 Contrastive analysis of Chinese andKorean with a focus on Korean verbalphrase generationsIn the Chinese-to-Korean SMT, the basic transla-tion units are morphemes.
For Chinese, sentencesare segmented into words.
As a typical isolatinglanguage, each segmented Chinese word is amorpheme.
Korean is a highly agglutinative lan-guage and an eojeol refers to a fully inflectedlexical form separated by a space in a sentence.Each eojeol in Korean consists of one or morebase forms (stem morphemes or content mor-phemes) and their inflections (function mor-phemes).
Inflections usually include postposi-tions and verb endings (verb affixes) of verbsand adjectives.
These base forms and inflectionsare grammatical units in Korean, and they aredefined as morphemes.
As for the translation unit,eojeol cause data sparseness problems hence weconsider a morpheme as a translation unit forKorean.As briefly mentioned in the previous section,Chinese and Korean belong to different word-order typologies.
The difference of verb positioncauses the difficulty in generating correct Koreanverbal phrases.
Also, the complexity of verb af-fixes in Korean verbs is problematic in SMT sys-tems targeting Korean, especially if the sourcelanguage is isolated.In the Dong-A newspaper corpus on which wecarry out our experiments in Section 4, Koreanfunction morphemes occupy 41.3% of all Koreanmorphemes.
Verb endings consist of 40.3% of allKorean function words, and the average numberof function morphemes inflected by a verb or anadjective is 1.94 while that of other content mor-phemes is only 0.7.These statistics indicate that the morphologicalform of Korean verbal phrases (Korean verbs) 1are significantly complex.
A verbal phrase inKorean consists of a series of verb affixes alongwith a verb stem.
A verb stem cannot be used byitself but should take at least one affix to form averbal complex.
Verb affixes in Korean are or-dered in a relative sequence within a verbal com-plex (Lee, 1991) and express different modalityinformation2: tense, aspect, mood, negation, andvoice (Figure 1).
These five grammatical catego-ries are the major constituents of modal expres-sion in Korean.K1: ?
(stem) +?_?
(aspect prt.)
+  ?
(aspect prt.
)+ ?
(tense prt.)
+ ?
(mood prt.
)E1: had been eatingK2.
?
(stem) + ?
(passive prt.)
+ ?
(aspect prt.)
+?_ ?_?
(modality prt.)
+ ?
(mood prt.
)E2: might have been caughtFigure 1.
Verbal phrases in Korean.
Bold-facedcontent morphemes followed by functional oneswith ?+?
symbols.
Prt.
is an acronym for particle.The modality of Korean is expressed inten-sively by verb affixes.
However, Chinese ex-presses modality using discontinuous morphemesscattered throughout a sentence (Figure 2).
Also,the prominence of grammatical categories ex-pressing modality information is different fromlanguage to language, and correlations of suchcategories in a language are also different.
Thedifferences between the two languages lead todifficulties in alignment and cause linking obscu-rities.C3: ??(thief)/??(might)/?
(passive prt.)/??(police)/?(catch)/?
(aspect prt.
)/?K3: ??(thief)+?
??(police)+???(catch)+?
(passive prt.)+?
(aspect prt.)+?_?_?
(modality prt.)+?
(mood prt.
)+./E3: The thief might have been caught by the police.Figure 2.
Underlined morphemes are modality-bearing morphemes in Chinese and Korean sen-tences.
Chinese words are separated by a ?/?symbol and Korean eojeols by a space.1 ?Korean verbal phrase?
or ?Korean verbs?
in this paperrefer to Korean predicates (verbs or adjectives) in a sentence.2  Modality system refers to five grammatical categories:tense, aspect, mood (modality & mood), negation, and voice.The definition of these categories is described in detail in(Li et al, 2005).191We consider two issues for generating ade-quate Korean verbal phrases.
First is the correctposition of verbal phrases, and the second is thegeneration of verb affixes which convey modali-ty information.3 Chinese syntactic reordering rulesIn this section, we describe a set of manuallyconstructed Chinese syntactic reordering rules.Chinese sentences are first parsed by StanfordPCFG parser which uses Penn Chinese Treebankas the training corpus (Levy and Manning, 2003).Penn Chinese Treebank adopts 23 tags for phras-es (Appendix A).
We identified three categoriesin Chinese that need to be reordered: verb phras-es (VPs), preposition phrases (PPs), and modali-ty-bearing words.3.1 Verb phrasesKorean is a verb-final language, and verb phrasemodifiers and complements occur in the pre-verbal positions.
However, in Chinese, verbphrase modifiers occur in the pre-verbal or post-verbal positions, and complements mostly occurin post-verbal positions.We move the verb phrase modifiers and com-plements located before the verbal heads to thepost-verbal position as demonstrated in the fol-lowing examples.
A verbal head consists of averb (including verb compound) and an aspectsequence (Xue and Xia, 2000).
Therefore, aspectmarkers such as ??
(perfective prt.
)?, ??
(durative prt.
)?, ??
(experiential prt.)?
positionedimmediately after a verb should remain in therelatively same position with the preceding verb.The third one in the example reordering rulesshows this case.
Mid-sentence punctuations arealso considered when constructing the reorderingrules.Examples of reordering rules of VPs3:VV0 NP1 ?
NP1 VV0VV0 IP1 ?
IP1 VV0VV0 AS1 NP2 ?
NP2 VV0 AS1VV0 PU1 IP2 ?
IP2 PU1 VV0Original parse tree:VPPP (P ?
)NP (NN ??
)PP (P ?
)3 VV: common verb; AS: aspect marker; P: preposi-tion; PU: punctuation; PN: pronoun;NP (PN ??
)VP (VV ??
)NP (NN ??
)Reordered parse tree:VPPP (P ?
)NP (NN ??
)PP (P ?
)NP (PN ??
)NP (NN ??
)VP (VV ??
)3.2 Preposition phrasesChinese prepositions originate from verbs, andthey preserve the characteristics of verbs.
Chi-nese prepositions are translated into Koreanverbs, other content words, or particles.
We onlyconsider the Chinese prepositions that translateinto verbs and other content words.
We swap theprepositions with their objects as demonstrated inthe following examples.Examples of reordering rules of PPs:Case 1: translate into Korean verbsP(?
)0 NP1 ?
NP1 P(?)0P(??
)0 IP1 ?
IP1 P(??)0P(??
)0 LCP1 ?
LCP1 P(??
)0Case 2: translate into other content wordsP(??
)0 IP1 ?
IP1 P(??)0P(??
)0 NP1 ?
NP1 P(??
)0Original parse tree:VPPP (P ?
)NP (NN ??
)PP (P ?
)NP (PN ??
)VP (VV ??
)NP (NN ??
)Reordered parse tree:VPNP (NN ??
)PP (P ?
)PP (P ?
)NP (PN ??
)VP (VV ??
)NP (NN ??
)1923.3 Modality-bearing wordsVerb affixes in Korean verbal phrases indicatemodality information such as tense, aspect, mood,negation, and voice.
The corresponding modalityinformation is implicitly or explicitly expressedin Chinese.
It is important to figure out what fea-tures are used to represent modality information.Li et al (2008) describes in detail the features inChinese that express modality information.However, since only lexical features can be reor-dered, we consider explicit modality featuresonly.Modality-bearing words are scattered over anentire sentence.
We move them near their verbalheads because their correspondences in Koreansentences are always placed right after theirverbs.When constructing reordering rules, we con-sider temporal adverbs, auxiliary verbs, negationparticles, and aspect particles only.
The follow-ing example sentences show the results of a fewof our reordering rules for modality-bearingwords.Examples of reordering rules of modality-bearing words:Original parse tree:VPADVP (AD ?)
?
Temporal adverbPP (P ?
)LCPNP (NN ??)
(NN ??)
(NN ??)(LC?
)VP (VV ??
)NP (NN ??
)Reordered parse tree:VPPP (P ?
)LCPNP (NN ??)
(NN ??)
(NN ??
)(LC ?
)ADVP (AD ?
)VP (VV ??
)NP (NN ??
)Original parse tree:VP (VV ?)
?
Auxiliary verbVPPP (P ?
)LCPNP (NN ??)
(NN ?
)(LC ?
)VP (VV ??
)Reordered parse tree:VPPP (P ?
)LCPNP (NN ??)
(NN ?
)(LC ?
)VP (VV ?
)VP (VV ??
)Original parse tree:VPADVP (AD ?)
?
Negation particleVP (VV ??)
?
Auxiliary verbVPPP (P ?
)NP (NN ???)
(NN ??
)VP (VV ??
)Reordered parse tree:VPPP (P ?
)NP (NN ???)
(NN ??
)ADVP (AD ?
)VP (VV ??
)VP (VV ??
)Generally speaking, Chinese does not havegrammatical forms for voice.
Although, voice isalso a grammatical category expressing modalityinformation, we have left it out of the currentphase of our experiment since voice detection isanother research issue and reordering rules forvoice are unavoidably complicated.4 ExperimentOur baseline system is a popular phrase-basedSMT system, Moses (Koehn et al, 2007), with5-gram SRILM language model (Stolcke, 2002),tuned with Minimum Error Training (Och, 2003).We adopt NIST (NIST, 2002) and BLEU (Papi-neni et al, 2001) as our evaluation metrics.Chinese sentences in training and test corporaare first parsed and are applied a series of syntac-tic reordering rules.
To evaluate the contributionof the three categories of syntactic reorderingrules, we perform the experiments applying eachcategory independently.
Experiments of variouscombinations are also carried out.4.1 Corpus profileWe automatically collected and constructed asentence-aligned parallel corpus from the online193Dong-A newspaper 4 .
Strictly speaking, it is anon-literally translated Korean-to-Chinese cor-pus.
The other corpus is provided by MSRA(Microsoft Research Asia).
It is a Chinese-Korean-English trilingual corpus of technicalmanuals and a literally translated corpus.Chinese sentences are segmented by StanfordChinese word segmenter (Tseng et al, 2005),and parsed by Stanford Chinese parser (Levy andManning, 2003).
Korean sentences are seg-mented into morphemes by an in-house morpho-logical analyzer.The detailed corpus profiles are displayed inTable 1 and 2.
The Dong-A newspaper corpus ismuch longer than the MSRA technical manualcorpus.
In Korean, we report the length of con-tent and function words.Training (99,226 sentences)Chinese Korean Content Function# of words 2,692,474 1,859,105 1,277,756# of singletons 78,326 67,070 514avg.
sen. length 27.13 18.74 12.88Development (500 sentences)Chinese Korean Content Function# of words 14,485 9,863 6,875# of singletons 4,029 4,166 163avg.
sen. length 28.97 19.73 13.75Test (500 sentences)Chinese Korean Content Function# of words 14,657 10,049 6,980# of singletons 4,027 4,217 164avg.
sen. length 29.31 20.10 13.96Table 1.
Corpus profile of Dong-A newspaper.Training (29,754 sentences)Chinese Korean Content Function# of words 425,023  316,289 207,909# of singletons 5,746 4,689 197avg.
sen. length 14.29 10.63 6.99Development (500 sentences)Chinese Korean Content Function# of words 6,380 4,853 3,214# of singletons 1,174 975 93avg.
sen. length 12.76 9.71 6.43Test (500 sentences)Chinese Korean Content Function4 http://www.donga.com/news/ (Korean) andhttp://chinese.donga.com/gb/index.html (Chinese)# of words 7,451 5,336 3,548# of singletons 1,182 964 99avg.
sen. length 14.90 10.67 7.10Table 2.
Corpus profile of MSRA technical ma-nual.4.2 Result and discussionThe experimental results are displayed in Table 3and 4.
Besides assessing the effectiveness ofeach reordering category, we test various combi-nations of the three categories.Method NIST BLEUBaseline 5.7801 20.49Reorder.VP 5.8402  22.12 (+7.96%)Reorder.PP 5.7773  20.10 (-1.90%)Reorder.Modality 5.7682  20.93 (+2.15%)Reorder.VP+PP 5.8176  21.96 (+7.17%)Reorder.VP+Modality 5.9198  22.24 (+8.54%)Reorder.All 5.9361 22.40 (+9.32%)Table 3.
Experimental results on the Dong-Anewspaper corpus.Method NIST BLEUBaseline 7.2596 44.03Reorder.VP 7.2238  44.57 (+1.23%)Reorder.PP 7.2793  44.22 (+0.43%)Reorder.Modality 7.3110  44.25 (+0.50%)Reorder.VP+PP 7.3401  45.28 (+2.84%)Reorder.VP+Modality 7.4246  46.42 (+5.43%)Reorder.All 7.3849  46.33 (+5.22%)Table 4.
Experimental results on the MSRAtechnical manual corpus.From the experimental result of the Dong-Anewspaper corpus, we find that the most effec-tive category is the reordering rules of VPs.When the VP reordering rules are combined withthe modality ones, the performance is even better.The gain of BLEU is not significant, but the gainof NIST is significant from 5.8402 to 5.9198.The PP reordering rules do not contribute to theperformance when they are singly applied.
How-ever, when combined with the other two catego-ries, they contribute to the performance.
The bestperformance is achieved when all three catego-ries?
reordering rules are applied and the relativeimprovement is +9.32% over the baseline system.In the MSRA corpus, the performance of vari-ous combinations of the three categories is betterthan those of the individual categories.
The PPcategory shows improvement when it is com-bined with the VP category.
The combination ofVP and modality category improves the perfor-mance by +5.43% over the baseline.194These results agree with our expectations: re-solving the word order and modality expressiondifferences of verbal phrases between Chineseand Korean is an effective approach.4.3 Error AnalysisWe adopt an error analysis method proposed byVilar et al (2006).
They presented a frameworkfor classifying error types of SMT systems.
(Ap-pendix B.
)Since our approach focuses on verbal phrasedifferences between Chinese and Korean, wecarry out the error analysis only on the verbalheads.
Three types of errors are considered:word order, missing words, and incorrect words.We further classify the incorrect words categoryinto two sub-categories: wrong lexicalchoice/extra word, and incorrect form of modali-ty information.
50 sentences are selected fromeach test corpus on which to perform the erroranalysis.
For each corpus, we choose the bestsystem: Reorder.All for the Dong-A corpus andReorder.VP+modality for the MSRA corpus.The most frequent error type is wrong wordorder in both corpora.
When a verb without anymodality information appears in a wrong position,we only count it as a wrong word order but notas a wrong modality.
Therefore, the number ofwrong modalities is not as frequent as it shouldbe.Table 5 and 6 indicate that our proposed me-thod helps improve the SMT system to reducethe number of error types related to verbal phras-es.Error type Frequency Baseline Reorder.Allwrong word order  34 7missing content word  18 5wrong lexical choice/extra word  6 1wrong modality  10 6Table 5.
Error analysis of the Dong-A newspapercorpus.Error typeFrequencyBaseline Reorder.
VP+Modalitywrong word order 19 11missing content word 4 2wrong lexical choice/extra word 8 3wrong modality  11 6Table 6.
Error analysis of the MSRA technicalmanual corpus.5 Conclusion and future workIn this paper, we proposed a Chinese syntacticreordering more suitable to adequately generateKorean verbal phrases in Chinese-to-KoreanSMT.
Specifically, we considered reorderingrules targeting Chinese VPs, PPs, and modality-bearing words that are closely related to Koreanverbal phrases.Through a contrastive analysis between thetwo languages, we first showed the difficulty ofgenerating Korean verbal phrases when translat-ing from a morphologically poor language, Chi-nese.
Then, we proposed a set of syntactic reor-dering rules to reorder Chinese sentences into amore Korean like word order.We conducted several experiments to assessthe contributions of our method.
The reorderingof VPs is the most effective, and improves theperformance even more when combined with thereordering rules of modality-bearing words.
Ap-plied to the Dong-A newspaper corpus and theMSRA technical manual corpus, our proposedapproach improved the baseline systems by9.32% and 5.43%, respectively.
We also per-formed error analysis with a focus on verbalphrases.
Our approach effectively decreased thesize of all errors.There remain several issues as possible futurework.
We only considered the explicit modalityfeatures and relocated them near the verbal heads.In the future, we may improve our system byextracting implicit modality features.In addition to generating verbal phrases, thereis the more general issue of generating complexmorphology in SMT systems targeting Korean,such as generating Korean case markers.
Thereare several previous studies on this topic (Min-kov et al, 2007; Toutanova et al, 2008).
Thisissue will also be the focus of our future work inboth the phrase- and syntax-based SMT frame-works.AcknowledgmentsThis work was supported in part by MKE & II-TA through the IT Leading R&D Support Projectand also in part by the BK 21 Project in 2009.ReferencesCharles N. Li, and Sandra A. Thompson 1996.
Man-darin Chinese: A functional reference grammar,University of California Press, USA.David Vilar, Jia Xu, Luis Fernando D?Haro, andHermann Ney.
2006.
Error Analysis of Statistical195Machine Translation Output.
In Proceedings ofLREC.Einat Minkov, Kristina Toutanova, and Hisami Suzu-ki.
2007.
Generating Complex Morphology forMachine Translation.
In Proceedings of ACL.Fei Xia and Michael McCord.
2004.
Improving a sta-tistical MT system with automatically learned re-write patterns.
In Proceedings of COLING.Huihsin Tseng, Pichuan Chang, Galen Andrew, Da-niel Jurafsky and Christopher Manning.
2005.
AConditional Random Field Word Segmenter.
InFourth SIGHAN Workshop on Chinese LanguageProcessing.HyoSang Lee 1991.
Tense, aspect, and modality: Adiscourse-pragmatic analysis of verbal affixes inKorean from a typological perspective, PhD thesis,Univ.
of California, Los Angeles.Jin-Ji Li, Ji-Eun Roh, Dong-Il Kimand Jong-HyeokLee.
2005.
Contrastive Analysis and Feature Selec-tion for Korean Modal Expression in Chinese-Korean Machine Translation System.
InternationalJournal of Computer Processing of Oriental Lan-guages, 18(3), 227--242.Jin-Ji Li, Dong-Il Kim and Jong-Hyeok Lee.
2008.Annotation Guidelines for Chinese-Korean WordAlignment.
In Proceedings of LREC.Kristina Toutanova, Hisami Suzuki, and AchimPuopp.
2008.
Applying Morphology GenerationModels to Machine Translation.
In Proceedings ofACL.Nianwen Xue, and Fei Xia.
2000.
The bracketingguidelines for the Penn Chinese Treebank (3.0).IRCS technical report, University of Pennsylvania.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese Treebank: Phrasestructure annotation of a large corpus.
NaturalLanguage Engineering, 11(2):207?238.Michael Collins, Philipp Koehn, and IvonaKu?cerov?a.
2005.
Clause restructuring for statis-tical machine translation.
In Proceedings of ACL,pages 531?540.NIST.
2002.
Automatic evaluation of machine trans-lation quality using n-gram co-occurrence statis-tics.Och, F. J.
2003.
Minimum error rate training in sta-tistical machine translation.
In Proceedings ofACL.Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris-Callison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, Ri-chard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstrantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of ACL, Demonstration Session.Roger Levy and Christopher D. Manning.
2003.
Is itharder to parse Chinese, or the Chinese Treebank?In Proceedings of ACL.Stolcke, A.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of ICSLP, 2:901-904.Appendix A. Tag for phrases in PennChinese Treebank.ADJP adjective phraseADVP adverbial phrase headed by AD (adverb)CLP  classifier phraseCP   clause headed by C (complementizer)DNP  phrase formed by ?XP+DEG?DP   determiner phraseDVP  phrase formed by ?XP+DEV?FRAG fragmentIP   simple clause headed by I (INFL)LCP  phrase formed by ?XP+LC?LST  list markerNP   noun phrasePP   preposition phrasePRN  parentheticalQP   quantifier phraseUCP  unidentical coordination phraseVP   verb phraseAppendix B.
Classification of translationerrors proposed by Vilar et al (2006).196
