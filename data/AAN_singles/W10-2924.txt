Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 203?212,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsJoint Entity and Relation Extraction using Card-Pyramid ParsingRohit J. Kate and Raymond J. MooneyDepartment of Computer ScienceThe University of Texas at Austin1 University Station C0500Austin, TX 78712-0233, USA{rjkate,mooney}@cs.utexas.eduAbstractBoth entity and relation extraction canbenefit from being performed jointly, al-lowing each task to correct the errors ofthe other.
We present a new method forjoint entity and relation extraction usinga graph we call a ?card-pyramid.?
Thisgraph compactly encodes all possible en-tities and relations in a sentence, reducingthe task of their joint extraction to jointlylabeling its nodes.
We give an efficient la-beling algorithm that is analogous to pars-ing using dynamic programming.
Exper-imental results show improved results forour joint extraction method compared to apipelined approach.1 IntroductionInformation extraction (IE) is the task of extract-ing structured information from text.
The twomost common sub-tasks of IE are extracting enti-ties (like Person, Location and Organization) andextracting relations between them (like Work Forwhich relates a Person and an Organization, Org-Based In which relates an Organization and a Lo-cation etc.).
Figure 1 shows a sample sentence an-notated with entities and relations.
The applica-tion domain and requirements of the downstreamtasks usually dictate the type of entities and rela-tions that an IE system needs to extract.Most work in IE has concentrated on entity ex-traction alone (Tjong Kim Sang, 2002; Sang andMeulder, 2003) or on relation extraction assum-ing entities are either given or previously extracted(Bunescu et al, 2005; Zhang et al, 2006; Giulianoet al, 2007; Qian et al, 2008).
However, thesetasks are very closely inter-related.
While iden-tifying correct entities is essential for identifyingrelations between them, identifying correct rela-tions can in turn improve identification of entities.For example, if the relation Work For is identifiedwith high confidence by a relation extractor, thenit can enforce identifying its arguments as Personand Organization, about which the entity extractormight not have been confident.A brute force algorithm for finding the mostprobable joint extraction will soon become in-tractable as the number of entities in a sentencegrows.
If there are n entities in a sentence, thenthere are O(n2) possible relations between themand if each relation can take l labels then there areO(ln2) total possibilities, which is intractable evenfor small l and n. Hence, an efficient inferencemechanism is needed for joint entity and relationextraction.The only work we are aware of for jointly ex-tracting entities and relations is by Roth & Yih(2004; 2007).
Their method first identifies the pos-sible entities and relations in a sentence using sep-arate classifiers which are applied independentlyand then computes a most probable consistentglobal set of entities and relations using linear pro-gramming.
In this paper, we present a different ap-proach to joint extraction using a ?card-pyramid?graph.
The labeled nodes in this graph compactlyencode the possible entities and relations in a sen-tence.
The task of joint extraction then reducesto finding the most probable joint assignment tothe nodes in the card-pyramid.
We give an ef-ficient dynamic-programming algorithm for thistask which resembles CYK parsing for context-free grammars (Jurafsky and Martin, 2008).
Thealgorithm does a beam search and gives an approx-imate solution for a finite beam size.
A naturaladvantage of this approach is that extraction froma part of the sentence is influenced by extractionfrom its subparts and vice-versa, thus leading to ajoint extraction.
During extraction from a part ofthe sentence it also allows use of features based onthe extraction from its sub-parts, thus leading to amore integrated extraction.
We use Roth & Yih?s203John lives in Los Angeles , California and works there for an American company called ABC Inc .Person Location LocationLive_InLocated_InWork_ForOrgBased_InOrgBased_InOther Organization0      1     2     3      4        5        6          7       8        9   10  11        12            13        14      15   16 17Live_InFigure 1: A sentence shown with entities and relations.Figure 2: A pyramid built out of playing-cards.
(2004; 2007) dataset in our experiments and showthat card-pyramid parsing improves accuracy overboth their approach and a pipelined extractor.2 Card-Pyramid Parsing for JointExtractionIn this section, we first introduce the card-pyramidstructure and describe how it represents entitiesand their relations in a sentence.
We then describean efficient algorithm for doing joint extraction us-ing this structure.2.1 Card-Pyramid StructureWe define a binary directed graph we call a card-pyramid because it looks like a pyramid built outof playing-cards as shown in Figure 2.
A card-pyramid is a ?tree-like?
graph with one root, in-ternal nodes, and leaves, such that if there aren leaves, then there are exactly n levels with adecreasing number of nodes from bottom to top,leaves are at the lowest level (0) and the root isat the highest level (n ?
1) (see Figure 3 for anexample).
In addition, every non-leaf node at po-Live_InLive_In NR OrgBased_InNR OrgBased_InWork_ForLocation Location Other OrganizationLocated_In NRNRLevel 1Level 2Level 3Level 4Person02100 10 1 3(0?0) (3?4) (6?6) (12?12) (15?16)0 1 2 3 42Level 0Figure 3: The card-pyramid for the sentence shown in Fig-ure 1.
Levels are shown by the horizontal lines under whichthe positions of its nodes are indicated.sition i in level l is the parent of exactly two nodesat positions i and i + 1 at level l ?
1.
Note thata card-pyramid is not a tree because many of itsnodes have two parents.
A useful property of acard-pyramid is that a non-leaf node at position iin level l is always the lowest common ancestor ofthe leaves at positions i and l + i.We now describe how entities and relations in asentence are easily represented in a card-pyramid.We assume that in addition to the given entitytypes, there is an extra type, Other, indicating thatthe entity is of none of the given types.
Similarly,there is an extra relation type, NR, indicating thatits two entity arguments are not related.Figure 3 shows the card-pyramid correspondingto the annotated sentence shown in figure 1.
To ob-tain it, first, all entities present in the sentence aremade leaves of the card-pyramid in the same orderas they appear in the sentence.
The label of a leafis the type of the corresponding entity.
The leafalso stores the range of the indices of its entity?swords in the sentence.
Note that although there isno overlap between entities in the given example(nor in the dataset we used for our experiments),204overlapping entities do not pose a problem.
Over-lapping entities can still be ordered and supplied asthe leaves of the card-pyramid.
Next, the relationbetween every two entities (leaves) is encoded asthe label of their lowest common ancestor.
If twoentities are not related, then the label of their low-est common ancestor is NR.
This way, every non-leaf node relates exactly two entities: the left-mostand right-most leaves beneath it.2.2 Card-Pyramid ParsingThe task of jointly extracting entities and rela-tions from a sentence reduces to jointly label-ing the nodes of a card-pyramid which has allthe candidate entities (i.e.
entity boundaries) ofthe sentence as its leaves.
We call this processcard-pyramid parsing.
We assume that all candi-date entities are given up-front.
If needed, candi-date entities can be either obtained automatically(Punyakanok and Roth, 2001) or generated usinga simple heuristic, like including all noun-phrasechunks as candidate entities.
Or, in the worst case,each substring of words in the sentence can begiven as a candidate entity.
Liberally includingcandidate entities is possible since they can sim-ply be given the label Other if they are none of thegiven types.In this section we describe our card-pyramidparsing algorithm whose pseudo-code is shownin Figure 4.
While the process is analogous tocontext-free grammar (CFG) parsing, particularlyCYK bottom-up parsing, there are several majordifferences.
Firstly, in card-pyramid parsing thestructure is already known and the only task islabeling the nodes, whereas in CFG parsing thestructure is not known in advance.
This fact sim-plifies some aspects of card-pyramid parsing.
Sec-ondly, in CFG parsing the subtrees under a nodedo not overlap which simplifies parsing.
How-ever, in card-pyramid parsing there is significantoverlap between the two sub-card-pyramids undera given node and this overlap needs to be consis-tently labeled.
This could have potentially com-plicated parsing, but there turns out to be a simpleconstant-time method for checking consistency ofthe overlap.
Thirdly, while CFG parsing parses thewords in a sentence, here we are parsing candi-date entities.
Finally, as described below, in card-pyramid parsing, a production at a non-leaf noderelates the left-most and right-most leaves beneathit, while in CFG parsing a production at a non-leafnode relates its immediate children which could beother non-leaf nodes.Parsing requires specifying a grammar for thecard-pyramid.
The productions in this grammarare of two types.
For leaf nodes, the produc-tions are of the form entityLabel ?
ce where ce,which stands for candidate entity, is the only ter-minal symbol in the grammar.
We call these pro-ductions entity productions.
For non-leaf nodes,the productions are of the form relationLabel ?entityLabel1 entityLabel2.
We call these produc-tions relation productions.
Note that their right-hand-side (RHS) non-terminals are entity labelsand not other relation labels.
From a trainingset of labeled sentences, the corresponding card-pyramids can be constructed using the proceduredescribed in the previous section.
From thesecard-pyramids, the entity productions are obtainedby simply reading off the labels of the leaves.
Arelation productions is obtained from each non-leaf node by making the node?s label the produc-tion?s left-hand-side (LHS) non-terminal and mak-ing the labels of its left-most and right-most leavesthe production?s RHS non-terminals.
For the ex-ample shown in Figure 3, some of the productionsare Work For?
Person Organization, NR?
Per-son Other, OrgBased In?
Loc Org, Person?
ce,Location ?
ce etc.
Note that there could be twoseparate productions like Work For ?
Person Or-ganization and Work For ?
Organization Personbased on the order in which the entities are foundin a sentence.
For the relations which take argu-ments of the same type, like Kill(Person,Person),two productions are used with different LHS non-terminals (Kill and Kill reverse) to distinguish be-tween the argument order of the entities.The parsing algorithm needs a classifier for ev-ery entity production which gives the probabil-ity of a candidate entity being of the type givenin the production?s LHS.
In the pseudo-code,this classifier is given by the function: entity-classifier(production, sentence, range).
The func-tion range(r) represents the boundaries or therange of the word indices for the rth candidateentity.
Similarly, we assume that a classifier isgiven for every relation production which givesthe probability that its two RHS entities are re-lated by its LHS relation.
In the pseudo-code it isthe function: relation-classifier(production, sen-tence, range1, range2, sub-card-pyramid1, sub-card-pyramid2), where range1 and range2 are the205ranges of the word indices of the two entitiesand sub-card-pyramid1 and sub-card-pyramid2are the sub-card-pyramids rooted at its two chil-dren.
Thus, along with the two entities and thewords in the sentence, information from these sub-card-pyramids is also used in deciding the relationat a node.
In the next section, we further spec-ify these entity and relation classifiers and explainhow they are trained.
We note that this use ofmultiple classifiers to determine the most probableparse is similar to the method used in the KRISPsemantic parser (Kate and Mooney, 2006).Given the candidate entities in a sentence, thegrammar, and the entity and relation classifiers,the card-pyramid parsing algorithm tries to findthe most probable joint-labeling of all of its nodes,and thus jointly extracts entities and their rela-tions.
The parsing algorithm does a beam searchand maintains a beam at each node of the card-pyramid.
A node is represented by l[i][j] in thepseudo-code which stands for the node in the jthposition in the ith level.
Note that at level i, thenodes range from l[i][0] to l[i][n?
i?
1], where nis the number of leaves.
The beam at each node isa queue of items we call beam elements.
At leafnodes, a beam element simply stores a possibleentity label with its corresponding probability.
Atnon-leaf nodes, a beam element contains a possi-ble joint assignment of labels to all the nodes inthe sub-card-pyramid rooted at that node with itsprobability.
This is efficiently maintained throughindices to the beam elements of its children nodes.The parsing proceeds as follows.
First, the en-tity classifiers are used to fill the beams at the leafnodes.
The add(beam, beam-element) functionadds the beam element to the beam while main-taining its maximum beam-width size and sortedorder based on the probabilities.
Next, the beamsof the non-leaf nodes are filled in a bottom-upmanner.
At any node, the beams of its childrennodes are considered and every combination oftheir beam elements are tried.
To be consideredfurther, the two possible sub-card-pyramids en-coded by the two beam elements must have a con-sistent overlap.
This is easily enforced by check-ing that its left child?s right child?s beam elementis same as its right child?s left child?s beam ele-ment.
If this condition is satisfied, then those re-lation productions are considered which have theleft-most leaf of the left child and right-most leafof the right child as its RHS non-terminals.1 Forevery such production in the grammar, 2 the prob-ability of the relation is determined using the re-lation classifier.
This probability is then multi-plied by the probabilities of the children sub-card-pyramids.
But, because of the overlap between thetwo children, a probability mass gets multipliedtwice.
Hence the probability of the overlap sub-card-pyramid is then suitably divided.
Finally, theestimated most-probable labeling is obtained fromthe top beam element of the root node.We note that this algorithm may not find theoptimal solution but only an approximate solu-tion owing to a limited beam size, this is unlikeprobabilistic CFG parsing algorithms in which theoptimal solution is found.
A limitless beam sizewill find the optimal solution but will reduce thealgorithm to a computationally intractable bruteforce search.
The parsing algorithm with a fi-nite beam size keeps the search computationallytractable while allowing a joint labelling.3 Classifiers for Entity and RelationExtractionThe card-pyramid parsing described in the previ-ous section requires classifiers for each of the en-tity and relation productions.
In this section, wedescribe the classifiers we used in our experimentsand how they were trained.We use a support vector machine (SVM) (Cris-tianini and Shawe-Taylor, 2000) classifier for eachof the entity productions in the grammar.
An entityclassifier gets as input a sentence and a candidateentity indicated by the range of the indices of itswords.
It outputs the probability that the candi-date entity is of the respective entity type.
Prob-abilities for the SVM outputs are computed usingthe method by Platt (1999).
We use all possibleword subsequences of the candidate entity wordsas implicit features using a word-subsequence ker-nel (Lodhi et al, 2002).
In addition, we usethe following standard entity extraction features:the part-of-speech (POS) tag sequence of the can-didate entity words, two words before and afterthe candidate entity and their POS tags, whetherany or all candidate entity words are capitalized,1These are stored in the beam elements.2Note that this step enforces the consistency constraint ofRoth and Yih (Roth and Yih, 2004; Roth and Yih, 2007) thata relation can only be between the entities of specific types.The grammar in our approach inherently enforces this con-straint.206function Card-Pyramid-Parsing(Sentence,Grammar,entity-classifiers,relation-classifiers)n = number of candidate entities in S// Let range(r) represent the range of the indices of the words for the rth candidate entity.// Let l[i][j] represent the jth node at ith level in the card-pyramid.// For leaves// A beam element at a leaf node is (label,probability).for j = 0 to n // for every leaffor each entityLabel ?
candidate entity ?
Grammarprob = entity-classifier(entityLabel ?
candidate entity, S, range(j))add(l[0][j].beam, (entityLabel,prob))// For non-leaf nodes// A beam element at a non-leaf node is (label,probability,leftIndex,rightIndex,leftMostLeaf,rightMostLeaf)// where leftIndex and rightIndex are the indices in the beams of the left and right children respectively.for i = 1 to n // for every level above the leavesfor j = 0 to n ?
i ?
1 // for every position at a level// for each combination of beam elements of the two childrenfor each f ?
l[i ?
1][j].beam and g ?
l[i ?
1][j + 1].beam// the overlapped part must be same (overlap happens for i > 1)if (i == 1||f.rightIndex == g.leftIndex)for each relationLabel ?
f.leftMostLeaf g.rightMostLeaf ?
Grammar// probability of that relation between the left-most and right-most leaf under the nodeprob = relation-classifier(relationLabel ?
f.leftMostLeaf g.rightMostLeaf , S, range(i), range(i + j), f , g);prob *= f.probability ?
g.probability // multiply probabilities of the children sub-card-pyramids// divide by the common probability that got multiplied twiceif (i > 1) prob /= l[i ?
2][j + 1].beam[f.rightIndex].probabilityadd(l[i][j].beam, (relationLabel, prob, index of f , index of g, f.leftMostLeaf , g.rightMostLeaf )return the labels starting from the first beam element of the root i.e.
l[n][0].beam[0]Figure 4: Card-Pyramid Parsing Algorithm.whether any or all words are found in a list of en-tity names, whether any word has sufffix ?ment?or ?ing?, and finally the alphanumeric pattern ofcharacters (Collins, 2002) of the last candidateentity word obtained by replacing each charac-ter by its character type (lowercase, uppercase ornumeric) and collapsing any consecutive repeti-tion (for example, the alphanumeric pattern forCoNLL2010 will be AaA0).
The full kernel iscomputed by adding the word-subsequence kerneland the dot-product of all these features, exploit-ing the convolution property of kernels.We also use an SVM classifier for each of therelation productions in the grammar which out-puts the probability that the relation holds betweenthe two entities.
A relation classifier is appliedat an internal node of a card-pyramid.
It takesthe input in two parts.
The first part is the sen-tence and the range of the word indices of its twoentities l and r which are the left-most and theright-most leaves under it respectively.
The sec-ond part consists of the sub-card-pyramids rootedat the node?s two children which represent a pos-sible entity and relation labeling for all the nodesunderneath.
In general, any information from thesub-card-pyramids could be used in the classifier.We use the following information: pairs of rela-tions that exist between l and b and between b andr for every entity (leaf) b that exists between thetwo entities l and r. For example, in figure 3,the relation classifier at the root node which re-lates Person(0-0) and Organization (15-16) willtake three pairs of relations as the informationfrom the two sub-card-pyramids of its children:?Live In?OrgBased In?
(with Location(3-4) asthe in-between entity), ?Live In?OrgBased In?
(with Location(6-6) as the in-between entity) and?NR?NR?
(with Other(12-12) as the in-betweenentity).
This information tells how the two enti-ties are related to the entities present in betweenthem.
This can affect the relation between the twoentities, for example, if the sentence mentions thata person lives at a location and also mentions thatan organization is based at that location then thatperson is likely to work at that organization.
Notethat this information can not be incorporated in apipelined approach in which each relation is de-termined independently.
It is also not possible toincorporate this in the linear programming methodpresented in (Roth and Yih, 2004; Roth and Yih,2007) because that method computes the probabil-ities of all the relations independently before find-ing the optimal solution through linear program-ming.
It would also not help to add hard con-straints to their linear program relating the rela-tions because they need not always hold.We add the kernels for each part of the input tocompute the final kernel for the SVM classifiers.The kernel for the second part of the input is com-puted by simply counting the number of common207pairs of relations between two examples thus im-plicitly considering every pair of relation (as de-scribed in the last paragraph) as a feature.
For thefirst part of the input, we use word-subsequencekernels which have shown to be effective for re-lation extraction (Bunescu and Mooney, 2005b).We compute the kernel as the sum of the word-subsequence kernels between: the words betweenthe two entities (between pattern), k (a parame-ter) words before the first entity (before pattern),k words after the second entity (after pattern) andthe words from the beginning of the first entity tothe end of the second entity (between-and-entitypattern).
The before, between and after patternshave been found useful in previous work (Bunescuand Mooney, 2005b; Giuliano et al, 2007).
Some-times the words of the entities can indicate the re-lations they are in, hence we also use the between-and-entity pattern.
When a relation classifier isused at a node, the labels of the leaves beneath itare already known, so we replace candidate entitywords that are in the between and between-and-entity3 patterns by their entity labels.
This pro-vides useful information to the relation classifierand also makes these patterns less sparse for train-ing.Given training data of sentences annotated withentities and relations, the positive and negative ex-amples for training the entity and relation clas-sifiers are collected in the following way.
First,the corresponding card-pyramids are obtained foreach of the training sentences as described in sec-tion 2.1.
For every entity production in a card-pyramid, a positive example is collected for itscorresponding classifier as the sentence and therange of the entity?s word indices.
Similarly, forevery relation production in a card-pyramid, a pos-itive example is collected for its correspondingclassifier as the sentence, the ranges of the twoentities?
word indices and the sub-card-pyramidsrooted at its two children.
The positive examplesof a production become the negative examples forall those productions which have the same right-hand-sides but different left-hand-sides.
We foundthat for NR productions, training separate classi-fiers is harmful because it has the unwanted side-effect of preferring one label assignment of enti-ties over another due to the fact that these pro-ductions gave different probabilities for the ?not-related?
relation between the entities.
To avoid3Except for the two entities at the endsthis, we found that it suffices if all these classi-fiers for NR productions always return 0.5 as theprobability.
This ensures that a real relation willbe preferred over NR if and only if its probabilityis greater than 0.5, otherwise nothing will change.4 ExperimentsWe conducted experiments to compare our card-pyramid parsing approach for joint entity and re-lation extraction to a pipelined approach.4.1 MethodologyWe used the dataset4 created by Roth & Yih (2004;2007) that was also used by Giuliano et el.
(2007).The sentences in this data were taken from theTREC corpus and annotated with entities and re-lations.
As in the previous work with this dataset,in order to observe the interaction between enti-ties and relations, our experiments used only the1437 sentences that include at least one relation.The boundaries of the entities are already suppliedby this dataset.
There are three types of entities:Person (1685), Location (1968) and Organization(978), in addition there is a fourth type Other(705), which indicates that the candidate entity isnone of the three types.
There are five types of re-lations: Located In (406) indicates that one Loca-tion is located inside another Location, Work For(394) indicates that a Person works for an Orga-nization, OrgBased In (451) indicates that an Or-ganization is based in a Location, Live In (521)indicates that a Person lives at a Location and Kill(268) indicates that a Person killed another Per-son.
There are 17007 pairs of entities that are notrelated by any of the five relations and hence havethe NR relation between them which thus signifi-cantly outnumbers other relations.Our implementation uses the LIBSVM5 soft-ware for SVM classifiers.
We kept the noisepenalty parameter of SVM very high (100) as-suming there is little noise in our data.
For theword-subsequence kernel, we set 5 as the max-imum length of a subsequence and 0.25 as thepenalty parameter for subsequence gaps (Lodhi etal., 2002).
We used k = 5 words for before andafter patterns for the relation classifiers.
These pa-rameter values were determined through pilot ex-periments on a subset of the data.
We used a beam4Available at: http://l2r.cs.uiuc.edu/?cogcomp/Data/ER/conll04.corp5http://www.csie.ntu.edu.tw/?cjlin/libsvm/208Entity Person Location OrganizationApproach Rec Pre F Rec Pre F Rec Pre FPipeline 93.6 92.0 92.8 94.0 90.3 92.1 87.9 90.6 89.2Card-pyramid 94.2 92.1 93.2 94.2 90.8 92.4?
88.7 90.5 89.5RY07 Pipeline 89.1 88.7 88.6 88.1 89.8 88.9 71.4 89.3 78.7RY07 Joint 89.5 89.1 89.0 88.7 89.7 89.1 72.0 89.5 79.2Relation Located In Work For OrgBased In Live In KillApproach Rec Pre F Rec Pre F Rec Pre F Rec Pre F Rec Pre FPipeline 57.0 71.5 62.3 66.0 74.1 69.7 60.2 70.6 64.6 56.6 68.1 61.7 61.2 91.1 73.1Card-pyramid 56.7 67.5 58.3 68.3 73.5 70.7 64.1 66.2 64.7 60.1 66.4 62.9?
64.1 91.6 75.2RY07 Pipeline 56.4 52.5 50.7 44.4 60.8 51.2 42.1 77.8 54.3 50.0 58.9 53.5 81.5 73.0 76.5RY07 Joint 55.7 53.9 51.3 42.3 72.0 53.1 41.6 79.8 54.3 49.0 59.1 53.0 81.5 77.5 79.0?Table 1: Results of five-fold cross-validation for entity and relation extraction using pipelined and joint extraction.
Boldfaceindicates statistical significance (p < 0.1 using paired t-test) when compared to the corresponding value in the other rowgrouped with it.
Symbol ?
indicates statistical significance with p < 0.05.
Only statistical significance for F-measures areindicated.
RY07 stands for the ?E ?
R?
model in (Roth and Yih, 2007).size of 5 in our card-pyramid parsing algorithm atwhich the performance plateaus.We note that by using a beam size of 1 and bynot using the second part of input for relation clas-sifiers as described in section 3 (i.e.
by ignoringthe relations at the lower levels), the card-parsingalgorithm reduces to the traditional pipelined ap-proach because then only the best entity label foreach candidate entity is considered for relation ex-traction.
Hence, in our experiments we simply usethis setting as our pipelined approach.We performed a 5-fold cross-validation to com-pare with the previous work with this dataset byRoth & Yih (2007), however, our folds are notsame as their folds which were not available.
Wealso note that our entity and relation classifiers aredifferent from theirs.
They experimented with sev-eral models to see the effect of joint inference onthem, we compare with the results they obtainedwith their most sophisticated model which theydenote by ?E ?
R?.
For every entity type andrelation type, we measured Precision (percentageof output labels correct), Recall (percentage ofgold-standard labels correctly identified) and F-measure (the harmonic mean of Precision and Re-call).4.2 Results and DiscussionTable 1 shows the results of entity and relation ex-traction.
The statistical significance is shown onlyfor F-measures.
We first note that except for theKill relation, all the results of our pipelined ap-proach are far better than the pipelined approachof (Roth and Yih, 2007), for both entities and rela-tions.
This shows that the entity and relation clas-sifiers we used are better that the ones they used.These strong baselines also set a higher ceiling forour joint extraction method to improve upon.The entity extraction results show that on allthe entities the card-pyramid parsing approach forjoint extraction obtains a better performance thanthe pipelined approach.
This shows that entityextraction benefits when it is jointly done withrelation extraction.
Joint extraction using card-pyramid parsing also gave improvement in perfor-mance on all the relations except the Located Inrelation.6The results thus show that entity and relation ex-traction correct some of each other?s errors whenjointly performed.
Roth & Yih (2004; 2007) re-port that 5% to 25% of the relation predictionsof their pipeline models were incoherent, meaningthat the types of the entities related by the relationsare not of the required types.
Their joint inferencemethod corrects these mistakes, hence a part of theimprovement their joint model obtains over theirpipeline model is due to the fact that their pipelinemodel can output incoherent relations.
Since thetypes of the entities a relation?s arguments should6Through error analysis we found that the drop in theperformance for this relation was mainly because of an un-usual sentence in the data which had twenty Location entitiesin it separated by commas.
After incorrectly extracting Lo-cated In relation between the Location entities at the lowerlevels, these erroneous extractions would be taken into ac-count at higher levels in the card-pyramid, leading to extract-ing many more incorrect instances of this relation while do-ing joint extraction.
Since this is the only such sentence in thedata, when it is present in the test set during cross-validation,the joint method never gets a chance to learn not to makethese mistakes.
The drop occurs in only that one fold andhence the overall drop is not found as statistically significantdespite being relatively large.209take are known, we believe that filtering out theincoherent relation predictions of their pipelinemodel can improve its precision without hurtingthe recall.
On the other hand our pipelined ap-proach never outputs incoherent relations becausethe grammar of relation productions enforce thatthe relations are always between entities of the re-quired types.
Thus the improvement obtained byour joint extraction method over our pipelined ap-proach is always non-trivial.5 Related WorkTo our knowledge, Roth & Yih (2004; 2007) havedone the only other work on joint entity and re-lation extraction.
Their method employs inde-pendent entity and relation classifiers whose out-puts are used to compute a most probable consis-tent global set of entities and relations using lin-ear programming.
One key advantage of our card-pyramid method over their method is that the clas-sifiers can take the output of other classifiers underits node as input features during parsing.
This isnot possible in their approach because all classi-fier outputs are determined before they are passedto the linear program solver.
Thus our approachis more integrated and allows greater interactionbetween dependent extraction decisions.Miller et al (2000) adapt a probabilisticcontext-free parser for information extraction byaugmenting syntactic labels with entity and rela-tion labels.
They thus do a joint syntactic parsingand information extraction using a fixed template.However, as designed, such a CFG approach can-not handle the cases when an entity is involvedin multiple relations and when the relations criss-cross each other in the sentence, as in Figure 1.These cases occur frequently in the dataset weused in our experiments and many other relation-extraction tasks.Giuliano et al (2007) thoroughly evaluate theeffect of entity extraction on relation extraction us-ing the dataset used in our experiments.
However,they employ a pipeline architecture and did not in-vestigate joint relation and entity extraction.
Carl-son et al (2009) present a method to simultane-ously do semi-supervised training of entity and re-lation classifiers.
However, their coupling methodis meant to take advantage of the available unsu-pervised data and does not do joint inference.Riedel et al (2009) present an approach for ex-tracting bio-molecular events and their argumentsusing Markov Logic.
Such an approach couldalso be adapted for jointly extracting entities andtheir relations, however, this would restrict entityand relation extraction to the same machine learn-ing method that is used with Markov Logic.
Forexample, one would not be able to use kernel-based SVM for relation extraction, which has beenvery successful at this task, because Markov Logicdoes not support kernel-based machine learning.In contrast, our joint approach is independent ofthe individual machine learning methods for en-tity and relation extraction, and hence allows useof the best machine learning methods available foreach of them.6 Future WorkThere are several possible directions for extend-ing the current approach.
The card-pyramid struc-ture could be used to perform other language-processing tasks jointly with entity and rela-tion extraction.
For example, co-reference res-olution between two entities within a sentencecan be easily incorporated in card-pyramid pars-ing by introducing a production like coref ?Person Person, indicating that the two personentities are the same.In this work, and in most previous work, re-lations are always considered between two enti-ties.
However, there could be relations betweenmore than two entities.
In that case, it shouldbe possible to binarize those relations and thenuse card-pyramid parsing.
If the relations are be-tween relations instead of between entities, thencard-pyramid parsing can handle it by consideringthe labels of the immediate children as RHS non-terminals instead of the labels of the left-most andthe right-most leaves beneath it.
Thus, it wouldbe interesting to apply card-pyramid parsing to ex-tract higher-order relations (such as causal or tem-poral relations).Given the regular graph structure of the card-pyramid, it would be interesting to investigatewhether it can be modeled using a probabilisticgraphical model (Koller and Friedman, 2009).
Inthat case, instead of using multiple probabilis-tic classifiers, one could employ a single jointly-trained probabilistic model, which is theoreticallymore appealing and might give better results.Finally, we note that a better relation classifiercould be used in the current approach which makesmore use of linguistic information.
For example,210by using dependency-based kernels (Bunescu andMooney, 2005a; Kate, 2008) or syntactic kernels(Qian et al, 2008; Moschitti, 2009) or by includ-ing the word categories and their POS tags in thesubsequences.
Also, it will be interesting to see ifa kernel that computes the similarity between sub-card-pyramids could be developed and used for re-lation classification.7 ConclusionsWe introduced a card-pyramid graph structure andpresented a new method for jointly extracting enti-ties and their relations from a sentence using it.
Acard-pyramid compactly encodes the entities andrelations in a sentence thus reducing the joint ex-traction task to jointly labeling its nodes.
We pre-sented an efficient parsing algorithm for jointlylabeling a card-pyramid using dynamic program-ming and beam search.
The experiments demon-strated the benefit of our joint extraction methodover a pipelined approach.AcknowledgmentsThis research was funded by Air Force ContractFA8750-09-C-0172 under the DARPA MachineReading Program.ReferencesRazvan C. Bunescu and Raymond J. Mooney.
2005a.
Ashortest path dependency kernel for relation extraction.
InProc.
of the Human Language Technology Conf.
and Conf.on Empirical Methods in Natural Language Processing(HLT/EMNLP-05), pages 724?731, Vancouver, BC, Oc-tober.Razvan C. Bunescu and Raymond J. Mooney.
2005b.
Sub-sequence kernels for relation extraction.
In Y. Weiss,B.
Scho?lkopf, and J. Platt, editors, Advances in Neural In-formation Processing Systems 18, Vancouver, BC.Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M. Mar-cotte, Raymond J. Mooney, Arun Kumar Ramani, andYuk Wah Wong.
2005.
Comparative experiments onlearning information extractors for proteins and their inter-actions.
Artificial Intelligence in Medicine (special issueon Summarization and Information Extraction from Med-ical Documents), 33(2):139?155.Andrew Carlson, Justin Betteridge, Estevam R. Hruschka,and Tom M. Mitchell.
2009.
Coupling semi-supervisedlearning of categories and relations.
In SemiSupLearn?09: Proceedings of the NAACL HLT 2009 Workshop onSemi-Supervised Learning for Natural Language Process-ing, pages 1?9, Boulder, Colorado.Michael Collins.
2002.
Ranking algorithms for named-entityextraction: Boosting and the voted perceptron.
In Proc.
ofthe 40th Annual Meeting of the Association for Computa-tional Linguistics (ACL-2002), pages 489?496, Philadel-phia, PA.Nello Cristianini and John Shawe-Taylor.
2000.
An Introduc-tion to Support Vector Machines and Other Kernel-basedLearning Methods.
Cambridge University Press.Claudio Giuliano, Alberto Lavelli, and Lorenza Romano.2007.
Relation extraction and the influence of automaticnamed-entity recognition.
ACM Trans.
Speech Lang.
Pro-cess., 5(1):1?26.D.
Jurafsky and J. H. Martin.
2008.
Speech and LanguageProcessing: An Introduction to Natural Lan guage Pro-cessing, Computational Linguistics, and Speech Recogni-tion.
Prentice Hall, Upper Saddle River, NJ.Rohit J. Kate and Raymond J. Mooney.
2006.
Using string-kernels for learning semantic parsers.
In Proc.
of the 21stIntl.
Conf.
on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguistics(COLING/ACL-06), pages 913?920, Sydney, Australia,July.Rohit J. Kate.
2008.
A dependency-based word subsequencekernel.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP 2008),pages 400?409, Waikiki,Honolulu,Hawaii, October.Daphne Koller and Nir Friedman.
2009.
ProbabilisticGraphical Models: Principles and Techniques.
The MITPress, Cambridge, MA.Huma Lodhi, Craig Saunders, John Shawe-Taylor, NelloCristianini, and Chris Watkins.
2002.
Text classificationusing string kernels.
Journal of Machine Learning Re-search, 2:419?444.Scott Miller, Heidi Fox, Lance A. Ramshaw, and Ralph M.Weischedel.
2000.
A novel use of statistical parsing toextract information from text.
In Proc.
of the Meeting ofthe N. American Association for Computational Linguis-tics, pages 226?233, Seattle, Washington.Alessandro Moschitti.
2009.
Syntactic and semantic ker-nels for short text pair categorization.
In Proceedings ofthe 12th Conference of the European Chapter of the ACL(EACL 2009), pages 576?584, Athens,Greece, March.John C. Platt.
1999.
Probabilistic outputs for support vec-tor machines and comparisons to regularized likelihoodmethods.
In Alexander J. Smola, Peter Bartlett, Bern-hard Scho?lkopf, and Dale Schuurmans, editors, Advancesin Large Margin Classifiers, pages 185?208.
MIT Press.Vasin Punyakanok and Dan Roth.
2001.
The use of classi-fiers in sequential inference.
In Advances in Neural Infor-mation Processing Systems 13.Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming Zhu,and Peide Qian.
2008.
Exploiting constituent depen-dencies for tree kernel-based semantic relation extraction.In Proceedings of the 22nd International Conference onComputational Linguistics (Coling 2008), pages 697?704,Manchester, UK, August.Sebastian Riedel, Hong-Woo Chun, Toshihisa Takagi, andJun?ichi Tsujii.
2009.
A Markov logic approach tobio-molecular event extraction.
In Proceedings of theBioNLP 2009 Workshop Companion Volume for SharedTask, pages 41?49, Boulder, Colorado, June.
Associationfor Computational Linguistics.211D.
Roth and W. Yih.
2004.
A linear programming formu-lation for global inference in natural language tasks.
InProc.
of 8th Conf.
on Computational Natural LanguageLearning (CoNLL-2004), pages 1?8, Boston, MA.D.
Roth and W. Yih.
2007.
Global inference for entity andrelation identification via a linear programming formula-tion.
In L. Getoor and B. Taskar, editors, Introduction toStatistical Relational Learning, pages 553?580.
The MITPress, Cambridge, MA.Erik F. Tjong Kim Sang and Fien De Meulder.
2003.
In-troduction to the CoNLL-2003 shared task: Language-independent named entity recognition.
In Proc.
of7th Conf.
on Computational Natural Language Learning(CoNLL-2003), Edmonton, Canada.Erik F. Tjong Kim Sang.
2002.
Introduction to the CoNLL-2002 shared task: Language-independent named entityrecognition.
In Proceedings of CoNLL-2002, pages 155?158.
Taipei, Taiwan.Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.
2006.A composite kernel to extract relations between entitieswith both flat and structured features.
In Proc.
of the 21stIntl.
Conf.
on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguistics(COLING/ACL-06), Sydney, Australia, July.212
