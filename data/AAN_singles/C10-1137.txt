Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1218?1226,Beijing, August 2010A Methodology for Automatic Identification of Nocuous AmbiguityHui Yang1            Anne de Roeck1            Alistair Willis1            Bashar Nuseibeh1, 21Department of Computing, The Open University2Lero, University of Limerick{h.yang, a.deroeck, a.g.willis, b.nuseibeh}@open.ac.ukAbstractNocuous ambiguity occurs when a lin-guistic expression is interpreted differ-ently by different readers in a given con-text.
We present an approach to auto-matically identify nocuous ambiguitythat is likely to lead to misunderstand-ings among readers.
Our model is builton a machine learning architecture.
Itlearns from a set of heuristics each ofwhich predicts a factor that may lead areader to favor a particular interpretation.An ambiguity threshold indicates the ex-tent to which ambiguity can be toleratedin the application domain.
Collections ofhuman judgments are used to train heu-ristics and set ambiguity thresholds, andfor evaluation.
We report results fromapplying the methodology to coordina-tion and anaphora ambiguity.
Resultsshow that the method can identify nocu-ous ambiguity in text, and may be wid-ened to cover further types of ambiguity.We discuss approaches to evaluation.1 IntroductionTraditional accounts of ambiguity have generallyassumed that each use of a linguistic expressionhas a unique intended interpretation in context,and attempted to develop a model to determine it(Nakov and Hearst, 2005; Brill and Resnik,1994).
However, disambiguation is not alwaysappropriate or even desirable (Poesio and Art-stein, 2008).
Ambiguous text may be interpreteddifferently by different readers, with no consen-sus about which reading is the intended one.
At-tempting to assign a preferred interpretation maytherefore be inappropriate.
Misunderstandingsamong readers do occur and may have undesir-able consequences.
In requirements engineeringprocesses, for example, this results in costly im-plementation errors (Boyd et al, 2005).Nonetheless, most text does not lead to sig-nificant misinterpretation.
Our research aims toestablish a model that estimates how likely anambiguity is to lead to misunderstandings.
Ourprevious work on nocuous ambiguity (Chantreeet al, 2006; Willis et al, 2008) cast ambiguitynot as a property of a text, but as a property oftext in relation to a set of stakeholders.
We drewon human judgments - interpretations held by agroup of readers of a text ?
to establish criteriafor judging the presence of nocuous ambiguity.An ambiguity is innocuous if it is read in thesame way by different people, and nocuous oth-erwise.
The model was tested on co-ordinationambiguity only.In this paper, we implement, refine and extendthe model.
We investigate two typical ambiguitytypes arising from coordination and anaphora.We extend the previous work (Willis et al,2008) with additional heuristics, and refine theconcept of ambiguity threshold.
We experimentwith alternative machine learning algorithms tofind optimal ways of combining the output of theheuristics.
Yang et al (2010a) describes a com-plete implementation in a prototype tool runningon full text.
Here we present our experimentalresults, to illustrate and evaluate the extendedmethodology.The rest of the paper is structured as follows.Section 2 introduces the methodology for auto-matic detection of nocuous ambiguity.
Sections3 and 4 provide details on how the model is ap-plied to coordination and anaphora ambiguity.Experimental setup and results are reported inSection 5, and discussed in Section 6.
Section 7reports on related work.
Conclusions and futurework are found in Section 8.12182 Methodology for Nocuous AmbiguityIdentificationThis section describes the main ideas underpin-ning our model of ambiguity.
We distinguishbetween structural and interpretative aspects.The former captures the fact that text may havestructure (i.e.
syntax) which, in principle, per-mits multiple readings.
These are relativelystraightforward to identify from the linguisticconstructs present in the text.
The latter ac-knowledges that if text is interpreted in the sameway by different readers, it has a low risk of be-ing misunderstood.
Modelling interpretive as-pects requires access to human judgments abouttexts.
Our approach has three elements, whichwe describe in turn: collection of human judg-ments; heuristics that model those judgments,and a machine learning component to train theheuristics.Human judgments.
We define an ambiguity asnocuous if it gives rise to diverging interpreta-tions.
Wasow et al (2003) suggests that ambigu-ity is always a product of the meaning that peo-ple assign to language, and thus a subjectivephenomenon.
We capture individual interpreta-tions of instances of ambiguity by surveying par-ticipants, asking them for their interpretation.We use this information to decide whether,given some ambiguity threshold, a particularinstance is seen as innocuous or nocuous de-pending on the degree of dissent between judges.A key concept in determining when ambiguityis nocuous is the ambiguity threshold.
Differentapplication areas may need to be more or lesstolerant of ambiguity (Poesio and Artstein, 2008).For instance, requirements documents describingsafety critical systems should seek to avoid mis-understandings between stakeholders.
Othercases, such as cookbooks, could be less sensitive.Willis et al (2008)?s general concept of ambigu-ity threshold sought to implement a flexible tol-erance level to nocuous ambiguity.
Given aninstance of ambiguous text, and a set of judg-ments as to the correct interpretation, the cer-tainty of an interpretation is the percentage ofreaders who assign that interpretation to the text.For example, in Table 1 below (sec.
3.1), thecertainty of the two interpretations, HA and LAof expression (a) are 12/17=71% and 1/17=5.9%respectively.
Here, an expression shows nocuousambiguity if none of the possible interpretationshave a certainty exceeding the chosen threshold.Later in this section, we will describe furtherexperiments with alternative, finer grained ap-proaches to setting and measuring thresholds,that affect the classifier?s behaviour.Heuristics.
Heuristics capture factors that mayfavour specific interpretations.
Each heuristicembodies a hypothesis, drawn from the literature,about a linguistic phenomenon signifying a pre-ferred reading.
Some use statistical information(e.g., word distribution information obtainedfrom a generic corpus, the BNC 1 , using theSketch Engine2).
Others flag the presence of sur-face features in the text, or draw on semantic orworld knowledge extracted from linguistic re-sources like WordNet3 or VerbNet4.Machine learning (ML).
Individual heuristicshave limited predictive power: their effective-ness lies in their ability to operate in concert.Importantly, the information they encapsulatemay be interdependent.
We harness this by usingML techniques to combine the outputs of indi-vidual heuristics.
ML is an established methodfor recognizing complex patterns automatically,making intelligent decisions based on empiricaldata, and learning of complex and nonlinear re-lations between data points.
Our model uses su-pervised learning ML techniques, deducing afunction from training data, to classify instancesof ambiguity into nocuous or innocuous cases.The classifier training data consists of pairs ofinput objects (i.e.
vectors made up of heuristicsscores) and desired outputs (i.e.
the class labelsdetermined by the distribution of human judg-ments as captured by thresholds).
To select anappropriate ML algorithm for the nocuity classi-fier, we tested our datasets (described in latersections) on several algorithms in the WEKA5package (e.g., decision tree, J48, Naive Bayes,SVM, Logistic Regression, LogitBoost, etc.
)To train, and validate, a nocuity classifier fora particular form of ambiguity, we build a data-set of judgments, and select heuristics that model1http://www.natcorp.ox.ac.uk/2http://sketchengine.co.uk/3http://wordnet.princeton.edu/4http://verbs.colorado.edu/~mpalmer/projects/verbnet.html5http://www.cs.waikato.ac.nz/~ml/index.html1219the information underlying the human judge-ments about a preferred interpretation.We validated the approach on two forms ofambiguity.
Sections 3 and 4 discuss how themethodology is applied to forms of coordinationand anaphoric ambiguity, and evaluate the per-formance of the final classifiers.3 Automatic Identification of NocuousCoordination AmbiguityOur previous work on nocuous ambiguity hasfocused on coordination ambiguity: a commonkind of structural ambiguity.
A coordinationstructure connects two words, phrases, or clausestogether via a coordination conjunction (e.g.,?and?, ?or?, etc) as in the following examples:(1) They support a typing system for architec-tural components and connectors.
(2) It might be rejected or flagged for furtherprocessing.In (1), the coordination construction ?architec-tural components and connectors?
consists of anear conjunct (NC) (i.e.
?components?
), a farconjunct (FC) (i.e.
?connectors?
), and the at-tached modifier (M) (i.e.
?architectural?).
Thisconstruction allows two bracketings correspond-ing to high modifier attachment ([architectural[components and connectors]]) or low modifierattachement ([[architectural components] andconnector]).
Our aim is to refine Chantree et al(2006) and Willis et al(2008), hence our focus ison the two phenomena they treated: modificationin noun phrase coordination (as in (1)) and inverb phrase coordination (as in (2)).We implemented the heuristics described inthe earlier work, and introduced two further ones(local document collocation frequency, and se-mantic similarity).
We used the Chantree et al(2006) dataset of human judgments, but em-ployed the LogitBoost algorithm for implement-ing the nocuity classifier (rather than the Logis-tic Regression equation).
The following subsec-tions give more detail.3.1 Building a datasetCoordination instances.
Our dataset was col-lected and described by Chantree et al (2006).
Itcontains 138 coordination instances gatheredfrom a set of requirement documents.
Nouncompound conjunctions account for the majority(85.5%) of cases (118 instances).
Nearly half ofthese arose as a result of noun modifiers, whilethere are 36 cases with adjective and 18 withpreposition modifiers.Human judgment collection.
The coordinationinstances containing potential ambiguity werepresented to a group of 17 computing profes-sionals including academic staff or research stu-dents.
For each instance, the judges were askedto select one of three options: high modifier at-tachment (HA), low modifier attachment (LA),or ambiguous (A).
Table 1 shows the judgmentcount for two sample instances.
In instance (a) intable 1, the certainty of HA is 12/17=71%, andthe certainty of LA is 1/17=6%.
Instance (b) wasjudged mainly to be ambiguous.JudgmentsHA LA A(a) security and privacy requirements 12 1 4(b) electrical characteristics and interface 4 4 9Table 1.
Judgment count for the sample instances (HA=high at-tachment; LA=low attachment; and A=Ambiguous)We set an ambiguity threshold, ?, to determinewhether the distribution of interpretations isnocuous or innocuous with respect to that par-ticular ?.
If the certainty of neither interpretation,HA or LA, exceeds the threshold ?, we say thisis an instance of nocuous coordination.
Other-wise it is innocuous.
Here, (a) displays nocuousambiguity for ?>71%.01020304050607080901000.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Ambiguity ThresholdsAmbiguities(%)InnoNocuFigure 1.
Proportions of interpretations at different ambiguitythresholds in the coordination instancesFigure 1 shows the systematic relationship be-tween ambiguity threshold and the incidence ofnocuous ambiguity in the dataset.
Low thresh-olds can be satisfied with a very low certaintyscores resulting in few instances being consid-ered nocuous.
At high thresholds, almost all in-stances are classified as nocuous unless thejudges report a consensus interpretation.12203.2 Heuristics to predict NocuityEach heuristic tests a factor favouring a high orlow modifier attachment (HA or LA).
We im-plemented and extended Willis et al (2008).Coordination matching favours HA when thehead words of near and far conjuncts are fre-quently found coordinated in a general corpuslike BNC, suggesting they may form a singlesyntactic unit.Distribution similarity measures how often twowords are found in the same contexts.
It favoursHA where it detects a strong distributional simi-larity between the headwords of the two con-juncts, suggesting these form a syntactic unit(Kilgariff 2003).Collocation frequency favours LA when themodifier is collocated much more frequentlywith the headword of the near conjunct than thefar conjunct, in the document, or in the BNC.Morphology favours HA when the conjunctheadwords share a morphological marker (suf-fix) (Okumura and Muraki 1994).Semantic similarity favours HA when the con-junct headwords display strong similarity in thetaxonomic structure in WordNet6.3.3 Nocuity classificationTo train, and test, the nocuity classifier, eachambiguity training/test instance is represented asan attribute-value vector, with the values set tothe score of a particular heuristic.
The class labelof each instance (nocuous (Y) or innocuous (N)at a given ambiguity threshold) is determined bythe certainty measure as discussed earlier.
Weselected the LogitBoost algorithm for buildingthe classifier, because it outperformed other can-didates on our training data than.
To determinewhether a test instance displays nocuity or not,we presented its feature vector to the classifier,and obtained a predicted class label (Y or N).4 Automatic Identification of NocuousAnaphora AmbiguityAn anaphor is an expression referring to an an-tecedent, usually a noun phrase (NP) found in6Implemented by the NLP tool - Java WordNet Similarity Library.http://nlp.shef.ac.uk/result/software.htmlthe preceding text.
Anaphora ambiguity occurswhen there are two or more candidate antece-dents, as in example (3).
(3) The procedure shall convert the 24 bit image toan 8 bit image, then display it in a dynamic window.In this case, both of the NPs, ?the 24 bit im-age?
and ?an 8 bit image?, are considered poten-tial candidate antecedents of the anaphor ?it?.Anaphora ambiguity is difficult to handle dueto contextual effects spread over several sen-tences.
Our goal is to determine whether a caseof anaphora ambiguity is nocuous or innocuous,automatically, by using our methodology.4.1 The building of the DatasetAnaphora instances.
We collected 200 anaph-ora instances from requirements documents fromRE@UTS website 7 .
We are specifically con-cerned with 3rd person pronouns, which arewidespread in requirements texts.
The datasetcontains different pronoun types.
Nearly halfthe cases (48%) involve subject pronouns, al-though pronouns also occurred in objective andpossessive positions (15% and 33%, respec-tively).
Pronouns in prepositional phrases (e.g.,?under it?)
are rarer (4% - only 8 instances).Human judgment collection.
The instanceswere presented to a group of 38 computing pro-fessionals (academic staff, research students,software developers).
For each instance, thejudges were asked to select the antecedent fromthe list of NP candidates.
Each instance wasjudged by at least 13 people.
Table 2 shows anexample of judgment counts, where 12 out of 13judges committed to ?supervisors?
as the antece-dent of ?they?, whereas 1 chose ?tasks?.1.
Supervisors may only modify tasks they supervise to theagents they supervise.ResponsePercentResponseCount(a) supervisors(b) tasks92.3%7.7%121Table 2.
Judgment count for an anaphora ambiguity instance.Ambiguity threshold.
Given an anaphor, theinterpretation certainty of a particular NP candi-date is calculated as the percentage of the judg-ments for this NP against the total judgments forthe instance.
For example, consider the examplein Table 2.
The certainty of the NP ?supervisors?7http://research.it.uts.edu.au/re/1221is 12/13=92.3% and the certainty of the NP?tasks?
is 1/13=7.7%.
Thus, at an ambiguitythreshold of, for instance, ?
= 0.8, the ambiguityin Table 2 is innocuous because the agreementbetween the judges exceeds the threshold.Figure 2 shows the relationship between am-biguity threshold and occurrence of nocuousambiguity.
As in Figure 1, the number of nocu-ous ambiguities increases with threshold ?.
Forhigh thresholds (e.g., ?
?0.9), more than 60% ofinstances are classified as nocuous.
Belowthreshold (?
?0.4), fewer than 8 cases are judgednocuous.
Also, comparing Figures 1 and 2 wouldappear to suggest that, in technical documents,anaphora ambiguity is less likely to lead to mis-understandings than coordination.01020304050607080901000.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Ambiguity ThresholdsAmbiguities(%)InnoNocuFigure 2.
Proportions of interpretations at different ambiguitythresholds in the anaphora instances.4.2 Antecedent Preference HeuristicsDrawing on the literature on anaphoric reference,we developed 12 heuristics of three types: re-lated to linguistic properties of text components,to context and discourse information, or to sta-tistical information drawn from standard corpora.Yang et al (2010b) gives more detail.
A heuris-tic marks candidate antecedents which it favours,or disfavours.
For instance, heuristics favourdefinite NPs as antecedents, candidate NPswhich agree in number and syntactic role withthe anaphor, and those which share a syntacticcollocation pattern in the text.
They also favourthose which respect the semantic constraints(e.g., animacy) propagated from subcategorisa-tion information, and reward proximity to theanaphor.
They disfavour candidate antecedentsthat occur in prepositional phrases, and thoseoccupying a syntactic role distinct from the ana-phor.
Note: not all NPs are marked by all heuris-tics, and some heuristics are interdependent.4.3 Nocuous Ambiguity IdentificationUnlike coordination ambiguity, where judgeschose for high or low modifier attachment,anaphora have scope over a variable set of po-tential antecedents, depending on each particularinstance.
To accommodate this, we developed anantecedent classifier which assigns a weightedantecedent tag to each NP candidate associatedwith an instance.
Tag information is used subse-quently to predict the whether the instance dis-plays nocuous ambiguity.The antecedent classifier is built using the Na-ive Bayes algorithm within the WEKA packageand is trained to return three classes of candidateantecedent: positive (Y), questionable (Q), ornegative (N).
In an innocuous case, a candidateNP will be classed as Y if its interpretation cer-tainty exceeds the threshold set by ?, and taggedas N otherwise; in a nocuous case, it will beclassed as N if its certainty is 0%, and classifiedas Q otherwise.1.
The LPS operational scenarios represent sequences of activi-ties performed by operations personnel as they relate to the LPSsoftware.Response Label(a) the LPS operational scenarios(b) sequences of activities(c) activities(d) operations personnel33.3%66.7%0%0%QQNNTable 3.
The determination of antecedent label for the NP candi-dates in a NOCUOUS ambiguity case (?
=0.8)2.
Testing performed to demonstrate to the acquirer that aCSCI system meets its specified requirements.ResponsePercentClassLabel(a) Testing(b) the acquirer(c) a CSCI system0%16.7%83.3%NNYTable 4.
The determination of antecedent label for the NP candi-dates in a INNOCUOUS ambiguity case (?
=0.8)Antecedent Class LabelY Q N?
= 0.5 181 54 623?
= 0.6 160 99 599?
= 0.7 137 149 572?
= 0.8 107 209 542?
= 0.9 77 261 520?
= 1.0 41 314 503Table 5.
The distribution of three antecedent class label at differentambiguity thresholdsTable 3 and 4 illustrate antecedent labels forNP antecedent candidates in a nocuous and in-nocuous case.
Candidates (a) and (b) in Table 3are labeled Q because their certainty falls belowthe threshold (?
= 0.8).
For the same threshold,candidate (c) in Table 4 is tagged as Y.
Table 51222shows the distribution of tags at certainty thresh-olds ?
?
0.5 for all (858) candidate antecedentsin our sample.Our intended application is a system to alertexperts to risk of misunderstandings.
This sug-gests we should emphasise recall even at the ex-pense of some precision (Berry et al 2003).
Wedeveloped two versions of the algorithm thatdetermines whether an instance is nocuous or not,depending on the contribution made by its ante-cedent candidates tagged Y.
We relax constraintsby introducing two concepts: a weak positivethreshold WYand a weak negative threshold WNset at 0.5 and 0.4, respectively8.
The rationale forweak thresholds is that antecedent preferencereflects a spectrum with Y (high), Q (medium),and N (low).
Weak positive and negative thresh-olds act as buffers to the Q area.
Antecedent NPsthat fall in the WYor WN buffer area are treatedas possible false negative (FN) for the classifica-tion of the label Q.
An antecedent tag Y/N is la-beled as weak positive or negative depending onthese thresholds.
The algorithm for identifyingnocuous ambiguity is given in Figure 3.
It treatsas innocuous those cases where the antecedentlabel list contains one clear Y candidate, whosecertainty exceeds all others by a margin.Given an anaphora ambiguity instance with multiple potential NPs,the antecedent classifier returns a label list, },,,{ 21 nrrrR K= , forindividual NPs.Parameters:1) WY- the threshold for the weak positive label.
The label Y isviewed as weak positive when the positive prediction score ri < WY2) WN- the threshold for the weak negative label.
The label N isviewed as weak negative when the negative prediction score ri <WNProcedure:if the label list R contains(one Y, no Q, one or more N )or(no Y, one Q, one or more N but not weak negative )or(one Y but not weak positive, any number of Q or N)thenthe ambiguity is INNOCUOUSelsethe ambiguity is NOCUOUSFigure 3.
The algorithm for nocuous ambiguity identification5 Experiments and ResultsIn all experiments, the performance was evalu-ated using 5-fold cross-validation, using  stan-8Weak positive and negative thresholds are set experimentally.dard measures of Precision (P), Recall (R), F-measure (F), and Accuracy.
We use two naivebaselines: BL-1 assumes that all ambiguity in-stances are innocuous; BL-2 assumes that theyare all nocuous.
For fair comparison against thebaselines, for both forms of ambiguity, we onlyreport the performance of our ML-based modelswhen the incidence of nocuous ambiguities fallsbetween 10% ~ 90% of the set (see Figures 1and 2).
We first report our findings for the iden-tification of nocuous coordination ambiguitiesand then discuss the effectiveness of our modelin distinguishing possible nocuous ambiguitiesfrom a set of ambiguity instances.5.1 Nocuous Coordination Ambiguity Iden-tificationWillis et al(2008) demonstrated the ability oftheir approach to adapt to different thresholds byplotting results against the two na?ve base lines.Since we extended and refined their approachdescribed we plot our experimental results (CM-1), for comparison, using the same measures,against their evaluation data (CM-2), in Figure 4.010203040506070809010040 45 50 55 60 65 70 75 80Ambiguity Threshold (%)Accuracy(%) BL-1BL-2CM-1CM-2Figure 4.
The performance comparison of the ML-based models,CM-1 and CM-2, to the two baseline models, BL-1 and BL-2, innocuous coordination ambiguity identification.Our CM-1 model performed well with an ac-curacy of above 75% on average at all ambiguitythreshold levels.
As expected, at very high andvery low thresholds, we did not improve on thenaive baselines (which have perfect recall andhence high accuracy).
The CM-1 model dis-played its advantage when the ambiguity thresh-old fell in the range between 0.45 and 0.75 (asignificantly wider range than reported for CM-2Willis et al(2008)).
CM-1 maximum improve-ment was achieved around the 58% crossoverpoint where the two na?ve baselines intersect andour model achieved around 21% increased accu-1223racy.
This suggests that the combined heuristicsdo have strong capability of distinguishingnocuous from innocuous ambiguity at the weak-est region of the baseline models.Figure 4 also shows that, the CM-1 modelbenefitted from the extended heuristics and theLogitBoost algorithm with an increased accuracyof around 5.54% on average compared with CM-2.
This suggests that local context informationand semantic relationships between coordinatingconjuncts provide useful clues for the identifica-tion of nocuous ambiguity.
Furthermore, theLogitBoost algorithm is more suitable for deal-ing with a numeric-attribute feature vector thanthe previous Logistic Regression algorithm.5.2 Nocuous Anaphora Ambiguity Identifi-cationWe report on two implementations: one withweak thresholds (AM-1) and one without (AM-2).
We compare both approaches using the base-lines, BL-1 and BL-2 (in Figure 5).
It shows thatAM-1 and AM-2 achieve consistent improve-ments on baseline accuracy at high thresholds(??0.75).
Here also, the improvement maximisesaround the 83% threshold point where the twobaselines intersect.
However, the ML-basedmodels perform worse than BL-1 at the lowerthresholds (0.5???0.7).
One possible explanationis that, at low thresholds, performance is affectedby lack of data for training of the Q class label,an important indicator for nocuous ambiguity(see Table 5).
This is also consistent with theML models performing well at higher thresh-olds, when enough nocuous instances are avail-able for training.010203040506070809010050 55 60 65 70 75 80 85 90 100Ambiguity Threshold (%)Accuracy(%)BL-1BL-2AM-1AM-2Figure 5.
The performance comparison of the ML-based models,AM-1 and AM-2, to the two baseline models, BL-1 and BL-2, innocuous anaphora ambiguity identification.Figure 5 further shows that the model withweak thresholds (AM-1) did not perform as wellas the model without weak thresholds (AM-2) onaccuracy.
Although both models perform muchbetter than the baselines on precision (more ex-perimental results are reported in Yang et al(2010b)), the actual precisions for both modelsare relatively low, ranging from 0.3 ~ 0.6 at dif-ferent thresholds.
When the AM-1 model at-tempts to discover more nocuous instances usingweak thresholds, it also introduces more falsepositives (innocuous instances incorrectlyclassed as nocuous).
The side-effect of introduc-ing false positives for AM-1 is to lower accu-racy.
However, the AM-1 model outperformsboth AM-2 and BL-2 models on F-measure(Figure 6), with an average increase of 5.2 and3.4 percentage points respectively.
This revealsthat relaxing sensitivity to the ambiguity thresh-old helps catch more instances of nocuousanaphora ambiguity.101520253035404550556050 55 60 65 70 75 80 85 90 100Ambiguity Threshold (%)F-measure(%) BL-2AM-1AM-2Figure 6.
The performance comparison of the ML-based models,AM-1 and AM-2, to the baseline model BL-2 (na?ve nocuous)6 DiscussionsWe presented judges with sentences containingambiguities without any surrounding context,even though contextual information (e.g., dis-course focus) clearly contributes to interpreta-tion.
This is a weakness in our data collectiontechnique.
Besides contextual information, vanDeemter?s Principle of Idiosyncratic Interpreta-tion (1998) suggests that some factors, includingthe reader?s degree of language competence, canaffect perceptions of ambiguity.
Similarly, fa-miliarity with a domain, including tacit specialistinformation (Polanyi, 1966), and the extent towhich this is shared by a group, will have an ef-fect on the extent to which stakeholders arrive atdiverging interpretations.In our case, we extracted instances from re-quirements documents covering several techni-1224cal domains.
Judgements are sensitive to thebackgrounds of the participants, and the extentto which stakeholder groups share such a back-ground.
Also, we used several large, generic NLresources, including the BNC and WordNet.
Theperformance of several heuristics would changeif they drew on domain specific resources.
Dif-ferent interpretations may be compatible, and sonot necessarily contribute to misunderstanding.Finally, we used different machine learningalgorithms to tackle different types of ambiguityinstances: LogitBoost for coordination ambigu-ity and Naive Bayes for anaphora ambiguity.The main reason is that coordination heuristicsreturned numeric values, whereas the anaphoraheuristics were Boolean.
Our method assumestailoring of the ML algorithm to the choice ofheuristic.
These limitations indicate that themethodology has a high degree of flexibility, butalso that it has several interdependent compo-nents and background assumptions that have tobe managed if an application is to be developed.7 Related WorkMany researchers have remarked on the fact thatsome ambiguities are more likely than others tolead to misunderstandings, and suggested classi-fying them accordingly.
Poesio (1996) discussedcases where multiple readings are intended tocoexist, and distinguished between language in-herent and human disambiguation factors from aphilosophical perspective.
His notion of ?per-ceived ambiguity?
suggests that human percep-tions are what actually cause an ambiguity to bemisunderstood.
Van Deemter?s (2004) ?viciousambiguity?
refers to an ambiguity that has nosingle, strongly preferred interpretation.
He pro-posed quantifying ?viciousness?
using probabili-ties taken from corpus data.
Van Rooy (2004)defined a notion of ?true ambiguity?
: a sentenceis truly ambiguous only if there are at least twointerpretations that are optimally relevant.
Theselast two approaches rely on probability analysisof language usage, and not directly on humanperception, which we believe to be the key toevaluating ambiguity.
Our work differs in that ittakes into account the distribution of interpreta-tions arrived at by a group of human judges en-gaged with a text.
Our model treats ambiguitynot as a property of a linguistic construct or atext, or a relation between a text and the percep-tions of a single reader, but seeks to understandthe mechanisms that lead to misunderstandingsbetween people in a group or process.Poesio et al(2006) have pointed out that dis-ambiguation is not always necessary; for in-stance, in some complex anaphora cases, the fi-nal interpretation may not be fully specified, butonly ?good enough?.
Our work does not attemptdisambiguation.
It seeks to highlight the risk ofmultiple interpretations (whatever those are).8 Conclusions and Future WorkWe have presented a general methodology forautomatically identifying nocuous ambiguity(i.e.
cases of ambiguity where there is a risk thatpeople will hold different interpretations) rela-tive to some tolerance level set for such a risk.The methodology has been implemented in aML based architecture, which combines a num-ber of heuristics each highlighting factors whichmay affect how humans interpret ambiguousconstructs.
We have validated the methodologyby identifying instances of nocuous ambiguity incoordination and anaphoric constructs.
Humanjudgments were collected in a dataset used fortraining the ML algorithm and evaluation.
Re-sults are encouraging, showing an improvementof approximately 21% on accuracy for coordina-tion ambiguity and about 3.4% on F-measure foranaphora ambiguity compared with naive base-lines at different ambiguity threshold levels.
Weshowed, by comparison with results reported inWillis et al(2008) that the methodology can befine tuned, and extended to other ambiguitytypes, by including different heuristics.Our method can highlight the risk of differentinterpretations arising: this is not a task a singlehuman could perform, as readers typically haveaccess only to their own interpretation and arenot routinely aware that others hold a differentone.
Nonetheless, our approach has limitations,particularly around data collection, and foranaphora ambiguity at low thresholds.
We en-visage further work on the implementation ofambiguity tolerance thresholdsSeveral interesting issues remain to be inves-tigated to improve our system?s performance andvalidate its use in practice.
We need to explorehow to include different and complex ambiguitytypes (e.g., PP attachment and quantifier scop-1225ing), and investigate whether these are equallyamenable to a heuristics based approach.AcknowledgementThis work is supported financially by UK EPSRC forthe MaTREx project (EP/F068859/1), and Irish SFIfor the grant 03/CE2/I303_1.ReferencesDaniel M. Berry, Erik Kamsties, and Michael M.Krieger.
2003.
From Contract Drafting to Soft-ware Specification: Linguistic Sources of Ambigu-ity.
Technical Report, School of Computer Sci-ence, University of Waterloo.Stephen Boyd, Didar Zowghi, and Alia Farroukh.2005.
Measuring the Expressiveness of a Con-strained Natural Language: An Empirical Study.
InProceedings of the 13th IEEE International Con-ference on Requirements Engineering (RE?05),Washington, DC, pages 339-52.Eric Brill and Philip Resnik.
1994.
A Rule-BasedApproach to Prepositional Phrase Attachment Dis-ambiguation.
In Proceedings of the 15th Interna-tional Conference on Computational Linguistics,pages 1198-204.Francis Chantree, Bashar Nuseibeh, Anne de Roeck,and Alistair Willis.
2006.
Identifying NocuousAmbiguities in Natural Language Requirements.In Proceedings of 14th IEEE International Re-quirements Engineering Conference (RE'06), Min-neapolis, USA, pages 59-68.Adam Kilgarriff.
2003.
Thesauruses for Natural Lan-guage Processing.
In Proceedings of NLP-KE,pages 5-13.Preslav Nakov and Marti  Hearst.
2005.
Using theWeb as an Implicit Training Set: Application toStructural Ambiguity Resolution.
In Proceedingsof HLT-NAACL?05, pages 835-42.Akitoshi Okumura and Kazunori Muraki.
1994.Symmetric Pattern Matching Analysis for EnglishCoordinate Structures.
In Proceedings of the 4thConference on Applied Natural Language Proc-essing, pages 41-46.Massimo Poesio.
1996.
Semantic Ambiguity and Per-ceived Ambiguity In Semantic Ambiguity and Un-derspecification edited by K. van Deemter and S.Peters, pages 159-201.Massimo Poesio and Ron Artstein.
2008.
Introductionto the Special Issue on Ambiguity and SemanticJudgements.
Research on Language & Computa-tion 6: 241-45.Massimo Poesio, Patick Sturt, Ron Artstein, and RuthFilik.
2006.
Underspecification and Anaphora:Theoretical Issues and Preliminary Evidence.
Dis-course Processes 42(2): 157-75.Michael Polanyi.
1966.
The Tacit Dimension.
RKP,London.Kees van Deemter.
1998.
Ambiguity and Idiosyn-cratic Interpretation.
Journal of Semantics 15(1):5-36.Kees van Deemter.
2004.
Towards a ProbabilisticVersion of Bidirectional Ot Syntax and Semantics.Journal of Semantics 21(3): 251-80.Robert van Rooy.
2004.
Relevance and BidirectionalOt.
In Optimality Theory and Pragmatic, edited byR.
Blutner and H. Zeevat, pages 173-210.Thomas Wasow, Amy Perfors, and David Beaver.2003.
The Puzzle of Ambiguity.
In Morphologyand the Web of Grammar: Essays in Menory ofSteven G. Lapointe, edited by O. Orgun and P.Sells.Alistair Willis, Francis Chantree, and Anne DeRoeck.
2008.
Automatic Identification of NocuousAmbiguity.
Research on Language & Computa-tion 6(3-4): 1-23.Hui Yang, Alistair Willis, Anne de Roeck, and Ba-shar Nuseibeh.
2010a.
Automatic Detection ofNocuous Coordination Ambiguities in NaturalLanguage Requirements.
In Proceedings of the25th IEEE/ACM International Conference onAutomated Software Engineering Conference(ASE?10).
(In press)Hui Yang, Anne de Roeck, Alistair Willis, and Ba-shar Nuseibeh.
2010b.
Extending Nocuous Ambi-guity Analysis for Anaphora in Natural LanguageRequirements.
In Proceedings of the 18th Interna-tional Requirements Engineering Conference(RE?10).
(In press)1226
