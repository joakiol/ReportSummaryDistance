SURFACE GRAMMATICAL ANALYSISFOR THE EXTRACTION OF TERMINOLOGICAL NOUN PHRASESDidier BOURIGAULTEcole des Hautes Etudes en Sciences SocialesetElectlicit6 de FranceDirection des Etudes et Recherches1, avenue du G6n6ral de Gaulle92141 Clamart CedexFranceTel : +33 1 47 65 50 64ABSTRACTLEXTER is a software package for extractingterminology.
A corpus of French language textson any subject field is fed in, and LEXTERproduces a list of likely terminological units tobe submitted to an expert to be validated.
Toidentify the terminological units, LEXTERtakes their form into account and proceeds intwo main stages : analysis, parsing.
In the firststage, LEXTER uses a base of rules designedto indentify frontier markers in view toanalysing the texts and extracting maximal-length noun phrases.
In the second stage,LEXTER parses these maximal-length nounphrases to extract subgroups which by virtue oftheir grammatical structure and their place in themaximal-length noun phrases are likely to beterminological units.
In this article, the type ofanalysis used (surface grammatical nalysis) ishighlighted, as the methodological pproachadopted to adapt the rules (experimentalapproach).I )  Const i tu t ingConstituting a terminology of a subject field,that is to say establishing a list of theterminological units that represent the conceptsof this field, is an oft-encountered problem.
Forthe Research Development Division ofElectricit6 de France (French Electricity Board),this problem arose in the informationdocumentation sector.
An automatic indexingsystem, using different thesauri according to theapplication, has been operational for three yearsor more \[Monteil 1990\].
The terminologists andinformation scientists need a terminologya te rmino logyextraction tool in order to keep these thesauri upto date in constantly changing fields and tocreate "ex nihilo" thesauri for new fields.This is the reason why the terminologicalextracting software, LEXTER, was developed,forming the first link in the chain that goes tomake up the thesaurus.
A corpus of french-language texts is fed into LEXTER, whichgives out a list of likely terminological units,which are then passed on to art expert forvalidation.AUlXS DE COLING-92, NANTES, 23-28 AO~r 1992 9 7 7 PROC.
OF COLING-92, NANTES, AUG. 23-28, 19922) What is a terminological unit ?The main aim here is not to provide a rigorousdefinition of what a terminological unit is, butrather to outline its essential features, and thusto justify the hypotheses (concerning the formof terminological units) on which LEXTER isbased.Semantic function : the representationof the conceptThe first characteristic of the terminological unitis its function as the representation of a concept.The terminological unit plays this role ofrepresentation in the framework of aterminology, which is the linguistic evidence ofthe organisation of a field of knowledge in theform of a network of concepts; theterminological unit represents a concept,uniquely and completely, taken out of anytextual context.
The existence of this one-to-onerelationship between a linguistic expression andan extra-linguistic object is, as we shall see, asituation which particulary concerns theterminological units.The appearance of a new terminological unit ismost often a parallel process to that of the birthof the concept which it represents.
This "birth"is marked by the consensus of a certainscientific ommunity.
This consensus i attestedonly when the occurrences of this linguisticexpression, or term-to-be, shows a stablecorrelation to the same object in the subjectfield, uniquely and completely, in the writingsof the agents of this scientific community.When this is the case, the object in questiontakes its place in the network describing thesubject field, and the expression takes on thestatus of a terminological unit.
This referentialfunction is, for E. Benveniste, the "synaptic"mark of a syntagm \[Benveniste 1966\].It is thus because occurrences in text of aterminological unit systematically refer to aconcept, that a relationship of representation isestablished, out of any textual context, betweenthe terminological unit and the concept.
Thisunderpins the specific status of theterminological unit as opposed to that of theword in language, a status close to that of adescriptor in Information Science (\[Le Guern1984\]).Syntactic form : synaptic compositionWe put forward the hypothesis that his functionof representing the concept out of context puts acertain number of constraints on the form thatterminological units may take on.
It has beenseen that he construction of terminological unitsobey well-known rules of syntactic formation,called synaptic composition (\[Benveniste1966\]).
For example : terminological units arenoun phrases, generally made up of nouns andadjectives, and pratically never containingconjugated verbs; the prepositions used mostoften are "de" and "~", rarely followed by adeterminer.To illustrate this, take the concept of a "screenbelonging to a portable computer".
Withoutgoing in to the linguistic phenomena behindthis, it can be said that, in context, both thesyntagms "l'rcran d'un ordinateur portable"("the screen of a portable computer") and "un6cran d'ordinateur portable" ("a portablecomputer screen") can refer generically to theconcept.
However, if one wished to representthis concept out of any textual context, thechances are that one would reject he expression"rcran d'un ordinateur portable", for wich theinterpretation of the article "un" may beambiguous, and accept he expression "6crand'ordinateur portable", more naturally used inisolation and thus more suitable to go into aterminology.From these considerations on the form and thefunction of terminological units, two mainsideas are relevant o developing a computerNLsed system of terminology constitution :1) It is possible to devise an extraction programsolely based on syntactic data, since thegrammatical form of terminological units isrelatively predictable;2) It is not possible to expect his program toextract terminological units and nothing else,given the basically referential semanticfunction of occurrences of terminologicalunits : this means that the results obtainedcan only be considered, a priori, as likelyterminological units.ACRES DE COL1NG-92, NAN'~S, 23-28 Aotrr 1992 9 7 8 PROC.
OF COLING-92, NANTES, AUG. 23-28, 19923) How LEXTER works : analysis and parsingTo detect erminological units, LEXTER takesthe form of these units into consideration, andworks in two phases : analysis and parsing.LEXTER treats categorized texts, which havebeen submitted to a morphological nalysis :each word is tagged with its grammaticalcategory (noun, verb, adjective, etc.
).Figure 1 : Simplified example of how LEXTER worksI (categorized) texts IUN TRAITEMENT DE TEXTE EST INSTALLE SUR LE DISQUE DUR DE LASTATION DE TRAVAILI analysisrules of frontier marker identificationverb ..... > frontier\[p re~.
(exce'~ t "de" et "a") + det.
..... > frontiermaximal-length noun phrasesTRAITEMENT DE TEXTEDISQUE DUR DE LA STATION DE TRAVAILparsingparsing rulesnouffladj prep det noun2 prep noun3nounl adjnoun2 fire D noun3\[ .
.
.
.
.
likely terminological unitsI TRAITEMENT DE TEXTEI DISQUE DUR DE LA STATION DE TRAVAIL\[ DISQUEDUR\[ STATIONDETRAVAILFirst step : analysis by identification offrontiersAt this stage, LEXTER takes advantages of"negative" knowledge about the form ofterminological units, by identifying thosegrammatical patterns which never go to makeup these units and which can thus be consideredpotential terminological limits.
Such patterns aremade up by, say, conjugated verbs, pronouns,conjonctions, certain strings of preposition +determiner, etc.The LEXTER analysis module is thus set upwith a base of rules for identifying frontiermarkers, which it uses to analyse the texts.
Thisanalysis phase produces a series of textsequences, most often noun phrases.
The waythe rules are worked out is presented in section5.These noun phrases may well be likelyterminological units themselves (as is the casewith TRAITEMENT DE TEXTE, in theexample in figure 1), but more often still, theycontain subgroups which are also likely units(such as DISQUE DUR DE LA STATION DETRAVAIL, which contains DISQUE DUR andSTATION DE TRAVAIL).
That is why it ispreferable at the analysis tage to refer to thenoun phrases identified as "maximal-lengthnoun phrases".Second stage : parsingthe maximal-length noun phrasesIt is thus necessary, in the second stage, toparse these maximal-length noun phrases inorder to obtain subgroups which are likelyterminological units by virtue of theirgrammatical structure and their position in themaximal-length noun phrase.
The LEXTERparsing module is made up of parsing ruleswhich indicate which subgroups to extract onthe basis of grammatical structure.
An exampleof a rule is given in figure 1.
In its presentform, the parsing module can recognize up to800 different structures, enabling it to treatA~F.S DE COLING-92.
NANTES, 23-28 AOt~r 1992 9 7 9 PROC.
OF COLING-92, NANTES.
AUG. 2.3-28, 1992around 95% of the maximal-length nounphrases obtained from our test corpus oncompletion of the analysis tage, that is around43,500 groups out of 46,000.
This module, thecore of LEXTER, is described more fully in\[Bouriganlt 1992b\].4) Sur face  grammat ica l  ana lys i s  versus  complete  syntact i c  analysisAt the beginning of the conceptual phase in thedevelopment of LEXTER, it was hypothesizedthat a complete syntactic analysis of thesentences of the corpus could be foregone,given the l imited aim of extractingterminological noun phrases with theircharacteristic grammatical structure.In LEXTER, the basic linguistic data is thegrammatical categoty of the lexical units whichmake up the sentences, and the analysis andparsing which make use of this data take intoaccount the surface form of utterance consideredas sequences of categorized units : only the"place" of the units in the surface sequence istaken into account and not their position (cf\[Milner 1989\]) in a syntactic structure.
This iswhy it is more accurate to speak of a surfacegrammatical analysis than of a completesyntactic analysis.The quality of the results obtained by thepresent prototype justify the non-necessity of acomplete syntactic analysis.
The advantages ofrestricting the analysis to surface structure areobvious : the program can deal with textswritten in styles that are not necessarilyacademic; it is sturdy and quick, not negligiblevirtues when it come to the development andextension stages.Although it is not necessary to go into acomplete syntactic analysis of the sentences toextract he terminology from a corpus, it wouldseem highly likely that a syntactic analyser(parser) would be much more efficient if itcould use a glossary of the terminological unitsof the subject area.
The syntactic structures of anatural language text, and the syntacticstructures of the terminological units,representing out of context, in a terminology,the concepts of a subject field, are to be placedon two different organisational levels.
It is thusadvisable to dissociate these two analysis,though using the results of one for the other.Since the terminological unit, as its namesuggests, is always a semantic unit, which is atthe basis of its status (cf ?1), it should betreated as such on the syntactic level as well.This makes it possible to envisage a textanalysis in two phases, the first identifyingterminological units, the second using theseresults to analyse the sentences syntactically,with the view to constructing a semanticrepresentation.
This is the principle which weintend to adopt o make LEXTER a text analysistool to aid knowledge acquisit ion (cf\[Bourigault 1992a\]).5) An experimental approach to work out rules of analysisTo analyse texts, LEXTER uses an analysis rulebase which detects frontier markers.
Some ofthese rules are simple : one of them detects allpunctuation marks; another all the wordsbelonging to certain grammatical categories :verbs, conjonctions, pronouns, etc.As well as theses imple rules, it is necessary toadd more complex rules which examinesequences of lexical units to find frontiers, inparticular to spot the boundaries between ounphrases that are complements of the same verbor the same noun.The constraint imposed by the choice of asurface grammatical nalysis make it difficult obase the detection of frontiers between nounphrases on reliable theorical morphosyntactichypothesis (even though the works of F. Debilishowed that this choice, for french language, ispertinent for computer processing \[Debili1982\]).
This is particulary so for the semantic-syntactic type of lexical information for thesubcategorization of verbs (nouns andadjectives as well) which must be foregone,making even more difficult the tricky task ofidentifying to what prepositional noun phrasesare attached.The alternative is then to rely on intuitive ideasand to compensate for the absence of theoricaljustification by adopting an empirical approachbased on large-scale corpus experimentation.Before any rule is put into one of LEXTER'smodules (rules of analysis, rules of parsing), itmust pass the test of the results it producesevery time it is applied to tile test corpus.ACRES DE COLING-92, NANTES, 23-28 AOOT 1992 9 8 0 PROC.
OF COLING-92.
NANTES, AUG. 23-28.
1992This is why it is necessary to work on a testcorpus of sufficient volume to be representativeof possible cases of analysis and parsing, and toproduce a sufficiently fast working software tomake this experimental pproach worthwhile.For this, a test corpus of 2 5000 pages(arround 1 200000 words) was used,gathered from 1 700 texts, in which thescientific officers of the Research DevelopmentDivision of Electricit6 de France describe in ashort paper (1 or 2 pages) each of their mediumterm research projects.
The analysis and parsingmodule of LEXTER were programmed in C,using lex and yacc tools in a Unix environment.Each of the stages of analysis and parsing isless than 2 minutes on a Sun work station,making very frequent tests easy and thuselmbling far reaching updathlg and ajustment.It is through an experimental pproach that theanalysing (and parsing) rules were worked out.By way of illustration, the analysis rulestreating the sequences preposition + determinerare presented in figure 2.Figure 2 : Analysis rules for the sequences : preposition + determiner0 LE, 'LA or LES UN, UNE orothersDE or A frontierothers frontier frontierIt is true too that these rules, as all the rules inLEXTER, have their limits and that there arecases where they apply (or do not apply)"wrongly".
These limitations come from thestrong hypotheses and the methodologicalchoices which have already been outlined.
Butin the field of Linguistic Engineerin.g,exceptions do not have the same status as mLinguistic Science; it is here a question ofcompromise.In the experimental pproach adopted, this riskof error is taken into account and kept undercontrol, as each rule is tested separately againstthe corpus, and it is the test of the number ofcases to which it applies which decides whetherit gets into LEXTER or not.
The principle is notto include rules of analysis which are too strict;it is preferable to drop a rule which isproductive in many cases (as for the ruleA + LE, LA or LES = frontier) if the numberof residual cases of erroneous analysis is toohigh.
This principle, called "of relativestrictness", is justified in that it will be easierfor the te~ninologist toeliminate certain likelyunits than to find real terminological units thatescaped etection by LEXTER6) Re ferences\[Benveniste 1966\] Benveniste Emile (1966)"Formes nouvelles de la compositionnominale", in Probldmes de linguistiquegdn~rale, Tome 2, PP 163-176, Gallimard,Paris\[Bourigault 1992a\] Bouriganlt  Didier(1992) "LEXTER, vers un outil liguistiqued'aide b. l'acquisition des connaissances", Actesdes 3dines Journ~es d'Acquisition desCot,naissances, Avri11992, Dourdan\[Bourigault 1992b\] Bonrigault  Didier(1992) "LEXTER, un logiciel d'extraction determinologie", Actes du symposium TAMA 92,Juin 1992, Avignon\[Debili t982\] Debili Fathi (1982), "Analysesyntaxico-stmantique fondte sur uneacquisition automatique de relations lexicalesstmantiques", Th~se d'6tat, Orsay\[Le Gueru 1984\] Le Guern Michel (1984),"Les descripteurs d'un systtme documentaire.Essai de definition", Actes du colloque"Traitement automatique des langues naturelleset syst~mes documentaires ", Clermont-Ferrand\[Milner 1989\] Milner Jean-Claude (1989),"Introduction ~t une science du langage", Scull,Paris\[Monteil 1990\] Monteil Marie Gaelle,P~not Nadine (1990), "IndexationAutomatique, fonctionnement - Principesgtntraux", Note interne HN46464, EDF,Direction des Etudes et Recherches, ServiceIPN, ClanlartAC'~E.S DE COLING-92, N^tcrs, 23-28 ,~o~ 1992 9 8 l Pgoc.
ov COLING-92, Nh~ES.
AUG. 23-28, 1992
