Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 8?17,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsAn Investigation for Implicatures in Chinese :Implicatures in Chinese and in English are similar !Lingjia DengIntelligent Systems ProgramUniversity of Pittsburghlid29@pitt.eduJanyce WiebeDepartment of Computer ScienceUniversity of Pittsburghwiebe@cs.pitt.eduAbstractImplicit opinions are commonly seen inopinion-oriented documents, such as po-litical editorials.
Previous work have uti-lized opinion inference rules to detectimplicit opinions evoked by events thatpositively/negatively affect entities (good-For/badFor) to improve sentiment analy-sis for English text.
Since people in differ-ent languages may express implicit opin-ions in different ways, in this work we in-vestigate implicit opinions expressed viagoodFor/badFor events in Chinese.
Thepositive results have provided evidencesthat such implicit opinions and inferencerules are similar in Chinese and in English.Moreover, we have observed cases wherethe inferences are blocked.1 IntroductionIn the opinion-oriented documents, many opin-ions are expressed implicitly rather than explicitly.Consider the following example from (Deng andWiebe, 2014):EX(1.1) The reform would lowerhealth care costs, which would be atremendous positive change across theentire health-care system.There is an explicit positive sentiment (positive)toward the event of reform lower costs.
In express-ing this sentiment, the writer implies he is nega-tive toward the costs, because he?s happy to see thecosts being decreased.
The writer may be positivetoward reform since it conducts the lower event.Such inferences may be seen as opinion-orientedimplicatures (i.e., defeasible inferences)1.1Implicatures ?normally accompany the utterances of agiven sentence unless special factors exclude that possibility(p.
39).?
(Huddleston and Pullum, 2002)We create an annotated corpus (denoted DCWcorpus) (Deng et al., 2013)2and generalizes suchevents, defining a badFor (bf) event to be anevent that negatively affects the object and a good-For (gf) event to be an event that positively af-fects the object of the event.
Here, lower is abf event.
According to the annotation scheme,goodFor/badFor (hereafter gfbf ) events have NPagents and objects (though the agent may be im-plicit), and the polarity of a gf event may bechanged to bf by a reverser (and vice versa).We have developed a set of rules for inferringimplicit sentiments, from explicit sentiments andgfbf events (Deng and Wiebe, 2014).
We incor-porate the rules into a graph-based model, whichsignificantly improves classifying the sentimentstoward agents and objects in the gfbf events.The contribution of this work is investigatingimplicatures in a second language, specifically inChinese.
People in different languages may ex-press implicit opinions in different ways, so it isbetter to first assess similarity of implicatures inthe two languages, rather than to directly utilizethe English resources.
In this work we conduct anagreement study for gfbf information in Chinese.The good agreement scores provide evidence forthe existence of similar implicature in Chinese.During the analysis of disagreement, we have ob-served interesting gfbf events triggered by Chinesesyntax, which are rare in English but common inChinese.
We should provide additional guidancefor such events when developing a Chinese gfbfmanual in the future.We run the graph-based model on the annotatedChinese corpus.
The good evaluation results sup-port our hypothesis that the inference rules in En-glish apply for Chinese.
Moreover, we have ob-served gfbf cases where the sentiment inferencesare blocked, which are similar to what we havefound in English (Wiebe and Deng, 2014).2Available at: http://mpqa.cs.pitt.edu/8Further, we analyze gfbf words and syntax ofagents/objects in Chinese.
Our analysis shows thatit is feasible to extract components of Chinese gfbfevents utilizing the existing resources.
In the lastsection we briefly talk bout the Chinese explicitsentiment analysis.2 Related WorkIn addition to researches focusing on explicit sen-timents (Wiebe et al., 2005; Johansson and Mos-chitti, 2013; Yang and Cardie, 2013), recentlythere are work investigating features that directlyindicate implicit sentiments (Zhang and Liu, 2011;Feng et al., 2013), or working on inferring implicitopinions (Choi and Cardie, 2008; Zhang and Liu,2011; Anand and Reschke, 2010; Reschke andAnand, 2011; Goyal et al., 2013).
Different fromtheir work, which do not cover all the inferences ofimplicit opinions over explicit opinions and gfbfevents, we define a generalized set of inferencerules and incorporate the rules into a graph-basedmodel to achieve sentiment propagation betweenthe agents and objects of gfbf events (Deng andWiebe, 2014).
The result shows that the graph-based model itself is able to assign the unknownnodes with correct labels 89% of the time.Many works in Chinese sentiment analysis de-velop heuristics for adapting methods in Englishto methods appropriate for Chinese (Tsou et al.,2005; Wang et al., 2007; Li and Sun, 2007).
In-stead of projecting English methods and resourcesinto Chinese versions, there are also works lever-aging Chinese-English parallel corpus to assistChinese sentiment analysis.
Wan (2008) trans-lates Chinese sentiment sentences into English andensemble the sentiment classification results fromboth English and Chinese sentiment classifiers.Wan (2009) adopt co-training methods, utilizinglabeled English sentences and unlabelled Chinesesentences.
Lu et al.
(2011) assumes parallel sen-tences in different languages bear the same sen-timent.
They utilize unlabelled Chinese-Englishparallel corpus to jointly improve sentiment clas-sification in both languages.
Boyd-Graber andResnik (2010) present a generative model, jointlymodeling topics that are consistent across lan-guages, to improve sentiment rating predictions.3 Implicature in ChineseThe definition of a gfbf event is from (Deng etal., 2013).
A goodFor (gf) event is an event thatpositively affects an entity (similarly, for badFor(bf) events).
A gfbf triple has the structure of ?agent, gfbf, object?, though the agent can be im-plicit.
For example, in the sentence from (Denget al., 2013), ?Repealing the Affordable Care Act(ACA) would hurt our economy.
?, there are twogfbf triples.
One is ?Repealing the ACA, hurt,families, our economy?, which is a bf.
The otheris ?implicit, Repealing, the ACA?, which is bf andthe agent is implicit.
The DCW corpus containsmanually annotated gfbf events, the gfbf polari-ties, the corresponding agents and objects and thewriter?s attitudes toward the agents and objects.Because people in different languages may ex-press their opinions in different ways.
In this sec-tion, we conduct an agreement study for Chinesegfbf information in Section 3.1 and achieve goodagreement scores, reported in Section 3.2, whichprovide supporting evidences for detecting Chi-nese gfbf events.
In the disagreement analysis,we have observed interesting cases which are gfbfevents in semantics but are triggered by Chineseown syntax.
We explain the cases in Section 3.3.3.1 Agreement Study DesignData: We collect 100 political editorials from theOpinion Column in the Chinese version of NewYork Times3, where each political editorial has anEnglish version and a Chinese version.
The Chi-nese editorial is a translated and paraphrased ver-sion of the corresponding English editorial, writ-ten by professional translators.
The English ver-sion and the Chinese version are paragraph paral-leled.
In the previous agreement study of (Deng etal., 2013), the annotators are asked to annotate thewhole document.
Because not all the sentencescontain gfbf events and the documents are long,a large proportion of disagreement we find that isdue to negligence.
In order to reduce negligenceand provide a more dense data for annotation, first,we collect a lexicon of English gfbf words in theDCW corpus.
Then we find the English sentencescontaining English gfbf words and select the para-graphs containing those sentences.
The parallelChinese paragraphs are collected.
Though a para-graph may contain more than one sentence andsome sentences do not have gfbf events, it is muchmore dense to annotate than the document as awhole.
When presenting data to the annotators, wedo not provide an isolated paragraph since it may3http://cn.nytimes.com/opinion/9lose the context information.
Instead, we presentthe original Chinese editorials and highlight theselected paragraphs.
The annotators are told toread through the whole document but only needto annotate the highlighted paragraphs.Procedure: We adopt our English manual in(Deng et al., 2013) to train the annotators.
Theannotators read through the manual and severalChinese gfbf examples.
Then, the annotators la-bel several paragraphs and discuss their disagree-ments to reconcile their differences.
For the for-mal agreement study, we randomly selected 60paragraphs, which have a total of 253 Chinese sen-tences.
These paragraphs are different from theparagraphs discussed during training.
The annota-tors then independently annotated the 60 selectedparagraphs.3.2 Agreement Study Evaluation and ResultWe use the same measurement for agreement forall types of spans.
(The type is either gfbf, agent,or object).
Suppose A is a set of annotations ofa particular type and B is the set of annotationsof the same type from the other annotator.
Forany text span a ?
A and b ?
B, the span cov-erage c counts the percentage of overlapping Chi-nese characters between a and b,c(a, b) =|a ?
b||b|(1)where |a| is the number of characters in span a,and ?
gives the set of characters that two spanshave in common (Johansson and Moschitti, 2013).Following (Wilson and Wiebe, 2003), we treateach set A and B in turn as the gold-standard andcalculate the average F-measure (agr(A,B)).agr(A||B) =?a?A,b?B,|a?b|>0c(a, b)|B|(2)agr(A,B) =agr(A||B) + agr(B||A)2(3)Now that we have the sets of annotations onwhich the annotators agree, we use ?
(Artsteinand Poesio, 2008) to measure agreement for the at-tributes.
We report three ?
values: one for the po-larities of the gfbf events, and the other two for thewriter?s attitudes toward the agents and objects.Three annotator participate in the agreementstudy.
All of them are Chinese graduate studentsstudying in US.
One of them is the co-authorof this work (Anno 1), while the other two doagr(A,B) gfbf agent objectAnno 1& 2 0.7929 0.9091 0.9091Anno 1 & 3 0.7044 0.9524 1.0gfbf agent object?
polarity attitude attitudeAnno 1 & 2 0.9385 0.7830 0.7238Anno 1 & 3 0.8966 0.5913 0.8478Table 1: Results for Agreement Study Analysis.not know details of gfbf and implicature before(Anno2, Anno3).
Since Anno1 is familiar with thiswork, we compare the other two?s annotations toAnno1?s.
In Table 1, the upper half is the agree-ment for span overlapping (agr(A,B)), and thelower half is the agreement for attribute (?
).The result have shown that the annotators havegood agreement scores, though our training periodis not long and our training data cover multipletopics.
In particular, the annotators agree quitewell on recognizing the agents and objects andjudging the polarity of gfbf events.For recognizing gfbf events, we have found twointeresting gfbf cases caused by the Chinese syn-tax that is different from English, elaborated in thenext section.
Among the spans only one annota-tor marks, one third is due to the two cases above;one third are borderlines that could be marked; onethird are incorrect.
For the spans two annotatormark but the third doesn?t, we regard it as negli-gence.For judging the writer?s attitudes toward agentsand objects, we can see from Table 1 that Anno 2and Anno 3 behave differently.
This is understand-able because we are marking the implicit opinionsof the writer.
Though trained, different annotatorshave different thresholds for judging whether anopinion is expressed here.
Some annotators maybe more sensitive than the others.
If we don?tcount the spans that one annotator marks it as none(i.e.
neutral) but the other doesn?t, the ?
scores in-crease a lot, as Row Polar shows in Table 2.
Thisindicates that the annotators mainly disagree onwhether the sentiment is neutral or not, rather thanthe polarity of opinions.To further investigate whether the disagreementis caused by Chinese, or is due to the annotators?inherent different sensitivities of opinions, we ran-domly select 5 documents from the DCW corpus,delete the writer?s attitude toward agents and ob-jects but keep the remaining annotations.
The an-10Anno 1 & 2 Anno 1& 3agent object agent objectTable 1 0.783 0.723 0.591 0.848Polar 0.875 0.915 1 0.88Eng 0.738 0.652 0.4633 0.8734Table 2: ?
for Agreement Study Analysis.notators are then told to mark the attitudes.
AsRow Eng in Table 2 shows, we have got consis-tent agreement results within the same annotatorswhen they annotate in English and in Chinese.This supports the idea that the differences betweenthe annotators are differences on the underlyingtask, regardless of the language.3.3 GoodFor/Badfor Triggered by ChineseSyntaxDuring the analysis of disagreement, we havefound gfbf cases which are triggered by the Chi-nese syntax that is different from English.
Sincethe annotators are trained by the English manual,some annotators stay consistent with the Englishsyntax, but the others go beyond syntax and iden-tify gfbf according to semantics and pragmatics,which lead to disagreement.
In this section we listtwo major cases due to the Chinese own syntax.This suggests that additional guidance to annotatesuch cases should be added to the English manualto develop a Chinese gfbf manual.The first case is due to unclear expression ofpassive voice in Chinese.
In English, the nounphrase that would be the object of an active sen-tence (Our troops defeated the enemy) appears asthe subject of a sentence with passive voice (Theenemy was defeated by our troops)4.
It is clearthat enemy is the object and our troops is the agentin both sentences.
However, this is not intuitivefor some Chinese sentences.A Chinese example is ?
??????????
?, whose English translation is: ?The economicpotential ... appeared to be unleashed?.
A word-to-word translation would be ?...appeared to havegot unleashed?.
In the two English versions, po-tential is obviously the object of unleashed event.However, some annotators analyze this sentenceaccording to syntax5.
The dependency syntax be-tween the object potential (??)
and the gfbf un-leash (??)
is nsubj(?
?-5, ?
?-2) so it is not4http://en.wikipedia.org/wiki/English passive voice.5We use Stanford?s dependency parser in this work.marked.
Some annotators view from pragmaticsand read as a passive voice.
Since there is no wordtransformation of Chinese verbs for passive voice(e.g.
unleash changes to unleashed in English),this raises disagreement.The other case is related to one constraint de-fined in (Deng et al., 2013).
According to themanual, the polarity of a gfbf triple must be de-termined within the triple.
As explained in themanual, in the sentence ?Tom has left his cousina big trouble?, the triple ?Tom, left, his cousin?
isnot a gfbf event, since we cannot judge whetherthis event is good for or bad for his cousin withoutknowing what Tom leaves to his cousin.
Whilein the sentence ?They decrease the manufacturingcosts?, the event decrease is a bf no matter howmany or by what means the costs are decreased.However, a Chinese instance is, ????????
?, whose translation is ?put the reform todie?.
Whether the event put (?)
is good for or badfor the object reform (??
), depends on whetherthe agent puts the reform to die or puts the reformto revive, for instance.
However, in Chinese, ?is not main verb (Li and Thompson, 1989), theobject (?
?, reform) of the main verb (???
?, die) is placed after the function word (?
), andthe verb is placed after the object, forming a sub-ject?object?verb (SOV) sentence (Chao, 1968)6,which is defined as ba structure (Chao, 1968; Liand Thompson, 1989; Sybesma, 1992).
Thus, inChinese the sentence is read as: ?kill the reform?,which could be seen as a gfbf event.
This structureis very common in Chinese.In conclusion, there are very similar implica-tures in Chinese.
However, in order to fully studythe gfbf events in Chinese, the manual shouldbe revised to provide guidance for annotating thecases mentioned above.4 Implicature Inference in ChineseWe propose a set of sentiment inference rules andincorporate them into a graph-based model to con-duct sentiment propagation among entities (agentsand objects) of gfbf events (Deng and Wiebe,2014).
In Section 4.1, we run this graph-basedmodel on the Chinese annotations.
The positiveresults of sentiment propagation support our hy-pothesis that the inference rules apply for Chineseas well.
Further, we categorize interesting gfbfcases where the inferences are blocked in Section6http://en.wikipedia.org/wiki/B%C7%8E construction.114.2.
From our observation, the blocking infer-ences are similar to what we have found in English(Wiebe and Deng, 2014).4.1 Graph-based ModelIn the graph-based model, a node represents an en-tity (agent, or object), and an edge exists betweentwo nodes if the two entities participate in one ormore gfbf events with each other.
Scores on thenodes represent the explicit sentiments, if any, ex-pressed by the writer toward the entities.
Scoreson the edges are based on constraints derived fromthe rules.
Loopy Belief Propagation (Pearl, 1982;Yedidia et al., 2005) is applied to accomplish sen-timent propagation in the graph.
Given a graphbuilt from manually annotations, an evaluation iscarried out to assess the ability to propagate sen-timent of the model.
In the study, for each sub-graph (connected component), we assign one ofthe nodes in the subgraph with its gold-standardpolarity.
Then we run LBP on each node in thesubgraph.
The experiment is run on the subgraph|S| times, where |S| is the number of nodes inthe subgraph.
Therefore, each node is assignedits gold-standard polarity exactly once, and eachnode is given a propagated value |S| ?
1 times, aspropagated by each of the other nodes in its sub-graph.
We use Equations (4) and (5) to evaluatethe chance of a node given a correct propagatedlabel.correct(a|b) ={1 a is correct0 otherwise(4)correctness(a) =?b?Sa,b 6=acorrect(a|b)|Sa| ?
1(5)Here we run the graph-based model on the Chi-nese annotations.
The data we use include thetraining and testing paragraphs in the agreementstudy, in total 85 paragraphs, 341 sentences and160 gfbf triples.
Later we use this corpus of 160gfbf triples for analysis (denoted Chinese gfbf cor-pus).
Since the edge scores of the model are de-fined according to the inference rules, if the senti-ments are propagated correctly, this is a good evi-dence that the inference rules apply to Chinese.The performances of the sentiment propagationare really good, reported in Table 3.
The modelhas an 70%-83% chance of propagating senti-ments correctly in Chinese.
This gives us confi-dence that the inference rules apply in Chinese andDataset # subgraph correctnessall subgraphs 136 0.7058multi-node subgraphs 61 0.8251Table 3: Performance of Graph-Based Model inChinese.further we can utilize these rules to assist Chinesesentiment analysis.
Compared to the scores ofcorrectness reported in (Deng and Wiebe, 2014),which are 0.8874 for all subgraphs and 0.9030 formulti-node subgraphs, our scores are lower.
Weanalyze the reasons for the gap between our scoresin Chinese and in English in the next section.4.2 Blocking the InferenceA wrong propagation indicates the inferences re-lated to that propagation are blocked.
During theerror analysis, we have found three interesting cat-egories of cases where the inferences are blocked.Interestingly, we have observed these cases in En-glish as well (Wiebe and Deng, 2014).
In otherwords, we didn?t find any blocking case specific toChinese.
The lower scores of correctness in Chi-nese might be due to the smaller amount of exper-iment data and more blocking cases in this corpus.Irrealis: This category contains gfbf events thathaven?t or will not happen.
One of the case iswhen the agent tried to conduct the gfbf event,but failed.
In Ex(4.1), the agent and objective areunderlined and the gfbf event is boldfaced.
Bythe rules, the writer has the same sentiment to-ward the agents and objects in gf events and op-posite sentiments toward the agents and objects inbf events (Deng and Wiebe, 2014).
In Ex(4.1), thewriter is negative toward both the agent and theobject, though this is a bf event.
This is becausethe event counter does not exist due to the failure,which is implied by intended to.
The inferencesfor gfbf events in this category are blocked be-cause the writer expresses the sentiments towardentities based on what they have done so far.EX(4.1) ...monetary policy activism in-tended to counter the cyclical bumpsand grinds of the free market.Forced GFBF: This category contains gfbf eventswhose agents don?t intend to do that or be-ing forced to conduct the event.
For exam-ple, in Ex(4.2), though the triple ?Obama, delay,mandate?
is an event which does not happen, it12is different from Ex(4.1).
Here, the agent Obamais forced to conduct the delaying, though he doesnot want to and the writer does not blame himif he does so.
For the entities involved in forcedevents, (at least the writer believes the entities areinvoluntary,) the forced event will not affect thewriter?s sentiments toward the entities so that theinferences are blocked.EX(4.2) Some of them even seem tothink that they can bully Mr. Obama intodelaying the individual mandate too.Quoted GFBF: This category contains gfbfevents in the quotations.
Consider the Ex(4.3),where one of the gfbf triple is ?law, reduce,amount of labor ?.
In the original editorial, thewriter supports the law and the writer has a posi-tive sentiment toward the number of jobs (becausehe/she expects to see more job opportunities).
Butmerely from the annotated gfbf triple, it is inferredthat the law has negative effect since it reduces thenumber of jobs.
This is not contradictory with thewriter?s stance because the writer regards the eventas a deliberate misreading he/she doesn?t believe.The actual agent of the event should be (misread-ing, Obama).
This example shows that inferencesof a triple in the quotation are blocked, or eventflipped, based on the writer?s sentiment toward theagent saying the quotation.
The agent in a quotedgfbf is similar to the notion of nested source insentiment analysis (Wilson and Wiebe, 2003).EX(4.3) Some of the job-killer scarestories are based on a deliberate mis-reading that estimated the law would?reduce the amount of labor used in theeconomy?
by about 800,000 jobs.In conclusion, the good performance in our pilotstudy gives supporting evidence for our hypothe-sis.
That is, the inference rules apply for Chinese.Moreover, there is no evidence showing that thecases where the inferences are blocked only hap-pen in Chinese.5 Chinese GoodFor/BadFor LexiconAbove all we have assessed the similarity of im-plicatures and inference rules in Chinese and En-glish.
In the following sections, we will analyzewhether Chinese gfbf components could be cap-tured by similar techniques in English.Description Count (Percentage %)Parallel Span 122 (76.25%)Chinese Adding GFBF 10 (6.875%)Chinese Adding Object 6 (3.75%)English Out Of Triple 5 (3.125%)English Neutral 6 (3.125%)Paraphrase 11 (6.875%)Table 4: Counts of Chinese-English CorrespondsIn this section, we compare the gfbf spans inthe Chinese gfbf corpus and the English version,to investigate the possibility of deriving a bilingualgfbf lexicon.
Though the Chinese and English ed-itorials are paragraph paralleled, they are not sen-tence paralleled, because an English sentence maybe translated into multiple Chinese sentences andseveral English sentences may be merged into oneChinese sentence.
Therefore, instead of automaticword-alignment, we manually pick up the Englishparallel spans of the Chinese annotated gfbfs.
Thecorrespondences of Chinese and English spans arecategorized in Table 4.
We present pairs of ex-amples from the Chinese gfbf corpus, beginningwith the original English sentence (Eng), followedby another English sentence which is the word-by-word translation of the Chinese sentence (Chi).Parallel Span: This category contains instanceswhere the Chinese annotated gfbf spans havethe corresponding translations in the English sen-tences, and the English spans are also gfbf words.Chinese Adding GFBF: In the original Englishsentence below, its own making is a noun phraserather than a gfbf verb used as a noun.
However, inthe Chinese version, there is a clear triple, ?itself,makes, a monetary prison?.
In such case the Chi-nese version adds a gfbf event into the sentence.Eng: ...the Fed is domiciled in a monetary prisonof its own making.Chi: ...the Fed is domiciled in a monetary prisonwhich itself makes.Chinese Adding Object: As stated in the manual,all gfbf triples should have objects.
Thus, in theoriginal sentence below, we will not mark exclu-sion because the object is implicit.
However, theChinese version clearly states the object, patients.Eng: ...no more exclusion based on pre-existingconditions...Chi: ...no more exclusion of the patients based onpre-existing conditions...13English Out Of Triple: Recall from Section 3.3,the gfbf polarity must be sufficient to perceive thegfbf polarity within the triple.
The ?the Fed, get,unemployment?
below cannot be considered as agfbf, since whether it is good for or bad for theunemployment depending on whether it is below6.5% or up 6.5%, for instance.
On the contrary,the Chinese version uses the word decrease, whichis a bf word, no matter how many percents arechanged.Eng: If and when the Fed ?
which now promisesto get unemployment below 6.5%...Chi: If and when the Fed ?
which now promisesto decrease the unemployment to 6.5%...English Neutral: Sometimes the English worddoesn?t have a gfbf meaning but the Chinese wordhas one, based on the translator?s interpretation ofthe whole editorial, though the triple structures arethe same in English and Chinese versions.Eng: We?ve had eight decades of increasinglyfrenetic monetary policy activism...Chi: We?ve been insisting increasingly freneticmonetary policy activism for eight decades...In the original English sentence, had eightdecades of is hardly regarded as a gfbf word.However, in the translated version, the word in-sisting is a gf word.
The change of wording intro-duces a new gfbf event into the sentence.Paraphrase: There are other cases where the sen-tences are paraphrased so largely that we cannotfind a corresponding parallel span of the annotatedChinese span in the original English sentence.
Amajority of cases in this category are gfbf eventstriggered by the Chinese syntax in Section 3.3.In conclusion, the percentage of 76.25% in RowParallel Span indicates that it is applicable to de-rive a bilingual gfbf lexicon from a parallel cor-pus.
However, we need to take into considerationthe 23.75% mismatches for higher precision.5.1 Chinese ReversersThe polarity of a gfbf event could be changed bya reverser (Deng et al., 2013).
A common classof reversers is negation.
For example, in the sen-tence, ?the bill will not increase the costs?, the gfincrease is changed to be bf via the negation not.In this section, we analyze the Chinese reversers.All of the reversers in the Chinese gfbf corpushappen to be negations.
In the English sentences,the negations are easily extracted by neg depen-dency relation.
About 50% of the Chinese nega-tions are linked to the gfbf events via neg as well.Among this half, there are two negations com-monly seen.
One is ?
(Not), often labeled as AD(adverb) in terms of Part-Of-Speech, the other is??
(do not have), labeled as VV (verb), shownbelow.
The negation is underlined and the gfbfevent it negates is boldfaced.EX(5.1)?/AD??/VV???/NNEX(5.2)??/VV??/VV?
?/NNFor the other half, the error mostly arises fromsegmentations.
For the sentence below, though??
(doesn?t have), often labeled as VB, could beregarded as a complete token, if we segment thetwo characters into two independent tokens, theparse is more similar to the English one.
Belowwe only list the most relevant part of the parses.Eng: He does n?t have ability control war budgetEng dep: neg(have-4, n?t-3), root(ROOT-0, have-4), dobj(have-4, ability-6)Chi: ?
?
?
??
??
??
?
?wrong dep: root(ROOT-0, ?
?-2), nsubj(??-4,?
?-3), dep(??-2,?
?-4)correct dep: neg(?-3, ?-2), root(ROOT-0, ?-3), nsubj(??-5,?
?-4)In conclusion, it is feasible to recognize re-versers in Chinese but it calls for a suitable wordsegmentation as input.6 Syntax of Agent/Object in ChineseAccording to (Deng et al., 2013), the agent is theentity conducting the gfbf event and the object isthe entity that the gfbf event affects.
This defini-tion is very similar to subject and (in)direct ob-ject in semantic role labeling.
Xue and Palmer(2004) investigate the Chinese semantic role la-beling.
They utilize the PropBank and the con-stituency parser.
However, from a preliminaryanalysis of constituency parse, we cannot distin-guish the agent and object merely from the parsetree, because the sentences in the editorials areusually complicated and it is difficult to classifywhether a noun phrase (NP) constituency is agentor object in terms of its position.
Kozhevnikovand Titov (2013) adopt a model transfer betweendifferent languages using dependency parser.
Inour case, the dependency parser has labels such14as ?nsubj?
and ?dobj?, which are strong indica-tions of agents and objects.
Thus, we use theStanford dependency parser, which has both En-glish and Chinese parsers, to analyze the syntaxof agents/objects in the gfbf events.
We count thetypes of dependencies on the path in a dependencyparse between the tokens of agents/objects and thetokens of gfbf events in the DCW corpus and theChinese gfbf corpus.Among all the dependency types, 19.57% of thelabels between agents and gfbfs are the ones spe-cially designed for Chinese and 25.82% betweenobjects and gfbf are the ones specially designedfor Chinese.
This indicates there is a consider-able number of differences in dependency types.Chang et al.
(2009), who create the Chineseparser, discuss the differences between Chineseand English types, which are similar to our obser-vations.First, there are more nsubj in Chinese foragents (21.53%) and more dobj in Chinese for ob-jects (21.59%), compared to English (17.43% and14.01%), which are easier for the parser to detect.Second, the most common types specially de-signed for Chinese are assm, assmod and cpm (intotal 12.23% for agents and 16.14% for objects).The relations assm is associative marker, assmodis associative modifier, and cpm is complemen-tizer.
These are defined because of the frequent us-age of ?
(whose, of) in Chinese.
Though there isnot a direct mapping between Chinese and Englishdependency types, they are similar to two commontypes in English: prep and pobj (together 23.36%for agents and 31.62% for objects).Third, there are more rcmod in Chinese thanthose in English.
There are 7.05% and 6.5% rc-mod in Chinese agents and objects, respectively.But there are only 1.7% and 2.16% in Englishagents and objects.
The type rcomd is a relativeclause modifier.
If a verb is used as the modifierof a noun, it will be labelled rcmod.
Instead, En-glish writers tend to use more adjectives to mod-ify nouns, which will be labeled amod (4.04% and4.48%).Fourth, there are 7.63% and 6.22% punct inChinese agents and object, compared to both 0%in English.
In addition, there are 3.36% and 3.31%conj in English agents and objects.
Chang etal.
(2009) explain that English use conjunctions(conj) to link clauses while Chinese tend to usepunctuation.
Another finding in our corpus is that,translators tend to break down a long English sen-tence into several Chinese clauses, linked by punc-tuations.For the other Chinese types, most of them aremodifiers, which may be grouped with similar En-glish modifiers.7 Chinese Explicit Sentiment AnalysisThere are various available resources for Chinesesentiment analysis, such as sentiment lexicon fromHowNet7, NTU Sentiment Dictionary (NTUSD)(Ku and Chen, 2007)8and the sentiment lexi-con from Tsinghua University (Li and Sun, 2007).The sentiments recognized from lexicon hits areexplicit, meaning that the writers use sentimentwords to express his/her opinions.
These explicitsentiment results are provided to the graph-basedmodel as input.
Note that the model plays a roleof sentiment inference, instead of directly detect-ing sentiments from the text.
The inferred senti-ments are implicit, meaning that the writers ex-press his/her opinions even without using a senti-ment lexical clue.8 ConclusionIn this work we investigate implicit opinionsexpressed via goodFor/badFor events in Chinese.The positive results have provided evidencesthat such implicit opinions and inference rulesare similar in Chinese and English.
There aresome gfbf events caused by the Chinese syntax,guidance for which could be added to the currentEnglish manual to develop a Chinese manual.Moreover, there is no evidence showing that theblocked inferences only happen in Chinese.
Wealso assess the feasibility of acquiring componentsof gfbf events from Chinese text using currentavailable resources.
In the future, it is promisingto utilize gfbf information to assist sentimentanalysis in Chinese.Acknowledgement This work was supportedin part by DARPA-BAA-12-47 DEFT grant#12475008 and National Science Foundationgrant #IIS-0916046.
We would like to thankChangsheng Liu and Fan Zhang for their anno-tations in the agreement study, and thank anony-mous reviewers for their feedback.7Available at: http://www.keenage.com/html/e index.html8Available at: http://nlg18.csie.ntu.edu.tw:8080/lwku/pub1.html15ReferencesPranav Anand and Kevin Reschke.
2010.
Verb classesas evaluativity functor classes.
In InterdisciplinaryWorkshop on Verbs.
The Identification and Repre-sentation of Verb Features.Ron Artstein and Massimo Poesio.
2008.
Inter-coderagreement for computational linguistics.
Comput.Linguist., 34(4):555?596, December.Jordan Boyd-Graber and Philip Resnik.
2010.
Holis-tic sentiment analysis across languages: Multilin-gual supervised latent dirichlet allocation.
In Pro-ceedings of the 2010 Conference on Empirical Meth-ods in Natural Language Processing, pages 45?55,Cambridge, MA, October.
Association for Compu-tational Linguistics.Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, andChristopher D Manning.
2009.
Discriminativereordering with chinese grammatical relations fea-tures.
In Proceedings of the Third Workshop on Syn-tax and Structure in Statistical Translation, pages51?59.
Association for Computational Linguistics.Yuen Ren Chao.
1968.
A grammar of spoken Chinese.Univ of California Press.Yejin Choi and Claire Cardie.
2008.
Learning withcompositional semantics as structural inference forsubsentential sentiment analysis.
In Proceedings ofthe 2008 Conference on Empirical Methods in Nat-ural Language Processing, pages 793?801, Hon-olulu, Hawaii, October.
Association for Computa-tional Linguistics.Lingjia Deng and Janyce Wiebe.
2014.
Sentimentpropagation via implicature constraints.
In Meetingof the European Chapter of the Association for Com-putational Linguistics (EACL-2014).Lingjia Deng, Yoonjung Choi, and Janyce Wiebe.2013.
Benefactive/malefactive event and writer at-titude annotation.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics (Volume 2: Short Papers), pages 120?125,Sofia, Bulgaria, August.
Association for Computa-tional Linguistics.Song Feng, Jun Sak Kang, Polina Kuznetsova, andYejin Choi.
2013.
Connotation lexicon: A dash ofsentiment beneath the surface meaning.
In Proceed-ings of the 51th Annual Meeting of the Associationfor Computational Linguistics (Volume 2: Short Pa-pers), Sofia, Bulgaria, Angust.
Association for Com-putational Linguistics.Amit Goyal, Ellen Riloff, and Hal Daum?e III.
2013.
Acomputational model for plot units.
ComputationalIntelligence, 29(3):466?488.Rodney D. Huddleston and Geoffrey K. Pullum.
2002.The Cambridge Grammar of the English Language.Cambridge University Press, April.Richard Johansson and Alessandro Moschitti.
2013.Relational features in fine-grained opinion analysis.Computational Linguistics, 39(3).Mikhail Kozhevnikov and Ivan Titov.
2013.
Cross-lingual transfer of semantic role labeling models.In Proceedings of the 51st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 1190?1200, Sofia, Bulgaria,August.
Association for Computational Linguistics.Lun-Wei Ku and Hsin-Hsi Chen.
2007.
Miningopinions from the web: Beyond relevance retrieval.Journal of the American Society for Information Sci-ence and Technology, 58(12):1838?1850.Jun Li and Maosong Sun.
2007.
Experimentalstudy on sentiment classification of chinese reviewusing machine learning techniques.
In NaturalLanguage Processing and Knowledge Engineering,2007.
NLP-KE 2007. International Conference on,pages 393?400.
IEEE.Charles N Li and Sandra A Thompson.
1989.
Man-darin Chinese: A functional reference grammar.Univ of California Press.Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin KTsou.
2011.
Joint bilingual sentiment classifica-tion with unlabeled parallel corpora.
In Proceed-ings of the 49th Annual Meeting of the Associationfor Computational Linguistics: Human LanguageTechnologies-Volume 1, pages 320?330.
Associationfor Computational Linguistics.J.
Pearl.
1982.
Reverend bayes on inference engines:A distributed hierarchical approach.
In Proceedingsof the American Association of Artificial IntelligenceNational Conference on AI, pages 133?136, Pitts-burgh, PA.Kevin Reschke and Pranav Anand.
2011.
Extractingcontextual evaluativity.
In Proceedings of the NinthInternational Conference on Computational Seman-tics, IWCS ?11, pages 370?374, Stroudsburg, PA,USA.
Association for Computational Linguistics.Rintje Pieter Eelke Sybesma.
1992.
Causatives andaccomplishments: The case of Chinese ba, vol-ume 1.
Holland Institute of Generative Linguistics.Benjamin KY Tsou, Raymond WM Yuen, Oi YeeKwong, TBY La, and Wei Lung Wong.
2005.
Po-larity classification of celebrity coverage in the chi-nese press.
In Proceedings of International Confer-ence on Intelligence Analysis.Xiaojun Wan.
2008.
Using bilingual knowledge andensemble techniques for unsupervised Chinese sen-timent analysis.
In Proceedings of the 2008 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 553?561, Honolulu, Hawaii, Oc-tober.
Association for Computational Linguistics.16Xiaojun Wan.
2009.
Co-training for cross-lingual sen-timent classification.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP: Volume 1-Volume 1, pages 235?243.
Association for Compu-tational Linguistics.Suge Wang, Yingjie Wei, Deyu Li, Wu Zhang, andWei Li.
2007.
A hybrid method of feature se-lection for chinese text sentiment classification.
InFuzzy Systems and Knowledge Discovery, 2007.FSKD 2007.
Fourth International Conference on,volume 3, pages 435?439.
IEEE.Janyce Wiebe and Lingjia Deng.
2014.
An account ofopinion implicatures.
arXiv:1404.6491v1 [cs.CL].Janyce Wiebe, Theresa Wilson, and Claire Cardie.2005.
Annotating expressions of opinions and emo-tions in language ann.
Language Resources andEvaluation, 39(2/3):164?210.Theresa Wilson and Janyce Wiebe.
2003.
Annotatingopinions in the world press.
In Proceedings of the4th ACL SIGdial Workshop on Discourse and Dia-logue (SIGdial-03), pages 13?22.Nianwen Xue and Martha Palmer.
2004.
Calibrat-ing features for semantic role labeling.
In EMNLP,pages 88?94.Bishan Yang and Claire Cardie.
2013.
Joint Inferencefor Fine-grained Opinion Extraction.
In Proceed-ings of ACL, pages 1640?1649.Jonathan S Yedidia, William T Freeman, and YairWeiss.
2005.
Constructing free-energy approx-imations and generalized belief propagation algo-rithms.
Information Theory, IEEE Transactions on,51(7):2282?2312.Lei Zhang and Bing Liu.
2011.
Identifying noun prod-uct features that imply opinions.
In Proceedings ofthe 49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 575?580, Portland, Oregon, USA, June.Association for Computational Linguistics.17
