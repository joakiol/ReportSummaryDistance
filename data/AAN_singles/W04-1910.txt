Bootstrapping Parallel TreebanksMartin VOLK and Yvonne SAMUELSSONStockholm UniversityDepartment of Linguistics10691 StockholmSwedenvolk@ling.su.seAbstractThis paper argues for the development of par-allel treebanks.
It summarizes the work donein this area and reports on experiments forbuilding a Swedish-German treebank.
And itdescribes our approach for reusing resourcesfrom one language while annotating anotherlanguage.1 IntroductionTreebanks have become valuable resources innatural language processing (NLP) in recentyears (Abeille?, 2003).
A treebank is a collectionof syntactically annotated sentences in whichthe annotation has been manually checked sothat the treebank can serve as training cor-pus for natural language parsers, as repositoryfor linguistic research, or as evaluation corpusfor NLP systems.
The current interest in tree-banks is documented in international workshopseries like ?Linguistically Interpreted Corpora(LINC)?
or ?Treebanks and Linguistic Theo-ries?
(TLT).
But also the recent internationalCL conferences have seen a wide variety of pa-pers that involved treebanks.
Treebanks havebecome a necessary resource for many researchactivities in NLP.On the other hand recent years have seenan increasing interest in parallel corpora (of-ten called bitexts).
See for example (Melamed,2001) or (Borin, 2002) for a broad picture ofthis area.But surprisingly little work has been reportedon combining these two areas: parallel tree-banks.
We define a parallel treebank as a bi-text where the sentences of each language areannotated with a syntactic tree, and the sen-tences are aligned below the clause level.
Thisleaves room for various kinds of tree structure(e.g.
dependency structure trees or constituentstructure trees) and does not specify a preciserequirement for tree alignments but rather forsome sort of sub-clausal alignment (e.g.
wordalignment or phrase alignment).But why has there been so little work doneon parallel treebanks?
The benefits of hav-ing such a treebank for training statistical ma-chine translation systems, experimenting withexample-based translation systems, or evalu-ating word alignment programs seem so over-whelming.
We speculate that this scarcity ismainly due to the expenses necessary for build-ing a parallel treebank (in terms of time andhuman resources).
It is well known that themanual labor involved in building a monolin-gual treebank is high (For the Penn Treebank(Taylor et al, 2003) report on 750 - 1000words per hour for an experienced annotator,which translates to 35 - 50 sentences per hour).And the cross-language alignment requires ad-ditional work.
Therefore every approach to fa-cilitate and speed up this process will be highlywelcome.The goal of this paper is to summarize the(little) work that has been done on paralleltreebanks and related areas such as annota-tion projection.
In particular we will report onour experiments for building a Swedish-Germanparallel treebank.
As a side issue we investi-gated whether the German treebank annota-tion guidelines (from the NEGRA / TIGERprojects) can be applied to Swedish.
We havechosen Swedish and German because they areour mother tongues, but also because they aresimilar and still interestingly different.2 Previous Work on ParallelTreebanksThe field of parallel treebanks is only now evolv-ing into a research field.
(Cmejrek et al, 2003)at the Charles University in Prague have builta treebank for the specific purpose of machinetranslation, the Czech-English Penn Treebankwith tectogrammatical dependency trees.
Theyhave asked translators to translate part of thePenn Treebank into Czech with the clear direc-tive to translate every English sentence with onein Czech and to stay as close as possible to theoriginal.This directive seems strange at first sight butit makes sense with regard to their objective.Since they specifically construct the treebankfor training and evaluating machine translationsystems, a close human translation is a validstarting point to get good automatic transla-tions.At the University of Mu?nster (Germany)(Cyrus et al, 2003) have started working onFuSe, a syntactically analyzed parallel corpus.The goal is a treebank with English and Germantexts (currently with examples from the Eu-roparl corpus).
The annotation is multi-layeredin that they use PoS-tags, constituent structure,functional relations, predicate-argument struc-ture and alignment information.
However theirfocus is on the predicate-argument structure.The Nordic Treebank Network1 has startedan initiative to syntactically annotate the firstchapter of ?Sophie?s World?2 in the nordic lan-guages.
This text was chosen since it has beentranslated into a vast number of languages andsince it includes interesting linguistic propertiessuch as direct speech.
Currently a prototypeof this parallel treebank with the first 50 sen-tences in Swedish, Norwegian, Danish, Estonianand German has been finished.
The challengein this project is that all involved researchersannotate the Sophie sentences of their languagein their format of choice (ranging from depen-dency structures for Danish and Swedish to con-stituency structures for Estonian and German).In order to make the results exchangeable andcomparable all results have been converted intoTIGER-XML so that TIGERSearch3 can beused to display and search the annotated sen-tences monolingually.
The alignment across lan-guages is still open.3 Bootstrapping a German-Swedishparallel treebankWe have built a small German-Swedish paralleltreebank with 25 sentence pairs taken from theEuroparl corpus.
First, the German sentences1The Nordic Treebank Network is headed byJoakim Nivre.
See www.masda.vxu.se/?nivre/research/nt.html2The Norwegian original is: Jostein Gaarder (1991):Sofies verden: roman om filosofiens historie.
Aschehoug.3TIGERSearch is a treebank query tool developed atthe University of Stuttgart.
See also section 5.2.were tokenized and loaded into the Annotatetreebank editor4.
Annotate includes ThorstenBrants?
Part-of-Speech Tagger and Chunker forGerman.
The PoS tagger employs the STTS, aset of around 50 PoS-tags for German.
The setis so large because it incorporates some morpho-syntactic features (e.g.
it distinguishes betweenfinite and non-finite verb forms).
The chun-ker assigns a flat constituent structure with theusual node labels (e.g.
AP, NP, PP, S, VP), butalso special labels for coordinated phrases (e.g.CAP, CNP, CPP, CS, CVP).
In addition thechunker suggests syntactic functions (like sub-ject, object, head or modifier) as edge labels.The human treebank annotator controls thesuggestions made by the tagger and the chun-ker and modifies them where necessary.
Taggerand chunker help to speed up the annotationprocess for German sentences enormously.
Theupper tree in figure 1 shows the structure forthe following sentence (taken from Europarl):(1) Doch sind Bu?rger einiger unsererMitgliedstaaten Opfer von schrecklichenNaturkatastrophen geworden.
(EN: But citizens of some of ourmember states have become victims ofterrible natural disasters.
)Now let us look at the resources available forSwedish.
First there is SUC (the Stockholm-Ume?a-Corpus), a 1 million word corpus of writ-ten Swedish designed as a representative corpusalong the lines of the Brown corpus.
SUC con-tains PoS-tags, morphological tags and lemmasfor all tokens as well as proper name classes.All the information is hand-checked.
So thisis proper training material for a PoS tagger.Compared to the 50 tags of the STTS, the 22SUC PoS-tags (e.g.
only one verb tag) are rathercoarse-grained, but of course we can use thecombination of PoS-tags and morphological in-formation to automatically derive a richer tagset.Training material for a Swedish chunker isharder to come by.
There are two earlySwedish treebanks, Mamba and SynTag (datingback to the 1970s (!)
and 1980s respectively),but they are rather small (about 5000 sen-tences each), very heterogeneously annotatedand somewhat faulty (cf.
(Nivre, 2002)).
There-fore, the most serious attempt at training a4Annotate is a treebank editor developed at the Uni-versity of Saarbru?cken.
See www.coli.uni-sb.de/sfb378/negra-corpus/annotate.htmlFigure 1: Parallel trees with lines showing the alignment.chunker for Swedish was based on an automat-ically created ?treebank?
which of course con-tained a certain error rate (Megyesi, 2002).
Es-sentially there exists no constituent structuretreebank for Swedish that could be used fortraining a chunker with resulting structures cor-responding to the German sentences.Therefore we have worked with a differentapproach (described in detail in (Samuelsson,2004)).
We first trained a PoS tagger on SUCand used it to assign PoS-tags to our Swedishsentences.
We then converted the Swedish PoS-tags in these sentences into the correspondingGerman STTS tags.5 We loaded the Swedishsentences into Annotate (now with STTS tags),and we were then able to reuse the Germanchunker to make structural decisions over theSwedish sentences.
This worked surprisingly5An alternative approach could have been to map alltags in the SUC to STTS and then train a Swedish taggeron this converted material.well due to the structural similarities of Swedishand German.
After the semi-automatic an-notation of the syntactic structure, the PoS-tags were converted back to the usual Swedishtag set.
This is a straight-forward example ofhow resources for one language (in this caseGerman) can be reused to bootstrap linguis-tic structure in another albeit related language(here Swedish).The lower tree in figure 1 shows the structurefor the Swedish sentence which corresponds tothe German sentence in example 1.
(2) Da?remot har inv?anarna i ett antal avv?ara medlemsla?nder drabbats avnaturkatastrofer som verkligen varitfo?rskra?ckliga.
(EN: However inhabitants of a numberof our member states were affected bynatural disasters which indeed wereterrible.
)Since the German STTS is more fine-grainedthan the SUC tag set, the mapping from theSUC tag set to STTS does not entail loosingany information.
When converting in this di-rection the problem is rather which option tochoose.
For example, the SUC tag set has onetag for adjectives, but the STTS distinguishesbetween attributive adjectives (ADJA) and ad-verbial or predicative adjectives (ADJD).
Wedecided to map all Swedish adjectives to ADJAsince the information in SUC does not give usany clue about the usage difference.
The humanannotator then needs to correct the ADJA tagto ADJD if appropriate, in order to enable thechunker to work as intended.Other tag mapping problems come with theSUC tags for adverb, determiner, pronoun andpossessive all of which are marked as ?interrog-ative or relative?
in the guidelines.
There is noclear mapping of these tags to STTS.
We de-cided to use the mapping in table 1.The benefit of using the German chunker forannotating the Swedish sentences is hard toquantify.
A precise experiment would requireone group of annotators to work with this chun-ker and another to work without it on the samesentences for a comparison of the time needed.We performed a small experiment to see howoften the German chunker suggests the correctnode labels and edge labels for the Swedish sen-tences (when the children tags/nodes were man-ually selected).
In 100 trials we observed 89 cor-rect node labels and 93% correct edge labels (for305 edges).
If we assume that manual inspec-tion of correct suggestions takes about a thirdof the time of manual annotation, and if we alsoassume that the correction of erroneous sugges-tions takes the same amount of time as manualannotation, then the employment of the Ger-man chunker for Swedish saves about 60% ofthe annotation time.Reusing a chunker for bootstrapping a paral-lel treebank between closely related languageslike German and Swedish is only a first step to-wards reusing annotation (be it automatic ormanual) in one language for another language.But it points to a promising research direc-tion.
(Yarowsky et al, 2001) have reportedinteresting results of an annotation-projectiontechnique for PoS tagging, named entities andmorphology.
And (Cabezas et al, 2001) haveexplored projecting syntactic dependency rela-tions from English to Basque.
This idea wasfollowed by (Hwa et al, 2002) who investi-gated English to Chinese projections based onthe direct correspondence assumption.
Theyconclude that annotation projections are nearly70% accurate (in terms of unlabelled dependen-cies) when some linguistic knowledge is used.We believe that annotation projection is a diffi-cult field but even if we only succeed in a limitednumber of cases, it will be valuable for increasedspeed in the development of parallel treebanks.3.1 AlignmentThe alignment in our experimental treebank isbased on the nodes, not the edge labels.
Fig-ure 1 shows the phrase alignment as thick linesacross the trees.
All of the alignment mappingwas done by hand.We decided to make the alignment determin-istic, i.e.
a node in one language can only bealigned with one node in the other language.There are, of course, a lot of problems withthe alignment.
We have looked at the meaning,rather than the exact wording.
Sometimes dif-ferent words are used in an S or VP, but we stillfeel that the meaning is the same, and thereforewe have aligned them.
We might have align-ment on one constituent level, while there aredifferences (i.e.
no alignment) on lower levels ofthe tree.
Therefore we consider it important tomake the parse trees sufficiently deep.
We needto be able to draw the alignment on as manylevels as possible.Another problem arises when the sentencesare constructed in different ways, due to e.g.passivisation or topicalisation.
Although Ger-man and Swedish are structurally close, thereare some clear differences.?
German separable prefix verbs (e.g.
fangenan = begin) do not have a direct corres-pondence in Swedish.
However, Swedishhas frequent particle verbs (e.g.
ta upp =bring up).
But whereas the German sep-arated verb prefix occupies a specific posi-tion at the end of a clause (?Rechte Satzk-lammer?
), the Swedish verb particle occursat the end of the verb group.?
The general word order in Swedish subordi-nate clauses is the same as in main clauses.Unlike in German there is no verb-final or-der in subordinate clauses.?
German uses accusative and dative caseendings to mark direct and indirect objects.This is reflected in the German functionlabels for accusative object (OA) and forSUC tag STTS tagHA int.
or rel.
adverb PWAV adverbial interrog.
or relative pronounHD int.
or rel.
determiner PWS (stand-alone) interrog.
pronounHP int.
or rel.
pronoun PRELS (stand-alone) relative pronounHS int.
or rel.
possessive PPOS (stand-alone) possessive pronounTable 1: Mapping of SUC tags to STTSdative object (DO).
Swedish has lost thesecase endings and the labels therefore neednot reflect case but rather object function.Our overall conclusion is that applying theGerman treebank annotation guidelines toSwedish works well when the few peculiaritiesof Swedish are taken care of.4 Corpus representationAfter annotating the sentences in both lan-guages with the Annotate treebank editor, thetree structures were exported in the NEGRAexport format from the MySQL database.
Thefile in NEGRA format is easily loaded intoTIGERSearch via the TIGERRegistry whichprovides an import filter for this format.
Thisimport process creates a TIGER-XML filewhich contains the same information as the NE-GRA file.
The difference is that the pointers inthe NEGRA format go from the tokens to thepre-terminal nodes (and from nodes to parentnodes) in a bottom-up fashion, whereas in theTIGER-XML file the nodes point to their chil-dren by listing their id numbers (idref) and theiredge label (in a top-down perspective).In this file the tokens of the sentence (ter-minals) are listed beneath each other with theircorresponding PoS-tag (PPER for personal pro-noun, VVFIN for finite verb, APPRART forcontracted preposition etc.).
The nodes (non-terminals) are listed with their name and theiroutgoing edges with labels such as HD for head,NK for noun kernel, SB for subject etc.<s id="s1"><graph root="522"><terminals><t id="1" word="Ich" pos="PPER" /><t id="2" word="erkla?re" pos="VVFIN"/><t id="3" word="die" pos="ART" /><t id="4" word="am" pos="APPRART"/><t id="5" word="Freitag" pos="NN" />[...]</terminals><nonterminals><nt id="500" cat="NP"><edge label="HD" idref="1" /></nt>[...]<nt id="522" cat="S"><edge label="HD" idref="2" /><edge label="SB" idref="500" /><edge label="MO" idref="511" /><edge label="OA" idref="521" /></nt></nonterminals></graph></s>Since all tokens and all nodes are uniquelynumbered, these numbers can be used for thephrase alignment.
For the representation of thealignment we adapted a DTD that was devel-oped for the Linko?ping Word Aligner (Ahren-berg et al, 2002).
The XML-file with the align-ment information then looks like this.
ThesentLink-tags each contain one sentence pair,while each phraseLink represents one alignednode pair.<!DOCTYPE DeSv SYSTEM "align.dtd"><DeSv fromDoc="De.xml" toDoc="Sv.xml"><linkList><sentLink xtargets="1 ; 1"><phraseLink xtargets="500; 500"/><phraseLink xtargets="501; 503"/>[...]</sentLink></linkList></DeSv>This fragment first specifies the two involvedXML files for German (De.xml) and Swedish(Sv.xml).
It then states the phrase pairs forthe sentence pair 1 - 1 from these files.
Forexample, phrase number 501 from the Germansentence 1 is aligned with phrase number 503 ofthe Swedish sentence.5 Tools for Parallel TreebanksTreebank tools are usually of two types.
Firstthere are tools for producing the treebank, i.e.for automatically adding information (taggers,chunkers, parsers) and for manual inspectionand correction (treebank editors).
On the otherhand we need tools for viewing and searching atreebank.5.1 Treebank EditorsOf course the tools for monolingual treebankproduction can also be used for building thelanguage-specific parts of a parallel treebank.Thus a treebank editor such as Annotate withbuilt-in PoS tagger and chunker is an invaluableresource.
But such a tool should include or becomplemented with a completeness and consis-tency checker.In addition the parallel treebank needs to bealigned on the sub-sentence level.
Automaticword alignment systems will help ((Tiedemann,2003) discusses some interesting approaches).But tools for checking and correcting this align-ment will be needed.
For example the I*Linksystem (Ahrenberg et al, 2002) could be usedfor this task.
I*Link comes with a graphicaluser interface for creating and storing associa-tions between segments in a bitext.
I*Link isaimed at word and phrase associations and re-quires bitexts that are pre-aligned at the sen-tence level.5.2 Treebank Search ToolsWith the announcement of the Penn Treebank,some 10 years ago, came a search tool calledtgrep.
It is a UNIX-based program that allowsquerying a treebank specifying dominance andprecedence relations over trees (plus regular ex-pressions and boolean operators).
The searchresults are bracketed trees in line-based or in-dented format catering for the needs of differentusers.
For example, the following tgrep querysearches for a VP that dominates (not necessar-ily directly) an NP which immediately precedesa PP.VP << (NP .
PP)More recently TIGERSearch was launched.It is a Java-based program that comes with agraphical user interface and a powerful feature-value-oriented query language.
The outputare graphical tree representations in which thematched part of the tree is highlighted and fo-cused.
TIGERSearch?s ease of installation andfriendly user interface have made it the tool ofchoice for many treebank researchers.According to our knowledge no specific searchtools for parallel treebanks exist.
In addition tothe above sketched search options of tgrep andTIGERSearch a search tool for parallel tree-banks will have to allow queries that combineconstraints over two trees.
For example onewants to issue queries such as ?Find a treein language 1 with a relative clause where theparallel tree in language 2 uses a prepositionalphrase for the same content.
?5.3 Displaying Parallel TreesThere is currently no off-the-shelf tool that candisplay parallel trees so that one could view twophrase structure trees at the same time withtheir alignment.
Therefore we discuss possibledisplay options of such a future program.One alternative is to show the two trees aboveeach other (as in figure 1).
And there aremany ways to visualize the alignment: Eitherby drawing lines between the nodes (as we did),or by color marking the nodes, or by opening an-other window where only chosen parallel nodesare shown.
The latter case corresponds to azoom function, but this also entails that the userhas to click on a node to view the alignment.Another alternative would be a mirror imag-ing.
One language would have its tree with theroot at the top and the tree of the other lan-guage would be below with the root at the bot-tom.
The alignment could be portrayed in thesame ways as above.But then the display problem is mainly aproblem concerning the computer screens of to-day, where a large picture partly lands outsideof the screen, while a smaller scale picture mightresult in words that are too small to be read-able.
One solution could be to use two screens(as is done in complex layout tasks), but thenwe cannot have a solution with the trees aboveeach other, but rather next to each other, pos-sibly with some kind of color marking of thenodes.A last alternative is to use vertical trees,where the words are listed below each other,showing phrase depth horizontally.
Then thealignment could be shown by having the nodesside by side instead of above each other.
Thisis the least space consuming alternative, but itis also the least intuitive one.
Furthermore, thisis not a viable alternative if the trees containcrossing branches.We currently favor the first approach withtwo trees above each other, and we have writ-ten a program that takes the SVG (scalablevector graphics) representation of two trees (asexported from TIGERSearch), merges the twographs into a single graph and adds the phrasealignment lines based on the information in thealignment file.6 ConclusionsWe have reported on our experiments for build-ing a German-Swedish parallel treebank.
Wehave shown that by mapping the German PoStag set to the Swedish tag set we were ableto reuse the German chunker for the semi-automatic annotation of the Swedish sentences.Our experiments have also shown that the Ger-man annotation guidelines with minor adapta-tions are well-suited for Swedish.We have argued that tools for building mono-lingual treebanks can be used for parallel tree-banks as well, and that tools for sub-sentencealignment are available but they are not enoughevaluated yet for aligning tree structures.
Toolsfor viewing and searching through parallel tree-banks are missing.7 AcknowledgementsWe would like to thank the anonymous review-ers for useful comments, the members of theNordic Treebank Network for many interestingdiscussions, and David Hagstrand for handlingour annotation databases.ReferencesAnne Abeille?, editor.
2003.
Building and Us-ing Parsed Corpora, volume 20 of Text,Speech and Language Technology.
Kluwer,Dordrecht.Lars Ahrenberg, Magnus Merkel, and MikaelAndersson.
2002.
A system for incrementaland interactive word linking.
In Proceedingsfrom The Third International Conference onLanguage Resources and Evaluation (LREC-2002), pages 485?490, Las Palmas.Lars Borin, editor.
2002.
Parallel Corpora,Parallel Worlds.
Selected Papers from a Sym-posium on Parallel and Comparable Corporaat Uppsala University, Sweden, 22-23 April,1999., volume 43 of Language and Comput-ers.
Rodopi, Amsterdam.Clara Cabezas, Bonnie Dorr, and Philip Resnik.2001.
Spanish language processing at Univer-sity of Maryland: Building infrastructure formultilingual applications.
In Proceedings ofthe Second International Workshop on Span-ish Language Processing and Language Tech-nologies (SLPLT-2), Jaen, Spain, September.Martin Cmejrek, Jan Curin, and Jiri Havelka.2003.
Treebanks in machine translation.
InProc.
Of the 2nd Workshop on Treebanks andLinguistic Theories, Va?xjo?, Sweden.Lea Cyrus, Hendrik Feddes, and Frank Schu-macher.
2003.
FuSe - a multi-layered paral-lel treebank.
In Proc.
Of the 2nd Workshopon Treebanks and Linguistic Theories, Va?xjo?,Sweden.Rebecca Hwa, Philip Resnik, Amy Weinberg,and Okan Kolak.
2002.
Evaluating transla-tional correspondence using annotation pro-jection.
In Proceedings of the 40th AnnualMeeting of the ACL, Philadelphia.Bea?ta Megyesi.
2002.
Data-Driven Syn-tactic Analysis.
Methods and Applicationsfor Swedish.
Doctoral dissertation, Kungl.Tekniska Ho?gskolan.
Department of Speech,Music and Hearing, Stockholm.I.
Dan Melamed.
2001.
Empirical Methods forExploiting Parallel Texts.
MIT Press, Cam-bridge, MA.Joakim Nivre.
2002.
What kinds of trees growin Swedish soil?
A comparison of four anno-tation schemes for Swedish.
In Proc.
Of FirstWorkshop on Treebanks and Linguistic The-ory, Sozopol, Bulgaria.Yvonne Samuelsson.
2004.
Parallel phrases.Experiments towards a German-Swedish par-allel treebank.
C-uppsats, Stockholms Uni-versitet.Ann Taylor, Mitchell Marcus, and BeatriceSantorini.
2003.
The Penn Treebank: Anoverview.
In Anne Abeille?, editor, Build-ing and Using Parsed Corpora, volume 20of Text, Speech and Language Technology.Kluwer, Dordrecht.Jo?rg Tiedemann.
2003.
Recycling Transla-tions.
Extraction of Lexical Data from Par-allel Corpora and Their Application in Nat-ural Language Processing.
Acta universitatisupsaliensis, Uppsala University.D.
Yarowsky, G. Ngai, and R. Wicentowski.2001.
Inducing multilingual text analysistools via robust projection across aligned cor-pora.
In Proceedings of HLT 2001, First In-ternational Conference on Human LanguageTechnology Research.
