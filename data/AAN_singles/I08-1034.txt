The Telling Tail:Signals of Success in Electronic Negotiation TextsMarina SokolovaIRO, Universite?
de Montre?alMontre?al, Que?bec, Canadasokolovm@iro.umontreal.caVivi NastaseEML Research, gGmbHHeidelberg,Germanynastase@eml-research.deStan SzpakowiczSITE, University of OttawaOttawa, Ontario, CanadaICS, Polish Academy of SciencesWarsaw, Polandszpak@site.uottawa.caAbstractWe analyze the linguistic behaviour of par-ticipants in bilateral electronic negotiations,and discover that particular language char-acteristics are in contrast with face-to-facenegotiations.
Language patterns in the laterpart of electronic negotiation are highly in-dicative of the successful or unsuccessfuloutcome of the process, whereas in face-to-face negotiations, the first part of the nego-tiation is more useful for predicting the out-come.
We formulate our problem in terms oftext classification on negotiation segmentsof different sizes.
The data are representedby a variety of linguistic features that cap-ture the gist of the discussion: negotiation-or strategy-related words.
We show that,as we consider ever smaller final segmentsof a negotiation transcript, the negotiation-related words become more indicative of thenegotiation outcome, and give predictionswith higher Accuracy than larger segmentsfrom the beginning of the process.1 IntroductionWe use language every day to convince, explain, ma-nipulate and thus reach our goals.
This aspect oflanguage use is even more obvious in the contextof negotiations.
The parties must reach an agree-ment on the partitioning or sharing of a resource,while each party usually wants to leave the negotia-tion table with the larger piece of the pie.
These ten-dencies become stronger when negotiators use onlyelectronic means to communicate, that is to say, par-ticipate in electronic negotiations.
In face-to-facecontact, prosody and body language often have acrucial role in conveying attitudes and feelings.
E-negotiators, on the other hand, must rely only ontexts.
We perform automatic analysis of the textualdata in e-negotiations.
We identify linguistic expres-sions of such negotiation-specific behaviour that areindicative of the final outcome of the process ?
suc-cess or failure ?
and observe how powerful a toollanguage is in helping people get what they want.In this paper we focus on the negotiation as an on-going process.
We analyze the linguistic features ofmessages exchanged at various points in the courseof the negotiation, to determine the time frame inwhich the outcome becomes decided.
From our ex-perimental point of view, we determine the segmentof the negotiation which is most predictive of theoutcome.
There is an imposed three-week deadlinein the electronic negotiations that we analyze.
Wehypothesize that the pressure of the deadline is re-flected in the messages exchanged.
The messageswritten later in the process are more indicative ofthe outcome of the process.
Our empirical resultssupport this hypothesis; an analysis of the linguis-tic features that make this prediction possible showswhat the negotiators?
main concerns are as the dead-line draws near.Here is what our results contribute to the fieldof text analysis.
Research on text records of face-to-face negotiations suggests that the language pat-terns used in the first half of a negotiation predictthe negotiation outcome better than those in the sec-ond half (Simons, 1993).
The explanation was that257in the first phase people establish contact, exchangepersonal information and engage in general politeconversation, creating a foundation of trust betweenpartners.
No numerical data, however, supportedthis diagnosis, and there was no distinction betweenthe prediction of successful and unsuccessful out-comes.
When it comes to text classification, ourhypothesis says that the classification of the secondparts of e-negotiation texts is more accurate with re-spect to the outcome than the classification of thefirst parts.
This makes e-negotiation texts differentfrom newsgroup messages, newspaper articles andother documents classified by Blatak et al (2004),where texts showe d better classification Accuracyon their initial parts.
We report the results of severalsets of Machine Learning (ML) experiments.
Per-formed on varying-size text data segments, they sup-port our hypothesis.We worked with a collection of transcripts ofnegotiations conducted over the Internet using theWeb-based negotiation support system Inspire (Ker-sten and Zhang, 2003).
Kersten and Zhang (2003)and Nastase (2006) classified e-negotiation out-comes using non-textual data.
Classification basedon texts is discussed in (Sokolova et al 2005;Sokolova and Szpakowicz, 2006).
None of those ex-periments considered segmenting the data, althoughSokolova and Szpakowicz (2006) analyzed the im-portance of the first part of e-negotiations.
The workwe present here is the first attempt to investigate theeffect of parts of e-negotiation textual data on classi-fication quality.
In this study we do not report typesof expressions that are relevant to success and failureof negotiations.
These expressions have been pre-sented and analyzed in (Sokolova and Szpakowicz,2005).In section 2 we take a brief look at other work onthe connection between behaviour and language.
Insection 3 we present our data and their representa-tion for ML experiments, and we further motivateour work.
Section 4 describes the experiments.
Wediscuss the results in Section 5.
Section 6 draws con-clusions and discusses a few ideas for future work.2 Background ReviewYoung (1991) discusses the theory that the situationin which language is used affects the way in which itis used.
This theory was illustrated with a particularexample of academic speech.The field of neuro-linguistic programming in-vestigates how to program our language (amongother things) to achieve a goal.
In the 1980s,Rodger Bailey developed the Language and Be-haviour Profile based on 60 meta-programs.
Charvet(1997) presents a simplified approach with 14 meta-programs.
This profile proposes that people?s lan-guage patterns are indicators of behavioural pref-erences.
In the study of planning dialogues (Chu-Carroll and Carberry, 2000), Searle?s theory ofspeech acts used through the discourse analysis alsosupports the fact that language carries much of peo-ple?s behaviour and emotions.
Reitter and Moore(2007) studied repetitions in task-oriented conver-sations.
They demonstrated that a speaker?s short-term ability to copy the interlocutor?s syntax is au-tonomous from the success of the task, whereaslong-term adaptation varies with such success.We consider a negotiation to be a communicationin which the participants want to reach an agreementrelative to the splitting/sharing of resources.
Lan-guage is one of the tools used to reach the goal.
Wepropose that not all messages exchanged throughouta negotiation have the same effect on the negotiationoutcome.
To test this hypothesis, we take an eversmaller segment of the negotiation, and see howwellwe can predict the outcome of the process, basedonly on the messages in this fragment.We encountered several challenges in predict-ing e-negotiation outcomes using the messages ex-changed.
First, electronic negotiations usually donot have a sequential-stage model of behaviour(Koeszegi et al 2007), which is common in face-to-face negotiations (Adair and Brett, 2005).
Here isan example of behavioural phases in face-to-face ne-gotiations: Perform Relational Positioning ?
Iden-tify the Problem ?
Generate Solutions ?
ReachAgreement.
Unexpected turns and moves ?
typicalof human behaviour ?
make prediction of the ne-gotiation outcome difficult.
In case of electronicnegotiation, the absence of the usual negotiationstructure further complicates the outcome predic-tion.
This distinguishes e-negotiations from agent-customer phone conversations studied in (Takeuchiet al 2007), where an agent follows the call flowpre-defined by his company?s policy.258The longer an e-negotiation takes, the more elab-orate the structure of the e-negotiation process be-comes.
Simpler e-negotiation may involve an ex-change of well-structured business documents suchas pre-defined contract or retail transactions.
Amore complex process comprises numerous offersand counter-offers and has a high degree of uncer-tainty because of the possible unpredictability of ne-gotiation moves.The next challenge stems from the limitations im-posed by the use of electronic means.
This overloadstext messages with various tasks: negotiation issuesthemselves, introductions and closures traditional innegotiations, and even socializing.
On the otherhand, electronic means make the contacts less for-mal, allowing people to communicate more freely.As a result, the data have a high volume of informal-ity such as abbreviations or slang.The last challenge is specific to text analysis.
E-negotiations usually involve a multi-cultural audi-ence of varied background, many of whom are notnative English speakers.
While communicating inEnglish, they introduce a fair amount of spelling andgrammatical mistakes.3 Textual Data in Electronic NegotiationsParticipants in a negotiation assume well-definedroles (such as buyers/sellers in some business nego-tiations, or facilitators in legal disputes), have goals,and adopt specific behaviour to achieve those goals(Koeszegi et al 2007).
These circumstances are re-flected in the language of texts exchanged in negoti-ations, and distinguish this type of texts from casuale-mail exchange and postings on discussion groupsand chat boards.
We claim that the language cap-tured in e-negotiation textual data changes as a nego-tiation progresses, and that this is clearly detectable,even though it does not follow a sequential-stagemodel common in face-to-face-negotiations (Adairand Brett, 2005) or an agent-customer interactioncall flow recommended by a company (Takeuchi etal, 2007).
To support the language change hypothe-sis, we have conducted a series of ML experimentson negotiation segments of varying size and posi-tion, using the largest available data of electronic ne-gotiations.Our data come from the Web-based negoti-ation support system Inspire.
Inspire has beenused in business courses to teach students aboute-negotiations and give them a chance to practicebilateral business negotiations conducted in a lightlycontrolled environment.
For many users, conductingnegotiations has been a business/ course assignment.Other users wanted to develop their English skillsby participating in an Inspire-enabled negotiation.A negotiation would last up to three weeks, afterwhich, if an agreement has not been reached, thesystems would terminate the negotiation and recordit as unsuccessful.
The following is an example of anegotiation message (with the original spelling):Dear Georg, I hope you are doig well.
I send you this messageto ask you what happened to our offer.
Just be aware thatwe will not be indifinitely waiting on your response.
As Itold you during our last meeting, Itex Manufacturing needsa partnership.
So it is important to me to know if you areready to negotiate with us.
We can not afford losing so muchprecious time.
We give you now five more days to answerour offer (1st of december 1997, 2400 Swiss time).
After thisdead line, will propose our services to your concurrence.
Istill believe in a good partnership and relationship betweenour two societies.
Let me know if you think so.
For ItexManufacturing.
Rookie.Among the wealth of data gathered by Inspire, wehave focussed on the accompanying text messages,extracted from the transcripts of 2557 negotiations.Each negotiation had two different participants, andone person participated in only one negotiation.
Thetotal number of contributors was over 5000; mostof them were not native English speakers.
The datacontain 1, 514, 623 word tokens and 27, 055 types.Compared with benchmark corpora, for example theBrown or the Wall Street Journal corpus (Francisand Kucera, 1997; Paul and Baker, 1992), this col-lection has a lower type-token ratio and a higherpresence of content words among the most frequentwords (this is typical of texts on a specific topic), anda high frequency of singular first- and second-personpronouns (this is typical of dialogues).We considered all messages from one negotiationto be a single negotiation text.
We concatenated themessages in chronological order, keeping the punc-tuation and spelling unedited.
Each negotiation hada unique label, either positive or negative, and wasa training example in one of two classes ?
success-259Features Split NB SVM DTAcc F P R Acc F P R Acc F P Rnegotiation-related 1/2 and 1/2 68.1 70.4 73.0 68.0 73.6 76.8 75.4 78.2 73.9 78.8 72.1 86.8negotiation-related 3/4 and 1/4 69.1 71.3 74.1 68.7 73.7 77.0 75.5 78.5 75.4 79.4 73.8 86.0Table 1: Accuracy and corresponding F ?
score , Precision and Recall .
Classifying all negotiations as successful gives abaseline Accuracy of 55%.ful or unsuccessful.
Inspire assigned a negotiationto the right class automatically.
55% of negotiationsin our data set were successful, i.e.
ended up withagreement.We represented a complete negotiation, or text aswe consider it, as a combined bag of words.
Wematched the tokens in the messages with an inven-tory of domains from Longman Dictionary of Con-temporary English (Procter, 1978).
This allowed usto select those terms that refer to negotiation specificissues ?
we call them negotiation-related words.
Weselect strategic words based on words and patternsthat literature shows to express the intentions, influ-ence, self-obligations and motivations of the negoti-ation participants.
In classifying successful and un-successful negotiations, subsets of these two typesof features provided better Accuracy than statisti-cally selected features, e.g.
most frequent unigramsand unigrams with a higher log-likelihood valuescalculated between positive and negative classes(Sokolova et al 2005).We halved each text, that is to say, the completerecord of a negotiation.
For each half we built abag of 123 negotiation-related words ?
more on thisin section 4.
The binary attributes represented thepresence or absence of the word in its half of thetext.
We concatenated the two bags, and labelledthe resulting bag by the outcome of the whole ne-gotiation: positive if the negotiation was successful,negative otherwise.
We repeated this procedure forthe split of the negotiation text into 34 and14 .
OurML tools were Weka?s (Witten and Frank, 2005)NAIVE BAYES (NB), the sequential minimal optimiza-tion (SVM) version of SUPPORT VECTOR MACHINE, andDECISION TREE (DT).
In Table 1 we report Accuracyand Precision (P ), Recall (R) and F ?
score (F ).P , R, F are calculated on the positive class.
Forevery classifier, the best Accuracy and correspond-ing P , R, F are reporte d; we performed an exhaus-tive search on adjustable parameters; the evaluationmethod was tenfold cross-validation.
Our Accuracyresults are comparable with those reported in pre-vious studies (Kersten and Zhang, 2003; Nastase,2006; Sokolova and Szpakowicz, 2006).We used the paired t-test to generalize the resultson both splits.1 The two-tailed P value was 0.0102.By conventional criteria, this difference is consid-ered to be statistically significant.Accuracy and, especially, Precision results showthat DECISION TREE is sensitive to the positions ofwords in different parts of the negotiations.
SUPPORTVECTOR MACHINE and NAIVE BAYES change Accuracyonly slightly.
The Precision and Recall resultsgive a better picture of the performance.
Thepresence/absence of words recorded for differentsplits of negotiations influences the identification oftrue positive examples (successful negotiations) andtrue negative examples (unsuccessful negotiations).Recall displays that DT classifies successful negoti-ations better when the negotiations are split 12 and12 .Precision andRecall together imply that unsuccess-ful negotiations have a higher rate of true classifica-tion achieved by NB, when the split is 34 and14 .
Thissplit lets us improve the worst rates of true classifi-cations ?
unsuccessful negotiations for DT and suc-cessful negotiations for NB.
Generally, the unequalsplit al lows us to reduce the difference between truepositive and true negative classification results, andthus makes the classification of negotiations morebalanced than the equal split.
For all the three clas-sifiers, Accuracy and F ?
score are better on the 34and 14 split.4 The Empirical Set-upWe wanted to determine the placement of the seg-ment of a negotiation most important in decidingwhether the outcome is positive: at the beginningor at the end of the process.
To do that, we split eachnegotiation in half, and built two parallel data sets,corresponding to the two halves.
We classified each1Results on the same data require the paired version of t-test.260part using various ML tools.
Next, we repeated thesame classification tasks using smaller and smallerfinal segments, in order to monitor the variation inperformance.
Thus each negotiation text N con-sisted of the head segment (h) and the tail segment(t): N = h?t, h?t = ?, where |t| = |N |i and t wasthe segment at the end of N , and |h| = (i?1)|N |i cov-ering the beginning of the negotiation.
We stoppedwhen for two consecutive splits two classifiers hadbetter Accuracy on the head than on the tail.
Eachsegment got the same class label as the whole nego-tiation.For these experiments, as briefly explained in sec-tion 3, we took the textual negotiation data repre-sented as bags of words.
Because of the large num-ber of word features (27, 055 tokens), we performedlexical feature selection.Statistical analysis of the corpus built from theInspire negotiation messages has revealed that theissues discussed in these messages can be groupedinto a small set of topics.
The particular topicor domain to which a word belongs derives fromthe most frequent bigram and trigram meanings;for instance, the second most frequent trigramwith the word delivery is payment upon delivery, sowe assign delivery to the domain negotiation process.The data come from negotiations on a specifictopic (sale/purchase of bicycle parts), so a likelycandidate subset would be words related to it.
Weselect such negotiation-related words as the firstset of features.
We show a text sample with thenegotiation-related words in bold:Dear Georg, I hope you are doig well.
I send you this messageto ask you what happened to our offer.
Just be aware thatwe will not be indifinitely waiting on your response.
As Itold you during our last meeting, Itex Manufacturing needsa partnership.
So it is important to me to know if you areready to negotiatewith us.
We can not afford losing so muchprecious time.
We give you now five more days to answer ouroffer (1st of december 1997, 2400 Swiss time).
After thisdead line, we will propose our services to your concurrence.I still believe in a good partnership and relationship betweenour two societies.
Let me know if you think so.
For ItexManufacturing.
Rookie.Strategies which the negotiators adopt (promises,threats, exchange of information, argumentation,and so on) affect the outcome (Sokolova andSzpakowicz, 2006).
Since the messages are dense,short and grammatically simple, the expression ofstrategies through language is straightforward andconcentrates on communicating the main goal.
Theword categories that convey negotiators?
strategiesare modals, personal pronouns, volition verbs,mental verbs; we refer to them as strategic words.Strategic words constitute the second set of features.Our text sample with strategic words in bold looksas follows:Dear Georg, I hope you are doig well.
I send you this mes-sage to ask you what happened to our offer.
Just be awarethat we will not be indifinitely waiting on your response.
AsI told you during our last meeting, Itex Manufacturing needsa partnership.
So it is important to me to know if you areready to negotiate with us.
We can not afford losing so muchprecious time.
We give you now five more days to answerour offer (1st of december 1997, 2400 Swiss time).
Afterthis dead line, we will propose our services to your concur-rence.
I still believe in a good partnership and relationshipbetween our two societies.
Let me know if you think so.For Itex Manufacturing.
Rookie.We work with kernel (SVM), decision-based (DT)and probabilistic (NB) classifiers.
Applying classi-fiers with different working paradigms allow us tocapture and understand different aspects of the data,as the results and our discussion in section 5 willshow.
For each classifier, we used tenfold cross-validation and exhaustive search on adjustable pa-rameters in model selection.
The best results, in par-ticular with high overall Accuracy , appear in Fig-ure 1.When the data are represented using negotiation-related words, the tail segments give more accurateoutcome classification than the head segments.
Thisholds for all splits and all classifiers; see Figure 1.The increase in Accuracy when the head segmentsgrow was to be expected, although it does not hap-pen with DT and SVM ?
only with NB.
At the sametime, there is no monotonic decline in Accuracywhen the length of the tail segments decreases.
Onthe contrary, NB constantly improves the Accuracyof the classification.
We note the fact that NB in-creases theAccuracy on both head and tail segmentsand makes the basic assumption of the conditionalindependence of features.
We explain the NB re-sults by the decreased dependence between the pres-2611.
DT7171.57272.57373.57474.57575.51  2  3  4  5  6AccuracyInverse size of segmenthead part, negotiation-related wordstail part, negotiation-related wordshead part, strategic wordstail part, strategic words2.
SVM7171.57272.57373.57474.57575.51  2  3  4  5  6AccuracyInverse size of segmenthead part, negotiation-related wordstail part, negotiation-related wordshead part, strategic wordstail part, strategic words3.
NB67.56868.56969.57070.57171.51  2  3  4  5  6AccuracyInverse size of segmenthead part, negotiation-related wordstail part, negotiation-related wordshead part, strategic wordstail part, strategic wordsFigure 1: The classification Accuracy with DT, SVM andNB, for negotiation-related and strategic words.ence/absence of negotiation-related words when thenegotiations move to the second part of the process.The results on the strategic-word representationare slightly different for the three classifiers; seeClassifier tail s1 s2 s1 s2 s3DT 74.4 71.9 74.9 72.5 71.9 73.9SVM 75.3 70.5 73.5 70.8 69.9 74.6NB 68.8 68.5 70.1 68.7 68.9 70.9Negotiation-related wordsClassifier tail s1 s2 s1 s2 s3DT 73.8 73.8 73.4 71.7 71.4 72.9SVM 73.8 70.9 72.8 72.0 71.3 73.4NB 60.8 70.6 69.5 69.2 69.3 68.7Strategic wordsTable 2: The Accuracy of the negotiation outcome classifica-tion on 2 and 3 splits of the second half of the negotiation ?
thetail segment.
Classifying all negotiations as successful gives abaseline Accuracy of 55%.Figure 1.
SVM classifies all tail segments betterthan head segments, DT classifies tail segments bet-ter than head segments up to the 45/15 split, and NBclassifies the tail segment better than the head seg-ment only for the half-and-half split.
The Accuracyresults are unstable for all three classifiers, with theAccuracy on the head segments decreasing whenthe segments grow and the Accuracy on the tailsegments increasing when the tail segments shrink.The performance of the classifiers indicate that, asthe deadline approaches, negotiation-related wordsreflect the negotiation process better than strategicwords.To investigate which part of the tail segments ismore important for classifying the outcomes, we in-troduced additional splits in the tail segments.
Wedivided the second half of each text into 2 and 3parts and repeated the classification procedures forevery new split.
The results appear at the top ofTable 2, where tail shows the classification resultswhen the second half of the text was classified, andthe other columns report the results on the tail splits;both splits satisfy the conditions tail =?i si, wheresi?sj = ?
for every i 6= j.The results show that adding splits in the tail seg-ments emphasizes the importance of the last part ofa negotiation.
For negotiation-related word repre-sentation, the classification of the outcome on thelast part of the tail is more accurate than on its otherparts.
This holds for all three classifiers.
For thestrategic-word representation the same is true forSVM and partially for DT, but not for NB; see thebottom of Table 2.
NB classifies the negotiation out-comes more accurately on s1 than on s2 and on s2rather than s3.262Classifier 1/3 1/4 1/5 1/6 1/7 1/8 1/9P R P R P R P R P R P R P RDT 74.2 85.3 74.2 84.3 75.2 82.3 73.61 83.0 74.5 82.4 72.1 81.6 74.0 81.3SVM 76.1 78.1 76.3 76.3 77.0 75.3 78.3 75.3 77.2 73.4 76.9 72.3 77.6 71.6NB 73.8 71.8 71.8 73.9 74.8 71.9 74.9 72.0 71.3 72.2 70.8 72.5 70.5 74.3Table 3: Precision and Recall on the tail segments; negotiation-related words.
Precision and Recall are calculated on thepositive class.676869707172737475761  2  3  4  5  6  7  8  9AccuracyInverse size of segmentC5.0SMONaive BayesFigure 2: The evolution of the success and failure classifica-tion Accuracy with decreasing segment sizes.5 Segmentation ResultsTaking into account the results reported in section4, we chose negotiation-related words as the featureset.
We selected for further analysis the half that per-formed better for a majority of the tools used.
Wefocussed on the last part of the negotiation, and weextracted a gradually smaller fragment (12 ?19 ; 9 isthe average number of text messages in one negotia-tion).
Figure 2 plots the results of the experimentsperformed with decreasing segment sizes.
As wesee, the tail segment of the length 17 gave a declineof the Accuracy for SVM and NB, with a slight im-provement on smaller tail segments.A more detailed analysis comes from consider-ing the Precision and Recall results on the seg-ments; see Table 3.
On 17 and19 tail segments ahigher Precision indicates that all classifiers haveimproved the identification of true negatives (unsuc-cessful negotiations).
This means that the trends inthe class of unsuccessful negotiations become morenoticeable for the classifiers when the deadline ap-proaches.
The 18 split is an exception, with theabrupt drop of true negative classification by DE-CISION TREE.
The correct classification of positiveexamples (successful negotiations), however, dimin-ishes when splits become smaller; this applies to theperformance of all three classifiers.
This means thatat the end of the negotiations the class of success-ful negotiations becomes more diverse and, subse-quently, multi-modal, and the trends are more diffi-cult to capture by the classifiers.As in the previous experiments, NB?s Accuracyon the tail segments is higher than on the completedata.
The opposite is true for SVM and DT: theirAccuracy on the tail segments is lower than on thecomplete data.
We explain this by the fact that thesizes of tail segments in the last splits do not givethese two classifiers sufficient information.6 Discussion and Future WorkWe have analyzed textual messages exchanged in thecourse of electronic negotiations.
The results sup-port our hypothesis that texts of electronic negoti-ation have different characteristics than records offace-to-face negotiation.
In particular, messages ex-changed later in the process are more informativewith regard to the negotiation outcome than mes-sages exchanged at the beginning.We represented textual records of negotiations bytwo types of word features.
These features cap-ture the important aspects of the negotiation process?
negotiation-related concepts and indicators of thestrategies employed.
We performed extensive exper-iments with different types of ML algorithms andsegments of varying sizes from the beginning andthe end of the negotiation, on a collection of over2500 electronic negotiations.
Our study shows thatwords expressing negotiation-related concepts aremore useful for distinguishing successful and failednegotiations, especially towards the end of negotia-tions.
We also have shown that there is no linear de-pendency between the segment sizes and Accuracyof classification of the negotiation success and fail-ure.263Our research plans include a continuation of theinvestigation of the negotiators?
behaviour in elec-tronic negotiations and its reflection in language.
Tosee whether dialogue analysis improves predictionof the negotiation outcomes, we will look at negotia-tions as dialogues between participants and take intoaccount their roles, e.g.
buyer and seller.
We willsplit a negotiation at message boundaries to avoidarbitrary splits of the negotiation process.AcknowledgmentsPartial support for this work came from the Natu-ral Sciences and Engineering Research Council ofCanada.ReferencesW.
Adair, J. M. Brett.
2005.
The negotiation dance: time,culture, and behavioral sequences in negotiation.
Or-ganization Science.
16(1): 33-51.J.
Blata?k, E.
Mra?kova?, L.
Popel??nsky.
2004.
Fragmentsand Text Categorization.
Proceedings of the 42th An-nual Meeting of the Association of Computational Lin-guistics (ACL 2004).
Companion Volume: 226-229,Association for Computational Linguistics.J.
M. Brett.
2001.
Negotiating Globally.
Jossey-Bass.S.
R. Charvet.
1997.
Words that Change Minds: Master-ing the Language of Influence.
Kendall/Hunt.J.
Chu-Carroll, S. Carberry.
2000.
Conflict Resolution inCollaborative Planning Dialogues.
International Jour-nal of HumanComputer Studies.
53(6): 969-1015.W.
N. Francis, H. Kuc?era.
1967.
Computational Analysisof Present-Day American English, Brown UniversityPress.G.
E. Kersten, G. Zhang.
2003.
Mining Inspire Datafor the Determinants of Successful Internet Negotia-tions.
Central European Journal of Operational Re-search.
11(3): 297-316.S.
Koeszegi, E.-M. Pesendorfer, R. Vetschera.
2007.Data-driven Episodic Phase Analysis of E-negotiation.Group Decision and Negotiation 2007.
2: 11?130.V.
Nastase.
2006.
Concession curve analysis for Inspirenegotiations.
Group Decision and Negotiation.
15:18?193.D.
B. Paul and J. M. Baker 1992 The Design for theWall Street Journal-based CSR Corpus.
Proceedingsof the 2nd International Conference on Spoken Lan-guage Processing (ICSLP?92), 357-361.P.
Procter.
1978.
Longman Dictionary of ContemporaryEnglish.
Longman Group Ltd. Essex, UK.D.
Reitter, J. Moore.
2007.
Predicting Success in Dia-logue.
Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics (ACL 2007),808-815, Association for Computational Linguistics.T.
Simons.
1993.
Speech Patterns and the Concept ofUtility in Cognitive Maps: the Case of Integrative Bar-gaining.
Academy of Management Journal.
38(1):139-156.M.
Sokolova, V. Nastase, M. Shah, S. Szpakowicz.2005.
Feature Selection in Electronic NegotiationTexts.
Proceedings of Recent Advances in NaturalLanguage Processing (RANLP?2005), 518-524, In-coma Ltd, Bulgaria.M.
Sokolova, S. Szpakowicz.
2006.
Language Patternsin the Learning of Strategies from Negotiation Texts.Proceedings of the 19th Canadian Conference on Ar-tificial Intelligence (AI?2006), 288-299, Springer.M.
Sokolova and S. Szpakowicz.
2005 Analysis andClassification of Strategies in Electronic Negotiations.Proceedings of the 18th Canadian Conference on Ar-tificial Intelligence (AI?2005), 145-157, Springer., H. Takeuchi, L. Subramaniam, T. Nasukawa, S. Roy.2007 Automatic Identification of Important Segmentsand Expressions for Mining of Business-OrientedConversations at Contact Centers.
Proceedings of the2007 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), 458?467, As-sociation for Computational Linguistics.I.
Witten, E. Frank.
2005.
Data Mining, 2nd ed.. MorganKaufmann.
www.cs.waikato.ac.nz/ml/weka/L.
Young.
1991.
Language as Behaviour, Language asCode: A Study of Academic English.
John Benjamins.264
