Schema Method:  A F rameworkfo r  Cor rec t ing  Grammat ica l ly  I l l - fo rmed InputIkuo KUD01) , Hideya KOSHINO2) , Moonkyung CHUNG2) and Tsuyosi MORIMOTO1)1)ATR Interpreting Telephony Research LaboratoriesTwin 21 Building MID Tower2-1-61 Shiromi, Higashi-kuOsaka 540, Japan2)CSK Research Institute3-22-17 Higashi-Ikebukuro, Toshima-kuTokyo 170, JapanAbstractThe schema method is a framework for correctinggrammatically ill-formed input.
In a natural languageprocessing system ill-formed input cannot be overlooked.
Acomputer assisted instruction (CAD system, in particular,needs to show the user's errors.
This framework diagnosesill-formed input, corrects it and explains the error, if aninput is ill-~'ormed.
The framework recognizes a sentence attwo steps: first parses weak grammar, and then stronglyfilters the parsed sentence.
When it is known whatsentences are passed by the filter, it can be used even if it isimperfect.
As the strong filter, a new method is used: aninterpretation schema and an interpretation rule.
Aninterpretation schema collects input information schemataand then an interpretation rule judges whether thecollected schemata re correct or incorrect.
This approachovercomes the problem of relaxation control, the majordrawback of the previous yntactically-oriented methods,and is also more efficient.1?
IntroductionIll-formed input cannot be ignored when a naturallanguage processing system such as a computer assistedinstruction (CAD system or a machine translation systemis built.
Particularly in a CAI System, students oftenmake mistakes, such as mispunctuation, lack of agreement,misplaced/improperly-used words, etc.
In these cases, aCAI system needs to point out input errors, and show whythe input it~ wrong.
In order to do so, the system needs todiagnose and correct ill-formed input to explain the errors.The schema method as a framework for correctinggrammatically ill-formed input is suggested and thediagnosis and correction of errors is discussed.There have been many studies for processing ill-formedinput for English.
The point of those studi.es is thediagnosis: how does the system find an error?
Theapproaches are classif ied into two groups:  thesyntactically-oriented group and the frame-based group.The syntactically-oriented group includes robustparsers based on Augmented Transition Networks (ATN)which Use the relaxation technique/Kwansny 1981./or themeta-rule/Weisehedel 1980, 82, 87/, and the EPISTLEsystem which addresses the problems of the checkinggrammar and style of texts, such as letters, reports andmanuals, written in ordinary English/Heidorn 1982/,/Jensen 1983/.The frame-based group attempts to deal withungramnmtical input through extensions to patternmatching parsing/Hayes 1981/, through conceptual caseframe instantiation/Schank 1980/and through approachesinvolving multiple cooperating pars ing strategies/Carbonell 1983/.
The target of that study is dialoguephenomena in communication with l imited-domainsystems, such as data-base systems, electronic mailsystems, etc.The aim of this study is error-correction of non-nativespeakers written Engl ish text.
This approach issyntactically oriented.The syntactically-oriented approaches/Kwansny 1981//Weischedel 1980,82,87/,/Heidorn 1982/,/Jensen 1983/arevery similar.
Their basic idea is relaxation.
They firstattempt to parse the input, using fully grammatical rules.If the sentence is not parsed, some of the conditions arerelaxed.
However these approaches have two majordrawback.
(1)Relaxation control strategies: when inputs are ill-formed, some means of ranking alternatives i  appropriate.The number of relaxed configurations may be large.One of the most critical problems is control.
The need torelax the very rules that constrain the search for aninterpretation is like opening Pandora's box./Weischedel1987(PP.117)/(2)Computational inefficiency: the relaxation approachcannot recognize ill-formed input before the analysis withwell-formed grammar is finished.
Furthermore, fully well-formed grammar is needed.
To make fully well-formedgrammar, subcategorization f parts of speech is neededand other conditions are added.
As a result, there are toomany rules.In comparison to previous approaches, this approachdoes not use the relaxation technique.
The differencebetween previous approaches and this one is the method ofrecognizing an ill-formed sentence.
Previous approachesfirst use a strong filter, then relax the conditions.
Thisapproach, however, first uses weak grammars, and thenstrongly filters the passed sentence.
This approachrecognizes a sentence at two steps.An attempt is made to expand lexical-functionalgrammar (LFG) /Kaplan 1982/to deal with ill-formedinput.
LFG has two drawbacks: (1) LFG can't deal witherrors of omission and (2) LFG has no framework for errorcorrection.
If an input sentence is well-formed, thisframework obtains an LFG f-structure.
If not, the sentenceis corrected.Examples of error correction are given in the nextsection.
In the section following the basic idea is described3~iand the problem of a unification mechanism for processingill-formed input is discussed.
This framework is shown insection 4.2.
Non-nat ive  speaker ' s  i l l - formed phenomenaIn this section, treated examples of non-native speaker'sill-formed phenomena re given.
The application is a CAIsystem for Japanese junior  high school s tudents  in aprimary English course.
Their  errors are different from anative speaker's.
Typical errors are shown in Table 1.Engl ish is very different from Japanese in parts ofspeech, word-order, tense, etc.
For a Japanese, there is noconcept of( l )  countable and uncountable nouns ~:> ~ ~> inTable 1, (2) singular and plural forms <~ (3) articles ~> ~>(4) agree-merit between subject and verb @ (5) adverbword-order ~.Japanese interfered with the students'  acquision ofEnglish.
The following errors are often made by Japaneseadults as well.
(4)verb style <~ (5) category mistakes, wordmisuse ~>.
Furthermore, junior high school students arereading and hearing a foreign language (English) for thefirst time, and thus have no concept of foreign languagewhatsoever.
(6) Logical error @: the student who made themistake explained that "are + not -* aren't", "is + not -*isn't" so" am+ not --* amn't".
(7) Pr imary students are notfami l iar  with Eng l i sh  grammar  and can't  d is t inguishbetween "Who" or "Where" @ @.
(8)Surface rror: letter orpunctuation problemsTable 1.
Examples of errors by junior high school students<~*He plays piano.
<~*He plsy the baseball.He plays the piano.
He plays baseball.
@*some good advices '<~*I am student.some good advice I am a student.
@*A moon is smaller than an erath.The moon is smaller than the earth.~*He is one of those men who is difficult to please.He is one of those men who are difficult to please.<~*I have finished my homework already.I have already finished my homework .~>*He is listening music on the radio now.He is listening to music on the radio now.<~*We cannot play baseball in here.We cannot play baseball here.
@*Yes, I amn't.Yes, I am not.
Yes, I'm not.~*Who does cook breakfast?
~*Where they live?Who cooks breakfast?
Where do they live?
@*Does mr. brown have a bookDoes Mr. Brown have a book?
@*We must stop to complain.We must stop complaining.Grammatical  errors ~ @ are treated, but notsemantic errors ~> and absolutely ill-formed sentenceswhich are not comprehensible.
The aim is to diagnosegrammatical  errors and show a reason for the error.
Forexample:Input sentence; Mr Brown has a pen,correction; Mr. Brown has a pen.the reason; A period is needed after"  Mr".The comma after "pen" should be a period.3423.
Basic ideaIn this section, the basic idea of the frsmework and ~beproblem of the LFG unification mechanism in dealing withill-formed input is described.3.1 Two - level f i l terThe framework uses two-level filters for input sentenceclassification: a well-formed sentence, a relat ively ill-formed sentence or an absolutely i l l-formed sentence asshown in Figure 1.
(1)First an attempt to parse the input,  us ing normalcontext-free grammar  (Fi l ter I ) is made~ Both a welloformed sentence and the relat ively illoformed sentencewhich includes feature errors are passed through the filter(Filter I ).
(2)Secondly, these inputs are checked with a strong filter(FilterII).
A well-formed sentence passes, but a relativelyill-formed sentence does noL(3)An input which is not passed through the first f i lter(Filter I ), includes word-order or omitted-word errors~ orunnecessary words @ @.
The input is classified by a filter(~), called Improper Grammar, as relatively ill-formed orabsolutely i l l -formed.j al~essed ~In iu t  .
.
.
.
.
"~.- .
.
~'--~rejectedFilter ( I ) \]F-S:iltor( ) 1\[ Improper Grammar /7Well-formed error corection failure(relatively ill-formed} (absolutely ill-formed)<~<~ <~ @ :sentence~>~ number in Table1Figure 1 Two-level filter3.2 F i l ter  testFi lter ( I ) is a context~free grammar.
This filter is aweak filter.
Therefore some relatively ill-formed inputs arepassed.
Consider how many sentences are derived from thegrammar rules in Figure 2.
25 (5 ?
1?5) sentences aregenerated by the grammar ules and dictionary entries.
Ofcourse, not only well-formed sentences as in (1) below, butalso i l l -formed sentences as in (2), (3), (4) below~ areincluded.Grammar rules DictionaryS--*NP VP : Verbal Phrase (VP)  pronoun-*thisVP--~verb NP verb -~isNP-*pronoun : Noun Phrase (NP) det ~anNP-~det noun noun -~appleNP-*noun noun --,applesThe generated sentences(1)This is an apple.
(2)This is apple.
(3)This is an apples.
(4)This is apples.Figure 2 The generated sentences3.3 The prob lem of the LFG uni f icat ion mechan ism f~oill-formed inputRelat ively i l l -formed sentences,  as well  as featureerrors, pas;~ t~rough Filter( I ).
Fi lter(I I)  must work as astrong grammatical filter.
LFG contains such a strongf i l ter ,  callc,d the unit ' icat ion mechan ism,  '"front F-.Descriptions to F-Structures fKaplan 1.982 (pp.203)/".
Forexmnpl%"This is a apple"In LFG a-disagreement, "a apple", is rejected becausethe following equations are not unified..; ( t  ~\]PEC) :a  froma( 1' SPEC) = an from appleI~owever~ for diagnosis and error-correctlon there are:~ome drawbacks in LFG framework :(1)LFG canq: check an error of omission as in the nounphrase '~  apple' in the sentence"This is apple".As tile sentence lacks the article "an", there  is nodeterminer equation and the unification mechanism doesnot work.
Thus the sentence is recognized as a well-formedsentence.f O from (h :lack of article( 1' iIPEC) = an from apple(2)LFG has no error-correction framework.
It only rejectsthe i l l -formed input.
Addit ion of an error-correct ionmechanism i'~ thus necessary.304 Improper  Grammar  \[Fi l ter (liD\]In this application, users are non-nat ive speakersunfamil iar with English grammar.
Thus, a user oftenmakes word-order errors, includes unnecessary words, orleaves out words @ @.
A teacher could show why "does" isnot necessary in the sentence @ "*Who does cookbreakfast'S", or wily "do" is needed in @ "*Where theylive?".
If a :~ystem diagnoses uch sentences, it needs toprovide the grammar ules tbr analysis.
The type of errorshown in Figure 3 is called improper grammar.
*S *Sq-pron *AUX VERB3 NP q-adv NP VERBI( ~ SUBJ)= 4 ( t OBJ)= ~ I ( t SUBJ)=I I I 1*wire doe~ cook breakfast ?
*where they live ?Figure 3 Examples of improper grammar4, '~?he fl?am(~wo~'kIn Ibis section an overv iew of the f ramework  isexplained.
Unif icagon approach has some drawbacks fordiagnosis as we described in 3.3.
A new method is used as afilter (lI).
The idea is to compare input style with properm, rfi~ce sty\]~.s which are synthesized from lexical  andgrarmmaticai conditions.
An interpretation schema collectsl:he conditions (surface schema and LFG schema) and anL~\[erpretation rule synthesizes proper styles and judgeswhether the sentence is  ill- or well,formed as shown inFigure 4.
In this section, at first, new schemata arenotated: surface schema (4.1), surface constraint (4.2),in~e~?pre~ation schema,  in terpreta t ion  schema wi thcondition, conditional schema and kill schema (4.3).
Andthen the ins~mnfiation mechanism and interpretat ion ofInput sentence.................... Jnpu~\[q)ParsingPl'oce s sing .
.
.
.
.
.
.
.
.
.
~ IFG schema'U" rfa e s cjlem a. .
.
.wm,~{ I ~ l@Instantiation * J Surface constraintFilter( II ) J ~"~T ~ ~I I mlnputsty lei - - - - -~  (~Synthesize styles (= Proper styles)Success Error lfDCorrect sentencef-structure ~ Explanation of the errorsFigure 4 A schema method overviewnew schemata are described (4.4) (4.5).
F inal ly  error-correction is i l lustrated (4.6).4.1 Inl~ut p rocess ing\ [Surface schema\[A capital etter and a punctuation indicate surface of aninput sentence.
In this framework such inibrmation isrepresented as a schema, called a surface schema.
In theinput processing, the input sentence is converted intosurface schemata.
The schema is notated as follows.
(gn f-name) =value"gn" is the designator which shows the word-order "n".
"f-name" is a function name of schema, like word, letter ormark, etc.
"value" is its schema's value.For example, tile ill-formed input, "MR.Brown have eata apple," is represented as surface schemata in Figure 5."MR."
is represented as lout-surface schemata:"(gl word) -- mr"; the word is "mr".
"(gl mark) =period"; the mark after the word is a period.
"(gl letter) = 1"; the first letter of the word is a capital ("M").
"(gl letter) = 2"; the second of the word letter is a capital ("R').Input sentence: *MR. Brown have eat a -apl~ieV--I/I I I I I * , MR. , Brown , have , eat , a , apple,designators L .
.
.
.
.
~ .
.
.
.
.
.
.
.
.
J. .
.
.
.
.
~_ .
.
.
.
.
_L ...... ~ .
.
.
.
.
.
.
.
.
.
r .
.
.
.
.
- v  .
.
.
.
.
.
.
~ .
.
.
.
.  "
I -  .
.
.
.
.
- r  .
.
.
.
.
c .
.
.
.
.
.
.
.
.ga ', gl ', g2 ', g3 I g4 *, g5 I g6Surface schemataWord = \[(gl word) = mr, (g2 word) = brown, (g3 word) = have,(g4 word) = eat, (g5 word)-- a, (g6 word) = apple\]Mark = \[(gl mark) = period, (g6 mark) =comma\]Letter -- i(gl letter) = 1, (gl letter) = 2, (g2 letter) = 1\]Figure 5 Examples of surface schema4.2 Lex icon\[Lexical  sur face  constra int \ [In the lexicon, lexical features and constraints areinvolved as schemata.
A constraint for a surface schema iscalled a surface constraint.
A surface constraint is notatedas follows:(IT f-name) = ?value.
"IT" means meta-vm: iable .
"It" is substituted for "gn",when the surface constraint is instantiated.There are two kinds of surface constraints: lexical andgranmaatical.
The capital letter "M" in "Mr." is a lexieal343constraint, because it  is capitalized regardless of sentenceposition.
A lexical surface constraint is assigned to thedictionary (Figure 6).
(IT word) =cmr; the word must be "mr".
(IT mark) = cperiod; the mark after the word must be a period.
(IT letter) =el; the first letter of the word"mr" must be a capital.Lexicon Lexical surface constraints and LFG schemataneun3 Mr. (IT word) =cmr (t  PRED-1) =mr(IT mark) = cperiod ( t GENDER) = male(IT letter) = cl ( 1' CATEGORY) = noun3nounl Brown (ITword)=cbrown (~PRED)=Brown(IT letter) = cl ( 1' PERSON) = 3( 1' NUM) = SG( 1' CATEGORY) = nounlFigure 6 Lexicon4.3 Grammar\ ]Grammat ica l  sur face  constra int \ ]The first letter in a sentence is always a capital letterand the last punctuation in a sentence is noted as a mark ( aperiod, a question mark or an exclamation point, etc.
).These are regarded as grammatica l  constraints.
In ourh'amework these grammatical  constraints are representedas grammatical surface constraints.
They are assigned togrammar ul~ as shown in Figure 7.
(ITF letter) = ?1; This means the first letter in the sentence must beacapital etter.
ITFshows firstorderinthesentence.
(ITL mark)=cperiod; This means the last mark in the sentencemust be a period.
IT L shows last order in the sentence.Grammar ruleS --* NP VP( 1' SUBJ)= $ 1' =(ITF letter)=cl (ITL mark)=cperiodFigure 7 Grammar rule with surface constraints\ [ In terpretat ion  schema\]In order to diagnose and correct errors, our frameworkhas three steps; (1)collecting information on the inputsentence, (2)synthesis of interpretation and (3) comparisonof( l )  and (2).The interpretation schema collects LFG schemata ndsurface schemata.
It is assigned to lexicon or grammarrules.
In the parsing process, it is instantiated and collectsschemata.
The schemata cor rec ted  by in terpretat ionschema are conveyed to the interpretat ion rule.
Thisschema is notated as follows.
( T f-name) = i{values}T is a meta:variable as well as LFG notation and "f- name"is a functional name of the interpretat ion schema.
ItsValues are sets of schemata?For example an interpretation schema for agreementbetween determiner and noun is notated as follows.
(~) ( t DET-NOUN)=i{\[DET\],\[NOUN\]}\[DET\] means set of schemata from determiner, and \[NOUN\]means from noun.
(Example 1) For the correctly-formed noun phrase "anapple", the interpretation schema, DET-NOUN, is attachedto grammar ule (1) as shown in Figure 8.
In instantiation,the interpretation schema collects LFG schemata in lexiconand surface schemata s its values below.344Grammar Rule and Interpretation schema(1)NP -* DET NOUN( 1' DET-NOUN) =i{\[DET\],\[NOUN\]}.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.NP:fn( 1' DET-NOUN) = i{\[DET\],\[NOUN\]}DET z / NOUN ~1 !
I x~exico.
I ( t  SPEC)='an' I I(1' PRED)='apple' '~LFGschemata I?
* NUM)=SG I I?t NUM)=SG \[.
.
.
.
.
.
.
J , , l J ( t  SPECl)='an/the'|An instantiated interpretation schema(~fn SPEC)='an' \[fin PRED)='apple' -(fn DET_NOUN)=i~\[ (fn NUM)= SG |(fn NUM)=SGU (giwOrD)=an I / ( t .
SPEC1)='an/the' A,  \[(gi+ 1WORD) = apple _Figure 8 An example of interpretation schema of"an apple"(Example 2) In another case, the ill-formed noun phrase"0  apple", lacks an article.
As above, an interpretationschema collects chemata in Figure 9.Other examples of interpretation schemata and theirattached grammar are shown in Figure 10.Grammar Rule and Interpretation schema(2)NP -,  NOUN(~' DEW-NOUN) = i{\[ ~\],\[NOUN\]}An instantiatsd interpretation schema(fn DET-NOUN)=i O 1 \[fin NUM)=SG | / I(t- SPEC1)='ar~the' | /?
J2Lg j WORD):apple A JFigure 9 An example of interpretation schema of "0  apple"\ [ Interpretat ion schema with a condi t ionand condi t iona l  schema\]An interpretation schema with a condition, and itsconditional schema are a pair and act as an interpretationschema.
An interpretation schema with condition can actwhen there is a conditional schema.
These schemata renotated as (a) an interpretation schema with a condition:( ~' f-name) = i -  CON{Values}and (b) a conditionalschema:( 1' f-name) = CON{Values}.For example, this schema (~) means that  i f  a nounphrase \[NP:f2\] is a pronoun \[PRONOUN\], it checks whetherthe case of pronoun is subjective \[subj\[.
I f the noun phrase isnot a pronoun, such as "an apple", there is no need tocheck.
(~ (f2 CASE) = i-CON\[\[NP:f2l,\[subj\]}.The following schema (~) is its conditional schema.
It isattached to grammar ule (5) and means the noun phrase isa pronoun.
(~ (f2 CASE)= CON{\[PRONOUN\]}\[Kill schema\]A k i l l  schema is the  ins tant ia t ion  inh ib i t ionmechanism.
It works to kil l  the interpretation schemataand is notated as follows:( ~ f-name)=k{( ~f-name-l), ( t f-name-2) ........
}.
(3)N~P ~-> D~T .... AOJ .~ ' NOUN~(~' ~I)ET2ADJ-NOUN) =i{\[I)ET\],\[ADJ\],\[NOUN\]}(4)NP -~ ADJ NOUN(~' DET-ADJ-NOUN) = i{\[O \],\[ADJ\],\[NOUN\]}(5)NP ~ PRONOUN(~ CASE) :~ CON{\[PRONOUN\]}(6)S:f1 --~ NF:f2 VERB3:Q NP:~(fi SUBJ) :~ i'2 (h oBJ)  = 5(ITF letter) :: ?1 (ITL mark) = cPeriod(Q SUBJ&V-.FORM) = i{\[NP:f2\],\[VERB3\]}(f2 CAGE) = i--CON{\[NP:f2\],\[subj\]}(f3 CAGE) :: i--.
OON{\[NP:fa\],\[obj/poss\]}(7)S:fl .-~ NP:t2 AUX:Q VERB3:fI NP:f3(il SUB J) ~: i2 (it onJ) = i'a(IT F letter) = cl (ITL mark) = cperiod(f~ SUBJ&A-FORM) = i{\[NP:f21,\[AUX\]}(fl AUX&V-FORM) = i{\[AUX\],\[VERB3\]}(f2 CASE) =i._CON(\[NP:f2\],\[subj\]}(f3 CASE) =~i~- C0~{\[NP:f~l,\[obj/poss\]}(8)S:it -,~ NP: f2  VERB-be:fl NP:f 3(fl SUBJ) = f2 (fl COMP) = f3(ITI,, letter) = c I (IT L mark) = cperiod(t' 1 SUBJ&V-FORM&COMP) = i{\[NP:f2I,\[VERB~be\],\[NP:f3\] }(h SUBJ&V.-FORM&COMP) = k{(f2 DET-NOUN),(f2 DET-ADJ-NOUN)}Interpretation Schemata Grammar rule~) (T DET~NOUN)=I{\[DET\],\[NOUN\]} Rule(I)(2)(~ (I' DET-AI)J-NOUN)=i{\[DET\],\[A1)J\],\[NOUN\]} Rule(3)(4)(~ (t'I SUBJ&V-FORM)=i{\[NP:f2\],\[VERB3\]} Rule(6)(8)(.4) (fl SUBJ&A-FORM) =i{\[NP:f2\],\[AUX\]} Rule('/)(f~ AUX&V-FORM) = d\[AUXI,\[VERB3\]} Rule(7)(fl SUBJ&V-FORM&COMP) = i{\[NP:f~\],\[VERB-be\],\[NP:fs\]}Rule(8)knterpretation Schemata with condition Gramlnar ule~) (f2 CASE) = i.~ CON{\[NP:f?.\],\[subj\]} Rule(6)(7)(8)Conditional ~chema Grarmnar rule(0_) (1" CASE)=cON{\[PRONOUN\] } Rule(5)Kill schema Grammar rule(9) (f2 SUBJ&V-FORM&COMP) = k{(f2 DE'r-NOUN), Rule(8)(f2 I)V.T-A~)J-NOON)}@)This schema checks agreement  between deter-miner, adjective and noun such as 'the same name','*some good advices', '*a good jobs', and '*a interestingbook'.
?Th is  schema checks whether verb ibrm (V-FORM} isa proper tbrm for subject style (SUBJ).
\[NP:f2\] is subject.For example "Tom gives...", "*He laugh ...", "Youmade _.." and "*Mr,and Mrs. Brown laughs ...".
(~)This schema checks whether auxi l iary verb form(A-FORM) i?,; a proper form for subject ~tyle (SUBJ).
\[NP:f2\]is subject.
For example "*Tom have  given..." and "Hecan laugh .. . '
.
@ This schema checks whether verb form (V-FORM) isa proper titan for auxi l iary verb.
For example '~l~om hasgiven...", '~*Tom has give..,", "*You can laughed ..." and"He is speaking ..."@This ~chema checks agreement between subjective"be" noun phrase, verb .
and compliment.
\[NP:f2\] issubjective ~aoun phrase and \[NP:fS\] is compliment.
Forexaraple "*These is apples."
, "*He is students."
and"*They are a student.
"Figure 10 Examples of grammar and interpretation schema1' is a metaovariable and "f-name" is a kil l-schema's name.Its value in { ....... } is the kil led schmnata's name.There are hierarchy and priority between interpretationschemata.
A kill schema is used to keep interpretationschemata independent.
The schema attached to nounphrase can collect schemata only wiflfin the noun phrase,while the schema attached to sentence level can collectschemata in the sentence.
Thus, the former is local and thelatter is global.
For example,"* This is a apples.
"Tile noun phrase, " a apples ", is wrong and should be"an apple".
But the local interpretation schema ~ (Figure10) can't determine which is correct, "an apple" or "apples",while the global interpretation schema @ can judge that"an apple" is correct.
The global interpretation schema ?checks ibr agreements within \[NP:fS\] instead of the localinterpretation schemata (~) or ?.
Therefore, the localinterpretation schemata (J) and (.2), are not necessary.Thus, the kill schema @, which corresponds to the globalin terpretat ion  schema @, k i l l s  local in te rpreta t ionschemata Q) and ?.
@ (f2SUBJ&V-FORM&COMP) =k{(f2 DET-NOUN),(f2 DET-ADJ-NOUN)}(~) (f2 DEW-NOUN) = i{\[DET\],\[NOUN\]}(~ (f2 DET-ADJ-NOUN) = i{\[DET\],\[ADJ\],\[NOUN\]}4.4 lns tant ia t ionHow to instantiate schema is explained.
Both t and ~ -meta-variables are assigned to actual variables (f l, f2....) aswell as LFG.A surface schema,  a sur face const ra in t  and aninterpretation schema include "IT" meta-variables.
"IT"recta-variables are assigned as follows.
(Din input processing, the designator "gn" which shows theword-order in the input sentence is assigned to surfaceschema.
(2)When' the dictionary is looked up, surface constraints inthe lexicon are instantiated.
"IT" meta-var iab le  in asurface constraint is bound to the designator "gn" in surfaceschema.
(3)When a grammar ule is fitted, surface constraints in theS: fl GrammarNP:f2 AUX:It VERB3:fl NP:fa(fl SUBJ)=f2 (fl SUBJ&A-FORM)=i (it OBJ)=fa ~ (gl letter)~-?l {\[NP:f2\],\[AUX\]} (g6 mark) =cperiod CASE)=i-CON (fl AUX&V-FORM)=i f ( f3  CASE)---i--CON {\[NP:f2\],\[subj\]} {\[AUX\],\[VERB3\]}/ {\[NP:fa\],\[obj\]}noun3 nounl l det noun!
~(  f3 DET-NOUN) = i\] | \[ \[ ~ {\[DET\],\[NOUN\]}\ : Lexicon \ :(~.
(gl word) --cmr ~ :~ : ~ ~ ~ ~" ~'~ 6wOrd)-~ capple(~) (gl word) = mr g2 g3 g4 g5 (g6 word) = appleMr.
Brown have eat an appleFigure 11 An example of a parsing tree and instantiation mechanism345grammar  ule are bound to tire designator "gn'.An example is shown in F igure 11.4.5 In terpretat ion  (F i l ter  It)After the pars ing proces.% in terpretat ion  schemata,in terpretat ion  schemata  wi th  a condit ion, condit ionalschemata nd kil l  schemata re instant iated.
Interpreta-t ion schemata re interpreted by interpretat ion rule.
Inputis judged for consistency or inconsistency.The interp, 'etat ion schemata re independent,  thus theinterpreted order is free.
The in terpretat ion  flow is asfollows.
(1)check condit ional  schema: if i t  is an in terpretat ionschema with condit ion, f ind the paired condit ion.
I fcondit ional schema are not paired, inh ib i t  the instant iatedinterpretat ion schema with a condition.
(2)check k i l l  schemata :  i f  the k i l l  schema inc ludesinterpretat ion schemata which should be killed, inh ib i t  theinstant ia ted interpretat ion schema.
(3) Interpretat ion rule: if i t  is not included, interpret  it.\ [ In terpretat ion  ru le  IAn interpretat ion rule diagnoses the input  sentence.The schemata collected by an interpretat ion schema arechecked by an interpretat ion rule.
An interpretat ion rulesynthesizes the word by us ing collected schemata.
Thediagnosis process is as follows.
(1)Find input  style from an interpretat ion schemata.
(2)Synthesize correct style by ?using an interpretat ion rule.
(3 )Compare  input  s ty le  w i th  synthes ized  s ty le ,  i fconsistent, he input  style is right.
If not, correct he inputstyle to the synthesized correct style.An in terpretat ion  ru le synthes izes  the resu l t  w i thconditions from interpretat ion schema.
For example, theI)ET-NOUN rule is Shown :in Table 2.
This rule determines ifthe noun is corrected and  synthes izes the specif ication(SPEC) tbrm as adapted for the noun.
(Example 1) In the case 0f correctly-formed noun phrase"an apple", the interpretat ion rule is shown in F igure 8.
(1)input style: (gi word)=an,  (g i+l  word) = apple fromsurface schemata in F igure 8.
(2 )synthes ized  s ty le :  cond i t ions  are  (~'NUM)=SG,( '~ SPEC1)= 'an/the' f rom noun and  ( i" SPEC) ='an'  f romdeterminant  in F igure 8, the result  is (~ SPEC)=an fromTable 2 Interpretation Rule for DET-NO_ UNRule No.
I123457 - - ,910 II__!L_ACondit ionsNUM SPEC1From noun From nounPL thePL aPL anPL ~DSG a/theSG a/theSG a/theSG an\]theSG an\]theSG an\]theSG XResultSPEC I SPECFrem dot~-- I the"- I O*- I Oa i athe I the-" I aan , anthe I the- -  I anI XRule B in Table E.(3)Compare '(gn word)== an' with '( t SeEC)=an '.
Th~ valueis the same.
Thus this noun phrase is correctly.-ibrmedo(Example 2) In the case of' the ill~tbrmed noun phrase"(D apple" which lacks an article, the interpretat ion rulesare shown in F igure 9.
(1) input style: ~, (gj word) :--= apple fYom surface schemata.
(2 )synthes ized  s ty le :  cond i t ions  are  (\]'NUM):=::\[~G,( 1" SPEC1) =: ~an/the' from noun,  the re~';ult is ( ~ SPI~C)---- anfrom rule 10 in Table 2.
(3)Comparison O with ( $ SI'EC)=an, as a result  it lacl~:s thearticle "an".
Add the surface constra int  "(gn -0.5 wo, rd):::can"  beibre "(gn word) = capple".4.6 Er ror  eorrecL ionThe error correction phase expla ins  the erroz to theuser.
For example, "*MR. F, rown have eat apple/~ the f:lowof'error correction is shown in F igure 12. input  sentence i~converted into surface schemata  and  parsed.
Sur faceconstraints and interpretat ion schemata re then obtained.These interpretat ion rules are diagnosed and three errorsfound; (1)SUBJ&A-FORM, (2)AUX&V.FORM and (3)DleT-.i'~OUNInput sentence: *MR. Brown have eat apple,.
.
.
.
.
.
.
-~-- - (Input processing) ...............................Surface schemataWord = \[(gl word):= mr, (g2 word) = brown, (g3 word) =: have,(g4 word) :: eat, (g5 word) =: apple\]Mark-: \[(gl mark) : period, (g5 mark) : comma\]Letter = \[(gl etter) := 1, (gI letter) == 2, (g2 letter) : 1\]:~ (Parsing and instantiation)Surface constraints from lexicon and grammar rulesWord: ?\[(gl word) := cmr, (g2 word) : thrown, (g3 word) : ehave,(g4 word) :: coat, (g5 word) : eapple\]Mark:  c\[(gl mark) = cperiod, (g5 mark) =: cperiod\]Letter: c\[(gl letter) --- ?1, (g2 letter) : ?1 \].
.
.
.
.
.
-~- .... (Interpretation) "-~ .... .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Convert(1)SUBJ&A-FORM: (g3 word) = chave -~ (g3 word) :=(:has(2)AUX&V-FORM: (g4 word) = coat ~ (g4 word) =ecaten(3)DET-NOUN: (g5 word) ~: apple~-~ (g4.5 word) = can, (g5 word) = apple(4)MARK: (g5 mark) : comma-+ (g5 mark) =:cperiod(5)LETTER: (gl letter) --~ 2 -~.
.
.
.
.
.
.
-~- .... (Error corection) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Surface constraints replaced by synthesized schemataWord = e\[(gl word) = cmr, (g2 word) := ebrown, (g3 word) = ehas,(g4 word) = eeaten, (g4.5 word) = can, (g5 word) ::: eapple\]Mark-- e\[(gl mark) = epcriod, (g5 mark) = cperiod\]Letter =~ ?\[(gl letter) --- el, (g2 letter) =: el \]the correct sentence : )\]/r.
Brown has eaten an apple.the reason :1)"have" must be "has".2)"eat" must be "eaten".3)" an" is needed befbx'e "apple".4)"W' in "MR" must be a small etter.5)"comma" af~er "apple" mu~t bc "period'*.Figure 12 An example of error correction346,(;,Vigure 10), Fmih~('w_ore, surface errors, (4)MARK and(5)I,ETTER, a~'e l~rlmd by the difference between surface:~chen-mta at~d surface constraints.
The surface constraintsare replac?~d by ~;ynthesized schemata.
The correctedseaten,:e, "Mr. Brown has eaten an apple.
", is thensynthe~:.
;zed ~Yom surface constraints.
The explanat ions1) ~ ?5) are g, mcrated by tim result of interpretation rule.This i}'m~,ework toa CAI ~;ystem, cal led" :\],~ :,i{}(English)(JA\["~ was applied and designed to teach English to juniorhiKh ;-mimol students.
This :.~y~tem has two main modules;( l)machine translat ion/Kudo 19g(i/and (2)this Crm,lework.If stm!e~t~: p~'oda(:?~ ill..fiwmed English int)nL, the sy~temcorrects the errors arid shows why they are wren F. If thereare no erro~'s~ gi~e sentence i.~ translated into Japanese.This sy,~i.em was implemented i~ Prolog (about 120KB).Performam~e is reul-.tir~,e (answers wi th in  5 seconds).Actually t,his system was ilscd by jun ior  h igh schoolst,dents?
We collected mistakes and then ted back to th,;system?This ~Lystem is one of applications of this \]Yamework in alimited d(m) aii).
The framework is easy to apply to anotherdomain.
To construct a m',,v system, only need be changedthe grammar, dictionary and interpretation rulcs.6, i~imitati,, m and fu tm,e  worl~The ti'a:mework/b.c grammatical ly ill...Ibrmed input wasdescribed~ (1'he following problems remain unsolved:(1)The _ Im ui(m of semantically i l ldbrmed input: in thisframework a semantically ill-..formed sentence is passed.
Ascma~,~.ic i i ~er mast be added alter filter ( l I ).
(2)The problem of interpretation: interpretation is oftenchanged by context and situation.
Human beings correctill-formed sentences by recognizing context and situation.Fo~" example, I1, is a boy?Which ic Lerpre~ation is right, dialogue situation, word..order error Cls he a boy ?)
or misimnctuation (He is a bay.)?
Asystem wil) need a context recognizer and a s i tuat ionrecognizer~C(meiasio~This paper has suggested the schema method, a newi~amework tbr correcting ill-formed input.
This fl'ameworkrecognizes input at two steps with weak and strong filters.When it is known what sentences are passed by the filter,it ca~ be u:~ed even if' imperfect.
This method has thetbllowing ad vantages:Cl)the proL(\[cul of control strategies for relaxation can beavoided beet ase the relaxation teelmiqae is not used, and(2)comfmtational efficiency?The LF(i~ floamework tbr correcting grannaatically ill-fi)~-med input was extended; a. mlrface schema and ani~terpreta t ion  schema have  bee~ proposed.
Th isfl"arnework ca~, correct enters wi thout  break ing  LFGfi 'amework, because these schm~mta, as well  as LFGschema, cab be treated.
Therefbre to make an appliedsystem is very easy.
This tYamework was implemented inProlog to devise.a ~J~ef'ul CAI system?AcknowledgmentWe would like to thank Akira Kurematu, president ofATR Interpreting Telephony Research Laboratories (ATR)and Mr.Yada, president of CSK Research Institute (CRI)for their constant encouragement.
And we would also liketo acknowledge the helpful comments of Hitoshi Iida(ATR).
Many thanks also to Hideo Kobayashi (Nishi-Sugamo Junior High School), Kenji Okamoto, YoshioOoyama, Kei Okabe and Syuuichi Tanaka (CRI).ReferencesCarboneli, J.G.&IIayes, P.J.
(1983)' Recovery Strategies for ParsingExtragramnmtical L nguage' American Journal of ComputatienalLinguistics, Volume 9, pp.123-146./iayes, P.J & Mouradian, G.V.
(1981) 'Flexible Parsing' AmericanJournal of Computational Linguistics, 7(4), pp.232-242.lteidorn, G.E.
(1982) 'Experience with an Easily Computed Metric forRanking Alternative Parses' Proceeding of 20tll Annual Meeting ofthe ACL.
Totont, Canada, pp.82-84.lleidorn, G.E,, Jensen, K., Miller, L.A. Byrd, R.J. and Codoro, M.S.
(1982} 'The EPISTLE Text-Critiquing System' IBM SystemsJournal 21 (3), pp.305-326.Jensen, K., IIeidorn, G.E., Miller, I,A.
and Ravin, Y.
(1983) 'ParseFitting and Prose Fixing: Getting a Hold on ill-formedness'American Journal of Computational Linguistics, Volume 9,Number 3-4, July-December, pp.147-160.Kaplan, R.M.& Bresnau, J.
(1982) 'Lexical-Functional Gramnmr: AFormal System for Grammatical Representation' In:Bresnan, d.(ed) 'The Mcmtal Representation of Grammatical Relations', TheMIT Press, Cambrige, Massachusetts, pp.
173-281.Katie, 1.
& Nomura, H. (1986) 'LexicaLfunctional Transfer: A TransferFramework in a Machine Translation System Based on LFG',Proceeding of 11th International Conference on ComputationalLinguistics, Bonn, August, pp.112-114.Kwasny, S.C. & Sondheimer, N.K.
(1981) 'Relaxation Techniques forParsing Grammatically Ill-formed Input in Natural LanguageUnderstanding Systems' Ammqcan Journal of ComputationalLinguistics, Vol.
7, Number 2, April-June, pp.99-108.Matmnoto, I.& Matumoto, Y.
(1976) 'A Practical IIandbook ofCommon Mistakes in English among Japanese Students andBusinessmen', ltokuseidoSchank, R.C .& Leboeitz, M. & Birnbaum, L. (1980) 'An IntegratedUnderstander' American Journal of Cmnputational Linguistics,Volume 6, Number 1, January-March, pp.13-30.Schuster, E.(1985) 'Grammar as user models' Proceedings ofthe NinethInternational Joint Conference on Artificial Intelligence, August,Los Angeles, California, pp.20-22Weischedel, R.M.
& Black, I.E.
(1980) 'Responding Intelligently toUnparsable Inputs' American Journal of ComputationalLinguistics, Volume 6, Number 2, pp.97-109.Weischedel, R.M.
& Sondheimer, N.K.
(1982) 'An hnproved Ileuristicfor Ellipsis Processing' Proceeding of 20th Annual Meeting of theACL.
To(on(, Canada, pp.85-88.Weischedel, R.M.
&'Sondheimer, N.K.
(1987) 'Meta-rules as a Basic forProcessing Ill-formed Input' ln;R.G.Reilly (ed.)
CmnmunieationFailure in Dialogue and Discourse, Elsevier Science PublishersB.V.
(North-Holland), pp.99-120.347
