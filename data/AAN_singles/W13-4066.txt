Proceedings of the SIGDIAL 2013 Conference, pages 414?422,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsRecipe For Building Robust Spoken Dialog State Trackers:Dialog State Tracking Challenge System DescriptionSungjin LeeLanguage Technologies Institute,Carnegie Mellon University,Pittsburgh, Pennsylvania, USAsungjin.lee@cs.cmu.eduMaxine EskenaziLanguage Technologies Institute,Carnegie Mellon University,Pittsburgh, Pennsylvania, USAmax@cs.cmu.eduAbstractFor robust spoken conversational interaction,many dialog state tracking algorithms havebeen developed.
Few studies, however, havereported the strengths and weaknesses of eachmethod.
The Dialog State Tracking Challenge(DSTC) is designed to address this issue bycomparing various methods on the samedomain.
In this paper, we present a set oftechniques that build a robust dialog statetracker with high performance: wide-coverageand well-calibrated data selection, feature-richdiscriminative model design, generalizationimprovement techniques and unsupervisedprior adaptation.
The DSTC results show thatthe proposed method is superior to othersystems on average on both the developmentand test datasets.1 IntroductionEven though we have recently seen an explosivegrowth of interest in speech-enabled applications,there are still many problems to overcome inorder to provide users with practical andprofitable services.
One of the long-standingproblems which may often frustrate users isAutomatic Speech Recognition (ASR) error.
Dueto ASR error, it is barely possible to directlyobserve what the user said and finally figure outthe true user goal.
The aim of dialog statetracking is, therefore, to accurately estimate thetrue dialog state from erroneous observations asa dialog unfolds.In order to achieve this goal, many dialog statetracking algorithms have been developed.
Fewstudies, however, have reported the strengths andweaknesses of each method.
The Dialog StateTracking Challenge1  (DSTC) was organized toadvance state-of-the-art technologies for dialogstate tracking by allowing for reliablecomparisons between different approaches usingthe same datasets.
Unlike other machinelearning-based empirical tasks, DSTC is alsocarefully designed to take into considerationdiverse realistic mismatches.
For instance, thereare test datasets that were collected by systemsusing different speech recognizers, spokenlanguage understanding (SLU) modules, anddialog managers.
Also there are test datasets thatwere produced by similar systems but deployedat a different time (1 year later) with extendedcoverage.
Since such mismatches betweentraining and test data may often happen in realdeployment, it is important to build a trackerwhich constantly shows high performance acrossall test datasets despite various mismatches.The aim of this paper is to describe a set oftechniques used to build a robust tracker withhigh performance: wide-coverage and well-calibrated data selection, feature-richdiscriminative model design, generalizationimprovement techniques and unsupervised prioradaptation.
Our challenge systems are basicallyvarious combinations of those techniques.
TheDSTC results demonstrate the effectiveness ofeach technique.This paper is structured as follows.
Section 2describes the challenge setup.
Section 3elaborates on our proposed approaches.
Section 4briefly describes previous research and othersystems that participated in DSTC.
Section 5presents and discusses the results.
Finally,Section 6 concludes with a brief summary andsuggestions for future research.1 http://research.microsoft.com/en-us/events/dstc/4142 Dialog State Tracking ChallengeThis section describes the task for DSTC anddatasets provided for training and test.
Most partof this section is borrowed from the DSTCmanual2.2.1 Task DescriptionDSTC data is taken from several differentspoken dialog systems which all provided busschedule information for Pittsburgh,Pennsylvania, USA as part of the Spoken DialogChallenge (Black et al 2011).
There are 9 slotswhich are evaluated: route, from.desc,from.neighborhood, from.monument, to.desc,to.neighborhood, to.monument, date, and time.Since both marginal and joint representations ofdialog states are important for deciding dialogactions, the challenge takes into considerationboth.
Each joint representation is an assignmentof values to all slots.
Thus there are 9 marginaloutputs and 1 joint output in total, which are allevaluated separately.The dialog tracker receives SLU N-besthypotheses for each user turn, each with aconfidence score.
In general, there are a largenumber of values for each slot, and the coverageof N-best hypotheses is good, thus the challengeconfines consideration of goals to slots andvalues that have been observed in an SLU output.By exploiting this aspect, the task of a dialogstate tracker is to generate a set of observed slotand value pairs, with a score between 0 and 1.The sum of all scores is restricted to sum to 1.0.Thus 1.0 ?
total score is defined as the score of aspecial value None that indicates the user?s goalhas not yet been appeared on any SLU output.2.2 DatasetsThe data is divided into 2 training sets and 4 testsets (Table 1).
For standardized development sets,each training set is split in half.
Participants wereasked to report results on the second half of eachset.
The data from group A in train2, and test1was collected using essentially the same dialogsystem.
Only a few updates were made to reflectchanges to the bus schedule.
The data in test2was collected using a different version of groupA?s dialog manager.
The data from group B intrain3 and test3 were collected using essentiallythe same dialog system; the main difference isthat test3 covers more bus routes.
Test4 tests thecondition when training and testing using totally2 http://research.microsoft.com/apps/pubs/?id=169024different dialog systems, and when there is nosame-system training data available.2.3 MetricsThere are a variety of aspects of trackerperformance that were measured: accuracy, meanreciprocal rank (MRR), ROC curves, Averagescore 3 , and Brier score 4 .
There are threeschedules for determining which turns to includein each evaluation.?
Schedule 1: Include all turns.?
Schedule 2: Include a turn for a givenconcept only if that concept either appears onthe SLU N-Best list in that turn, or if thesystem?s action references that concept inthat turn.?
Schedule 3: Include only the turn before thesystem starts over from the beginning, andthe last turn of the dialog.3 Recipe for Building a Robust TrackerIn this section, we present several ingredients forbuilding a robust state tracker that come into playat various levels of the development process:from data selection to model adaptation.3.1 Wide-Coverage and Well-CalibratedData SelectionThe first step to create a robust dialog statetracker is the use of data which covers diversesystem dialog actions and user inputs with well-calibrated confidence scores.
Since dialogpolicies can be varying according to how adialog proceeds, it is crucial to arrange a trainingdialog corpus with well-balanced dialog actions.For example, group A datasets barely haveimplicit confirmation and heavily rely on explicitconfirmation, while group B datasets have bothtypes of confirmation.
Thus a model trained ongroup A datasets cannot exploit implicit3 the average score assigned to the correct item4 the L2 norm between the vector of scores output bydialog state tracker and a vector with 1 in the positionof the correct item, and 0 elsewhereDataset Source Calls Time periodtrain2 Group A 678 Summer 2010train3 Group B 779 Summer 2010test1 Group A 765 Winter 2011-12test2 Group A 983 Winter 2011-12test3 Group B 1037 Winter 2011-12test4 Group C 451 Summer 2010Table 1: Dataset description.415confirmation when applied to group B datasets,whereas a model trained on group B datasets canbe applied to group A datasets without muchloss.Another important aspect of the data is howwell user inputs are calibrated.
If the confidencescore is well-calibrated, confirmation can beskipped in the case of a hypothesis with a highconfidence.
On the contrary, if the quality of theconfidence score is very poor, a successful dialogwill only be possible via heavy use ofconfirmation.
Thus a model trained on a well-calibrated dataset is likely to perform well on thepoorly-calibrated dataset because of backupconfirmation.
Whereas, a model trained on thepoorly-calibrated dataset will not perform wellon the well-calibrated dataset due to themismatch of the confidence score as well as thescarceness of confirmation information.
Thegroup A datasets have been shown to be poorlycalibrated (Lee and Eskenazi, 2012); this is alsoshown in Fig.
2.
Group B datasets are relativelywell-calibrated, however.The importance of wide coverage and well-calibrated data can be observed by examining theresults of entry1 and entry2 (Fig.
1) which aretrained on group A and B datasets, respectively.3.2 Feature-Rich Discriminative Model DesignMost previous approaches are based ongenerative temporal modeling where the currentdialog state is estimated using a few featuressuch as the current system action and N-besthypotheses with corresponding confidence scoresgiven the estimated dialog state at the previousturn (Gasic and Young, 2011; Lee and Eskenazi,2012; Raux and Ma, 2011; Thomson and Young,2010; Williams, 2010; Young et al 2010).However, several fundamental questions havebeen raised recently about the formulation of thedialog state update as a generative temporalmodel: limitation in modeling correlationsbetween observations in different time slices; andthe insensitive discrimination between true andfalse dialog states (Williams, 2012).Figure 2: Estimated empirical accuracy of confidencescore for from slot.
Ideally calibrated confidence scoreshould be directly proportional to empirical accuracy.Figure 1: Diagram showing the relation between datasets and models.
Each team could have up to five systemsentered.
Our challenge entries are tagged by their entry numbers.
More detailed descriptions about each modelare provided in Section 3.416In fact, such limitations can be improved byadopting a discriminative approach, whichenables the incorporation of a rich set of featureswithout worrying about their interdependence(Sutton and McCallum, 2006).
For example, ahypothesis that repeats with low confidencescores is likely to be a manifestation of ASRerror correlations between observations indifferent time slices.
Thus, the highestconfidence score that a hypothesis has attainedso far could be a useful feature in preventingrepeated incorrect hypotheses from defeating thecorrect hypothesis (which had a higher score butwas only seen once).
Another useful featurecould be the distribution of confidence scoresthat a hypothesis has attained thus far, since itmay not have the same effect as having a singleobservation with the total score due to thepotential nonlinearity of confidence scores.There are many other potentially useful features.The entire list of features used for the challengesystem is found in Appendix A.In addition to the role of rich features inperformance enhancement, the incorporation ofrich features is also important for robust statetracking.
If the tracker estimates the true state byconsidering various aspects of observations andprior knowledge, then the influence ofdifferences in certain factors between datasetscan be mitigated by many other factors that areretained relatively unchanged between datasets.For the challenge system, we employed aMaximum Entropy (MaxEnt) model which is oneof most powerful undirected graphical models.Unlike previous work using MaxEnt (Bohus andRudnicky, 2006) where the model is limited tomaintain only the top K-best hypotheses, weamended MaxEnt to allow for the entire set ofobserved hypotheses to be incorporated; Severalfeature functions which differ only by outputlabels were aggregated into one common featurefunction so that they can share commonparameters and gather their statistics together(Appendix A).
This modification is also crucialfor robust estimation of the model parameterssince some slots such as from and to can haveabout 104 values but most of them are not seen inthe training corpus.The effectiveness of feature-richdiscriminative modeling can be observed bycomparing the results of DMALL and PBM (Fig.1) which are discriminative and generativemodels, respectively.Note that interesting relational constraints, e.g.whether or not departure and arrival places arevalid on a route, can be incorporated by adoptinga structured model such as Conditional RandomField (CRF).
But CRF was not used for thechallenge since the bus information that wasprovided is not compatible with every dataset.The effectiveness of a structured model has beeninvestigated in a separate publication (Lee, 2013).3.3 Generalization Improvement TechniquesEven though the incorporation of a set of richfeatures helps overcome the weaknesses ofprevious approaches, it also implies a risk ofoverfitting training datasets due to its increasedcapacity of function class.
Overfitting is a serioushazard especially for test datasets that areseverely dissimilar to training datasets.
As notedabove, since the test datasets of the challenge areintentionally arranged to have variousmismatches, it is crucial that we prevent a modelfrom overfitting training datasets.
In the rest ofthis section, we describe various ways ofcontrolling the capacity of a model.The most obvious method to control thecapacity is to penalize larger weightsproportional to the squared values of the weightsor the absolute values of the weights.
We employthe Orthant-wise Limited-memory Quasi Newtonoptimizer (Andrew and Gao, 2007) for L1regularization.
The weights for L1 regularizationwere set to be 10 and 3 for the prior features andthe other features, respectively.
These valueswere chosen through cross-validation overseveral values rather than doing a thoroughsearch.A second method, which is often convenient,is to start with small weights and then stop thelearning before it has time to overfit providedthat it finds the true regularities before it findsthe spurious regularities that are related tospecific training datasets.
It could be hard,however, to decide when to stop.
A typicaltechnique is to keep learning until theperformance on the validation set gets worse andthen stop training and go back to the best point.For the challenge systems, we applied a simplermethod that is to stop the training if the averageobjective function change over the course of 10previous iterations is less than 0.1, which isusually set to a much smaller number such as 10-4.In general, prediction errors can bedecomposed into two main subcomponents, i.e.,error due to bias and variance (Hastie et.
al,2009).
It is also known that there is a tradeoffbetween bias and variance.
If a model is flexibleenough to fit the given data, errors due to bias417will decrease while errors due to variance willincrease.
The methods stated above try toachieve less error by decreasing errors due tovariance.
However we cannot avoid increasingerrors due to bias in this way.
Thus we need amethod to alleviate the tradeoff between bias andvariance.System combination is one powerful way toreduce variance without raising bias.
If weaverage models that have different forms andmake different mistakes, the average will dobetter than the individual models.
This effect islargest when the models make very differentpredictions from one another.
We could make themodels different by simply employing differentmachine learning algorithms as well as bytraining them on different subsets of the trainingdata.The challenge system, entry3, consists of threediscriminative models and one generative model(Fig.
1).
Entry1 and entry2 were trained ondifferent training datasets to make them producedifferent predictions.
DMCOND is a discriminativemodel trained on both train2 and train3.
Also,DMCOND differs from other discriminativemodels in the way that it was trained: theparameters associated with the features which arecomputable without grounding actioninformation (features (1), (5), (8), (9) and (10) inAppendix A) are trained first and then the otherfeatures are learned given the former parameters.The idea behind this training method is toencourage the model to put more weight ondialog policy invariant features.
The finalcomponent PBM is the AT&T Statistical DialogToolkit 5  which is one of the state-of-the-artgenerative model-based systems.
We modified itto process implicit confirmation and incorporatethe prior distribution which was estimated on thetraining corpus.
The prior distribution wassmoothed by an approximate Good-Turingestimation on the fly when the system encountersan unseen value at run time.
The improvementfrom system combination is verified by theresults of entry3.3.4 Unsupervised Prior AdaptationWhile a prior is a highly effective type ofinformation for dialog state tracking, it is alsoable to hamper the performance when incorrectlyestimated.
Thus it is worthwhile to investigateadapting the prior to the test datasets.
Since adialog state tracker is meant to estimate the5 http://www2.research.att.com/sw/tools/asdt/posterior probabilities over hypotheses, we canextract estimated labels from test datasets bysetting an appropriate threshold, taking thehypotheses with a greater probability than thethreshold as labels.
By combining the predictiveprior from test datasets and the prior fromtraining datasets, we adapted entry2 and entry3in an unsupervised way to produce entry5 andentry4, respectively (Fig.
1).
For each test dataset,we used different thresholds: 0.95 for test1, test2and test3, and 0.85 for test4.4 Related WorkSince the Partially Observable Markov DecisionProcess (POMDP) framework has offered awell-founded theory for both state tracking anddecision making, most earlier studies adoptedgenerative temporal models, the typical way toformulate belief state updates for POMDP-basedsystems (Williams and Young, 2007).
Severalapproximate methods have also emerged totackle the vast complexity of representing andmaintaining belief states, e.g., partition-basedapproaches (Gasic and Young, 2011; Lee andEskenazi, 2012; Williams, 2010; Young et al2010) and Bayesian network (BN)-basedmethods (Raux and Ma, 2011; Thomson andYoung, 2010).
A drawback of the previousgenerative models is that it is hard to incorporatea rich set of observation features, which are oftenpartly dependent on one another.
Moreover, thequality of the confidence score will be critical toall generative models proposed so far, since theydo not usually try to handle potential nonlinearityin confidence scores.As far as discriminative models are concerned,the MaxEnt model has been applied (Bohus andRudnicky, 2006).
But the model is restricted tomaintaining only the top K-best hypotheses,where K is a predefined parameter, resulting inpotential degradation of performance anddifficulties in extending it to structured models.Finally, there is a wide range of systems thatparticipated in Dialog State Tracking Challenge2013: from rule-based systems to fairly complexstatistical methods such as Deep NeuralNetworks.
Since we have not only traditionalgenerative models such as Dynamic BayesianNetwork and partition-based approaches, but alsonewly-proposed discriminative approaches suchas log-linear models, Support Vector Machinesand Deep Neural Networks, the analysis of thechallenge results is expected to reveal valuablelessons and future research directions.4185 Results and DiscussionThe official results of the challenge are publiclyavailable and our team is team6.
As mentioned inSection 2.3, there are a variety of aspects oftracker performance that were measured ondifferent schedules.
Since prediction accuracy atthe end of a dialog directly translates to thesuccess of the entire task, we first show theaverage accuracy across all test datasetsmeasured at schedule 3 in Fig.
3.
The averageaccuracy at schedule 3 also well represents howrobust a state tracker is since the test datasets arewidely distributed in the dimensions of dialogpolicies, dialog length and the quality of userinput and confidence score.First of all, we note that our 4 entries(entries2-5) took the top positions in both the Alland Joint categories.
Entry4, which showed thebest performance, outperformed the best entryfrom other teams by 4.59% (entry2 of team9)and 10.1% (entry2 of team2).
Specificially, thelarge improvement in Joint implies that ourmodel performs evenly well for all slots and ismore robust to the traits of each slot.Furthermore, from the results we can verifythe effectiveness of each technique for achievingrobustness.
Given the large gap between theperformance of entry1 and of entry2, it is clearlyshown that a model trained on a wide-coverageand well-calibrated dialog corpus can beapplicable to a broad range of test datasetswithout much loss.
Even though entry2 wastrained on only 344 dialogs (the first half oftrain3), it already surpasses most of competingmodels.The utility of a feature-rich discriminativemodel is demonstrated by the fact that DMALLgreatly outperformed PBM.
We also note thatjust using a discriminative model does not(a) All slot: a weighted average accuracy across all slots(b) Joint slotFigure 3: Accuracy measured at schedule 3 averaged over the test and development datasets.
Models which donot appear in Fig.
1 are the best system of each team except for us.
Rule denotes a rule-based system, Hybrid ahybrid system of discriminative and generative approaches, DiscTemp a discriminative temporal model, RForesta random forest model, DNN a deep neural network model, DiscJoint a discriminative model which deals withslots jointly, SVM a support vector machine model, and DBN a dynamic Bayesian network mode.419guarantee improved performance since manydiscriminative systems that participated in thechallenge underperformed some of the entriesthat were based on generative modeling or rules.This result implies that devising effectivefeatures is central to performance.In addition, this result also points to thenecessity of controlling the capacity of a model.While our models constantly show goodperformance both on development sets and testsets, the performance of the other modelssignificantly dropped off.
In fact, this explainswhy Hybrid and Rule systems switch theirpositions in the Joint slot.
Moreover, many othersystems in the graph tail seem to be severelyoverfitted, resulting in poor performance on testdatasets despite relatively good performance ondevelopment datasets.
As expected, systemcombination gives rise to better accuracy withoutloss of robustness; entry3 clearly outperformseach of its components, i.e.
entry1, entry2,DMCOND and PBM, on both development and testdatasets.Finally, the improvement observed whenusing unsupervised prior adaptation is alsoshown to be positive but its effect size is notsignificant: entry5 vs. entry2 and entry4 vs.entry3.
Given that the way in which we haveadapted the model is fairly primitive, we believethat there is much room to refine theunsupervised adaptation method.MRR measures the average of 1/R, where R isthe rank of the first correct hypothesis.
MRR atschedule 3 measures the quality of the finalranking which may be most important to a multi-modal interface that can display results to theuser.
Even though the results are not displayeddue to space limitations, the results for MRR arevery similar to those for accuracy.
Our 4 entries(entries2-5) still take the top positions.The ROC curves assess the discrimination ofthe top hypothesis?
score.
The betterdiscrimination at schedule 2 may be helpful forreducing unnecessary confirmations for valueswith sufficiently high belief.
Also, the betterdiscrimination at schedule 3 may enable a modelto adapt to test data in an unsupervised mannerby allowing us to set a proper threshold toproduce predictive labels.
The ROC curves ofour systems again showed the highest levels ofdiscrimination.6 ConclusionIn this paper, we presented a set of techniques tobuild a robust dialog state tracker without losingperformance: wide-coverage and well-calibrateddata selection, feature-rich discriminative modeldesign, generalization improvement techniquesand unsupervised prior adaptation.
The results interms of various metrics show that the proposedmethod is truly useful for building a trackerprominently robust not only to mismatchesbetween training and test datasets but also to thetraits of different slots.
Since we used relativelysimple features for this work, there is much roomto boost performance through featureengineering.
Also, more thorough search forregularization weights can give additionalperformance gain.
Moreover, one can extend thepresent discriminative model presented here to astructured version which can improveperformance further by allowing  relationalconstraints to be incorporated (Lee, 2013).Finally, we believe that once a more detailed andthorough investigation of the challenge resultshas been carried out, we will be able to take thebest of each system and combine them togenerate a much better dialog state tracker.AcknowledgmentsThis work was funded by NSF grant IIS0914927.The opinions expressed in this paper do notnecessarily reflect those of NSF.ReferencesG.
Andrew and J. Gao, 2007.
Scalable training of L1-regularized log-linear models.
In Proceedings ofICML.A.
Black et al 2011.
Spoken dialog challenge 2010:Comparison of live and control test results.
InProceedings of SIGDIAL.D.
Bohus and A. Rudnicky, 2006.
A K hypotheses +other belief updating model.
In Proceedings ofAAAI Workshop on Statistical and EmpiricalApproaches for Spoken Dialogue Systems.M.
Gasic and S. Young, 2011.
Effective handling ofdialogue state in the hidden information statePOMDP-based dialogue manager.
ACMTransactions on Speech and Language Processing,7(3).T.
Hastie, R. Tibshirani, and J. Friedman, 2009.
TheElements of Statistical Learning: Data Mining,Inference, and Prediction (2nd edition).
Springer.420S.
Lee and M. Eskenazi, 2012.
Exploiting Machine-Transcribed Dialog Corpus to Improve MultipleDialog  States Tracking Methods.
In Proceedingsof SIGDIAL, 2012.S.
Lee, 2013.
Structured Discriminative Model ForDialog State Tracking.
Submitted to SIGDIAL,2013.A.
Raux, B. Langner, D. Bohus, A. W Black, and M.Eskenazi, 2005.
Let?s Go Public!
Taking a SpokenDialog System to the Real World.
In Proceedingsof Interspeech.A.
Raux and Y. Ma, 2011.
Efficient ProbabilisticTracking of User Goal and Dialog History forSpoken Dialog Systems.
In Proceedings ofInterspeech.C.
Sutton and A. McCallum, 2006.
An Introduction toConditional Random Fields for RelationalLearning.
Introduction to Statistical RelationalLearning.
Cambridge: MIT Press.B.
Thomson and S. Young, 2010.
Bayesian update ofdialogue state: A POMDP framework for spokendialogue systems.
Computer Speech & Language,24(4):562-588.B.
Thomson, F. Jurccek, M. Gasic, S. Keizer, F.Mairesse, K. Yu, S. Young, 2010a.
Parameterlearning for POMDP spoken dialogue models.
InProceedings of SLT.J.
Williams and S. Young, 2007.
Partially observableMarkov decision processes for spoken dialogsystems.
Computer Speech & Language,21(2):393-422.J.
Williams, 2010.
Incremental partitionrecombination for efficient tracking of multipledialog states.
In Proceedings of ICASSP.J.
Williams, 2011.
An Empirical Evaluation of aStatistical Dialog System in Public Use, InProceedings of SIGDIAL.J.
Williams, 2012.
A Critical Analysis of TwoStatistical Spoken Dialog Systems in Public Use.In Proceedings of SLT.S.
Young, M. Gasic, S. Keizer, F. Mairesse, J. Schatz-mann, B. Thomson and K. Yu, 2010.
The HiddenInformation State Model: a practical framework forPOMDP-based spoken dialogue management.Computer Speech and Language, 24(2):150?174.Appendix A.
Feature FunctionsFeature functions are playing a central role to theperformance of discriminative models.
Wedescribe the feature functions that we used forthe challenge system in the following.
Tofacilitate readers?
understanding an example offeature extraction is illustrated in Fig.
4.One of the most fundamental features fordialog state tracking should exploit theconfidence scores assigned to an informedhypothesis.
The simplest form could be directuse of confidence scores.
But often pre-trainedconfidence measures fail to match the empiricaldistribution of a given dialog domain (Lee andEskenazi, 2012; Thomson et al2010).
Also thedistribution of confidence scores that ahypothesis has attained so far may not have thesame effect as the total score of the confidencescores (e.g., in Fig.
4, two observations for 61Cwith confidence score 0.3 vs. 0.6 which is thesum of the scores).
Thus we create a featurefunction that divides the range of confidencescores into bins and returns the frequency ofobservations that fall into the corresponding bin:(){(       ())(1)where      ( )  returns the set of confidencescores whose action informs   in the sequence ofobservations.
(   )  computes thefrequency of observations that fall into thebin.There are two types of grounding actionswhich are popular in spoken dialog systems, i.e.,implicit and explicit confirmation.
To leverageaffirmative or negative responses, the followingfeature functions are introduced in a similarfashion as the        feature function:(){(       ())(2)(){(       ())(3)where      ( )  /      ( )  returns the set ofconfidence scores whose associated actionaffirms / negates   in the sequence ofobservations.
(){()(4)421where          ( ) indicates whether or not theuser has negated the system?s implicitconfirmation in the sequence of observations.One of interesting feature functions is the so-called baseline feature which exploits the outputof a baseline system.
The following featurefunction emulates the output of the baselinesystem which always selects the top ASRhypothesis for the entire dialog:(){(           ())(5)where          ( )  returns the maximumconfidence score whose action informs   in thesequence of observations.
(   )  indicateswhether or not the maximum score falls into thebin.Yet another feature function of this kind is theaccumulated score which adds up all confidencescores associated with inform and affirm andsubtracts the ones with negation:(){()()()(6)Since we have a partition-based tracker, it is alsopossible to take advantage of its output:(){())(7)where    ( )  returns the posterior probabilityof a hypothesis estimated by the partition-basedtracker.
Note that such feature functions as( ) ,         ( )  and    ( )  are notindependent of the others defined previously,which may cause generative models to producedeficient probability distributions.It is known that prior information can boostthe performance (Williams, 2012) if the prior iswell-estimated.
One of advantages of generativemodels is that they provide a natural mechanismto incorporate a prior.
Discriminative modelsalso can exploit a prior by introducing additionalfeature functions:(){(            ( ))(8)where           ( ) returns the fraction ofoccurrences of   in the set of true labels.If the system cannot process a certain userrequest, it is highly likely that the user changehis/her goal.
The following feature function isdesigned to take care of such cases:()  {( )(9)where     ( ) indicates whether or not   is out-of-coverage.As with other log-linear models, we also havefeature functions for bias:()()   {(10)Note that we have an additional bias term forNone to estimate an appropriate weight for it.Here, None is a special value to indicate that thetrue hypothesis has not yet appeared in the ASRN-best lists.
Since there are generally a largenumber of values for each concept, theprobability of the true hypothesis will be verysmall unless the true hypothesis appears on theN-best lists.
Thus we can make inferences on themodel very quickly by focusing only on theobserved hypotheses at the cost of littleperformance degradation.Figure 4: A simplified example of feature extraction for the route concept.
It shows the values that each featurewill have when three consecutive user inputs are given.422
