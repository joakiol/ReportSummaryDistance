Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 492?500,Beijing, August 2010Feature-Rich Discriminative Phrase Rescoring for SMTFei Huang   and    Bing XiangIBM T. J. Watson Research Center{huangfe, bxiang}@us.ibm.comAbstractThis paper proposes a new approach tophrase rescoring for statistical machinetranslation (SMT).
A set of novel fea-tures capturing the translingual equiva-lence between a source and a targetphrase pair are introduced.
These featuresare combined with linear regressionmodel and neural network to predict thequality score of the phrase translationpair.
These phrase scores are used to dis-criminatively rescore the baseline MTsystem?s phrase library: boost goodphrase translations while prune bad ones.This approach not only significantly im-proves machine translation quality, butalso reduces the model size by a consid-erable margin.1 IntroductionStatistical Machine Translation (SMT) systems,including phrase-based (Och and Ney 2002;Koehn et.
al.
2003), syntax-based (Yamada andKnight 2001; Galley et.
al.
2004) or hybrid sys-tems (Chiang 2005; Zollmann and Venugopal2006), are typically built with bilingual phrasepairs, which are extracted from parallel sentenceswith word alignment.
Due to the noises in thebilingual sentence pairs and errors from auto-matic word alignment, the extracted phrase pairsmay contain errors, such as?
dropping content words(the $num countries ,||?:<null>),?
length mismatch(along the lines of the || ?:of)?
content irrelevance(the next $num years, ||??
:level ??
:aspect ?
:<null>)These incorrect phrase pairs compete with cor-rect phrase pairs during the decoding process,and are often selected when their counts are high(if they contain systematic alignment errors) orcertain model costs are low (for example, whensome source content words are translated intotarget function words in an incorrect phrase pair,the language model cost of the incorrect pair maybe small, making it more likely that the pair willbe selected for the final translation).
As a result,the translation quality is degraded when theseincorrect phrase pairs are selected.Various approaches have been proposed overthe past decade for the purpose of improving thephrase pair quality for SMT.
For example, a termweight based model was presented in (Zhao, etal., 2004) to rescore phrase translation pairs.
Itmodels the translation probability with similari-ties between the query (source phrase) anddocument (target phrase).
Significant improve-ment was obtained in the translation performance.In (Johnson, et al, 2007; Yang and Zheng, 2009),a statistical significance test was used to heavilyprune the phrase table and thus achieved higherprecision and better MT performance.In (Deng, et al, 2008), a generic phrase train-ing algorithm was proposed with the focus onphrase extraction.
Multiple feature functions areutilized based on information metrics or wordalignment.
The feature parameters are optimizedto directly maximize the end-to-end system per-formance.
Significant improvement was reportedfor a small MT task.
But when the phrase table islarge, such as in a large-scale SMT system, thecomputational cost of tuning with this approachwill be high due to many iterations of phrase ex-traction and re-decoding.In this paper we attempt to improve the qualityof the phrase table using discriminative phraserescoring method.
We develop extensive set offeatures capturing the equivalence of bilingual492phrase pairs.
We combine these features usinglinear and nonlinear models in order to predictthe quality of phrase pairs.
Finally we boost thescore of good phrases while pruning bad phrases.This approach not only significantly improvesthe translation quality, but also reduces thephrase table size by 16%.The paper is organized as follows: in section 2we discuss two regression models for phrase pairquality prediction: linear regression and neuralnetwork.
In section 3 we introduce the rich set offeatures.
We describe how to obtain the trainingdata for supervised learning of the two models insection 4.
Section 5 presents some approaches todiscriminative phrase rescoring using thesescores, followed by experiments on model re-gression and machine translation in section 6.2 Problem FormulationOur goal is to predict the translation quality of agiven bilingual phrase pair based on a set offeatures capturing their similarities.
Thesefeatures are combined with linear regressionmodel and neural network.
The training data forboth models are derived from phrase pairsextracted from small amount of parallelsentences with hand alignment and machinealignment.
Details are given in section 4.2.1 Linear regression modelIn the linear regression model, the predictedphrase pair quality score is defined as?=iii feffeSco ),(),( ?
(1)where ),( fef i is the feature for the phrase pair(e,f), as to be defined in section 3.
These featurevalues can be binary (0/1), integers or real val-ues.
?
s are the feature weights to be learnedfrom training data.
The phrase pair quality scorein the training data is defined as the sum of thetarget phrase?s BLEU score (Papineni et.
al.2002) and the source phrase?s BLEU score,where the reference translation is obtained fromphrase pairs extracted from human alignment.Details about the training data are given in sec-tion 4.
The linear regression model is trained us-ing a statistical package R1.
After training, the1http://www.r-project.org/learned feature weights are applied on a held-outset of phrase pairs with known quality scores toevaluate the model?s regression accuracy.2.2 Neural Network modelA feed-forward back-propagation network (Bry-son and Ho, 1969) is created with one hiddenlayer and 20 nodes.
During training, the phrasepair features are fed into the network with theirquality scores as expected outputs.
After certainiterations of training, the neural net?s weights arestable and its mean square error on the trainingset has been significantly reduced.
Then thelearned network weights are fixed, and are ap-plied to the test phrase pairs for regression accu-racy evaluation.
We use MatLab?
?s neural nettoolkit for training and test.We will compare both models?
predictionaccuracy in section 6.
We would like to knowwhether the non-linear regression model outper-forms linear regression model in terms of scoreprediction error, and if fewer regression errorscorrespond to better translation quality.3 Feature DescriptionIn this section we will describe the features weuse to model the equivalence of a bilingualphrase pair (e,f).
These features are defined onthe phrase pair, its compositional units (wordsand characters), attributes (POS tags, numbers),co-occurrence frequency, length ratio, coverageratio and alignment pattern.?
Phrase : )|( efPp , )|( fePp)(),()|( fCfeCfePp =   (2)where ),( feC is the co-occurrence frequency ofthe phrase pair (e,f), and C(f) is the occurrencefrequency of the source phrase f. )|( efPp isdefined similarly.?
Word : )|( efPw , )|( fePw?=ijijw fetfeP )|(max)|(   (3)where )|( ji fet  is the lexical translation prob-ability.
This is similar to the word-level phrase493translation probability, as typically calculated inSMT systems (Brown et.
al.
1993).
Here we usemax instead of sum.
)|( efPw is calculated simi-larly.?
Character: )|( efPc , )|( fePcWhen the source or target words are composedof smaller units, such as characters for Chinesewords, or prefix/stem/suffix for Arabic words,we can calculate their translation probability onthe sub-unit level.
This is helpful for languageswhere the meaning of a word is closely related toits compositional units, such as Chinese andArabic.
?=ininc cetfeP )|(max)|(  (4)where nc is the n-th character in the sourcephrase  f  (n=1,?,N).?
POS tag: )|( efPt , )|( fePtIn addition to the probabilities estimated at thecharacter, word and phrase levels based on thesurface forms, we also compute the POS-basedphrase translation probabilities.
For each sourceand target word in a phrase pair, we automati-cally label their POS tags.
Then POS-basedprobabilities are computed in a way similar to thecalculation of the word-level phrase translationprobability (formula 3).
It is believed that suchsyntactic information can help to distinguishgood phrase pairs from bad ones (for example,when a verb is aligned to a noun, its POS transla-tion probability should be low).?
Length ratioThis feature computes the ratio of the numberof content words in the source and target phrases.It is designed to penalize phrases where contentwords in the source phrase are dropped in thetarget phrase (or vice versa).
The ratio is definedto be 10 if the target phrase has zero contentword while the source phrase has non-zero con-tent words.
If neither phrase contains a contentword, the ratio is defined to be 1.?
Log frequencyThis feature takes the logarithm of the co-occurrence frequency of the phrase pair.
Highfrequency phrase pairs are more likely to be cor-rect translations if they are not due to systematicalignment errors.?
Coverage ratioWe propose this novel feature based on theobservation that if a phrase pair is a correct trans-lation, it often includes correct sub-phrase pairtranslations (decomposition).
Similarly a correctphrase pair will also appear in correct longerphrase pair translations (composition) unless it isa very long phrase pair itself.
Formally we definethe coverage ratio of a phrase pair (e,f) as:),(),(),( feCovfeCovfeCov cd += .
(5)Here ),( feCovd is the decomposition coverage:?
?????
?=ffPfPfeidiLiLiieefeCov)(*,)(1),(),( ,  (6)where if  is a sub-phrase of  f, and ( ie , if ) is aphrase pair in  the MT system?s bilingual phraselibrary LP .
),( 21 ee?
is defined to be 1if 21 ee ?
, otherwise it is 0.
For each sourcesub-phrase if , this formula calculates the ratiothat its target translation ie  is also a sub-phraseof the target phrase e, then the ratio is summedover all the source sub-phrases.Similarly the composition coverage is definedas?
?????
?=jLjLjjffPfPfejceefeCov)(*,),(1),(),(   (7)where jf is any source phrase containing f  andje  is one of jf ?s translations in LP .
We calljf a super-phrase of f. For each source super-phrase jf , this formula calculates the ratio thatits target translation je  is also a super-phrase ofthe target phrase e, then the ratio is summed overall the source super-phrases.Short phrase pairs (such as a phrase pair withone source word translating into one target word)have less sub-phrases but more super-phrases(for long phrase pairs, it is the other way around).494Combining the two coverage factors producesbalanced coverage ratio, not penalizing too shortor too long phrases.?
Number matchDuring preprocessing of the training data,numbers are mapped into a special token ($num)for better generalization.
Typically one numbercorresponds to one special token.
During transla-tion numbers should not be arbitrarily dropped orinserted.
Therefore we can check whether thesource and target phrases have the right numberof $num to be matched.
If they are the same thenumber match feature has value 1, otherwise itis 0.?
Alignment patternThis feature calculates the number of unalignedcontent words in a given phrase pair, where wordalignment is obtained simply based on the maxi-mum lexical translation probability of the source(target) word given all the target (source) wordsin the phrase pair.Among the above 13 features, the numbermatch feature is a binary feature, the alignmentpattern feature is an integer-value feature, andthe rest are real-value features.
Also note thatmost features are positively correlated with thephrase translation quality (the greater the featurevalue, the more likely it is a correct phrase trans-lation) except the alignment pattern feature,where more unaligned content words corre-sponds to bad phrase translations.4 Training DataThe training data for both the linear regressionand neural network models are bilingual phrasepairs with the above 13 feature values as well astheir expected phrase quality scores.
The featurevalues can be computed according to thedescription in section 3.
The expected translationquality score for the phrase pair (e,f) is defined as)|,()|,(),( ** effBleufeeBleufeB +=(8)where *e is the human translation of the sourcephrase f, and *f is the human translation of thetarget phrase e. These human translations areobtained from hand alignment of some parallelsentences.1.
Given hand alignment of some bilingualsentence pairs, extract gold phrasetranslation pairs.2.
Apply automatic word alignment on thesame bilingual sentences, and extractphrase pairs.
Note that due to the wordalignment errors, the extracted phrasepairs are noisy.3.
For each phrase pair (e, f) in the noisyphrase table, find whether the sourcephrase f also appears in the gold phrasetable as (e*, f).
If so, use the correspond-ing target phrase(s) e* as reference trans-lation(s) to evaluate the BLEU score ofthe target phrase e in the noisy phrase ta-ble.4.
Similarly, for each e in (e, f), identify (e,f*) in the gold phrase table and computethe BLEU score of f using f* as the ref-erence.5.
The sum of the above two BLEU scoresis the phrase pair?s translation qualityscore.5 Phrase RescoringGiven the bilingual phrase pairs?
quality score,there are several ways to use them for statisticalmachine translation.5.1 Quality score as a decoder featureA straightforward way is to use the quality scoresas an additional feature in the SMT system, com-bined with other features (phrase scores, wordscores, distortion scores, LM scores etc.)
for MThypotheses scoring.
The feature weight can beempirically learned using manual tuning orautomatic tuning such as MERT (Och 2003).
Inthis situation, all the phrase pairs and their qual-ity scores are stored in the MT system, which isdifferent from the following approach where in-correct phrase translations are pruned.5.2 Discriminative phrase rescoringAnother approach is to select good and badphrase pairs based on their predicted qualityscores, then discriminatively rescore the phrasepairs in the baseline phrase library.
We sort thephrase pairs based on their quality scores in adecreasing order.
The bottom N phrase pairs are495considered as incorrect translations and prunedfrom the phrase library.
The top M phrase pairsMP  are considered as good phrases with correcttranslations.
As identifying correct sub-phrasetranslation requires accurate word alignmentwithin phrase pairs, which is not easy to obtaindue to the lack of rich context information withinthe phrase pair, we only boost the good phrasepairs?
super-phrases in the phrase library.
Givena phrase pair (e,f) with phrase co-occurrencecount C(e,f), the weighted co-occurrence count isdefined as:?
?=),(),(),(),('fefeiiibfeCfeC   (9)where ( ii fe , ) is a good sub-phrase pair of (e,f)belonging to MP , with quality score ib .
Notethat if (e,f) contains multiple good sub-phrasepairs, its co-occurrence count will be boostedmultiple times.
Here the boost factor is definedas the product of quality scores of good sub-phrase pairs.
Instead of product, one can also usesum, which did not perform as well in our ex-periments.
The weighted co-occurrence count isused to calculate the new phrase translationscores:?= )(*,'),(')|(' fCfeCfeP  (10)?= ,*)('),(')|('eCfeCefP  (11)which replace the original phrase translationscores in the SMT system.
In addition to phraseco-occurrence count rescoring, the quality scorescan also be used to rescore word translation lexi-cons by updating word co-occurrence counts ac-cordingly.6 ExperimentsWe conducted several experiments to evaluatethe proposed phrase rescoring approach.
First weevaluate the two regression models?
quality scoreprediction accuracy.
Secondly, we apply the pre-dicted phrase scores on machine translation tasks.We will measure the improvement on translationquality as well as the reduction of model size.Our experiments are on English-Chinese transla-tion.6.1 Regression model evaluationWe select 10K English-Chinese sentence pairswith both hand alignment and automatic HMMalignment, and extract 106K phrase pairs withtrue phrase translation quality scores as com-puted according to formula 8.
We choose 53Kphrase pairs for regression model training andanother 53K phrase pairs for model evaluation.There are 14 parameters to be learned (13 featureweights plus an intercept parameter) for the lin-ear regression model, and 280 weights ( 2013?MSE of Phrase Pair Quality Scores0.660.680.70.720.740.760.780.8phrt2schart2s cov alignnum logfqwordt2spost2sposs2tlengthwords2tphars2tchars2tFigure 1.
Linear regression model phrase pair pre-diction MSE curve.
Errors are significantly reducedwhen more features are introduced (phrs2t /phrt2s:phrase source-to-target/target-to-source features;words2t/wordt2s: word-level; chars2t/chart2s:character-level; poss2t/post2s: POS-level; cov: cov-erage ratio; align: alignment pattern; logfq: log fre-quency; num: number match; length: length ratio).Figure 2.
Neural network model phrase pair predic-tion MSE curve.
Errors are significantly reducedwith more training iterations.496for the input weight matrix plus 120 ?
for theoutput weight vector) for the neural networkmodel.
In both cases, the training data size ismuch more than the parameters size, so there isno data sparseness problem.After the model parameters are learned fromthe training data, we apply the regression modelto the evaluation data set, then compute thephrase quality score prediction mean squarederror (MSE, also known as the average residualsum of squares):[ ]2),(),(1 ?
?=kkktkkp feBfeBKMSE (12)where pB is the predicted quality score of thephrase pair ( kk fe , ), while tB is the true scorecalculated based on human translations.Figure 1 shows the reduction of the regressionerror in the linear regression model trained withdifferent features.
One may find that the MSE issignificantly reduced (from 0.78 to 0.70) whenadditional features are added into the regressionmodel.Similarly, the neural network?s MSE curve isshown in Figure 2.
It can be seen that the MSE issignificantly reduced with more iterations oftraining (from the initial error of 1.33 to 0.42after 40 iterations).Table 2 shows some phrase pairs withhigh/low quality scores predicted by the linearregression model and the neural network.
Onecan see that both models assign high scores togood phrase translations and low scores to noisyphrase pairs.
Although the values of these scoresare beyond the range of [0, 2] as defined in for-mula 8, this is not a problem for our MT tasks,since they are only used as phrase boostingweights or pruning threshold.6.2 Machine translation evaluationWe test the above phrase rescoring approach onEnglish-Chinese machine translation.
The SMTsystem is a phrase-based decoder similar to thedescription in (Tillman 2006), where variousfeatures are combined within the log-linearframework.
These features include source-to-target phrase translation score based on relativefrequency, source-to-target and target-to-sourceword-to-word translation scores, language modelscore, distortion model scores and word count.The training data for these features are 10M Chi-Linear Regression Neural NetworkGoodphrasepairsand|?|5.52327amount|??
?
?|4.03006us|, ?
-|3.91992her husband|?
?
?|3.85536the program|??
, ?|3.81078the job|?
?
?
?
?|3.77406shrine|; ???
?|3.74336of course ,|, ??
, ?
?|3.7174is only|?
?
?
?|3.69426visit|??
?|3.67256facilities and|??
, ?
?|3.65402rights|??
|6.96817has become|?
??
|4.16468why|???
|3.82629by armed|?
??
|3.62988o|O |3.47795of drama|?
??
|3.36601government and|??
?
|3.27347introduction|??
|3.19113heart disease|??
??
|3.11829heads|???
|3.05467american consumers|??
???
|2.99706Badphrasepairsas well|?
?|1.03234closed|??
?
?|1.01271she was|???|0.99011way|??
?
?|0.955918of a|?
?
?|0.914717knowledge|??|0.875116made|??
"|0.837358the|??
??|0.801142end|??|0.769938held|?
??
?|0.742588letter|??
??
|0.39203, though|??
?
|0.37020levels of|?
?
??
|0.34892- board|??
|0.32826number of|?
??
|0.30499indonesia|?????
|0.27827xinhua at|$num |0.24433provinces|??
|0.20281new .|??
?
?
?
, |0.15430can|?
??
|0.09502Table 2.
Examples of good and bad phrase pairs based on the linear regression model and neural network?spredicted quality scores.497BLEU NIST PhraseTableSizeBaseline 38.67 9.3738 3.65MLR-mtfeat 39.31 9.5356 3.65MLR-boost (top30k) 39.36 9.5465 3.65MLR-prune (tail600k) 39.06 9.4890 3.05MLR-disc(top30K/tail600K)39.75 9.6388 3.05MNN-disc(top30K/tail600K)39.76 9.6547 3.05MLR-disc tuning 39.87 9.6594 3.05MSignificance-prune 38.96 9.3953 3.01MCount-Prune 38.65 9.3549 3.05MTable 3.
Translation quality improvementswith rescored phrase tables.
Best result (1.2BLEU gain) is obtained with discriminative res-coring by boosting top 30K phrase pairs andpruning bottom 600K phrase pairs, with someweight tuning.nese-English sentence pairs, mostly newswireand UN corpora released by LDC.
The parallelsentences have word alignment automaticallygenerated with HMM and MaxEnt word aligner.Bilingual phrase translations are extracted fromthese word-aligned parallel corpora.
Due to thenoise in the bilingual sentence pairs andautomatic word alignment errors, the phrasetranslation library contains many incorrect phrasetranslations, which lead to inaccurate translations,as seen in Figure 3.Our evaluation data is NIST MT08 English-Chinese evaluation testset, which includes 1859sentences from 129 news documents.
The auto-matic metrics are BLEU and NIST scores, asused in the NIST 2008 English-Chinese MTevaluation.
Note that as there is no whitespace asChinese word boundary, the Chinese translationsare segmented into characters before scoring inorder to reduce the variance and errors caused byautomatic word segmentation, which is also donein the NIST MT evaluation.Table 3 shows the automatic MT scores usingthe baseline phrase table and rescored phrasetables.
When the phrase quality scores from thelinear regression model are used as a separatefeature in the SMT system (LR-mtfeat as de-scribed in section 5.1), the improvement is 0.7BLEU points (0.16 in terms of NIST scores).
Byboosting the good phrase pairs (top 30K2 phrasepairs, LR-boost) from linear regression model,the MT quality is improved by 0.7 BLEU pointsover the baseline system.
Pruning the bad phrasepairs (tail 600K phrase pairs) without using thequality scores as features (LR-prune) also im-proves the MT by 0.4 BLEU points.
CombiningLR-boost and LR_prune, a discriminatively res-cored phrase table (LR-disc) improved the BLEUscore by 1.1 BLEU points, and reduce the phrasetable size by 16% (from 3.6M to 3.0M phrasepairs).
Manually tuning the boosting weights ofgood phrase pairs leads to additional improve-ment.
Discriminative rescoring using the neuralnet work scores (NN-disc) produced similar im-provement.We also experiment with phrase table pruningusing Fisher significant test, as proposed in(Johnson et.
al.
2007).
We tuned the pruningthreshold for the best result.
It shows that thesignificance pruning improves over the baselineby 0.3 BLEU pts with 17.5% reduction in phrasetable, but is not as good as our proposed phraserescoring method.
In addition, we also show theMT result using a count pruning phrase table(Count-Prune) where 600K phrase translationpairs are pruned based on their co-occurrencecounts.
The MT performance of such phrase ta-ble pruning is slightly worse than the baselineMT system, and significantly worse than the re-sult using the proposed rescored phrase table.When comparing the linear regression andneural network models, we find rescoring withboth models lead to similar MT improvements,even though the neural network model has muchfewer regression errors (0.44 vs. 0.7 in terms ofMSE).
This is due to the rich parameter space ofthe neural network.Overall, the discriminative phrase rescoringimproves the SMT quality by 1.2 BLEU pointsand reduces the phrase table size by 16%.
Withstatistical significance test (Zhang and Vogel2004), all the improvements are statistically sig-nificant with p-value < 0.0001.Figure 3 presents some English sentences,with phrase translation pairs selected in the finaltranslations (the top one is from the baseline MTsystem and the bottom one is from the LR-discsystem).2These thresholds are empirically chosen.498We find that incorrect phrase translations in thebaseline system (as highlighted with blue boldfont) are corrected and better translation resultsare obtained.7 ConclusionWe introduced a discriminative phrase rescoringapproach, which combined rich features withlinear regression and neural network to predictphrase pair translation qualities.
Based on thesequality scores, we boost good phrase translationswhile pruning bad phrase translations.
This led tostatistically significant improvement (1.2 BLEUpoints) in MT and reduced phrase table size by16%.For the future work, we would like to exploreother models for quality score prediction, such asSVM.
We will want to try other approaches toutilize the phrase pair quality scores, in additionto rescoring the co-occurrence frequency.
Finally,we will test this approach in other domain appli-cations and language pairs.ReferencesPeter F. Brown, Vincent J. Della Pietra, Stephen A.Della Pietra, Robert L. Mercer.
1993.
The Mathe-matics of Statistical Machine Translation: Parame-ter Estimation, Computational Linguistics, v.19 n.2,June 1993.Arthur Earl Bryson, Yu-Chi Ho.
1969.
Applied Opti-mal Control: Optimization, Estimation, and Con-trol.
Blaisdell Publishing Company.
p481.David Chiang.
2005.
A Hierarchical Phrase-basedModel for Statistical Machine Translation.
2005.In Proc.
of ACL, pp.
263?270.Yonggang Deng, Jia Xu, and Yuqing Gao.
2008.Phrase Table Training for Precision and Recall:What Makes a Good Phrase and a Good PhrasePair?
In Proc.
of ACL/HLT, pp.
81-88.Michel Galley, Mark Hopkins, Kevin Knight, DanielMarcu.
2004.
What's in a Translation Rule?
InProc.
of NAACL 2004, pp.
273-280.Howard Johnson, Joel Martin, George Foster, andRoland Kuhn.
2007.
Improving Translation Qualityby Discarding Most of the Phrase Table.
In Proc.of EMNLP-CoNLL, pp.
967-975.SrcBaselinePhrRescoIndonesian bird flu victim contracted virus indirectly:<indonesian bird flu|??
??
?> <virus|?
?> <victim contracted|??
?> <indi-rectly :|??
:><indonesian bird flu|??
??
?> <victim|??
?> <contracted|?
?> <virus|?
?> <indirectly :|??
:>SrcBaselinePhrRescoThe director of Palestinian human rights group Al-Dhamir, Khalil Abu Shammaleh, saidhe was also opposed to the move.<the director of|??
?> <palestinian|???
?> <human rights group|??
?
?><al -|" ?? "
?
?> <,|,> <abu|Abu> <khalil|Khalil> <, said he was|??
, ?> <also opposed to|?
?
?> <the move .|?
?
??
?><the director of|??
?> <palestinian|???
?> <human rights group|??
?
?><al -|al -> <, khalil|, khalil> <abu|?
?> <, said he was|?
, ?> <also opposed to|??
?> <the move .|?
?
??
?>SrcBaselinePhrRescoA young female tourist and two of her Kashmiri friends were among the victims.<a young female|?
?
?
??
?
?> <tourist and|??
?> <$num of her|?
?$num ?> <kashmiri|???
?> <friends were|?
?> <among the|??
?> <victims.|???
?><a young|?
?
??
?> <female|?
?> <tourist and|??
?> <$num of her|?
?$num ?> <kashmiri|???
?> <friends were|?
?> <among the|??
?> <victims.|???
?>Figure 3.
Examples of English sentences and their translation, with phrase pairs from baseline sys-tem and phrase rescored system.
Highlighted text are initial phrase translation errors which are cor-rected in the PhrResco translations.499Philipp Koehn, Franz Josef Och, Daniel Marcu.
2003.Statistical Phrase-based Translation, In Proc.
ofNAACL, pp.
48-54.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels, Computational Linguistics, v.29 n.1,pp.19-51, March 2003Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation, In Proc.
of ACL,2003, pp.
160-167.Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation, In Proc.
ofACL, pp.
311-318.Christoph Tillmann.
2006.
Efficient Dynamic Pro-gramming Search Algorithms for Phrase-basedSMT.
In Proc.
of the Workshop CHPSLP atHLT'06.Kenji Yamada and Kevin Knight.
2001.
A Syntax-based Statistical Translation Model, In Proc.
ofACL, pp.523-530.Mei Yang and Jing Zheng.
2009.
Toward Smaller,Faster, and Better Hierarchical Phrase-basedSMT.
In Proc.
of ACL-IJCNLP, pp.
237-240.Ying Zhang and Stephan Vogel.
2004.
MeasuringConfidence Intervals for the Machine TranslationEvaluation Metrics, In Proc.
TMI, pp.
4-6.Bing Zhao, Stephan Vogel, and Alex Waibel.
2004.Phrase Pair Rescoring with Term Weighting forStatistical Machine Translation.
In Proc.
ofEMNLP, pp.
206-213.Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax Augmented Machine Translation via ChartParsing.
In Proc.
of NAACL 2006- Workshop onstatistical machine translation.500
